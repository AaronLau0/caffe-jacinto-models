I0702 23:02:42.982724 13779 caffe.cpp:209] Using GPUs 0, 1
I0702 23:02:42.985044 13779 caffe.cpp:214] GPU 0: GeForce GTX 1080
I0702 23:02:42.985390 13779 caffe.cpp:214] GPU 1: GeForce GTX 1080
I0702 23:02:43.375926 13779 solver.cpp:48] Initializing solver from parameters: 
train_net: "training/cityscapes5_jsegnet21v2_2017-07-02_23-02-42/initial/train.prototxt"
test_net: "training/cityscapes5_jsegnet21v2_2017-07-02_23-02-42/initial/test.prototxt"
test_iter: 125
test_interval: 2000
base_lr: 0.0001
display: 100
max_iter: 32000
lr_policy: "multistep"
gamma: 0.1
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 10000
snapshot_prefix: "training/cityscapes5_jsegnet21v2_2017-07-02_23-02-42/initial/cityscapes5_jsegnet21v2"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
snapshot_after_train: true
test_initialization: false
stepvalue: 24000
iter_size: 1
type: "Adam"
I0702 23:02:43.376019 13779 solver.cpp:82] Creating training net from train_net file: training/cityscapes5_jsegnet21v2_2017-07-02_23-02-42/initial/train.prototxt
I0702 23:02:43.376726 13779 net.cpp:327] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top1
I0702 23:02:43.376732 13779 net.cpp:327] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top5
W0702 23:02:43.376744 13779 parallel.cpp:400] Batch size must be divisible by the number of solvers (GPUs)
I0702 23:02:43.377065 13779 net.cpp:56] Initializing net from parameters: 
name: "jsegnet21v2_train"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageLabelData"
  top: "data"
  top: "label"
  transform_param {
    mirror: true
    crop_size: 640
    mean_value: 0
  }
  image_label_data_param {
    image_list_path: "data/train-image-lmdb"
    label_list_path: "data/train-label-lmdb"
    batch_size: 8
    threads: 4
    backend: LMDB
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a/bn"
  top: "conv1a/bn"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a/bn"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b/bn"
  top: "conv1b/bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b/bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2a/bn"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b/bn"
  top: "res2a_branch2b/bn"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b/bn"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2a/bn"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b/bn"
  top: "res3a_branch2b/bn"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b/bn"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2a/bn"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b/bn"
  top: "res4a_branch2b/bn"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b/bn"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2a/bn"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b/bn"
  top: "res5a_branch2b/bn"
}
layer {
  name: "out5a"
  type: "Convolution"
  bottom: "res5a_branch2b/bn"
  top: "out5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "out5a/bn"
  type: "BatchNorm"
  bottom: "out5a"
  top: "out5a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "out5a/relu"
  type: "ReLU"
  bottom: "out5a/bn"
  top: "out5a/bn"
}
layer {
  name: "out5a_up2"
  type: "Deconvolution"
  bottom: "out5a/bn"
  top: "out5a_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 64
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out3a"
  type: "Convolution"
  bottom: "res3a_branch2b/bn"
  top: "out3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "out3a/bn"
  type: "BatchNorm"
  bottom: "out3a"
  top: "out3a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "out3a/relu"
  type: "ReLU"
  bottom: "out3a/bn"
  top: "out3a/bn"
}
layer {
  name: "out3_out5_combined"
  type: "Eltwise"
  bottom: "out5a_up2"
  bottom: "out3a/bn"
  top: "out3_out5_combined"
}
layer {
  name: "ctx_conv1"
  type: "Convolution"
  bottom: "out3_out5_combined"
  top: "ctx_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_conv1/bn"
  type: "BatchNorm"
  bottom: "ctx_conv1"
  top: "ctx_conv1/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ctx_conv1/relu"
  type: "ReLU"
  bottom: "ctx_conv1/bn"
  top: "ctx_conv1/bn"
}
layer {
  name: "ctx_conv2"
  type: "Convolution"
  bottom: "ctx_conv1/bn"
  top: "ctx_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv2/bn"
  type: "BatchNorm"
  bottom: "ctx_conv2"
  top: "ctx_conv2/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ctx_conv2/relu"
  type: "ReLU"
  bottom: "ctx_conv2/bn"
  top: "ctx_conv2/bn"
}
layer {
  name: "ctx_conv3"
  type: "Convolution"
  bottom: "ctx_conv2/bn"
  top: "ctx_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv3/bn"
  type: "BatchNorm"
  bottom: "ctx_conv3"
  top: "ctx_conv3/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ctx_conv3/relu"
  type: "ReLU"
  bottom: "ctx_conv3/bn"
  top: "ctx_conv3/bn"
}
layer {
  name: "ctx_conv4"
  type: "Convolution"
  bottom: "ctx_conv3/bn"
  top: "ctx_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv4/bn"
  type: "BatchNorm"
  bottom: "ctx_conv4"
  top: "ctx_conv4/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ctx_conv4/relu"
  type: "ReLU"
  bottom: "ctx_conv4/bn"
  top: "ctx_conv4/bn"
}
layer {
  name: "ctx_final"
  type: "Convolution"
  bottom: "ctx_conv4/bn"
  top: "ctx_final"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_final/relu"
  type: "ReLU"
  bottom: "ctx_final"
  top: "ctx_final"
}
layer {
  name: "out_deconv_final_up2"
  type: "Deconvolution"
  bottom: "ctx_final"
  top: "out_deconv_final_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up4"
  type: "Deconvolution"
  bottom: "out_deconv_final_up2"
  top: "out_deconv_final_up4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up8"
  type: "Deconvolution"
  bottom: "out_deconv_final_up4"
  top: "out_deconv_final_up8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: 255
    normalization: VALID
  }
}
I0702 23:02:43.377203 13779 layer_factory.hpp:77] Creating layer data
I0702 23:02:43.377215 13779 net.cpp:98] Creating Layer data
I0702 23:02:43.377220 13779 net.cpp:413] data -> data
I0702 23:02:43.377238 13779 net.cpp:413] data -> label
I0702 23:02:43.378918 13794 db_lmdb.cpp:35] Opened lmdb data/train-image-lmdb
I0702 23:02:43.378918 13799 db_lmdb.cpp:35] Opened lmdb data/train-label-lmdb
I0702 23:02:43.382324 13779 data_layer.cpp:78] ReshapePrefetch 8, 3, 640, 640
I0702 23:02:43.382370 13779 data_layer.cpp:83] output data size: 8,3,640,640
I0702 23:02:43.422585 13779 data_layer.cpp:78] ReshapePrefetch 8, 1, 640, 640
I0702 23:02:43.422629 13779 data_layer.cpp:83] output data size: 8,1,640,640
I0702 23:02:43.431246 13815 blocking_queue.cpp:50] Waiting for data
I0702 23:02:43.440179 13779 net.cpp:148] Setting up data
I0702 23:02:43.440198 13779 net.cpp:155] Top shape: 8 3 640 640 (9830400)
I0702 23:02:43.440201 13779 net.cpp:155] Top shape: 8 1 640 640 (3276800)
I0702 23:02:43.440203 13779 net.cpp:163] Memory required for data: 52428800
I0702 23:02:43.440212 13779 layer_factory.hpp:77] Creating layer data/bias
I0702 23:02:43.440219 13779 net.cpp:98] Creating Layer data/bias
I0702 23:02:43.440223 13779 net.cpp:439] data/bias <- data
I0702 23:02:43.440230 13779 net.cpp:413] data/bias -> data/bias
I0702 23:02:43.441210 13779 net.cpp:148] Setting up data/bias
I0702 23:02:43.441218 13779 net.cpp:155] Top shape: 8 3 640 640 (9830400)
I0702 23:02:43.441220 13779 net.cpp:163] Memory required for data: 91750400
I0702 23:02:43.441229 13779 layer_factory.hpp:77] Creating layer conv1a
I0702 23:02:43.441239 13779 net.cpp:98] Creating Layer conv1a
I0702 23:02:43.441242 13779 net.cpp:439] conv1a <- data/bias
I0702 23:02:43.441246 13779 net.cpp:413] conv1a -> conv1a
I0702 23:02:43.443279 13779 net.cpp:148] Setting up conv1a
I0702 23:02:43.443294 13779 net.cpp:155] Top shape: 8 32 320 320 (26214400)
I0702 23:02:43.443296 13779 net.cpp:163] Memory required for data: 196608000
I0702 23:02:43.443302 13779 layer_factory.hpp:77] Creating layer conv1a/bn
I0702 23:02:43.443308 13779 net.cpp:98] Creating Layer conv1a/bn
I0702 23:02:43.443310 13779 net.cpp:439] conv1a/bn <- conv1a
I0702 23:02:43.443315 13779 net.cpp:413] conv1a/bn -> conv1a/bn
I0702 23:02:43.444597 13779 net.cpp:148] Setting up conv1a/bn
I0702 23:02:43.444607 13779 net.cpp:155] Top shape: 8 32 320 320 (26214400)
I0702 23:02:43.444609 13779 net.cpp:163] Memory required for data: 301465600
I0702 23:02:43.444615 13779 layer_factory.hpp:77] Creating layer conv1a/relu
I0702 23:02:43.444620 13779 net.cpp:98] Creating Layer conv1a/relu
I0702 23:02:43.444622 13779 net.cpp:439] conv1a/relu <- conv1a/bn
I0702 23:02:43.444625 13779 net.cpp:400] conv1a/relu -> conv1a/bn (in-place)
I0702 23:02:43.444638 13779 net.cpp:148] Setting up conv1a/relu
I0702 23:02:43.444640 13779 net.cpp:155] Top shape: 8 32 320 320 (26214400)
I0702 23:02:43.444643 13779 net.cpp:163] Memory required for data: 406323200
I0702 23:02:43.444645 13779 layer_factory.hpp:77] Creating layer conv1b
I0702 23:02:43.444651 13779 net.cpp:98] Creating Layer conv1b
I0702 23:02:43.444653 13779 net.cpp:439] conv1b <- conv1a/bn
I0702 23:02:43.444656 13779 net.cpp:413] conv1b -> conv1b
I0702 23:02:43.444949 13779 net.cpp:148] Setting up conv1b
I0702 23:02:43.444955 13779 net.cpp:155] Top shape: 8 32 320 320 (26214400)
I0702 23:02:43.444957 13779 net.cpp:163] Memory required for data: 511180800
I0702 23:02:43.444962 13779 layer_factory.hpp:77] Creating layer conv1b/bn
I0702 23:02:43.444965 13779 net.cpp:98] Creating Layer conv1b/bn
I0702 23:02:43.444967 13779 net.cpp:439] conv1b/bn <- conv1b
I0702 23:02:43.444970 13779 net.cpp:413] conv1b/bn -> conv1b/bn
I0702 23:02:43.445454 13779 net.cpp:148] Setting up conv1b/bn
I0702 23:02:43.445461 13779 net.cpp:155] Top shape: 8 32 320 320 (26214400)
I0702 23:02:43.445462 13779 net.cpp:163] Memory required for data: 616038400
I0702 23:02:43.445467 13779 layer_factory.hpp:77] Creating layer conv1b/relu
I0702 23:02:43.445469 13779 net.cpp:98] Creating Layer conv1b/relu
I0702 23:02:43.445472 13779 net.cpp:439] conv1b/relu <- conv1b/bn
I0702 23:02:43.445474 13779 net.cpp:400] conv1b/relu -> conv1b/bn (in-place)
I0702 23:02:43.445477 13779 net.cpp:148] Setting up conv1b/relu
I0702 23:02:43.445479 13779 net.cpp:155] Top shape: 8 32 320 320 (26214400)
I0702 23:02:43.445482 13779 net.cpp:163] Memory required for data: 720896000
I0702 23:02:43.445483 13779 layer_factory.hpp:77] Creating layer pool1
I0702 23:02:43.445488 13779 net.cpp:98] Creating Layer pool1
I0702 23:02:43.445490 13779 net.cpp:439] pool1 <- conv1b/bn
I0702 23:02:43.445493 13779 net.cpp:413] pool1 -> pool1
I0702 23:02:43.445523 13779 net.cpp:148] Setting up pool1
I0702 23:02:43.445528 13779 net.cpp:155] Top shape: 8 32 160 160 (6553600)
I0702 23:02:43.445529 13779 net.cpp:163] Memory required for data: 747110400
I0702 23:02:43.445531 13779 layer_factory.hpp:77] Creating layer res2a_branch2a
I0702 23:02:43.445535 13779 net.cpp:98] Creating Layer res2a_branch2a
I0702 23:02:43.445538 13779 net.cpp:439] res2a_branch2a <- pool1
I0702 23:02:43.445540 13779 net.cpp:413] res2a_branch2a -> res2a_branch2a
I0702 23:02:43.446800 13779 net.cpp:148] Setting up res2a_branch2a
I0702 23:02:43.446810 13779 net.cpp:155] Top shape: 8 64 160 160 (13107200)
I0702 23:02:43.446811 13779 net.cpp:163] Memory required for data: 799539200
I0702 23:02:43.446816 13779 layer_factory.hpp:77] Creating layer res2a_branch2a/bn
I0702 23:02:43.446820 13779 net.cpp:98] Creating Layer res2a_branch2a/bn
I0702 23:02:43.446822 13779 net.cpp:439] res2a_branch2a/bn <- res2a_branch2a
I0702 23:02:43.446825 13779 net.cpp:413] res2a_branch2a/bn -> res2a_branch2a/bn
I0702 23:02:43.447300 13779 net.cpp:148] Setting up res2a_branch2a/bn
I0702 23:02:43.447305 13779 net.cpp:155] Top shape: 8 64 160 160 (13107200)
I0702 23:02:43.447307 13779 net.cpp:163] Memory required for data: 851968000
I0702 23:02:43.447312 13779 layer_factory.hpp:77] Creating layer res2a_branch2a/relu
I0702 23:02:43.447314 13779 net.cpp:98] Creating Layer res2a_branch2a/relu
I0702 23:02:43.447316 13779 net.cpp:439] res2a_branch2a/relu <- res2a_branch2a/bn
I0702 23:02:43.447319 13779 net.cpp:400] res2a_branch2a/relu -> res2a_branch2a/bn (in-place)
I0702 23:02:43.447322 13779 net.cpp:148] Setting up res2a_branch2a/relu
I0702 23:02:43.447324 13779 net.cpp:155] Top shape: 8 64 160 160 (13107200)
I0702 23:02:43.447326 13779 net.cpp:163] Memory required for data: 904396800
I0702 23:02:43.447329 13779 layer_factory.hpp:77] Creating layer res2a_branch2b
I0702 23:02:43.447335 13779 net.cpp:98] Creating Layer res2a_branch2b
I0702 23:02:43.447336 13779 net.cpp:439] res2a_branch2b <- res2a_branch2a/bn
I0702 23:02:43.447340 13779 net.cpp:413] res2a_branch2b -> res2a_branch2b
I0702 23:02:43.448400 13779 net.cpp:148] Setting up res2a_branch2b
I0702 23:02:43.448407 13779 net.cpp:155] Top shape: 8 64 160 160 (13107200)
I0702 23:02:43.448410 13779 net.cpp:163] Memory required for data: 956825600
I0702 23:02:43.448413 13779 layer_factory.hpp:77] Creating layer res2a_branch2b/bn
I0702 23:02:43.448417 13779 net.cpp:98] Creating Layer res2a_branch2b/bn
I0702 23:02:43.448420 13779 net.cpp:439] res2a_branch2b/bn <- res2a_branch2b
I0702 23:02:43.448422 13779 net.cpp:413] res2a_branch2b/bn -> res2a_branch2b/bn
I0702 23:02:43.448909 13779 net.cpp:148] Setting up res2a_branch2b/bn
I0702 23:02:43.448915 13779 net.cpp:155] Top shape: 8 64 160 160 (13107200)
I0702 23:02:43.448917 13779 net.cpp:163] Memory required for data: 1009254400
I0702 23:02:43.448922 13779 layer_factory.hpp:77] Creating layer res2a_branch2b/relu
I0702 23:02:43.448925 13779 net.cpp:98] Creating Layer res2a_branch2b/relu
I0702 23:02:43.448927 13779 net.cpp:439] res2a_branch2b/relu <- res2a_branch2b/bn
I0702 23:02:43.448930 13779 net.cpp:400] res2a_branch2b/relu -> res2a_branch2b/bn (in-place)
I0702 23:02:43.448933 13779 net.cpp:148] Setting up res2a_branch2b/relu
I0702 23:02:43.448935 13779 net.cpp:155] Top shape: 8 64 160 160 (13107200)
I0702 23:02:43.448937 13779 net.cpp:163] Memory required for data: 1061683200
I0702 23:02:43.448940 13779 layer_factory.hpp:77] Creating layer pool2
I0702 23:02:43.448942 13779 net.cpp:98] Creating Layer pool2
I0702 23:02:43.448945 13779 net.cpp:439] pool2 <- res2a_branch2b/bn
I0702 23:02:43.448946 13779 net.cpp:413] pool2 -> pool2
I0702 23:02:43.448971 13779 net.cpp:148] Setting up pool2
I0702 23:02:43.448976 13779 net.cpp:155] Top shape: 8 64 80 80 (3276800)
I0702 23:02:43.448977 13779 net.cpp:163] Memory required for data: 1074790400
I0702 23:02:43.448979 13779 layer_factory.hpp:77] Creating layer res3a_branch2a
I0702 23:02:43.448983 13779 net.cpp:98] Creating Layer res3a_branch2a
I0702 23:02:43.448985 13779 net.cpp:439] res3a_branch2a <- pool2
I0702 23:02:43.448988 13779 net.cpp:413] res3a_branch2a -> res3a_branch2a
I0702 23:02:43.450639 13779 net.cpp:148] Setting up res3a_branch2a
I0702 23:02:43.450645 13779 net.cpp:155] Top shape: 8 128 80 80 (6553600)
I0702 23:02:43.450647 13779 net.cpp:163] Memory required for data: 1101004800
I0702 23:02:43.450650 13779 layer_factory.hpp:77] Creating layer res3a_branch2a/bn
I0702 23:02:43.450654 13779 net.cpp:98] Creating Layer res3a_branch2a/bn
I0702 23:02:43.450655 13779 net.cpp:439] res3a_branch2a/bn <- res3a_branch2a
I0702 23:02:43.450659 13779 net.cpp:413] res3a_branch2a/bn -> res3a_branch2a/bn
I0702 23:02:43.451082 13779 net.cpp:148] Setting up res3a_branch2a/bn
I0702 23:02:43.451087 13779 net.cpp:155] Top shape: 8 128 80 80 (6553600)
I0702 23:02:43.451089 13779 net.cpp:163] Memory required for data: 1127219200
I0702 23:02:43.451097 13779 layer_factory.hpp:77] Creating layer res3a_branch2a/relu
I0702 23:02:43.451098 13779 net.cpp:98] Creating Layer res3a_branch2a/relu
I0702 23:02:43.451100 13779 net.cpp:439] res3a_branch2a/relu <- res3a_branch2a/bn
I0702 23:02:43.451103 13779 net.cpp:400] res3a_branch2a/relu -> res3a_branch2a/bn (in-place)
I0702 23:02:43.451107 13779 net.cpp:148] Setting up res3a_branch2a/relu
I0702 23:02:43.451110 13779 net.cpp:155] Top shape: 8 128 80 80 (6553600)
I0702 23:02:43.451112 13779 net.cpp:163] Memory required for data: 1153433600
I0702 23:02:43.451113 13779 layer_factory.hpp:77] Creating layer res3a_branch2b
I0702 23:02:43.451118 13779 net.cpp:98] Creating Layer res3a_branch2b
I0702 23:02:43.451120 13779 net.cpp:439] res3a_branch2b <- res3a_branch2a/bn
I0702 23:02:43.451124 13779 net.cpp:413] res3a_branch2b -> res3a_branch2b
I0702 23:02:43.452039 13779 net.cpp:148] Setting up res3a_branch2b
I0702 23:02:43.452044 13779 net.cpp:155] Top shape: 8 128 80 80 (6553600)
I0702 23:02:43.452046 13779 net.cpp:163] Memory required for data: 1179648000
I0702 23:02:43.452049 13779 layer_factory.hpp:77] Creating layer res3a_branch2b/bn
I0702 23:02:43.452052 13779 net.cpp:98] Creating Layer res3a_branch2b/bn
I0702 23:02:43.452054 13779 net.cpp:439] res3a_branch2b/bn <- res3a_branch2b
I0702 23:02:43.452056 13779 net.cpp:413] res3a_branch2b/bn -> res3a_branch2b/bn
I0702 23:02:43.452476 13779 net.cpp:148] Setting up res3a_branch2b/bn
I0702 23:02:43.452482 13779 net.cpp:155] Top shape: 8 128 80 80 (6553600)
I0702 23:02:43.452484 13779 net.cpp:163] Memory required for data: 1205862400
I0702 23:02:43.452488 13779 layer_factory.hpp:77] Creating layer res3a_branch2b/relu
I0702 23:02:43.452491 13779 net.cpp:98] Creating Layer res3a_branch2b/relu
I0702 23:02:43.452498 13779 net.cpp:439] res3a_branch2b/relu <- res3a_branch2b/bn
I0702 23:02:43.452502 13779 net.cpp:400] res3a_branch2b/relu -> res3a_branch2b/bn (in-place)
I0702 23:02:43.452505 13779 net.cpp:148] Setting up res3a_branch2b/relu
I0702 23:02:43.452507 13779 net.cpp:155] Top shape: 8 128 80 80 (6553600)
I0702 23:02:43.452509 13779 net.cpp:163] Memory required for data: 1232076800
I0702 23:02:43.452510 13779 layer_factory.hpp:77] Creating layer res3a_branch2b/bn_res3a_branch2b/relu_0_split
I0702 23:02:43.452513 13779 net.cpp:98] Creating Layer res3a_branch2b/bn_res3a_branch2b/relu_0_split
I0702 23:02:43.452515 13779 net.cpp:439] res3a_branch2b/bn_res3a_branch2b/relu_0_split <- res3a_branch2b/bn
I0702 23:02:43.452517 13779 net.cpp:413] res3a_branch2b/bn_res3a_branch2b/relu_0_split -> res3a_branch2b/bn_res3a_branch2b/relu_0_split_0
I0702 23:02:43.452520 13779 net.cpp:413] res3a_branch2b/bn_res3a_branch2b/relu_0_split -> res3a_branch2b/bn_res3a_branch2b/relu_0_split_1
I0702 23:02:43.452545 13779 net.cpp:148] Setting up res3a_branch2b/bn_res3a_branch2b/relu_0_split
I0702 23:02:43.452548 13779 net.cpp:155] Top shape: 8 128 80 80 (6553600)
I0702 23:02:43.452551 13779 net.cpp:155] Top shape: 8 128 80 80 (6553600)
I0702 23:02:43.452553 13779 net.cpp:163] Memory required for data: 1284505600
I0702 23:02:43.452554 13779 layer_factory.hpp:77] Creating layer pool3
I0702 23:02:43.452558 13779 net.cpp:98] Creating Layer pool3
I0702 23:02:43.452559 13779 net.cpp:439] pool3 <- res3a_branch2b/bn_res3a_branch2b/relu_0_split_0
I0702 23:02:43.452561 13779 net.cpp:413] pool3 -> pool3
I0702 23:02:43.452585 13779 net.cpp:148] Setting up pool3
I0702 23:02:43.452589 13779 net.cpp:155] Top shape: 8 128 40 40 (1638400)
I0702 23:02:43.452590 13779 net.cpp:163] Memory required for data: 1291059200
I0702 23:02:43.452592 13779 layer_factory.hpp:77] Creating layer res4a_branch2a
I0702 23:02:43.452597 13779 net.cpp:98] Creating Layer res4a_branch2a
I0702 23:02:43.452600 13779 net.cpp:439] res4a_branch2a <- pool3
I0702 23:02:43.452602 13779 net.cpp:413] res4a_branch2a -> res4a_branch2a
I0702 23:02:43.459278 13779 net.cpp:148] Setting up res4a_branch2a
I0702 23:02:43.459286 13779 net.cpp:155] Top shape: 8 256 40 40 (3276800)
I0702 23:02:43.459288 13779 net.cpp:163] Memory required for data: 1304166400
I0702 23:02:43.459292 13779 layer_factory.hpp:77] Creating layer res4a_branch2a/bn
I0702 23:02:43.459296 13779 net.cpp:98] Creating Layer res4a_branch2a/bn
I0702 23:02:43.459298 13779 net.cpp:439] res4a_branch2a/bn <- res4a_branch2a
I0702 23:02:43.459302 13779 net.cpp:413] res4a_branch2a/bn -> res4a_branch2a/bn
I0702 23:02:43.459734 13779 net.cpp:148] Setting up res4a_branch2a/bn
I0702 23:02:43.459739 13779 net.cpp:155] Top shape: 8 256 40 40 (3276800)
I0702 23:02:43.459741 13779 net.cpp:163] Memory required for data: 1317273600
I0702 23:02:43.459746 13779 layer_factory.hpp:77] Creating layer res4a_branch2a/relu
I0702 23:02:43.459749 13779 net.cpp:98] Creating Layer res4a_branch2a/relu
I0702 23:02:43.459751 13779 net.cpp:439] res4a_branch2a/relu <- res4a_branch2a/bn
I0702 23:02:43.459753 13779 net.cpp:400] res4a_branch2a/relu -> res4a_branch2a/bn (in-place)
I0702 23:02:43.459758 13779 net.cpp:148] Setting up res4a_branch2a/relu
I0702 23:02:43.459759 13779 net.cpp:155] Top shape: 8 256 40 40 (3276800)
I0702 23:02:43.459761 13779 net.cpp:163] Memory required for data: 1330380800
I0702 23:02:43.459763 13779 layer_factory.hpp:77] Creating layer res4a_branch2b
I0702 23:02:43.459766 13779 net.cpp:98] Creating Layer res4a_branch2b
I0702 23:02:43.459769 13779 net.cpp:439] res4a_branch2b <- res4a_branch2a/bn
I0702 23:02:43.459771 13779 net.cpp:413] res4a_branch2b -> res4a_branch2b
I0702 23:02:43.462853 13779 net.cpp:148] Setting up res4a_branch2b
I0702 23:02:43.462859 13779 net.cpp:155] Top shape: 8 256 40 40 (3276800)
I0702 23:02:43.462862 13779 net.cpp:163] Memory required for data: 1343488000
I0702 23:02:43.462864 13779 layer_factory.hpp:77] Creating layer res4a_branch2b/bn
I0702 23:02:43.462868 13779 net.cpp:98] Creating Layer res4a_branch2b/bn
I0702 23:02:43.462877 13779 net.cpp:439] res4a_branch2b/bn <- res4a_branch2b
I0702 23:02:43.462879 13779 net.cpp:413] res4a_branch2b/bn -> res4a_branch2b/bn
I0702 23:02:43.463330 13779 net.cpp:148] Setting up res4a_branch2b/bn
I0702 23:02:43.463336 13779 net.cpp:155] Top shape: 8 256 40 40 (3276800)
I0702 23:02:43.463338 13779 net.cpp:163] Memory required for data: 1356595200
I0702 23:02:43.463343 13779 layer_factory.hpp:77] Creating layer res4a_branch2b/relu
I0702 23:02:43.463346 13779 net.cpp:98] Creating Layer res4a_branch2b/relu
I0702 23:02:43.463348 13779 net.cpp:439] res4a_branch2b/relu <- res4a_branch2b/bn
I0702 23:02:43.463351 13779 net.cpp:400] res4a_branch2b/relu -> res4a_branch2b/bn (in-place)
I0702 23:02:43.463354 13779 net.cpp:148] Setting up res4a_branch2b/relu
I0702 23:02:43.463356 13779 net.cpp:155] Top shape: 8 256 40 40 (3276800)
I0702 23:02:43.463358 13779 net.cpp:163] Memory required for data: 1369702400
I0702 23:02:43.463361 13779 layer_factory.hpp:77] Creating layer pool4
I0702 23:02:43.463363 13779 net.cpp:98] Creating Layer pool4
I0702 23:02:43.463366 13779 net.cpp:439] pool4 <- res4a_branch2b/bn
I0702 23:02:43.463367 13779 net.cpp:413] pool4 -> pool4
I0702 23:02:43.463392 13779 net.cpp:148] Setting up pool4
I0702 23:02:43.463397 13779 net.cpp:155] Top shape: 8 256 40 40 (3276800)
I0702 23:02:43.463398 13779 net.cpp:163] Memory required for data: 1382809600
I0702 23:02:43.463400 13779 layer_factory.hpp:77] Creating layer res5a_branch2a
I0702 23:02:43.463404 13779 net.cpp:98] Creating Layer res5a_branch2a
I0702 23:02:43.463407 13779 net.cpp:439] res5a_branch2a <- pool4
I0702 23:02:43.463408 13779 net.cpp:413] res5a_branch2a -> res5a_branch2a
I0702 23:02:43.488729 13779 net.cpp:148] Setting up res5a_branch2a
I0702 23:02:43.488747 13779 net.cpp:155] Top shape: 8 512 40 40 (6553600)
I0702 23:02:43.488749 13779 net.cpp:163] Memory required for data: 1409024000
I0702 23:02:43.488755 13779 layer_factory.hpp:77] Creating layer res5a_branch2a/bn
I0702 23:02:43.488764 13779 net.cpp:98] Creating Layer res5a_branch2a/bn
I0702 23:02:43.488766 13779 net.cpp:439] res5a_branch2a/bn <- res5a_branch2a
I0702 23:02:43.488770 13779 net.cpp:413] res5a_branch2a/bn -> res5a_branch2a/bn
I0702 23:02:43.489228 13779 net.cpp:148] Setting up res5a_branch2a/bn
I0702 23:02:43.489234 13779 net.cpp:155] Top shape: 8 512 40 40 (6553600)
I0702 23:02:43.489236 13779 net.cpp:163] Memory required for data: 1435238400
I0702 23:02:43.489241 13779 layer_factory.hpp:77] Creating layer res5a_branch2a/relu
I0702 23:02:43.489244 13779 net.cpp:98] Creating Layer res5a_branch2a/relu
I0702 23:02:43.489248 13779 net.cpp:439] res5a_branch2a/relu <- res5a_branch2a/bn
I0702 23:02:43.489249 13779 net.cpp:400] res5a_branch2a/relu -> res5a_branch2a/bn (in-place)
I0702 23:02:43.489253 13779 net.cpp:148] Setting up res5a_branch2a/relu
I0702 23:02:43.489255 13779 net.cpp:155] Top shape: 8 512 40 40 (6553600)
I0702 23:02:43.489258 13779 net.cpp:163] Memory required for data: 1461452800
I0702 23:02:43.489259 13779 layer_factory.hpp:77] Creating layer res5a_branch2b
I0702 23:02:43.489264 13779 net.cpp:98] Creating Layer res5a_branch2b
I0702 23:02:43.489266 13779 net.cpp:439] res5a_branch2b <- res5a_branch2a/bn
I0702 23:02:43.489269 13779 net.cpp:413] res5a_branch2b -> res5a_branch2b
I0702 23:02:43.501873 13779 net.cpp:148] Setting up res5a_branch2b
I0702 23:02:43.501894 13779 net.cpp:155] Top shape: 8 512 40 40 (6553600)
I0702 23:02:43.501896 13779 net.cpp:163] Memory required for data: 1487667200
I0702 23:02:43.501906 13779 layer_factory.hpp:77] Creating layer res5a_branch2b/bn
I0702 23:02:43.501914 13779 net.cpp:98] Creating Layer res5a_branch2b/bn
I0702 23:02:43.501916 13779 net.cpp:439] res5a_branch2b/bn <- res5a_branch2b
I0702 23:02:43.501920 13779 net.cpp:413] res5a_branch2b/bn -> res5a_branch2b/bn
I0702 23:02:43.502379 13779 net.cpp:148] Setting up res5a_branch2b/bn
I0702 23:02:43.502390 13779 net.cpp:155] Top shape: 8 512 40 40 (6553600)
I0702 23:02:43.502394 13779 net.cpp:163] Memory required for data: 1513881600
I0702 23:02:43.502401 13779 layer_factory.hpp:77] Creating layer res5a_branch2b/relu
I0702 23:02:43.502413 13779 net.cpp:98] Creating Layer res5a_branch2b/relu
I0702 23:02:43.502416 13779 net.cpp:439] res5a_branch2b/relu <- res5a_branch2b/bn
I0702 23:02:43.502418 13779 net.cpp:400] res5a_branch2b/relu -> res5a_branch2b/bn (in-place)
I0702 23:02:43.502424 13779 net.cpp:148] Setting up res5a_branch2b/relu
I0702 23:02:43.502427 13779 net.cpp:155] Top shape: 8 512 40 40 (6553600)
I0702 23:02:43.502429 13779 net.cpp:163] Memory required for data: 1540096000
I0702 23:02:43.502431 13779 layer_factory.hpp:77] Creating layer out5a
I0702 23:02:43.502437 13779 net.cpp:98] Creating Layer out5a
I0702 23:02:43.502439 13779 net.cpp:439] out5a <- res5a_branch2b/bn
I0702 23:02:43.502442 13779 net.cpp:413] out5a -> out5a
I0702 23:02:43.506292 13779 net.cpp:148] Setting up out5a
I0702 23:02:43.506300 13779 net.cpp:155] Top shape: 8 64 40 40 (819200)
I0702 23:02:43.506302 13779 net.cpp:163] Memory required for data: 1543372800
I0702 23:02:43.506306 13779 layer_factory.hpp:77] Creating layer out5a/bn
I0702 23:02:43.506310 13779 net.cpp:98] Creating Layer out5a/bn
I0702 23:02:43.506312 13779 net.cpp:439] out5a/bn <- out5a
I0702 23:02:43.506315 13779 net.cpp:413] out5a/bn -> out5a/bn
I0702 23:02:43.506817 13779 net.cpp:148] Setting up out5a/bn
I0702 23:02:43.506824 13779 net.cpp:155] Top shape: 8 64 40 40 (819200)
I0702 23:02:43.506825 13779 net.cpp:163] Memory required for data: 1546649600
I0702 23:02:43.506830 13779 layer_factory.hpp:77] Creating layer out5a/relu
I0702 23:02:43.506834 13779 net.cpp:98] Creating Layer out5a/relu
I0702 23:02:43.506836 13779 net.cpp:439] out5a/relu <- out5a/bn
I0702 23:02:43.506839 13779 net.cpp:400] out5a/relu -> out5a/bn (in-place)
I0702 23:02:43.506841 13779 net.cpp:148] Setting up out5a/relu
I0702 23:02:43.506844 13779 net.cpp:155] Top shape: 8 64 40 40 (819200)
I0702 23:02:43.506845 13779 net.cpp:163] Memory required for data: 1549926400
I0702 23:02:43.506847 13779 layer_factory.hpp:77] Creating layer out5a_up2
I0702 23:02:43.506855 13779 net.cpp:98] Creating Layer out5a_up2
I0702 23:02:43.506858 13779 net.cpp:439] out5a_up2 <- out5a/bn
I0702 23:02:43.506861 13779 net.cpp:413] out5a_up2 -> out5a_up2
I0702 23:02:43.507040 13779 net.cpp:148] Setting up out5a_up2
I0702 23:02:43.507045 13779 net.cpp:155] Top shape: 8 64 80 80 (3276800)
I0702 23:02:43.507046 13779 net.cpp:163] Memory required for data: 1563033600
I0702 23:02:43.507050 13779 layer_factory.hpp:77] Creating layer out3a
I0702 23:02:43.507055 13779 net.cpp:98] Creating Layer out3a
I0702 23:02:43.507058 13779 net.cpp:439] out3a <- res3a_branch2b/bn_res3a_branch2b/relu_0_split_1
I0702 23:02:43.507062 13779 net.cpp:413] out3a -> out3a
I0702 23:02:43.508002 13779 net.cpp:148] Setting up out3a
I0702 23:02:43.508008 13779 net.cpp:155] Top shape: 8 64 80 80 (3276800)
I0702 23:02:43.508009 13779 net.cpp:163] Memory required for data: 1576140800
I0702 23:02:43.508013 13779 layer_factory.hpp:77] Creating layer out3a/bn
I0702 23:02:43.508015 13779 net.cpp:98] Creating Layer out3a/bn
I0702 23:02:43.508018 13779 net.cpp:439] out3a/bn <- out3a
I0702 23:02:43.508020 13779 net.cpp:413] out3a/bn -> out3a/bn
I0702 23:02:43.508508 13779 net.cpp:148] Setting up out3a/bn
I0702 23:02:43.508513 13779 net.cpp:155] Top shape: 8 64 80 80 (3276800)
I0702 23:02:43.508515 13779 net.cpp:163] Memory required for data: 1589248000
I0702 23:02:43.508520 13779 layer_factory.hpp:77] Creating layer out3a/relu
I0702 23:02:43.508522 13779 net.cpp:98] Creating Layer out3a/relu
I0702 23:02:43.508525 13779 net.cpp:439] out3a/relu <- out3a/bn
I0702 23:02:43.508527 13779 net.cpp:400] out3a/relu -> out3a/bn (in-place)
I0702 23:02:43.508530 13779 net.cpp:148] Setting up out3a/relu
I0702 23:02:43.508533 13779 net.cpp:155] Top shape: 8 64 80 80 (3276800)
I0702 23:02:43.508534 13779 net.cpp:163] Memory required for data: 1602355200
I0702 23:02:43.508536 13779 layer_factory.hpp:77] Creating layer out3_out5_combined
I0702 23:02:43.508541 13779 net.cpp:98] Creating Layer out3_out5_combined
I0702 23:02:43.508543 13779 net.cpp:439] out3_out5_combined <- out5a_up2
I0702 23:02:43.508553 13779 net.cpp:439] out3_out5_combined <- out3a/bn
I0702 23:02:43.508556 13779 net.cpp:413] out3_out5_combined -> out3_out5_combined
I0702 23:02:43.508574 13779 net.cpp:148] Setting up out3_out5_combined
I0702 23:02:43.508579 13779 net.cpp:155] Top shape: 8 64 80 80 (3276800)
I0702 23:02:43.508580 13779 net.cpp:163] Memory required for data: 1615462400
I0702 23:02:43.508582 13779 layer_factory.hpp:77] Creating layer ctx_conv1
I0702 23:02:43.508586 13779 net.cpp:98] Creating Layer ctx_conv1
I0702 23:02:43.508589 13779 net.cpp:439] ctx_conv1 <- out3_out5_combined
I0702 23:02:43.508590 13779 net.cpp:413] ctx_conv1 -> ctx_conv1
I0702 23:02:43.509518 13779 net.cpp:148] Setting up ctx_conv1
I0702 23:02:43.509523 13779 net.cpp:155] Top shape: 8 64 80 80 (3276800)
I0702 23:02:43.509526 13779 net.cpp:163] Memory required for data: 1628569600
I0702 23:02:43.509528 13779 layer_factory.hpp:77] Creating layer ctx_conv1/bn
I0702 23:02:43.509531 13779 net.cpp:98] Creating Layer ctx_conv1/bn
I0702 23:02:43.509533 13779 net.cpp:439] ctx_conv1/bn <- ctx_conv1
I0702 23:02:43.509536 13779 net.cpp:413] ctx_conv1/bn -> ctx_conv1/bn
I0702 23:02:43.510020 13779 net.cpp:148] Setting up ctx_conv1/bn
I0702 23:02:43.510025 13779 net.cpp:155] Top shape: 8 64 80 80 (3276800)
I0702 23:02:43.510026 13779 net.cpp:163] Memory required for data: 1641676800
I0702 23:02:43.510031 13779 layer_factory.hpp:77] Creating layer ctx_conv1/relu
I0702 23:02:43.510035 13779 net.cpp:98] Creating Layer ctx_conv1/relu
I0702 23:02:43.510036 13779 net.cpp:439] ctx_conv1/relu <- ctx_conv1/bn
I0702 23:02:43.510040 13779 net.cpp:400] ctx_conv1/relu -> ctx_conv1/bn (in-place)
I0702 23:02:43.510042 13779 net.cpp:148] Setting up ctx_conv1/relu
I0702 23:02:43.510044 13779 net.cpp:155] Top shape: 8 64 80 80 (3276800)
I0702 23:02:43.510046 13779 net.cpp:163] Memory required for data: 1654784000
I0702 23:02:43.510048 13779 layer_factory.hpp:77] Creating layer ctx_conv2
I0702 23:02:43.510051 13779 net.cpp:98] Creating Layer ctx_conv2
I0702 23:02:43.510054 13779 net.cpp:439] ctx_conv2 <- ctx_conv1/bn
I0702 23:02:43.510056 13779 net.cpp:413] ctx_conv2 -> ctx_conv2
I0702 23:02:43.510993 13779 net.cpp:148] Setting up ctx_conv2
I0702 23:02:43.510998 13779 net.cpp:155] Top shape: 8 64 80 80 (3276800)
I0702 23:02:43.511000 13779 net.cpp:163] Memory required for data: 1667891200
I0702 23:02:43.511003 13779 layer_factory.hpp:77] Creating layer ctx_conv2/bn
I0702 23:02:43.511006 13779 net.cpp:98] Creating Layer ctx_conv2/bn
I0702 23:02:43.511008 13779 net.cpp:439] ctx_conv2/bn <- ctx_conv2
I0702 23:02:43.511011 13779 net.cpp:413] ctx_conv2/bn -> ctx_conv2/bn
I0702 23:02:43.511502 13779 net.cpp:148] Setting up ctx_conv2/bn
I0702 23:02:43.511507 13779 net.cpp:155] Top shape: 8 64 80 80 (3276800)
I0702 23:02:43.511509 13779 net.cpp:163] Memory required for data: 1680998400
I0702 23:02:43.511514 13779 layer_factory.hpp:77] Creating layer ctx_conv2/relu
I0702 23:02:43.511518 13779 net.cpp:98] Creating Layer ctx_conv2/relu
I0702 23:02:43.511519 13779 net.cpp:439] ctx_conv2/relu <- ctx_conv2/bn
I0702 23:02:43.511523 13779 net.cpp:400] ctx_conv2/relu -> ctx_conv2/bn (in-place)
I0702 23:02:43.511526 13779 net.cpp:148] Setting up ctx_conv2/relu
I0702 23:02:43.511528 13779 net.cpp:155] Top shape: 8 64 80 80 (3276800)
I0702 23:02:43.511530 13779 net.cpp:163] Memory required for data: 1694105600
I0702 23:02:43.511533 13779 layer_factory.hpp:77] Creating layer ctx_conv3
I0702 23:02:43.511535 13779 net.cpp:98] Creating Layer ctx_conv3
I0702 23:02:43.511538 13779 net.cpp:439] ctx_conv3 <- ctx_conv2/bn
I0702 23:02:43.511540 13779 net.cpp:413] ctx_conv3 -> ctx_conv3
I0702 23:02:43.512468 13779 net.cpp:148] Setting up ctx_conv3
I0702 23:02:43.512472 13779 net.cpp:155] Top shape: 8 64 80 80 (3276800)
I0702 23:02:43.512475 13779 net.cpp:163] Memory required for data: 1707212800
I0702 23:02:43.512478 13779 layer_factory.hpp:77] Creating layer ctx_conv3/bn
I0702 23:02:43.512481 13779 net.cpp:98] Creating Layer ctx_conv3/bn
I0702 23:02:43.512483 13779 net.cpp:439] ctx_conv3/bn <- ctx_conv3
I0702 23:02:43.512491 13779 net.cpp:413] ctx_conv3/bn -> ctx_conv3/bn
I0702 23:02:43.512979 13779 net.cpp:148] Setting up ctx_conv3/bn
I0702 23:02:43.512984 13779 net.cpp:155] Top shape: 8 64 80 80 (3276800)
I0702 23:02:43.512985 13779 net.cpp:163] Memory required for data: 1720320000
I0702 23:02:43.512990 13779 layer_factory.hpp:77] Creating layer ctx_conv3/relu
I0702 23:02:43.512992 13779 net.cpp:98] Creating Layer ctx_conv3/relu
I0702 23:02:43.512995 13779 net.cpp:439] ctx_conv3/relu <- ctx_conv3/bn
I0702 23:02:43.512997 13779 net.cpp:400] ctx_conv3/relu -> ctx_conv3/bn (in-place)
I0702 23:02:43.513000 13779 net.cpp:148] Setting up ctx_conv3/relu
I0702 23:02:43.513002 13779 net.cpp:155] Top shape: 8 64 80 80 (3276800)
I0702 23:02:43.513005 13779 net.cpp:163] Memory required for data: 1733427200
I0702 23:02:43.513005 13779 layer_factory.hpp:77] Creating layer ctx_conv4
I0702 23:02:43.513010 13779 net.cpp:98] Creating Layer ctx_conv4
I0702 23:02:43.513011 13779 net.cpp:439] ctx_conv4 <- ctx_conv3/bn
I0702 23:02:43.513013 13779 net.cpp:413] ctx_conv4 -> ctx_conv4
I0702 23:02:43.513944 13779 net.cpp:148] Setting up ctx_conv4
I0702 23:02:43.513948 13779 net.cpp:155] Top shape: 8 64 80 80 (3276800)
I0702 23:02:43.513950 13779 net.cpp:163] Memory required for data: 1746534400
I0702 23:02:43.513953 13779 layer_factory.hpp:77] Creating layer ctx_conv4/bn
I0702 23:02:43.513957 13779 net.cpp:98] Creating Layer ctx_conv4/bn
I0702 23:02:43.513959 13779 net.cpp:439] ctx_conv4/bn <- ctx_conv4
I0702 23:02:43.513962 13779 net.cpp:413] ctx_conv4/bn -> ctx_conv4/bn
I0702 23:02:43.514461 13779 net.cpp:148] Setting up ctx_conv4/bn
I0702 23:02:43.514467 13779 net.cpp:155] Top shape: 8 64 80 80 (3276800)
I0702 23:02:43.514468 13779 net.cpp:163] Memory required for data: 1759641600
I0702 23:02:43.514473 13779 layer_factory.hpp:77] Creating layer ctx_conv4/relu
I0702 23:02:43.514475 13779 net.cpp:98] Creating Layer ctx_conv4/relu
I0702 23:02:43.514477 13779 net.cpp:439] ctx_conv4/relu <- ctx_conv4/bn
I0702 23:02:43.514480 13779 net.cpp:400] ctx_conv4/relu -> ctx_conv4/bn (in-place)
I0702 23:02:43.514483 13779 net.cpp:148] Setting up ctx_conv4/relu
I0702 23:02:43.514485 13779 net.cpp:155] Top shape: 8 64 80 80 (3276800)
I0702 23:02:43.514487 13779 net.cpp:163] Memory required for data: 1772748800
I0702 23:02:43.514489 13779 layer_factory.hpp:77] Creating layer ctx_final
I0702 23:02:43.514492 13779 net.cpp:98] Creating Layer ctx_final
I0702 23:02:43.514494 13779 net.cpp:439] ctx_final <- ctx_conv4/bn
I0702 23:02:43.514497 13779 net.cpp:413] ctx_final -> ctx_final
I0702 23:02:43.514791 13779 net.cpp:148] Setting up ctx_final
I0702 23:02:43.514796 13779 net.cpp:155] Top shape: 8 8 80 80 (409600)
I0702 23:02:43.514797 13779 net.cpp:163] Memory required for data: 1774387200
I0702 23:02:43.514801 13779 layer_factory.hpp:77] Creating layer ctx_final/relu
I0702 23:02:43.514802 13779 net.cpp:98] Creating Layer ctx_final/relu
I0702 23:02:43.514804 13779 net.cpp:439] ctx_final/relu <- ctx_final
I0702 23:02:43.514806 13779 net.cpp:400] ctx_final/relu -> ctx_final (in-place)
I0702 23:02:43.514809 13779 net.cpp:148] Setting up ctx_final/relu
I0702 23:02:43.514812 13779 net.cpp:155] Top shape: 8 8 80 80 (409600)
I0702 23:02:43.514813 13779 net.cpp:163] Memory required for data: 1776025600
I0702 23:02:43.514816 13779 layer_factory.hpp:77] Creating layer out_deconv_final_up2
I0702 23:02:43.514818 13779 net.cpp:98] Creating Layer out_deconv_final_up2
I0702 23:02:43.514820 13779 net.cpp:439] out_deconv_final_up2 <- ctx_final
I0702 23:02:43.514822 13779 net.cpp:413] out_deconv_final_up2 -> out_deconv_final_up2
I0702 23:02:43.514978 13779 net.cpp:148] Setting up out_deconv_final_up2
I0702 23:02:43.514982 13779 net.cpp:155] Top shape: 8 8 160 160 (1638400)
I0702 23:02:43.514984 13779 net.cpp:163] Memory required for data: 1782579200
I0702 23:02:43.514987 13779 layer_factory.hpp:77] Creating layer out_deconv_final_up4
I0702 23:02:43.514991 13779 net.cpp:98] Creating Layer out_deconv_final_up4
I0702 23:02:43.514992 13779 net.cpp:439] out_deconv_final_up4 <- out_deconv_final_up2
I0702 23:02:43.515000 13779 net.cpp:413] out_deconv_final_up4 -> out_deconv_final_up4
I0702 23:02:43.515154 13779 net.cpp:148] Setting up out_deconv_final_up4
I0702 23:02:43.515159 13779 net.cpp:155] Top shape: 8 8 320 320 (6553600)
I0702 23:02:43.515161 13779 net.cpp:163] Memory required for data: 1808793600
I0702 23:02:43.515163 13779 layer_factory.hpp:77] Creating layer out_deconv_final_up8
I0702 23:02:43.515166 13779 net.cpp:98] Creating Layer out_deconv_final_up8
I0702 23:02:43.515168 13779 net.cpp:439] out_deconv_final_up8 <- out_deconv_final_up4
I0702 23:02:43.515171 13779 net.cpp:413] out_deconv_final_up8 -> out_deconv_final_up8
I0702 23:02:43.515324 13779 net.cpp:148] Setting up out_deconv_final_up8
I0702 23:02:43.515328 13779 net.cpp:155] Top shape: 8 8 640 640 (26214400)
I0702 23:02:43.515331 13779 net.cpp:163] Memory required for data: 1913651200
I0702 23:02:43.515332 13779 layer_factory.hpp:77] Creating layer loss
I0702 23:02:43.515338 13779 net.cpp:98] Creating Layer loss
I0702 23:02:43.515341 13779 net.cpp:439] loss <- out_deconv_final_up8
I0702 23:02:43.515342 13779 net.cpp:439] loss <- label
I0702 23:02:43.515347 13779 net.cpp:413] loss -> loss
I0702 23:02:43.515352 13779 layer_factory.hpp:77] Creating layer loss
I0702 23:02:43.546562 13779 net.cpp:148] Setting up loss
I0702 23:02:43.546586 13779 net.cpp:155] Top shape: (1)
I0702 23:02:43.546587 13779 net.cpp:158]     with loss weight 1
I0702 23:02:43.546602 13779 net.cpp:163] Memory required for data: 1913651204
I0702 23:02:43.546604 13779 net.cpp:224] loss needs backward computation.
I0702 23:02:43.546608 13779 net.cpp:224] out_deconv_final_up8 needs backward computation.
I0702 23:02:43.546612 13779 net.cpp:224] out_deconv_final_up4 needs backward computation.
I0702 23:02:43.546613 13779 net.cpp:224] out_deconv_final_up2 needs backward computation.
I0702 23:02:43.546614 13779 net.cpp:224] ctx_final/relu needs backward computation.
I0702 23:02:43.546617 13779 net.cpp:224] ctx_final needs backward computation.
I0702 23:02:43.546618 13779 net.cpp:224] ctx_conv4/relu needs backward computation.
I0702 23:02:43.546620 13779 net.cpp:224] ctx_conv4/bn needs backward computation.
I0702 23:02:43.546623 13779 net.cpp:224] ctx_conv4 needs backward computation.
I0702 23:02:43.546625 13779 net.cpp:224] ctx_conv3/relu needs backward computation.
I0702 23:02:43.546628 13779 net.cpp:224] ctx_conv3/bn needs backward computation.
I0702 23:02:43.546630 13779 net.cpp:224] ctx_conv3 needs backward computation.
I0702 23:02:43.546633 13779 net.cpp:224] ctx_conv2/relu needs backward computation.
I0702 23:02:43.546634 13779 net.cpp:224] ctx_conv2/bn needs backward computation.
I0702 23:02:43.546636 13779 net.cpp:224] ctx_conv2 needs backward computation.
I0702 23:02:43.546638 13779 net.cpp:224] ctx_conv1/relu needs backward computation.
I0702 23:02:43.546641 13779 net.cpp:224] ctx_conv1/bn needs backward computation.
I0702 23:02:43.546643 13779 net.cpp:224] ctx_conv1 needs backward computation.
I0702 23:02:43.546645 13779 net.cpp:224] out3_out5_combined needs backward computation.
I0702 23:02:43.546648 13779 net.cpp:224] out3a/relu needs backward computation.
I0702 23:02:43.546650 13779 net.cpp:224] out3a/bn needs backward computation.
I0702 23:02:43.546653 13779 net.cpp:224] out3a needs backward computation.
I0702 23:02:43.546656 13779 net.cpp:224] out5a_up2 needs backward computation.
I0702 23:02:43.546659 13779 net.cpp:224] out5a/relu needs backward computation.
I0702 23:02:43.546661 13779 net.cpp:224] out5a/bn needs backward computation.
I0702 23:02:43.546664 13779 net.cpp:224] out5a needs backward computation.
I0702 23:02:43.546667 13779 net.cpp:224] res5a_branch2b/relu needs backward computation.
I0702 23:02:43.546669 13779 net.cpp:224] res5a_branch2b/bn needs backward computation.
I0702 23:02:43.546671 13779 net.cpp:224] res5a_branch2b needs backward computation.
I0702 23:02:43.546674 13779 net.cpp:224] res5a_branch2a/relu needs backward computation.
I0702 23:02:43.546676 13779 net.cpp:224] res5a_branch2a/bn needs backward computation.
I0702 23:02:43.546689 13779 net.cpp:224] res5a_branch2a needs backward computation.
I0702 23:02:43.546692 13779 net.cpp:224] pool4 needs backward computation.
I0702 23:02:43.546694 13779 net.cpp:224] res4a_branch2b/relu needs backward computation.
I0702 23:02:43.546697 13779 net.cpp:224] res4a_branch2b/bn needs backward computation.
I0702 23:02:43.546700 13779 net.cpp:224] res4a_branch2b needs backward computation.
I0702 23:02:43.546702 13779 net.cpp:224] res4a_branch2a/relu needs backward computation.
I0702 23:02:43.546705 13779 net.cpp:224] res4a_branch2a/bn needs backward computation.
I0702 23:02:43.546707 13779 net.cpp:224] res4a_branch2a needs backward computation.
I0702 23:02:43.546710 13779 net.cpp:224] pool3 needs backward computation.
I0702 23:02:43.546712 13779 net.cpp:224] res3a_branch2b/bn_res3a_branch2b/relu_0_split needs backward computation.
I0702 23:02:43.546715 13779 net.cpp:224] res3a_branch2b/relu needs backward computation.
I0702 23:02:43.546718 13779 net.cpp:224] res3a_branch2b/bn needs backward computation.
I0702 23:02:43.546720 13779 net.cpp:224] res3a_branch2b needs backward computation.
I0702 23:02:43.546723 13779 net.cpp:224] res3a_branch2a/relu needs backward computation.
I0702 23:02:43.546725 13779 net.cpp:224] res3a_branch2a/bn needs backward computation.
I0702 23:02:43.546727 13779 net.cpp:224] res3a_branch2a needs backward computation.
I0702 23:02:43.546730 13779 net.cpp:224] pool2 needs backward computation.
I0702 23:02:43.546732 13779 net.cpp:224] res2a_branch2b/relu needs backward computation.
I0702 23:02:43.546736 13779 net.cpp:224] res2a_branch2b/bn needs backward computation.
I0702 23:02:43.546737 13779 net.cpp:224] res2a_branch2b needs backward computation.
I0702 23:02:43.546739 13779 net.cpp:224] res2a_branch2a/relu needs backward computation.
I0702 23:02:43.546741 13779 net.cpp:224] res2a_branch2a/bn needs backward computation.
I0702 23:02:43.546744 13779 net.cpp:224] res2a_branch2a needs backward computation.
I0702 23:02:43.546747 13779 net.cpp:224] pool1 needs backward computation.
I0702 23:02:43.546749 13779 net.cpp:224] conv1b/relu needs backward computation.
I0702 23:02:43.546751 13779 net.cpp:224] conv1b/bn needs backward computation.
I0702 23:02:43.546754 13779 net.cpp:224] conv1b needs backward computation.
I0702 23:02:43.546756 13779 net.cpp:224] conv1a/relu needs backward computation.
I0702 23:02:43.546758 13779 net.cpp:224] conv1a/bn needs backward computation.
I0702 23:02:43.546761 13779 net.cpp:224] conv1a needs backward computation.
I0702 23:02:43.546763 13779 net.cpp:226] data/bias does not need backward computation.
I0702 23:02:43.546766 13779 net.cpp:226] data does not need backward computation.
I0702 23:02:43.546768 13779 net.cpp:268] This network produces output loss
I0702 23:02:43.546797 13779 net.cpp:288] Network initialization done.
I0702 23:02:43.547479 13779 solver.cpp:182] Creating test net (#0) specified by test_net file: training/cityscapes5_jsegnet21v2_2017-07-02_23-02-42/initial/test.prototxt
I0702 23:02:43.547762 13779 net.cpp:56] Initializing net from parameters: 
name: "jsegnet21v2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageLabelData"
  top: "data"
  top: "label"
  transform_param {
    mirror: false
    crop_size: 640
    mean_value: 0
  }
  image_label_data_param {
    image_list_path: "data/val-image-lmdb"
    label_list_path: "data/val-label-lmdb"
    batch_size: 4
    threads: 4
    backend: LMDB
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a/bn"
  top: "conv1a/bn"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a/bn"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b/bn"
  top: "conv1b/bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b/bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2a/bn"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b/bn"
  top: "res2a_branch2b/bn"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b/bn"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2a/bn"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b/bn"
  top: "res3a_branch2b/bn"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b/bn"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2a/bn"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b/bn"
  top: "res4a_branch2b/bn"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b/bn"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2a/bn"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b/bn"
  top: "res5a_branch2b/bn"
}
layer {
  name: "out5a"
  type: "Convolution"
  bottom: "res5a_branch2b/bn"
  top: "out5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "out5a/bn"
  type: "BatchNorm"
  bottom: "out5a"
  top: "out5a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "out5a/relu"
  type: "ReLU"
  bottom: "out5a/bn"
  top: "out5a/bn"
}
layer {
  name: "out5a_up2"
  type: "Deconvolution"
  bottom: "out5a/bn"
  top: "out5a_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 64
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out3a"
  type: "Convolution"
  bottom: "res3a_branch2b/bn"
  top: "out3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "out3a/bn"
  type: "BatchNorm"
  bottom: "out3a"
  top: "out3a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "out3a/relu"
  type: "ReLU"
  bottom: "out3a/bn"
  top: "out3a/bn"
}
layer {
  name: "out3_out5_combined"
  type: "Eltwise"
  bottom: "out5a_up2"
  bottom: "out3a/bn"
  top: "out3_out5_combined"
}
layer {
  name: "ctx_conv1"
  type: "Convolution"
  bottom: "out3_out5_combined"
  top: "ctx_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_conv1/bn"
  type: "BatchNorm"
  bottom: "ctx_conv1"
  top: "ctx_conv1/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ctx_conv1/relu"
  type: "ReLU"
  bottom: "ctx_conv1/bn"
  top: "ctx_conv1/bn"
}
layer {
  name: "ctx_conv2"
  type: "Convolution"
  bottom: "ctx_conv1/bn"
  top: "ctx_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv2/bn"
  type: "BatchNorm"
  bottom: "ctx_conv2"
  top: "ctx_conv2/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ctx_conv2/relu"
  type: "ReLU"
  bottom: "ctx_conv2/bn"
  top: "ctx_conv2/bn"
}
layer {
  name: "ctx_conv3"
  type: "Convolution"
  bottom: "ctx_conv2/bn"
  top: "ctx_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv3/bn"
  type: "BatchNorm"
  bottom: "ctx_conv3"
  top: "ctx_conv3/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ctx_conv3/relu"
  type: "ReLU"
  bottom: "ctx_conv3/bn"
  top: "ctx_conv3/bn"
}
layer {
  name: "ctx_conv4"
  type: "Convolution"
  bottom: "ctx_conv3/bn"
  top: "ctx_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv4/bn"
  type: "BatchNorm"
  bottom: "ctx_conv4"
  top: "ctx_conv4/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ctx_conv4/relu"
  type: "ReLU"
  bottom: "ctx_conv4/bn"
  top: "ctx_conv4/bn"
}
layer {
  name: "ctx_final"
  type: "Convolution"
  bottom: "ctx_conv4/bn"
  top: "ctx_final"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_final/relu"
  type: "ReLU"
  bottom: "ctx_final"
  top: "ctx_final"
}
layer {
  name: "out_deconv_final_up2"
  type: "Deconvolution"
  bottom: "ctx_final"
  top: "out_deconv_final_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up4"
  type: "Deconvolution"
  bottom: "out_deconv_final_up2"
  top: "out_deconv_final_up4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up8"
  type: "Deconvolution"
  bottom: "out_deconv_final_up4"
  top: "out_deconv_final_up8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: 255
    normalization: VALID
  }
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "accuracy/top1"
  include {
    phase: TEST
  }
  accuracy_param {
    ignore_label: 255
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "accuracy/top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
    ignore_label: 255
  }
}
I0702 23:02:43.547879 13779 layer_factory.hpp:77] Creating layer data
I0702 23:02:43.547886 13779 net.cpp:98] Creating Layer data
I0702 23:02:43.547890 13779 net.cpp:413] data -> data
I0702 23:02:43.547894 13779 net.cpp:413] data -> label
I0702 23:02:43.549422 13817 db_lmdb.cpp:35] Opened lmdb data/val-image-lmdb
I0702 23:02:43.549422 13822 db_lmdb.cpp:35] Opened lmdb data/val-label-lmdb
I0702 23:02:43.553217 13779 data_layer.cpp:78] ReshapePrefetch 4, 3, 640, 640
I0702 23:02:43.553303 13779 data_layer.cpp:83] output data size: 4,3,640,640
I0702 23:02:43.578783 13779 data_layer.cpp:78] ReshapePrefetch 4, 1, 640, 640
I0702 23:02:43.578850 13779 data_layer.cpp:83] output data size: 4,1,640,640
I0702 23:02:43.591603 13779 net.cpp:148] Setting up data
I0702 23:02:43.591652 13779 net.cpp:155] Top shape: 4 3 640 640 (4915200)
I0702 23:02:43.591658 13779 net.cpp:155] Top shape: 4 1 640 640 (1638400)
I0702 23:02:43.591661 13779 net.cpp:163] Memory required for data: 26214400
I0702 23:02:43.591670 13779 layer_factory.hpp:77] Creating layer label_data_1_split
I0702 23:02:43.591691 13779 net.cpp:98] Creating Layer label_data_1_split
I0702 23:02:43.591723 13779 net.cpp:439] label_data_1_split <- label
I0702 23:02:43.591733 13779 net.cpp:413] label_data_1_split -> label_data_1_split_0
I0702 23:02:43.591744 13779 net.cpp:413] label_data_1_split -> label_data_1_split_1
I0702 23:02:43.591750 13779 net.cpp:413] label_data_1_split -> label_data_1_split_2
I0702 23:02:43.591907 13779 net.cpp:148] Setting up label_data_1_split
I0702 23:02:43.591912 13779 net.cpp:155] Top shape: 4 1 640 640 (1638400)
I0702 23:02:43.591917 13779 net.cpp:155] Top shape: 4 1 640 640 (1638400)
I0702 23:02:43.591919 13779 net.cpp:155] Top shape: 4 1 640 640 (1638400)
I0702 23:02:43.591928 13779 net.cpp:163] Memory required for data: 45875200
I0702 23:02:43.591931 13779 layer_factory.hpp:77] Creating layer data/bias
I0702 23:02:43.591944 13779 net.cpp:98] Creating Layer data/bias
I0702 23:02:43.591948 13779 net.cpp:439] data/bias <- data
I0702 23:02:43.591953 13779 net.cpp:413] data/bias -> data/bias
I0702 23:02:43.593540 13779 net.cpp:148] Setting up data/bias
I0702 23:02:43.593571 13779 net.cpp:155] Top shape: 4 3 640 640 (4915200)
I0702 23:02:43.593575 13779 net.cpp:163] Memory required for data: 65536000
I0702 23:02:43.593590 13779 layer_factory.hpp:77] Creating layer conv1a
I0702 23:02:43.593607 13779 net.cpp:98] Creating Layer conv1a
I0702 23:02:43.593611 13779 net.cpp:439] conv1a <- data/bias
I0702 23:02:43.593617 13779 net.cpp:413] conv1a -> conv1a
I0702 23:02:43.594122 13779 net.cpp:148] Setting up conv1a
I0702 23:02:43.594131 13779 net.cpp:155] Top shape: 4 32 320 320 (13107200)
I0702 23:02:43.594135 13779 net.cpp:163] Memory required for data: 117964800
I0702 23:02:43.594142 13779 layer_factory.hpp:77] Creating layer conv1a/bn
I0702 23:02:43.594151 13779 net.cpp:98] Creating Layer conv1a/bn
I0702 23:02:43.594154 13779 net.cpp:439] conv1a/bn <- conv1a
I0702 23:02:43.594161 13779 net.cpp:413] conv1a/bn -> conv1a/bn
I0702 23:02:43.594952 13779 net.cpp:148] Setting up conv1a/bn
I0702 23:02:43.594961 13779 net.cpp:155] Top shape: 4 32 320 320 (13107200)
I0702 23:02:43.594964 13779 net.cpp:163] Memory required for data: 170393600
I0702 23:02:43.594974 13779 layer_factory.hpp:77] Creating layer conv1a/relu
I0702 23:02:43.594979 13779 net.cpp:98] Creating Layer conv1a/relu
I0702 23:02:43.594983 13779 net.cpp:439] conv1a/relu <- conv1a/bn
I0702 23:02:43.594987 13779 net.cpp:400] conv1a/relu -> conv1a/bn (in-place)
I0702 23:02:43.594995 13779 net.cpp:148] Setting up conv1a/relu
I0702 23:02:43.595000 13779 net.cpp:155] Top shape: 4 32 320 320 (13107200)
I0702 23:02:43.595002 13779 net.cpp:163] Memory required for data: 222822400
I0702 23:02:43.595006 13779 layer_factory.hpp:77] Creating layer conv1b
I0702 23:02:43.595015 13779 net.cpp:98] Creating Layer conv1b
I0702 23:02:43.595017 13779 net.cpp:439] conv1b <- conv1a/bn
I0702 23:02:43.595021 13779 net.cpp:413] conv1b -> conv1b
I0702 23:02:43.595425 13779 net.cpp:148] Setting up conv1b
I0702 23:02:43.595432 13779 net.cpp:155] Top shape: 4 32 320 320 (13107200)
I0702 23:02:43.595437 13779 net.cpp:163] Memory required for data: 275251200
I0702 23:02:43.595444 13779 layer_factory.hpp:77] Creating layer conv1b/bn
I0702 23:02:43.595449 13779 net.cpp:98] Creating Layer conv1b/bn
I0702 23:02:43.595453 13779 net.cpp:439] conv1b/bn <- conv1b
I0702 23:02:43.595458 13779 net.cpp:413] conv1b/bn -> conv1b/bn
I0702 23:02:43.596349 13779 net.cpp:148] Setting up conv1b/bn
I0702 23:02:43.596357 13779 net.cpp:155] Top shape: 4 32 320 320 (13107200)
I0702 23:02:43.596360 13779 net.cpp:163] Memory required for data: 327680000
I0702 23:02:43.596369 13779 layer_factory.hpp:77] Creating layer conv1b/relu
I0702 23:02:43.596376 13779 net.cpp:98] Creating Layer conv1b/relu
I0702 23:02:43.596380 13779 net.cpp:439] conv1b/relu <- conv1b/bn
I0702 23:02:43.596385 13779 net.cpp:400] conv1b/relu -> conv1b/bn (in-place)
I0702 23:02:43.596390 13779 net.cpp:148] Setting up conv1b/relu
I0702 23:02:43.596395 13779 net.cpp:155] Top shape: 4 32 320 320 (13107200)
I0702 23:02:43.596398 13779 net.cpp:163] Memory required for data: 380108800
I0702 23:02:43.596401 13779 layer_factory.hpp:77] Creating layer pool1
I0702 23:02:43.596421 13779 net.cpp:98] Creating Layer pool1
I0702 23:02:43.596423 13779 net.cpp:439] pool1 <- conv1b/bn
I0702 23:02:43.596428 13779 net.cpp:413] pool1 -> pool1
I0702 23:02:43.596462 13779 net.cpp:148] Setting up pool1
I0702 23:02:43.596467 13779 net.cpp:155] Top shape: 4 32 160 160 (3276800)
I0702 23:02:43.596470 13779 net.cpp:163] Memory required for data: 393216000
I0702 23:02:43.596473 13779 layer_factory.hpp:77] Creating layer res2a_branch2a
I0702 23:02:43.596482 13779 net.cpp:98] Creating Layer res2a_branch2a
I0702 23:02:43.596484 13779 net.cpp:439] res2a_branch2a <- pool1
I0702 23:02:43.596489 13779 net.cpp:413] res2a_branch2a -> res2a_branch2a
I0702 23:02:43.597143 13779 net.cpp:148] Setting up res2a_branch2a
I0702 23:02:43.597151 13779 net.cpp:155] Top shape: 4 64 160 160 (6553600)
I0702 23:02:43.597153 13779 net.cpp:163] Memory required for data: 419430400
I0702 23:02:43.597162 13779 layer_factory.hpp:77] Creating layer res2a_branch2a/bn
I0702 23:02:43.597169 13779 net.cpp:98] Creating Layer res2a_branch2a/bn
I0702 23:02:43.597172 13779 net.cpp:439] res2a_branch2a/bn <- res2a_branch2a
I0702 23:02:43.597178 13779 net.cpp:413] res2a_branch2a/bn -> res2a_branch2a/bn
I0702 23:02:43.601799 13779 net.cpp:148] Setting up res2a_branch2a/bn
I0702 23:02:43.601842 13779 net.cpp:155] Top shape: 4 64 160 160 (6553600)
I0702 23:02:43.601864 13779 net.cpp:163] Memory required for data: 445644800
I0702 23:02:43.601898 13779 layer_factory.hpp:77] Creating layer res2a_branch2a/relu
I0702 23:02:43.601917 13779 net.cpp:98] Creating Layer res2a_branch2a/relu
I0702 23:02:43.601928 13779 net.cpp:439] res2a_branch2a/relu <- res2a_branch2a/bn
I0702 23:02:43.601943 13779 net.cpp:400] res2a_branch2a/relu -> res2a_branch2a/bn (in-place)
I0702 23:02:43.601958 13779 net.cpp:148] Setting up res2a_branch2a/relu
I0702 23:02:43.601974 13779 net.cpp:155] Top shape: 4 64 160 160 (6553600)
I0702 23:02:43.601985 13779 net.cpp:163] Memory required for data: 471859200
I0702 23:02:43.601997 13779 layer_factory.hpp:77] Creating layer res2a_branch2b
I0702 23:02:43.602015 13779 net.cpp:98] Creating Layer res2a_branch2b
I0702 23:02:43.602030 13779 net.cpp:439] res2a_branch2b <- res2a_branch2a/bn
I0702 23:02:43.602043 13779 net.cpp:413] res2a_branch2b -> res2a_branch2b
I0702 23:02:43.602808 13779 net.cpp:148] Setting up res2a_branch2b
I0702 23:02:43.602821 13779 net.cpp:155] Top shape: 4 64 160 160 (6553600)
I0702 23:02:43.602825 13779 net.cpp:163] Memory required for data: 498073600
I0702 23:02:43.602833 13779 layer_factory.hpp:77] Creating layer res2a_branch2b/bn
I0702 23:02:43.602843 13779 net.cpp:98] Creating Layer res2a_branch2b/bn
I0702 23:02:43.602847 13779 net.cpp:439] res2a_branch2b/bn <- res2a_branch2b
I0702 23:02:43.602855 13779 net.cpp:413] res2a_branch2b/bn -> res2a_branch2b/bn
I0702 23:02:43.606034 13779 net.cpp:148] Setting up res2a_branch2b/bn
I0702 23:02:43.606045 13779 net.cpp:155] Top shape: 4 64 160 160 (6553600)
I0702 23:02:43.606047 13779 net.cpp:163] Memory required for data: 524288000
I0702 23:02:43.606058 13779 layer_factory.hpp:77] Creating layer res2a_branch2b/relu
I0702 23:02:43.606066 13779 net.cpp:98] Creating Layer res2a_branch2b/relu
I0702 23:02:43.606070 13779 net.cpp:439] res2a_branch2b/relu <- res2a_branch2b/bn
I0702 23:02:43.606075 13779 net.cpp:400] res2a_branch2b/relu -> res2a_branch2b/bn (in-place)
I0702 23:02:43.606082 13779 net.cpp:148] Setting up res2a_branch2b/relu
I0702 23:02:43.606086 13779 net.cpp:155] Top shape: 4 64 160 160 (6553600)
I0702 23:02:43.606091 13779 net.cpp:163] Memory required for data: 550502400
I0702 23:02:43.606094 13779 layer_factory.hpp:77] Creating layer pool2
I0702 23:02:43.606106 13779 net.cpp:98] Creating Layer pool2
I0702 23:02:43.606109 13779 net.cpp:439] pool2 <- res2a_branch2b/bn
I0702 23:02:43.606117 13779 net.cpp:413] pool2 -> pool2
I0702 23:02:43.606166 13779 net.cpp:148] Setting up pool2
I0702 23:02:43.606173 13779 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0702 23:02:43.606175 13779 net.cpp:163] Memory required for data: 557056000
I0702 23:02:43.606200 13779 layer_factory.hpp:77] Creating layer res3a_branch2a
I0702 23:02:43.606211 13779 net.cpp:98] Creating Layer res3a_branch2a
I0702 23:02:43.606215 13779 net.cpp:439] res3a_branch2a <- pool2
I0702 23:02:43.606220 13779 net.cpp:413] res3a_branch2a -> res3a_branch2a
I0702 23:02:43.608044 13779 net.cpp:148] Setting up res3a_branch2a
I0702 23:02:43.608055 13779 net.cpp:155] Top shape: 4 128 80 80 (3276800)
I0702 23:02:43.608058 13779 net.cpp:163] Memory required for data: 570163200
I0702 23:02:43.608065 13779 layer_factory.hpp:77] Creating layer res3a_branch2a/bn
I0702 23:02:43.608074 13779 net.cpp:98] Creating Layer res3a_branch2a/bn
I0702 23:02:43.608078 13779 net.cpp:439] res3a_branch2a/bn <- res3a_branch2a
I0702 23:02:43.608083 13779 net.cpp:413] res3a_branch2a/bn -> res3a_branch2a/bn
I0702 23:02:43.608610 13779 net.cpp:148] Setting up res3a_branch2a/bn
I0702 23:02:43.608618 13779 net.cpp:155] Top shape: 4 128 80 80 (3276800)
I0702 23:02:43.608621 13779 net.cpp:163] Memory required for data: 583270400
I0702 23:02:43.608633 13779 layer_factory.hpp:77] Creating layer res3a_branch2a/relu
I0702 23:02:43.608639 13779 net.cpp:98] Creating Layer res3a_branch2a/relu
I0702 23:02:43.608644 13779 net.cpp:439] res3a_branch2a/relu <- res3a_branch2a/bn
I0702 23:02:43.608647 13779 net.cpp:400] res3a_branch2a/relu -> res3a_branch2a/bn (in-place)
I0702 23:02:43.608654 13779 net.cpp:148] Setting up res3a_branch2a/relu
I0702 23:02:43.608659 13779 net.cpp:155] Top shape: 4 128 80 80 (3276800)
I0702 23:02:43.608660 13779 net.cpp:163] Memory required for data: 596377600
I0702 23:02:43.608664 13779 layer_factory.hpp:77] Creating layer res3a_branch2b
I0702 23:02:43.608675 13779 net.cpp:98] Creating Layer res3a_branch2b
I0702 23:02:43.608677 13779 net.cpp:439] res3a_branch2b <- res3a_branch2a/bn
I0702 23:02:43.608682 13779 net.cpp:413] res3a_branch2b -> res3a_branch2b
I0702 23:02:43.609699 13779 net.cpp:148] Setting up res3a_branch2b
I0702 23:02:43.609707 13779 net.cpp:155] Top shape: 4 128 80 80 (3276800)
I0702 23:02:43.609710 13779 net.cpp:163] Memory required for data: 609484800
I0702 23:02:43.609716 13779 layer_factory.hpp:77] Creating layer res3a_branch2b/bn
I0702 23:02:43.609724 13779 net.cpp:98] Creating Layer res3a_branch2b/bn
I0702 23:02:43.609728 13779 net.cpp:439] res3a_branch2b/bn <- res3a_branch2b
I0702 23:02:43.609733 13779 net.cpp:413] res3a_branch2b/bn -> res3a_branch2b/bn
I0702 23:02:43.610414 13779 net.cpp:148] Setting up res3a_branch2b/bn
I0702 23:02:43.610445 13779 net.cpp:155] Top shape: 4 128 80 80 (3276800)
I0702 23:02:43.610455 13779 net.cpp:163] Memory required for data: 622592000
I0702 23:02:43.610474 13779 layer_factory.hpp:77] Creating layer res3a_branch2b/relu
I0702 23:02:43.610487 13779 net.cpp:98] Creating Layer res3a_branch2b/relu
I0702 23:02:43.610497 13779 net.cpp:439] res3a_branch2b/relu <- res3a_branch2b/bn
I0702 23:02:43.610507 13779 net.cpp:400] res3a_branch2b/relu -> res3a_branch2b/bn (in-place)
I0702 23:02:43.610519 13779 net.cpp:148] Setting up res3a_branch2b/relu
I0702 23:02:43.610529 13779 net.cpp:155] Top shape: 4 128 80 80 (3276800)
I0702 23:02:43.610538 13779 net.cpp:163] Memory required for data: 635699200
I0702 23:02:43.610546 13779 layer_factory.hpp:77] Creating layer res3a_branch2b/bn_res3a_branch2b/relu_0_split
I0702 23:02:43.610560 13779 net.cpp:98] Creating Layer res3a_branch2b/bn_res3a_branch2b/relu_0_split
I0702 23:02:43.610570 13779 net.cpp:439] res3a_branch2b/bn_res3a_branch2b/relu_0_split <- res3a_branch2b/bn
I0702 23:02:43.610582 13779 net.cpp:413] res3a_branch2b/bn_res3a_branch2b/relu_0_split -> res3a_branch2b/bn_res3a_branch2b/relu_0_split_0
I0702 23:02:43.610594 13779 net.cpp:413] res3a_branch2b/bn_res3a_branch2b/relu_0_split -> res3a_branch2b/bn_res3a_branch2b/relu_0_split_1
I0702 23:02:43.610651 13779 net.cpp:148] Setting up res3a_branch2b/bn_res3a_branch2b/relu_0_split
I0702 23:02:43.610663 13779 net.cpp:155] Top shape: 4 128 80 80 (3276800)
I0702 23:02:43.610672 13779 net.cpp:155] Top shape: 4 128 80 80 (3276800)
I0702 23:02:43.610688 13779 net.cpp:163] Memory required for data: 661913600
I0702 23:02:43.610715 13779 layer_factory.hpp:77] Creating layer pool3
I0702 23:02:43.610729 13779 net.cpp:98] Creating Layer pool3
I0702 23:02:43.610738 13779 net.cpp:439] pool3 <- res3a_branch2b/bn_res3a_branch2b/relu_0_split_0
I0702 23:02:43.610750 13779 net.cpp:413] pool3 -> pool3
I0702 23:02:43.610810 13779 net.cpp:148] Setting up pool3
I0702 23:02:43.610822 13779 net.cpp:155] Top shape: 4 128 40 40 (819200)
I0702 23:02:43.610831 13779 net.cpp:163] Memory required for data: 665190400
I0702 23:02:43.610841 13779 layer_factory.hpp:77] Creating layer res4a_branch2a
I0702 23:02:43.611178 13779 net.cpp:98] Creating Layer res4a_branch2a
I0702 23:02:43.611196 13779 net.cpp:439] res4a_branch2a <- pool3
I0702 23:02:43.611207 13779 net.cpp:413] res4a_branch2a -> res4a_branch2a
I0702 23:02:43.621978 13779 net.cpp:148] Setting up res4a_branch2a
I0702 23:02:43.622012 13779 net.cpp:155] Top shape: 4 256 40 40 (1638400)
I0702 23:02:43.622016 13779 net.cpp:163] Memory required for data: 671744000
I0702 23:02:43.622027 13779 layer_factory.hpp:77] Creating layer res4a_branch2a/bn
I0702 23:02:43.622045 13779 net.cpp:98] Creating Layer res4a_branch2a/bn
I0702 23:02:43.622050 13779 net.cpp:439] res4a_branch2a/bn <- res4a_branch2a
I0702 23:02:43.622057 13779 net.cpp:413] res4a_branch2a/bn -> res4a_branch2a/bn
I0702 23:02:43.625102 13779 net.cpp:148] Setting up res4a_branch2a/bn
I0702 23:02:43.625145 13779 net.cpp:155] Top shape: 4 256 40 40 (1638400)
I0702 23:02:43.625149 13779 net.cpp:163] Memory required for data: 678297600
I0702 23:02:43.625164 13779 layer_factory.hpp:77] Creating layer res4a_branch2a/relu
I0702 23:02:43.625185 13779 net.cpp:98] Creating Layer res4a_branch2a/relu
I0702 23:02:43.625196 13779 net.cpp:439] res4a_branch2a/relu <- res4a_branch2a/bn
I0702 23:02:43.625203 13779 net.cpp:400] res4a_branch2a/relu -> res4a_branch2a/bn (in-place)
I0702 23:02:43.625218 13779 net.cpp:148] Setting up res4a_branch2a/relu
I0702 23:02:43.625228 13779 net.cpp:155] Top shape: 4 256 40 40 (1638400)
I0702 23:02:43.625234 13779 net.cpp:163] Memory required for data: 684851200
I0702 23:02:43.625239 13779 layer_factory.hpp:77] Creating layer res4a_branch2b
I0702 23:02:43.625262 13779 net.cpp:98] Creating Layer res4a_branch2b
I0702 23:02:43.625272 13779 net.cpp:439] res4a_branch2b <- res4a_branch2a/bn
I0702 23:02:43.625283 13779 net.cpp:413] res4a_branch2b -> res4a_branch2b
I0702 23:02:43.630349 13779 net.cpp:148] Setting up res4a_branch2b
I0702 23:02:43.630362 13779 net.cpp:155] Top shape: 4 256 40 40 (1638400)
I0702 23:02:43.630367 13779 net.cpp:163] Memory required for data: 691404800
I0702 23:02:43.630373 13779 layer_factory.hpp:77] Creating layer res4a_branch2b/bn
I0702 23:02:43.630398 13779 net.cpp:98] Creating Layer res4a_branch2b/bn
I0702 23:02:43.630403 13779 net.cpp:439] res4a_branch2b/bn <- res4a_branch2b
I0702 23:02:43.630409 13779 net.cpp:413] res4a_branch2b/bn -> res4a_branch2b/bn
I0702 23:02:43.631119 13779 net.cpp:148] Setting up res4a_branch2b/bn
I0702 23:02:43.631129 13779 net.cpp:155] Top shape: 4 256 40 40 (1638400)
I0702 23:02:43.631131 13779 net.cpp:163] Memory required for data: 697958400
I0702 23:02:43.631139 13779 layer_factory.hpp:77] Creating layer res4a_branch2b/relu
I0702 23:02:43.631145 13779 net.cpp:98] Creating Layer res4a_branch2b/relu
I0702 23:02:43.631147 13779 net.cpp:439] res4a_branch2b/relu <- res4a_branch2b/bn
I0702 23:02:43.631152 13779 net.cpp:400] res4a_branch2b/relu -> res4a_branch2b/bn (in-place)
I0702 23:02:43.631157 13779 net.cpp:148] Setting up res4a_branch2b/relu
I0702 23:02:43.631161 13779 net.cpp:155] Top shape: 4 256 40 40 (1638400)
I0702 23:02:43.631165 13779 net.cpp:163] Memory required for data: 704512000
I0702 23:02:43.631168 13779 layer_factory.hpp:77] Creating layer pool4
I0702 23:02:43.631176 13779 net.cpp:98] Creating Layer pool4
I0702 23:02:43.631180 13779 net.cpp:439] pool4 <- res4a_branch2b/bn
I0702 23:02:43.631183 13779 net.cpp:413] pool4 -> pool4
I0702 23:02:43.631224 13779 net.cpp:148] Setting up pool4
I0702 23:02:43.631229 13779 net.cpp:155] Top shape: 4 256 40 40 (1638400)
I0702 23:02:43.631247 13779 net.cpp:163] Memory required for data: 711065600
I0702 23:02:43.631252 13779 layer_factory.hpp:77] Creating layer res5a_branch2a
I0702 23:02:43.631261 13779 net.cpp:98] Creating Layer res5a_branch2a
I0702 23:02:43.631265 13779 net.cpp:439] res5a_branch2a <- pool4
I0702 23:02:43.631269 13779 net.cpp:413] res5a_branch2a -> res5a_branch2a
I0702 23:02:43.659397 13779 net.cpp:148] Setting up res5a_branch2a
I0702 23:02:43.659420 13779 net.cpp:155] Top shape: 4 512 40 40 (3276800)
I0702 23:02:43.659421 13779 net.cpp:163] Memory required for data: 724172800
I0702 23:02:43.659427 13779 layer_factory.hpp:77] Creating layer res5a_branch2a/bn
I0702 23:02:43.659435 13779 net.cpp:98] Creating Layer res5a_branch2a/bn
I0702 23:02:43.659437 13779 net.cpp:439] res5a_branch2a/bn <- res5a_branch2a
I0702 23:02:43.659440 13779 net.cpp:413] res5a_branch2a/bn -> res5a_branch2a/bn
I0702 23:02:43.659955 13779 net.cpp:148] Setting up res5a_branch2a/bn
I0702 23:02:43.659962 13779 net.cpp:155] Top shape: 4 512 40 40 (3276800)
I0702 23:02:43.659965 13779 net.cpp:163] Memory required for data: 737280000
I0702 23:02:43.659970 13779 layer_factory.hpp:77] Creating layer res5a_branch2a/relu
I0702 23:02:43.659973 13779 net.cpp:98] Creating Layer res5a_branch2a/relu
I0702 23:02:43.659976 13779 net.cpp:439] res5a_branch2a/relu <- res5a_branch2a/bn
I0702 23:02:43.659977 13779 net.cpp:400] res5a_branch2a/relu -> res5a_branch2a/bn (in-place)
I0702 23:02:43.659981 13779 net.cpp:148] Setting up res5a_branch2a/relu
I0702 23:02:43.659984 13779 net.cpp:155] Top shape: 4 512 40 40 (3276800)
I0702 23:02:43.659986 13779 net.cpp:163] Memory required for data: 750387200
I0702 23:02:43.659987 13779 layer_factory.hpp:77] Creating layer res5a_branch2b
I0702 23:02:43.659992 13779 net.cpp:98] Creating Layer res5a_branch2b
I0702 23:02:43.659994 13779 net.cpp:439] res5a_branch2b <- res5a_branch2a/bn
I0702 23:02:43.659998 13779 net.cpp:413] res5a_branch2b -> res5a_branch2b
I0702 23:02:43.673339 13779 net.cpp:148] Setting up res5a_branch2b
I0702 23:02:43.673348 13779 net.cpp:155] Top shape: 4 512 40 40 (3276800)
I0702 23:02:43.673351 13779 net.cpp:163] Memory required for data: 763494400
I0702 23:02:43.673357 13779 layer_factory.hpp:77] Creating layer res5a_branch2b/bn
I0702 23:02:43.673362 13779 net.cpp:98] Creating Layer res5a_branch2b/bn
I0702 23:02:43.673363 13779 net.cpp:439] res5a_branch2b/bn <- res5a_branch2b
I0702 23:02:43.673367 13779 net.cpp:413] res5a_branch2b/bn -> res5a_branch2b/bn
I0702 23:02:43.673861 13779 net.cpp:148] Setting up res5a_branch2b/bn
I0702 23:02:43.673866 13779 net.cpp:155] Top shape: 4 512 40 40 (3276800)
I0702 23:02:43.673868 13779 net.cpp:163] Memory required for data: 776601600
I0702 23:02:43.673873 13779 layer_factory.hpp:77] Creating layer res5a_branch2b/relu
I0702 23:02:43.673877 13779 net.cpp:98] Creating Layer res5a_branch2b/relu
I0702 23:02:43.673878 13779 net.cpp:439] res5a_branch2b/relu <- res5a_branch2b/bn
I0702 23:02:43.673882 13779 net.cpp:400] res5a_branch2b/relu -> res5a_branch2b/bn (in-place)
I0702 23:02:43.673884 13779 net.cpp:148] Setting up res5a_branch2b/relu
I0702 23:02:43.673887 13779 net.cpp:155] Top shape: 4 512 40 40 (3276800)
I0702 23:02:43.673889 13779 net.cpp:163] Memory required for data: 789708800
I0702 23:02:43.673892 13779 layer_factory.hpp:77] Creating layer out5a
I0702 23:02:43.673895 13779 net.cpp:98] Creating Layer out5a
I0702 23:02:43.673897 13779 net.cpp:439] out5a <- res5a_branch2b/bn
I0702 23:02:43.673900 13779 net.cpp:413] out5a -> out5a
I0702 23:02:43.678200 13779 net.cpp:148] Setting up out5a
I0702 23:02:43.678218 13779 net.cpp:155] Top shape: 4 64 40 40 (409600)
I0702 23:02:43.678220 13779 net.cpp:163] Memory required for data: 791347200
I0702 23:02:43.678226 13779 layer_factory.hpp:77] Creating layer out5a/bn
I0702 23:02:43.678233 13779 net.cpp:98] Creating Layer out5a/bn
I0702 23:02:43.678236 13779 net.cpp:439] out5a/bn <- out5a
I0702 23:02:43.678241 13779 net.cpp:413] out5a/bn -> out5a/bn
I0702 23:02:43.678848 13779 net.cpp:148] Setting up out5a/bn
I0702 23:02:43.678864 13779 net.cpp:155] Top shape: 4 64 40 40 (409600)
I0702 23:02:43.678867 13779 net.cpp:163] Memory required for data: 792985600
I0702 23:02:43.678875 13779 layer_factory.hpp:77] Creating layer out5a/relu
I0702 23:02:43.678879 13779 net.cpp:98] Creating Layer out5a/relu
I0702 23:02:43.678881 13779 net.cpp:439] out5a/relu <- out5a/bn
I0702 23:02:43.678884 13779 net.cpp:400] out5a/relu -> out5a/bn (in-place)
I0702 23:02:43.678890 13779 net.cpp:148] Setting up out5a/relu
I0702 23:02:43.678894 13779 net.cpp:155] Top shape: 4 64 40 40 (409600)
I0702 23:02:43.678894 13779 net.cpp:163] Memory required for data: 794624000
I0702 23:02:43.678896 13779 layer_factory.hpp:77] Creating layer out5a_up2
I0702 23:02:43.678903 13779 net.cpp:98] Creating Layer out5a_up2
I0702 23:02:43.678905 13779 net.cpp:439] out5a_up2 <- out5a/bn
I0702 23:02:43.678911 13779 net.cpp:413] out5a_up2 -> out5a_up2
I0702 23:02:43.679111 13779 net.cpp:148] Setting up out5a_up2
I0702 23:02:43.679116 13779 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0702 23:02:43.679117 13779 net.cpp:163] Memory required for data: 801177600
I0702 23:02:43.679121 13779 layer_factory.hpp:77] Creating layer out3a
I0702 23:02:43.679124 13779 net.cpp:98] Creating Layer out3a
I0702 23:02:43.679127 13779 net.cpp:439] out3a <- res3a_branch2b/bn_res3a_branch2b/relu_0_split_1
I0702 23:02:43.679131 13779 net.cpp:413] out3a -> out3a
I0702 23:02:43.680892 13779 net.cpp:148] Setting up out3a
I0702 23:02:43.680902 13779 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0702 23:02:43.680904 13779 net.cpp:163] Memory required for data: 807731200
I0702 23:02:43.680907 13779 layer_factory.hpp:77] Creating layer out3a/bn
I0702 23:02:43.680912 13779 net.cpp:98] Creating Layer out3a/bn
I0702 23:02:43.680914 13779 net.cpp:439] out3a/bn <- out3a
I0702 23:02:43.680917 13779 net.cpp:413] out3a/bn -> out3a/bn
I0702 23:02:43.681466 13779 net.cpp:148] Setting up out3a/bn
I0702 23:02:43.681473 13779 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0702 23:02:43.681474 13779 net.cpp:163] Memory required for data: 814284800
I0702 23:02:43.681479 13779 layer_factory.hpp:77] Creating layer out3a/relu
I0702 23:02:43.681483 13779 net.cpp:98] Creating Layer out3a/relu
I0702 23:02:43.681485 13779 net.cpp:439] out3a/relu <- out3a/bn
I0702 23:02:43.681488 13779 net.cpp:400] out3a/relu -> out3a/bn (in-place)
I0702 23:02:43.681491 13779 net.cpp:148] Setting up out3a/relu
I0702 23:02:43.681493 13779 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0702 23:02:43.681495 13779 net.cpp:163] Memory required for data: 820838400
I0702 23:02:43.681498 13779 layer_factory.hpp:77] Creating layer out3_out5_combined
I0702 23:02:43.681500 13779 net.cpp:98] Creating Layer out3_out5_combined
I0702 23:02:43.681502 13779 net.cpp:439] out3_out5_combined <- out5a_up2
I0702 23:02:43.681504 13779 net.cpp:439] out3_out5_combined <- out3a/bn
I0702 23:02:43.681509 13779 net.cpp:413] out3_out5_combined -> out3_out5_combined
I0702 23:02:43.681529 13779 net.cpp:148] Setting up out3_out5_combined
I0702 23:02:43.681532 13779 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0702 23:02:43.681535 13779 net.cpp:163] Memory required for data: 827392000
I0702 23:02:43.681536 13779 layer_factory.hpp:77] Creating layer ctx_conv1
I0702 23:02:43.681540 13779 net.cpp:98] Creating Layer ctx_conv1
I0702 23:02:43.681542 13779 net.cpp:439] ctx_conv1 <- out3_out5_combined
I0702 23:02:43.681545 13779 net.cpp:413] ctx_conv1 -> ctx_conv1
I0702 23:02:43.682533 13779 net.cpp:148] Setting up ctx_conv1
I0702 23:02:43.682541 13779 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0702 23:02:43.682545 13779 net.cpp:163] Memory required for data: 833945600
I0702 23:02:43.682548 13779 layer_factory.hpp:77] Creating layer ctx_conv1/bn
I0702 23:02:43.682552 13779 net.cpp:98] Creating Layer ctx_conv1/bn
I0702 23:02:43.682554 13779 net.cpp:439] ctx_conv1/bn <- ctx_conv1
I0702 23:02:43.682557 13779 net.cpp:413] ctx_conv1/bn -> ctx_conv1/bn
I0702 23:02:43.683099 13779 net.cpp:148] Setting up ctx_conv1/bn
I0702 23:02:43.683104 13779 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0702 23:02:43.683113 13779 net.cpp:163] Memory required for data: 840499200
I0702 23:02:43.683120 13779 layer_factory.hpp:77] Creating layer ctx_conv1/relu
I0702 23:02:43.683121 13779 net.cpp:98] Creating Layer ctx_conv1/relu
I0702 23:02:43.683125 13779 net.cpp:439] ctx_conv1/relu <- ctx_conv1/bn
I0702 23:02:43.683126 13779 net.cpp:400] ctx_conv1/relu -> ctx_conv1/bn (in-place)
I0702 23:02:43.683130 13779 net.cpp:148] Setting up ctx_conv1/relu
I0702 23:02:43.683132 13779 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0702 23:02:43.683135 13779 net.cpp:163] Memory required for data: 847052800
I0702 23:02:43.683136 13779 layer_factory.hpp:77] Creating layer ctx_conv2
I0702 23:02:43.683140 13779 net.cpp:98] Creating Layer ctx_conv2
I0702 23:02:43.683142 13779 net.cpp:439] ctx_conv2 <- ctx_conv1/bn
I0702 23:02:43.683145 13779 net.cpp:413] ctx_conv2 -> ctx_conv2
I0702 23:02:43.684139 13779 net.cpp:148] Setting up ctx_conv2
I0702 23:02:43.684144 13779 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0702 23:02:43.684146 13779 net.cpp:163] Memory required for data: 853606400
I0702 23:02:43.684149 13779 layer_factory.hpp:77] Creating layer ctx_conv2/bn
I0702 23:02:43.684152 13779 net.cpp:98] Creating Layer ctx_conv2/bn
I0702 23:02:43.684154 13779 net.cpp:439] ctx_conv2/bn <- ctx_conv2
I0702 23:02:43.684157 13779 net.cpp:413] ctx_conv2/bn -> ctx_conv2/bn
I0702 23:02:43.684690 13779 net.cpp:148] Setting up ctx_conv2/bn
I0702 23:02:43.684695 13779 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0702 23:02:43.684697 13779 net.cpp:163] Memory required for data: 860160000
I0702 23:02:43.684701 13779 layer_factory.hpp:77] Creating layer ctx_conv2/relu
I0702 23:02:43.684705 13779 net.cpp:98] Creating Layer ctx_conv2/relu
I0702 23:02:43.684707 13779 net.cpp:439] ctx_conv2/relu <- ctx_conv2/bn
I0702 23:02:43.684710 13779 net.cpp:400] ctx_conv2/relu -> ctx_conv2/bn (in-place)
I0702 23:02:43.684712 13779 net.cpp:148] Setting up ctx_conv2/relu
I0702 23:02:43.684715 13779 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0702 23:02:43.684716 13779 net.cpp:163] Memory required for data: 866713600
I0702 23:02:43.684718 13779 layer_factory.hpp:77] Creating layer ctx_conv3
I0702 23:02:43.684722 13779 net.cpp:98] Creating Layer ctx_conv3
I0702 23:02:43.684725 13779 net.cpp:439] ctx_conv3 <- ctx_conv2/bn
I0702 23:02:43.684727 13779 net.cpp:413] ctx_conv3 -> ctx_conv3
I0702 23:02:43.685719 13779 net.cpp:148] Setting up ctx_conv3
I0702 23:02:43.685724 13779 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0702 23:02:43.685726 13779 net.cpp:163] Memory required for data: 873267200
I0702 23:02:43.685729 13779 layer_factory.hpp:77] Creating layer ctx_conv3/bn
I0702 23:02:43.685734 13779 net.cpp:98] Creating Layer ctx_conv3/bn
I0702 23:02:43.685735 13779 net.cpp:439] ctx_conv3/bn <- ctx_conv3
I0702 23:02:43.685739 13779 net.cpp:413] ctx_conv3/bn -> ctx_conv3/bn
I0702 23:02:43.686264 13779 net.cpp:148] Setting up ctx_conv3/bn
I0702 23:02:43.686269 13779 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0702 23:02:43.686270 13779 net.cpp:163] Memory required for data: 879820800
I0702 23:02:43.686275 13779 layer_factory.hpp:77] Creating layer ctx_conv3/relu
I0702 23:02:43.686277 13779 net.cpp:98] Creating Layer ctx_conv3/relu
I0702 23:02:43.686280 13779 net.cpp:439] ctx_conv3/relu <- ctx_conv3/bn
I0702 23:02:43.686285 13779 net.cpp:400] ctx_conv3/relu -> ctx_conv3/bn (in-place)
I0702 23:02:43.686287 13779 net.cpp:148] Setting up ctx_conv3/relu
I0702 23:02:43.686290 13779 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0702 23:02:43.686291 13779 net.cpp:163] Memory required for data: 886374400
I0702 23:02:43.686293 13779 layer_factory.hpp:77] Creating layer ctx_conv4
I0702 23:02:43.686297 13779 net.cpp:98] Creating Layer ctx_conv4
I0702 23:02:43.686300 13779 net.cpp:439] ctx_conv4 <- ctx_conv3/bn
I0702 23:02:43.686301 13779 net.cpp:413] ctx_conv4 -> ctx_conv4
I0702 23:02:43.687295 13779 net.cpp:148] Setting up ctx_conv4
I0702 23:02:43.687300 13779 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0702 23:02:43.687302 13779 net.cpp:163] Memory required for data: 892928000
I0702 23:02:43.687310 13779 layer_factory.hpp:77] Creating layer ctx_conv4/bn
I0702 23:02:43.687314 13779 net.cpp:98] Creating Layer ctx_conv4/bn
I0702 23:02:43.687316 13779 net.cpp:439] ctx_conv4/bn <- ctx_conv4
I0702 23:02:43.687319 13779 net.cpp:413] ctx_conv4/bn -> ctx_conv4/bn
I0702 23:02:43.687840 13779 net.cpp:148] Setting up ctx_conv4/bn
I0702 23:02:43.687845 13779 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0702 23:02:43.687847 13779 net.cpp:163] Memory required for data: 899481600
I0702 23:02:43.687851 13779 layer_factory.hpp:77] Creating layer ctx_conv4/relu
I0702 23:02:43.687855 13779 net.cpp:98] Creating Layer ctx_conv4/relu
I0702 23:02:43.687856 13779 net.cpp:439] ctx_conv4/relu <- ctx_conv4/bn
I0702 23:02:43.687858 13779 net.cpp:400] ctx_conv4/relu -> ctx_conv4/bn (in-place)
I0702 23:02:43.687861 13779 net.cpp:148] Setting up ctx_conv4/relu
I0702 23:02:43.687863 13779 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0702 23:02:43.687865 13779 net.cpp:163] Memory required for data: 906035200
I0702 23:02:43.687867 13779 layer_factory.hpp:77] Creating layer ctx_final
I0702 23:02:43.687871 13779 net.cpp:98] Creating Layer ctx_final
I0702 23:02:43.687872 13779 net.cpp:439] ctx_final <- ctx_conv4/bn
I0702 23:02:43.687875 13779 net.cpp:413] ctx_final -> ctx_final
I0702 23:02:43.688194 13779 net.cpp:148] Setting up ctx_final
I0702 23:02:43.688199 13779 net.cpp:155] Top shape: 4 8 80 80 (204800)
I0702 23:02:43.688200 13779 net.cpp:163] Memory required for data: 906854400
I0702 23:02:43.688204 13779 layer_factory.hpp:77] Creating layer ctx_final/relu
I0702 23:02:43.688205 13779 net.cpp:98] Creating Layer ctx_final/relu
I0702 23:02:43.688207 13779 net.cpp:439] ctx_final/relu <- ctx_final
I0702 23:02:43.688210 13779 net.cpp:400] ctx_final/relu -> ctx_final (in-place)
I0702 23:02:43.688212 13779 net.cpp:148] Setting up ctx_final/relu
I0702 23:02:43.688215 13779 net.cpp:155] Top shape: 4 8 80 80 (204800)
I0702 23:02:43.688216 13779 net.cpp:163] Memory required for data: 907673600
I0702 23:02:43.688218 13779 layer_factory.hpp:77] Creating layer out_deconv_final_up2
I0702 23:02:43.688221 13779 net.cpp:98] Creating Layer out_deconv_final_up2
I0702 23:02:43.688223 13779 net.cpp:439] out_deconv_final_up2 <- ctx_final
I0702 23:02:43.688225 13779 net.cpp:413] out_deconv_final_up2 -> out_deconv_final_up2
I0702 23:02:43.688393 13779 net.cpp:148] Setting up out_deconv_final_up2
I0702 23:02:43.688397 13779 net.cpp:155] Top shape: 4 8 160 160 (819200)
I0702 23:02:43.688400 13779 net.cpp:163] Memory required for data: 910950400
I0702 23:02:43.688402 13779 layer_factory.hpp:77] Creating layer out_deconv_final_up4
I0702 23:02:43.688405 13779 net.cpp:98] Creating Layer out_deconv_final_up4
I0702 23:02:43.688406 13779 net.cpp:439] out_deconv_final_up4 <- out_deconv_final_up2
I0702 23:02:43.688410 13779 net.cpp:413] out_deconv_final_up4 -> out_deconv_final_up4
I0702 23:02:43.688575 13779 net.cpp:148] Setting up out_deconv_final_up4
I0702 23:02:43.688578 13779 net.cpp:155] Top shape: 4 8 320 320 (3276800)
I0702 23:02:43.688580 13779 net.cpp:163] Memory required for data: 924057600
I0702 23:02:43.688583 13779 layer_factory.hpp:77] Creating layer out_deconv_final_up8
I0702 23:02:43.688585 13779 net.cpp:98] Creating Layer out_deconv_final_up8
I0702 23:02:43.688587 13779 net.cpp:439] out_deconv_final_up8 <- out_deconv_final_up4
I0702 23:02:43.688591 13779 net.cpp:413] out_deconv_final_up8 -> out_deconv_final_up8
I0702 23:02:43.688752 13779 net.cpp:148] Setting up out_deconv_final_up8
I0702 23:02:43.688757 13779 net.cpp:155] Top shape: 4 8 640 640 (13107200)
I0702 23:02:43.688758 13779 net.cpp:163] Memory required for data: 976486400
I0702 23:02:43.688761 13779 layer_factory.hpp:77] Creating layer out_deconv_final_up8_out_deconv_final_up8_0_split
I0702 23:02:43.688765 13779 net.cpp:98] Creating Layer out_deconv_final_up8_out_deconv_final_up8_0_split
I0702 23:02:43.688766 13779 net.cpp:439] out_deconv_final_up8_out_deconv_final_up8_0_split <- out_deconv_final_up8
I0702 23:02:43.688768 13779 net.cpp:413] out_deconv_final_up8_out_deconv_final_up8_0_split -> out_deconv_final_up8_out_deconv_final_up8_0_split_0
I0702 23:02:43.688776 13779 net.cpp:413] out_deconv_final_up8_out_deconv_final_up8_0_split -> out_deconv_final_up8_out_deconv_final_up8_0_split_1
I0702 23:02:43.688779 13779 net.cpp:413] out_deconv_final_up8_out_deconv_final_up8_0_split -> out_deconv_final_up8_out_deconv_final_up8_0_split_2
I0702 23:02:43.688819 13779 net.cpp:148] Setting up out_deconv_final_up8_out_deconv_final_up8_0_split
I0702 23:02:43.688823 13779 net.cpp:155] Top shape: 4 8 640 640 (13107200)
I0702 23:02:43.688825 13779 net.cpp:155] Top shape: 4 8 640 640 (13107200)
I0702 23:02:43.688827 13779 net.cpp:155] Top shape: 4 8 640 640 (13107200)
I0702 23:02:43.688829 13779 net.cpp:163] Memory required for data: 1133772800
I0702 23:02:43.688832 13779 layer_factory.hpp:77] Creating layer loss
I0702 23:02:43.688835 13779 net.cpp:98] Creating Layer loss
I0702 23:02:43.688838 13779 net.cpp:439] loss <- out_deconv_final_up8_out_deconv_final_up8_0_split_0
I0702 23:02:43.688839 13779 net.cpp:439] loss <- label_data_1_split_0
I0702 23:02:43.688843 13779 net.cpp:413] loss -> loss
I0702 23:02:43.688846 13779 layer_factory.hpp:77] Creating layer loss
I0702 23:02:43.704440 13779 net.cpp:148] Setting up loss
I0702 23:02:43.704463 13779 net.cpp:155] Top shape: (1)
I0702 23:02:43.704465 13779 net.cpp:158]     with loss weight 1
I0702 23:02:43.704473 13779 net.cpp:163] Memory required for data: 1133772804
I0702 23:02:43.704476 13779 layer_factory.hpp:77] Creating layer accuracy/top1
I0702 23:02:43.704485 13779 net.cpp:98] Creating Layer accuracy/top1
I0702 23:02:43.704489 13779 net.cpp:439] accuracy/top1 <- out_deconv_final_up8_out_deconv_final_up8_0_split_1
I0702 23:02:43.704494 13779 net.cpp:439] accuracy/top1 <- label_data_1_split_1
I0702 23:02:43.704499 13779 net.cpp:413] accuracy/top1 -> accuracy/top1
I0702 23:02:43.704506 13779 net.cpp:148] Setting up accuracy/top1
I0702 23:02:43.704509 13779 net.cpp:155] Top shape: (1)
I0702 23:02:43.704511 13779 net.cpp:163] Memory required for data: 1133772808
I0702 23:02:43.704512 13779 layer_factory.hpp:77] Creating layer accuracy/top5
I0702 23:02:43.704516 13779 net.cpp:98] Creating Layer accuracy/top5
I0702 23:02:43.704519 13779 net.cpp:439] accuracy/top5 <- out_deconv_final_up8_out_deconv_final_up8_0_split_2
I0702 23:02:43.704520 13779 net.cpp:439] accuracy/top5 <- label_data_1_split_2
I0702 23:02:43.704524 13779 net.cpp:413] accuracy/top5 -> accuracy/top5
I0702 23:02:43.704527 13779 net.cpp:148] Setting up accuracy/top5
I0702 23:02:43.704530 13779 net.cpp:155] Top shape: (1)
I0702 23:02:43.704532 13779 net.cpp:163] Memory required for data: 1133772812
I0702 23:02:43.704535 13779 net.cpp:226] accuracy/top5 does not need backward computation.
I0702 23:02:43.704537 13779 net.cpp:226] accuracy/top1 does not need backward computation.
I0702 23:02:43.704540 13779 net.cpp:224] loss needs backward computation.
I0702 23:02:43.704542 13779 net.cpp:224] out_deconv_final_up8_out_deconv_final_up8_0_split needs backward computation.
I0702 23:02:43.704545 13779 net.cpp:224] out_deconv_final_up8 needs backward computation.
I0702 23:02:43.704546 13779 net.cpp:224] out_deconv_final_up4 needs backward computation.
I0702 23:02:43.704550 13779 net.cpp:224] out_deconv_final_up2 needs backward computation.
I0702 23:02:43.704551 13779 net.cpp:224] ctx_final/relu needs backward computation.
I0702 23:02:43.704553 13779 net.cpp:224] ctx_final needs backward computation.
I0702 23:02:43.704555 13779 net.cpp:224] ctx_conv4/relu needs backward computation.
I0702 23:02:43.704557 13779 net.cpp:224] ctx_conv4/bn needs backward computation.
I0702 23:02:43.704560 13779 net.cpp:224] ctx_conv4 needs backward computation.
I0702 23:02:43.704562 13779 net.cpp:224] ctx_conv3/relu needs backward computation.
I0702 23:02:43.704565 13779 net.cpp:224] ctx_conv3/bn needs backward computation.
I0702 23:02:43.704567 13779 net.cpp:224] ctx_conv3 needs backward computation.
I0702 23:02:43.704569 13779 net.cpp:224] ctx_conv2/relu needs backward computation.
I0702 23:02:43.704572 13779 net.cpp:224] ctx_conv2/bn needs backward computation.
I0702 23:02:43.704586 13779 net.cpp:224] ctx_conv2 needs backward computation.
I0702 23:02:43.704587 13779 net.cpp:224] ctx_conv1/relu needs backward computation.
I0702 23:02:43.704589 13779 net.cpp:224] ctx_conv1/bn needs backward computation.
I0702 23:02:43.704591 13779 net.cpp:224] ctx_conv1 needs backward computation.
I0702 23:02:43.704596 13779 net.cpp:224] out3_out5_combined needs backward computation.
I0702 23:02:43.704598 13779 net.cpp:224] out3a/relu needs backward computation.
I0702 23:02:43.704601 13779 net.cpp:224] out3a/bn needs backward computation.
I0702 23:02:43.704603 13779 net.cpp:224] out3a needs backward computation.
I0702 23:02:43.704605 13779 net.cpp:224] out5a_up2 needs backward computation.
I0702 23:02:43.704608 13779 net.cpp:224] out5a/relu needs backward computation.
I0702 23:02:43.704610 13779 net.cpp:224] out5a/bn needs backward computation.
I0702 23:02:43.704612 13779 net.cpp:224] out5a needs backward computation.
I0702 23:02:43.704615 13779 net.cpp:224] res5a_branch2b/relu needs backward computation.
I0702 23:02:43.704617 13779 net.cpp:224] res5a_branch2b/bn needs backward computation.
I0702 23:02:43.704619 13779 net.cpp:224] res5a_branch2b needs backward computation.
I0702 23:02:43.704622 13779 net.cpp:224] res5a_branch2a/relu needs backward computation.
I0702 23:02:43.704624 13779 net.cpp:224] res5a_branch2a/bn needs backward computation.
I0702 23:02:43.704627 13779 net.cpp:224] res5a_branch2a needs backward computation.
I0702 23:02:43.704628 13779 net.cpp:224] pool4 needs backward computation.
I0702 23:02:43.704632 13779 net.cpp:224] res4a_branch2b/relu needs backward computation.
I0702 23:02:43.704633 13779 net.cpp:224] res4a_branch2b/bn needs backward computation.
I0702 23:02:43.704635 13779 net.cpp:224] res4a_branch2b needs backward computation.
I0702 23:02:43.704638 13779 net.cpp:224] res4a_branch2a/relu needs backward computation.
I0702 23:02:43.704640 13779 net.cpp:224] res4a_branch2a/bn needs backward computation.
I0702 23:02:43.704643 13779 net.cpp:224] res4a_branch2a needs backward computation.
I0702 23:02:43.704645 13779 net.cpp:224] pool3 needs backward computation.
I0702 23:02:43.704648 13779 net.cpp:224] res3a_branch2b/bn_res3a_branch2b/relu_0_split needs backward computation.
I0702 23:02:43.704650 13779 net.cpp:224] res3a_branch2b/relu needs backward computation.
I0702 23:02:43.704653 13779 net.cpp:224] res3a_branch2b/bn needs backward computation.
I0702 23:02:43.704655 13779 net.cpp:224] res3a_branch2b needs backward computation.
I0702 23:02:43.704658 13779 net.cpp:224] res3a_branch2a/relu needs backward computation.
I0702 23:02:43.704660 13779 net.cpp:224] res3a_branch2a/bn needs backward computation.
I0702 23:02:43.704663 13779 net.cpp:224] res3a_branch2a needs backward computation.
I0702 23:02:43.704665 13779 net.cpp:224] pool2 needs backward computation.
I0702 23:02:43.704668 13779 net.cpp:224] res2a_branch2b/relu needs backward computation.
I0702 23:02:43.704670 13779 net.cpp:224] res2a_branch2b/bn needs backward computation.
I0702 23:02:43.704672 13779 net.cpp:224] res2a_branch2b needs backward computation.
I0702 23:02:43.704675 13779 net.cpp:224] res2a_branch2a/relu needs backward computation.
I0702 23:02:43.704677 13779 net.cpp:224] res2a_branch2a/bn needs backward computation.
I0702 23:02:43.704679 13779 net.cpp:224] res2a_branch2a needs backward computation.
I0702 23:02:43.704682 13779 net.cpp:224] pool1 needs backward computation.
I0702 23:02:43.704684 13779 net.cpp:224] conv1b/relu needs backward computation.
I0702 23:02:43.704687 13779 net.cpp:224] conv1b/bn needs backward computation.
I0702 23:02:43.704689 13779 net.cpp:224] conv1b needs backward computation.
I0702 23:02:43.704692 13779 net.cpp:224] conv1a/relu needs backward computation.
I0702 23:02:43.704694 13779 net.cpp:224] conv1a/bn needs backward computation.
I0702 23:02:43.704697 13779 net.cpp:224] conv1a needs backward computation.
I0702 23:02:43.704699 13779 net.cpp:226] data/bias does not need backward computation.
I0702 23:02:43.704702 13779 net.cpp:226] label_data_1_split does not need backward computation.
I0702 23:02:43.704708 13779 net.cpp:226] data does not need backward computation.
I0702 23:02:43.704711 13779 net.cpp:268] This network produces output accuracy/top1
I0702 23:02:43.704713 13779 net.cpp:268] This network produces output accuracy/top5
I0702 23:02:43.704716 13779 net.cpp:268] This network produces output loss
I0702 23:02:43.704744 13779 net.cpp:288] Network initialization done.
I0702 23:02:43.704839 13779 solver.cpp:60] Solver scaffolding done.
I0702 23:02:43.710650 13779 caffe.cpp:145] Finetuning from training/imagenet_jacintonet11_v2_bn_iter_160000.caffemodel
I0702 23:02:43.806730 13779 net.cpp:804] Ignoring source layer input
I0702 23:02:43.811050 13779 net.cpp:804] Ignoring source layer pool5
I0702 23:02:43.811079 13779 net.cpp:804] Ignoring source layer fc1000
I0702 23:02:43.811094 13779 net.cpp:804] Ignoring source layer fc1000_fc1000_0_split
I0702 23:02:43.811110 13779 net.cpp:804] Ignoring source layer prob
I0702 23:02:43.811131 13779 net.cpp:804] Ignoring source layer argMaxOut
I0702 23:02:43.836127 13779 net.cpp:804] Ignoring source layer input
I0702 23:02:43.837726 13779 net.cpp:804] Ignoring source layer pool5
I0702 23:02:43.837736 13779 net.cpp:804] Ignoring source layer fc1000
I0702 23:02:43.837741 13779 net.cpp:804] Ignoring source layer fc1000_fc1000_0_split
I0702 23:02:43.837746 13779 net.cpp:804] Ignoring source layer prob
I0702 23:02:43.837752 13779 net.cpp:804] Ignoring source layer argMaxOut
W0702 23:02:43.849113 13779 parallel.cpp:400] Batch size must be divisible by the number of solvers (GPUs)
I0702 23:02:43.899621 13779 data_layer.cpp:78] ReshapePrefetch 8, 3, 640, 640
I0702 23:02:43.899670 13779 data_layer.cpp:83] output data size: 8,3,640,640
I0702 23:02:43.961908 13779 data_layer.cpp:78] ReshapePrefetch 8, 1, 640, 640
I0702 23:02:43.961966 13779 data_layer.cpp:83] output data size: 8,1,640,640
I0702 23:02:44.529709 13779 parallel.cpp:334] Starting Optimization
I0702 23:02:44.529754 13779 solver.cpp:415] Solving jsegnet21v2_train
I0702 23:02:44.529759 13779 solver.cpp:416] Learning Rate Policy: multistep
I0702 23:02:44.533639 13779 blocking_queue.cpp:50] Data layer prefetch queue empty
I0702 23:02:44.533640 13869 blocking_queue.cpp:50] Data layer prefetch queue empty
I0702 23:02:44.943545 13779 solver.cpp:290] Iteration 0 (0 iter/s, 0.413752s/100 iter), loss = 1.78075
I0702 23:02:44.943572 13779 solver.cpp:309]     Train net output #0: loss = 1.78075 (* 1 = 1.78075 loss)
I0702 23:02:44.943578 13779 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
I0702 23:03:39.091298 13815 blocking_queue.cpp:50] Waiting for data
I0702 23:04:02.724092 13779 solver.cpp:290] Iteration 100 (1.2857 iter/s, 77.7785s/100 iter), loss = 0.433657
I0702 23:04:02.724118 13779 solver.cpp:309]     Train net output #0: loss = 0.433657 (* 1 = 0.433657 loss)
I0702 23:04:02.724125 13779 sgd_solver.cpp:106] Iteration 100, lr = 0.0001
I0702 23:04:33.724577 13815 blocking_queue.cpp:50] Waiting for data
I0702 23:05:10.147992 13779 solver.cpp:290] Iteration 200 (1.48319 iter/s, 67.422s/100 iter), loss = 0.121768
I0702 23:05:10.148046 13779 solver.cpp:309]     Train net output #0: loss = 0.121768 (* 1 = 0.121768 loss)
I0702 23:05:10.148054 13779 sgd_solver.cpp:106] Iteration 200, lr = 0.0001
I0702 23:05:33.480031 13779 solver.cpp:290] Iteration 300 (4.28608 iter/s, 23.3313s/100 iter), loss = 0.107143
I0702 23:05:33.480056 13779 solver.cpp:309]     Train net output #0: loss = 0.107142 (* 1 = 0.107142 loss)
I0702 23:05:33.480064 13779 sgd_solver.cpp:106] Iteration 300, lr = 0.0001
I0702 23:05:57.799996 13779 solver.cpp:290] Iteration 400 (4.11197 iter/s, 24.3193s/100 iter), loss = 0.173569
I0702 23:05:57.800052 13779 solver.cpp:309]     Train net output #0: loss = 0.173569 (* 1 = 0.173569 loss)
I0702 23:05:57.800060 13779 sgd_solver.cpp:106] Iteration 400, lr = 0.0001
I0702 23:06:22.299057 13779 solver.cpp:290] Iteration 500 (4.08191 iter/s, 24.4983s/100 iter), loss = 0.0841622
I0702 23:06:22.299083 13779 solver.cpp:309]     Train net output #0: loss = 0.0841622 (* 1 = 0.0841622 loss)
I0702 23:06:22.299090 13779 sgd_solver.cpp:106] Iteration 500, lr = 0.0001
I0702 23:06:46.850190 13779 solver.cpp:290] Iteration 600 (4.07325 iter/s, 24.5504s/100 iter), loss = 0.0529981
I0702 23:06:46.850266 13779 solver.cpp:309]     Train net output #0: loss = 0.052998 (* 1 = 0.052998 loss)
I0702 23:06:46.850276 13779 sgd_solver.cpp:106] Iteration 600, lr = 0.0001
I0702 23:07:11.366199 13779 solver.cpp:290] Iteration 700 (4.07909 iter/s, 24.5153s/100 iter), loss = 0.117636
I0702 23:07:11.366225 13779 solver.cpp:309]     Train net output #0: loss = 0.117635 (* 1 = 0.117635 loss)
I0702 23:07:11.366233 13779 sgd_solver.cpp:106] Iteration 700, lr = 0.0001
I0702 23:07:35.850114 13779 solver.cpp:290] Iteration 800 (4.08443 iter/s, 24.4832s/100 iter), loss = 0.148181
I0702 23:07:35.850162 13779 solver.cpp:309]     Train net output #0: loss = 0.148181 (* 1 = 0.148181 loss)
I0702 23:07:35.850170 13779 sgd_solver.cpp:106] Iteration 800, lr = 0.0001
I0702 23:08:00.314208 13779 solver.cpp:290] Iteration 900 (4.08774 iter/s, 24.4634s/100 iter), loss = 0.132403
I0702 23:08:00.314232 13779 solver.cpp:309]     Train net output #0: loss = 0.132403 (* 1 = 0.132403 loss)
I0702 23:08:00.314240 13779 sgd_solver.cpp:106] Iteration 900, lr = 0.0001
I0702 23:08:24.790918 13779 solver.cpp:290] Iteration 1000 (4.08563 iter/s, 24.476s/100 iter), loss = 0.0407398
I0702 23:08:24.791031 13779 solver.cpp:309]     Train net output #0: loss = 0.0407398 (* 1 = 0.0407398 loss)
I0702 23:08:24.791043 13779 sgd_solver.cpp:106] Iteration 1000, lr = 0.0001
I0702 23:08:49.325865 13779 solver.cpp:290] Iteration 1100 (4.07595 iter/s, 24.5342s/100 iter), loss = 0.0817075
I0702 23:08:49.325889 13779 solver.cpp:309]     Train net output #0: loss = 0.0817074 (* 1 = 0.0817074 loss)
I0702 23:08:49.325897 13779 sgd_solver.cpp:106] Iteration 1100, lr = 0.0001
I0702 23:09:13.830158 13779 solver.cpp:290] Iteration 1200 (4.08103 iter/s, 24.5036s/100 iter), loss = 0.118135
I0702 23:09:13.830265 13779 solver.cpp:309]     Train net output #0: loss = 0.118134 (* 1 = 0.118134 loss)
I0702 23:09:13.830274 13779 sgd_solver.cpp:106] Iteration 1200, lr = 0.0001
I0702 23:09:38.323781 13779 solver.cpp:290] Iteration 1300 (4.08282 iter/s, 24.4929s/100 iter), loss = 0.0586465
I0702 23:09:38.323803 13779 solver.cpp:309]     Train net output #0: loss = 0.0586464 (* 1 = 0.0586464 loss)
I0702 23:09:38.323810 13779 sgd_solver.cpp:106] Iteration 1300, lr = 0.0001
I0702 23:10:02.779587 13779 solver.cpp:290] Iteration 1400 (4.08912 iter/s, 24.4551s/100 iter), loss = 0.0652974
I0702 23:10:02.779676 13779 solver.cpp:309]     Train net output #0: loss = 0.0652973 (* 1 = 0.0652973 loss)
I0702 23:10:02.779686 13779 sgd_solver.cpp:106] Iteration 1400, lr = 0.0001
I0702 23:10:27.316624 13779 solver.cpp:290] Iteration 1500 (4.0756 iter/s, 24.5363s/100 iter), loss = 0.0771398
I0702 23:10:27.316649 13779 solver.cpp:309]     Train net output #0: loss = 0.0771397 (* 1 = 0.0771397 loss)
I0702 23:10:27.316656 13779 sgd_solver.cpp:106] Iteration 1500, lr = 0.0001
I0702 23:10:51.807673 13779 solver.cpp:290] Iteration 1600 (4.08324 iter/s, 24.4904s/100 iter), loss = 0.0556691
I0702 23:10:51.807749 13779 solver.cpp:309]     Train net output #0: loss = 0.055669 (* 1 = 0.055669 loss)
I0702 23:10:51.807761 13779 sgd_solver.cpp:106] Iteration 1600, lr = 0.0001
I0702 23:11:16.288795 13779 solver.cpp:290] Iteration 1700 (4.0849 iter/s, 24.4804s/100 iter), loss = 0.0555077
I0702 23:11:16.288817 13779 solver.cpp:309]     Train net output #0: loss = 0.0555077 (* 1 = 0.0555077 loss)
I0702 23:11:16.288825 13779 sgd_solver.cpp:106] Iteration 1700, lr = 0.0001
I0702 23:11:40.745383 13779 solver.cpp:290] Iteration 1800 (4.08899 iter/s, 24.4559s/100 iter), loss = 0.0703586
I0702 23:11:40.745493 13779 solver.cpp:309]     Train net output #0: loss = 0.0703586 (* 1 = 0.0703586 loss)
I0702 23:11:40.745503 13779 sgd_solver.cpp:106] Iteration 1800, lr = 0.0001
I0702 23:12:05.293540 13779 solver.cpp:290] Iteration 1900 (4.07375 iter/s, 24.5474s/100 iter), loss = 0.0579196
I0702 23:12:05.293561 13779 solver.cpp:309]     Train net output #0: loss = 0.0579196 (* 1 = 0.0579196 loss)
I0702 23:12:05.293570 13779 sgd_solver.cpp:106] Iteration 1900, lr = 0.0001
I0702 23:12:29.500013 13779 solver.cpp:473] Iteration 2000, Testing net (#0)
I0702 23:13:17.071158 13779 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.940226
I0702 23:13:17.072762 13779 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.999967
I0702 23:13:17.072772 13779 solver.cpp:546]     Test net output #2: loss = 0.100519 (* 1 = 0.100519 loss)
I0702 23:13:17.333117 13779 solver.cpp:290] Iteration 2000 (1.38816 iter/s, 72.0376s/100 iter), loss = 0.0535656
I0702 23:13:17.333140 13779 solver.cpp:309]     Train net output #0: loss = 0.0535656 (* 1 = 0.0535656 loss)
I0702 23:13:17.333148 13779 sgd_solver.cpp:106] Iteration 2000, lr = 0.0001
I0702 23:13:48.621125 13815 blocking_queue.cpp:50] Waiting for data
I0702 23:14:08.732981 13779 solver.cpp:290] Iteration 2100 (1.94558 iter/s, 51.3985s/100 iter), loss = 0.0642405
I0702 23:14:08.733011 13779 solver.cpp:309]     Train net output #0: loss = 0.0642405 (* 1 = 0.0642405 loss)
I0702 23:14:08.733021 13779 sgd_solver.cpp:106] Iteration 2100, lr = 0.0001
I0702 23:14:41.051951 13815 blocking_queue.cpp:50] Waiting for data
I0702 23:15:19.806202 13779 solver.cpp:290] Iteration 2200 (1.40704 iter/s, 71.0713s/100 iter), loss = 0.0406064
I0702 23:15:19.806258 13779 solver.cpp:309]     Train net output #0: loss = 0.0406064 (* 1 = 0.0406064 loss)
I0702 23:15:19.806267 13779 sgd_solver.cpp:106] Iteration 2200, lr = 0.0001
I0702 23:15:25.845926 13840 blocking_queue.cpp:50] Waiting for data
I0702 23:15:48.533037 13779 solver.cpp:290] Iteration 2300 (3.48117 iter/s, 28.726s/100 iter), loss = 0.0320029
I0702 23:15:48.533061 13779 solver.cpp:309]     Train net output #0: loss = 0.0320029 (* 1 = 0.0320029 loss)
I0702 23:15:48.533071 13779 sgd_solver.cpp:106] Iteration 2300, lr = 0.0001
I0702 23:16:12.623971 13779 solver.cpp:290] Iteration 2400 (4.15105 iter/s, 24.0903s/100 iter), loss = 0.0533104
I0702 23:16:12.624075 13779 solver.cpp:309]     Train net output #0: loss = 0.0533103 (* 1 = 0.0533103 loss)
I0702 23:16:12.624085 13779 sgd_solver.cpp:106] Iteration 2400, lr = 0.0001
I0702 23:16:36.787916 13779 solver.cpp:290] Iteration 2500 (4.13853 iter/s, 24.1632s/100 iter), loss = 0.0906536
I0702 23:16:36.787941 13779 solver.cpp:309]     Train net output #0: loss = 0.0906536 (* 1 = 0.0906536 loss)
I0702 23:16:36.787950 13779 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0702 23:17:00.920524 13779 solver.cpp:290] Iteration 2600 (4.14389 iter/s, 24.1319s/100 iter), loss = 0.0656374
I0702 23:17:00.920626 13779 solver.cpp:309]     Train net output #0: loss = 0.0656374 (* 1 = 0.0656374 loss)
I0702 23:17:00.920637 13779 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0702 23:17:25.088104 13779 solver.cpp:290] Iteration 2700 (4.1379 iter/s, 24.1668s/100 iter), loss = 0.038099
I0702 23:17:25.088127 13779 solver.cpp:309]     Train net output #0: loss = 0.038099 (* 1 = 0.038099 loss)
I0702 23:17:25.088135 13779 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0702 23:17:49.238930 13779 solver.cpp:290] Iteration 2800 (4.14076 iter/s, 24.1502s/100 iter), loss = 0.089529
I0702 23:17:49.239040 13779 solver.cpp:309]     Train net output #0: loss = 0.089529 (* 1 = 0.089529 loss)
I0702 23:17:49.239050 13779 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0702 23:18:13.389513 13779 solver.cpp:290] Iteration 2900 (4.14082 iter/s, 24.1498s/100 iter), loss = 0.0538159
I0702 23:18:13.389539 13779 solver.cpp:309]     Train net output #0: loss = 0.0538159 (* 1 = 0.0538159 loss)
I0702 23:18:13.389545 13779 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0702 23:18:37.538589 13779 solver.cpp:290] Iteration 3000 (4.14106 iter/s, 24.1484s/100 iter), loss = 0.0712822
I0702 23:18:37.538700 13779 solver.cpp:309]     Train net output #0: loss = 0.0712822 (* 1 = 0.0712822 loss)
I0702 23:18:37.538710 13779 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0702 23:19:01.660603 13779 solver.cpp:290] Iteration 3100 (4.14572 iter/s, 24.1213s/100 iter), loss = 0.0577893
I0702 23:19:01.660624 13779 solver.cpp:309]     Train net output #0: loss = 0.0577893 (* 1 = 0.0577893 loss)
I0702 23:19:01.660632 13779 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0702 23:19:25.817291 13779 solver.cpp:290] Iteration 3200 (4.13975 iter/s, 24.156s/100 iter), loss = 0.0364773
I0702 23:19:25.817414 13779 solver.cpp:309]     Train net output #0: loss = 0.0364774 (* 1 = 0.0364774 loss)
I0702 23:19:25.817423 13779 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0702 23:19:49.919956 13779 solver.cpp:290] Iteration 3300 (4.14905 iter/s, 24.1019s/100 iter), loss = 0.145375
I0702 23:19:49.919978 13779 solver.cpp:309]     Train net output #0: loss = 0.145375 (* 1 = 0.145375 loss)
I0702 23:19:49.919986 13779 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0702 23:20:14.035094 13779 solver.cpp:290] Iteration 3400 (4.14689 iter/s, 24.1145s/100 iter), loss = 0.0460306
I0702 23:20:14.035195 13779 solver.cpp:309]     Train net output #0: loss = 0.0460306 (* 1 = 0.0460306 loss)
I0702 23:20:14.035205 13779 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0702 23:20:38.201944 13779 solver.cpp:290] Iteration 3500 (4.13803 iter/s, 24.1661s/100 iter), loss = 0.0635301
I0702 23:20:38.201967 13779 solver.cpp:309]     Train net output #0: loss = 0.0635301 (* 1 = 0.0635301 loss)
I0702 23:20:38.201975 13779 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0702 23:21:02.311497 13779 solver.cpp:290] Iteration 3600 (4.14785 iter/s, 24.1089s/100 iter), loss = 0.122967
I0702 23:21:02.311609 13779 solver.cpp:309]     Train net output #0: loss = 0.122967 (* 1 = 0.122967 loss)
I0702 23:21:02.311619 13779 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0702 23:21:26.444140 13779 solver.cpp:290] Iteration 3700 (4.14389 iter/s, 24.1319s/100 iter), loss = 0.0399725
I0702 23:21:26.444164 13779 solver.cpp:309]     Train net output #0: loss = 0.0399725 (* 1 = 0.0399725 loss)
I0702 23:21:26.444171 13779 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0702 23:21:50.571995 13779 solver.cpp:290] Iteration 3800 (4.1447 iter/s, 24.1272s/100 iter), loss = 0.054645
I0702 23:21:50.572109 13779 solver.cpp:309]     Train net output #0: loss = 0.054645 (* 1 = 0.054645 loss)
I0702 23:21:50.572120 13779 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0702 23:22:14.685928 13779 solver.cpp:290] Iteration 3900 (4.14711 iter/s, 24.1132s/100 iter), loss = 0.0306287
I0702 23:22:14.685951 13779 solver.cpp:309]     Train net output #0: loss = 0.0306287 (* 1 = 0.0306287 loss)
I0702 23:22:14.685958 13779 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0702 23:22:38.614172 13779 solver.cpp:473] Iteration 4000, Testing net (#0)
I0702 23:23:26.106452 13779 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.943062
I0702 23:23:26.106536 13779 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.999989
I0702 23:23:26.106544 13779 solver.cpp:546]     Test net output #2: loss = 0.104184 (* 1 = 0.104184 loss)
I0702 23:23:26.360438 13779 solver.cpp:290] Iteration 4000 (1.39523 iter/s, 71.6726s/100 iter), loss = 0.0475856
I0702 23:23:26.360463 13779 solver.cpp:309]     Train net output #0: loss = 0.0475857 (* 1 = 0.0475857 loss)
I0702 23:23:26.360471 13779 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0702 23:23:49.864450 13779 solver.cpp:290] Iteration 4100 (4.25471 iter/s, 23.5034s/100 iter), loss = 0.0656268
I0702 23:23:49.864476 13779 solver.cpp:309]     Train net output #0: loss = 0.0656269 (* 1 = 0.0656269 loss)
I0702 23:23:49.864483 13779 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0702 23:24:34.009748 13815 blocking_queue.cpp:50] Waiting for data
I0702 23:24:44.424557 13779 solver.cpp:290] Iteration 4200 (1.83289 iter/s, 54.5586s/100 iter), loss = 0.0583775
I0702 23:24:44.424584 13779 solver.cpp:309]     Train net output #0: loss = 0.0583776 (* 1 = 0.0583776 loss)
I0702 23:24:44.424592 13779 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0702 23:25:08.567893 13779 solver.cpp:290] Iteration 4300 (4.14205 iter/s, 24.1427s/100 iter), loss = 0.0717098
I0702 23:25:08.568022 13779 solver.cpp:309]     Train net output #0: loss = 0.0717099 (* 1 = 0.0717099 loss)
I0702 23:25:08.568032 13779 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0702 23:25:32.771695 13779 solver.cpp:290] Iteration 4400 (4.13171 iter/s, 24.203s/100 iter), loss = 0.0704586
I0702 23:25:32.771719 13779 solver.cpp:309]     Train net output #0: loss = 0.0704587 (* 1 = 0.0704587 loss)
I0702 23:25:32.771728 13779 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0702 23:25:56.963681 13779 solver.cpp:290] Iteration 4500 (4.13371 iter/s, 24.1913s/100 iter), loss = 0.0605963
I0702 23:25:56.963734 13779 solver.cpp:309]     Train net output #0: loss = 0.0605963 (* 1 = 0.0605963 loss)
I0702 23:25:56.963745 13779 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0702 23:26:21.103955 13779 solver.cpp:290] Iteration 4600 (4.14257 iter/s, 24.1396s/100 iter), loss = 0.0364135
I0702 23:26:21.103978 13779 solver.cpp:309]     Train net output #0: loss = 0.0364135 (* 1 = 0.0364135 loss)
I0702 23:26:21.103986 13779 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0702 23:26:45.292218 13779 solver.cpp:290] Iteration 4700 (4.13435 iter/s, 24.1876s/100 iter), loss = 0.0435726
I0702 23:26:45.292349 13779 solver.cpp:309]     Train net output #0: loss = 0.0435726 (* 1 = 0.0435726 loss)
I0702 23:26:45.292364 13779 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0702 23:27:09.479082 13779 solver.cpp:290] Iteration 4800 (4.13461 iter/s, 24.1861s/100 iter), loss = 0.0533334
I0702 23:27:09.479109 13779 solver.cpp:309]     Train net output #0: loss = 0.0533333 (* 1 = 0.0533333 loss)
I0702 23:27:09.479115 13779 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0702 23:27:33.644706 13779 solver.cpp:290] Iteration 4900 (4.13822 iter/s, 24.165s/100 iter), loss = 0.0472902
I0702 23:27:33.644815 13779 solver.cpp:309]     Train net output #0: loss = 0.0472902 (* 1 = 0.0472902 loss)
I0702 23:27:33.644830 13779 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0702 23:27:57.845963 13779 solver.cpp:290] Iteration 5000 (4.13214 iter/s, 24.2005s/100 iter), loss = 0.0468225
I0702 23:27:57.845986 13779 solver.cpp:309]     Train net output #0: loss = 0.0468225 (* 1 = 0.0468225 loss)
I0702 23:27:57.845994 13779 sgd_solver.cpp:106] Iteration 5000, lr = 0.0001
I0702 23:28:22.003594 13779 solver.cpp:290] Iteration 5100 (4.13959 iter/s, 24.157s/100 iter), loss = 0.0397288
I0702 23:28:22.003690 13779 solver.cpp:309]     Train net output #0: loss = 0.0397288 (* 1 = 0.0397288 loss)
I0702 23:28:22.003705 13779 sgd_solver.cpp:106] Iteration 5100, lr = 0.0001
I0702 23:28:46.205267 13779 solver.cpp:290] Iteration 5200 (4.13207 iter/s, 24.2009s/100 iter), loss = 0.0421866
I0702 23:28:46.205291 13779 solver.cpp:309]     Train net output #0: loss = 0.0421866 (* 1 = 0.0421866 loss)
I0702 23:28:46.205298 13779 sgd_solver.cpp:106] Iteration 5200, lr = 0.0001
I0702 23:29:10.404304 13779 solver.cpp:290] Iteration 5300 (4.13251 iter/s, 24.1984s/100 iter), loss = 0.0547123
I0702 23:29:10.404415 13779 solver.cpp:309]     Train net output #0: loss = 0.0547123 (* 1 = 0.0547123 loss)
I0702 23:29:10.404429 13779 sgd_solver.cpp:106] Iteration 5300, lr = 0.0001
I0702 23:29:34.580229 13779 solver.cpp:290] Iteration 5400 (4.13647 iter/s, 24.1752s/100 iter), loss = 0.0548556
I0702 23:29:34.580252 13779 solver.cpp:309]     Train net output #0: loss = 0.0548555 (* 1 = 0.0548555 loss)
I0702 23:29:34.580260 13779 sgd_solver.cpp:106] Iteration 5400, lr = 0.0001
I0702 23:29:58.717377 13779 solver.cpp:290] Iteration 5500 (4.14311 iter/s, 24.1365s/100 iter), loss = 0.0436614
I0702 23:29:58.717494 13779 solver.cpp:309]     Train net output #0: loss = 0.0436614 (* 1 = 0.0436614 loss)
I0702 23:29:58.717505 13779 sgd_solver.cpp:106] Iteration 5500, lr = 0.0001
I0702 23:30:22.881502 13779 solver.cpp:290] Iteration 5600 (4.13849 iter/s, 24.1634s/100 iter), loss = 0.047574
I0702 23:30:22.881526 13779 solver.cpp:309]     Train net output #0: loss = 0.0475739 (* 1 = 0.0475739 loss)
I0702 23:30:22.881533 13779 sgd_solver.cpp:106] Iteration 5600, lr = 0.0001
I0702 23:30:47.064916 13779 solver.cpp:290] Iteration 5700 (4.13518 iter/s, 24.1828s/100 iter), loss = 0.0563022
I0702 23:30:47.065011 13779 solver.cpp:309]     Train net output #0: loss = 0.0563022 (* 1 = 0.0563022 loss)
I0702 23:30:47.065024 13779 sgd_solver.cpp:106] Iteration 5700, lr = 0.0001
I0702 23:31:11.233201 13779 solver.cpp:290] Iteration 5800 (4.13778 iter/s, 24.1676s/100 iter), loss = 0.181538
I0702 23:31:11.233224 13779 solver.cpp:309]     Train net output #0: loss = 0.181538 (* 1 = 0.181538 loss)
I0702 23:31:11.233232 13779 sgd_solver.cpp:106] Iteration 5800, lr = 0.0001
I0702 23:31:35.430907 13779 solver.cpp:290] Iteration 5900 (4.13274 iter/s, 24.197s/100 iter), loss = 0.041485
I0702 23:31:35.430961 13779 solver.cpp:309]     Train net output #0: loss = 0.0414849 (* 1 = 0.0414849 loss)
I0702 23:31:35.430970 13779 sgd_solver.cpp:106] Iteration 5900, lr = 0.0001
I0702 23:31:59.371944 13779 solver.cpp:473] Iteration 6000, Testing net (#0)
I0702 23:32:46.702782 13779 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.945313
I0702 23:32:46.702870 13779 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.999513
I0702 23:32:46.702878 13779 solver.cpp:546]     Test net output #2: loss = 0.146017 (* 1 = 0.146017 loss)
I0702 23:32:46.950688 13779 solver.cpp:290] Iteration 6000 (1.39825 iter/s, 71.5179s/100 iter), loss = 0.0521701
I0702 23:32:46.950713 13779 solver.cpp:309]     Train net output #0: loss = 0.0521701 (* 1 = 0.0521701 loss)
I0702 23:32:46.950721 13779 sgd_solver.cpp:106] Iteration 6000, lr = 0.0001
I0702 23:33:10.415491 13779 solver.cpp:290] Iteration 6100 (4.26182 iter/s, 23.4642s/100 iter), loss = 0.0467612
I0702 23:33:10.415515 13779 solver.cpp:309]     Train net output #0: loss = 0.0467612 (* 1 = 0.0467612 loss)
I0702 23:33:10.415524 13779 sgd_solver.cpp:106] Iteration 6100, lr = 0.0001
I0702 23:33:43.641671 13779 solver.cpp:290] Iteration 6200 (3.00976 iter/s, 33.2253s/100 iter), loss = 0.0750015
I0702 23:33:43.641942 13779 solver.cpp:309]     Train net output #0: loss = 0.0750015 (* 1 = 0.0750015 loss)
I0702 23:33:43.641953 13779 sgd_solver.cpp:106] Iteration 6200, lr = 0.0001
I0702 23:34:07.774092 13779 solver.cpp:290] Iteration 6300 (4.14396 iter/s, 24.1315s/100 iter), loss = 0.046345
I0702 23:34:07.774114 13779 solver.cpp:309]     Train net output #0: loss = 0.046345 (* 1 = 0.046345 loss)
I0702 23:34:07.774122 13779 sgd_solver.cpp:106] Iteration 6300, lr = 0.0001
I0702 23:34:31.944403 13779 solver.cpp:290] Iteration 6400 (4.13742 iter/s, 24.1696s/100 iter), loss = 0.119092
I0702 23:34:31.944454 13779 solver.cpp:309]     Train net output #0: loss = 0.119092 (* 1 = 0.119092 loss)
I0702 23:34:31.944463 13779 sgd_solver.cpp:106] Iteration 6400, lr = 0.0001
I0702 23:34:56.150727 13779 solver.cpp:290] Iteration 6500 (4.13127 iter/s, 24.2056s/100 iter), loss = 0.0401036
I0702 23:34:56.150751 13779 solver.cpp:309]     Train net output #0: loss = 0.0401036 (* 1 = 0.0401036 loss)
I0702 23:34:56.150758 13779 sgd_solver.cpp:106] Iteration 6500, lr = 0.0001
I0702 23:35:20.286473 13779 solver.cpp:290] Iteration 6600 (4.14335 iter/s, 24.1351s/100 iter), loss = 0.0371597
I0702 23:35:20.286556 13779 solver.cpp:309]     Train net output #0: loss = 0.0371597 (* 1 = 0.0371597 loss)
I0702 23:35:20.286566 13779 sgd_solver.cpp:106] Iteration 6600, lr = 0.0001
I0702 23:35:44.415343 13779 solver.cpp:290] Iteration 6700 (4.14454 iter/s, 24.1282s/100 iter), loss = 0.130172
I0702 23:35:44.415366 13779 solver.cpp:309]     Train net output #0: loss = 0.130172 (* 1 = 0.130172 loss)
I0702 23:35:44.415374 13779 sgd_solver.cpp:106] Iteration 6700, lr = 0.0001
I0702 23:36:08.596772 13779 solver.cpp:290] Iteration 6800 (4.13552 iter/s, 24.1808s/100 iter), loss = 0.0313324
I0702 23:36:08.596823 13779 solver.cpp:309]     Train net output #0: loss = 0.0313324 (* 1 = 0.0313324 loss)
I0702 23:36:08.596832 13779 sgd_solver.cpp:106] Iteration 6800, lr = 0.0001
I0702 23:36:32.771428 13779 solver.cpp:290] Iteration 6900 (4.13668 iter/s, 24.174s/100 iter), loss = 0.0406241
I0702 23:36:32.771455 13779 solver.cpp:309]     Train net output #0: loss = 0.040624 (* 1 = 0.040624 loss)
I0702 23:36:32.771461 13779 sgd_solver.cpp:106] Iteration 6900, lr = 0.0001
I0702 23:36:56.960052 13779 solver.cpp:290] Iteration 7000 (4.13429 iter/s, 24.188s/100 iter), loss = 0.0438908
I0702 23:36:56.960170 13779 solver.cpp:309]     Train net output #0: loss = 0.0438908 (* 1 = 0.0438908 loss)
I0702 23:36:56.960180 13779 sgd_solver.cpp:106] Iteration 7000, lr = 0.0001
I0702 23:37:21.111639 13779 solver.cpp:290] Iteration 7100 (4.14064 iter/s, 24.1508s/100 iter), loss = 0.127329
I0702 23:37:21.111660 13779 solver.cpp:309]     Train net output #0: loss = 0.127329 (* 1 = 0.127329 loss)
I0702 23:37:21.111667 13779 sgd_solver.cpp:106] Iteration 7100, lr = 0.0001
I0702 23:37:45.280558 13779 solver.cpp:290] Iteration 7200 (4.13766 iter/s, 24.1683s/100 iter), loss = 0.039989
I0702 23:37:45.280675 13779 solver.cpp:309]     Train net output #0: loss = 0.039989 (* 1 = 0.039989 loss)
I0702 23:37:45.280685 13779 sgd_solver.cpp:106] Iteration 7200, lr = 0.0001
I0702 23:38:09.422340 13779 solver.cpp:290] Iteration 7300 (4.14232 iter/s, 24.141s/100 iter), loss = 0.0392657
I0702 23:38:09.422365 13779 solver.cpp:309]     Train net output #0: loss = 0.0392657 (* 1 = 0.0392657 loss)
I0702 23:38:09.422372 13779 sgd_solver.cpp:106] Iteration 7300, lr = 0.0001
I0702 23:38:33.599251 13779 solver.cpp:290] Iteration 7400 (4.13629 iter/s, 24.1763s/100 iter), loss = 0.0326937
I0702 23:38:33.599361 13779 solver.cpp:309]     Train net output #0: loss = 0.0326937 (* 1 = 0.0326937 loss)
I0702 23:38:33.599372 13779 sgd_solver.cpp:106] Iteration 7400, lr = 0.0001
I0702 23:38:57.766278 13779 solver.cpp:290] Iteration 7500 (4.138 iter/s, 24.1663s/100 iter), loss = 0.0541119
I0702 23:38:57.766302 13779 solver.cpp:309]     Train net output #0: loss = 0.0541118 (* 1 = 0.0541118 loss)
I0702 23:38:57.766310 13779 sgd_solver.cpp:106] Iteration 7500, lr = 0.0001
I0702 23:39:21.939450 13779 solver.cpp:290] Iteration 7600 (4.13693 iter/s, 24.1725s/100 iter), loss = 0.0249413
I0702 23:39:21.939563 13779 solver.cpp:309]     Train net output #0: loss = 0.0249413 (* 1 = 0.0249413 loss)
I0702 23:39:21.939574 13779 sgd_solver.cpp:106] Iteration 7600, lr = 0.0001
I0702 23:39:46.146004 13779 solver.cpp:290] Iteration 7700 (4.13124 iter/s, 24.2058s/100 iter), loss = 0.0442923
I0702 23:39:46.146028 13779 solver.cpp:309]     Train net output #0: loss = 0.0442923 (* 1 = 0.0442923 loss)
I0702 23:39:46.146036 13779 sgd_solver.cpp:106] Iteration 7700, lr = 0.0001
I0702 23:40:10.292623 13779 solver.cpp:290] Iteration 7800 (4.14148 iter/s, 24.146s/100 iter), loss = 0.0432903
I0702 23:40:10.292724 13779 solver.cpp:309]     Train net output #0: loss = 0.0432902 (* 1 = 0.0432902 loss)
I0702 23:40:10.292734 13779 sgd_solver.cpp:106] Iteration 7800, lr = 0.0001
I0702 23:40:34.430179 13779 solver.cpp:290] Iteration 7900 (4.14305 iter/s, 24.1368s/100 iter), loss = 0.0395089
I0702 23:40:34.430208 13779 solver.cpp:309]     Train net output #0: loss = 0.0395088 (* 1 = 0.0395088 loss)
I0702 23:40:34.430218 13779 sgd_solver.cpp:106] Iteration 7900, lr = 0.0001
I0702 23:40:58.344388 13779 solver.cpp:473] Iteration 8000, Testing net (#0)
I0702 23:41:45.310365 13779 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.950123
I0702 23:41:45.310526 13779 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.99978
I0702 23:41:45.310539 13779 solver.cpp:546]     Test net output #2: loss = 0.115558 (* 1 = 0.115558 loss)
I0702 23:41:45.561110 13779 solver.cpp:290] Iteration 8000 (1.4059 iter/s, 71.129s/100 iter), loss = 0.0322065
I0702 23:41:45.561133 13779 solver.cpp:309]     Train net output #0: loss = 0.0322065 (* 1 = 0.0322065 loss)
I0702 23:41:45.561141 13779 sgd_solver.cpp:106] Iteration 8000, lr = 0.0001
I0702 23:42:09.056849 13779 solver.cpp:290] Iteration 8100 (4.25621 iter/s, 23.4951s/100 iter), loss = 0.0243085
I0702 23:42:09.056872 13779 solver.cpp:309]     Train net output #0: loss = 0.0243084 (* 1 = 0.0243084 loss)
I0702 23:42:09.056879 13779 sgd_solver.cpp:106] Iteration 8100, lr = 0.0001
I0702 23:42:33.199275 13779 solver.cpp:290] Iteration 8200 (4.1422 iter/s, 24.1418s/100 iter), loss = 0.0330328
I0702 23:42:33.199403 13779 solver.cpp:309]     Train net output #0: loss = 0.0330327 (* 1 = 0.0330327 loss)
I0702 23:42:33.199414 13779 sgd_solver.cpp:106] Iteration 8200, lr = 0.0001
I0702 23:42:57.379966 13779 solver.cpp:290] Iteration 8300 (4.13566 iter/s, 24.1799s/100 iter), loss = 0.0312198
I0702 23:42:57.379989 13779 solver.cpp:309]     Train net output #0: loss = 0.0312198 (* 1 = 0.0312198 loss)
I0702 23:42:57.379997 13779 sgd_solver.cpp:106] Iteration 8300, lr = 0.0001
I0702 23:43:21.543992 13779 solver.cpp:290] Iteration 8400 (4.1385 iter/s, 24.1634s/100 iter), loss = 0.0321853
I0702 23:43:21.544087 13779 solver.cpp:309]     Train net output #0: loss = 0.0321853 (* 1 = 0.0321853 loss)
I0702 23:43:21.544098 13779 sgd_solver.cpp:106] Iteration 8400, lr = 0.0001
I0702 23:43:45.720531 13779 solver.cpp:290] Iteration 8500 (4.13637 iter/s, 24.1758s/100 iter), loss = 0.0243596
I0702 23:43:45.720553 13779 solver.cpp:309]     Train net output #0: loss = 0.0243596 (* 1 = 0.0243596 loss)
I0702 23:43:45.720561 13779 sgd_solver.cpp:106] Iteration 8500, lr = 0.0001
I0702 23:44:09.862990 13779 solver.cpp:290] Iteration 8600 (4.14219 iter/s, 24.1418s/100 iter), loss = 0.0541097
I0702 23:44:09.863093 13779 solver.cpp:309]     Train net output #0: loss = 0.0541097 (* 1 = 0.0541097 loss)
I0702 23:44:09.863103 13779 sgd_solver.cpp:106] Iteration 8600, lr = 0.0001
I0702 23:44:34.008254 13779 solver.cpp:290] Iteration 8700 (4.14173 iter/s, 24.1445s/100 iter), loss = 0.0372143
I0702 23:44:34.008277 13779 solver.cpp:309]     Train net output #0: loss = 0.0372142 (* 1 = 0.0372142 loss)
I0702 23:44:34.008285 13779 sgd_solver.cpp:106] Iteration 8700, lr = 0.0001
I0702 23:44:58.157186 13779 solver.cpp:290] Iteration 8800 (4.14108 iter/s, 24.1483s/100 iter), loss = 0.0421834
I0702 23:44:58.157300 13779 solver.cpp:309]     Train net output #0: loss = 0.0421834 (* 1 = 0.0421834 loss)
I0702 23:44:58.157310 13779 sgd_solver.cpp:106] Iteration 8800, lr = 0.0001
I0702 23:45:22.345590 13779 solver.cpp:290] Iteration 8900 (4.13434 iter/s, 24.1877s/100 iter), loss = 0.0486177
I0702 23:45:22.345615 13779 solver.cpp:309]     Train net output #0: loss = 0.0486177 (* 1 = 0.0486177 loss)
I0702 23:45:22.345623 13779 sgd_solver.cpp:106] Iteration 8900, lr = 0.0001
I0702 23:45:46.537865 13779 solver.cpp:290] Iteration 9000 (4.13366 iter/s, 24.1916s/100 iter), loss = 0.0286085
I0702 23:45:46.537978 13779 solver.cpp:309]     Train net output #0: loss = 0.0286085 (* 1 = 0.0286085 loss)
I0702 23:45:46.537992 13779 sgd_solver.cpp:106] Iteration 9000, lr = 0.0001
I0702 23:46:10.699127 13779 solver.cpp:290] Iteration 9100 (4.13898 iter/s, 24.1605s/100 iter), loss = 0.0296295
I0702 23:46:10.699149 13779 solver.cpp:309]     Train net output #0: loss = 0.0296295 (* 1 = 0.0296295 loss)
I0702 23:46:10.699156 13779 sgd_solver.cpp:106] Iteration 9100, lr = 0.0001
I0702 23:46:34.866216 13779 solver.cpp:290] Iteration 9200 (4.13797 iter/s, 24.1664s/100 iter), loss = 0.026876
I0702 23:46:34.866323 13779 solver.cpp:309]     Train net output #0: loss = 0.0268759 (* 1 = 0.0268759 loss)
I0702 23:46:34.866333 13779 sgd_solver.cpp:106] Iteration 9200, lr = 0.0001
I0702 23:46:59.038342 13779 solver.cpp:290] Iteration 9300 (4.13712 iter/s, 24.1714s/100 iter), loss = 0.0392999
I0702 23:46:59.038365 13779 solver.cpp:309]     Train net output #0: loss = 0.0392998 (* 1 = 0.0392998 loss)
I0702 23:46:59.038373 13779 sgd_solver.cpp:106] Iteration 9300, lr = 0.0001
I0702 23:47:23.205626 13779 solver.cpp:290] Iteration 9400 (4.13794 iter/s, 24.1666s/100 iter), loss = 0.0461395
I0702 23:47:23.205734 13779 solver.cpp:309]     Train net output #0: loss = 0.0461395 (* 1 = 0.0461395 loss)
I0702 23:47:23.205744 13779 sgd_solver.cpp:106] Iteration 9400, lr = 0.0001
I0702 23:47:47.404332 13779 solver.cpp:290] Iteration 9500 (4.13258 iter/s, 24.198s/100 iter), loss = 0.0318986
I0702 23:47:47.404356 13779 solver.cpp:309]     Train net output #0: loss = 0.0318985 (* 1 = 0.0318985 loss)
I0702 23:47:47.404362 13779 sgd_solver.cpp:106] Iteration 9500, lr = 0.0001
I0702 23:48:11.553963 13779 solver.cpp:290] Iteration 9600 (4.14096 iter/s, 24.149s/100 iter), loss = 0.0481308
I0702 23:48:11.554097 13779 solver.cpp:309]     Train net output #0: loss = 0.0481308 (* 1 = 0.0481308 loss)
I0702 23:48:11.554107 13779 sgd_solver.cpp:106] Iteration 9600, lr = 0.0001
I0702 23:48:35.724839 13779 solver.cpp:290] Iteration 9700 (4.13734 iter/s, 24.1701s/100 iter), loss = 0.0276291
I0702 23:48:35.724864 13779 solver.cpp:309]     Train net output #0: loss = 0.027629 (* 1 = 0.027629 loss)
I0702 23:48:35.724874 13779 sgd_solver.cpp:106] Iteration 9700, lr = 0.0001
I0702 23:48:59.899077 13779 solver.cpp:290] Iteration 9800 (4.13675 iter/s, 24.1736s/100 iter), loss = 0.0448184
I0702 23:48:59.899183 13779 solver.cpp:309]     Train net output #0: loss = 0.0448184 (* 1 = 0.0448184 loss)
I0702 23:48:59.899194 13779 sgd_solver.cpp:106] Iteration 9800, lr = 0.0001
I0702 23:49:24.082242 13779 solver.cpp:290] Iteration 9900 (4.13523 iter/s, 24.1824s/100 iter), loss = 0.0520499
I0702 23:49:24.082265 13779 solver.cpp:309]     Train net output #0: loss = 0.0520499 (* 1 = 0.0520499 loss)
I0702 23:49:24.082273 13779 sgd_solver.cpp:106] Iteration 9900, lr = 0.0001
I0702 23:49:48.043668 13779 solver.cpp:600] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-07-02_23-02-42/initial/cityscapes5_jsegnet21v2_iter_10000.caffemodel
I0702 23:49:48.173094 13779 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-07-02_23-02-42/initial/cityscapes5_jsegnet21v2_iter_10000.solverstate
I0702 23:49:48.190333 13779 solver.cpp:473] Iteration 10000, Testing net (#0)
I0702 23:50:35.296077 13779 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.947628
I0702 23:50:35.296162 13779 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.999722
I0702 23:50:35.296172 13779 solver.cpp:546]     Test net output #2: loss = 0.136167 (* 1 = 0.136167 loss)
I0702 23:50:35.552404 13779 solver.cpp:290] Iteration 10000 (1.39922 iter/s, 71.4683s/100 iter), loss = 0.0255164
I0702 23:50:35.552428 13779 solver.cpp:309]     Train net output #0: loss = 0.0255164 (* 1 = 0.0255164 loss)
I0702 23:50:35.552435 13779 sgd_solver.cpp:106] Iteration 10000, lr = 0.0001
I0702 23:50:59.726033 13779 solver.cpp:290] Iteration 10100 (4.13685 iter/s, 24.173s/100 iter), loss = 0.0330942
I0702 23:50:59.726058 13779 solver.cpp:309]     Train net output #0: loss = 0.0330942 (* 1 = 0.0330942 loss)
I0702 23:50:59.726065 13779 sgd_solver.cpp:106] Iteration 10100, lr = 0.0001
I0702 23:51:23.834576 13779 solver.cpp:290] Iteration 10200 (4.14802 iter/s, 24.1079s/100 iter), loss = 0.0256059
I0702 23:51:23.834677 13779 solver.cpp:309]     Train net output #0: loss = 0.0256059 (* 1 = 0.0256059 loss)
I0702 23:51:23.834687 13779 sgd_solver.cpp:106] Iteration 10200, lr = 0.0001
I0702 23:51:48.014266 13779 solver.cpp:290] Iteration 10300 (4.13583 iter/s, 24.179s/100 iter), loss = 0.111669
I0702 23:51:48.014295 13779 solver.cpp:309]     Train net output #0: loss = 0.111669 (* 1 = 0.111669 loss)
I0702 23:51:48.014302 13779 sgd_solver.cpp:106] Iteration 10300, lr = 0.0001
I0702 23:52:12.207329 13779 solver.cpp:290] Iteration 10400 (4.13353 iter/s, 24.1924s/100 iter), loss = 0.0322882
I0702 23:52:12.207437 13779 solver.cpp:309]     Train net output #0: loss = 0.0322881 (* 1 = 0.0322881 loss)
I0702 23:52:12.207448 13779 sgd_solver.cpp:106] Iteration 10400, lr = 0.0001
I0702 23:52:36.419632 13779 solver.cpp:290] Iteration 10500 (4.13026 iter/s, 24.2116s/100 iter), loss = 0.038472
I0702 23:52:36.419658 13779 solver.cpp:309]     Train net output #0: loss = 0.038472 (* 1 = 0.038472 loss)
I0702 23:52:36.419665 13779 sgd_solver.cpp:106] Iteration 10500, lr = 0.0001
I0702 23:53:00.585813 13779 solver.cpp:290] Iteration 10600 (4.13813 iter/s, 24.1655s/100 iter), loss = 0.0482803
I0702 23:53:00.585928 13779 solver.cpp:309]     Train net output #0: loss = 0.0482802 (* 1 = 0.0482802 loss)
I0702 23:53:00.585939 13779 sgd_solver.cpp:106] Iteration 10600, lr = 0.0001
I0702 23:53:24.761651 13779 solver.cpp:290] Iteration 10700 (4.13649 iter/s, 24.1751s/100 iter), loss = 0.0469127
I0702 23:53:24.761675 13779 solver.cpp:309]     Train net output #0: loss = 0.0469126 (* 1 = 0.0469126 loss)
I0702 23:53:24.761682 13779 sgd_solver.cpp:106] Iteration 10700, lr = 0.0001
I0702 23:53:48.912576 13779 solver.cpp:290] Iteration 10800 (4.14074 iter/s, 24.1503s/100 iter), loss = 0.0305312
I0702 23:53:48.912708 13779 solver.cpp:309]     Train net output #0: loss = 0.0305312 (* 1 = 0.0305312 loss)
I0702 23:53:48.912719 13779 sgd_solver.cpp:106] Iteration 10800, lr = 0.0001
I0702 23:54:13.082952 13779 solver.cpp:290] Iteration 10900 (4.13743 iter/s, 24.1696s/100 iter), loss = 0.0229825
I0702 23:54:13.082974 13779 solver.cpp:309]     Train net output #0: loss = 0.0229824 (* 1 = 0.0229824 loss)
I0702 23:54:13.082981 13779 sgd_solver.cpp:106] Iteration 10900, lr = 0.0001
I0702 23:54:37.210264 13779 solver.cpp:290] Iteration 11000 (4.14479 iter/s, 24.1267s/100 iter), loss = 0.0522795
I0702 23:54:37.210304 13779 solver.cpp:309]     Train net output #0: loss = 0.0522794 (* 1 = 0.0522794 loss)
I0702 23:54:37.210311 13779 sgd_solver.cpp:106] Iteration 11000, lr = 0.0001
I0702 23:55:01.405537 13779 solver.cpp:290] Iteration 11100 (4.13315 iter/s, 24.1946s/100 iter), loss = 0.0261999
I0702 23:55:01.405560 13779 solver.cpp:309]     Train net output #0: loss = 0.0261998 (* 1 = 0.0261998 loss)
I0702 23:55:01.405566 13779 sgd_solver.cpp:106] Iteration 11100, lr = 0.0001
I0702 23:55:25.567909 13779 solver.cpp:290] Iteration 11200 (4.13878 iter/s, 24.1617s/100 iter), loss = 0.0289556
I0702 23:55:25.567965 13779 solver.cpp:309]     Train net output #0: loss = 0.0289555 (* 1 = 0.0289555 loss)
I0702 23:55:25.567976 13779 sgd_solver.cpp:106] Iteration 11200, lr = 0.0001
I0702 23:55:49.754271 13779 solver.cpp:290] Iteration 11300 (4.13468 iter/s, 24.1857s/100 iter), loss = 0.0483918
I0702 23:55:49.754297 13779 solver.cpp:309]     Train net output #0: loss = 0.0483917 (* 1 = 0.0483917 loss)
I0702 23:55:49.754303 13779 sgd_solver.cpp:106] Iteration 11300, lr = 0.0001
I0702 23:56:13.905783 13779 solver.cpp:290] Iteration 11400 (4.14064 iter/s, 24.1509s/100 iter), loss = 0.0387307
I0702 23:56:13.905822 13779 solver.cpp:309]     Train net output #0: loss = 0.0387306 (* 1 = 0.0387306 loss)
I0702 23:56:13.905829 13779 sgd_solver.cpp:106] Iteration 11400, lr = 0.0001
I0702 23:56:38.070417 13779 solver.cpp:290] Iteration 11500 (4.13839 iter/s, 24.164s/100 iter), loss = 0.0282366
I0702 23:56:38.070441 13779 solver.cpp:309]     Train net output #0: loss = 0.0282365 (* 1 = 0.0282365 loss)
I0702 23:56:38.070448 13779 sgd_solver.cpp:106] Iteration 11500, lr = 0.0001
I0702 23:57:02.346323 13779 solver.cpp:290] Iteration 11600 (4.11942 iter/s, 24.2752s/100 iter), loss = 0.0353232
I0702 23:57:02.346369 13779 solver.cpp:309]     Train net output #0: loss = 0.0353231 (* 1 = 0.0353231 loss)
I0702 23:57:02.346376 13779 sgd_solver.cpp:106] Iteration 11600, lr = 0.0001
I0702 23:57:26.534102 13779 solver.cpp:290] Iteration 11700 (4.13444 iter/s, 24.1871s/100 iter), loss = 0.0306663
I0702 23:57:26.534126 13779 solver.cpp:309]     Train net output #0: loss = 0.0306662 (* 1 = 0.0306662 loss)
I0702 23:57:26.534132 13779 sgd_solver.cpp:106] Iteration 11700, lr = 0.0001
I0702 23:57:50.660737 13779 solver.cpp:290] Iteration 11800 (4.14491 iter/s, 24.126s/100 iter), loss = 0.0485839
I0702 23:57:50.660845 13779 solver.cpp:309]     Train net output #0: loss = 0.0485838 (* 1 = 0.0485838 loss)
I0702 23:57:50.660856 13779 sgd_solver.cpp:106] Iteration 11800, lr = 0.0001
I0702 23:58:14.823622 13779 solver.cpp:290] Iteration 11900 (4.13871 iter/s, 24.1621s/100 iter), loss = 0.0403773
I0702 23:58:14.823647 13779 solver.cpp:309]     Train net output #0: loss = 0.0403772 (* 1 = 0.0403772 loss)
I0702 23:58:14.823653 13779 sgd_solver.cpp:106] Iteration 11900, lr = 0.0001
I0702 23:58:38.782969 13779 solver.cpp:473] Iteration 12000, Testing net (#0)
I0702 23:59:25.460856 13779 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.944467
I0702 23:59:25.461017 13779 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.999621
I0702 23:59:25.461028 13779 solver.cpp:546]     Test net output #2: loss = 0.142106 (* 1 = 0.142106 loss)
I0702 23:59:25.717615 13779 solver.cpp:290] Iteration 12000 (1.41059 iter/s, 70.8921s/100 iter), loss = 0.0769032
I0702 23:59:25.717638 13779 solver.cpp:309]     Train net output #0: loss = 0.0769032 (* 1 = 0.0769032 loss)
I0702 23:59:25.717644 13779 sgd_solver.cpp:106] Iteration 12000, lr = 0.0001
I0702 23:59:49.850721 13779 solver.cpp:290] Iteration 12100 (4.1438 iter/s, 24.1324s/100 iter), loss = 0.0490073
I0702 23:59:49.850746 13779 solver.cpp:309]     Train net output #0: loss = 0.0490072 (* 1 = 0.0490072 loss)
I0702 23:59:49.850754 13779 sgd_solver.cpp:106] Iteration 12100, lr = 0.0001
I0703 00:00:14.038502 13779 solver.cpp:290] Iteration 12200 (4.13443 iter/s, 24.1871s/100 iter), loss = 0.0444688
I0703 00:00:14.038553 13779 solver.cpp:309]     Train net output #0: loss = 0.0444687 (* 1 = 0.0444687 loss)
I0703 00:00:14.038561 13779 sgd_solver.cpp:106] Iteration 12200, lr = 0.0001
I0703 00:00:38.206866 13779 solver.cpp:290] Iteration 12300 (4.13776 iter/s, 24.1677s/100 iter), loss = 0.0466989
I0703 00:00:38.206889 13779 solver.cpp:309]     Train net output #0: loss = 0.0466988 (* 1 = 0.0466988 loss)
I0703 00:00:38.206897 13779 sgd_solver.cpp:106] Iteration 12300, lr = 0.0001
I0703 00:01:02.379874 13779 solver.cpp:290] Iteration 12400 (4.13696 iter/s, 24.1723s/100 iter), loss = 0.023381
I0703 00:01:02.379917 13779 solver.cpp:309]     Train net output #0: loss = 0.0233809 (* 1 = 0.0233809 loss)
I0703 00:01:02.379925 13779 sgd_solver.cpp:106] Iteration 12400, lr = 0.0001
I0703 00:01:26.618628 13779 solver.cpp:290] Iteration 12500 (4.12574 iter/s, 24.2381s/100 iter), loss = 0.023281
I0703 00:01:26.618654 13779 solver.cpp:309]     Train net output #0: loss = 0.0232809 (* 1 = 0.0232809 loss)
I0703 00:01:26.618661 13779 sgd_solver.cpp:106] Iteration 12500, lr = 0.0001
I0703 00:01:50.834470 13779 solver.cpp:290] Iteration 12600 (4.12964 iter/s, 24.2152s/100 iter), loss = 0.0420162
I0703 00:01:50.834523 13779 solver.cpp:309]     Train net output #0: loss = 0.0420161 (* 1 = 0.0420161 loss)
I0703 00:01:50.834532 13779 sgd_solver.cpp:106] Iteration 12600, lr = 0.0001
I0703 00:02:15.018177 13779 solver.cpp:290] Iteration 12700 (4.13513 iter/s, 24.183s/100 iter), loss = 0.0418404
I0703 00:02:15.018199 13779 solver.cpp:309]     Train net output #0: loss = 0.0418403 (* 1 = 0.0418403 loss)
I0703 00:02:15.018206 13779 sgd_solver.cpp:106] Iteration 12700, lr = 0.0001
I0703 00:02:39.211203 13779 solver.cpp:290] Iteration 12800 (4.13354 iter/s, 24.1924s/100 iter), loss = 0.0402074
I0703 00:02:39.211247 13779 solver.cpp:309]     Train net output #0: loss = 0.0402073 (* 1 = 0.0402073 loss)
I0703 00:02:39.211254 13779 sgd_solver.cpp:106] Iteration 12800, lr = 0.0001
I0703 00:03:03.439355 13779 solver.cpp:290] Iteration 12900 (4.12755 iter/s, 24.2275s/100 iter), loss = 0.0258465
I0703 00:03:03.439383 13779 solver.cpp:309]     Train net output #0: loss = 0.0258464 (* 1 = 0.0258464 loss)
I0703 00:03:03.439389 13779 sgd_solver.cpp:106] Iteration 12900, lr = 0.0001
I0703 00:03:27.613148 13779 solver.cpp:290] Iteration 13000 (4.13683 iter/s, 24.1731s/100 iter), loss = 0.0379678
I0703 00:03:27.613247 13779 solver.cpp:309]     Train net output #0: loss = 0.0379677 (* 1 = 0.0379677 loss)
I0703 00:03:27.613258 13779 sgd_solver.cpp:106] Iteration 13000, lr = 0.0001
I0703 00:03:51.834902 13779 solver.cpp:290] Iteration 13100 (4.12865 iter/s, 24.221s/100 iter), loss = 0.0450732
I0703 00:03:51.834924 13779 solver.cpp:309]     Train net output #0: loss = 0.0450732 (* 1 = 0.0450732 loss)
I0703 00:03:51.834933 13779 sgd_solver.cpp:106] Iteration 13100, lr = 0.0001
I0703 00:04:16.076299 13779 solver.cpp:290] Iteration 13200 (4.12529 iter/s, 24.2407s/100 iter), loss = 0.0360968
I0703 00:04:16.076504 13779 solver.cpp:309]     Train net output #0: loss = 0.0360968 (* 1 = 0.0360968 loss)
I0703 00:04:16.076514 13779 sgd_solver.cpp:106] Iteration 13200, lr = 0.0001
I0703 00:04:40.394857 13779 solver.cpp:290] Iteration 13300 (4.11223 iter/s, 24.3177s/100 iter), loss = 0.038389
I0703 00:04:40.394881 13779 solver.cpp:309]     Train net output #0: loss = 0.038389 (* 1 = 0.038389 loss)
I0703 00:04:40.394887 13779 sgd_solver.cpp:106] Iteration 13300, lr = 0.0001
I0703 00:05:04.713466 13779 solver.cpp:290] Iteration 13400 (4.11219 iter/s, 24.3179s/100 iter), loss = 0.0346904
I0703 00:05:04.713593 13779 solver.cpp:309]     Train net output #0: loss = 0.0346903 (* 1 = 0.0346903 loss)
I0703 00:05:04.713603 13779 sgd_solver.cpp:106] Iteration 13400, lr = 0.0001
I0703 00:05:28.909299 13779 solver.cpp:290] Iteration 13500 (4.13307 iter/s, 24.1951s/100 iter), loss = 0.0310236
I0703 00:05:28.909323 13779 solver.cpp:309]     Train net output #0: loss = 0.0310236 (* 1 = 0.0310236 loss)
I0703 00:05:28.909332 13779 sgd_solver.cpp:106] Iteration 13500, lr = 0.0001
I0703 00:05:53.223808 13779 solver.cpp:290] Iteration 13600 (4.11288 iter/s, 24.3138s/100 iter), loss = 0.0296147
I0703 00:05:53.223913 13779 solver.cpp:309]     Train net output #0: loss = 0.0296147 (* 1 = 0.0296147 loss)
I0703 00:05:53.223924 13779 sgd_solver.cpp:106] Iteration 13600, lr = 0.0001
I0703 00:06:17.509582 13779 solver.cpp:290] Iteration 13700 (4.11776 iter/s, 24.285s/100 iter), loss = 0.0336856
I0703 00:06:17.509609 13779 solver.cpp:309]     Train net output #0: loss = 0.0336856 (* 1 = 0.0336856 loss)
I0703 00:06:17.509616 13779 sgd_solver.cpp:106] Iteration 13700, lr = 0.0001
I0703 00:06:41.695549 13779 solver.cpp:290] Iteration 13800 (4.13474 iter/s, 24.1853s/100 iter), loss = 0.0332787
I0703 00:06:41.695657 13779 solver.cpp:309]     Train net output #0: loss = 0.0332787 (* 1 = 0.0332787 loss)
I0703 00:06:41.695668 13779 sgd_solver.cpp:106] Iteration 13800, lr = 0.0001
I0703 00:07:05.841073 13779 solver.cpp:290] Iteration 13900 (4.14168 iter/s, 24.1448s/100 iter), loss = 0.0260395
I0703 00:07:05.841096 13779 solver.cpp:309]     Train net output #0: loss = 0.0260394 (* 1 = 0.0260394 loss)
I0703 00:07:05.841104 13779 sgd_solver.cpp:106] Iteration 13900, lr = 0.0001
I0703 00:07:29.776346 13779 solver.cpp:473] Iteration 14000, Testing net (#0)
I0703 00:08:16.360644 13779 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.948359
I0703 00:08:16.360718 13779 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.999994
I0703 00:08:16.360724 13779 solver.cpp:546]     Test net output #2: loss = 0.116941 (* 1 = 0.116941 loss)
I0703 00:08:16.625695 13779 solver.cpp:290] Iteration 14000 (1.41277 iter/s, 70.7827s/100 iter), loss = 0.0521057
I0703 00:08:16.625721 13779 solver.cpp:309]     Train net output #0: loss = 0.0521056 (* 1 = 0.0521056 loss)
I0703 00:08:16.625728 13779 sgd_solver.cpp:106] Iteration 14000, lr = 0.0001
I0703 00:08:40.789089 13779 solver.cpp:290] Iteration 14100 (4.13861 iter/s, 24.1627s/100 iter), loss = 0.0261743
I0703 00:08:40.789113 13779 solver.cpp:309]     Train net output #0: loss = 0.0261743 (* 1 = 0.0261743 loss)
I0703 00:08:40.789120 13779 sgd_solver.cpp:106] Iteration 14100, lr = 0.0001
I0703 00:09:04.935784 13779 solver.cpp:290] Iteration 14200 (4.14147 iter/s, 24.146s/100 iter), loss = 0.0203192
I0703 00:09:04.935837 13779 solver.cpp:309]     Train net output #0: loss = 0.0203192 (* 1 = 0.0203192 loss)
I0703 00:09:04.935847 13779 sgd_solver.cpp:106] Iteration 14200, lr = 0.0001
I0703 00:09:29.099527 13779 solver.cpp:290] Iteration 14300 (4.13855 iter/s, 24.163s/100 iter), loss = 0.0242572
I0703 00:09:29.099550 13779 solver.cpp:309]     Train net output #0: loss = 0.0242572 (* 1 = 0.0242572 loss)
I0703 00:09:29.099558 13779 sgd_solver.cpp:106] Iteration 14300, lr = 0.0001
I0703 00:09:53.280936 13779 solver.cpp:290] Iteration 14400 (4.13552 iter/s, 24.1807s/100 iter), loss = 0.0345069
I0703 00:09:53.281044 13779 solver.cpp:309]     Train net output #0: loss = 0.0345069 (* 1 = 0.0345069 loss)
I0703 00:09:53.281055 13779 sgd_solver.cpp:106] Iteration 14400, lr = 0.0001
I0703 00:10:17.430297 13779 solver.cpp:290] Iteration 14500 (4.14103 iter/s, 24.1486s/100 iter), loss = 0.0332651
I0703 00:10:17.430320 13779 solver.cpp:309]     Train net output #0: loss = 0.0332651 (* 1 = 0.0332651 loss)
I0703 00:10:17.430327 13779 sgd_solver.cpp:106] Iteration 14500, lr = 0.0001
I0703 00:10:41.597764 13779 solver.cpp:290] Iteration 14600 (4.13791 iter/s, 24.1668s/100 iter), loss = 0.0480925
I0703 00:10:41.597892 13779 solver.cpp:309]     Train net output #0: loss = 0.0480924 (* 1 = 0.0480924 loss)
I0703 00:10:41.597901 13779 sgd_solver.cpp:106] Iteration 14600, lr = 0.0001
I0703 00:11:05.771225 13779 solver.cpp:290] Iteration 14700 (4.1369 iter/s, 24.1727s/100 iter), loss = 0.0454142
I0703 00:11:05.771247 13779 solver.cpp:309]     Train net output #0: loss = 0.0454142 (* 1 = 0.0454142 loss)
I0703 00:11:05.771255 13779 sgd_solver.cpp:106] Iteration 14700, lr = 0.0001
I0703 00:11:29.926257 13779 solver.cpp:290] Iteration 14800 (4.14004 iter/s, 24.1544s/100 iter), loss = 0.031058
I0703 00:11:29.926308 13779 solver.cpp:309]     Train net output #0: loss = 0.031058 (* 1 = 0.031058 loss)
I0703 00:11:29.926317 13779 sgd_solver.cpp:106] Iteration 14800, lr = 0.0001
I0703 00:11:54.088945 13779 solver.cpp:290] Iteration 14900 (4.13873 iter/s, 24.162s/100 iter), loss = 0.0365733
I0703 00:11:54.088968 13779 solver.cpp:309]     Train net output #0: loss = 0.0365733 (* 1 = 0.0365733 loss)
I0703 00:11:54.088975 13779 sgd_solver.cpp:106] Iteration 14900, lr = 0.0001
I0703 00:12:18.242923 13779 solver.cpp:290] Iteration 15000 (4.14022 iter/s, 24.1533s/100 iter), loss = 0.0305932
I0703 00:12:18.243029 13779 solver.cpp:309]     Train net output #0: loss = 0.0305932 (* 1 = 0.0305932 loss)
I0703 00:12:18.243039 13779 sgd_solver.cpp:106] Iteration 15000, lr = 0.0001
I0703 00:12:42.395382 13779 solver.cpp:290] Iteration 15100 (4.14049 iter/s, 24.1517s/100 iter), loss = 0.0198778
I0703 00:12:42.395408 13779 solver.cpp:309]     Train net output #0: loss = 0.0198778 (* 1 = 0.0198778 loss)
I0703 00:12:42.395417 13779 sgd_solver.cpp:106] Iteration 15100, lr = 0.0001
I0703 00:13:06.563217 13779 solver.cpp:290] Iteration 15200 (4.13785 iter/s, 24.1672s/100 iter), loss = 0.0376205
I0703 00:13:06.563329 13779 solver.cpp:309]     Train net output #0: loss = 0.0376205 (* 1 = 0.0376205 loss)
I0703 00:13:06.563340 13779 sgd_solver.cpp:106] Iteration 15200, lr = 0.0001
I0703 00:13:30.820339 13779 solver.cpp:290] Iteration 15300 (4.12263 iter/s, 24.2564s/100 iter), loss = 0.0525517
I0703 00:13:30.820363 13779 solver.cpp:309]     Train net output #0: loss = 0.0525517 (* 1 = 0.0525517 loss)
I0703 00:13:30.820370 13779 sgd_solver.cpp:106] Iteration 15300, lr = 0.0001
I0703 00:13:55.004906 13779 solver.cpp:290] Iteration 15400 (4.13498 iter/s, 24.1839s/100 iter), loss = 0.0291003
I0703 00:13:55.004987 13779 solver.cpp:309]     Train net output #0: loss = 0.0291003 (* 1 = 0.0291003 loss)
I0703 00:13:55.004995 13779 sgd_solver.cpp:106] Iteration 15400, lr = 0.0001
I0703 00:14:19.202602 13779 solver.cpp:290] Iteration 15500 (4.13275 iter/s, 24.197s/100 iter), loss = 0.0577418
I0703 00:14:19.202626 13779 solver.cpp:309]     Train net output #0: loss = 0.0577418 (* 1 = 0.0577418 loss)
I0703 00:14:19.202633 13779 sgd_solver.cpp:106] Iteration 15500, lr = 0.0001
I0703 00:14:43.395948 13779 solver.cpp:290] Iteration 15600 (4.13348 iter/s, 24.1927s/100 iter), loss = 0.0311261
I0703 00:14:43.395999 13779 solver.cpp:309]     Train net output #0: loss = 0.0311261 (* 1 = 0.0311261 loss)
I0703 00:14:43.396008 13779 sgd_solver.cpp:106] Iteration 15600, lr = 0.0001
I0703 00:15:07.551295 13779 solver.cpp:290] Iteration 15700 (4.13999 iter/s, 24.1546s/100 iter), loss = 0.0314561
I0703 00:15:07.551318 13779 solver.cpp:309]     Train net output #0: loss = 0.0314561 (* 1 = 0.0314561 loss)
I0703 00:15:07.551326 13779 sgd_solver.cpp:106] Iteration 15700, lr = 0.0001
I0703 00:15:31.700750 13779 solver.cpp:290] Iteration 15800 (4.141 iter/s, 24.1488s/100 iter), loss = 0.029358
I0703 00:15:31.700853 13779 solver.cpp:309]     Train net output #0: loss = 0.029358 (* 1 = 0.029358 loss)
I0703 00:15:31.700865 13779 sgd_solver.cpp:106] Iteration 15800, lr = 0.0001
I0703 00:15:55.938738 13779 solver.cpp:290] Iteration 15900 (4.12588 iter/s, 24.2372s/100 iter), loss = 0.0260849
I0703 00:15:55.938761 13779 solver.cpp:309]     Train net output #0: loss = 0.0260849 (* 1 = 0.0260849 loss)
I0703 00:15:55.938768 13779 sgd_solver.cpp:106] Iteration 15900, lr = 0.0001
I0703 00:16:19.877607 13779 solver.cpp:473] Iteration 16000, Testing net (#0)
I0703 00:17:06.523891 13779 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.951288
I0703 00:17:06.523946 13779 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.999139
I0703 00:17:06.523952 13779 solver.cpp:546]     Test net output #2: loss = 0.130729 (* 1 = 0.130729 loss)
I0703 00:17:06.767738 13779 solver.cpp:290] Iteration 16000 (1.41189 iter/s, 70.8271s/100 iter), loss = 0.0412796
I0703 00:17:06.767765 13779 solver.cpp:309]     Train net output #0: loss = 0.0412796 (* 1 = 0.0412796 loss)
I0703 00:17:06.767771 13779 sgd_solver.cpp:106] Iteration 16000, lr = 0.0001
I0703 00:17:30.867949 13779 solver.cpp:290] Iteration 16100 (4.14946 iter/s, 24.0995s/100 iter), loss = 0.0411171
I0703 00:17:30.867974 13779 solver.cpp:309]     Train net output #0: loss = 0.0411171 (* 1 = 0.0411171 loss)
I0703 00:17:30.867980 13779 sgd_solver.cpp:106] Iteration 16100, lr = 0.0001
I0703 00:17:55.068640 13779 solver.cpp:290] Iteration 16200 (4.13223 iter/s, 24.2s/100 iter), loss = 0.0368303
I0703 00:17:55.068750 13779 solver.cpp:309]     Train net output #0: loss = 0.0368303 (* 1 = 0.0368303 loss)
I0703 00:17:55.068761 13779 sgd_solver.cpp:106] Iteration 16200, lr = 0.0001
I0703 00:18:19.258518 13779 solver.cpp:290] Iteration 16300 (4.13409 iter/s, 24.1891s/100 iter), loss = 0.0297767
I0703 00:18:19.258541 13779 solver.cpp:309]     Train net output #0: loss = 0.0297767 (* 1 = 0.0297767 loss)
I0703 00:18:19.258548 13779 sgd_solver.cpp:106] Iteration 16300, lr = 0.0001
I0703 00:18:43.435556 13779 solver.cpp:290] Iteration 16400 (4.13627 iter/s, 24.1764s/100 iter), loss = 0.0763416
I0703 00:18:43.435637 13779 solver.cpp:309]     Train net output #0: loss = 0.0763416 (* 1 = 0.0763416 loss)
I0703 00:18:43.435648 13779 sgd_solver.cpp:106] Iteration 16400, lr = 0.0001
I0703 00:19:07.610242 13779 solver.cpp:290] Iteration 16500 (4.13668 iter/s, 24.1739s/100 iter), loss = 0.0153301
I0703 00:19:07.610266 13779 solver.cpp:309]     Train net output #0: loss = 0.0153301 (* 1 = 0.0153301 loss)
I0703 00:19:07.610275 13779 sgd_solver.cpp:106] Iteration 16500, lr = 0.0001
I0703 00:19:31.765655 13779 solver.cpp:290] Iteration 16600 (4.13998 iter/s, 24.1547s/100 iter), loss = 0.0253713
I0703 00:19:31.765758 13779 solver.cpp:309]     Train net output #0: loss = 0.0253713 (* 1 = 0.0253713 loss)
I0703 00:19:31.765769 13779 sgd_solver.cpp:106] Iteration 16600, lr = 0.0001
I0703 00:19:55.943950 13779 solver.cpp:290] Iteration 16700 (4.13607 iter/s, 24.1775s/100 iter), loss = 0.0532802
I0703 00:19:55.943975 13779 solver.cpp:309]     Train net output #0: loss = 0.0532802 (* 1 = 0.0532802 loss)
I0703 00:19:55.943982 13779 sgd_solver.cpp:106] Iteration 16700, lr = 0.0001
I0703 00:20:20.095468 13779 solver.cpp:290] Iteration 16800 (4.14064 iter/s, 24.1508s/100 iter), loss = 0.0241321
I0703 00:20:20.095546 13779 solver.cpp:309]     Train net output #0: loss = 0.0241321 (* 1 = 0.0241321 loss)
I0703 00:20:20.095554 13779 sgd_solver.cpp:106] Iteration 16800, lr = 0.0001
I0703 00:20:44.290313 13779 solver.cpp:290] Iteration 16900 (4.13324 iter/s, 24.1941s/100 iter), loss = 0.0425849
I0703 00:20:44.290339 13779 solver.cpp:309]     Train net output #0: loss = 0.0425849 (* 1 = 0.0425849 loss)
I0703 00:20:44.290346 13779 sgd_solver.cpp:106] Iteration 16900, lr = 0.0001
I0703 00:21:08.472865 13779 solver.cpp:290] Iteration 17000 (4.13533 iter/s, 24.1819s/100 iter), loss = 0.0290122
I0703 00:21:08.472980 13779 solver.cpp:309]     Train net output #0: loss = 0.0290121 (* 1 = 0.0290121 loss)
I0703 00:21:08.472990 13779 sgd_solver.cpp:106] Iteration 17000, lr = 0.0001
I0703 00:21:32.623298 13779 solver.cpp:290] Iteration 17100 (4.14084 iter/s, 24.1497s/100 iter), loss = 0.0234619
I0703 00:21:32.623322 13779 solver.cpp:309]     Train net output #0: loss = 0.0234619 (* 1 = 0.0234619 loss)
I0703 00:21:32.623330 13779 sgd_solver.cpp:106] Iteration 17100, lr = 0.0001
I0703 00:21:56.775589 13779 solver.cpp:290] Iteration 17200 (4.14051 iter/s, 24.1516s/100 iter), loss = 0.0274234
I0703 00:21:56.775708 13779 solver.cpp:309]     Train net output #0: loss = 0.0274234 (* 1 = 0.0274234 loss)
I0703 00:21:56.775719 13779 sgd_solver.cpp:106] Iteration 17200, lr = 0.0001
I0703 00:22:20.995120 13779 solver.cpp:290] Iteration 17300 (4.12903 iter/s, 24.2188s/100 iter), loss = 0.0311331
I0703 00:22:20.995146 13779 solver.cpp:309]     Train net output #0: loss = 0.0311331 (* 1 = 0.0311331 loss)
I0703 00:22:20.995152 13779 sgd_solver.cpp:106] Iteration 17300, lr = 0.0001
I0703 00:22:45.212882 13779 solver.cpp:290] Iteration 17400 (4.12932 iter/s, 24.2171s/100 iter), loss = 0.0370052
I0703 00:22:45.212990 13779 solver.cpp:309]     Train net output #0: loss = 0.0370051 (* 1 = 0.0370051 loss)
I0703 00:22:45.213001 13779 sgd_solver.cpp:106] Iteration 17400, lr = 0.0001
I0703 00:23:09.344712 13779 solver.cpp:290] Iteration 17500 (4.14403 iter/s, 24.1311s/100 iter), loss = 0.0253961
I0703 00:23:09.344739 13779 solver.cpp:309]     Train net output #0: loss = 0.0253961 (* 1 = 0.0253961 loss)
I0703 00:23:09.344746 13779 sgd_solver.cpp:106] Iteration 17500, lr = 0.0001
I0703 00:23:33.515699 13779 solver.cpp:290] Iteration 17600 (4.13731 iter/s, 24.1703s/100 iter), loss = 0.0593604
I0703 00:23:33.515806 13779 solver.cpp:309]     Train net output #0: loss = 0.0593603 (* 1 = 0.0593603 loss)
I0703 00:23:33.515817 13779 sgd_solver.cpp:106] Iteration 17600, lr = 0.0001
I0703 00:23:57.725368 13779 solver.cpp:290] Iteration 17700 (4.13071 iter/s, 24.2089s/100 iter), loss = 0.0293399
I0703 00:23:57.725394 13779 solver.cpp:309]     Train net output #0: loss = 0.0293399 (* 1 = 0.0293399 loss)
I0703 00:23:57.725400 13779 sgd_solver.cpp:106] Iteration 17700, lr = 0.0001
I0703 00:24:21.924835 13779 solver.cpp:290] Iteration 17800 (4.13244 iter/s, 24.1988s/100 iter), loss = 0.0264623
I0703 00:24:21.924944 13779 solver.cpp:309]     Train net output #0: loss = 0.0264623 (* 1 = 0.0264623 loss)
I0703 00:24:21.924955 13779 sgd_solver.cpp:106] Iteration 17800, lr = 0.0001
I0703 00:24:46.146306 13779 solver.cpp:290] Iteration 17900 (4.1287 iter/s, 24.2207s/100 iter), loss = 0.0386057
I0703 00:24:46.146332 13779 solver.cpp:309]     Train net output #0: loss = 0.0386057 (* 1 = 0.0386057 loss)
I0703 00:24:46.146342 13779 sgd_solver.cpp:106] Iteration 17900, lr = 0.0001
I0703 00:25:10.070552 13779 solver.cpp:473] Iteration 18000, Testing net (#0)
I0703 00:25:56.701376 13779 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.948156
I0703 00:25:56.701450 13779 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.999957
I0703 00:25:56.701458 13779 solver.cpp:546]     Test net output #2: loss = 0.142204 (* 1 = 0.142204 loss)
I0703 00:25:56.955337 13779 solver.cpp:290] Iteration 18000 (1.41229 iter/s, 70.8071s/100 iter), loss = 0.0340801
I0703 00:25:56.955361 13779 solver.cpp:309]     Train net output #0: loss = 0.0340801 (* 1 = 0.0340801 loss)
I0703 00:25:56.955371 13779 sgd_solver.cpp:106] Iteration 18000, lr = 0.0001
I0703 00:26:21.091219 13779 solver.cpp:290] Iteration 18100 (4.14333 iter/s, 24.1352s/100 iter), loss = 0.0327507
I0703 00:26:21.091245 13779 solver.cpp:309]     Train net output #0: loss = 0.0327507 (* 1 = 0.0327507 loss)
I0703 00:26:21.091253 13779 sgd_solver.cpp:106] Iteration 18100, lr = 0.0001
I0703 00:26:45.297258 13779 solver.cpp:290] Iteration 18200 (4.13132 iter/s, 24.2054s/100 iter), loss = 0.0430454
I0703 00:26:45.297369 13779 solver.cpp:309]     Train net output #0: loss = 0.0430453 (* 1 = 0.0430453 loss)
I0703 00:26:45.297379 13779 sgd_solver.cpp:106] Iteration 18200, lr = 0.0001
I0703 00:27:09.473340 13779 solver.cpp:290] Iteration 18300 (4.13645 iter/s, 24.1753s/100 iter), loss = 0.0215262
I0703 00:27:09.473363 13779 solver.cpp:309]     Train net output #0: loss = 0.0215262 (* 1 = 0.0215262 loss)
I0703 00:27:09.473371 13779 sgd_solver.cpp:106] Iteration 18300, lr = 0.0001
I0703 00:27:33.667819 13779 solver.cpp:290] Iteration 18400 (4.13329 iter/s, 24.1938s/100 iter), loss = 0.025691
I0703 00:27:33.667938 13779 solver.cpp:309]     Train net output #0: loss = 0.025691 (* 1 = 0.025691 loss)
I0703 00:27:33.667949 13779 sgd_solver.cpp:106] Iteration 18400, lr = 0.0001
I0703 00:27:57.834281 13779 solver.cpp:290] Iteration 18500 (4.1381 iter/s, 24.1657s/100 iter), loss = 0.0221497
I0703 00:27:57.834308 13779 solver.cpp:309]     Train net output #0: loss = 0.0221497 (* 1 = 0.0221497 loss)
I0703 00:27:57.834318 13779 sgd_solver.cpp:106] Iteration 18500, lr = 0.0001
I0703 00:28:22.046712 13779 solver.cpp:290] Iteration 18600 (4.13023 iter/s, 24.2118s/100 iter), loss = 0.0284573
I0703 00:28:22.046825 13779 solver.cpp:309]     Train net output #0: loss = 0.0284573 (* 1 = 0.0284573 loss)
I0703 00:28:22.046835 13779 sgd_solver.cpp:106] Iteration 18600, lr = 0.0001
I0703 00:28:46.206428 13779 solver.cpp:290] Iteration 18700 (4.13925 iter/s, 24.159s/100 iter), loss = 0.0290043
I0703 00:28:46.206451 13779 solver.cpp:309]     Train net output #0: loss = 0.0290043 (* 1 = 0.0290043 loss)
I0703 00:28:46.206459 13779 sgd_solver.cpp:106] Iteration 18700, lr = 0.0001
I0703 00:29:10.366572 13779 solver.cpp:290] Iteration 18800 (4.13916 iter/s, 24.1595s/100 iter), loss = 0.042997
I0703 00:29:10.366677 13779 solver.cpp:309]     Train net output #0: loss = 0.042997 (* 1 = 0.042997 loss)
I0703 00:29:10.366688 13779 sgd_solver.cpp:106] Iteration 18800, lr = 0.0001
I0703 00:29:34.508698 13779 solver.cpp:290] Iteration 18900 (4.14227 iter/s, 24.1414s/100 iter), loss = 0.0257624
I0703 00:29:34.508724 13779 solver.cpp:309]     Train net output #0: loss = 0.0257624 (* 1 = 0.0257624 loss)
I0703 00:29:34.508731 13779 sgd_solver.cpp:106] Iteration 18900, lr = 0.0001
I0703 00:29:58.658452 13779 solver.cpp:290] Iteration 19000 (4.14094 iter/s, 24.1491s/100 iter), loss = 0.0307679
I0703 00:29:58.658495 13779 solver.cpp:309]     Train net output #0: loss = 0.0307679 (* 1 = 0.0307679 loss)
I0703 00:29:58.658504 13779 sgd_solver.cpp:106] Iteration 19000, lr = 0.0001
I0703 00:30:22.838259 13779 solver.cpp:290] Iteration 19100 (4.1358 iter/s, 24.1791s/100 iter), loss = 0.0304391
I0703 00:30:22.838284 13779 solver.cpp:309]     Train net output #0: loss = 0.0304391 (* 1 = 0.0304391 loss)
I0703 00:30:22.838292 13779 sgd_solver.cpp:106] Iteration 19100, lr = 0.0001
I0703 00:30:47.026108 13779 solver.cpp:290] Iteration 19200 (4.13442 iter/s, 24.1872s/100 iter), loss = 0.0348779
I0703 00:30:47.026160 13779 solver.cpp:309]     Train net output #0: loss = 0.0348779 (* 1 = 0.0348779 loss)
I0703 00:30:47.026168 13779 sgd_solver.cpp:106] Iteration 19200, lr = 0.0001
I0703 00:31:11.182829 13779 solver.cpp:290] Iteration 19300 (4.13975 iter/s, 24.156s/100 iter), loss = 0.0326574
I0703 00:31:11.182853 13779 solver.cpp:309]     Train net output #0: loss = 0.0326574 (* 1 = 0.0326574 loss)
I0703 00:31:11.182860 13779 sgd_solver.cpp:106] Iteration 19300, lr = 0.0001
I0703 00:31:35.447942 13779 solver.cpp:290] Iteration 19400 (4.12126 iter/s, 24.2644s/100 iter), loss = 0.0418831
I0703 00:31:35.448002 13779 solver.cpp:309]     Train net output #0: loss = 0.0418831 (* 1 = 0.0418831 loss)
I0703 00:31:35.448010 13779 sgd_solver.cpp:106] Iteration 19400, lr = 0.0001
I0703 00:31:59.649606 13779 solver.cpp:290] Iteration 19500 (4.13207 iter/s, 24.201s/100 iter), loss = 0.027058
I0703 00:31:59.649631 13779 solver.cpp:309]     Train net output #0: loss = 0.027058 (* 1 = 0.027058 loss)
I0703 00:31:59.649637 13779 sgd_solver.cpp:106] Iteration 19500, lr = 0.0001
I0703 00:32:23.842020 13779 solver.cpp:290] Iteration 19600 (4.13364 iter/s, 24.1917s/100 iter), loss = 0.0306203
I0703 00:32:23.842130 13779 solver.cpp:309]     Train net output #0: loss = 0.0306203 (* 1 = 0.0306203 loss)
I0703 00:32:23.842145 13779 sgd_solver.cpp:106] Iteration 19600, lr = 0.0001
I0703 00:32:48.042476 13779 solver.cpp:290] Iteration 19700 (4.13228 iter/s, 24.1997s/100 iter), loss = 0.0408374
I0703 00:32:48.042500 13779 solver.cpp:309]     Train net output #0: loss = 0.0408374 (* 1 = 0.0408374 loss)
I0703 00:32:48.042506 13779 sgd_solver.cpp:106] Iteration 19700, lr = 0.0001
I0703 00:33:12.181731 13779 solver.cpp:290] Iteration 19800 (4.14275 iter/s, 24.1386s/100 iter), loss = 0.0385623
I0703 00:33:12.181856 13779 solver.cpp:309]     Train net output #0: loss = 0.0385623 (* 1 = 0.0385623 loss)
I0703 00:33:12.181866 13779 sgd_solver.cpp:106] Iteration 19800, lr = 0.0001
I0703 00:33:36.312343 13779 solver.cpp:290] Iteration 19900 (4.14425 iter/s, 24.1298s/100 iter), loss = 0.0218966
I0703 00:33:36.312366 13779 solver.cpp:309]     Train net output #0: loss = 0.0218966 (* 1 = 0.0218966 loss)
I0703 00:33:36.312372 13779 sgd_solver.cpp:106] Iteration 19900, lr = 0.0001
I0703 00:34:00.247042 13779 solver.cpp:600] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-07-02_23-02-42/initial/cityscapes5_jsegnet21v2_iter_20000.caffemodel
I0703 00:34:00.311905 13779 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-07-02_23-02-42/initial/cityscapes5_jsegnet21v2_iter_20000.solverstate
I0703 00:34:00.329949 13779 solver.cpp:473] Iteration 20000, Testing net (#0)
I0703 00:34:46.883056 13779 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.951865
I0703 00:34:46.883139 13779 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.999673
I0703 00:34:46.883147 13779 solver.cpp:546]     Test net output #2: loss = 0.146016 (* 1 = 0.146016 loss)
I0703 00:34:47.137537 13779 solver.cpp:290] Iteration 20000 (1.41197 iter/s, 70.8233s/100 iter), loss = 0.0128292
I0703 00:34:47.137560 13779 solver.cpp:309]     Train net output #0: loss = 0.0128292 (* 1 = 0.0128292 loss)
I0703 00:34:47.137567 13779 sgd_solver.cpp:106] Iteration 20000, lr = 0.0001
I0703 00:35:11.217018 13779 solver.cpp:290] Iteration 20100 (4.15303 iter/s, 24.0788s/100 iter), loss = 0.0392077
I0703 00:35:11.217044 13779 solver.cpp:309]     Train net output #0: loss = 0.0392078 (* 1 = 0.0392078 loss)
I0703 00:35:11.217051 13779 sgd_solver.cpp:106] Iteration 20100, lr = 0.0001
I0703 00:35:35.390445 13779 solver.cpp:290] Iteration 20200 (4.13689 iter/s, 24.1727s/100 iter), loss = 0.0210008
I0703 00:35:35.390550 13779 solver.cpp:309]     Train net output #0: loss = 0.0210008 (* 1 = 0.0210008 loss)
I0703 00:35:35.390560 13779 sgd_solver.cpp:106] Iteration 20200, lr = 0.0001
I0703 00:35:59.597362 13779 solver.cpp:290] Iteration 20300 (4.13118 iter/s, 24.2062s/100 iter), loss = 0.0121182
I0703 00:35:59.597398 13779 solver.cpp:309]     Train net output #0: loss = 0.0121182 (* 1 = 0.0121182 loss)
I0703 00:35:59.597406 13779 sgd_solver.cpp:106] Iteration 20300, lr = 0.0001
I0703 00:36:23.900501 13779 solver.cpp:290] Iteration 20400 (4.11481 iter/s, 24.3024s/100 iter), loss = 0.0443118
I0703 00:36:23.900611 13779 solver.cpp:309]     Train net output #0: loss = 0.0443118 (* 1 = 0.0443118 loss)
I0703 00:36:23.900621 13779 sgd_solver.cpp:106] Iteration 20400, lr = 0.0001
I0703 00:36:48.290158 13779 solver.cpp:290] Iteration 20500 (4.10023 iter/s, 24.3889s/100 iter), loss = 0.0293567
I0703 00:36:48.290181 13779 solver.cpp:309]     Train net output #0: loss = 0.0293567 (* 1 = 0.0293567 loss)
I0703 00:36:48.290189 13779 sgd_solver.cpp:106] Iteration 20500, lr = 0.0001
I0703 00:37:12.545316 13779 solver.cpp:290] Iteration 20600 (4.12295 iter/s, 24.2545s/100 iter), loss = 0.0246662
I0703 00:37:12.545362 13779 solver.cpp:309]     Train net output #0: loss = 0.0246663 (* 1 = 0.0246663 loss)
I0703 00:37:12.545370 13779 sgd_solver.cpp:106] Iteration 20600, lr = 0.0001
I0703 00:37:36.745662 13779 solver.cpp:290] Iteration 20700 (4.13229 iter/s, 24.1996s/100 iter), loss = 0.0251468
I0703 00:37:36.745687 13779 solver.cpp:309]     Train net output #0: loss = 0.0251468 (* 1 = 0.0251468 loss)
I0703 00:37:36.745693 13779 sgd_solver.cpp:106] Iteration 20700, lr = 0.0001
I0703 00:38:00.895920 13779 solver.cpp:290] Iteration 20800 (4.14086 iter/s, 24.1496s/100 iter), loss = 0.0323147
I0703 00:38:00.896126 13779 solver.cpp:309]     Train net output #0: loss = 0.0323147 (* 1 = 0.0323147 loss)
I0703 00:38:00.896140 13779 sgd_solver.cpp:106] Iteration 20800, lr = 0.0001
I0703 00:38:25.073227 13779 solver.cpp:290] Iteration 20900 (4.13626 iter/s, 24.1765s/100 iter), loss = 0.0313347
I0703 00:38:25.073251 13779 solver.cpp:309]     Train net output #0: loss = 0.0313348 (* 1 = 0.0313348 loss)
I0703 00:38:25.073257 13779 sgd_solver.cpp:106] Iteration 20900, lr = 0.0001
I0703 00:38:49.243969 13779 solver.cpp:290] Iteration 21000 (4.13735 iter/s, 24.1701s/100 iter), loss = 0.0250645
I0703 00:38:49.244045 13779 solver.cpp:309]     Train net output #0: loss = 0.0250645 (* 1 = 0.0250645 loss)
I0703 00:38:49.244055 13779 sgd_solver.cpp:106] Iteration 21000, lr = 0.0001
I0703 00:39:13.411789 13779 solver.cpp:290] Iteration 21100 (4.13786 iter/s, 24.1671s/100 iter), loss = 0.021332
I0703 00:39:13.411816 13779 solver.cpp:309]     Train net output #0: loss = 0.021332 (* 1 = 0.021332 loss)
I0703 00:39:13.411826 13779 sgd_solver.cpp:106] Iteration 21100, lr = 0.0001
I0703 00:39:37.587838 13779 solver.cpp:290] Iteration 21200 (4.13644 iter/s, 24.1754s/100 iter), loss = 0.0233636
I0703 00:39:37.587947 13779 solver.cpp:309]     Train net output #0: loss = 0.0233636 (* 1 = 0.0233636 loss)
I0703 00:39:37.587957 13779 sgd_solver.cpp:106] Iteration 21200, lr = 0.0001
I0703 00:40:01.756080 13779 solver.cpp:290] Iteration 21300 (4.13779 iter/s, 24.1675s/100 iter), loss = 0.0310525
I0703 00:40:01.756103 13779 solver.cpp:309]     Train net output #0: loss = 0.0310526 (* 1 = 0.0310526 loss)
I0703 00:40:01.756109 13779 sgd_solver.cpp:106] Iteration 21300, lr = 0.0001
I0703 00:40:25.918697 13779 solver.cpp:290] Iteration 21400 (4.13874 iter/s, 24.1619s/100 iter), loss = 0.0254362
I0703 00:40:25.918809 13779 solver.cpp:309]     Train net output #0: loss = 0.0254362 (* 1 = 0.0254362 loss)
I0703 00:40:25.918819 13779 sgd_solver.cpp:106] Iteration 21400, lr = 0.0001
I0703 00:40:50.114789 13779 solver.cpp:290] Iteration 21500 (4.13303 iter/s, 24.1953s/100 iter), loss = 0.032104
I0703 00:40:50.114812 13779 solver.cpp:309]     Train net output #0: loss = 0.0321041 (* 1 = 0.0321041 loss)
I0703 00:40:50.114820 13779 sgd_solver.cpp:106] Iteration 21500, lr = 0.0001
I0703 00:41:14.291661 13779 solver.cpp:290] Iteration 21600 (4.1363 iter/s, 24.1762s/100 iter), loss = 0.0377092
I0703 00:41:14.291703 13779 solver.cpp:309]     Train net output #0: loss = 0.0377092 (* 1 = 0.0377092 loss)
I0703 00:41:14.291712 13779 sgd_solver.cpp:106] Iteration 21600, lr = 0.0001
I0703 00:41:38.460515 13779 solver.cpp:290] Iteration 21700 (4.13768 iter/s, 24.1682s/100 iter), loss = 0.0438542
I0703 00:41:38.460538 13779 solver.cpp:309]     Train net output #0: loss = 0.0438542 (* 1 = 0.0438542 loss)
I0703 00:41:38.460546 13779 sgd_solver.cpp:106] Iteration 21700, lr = 0.0001
I0703 00:42:02.632253 13779 solver.cpp:290] Iteration 21800 (4.13718 iter/s, 24.1711s/100 iter), loss = 0.0550301
I0703 00:42:02.632295 13779 solver.cpp:309]     Train net output #0: loss = 0.0550301 (* 1 = 0.0550301 loss)
I0703 00:42:02.632302 13779 sgd_solver.cpp:106] Iteration 21800, lr = 0.0001
I0703 00:42:26.771292 13779 solver.cpp:290] Iteration 21900 (4.14279 iter/s, 24.1383s/100 iter), loss = 0.0235263
I0703 00:42:26.771314 13779 solver.cpp:309]     Train net output #0: loss = 0.0235263 (* 1 = 0.0235263 loss)
I0703 00:42:26.771322 13779 sgd_solver.cpp:106] Iteration 21900, lr = 0.0001
I0703 00:42:50.687418 13779 solver.cpp:473] Iteration 22000, Testing net (#0)
I0703 00:43:37.313529 13779 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.95402
I0703 00:43:37.313572 13779 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.999995
I0703 00:43:37.313580 13779 solver.cpp:546]     Test net output #2: loss = 0.114859 (* 1 = 0.114859 loss)
I0703 00:43:37.588171 13779 solver.cpp:290] Iteration 22000 (1.41213 iter/s, 70.815s/100 iter), loss = 0.0302485
I0703 00:43:37.588196 13779 solver.cpp:309]     Train net output #0: loss = 0.0302485 (* 1 = 0.0302485 loss)
I0703 00:43:37.588202 13779 sgd_solver.cpp:106] Iteration 22000, lr = 0.0001
I0703 00:44:01.712959 13779 solver.cpp:290] Iteration 22100 (4.14523 iter/s, 24.1241s/100 iter), loss = 0.0302076
I0703 00:44:01.712982 13779 solver.cpp:309]     Train net output #0: loss = 0.0302076 (* 1 = 0.0302076 loss)
I0703 00:44:01.712990 13779 sgd_solver.cpp:106] Iteration 22100, lr = 0.0001
I0703 00:44:25.880208 13779 solver.cpp:290] Iteration 22200 (4.13795 iter/s, 24.1666s/100 iter), loss = 0.0277547
I0703 00:44:25.880281 13779 solver.cpp:309]     Train net output #0: loss = 0.0277548 (* 1 = 0.0277548 loss)
I0703 00:44:25.880296 13779 sgd_solver.cpp:106] Iteration 22200, lr = 0.0001
I0703 00:44:50.038023 13779 solver.cpp:290] Iteration 22300 (4.13957 iter/s, 24.1571s/100 iter), loss = 0.0215179
I0703 00:44:50.038046 13779 solver.cpp:309]     Train net output #0: loss = 0.0215179 (* 1 = 0.0215179 loss)
I0703 00:44:50.038053 13779 sgd_solver.cpp:106] Iteration 22300, lr = 0.0001
I0703 00:45:14.191702 13779 solver.cpp:290] Iteration 22400 (4.14027 iter/s, 24.153s/100 iter), loss = 0.0312096
I0703 00:45:14.191810 13779 solver.cpp:309]     Train net output #0: loss = 0.0312097 (* 1 = 0.0312097 loss)
I0703 00:45:14.191820 13779 sgd_solver.cpp:106] Iteration 22400, lr = 0.0001
I0703 00:45:38.394645 13779 solver.cpp:290] Iteration 22500 (4.13186 iter/s, 24.2022s/100 iter), loss = 0.0256189
I0703 00:45:38.394670 13779 solver.cpp:309]     Train net output #0: loss = 0.0256189 (* 1 = 0.0256189 loss)
I0703 00:45:38.394677 13779 sgd_solver.cpp:106] Iteration 22500, lr = 0.0001
I0703 00:46:02.560600 13779 solver.cpp:290] Iteration 22600 (4.13817 iter/s, 24.1653s/100 iter), loss = 0.0241531
I0703 00:46:02.560695 13779 solver.cpp:309]     Train net output #0: loss = 0.0241532 (* 1 = 0.0241532 loss)
I0703 00:46:02.560704 13779 sgd_solver.cpp:106] Iteration 22600, lr = 0.0001
I0703 00:46:26.731762 13779 solver.cpp:290] Iteration 22700 (4.13729 iter/s, 24.1704s/100 iter), loss = 0.0240193
I0703 00:46:26.731787 13779 solver.cpp:309]     Train net output #0: loss = 0.0240193 (* 1 = 0.0240193 loss)
I0703 00:46:26.731796 13779 sgd_solver.cpp:106] Iteration 22700, lr = 0.0001
I0703 00:46:51.028792 13779 solver.cpp:290] Iteration 22800 (4.11584 iter/s, 24.2964s/100 iter), loss = 0.0237118
I0703 00:46:51.028901 13779 solver.cpp:309]     Train net output #0: loss = 0.0237119 (* 1 = 0.0237119 loss)
I0703 00:46:51.028913 13779 sgd_solver.cpp:106] Iteration 22800, lr = 0.0001
I0703 00:47:15.192592 13779 solver.cpp:290] Iteration 22900 (4.13855 iter/s, 24.163s/100 iter), loss = 0.0393145
I0703 00:47:15.192615 13779 solver.cpp:309]     Train net output #0: loss = 0.0393145 (* 1 = 0.0393145 loss)
I0703 00:47:15.192623 13779 sgd_solver.cpp:106] Iteration 22900, lr = 0.0001
I0703 00:47:39.348197 13779 solver.cpp:290] Iteration 23000 (4.13994 iter/s, 24.1549s/100 iter), loss = 0.019752
I0703 00:47:39.348310 13779 solver.cpp:309]     Train net output #0: loss = 0.019752 (* 1 = 0.019752 loss)
I0703 00:47:39.348325 13779 sgd_solver.cpp:106] Iteration 23000, lr = 0.0001
I0703 00:48:03.523097 13779 solver.cpp:290] Iteration 23100 (4.13665 iter/s, 24.1741s/100 iter), loss = 0.0385317
I0703 00:48:03.523121 13779 solver.cpp:309]     Train net output #0: loss = 0.0385318 (* 1 = 0.0385318 loss)
I0703 00:48:03.523129 13779 sgd_solver.cpp:106] Iteration 23100, lr = 0.0001
I0703 00:48:27.702047 13779 solver.cpp:290] Iteration 23200 (4.13594 iter/s, 24.1783s/100 iter), loss = 0.0318874
I0703 00:48:27.702157 13779 solver.cpp:309]     Train net output #0: loss = 0.0318874 (* 1 = 0.0318874 loss)
I0703 00:48:27.702170 13779 sgd_solver.cpp:106] Iteration 23200, lr = 0.0001
I0703 00:48:51.863256 13779 solver.cpp:290] Iteration 23300 (4.13899 iter/s, 24.1605s/100 iter), loss = 0.0293132
I0703 00:48:51.863281 13779 solver.cpp:309]     Train net output #0: loss = 0.0293133 (* 1 = 0.0293133 loss)
I0703 00:48:51.863287 13779 sgd_solver.cpp:106] Iteration 23300, lr = 0.0001
I0703 00:49:16.072332 13779 solver.cpp:290] Iteration 23400 (4.1308 iter/s, 24.2084s/100 iter), loss = 0.0173989
I0703 00:49:16.072381 13779 solver.cpp:309]     Train net output #0: loss = 0.017399 (* 1 = 0.017399 loss)
I0703 00:49:16.072388 13779 sgd_solver.cpp:106] Iteration 23400, lr = 0.0001
I0703 00:49:40.226848 13779 solver.cpp:290] Iteration 23500 (4.14013 iter/s, 24.1538s/100 iter), loss = 0.0297203
I0703 00:49:40.226872 13779 solver.cpp:309]     Train net output #0: loss = 0.0297203 (* 1 = 0.0297203 loss)
I0703 00:49:40.226879 13779 sgd_solver.cpp:106] Iteration 23500, lr = 0.0001
I0703 00:50:04.383360 13779 solver.cpp:290] Iteration 23600 (4.13979 iter/s, 24.1558s/100 iter), loss = 0.031779
I0703 00:50:04.383484 13779 solver.cpp:309]     Train net output #0: loss = 0.031779 (* 1 = 0.031779 loss)
I0703 00:50:04.383497 13779 sgd_solver.cpp:106] Iteration 23600, lr = 0.0001
I0703 00:50:28.658576 13779 solver.cpp:290] Iteration 23700 (4.11956 iter/s, 24.2744s/100 iter), loss = 0.023689
I0703 00:50:28.658598 13779 solver.cpp:309]     Train net output #0: loss = 0.023689 (* 1 = 0.023689 loss)
I0703 00:50:28.658605 13779 sgd_solver.cpp:106] Iteration 23700, lr = 0.0001
I0703 00:50:52.904894 13779 solver.cpp:290] Iteration 23800 (4.12445 iter/s, 24.2456s/100 iter), loss = 0.0241522
I0703 00:50:52.905007 13779 solver.cpp:309]     Train net output #0: loss = 0.0241522 (* 1 = 0.0241522 loss)
I0703 00:50:52.905017 13779 sgd_solver.cpp:106] Iteration 23800, lr = 0.0001
I0703 00:51:17.045632 13779 solver.cpp:290] Iteration 23900 (4.1425 iter/s, 24.14s/100 iter), loss = 0.0395136
I0703 00:51:17.045655 13779 solver.cpp:309]     Train net output #0: loss = 0.0395136 (* 1 = 0.0395136 loss)
I0703 00:51:17.045662 13779 sgd_solver.cpp:106] Iteration 23900, lr = 0.0001
I0703 00:51:40.984131 13779 solver.cpp:473] Iteration 24000, Testing net (#0)
I0703 00:52:27.592610 13779 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.953694
I0703 00:52:27.592653 13779 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.999965
I0703 00:52:27.592659 13779 solver.cpp:546]     Test net output #2: loss = 0.124169 (* 1 = 0.124169 loss)
I0703 00:52:27.854789 13779 solver.cpp:290] Iteration 24000 (1.41228 iter/s, 70.8073s/100 iter), loss = 0.0264137
I0703 00:52:27.854801 13869 sgd_solver.cpp:46] MultiStep Status: Iteration 24000, step = 1
I0703 00:52:27.854813 13779 solver.cpp:309]     Train net output #0: loss = 0.0264137 (* 1 = 0.0264137 loss)
I0703 00:52:27.854820 13779 sgd_solver.cpp:46] MultiStep Status: Iteration 24000, step = 1
I0703 00:52:27.854823 13779 sgd_solver.cpp:106] Iteration 24000, lr = 1e-05
I0703 00:52:51.955360 13779 solver.cpp:290] Iteration 24100 (4.1494 iter/s, 24.0999s/100 iter), loss = 0.0166557
I0703 00:52:51.955384 13779 solver.cpp:309]     Train net output #0: loss = 0.0166557 (* 1 = 0.0166557 loss)
I0703 00:52:51.955391 13779 sgd_solver.cpp:106] Iteration 24100, lr = 1e-05
I0703 00:53:16.099674 13779 solver.cpp:290] Iteration 24200 (4.14188 iter/s, 24.1436s/100 iter), loss = 0.025538
I0703 00:53:16.099786 13779 solver.cpp:309]     Train net output #0: loss = 0.025538 (* 1 = 0.025538 loss)
I0703 00:53:16.099797 13779 sgd_solver.cpp:106] Iteration 24200, lr = 1e-05
I0703 00:53:40.249230 13779 solver.cpp:290] Iteration 24300 (4.14099 iter/s, 24.1488s/100 iter), loss = 0.0219485
I0703 00:53:40.249254 13779 solver.cpp:309]     Train net output #0: loss = 0.0219486 (* 1 = 0.0219486 loss)
I0703 00:53:40.249261 13779 sgd_solver.cpp:106] Iteration 24300, lr = 1e-05
I0703 00:54:04.514518 13779 solver.cpp:290] Iteration 24400 (4.12123 iter/s, 24.2646s/100 iter), loss = 0.018248
I0703 00:54:04.514633 13779 solver.cpp:309]     Train net output #0: loss = 0.018248 (* 1 = 0.018248 loss)
I0703 00:54:04.514643 13779 sgd_solver.cpp:106] Iteration 24400, lr = 1e-05
I0703 00:54:28.795617 13779 solver.cpp:290] Iteration 24500 (4.11856 iter/s, 24.2803s/100 iter), loss = 0.0319882
I0703 00:54:28.795642 13779 solver.cpp:309]     Train net output #0: loss = 0.0319882 (* 1 = 0.0319882 loss)
I0703 00:54:28.795650 13779 sgd_solver.cpp:106] Iteration 24500, lr = 1e-05
I0703 00:54:52.974011 13779 solver.cpp:290] Iteration 24600 (4.13604 iter/s, 24.1777s/100 iter), loss = 0.0235675
I0703 00:54:52.974123 13779 solver.cpp:309]     Train net output #0: loss = 0.0235675 (* 1 = 0.0235675 loss)
I0703 00:54:52.974133 13779 sgd_solver.cpp:106] Iteration 24600, lr = 1e-05
I0703 00:55:17.145627 13779 solver.cpp:290] Iteration 24700 (4.13721 iter/s, 24.1709s/100 iter), loss = 0.0308665
I0703 00:55:17.145649 13779 solver.cpp:309]     Train net output #0: loss = 0.0308665 (* 1 = 0.0308665 loss)
I0703 00:55:17.145656 13779 sgd_solver.cpp:106] Iteration 24700, lr = 1e-05
I0703 00:55:41.371948 13779 solver.cpp:290] Iteration 24800 (4.12786 iter/s, 24.2256s/100 iter), loss = 0.016625
I0703 00:55:41.372017 13779 solver.cpp:309]     Train net output #0: loss = 0.0166251 (* 1 = 0.0166251 loss)
I0703 00:55:41.372025 13779 sgd_solver.cpp:106] Iteration 24800, lr = 1e-05
I0703 00:56:05.521744 13779 solver.cpp:290] Iteration 24900 (4.14094 iter/s, 24.1491s/100 iter), loss = 0.0222772
I0703 00:56:05.521769 13779 solver.cpp:309]     Train net output #0: loss = 0.0222772 (* 1 = 0.0222772 loss)
I0703 00:56:05.521775 13779 sgd_solver.cpp:106] Iteration 24900, lr = 1e-05
I0703 00:56:29.671002 13779 solver.cpp:290] Iteration 25000 (4.14103 iter/s, 24.1486s/100 iter), loss = 0.0346808
I0703 00:56:29.671114 13779 solver.cpp:309]     Train net output #0: loss = 0.0346809 (* 1 = 0.0346809 loss)
I0703 00:56:29.671125 13779 sgd_solver.cpp:106] Iteration 25000, lr = 1e-05
I0703 00:56:53.839869 13779 solver.cpp:290] Iteration 25100 (4.13768 iter/s, 24.1681s/100 iter), loss = 0.0170978
I0703 00:56:53.839892 13779 solver.cpp:309]     Train net output #0: loss = 0.0170978 (* 1 = 0.0170978 loss)
I0703 00:56:53.839900 13779 sgd_solver.cpp:106] Iteration 25100, lr = 1e-05
I0703 00:57:18.009886 13779 solver.cpp:290] Iteration 25200 (4.13747 iter/s, 24.1694s/100 iter), loss = 0.0265607
I0703 00:57:18.009986 13779 solver.cpp:309]     Train net output #0: loss = 0.0265608 (* 1 = 0.0265608 loss)
I0703 00:57:18.009995 13779 sgd_solver.cpp:106] Iteration 25200, lr = 1e-05
I0703 00:57:42.279796 13779 solver.cpp:290] Iteration 25300 (4.12046 iter/s, 24.2692s/100 iter), loss = 0.04381
I0703 00:57:42.279820 13779 solver.cpp:309]     Train net output #0: loss = 0.04381 (* 1 = 0.04381 loss)
I0703 00:57:42.279827 13779 sgd_solver.cpp:106] Iteration 25300, lr = 1e-05
I0703 00:58:06.411377 13779 solver.cpp:290] Iteration 25400 (4.14406 iter/s, 24.1309s/100 iter), loss = 0.0175286
I0703 00:58:06.411432 13779 solver.cpp:309]     Train net output #0: loss = 0.0175286 (* 1 = 0.0175286 loss)
I0703 00:58:06.411440 13779 sgd_solver.cpp:106] Iteration 25400, lr = 1e-05
I0703 00:58:30.595194 13779 solver.cpp:290] Iteration 25500 (4.13512 iter/s, 24.1831s/100 iter), loss = 0.0307658
I0703 00:58:30.595218 13779 solver.cpp:309]     Train net output #0: loss = 0.0307658 (* 1 = 0.0307658 loss)
I0703 00:58:30.595226 13779 sgd_solver.cpp:106] Iteration 25500, lr = 1e-05
I0703 00:58:54.738919 13779 solver.cpp:290] Iteration 25600 (4.14198 iter/s, 24.1431s/100 iter), loss = 0.0323086
I0703 00:58:54.738977 13779 solver.cpp:309]     Train net output #0: loss = 0.0323086 (* 1 = 0.0323086 loss)
I0703 00:58:54.738986 13779 sgd_solver.cpp:106] Iteration 25600, lr = 1e-05
I0703 00:59:18.928082 13779 solver.cpp:290] Iteration 25700 (4.1342 iter/s, 24.1885s/100 iter), loss = 0.0330083
I0703 00:59:18.928107 13779 solver.cpp:309]     Train net output #0: loss = 0.0330083 (* 1 = 0.0330083 loss)
I0703 00:59:18.928114 13779 sgd_solver.cpp:106] Iteration 25700, lr = 1e-05
I0703 00:59:43.173612 13779 solver.cpp:290] Iteration 25800 (4.12459 iter/s, 24.2449s/100 iter), loss = 0.0307969
I0703 00:59:43.173717 13779 solver.cpp:309]     Train net output #0: loss = 0.0307969 (* 1 = 0.0307969 loss)
I0703 00:59:43.173727 13779 sgd_solver.cpp:106] Iteration 25800, lr = 1e-05
I0703 01:00:07.334487 13779 solver.cpp:290] Iteration 25900 (4.13905 iter/s, 24.1601s/100 iter), loss = 0.023846
I0703 01:00:07.334511 13779 solver.cpp:309]     Train net output #0: loss = 0.023846 (* 1 = 0.023846 loss)
I0703 01:00:07.334518 13779 sgd_solver.cpp:106] Iteration 25900, lr = 1e-05
I0703 01:00:31.264948 13779 solver.cpp:473] Iteration 26000, Testing net (#0)
I0703 01:01:20.933001 13779 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.954159
I0703 01:01:20.933184 13779 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.999975
I0703 01:01:20.933194 13779 solver.cpp:546]     Test net output #2: loss = 0.140118 (* 1 = 0.140118 loss)
I0703 01:01:21.188012 13779 solver.cpp:290] Iteration 26000 (1.35407 iter/s, 73.8515s/100 iter), loss = 0.023295
I0703 01:01:21.188064 13779 solver.cpp:309]     Train net output #0: loss = 0.023295 (* 1 = 0.023295 loss)
I0703 01:01:21.188087 13779 sgd_solver.cpp:106] Iteration 26000, lr = 1e-05
I0703 01:01:45.583776 13779 solver.cpp:290] Iteration 26100 (4.09919 iter/s, 24.3951s/100 iter), loss = 0.0169904
I0703 01:01:45.583799 13779 solver.cpp:309]     Train net output #0: loss = 0.0169904 (* 1 = 0.0169904 loss)
I0703 01:01:45.583806 13779 sgd_solver.cpp:106] Iteration 26100, lr = 1e-05
I0703 01:02:09.804961 13779 solver.cpp:290] Iteration 26200 (4.12873 iter/s, 24.2205s/100 iter), loss = 0.0262295
I0703 01:02:09.805073 13779 solver.cpp:309]     Train net output #0: loss = 0.0262296 (* 1 = 0.0262296 loss)
I0703 01:02:09.805083 13779 sgd_solver.cpp:106] Iteration 26200, lr = 1e-05
I0703 01:02:34.074272 13779 solver.cpp:290] Iteration 26300 (4.12056 iter/s, 24.2685s/100 iter), loss = 0.0335413
I0703 01:02:34.074295 13779 solver.cpp:309]     Train net output #0: loss = 0.0335413 (* 1 = 0.0335413 loss)
I0703 01:02:34.074302 13779 sgd_solver.cpp:106] Iteration 26300, lr = 1e-05
I0703 01:02:58.255046 13779 solver.cpp:290] Iteration 26400 (4.13563 iter/s, 24.1801s/100 iter), loss = 0.0183117
I0703 01:02:58.255156 13779 solver.cpp:309]     Train net output #0: loss = 0.0183117 (* 1 = 0.0183117 loss)
I0703 01:02:58.255167 13779 sgd_solver.cpp:106] Iteration 26400, lr = 1e-05
I0703 01:03:22.402809 13779 solver.cpp:290] Iteration 26500 (4.1413 iter/s, 24.147s/100 iter), loss = 0.025803
I0703 01:03:22.402837 13779 solver.cpp:309]     Train net output #0: loss = 0.025803 (* 1 = 0.025803 loss)
I0703 01:03:22.402846 13779 sgd_solver.cpp:106] Iteration 26500, lr = 1e-05
I0703 01:03:46.617785 13779 solver.cpp:290] Iteration 26600 (4.12979 iter/s, 24.2143s/100 iter), loss = 0.0400401
I0703 01:03:46.617869 13779 solver.cpp:309]     Train net output #0: loss = 0.0400401 (* 1 = 0.0400401 loss)
I0703 01:03:46.617879 13779 sgd_solver.cpp:106] Iteration 26600, lr = 1e-05
I0703 01:04:10.831933 13779 solver.cpp:290] Iteration 26700 (4.12994 iter/s, 24.2134s/100 iter), loss = 0.015901
I0703 01:04:10.831957 13779 solver.cpp:309]     Train net output #0: loss = 0.015901 (* 1 = 0.015901 loss)
I0703 01:04:10.831964 13779 sgd_solver.cpp:106] Iteration 26700, lr = 1e-05
I0703 01:04:34.998608 13779 solver.cpp:290] Iteration 26800 (4.13804 iter/s, 24.166s/100 iter), loss = 0.0292571
I0703 01:04:34.998661 13779 solver.cpp:309]     Train net output #0: loss = 0.0292571 (* 1 = 0.0292571 loss)
I0703 01:04:34.998669 13779 sgd_solver.cpp:106] Iteration 26800, lr = 1e-05
I0703 01:04:59.161015 13779 solver.cpp:290] Iteration 26900 (4.13878 iter/s, 24.1617s/100 iter), loss = 0.0303091
I0703 01:04:59.161039 13779 solver.cpp:309]     Train net output #0: loss = 0.0303091 (* 1 = 0.0303091 loss)
I0703 01:04:59.161046 13779 sgd_solver.cpp:106] Iteration 26900, lr = 1e-05
I0703 01:05:23.367312 13779 solver.cpp:290] Iteration 27000 (4.13127 iter/s, 24.2056s/100 iter), loss = 0.0264759
I0703 01:05:23.367422 13779 solver.cpp:309]     Train net output #0: loss = 0.0264759 (* 1 = 0.0264759 loss)
I0703 01:05:23.367432 13779 sgd_solver.cpp:106] Iteration 27000, lr = 1e-05
I0703 01:05:47.634969 13779 solver.cpp:290] Iteration 27100 (4.12084 iter/s, 24.2669s/100 iter), loss = 0.0245516
I0703 01:05:47.634997 13779 solver.cpp:309]     Train net output #0: loss = 0.0245516 (* 1 = 0.0245516 loss)
I0703 01:05:47.635004 13779 sgd_solver.cpp:106] Iteration 27100, lr = 1e-05
I0703 01:06:11.914808 13779 solver.cpp:290] Iteration 27200 (4.11876 iter/s, 24.2792s/100 iter), loss = 0.0314758
I0703 01:06:11.914919 13779 solver.cpp:309]     Train net output #0: loss = 0.0314758 (* 1 = 0.0314758 loss)
I0703 01:06:11.914930 13779 sgd_solver.cpp:106] Iteration 27200, lr = 1e-05
I0703 01:06:36.144637 13779 solver.cpp:290] Iteration 27300 (4.12727 iter/s, 24.2291s/100 iter), loss = 0.0211298
I0703 01:06:36.144661 13779 solver.cpp:309]     Train net output #0: loss = 0.0211298 (* 1 = 0.0211298 loss)
I0703 01:06:36.144668 13779 sgd_solver.cpp:106] Iteration 27300, lr = 1e-05
I0703 01:07:00.309785 13779 solver.cpp:290] Iteration 27400 (4.13831 iter/s, 24.1645s/100 iter), loss = 0.0255148
I0703 01:07:00.309914 13779 solver.cpp:309]     Train net output #0: loss = 0.0255148 (* 1 = 0.0255148 loss)
I0703 01:07:00.309924 13779 sgd_solver.cpp:106] Iteration 27400, lr = 1e-05
I0703 01:07:24.481238 13779 solver.cpp:290] Iteration 27500 (4.13724 iter/s, 24.1707s/100 iter), loss = 0.0331433
I0703 01:07:24.481261 13779 solver.cpp:309]     Train net output #0: loss = 0.0331434 (* 1 = 0.0331434 loss)
I0703 01:07:24.481268 13779 sgd_solver.cpp:106] Iteration 27500, lr = 1e-05
I0703 01:07:48.625279 13779 solver.cpp:290] Iteration 27600 (4.14193 iter/s, 24.1433s/100 iter), loss = 0.0282266
I0703 01:07:48.625329 13779 solver.cpp:309]     Train net output #0: loss = 0.0282267 (* 1 = 0.0282267 loss)
I0703 01:07:48.625339 13779 sgd_solver.cpp:106] Iteration 27600, lr = 1e-05
I0703 01:08:12.762171 13779 solver.cpp:290] Iteration 27700 (4.14316 iter/s, 24.1362s/100 iter), loss = 0.0249148
I0703 01:08:12.762193 13779 solver.cpp:309]     Train net output #0: loss = 0.0249148 (* 1 = 0.0249148 loss)
I0703 01:08:12.762200 13779 sgd_solver.cpp:106] Iteration 27700, lr = 1e-05
I0703 01:08:36.951421 13779 solver.cpp:290] Iteration 27800 (4.13419 iter/s, 24.1885s/100 iter), loss = 0.0229094
I0703 01:08:36.951489 13779 solver.cpp:309]     Train net output #0: loss = 0.0229094 (* 1 = 0.0229094 loss)
I0703 01:08:36.951498 13779 sgd_solver.cpp:106] Iteration 27800, lr = 1e-05
I0703 01:09:01.114390 13779 solver.cpp:290] Iteration 27900 (4.13869 iter/s, 24.1622s/100 iter), loss = 0.025317
I0703 01:09:01.114413 13779 solver.cpp:309]     Train net output #0: loss = 0.025317 (* 1 = 0.025317 loss)
I0703 01:09:01.114421 13779 sgd_solver.cpp:106] Iteration 27900, lr = 1e-05
I0703 01:09:25.057199 13779 solver.cpp:473] Iteration 28000, Testing net (#0)
I0703 01:10:11.582721 13779 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.954415
I0703 01:10:11.582805 13779 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.999785
I0703 01:10:11.582813 13779 solver.cpp:546]     Test net output #2: loss = 0.148606 (* 1 = 0.148606 loss)
I0703 01:10:11.833220 13779 solver.cpp:290] Iteration 28000 (1.41409 iter/s, 70.7168s/100 iter), loss = 0.0267997
I0703 01:10:11.833241 13779 solver.cpp:309]     Train net output #0: loss = 0.0267997 (* 1 = 0.0267997 loss)
I0703 01:10:11.833248 13779 sgd_solver.cpp:106] Iteration 28000, lr = 1e-05
I0703 01:10:35.319494 13779 solver.cpp:290] Iteration 28100 (4.25793 iter/s, 23.4856s/100 iter), loss = 0.0259186
I0703 01:10:35.319521 13779 solver.cpp:309]     Train net output #0: loss = 0.0259186 (* 1 = 0.0259186 loss)
I0703 01:10:35.319528 13779 sgd_solver.cpp:106] Iteration 28100, lr = 1e-05
I0703 01:10:59.505043 13779 solver.cpp:290] Iteration 28200 (4.13482 iter/s, 24.1848s/100 iter), loss = 0.0279785
I0703 01:10:59.505151 13779 solver.cpp:309]     Train net output #0: loss = 0.0279785 (* 1 = 0.0279785 loss)
I0703 01:10:59.505162 13779 sgd_solver.cpp:106] Iteration 28200, lr = 1e-05
I0703 01:11:23.743326 13779 solver.cpp:290] Iteration 28300 (4.12584 iter/s, 24.2375s/100 iter), loss = 0.0231631
I0703 01:11:23.743352 13779 solver.cpp:309]     Train net output #0: loss = 0.0231631 (* 1 = 0.0231631 loss)
I0703 01:11:23.743360 13779 sgd_solver.cpp:106] Iteration 28300, lr = 1e-05
I0703 01:11:47.998965 13779 solver.cpp:290] Iteration 28400 (4.12288 iter/s, 24.2549s/100 iter), loss = 0.0194882
I0703 01:11:47.999053 13779 solver.cpp:309]     Train net output #0: loss = 0.0194882 (* 1 = 0.0194882 loss)
I0703 01:11:47.999074 13779 sgd_solver.cpp:106] Iteration 28400, lr = 1e-05
I0703 01:12:12.329766 13779 solver.cpp:290] Iteration 28500 (4.11015 iter/s, 24.33s/100 iter), loss = 0.0267676
I0703 01:12:12.329789 13779 solver.cpp:309]     Train net output #0: loss = 0.0267676 (* 1 = 0.0267676 loss)
I0703 01:12:12.329797 13779 sgd_solver.cpp:106] Iteration 28500, lr = 1e-05
I0703 01:12:36.550221 13779 solver.cpp:290] Iteration 28600 (4.12886 iter/s, 24.2197s/100 iter), loss = 0.0166107
I0703 01:12:36.550294 13779 solver.cpp:309]     Train net output #0: loss = 0.0166107 (* 1 = 0.0166107 loss)
I0703 01:12:36.550303 13779 sgd_solver.cpp:106] Iteration 28600, lr = 1e-05
I0703 01:13:00.796172 13779 solver.cpp:290] Iteration 28700 (4.12453 iter/s, 24.2452s/100 iter), loss = 0.0298468
I0703 01:13:00.796196 13779 solver.cpp:309]     Train net output #0: loss = 0.0298468 (* 1 = 0.0298468 loss)
I0703 01:13:00.796203 13779 sgd_solver.cpp:106] Iteration 28700, lr = 1e-05
I0703 01:13:25.012809 13779 solver.cpp:290] Iteration 28800 (4.12951 iter/s, 24.2159s/100 iter), loss = 0.0199554
I0703 01:13:25.012955 13779 solver.cpp:309]     Train net output #0: loss = 0.0199554 (* 1 = 0.0199554 loss)
I0703 01:13:25.012976 13779 sgd_solver.cpp:106] Iteration 28800, lr = 1e-05
I0703 01:13:49.228834 13779 solver.cpp:290] Iteration 28900 (4.12964 iter/s, 24.2152s/100 iter), loss = 0.020952
I0703 01:13:49.228857 13779 solver.cpp:309]     Train net output #0: loss = 0.020952 (* 1 = 0.020952 loss)
I0703 01:13:49.228864 13779 sgd_solver.cpp:106] Iteration 28900, lr = 1e-05
I0703 01:14:13.412087 13779 solver.cpp:290] Iteration 29000 (4.13521 iter/s, 24.1826s/100 iter), loss = 0.0200087
I0703 01:14:13.412194 13779 solver.cpp:309]     Train net output #0: loss = 0.0200087 (* 1 = 0.0200087 loss)
I0703 01:14:13.412204 13779 sgd_solver.cpp:106] Iteration 29000, lr = 1e-05
I0703 01:14:37.563202 13779 solver.cpp:290] Iteration 29100 (4.14073 iter/s, 24.1503s/100 iter), loss = 0.0165588
I0703 01:14:37.563227 13779 solver.cpp:309]     Train net output #0: loss = 0.0165588 (* 1 = 0.0165588 loss)
I0703 01:14:37.563235 13779 sgd_solver.cpp:106] Iteration 29100, lr = 1e-05
I0703 01:15:01.743239 13779 solver.cpp:290] Iteration 29200 (4.13576 iter/s, 24.1793s/100 iter), loss = 0.0347305
I0703 01:15:01.743342 13779 solver.cpp:309]     Train net output #0: loss = 0.0347305 (* 1 = 0.0347305 loss)
I0703 01:15:01.743357 13779 sgd_solver.cpp:106] Iteration 29200, lr = 1e-05
I0703 01:15:25.900540 13779 solver.cpp:290] Iteration 29300 (4.13967 iter/s, 24.1565s/100 iter), loss = 0.0355822
I0703 01:15:25.900564 13779 solver.cpp:309]     Train net output #0: loss = 0.0355822 (* 1 = 0.0355822 loss)
I0703 01:15:25.900571 13779 sgd_solver.cpp:106] Iteration 29300, lr = 1e-05
I0703 01:15:50.065194 13779 solver.cpp:290] Iteration 29400 (4.13839 iter/s, 24.164s/100 iter), loss = 0.0254183
I0703 01:15:50.065312 13779 solver.cpp:309]     Train net output #0: loss = 0.0254183 (* 1 = 0.0254183 loss)
I0703 01:15:50.065326 13779 sgd_solver.cpp:106] Iteration 29400, lr = 1e-05
I0703 01:16:14.289355 13779 solver.cpp:290] Iteration 29500 (4.12825 iter/s, 24.2234s/100 iter), loss = 0.0274391
I0703 01:16:14.289399 13779 solver.cpp:309]     Train net output #0: loss = 0.0274391 (* 1 = 0.0274391 loss)
I0703 01:16:14.289415 13779 sgd_solver.cpp:106] Iteration 29500, lr = 1e-05
I0703 01:16:38.668822 13779 solver.cpp:290] Iteration 29600 (4.10193 iter/s, 24.3787s/100 iter), loss = 0.0219041
I0703 01:16:38.668931 13779 solver.cpp:309]     Train net output #0: loss = 0.0219041 (* 1 = 0.0219041 loss)
I0703 01:16:38.668942 13779 sgd_solver.cpp:106] Iteration 29600, lr = 1e-05
I0703 01:17:02.981750 13779 solver.cpp:290] Iteration 29700 (4.11317 iter/s, 24.3121s/100 iter), loss = 0.0288469
I0703 01:17:02.981775 13779 solver.cpp:309]     Train net output #0: loss = 0.0288469 (* 1 = 0.0288469 loss)
I0703 01:17:02.981781 13779 sgd_solver.cpp:106] Iteration 29700, lr = 1e-05
I0703 01:17:27.147462 13779 solver.cpp:290] Iteration 29800 (4.13821 iter/s, 24.165s/100 iter), loss = 0.0273427
I0703 01:17:27.147570 13779 solver.cpp:309]     Train net output #0: loss = 0.0273427 (* 1 = 0.0273427 loss)
I0703 01:17:27.147584 13779 sgd_solver.cpp:106] Iteration 29800, lr = 1e-05
I0703 01:17:51.373028 13779 solver.cpp:290] Iteration 29900 (4.128 iter/s, 24.2248s/100 iter), loss = 0.0245696
I0703 01:17:51.373051 13779 solver.cpp:309]     Train net output #0: loss = 0.0245696 (* 1 = 0.0245696 loss)
I0703 01:17:51.373059 13779 sgd_solver.cpp:106] Iteration 29900, lr = 1e-05
I0703 01:18:15.271648 13779 solver.cpp:600] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-07-02_23-02-42/initial/cityscapes5_jsegnet21v2_iter_30000.caffemodel
I0703 01:18:15.299340 13779 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-07-02_23-02-42/initial/cityscapes5_jsegnet21v2_iter_30000.solverstate
I0703 01:18:15.316315 13779 solver.cpp:473] Iteration 30000, Testing net (#0)
I0703 01:19:01.967605 13779 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.954793
I0703 01:19:01.967695 13779 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.999793
I0703 01:19:01.967706 13779 solver.cpp:546]     Test net output #2: loss = 0.146515 (* 1 = 0.146515 loss)
I0703 01:19:02.219898 13779 solver.cpp:290] Iteration 30000 (1.41153 iter/s, 70.8449s/100 iter), loss = 0.0254025
I0703 01:19:02.219925 13779 solver.cpp:309]     Train net output #0: loss = 0.0254025 (* 1 = 0.0254025 loss)
I0703 01:19:02.219933 13779 sgd_solver.cpp:106] Iteration 30000, lr = 1e-05
I0703 01:19:25.698051 13779 solver.cpp:290] Iteration 30100 (4.2594 iter/s, 23.4775s/100 iter), loss = 0.0261522
I0703 01:19:25.698074 13779 solver.cpp:309]     Train net output #0: loss = 0.0261522 (* 1 = 0.0261522 loss)
I0703 01:19:25.698082 13779 sgd_solver.cpp:106] Iteration 30100, lr = 1e-05
I0703 01:19:49.889587 13779 solver.cpp:290] Iteration 30200 (4.1338 iter/s, 24.1908s/100 iter), loss = 0.0267954
I0703 01:19:49.889695 13779 solver.cpp:309]     Train net output #0: loss = 0.0267954 (* 1 = 0.0267954 loss)
I0703 01:19:49.889706 13779 sgd_solver.cpp:106] Iteration 30200, lr = 1e-05
I0703 01:20:14.066532 13779 solver.cpp:290] Iteration 30300 (4.13631 iter/s, 24.1762s/100 iter), loss = 0.0285043
I0703 01:20:14.066560 13779 solver.cpp:309]     Train net output #0: loss = 0.0285043 (* 1 = 0.0285043 loss)
I0703 01:20:14.066567 13779 sgd_solver.cpp:106] Iteration 30300, lr = 1e-05
I0703 01:20:38.212982 13779 solver.cpp:290] Iteration 30400 (4.14152 iter/s, 24.1457s/100 iter), loss = 0.0350156
I0703 01:20:38.213083 13779 solver.cpp:309]     Train net output #0: loss = 0.0350156 (* 1 = 0.0350156 loss)
I0703 01:20:38.213093 13779 sgd_solver.cpp:106] Iteration 30400, lr = 1e-05
I0703 01:21:02.402736 13779 solver.cpp:290] Iteration 30500 (4.13411 iter/s, 24.189s/100 iter), loss = 0.0293875
I0703 01:21:02.402760 13779 solver.cpp:309]     Train net output #0: loss = 0.0293875 (* 1 = 0.0293875 loss)
I0703 01:21:02.402766 13779 sgd_solver.cpp:106] Iteration 30500, lr = 1e-05
I0703 01:21:26.568475 13779 solver.cpp:290] Iteration 30600 (4.13821 iter/s, 24.165s/100 iter), loss = 0.0210223
I0703 01:21:26.568514 13779 solver.cpp:309]     Train net output #0: loss = 0.0210223 (* 1 = 0.0210223 loss)
I0703 01:21:26.568522 13779 sgd_solver.cpp:106] Iteration 30600, lr = 1e-05
I0703 01:21:50.728703 13779 solver.cpp:290] Iteration 30700 (4.13915 iter/s, 24.1595s/100 iter), loss = 0.0304843
I0703 01:21:50.728729 13779 solver.cpp:309]     Train net output #0: loss = 0.0304843 (* 1 = 0.0304843 loss)
I0703 01:21:50.728737 13779 sgd_solver.cpp:106] Iteration 30700, lr = 1e-05
I0703 01:22:14.917178 13779 solver.cpp:290] Iteration 30800 (4.13432 iter/s, 24.1878s/100 iter), loss = 0.0233428
I0703 01:22:14.917291 13779 solver.cpp:309]     Train net output #0: loss = 0.0233428 (* 1 = 0.0233428 loss)
I0703 01:22:14.917302 13779 sgd_solver.cpp:106] Iteration 30800, lr = 1e-05
I0703 01:22:39.075938 13779 solver.cpp:290] Iteration 30900 (4.13942 iter/s, 24.158s/100 iter), loss = 0.0420963
I0703 01:22:39.075961 13779 solver.cpp:309]     Train net output #0: loss = 0.0420963 (* 1 = 0.0420963 loss)
I0703 01:22:39.075968 13779 sgd_solver.cpp:106] Iteration 30900, lr = 1e-05
I0703 01:23:03.208891 13779 solver.cpp:290] Iteration 31000 (4.14383 iter/s, 24.1323s/100 iter), loss = 0.0348484
I0703 01:23:03.209002 13779 solver.cpp:309]     Train net output #0: loss = 0.0348484 (* 1 = 0.0348484 loss)
I0703 01:23:03.209012 13779 sgd_solver.cpp:106] Iteration 31000, lr = 1e-05
I0703 01:23:27.361438 13779 solver.cpp:290] Iteration 31100 (4.14048 iter/s, 24.1518s/100 iter), loss = 0.0247979
I0703 01:23:27.361462 13779 solver.cpp:309]     Train net output #0: loss = 0.0247979 (* 1 = 0.0247979 loss)
I0703 01:23:27.361469 13779 sgd_solver.cpp:106] Iteration 31100, lr = 1e-05
I0703 01:23:51.520144 13779 solver.cpp:290] Iteration 31200 (4.13941 iter/s, 24.158s/100 iter), loss = 0.0189387
I0703 01:23:51.530369 13779 solver.cpp:309]     Train net output #0: loss = 0.0189387 (* 1 = 0.0189387 loss)
I0703 01:23:51.530416 13779 sgd_solver.cpp:106] Iteration 31200, lr = 1e-05
I0703 01:24:15.676286 13779 solver.cpp:290] Iteration 31300 (4.14159 iter/s, 24.1453s/100 iter), loss = 0.0274857
I0703 01:24:15.676309 13779 solver.cpp:309]     Train net output #0: loss = 0.0274857 (* 1 = 0.0274857 loss)
I0703 01:24:15.676317 13779 sgd_solver.cpp:106] Iteration 31300, lr = 1e-05
I0703 01:24:39.892921 13779 solver.cpp:290] Iteration 31400 (4.12951 iter/s, 24.216s/100 iter), loss = 0.0190852
I0703 01:24:39.892966 13779 solver.cpp:309]     Train net output #0: loss = 0.0190852 (* 1 = 0.0190852 loss)
I0703 01:24:39.892973 13779 sgd_solver.cpp:106] Iteration 31400, lr = 1e-05
I0703 01:25:04.046023 13779 solver.cpp:290] Iteration 31500 (4.14038 iter/s, 24.1524s/100 iter), loss = 0.0159122
I0703 01:25:04.046046 13779 solver.cpp:309]     Train net output #0: loss = 0.0159122 (* 1 = 0.0159122 loss)
I0703 01:25:04.046054 13779 sgd_solver.cpp:106] Iteration 31500, lr = 1e-05
I0703 01:25:28.214152 13779 solver.cpp:290] Iteration 31600 (4.1378 iter/s, 24.1674s/100 iter), loss = 0.0258262
I0703 01:25:28.214258 13779 solver.cpp:309]     Train net output #0: loss = 0.0258262 (* 1 = 0.0258262 loss)
I0703 01:25:28.214268 13779 sgd_solver.cpp:106] Iteration 31600, lr = 1e-05
I0703 01:25:52.359244 13779 solver.cpp:290] Iteration 31700 (4.14176 iter/s, 24.1443s/100 iter), loss = 0.0250027
I0703 01:25:52.359271 13779 solver.cpp:309]     Train net output #0: loss = 0.0250027 (* 1 = 0.0250027 loss)
I0703 01:25:52.359279 13779 sgd_solver.cpp:106] Iteration 31700, lr = 1e-05
I0703 01:26:16.509021 13779 solver.cpp:290] Iteration 31800 (4.14094 iter/s, 24.1491s/100 iter), loss = 0.02098
I0703 01:26:16.509145 13779 solver.cpp:309]     Train net output #0: loss = 0.02098 (* 1 = 0.02098 loss)
I0703 01:26:16.509160 13779 sgd_solver.cpp:106] Iteration 31800, lr = 1e-05
I0703 01:26:40.711241 13779 solver.cpp:290] Iteration 31900 (4.13199 iter/s, 24.2014s/100 iter), loss = 0.0164478
I0703 01:26:40.711263 13779 solver.cpp:309]     Train net output #0: loss = 0.0164478 (* 1 = 0.0164478 loss)
I0703 01:26:40.711271 13779 sgd_solver.cpp:106] Iteration 31900, lr = 1e-05
I0703 01:27:04.672876 13779 solver.cpp:600] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-07-02_23-02-42/initial/cityscapes5_jsegnet21v2_iter_32000.caffemodel
I0703 01:27:04.697863 13779 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-07-02_23-02-42/initial/cityscapes5_jsegnet21v2_iter_32000.solverstate
I0703 01:27:04.783983 13779 solver.cpp:453] Iteration 32000, loss = 0.0203892
I0703 01:27:04.784005 13779 solver.cpp:473] Iteration 32000, Testing net (#0)
I0703 01:27:51.328760 13779 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.955501
I0703 01:27:51.328833 13779 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.999708
I0703 01:27:51.328840 13779 solver.cpp:546]     Test net output #2: loss = 0.141078 (* 1 = 0.141078 loss)
I0703 01:27:51.328843 13779 solver.cpp:458] Optimization Done.
I0703 01:27:51.446749 13779 caffe.cpp:246] Optimization Done.
