I0711 18:09:29.790408  7290 caffe.cpp:209] Using GPUs 0, 1, 2
I0711 18:09:29.790868  7290 caffe.cpp:214] GPU 0: GeForce GTX 1080
I0711 18:09:29.791204  7290 caffe.cpp:214] GPU 1: GeForce GTX 1080
I0711 18:09:29.791538  7290 caffe.cpp:214] GPU 2: GeForce GTX 1080
I0711 18:09:31.132441  7290 solver.cpp:48] Initializing solver from parameters: 
train_net: "training/cityscapes5_jsegnet21v2_2017-07-11_18-09-28/initial/train.prototxt"
test_net: "training/cityscapes5_jsegnet21v2_2017-07-11_18-09-28/initial/test.prototxt"
test_iter: 125
test_interval: 2000
base_lr: 0.0001
display: 100
max_iter: 32000
lr_policy: "multistep"
gamma: 0.1
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 10000
snapshot_prefix: "training/cityscapes5_jsegnet21v2_2017-07-11_18-09-28/initial/cityscapes5_jsegnet21v2"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
snapshot_after_train: true
test_initialization: false
stepvalue: 24000
iter_size: 1
type: "Adam"
I0711 18:09:31.132540  7290 solver.cpp:82] Creating training net from train_net file: training/cityscapes5_jsegnet21v2_2017-07-11_18-09-28/initial/train.prototxt
I0711 18:09:31.133242  7290 net.cpp:327] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top1
I0711 18:09:31.133249  7290 net.cpp:327] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top5
I0711 18:09:31.133507  7290 net.cpp:56] Initializing net from parameters: 
name: "jsegnet21v2_train"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageLabelData"
  top: "data"
  top: "label"
  transform_param {
    mirror: true
    crop_size: 640
    mean_value: 0
  }
  image_label_data_param {
    image_list_path: "data/train-image-lmdb"
    label_list_path: "data/train-label-lmdb"
    batch_size: 5
    shuffle: false
    threads: 4
    backend: LMDB
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a/bn"
  top: "conv1a/bn"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a/bn"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b/bn"
  top: "conv1b/bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b/bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2a/bn"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b/bn"
  top: "res2a_branch2b/bn"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b/bn"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2a/bn"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b/bn"
  top: "res3a_branch2b/bn"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b/bn"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2a/bn"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b/bn"
  top: "res4a_branch2b/bn"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b/bn"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2a/bn"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b/bn"
  top: "res5a_branch2b/bn"
}
layer {
  name: "out5a"
  type: "Convolution"
  bottom: "res5a_branch2b/bn"
  top: "out5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "out5a/bn"
  type: "BatchNorm"
  bottom: "out5a"
  top: "out5a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "out5a/relu"
  type: "ReLU"
  bottom: "out5a/bn"
  top: "out5a/bn"
}
layer {
  name: "out5a_up2"
  type: "Deconvolution"
  bottom: "out5a/bn"
  top: "out5a_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 64
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out3a"
  type: "Convolution"
  bottom: "res3a_branch2b/bn"
  top: "out3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "out3a/bn"
  type: "BatchNorm"
  bottom: "out3a"
  top: "out3a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "out3a/relu"
  type: "ReLU"
  bottom: "out3a/bn"
  top: "out3a/bn"
}
layer {
  name: "out3_out5_combined"
  type: "Eltwise"
  bottom: "out5a_up2"
  bottom: "out3a/bn"
  top: "out3_out5_combined"
}
layer {
  name: "ctx_conv1"
  type: "Convolution"
  bottom: "out3_out5_combined"
  top: "ctx_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_conv1/bn"
  type: "BatchNorm"
  bottom: "ctx_conv1"
  top: "ctx_conv1/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ctx_conv1/relu"
  type: "ReLU"
  bottom: "ctx_conv1/bn"
  top: "ctx_conv1/bn"
}
layer {
  name: "ctx_conv2"
  type: "Convolution"
  bottom: "ctx_conv1/bn"
  top: "ctx_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv2/bn"
  type: "BatchNorm"
  bottom: "ctx_conv2"
  top: "ctx_conv2/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ctx_conv2/relu"
  type: "ReLU"
  bottom: "ctx_conv2/bn"
  top: "ctx_conv2/bn"
}
layer {
  name: "ctx_conv3"
  type: "Convolution"
  bottom: "ctx_conv2/bn"
  top: "ctx_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv3/bn"
  type: "BatchNorm"
  bottom: "ctx_conv3"
  top: "ctx_conv3/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ctx_conv3/relu"
  type: "ReLU"
  bottom: "ctx_conv3/bn"
  top: "ctx_conv3/bn"
}
layer {
  name: "ctx_conv4"
  type: "Convolution"
  bottom: "ctx_conv3/bn"
  top: "ctx_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv4/bn"
  type: "BatchNorm"
  bottom: "ctx_conv4"
  top: "ctx_conv4/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ctx_conv4/relu"
  type: "ReLU"
  bottom: "ctx_conv4/bn"
  top: "ctx_conv4/bn"
}
layer {
  name: "ctx_final"
  type: "Convolution"
  bottom: "ctx_conv4/bn"
  top: "ctx_final"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_final/relu"
  type: "ReLU"
  bottom: "ctx_final"
  top: "ctx_final"
}
layer {
  name: "out_deconv_final_up2"
  type: "Deconvolution"
  bottom: "ctx_final"
  top: "out_deconv_final_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up4"
  type: "Deconvolution"
  bottom: "out_deconv_final_up2"
  top: "out_deconv_final_up4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up8"
  type: "Deconvolution"
  bottom: "out_deconv_final_up4"
  top: "out_deconv_final_up8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: 255
    normalization: VALID
  }
}
I0711 18:09:31.133642  7290 layer_factory.hpp:77] Creating layer data
I0711 18:09:31.133656  7290 net.cpp:98] Creating Layer data
I0711 18:09:31.133659  7290 net.cpp:413] data -> data
I0711 18:09:31.133675  7290 net.cpp:413] data -> label
I0711 18:09:31.135936  7342 db_lmdb.cpp:35] Opened lmdb data/train-image-lmdb
I0711 18:09:31.165035  7347 db_lmdb.cpp:35] Opened lmdb data/train-label-lmdb
I0711 18:09:31.225064  7290 data_layer.cpp:78] ReshapePrefetch 5, 3, 640, 640
I0711 18:09:31.225127  7290 data_layer.cpp:83] output data size: 5,3,640,640
I0711 18:09:31.253641  7290 data_layer.cpp:78] ReshapePrefetch 5, 1, 640, 640
I0711 18:09:31.253711  7290 data_layer.cpp:83] output data size: 5,1,640,640
I0711 18:09:31.263092  7352 blocking_queue.cpp:50] Waiting for data
I0711 18:09:31.294282  7290 net.cpp:148] Setting up data
I0711 18:09:31.294306  7290 net.cpp:155] Top shape: 5 3 640 640 (6144000)
I0711 18:09:31.294308  7290 net.cpp:155] Top shape: 5 1 640 640 (2048000)
I0711 18:09:31.294311  7290 net.cpp:163] Memory required for data: 32768000
I0711 18:09:31.294317  7290 layer_factory.hpp:77] Creating layer data/bias
I0711 18:09:31.294332  7290 net.cpp:98] Creating Layer data/bias
I0711 18:09:31.294337  7290 net.cpp:439] data/bias <- data
I0711 18:09:31.294347  7290 net.cpp:413] data/bias -> data/bias
I0711 18:09:31.295812  7290 net.cpp:148] Setting up data/bias
I0711 18:09:31.295826  7290 net.cpp:155] Top shape: 5 3 640 640 (6144000)
I0711 18:09:31.295828  7290 net.cpp:163] Memory required for data: 57344000
I0711 18:09:31.295840  7290 layer_factory.hpp:77] Creating layer conv1a
I0711 18:09:31.295855  7290 net.cpp:98] Creating Layer conv1a
I0711 18:09:31.295866  7290 net.cpp:439] conv1a <- data/bias
I0711 18:09:31.295872  7290 net.cpp:413] conv1a -> conv1a
I0711 18:09:31.297780  7290 net.cpp:148] Setting up conv1a
I0711 18:09:31.297801  7290 net.cpp:155] Top shape: 5 32 320 320 (16384000)
I0711 18:09:31.297804  7290 net.cpp:163] Memory required for data: 122880000
I0711 18:09:31.297812  7290 layer_factory.hpp:77] Creating layer conv1a/bn
I0711 18:09:31.297821  7290 net.cpp:98] Creating Layer conv1a/bn
I0711 18:09:31.297827  7290 net.cpp:439] conv1a/bn <- conv1a
I0711 18:09:31.297832  7290 net.cpp:413] conv1a/bn -> conv1a/bn
I0711 18:09:31.299615  7290 net.cpp:148] Setting up conv1a/bn
I0711 18:09:31.299628  7290 net.cpp:155] Top shape: 5 32 320 320 (16384000)
I0711 18:09:31.299631  7290 net.cpp:163] Memory required for data: 188416000
I0711 18:09:31.299638  7290 layer_factory.hpp:77] Creating layer conv1a/relu
I0711 18:09:31.299643  7290 net.cpp:98] Creating Layer conv1a/relu
I0711 18:09:31.299645  7290 net.cpp:439] conv1a/relu <- conv1a/bn
I0711 18:09:31.299649  7290 net.cpp:400] conv1a/relu -> conv1a/bn (in-place)
I0711 18:09:31.299662  7290 net.cpp:148] Setting up conv1a/relu
I0711 18:09:31.299665  7290 net.cpp:155] Top shape: 5 32 320 320 (16384000)
I0711 18:09:31.299679  7290 net.cpp:163] Memory required for data: 253952000
I0711 18:09:31.299681  7290 layer_factory.hpp:77] Creating layer conv1b
I0711 18:09:31.299690  7290 net.cpp:98] Creating Layer conv1b
I0711 18:09:31.299695  7290 net.cpp:439] conv1b <- conv1a/bn
I0711 18:09:31.299700  7290 net.cpp:413] conv1b -> conv1b
I0711 18:09:31.300189  7290 net.cpp:148] Setting up conv1b
I0711 18:09:31.300195  7290 net.cpp:155] Top shape: 5 32 320 320 (16384000)
I0711 18:09:31.300199  7290 net.cpp:163] Memory required for data: 319488000
I0711 18:09:31.300202  7290 layer_factory.hpp:77] Creating layer conv1b/bn
I0711 18:09:31.300206  7290 net.cpp:98] Creating Layer conv1b/bn
I0711 18:09:31.300209  7290 net.cpp:439] conv1b/bn <- conv1b
I0711 18:09:31.300211  7290 net.cpp:413] conv1b/bn -> conv1b/bn
I0711 18:09:31.301023  7290 net.cpp:148] Setting up conv1b/bn
I0711 18:09:31.301030  7290 net.cpp:155] Top shape: 5 32 320 320 (16384000)
I0711 18:09:31.301033  7290 net.cpp:163] Memory required for data: 385024000
I0711 18:09:31.301038  7290 layer_factory.hpp:77] Creating layer conv1b/relu
I0711 18:09:31.301040  7290 net.cpp:98] Creating Layer conv1b/relu
I0711 18:09:31.301043  7290 net.cpp:439] conv1b/relu <- conv1b/bn
I0711 18:09:31.301045  7290 net.cpp:400] conv1b/relu -> conv1b/bn (in-place)
I0711 18:09:31.301049  7290 net.cpp:148] Setting up conv1b/relu
I0711 18:09:31.301051  7290 net.cpp:155] Top shape: 5 32 320 320 (16384000)
I0711 18:09:31.301054  7290 net.cpp:163] Memory required for data: 450560000
I0711 18:09:31.301055  7290 layer_factory.hpp:77] Creating layer pool1
I0711 18:09:31.301060  7290 net.cpp:98] Creating Layer pool1
I0711 18:09:31.301062  7290 net.cpp:439] pool1 <- conv1b/bn
I0711 18:09:31.301064  7290 net.cpp:413] pool1 -> pool1
I0711 18:09:31.301126  7290 net.cpp:148] Setting up pool1
I0711 18:09:31.301133  7290 net.cpp:155] Top shape: 5 32 160 160 (4096000)
I0711 18:09:31.301136  7290 net.cpp:163] Memory required for data: 466944000
I0711 18:09:31.301139  7290 layer_factory.hpp:77] Creating layer res2a_branch2a
I0711 18:09:31.301146  7290 net.cpp:98] Creating Layer res2a_branch2a
I0711 18:09:31.301149  7290 net.cpp:439] res2a_branch2a <- pool1
I0711 18:09:31.301154  7290 net.cpp:413] res2a_branch2a -> res2a_branch2a
I0711 18:09:31.302872  7290 net.cpp:148] Setting up res2a_branch2a
I0711 18:09:31.302883  7290 net.cpp:155] Top shape: 5 64 160 160 (8192000)
I0711 18:09:31.302886  7290 net.cpp:163] Memory required for data: 499712000
I0711 18:09:31.302891  7290 layer_factory.hpp:77] Creating layer res2a_branch2a/bn
I0711 18:09:31.302896  7290 net.cpp:98] Creating Layer res2a_branch2a/bn
I0711 18:09:31.302898  7290 net.cpp:439] res2a_branch2a/bn <- res2a_branch2a
I0711 18:09:31.302902  7290 net.cpp:413] res2a_branch2a/bn -> res2a_branch2a/bn
I0711 18:09:31.303670  7290 net.cpp:148] Setting up res2a_branch2a/bn
I0711 18:09:31.303678  7290 net.cpp:155] Top shape: 5 64 160 160 (8192000)
I0711 18:09:31.303680  7290 net.cpp:163] Memory required for data: 532480000
I0711 18:09:31.303688  7290 layer_factory.hpp:77] Creating layer res2a_branch2a/relu
I0711 18:09:31.303692  7290 net.cpp:98] Creating Layer res2a_branch2a/relu
I0711 18:09:31.303696  7290 net.cpp:439] res2a_branch2a/relu <- res2a_branch2a/bn
I0711 18:09:31.303701  7290 net.cpp:400] res2a_branch2a/relu -> res2a_branch2a/bn (in-place)
I0711 18:09:31.303707  7290 net.cpp:148] Setting up res2a_branch2a/relu
I0711 18:09:31.303712  7290 net.cpp:155] Top shape: 5 64 160 160 (8192000)
I0711 18:09:31.303715  7290 net.cpp:163] Memory required for data: 565248000
I0711 18:09:31.303719  7290 layer_factory.hpp:77] Creating layer res2a_branch2b
I0711 18:09:31.303725  7290 net.cpp:98] Creating Layer res2a_branch2b
I0711 18:09:31.303730  7290 net.cpp:439] res2a_branch2b <- res2a_branch2a/bn
I0711 18:09:31.303735  7290 net.cpp:413] res2a_branch2b -> res2a_branch2b
I0711 18:09:31.305222  7290 net.cpp:148] Setting up res2a_branch2b
I0711 18:09:31.305232  7290 net.cpp:155] Top shape: 5 64 160 160 (8192000)
I0711 18:09:31.305234  7290 net.cpp:163] Memory required for data: 598016000
I0711 18:09:31.305240  7290 layer_factory.hpp:77] Creating layer res2a_branch2b/bn
I0711 18:09:31.305248  7290 net.cpp:98] Creating Layer res2a_branch2b/bn
I0711 18:09:31.305253  7290 net.cpp:439] res2a_branch2b/bn <- res2a_branch2b
I0711 18:09:31.305258  7290 net.cpp:413] res2a_branch2b/bn -> res2a_branch2b/bn
I0711 18:09:31.306046  7290 net.cpp:148] Setting up res2a_branch2b/bn
I0711 18:09:31.306053  7290 net.cpp:155] Top shape: 5 64 160 160 (8192000)
I0711 18:09:31.306056  7290 net.cpp:163] Memory required for data: 630784000
I0711 18:09:31.306063  7290 layer_factory.hpp:77] Creating layer res2a_branch2b/relu
I0711 18:09:31.306069  7290 net.cpp:98] Creating Layer res2a_branch2b/relu
I0711 18:09:31.306073  7290 net.cpp:439] res2a_branch2b/relu <- res2a_branch2b/bn
I0711 18:09:31.306078  7290 net.cpp:400] res2a_branch2b/relu -> res2a_branch2b/bn (in-place)
I0711 18:09:31.306084  7290 net.cpp:148] Setting up res2a_branch2b/relu
I0711 18:09:31.306089  7290 net.cpp:155] Top shape: 5 64 160 160 (8192000)
I0711 18:09:31.306093  7290 net.cpp:163] Memory required for data: 663552000
I0711 18:09:31.306097  7290 layer_factory.hpp:77] Creating layer pool2
I0711 18:09:31.306102  7290 net.cpp:98] Creating Layer pool2
I0711 18:09:31.306105  7290 net.cpp:439] pool2 <- res2a_branch2b/bn
I0711 18:09:31.306109  7290 net.cpp:413] pool2 -> pool2
I0711 18:09:31.306165  7290 net.cpp:148] Setting up pool2
I0711 18:09:31.306172  7290 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0711 18:09:31.306176  7290 net.cpp:163] Memory required for data: 671744000
I0711 18:09:31.306180  7290 layer_factory.hpp:77] Creating layer res3a_branch2a
I0711 18:09:31.306187  7290 net.cpp:98] Creating Layer res3a_branch2a
I0711 18:09:31.306191  7290 net.cpp:439] res3a_branch2a <- pool2
I0711 18:09:31.306197  7290 net.cpp:413] res3a_branch2a -> res3a_branch2a
I0711 18:09:31.308032  7290 net.cpp:148] Setting up res3a_branch2a
I0711 18:09:31.308039  7290 net.cpp:155] Top shape: 5 128 80 80 (4096000)
I0711 18:09:31.308042  7290 net.cpp:163] Memory required for data: 688128000
I0711 18:09:31.308046  7290 layer_factory.hpp:77] Creating layer res3a_branch2a/bn
I0711 18:09:31.308053  7290 net.cpp:98] Creating Layer res3a_branch2a/bn
I0711 18:09:31.308056  7290 net.cpp:439] res3a_branch2a/bn <- res3a_branch2a
I0711 18:09:31.308061  7290 net.cpp:413] res3a_branch2a/bn -> res3a_branch2a/bn
I0711 18:09:31.308746  7290 net.cpp:148] Setting up res3a_branch2a/bn
I0711 18:09:31.308753  7290 net.cpp:155] Top shape: 5 128 80 80 (4096000)
I0711 18:09:31.308756  7290 net.cpp:163] Memory required for data: 704512000
I0711 18:09:31.308765  7290 layer_factory.hpp:77] Creating layer res3a_branch2a/relu
I0711 18:09:31.308771  7290 net.cpp:98] Creating Layer res3a_branch2a/relu
I0711 18:09:31.308775  7290 net.cpp:439] res3a_branch2a/relu <- res3a_branch2a/bn
I0711 18:09:31.308779  7290 net.cpp:400] res3a_branch2a/relu -> res3a_branch2a/bn (in-place)
I0711 18:09:31.308785  7290 net.cpp:148] Setting up res3a_branch2a/relu
I0711 18:09:31.308790  7290 net.cpp:155] Top shape: 5 128 80 80 (4096000)
I0711 18:09:31.308794  7290 net.cpp:163] Memory required for data: 720896000
I0711 18:09:31.308799  7290 layer_factory.hpp:77] Creating layer res3a_branch2b
I0711 18:09:31.308805  7290 net.cpp:98] Creating Layer res3a_branch2b
I0711 18:09:31.308809  7290 net.cpp:439] res3a_branch2b <- res3a_branch2a/bn
I0711 18:09:31.308817  7290 net.cpp:413] res3a_branch2b -> res3a_branch2b
I0711 18:09:31.309854  7290 net.cpp:148] Setting up res3a_branch2b
I0711 18:09:31.309860  7290 net.cpp:155] Top shape: 5 128 80 80 (4096000)
I0711 18:09:31.309864  7290 net.cpp:163] Memory required for data: 737280000
I0711 18:09:31.309867  7290 layer_factory.hpp:77] Creating layer res3a_branch2b/bn
I0711 18:09:31.309875  7290 net.cpp:98] Creating Layer res3a_branch2b/bn
I0711 18:09:31.309880  7290 net.cpp:439] res3a_branch2b/bn <- res3a_branch2b
I0711 18:09:31.309885  7290 net.cpp:413] res3a_branch2b/bn -> res3a_branch2b/bn
I0711 18:09:31.310531  7290 net.cpp:148] Setting up res3a_branch2b/bn
I0711 18:09:31.310539  7290 net.cpp:155] Top shape: 5 128 80 80 (4096000)
I0711 18:09:31.310541  7290 net.cpp:163] Memory required for data: 753664000
I0711 18:09:31.310549  7290 layer_factory.hpp:77] Creating layer res3a_branch2b/relu
I0711 18:09:31.310554  7290 net.cpp:98] Creating Layer res3a_branch2b/relu
I0711 18:09:31.310557  7290 net.cpp:439] res3a_branch2b/relu <- res3a_branch2b/bn
I0711 18:09:31.310571  7290 net.cpp:400] res3a_branch2b/relu -> res3a_branch2b/bn (in-place)
I0711 18:09:31.310578  7290 net.cpp:148] Setting up res3a_branch2b/relu
I0711 18:09:31.310582  7290 net.cpp:155] Top shape: 5 128 80 80 (4096000)
I0711 18:09:31.310586  7290 net.cpp:163] Memory required for data: 770048000
I0711 18:09:31.310590  7290 layer_factory.hpp:77] Creating layer res3a_branch2b/bn_res3a_branch2b/relu_0_split
I0711 18:09:31.310595  7290 net.cpp:98] Creating Layer res3a_branch2b/bn_res3a_branch2b/relu_0_split
I0711 18:09:31.310600  7290 net.cpp:439] res3a_branch2b/bn_res3a_branch2b/relu_0_split <- res3a_branch2b/bn
I0711 18:09:31.310605  7290 net.cpp:413] res3a_branch2b/bn_res3a_branch2b/relu_0_split -> res3a_branch2b/bn_res3a_branch2b/relu_0_split_0
I0711 18:09:31.310609  7290 net.cpp:413] res3a_branch2b/bn_res3a_branch2b/relu_0_split -> res3a_branch2b/bn_res3a_branch2b/relu_0_split_1
I0711 18:09:31.310659  7290 net.cpp:148] Setting up res3a_branch2b/bn_res3a_branch2b/relu_0_split
I0711 18:09:31.310667  7290 net.cpp:155] Top shape: 5 128 80 80 (4096000)
I0711 18:09:31.310670  7290 net.cpp:155] Top shape: 5 128 80 80 (4096000)
I0711 18:09:31.310674  7290 net.cpp:163] Memory required for data: 802816000
I0711 18:09:31.310678  7290 layer_factory.hpp:77] Creating layer pool3
I0711 18:09:31.310683  7290 net.cpp:98] Creating Layer pool3
I0711 18:09:31.310688  7290 net.cpp:439] pool3 <- res3a_branch2b/bn_res3a_branch2b/relu_0_split_0
I0711 18:09:31.310691  7290 net.cpp:413] pool3 -> pool3
I0711 18:09:31.310744  7290 net.cpp:148] Setting up pool3
I0711 18:09:31.310750  7290 net.cpp:155] Top shape: 5 128 40 40 (1024000)
I0711 18:09:31.310753  7290 net.cpp:163] Memory required for data: 806912000
I0711 18:09:31.310756  7290 layer_factory.hpp:77] Creating layer res4a_branch2a
I0711 18:09:31.310763  7290 net.cpp:98] Creating Layer res4a_branch2a
I0711 18:09:31.310767  7290 net.cpp:439] res4a_branch2a <- pool3
I0711 18:09:31.310772  7290 net.cpp:413] res4a_branch2a -> res4a_branch2a
I0711 18:09:31.317945  7290 net.cpp:148] Setting up res4a_branch2a
I0711 18:09:31.317966  7290 net.cpp:155] Top shape: 5 256 40 40 (2048000)
I0711 18:09:31.317970  7290 net.cpp:163] Memory required for data: 815104000
I0711 18:09:31.317975  7290 layer_factory.hpp:77] Creating layer res4a_branch2a/bn
I0711 18:09:31.317986  7290 net.cpp:98] Creating Layer res4a_branch2a/bn
I0711 18:09:31.317992  7290 net.cpp:439] res4a_branch2a/bn <- res4a_branch2a
I0711 18:09:31.317998  7290 net.cpp:413] res4a_branch2a/bn -> res4a_branch2a/bn
I0711 18:09:31.318740  7290 net.cpp:148] Setting up res4a_branch2a/bn
I0711 18:09:31.318748  7290 net.cpp:155] Top shape: 5 256 40 40 (2048000)
I0711 18:09:31.318750  7290 net.cpp:163] Memory required for data: 823296000
I0711 18:09:31.318756  7290 layer_factory.hpp:77] Creating layer res4a_branch2a/relu
I0711 18:09:31.318763  7290 net.cpp:98] Creating Layer res4a_branch2a/relu
I0711 18:09:31.318765  7290 net.cpp:439] res4a_branch2a/relu <- res4a_branch2a/bn
I0711 18:09:31.318769  7290 net.cpp:400] res4a_branch2a/relu -> res4a_branch2a/bn (in-place)
I0711 18:09:31.318776  7290 net.cpp:148] Setting up res4a_branch2a/relu
I0711 18:09:31.318781  7290 net.cpp:155] Top shape: 5 256 40 40 (2048000)
I0711 18:09:31.318784  7290 net.cpp:163] Memory required for data: 831488000
I0711 18:09:31.318789  7290 layer_factory.hpp:77] Creating layer res4a_branch2b
I0711 18:09:31.318797  7290 net.cpp:98] Creating Layer res4a_branch2b
I0711 18:09:31.318801  7290 net.cpp:439] res4a_branch2b <- res4a_branch2a/bn
I0711 18:09:31.318806  7290 net.cpp:413] res4a_branch2b -> res4a_branch2b
I0711 18:09:31.322146  7290 net.cpp:148] Setting up res4a_branch2b
I0711 18:09:31.322154  7290 net.cpp:155] Top shape: 5 256 40 40 (2048000)
I0711 18:09:31.322156  7290 net.cpp:163] Memory required for data: 839680000
I0711 18:09:31.322160  7290 layer_factory.hpp:77] Creating layer res4a_branch2b/bn
I0711 18:09:31.322165  7290 net.cpp:98] Creating Layer res4a_branch2b/bn
I0711 18:09:31.322168  7290 net.cpp:439] res4a_branch2b/bn <- res4a_branch2b
I0711 18:09:31.322186  7290 net.cpp:413] res4a_branch2b/bn -> res4a_branch2b/bn
I0711 18:09:31.322883  7290 net.cpp:148] Setting up res4a_branch2b/bn
I0711 18:09:31.322890  7290 net.cpp:155] Top shape: 5 256 40 40 (2048000)
I0711 18:09:31.322892  7290 net.cpp:163] Memory required for data: 847872000
I0711 18:09:31.322898  7290 layer_factory.hpp:77] Creating layer res4a_branch2b/relu
I0711 18:09:31.322903  7290 net.cpp:98] Creating Layer res4a_branch2b/relu
I0711 18:09:31.322907  7290 net.cpp:439] res4a_branch2b/relu <- res4a_branch2b/bn
I0711 18:09:31.322912  7290 net.cpp:400] res4a_branch2b/relu -> res4a_branch2b/bn (in-place)
I0711 18:09:31.322918  7290 net.cpp:148] Setting up res4a_branch2b/relu
I0711 18:09:31.322923  7290 net.cpp:155] Top shape: 5 256 40 40 (2048000)
I0711 18:09:31.322926  7290 net.cpp:163] Memory required for data: 856064000
I0711 18:09:31.322931  7290 layer_factory.hpp:77] Creating layer pool4
I0711 18:09:31.322937  7290 net.cpp:98] Creating Layer pool4
I0711 18:09:31.322940  7290 net.cpp:439] pool4 <- res4a_branch2b/bn
I0711 18:09:31.322944  7290 net.cpp:413] pool4 -> pool4
I0711 18:09:31.322995  7290 net.cpp:148] Setting up pool4
I0711 18:09:31.323001  7290 net.cpp:155] Top shape: 5 256 40 40 (2048000)
I0711 18:09:31.323005  7290 net.cpp:163] Memory required for data: 864256000
I0711 18:09:31.323009  7290 layer_factory.hpp:77] Creating layer res5a_branch2a
I0711 18:09:31.323016  7290 net.cpp:98] Creating Layer res5a_branch2a
I0711 18:09:31.323021  7290 net.cpp:439] res5a_branch2a <- pool4
I0711 18:09:31.323026  7290 net.cpp:413] res5a_branch2a -> res5a_branch2a
I0711 18:09:31.349087  7290 net.cpp:148] Setting up res5a_branch2a
I0711 18:09:31.349112  7290 net.cpp:155] Top shape: 5 512 40 40 (4096000)
I0711 18:09:31.349114  7290 net.cpp:163] Memory required for data: 880640000
I0711 18:09:31.349122  7290 layer_factory.hpp:77] Creating layer res5a_branch2a/bn
I0711 18:09:31.349135  7290 net.cpp:98] Creating Layer res5a_branch2a/bn
I0711 18:09:31.349151  7290 net.cpp:439] res5a_branch2a/bn <- res5a_branch2a
I0711 18:09:31.349162  7290 net.cpp:413] res5a_branch2a/bn -> res5a_branch2a/bn
I0711 18:09:31.349946  7290 net.cpp:148] Setting up res5a_branch2a/bn
I0711 18:09:31.349956  7290 net.cpp:155] Top shape: 5 512 40 40 (4096000)
I0711 18:09:31.349958  7290 net.cpp:163] Memory required for data: 897024000
I0711 18:09:31.349964  7290 layer_factory.hpp:77] Creating layer res5a_branch2a/relu
I0711 18:09:31.349970  7290 net.cpp:98] Creating Layer res5a_branch2a/relu
I0711 18:09:31.349975  7290 net.cpp:439] res5a_branch2a/relu <- res5a_branch2a/bn
I0711 18:09:31.349979  7290 net.cpp:400] res5a_branch2a/relu -> res5a_branch2a/bn (in-place)
I0711 18:09:31.349985  7290 net.cpp:148] Setting up res5a_branch2a/relu
I0711 18:09:31.349990  7290 net.cpp:155] Top shape: 5 512 40 40 (4096000)
I0711 18:09:31.349994  7290 net.cpp:163] Memory required for data: 913408000
I0711 18:09:31.349997  7290 layer_factory.hpp:77] Creating layer res5a_branch2b
I0711 18:09:31.350008  7290 net.cpp:98] Creating Layer res5a_branch2b
I0711 18:09:31.350011  7290 net.cpp:439] res5a_branch2b <- res5a_branch2a/bn
I0711 18:09:31.350016  7290 net.cpp:413] res5a_branch2b -> res5a_branch2b
I0711 18:09:31.363626  7290 net.cpp:148] Setting up res5a_branch2b
I0711 18:09:31.363646  7290 net.cpp:155] Top shape: 5 512 40 40 (4096000)
I0711 18:09:31.363649  7290 net.cpp:163] Memory required for data: 929792000
I0711 18:09:31.363661  7290 layer_factory.hpp:77] Creating layer res5a_branch2b/bn
I0711 18:09:31.363672  7290 net.cpp:98] Creating Layer res5a_branch2b/bn
I0711 18:09:31.363677  7290 net.cpp:439] res5a_branch2b/bn <- res5a_branch2b
I0711 18:09:31.363682  7290 net.cpp:413] res5a_branch2b/bn -> res5a_branch2b/bn
I0711 18:09:31.364440  7290 net.cpp:148] Setting up res5a_branch2b/bn
I0711 18:09:31.364449  7290 net.cpp:155] Top shape: 5 512 40 40 (4096000)
I0711 18:09:31.364451  7290 net.cpp:163] Memory required for data: 946176000
I0711 18:09:31.364456  7290 layer_factory.hpp:77] Creating layer res5a_branch2b/relu
I0711 18:09:31.364470  7290 net.cpp:98] Creating Layer res5a_branch2b/relu
I0711 18:09:31.364472  7290 net.cpp:439] res5a_branch2b/relu <- res5a_branch2b/bn
I0711 18:09:31.364475  7290 net.cpp:400] res5a_branch2b/relu -> res5a_branch2b/bn (in-place)
I0711 18:09:31.364480  7290 net.cpp:148] Setting up res5a_branch2b/relu
I0711 18:09:31.364482  7290 net.cpp:155] Top shape: 5 512 40 40 (4096000)
I0711 18:09:31.364485  7290 net.cpp:163] Memory required for data: 962560000
I0711 18:09:31.364487  7290 layer_factory.hpp:77] Creating layer out5a
I0711 18:09:31.364496  7290 net.cpp:98] Creating Layer out5a
I0711 18:09:31.364500  7290 net.cpp:439] out5a <- res5a_branch2b/bn
I0711 18:09:31.364506  7290 net.cpp:413] out5a -> out5a
I0711 18:09:31.368798  7290 net.cpp:148] Setting up out5a
I0711 18:09:31.368808  7290 net.cpp:155] Top shape: 5 64 40 40 (512000)
I0711 18:09:31.368811  7290 net.cpp:163] Memory required for data: 964608000
I0711 18:09:31.368821  7290 layer_factory.hpp:77] Creating layer out5a/bn
I0711 18:09:31.368830  7290 net.cpp:98] Creating Layer out5a/bn
I0711 18:09:31.368835  7290 net.cpp:439] out5a/bn <- out5a
I0711 18:09:31.368841  7290 net.cpp:413] out5a/bn -> out5a/bn
I0711 18:09:31.369621  7290 net.cpp:148] Setting up out5a/bn
I0711 18:09:31.369629  7290 net.cpp:155] Top shape: 5 64 40 40 (512000)
I0711 18:09:31.369632  7290 net.cpp:163] Memory required for data: 966656000
I0711 18:09:31.369637  7290 layer_factory.hpp:77] Creating layer out5a/relu
I0711 18:09:31.369640  7290 net.cpp:98] Creating Layer out5a/relu
I0711 18:09:31.369642  7290 net.cpp:439] out5a/relu <- out5a/bn
I0711 18:09:31.369647  7290 net.cpp:400] out5a/relu -> out5a/bn (in-place)
I0711 18:09:31.369650  7290 net.cpp:148] Setting up out5a/relu
I0711 18:09:31.369653  7290 net.cpp:155] Top shape: 5 64 40 40 (512000)
I0711 18:09:31.369657  7290 net.cpp:163] Memory required for data: 968704000
I0711 18:09:31.369658  7290 layer_factory.hpp:77] Creating layer out5a_up2
I0711 18:09:31.369668  7290 net.cpp:98] Creating Layer out5a_up2
I0711 18:09:31.369673  7290 net.cpp:439] out5a_up2 <- out5a/bn
I0711 18:09:31.369680  7290 net.cpp:413] out5a_up2 -> out5a_up2
I0711 18:09:31.370033  7290 net.cpp:148] Setting up out5a_up2
I0711 18:09:31.370039  7290 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0711 18:09:31.370041  7290 net.cpp:163] Memory required for data: 976896000
I0711 18:09:31.370045  7290 layer_factory.hpp:77] Creating layer out3a
I0711 18:09:31.370050  7290 net.cpp:98] Creating Layer out3a
I0711 18:09:31.370054  7290 net.cpp:439] out3a <- res3a_branch2b/bn_res3a_branch2b/relu_0_split_1
I0711 18:09:31.370056  7290 net.cpp:413] out3a -> out3a
I0711 18:09:31.371141  7290 net.cpp:148] Setting up out3a
I0711 18:09:31.371150  7290 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0711 18:09:31.371151  7290 net.cpp:163] Memory required for data: 985088000
I0711 18:09:31.371155  7290 layer_factory.hpp:77] Creating layer out3a/bn
I0711 18:09:31.371175  7290 net.cpp:98] Creating Layer out3a/bn
I0711 18:09:31.371181  7290 net.cpp:439] out3a/bn <- out3a
I0711 18:09:31.371187  7290 net.cpp:413] out3a/bn -> out3a/bn
I0711 18:09:31.371954  7290 net.cpp:148] Setting up out3a/bn
I0711 18:09:31.371961  7290 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0711 18:09:31.371964  7290 net.cpp:163] Memory required for data: 993280000
I0711 18:09:31.371971  7290 layer_factory.hpp:77] Creating layer out3a/relu
I0711 18:09:31.371976  7290 net.cpp:98] Creating Layer out3a/relu
I0711 18:09:31.371980  7290 net.cpp:439] out3a/relu <- out3a/bn
I0711 18:09:31.371985  7290 net.cpp:400] out3a/relu -> out3a/bn (in-place)
I0711 18:09:31.371991  7290 net.cpp:148] Setting up out3a/relu
I0711 18:09:31.371996  7290 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0711 18:09:31.372000  7290 net.cpp:163] Memory required for data: 1001472000
I0711 18:09:31.372004  7290 layer_factory.hpp:77] Creating layer out3_out5_combined
I0711 18:09:31.372014  7290 net.cpp:98] Creating Layer out3_out5_combined
I0711 18:09:31.372017  7290 net.cpp:439] out3_out5_combined <- out5a_up2
I0711 18:09:31.372021  7290 net.cpp:439] out3_out5_combined <- out3a/bn
I0711 18:09:31.372035  7290 net.cpp:413] out3_out5_combined -> out3_out5_combined
I0711 18:09:31.372067  7290 net.cpp:148] Setting up out3_out5_combined
I0711 18:09:31.372074  7290 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0711 18:09:31.372077  7290 net.cpp:163] Memory required for data: 1009664000
I0711 18:09:31.372081  7290 layer_factory.hpp:77] Creating layer ctx_conv1
I0711 18:09:31.372087  7290 net.cpp:98] Creating Layer ctx_conv1
I0711 18:09:31.372092  7290 net.cpp:439] ctx_conv1 <- out3_out5_combined
I0711 18:09:31.372098  7290 net.cpp:413] ctx_conv1 -> ctx_conv1
I0711 18:09:31.373149  7290 net.cpp:148] Setting up ctx_conv1
I0711 18:09:31.373157  7290 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0711 18:09:31.373158  7290 net.cpp:163] Memory required for data: 1017856000
I0711 18:09:31.373162  7290 layer_factory.hpp:77] Creating layer ctx_conv1/bn
I0711 18:09:31.373167  7290 net.cpp:98] Creating Layer ctx_conv1/bn
I0711 18:09:31.373170  7290 net.cpp:439] ctx_conv1/bn <- ctx_conv1
I0711 18:09:31.373176  7290 net.cpp:413] ctx_conv1/bn -> ctx_conv1/bn
I0711 18:09:31.373924  7290 net.cpp:148] Setting up ctx_conv1/bn
I0711 18:09:31.373932  7290 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0711 18:09:31.373935  7290 net.cpp:163] Memory required for data: 1026048000
I0711 18:09:31.373944  7290 layer_factory.hpp:77] Creating layer ctx_conv1/relu
I0711 18:09:31.373958  7290 net.cpp:98] Creating Layer ctx_conv1/relu
I0711 18:09:31.373965  7290 net.cpp:439] ctx_conv1/relu <- ctx_conv1/bn
I0711 18:09:31.373968  7290 net.cpp:400] ctx_conv1/relu -> ctx_conv1/bn (in-place)
I0711 18:09:31.373977  7290 net.cpp:148] Setting up ctx_conv1/relu
I0711 18:09:31.373982  7290 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0711 18:09:31.373987  7290 net.cpp:163] Memory required for data: 1034240000
I0711 18:09:31.373991  7290 layer_factory.hpp:77] Creating layer ctx_conv2
I0711 18:09:31.374001  7290 net.cpp:98] Creating Layer ctx_conv2
I0711 18:09:31.374004  7290 net.cpp:439] ctx_conv2 <- ctx_conv1/bn
I0711 18:09:31.374008  7290 net.cpp:413] ctx_conv2 -> ctx_conv2
I0711 18:09:31.375102  7290 net.cpp:148] Setting up ctx_conv2
I0711 18:09:31.375110  7290 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0711 18:09:31.375113  7290 net.cpp:163] Memory required for data: 1042432000
I0711 18:09:31.375118  7290 layer_factory.hpp:77] Creating layer ctx_conv2/bn
I0711 18:09:31.375133  7290 net.cpp:98] Creating Layer ctx_conv2/bn
I0711 18:09:31.375139  7290 net.cpp:439] ctx_conv2/bn <- ctx_conv2
I0711 18:09:31.375144  7290 net.cpp:413] ctx_conv2/bn -> ctx_conv2/bn
I0711 18:09:31.375896  7290 net.cpp:148] Setting up ctx_conv2/bn
I0711 18:09:31.375902  7290 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0711 18:09:31.375905  7290 net.cpp:163] Memory required for data: 1050624000
I0711 18:09:31.375912  7290 layer_factory.hpp:77] Creating layer ctx_conv2/relu
I0711 18:09:31.375926  7290 net.cpp:98] Creating Layer ctx_conv2/relu
I0711 18:09:31.375929  7290 net.cpp:439] ctx_conv2/relu <- ctx_conv2/bn
I0711 18:09:31.375932  7290 net.cpp:400] ctx_conv2/relu -> ctx_conv2/bn (in-place)
I0711 18:09:31.375941  7290 net.cpp:148] Setting up ctx_conv2/relu
I0711 18:09:31.375949  7290 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0711 18:09:31.375954  7290 net.cpp:163] Memory required for data: 1058816000
I0711 18:09:31.375957  7290 layer_factory.hpp:77] Creating layer ctx_conv3
I0711 18:09:31.375964  7290 net.cpp:98] Creating Layer ctx_conv3
I0711 18:09:31.375969  7290 net.cpp:439] ctx_conv3 <- ctx_conv2/bn
I0711 18:09:31.375974  7290 net.cpp:413] ctx_conv3 -> ctx_conv3
I0711 18:09:31.377029  7290 net.cpp:148] Setting up ctx_conv3
I0711 18:09:31.377037  7290 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0711 18:09:31.377038  7290 net.cpp:163] Memory required for data: 1067008000
I0711 18:09:31.377043  7290 layer_factory.hpp:77] Creating layer ctx_conv3/bn
I0711 18:09:31.377050  7290 net.cpp:98] Creating Layer ctx_conv3/bn
I0711 18:09:31.377054  7290 net.cpp:439] ctx_conv3/bn <- ctx_conv3
I0711 18:09:31.377060  7290 net.cpp:413] ctx_conv3/bn -> ctx_conv3/bn
I0711 18:09:31.377812  7290 net.cpp:148] Setting up ctx_conv3/bn
I0711 18:09:31.377820  7290 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0711 18:09:31.377822  7290 net.cpp:163] Memory required for data: 1075200000
I0711 18:09:31.377830  7290 layer_factory.hpp:77] Creating layer ctx_conv3/relu
I0711 18:09:31.377836  7290 net.cpp:98] Creating Layer ctx_conv3/relu
I0711 18:09:31.377840  7290 net.cpp:439] ctx_conv3/relu <- ctx_conv3/bn
I0711 18:09:31.377846  7290 net.cpp:400] ctx_conv3/relu -> ctx_conv3/bn (in-place)
I0711 18:09:31.377853  7290 net.cpp:148] Setting up ctx_conv3/relu
I0711 18:09:31.377858  7290 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0711 18:09:31.377861  7290 net.cpp:163] Memory required for data: 1083392000
I0711 18:09:31.377866  7290 layer_factory.hpp:77] Creating layer ctx_conv4
I0711 18:09:31.377873  7290 net.cpp:98] Creating Layer ctx_conv4
I0711 18:09:31.377877  7290 net.cpp:439] ctx_conv4 <- ctx_conv3/bn
I0711 18:09:31.377882  7290 net.cpp:413] ctx_conv4 -> ctx_conv4
I0711 18:09:31.378926  7290 net.cpp:148] Setting up ctx_conv4
I0711 18:09:31.378931  7290 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0711 18:09:31.378933  7290 net.cpp:163] Memory required for data: 1091584000
I0711 18:09:31.378938  7290 layer_factory.hpp:77] Creating layer ctx_conv4/bn
I0711 18:09:31.378944  7290 net.cpp:98] Creating Layer ctx_conv4/bn
I0711 18:09:31.378948  7290 net.cpp:439] ctx_conv4/bn <- ctx_conv4
I0711 18:09:31.378954  7290 net.cpp:413] ctx_conv4/bn -> ctx_conv4/bn
I0711 18:09:31.379688  7290 net.cpp:148] Setting up ctx_conv4/bn
I0711 18:09:31.379694  7290 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0711 18:09:31.379698  7290 net.cpp:163] Memory required for data: 1099776000
I0711 18:09:31.379704  7290 layer_factory.hpp:77] Creating layer ctx_conv4/relu
I0711 18:09:31.379710  7290 net.cpp:98] Creating Layer ctx_conv4/relu
I0711 18:09:31.379714  7290 net.cpp:439] ctx_conv4/relu <- ctx_conv4/bn
I0711 18:09:31.379719  7290 net.cpp:400] ctx_conv4/relu -> ctx_conv4/bn (in-place)
I0711 18:09:31.379726  7290 net.cpp:148] Setting up ctx_conv4/relu
I0711 18:09:31.379731  7290 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0711 18:09:31.379735  7290 net.cpp:163] Memory required for data: 1107968000
I0711 18:09:31.379739  7290 layer_factory.hpp:77] Creating layer ctx_final
I0711 18:09:31.379745  7290 net.cpp:98] Creating Layer ctx_final
I0711 18:09:31.379750  7290 net.cpp:439] ctx_final <- ctx_conv4/bn
I0711 18:09:31.379753  7290 net.cpp:413] ctx_final -> ctx_final
I0711 18:09:31.380157  7290 net.cpp:148] Setting up ctx_final
I0711 18:09:31.380163  7290 net.cpp:155] Top shape: 5 8 80 80 (256000)
I0711 18:09:31.380165  7290 net.cpp:163] Memory required for data: 1108992000
I0711 18:09:31.380170  7290 layer_factory.hpp:77] Creating layer ctx_final/relu
I0711 18:09:31.380177  7290 net.cpp:98] Creating Layer ctx_final/relu
I0711 18:09:31.380179  7290 net.cpp:439] ctx_final/relu <- ctx_final
I0711 18:09:31.380182  7290 net.cpp:400] ctx_final/relu -> ctx_final (in-place)
I0711 18:09:31.380185  7290 net.cpp:148] Setting up ctx_final/relu
I0711 18:09:31.380187  7290 net.cpp:155] Top shape: 5 8 80 80 (256000)
I0711 18:09:31.380189  7290 net.cpp:163] Memory required for data: 1110016000
I0711 18:09:31.380192  7290 layer_factory.hpp:77] Creating layer out_deconv_final_up2
I0711 18:09:31.380197  7290 net.cpp:98] Creating Layer out_deconv_final_up2
I0711 18:09:31.380198  7290 net.cpp:439] out_deconv_final_up2 <- ctx_final
I0711 18:09:31.380201  7290 net.cpp:413] out_deconv_final_up2 -> out_deconv_final_up2
I0711 18:09:31.380440  7290 net.cpp:148] Setting up out_deconv_final_up2
I0711 18:09:31.380446  7290 net.cpp:155] Top shape: 5 8 160 160 (1024000)
I0711 18:09:31.380448  7290 net.cpp:163] Memory required for data: 1114112000
I0711 18:09:31.380453  7290 layer_factory.hpp:77] Creating layer out_deconv_final_up4
I0711 18:09:31.380466  7290 net.cpp:98] Creating Layer out_deconv_final_up4
I0711 18:09:31.380470  7290 net.cpp:439] out_deconv_final_up4 <- out_deconv_final_up2
I0711 18:09:31.380475  7290 net.cpp:413] out_deconv_final_up4 -> out_deconv_final_up4
I0711 18:09:31.380718  7290 net.cpp:148] Setting up out_deconv_final_up4
I0711 18:09:31.380724  7290 net.cpp:155] Top shape: 5 8 320 320 (4096000)
I0711 18:09:31.380728  7290 net.cpp:163] Memory required for data: 1130496000
I0711 18:09:31.380733  7290 layer_factory.hpp:77] Creating layer out_deconv_final_up8
I0711 18:09:31.380738  7290 net.cpp:98] Creating Layer out_deconv_final_up8
I0711 18:09:31.380743  7290 net.cpp:439] out_deconv_final_up8 <- out_deconv_final_up4
I0711 18:09:31.380746  7290 net.cpp:413] out_deconv_final_up8 -> out_deconv_final_up8
I0711 18:09:31.380987  7290 net.cpp:148] Setting up out_deconv_final_up8
I0711 18:09:31.380995  7290 net.cpp:155] Top shape: 5 8 640 640 (16384000)
I0711 18:09:31.380997  7290 net.cpp:163] Memory required for data: 1196032000
I0711 18:09:31.381002  7290 layer_factory.hpp:77] Creating layer loss
I0711 18:09:31.381007  7290 net.cpp:98] Creating Layer loss
I0711 18:09:31.381011  7290 net.cpp:439] loss <- out_deconv_final_up8
I0711 18:09:31.381014  7290 net.cpp:439] loss <- label
I0711 18:09:31.381021  7290 net.cpp:413] loss -> loss
I0711 18:09:31.381031  7290 layer_factory.hpp:77] Creating layer loss
I0711 18:09:31.408262  7290 net.cpp:148] Setting up loss
I0711 18:09:31.408299  7290 net.cpp:155] Top shape: (1)
I0711 18:09:31.408303  7290 net.cpp:158]     with loss weight 1
I0711 18:09:31.408332  7290 net.cpp:163] Memory required for data: 1196032004
I0711 18:09:31.408354  7290 net.cpp:224] loss needs backward computation.
I0711 18:09:31.408363  7290 net.cpp:224] out_deconv_final_up8 needs backward computation.
I0711 18:09:31.408370  7290 net.cpp:224] out_deconv_final_up4 needs backward computation.
I0711 18:09:31.408378  7290 net.cpp:224] out_deconv_final_up2 needs backward computation.
I0711 18:09:31.408388  7290 net.cpp:224] ctx_final/relu needs backward computation.
I0711 18:09:31.408393  7290 net.cpp:224] ctx_final needs backward computation.
I0711 18:09:31.408401  7290 net.cpp:224] ctx_conv4/relu needs backward computation.
I0711 18:09:31.408406  7290 net.cpp:224] ctx_conv4/bn needs backward computation.
I0711 18:09:31.408418  7290 net.cpp:224] ctx_conv4 needs backward computation.
I0711 18:09:31.408422  7290 net.cpp:224] ctx_conv3/relu needs backward computation.
I0711 18:09:31.408429  7290 net.cpp:224] ctx_conv3/bn needs backward computation.
I0711 18:09:31.408434  7290 net.cpp:224] ctx_conv3 needs backward computation.
I0711 18:09:31.408445  7290 net.cpp:224] ctx_conv2/relu needs backward computation.
I0711 18:09:31.408449  7290 net.cpp:224] ctx_conv2/bn needs backward computation.
I0711 18:09:31.408457  7290 net.cpp:224] ctx_conv2 needs backward computation.
I0711 18:09:31.408462  7290 net.cpp:224] ctx_conv1/relu needs backward computation.
I0711 18:09:31.408471  7290 net.cpp:224] ctx_conv1/bn needs backward computation.
I0711 18:09:31.408475  7290 net.cpp:224] ctx_conv1 needs backward computation.
I0711 18:09:31.408483  7290 net.cpp:224] out3_out5_combined needs backward computation.
I0711 18:09:31.408488  7290 net.cpp:224] out3a/relu needs backward computation.
I0711 18:09:31.408499  7290 net.cpp:224] out3a/bn needs backward computation.
I0711 18:09:31.408504  7290 net.cpp:224] out3a needs backward computation.
I0711 18:09:31.408510  7290 net.cpp:224] out5a_up2 needs backward computation.
I0711 18:09:31.408516  7290 net.cpp:224] out5a/relu needs backward computation.
I0711 18:09:31.408526  7290 net.cpp:224] out5a/bn needs backward computation.
I0711 18:09:31.408530  7290 net.cpp:224] out5a needs backward computation.
I0711 18:09:31.408537  7290 net.cpp:224] res5a_branch2b/relu needs backward computation.
I0711 18:09:31.408542  7290 net.cpp:224] res5a_branch2b/bn needs backward computation.
I0711 18:09:31.408555  7290 net.cpp:224] res5a_branch2b needs backward computation.
I0711 18:09:31.408558  7290 net.cpp:224] res5a_branch2a/relu needs backward computation.
I0711 18:09:31.408565  7290 net.cpp:224] res5a_branch2a/bn needs backward computation.
I0711 18:09:31.408579  7290 net.cpp:224] res5a_branch2a needs backward computation.
I0711 18:09:31.408589  7290 net.cpp:224] pool4 needs backward computation.
I0711 18:09:31.408601  7290 net.cpp:224] res4a_branch2b/relu needs backward computation.
I0711 18:09:31.408604  7290 net.cpp:224] res4a_branch2b/bn needs backward computation.
I0711 18:09:31.408612  7290 net.cpp:224] res4a_branch2b needs backward computation.
I0711 18:09:31.408618  7290 net.cpp:224] res4a_branch2a/relu needs backward computation.
I0711 18:09:31.408628  7290 net.cpp:224] res4a_branch2a/bn needs backward computation.
I0711 18:09:31.408632  7290 net.cpp:224] res4a_branch2a needs backward computation.
I0711 18:09:31.408640  7290 net.cpp:224] pool3 needs backward computation.
I0711 18:09:31.408645  7290 net.cpp:224] res3a_branch2b/bn_res3a_branch2b/relu_0_split needs backward computation.
I0711 18:09:31.408656  7290 net.cpp:224] res3a_branch2b/relu needs backward computation.
I0711 18:09:31.408659  7290 net.cpp:224] res3a_branch2b/bn needs backward computation.
I0711 18:09:31.408668  7290 net.cpp:224] res3a_branch2b needs backward computation.
I0711 18:09:31.408671  7290 net.cpp:224] res3a_branch2a/relu needs backward computation.
I0711 18:09:31.408679  7290 net.cpp:224] res3a_branch2a/bn needs backward computation.
I0711 18:09:31.408682  7290 net.cpp:224] res3a_branch2a needs backward computation.
I0711 18:09:31.408690  7290 net.cpp:224] pool2 needs backward computation.
I0711 18:09:31.408694  7290 net.cpp:224] res2a_branch2b/relu needs backward computation.
I0711 18:09:31.408701  7290 net.cpp:224] res2a_branch2b/bn needs backward computation.
I0711 18:09:31.408705  7290 net.cpp:224] res2a_branch2b needs backward computation.
I0711 18:09:31.408713  7290 net.cpp:224] res2a_branch2a/relu needs backward computation.
I0711 18:09:31.408716  7290 net.cpp:224] res2a_branch2a/bn needs backward computation.
I0711 18:09:31.408725  7290 net.cpp:224] res2a_branch2a needs backward computation.
I0711 18:09:31.408728  7290 net.cpp:224] pool1 needs backward computation.
I0711 18:09:31.408735  7290 net.cpp:224] conv1b/relu needs backward computation.
I0711 18:09:31.408740  7290 net.cpp:224] conv1b/bn needs backward computation.
I0711 18:09:31.408747  7290 net.cpp:224] conv1b needs backward computation.
I0711 18:09:31.408751  7290 net.cpp:224] conv1a/relu needs backward computation.
I0711 18:09:31.408758  7290 net.cpp:224] conv1a/bn needs backward computation.
I0711 18:09:31.408762  7290 net.cpp:224] conv1a needs backward computation.
I0711 18:09:31.408771  7290 net.cpp:226] data/bias does not need backward computation.
I0711 18:09:31.408774  7290 net.cpp:226] data does not need backward computation.
I0711 18:09:31.408782  7290 net.cpp:268] This network produces output loss
I0711 18:09:31.408825  7290 net.cpp:288] Network initialization done.
I0711 18:09:31.409572  7290 solver.cpp:182] Creating test net (#0) specified by test_net file: training/cityscapes5_jsegnet21v2_2017-07-11_18-09-28/initial/test.prototxt
I0711 18:09:31.409873  7290 net.cpp:56] Initializing net from parameters: 
name: "jsegnet21v2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageLabelData"
  top: "data"
  top: "label"
  transform_param {
    mirror: false
    crop_size: 640
    mean_value: 0
  }
  image_label_data_param {
    image_list_path: "data/val-image-lmdb"
    label_list_path: "data/val-label-lmdb"
    batch_size: 4
    threads: 4
    backend: LMDB
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a/bn"
  top: "conv1a/bn"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a/bn"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b/bn"
  top: "conv1b/bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b/bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2a/bn"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b/bn"
  top: "res2a_branch2b/bn"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b/bn"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2a/bn"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b/bn"
  top: "res3a_branch2b/bn"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b/bn"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2a/bn"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b/bn"
  top: "res4a_branch2b/bn"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b/bn"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2a/bn"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b/bn"
  top: "res5a_branch2b/bn"
}
layer {
  name: "out5a"
  type: "Convolution"
  bottom: "res5a_branch2b/bn"
  top: "out5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "out5a/bn"
  type: "BatchNorm"
  bottom: "out5a"
  top: "out5a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "out5a/relu"
  type: "ReLU"
  bottom: "out5a/bn"
  top: "out5a/bn"
}
layer {
  name: "out5a_up2"
  type: "Deconvolution"
  bottom: "out5a/bn"
  top: "out5a_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 64
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out3a"
  type: "Convolution"
  bottom: "res3a_branch2b/bn"
  top: "out3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "out3a/bn"
  type: "BatchNorm"
  bottom: "out3a"
  top: "out3a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "out3a/relu"
  type: "ReLU"
  bottom: "out3a/bn"
  top: "out3a/bn"
}
layer {
  name: "out3_out5_combined"
  type: "Eltwise"
  bottom: "out5a_up2"
  bottom: "out3a/bn"
  top: "out3_out5_combined"
}
layer {
  name: "ctx_conv1"
  type: "Convolution"
  bottom: "out3_out5_combined"
  top: "ctx_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_conv1/bn"
  type: "BatchNorm"
  bottom: "ctx_conv1"
  top: "ctx_conv1/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ctx_conv1/relu"
  type: "ReLU"
  bottom: "ctx_conv1/bn"
  top: "ctx_conv1/bn"
}
layer {
  name: "ctx_conv2"
  type: "Convolution"
  bottom: "ctx_conv1/bn"
  top: "ctx_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv2/bn"
  type: "BatchNorm"
  bottom: "ctx_conv2"
  top: "ctx_conv2/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ctx_conv2/relu"
  type: "ReLU"
  bottom: "ctx_conv2/bn"
  top: "ctx_conv2/bn"
}
layer {
  name: "ctx_conv3"
  type: "Convolution"
  bottom: "ctx_conv2/bn"
  top: "ctx_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv3/bn"
  type: "BatchNorm"
  bottom: "ctx_conv3"
  top: "ctx_conv3/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ctx_conv3/relu"
  type: "ReLU"
  bottom: "ctx_conv3/bn"
  top: "ctx_conv3/bn"
}
layer {
  name: "ctx_conv4"
  type: "Convolution"
  bottom: "ctx_conv3/bn"
  top: "ctx_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv4/bn"
  type: "BatchNorm"
  bottom: "ctx_conv4"
  top: "ctx_conv4/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ctx_conv4/relu"
  type: "ReLU"
  bottom: "ctx_conv4/bn"
  top: "ctx_conv4/bn"
}
layer {
  name: "ctx_final"
  type: "Convolution"
  bottom: "ctx_conv4/bn"
  top: "ctx_final"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_final/relu"
  type: "ReLU"
  bottom: "ctx_final"
  top: "ctx_final"
}
layer {
  name: "out_deconv_final_up2"
  type: "Deconvolution"
  bottom: "ctx_final"
  top: "out_deconv_final_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up4"
  type: "Deconvolution"
  bottom: "out_deconv_final_up2"
  top: "out_deconv_final_up4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up8"
  type: "Deconvolution"
  bottom: "out_deconv_final_up4"
  top: "out_deconv_final_up8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: 255
    normalization: VALID
  }
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "accuracy/top1"
  include {
    phase: TEST
  }
  accuracy_param {
    ignore_label: 255
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "accuracy/top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
    ignore_label: 255
  }
}
I0711 18:09:31.410055  7290 layer_factory.hpp:77] Creating layer data
I0711 18:09:31.410071  7290 net.cpp:98] Creating Layer data
I0711 18:09:31.410081  7290 net.cpp:413] data -> data
I0711 18:09:31.410092  7290 net.cpp:413] data -> label
I0711 18:09:31.411417  7360 db_lmdb.cpp:35] Opened lmdb data/val-image-lmdb
I0711 18:09:31.413859  7365 db_lmdb.cpp:35] Opened lmdb data/val-label-lmdb
I0711 18:09:31.446334  7290 data_layer.cpp:78] ReshapePrefetch 4, 3, 640, 640
I0711 18:09:31.446413  7290 data_layer.cpp:83] output data size: 4,3,640,640
I0711 18:09:31.489640  7290 data_layer.cpp:78] ReshapePrefetch 4, 1, 640, 640
I0711 18:09:31.489715  7290 data_layer.cpp:83] output data size: 4,1,640,640
I0711 18:09:31.804074  7290 net.cpp:148] Setting up data
I0711 18:09:31.804158  7290 net.cpp:155] Top shape: 4 3 640 640 (4915200)
I0711 18:09:31.804168  7290 net.cpp:155] Top shape: 4 1 640 640 (1638400)
I0711 18:09:31.804173  7290 net.cpp:163] Memory required for data: 26214400
I0711 18:09:31.804183  7290 layer_factory.hpp:77] Creating layer label_data_1_split
I0711 18:09:31.804210  7290 net.cpp:98] Creating Layer label_data_1_split
I0711 18:09:31.804222  7290 net.cpp:439] label_data_1_split <- label
I0711 18:09:31.804285  7290 net.cpp:413] label_data_1_split -> label_data_1_split_0
I0711 18:09:31.804302  7290 net.cpp:413] label_data_1_split -> label_data_1_split_1
I0711 18:09:31.804311  7290 net.cpp:413] label_data_1_split -> label_data_1_split_2
I0711 18:09:31.804744  7290 net.cpp:148] Setting up label_data_1_split
I0711 18:09:31.804759  7290 net.cpp:155] Top shape: 4 1 640 640 (1638400)
I0711 18:09:31.804766  7290 net.cpp:155] Top shape: 4 1 640 640 (1638400)
I0711 18:09:31.804774  7290 net.cpp:155] Top shape: 4 1 640 640 (1638400)
I0711 18:09:31.804778  7290 net.cpp:163] Memory required for data: 45875200
I0711 18:09:31.804783  7290 layer_factory.hpp:77] Creating layer data/bias
I0711 18:09:31.804813  7290 net.cpp:98] Creating Layer data/bias
I0711 18:09:31.804837  7290 net.cpp:439] data/bias <- data
I0711 18:09:31.804847  7290 net.cpp:413] data/bias -> data/bias
I0711 18:09:31.807446  7290 net.cpp:148] Setting up data/bias
I0711 18:09:31.807462  7290 net.cpp:155] Top shape: 4 3 640 640 (4915200)
I0711 18:09:31.807464  7290 net.cpp:163] Memory required for data: 65536000
I0711 18:09:31.807472  7290 layer_factory.hpp:77] Creating layer conv1a
I0711 18:09:31.807483  7290 net.cpp:98] Creating Layer conv1a
I0711 18:09:31.807487  7290 net.cpp:439] conv1a <- data/bias
I0711 18:09:31.807490  7290 net.cpp:413] conv1a -> conv1a
I0711 18:09:31.808028  7290 net.cpp:148] Setting up conv1a
I0711 18:09:31.808034  7290 net.cpp:155] Top shape: 4 32 320 320 (13107200)
I0711 18:09:31.808037  7290 net.cpp:163] Memory required for data: 117964800
I0711 18:09:31.808042  7290 layer_factory.hpp:77] Creating layer conv1a/bn
I0711 18:09:31.808048  7290 net.cpp:98] Creating Layer conv1a/bn
I0711 18:09:31.808050  7290 net.cpp:439] conv1a/bn <- conv1a
I0711 18:09:31.808053  7290 net.cpp:413] conv1a/bn -> conv1a/bn
I0711 18:09:31.809293  7290 net.cpp:148] Setting up conv1a/bn
I0711 18:09:31.809310  7290 net.cpp:155] Top shape: 4 32 320 320 (13107200)
I0711 18:09:31.809319  7290 net.cpp:163] Memory required for data: 170393600
I0711 18:09:31.809334  7290 layer_factory.hpp:77] Creating layer conv1a/relu
I0711 18:09:31.809342  7290 net.cpp:98] Creating Layer conv1a/relu
I0711 18:09:31.809346  7290 net.cpp:439] conv1a/relu <- conv1a/bn
I0711 18:09:31.809350  7290 net.cpp:400] conv1a/relu -> conv1a/bn (in-place)
I0711 18:09:31.809357  7290 net.cpp:148] Setting up conv1a/relu
I0711 18:09:31.809362  7290 net.cpp:155] Top shape: 4 32 320 320 (13107200)
I0711 18:09:31.809365  7290 net.cpp:163] Memory required for data: 222822400
I0711 18:09:31.809368  7290 layer_factory.hpp:77] Creating layer conv1b
I0711 18:09:31.809377  7290 net.cpp:98] Creating Layer conv1b
I0711 18:09:31.809381  7290 net.cpp:439] conv1b <- conv1a/bn
I0711 18:09:31.809386  7290 net.cpp:413] conv1b -> conv1b
I0711 18:09:31.810032  7290 net.cpp:148] Setting up conv1b
I0711 18:09:31.810044  7290 net.cpp:155] Top shape: 4 32 320 320 (13107200)
I0711 18:09:31.810047  7290 net.cpp:163] Memory required for data: 275251200
I0711 18:09:31.810055  7290 layer_factory.hpp:77] Creating layer conv1b/bn
I0711 18:09:31.810060  7290 net.cpp:98] Creating Layer conv1b/bn
I0711 18:09:31.810065  7290 net.cpp:439] conv1b/bn <- conv1b
I0711 18:09:31.810070  7290 net.cpp:413] conv1b/bn -> conv1b/bn
I0711 18:09:31.811287  7290 net.cpp:148] Setting up conv1b/bn
I0711 18:09:31.811298  7290 net.cpp:155] Top shape: 4 32 320 320 (13107200)
I0711 18:09:31.811305  7290 net.cpp:163] Memory required for data: 327680000
I0711 18:09:31.811312  7290 layer_factory.hpp:77] Creating layer conv1b/relu
I0711 18:09:31.811318  7290 net.cpp:98] Creating Layer conv1b/relu
I0711 18:09:31.811322  7290 net.cpp:439] conv1b/relu <- conv1b/bn
I0711 18:09:31.811327  7290 net.cpp:400] conv1b/relu -> conv1b/bn (in-place)
I0711 18:09:31.811333  7290 net.cpp:148] Setting up conv1b/relu
I0711 18:09:31.811338  7290 net.cpp:155] Top shape: 4 32 320 320 (13107200)
I0711 18:09:31.811342  7290 net.cpp:163] Memory required for data: 380108800
I0711 18:09:31.811345  7290 layer_factory.hpp:77] Creating layer pool1
I0711 18:09:31.811352  7290 net.cpp:98] Creating Layer pool1
I0711 18:09:31.811370  7290 net.cpp:439] pool1 <- conv1b/bn
I0711 18:09:31.811377  7290 net.cpp:413] pool1 -> pool1
I0711 18:09:31.811439  7290 net.cpp:148] Setting up pool1
I0711 18:09:31.811445  7290 net.cpp:155] Top shape: 4 32 160 160 (3276800)
I0711 18:09:31.811450  7290 net.cpp:163] Memory required for data: 393216000
I0711 18:09:31.811453  7290 layer_factory.hpp:77] Creating layer res2a_branch2a
I0711 18:09:31.811461  7290 net.cpp:98] Creating Layer res2a_branch2a
I0711 18:09:31.811466  7290 net.cpp:439] res2a_branch2a <- pool1
I0711 18:09:31.811471  7290 net.cpp:413] res2a_branch2a -> res2a_branch2a
I0711 18:09:31.812367  7290 net.cpp:148] Setting up res2a_branch2a
I0711 18:09:31.812376  7290 net.cpp:155] Top shape: 4 64 160 160 (6553600)
I0711 18:09:31.812378  7290 net.cpp:163] Memory required for data: 419430400
I0711 18:09:31.812388  7290 layer_factory.hpp:77] Creating layer res2a_branch2a/bn
I0711 18:09:31.812396  7290 net.cpp:98] Creating Layer res2a_branch2a/bn
I0711 18:09:31.812400  7290 net.cpp:439] res2a_branch2a/bn <- res2a_branch2a
I0711 18:09:31.812407  7290 net.cpp:413] res2a_branch2a/bn -> res2a_branch2a/bn
I0711 18:09:31.814070  7290 net.cpp:148] Setting up res2a_branch2a/bn
I0711 18:09:31.814081  7290 net.cpp:155] Top shape: 4 64 160 160 (6553600)
I0711 18:09:31.814083  7290 net.cpp:163] Memory required for data: 445644800
I0711 18:09:31.814090  7290 layer_factory.hpp:77] Creating layer res2a_branch2a/relu
I0711 18:09:31.814095  7290 net.cpp:98] Creating Layer res2a_branch2a/relu
I0711 18:09:31.814098  7290 net.cpp:439] res2a_branch2a/relu <- res2a_branch2a/bn
I0711 18:09:31.814101  7290 net.cpp:400] res2a_branch2a/relu -> res2a_branch2a/bn (in-place)
I0711 18:09:31.814105  7290 net.cpp:148] Setting up res2a_branch2a/relu
I0711 18:09:31.814110  7290 net.cpp:155] Top shape: 4 64 160 160 (6553600)
I0711 18:09:31.814110  7290 net.cpp:163] Memory required for data: 471859200
I0711 18:09:31.814112  7290 layer_factory.hpp:77] Creating layer res2a_branch2b
I0711 18:09:31.814118  7290 net.cpp:98] Creating Layer res2a_branch2b
I0711 18:09:31.814121  7290 net.cpp:439] res2a_branch2b <- res2a_branch2a/bn
I0711 18:09:31.814123  7290 net.cpp:413] res2a_branch2b -> res2a_branch2b
I0711 18:09:31.816365  7290 net.cpp:148] Setting up res2a_branch2b
I0711 18:09:31.816382  7290 net.cpp:155] Top shape: 4 64 160 160 (6553600)
I0711 18:09:31.816386  7290 net.cpp:163] Memory required for data: 498073600
I0711 18:09:31.816396  7290 layer_factory.hpp:77] Creating layer res2a_branch2b/bn
I0711 18:09:31.816411  7290 net.cpp:98] Creating Layer res2a_branch2b/bn
I0711 18:09:31.816416  7290 net.cpp:439] res2a_branch2b/bn <- res2a_branch2b
I0711 18:09:31.816426  7290 net.cpp:413] res2a_branch2b/bn -> res2a_branch2b/bn
I0711 18:09:31.841977  7290 net.cpp:148] Setting up res2a_branch2b/bn
I0711 18:09:31.842005  7290 net.cpp:155] Top shape: 4 64 160 160 (6553600)
I0711 18:09:31.842008  7290 net.cpp:163] Memory required for data: 524288000
I0711 18:09:31.842022  7290 layer_factory.hpp:77] Creating layer res2a_branch2b/relu
I0711 18:09:31.842032  7290 net.cpp:98] Creating Layer res2a_branch2b/relu
I0711 18:09:31.842038  7290 net.cpp:439] res2a_branch2b/relu <- res2a_branch2b/bn
I0711 18:09:31.842044  7290 net.cpp:400] res2a_branch2b/relu -> res2a_branch2b/bn (in-place)
I0711 18:09:31.842056  7290 net.cpp:148] Setting up res2a_branch2b/relu
I0711 18:09:31.842062  7290 net.cpp:155] Top shape: 4 64 160 160 (6553600)
I0711 18:09:31.842066  7290 net.cpp:163] Memory required for data: 550502400
I0711 18:09:31.842068  7290 layer_factory.hpp:77] Creating layer pool2
I0711 18:09:31.842077  7290 net.cpp:98] Creating Layer pool2
I0711 18:09:31.842082  7290 net.cpp:439] pool2 <- res2a_branch2b/bn
I0711 18:09:31.842085  7290 net.cpp:413] pool2 -> pool2
I0711 18:09:31.842160  7290 net.cpp:148] Setting up pool2
I0711 18:09:31.842166  7290 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0711 18:09:31.842170  7290 net.cpp:163] Memory required for data: 557056000
I0711 18:09:31.842172  7290 layer_factory.hpp:77] Creating layer res3a_branch2a
I0711 18:09:31.842193  7290 net.cpp:98] Creating Layer res3a_branch2a
I0711 18:09:31.842198  7290 net.cpp:439] res3a_branch2a <- pool2
I0711 18:09:31.842202  7290 net.cpp:413] res3a_branch2a -> res3a_branch2a
I0711 18:09:31.845340  7290 net.cpp:148] Setting up res3a_branch2a
I0711 18:09:31.845357  7290 net.cpp:155] Top shape: 4 128 80 80 (3276800)
I0711 18:09:31.845360  7290 net.cpp:163] Memory required for data: 570163200
I0711 18:09:31.845367  7290 layer_factory.hpp:77] Creating layer res3a_branch2a/bn
I0711 18:09:31.845376  7290 net.cpp:98] Creating Layer res3a_branch2a/bn
I0711 18:09:31.845381  7290 net.cpp:439] res3a_branch2a/bn <- res3a_branch2a
I0711 18:09:31.845386  7290 net.cpp:413] res3a_branch2a/bn -> res3a_branch2a/bn
I0711 18:09:31.846417  7290 net.cpp:148] Setting up res3a_branch2a/bn
I0711 18:09:31.846427  7290 net.cpp:155] Top shape: 4 128 80 80 (3276800)
I0711 18:09:31.846431  7290 net.cpp:163] Memory required for data: 583270400
I0711 18:09:31.846439  7290 layer_factory.hpp:77] Creating layer res3a_branch2a/relu
I0711 18:09:31.846444  7290 net.cpp:98] Creating Layer res3a_branch2a/relu
I0711 18:09:31.846448  7290 net.cpp:439] res3a_branch2a/relu <- res3a_branch2a/bn
I0711 18:09:31.846452  7290 net.cpp:400] res3a_branch2a/relu -> res3a_branch2a/bn (in-place)
I0711 18:09:31.846458  7290 net.cpp:148] Setting up res3a_branch2a/relu
I0711 18:09:31.846462  7290 net.cpp:155] Top shape: 4 128 80 80 (3276800)
I0711 18:09:31.846465  7290 net.cpp:163] Memory required for data: 596377600
I0711 18:09:31.846469  7290 layer_factory.hpp:77] Creating layer res3a_branch2b
I0711 18:09:31.846477  7290 net.cpp:98] Creating Layer res3a_branch2b
I0711 18:09:31.846480  7290 net.cpp:439] res3a_branch2b <- res3a_branch2a/bn
I0711 18:09:31.846485  7290 net.cpp:413] res3a_branch2b -> res3a_branch2b
I0711 18:09:31.848008  7290 net.cpp:148] Setting up res3a_branch2b
I0711 18:09:31.848016  7290 net.cpp:155] Top shape: 4 128 80 80 (3276800)
I0711 18:09:31.848019  7290 net.cpp:163] Memory required for data: 609484800
I0711 18:09:31.848023  7290 layer_factory.hpp:77] Creating layer res3a_branch2b/bn
I0711 18:09:31.848029  7290 net.cpp:98] Creating Layer res3a_branch2b/bn
I0711 18:09:31.848033  7290 net.cpp:439] res3a_branch2b/bn <- res3a_branch2b
I0711 18:09:31.848039  7290 net.cpp:413] res3a_branch2b/bn -> res3a_branch2b/bn
I0711 18:09:31.848960  7290 net.cpp:148] Setting up res3a_branch2b/bn
I0711 18:09:31.848968  7290 net.cpp:155] Top shape: 4 128 80 80 (3276800)
I0711 18:09:31.848970  7290 net.cpp:163] Memory required for data: 622592000
I0711 18:09:31.848978  7290 layer_factory.hpp:77] Creating layer res3a_branch2b/relu
I0711 18:09:31.848984  7290 net.cpp:98] Creating Layer res3a_branch2b/relu
I0711 18:09:31.848987  7290 net.cpp:439] res3a_branch2b/relu <- res3a_branch2b/bn
I0711 18:09:31.848992  7290 net.cpp:400] res3a_branch2b/relu -> res3a_branch2b/bn (in-place)
I0711 18:09:31.848999  7290 net.cpp:148] Setting up res3a_branch2b/relu
I0711 18:09:31.849004  7290 net.cpp:155] Top shape: 4 128 80 80 (3276800)
I0711 18:09:31.849005  7290 net.cpp:163] Memory required for data: 635699200
I0711 18:09:31.849009  7290 layer_factory.hpp:77] Creating layer res3a_branch2b/bn_res3a_branch2b/relu_0_split
I0711 18:09:31.849014  7290 net.cpp:98] Creating Layer res3a_branch2b/bn_res3a_branch2b/relu_0_split
I0711 18:09:31.849020  7290 net.cpp:439] res3a_branch2b/bn_res3a_branch2b/relu_0_split <- res3a_branch2b/bn
I0711 18:09:31.849023  7290 net.cpp:413] res3a_branch2b/bn_res3a_branch2b/relu_0_split -> res3a_branch2b/bn_res3a_branch2b/relu_0_split_0
I0711 18:09:31.849028  7290 net.cpp:413] res3a_branch2b/bn_res3a_branch2b/relu_0_split -> res3a_branch2b/bn_res3a_branch2b/relu_0_split_1
I0711 18:09:31.849088  7290 net.cpp:148] Setting up res3a_branch2b/bn_res3a_branch2b/relu_0_split
I0711 18:09:31.849094  7290 net.cpp:155] Top shape: 4 128 80 80 (3276800)
I0711 18:09:31.849097  7290 net.cpp:155] Top shape: 4 128 80 80 (3276800)
I0711 18:09:31.849102  7290 net.cpp:163] Memory required for data: 661913600
I0711 18:09:31.849118  7290 layer_factory.hpp:77] Creating layer pool3
I0711 18:09:31.849128  7290 net.cpp:98] Creating Layer pool3
I0711 18:09:31.849133  7290 net.cpp:439] pool3 <- res3a_branch2b/bn_res3a_branch2b/relu_0_split_0
I0711 18:09:31.849139  7290 net.cpp:413] pool3 -> pool3
I0711 18:09:31.849200  7290 net.cpp:148] Setting up pool3
I0711 18:09:31.849206  7290 net.cpp:155] Top shape: 4 128 40 40 (819200)
I0711 18:09:31.849210  7290 net.cpp:163] Memory required for data: 665190400
I0711 18:09:31.849212  7290 layer_factory.hpp:77] Creating layer res4a_branch2a
I0711 18:09:31.849222  7290 net.cpp:98] Creating Layer res4a_branch2a
I0711 18:09:31.849226  7290 net.cpp:439] res4a_branch2a <- pool3
I0711 18:09:31.849231  7290 net.cpp:413] res4a_branch2a -> res4a_branch2a
I0711 18:09:31.886525  7290 net.cpp:148] Setting up res4a_branch2a
I0711 18:09:31.886564  7290 net.cpp:155] Top shape: 4 256 40 40 (1638400)
I0711 18:09:31.886567  7290 net.cpp:163] Memory required for data: 671744000
I0711 18:09:31.886579  7290 layer_factory.hpp:77] Creating layer res4a_branch2a/bn
I0711 18:09:31.886593  7290 net.cpp:98] Creating Layer res4a_branch2a/bn
I0711 18:09:31.886598  7290 net.cpp:439] res4a_branch2a/bn <- res4a_branch2a
I0711 18:09:31.886605  7290 net.cpp:413] res4a_branch2a/bn -> res4a_branch2a/bn
I0711 18:09:31.887536  7290 net.cpp:148] Setting up res4a_branch2a/bn
I0711 18:09:31.887545  7290 net.cpp:155] Top shape: 4 256 40 40 (1638400)
I0711 18:09:31.887547  7290 net.cpp:163] Memory required for data: 678297600
I0711 18:09:31.887554  7290 layer_factory.hpp:77] Creating layer res4a_branch2a/relu
I0711 18:09:31.887560  7290 net.cpp:98] Creating Layer res4a_branch2a/relu
I0711 18:09:31.887563  7290 net.cpp:439] res4a_branch2a/relu <- res4a_branch2a/bn
I0711 18:09:31.887565  7290 net.cpp:400] res4a_branch2a/relu -> res4a_branch2a/bn (in-place)
I0711 18:09:31.887570  7290 net.cpp:148] Setting up res4a_branch2a/relu
I0711 18:09:31.887573  7290 net.cpp:155] Top shape: 4 256 40 40 (1638400)
I0711 18:09:31.887575  7290 net.cpp:163] Memory required for data: 684851200
I0711 18:09:31.887578  7290 layer_factory.hpp:77] Creating layer res4a_branch2b
I0711 18:09:31.887585  7290 net.cpp:98] Creating Layer res4a_branch2b
I0711 18:09:31.887588  7290 net.cpp:439] res4a_branch2b <- res4a_branch2a/bn
I0711 18:09:31.887590  7290 net.cpp:413] res4a_branch2b -> res4a_branch2b
I0711 18:09:31.898526  7290 net.cpp:148] Setting up res4a_branch2b
I0711 18:09:31.898561  7290 net.cpp:155] Top shape: 4 256 40 40 (1638400)
I0711 18:09:31.898567  7290 net.cpp:163] Memory required for data: 691404800
I0711 18:09:31.898583  7290 layer_factory.hpp:77] Creating layer res4a_branch2b/bn
I0711 18:09:31.898602  7290 net.cpp:98] Creating Layer res4a_branch2b/bn
I0711 18:09:31.898610  7290 net.cpp:439] res4a_branch2b/bn <- res4a_branch2b
I0711 18:09:31.898620  7290 net.cpp:413] res4a_branch2b/bn -> res4a_branch2b/bn
I0711 18:09:31.901593  7290 net.cpp:148] Setting up res4a_branch2b/bn
I0711 18:09:31.901643  7290 net.cpp:155] Top shape: 4 256 40 40 (1638400)
I0711 18:09:31.901650  7290 net.cpp:163] Memory required for data: 697958400
I0711 18:09:31.901669  7290 layer_factory.hpp:77] Creating layer res4a_branch2b/relu
I0711 18:09:31.901693  7290 net.cpp:98] Creating Layer res4a_branch2b/relu
I0711 18:09:31.901705  7290 net.cpp:439] res4a_branch2b/relu <- res4a_branch2b/bn
I0711 18:09:31.901715  7290 net.cpp:400] res4a_branch2b/relu -> res4a_branch2b/bn (in-place)
I0711 18:09:31.901736  7290 net.cpp:148] Setting up res4a_branch2b/relu
I0711 18:09:31.901741  7290 net.cpp:155] Top shape: 4 256 40 40 (1638400)
I0711 18:09:31.901744  7290 net.cpp:163] Memory required for data: 704512000
I0711 18:09:31.901748  7290 layer_factory.hpp:77] Creating layer pool4
I0711 18:09:31.901759  7290 net.cpp:98] Creating Layer pool4
I0711 18:09:31.901764  7290 net.cpp:439] pool4 <- res4a_branch2b/bn
I0711 18:09:31.901772  7290 net.cpp:413] pool4 -> pool4
I0711 18:09:31.901862  7290 net.cpp:148] Setting up pool4
I0711 18:09:31.901871  7290 net.cpp:155] Top shape: 4 256 40 40 (1638400)
I0711 18:09:31.901875  7290 net.cpp:163] Memory required for data: 711065600
I0711 18:09:31.901901  7290 layer_factory.hpp:77] Creating layer res5a_branch2a
I0711 18:09:31.901916  7290 net.cpp:98] Creating Layer res5a_branch2a
I0711 18:09:31.901923  7290 net.cpp:439] res5a_branch2a <- pool4
I0711 18:09:31.901929  7290 net.cpp:413] res5a_branch2a -> res5a_branch2a
I0711 18:09:31.938400  7290 net.cpp:148] Setting up res5a_branch2a
I0711 18:09:31.938436  7290 net.cpp:155] Top shape: 4 512 40 40 (3276800)
I0711 18:09:31.938439  7290 net.cpp:163] Memory required for data: 724172800
I0711 18:09:31.938449  7290 layer_factory.hpp:77] Creating layer res5a_branch2a/bn
I0711 18:09:31.938462  7290 net.cpp:98] Creating Layer res5a_branch2a/bn
I0711 18:09:31.938468  7290 net.cpp:439] res5a_branch2a/bn <- res5a_branch2a
I0711 18:09:31.938474  7290 net.cpp:413] res5a_branch2a/bn -> res5a_branch2a/bn
I0711 18:09:31.939641  7290 net.cpp:148] Setting up res5a_branch2a/bn
I0711 18:09:31.939651  7290 net.cpp:155] Top shape: 4 512 40 40 (3276800)
I0711 18:09:31.939653  7290 net.cpp:163] Memory required for data: 737280000
I0711 18:09:31.939666  7290 layer_factory.hpp:77] Creating layer res5a_branch2a/relu
I0711 18:09:31.939671  7290 net.cpp:98] Creating Layer res5a_branch2a/relu
I0711 18:09:31.939677  7290 net.cpp:439] res5a_branch2a/relu <- res5a_branch2a/bn
I0711 18:09:31.939680  7290 net.cpp:400] res5a_branch2a/relu -> res5a_branch2a/bn (in-place)
I0711 18:09:31.939687  7290 net.cpp:148] Setting up res5a_branch2a/relu
I0711 18:09:31.939692  7290 net.cpp:155] Top shape: 4 512 40 40 (3276800)
I0711 18:09:31.939695  7290 net.cpp:163] Memory required for data: 750387200
I0711 18:09:31.939699  7290 layer_factory.hpp:77] Creating layer res5a_branch2b
I0711 18:09:31.939707  7290 net.cpp:98] Creating Layer res5a_branch2b
I0711 18:09:31.939710  7290 net.cpp:439] res5a_branch2b <- res5a_branch2a/bn
I0711 18:09:31.939714  7290 net.cpp:413] res5a_branch2b -> res5a_branch2b
I0711 18:09:31.959228  7290 net.cpp:148] Setting up res5a_branch2b
I0711 18:09:31.959251  7290 net.cpp:155] Top shape: 4 512 40 40 (3276800)
I0711 18:09:31.959254  7290 net.cpp:163] Memory required for data: 763494400
I0711 18:09:31.959264  7290 layer_factory.hpp:77] Creating layer res5a_branch2b/bn
I0711 18:09:31.959271  7290 net.cpp:98] Creating Layer res5a_branch2b/bn
I0711 18:09:31.959276  7290 net.cpp:439] res5a_branch2b/bn <- res5a_branch2b
I0711 18:09:31.959280  7290 net.cpp:413] res5a_branch2b/bn -> res5a_branch2b/bn
I0711 18:09:31.960026  7290 net.cpp:148] Setting up res5a_branch2b/bn
I0711 18:09:31.960032  7290 net.cpp:155] Top shape: 4 512 40 40 (3276800)
I0711 18:09:31.960034  7290 net.cpp:163] Memory required for data: 776601600
I0711 18:09:31.960039  7290 layer_factory.hpp:77] Creating layer res5a_branch2b/relu
I0711 18:09:31.960043  7290 net.cpp:98] Creating Layer res5a_branch2b/relu
I0711 18:09:31.960052  7290 net.cpp:439] res5a_branch2b/relu <- res5a_branch2b/bn
I0711 18:09:31.960054  7290 net.cpp:400] res5a_branch2b/relu -> res5a_branch2b/bn (in-place)
I0711 18:09:31.960058  7290 net.cpp:148] Setting up res5a_branch2b/relu
I0711 18:09:31.960062  7290 net.cpp:155] Top shape: 4 512 40 40 (3276800)
I0711 18:09:31.960063  7290 net.cpp:163] Memory required for data: 789708800
I0711 18:09:31.960065  7290 layer_factory.hpp:77] Creating layer out5a
I0711 18:09:31.960072  7290 net.cpp:98] Creating Layer out5a
I0711 18:09:31.960074  7290 net.cpp:439] out5a <- res5a_branch2b/bn
I0711 18:09:31.960078  7290 net.cpp:413] out5a -> out5a
I0711 18:09:31.964403  7290 net.cpp:148] Setting up out5a
I0711 18:09:31.964421  7290 net.cpp:155] Top shape: 4 64 40 40 (409600)
I0711 18:09:31.964423  7290 net.cpp:163] Memory required for data: 791347200
I0711 18:09:31.964428  7290 layer_factory.hpp:77] Creating layer out5a/bn
I0711 18:09:31.964443  7290 net.cpp:98] Creating Layer out5a/bn
I0711 18:09:31.964447  7290 net.cpp:439] out5a/bn <- out5a
I0711 18:09:31.964450  7290 net.cpp:413] out5a/bn -> out5a/bn
I0711 18:09:31.965260  7290 net.cpp:148] Setting up out5a/bn
I0711 18:09:31.965267  7290 net.cpp:155] Top shape: 4 64 40 40 (409600)
I0711 18:09:31.965279  7290 net.cpp:163] Memory required for data: 792985600
I0711 18:09:31.965284  7290 layer_factory.hpp:77] Creating layer out5a/relu
I0711 18:09:31.965288  7290 net.cpp:98] Creating Layer out5a/relu
I0711 18:09:31.965291  7290 net.cpp:439] out5a/relu <- out5a/bn
I0711 18:09:31.965293  7290 net.cpp:400] out5a/relu -> out5a/bn (in-place)
I0711 18:09:31.965297  7290 net.cpp:148] Setting up out5a/relu
I0711 18:09:31.965299  7290 net.cpp:155] Top shape: 4 64 40 40 (409600)
I0711 18:09:31.965301  7290 net.cpp:163] Memory required for data: 794624000
I0711 18:09:31.965303  7290 layer_factory.hpp:77] Creating layer out5a_up2
I0711 18:09:31.965307  7290 net.cpp:98] Creating Layer out5a_up2
I0711 18:09:31.965309  7290 net.cpp:439] out5a_up2 <- out5a/bn
I0711 18:09:31.965312  7290 net.cpp:413] out5a_up2 -> out5a_up2
I0711 18:09:31.965600  7290 net.cpp:148] Setting up out5a_up2
I0711 18:09:31.965605  7290 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0711 18:09:31.965606  7290 net.cpp:163] Memory required for data: 801177600
I0711 18:09:31.965610  7290 layer_factory.hpp:77] Creating layer out3a
I0711 18:09:31.965613  7290 net.cpp:98] Creating Layer out3a
I0711 18:09:31.965616  7290 net.cpp:439] out3a <- res3a_branch2b/bn_res3a_branch2b/relu_0_split_1
I0711 18:09:31.965620  7290 net.cpp:413] out3a -> out3a
I0711 18:09:31.967731  7290 net.cpp:148] Setting up out3a
I0711 18:09:31.967742  7290 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0711 18:09:31.967744  7290 net.cpp:163] Memory required for data: 807731200
I0711 18:09:31.967749  7290 layer_factory.hpp:77] Creating layer out3a/bn
I0711 18:09:31.967754  7290 net.cpp:98] Creating Layer out3a/bn
I0711 18:09:31.967756  7290 net.cpp:439] out3a/bn <- out3a
I0711 18:09:31.967761  7290 net.cpp:413] out3a/bn -> out3a/bn
I0711 18:09:31.968570  7290 net.cpp:148] Setting up out3a/bn
I0711 18:09:31.968577  7290 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0711 18:09:31.968580  7290 net.cpp:163] Memory required for data: 814284800
I0711 18:09:31.968585  7290 layer_factory.hpp:77] Creating layer out3a/relu
I0711 18:09:31.968587  7290 net.cpp:98] Creating Layer out3a/relu
I0711 18:09:31.968590  7290 net.cpp:439] out3a/relu <- out3a/bn
I0711 18:09:31.968592  7290 net.cpp:400] out3a/relu -> out3a/bn (in-place)
I0711 18:09:31.968596  7290 net.cpp:148] Setting up out3a/relu
I0711 18:09:31.968598  7290 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0711 18:09:31.968600  7290 net.cpp:163] Memory required for data: 820838400
I0711 18:09:31.968602  7290 layer_factory.hpp:77] Creating layer out3_out5_combined
I0711 18:09:31.968606  7290 net.cpp:98] Creating Layer out3_out5_combined
I0711 18:09:31.968608  7290 net.cpp:439] out3_out5_combined <- out5a_up2
I0711 18:09:31.968611  7290 net.cpp:439] out3_out5_combined <- out3a/bn
I0711 18:09:31.968612  7290 net.cpp:413] out3_out5_combined -> out3_out5_combined
I0711 18:09:31.968637  7290 net.cpp:148] Setting up out3_out5_combined
I0711 18:09:31.968641  7290 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0711 18:09:31.968643  7290 net.cpp:163] Memory required for data: 827392000
I0711 18:09:31.968646  7290 layer_factory.hpp:77] Creating layer ctx_conv1
I0711 18:09:31.968650  7290 net.cpp:98] Creating Layer ctx_conv1
I0711 18:09:31.968652  7290 net.cpp:439] ctx_conv1 <- out3_out5_combined
I0711 18:09:31.968657  7290 net.cpp:413] ctx_conv1 -> ctx_conv1
I0711 18:09:31.969722  7290 net.cpp:148] Setting up ctx_conv1
I0711 18:09:31.969727  7290 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0711 18:09:31.969729  7290 net.cpp:163] Memory required for data: 833945600
I0711 18:09:31.969732  7290 layer_factory.hpp:77] Creating layer ctx_conv1/bn
I0711 18:09:31.969735  7290 net.cpp:98] Creating Layer ctx_conv1/bn
I0711 18:09:31.969738  7290 net.cpp:439] ctx_conv1/bn <- ctx_conv1
I0711 18:09:31.969740  7290 net.cpp:413] ctx_conv1/bn -> ctx_conv1/bn
I0711 18:09:31.970549  7290 net.cpp:148] Setting up ctx_conv1/bn
I0711 18:09:31.970554  7290 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0711 18:09:31.970556  7290 net.cpp:163] Memory required for data: 840499200
I0711 18:09:31.970569  7290 layer_factory.hpp:77] Creating layer ctx_conv1/relu
I0711 18:09:31.970572  7290 net.cpp:98] Creating Layer ctx_conv1/relu
I0711 18:09:31.970576  7290 net.cpp:439] ctx_conv1/relu <- ctx_conv1/bn
I0711 18:09:31.970577  7290 net.cpp:400] ctx_conv1/relu -> ctx_conv1/bn (in-place)
I0711 18:09:31.970580  7290 net.cpp:148] Setting up ctx_conv1/relu
I0711 18:09:31.970583  7290 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0711 18:09:31.970585  7290 net.cpp:163] Memory required for data: 847052800
I0711 18:09:31.970587  7290 layer_factory.hpp:77] Creating layer ctx_conv2
I0711 18:09:31.970592  7290 net.cpp:98] Creating Layer ctx_conv2
I0711 18:09:31.970595  7290 net.cpp:439] ctx_conv2 <- ctx_conv1/bn
I0711 18:09:31.970598  7290 net.cpp:413] ctx_conv2 -> ctx_conv2
I0711 18:09:31.971653  7290 net.cpp:148] Setting up ctx_conv2
I0711 18:09:31.971658  7290 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0711 18:09:31.971660  7290 net.cpp:163] Memory required for data: 853606400
I0711 18:09:31.971663  7290 layer_factory.hpp:77] Creating layer ctx_conv2/bn
I0711 18:09:31.971667  7290 net.cpp:98] Creating Layer ctx_conv2/bn
I0711 18:09:31.971668  7290 net.cpp:439] ctx_conv2/bn <- ctx_conv2
I0711 18:09:31.971671  7290 net.cpp:413] ctx_conv2/bn -> ctx_conv2/bn
I0711 18:09:31.972483  7290 net.cpp:148] Setting up ctx_conv2/bn
I0711 18:09:31.972491  7290 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0711 18:09:31.972492  7290 net.cpp:163] Memory required for data: 860160000
I0711 18:09:31.972496  7290 layer_factory.hpp:77] Creating layer ctx_conv2/relu
I0711 18:09:31.972499  7290 net.cpp:98] Creating Layer ctx_conv2/relu
I0711 18:09:31.972501  7290 net.cpp:439] ctx_conv2/relu <- ctx_conv2/bn
I0711 18:09:31.972503  7290 net.cpp:400] ctx_conv2/relu -> ctx_conv2/bn (in-place)
I0711 18:09:31.972507  7290 net.cpp:148] Setting up ctx_conv2/relu
I0711 18:09:31.972509  7290 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0711 18:09:31.972512  7290 net.cpp:163] Memory required for data: 866713600
I0711 18:09:31.972513  7290 layer_factory.hpp:77] Creating layer ctx_conv3
I0711 18:09:31.972517  7290 net.cpp:98] Creating Layer ctx_conv3
I0711 18:09:31.972519  7290 net.cpp:439] ctx_conv3 <- ctx_conv2/bn
I0711 18:09:31.972522  7290 net.cpp:413] ctx_conv3 -> ctx_conv3
I0711 18:09:31.973588  7290 net.cpp:148] Setting up ctx_conv3
I0711 18:09:31.973594  7290 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0711 18:09:31.973597  7290 net.cpp:163] Memory required for data: 873267200
I0711 18:09:31.973599  7290 layer_factory.hpp:77] Creating layer ctx_conv3/bn
I0711 18:09:31.973603  7290 net.cpp:98] Creating Layer ctx_conv3/bn
I0711 18:09:31.973605  7290 net.cpp:439] ctx_conv3/bn <- ctx_conv3
I0711 18:09:31.973608  7290 net.cpp:413] ctx_conv3/bn -> ctx_conv3/bn
I0711 18:09:31.974416  7290 net.cpp:148] Setting up ctx_conv3/bn
I0711 18:09:31.974421  7290 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0711 18:09:31.974423  7290 net.cpp:163] Memory required for data: 879820800
I0711 18:09:31.974428  7290 layer_factory.hpp:77] Creating layer ctx_conv3/relu
I0711 18:09:31.974432  7290 net.cpp:98] Creating Layer ctx_conv3/relu
I0711 18:09:31.974436  7290 net.cpp:439] ctx_conv3/relu <- ctx_conv3/bn
I0711 18:09:31.974437  7290 net.cpp:400] ctx_conv3/relu -> ctx_conv3/bn (in-place)
I0711 18:09:31.974440  7290 net.cpp:148] Setting up ctx_conv3/relu
I0711 18:09:31.974443  7290 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0711 18:09:31.974445  7290 net.cpp:163] Memory required for data: 886374400
I0711 18:09:31.974449  7290 layer_factory.hpp:77] Creating layer ctx_conv4
I0711 18:09:31.974452  7290 net.cpp:98] Creating Layer ctx_conv4
I0711 18:09:31.974457  7290 net.cpp:439] ctx_conv4 <- ctx_conv3/bn
I0711 18:09:31.974459  7290 net.cpp:413] ctx_conv4 -> ctx_conv4
I0711 18:09:31.975518  7290 net.cpp:148] Setting up ctx_conv4
I0711 18:09:31.975524  7290 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0711 18:09:31.975527  7290 net.cpp:163] Memory required for data: 892928000
I0711 18:09:31.975529  7290 layer_factory.hpp:77] Creating layer ctx_conv4/bn
I0711 18:09:31.975539  7290 net.cpp:98] Creating Layer ctx_conv4/bn
I0711 18:09:31.975543  7290 net.cpp:439] ctx_conv4/bn <- ctx_conv4
I0711 18:09:31.975545  7290 net.cpp:413] ctx_conv4/bn -> ctx_conv4/bn
I0711 18:09:31.976346  7290 net.cpp:148] Setting up ctx_conv4/bn
I0711 18:09:31.976351  7290 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0711 18:09:31.976353  7290 net.cpp:163] Memory required for data: 899481600
I0711 18:09:31.976357  7290 layer_factory.hpp:77] Creating layer ctx_conv4/relu
I0711 18:09:31.976361  7290 net.cpp:98] Creating Layer ctx_conv4/relu
I0711 18:09:31.976363  7290 net.cpp:439] ctx_conv4/relu <- ctx_conv4/bn
I0711 18:09:31.976366  7290 net.cpp:400] ctx_conv4/relu -> ctx_conv4/bn (in-place)
I0711 18:09:31.976369  7290 net.cpp:148] Setting up ctx_conv4/relu
I0711 18:09:31.976372  7290 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0711 18:09:31.976375  7290 net.cpp:163] Memory required for data: 906035200
I0711 18:09:31.976377  7290 layer_factory.hpp:77] Creating layer ctx_final
I0711 18:09:31.976380  7290 net.cpp:98] Creating Layer ctx_final
I0711 18:09:31.976383  7290 net.cpp:439] ctx_final <- ctx_conv4/bn
I0711 18:09:31.976385  7290 net.cpp:413] ctx_final -> ctx_final
I0711 18:09:31.976821  7290 net.cpp:148] Setting up ctx_final
I0711 18:09:31.976827  7290 net.cpp:155] Top shape: 4 8 80 80 (204800)
I0711 18:09:31.976830  7290 net.cpp:163] Memory required for data: 906854400
I0711 18:09:31.976832  7290 layer_factory.hpp:77] Creating layer ctx_final/relu
I0711 18:09:31.976835  7290 net.cpp:98] Creating Layer ctx_final/relu
I0711 18:09:31.976837  7290 net.cpp:439] ctx_final/relu <- ctx_final
I0711 18:09:31.976840  7290 net.cpp:400] ctx_final/relu -> ctx_final (in-place)
I0711 18:09:31.976843  7290 net.cpp:148] Setting up ctx_final/relu
I0711 18:09:31.976846  7290 net.cpp:155] Top shape: 4 8 80 80 (204800)
I0711 18:09:31.976848  7290 net.cpp:163] Memory required for data: 907673600
I0711 18:09:31.976850  7290 layer_factory.hpp:77] Creating layer out_deconv_final_up2
I0711 18:09:31.976853  7290 net.cpp:98] Creating Layer out_deconv_final_up2
I0711 18:09:31.976856  7290 net.cpp:439] out_deconv_final_up2 <- ctx_final
I0711 18:09:31.976860  7290 net.cpp:413] out_deconv_final_up2 -> out_deconv_final_up2
I0711 18:09:31.977118  7290 net.cpp:148] Setting up out_deconv_final_up2
I0711 18:09:31.977123  7290 net.cpp:155] Top shape: 4 8 160 160 (819200)
I0711 18:09:31.977124  7290 net.cpp:163] Memory required for data: 910950400
I0711 18:09:31.977128  7290 layer_factory.hpp:77] Creating layer out_deconv_final_up4
I0711 18:09:31.977130  7290 net.cpp:98] Creating Layer out_deconv_final_up4
I0711 18:09:31.977133  7290 net.cpp:439] out_deconv_final_up4 <- out_deconv_final_up2
I0711 18:09:31.977136  7290 net.cpp:413] out_deconv_final_up4 -> out_deconv_final_up4
I0711 18:09:31.977394  7290 net.cpp:148] Setting up out_deconv_final_up4
I0711 18:09:31.977399  7290 net.cpp:155] Top shape: 4 8 320 320 (3276800)
I0711 18:09:31.977401  7290 net.cpp:163] Memory required for data: 924057600
I0711 18:09:31.977404  7290 layer_factory.hpp:77] Creating layer out_deconv_final_up8
I0711 18:09:31.977407  7290 net.cpp:98] Creating Layer out_deconv_final_up8
I0711 18:09:31.977411  7290 net.cpp:439] out_deconv_final_up8 <- out_deconv_final_up4
I0711 18:09:31.977413  7290 net.cpp:413] out_deconv_final_up8 -> out_deconv_final_up8
I0711 18:09:31.977661  7290 net.cpp:148] Setting up out_deconv_final_up8
I0711 18:09:31.977666  7290 net.cpp:155] Top shape: 4 8 640 640 (13107200)
I0711 18:09:31.977669  7290 net.cpp:163] Memory required for data: 976486400
I0711 18:09:31.977671  7290 layer_factory.hpp:77] Creating layer out_deconv_final_up8_out_deconv_final_up8_0_split
I0711 18:09:31.977675  7290 net.cpp:98] Creating Layer out_deconv_final_up8_out_deconv_final_up8_0_split
I0711 18:09:31.977677  7290 net.cpp:439] out_deconv_final_up8_out_deconv_final_up8_0_split <- out_deconv_final_up8
I0711 18:09:31.977680  7290 net.cpp:413] out_deconv_final_up8_out_deconv_final_up8_0_split -> out_deconv_final_up8_out_deconv_final_up8_0_split_0
I0711 18:09:31.977689  7290 net.cpp:413] out_deconv_final_up8_out_deconv_final_up8_0_split -> out_deconv_final_up8_out_deconv_final_up8_0_split_1
I0711 18:09:31.977694  7290 net.cpp:413] out_deconv_final_up8_out_deconv_final_up8_0_split -> out_deconv_final_up8_out_deconv_final_up8_0_split_2
I0711 18:09:31.977752  7290 net.cpp:148] Setting up out_deconv_final_up8_out_deconv_final_up8_0_split
I0711 18:09:31.977757  7290 net.cpp:155] Top shape: 4 8 640 640 (13107200)
I0711 18:09:31.977759  7290 net.cpp:155] Top shape: 4 8 640 640 (13107200)
I0711 18:09:31.977762  7290 net.cpp:155] Top shape: 4 8 640 640 (13107200)
I0711 18:09:31.977764  7290 net.cpp:163] Memory required for data: 1133772800
I0711 18:09:31.977766  7290 layer_factory.hpp:77] Creating layer loss
I0711 18:09:31.977771  7290 net.cpp:98] Creating Layer loss
I0711 18:09:31.977774  7290 net.cpp:439] loss <- out_deconv_final_up8_out_deconv_final_up8_0_split_0
I0711 18:09:31.977777  7290 net.cpp:439] loss <- label_data_1_split_0
I0711 18:09:31.977779  7290 net.cpp:413] loss -> loss
I0711 18:09:31.977784  7290 layer_factory.hpp:77] Creating layer loss
I0711 18:09:31.996263  7290 net.cpp:148] Setting up loss
I0711 18:09:31.996284  7290 net.cpp:155] Top shape: (1)
I0711 18:09:31.996287  7290 net.cpp:158]     with loss weight 1
I0711 18:09:31.996295  7290 net.cpp:163] Memory required for data: 1133772804
I0711 18:09:31.996299  7290 layer_factory.hpp:77] Creating layer accuracy/top1
I0711 18:09:31.996306  7290 net.cpp:98] Creating Layer accuracy/top1
I0711 18:09:31.996311  7290 net.cpp:439] accuracy/top1 <- out_deconv_final_up8_out_deconv_final_up8_0_split_1
I0711 18:09:31.996316  7290 net.cpp:439] accuracy/top1 <- label_data_1_split_1
I0711 18:09:31.996320  7290 net.cpp:413] accuracy/top1 -> accuracy/top1
I0711 18:09:31.996328  7290 net.cpp:148] Setting up accuracy/top1
I0711 18:09:31.996331  7290 net.cpp:155] Top shape: (1)
I0711 18:09:31.996333  7290 net.cpp:163] Memory required for data: 1133772808
I0711 18:09:31.996335  7290 layer_factory.hpp:77] Creating layer accuracy/top5
I0711 18:09:31.996338  7290 net.cpp:98] Creating Layer accuracy/top5
I0711 18:09:31.996341  7290 net.cpp:439] accuracy/top5 <- out_deconv_final_up8_out_deconv_final_up8_0_split_2
I0711 18:09:31.996343  7290 net.cpp:439] accuracy/top5 <- label_data_1_split_2
I0711 18:09:31.996347  7290 net.cpp:413] accuracy/top5 -> accuracy/top5
I0711 18:09:31.996351  7290 net.cpp:148] Setting up accuracy/top5
I0711 18:09:31.996353  7290 net.cpp:155] Top shape: (1)
I0711 18:09:31.996356  7290 net.cpp:163] Memory required for data: 1133772812
I0711 18:09:31.996357  7290 net.cpp:226] accuracy/top5 does not need backward computation.
I0711 18:09:31.996359  7290 net.cpp:226] accuracy/top1 does not need backward computation.
I0711 18:09:31.996362  7290 net.cpp:224] loss needs backward computation.
I0711 18:09:31.996366  7290 net.cpp:224] out_deconv_final_up8_out_deconv_final_up8_0_split needs backward computation.
I0711 18:09:31.996367  7290 net.cpp:224] out_deconv_final_up8 needs backward computation.
I0711 18:09:31.996369  7290 net.cpp:224] out_deconv_final_up4 needs backward computation.
I0711 18:09:31.996371  7290 net.cpp:224] out_deconv_final_up2 needs backward computation.
I0711 18:09:31.996374  7290 net.cpp:224] ctx_final/relu needs backward computation.
I0711 18:09:31.996377  7290 net.cpp:224] ctx_final needs backward computation.
I0711 18:09:31.996379  7290 net.cpp:224] ctx_conv4/relu needs backward computation.
I0711 18:09:31.996381  7290 net.cpp:224] ctx_conv4/bn needs backward computation.
I0711 18:09:31.996383  7290 net.cpp:224] ctx_conv4 needs backward computation.
I0711 18:09:31.996386  7290 net.cpp:224] ctx_conv3/relu needs backward computation.
I0711 18:09:31.996387  7290 net.cpp:224] ctx_conv3/bn needs backward computation.
I0711 18:09:31.996389  7290 net.cpp:224] ctx_conv3 needs backward computation.
I0711 18:09:31.996392  7290 net.cpp:224] ctx_conv2/relu needs backward computation.
I0711 18:09:31.996394  7290 net.cpp:224] ctx_conv2/bn needs backward computation.
I0711 18:09:31.996397  7290 net.cpp:224] ctx_conv2 needs backward computation.
I0711 18:09:31.996408  7290 net.cpp:224] ctx_conv1/relu needs backward computation.
I0711 18:09:31.996410  7290 net.cpp:224] ctx_conv1/bn needs backward computation.
I0711 18:09:31.996413  7290 net.cpp:224] ctx_conv1 needs backward computation.
I0711 18:09:31.996417  7290 net.cpp:224] out3_out5_combined needs backward computation.
I0711 18:09:31.996418  7290 net.cpp:224] out3a/relu needs backward computation.
I0711 18:09:31.996420  7290 net.cpp:224] out3a/bn needs backward computation.
I0711 18:09:31.996423  7290 net.cpp:224] out3a needs backward computation.
I0711 18:09:31.996425  7290 net.cpp:224] out5a_up2 needs backward computation.
I0711 18:09:31.996428  7290 net.cpp:224] out5a/relu needs backward computation.
I0711 18:09:31.996430  7290 net.cpp:224] out5a/bn needs backward computation.
I0711 18:09:31.996433  7290 net.cpp:224] out5a needs backward computation.
I0711 18:09:31.996435  7290 net.cpp:224] res5a_branch2b/relu needs backward computation.
I0711 18:09:31.996438  7290 net.cpp:224] res5a_branch2b/bn needs backward computation.
I0711 18:09:31.996440  7290 net.cpp:224] res5a_branch2b needs backward computation.
I0711 18:09:31.996443  7290 net.cpp:224] res5a_branch2a/relu needs backward computation.
I0711 18:09:31.996445  7290 net.cpp:224] res5a_branch2a/bn needs backward computation.
I0711 18:09:31.996448  7290 net.cpp:224] res5a_branch2a needs backward computation.
I0711 18:09:31.996450  7290 net.cpp:224] pool4 needs backward computation.
I0711 18:09:31.996454  7290 net.cpp:224] res4a_branch2b/relu needs backward computation.
I0711 18:09:31.996455  7290 net.cpp:224] res4a_branch2b/bn needs backward computation.
I0711 18:09:31.996457  7290 net.cpp:224] res4a_branch2b needs backward computation.
I0711 18:09:31.996460  7290 net.cpp:224] res4a_branch2a/relu needs backward computation.
I0711 18:09:31.996462  7290 net.cpp:224] res4a_branch2a/bn needs backward computation.
I0711 18:09:31.996464  7290 net.cpp:224] res4a_branch2a needs backward computation.
I0711 18:09:31.996467  7290 net.cpp:224] pool3 needs backward computation.
I0711 18:09:31.996469  7290 net.cpp:224] res3a_branch2b/bn_res3a_branch2b/relu_0_split needs backward computation.
I0711 18:09:31.996472  7290 net.cpp:224] res3a_branch2b/relu needs backward computation.
I0711 18:09:31.996474  7290 net.cpp:224] res3a_branch2b/bn needs backward computation.
I0711 18:09:31.996476  7290 net.cpp:224] res3a_branch2b needs backward computation.
I0711 18:09:31.996479  7290 net.cpp:224] res3a_branch2a/relu needs backward computation.
I0711 18:09:31.996482  7290 net.cpp:224] res3a_branch2a/bn needs backward computation.
I0711 18:09:31.996484  7290 net.cpp:224] res3a_branch2a needs backward computation.
I0711 18:09:31.996486  7290 net.cpp:224] pool2 needs backward computation.
I0711 18:09:31.996490  7290 net.cpp:224] res2a_branch2b/relu needs backward computation.
I0711 18:09:31.996492  7290 net.cpp:224] res2a_branch2b/bn needs backward computation.
I0711 18:09:31.996495  7290 net.cpp:224] res2a_branch2b needs backward computation.
I0711 18:09:31.996497  7290 net.cpp:224] res2a_branch2a/relu needs backward computation.
I0711 18:09:31.996500  7290 net.cpp:224] res2a_branch2a/bn needs backward computation.
I0711 18:09:31.996502  7290 net.cpp:224] res2a_branch2a needs backward computation.
I0711 18:09:31.996505  7290 net.cpp:224] pool1 needs backward computation.
I0711 18:09:31.996506  7290 net.cpp:224] conv1b/relu needs backward computation.
I0711 18:09:31.996508  7290 net.cpp:224] conv1b/bn needs backward computation.
I0711 18:09:31.996511  7290 net.cpp:224] conv1b needs backward computation.
I0711 18:09:31.996513  7290 net.cpp:224] conv1a/relu needs backward computation.
I0711 18:09:31.996515  7290 net.cpp:224] conv1a/bn needs backward computation.
I0711 18:09:31.996517  7290 net.cpp:224] conv1a needs backward computation.
I0711 18:09:31.996520  7290 net.cpp:226] data/bias does not need backward computation.
I0711 18:09:31.996523  7290 net.cpp:226] label_data_1_split does not need backward computation.
I0711 18:09:31.996526  7290 net.cpp:226] data does not need backward computation.
I0711 18:09:31.996531  7290 net.cpp:268] This network produces output accuracy/top1
I0711 18:09:31.996534  7290 net.cpp:268] This network produces output accuracy/top5
I0711 18:09:31.996536  7290 net.cpp:268] This network produces output loss
I0711 18:09:31.996569  7290 net.cpp:288] Network initialization done.
I0711 18:09:31.996666  7290 solver.cpp:60] Solver scaffolding done.
I0711 18:09:32.004822  7290 caffe.cpp:145] Finetuning from training/imagenet_jacintonet11v2_iter_320000.caffemodel
I0711 18:09:32.116971  7290 net.cpp:804] Ignoring source layer pool5
I0711 18:09:32.116991  7290 net.cpp:804] Ignoring source layer fc1000
I0711 18:09:32.127862  7290 net.cpp:804] Ignoring source layer pool5
I0711 18:09:32.127882  7290 net.cpp:804] Ignoring source layer fc1000
I0711 18:09:32.141258  7290 data_layer.cpp:78] ReshapePrefetch 5, 3, 640, 640
I0711 18:09:32.141343  7290 data_layer.cpp:83] output data size: 5,3,640,640
I0711 18:09:32.177129  7290 data_layer.cpp:78] ReshapePrefetch 5, 1, 640, 640
I0711 18:09:32.177563  7290 data_layer.cpp:83] output data size: 5,1,640,640
I0711 18:09:34.819324  7290 data_layer.cpp:78] ReshapePrefetch 5, 3, 640, 640
I0711 18:09:34.819582  7290 data_layer.cpp:83] output data size: 5,3,640,640
I0711 18:09:35.451122  7290 data_layer.cpp:78] ReshapePrefetch 5, 1, 640, 640
I0711 18:09:35.454493  7290 data_layer.cpp:83] output data size: 5,1,640,640
I0711 18:09:36.430651  7290 parallel.cpp:334] Starting Optimization
I0711 18:09:36.430721  7290 solver.cpp:409] Solving jsegnet21v2_train
I0711 18:09:36.430729  7290 solver.cpp:410] Learning Rate Policy: multistep
I0711 18:09:36.984307  7290 solver.cpp:290] Iteration 0 (0 iter/s, 0.553501s/100 iter), loss = 1.91868
I0711 18:09:36.984338  7290 solver.cpp:309]     Train net output #0: loss = 1.91868 (* 1 = 1.91868 loss)
I0711 18:09:36.984366  7290 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
I0711 18:09:50.582197  7500 blocking_queue.cpp:50] Data layer prefetch queue empty
I0711 18:09:56.994362  7290 solver.cpp:290] Iteration 100 (4.99763 iter/s, 20.0095s/100 iter), loss = 0.667329
I0711 18:09:56.994395  7290 solver.cpp:309]     Train net output #0: loss = 0.667329 (* 1 = 0.667329 loss)
I0711 18:09:56.994407  7290 sgd_solver.cpp:106] Iteration 100, lr = 0.0001
I0711 18:11:45.395501  7352 blocking_queue.cpp:50] Waiting for data
I0711 18:12:06.712467  7290 solver.cpp:290] Iteration 200 (0.770924 iter/s, 129.715s/100 iter), loss = 0.167559
I0711 18:12:06.712489  7290 solver.cpp:309]     Train net output #0: loss = 0.167559 (* 1 = 0.167559 loss)
I0711 18:12:06.712496  7290 sgd_solver.cpp:106] Iteration 200, lr = 0.0001
I0711 18:12:23.744797  7290 solver.cpp:290] Iteration 300 (5.87136 iter/s, 17.0318s/100 iter), loss = 0.133885
I0711 18:12:23.744843  7290 solver.cpp:309]     Train net output #0: loss = 0.133885 (* 1 = 0.133885 loss)
I0711 18:12:23.744850  7290 sgd_solver.cpp:106] Iteration 300, lr = 0.0001
I0711 18:12:40.786767  7290 solver.cpp:290] Iteration 400 (5.86804 iter/s, 17.0415s/100 iter), loss = 0.0947322
I0711 18:12:40.786789  7290 solver.cpp:309]     Train net output #0: loss = 0.0947322 (* 1 = 0.0947322 loss)
I0711 18:12:40.786797  7290 sgd_solver.cpp:106] Iteration 400, lr = 0.0001
I0711 18:12:58.029858  7290 solver.cpp:290] Iteration 500 (5.79959 iter/s, 17.2426s/100 iter), loss = 0.132188
I0711 18:12:58.029949  7290 solver.cpp:309]     Train net output #0: loss = 0.132188 (* 1 = 0.132188 loss)
I0711 18:12:58.029960  7290 sgd_solver.cpp:106] Iteration 500, lr = 0.0001
I0711 18:13:15.236356  7290 solver.cpp:290] Iteration 600 (5.81195 iter/s, 17.2059s/100 iter), loss = 0.0519722
I0711 18:13:15.236379  7290 solver.cpp:309]     Train net output #0: loss = 0.0519722 (* 1 = 0.0519722 loss)
I0711 18:13:15.236387  7290 sgd_solver.cpp:106] Iteration 600, lr = 0.0001
I0711 18:13:32.419400  7290 solver.cpp:290] Iteration 700 (5.81986 iter/s, 17.1825s/100 iter), loss = 0.0685836
I0711 18:13:32.419478  7290 solver.cpp:309]     Train net output #0: loss = 0.0685836 (* 1 = 0.0685836 loss)
I0711 18:13:32.419487  7290 sgd_solver.cpp:106] Iteration 700, lr = 0.0001
I0711 18:13:49.525527  7290 solver.cpp:290] Iteration 800 (5.84605 iter/s, 17.1056s/100 iter), loss = 0.185176
I0711 18:13:49.525549  7290 solver.cpp:309]     Train net output #0: loss = 0.185176 (* 1 = 0.185176 loss)
I0711 18:13:49.525557  7290 sgd_solver.cpp:106] Iteration 800, lr = 0.0001
I0711 18:14:06.586501  7290 solver.cpp:290] Iteration 900 (5.8615 iter/s, 17.0605s/100 iter), loss = 0.041229
I0711 18:14:06.586621  7290 solver.cpp:309]     Train net output #0: loss = 0.041229 (* 1 = 0.041229 loss)
I0711 18:14:06.586629  7290 sgd_solver.cpp:106] Iteration 900, lr = 0.0001
I0711 18:14:23.656035  7290 solver.cpp:290] Iteration 1000 (5.85859 iter/s, 17.0689s/100 iter), loss = 0.160046
I0711 18:14:23.656059  7290 solver.cpp:309]     Train net output #0: loss = 0.160046 (* 1 = 0.160046 loss)
I0711 18:14:23.656066  7290 sgd_solver.cpp:106] Iteration 1000, lr = 0.0001
I0711 18:14:40.917798  7290 solver.cpp:290] Iteration 1100 (5.79332 iter/s, 17.2613s/100 iter), loss = 0.0953071
I0711 18:14:40.917850  7290 solver.cpp:309]     Train net output #0: loss = 0.0953072 (* 1 = 0.0953072 loss)
I0711 18:14:40.917858  7290 sgd_solver.cpp:106] Iteration 1100, lr = 0.0001
I0711 18:14:57.918982  7290 solver.cpp:290] Iteration 1200 (5.88212 iter/s, 17.0007s/100 iter), loss = 0.0970717
I0711 18:14:57.919004  7290 solver.cpp:309]     Train net output #0: loss = 0.0970718 (* 1 = 0.0970718 loss)
I0711 18:14:57.919011  7290 sgd_solver.cpp:106] Iteration 1200, lr = 0.0001
I0711 18:15:14.954910  7290 solver.cpp:290] Iteration 1300 (5.87012 iter/s, 17.0354s/100 iter), loss = 0.0564315
I0711 18:15:14.954957  7290 solver.cpp:309]     Train net output #0: loss = 0.0564316 (* 1 = 0.0564316 loss)
I0711 18:15:14.954965  7290 sgd_solver.cpp:106] Iteration 1300, lr = 0.0001
I0711 18:15:32.167434  7290 solver.cpp:290] Iteration 1400 (5.8099 iter/s, 17.212s/100 iter), loss = 0.0944538
I0711 18:15:32.167460  7290 solver.cpp:309]     Train net output #0: loss = 0.0944539 (* 1 = 0.0944539 loss)
I0711 18:15:32.167469  7290 sgd_solver.cpp:106] Iteration 1400, lr = 0.0001
I0711 18:15:49.564564  7290 solver.cpp:290] Iteration 1500 (5.74824 iter/s, 17.3966s/100 iter), loss = 0.0403869
I0711 18:15:49.564662  7290 solver.cpp:309]     Train net output #0: loss = 0.040387 (* 1 = 0.040387 loss)
I0711 18:15:49.564671  7290 sgd_solver.cpp:106] Iteration 1500, lr = 0.0001
I0711 18:16:06.592124  7290 solver.cpp:290] Iteration 1600 (5.87303 iter/s, 17.027s/100 iter), loss = 0.100196
I0711 18:16:06.592154  7290 solver.cpp:309]     Train net output #0: loss = 0.100196 (* 1 = 0.100196 loss)
I0711 18:16:06.592164  7290 sgd_solver.cpp:106] Iteration 1600, lr = 0.0001
I0711 18:16:23.894589  7290 solver.cpp:290] Iteration 1700 (5.77969 iter/s, 17.302s/100 iter), loss = 0.0670149
I0711 18:16:23.894644  7290 solver.cpp:309]     Train net output #0: loss = 0.0670151 (* 1 = 0.0670151 loss)
I0711 18:16:23.894654  7290 sgd_solver.cpp:106] Iteration 1700, lr = 0.0001
I0711 18:16:41.085741  7290 solver.cpp:290] Iteration 1800 (5.81712 iter/s, 17.1906s/100 iter), loss = 0.0896805
I0711 18:16:41.085769  7290 solver.cpp:309]     Train net output #0: loss = 0.0896807 (* 1 = 0.0896807 loss)
I0711 18:16:41.085779  7290 sgd_solver.cpp:106] Iteration 1800, lr = 0.0001
I0711 18:16:58.132289  7290 solver.cpp:290] Iteration 1900 (5.86646 iter/s, 17.0461s/100 iter), loss = 0.0702805
I0711 18:16:58.132331  7290 solver.cpp:309]     Train net output #0: loss = 0.0702806 (* 1 = 0.0702806 loss)
I0711 18:16:58.132339  7290 sgd_solver.cpp:106] Iteration 1900, lr = 0.0001
I0711 18:17:14.998767  7290 solver.cpp:467] Iteration 2000, Testing net (#0)
I0711 18:18:02.568859  7290 solver.cpp:540]     Test net output #0: accuracy/top1 = 0.9376
I0711 18:18:02.568938  7290 solver.cpp:540]     Test net output #1: accuracy/top5 = 0.999886
I0711 18:18:02.568945  7290 solver.cpp:540]     Test net output #2: loss = 0.0980816 (* 1 = 0.0980816 loss)
I0711 18:18:02.766706  7290 solver.cpp:290] Iteration 2000 (1.54721 iter/s, 64.6326s/100 iter), loss = 0.0261143
I0711 18:18:02.766736  7290 solver.cpp:309]     Train net output #0: loss = 0.0261144 (* 1 = 0.0261144 loss)
I0711 18:18:02.766744  7290 sgd_solver.cpp:106] Iteration 2000, lr = 0.0001
I0711 18:18:23.314285  7386 blocking_queue.cpp:50] Waiting for data
I0711 18:18:53.397811  7290 solver.cpp:290] Iteration 2100 (1.97513 iter/s, 50.6297s/100 iter), loss = 0.0491348
I0711 18:18:53.397930  7290 solver.cpp:309]     Train net output #0: loss = 0.0491348 (* 1 = 0.0491348 loss)
I0711 18:18:53.397940  7290 sgd_solver.cpp:106] Iteration 2100, lr = 0.0001
I0711 18:20:01.529809  7483 blocking_queue.cpp:50] Waiting for data
I0711 18:20:25.158123  7290 solver.cpp:290] Iteration 2200 (1.08983 iter/s, 91.7577s/100 iter), loss = 0.0617981
I0711 18:20:25.158149  7290 solver.cpp:309]     Train net output #0: loss = 0.0617981 (* 1 = 0.0617981 loss)
I0711 18:20:25.158157  7290 sgd_solver.cpp:106] Iteration 2200, lr = 0.0001
I0711 18:20:49.393815  7290 solver.cpp:290] Iteration 2300 (4.12627 iter/s, 24.235s/100 iter), loss = 0.0827685
I0711 18:20:49.393924  7290 solver.cpp:309]     Train net output #0: loss = 0.0827686 (* 1 = 0.0827686 loss)
I0711 18:20:49.393935  7290 sgd_solver.cpp:106] Iteration 2300, lr = 0.0001
I0711 18:21:06.378211  7290 solver.cpp:290] Iteration 2400 (5.88796 iter/s, 16.9838s/100 iter), loss = 0.0362968
I0711 18:21:06.378234  7290 solver.cpp:309]     Train net output #0: loss = 0.0362968 (* 1 = 0.0362968 loss)
I0711 18:21:06.378242  7290 sgd_solver.cpp:106] Iteration 2400, lr = 0.0001
I0711 18:21:23.457068  7290 solver.cpp:290] Iteration 2500 (5.85536 iter/s, 17.0784s/100 iter), loss = 0.042775
I0711 18:21:23.457128  7290 solver.cpp:309]     Train net output #0: loss = 0.042775 (* 1 = 0.042775 loss)
I0711 18:21:23.457135  7290 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0711 18:21:40.594348  7290 solver.cpp:290] Iteration 2600 (5.83541 iter/s, 17.1367s/100 iter), loss = 0.0448009
I0711 18:21:40.594372  7290 solver.cpp:309]     Train net output #0: loss = 0.0448009 (* 1 = 0.0448009 loss)
I0711 18:21:40.594380  7290 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0711 18:21:57.593452  7290 solver.cpp:290] Iteration 2700 (5.88283 iter/s, 16.9986s/100 iter), loss = 0.0378237
I0711 18:21:57.593492  7290 solver.cpp:309]     Train net output #0: loss = 0.0378237 (* 1 = 0.0378237 loss)
I0711 18:21:57.593502  7290 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0711 18:22:14.553247  7290 solver.cpp:290] Iteration 2800 (5.89648 iter/s, 16.9593s/100 iter), loss = 0.0821368
I0711 18:22:14.553277  7290 solver.cpp:309]     Train net output #0: loss = 0.0821368 (* 1 = 0.0821368 loss)
I0711 18:22:14.553287  7290 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0711 18:22:31.437991  7290 solver.cpp:290] Iteration 2900 (5.92268 iter/s, 16.8842s/100 iter), loss = 0.054734
I0711 18:22:31.438076  7290 solver.cpp:309]     Train net output #0: loss = 0.054734 (* 1 = 0.054734 loss)
I0711 18:22:31.438086  7290 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0711 18:22:48.349581  7290 solver.cpp:290] Iteration 3000 (5.9133 iter/s, 16.911s/100 iter), loss = 0.0696464
I0711 18:22:48.349602  7290 solver.cpp:309]     Train net output #0: loss = 0.0696464 (* 1 = 0.0696464 loss)
I0711 18:22:48.349609  7290 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0711 18:23:05.442375  7290 solver.cpp:290] Iteration 3100 (5.85059 iter/s, 17.0923s/100 iter), loss = 0.0494853
I0711 18:23:05.442452  7290 solver.cpp:309]     Train net output #0: loss = 0.0494854 (* 1 = 0.0494854 loss)
I0711 18:23:05.442463  7290 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0711 18:23:22.444973  7290 solver.cpp:290] Iteration 3200 (5.88164 iter/s, 17.0021s/100 iter), loss = 0.0547966
I0711 18:23:22.444998  7290 solver.cpp:309]     Train net output #0: loss = 0.0547966 (* 1 = 0.0547966 loss)
I0711 18:23:22.445006  7290 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0711 18:23:39.496029  7290 solver.cpp:290] Iteration 3300 (5.86491 iter/s, 17.0506s/100 iter), loss = 0.0462428
I0711 18:23:39.496098  7290 solver.cpp:309]     Train net output #0: loss = 0.0462429 (* 1 = 0.0462429 loss)
I0711 18:23:39.496105  7290 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0711 18:23:56.443899  7290 solver.cpp:290] Iteration 3400 (5.90063 iter/s, 16.9473s/100 iter), loss = 0.0499624
I0711 18:23:56.443925  7290 solver.cpp:309]     Train net output #0: loss = 0.0499624 (* 1 = 0.0499624 loss)
I0711 18:23:56.443935  7290 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0711 18:24:13.482775  7290 solver.cpp:290] Iteration 3500 (5.8691 iter/s, 17.0384s/100 iter), loss = 0.0651987
I0711 18:24:13.482830  7290 solver.cpp:309]     Train net output #0: loss = 0.0651987 (* 1 = 0.0651987 loss)
I0711 18:24:13.482839  7290 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0711 18:24:30.267144  7290 solver.cpp:290] Iteration 3600 (5.95811 iter/s, 16.7839s/100 iter), loss = 0.0420858
I0711 18:24:30.267171  7290 solver.cpp:309]     Train net output #0: loss = 0.0420858 (* 1 = 0.0420858 loss)
I0711 18:24:30.267180  7290 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0711 18:24:47.357051  7290 solver.cpp:290] Iteration 3700 (5.85158 iter/s, 17.0894s/100 iter), loss = 0.0730352
I0711 18:24:47.357157  7290 solver.cpp:309]     Train net output #0: loss = 0.0730353 (* 1 = 0.0730353 loss)
I0711 18:24:47.357167  7290 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0711 18:25:04.249699  7290 solver.cpp:290] Iteration 3800 (5.91994 iter/s, 16.8921s/100 iter), loss = 0.0418119
I0711 18:25:04.249727  7290 solver.cpp:309]     Train net output #0: loss = 0.041812 (* 1 = 0.041812 loss)
I0711 18:25:04.249735  7290 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0711 18:25:21.217327  7290 solver.cpp:290] Iteration 3900 (5.89375 iter/s, 16.9671s/100 iter), loss = 0.0537464
I0711 18:25:21.217376  7290 solver.cpp:309]     Train net output #0: loss = 0.0537465 (* 1 = 0.0537465 loss)
I0711 18:25:21.217384  7290 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0711 18:25:38.108829  7290 solver.cpp:467] Iteration 4000, Testing net (#0)
I0711 18:26:25.500630  7290 solver.cpp:540]     Test net output #0: accuracy/top1 = 0.942848
I0711 18:26:25.500720  7290 solver.cpp:540]     Test net output #1: accuracy/top5 = 0.999983
I0711 18:26:25.500727  7290 solver.cpp:540]     Test net output #2: loss = 0.0978816 (* 1 = 0.0978816 loss)
I0711 18:26:25.675846  7290 solver.cpp:290] Iteration 4000 (1.55143 iter/s, 64.4567s/100 iter), loss = 0.0529157
I0711 18:26:25.675879  7290 solver.cpp:309]     Train net output #0: loss = 0.0529158 (* 1 = 0.0529158 loss)
I0711 18:26:25.675887  7290 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0711 18:26:34.755595  7386 blocking_queue.cpp:50] Waiting for data
I0711 18:27:41.172003  7290 solver.cpp:290] Iteration 4100 (1.32461 iter/s, 75.494s/100 iter), loss = 0.114303
I0711 18:27:41.172109  7290 solver.cpp:309]     Train net output #0: loss = 0.114303 (* 1 = 0.114303 loss)
I0711 18:27:41.172121  7290 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0711 18:28:02.294813  7485 blocking_queue.cpp:50] Waiting for data
I0711 18:28:34.424893  7290 blocking_queue.cpp:50] Data layer prefetch queue empty
I0711 18:29:11.113041  7290 solver.cpp:290] Iteration 4200 (1.11187 iter/s, 89.9385s/100 iter), loss = 0.0317651
I0711 18:29:11.113091  7290 solver.cpp:309]     Train net output #0: loss = 0.0317651 (* 1 = 0.0317651 loss)
I0711 18:29:11.113099  7290 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0711 18:29:29.062860  7290 solver.cpp:290] Iteration 4300 (5.57126 iter/s, 17.9493s/100 iter), loss = 0.0681308
I0711 18:29:29.062882  7290 solver.cpp:309]     Train net output #0: loss = 0.0681309 (* 1 = 0.0681309 loss)
I0711 18:29:29.062889  7290 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0711 18:29:46.217173  7290 solver.cpp:290] Iteration 4400 (5.82961 iter/s, 17.1538s/100 iter), loss = 0.0887211
I0711 18:29:46.217228  7290 solver.cpp:309]     Train net output #0: loss = 0.0887212 (* 1 = 0.0887212 loss)
I0711 18:29:46.217239  7290 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0711 18:30:03.004484  7290 solver.cpp:290] Iteration 4500 (5.95707 iter/s, 16.7868s/100 iter), loss = 0.0351928
I0711 18:30:03.004506  7290 solver.cpp:309]     Train net output #0: loss = 0.0351929 (* 1 = 0.0351929 loss)
I0711 18:30:03.004513  7290 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0711 18:30:20.159389  7290 solver.cpp:290] Iteration 4600 (5.82941 iter/s, 17.1544s/100 iter), loss = 0.0689037
I0711 18:30:20.159494  7290 solver.cpp:309]     Train net output #0: loss = 0.0689038 (* 1 = 0.0689038 loss)
I0711 18:30:20.159507  7290 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0711 18:30:37.247740  7290 solver.cpp:290] Iteration 4700 (5.85214 iter/s, 17.0878s/100 iter), loss = 0.0781765
I0711 18:30:37.247764  7290 solver.cpp:309]     Train net output #0: loss = 0.0781766 (* 1 = 0.0781766 loss)
I0711 18:30:37.247773  7290 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0711 18:30:54.261812  7290 solver.cpp:290] Iteration 4800 (5.87766 iter/s, 17.0136s/100 iter), loss = 0.140073
I0711 18:30:54.261862  7290 solver.cpp:309]     Train net output #0: loss = 0.140073 (* 1 = 0.140073 loss)
I0711 18:30:54.261870  7290 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0711 18:31:11.128482  7290 solver.cpp:290] Iteration 4900 (5.92904 iter/s, 16.8661s/100 iter), loss = 0.10359
I0711 18:31:11.128504  7290 solver.cpp:309]     Train net output #0: loss = 0.10359 (* 1 = 0.10359 loss)
I0711 18:31:11.128512  7290 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0711 18:31:28.064632  7290 solver.cpp:290] Iteration 5000 (5.9047 iter/s, 16.9357s/100 iter), loss = 0.0245194
I0711 18:31:28.064673  7290 solver.cpp:309]     Train net output #0: loss = 0.0245194 (* 1 = 0.0245194 loss)
I0711 18:31:28.064682  7290 sgd_solver.cpp:106] Iteration 5000, lr = 0.0001
I0711 18:31:44.919827  7290 solver.cpp:290] Iteration 5100 (5.93307 iter/s, 16.8547s/100 iter), loss = 0.0978219
I0711 18:31:44.919850  7290 solver.cpp:309]     Train net output #0: loss = 0.0978219 (* 1 = 0.0978219 loss)
I0711 18:31:44.919857  7290 sgd_solver.cpp:106] Iteration 5100, lr = 0.0001
I0711 18:32:02.108726  7290 solver.cpp:290] Iteration 5200 (5.81788 iter/s, 17.1884s/100 iter), loss = 0.0318916
I0711 18:32:02.108770  7290 solver.cpp:309]     Train net output #0: loss = 0.0318916 (* 1 = 0.0318916 loss)
I0711 18:32:02.108778  7290 sgd_solver.cpp:106] Iteration 5200, lr = 0.0001
I0711 18:32:19.036031  7290 solver.cpp:290] Iteration 5300 (5.90779 iter/s, 16.9268s/100 iter), loss = 0.0365637
I0711 18:32:19.036053  7290 solver.cpp:309]     Train net output #0: loss = 0.0365638 (* 1 = 0.0365638 loss)
I0711 18:32:19.036061  7290 sgd_solver.cpp:106] Iteration 5300, lr = 0.0001
I0711 18:32:36.120342  7290 solver.cpp:290] Iteration 5400 (5.85349 iter/s, 17.0838s/100 iter), loss = 0.0258145
I0711 18:32:36.120388  7290 solver.cpp:309]     Train net output #0: loss = 0.0258145 (* 1 = 0.0258145 loss)
I0711 18:32:36.120395  7290 sgd_solver.cpp:106] Iteration 5400, lr = 0.0001
I0711 18:32:53.280110  7290 solver.cpp:290] Iteration 5500 (5.82776 iter/s, 17.1593s/100 iter), loss = 0.0561454
I0711 18:32:53.280133  7290 solver.cpp:309]     Train net output #0: loss = 0.0561455 (* 1 = 0.0561455 loss)
I0711 18:32:53.280140  7290 sgd_solver.cpp:106] Iteration 5500, lr = 0.0001
I0711 18:33:10.289558  7290 solver.cpp:290] Iteration 5600 (5.87926 iter/s, 17.009s/100 iter), loss = 0.0635741
I0711 18:33:10.289675  7290 solver.cpp:309]     Train net output #0: loss = 0.0635742 (* 1 = 0.0635742 loss)
I0711 18:33:10.289690  7290 sgd_solver.cpp:106] Iteration 5600, lr = 0.0001
I0711 18:33:27.239049  7290 solver.cpp:290] Iteration 5700 (5.90008 iter/s, 16.9489s/100 iter), loss = 0.0391532
I0711 18:33:27.239073  7290 solver.cpp:309]     Train net output #0: loss = 0.0391533 (* 1 = 0.0391533 loss)
I0711 18:33:27.239079  7290 sgd_solver.cpp:106] Iteration 5700, lr = 0.0001
I0711 18:33:44.280241  7290 solver.cpp:290] Iteration 5800 (5.8683 iter/s, 17.0407s/100 iter), loss = 0.0799887
I0711 18:33:44.280292  7290 solver.cpp:309]     Train net output #0: loss = 0.0799888 (* 1 = 0.0799888 loss)
I0711 18:33:44.280299  7290 sgd_solver.cpp:106] Iteration 5800, lr = 0.0001
I0711 18:34:01.172812  7290 solver.cpp:290] Iteration 5900 (5.91994 iter/s, 16.8921s/100 iter), loss = 0.214317
I0711 18:34:01.172847  7290 solver.cpp:309]     Train net output #0: loss = 0.214317 (* 1 = 0.214317 loss)
I0711 18:34:01.172854  7290 sgd_solver.cpp:106] Iteration 5900, lr = 0.0001
I0711 18:34:17.938062  7290 solver.cpp:467] Iteration 6000, Testing net (#0)
I0711 18:35:05.549047  7290 solver.cpp:540]     Test net output #0: accuracy/top1 = 0.944847
I0711 18:35:05.549222  7290 solver.cpp:540]     Test net output #1: accuracy/top5 = 0.999993
I0711 18:35:05.549232  7290 solver.cpp:540]     Test net output #2: loss = 0.108163 (* 1 = 0.108163 loss)
I0711 18:35:05.747937  7290 solver.cpp:290] Iteration 6000 (1.54863 iter/s, 64.5733s/100 iter), loss = 0.0779569
I0711 18:35:05.747962  7290 solver.cpp:309]     Train net output #0: loss = 0.077957 (* 1 = 0.077957 loss)
I0711 18:35:05.747969  7290 sgd_solver.cpp:106] Iteration 6000, lr = 0.0001
I0711 18:35:11.915148  7386 blocking_queue.cpp:50] Waiting for data
I0711 18:36:29.768244  7290 solver.cpp:290] Iteration 6100 (1.19022 iter/s, 84.018s/100 iter), loss = 0.0386538
I0711 18:36:29.768349  7290 solver.cpp:309]     Train net output #0: loss = 0.0386538 (* 1 = 0.0386538 loss)
I0711 18:36:29.768360  7290 sgd_solver.cpp:106] Iteration 6100, lr = 0.0001
I0711 18:36:30.341492  7352 blocking_queue.cpp:50] Waiting for data
I0711 18:37:31.806093  7386 blocking_queue.cpp:50] Waiting for data
I0711 18:38:29.554322  7290 solver.cpp:290] Iteration 6200 (0.834845 iter/s, 119.783s/100 iter), loss = 0.0413135
I0711 18:38:29.554482  7290 solver.cpp:309]     Train net output #0: loss = 0.0413135 (* 1 = 0.0413135 loss)
I0711 18:38:29.554496  7290 sgd_solver.cpp:106] Iteration 6200, lr = 0.0001
I0711 18:38:55.955407  7483 blocking_queue.cpp:50] Waiting for data
I0711 18:39:11.683820  7290 solver.cpp:290] Iteration 6300 (2.37371 iter/s, 42.1282s/100 iter), loss = 0.112893
I0711 18:39:11.683868  7290 solver.cpp:309]     Train net output #0: loss = 0.112893 (* 1 = 0.112893 loss)
I0711 18:39:11.683879  7290 sgd_solver.cpp:106] Iteration 6300, lr = 0.0001
I0711 18:39:28.657593  7290 solver.cpp:290] Iteration 6400 (5.89162 iter/s, 16.9733s/100 iter), loss = 0.0554843
I0711 18:39:28.657615  7290 solver.cpp:309]     Train net output #0: loss = 0.0554843 (* 1 = 0.0554843 loss)
I0711 18:39:28.657624  7290 sgd_solver.cpp:106] Iteration 6400, lr = 0.0001
I0711 18:39:45.569495  7290 solver.cpp:290] Iteration 6500 (5.91317 iter/s, 16.9114s/100 iter), loss = 0.0666582
I0711 18:39:45.569581  7290 solver.cpp:309]     Train net output #0: loss = 0.0666583 (* 1 = 0.0666583 loss)
I0711 18:39:45.569589  7290 sgd_solver.cpp:106] Iteration 6500, lr = 0.0001
I0711 18:40:02.475806  7290 solver.cpp:290] Iteration 6600 (5.91514 iter/s, 16.9058s/100 iter), loss = 0.0294992
I0711 18:40:02.475831  7290 solver.cpp:309]     Train net output #0: loss = 0.0294992 (* 1 = 0.0294992 loss)
I0711 18:40:02.475837  7290 sgd_solver.cpp:106] Iteration 6600, lr = 0.0001
I0711 18:40:19.459666  7290 solver.cpp:290] Iteration 6700 (5.88812 iter/s, 16.9834s/100 iter), loss = 0.0326719
I0711 18:40:19.459756  7290 solver.cpp:309]     Train net output #0: loss = 0.0326719 (* 1 = 0.0326719 loss)
I0711 18:40:19.459767  7290 sgd_solver.cpp:106] Iteration 6700, lr = 0.0001
I0711 18:40:36.476174  7290 solver.cpp:290] Iteration 6800 (5.87684 iter/s, 17.0159s/100 iter), loss = 0.0317981
I0711 18:40:36.476202  7290 solver.cpp:309]     Train net output #0: loss = 0.0317981 (* 1 = 0.0317981 loss)
I0711 18:40:36.476209  7290 sgd_solver.cpp:106] Iteration 6800, lr = 0.0001
I0711 18:40:53.448981  7290 solver.cpp:290] Iteration 6900 (5.89195 iter/s, 16.9723s/100 iter), loss = 0.0472939
I0711 18:40:53.449028  7290 solver.cpp:309]     Train net output #0: loss = 0.047294 (* 1 = 0.047294 loss)
I0711 18:40:53.449036  7290 sgd_solver.cpp:106] Iteration 6900, lr = 0.0001
I0711 18:41:10.555889  7290 solver.cpp:290] Iteration 7000 (5.84577 iter/s, 17.1064s/100 iter), loss = 0.0335818
I0711 18:41:10.555912  7290 solver.cpp:309]     Train net output #0: loss = 0.0335818 (* 1 = 0.0335818 loss)
I0711 18:41:10.555919  7290 sgd_solver.cpp:106] Iteration 7000, lr = 0.0001
I0711 18:41:27.511945  7290 solver.cpp:290] Iteration 7100 (5.89777 iter/s, 16.9556s/100 iter), loss = 0.053921
I0711 18:41:27.512018  7290 solver.cpp:309]     Train net output #0: loss = 0.053921 (* 1 = 0.053921 loss)
I0711 18:41:27.512027  7290 sgd_solver.cpp:106] Iteration 7100, lr = 0.0001
I0711 18:41:44.455235  7290 solver.cpp:290] Iteration 7200 (5.90223 iter/s, 16.9427s/100 iter), loss = 0.0283452
I0711 18:41:44.455257  7290 solver.cpp:309]     Train net output #0: loss = 0.0283453 (* 1 = 0.0283453 loss)
I0711 18:41:44.455265  7290 sgd_solver.cpp:106] Iteration 7200, lr = 0.0001
I0711 18:42:01.452533  7290 solver.cpp:290] Iteration 7300 (5.88346 iter/s, 16.9968s/100 iter), loss = 0.0512436
I0711 18:42:01.452589  7290 solver.cpp:309]     Train net output #0: loss = 0.0512437 (* 1 = 0.0512437 loss)
I0711 18:42:01.452596  7290 sgd_solver.cpp:106] Iteration 7300, lr = 0.0001
I0711 18:42:18.427023  7290 solver.cpp:290] Iteration 7400 (5.89138 iter/s, 16.974s/100 iter), loss = 0.0561066
I0711 18:42:18.427048  7290 solver.cpp:309]     Train net output #0: loss = 0.0561067 (* 1 = 0.0561067 loss)
I0711 18:42:18.427055  7290 sgd_solver.cpp:106] Iteration 7400, lr = 0.0001
I0711 18:42:35.504536  7290 solver.cpp:290] Iteration 7500 (5.85582 iter/s, 17.077s/100 iter), loss = 0.0699209
I0711 18:42:35.504622  7290 solver.cpp:309]     Train net output #0: loss = 0.069921 (* 1 = 0.069921 loss)
I0711 18:42:35.504633  7290 sgd_solver.cpp:106] Iteration 7500, lr = 0.0001
I0711 18:42:52.580734  7290 solver.cpp:290] Iteration 7600 (5.8563 iter/s, 17.0756s/100 iter), loss = 0.0475304
I0711 18:42:52.580759  7290 solver.cpp:309]     Train net output #0: loss = 0.0475305 (* 1 = 0.0475305 loss)
I0711 18:42:52.580765  7290 sgd_solver.cpp:106] Iteration 7600, lr = 0.0001
I0711 18:43:09.450033  7290 solver.cpp:290] Iteration 7700 (5.9281 iter/s, 16.8688s/100 iter), loss = 0.0303552
I0711 18:43:09.450131  7290 solver.cpp:309]     Train net output #0: loss = 0.0303552 (* 1 = 0.0303552 loss)
I0711 18:43:09.450142  7290 sgd_solver.cpp:106] Iteration 7700, lr = 0.0001
I0711 18:43:26.474130  7290 solver.cpp:290] Iteration 7800 (5.87422 iter/s, 17.0235s/100 iter), loss = 0.0236738
I0711 18:43:26.474155  7290 solver.cpp:309]     Train net output #0: loss = 0.0236738 (* 1 = 0.0236738 loss)
I0711 18:43:26.474164  7290 sgd_solver.cpp:106] Iteration 7800, lr = 0.0001
I0711 18:43:43.414438  7290 solver.cpp:290] Iteration 7900 (5.90325 iter/s, 16.9398s/100 iter), loss = 0.0648853
I0711 18:43:43.414491  7290 solver.cpp:309]     Train net output #0: loss = 0.0648853 (* 1 = 0.0648853 loss)
I0711 18:43:43.414502  7290 sgd_solver.cpp:106] Iteration 7900, lr = 0.0001
I0711 18:44:00.305789  7290 solver.cpp:467] Iteration 8000, Testing net (#0)
I0711 18:44:47.584740  7290 solver.cpp:540]     Test net output #0: accuracy/top1 = 0.943554
I0711 18:44:47.584822  7290 solver.cpp:540]     Test net output #1: accuracy/top5 = 0.999988
I0711 18:44:47.584831  7290 solver.cpp:540]     Test net output #2: loss = 0.125779 (* 1 = 0.125779 loss)
I0711 18:44:47.772753  7290 solver.cpp:290] Iteration 8000 (1.55384 iter/s, 64.3565s/100 iter), loss = 0.0304079
I0711 18:44:47.772775  7290 solver.cpp:309]     Train net output #0: loss = 0.0304079 (* 1 = 0.0304079 loss)
I0711 18:44:47.772783  7290 sgd_solver.cpp:106] Iteration 8000, lr = 0.0001
I0711 18:45:04.611014  7290 solver.cpp:290] Iteration 8100 (5.93904 iter/s, 16.8377s/100 iter), loss = 0.0566438
I0711 18:45:04.611040  7290 solver.cpp:309]     Train net output #0: loss = 0.0566437 (* 1 = 0.0566437 loss)
I0711 18:45:04.611050  7290 sgd_solver.cpp:106] Iteration 8100, lr = 0.0001
I0711 18:46:11.175535  7386 blocking_queue.cpp:50] Waiting for data
I0711 18:46:58.808794  7290 solver.cpp:290] Iteration 8200 (0.875698 iter/s, 114.195s/100 iter), loss = 0.0456689
I0711 18:46:58.808909  7290 solver.cpp:309]     Train net output #0: loss = 0.0456688 (* 1 = 0.0456688 loss)
I0711 18:46:58.808919  7290 sgd_solver.cpp:106] Iteration 8200, lr = 0.0001
I0711 18:47:18.937459  7500 blocking_queue.cpp:50] Data layer prefetch queue empty
I0711 18:47:22.143247  7483 blocking_queue.cpp:50] Waiting for data
I0711 18:47:32.561826  7290 solver.cpp:290] Iteration 8300 (2.96279 iter/s, 33.752s/100 iter), loss = 0.044689
I0711 18:47:32.561909  7290 solver.cpp:309]     Train net output #0: loss = 0.044689 (* 1 = 0.044689 loss)
I0711 18:47:32.561918  7290 sgd_solver.cpp:106] Iteration 8300, lr = 0.0001
I0711 18:48:02.594121  7290 solver.cpp:290] Iteration 8400 (3.32985 iter/s, 30.0314s/100 iter), loss = 0.0327974
I0711 18:48:02.594204  7290 solver.cpp:309]     Train net output #0: loss = 0.0327974 (* 1 = 0.0327974 loss)
I0711 18:48:02.594216  7290 sgd_solver.cpp:106] Iteration 8400, lr = 0.0001
I0711 18:48:19.599619  7290 solver.cpp:290] Iteration 8500 (5.88065 iter/s, 17.0049s/100 iter), loss = 0.0686541
I0711 18:48:19.599645  7290 solver.cpp:309]     Train net output #0: loss = 0.0686541 (* 1 = 0.0686541 loss)
I0711 18:48:19.599654  7290 sgd_solver.cpp:106] Iteration 8500, lr = 0.0001
I0711 18:48:36.708510  7290 solver.cpp:290] Iteration 8600 (5.84509 iter/s, 17.1084s/100 iter), loss = 0.0541645
I0711 18:48:36.708590  7290 solver.cpp:309]     Train net output #0: loss = 0.0541645 (* 1 = 0.0541645 loss)
I0711 18:48:36.708598  7290 sgd_solver.cpp:106] Iteration 8600, lr = 0.0001
I0711 18:48:53.695282  7290 solver.cpp:290] Iteration 8700 (5.88713 iter/s, 16.9862s/100 iter), loss = 0.0362202
I0711 18:48:53.695307  7290 solver.cpp:309]     Train net output #0: loss = 0.0362202 (* 1 = 0.0362202 loss)
I0711 18:48:53.695314  7290 sgd_solver.cpp:106] Iteration 8700, lr = 0.0001
I0711 18:49:10.646250  7290 solver.cpp:290] Iteration 8800 (5.89954 iter/s, 16.9505s/100 iter), loss = 0.0544917
I0711 18:49:10.646297  7290 solver.cpp:309]     Train net output #0: loss = 0.0544917 (* 1 = 0.0544917 loss)
I0711 18:49:10.646304  7290 sgd_solver.cpp:106] Iteration 8800, lr = 0.0001
I0711 18:49:27.501307  7290 solver.cpp:290] Iteration 8900 (5.93312 iter/s, 16.8545s/100 iter), loss = 0.0355642
I0711 18:49:27.501332  7290 solver.cpp:309]     Train net output #0: loss = 0.0355642 (* 1 = 0.0355642 loss)
I0711 18:49:27.501340  7290 sgd_solver.cpp:106] Iteration 8900, lr = 0.0001
I0711 18:49:44.494953  7290 solver.cpp:290] Iteration 9000 (5.88473 iter/s, 16.9931s/100 iter), loss = 0.044753
I0711 18:49:44.495002  7290 solver.cpp:309]     Train net output #0: loss = 0.0447529 (* 1 = 0.0447529 loss)
I0711 18:49:44.495008  7290 sgd_solver.cpp:106] Iteration 9000, lr = 0.0001
I0711 18:50:01.441182  7290 solver.cpp:290] Iteration 9100 (5.9012 iter/s, 16.9457s/100 iter), loss = 0.0780392
I0711 18:50:01.441210  7290 solver.cpp:309]     Train net output #0: loss = 0.0780391 (* 1 = 0.0780391 loss)
I0711 18:50:01.441223  7290 sgd_solver.cpp:106] Iteration 9100, lr = 0.0001
I0711 18:50:18.506731  7290 solver.cpp:290] Iteration 9200 (5.85993 iter/s, 17.065s/100 iter), loss = 0.0463734
I0711 18:50:18.506784  7290 solver.cpp:309]     Train net output #0: loss = 0.0463733 (* 1 = 0.0463733 loss)
I0711 18:50:18.506794  7290 sgd_solver.cpp:106] Iteration 9200, lr = 0.0001
I0711 18:50:35.500071  7290 solver.cpp:290] Iteration 9300 (5.88484 iter/s, 16.9928s/100 iter), loss = 0.0507376
I0711 18:50:35.500094  7290 solver.cpp:309]     Train net output #0: loss = 0.0507376 (* 1 = 0.0507376 loss)
I0711 18:50:35.500102  7290 sgd_solver.cpp:106] Iteration 9300, lr = 0.0001
I0711 18:50:52.413705  7290 solver.cpp:290] Iteration 9400 (5.91256 iter/s, 16.9131s/100 iter), loss = 0.0234703
I0711 18:50:52.413748  7290 solver.cpp:309]     Train net output #0: loss = 0.0234702 (* 1 = 0.0234702 loss)
I0711 18:50:52.413755  7290 sgd_solver.cpp:106] Iteration 9400, lr = 0.0001
I0711 18:51:09.377997  7290 solver.cpp:290] Iteration 9500 (5.89491 iter/s, 16.9638s/100 iter), loss = 0.0452537
I0711 18:51:09.378020  7290 solver.cpp:309]     Train net output #0: loss = 0.0452536 (* 1 = 0.0452536 loss)
I0711 18:51:09.378027  7290 sgd_solver.cpp:106] Iteration 9500, lr = 0.0001
I0711 18:51:26.420608  7290 solver.cpp:290] Iteration 9600 (5.86782 iter/s, 17.0421s/100 iter), loss = 0.0357792
I0711 18:51:26.420702  7290 solver.cpp:309]     Train net output #0: loss = 0.0357791 (* 1 = 0.0357791 loss)
I0711 18:51:26.420711  7290 sgd_solver.cpp:106] Iteration 9600, lr = 0.0001
I0711 18:51:43.368444  7290 solver.cpp:290] Iteration 9700 (5.90066 iter/s, 16.9473s/100 iter), loss = 0.0367929
I0711 18:51:43.368468  7290 solver.cpp:309]     Train net output #0: loss = 0.0367928 (* 1 = 0.0367928 loss)
I0711 18:51:43.368476  7290 sgd_solver.cpp:106] Iteration 9700, lr = 0.0001
I0711 18:52:00.429651  7290 solver.cpp:290] Iteration 9800 (5.86142 iter/s, 17.0607s/100 iter), loss = 0.0436817
I0711 18:52:00.429759  7290 solver.cpp:309]     Train net output #0: loss = 0.0436816 (* 1 = 0.0436816 loss)
I0711 18:52:00.429774  7290 sgd_solver.cpp:106] Iteration 9800, lr = 0.0001
I0711 18:52:17.483789  7290 solver.cpp:290] Iteration 9900 (5.86388 iter/s, 17.0536s/100 iter), loss = 0.0265108
I0711 18:52:17.483814  7290 solver.cpp:309]     Train net output #0: loss = 0.0265107 (* 1 = 0.0265107 loss)
I0711 18:52:17.483820  7290 sgd_solver.cpp:106] Iteration 9900, lr = 0.0001
I0711 18:52:34.475661  7290 solver.cpp:594] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-07-11_18-09-28/initial/cityscapes5_jsegnet21v2_iter_10000.caffemodel
I0711 18:52:34.588274  7290 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-07-11_18-09-28/initial/cityscapes5_jsegnet21v2_iter_10000.solverstate
I0711 18:52:34.605295  7290 solver.cpp:467] Iteration 10000, Testing net (#0)
I0711 18:53:22.090937  7290 solver.cpp:540]     Test net output #0: accuracy/top1 = 0.942409
I0711 18:53:22.091028  7290 solver.cpp:540]     Test net output #1: accuracy/top5 = 0.999882
I0711 18:53:22.091251  7290 solver.cpp:540]     Test net output #2: loss = 0.130371 (* 1 = 0.130371 loss)
I0711 18:53:22.290850  7290 solver.cpp:290] Iteration 10000 (1.54309 iter/s, 64.8052s/100 iter), loss = 0.0235543
I0711 18:53:22.290873  7290 solver.cpp:309]     Train net output #0: loss = 0.0235542 (* 1 = 0.0235542 loss)
I0711 18:53:22.290879  7290 sgd_solver.cpp:106] Iteration 10000, lr = 0.0001
I0711 18:53:27.004294  7352 blocking_queue.cpp:50] Waiting for data
I0711 18:53:59.253542  7290 solver.cpp:290] Iteration 10100 (2.70551 iter/s, 36.9616s/100 iter), loss = 0.0429007
I0711 18:53:59.253594  7290 solver.cpp:309]     Train net output #0: loss = 0.0429006 (* 1 = 0.0429006 loss)
I0711 18:53:59.253602  7290 sgd_solver.cpp:106] Iteration 10100, lr = 0.0001
I0711 18:55:05.272697  7290 solver.cpp:290] Iteration 10200 (1.51476 iter/s, 66.0173s/100 iter), loss = 0.0252992
I0711 18:55:05.272781  7290 solver.cpp:309]     Train net output #0: loss = 0.0252991 (* 1 = 0.0252991 loss)
I0711 18:55:05.272792  7290 sgd_solver.cpp:106] Iteration 10200, lr = 0.0001
I0711 18:55:24.860239  7352 blocking_queue.cpp:50] Waiting for data
I0711 18:55:43.813117  7290 solver.cpp:290] Iteration 10300 (2.59476 iter/s, 38.5393s/100 iter), loss = 0.0324675
I0711 18:55:43.813179  7290 solver.cpp:309]     Train net output #0: loss = 0.0324674 (* 1 = 0.0324674 loss)
I0711 18:55:43.813189  7290 sgd_solver.cpp:106] Iteration 10300, lr = 0.0001
I0711 18:56:00.670248  7290 solver.cpp:290] Iteration 10400 (5.9324 iter/s, 16.8566s/100 iter), loss = 0.0603028
I0711 18:56:00.670271  7290 solver.cpp:309]     Train net output #0: loss = 0.0603027 (* 1 = 0.0603027 loss)
I0711 18:56:00.670279  7290 sgd_solver.cpp:106] Iteration 10400, lr = 0.0001
I0711 18:56:17.605761  7290 solver.cpp:290] Iteration 10500 (5.90493 iter/s, 16.935s/100 iter), loss = 0.0141168
I0711 18:56:17.605855  7290 solver.cpp:309]     Train net output #0: loss = 0.0141167 (* 1 = 0.0141167 loss)
I0711 18:56:17.605866  7290 sgd_solver.cpp:106] Iteration 10500, lr = 0.0001
I0711 18:56:34.632040  7290 solver.cpp:290] Iteration 10600 (5.87347 iter/s, 17.0257s/100 iter), loss = 0.0363722
I0711 18:56:34.632063  7290 solver.cpp:309]     Train net output #0: loss = 0.0363721 (* 1 = 0.0363721 loss)
I0711 18:56:34.632069  7290 sgd_solver.cpp:106] Iteration 10600, lr = 0.0001
I0711 18:56:51.594962  7290 solver.cpp:290] Iteration 10700 (5.89539 iter/s, 16.9624s/100 iter), loss = 0.0425913
I0711 18:56:51.595026  7290 solver.cpp:309]     Train net output #0: loss = 0.0425912 (* 1 = 0.0425912 loss)
I0711 18:56:51.595034  7290 sgd_solver.cpp:106] Iteration 10700, lr = 0.0001
I0711 18:57:08.538167  7290 solver.cpp:290] Iteration 10800 (5.90226 iter/s, 16.9427s/100 iter), loss = 0.0332228
I0711 18:57:08.538189  7290 solver.cpp:309]     Train net output #0: loss = 0.0332227 (* 1 = 0.0332227 loss)
I0711 18:57:08.538198  7290 sgd_solver.cpp:106] Iteration 10800, lr = 0.0001
I0711 18:57:25.583931  7290 solver.cpp:290] Iteration 10900 (5.86673 iter/s, 17.0453s/100 iter), loss = 0.0313951
I0711 18:57:25.584004  7290 solver.cpp:309]     Train net output #0: loss = 0.031395 (* 1 = 0.031395 loss)
I0711 18:57:25.584012  7290 sgd_solver.cpp:106] Iteration 10900, lr = 0.0001
I0711 18:57:42.390424  7290 solver.cpp:290] Iteration 11000 (5.95028 iter/s, 16.8059s/100 iter), loss = 0.0361319
I0711 18:57:42.390450  7290 solver.cpp:309]     Train net output #0: loss = 0.0361318 (* 1 = 0.0361318 loss)
I0711 18:57:42.390460  7290 sgd_solver.cpp:106] Iteration 11000, lr = 0.0001
I0711 18:57:59.271373  7290 solver.cpp:290] Iteration 11100 (5.92401 iter/s, 16.8804s/100 iter), loss = 0.0214206
I0711 18:57:59.271455  7290 solver.cpp:309]     Train net output #0: loss = 0.0214205 (* 1 = 0.0214205 loss)
I0711 18:57:59.271466  7290 sgd_solver.cpp:106] Iteration 11100, lr = 0.0001
I0711 18:58:16.262204  7290 solver.cpp:290] Iteration 11200 (5.88572 iter/s, 16.9903s/100 iter), loss = 0.0429011
I0711 18:58:16.262228  7290 solver.cpp:309]     Train net output #0: loss = 0.042901 (* 1 = 0.042901 loss)
I0711 18:58:16.262235  7290 sgd_solver.cpp:106] Iteration 11200, lr = 0.0001
I0711 18:58:33.408268  7290 solver.cpp:290] Iteration 11300 (5.83241 iter/s, 17.1456s/100 iter), loss = 0.0315334
I0711 18:58:33.408321  7290 solver.cpp:309]     Train net output #0: loss = 0.0315333 (* 1 = 0.0315333 loss)
I0711 18:58:33.408332  7290 sgd_solver.cpp:106] Iteration 11300, lr = 0.0001
I0711 18:58:50.253156  7290 solver.cpp:290] Iteration 11400 (5.9367 iter/s, 16.8444s/100 iter), loss = 0.0293833
I0711 18:58:50.253183  7290 solver.cpp:309]     Train net output #0: loss = 0.0293832 (* 1 = 0.0293832 loss)
I0711 18:58:50.253192  7290 sgd_solver.cpp:106] Iteration 11400, lr = 0.0001
I0711 18:59:07.335412  7290 solver.cpp:290] Iteration 11500 (5.8542 iter/s, 17.0818s/100 iter), loss = 0.0335265
I0711 18:59:07.335463  7290 solver.cpp:309]     Train net output #0: loss = 0.0335264 (* 1 = 0.0335264 loss)
I0711 18:59:07.335471  7290 sgd_solver.cpp:106] Iteration 11500, lr = 0.0001
I0711 18:59:24.418406  7290 solver.cpp:290] Iteration 11600 (5.85396 iter/s, 17.0825s/100 iter), loss = 0.0417331
I0711 18:59:24.418434  7290 solver.cpp:309]     Train net output #0: loss = 0.041733 (* 1 = 0.041733 loss)
I0711 18:59:24.418444  7290 sgd_solver.cpp:106] Iteration 11600, lr = 0.0001
I0711 18:59:41.589856  7290 solver.cpp:290] Iteration 11700 (5.82379 iter/s, 17.1709s/100 iter), loss = 0.0253136
I0711 18:59:41.589929  7290 solver.cpp:309]     Train net output #0: loss = 0.0253135 (* 1 = 0.0253135 loss)
I0711 18:59:41.589938  7290 sgd_solver.cpp:106] Iteration 11700, lr = 0.0001
I0711 18:59:58.756314  7290 solver.cpp:290] Iteration 11800 (5.8255 iter/s, 17.1659s/100 iter), loss = 0.0228712
I0711 18:59:58.756337  7290 solver.cpp:309]     Train net output #0: loss = 0.0228711 (* 1 = 0.0228711 loss)
I0711 18:59:58.756345  7290 sgd_solver.cpp:106] Iteration 11800, lr = 0.0001
I0711 19:00:15.961663  7290 solver.cpp:290] Iteration 11900 (5.81232 iter/s, 17.2048s/100 iter), loss = 0.0338853
I0711 19:00:15.961751  7290 solver.cpp:309]     Train net output #0: loss = 0.0338852 (* 1 = 0.0338852 loss)
I0711 19:00:15.961760  7290 sgd_solver.cpp:106] Iteration 11900, lr = 0.0001
I0711 19:00:32.983909  7290 solver.cpp:467] Iteration 12000, Testing net (#0)
I0711 19:01:20.673041  7290 solver.cpp:540]     Test net output #0: accuracy/top1 = 0.950261
I0711 19:01:20.673152  7290 solver.cpp:540]     Test net output #1: accuracy/top5 = 0.999462
I0711 19:01:20.673161  7290 solver.cpp:540]     Test net output #2: loss = 0.1332 (* 1 = 0.1332 loss)
I0711 19:01:20.851073  7290 solver.cpp:290] Iteration 12000 (1.54113 iter/s, 64.8875s/100 iter), loss = 0.0305318
I0711 19:01:20.851097  7290 solver.cpp:309]     Train net output #0: loss = 0.0305317 (* 1 = 0.0305317 loss)
I0711 19:01:20.851104  7290 sgd_solver.cpp:106] Iteration 12000, lr = 0.0001
I0711 19:01:48.844015  7290 solver.cpp:290] Iteration 12100 (3.57243 iter/s, 27.9921s/100 iter), loss = 0.0338263
I0711 19:01:48.844039  7290 solver.cpp:309]     Train net output #0: loss = 0.0338262 (* 1 = 0.0338262 loss)
I0711 19:01:48.844046  7290 sgd_solver.cpp:106] Iteration 12100, lr = 0.0001
I0711 19:02:14.409940  7352 blocking_queue.cpp:50] Waiting for data
I0711 19:02:39.786128  7290 solver.cpp:290] Iteration 12200 (1.96307 iter/s, 50.9407s/100 iter), loss = 0.0226129
I0711 19:02:39.786159  7290 solver.cpp:309]     Train net output #0: loss = 0.0226128 (* 1 = 0.0226128 loss)
I0711 19:02:39.786166  7290 sgd_solver.cpp:106] Iteration 12200, lr = 0.0001
I0711 19:02:58.149039  7386 blocking_queue.cpp:50] Waiting for data
I0711 19:03:05.875540  7290 solver.cpp:290] Iteration 12300 (3.83308 iter/s, 26.0886s/100 iter), loss = 0.0626612
I0711 19:03:05.875562  7290 solver.cpp:309]     Train net output #0: loss = 0.0626611 (* 1 = 0.0626611 loss)
I0711 19:03:05.875569  7290 sgd_solver.cpp:106] Iteration 12300, lr = 0.0001
I0711 19:03:22.723865  7290 solver.cpp:290] Iteration 12400 (5.93548 iter/s, 16.8478s/100 iter), loss = 0.043537
I0711 19:03:22.723888  7290 solver.cpp:309]     Train net output #0: loss = 0.0435369 (* 1 = 0.0435369 loss)
I0711 19:03:22.723894  7290 sgd_solver.cpp:106] Iteration 12400, lr = 0.0001
I0711 19:03:39.719332  7290 solver.cpp:290] Iteration 12500 (5.8841 iter/s, 16.995s/100 iter), loss = 0.025833
I0711 19:03:39.719405  7290 solver.cpp:309]     Train net output #0: loss = 0.0258329 (* 1 = 0.0258329 loss)
I0711 19:03:39.719413  7290 sgd_solver.cpp:106] Iteration 12500, lr = 0.0001
I0711 19:03:56.822793  7290 solver.cpp:290] Iteration 12600 (5.84696 iter/s, 17.1029s/100 iter), loss = 0.0276784
I0711 19:03:56.822815  7290 solver.cpp:309]     Train net output #0: loss = 0.0276783 (* 1 = 0.0276783 loss)
I0711 19:03:56.822823  7290 sgd_solver.cpp:106] Iteration 12600, lr = 0.0001
I0711 19:04:13.992703  7290 solver.cpp:290] Iteration 12700 (5.82431 iter/s, 17.1694s/100 iter), loss = 0.0371779
I0711 19:04:13.992754  7290 solver.cpp:309]     Train net output #0: loss = 0.0371778 (* 1 = 0.0371778 loss)
I0711 19:04:13.992763  7290 sgd_solver.cpp:106] Iteration 12700, lr = 0.0001
I0711 19:04:31.153731  7290 solver.cpp:290] Iteration 12800 (5.82734 iter/s, 17.1605s/100 iter), loss = 0.0233727
I0711 19:04:31.153755  7290 solver.cpp:309]     Train net output #0: loss = 0.0233726 (* 1 = 0.0233726 loss)
I0711 19:04:31.153761  7290 sgd_solver.cpp:106] Iteration 12800, lr = 0.0001
I0711 19:04:48.066968  7290 solver.cpp:290] Iteration 12900 (5.9127 iter/s, 16.9127s/100 iter), loss = 0.0360042
I0711 19:04:48.067052  7290 solver.cpp:309]     Train net output #0: loss = 0.0360041 (* 1 = 0.0360041 loss)
I0711 19:04:48.067062  7290 sgd_solver.cpp:106] Iteration 12900, lr = 0.0001
I0711 19:05:05.114923  7290 solver.cpp:290] Iteration 13000 (5.866 iter/s, 17.0474s/100 iter), loss = 0.0422174
I0711 19:05:05.114946  7290 solver.cpp:309]     Train net output #0: loss = 0.0422173 (* 1 = 0.0422173 loss)
I0711 19:05:05.114953  7290 sgd_solver.cpp:106] Iteration 13000, lr = 0.0001
I0711 19:05:22.182996  7290 solver.cpp:290] Iteration 13100 (5.85907 iter/s, 17.0676s/100 iter), loss = 0.0287268
I0711 19:05:22.183049  7290 solver.cpp:309]     Train net output #0: loss = 0.0287267 (* 1 = 0.0287267 loss)
I0711 19:05:22.183063  7290 sgd_solver.cpp:106] Iteration 13100, lr = 0.0001
I0711 19:05:39.401485  7290 solver.cpp:290] Iteration 13200 (5.80789 iter/s, 17.218s/100 iter), loss = 0.0301324
I0711 19:05:39.401512  7290 solver.cpp:309]     Train net output #0: loss = 0.0301323 (* 1 = 0.0301323 loss)
I0711 19:05:39.401520  7290 sgd_solver.cpp:106] Iteration 13200, lr = 0.0001
I0711 19:05:56.508700  7290 solver.cpp:290] Iteration 13300 (5.84566 iter/s, 17.1067s/100 iter), loss = 0.0452536
I0711 19:05:56.508796  7290 solver.cpp:309]     Train net output #0: loss = 0.0452535 (* 1 = 0.0452535 loss)
I0711 19:05:56.508805  7290 sgd_solver.cpp:106] Iteration 13300, lr = 0.0001
I0711 19:06:13.485415  7290 solver.cpp:290] Iteration 13400 (5.89062 iter/s, 16.9761s/100 iter), loss = 0.035885
I0711 19:06:13.485440  7290 solver.cpp:309]     Train net output #0: loss = 0.0358849 (* 1 = 0.0358849 loss)
I0711 19:06:13.485445  7290 sgd_solver.cpp:106] Iteration 13400, lr = 0.0001
I0711 19:06:30.596299  7290 solver.cpp:290] Iteration 13500 (5.84441 iter/s, 17.1104s/100 iter), loss = 0.0337028
I0711 19:06:30.596379  7290 solver.cpp:309]     Train net output #0: loss = 0.0337027 (* 1 = 0.0337027 loss)
I0711 19:06:30.596390  7290 sgd_solver.cpp:106] Iteration 13500, lr = 0.0001
I0711 19:06:47.456398  7290 solver.cpp:290] Iteration 13600 (5.93136 iter/s, 16.8595s/100 iter), loss = 0.0252978
I0711 19:06:47.456421  7290 solver.cpp:309]     Train net output #0: loss = 0.0252977 (* 1 = 0.0252977 loss)
I0711 19:06:47.456435  7290 sgd_solver.cpp:106] Iteration 13600, lr = 0.0001
I0711 19:07:04.400682  7290 solver.cpp:290] Iteration 13700 (5.90187 iter/s, 16.9438s/100 iter), loss = 0.0398415
I0711 19:07:04.400775  7290 solver.cpp:309]     Train net output #0: loss = 0.0398414 (* 1 = 0.0398414 loss)
I0711 19:07:04.400784  7290 sgd_solver.cpp:106] Iteration 13700, lr = 0.0001
I0711 19:07:21.365521  7290 solver.cpp:290] Iteration 13800 (5.89474 iter/s, 16.9643s/100 iter), loss = 0.0289731
I0711 19:07:21.365548  7290 solver.cpp:309]     Train net output #0: loss = 0.028973 (* 1 = 0.028973 loss)
I0711 19:07:21.365557  7290 sgd_solver.cpp:106] Iteration 13800, lr = 0.0001
I0711 19:07:38.513283  7290 solver.cpp:290] Iteration 13900 (5.83184 iter/s, 17.1472s/100 iter), loss = 0.0289237
I0711 19:07:38.513380  7290 solver.cpp:309]     Train net output #0: loss = 0.0289236 (* 1 = 0.0289236 loss)
I0711 19:07:38.513391  7290 sgd_solver.cpp:106] Iteration 13900, lr = 0.0001
I0711 19:07:55.247089  7290 solver.cpp:467] Iteration 14000, Testing net (#0)
I0711 19:08:42.540029  7290 solver.cpp:540]     Test net output #0: accuracy/top1 = 0.951701
I0711 19:08:42.540122  7290 solver.cpp:540]     Test net output #1: accuracy/top5 = 0.999927
I0711 19:08:42.540128  7290 solver.cpp:540]     Test net output #2: loss = 0.110516 (* 1 = 0.110516 loss)
I0711 19:08:42.734617  7290 solver.cpp:290] Iteration 14000 (1.55716 iter/s, 64.2194s/100 iter), loss = 0.030904
I0711 19:08:42.734647  7290 solver.cpp:309]     Train net output #0: loss = 0.0309039 (* 1 = 0.0309039 loss)
I0711 19:08:42.734655  7290 sgd_solver.cpp:106] Iteration 14000, lr = 0.0001
I0711 19:09:06.193305  7290 solver.cpp:290] Iteration 14100 (4.26294 iter/s, 23.458s/100 iter), loss = 0.0250245
I0711 19:09:06.193330  7290 solver.cpp:309]     Train net output #0: loss = 0.0250244 (* 1 = 0.0250244 loss)
I0711 19:09:06.193336  7290 sgd_solver.cpp:106] Iteration 14100, lr = 0.0001
I0711 19:09:27.841598  7290 solver.cpp:290] Iteration 14200 (4.61944 iter/s, 21.6477s/100 iter), loss = 0.0280597
I0711 19:09:27.841645  7290 solver.cpp:309]     Train net output #0: loss = 0.0280596 (* 1 = 0.0280596 loss)
I0711 19:09:27.841652  7290 sgd_solver.cpp:106] Iteration 14200, lr = 0.0001
I0711 19:09:44.851824  7290 solver.cpp:290] Iteration 14300 (5.879 iter/s, 17.0097s/100 iter), loss = 0.0383565
I0711 19:09:44.851846  7290 solver.cpp:309]     Train net output #0: loss = 0.0383564 (* 1 = 0.0383564 loss)
I0711 19:09:44.851853  7290 sgd_solver.cpp:106] Iteration 14300, lr = 0.0001
I0711 19:10:01.820013  7290 solver.cpp:290] Iteration 14400 (5.89356 iter/s, 16.9677s/100 iter), loss = 0.0206324
I0711 19:10:01.820086  7290 solver.cpp:309]     Train net output #0: loss = 0.0206323 (* 1 = 0.0206323 loss)
I0711 19:10:01.820094  7290 sgd_solver.cpp:106] Iteration 14400, lr = 0.0001
I0711 19:10:18.828466  7290 solver.cpp:290] Iteration 14500 (5.87962 iter/s, 17.0079s/100 iter), loss = 0.0442858
I0711 19:10:18.828490  7290 solver.cpp:309]     Train net output #0: loss = 0.0442858 (* 1 = 0.0442858 loss)
I0711 19:10:18.828496  7290 sgd_solver.cpp:106] Iteration 14500, lr = 0.0001
I0711 19:10:35.779430  7290 solver.cpp:290] Iteration 14600 (5.89955 iter/s, 16.9505s/100 iter), loss = 0.0305562
I0711 19:10:35.779537  7290 solver.cpp:309]     Train net output #0: loss = 0.0305561 (* 1 = 0.0305561 loss)
I0711 19:10:35.779548  7290 sgd_solver.cpp:106] Iteration 14600, lr = 0.0001
I0711 19:10:52.750440  7290 solver.cpp:290] Iteration 14700 (5.8926 iter/s, 16.9704s/100 iter), loss = 0.0911707
I0711 19:10:52.750468  7290 solver.cpp:309]     Train net output #0: loss = 0.0911706 (* 1 = 0.0911706 loss)
I0711 19:10:52.750476  7290 sgd_solver.cpp:106] Iteration 14700, lr = 0.0001
I0711 19:11:09.754436  7290 solver.cpp:290] Iteration 14800 (5.88115 iter/s, 17.0035s/100 iter), loss = 0.0420324
I0711 19:11:09.754518  7290 solver.cpp:309]     Train net output #0: loss = 0.0420323 (* 1 = 0.0420323 loss)
I0711 19:11:09.754528  7290 sgd_solver.cpp:106] Iteration 14800, lr = 0.0001
I0711 19:11:26.805960  7290 solver.cpp:290] Iteration 14900 (5.86477 iter/s, 17.051s/100 iter), loss = 0.0508641
I0711 19:11:26.805984  7290 solver.cpp:309]     Train net output #0: loss = 0.050864 (* 1 = 0.050864 loss)
I0711 19:11:26.805991  7290 sgd_solver.cpp:106] Iteration 14900, lr = 0.0001
I0711 19:11:43.800273  7290 solver.cpp:290] Iteration 15000 (5.8845 iter/s, 16.9938s/100 iter), loss = 0.0404286
I0711 19:11:43.800351  7290 solver.cpp:309]     Train net output #0: loss = 0.0404285 (* 1 = 0.0404285 loss)
I0711 19:11:43.800359  7290 sgd_solver.cpp:106] Iteration 15000, lr = 0.0001
I0711 19:12:00.844322  7290 solver.cpp:290] Iteration 15100 (5.86734 iter/s, 17.0435s/100 iter), loss = 0.0198565
I0711 19:12:00.844348  7290 solver.cpp:309]     Train net output #0: loss = 0.0198564 (* 1 = 0.0198564 loss)
I0711 19:12:00.844355  7290 sgd_solver.cpp:106] Iteration 15100, lr = 0.0001
I0711 19:12:17.885655  7290 solver.cpp:290] Iteration 15200 (5.86826 iter/s, 17.0408s/100 iter), loss = 0.0236007
I0711 19:12:17.885728  7290 solver.cpp:309]     Train net output #0: loss = 0.0236006 (* 1 = 0.0236006 loss)
I0711 19:12:17.885735  7290 sgd_solver.cpp:106] Iteration 15200, lr = 0.0001
I0711 19:12:34.967686  7290 solver.cpp:290] Iteration 15300 (5.85429 iter/s, 17.0815s/100 iter), loss = 0.0426724
I0711 19:12:34.967711  7290 solver.cpp:309]     Train net output #0: loss = 0.0426723 (* 1 = 0.0426723 loss)
I0711 19:12:34.967717  7290 sgd_solver.cpp:106] Iteration 15300, lr = 0.0001
I0711 19:12:51.919492  7290 solver.cpp:290] Iteration 15400 (5.89925 iter/s, 16.9513s/100 iter), loss = 0.0388065
I0711 19:12:51.919539  7290 solver.cpp:309]     Train net output #0: loss = 0.0388064 (* 1 = 0.0388064 loss)
I0711 19:12:51.919548  7290 sgd_solver.cpp:106] Iteration 15400, lr = 0.0001
I0711 19:13:08.772083  7290 solver.cpp:290] Iteration 15500 (5.93399 iter/s, 16.8521s/100 iter), loss = 0.0311759
I0711 19:13:08.772104  7290 solver.cpp:309]     Train net output #0: loss = 0.0311758 (* 1 = 0.0311758 loss)
I0711 19:13:08.772111  7290 sgd_solver.cpp:106] Iteration 15500, lr = 0.0001
I0711 19:13:25.811730  7290 solver.cpp:290] Iteration 15600 (5.86884 iter/s, 17.0391s/100 iter), loss = 0.0308214
I0711 19:13:25.811843  7290 solver.cpp:309]     Train net output #0: loss = 0.0308213 (* 1 = 0.0308213 loss)
I0711 19:13:25.811853  7290 sgd_solver.cpp:106] Iteration 15600, lr = 0.0001
I0711 19:13:42.790235  7290 solver.cpp:290] Iteration 15700 (5.89 iter/s, 16.9779s/100 iter), loss = 0.0315022
I0711 19:13:42.790261  7290 solver.cpp:309]     Train net output #0: loss = 0.0315021 (* 1 = 0.0315021 loss)
I0711 19:13:42.790267  7290 sgd_solver.cpp:106] Iteration 15700, lr = 0.0001
I0711 19:13:59.628919  7290 solver.cpp:290] Iteration 15800 (5.93888 iter/s, 16.8382s/100 iter), loss = 0.0517453
I0711 19:13:59.628990  7290 solver.cpp:309]     Train net output #0: loss = 0.0517452 (* 1 = 0.0517452 loss)
I0711 19:13:59.628998  7290 sgd_solver.cpp:106] Iteration 15800, lr = 0.0001
I0711 19:14:16.452039  7290 solver.cpp:290] Iteration 15900 (5.94439 iter/s, 16.8226s/100 iter), loss = 0.0326285
I0711 19:14:16.452061  7290 solver.cpp:309]     Train net output #0: loss = 0.0326284 (* 1 = 0.0326284 loss)
I0711 19:14:16.452069  7290 sgd_solver.cpp:106] Iteration 15900, lr = 0.0001
I0711 19:14:33.211323  7290 solver.cpp:467] Iteration 16000, Testing net (#0)
I0711 19:15:20.313905  7290 solver.cpp:540]     Test net output #0: accuracy/top1 = 0.949388
I0711 19:15:20.313982  7290 solver.cpp:540]     Test net output #1: accuracy/top5 = 0.999545
I0711 19:15:20.313989  7290 solver.cpp:540]     Test net output #2: loss = 0.13676 (* 1 = 0.13676 loss)
I0711 19:15:20.501101  7290 solver.cpp:290] Iteration 16000 (1.56135 iter/s, 64.0473s/100 iter), loss = 0.0377887
I0711 19:15:20.501129  7290 solver.cpp:309]     Train net output #0: loss = 0.0377886 (* 1 = 0.0377886 loss)
I0711 19:15:20.501138  7290 sgd_solver.cpp:106] Iteration 16000, lr = 0.0001
I0711 19:15:37.522467  7290 solver.cpp:290] Iteration 16100 (5.87514 iter/s, 17.0209s/100 iter), loss = 0.0250812
I0711 19:15:37.522491  7290 solver.cpp:309]     Train net output #0: loss = 0.0250811 (* 1 = 0.0250811 loss)
I0711 19:15:37.522498  7290 sgd_solver.cpp:106] Iteration 16100, lr = 0.0001
I0711 19:16:02.536870  7290 solver.cpp:290] Iteration 16200 (3.99781 iter/s, 25.0137s/100 iter), loss = 0.0516085
I0711 19:16:02.536976  7290 solver.cpp:309]     Train net output #0: loss = 0.0516084 (* 1 = 0.0516084 loss)
I0711 19:16:02.536986  7290 sgd_solver.cpp:106] Iteration 16200, lr = 0.0001
I0711 19:16:21.384667  7290 solver.cpp:290] Iteration 16300 (5.30584 iter/s, 18.8472s/100 iter), loss = 0.0515404
I0711 19:16:21.384688  7290 solver.cpp:309]     Train net output #0: loss = 0.0515403 (* 1 = 0.0515403 loss)
I0711 19:16:21.384696  7290 sgd_solver.cpp:106] Iteration 16300, lr = 0.0001
I0711 19:16:38.688524  7290 solver.cpp:290] Iteration 16400 (5.77923 iter/s, 17.3033s/100 iter), loss = 0.0296192
I0711 19:16:38.688565  7290 solver.cpp:309]     Train net output #0: loss = 0.0296191 (* 1 = 0.0296191 loss)
I0711 19:16:38.688573  7290 sgd_solver.cpp:106] Iteration 16400, lr = 0.0001
I0711 19:16:55.850051  7290 solver.cpp:290] Iteration 16500 (5.82717 iter/s, 17.161s/100 iter), loss = 0.020527
I0711 19:16:55.850081  7290 solver.cpp:309]     Train net output #0: loss = 0.0205269 (* 1 = 0.0205269 loss)
I0711 19:16:55.850090  7290 sgd_solver.cpp:106] Iteration 16500, lr = 0.0001
I0711 19:17:12.997292  7290 solver.cpp:290] Iteration 16600 (5.83202 iter/s, 17.1467s/100 iter), loss = 0.0348751
I0711 19:17:12.997336  7290 solver.cpp:309]     Train net output #0: loss = 0.034875 (* 1 = 0.034875 loss)
I0711 19:17:12.997344  7290 sgd_solver.cpp:106] Iteration 16600, lr = 0.0001
I0711 19:17:30.327029  7290 solver.cpp:290] Iteration 16700 (5.7706 iter/s, 17.3292s/100 iter), loss = 0.0870045
I0711 19:17:30.327054  7290 solver.cpp:309]     Train net output #0: loss = 0.0870044 (* 1 = 0.0870044 loss)
I0711 19:17:30.327061  7290 sgd_solver.cpp:106] Iteration 16700, lr = 0.0001
I0711 19:17:47.779891  7290 solver.cpp:290] Iteration 16800 (5.72989 iter/s, 17.4523s/100 iter), loss = 0.0556285
I0711 19:17:47.779971  7290 solver.cpp:309]     Train net output #0: loss = 0.0556284 (* 1 = 0.0556284 loss)
I0711 19:17:47.779983  7290 sgd_solver.cpp:106] Iteration 16800, lr = 0.0001
I0711 19:18:05.085136  7290 solver.cpp:290] Iteration 16900 (5.77878 iter/s, 17.3047s/100 iter), loss = 0.0249942
I0711 19:18:05.085163  7290 solver.cpp:309]     Train net output #0: loss = 0.0249941 (* 1 = 0.0249941 loss)
I0711 19:18:05.085173  7290 sgd_solver.cpp:106] Iteration 16900, lr = 0.0001
I0711 19:18:22.229784  7290 solver.cpp:290] Iteration 17000 (5.8329 iter/s, 17.1441s/100 iter), loss = 0.0162487
I0711 19:18:22.242244  7290 solver.cpp:309]     Train net output #0: loss = 0.0162485 (* 1 = 0.0162485 loss)
I0711 19:18:22.242283  7290 sgd_solver.cpp:106] Iteration 17000, lr = 0.0001
I0711 19:18:39.726971  7290 solver.cpp:290] Iteration 17100 (5.71943 iter/s, 17.4843s/100 iter), loss = 0.0227745
I0711 19:18:39.727002  7290 solver.cpp:309]     Train net output #0: loss = 0.0227743 (* 1 = 0.0227743 loss)
I0711 19:18:39.727011  7290 sgd_solver.cpp:106] Iteration 17100, lr = 0.0001
I0711 19:18:57.253412  7290 solver.cpp:290] Iteration 17200 (5.70583 iter/s, 17.5259s/100 iter), loss = 0.0266461
I0711 19:18:57.253479  7290 solver.cpp:309]     Train net output #0: loss = 0.026646 (* 1 = 0.026646 loss)
I0711 19:18:57.253487  7290 sgd_solver.cpp:106] Iteration 17200, lr = 0.0001
I0711 19:19:14.610429  7290 solver.cpp:290] Iteration 17300 (5.76154 iter/s, 17.3565s/100 iter), loss = 0.0239469
I0711 19:19:14.610453  7290 solver.cpp:309]     Train net output #0: loss = 0.0239468 (* 1 = 0.0239468 loss)
I0711 19:19:14.610460  7290 sgd_solver.cpp:106] Iteration 17300, lr = 0.0001
I0711 19:19:31.998571  7290 solver.cpp:290] Iteration 17400 (5.75122 iter/s, 17.3876s/100 iter), loss = 0.0250904
I0711 19:19:31.998661  7290 solver.cpp:309]     Train net output #0: loss = 0.0250903 (* 1 = 0.0250903 loss)
I0711 19:19:31.998680  7290 sgd_solver.cpp:106] Iteration 17400, lr = 0.0001
I0711 19:19:49.397598  7290 solver.cpp:290] Iteration 17500 (5.74764 iter/s, 17.3985s/100 iter), loss = 0.118535
I0711 19:19:49.397621  7290 solver.cpp:309]     Train net output #0: loss = 0.118535 (* 1 = 0.118535 loss)
I0711 19:19:49.397629  7290 sgd_solver.cpp:106] Iteration 17500, lr = 0.0001
I0711 19:20:06.372879  7290 solver.cpp:290] Iteration 17600 (5.89109 iter/s, 16.9748s/100 iter), loss = 0.0171973
I0711 19:20:06.372927  7290 solver.cpp:309]     Train net output #0: loss = 0.0171972 (* 1 = 0.0171972 loss)
I0711 19:20:06.372934  7290 sgd_solver.cpp:106] Iteration 17600, lr = 0.0001
I0711 19:20:23.480384  7290 solver.cpp:290] Iteration 17700 (5.84557 iter/s, 17.107s/100 iter), loss = 0.0311948
I0711 19:20:23.480409  7290 solver.cpp:309]     Train net output #0: loss = 0.0311947 (* 1 = 0.0311947 loss)
I0711 19:20:23.480417  7290 sgd_solver.cpp:106] Iteration 17700, lr = 0.0001
I0711 19:20:40.422580  7290 solver.cpp:290] Iteration 17800 (5.9026 iter/s, 16.9417s/100 iter), loss = 0.109196
I0711 19:20:40.422680  7290 solver.cpp:309]     Train net output #0: loss = 0.109196 (* 1 = 0.109196 loss)
I0711 19:20:40.422691  7290 sgd_solver.cpp:106] Iteration 17800, lr = 0.0001
I0711 19:20:57.339088  7290 solver.cpp:290] Iteration 17900 (5.91158 iter/s, 16.9159s/100 iter), loss = 0.114935
I0711 19:20:57.339112  7290 solver.cpp:309]     Train net output #0: loss = 0.114935 (* 1 = 0.114935 loss)
I0711 19:20:57.339118  7290 sgd_solver.cpp:106] Iteration 17900, lr = 0.0001
I0711 19:21:14.168315  7290 solver.cpp:467] Iteration 18000, Testing net (#0)
I0711 19:22:01.098083  7290 solver.cpp:540]     Test net output #0: accuracy/top1 = 0.951948
I0711 19:22:01.098155  7290 solver.cpp:540]     Test net output #1: accuracy/top5 = 0.999994
I0711 19:22:01.098160  7290 solver.cpp:540]     Test net output #2: loss = 0.111072 (* 1 = 0.111072 loss)
I0711 19:22:01.298126  7290 solver.cpp:290] Iteration 18000 (1.56354 iter/s, 63.9572s/100 iter), loss = 0.0251778
I0711 19:22:01.298149  7290 solver.cpp:309]     Train net output #0: loss = 0.0251777 (* 1 = 0.0251777 loss)
I0711 19:22:01.298156  7290 sgd_solver.cpp:106] Iteration 18000, lr = 0.0001
I0711 19:22:18.206068  7290 solver.cpp:290] Iteration 18100 (5.91456 iter/s, 16.9074s/100 iter), loss = 0.0361842
I0711 19:22:18.206100  7290 solver.cpp:309]     Train net output #0: loss = 0.0361841 (* 1 = 0.0361841 loss)
I0711 19:22:18.206111  7290 sgd_solver.cpp:106] Iteration 18100, lr = 0.0001
I0711 19:22:35.224308  7290 solver.cpp:290] Iteration 18200 (5.87623 iter/s, 17.0177s/100 iter), loss = 0.0305811
I0711 19:22:35.224380  7290 solver.cpp:309]     Train net output #0: loss = 0.0305811 (* 1 = 0.0305811 loss)
I0711 19:22:35.224388  7290 sgd_solver.cpp:106] Iteration 18200, lr = 0.0001
I0711 19:22:52.202952  7290 solver.cpp:290] Iteration 18300 (5.88994 iter/s, 16.9781s/100 iter), loss = 0.0312113
I0711 19:22:52.202976  7290 solver.cpp:309]     Train net output #0: loss = 0.0312112 (* 1 = 0.0312112 loss)
I0711 19:22:52.202983  7290 sgd_solver.cpp:106] Iteration 18300, lr = 0.0001
I0711 19:23:09.178663  7290 solver.cpp:290] Iteration 18400 (5.89094 iter/s, 16.9752s/100 iter), loss = 0.0362004
I0711 19:23:09.178773  7290 solver.cpp:309]     Train net output #0: loss = 0.0362003 (* 1 = 0.0362003 loss)
I0711 19:23:09.178786  7290 sgd_solver.cpp:106] Iteration 18400, lr = 0.0001
I0711 19:23:26.077397  7290 solver.cpp:290] Iteration 18500 (5.91781 iter/s, 16.8982s/100 iter), loss = 0.0612979
I0711 19:23:26.077419  7290 solver.cpp:309]     Train net output #0: loss = 0.0612979 (* 1 = 0.0612979 loss)
I0711 19:23:26.077426  7290 sgd_solver.cpp:106] Iteration 18500, lr = 0.0001
I0711 19:23:43.056598  7290 solver.cpp:290] Iteration 18600 (5.88973 iter/s, 16.9787s/100 iter), loss = 0.0182906
I0711 19:23:43.056648  7290 solver.cpp:309]     Train net output #0: loss = 0.0182905 (* 1 = 0.0182905 loss)
I0711 19:23:43.056655  7290 sgd_solver.cpp:106] Iteration 18600, lr = 0.0001
I0711 19:24:00.093200  7290 solver.cpp:290] Iteration 18700 (5.8699 iter/s, 17.0361s/100 iter), loss = 0.0482359
I0711 19:24:00.093225  7290 solver.cpp:309]     Train net output #0: loss = 0.0482358 (* 1 = 0.0482358 loss)
I0711 19:24:00.093235  7290 sgd_solver.cpp:106] Iteration 18700, lr = 0.0001
I0711 19:24:17.083343  7290 solver.cpp:290] Iteration 18800 (5.88594 iter/s, 16.9896s/100 iter), loss = 0.020993
I0711 19:24:17.083410  7290 solver.cpp:309]     Train net output #0: loss = 0.0209929 (* 1 = 0.0209929 loss)
I0711 19:24:17.083420  7290 sgd_solver.cpp:106] Iteration 18800, lr = 0.0001
I0711 19:24:34.226048  7290 solver.cpp:290] Iteration 18900 (5.83357 iter/s, 17.1422s/100 iter), loss = 0.028795
I0711 19:24:34.226073  7290 solver.cpp:309]     Train net output #0: loss = 0.0287949 (* 1 = 0.0287949 loss)
I0711 19:24:34.226079  7290 sgd_solver.cpp:106] Iteration 18900, lr = 0.0001
I0711 19:24:51.320755  7290 solver.cpp:290] Iteration 19000 (5.84994 iter/s, 17.0942s/100 iter), loss = 0.0338881
I0711 19:24:51.320838  7290 solver.cpp:309]     Train net output #0: loss = 0.033888 (* 1 = 0.033888 loss)
I0711 19:24:51.320847  7290 sgd_solver.cpp:106] Iteration 19000, lr = 0.0001
I0711 19:25:08.314604  7290 solver.cpp:290] Iteration 19100 (5.88468 iter/s, 16.9933s/100 iter), loss = 0.0310824
I0711 19:25:08.314627  7290 solver.cpp:309]     Train net output #0: loss = 0.0310823 (* 1 = 0.0310823 loss)
I0711 19:25:08.314635  7290 sgd_solver.cpp:106] Iteration 19100, lr = 0.0001
I0711 19:25:25.256896  7290 solver.cpp:290] Iteration 19200 (5.90256 iter/s, 16.9418s/100 iter), loss = 0.0210726
I0711 19:25:25.256948  7290 solver.cpp:309]     Train net output #0: loss = 0.0210725 (* 1 = 0.0210725 loss)
I0711 19:25:25.256956  7290 sgd_solver.cpp:106] Iteration 19200, lr = 0.0001
I0711 19:25:42.256666  7290 solver.cpp:290] Iteration 19300 (5.88261 iter/s, 16.9992s/100 iter), loss = 0.0643411
I0711 19:25:42.256690  7290 solver.cpp:309]     Train net output #0: loss = 0.064341 (* 1 = 0.064341 loss)
I0711 19:25:42.256696  7290 sgd_solver.cpp:106] Iteration 19300, lr = 0.0001
I0711 19:25:59.182636  7290 solver.cpp:290] Iteration 19400 (5.90826 iter/s, 16.9255s/100 iter), loss = 0.0264929
I0711 19:25:59.182683  7290 solver.cpp:309]     Train net output #0: loss = 0.0264928 (* 1 = 0.0264928 loss)
I0711 19:25:59.182692  7290 sgd_solver.cpp:106] Iteration 19400, lr = 0.0001
I0711 19:26:16.226498  7290 solver.cpp:290] Iteration 19500 (5.86739 iter/s, 17.0433s/100 iter), loss = 0.0307169
I0711 19:26:16.226522  7290 solver.cpp:309]     Train net output #0: loss = 0.0307168 (* 1 = 0.0307168 loss)
I0711 19:26:16.226529  7290 sgd_solver.cpp:106] Iteration 19500, lr = 0.0001
I0711 19:26:33.146615  7290 solver.cpp:290] Iteration 19600 (5.9103 iter/s, 16.9196s/100 iter), loss = 0.0170138
I0711 19:26:33.146657  7290 solver.cpp:309]     Train net output #0: loss = 0.0170137 (* 1 = 0.0170137 loss)
I0711 19:26:33.146666  7290 sgd_solver.cpp:106] Iteration 19600, lr = 0.0001
I0711 19:26:50.268736  7290 solver.cpp:290] Iteration 19700 (5.84057 iter/s, 17.1216s/100 iter), loss = 0.0205243
I0711 19:26:50.268760  7290 solver.cpp:309]     Train net output #0: loss = 0.0205242 (* 1 = 0.0205242 loss)
I0711 19:26:50.268767  7290 sgd_solver.cpp:106] Iteration 19700, lr = 0.0001
I0711 19:27:07.209236  7290 solver.cpp:290] Iteration 19800 (5.90319 iter/s, 16.94s/100 iter), loss = 0.0225709
I0711 19:27:07.209295  7290 solver.cpp:309]     Train net output #0: loss = 0.0225708 (* 1 = 0.0225708 loss)
I0711 19:27:07.209303  7290 sgd_solver.cpp:106] Iteration 19800, lr = 0.0001
I0711 19:27:24.384630  7290 solver.cpp:290] Iteration 19900 (5.82246 iter/s, 17.1749s/100 iter), loss = 0.0584642
I0711 19:27:24.384656  7290 solver.cpp:309]     Train net output #0: loss = 0.058464 (* 1 = 0.058464 loss)
I0711 19:27:24.384665  7290 sgd_solver.cpp:106] Iteration 19900, lr = 0.0001
I0711 19:27:41.572367  7290 solver.cpp:594] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-07-11_18-09-28/initial/cityscapes5_jsegnet21v2_iter_20000.caffemodel
I0711 19:27:41.701989  7290 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-07-11_18-09-28/initial/cityscapes5_jsegnet21v2_iter_20000.solverstate
I0711 19:27:41.724115  7290 solver.cpp:467] Iteration 20000, Testing net (#0)
I0711 19:28:31.487493  7290 solver.cpp:540]     Test net output #0: accuracy/top1 = 0.949127
I0711 19:28:31.487530  7290 solver.cpp:540]     Test net output #1: accuracy/top5 = 0.999912
I0711 19:28:31.487536  7290 solver.cpp:540]     Test net output #2: loss = 0.121776 (* 1 = 0.121776 loss)
I0711 19:28:31.680284  7290 solver.cpp:290] Iteration 20000 (1.48602 iter/s, 67.2938s/100 iter), loss = 0.0231253
I0711 19:28:31.680317  7290 solver.cpp:309]     Train net output #0: loss = 0.0231251 (* 1 = 0.0231251 loss)
I0711 19:28:31.680328  7290 sgd_solver.cpp:106] Iteration 20000, lr = 0.0001
I0711 19:28:49.030557  7290 solver.cpp:290] Iteration 20100 (5.76377 iter/s, 17.3498s/100 iter), loss = 0.0380613
I0711 19:28:49.030581  7290 solver.cpp:309]     Train net output #0: loss = 0.0380611 (* 1 = 0.0380611 loss)
I0711 19:28:49.030588  7290 sgd_solver.cpp:106] Iteration 20100, lr = 0.0001
I0711 19:29:06.458914  7290 solver.cpp:290] Iteration 20200 (5.73795 iter/s, 17.4278s/100 iter), loss = 0.0207219
I0711 19:29:06.459056  7290 solver.cpp:309]     Train net output #0: loss = 0.0207217 (* 1 = 0.0207217 loss)
I0711 19:29:06.459111  7290 sgd_solver.cpp:106] Iteration 20200, lr = 0.0001
I0711 19:29:24.028281  7290 solver.cpp:290] Iteration 20300 (5.69193 iter/s, 17.5687s/100 iter), loss = 0.0203983
I0711 19:29:24.028306  7290 solver.cpp:309]     Train net output #0: loss = 0.0203981 (* 1 = 0.0203981 loss)
I0711 19:29:24.028314  7290 sgd_solver.cpp:106] Iteration 20300, lr = 0.0001
I0711 19:29:41.779180  7290 solver.cpp:290] Iteration 20400 (5.63368 iter/s, 17.7504s/100 iter), loss = 0.0602204
I0711 19:29:41.779253  7290 solver.cpp:309]     Train net output #0: loss = 0.0602202 (* 1 = 0.0602202 loss)
I0711 19:29:41.779260  7290 sgd_solver.cpp:106] Iteration 20400, lr = 0.0001
I0711 19:29:59.057377  7290 solver.cpp:290] Iteration 20500 (5.78783 iter/s, 17.2776s/100 iter), loss = 0.039767
I0711 19:29:59.057421  7290 solver.cpp:309]     Train net output #0: loss = 0.0397668 (* 1 = 0.0397668 loss)
I0711 19:29:59.057435  7290 sgd_solver.cpp:106] Iteration 20500, lr = 0.0001
I0711 19:30:16.339249  7290 solver.cpp:290] Iteration 20600 (5.78659 iter/s, 17.2813s/100 iter), loss = 0.0270132
I0711 19:30:16.339504  7290 solver.cpp:309]     Train net output #0: loss = 0.027013 (* 1 = 0.027013 loss)
I0711 19:30:16.339592  7290 sgd_solver.cpp:106] Iteration 20600, lr = 0.0001
I0711 19:30:33.825769  7290 solver.cpp:290] Iteration 20700 (5.71893 iter/s, 17.4858s/100 iter), loss = 0.0428762
I0711 19:30:33.825795  7290 solver.cpp:309]     Train net output #0: loss = 0.042876 (* 1 = 0.042876 loss)
I0711 19:30:33.825804  7290 sgd_solver.cpp:106] Iteration 20700, lr = 0.0001
I0711 19:30:51.238736  7290 solver.cpp:290] Iteration 20800 (5.74302 iter/s, 17.4125s/100 iter), loss = 0.0271103
I0711 19:30:51.238833  7290 solver.cpp:309]     Train net output #0: loss = 0.0271101 (* 1 = 0.0271101 loss)
I0711 19:30:51.238842  7290 sgd_solver.cpp:106] Iteration 20800, lr = 0.0001
I0711 19:31:08.478463  7290 solver.cpp:290] Iteration 20900 (5.80075 iter/s, 17.2391s/100 iter), loss = 0.0215658
I0711 19:31:08.478489  7290 solver.cpp:309]     Train net output #0: loss = 0.0215656 (* 1 = 0.0215656 loss)
I0711 19:31:08.478495  7290 sgd_solver.cpp:106] Iteration 20900, lr = 0.0001
I0711 19:31:25.727005  7290 solver.cpp:290] Iteration 21000 (5.79776 iter/s, 17.248s/100 iter), loss = 0.0434636
I0711 19:31:25.727082  7290 solver.cpp:309]     Train net output #0: loss = 0.0434634 (* 1 = 0.0434634 loss)
I0711 19:31:25.727092  7290 sgd_solver.cpp:106] Iteration 21000, lr = 0.0001
I0711 19:31:43.073173  7290 solver.cpp:290] Iteration 21100 (5.76515 iter/s, 17.3456s/100 iter), loss = 0.0290455
I0711 19:31:43.073197  7290 solver.cpp:309]     Train net output #0: loss = 0.0290453 (* 1 = 0.0290453 loss)
I0711 19:31:43.073206  7290 sgd_solver.cpp:106] Iteration 21100, lr = 0.0001
I0711 19:32:00.467160  7290 solver.cpp:290] Iteration 21200 (5.74928 iter/s, 17.3935s/100 iter), loss = 0.0519431
I0711 19:32:00.467222  7290 solver.cpp:309]     Train net output #0: loss = 0.051943 (* 1 = 0.051943 loss)
I0711 19:32:00.467233  7290 sgd_solver.cpp:106] Iteration 21200, lr = 0.0001
I0711 19:32:18.022115  7290 solver.cpp:290] Iteration 21300 (5.69657 iter/s, 17.5544s/100 iter), loss = 0.0219607
I0711 19:32:18.022141  7290 solver.cpp:309]     Train net output #0: loss = 0.0219605 (* 1 = 0.0219605 loss)
I0711 19:32:18.022151  7290 sgd_solver.cpp:106] Iteration 21300, lr = 0.0001
I0711 19:32:35.372797  7290 solver.cpp:290] Iteration 21400 (5.76363 iter/s, 17.3502s/100 iter), loss = 0.0295505
I0711 19:32:35.372886  7290 solver.cpp:309]     Train net output #0: loss = 0.0295503 (* 1 = 0.0295503 loss)
I0711 19:32:35.372898  7290 sgd_solver.cpp:106] Iteration 21400, lr = 0.0001
I0711 19:32:52.856266  7290 solver.cpp:290] Iteration 21500 (5.71988 iter/s, 17.4829s/100 iter), loss = 0.0381487
I0711 19:32:52.856293  7290 solver.cpp:309]     Train net output #0: loss = 0.0381486 (* 1 = 0.0381486 loss)
I0711 19:32:52.856300  7290 sgd_solver.cpp:106] Iteration 21500, lr = 0.0001
I0711 19:33:10.520392  7290 solver.cpp:290] Iteration 21600 (5.66136 iter/s, 17.6636s/100 iter), loss = 0.0367602
I0711 19:33:10.520498  7290 solver.cpp:309]     Train net output #0: loss = 0.0367601 (* 1 = 0.0367601 loss)
I0711 19:33:10.520510  7290 sgd_solver.cpp:106] Iteration 21600, lr = 0.0001
I0711 19:33:27.939492  7290 solver.cpp:290] Iteration 21700 (5.74102 iter/s, 17.4185s/100 iter), loss = 0.0346573
I0711 19:33:27.939520  7290 solver.cpp:309]     Train net output #0: loss = 0.0346572 (* 1 = 0.0346572 loss)
I0711 19:33:27.939529  7290 sgd_solver.cpp:106] Iteration 21700, lr = 0.0001
I0711 19:33:45.166438  7290 solver.cpp:290] Iteration 21800 (5.80503 iter/s, 17.2264s/100 iter), loss = 0.0177993
I0711 19:33:45.166486  7290 solver.cpp:309]     Train net output #0: loss = 0.0177992 (* 1 = 0.0177992 loss)
I0711 19:33:45.166496  7290 sgd_solver.cpp:106] Iteration 21800, lr = 0.0001
I0711 19:34:02.270303  7290 solver.cpp:290] Iteration 21900 (5.84681 iter/s, 17.1033s/100 iter), loss = 0.018152
I0711 19:34:02.270325  7290 solver.cpp:309]     Train net output #0: loss = 0.0181519 (* 1 = 0.0181519 loss)
I0711 19:34:02.270332  7290 sgd_solver.cpp:106] Iteration 21900, lr = 0.0001
I0711 19:34:19.073936  7290 solver.cpp:467] Iteration 22000, Testing net (#0)
I0711 19:35:06.012209  7290 solver.cpp:540]     Test net output #0: accuracy/top1 = 0.94955
I0711 19:35:06.012300  7290 solver.cpp:540]     Test net output #1: accuracy/top5 = 0.999716
I0711 19:35:06.012307  7290 solver.cpp:540]     Test net output #2: loss = 0.127833 (* 1 = 0.127833 loss)
I0711 19:35:06.201530  7290 solver.cpp:290] Iteration 22000 (1.56422 iter/s, 63.9294s/100 iter), loss = 0.0499741
I0711 19:35:06.201555  7290 solver.cpp:309]     Train net output #0: loss = 0.0499739 (* 1 = 0.0499739 loss)
I0711 19:35:06.201562  7290 sgd_solver.cpp:106] Iteration 22000, lr = 0.0001
I0711 19:35:23.312695  7290 solver.cpp:290] Iteration 22100 (5.84431 iter/s, 17.1107s/100 iter), loss = 0.0225639
I0711 19:35:23.312721  7290 solver.cpp:309]     Train net output #0: loss = 0.0225637 (* 1 = 0.0225637 loss)
I0711 19:35:23.312731  7290 sgd_solver.cpp:106] Iteration 22100, lr = 0.0001
I0711 19:35:40.268235  7290 solver.cpp:290] Iteration 22200 (5.89795 iter/s, 16.955s/100 iter), loss = 0.0239346
I0711 19:35:40.268309  7290 solver.cpp:309]     Train net output #0: loss = 0.0239344 (* 1 = 0.0239344 loss)
I0711 19:35:40.268317  7290 sgd_solver.cpp:106] Iteration 22200, lr = 0.0001
I0711 19:35:57.170966  7290 solver.cpp:290] Iteration 22300 (5.9164 iter/s, 16.9022s/100 iter), loss = 0.0333297
I0711 19:35:57.170994  7290 solver.cpp:309]     Train net output #0: loss = 0.0333296 (* 1 = 0.0333296 loss)
I0711 19:35:57.171002  7290 sgd_solver.cpp:106] Iteration 22300, lr = 0.0001
I0711 19:36:14.226254  7290 solver.cpp:290] Iteration 22400 (5.86346 iter/s, 17.0548s/100 iter), loss = 0.024157
I0711 19:36:14.226310  7290 solver.cpp:309]     Train net output #0: loss = 0.0241568 (* 1 = 0.0241568 loss)
I0711 19:36:14.226317  7290 sgd_solver.cpp:106] Iteration 22400, lr = 0.0001
I0711 19:36:31.664942  7290 solver.cpp:290] Iteration 22500 (5.73455 iter/s, 17.4381s/100 iter), loss = 0.0324011
I0711 19:36:31.664964  7290 solver.cpp:309]     Train net output #0: loss = 0.032401 (* 1 = 0.032401 loss)
I0711 19:36:31.664971  7290 sgd_solver.cpp:106] Iteration 22500, lr = 0.0001
I0711 19:36:48.875891  7290 solver.cpp:290] Iteration 22600 (5.81043 iter/s, 17.2104s/100 iter), loss = 0.0364833
I0711 19:36:48.875975  7290 solver.cpp:309]     Train net output #0: loss = 0.0364831 (* 1 = 0.0364831 loss)
I0711 19:36:48.875986  7290 sgd_solver.cpp:106] Iteration 22600, lr = 0.0001
I0711 19:37:06.199823  7290 solver.cpp:290] Iteration 22700 (5.77255 iter/s, 17.3234s/100 iter), loss = 0.0228351
I0711 19:37:06.199851  7290 solver.cpp:309]     Train net output #0: loss = 0.022835 (* 1 = 0.022835 loss)
I0711 19:37:06.199859  7290 sgd_solver.cpp:106] Iteration 22700, lr = 0.0001
I0711 19:37:23.373271  7290 solver.cpp:290] Iteration 22800 (5.82312 iter/s, 17.1729s/100 iter), loss = 0.0260692
I0711 19:37:23.373373  7290 solver.cpp:309]     Train net output #0: loss = 0.026069 (* 1 = 0.026069 loss)
I0711 19:37:23.373399  7290 sgd_solver.cpp:106] Iteration 22800, lr = 0.0001
I0711 19:37:40.744695  7290 solver.cpp:290] Iteration 22900 (5.75677 iter/s, 17.3708s/100 iter), loss = 0.0187004
I0711 19:37:40.744719  7290 solver.cpp:309]     Train net output #0: loss = 0.0187002 (* 1 = 0.0187002 loss)
I0711 19:37:40.744725  7290 sgd_solver.cpp:106] Iteration 22900, lr = 0.0001
I0711 19:37:57.884246  7290 solver.cpp:290] Iteration 23000 (5.83463 iter/s, 17.139s/100 iter), loss = 0.0313216
I0711 19:37:57.884523  7290 solver.cpp:309]     Train net output #0: loss = 0.0313214 (* 1 = 0.0313214 loss)
I0711 19:37:57.884537  7290 sgd_solver.cpp:106] Iteration 23000, lr = 0.0001
I0711 19:38:15.260576  7290 solver.cpp:290] Iteration 23100 (5.75521 iter/s, 17.3756s/100 iter), loss = 0.0274884
I0711 19:38:15.260598  7290 solver.cpp:309]     Train net output #0: loss = 0.0274882 (* 1 = 0.0274882 loss)
I0711 19:38:15.260607  7290 sgd_solver.cpp:106] Iteration 23100, lr = 0.0001
I0711 19:38:32.470405  7290 solver.cpp:290] Iteration 23200 (5.8108 iter/s, 17.2093s/100 iter), loss = 0.0173784
I0711 19:38:32.470502  7290 solver.cpp:309]     Train net output #0: loss = 0.0173783 (* 1 = 0.0173783 loss)
I0711 19:38:32.470523  7290 sgd_solver.cpp:106] Iteration 23200, lr = 0.0001
I0711 19:38:49.655822  7290 solver.cpp:290] Iteration 23300 (5.81908 iter/s, 17.1848s/100 iter), loss = 0.0183244
I0711 19:38:49.655848  7290 solver.cpp:309]     Train net output #0: loss = 0.0183242 (* 1 = 0.0183242 loss)
I0711 19:38:49.655858  7290 sgd_solver.cpp:106] Iteration 23300, lr = 0.0001
I0711 19:39:07.105202  7290 solver.cpp:290] Iteration 23400 (5.73103 iter/s, 17.4489s/100 iter), loss = 0.0314142
I0711 19:39:07.105294  7290 solver.cpp:309]     Train net output #0: loss = 0.0314141 (* 1 = 0.0314141 loss)
I0711 19:39:07.105304  7290 sgd_solver.cpp:106] Iteration 23400, lr = 0.0001
I0711 19:39:24.437666  7290 solver.cpp:290] Iteration 23500 (5.76971 iter/s, 17.3319s/100 iter), loss = 0.0239255
I0711 19:39:24.437690  7290 solver.cpp:309]     Train net output #0: loss = 0.0239253 (* 1 = 0.0239253 loss)
I0711 19:39:24.437696  7290 sgd_solver.cpp:106] Iteration 23500, lr = 0.0001
I0711 19:39:41.527186  7290 solver.cpp:290] Iteration 23600 (5.85171 iter/s, 17.089s/100 iter), loss = 0.207712
I0711 19:39:41.527282  7290 solver.cpp:309]     Train net output #0: loss = 0.207712 (* 1 = 0.207712 loss)
I0711 19:39:41.527293  7290 sgd_solver.cpp:106] Iteration 23600, lr = 0.0001
I0711 19:39:58.883056  7290 solver.cpp:290] Iteration 23700 (5.76193 iter/s, 17.3553s/100 iter), loss = 0.029736
I0711 19:39:58.883080  7290 solver.cpp:309]     Train net output #0: loss = 0.0297358 (* 1 = 0.0297358 loss)
I0711 19:39:58.883086  7290 sgd_solver.cpp:106] Iteration 23700, lr = 0.0001
I0711 19:40:16.365200  7290 solver.cpp:290] Iteration 23800 (5.72029 iter/s, 17.4816s/100 iter), loss = 0.0355305
I0711 19:40:16.365285  7290 solver.cpp:309]     Train net output #0: loss = 0.0355303 (* 1 = 0.0355303 loss)
I0711 19:40:16.365299  7290 sgd_solver.cpp:106] Iteration 23800, lr = 0.0001
I0711 19:40:33.869624  7290 solver.cpp:290] Iteration 23900 (5.71303 iter/s, 17.5039s/100 iter), loss = 0.0231232
I0711 19:40:33.869650  7290 solver.cpp:309]     Train net output #0: loss = 0.023123 (* 1 = 0.023123 loss)
I0711 19:40:33.869658  7290 sgd_solver.cpp:106] Iteration 23900, lr = 0.0001
I0711 19:40:50.805266  7290 solver.cpp:467] Iteration 24000, Testing net (#0)
I0711 19:41:43.372508  7290 solver.cpp:540]     Test net output #0: accuracy/top1 = 0.952738
I0711 19:41:43.372592  7290 solver.cpp:540]     Test net output #1: accuracy/top5 = 0.999935
I0711 19:41:43.372599  7290 solver.cpp:540]     Test net output #2: loss = 0.127557 (* 1 = 0.127557 loss)
I0711 19:41:43.561893  7290 solver.cpp:290] Iteration 24000 (1.43492 iter/s, 69.6903s/100 iter), loss = 0.0288483
I0711 19:41:43.561916  7290 solver.cpp:309]     Train net output #0: loss = 0.0288481 (* 1 = 0.0288481 loss)
I0711 19:41:43.561923  7500 sgd_solver.cpp:46] MultiStep Status: Iteration 24000, step = 1
I0711 19:41:43.561928  7501 sgd_solver.cpp:46] MultiStep Status: Iteration 24000, step = 1
I0711 19:41:43.561923  7290 sgd_solver.cpp:46] MultiStep Status: Iteration 24000, step = 1
I0711 19:41:43.561939  7290 sgd_solver.cpp:106] Iteration 24000, lr = 1e-05
I0711 19:42:00.759773  7290 solver.cpp:290] Iteration 24100 (5.81484 iter/s, 17.1974s/100 iter), loss = 0.0192892
I0711 19:42:00.759799  7290 solver.cpp:309]     Train net output #0: loss = 0.0192891 (* 1 = 0.0192891 loss)
I0711 19:42:00.759809  7290 sgd_solver.cpp:106] Iteration 24100, lr = 1e-05
I0711 19:42:18.460419  7290 solver.cpp:290] Iteration 24200 (5.64968 iter/s, 17.7001s/100 iter), loss = 0.0470148
I0711 19:42:18.460458  7290 solver.cpp:309]     Train net output #0: loss = 0.0470146 (* 1 = 0.0470146 loss)
I0711 19:42:18.460465  7290 sgd_solver.cpp:106] Iteration 24200, lr = 1e-05
I0711 19:42:35.967129  7290 solver.cpp:290] Iteration 24300 (5.71227 iter/s, 17.5062s/100 iter), loss = 0.0294049
I0711 19:42:35.967156  7290 solver.cpp:309]     Train net output #0: loss = 0.0294048 (* 1 = 0.0294048 loss)
I0711 19:42:35.967165  7290 sgd_solver.cpp:106] Iteration 24300, lr = 1e-05
I0711 19:42:53.296622  7290 solver.cpp:290] Iteration 24400 (5.77068 iter/s, 17.329s/100 iter), loss = 0.0174914
I0711 19:42:53.296669  7290 solver.cpp:309]     Train net output #0: loss = 0.0174912 (* 1 = 0.0174912 loss)
I0711 19:42:53.296679  7290 sgd_solver.cpp:106] Iteration 24400, lr = 1e-05
I0711 19:43:10.440153  7290 solver.cpp:290] Iteration 24500 (5.83328 iter/s, 17.143s/100 iter), loss = 0.0237801
I0711 19:43:10.440176  7290 solver.cpp:309]     Train net output #0: loss = 0.0237799 (* 1 = 0.0237799 loss)
I0711 19:43:10.440184  7290 sgd_solver.cpp:106] Iteration 24500, lr = 1e-05
I0711 19:43:27.358557  7290 solver.cpp:290] Iteration 24600 (5.91089 iter/s, 16.9179s/100 iter), loss = 0.0303642
I0711 19:43:27.358629  7290 solver.cpp:309]     Train net output #0: loss = 0.030364 (* 1 = 0.030364 loss)
I0711 19:43:27.358638  7290 sgd_solver.cpp:106] Iteration 24600, lr = 1e-05
I0711 19:43:44.396653  7290 solver.cpp:290] Iteration 24700 (5.86939 iter/s, 17.0376s/100 iter), loss = 0.0200329
I0711 19:43:44.396675  7290 solver.cpp:309]     Train net output #0: loss = 0.0200327 (* 1 = 0.0200327 loss)
I0711 19:43:44.396683  7290 sgd_solver.cpp:106] Iteration 24700, lr = 1e-05
I0711 19:44:01.413066  7290 solver.cpp:290] Iteration 24800 (5.87685 iter/s, 17.0159s/100 iter), loss = 0.0199048
I0711 19:44:01.413147  7290 solver.cpp:309]     Train net output #0: loss = 0.0199047 (* 1 = 0.0199047 loss)
I0711 19:44:01.413159  7290 sgd_solver.cpp:106] Iteration 24800, lr = 1e-05
I0711 19:44:18.519798  7290 solver.cpp:290] Iteration 24900 (5.84584 iter/s, 17.1062s/100 iter), loss = 0.0383152
I0711 19:44:18.519827  7290 solver.cpp:309]     Train net output #0: loss = 0.038315 (* 1 = 0.038315 loss)
I0711 19:44:18.519836  7290 sgd_solver.cpp:106] Iteration 24900, lr = 1e-05
I0711 19:44:35.580029  7290 solver.cpp:290] Iteration 25000 (5.86176 iter/s, 17.0597s/100 iter), loss = 0.0270356
I0711 19:44:35.580101  7290 solver.cpp:309]     Train net output #0: loss = 0.0270355 (* 1 = 0.0270355 loss)
I0711 19:44:35.580111  7290 sgd_solver.cpp:106] Iteration 25000, lr = 1e-05
I0711 19:44:52.499197  7290 solver.cpp:290] Iteration 25100 (5.91064 iter/s, 16.9186s/100 iter), loss = 0.022068
I0711 19:44:52.499220  7290 solver.cpp:309]     Train net output #0: loss = 0.0220679 (* 1 = 0.0220679 loss)
I0711 19:44:52.499227  7290 sgd_solver.cpp:106] Iteration 25100, lr = 1e-05
I0711 19:45:09.356052  7290 solver.cpp:290] Iteration 25200 (5.93248 iter/s, 16.8564s/100 iter), loss = 0.0549388
I0711 19:45:09.356098  7290 solver.cpp:309]     Train net output #0: loss = 0.0549386 (* 1 = 0.0549386 loss)
I0711 19:45:09.356107  7290 sgd_solver.cpp:106] Iteration 25200, lr = 1e-05
I0711 19:45:26.216164  7290 solver.cpp:290] Iteration 25300 (5.93134 iter/s, 16.8596s/100 iter), loss = 0.0219621
I0711 19:45:26.216188  7290 solver.cpp:309]     Train net output #0: loss = 0.0219619 (* 1 = 0.0219619 loss)
I0711 19:45:26.216197  7290 sgd_solver.cpp:106] Iteration 25300, lr = 1e-05
I0711 19:45:43.615453  7290 solver.cpp:290] Iteration 25400 (5.74753 iter/s, 17.3988s/100 iter), loss = 0.0228791
I0711 19:45:43.615559  7290 solver.cpp:309]     Train net output #0: loss = 0.0228789 (* 1 = 0.0228789 loss)
I0711 19:45:43.615586  7290 sgd_solver.cpp:106] Iteration 25400, lr = 1e-05
I0711 19:46:01.032178  7290 solver.cpp:290] Iteration 25500 (5.7418 iter/s, 17.4161s/100 iter), loss = 0.0234289
I0711 19:46:01.032223  7290 solver.cpp:309]     Train net output #0: loss = 0.0234287 (* 1 = 0.0234287 loss)
I0711 19:46:01.032248  7290 sgd_solver.cpp:106] Iteration 25500, lr = 1e-05
I0711 19:46:18.520123  7290 solver.cpp:290] Iteration 25600 (5.7184 iter/s, 17.4874s/100 iter), loss = 0.0325431
I0711 19:46:18.520207  7290 solver.cpp:309]     Train net output #0: loss = 0.032543 (* 1 = 0.032543 loss)
I0711 19:46:18.520233  7290 sgd_solver.cpp:106] Iteration 25600, lr = 1e-05
I0711 19:46:35.837332  7290 solver.cpp:290] Iteration 25700 (5.77479 iter/s, 17.3167s/100 iter), loss = 0.0203291
I0711 19:46:35.837357  7290 solver.cpp:309]     Train net output #0: loss = 0.0203289 (* 1 = 0.0203289 loss)
I0711 19:46:35.837366  7290 sgd_solver.cpp:106] Iteration 25700, lr = 1e-05
I0711 19:46:53.218660  7290 solver.cpp:290] Iteration 25800 (5.75347 iter/s, 17.3808s/100 iter), loss = 0.0349839
I0711 19:46:53.218777  7290 solver.cpp:309]     Train net output #0: loss = 0.0349837 (* 1 = 0.0349837 loss)
I0711 19:46:53.218794  7290 sgd_solver.cpp:106] Iteration 25800, lr = 1e-05
I0711 19:47:10.728687  7290 solver.cpp:290] Iteration 25900 (5.71121 iter/s, 17.5094s/100 iter), loss = 0.018033
I0711 19:47:10.728718  7290 solver.cpp:309]     Train net output #0: loss = 0.0180328 (* 1 = 0.0180328 loss)
I0711 19:47:10.728724  7290 sgd_solver.cpp:106] Iteration 25900, lr = 1e-05
I0711 19:47:28.111424  7290 solver.cpp:467] Iteration 26000, Testing net (#0)
I0711 19:48:19.762604  7290 solver.cpp:540]     Test net output #0: accuracy/top1 = 0.952551
I0711 19:48:19.762665  7290 solver.cpp:540]     Test net output #1: accuracy/top5 = 0.999744
I0711 19:48:19.762673  7290 solver.cpp:540]     Test net output #2: loss = 0.140247 (* 1 = 0.140247 loss)
I0711 19:48:19.964718  7290 solver.cpp:290] Iteration 26000 (1.44437 iter/s, 69.2341s/100 iter), loss = 0.0231964
I0711 19:48:19.964743  7290 solver.cpp:309]     Train net output #0: loss = 0.0231963 (* 1 = 0.0231963 loss)
I0711 19:48:19.964761  7290 sgd_solver.cpp:106] Iteration 26000, lr = 1e-05
I0711 19:48:37.329900  7290 solver.cpp:290] Iteration 26100 (5.75882 iter/s, 17.3647s/100 iter), loss = 0.0202824
I0711 19:48:37.329924  7290 solver.cpp:309]     Train net output #0: loss = 0.0202822 (* 1 = 0.0202822 loss)
I0711 19:48:37.329931  7290 sgd_solver.cpp:106] Iteration 26100, lr = 1e-05
I0711 19:48:54.680801  7290 solver.cpp:290] Iteration 26200 (5.76356 iter/s, 17.3504s/100 iter), loss = 0.0286325
I0711 19:48:54.680843  7290 solver.cpp:309]     Train net output #0: loss = 0.0286323 (* 1 = 0.0286323 loss)
I0711 19:48:54.680852  7290 sgd_solver.cpp:106] Iteration 26200, lr = 1e-05
I0711 19:49:12.069919  7290 solver.cpp:290] Iteration 26300 (5.7509 iter/s, 17.3886s/100 iter), loss = 0.023574
I0711 19:49:12.069942  7290 solver.cpp:309]     Train net output #0: loss = 0.0235738 (* 1 = 0.0235738 loss)
I0711 19:49:12.069949  7290 sgd_solver.cpp:106] Iteration 26300, lr = 1e-05
I0711 19:49:29.667327  7290 solver.cpp:290] Iteration 26400 (5.68282 iter/s, 17.5969s/100 iter), loss = 0.0225688
I0711 19:49:29.667430  7290 solver.cpp:309]     Train net output #0: loss = 0.0225686 (* 1 = 0.0225686 loss)
I0711 19:49:29.667454  7290 sgd_solver.cpp:106] Iteration 26400, lr = 1e-05
I0711 19:49:47.191818  7290 solver.cpp:290] Iteration 26500 (5.70649 iter/s, 17.5239s/100 iter), loss = 0.0325137
I0711 19:49:47.191840  7290 solver.cpp:309]     Train net output #0: loss = 0.0325135 (* 1 = 0.0325135 loss)
I0711 19:49:47.191848  7290 sgd_solver.cpp:106] Iteration 26500, lr = 1e-05
I0711 19:50:04.452292  7290 solver.cpp:290] Iteration 26600 (5.79375 iter/s, 17.26s/100 iter), loss = 0.0385882
I0711 19:50:04.452407  7290 solver.cpp:309]     Train net output #0: loss = 0.0385881 (* 1 = 0.0385881 loss)
I0711 19:50:04.452419  7290 sgd_solver.cpp:106] Iteration 26600, lr = 1e-05
I0711 19:50:21.786654  7290 solver.cpp:290] Iteration 26700 (5.76909 iter/s, 17.3338s/100 iter), loss = 0.0205319
I0711 19:50:21.786705  7290 solver.cpp:309]     Train net output #0: loss = 0.0205318 (* 1 = 0.0205318 loss)
I0711 19:50:21.786725  7290 sgd_solver.cpp:106] Iteration 26700, lr = 1e-05
I0711 19:50:39.051020  7290 solver.cpp:290] Iteration 26800 (5.79245 iter/s, 17.2638s/100 iter), loss = 0.0331906
I0711 19:50:39.051120  7290 solver.cpp:309]     Train net output #0: loss = 0.0331904 (* 1 = 0.0331904 loss)
I0711 19:50:39.051142  7290 sgd_solver.cpp:106] Iteration 26800, lr = 1e-05
I0711 19:50:56.463695  7290 solver.cpp:290] Iteration 26900 (5.74313 iter/s, 17.4121s/100 iter), loss = 0.0300695
I0711 19:50:56.463717  7290 solver.cpp:309]     Train net output #0: loss = 0.0300693 (* 1 = 0.0300693 loss)
I0711 19:50:56.463724  7290 sgd_solver.cpp:106] Iteration 26900, lr = 1e-05
I0711 19:51:13.900424  7290 solver.cpp:290] Iteration 27000 (5.73518 iter/s, 17.4362s/100 iter), loss = 0.0170511
I0711 19:51:13.900466  7290 solver.cpp:309]     Train net output #0: loss = 0.017051 (* 1 = 0.017051 loss)
I0711 19:51:13.900475  7290 sgd_solver.cpp:106] Iteration 27000, lr = 1e-05
I0711 19:51:31.208564  7290 solver.cpp:290] Iteration 27100 (5.7778 iter/s, 17.3076s/100 iter), loss = 0.0170417
I0711 19:51:31.208588  7290 solver.cpp:309]     Train net output #0: loss = 0.0170415 (* 1 = 0.0170415 loss)
I0711 19:51:31.208595  7290 sgd_solver.cpp:106] Iteration 27100, lr = 1e-05
I0711 19:51:48.410617  7290 solver.cpp:290] Iteration 27200 (5.81343 iter/s, 17.2016s/100 iter), loss = 0.0219093
I0711 19:51:48.410742  7290 solver.cpp:309]     Train net output #0: loss = 0.0219092 (* 1 = 0.0219092 loss)
I0711 19:51:48.410753  7290 sgd_solver.cpp:106] Iteration 27200, lr = 1e-05
I0711 19:52:05.743335  7290 solver.cpp:290] Iteration 27300 (5.76964 iter/s, 17.3321s/100 iter), loss = 0.0336758
I0711 19:52:05.743413  7290 solver.cpp:309]     Train net output #0: loss = 0.0336756 (* 1 = 0.0336756 loss)
I0711 19:52:05.743433  7290 sgd_solver.cpp:106] Iteration 27300, lr = 1e-05
I0711 19:52:22.879385  7290 solver.cpp:290] Iteration 27400 (5.83584 iter/s, 17.1355s/100 iter), loss = 0.0193283
I0711 19:52:22.879436  7290 solver.cpp:309]     Train net output #0: loss = 0.0193282 (* 1 = 0.0193282 loss)
I0711 19:52:22.879443  7290 sgd_solver.cpp:106] Iteration 27400, lr = 1e-05
I0711 19:52:40.217723  7290 solver.cpp:290] Iteration 27500 (5.76774 iter/s, 17.3378s/100 iter), loss = 0.0213278
I0711 19:52:40.217746  7290 solver.cpp:309]     Train net output #0: loss = 0.0213277 (* 1 = 0.0213277 loss)
I0711 19:52:40.217752  7290 sgd_solver.cpp:106] Iteration 27500, lr = 1e-05
I0711 19:52:57.580207  7290 solver.cpp:290] Iteration 27600 (5.75971 iter/s, 17.362s/100 iter), loss = 0.0253669
I0711 19:52:57.580286  7290 solver.cpp:309]     Train net output #0: loss = 0.0253667 (* 1 = 0.0253667 loss)
I0711 19:52:57.580297  7290 sgd_solver.cpp:106] Iteration 27600, lr = 1e-05
I0711 19:53:14.943109  7290 solver.cpp:290] Iteration 27700 (5.75959 iter/s, 17.3623s/100 iter), loss = 0.0391308
I0711 19:53:14.943146  7290 solver.cpp:309]     Train net output #0: loss = 0.0391307 (* 1 = 0.0391307 loss)
I0711 19:53:14.943156  7290 sgd_solver.cpp:106] Iteration 27700, lr = 1e-05
I0711 19:53:32.197372  7290 solver.cpp:290] Iteration 27800 (5.79584 iter/s, 17.2537s/100 iter), loss = 0.0331955
I0711 19:53:32.197458  7290 solver.cpp:309]     Train net output #0: loss = 0.0331953 (* 1 = 0.0331953 loss)
I0711 19:53:32.197485  7290 sgd_solver.cpp:106] Iteration 27800, lr = 1e-05
I0711 19:53:49.376638  7290 solver.cpp:290] Iteration 27900 (5.82116 iter/s, 17.1787s/100 iter), loss = 0.0396285
I0711 19:53:49.376662  7290 solver.cpp:309]     Train net output #0: loss = 0.0396283 (* 1 = 0.0396283 loss)
I0711 19:53:49.376668  7290 sgd_solver.cpp:106] Iteration 27900, lr = 1e-05
I0711 19:54:06.647390  7290 solver.cpp:467] Iteration 28000, Testing net (#0)
I0711 19:54:56.690570  7290 solver.cpp:540]     Test net output #0: accuracy/top1 = 0.95381
I0711 19:54:56.690656  7290 solver.cpp:540]     Test net output #1: accuracy/top5 = 0.999792
I0711 19:54:56.690663  7290 solver.cpp:540]     Test net output #2: loss = 0.139063 (* 1 = 0.139063 loss)
I0711 19:54:56.882596  7290 solver.cpp:290] Iteration 28000 (1.48139 iter/s, 67.5041s/100 iter), loss = 0.0203176
I0711 19:54:56.882621  7290 solver.cpp:309]     Train net output #0: loss = 0.0203174 (* 1 = 0.0203174 loss)
I0711 19:54:56.882627  7290 sgd_solver.cpp:106] Iteration 28000, lr = 1e-05
I0711 19:55:14.095139  7290 solver.cpp:290] Iteration 28100 (5.80989 iter/s, 17.212s/100 iter), loss = 0.0412571
I0711 19:55:14.095170  7290 solver.cpp:309]     Train net output #0: loss = 0.041257 (* 1 = 0.041257 loss)
I0711 19:55:14.095180  7290 sgd_solver.cpp:106] Iteration 28100, lr = 1e-05
I0711 19:55:31.608945  7290 solver.cpp:290] Iteration 28200 (5.70995 iter/s, 17.5133s/100 iter), loss = 0.0258932
I0711 19:55:31.609027  7290 solver.cpp:309]     Train net output #0: loss = 0.025893 (* 1 = 0.025893 loss)
I0711 19:55:31.609037  7290 sgd_solver.cpp:106] Iteration 28200, lr = 1e-05
I0711 19:55:48.789770  7290 solver.cpp:290] Iteration 28300 (5.82063 iter/s, 17.1803s/100 iter), loss = 0.0240568
I0711 19:55:48.789795  7290 solver.cpp:309]     Train net output #0: loss = 0.0240567 (* 1 = 0.0240567 loss)
I0711 19:55:48.789804  7290 sgd_solver.cpp:106] Iteration 28300, lr = 1e-05
I0711 19:56:05.817935  7290 solver.cpp:290] Iteration 28400 (5.87279 iter/s, 17.0277s/100 iter), loss = 0.0193142
I0711 19:56:05.818006  7290 solver.cpp:309]     Train net output #0: loss = 0.019314 (* 1 = 0.019314 loss)
I0711 19:56:05.818013  7290 sgd_solver.cpp:106] Iteration 28400, lr = 1e-05
I0711 19:56:23.206086  7290 solver.cpp:290] Iteration 28500 (5.75122 iter/s, 17.3876s/100 iter), loss = 0.0204719
I0711 19:56:23.206110  7290 solver.cpp:309]     Train net output #0: loss = 0.0204717 (* 1 = 0.0204717 loss)
I0711 19:56:23.206118  7290 sgd_solver.cpp:106] Iteration 28500, lr = 1e-05
I0711 19:56:40.123849  7290 solver.cpp:290] Iteration 28600 (5.91112 iter/s, 16.9173s/100 iter), loss = 0.0233298
I0711 19:56:40.123893  7290 solver.cpp:309]     Train net output #0: loss = 0.0233296 (* 1 = 0.0233296 loss)
I0711 19:56:40.123900  7290 sgd_solver.cpp:106] Iteration 28600, lr = 1e-05
I0711 19:56:57.295857  7290 solver.cpp:290] Iteration 28700 (5.82361 iter/s, 17.1715s/100 iter), loss = 0.0295925
I0711 19:56:57.295882  7290 solver.cpp:309]     Train net output #0: loss = 0.0295923 (* 1 = 0.0295923 loss)
I0711 19:56:57.295889  7290 sgd_solver.cpp:106] Iteration 28700, lr = 1e-05
I0711 19:57:14.397913  7290 solver.cpp:290] Iteration 28800 (5.84742 iter/s, 17.1016s/100 iter), loss = 0.0153141
I0711 19:57:14.398020  7290 solver.cpp:309]     Train net output #0: loss = 0.015314 (* 1 = 0.015314 loss)
I0711 19:57:14.398028  7290 sgd_solver.cpp:106] Iteration 28800, lr = 1e-05
I0711 19:57:31.482259  7290 solver.cpp:290] Iteration 28900 (5.85351 iter/s, 17.0838s/100 iter), loss = 0.0234288
I0711 19:57:31.482282  7290 solver.cpp:309]     Train net output #0: loss = 0.0234286 (* 1 = 0.0234286 loss)
I0711 19:57:31.482290  7290 sgd_solver.cpp:106] Iteration 28900, lr = 1e-05
I0711 19:57:48.407840  7290 solver.cpp:290] Iteration 29000 (5.90839 iter/s, 16.9251s/100 iter), loss = 0.022881
I0711 19:57:48.407918  7290 solver.cpp:309]     Train net output #0: loss = 0.0228809 (* 1 = 0.0228809 loss)
I0711 19:57:48.407928  7290 sgd_solver.cpp:106] Iteration 29000, lr = 1e-05
I0711 19:58:05.428635  7290 solver.cpp:290] Iteration 29100 (5.87535 iter/s, 17.0203s/100 iter), loss = 0.0163629
I0711 19:58:05.428659  7290 solver.cpp:309]     Train net output #0: loss = 0.0163628 (* 1 = 0.0163628 loss)
I0711 19:58:05.428666  7290 sgd_solver.cpp:106] Iteration 29100, lr = 1e-05
I0711 19:58:22.598071  7290 solver.cpp:290] Iteration 29200 (5.82447 iter/s, 17.1689s/100 iter), loss = 0.0145334
I0711 19:58:22.598152  7290 solver.cpp:309]     Train net output #0: loss = 0.0145332 (* 1 = 0.0145332 loss)
I0711 19:58:22.598163  7290 sgd_solver.cpp:106] Iteration 29200, lr = 1e-05
I0711 19:58:39.551285  7290 solver.cpp:290] Iteration 29300 (5.89878 iter/s, 16.9527s/100 iter), loss = 0.0389174
I0711 19:58:39.551312  7290 solver.cpp:309]     Train net output #0: loss = 0.0389173 (* 1 = 0.0389173 loss)
I0711 19:58:39.551321  7290 sgd_solver.cpp:106] Iteration 29300, lr = 1e-05
I0711 19:58:56.494639  7290 solver.cpp:290] Iteration 29400 (5.90219 iter/s, 16.9429s/100 iter), loss = 0.0316219
I0711 19:58:56.494719  7290 solver.cpp:309]     Train net output #0: loss = 0.0316218 (* 1 = 0.0316218 loss)
I0711 19:58:56.494730  7290 sgd_solver.cpp:106] Iteration 29400, lr = 1e-05
I0711 19:59:13.515385  7290 solver.cpp:290] Iteration 29500 (5.87537 iter/s, 17.0202s/100 iter), loss = 0.0215387
I0711 19:59:13.515411  7290 solver.cpp:309]     Train net output #0: loss = 0.0215386 (* 1 = 0.0215386 loss)
I0711 19:59:13.515419  7290 sgd_solver.cpp:106] Iteration 29500, lr = 1e-05
I0711 19:59:30.494977  7290 solver.cpp:290] Iteration 29600 (5.88959 iter/s, 16.9791s/100 iter), loss = 0.0430063
I0711 19:59:30.495046  7290 solver.cpp:309]     Train net output #0: loss = 0.0430062 (* 1 = 0.0430062 loss)
I0711 19:59:30.495059  7290 sgd_solver.cpp:106] Iteration 29600, lr = 1e-05
I0711 19:59:48.083304  7290 solver.cpp:290] Iteration 29700 (5.68577 iter/s, 17.5878s/100 iter), loss = 0.0363303
I0711 19:59:48.083328  7290 solver.cpp:309]     Train net output #0: loss = 0.0363302 (* 1 = 0.0363302 loss)
I0711 19:59:48.083333  7290 sgd_solver.cpp:106] Iteration 29700, lr = 1e-05
I0711 20:00:05.494956  7290 solver.cpp:290] Iteration 29800 (5.74345 iter/s, 17.4111s/100 iter), loss = 0.0204105
I0711 20:00:05.495033  7290 solver.cpp:309]     Train net output #0: loss = 0.0204103 (* 1 = 0.0204103 loss)
I0711 20:00:05.495043  7290 sgd_solver.cpp:106] Iteration 29800, lr = 1e-05
I0711 20:00:22.537140  7290 solver.cpp:290] Iteration 29900 (5.86798 iter/s, 17.0416s/100 iter), loss = 0.0248608
I0711 20:00:22.537164  7290 solver.cpp:309]     Train net output #0: loss = 0.0248606 (* 1 = 0.0248606 loss)
I0711 20:00:22.537170  7290 sgd_solver.cpp:106] Iteration 29900, lr = 1e-05
I0711 20:00:39.348532  7290 solver.cpp:594] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-07-11_18-09-28/initial/cityscapes5_jsegnet21v2_iter_30000.caffemodel
I0711 20:00:39.400977  7290 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-07-11_18-09-28/initial/cityscapes5_jsegnet21v2_iter_30000.solverstate
I0711 20:00:39.419348  7290 solver.cpp:467] Iteration 30000, Testing net (#0)
I0711 20:01:26.286561  7290 solver.cpp:540]     Test net output #0: accuracy/top1 = 0.954205
I0711 20:01:26.286628  7290 solver.cpp:540]     Test net output #1: accuracy/top5 = 0.999786
I0711 20:01:26.286636  7290 solver.cpp:540]     Test net output #2: loss = 0.137828 (* 1 = 0.137828 loss)
I0711 20:01:26.473192  7290 solver.cpp:290] Iteration 30000 (1.56411 iter/s, 63.9343s/100 iter), loss = 0.0173026
I0711 20:01:26.473217  7290 solver.cpp:309]     Train net output #0: loss = 0.0173025 (* 1 = 0.0173025 loss)
I0711 20:01:26.473225  7290 sgd_solver.cpp:106] Iteration 30000, lr = 1e-05
I0711 20:01:43.510619  7290 solver.cpp:290] Iteration 30100 (5.8696 iter/s, 17.0369s/100 iter), loss = 0.0291802
I0711 20:01:43.510643  7290 solver.cpp:309]     Train net output #0: loss = 0.02918 (* 1 = 0.02918 loss)
I0711 20:01:43.510649  7290 sgd_solver.cpp:106] Iteration 30100, lr = 1e-05
I0711 20:02:00.428903  7290 solver.cpp:290] Iteration 30200 (5.91094 iter/s, 16.9178s/100 iter), loss = 0.0445827
I0711 20:02:00.428982  7290 solver.cpp:309]     Train net output #0: loss = 0.0445825 (* 1 = 0.0445825 loss)
I0711 20:02:00.429003  7290 sgd_solver.cpp:106] Iteration 30200, lr = 1e-05
I0711 20:02:17.457499  7290 solver.cpp:290] Iteration 30300 (5.87266 iter/s, 17.028s/100 iter), loss = 0.0357215
I0711 20:02:17.457526  7290 solver.cpp:309]     Train net output #0: loss = 0.0357213 (* 1 = 0.0357213 loss)
I0711 20:02:17.457535  7290 sgd_solver.cpp:106] Iteration 30300, lr = 1e-05
I0711 20:02:34.478695  7290 solver.cpp:290] Iteration 30400 (5.8752 iter/s, 17.0207s/100 iter), loss = 0.0223276
I0711 20:02:34.478759  7290 solver.cpp:309]     Train net output #0: loss = 0.0223274 (* 1 = 0.0223274 loss)
I0711 20:02:34.478768  7290 sgd_solver.cpp:106] Iteration 30400, lr = 1e-05
I0711 20:02:51.379216  7290 solver.cpp:290] Iteration 30500 (5.91716 iter/s, 16.9s/100 iter), loss = 0.0154606
I0711 20:02:51.379242  7290 solver.cpp:309]     Train net output #0: loss = 0.0154605 (* 1 = 0.0154605 loss)
I0711 20:02:51.379251  7290 sgd_solver.cpp:106] Iteration 30500, lr = 1e-05
I0711 20:03:08.576297  7290 solver.cpp:290] Iteration 30600 (5.81511 iter/s, 17.1966s/100 iter), loss = 0.018006
I0711 20:03:08.576400  7290 solver.cpp:309]     Train net output #0: loss = 0.0180059 (* 1 = 0.0180059 loss)
I0711 20:03:08.576417  7290 sgd_solver.cpp:106] Iteration 30600, lr = 1e-05
I0711 20:03:25.873880  7290 solver.cpp:290] Iteration 30700 (5.78135 iter/s, 17.297s/100 iter), loss = 0.0245963
I0711 20:03:25.873916  7290 solver.cpp:309]     Train net output #0: loss = 0.0245962 (* 1 = 0.0245962 loss)
I0711 20:03:25.873926  7290 sgd_solver.cpp:106] Iteration 30700, lr = 1e-05
I0711 20:03:43.252645  7290 solver.cpp:290] Iteration 30800 (5.75432 iter/s, 17.3782s/100 iter), loss = 0.02128
I0711 20:03:43.252748  7290 solver.cpp:309]     Train net output #0: loss = 0.0212798 (* 1 = 0.0212798 loss)
I0711 20:03:43.252771  7290 sgd_solver.cpp:106] Iteration 30800, lr = 1e-05
I0711 20:04:00.628490  7290 solver.cpp:290] Iteration 30900 (5.75531 iter/s, 17.3753s/100 iter), loss = 0.0425611
I0711 20:04:00.628512  7290 solver.cpp:309]     Train net output #0: loss = 0.042561 (* 1 = 0.042561 loss)
I0711 20:04:00.628520  7290 sgd_solver.cpp:106] Iteration 30900, lr = 1e-05
I0711 20:04:18.005465  7290 solver.cpp:290] Iteration 31000 (5.75491 iter/s, 17.3765s/100 iter), loss = 0.0197839
I0711 20:04:18.005525  7290 solver.cpp:309]     Train net output #0: loss = 0.0197838 (* 1 = 0.0197838 loss)
I0711 20:04:18.005534  7290 sgd_solver.cpp:106] Iteration 31000, lr = 1e-05
I0711 20:04:35.465118  7290 solver.cpp:290] Iteration 31100 (5.72767 iter/s, 17.4591s/100 iter), loss = 0.0257725
I0711 20:04:35.465143  7290 solver.cpp:309]     Train net output #0: loss = 0.0257723 (* 1 = 0.0257723 loss)
I0711 20:04:35.465152  7290 sgd_solver.cpp:106] Iteration 31100, lr = 1e-05
I0711 20:04:52.845741  7290 solver.cpp:290] Iteration 31200 (5.7537 iter/s, 17.3801s/100 iter), loss = 0.0260645
I0711 20:04:52.845819  7290 solver.cpp:309]     Train net output #0: loss = 0.0260643 (* 1 = 0.0260643 loss)
I0711 20:04:52.845830  7290 sgd_solver.cpp:106] Iteration 31200, lr = 1e-05
I0711 20:05:10.154433  7290 solver.cpp:290] Iteration 31300 (5.77763 iter/s, 17.3081s/100 iter), loss = 0.0350436
I0711 20:05:10.154458  7290 solver.cpp:309]     Train net output #0: loss = 0.0350435 (* 1 = 0.0350435 loss)
I0711 20:05:10.154464  7290 sgd_solver.cpp:106] Iteration 31300, lr = 1e-05
I0711 20:05:27.318169  7290 solver.cpp:290] Iteration 31400 (5.82641 iter/s, 17.1632s/100 iter), loss = 0.0255884
I0711 20:05:27.318248  7290 solver.cpp:309]     Train net output #0: loss = 0.0255883 (* 1 = 0.0255883 loss)
I0711 20:05:27.318259  7290 sgd_solver.cpp:106] Iteration 31400, lr = 1e-05
I0711 20:05:44.326303  7290 solver.cpp:290] Iteration 31500 (5.87973 iter/s, 17.0076s/100 iter), loss = 0.0145094
I0711 20:05:44.326326  7290 solver.cpp:309]     Train net output #0: loss = 0.0145093 (* 1 = 0.0145093 loss)
I0711 20:05:44.326335  7290 sgd_solver.cpp:106] Iteration 31500, lr = 1e-05
I0711 20:06:01.374552  7290 solver.cpp:290] Iteration 31600 (5.86587 iter/s, 17.0478s/100 iter), loss = 0.0288533
I0711 20:06:01.374630  7290 solver.cpp:309]     Train net output #0: loss = 0.0288531 (* 1 = 0.0288531 loss)
I0711 20:06:01.374639  7290 sgd_solver.cpp:106] Iteration 31600, lr = 1e-05
I0711 20:06:18.279189  7290 solver.cpp:290] Iteration 31700 (5.91573 iter/s, 16.9041s/100 iter), loss = 0.0407668
I0711 20:06:18.279212  7290 solver.cpp:309]     Train net output #0: loss = 0.0407666 (* 1 = 0.0407666 loss)
I0711 20:06:18.279219  7290 sgd_solver.cpp:106] Iteration 31700, lr = 1e-05
I0711 20:06:35.315052  7290 solver.cpp:290] Iteration 31800 (5.87014 iter/s, 17.0354s/100 iter), loss = 0.0192384
I0711 20:06:35.315140  7290 solver.cpp:309]     Train net output #0: loss = 0.0192383 (* 1 = 0.0192383 loss)
I0711 20:06:35.315153  7290 sgd_solver.cpp:106] Iteration 31800, lr = 1e-05
I0711 20:06:52.410508  7290 solver.cpp:290] Iteration 31900 (5.8497 iter/s, 17.0949s/100 iter), loss = 0.0342516
I0711 20:06:52.410531  7290 solver.cpp:309]     Train net output #0: loss = 0.0342515 (* 1 = 0.0342515 loss)
I0711 20:06:52.410537  7290 sgd_solver.cpp:106] Iteration 31900, lr = 1e-05
I0711 20:07:09.320436  7290 solver.cpp:594] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-07-11_18-09-28/initial/cityscapes5_jsegnet21v2_iter_32000.caffemodel
I0711 20:07:09.346453  7290 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-07-11_18-09-28/initial/cityscapes5_jsegnet21v2_iter_32000.solverstate
I0711 20:07:09.408466  7290 solver.cpp:447] Iteration 32000, loss = 0.0258329
I0711 20:07:09.408486  7290 solver.cpp:467] Iteration 32000, Testing net (#0)
I0711 20:07:58.729935  7290 solver.cpp:540]     Test net output #0: accuracy/top1 = 0.955783
I0711 20:07:58.730022  7290 solver.cpp:540]     Test net output #1: accuracy/top5 = 0.999669
I0711 20:07:58.730031  7290 solver.cpp:540]     Test net output #2: loss = 0.138874 (* 1 = 0.138874 loss)
I0711 20:07:58.730036  7290 solver.cpp:452] Optimization Done.
I0711 20:07:59.013834  7290 caffe.cpp:246] Optimization Done.
