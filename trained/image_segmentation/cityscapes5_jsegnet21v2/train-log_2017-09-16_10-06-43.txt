Logging output to training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/train-log_2017-09-16_10-06-43.txt
Using pretrained model training/imagenet_jacintonet11v2_iter_320000.caffemodel
training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial
training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg
training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/sparse
training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/test
training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/test_quantize
training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/run.sh: line 1: cd: /user/a0393608/files/work/code/vision/ti/bitbucket/algoref/caffe-jacinto/build/tools/caffe.bin: Not a directory
I0916 10:06:48.191828 18930 caffe.cpp:807] This is NVCaffe 0.16.4 started at Sat Sep 16 10:06:47 2017
I0916 10:06:48.191946 18930 caffe.cpp:810] CuDNN version: 6021
I0916 10:06:48.191951 18930 caffe.cpp:811] CuBLAS version: 8000
I0916 10:06:48.191954 18930 caffe.cpp:812] CUDA version: 8000
I0916 10:06:48.191956 18930 caffe.cpp:813] CUDA driver version: 8000
I0916 10:06:48.486515 18930 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0916 10:06:48.487090 18930 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8278441984, dev_info[0]: total=8506769408 free=8278441984
I0916 10:06:48.487613 18930 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8278441984, dev_info[1]: total=8508145664 free=8379236352
I0916 10:06:48.488131 18930 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8278441984, dev_info[2]: total=8508145664 free=8379236352
I0916 10:06:48.488142 18930 caffe.cpp:214] Using GPUs 0, 1, 2
I0916 10:06:48.488471 18930 caffe.cpp:219] GPU 0: GeForce GTX 1080
I0916 10:06:48.488795 18930 caffe.cpp:219] GPU 1: GeForce GTX 1080
I0916 10:06:48.489120 18930 caffe.cpp:219] GPU 2: GeForce GTX 1080
I0916 10:06:48.489161 18930 solver.cpp:43] Solver data type: FLOAT
I0916 10:06:48.489195 18930 solver.cpp:46] Initializing solver from parameters: 
train_net: "training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/train.prototxt"
test_net: "training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/test.prototxt"
test_iter: 125
test_interval: 2000
base_lr: 0.01
display: 100
max_iter: 120000
lr_policy: "multistep"
gamma: 0.1
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 10000
snapshot_prefix: "training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/cityscapes5_jsegnet21v2"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
snapshot_after_train: true
test_initialization: false
stepvalue: 60000
stepvalue: 90000
iter_size: 1
type: "SGD"
I0916 10:06:48.495582 18930 solver.cpp:78] Creating training net from train_net file: training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/train.prototxt
I0916 10:06:48.496181 18930 net.cpp:443] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top1
I0916 10:06:48.496187 18930 net.cpp:443] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top5
W0916 10:06:48.496215 18930 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 16 to 18
I0916 10:06:48.496456 18930 net.cpp:72] Initializing net from parameters: 
name: "jsegnet21v2_train"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageLabelData"
  top: "data"
  top: "label"
  transform_param {
    mirror: true
    crop_size: 640
    mean_value: 0
  }
  image_label_data_param {
    image_list_path: "data/train-image-lmdb"
    label_list_path: "data/train-label-lmdb"
    batch_size: 6
    shuffle: true
    threads: 1
    backend: LMDB
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "out5a"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "out5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "out5a/bn"
  type: "BatchNorm"
  bottom: "out5a"
  top: "out5a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out5a/relu"
  type: "ReLU"
  bottom: "out5a"
  top: "out5a"
}
layer {
  name: "out5a_up2"
  type: "Deconvolution"
  bottom: "out5a"
  top: "out5a_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 64
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out3a"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "out3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "out3a/bn"
  type: "BatchNorm"
  bottom: "out3a"
  top: "out3a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out3a/relu"
  type: "ReLU"
  bottom: "out3a"
  top: "out3a"
}
layer {
  name: "out3_out5_combined"
  type: "Eltwise"
  bottom: "out5a_up2"
  bottom: "out3a"
  top: "out3_out5_combined"
}
layer {
  name: "ctx_conv1"
  type: "Convolution"
  bottom: "out3_out5_combined"
  top: "ctx_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_conv1/bn"
  type: "BatchNorm"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv1/relu"
  type: "ReLU"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
}
layer {
  name: "ctx_conv2"
  type: "Convolution"
  bottom: "ctx_conv1"
  top: "ctx_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv2/bn"
  type: "BatchNorm"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv2/relu"
  type: "ReLU"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
}
layer {
  name: "ctx_conv3"
  type: "Convolution"
  bottom: "ctx_conv2"
  top: "ctx_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv3/bn"
  type: "BatchNorm"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv3/relu"
  type: "ReLU"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
}
layer {
  name: "ctx_conv4"
  type: "Convolution"
  bottom: "ctx_conv3"
  top: "ctx_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv4/bn"
  type: "BatchNorm"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv4/relu"
  type: "ReLU"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
}
layer {
  name: "ctx_final"
  type: "Convolution"
  bottom: "ctx_conv4"
  top: "ctx_final"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_final/relu"
  type: "ReLU"
  bottom: "ctx_final"
  top: "ctx_final"
}
layer {
  name: "out_deconv_final_up2"
  type: "Deconvolution"
  bottom: "ctx_final"
  top: "out_deconv_final_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up4"
  type: "Deconvolution"
  bottom: "out_deconv_final_up2"
  top: "out_deconv_final_up4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up8"
  type: "Deconvolution"
  bottom: "out_deconv_final_up4"
  top: "out_deconv_final_up8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: 255
    normalization: VALID
  }
}
I0916 10:06:48.496598 18930 net.cpp:104] Using FLOAT as default forward math type
I0916 10:06:48.496603 18930 net.cpp:110] Using FLOAT as default backward math type
I0916 10:06:48.496608 18930 layer_factory.hpp:136] Creating layer 'data' of type 'ImageLabelData'
I0916 10:06:48.496619 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.496634 18930 net.cpp:184] Created Layer data (0)
I0916 10:06:48.496639 18930 net.cpp:530] data -> data
I0916 10:06:48.496654 18930 net.cpp:530] data -> label
I0916 10:06:48.496732 18930 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0916 10:06:48.496747 18930 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 10:06:48.497495 18961 db_lmdb.cpp:24] Opened lmdb data/train-image-lmdb
I0916 10:06:48.500568 18930 data_layer.cpp:187] [0] ReshapePrefetch 6, 3, 640, 640
I0916 10:06:48.500638 18930 data_layer.cpp:211] [0] Output data size: 6, 3, 640, 640
I0916 10:06:48.500648 18930 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 10:06:48.500701 18930 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0916 10:06:48.500711 18930 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 10:06:48.501461 18962 data_layer.cpp:101] [0] Parser threads: 1
I0916 10:06:48.501477 18962 data_layer.cpp:103] [0] Transformer threads: 1
I0916 10:06:48.507098 18963 db_lmdb.cpp:24] Opened lmdb data/train-label-lmdb
I0916 10:06:48.508486 18930 data_layer.cpp:187] [0] ReshapePrefetch 6, 1, 640, 640
I0916 10:06:48.508631 18930 data_layer.cpp:211] [0] Output data size: 6, 1, 640, 640
I0916 10:06:48.508651 18930 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 10:06:48.508772 18930 net.cpp:245] Setting up data
I0916 10:06:48.508798 18930 net.cpp:252] TRAIN Top shape for layer 0 'data' 6 3 640 640 (7372800)
I0916 10:06:48.508815 18930 net.cpp:252] TRAIN Top shape for layer 0 'data' 6 1 640 640 (2457600)
I0916 10:06:48.508831 18930 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0916 10:06:48.508844 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.508877 18930 net.cpp:184] Created Layer data/bias (1)
I0916 10:06:48.508889 18930 net.cpp:561] data/bias <- data
I0916 10:06:48.508911 18930 net.cpp:530] data/bias -> data/bias
I0916 10:06:48.510409 18964 data_layer.cpp:101] [0] Parser threads: 1
I0916 10:06:48.510450 18964 data_layer.cpp:103] [0] Transformer threads: 1
I0916 10:06:48.515446 18930 net.cpp:245] Setting up data/bias
I0916 10:06:48.515583 18930 net.cpp:252] TRAIN Top shape for layer 1 'data/bias' 6 3 640 640 (7372800)
I0916 10:06:48.515622 18930 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0916 10:06:48.515657 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.515720 18930 net.cpp:184] Created Layer conv1a (2)
I0916 10:06:48.515738 18930 net.cpp:561] conv1a <- data/bias
I0916 10:06:48.515758 18930 net.cpp:530] conv1a -> conv1a
I0916 10:06:48.849834 18930 net.cpp:245] Setting up conv1a
I0916 10:06:48.849858 18930 net.cpp:252] TRAIN Top shape for layer 2 'conv1a' 6 32 320 320 (19660800)
I0916 10:06:48.849869 18930 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0916 10:06:48.849874 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.849884 18930 net.cpp:184] Created Layer conv1a/bn (3)
I0916 10:06:48.849889 18930 net.cpp:561] conv1a/bn <- conv1a
I0916 10:06:48.849892 18930 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0916 10:06:48.850565 18930 net.cpp:245] Setting up conv1a/bn
I0916 10:06:48.850574 18930 net.cpp:252] TRAIN Top shape for layer 3 'conv1a/bn' 6 32 320 320 (19660800)
I0916 10:06:48.850581 18930 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0916 10:06:48.850584 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.850589 18930 net.cpp:184] Created Layer conv1a/relu (4)
I0916 10:06:48.850591 18930 net.cpp:561] conv1a/relu <- conv1a
I0916 10:06:48.850594 18930 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0916 10:06:48.850603 18930 net.cpp:245] Setting up conv1a/relu
I0916 10:06:48.850606 18930 net.cpp:252] TRAIN Top shape for layer 4 'conv1a/relu' 6 32 320 320 (19660800)
I0916 10:06:48.850610 18930 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0916 10:06:48.850613 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.850627 18930 net.cpp:184] Created Layer conv1b (5)
I0916 10:06:48.850630 18930 net.cpp:561] conv1b <- conv1a
I0916 10:06:48.850632 18930 net.cpp:530] conv1b -> conv1b
I0916 10:06:48.852048 18930 net.cpp:245] Setting up conv1b
I0916 10:06:48.852057 18930 net.cpp:252] TRAIN Top shape for layer 5 'conv1b' 6 32 320 320 (19660800)
I0916 10:06:48.852062 18930 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0916 10:06:48.852066 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.852071 18930 net.cpp:184] Created Layer conv1b/bn (6)
I0916 10:06:48.852072 18930 net.cpp:561] conv1b/bn <- conv1b
I0916 10:06:48.852074 18930 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0916 10:06:48.852695 18930 net.cpp:245] Setting up conv1b/bn
I0916 10:06:48.852704 18930 net.cpp:252] TRAIN Top shape for layer 6 'conv1b/bn' 6 32 320 320 (19660800)
I0916 10:06:48.852710 18930 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0916 10:06:48.852712 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.852715 18930 net.cpp:184] Created Layer conv1b/relu (7)
I0916 10:06:48.852717 18930 net.cpp:561] conv1b/relu <- conv1b
I0916 10:06:48.852720 18930 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0916 10:06:48.852722 18930 net.cpp:245] Setting up conv1b/relu
I0916 10:06:48.852725 18930 net.cpp:252] TRAIN Top shape for layer 7 'conv1b/relu' 6 32 320 320 (19660800)
I0916 10:06:48.852727 18930 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0916 10:06:48.852730 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.852735 18930 net.cpp:184] Created Layer pool1 (8)
I0916 10:06:48.852738 18930 net.cpp:561] pool1 <- conv1b
I0916 10:06:48.852741 18930 net.cpp:530] pool1 -> pool1
I0916 10:06:48.852813 18930 net.cpp:245] Setting up pool1
I0916 10:06:48.852818 18930 net.cpp:252] TRAIN Top shape for layer 8 'pool1' 6 32 160 160 (4915200)
I0916 10:06:48.852819 18930 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0916 10:06:48.852823 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.852828 18930 net.cpp:184] Created Layer res2a_branch2a (9)
I0916 10:06:48.852839 18930 net.cpp:561] res2a_branch2a <- pool1
I0916 10:06:48.852841 18930 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0916 10:06:48.854876 18930 net.cpp:245] Setting up res2a_branch2a
I0916 10:06:48.854887 18930 net.cpp:252] TRAIN Top shape for layer 9 'res2a_branch2a' 6 64 160 160 (9830400)
I0916 10:06:48.854892 18930 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0916 10:06:48.854894 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.854899 18930 net.cpp:184] Created Layer res2a_branch2a/bn (10)
I0916 10:06:48.854902 18930 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0916 10:06:48.854903 18930 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0916 10:06:48.855922 18930 net.cpp:245] Setting up res2a_branch2a/bn
I0916 10:06:48.855931 18930 net.cpp:252] TRAIN Top shape for layer 10 'res2a_branch2a/bn' 6 64 160 160 (9830400)
I0916 10:06:48.855937 18930 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0916 10:06:48.855939 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.855942 18930 net.cpp:184] Created Layer res2a_branch2a/relu (11)
I0916 10:06:48.855945 18930 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0916 10:06:48.855947 18930 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0916 10:06:48.855952 18930 net.cpp:245] Setting up res2a_branch2a/relu
I0916 10:06:48.855955 18930 net.cpp:252] TRAIN Top shape for layer 11 'res2a_branch2a/relu' 6 64 160 160 (9830400)
I0916 10:06:48.855957 18930 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0916 10:06:48.855959 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.855967 18930 net.cpp:184] Created Layer res2a_branch2b (12)
I0916 10:06:48.855970 18930 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0916 10:06:48.855973 18930 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0916 10:06:48.857372 18930 net.cpp:245] Setting up res2a_branch2b
I0916 10:06:48.857380 18930 net.cpp:252] TRAIN Top shape for layer 12 'res2a_branch2b' 6 64 160 160 (9830400)
I0916 10:06:48.857385 18930 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0916 10:06:48.857388 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.857391 18930 net.cpp:184] Created Layer res2a_branch2b/bn (13)
I0916 10:06:48.857394 18930 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0916 10:06:48.857396 18930 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0916 10:06:48.858002 18930 net.cpp:245] Setting up res2a_branch2b/bn
I0916 10:06:48.858009 18930 net.cpp:252] TRAIN Top shape for layer 13 'res2a_branch2b/bn' 6 64 160 160 (9830400)
I0916 10:06:48.858014 18930 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0916 10:06:48.858017 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.858019 18930 net.cpp:184] Created Layer res2a_branch2b/relu (14)
I0916 10:06:48.858022 18930 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0916 10:06:48.858024 18930 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0916 10:06:48.858028 18930 net.cpp:245] Setting up res2a_branch2b/relu
I0916 10:06:48.858031 18930 net.cpp:252] TRAIN Top shape for layer 14 'res2a_branch2b/relu' 6 64 160 160 (9830400)
I0916 10:06:48.858033 18930 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0916 10:06:48.858036 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.858038 18930 net.cpp:184] Created Layer pool2 (15)
I0916 10:06:48.858041 18930 net.cpp:561] pool2 <- res2a_branch2b
I0916 10:06:48.858042 18930 net.cpp:530] pool2 -> pool2
I0916 10:06:48.858103 18930 net.cpp:245] Setting up pool2
I0916 10:06:48.858109 18930 net.cpp:252] TRAIN Top shape for layer 15 'pool2' 6 64 80 80 (2457600)
I0916 10:06:48.858120 18930 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0916 10:06:48.858124 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.858131 18930 net.cpp:184] Created Layer res3a_branch2a (16)
I0916 10:06:48.858134 18930 net.cpp:561] res3a_branch2a <- pool2
I0916 10:06:48.858137 18930 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0916 10:06:48.859912 18930 net.cpp:245] Setting up res3a_branch2a
I0916 10:06:48.859918 18930 net.cpp:252] TRAIN Top shape for layer 16 'res3a_branch2a' 6 128 80 80 (4915200)
I0916 10:06:48.859923 18930 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0916 10:06:48.859926 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.859930 18930 net.cpp:184] Created Layer res3a_branch2a/bn (17)
I0916 10:06:48.859933 18930 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0916 10:06:48.859936 18930 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0916 10:06:48.860630 18930 net.cpp:245] Setting up res3a_branch2a/bn
I0916 10:06:48.860641 18930 net.cpp:252] TRAIN Top shape for layer 17 'res3a_branch2a/bn' 6 128 80 80 (4915200)
I0916 10:06:48.860651 18930 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0916 10:06:48.860656 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.860662 18930 net.cpp:184] Created Layer res3a_branch2a/relu (18)
I0916 10:06:48.860666 18930 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0916 10:06:48.860671 18930 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0916 10:06:48.860677 18930 net.cpp:245] Setting up res3a_branch2a/relu
I0916 10:06:48.860682 18930 net.cpp:252] TRAIN Top shape for layer 18 'res3a_branch2a/relu' 6 128 80 80 (4915200)
I0916 10:06:48.860687 18930 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0916 10:06:48.860689 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.860697 18930 net.cpp:184] Created Layer res3a_branch2b (19)
I0916 10:06:48.860702 18930 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0916 10:06:48.860707 18930 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0916 10:06:48.861876 18930 net.cpp:245] Setting up res3a_branch2b
I0916 10:06:48.861886 18930 net.cpp:252] TRAIN Top shape for layer 19 'res3a_branch2b' 6 128 80 80 (4915200)
I0916 10:06:48.861889 18930 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0916 10:06:48.861892 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.861896 18930 net.cpp:184] Created Layer res3a_branch2b/bn (20)
I0916 10:06:48.861898 18930 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0916 10:06:48.861901 18930 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0916 10:06:48.862490 18930 net.cpp:245] Setting up res3a_branch2b/bn
I0916 10:06:48.862498 18930 net.cpp:252] TRAIN Top shape for layer 20 'res3a_branch2b/bn' 6 128 80 80 (4915200)
I0916 10:06:48.862504 18930 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0916 10:06:48.862506 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.862509 18930 net.cpp:184] Created Layer res3a_branch2b/relu (21)
I0916 10:06:48.862512 18930 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0916 10:06:48.862514 18930 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0916 10:06:48.862519 18930 net.cpp:245] Setting up res3a_branch2b/relu
I0916 10:06:48.862521 18930 net.cpp:252] TRAIN Top shape for layer 21 'res3a_branch2b/relu' 6 128 80 80 (4915200)
I0916 10:06:48.862524 18930 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0916 10:06:48.862527 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.862542 18930 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (22)
I0916 10:06:48.862545 18930 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0916 10:06:48.862547 18930 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0916 10:06:48.862550 18930 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0916 10:06:48.862594 18930 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0916 10:06:48.862599 18930 net.cpp:252] TRAIN Top shape for layer 22 'res3a_branch2b_res3a_branch2b/relu_0_split' 6 128 80 80 (4915200)
I0916 10:06:48.862602 18930 net.cpp:252] TRAIN Top shape for layer 22 'res3a_branch2b_res3a_branch2b/relu_0_split' 6 128 80 80 (4915200)
I0916 10:06:48.862604 18930 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0916 10:06:48.862607 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.862610 18930 net.cpp:184] Created Layer pool3 (23)
I0916 10:06:48.862613 18930 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0916 10:06:48.862615 18930 net.cpp:530] pool3 -> pool3
I0916 10:06:48.862673 18930 net.cpp:245] Setting up pool3
I0916 10:06:48.862676 18930 net.cpp:252] TRAIN Top shape for layer 23 'pool3' 6 128 40 40 (1228800)
I0916 10:06:48.862679 18930 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0916 10:06:48.862681 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.862689 18930 net.cpp:184] Created Layer res4a_branch2a (24)
I0916 10:06:48.862690 18930 net.cpp:561] res4a_branch2a <- pool3
I0916 10:06:48.862694 18930 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0916 10:06:48.870263 18930 net.cpp:245] Setting up res4a_branch2a
I0916 10:06:48.870273 18930 net.cpp:252] TRAIN Top shape for layer 24 'res4a_branch2a' 6 256 40 40 (2457600)
I0916 10:06:48.870278 18930 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0916 10:06:48.870281 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.870286 18930 net.cpp:184] Created Layer res4a_branch2a/bn (25)
I0916 10:06:48.870288 18930 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0916 10:06:48.870291 18930 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0916 10:06:48.870904 18930 net.cpp:245] Setting up res4a_branch2a/bn
I0916 10:06:48.870911 18930 net.cpp:252] TRAIN Top shape for layer 25 'res4a_branch2a/bn' 6 256 40 40 (2457600)
I0916 10:06:48.870916 18930 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0916 10:06:48.870918 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.870921 18930 net.cpp:184] Created Layer res4a_branch2a/relu (26)
I0916 10:06:48.870924 18930 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0916 10:06:48.870926 18930 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0916 10:06:48.870929 18930 net.cpp:245] Setting up res4a_branch2a/relu
I0916 10:06:48.870932 18930 net.cpp:252] TRAIN Top shape for layer 26 'res4a_branch2a/relu' 6 256 40 40 (2457600)
I0916 10:06:48.870934 18930 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0916 10:06:48.870936 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.870942 18930 net.cpp:184] Created Layer res4a_branch2b (27)
I0916 10:06:48.870944 18930 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0916 10:06:48.870947 18930 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0916 10:06:48.874184 18930 net.cpp:245] Setting up res4a_branch2b
I0916 10:06:48.874192 18930 net.cpp:252] TRAIN Top shape for layer 27 'res4a_branch2b' 6 256 40 40 (2457600)
I0916 10:06:48.874197 18930 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0916 10:06:48.874198 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.874209 18930 net.cpp:184] Created Layer res4a_branch2b/bn (28)
I0916 10:06:48.874212 18930 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0916 10:06:48.874214 18930 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0916 10:06:48.874809 18930 net.cpp:245] Setting up res4a_branch2b/bn
I0916 10:06:48.874815 18930 net.cpp:252] TRAIN Top shape for layer 28 'res4a_branch2b/bn' 6 256 40 40 (2457600)
I0916 10:06:48.874820 18930 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0916 10:06:48.874824 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.874825 18930 net.cpp:184] Created Layer res4a_branch2b/relu (29)
I0916 10:06:48.874827 18930 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0916 10:06:48.874830 18930 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0916 10:06:48.874833 18930 net.cpp:245] Setting up res4a_branch2b/relu
I0916 10:06:48.874835 18930 net.cpp:252] TRAIN Top shape for layer 29 'res4a_branch2b/relu' 6 256 40 40 (2457600)
I0916 10:06:48.874837 18930 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0916 10:06:48.874840 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.874842 18930 net.cpp:184] Created Layer pool4 (30)
I0916 10:06:48.874845 18930 net.cpp:561] pool4 <- res4a_branch2b
I0916 10:06:48.874846 18930 net.cpp:530] pool4 -> pool4
I0916 10:06:48.874907 18930 net.cpp:245] Setting up pool4
I0916 10:06:48.874912 18930 net.cpp:252] TRAIN Top shape for layer 30 'pool4' 6 256 40 40 (2457600)
I0916 10:06:48.874914 18930 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0916 10:06:48.874917 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.874923 18930 net.cpp:184] Created Layer res5a_branch2a (31)
I0916 10:06:48.874927 18930 net.cpp:561] res5a_branch2a <- pool4
I0916 10:06:48.874929 18930 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0916 10:06:48.903740 18930 net.cpp:245] Setting up res5a_branch2a
I0916 10:06:48.903760 18930 net.cpp:252] TRAIN Top shape for layer 31 'res5a_branch2a' 6 512 40 40 (4915200)
I0916 10:06:48.903769 18930 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0916 10:06:48.903772 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.903782 18930 net.cpp:184] Created Layer res5a_branch2a/bn (32)
I0916 10:06:48.903786 18930 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0916 10:06:48.903790 18930 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0916 10:06:48.904413 18930 net.cpp:245] Setting up res5a_branch2a/bn
I0916 10:06:48.904420 18930 net.cpp:252] TRAIN Top shape for layer 32 'res5a_branch2a/bn' 6 512 40 40 (4915200)
I0916 10:06:48.904425 18930 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0916 10:06:48.904428 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.904431 18930 net.cpp:184] Created Layer res5a_branch2a/relu (33)
I0916 10:06:48.904434 18930 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0916 10:06:48.904436 18930 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0916 10:06:48.904440 18930 net.cpp:245] Setting up res5a_branch2a/relu
I0916 10:06:48.904443 18930 net.cpp:252] TRAIN Top shape for layer 33 'res5a_branch2a/relu' 6 512 40 40 (4915200)
I0916 10:06:48.904445 18930 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0916 10:06:48.904448 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.904454 18930 net.cpp:184] Created Layer res5a_branch2b (34)
I0916 10:06:48.904464 18930 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0916 10:06:48.904465 18930 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0916 10:06:48.920245 18930 net.cpp:245] Setting up res5a_branch2b
I0916 10:06:48.920282 18930 net.cpp:252] TRAIN Top shape for layer 34 'res5a_branch2b' 6 512 40 40 (4915200)
I0916 10:06:48.920294 18930 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0916 10:06:48.920300 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.920310 18930 net.cpp:184] Created Layer res5a_branch2b/bn (35)
I0916 10:06:48.920322 18930 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0916 10:06:48.920327 18930 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0916 10:06:48.921041 18930 net.cpp:245] Setting up res5a_branch2b/bn
I0916 10:06:48.921051 18930 net.cpp:252] TRAIN Top shape for layer 35 'res5a_branch2b/bn' 6 512 40 40 (4915200)
I0916 10:06:48.921063 18930 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0916 10:06:48.921067 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.921073 18930 net.cpp:184] Created Layer res5a_branch2b/relu (36)
I0916 10:06:48.921077 18930 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0916 10:06:48.921082 18930 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0916 10:06:48.921088 18930 net.cpp:245] Setting up res5a_branch2b/relu
I0916 10:06:48.921093 18930 net.cpp:252] TRAIN Top shape for layer 36 'res5a_branch2b/relu' 6 512 40 40 (4915200)
I0916 10:06:48.921097 18930 layer_factory.hpp:136] Creating layer 'out5a' of type 'Convolution'
I0916 10:06:48.921102 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.921111 18930 net.cpp:184] Created Layer out5a (37)
I0916 10:06:48.921118 18930 net.cpp:561] out5a <- res5a_branch2b
I0916 10:06:48.921123 18930 net.cpp:530] out5a -> out5a
I0916 10:06:48.925779 18930 net.cpp:245] Setting up out5a
I0916 10:06:48.925797 18930 net.cpp:252] TRAIN Top shape for layer 37 'out5a' 6 64 40 40 (614400)
I0916 10:06:48.925803 18930 layer_factory.hpp:136] Creating layer 'out5a/bn' of type 'BatchNorm'
I0916 10:06:48.925807 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.925815 18930 net.cpp:184] Created Layer out5a/bn (38)
I0916 10:06:48.925818 18930 net.cpp:561] out5a/bn <- out5a
I0916 10:06:48.925822 18930 net.cpp:513] out5a/bn -> out5a (in-place)
I0916 10:06:48.926604 18930 net.cpp:245] Setting up out5a/bn
I0916 10:06:48.926614 18930 net.cpp:252] TRAIN Top shape for layer 38 'out5a/bn' 6 64 40 40 (614400)
I0916 10:06:48.926620 18930 layer_factory.hpp:136] Creating layer 'out5a/relu' of type 'ReLU'
I0916 10:06:48.926622 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.926626 18930 net.cpp:184] Created Layer out5a/relu (39)
I0916 10:06:48.926630 18930 net.cpp:561] out5a/relu <- out5a
I0916 10:06:48.926635 18930 net.cpp:513] out5a/relu -> out5a (in-place)
I0916 10:06:48.926641 18930 net.cpp:245] Setting up out5a/relu
I0916 10:06:48.926647 18930 net.cpp:252] TRAIN Top shape for layer 39 'out5a/relu' 6 64 40 40 (614400)
I0916 10:06:48.926650 18930 layer_factory.hpp:136] Creating layer 'out5a_up2' of type 'Deconvolution'
I0916 10:06:48.926652 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.926668 18930 net.cpp:184] Created Layer out5a_up2 (40)
I0916 10:06:48.926673 18930 net.cpp:561] out5a_up2 <- out5a
I0916 10:06:48.926677 18930 net.cpp:530] out5a_up2 -> out5a_up2
I0916 10:06:48.927083 18930 net.cpp:245] Setting up out5a_up2
I0916 10:06:48.927091 18930 net.cpp:252] TRAIN Top shape for layer 40 'out5a_up2' 6 64 80 80 (2457600)
I0916 10:06:48.927096 18930 layer_factory.hpp:136] Creating layer 'out3a' of type 'Convolution'
I0916 10:06:48.927112 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.927129 18930 net.cpp:184] Created Layer out3a (41)
I0916 10:06:48.927134 18930 net.cpp:561] out3a <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0916 10:06:48.927150 18930 net.cpp:530] out3a -> out3a
I0916 10:06:48.928346 18930 net.cpp:245] Setting up out3a
I0916 10:06:48.928355 18930 net.cpp:252] TRAIN Top shape for layer 41 'out3a' 6 64 80 80 (2457600)
I0916 10:06:48.928359 18930 layer_factory.hpp:136] Creating layer 'out3a/bn' of type 'BatchNorm'
I0916 10:06:48.928364 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.928370 18930 net.cpp:184] Created Layer out3a/bn (42)
I0916 10:06:48.928376 18930 net.cpp:561] out3a/bn <- out3a
I0916 10:06:48.928380 18930 net.cpp:513] out3a/bn -> out3a (in-place)
I0916 10:06:48.929075 18930 net.cpp:245] Setting up out3a/bn
I0916 10:06:48.929083 18930 net.cpp:252] TRAIN Top shape for layer 42 'out3a/bn' 6 64 80 80 (2457600)
I0916 10:06:48.929091 18930 layer_factory.hpp:136] Creating layer 'out3a/relu' of type 'ReLU'
I0916 10:06:48.929096 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.929101 18930 net.cpp:184] Created Layer out3a/relu (43)
I0916 10:06:48.929105 18930 net.cpp:561] out3a/relu <- out3a
I0916 10:06:48.929111 18930 net.cpp:513] out3a/relu -> out3a (in-place)
I0916 10:06:48.929116 18930 net.cpp:245] Setting up out3a/relu
I0916 10:06:48.929121 18930 net.cpp:252] TRAIN Top shape for layer 43 'out3a/relu' 6 64 80 80 (2457600)
I0916 10:06:48.929126 18930 layer_factory.hpp:136] Creating layer 'out3_out5_combined' of type 'Eltwise'
I0916 10:06:48.929131 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.929141 18930 net.cpp:184] Created Layer out3_out5_combined (44)
I0916 10:06:48.929145 18930 net.cpp:561] out3_out5_combined <- out5a_up2
I0916 10:06:48.929149 18930 net.cpp:561] out3_out5_combined <- out3a
I0916 10:06:48.929154 18930 net.cpp:530] out3_out5_combined -> out3_out5_combined
I0916 10:06:48.929195 18930 net.cpp:245] Setting up out3_out5_combined
I0916 10:06:48.929203 18930 net.cpp:252] TRAIN Top shape for layer 44 'out3_out5_combined' 6 64 80 80 (2457600)
I0916 10:06:48.929208 18930 layer_factory.hpp:136] Creating layer 'ctx_conv1' of type 'Convolution'
I0916 10:06:48.929211 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.929224 18930 net.cpp:184] Created Layer ctx_conv1 (45)
I0916 10:06:48.929229 18930 net.cpp:561] ctx_conv1 <- out3_out5_combined
I0916 10:06:48.929232 18930 net.cpp:530] ctx_conv1 -> ctx_conv1
I0916 10:06:48.930366 18930 net.cpp:245] Setting up ctx_conv1
I0916 10:06:48.930374 18930 net.cpp:252] TRAIN Top shape for layer 45 'ctx_conv1' 6 64 80 80 (2457600)
I0916 10:06:48.930382 18930 layer_factory.hpp:136] Creating layer 'ctx_conv1/bn' of type 'BatchNorm'
I0916 10:06:48.930387 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.930395 18930 net.cpp:184] Created Layer ctx_conv1/bn (46)
I0916 10:06:48.930400 18930 net.cpp:561] ctx_conv1/bn <- ctx_conv1
I0916 10:06:48.930404 18930 net.cpp:513] ctx_conv1/bn -> ctx_conv1 (in-place)
I0916 10:06:48.931057 18930 net.cpp:245] Setting up ctx_conv1/bn
I0916 10:06:48.931064 18930 net.cpp:252] TRAIN Top shape for layer 46 'ctx_conv1/bn' 6 64 80 80 (2457600)
I0916 10:06:48.931071 18930 layer_factory.hpp:136] Creating layer 'ctx_conv1/relu' of type 'ReLU'
I0916 10:06:48.931074 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.931090 18930 net.cpp:184] Created Layer ctx_conv1/relu (47)
I0916 10:06:48.931095 18930 net.cpp:561] ctx_conv1/relu <- ctx_conv1
I0916 10:06:48.931107 18930 net.cpp:513] ctx_conv1/relu -> ctx_conv1 (in-place)
I0916 10:06:48.931114 18930 net.cpp:245] Setting up ctx_conv1/relu
I0916 10:06:48.931120 18930 net.cpp:252] TRAIN Top shape for layer 47 'ctx_conv1/relu' 6 64 80 80 (2457600)
I0916 10:06:48.931124 18930 layer_factory.hpp:136] Creating layer 'ctx_conv2' of type 'Convolution'
I0916 10:06:48.931128 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.931147 18930 net.cpp:184] Created Layer ctx_conv2 (48)
I0916 10:06:48.931152 18930 net.cpp:561] ctx_conv2 <- ctx_conv1
I0916 10:06:48.931164 18930 net.cpp:530] ctx_conv2 -> ctx_conv2
I0916 10:06:48.932303 18930 net.cpp:245] Setting up ctx_conv2
I0916 10:06:48.932313 18930 net.cpp:252] TRAIN Top shape for layer 48 'ctx_conv2' 6 64 80 80 (2457600)
I0916 10:06:48.932320 18930 layer_factory.hpp:136] Creating layer 'ctx_conv2/bn' of type 'BatchNorm'
I0916 10:06:48.932332 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.932345 18930 net.cpp:184] Created Layer ctx_conv2/bn (49)
I0916 10:06:48.932354 18930 net.cpp:561] ctx_conv2/bn <- ctx_conv2
I0916 10:06:48.932359 18930 net.cpp:513] ctx_conv2/bn -> ctx_conv2 (in-place)
I0916 10:06:48.933068 18930 net.cpp:245] Setting up ctx_conv2/bn
I0916 10:06:48.933076 18930 net.cpp:252] TRAIN Top shape for layer 49 'ctx_conv2/bn' 6 64 80 80 (2457600)
I0916 10:06:48.933082 18930 layer_factory.hpp:136] Creating layer 'ctx_conv2/relu' of type 'ReLU'
I0916 10:06:48.933086 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.933091 18930 net.cpp:184] Created Layer ctx_conv2/relu (50)
I0916 10:06:48.933096 18930 net.cpp:561] ctx_conv2/relu <- ctx_conv2
I0916 10:06:48.933100 18930 net.cpp:513] ctx_conv2/relu -> ctx_conv2 (in-place)
I0916 10:06:48.933106 18930 net.cpp:245] Setting up ctx_conv2/relu
I0916 10:06:48.933111 18930 net.cpp:252] TRAIN Top shape for layer 50 'ctx_conv2/relu' 6 64 80 80 (2457600)
I0916 10:06:48.933115 18930 layer_factory.hpp:136] Creating layer 'ctx_conv3' of type 'Convolution'
I0916 10:06:48.933120 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.933130 18930 net.cpp:184] Created Layer ctx_conv3 (51)
I0916 10:06:48.933135 18930 net.cpp:561] ctx_conv3 <- ctx_conv2
I0916 10:06:48.933140 18930 net.cpp:530] ctx_conv3 -> ctx_conv3
I0916 10:06:48.934335 18930 net.cpp:245] Setting up ctx_conv3
I0916 10:06:48.934345 18930 net.cpp:252] TRAIN Top shape for layer 51 'ctx_conv3' 6 64 80 80 (2457600)
I0916 10:06:48.934348 18930 layer_factory.hpp:136] Creating layer 'ctx_conv3/bn' of type 'BatchNorm'
I0916 10:06:48.934362 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.934371 18930 net.cpp:184] Created Layer ctx_conv3/bn (52)
I0916 10:06:48.934376 18930 net.cpp:561] ctx_conv3/bn <- ctx_conv3
I0916 10:06:48.934379 18930 net.cpp:513] ctx_conv3/bn -> ctx_conv3 (in-place)
I0916 10:06:48.935199 18930 net.cpp:245] Setting up ctx_conv3/bn
I0916 10:06:48.935207 18930 net.cpp:252] TRAIN Top shape for layer 52 'ctx_conv3/bn' 6 64 80 80 (2457600)
I0916 10:06:48.935214 18930 layer_factory.hpp:136] Creating layer 'ctx_conv3/relu' of type 'ReLU'
I0916 10:06:48.935216 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.935220 18930 net.cpp:184] Created Layer ctx_conv3/relu (53)
I0916 10:06:48.935222 18930 net.cpp:561] ctx_conv3/relu <- ctx_conv3
I0916 10:06:48.935225 18930 net.cpp:513] ctx_conv3/relu -> ctx_conv3 (in-place)
I0916 10:06:48.935231 18930 net.cpp:245] Setting up ctx_conv3/relu
I0916 10:06:48.935235 18930 net.cpp:252] TRAIN Top shape for layer 53 'ctx_conv3/relu' 6 64 80 80 (2457600)
I0916 10:06:48.935238 18930 layer_factory.hpp:136] Creating layer 'ctx_conv4' of type 'Convolution'
I0916 10:06:48.935242 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.935252 18930 net.cpp:184] Created Layer ctx_conv4 (54)
I0916 10:06:48.935257 18930 net.cpp:561] ctx_conv4 <- ctx_conv3
I0916 10:06:48.935261 18930 net.cpp:530] ctx_conv4 -> ctx_conv4
I0916 10:06:48.936437 18930 net.cpp:245] Setting up ctx_conv4
I0916 10:06:48.936445 18930 net.cpp:252] TRAIN Top shape for layer 54 'ctx_conv4' 6 64 80 80 (2457600)
I0916 10:06:48.936450 18930 layer_factory.hpp:136] Creating layer 'ctx_conv4/bn' of type 'BatchNorm'
I0916 10:06:48.936460 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.936465 18930 net.cpp:184] Created Layer ctx_conv4/bn (55)
I0916 10:06:48.936468 18930 net.cpp:561] ctx_conv4/bn <- ctx_conv4
I0916 10:06:48.936471 18930 net.cpp:513] ctx_conv4/bn -> ctx_conv4 (in-place)
I0916 10:06:48.937156 18930 net.cpp:245] Setting up ctx_conv4/bn
I0916 10:06:48.937165 18930 net.cpp:252] TRAIN Top shape for layer 55 'ctx_conv4/bn' 6 64 80 80 (2457600)
I0916 10:06:48.937172 18930 layer_factory.hpp:136] Creating layer 'ctx_conv4/relu' of type 'ReLU'
I0916 10:06:48.937176 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.937182 18930 net.cpp:184] Created Layer ctx_conv4/relu (56)
I0916 10:06:48.937186 18930 net.cpp:561] ctx_conv4/relu <- ctx_conv4
I0916 10:06:48.937191 18930 net.cpp:513] ctx_conv4/relu -> ctx_conv4 (in-place)
I0916 10:06:48.937197 18930 net.cpp:245] Setting up ctx_conv4/relu
I0916 10:06:48.937202 18930 net.cpp:252] TRAIN Top shape for layer 56 'ctx_conv4/relu' 6 64 80 80 (2457600)
I0916 10:06:48.937207 18930 layer_factory.hpp:136] Creating layer 'ctx_final' of type 'Convolution'
I0916 10:06:48.937211 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.937223 18930 net.cpp:184] Created Layer ctx_final (57)
I0916 10:06:48.937227 18930 net.cpp:561] ctx_final <- ctx_conv4
I0916 10:06:48.937232 18930 net.cpp:530] ctx_final -> ctx_final
I0916 10:06:48.937784 18930 net.cpp:245] Setting up ctx_final
I0916 10:06:48.937793 18930 net.cpp:252] TRAIN Top shape for layer 57 'ctx_final' 6 8 80 80 (307200)
I0916 10:06:48.937798 18930 layer_factory.hpp:136] Creating layer 'ctx_final/relu' of type 'ReLU'
I0916 10:06:48.937803 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.937808 18930 net.cpp:184] Created Layer ctx_final/relu (58)
I0916 10:06:48.937813 18930 net.cpp:561] ctx_final/relu <- ctx_final
I0916 10:06:48.937816 18930 net.cpp:513] ctx_final/relu -> ctx_final (in-place)
I0916 10:06:48.937822 18930 net.cpp:245] Setting up ctx_final/relu
I0916 10:06:48.937829 18930 net.cpp:252] TRAIN Top shape for layer 58 'ctx_final/relu' 6 8 80 80 (307200)
I0916 10:06:48.937832 18930 layer_factory.hpp:136] Creating layer 'out_deconv_final_up2' of type 'Deconvolution'
I0916 10:06:48.937836 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.937844 18930 net.cpp:184] Created Layer out_deconv_final_up2 (59)
I0916 10:06:48.937847 18930 net.cpp:561] out_deconv_final_up2 <- ctx_final
I0916 10:06:48.937852 18930 net.cpp:530] out_deconv_final_up2 -> out_deconv_final_up2
I0916 10:06:48.938228 18930 net.cpp:245] Setting up out_deconv_final_up2
I0916 10:06:48.938235 18930 net.cpp:252] TRAIN Top shape for layer 59 'out_deconv_final_up2' 6 8 160 160 (1228800)
I0916 10:06:48.938239 18930 layer_factory.hpp:136] Creating layer 'out_deconv_final_up4' of type 'Deconvolution'
I0916 10:06:48.938243 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.938251 18930 net.cpp:184] Created Layer out_deconv_final_up4 (60)
I0916 10:06:48.938256 18930 net.cpp:561] out_deconv_final_up4 <- out_deconv_final_up2
I0916 10:06:48.938259 18930 net.cpp:530] out_deconv_final_up4 -> out_deconv_final_up4
I0916 10:06:48.938586 18930 net.cpp:245] Setting up out_deconv_final_up4
I0916 10:06:48.938592 18930 net.cpp:252] TRAIN Top shape for layer 60 'out_deconv_final_up4' 6 8 320 320 (4915200)
I0916 10:06:48.938597 18930 layer_factory.hpp:136] Creating layer 'out_deconv_final_up8' of type 'Deconvolution'
I0916 10:06:48.938601 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.938609 18930 net.cpp:184] Created Layer out_deconv_final_up8 (61)
I0916 10:06:48.938613 18930 net.cpp:561] out_deconv_final_up8 <- out_deconv_final_up4
I0916 10:06:48.938618 18930 net.cpp:530] out_deconv_final_up8 -> out_deconv_final_up8
I0916 10:06:48.938942 18930 net.cpp:245] Setting up out_deconv_final_up8
I0916 10:06:48.938949 18930 net.cpp:252] TRAIN Top shape for layer 61 'out_deconv_final_up8' 6 8 640 640 (19660800)
I0916 10:06:48.938954 18930 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0916 10:06:48.938958 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.938972 18930 net.cpp:184] Created Layer loss (62)
I0916 10:06:48.938977 18930 net.cpp:561] loss <- out_deconv_final_up8
I0916 10:06:48.938982 18930 net.cpp:561] loss <- label
I0916 10:06:48.938987 18930 net.cpp:530] loss -> loss
I0916 10:06:48.940421 18930 net.cpp:245] Setting up loss
I0916 10:06:48.940431 18930 net.cpp:252] TRAIN Top shape for layer 62 'loss' (1)
I0916 10:06:48.940436 18930 net.cpp:256]     with loss weight 1
I0916 10:06:48.940451 18930 net.cpp:323] loss needs backward computation.
I0916 10:06:48.940456 18930 net.cpp:323] out_deconv_final_up8 needs backward computation.
I0916 10:06:48.940460 18930 net.cpp:323] out_deconv_final_up4 needs backward computation.
I0916 10:06:48.940467 18930 net.cpp:323] out_deconv_final_up2 needs backward computation.
I0916 10:06:48.940471 18930 net.cpp:323] ctx_final/relu needs backward computation.
I0916 10:06:48.940474 18930 net.cpp:323] ctx_final needs backward computation.
I0916 10:06:48.940476 18930 net.cpp:323] ctx_conv4/relu needs backward computation.
I0916 10:06:48.940490 18930 net.cpp:323] ctx_conv4/bn needs backward computation.
I0916 10:06:48.940500 18930 net.cpp:323] ctx_conv4 needs backward computation.
I0916 10:06:48.940506 18930 net.cpp:323] ctx_conv3/relu needs backward computation.
I0916 10:06:48.940512 18930 net.cpp:323] ctx_conv3/bn needs backward computation.
I0916 10:06:48.940517 18930 net.cpp:323] ctx_conv3 needs backward computation.
I0916 10:06:48.940523 18930 net.cpp:323] ctx_conv2/relu needs backward computation.
I0916 10:06:48.940528 18930 net.cpp:323] ctx_conv2/bn needs backward computation.
I0916 10:06:48.940534 18930 net.cpp:323] ctx_conv2 needs backward computation.
I0916 10:06:48.940539 18930 net.cpp:323] ctx_conv1/relu needs backward computation.
I0916 10:06:48.940546 18930 net.cpp:323] ctx_conv1/bn needs backward computation.
I0916 10:06:48.940551 18930 net.cpp:323] ctx_conv1 needs backward computation.
I0916 10:06:48.940557 18930 net.cpp:323] out3_out5_combined needs backward computation.
I0916 10:06:48.940563 18930 net.cpp:323] out3a/relu needs backward computation.
I0916 10:06:48.940569 18930 net.cpp:323] out3a/bn needs backward computation.
I0916 10:06:48.940575 18930 net.cpp:323] out3a needs backward computation.
I0916 10:06:48.940582 18930 net.cpp:323] out5a_up2 needs backward computation.
I0916 10:06:48.940587 18930 net.cpp:323] out5a/relu needs backward computation.
I0916 10:06:48.940593 18930 net.cpp:323] out5a/bn needs backward computation.
I0916 10:06:48.940599 18930 net.cpp:323] out5a needs backward computation.
I0916 10:06:48.940606 18930 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0916 10:06:48.940613 18930 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0916 10:06:48.940618 18930 net.cpp:323] res5a_branch2b needs backward computation.
I0916 10:06:48.940624 18930 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0916 10:06:48.940630 18930 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0916 10:06:48.940636 18930 net.cpp:323] res5a_branch2a needs backward computation.
I0916 10:06:48.940642 18930 net.cpp:323] pool4 needs backward computation.
I0916 10:06:48.940649 18930 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0916 10:06:48.940655 18930 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0916 10:06:48.940661 18930 net.cpp:323] res4a_branch2b needs backward computation.
I0916 10:06:48.940667 18930 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0916 10:06:48.940672 18930 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0916 10:06:48.940678 18930 net.cpp:323] res4a_branch2a needs backward computation.
I0916 10:06:48.940695 18930 net.cpp:323] pool3 needs backward computation.
I0916 10:06:48.940701 18930 net.cpp:323] res3a_branch2b_res3a_branch2b/relu_0_split needs backward computation.
I0916 10:06:48.940707 18930 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0916 10:06:48.940714 18930 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0916 10:06:48.940719 18930 net.cpp:323] res3a_branch2b needs backward computation.
I0916 10:06:48.940726 18930 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0916 10:06:48.940732 18930 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0916 10:06:48.940738 18930 net.cpp:323] res3a_branch2a needs backward computation.
I0916 10:06:48.940744 18930 net.cpp:323] pool2 needs backward computation.
I0916 10:06:48.940750 18930 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0916 10:06:48.940757 18930 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0916 10:06:48.940762 18930 net.cpp:323] res2a_branch2b needs backward computation.
I0916 10:06:48.940768 18930 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0916 10:06:48.940773 18930 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0916 10:06:48.940779 18930 net.cpp:323] res2a_branch2a needs backward computation.
I0916 10:06:48.940785 18930 net.cpp:323] pool1 needs backward computation.
I0916 10:06:48.940791 18930 net.cpp:323] conv1b/relu needs backward computation.
I0916 10:06:48.940798 18930 net.cpp:323] conv1b/bn needs backward computation.
I0916 10:06:48.940804 18930 net.cpp:323] conv1b needs backward computation.
I0916 10:06:48.940810 18930 net.cpp:323] conv1a/relu needs backward computation.
I0916 10:06:48.940817 18930 net.cpp:323] conv1a/bn needs backward computation.
I0916 10:06:48.940824 18930 net.cpp:323] conv1a needs backward computation.
I0916 10:06:48.940829 18930 net.cpp:325] data/bias does not need backward computation.
I0916 10:06:48.940836 18930 net.cpp:325] data does not need backward computation.
I0916 10:06:48.940842 18930 net.cpp:367] This network produces output loss
I0916 10:06:48.940927 18930 net.cpp:389] Top memory (TRAIN) required for data: 1435238408 diff: 1435238408
I0916 10:06:48.940933 18930 net.cpp:392] Bottom memory (TRAIN) required for data: 1435238400 diff: 1435238400
I0916 10:06:48.940938 18930 net.cpp:395] Shared (in-place) memory (TRAIN) by data: 772915200 diff: 772915200
I0916 10:06:48.940943 18930 net.cpp:398] Parameters memory (TRAIN) required for data: 10817840 diff: 10817840
I0916 10:06:48.940948 18930 net.cpp:401] Parameters shared memory (TRAIN) by data: 0 diff: 0
I0916 10:06:48.940953 18930 net.cpp:407] Network initialization done.
I0916 10:06:48.941922 18930 solver.cpp:177] Creating test net (#0) specified by test_net file: training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/test.prototxt
W0916 10:06:48.942019 18930 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 4 to 6
I0916 10:06:48.942312 18930 net.cpp:72] Initializing net from parameters: 
name: "jsegnet21v2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageLabelData"
  top: "data"
  top: "label"
  transform_param {
    mirror: false
    crop_size: 640
    mean_value: 0
  }
  image_label_data_param {
    image_list_path: "data/val-image-lmdb"
    label_list_path: "data/val-label-lmdb"
    batch_size: 2
    threads: 1
    backend: LMDB
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "out5a"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "out5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "out5a/bn"
  type: "BatchNorm"
  bottom: "out5a"
  top: "out5a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out5a/relu"
  type: "ReLU"
  bottom: "out5a"
  top: "out5a"
}
layer {
  name: "out5a_up2"
  type: "Deconvolution"
  bottom: "out5a"
  top: "out5a_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 64
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out3a"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "out3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "out3a/bn"
  type: "BatchNorm"
  bottom: "out3a"
  top: "out3a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out3a/relu"
  type: "ReLU"
  bottom: "out3a"
  top: "out3a"
}
layer {
  name: "out3_out5_combined"
  type: "Eltwise"
  bottom: "out5a_up2"
  bottom: "out3a"
  top: "out3_out5_combined"
}
layer {
  name: "ctx_conv1"
  type: "Convolution"
  bottom: "out3_out5_combined"
  top: "ctx_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_conv1/bn"
  type: "BatchNorm"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv1/relu"
  type: "ReLU"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
}
layer {
  name: "ctx_conv2"
  type: "Convolution"
  bottom: "ctx_conv1"
  top: "ctx_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv2/bn"
  type: "BatchNorm"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv2/relu"
  type: "ReLU"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
}
layer {
  name: "ctx_conv3"
  type: "Convolution"
  bottom: "ctx_conv2"
  top: "ctx_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv3/bn"
  type: "BatchNorm"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv3/relu"
  type: "ReLU"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
}
layer {
  name: "ctx_conv4"
  type: "Convolution"
  bottom: "ctx_conv3"
  top: "ctx_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv4/bn"
  type: "BatchNorm"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv4/relu"
  type: "ReLU"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
}
layer {
  name: "ctx_final"
  type: "Convolution"
  bottom: "ctx_conv4"
  top: "ctx_final"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_final/relu"
  type: "ReLU"
  bottom: "ctx_final"
  top: "ctx_final"
}
layer {
  name: "out_deconv_final_up2"
  type: "Deconvolution"
  bottom: "ctx_final"
  top: "out_deconv_final_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up4"
  type: "Deconvolution"
  bottom: "out_deconv_final_up2"
  top: "out_deconv_final_up4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up8"
  type: "Deconvolution"
  bottom: "out_deconv_final_up4"
  top: "out_deconv_final_up8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: 255
    normalization: VALID
  }
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "accuracy/top1"
  include {
    phase: TEST
  }
  accuracy_param {
    ignore_label: 255
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "accuracy/top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
    ignore_label: 255
  }
}
I0916 10:06:48.942497 18930 net.cpp:104] Using FLOAT as default forward math type
I0916 10:06:48.942512 18930 net.cpp:110] Using FLOAT as default backward math type
I0916 10:06:48.942519 18930 layer_factory.hpp:136] Creating layer 'data' of type 'ImageLabelData'
I0916 10:06:48.942528 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.942539 18930 net.cpp:184] Created Layer data (0)
I0916 10:06:48.942544 18930 net.cpp:530] data -> data
I0916 10:06:48.942550 18930 net.cpp:530] data -> label
I0916 10:06:48.942581 18930 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 2
I0916 10:06:48.942589 18930 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 10:06:48.943326 19000 db_lmdb.cpp:24] Opened lmdb data/val-image-lmdb
I0916 10:06:48.948829 18930 data_layer.cpp:187] (0) ReshapePrefetch 2, 3, 640, 640
I0916 10:06:48.948884 18930 data_layer.cpp:211] (0) Output data size: 2, 3, 640, 640
I0916 10:06:48.948890 18930 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 10:06:48.948935 18930 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 2
I0916 10:06:48.948945 18930 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 10:06:48.950888 19001 data_layer.cpp:101] (0) Parser threads: 1
I0916 10:06:48.950901 19001 data_layer.cpp:103] (0) Transformer threads: 1
I0916 10:06:48.952850 19002 db_lmdb.cpp:24] Opened lmdb data/val-label-lmdb
I0916 10:06:48.953661 18930 data_layer.cpp:187] (0) ReshapePrefetch 2, 1, 640, 640
I0916 10:06:48.953734 18930 data_layer.cpp:211] (0) Output data size: 2, 1, 640, 640
I0916 10:06:48.953742 18930 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 10:06:48.953805 18930 net.cpp:245] Setting up data
I0916 10:06:48.953816 18930 net.cpp:252] TEST Top shape for layer 0 'data' 2 3 640 640 (2457600)
I0916 10:06:48.953852 18930 net.cpp:252] TEST Top shape for layer 0 'data' 2 1 640 640 (819200)
I0916 10:06:48.953871 18930 layer_factory.hpp:136] Creating layer 'label_data_1_split' of type 'Split'
I0916 10:06:48.953887 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.953907 18930 net.cpp:184] Created Layer label_data_1_split (1)
I0916 10:06:48.953922 18930 net.cpp:561] label_data_1_split <- label
I0916 10:06:48.953936 18930 net.cpp:530] label_data_1_split -> label_data_1_split_0
I0916 10:06:48.953953 18930 net.cpp:530] label_data_1_split -> label_data_1_split_1
I0916 10:06:48.953966 18930 net.cpp:530] label_data_1_split -> label_data_1_split_2
I0916 10:06:48.954089 18930 net.cpp:245] Setting up label_data_1_split
I0916 10:06:48.954108 18930 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 2 1 640 640 (819200)
I0916 10:06:48.954123 18930 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 2 1 640 640 (819200)
I0916 10:06:48.954136 18930 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 2 1 640 640 (819200)
I0916 10:06:48.954149 18930 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0916 10:06:48.954162 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.954180 18930 net.cpp:184] Created Layer data/bias (2)
I0916 10:06:48.954191 18930 net.cpp:561] data/bias <- data
I0916 10:06:48.954205 18930 net.cpp:530] data/bias -> data/bias
I0916 10:06:48.960633 19003 data_layer.cpp:101] (0) Parser threads: 1
I0916 10:06:48.960664 19003 data_layer.cpp:103] (0) Transformer threads: 1
I0916 10:06:48.962335 18930 net.cpp:245] Setting up data/bias
I0916 10:06:48.962349 18930 net.cpp:252] TEST Top shape for layer 2 'data/bias' 2 3 640 640 (2457600)
I0916 10:06:48.962360 18930 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0916 10:06:48.962365 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.962381 18930 net.cpp:184] Created Layer conv1a (3)
I0916 10:06:48.962386 18930 net.cpp:561] conv1a <- data/bias
I0916 10:06:48.962391 18930 net.cpp:530] conv1a -> conv1a
I0916 10:06:48.963136 18930 net.cpp:245] Setting up conv1a
I0916 10:06:48.963147 18930 net.cpp:252] TEST Top shape for layer 3 'conv1a' 2 32 320 320 (6553600)
I0916 10:06:48.963155 18930 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0916 10:06:48.963158 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.963165 18930 net.cpp:184] Created Layer conv1a/bn (4)
I0916 10:06:48.963169 18930 net.cpp:561] conv1a/bn <- conv1a
I0916 10:06:48.963172 18930 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0916 10:06:48.964018 18930 net.cpp:245] Setting up conv1a/bn
I0916 10:06:48.964030 18930 net.cpp:252] TEST Top shape for layer 4 'conv1a/bn' 2 32 320 320 (6553600)
I0916 10:06:48.964038 18930 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0916 10:06:48.964053 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.964066 18930 net.cpp:184] Created Layer conv1a/relu (5)
I0916 10:06:48.964074 18930 net.cpp:561] conv1a/relu <- conv1a
I0916 10:06:48.964083 18930 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0916 10:06:48.964094 18930 net.cpp:245] Setting up conv1a/relu
I0916 10:06:48.964103 18930 net.cpp:252] TEST Top shape for layer 5 'conv1a/relu' 2 32 320 320 (6553600)
I0916 10:06:48.964112 18930 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0916 10:06:48.964121 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.964136 18930 net.cpp:184] Created Layer conv1b (6)
I0916 10:06:48.964144 18930 net.cpp:561] conv1b <- conv1a
I0916 10:06:48.964154 18930 net.cpp:530] conv1b -> conv1b
I0916 10:06:48.965405 18930 net.cpp:245] Setting up conv1b
I0916 10:06:48.965421 18930 net.cpp:252] TEST Top shape for layer 6 'conv1b' 2 32 320 320 (6553600)
I0916 10:06:48.965451 18930 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0916 10:06:48.965457 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.965483 18930 net.cpp:184] Created Layer conv1b/bn (7)
I0916 10:06:48.965488 18930 net.cpp:561] conv1b/bn <- conv1b
I0916 10:06:48.965494 18930 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0916 10:06:48.966199 18930 net.cpp:245] Setting up conv1b/bn
I0916 10:06:48.966207 18930 net.cpp:252] TEST Top shape for layer 7 'conv1b/bn' 2 32 320 320 (6553600)
I0916 10:06:48.966214 18930 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0916 10:06:48.966217 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.966222 18930 net.cpp:184] Created Layer conv1b/relu (8)
I0916 10:06:48.966223 18930 net.cpp:561] conv1b/relu <- conv1b
I0916 10:06:48.966226 18930 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0916 10:06:48.966231 18930 net.cpp:245] Setting up conv1b/relu
I0916 10:06:48.966234 18930 net.cpp:252] TEST Top shape for layer 8 'conv1b/relu' 2 32 320 320 (6553600)
I0916 10:06:48.966236 18930 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0916 10:06:48.966239 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.966244 18930 net.cpp:184] Created Layer pool1 (9)
I0916 10:06:48.966248 18930 net.cpp:561] pool1 <- conv1b
I0916 10:06:48.966249 18930 net.cpp:530] pool1 -> pool1
I0916 10:06:48.966315 18930 net.cpp:245] Setting up pool1
I0916 10:06:48.966320 18930 net.cpp:252] TEST Top shape for layer 9 'pool1' 2 32 160 160 (1638400)
I0916 10:06:48.966325 18930 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0916 10:06:48.966327 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.966336 18930 net.cpp:184] Created Layer res2a_branch2a (10)
I0916 10:06:48.966338 18930 net.cpp:561] res2a_branch2a <- pool1
I0916 10:06:48.966341 18930 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0916 10:06:48.967090 18930 net.cpp:245] Setting up res2a_branch2a
I0916 10:06:48.967098 18930 net.cpp:252] TEST Top shape for layer 10 'res2a_branch2a' 2 64 160 160 (3276800)
I0916 10:06:48.967104 18930 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0916 10:06:48.967108 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.967113 18930 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0916 10:06:48.967115 18930 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0916 10:06:48.967118 18930 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0916 10:06:48.968585 18930 net.cpp:245] Setting up res2a_branch2a/bn
I0916 10:06:48.968596 18930 net.cpp:252] TEST Top shape for layer 11 'res2a_branch2a/bn' 2 64 160 160 (3276800)
I0916 10:06:48.968606 18930 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0916 10:06:48.968623 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.968631 18930 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0916 10:06:48.968636 18930 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0916 10:06:48.968641 18930 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0916 10:06:48.968648 18930 net.cpp:245] Setting up res2a_branch2a/relu
I0916 10:06:48.968653 18930 net.cpp:252] TEST Top shape for layer 12 'res2a_branch2a/relu' 2 64 160 160 (3276800)
I0916 10:06:48.968657 18930 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0916 10:06:48.968662 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.968672 18930 net.cpp:184] Created Layer res2a_branch2b (13)
I0916 10:06:48.968675 18930 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0916 10:06:48.968679 18930 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0916 10:06:48.969310 18930 net.cpp:245] Setting up res2a_branch2b
I0916 10:06:48.969318 18930 net.cpp:252] TEST Top shape for layer 13 'res2a_branch2b' 2 64 160 160 (3276800)
I0916 10:06:48.969324 18930 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0916 10:06:48.969329 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.969336 18930 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0916 10:06:48.969347 18930 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0916 10:06:48.969352 18930 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0916 10:06:48.970612 18930 net.cpp:245] Setting up res2a_branch2b/bn
I0916 10:06:48.970619 18930 net.cpp:252] TEST Top shape for layer 14 'res2a_branch2b/bn' 2 64 160 160 (3276800)
I0916 10:06:48.970628 18930 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0916 10:06:48.970633 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.970638 18930 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0916 10:06:48.970650 18930 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0916 10:06:48.970655 18930 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0916 10:06:48.970661 18930 net.cpp:245] Setting up res2a_branch2b/relu
I0916 10:06:48.970671 18930 net.cpp:252] TEST Top shape for layer 15 'res2a_branch2b/relu' 2 64 160 160 (3276800)
I0916 10:06:48.970675 18930 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0916 10:06:48.970683 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.970691 18930 net.cpp:184] Created Layer pool2 (16)
I0916 10:06:48.970695 18930 net.cpp:561] pool2 <- res2a_branch2b
I0916 10:06:48.970705 18930 net.cpp:530] pool2 -> pool2
I0916 10:06:48.970774 18930 net.cpp:245] Setting up pool2
I0916 10:06:48.970780 18930 net.cpp:252] TEST Top shape for layer 16 'pool2' 2 64 80 80 (819200)
I0916 10:06:48.970788 18930 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0916 10:06:48.970793 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.970805 18930 net.cpp:184] Created Layer res3a_branch2a (17)
I0916 10:06:48.970809 18930 net.cpp:561] res3a_branch2a <- pool2
I0916 10:06:48.970813 18930 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0916 10:06:48.973003 18930 net.cpp:245] Setting up res3a_branch2a
I0916 10:06:48.973021 18930 net.cpp:252] TEST Top shape for layer 17 'res3a_branch2a' 2 128 80 80 (1638400)
I0916 10:06:48.973028 18930 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0916 10:06:48.973034 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.973042 18930 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0916 10:06:48.973047 18930 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0916 10:06:48.973052 18930 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0916 10:06:48.974071 18930 net.cpp:245] Setting up res3a_branch2a/bn
I0916 10:06:48.974090 18930 net.cpp:252] TEST Top shape for layer 18 'res3a_branch2a/bn' 2 128 80 80 (1638400)
I0916 10:06:48.974107 18930 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0916 10:06:48.974113 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.974118 18930 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0916 10:06:48.974123 18930 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0916 10:06:48.974128 18930 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0916 10:06:48.974133 18930 net.cpp:245] Setting up res3a_branch2a/relu
I0916 10:06:48.974138 18930 net.cpp:252] TEST Top shape for layer 19 'res3a_branch2a/relu' 2 128 80 80 (1638400)
I0916 10:06:48.974143 18930 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0916 10:06:48.974146 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.974177 18930 net.cpp:184] Created Layer res3a_branch2b (20)
I0916 10:06:48.974182 18930 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0916 10:06:48.974186 18930 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0916 10:06:48.975713 18930 net.cpp:245] Setting up res3a_branch2b
I0916 10:06:48.975724 18930 net.cpp:252] TEST Top shape for layer 20 'res3a_branch2b' 2 128 80 80 (1638400)
I0916 10:06:48.975731 18930 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0916 10:06:48.975736 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.975744 18930 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0916 10:06:48.975747 18930 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0916 10:06:48.975752 18930 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0916 10:06:48.976629 18930 net.cpp:245] Setting up res3a_branch2b/bn
I0916 10:06:48.976639 18930 net.cpp:252] TEST Top shape for layer 21 'res3a_branch2b/bn' 2 128 80 80 (1638400)
I0916 10:06:48.976647 18930 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0916 10:06:48.976652 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.976658 18930 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0916 10:06:48.976662 18930 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0916 10:06:48.976666 18930 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0916 10:06:48.976672 18930 net.cpp:245] Setting up res3a_branch2b/relu
I0916 10:06:48.976677 18930 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b/relu' 2 128 80 80 (1638400)
I0916 10:06:48.976681 18930 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0916 10:06:48.976686 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.976691 18930 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (23)
I0916 10:06:48.976694 18930 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0916 10:06:48.976698 18930 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0916 10:06:48.976704 18930 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0916 10:06:48.976771 18930 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0916 10:06:48.976778 18930 net.cpp:252] TEST Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 2 128 80 80 (1638400)
I0916 10:06:48.976783 18930 net.cpp:252] TEST Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 2 128 80 80 (1638400)
I0916 10:06:48.976788 18930 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0916 10:06:48.976791 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.976797 18930 net.cpp:184] Created Layer pool3 (24)
I0916 10:06:48.976801 18930 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0916 10:06:48.976805 18930 net.cpp:530] pool3 -> pool3
I0916 10:06:48.976896 18930 net.cpp:245] Setting up pool3
I0916 10:06:48.976902 18930 net.cpp:252] TEST Top shape for layer 24 'pool3' 2 128 40 40 (409600)
I0916 10:06:48.976907 18930 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0916 10:06:48.976910 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.976919 18930 net.cpp:184] Created Layer res4a_branch2a (25)
I0916 10:06:48.976923 18930 net.cpp:561] res4a_branch2a <- pool3
I0916 10:06:48.976927 18930 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0916 10:06:48.983752 18930 net.cpp:245] Setting up res4a_branch2a
I0916 10:06:48.983762 18930 net.cpp:252] TEST Top shape for layer 25 'res4a_branch2a' 2 256 40 40 (819200)
I0916 10:06:48.983765 18930 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0916 10:06:48.983777 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.983783 18930 net.cpp:184] Created Layer res4a_branch2a/bn (26)
I0916 10:06:48.983784 18930 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0916 10:06:48.983788 18930 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0916 10:06:48.984437 18930 net.cpp:245] Setting up res4a_branch2a/bn
I0916 10:06:48.984444 18930 net.cpp:252] TEST Top shape for layer 26 'res4a_branch2a/bn' 2 256 40 40 (819200)
I0916 10:06:48.984449 18930 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0916 10:06:48.984452 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.984455 18930 net.cpp:184] Created Layer res4a_branch2a/relu (27)
I0916 10:06:48.984457 18930 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0916 10:06:48.984459 18930 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0916 10:06:48.984463 18930 net.cpp:245] Setting up res4a_branch2a/relu
I0916 10:06:48.984465 18930 net.cpp:252] TEST Top shape for layer 27 'res4a_branch2a/relu' 2 256 40 40 (819200)
I0916 10:06:48.984467 18930 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0916 10:06:48.984469 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.984479 18930 net.cpp:184] Created Layer res4a_branch2b (28)
I0916 10:06:48.984483 18930 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0916 10:06:48.984486 18930 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0916 10:06:48.988755 18930 net.cpp:245] Setting up res4a_branch2b
I0916 10:06:48.988765 18930 net.cpp:252] TEST Top shape for layer 28 'res4a_branch2b' 2 256 40 40 (819200)
I0916 10:06:48.988770 18930 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0916 10:06:48.988772 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.988777 18930 net.cpp:184] Created Layer res4a_branch2b/bn (29)
I0916 10:06:48.988780 18930 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0916 10:06:48.988781 18930 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0916 10:06:48.989421 18930 net.cpp:245] Setting up res4a_branch2b/bn
I0916 10:06:48.989428 18930 net.cpp:252] TEST Top shape for layer 29 'res4a_branch2b/bn' 2 256 40 40 (819200)
I0916 10:06:48.989434 18930 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0916 10:06:48.989436 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.989439 18930 net.cpp:184] Created Layer res4a_branch2b/relu (30)
I0916 10:06:48.989441 18930 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0916 10:06:48.989444 18930 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0916 10:06:48.989447 18930 net.cpp:245] Setting up res4a_branch2b/relu
I0916 10:06:48.989449 18930 net.cpp:252] TEST Top shape for layer 30 'res4a_branch2b/relu' 2 256 40 40 (819200)
I0916 10:06:48.989451 18930 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0916 10:06:48.989454 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.989457 18930 net.cpp:184] Created Layer pool4 (31)
I0916 10:06:48.989459 18930 net.cpp:561] pool4 <- res4a_branch2b
I0916 10:06:48.989461 18930 net.cpp:530] pool4 -> pool4
I0916 10:06:48.989532 18930 net.cpp:245] Setting up pool4
I0916 10:06:48.989537 18930 net.cpp:252] TEST Top shape for layer 31 'pool4' 2 256 40 40 (819200)
I0916 10:06:48.989539 18930 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0916 10:06:48.989542 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:48.989548 18930 net.cpp:184] Created Layer res5a_branch2a (32)
I0916 10:06:48.989550 18930 net.cpp:561] res5a_branch2a <- pool4
I0916 10:06:48.989559 18930 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0916 10:06:49.017102 18930 net.cpp:245] Setting up res5a_branch2a
I0916 10:06:49.017127 18930 net.cpp:252] TEST Top shape for layer 32 'res5a_branch2a' 2 512 40 40 (1638400)
I0916 10:06:49.017133 18930 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0916 10:06:49.017138 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.017144 18930 net.cpp:184] Created Layer res5a_branch2a/bn (33)
I0916 10:06:49.017148 18930 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0916 10:06:49.017151 18930 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0916 10:06:49.017813 18930 net.cpp:245] Setting up res5a_branch2a/bn
I0916 10:06:49.017822 18930 net.cpp:252] TEST Top shape for layer 33 'res5a_branch2a/bn' 2 512 40 40 (1638400)
I0916 10:06:49.017829 18930 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0916 10:06:49.017832 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.017835 18930 net.cpp:184] Created Layer res5a_branch2a/relu (34)
I0916 10:06:49.017838 18930 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0916 10:06:49.017839 18930 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0916 10:06:49.017843 18930 net.cpp:245] Setting up res5a_branch2a/relu
I0916 10:06:49.017846 18930 net.cpp:252] TEST Top shape for layer 34 'res5a_branch2a/relu' 2 512 40 40 (1638400)
I0916 10:06:49.017848 18930 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0916 10:06:49.017850 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.017856 18930 net.cpp:184] Created Layer res5a_branch2b (35)
I0916 10:06:49.017859 18930 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0916 10:06:49.017863 18930 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0916 10:06:49.031378 18930 net.cpp:245] Setting up res5a_branch2b
I0916 10:06:49.031392 18930 net.cpp:252] TEST Top shape for layer 35 'res5a_branch2b' 2 512 40 40 (1638400)
I0916 10:06:49.031401 18930 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0916 10:06:49.031405 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.031411 18930 net.cpp:184] Created Layer res5a_branch2b/bn (36)
I0916 10:06:49.031414 18930 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0916 10:06:49.031417 18930 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0916 10:06:49.032152 18930 net.cpp:245] Setting up res5a_branch2b/bn
I0916 10:06:49.032161 18930 net.cpp:252] TEST Top shape for layer 36 'res5a_branch2b/bn' 2 512 40 40 (1638400)
I0916 10:06:49.032167 18930 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0916 10:06:49.032171 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.032176 18930 net.cpp:184] Created Layer res5a_branch2b/relu (37)
I0916 10:06:49.032178 18930 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0916 10:06:49.032182 18930 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0916 10:06:49.032188 18930 net.cpp:245] Setting up res5a_branch2b/relu
I0916 10:06:49.032192 18930 net.cpp:252] TEST Top shape for layer 37 'res5a_branch2b/relu' 2 512 40 40 (1638400)
I0916 10:06:49.032197 18930 layer_factory.hpp:136] Creating layer 'out5a' of type 'Convolution'
I0916 10:06:49.032202 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.032214 18930 net.cpp:184] Created Layer out5a (38)
I0916 10:06:49.032217 18930 net.cpp:561] out5a <- res5a_branch2b
I0916 10:06:49.032220 18930 net.cpp:530] out5a -> out5a
I0916 10:06:49.036490 18930 net.cpp:245] Setting up out5a
I0916 10:06:49.036510 18930 net.cpp:252] TEST Top shape for layer 38 'out5a' 2 64 40 40 (204800)
I0916 10:06:49.036520 18930 layer_factory.hpp:136] Creating layer 'out5a/bn' of type 'BatchNorm'
I0916 10:06:49.036538 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.036548 18930 net.cpp:184] Created Layer out5a/bn (39)
I0916 10:06:49.036553 18930 net.cpp:561] out5a/bn <- out5a
I0916 10:06:49.036558 18930 net.cpp:513] out5a/bn -> out5a (in-place)
I0916 10:06:49.037487 18930 net.cpp:245] Setting up out5a/bn
I0916 10:06:49.037497 18930 net.cpp:252] TEST Top shape for layer 39 'out5a/bn' 2 64 40 40 (204800)
I0916 10:06:49.037505 18930 layer_factory.hpp:136] Creating layer 'out5a/relu' of type 'ReLU'
I0916 10:06:49.037509 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.037513 18930 net.cpp:184] Created Layer out5a/relu (40)
I0916 10:06:49.037518 18930 net.cpp:561] out5a/relu <- out5a
I0916 10:06:49.037520 18930 net.cpp:513] out5a/relu -> out5a (in-place)
I0916 10:06:49.037526 18930 net.cpp:245] Setting up out5a/relu
I0916 10:06:49.037531 18930 net.cpp:252] TEST Top shape for layer 40 'out5a/relu' 2 64 40 40 (204800)
I0916 10:06:49.037535 18930 layer_factory.hpp:136] Creating layer 'out5a_up2' of type 'Deconvolution'
I0916 10:06:49.037539 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.037547 18930 net.cpp:184] Created Layer out5a_up2 (41)
I0916 10:06:49.037551 18930 net.cpp:561] out5a_up2 <- out5a
I0916 10:06:49.037555 18930 net.cpp:530] out5a_up2 -> out5a_up2
I0916 10:06:49.037982 18930 net.cpp:245] Setting up out5a_up2
I0916 10:06:49.037992 18930 net.cpp:252] TEST Top shape for layer 41 'out5a_up2' 2 64 80 80 (819200)
I0916 10:06:49.037997 18930 layer_factory.hpp:136] Creating layer 'out3a' of type 'Convolution'
I0916 10:06:49.038002 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.038014 18930 net.cpp:184] Created Layer out3a (42)
I0916 10:06:49.038019 18930 net.cpp:561] out3a <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0916 10:06:49.038024 18930 net.cpp:530] out3a -> out3a
I0916 10:06:49.039562 18930 net.cpp:245] Setting up out3a
I0916 10:06:49.039572 18930 net.cpp:252] TEST Top shape for layer 42 'out3a' 2 64 80 80 (819200)
I0916 10:06:49.039579 18930 layer_factory.hpp:136] Creating layer 'out3a/bn' of type 'BatchNorm'
I0916 10:06:49.039583 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.039590 18930 net.cpp:184] Created Layer out3a/bn (43)
I0916 10:06:49.039594 18930 net.cpp:561] out3a/bn <- out3a
I0916 10:06:49.039599 18930 net.cpp:513] out3a/bn -> out3a (in-place)
I0916 10:06:49.040513 18930 net.cpp:245] Setting up out3a/bn
I0916 10:06:49.040521 18930 net.cpp:252] TEST Top shape for layer 43 'out3a/bn' 2 64 80 80 (819200)
I0916 10:06:49.040530 18930 layer_factory.hpp:136] Creating layer 'out3a/relu' of type 'ReLU'
I0916 10:06:49.040534 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.040540 18930 net.cpp:184] Created Layer out3a/relu (44)
I0916 10:06:49.040544 18930 net.cpp:561] out3a/relu <- out3a
I0916 10:06:49.040549 18930 net.cpp:513] out3a/relu -> out3a (in-place)
I0916 10:06:49.040555 18930 net.cpp:245] Setting up out3a/relu
I0916 10:06:49.040558 18930 net.cpp:252] TEST Top shape for layer 44 'out3a/relu' 2 64 80 80 (819200)
I0916 10:06:49.040562 18930 layer_factory.hpp:136] Creating layer 'out3_out5_combined' of type 'Eltwise'
I0916 10:06:49.040566 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.040572 18930 net.cpp:184] Created Layer out3_out5_combined (45)
I0916 10:06:49.040576 18930 net.cpp:561] out3_out5_combined <- out5a_up2
I0916 10:06:49.040580 18930 net.cpp:561] out3_out5_combined <- out3a
I0916 10:06:49.040585 18930 net.cpp:530] out3_out5_combined -> out3_out5_combined
I0916 10:06:49.040618 18930 net.cpp:245] Setting up out3_out5_combined
I0916 10:06:49.040624 18930 net.cpp:252] TEST Top shape for layer 45 'out3_out5_combined' 2 64 80 80 (819200)
I0916 10:06:49.040637 18930 layer_factory.hpp:136] Creating layer 'ctx_conv1' of type 'Convolution'
I0916 10:06:49.040642 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.040652 18930 net.cpp:184] Created Layer ctx_conv1 (46)
I0916 10:06:49.040657 18930 net.cpp:561] ctx_conv1 <- out3_out5_combined
I0916 10:06:49.040663 18930 net.cpp:530] ctx_conv1 -> ctx_conv1
I0916 10:06:49.042141 18930 net.cpp:245] Setting up ctx_conv1
I0916 10:06:49.042151 18930 net.cpp:252] TEST Top shape for layer 46 'ctx_conv1' 2 64 80 80 (819200)
I0916 10:06:49.042156 18930 layer_factory.hpp:136] Creating layer 'ctx_conv1/bn' of type 'BatchNorm'
I0916 10:06:49.042160 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.042170 18930 net.cpp:184] Created Layer ctx_conv1/bn (47)
I0916 10:06:49.042172 18930 net.cpp:561] ctx_conv1/bn <- ctx_conv1
I0916 10:06:49.042176 18930 net.cpp:513] ctx_conv1/bn -> ctx_conv1 (in-place)
I0916 10:06:49.042850 18930 net.cpp:245] Setting up ctx_conv1/bn
I0916 10:06:49.042856 18930 net.cpp:252] TEST Top shape for layer 47 'ctx_conv1/bn' 2 64 80 80 (819200)
I0916 10:06:49.042862 18930 layer_factory.hpp:136] Creating layer 'ctx_conv1/relu' of type 'ReLU'
I0916 10:06:49.042865 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.042870 18930 net.cpp:184] Created Layer ctx_conv1/relu (48)
I0916 10:06:49.042871 18930 net.cpp:561] ctx_conv1/relu <- ctx_conv1
I0916 10:06:49.042874 18930 net.cpp:513] ctx_conv1/relu -> ctx_conv1 (in-place)
I0916 10:06:49.042878 18930 net.cpp:245] Setting up ctx_conv1/relu
I0916 10:06:49.042881 18930 net.cpp:252] TEST Top shape for layer 48 'ctx_conv1/relu' 2 64 80 80 (819200)
I0916 10:06:49.042883 18930 layer_factory.hpp:136] Creating layer 'ctx_conv2' of type 'Convolution'
I0916 10:06:49.042886 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.042891 18930 net.cpp:184] Created Layer ctx_conv2 (49)
I0916 10:06:49.042894 18930 net.cpp:561] ctx_conv2 <- ctx_conv1
I0916 10:06:49.042896 18930 net.cpp:530] ctx_conv2 -> ctx_conv2
I0916 10:06:49.043993 18930 net.cpp:245] Setting up ctx_conv2
I0916 10:06:49.044000 18930 net.cpp:252] TEST Top shape for layer 49 'ctx_conv2' 2 64 80 80 (819200)
I0916 10:06:49.044005 18930 layer_factory.hpp:136] Creating layer 'ctx_conv2/bn' of type 'BatchNorm'
I0916 10:06:49.044008 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.044013 18930 net.cpp:184] Created Layer ctx_conv2/bn (50)
I0916 10:06:49.044015 18930 net.cpp:561] ctx_conv2/bn <- ctx_conv2
I0916 10:06:49.044018 18930 net.cpp:513] ctx_conv2/bn -> ctx_conv2 (in-place)
I0916 10:06:49.044678 18930 net.cpp:245] Setting up ctx_conv2/bn
I0916 10:06:49.044685 18930 net.cpp:252] TEST Top shape for layer 50 'ctx_conv2/bn' 2 64 80 80 (819200)
I0916 10:06:49.044692 18930 layer_factory.hpp:136] Creating layer 'ctx_conv2/relu' of type 'ReLU'
I0916 10:06:49.044694 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.044697 18930 net.cpp:184] Created Layer ctx_conv2/relu (51)
I0916 10:06:49.044700 18930 net.cpp:561] ctx_conv2/relu <- ctx_conv2
I0916 10:06:49.044703 18930 net.cpp:513] ctx_conv2/relu -> ctx_conv2 (in-place)
I0916 10:06:49.044706 18930 net.cpp:245] Setting up ctx_conv2/relu
I0916 10:06:49.044709 18930 net.cpp:252] TEST Top shape for layer 51 'ctx_conv2/relu' 2 64 80 80 (819200)
I0916 10:06:49.044713 18930 layer_factory.hpp:136] Creating layer 'ctx_conv3' of type 'Convolution'
I0916 10:06:49.044714 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.044719 18930 net.cpp:184] Created Layer ctx_conv3 (52)
I0916 10:06:49.044723 18930 net.cpp:561] ctx_conv3 <- ctx_conv2
I0916 10:06:49.044724 18930 net.cpp:530] ctx_conv3 -> ctx_conv3
I0916 10:06:49.045855 18930 net.cpp:245] Setting up ctx_conv3
I0916 10:06:49.045863 18930 net.cpp:252] TEST Top shape for layer 52 'ctx_conv3' 2 64 80 80 (819200)
I0916 10:06:49.045874 18930 layer_factory.hpp:136] Creating layer 'ctx_conv3/bn' of type 'BatchNorm'
I0916 10:06:49.045877 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.045881 18930 net.cpp:184] Created Layer ctx_conv3/bn (53)
I0916 10:06:49.045884 18930 net.cpp:561] ctx_conv3/bn <- ctx_conv3
I0916 10:06:49.045886 18930 net.cpp:513] ctx_conv3/bn -> ctx_conv3 (in-place)
I0916 10:06:49.046566 18930 net.cpp:245] Setting up ctx_conv3/bn
I0916 10:06:49.046573 18930 net.cpp:252] TEST Top shape for layer 53 'ctx_conv3/bn' 2 64 80 80 (819200)
I0916 10:06:49.046579 18930 layer_factory.hpp:136] Creating layer 'ctx_conv3/relu' of type 'ReLU'
I0916 10:06:49.046582 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.046586 18930 net.cpp:184] Created Layer ctx_conv3/relu (54)
I0916 10:06:49.046588 18930 net.cpp:561] ctx_conv3/relu <- ctx_conv3
I0916 10:06:49.046591 18930 net.cpp:513] ctx_conv3/relu -> ctx_conv3 (in-place)
I0916 10:06:49.046594 18930 net.cpp:245] Setting up ctx_conv3/relu
I0916 10:06:49.046597 18930 net.cpp:252] TEST Top shape for layer 54 'ctx_conv3/relu' 2 64 80 80 (819200)
I0916 10:06:49.046599 18930 layer_factory.hpp:136] Creating layer 'ctx_conv4' of type 'Convolution'
I0916 10:06:49.046602 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.046607 18930 net.cpp:184] Created Layer ctx_conv4 (55)
I0916 10:06:49.046612 18930 net.cpp:561] ctx_conv4 <- ctx_conv3
I0916 10:06:49.046614 18930 net.cpp:530] ctx_conv4 -> ctx_conv4
I0916 10:06:49.047715 18930 net.cpp:245] Setting up ctx_conv4
I0916 10:06:49.047722 18930 net.cpp:252] TEST Top shape for layer 55 'ctx_conv4' 2 64 80 80 (819200)
I0916 10:06:49.047729 18930 layer_factory.hpp:136] Creating layer 'ctx_conv4/bn' of type 'BatchNorm'
I0916 10:06:49.047734 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.047739 18930 net.cpp:184] Created Layer ctx_conv4/bn (56)
I0916 10:06:49.047744 18930 net.cpp:561] ctx_conv4/bn <- ctx_conv4
I0916 10:06:49.047747 18930 net.cpp:513] ctx_conv4/bn -> ctx_conv4 (in-place)
I0916 10:06:49.048434 18930 net.cpp:245] Setting up ctx_conv4/bn
I0916 10:06:49.048442 18930 net.cpp:252] TEST Top shape for layer 56 'ctx_conv4/bn' 2 64 80 80 (819200)
I0916 10:06:49.048450 18930 layer_factory.hpp:136] Creating layer 'ctx_conv4/relu' of type 'ReLU'
I0916 10:06:49.048454 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.048460 18930 net.cpp:184] Created Layer ctx_conv4/relu (57)
I0916 10:06:49.048463 18930 net.cpp:561] ctx_conv4/relu <- ctx_conv4
I0916 10:06:49.048467 18930 net.cpp:513] ctx_conv4/relu -> ctx_conv4 (in-place)
I0916 10:06:49.048472 18930 net.cpp:245] Setting up ctx_conv4/relu
I0916 10:06:49.048478 18930 net.cpp:252] TEST Top shape for layer 57 'ctx_conv4/relu' 2 64 80 80 (819200)
I0916 10:06:49.048482 18930 layer_factory.hpp:136] Creating layer 'ctx_final' of type 'Convolution'
I0916 10:06:49.048486 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.048494 18930 net.cpp:184] Created Layer ctx_final (58)
I0916 10:06:49.048498 18930 net.cpp:561] ctx_final <- ctx_conv4
I0916 10:06:49.048502 18930 net.cpp:530] ctx_final -> ctx_final
I0916 10:06:49.048974 18930 net.cpp:245] Setting up ctx_final
I0916 10:06:49.048984 18930 net.cpp:252] TEST Top shape for layer 58 'ctx_final' 2 8 80 80 (102400)
I0916 10:06:49.048990 18930 layer_factory.hpp:136] Creating layer 'ctx_final/relu' of type 'ReLU'
I0916 10:06:49.048993 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.048998 18930 net.cpp:184] Created Layer ctx_final/relu (59)
I0916 10:06:49.049002 18930 net.cpp:561] ctx_final/relu <- ctx_final
I0916 10:06:49.049006 18930 net.cpp:513] ctx_final/relu -> ctx_final (in-place)
I0916 10:06:49.049018 18930 net.cpp:245] Setting up ctx_final/relu
I0916 10:06:49.049023 18930 net.cpp:252] TEST Top shape for layer 59 'ctx_final/relu' 2 8 80 80 (102400)
I0916 10:06:49.049027 18930 layer_factory.hpp:136] Creating layer 'out_deconv_final_up2' of type 'Deconvolution'
I0916 10:06:49.049031 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.049044 18930 net.cpp:184] Created Layer out_deconv_final_up2 (60)
I0916 10:06:49.049047 18930 net.cpp:561] out_deconv_final_up2 <- ctx_final
I0916 10:06:49.049052 18930 net.cpp:530] out_deconv_final_up2 -> out_deconv_final_up2
I0916 10:06:49.049335 18930 net.cpp:245] Setting up out_deconv_final_up2
I0916 10:06:49.049342 18930 net.cpp:252] TEST Top shape for layer 60 'out_deconv_final_up2' 2 8 160 160 (409600)
I0916 10:06:49.049347 18930 layer_factory.hpp:136] Creating layer 'out_deconv_final_up4' of type 'Deconvolution'
I0916 10:06:49.049351 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.049358 18930 net.cpp:184] Created Layer out_deconv_final_up4 (61)
I0916 10:06:49.049361 18930 net.cpp:561] out_deconv_final_up4 <- out_deconv_final_up2
I0916 10:06:49.049365 18930 net.cpp:530] out_deconv_final_up4 -> out_deconv_final_up4
I0916 10:06:49.049645 18930 net.cpp:245] Setting up out_deconv_final_up4
I0916 10:06:49.049652 18930 net.cpp:252] TEST Top shape for layer 61 'out_deconv_final_up4' 2 8 320 320 (1638400)
I0916 10:06:49.049657 18930 layer_factory.hpp:136] Creating layer 'out_deconv_final_up8' of type 'Deconvolution'
I0916 10:06:49.049662 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.049669 18930 net.cpp:184] Created Layer out_deconv_final_up8 (62)
I0916 10:06:49.049672 18930 net.cpp:561] out_deconv_final_up8 <- out_deconv_final_up4
I0916 10:06:49.049679 18930 net.cpp:530] out_deconv_final_up8 -> out_deconv_final_up8
I0916 10:06:49.049964 18930 net.cpp:245] Setting up out_deconv_final_up8
I0916 10:06:49.049970 18930 net.cpp:252] TEST Top shape for layer 62 'out_deconv_final_up8' 2 8 640 640 (6553600)
I0916 10:06:49.049976 18930 layer_factory.hpp:136] Creating layer 'out_deconv_final_up8_out_deconv_final_up8_0_split' of type 'Split'
I0916 10:06:49.049980 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.049986 18930 net.cpp:184] Created Layer out_deconv_final_up8_out_deconv_final_up8_0_split (63)
I0916 10:06:49.049990 18930 net.cpp:561] out_deconv_final_up8_out_deconv_final_up8_0_split <- out_deconv_final_up8
I0916 10:06:49.049994 18930 net.cpp:530] out_deconv_final_up8_out_deconv_final_up8_0_split -> out_deconv_final_up8_out_deconv_final_up8_0_split_0
I0916 10:06:49.049998 18930 net.cpp:530] out_deconv_final_up8_out_deconv_final_up8_0_split -> out_deconv_final_up8_out_deconv_final_up8_0_split_1
I0916 10:06:49.050004 18930 net.cpp:530] out_deconv_final_up8_out_deconv_final_up8_0_split -> out_deconv_final_up8_out_deconv_final_up8_0_split_2
I0916 10:06:49.050071 18930 net.cpp:245] Setting up out_deconv_final_up8_out_deconv_final_up8_0_split
I0916 10:06:49.050078 18930 net.cpp:252] TEST Top shape for layer 63 'out_deconv_final_up8_out_deconv_final_up8_0_split' 2 8 640 640 (6553600)
I0916 10:06:49.050084 18930 net.cpp:252] TEST Top shape for layer 63 'out_deconv_final_up8_out_deconv_final_up8_0_split' 2 8 640 640 (6553600)
I0916 10:06:49.050089 18930 net.cpp:252] TEST Top shape for layer 63 'out_deconv_final_up8_out_deconv_final_up8_0_split' 2 8 640 640 (6553600)
I0916 10:06:49.050093 18930 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0916 10:06:49.050097 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.050109 18930 net.cpp:184] Created Layer loss (64)
I0916 10:06:49.050112 18930 net.cpp:561] loss <- out_deconv_final_up8_out_deconv_final_up8_0_split_0
I0916 10:06:49.050117 18930 net.cpp:561] loss <- label_data_1_split_0
I0916 10:06:49.050122 18930 net.cpp:530] loss -> loss
I0916 10:06:49.051030 18930 net.cpp:245] Setting up loss
I0916 10:06:49.051039 18930 net.cpp:252] TEST Top shape for layer 64 'loss' (1)
I0916 10:06:49.051043 18930 net.cpp:256]     with loss weight 1
I0916 10:06:49.051053 18930 layer_factory.hpp:136] Creating layer 'accuracy/top1' of type 'Accuracy'
I0916 10:06:49.051056 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.051065 18930 net.cpp:184] Created Layer accuracy/top1 (65)
I0916 10:06:49.051069 18930 net.cpp:561] accuracy/top1 <- out_deconv_final_up8_out_deconv_final_up8_0_split_1
I0916 10:06:49.051074 18930 net.cpp:561] accuracy/top1 <- label_data_1_split_1
I0916 10:06:49.051079 18930 net.cpp:530] accuracy/top1 -> accuracy/top1
I0916 10:06:49.051085 18930 net.cpp:245] Setting up accuracy/top1
I0916 10:06:49.051090 18930 net.cpp:252] TEST Top shape for layer 65 'accuracy/top1' (1)
I0916 10:06:49.051095 18930 layer_factory.hpp:136] Creating layer 'accuracy/top5' of type 'Accuracy'
I0916 10:06:49.051098 18930 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 10:06:49.051103 18930 net.cpp:184] Created Layer accuracy/top5 (66)
I0916 10:06:49.051107 18930 net.cpp:561] accuracy/top5 <- out_deconv_final_up8_out_deconv_final_up8_0_split_2
I0916 10:06:49.051112 18930 net.cpp:561] accuracy/top5 <- label_data_1_split_2
I0916 10:06:49.051117 18930 net.cpp:530] accuracy/top5 -> accuracy/top5
I0916 10:06:49.051128 18930 net.cpp:245] Setting up accuracy/top5
I0916 10:06:49.051133 18930 net.cpp:252] TEST Top shape for layer 66 'accuracy/top5' (1)
I0916 10:06:49.051137 18930 net.cpp:325] accuracy/top5 does not need backward computation.
I0916 10:06:49.051141 18930 net.cpp:325] accuracy/top1 does not need backward computation.
I0916 10:06:49.051146 18930 net.cpp:323] loss needs backward computation.
I0916 10:06:49.051151 18930 net.cpp:323] out_deconv_final_up8_out_deconv_final_up8_0_split needs backward computation.
I0916 10:06:49.051154 18930 net.cpp:323] out_deconv_final_up8 needs backward computation.
I0916 10:06:49.051158 18930 net.cpp:323] out_deconv_final_up4 needs backward computation.
I0916 10:06:49.051162 18930 net.cpp:323] out_deconv_final_up2 needs backward computation.
I0916 10:06:49.051165 18930 net.cpp:323] ctx_final/relu needs backward computation.
I0916 10:06:49.051168 18930 net.cpp:323] ctx_final needs backward computation.
I0916 10:06:49.051172 18930 net.cpp:323] ctx_conv4/relu needs backward computation.
I0916 10:06:49.051175 18930 net.cpp:323] ctx_conv4/bn needs backward computation.
I0916 10:06:49.051179 18930 net.cpp:323] ctx_conv4 needs backward computation.
I0916 10:06:49.051182 18930 net.cpp:323] ctx_conv3/relu needs backward computation.
I0916 10:06:49.051187 18930 net.cpp:323] ctx_conv3/bn needs backward computation.
I0916 10:06:49.051189 18930 net.cpp:323] ctx_conv3 needs backward computation.
I0916 10:06:49.051192 18930 net.cpp:323] ctx_conv2/relu needs backward computation.
I0916 10:06:49.051196 18930 net.cpp:323] ctx_conv2/bn needs backward computation.
I0916 10:06:49.051200 18930 net.cpp:323] ctx_conv2 needs backward computation.
I0916 10:06:49.051203 18930 net.cpp:323] ctx_conv1/relu needs backward computation.
I0916 10:06:49.051208 18930 net.cpp:323] ctx_conv1/bn needs backward computation.
I0916 10:06:49.051211 18930 net.cpp:323] ctx_conv1 needs backward computation.
I0916 10:06:49.051214 18930 net.cpp:323] out3_out5_combined needs backward computation.
I0916 10:06:49.051219 18930 net.cpp:323] out3a/relu needs backward computation.
I0916 10:06:49.051223 18930 net.cpp:323] out3a/bn needs backward computation.
I0916 10:06:49.051226 18930 net.cpp:323] out3a needs backward computation.
I0916 10:06:49.051230 18930 net.cpp:323] out5a_up2 needs backward computation.
I0916 10:06:49.051234 18930 net.cpp:323] out5a/relu needs backward computation.
I0916 10:06:49.051237 18930 net.cpp:323] out5a/bn needs backward computation.
I0916 10:06:49.051241 18930 net.cpp:323] out5a needs backward computation.
I0916 10:06:49.051244 18930 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0916 10:06:49.051252 18930 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0916 10:06:49.051256 18930 net.cpp:323] res5a_branch2b needs backward computation.
I0916 10:06:49.051260 18930 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0916 10:06:49.051265 18930 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0916 10:06:49.051267 18930 net.cpp:323] res5a_branch2a needs backward computation.
I0916 10:06:49.051271 18930 net.cpp:323] pool4 needs backward computation.
I0916 10:06:49.051275 18930 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0916 10:06:49.051280 18930 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0916 10:06:49.051283 18930 net.cpp:323] res4a_branch2b needs backward computation.
I0916 10:06:49.051287 18930 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0916 10:06:49.051290 18930 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0916 10:06:49.051293 18930 net.cpp:323] res4a_branch2a needs backward computation.
I0916 10:06:49.051297 18930 net.cpp:323] pool3 needs backward computation.
I0916 10:06:49.051302 18930 net.cpp:323] res3a_branch2b_res3a_branch2b/relu_0_split needs backward computation.
I0916 10:06:49.051306 18930 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0916 10:06:49.051311 18930 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0916 10:06:49.051314 18930 net.cpp:323] res3a_branch2b needs backward computation.
I0916 10:06:49.051318 18930 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0916 10:06:49.051322 18930 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0916 10:06:49.051326 18930 net.cpp:323] res3a_branch2a needs backward computation.
I0916 10:06:49.051331 18930 net.cpp:323] pool2 needs backward computation.
I0916 10:06:49.051333 18930 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0916 10:06:49.051337 18930 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0916 10:06:49.051342 18930 net.cpp:323] res2a_branch2b needs backward computation.
I0916 10:06:49.051345 18930 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0916 10:06:49.051349 18930 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0916 10:06:49.051352 18930 net.cpp:323] res2a_branch2a needs backward computation.
I0916 10:06:49.051357 18930 net.cpp:323] pool1 needs backward computation.
I0916 10:06:49.051360 18930 net.cpp:323] conv1b/relu needs backward computation.
I0916 10:06:49.051364 18930 net.cpp:323] conv1b/bn needs backward computation.
I0916 10:06:49.051368 18930 net.cpp:323] conv1b needs backward computation.
I0916 10:06:49.051376 18930 net.cpp:323] conv1a/relu needs backward computation.
I0916 10:06:49.051379 18930 net.cpp:323] conv1a/bn needs backward computation.
I0916 10:06:49.051383 18930 net.cpp:323] conv1a needs backward computation.
I0916 10:06:49.051386 18930 net.cpp:325] data/bias does not need backward computation.
I0916 10:06:49.051391 18930 net.cpp:325] label_data_1_split does not need backward computation.
I0916 10:06:49.051396 18930 net.cpp:325] data does not need backward computation.
I0916 10:06:49.051399 18930 net.cpp:367] This network produces output accuracy/top1
I0916 10:06:49.051403 18930 net.cpp:367] This network produces output accuracy/top5
I0916 10:06:49.051407 18930 net.cpp:367] This network produces output loss
I0916 10:06:49.051447 18930 net.cpp:389] Top memory (TEST) required for data: 566886424 diff: 566886424
I0916 10:06:49.051451 18930 net.cpp:392] Bottom memory (TEST) required for data: 566886400 diff: 566886400
I0916 10:06:49.051455 18930 net.cpp:395] Shared (in-place) memory (TEST) by data: 257638400 diff: 257638400
I0916 10:06:49.051458 18930 net.cpp:398] Parameters memory (TEST) required for data: 10817840 diff: 10817840
I0916 10:06:49.051461 18930 net.cpp:401] Parameters shared memory (TEST) by data: 0 diff: 0
I0916 10:06:49.051465 18930 net.cpp:407] Network initialization done.
I0916 10:06:49.051538 18930 solver.cpp:57] Solver scaffolding done.
I0916 10:06:49.058372 18930 caffe.cpp:143] Finetuning from training/imagenet_jacintonet11v2_iter_320000.caffemodel
I0916 10:06:49.068987 18930 net.cpp:1094] Copying source layer data Type:Data #blobs=0
I0916 10:06:49.069010 18930 net.cpp:1094] Copying source layer data/bias Type:Bias #blobs=1
I0916 10:06:49.069047 18930 net.cpp:1094] Copying source layer conv1a Type:Convolution #blobs=2
I0916 10:06:49.069062 18930 net.cpp:1094] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0916 10:06:49.069396 18930 net.cpp:1094] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0916 10:06:49.069404 18930 net.cpp:1094] Copying source layer conv1b Type:Convolution #blobs=2
I0916 10:06:49.069417 18930 net.cpp:1094] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0916 10:06:49.069620 18930 net.cpp:1094] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0916 10:06:49.069628 18930 net.cpp:1094] Copying source layer pool1 Type:Pooling #blobs=0
I0916 10:06:49.069631 18930 net.cpp:1094] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0916 10:06:49.069651 18930 net.cpp:1094] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0916 10:06:49.069869 18930 net.cpp:1094] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0916 10:06:49.069875 18930 net.cpp:1094] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0916 10:06:49.069891 18930 net.cpp:1094] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0916 10:06:49.070099 18930 net.cpp:1094] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0916 10:06:49.070106 18930 net.cpp:1094] Copying source layer pool2 Type:Pooling #blobs=0
I0916 10:06:49.070111 18930 net.cpp:1094] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0916 10:06:49.070154 18930 net.cpp:1094] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0916 10:06:49.070338 18930 net.cpp:1094] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0916 10:06:49.070344 18930 net.cpp:1094] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0916 10:06:49.070370 18930 net.cpp:1094] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0916 10:06:49.070529 18930 net.cpp:1094] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0916 10:06:49.070536 18930 net.cpp:1094] Copying source layer pool3 Type:Pooling #blobs=0
I0916 10:06:49.070539 18930 net.cpp:1094] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0916 10:06:49.070662 18930 net.cpp:1094] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0916 10:06:49.070838 18930 net.cpp:1094] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0916 10:06:49.070844 18930 net.cpp:1094] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0916 10:06:49.070914 18930 net.cpp:1094] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0916 10:06:49.071121 18930 net.cpp:1094] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0916 10:06:49.071130 18930 net.cpp:1094] Copying source layer pool4 Type:Pooling #blobs=0
I0916 10:06:49.071135 18930 net.cpp:1094] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0916 10:06:49.071861 18930 net.cpp:1094] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0916 10:06:49.072027 18930 net.cpp:1094] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0916 10:06:49.072034 18930 net.cpp:1094] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0916 10:06:49.072257 18930 net.cpp:1094] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0916 10:06:49.072392 18930 net.cpp:1094] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0916 10:06:49.072397 18930 net.cpp:1078] Ignoring source layer pool5
I0916 10:06:49.072399 18930 net.cpp:1078] Ignoring source layer fc1000
I0916 10:06:49.072402 18930 net.cpp:1094] Copying source layer loss Type:SoftmaxWithLoss #blobs=0
I0916 10:06:49.076109 18930 net.cpp:1094] Copying source layer data Type:Data #blobs=0
I0916 10:06:49.076125 18930 net.cpp:1094] Copying source layer data/bias Type:Bias #blobs=1
I0916 10:06:49.076167 18930 net.cpp:1094] Copying source layer conv1a Type:Convolution #blobs=2
I0916 10:06:49.076179 18930 net.cpp:1094] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0916 10:06:49.076436 18930 net.cpp:1094] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0916 10:06:49.076442 18930 net.cpp:1094] Copying source layer conv1b Type:Convolution #blobs=2
I0916 10:06:49.076450 18930 net.cpp:1094] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0916 10:06:49.076599 18930 net.cpp:1094] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0916 10:06:49.076603 18930 net.cpp:1094] Copying source layer pool1 Type:Pooling #blobs=0
I0916 10:06:49.076606 18930 net.cpp:1094] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0916 10:06:49.076620 18930 net.cpp:1094] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0916 10:06:49.076776 18930 net.cpp:1094] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0916 10:06:49.076781 18930 net.cpp:1094] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0916 10:06:49.076792 18930 net.cpp:1094] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0916 10:06:49.076937 18930 net.cpp:1094] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0916 10:06:49.076942 18930 net.cpp:1094] Copying source layer pool2 Type:Pooling #blobs=0
I0916 10:06:49.076944 18930 net.cpp:1094] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0916 10:06:49.076982 18930 net.cpp:1094] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0916 10:06:49.077116 18930 net.cpp:1094] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0916 10:06:49.077121 18930 net.cpp:1094] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0916 10:06:49.077142 18930 net.cpp:1094] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0916 10:06:49.077260 18930 net.cpp:1094] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0916 10:06:49.077265 18930 net.cpp:1094] Copying source layer pool3 Type:Pooling #blobs=0
I0916 10:06:49.077267 18930 net.cpp:1094] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0916 10:06:49.077378 18930 net.cpp:1094] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0916 10:06:49.077500 18930 net.cpp:1094] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0916 10:06:49.077504 18930 net.cpp:1094] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0916 10:06:49.077561 18930 net.cpp:1094] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0916 10:06:49.077682 18930 net.cpp:1094] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0916 10:06:49.077687 18930 net.cpp:1094] Copying source layer pool4 Type:Pooling #blobs=0
I0916 10:06:49.077688 18930 net.cpp:1094] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0916 10:06:49.078060 18930 net.cpp:1094] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0916 10:06:49.078188 18930 net.cpp:1094] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0916 10:06:49.078193 18930 net.cpp:1094] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0916 10:06:49.078366 18930 net.cpp:1094] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0916 10:06:49.078483 18930 net.cpp:1094] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0916 10:06:49.078488 18930 net.cpp:1078] Ignoring source layer pool5
I0916 10:06:49.078490 18930 net.cpp:1078] Ignoring source layer fc1000
I0916 10:06:49.078492 18930 net.cpp:1094] Copying source layer loss Type:SoftmaxWithLoss #blobs=0
I0916 10:06:49.078588 18930 parallel.cpp:106] [0 - 0] P2pSync adding callback
I0916 10:06:49.078591 18930 parallel.cpp:106] [1 - 1] P2pSync adding callback
I0916 10:06:49.078594 18930 parallel.cpp:106] [2 - 2] P2pSync adding callback
I0916 10:06:49.078596 18930 parallel.cpp:59] Starting Optimization
I0916 10:06:49.078598 18930 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 10:06:49.078634 18930 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 10:06:49.078644 18930 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 10:06:49.079377 19004 device_alternate.hpp:116] NVML initialized on thread 136158660445952
I0916 10:06:49.092145 19004 common.cpp:585] NVML succeeded to set CPU affinity on device 0
I0916 10:06:49.092190 19005 device_alternate.hpp:116] NVML initialized on thread 136158652053248
I0916 10:06:49.093406 19005 common.cpp:585] NVML succeeded to set CPU affinity on device 1
I0916 10:06:49.093420 19006 device_alternate.hpp:116] NVML initialized on thread 136158643660544
I0916 10:06:49.094027 19006 common.cpp:585] NVML succeeded to set CPU affinity on device 2
I0916 10:06:49.098145 19005 solver.cpp:43] Solver data type: FLOAT
W0916 10:06:49.098733 19005 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 16 to 18
I0916 10:06:49.098872 19005 net.cpp:104] Using FLOAT as default forward math type
I0916 10:06:49.098878 19005 net.cpp:110] Using FLOAT as default backward math type
I0916 10:06:49.098927 19005 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0916 10:06:49.098937 19005 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 10:06:49.102272 19006 solver.cpp:43] Solver data type: FLOAT
W0916 10:06:49.102798 19006 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 16 to 18
I0916 10:06:49.102910 19006 net.cpp:104] Using FLOAT as default forward math type
I0916 10:06:49.102916 19006 net.cpp:110] Using FLOAT as default backward math type
I0916 10:06:49.102946 19006 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0916 10:06:49.102947 19007 db_lmdb.cpp:24] Opened lmdb data/train-image-lmdb
I0916 10:06:49.102953 19006 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 10:06:49.105006 19008 db_lmdb.cpp:24] Opened lmdb data/train-image-lmdb
I0916 10:06:49.111145 19005 data_layer.cpp:187] [1] ReshapePrefetch 6, 3, 640, 640
I0916 10:06:49.111243 19005 data_layer.cpp:211] [1] Output data size: 6, 3, 640, 640
I0916 10:06:49.111250 19005 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 10:06:49.112555 19005 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0916 10:06:49.112576 19005 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 10:06:49.114231 19009 data_layer.cpp:101] [1] Parser threads: 1
I0916 10:06:49.114248 19009 data_layer.cpp:103] [1] Transformer threads: 1
I0916 10:06:49.115080 19006 data_layer.cpp:187] [2] ReshapePrefetch 6, 3, 640, 640
I0916 10:06:49.115151 19006 data_layer.cpp:211] [2] Output data size: 6, 3, 640, 640
I0916 10:06:49.115169 19006 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 10:06:49.116403 19006 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0916 10:06:49.116510 19006 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 10:06:49.125201 19010 db_lmdb.cpp:24] Opened lmdb data/train-label-lmdb
I0916 10:06:49.125845 19011 data_layer.cpp:101] [2] Parser threads: 1
I0916 10:06:49.125871 19011 data_layer.cpp:103] [2] Transformer threads: 1
I0916 10:06:49.135118 19012 db_lmdb.cpp:24] Opened lmdb data/train-label-lmdb
I0916 10:06:49.136018 19005 data_layer.cpp:187] [1] ReshapePrefetch 6, 1, 640, 640
I0916 10:06:49.136217 19005 data_layer.cpp:211] [1] Output data size: 6, 1, 640, 640
I0916 10:06:49.136237 19005 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 10:06:49.140316 19009 blocking_queue.cpp:40] Waiting for datum
I0916 10:06:49.140602 19006 data_layer.cpp:187] [2] ReshapePrefetch 6, 1, 640, 640
I0916 10:06:49.140651 19013 data_layer.cpp:101] [1] Parser threads: 1
I0916 10:06:49.140671 19013 data_layer.cpp:103] [1] Transformer threads: 1
I0916 10:06:49.145262 19006 data_layer.cpp:211] [2] Output data size: 6, 1, 640, 640
I0916 10:06:49.145452 19006 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 10:06:49.151114 19014 data_layer.cpp:101] [2] Parser threads: 1
I0916 10:06:49.151175 19014 data_layer.cpp:103] [2] Transformer threads: 1
I0916 10:06:49.880314 19005 solver.cpp:177] Creating test net (#0) specified by test_net file: training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/test.prototxt
W0916 10:06:49.880384 19005 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 4 to 6
I0916 10:06:49.880518 19005 net.cpp:104] Using FLOAT as default forward math type
I0916 10:06:49.880523 19005 net.cpp:110] Using FLOAT as default backward math type
I0916 10:06:49.880545 19005 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 2
I0916 10:06:49.880551 19005 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 10:06:49.881314 19015 db_lmdb.cpp:24] Opened lmdb data/val-image-lmdb
I0916 10:06:49.883237 19006 solver.cpp:177] Creating test net (#0) specified by test_net file: training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/test.prototxt
W0916 10:06:49.883303 19006 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 4 to 6
I0916 10:06:49.883416 19006 net.cpp:104] Using FLOAT as default forward math type
I0916 10:06:49.883421 19006 net.cpp:110] Using FLOAT as default backward math type
I0916 10:06:49.883447 19006 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 2
I0916 10:06:49.883452 19006 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 10:06:49.885805 19016 db_lmdb.cpp:24] Opened lmdb data/val-image-lmdb
I0916 10:06:49.887063 19005 data_layer.cpp:187] (1) ReshapePrefetch 2, 3, 640, 640
I0916 10:06:49.887116 19005 data_layer.cpp:211] (1) Output data size: 2, 3, 640, 640
I0916 10:06:49.887122 19005 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 10:06:49.889583 19005 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 2
I0916 10:06:49.889595 19005 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 10:06:49.892318 19017 data_layer.cpp:101] (1) Parser threads: 1
I0916 10:06:49.892333 19017 data_layer.cpp:103] (1) Transformer threads: 1
I0916 10:06:49.895036 19018 db_lmdb.cpp:24] Opened lmdb data/val-label-lmdb
I0916 10:06:49.902819 19006 data_layer.cpp:187] (2) ReshapePrefetch 2, 3, 640, 640
I0916 10:06:49.902886 19005 data_layer.cpp:187] (1) ReshapePrefetch 2, 1, 640, 640
I0916 10:06:49.905489 19005 data_layer.cpp:211] (1) Output data size: 2, 1, 640, 640
I0916 10:06:49.905524 19005 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 10:06:49.906291 19006 data_layer.cpp:211] (2) Output data size: 2, 3, 640, 640
I0916 10:06:49.906316 19006 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 10:06:49.910811 19006 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 2
I0916 10:06:49.910866 19006 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 10:06:49.918215 19021 data_layer.cpp:101] (1) Parser threads: 1
I0916 10:06:49.918243 19021 data_layer.cpp:103] (1) Transformer threads: 1
I0916 10:06:49.919278 19024 data_layer.cpp:101] (2) Parser threads: 1
I0916 10:06:49.919291 19024 data_layer.cpp:103] (2) Transformer threads: 1
I0916 10:06:49.923418 19029 db_lmdb.cpp:24] Opened lmdb data/val-label-lmdb
I0916 10:06:49.929314 19006 data_layer.cpp:187] (2) ReshapePrefetch 2, 1, 640, 640
I0916 10:06:49.929455 19006 data_layer.cpp:211] (2) Output data size: 2, 1, 640, 640
I0916 10:06:49.929468 19006 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 10:06:49.932219 19032 data_layer.cpp:101] (2) Parser threads: 1
I0916 10:06:49.932471 19032 data_layer.cpp:103] (2) Transformer threads: 1
I0916 10:06:50.024683 19005 solver.cpp:57] Solver scaffolding done.
I0916 10:06:50.028921 19006 solver.cpp:57] Solver scaffolding done.
I0916 10:06:50.067448 19005 parallel.cpp:161] [1 - 1] P2pSync adding callback
I0916 10:06:50.067448 19004 parallel.cpp:161] [0 - 0] P2pSync adding callback
I0916 10:06:50.067474 19006 parallel.cpp:161] [2 - 2] P2pSync adding callback
I0916 10:06:50.273857 19006 solver.cpp:490] Solving jsegnet21v2_train
I0916 10:06:50.273874 19006 solver.cpp:491] Learning Rate Policy: multistep
I0916 10:06:50.273885 19005 solver.cpp:490] Solving jsegnet21v2_train
I0916 10:06:50.273885 19004 solver.cpp:490] Solving jsegnet21v2_train
I0916 10:06:50.273895 19005 solver.cpp:491] Learning Rate Policy: multistep
I0916 10:06:50.273900 19004 solver.cpp:491] Learning Rate Policy: multistep
I0916 10:06:50.283504 19006 net.cpp:1412] [2] Reserving 10800128 bytes of shared learnable space
I0916 10:06:50.285066 19005 net.cpp:1412] [1] Reserving 10800128 bytes of shared learnable space
I0916 10:06:50.286216 19004 net.cpp:1412] [0] Reserving 10800128 bytes of shared learnable space
I0916 10:06:50.291242 19005 solver.cpp:228] Starting Optimization on GPU 1
I0916 10:06:50.291249 19006 solver.cpp:228] Starting Optimization on GPU 2
I0916 10:06:50.291280 19004 solver.cpp:228] Starting Optimization on GPU 0
I0916 10:06:50.291321 19033 device_alternate.hpp:116] NVML initialized on thread 128158492186368
I0916 10:06:50.291322 19004 solver.cpp:563] Iteration 0, Testing net (#0)
I0916 10:06:50.291340 19033 common.cpp:585] NVML succeeded to set CPU affinity on device 1
I0916 10:06:50.291353 19034 device_alternate.hpp:116] NVML initialized on thread 128158483793664
I0916 10:06:50.291368 19034 common.cpp:585] NVML succeeded to set CPU affinity on device 2
I0916 10:06:50.291384 19035 device_alternate.hpp:116] NVML initialized on thread 128158475400960
I0916 10:06:50.291399 19035 common.cpp:585] NVML succeeded to set CPU affinity on device 0
I0916 10:06:50.567972 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.181719
I0916 10:06:50.567992 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.730726
I0916 10:06:50.568001 19004 solver.cpp:655]     Test net output #2: loss = 71.4659 (* 1 = 71.4659 loss)
I0916 10:06:50.568014 19004 solver.cpp:255] [MultiGPU] Initial Test completed
I0916 10:06:51.015485 19004 solver.cpp:319] Iteration 0 (0.447424 s), loss = 2.12776
I0916 10:06:51.015508 19004 solver.cpp:336]     Train net output #0: loss = 2.12776 (* 1 = 2.12776 loss)
I0916 10:06:51.015514 19004 sgd_solver.cpp:136] Iteration 0, lr = 0.01, m = 0.9
I0916 10:06:51.215873 19004 solver.cpp:319] Iteration 1 (0.200378 s), loss = 2.04528
I0916 10:06:51.215899 19004 solver.cpp:336]     Train net output #0: loss = 2.04528 (* 1 = 2.04528 loss)
I0916 10:06:51.368119 19005 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'conv1a' with space 4.24G 3/1 1 0 3 	(avail 0.14G, req 0G)	t: 0 2.95 2.54
I0916 10:06:51.372247 19004 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'conv1a' with space 4.24G 3/1 1 0 3 	(avail 0.07G, req 0G)	t: 0 2.82 2.54
I0916 10:06:51.401208 19006 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'conv1a' with space 4.24G 3/1 1 0 3 	(avail 0.14G, req 0G)	t: 0 2.95 2.54
I0916 10:06:51.502979 19004 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'conv1b' with space 4.24G 32/4 6 4 3 	(avail 0.07G, req 0G)	t: 0 0.59 1.25
I0916 10:06:51.505247 19005 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'conv1b' with space 4.24G 32/4 6 4 3 	(avail 0.14G, req 0G)	t: 0 0.63 1.31
I0916 10:06:51.511931 19006 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'conv1b' with space 4.24G 32/4 6 4 3 	(avail 0.14G, req 0G)	t: 0 0.62 1.3
I0916 10:06:51.756141 19005 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 4.24G 32/1 6 4 3 	(avail 0.14G, req 0G)	t: 0 0.75 1.51
I0916 10:06:51.762109 19006 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 4.24G 32/1 6 4 3 	(avail 0.14G, req 0G)	t: 0 0.74 1.5
I0916 10:06:51.794508 19004 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 4.24G 32/1 6 4 3 	(avail 0.07G, req 0G)	t: 0 0.77 1.46
I0916 10:06:51.862630 19005 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 4.24G 64/4 6 4 3 	(avail 0.14G, req 0G)	t: 0 0.27 0.66
I0916 10:06:51.865087 19006 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 4.24G 64/4 6 4 3 	(avail 0.14G, req 0G)	t: 0 0.27 0.64
I0916 10:06:51.876044 19004 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 4.24G 64/4 6 4 3 	(avail 0.07G, req 0G)	t: 0 0.28 0.64
I0916 10:06:52.052821 19005 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 4.24G 64/1 6 4 5 	(avail 0.14G, req 0.07G)	t: 0 0.45 0.93
I0916 10:06:52.055778 19006 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 4.24G 64/1 6 4 5 	(avail 0.14G, req 0.07G)	t: 0 0.45 0.94
I0916 10:06:52.105294 19005 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 4.24G 128/4 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.14 0.28
I0916 10:06:52.105859 19006 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 4.24G 128/4 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.13 0.28
I0916 10:06:52.149813 19004 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 4.24G 64/1 6 4 5 	(avail 0.07G, req 0.07G)	t: 0 0.45 0.91
I0916 10:06:52.197652 19004 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 4.24G 128/4 6 4 3 	(avail 0.07G, req 0.07G)	t: 0 0.14 0.29
I0916 10:06:52.243486 19005 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 4.24G 128/1 6 4 5 	(avail 0.14G, req 0.07G)	t: 0 0.47 0.55
I0916 10:06:52.245466 19006 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 4.24G 128/1 6 4 5 	(avail 0.14G, req 0.07G)	t: 0 0.46 0.55
I0916 10:06:52.274009 19005 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 4.24G 256/4 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.1 0.19
I0916 10:06:52.275755 19006 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 4.24G 256/4 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.1 0.19
I0916 10:06:52.338454 19004 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 4.24G 128/1 6 4 5 	(avail 0.07G, req 0.07G)	t: 0 0.44 0.54
I0916 10:06:52.371414 19004 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 4.24G 256/4 6 4 3 	(avail 0.07G, req 0.07G)	t: 0 0.1 0.19
I0916 10:06:52.375733 19005 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'out3a' with space 4.24G 128/2 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.22 0.41
I0916 10:06:52.376730 19006 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'out3a' with space 4.24G 128/2 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.22 0.41
I0916 10:06:52.471369 19004 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'out3a' with space 4.24G 128/2 6 4 3 	(avail 0.07G, req 0.07G)	t: 0 0.21 0.4
I0916 10:06:52.488184 19005 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_conv1' with space 4.24G 64/1 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.29 0.62
I0916 10:06:52.489168 19006 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'ctx_conv1' with space 4.24G 64/1 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.29 0.62
I0916 10:06:52.546708 19005 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_final' with space 4.24G 64/1 6 1 5 	(avail 0.14G, req 0.07G)	t: 0 0.11 0.36
I0916 10:06:52.549265 19006 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'ctx_final' with space 4.24G 64/1 6 1 5 	(avail 0.14G, req 0.07G)	t: 0 0.11 0.35
I0916 10:06:52.589714 19004 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_conv1' with space 4.24G 64/1 6 4 3 	(avail 0.07G, req 0.07G)	t: 0 0.29 0.6
I0916 10:06:52.647094 19004 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_final' with space 4.24G 64/1 6 1 5 	(avail 0.07G, req 0.07G)	t: 0 0.11 0.35
I0916 10:06:52.767194 19004 solver.cpp:319] Iteration 2 (1.55127 s), loss = 1.99246
I0916 10:06:52.767220 19004 solver.cpp:336]     Train net output #0: loss = 1.99246 (* 1 = 1.99246 loss)
I0916 10:06:52.767863 19006 cudnn_conv_layer.cpp:474] [2] Layer 'conv1a' reallocating workspace 4.24G to 0.14G
I0916 10:06:52.776067 19004 cudnn_conv_layer.cpp:474] [0] Layer 'conv1a' reallocating workspace 4.24G to 0.14G
I0916 10:06:52.806574 19005 cudnn_conv_layer.cpp:474] [1] Layer 'conv1a' reallocating workspace 4.24G to 0.14G
I0916 10:07:11.057986 19004 solver.cpp:314] Iteration 100 (5.35804 iter/s, 18.2903s/98 iter), loss = 0.289444
I0916 10:07:11.058008 19004 solver.cpp:336]     Train net output #0: loss = 0.289444 (* 1 = 0.289444 loss)
I0916 10:07:11.058013 19004 sgd_solver.cpp:136] Iteration 100, lr = 0.01, m = 0.9
I0916 10:07:22.690702 19012 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 10:07:29.678715 19004 solver.cpp:314] Iteration 200 (5.37051 iter/s, 18.6202s/100 iter), loss = 0.388922
I0916 10:07:29.678740 19004 solver.cpp:336]     Train net output #0: loss = 0.388921 (* 1 = 0.388921 loss)
I0916 10:07:29.678746 19004 sgd_solver.cpp:136] Iteration 200, lr = 0.01, m = 0.9
I0916 10:07:48.786584 19004 solver.cpp:314] Iteration 300 (5.2336 iter/s, 19.1073s/100 iter), loss = 0.245527
I0916 10:07:48.786609 19004 solver.cpp:336]     Train net output #0: loss = 0.245527 (* 1 = 0.245527 loss)
I0916 10:07:48.786615 19004 sgd_solver.cpp:136] Iteration 300, lr = 0.01, m = 0.9
I0916 10:07:54.020880 18961 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 10:08:08.127687 19004 solver.cpp:314] Iteration 400 (5.17049 iter/s, 19.3405s/100 iter), loss = 0.327938
I0916 10:08:08.127709 19004 solver.cpp:336]     Train net output #0: loss = 0.327938 (* 1 = 0.327938 loss)
I0916 10:08:08.127714 19004 sgd_solver.cpp:136] Iteration 400, lr = 0.01, m = 0.9
I0916 10:08:27.365489 19004 solver.cpp:314] Iteration 500 (5.19825 iter/s, 19.2372s/100 iter), loss = 0.197279
I0916 10:08:27.365540 19004 solver.cpp:336]     Train net output #0: loss = 0.197279 (* 1 = 0.197279 loss)
I0916 10:08:27.365546 19004 sgd_solver.cpp:136] Iteration 500, lr = 0.01, m = 0.9
I0916 10:08:46.457110 19004 solver.cpp:314] Iteration 600 (5.23805 iter/s, 19.0911s/100 iter), loss = 0.215715
I0916 10:08:46.457135 19004 solver.cpp:336]     Train net output #0: loss = 0.215715 (* 1 = 0.215715 loss)
I0916 10:08:46.457140 19004 sgd_solver.cpp:136] Iteration 600, lr = 0.01, m = 0.9
I0916 10:08:57.502929 19010 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 10:09:05.540066 19004 solver.cpp:314] Iteration 700 (5.24043 iter/s, 19.0824s/100 iter), loss = 0.302964
I0916 10:09:05.540091 19004 solver.cpp:336]     Train net output #0: loss = 0.302964 (* 1 = 0.302964 loss)
I0916 10:09:05.540096 19004 sgd_solver.cpp:136] Iteration 700, lr = 0.01, m = 0.9
I0916 10:09:24.678333 19004 solver.cpp:314] Iteration 800 (5.22529 iter/s, 19.1377s/100 iter), loss = 0.29125
I0916 10:09:24.678361 19004 solver.cpp:336]     Train net output #0: loss = 0.29125 (* 1 = 0.29125 loss)
I0916 10:09:24.678369 19004 sgd_solver.cpp:136] Iteration 800, lr = 0.01, m = 0.9
I0916 10:09:43.990962 19004 solver.cpp:314] Iteration 900 (5.17811 iter/s, 19.3121s/100 iter), loss = 0.176526
I0916 10:09:43.991014 19004 solver.cpp:336]     Train net output #0: loss = 0.176526 (* 1 = 0.176526 loss)
I0916 10:09:43.991019 19004 sgd_solver.cpp:136] Iteration 900, lr = 0.01, m = 0.9
I0916 10:10:01.196851 19010 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 10:10:01.196851 18963 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 10:10:03.554080 19004 solver.cpp:314] Iteration 1000 (5.11181 iter/s, 19.5626s/100 iter), loss = 0.19195
I0916 10:10:03.554105 19004 solver.cpp:336]     Train net output #0: loss = 0.19195 (* 1 = 0.19195 loss)
I0916 10:10:03.554108 19004 sgd_solver.cpp:136] Iteration 1000, lr = 0.01, m = 0.9
I0916 10:10:23.064409 19004 solver.cpp:314] Iteration 1100 (5.12564 iter/s, 19.5098s/100 iter), loss = 0.141489
I0916 10:10:23.064491 19004 solver.cpp:336]     Train net output #0: loss = 0.141488 (* 1 = 0.141488 loss)
I0916 10:10:23.064497 19004 sgd_solver.cpp:136] Iteration 1100, lr = 0.01, m = 0.9
I0916 10:10:42.337908 19004 solver.cpp:314] Iteration 1200 (5.18862 iter/s, 19.2729s/100 iter), loss = 0.215626
I0916 10:10:42.337934 19004 solver.cpp:336]     Train net output #0: loss = 0.215626 (* 1 = 0.215626 loss)
I0916 10:10:42.337939 19004 sgd_solver.cpp:136] Iteration 1200, lr = 0.01, m = 0.9
I0916 10:11:01.891742 19004 solver.cpp:314] Iteration 1300 (5.11423 iter/s, 19.5533s/100 iter), loss = 0.273704
I0916 10:11:01.891808 19004 solver.cpp:336]     Train net output #0: loss = 0.273703 (* 1 = 0.273703 loss)
I0916 10:11:01.891815 19004 sgd_solver.cpp:136] Iteration 1300, lr = 0.01, m = 0.9
I0916 10:11:05.639230 18963 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 10:11:21.344800 19004 solver.cpp:314] Iteration 1400 (5.14073 iter/s, 19.4525s/100 iter), loss = 0.232079
I0916 10:11:21.344825 19004 solver.cpp:336]     Train net output #0: loss = 0.232078 (* 1 = 0.232078 loss)
I0916 10:11:21.344828 19004 sgd_solver.cpp:136] Iteration 1400, lr = 0.01, m = 0.9
I0916 10:11:37.715776 19007 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 10:11:40.724902 19004 solver.cpp:314] Iteration 1500 (5.16008 iter/s, 19.3796s/100 iter), loss = 0.277154
I0916 10:11:40.724930 19004 solver.cpp:336]     Train net output #0: loss = 0.277153 (* 1 = 0.277153 loss)
I0916 10:11:40.724934 19004 sgd_solver.cpp:136] Iteration 1500, lr = 0.01, m = 0.9
I0916 10:12:00.019055 19004 solver.cpp:314] Iteration 1600 (5.18306 iter/s, 19.2936s/100 iter), loss = 0.171179
I0916 10:12:00.019080 19004 solver.cpp:336]     Train net output #0: loss = 0.171179 (* 1 = 0.171179 loss)
I0916 10:12:00.019084 19004 sgd_solver.cpp:136] Iteration 1600, lr = 0.01, m = 0.9
I0916 10:12:19.369978 19004 solver.cpp:314] Iteration 1700 (5.16786 iter/s, 19.3504s/100 iter), loss = 0.208718
I0916 10:12:19.370025 19004 solver.cpp:336]     Train net output #0: loss = 0.208718 (* 1 = 0.208718 loss)
I0916 10:12:19.370033 19004 sgd_solver.cpp:136] Iteration 1700, lr = 0.01, m = 0.9
I0916 10:12:38.694983 19004 solver.cpp:314] Iteration 1800 (5.17479 iter/s, 19.3245s/100 iter), loss = 0.14887
I0916 10:12:38.695008 19004 solver.cpp:336]     Train net output #0: loss = 0.14887 (* 1 = 0.14887 loss)
I0916 10:12:38.695013 19004 sgd_solver.cpp:136] Iteration 1800, lr = 0.01, m = 0.9
I0916 10:12:41.556424 19007 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 10:12:58.138052 19004 solver.cpp:314] Iteration 1900 (5.14336 iter/s, 19.4425s/100 iter), loss = 0.140668
I0916 10:12:58.138137 19004 solver.cpp:336]     Train net output #0: loss = 0.140667 (* 1 = 0.140667 loss)
I0916 10:12:58.138144 19004 sgd_solver.cpp:136] Iteration 1900, lr = 0.01, m = 0.9
I0916 10:13:17.370896 19004 solver.cpp:563] Iteration 2000, Testing net (#0)
I0916 10:13:17.462136 19004 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1a' with space 0.14G 3/1 1 	(avail 4.17G, req 0G)	t: 0
I0916 10:13:17.470363 19005 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'conv1a' with space 0.14G 3/1 1 	(avail 4.24G, req 0G)	t: 0
I0916 10:13:17.477604 19006 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'conv1a' with space 0.14G 3/1 1 	(avail 4.24G, req 0G)	t: 0
I0916 10:13:17.489717 19004 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1b' with space 0.14G 32/4 6 	(avail 4.17G, req 0G)	t: 0
I0916 10:13:17.500843 19005 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'conv1b' with space 0.14G 32/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 10:13:17.508529 19006 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'conv1b' with space 0.14G 32/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 10:13:17.512399 19004 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2a' with space 0.14G 32/1 6 	(avail 4.17G, req 0G)	t: 0
I0916 10:13:17.517345 19005 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res2a_branch2a' with space 0.14G 32/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 10:13:17.523434 19004 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2b' with space 0.14G 64/4 6 	(avail 4.17G, req 0G)	t: 0
I0916 10:13:17.525215 19006 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'res2a_branch2a' with space 0.14G 32/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 10:13:17.529361 19005 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res2a_branch2b' with space 0.14G 64/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 10:13:17.536519 19004 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2a' with space 0.14G 64/1 6 	(avail 4.17G, req 0G)	t: 0
I0916 10:13:17.537431 19006 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'res2a_branch2b' with space 0.14G 64/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 10:13:17.541909 19005 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res3a_branch2a' with space 0.14G 64/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 10:13:17.543239 19004 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2b' with space 0.14G 128/4 6 	(avail 4.17G, req 0G)	t: 0
I0916 10:13:17.549044 19005 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res3a_branch2b' with space 0.14G 128/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 10:13:17.549422 19006 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'res3a_branch2a' with space 0.14G 64/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 10:13:17.551576 19004 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2a' with space 0.14G 128/1 6 	(avail 4.17G, req 0G)	t: 0
I0916 10:13:17.557575 19004 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2b' with space 0.14G 256/4 6 	(avail 4.17G, req 0G)	t: 0
I0916 10:13:17.557705 19006 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'res3a_branch2b' with space 0.14G 128/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 10:13:17.559705 19005 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res4a_branch2a' with space 0.14G 128/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 10:13:17.564213 19005 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res4a_branch2b' with space 0.14G 256/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 10:13:17.566514 19006 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'res4a_branch2a' with space 0.14G 128/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 10:13:17.569977 19004 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'out3a' with space 0.14G 128/2 6 	(avail 4.17G, req 0G)	t: 0
I0916 10:13:17.571269 19006 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'res4a_branch2b' with space 0.14G 256/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 10:13:17.579480 19004 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_conv1' with space 0.14G 64/1 6 	(avail 4.17G, req 0G)	t: 0
I0916 10:13:17.580237 19005 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'out3a' with space 0.14G 128/2 6 	(avail 4.24G, req 0G)	t: 0
I0916 10:13:17.584810 19006 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'out3a' with space 0.14G 128/2 6 	(avail 4.24G, req 0G)	t: 0
I0916 10:13:17.590286 19005 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_conv1' with space 0.14G 64/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 10:13:17.592833 19004 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_final' with space 0.14G 64/1 6 	(avail 4.17G, req 0G)	t: 0
I0916 10:13:17.595661 19006 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'ctx_conv1' with space 0.14G 64/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 10:13:17.604923 19005 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_final' with space 0.14G 64/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 10:13:17.610608 19006 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'ctx_final' with space 0.14G 64/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 10:13:24.292873 19018 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 10:13:28.594370 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.937523
I0916 10:13:28.594444 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.999992
I0916 10:13:28.594451 19004 solver.cpp:655]     Test net output #2: loss = 0.185447 (* 1 = 0.185447 loss)
I0916 10:13:28.594475 19004 solver.cpp:265] [MultiGPU] Tests completed in 11.2233s
I0916 10:13:28.813843 19004 solver.cpp:314] Iteration 2000 (3.25999 iter/s, 30.6749s/100 iter), loss = 0.247975
I0916 10:13:28.813865 19004 solver.cpp:336]     Train net output #0: loss = 0.247974 (* 1 = 0.247974 loss)
I0916 10:13:28.813869 19004 sgd_solver.cpp:136] Iteration 2000, lr = 0.01, m = 0.9
I0916 10:13:48.075666 19004 solver.cpp:314] Iteration 2100 (5.19176 iter/s, 19.2613s/100 iter), loss = 0.123469
I0916 10:13:48.075690 19004 solver.cpp:336]     Train net output #0: loss = 0.123468 (* 1 = 0.123468 loss)
I0916 10:13:48.075695 19004 sgd_solver.cpp:136] Iteration 2100, lr = 0.01, m = 0.9
I0916 10:13:56.700929 19008 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 10:14:07.374948 19004 solver.cpp:314] Iteration 2200 (5.18168 iter/s, 19.2987s/100 iter), loss = 0.310262
I0916 10:14:07.375017 19004 solver.cpp:336]     Train net output #0: loss = 0.310262 (* 1 = 0.310262 loss)
I0916 10:14:07.375025 19004 sgd_solver.cpp:136] Iteration 2200, lr = 0.01, m = 0.9
I0916 10:14:27.086130 19004 solver.cpp:314] Iteration 2300 (5.0734 iter/s, 19.7106s/100 iter), loss = 0.125355
I0916 10:14:27.086161 19004 solver.cpp:336]     Train net output #0: loss = 0.125355 (* 1 = 0.125355 loss)
I0916 10:14:27.086168 19004 sgd_solver.cpp:136] Iteration 2300, lr = 0.01, m = 0.9
I0916 10:14:46.400466 19004 solver.cpp:314] Iteration 2400 (5.17764 iter/s, 19.3138s/100 iter), loss = 0.12001
I0916 10:14:46.400528 19004 solver.cpp:336]     Train net output #0: loss = 0.12001 (* 1 = 0.12001 loss)
I0916 10:14:46.400534 19004 sgd_solver.cpp:136] Iteration 2400, lr = 0.01, m = 0.9
I0916 10:15:01.373587 18961 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 10:15:06.071655 19004 solver.cpp:314] Iteration 2500 (5.08372 iter/s, 19.6706s/100 iter), loss = 0.177845
I0916 10:15:06.071679 19004 solver.cpp:336]     Train net output #0: loss = 0.177845 (* 1 = 0.177845 loss)
I0916 10:15:06.071683 19004 sgd_solver.cpp:136] Iteration 2500, lr = 0.01, m = 0.9
I0916 10:15:25.526406 19004 solver.cpp:314] Iteration 2600 (5.14028 iter/s, 19.4542s/100 iter), loss = 0.126781
I0916 10:15:25.526468 19004 solver.cpp:336]     Train net output #0: loss = 0.12678 (* 1 = 0.12678 loss)
I0916 10:15:25.526475 19004 sgd_solver.cpp:136] Iteration 2600, lr = 0.01, m = 0.9
I0916 10:15:44.880638 19004 solver.cpp:314] Iteration 2700 (5.16697 iter/s, 19.3537s/100 iter), loss = 0.121291
I0916 10:15:44.880666 19004 solver.cpp:336]     Train net output #0: loss = 0.121291 (* 1 = 0.121291 loss)
I0916 10:15:44.880671 19004 sgd_solver.cpp:136] Iteration 2700, lr = 0.01, m = 0.9
I0916 10:16:04.311975 19004 solver.cpp:314] Iteration 2800 (5.14647 iter/s, 19.4308s/100 iter), loss = 0.119292
I0916 10:16:04.312068 19004 solver.cpp:336]     Train net output #0: loss = 0.119292 (* 1 = 0.119292 loss)
I0916 10:16:04.312075 19004 sgd_solver.cpp:136] Iteration 2800, lr = 0.01, m = 0.9
I0916 10:16:05.489421 19010 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 10:16:23.679126 19004 solver.cpp:314] Iteration 2900 (5.16352 iter/s, 19.3666s/100 iter), loss = 0.146839
I0916 10:16:23.679147 19004 solver.cpp:336]     Train net output #0: loss = 0.146838 (* 1 = 0.146838 loss)
I0916 10:16:23.679152 19004 sgd_solver.cpp:136] Iteration 2900, lr = 0.01, m = 0.9
I0916 10:16:37.492621 19007 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 10:16:43.160730 19004 solver.cpp:314] Iteration 3000 (5.13319 iter/s, 19.4811s/100 iter), loss = 0.145995
I0916 10:16:43.160758 19004 solver.cpp:336]     Train net output #0: loss = 0.145994 (* 1 = 0.145994 loss)
I0916 10:16:43.160765 19004 sgd_solver.cpp:136] Iteration 3000, lr = 0.01, m = 0.9
I0916 10:17:02.383920 19004 solver.cpp:314] Iteration 3100 (5.20219 iter/s, 19.2227s/100 iter), loss = 0.10653
I0916 10:17:02.383946 19004 solver.cpp:336]     Train net output #0: loss = 0.10653 (* 1 = 0.10653 loss)
I0916 10:17:02.383952 19004 sgd_solver.cpp:136] Iteration 3100, lr = 0.01, m = 0.9
I0916 10:17:22.053450 19004 solver.cpp:314] Iteration 3200 (5.08415 iter/s, 19.669s/100 iter), loss = 0.282771
I0916 10:17:22.053504 19004 solver.cpp:336]     Train net output #0: loss = 0.28277 (* 1 = 0.28277 loss)
I0916 10:17:22.053511 19004 sgd_solver.cpp:136] Iteration 3200, lr = 0.01, m = 0.9
I0916 10:17:41.604997 19004 solver.cpp:314] Iteration 3300 (5.11483 iter/s, 19.551s/100 iter), loss = 0.141267
I0916 10:17:41.605021 19004 solver.cpp:336]     Train net output #0: loss = 0.141267 (* 1 = 0.141267 loss)
I0916 10:17:41.605026 19004 sgd_solver.cpp:136] Iteration 3300, lr = 0.01, m = 0.9
I0916 10:17:41.991045 18963 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 10:18:01.081535 19004 solver.cpp:314] Iteration 3400 (5.13452 iter/s, 19.476s/100 iter), loss = 0.096726
I0916 10:18:01.081601 19004 solver.cpp:336]     Train net output #0: loss = 0.0967258 (* 1 = 0.0967258 loss)
I0916 10:18:01.081606 19004 sgd_solver.cpp:136] Iteration 3400, lr = 0.01, m = 0.9
I0916 10:18:20.572878 19004 solver.cpp:314] Iteration 3500 (5.13062 iter/s, 19.4908s/100 iter), loss = 0.206479
I0916 10:18:20.572903 19004 solver.cpp:336]     Train net output #0: loss = 0.206479 (* 1 = 0.206479 loss)
I0916 10:18:20.572909 19004 sgd_solver.cpp:136] Iteration 3500, lr = 0.01, m = 0.9
I0916 10:18:40.043316 19004 solver.cpp:314] Iteration 3600 (5.13613 iter/s, 19.4699s/100 iter), loss = 0.159635
I0916 10:18:40.043362 19004 solver.cpp:336]     Train net output #0: loss = 0.159634 (* 1 = 0.159634 loss)
I0916 10:18:40.043367 19004 sgd_solver.cpp:136] Iteration 3600, lr = 0.01, m = 0.9
I0916 10:18:46.357854 18961 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 10:18:59.683560 19004 solver.cpp:314] Iteration 3700 (5.09173 iter/s, 19.6397s/100 iter), loss = 0.153922
I0916 10:18:59.683588 19004 solver.cpp:336]     Train net output #0: loss = 0.153922 (* 1 = 0.153922 loss)
I0916 10:18:59.683594 19004 sgd_solver.cpp:136] Iteration 3700, lr = 0.01, m = 0.9
I0916 10:19:19.067662 18961 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 10:19:19.424916 19004 solver.cpp:314] Iteration 3800 (5.06565 iter/s, 19.7408s/100 iter), loss = 0.231483
I0916 10:19:19.424940 19004 solver.cpp:336]     Train net output #0: loss = 0.231482 (* 1 = 0.231482 loss)
I0916 10:19:19.424947 19004 sgd_solver.cpp:136] Iteration 3800, lr = 0.01, m = 0.9
I0916 10:19:38.683727 19004 solver.cpp:314] Iteration 3900 (5.19257 iter/s, 19.2583s/100 iter), loss = 0.135928
I0916 10:19:38.683755 19004 solver.cpp:336]     Train net output #0: loss = 0.135927 (* 1 = 0.135927 loss)
I0916 10:19:38.683761 19004 sgd_solver.cpp:136] Iteration 3900, lr = 0.01, m = 0.9
I0916 10:19:57.942519 19004 solver.cpp:563] Iteration 4000, Testing net (#0)
I0916 10:19:58.109784 19005 blocking_queue.cpp:40] Data layer prefetch queue empty
I0916 10:20:05.136559 19029 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 10:20:22.064795 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.933791
I0916 10:20:22.064815 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.999995
I0916 10:20:22.064821 19004 solver.cpp:655]     Test net output #2: loss = 0.18751 (* 1 = 0.18751 loss)
I0916 10:20:22.064846 19004 solver.cpp:265] [MultiGPU] Tests completed in 24.1217s
I0916 10:20:22.270380 19004 solver.cpp:314] Iteration 4000 (2.29434 iter/s, 43.5855s/100 iter), loss = 0.0910005
I0916 10:20:22.270431 19004 solver.cpp:336]     Train net output #0: loss = 0.0910002 (* 1 = 0.0910002 loss)
I0916 10:20:22.270445 19004 sgd_solver.cpp:136] Iteration 4000, lr = 0.01, m = 0.9
I0916 10:20:41.108351 19004 solver.cpp:314] Iteration 4100 (5.30858 iter/s, 18.8374s/100 iter), loss = 0.175866
I0916 10:20:41.108404 19004 solver.cpp:336]     Train net output #0: loss = 0.175866 (* 1 = 0.175866 loss)
I0916 10:20:41.108409 19004 sgd_solver.cpp:136] Iteration 4100, lr = 0.01, m = 0.9
I0916 10:20:46.528496 18961 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 10:21:00.250525 19004 solver.cpp:314] Iteration 4200 (5.22421 iter/s, 19.1416s/100 iter), loss = 0.213297
I0916 10:21:00.250552 19004 solver.cpp:336]     Train net output #0: loss = 0.213297 (* 1 = 0.213297 loss)
I0916 10:21:00.250558 19004 sgd_solver.cpp:136] Iteration 4200, lr = 0.01, m = 0.9
I0916 10:21:19.712563 19004 solver.cpp:314] Iteration 4300 (5.13835 iter/s, 19.4615s/100 iter), loss = 0.15761
I0916 10:21:19.712671 19004 solver.cpp:336]     Train net output #0: loss = 0.15761 (* 1 = 0.15761 loss)
I0916 10:21:19.712678 19004 sgd_solver.cpp:136] Iteration 4300, lr = 0.01, m = 0.9
I0916 10:21:39.173398 19004 solver.cpp:314] Iteration 4400 (5.13867 iter/s, 19.4603s/100 iter), loss = 0.117852
I0916 10:21:39.173421 19004 solver.cpp:336]     Train net output #0: loss = 0.117851 (* 1 = 0.117851 loss)
I0916 10:21:39.173425 19004 sgd_solver.cpp:136] Iteration 4400, lr = 0.01, m = 0.9
I0916 10:21:50.487035 18963 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 10:21:58.337565 19004 solver.cpp:314] Iteration 4500 (5.21822 iter/s, 19.1636s/100 iter), loss = 0.0869218
I0916 10:21:58.337594 19004 solver.cpp:336]     Train net output #0: loss = 0.0869216 (* 1 = 0.0869216 loss)
I0916 10:21:58.337600 19004 sgd_solver.cpp:136] Iteration 4500, lr = 0.01, m = 0.9
I0916 10:22:17.717284 19004 solver.cpp:314] Iteration 4600 (5.16018 iter/s, 19.3792s/100 iter), loss = 0.165092
I0916 10:22:17.717505 19004 solver.cpp:336]     Train net output #0: loss = 0.165091 (* 1 = 0.165091 loss)
I0916 10:22:17.718109 19004 sgd_solver.cpp:136] Iteration 4600, lr = 0.01, m = 0.9
I0916 10:22:41.169380 19004 solver.cpp:314] Iteration 4700 (4.26413 iter/s, 23.4515s/100 iter), loss = 0.138221
I0916 10:22:41.170140 19004 solver.cpp:336]     Train net output #0: loss = 0.13822 (* 1 = 0.13822 loss)
I0916 10:22:41.170148 19004 sgd_solver.cpp:136] Iteration 4700, lr = 0.01, m = 0.9
I0916 10:22:58.460564 19012 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 10:23:00.442682 19004 solver.cpp:314] Iteration 4800 (5.18867 iter/s, 19.2728s/100 iter), loss = 0.219692
I0916 10:23:00.442708 19004 solver.cpp:336]     Train net output #0: loss = 0.219692 (* 1 = 0.219692 loss)
I0916 10:23:00.442713 19004 sgd_solver.cpp:136] Iteration 4800, lr = 0.01, m = 0.9
I0916 10:23:19.726461 19004 solver.cpp:314] Iteration 4900 (5.18585 iter/s, 19.2833s/100 iter), loss = 0.140282
I0916 10:23:19.726568 19004 solver.cpp:336]     Train net output #0: loss = 0.140282 (* 1 = 0.140282 loss)
I0916 10:23:19.726575 19004 sgd_solver.cpp:136] Iteration 4900, lr = 0.01, m = 0.9
I0916 10:23:39.313482 19004 solver.cpp:314] Iteration 5000 (5.10556 iter/s, 19.5865s/100 iter), loss = 0.166151
I0916 10:23:39.313504 19004 solver.cpp:336]     Train net output #0: loss = 0.166151 (* 1 = 0.166151 loss)
I0916 10:23:39.313510 19004 sgd_solver.cpp:136] Iteration 5000, lr = 0.01, m = 0.9
I0916 10:23:58.803629 19004 solver.cpp:314] Iteration 5100 (5.13094 iter/s, 19.4896s/100 iter), loss = 0.220764
I0916 10:23:58.803688 19004 solver.cpp:336]     Train net output #0: loss = 0.220764 (* 1 = 0.220764 loss)
I0916 10:23:58.803694 19004 sgd_solver.cpp:136] Iteration 5100, lr = 0.01, m = 0.9
I0916 10:24:02.703481 19012 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 10:24:18.078897 19004 solver.cpp:314] Iteration 5200 (5.18814 iter/s, 19.2747s/100 iter), loss = 0.17108
I0916 10:24:18.078918 19004 solver.cpp:336]     Train net output #0: loss = 0.171079 (* 1 = 0.171079 loss)
I0916 10:24:18.078922 19004 sgd_solver.cpp:136] Iteration 5200, lr = 0.01, m = 0.9
I0916 10:24:34.598649 19007 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 10:24:37.525774 19004 solver.cpp:314] Iteration 5300 (5.14235 iter/s, 19.4463s/100 iter), loss = 0.0913578
I0916 10:24:37.525799 19004 solver.cpp:336]     Train net output #0: loss = 0.0913576 (* 1 = 0.0913576 loss)
I0916 10:24:37.525805 19004 sgd_solver.cpp:136] Iteration 5300, lr = 0.01, m = 0.9
I0916 10:24:56.995651 19004 solver.cpp:314] Iteration 5400 (5.13628 iter/s, 19.4693s/100 iter), loss = 0.10526
I0916 10:24:56.995672 19004 solver.cpp:336]     Train net output #0: loss = 0.10526 (* 1 = 0.10526 loss)
I0916 10:24:56.995677 19004 sgd_solver.cpp:136] Iteration 5400, lr = 0.01, m = 0.9
I0916 10:25:16.307166 19004 solver.cpp:314] Iteration 5500 (5.1784 iter/s, 19.311s/100 iter), loss = 0.112826
I0916 10:25:16.309329 19004 solver.cpp:336]     Train net output #0: loss = 0.112826 (* 1 = 0.112826 loss)
I0916 10:25:16.309350 19004 sgd_solver.cpp:136] Iteration 5500, lr = 0.01, m = 0.9
I0916 10:25:35.614461 19004 solver.cpp:314] Iteration 5600 (5.17953 iter/s, 19.3068s/100 iter), loss = 0.0615553
I0916 10:25:35.614485 19004 solver.cpp:336]     Train net output #0: loss = 0.0615551 (* 1 = 0.0615551 loss)
I0916 10:25:35.614488 19004 sgd_solver.cpp:136] Iteration 5600, lr = 0.01, m = 0.9
I0916 10:25:38.819895 19010 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 10:25:55.308552 19004 solver.cpp:314] Iteration 5700 (5.0778 iter/s, 19.6936s/100 iter), loss = 0.414865
I0916 10:25:55.308612 19004 solver.cpp:336]     Train net output #0: loss = 0.414865 (* 1 = 0.414865 loss)
I0916 10:25:55.308617 19004 sgd_solver.cpp:136] Iteration 5700, lr = 0.01, m = 0.9
I0916 10:26:14.959331 19004 solver.cpp:314] Iteration 5800 (5.089 iter/s, 19.6502s/100 iter), loss = 0.10366
I0916 10:26:14.959360 19004 solver.cpp:336]     Train net output #0: loss = 0.10366 (* 1 = 0.10366 loss)
I0916 10:26:14.959367 19004 sgd_solver.cpp:136] Iteration 5800, lr = 0.01, m = 0.9
I0916 10:26:34.492940 19004 solver.cpp:314] Iteration 5900 (5.11952 iter/s, 19.5331s/100 iter), loss = 0.26441
I0916 10:26:34.493026 19004 solver.cpp:336]     Train net output #0: loss = 0.26441 (* 1 = 0.26441 loss)
I0916 10:26:34.493036 19004 sgd_solver.cpp:136] Iteration 5900, lr = 0.01, m = 0.9
I0916 10:26:43.512410 19012 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 10:26:53.856655 19004 solver.cpp:563] Iteration 6000, Testing net (#0)
I0916 10:27:10.336782 19000 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 10:27:10.336782 19016 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 10:27:19.404281 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.94108
I0916 10:27:19.404309 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.999999
I0916 10:27:19.404314 19004 solver.cpp:655]     Test net output #2: loss = 0.178422 (* 1 = 0.178422 loss)
I0916 10:27:19.404345 19004 solver.cpp:265] [MultiGPU] Tests completed in 25.547s
I0916 10:27:19.636611 19004 solver.cpp:314] Iteration 6000 (2.21521 iter/s, 45.1424s/100 iter), loss = 0.215596
I0916 10:27:19.636637 19004 solver.cpp:336]     Train net output #0: loss = 0.215596 (* 1 = 0.215596 loss)
I0916 10:27:19.636643 19004 sgd_solver.cpp:136] Iteration 6000, lr = 0.01, m = 0.9
I0916 10:27:38.789584 19004 solver.cpp:314] Iteration 6100 (5.22127 iter/s, 19.1524s/100 iter), loss = 0.140168
I0916 10:27:38.789610 19004 solver.cpp:336]     Train net output #0: loss = 0.140167 (* 1 = 0.140167 loss)
I0916 10:27:38.789614 19004 sgd_solver.cpp:136] Iteration 6100, lr = 0.01, m = 0.9
I0916 10:27:57.963683 19004 solver.cpp:314] Iteration 6200 (5.21551 iter/s, 19.1736s/100 iter), loss = 0.187785
I0916 10:27:57.963793 19004 solver.cpp:336]     Train net output #0: loss = 0.187785 (* 1 = 0.187785 loss)
I0916 10:27:57.963800 19004 sgd_solver.cpp:136] Iteration 6200, lr = 0.01, m = 0.9
I0916 10:28:12.794267 19007 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 10:28:17.205418 19004 solver.cpp:314] Iteration 6300 (5.19718 iter/s, 19.2412s/100 iter), loss = 0.127043
I0916 10:28:17.205442 19004 solver.cpp:336]     Train net output #0: loss = 0.127043 (* 1 = 0.127043 loss)
I0916 10:28:17.205447 19004 sgd_solver.cpp:136] Iteration 6300, lr = 0.01, m = 0.9
I0916 10:28:36.968446 19004 solver.cpp:314] Iteration 6400 (5.06009 iter/s, 19.7625s/100 iter), loss = 0.145277
I0916 10:28:36.968498 19004 solver.cpp:336]     Train net output #0: loss = 0.145277 (* 1 = 0.145277 loss)
I0916 10:28:36.968504 19004 sgd_solver.cpp:136] Iteration 6400, lr = 0.01, m = 0.9
I0916 10:28:56.618355 19004 solver.cpp:314] Iteration 6500 (5.08922 iter/s, 19.6494s/100 iter), loss = 0.141141
I0916 10:28:56.618377 19004 solver.cpp:336]     Train net output #0: loss = 0.14114 (* 1 = 0.14114 loss)
I0916 10:28:56.618382 19004 sgd_solver.cpp:136] Iteration 6500, lr = 0.01, m = 0.9
I0916 10:29:16.021823 19004 solver.cpp:314] Iteration 6600 (5.15386 iter/s, 19.4029s/100 iter), loss = 0.248243
I0916 10:29:16.021872 19004 solver.cpp:336]     Train net output #0: loss = 0.248243 (* 1 = 0.248243 loss)
I0916 10:29:16.021878 19004 sgd_solver.cpp:136] Iteration 6600, lr = 0.01, m = 0.9
I0916 10:29:17.595947 19012 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 10:29:35.719338 19004 solver.cpp:314] Iteration 6700 (5.07692 iter/s, 19.697s/100 iter), loss = 0.192179
I0916 10:29:35.719362 19004 solver.cpp:336]     Train net output #0: loss = 0.192178 (* 1 = 0.192178 loss)
I0916 10:29:35.719367 19004 sgd_solver.cpp:136] Iteration 6700, lr = 0.01, m = 0.9
I0916 10:29:55.171947 19004 solver.cpp:314] Iteration 6800 (5.14084 iter/s, 19.4521s/100 iter), loss = 0.0705306
I0916 10:29:55.172015 19004 solver.cpp:336]     Train net output #0: loss = 0.0705303 (* 1 = 0.0705303 loss)
I0916 10:29:55.172020 19004 sgd_solver.cpp:136] Iteration 6800, lr = 0.01, m = 0.9
I0916 10:30:14.507716 19004 solver.cpp:314] Iteration 6900 (5.1719 iter/s, 19.3352s/100 iter), loss = 0.144103
I0916 10:30:14.507741 19004 solver.cpp:336]     Train net output #0: loss = 0.144103 (* 1 = 0.144103 loss)
I0916 10:30:14.507745 19004 sgd_solver.cpp:136] Iteration 6900, lr = 0.01, m = 0.9
I0916 10:30:22.024621 19012 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 10:30:34.309912 19004 solver.cpp:314] Iteration 7000 (5.05008 iter/s, 19.8017s/100 iter), loss = 0.22683
I0916 10:30:34.309965 19004 solver.cpp:336]     Train net output #0: loss = 0.22683 (* 1 = 0.22683 loss)
I0916 10:30:34.309973 19004 sgd_solver.cpp:136] Iteration 7000, lr = 0.01, m = 0.9
I0916 10:30:53.848119 19004 solver.cpp:314] Iteration 7100 (5.11832 iter/s, 19.5377s/100 iter), loss = 0.13359
I0916 10:30:53.848140 19004 solver.cpp:336]     Train net output #0: loss = 0.13359 (* 1 = 0.13359 loss)
I0916 10:30:53.848145 19004 sgd_solver.cpp:136] Iteration 7100, lr = 0.01, m = 0.9
I0916 10:30:54.489151 18961 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 10:31:13.344574 19004 solver.cpp:314] Iteration 7200 (5.12928 iter/s, 19.4959s/100 iter), loss = 0.123153
I0916 10:31:13.344626 19004 solver.cpp:336]     Train net output #0: loss = 0.123152 (* 1 = 0.123152 loss)
I0916 10:31:13.344632 19004 sgd_solver.cpp:136] Iteration 7200, lr = 0.01, m = 0.9
I0916 10:31:32.793639 19004 solver.cpp:314] Iteration 7300 (5.14178 iter/s, 19.4485s/100 iter), loss = 0.100692
I0916 10:31:32.793663 19004 solver.cpp:336]     Train net output #0: loss = 0.100691 (* 1 = 0.100691 loss)
I0916 10:31:32.793668 19004 sgd_solver.cpp:136] Iteration 7300, lr = 0.01, m = 0.9
I0916 10:31:52.437058 19004 solver.cpp:314] Iteration 7400 (5.0909 iter/s, 19.6429s/100 iter), loss = 0.195729
I0916 10:31:52.437114 19004 solver.cpp:336]     Train net output #0: loss = 0.195728 (* 1 = 0.195728 loss)
I0916 10:31:52.437119 19004 sgd_solver.cpp:136] Iteration 7400, lr = 0.01, m = 0.9
I0916 10:31:59.071502 19012 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 10:32:11.899426 19004 solver.cpp:314] Iteration 7500 (5.13826 iter/s, 19.4618s/100 iter), loss = 0.145961
I0916 10:32:11.899447 19004 solver.cpp:336]     Train net output #0: loss = 0.145961 (* 1 = 0.145961 loss)
I0916 10:32:11.899454 19004 sgd_solver.cpp:136] Iteration 7500, lr = 0.01, m = 0.9
I0916 10:32:31.192354 19004 solver.cpp:314] Iteration 7600 (5.18339 iter/s, 19.2924s/100 iter), loss = 0.103731
I0916 10:32:31.192405 19004 solver.cpp:336]     Train net output #0: loss = 0.103731 (* 1 = 0.103731 loss)
I0916 10:32:31.192411 19004 sgd_solver.cpp:136] Iteration 7600, lr = 0.01, m = 0.9
I0916 10:32:50.801127 19004 solver.cpp:314] Iteration 7700 (5.0999 iter/s, 19.6082s/100 iter), loss = 0.0812066
I0916 10:32:50.801151 19004 solver.cpp:336]     Train net output #0: loss = 0.0812063 (* 1 = 0.0812063 loss)
I0916 10:32:50.801158 19004 sgd_solver.cpp:136] Iteration 7700, lr = 0.01, m = 0.9
I0916 10:33:03.577723 19008 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 10:33:10.282124 19004 solver.cpp:314] Iteration 7800 (5.13335 iter/s, 19.4805s/100 iter), loss = 0.239172
I0916 10:33:10.282151 19004 solver.cpp:336]     Train net output #0: loss = 0.239172 (* 1 = 0.239172 loss)
I0916 10:33:10.282156 19004 sgd_solver.cpp:136] Iteration 7800, lr = 0.01, m = 0.9
I0916 10:33:29.809028 19004 solver.cpp:314] Iteration 7900 (5.12128 iter/s, 19.5264s/100 iter), loss = 0.106511
I0916 10:33:29.809057 19004 solver.cpp:336]     Train net output #0: loss = 0.106511 (* 1 = 0.106511 loss)
I0916 10:33:29.809063 19004 sgd_solver.cpp:136] Iteration 7900, lr = 0.01, m = 0.9
I0916 10:33:35.729460 19008 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 10:33:48.920661 19004 solver.cpp:563] Iteration 8000, Testing net (#0)
I0916 10:33:59.609638 19016 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 10:34:00.206431 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.944676
I0916 10:34:00.206451 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 10:34:00.206456 19004 solver.cpp:655]     Test net output #2: loss = 0.155116 (* 1 = 0.155116 loss)
I0916 10:34:00.206480 19004 solver.cpp:265] [MultiGPU] Tests completed in 11.2855s
I0916 10:34:00.405776 19004 solver.cpp:314] Iteration 8000 (3.26841 iter/s, 30.5959s/100 iter), loss = 0.111848
I0916 10:34:00.405799 19004 solver.cpp:336]     Train net output #0: loss = 0.111847 (* 1 = 0.111847 loss)
I0916 10:34:00.405803 19004 sgd_solver.cpp:136] Iteration 8000, lr = 0.01, m = 0.9
I0916 10:34:19.798684 19004 solver.cpp:314] Iteration 8100 (5.15667 iter/s, 19.3924s/100 iter), loss = 0.0959846
I0916 10:34:19.798735 19004 solver.cpp:336]     Train net output #0: loss = 0.0959844 (* 1 = 0.0959844 loss)
I0916 10:34:19.798740 19004 sgd_solver.cpp:136] Iteration 8100, lr = 0.01, m = 0.9
I0916 10:34:39.064153 19004 solver.cpp:314] Iteration 8200 (5.19078 iter/s, 19.2649s/100 iter), loss = 0.0930892
I0916 10:34:39.064184 19004 solver.cpp:336]     Train net output #0: loss = 0.0930889 (* 1 = 0.0930889 loss)
I0916 10:34:39.064193 19004 sgd_solver.cpp:136] Iteration 8200, lr = 0.01, m = 0.9
I0916 10:34:50.851131 19012 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 10:34:58.601302 19004 solver.cpp:314] Iteration 8300 (5.11859 iter/s, 19.5366s/100 iter), loss = 0.215754
I0916 10:34:58.601326 19004 solver.cpp:336]     Train net output #0: loss = 0.215753 (* 1 = 0.215753 loss)
I0916 10:34:58.601330 19004 sgd_solver.cpp:136] Iteration 8300, lr = 0.01, m = 0.9
I0916 10:35:18.122648 19004 solver.cpp:314] Iteration 8400 (5.12274 iter/s, 19.5208s/100 iter), loss = 0.125172
I0916 10:35:18.122669 19004 solver.cpp:336]     Train net output #0: loss = 0.125172 (* 1 = 0.125172 loss)
I0916 10:35:18.122673 19004 sgd_solver.cpp:136] Iteration 8400, lr = 0.01, m = 0.9
I0916 10:35:23.281903 19007 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 10:35:37.434267 19004 solver.cpp:314] Iteration 8500 (5.17837 iter/s, 19.3111s/100 iter), loss = 0.0894014
I0916 10:35:37.434294 19004 solver.cpp:336]     Train net output #0: loss = 0.0894012 (* 1 = 0.0894012 loss)
I0916 10:35:37.434300 19004 sgd_solver.cpp:136] Iteration 8500, lr = 0.01, m = 0.9
I0916 10:35:56.778738 19004 solver.cpp:314] Iteration 8600 (5.16958 iter/s, 19.3439s/100 iter), loss = 0.163366
I0916 10:35:56.778805 19004 solver.cpp:336]     Train net output #0: loss = 0.163366 (* 1 = 0.163366 loss)
I0916 10:35:56.778811 19004 sgd_solver.cpp:136] Iteration 8600, lr = 0.01, m = 0.9
I0916 10:36:16.199194 19004 solver.cpp:314] Iteration 8700 (5.14935 iter/s, 19.4199s/100 iter), loss = 0.0966173
I0916 10:36:16.199218 19004 solver.cpp:336]     Train net output #0: loss = 0.0966171 (* 1 = 0.0966171 loss)
I0916 10:36:16.199223 19004 sgd_solver.cpp:136] Iteration 8700, lr = 0.01, m = 0.9
I0916 10:36:27.099135 18961 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 10:36:35.721683 19004 solver.cpp:314] Iteration 8800 (5.12244 iter/s, 19.522s/100 iter), loss = 0.096835
I0916 10:36:35.721711 19004 solver.cpp:336]     Train net output #0: loss = 0.0968348 (* 1 = 0.0968348 loss)
I0916 10:36:35.721717 19004 sgd_solver.cpp:136] Iteration 8800, lr = 0.01, m = 0.9
I0916 10:36:55.463223 19004 solver.cpp:314] Iteration 8900 (5.0656 iter/s, 19.741s/100 iter), loss = 0.121101
I0916 10:36:55.463248 19004 solver.cpp:336]     Train net output #0: loss = 0.121101 (* 1 = 0.121101 loss)
I0916 10:36:55.463254 19004 sgd_solver.cpp:136] Iteration 8900, lr = 0.01, m = 0.9
I0916 10:37:14.955550 19004 solver.cpp:314] Iteration 9000 (5.13036 iter/s, 19.4918s/100 iter), loss = 0.116163
I0916 10:37:14.955605 19004 solver.cpp:336]     Train net output #0: loss = 0.116162 (* 1 = 0.116162 loss)
I0916 10:37:14.955610 19004 sgd_solver.cpp:136] Iteration 9000, lr = 0.01, m = 0.9
I0916 10:37:31.878890 19012 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 10:37:34.428127 19004 solver.cpp:314] Iteration 9100 (5.13557 iter/s, 19.472s/100 iter), loss = 0.159083
I0916 10:37:34.428153 19004 solver.cpp:336]     Train net output #0: loss = 0.159083 (* 1 = 0.159083 loss)
I0916 10:37:34.428158 19004 sgd_solver.cpp:136] Iteration 9100, lr = 0.01, m = 0.9
I0916 10:37:53.798585 19004 solver.cpp:314] Iteration 9200 (5.16264 iter/s, 19.3699s/100 iter), loss = 0.0880225
I0916 10:37:53.798660 19004 solver.cpp:336]     Train net output #0: loss = 0.0880222 (* 1 = 0.0880222 loss)
I0916 10:37:53.798665 19004 sgd_solver.cpp:136] Iteration 9200, lr = 0.01, m = 0.9
I0916 10:38:03.952203 18961 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 10:38:13.350462 19004 solver.cpp:314] Iteration 9300 (5.11474 iter/s, 19.5513s/100 iter), loss = 0.159245
I0916 10:38:13.350483 19004 solver.cpp:336]     Train net output #0: loss = 0.159245 (* 1 = 0.159245 loss)
I0916 10:38:13.350487 19004 sgd_solver.cpp:136] Iteration 9300, lr = 0.01, m = 0.9
I0916 10:38:32.594393 19004 solver.cpp:314] Iteration 9400 (5.19658 iter/s, 19.2434s/100 iter), loss = 0.143048
I0916 10:38:32.594439 19004 solver.cpp:336]     Train net output #0: loss = 0.143048 (* 1 = 0.143048 loss)
I0916 10:38:32.594444 19004 sgd_solver.cpp:136] Iteration 9400, lr = 0.01, m = 0.9
I0916 10:38:52.082015 19004 solver.cpp:314] Iteration 9500 (5.1316 iter/s, 19.4871s/100 iter), loss = 0.0953171
I0916 10:38:52.082041 19004 solver.cpp:336]     Train net output #0: loss = 0.0953169 (* 1 = 0.0953169 loss)
I0916 10:38:52.082046 19004 sgd_solver.cpp:136] Iteration 9500, lr = 0.01, m = 0.9
I0916 10:39:08.232635 18963 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 10:39:11.477896 19004 solver.cpp:314] Iteration 9600 (5.15587 iter/s, 19.3954s/100 iter), loss = 0.114497
I0916 10:39:11.477922 19004 solver.cpp:336]     Train net output #0: loss = 0.114497 (* 1 = 0.114497 loss)
I0916 10:39:11.477928 19004 sgd_solver.cpp:136] Iteration 9600, lr = 0.01, m = 0.9
I0916 10:39:30.859310 19004 solver.cpp:314] Iteration 9700 (5.15972 iter/s, 19.3809s/100 iter), loss = 0.111787
I0916 10:39:30.859336 19004 solver.cpp:336]     Train net output #0: loss = 0.111787 (* 1 = 0.111787 loss)
I0916 10:39:30.859342 19004 sgd_solver.cpp:136] Iteration 9700, lr = 0.01, m = 0.9
I0916 10:39:50.440431 19004 solver.cpp:314] Iteration 9800 (5.1071 iter/s, 19.5806s/100 iter), loss = 0.096057
I0916 10:39:50.440482 19004 solver.cpp:336]     Train net output #0: loss = 0.0960568 (* 1 = 0.0960568 loss)
I0916 10:39:50.440487 19004 sgd_solver.cpp:136] Iteration 9800, lr = 0.01, m = 0.9
I0916 10:40:09.926430 19004 solver.cpp:314] Iteration 9900 (5.13203 iter/s, 19.4855s/100 iter), loss = 0.13782
I0916 10:40:09.926455 19004 solver.cpp:336]     Train net output #0: loss = 0.13782 (* 1 = 0.13782 loss)
I0916 10:40:09.926461 19004 sgd_solver.cpp:136] Iteration 9900, lr = 0.01, m = 0.9
I0916 10:40:12.410965 19012 data_reader.cpp:305] Starting prefetch of epoch 10
I0916 10:40:29.109777 19004 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/cityscapes5_jsegnet21v2_iter_10000.caffemodel
I0916 10:40:29.228605 19004 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/cityscapes5_jsegnet21v2_iter_10000.solverstate
I0916 10:40:29.234138 19004 solver.cpp:563] Iteration 10000, Testing net (#0)
I0916 10:40:40.669185 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.935146
I0916 10:40:40.669214 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 10:40:40.669219 19004 solver.cpp:655]     Test net output #2: loss = 0.20555 (* 1 = 0.20555 loss)
I0916 10:40:40.669244 19004 solver.cpp:265] [MultiGPU] Tests completed in 11.4348s
I0916 10:40:40.880795 19004 solver.cpp:314] Iteration 10000 (3.23065 iter/s, 30.9535s/100 iter), loss = 0.0879399
I0916 10:40:40.880823 19004 solver.cpp:336]     Train net output #0: loss = 0.0879397 (* 1 = 0.0879397 loss)
I0916 10:40:40.880831 19004 sgd_solver.cpp:136] Iteration 10000, lr = 0.01, m = 0.9
I0916 10:40:56.012600 19010 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 10:41:00.344727 19004 solver.cpp:314] Iteration 10100 (5.13785 iter/s, 19.4634s/100 iter), loss = 0.089557
I0916 10:41:00.344827 19004 solver.cpp:336]     Train net output #0: loss = 0.0895568 (* 1 = 0.0895568 loss)
I0916 10:41:00.344846 19004 sgd_solver.cpp:136] Iteration 10100, lr = 0.01, m = 0.9
I0916 10:41:19.970237 19004 solver.cpp:314] Iteration 10200 (5.09555 iter/s, 19.625s/100 iter), loss = 0.181827
I0916 10:41:19.970263 19004 solver.cpp:336]     Train net output #0: loss = 0.181827 (* 1 = 0.181827 loss)
I0916 10:41:19.970269 19004 sgd_solver.cpp:136] Iteration 10200, lr = 0.01, m = 0.9
I0916 10:41:28.614107 19008 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 10:41:39.338460 19004 solver.cpp:314] Iteration 10300 (5.16324 iter/s, 19.3677s/100 iter), loss = 0.107248
I0916 10:41:39.338516 19004 solver.cpp:336]     Train net output #0: loss = 0.107248 (* 1 = 0.107248 loss)
I0916 10:41:39.338523 19004 sgd_solver.cpp:136] Iteration 10300, lr = 0.01, m = 0.9
I0916 10:41:58.844055 19004 solver.cpp:314] Iteration 10400 (5.12688 iter/s, 19.5051s/100 iter), loss = 0.0739569
I0916 10:41:58.844080 19004 solver.cpp:336]     Train net output #0: loss = 0.0739568 (* 1 = 0.0739568 loss)
I0916 10:41:58.844084 19004 sgd_solver.cpp:136] Iteration 10400, lr = 0.01, m = 0.9
I0916 10:42:18.406260 19004 solver.cpp:314] Iteration 10500 (5.11204 iter/s, 19.5617s/100 iter), loss = 0.0939477
I0916 10:42:18.406337 19004 solver.cpp:336]     Train net output #0: loss = 0.0939475 (* 1 = 0.0939475 loss)
I0916 10:42:18.406342 19004 sgd_solver.cpp:136] Iteration 10500, lr = 0.01, m = 0.9
I0916 10:42:32.750265 19007 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 10:42:37.650315 19004 solver.cpp:314] Iteration 10600 (5.19655 iter/s, 19.2435s/100 iter), loss = 0.118822
I0916 10:42:37.650336 19004 solver.cpp:336]     Train net output #0: loss = 0.118822 (* 1 = 0.118822 loss)
I0916 10:42:37.650341 19004 sgd_solver.cpp:136] Iteration 10600, lr = 0.01, m = 0.9
I0916 10:42:56.896762 19004 solver.cpp:314] Iteration 10700 (5.19591 iter/s, 19.2459s/100 iter), loss = 0.0839383
I0916 10:42:56.896813 19004 solver.cpp:336]     Train net output #0: loss = 0.0839381 (* 1 = 0.0839381 loss)
I0916 10:42:56.896818 19004 sgd_solver.cpp:136] Iteration 10700, lr = 0.01, m = 0.9
I0916 10:43:16.221598 19004 solver.cpp:314] Iteration 10800 (5.17483 iter/s, 19.3243s/100 iter), loss = 0.133612
I0916 10:43:16.221623 19004 solver.cpp:336]     Train net output #0: loss = 0.133612 (* 1 = 0.133612 loss)
I0916 10:43:16.221627 19004 sgd_solver.cpp:136] Iteration 10800, lr = 0.01, m = 0.9
I0916 10:43:35.406124 19004 solver.cpp:314] Iteration 10900 (5.21268 iter/s, 19.184s/100 iter), loss = 0.0655711
I0916 10:43:35.414134 19004 solver.cpp:336]     Train net output #0: loss = 0.0655709 (* 1 = 0.0655709 loss)
I0916 10:43:35.414161 19004 sgd_solver.cpp:136] Iteration 10900, lr = 0.01, m = 0.9
I0916 10:43:36.372068 19010 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 10:43:54.660208 19004 solver.cpp:314] Iteration 11000 (5.19384 iter/s, 19.2536s/100 iter), loss = 0.109101
I0916 10:43:54.660229 19004 solver.cpp:336]     Train net output #0: loss = 0.1091 (* 1 = 0.1091 loss)
I0916 10:43:54.660233 19004 sgd_solver.cpp:136] Iteration 11000, lr = 0.01, m = 0.9
I0916 10:44:14.062397 19004 solver.cpp:314] Iteration 11100 (5.1542 iter/s, 19.4017s/100 iter), loss = 0.117145
I0916 10:44:14.062446 19004 solver.cpp:336]     Train net output #0: loss = 0.117145 (* 1 = 0.117145 loss)
I0916 10:44:14.062451 19004 sgd_solver.cpp:136] Iteration 11100, lr = 0.01, m = 0.9
I0916 10:44:33.356843 19004 solver.cpp:314] Iteration 11200 (5.18298 iter/s, 19.2939s/100 iter), loss = 0.109687
I0916 10:44:33.356868 19004 solver.cpp:336]     Train net output #0: loss = 0.109687 (* 1 = 0.109687 loss)
I0916 10:44:33.356873 19004 sgd_solver.cpp:136] Iteration 11200, lr = 0.01, m = 0.9
I0916 10:44:40.134963 19010 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 10:44:52.852818 19004 solver.cpp:314] Iteration 11300 (5.1294 iter/s, 19.4954s/100 iter), loss = 0.127382
I0916 10:44:52.852886 19004 solver.cpp:336]     Train net output #0: loss = 0.127382 (* 1 = 0.127382 loss)
I0916 10:44:52.852892 19004 sgd_solver.cpp:136] Iteration 11300, lr = 0.01, m = 0.9
I0916 10:45:12.532349 19004 solver.cpp:314] Iteration 11400 (5.08156 iter/s, 19.679s/100 iter), loss = 0.0751816
I0916 10:45:12.532377 19004 solver.cpp:336]     Train net output #0: loss = 0.0751815 (* 1 = 0.0751815 loss)
I0916 10:45:12.532382 19004 sgd_solver.cpp:136] Iteration 11400, lr = 0.01, m = 0.9
I0916 10:45:12.757588 18961 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 10:45:32.046408 19004 solver.cpp:314] Iteration 11500 (5.12465 iter/s, 19.5135s/100 iter), loss = 0.165499
I0916 10:45:32.046468 19004 solver.cpp:336]     Train net output #0: loss = 0.165499 (* 1 = 0.165499 loss)
I0916 10:45:32.046474 19004 sgd_solver.cpp:136] Iteration 11500, lr = 0.01, m = 0.9
I0916 10:45:51.231508 19004 solver.cpp:314] Iteration 11600 (5.21252 iter/s, 19.1846s/100 iter), loss = 0.148434
I0916 10:45:51.231534 19004 solver.cpp:336]     Train net output #0: loss = 0.148434 (* 1 = 0.148434 loss)
I0916 10:45:51.231537 19004 sgd_solver.cpp:136] Iteration 11600, lr = 0.01, m = 0.9
I0916 10:46:10.521260 19004 solver.cpp:314] Iteration 11700 (5.18424 iter/s, 19.2892s/100 iter), loss = 0.0575608
I0916 10:46:10.521320 19004 solver.cpp:336]     Train net output #0: loss = 0.0575606 (* 1 = 0.0575606 loss)
I0916 10:46:10.521327 19004 sgd_solver.cpp:136] Iteration 11700, lr = 0.01, m = 0.9
I0916 10:46:16.668736 19007 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 10:46:30.188205 19004 solver.cpp:314] Iteration 11800 (5.08481 iter/s, 19.6664s/100 iter), loss = 0.10273
I0916 10:46:30.188228 19004 solver.cpp:336]     Train net output #0: loss = 0.10273 (* 1 = 0.10273 loss)
I0916 10:46:30.188235 19004 sgd_solver.cpp:136] Iteration 11800, lr = 0.01, m = 0.9
I0916 10:46:49.568568 19004 solver.cpp:314] Iteration 11900 (5.16 iter/s, 19.3798s/100 iter), loss = 0.0875857
I0916 10:46:49.568624 19004 solver.cpp:336]     Train net output #0: loss = 0.0875855 (* 1 = 0.0875855 loss)
I0916 10:46:49.568630 19004 sgd_solver.cpp:136] Iteration 11900, lr = 0.01, m = 0.9
I0916 10:47:09.047307 19004 solver.cpp:563] Iteration 12000, Testing net (#0)
I0916 10:47:12.488832 19002 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 10:47:20.607586 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.939685
I0916 10:47:20.607669 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 10:47:20.607676 19004 solver.cpp:655]     Test net output #2: loss = 0.158569 (* 1 = 0.158569 loss)
I0916 10:47:20.607699 19004 solver.cpp:265] [MultiGPU] Tests completed in 11.5601s
I0916 10:47:20.818276 19004 solver.cpp:314] Iteration 12000 (3.20012 iter/s, 31.2489s/100 iter), loss = 0.058243
I0916 10:47:20.818300 19004 solver.cpp:336]     Train net output #0: loss = 0.0582428 (* 1 = 0.0582428 loss)
I0916 10:47:20.818305 19004 sgd_solver.cpp:136] Iteration 12000, lr = 0.01, m = 0.9
I0916 10:47:32.810937 19012 data_reader.cpp:305] Starting prefetch of epoch 11
I0916 10:47:40.036864 19004 solver.cpp:314] Iteration 12100 (5.20344 iter/s, 19.2181s/100 iter), loss = 0.175417
I0916 10:47:40.036885 19004 solver.cpp:336]     Train net output #0: loss = 0.175417 (* 1 = 0.175417 loss)
I0916 10:47:40.036888 19004 sgd_solver.cpp:136] Iteration 12100, lr = 0.01, m = 0.9
I0916 10:47:59.357527 19004 solver.cpp:314] Iteration 12200 (5.17595 iter/s, 19.3201s/100 iter), loss = 0.129269
I0916 10:47:59.357616 19004 solver.cpp:336]     Train net output #0: loss = 0.129269 (* 1 = 0.129269 loss)
I0916 10:47:59.357621 19004 sgd_solver.cpp:136] Iteration 12200, lr = 0.01, m = 0.9
I0916 10:48:04.592514 19008 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 10:48:18.902256 19004 solver.cpp:314] Iteration 12300 (5.11661 iter/s, 19.5442s/100 iter), loss = 0.0896617
I0916 10:48:18.902281 19004 solver.cpp:336]     Train net output #0: loss = 0.0896615 (* 1 = 0.0896615 loss)
I0916 10:48:18.902287 19004 sgd_solver.cpp:136] Iteration 12300, lr = 0.01, m = 0.9
I0916 10:48:38.363626 19004 solver.cpp:314] Iteration 12400 (5.13852 iter/s, 19.4608s/100 iter), loss = 0.0739432
I0916 10:48:38.363700 19004 solver.cpp:336]     Train net output #0: loss = 0.073943 (* 1 = 0.073943 loss)
I0916 10:48:38.363706 19004 sgd_solver.cpp:136] Iteration 12400, lr = 0.01, m = 0.9
I0916 10:48:57.845366 19004 solver.cpp:314] Iteration 12500 (5.13315 iter/s, 19.4812s/100 iter), loss = 0.0968819
I0916 10:48:57.845391 19004 solver.cpp:336]     Train net output #0: loss = 0.0968817 (* 1 = 0.0968817 loss)
I0916 10:48:57.845396 19004 sgd_solver.cpp:136] Iteration 12500, lr = 0.01, m = 0.9
I0916 10:49:09.190912 19012 data_reader.cpp:305] Starting prefetch of epoch 12
I0916 10:49:17.321357 19004 solver.cpp:314] Iteration 12600 (5.13467 iter/s, 19.4755s/100 iter), loss = 0.0803289
I0916 10:49:17.321382 19004 solver.cpp:336]     Train net output #0: loss = 0.0803288 (* 1 = 0.0803288 loss)
I0916 10:49:17.321386 19004 sgd_solver.cpp:136] Iteration 12600, lr = 0.01, m = 0.9
I0916 10:49:36.525434 19004 solver.cpp:314] Iteration 12700 (5.20737 iter/s, 19.2036s/100 iter), loss = 0.301281
I0916 10:49:36.525463 19004 solver.cpp:336]     Train net output #0: loss = 0.301281 (* 1 = 0.301281 loss)
I0916 10:49:36.525468 19004 sgd_solver.cpp:136] Iteration 12700, lr = 0.01, m = 0.9
I0916 10:49:55.691411 19004 solver.cpp:314] Iteration 12800 (5.21772 iter/s, 19.1655s/100 iter), loss = 0.0823101
I0916 10:49:55.691463 19004 solver.cpp:336]     Train net output #0: loss = 0.08231 (* 1 = 0.08231 loss)
I0916 10:49:55.691469 19004 sgd_solver.cpp:136] Iteration 12800, lr = 0.01, m = 0.9
I0916 10:50:12.646255 18963 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 10:50:14.997251 19004 solver.cpp:314] Iteration 12900 (5.17992 iter/s, 19.3053s/100 iter), loss = 0.0928249
I0916 10:50:14.997277 19004 solver.cpp:336]     Train net output #0: loss = 0.0928248 (* 1 = 0.0928248 loss)
I0916 10:50:14.997280 19004 sgd_solver.cpp:136] Iteration 12900, lr = 0.01, m = 0.9
I0916 10:50:34.600868 19004 solver.cpp:314] Iteration 13000 (5.10124 iter/s, 19.6031s/100 iter), loss = 0.0812404
I0916 10:50:34.600921 19004 solver.cpp:336]     Train net output #0: loss = 0.0812402 (* 1 = 0.0812402 loss)
I0916 10:50:34.600926 19004 sgd_solver.cpp:136] Iteration 13000, lr = 0.01, m = 0.9
I0916 10:50:45.020133 19008 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 10:50:54.016101 19004 solver.cpp:314] Iteration 13100 (5.15073 iter/s, 19.4147s/100 iter), loss = 0.131569
I0916 10:50:54.016126 19004 solver.cpp:336]     Train net output #0: loss = 0.131568 (* 1 = 0.131568 loss)
I0916 10:50:54.016132 19004 sgd_solver.cpp:136] Iteration 13100, lr = 0.01, m = 0.9
I0916 10:51:13.374395 19004 solver.cpp:314] Iteration 13200 (5.16588 iter/s, 19.3578s/100 iter), loss = 0.0764606
I0916 10:51:13.374477 19004 solver.cpp:336]     Train net output #0: loss = 0.0764605 (* 1 = 0.0764605 loss)
I0916 10:51:13.374485 19004 sgd_solver.cpp:136] Iteration 13200, lr = 0.01, m = 0.9
I0916 10:51:32.840276 19004 solver.cpp:314] Iteration 13300 (5.13733 iter/s, 19.4654s/100 iter), loss = 0.126004
I0916 10:51:32.840306 19004 solver.cpp:336]     Train net output #0: loss = 0.126004 (* 1 = 0.126004 loss)
I0916 10:51:32.840312 19004 sgd_solver.cpp:136] Iteration 13300, lr = 0.01, m = 0.9
I0916 10:51:49.369791 18963 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 10:51:52.422580 19004 solver.cpp:314] Iteration 13400 (5.10679 iter/s, 19.5818s/100 iter), loss = 0.0839963
I0916 10:51:52.422608 19004 solver.cpp:336]     Train net output #0: loss = 0.0839961 (* 1 = 0.0839961 loss)
I0916 10:51:52.422616 19004 sgd_solver.cpp:136] Iteration 13400, lr = 0.01, m = 0.9
I0916 10:52:11.873183 19004 solver.cpp:314] Iteration 13500 (5.14137 iter/s, 19.4501s/100 iter), loss = 0.122499
I0916 10:52:11.873208 19004 solver.cpp:336]     Train net output #0: loss = 0.122498 (* 1 = 0.122498 loss)
I0916 10:52:11.873211 19004 sgd_solver.cpp:136] Iteration 13500, lr = 0.01, m = 0.9
I0916 10:52:31.386276 19004 solver.cpp:314] Iteration 13600 (5.1249 iter/s, 19.5126s/100 iter), loss = 0.113996
I0916 10:52:31.386348 19004 solver.cpp:336]     Train net output #0: loss = 0.113996 (* 1 = 0.113996 loss)
I0916 10:52:31.386354 19004 sgd_solver.cpp:136] Iteration 13600, lr = 0.01, m = 0.9
I0916 10:52:50.891943 19004 solver.cpp:314] Iteration 13700 (5.12685 iter/s, 19.5051s/100 iter), loss = 0.0836929
I0916 10:52:50.891968 19004 solver.cpp:336]     Train net output #0: loss = 0.0836927 (* 1 = 0.0836927 loss)
I0916 10:52:50.891971 19004 sgd_solver.cpp:136] Iteration 13700, lr = 0.01, m = 0.9
I0916 10:52:53.843979 18963 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 10:53:10.619240 19004 solver.cpp:314] Iteration 13800 (5.06925 iter/s, 19.7268s/100 iter), loss = 0.0914566
I0916 10:53:10.619293 19004 solver.cpp:336]     Train net output #0: loss = 0.0914563 (* 1 = 0.0914563 loss)
I0916 10:53:10.619300 19004 sgd_solver.cpp:136] Iteration 13800, lr = 0.01, m = 0.9
I0916 10:53:26.421286 19008 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 10:53:30.276496 19004 solver.cpp:314] Iteration 13900 (5.08732 iter/s, 19.6567s/100 iter), loss = 0.101338
I0916 10:53:30.276517 19004 solver.cpp:336]     Train net output #0: loss = 0.101337 (* 1 = 0.101337 loss)
I0916 10:53:30.276522 19004 sgd_solver.cpp:136] Iteration 13900, lr = 0.01, m = 0.9
I0916 10:53:49.494103 19004 solver.cpp:563] Iteration 14000, Testing net (#0)
I0916 10:54:00.972136 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.942328
I0916 10:54:00.972158 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 10:54:00.972163 19004 solver.cpp:655]     Test net output #2: loss = 0.163291 (* 1 = 0.163291 loss)
I0916 10:54:00.972187 19004 solver.cpp:265] [MultiGPU] Tests completed in 11.4778s
I0916 10:54:01.179594 19004 solver.cpp:314] Iteration 14000 (3.23601 iter/s, 30.9023s/100 iter), loss = 0.129295
I0916 10:54:01.179615 19004 solver.cpp:336]     Train net output #0: loss = 0.129295 (* 1 = 0.129295 loss)
I0916 10:54:01.179618 19004 sgd_solver.cpp:136] Iteration 14000, lr = 0.01, m = 0.9
I0916 10:54:09.751372 18963 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 10:54:20.280050 19004 solver.cpp:314] Iteration 14100 (5.23562 iter/s, 19.0999s/100 iter), loss = 0.141428
I0916 10:54:20.280107 19004 solver.cpp:336]     Train net output #0: loss = 0.141428 (* 1 = 0.141428 loss)
I0916 10:54:20.280113 19004 sgd_solver.cpp:136] Iteration 14100, lr = 0.01, m = 0.9
I0916 10:54:39.877910 19004 solver.cpp:314] Iteration 14200 (5.10274 iter/s, 19.5973s/100 iter), loss = 0.0851084
I0916 10:54:39.877936 19004 solver.cpp:336]     Train net output #0: loss = 0.0851082 (* 1 = 0.0851082 loss)
I0916 10:54:39.877940 19004 sgd_solver.cpp:136] Iteration 14200, lr = 0.01, m = 0.9
I0916 10:54:59.384691 19004 solver.cpp:314] Iteration 14300 (5.12656 iter/s, 19.5063s/100 iter), loss = 0.122718
I0916 10:54:59.384764 19004 solver.cpp:336]     Train net output #0: loss = 0.122718 (* 1 = 0.122718 loss)
I0916 10:54:59.384771 19004 sgd_solver.cpp:136] Iteration 14300, lr = 0.01, m = 0.9
I0916 10:55:14.243647 18963 data_reader.cpp:305] Starting prefetch of epoch 10
I0916 10:55:18.890992 19004 solver.cpp:314] Iteration 14400 (5.12669 iter/s, 19.5058s/100 iter), loss = 0.107211
I0916 10:55:18.891017 19004 solver.cpp:336]     Train net output #0: loss = 0.107211 (* 1 = 0.107211 loss)
I0916 10:55:18.891023 19004 sgd_solver.cpp:136] Iteration 14400, lr = 0.01, m = 0.9
I0916 10:55:38.522984 19004 solver.cpp:314] Iteration 14500 (5.09386 iter/s, 19.6315s/100 iter), loss = 0.105635
I0916 10:55:38.523061 19004 solver.cpp:336]     Train net output #0: loss = 0.105635 (* 1 = 0.105635 loss)
I0916 10:55:38.523066 19004 sgd_solver.cpp:136] Iteration 14500, lr = 0.01, m = 0.9
I0916 10:55:46.484810 19008 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 10:55:57.878842 19004 solver.cpp:314] Iteration 14600 (5.16653 iter/s, 19.3553s/100 iter), loss = 0.0896563
I0916 10:55:57.878871 19004 solver.cpp:336]     Train net output #0: loss = 0.0896561 (* 1 = 0.0896561 loss)
I0916 10:55:57.878878 19004 sgd_solver.cpp:136] Iteration 14600, lr = 0.01, m = 0.9
I0916 10:56:17.331161 19004 solver.cpp:314] Iteration 14700 (5.14091 iter/s, 19.4518s/100 iter), loss = 0.162227
I0916 10:56:17.331228 19004 solver.cpp:336]     Train net output #0: loss = 0.162227 (* 1 = 0.162227 loss)
I0916 10:56:17.331234 19004 sgd_solver.cpp:136] Iteration 14700, lr = 0.01, m = 0.9
I0916 10:56:36.760391 19004 solver.cpp:314] Iteration 14800 (5.14702 iter/s, 19.4287s/100 iter), loss = 0.0830501
I0916 10:56:36.760419 19004 solver.cpp:336]     Train net output #0: loss = 0.08305 (* 1 = 0.08305 loss)
I0916 10:56:36.760426 19004 sgd_solver.cpp:136] Iteration 14800, lr = 0.01, m = 0.9
I0916 10:56:50.835314 18963 data_reader.cpp:305] Starting prefetch of epoch 11
I0916 10:56:56.622645 19004 solver.cpp:314] Iteration 14900 (5.03481 iter/s, 19.8617s/100 iter), loss = 0.208084
I0916 10:56:56.622668 19004 solver.cpp:336]     Train net output #0: loss = 0.208084 (* 1 = 0.208084 loss)
I0916 10:56:56.622673 19004 sgd_solver.cpp:136] Iteration 14900, lr = 0.01, m = 0.9
I0916 10:57:15.805505 19004 solver.cpp:314] Iteration 15000 (5.21313 iter/s, 19.1823s/100 iter), loss = 0.0722161
I0916 10:57:15.805531 19004 solver.cpp:336]     Train net output #0: loss = 0.0722159 (* 1 = 0.0722159 loss)
I0916 10:57:15.805537 19004 sgd_solver.cpp:136] Iteration 15000, lr = 0.01, m = 0.9
I0916 10:57:35.293491 19004 solver.cpp:314] Iteration 15100 (5.13151 iter/s, 19.4875s/100 iter), loss = 0.164484
I0916 10:57:35.293592 19004 solver.cpp:336]     Train net output #0: loss = 0.164484 (* 1 = 0.164484 loss)
I0916 10:57:35.293598 19004 sgd_solver.cpp:136] Iteration 15100, lr = 0.01, m = 0.9
I0916 10:57:54.873694 19004 solver.cpp:314] Iteration 15200 (5.10734 iter/s, 19.5797s/100 iter), loss = 0.10575
I0916 10:57:54.873724 19004 solver.cpp:336]     Train net output #0: loss = 0.10575 (* 1 = 0.10575 loss)
I0916 10:57:54.873730 19004 sgd_solver.cpp:136] Iteration 15200, lr = 0.01, m = 0.9
I0916 10:57:55.269703 18963 data_reader.cpp:305] Starting prefetch of epoch 12
I0916 10:58:14.412261 19004 solver.cpp:314] Iteration 15300 (5.11822 iter/s, 19.538s/100 iter), loss = 0.0439267
I0916 10:58:14.412351 19004 solver.cpp:336]     Train net output #0: loss = 0.0439266 (* 1 = 0.0439266 loss)
I0916 10:58:14.412359 19004 sgd_solver.cpp:136] Iteration 15300, lr = 0.01, m = 0.9
I0916 10:58:27.346408 18961 data_reader.cpp:305] Starting prefetch of epoch 10
I0916 10:58:33.721747 19004 solver.cpp:314] Iteration 15400 (5.17894 iter/s, 19.309s/100 iter), loss = 0.114738
I0916 10:58:33.721771 19004 solver.cpp:336]     Train net output #0: loss = 0.114738 (* 1 = 0.114738 loss)
I0916 10:58:33.721777 19004 sgd_solver.cpp:136] Iteration 15400, lr = 0.01, m = 0.9
I0916 10:58:53.164095 19004 solver.cpp:314] Iteration 15500 (5.14355 iter/s, 19.4418s/100 iter), loss = 0.0952991
I0916 10:58:53.164186 19004 solver.cpp:336]     Train net output #0: loss = 0.0952989 (* 1 = 0.0952989 loss)
I0916 10:58:53.164193 19004 sgd_solver.cpp:136] Iteration 15500, lr = 0.01, m = 0.9
I0916 10:59:12.520978 19004 solver.cpp:314] Iteration 15600 (5.16626 iter/s, 19.3564s/100 iter), loss = 0.0972764
I0916 10:59:12.521006 19004 solver.cpp:336]     Train net output #0: loss = 0.0972762 (* 1 = 0.0972762 loss)
I0916 10:59:12.521013 19004 sgd_solver.cpp:136] Iteration 15600, lr = 0.01, m = 0.9
I0916 10:59:31.756762 18963 data_reader.cpp:305] Starting prefetch of epoch 13
I0916 10:59:32.126509 19004 solver.cpp:314] Iteration 15700 (5.10074 iter/s, 19.605s/100 iter), loss = 0.102803
I0916 10:59:32.126535 19004 solver.cpp:336]     Train net output #0: loss = 0.102802 (* 1 = 0.102802 loss)
I0916 10:59:32.126543 19004 sgd_solver.cpp:136] Iteration 15700, lr = 0.01, m = 0.9
I0916 10:59:51.874409 19004 solver.cpp:314] Iteration 15800 (5.06397 iter/s, 19.7474s/100 iter), loss = 0.0983634
I0916 10:59:51.874434 19004 solver.cpp:336]     Train net output #0: loss = 0.0983633 (* 1 = 0.0983633 loss)
I0916 10:59:51.874441 19004 sgd_solver.cpp:136] Iteration 15800, lr = 0.01, m = 0.9
I0916 11:00:11.466737 19004 solver.cpp:314] Iteration 15900 (5.10418 iter/s, 19.5918s/100 iter), loss = 0.0815663
I0916 11:00:11.466814 19004 solver.cpp:336]     Train net output #0: loss = 0.0815662 (* 1 = 0.0815662 loss)
I0916 11:00:11.466821 19004 sgd_solver.cpp:136] Iteration 15900, lr = 0.01, m = 0.9
I0916 11:00:30.820828 19004 solver.cpp:563] Iteration 16000, Testing net (#0)
I0916 11:00:34.067014 19018 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 11:00:41.637506 19029 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 11:00:42.027643 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.94293
I0916 11:00:42.027663 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 11:00:42.027669 19004 solver.cpp:655]     Test net output #2: loss = 0.178783 (* 1 = 0.178783 loss)
I0916 11:00:42.027765 19004 solver.cpp:265] [MultiGPU] Tests completed in 11.2066s
I0916 11:00:42.234243 19004 solver.cpp:314] Iteration 16000 (3.25027 iter/s, 30.7667s/100 iter), loss = 0.121719
I0916 11:00:42.234272 19004 solver.cpp:336]     Train net output #0: loss = 0.121718 (* 1 = 0.121718 loss)
I0916 11:00:42.234279 19004 sgd_solver.cpp:136] Iteration 16000, lr = 0.01, m = 0.9
I0916 11:01:01.424976 19004 solver.cpp:314] Iteration 16100 (5.21099 iter/s, 19.1902s/100 iter), loss = 0.13169
I0916 11:01:01.425001 19004 solver.cpp:336]     Train net output #0: loss = 0.13169 (* 1 = 0.13169 loss)
I0916 11:01:01.425006 19004 sgd_solver.cpp:136] Iteration 16100, lr = 0.01, m = 0.9
I0916 11:01:19.716358 18963 data_reader.cpp:305] Starting prefetch of epoch 14
I0916 11:01:20.910897 19004 solver.cpp:314] Iteration 16200 (5.13205 iter/s, 19.4854s/100 iter), loss = 0.133152
I0916 11:01:20.910917 19004 solver.cpp:336]     Train net output #0: loss = 0.133151 (* 1 = 0.133151 loss)
I0916 11:01:20.910922 19004 sgd_solver.cpp:136] Iteration 16200, lr = 0.01, m = 0.9
I0916 11:01:40.479228 19004 solver.cpp:314] Iteration 16300 (5.11044 iter/s, 19.5678s/100 iter), loss = 0.0882496
I0916 11:01:40.479256 19004 solver.cpp:336]     Train net output #0: loss = 0.0882494 (* 1 = 0.0882494 loss)
I0916 11:01:40.479262 19004 sgd_solver.cpp:136] Iteration 16300, lr = 0.01, m = 0.9
I0916 11:02:00.281287 19004 solver.cpp:314] Iteration 16400 (5.05012 iter/s, 19.8015s/100 iter), loss = 0.0704384
I0916 11:02:00.281334 19004 solver.cpp:336]     Train net output #0: loss = 0.0704383 (* 1 = 0.0704383 loss)
I0916 11:02:00.281342 19004 sgd_solver.cpp:136] Iteration 16400, lr = 0.01, m = 0.9
I0916 11:02:19.518422 19004 solver.cpp:314] Iteration 16500 (5.19842 iter/s, 19.2366s/100 iter), loss = 0.0899441
I0916 11:02:19.518446 19004 solver.cpp:336]     Train net output #0: loss = 0.089944 (* 1 = 0.089944 loss)
I0916 11:02:19.518450 19004 sgd_solver.cpp:136] Iteration 16500, lr = 0.01, m = 0.9
I0916 11:02:24.286154 18963 data_reader.cpp:305] Starting prefetch of epoch 15
I0916 11:02:38.889565 19004 solver.cpp:314] Iteration 16600 (5.16246 iter/s, 19.3706s/100 iter), loss = 0.0949627
I0916 11:02:38.889619 19004 solver.cpp:336]     Train net output #0: loss = 0.0949626 (* 1 = 0.0949626 loss)
I0916 11:02:38.889626 19004 sgd_solver.cpp:136] Iteration 16600, lr = 0.01, m = 0.9
I0916 11:02:56.680102 19010 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 11:02:58.583204 19004 solver.cpp:314] Iteration 16700 (5.07792 iter/s, 19.6931s/100 iter), loss = 0.35614
I0916 11:02:58.583231 19004 solver.cpp:336]     Train net output #0: loss = 0.35614 (* 1 = 0.35614 loss)
I0916 11:02:58.583237 19004 sgd_solver.cpp:136] Iteration 16700, lr = 0.01, m = 0.9
I0916 11:03:18.003857 19004 solver.cpp:314] Iteration 16800 (5.1493 iter/s, 19.4201s/100 iter), loss = 0.11124
I0916 11:03:18.003935 19004 solver.cpp:336]     Train net output #0: loss = 0.11124 (* 1 = 0.11124 loss)
I0916 11:03:18.003943 19004 sgd_solver.cpp:136] Iteration 16800, lr = 0.01, m = 0.9
I0916 11:03:37.451231 19004 solver.cpp:314] Iteration 16900 (5.14222 iter/s, 19.4468s/100 iter), loss = 0.0903608
I0916 11:03:37.451257 19004 solver.cpp:336]     Train net output #0: loss = 0.0903607 (* 1 = 0.0903607 loss)
I0916 11:03:37.451264 19004 sgd_solver.cpp:136] Iteration 16900, lr = 0.01, m = 0.9
I0916 11:03:56.812789 19004 solver.cpp:314] Iteration 17000 (5.16501 iter/s, 19.361s/100 iter), loss = 0.150512
I0916 11:03:56.812855 19004 solver.cpp:336]     Train net output #0: loss = 0.150512 (* 1 = 0.150512 loss)
I0916 11:03:56.812862 19004 sgd_solver.cpp:136] Iteration 17000, lr = 0.01, m = 0.9
I0916 11:04:00.640914 19010 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 11:04:16.529083 19004 solver.cpp:314] Iteration 17100 (5.07209 iter/s, 19.7158s/100 iter), loss = 0.127642
I0916 11:04:16.529181 19004 solver.cpp:336]     Train net output #0: loss = 0.127642 (* 1 = 0.127642 loss)
I0916 11:04:16.529188 19004 sgd_solver.cpp:136] Iteration 17100, lr = 0.01, m = 0.9
I0916 11:04:35.962091 19004 solver.cpp:314] Iteration 17200 (5.14603 iter/s, 19.4325s/100 iter), loss = 0.105141
I0916 11:04:35.962154 19004 solver.cpp:336]     Train net output #0: loss = 0.105141 (* 1 = 0.105141 loss)
I0916 11:04:35.962162 19004 sgd_solver.cpp:136] Iteration 17200, lr = 0.01, m = 0.9
I0916 11:04:55.601994 19004 solver.cpp:314] Iteration 17300 (5.09181 iter/s, 19.6394s/100 iter), loss = 0.0791848
I0916 11:04:55.602017 19004 solver.cpp:336]     Train net output #0: loss = 0.0791847 (* 1 = 0.0791847 loss)
I0916 11:04:55.602021 19004 sgd_solver.cpp:136] Iteration 17300, lr = 0.01, m = 0.9
I0916 11:05:05.458530 19007 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 11:05:15.036149 19004 solver.cpp:314] Iteration 17400 (5.14572 iter/s, 19.4336s/100 iter), loss = 0.0663351
I0916 11:05:15.036203 19004 solver.cpp:336]     Train net output #0: loss = 0.0663351 (* 1 = 0.0663351 loss)
I0916 11:05:15.036208 19004 sgd_solver.cpp:136] Iteration 17400, lr = 0.01, m = 0.9
I0916 11:05:34.636826 19004 solver.cpp:314] Iteration 17500 (5.102 iter/s, 19.6001s/100 iter), loss = 0.0783707
I0916 11:05:34.636889 19004 solver.cpp:336]     Train net output #0: loss = 0.0783707 (* 1 = 0.0783707 loss)
I0916 11:05:34.636906 19004 sgd_solver.cpp:136] Iteration 17500, lr = 0.01, m = 0.9
I0916 11:05:37.663575 19007 data_reader.cpp:305] Starting prefetch of epoch 10
I0916 11:05:54.033983 19004 solver.cpp:314] Iteration 17600 (5.15554 iter/s, 19.3966s/100 iter), loss = 0.137471
I0916 11:05:54.034031 19004 solver.cpp:336]     Train net output #0: loss = 0.137471 (* 1 = 0.137471 loss)
I0916 11:05:54.034039 19004 sgd_solver.cpp:136] Iteration 17600, lr = 0.01, m = 0.9
I0916 11:06:13.447903 19004 solver.cpp:314] Iteration 17700 (5.15108 iter/s, 19.4134s/100 iter), loss = 0.0806219
I0916 11:06:13.447926 19004 solver.cpp:336]     Train net output #0: loss = 0.0806219 (* 1 = 0.0806219 loss)
I0916 11:06:13.447932 19004 sgd_solver.cpp:136] Iteration 17700, lr = 0.01, m = 0.9
I0916 11:06:33.282054 19004 solver.cpp:314] Iteration 17800 (5.04195 iter/s, 19.8336s/100 iter), loss = 0.0788019
I0916 11:06:33.282102 19004 solver.cpp:336]     Train net output #0: loss = 0.0788019 (* 1 = 0.0788019 loss)
I0916 11:06:33.282109 19004 sgd_solver.cpp:136] Iteration 17800, lr = 0.01, m = 0.9
I0916 11:06:42.188200 19007 data_reader.cpp:305] Starting prefetch of epoch 11
I0916 11:06:52.606729 19004 solver.cpp:314] Iteration 17900 (5.17487 iter/s, 19.3241s/100 iter), loss = 0.104518
I0916 11:06:52.606756 19004 solver.cpp:336]     Train net output #0: loss = 0.104518 (* 1 = 0.104518 loss)
I0916 11:06:52.606761 19004 sgd_solver.cpp:136] Iteration 17900, lr = 0.01, m = 0.9
I0916 11:07:11.646136 19004 solver.cpp:563] Iteration 18000, Testing net (#0)
I0916 11:07:22.742477 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.944849
I0916 11:07:22.742498 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 11:07:22.742504 19004 solver.cpp:655]     Test net output #2: loss = 0.177816 (* 1 = 0.177816 loss)
I0916 11:07:22.742528 19004 solver.cpp:265] [MultiGPU] Tests completed in 11.0961s
I0916 11:07:22.959930 19004 solver.cpp:314] Iteration 18000 (3.29464 iter/s, 30.3524s/100 iter), loss = 0.112142
I0916 11:07:22.959952 19004 solver.cpp:336]     Train net output #0: loss = 0.112142 (* 1 = 0.112142 loss)
I0916 11:07:22.959957 19004 sgd_solver.cpp:136] Iteration 18000, lr = 0.01, m = 0.9
I0916 11:07:25.276733 19010 data_reader.cpp:305] Starting prefetch of epoch 10
I0916 11:07:42.171377 19004 solver.cpp:314] Iteration 18100 (5.20537 iter/s, 19.2109s/100 iter), loss = 0.0769172
I0916 11:07:42.171454 19004 solver.cpp:336]     Train net output #0: loss = 0.0769172 (* 1 = 0.0769172 loss)
I0916 11:07:42.171461 19004 sgd_solver.cpp:136] Iteration 18100, lr = 0.01, m = 0.9
I0916 11:07:57.255911 18961 data_reader.cpp:305] Starting prefetch of epoch 11
I0916 11:08:01.742732 19004 solver.cpp:314] Iteration 18200 (5.10965 iter/s, 19.5708s/100 iter), loss = 0.0866709
I0916 11:08:01.742755 19004 solver.cpp:336]     Train net output #0: loss = 0.0866709 (* 1 = 0.0866709 loss)
I0916 11:08:01.742759 19004 sgd_solver.cpp:136] Iteration 18200, lr = 0.01, m = 0.9
I0916 11:08:21.251000 19004 solver.cpp:314] Iteration 18300 (5.12617 iter/s, 19.5077s/100 iter), loss = 0.106051
I0916 11:08:21.251061 19004 solver.cpp:336]     Train net output #0: loss = 0.106051 (* 1 = 0.106051 loss)
I0916 11:08:21.251070 19004 sgd_solver.cpp:136] Iteration 18300, lr = 0.01, m = 0.9
I0916 11:08:40.508097 19004 solver.cpp:314] Iteration 18400 (5.19303 iter/s, 19.2566s/100 iter), loss = 0.0722597
I0916 11:08:40.508124 19004 solver.cpp:336]     Train net output #0: loss = 0.0722596 (* 1 = 0.0722596 loss)
I0916 11:08:40.508131 19004 sgd_solver.cpp:136] Iteration 18400, lr = 0.01, m = 0.9
I0916 11:08:59.969256 19004 solver.cpp:314] Iteration 18500 (5.13858 iter/s, 19.4606s/100 iter), loss = 0.187598
I0916 11:08:59.969317 19004 solver.cpp:336]     Train net output #0: loss = 0.187598 (* 1 = 0.187598 loss)
I0916 11:08:59.969323 19004 sgd_solver.cpp:136] Iteration 18500, lr = 0.01, m = 0.9
I0916 11:09:01.560370 18961 data_reader.cpp:305] Starting prefetch of epoch 12
I0916 11:09:19.538789 19004 solver.cpp:314] Iteration 18600 (5.11012 iter/s, 19.569s/100 iter), loss = 0.110497
I0916 11:09:19.538813 19004 solver.cpp:336]     Train net output #0: loss = 0.110497 (* 1 = 0.110497 loss)
I0916 11:09:19.538820 19004 sgd_solver.cpp:136] Iteration 18600, lr = 0.01, m = 0.9
I0916 11:09:39.215066 19004 solver.cpp:314] Iteration 18700 (5.0824 iter/s, 19.6757s/100 iter), loss = 0.0542315
I0916 11:09:39.215117 19004 solver.cpp:336]     Train net output #0: loss = 0.0542314 (* 1 = 0.0542314 loss)
I0916 11:09:39.215123 19004 sgd_solver.cpp:136] Iteration 18700, lr = 0.01, m = 0.9
I0916 11:09:59.210119 19004 solver.cpp:314] Iteration 18800 (5.00137 iter/s, 19.9945s/100 iter), loss = 0.287081
I0916 11:09:59.210144 19004 solver.cpp:336]     Train net output #0: loss = 0.287081 (* 1 = 0.287081 loss)
I0916 11:09:59.210147 19004 sgd_solver.cpp:136] Iteration 18800, lr = 0.01, m = 0.9
I0916 11:10:06.670236 19012 data_reader.cpp:305] Starting prefetch of epoch 13
I0916 11:10:18.688239 19004 solver.cpp:314] Iteration 18900 (5.13411 iter/s, 19.4776s/100 iter), loss = 0.0939031
I0916 11:10:18.688302 19004 solver.cpp:336]     Train net output #0: loss = 0.0939031 (* 1 = 0.0939031 loss)
I0916 11:10:18.688309 19004 sgd_solver.cpp:136] Iteration 18900, lr = 0.01, m = 0.9
I0916 11:10:38.218438 19004 solver.cpp:314] Iteration 19000 (5.12042 iter/s, 19.5297s/100 iter), loss = 0.181517
I0916 11:10:38.218467 19004 solver.cpp:336]     Train net output #0: loss = 0.181517 (* 1 = 0.181517 loss)
I0916 11:10:38.218472 19004 sgd_solver.cpp:136] Iteration 19000, lr = 0.01, m = 0.9
I0916 11:10:38.872537 19008 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 11:10:57.920287 19004 solver.cpp:314] Iteration 19100 (5.0758 iter/s, 19.7013s/100 iter), loss = 0.0679574
I0916 11:10:57.920343 19004 solver.cpp:336]     Train net output #0: loss = 0.0679574 (* 1 = 0.0679574 loss)
I0916 11:10:57.920351 19004 sgd_solver.cpp:136] Iteration 19100, lr = 0.01, m = 0.9
I0916 11:11:17.283514 19004 solver.cpp:314] Iteration 19200 (5.16457 iter/s, 19.3627s/100 iter), loss = 0.107456
I0916 11:11:17.283540 19004 solver.cpp:336]     Train net output #0: loss = 0.107456 (* 1 = 0.107456 loss)
I0916 11:11:17.283546 19004 sgd_solver.cpp:136] Iteration 19200, lr = 0.01, m = 0.9
I0916 11:11:36.574302 19004 solver.cpp:314] Iteration 19300 (5.18396 iter/s, 19.2903s/100 iter), loss = 0.113985
I0916 11:11:36.574406 19004 solver.cpp:336]     Train net output #0: loss = 0.113985 (* 1 = 0.113985 loss)
I0916 11:11:36.574422 19004 sgd_solver.cpp:136] Iteration 19300, lr = 0.01, m = 0.9
I0916 11:11:43.190083 18961 data_reader.cpp:305] Starting prefetch of epoch 13
I0916 11:11:56.182646 19004 solver.cpp:314] Iteration 19400 (5.10001 iter/s, 19.6078s/100 iter), loss = 0.123967
I0916 11:11:56.182672 19004 solver.cpp:336]     Train net output #0: loss = 0.123967 (* 1 = 0.123967 loss)
I0916 11:11:56.182678 19004 sgd_solver.cpp:136] Iteration 19400, lr = 0.01, m = 0.9
I0916 11:12:15.628237 19004 solver.cpp:314] Iteration 19500 (5.14269 iter/s, 19.4451s/100 iter), loss = 0.0833506
I0916 11:12:15.628280 19004 solver.cpp:336]     Train net output #0: loss = 0.0833506 (* 1 = 0.0833506 loss)
I0916 11:12:15.628288 19004 sgd_solver.cpp:136] Iteration 19500, lr = 0.01, m = 0.9
I0916 11:12:35.060911 19004 solver.cpp:314] Iteration 19600 (5.14611 iter/s, 19.4321s/100 iter), loss = 0.0882402
I0916 11:12:35.060935 19004 solver.cpp:336]     Train net output #0: loss = 0.0882401 (* 1 = 0.0882401 loss)
I0916 11:12:35.060942 19004 sgd_solver.cpp:136] Iteration 19600, lr = 0.01, m = 0.9
I0916 11:12:47.821256 19007 data_reader.cpp:305] Starting prefetch of epoch 12
I0916 11:12:54.732020 19004 solver.cpp:314] Iteration 19700 (5.08374 iter/s, 19.6706s/100 iter), loss = 0.730041
I0916 11:12:54.732043 19004 solver.cpp:336]     Train net output #0: loss = 0.730041 (* 1 = 0.730041 loss)
I0916 11:12:54.732050 19004 sgd_solver.cpp:136] Iteration 19700, lr = 0.01, m = 0.9
I0916 11:13:14.171407 19004 solver.cpp:314] Iteration 19800 (5.14434 iter/s, 19.4389s/100 iter), loss = 0.0918919
I0916 11:13:14.171429 19004 solver.cpp:336]     Train net output #0: loss = 0.0918918 (* 1 = 0.0918918 loss)
I0916 11:13:14.171433 19004 sgd_solver.cpp:136] Iteration 19800, lr = 0.01, m = 0.9
I0916 11:13:19.951445 19007 data_reader.cpp:305] Starting prefetch of epoch 13
I0916 11:13:33.502849 19004 solver.cpp:314] Iteration 19900 (5.17306 iter/s, 19.3309s/100 iter), loss = 0.0914742
I0916 11:13:33.502873 19004 solver.cpp:336]     Train net output #0: loss = 0.0914741 (* 1 = 0.0914741 loss)
I0916 11:13:33.502877 19004 sgd_solver.cpp:136] Iteration 19900, lr = 0.01, m = 0.9
I0916 11:13:52.732362 19004 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/cityscapes5_jsegnet21v2_iter_20000.caffemodel
I0916 11:13:52.788523 19004 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/cityscapes5_jsegnet21v2_iter_20000.solverstate
I0916 11:13:52.792593 19004 solver.cpp:563] Iteration 20000, Testing net (#0)
I0916 11:13:56.195498 19016 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 11:14:04.158217 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.951586
I0916 11:14:04.158237 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 11:14:04.158242 19004 solver.cpp:655]     Test net output #2: loss = 0.138797 (* 1 = 0.138797 loss)
I0916 11:14:04.158277 19004 solver.cpp:265] [MultiGPU] Tests completed in 11.3654s
I0916 11:14:04.371665 19004 solver.cpp:314] Iteration 20000 (3.2396 iter/s, 30.868s/100 iter), loss = 0.062709
I0916 11:14:04.371693 19004 solver.cpp:336]     Train net output #0: loss = 0.0627089 (* 1 = 0.0627089 loss)
I0916 11:14:04.371701 19004 sgd_solver.cpp:136] Iteration 20000, lr = 0.01, m = 0.9
I0916 11:14:23.467008 19004 solver.cpp:314] Iteration 20100 (5.23702 iter/s, 19.0948s/100 iter), loss = 0.0572674
I0916 11:14:23.467061 19004 solver.cpp:336]     Train net output #0: loss = 0.0572673 (* 1 = 0.0572673 loss)
I0916 11:14:23.467068 19004 sgd_solver.cpp:136] Iteration 20100, lr = 0.01, m = 0.9
I0916 11:14:35.068130 18963 data_reader.cpp:305] Starting prefetch of epoch 16
I0916 11:14:42.862622 19004 solver.cpp:314] Iteration 20200 (5.15595 iter/s, 19.3951s/100 iter), loss = 0.113584
I0916 11:14:42.862649 19004 solver.cpp:336]     Train net output #0: loss = 0.113584 (* 1 = 0.113584 loss)
I0916 11:14:42.862655 19004 sgd_solver.cpp:136] Iteration 20200, lr = 0.01, m = 0.9
I0916 11:15:02.418579 19004 solver.cpp:314] Iteration 20300 (5.11367 iter/s, 19.5554s/100 iter), loss = 0.0904229
I0916 11:15:02.418645 19004 solver.cpp:336]     Train net output #0: loss = 0.0904228 (* 1 = 0.0904228 loss)
I0916 11:15:02.418650 19004 sgd_solver.cpp:136] Iteration 20300, lr = 0.01, m = 0.9
I0916 11:15:07.655403 19008 data_reader.cpp:305] Starting prefetch of epoch 10
I0916 11:15:21.977568 19004 solver.cpp:314] Iteration 20400 (5.11288 iter/s, 19.5584s/100 iter), loss = 0.119749
I0916 11:15:21.977598 19004 solver.cpp:336]     Train net output #0: loss = 0.119749 (* 1 = 0.119749 loss)
I0916 11:15:21.977602 19004 sgd_solver.cpp:136] Iteration 20400, lr = 0.01, m = 0.9
I0916 11:15:41.453006 19004 solver.cpp:314] Iteration 20500 (5.13481 iter/s, 19.4749s/100 iter), loss = 0.0763197
I0916 11:15:41.453063 19004 solver.cpp:336]     Train net output #0: loss = 0.0763197 (* 1 = 0.0763197 loss)
I0916 11:15:41.453068 19004 sgd_solver.cpp:136] Iteration 20500, lr = 0.01, m = 0.9
I0916 11:16:01.066308 19004 solver.cpp:314] Iteration 20600 (5.09872 iter/s, 19.6128s/100 iter), loss = 0.0808236
I0916 11:16:01.066329 19004 solver.cpp:336]     Train net output #0: loss = 0.0808235 (* 1 = 0.0808235 loss)
I0916 11:16:01.066335 19004 sgd_solver.cpp:136] Iteration 20600, lr = 0.01, m = 0.9
I0916 11:16:12.107765 18961 data_reader.cpp:305] Starting prefetch of epoch 14
I0916 11:16:20.643522 19004 solver.cpp:314] Iteration 20700 (5.10812 iter/s, 19.5767s/100 iter), loss = 0.0712318
I0916 11:16:20.643549 19004 solver.cpp:336]     Train net output #0: loss = 0.0712316 (* 1 = 0.0712316 loss)
I0916 11:16:20.643556 19004 sgd_solver.cpp:136] Iteration 20700, lr = 0.01, m = 0.9
I0916 11:16:39.912904 19004 solver.cpp:314] Iteration 20800 (5.18972 iter/s, 19.2689s/100 iter), loss = 0.0592448
I0916 11:16:39.912955 19004 solver.cpp:336]     Train net output #0: loss = 0.0592447 (* 1 = 0.0592447 loss)
I0916 11:16:39.912968 19004 sgd_solver.cpp:136] Iteration 20800, lr = 0.01, m = 0.9
I0916 11:16:59.262141 19004 solver.cpp:314] Iteration 20900 (5.1683 iter/s, 19.3487s/100 iter), loss = 0.0635613
I0916 11:16:59.262198 19004 solver.cpp:336]     Train net output #0: loss = 0.0635612 (* 1 = 0.0635612 loss)
I0916 11:16:59.262207 19004 sgd_solver.cpp:136] Iteration 20900, lr = 0.01, m = 0.9
I0916 11:17:16.241078 18963 data_reader.cpp:305] Starting prefetch of epoch 17
I0916 11:17:18.708770 19004 solver.cpp:314] Iteration 21000 (5.14242 iter/s, 19.4461s/100 iter), loss = 0.112834
I0916 11:17:18.708796 19004 solver.cpp:336]     Train net output #0: loss = 0.112834 (* 1 = 0.112834 loss)
I0916 11:17:18.708802 19004 sgd_solver.cpp:136] Iteration 21000, lr = 0.01, m = 0.9
I0916 11:17:38.055954 19004 solver.cpp:314] Iteration 21100 (5.16885 iter/s, 19.3467s/100 iter), loss = 0.0826497
I0916 11:17:38.056062 19004 solver.cpp:336]     Train net output #0: loss = 0.0826496 (* 1 = 0.0826496 loss)
I0916 11:17:38.056069 19004 sgd_solver.cpp:136] Iteration 21100, lr = 0.01, m = 0.9
I0916 11:17:48.245574 19008 data_reader.cpp:305] Starting prefetch of epoch 11
I0916 11:17:57.594060 19004 solver.cpp:314] Iteration 21200 (5.11834 iter/s, 19.5376s/100 iter), loss = 0.193768
I0916 11:17:57.594094 19004 solver.cpp:336]     Train net output #0: loss = 0.193768 (* 1 = 0.193768 loss)
I0916 11:17:57.594099 19004 sgd_solver.cpp:136] Iteration 21200, lr = 0.01, m = 0.9
I0916 11:18:17.057971 19004 solver.cpp:314] Iteration 21300 (5.13786 iter/s, 19.4634s/100 iter), loss = 0.0943797
I0916 11:18:17.058027 19004 solver.cpp:336]     Train net output #0: loss = 0.0943795 (* 1 = 0.0943795 loss)
I0916 11:18:17.058033 19004 sgd_solver.cpp:136] Iteration 21300, lr = 0.01, m = 0.9
I0916 11:18:36.478291 19004 solver.cpp:314] Iteration 21400 (5.14939 iter/s, 19.4198s/100 iter), loss = 0.0848796
I0916 11:18:36.478313 19004 solver.cpp:336]     Train net output #0: loss = 0.0848794 (* 1 = 0.0848794 loss)
I0916 11:18:36.478318 19004 sgd_solver.cpp:136] Iteration 21400, lr = 0.01, m = 0.9
I0916 11:18:52.748723 18961 data_reader.cpp:305] Starting prefetch of epoch 15
I0916 11:18:55.971124 19004 solver.cpp:314] Iteration 21500 (5.13023 iter/s, 19.4923s/100 iter), loss = 0.0950744
I0916 11:18:55.971153 19004 solver.cpp:336]     Train net output #0: loss = 0.0950742 (* 1 = 0.0950742 loss)
I0916 11:18:55.971159 19004 sgd_solver.cpp:136] Iteration 21500, lr = 0.01, m = 0.9
I0916 11:19:15.353915 19004 solver.cpp:314] Iteration 21600 (5.15936 iter/s, 19.3823s/100 iter), loss = 0.105046
I0916 11:19:15.353941 19004 solver.cpp:336]     Train net output #0: loss = 0.105046 (* 1 = 0.105046 loss)
I0916 11:19:15.353946 19004 sgd_solver.cpp:136] Iteration 21600, lr = 0.01, m = 0.9
I0916 11:19:35.159073 19004 solver.cpp:314] Iteration 21700 (5.04933 iter/s, 19.8046s/100 iter), loss = 0.0997847
I0916 11:19:35.162142 19004 solver.cpp:336]     Train net output #0: loss = 0.0997845 (* 1 = 0.0997845 loss)
I0916 11:19:35.162163 19004 sgd_solver.cpp:136] Iteration 21700, lr = 0.01, m = 0.9
I0916 11:19:54.790940 19004 solver.cpp:314] Iteration 21800 (5.0939 iter/s, 19.6313s/100 iter), loss = 0.102004
I0916 11:19:54.790969 19004 solver.cpp:336]     Train net output #0: loss = 0.102004 (* 1 = 0.102004 loss)
I0916 11:19:54.790976 19004 sgd_solver.cpp:136] Iteration 21800, lr = 0.01, m = 0.9
I0916 11:19:57.375038 19010 data_reader.cpp:305] Starting prefetch of epoch 11
I0916 11:20:14.081634 19004 solver.cpp:314] Iteration 21900 (5.18399 iter/s, 19.2902s/100 iter), loss = 0.107717
I0916 11:20:14.081686 19004 solver.cpp:336]     Train net output #0: loss = 0.107717 (* 1 = 0.107717 loss)
I0916 11:20:14.081691 19004 sgd_solver.cpp:136] Iteration 21900, lr = 0.01, m = 0.9
I0916 11:20:29.620335 19010 data_reader.cpp:305] Starting prefetch of epoch 12
I0916 11:20:34.162601 19004 solver.cpp:563] Iteration 22000, Testing net (#0)
I0916 11:20:46.075126 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.947486
I0916 11:20:46.075213 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 11:20:46.075222 19004 solver.cpp:655]     Test net output #2: loss = 0.149737 (* 1 = 0.149737 loss)
I0916 11:20:46.075248 19004 solver.cpp:265] [MultiGPU] Tests completed in 11.9123s
I0916 11:20:46.282804 19004 solver.cpp:314] Iteration 22000 (3.10556 iter/s, 32.2003s/100 iter), loss = 0.112336
I0916 11:20:46.282825 19004 solver.cpp:336]     Train net output #0: loss = 0.112336 (* 1 = 0.112336 loss)
I0916 11:20:46.282831 19004 sgd_solver.cpp:136] Iteration 22000, lr = 0.01, m = 0.9
I0916 11:21:05.389984 19004 solver.cpp:314] Iteration 22100 (5.23378 iter/s, 19.1067s/100 iter), loss = 0.114942
I0916 11:21:05.390007 19004 solver.cpp:336]     Train net output #0: loss = 0.114942 (* 1 = 0.114942 loss)
I0916 11:21:05.390012 19004 sgd_solver.cpp:136] Iteration 22100, lr = 0.01, m = 0.9
I0916 11:21:13.931991 18963 data_reader.cpp:305] Starting prefetch of epoch 18
I0916 11:21:24.871280 19004 solver.cpp:314] Iteration 22200 (5.13327 iter/s, 19.4808s/100 iter), loss = 0.0995273
I0916 11:21:24.871337 19004 solver.cpp:336]     Train net output #0: loss = 0.0995272 (* 1 = 0.0995272 loss)
I0916 11:21:24.871343 19004 sgd_solver.cpp:136] Iteration 22200, lr = 0.01, m = 0.9
I0916 11:21:44.307334 19004 solver.cpp:314] Iteration 22300 (5.14522 iter/s, 19.4355s/100 iter), loss = 0.0567039
I0916 11:21:44.307358 19004 solver.cpp:336]     Train net output #0: loss = 0.0567038 (* 1 = 0.0567038 loss)
I0916 11:21:44.307365 19004 sgd_solver.cpp:136] Iteration 22300, lr = 0.01, m = 0.9
I0916 11:22:03.814406 19004 solver.cpp:314] Iteration 22400 (5.12649 iter/s, 19.5065s/100 iter), loss = 0.0948211
I0916 11:22:03.814509 19004 solver.cpp:336]     Train net output #0: loss = 0.0948209 (* 1 = 0.0948209 loss)
I0916 11:22:03.814518 19004 sgd_solver.cpp:136] Iteration 22400, lr = 0.01, m = 0.9
I0916 11:22:17.898025 19010 data_reader.cpp:305] Starting prefetch of epoch 13
I0916 11:22:22.945638 19004 solver.cpp:314] Iteration 22500 (5.2272 iter/s, 19.1307s/100 iter), loss = 0.149314
I0916 11:22:22.945668 19004 solver.cpp:336]     Train net output #0: loss = 0.149314 (* 1 = 0.149314 loss)
I0916 11:22:22.945675 19004 sgd_solver.cpp:136] Iteration 22500, lr = 0.01, m = 0.9
I0916 11:22:42.134775 19004 solver.cpp:314] Iteration 22600 (5.21143 iter/s, 19.1886s/100 iter), loss = 0.0903213
I0916 11:22:42.134845 19004 solver.cpp:336]     Train net output #0: loss = 0.0903212 (* 1 = 0.0903212 loss)
I0916 11:22:42.134850 19004 sgd_solver.cpp:136] Iteration 22600, lr = 0.01, m = 0.9
I0916 11:22:49.873857 19008 data_reader.cpp:305] Starting prefetch of epoch 12
I0916 11:23:01.549895 19004 solver.cpp:314] Iteration 22700 (5.15077 iter/s, 19.4146s/100 iter), loss = 0.101102
I0916 11:23:01.549947 19004 solver.cpp:336]     Train net output #0: loss = 0.101102 (* 1 = 0.101102 loss)
I0916 11:23:01.549955 19004 sgd_solver.cpp:136] Iteration 22700, lr = 0.01, m = 0.9
I0916 11:23:20.988574 19004 solver.cpp:314] Iteration 22800 (5.14452 iter/s, 19.4381s/100 iter), loss = 0.0484458
I0916 11:23:20.988626 19004 solver.cpp:336]     Train net output #0: loss = 0.0484457 (* 1 = 0.0484457 loss)
I0916 11:23:20.988631 19004 sgd_solver.cpp:136] Iteration 22800, lr = 0.01, m = 0.9
I0916 11:23:40.489250 19004 solver.cpp:314] Iteration 22900 (5.12817 iter/s, 19.5001s/100 iter), loss = 0.102237
I0916 11:23:40.489271 19004 solver.cpp:336]     Train net output #0: loss = 0.102237 (* 1 = 0.102237 loss)
I0916 11:23:40.489276 19004 sgd_solver.cpp:136] Iteration 22900, lr = 0.01, m = 0.9
I0916 11:23:54.111796 19008 data_reader.cpp:305] Starting prefetch of epoch 13
I0916 11:24:00.406067 19004 solver.cpp:314] Iteration 23000 (5.02102 iter/s, 19.9163s/100 iter), loss = 0.115022
I0916 11:24:00.406112 19004 solver.cpp:336]     Train net output #0: loss = 0.115022 (* 1 = 0.115022 loss)
I0916 11:24:00.406121 19004 sgd_solver.cpp:136] Iteration 23000, lr = 0.01, m = 0.9
I0916 11:24:20.249578 19004 solver.cpp:314] Iteration 23100 (5.03957 iter/s, 19.843s/100 iter), loss = 0.113483
I0916 11:24:20.249606 19004 solver.cpp:336]     Train net output #0: loss = 0.113483 (* 1 = 0.113483 loss)
I0916 11:24:20.249614 19004 sgd_solver.cpp:136] Iteration 23100, lr = 0.01, m = 0.9
I0916 11:24:39.631484 19004 solver.cpp:314] Iteration 23200 (5.15959 iter/s, 19.3814s/100 iter), loss = 0.143317
I0916 11:24:39.631531 19004 solver.cpp:336]     Train net output #0: loss = 0.143317 (* 1 = 0.143317 loss)
I0916 11:24:39.631537 19004 sgd_solver.cpp:136] Iteration 23200, lr = 0.01, m = 0.9
I0916 11:24:59.171294 19004 solver.cpp:314] Iteration 23300 (5.1179 iter/s, 19.5393s/100 iter), loss = 0.0461463
I0916 11:24:59.171319 19004 solver.cpp:336]     Train net output #0: loss = 0.0461463 (* 1 = 0.0461463 loss)
I0916 11:24:59.171322 19004 sgd_solver.cpp:136] Iteration 23300, lr = 0.01, m = 0.9
I0916 11:24:59.378068 19007 data_reader.cpp:305] Starting prefetch of epoch 14
I0916 11:25:18.607399 19004 solver.cpp:314] Iteration 23400 (5.14521 iter/s, 19.4356s/100 iter), loss = 0.086673
I0916 11:25:18.607447 19004 solver.cpp:336]     Train net output #0: loss = 0.086673 (* 1 = 0.086673 loss)
I0916 11:25:18.607455 19004 sgd_solver.cpp:136] Iteration 23400, lr = 0.01, m = 0.9
I0916 11:25:31.384083 19007 data_reader.cpp:305] Starting prefetch of epoch 15
I0916 11:25:37.939251 19004 solver.cpp:314] Iteration 23500 (5.17295 iter/s, 19.3313s/100 iter), loss = 0.281104
I0916 11:25:37.939276 19004 solver.cpp:336]     Train net output #0: loss = 0.281104 (* 1 = 0.281104 loss)
I0916 11:25:37.939282 19004 sgd_solver.cpp:136] Iteration 23500, lr = 0.01, m = 0.9
I0916 11:25:57.423384 19004 solver.cpp:314] Iteration 23600 (5.13252 iter/s, 19.4836s/100 iter), loss = 0.0498356
I0916 11:25:57.423439 19004 solver.cpp:336]     Train net output #0: loss = 0.0498355 (* 1 = 0.0498355 loss)
I0916 11:25:57.423444 19004 sgd_solver.cpp:136] Iteration 23600, lr = 0.01, m = 0.9
I0916 11:26:16.649631 19004 solver.cpp:314] Iteration 23700 (5.20137 iter/s, 19.2257s/100 iter), loss = 0.0708625
I0916 11:26:16.649652 19004 solver.cpp:336]     Train net output #0: loss = 0.0708625 (* 1 = 0.0708625 loss)
I0916 11:26:16.649655 19004 sgd_solver.cpp:136] Iteration 23700, lr = 0.01, m = 0.9
I0916 11:26:35.334312 19007 data_reader.cpp:305] Starting prefetch of epoch 16
I0916 11:26:36.067112 19004 solver.cpp:314] Iteration 23800 (5.15014 iter/s, 19.4169s/100 iter), loss = 0.148399
I0916 11:26:36.067133 19004 solver.cpp:336]     Train net output #0: loss = 0.148399 (* 1 = 0.148399 loss)
I0916 11:26:36.067137 19004 sgd_solver.cpp:136] Iteration 23800, lr = 0.01, m = 0.9
I0916 11:26:55.176156 19004 solver.cpp:314] Iteration 23900 (5.23327 iter/s, 19.1085s/100 iter), loss = 0.0743621
I0916 11:26:55.176185 19004 solver.cpp:336]     Train net output #0: loss = 0.0743621 (* 1 = 0.0743621 loss)
I0916 11:26:55.176192 19004 sgd_solver.cpp:136] Iteration 23900, lr = 0.01, m = 0.9
I0916 11:27:14.442844 19004 solver.cpp:563] Iteration 24000, Testing net (#0)
I0916 11:27:17.800866 19029 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 11:27:25.924607 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.946255
I0916 11:27:25.924628 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 11:27:25.924633 19004 solver.cpp:655]     Test net output #2: loss = 0.171236 (* 1 = 0.171236 loss)
I0916 11:27:25.924657 19004 solver.cpp:265] [MultiGPU] Tests completed in 11.4815s
I0916 11:27:26.134559 19004 solver.cpp:314] Iteration 24000 (3.23023 iter/s, 30.9576s/100 iter), loss = 0.0849195
I0916 11:27:26.134582 19004 solver.cpp:336]     Train net output #0: loss = 0.0849195 (* 1 = 0.0849195 loss)
I0916 11:27:26.134587 19004 sgd_solver.cpp:136] Iteration 24000, lr = 0.01, m = 0.9
I0916 11:27:46.206611 19004 solver.cpp:314] Iteration 24100 (4.98219 iter/s, 20.0715s/100 iter), loss = 0.106
I0916 11:27:46.206665 19004 solver.cpp:336]     Train net output #0: loss = 0.106 (* 1 = 0.106 loss)
I0916 11:27:46.206670 19004 sgd_solver.cpp:136] Iteration 24100, lr = 0.01, m = 0.9
I0916 11:27:51.507191 19012 data_reader.cpp:305] Starting prefetch of epoch 14
I0916 11:28:06.462942 19004 solver.cpp:314] Iteration 24200 (4.93687 iter/s, 20.2558s/100 iter), loss = 0.230969
I0916 11:28:06.462970 19004 solver.cpp:336]     Train net output #0: loss = 0.230969 (* 1 = 0.230969 loss)
I0916 11:28:06.462975 19004 sgd_solver.cpp:136] Iteration 24200, lr = 0.01, m = 0.9
I0916 11:28:25.520162 19007 data_reader.cpp:305] Starting prefetch of epoch 17
I0916 11:28:27.066939 19004 solver.cpp:314] Iteration 24300 (4.85356 iter/s, 20.6034s/100 iter), loss = 0.0560174
I0916 11:28:27.066963 19004 solver.cpp:336]     Train net output #0: loss = 0.0560173 (* 1 = 0.0560173 loss)
I0916 11:28:27.066967 19004 sgd_solver.cpp:136] Iteration 24300, lr = 0.01, m = 0.9
I0916 11:28:47.169654 19004 solver.cpp:314] Iteration 24400 (4.97459 iter/s, 20.1022s/100 iter), loss = 0.0978324
I0916 11:28:47.169682 19004 solver.cpp:336]     Train net output #0: loss = 0.0978324 (* 1 = 0.0978324 loss)
I0916 11:28:47.169688 19004 sgd_solver.cpp:136] Iteration 24400, lr = 0.01, m = 0.9
I0916 11:29:07.927520 19004 solver.cpp:314] Iteration 24500 (4.81759 iter/s, 20.7573s/100 iter), loss = 0.0705012
I0916 11:29:07.927649 19004 solver.cpp:336]     Train net output #0: loss = 0.0705012 (* 1 = 0.0705012 loss)
I0916 11:29:07.927666 19004 sgd_solver.cpp:136] Iteration 24500, lr = 0.01, m = 0.9
I0916 11:29:28.632725 19004 solver.cpp:314] Iteration 24600 (4.82984 iter/s, 20.7046s/100 iter), loss = 0.131597
I0916 11:29:28.632748 19004 solver.cpp:336]     Train net output #0: loss = 0.131596 (* 1 = 0.131596 loss)
I0916 11:29:28.632755 19004 sgd_solver.cpp:136] Iteration 24600, lr = 0.01, m = 0.9
I0916 11:29:33.221758 19012 data_reader.cpp:305] Starting prefetch of epoch 15
I0916 11:29:48.481806 19004 solver.cpp:314] Iteration 24700 (5.03816 iter/s, 19.8485s/100 iter), loss = 0.0760579
I0916 11:29:48.481887 19004 solver.cpp:336]     Train net output #0: loss = 0.0760579 (* 1 = 0.0760579 loss)
I0916 11:29:48.481892 19004 sgd_solver.cpp:136] Iteration 24700, lr = 0.01, m = 0.9
I0916 11:30:08.657415 19004 solver.cpp:314] Iteration 24800 (4.95662 iter/s, 20.1751s/100 iter), loss = 0.115852
I0916 11:30:08.657438 19004 solver.cpp:336]     Train net output #0: loss = 0.115852 (* 1 = 0.115852 loss)
I0916 11:30:08.657444 19004 sgd_solver.cpp:136] Iteration 24800, lr = 0.01, m = 0.9
I0916 11:30:28.795442 19004 solver.cpp:314] Iteration 24900 (4.96587 iter/s, 20.1375s/100 iter), loss = 0.067764
I0916 11:30:28.795684 19004 solver.cpp:336]     Train net output #0: loss = 0.0677639 (* 1 = 0.0677639 loss)
I0916 11:30:28.795691 19004 sgd_solver.cpp:136] Iteration 24900, lr = 0.01, m = 0.9
I0916 11:30:39.518532 18963 data_reader.cpp:305] Starting prefetch of epoch 19
I0916 11:30:48.731739 19004 solver.cpp:314] Iteration 25000 (5.01612 iter/s, 19.9357s/100 iter), loss = 0.108048
I0916 11:30:48.731761 19004 solver.cpp:336]     Train net output #0: loss = 0.108048 (* 1 = 0.108048 loss)
I0916 11:30:48.731765 19004 sgd_solver.cpp:136] Iteration 25000, lr = 0.01, m = 0.9
I0916 11:31:08.684629 19004 solver.cpp:314] Iteration 25100 (5.01194 iter/s, 19.9523s/100 iter), loss = 0.0834283
I0916 11:31:08.684721 19004 solver.cpp:336]     Train net output #0: loss = 0.0834282 (* 1 = 0.0834282 loss)
I0916 11:31:08.684727 19004 sgd_solver.cpp:136] Iteration 25100, lr = 0.01, m = 0.9
I0916 11:31:12.602031 19008 data_reader.cpp:305] Starting prefetch of epoch 14
I0916 11:31:29.313483 19004 solver.cpp:314] Iteration 25200 (4.84771 iter/s, 20.6283s/100 iter), loss = 0.109674
I0916 11:31:29.313518 19004 solver.cpp:336]     Train net output #0: loss = 0.109674 (* 1 = 0.109674 loss)
I0916 11:31:29.313524 19004 sgd_solver.cpp:136] Iteration 25200, lr = 0.01, m = 0.9
I0916 11:31:50.009573 19004 solver.cpp:314] Iteration 25300 (4.83196 iter/s, 20.6955s/100 iter), loss = 0.13061
I0916 11:31:50.009618 19004 solver.cpp:336]     Train net output #0: loss = 0.13061 (* 1 = 0.13061 loss)
I0916 11:31:50.009624 19004 sgd_solver.cpp:136] Iteration 25300, lr = 0.01, m = 0.9
I0916 11:32:09.532387 19004 solver.cpp:314] Iteration 25400 (5.12235 iter/s, 19.5223s/100 iter), loss = 0.0771163
I0916 11:32:09.532418 19004 solver.cpp:336]     Train net output #0: loss = 0.0771164 (* 1 = 0.0771164 loss)
I0916 11:32:09.532423 19004 sgd_solver.cpp:136] Iteration 25400, lr = 0.01, m = 0.9
I0916 11:32:19.489471 18961 data_reader.cpp:305] Starting prefetch of epoch 16
I0916 11:32:29.765548 19004 solver.cpp:314] Iteration 25500 (4.94252 iter/s, 20.2326s/100 iter), loss = 0.0694348
I0916 11:32:29.765615 19004 solver.cpp:336]     Train net output #0: loss = 0.0694349 (* 1 = 0.0694349 loss)
I0916 11:32:29.765622 19004 sgd_solver.cpp:136] Iteration 25500, lr = 0.01, m = 0.9
I0916 11:32:50.329080 19004 solver.cpp:314] Iteration 25600 (4.86311 iter/s, 20.563s/100 iter), loss = 0.132347
I0916 11:32:50.329133 19004 solver.cpp:336]     Train net output #0: loss = 0.132347 (* 1 = 0.132347 loss)
I0916 11:32:50.329160 19004 sgd_solver.cpp:136] Iteration 25600, lr = 0.01, m = 0.9
I0916 11:33:10.841533 19004 solver.cpp:314] Iteration 25700 (4.87522 iter/s, 20.5119s/100 iter), loss = 0.072308
I0916 11:33:10.841590 19004 solver.cpp:336]     Train net output #0: loss = 0.0723081 (* 1 = 0.0723081 loss)
I0916 11:33:10.841598 19004 sgd_solver.cpp:136] Iteration 25700, lr = 0.01, m = 0.9
I0916 11:33:27.156239 18963 data_reader.cpp:305] Starting prefetch of epoch 20
I0916 11:33:31.096879 19004 solver.cpp:314] Iteration 25800 (4.9371 iter/s, 20.2548s/100 iter), loss = 0.0813386
I0916 11:33:31.096905 19004 solver.cpp:336]     Train net output #0: loss = 0.0813387 (* 1 = 0.0813387 loss)
I0916 11:33:31.096911 19004 sgd_solver.cpp:136] Iteration 25800, lr = 0.01, m = 0.9
I0916 11:33:51.520588 19004 solver.cpp:314] Iteration 25900 (4.89641 iter/s, 20.4231s/100 iter), loss = 0.0553777
I0916 11:33:51.520648 19004 solver.cpp:336]     Train net output #0: loss = 0.0553778 (* 1 = 0.0553778 loss)
I0916 11:33:51.520655 19004 sgd_solver.cpp:136] Iteration 25900, lr = 0.01, m = 0.9
I0916 11:34:00.784720 19008 data_reader.cpp:305] Starting prefetch of epoch 15
I0916 11:34:12.142278 19004 solver.cpp:563] Iteration 26000, Testing net (#0)
I0916 11:34:23.448527 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.94955
I0916 11:34:23.448599 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 11:34:23.448606 19004 solver.cpp:655]     Test net output #2: loss = 0.161856 (* 1 = 0.161856 loss)
I0916 11:34:23.448626 19004 solver.cpp:265] [MultiGPU] Tests completed in 11.306s
I0916 11:34:23.664512 19004 solver.cpp:314] Iteration 26000 (3.11109 iter/s, 32.143s/100 iter), loss = 0.158268
I0916 11:34:23.664538 19004 solver.cpp:336]     Train net output #0: loss = 0.158269 (* 1 = 0.158269 loss)
I0916 11:34:23.664546 19004 sgd_solver.cpp:136] Iteration 26000, lr = 0.01, m = 0.9
I0916 11:34:44.003520 19004 solver.cpp:314] Iteration 26100 (4.9168 iter/s, 20.3384s/100 iter), loss = 0.0578341
I0916 11:34:44.003542 19004 solver.cpp:336]     Train net output #0: loss = 0.0578342 (* 1 = 0.0578342 loss)
I0916 11:34:44.003549 19004 sgd_solver.cpp:136] Iteration 26100, lr = 0.01, m = 0.9
I0916 11:34:46.085296 19007 data_reader.cpp:305] Starting prefetch of epoch 18
I0916 11:35:04.953131 19004 solver.cpp:314] Iteration 26200 (4.77349 iter/s, 20.949s/100 iter), loss = 0.125296
I0916 11:35:04.953183 19004 solver.cpp:336]     Train net output #0: loss = 0.125296 (* 1 = 0.125296 loss)
I0916 11:35:04.953191 19004 sgd_solver.cpp:136] Iteration 26200, lr = 0.01, m = 0.9
I0916 11:35:25.488675 19004 solver.cpp:314] Iteration 26300 (4.86974 iter/s, 20.535s/100 iter), loss = 0.0958327
I0916 11:35:25.488703 19004 solver.cpp:336]     Train net output #0: loss = 0.0958327 (* 1 = 0.0958327 loss)
I0916 11:35:25.488708 19004 sgd_solver.cpp:136] Iteration 26300, lr = 0.01, m = 0.9
I0916 11:35:45.690588 19004 solver.cpp:314] Iteration 26400 (4.95016 iter/s, 20.2014s/100 iter), loss = 0.110889
I0916 11:35:45.690636 19004 solver.cpp:336]     Train net output #0: loss = 0.11089 (* 1 = 0.11089 loss)
I0916 11:35:45.690642 19004 sgd_solver.cpp:136] Iteration 26400, lr = 0.01, m = 0.9
I0916 11:35:54.012444 19010 data_reader.cpp:305] Starting prefetch of epoch 14
I0916 11:36:06.411442 19004 solver.cpp:314] Iteration 26500 (4.82619 iter/s, 20.7203s/100 iter), loss = 0.0589385
I0916 11:36:06.411486 19004 solver.cpp:336]     Train net output #0: loss = 0.0589386 (* 1 = 0.0589386 loss)
I0916 11:36:06.411499 19004 sgd_solver.cpp:136] Iteration 26500, lr = 0.01, m = 0.9
I0916 11:36:26.915515 19004 solver.cpp:314] Iteration 26600 (4.87721 iter/s, 20.5035s/100 iter), loss = 0.0839463
I0916 11:36:26.915560 19004 solver.cpp:336]     Train net output #0: loss = 0.0839464 (* 1 = 0.0839464 loss)
I0916 11:36:26.915566 19004 sgd_solver.cpp:136] Iteration 26600, lr = 0.01, m = 0.9
I0916 11:36:28.237663 19007 data_reader.cpp:305] Starting prefetch of epoch 19
I0916 11:36:47.249421 19004 solver.cpp:314] Iteration 26700 (4.91803 iter/s, 20.3333s/100 iter), loss = 0.0799737
I0916 11:36:47.249447 19004 solver.cpp:336]     Train net output #0: loss = 0.0799737 (* 1 = 0.0799737 loss)
I0916 11:36:47.249452 19004 sgd_solver.cpp:136] Iteration 26700, lr = 0.01, m = 0.9
I0916 11:37:07.967133 19004 solver.cpp:314] Iteration 26800 (4.82692 iter/s, 20.7171s/100 iter), loss = 0.0981644
I0916 11:37:07.967190 19004 solver.cpp:336]     Train net output #0: loss = 0.0981645 (* 1 = 0.0981645 loss)
I0916 11:37:07.967200 19004 sgd_solver.cpp:136] Iteration 26800, lr = 0.01, m = 0.9
I0916 11:37:28.611177 19004 solver.cpp:314] Iteration 26900 (4.84415 iter/s, 20.6435s/100 iter), loss = 0.0641
I0916 11:37:28.611223 19004 solver.cpp:336]     Train net output #0: loss = 0.0641001 (* 1 = 0.0641001 loss)
I0916 11:37:28.611239 19004 sgd_solver.cpp:136] Iteration 26900, lr = 0.01, m = 0.9
I0916 11:37:36.103050 19012 data_reader.cpp:305] Starting prefetch of epoch 16
I0916 11:37:49.262274 19004 solver.cpp:314] Iteration 27000 (4.84249 iter/s, 20.6505s/100 iter), loss = 0.218264
I0916 11:37:49.262323 19004 solver.cpp:336]     Train net output #0: loss = 0.218264 (* 1 = 0.218264 loss)
I0916 11:37:49.262328 19004 sgd_solver.cpp:136] Iteration 27000, lr = 0.01, m = 0.9
I0916 11:38:10.042438 19004 solver.cpp:314] Iteration 27100 (4.81241 iter/s, 20.7796s/100 iter), loss = 0.0909182
I0916 11:38:10.042460 19004 solver.cpp:336]     Train net output #0: loss = 0.0909183 (* 1 = 0.0909183 loss)
I0916 11:38:10.042466 19004 sgd_solver.cpp:136] Iteration 27100, lr = 0.01, m = 0.9
I0916 11:38:31.009698 19004 solver.cpp:314] Iteration 27200 (4.76947 iter/s, 20.9667s/100 iter), loss = 0.0490077
I0916 11:38:31.009799 19004 solver.cpp:336]     Train net output #0: loss = 0.0490078 (* 1 = 0.0490078 loss)
I0916 11:38:31.009807 19004 sgd_solver.cpp:136] Iteration 27200, lr = 0.01, m = 0.9
I0916 11:38:44.780985 18963 data_reader.cpp:305] Starting prefetch of epoch 21
I0916 11:38:51.519454 19004 solver.cpp:314] Iteration 27300 (4.87587 iter/s, 20.5092s/100 iter), loss = 0.0830768
I0916 11:38:51.519497 19004 solver.cpp:336]     Train net output #0: loss = 0.0830769 (* 1 = 0.0830769 loss)
I0916 11:38:51.519505 19004 sgd_solver.cpp:136] Iteration 27300, lr = 0.01, m = 0.9
I0916 11:39:12.050724 19004 solver.cpp:314] Iteration 27400 (4.87075 iter/s, 20.5307s/100 iter), loss = 0.158808
I0916 11:39:12.050787 19004 solver.cpp:336]     Train net output #0: loss = 0.158808 (* 1 = 0.158808 loss)
I0916 11:39:12.050793 19004 sgd_solver.cpp:136] Iteration 27400, lr = 0.01, m = 0.9
I0916 11:39:19.110731 19008 data_reader.cpp:305] Starting prefetch of epoch 16
I0916 11:39:32.647251 19004 solver.cpp:314] Iteration 27500 (4.85532 iter/s, 20.5959s/100 iter), loss = 0.0650467
I0916 11:39:32.647302 19004 solver.cpp:336]     Train net output #0: loss = 0.0650467 (* 1 = 0.0650467 loss)
I0916 11:39:32.647311 19004 sgd_solver.cpp:136] Iteration 27500, lr = 0.01, m = 0.9
I0916 11:39:53.113906 19004 solver.cpp:314] Iteration 27600 (4.88613 iter/s, 20.4661s/100 iter), loss = 0.0862338
I0916 11:39:53.113960 19004 solver.cpp:336]     Train net output #0: loss = 0.0862339 (* 1 = 0.0862339 loss)
I0916 11:39:53.113966 19004 sgd_solver.cpp:136] Iteration 27600, lr = 0.01, m = 0.9
I0916 11:40:13.402979 19004 solver.cpp:314] Iteration 27700 (4.9289 iter/s, 20.2885s/100 iter), loss = 0.08861
I0916 11:40:13.403030 19004 solver.cpp:336]     Train net output #0: loss = 0.08861 (* 1 = 0.08861 loss)
I0916 11:40:13.403045 19004 sgd_solver.cpp:136] Iteration 27700, lr = 0.01, m = 0.9
I0916 11:40:26.562355 19012 data_reader.cpp:305] Starting prefetch of epoch 17
I0916 11:40:34.065846 19004 solver.cpp:314] Iteration 27800 (4.83973 iter/s, 20.6623s/100 iter), loss = 0.0583192
I0916 11:40:34.065870 19004 solver.cpp:336]     Train net output #0: loss = 0.0583192 (* 1 = 0.0583192 loss)
I0916 11:40:34.065874 19004 sgd_solver.cpp:136] Iteration 27800, lr = 0.01, m = 0.9
I0916 11:40:54.546118 19004 solver.cpp:314] Iteration 27900 (4.88288 iter/s, 20.4797s/100 iter), loss = 0.0688124
I0916 11:40:54.546155 19004 solver.cpp:336]     Train net output #0: loss = 0.0688124 (* 1 = 0.0688124 loss)
I0916 11:40:54.546162 19004 sgd_solver.cpp:136] Iteration 27900, lr = 0.01, m = 0.9
I0916 11:41:14.737171 19004 solver.cpp:563] Iteration 28000, Testing net (#0)
I0916 11:41:18.715306 19016 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 11:41:26.607183 19015 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 11:41:26.923120 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.948476
I0916 11:41:26.923141 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 11:41:26.923146 19004 solver.cpp:655]     Test net output #2: loss = 0.149547 (* 1 = 0.149547 loss)
I0916 11:41:26.923235 19004 solver.cpp:265] [MultiGPU] Tests completed in 12.1857s
I0916 11:41:27.123813 19004 solver.cpp:314] Iteration 28000 (3.06967 iter/s, 32.5768s/100 iter), loss = 0.0889437
I0916 11:41:27.123836 19004 solver.cpp:336]     Train net output #0: loss = 0.0889438 (* 1 = 0.0889438 loss)
I0916 11:41:27.123839 19004 sgd_solver.cpp:136] Iteration 28000, lr = 0.01, m = 0.9
I0916 11:41:47.445437 19004 solver.cpp:314] Iteration 28100 (4.921 iter/s, 20.3211s/100 iter), loss = 0.0731887
I0916 11:41:47.445484 19004 solver.cpp:336]     Train net output #0: loss = 0.0731887 (* 1 = 0.0731887 loss)
I0916 11:41:47.445489 19004 sgd_solver.cpp:136] Iteration 28100, lr = 0.01, m = 0.9
I0916 11:42:07.992055 19004 solver.cpp:314] Iteration 28200 (4.86712 iter/s, 20.546s/100 iter), loss = 0.0864373
I0916 11:42:07.992082 19004 solver.cpp:336]     Train net output #0: loss = 0.0864373 (* 1 = 0.0864373 loss)
I0916 11:42:07.992089 19004 sgd_solver.cpp:136] Iteration 28200, lr = 0.01, m = 0.9
I0916 11:42:19.911808 18961 data_reader.cpp:305] Starting prefetch of epoch 17
I0916 11:42:28.121193 19004 solver.cpp:314] Iteration 28300 (4.96806 iter/s, 20.1286s/100 iter), loss = 0.0592032
I0916 11:42:28.121217 19004 solver.cpp:336]     Train net output #0: loss = 0.0592033 (* 1 = 0.0592033 loss)
I0916 11:42:28.121220 19004 sgd_solver.cpp:136] Iteration 28300, lr = 0.01, m = 0.9
I0916 11:42:48.322854 19004 solver.cpp:314] Iteration 28400 (4.95023 iter/s, 20.2011s/100 iter), loss = 0.0827143
I0916 11:42:48.322878 19004 solver.cpp:336]     Train net output #0: loss = 0.0827144 (* 1 = 0.0827144 loss)
I0916 11:42:48.322883 19004 sgd_solver.cpp:136] Iteration 28400, lr = 0.01, m = 0.9
I0916 11:43:08.572684 19004 solver.cpp:314] Iteration 28500 (4.93845 iter/s, 20.2493s/100 iter), loss = 0.101832
I0916 11:43:08.572738 19004 solver.cpp:336]     Train net output #0: loss = 0.101832 (* 1 = 0.101832 loss)
I0916 11:43:08.572743 19004 sgd_solver.cpp:136] Iteration 28500, lr = 0.01, m = 0.9
I0916 11:43:26.526953 18963 data_reader.cpp:305] Starting prefetch of epoch 22
I0916 11:43:28.521960 19004 solver.cpp:314] Iteration 28600 (5.01285 iter/s, 19.9487s/100 iter), loss = 0.130048
I0916 11:43:28.521988 19004 solver.cpp:336]     Train net output #0: loss = 0.130048 (* 1 = 0.130048 loss)
I0916 11:43:28.521996 19004 sgd_solver.cpp:136] Iteration 28600, lr = 0.01, m = 0.9
I0916 11:43:48.934056 19004 solver.cpp:314] Iteration 28700 (4.89919 iter/s, 20.4115s/100 iter), loss = 0.130007
I0916 11:43:48.934155 19004 solver.cpp:336]     Train net output #0: loss = 0.130008 (* 1 = 0.130008 loss)
I0916 11:43:48.934170 19004 sgd_solver.cpp:136] Iteration 28700, lr = 0.01, m = 0.9
I0916 11:44:08.853981 19004 solver.cpp:314] Iteration 28800 (5.02024 iter/s, 19.9194s/100 iter), loss = 0.0678151
I0916 11:44:08.854007 19004 solver.cpp:336]     Train net output #0: loss = 0.0678152 (* 1 = 0.0678152 loss)
I0916 11:44:08.854012 19004 sgd_solver.cpp:136] Iteration 28800, lr = 0.01, m = 0.9
I0916 11:44:29.108660 19004 solver.cpp:314] Iteration 28900 (4.93727 iter/s, 20.2541s/100 iter), loss = 0.163231
I0916 11:44:29.108785 19004 solver.cpp:336]     Train net output #0: loss = 0.163231 (* 1 = 0.163231 loss)
I0916 11:44:29.108811 19004 sgd_solver.cpp:136] Iteration 28900, lr = 0.01, m = 0.9
I0916 11:44:33.300243 19010 data_reader.cpp:305] Starting prefetch of epoch 15
I0916 11:44:49.408746 19004 solver.cpp:314] Iteration 29000 (4.92622 iter/s, 20.2995s/100 iter), loss = 0.08669
I0916 11:44:49.408774 19004 solver.cpp:336]     Train net output #0: loss = 0.0866901 (* 1 = 0.0866901 loss)
I0916 11:44:49.408782 19004 sgd_solver.cpp:136] Iteration 29000, lr = 0.01, m = 0.9
I0916 11:45:06.762264 18961 data_reader.cpp:305] Starting prefetch of epoch 18
I0916 11:45:09.675858 19004 solver.cpp:314] Iteration 29100 (4.93424 iter/s, 20.2666s/100 iter), loss = 0.0804137
I0916 11:45:09.675881 19004 solver.cpp:336]     Train net output #0: loss = 0.0804137 (* 1 = 0.0804137 loss)
I0916 11:45:09.675885 19004 sgd_solver.cpp:136] Iteration 29100, lr = 0.01, m = 0.9
I0916 11:45:29.651255 19004 solver.cpp:314] Iteration 29200 (5.0063 iter/s, 19.9748s/100 iter), loss = 0.0649198
I0916 11:45:29.651283 19004 solver.cpp:336]     Train net output #0: loss = 0.0649199 (* 1 = 0.0649199 loss)
I0916 11:45:29.651288 19004 sgd_solver.cpp:136] Iteration 29200, lr = 0.01, m = 0.9
I0916 11:45:49.894544 19004 solver.cpp:314] Iteration 29300 (4.94004 iter/s, 20.2427s/100 iter), loss = 0.0587528
I0916 11:45:49.894593 19004 solver.cpp:336]     Train net output #0: loss = 0.0587529 (* 1 = 0.0587529 loss)
I0916 11:45:49.894598 19004 sgd_solver.cpp:136] Iteration 29300, lr = 0.01, m = 0.9
I0916 11:46:10.150705 19004 solver.cpp:314] Iteration 29400 (4.93691 iter/s, 20.2556s/100 iter), loss = 0.05943
I0916 11:46:10.150732 19004 solver.cpp:336]     Train net output #0: loss = 0.0594301 (* 1 = 0.0594301 loss)
I0916 11:46:10.150738 19004 sgd_solver.cpp:136] Iteration 29400, lr = 0.01, m = 0.9
I0916 11:46:13.354029 19007 data_reader.cpp:305] Starting prefetch of epoch 20
I0916 11:46:29.770807 19004 solver.cpp:314] Iteration 29500 (5.09695 iter/s, 19.6196s/100 iter), loss = 0.139442
I0916 11:46:29.770880 19004 solver.cpp:336]     Train net output #0: loss = 0.139442 (* 1 = 0.139442 loss)
I0916 11:46:29.770887 19004 sgd_solver.cpp:136] Iteration 29500, lr = 0.01, m = 0.9
I0916 11:46:50.479490 19004 solver.cpp:314] Iteration 29600 (4.82903 iter/s, 20.7081s/100 iter), loss = 0.0802903
I0916 11:46:50.479516 19004 solver.cpp:336]     Train net output #0: loss = 0.0802904 (* 1 = 0.0802904 loss)
I0916 11:46:50.479521 19004 sgd_solver.cpp:136] Iteration 29600, lr = 0.01, m = 0.9
I0916 11:47:10.649876 19004 solver.cpp:314] Iteration 29700 (4.9579 iter/s, 20.1698s/100 iter), loss = 0.0922696
I0916 11:47:10.649926 19004 solver.cpp:336]     Train net output #0: loss = 0.0922696 (* 1 = 0.0922696 loss)
I0916 11:47:10.649931 19004 sgd_solver.cpp:136] Iteration 29700, lr = 0.01, m = 0.9
I0916 11:47:19.708705 19010 data_reader.cpp:305] Starting prefetch of epoch 16
I0916 11:47:30.462612 19004 solver.cpp:314] Iteration 29800 (5.0474 iter/s, 19.8122s/100 iter), loss = 0.154824
I0916 11:47:30.462635 19004 solver.cpp:336]     Train net output #0: loss = 0.154825 (* 1 = 0.154825 loss)
I0916 11:47:30.462641 19004 sgd_solver.cpp:136] Iteration 29800, lr = 0.01, m = 0.9
I0916 11:47:50.831883 19004 solver.cpp:314] Iteration 29900 (4.90949 iter/s, 20.3687s/100 iter), loss = 0.0790778
I0916 11:47:50.831961 19004 solver.cpp:336]     Train net output #0: loss = 0.0790779 (* 1 = 0.0790779 loss)
I0916 11:47:50.831969 19004 sgd_solver.cpp:136] Iteration 29900, lr = 0.01, m = 0.9
I0916 11:47:53.405133 18961 data_reader.cpp:305] Starting prefetch of epoch 19
I0916 11:48:11.145357 19004 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/cityscapes5_jsegnet21v2_iter_30000.caffemodel
I0916 11:48:11.615608 19004 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/cityscapes5_jsegnet21v2_iter_30000.solverstate
I0916 11:48:11.621573 19004 solver.cpp:563] Iteration 30000, Testing net (#0)
I0916 11:48:24.205148 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.947625
I0916 11:48:24.205257 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 11:48:24.205269 19004 solver.cpp:655]     Test net output #2: loss = 0.183912 (* 1 = 0.183912 loss)
I0916 11:48:24.205302 19004 solver.cpp:265] [MultiGPU] Tests completed in 12.5834s
I0916 11:48:24.430887 19004 solver.cpp:314] Iteration 30000 (2.97636 iter/s, 33.5981s/100 iter), loss = 0.17255
I0916 11:48:24.430910 19004 solver.cpp:336]     Train net output #0: loss = 0.17255 (* 1 = 0.17255 loss)
I0916 11:48:24.430917 19004 sgd_solver.cpp:136] Iteration 30000, lr = 0.01, m = 0.9
I0916 11:48:39.445894 19010 data_reader.cpp:305] Starting prefetch of epoch 17
I0916 11:48:43.919749 19004 solver.cpp:314] Iteration 30100 (5.13128 iter/s, 19.4883s/100 iter), loss = 0.083174
I0916 11:48:43.919777 19004 solver.cpp:336]     Train net output #0: loss = 0.0831741 (* 1 = 0.0831741 loss)
I0916 11:48:43.919783 19004 sgd_solver.cpp:136] Iteration 30100, lr = 0.01, m = 0.9
I0916 11:49:03.801683 19004 solver.cpp:314] Iteration 30200 (5.02983 iter/s, 19.8814s/100 iter), loss = 0.0860286
I0916 11:49:03.801734 19004 solver.cpp:336]     Train net output #0: loss = 0.0860286 (* 1 = 0.0860286 loss)
I0916 11:49:03.801741 19004 sgd_solver.cpp:136] Iteration 30200, lr = 0.01, m = 0.9
I0916 11:49:24.314433 19004 solver.cpp:314] Iteration 30300 (4.87515 iter/s, 20.5122s/100 iter), loss = 0.0891821
I0916 11:49:24.314455 19004 solver.cpp:336]     Train net output #0: loss = 0.0891822 (* 1 = 0.0891822 loss)
I0916 11:49:24.314461 19004 sgd_solver.cpp:136] Iteration 30300, lr = 0.01, m = 0.9
I0916 11:49:45.115697 19004 solver.cpp:314] Iteration 30400 (4.80753 iter/s, 20.8007s/100 iter), loss = 0.0753429
I0916 11:49:45.115770 19004 solver.cpp:336]     Train net output #0: loss = 0.075343 (* 1 = 0.075343 loss)
I0916 11:49:45.115778 19004 sgd_solver.cpp:136] Iteration 30400, lr = 0.01, m = 0.9
I0916 11:49:46.682641 19007 data_reader.cpp:305] Starting prefetch of epoch 21
I0916 11:50:05.034473 19004 solver.cpp:314] Iteration 30500 (5.02053 iter/s, 19.9182s/100 iter), loss = 0.0877136
I0916 11:50:05.034493 19004 solver.cpp:336]     Train net output #0: loss = 0.0877136 (* 1 = 0.0877136 loss)
I0916 11:50:05.034497 19004 sgd_solver.cpp:136] Iteration 30500, lr = 0.01, m = 0.9
I0916 11:50:19.994998 19008 data_reader.cpp:305] Starting prefetch of epoch 17
I0916 11:50:25.716078 19004 solver.cpp:314] Iteration 30600 (4.83535 iter/s, 20.681s/100 iter), loss = 0.0590175
I0916 11:50:25.716105 19004 solver.cpp:336]     Train net output #0: loss = 0.0590176 (* 1 = 0.0590176 loss)
I0916 11:50:25.716111 19004 sgd_solver.cpp:136] Iteration 30600, lr = 0.01, m = 0.9
I0916 11:50:46.371117 19004 solver.cpp:314] Iteration 30700 (4.84157 iter/s, 20.6545s/100 iter), loss = 0.197163
I0916 11:50:46.371143 19004 solver.cpp:336]     Train net output #0: loss = 0.197163 (* 1 = 0.197163 loss)
I0916 11:50:46.371150 19004 sgd_solver.cpp:136] Iteration 30700, lr = 0.01, m = 0.9
I0916 11:51:06.547901 19004 solver.cpp:314] Iteration 30800 (4.95633 iter/s, 20.1762s/100 iter), loss = 0.0931105
I0916 11:51:06.547956 19004 solver.cpp:336]     Train net output #0: loss = 0.0931105 (* 1 = 0.0931105 loss)
I0916 11:51:06.547963 19004 sgd_solver.cpp:136] Iteration 30800, lr = 0.01, m = 0.9
I0916 11:51:26.850874 19004 solver.cpp:314] Iteration 30900 (4.92552 iter/s, 20.3024s/100 iter), loss = 0.104912
I0916 11:51:26.850898 19004 solver.cpp:336]     Train net output #0: loss = 0.104913 (* 1 = 0.104913 loss)
I0916 11:51:26.850903 19004 sgd_solver.cpp:136] Iteration 30900, lr = 0.01, m = 0.9
I0916 11:51:27.517485 19010 data_reader.cpp:305] Starting prefetch of epoch 18
I0916 11:51:47.620226 19004 solver.cpp:314] Iteration 31000 (4.81492 iter/s, 20.7688s/100 iter), loss = 0.0766531
I0916 11:51:47.620332 19004 solver.cpp:336]     Train net output #0: loss = 0.0766531 (* 1 = 0.0766531 loss)
I0916 11:51:47.620338 19004 sgd_solver.cpp:136] Iteration 31000, lr = 0.01, m = 0.9
I0916 11:52:08.318035 19004 solver.cpp:314] Iteration 31100 (4.83156 iter/s, 20.6972s/100 iter), loss = 0.0899401
I0916 11:52:08.318058 19004 solver.cpp:336]     Train net output #0: loss = 0.0899401 (* 1 = 0.0899401 loss)
I0916 11:52:08.318063 19004 sgd_solver.cpp:136] Iteration 31100, lr = 0.01, m = 0.9
I0916 11:52:28.868386 19004 solver.cpp:314] Iteration 31200 (4.86623 iter/s, 20.5498s/100 iter), loss = 0.176446
I0916 11:52:28.868436 19004 solver.cpp:336]     Train net output #0: loss = 0.176446 (* 1 = 0.176446 loss)
I0916 11:52:28.868443 19004 sgd_solver.cpp:136] Iteration 31200, lr = 0.01, m = 0.9
I0916 11:52:35.924324 19010 data_reader.cpp:305] Starting prefetch of epoch 19
I0916 11:52:49.655659 19004 solver.cpp:314] Iteration 31300 (4.81077 iter/s, 20.7867s/100 iter), loss = 0.0982188
I0916 11:52:49.655683 19004 solver.cpp:336]     Train net output #0: loss = 0.0982188 (* 1 = 0.0982188 loss)
I0916 11:52:49.655689 19004 sgd_solver.cpp:136] Iteration 31300, lr = 0.01, m = 0.9
I0916 11:53:10.222223 19007 data_reader.cpp:305] Starting prefetch of epoch 22
I0916 11:53:10.390116 19004 solver.cpp:314] Iteration 31400 (4.82302 iter/s, 20.7339s/100 iter), loss = 0.0606703
I0916 11:53:10.390233 19004 solver.cpp:336]     Train net output #0: loss = 0.0606703 (* 1 = 0.0606703 loss)
I0916 11:53:10.390261 19004 sgd_solver.cpp:136] Iteration 31400, lr = 0.01, m = 0.9
I0916 11:53:31.199728 19004 solver.cpp:314] Iteration 31500 (4.8056 iter/s, 20.809s/100 iter), loss = 0.0684231
I0916 11:53:31.199887 19004 solver.cpp:336]     Train net output #0: loss = 0.0684231 (* 1 = 0.0684231 loss)
I0916 11:53:31.199910 19004 sgd_solver.cpp:136] Iteration 31500, lr = 0.01, m = 0.9
I0916 11:53:51.796463 19004 solver.cpp:314] Iteration 31600 (4.85527 iter/s, 20.5962s/100 iter), loss = 0.231444
I0916 11:53:51.796574 19004 solver.cpp:336]     Train net output #0: loss = 0.231444 (* 1 = 0.231444 loss)
I0916 11:53:51.796607 19004 sgd_solver.cpp:136] Iteration 31600, lr = 0.01, m = 0.9
I0916 11:54:12.299715 19004 solver.cpp:314] Iteration 31700 (4.87741 iter/s, 20.5027s/100 iter), loss = 0.0743793
I0916 11:54:12.299737 19004 solver.cpp:336]     Train net output #0: loss = 0.0743793 (* 1 = 0.0743793 loss)
I0916 11:54:12.299741 19004 sgd_solver.cpp:136] Iteration 31700, lr = 0.01, m = 0.9
I0916 11:54:18.714669 18961 data_reader.cpp:305] Starting prefetch of epoch 20
I0916 11:54:33.186777 19004 solver.cpp:314] Iteration 31800 (4.78778 iter/s, 20.8865s/100 iter), loss = 0.0909991
I0916 11:54:33.186838 19004 solver.cpp:336]     Train net output #0: loss = 0.0909991 (* 1 = 0.0909991 loss)
I0916 11:54:33.186846 19004 sgd_solver.cpp:136] Iteration 31800, lr = 0.01, m = 0.9
I0916 11:54:53.816366 19004 solver.cpp:314] Iteration 31900 (4.84754 iter/s, 20.629s/100 iter), loss = 0.052702
I0916 11:54:53.816397 19004 solver.cpp:336]     Train net output #0: loss = 0.052702 (* 1 = 0.052702 loss)
I0916 11:54:53.816404 19004 sgd_solver.cpp:136] Iteration 31900, lr = 0.01, m = 0.9
I0916 11:55:14.246475 19004 solver.cpp:563] Iteration 32000, Testing net (#0)
I0916 11:55:18.233992 19000 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 11:55:27.134661 19002 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 11:55:27.530540 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.937377
I0916 11:55:27.530565 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 11:55:27.530573 19004 solver.cpp:655]     Test net output #2: loss = 0.184654 (* 1 = 0.184654 loss)
I0916 11:55:27.530607 19004 solver.cpp:265] [MultiGPU] Tests completed in 13.2838s
I0916 11:55:27.760874 19004 solver.cpp:314] Iteration 32000 (2.94607 iter/s, 33.9436s/100 iter), loss = 0.0804592
I0916 11:55:27.760901 19004 solver.cpp:336]     Train net output #0: loss = 0.0804592 (* 1 = 0.0804592 loss)
I0916 11:55:27.760905 19004 sgd_solver.cpp:136] Iteration 32000, lr = 0.01, m = 0.9
I0916 11:55:47.841730 19004 solver.cpp:314] Iteration 32100 (4.98 iter/s, 20.0803s/100 iter), loss = 0.112737
I0916 11:55:47.841786 19004 solver.cpp:336]     Train net output #0: loss = 0.112737 (* 1 = 0.112737 loss)
I0916 11:55:47.841794 19004 sgd_solver.cpp:136] Iteration 32100, lr = 0.01, m = 0.9
I0916 11:56:08.006834 19004 solver.cpp:314] Iteration 32200 (4.9592 iter/s, 20.1645s/100 iter), loss = 0.0748542
I0916 11:56:08.006860 19004 solver.cpp:336]     Train net output #0: loss = 0.0748541 (* 1 = 0.0748541 loss)
I0916 11:56:08.006865 19004 sgd_solver.cpp:136] Iteration 32200, lr = 0.01, m = 0.9
I0916 11:56:13.315829 19010 data_reader.cpp:305] Starting prefetch of epoch 20
I0916 11:56:28.520026 19004 solver.cpp:314] Iteration 32300 (4.87505 iter/s, 20.5126s/100 iter), loss = 0.0926497
I0916 11:56:28.520146 19004 solver.cpp:336]     Train net output #0: loss = 0.0926497 (* 1 = 0.0926497 loss)
I0916 11:56:28.520164 19004 sgd_solver.cpp:136] Iteration 32300, lr = 0.01, m = 0.9
I0916 11:56:48.872387 19004 solver.cpp:314] Iteration 32400 (4.91357 iter/s, 20.3518s/100 iter), loss = 0.0995618
I0916 11:56:48.872447 19004 solver.cpp:336]     Train net output #0: loss = 0.0995618 (* 1 = 0.0995618 loss)
I0916 11:56:48.872457 19004 sgd_solver.cpp:136] Iteration 32400, lr = 0.01, m = 0.9
I0916 11:57:08.951123 19004 solver.cpp:314] Iteration 32500 (4.98053 iter/s, 20.0782s/100 iter), loss = 0.0734674
I0916 11:57:08.951170 19004 solver.cpp:336]     Train net output #0: loss = 0.0734674 (* 1 = 0.0734674 loss)
I0916 11:57:08.951175 19004 sgd_solver.cpp:136] Iteration 32500, lr = 0.01, m = 0.9
I0916 11:57:20.307556 18963 data_reader.cpp:305] Starting prefetch of epoch 23
I0916 11:57:29.195936 19004 solver.cpp:314] Iteration 32600 (4.93968 iter/s, 20.2442s/100 iter), loss = 0.0563027
I0916 11:57:29.195986 19004 solver.cpp:336]     Train net output #0: loss = 0.0563027 (* 1 = 0.0563027 loss)
I0916 11:57:29.195999 19004 sgd_solver.cpp:136] Iteration 32600, lr = 0.01, m = 0.9
I0916 11:57:49.676489 19004 solver.cpp:314] Iteration 32700 (4.88282 iter/s, 20.48s/100 iter), loss = 0.0783891
I0916 11:57:49.676574 19004 solver.cpp:336]     Train net output #0: loss = 0.0783891 (* 1 = 0.0783891 loss)
I0916 11:57:49.676581 19004 sgd_solver.cpp:136] Iteration 32700, lr = 0.01, m = 0.9
I0916 11:57:54.030405 18961 data_reader.cpp:305] Starting prefetch of epoch 21
I0916 11:58:09.610502 19004 solver.cpp:314] Iteration 32800 (5.01669 iter/s, 19.9335s/100 iter), loss = 0.0645152
I0916 11:58:09.610522 19004 solver.cpp:336]     Train net output #0: loss = 0.0645152 (* 1 = 0.0645152 loss)
I0916 11:58:09.610527 19004 sgd_solver.cpp:136] Iteration 32800, lr = 0.01, m = 0.9
I0916 11:58:30.134140 19004 solver.cpp:314] Iteration 32900 (4.87256 iter/s, 20.5231s/100 iter), loss = 0.110151
I0916 11:58:30.134191 19004 solver.cpp:336]     Train net output #0: loss = 0.110151 (* 1 = 0.110151 loss)
I0916 11:58:30.134196 19004 sgd_solver.cpp:136] Iteration 32900, lr = 0.01, m = 0.9
I0916 11:58:50.733315 19004 solver.cpp:314] Iteration 33000 (4.8547 iter/s, 20.5986s/100 iter), loss = 0.0801855
I0916 11:58:50.733392 19004 solver.cpp:336]     Train net output #0: loss = 0.0801854 (* 1 = 0.0801854 loss)
I0916 11:58:50.733414 19004 sgd_solver.cpp:136] Iteration 33000, lr = 0.01, m = 0.9
I0916 11:59:01.332399 19007 data_reader.cpp:305] Starting prefetch of epoch 23
I0916 11:59:11.016185 19004 solver.cpp:314] Iteration 33100 (4.9304 iter/s, 20.2823s/100 iter), loss = 0.104094
I0916 11:59:11.016209 19004 solver.cpp:336]     Train net output #0: loss = 0.104094 (* 1 = 0.104094 loss)
I0916 11:59:11.016216 19004 sgd_solver.cpp:136] Iteration 33100, lr = 0.01, m = 0.9
I0916 11:59:31.205899 19004 solver.cpp:314] Iteration 33200 (4.95315 iter/s, 20.1892s/100 iter), loss = 0.0851912
I0916 11:59:31.205922 19004 solver.cpp:336]     Train net output #0: loss = 0.0851912 (* 1 = 0.0851912 loss)
I0916 11:59:31.205929 19004 sgd_solver.cpp:136] Iteration 33200, lr = 0.01, m = 0.9
I0916 11:59:51.721429 19004 solver.cpp:314] Iteration 33300 (4.87449 iter/s, 20.515s/100 iter), loss = 0.0863086
I0916 11:59:51.722113 19004 solver.cpp:336]     Train net output #0: loss = 0.0863086 (* 1 = 0.0863086 loss)
I0916 11:59:51.722124 19004 sgd_solver.cpp:136] Iteration 33300, lr = 0.01, m = 0.9
I0916 12:00:08.458815 19012 data_reader.cpp:305] Starting prefetch of epoch 18
I0916 12:00:11.974715 19004 solver.cpp:314] Iteration 33400 (4.93761 iter/s, 20.2527s/100 iter), loss = 0.0719116
I0916 12:00:11.974750 19004 solver.cpp:336]     Train net output #0: loss = 0.0719116 (* 1 = 0.0719116 loss)
I0916 12:00:11.974758 19004 sgd_solver.cpp:136] Iteration 33400, lr = 0.01, m = 0.9
I0916 12:00:31.814967 19004 solver.cpp:314] Iteration 33500 (5.0404 iter/s, 19.8397s/100 iter), loss = 0.0818013
I0916 12:00:31.815014 19004 solver.cpp:336]     Train net output #0: loss = 0.0818013 (* 1 = 0.0818013 loss)
I0916 12:00:31.815019 19004 sgd_solver.cpp:136] Iteration 33500, lr = 0.01, m = 0.9
I0916 12:00:41.573577 19012 data_reader.cpp:305] Starting prefetch of epoch 19
I0916 12:00:52.282165 19004 solver.cpp:314] Iteration 33600 (4.886 iter/s, 20.4666s/100 iter), loss = 0.0763766
I0916 12:00:52.282191 19004 solver.cpp:336]     Train net output #0: loss = 0.0763766 (* 1 = 0.0763766 loss)
I0916 12:00:52.282199 19004 sgd_solver.cpp:136] Iteration 33600, lr = 0.01, m = 0.9
I0916 12:01:12.688261 19004 solver.cpp:314] Iteration 33700 (4.90063 iter/s, 20.4055s/100 iter), loss = 0.150764
I0916 12:01:12.704838 19004 solver.cpp:336]     Train net output #0: loss = 0.150764 (* 1 = 0.150764 loss)
I0916 12:01:12.705021 19004 sgd_solver.cpp:136] Iteration 33700, lr = 0.01, m = 0.9
I0916 12:01:32.921353 19004 solver.cpp:314] Iteration 33800 (4.94253 iter/s, 20.2325s/100 iter), loss = 0.075696
I0916 12:01:32.921375 19004 solver.cpp:336]     Train net output #0: loss = 0.075696 (* 1 = 0.075696 loss)
I0916 12:01:32.921378 19004 sgd_solver.cpp:136] Iteration 33800, lr = 0.01, m = 0.9
I0916 12:01:48.992420 19008 data_reader.cpp:305] Starting prefetch of epoch 18
I0916 12:01:53.501420 19004 solver.cpp:314] Iteration 33900 (4.8592 iter/s, 20.5795s/100 iter), loss = 0.106554
I0916 12:01:53.501444 19004 solver.cpp:336]     Train net output #0: loss = 0.106554 (* 1 = 0.106554 loss)
I0916 12:01:53.501448 19004 sgd_solver.cpp:136] Iteration 33900, lr = 0.01, m = 0.9
I0916 12:02:13.285697 19004 solver.cpp:563] Iteration 34000, Testing net (#0)
I0916 12:02:25.557288 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.943299
I0916 12:02:25.557391 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.999999
I0916 12:02:25.557410 19004 solver.cpp:655]     Test net output #2: loss = 0.200275 (* 1 = 0.200275 loss)
I0916 12:02:25.557453 19004 solver.cpp:265] [MultiGPU] Tests completed in 12.2714s
I0916 12:02:25.788419 19004 solver.cpp:314] Iteration 34000 (3.09731 iter/s, 32.2861s/100 iter), loss = 0.152724
I0916 12:02:25.788442 19004 solver.cpp:336]     Train net output #0: loss = 0.152724 (* 1 = 0.152724 loss)
I0916 12:02:25.788449 19004 sgd_solver.cpp:136] Iteration 34000, lr = 0.01, m = 0.9
I0916 12:02:34.650415 19012 data_reader.cpp:305] Starting prefetch of epoch 20
I0916 12:02:45.647090 19004 solver.cpp:314] Iteration 34100 (5.03572 iter/s, 19.8581s/100 iter), loss = 0.0725823
I0916 12:02:45.647114 19004 solver.cpp:336]     Train net output #0: loss = 0.0725823 (* 1 = 0.0725823 loss)
I0916 12:02:45.647117 19004 sgd_solver.cpp:136] Iteration 34100, lr = 0.01, m = 0.9
I0916 12:03:05.426877 19004 solver.cpp:314] Iteration 34200 (5.05581 iter/s, 19.7792s/100 iter), loss = 0.0515061
I0916 12:03:05.426934 19004 solver.cpp:336]     Train net output #0: loss = 0.0515061 (* 1 = 0.0515061 loss)
I0916 12:03:05.426940 19004 sgd_solver.cpp:136] Iteration 34200, lr = 0.01, m = 0.9
I0916 12:03:07.277851 19008 data_reader.cpp:305] Starting prefetch of epoch 19
I0916 12:03:25.854305 19004 solver.cpp:314] Iteration 34300 (4.89551 iter/s, 20.4269s/100 iter), loss = 0.0609613
I0916 12:03:25.854331 19004 solver.cpp:336]     Train net output #0: loss = 0.0609613 (* 1 = 0.0609613 loss)
I0916 12:03:25.854337 19004 sgd_solver.cpp:136] Iteration 34300, lr = 0.01, m = 0.9
I0916 12:03:46.033445 19004 solver.cpp:314] Iteration 34400 (4.95575 iter/s, 20.1786s/100 iter), loss = 0.0822357
I0916 12:03:46.033560 19004 solver.cpp:336]     Train net output #0: loss = 0.0822357 (* 1 = 0.0822357 loss)
I0916 12:03:46.033576 19004 sgd_solver.cpp:136] Iteration 34400, lr = 0.01, m = 0.9
I0916 12:04:05.945614 19004 solver.cpp:314] Iteration 34500 (5.02219 iter/s, 19.9116s/100 iter), loss = 0.192118
I0916 12:04:05.945700 19004 solver.cpp:336]     Train net output #0: loss = 0.192118 (* 1 = 0.192118 loss)
I0916 12:04:05.945722 19004 sgd_solver.cpp:136] Iteration 34500, lr = 0.01, m = 0.9
I0916 12:04:14.122522 18963 data_reader.cpp:305] Starting prefetch of epoch 24
I0916 12:04:25.901496 19004 solver.cpp:314] Iteration 34600 (5.01119 iter/s, 19.9553s/100 iter), loss = 0.181942
I0916 12:04:25.901578 19004 solver.cpp:336]     Train net output #0: loss = 0.181942 (* 1 = 0.181942 loss)
I0916 12:04:25.901585 19004 sgd_solver.cpp:136] Iteration 34600, lr = 0.01, m = 0.9
I0916 12:04:46.204103 19004 solver.cpp:314] Iteration 34700 (4.92561 iter/s, 20.302s/100 iter), loss = 0.062723
I0916 12:04:46.204128 19004 solver.cpp:336]     Train net output #0: loss = 0.062723 (* 1 = 0.062723 loss)
I0916 12:04:46.204135 19004 sgd_solver.cpp:136] Iteration 34700, lr = 0.01, m = 0.9
I0916 12:05:06.192919 19004 solver.cpp:314] Iteration 34800 (5.00294 iter/s, 19.9883s/100 iter), loss = 0.0846933
I0916 12:05:06.193003 19004 solver.cpp:336]     Train net output #0: loss = 0.0846933 (* 1 = 0.0846933 loss)
I0916 12:05:06.193018 19004 sgd_solver.cpp:136] Iteration 34800, lr = 0.01, m = 0.9
I0916 12:05:20.252120 19007 data_reader.cpp:305] Starting prefetch of epoch 24
I0916 12:05:26.035848 19004 solver.cpp:314] Iteration 34900 (5.03972 iter/s, 19.8424s/100 iter), loss = 0.0915667
I0916 12:05:26.036041 19004 solver.cpp:336]     Train net output #0: loss = 0.0915666 (* 1 = 0.0915666 loss)
I0916 12:05:26.036128 19004 sgd_solver.cpp:136] Iteration 34900, lr = 0.01, m = 0.9
I0916 12:05:46.497699 19004 solver.cpp:314] Iteration 35000 (4.88728 iter/s, 20.4613s/100 iter), loss = 0.0866515
I0916 12:05:46.497771 19004 solver.cpp:336]     Train net output #0: loss = 0.0866515 (* 1 = 0.0866515 loss)
I0916 12:05:46.497778 19004 sgd_solver.cpp:136] Iteration 35000, lr = 0.01, m = 0.9
I0916 12:06:07.390005 19004 solver.cpp:314] Iteration 35100 (4.78658 iter/s, 20.8917s/100 iter), loss = 0.116272
I0916 12:06:07.390105 19004 solver.cpp:336]     Train net output #0: loss = 0.116272 (* 1 = 0.116272 loss)
I0916 12:06:07.390126 19004 sgd_solver.cpp:136] Iteration 35100, lr = 0.01, m = 0.9
I0916 12:06:27.471464 19004 solver.cpp:314] Iteration 35200 (4.97985 iter/s, 20.0809s/100 iter), loss = 0.0898079
I0916 12:06:27.471518 19004 solver.cpp:336]     Train net output #0: loss = 0.0898079 (* 1 = 0.0898079 loss)
I0916 12:06:27.471525 19004 sgd_solver.cpp:136] Iteration 35200, lr = 0.01, m = 0.9
I0916 12:06:27.693346 19007 data_reader.cpp:305] Starting prefetch of epoch 25
I0916 12:06:48.173764 19004 solver.cpp:314] Iteration 35300 (4.83051 iter/s, 20.7017s/100 iter), loss = 0.116522
I0916 12:06:48.173794 19004 solver.cpp:336]     Train net output #0: loss = 0.116522 (* 1 = 0.116522 loss)
I0916 12:06:48.173801 19004 sgd_solver.cpp:136] Iteration 35300, lr = 0.01, m = 0.9
I0916 12:07:01.912272 18961 data_reader.cpp:305] Starting prefetch of epoch 22
I0916 12:07:09.045588 19004 solver.cpp:314] Iteration 35400 (4.79128 iter/s, 20.8712s/100 iter), loss = 0.085512
I0916 12:07:09.045614 19004 solver.cpp:336]     Train net output #0: loss = 0.085512 (* 1 = 0.085512 loss)
I0916 12:07:09.045620 19004 sgd_solver.cpp:136] Iteration 35400, lr = 0.01, m = 0.9
I0916 12:07:29.848413 19004 solver.cpp:314] Iteration 35500 (4.80717 iter/s, 20.8023s/100 iter), loss = 0.048883
I0916 12:07:29.848441 19004 solver.cpp:336]     Train net output #0: loss = 0.048883 (* 1 = 0.048883 loss)
I0916 12:07:29.848448 19004 sgd_solver.cpp:136] Iteration 35500, lr = 0.01, m = 0.9
I0916 12:07:50.732553 19004 solver.cpp:314] Iteration 35600 (4.78845 iter/s, 20.8836s/100 iter), loss = 0.110673
I0916 12:07:50.732609 19004 solver.cpp:336]     Train net output #0: loss = 0.110673 (* 1 = 0.110673 loss)
I0916 12:07:50.732614 19004 sgd_solver.cpp:136] Iteration 35600, lr = 0.01, m = 0.9
I0916 12:08:10.911826 19007 data_reader.cpp:305] Starting prefetch of epoch 26
I0916 12:08:11.660730 19004 solver.cpp:314] Iteration 35700 (4.77838 iter/s, 20.9276s/100 iter), loss = 0.0832244
I0916 12:08:11.660755 19004 solver.cpp:336]     Train net output #0: loss = 0.0832244 (* 1 = 0.0832244 loss)
I0916 12:08:11.660761 19004 sgd_solver.cpp:136] Iteration 35700, lr = 0.01, m = 0.9
I0916 12:08:32.226056 19004 solver.cpp:314] Iteration 35800 (4.86269 iter/s, 20.5648s/100 iter), loss = 0.0696689
I0916 12:08:32.226136 19004 solver.cpp:336]     Train net output #0: loss = 0.0696689 (* 1 = 0.0696689 loss)
I0916 12:08:32.226142 19004 sgd_solver.cpp:136] Iteration 35800, lr = 0.01, m = 0.9
I0916 12:08:52.454838 19004 solver.cpp:314] Iteration 35900 (4.94359 iter/s, 20.2282s/100 iter), loss = 0.0928495
I0916 12:08:52.454860 19004 solver.cpp:336]     Train net output #0: loss = 0.0928494 (* 1 = 0.0928494 loss)
I0916 12:08:52.454865 19004 sgd_solver.cpp:136] Iteration 35900, lr = 0.01, m = 0.9
I0916 12:09:12.816684 19004 solver.cpp:563] Iteration 36000, Testing net (#0)
I0916 12:09:16.613661 19016 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 12:09:25.685869 19000 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 12:09:26.006166 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.945026
I0916 12:09:26.006186 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 12:09:26.006191 19004 solver.cpp:655]     Test net output #2: loss = 0.154644 (* 1 = 0.154644 loss)
I0916 12:09:26.006217 19004 solver.cpp:265] [MultiGPU] Tests completed in 13.1892s
I0916 12:09:26.226521 19004 solver.cpp:314] Iteration 36000 (2.96114 iter/s, 33.7708s/100 iter), loss = 0.101335
I0916 12:09:26.226544 19004 solver.cpp:336]     Train net output #0: loss = 0.101335 (* 1 = 0.101335 loss)
I0916 12:09:26.226548 19004 sgd_solver.cpp:136] Iteration 36000, lr = 0.01, m = 0.9
I0916 12:09:46.772583 19004 solver.cpp:314] Iteration 36100 (4.86725 iter/s, 20.5455s/100 iter), loss = 0.31705
I0916 12:09:46.772687 19004 solver.cpp:336]     Train net output #0: loss = 0.31705 (* 1 = 0.31705 loss)
I0916 12:09:46.772694 19004 sgd_solver.cpp:136] Iteration 36100, lr = 0.01, m = 0.9
I0916 12:10:05.538359 19008 data_reader.cpp:305] Starting prefetch of epoch 20
I0916 12:10:07.105669 19004 solver.cpp:314] Iteration 36200 (4.91823 iter/s, 20.3325s/100 iter), loss = 0.0632126
I0916 12:10:07.105711 19004 solver.cpp:336]     Train net output #0: loss = 0.0632126 (* 1 = 0.0632126 loss)
I0916 12:10:07.105720 19004 sgd_solver.cpp:136] Iteration 36200, lr = 0.01, m = 0.9
I0916 12:10:27.808676 19004 solver.cpp:314] Iteration 36300 (4.83035 iter/s, 20.7024s/100 iter), loss = 0.0846273
I0916 12:10:27.808755 19004 solver.cpp:336]     Train net output #0: loss = 0.0846272 (* 1 = 0.0846272 loss)
I0916 12:10:27.808763 19004 sgd_solver.cpp:136] Iteration 36300, lr = 0.01, m = 0.9
I0916 12:10:48.199959 19004 solver.cpp:314] Iteration 36400 (4.90419 iter/s, 20.3907s/100 iter), loss = 0.0649764
I0916 12:10:48.199982 19004 solver.cpp:336]     Train net output #0: loss = 0.0649764 (* 1 = 0.0649764 loss)
I0916 12:10:48.199988 19004 sgd_solver.cpp:136] Iteration 36400, lr = 0.01, m = 0.9
I0916 12:11:08.311285 19004 solver.cpp:314] Iteration 36500 (4.97246 iter/s, 20.1108s/100 iter), loss = 0.141515
I0916 12:11:08.311396 19004 solver.cpp:336]     Train net output #0: loss = 0.141515 (* 1 = 0.141515 loss)
I0916 12:11:08.311404 19004 sgd_solver.cpp:136] Iteration 36500, lr = 0.01, m = 0.9
I0916 12:11:13.050999 19010 data_reader.cpp:305] Starting prefetch of epoch 21
I0916 12:11:29.167776 19004 solver.cpp:314] Iteration 36600 (4.7948 iter/s, 20.8559s/100 iter), loss = 0.0682796
I0916 12:11:29.167821 19004 solver.cpp:336]     Train net output #0: loss = 0.0682796 (* 1 = 0.0682796 loss)
I0916 12:11:29.167937 19004 sgd_solver.cpp:136] Iteration 36600, lr = 0.01, m = 0.9
I0916 12:11:47.519786 19007 data_reader.cpp:305] Starting prefetch of epoch 27
I0916 12:11:49.909555 19004 solver.cpp:314] Iteration 36700 (4.82132 iter/s, 20.7412s/100 iter), loss = 0.0646948
I0916 12:11:49.909581 19004 solver.cpp:336]     Train net output #0: loss = 0.0646948 (* 1 = 0.0646948 loss)
I0916 12:11:49.909586 19004 sgd_solver.cpp:136] Iteration 36700, lr = 0.01, m = 0.9
I0916 12:12:10.785948 19004 solver.cpp:314] Iteration 36800 (4.79023 iter/s, 20.8758s/100 iter), loss = 0.0682531
I0916 12:12:10.785970 19004 solver.cpp:336]     Train net output #0: loss = 0.0682531 (* 1 = 0.0682531 loss)
I0916 12:12:10.785977 19004 sgd_solver.cpp:136] Iteration 36800, lr = 0.01, m = 0.9
I0916 12:12:30.964046 19004 solver.cpp:314] Iteration 36900 (4.95601 iter/s, 20.1775s/100 iter), loss = 0.0823968
I0916 12:12:30.964093 19004 solver.cpp:336]     Train net output #0: loss = 0.0823968 (* 1 = 0.0823968 loss)
I0916 12:12:30.964099 19004 sgd_solver.cpp:136] Iteration 36900, lr = 0.01, m = 0.9
I0916 12:12:51.492192 19004 solver.cpp:314] Iteration 37000 (4.8715 iter/s, 20.5275s/100 iter), loss = 0.123137
I0916 12:12:51.492411 19004 solver.cpp:336]     Train net output #0: loss = 0.123137 (* 1 = 0.123137 loss)
I0916 12:12:51.492447 19004 sgd_solver.cpp:136] Iteration 37000, lr = 0.01, m = 0.9
I0916 12:12:55.346173 19007 data_reader.cpp:305] Starting prefetch of epoch 28
I0916 12:13:11.866160 19004 solver.cpp:314] Iteration 37100 (4.90836 iter/s, 20.3734s/100 iter), loss = 0.102991
I0916 12:13:11.866257 19004 solver.cpp:336]     Train net output #0: loss = 0.102991 (* 1 = 0.102991 loss)
I0916 12:13:11.866273 19004 sgd_solver.cpp:136] Iteration 37100, lr = 0.01, m = 0.9
I0916 12:13:32.101853 19004 solver.cpp:314] Iteration 37200 (4.9419 iter/s, 20.2351s/100 iter), loss = 0.0635042
I0916 12:13:32.101925 19004 solver.cpp:336]     Train net output #0: loss = 0.0635041 (* 1 = 0.0635041 loss)
I0916 12:13:32.101948 19004 sgd_solver.cpp:136] Iteration 37200, lr = 0.01, m = 0.9
I0916 12:13:52.326210 19004 solver.cpp:314] Iteration 37300 (4.94467 iter/s, 20.2238s/100 iter), loss = 0.253821
I0916 12:13:52.326378 19004 solver.cpp:336]     Train net output #0: loss = 0.253821 (* 1 = 0.253821 loss)
I0916 12:13:52.326398 19004 sgd_solver.cpp:136] Iteration 37300, lr = 0.01, m = 0.9
I0916 12:14:02.372784 19010 data_reader.cpp:305] Starting prefetch of epoch 22
I0916 12:14:12.803144 19004 solver.cpp:314] Iteration 37400 (4.88368 iter/s, 20.4764s/100 iter), loss = 0.0891282
I0916 12:14:12.803169 19004 solver.cpp:336]     Train net output #0: loss = 0.0891281 (* 1 = 0.0891281 loss)
I0916 12:14:12.803176 19004 sgd_solver.cpp:136] Iteration 37400, lr = 0.01, m = 0.9
I0916 12:14:33.126404 19004 solver.cpp:314] Iteration 37500 (4.92061 iter/s, 20.3227s/100 iter), loss = 0.052717
I0916 12:14:33.126492 19004 solver.cpp:336]     Train net output #0: loss = 0.0527169 (* 1 = 0.0527169 loss)
I0916 12:14:33.126497 19004 sgd_solver.cpp:136] Iteration 37500, lr = 0.01, m = 0.9
I0916 12:14:36.082514 19007 data_reader.cpp:305] Starting prefetch of epoch 29
I0916 12:14:53.422655 19004 solver.cpp:314] Iteration 37600 (4.92715 iter/s, 20.2957s/100 iter), loss = 0.0529726
I0916 12:14:53.422682 19004 solver.cpp:336]     Train net output #0: loss = 0.0529725 (* 1 = 0.0529725 loss)
I0916 12:14:53.422686 19004 sgd_solver.cpp:136] Iteration 37600, lr = 0.01, m = 0.9
I0916 12:15:13.782688 19004 solver.cpp:314] Iteration 37700 (4.91172 iter/s, 20.3595s/100 iter), loss = 0.0883929
I0916 12:15:13.782733 19004 solver.cpp:336]     Train net output #0: loss = 0.0883928 (* 1 = 0.0883928 loss)
I0916 12:15:13.782738 19004 sgd_solver.cpp:136] Iteration 37700, lr = 0.01, m = 0.9
I0916 12:15:34.183786 19004 solver.cpp:314] Iteration 37800 (4.90183 iter/s, 20.4005s/100 iter), loss = 0.0499694
I0916 12:15:34.183812 19004 solver.cpp:336]     Train net output #0: loss = 0.0499693 (* 1 = 0.0499693 loss)
I0916 12:15:34.183820 19004 sgd_solver.cpp:136] Iteration 37800, lr = 0.01, m = 0.9
I0916 12:15:43.498131 19007 data_reader.cpp:305] Starting prefetch of epoch 30
I0916 12:15:54.689378 19004 solver.cpp:314] Iteration 37900 (4.87686 iter/s, 20.505s/100 iter), loss = 0.0877899
I0916 12:15:54.689473 19004 solver.cpp:336]     Train net output #0: loss = 0.0877898 (* 1 = 0.0877898 loss)
I0916 12:15:54.689491 19004 sgd_solver.cpp:136] Iteration 37900, lr = 0.01, m = 0.9
I0916 12:16:14.549618 19004 solver.cpp:563] Iteration 38000, Testing net (#0)
I0916 12:16:27.343545 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.948277
I0916 12:16:27.343657 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.999999
I0916 12:16:27.343667 19004 solver.cpp:655]     Test net output #2: loss = 0.175801 (* 1 = 0.175801 loss)
I0916 12:16:27.343691 19004 solver.cpp:265] [MultiGPU] Tests completed in 12.7937s
I0916 12:16:27.557552 19004 solver.cpp:314] Iteration 38000 (3.04254 iter/s, 32.8673s/100 iter), loss = 0.10758
I0916 12:16:27.557579 19004 solver.cpp:336]     Train net output #0: loss = 0.10758 (* 1 = 0.10758 loss)
I0916 12:16:27.557585 19004 sgd_solver.cpp:136] Iteration 38000, lr = 0.01, m = 0.9
I0916 12:16:29.585942 18963 data_reader.cpp:305] Starting prefetch of epoch 25
I0916 12:16:47.795513 19004 solver.cpp:314] Iteration 38100 (4.94135 iter/s, 20.2374s/100 iter), loss = 0.0899291
I0916 12:16:47.795537 19004 solver.cpp:336]     Train net output #0: loss = 0.089929 (* 1 = 0.089929 loss)
I0916 12:16:47.795542 19004 sgd_solver.cpp:136] Iteration 38100, lr = 0.01, m = 0.9
I0916 12:17:08.035226 19004 solver.cpp:314] Iteration 38200 (4.94092 iter/s, 20.2392s/100 iter), loss = 0.147835
I0916 12:17:08.035276 19004 solver.cpp:336]     Train net output #0: loss = 0.147835 (* 1 = 0.147835 loss)
I0916 12:17:08.035282 19004 sgd_solver.cpp:136] Iteration 38200, lr = 0.01, m = 0.9
I0916 12:17:28.530324 19004 solver.cpp:314] Iteration 38300 (4.87935 iter/s, 20.4945s/100 iter), loss = 0.065717
I0916 12:17:28.530350 19004 solver.cpp:336]     Train net output #0: loss = 0.0657169 (* 1 = 0.0657169 loss)
I0916 12:17:28.530355 19004 sgd_solver.cpp:136] Iteration 38300, lr = 0.01, m = 0.9
I0916 12:17:36.885660 18963 data_reader.cpp:305] Starting prefetch of epoch 26
I0916 12:17:49.021289 19004 solver.cpp:314] Iteration 38400 (4.88033 iter/s, 20.4904s/100 iter), loss = 0.070832
I0916 12:17:49.021364 19004 solver.cpp:336]     Train net output #0: loss = 0.0708319 (* 1 = 0.0708319 loss)
I0916 12:17:49.021371 19004 sgd_solver.cpp:136] Iteration 38400, lr = 0.01, m = 0.9
I0916 12:18:09.425957 19004 solver.cpp:314] Iteration 38500 (4.90097 iter/s, 20.4041s/100 iter), loss = 0.0716843
I0916 12:18:09.425981 19004 solver.cpp:336]     Train net output #0: loss = 0.0716842 (* 1 = 0.0716842 loss)
I0916 12:18:09.425984 19004 sgd_solver.cpp:136] Iteration 38500, lr = 0.01, m = 0.9
I0916 12:18:10.672303 19007 data_reader.cpp:305] Starting prefetch of epoch 31
I0916 12:18:29.848266 19004 solver.cpp:314] Iteration 38600 (4.89674 iter/s, 20.4217s/100 iter), loss = 0.0902737
I0916 12:18:29.848372 19004 solver.cpp:336]     Train net output #0: loss = 0.0902737 (* 1 = 0.0902737 loss)
I0916 12:18:29.848393 19004 sgd_solver.cpp:136] Iteration 38600, lr = 0.01, m = 0.9
I0916 12:18:49.867933 19004 solver.cpp:314] Iteration 38700 (4.99523 iter/s, 20.0191s/100 iter), loss = 0.113824
I0916 12:18:49.867964 19004 solver.cpp:336]     Train net output #0: loss = 0.113823 (* 1 = 0.113823 loss)
I0916 12:18:49.867971 19004 sgd_solver.cpp:136] Iteration 38700, lr = 0.01, m = 0.9
I0916 12:19:10.108927 19004 solver.cpp:314] Iteration 38800 (4.9406 iter/s, 20.2404s/100 iter), loss = 0.0976111
I0916 12:19:10.108980 19004 solver.cpp:336]     Train net output #0: loss = 0.0976111 (* 1 = 0.0976111 loss)
I0916 12:19:10.108985 19004 sgd_solver.cpp:136] Iteration 38800, lr = 0.01, m = 0.9
I0916 12:19:17.477339 18963 data_reader.cpp:305] Starting prefetch of epoch 27
I0916 12:19:30.381006 19004 solver.cpp:314] Iteration 38900 (4.93303 iter/s, 20.2715s/100 iter), loss = 0.138645
I0916 12:19:30.381033 19004 solver.cpp:336]     Train net output #0: loss = 0.138645 (* 1 = 0.138645 loss)
I0916 12:19:30.381039 19004 sgd_solver.cpp:136] Iteration 38900, lr = 0.01, m = 0.9
I0916 12:19:50.294451 19004 solver.cpp:314] Iteration 39000 (5.02187 iter/s, 19.9129s/100 iter), loss = 0.0766565
I0916 12:19:50.294533 19004 solver.cpp:336]     Train net output #0: loss = 0.0766565 (* 1 = 0.0766565 loss)
I0916 12:19:50.294540 19004 sgd_solver.cpp:136] Iteration 39000, lr = 0.01, m = 0.9
I0916 12:20:10.390518 19004 solver.cpp:314] Iteration 39100 (4.97624 iter/s, 20.0955s/100 iter), loss = 0.0450124
I0916 12:20:10.390575 19004 solver.cpp:336]     Train net output #0: loss = 0.0450124 (* 1 = 0.0450124 loss)
I0916 12:20:10.390588 19004 sgd_solver.cpp:136] Iteration 39100, lr = 0.01, m = 0.9
I0916 12:20:24.013712 18963 data_reader.cpp:305] Starting prefetch of epoch 28
I0916 12:20:30.695652 19004 solver.cpp:314] Iteration 39200 (4.925 iter/s, 20.3046s/100 iter), loss = 0.104035
I0916 12:20:30.695680 19004 solver.cpp:336]     Train net output #0: loss = 0.104035 (* 1 = 0.104035 loss)
I0916 12:20:30.695685 19004 sgd_solver.cpp:136] Iteration 39200, lr = 0.01, m = 0.9
I0916 12:20:51.208417 19004 solver.cpp:314] Iteration 39300 (4.87515 iter/s, 20.5122s/100 iter), loss = 0.0883185
I0916 12:20:51.208446 19004 solver.cpp:336]     Train net output #0: loss = 0.0883184 (* 1 = 0.0883184 loss)
I0916 12:20:51.208452 19004 sgd_solver.cpp:136] Iteration 39300, lr = 0.01, m = 0.9
I0916 12:20:57.563104 19007 data_reader.cpp:305] Starting prefetch of epoch 32
I0916 12:21:11.093058 19004 solver.cpp:314] Iteration 39400 (5.02915 iter/s, 19.8841s/100 iter), loss = 0.0586241
I0916 12:21:11.093112 19004 solver.cpp:336]     Train net output #0: loss = 0.058624 (* 1 = 0.058624 loss)
I0916 12:21:11.093127 19004 sgd_solver.cpp:136] Iteration 39400, lr = 0.01, m = 0.9
I0916 12:21:31.318774 19004 solver.cpp:314] Iteration 39500 (4.94434 iter/s, 20.2252s/100 iter), loss = 0.0737127
I0916 12:21:31.321338 19004 solver.cpp:336]     Train net output #0: loss = 0.0737126 (* 1 = 0.0737126 loss)
I0916 12:21:31.321348 19004 sgd_solver.cpp:136] Iteration 39500, lr = 0.01, m = 0.9
I0916 12:21:51.189350 19004 solver.cpp:314] Iteration 39600 (5.03271 iter/s, 19.87s/100 iter), loss = 0.0743411
I0916 12:21:51.189374 19004 solver.cpp:336]     Train net output #0: loss = 0.074341 (* 1 = 0.074341 loss)
I0916 12:21:51.189378 19004 sgd_solver.cpp:136] Iteration 39600, lr = 0.01, m = 0.9
I0916 12:22:03.798148 19007 data_reader.cpp:305] Starting prefetch of epoch 33
I0916 12:22:11.080395 19004 solver.cpp:314] Iteration 39700 (5.02753 iter/s, 19.8905s/100 iter), loss = 0.079413
I0916 12:22:11.080428 19004 solver.cpp:336]     Train net output #0: loss = 0.0794129 (* 1 = 0.0794129 loss)
I0916 12:22:11.080433 19004 sgd_solver.cpp:136] Iteration 39700, lr = 0.01, m = 0.9
I0916 12:22:31.465878 19004 solver.cpp:314] Iteration 39800 (4.90559 iter/s, 20.3849s/100 iter), loss = 0.0710407
I0916 12:22:31.465901 19004 solver.cpp:336]     Train net output #0: loss = 0.0710406 (* 1 = 0.0710406 loss)
I0916 12:22:31.465908 19004 sgd_solver.cpp:136] Iteration 39800, lr = 0.01, m = 0.9
I0916 12:22:52.511124 19004 solver.cpp:314] Iteration 39900 (4.7518 iter/s, 21.0447s/100 iter), loss = 0.0783431
I0916 12:22:52.511183 19004 solver.cpp:336]     Train net output #0: loss = 0.078343 (* 1 = 0.078343 loss)
I0916 12:22:52.511190 19004 sgd_solver.cpp:136] Iteration 39900, lr = 0.01, m = 0.9
I0916 12:23:12.192661 19012 data_reader.cpp:305] Starting prefetch of epoch 21
I0916 12:23:13.179704 19004 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/cityscapes5_jsegnet21v2_iter_40000.caffemodel
I0916 12:23:13.516422 19004 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/cityscapes5_jsegnet21v2_iter_40000.solverstate
I0916 12:23:13.522022 19004 solver.cpp:563] Iteration 40000, Testing net (#0)
I0916 12:23:17.585093 19000 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 12:23:26.042506 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.936629
I0916 12:23:26.042562 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 12:23:26.042569 19004 solver.cpp:655]     Test net output #2: loss = 0.18561 (* 1 = 0.18561 loss)
I0916 12:23:26.042594 19004 solver.cpp:265] [MultiGPU] Tests completed in 12.5202s
I0916 12:23:26.248472 19004 solver.cpp:314] Iteration 40000 (2.96416 iter/s, 33.7364s/100 iter), loss = 0.100535
I0916 12:23:26.248493 19004 solver.cpp:336]     Train net output #0: loss = 0.100535 (* 1 = 0.100535 loss)
I0916 12:23:26.248497 19004 sgd_solver.cpp:136] Iteration 40000, lr = 0.01, m = 0.9
I0916 12:23:46.310868 19004 solver.cpp:314] Iteration 40100 (4.98459 iter/s, 20.0618s/100 iter), loss = 0.111358
I0916 12:23:46.310892 19004 solver.cpp:336]     Train net output #0: loss = 0.111358 (* 1 = 0.111358 loss)
I0916 12:23:46.310896 19004 sgd_solver.cpp:136] Iteration 40100, lr = 0.01, m = 0.9
I0916 12:23:58.262697 19007 data_reader.cpp:305] Starting prefetch of epoch 34
I0916 12:24:06.928177 19004 solver.cpp:314] Iteration 40200 (4.85043 iter/s, 20.6167s/100 iter), loss = 0.0704265
I0916 12:24:06.928205 19004 solver.cpp:336]     Train net output #0: loss = 0.0704264 (* 1 = 0.0704264 loss)
I0916 12:24:06.928211 19004 sgd_solver.cpp:136] Iteration 40200, lr = 0.01, m = 0.9
I0916 12:24:27.864004 19004 solver.cpp:314] Iteration 40300 (4.77663 iter/s, 20.9352s/100 iter), loss = 0.107131
I0916 12:24:27.864032 19004 solver.cpp:336]     Train net output #0: loss = 0.107131 (* 1 = 0.107131 loss)
I0916 12:24:27.864038 19004 sgd_solver.cpp:136] Iteration 40300, lr = 0.01, m = 0.9
I0916 12:24:48.732583 19004 solver.cpp:314] Iteration 40400 (4.79203 iter/s, 20.868s/100 iter), loss = 0.0873073
I0916 12:24:48.732666 19004 solver.cpp:336]     Train net output #0: loss = 0.0873072 (* 1 = 0.0873072 loss)
I0916 12:24:48.732673 19004 sgd_solver.cpp:136] Iteration 40400, lr = 0.01, m = 0.9
I0916 12:25:07.128427 18963 data_reader.cpp:305] Starting prefetch of epoch 29
I0916 12:25:09.109352 19004 solver.cpp:314] Iteration 40500 (4.90768 iter/s, 20.3762s/100 iter), loss = 0.0930759
I0916 12:25:09.109374 19004 solver.cpp:336]     Train net output #0: loss = 0.0930757 (* 1 = 0.0930757 loss)
I0916 12:25:09.109378 19004 sgd_solver.cpp:136] Iteration 40500, lr = 0.01, m = 0.9
I0916 12:25:29.846096 19004 solver.cpp:314] Iteration 40600 (4.82249 iter/s, 20.7362s/100 iter), loss = 0.0684207
I0916 12:25:29.846199 19004 solver.cpp:336]     Train net output #0: loss = 0.0684206 (* 1 = 0.0684206 loss)
I0916 12:25:29.846206 19004 sgd_solver.cpp:136] Iteration 40600, lr = 0.01, m = 0.9
I0916 12:25:50.664691 19004 solver.cpp:314] Iteration 40700 (4.80353 iter/s, 20.818s/100 iter), loss = 0.094181
I0916 12:25:50.664716 19004 solver.cpp:336]     Train net output #0: loss = 0.0941809 (* 1 = 0.0941809 loss)
I0916 12:25:50.664721 19004 sgd_solver.cpp:136] Iteration 40700, lr = 0.01, m = 0.9
I0916 12:26:11.566315 19004 solver.cpp:314] Iteration 40800 (4.78445 iter/s, 20.901s/100 iter), loss = 0.129571
I0916 12:26:11.566380 19004 solver.cpp:336]     Train net output #0: loss = 0.129571 (* 1 = 0.129571 loss)
I0916 12:26:11.566385 19004 sgd_solver.cpp:136] Iteration 40800, lr = 0.01, m = 0.9
I0916 12:26:15.560111 19010 data_reader.cpp:305] Starting prefetch of epoch 23
I0916 12:26:31.956575 19004 solver.cpp:314] Iteration 40900 (4.90444 iter/s, 20.3897s/100 iter), loss = 0.0722829
I0916 12:26:31.956603 19004 solver.cpp:336]     Train net output #0: loss = 0.0722828 (* 1 = 0.0722828 loss)
I0916 12:26:31.956609 19004 sgd_solver.cpp:136] Iteration 40900, lr = 0.01, m = 0.9
I0916 12:26:49.817351 19007 data_reader.cpp:305] Starting prefetch of epoch 35
I0916 12:26:52.827613 19004 solver.cpp:314] Iteration 41000 (4.79146 iter/s, 20.8705s/100 iter), loss = 0.0956594
I0916 12:26:52.827638 19004 solver.cpp:336]     Train net output #0: loss = 0.0956593 (* 1 = 0.0956593 loss)
I0916 12:26:52.827643 19004 sgd_solver.cpp:136] Iteration 41000, lr = 0.01, m = 0.9
I0916 12:27:13.517035 19004 solver.cpp:314] Iteration 41100 (4.83352 iter/s, 20.6888s/100 iter), loss = 0.0679334
I0916 12:27:13.517072 19004 solver.cpp:336]     Train net output #0: loss = 0.0679333 (* 1 = 0.0679333 loss)
I0916 12:27:13.517079 19004 sgd_solver.cpp:136] Iteration 41100, lr = 0.01, m = 0.9
I0916 12:27:34.021301 19004 solver.cpp:314] Iteration 41200 (4.87717 iter/s, 20.5037s/100 iter), loss = 0.0602714
I0916 12:27:34.021345 19004 solver.cpp:336]     Train net output #0: loss = 0.0602713 (* 1 = 0.0602713 loss)
I0916 12:27:34.021353 19004 sgd_solver.cpp:136] Iteration 41200, lr = 0.01, m = 0.9
I0916 12:27:54.724433 19004 solver.cpp:314] Iteration 41300 (4.83032 iter/s, 20.7026s/100 iter), loss = 0.0398499
I0916 12:27:54.724521 19004 solver.cpp:336]     Train net output #0: loss = 0.0398498 (* 1 = 0.0398498 loss)
I0916 12:27:54.724547 19004 sgd_solver.cpp:136] Iteration 41300, lr = 0.01, m = 0.9
I0916 12:27:57.993830 19008 data_reader.cpp:305] Starting prefetch of epoch 21
I0916 12:28:15.564368 19004 solver.cpp:314] Iteration 41400 (4.79861 iter/s, 20.8394s/100 iter), loss = 0.146984
I0916 12:28:15.564422 19004 solver.cpp:336]     Train net output #0: loss = 0.146983 (* 1 = 0.146983 loss)
I0916 12:28:15.564427 19004 sgd_solver.cpp:136] Iteration 41400, lr = 0.01, m = 0.9
I0916 12:28:35.868748 19004 solver.cpp:314] Iteration 41500 (4.92518 iter/s, 20.3038s/100 iter), loss = 0.0926248
I0916 12:28:35.868773 19004 solver.cpp:336]     Train net output #0: loss = 0.0926247 (* 1 = 0.0926247 loss)
I0916 12:28:35.868779 19004 sgd_solver.cpp:136] Iteration 41500, lr = 0.01, m = 0.9
I0916 12:28:56.291107 19004 solver.cpp:314] Iteration 41600 (4.89673 iter/s, 20.4218s/100 iter), loss = 0.0558721
I0916 12:28:56.291206 19004 solver.cpp:336]     Train net output #0: loss = 0.055872 (* 1 = 0.055872 loss)
I0916 12:28:56.291223 19004 sgd_solver.cpp:136] Iteration 41600, lr = 0.01, m = 0.9
I0916 12:29:06.039258 19010 data_reader.cpp:305] Starting prefetch of epoch 24
I0916 12:29:17.536607 19004 solver.cpp:314] Iteration 41700 (4.70701 iter/s, 21.2449s/100 iter), loss = 0.126317
I0916 12:29:17.536628 19004 solver.cpp:336]     Train net output #0: loss = 0.126317 (* 1 = 0.126317 loss)
I0916 12:29:17.536634 19004 sgd_solver.cpp:136] Iteration 41700, lr = 0.01, m = 0.9
I0916 12:29:37.885757 19004 solver.cpp:314] Iteration 41800 (4.91435 iter/s, 20.3486s/100 iter), loss = 0.0945935
I0916 12:29:37.885833 19004 solver.cpp:336]     Train net output #0: loss = 0.0945933 (* 1 = 0.0945933 loss)
I0916 12:29:37.885838 19004 sgd_solver.cpp:136] Iteration 41800, lr = 0.01, m = 0.9
I0916 12:29:40.430213 19008 data_reader.cpp:305] Starting prefetch of epoch 22
I0916 12:29:58.251405 19004 solver.cpp:314] Iteration 41900 (4.91037 iter/s, 20.3651s/100 iter), loss = 0.101525
I0916 12:29:58.251432 19004 solver.cpp:336]     Train net output #0: loss = 0.101525 (* 1 = 0.101525 loss)
I0916 12:29:58.251440 19004 sgd_solver.cpp:136] Iteration 41900, lr = 0.01, m = 0.9
I0916 12:30:18.454674 19004 solver.cpp:563] Iteration 42000, Testing net (#0)
I0916 12:30:26.511250 19015 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 12:30:31.165532 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.72536
I0916 12:30:31.165552 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.999969
I0916 12:30:31.165558 19004 solver.cpp:655]     Test net output #2: loss = 0.942593 (* 1 = 0.942593 loss)
I0916 12:30:31.165581 19004 solver.cpp:265] [MultiGPU] Tests completed in 12.7106s
I0916 12:30:31.365226 19004 solver.cpp:314] Iteration 42000 (3.01997 iter/s, 33.1129s/100 iter), loss = 0.0877278
I0916 12:30:31.365252 19004 solver.cpp:336]     Train net output #0: loss = 0.0877276 (* 1 = 0.0877276 loss)
I0916 12:30:31.365257 19004 sgd_solver.cpp:136] Iteration 42000, lr = 0.01, m = 0.9
I0916 12:30:51.242769 19004 solver.cpp:314] Iteration 42100 (5.03094 iter/s, 19.877s/100 iter), loss = 0.0731179
I0916 12:30:51.242820 19004 solver.cpp:336]     Train net output #0: loss = 0.0731177 (* 1 = 0.0731177 loss)
I0916 12:30:51.242825 19004 sgd_solver.cpp:136] Iteration 42100, lr = 0.01, m = 0.9
I0916 12:31:11.292573 19004 solver.cpp:314] Iteration 42200 (4.98772 iter/s, 20.0492s/100 iter), loss = 0.0581801
I0916 12:31:11.292598 19004 solver.cpp:336]     Train net output #0: loss = 0.0581799 (* 1 = 0.0581799 loss)
I0916 12:31:11.292603 19004 sgd_solver.cpp:136] Iteration 42200, lr = 0.01, m = 0.9
I0916 12:31:31.777068 19004 solver.cpp:314] Iteration 42300 (4.88188 iter/s, 20.4839s/100 iter), loss = 0.0856563
I0916 12:31:31.778110 19004 solver.cpp:336]     Train net output #0: loss = 0.0856561 (* 1 = 0.0856561 loss)
I0916 12:31:31.778128 19004 sgd_solver.cpp:136] Iteration 42300, lr = 0.01, m = 0.9
I0916 12:31:33.412624 19010 data_reader.cpp:305] Starting prefetch of epoch 25
I0916 12:31:52.386106 19004 solver.cpp:314] Iteration 42400 (4.85238 iter/s, 20.6085s/100 iter), loss = 0.0635557
I0916 12:31:52.386148 19004 solver.cpp:336]     Train net output #0: loss = 0.0635555 (* 1 = 0.0635555 loss)
I0916 12:31:52.386158 19004 sgd_solver.cpp:136] Iteration 42400, lr = 0.01, m = 0.9
I0916 12:32:12.092944 19004 solver.cpp:314] Iteration 42500 (5.07452 iter/s, 19.7063s/100 iter), loss = 0.0602097
I0916 12:32:12.093030 19004 solver.cpp:336]     Train net output #0: loss = 0.0602096 (* 1 = 0.0602096 loss)
I0916 12:32:12.093045 19004 sgd_solver.cpp:136] Iteration 42500, lr = 0.01, m = 0.9
I0916 12:32:32.541795 19004 solver.cpp:314] Iteration 42600 (4.89039 iter/s, 20.4483s/100 iter), loss = 0.110015
I0916 12:32:32.541844 19004 solver.cpp:336]     Train net output #0: loss = 0.110014 (* 1 = 0.110014 loss)
I0916 12:32:32.541858 19004 sgd_solver.cpp:136] Iteration 42600, lr = 0.01, m = 0.9
I0916 12:32:40.340186 18963 data_reader.cpp:305] Starting prefetch of epoch 30
I0916 12:32:52.900167 19004 solver.cpp:314] Iteration 42700 (4.91212 iter/s, 20.3578s/100 iter), loss = 0.0647124
I0916 12:32:52.900223 19004 solver.cpp:336]     Train net output #0: loss = 0.0647123 (* 1 = 0.0647123 loss)
I0916 12:32:52.900228 19004 sgd_solver.cpp:136] Iteration 42700, lr = 0.01, m = 0.9
I0916 12:33:13.356602 19004 solver.cpp:314] Iteration 42800 (4.88857 iter/s, 20.4559s/100 iter), loss = 0.065893
I0916 12:33:13.356631 19004 solver.cpp:336]     Train net output #0: loss = 0.0658928 (* 1 = 0.0658928 loss)
I0916 12:33:13.356637 19004 sgd_solver.cpp:136] Iteration 42800, lr = 0.01, m = 0.9
I0916 12:33:13.998836 18963 data_reader.cpp:305] Starting prefetch of epoch 31
I0916 12:33:34.160840 19004 solver.cpp:314] Iteration 42900 (4.80685 iter/s, 20.8037s/100 iter), loss = 0.0552647
I0916 12:33:34.160912 19004 solver.cpp:336]     Train net output #0: loss = 0.0552645 (* 1 = 0.0552645 loss)
I0916 12:33:34.160918 19004 sgd_solver.cpp:136] Iteration 42900, lr = 0.01, m = 0.9
I0916 12:33:54.653443 19004 solver.cpp:314] Iteration 43000 (4.87994 iter/s, 20.492s/100 iter), loss = 0.0542921
I0916 12:33:54.653467 19004 solver.cpp:336]     Train net output #0: loss = 0.0542919 (* 1 = 0.0542919 loss)
I0916 12:33:54.653473 19004 sgd_solver.cpp:136] Iteration 43000, lr = 0.01, m = 0.9
I0916 12:34:15.437078 19004 solver.cpp:314] Iteration 43100 (4.81161 iter/s, 20.7831s/100 iter), loss = 0.103619
I0916 12:34:15.437135 19004 solver.cpp:336]     Train net output #0: loss = 0.103619 (* 1 = 0.103619 loss)
I0916 12:34:15.437142 19004 sgd_solver.cpp:136] Iteration 43100, lr = 0.01, m = 0.9
I0916 12:34:22.427211 18963 data_reader.cpp:305] Starting prefetch of epoch 32
I0916 12:34:35.890825 19004 solver.cpp:314] Iteration 43200 (4.88922 iter/s, 20.4532s/100 iter), loss = 0.117936
I0916 12:34:35.890872 19004 solver.cpp:336]     Train net output #0: loss = 0.117936 (* 1 = 0.117936 loss)
I0916 12:34:35.890887 19004 sgd_solver.cpp:136] Iteration 43200, lr = 0.01, m = 0.9
I0916 12:34:56.703125 19004 solver.cpp:314] Iteration 43300 (4.80498 iter/s, 20.8117s/100 iter), loss = 0.0577251
I0916 12:34:56.703207 19004 solver.cpp:336]     Train net output #0: loss = 0.0577249 (* 1 = 0.0577249 loss)
I0916 12:34:56.703213 19004 sgd_solver.cpp:136] Iteration 43300, lr = 0.01, m = 0.9
I0916 12:35:16.720717 19004 solver.cpp:314] Iteration 43400 (4.99575 iter/s, 20.017s/100 iter), loss = 0.0796546
I0916 12:35:16.720746 19004 solver.cpp:336]     Train net output #0: loss = 0.0796544 (* 1 = 0.0796544 loss)
I0916 12:35:16.720752 19004 sgd_solver.cpp:136] Iteration 43400, lr = 0.01, m = 0.9
I0916 12:35:30.045109 18961 data_reader.cpp:305] Starting prefetch of epoch 23
I0916 12:35:37.278877 19004 solver.cpp:314] Iteration 43500 (4.86439 iter/s, 20.5576s/100 iter), loss = 0.219043
I0916 12:35:37.278928 19004 solver.cpp:336]     Train net output #0: loss = 0.219043 (* 1 = 0.219043 loss)
I0916 12:35:37.278944 19004 sgd_solver.cpp:136] Iteration 43500, lr = 0.01, m = 0.9
I0916 12:35:57.508889 19004 solver.cpp:314] Iteration 43600 (4.94329 iter/s, 20.2295s/100 iter), loss = 0.0560241
I0916 12:35:57.508916 19004 solver.cpp:336]     Train net output #0: loss = 0.056024 (* 1 = 0.056024 loss)
I0916 12:35:57.508922 19004 sgd_solver.cpp:136] Iteration 43600, lr = 0.01, m = 0.9
I0916 12:36:03.662516 18961 data_reader.cpp:305] Starting prefetch of epoch 24
I0916 12:36:17.595466 19004 solver.cpp:314] Iteration 43700 (4.97859 iter/s, 20.086s/100 iter), loss = 0.102619
I0916 12:36:17.595499 19004 solver.cpp:336]     Train net output #0: loss = 0.102618 (* 1 = 0.102618 loss)
I0916 12:36:17.595505 19004 sgd_solver.cpp:136] Iteration 43700, lr = 0.01, m = 0.9
I0916 12:36:37.908519 19004 solver.cpp:314] Iteration 43800 (4.92308 iter/s, 20.3125s/100 iter), loss = 0.0418136
I0916 12:36:37.908587 19004 solver.cpp:336]     Train net output #0: loss = 0.0418135 (* 1 = 0.0418135 loss)
I0916 12:36:37.908596 19004 sgd_solver.cpp:136] Iteration 43800, lr = 0.01, m = 0.9
I0916 12:36:58.111428 19004 solver.cpp:314] Iteration 43900 (4.94992 iter/s, 20.2024s/100 iter), loss = 0.0565081
I0916 12:36:58.111449 19004 solver.cpp:336]     Train net output #0: loss = 0.0565079 (* 1 = 0.0565079 loss)
I0916 12:36:58.111454 19004 sgd_solver.cpp:136] Iteration 43900, lr = 0.01, m = 0.9
I0916 12:37:10.245033 19012 data_reader.cpp:305] Starting prefetch of epoch 22
I0916 12:37:18.071671 19004 solver.cpp:563] Iteration 44000, Testing net (#0)
I0916 12:37:29.529166 19002 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 12:37:30.522693 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.950617
I0916 12:37:30.522719 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 12:37:30.522727 19004 solver.cpp:655]     Test net output #2: loss = 0.145066 (* 1 = 0.145066 loss)
I0916 12:37:30.522754 19004 solver.cpp:265] [MultiGPU] Tests completed in 12.4507s
I0916 12:37:30.743870 19004 solver.cpp:314] Iteration 44000 (3.06452 iter/s, 32.6315s/100 iter), loss = 0.103628
I0916 12:37:30.743903 19004 solver.cpp:336]     Train net output #0: loss = 0.103628 (* 1 = 0.103628 loss)
I0916 12:37:30.743909 19004 sgd_solver.cpp:136] Iteration 44000, lr = 0.01, m = 0.9
I0916 12:37:50.915756 19004 solver.cpp:314] Iteration 44100 (4.95753 iter/s, 20.1713s/100 iter), loss = 0.0643817
I0916 12:37:50.917872 19004 solver.cpp:336]     Train net output #0: loss = 0.0643815 (* 1 = 0.0643815 loss)
I0916 12:37:50.917896 19004 sgd_solver.cpp:136] Iteration 44100, lr = 0.01, m = 0.9
I0916 12:37:56.331069 18961 data_reader.cpp:305] Starting prefetch of epoch 25
I0916 12:38:11.548358 19004 solver.cpp:314] Iteration 44200 (4.84683 iter/s, 20.632s/100 iter), loss = 0.0846753
I0916 12:38:11.548382 19004 solver.cpp:336]     Train net output #0: loss = 0.0846751 (* 1 = 0.0846751 loss)
I0916 12:38:11.548388 19004 sgd_solver.cpp:136] Iteration 44200, lr = 0.01, m = 0.9
I0916 12:38:31.752636 19004 solver.cpp:314] Iteration 44300 (4.94958 iter/s, 20.2037s/100 iter), loss = 0.0658988
I0916 12:38:31.752687 19004 solver.cpp:336]     Train net output #0: loss = 0.0658987 (* 1 = 0.0658987 loss)
I0916 12:38:31.752692 19004 sgd_solver.cpp:136] Iteration 44300, lr = 0.01, m = 0.9
I0916 12:38:51.963670 19004 solver.cpp:314] Iteration 44400 (4.94793 iter/s, 20.2105s/100 iter), loss = 0.0625844
I0916 12:38:51.963696 19004 solver.cpp:336]     Train net output #0: loss = 0.0625842 (* 1 = 0.0625842 loss)
I0916 12:38:51.963701 19004 sgd_solver.cpp:136] Iteration 44400, lr = 0.01, m = 0.9
I0916 12:39:03.414710 19010 data_reader.cpp:305] Starting prefetch of epoch 26
I0916 12:39:12.270669 19004 solver.cpp:314] Iteration 44500 (4.92455 iter/s, 20.3064s/100 iter), loss = 0.0651625
I0916 12:39:12.270701 19004 solver.cpp:336]     Train net output #0: loss = 0.0651623 (* 1 = 0.0651623 loss)
I0916 12:39:12.270705 19004 sgd_solver.cpp:136] Iteration 44500, lr = 0.01, m = 0.9
I0916 12:39:32.768496 19004 solver.cpp:314] Iteration 44600 (4.8787 iter/s, 20.4973s/100 iter), loss = 0.0798738
I0916 12:39:32.768524 19004 solver.cpp:336]     Train net output #0: loss = 0.0798736 (* 1 = 0.0798736 loss)
I0916 12:39:32.768530 19004 sgd_solver.cpp:136] Iteration 44600, lr = 0.01, m = 0.9
I0916 12:39:52.854178 19004 solver.cpp:314] Iteration 44700 (4.97881 iter/s, 20.0851s/100 iter), loss = 0.0664947
I0916 12:39:52.854223 19004 solver.cpp:336]     Train net output #0: loss = 0.0664945 (* 1 = 0.0664945 loss)
I0916 12:39:52.854228 19004 sgd_solver.cpp:136] Iteration 44700, lr = 0.01, m = 0.9
I0916 12:40:11.103389 19012 data_reader.cpp:305] Starting prefetch of epoch 23
I0916 12:40:13.884285 19004 solver.cpp:314] Iteration 44800 (4.75522 iter/s, 21.0295s/100 iter), loss = 0.0823071
I0916 12:40:13.884342 19004 solver.cpp:336]     Train net output #0: loss = 0.0823069 (* 1 = 0.0823069 loss)
I0916 12:40:13.884372 19004 sgd_solver.cpp:136] Iteration 44800, lr = 0.01, m = 0.9
I0916 12:40:34.878866 19004 solver.cpp:314] Iteration 44900 (4.76327 iter/s, 20.994s/100 iter), loss = 0.0746129
I0916 12:40:34.878921 19004 solver.cpp:336]     Train net output #0: loss = 0.0746127 (* 1 = 0.0746127 loss)
I0916 12:40:34.878927 19004 sgd_solver.cpp:136] Iteration 44900, lr = 0.01, m = 0.9
I0916 12:40:45.626087 19008 data_reader.cpp:305] Starting prefetch of epoch 23
I0916 12:40:54.925810 19004 solver.cpp:314] Iteration 45000 (4.98843 iter/s, 20.0464s/100 iter), loss = 0.0735157
I0916 12:40:54.925832 19004 solver.cpp:336]     Train net output #0: loss = 0.0735155 (* 1 = 0.0735155 loss)
I0916 12:40:54.925835 19004 sgd_solver.cpp:136] Iteration 45000, lr = 0.01, m = 0.9
I0916 12:41:15.780223 19004 solver.cpp:314] Iteration 45100 (4.79528 iter/s, 20.8538s/100 iter), loss = 0.149981
I0916 12:41:15.780365 19004 solver.cpp:336]     Train net output #0: loss = 0.149981 (* 1 = 0.149981 loss)
I0916 12:41:15.780380 19004 sgd_solver.cpp:136] Iteration 45100, lr = 0.01, m = 0.9
I0916 12:41:36.198704 19004 solver.cpp:314] Iteration 45200 (4.89766 iter/s, 20.4179s/100 iter), loss = 0.079823
I0916 12:41:36.198932 19004 solver.cpp:336]     Train net output #0: loss = 0.0798228 (* 1 = 0.0798228 loss)
I0916 12:41:36.199024 19004 sgd_solver.cpp:136] Iteration 45200, lr = 0.01, m = 0.9
I0916 12:41:52.913228 18961 data_reader.cpp:305] Starting prefetch of epoch 26
I0916 12:41:56.353343 19004 solver.cpp:314] Iteration 45300 (4.96177 iter/s, 20.1541s/100 iter), loss = 0.0732792
I0916 12:41:56.353366 19004 solver.cpp:336]     Train net output #0: loss = 0.0732789 (* 1 = 0.0732789 loss)
I0916 12:41:56.353371 19004 sgd_solver.cpp:136] Iteration 45300, lr = 0.01, m = 0.9
I0916 12:42:16.793197 19004 solver.cpp:314] Iteration 45400 (4.89254 iter/s, 20.4393s/100 iter), loss = 0.0746688
I0916 12:42:16.793222 19004 solver.cpp:336]     Train net output #0: loss = 0.0746686 (* 1 = 0.0746686 loss)
I0916 12:42:16.793228 19004 sgd_solver.cpp:136] Iteration 45400, lr = 0.01, m = 0.9
I0916 12:42:37.390162 19004 solver.cpp:314] Iteration 45500 (4.85522 iter/s, 20.5964s/100 iter), loss = 0.0870075
I0916 12:42:37.390302 19004 solver.cpp:336]     Train net output #0: loss = 0.0870073 (* 1 = 0.0870073 loss)
I0916 12:42:37.390336 19004 sgd_solver.cpp:136] Iteration 45500, lr = 0.01, m = 0.9
I0916 12:42:58.470544 19004 solver.cpp:314] Iteration 45600 (4.74388 iter/s, 21.0798s/100 iter), loss = 0.10386
I0916 12:42:58.470573 19004 solver.cpp:336]     Train net output #0: loss = 0.103859 (* 1 = 0.103859 loss)
I0916 12:42:58.470579 19004 sgd_solver.cpp:136] Iteration 45600, lr = 0.01, m = 0.9
I0916 12:43:00.992514 18963 data_reader.cpp:305] Starting prefetch of epoch 33
I0916 12:43:18.392413 19004 solver.cpp:314] Iteration 45700 (5.01975 iter/s, 19.9213s/100 iter), loss = 0.0558614
I0916 12:43:18.392515 19004 solver.cpp:336]     Train net output #0: loss = 0.0558611 (* 1 = 0.0558611 loss)
I0916 12:43:18.392535 19004 sgd_solver.cpp:136] Iteration 45700, lr = 0.01, m = 0.9
I0916 12:43:34.844007 19008 data_reader.cpp:305] Starting prefetch of epoch 24
I0916 12:43:39.326208 19004 solver.cpp:314] Iteration 45800 (4.7771 iter/s, 20.9332s/100 iter), loss = 0.0896395
I0916 12:43:39.326287 19004 solver.cpp:336]     Train net output #0: loss = 0.0896393 (* 1 = 0.0896393 loss)
I0916 12:43:39.326313 19004 sgd_solver.cpp:136] Iteration 45800, lr = 0.01, m = 0.9
I0916 12:44:00.166172 19004 solver.cpp:314] Iteration 45900 (4.7986 iter/s, 20.8394s/100 iter), loss = 0.0491346
I0916 12:44:00.166267 19004 solver.cpp:336]     Train net output #0: loss = 0.0491345 (* 1 = 0.0491345 loss)
I0916 12:44:00.166275 19004 sgd_solver.cpp:136] Iteration 45900, lr = 0.01, m = 0.9
I0916 12:44:20.336724 19004 solver.cpp:563] Iteration 46000, Testing net (#0)
I0916 12:44:28.083513 19018 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 12:44:33.115671 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.950474
I0916 12:44:33.115770 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 12:44:33.115779 19004 solver.cpp:655]     Test net output #2: loss = 0.191106 (* 1 = 0.191106 loss)
I0916 12:44:33.115805 19004 solver.cpp:265] [MultiGPU] Tests completed in 12.7787s
I0916 12:44:33.332659 19004 solver.cpp:314] Iteration 46000 (3.01517 iter/s, 33.1656s/100 iter), loss = 0.0656871
I0916 12:44:33.332680 19004 solver.cpp:336]     Train net output #0: loss = 0.0656869 (* 1 = 0.0656869 loss)
I0916 12:44:33.332684 19004 sgd_solver.cpp:136] Iteration 46000, lr = 0.01, m = 0.9
I0916 12:44:52.584581 19004 solver.cpp:314] Iteration 46100 (5.19443 iter/s, 19.2514s/100 iter), loss = 0.0579707
I0916 12:44:52.584602 19004 solver.cpp:336]     Train net output #0: loss = 0.0579705 (* 1 = 0.0579705 loss)
I0916 12:44:52.584609 19004 sgd_solver.cpp:136] Iteration 46100, lr = 0.01, m = 0.9
I0916 12:45:11.911447 19004 solver.cpp:314] Iteration 46200 (5.17429 iter/s, 19.3263s/100 iter), loss = 0.0422299
I0916 12:45:11.911535 19004 solver.cpp:336]     Train net output #0: loss = 0.0422297 (* 1 = 0.0422297 loss)
I0916 12:45:11.911545 19004 sgd_solver.cpp:136] Iteration 46200, lr = 0.01, m = 0.9
I0916 12:45:26.130019 19012 data_reader.cpp:305] Starting prefetch of epoch 24
I0916 12:45:26.130019 18963 data_reader.cpp:305] Starting prefetch of epoch 34
I0916 12:45:26.130019 19010 data_reader.cpp:305] Starting prefetch of epoch 27
I0916 12:45:31.178233 19004 solver.cpp:314] Iteration 46300 (5.19042 iter/s, 19.2663s/100 iter), loss = 0.0700249
I0916 12:45:31.178261 19004 solver.cpp:336]     Train net output #0: loss = 0.0700247 (* 1 = 0.0700247 loss)
I0916 12:45:31.178267 19004 sgd_solver.cpp:136] Iteration 46300, lr = 0.01, m = 0.9
I0916 12:45:50.645879 19004 solver.cpp:314] Iteration 46400 (5.13687 iter/s, 19.4671s/100 iter), loss = 0.0997258
I0916 12:45:50.645929 19004 solver.cpp:336]     Train net output #0: loss = 0.0997257 (* 1 = 0.0997257 loss)
I0916 12:45:50.645936 19004 sgd_solver.cpp:136] Iteration 46400, lr = 0.01, m = 0.9
I0916 12:46:10.028951 19004 solver.cpp:314] Iteration 46500 (5.15928 iter/s, 19.3825s/100 iter), loss = 0.109924
I0916 12:46:10.028980 19004 solver.cpp:336]     Train net output #0: loss = 0.109924 (* 1 = 0.109924 loss)
I0916 12:46:10.028987 19004 sgd_solver.cpp:136] Iteration 46500, lr = 0.01, m = 0.9
I0916 12:46:29.533120 19004 solver.cpp:314] Iteration 46600 (5.12725 iter/s, 19.5036s/100 iter), loss = 0.0424598
I0916 12:46:29.538148 19004 solver.cpp:336]     Train net output #0: loss = 0.0424597 (* 1 = 0.0424597 loss)
I0916 12:46:29.538175 19004 sgd_solver.cpp:136] Iteration 46600, lr = 0.01, m = 0.9
I0916 12:46:30.550218 19012 data_reader.cpp:305] Starting prefetch of epoch 25
I0916 12:46:48.779893 19004 solver.cpp:314] Iteration 46700 (5.19582 iter/s, 19.2462s/100 iter), loss = 0.084398
I0916 12:46:48.779917 19004 solver.cpp:336]     Train net output #0: loss = 0.0843978 (* 1 = 0.0843978 loss)
I0916 12:46:48.779920 19004 sgd_solver.cpp:136] Iteration 46700, lr = 0.01, m = 0.9
I0916 12:47:02.510603 19008 data_reader.cpp:305] Starting prefetch of epoch 25
I0916 12:47:08.180799 19004 solver.cpp:314] Iteration 46800 (5.15454 iter/s, 19.4004s/100 iter), loss = 0.0959525
I0916 12:47:08.180822 19004 solver.cpp:336]     Train net output #0: loss = 0.0959524 (* 1 = 0.0959524 loss)
I0916 12:47:08.180829 19004 sgd_solver.cpp:136] Iteration 46800, lr = 0.01, m = 0.9
I0916 12:47:27.892709 19004 solver.cpp:314] Iteration 46900 (5.07322 iter/s, 19.7114s/100 iter), loss = 0.0817681
I0916 12:47:27.892735 19004 solver.cpp:336]     Train net output #0: loss = 0.0817679 (* 1 = 0.0817679 loss)
I0916 12:47:27.892741 19004 sgd_solver.cpp:136] Iteration 46900, lr = 0.01, m = 0.9
I0916 12:47:47.363637 19004 solver.cpp:314] Iteration 47000 (5.136 iter/s, 19.4704s/100 iter), loss = 0.05213
I0916 12:47:47.363690 19004 solver.cpp:336]     Train net output #0: loss = 0.0521299 (* 1 = 0.0521299 loss)
I0916 12:47:47.363698 19004 sgd_solver.cpp:136] Iteration 47000, lr = 0.01, m = 0.9
I0916 12:48:06.784152 19004 solver.cpp:314] Iteration 47100 (5.14934 iter/s, 19.42s/100 iter), loss = 0.073306
I0916 12:48:06.784173 19004 solver.cpp:336]     Train net output #0: loss = 0.0733059 (* 1 = 0.0733059 loss)
I0916 12:48:06.784179 19004 sgd_solver.cpp:136] Iteration 47100, lr = 0.01, m = 0.9
I0916 12:48:07.003970 19008 data_reader.cpp:305] Starting prefetch of epoch 26
I0916 12:48:26.210577 19004 solver.cpp:314] Iteration 47200 (5.14777 iter/s, 19.4259s/100 iter), loss = 0.0628857
I0916 12:48:26.210633 19004 solver.cpp:336]     Train net output #0: loss = 0.0628855 (* 1 = 0.0628855 loss)
I0916 12:48:26.210638 19004 sgd_solver.cpp:136] Iteration 47200, lr = 0.01, m = 0.9
I0916 12:48:45.776880 19004 solver.cpp:314] Iteration 47300 (5.11097 iter/s, 19.5658s/100 iter), loss = 0.193129
I0916 12:48:45.776902 19004 solver.cpp:336]     Train net output #0: loss = 0.193129 (* 1 = 0.193129 loss)
I0916 12:48:45.776907 19004 sgd_solver.cpp:136] Iteration 47300, lr = 0.01, m = 0.9
I0916 12:49:05.672868 19004 solver.cpp:314] Iteration 47400 (5.02628 iter/s, 19.8954s/100 iter), loss = 0.0506618
I0916 12:49:05.675277 19004 solver.cpp:336]     Train net output #0: loss = 0.0506616 (* 1 = 0.0506616 loss)
I0916 12:49:05.675292 19004 sgd_solver.cpp:136] Iteration 47400, lr = 0.01, m = 0.9
I0916 12:49:12.088275 19012 data_reader.cpp:305] Starting prefetch of epoch 26
I0916 12:49:25.990465 19004 solver.cpp:314] Iteration 47500 (4.92198 iter/s, 20.317s/100 iter), loss = 0.0537592
I0916 12:49:25.990490 19004 solver.cpp:336]     Train net output #0: loss = 0.053759 (* 1 = 0.053759 loss)
I0916 12:49:25.990494 19004 sgd_solver.cpp:136] Iteration 47500, lr = 0.01, m = 0.9
I0916 12:49:45.897135 18961 data_reader.cpp:305] Starting prefetch of epoch 27
I0916 12:49:46.649361 19004 solver.cpp:314] Iteration 47600 (4.84066 iter/s, 20.6583s/100 iter), loss = 0.0844291
I0916 12:49:46.649389 19004 solver.cpp:336]     Train net output #0: loss = 0.084429 (* 1 = 0.084429 loss)
I0916 12:49:46.649395 19004 sgd_solver.cpp:136] Iteration 47600, lr = 0.01, m = 0.9
I0916 12:50:07.322046 19004 solver.cpp:314] Iteration 47700 (4.83744 iter/s, 20.6721s/100 iter), loss = 0.072213
I0916 12:50:07.322104 19004 solver.cpp:336]     Train net output #0: loss = 0.0722129 (* 1 = 0.0722129 loss)
I0916 12:50:07.322130 19004 sgd_solver.cpp:136] Iteration 47700, lr = 0.01, m = 0.9
I0916 12:50:27.957361 19004 solver.cpp:314] Iteration 47800 (4.84619 iter/s, 20.6348s/100 iter), loss = 0.101593
I0916 12:50:27.957412 19004 solver.cpp:336]     Train net output #0: loss = 0.101592 (* 1 = 0.101592 loss)
I0916 12:50:27.957417 19004 sgd_solver.cpp:136] Iteration 47800, lr = 0.01, m = 0.9
I0916 12:50:48.344139 19004 solver.cpp:314] Iteration 47900 (4.90527 iter/s, 20.3862s/100 iter), loss = 0.069425
I0916 12:50:48.344161 19004 solver.cpp:336]     Train net output #0: loss = 0.0694249 (* 1 = 0.0694249 loss)
I0916 12:50:48.344167 19004 sgd_solver.cpp:136] Iteration 47900, lr = 0.01, m = 0.9
I0916 12:50:53.764566 18963 data_reader.cpp:305] Starting prefetch of epoch 35
I0916 12:51:08.247339 19004 solver.cpp:563] Iteration 48000, Testing net (#0)
I0916 12:51:19.489050 19018 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 12:51:20.226167 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.950638
I0916 12:51:20.226187 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 12:51:20.226194 19004 solver.cpp:655]     Test net output #2: loss = 0.180522 (* 1 = 0.180522 loss)
I0916 12:51:20.226215 19004 solver.cpp:265] [MultiGPU] Tests completed in 11.9785s
I0916 12:51:20.412683 19004 solver.cpp:314] Iteration 48000 (3.11841 iter/s, 32.0677s/100 iter), loss = 0.216324
I0916 12:51:20.412709 19004 solver.cpp:336]     Train net output #0: loss = 0.216324 (* 1 = 0.216324 loss)
I0916 12:51:20.412714 19004 sgd_solver.cpp:136] Iteration 48000, lr = 0.01, m = 0.9
I0916 12:51:39.347846 19008 data_reader.cpp:305] Starting prefetch of epoch 27
I0916 12:51:40.872469 19004 solver.cpp:314] Iteration 48100 (4.88777 iter/s, 20.4592s/100 iter), loss = 0.058082
I0916 12:51:40.872495 19004 solver.cpp:336]     Train net output #0: loss = 0.0580818 (* 1 = 0.0580818 loss)
I0916 12:51:40.872501 19004 sgd_solver.cpp:136] Iteration 48100, lr = 0.01, m = 0.9
I0916 12:52:00.345072 19004 solver.cpp:314] Iteration 48200 (5.13556 iter/s, 19.4721s/100 iter), loss = 0.0651345
I0916 12:52:00.345096 19004 solver.cpp:336]     Train net output #0: loss = 0.0651343 (* 1 = 0.0651343 loss)
I0916 12:52:00.345100 19004 sgd_solver.cpp:136] Iteration 48200, lr = 0.01, m = 0.9
I0916 12:52:19.629281 19004 solver.cpp:314] Iteration 48300 (5.18573 iter/s, 19.2837s/100 iter), loss = 0.0451128
I0916 12:52:19.629362 19004 solver.cpp:336]     Train net output #0: loss = 0.0451127 (* 1 = 0.0451127 loss)
I0916 12:52:19.629369 19004 sgd_solver.cpp:136] Iteration 48300, lr = 0.01, m = 0.9
I0916 12:52:38.941347 19004 solver.cpp:314] Iteration 48400 (5.17825 iter/s, 19.3115s/100 iter), loss = 0.0581393
I0916 12:52:38.941416 19004 solver.cpp:336]     Train net output #0: loss = 0.0581392 (* 1 = 0.0581392 loss)
I0916 12:52:38.941434 19004 sgd_solver.cpp:136] Iteration 48400, lr = 0.01, m = 0.9
I0916 12:52:43.404273 18963 data_reader.cpp:305] Starting prefetch of epoch 36
I0916 12:52:58.326547 19004 solver.cpp:314] Iteration 48500 (5.15872 iter/s, 19.3847s/100 iter), loss = 0.0545872
I0916 12:52:58.326617 19004 solver.cpp:336]     Train net output #0: loss = 0.0545871 (* 1 = 0.0545871 loss)
I0916 12:52:58.326623 19004 sgd_solver.cpp:136] Iteration 48500, lr = 0.01, m = 0.9
I0916 12:53:17.994740 19004 solver.cpp:314] Iteration 48600 (5.08449 iter/s, 19.6677s/100 iter), loss = 0.0520519
I0916 12:53:17.994762 19004 solver.cpp:336]     Train net output #0: loss = 0.0520518 (* 1 = 0.0520518 loss)
I0916 12:53:17.994770 19004 sgd_solver.cpp:136] Iteration 48600, lr = 0.01, m = 0.9
I0916 12:53:37.373087 19004 solver.cpp:314] Iteration 48700 (5.16054 iter/s, 19.3778s/100 iter), loss = 0.0588717
I0916 12:53:37.373143 19004 solver.cpp:336]     Train net output #0: loss = 0.0588715 (* 1 = 0.0588715 loss)
I0916 12:53:37.373150 19004 sgd_solver.cpp:136] Iteration 48700, lr = 0.01, m = 0.9
I0916 12:53:47.675182 19010 data_reader.cpp:305] Starting prefetch of epoch 28
I0916 12:53:56.642935 19004 solver.cpp:314] Iteration 48800 (5.1896 iter/s, 19.2693s/100 iter), loss = 0.113139
I0916 12:53:56.642961 19004 solver.cpp:336]     Train net output #0: loss = 0.113139 (* 1 = 0.113139 loss)
I0916 12:53:56.642966 19004 sgd_solver.cpp:136] Iteration 48800, lr = 0.01, m = 0.9
I0916 12:54:15.862453 19004 solver.cpp:314] Iteration 48900 (5.20319 iter/s, 19.219s/100 iter), loss = 0.069401
I0916 12:54:15.862506 19004 solver.cpp:336]     Train net output #0: loss = 0.0694009 (* 1 = 0.0694009 loss)
I0916 12:54:15.862511 19004 sgd_solver.cpp:136] Iteration 48900, lr = 0.01, m = 0.9
I0916 12:54:19.621474 18961 data_reader.cpp:305] Starting prefetch of epoch 28
I0916 12:54:35.458187 19004 solver.cpp:314] Iteration 49000 (5.10329 iter/s, 19.5952s/100 iter), loss = 0.0912406
I0916 12:54:35.458212 19004 solver.cpp:336]     Train net output #0: loss = 0.0912405 (* 1 = 0.0912405 loss)
I0916 12:54:35.458216 19004 sgd_solver.cpp:136] Iteration 49000, lr = 0.01, m = 0.9
I0916 12:54:54.823838 19004 solver.cpp:314] Iteration 49100 (5.16392 iter/s, 19.3651s/100 iter), loss = 0.0804436
I0916 12:54:54.823891 19004 solver.cpp:336]     Train net output #0: loss = 0.0804435 (* 1 = 0.0804435 loss)
I0916 12:54:54.823896 19004 sgd_solver.cpp:136] Iteration 49100, lr = 0.01, m = 0.9
I0916 12:55:14.270949 19004 solver.cpp:314] Iteration 49200 (5.14229 iter/s, 19.4466s/100 iter), loss = 0.112277
I0916 12:55:14.270970 19004 solver.cpp:336]     Train net output #0: loss = 0.112277 (* 1 = 0.112277 loss)
I0916 12:55:14.270975 19004 sgd_solver.cpp:136] Iteration 49200, lr = 0.01, m = 0.9
I0916 12:55:23.796082 19012 data_reader.cpp:305] Starting prefetch of epoch 27
I0916 12:55:33.827325 19004 solver.cpp:314] Iteration 49300 (5.11356 iter/s, 19.5558s/100 iter), loss = 0.135041
I0916 12:55:33.827415 19004 solver.cpp:336]     Train net output #0: loss = 0.135041 (* 1 = 0.135041 loss)
I0916 12:55:33.827433 19004 sgd_solver.cpp:136] Iteration 49300, lr = 0.01, m = 0.9
I0916 12:55:53.344483 19004 solver.cpp:314] Iteration 49400 (5.12384 iter/s, 19.5166s/100 iter), loss = 0.0726087
I0916 12:55:53.344508 19004 solver.cpp:336]     Train net output #0: loss = 0.0726086 (* 1 = 0.0726086 loss)
I0916 12:55:53.344514 19004 sgd_solver.cpp:136] Iteration 49400, lr = 0.01, m = 0.9
I0916 12:56:13.790671 19004 solver.cpp:314] Iteration 49500 (4.89102 iter/s, 20.4456s/100 iter), loss = 0.0534747
I0916 12:56:13.790773 19004 solver.cpp:336]     Train net output #0: loss = 0.0534746 (* 1 = 0.0534746 loss)
I0916 12:56:13.790781 19004 sgd_solver.cpp:136] Iteration 49500, lr = 0.01, m = 0.9
I0916 12:56:30.440232 19012 data_reader.cpp:305] Starting prefetch of epoch 28
I0916 12:56:34.651623 19004 solver.cpp:314] Iteration 49600 (4.79378 iter/s, 20.8604s/100 iter), loss = 0.0614025
I0916 12:56:34.651674 19004 solver.cpp:336]     Train net output #0: loss = 0.0614024 (* 1 = 0.0614024 loss)
I0916 12:56:34.651690 19004 sgd_solver.cpp:136] Iteration 49600, lr = 0.01, m = 0.9
I0916 12:56:55.624346 19004 solver.cpp:314] Iteration 49700 (4.76823 iter/s, 20.9722s/100 iter), loss = 0.0927896
I0916 12:56:55.624419 19004 solver.cpp:336]     Train net output #0: loss = 0.0927895 (* 1 = 0.0927895 loss)
I0916 12:56:55.624426 19004 sgd_solver.cpp:136] Iteration 49700, lr = 0.01, m = 0.9
I0916 12:57:04.717053 19007 data_reader.cpp:305] Starting prefetch of epoch 36
I0916 12:57:15.820641 19004 solver.cpp:314] Iteration 49800 (4.95154 iter/s, 20.1957s/100 iter), loss = 0.0957632
I0916 12:57:15.820665 19004 solver.cpp:336]     Train net output #0: loss = 0.0957631 (* 1 = 0.0957631 loss)
I0916 12:57:15.820672 19004 sgd_solver.cpp:136] Iteration 49800, lr = 0.01, m = 0.9
I0916 12:57:36.446522 19004 solver.cpp:314] Iteration 49900 (4.84841 iter/s, 20.6253s/100 iter), loss = 0.0468445
I0916 12:57:36.446622 19004 solver.cpp:336]     Train net output #0: loss = 0.0468444 (* 1 = 0.0468444 loss)
I0916 12:57:36.446638 19004 sgd_solver.cpp:136] Iteration 49900, lr = 0.01, m = 0.9
I0916 12:57:57.163666 19004 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/cityscapes5_jsegnet21v2_iter_50000.caffemodel
I0916 12:57:57.219053 19004 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/cityscapes5_jsegnet21v2_iter_50000.solverstate
I0916 12:57:57.223042 19004 solver.cpp:563] Iteration 50000, Testing net (#0)
I0916 12:58:06.608650 19029 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 12:58:11.270303 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.943358
I0916 12:58:11.270320 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 12:58:11.270325 19004 solver.cpp:655]     Test net output #2: loss = 0.177624 (* 1 = 0.177624 loss)
I0916 12:58:11.270354 19004 solver.cpp:265] [MultiGPU] Tests completed in 14.0469s
I0916 12:58:11.485621 19004 solver.cpp:314] Iteration 50000 (2.85403 iter/s, 35.0381s/100 iter), loss = 0.071514
I0916 12:58:11.485644 19004 solver.cpp:336]     Train net output #0: loss = 0.0715139 (* 1 = 0.0715139 loss)
I0916 12:58:11.485648 19004 sgd_solver.cpp:136] Iteration 50000, lr = 0.01, m = 0.9
I0916 12:58:31.809262 19004 solver.cpp:314] Iteration 50100 (4.92052 iter/s, 20.3231s/100 iter), loss = 0.0725779
I0916 12:58:31.809351 19004 solver.cpp:336]     Train net output #0: loss = 0.0725777 (* 1 = 0.0725777 loss)
I0916 12:58:31.809376 19004 sgd_solver.cpp:136] Iteration 50100, lr = 0.01, m = 0.9
I0916 12:58:52.815027 19004 solver.cpp:314] Iteration 50200 (4.76073 iter/s, 21.0052s/100 iter), loss = 0.0943601
I0916 12:58:52.815074 19004 solver.cpp:336]     Train net output #0: loss = 0.0943599 (* 1 = 0.0943599 loss)
I0916 12:58:52.815080 19004 sgd_solver.cpp:136] Iteration 50200, lr = 0.01, m = 0.9
I0916 12:59:01.382437 18963 data_reader.cpp:305] Starting prefetch of epoch 37
I0916 12:59:13.734597 19004 solver.cpp:314] Iteration 50300 (4.78035 iter/s, 20.919s/100 iter), loss = 0.0423758
I0916 12:59:13.734623 19004 solver.cpp:336]     Train net output #0: loss = 0.0423756 (* 1 = 0.0423756 loss)
I0916 12:59:13.734628 19004 sgd_solver.cpp:136] Iteration 50300, lr = 0.01, m = 0.9
I0916 12:59:34.154291 19004 solver.cpp:314] Iteration 50400 (4.89737 iter/s, 20.4191s/100 iter), loss = 0.059515
I0916 12:59:34.154342 19004 solver.cpp:336]     Train net output #0: loss = 0.0595148 (* 1 = 0.0595148 loss)
I0916 12:59:34.154350 19004 sgd_solver.cpp:136] Iteration 50400, lr = 0.01, m = 0.9
I0916 12:59:35.338796 19007 data_reader.cpp:305] Starting prefetch of epoch 37
I0916 12:59:54.726716 19004 solver.cpp:314] Iteration 50500 (4.86101 iter/s, 20.5718s/100 iter), loss = 0.0801042
I0916 12:59:54.726755 19004 solver.cpp:336]     Train net output #0: loss = 0.0801041 (* 1 = 0.0801041 loss)
I0916 12:59:54.726761 19004 sgd_solver.cpp:136] Iteration 50500, lr = 0.01, m = 0.9
I0916 13:00:14.980379 19004 solver.cpp:314] Iteration 50600 (4.93751 iter/s, 20.2531s/100 iter), loss = 0.13088
I0916 13:00:14.980520 19004 solver.cpp:336]     Train net output #0: loss = 0.130879 (* 1 = 0.130879 loss)
I0916 13:00:14.980547 19004 sgd_solver.cpp:136] Iteration 50600, lr = 0.01, m = 0.9
I0916 13:00:35.114631 19004 solver.cpp:314] Iteration 50700 (4.9668 iter/s, 20.1337s/100 iter), loss = 0.0535527
I0916 13:00:35.114655 19004 solver.cpp:336]     Train net output #0: loss = 0.0535525 (* 1 = 0.0535525 loss)
I0916 13:00:35.114661 19004 sgd_solver.cpp:136] Iteration 50700, lr = 0.01, m = 0.9
I0916 13:00:42.797571 19012 data_reader.cpp:305] Starting prefetch of epoch 29
I0916 13:00:55.773144 19004 solver.cpp:314] Iteration 50800 (4.84075 iter/s, 20.6579s/100 iter), loss = 0.122801
I0916 13:00:55.773216 19004 solver.cpp:336]     Train net output #0: loss = 0.122801 (* 1 = 0.122801 loss)
I0916 13:00:55.773222 19004 sgd_solver.cpp:136] Iteration 50800, lr = 0.01, m = 0.9
I0916 13:01:16.392475 19004 solver.cpp:314] Iteration 50900 (4.84995 iter/s, 20.6188s/100 iter), loss = 0.0639805
I0916 13:01:16.392505 19004 solver.cpp:336]     Train net output #0: loss = 0.0639804 (* 1 = 0.0639804 loss)
I0916 13:01:16.392511 19004 sgd_solver.cpp:136] Iteration 50900, lr = 0.01, m = 0.9
I0916 13:01:36.864198 19004 solver.cpp:314] Iteration 51000 (4.88492 iter/s, 20.4712s/100 iter), loss = 0.0263549
I0916 13:01:36.864264 19004 solver.cpp:336]     Train net output #0: loss = 0.0263547 (* 1 = 0.0263547 loss)
I0916 13:01:36.864270 19004 sgd_solver.cpp:136] Iteration 51000, lr = 0.01, m = 0.9
I0916 13:01:50.318886 19012 data_reader.cpp:305] Starting prefetch of epoch 30
I0916 13:01:56.804051 19004 solver.cpp:314] Iteration 51100 (5.01522 iter/s, 19.9393s/100 iter), loss = 0.178552
I0916 13:01:56.804078 19004 solver.cpp:336]     Train net output #0: loss = 0.178552 (* 1 = 0.178552 loss)
I0916 13:01:56.804085 19004 sgd_solver.cpp:136] Iteration 51100, lr = 0.01, m = 0.9
I0916 13:02:16.941926 19004 solver.cpp:314] Iteration 51200 (4.96591 iter/s, 20.1373s/100 iter), loss = 0.0905364
I0916 13:02:16.941973 19004 solver.cpp:336]     Train net output #0: loss = 0.0905362 (* 1 = 0.0905362 loss)
I0916 13:02:16.941979 19004 sgd_solver.cpp:136] Iteration 51200, lr = 0.01, m = 0.9
I0916 13:02:23.697710 19012 data_reader.cpp:305] Starting prefetch of epoch 31
I0916 13:02:37.297590 19004 solver.cpp:314] Iteration 51300 (4.91277 iter/s, 20.3551s/100 iter), loss = 0.0888994
I0916 13:02:37.297611 19004 solver.cpp:336]     Train net output #0: loss = 0.0888992 (* 1 = 0.0888992 loss)
I0916 13:02:37.297617 19004 sgd_solver.cpp:136] Iteration 51300, lr = 0.01, m = 0.9
I0916 13:02:57.484675 19004 solver.cpp:314] Iteration 51400 (4.9538 iter/s, 20.1865s/100 iter), loss = 0.0726976
I0916 13:02:57.484730 19004 solver.cpp:336]     Train net output #0: loss = 0.0726975 (* 1 = 0.0726975 loss)
I0916 13:02:57.484735 19004 sgd_solver.cpp:136] Iteration 51400, lr = 0.01, m = 0.9
I0916 13:03:18.049409 19004 solver.cpp:314] Iteration 51500 (4.86283 iter/s, 20.5642s/100 iter), loss = 0.041006
I0916 13:03:18.049433 19004 solver.cpp:336]     Train net output #0: loss = 0.0410058 (* 1 = 0.0410058 loss)
I0916 13:03:18.049439 19004 sgd_solver.cpp:136] Iteration 51500, lr = 0.01, m = 0.9
I0916 13:03:31.089707 19012 data_reader.cpp:305] Starting prefetch of epoch 32
I0916 13:03:38.578904 19004 solver.cpp:314] Iteration 51600 (4.87118 iter/s, 20.5289s/100 iter), loss = 0.0775363
I0916 13:03:38.578933 19004 solver.cpp:336]     Train net output #0: loss = 0.0775362 (* 1 = 0.0775362 loss)
I0916 13:03:38.578939 19004 sgd_solver.cpp:136] Iteration 51600, lr = 0.01, m = 0.9
I0916 13:03:59.161195 19004 solver.cpp:314] Iteration 51700 (4.85868 iter/s, 20.5817s/100 iter), loss = 0.0635382
I0916 13:03:59.161269 19004 solver.cpp:336]     Train net output #0: loss = 0.063538 (* 1 = 0.063538 loss)
I0916 13:03:59.161293 19004 sgd_solver.cpp:136] Iteration 51700, lr = 0.01, m = 0.9
I0916 13:04:19.469612 19004 solver.cpp:314] Iteration 51800 (4.9242 iter/s, 20.3079s/100 iter), loss = 0.0687301
I0916 13:04:19.474150 19004 solver.cpp:336]     Train net output #0: loss = 0.0687299 (* 1 = 0.0687299 loss)
I0916 13:04:19.474171 19004 sgd_solver.cpp:136] Iteration 51800, lr = 0.01, m = 0.9
I0916 13:04:38.975847 19010 data_reader.cpp:305] Starting prefetch of epoch 29
I0916 13:04:40.277686 19004 solver.cpp:314] Iteration 51900 (4.80596 iter/s, 20.8075s/100 iter), loss = 0.0935469
I0916 13:04:40.277745 19004 solver.cpp:336]     Train net output #0: loss = 0.0935467 (* 1 = 0.0935467 loss)
I0916 13:04:40.277763 19004 sgd_solver.cpp:136] Iteration 51900, lr = 0.01, m = 0.9
I0916 13:05:00.289520 19004 solver.cpp:563] Iteration 52000, Testing net (#0)
I0916 13:05:04.446182 19018 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 13:05:13.418453 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.948362
I0916 13:05:13.418478 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 13:05:13.418485 19004 solver.cpp:655]     Test net output #2: loss = 0.158028 (* 1 = 0.158028 loss)
I0916 13:05:13.418505 19004 solver.cpp:265] [MultiGPU] Tests completed in 13.1286s
I0916 13:05:13.617946 19004 solver.cpp:314] Iteration 52000 (2.99946 iter/s, 33.3393s/100 iter), loss = 0.0801188
I0916 13:05:13.617974 19004 solver.cpp:336]     Train net output #0: loss = 0.0801186 (* 1 = 0.0801186 loss)
I0916 13:05:13.617980 19004 sgd_solver.cpp:136] Iteration 52000, lr = 0.01, m = 0.9
I0916 13:05:25.401782 18963 data_reader.cpp:305] Starting prefetch of epoch 38
I0916 13:05:33.604120 19004 solver.cpp:314] Iteration 52100 (5.0036 iter/s, 19.9856s/100 iter), loss = 0.0385051
I0916 13:05:33.604202 19004 solver.cpp:336]     Train net output #0: loss = 0.0385049 (* 1 = 0.0385049 loss)
I0916 13:05:33.604210 19004 sgd_solver.cpp:136] Iteration 52100, lr = 0.01, m = 0.9
I0916 13:05:53.894706 19004 solver.cpp:314] Iteration 52200 (4.92853 iter/s, 20.29s/100 iter), loss = 0.0705606
I0916 13:05:53.894731 19004 solver.cpp:336]     Train net output #0: loss = 0.0705604 (* 1 = 0.0705604 loss)
I0916 13:05:53.894737 19004 sgd_solver.cpp:136] Iteration 52200, lr = 0.01, m = 0.9
I0916 13:06:14.168373 19004 solver.cpp:314] Iteration 52300 (4.93264 iter/s, 20.2731s/100 iter), loss = 0.119253
I0916 13:06:14.168423 19004 solver.cpp:336]     Train net output #0: loss = 0.119253 (* 1 = 0.119253 loss)
I0916 13:06:14.168431 19004 sgd_solver.cpp:136] Iteration 52300, lr = 0.01, m = 0.9
I0916 13:06:32.150816 19008 data_reader.cpp:305] Starting prefetch of epoch 28
I0916 13:06:34.023383 19004 solver.cpp:314] Iteration 52400 (5.03665 iter/s, 19.8545s/100 iter), loss = 0.0552928
I0916 13:06:34.023403 19004 solver.cpp:336]     Train net output #0: loss = 0.0552926 (* 1 = 0.0552926 loss)
I0916 13:06:34.023407 19004 sgd_solver.cpp:136] Iteration 52400, lr = 0.01, m = 0.9
I0916 13:06:54.073683 19004 solver.cpp:314] Iteration 52500 (4.9876 iter/s, 20.0497s/100 iter), loss = 0.0859294
I0916 13:06:54.074415 19004 solver.cpp:336]     Train net output #0: loss = 0.0859292 (* 1 = 0.0859292 loss)
I0916 13:06:54.074430 19004 sgd_solver.cpp:136] Iteration 52500, lr = 0.01, m = 0.9
I0916 13:07:05.306474 19007 data_reader.cpp:305] Starting prefetch of epoch 38
I0916 13:07:14.438182 19004 solver.cpp:314] Iteration 52600 (4.91064 iter/s, 20.3639s/100 iter), loss = 0.114239
I0916 13:07:14.438206 19004 solver.cpp:336]     Train net output #0: loss = 0.114239 (* 1 = 0.114239 loss)
I0916 13:07:14.438212 19004 sgd_solver.cpp:136] Iteration 52600, lr = 0.01, m = 0.9
I0916 13:07:35.121855 19004 solver.cpp:314] Iteration 52700 (4.83486 iter/s, 20.6831s/100 iter), loss = 0.122979
I0916 13:07:35.121933 19004 solver.cpp:336]     Train net output #0: loss = 0.122979 (* 1 = 0.122979 loss)
I0916 13:07:35.121942 19004 sgd_solver.cpp:136] Iteration 52700, lr = 0.01, m = 0.9
I0916 13:07:55.239387 19004 solver.cpp:314] Iteration 52800 (4.97093 iter/s, 20.117s/100 iter), loss = 0.0797557
I0916 13:07:55.239411 19004 solver.cpp:336]     Train net output #0: loss = 0.0797556 (* 1 = 0.0797556 loss)
I0916 13:07:55.239418 19004 sgd_solver.cpp:136] Iteration 52800, lr = 0.01, m = 0.9
I0916 13:08:12.139749 19012 data_reader.cpp:305] Starting prefetch of epoch 33
I0916 13:08:15.106757 19004 solver.cpp:314] Iteration 52900 (5.03352 iter/s, 19.8668s/100 iter), loss = 0.0581392
I0916 13:08:15.106933 19004 solver.cpp:336]     Train net output #0: loss = 0.058139 (* 1 = 0.058139 loss)
I0916 13:08:15.107010 19004 sgd_solver.cpp:136] Iteration 52900, lr = 0.01, m = 0.9
I0916 13:08:35.314003 19004 solver.cpp:314] Iteration 53000 (4.94886 iter/s, 20.2067s/100 iter), loss = 0.107203
I0916 13:08:35.314026 19004 solver.cpp:336]     Train net output #0: loss = 0.107203 (* 1 = 0.107203 loss)
I0916 13:08:35.314033 19004 sgd_solver.cpp:136] Iteration 53000, lr = 0.01, m = 0.9
I0916 13:08:55.659360 19004 solver.cpp:314] Iteration 53100 (4.91526 iter/s, 20.3448s/100 iter), loss = 0.0888344
I0916 13:08:55.673928 19004 solver.cpp:336]     Train net output #0: loss = 0.0888342 (* 1 = 0.0888342 loss)
I0916 13:08:55.673971 19004 sgd_solver.cpp:136] Iteration 53100, lr = 0.01, m = 0.9
I0916 13:09:15.724742 19004 solver.cpp:314] Iteration 53200 (4.98385 iter/s, 20.0648s/100 iter), loss = 0.0580025
I0916 13:09:15.724766 19004 solver.cpp:336]     Train net output #0: loss = 0.0580022 (* 1 = 0.0580022 loss)
I0916 13:09:15.724771 19004 sgd_solver.cpp:136] Iteration 53200, lr = 0.01, m = 0.9
I0916 13:09:19.047751 18963 data_reader.cpp:305] Starting prefetch of epoch 39
I0916 13:09:35.879004 19004 solver.cpp:314] Iteration 53300 (4.96187 iter/s, 20.1537s/100 iter), loss = 0.0769332
I0916 13:09:35.879062 19004 solver.cpp:336]     Train net output #0: loss = 0.076933 (* 1 = 0.076933 loss)
I0916 13:09:35.879068 19004 sgd_solver.cpp:136] Iteration 53300, lr = 0.01, m = 0.9
I0916 13:09:52.319324 18961 data_reader.cpp:305] Starting prefetch of epoch 29
I0916 13:09:56.029096 19004 solver.cpp:314] Iteration 53400 (4.96289 iter/s, 20.1495s/100 iter), loss = 0.0733889
I0916 13:09:56.029130 19004 solver.cpp:336]     Train net output #0: loss = 0.0733886 (* 1 = 0.0733886 loss)
I0916 13:09:56.029136 19004 sgd_solver.cpp:136] Iteration 53400, lr = 0.01, m = 0.9
I0916 13:10:16.689697 19004 solver.cpp:314] Iteration 53500 (4.84027 iter/s, 20.66s/100 iter), loss = 0.0536049
I0916 13:10:16.689800 19004 solver.cpp:336]     Train net output #0: loss = 0.0536047 (* 1 = 0.0536047 loss)
I0916 13:10:16.689815 19004 sgd_solver.cpp:136] Iteration 53500, lr = 0.01, m = 0.9
I0916 13:10:37.257351 19004 solver.cpp:314] Iteration 53600 (4.86214 iter/s, 20.5671s/100 iter), loss = 0.13412
I0916 13:10:37.257395 19004 solver.cpp:336]     Train net output #0: loss = 0.13412 (* 1 = 0.13412 loss)
I0916 13:10:37.257406 19004 sgd_solver.cpp:136] Iteration 53600, lr = 0.01, m = 0.9
I0916 13:10:57.675876 19004 solver.cpp:314] Iteration 53700 (4.89765 iter/s, 20.418s/100 iter), loss = 0.0946463
I0916 13:10:57.675931 19004 solver.cpp:336]     Train net output #0: loss = 0.0946461 (* 1 = 0.0946461 loss)
I0916 13:10:57.675937 19004 sgd_solver.cpp:136] Iteration 53700, lr = 0.01, m = 0.9
I0916 13:10:59.989917 19007 data_reader.cpp:305] Starting prefetch of epoch 39
I0916 13:11:18.455091 19004 solver.cpp:314] Iteration 53800 (4.81264 iter/s, 20.7786s/100 iter), loss = 0.0781389
I0916 13:11:18.455121 19004 solver.cpp:336]     Train net output #0: loss = 0.0781387 (* 1 = 0.0781387 loss)
I0916 13:11:18.455128 19004 sgd_solver.cpp:136] Iteration 53800, lr = 0.01, m = 0.9
I0916 13:11:39.248562 19004 solver.cpp:314] Iteration 53900 (4.80934 iter/s, 20.7929s/100 iter), loss = 0.0597539
I0916 13:11:39.248677 19004 solver.cpp:336]     Train net output #0: loss = 0.0597537 (* 1 = 0.0597537 loss)
I0916 13:11:39.248700 19004 sgd_solver.cpp:136] Iteration 53900, lr = 0.01, m = 0.9
I0916 13:12:00.026085 19004 solver.cpp:563] Iteration 54000, Testing net (#0)
I0916 13:12:07.567468 19016 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 13:12:12.955330 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.950786
I0916 13:12:12.955430 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 13:12:12.955440 19004 solver.cpp:655]     Test net output #2: loss = 0.163581 (* 1 = 0.163581 loss)
I0916 13:12:12.955466 19004 solver.cpp:265] [MultiGPU] Tests completed in 12.929s
I0916 13:12:13.150357 19004 solver.cpp:314] Iteration 54000 (2.94978 iter/s, 33.9009s/100 iter), loss = 0.0654723
I0916 13:12:13.150403 19004 solver.cpp:336]     Train net output #0: loss = 0.0654721 (* 1 = 0.0654721 loss)
I0916 13:12:13.150413 19004 sgd_solver.cpp:136] Iteration 54000, lr = 0.01, m = 0.9
I0916 13:12:21.692620 18961 data_reader.cpp:305] Starting prefetch of epoch 30
I0916 13:12:33.558123 19004 solver.cpp:314] Iteration 54100 (4.90023 iter/s, 20.4072s/100 iter), loss = 0.0688439
I0916 13:12:33.558177 19004 solver.cpp:336]     Train net output #0: loss = 0.0688437 (* 1 = 0.0688437 loss)
I0916 13:12:33.558188 19004 sgd_solver.cpp:136] Iteration 54100, lr = 0.01, m = 0.9
I0916 13:12:53.917151 19004 solver.cpp:314] Iteration 54200 (4.91196 iter/s, 20.3585s/100 iter), loss = 0.076476
I0916 13:12:53.917256 19004 solver.cpp:336]     Train net output #0: loss = 0.0764758 (* 1 = 0.0764758 loss)
I0916 13:12:53.917261 19004 sgd_solver.cpp:136] Iteration 54200, lr = 0.01, m = 0.9
I0916 13:13:14.227421 19004 solver.cpp:314] Iteration 54300 (4.92375 iter/s, 20.3097s/100 iter), loss = 0.12366
I0916 13:13:14.227444 19004 solver.cpp:336]     Train net output #0: loss = 0.12366 (* 1 = 0.12366 loss)
I0916 13:13:14.227450 19004 sgd_solver.cpp:136] Iteration 54300, lr = 0.01, m = 0.9
I0916 13:13:29.274121 19012 data_reader.cpp:305] Starting prefetch of epoch 34
I0916 13:13:34.825700 19004 solver.cpp:314] Iteration 54400 (4.85491 iter/s, 20.5977s/100 iter), loss = 0.0489787
I0916 13:13:34.825775 19004 solver.cpp:336]     Train net output #0: loss = 0.0489785 (* 1 = 0.0489785 loss)
I0916 13:13:34.825808 19004 sgd_solver.cpp:136] Iteration 54400, lr = 0.01, m = 0.9
I0916 13:13:55.578939 19004 solver.cpp:314] Iteration 54500 (4.81866 iter/s, 20.7527s/100 iter), loss = 0.125218
I0916 13:13:55.579025 19004 solver.cpp:336]     Train net output #0: loss = 0.125217 (* 1 = 0.125217 loss)
I0916 13:13:55.579053 19004 sgd_solver.cpp:136] Iteration 54500, lr = 0.01, m = 0.9
I0916 13:14:16.251029 19004 solver.cpp:314] Iteration 54600 (4.83757 iter/s, 20.6715s/100 iter), loss = 0.0893524
I0916 13:14:16.251086 19004 solver.cpp:336]     Train net output #0: loss = 0.0893522 (* 1 = 0.0893522 loss)
I0916 13:14:16.251093 19004 sgd_solver.cpp:136] Iteration 54600, lr = 0.01, m = 0.9
I0916 13:14:36.761837 19004 solver.cpp:314] Iteration 54700 (4.87561 iter/s, 20.5102s/100 iter), loss = 0.077968
I0916 13:14:36.761862 19004 solver.cpp:336]     Train net output #0: loss = 0.0779678 (* 1 = 0.0779678 loss)
I0916 13:14:36.761869 19004 sgd_solver.cpp:136] Iteration 54700, lr = 0.01, m = 0.9
I0916 13:14:37.400383 19010 data_reader.cpp:305] Starting prefetch of epoch 30
I0916 13:14:57.475687 19004 solver.cpp:314] Iteration 54800 (4.82782 iter/s, 20.7133s/100 iter), loss = 0.0973483
I0916 13:14:57.475777 19004 solver.cpp:336]     Train net output #0: loss = 0.097348 (* 1 = 0.097348 loss)
I0916 13:14:57.475787 19004 sgd_solver.cpp:136] Iteration 54800, lr = 0.01, m = 0.9
I0916 13:15:12.011013 19008 data_reader.cpp:305] Starting prefetch of epoch 29
I0916 13:15:18.439812 19004 solver.cpp:314] Iteration 54900 (4.77019 iter/s, 20.9635s/100 iter), loss = 0.077156
I0916 13:15:18.439846 19004 solver.cpp:336]     Train net output #0: loss = 0.0771558 (* 1 = 0.0771558 loss)
I0916 13:15:18.439851 19004 sgd_solver.cpp:136] Iteration 54900, lr = 0.01, m = 0.9
I0916 13:15:38.640326 19004 solver.cpp:314] Iteration 55000 (4.95051 iter/s, 20.2s/100 iter), loss = 0.119428
I0916 13:15:38.640422 19004 solver.cpp:336]     Train net output #0: loss = 0.119427 (* 1 = 0.119427 loss)
I0916 13:15:38.640434 19004 sgd_solver.cpp:136] Iteration 55000, lr = 0.01, m = 0.9
I0916 13:15:59.388646 19004 solver.cpp:314] Iteration 55100 (4.8198 iter/s, 20.7477s/100 iter), loss = 0.131125
I0916 13:15:59.388671 19004 solver.cpp:336]     Train net output #0: loss = 0.131125 (* 1 = 0.131125 loss)
I0916 13:15:59.388677 19004 sgd_solver.cpp:136] Iteration 55100, lr = 0.01, m = 0.9
I0916 13:16:19.491474 19007 data_reader.cpp:305] Starting prefetch of epoch 40
I0916 13:16:19.694689 19004 solver.cpp:314] Iteration 55200 (4.92478 iter/s, 20.3055s/100 iter), loss = 0.0513503
I0916 13:16:19.694720 19004 solver.cpp:336]     Train net output #0: loss = 0.0513501 (* 1 = 0.0513501 loss)
I0916 13:16:19.694726 19004 sgd_solver.cpp:136] Iteration 55200, lr = 0.01, m = 0.9
I0916 13:16:39.900298 19004 solver.cpp:314] Iteration 55300 (4.94926 iter/s, 20.2051s/100 iter), loss = 0.0694984
I0916 13:16:39.900323 19004 solver.cpp:336]     Train net output #0: loss = 0.0694982 (* 1 = 0.0694982 loss)
I0916 13:16:39.900329 19004 sgd_solver.cpp:136] Iteration 55300, lr = 0.01, m = 0.9
I0916 13:17:00.116816 19004 solver.cpp:314] Iteration 55400 (4.94659 iter/s, 20.216s/100 iter), loss = 0.117462
I0916 13:17:00.117920 19004 solver.cpp:336]     Train net output #0: loss = 0.117462 (* 1 = 0.117462 loss)
I0916 13:17:00.117930 19004 sgd_solver.cpp:136] Iteration 55400, lr = 0.01, m = 0.9
I0916 13:17:20.854514 19004 solver.cpp:314] Iteration 55500 (4.82227 iter/s, 20.7371s/100 iter), loss = 0.0535527
I0916 13:17:20.854542 19004 solver.cpp:336]     Train net output #0: loss = 0.0535524 (* 1 = 0.0535524 loss)
I0916 13:17:20.854548 19004 sgd_solver.cpp:136] Iteration 55500, lr = 0.01, m = 0.9
I0916 13:17:27.372093 19010 data_reader.cpp:305] Starting prefetch of epoch 31
I0916 13:17:41.835263 19004 solver.cpp:314] Iteration 55600 (4.76641 iter/s, 20.9802s/100 iter), loss = 0.0753242
I0916 13:17:41.835314 19004 solver.cpp:336]     Train net output #0: loss = 0.075324 (* 1 = 0.075324 loss)
I0916 13:17:41.835319 19004 sgd_solver.cpp:136] Iteration 55600, lr = 0.01, m = 0.9
I0916 13:18:00.827949 19008 data_reader.cpp:305] Starting prefetch of epoch 30
I0916 13:18:01.803375 19004 solver.cpp:314] Iteration 55700 (5.00813 iter/s, 19.9675s/100 iter), loss = 0.0431232
I0916 13:18:01.803417 19004 solver.cpp:336]     Train net output #0: loss = 0.043123 (* 1 = 0.043123 loss)
I0916 13:18:01.803426 19004 sgd_solver.cpp:136] Iteration 55700, lr = 0.01, m = 0.9
I0916 13:18:22.319383 19004 solver.cpp:314] Iteration 55800 (4.87438 iter/s, 20.5154s/100 iter), loss = 0.0732255
I0916 13:18:22.319465 19004 solver.cpp:336]     Train net output #0: loss = 0.0732253 (* 1 = 0.0732253 loss)
I0916 13:18:22.319473 19004 sgd_solver.cpp:136] Iteration 55800, lr = 0.01, m = 0.9
I0916 13:18:43.029227 19004 solver.cpp:314] Iteration 55900 (4.82876 iter/s, 20.7093s/100 iter), loss = 0.108459
I0916 13:18:43.029263 19004 solver.cpp:336]     Train net output #0: loss = 0.108459 (* 1 = 0.108459 loss)
I0916 13:18:43.029273 19004 sgd_solver.cpp:136] Iteration 55900, lr = 0.01, m = 0.9
I0916 13:19:02.975138 19004 solver.cpp:563] Iteration 56000, Testing net (#0)
I0916 13:19:06.597249 19016 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 13:19:16.138718 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.943515
I0916 13:19:16.138739 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 13:19:16.138744 19004 solver.cpp:655]     Test net output #2: loss = 0.175269 (* 1 = 0.175269 loss)
I0916 13:19:16.138772 19004 solver.cpp:265] [MultiGPU] Tests completed in 13.1633s
I0916 13:19:16.360167 19004 solver.cpp:314] Iteration 56000 (3.0003 iter/s, 33.33s/100 iter), loss = 0.0669659
I0916 13:19:16.360194 19004 solver.cpp:336]     Train net output #0: loss = 0.0669657 (* 1 = 0.0669657 loss)
I0916 13:19:16.360198 19004 sgd_solver.cpp:136] Iteration 56000, lr = 0.01, m = 0.9
I0916 13:19:21.474737 18963 data_reader.cpp:305] Starting prefetch of epoch 40
I0916 13:19:35.659354 19004 solver.cpp:314] Iteration 56100 (5.18171 iter/s, 19.2987s/100 iter), loss = 0.123102
I0916 13:19:35.659755 19004 solver.cpp:336]     Train net output #0: loss = 0.123101 (* 1 = 0.123101 loss)
I0916 13:19:35.659768 19004 sgd_solver.cpp:136] Iteration 56100, lr = 0.01, m = 0.9
I0916 13:19:53.474436 19007 data_reader.cpp:305] Starting prefetch of epoch 41
I0916 13:19:55.121438 19004 solver.cpp:314] Iteration 56200 (5.13834 iter/s, 19.4615s/100 iter), loss = 0.0839063
I0916 13:19:55.121466 19004 solver.cpp:336]     Train net output #0: loss = 0.083906 (* 1 = 0.083906 loss)
I0916 13:19:55.121474 19004 sgd_solver.cpp:136] Iteration 56200, lr = 0.01, m = 0.9
I0916 13:20:14.683185 19004 solver.cpp:314] Iteration 56300 (5.11216 iter/s, 19.5612s/100 iter), loss = 0.0617444
I0916 13:20:14.683264 19004 solver.cpp:336]     Train net output #0: loss = 0.0617442 (* 1 = 0.0617442 loss)
I0916 13:20:14.683274 19004 sgd_solver.cpp:136] Iteration 56300, lr = 0.01, m = 0.9
I0916 13:20:34.393656 19004 solver.cpp:314] Iteration 56400 (5.07359 iter/s, 19.7099s/100 iter), loss = 0.0893901
I0916 13:20:34.393687 19004 solver.cpp:336]     Train net output #0: loss = 0.0893898 (* 1 = 0.0893898 loss)
I0916 13:20:34.393694 19004 sgd_solver.cpp:136] Iteration 56400, lr = 0.01, m = 0.9
I0916 13:20:54.144240 19004 solver.cpp:314] Iteration 56500 (5.06328 iter/s, 19.75s/100 iter), loss = 0.0771522
I0916 13:20:54.144295 19004 solver.cpp:336]     Train net output #0: loss = 0.0771519 (* 1 = 0.0771519 loss)
I0916 13:20:54.144302 19004 sgd_solver.cpp:136] Iteration 56500, lr = 0.01, m = 0.9
I0916 13:20:58.300050 19007 data_reader.cpp:305] Starting prefetch of epoch 42
I0916 13:21:13.999202 19004 solver.cpp:314] Iteration 56600 (5.03666 iter/s, 19.8544s/100 iter), loss = 0.0568411
I0916 13:21:13.999271 19004 solver.cpp:336]     Train net output #0: loss = 0.0568408 (* 1 = 0.0568408 loss)
I0916 13:21:13.999290 19004 sgd_solver.cpp:136] Iteration 56600, lr = 0.01, m = 0.9
I0916 13:21:33.468816 19004 solver.cpp:314] Iteration 56700 (5.13635 iter/s, 19.4691s/100 iter), loss = 0.0808403
I0916 13:21:33.468861 19004 solver.cpp:336]     Train net output #0: loss = 0.08084 (* 1 = 0.08084 loss)
I0916 13:21:33.468866 19004 sgd_solver.cpp:136] Iteration 56700, lr = 0.01, m = 0.9
I0916 13:21:52.955564 19004 solver.cpp:314] Iteration 56800 (5.13183 iter/s, 19.4862s/100 iter), loss = 0.083243
I0916 13:21:52.955721 19004 solver.cpp:336]     Train net output #0: loss = 0.0832428 (* 1 = 0.0832428 loss)
I0916 13:21:52.955741 19004 sgd_solver.cpp:136] Iteration 56800, lr = 0.01, m = 0.9
I0916 13:22:03.020817 19012 data_reader.cpp:305] Starting prefetch of epoch 35
I0916 13:22:12.412816 19004 solver.cpp:314] Iteration 56900 (5.13961 iter/s, 19.4567s/100 iter), loss = 0.192482
I0916 13:22:12.413887 19004 solver.cpp:336]     Train net output #0: loss = 0.192481 (* 1 = 0.192481 loss)
I0916 13:22:12.413897 19004 sgd_solver.cpp:136] Iteration 56900, lr = 0.01, m = 0.9
I0916 13:22:31.976658 19004 solver.cpp:314] Iteration 57000 (5.11161 iter/s, 19.5633s/100 iter), loss = 0.112514
I0916 13:22:31.976683 19004 solver.cpp:336]     Train net output #0: loss = 0.112513 (* 1 = 0.112513 loss)
I0916 13:22:31.976687 19004 sgd_solver.cpp:136] Iteration 57000, lr = 0.01, m = 0.9
I0916 13:22:51.198055 19004 solver.cpp:314] Iteration 57100 (5.20268 iter/s, 19.2209s/100 iter), loss = 0.0579605
I0916 13:22:51.198844 19004 solver.cpp:336]     Train net output #0: loss = 0.0579602 (* 1 = 0.0579602 loss)
I0916 13:22:51.198859 19004 sgd_solver.cpp:136] Iteration 57100, lr = 0.01, m = 0.9
I0916 13:23:07.839872 19010 data_reader.cpp:305] Starting prefetch of epoch 32
I0916 13:23:11.263419 19004 solver.cpp:314] Iteration 57200 (4.98385 iter/s, 20.0648s/100 iter), loss = 0.115618
I0916 13:23:11.263440 19004 solver.cpp:336]     Train net output #0: loss = 0.115617 (* 1 = 0.115617 loss)
I0916 13:23:11.263445 19004 sgd_solver.cpp:136] Iteration 57200, lr = 0.01, m = 0.9
I0916 13:23:31.433044 19004 solver.cpp:314] Iteration 57300 (4.95809 iter/s, 20.1691s/100 iter), loss = 0.108307
I0916 13:23:31.433089 19004 solver.cpp:336]     Train net output #0: loss = 0.108307 (* 1 = 0.108307 loss)
I0916 13:23:31.433094 19004 sgd_solver.cpp:136] Iteration 57300, lr = 0.01, m = 0.9
I0916 13:23:41.056743 19007 data_reader.cpp:305] Starting prefetch of epoch 43
I0916 13:23:51.389922 19004 solver.cpp:314] Iteration 57400 (5.01094 iter/s, 19.9563s/100 iter), loss = 0.0636821
I0916 13:23:51.389950 19004 solver.cpp:336]     Train net output #0: loss = 0.0636818 (* 1 = 0.0636818 loss)
I0916 13:23:51.389956 19004 sgd_solver.cpp:136] Iteration 57400, lr = 0.01, m = 0.9
I0916 13:24:11.359676 19004 solver.cpp:314] Iteration 57500 (5.00771 iter/s, 19.9692s/100 iter), loss = 0.103192
I0916 13:24:11.359798 19004 solver.cpp:336]     Train net output #0: loss = 0.103192 (* 1 = 0.103192 loss)
I0916 13:24:11.359812 19004 sgd_solver.cpp:136] Iteration 57500, lr = 0.01, m = 0.9
I0916 13:24:31.825752 19004 solver.cpp:314] Iteration 57600 (4.88627 iter/s, 20.4655s/100 iter), loss = 0.0546426
I0916 13:24:31.825776 19004 solver.cpp:336]     Train net output #0: loss = 0.0546423 (* 1 = 0.0546423 loss)
I0916 13:24:31.825781 19004 sgd_solver.cpp:136] Iteration 57600, lr = 0.01, m = 0.9
I0916 13:24:47.577800 19007 data_reader.cpp:305] Starting prefetch of epoch 44
I0916 13:24:52.008651 19004 solver.cpp:314] Iteration 57700 (4.95483 iter/s, 20.1823s/100 iter), loss = 0.0795799
I0916 13:24:52.008698 19004 solver.cpp:336]     Train net output #0: loss = 0.0795796 (* 1 = 0.0795796 loss)
I0916 13:24:52.008713 19004 sgd_solver.cpp:136] Iteration 57700, lr = 0.01, m = 0.9
I0916 13:25:11.760571 19004 solver.cpp:314] Iteration 57800 (5.06294 iter/s, 19.7514s/100 iter), loss = 0.0505052
I0916 13:25:11.760599 19004 solver.cpp:336]     Train net output #0: loss = 0.0505049 (* 1 = 0.0505049 loss)
I0916 13:25:11.760606 19004 sgd_solver.cpp:136] Iteration 57800, lr = 0.01, m = 0.9
I0916 13:25:31.635918 19004 solver.cpp:314] Iteration 57900 (5.0315 iter/s, 19.8748s/100 iter), loss = 0.0486095
I0916 13:25:31.635970 19004 solver.cpp:336]     Train net output #0: loss = 0.0486093 (* 1 = 0.0486093 loss)
I0916 13:25:31.635977 19004 sgd_solver.cpp:136] Iteration 57900, lr = 0.01, m = 0.9
I0916 13:25:51.806507 19004 solver.cpp:563] Iteration 58000, Testing net (#0)
I0916 13:26:00.621484 19029 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 13:26:06.109778 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.951348
I0916 13:26:06.109838 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 13:26:06.109846 19004 solver.cpp:655]     Test net output #2: loss = 0.167031 (* 1 = 0.167031 loss)
I0916 13:26:06.109880 19004 solver.cpp:265] [MultiGPU] Tests completed in 14.303s
I0916 13:26:06.328476 19004 solver.cpp:314] Iteration 58000 (2.88254 iter/s, 34.6916s/100 iter), loss = 0.0410068
I0916 13:26:06.328568 19004 solver.cpp:336]     Train net output #0: loss = 0.0410066 (* 1 = 0.0410066 loss)
I0916 13:26:06.328598 19004 sgd_solver.cpp:136] Iteration 58000, lr = 0.01, m = 0.9
I0916 13:26:08.261457 19007 data_reader.cpp:305] Starting prefetch of epoch 45
I0916 13:26:26.865358 19004 solver.cpp:314] Iteration 58100 (4.86942 iter/s, 20.5363s/100 iter), loss = 0.0802003
I0916 13:26:26.865382 19004 solver.cpp:336]     Train net output #0: loss = 0.0802 (* 1 = 0.0802 loss)
I0916 13:26:26.865386 19004 sgd_solver.cpp:136] Iteration 58100, lr = 0.01, m = 0.9
I0916 13:26:47.432731 19004 solver.cpp:314] Iteration 58200 (4.8622 iter/s, 20.5668s/100 iter), loss = 0.0802536
I0916 13:26:47.432783 19004 solver.cpp:336]     Train net output #0: loss = 0.0802533 (* 1 = 0.0802533 loss)
I0916 13:26:47.432790 19004 sgd_solver.cpp:136] Iteration 58200, lr = 0.01, m = 0.9
I0916 13:27:07.993126 19004 solver.cpp:314] Iteration 58300 (4.86386 iter/s, 20.5598s/100 iter), loss = 0.0418768
I0916 13:27:07.993151 19004 solver.cpp:336]     Train net output #0: loss = 0.0418766 (* 1 = 0.0418766 loss)
I0916 13:27:07.993157 19004 sgd_solver.cpp:136] Iteration 58300, lr = 0.01, m = 0.9
I0916 13:27:16.461341 19007 data_reader.cpp:305] Starting prefetch of epoch 46
I0916 13:27:28.918594 19004 solver.cpp:314] Iteration 58400 (4.779 iter/s, 20.9249s/100 iter), loss = 0.114009
I0916 13:27:28.918710 19004 solver.cpp:336]     Train net output #0: loss = 0.114009 (* 1 = 0.114009 loss)
I0916 13:27:28.918720 19004 sgd_solver.cpp:136] Iteration 58400, lr = 0.01, m = 0.9
I0916 13:27:49.422724 19004 solver.cpp:314] Iteration 58500 (4.8772 iter/s, 20.5035s/100 iter), loss = 0.043786
I0916 13:27:49.422765 19004 solver.cpp:336]     Train net output #0: loss = 0.0437857 (* 1 = 0.0437857 loss)
I0916 13:27:49.422772 19004 sgd_solver.cpp:136] Iteration 58500, lr = 0.01, m = 0.9
I0916 13:28:09.882380 19004 solver.cpp:314] Iteration 58600 (4.8878 iter/s, 20.4591s/100 iter), loss = 0.0818521
I0916 13:28:09.882462 19004 solver.cpp:336]     Train net output #0: loss = 0.0818518 (* 1 = 0.0818518 loss)
I0916 13:28:09.882470 19004 sgd_solver.cpp:136] Iteration 58600, lr = 0.01, m = 0.9
I0916 13:28:24.509428 19012 data_reader.cpp:305] Starting prefetch of epoch 36
I0916 13:28:30.731127 19004 solver.cpp:314] Iteration 58700 (4.79659 iter/s, 20.8482s/100 iter), loss = 0.113317
I0916 13:28:30.731151 19004 solver.cpp:336]     Train net output #0: loss = 0.113316 (* 1 = 0.113316 loss)
I0916 13:28:30.731155 19004 sgd_solver.cpp:136] Iteration 58700, lr = 0.01, m = 0.9
I0916 13:28:50.730103 19004 solver.cpp:314] Iteration 58800 (5.00039 iter/s, 19.9984s/100 iter), loss = 0.107373
I0916 13:28:50.730161 19004 solver.cpp:336]     Train net output #0: loss = 0.107373 (* 1 = 0.107373 loss)
I0916 13:28:50.730170 19004 sgd_solver.cpp:136] Iteration 58800, lr = 0.01, m = 0.9
I0916 13:28:57.888931 19007 data_reader.cpp:305] Starting prefetch of epoch 47
I0916 13:29:11.277856 19004 solver.cpp:314] Iteration 58900 (4.86685 iter/s, 20.5472s/100 iter), loss = 0.0960977
I0916 13:29:11.277895 19004 solver.cpp:336]     Train net output #0: loss = 0.0960974 (* 1 = 0.0960974 loss)
I0916 13:29:11.277901 19004 sgd_solver.cpp:136] Iteration 58900, lr = 0.01, m = 0.9
I0916 13:29:31.906899 19004 solver.cpp:314] Iteration 59000 (4.84767 iter/s, 20.6285s/100 iter), loss = 0.0536595
I0916 13:29:31.906950 19004 solver.cpp:336]     Train net output #0: loss = 0.0536593 (* 1 = 0.0536593 loss)
I0916 13:29:31.906957 19004 sgd_solver.cpp:136] Iteration 59000, lr = 0.01, m = 0.9
I0916 13:29:52.216951 19004 solver.cpp:314] Iteration 59100 (4.92381 iter/s, 20.3095s/100 iter), loss = 0.0739761
I0916 13:29:52.216975 19004 solver.cpp:336]     Train net output #0: loss = 0.0739759 (* 1 = 0.0739759 loss)
I0916 13:29:52.216981 19004 sgd_solver.cpp:136] Iteration 59100, lr = 0.01, m = 0.9
I0916 13:30:05.531081 19010 data_reader.cpp:305] Starting prefetch of epoch 33
I0916 13:30:12.442817 19004 solver.cpp:314] Iteration 59200 (4.9443 iter/s, 20.2253s/100 iter), loss = 0.0632013
I0916 13:30:12.442847 19004 solver.cpp:336]     Train net output #0: loss = 0.0632011 (* 1 = 0.0632011 loss)
I0916 13:30:12.442854 19004 sgd_solver.cpp:136] Iteration 59200, lr = 0.01, m = 0.9
I0916 13:30:33.671458 19004 solver.cpp:314] Iteration 59300 (4.71075 iter/s, 21.228s/100 iter), loss = 0.0468814
I0916 13:30:33.671479 19004 solver.cpp:336]     Train net output #0: loss = 0.0468812 (* 1 = 0.0468812 loss)
I0916 13:30:33.671483 19004 sgd_solver.cpp:136] Iteration 59300, lr = 0.01, m = 0.9
I0916 13:30:54.360755 19004 solver.cpp:314] Iteration 59400 (4.83355 iter/s, 20.6887s/100 iter), loss = 0.0579972
I0916 13:30:54.360862 19004 solver.cpp:336]     Train net output #0: loss = 0.057997 (* 1 = 0.057997 loss)
I0916 13:30:54.360878 19004 sgd_solver.cpp:136] Iteration 59400, lr = 0.01, m = 0.9
I0916 13:31:13.743396 19010 data_reader.cpp:305] Starting prefetch of epoch 34
I0916 13:31:14.559501 19004 solver.cpp:314] Iteration 59500 (4.95094 iter/s, 20.1982s/100 iter), loss = 0.0650078
I0916 13:31:14.559543 19004 solver.cpp:336]     Train net output #0: loss = 0.0650076 (* 1 = 0.0650076 loss)
I0916 13:31:14.559550 19004 sgd_solver.cpp:136] Iteration 59500, lr = 0.01, m = 0.9
I0916 13:31:35.111321 19004 solver.cpp:314] Iteration 59600 (4.86588 iter/s, 20.5513s/100 iter), loss = 0.0517803
I0916 13:31:35.111376 19004 solver.cpp:336]     Train net output #0: loss = 0.05178 (* 1 = 0.05178 loss)
I0916 13:31:35.111380 19004 sgd_solver.cpp:136] Iteration 59600, lr = 0.01, m = 0.9
I0916 13:31:47.839141 19008 data_reader.cpp:305] Starting prefetch of epoch 31
I0916 13:31:55.628178 19004 solver.cpp:314] Iteration 59700 (4.87418 iter/s, 20.5163s/100 iter), loss = 0.0809937
I0916 13:31:55.628249 19004 solver.cpp:336]     Train net output #0: loss = 0.0809935 (* 1 = 0.0809935 loss)
I0916 13:31:55.628268 19004 sgd_solver.cpp:136] Iteration 59700, lr = 0.01, m = 0.9
I0916 13:32:15.842838 19004 solver.cpp:314] Iteration 59800 (4.94704 iter/s, 20.2141s/100 iter), loss = 0.103318
I0916 13:32:15.842896 19004 solver.cpp:336]     Train net output #0: loss = 0.103318 (* 1 = 0.103318 loss)
I0916 13:32:15.842905 19004 sgd_solver.cpp:136] Iteration 59800, lr = 0.01, m = 0.9
I0916 13:32:35.688190 19004 solver.cpp:314] Iteration 59900 (5.0391 iter/s, 19.8448s/100 iter), loss = 0.100061
I0916 13:32:35.688215 19004 solver.cpp:336]     Train net output #0: loss = 0.10006 (* 1 = 0.10006 loss)
I0916 13:32:35.688220 19004 sgd_solver.cpp:136] Iteration 59900, lr = 0.01, m = 0.9
I0916 13:32:54.368448 18963 data_reader.cpp:305] Starting prefetch of epoch 41
I0916 13:32:55.860481 19004 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/cityscapes5_jsegnet21v2_iter_60000.caffemodel
I0916 13:32:56.025275 19004 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/cityscapes5_jsegnet21v2_iter_60000.solverstate
I0916 13:32:56.029384 19004 solver.cpp:563] Iteration 60000, Testing net (#0)
I0916 13:33:08.683356 19018 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 13:33:09.526232 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.942596
I0916 13:33:09.526280 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.999999
I0916 13:33:09.526293 19004 solver.cpp:655]     Test net output #2: loss = 0.191546 (* 1 = 0.191546 loss)
I0916 13:33:09.526350 19004 solver.cpp:265] [MultiGPU] Tests completed in 13.4966s
I0916 13:33:09.646456 19033 sgd_solver.cpp:48] MultiStep Status: Iteration 60000, step = 1
I0916 13:33:09.646456 19034 sgd_solver.cpp:48] MultiStep Status: Iteration 60000, step = 1
I0916 13:33:09.646574 19035 sgd_solver.cpp:48] MultiStep Status: Iteration 60000, step = 1
I0916 13:33:09.756779 19004 solver.cpp:314] Iteration 60000 (2.93534 iter/s, 34.0676s/100 iter), loss = 0.119377
I0916 13:33:09.756803 19004 solver.cpp:336]     Train net output #0: loss = 0.119377 (* 1 = 0.119377 loss)
I0916 13:33:09.756809 19004 sgd_solver.cpp:136] Iteration 60000, lr = 0.001, m = 0.9
I0916 13:33:29.762858 19004 solver.cpp:314] Iteration 60100 (4.99862 iter/s, 20.0055s/100 iter), loss = 0.0735934
I0916 13:33:29.762904 19004 solver.cpp:336]     Train net output #0: loss = 0.0735932 (* 1 = 0.0735932 loss)
I0916 13:33:29.762912 19004 sgd_solver.cpp:136] Iteration 60100, lr = 0.001, m = 0.9
I0916 13:33:41.824975 18961 data_reader.cpp:305] Starting prefetch of epoch 31
I0916 13:33:50.391974 19004 solver.cpp:314] Iteration 60200 (4.84765 iter/s, 20.6285s/100 iter), loss = 0.0492608
I0916 13:33:50.392004 19004 solver.cpp:336]     Train net output #0: loss = 0.0492606 (* 1 = 0.0492606 loss)
I0916 13:33:50.392010 19004 sgd_solver.cpp:136] Iteration 60200, lr = 0.001, m = 0.9
I0916 13:34:10.378386 19004 solver.cpp:314] Iteration 60300 (5.00354 iter/s, 19.9859s/100 iter), loss = 0.0782004
I0916 13:34:10.378443 19004 solver.cpp:336]     Train net output #0: loss = 0.0782001 (* 1 = 0.0782001 loss)
I0916 13:34:10.378448 19004 sgd_solver.cpp:136] Iteration 60300, lr = 0.001, m = 0.9
I0916 13:34:30.859711 19004 solver.cpp:314] Iteration 60400 (4.88263 iter/s, 20.4807s/100 iter), loss = 0.155481
I0916 13:34:30.859747 19004 solver.cpp:336]     Train net output #0: loss = 0.15548 (* 1 = 0.15548 loss)
I0916 13:34:30.859755 19004 sgd_solver.cpp:136] Iteration 60400, lr = 0.001, m = 0.9
I0916 13:34:48.880805 19012 data_reader.cpp:305] Starting prefetch of epoch 37
I0916 13:34:51.329919 19004 solver.cpp:314] Iteration 60500 (4.88528 iter/s, 20.4696s/100 iter), loss = 0.0602577
I0916 13:34:51.329948 19004 solver.cpp:336]     Train net output #0: loss = 0.0602575 (* 1 = 0.0602575 loss)
I0916 13:34:51.329952 19004 sgd_solver.cpp:136] Iteration 60500, lr = 0.001, m = 0.9
I0916 13:35:11.406762 19004 solver.cpp:314] Iteration 60600 (4.981 iter/s, 20.0763s/100 iter), loss = 0.0683353
I0916 13:35:11.406786 19004 solver.cpp:336]     Train net output #0: loss = 0.068335 (* 1 = 0.068335 loss)
I0916 13:35:11.406792 19004 sgd_solver.cpp:136] Iteration 60600, lr = 0.001, m = 0.9
I0916 13:35:31.497411 19004 solver.cpp:314] Iteration 60700 (4.97758 iter/s, 20.0901s/100 iter), loss = 0.0696849
I0916 13:35:31.497483 19004 solver.cpp:336]     Train net output #0: loss = 0.0696846 (* 1 = 0.0696846 loss)
I0916 13:35:31.497488 19004 sgd_solver.cpp:136] Iteration 60700, lr = 0.001, m = 0.9
I0916 13:35:51.839289 19004 solver.cpp:314] Iteration 60800 (4.9161 iter/s, 20.3413s/100 iter), loss = 0.0571367
I0916 13:35:51.839316 19004 solver.cpp:336]     Train net output #0: loss = 0.0571364 (* 1 = 0.0571364 loss)
I0916 13:35:51.839323 19004 sgd_solver.cpp:136] Iteration 60800, lr = 0.001, m = 0.9
I0916 13:35:55.593335 19012 data_reader.cpp:305] Starting prefetch of epoch 38
I0916 13:36:11.899308 19004 solver.cpp:314] Iteration 60900 (4.98518 iter/s, 20.0595s/100 iter), loss = 0.0849457
I0916 13:36:11.899358 19004 solver.cpp:336]     Train net output #0: loss = 0.0849454 (* 1 = 0.0849454 loss)
I0916 13:36:11.899363 19004 sgd_solver.cpp:136] Iteration 60900, lr = 0.001, m = 0.9
I0916 13:36:28.956981 19007 data_reader.cpp:305] Starting prefetch of epoch 48
I0916 13:36:32.088449 19004 solver.cpp:314] Iteration 61000 (4.9533 iter/s, 20.1886s/100 iter), loss = 0.0673979
I0916 13:36:32.088470 19004 solver.cpp:336]     Train net output #0: loss = 0.0673976 (* 1 = 0.0673976 loss)
I0916 13:36:32.088475 19004 sgd_solver.cpp:136] Iteration 61000, lr = 0.001, m = 0.9
I0916 13:36:52.147496 19004 solver.cpp:314] Iteration 61100 (4.98542 iter/s, 20.0585s/100 iter), loss = 0.0582164
I0916 13:36:52.147555 19004 solver.cpp:336]     Train net output #0: loss = 0.0582162 (* 1 = 0.0582162 loss)
I0916 13:36:52.147562 19004 sgd_solver.cpp:136] Iteration 61100, lr = 0.001, m = 0.9
I0916 13:37:12.535995 19004 solver.cpp:314] Iteration 61200 (4.90486 iter/s, 20.3879s/100 iter), loss = 0.0388166
I0916 13:37:12.536021 19004 solver.cpp:336]     Train net output #0: loss = 0.0388163 (* 1 = 0.0388163 loss)
I0916 13:37:12.536028 19004 sgd_solver.cpp:136] Iteration 61200, lr = 0.001, m = 0.9
I0916 13:37:32.594678 19004 solver.cpp:314] Iteration 61300 (4.98551 iter/s, 20.0581s/100 iter), loss = 0.0670301
I0916 13:37:32.594718 19004 solver.cpp:336]     Train net output #0: loss = 0.0670298 (* 1 = 0.0670298 loss)
I0916 13:37:32.594723 19004 sgd_solver.cpp:136] Iteration 61300, lr = 0.001, m = 0.9
I0916 13:37:35.567087 18963 data_reader.cpp:305] Starting prefetch of epoch 42
I0916 13:37:52.694604 19004 solver.cpp:314] Iteration 61400 (4.97528 iter/s, 20.0994s/100 iter), loss = 0.0489933
I0916 13:37:52.694633 19004 solver.cpp:336]     Train net output #0: loss = 0.048993 (* 1 = 0.048993 loss)
I0916 13:37:52.694640 19004 sgd_solver.cpp:136] Iteration 61400, lr = 0.001, m = 0.9
I0916 13:38:12.839121 19004 solver.cpp:314] Iteration 61500 (4.96427 iter/s, 20.1439s/100 iter), loss = 0.0631198
I0916 13:38:12.839213 19004 solver.cpp:336]     Train net output #0: loss = 0.0631195 (* 1 = 0.0631195 loss)
I0916 13:38:12.839227 19004 sgd_solver.cpp:136] Iteration 61500, lr = 0.001, m = 0.9
I0916 13:38:32.612581 19004 solver.cpp:314] Iteration 61600 (5.05742 iter/s, 19.7729s/100 iter), loss = 0.0663119
I0916 13:38:32.612607 19004 solver.cpp:336]     Train net output #0: loss = 0.0663116 (* 1 = 0.0663116 loss)
I0916 13:38:32.612612 19004 sgd_solver.cpp:136] Iteration 61600, lr = 0.001, m = 0.9
I0916 13:38:41.408926 18963 data_reader.cpp:305] Starting prefetch of epoch 43
I0916 13:38:52.086580 19004 solver.cpp:314] Iteration 61700 (5.13519 iter/s, 19.4735s/100 iter), loss = 0.0874206
I0916 13:38:52.086630 19004 solver.cpp:336]     Train net output #0: loss = 0.0874203 (* 1 = 0.0874203 loss)
I0916 13:38:52.086635 19004 sgd_solver.cpp:136] Iteration 61700, lr = 0.001, m = 0.9
I0916 13:39:11.503651 19004 solver.cpp:314] Iteration 61800 (5.15025 iter/s, 19.4165s/100 iter), loss = 0.0488665
I0916 13:39:11.503684 19004 solver.cpp:336]     Train net output #0: loss = 0.0488662 (* 1 = 0.0488662 loss)
I0916 13:39:11.503690 19004 sgd_solver.cpp:136] Iteration 61800, lr = 0.001, m = 0.9
I0916 13:39:13.505524 19007 data_reader.cpp:305] Starting prefetch of epoch 49
I0916 13:39:30.878502 19004 solver.cpp:314] Iteration 61900 (5.16147 iter/s, 19.3743s/100 iter), loss = 0.0750826
I0916 13:39:30.878597 19004 solver.cpp:336]     Train net output #0: loss = 0.0750823 (* 1 = 0.0750823 loss)
I0916 13:39:30.878613 19004 sgd_solver.cpp:136] Iteration 61900, lr = 0.001, m = 0.9
I0916 13:39:50.137763 19004 solver.cpp:563] Iteration 62000, Testing net (#0)
I0916 13:39:57.105239 19018 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 13:40:01.108769 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.954536
I0916 13:40:01.108840 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.999948
I0916 13:40:01.108849 19004 solver.cpp:655]     Test net output #2: loss = 0.18429 (* 1 = 0.18429 loss)
I0916 13:40:01.108871 19004 solver.cpp:265] [MultiGPU] Tests completed in 10.9708s
I0916 13:40:01.308512 19004 solver.cpp:314] Iteration 62000 (3.28632 iter/s, 30.4292s/100 iter), loss = 0.07357
I0916 13:40:01.308537 19004 solver.cpp:336]     Train net output #0: loss = 0.0735697 (* 1 = 0.0735697 loss)
I0916 13:40:01.308544 19004 sgd_solver.cpp:136] Iteration 62000, lr = 0.001, m = 0.9
I0916 13:40:20.719317 19004 solver.cpp:314] Iteration 62100 (5.15191 iter/s, 19.4103s/100 iter), loss = 0.0597172
I0916 13:40:20.719341 19004 solver.cpp:336]     Train net output #0: loss = 0.059717 (* 1 = 0.059717 loss)
I0916 13:40:20.719346 19004 sgd_solver.cpp:136] Iteration 62100, lr = 0.001, m = 0.9
I0916 13:40:40.217243 19004 solver.cpp:314] Iteration 62200 (5.12889 iter/s, 19.4974s/100 iter), loss = 0.0795327
I0916 13:40:40.217322 19004 solver.cpp:336]     Train net output #0: loss = 0.0795325 (* 1 = 0.0795325 loss)
I0916 13:40:40.217327 19004 sgd_solver.cpp:136] Iteration 62200, lr = 0.001, m = 0.9
I0916 13:40:59.709246 19004 solver.cpp:314] Iteration 62300 (5.13045 iter/s, 19.4915s/100 iter), loss = 0.0621151
I0916 13:40:59.709275 19004 solver.cpp:336]     Train net output #0: loss = 0.0621148 (* 1 = 0.0621148 loss)
I0916 13:40:59.709281 19004 sgd_solver.cpp:136] Iteration 62300, lr = 0.001, m = 0.9
I0916 13:41:00.907402 19010 data_reader.cpp:305] Starting prefetch of epoch 35
I0916 13:41:19.391696 19004 solver.cpp:314] Iteration 62400 (5.08081 iter/s, 19.6819s/100 iter), loss = 0.0669116
I0916 13:41:19.391749 19004 solver.cpp:336]     Train net output #0: loss = 0.0669113 (* 1 = 0.0669113 loss)
I0916 13:41:19.391753 19004 sgd_solver.cpp:136] Iteration 62400, lr = 0.001, m = 0.9
I0916 13:41:33.287767 18961 data_reader.cpp:305] Starting prefetch of epoch 32
I0916 13:41:39.066045 19004 solver.cpp:314] Iteration 62500 (5.0829 iter/s, 19.6738s/100 iter), loss = 0.0736028
I0916 13:41:39.066066 19004 solver.cpp:336]     Train net output #0: loss = 0.0736026 (* 1 = 0.0736026 loss)
I0916 13:41:39.066069 19004 sgd_solver.cpp:136] Iteration 62500, lr = 0.001, m = 0.9
I0916 13:41:58.478782 19004 solver.cpp:314] Iteration 62600 (5.1514 iter/s, 19.4122s/100 iter), loss = 0.0676722
I0916 13:41:58.478833 19004 solver.cpp:336]     Train net output #0: loss = 0.067672 (* 1 = 0.067672 loss)
I0916 13:41:58.478839 19004 sgd_solver.cpp:136] Iteration 62600, lr = 0.001, m = 0.9
I0916 13:42:18.017765 19004 solver.cpp:314] Iteration 62700 (5.11812 iter/s, 19.5384s/100 iter), loss = 0.0743633
I0916 13:42:18.017788 19004 solver.cpp:336]     Train net output #0: loss = 0.074363 (* 1 = 0.074363 loss)
I0916 13:42:18.017792 19004 sgd_solver.cpp:136] Iteration 62700, lr = 0.001, m = 0.9
I0916 13:42:37.389178 19004 solver.cpp:314] Iteration 62800 (5.16239 iter/s, 19.3709s/100 iter), loss = 0.0727711
I0916 13:42:37.389232 19004 solver.cpp:336]     Train net output #0: loss = 0.0727708 (* 1 = 0.0727708 loss)
I0916 13:42:37.389237 19004 sgd_solver.cpp:136] Iteration 62800, lr = 0.001, m = 0.9
I0916 13:42:37.817909 19008 data_reader.cpp:305] Starting prefetch of epoch 32
I0916 13:42:56.677429 19004 solver.cpp:314] Iteration 62900 (5.18465 iter/s, 19.2877s/100 iter), loss = 0.0331015
I0916 13:42:56.677455 19004 solver.cpp:336]     Train net output #0: loss = 0.0331013 (* 1 = 0.0331013 loss)
I0916 13:42:56.677460 19004 sgd_solver.cpp:136] Iteration 62900, lr = 0.001, m = 0.9
I0916 13:43:16.459233 19004 solver.cpp:314] Iteration 63000 (5.05529 iter/s, 19.7812s/100 iter), loss = 0.0593115
I0916 13:43:16.459306 19004 solver.cpp:336]     Train net output #0: loss = 0.0593112 (* 1 = 0.0593112 loss)
I0916 13:43:16.459311 19004 sgd_solver.cpp:136] Iteration 63000, lr = 0.001, m = 0.9
I0916 13:43:36.176432 19004 solver.cpp:314] Iteration 63100 (5.07186 iter/s, 19.7167s/100 iter), loss = 0.0516929
I0916 13:43:36.176460 19004 solver.cpp:336]     Train net output #0: loss = 0.0516927 (* 1 = 0.0516927 loss)
I0916 13:43:36.176465 19004 sgd_solver.cpp:136] Iteration 63100, lr = 0.001, m = 0.9
I0916 13:43:42.532083 18963 data_reader.cpp:305] Starting prefetch of epoch 44
I0916 13:43:55.505492 19004 solver.cpp:314] Iteration 63200 (5.1737 iter/s, 19.3285s/100 iter), loss = 0.0856422
I0916 13:43:55.505604 19004 solver.cpp:336]     Train net output #0: loss = 0.0856419 (* 1 = 0.0856419 loss)
I0916 13:43:55.505611 19004 sgd_solver.cpp:136] Iteration 63200, lr = 0.001, m = 0.9
I0916 13:44:14.444809 19007 data_reader.cpp:305] Starting prefetch of epoch 50
I0916 13:44:14.795788 19004 solver.cpp:314] Iteration 63300 (5.1841 iter/s, 19.2898s/100 iter), loss = 0.0567931
I0916 13:44:14.795816 19004 solver.cpp:336]     Train net output #0: loss = 0.0567928 (* 1 = 0.0567928 loss)
I0916 13:44:14.795824 19004 sgd_solver.cpp:136] Iteration 63300, lr = 0.001, m = 0.9
I0916 13:44:34.352782 19004 solver.cpp:314] Iteration 63400 (5.1134 iter/s, 19.5565s/100 iter), loss = 0.0594937
I0916 13:44:34.352854 19004 solver.cpp:336]     Train net output #0: loss = 0.0594934 (* 1 = 0.0594934 loss)
I0916 13:44:34.352859 19004 sgd_solver.cpp:136] Iteration 63400, lr = 0.001, m = 0.9
I0916 13:44:54.586141 19004 solver.cpp:314] Iteration 63500 (4.94247 iter/s, 20.2328s/100 iter), loss = 0.0468958
I0916 13:44:54.586165 19004 solver.cpp:336]     Train net output #0: loss = 0.0468955 (* 1 = 0.0468955 loss)
I0916 13:44:54.586170 19004 sgd_solver.cpp:136] Iteration 63500, lr = 0.001, m = 0.9
I0916 13:45:13.829907 19004 solver.cpp:314] Iteration 63600 (5.19663 iter/s, 19.2432s/100 iter), loss = 0.0503508
I0916 13:45:13.829957 19004 solver.cpp:336]     Train net output #0: loss = 0.0503506 (* 1 = 0.0503506 loss)
I0916 13:45:13.829962 19004 sgd_solver.cpp:136] Iteration 63600, lr = 0.001, m = 0.9
I0916 13:45:19.419955 19010 data_reader.cpp:305] Starting prefetch of epoch 36
I0916 13:45:33.327145 19004 solver.cpp:314] Iteration 63700 (5.12907 iter/s, 19.4967s/100 iter), loss = 0.0603197
I0916 13:45:33.327165 19004 solver.cpp:336]     Train net output #0: loss = 0.0603194 (* 1 = 0.0603194 loss)
I0916 13:45:33.327169 19004 sgd_solver.cpp:136] Iteration 63700, lr = 0.001, m = 0.9
I0916 13:45:52.816648 19004 solver.cpp:314] Iteration 63800 (5.13111 iter/s, 19.489s/100 iter), loss = 0.0717362
I0916 13:45:52.816754 19004 solver.cpp:336]     Train net output #0: loss = 0.0717359 (* 1 = 0.0717359 loss)
I0916 13:45:52.816761 19004 sgd_solver.cpp:136] Iteration 63800, lr = 0.001, m = 0.9
I0916 13:46:12.392874 19004 solver.cpp:314] Iteration 63900 (5.10838 iter/s, 19.5757s/100 iter), loss = 0.0479012
I0916 13:46:12.392895 19004 solver.cpp:336]     Train net output #0: loss = 0.047901 (* 1 = 0.047901 loss)
I0916 13:46:12.392899 19004 sgd_solver.cpp:136] Iteration 63900, lr = 0.001, m = 0.9
I0916 13:46:23.909047 19012 data_reader.cpp:305] Starting prefetch of epoch 39
I0916 13:46:23.909047 18963 data_reader.cpp:305] Starting prefetch of epoch 45
I0916 13:46:31.656450 19004 solver.cpp:563] Iteration 64000, Testing net (#0)
I0916 13:46:43.672415 19018 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 13:46:44.117768 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.955707
I0916 13:46:44.117787 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 13:46:44.117792 19004 solver.cpp:655]     Test net output #2: loss = 0.14814 (* 1 = 0.14814 loss)
I0916 13:46:44.117818 19004 solver.cpp:265] [MultiGPU] Tests completed in 12.461s
I0916 13:46:44.330440 19004 solver.cpp:314] Iteration 64000 (3.1312 iter/s, 31.9367s/100 iter), loss = 0.0509877
I0916 13:46:44.330463 19004 solver.cpp:336]     Train net output #0: loss = 0.0509874 (* 1 = 0.0509874 loss)
I0916 13:46:44.330467 19004 sgd_solver.cpp:136] Iteration 64000, lr = 0.001, m = 0.9
I0916 13:47:03.679630 19004 solver.cpp:314] Iteration 64100 (5.16832 iter/s, 19.3486s/100 iter), loss = 0.0738556
I0916 13:47:03.679699 19004 solver.cpp:336]     Train net output #0: loss = 0.0738553 (* 1 = 0.0738553 loss)
I0916 13:47:03.679707 19004 sgd_solver.cpp:136] Iteration 64100, lr = 0.001, m = 0.9
I0916 13:47:08.354295 18961 data_reader.cpp:305] Starting prefetch of epoch 33
I0916 13:47:23.056072 19004 solver.cpp:314] Iteration 64200 (5.16105 iter/s, 19.3759s/100 iter), loss = 0.0721396
I0916 13:47:23.056097 19004 solver.cpp:336]     Train net output #0: loss = 0.0721394 (* 1 = 0.0721394 loss)
I0916 13:47:23.056102 19004 sgd_solver.cpp:136] Iteration 64200, lr = 0.001, m = 0.9
I0916 13:47:42.506992 19004 solver.cpp:314] Iteration 64300 (5.14129 iter/s, 19.4504s/100 iter), loss = 0.0800375
I0916 13:47:42.507040 19004 solver.cpp:336]     Train net output #0: loss = 0.0800372 (* 1 = 0.0800372 loss)
I0916 13:47:42.507045 19004 sgd_solver.cpp:136] Iteration 64300, lr = 0.001, m = 0.9
I0916 13:48:01.987457 19004 solver.cpp:314] Iteration 64400 (5.13349 iter/s, 19.4799s/100 iter), loss = 0.0645824
I0916 13:48:01.987478 19004 solver.cpp:336]     Train net output #0: loss = 0.0645822 (* 1 = 0.0645822 loss)
I0916 13:48:01.987484 19004 sgd_solver.cpp:136] Iteration 64400, lr = 0.001, m = 0.9
I0916 13:48:12.807266 18963 data_reader.cpp:305] Starting prefetch of epoch 46
I0916 13:48:21.464583 19004 solver.cpp:314] Iteration 64500 (5.13437 iter/s, 19.4766s/100 iter), loss = 0.0588529
I0916 13:48:21.464608 19004 solver.cpp:336]     Train net output #0: loss = 0.0588527 (* 1 = 0.0588527 loss)
I0916 13:48:21.464614 19004 sgd_solver.cpp:136] Iteration 64500, lr = 0.001, m = 0.9
I0916 13:48:41.090968 19004 solver.cpp:314] Iteration 64600 (5.09532 iter/s, 19.6258s/100 iter), loss = 0.0990583
I0916 13:48:41.090993 19004 solver.cpp:336]     Train net output #0: loss = 0.099058 (* 1 = 0.099058 loss)
I0916 13:48:41.091001 19004 sgd_solver.cpp:136] Iteration 64600, lr = 0.001, m = 0.9
I0916 13:49:00.318568 19004 solver.cpp:314] Iteration 64700 (5.201 iter/s, 19.2271s/100 iter), loss = 0.0689018
I0916 13:49:00.318616 19004 solver.cpp:336]     Train net output #0: loss = 0.0689015 (* 1 = 0.0689015 loss)
I0916 13:49:00.318622 19004 sgd_solver.cpp:136] Iteration 64700, lr = 0.001, m = 0.9
I0916 13:49:16.773864 19010 data_reader.cpp:305] Starting prefetch of epoch 37
I0916 13:49:19.692733 19004 solver.cpp:314] Iteration 64800 (5.16166 iter/s, 19.3736s/100 iter), loss = 0.0522546
I0916 13:49:19.692757 19004 solver.cpp:336]     Train net output #0: loss = 0.0522543 (* 1 = 0.0522543 loss)
I0916 13:49:19.692764 19004 sgd_solver.cpp:136] Iteration 64800, lr = 0.001, m = 0.9
I0916 13:49:39.063243 19004 solver.cpp:314] Iteration 64900 (5.16263 iter/s, 19.37s/100 iter), loss = 0.0471684
I0916 13:49:39.063297 19004 solver.cpp:336]     Train net output #0: loss = 0.0471681 (* 1 = 0.0471681 loss)
I0916 13:49:39.063303 19004 sgd_solver.cpp:136] Iteration 64900, lr = 0.001, m = 0.9
I0916 13:49:49.017877 19007 data_reader.cpp:305] Starting prefetch of epoch 51
I0916 13:49:58.392160 19004 solver.cpp:314] Iteration 65000 (5.17374 iter/s, 19.3284s/100 iter), loss = 0.0430413
I0916 13:49:58.392187 19004 solver.cpp:336]     Train net output #0: loss = 0.043041 (* 1 = 0.043041 loss)
I0916 13:49:58.392192 19004 sgd_solver.cpp:136] Iteration 65000, lr = 0.001, m = 0.9
I0916 13:50:17.762485 19004 solver.cpp:314] Iteration 65100 (5.16268 iter/s, 19.3698s/100 iter), loss = 0.0521747
I0916 13:50:17.762536 19004 solver.cpp:336]     Train net output #0: loss = 0.0521744 (* 1 = 0.0521744 loss)
I0916 13:50:17.762542 19004 sgd_solver.cpp:136] Iteration 65100, lr = 0.001, m = 0.9
I0916 13:50:37.163823 19004 solver.cpp:314] Iteration 65200 (5.15443 iter/s, 19.4008s/100 iter), loss = 0.0664316
I0916 13:50:37.163847 19004 solver.cpp:336]     Train net output #0: loss = 0.0664313 (* 1 = 0.0664313 loss)
I0916 13:50:37.163852 19004 sgd_solver.cpp:136] Iteration 65200, lr = 0.001, m = 0.9
I0916 13:50:52.675655 19007 data_reader.cpp:305] Starting prefetch of epoch 52
I0916 13:50:56.307742 19004 solver.cpp:314] Iteration 65300 (5.22374 iter/s, 19.1434s/100 iter), loss = 0.0622932
I0916 13:50:56.307768 19004 solver.cpp:336]     Train net output #0: loss = 0.0622929 (* 1 = 0.0622929 loss)
I0916 13:50:56.307773 19004 sgd_solver.cpp:136] Iteration 65300, lr = 0.001, m = 0.9
I0916 13:51:15.831208 19004 solver.cpp:314] Iteration 65400 (5.12218 iter/s, 19.5229s/100 iter), loss = 0.045749
I0916 13:51:15.831228 19004 solver.cpp:336]     Train net output #0: loss = 0.0457488 (* 1 = 0.0457488 loss)
I0916 13:51:15.831233 19004 sgd_solver.cpp:136] Iteration 65400, lr = 0.001, m = 0.9
I0916 13:51:35.734118 19004 solver.cpp:314] Iteration 65500 (5.02453 iter/s, 19.9023s/100 iter), loss = 0.0698102
I0916 13:51:35.739996 19004 solver.cpp:336]     Train net output #0: loss = 0.0698099 (* 1 = 0.0698099 loss)
I0916 13:51:35.740025 19004 sgd_solver.cpp:136] Iteration 65500, lr = 0.001, m = 0.9
I0916 13:51:56.160790 19004 solver.cpp:314] Iteration 65600 (4.89569 iter/s, 20.4261s/100 iter), loss = 0.0622571
I0916 13:51:56.160814 19004 solver.cpp:336]     Train net output #0: loss = 0.0622568 (* 1 = 0.0622568 loss)
I0916 13:51:56.160820 19004 sgd_solver.cpp:136] Iteration 65600, lr = 0.001, m = 0.9
I0916 13:51:58.653929 18963 data_reader.cpp:305] Starting prefetch of epoch 47
I0916 13:52:16.281601 19004 solver.cpp:314] Iteration 65700 (4.97012 iter/s, 20.1203s/100 iter), loss = 0.0517508
I0916 13:52:16.281653 19004 solver.cpp:336]     Train net output #0: loss = 0.0517506 (* 1 = 0.0517506 loss)
I0916 13:52:16.281659 19004 sgd_solver.cpp:136] Iteration 65700, lr = 0.001, m = 0.9
I0916 13:52:31.942656 19007 data_reader.cpp:305] Starting prefetch of epoch 53
I0916 13:52:36.445371 19004 solver.cpp:314] Iteration 65800 (4.95953 iter/s, 20.1632s/100 iter), loss = 0.0524246
I0916 13:52:36.445395 19004 solver.cpp:336]     Train net output #0: loss = 0.0524243 (* 1 = 0.0524243 loss)
I0916 13:52:36.445399 19004 sgd_solver.cpp:136] Iteration 65800, lr = 0.001, m = 0.9
I0916 13:52:56.388586 19004 solver.cpp:314] Iteration 65900 (5.01438 iter/s, 19.9427s/100 iter), loss = 0.0628017
I0916 13:52:56.388691 19004 solver.cpp:336]     Train net output #0: loss = 0.0628015 (* 1 = 0.0628015 loss)
I0916 13:52:56.388700 19004 sgd_solver.cpp:136] Iteration 65900, lr = 0.001, m = 0.9
I0916 13:53:16.439976 19004 solver.cpp:563] Iteration 66000, Testing net (#0)
I0916 13:53:24.145117 19015 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 13:53:28.755269 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.955992
I0916 13:53:28.755367 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.999891
I0916 13:53:28.755378 19004 solver.cpp:655]     Test net output #2: loss = 0.181773 (* 1 = 0.181773 loss)
I0916 13:53:28.755405 19004 solver.cpp:265] [MultiGPU] Tests completed in 12.3151s
I0916 13:53:28.967602 19004 solver.cpp:314] Iteration 66000 (3.06955 iter/s, 32.5781s/100 iter), loss = 0.0580426
I0916 13:53:28.967667 19004 solver.cpp:336]     Train net output #0: loss = 0.0580424 (* 1 = 0.0580424 loss)
I0916 13:53:28.967689 19004 sgd_solver.cpp:136] Iteration 66000, lr = 0.001, m = 0.9
I0916 13:53:48.804769 19004 solver.cpp:314] Iteration 66100 (5.04118 iter/s, 19.8366s/100 iter), loss = 0.0818822
I0916 13:53:48.804797 19004 solver.cpp:336]     Train net output #0: loss = 0.0818819 (* 1 = 0.0818819 loss)
I0916 13:53:48.804803 19004 sgd_solver.cpp:136] Iteration 66100, lr = 0.001, m = 0.9
I0916 13:54:08.873116 19004 solver.cpp:314] Iteration 66200 (4.98311 iter/s, 20.0678s/100 iter), loss = 0.0567817
I0916 13:54:08.873175 19004 solver.cpp:336]     Train net output #0: loss = 0.0567815 (* 1 = 0.0567815 loss)
I0916 13:54:08.873181 19004 sgd_solver.cpp:136] Iteration 66200, lr = 0.001, m = 0.9
I0916 13:54:23.509631 18963 data_reader.cpp:305] Starting prefetch of epoch 48
I0916 13:54:28.782939 19004 solver.cpp:314] Iteration 66300 (5.02279 iter/s, 19.9093s/100 iter), loss = 0.0432631
I0916 13:54:28.782966 19004 solver.cpp:336]     Train net output #0: loss = 0.0432628 (* 1 = 0.0432628 loss)
I0916 13:54:28.782971 19004 sgd_solver.cpp:136] Iteration 66300, lr = 0.001, m = 0.9
I0916 13:54:49.164652 19004 solver.cpp:314] Iteration 66400 (4.9065 iter/s, 20.3811s/100 iter), loss = 0.0592818
I0916 13:54:49.164721 19004 solver.cpp:336]     Train net output #0: loss = 0.0592815 (* 1 = 0.0592815 loss)
I0916 13:54:49.164726 19004 sgd_solver.cpp:136] Iteration 66400, lr = 0.001, m = 0.9
I0916 13:54:57.022559 18961 data_reader.cpp:305] Starting prefetch of epoch 34
I0916 13:55:09.335800 19004 solver.cpp:314] Iteration 66500 (4.95772 iter/s, 20.1706s/100 iter), loss = 0.0536121
I0916 13:55:09.335826 19004 solver.cpp:336]     Train net output #0: loss = 0.0536118 (* 1 = 0.0536118 loss)
I0916 13:55:09.335832 19004 sgd_solver.cpp:136] Iteration 66500, lr = 0.001, m = 0.9
I0916 13:55:29.156599 19004 solver.cpp:314] Iteration 66600 (5.04535 iter/s, 19.8202s/100 iter), loss = 0.079059
I0916 13:55:29.156703 19004 solver.cpp:336]     Train net output #0: loss = 0.0790587 (* 1 = 0.0790587 loss)
I0916 13:55:29.156710 19004 sgd_solver.cpp:136] Iteration 66600, lr = 0.001, m = 0.9
I0916 13:55:49.056229 19004 solver.cpp:314] Iteration 66700 (5.02536 iter/s, 19.8991s/100 iter), loss = 0.0576073
I0916 13:55:49.056253 19004 solver.cpp:336]     Train net output #0: loss = 0.0576071 (* 1 = 0.0576071 loss)
I0916 13:55:49.056259 19004 sgd_solver.cpp:136] Iteration 66700, lr = 0.001, m = 0.9
I0916 13:56:02.697842 19007 data_reader.cpp:305] Starting prefetch of epoch 54
I0916 13:56:08.883769 19004 solver.cpp:314] Iteration 66800 (5.04363 iter/s, 19.827s/100 iter), loss = 0.0804015
I0916 13:56:08.883798 19004 solver.cpp:336]     Train net output #0: loss = 0.0804012 (* 1 = 0.0804012 loss)
I0916 13:56:08.883805 19004 sgd_solver.cpp:136] Iteration 66800, lr = 0.001, m = 0.9
I0916 13:56:28.688117 19004 solver.cpp:314] Iteration 66900 (5.04954 iter/s, 19.8038s/100 iter), loss = 0.0566334
I0916 13:56:28.688141 19004 solver.cpp:336]     Train net output #0: loss = 0.0566332 (* 1 = 0.0566332 loss)
I0916 13:56:28.688146 19004 sgd_solver.cpp:136] Iteration 66900, lr = 0.001, m = 0.9
I0916 13:56:48.328282 19004 solver.cpp:314] Iteration 67000 (5.09175 iter/s, 19.6396s/100 iter), loss = 0.0894225
I0916 13:56:48.328364 19004 solver.cpp:336]     Train net output #0: loss = 0.0894223 (* 1 = 0.0894223 loss)
I0916 13:56:48.328372 19004 sgd_solver.cpp:136] Iteration 67000, lr = 0.001, m = 0.9
I0916 13:57:07.776321 19010 data_reader.cpp:305] Starting prefetch of epoch 38
I0916 13:57:07.948354 19004 solver.cpp:314] Iteration 67100 (5.09696 iter/s, 19.6195s/100 iter), loss = 0.0506412
I0916 13:57:07.948379 19004 solver.cpp:336]     Train net output #0: loss = 0.0506409 (* 1 = 0.0506409 loss)
I0916 13:57:07.948385 19004 sgd_solver.cpp:136] Iteration 67100, lr = 0.001, m = 0.9
I0916 13:57:27.696666 19004 solver.cpp:314] Iteration 67200 (5.06387 iter/s, 19.7478s/100 iter), loss = 0.0625643
I0916 13:57:27.696714 19004 solver.cpp:336]     Train net output #0: loss = 0.0625641 (* 1 = 0.0625641 loss)
I0916 13:57:27.696720 19004 sgd_solver.cpp:136] Iteration 67200, lr = 0.001, m = 0.9
I0916 13:57:40.320703 19008 data_reader.cpp:305] Starting prefetch of epoch 33
I0916 13:57:47.228190 19004 solver.cpp:314] Iteration 67300 (5.12007 iter/s, 19.531s/100 iter), loss = 0.0676498
I0916 13:57:47.228212 19004 solver.cpp:336]     Train net output #0: loss = 0.0676495 (* 1 = 0.0676495 loss)
I0916 13:57:47.228217 19004 sgd_solver.cpp:136] Iteration 67300, lr = 0.001, m = 0.9
I0916 13:58:06.736224 19004 solver.cpp:314] Iteration 67400 (5.12624 iter/s, 19.5075s/100 iter), loss = 0.0392432
I0916 13:58:06.736276 19004 solver.cpp:336]     Train net output #0: loss = 0.0392429 (* 1 = 0.0392429 loss)
I0916 13:58:06.736280 19004 sgd_solver.cpp:136] Iteration 67400, lr = 0.001, m = 0.9
I0916 13:58:26.193461 19004 solver.cpp:314] Iteration 67500 (5.13962 iter/s, 19.4567s/100 iter), loss = 0.0649474
I0916 13:58:26.193481 19004 solver.cpp:336]     Train net output #0: loss = 0.0649471 (* 1 = 0.0649471 loss)
I0916 13:58:26.193486 19004 sgd_solver.cpp:136] Iteration 67500, lr = 0.001, m = 0.9
I0916 13:58:44.795361 18961 data_reader.cpp:305] Starting prefetch of epoch 35
I0916 13:58:45.761318 19004 solver.cpp:314] Iteration 67600 (5.11056 iter/s, 19.5673s/100 iter), loss = 0.038983
I0916 13:58:45.761343 19004 solver.cpp:336]     Train net output #0: loss = 0.0389827 (* 1 = 0.0389827 loss)
I0916 13:58:45.761348 19004 sgd_solver.cpp:136] Iteration 67600, lr = 0.001, m = 0.9
I0916 13:59:05.084975 19004 solver.cpp:314] Iteration 67700 (5.17515 iter/s, 19.3231s/100 iter), loss = 0.035715
I0916 13:59:05.085002 19004 solver.cpp:336]     Train net output #0: loss = 0.0357148 (* 1 = 0.0357148 loss)
I0916 13:59:05.085007 19004 sgd_solver.cpp:136] Iteration 67700, lr = 0.001, m = 0.9
I0916 13:59:24.402262 19004 solver.cpp:314] Iteration 67800 (5.17685 iter/s, 19.3167s/100 iter), loss = 0.0783619
I0916 13:59:24.402310 19004 solver.cpp:336]     Train net output #0: loss = 0.0783616 (* 1 = 0.0783616 loss)
I0916 13:59:24.402317 19004 sgd_solver.cpp:136] Iteration 67800, lr = 0.001, m = 0.9
I0916 13:59:43.874248 19004 solver.cpp:314] Iteration 67900 (5.13573 iter/s, 19.4714s/100 iter), loss = 0.0452266
I0916 13:59:43.874274 19004 solver.cpp:336]     Train net output #0: loss = 0.0452263 (* 1 = 0.0452263 loss)
I0916 13:59:43.874279 19004 sgd_solver.cpp:136] Iteration 67900, lr = 0.001, m = 0.9
I0916 13:59:48.833263 19010 data_reader.cpp:305] Starting prefetch of epoch 39
I0916 14:00:03.020929 19004 solver.cpp:563] Iteration 68000, Testing net (#0)
I0916 14:00:21.955165 19029 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 14:00:22.635274 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.955584
I0916 14:00:22.635300 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 14:00:22.635306 19004 solver.cpp:655]     Test net output #2: loss = 0.152522 (* 1 = 0.152522 loss)
I0916 14:00:22.635335 19004 solver.cpp:265] [MultiGPU] Tests completed in 19.6139s
I0916 14:00:22.855007 19004 solver.cpp:314] Iteration 68000 (2.56544 iter/s, 38.9797s/100 iter), loss = 0.0380655
I0916 14:00:22.855042 19004 solver.cpp:336]     Train net output #0: loss = 0.0380652 (* 1 = 0.0380652 loss)
I0916 14:00:22.855048 19004 sgd_solver.cpp:136] Iteration 68000, lr = 0.001, m = 0.9
I0916 14:00:40.692677 18961 data_reader.cpp:305] Starting prefetch of epoch 36
I0916 14:00:42.325810 19004 solver.cpp:314] Iteration 68100 (5.13604 iter/s, 19.4703s/100 iter), loss = 0.0482261
I0916 14:00:42.325836 19004 solver.cpp:336]     Train net output #0: loss = 0.0482258 (* 1 = 0.0482258 loss)
I0916 14:00:42.325841 19004 sgd_solver.cpp:136] Iteration 68100, lr = 0.001, m = 0.9
I0916 14:01:01.559820 19004 solver.cpp:314] Iteration 68200 (5.19927 iter/s, 19.2335s/100 iter), loss = 0.0563262
I0916 14:01:01.559844 19004 solver.cpp:336]     Train net output #0: loss = 0.0563259 (* 1 = 0.0563259 loss)
I0916 14:01:01.559847 19004 sgd_solver.cpp:136] Iteration 68200, lr = 0.001, m = 0.9
I0916 14:01:20.948745 19004 solver.cpp:314] Iteration 68300 (5.15773 iter/s, 19.3884s/100 iter), loss = 0.0642933
I0916 14:01:20.948796 19004 solver.cpp:336]     Train net output #0: loss = 0.0642931 (* 1 = 0.0642931 loss)
I0916 14:01:20.948801 19004 sgd_solver.cpp:136] Iteration 68300, lr = 0.001, m = 0.9
I0916 14:01:40.413753 19004 solver.cpp:314] Iteration 68400 (5.13757 iter/s, 19.4645s/100 iter), loss = 0.0469783
I0916 14:01:40.413774 19004 solver.cpp:336]     Train net output #0: loss = 0.046978 (* 1 = 0.046978 loss)
I0916 14:01:40.413779 19004 sgd_solver.cpp:136] Iteration 68400, lr = 0.001, m = 0.9
I0916 14:01:44.539665 19010 data_reader.cpp:305] Starting prefetch of epoch 40
I0916 14:01:59.551014 19004 solver.cpp:314] Iteration 68500 (5.22555 iter/s, 19.1367s/100 iter), loss = 0.0619355
I0916 14:01:59.551062 19004 solver.cpp:336]     Train net output #0: loss = 0.0619352 (* 1 = 0.0619352 loss)
I0916 14:01:59.551069 19004 sgd_solver.cpp:136] Iteration 68500, lr = 0.001, m = 0.9
I0916 14:02:19.118861 19004 solver.cpp:314] Iteration 68600 (5.11057 iter/s, 19.5673s/100 iter), loss = 0.0777236
I0916 14:02:19.118885 19004 solver.cpp:336]     Train net output #0: loss = 0.0777233 (* 1 = 0.0777233 loss)
I0916 14:02:19.118891 19004 sgd_solver.cpp:136] Iteration 68600, lr = 0.001, m = 0.9
I0916 14:02:38.444933 19004 solver.cpp:314] Iteration 68700 (5.1745 iter/s, 19.3255s/100 iter), loss = 0.0515185
I0916 14:02:38.445027 19004 solver.cpp:336]     Train net output #0: loss = 0.0515182 (* 1 = 0.0515182 loss)
I0916 14:02:38.445035 19004 sgd_solver.cpp:136] Iteration 68700, lr = 0.001, m = 0.9
I0916 14:02:48.508464 19010 data_reader.cpp:305] Starting prefetch of epoch 41
I0916 14:02:57.773382 19004 solver.cpp:314] Iteration 68800 (5.17387 iter/s, 19.3279s/100 iter), loss = 0.0645397
I0916 14:02:57.773406 19004 solver.cpp:336]     Train net output #0: loss = 0.0645394 (* 1 = 0.0645394 loss)
I0916 14:02:57.773411 19004 sgd_solver.cpp:136] Iteration 68800, lr = 0.001, m = 0.9
I0916 14:03:17.204044 19004 solver.cpp:314] Iteration 68900 (5.14665 iter/s, 19.4301s/100 iter), loss = 0.0615279
I0916 14:03:17.204100 19004 solver.cpp:336]     Train net output #0: loss = 0.0615276 (* 1 = 0.0615276 loss)
I0916 14:03:17.204107 19004 sgd_solver.cpp:136] Iteration 68900, lr = 0.001, m = 0.9
I0916 14:03:20.602324 19008 data_reader.cpp:305] Starting prefetch of epoch 34
I0916 14:03:36.738685 19004 solver.cpp:314] Iteration 69000 (5.11925 iter/s, 19.5341s/100 iter), loss = 0.0577015
I0916 14:03:36.738710 19004 solver.cpp:336]     Train net output #0: loss = 0.0577012 (* 1 = 0.0577012 loss)
I0916 14:03:36.738715 19004 sgd_solver.cpp:136] Iteration 69000, lr = 0.001, m = 0.9
I0916 14:03:56.077090 19004 solver.cpp:314] Iteration 69100 (5.1712 iter/s, 19.3379s/100 iter), loss = 0.0404865
I0916 14:03:56.077134 19004 solver.cpp:336]     Train net output #0: loss = 0.0404862 (* 1 = 0.0404862 loss)
I0916 14:03:56.077141 19004 sgd_solver.cpp:136] Iteration 69100, lr = 0.001, m = 0.9
I0916 14:04:15.382652 19004 solver.cpp:314] Iteration 69200 (5.18 iter/s, 19.305s/100 iter), loss = 0.0505875
I0916 14:04:15.382676 19004 solver.cpp:336]     Train net output #0: loss = 0.0505872 (* 1 = 0.0505872 loss)
I0916 14:04:15.382683 19004 sgd_solver.cpp:136] Iteration 69200, lr = 0.001, m = 0.9
I0916 14:04:24.678217 19012 data_reader.cpp:305] Starting prefetch of epoch 40
I0916 14:04:34.646579 19004 solver.cpp:314] Iteration 69300 (5.1912 iter/s, 19.2634s/100 iter), loss = 0.047041
I0916 14:04:34.646627 19004 solver.cpp:336]     Train net output #0: loss = 0.0470407 (* 1 = 0.0470407 loss)
I0916 14:04:34.646634 19004 sgd_solver.cpp:136] Iteration 69300, lr = 0.001, m = 0.9
I0916 14:04:54.291172 19004 solver.cpp:314] Iteration 69400 (5.0906 iter/s, 19.6441s/100 iter), loss = 0.0634215
I0916 14:04:54.291198 19004 solver.cpp:336]     Train net output #0: loss = 0.0634212 (* 1 = 0.0634212 loss)
I0916 14:04:54.291203 19004 sgd_solver.cpp:136] Iteration 69400, lr = 0.001, m = 0.9
I0916 14:05:13.947199 19004 solver.cpp:314] Iteration 69500 (5.08764 iter/s, 19.6555s/100 iter), loss = 0.0496851
I0916 14:05:13.947250 19004 solver.cpp:336]     Train net output #0: loss = 0.0496848 (* 1 = 0.0496848 loss)
I0916 14:05:13.947255 19004 sgd_solver.cpp:136] Iteration 69500, lr = 0.001, m = 0.9
I0916 14:05:29.217823 19010 data_reader.cpp:305] Starting prefetch of epoch 42
I0916 14:05:33.572244 19004 solver.cpp:314] Iteration 69600 (5.09567 iter/s, 19.6245s/100 iter), loss = 0.059497
I0916 14:05:33.572268 19004 solver.cpp:336]     Train net output #0: loss = 0.0594967 (* 1 = 0.0594967 loss)
I0916 14:05:33.572271 19004 sgd_solver.cpp:136] Iteration 69600, lr = 0.001, m = 0.9
I0916 14:05:52.939277 19004 solver.cpp:314] Iteration 69700 (5.16356 iter/s, 19.3665s/100 iter), loss = 0.0417639
I0916 14:05:52.939332 19004 solver.cpp:336]     Train net output #0: loss = 0.0417636 (* 1 = 0.0417636 loss)
I0916 14:05:52.939337 19004 sgd_solver.cpp:136] Iteration 69700, lr = 0.001, m = 0.9
I0916 14:06:01.610661 19007 data_reader.cpp:305] Starting prefetch of epoch 55
I0916 14:06:12.471077 19004 solver.cpp:314] Iteration 69800 (5.12 iter/s, 19.5313s/100 iter), loss = 0.0369273
I0916 14:06:12.471102 19004 solver.cpp:336]     Train net output #0: loss = 0.036927 (* 1 = 0.036927 loss)
I0916 14:06:12.471107 19004 sgd_solver.cpp:136] Iteration 69800, lr = 0.001, m = 0.9
I0916 14:06:32.728442 19004 solver.cpp:314] Iteration 69900 (4.93662 iter/s, 20.2568s/100 iter), loss = 0.0390449
I0916 14:06:32.728631 19004 solver.cpp:336]     Train net output #0: loss = 0.0390446 (* 1 = 0.0390446 loss)
I0916 14:06:32.728643 19004 sgd_solver.cpp:136] Iteration 69900, lr = 0.001, m = 0.9
I0916 14:06:52.177285 19004 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/cityscapes5_jsegnet21v2_iter_70000.caffemodel
I0916 14:06:52.516281 19004 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/cityscapes5_jsegnet21v2_iter_70000.solverstate
I0916 14:06:52.520175 19004 solver.cpp:563] Iteration 70000, Testing net (#0)
I0916 14:07:03.309473 19018 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 14:07:07.284214 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.956231
I0916 14:07:07.284235 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.999845
I0916 14:07:07.284240 19004 solver.cpp:655]     Test net output #2: loss = 0.182133 (* 1 = 0.182133 loss)
I0916 14:07:07.284265 19004 solver.cpp:265] [MultiGPU] Tests completed in 14.7637s
I0916 14:07:07.500198 19004 solver.cpp:314] Iteration 70000 (2.87598 iter/s, 34.7708s/100 iter), loss = 0.0410241
I0916 14:07:07.500223 19004 solver.cpp:336]     Train net output #0: loss = 0.0410238 (* 1 = 0.0410238 loss)
I0916 14:07:07.500227 19004 sgd_solver.cpp:136] Iteration 70000, lr = 0.001, m = 0.9
I0916 14:07:26.761286 19004 solver.cpp:314] Iteration 70100 (5.19196 iter/s, 19.2605s/100 iter), loss = 0.061723
I0916 14:07:26.761324 19004 solver.cpp:336]     Train net output #0: loss = 0.0617227 (* 1 = 0.0617227 loss)
I0916 14:07:26.761332 19004 sgd_solver.cpp:136] Iteration 70100, lr = 0.001, m = 0.9
I0916 14:07:46.123893 19004 solver.cpp:314] Iteration 70200 (5.16474 iter/s, 19.3621s/100 iter), loss = 0.0377427
I0916 14:07:46.123942 19004 solver.cpp:336]     Train net output #0: loss = 0.0377424 (* 1 = 0.0377424 loss)
I0916 14:07:46.123947 19004 sgd_solver.cpp:136] Iteration 70200, lr = 0.001, m = 0.9
I0916 14:07:53.806669 19008 data_reader.cpp:305] Starting prefetch of epoch 35
I0916 14:08:05.449740 19004 solver.cpp:314] Iteration 70300 (5.17456 iter/s, 19.3253s/100 iter), loss = 0.0794071
I0916 14:08:05.449765 19004 solver.cpp:336]     Train net output #0: loss = 0.0794068 (* 1 = 0.0794068 loss)
I0916 14:08:05.449769 19004 sgd_solver.cpp:136] Iteration 70300, lr = 0.001, m = 0.9
I0916 14:08:24.809906 19004 solver.cpp:314] Iteration 70400 (5.16539 iter/s, 19.3596s/100 iter), loss = 0.029477
I0916 14:08:24.809962 19004 solver.cpp:336]     Train net output #0: loss = 0.0294767 (* 1 = 0.0294767 loss)
I0916 14:08:24.809967 19004 sgd_solver.cpp:136] Iteration 70400, lr = 0.001, m = 0.9
I0916 14:08:25.840754 19008 data_reader.cpp:305] Starting prefetch of epoch 36
I0916 14:08:44.081393 19004 solver.cpp:314] Iteration 70500 (5.18916 iter/s, 19.2709s/100 iter), loss = 0.0501305
I0916 14:08:44.081414 19004 solver.cpp:336]     Train net output #0: loss = 0.0501302 (* 1 = 0.0501302 loss)
I0916 14:08:44.081420 19004 sgd_solver.cpp:136] Iteration 70500, lr = 0.001, m = 0.9
I0916 14:09:03.409126 19004 solver.cpp:314] Iteration 70600 (5.17406 iter/s, 19.3272s/100 iter), loss = 0.0731225
I0916 14:09:03.409181 19004 solver.cpp:336]     Train net output #0: loss = 0.0731222 (* 1 = 0.0731222 loss)
I0916 14:09:03.409188 19004 sgd_solver.cpp:136] Iteration 70600, lr = 0.001, m = 0.9
I0916 14:09:22.909263 19004 solver.cpp:314] Iteration 70700 (5.12831 iter/s, 19.4996s/100 iter), loss = 0.0566369
I0916 14:09:22.909287 19004 solver.cpp:336]     Train net output #0: loss = 0.0566366 (* 1 = 0.0566366 loss)
I0916 14:09:22.909291 19004 sgd_solver.cpp:136] Iteration 70700, lr = 0.001, m = 0.9
I0916 14:09:29.787483 18963 data_reader.cpp:305] Starting prefetch of epoch 49
I0916 14:09:42.405398 19004 solver.cpp:314] Iteration 70800 (5.12936 iter/s, 19.4956s/100 iter), loss = 0.0409276
I0916 14:09:42.405467 19004 solver.cpp:336]     Train net output #0: loss = 0.0409273 (* 1 = 0.0409273 loss)
I0916 14:09:42.405473 19004 sgd_solver.cpp:136] Iteration 70800, lr = 0.001, m = 0.9
I0916 14:10:02.201632 19004 solver.cpp:314] Iteration 70900 (5.05161 iter/s, 19.7957s/100 iter), loss = 0.0440225
I0916 14:10:02.201663 19004 solver.cpp:336]     Train net output #0: loss = 0.0440222 (* 1 = 0.0440222 loss)
I0916 14:10:02.201669 19004 sgd_solver.cpp:136] Iteration 70900, lr = 0.001, m = 0.9
I0916 14:10:22.580602 19004 solver.cpp:314] Iteration 71000 (4.90716 iter/s, 20.3784s/100 iter), loss = 0.0626209
I0916 14:10:22.580651 19004 solver.cpp:336]     Train net output #0: loss = 0.0626206 (* 1 = 0.0626206 loss)
I0916 14:10:22.580657 19004 sgd_solver.cpp:136] Iteration 71000, lr = 0.001, m = 0.9
I0916 14:10:36.004451 18963 data_reader.cpp:305] Starting prefetch of epoch 50
I0916 14:10:42.841995 19004 solver.cpp:314] Iteration 71100 (4.93563 iter/s, 20.2608s/100 iter), loss = 0.0684709
I0916 14:10:42.842020 19004 solver.cpp:336]     Train net output #0: loss = 0.0684706 (* 1 = 0.0684706 loss)
I0916 14:10:42.842026 19004 sgd_solver.cpp:136] Iteration 71100, lr = 0.001, m = 0.9
I0916 14:11:02.372268 19004 solver.cpp:314] Iteration 71200 (5.1204 iter/s, 19.5297s/100 iter), loss = 0.0306411
I0916 14:11:02.372323 19004 solver.cpp:336]     Train net output #0: loss = 0.0306408 (* 1 = 0.0306408 loss)
I0916 14:11:02.372328 19004 sgd_solver.cpp:136] Iteration 71200, lr = 0.001, m = 0.9
I0916 14:11:08.441429 18961 data_reader.cpp:305] Starting prefetch of epoch 37
I0916 14:11:22.288213 19004 solver.cpp:314] Iteration 71300 (5.02125 iter/s, 19.9154s/100 iter), loss = 0.0430651
I0916 14:11:22.288255 19004 solver.cpp:336]     Train net output #0: loss = 0.0430648 (* 1 = 0.0430648 loss)
I0916 14:11:22.311691 19004 sgd_solver.cpp:136] Iteration 71300, lr = 0.001, m = 0.9
I0916 14:11:42.952121 19004 solver.cpp:314] Iteration 71400 (4.83949 iter/s, 20.6633s/100 iter), loss = 0.0512918
I0916 14:11:42.952172 19004 solver.cpp:336]     Train net output #0: loss = 0.0512914 (* 1 = 0.0512914 loss)
I0916 14:11:42.952180 19004 sgd_solver.cpp:136] Iteration 71400, lr = 0.001, m = 0.9
I0916 14:12:03.260499 19004 solver.cpp:314] Iteration 71500 (4.92421 iter/s, 20.3078s/100 iter), loss = 0.0765989
I0916 14:12:03.260524 19004 solver.cpp:336]     Train net output #0: loss = 0.0765985 (* 1 = 0.0765985 loss)
I0916 14:12:03.260529 19004 sgd_solver.cpp:136] Iteration 71500, lr = 0.001, m = 0.9
I0916 14:12:15.725949 19010 data_reader.cpp:305] Starting prefetch of epoch 43
I0916 14:12:23.470173 19004 solver.cpp:314] Iteration 71600 (4.94826 iter/s, 20.2091s/100 iter), loss = 0.0784162
I0916 14:12:23.470216 19004 solver.cpp:336]     Train net output #0: loss = 0.0784159 (* 1 = 0.0784159 loss)
I0916 14:12:23.470240 19004 sgd_solver.cpp:136] Iteration 71600, lr = 0.001, m = 0.9
I0916 14:12:44.082403 19004 solver.cpp:314] Iteration 71700 (4.85162 iter/s, 20.6117s/100 iter), loss = 0.0746644
I0916 14:12:44.082427 19004 solver.cpp:336]     Train net output #0: loss = 0.0746641 (* 1 = 0.0746641 loss)
I0916 14:12:44.082432 19004 sgd_solver.cpp:136] Iteration 71700, lr = 0.001, m = 0.9
I0916 14:13:05.455543 19004 solver.cpp:314] Iteration 71800 (4.6789 iter/s, 21.3725s/100 iter), loss = 0.0418129
I0916 14:13:05.455597 19004 solver.cpp:336]     Train net output #0: loss = 0.0418126 (* 1 = 0.0418126 loss)
I0916 14:13:05.455603 19004 sgd_solver.cpp:136] Iteration 71800, lr = 0.001, m = 0.9
I0916 14:13:24.419253 18963 data_reader.cpp:305] Starting prefetch of epoch 51
I0916 14:13:26.062309 19004 solver.cpp:314] Iteration 71900 (4.85291 iter/s, 20.6062s/100 iter), loss = 0.0358405
I0916 14:13:26.062330 19004 solver.cpp:336]     Train net output #0: loss = 0.0358401 (* 1 = 0.0358401 loss)
I0916 14:13:26.062335 19004 sgd_solver.cpp:136] Iteration 71900, lr = 0.001, m = 0.9
I0916 14:13:46.616911 19004 solver.cpp:563] Iteration 72000, Testing net (#0)
I0916 14:13:51.544803 19002 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 14:14:01.015525 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.956371
I0916 14:14:01.015548 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 14:14:01.015553 19004 solver.cpp:655]     Test net output #2: loss = 0.146787 (* 1 = 0.146787 loss)
I0916 14:14:01.015579 19004 solver.cpp:265] [MultiGPU] Tests completed in 14.3983s
I0916 14:14:01.229109 19004 solver.cpp:314] Iteration 72000 (2.84367 iter/s, 35.1658s/100 iter), loss = 0.0646516
I0916 14:14:01.229142 19004 solver.cpp:336]     Train net output #0: loss = 0.0646513 (* 1 = 0.0646513 loss)
I0916 14:14:01.229148 19004 sgd_solver.cpp:136] Iteration 72000, lr = 0.001, m = 0.9
I0916 14:14:12.914417 19010 data_reader.cpp:305] Starting prefetch of epoch 44
I0916 14:14:21.666626 19004 solver.cpp:314] Iteration 72100 (4.8931 iter/s, 20.4369s/100 iter), loss = 0.0322361
I0916 14:14:21.666688 19004 solver.cpp:336]     Train net output #0: loss = 0.0322357 (* 1 = 0.0322357 loss)
I0916 14:14:21.666695 19004 sgd_solver.cpp:136] Iteration 72100, lr = 0.001, m = 0.9
I0916 14:14:42.063963 19004 solver.cpp:314] Iteration 72200 (4.90274 iter/s, 20.3968s/100 iter), loss = 0.0669692
I0916 14:14:42.063985 19004 solver.cpp:336]     Train net output #0: loss = 0.0669689 (* 1 = 0.0669689 loss)
I0916 14:14:42.063989 19004 sgd_solver.cpp:136] Iteration 72200, lr = 0.001, m = 0.9
I0916 14:15:02.906927 19004 solver.cpp:314] Iteration 72300 (4.79792 iter/s, 20.8424s/100 iter), loss = 0.0489574
I0916 14:15:02.906980 19004 solver.cpp:336]     Train net output #0: loss = 0.048957 (* 1 = 0.048957 loss)
I0916 14:15:02.906986 19004 sgd_solver.cpp:136] Iteration 72300, lr = 0.001, m = 0.9
I0916 14:15:21.404451 18963 data_reader.cpp:305] Starting prefetch of epoch 52
I0916 14:15:23.800833 19004 solver.cpp:314] Iteration 72400 (4.78622 iter/s, 20.8933s/100 iter), loss = 0.0467687
I0916 14:15:23.800854 19004 solver.cpp:336]     Train net output #0: loss = 0.0467684 (* 1 = 0.0467684 loss)
I0916 14:15:23.800858 19004 sgd_solver.cpp:136] Iteration 72400, lr = 0.001, m = 0.9
I0916 14:15:44.721213 19004 solver.cpp:314] Iteration 72500 (4.78016 iter/s, 20.9198s/100 iter), loss = 0.0516731
I0916 14:15:44.721304 19004 solver.cpp:336]     Train net output #0: loss = 0.0516728 (* 1 = 0.0516728 loss)
I0916 14:15:44.721312 19004 sgd_solver.cpp:136] Iteration 72500, lr = 0.001, m = 0.9
I0916 14:15:55.832476 19008 data_reader.cpp:305] Starting prefetch of epoch 37
I0916 14:16:05.304179 19004 solver.cpp:314] Iteration 72600 (4.85852 iter/s, 20.5824s/100 iter), loss = 0.0623642
I0916 14:16:05.304204 19004 solver.cpp:336]     Train net output #0: loss = 0.0623638 (* 1 = 0.0623638 loss)
I0916 14:16:05.304209 19004 sgd_solver.cpp:136] Iteration 72600, lr = 0.001, m = 0.9
I0916 14:16:26.022760 19004 solver.cpp:314] Iteration 72700 (4.82672 iter/s, 20.718s/100 iter), loss = 0.0509351
I0916 14:16:26.022811 19004 solver.cpp:336]     Train net output #0: loss = 0.0509347 (* 1 = 0.0509347 loss)
I0916 14:16:26.022816 19004 sgd_solver.cpp:136] Iteration 72700, lr = 0.001, m = 0.9
I0916 14:16:46.885035 19004 solver.cpp:314] Iteration 72800 (4.79348 iter/s, 20.8617s/100 iter), loss = 0.0760545
I0916 14:16:46.885076 19004 solver.cpp:336]     Train net output #0: loss = 0.0760542 (* 1 = 0.0760542 loss)
I0916 14:16:46.885105 19004 sgd_solver.cpp:136] Iteration 72800, lr = 0.001, m = 0.9
I0916 14:17:04.339251 19010 data_reader.cpp:305] Starting prefetch of epoch 45
I0916 14:17:07.481917 19004 solver.cpp:314] Iteration 72900 (4.85524 iter/s, 20.5963s/100 iter), loss = 0.045941
I0916 14:17:07.482012 19004 solver.cpp:336]     Train net output #0: loss = 0.0459406 (* 1 = 0.0459406 loss)
I0916 14:17:07.482048 19004 sgd_solver.cpp:136] Iteration 72900, lr = 0.001, m = 0.9
I0916 14:17:27.802431 19004 solver.cpp:314] Iteration 73000 (4.92127 iter/s, 20.32s/100 iter), loss = 0.0630204
I0916 14:17:27.802460 19004 solver.cpp:336]     Train net output #0: loss = 0.0630201 (* 1 = 0.0630201 loss)
I0916 14:17:27.802467 19004 sgd_solver.cpp:136] Iteration 73000, lr = 0.001, m = 0.9
I0916 14:17:47.167757 19004 solver.cpp:314] Iteration 73100 (5.16401 iter/s, 19.3648s/100 iter), loss = 0.0799194
I0916 14:17:47.167825 19004 solver.cpp:336]     Train net output #0: loss = 0.079919 (* 1 = 0.079919 loss)
I0916 14:17:47.167831 19004 sgd_solver.cpp:136] Iteration 73100, lr = 0.001, m = 0.9
I0916 14:18:06.968065 19004 solver.cpp:314] Iteration 73200 (5.05057 iter/s, 19.7998s/100 iter), loss = 0.0566471
I0916 14:18:06.968091 19004 solver.cpp:336]     Train net output #0: loss = 0.0566468 (* 1 = 0.0566468 loss)
I0916 14:18:06.968096 19004 sgd_solver.cpp:136] Iteration 73200, lr = 0.001, m = 0.9
I0916 14:18:09.869072 19010 data_reader.cpp:305] Starting prefetch of epoch 46
I0916 14:18:26.402899 19004 solver.cpp:314] Iteration 73300 (5.14554 iter/s, 19.4343s/100 iter), loss = 0.0333387
I0916 14:18:26.402954 19004 solver.cpp:336]     Train net output #0: loss = 0.0333384 (* 1 = 0.0333384 loss)
I0916 14:18:26.402961 19004 sgd_solver.cpp:136] Iteration 73300, lr = 0.001, m = 0.9
I0916 14:18:42.073225 19008 data_reader.cpp:305] Starting prefetch of epoch 38
I0916 14:18:45.912076 19004 solver.cpp:314] Iteration 73400 (5.12594 iter/s, 19.5086s/100 iter), loss = 0.0691323
I0916 14:18:45.912101 19004 solver.cpp:336]     Train net output #0: loss = 0.0691319 (* 1 = 0.0691319 loss)
I0916 14:18:45.912107 19004 sgd_solver.cpp:136] Iteration 73400, lr = 0.001, m = 0.9
I0916 14:19:05.288576 19004 solver.cpp:314] Iteration 73500 (5.16103 iter/s, 19.376s/100 iter), loss = 0.0623904
I0916 14:19:05.288663 19004 solver.cpp:336]     Train net output #0: loss = 0.0623901 (* 1 = 0.0623901 loss)
I0916 14:19:05.288671 19004 sgd_solver.cpp:136] Iteration 73500, lr = 0.001, m = 0.9
I0916 14:19:24.707665 19004 solver.cpp:314] Iteration 73600 (5.14972 iter/s, 19.4185s/100 iter), loss = 0.0716062
I0916 14:19:24.707687 19004 solver.cpp:336]     Train net output #0: loss = 0.0716059 (* 1 = 0.0716059 loss)
I0916 14:19:24.707692 19004 sgd_solver.cpp:136] Iteration 73600, lr = 0.001, m = 0.9
I0916 14:19:44.121062 19004 solver.cpp:314] Iteration 73700 (5.15123 iter/s, 19.4129s/100 iter), loss = 0.100906
I0916 14:19:44.121111 19004 solver.cpp:336]     Train net output #0: loss = 0.100906 (* 1 = 0.100906 loss)
I0916 14:19:44.121116 19004 sgd_solver.cpp:136] Iteration 73700, lr = 0.001, m = 0.9
I0916 14:19:46.091037 18963 data_reader.cpp:305] Starting prefetch of epoch 53
I0916 14:20:03.621441 19004 solver.cpp:314] Iteration 73800 (5.12825 iter/s, 19.4998s/100 iter), loss = 0.0620662
I0916 14:20:03.621461 19004 solver.cpp:336]     Train net output #0: loss = 0.0620658 (* 1 = 0.0620658 loss)
I0916 14:20:03.621465 19004 sgd_solver.cpp:136] Iteration 73800, lr = 0.001, m = 0.9
I0916 14:20:22.866751 19004 solver.cpp:314] Iteration 73900 (5.19622 iter/s, 19.2448s/100 iter), loss = 0.065291
I0916 14:20:22.866803 19004 solver.cpp:336]     Train net output #0: loss = 0.0652907 (* 1 = 0.0652907 loss)
I0916 14:20:22.866809 19004 sgd_solver.cpp:136] Iteration 73900, lr = 0.001, m = 0.9
I0916 14:20:42.237622 19004 solver.cpp:563] Iteration 74000, Testing net (#0)
I0916 14:20:49.520390 19029 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 14:20:53.545521 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.955536
I0916 14:20:53.545646 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.999785
I0916 14:20:53.545656 19004 solver.cpp:655]     Test net output #2: loss = 0.191989 (* 1 = 0.191989 loss)
I0916 14:20:53.545680 19004 solver.cpp:265] [MultiGPU] Tests completed in 11.3077s
I0916 14:20:53.755523 19004 solver.cpp:314] Iteration 74000 (3.23751 iter/s, 30.8879s/100 iter), loss = 0.0644693
I0916 14:20:53.755548 19004 solver.cpp:336]     Train net output #0: loss = 0.0644689 (* 1 = 0.0644689 loss)
I0916 14:20:53.755551 19004 sgd_solver.cpp:136] Iteration 74000, lr = 0.001, m = 0.9
I0916 14:21:01.820927 18961 data_reader.cpp:305] Starting prefetch of epoch 38
I0916 14:21:13.257920 19004 solver.cpp:314] Iteration 74100 (5.12772 iter/s, 19.5018s/100 iter), loss = 0.0481768
I0916 14:21:13.257953 19004 solver.cpp:336]     Train net output #0: loss = 0.0481765 (* 1 = 0.0481765 loss)
I0916 14:21:13.257961 19004 sgd_solver.cpp:136] Iteration 74100, lr = 0.001, m = 0.9
I0916 14:21:32.795439 19004 solver.cpp:314] Iteration 74200 (5.1185 iter/s, 19.537s/100 iter), loss = 0.056077
I0916 14:21:32.795512 19004 solver.cpp:336]     Train net output #0: loss = 0.0560767 (* 1 = 0.0560767 loss)
I0916 14:21:32.795519 19004 sgd_solver.cpp:136] Iteration 74200, lr = 0.001, m = 0.9
I0916 14:21:52.315662 19004 solver.cpp:314] Iteration 74300 (5.12304 iter/s, 19.5197s/100 iter), loss = 0.0649375
I0916 14:21:52.315685 19004 solver.cpp:336]     Train net output #0: loss = 0.0649372 (* 1 = 0.0649372 loss)
I0916 14:21:52.315690 19004 sgd_solver.cpp:136] Iteration 74300, lr = 0.001, m = 0.9
I0916 14:22:05.990263 19012 data_reader.cpp:305] Starting prefetch of epoch 41
I0916 14:22:11.594555 19004 solver.cpp:314] Iteration 74400 (5.18717 iter/s, 19.2783s/100 iter), loss = 0.062689
I0916 14:22:11.594579 19004 solver.cpp:336]     Train net output #0: loss = 0.0626886 (* 1 = 0.0626886 loss)
I0916 14:22:11.594585 19004 sgd_solver.cpp:136] Iteration 74400, lr = 0.001, m = 0.9
I0916 14:22:31.904964 19004 solver.cpp:314] Iteration 74500 (4.92372 iter/s, 20.3098s/100 iter), loss = 0.0506368
I0916 14:22:31.904990 19004 solver.cpp:336]     Train net output #0: loss = 0.0506364 (* 1 = 0.0506364 loss)
I0916 14:22:31.904995 19004 sgd_solver.cpp:136] Iteration 74500, lr = 0.001, m = 0.9
I0916 14:22:52.116848 19004 solver.cpp:314] Iteration 74600 (4.94772 iter/s, 20.2113s/100 iter), loss = 0.0602769
I0916 14:22:52.116930 19004 solver.cpp:336]     Train net output #0: loss = 0.0602765 (* 1 = 0.0602765 loss)
I0916 14:22:52.116936 19004 sgd_solver.cpp:136] Iteration 74600, lr = 0.001, m = 0.9
I0916 14:23:12.408380 19004 solver.cpp:314] Iteration 74700 (4.9283 iter/s, 20.291s/100 iter), loss = 0.055413
I0916 14:23:12.408404 19004 solver.cpp:336]     Train net output #0: loss = 0.0554126 (* 1 = 0.0554126 loss)
I0916 14:23:12.408408 19004 sgd_solver.cpp:136] Iteration 74700, lr = 0.001, m = 0.9
I0916 14:23:12.826414 18963 data_reader.cpp:305] Starting prefetch of epoch 54
I0916 14:23:32.415511 19004 solver.cpp:314] Iteration 74800 (4.99836 iter/s, 20.0066s/100 iter), loss = 0.0389207
I0916 14:23:32.415560 19004 solver.cpp:336]     Train net output #0: loss = 0.0389203 (* 1 = 0.0389203 loss)
I0916 14:23:32.415565 19004 sgd_solver.cpp:136] Iteration 74800, lr = 0.001, m = 0.9
I0916 14:23:46.007555 19008 data_reader.cpp:305] Starting prefetch of epoch 39
I0916 14:23:52.704704 19004 solver.cpp:314] Iteration 74900 (4.92887 iter/s, 20.2886s/100 iter), loss = 0.0535058
I0916 14:23:52.704728 19004 solver.cpp:336]     Train net output #0: loss = 0.0535055 (* 1 = 0.0535055 loss)
I0916 14:23:52.704732 19004 sgd_solver.cpp:136] Iteration 74900, lr = 0.001, m = 0.9
I0916 14:24:12.979583 19004 solver.cpp:314] Iteration 75000 (4.93235 iter/s, 20.2743s/100 iter), loss = 0.0560842
I0916 14:24:12.979665 19004 solver.cpp:336]     Train net output #0: loss = 0.0560838 (* 1 = 0.0560838 loss)
I0916 14:24:12.979672 19004 sgd_solver.cpp:136] Iteration 75000, lr = 0.001, m = 0.9
I0916 14:24:33.187396 19004 solver.cpp:314] Iteration 75100 (4.94872 iter/s, 20.2072s/100 iter), loss = 0.0724591
I0916 14:24:33.187422 19004 solver.cpp:336]     Train net output #0: loss = 0.0724587 (* 1 = 0.0724587 loss)
I0916 14:24:33.187427 19004 sgd_solver.cpp:136] Iteration 75100, lr = 0.001, m = 0.9
I0916 14:24:52.877521 19012 data_reader.cpp:305] Starting prefetch of epoch 42
I0916 14:24:53.271785 19004 solver.cpp:314] Iteration 75200 (4.97913 iter/s, 20.0838s/100 iter), loss = 0.072883
I0916 14:24:53.271809 19004 solver.cpp:336]     Train net output #0: loss = 0.0728827 (* 1 = 0.0728827 loss)
I0916 14:24:53.271816 19004 sgd_solver.cpp:136] Iteration 75200, lr = 0.001, m = 0.9
I0916 14:25:13.239715 19004 solver.cpp:314] Iteration 75300 (5.00817 iter/s, 19.9674s/100 iter), loss = 0.044085
I0916 14:25:13.239738 19004 solver.cpp:336]     Train net output #0: loss = 0.0440846 (* 1 = 0.0440846 loss)
I0916 14:25:13.239743 19004 sgd_solver.cpp:136] Iteration 75300, lr = 0.001, m = 0.9
I0916 14:25:33.680179 19004 solver.cpp:314] Iteration 75400 (4.8924 iter/s, 20.4399s/100 iter), loss = 0.0504331
I0916 14:25:33.680269 19004 solver.cpp:336]     Train net output #0: loss = 0.0504328 (* 1 = 0.0504328 loss)
I0916 14:25:33.680276 19004 sgd_solver.cpp:136] Iteration 75400, lr = 0.001, m = 0.9
I0916 14:25:53.653806 19004 solver.cpp:314] Iteration 75500 (5.00674 iter/s, 19.9731s/100 iter), loss = 0.060986
I0916 14:25:53.653831 19004 solver.cpp:336]     Train net output #0: loss = 0.0609857 (* 1 = 0.0609857 loss)
I0916 14:25:53.653836 19004 sgd_solver.cpp:136] Iteration 75500, lr = 0.001, m = 0.9
I0916 14:25:59.370501 19012 data_reader.cpp:305] Starting prefetch of epoch 43
I0916 14:26:13.806627 19004 solver.cpp:314] Iteration 75600 (4.96222 iter/s, 20.1523s/100 iter), loss = 0.0836586
I0916 14:26:13.806689 19004 solver.cpp:336]     Train net output #0: loss = 0.0836582 (* 1 = 0.0836582 loss)
I0916 14:26:13.806696 19004 sgd_solver.cpp:136] Iteration 75600, lr = 0.001, m = 0.9
I0916 14:26:32.655820 19007 data_reader.cpp:305] Starting prefetch of epoch 56
I0916 14:26:33.804828 19004 solver.cpp:314] Iteration 75700 (5.00059 iter/s, 19.9976s/100 iter), loss = 0.0549529
I0916 14:26:33.804855 19004 solver.cpp:336]     Train net output #0: loss = 0.0549526 (* 1 = 0.0549526 loss)
I0916 14:26:33.804862 19004 sgd_solver.cpp:136] Iteration 75700, lr = 0.001, m = 0.9
I0916 14:26:54.364778 19004 solver.cpp:314] Iteration 75800 (4.86396 iter/s, 20.5594s/100 iter), loss = 0.0462039
I0916 14:26:54.364837 19004 solver.cpp:336]     Train net output #0: loss = 0.0462036 (* 1 = 0.0462036 loss)
I0916 14:26:54.364845 19004 sgd_solver.cpp:136] Iteration 75800, lr = 0.001, m = 0.9
I0916 14:27:14.697520 19004 solver.cpp:314] Iteration 75900 (4.91831 iter/s, 20.3322s/100 iter), loss = 0.0409312
I0916 14:27:14.697547 19004 solver.cpp:336]     Train net output #0: loss = 0.0409309 (* 1 = 0.0409309 loss)
I0916 14:27:14.697553 19004 sgd_solver.cpp:136] Iteration 75900, lr = 0.001, m = 0.9
I0916 14:27:35.113543 19004 solver.cpp:563] Iteration 76000, Testing net (#0)
I0916 14:27:39.563720 19029 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 14:27:49.540036 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.956068
I0916 14:27:49.540057 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 14:27:49.540062 19004 solver.cpp:655]     Test net output #2: loss = 0.148198 (* 1 = 0.148198 loss)
I0916 14:27:49.540086 19004 solver.cpp:265] [MultiGPU] Tests completed in 14.4261s
I0916 14:27:49.744076 19004 solver.cpp:314] Iteration 76000 (2.85343 iter/s, 35.0456s/100 iter), loss = 0.0495591
I0916 14:27:49.744099 19004 solver.cpp:336]     Train net output #0: loss = 0.0495588 (* 1 = 0.0495588 loss)
I0916 14:27:49.744103 19004 sgd_solver.cpp:136] Iteration 76000, lr = 0.001, m = 0.9
I0916 14:27:54.651597 19010 data_reader.cpp:305] Starting prefetch of epoch 47
I0916 14:28:09.881026 19004 solver.cpp:314] Iteration 76100 (4.96614 iter/s, 20.1364s/100 iter), loss = 0.0793135
I0916 14:28:09.881090 19004 solver.cpp:336]     Train net output #0: loss = 0.0793133 (* 1 = 0.0793133 loss)
I0916 14:28:09.881098 19004 sgd_solver.cpp:136] Iteration 76100, lr = 0.001, m = 0.9
I0916 14:28:28.313334 19007 data_reader.cpp:305] Starting prefetch of epoch 57
I0916 14:28:30.501636 19004 solver.cpp:314] Iteration 76200 (4.84965 iter/s, 20.62s/100 iter), loss = 0.0588278
I0916 14:28:30.501659 19004 solver.cpp:336]     Train net output #0: loss = 0.0588275 (* 1 = 0.0588275 loss)
I0916 14:28:30.501664 19004 sgd_solver.cpp:136] Iteration 76200, lr = 0.001, m = 0.9
I0916 14:28:50.854769 19004 solver.cpp:314] Iteration 76300 (4.91339 iter/s, 20.3526s/100 iter), loss = 0.0593508
I0916 14:28:50.854852 19004 solver.cpp:336]     Train net output #0: loss = 0.0593506 (* 1 = 0.0593506 loss)
I0916 14:28:50.854859 19004 sgd_solver.cpp:136] Iteration 76300, lr = 0.001, m = 0.9
I0916 14:29:11.670264 19004 solver.cpp:314] Iteration 76400 (4.80425 iter/s, 20.8149s/100 iter), loss = 0.0702389
I0916 14:29:11.670289 19004 solver.cpp:336]     Train net output #0: loss = 0.0702386 (* 1 = 0.0702386 loss)
I0916 14:29:11.670294 19004 sgd_solver.cpp:136] Iteration 76400, lr = 0.001, m = 0.9
I0916 14:29:31.988346 19004 solver.cpp:314] Iteration 76500 (4.92186 iter/s, 20.3175s/100 iter), loss = 0.0891686
I0916 14:29:31.988472 19004 solver.cpp:336]     Train net output #0: loss = 0.0891684 (* 1 = 0.0891684 loss)
I0916 14:29:31.988478 19004 sgd_solver.cpp:136] Iteration 76500, lr = 0.001, m = 0.9
I0916 14:29:36.204218 19012 data_reader.cpp:305] Starting prefetch of epoch 44
I0916 14:29:52.787876 19004 solver.cpp:314] Iteration 76600 (4.80794 iter/s, 20.7989s/100 iter), loss = 0.0467259
I0916 14:29:52.787905 19004 solver.cpp:336]     Train net output #0: loss = 0.0467257 (* 1 = 0.0467257 loss)
I0916 14:29:52.787911 19004 sgd_solver.cpp:136] Iteration 76600, lr = 0.001, m = 0.9
I0916 14:30:13.577612 19004 solver.cpp:314] Iteration 76700 (4.8102 iter/s, 20.7892s/100 iter), loss = 0.0626942
I0916 14:30:13.593930 19004 solver.cpp:336]     Train net output #0: loss = 0.0626939 (* 1 = 0.0626939 loss)
I0916 14:30:13.593966 19004 sgd_solver.cpp:136] Iteration 76700, lr = 0.001, m = 0.9
I0916 14:30:33.897886 19004 solver.cpp:314] Iteration 76800 (4.92133 iter/s, 20.3197s/100 iter), loss = 0.0532773
I0916 14:30:33.897913 19004 solver.cpp:336]     Train net output #0: loss = 0.053277 (* 1 = 0.053277 loss)
I0916 14:30:33.897920 19004 sgd_solver.cpp:136] Iteration 76800, lr = 0.001, m = 0.9
I0916 14:30:44.297171 19010 data_reader.cpp:305] Starting prefetch of epoch 48
I0916 14:30:54.504093 19004 solver.cpp:314] Iteration 76900 (4.85304 iter/s, 20.6056s/100 iter), loss = 0.0355199
I0916 14:30:54.504179 19004 solver.cpp:336]     Train net output #0: loss = 0.0355196 (* 1 = 0.0355196 loss)
I0916 14:30:54.504199 19004 sgd_solver.cpp:136] Iteration 76900, lr = 0.001, m = 0.9
I0916 14:31:14.942343 19004 solver.cpp:314] Iteration 77000 (4.89292 iter/s, 20.4377s/100 iter), loss = 0.0318464
I0916 14:31:14.942394 19004 solver.cpp:336]     Train net output #0: loss = 0.0318461 (* 1 = 0.0318461 loss)
I0916 14:31:14.942399 19004 sgd_solver.cpp:136] Iteration 77000, lr = 0.001, m = 0.9
I0916 14:31:18.323330 18961 data_reader.cpp:305] Starting prefetch of epoch 39
I0916 14:31:36.063962 19004 solver.cpp:314] Iteration 77100 (4.73462 iter/s, 21.121s/100 iter), loss = 0.142641
I0916 14:31:36.063982 19004 solver.cpp:336]     Train net output #0: loss = 0.142641 (* 1 = 0.142641 loss)
I0916 14:31:36.063987 19004 sgd_solver.cpp:136] Iteration 77100, lr = 0.001, m = 0.9
I0916 14:31:56.497694 19004 solver.cpp:314] Iteration 77200 (4.89401 iter/s, 20.4332s/100 iter), loss = 0.0577432
I0916 14:31:56.497756 19004 solver.cpp:336]     Train net output #0: loss = 0.0577429 (* 1 = 0.0577429 loss)
I0916 14:31:56.497764 19004 sgd_solver.cpp:136] Iteration 77200, lr = 0.001, m = 0.9
I0916 14:32:17.467571 19004 solver.cpp:314] Iteration 77300 (4.76888 iter/s, 20.9693s/100 iter), loss = 0.0494651
I0916 14:32:17.467599 19004 solver.cpp:336]     Train net output #0: loss = 0.0494648 (* 1 = 0.0494648 loss)
I0916 14:32:17.467604 19004 sgd_solver.cpp:136] Iteration 77300, lr = 0.001, m = 0.9
I0916 14:32:27.033341 18963 data_reader.cpp:305] Starting prefetch of epoch 55
I0916 14:32:38.040841 19004 solver.cpp:314] Iteration 77400 (4.86081 iter/s, 20.5727s/100 iter), loss = 0.0496184
I0916 14:32:38.040864 19004 solver.cpp:336]     Train net output #0: loss = 0.0496181 (* 1 = 0.0496181 loss)
I0916 14:32:38.040869 19004 sgd_solver.cpp:136] Iteration 77400, lr = 0.001, m = 0.9
I0916 14:32:58.517874 19004 solver.cpp:314] Iteration 77500 (4.88366 iter/s, 20.4765s/100 iter), loss = 0.073024
I0916 14:32:58.517940 19004 solver.cpp:336]     Train net output #0: loss = 0.0730237 (* 1 = 0.0730237 loss)
I0916 14:32:58.517946 19004 sgd_solver.cpp:136] Iteration 77500, lr = 0.001, m = 0.9
I0916 14:33:19.372921 19004 solver.cpp:314] Iteration 77600 (4.79514 iter/s, 20.8545s/100 iter), loss = 0.0457397
I0916 14:33:19.372946 19004 solver.cpp:336]     Train net output #0: loss = 0.0457394 (* 1 = 0.0457394 loss)
I0916 14:33:19.372951 19004 sgd_solver.cpp:136] Iteration 77600, lr = 0.001, m = 0.9
I0916 14:33:35.505231 19012 data_reader.cpp:305] Starting prefetch of epoch 45
I0916 14:33:40.222139 19004 solver.cpp:314] Iteration 77700 (4.79648 iter/s, 20.8486s/100 iter), loss = 0.0509053
I0916 14:33:40.222167 19004 solver.cpp:336]     Train net output #0: loss = 0.050905 (* 1 = 0.050905 loss)
I0916 14:33:40.222174 19004 sgd_solver.cpp:136] Iteration 77700, lr = 0.001, m = 0.9
I0916 14:34:00.956821 19004 solver.cpp:314] Iteration 77800 (4.82297 iter/s, 20.7341s/100 iter), loss = 0.0524338
I0916 14:34:00.956846 19004 solver.cpp:336]     Train net output #0: loss = 0.0524335 (* 1 = 0.0524335 loss)
I0916 14:34:00.956849 19004 sgd_solver.cpp:136] Iteration 77800, lr = 0.001, m = 0.9
I0916 14:34:09.383671 18961 data_reader.cpp:305] Starting prefetch of epoch 40
I0916 14:34:21.381364 19004 solver.cpp:314] Iteration 77900 (4.89621 iter/s, 20.424s/100 iter), loss = 0.0542771
I0916 14:34:21.382946 19004 solver.cpp:336]     Train net output #0: loss = 0.0542768 (* 1 = 0.0542768 loss)
I0916 14:34:21.382959 19004 sgd_solver.cpp:136] Iteration 77900, lr = 0.001, m = 0.9
I0916 14:34:41.588410 19004 solver.cpp:563] Iteration 78000, Testing net (#0)
I0916 14:34:55.791532 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.956022
I0916 14:34:55.791574 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.999762
I0916 14:34:55.791592 19004 solver.cpp:655]     Test net output #2: loss = 0.19316 (* 1 = 0.19316 loss)
I0916 14:34:55.791651 19004 solver.cpp:265] [MultiGPU] Tests completed in 14.2028s
I0916 14:34:56.016993 19004 solver.cpp:314] Iteration 78000 (2.88728 iter/s, 34.6347s/100 iter), loss = 0.127928
I0916 14:34:56.017020 19004 solver.cpp:336]     Train net output #0: loss = 0.127928 (* 1 = 0.127928 loss)
I0916 14:34:56.017027 19004 sgd_solver.cpp:136] Iteration 78000, lr = 0.001, m = 0.9
I0916 14:34:57.684811 19008 data_reader.cpp:305] Starting prefetch of epoch 40
I0916 14:35:16.283287 19004 solver.cpp:314] Iteration 78100 (4.93444 iter/s, 20.2657s/100 iter), loss = 0.0523888
I0916 14:35:16.283344 19004 solver.cpp:336]     Train net output #0: loss = 0.0523885 (* 1 = 0.0523885 loss)
I0916 14:35:16.283351 19004 sgd_solver.cpp:136] Iteration 78100, lr = 0.001, m = 0.9
I0916 14:35:36.592572 19004 solver.cpp:314] Iteration 78200 (4.924 iter/s, 20.3087s/100 iter), loss = 0.044469
I0916 14:35:36.592600 19004 solver.cpp:336]     Train net output #0: loss = 0.0444687 (* 1 = 0.0444687 loss)
I0916 14:35:36.592607 19004 sgd_solver.cpp:136] Iteration 78200, lr = 0.001, m = 0.9
I0916 14:35:57.125718 19004 solver.cpp:314] Iteration 78300 (4.87031 iter/s, 20.5326s/100 iter), loss = 0.0636641
I0916 14:35:57.125797 19004 solver.cpp:336]     Train net output #0: loss = 0.0636638 (* 1 = 0.0636638 loss)
I0916 14:35:57.125804 19004 sgd_solver.cpp:136] Iteration 78300, lr = 0.001, m = 0.9
I0916 14:36:04.907891 19010 data_reader.cpp:305] Starting prefetch of epoch 49
I0916 14:36:17.504446 19004 solver.cpp:314] Iteration 78400 (4.90722 iter/s, 20.3782s/100 iter), loss = 0.0667096
I0916 14:36:17.504472 19004 solver.cpp:336]     Train net output #0: loss = 0.0667093 (* 1 = 0.0667093 loss)
I0916 14:36:17.504477 19004 sgd_solver.cpp:136] Iteration 78400, lr = 0.001, m = 0.9
I0916 14:36:37.387259 19004 solver.cpp:314] Iteration 78500 (5.02961 iter/s, 19.8822s/100 iter), loss = 0.0629315
I0916 14:36:37.387343 19004 solver.cpp:336]     Train net output #0: loss = 0.0629312 (* 1 = 0.0629312 loss)
I0916 14:36:37.387351 19004 sgd_solver.cpp:136] Iteration 78500, lr = 0.001, m = 0.9
I0916 14:36:38.025990 18961 data_reader.cpp:305] Starting prefetch of epoch 41
I0916 14:36:57.803829 19004 solver.cpp:314] Iteration 78600 (4.89812 iter/s, 20.416s/100 iter), loss = 0.0447296
I0916 14:36:57.804057 19004 solver.cpp:336]     Train net output #0: loss = 0.0447293 (* 1 = 0.0447293 loss)
I0916 14:36:57.804090 19004 sgd_solver.cpp:136] Iteration 78600, lr = 0.001, m = 0.9
I0916 14:37:18.195940 19004 solver.cpp:314] Iteration 78700 (4.904 iter/s, 20.3915s/100 iter), loss = 0.0467773
I0916 14:37:18.196048 19004 solver.cpp:336]     Train net output #0: loss = 0.046777 (* 1 = 0.046777 loss)
I0916 14:37:18.196056 19004 sgd_solver.cpp:136] Iteration 78700, lr = 0.001, m = 0.9
I0916 14:37:38.391559 19004 solver.cpp:314] Iteration 78800 (4.95171 iter/s, 20.1951s/100 iter), loss = 0.0510085
I0916 14:37:38.391585 19004 solver.cpp:336]     Train net output #0: loss = 0.0510082 (* 1 = 0.0510082 loss)
I0916 14:37:38.391592 19004 sgd_solver.cpp:136] Iteration 78800, lr = 0.001, m = 0.9
I0916 14:37:45.235107 19010 data_reader.cpp:305] Starting prefetch of epoch 50
I0916 14:37:58.393780 19004 solver.cpp:314] Iteration 78900 (4.99959 iter/s, 20.0017s/100 iter), loss = 0.0751333
I0916 14:37:58.393836 19004 solver.cpp:336]     Train net output #0: loss = 0.075133 (* 1 = 0.075133 loss)
I0916 14:37:58.393841 19004 sgd_solver.cpp:136] Iteration 78900, lr = 0.001, m = 0.9
I0916 14:38:18.598143 19004 solver.cpp:314] Iteration 79000 (4.94957 iter/s, 20.2038s/100 iter), loss = 0.049918
I0916 14:38:18.598163 19004 solver.cpp:336]     Train net output #0: loss = 0.0499177 (* 1 = 0.0499177 loss)
I0916 14:38:18.598167 19004 sgd_solver.cpp:136] Iteration 79000, lr = 0.001, m = 0.9
I0916 14:38:39.001637 19004 solver.cpp:314] Iteration 79100 (4.90126 iter/s, 20.4029s/100 iter), loss = 0.0524508
I0916 14:38:39.001706 19004 solver.cpp:336]     Train net output #0: loss = 0.0524505 (* 1 = 0.0524505 loss)
I0916 14:38:39.001714 19004 sgd_solver.cpp:136] Iteration 79100, lr = 0.001, m = 0.9
I0916 14:38:52.602792 19012 data_reader.cpp:305] Starting prefetch of epoch 46
I0916 14:38:59.436486 19004 solver.cpp:314] Iteration 79200 (4.89374 iter/s, 20.4343s/100 iter), loss = 0.0650171
I0916 14:38:59.436511 19004 solver.cpp:336]     Train net output #0: loss = 0.0650168 (* 1 = 0.0650168 loss)
I0916 14:38:59.436516 19004 sgd_solver.cpp:136] Iteration 79200, lr = 0.001, m = 0.9
I0916 14:39:19.085898 19004 solver.cpp:314] Iteration 79300 (5.08936 iter/s, 19.6489s/100 iter), loss = 0.0408494
I0916 14:39:19.086691 19004 solver.cpp:336]     Train net output #0: loss = 0.0408491 (* 1 = 0.0408491 loss)
I0916 14:39:19.086712 19004 sgd_solver.cpp:136] Iteration 79300, lr = 0.001, m = 0.9
I0916 14:39:25.259724 19008 data_reader.cpp:305] Starting prefetch of epoch 41
I0916 14:39:39.498489 19004 solver.cpp:314] Iteration 79400 (4.89907 iter/s, 20.412s/100 iter), loss = 0.0601234
I0916 14:39:39.498517 19004 solver.cpp:336]     Train net output #0: loss = 0.0601231 (* 1 = 0.0601231 loss)
I0916 14:39:39.498520 19004 sgd_solver.cpp:136] Iteration 79400, lr = 0.001, m = 0.9
I0916 14:39:59.794498 19004 solver.cpp:314] Iteration 79500 (4.92722 iter/s, 20.2954s/100 iter), loss = 0.0345484
I0916 14:39:59.794548 19004 solver.cpp:336]     Train net output #0: loss = 0.034548 (* 1 = 0.034548 loss)
I0916 14:39:59.794555 19004 sgd_solver.cpp:136] Iteration 79500, lr = 0.001, m = 0.9
I0916 14:40:19.836490 19004 solver.cpp:314] Iteration 79600 (4.98967 iter/s, 20.0414s/100 iter), loss = 0.0516102
I0916 14:40:19.836524 19004 solver.cpp:336]     Train net output #0: loss = 0.0516099 (* 1 = 0.0516099 loss)
I0916 14:40:19.836532 19004 sgd_solver.cpp:136] Iteration 79600, lr = 0.001, m = 0.9
I0916 14:40:31.756480 19010 data_reader.cpp:305] Starting prefetch of epoch 51
I0916 14:40:39.678614 19004 solver.cpp:314] Iteration 79700 (5.03992 iter/s, 19.8416s/100 iter), loss = 0.0788788
I0916 14:40:39.678638 19004 solver.cpp:336]     Train net output #0: loss = 0.0788785 (* 1 = 0.0788785 loss)
I0916 14:40:39.678643 19004 sgd_solver.cpp:136] Iteration 79700, lr = 0.001, m = 0.9
I0916 14:41:00.127063 19004 solver.cpp:314] Iteration 79800 (4.89048 iter/s, 20.4479s/100 iter), loss = 0.0451689
I0916 14:41:00.127084 19004 solver.cpp:336]     Train net output #0: loss = 0.0451686 (* 1 = 0.0451686 loss)
I0916 14:41:00.127087 19004 sgd_solver.cpp:136] Iteration 79800, lr = 0.001, m = 0.9
I0916 14:41:20.366150 19004 solver.cpp:314] Iteration 79900 (4.94107 iter/s, 20.2385s/100 iter), loss = 0.0633934
I0916 14:41:20.366251 19004 solver.cpp:336]     Train net output #0: loss = 0.063393 (* 1 = 0.063393 loss)
I0916 14:41:20.366259 19004 sgd_solver.cpp:136] Iteration 79900, lr = 0.001, m = 0.9
I0916 14:41:38.400797 19012 data_reader.cpp:305] Starting prefetch of epoch 47
I0916 14:41:39.959260 19004 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/cityscapes5_jsegnet21v2_iter_80000.caffemodel
I0916 14:41:40.018858 19004 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/cityscapes5_jsegnet21v2_iter_80000.solverstate
I0916 14:41:40.024238 19004 solver.cpp:563] Iteration 80000, Testing net (#0)
I0916 14:41:43.631963 19018 data_reader.cpp:305] Starting prefetch of epoch 10
I0916 14:41:51.870851 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.954466
I0916 14:41:51.870957 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 14:41:51.870966 19004 solver.cpp:655]     Test net output #2: loss = 0.154003 (* 1 = 0.154003 loss)
I0916 14:41:51.870991 19004 solver.cpp:265] [MultiGPU] Tests completed in 11.8464s
I0916 14:41:52.077584 19004 solver.cpp:314] Iteration 80000 (3.15353 iter/s, 31.7105s/100 iter), loss = 0.0657267
I0916 14:41:52.077606 19004 solver.cpp:336]     Train net output #0: loss = 0.0657263 (* 1 = 0.0657263 loss)
I0916 14:41:52.077611 19004 sgd_solver.cpp:136] Iteration 80000, lr = 0.001, m = 0.9
I0916 14:42:11.928174 19004 solver.cpp:314] Iteration 80100 (5.03778 iter/s, 19.85s/100 iter), loss = 0.0459191
I0916 14:42:11.928201 19004 solver.cpp:336]     Train net output #0: loss = 0.0459187 (* 1 = 0.0459187 loss)
I0916 14:42:11.928208 19004 sgd_solver.cpp:136] Iteration 80100, lr = 0.001, m = 0.9
I0916 14:42:23.255401 18963 data_reader.cpp:305] Starting prefetch of epoch 56
I0916 14:42:32.037564 19004 solver.cpp:314] Iteration 80200 (4.97294 iter/s, 20.1088s/100 iter), loss = 0.0682207
I0916 14:42:32.037632 19004 solver.cpp:336]     Train net output #0: loss = 0.0682203 (* 1 = 0.0682203 loss)
I0916 14:42:32.037639 19004 sgd_solver.cpp:136] Iteration 80200, lr = 0.001, m = 0.9
I0916 14:42:51.826248 19004 solver.cpp:314] Iteration 80300 (5.05353 iter/s, 19.7881s/100 iter), loss = 0.0529686
I0916 14:42:51.826277 19004 solver.cpp:336]     Train net output #0: loss = 0.0529683 (* 1 = 0.0529683 loss)
I0916 14:42:51.826283 19004 sgd_solver.cpp:136] Iteration 80300, lr = 0.001, m = 0.9
I0916 14:43:11.804894 19004 solver.cpp:314] Iteration 80400 (5.00549 iter/s, 19.9781s/100 iter), loss = 0.0612969
I0916 14:43:11.818249 19004 solver.cpp:336]     Train net output #0: loss = 0.0612965 (* 1 = 0.0612965 loss)
I0916 14:43:11.818316 19004 sgd_solver.cpp:136] Iteration 80400, lr = 0.001, m = 0.9
I0916 14:43:29.890288 18963 data_reader.cpp:305] Starting prefetch of epoch 57
I0916 14:43:32.583539 19004 solver.cpp:314] Iteration 80500 (4.81277 iter/s, 20.7781s/100 iter), loss = 0.0715782
I0916 14:43:32.583564 19004 solver.cpp:336]     Train net output #0: loss = 0.0715779 (* 1 = 0.0715779 loss)
I0916 14:43:32.583567 19004 sgd_solver.cpp:136] Iteration 80500, lr = 0.001, m = 0.9
I0916 14:43:52.678560 19004 solver.cpp:314] Iteration 80600 (4.9765 iter/s, 20.0945s/100 iter), loss = 0.0490821
I0916 14:43:52.690222 19004 solver.cpp:336]     Train net output #0: loss = 0.0490817 (* 1 = 0.0490817 loss)
I0916 14:43:52.690253 19004 sgd_solver.cpp:136] Iteration 80600, lr = 0.001, m = 0.9
I0916 14:44:03.196626 18961 data_reader.cpp:305] Starting prefetch of epoch 42
I0916 14:44:13.052233 19004 solver.cpp:314] Iteration 80700 (4.90843 iter/s, 20.3731s/100 iter), loss = 0.0552995
I0916 14:44:13.052258 19004 solver.cpp:336]     Train net output #0: loss = 0.0552991 (* 1 = 0.0552991 loss)
I0916 14:44:13.052263 19004 sgd_solver.cpp:136] Iteration 80700, lr = 0.001, m = 0.9
I0916 14:44:33.872817 19004 solver.cpp:314] Iteration 80800 (4.80307 iter/s, 20.82s/100 iter), loss = 0.0719623
I0916 14:44:33.872881 19004 solver.cpp:336]     Train net output #0: loss = 0.071962 (* 1 = 0.071962 loss)
I0916 14:44:33.872886 19004 sgd_solver.cpp:136] Iteration 80800, lr = 0.001, m = 0.9
I0916 14:44:54.760263 19004 solver.cpp:314] Iteration 80900 (4.7877 iter/s, 20.8869s/100 iter), loss = 0.0611447
I0916 14:44:54.760293 19004 solver.cpp:336]     Train net output #0: loss = 0.0611444 (* 1 = 0.0611444 loss)
I0916 14:44:54.760298 19004 sgd_solver.cpp:136] Iteration 80900, lr = 0.001, m = 0.9
I0916 14:45:11.389515 19008 data_reader.cpp:305] Starting prefetch of epoch 42
I0916 14:45:14.778915 19004 solver.cpp:314] Iteration 81000 (4.99548 iter/s, 20.0181s/100 iter), loss = 0.0553164
I0916 14:45:14.778942 19004 solver.cpp:336]     Train net output #0: loss = 0.055316 (* 1 = 0.055316 loss)
I0916 14:45:14.778949 19004 sgd_solver.cpp:136] Iteration 81000, lr = 0.001, m = 0.9
I0916 14:45:35.461820 19004 solver.cpp:314] Iteration 81100 (4.83505 iter/s, 20.6823s/100 iter), loss = 0.0710713
I0916 14:45:35.461841 19004 solver.cpp:336]     Train net output #0: loss = 0.071071 (* 1 = 0.071071 loss)
I0916 14:45:35.461846 19004 sgd_solver.cpp:136] Iteration 81100, lr = 0.001, m = 0.9
I0916 14:45:56.151032 19004 solver.cpp:314] Iteration 81200 (4.83357 iter/s, 20.6886s/100 iter), loss = 0.0535561
I0916 14:45:56.151087 19004 solver.cpp:336]     Train net output #0: loss = 0.0535557 (* 1 = 0.0535557 loss)
I0916 14:45:56.151094 19004 sgd_solver.cpp:136] Iteration 81200, lr = 0.001, m = 0.9
I0916 14:46:16.820572 19004 solver.cpp:314] Iteration 81300 (4.83817 iter/s, 20.669s/100 iter), loss = 0.0808
I0916 14:46:16.820597 19004 solver.cpp:336]     Train net output #0: loss = 0.0807996 (* 1 = 0.0807996 loss)
I0916 14:46:16.820603 19004 sgd_solver.cpp:136] Iteration 81300, lr = 0.001, m = 0.9
I0916 14:46:19.474956 19012 data_reader.cpp:305] Starting prefetch of epoch 48
I0916 14:46:37.243880 19004 solver.cpp:314] Iteration 81400 (4.8965 iter/s, 20.4227s/100 iter), loss = 0.0570162
I0916 14:46:37.243930 19004 solver.cpp:336]     Train net output #0: loss = 0.0570159 (* 1 = 0.0570159 loss)
I0916 14:46:37.243935 19004 sgd_solver.cpp:136] Iteration 81400, lr = 0.001, m = 0.9
I0916 14:46:53.608721 19007 data_reader.cpp:305] Starting prefetch of epoch 58
I0916 14:46:58.172281 19004 solver.cpp:314] Iteration 81500 (4.77833 iter/s, 20.9278s/100 iter), loss = 0.0530155
I0916 14:46:58.172344 19004 solver.cpp:336]     Train net output #0: loss = 0.0530151 (* 1 = 0.0530151 loss)
I0916 14:46:58.172361 19004 sgd_solver.cpp:136] Iteration 81500, lr = 0.001, m = 0.9
I0916 14:47:18.762538 19004 solver.cpp:314] Iteration 81600 (4.8568 iter/s, 20.5897s/100 iter), loss = 0.0389971
I0916 14:47:18.762658 19004 solver.cpp:336]     Train net output #0: loss = 0.0389967 (* 1 = 0.0389967 loss)
I0916 14:47:18.762665 19004 sgd_solver.cpp:136] Iteration 81600, lr = 0.001, m = 0.9
I0916 14:47:38.863692 19004 solver.cpp:314] Iteration 81700 (4.97498 iter/s, 20.1006s/100 iter), loss = 0.0506632
I0916 14:47:38.863723 19004 solver.cpp:336]     Train net output #0: loss = 0.0506629 (* 1 = 0.0506629 loss)
I0916 14:47:38.863729 19004 sgd_solver.cpp:136] Iteration 81700, lr = 0.001, m = 0.9
I0916 14:47:59.420925 19004 solver.cpp:314] Iteration 81800 (4.86461 iter/s, 20.5566s/100 iter), loss = 0.0401012
I0916 14:47:59.421001 19004 solver.cpp:336]     Train net output #0: loss = 0.0401008 (* 1 = 0.0401008 loss)
I0916 14:47:59.421027 19004 sgd_solver.cpp:136] Iteration 81800, lr = 0.001, m = 0.9
I0916 14:48:01.328692 18963 data_reader.cpp:305] Starting prefetch of epoch 58
I0916 14:48:20.099620 19004 solver.cpp:314] Iteration 81900 (4.83603 iter/s, 20.6781s/100 iter), loss = 0.0565727
I0916 14:48:20.099648 19004 solver.cpp:336]     Train net output #0: loss = 0.0565723 (* 1 = 0.0565723 loss)
I0916 14:48:20.099653 19004 sgd_solver.cpp:136] Iteration 81900, lr = 0.001, m = 0.9
I0916 14:48:39.786509 19004 solver.cpp:563] Iteration 82000, Testing net (#0)
I0916 14:48:47.587060 19018 data_reader.cpp:305] Starting prefetch of epoch 11
I0916 14:48:52.890324 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.956067
I0916 14:48:52.890367 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.999818
I0916 14:48:52.890378 19004 solver.cpp:655]     Test net output #2: loss = 0.186419 (* 1 = 0.186419 loss)
I0916 14:48:52.890441 19004 solver.cpp:265] [MultiGPU] Tests completed in 13.1036s
I0916 14:48:53.114614 19004 solver.cpp:314] Iteration 82000 (3.02901 iter/s, 33.0141s/100 iter), loss = 0.0574703
I0916 14:48:53.114637 19004 solver.cpp:336]     Train net output #0: loss = 0.0574699 (* 1 = 0.0574699 loss)
I0916 14:48:53.114644 19004 sgd_solver.cpp:136] Iteration 82000, lr = 0.001, m = 0.9
I0916 14:49:13.963281 19004 solver.cpp:314] Iteration 82100 (4.7966 iter/s, 20.8481s/100 iter), loss = 0.0386621
I0916 14:49:13.963346 19004 solver.cpp:336]     Train net output #0: loss = 0.0386618 (* 1 = 0.0386618 loss)
I0916 14:49:13.963352 19004 sgd_solver.cpp:136] Iteration 82100, lr = 0.001, m = 0.9
I0916 14:49:22.426666 18963 data_reader.cpp:305] Starting prefetch of epoch 59
I0916 14:49:34.802284 19004 solver.cpp:314] Iteration 82200 (4.79883 iter/s, 20.8384s/100 iter), loss = 0.0712581
I0916 14:49:34.802307 19004 solver.cpp:336]     Train net output #0: loss = 0.0712577 (* 1 = 0.0712577 loss)
I0916 14:49:34.802314 19004 sgd_solver.cpp:136] Iteration 82200, lr = 0.001, m = 0.9
I0916 14:49:54.999243 19004 solver.cpp:314] Iteration 82300 (4.95138 iter/s, 20.1964s/100 iter), loss = 0.037005
I0916 14:49:54.999328 19004 solver.cpp:336]     Train net output #0: loss = 0.0370046 (* 1 = 0.0370046 loss)
I0916 14:49:54.999354 19004 sgd_solver.cpp:136] Iteration 82300, lr = 0.001, m = 0.9
I0916 14:50:15.421635 19004 solver.cpp:314] Iteration 82400 (4.89672 iter/s, 20.4218s/100 iter), loss = 0.0567024
I0916 14:50:15.421660 19004 solver.cpp:336]     Train net output #0: loss = 0.056702 (* 1 = 0.056702 loss)
I0916 14:50:15.421664 19004 sgd_solver.cpp:136] Iteration 82400, lr = 0.001, m = 0.9
I0916 14:50:29.862200 18963 data_reader.cpp:305] Starting prefetch of epoch 60
I0916 14:50:36.228242 19004 solver.cpp:314] Iteration 82500 (4.8063 iter/s, 20.806s/100 iter), loss = 0.0773681
I0916 14:50:36.228266 19004 solver.cpp:336]     Train net output #0: loss = 0.0773677 (* 1 = 0.0773677 loss)
I0916 14:50:36.228271 19004 sgd_solver.cpp:136] Iteration 82500, lr = 0.001, m = 0.9
I0916 14:50:56.960464 19004 solver.cpp:314] Iteration 82600 (4.82355 iter/s, 20.7316s/100 iter), loss = 0.0523282
I0916 14:50:56.960491 19004 solver.cpp:336]     Train net output #0: loss = 0.0523278 (* 1 = 0.0523278 loss)
I0916 14:50:56.960499 19004 sgd_solver.cpp:136] Iteration 82600, lr = 0.001, m = 0.9
I0916 14:51:17.201923 19004 solver.cpp:314] Iteration 82700 (4.94049 iter/s, 20.2409s/100 iter), loss = 0.0451533
I0916 14:51:17.202009 19004 solver.cpp:336]     Train net output #0: loss = 0.045153 (* 1 = 0.045153 loss)
I0916 14:51:17.202016 19004 sgd_solver.cpp:136] Iteration 82700, lr = 0.001, m = 0.9
I0916 14:51:37.315619 19004 solver.cpp:314] Iteration 82800 (4.97188 iter/s, 20.1131s/100 iter), loss = 0.0303113
I0916 14:51:37.315652 19004 solver.cpp:336]     Train net output #0: loss = 0.0303109 (* 1 = 0.0303109 loss)
I0916 14:51:37.315659 19004 sgd_solver.cpp:136] Iteration 82800, lr = 0.001, m = 0.9
I0916 14:51:37.533987 19012 data_reader.cpp:305] Starting prefetch of epoch 49
I0916 14:51:57.968317 19004 solver.cpp:314] Iteration 82900 (4.84212 iter/s, 20.6521s/100 iter), loss = 0.0504551
I0916 14:51:57.968381 19004 solver.cpp:336]     Train net output #0: loss = 0.0504548 (* 1 = 0.0504548 loss)
I0916 14:51:57.968389 19004 sgd_solver.cpp:136] Iteration 82900, lr = 0.001, m = 0.9
I0916 14:52:11.505640 19007 data_reader.cpp:305] Starting prefetch of epoch 59
I0916 14:52:18.392587 19004 solver.cpp:314] Iteration 83000 (4.89627 iter/s, 20.4237s/100 iter), loss = 0.0746884
I0916 14:52:18.392611 19004 solver.cpp:336]     Train net output #0: loss = 0.0746881 (* 1 = 0.0746881 loss)
I0916 14:52:18.392614 19004 sgd_solver.cpp:136] Iteration 83000, lr = 0.001, m = 0.9
I0916 14:52:38.279108 19004 solver.cpp:314] Iteration 83100 (5.02868 iter/s, 19.886s/100 iter), loss = 0.0348668
I0916 14:52:38.279224 19004 solver.cpp:336]     Train net output #0: loss = 0.0348665 (* 1 = 0.0348665 loss)
I0916 14:52:38.279242 19004 sgd_solver.cpp:136] Iteration 83100, lr = 0.001, m = 0.9
I0916 14:52:58.731695 19004 solver.cpp:314] Iteration 83200 (4.88949 iter/s, 20.452s/100 iter), loss = 0.0551304
I0916 14:52:58.731747 19004 solver.cpp:336]     Train net output #0: loss = 0.0551301 (* 1 = 0.0551301 loss)
I0916 14:52:58.731765 19004 sgd_solver.cpp:136] Iteration 83200, lr = 0.001, m = 0.9
I0916 14:53:18.566242 18963 data_reader.cpp:305] Starting prefetch of epoch 61
I0916 14:53:19.367352 19004 solver.cpp:314] Iteration 83300 (4.84612 iter/s, 20.6351s/100 iter), loss = 0.0609766
I0916 14:53:19.367378 19004 solver.cpp:336]     Train net output #0: loss = 0.0609763 (* 1 = 0.0609763 loss)
I0916 14:53:19.367384 19004 sgd_solver.cpp:136] Iteration 83300, lr = 0.001, m = 0.9
I0916 14:53:39.396901 19004 solver.cpp:314] Iteration 83400 (4.99276 iter/s, 20.029s/100 iter), loss = 0.0513229
I0916 14:53:39.396925 19004 solver.cpp:336]     Train net output #0: loss = 0.0513225 (* 1 = 0.0513225 loss)
I0916 14:53:39.396929 19004 sgd_solver.cpp:136] Iteration 83400, lr = 0.001, m = 0.9
I0916 14:54:00.006252 19004 solver.cpp:314] Iteration 83500 (4.8523 iter/s, 20.6088s/100 iter), loss = 0.0806886
I0916 14:54:00.018143 19004 solver.cpp:336]     Train net output #0: loss = 0.0806883 (* 1 = 0.0806883 loss)
I0916 14:54:00.018167 19004 sgd_solver.cpp:136] Iteration 83500, lr = 0.001, m = 0.9
I0916 14:54:20.585911 19004 solver.cpp:314] Iteration 83600 (4.8593 iter/s, 20.5791s/100 iter), loss = 0.0491894
I0916 14:54:20.585933 19004 solver.cpp:336]     Train net output #0: loss = 0.0491891 (* 1 = 0.0491891 loss)
I0916 14:54:20.585937 19004 sgd_solver.cpp:136] Iteration 83600, lr = 0.001, m = 0.9
I0916 14:54:26.057430 19012 data_reader.cpp:305] Starting prefetch of epoch 50
I0916 14:54:40.760262 19004 solver.cpp:314] Iteration 83700 (4.95693 iter/s, 20.1738s/100 iter), loss = 0.0525369
I0916 14:54:40.760316 19004 solver.cpp:336]     Train net output #0: loss = 0.0525365 (* 1 = 0.0525365 loss)
I0916 14:54:40.760321 19004 sgd_solver.cpp:136] Iteration 83700, lr = 0.001, m = 0.9
I0916 14:54:59.373518 19008 data_reader.cpp:305] Starting prefetch of epoch 43
I0916 14:55:00.905412 19004 solver.cpp:314] Iteration 83800 (4.96411 iter/s, 20.1446s/100 iter), loss = 0.0476682
I0916 14:55:00.905436 19004 solver.cpp:336]     Train net output #0: loss = 0.0476678 (* 1 = 0.0476678 loss)
I0916 14:55:00.905441 19004 sgd_solver.cpp:136] Iteration 83800, lr = 0.001, m = 0.9
I0916 14:55:21.349936 19004 solver.cpp:314] Iteration 83900 (4.89142 iter/s, 20.444s/100 iter), loss = 0.0568545
I0916 14:55:21.349989 19004 solver.cpp:336]     Train net output #0: loss = 0.0568541 (* 1 = 0.0568541 loss)
I0916 14:55:21.349997 19004 sgd_solver.cpp:136] Iteration 83900, lr = 0.001, m = 0.9
I0916 14:55:42.042919 19004 solver.cpp:563] Iteration 84000, Testing net (#0)
I0916 14:55:45.739137 19018 data_reader.cpp:305] Starting prefetch of epoch 12
I0916 14:55:53.722642 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.957021
I0916 14:55:53.722735 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 14:55:53.722743 19004 solver.cpp:655]     Test net output #2: loss = 0.143873 (* 1 = 0.143873 loss)
I0916 14:55:53.722772 19004 solver.cpp:265] [MultiGPU] Tests completed in 11.6795s
I0916 14:55:53.949126 19004 solver.cpp:314] Iteration 84000 (3.06765 iter/s, 32.5983s/100 iter), loss = 0.0447548
I0916 14:55:53.949182 19004 solver.cpp:336]     Train net output #0: loss = 0.0447545 (* 1 = 0.0447545 loss)
I0916 14:55:53.949198 19004 sgd_solver.cpp:136] Iteration 84000, lr = 0.001, m = 0.9
I0916 14:56:13.838369 19004 solver.cpp:314] Iteration 84100 (5.02799 iter/s, 19.8887s/100 iter), loss = 0.0623144
I0916 14:56:13.838399 19004 solver.cpp:336]     Train net output #0: loss = 0.0623141 (* 1 = 0.0623141 loss)
I0916 14:56:13.838405 19004 sgd_solver.cpp:136] Iteration 84100, lr = 0.001, m = 0.9
I0916 14:56:18.514794 19012 data_reader.cpp:305] Starting prefetch of epoch 51
I0916 14:56:34.147454 19004 solver.cpp:314] Iteration 84200 (4.92405 iter/s, 20.3085s/100 iter), loss = 0.0413948
I0916 14:56:34.147598 19004 solver.cpp:336]     Train net output #0: loss = 0.0413945 (* 1 = 0.0413945 loss)
I0916 14:56:34.147620 19004 sgd_solver.cpp:136] Iteration 84200, lr = 0.001, m = 0.9
I0916 14:56:51.791216 18961 data_reader.cpp:305] Starting prefetch of epoch 43
I0916 14:56:54.300626 19004 solver.cpp:314] Iteration 84300 (4.96214 iter/s, 20.1526s/100 iter), loss = 0.0545784
I0916 14:56:54.300647 19004 solver.cpp:336]     Train net output #0: loss = 0.0545781 (* 1 = 0.0545781 loss)
I0916 14:56:54.300650 19004 sgd_solver.cpp:136] Iteration 84300, lr = 0.001, m = 0.9
I0916 14:57:14.186132 19004 solver.cpp:314] Iteration 84400 (5.02893 iter/s, 19.8849s/100 iter), loss = 0.0521858
I0916 14:57:14.186219 19004 solver.cpp:336]     Train net output #0: loss = 0.0521855 (* 1 = 0.0521855 loss)
I0916 14:57:14.186228 19004 sgd_solver.cpp:136] Iteration 84400, lr = 0.001, m = 0.9
I0916 14:57:34.111155 19004 solver.cpp:314] Iteration 84500 (5.01896 iter/s, 19.9245s/100 iter), loss = 0.051887
I0916 14:57:34.111196 19004 solver.cpp:336]     Train net output #0: loss = 0.0518867 (* 1 = 0.0518867 loss)
I0916 14:57:34.111205 19004 sgd_solver.cpp:136] Iteration 84500, lr = 0.001, m = 0.9
I0916 14:57:54.288239 19004 solver.cpp:314] Iteration 84600 (4.95626 iter/s, 20.1765s/100 iter), loss = 0.0578856
I0916 14:57:54.288287 19004 solver.cpp:336]     Train net output #0: loss = 0.0578853 (* 1 = 0.0578853 loss)
I0916 14:57:54.288293 19004 sgd_solver.cpp:136] Iteration 84600, lr = 0.001, m = 0.9
I0916 14:57:58.044899 18963 data_reader.cpp:305] Starting prefetch of epoch 62
I0916 14:58:14.140259 19004 solver.cpp:314] Iteration 84700 (5.03741 iter/s, 19.8515s/100 iter), loss = 0.0727239
I0916 14:58:14.140280 19004 solver.cpp:336]     Train net output #0: loss = 0.0727235 (* 1 = 0.0727235 loss)
I0916 14:58:14.140285 19004 sgd_solver.cpp:136] Iteration 84700, lr = 0.001, m = 0.9
I0916 14:58:34.142055 19004 solver.cpp:314] Iteration 84800 (4.99969 iter/s, 20.0012s/100 iter), loss = 0.0499166
I0916 14:58:34.142110 19004 solver.cpp:336]     Train net output #0: loss = 0.0499163 (* 1 = 0.0499163 loss)
I0916 14:58:34.142115 19004 sgd_solver.cpp:136] Iteration 84800, lr = 0.001, m = 0.9
I0916 14:58:54.126302 19004 solver.cpp:314] Iteration 84900 (5.00408 iter/s, 19.9837s/100 iter), loss = 0.0727825
I0916 14:58:54.126324 19004 solver.cpp:336]     Train net output #0: loss = 0.0727821 (* 1 = 0.0727821 loss)
I0916 14:58:54.126330 19004 sgd_solver.cpp:136] Iteration 84900, lr = 0.001, m = 0.9
I0916 14:59:04.275064 19012 data_reader.cpp:305] Starting prefetch of epoch 52
I0916 14:59:14.349285 19004 solver.cpp:314] Iteration 85000 (4.94501 iter/s, 20.2224s/100 iter), loss = 0.0457745
I0916 14:59:14.349310 19004 solver.cpp:336]     Train net output #0: loss = 0.0457742 (* 1 = 0.0457742 loss)
I0916 14:59:14.349314 19004 sgd_solver.cpp:136] Iteration 85000, lr = 0.001, m = 0.9
I0916 14:59:34.250082 19004 solver.cpp:314] Iteration 85100 (5.02507 iter/s, 19.9002s/100 iter), loss = 0.0602225
I0916 14:59:34.250109 19004 solver.cpp:336]     Train net output #0: loss = 0.0602221 (* 1 = 0.0602221 loss)
I0916 14:59:34.250116 19004 sgd_solver.cpp:136] Iteration 85100, lr = 0.001, m = 0.9
I0916 14:59:37.209053 18961 data_reader.cpp:305] Starting prefetch of epoch 44
I0916 14:59:54.176810 19004 solver.cpp:314] Iteration 85200 (5.01853 iter/s, 19.9262s/100 iter), loss = 0.041309
I0916 14:59:54.176831 19004 solver.cpp:336]     Train net output #0: loss = 0.0413087 (* 1 = 0.0413087 loss)
I0916 14:59:54.176836 19004 sgd_solver.cpp:136] Iteration 85200, lr = 0.001, m = 0.9
I0916 15:00:14.804720 19004 solver.cpp:314] Iteration 85300 (4.84794 iter/s, 20.6273s/100 iter), loss = 0.0548203
I0916 15:00:14.804819 19004 solver.cpp:336]     Train net output #0: loss = 0.05482 (* 1 = 0.05482 loss)
I0916 15:00:14.804826 19004 sgd_solver.cpp:136] Iteration 85300, lr = 0.001, m = 0.9
I0916 15:00:35.201439 19004 solver.cpp:314] Iteration 85400 (4.90289 iter/s, 20.3961s/100 iter), loss = 0.0557604
I0916 15:00:35.201462 19004 solver.cpp:336]     Train net output #0: loss = 0.05576 (* 1 = 0.05576 loss)
I0916 15:00:35.201468 19004 sgd_solver.cpp:136] Iteration 85400, lr = 0.001, m = 0.9
I0916 15:00:44.165807 19012 data_reader.cpp:305] Starting prefetch of epoch 53
I0916 15:00:55.246883 19004 solver.cpp:314] Iteration 85500 (4.9888 iter/s, 20.0449s/100 iter), loss = 0.0697384
I0916 15:00:55.246950 19004 solver.cpp:336]     Train net output #0: loss = 0.069738 (* 1 = 0.069738 loss)
I0916 15:00:55.246958 19004 sgd_solver.cpp:136] Iteration 85500, lr = 0.001, m = 0.9
I0916 15:01:14.849231 19004 solver.cpp:314] Iteration 85600 (5.10157 iter/s, 19.6018s/100 iter), loss = 0.0457251
I0916 15:01:14.849256 19004 solver.cpp:336]     Train net output #0: loss = 0.0457247 (* 1 = 0.0457247 loss)
I0916 15:01:14.849262 19004 sgd_solver.cpp:136] Iteration 85600, lr = 0.001, m = 0.9
I0916 15:01:34.185683 19004 solver.cpp:314] Iteration 85700 (5.17172 iter/s, 19.3359s/100 iter), loss = 0.0458312
I0916 15:01:34.185766 19004 solver.cpp:336]     Train net output #0: loss = 0.0458309 (* 1 = 0.0458309 loss)
I0916 15:01:34.185783 19004 sgd_solver.cpp:136] Iteration 85700, lr = 0.001, m = 0.9
I0916 15:01:49.128286 18961 data_reader.cpp:305] Starting prefetch of epoch 45
I0916 15:01:53.713196 19004 solver.cpp:314] Iteration 85800 (5.12112 iter/s, 19.527s/100 iter), loss = 0.0497608
I0916 15:01:53.713222 19004 solver.cpp:336]     Train net output #0: loss = 0.0497604 (* 1 = 0.0497604 loss)
I0916 15:01:53.713227 19004 sgd_solver.cpp:136] Iteration 85800, lr = 0.001, m = 0.9
I0916 15:02:13.059690 19004 solver.cpp:314] Iteration 85900 (5.16904 iter/s, 19.3459s/100 iter), loss = 0.0573731
I0916 15:02:13.059768 19004 solver.cpp:336]     Train net output #0: loss = 0.0573727 (* 1 = 0.0573727 loss)
I0916 15:02:13.059775 19004 sgd_solver.cpp:136] Iteration 85900, lr = 0.001, m = 0.9
I0916 15:02:21.015919 19007 data_reader.cpp:305] Starting prefetch of epoch 60
I0916 15:02:32.417848 19004 solver.cpp:563] Iteration 86000, Testing net (#0)
I0916 15:02:43.405050 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.956694
I0916 15:02:43.405148 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.999765
I0916 15:02:43.405156 19004 solver.cpp:655]     Test net output #2: loss = 0.187908 (* 1 = 0.187908 loss)
I0916 15:02:43.405182 19004 solver.cpp:265] [MultiGPU] Tests completed in 10.987s
I0916 15:02:43.610368 19004 solver.cpp:314] Iteration 86000 (3.27334 iter/s, 30.5498s/100 iter), loss = 0.0540312
I0916 15:02:43.610391 19004 solver.cpp:336]     Train net output #0: loss = 0.0540309 (* 1 = 0.0540309 loss)
I0916 15:02:43.610397 19004 sgd_solver.cpp:136] Iteration 86000, lr = 0.001, m = 0.9
I0916 15:03:03.024134 19004 solver.cpp:314] Iteration 86100 (5.15113 iter/s, 19.4132s/100 iter), loss = 0.0532298
I0916 15:03:03.024158 19004 solver.cpp:336]     Train net output #0: loss = 0.0532295 (* 1 = 0.0532295 loss)
I0916 15:03:03.024165 19004 sgd_solver.cpp:136] Iteration 86100, lr = 0.001, m = 0.9
I0916 15:03:04.261871 19012 data_reader.cpp:305] Starting prefetch of epoch 54
I0916 15:03:22.733603 19004 solver.cpp:314] Iteration 86200 (5.07385 iter/s, 19.7089s/100 iter), loss = 0.0600594
I0916 15:03:22.733654 19004 solver.cpp:336]     Train net output #0: loss = 0.0600591 (* 1 = 0.0600591 loss)
I0916 15:03:22.733661 19004 sgd_solver.cpp:136] Iteration 86200, lr = 0.001, m = 0.9
I0916 15:03:42.205174 19004 solver.cpp:314] Iteration 86300 (5.13584 iter/s, 19.471s/100 iter), loss = 0.083608
I0916 15:03:42.205199 19004 solver.cpp:336]     Train net output #0: loss = 0.0836077 (* 1 = 0.0836077 loss)
I0916 15:03:42.205202 19004 sgd_solver.cpp:136] Iteration 86300, lr = 0.001, m = 0.9
I0916 15:04:01.692549 19004 solver.cpp:314] Iteration 86400 (5.13167 iter/s, 19.4868s/100 iter), loss = 0.0418594
I0916 15:04:01.692625 19004 solver.cpp:336]     Train net output #0: loss = 0.041859 (* 1 = 0.041859 loss)
I0916 15:04:01.692633 19004 sgd_solver.cpp:136] Iteration 86400, lr = 0.001, m = 0.9
I0916 15:04:08.982481 19012 data_reader.cpp:305] Starting prefetch of epoch 55
I0916 15:04:21.179931 19004 solver.cpp:314] Iteration 86500 (5.13167 iter/s, 19.4868s/100 iter), loss = 0.0968798
I0916 15:04:21.179955 19004 solver.cpp:336]     Train net output #0: loss = 0.0968794 (* 1 = 0.0968794 loss)
I0916 15:04:21.179960 19004 sgd_solver.cpp:136] Iteration 86500, lr = 0.001, m = 0.9
I0916 15:04:40.536391 19004 solver.cpp:314] Iteration 86600 (5.16638 iter/s, 19.3559s/100 iter), loss = 0.0514659
I0916 15:04:40.536463 19004 solver.cpp:336]     Train net output #0: loss = 0.0514656 (* 1 = 0.0514656 loss)
I0916 15:04:40.536469 19004 sgd_solver.cpp:136] Iteration 86600, lr = 0.001, m = 0.9
I0916 15:04:40.973419 19008 data_reader.cpp:305] Starting prefetch of epoch 44
I0916 15:04:59.958433 19004 solver.cpp:314] Iteration 86700 (5.14893 iter/s, 19.4215s/100 iter), loss = 0.0369418
I0916 15:04:59.958462 19004 solver.cpp:336]     Train net output #0: loss = 0.0369414 (* 1 = 0.0369414 loss)
I0916 15:04:59.958468 19004 sgd_solver.cpp:136] Iteration 86700, lr = 0.001, m = 0.9
I0916 15:05:19.449204 19004 solver.cpp:314] Iteration 86800 (5.13078 iter/s, 19.4902s/100 iter), loss = 0.0454615
I0916 15:05:19.449249 19004 solver.cpp:336]     Train net output #0: loss = 0.0454612 (* 1 = 0.0454612 loss)
I0916 15:05:19.449255 19004 sgd_solver.cpp:136] Iteration 86800, lr = 0.001, m = 0.9
I0916 15:05:39.406625 19004 solver.cpp:314] Iteration 86900 (5.01081 iter/s, 19.9569s/100 iter), loss = 0.0606515
I0916 15:05:39.406658 19004 solver.cpp:336]     Train net output #0: loss = 0.0606511 (* 1 = 0.0606511 loss)
I0916 15:05:39.406666 19004 sgd_solver.cpp:136] Iteration 86900, lr = 0.001, m = 0.9
I0916 15:05:45.912834 19012 data_reader.cpp:305] Starting prefetch of epoch 56
I0916 15:05:59.338407 19004 solver.cpp:314] Iteration 87000 (5.01725 iter/s, 19.9312s/100 iter), loss = 0.045975
I0916 15:05:59.338524 19004 solver.cpp:336]     Train net output #0: loss = 0.0459746 (* 1 = 0.0459746 loss)
I0916 15:05:59.338533 19004 sgd_solver.cpp:136] Iteration 87000, lr = 0.001, m = 0.9
I0916 15:06:19.870805 19004 solver.cpp:314] Iteration 87100 (4.87049 iter/s, 20.5318s/100 iter), loss = 0.0656761
I0916 15:06:19.870843 19004 solver.cpp:336]     Train net output #0: loss = 0.0656758 (* 1 = 0.0656758 loss)
I0916 15:06:19.870851 19004 sgd_solver.cpp:136] Iteration 87100, lr = 0.001, m = 0.9
I0916 15:06:40.452383 19004 solver.cpp:314] Iteration 87200 (4.85885 iter/s, 20.581s/100 iter), loss = 0.0524133
I0916 15:06:40.452486 19004 solver.cpp:336]     Train net output #0: loss = 0.052413 (* 1 = 0.052413 loss)
I0916 15:06:40.452493 19004 sgd_solver.cpp:136] Iteration 87200, lr = 0.001, m = 0.9
I0916 15:06:53.338222 19010 data_reader.cpp:305] Starting prefetch of epoch 52
I0916 15:07:00.730729 19004 solver.cpp:314] Iteration 87300 (4.93151 iter/s, 20.2778s/100 iter), loss = 0.0497881
I0916 15:07:00.730752 19004 solver.cpp:336]     Train net output #0: loss = 0.0497877 (* 1 = 0.0497877 loss)
I0916 15:07:00.730758 19004 sgd_solver.cpp:136] Iteration 87300, lr = 0.001, m = 0.9
I0916 15:07:20.893417 19004 solver.cpp:314] Iteration 87400 (4.9598 iter/s, 20.1621s/100 iter), loss = 0.055766
I0916 15:07:20.893568 19004 solver.cpp:336]     Train net output #0: loss = 0.0557657 (* 1 = 0.0557657 loss)
I0916 15:07:20.893671 19004 sgd_solver.cpp:136] Iteration 87400, lr = 0.001, m = 0.9
I0916 15:07:26.606892 19007 data_reader.cpp:305] Starting prefetch of epoch 61
I0916 15:07:41.190181 19004 solver.cpp:314] Iteration 87500 (4.92703 iter/s, 20.2962s/100 iter), loss = 0.0576998
I0916 15:07:41.190276 19004 solver.cpp:336]     Train net output #0: loss = 0.0576994 (* 1 = 0.0576994 loss)
I0916 15:07:41.190306 19004 sgd_solver.cpp:136] Iteration 87500, lr = 0.001, m = 0.9
I0916 15:08:01.502739 19004 solver.cpp:314] Iteration 87600 (4.9232 iter/s, 20.312s/100 iter), loss = 0.0554725
I0916 15:08:01.502795 19004 solver.cpp:336]     Train net output #0: loss = 0.0554722 (* 1 = 0.0554722 loss)
I0916 15:08:01.502799 19004 sgd_solver.cpp:136] Iteration 87600, lr = 0.001, m = 0.9
I0916 15:08:21.396276 19004 solver.cpp:314] Iteration 87700 (5.0269 iter/s, 19.893s/100 iter), loss = 0.0364617
I0916 15:08:21.396301 19004 solver.cpp:336]     Train net output #0: loss = 0.0364614 (* 1 = 0.0364614 loss)
I0916 15:08:21.396307 19004 sgd_solver.cpp:136] Iteration 87700, lr = 0.001, m = 0.9
I0916 15:08:33.501560 18961 data_reader.cpp:305] Starting prefetch of epoch 46
I0916 15:08:41.807896 19004 solver.cpp:314] Iteration 87800 (4.89931 iter/s, 20.411s/100 iter), loss = 0.0424899
I0916 15:08:41.807971 19004 solver.cpp:336]     Train net output #0: loss = 0.0424896 (* 1 = 0.0424896 loss)
I0916 15:08:41.807993 19004 sgd_solver.cpp:136] Iteration 87800, lr = 0.001, m = 0.9
I0916 15:09:02.115866 19004 solver.cpp:314] Iteration 87900 (4.92431 iter/s, 20.3074s/100 iter), loss = 0.0782432
I0916 15:09:02.115897 19004 solver.cpp:336]     Train net output #0: loss = 0.0782428 (* 1 = 0.0782428 loss)
I0916 15:09:02.115905 19004 sgd_solver.cpp:136] Iteration 87900, lr = 0.001, m = 0.9
I0916 15:09:21.888592 19004 solver.cpp:563] Iteration 88000, Testing net (#0)
I0916 15:09:25.170279 19000 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 15:09:34.152966 19000 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 15:09:34.494550 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.955826
I0916 15:09:34.494570 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 15:09:34.494576 19004 solver.cpp:655]     Test net output #2: loss = 0.153676 (* 1 = 0.153676 loss)
I0916 15:09:34.494601 19004 solver.cpp:265] [MultiGPU] Tests completed in 12.6057s
I0916 15:09:34.699285 19004 solver.cpp:314] Iteration 88000 (3.06913 iter/s, 32.5825s/100 iter), loss = 0.0632978
I0916 15:09:34.699329 19004 solver.cpp:336]     Train net output #0: loss = 0.0632974 (* 1 = 0.0632974 loss)
I0916 15:09:34.699338 19004 sgd_solver.cpp:136] Iteration 88000, lr = 0.001, m = 0.9
I0916 15:09:54.703675 19004 solver.cpp:314] Iteration 88100 (4.99904 iter/s, 20.0038s/100 iter), loss = 0.0707851
I0916 15:09:54.703727 19004 solver.cpp:336]     Train net output #0: loss = 0.0707848 (* 1 = 0.0707848 loss)
I0916 15:09:54.703732 19004 sgd_solver.cpp:136] Iteration 88100, lr = 0.001, m = 0.9
I0916 15:10:15.134428 19004 solver.cpp:314] Iteration 88200 (4.89472 iter/s, 20.4302s/100 iter), loss = 0.0489511
I0916 15:10:15.134454 19004 solver.cpp:336]     Train net output #0: loss = 0.0489508 (* 1 = 0.0489508 loss)
I0916 15:10:15.134459 19004 sgd_solver.cpp:136] Iteration 88200, lr = 0.001, m = 0.9
I0916 15:10:26.249905 18961 data_reader.cpp:305] Starting prefetch of epoch 47
I0916 15:10:35.190547 19004 solver.cpp:314] Iteration 88300 (4.98615 iter/s, 20.0556s/100 iter), loss = 0.0428476
I0916 15:10:35.190572 19004 solver.cpp:336]     Train net output #0: loss = 0.0428473 (* 1 = 0.0428473 loss)
I0916 15:10:35.190578 19004 sgd_solver.cpp:136] Iteration 88300, lr = 0.001, m = 0.9
I0916 15:10:55.103165 19004 solver.cpp:314] Iteration 88400 (5.02208 iter/s, 19.9121s/100 iter), loss = 0.072575
I0916 15:10:55.103200 19004 solver.cpp:336]     Train net output #0: loss = 0.0725747 (* 1 = 0.0725747 loss)
I0916 15:10:55.103211 19004 sgd_solver.cpp:136] Iteration 88400, lr = 0.001, m = 0.9
I0916 15:11:15.981716 19004 solver.cpp:314] Iteration 88500 (4.78974 iter/s, 20.878s/100 iter), loss = 0.0470006
I0916 15:11:15.981838 19004 solver.cpp:336]     Train net output #0: loss = 0.0470002 (* 1 = 0.0470002 loss)
I0916 15:11:15.981864 19004 sgd_solver.cpp:136] Iteration 88500, lr = 0.001, m = 0.9
I0916 15:11:33.439319 18963 data_reader.cpp:305] Starting prefetch of epoch 63
I0916 15:11:36.362736 19004 solver.cpp:314] Iteration 88600 (4.90666 iter/s, 20.3804s/100 iter), loss = 0.0488911
I0916 15:11:36.362761 19004 solver.cpp:336]     Train net output #0: loss = 0.0488907 (* 1 = 0.0488907 loss)
I0916 15:11:36.362766 19004 sgd_solver.cpp:136] Iteration 88600, lr = 0.001, m = 0.9
I0916 15:11:56.512720 19004 solver.cpp:314] Iteration 88700 (4.96292 iter/s, 20.1494s/100 iter), loss = 0.0469972
I0916 15:11:56.512830 19004 solver.cpp:336]     Train net output #0: loss = 0.0469969 (* 1 = 0.0469969 loss)
I0916 15:11:56.512838 19004 sgd_solver.cpp:136] Iteration 88700, lr = 0.001, m = 0.9
I0916 15:12:06.741281 19007 data_reader.cpp:305] Starting prefetch of epoch 62
I0916 15:12:16.579411 19004 solver.cpp:314] Iteration 88800 (4.98352 iter/s, 20.0661s/100 iter), loss = 0.0346651
I0916 15:12:16.579437 19004 solver.cpp:336]     Train net output #0: loss = 0.0346648 (* 1 = 0.0346648 loss)
I0916 15:12:16.579443 19004 sgd_solver.cpp:136] Iteration 88800, lr = 0.001, m = 0.9
I0916 15:12:36.965091 19004 solver.cpp:314] Iteration 88900 (4.90554 iter/s, 20.3851s/100 iter), loss = 0.0570259
I0916 15:12:36.965184 19004 solver.cpp:336]     Train net output #0: loss = 0.0570256 (* 1 = 0.0570256 loss)
I0916 15:12:36.965199 19004 sgd_solver.cpp:136] Iteration 88900, lr = 0.001, m = 0.9
I0916 15:12:57.094199 19004 solver.cpp:314] Iteration 89000 (4.96807 iter/s, 20.1285s/100 iter), loss = 0.0666081
I0916 15:12:57.094220 19004 solver.cpp:336]     Train net output #0: loss = 0.0666078 (* 1 = 0.0666078 loss)
I0916 15:12:57.094224 19004 sgd_solver.cpp:136] Iteration 89000, lr = 0.001, m = 0.9
I0916 15:13:13.529259 19007 data_reader.cpp:305] Starting prefetch of epoch 63
I0916 15:13:17.408730 19004 solver.cpp:314] Iteration 89100 (4.92272 iter/s, 20.314s/100 iter), loss = 0.0504051
I0916 15:13:17.408753 19004 solver.cpp:336]     Train net output #0: loss = 0.0504048 (* 1 = 0.0504048 loss)
I0916 15:13:17.408757 19004 sgd_solver.cpp:136] Iteration 89100, lr = 0.001, m = 0.9
I0916 15:13:37.483206 19004 solver.cpp:314] Iteration 89200 (4.98159 iter/s, 20.0739s/100 iter), loss = 0.0478287
I0916 15:13:37.483235 19004 solver.cpp:336]     Train net output #0: loss = 0.0478284 (* 1 = 0.0478284 loss)
I0916 15:13:37.483242 19004 sgd_solver.cpp:136] Iteration 89200, lr = 0.001, m = 0.9
I0916 15:13:57.552059 19004 solver.cpp:314] Iteration 89300 (4.98299 iter/s, 20.0683s/100 iter), loss = 0.0680105
I0916 15:13:57.552114 19004 solver.cpp:336]     Train net output #0: loss = 0.0680102 (* 1 = 0.0680102 loss)
I0916 15:13:57.552119 19004 sgd_solver.cpp:136] Iteration 89300, lr = 0.001, m = 0.9
I0916 15:14:17.580682 19004 solver.cpp:314] Iteration 89400 (4.99299 iter/s, 20.0281s/100 iter), loss = 0.0412473
I0916 15:14:17.580708 19004 solver.cpp:336]     Train net output #0: loss = 0.041247 (* 1 = 0.041247 loss)
I0916 15:14:17.580713 19004 sgd_solver.cpp:136] Iteration 89400, lr = 0.001, m = 0.9
I0916 15:14:20.062623 19010 data_reader.cpp:305] Starting prefetch of epoch 53
I0916 15:14:37.915824 19004 solver.cpp:314] Iteration 89500 (4.91773 iter/s, 20.3346s/100 iter), loss = 0.0441573
I0916 15:14:37.915879 19004 solver.cpp:336]     Train net output #0: loss = 0.044157 (* 1 = 0.044157 loss)
I0916 15:14:37.915886 19004 sgd_solver.cpp:136] Iteration 89500, lr = 0.001, m = 0.9
I0916 15:14:53.467064 18961 data_reader.cpp:305] Starting prefetch of epoch 48
I0916 15:14:58.299783 19004 solver.cpp:314] Iteration 89600 (4.90596 iter/s, 20.3834s/100 iter), loss = 0.0558016
I0916 15:14:58.299810 19004 solver.cpp:336]     Train net output #0: loss = 0.0558012 (* 1 = 0.0558012 loss)
I0916 15:14:58.299814 19004 sgd_solver.cpp:136] Iteration 89600, lr = 0.001, m = 0.9
I0916 15:15:18.496552 19004 solver.cpp:314] Iteration 89700 (4.95143 iter/s, 20.1962s/100 iter), loss = 0.0547375
I0916 15:15:18.496634 19004 solver.cpp:336]     Train net output #0: loss = 0.0547372 (* 1 = 0.0547372 loss)
I0916 15:15:18.496641 19004 sgd_solver.cpp:136] Iteration 89700, lr = 0.001, m = 0.9
I0916 15:15:39.163354 19004 solver.cpp:314] Iteration 89800 (4.83882 iter/s, 20.6662s/100 iter), loss = 0.061417
I0916 15:15:39.163403 19004 solver.cpp:336]     Train net output #0: loss = 0.0614167 (* 1 = 0.0614167 loss)
I0916 15:15:39.163410 19004 sgd_solver.cpp:136] Iteration 89800, lr = 0.001, m = 0.9
I0916 15:15:59.662470 19004 solver.cpp:314] Iteration 89900 (4.87839 iter/s, 20.4985s/100 iter), loss = 0.0712695
I0916 15:15:59.662518 19004 solver.cpp:336]     Train net output #0: loss = 0.0712692 (* 1 = 0.0712692 loss)
I0916 15:15:59.662523 19004 sgd_solver.cpp:136] Iteration 89900, lr = 0.001, m = 0.9
I0916 15:16:01.390125 19012 data_reader.cpp:305] Starting prefetch of epoch 57
I0916 15:16:20.055742 19004 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/cityscapes5_jsegnet21v2_iter_90000.caffemodel
I0916 15:16:20.145483 19004 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/cityscapes5_jsegnet21v2_iter_90000.solverstate
I0916 15:16:20.158737 19004 solver.cpp:563] Iteration 90000, Testing net (#0)
I0916 15:16:32.909032 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.956617
I0916 15:16:32.909154 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.999774
I0916 15:16:32.909164 19004 solver.cpp:655]     Test net output #2: loss = 0.19327 (* 1 = 0.19327 loss)
I0916 15:16:32.909190 19004 solver.cpp:265] [MultiGPU] Tests completed in 12.7501s
I0916 15:16:32.995954 19035 sgd_solver.cpp:48] MultiStep Status: Iteration 90000, step = 2
I0916 15:16:32.995956 19033 sgd_solver.cpp:48] MultiStep Status: Iteration 90000, step = 2
I0916 15:16:32.995954 19034 sgd_solver.cpp:48] MultiStep Status: Iteration 90000, step = 2
I0916 15:16:33.109860 19004 solver.cpp:314] Iteration 90000 (2.98985 iter/s, 33.4465s/100 iter), loss = 0.06601
I0916 15:16:33.109886 19004 solver.cpp:336]     Train net output #0: loss = 0.0660097 (* 1 = 0.0660097 loss)
I0916 15:16:33.109892 19004 sgd_solver.cpp:136] Iteration 90000, lr = 0.0001, m = 0.9
I0916 15:16:48.001927 18963 data_reader.cpp:305] Starting prefetch of epoch 64
I0916 15:16:53.442965 19004 solver.cpp:314] Iteration 90100 (4.91823 iter/s, 20.3325s/100 iter), loss = 0.0498669
I0916 15:16:53.442989 19004 solver.cpp:336]     Train net output #0: loss = 0.0498666 (* 1 = 0.0498666 loss)
I0916 15:16:53.442993 19004 sgd_solver.cpp:136] Iteration 90100, lr = 0.0001, m = 0.9
I0916 15:17:13.793854 19004 solver.cpp:314] Iteration 90200 (4.91393 iter/s, 20.3503s/100 iter), loss = 0.0813378
I0916 15:17:13.793898 19004 solver.cpp:336]     Train net output #0: loss = 0.0813375 (* 1 = 0.0813375 loss)
I0916 15:17:13.793905 19004 sgd_solver.cpp:136] Iteration 90200, lr = 0.0001, m = 0.9
I0916 15:17:33.722877 19004 solver.cpp:314] Iteration 90300 (5.01795 iter/s, 19.9285s/100 iter), loss = 0.0492092
I0916 15:17:33.722901 19004 solver.cpp:336]     Train net output #0: loss = 0.0492088 (* 1 = 0.0492088 loss)
I0916 15:17:33.722908 19004 sgd_solver.cpp:136] Iteration 90300, lr = 0.0001, m = 0.9
I0916 15:17:53.964314 19004 solver.cpp:314] Iteration 90400 (4.9405 iter/s, 20.2409s/100 iter), loss = 0.0661939
I0916 15:17:53.964452 19004 solver.cpp:336]     Train net output #0: loss = 0.0661935 (* 1 = 0.0661935 loss)
I0916 15:17:53.964481 19004 sgd_solver.cpp:136] Iteration 90400, lr = 0.0001, m = 0.9
I0916 15:17:54.615913 19010 data_reader.cpp:305] Starting prefetch of epoch 54
I0916 15:18:14.441895 19004 solver.cpp:314] Iteration 90500 (4.88353 iter/s, 20.477s/100 iter), loss = 0.0561375
I0916 15:18:14.441978 19004 solver.cpp:336]     Train net output #0: loss = 0.0561372 (* 1 = 0.0561372 loss)
I0916 15:18:14.441992 19004 sgd_solver.cpp:136] Iteration 90500, lr = 0.0001, m = 0.9
I0916 15:18:28.543432 19008 data_reader.cpp:305] Starting prefetch of epoch 45
I0916 15:18:35.020153 19004 solver.cpp:314] Iteration 90600 (4.85963 iter/s, 20.5777s/100 iter), loss = 0.0367478
I0916 15:18:35.020179 19004 solver.cpp:336]     Train net output #0: loss = 0.0367475 (* 1 = 0.0367475 loss)
I0916 15:18:35.020185 19004 sgd_solver.cpp:136] Iteration 90600, lr = 0.0001, m = 0.9
I0916 15:18:55.002593 19004 solver.cpp:314] Iteration 90700 (5.00454 iter/s, 19.9819s/100 iter), loss = 0.0606491
I0916 15:18:55.002616 19004 solver.cpp:336]     Train net output #0: loss = 0.0606488 (* 1 = 0.0606488 loss)
I0916 15:18:55.002622 19004 sgd_solver.cpp:136] Iteration 90700, lr = 0.0001, m = 0.9
I0916 15:19:15.532964 19004 solver.cpp:314] Iteration 90800 (4.87097 iter/s, 20.5298s/100 iter), loss = 0.0815799
I0916 15:19:15.533051 19004 solver.cpp:336]     Train net output #0: loss = 0.0815795 (* 1 = 0.0815795 loss)
I0916 15:19:15.533057 19004 sgd_solver.cpp:136] Iteration 90800, lr = 0.0001, m = 0.9
I0916 15:19:35.604679 19008 data_reader.cpp:305] Starting prefetch of epoch 46
I0916 15:19:35.780951 19004 solver.cpp:314] Iteration 90900 (4.9389 iter/s, 20.2474s/100 iter), loss = 0.0545089
I0916 15:19:35.780973 19004 solver.cpp:336]     Train net output #0: loss = 0.0545086 (* 1 = 0.0545086 loss)
I0916 15:19:35.780977 19004 sgd_solver.cpp:136] Iteration 90900, lr = 0.0001, m = 0.9
I0916 15:19:55.938628 19004 solver.cpp:314] Iteration 91000 (4.96103 iter/s, 20.1571s/100 iter), loss = 0.05017
I0916 15:19:55.938678 19004 solver.cpp:336]     Train net output #0: loss = 0.0501696 (* 1 = 0.0501696 loss)
I0916 15:19:55.938683 19004 sgd_solver.cpp:136] Iteration 91000, lr = 0.0001, m = 0.9
I0916 15:20:16.089602 19004 solver.cpp:314] Iteration 91100 (4.96268 iter/s, 20.1504s/100 iter), loss = 0.0707402
I0916 15:20:16.089625 19004 solver.cpp:336]     Train net output #0: loss = 0.0707399 (* 1 = 0.0707399 loss)
I0916 15:20:16.089629 19004 sgd_solver.cpp:136] Iteration 91100, lr = 0.0001, m = 0.9
I0916 15:20:36.373975 19004 solver.cpp:314] Iteration 91200 (4.93004 iter/s, 20.2838s/100 iter), loss = 0.0464809
I0916 15:20:36.374033 19004 solver.cpp:336]     Train net output #0: loss = 0.0464806 (* 1 = 0.0464806 loss)
I0916 15:20:36.374040 19004 sgd_solver.cpp:136] Iteration 91200, lr = 0.0001, m = 0.9
I0916 15:20:42.618201 19010 data_reader.cpp:305] Starting prefetch of epoch 55
I0916 15:20:57.014565 19004 solver.cpp:314] Iteration 91300 (4.84496 iter/s, 20.64s/100 iter), loss = 0.0504734
I0916 15:20:57.014591 19004 solver.cpp:336]     Train net output #0: loss = 0.0504731 (* 1 = 0.0504731 loss)
I0916 15:20:57.014596 19004 sgd_solver.cpp:136] Iteration 91300, lr = 0.0001, m = 0.9
I0916 15:21:15.836483 19008 data_reader.cpp:305] Starting prefetch of epoch 47
I0916 15:21:16.798120 19004 solver.cpp:314] Iteration 91400 (5.05485 iter/s, 19.783s/100 iter), loss = 0.055136
I0916 15:21:16.798154 19004 solver.cpp:336]     Train net output #0: loss = 0.0551357 (* 1 = 0.0551357 loss)
I0916 15:21:16.798161 19004 sgd_solver.cpp:136] Iteration 91400, lr = 0.0001, m = 0.9
I0916 15:21:37.074699 19004 solver.cpp:314] Iteration 91500 (4.93194 iter/s, 20.276s/100 iter), loss = 0.0404127
I0916 15:21:37.074723 19004 solver.cpp:336]     Train net output #0: loss = 0.0404124 (* 1 = 0.0404124 loss)
I0916 15:21:37.074728 19004 sgd_solver.cpp:136] Iteration 91500, lr = 0.0001, m = 0.9
I0916 15:21:57.409294 19004 solver.cpp:314] Iteration 91600 (4.91787 iter/s, 20.334s/100 iter), loss = 0.122822
I0916 15:21:57.409379 19004 solver.cpp:336]     Train net output #0: loss = 0.122822 (* 1 = 0.122822 loss)
I0916 15:21:57.409387 19004 sgd_solver.cpp:136] Iteration 91600, lr = 0.0001, m = 0.9
I0916 15:22:17.526242 19004 solver.cpp:314] Iteration 91700 (4.97107 iter/s, 20.1164s/100 iter), loss = 0.0569321
I0916 15:22:17.526265 19004 solver.cpp:336]     Train net output #0: loss = 0.0569318 (* 1 = 0.0569318 loss)
I0916 15:22:17.526271 19004 sgd_solver.cpp:136] Iteration 91700, lr = 0.0001, m = 0.9
I0916 15:22:22.598589 18963 data_reader.cpp:305] Starting prefetch of epoch 65
I0916 15:22:37.453845 19004 solver.cpp:314] Iteration 91800 (5.01831 iter/s, 19.927s/100 iter), loss = 0.05364
I0916 15:22:37.453936 19004 solver.cpp:336]     Train net output #0: loss = 0.0536397 (* 1 = 0.0536397 loss)
I0916 15:22:37.454129 19004 sgd_solver.cpp:136] Iteration 91800, lr = 0.0001, m = 0.9
I0916 15:22:57.582111 19004 solver.cpp:314] Iteration 91900 (4.96828 iter/s, 20.1277s/100 iter), loss = 0.0410265
I0916 15:22:57.582191 19004 solver.cpp:336]     Train net output #0: loss = 0.0410262 (* 1 = 0.0410262 loss)
I0916 15:22:57.582214 19004 sgd_solver.cpp:136] Iteration 91900, lr = 0.0001, m = 0.9
I0916 15:23:17.622849 19004 solver.cpp:563] Iteration 92000, Testing net (#0)
I0916 15:23:21.038230 19018 data_reader.cpp:305] Starting prefetch of epoch 13
I0916 15:23:28.814533 19002 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 15:23:29.142031 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.955839
I0916 15:23:29.142052 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 15:23:29.142057 19004 solver.cpp:655]     Test net output #2: loss = 0.156239 (* 1 = 0.156239 loss)
I0916 15:23:29.142096 19004 solver.cpp:265] [MultiGPU] Tests completed in 11.5189s
I0916 15:23:29.327759 19004 solver.cpp:314] Iteration 92000 (3.15013 iter/s, 31.7448s/100 iter), loss = 0.0561851
I0916 15:23:29.327785 19004 solver.cpp:336]     Train net output #0: loss = 0.0561848 (* 1 = 0.0561848 loss)
I0916 15:23:29.327792 19004 sgd_solver.cpp:136] Iteration 92000, lr = 0.0001, m = 0.9
I0916 15:23:49.186055 19004 solver.cpp:314] Iteration 92100 (5.03582 iter/s, 19.8577s/100 iter), loss = 0.0580664
I0916 15:23:49.186126 19004 solver.cpp:336]     Train net output #0: loss = 0.0580661 (* 1 = 0.0580661 loss)
I0916 15:23:49.186138 19004 sgd_solver.cpp:136] Iteration 92100, lr = 0.0001, m = 0.9
I0916 15:24:09.487721 19004 solver.cpp:314] Iteration 92200 (4.92584 iter/s, 20.3011s/100 iter), loss = 0.068117
I0916 15:24:09.487747 19004 solver.cpp:336]     Train net output #0: loss = 0.0681167 (* 1 = 0.0681167 loss)
I0916 15:24:09.487752 19004 sgd_solver.cpp:136] Iteration 92200, lr = 0.0001, m = 0.9
I0916 15:24:13.756762 19012 data_reader.cpp:305] Starting prefetch of epoch 58
I0916 15:24:29.623375 19004 solver.cpp:314] Iteration 92300 (4.96646 iter/s, 20.1351s/100 iter), loss = 0.0618176
I0916 15:24:29.623431 19004 solver.cpp:336]     Train net output #0: loss = 0.0618173 (* 1 = 0.0618173 loss)
I0916 15:24:29.623438 19004 sgd_solver.cpp:136] Iteration 92300, lr = 0.0001, m = 0.9
I0916 15:24:49.915477 19004 solver.cpp:314] Iteration 92400 (4.92817 iter/s, 20.2915s/100 iter), loss = 0.068969
I0916 15:24:49.915516 19004 solver.cpp:336]     Train net output #0: loss = 0.0689686 (* 1 = 0.0689686 loss)
I0916 15:24:49.915524 19004 sgd_solver.cpp:136] Iteration 92400, lr = 0.0001, m = 0.9
I0916 15:25:10.137991 19004 solver.cpp:314] Iteration 92500 (4.94512 iter/s, 20.2219s/100 iter), loss = 0.0434721
I0916 15:25:10.138046 19004 solver.cpp:336]     Train net output #0: loss = 0.0434717 (* 1 = 0.0434717 loss)
I0916 15:25:10.138052 19004 sgd_solver.cpp:136] Iteration 92500, lr = 0.0001, m = 0.9
I0916 15:25:20.591950 19012 data_reader.cpp:305] Starting prefetch of epoch 59
I0916 15:25:30.453022 19004 solver.cpp:314] Iteration 92600 (4.9226 iter/s, 20.3145s/100 iter), loss = 0.0549414
I0916 15:25:30.453044 19004 solver.cpp:336]     Train net output #0: loss = 0.0549411 (* 1 = 0.0549411 loss)
I0916 15:25:30.453052 19004 sgd_solver.cpp:136] Iteration 92600, lr = 0.0001, m = 0.9
I0916 15:25:50.400424 19004 solver.cpp:314] Iteration 92700 (5.01333 iter/s, 19.9468s/100 iter), loss = 0.0688387
I0916 15:25:50.400485 19004 solver.cpp:336]     Train net output #0: loss = 0.0688384 (* 1 = 0.0688384 loss)
I0916 15:25:50.400493 19004 sgd_solver.cpp:136] Iteration 92700, lr = 0.0001, m = 0.9
I0916 15:25:54.113746 19008 data_reader.cpp:305] Starting prefetch of epoch 48
I0916 15:26:11.004724 19004 solver.cpp:314] Iteration 92800 (4.85349 iter/s, 20.6037s/100 iter), loss = 0.0437266
I0916 15:26:11.004751 19004 solver.cpp:336]     Train net output #0: loss = 0.0437263 (* 1 = 0.0437263 loss)
I0916 15:26:11.004757 19004 sgd_solver.cpp:136] Iteration 92800, lr = 0.0001, m = 0.9
I0916 15:26:31.157119 19004 solver.cpp:314] Iteration 92900 (4.96233 iter/s, 20.1518s/100 iter), loss = 0.0625218
I0916 15:26:31.157215 19004 solver.cpp:336]     Train net output #0: loss = 0.0625214 (* 1 = 0.0625214 loss)
I0916 15:26:31.157223 19004 sgd_solver.cpp:136] Iteration 92900, lr = 0.0001, m = 0.9
I0916 15:26:51.084488 19004 solver.cpp:314] Iteration 93000 (5.01837 iter/s, 19.9268s/100 iter), loss = 0.069889
I0916 15:26:51.084513 19004 solver.cpp:336]     Train net output #0: loss = 0.0698887 (* 1 = 0.0698887 loss)
I0916 15:26:51.084520 19004 sgd_solver.cpp:136] Iteration 93000, lr = 0.0001, m = 0.9
I0916 15:27:00.541018 19010 data_reader.cpp:305] Starting prefetch of epoch 56
I0916 15:27:11.351119 19004 solver.cpp:314] Iteration 93100 (4.93436 iter/s, 20.2661s/100 iter), loss = 0.0601861
I0916 15:27:11.351227 19004 solver.cpp:336]     Train net output #0: loss = 0.0601858 (* 1 = 0.0601858 loss)
I0916 15:27:11.351233 19004 sgd_solver.cpp:136] Iteration 93100, lr = 0.0001, m = 0.9
I0916 15:27:31.446334 19004 solver.cpp:314] Iteration 93200 (4.97645 iter/s, 20.0946s/100 iter), loss = 0.0469884
I0916 15:27:31.446360 19004 solver.cpp:336]     Train net output #0: loss = 0.0469881 (* 1 = 0.0469881 loss)
I0916 15:27:31.446367 19004 sgd_solver.cpp:136] Iteration 93200, lr = 0.0001, m = 0.9
I0916 15:27:51.587612 19004 solver.cpp:314] Iteration 93300 (4.96507 iter/s, 20.1407s/100 iter), loss = 0.0483675
I0916 15:27:51.587672 19004 solver.cpp:336]     Train net output #0: loss = 0.0483672 (* 1 = 0.0483672 loss)
I0916 15:27:51.587679 19004 sgd_solver.cpp:136] Iteration 93300, lr = 0.0001, m = 0.9
I0916 15:28:06.957525 18963 data_reader.cpp:305] Starting prefetch of epoch 66
I0916 15:28:11.188498 19004 solver.cpp:314] Iteration 93400 (5.10195 iter/s, 19.6003s/100 iter), loss = 0.0488066
I0916 15:28:11.188522 19004 solver.cpp:336]     Train net output #0: loss = 0.0488063 (* 1 = 0.0488063 loss)
I0916 15:28:11.188526 19004 sgd_solver.cpp:136] Iteration 93400, lr = 0.0001, m = 0.9
I0916 15:28:31.151456 19004 solver.cpp:314] Iteration 93500 (5.00942 iter/s, 19.9624s/100 iter), loss = 0.0420205
I0916 15:28:31.151564 19004 solver.cpp:336]     Train net output #0: loss = 0.0420202 (* 1 = 0.0420202 loss)
I0916 15:28:31.151572 19004 sgd_solver.cpp:136] Iteration 93500, lr = 0.0001, m = 0.9
I0916 15:28:40.245157 19007 data_reader.cpp:305] Starting prefetch of epoch 64
I0916 15:28:51.675374 19004 solver.cpp:314] Iteration 93600 (4.8725 iter/s, 20.5233s/100 iter), loss = 0.044927
I0916 15:28:51.675401 19004 solver.cpp:336]     Train net output #0: loss = 0.0449266 (* 1 = 0.0449266 loss)
I0916 15:28:51.675407 19004 sgd_solver.cpp:136] Iteration 93600, lr = 0.0001, m = 0.9
I0916 15:29:11.952473 19004 solver.cpp:314] Iteration 93700 (4.93181 iter/s, 20.2765s/100 iter), loss = 0.0380758
I0916 15:29:11.952527 19004 solver.cpp:336]     Train net output #0: loss = 0.0380754 (* 1 = 0.0380754 loss)
I0916 15:29:11.952534 19004 sgd_solver.cpp:136] Iteration 93700, lr = 0.0001, m = 0.9
I0916 15:29:32.144732 19004 solver.cpp:314] Iteration 93800 (4.95253 iter/s, 20.1917s/100 iter), loss = 0.0443269
I0916 15:29:32.144790 19004 solver.cpp:336]     Train net output #0: loss = 0.0443266 (* 1 = 0.0443266 loss)
I0916 15:29:32.144806 19004 sgd_solver.cpp:136] Iteration 93800, lr = 0.0001, m = 0.9
I0916 15:29:47.075228 18963 data_reader.cpp:305] Starting prefetch of epoch 67
I0916 15:29:52.334627 19004 solver.cpp:314] Iteration 93900 (4.95311 iter/s, 20.1893s/100 iter), loss = 0.0571214
I0916 15:29:52.334659 19004 solver.cpp:336]     Train net output #0: loss = 0.0571211 (* 1 = 0.0571211 loss)
I0916 15:29:52.334666 19004 sgd_solver.cpp:136] Iteration 93900, lr = 0.0001, m = 0.9
I0916 15:30:12.356926 19004 solver.cpp:563] Iteration 94000, Testing net (#0)
I0916 15:30:24.372750 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.956669
I0916 15:30:24.372849 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.999762
I0916 15:30:24.372859 19004 solver.cpp:655]     Test net output #2: loss = 0.192679 (* 1 = 0.192679 loss)
I0916 15:30:24.372884 19004 solver.cpp:265] [MultiGPU] Tests completed in 12.0156s
I0916 15:30:24.563858 19004 solver.cpp:314] Iteration 94000 (3.10286 iter/s, 32.2283s/100 iter), loss = 0.0386977
I0916 15:30:24.563884 19004 solver.cpp:336]     Train net output #0: loss = 0.0386974 (* 1 = 0.0386974 loss)
I0916 15:30:24.563889 19004 sgd_solver.cpp:136] Iteration 94000, lr = 0.0001, m = 0.9
I0916 15:30:32.233497 19012 data_reader.cpp:305] Starting prefetch of epoch 60
I0916 15:30:44.072850 19004 solver.cpp:314] Iteration 94100 (5.12599 iter/s, 19.5084s/100 iter), loss = 0.0625595
I0916 15:30:44.073117 19004 solver.cpp:336]     Train net output #0: loss = 0.0625591 (* 1 = 0.0625591 loss)
I0916 15:30:44.073225 19004 sgd_solver.cpp:136] Iteration 94100, lr = 0.0001, m = 0.9
I0916 15:31:04.409708 19004 solver.cpp:314] Iteration 94200 (4.91732 iter/s, 20.3363s/100 iter), loss = 0.0415488
I0916 15:31:04.409895 19004 solver.cpp:336]     Train net output #0: loss = 0.0415485 (* 1 = 0.0415485 loss)
I0916 15:31:04.409927 19004 sgd_solver.cpp:136] Iteration 94200, lr = 0.0001, m = 0.9
I0916 15:31:05.563576 18961 data_reader.cpp:305] Starting prefetch of epoch 49
I0916 15:31:25.573896 19004 solver.cpp:314] Iteration 94300 (4.7251 iter/s, 21.1636s/100 iter), loss = 0.06006
I0916 15:31:25.573988 19004 solver.cpp:336]     Train net output #0: loss = 0.0600596 (* 1 = 0.0600596 loss)
I0916 15:31:25.574014 19004 sgd_solver.cpp:136] Iteration 94300, lr = 0.0001, m = 0.9
I0916 15:31:45.752717 19004 solver.cpp:314] Iteration 94400 (4.95583 iter/s, 20.1783s/100 iter), loss = 0.0651362
I0916 15:31:45.752777 19004 solver.cpp:336]     Train net output #0: loss = 0.0651359 (* 1 = 0.0651359 loss)
I0916 15:31:45.752784 19004 sgd_solver.cpp:136] Iteration 94400, lr = 0.0001, m = 0.9
I0916 15:32:05.852329 19004 solver.cpp:314] Iteration 94500 (4.97536 iter/s, 20.099s/100 iter), loss = 0.0392509
I0916 15:32:05.852354 19004 solver.cpp:336]     Train net output #0: loss = 0.0392505 (* 1 = 0.0392505 loss)
I0916 15:32:05.852358 19004 sgd_solver.cpp:136] Iteration 94500, lr = 0.0001, m = 0.9
I0916 15:32:12.994786 19010 data_reader.cpp:305] Starting prefetch of epoch 57
I0916 15:32:26.172860 19004 solver.cpp:314] Iteration 94600 (4.92128 iter/s, 20.3199s/100 iter), loss = 0.0474656
I0916 15:32:26.182163 19004 solver.cpp:336]     Train net output #0: loss = 0.0474653 (* 1 = 0.0474653 loss)
I0916 15:32:26.182214 19004 sgd_solver.cpp:136] Iteration 94600, lr = 0.0001, m = 0.9
I0916 15:32:46.963276 19004 solver.cpp:314] Iteration 94700 (4.81004 iter/s, 20.7898s/100 iter), loss = 0.0537574
I0916 15:32:46.963301 19004 solver.cpp:336]     Train net output #0: loss = 0.0537571 (* 1 = 0.0537571 loss)
I0916 15:32:46.963306 19004 sgd_solver.cpp:136] Iteration 94700, lr = 0.0001, m = 0.9
I0916 15:33:07.099748 19004 solver.cpp:314] Iteration 94800 (4.96625 iter/s, 20.1359s/100 iter), loss = 0.0615358
I0916 15:33:07.099920 19004 solver.cpp:336]     Train net output #0: loss = 0.0615355 (* 1 = 0.0615355 loss)
I0916 15:33:07.099925 19004 sgd_solver.cpp:136] Iteration 94800, lr = 0.0001, m = 0.9
I0916 15:33:20.760709 18963 data_reader.cpp:305] Starting prefetch of epoch 68
I0916 15:33:27.666570 19004 solver.cpp:314] Iteration 94900 (4.86234 iter/s, 20.5662s/100 iter), loss = 0.0686593
I0916 15:33:27.666596 19004 solver.cpp:336]     Train net output #0: loss = 0.068659 (* 1 = 0.068659 loss)
I0916 15:33:27.666602 19004 sgd_solver.cpp:136] Iteration 94900, lr = 0.0001, m = 0.9
I0916 15:33:47.971562 19004 solver.cpp:314] Iteration 95000 (4.92504 iter/s, 20.3044s/100 iter), loss = 0.032023
I0916 15:33:47.971628 19004 solver.cpp:336]     Train net output #0: loss = 0.0320227 (* 1 = 0.0320227 loss)
I0916 15:33:47.971637 19004 sgd_solver.cpp:136] Iteration 95000, lr = 0.0001, m = 0.9
I0916 15:33:54.392555 19008 data_reader.cpp:305] Starting prefetch of epoch 49
I0916 15:34:08.395256 19004 solver.cpp:314] Iteration 95100 (4.89641 iter/s, 20.4231s/100 iter), loss = 0.0495483
I0916 15:34:08.395283 19004 solver.cpp:336]     Train net output #0: loss = 0.049548 (* 1 = 0.049548 loss)
I0916 15:34:08.395288 19004 sgd_solver.cpp:136] Iteration 95100, lr = 0.0001, m = 0.9
I0916 15:34:28.530828 19004 solver.cpp:314] Iteration 95200 (4.96648 iter/s, 20.135s/100 iter), loss = 0.0561263
I0916 15:34:28.530879 19004 solver.cpp:336]     Train net output #0: loss = 0.056126 (* 1 = 0.056126 loss)
I0916 15:34:28.530882 19004 sgd_solver.cpp:136] Iteration 95200, lr = 0.0001, m = 0.9
I0916 15:34:48.786356 19004 solver.cpp:314] Iteration 95300 (4.93706 iter/s, 20.255s/100 iter), loss = 0.0691132
I0916 15:34:48.786381 19004 solver.cpp:336]     Train net output #0: loss = 0.0691128 (* 1 = 0.0691128 loss)
I0916 15:34:48.786387 19004 sgd_solver.cpp:136] Iteration 95300, lr = 0.0001, m = 0.9
I0916 15:35:01.324971 18963 data_reader.cpp:305] Starting prefetch of epoch 69
I0916 15:35:09.083461 19004 solver.cpp:314] Iteration 95400 (4.92695 iter/s, 20.2965s/100 iter), loss = 0.0461164
I0916 15:35:09.083482 19004 solver.cpp:336]     Train net output #0: loss = 0.046116 (* 1 = 0.046116 loss)
I0916 15:35:09.083487 19004 sgd_solver.cpp:136] Iteration 95400, lr = 0.0001, m = 0.9
I0916 15:35:29.938040 19004 solver.cpp:314] Iteration 95500 (4.79525 iter/s, 20.854s/100 iter), loss = 0.0460029
I0916 15:35:29.938064 19004 solver.cpp:336]     Train net output #0: loss = 0.0460026 (* 1 = 0.0460026 loss)
I0916 15:35:29.938068 19004 sgd_solver.cpp:136] Iteration 95500, lr = 0.0001, m = 0.9
I0916 15:35:50.152245 19004 solver.cpp:314] Iteration 95600 (4.94716 iter/s, 20.2136s/100 iter), loss = 0.0485402
I0916 15:35:50.152302 19004 solver.cpp:336]     Train net output #0: loss = 0.0485399 (* 1 = 0.0485399 loss)
I0916 15:35:50.152308 19004 sgd_solver.cpp:136] Iteration 95600, lr = 0.0001, m = 0.9
I0916 15:36:09.064543 19012 data_reader.cpp:305] Starting prefetch of epoch 61
I0916 15:36:10.710151 19004 solver.cpp:314] Iteration 95700 (4.86445 iter/s, 20.5573s/100 iter), loss = 0.0610228
I0916 15:36:10.710175 19004 solver.cpp:336]     Train net output #0: loss = 0.0610224 (* 1 = 0.0610224 loss)
I0916 15:36:10.710180 19004 sgd_solver.cpp:136] Iteration 95700, lr = 0.0001, m = 0.9
I0916 15:36:31.272820 19004 solver.cpp:314] Iteration 95800 (4.86332 iter/s, 20.5621s/100 iter), loss = 0.0662383
I0916 15:36:31.272904 19004 solver.cpp:336]     Train net output #0: loss = 0.066238 (* 1 = 0.066238 loss)
I0916 15:36:31.272910 19004 sgd_solver.cpp:136] Iteration 95800, lr = 0.0001, m = 0.9
I0916 15:36:43.233755 19007 data_reader.cpp:305] Starting prefetch of epoch 65
I0916 15:36:51.630144 19004 solver.cpp:314] Iteration 95900 (4.91238 iter/s, 20.3568s/100 iter), loss = 0.0377288
I0916 15:36:51.630172 19004 solver.cpp:336]     Train net output #0: loss = 0.0377285 (* 1 = 0.0377285 loss)
I0916 15:36:51.630177 19004 sgd_solver.cpp:136] Iteration 95900, lr = 0.0001, m = 0.9
I0916 15:37:11.969415 19004 solver.cpp:563] Iteration 96000, Testing net (#0)
I0916 15:37:24.292488 19029 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 15:37:24.728751 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.956227
I0916 15:37:24.728777 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 15:37:24.728783 19004 solver.cpp:655]     Test net output #2: loss = 0.154633 (* 1 = 0.154633 loss)
I0916 15:37:24.728816 19004 solver.cpp:265] [MultiGPU] Tests completed in 12.759s
I0916 15:37:24.940546 19004 solver.cpp:314] Iteration 96000 (3.00215 iter/s, 33.3095s/100 iter), loss = 0.0630351
I0916 15:37:24.940570 19004 solver.cpp:336]     Train net output #0: loss = 0.0630348 (* 1 = 0.0630348 loss)
I0916 15:37:24.940574 19004 sgd_solver.cpp:136] Iteration 96000, lr = 0.0001, m = 0.9
I0916 15:37:45.817878 19004 solver.cpp:314] Iteration 96100 (4.79002 iter/s, 20.8767s/100 iter), loss = 0.0448055
I0916 15:37:45.817965 19004 solver.cpp:336]     Train net output #0: loss = 0.0448052 (* 1 = 0.0448052 loss)
I0916 15:37:45.817978 19004 sgd_solver.cpp:136] Iteration 96100, lr = 0.0001, m = 0.9
I0916 15:38:04.347182 19012 data_reader.cpp:305] Starting prefetch of epoch 62
I0916 15:38:06.923106 19004 solver.cpp:314] Iteration 96200 (4.7383 iter/s, 21.1046s/100 iter), loss = 0.0712989
I0916 15:38:06.923135 19004 solver.cpp:336]     Train net output #0: loss = 0.0712985 (* 1 = 0.0712985 loss)
I0916 15:38:06.923142 19004 sgd_solver.cpp:136] Iteration 96200, lr = 0.0001, m = 0.9
I0916 15:38:26.901981 19004 solver.cpp:314] Iteration 96300 (5.00543 iter/s, 19.9783s/100 iter), loss = 0.0484626
I0916 15:38:26.902065 19004 solver.cpp:336]     Train net output #0: loss = 0.0484622 (* 1 = 0.0484622 loss)
I0916 15:38:26.902081 19004 sgd_solver.cpp:136] Iteration 96300, lr = 0.0001, m = 0.9
I0916 15:38:37.975239 19007 data_reader.cpp:305] Starting prefetch of epoch 66
I0916 15:38:47.818630 19004 solver.cpp:314] Iteration 96400 (4.78102 iter/s, 20.9161s/100 iter), loss = 0.0652859
I0916 15:38:47.818656 19004 solver.cpp:336]     Train net output #0: loss = 0.0652856 (* 1 = 0.0652856 loss)
I0916 15:38:47.818662 19004 sgd_solver.cpp:136] Iteration 96400, lr = 0.0001, m = 0.9
I0916 15:39:08.282757 19004 solver.cpp:314] Iteration 96500 (4.88674 iter/s, 20.4635s/100 iter), loss = 0.0649076
I0916 15:39:08.282842 19004 solver.cpp:336]     Train net output #0: loss = 0.0649073 (* 1 = 0.0649073 loss)
I0916 15:39:08.282850 19004 sgd_solver.cpp:136] Iteration 96500, lr = 0.0001, m = 0.9
I0916 15:39:28.452841 19004 solver.cpp:314] Iteration 96600 (4.95798 iter/s, 20.1695s/100 iter), loss = 0.0532727
I0916 15:39:28.452894 19004 solver.cpp:336]     Train net output #0: loss = 0.0532723 (* 1 = 0.0532723 loss)
I0916 15:39:28.453016 19004 sgd_solver.cpp:136] Iteration 96600, lr = 0.0001, m = 0.9
I0916 15:39:45.895805 19007 data_reader.cpp:305] Starting prefetch of epoch 67
I0916 15:39:49.164279 19004 solver.cpp:314] Iteration 96700 (4.82838 iter/s, 20.7109s/100 iter), loss = 0.0612359
I0916 15:39:49.164304 19004 solver.cpp:336]     Train net output #0: loss = 0.0612356 (* 1 = 0.0612356 loss)
I0916 15:39:49.164312 19004 sgd_solver.cpp:136] Iteration 96700, lr = 0.0001, m = 0.9
I0916 15:40:09.425961 19004 solver.cpp:314] Iteration 96800 (4.93556 iter/s, 20.2611s/100 iter), loss = 0.0614938
I0916 15:40:09.425982 19004 solver.cpp:336]     Train net output #0: loss = 0.0614935 (* 1 = 0.0614935 loss)
I0916 15:40:09.425987 19004 sgd_solver.cpp:136] Iteration 96800, lr = 0.0001, m = 0.9
I0916 15:40:29.747898 19004 solver.cpp:314] Iteration 96900 (4.92093 iter/s, 20.3214s/100 iter), loss = 0.052031
I0916 15:40:29.747942 19004 solver.cpp:336]     Train net output #0: loss = 0.0520307 (* 1 = 0.0520307 loss)
I0916 15:40:29.747947 19004 sgd_solver.cpp:136] Iteration 96900, lr = 0.0001, m = 0.9
I0916 15:40:50.073483 19004 solver.cpp:314] Iteration 97000 (4.92005 iter/s, 20.325s/100 iter), loss = 0.0440125
I0916 15:40:50.073504 19004 solver.cpp:336]     Train net output #0: loss = 0.0440122 (* 1 = 0.0440122 loss)
I0916 15:40:50.073508 19004 sgd_solver.cpp:136] Iteration 97000, lr = 0.0001, m = 0.9
I0916 15:40:53.029122 19012 data_reader.cpp:305] Starting prefetch of epoch 63
I0916 15:41:10.390933 19004 solver.cpp:314] Iteration 97100 (4.92202 iter/s, 20.3169s/100 iter), loss = 0.0317908
I0916 15:41:10.390982 19004 solver.cpp:336]     Train net output #0: loss = 0.0317904 (* 1 = 0.0317904 loss)
I0916 15:41:10.390987 19004 sgd_solver.cpp:136] Iteration 97100, lr = 0.0001, m = 0.9
I0916 15:41:26.878029 19008 data_reader.cpp:305] Starting prefetch of epoch 50
I0916 15:41:30.909945 19004 solver.cpp:314] Iteration 97200 (4.87367 iter/s, 20.5184s/100 iter), loss = 0.0572993
I0916 15:41:30.909986 19004 solver.cpp:336]     Train net output #0: loss = 0.057299 (* 1 = 0.057299 loss)
I0916 15:41:30.909996 19004 sgd_solver.cpp:136] Iteration 97200, lr = 0.0001, m = 0.9
I0916 15:41:51.618135 19004 solver.cpp:314] Iteration 97300 (4.82914 iter/s, 20.7076s/100 iter), loss = 0.054188
I0916 15:41:51.618188 19004 solver.cpp:336]     Train net output #0: loss = 0.0541877 (* 1 = 0.0541877 loss)
I0916 15:41:51.618196 19004 sgd_solver.cpp:136] Iteration 97300, lr = 0.0001, m = 0.9
I0916 15:42:11.477900 19004 solver.cpp:314] Iteration 97400 (5.03545 iter/s, 19.8592s/100 iter), loss = 0.0699813
I0916 15:42:11.477927 19004 solver.cpp:336]     Train net output #0: loss = 0.0699809 (* 1 = 0.0699809 loss)
I0916 15:42:11.477933 19004 sgd_solver.cpp:136] Iteration 97400, lr = 0.0001, m = 0.9
I0916 15:42:31.598047 19004 solver.cpp:314] Iteration 97500 (4.97028 iter/s, 20.1196s/100 iter), loss = 0.0417105
I0916 15:42:31.598177 19004 solver.cpp:336]     Train net output #0: loss = 0.0417102 (* 1 = 0.0417102 loss)
I0916 15:42:31.598184 19004 sgd_solver.cpp:136] Iteration 97500, lr = 0.0001, m = 0.9
I0916 15:42:33.623893 18963 data_reader.cpp:305] Starting prefetch of epoch 70
I0916 15:42:51.687389 19004 solver.cpp:314] Iteration 97600 (4.9779 iter/s, 20.0888s/100 iter), loss = 0.0378237
I0916 15:42:51.687414 19004 solver.cpp:336]     Train net output #0: loss = 0.0378233 (* 1 = 0.0378233 loss)
I0916 15:42:51.687420 19004 sgd_solver.cpp:136] Iteration 97600, lr = 0.0001, m = 0.9
I0916 15:43:11.326692 19004 solver.cpp:314] Iteration 97700 (5.09197 iter/s, 19.6388s/100 iter), loss = 0.0611925
I0916 15:43:11.326776 19004 solver.cpp:336]     Train net output #0: loss = 0.0611922 (* 1 = 0.0611922 loss)
I0916 15:43:11.326781 19004 sgd_solver.cpp:136] Iteration 97700, lr = 0.0001, m = 0.9
I0916 15:43:31.489259 19004 solver.cpp:314] Iteration 97800 (4.95982 iter/s, 20.162s/100 iter), loss = 0.0566719
I0916 15:43:31.489285 19004 solver.cpp:336]     Train net output #0: loss = 0.0566716 (* 1 = 0.0566716 loss)
I0916 15:43:31.489290 19004 sgd_solver.cpp:136] Iteration 97800, lr = 0.0001, m = 0.9
I0916 15:43:39.757902 19012 data_reader.cpp:305] Starting prefetch of epoch 64
I0916 15:43:51.614150 19004 solver.cpp:314] Iteration 97900 (4.96911 iter/s, 20.1243s/100 iter), loss = 0.0654361
I0916 15:43:51.614215 19004 solver.cpp:336]     Train net output #0: loss = 0.0654358 (* 1 = 0.0654358 loss)
I0916 15:43:51.614223 19004 sgd_solver.cpp:136] Iteration 97900, lr = 0.0001, m = 0.9
I0916 15:44:11.644953 19004 solver.cpp:563] Iteration 98000, Testing net (#0)
I0916 15:44:19.534180 19018 data_reader.cpp:305] Starting prefetch of epoch 14
I0916 15:44:23.559996 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.956543
I0916 15:44:23.560077 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.999751
I0916 15:44:23.560087 19004 solver.cpp:655]     Test net output #2: loss = 0.194105 (* 1 = 0.194105 loss)
I0916 15:44:23.560106 19004 solver.cpp:265] [MultiGPU] Tests completed in 11.9148s
I0916 15:44:23.760543 19004 solver.cpp:314] Iteration 98000 (3.11086 iter/s, 32.1455s/100 iter), loss = 0.0593954
I0916 15:44:23.760571 19004 solver.cpp:336]     Train net output #0: loss = 0.0593951 (* 1 = 0.0593951 loss)
I0916 15:44:23.760576 19004 sgd_solver.cpp:136] Iteration 98000, lr = 0.0001, m = 0.9
I0916 15:44:43.538002 19004 solver.cpp:314] Iteration 98100 (5.0564 iter/s, 19.7769s/100 iter), loss = 0.0633077
I0916 15:44:43.538025 19004 solver.cpp:336]     Train net output #0: loss = 0.0633074 (* 1 = 0.0633074 loss)
I0916 15:44:43.538029 19004 sgd_solver.cpp:136] Iteration 98100, lr = 0.0001, m = 0.9
I0916 15:44:57.743309 19012 data_reader.cpp:305] Starting prefetch of epoch 65
I0916 15:45:03.597175 19004 solver.cpp:314] Iteration 98200 (4.98539 iter/s, 20.0586s/100 iter), loss = 0.0582459
I0916 15:45:03.597199 19004 solver.cpp:336]     Train net output #0: loss = 0.0582456 (* 1 = 0.0582456 loss)
I0916 15:45:03.597205 19004 sgd_solver.cpp:136] Iteration 98200, lr = 0.0001, m = 0.9
I0916 15:45:23.320041 19004 solver.cpp:314] Iteration 98300 (5.0704 iter/s, 19.7223s/100 iter), loss = 0.0481608
I0916 15:45:23.320066 19004 solver.cpp:336]     Train net output #0: loss = 0.0481605 (* 1 = 0.0481605 loss)
I0916 15:45:23.320072 19004 sgd_solver.cpp:136] Iteration 98300, lr = 0.0001, m = 0.9
I0916 15:45:43.093324 19004 solver.cpp:314] Iteration 98400 (5.05747 iter/s, 19.7727s/100 iter), loss = 0.0750258
I0916 15:45:43.093420 19004 solver.cpp:336]     Train net output #0: loss = 0.0750254 (* 1 = 0.0750254 loss)
I0916 15:45:43.093430 19004 sgd_solver.cpp:136] Iteration 98400, lr = 0.0001, m = 0.9
I0916 15:46:03.623010 19004 solver.cpp:314] Iteration 98500 (4.87113 iter/s, 20.5291s/100 iter), loss = 0.0454928
I0916 15:46:03.623037 19004 solver.cpp:336]     Train net output #0: loss = 0.0454925 (* 1 = 0.0454925 loss)
I0916 15:46:03.623044 19004 sgd_solver.cpp:136] Iteration 98500, lr = 0.0001, m = 0.9
I0916 15:46:04.041446 18963 data_reader.cpp:305] Starting prefetch of epoch 71
I0916 15:46:23.897758 19004 solver.cpp:314] Iteration 98600 (4.93238 iter/s, 20.2742s/100 iter), loss = 0.032107
I0916 15:46:23.912987 19004 solver.cpp:336]     Train net output #0: loss = 0.0321067 (* 1 = 0.0321067 loss)
I0916 15:46:23.913123 19004 sgd_solver.cpp:136] Iteration 98600, lr = 0.0001, m = 0.9
I0916 15:46:37.530881 18961 data_reader.cpp:305] Starting prefetch of epoch 50
I0916 15:46:44.121867 19004 solver.cpp:314] Iteration 98700 (4.94473 iter/s, 20.2235s/100 iter), loss = 0.0632007
I0916 15:46:44.121891 19004 solver.cpp:336]     Train net output #0: loss = 0.0632004 (* 1 = 0.0632004 loss)
I0916 15:46:44.121896 19004 sgd_solver.cpp:136] Iteration 98700, lr = 0.0001, m = 0.9
I0916 15:47:04.328456 19004 solver.cpp:314] Iteration 98800 (4.94902 iter/s, 20.206s/100 iter), loss = 0.0603946
I0916 15:47:04.328555 19004 solver.cpp:336]     Train net output #0: loss = 0.0603943 (* 1 = 0.0603943 loss)
I0916 15:47:04.328565 19004 sgd_solver.cpp:136] Iteration 98800, lr = 0.0001, m = 0.9
I0916 15:47:24.455206 19004 solver.cpp:314] Iteration 98900 (4.96865 iter/s, 20.1262s/100 iter), loss = 0.043346
I0916 15:47:24.455231 19004 solver.cpp:336]     Train net output #0: loss = 0.0433457 (* 1 = 0.0433457 loss)
I0916 15:47:24.455237 19004 sgd_solver.cpp:136] Iteration 98900, lr = 0.0001, m = 0.9
I0916 15:47:44.424839 19010 data_reader.cpp:305] Starting prefetch of epoch 58
I0916 15:47:44.775787 19004 solver.cpp:314] Iteration 99000 (4.92126 iter/s, 20.32s/100 iter), loss = 0.0525186
I0916 15:47:44.775812 19004 solver.cpp:336]     Train net output #0: loss = 0.0525183 (* 1 = 0.0525183 loss)
I0916 15:47:44.775816 19004 sgd_solver.cpp:136] Iteration 99000, lr = 0.0001, m = 0.9
I0916 15:48:05.363590 19004 solver.cpp:314] Iteration 99100 (4.85738 iter/s, 20.5872s/100 iter), loss = 0.0407078
I0916 15:48:05.363613 19004 solver.cpp:336]     Train net output #0: loss = 0.0407075 (* 1 = 0.0407075 loss)
I0916 15:48:05.363618 19004 sgd_solver.cpp:136] Iteration 99100, lr = 0.0001, m = 0.9
I0916 15:48:26.413138 19004 solver.cpp:314] Iteration 99200 (4.75083 iter/s, 21.049s/100 iter), loss = 0.0477201
I0916 15:48:26.413249 19004 solver.cpp:336]     Train net output #0: loss = 0.0477198 (* 1 = 0.0477198 loss)
I0916 15:48:26.413271 19004 sgd_solver.cpp:136] Iteration 99200, lr = 0.0001, m = 0.9
I0916 15:48:47.108069 19004 solver.cpp:314] Iteration 99300 (4.83224 iter/s, 20.6944s/100 iter), loss = 0.0521845
I0916 15:48:47.108098 19004 solver.cpp:336]     Train net output #0: loss = 0.0521842 (* 1 = 0.0521842 loss)
I0916 15:48:47.108104 19004 sgd_solver.cpp:136] Iteration 99300, lr = 0.0001, m = 0.9
I0916 15:48:52.850196 19012 data_reader.cpp:305] Starting prefetch of epoch 66
I0916 15:49:07.747457 19004 solver.cpp:314] Iteration 99400 (4.84524 iter/s, 20.6388s/100 iter), loss = 0.0645702
I0916 15:49:07.747519 19004 solver.cpp:336]     Train net output #0: loss = 0.0645699 (* 1 = 0.0645699 loss)
I0916 15:49:07.747529 19004 sgd_solver.cpp:136] Iteration 99400, lr = 0.0001, m = 0.9
I0916 15:49:27.545156 18961 data_reader.cpp:305] Starting prefetch of epoch 51
I0916 15:49:28.777509 19004 solver.cpp:314] Iteration 99500 (4.75524 iter/s, 21.0294s/100 iter), loss = 0.0928396
I0916 15:49:28.777556 19004 solver.cpp:336]     Train net output #0: loss = 0.0928393 (* 1 = 0.0928393 loss)
I0916 15:49:28.777566 19004 sgd_solver.cpp:136] Iteration 99500, lr = 0.0001, m = 0.9
I0916 15:49:49.367272 19004 solver.cpp:314] Iteration 99600 (4.85692 iter/s, 20.5892s/100 iter), loss = 0.0544635
I0916 15:49:49.367378 19004 solver.cpp:336]     Train net output #0: loss = 0.0544632 (* 1 = 0.0544632 loss)
I0916 15:49:49.367398 19004 sgd_solver.cpp:136] Iteration 99600, lr = 0.0001, m = 0.9
I0916 15:50:09.685906 19004 solver.cpp:314] Iteration 99700 (4.92173 iter/s, 20.3181s/100 iter), loss = 0.0289208
I0916 15:50:09.685955 19004 solver.cpp:336]     Train net output #0: loss = 0.0289204 (* 1 = 0.0289204 loss)
I0916 15:50:09.685961 19004 sgd_solver.cpp:136] Iteration 99700, lr = 0.0001, m = 0.9
I0916 15:50:30.136143 19004 solver.cpp:314] Iteration 99800 (4.89005 iter/s, 20.4497s/100 iter), loss = 0.0551108
I0916 15:50:30.136194 19004 solver.cpp:336]     Train net output #0: loss = 0.0551105 (* 1 = 0.0551105 loss)
I0916 15:50:30.136200 19004 sgd_solver.cpp:136] Iteration 99800, lr = 0.0001, m = 0.9
I0916 15:50:35.176682 18963 data_reader.cpp:305] Starting prefetch of epoch 72
I0916 15:50:51.135812 19004 solver.cpp:314] Iteration 99900 (4.76211 iter/s, 20.9991s/100 iter), loss = 0.0531411
I0916 15:50:51.135835 19004 solver.cpp:336]     Train net output #0: loss = 0.0531408 (* 1 = 0.0531408 loss)
I0916 15:50:51.135841 19004 sgd_solver.cpp:136] Iteration 99900, lr = 0.0001, m = 0.9
I0916 15:51:11.659313 19004 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/cityscapes5_jsegnet21v2_iter_100000.caffemodel
I0916 15:51:11.699100 19004 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/cityscapes5_jsegnet21v2_iter_100000.solverstate
I0916 15:51:11.703116 19004 solver.cpp:563] Iteration 100000, Testing net (#0)
I0916 15:51:14.959990 19029 data_reader.cpp:305] Starting prefetch of epoch 10
I0916 15:51:23.729624 19002 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 15:51:24.068823 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.956249
I0916 15:51:24.068845 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 15:51:24.068850 19004 solver.cpp:655]     Test net output #2: loss = 0.15544 (* 1 = 0.15544 loss)
I0916 15:51:24.068874 19004 solver.cpp:265] [MultiGPU] Tests completed in 12.3654s
I0916 15:51:24.278388 19004 solver.cpp:314] Iteration 100000 (3.01735 iter/s, 33.1416s/100 iter), loss = 0.042034
I0916 15:51:24.278409 19004 solver.cpp:336]     Train net output #0: loss = 0.0420337 (* 1 = 0.0420337 loss)
I0916 15:51:24.278414 19004 sgd_solver.cpp:136] Iteration 100000, lr = 0.0001, m = 0.9
I0916 15:51:44.847666 19004 solver.cpp:314] Iteration 100100 (4.86176 iter/s, 20.5687s/100 iter), loss = 0.0556361
I0916 15:51:44.847713 19004 solver.cpp:336]     Train net output #0: loss = 0.0556358 (* 1 = 0.0556358 loss)
I0916 15:51:44.847720 19004 sgd_solver.cpp:136] Iteration 100100, lr = 0.0001, m = 0.9
I0916 15:52:05.455811 19004 solver.cpp:314] Iteration 100200 (4.85259 iter/s, 20.6076s/100 iter), loss = 0.055929
I0916 15:52:05.455833 19004 solver.cpp:336]     Train net output #0: loss = 0.0559287 (* 1 = 0.0559287 loss)
I0916 15:52:05.455840 19004 sgd_solver.cpp:136] Iteration 100200, lr = 0.0001, m = 0.9
I0916 15:52:26.030958 19004 solver.cpp:314] Iteration 100300 (4.86037 iter/s, 20.5746s/100 iter), loss = 0.0792383
I0916 15:52:26.031054 19004 solver.cpp:336]     Train net output #0: loss = 0.079238 (* 1 = 0.079238 loss)
I0916 15:52:26.031061 19004 sgd_solver.cpp:136] Iteration 100300, lr = 0.0001, m = 0.9
I0916 15:52:30.300700 19012 data_reader.cpp:305] Starting prefetch of epoch 67
I0916 15:52:46.558122 19004 solver.cpp:314] Iteration 100400 (4.87173 iter/s, 20.5266s/100 iter), loss = 0.052178
I0916 15:52:46.558208 19004 solver.cpp:336]     Train net output #0: loss = 0.0521776 (* 1 = 0.0521776 loss)
I0916 15:52:46.558230 19004 sgd_solver.cpp:136] Iteration 100400, lr = 0.0001, m = 0.9
I0916 15:53:07.182088 19004 solver.cpp:314] Iteration 100500 (4.84887 iter/s, 20.6234s/100 iter), loss = 0.0591837
I0916 15:53:07.182139 19004 solver.cpp:336]     Train net output #0: loss = 0.0591833 (* 1 = 0.0591833 loss)
I0916 15:53:07.182145 19004 sgd_solver.cpp:136] Iteration 100500, lr = 0.0001, m = 0.9
I0916 15:53:27.719674 19004 solver.cpp:314] Iteration 100600 (4.86926 iter/s, 20.537s/100 iter), loss = 0.0427292
I0916 15:53:27.719919 19004 solver.cpp:336]     Train net output #0: loss = 0.0427289 (* 1 = 0.0427289 loss)
I0916 15:53:27.739758 19004 sgd_solver.cpp:136] Iteration 100600, lr = 0.0001, m = 0.9
I0916 15:53:37.777509 19012 data_reader.cpp:305] Starting prefetch of epoch 68
I0916 15:53:47.394246 19004 solver.cpp:314] Iteration 100700 (5.08285 iter/s, 19.674s/100 iter), loss = 0.0438952
I0916 15:53:47.394312 19004 solver.cpp:336]     Train net output #0: loss = 0.0438949 (* 1 = 0.0438949 loss)
I0916 15:53:47.394330 19004 sgd_solver.cpp:136] Iteration 100700, lr = 0.0001, m = 0.9
I0916 15:54:07.966603 19004 solver.cpp:314] Iteration 100800 (4.86103 iter/s, 20.5718s/100 iter), loss = 0.0510042
I0916 15:54:07.966686 19004 solver.cpp:336]     Train net output #0: loss = 0.0510039 (* 1 = 0.0510039 loss)
I0916 15:54:07.966694 19004 sgd_solver.cpp:136] Iteration 100800, lr = 0.0001, m = 0.9
I0916 15:54:11.312304 18961 data_reader.cpp:305] Starting prefetch of epoch 52
I0916 15:54:28.696358 19004 solver.cpp:314] Iteration 100900 (4.82412 iter/s, 20.7292s/100 iter), loss = 0.052229
I0916 15:54:28.696379 19004 solver.cpp:336]     Train net output #0: loss = 0.0522287 (* 1 = 0.0522287 loss)
I0916 15:54:28.696383 19004 sgd_solver.cpp:136] Iteration 100900, lr = 0.0001, m = 0.9
I0916 15:54:48.881439 19004 solver.cpp:314] Iteration 101000 (4.9543 iter/s, 20.1845s/100 iter), loss = 0.0551975
I0916 15:54:48.881583 19004 solver.cpp:336]     Train net output #0: loss = 0.0551971 (* 1 = 0.0551971 loss)
I0916 15:54:48.881608 19004 sgd_solver.cpp:136] Iteration 101000, lr = 0.0001, m = 0.9
I0916 15:55:09.206717 19004 solver.cpp:314] Iteration 101100 (4.92012 iter/s, 20.3247s/100 iter), loss = 0.0494573
I0916 15:55:09.206746 19004 solver.cpp:336]     Train net output #0: loss = 0.049457 (* 1 = 0.049457 loss)
I0916 15:55:09.206753 19004 sgd_solver.cpp:136] Iteration 101100, lr = 0.0001, m = 0.9
I0916 15:55:18.713642 18963 data_reader.cpp:305] Starting prefetch of epoch 73
I0916 15:55:29.751674 19004 solver.cpp:314] Iteration 101200 (4.86751 iter/s, 20.5444s/100 iter), loss = 0.0694868
I0916 15:55:29.751749 19004 solver.cpp:336]     Train net output #0: loss = 0.0694865 (* 1 = 0.0694865 loss)
I0916 15:55:29.751756 19004 sgd_solver.cpp:136] Iteration 101200, lr = 0.0001, m = 0.9
I0916 15:55:50.401077 19004 solver.cpp:314] Iteration 101300 (4.84289 iter/s, 20.6488s/100 iter), loss = 0.0478795
I0916 15:55:50.401098 19004 solver.cpp:336]     Train net output #0: loss = 0.0478792 (* 1 = 0.0478792 loss)
I0916 15:55:50.401101 19004 sgd_solver.cpp:136] Iteration 101300, lr = 0.0001, m = 0.9
I0916 15:56:10.395149 19004 solver.cpp:314] Iteration 101400 (5.00162 iter/s, 19.9935s/100 iter), loss = 0.0523385
I0916 15:56:10.395236 19004 solver.cpp:336]     Train net output #0: loss = 0.0523382 (* 1 = 0.0523382 loss)
I0916 15:56:10.395243 19004 sgd_solver.cpp:136] Iteration 101400, lr = 0.0001, m = 0.9
I0916 15:56:26.266547 19012 data_reader.cpp:305] Starting prefetch of epoch 69
I0916 15:56:30.970069 19004 solver.cpp:314] Iteration 101500 (4.86043 iter/s, 20.5743s/100 iter), loss = 0.0496339
I0916 15:56:30.970115 19004 solver.cpp:336]     Train net output #0: loss = 0.0496336 (* 1 = 0.0496336 loss)
I0916 15:56:30.970124 19004 sgd_solver.cpp:136] Iteration 101500, lr = 0.0001, m = 0.9
I0916 15:56:51.685415 19004 solver.cpp:314] Iteration 101600 (4.82747 iter/s, 20.7148s/100 iter), loss = 0.061387
I0916 15:56:51.685461 19004 solver.cpp:336]     Train net output #0: loss = 0.0613867 (* 1 = 0.0613867 loss)
I0916 15:56:51.685467 19004 sgd_solver.cpp:136] Iteration 101600, lr = 0.0001, m = 0.9
I0916 15:57:11.750269 19004 solver.cpp:314] Iteration 101700 (4.98398 iter/s, 20.0643s/100 iter), loss = 0.0576828
I0916 15:57:11.750303 19004 solver.cpp:336]     Train net output #0: loss = 0.0576825 (* 1 = 0.0576825 loss)
I0916 15:57:11.750309 19004 sgd_solver.cpp:136] Iteration 101700, lr = 0.0001, m = 0.9
I0916 15:57:31.867317 19004 solver.cpp:314] Iteration 101800 (4.97105 iter/s, 20.1165s/100 iter), loss = 0.0555962
I0916 15:57:31.867380 19004 solver.cpp:336]     Train net output #0: loss = 0.0555958 (* 1 = 0.0555958 loss)
I0916 15:57:31.867388 19004 sgd_solver.cpp:136] Iteration 101800, lr = 0.0001, m = 0.9
I0916 15:57:33.510318 18963 data_reader.cpp:305] Starting prefetch of epoch 74
I0916 15:57:52.204571 19004 solver.cpp:314] Iteration 101900 (4.91722 iter/s, 20.3367s/100 iter), loss = 0.046495
I0916 15:57:52.204593 19004 solver.cpp:336]     Train net output #0: loss = 0.0464947 (* 1 = 0.0464947 loss)
I0916 15:57:52.204597 19004 sgd_solver.cpp:136] Iteration 101900, lr = 0.0001, m = 0.9
I0916 15:58:07.287257 19008 data_reader.cpp:305] Starting prefetch of epoch 51
I0916 15:58:12.556103 19004 solver.cpp:563] Iteration 102000, Testing net (#0)
I0916 15:58:24.723395 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.956717
I0916 15:58:24.723417 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.999754
I0916 15:58:24.723422 19004 solver.cpp:655]     Test net output #2: loss = 0.191356 (* 1 = 0.191356 loss)
I0916 15:58:24.723446 19004 solver.cpp:265] [MultiGPU] Tests completed in 12.167s
I0916 15:58:24.941925 19004 solver.cpp:314] Iteration 102000 (3.0547 iter/s, 32.7364s/100 iter), loss = 0.0478463
I0916 15:58:24.941951 19004 solver.cpp:336]     Train net output #0: loss = 0.0478459 (* 1 = 0.0478459 loss)
I0916 15:58:24.941956 19004 sgd_solver.cpp:136] Iteration 102000, lr = 0.0001, m = 0.9
I0916 15:58:45.252625 19004 solver.cpp:314] Iteration 102100 (4.92365 iter/s, 20.3101s/100 iter), loss = 0.0793697
I0916 15:58:45.252696 19004 solver.cpp:336]     Train net output #0: loss = 0.0793693 (* 1 = 0.0793693 loss)
I0916 15:58:45.252702 19004 sgd_solver.cpp:136] Iteration 102100, lr = 0.0001, m = 0.9
I0916 15:58:52.811408 19012 data_reader.cpp:305] Starting prefetch of epoch 70
I0916 15:59:05.572989 19004 solver.cpp:314] Iteration 102200 (4.92131 iter/s, 20.3198s/100 iter), loss = 0.0618823
I0916 15:59:05.573014 19004 solver.cpp:336]     Train net output #0: loss = 0.061882 (* 1 = 0.061882 loss)
I0916 15:59:05.573019 19004 sgd_solver.cpp:136] Iteration 102200, lr = 0.0001, m = 0.9
I0916 15:59:25.908679 19004 solver.cpp:314] Iteration 102300 (4.9176 iter/s, 20.3351s/100 iter), loss = 0.115264
I0916 15:59:25.908780 19004 solver.cpp:336]     Train net output #0: loss = 0.115264 (* 1 = 0.115264 loss)
I0916 15:59:25.908787 19004 sgd_solver.cpp:136] Iteration 102300, lr = 0.0001, m = 0.9
I0916 15:59:46.033073 19004 solver.cpp:314] Iteration 102400 (4.96923 iter/s, 20.1238s/100 iter), loss = 0.0428394
I0916 15:59:46.033102 19004 solver.cpp:336]     Train net output #0: loss = 0.042839 (* 1 = 0.042839 loss)
I0916 15:59:46.033108 19004 sgd_solver.cpp:136] Iteration 102400, lr = 0.0001, m = 0.9
I0916 15:59:59.732333 19012 data_reader.cpp:305] Starting prefetch of epoch 71
I0916 16:00:06.021898 19004 solver.cpp:314] Iteration 102500 (5.00294 iter/s, 19.9883s/100 iter), loss = 0.0596843
I0916 16:00:06.021939 19004 solver.cpp:336]     Train net output #0: loss = 0.059684 (* 1 = 0.059684 loss)
I0916 16:00:06.021944 19004 sgd_solver.cpp:136] Iteration 102500, lr = 0.0001, m = 0.9
I0916 16:00:26.650490 19004 solver.cpp:314] Iteration 102600 (4.84778 iter/s, 20.628s/100 iter), loss = 0.0647461
I0916 16:00:26.650538 19004 solver.cpp:336]     Train net output #0: loss = 0.0647457 (* 1 = 0.0647457 loss)
I0916 16:00:26.650553 19004 sgd_solver.cpp:136] Iteration 102600, lr = 0.0001, m = 0.9
I0916 16:00:33.585929 19008 data_reader.cpp:305] Starting prefetch of epoch 52
I0916 16:00:46.704324 19004 solver.cpp:314] Iteration 102700 (4.98672 iter/s, 20.0533s/100 iter), loss = 0.086209
I0916 16:00:46.704349 19004 solver.cpp:336]     Train net output #0: loss = 0.0862087 (* 1 = 0.0862087 loss)
I0916 16:00:46.704355 19004 sgd_solver.cpp:136] Iteration 102700, lr = 0.0001, m = 0.9
I0916 16:01:06.884836 19004 solver.cpp:314] Iteration 102800 (4.95542 iter/s, 20.1799s/100 iter), loss = 0.0451366
I0916 16:01:06.884937 19004 solver.cpp:336]     Train net output #0: loss = 0.0451363 (* 1 = 0.0451363 loss)
I0916 16:01:06.884966 19004 sgd_solver.cpp:136] Iteration 102800, lr = 0.0001, m = 0.9
I0916 16:01:27.386687 19004 solver.cpp:314] Iteration 102900 (4.87775 iter/s, 20.5013s/100 iter), loss = 0.0574126
I0916 16:01:27.386711 19004 solver.cpp:336]     Train net output #0: loss = 0.0574123 (* 1 = 0.0574123 loss)
I0916 16:01:27.386715 19004 sgd_solver.cpp:136] Iteration 102900, lr = 0.0001, m = 0.9
I0916 16:01:40.412576 19007 data_reader.cpp:305] Starting prefetch of epoch 68
I0916 16:01:47.380842 19004 solver.cpp:314] Iteration 103000 (5.0016 iter/s, 19.9936s/100 iter), loss = 0.0459803
I0916 16:01:47.380869 19004 solver.cpp:336]     Train net output #0: loss = 0.04598 (* 1 = 0.04598 loss)
I0916 16:01:47.380874 19004 sgd_solver.cpp:136] Iteration 103000, lr = 0.0001, m = 0.9
I0916 16:02:07.310602 19004 solver.cpp:314] Iteration 103100 (5.01777 iter/s, 19.9292s/100 iter), loss = 0.0545044
I0916 16:02:07.310657 19004 solver.cpp:336]     Train net output #0: loss = 0.0545041 (* 1 = 0.0545041 loss)
I0916 16:02:07.310674 19004 sgd_solver.cpp:136] Iteration 103100, lr = 0.0001, m = 0.9
I0916 16:02:27.388993 19004 solver.cpp:314] Iteration 103200 (4.98062 iter/s, 20.0778s/100 iter), loss = 0.0680318
I0916 16:02:27.390099 19004 solver.cpp:336]     Train net output #0: loss = 0.0680315 (* 1 = 0.0680315 loss)
I0916 16:02:27.390108 19004 sgd_solver.cpp:136] Iteration 103200, lr = 0.0001, m = 0.9
I0916 16:02:46.422718 18963 data_reader.cpp:305] Starting prefetch of epoch 75
I0916 16:02:47.390877 19004 solver.cpp:314] Iteration 103300 (4.99967 iter/s, 20.0013s/100 iter), loss = 0.0605355
I0916 16:02:47.390905 19004 solver.cpp:336]     Train net output #0: loss = 0.0605352 (* 1 = 0.0605352 loss)
I0916 16:02:47.390911 19004 sgd_solver.cpp:136] Iteration 103300, lr = 0.0001, m = 0.9
I0916 16:03:07.189988 19004 solver.cpp:314] Iteration 103400 (5.05088 iter/s, 19.7985s/100 iter), loss = 0.0413179
I0916 16:03:07.190042 19004 solver.cpp:336]     Train net output #0: loss = 0.0413175 (* 1 = 0.0413175 loss)
I0916 16:03:07.190048 19004 sgd_solver.cpp:136] Iteration 103400, lr = 0.0001, m = 0.9
I0916 16:03:19.376628 19008 data_reader.cpp:305] Starting prefetch of epoch 53
I0916 16:03:27.699797 19004 solver.cpp:314] Iteration 103500 (4.87585 iter/s, 20.5092s/100 iter), loss = 0.0760004
I0916 16:03:27.699822 19004 solver.cpp:336]     Train net output #0: loss = 0.0760001 (* 1 = 0.0760001 loss)
I0916 16:03:27.699827 19004 sgd_solver.cpp:136] Iteration 103500, lr = 0.0001, m = 0.9
I0916 16:03:47.912628 19004 solver.cpp:314] Iteration 103600 (4.94749 iter/s, 20.2122s/100 iter), loss = 0.0537458
I0916 16:03:47.912750 19004 solver.cpp:336]     Train net output #0: loss = 0.0537455 (* 1 = 0.0537455 loss)
I0916 16:03:47.912773 19004 sgd_solver.cpp:136] Iteration 103600, lr = 0.0001, m = 0.9
I0916 16:04:07.949609 19004 solver.cpp:314] Iteration 103700 (4.99091 iter/s, 20.0364s/100 iter), loss = 0.0510182
I0916 16:04:07.949633 19004 solver.cpp:336]     Train net output #0: loss = 0.0510178 (* 1 = 0.0510178 loss)
I0916 16:04:07.949637 19004 sgd_solver.cpp:136] Iteration 103700, lr = 0.0001, m = 0.9
I0916 16:04:26.331212 18963 data_reader.cpp:305] Starting prefetch of epoch 76
I0916 16:04:28.034351 19004 solver.cpp:314] Iteration 103800 (4.97905 iter/s, 20.0842s/100 iter), loss = 0.0696524
I0916 16:04:28.034376 19004 solver.cpp:336]     Train net output #0: loss = 0.0696521 (* 1 = 0.0696521 loss)
I0916 16:04:28.034382 19004 sgd_solver.cpp:136] Iteration 103800, lr = 0.0001, m = 0.9
I0916 16:04:48.914438 19004 solver.cpp:314] Iteration 103900 (4.78939 iter/s, 20.8795s/100 iter), loss = 0.0476474
I0916 16:04:48.914605 19004 solver.cpp:336]     Train net output #0: loss = 0.0476471 (* 1 = 0.0476471 loss)
I0916 16:04:48.914643 19004 sgd_solver.cpp:136] Iteration 103900, lr = 0.0001, m = 0.9
I0916 16:05:09.822255 19004 solver.cpp:563] Iteration 104000, Testing net (#0)
I0916 16:05:14.079288 19002 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 16:05:22.781576 19002 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 16:05:23.181008 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.956316
I0916 16:05:23.181037 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 16:05:23.181044 19004 solver.cpp:655]     Test net output #2: loss = 0.155449 (* 1 = 0.155449 loss)
I0916 16:05:23.181084 19004 solver.cpp:265] [MultiGPU] Tests completed in 13.3584s
I0916 16:05:23.399471 19004 solver.cpp:314] Iteration 104000 (2.89989 iter/s, 34.4841s/100 iter), loss = 0.0598233
I0916 16:05:23.399510 19004 solver.cpp:336]     Train net output #0: loss = 0.0598229 (* 1 = 0.0598229 loss)
I0916 16:05:23.399518 19004 sgd_solver.cpp:136] Iteration 104000, lr = 0.0001, m = 0.9
I0916 16:05:43.756834 19004 solver.cpp:314] Iteration 104100 (4.91237 iter/s, 20.3568s/100 iter), loss = 0.0631899
I0916 16:05:43.756912 19004 solver.cpp:336]     Train net output #0: loss = 0.0631896 (* 1 = 0.0631896 loss)
I0916 16:05:43.756919 19004 sgd_solver.cpp:136] Iteration 104100, lr = 0.0001, m = 0.9
I0916 16:06:04.531744 19004 solver.cpp:314] Iteration 104200 (4.81364 iter/s, 20.7743s/100 iter), loss = 0.0563262
I0916 16:06:04.531772 19004 solver.cpp:336]     Train net output #0: loss = 0.0563258 (* 1 = 0.0563258 loss)
I0916 16:06:04.531780 19004 sgd_solver.cpp:136] Iteration 104200, lr = 0.0001, m = 0.9
I0916 16:06:22.419035 19010 data_reader.cpp:305] Starting prefetch of epoch 59
I0916 16:06:25.105048 19004 solver.cpp:314] Iteration 104300 (4.86081 iter/s, 20.5727s/100 iter), loss = 0.064645
I0916 16:06:25.105072 19004 solver.cpp:336]     Train net output #0: loss = 0.0646447 (* 1 = 0.0646447 loss)
I0916 16:06:25.105077 19004 sgd_solver.cpp:136] Iteration 104300, lr = 0.0001, m = 0.9
I0916 16:06:45.163295 19004 solver.cpp:314] Iteration 104400 (4.98562 iter/s, 20.0577s/100 iter), loss = 0.046777
I0916 16:06:45.163318 19004 solver.cpp:336]     Train net output #0: loss = 0.0467767 (* 1 = 0.0467767 loss)
I0916 16:06:45.163324 19004 sgd_solver.cpp:136] Iteration 104400, lr = 0.0001, m = 0.9
I0916 16:07:05.831179 19004 solver.cpp:314] Iteration 104500 (4.83856 iter/s, 20.6673s/100 iter), loss = 0.0521893
I0916 16:07:05.831270 19004 solver.cpp:336]     Train net output #0: loss = 0.0521889 (* 1 = 0.0521889 loss)
I0916 16:07:05.831287 19004 sgd_solver.cpp:136] Iteration 104500, lr = 0.0001, m = 0.9
I0916 16:07:26.659301 19004 solver.cpp:314] Iteration 104600 (4.80133 iter/s, 20.8275s/100 iter), loss = 0.0606719
I0916 16:07:26.659329 19004 solver.cpp:336]     Train net output #0: loss = 0.0606716 (* 1 = 0.0606716 loss)
I0916 16:07:26.659335 19004 sgd_solver.cpp:136] Iteration 104600, lr = 0.0001, m = 0.9
I0916 16:07:30.112654 19010 data_reader.cpp:305] Starting prefetch of epoch 60
I0916 16:07:46.936653 19004 solver.cpp:314] Iteration 104700 (4.93175 iter/s, 20.2768s/100 iter), loss = 0.0439886
I0916 16:07:46.936702 19004 solver.cpp:336]     Train net output #0: loss = 0.0439883 (* 1 = 0.0439883 loss)
I0916 16:07:46.936708 19004 sgd_solver.cpp:136] Iteration 104700, lr = 0.0001, m = 0.9
I0916 16:08:03.950237 18961 data_reader.cpp:305] Starting prefetch of epoch 53
I0916 16:08:07.269234 19004 solver.cpp:314] Iteration 104800 (4.91835 iter/s, 20.332s/100 iter), loss = 0.0419414
I0916 16:08:07.269284 19004 solver.cpp:336]     Train net output #0: loss = 0.0419411 (* 1 = 0.0419411 loss)
I0916 16:08:07.269295 19004 sgd_solver.cpp:136] Iteration 104800, lr = 0.0001, m = 0.9
I0916 16:08:27.896430 19004 solver.cpp:314] Iteration 104900 (4.8481 iter/s, 20.6266s/100 iter), loss = 0.0585423
I0916 16:08:27.896488 19004 solver.cpp:336]     Train net output #0: loss = 0.058542 (* 1 = 0.058542 loss)
I0916 16:08:27.896495 19004 sgd_solver.cpp:136] Iteration 104900, lr = 0.0001, m = 0.9
I0916 16:08:48.279486 19004 solver.cpp:314] Iteration 105000 (4.90617 iter/s, 20.3825s/100 iter), loss = 0.0479468
I0916 16:08:48.279512 19004 solver.cpp:336]     Train net output #0: loss = 0.0479465 (* 1 = 0.0479465 loss)
I0916 16:08:48.279520 19004 sgd_solver.cpp:136] Iteration 105000, lr = 0.0001, m = 0.9
I0916 16:09:08.651568 19004 solver.cpp:314] Iteration 105100 (4.90882 iter/s, 20.3715s/100 iter), loss = 0.0451906
I0916 16:09:08.651671 19004 solver.cpp:336]     Train net output #0: loss = 0.0451903 (* 1 = 0.0451903 loss)
I0916 16:09:08.651687 19004 sgd_solver.cpp:136] Iteration 105100, lr = 0.0001, m = 0.9
I0916 16:09:11.601294 18963 data_reader.cpp:305] Starting prefetch of epoch 77
I0916 16:09:29.834197 19004 solver.cpp:314] Iteration 105200 (4.72098 iter/s, 21.182s/100 iter), loss = 0.0535535
I0916 16:09:29.834224 19004 solver.cpp:336]     Train net output #0: loss = 0.0535532 (* 1 = 0.0535532 loss)
I0916 16:09:29.834230 19004 sgd_solver.cpp:136] Iteration 105200, lr = 0.0001, m = 0.9
I0916 16:09:50.291301 19004 solver.cpp:314] Iteration 105300 (4.88842 iter/s, 20.4565s/100 iter), loss = 0.0547128
I0916 16:09:50.292100 19004 solver.cpp:336]     Train net output #0: loss = 0.0547124 (* 1 = 0.0547124 loss)
I0916 16:09:50.292115 19004 sgd_solver.cpp:136] Iteration 105300, lr = 0.0001, m = 0.9
I0916 16:10:10.768612 19004 solver.cpp:314] Iteration 105400 (4.88359 iter/s, 20.4767s/100 iter), loss = 0.023967
I0916 16:10:10.768637 19004 solver.cpp:336]     Train net output #0: loss = 0.0239667 (* 1 = 0.0239667 loss)
I0916 16:10:10.768642 19004 sgd_solver.cpp:136] Iteration 105400, lr = 0.0001, m = 0.9
I0916 16:10:19.764709 19012 data_reader.cpp:305] Starting prefetch of epoch 72
I0916 16:10:31.389780 19004 solver.cpp:314] Iteration 105500 (4.84952 iter/s, 20.6206s/100 iter), loss = 0.0390666
I0916 16:10:31.389886 19004 solver.cpp:336]     Train net output #0: loss = 0.0390663 (* 1 = 0.0390663 loss)
I0916 16:10:31.389894 19004 sgd_solver.cpp:136] Iteration 105500, lr = 0.0001, m = 0.9
I0916 16:10:52.010586 19004 solver.cpp:314] Iteration 105600 (4.84961 iter/s, 20.6202s/100 iter), loss = 0.039198
I0916 16:10:52.010664 19004 solver.cpp:336]     Train net output #0: loss = 0.0391977 (* 1 = 0.0391977 loss)
I0916 16:10:52.010684 19004 sgd_solver.cpp:136] Iteration 105600, lr = 0.0001, m = 0.9
I0916 16:10:53.866907 18961 data_reader.cpp:305] Starting prefetch of epoch 54
I0916 16:11:12.389614 19004 solver.cpp:314] Iteration 105700 (4.90714 iter/s, 20.3785s/100 iter), loss = 0.0360625
I0916 16:11:12.389675 19004 solver.cpp:336]     Train net output #0: loss = 0.0360622 (* 1 = 0.0360622 loss)
I0916 16:11:12.389683 19004 sgd_solver.cpp:136] Iteration 105700, lr = 0.0001, m = 0.9
I0916 16:11:32.514328 19004 solver.cpp:314] Iteration 105800 (4.96915 iter/s, 20.1242s/100 iter), loss = 0.0506567
I0916 16:11:32.514364 19004 solver.cpp:336]     Train net output #0: loss = 0.0506564 (* 1 = 0.0506564 loss)
I0916 16:11:32.514371 19004 sgd_solver.cpp:136] Iteration 105800, lr = 0.0001, m = 0.9
I0916 16:11:53.128765 19004 solver.cpp:314] Iteration 105900 (4.8511 iter/s, 20.6139s/100 iter), loss = 0.032452
I0916 16:11:53.129221 19004 solver.cpp:336]     Train net output #0: loss = 0.0324517 (* 1 = 0.0324517 loss)
I0916 16:11:53.129235 19004 sgd_solver.cpp:136] Iteration 105900, lr = 0.0001, m = 0.9
I0916 16:12:01.627450 19010 data_reader.cpp:305] Starting prefetch of epoch 61
I0916 16:12:13.612278 19004 solver.cpp:563] Iteration 106000, Testing net (#0)
I0916 16:12:26.314394 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.956631
I0916 16:12:26.314481 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.999746
I0916 16:12:26.314486 19004 solver.cpp:655]     Test net output #2: loss = 0.19217 (* 1 = 0.19217 loss)
I0916 16:12:26.314512 19004 solver.cpp:265] [MultiGPU] Tests completed in 12.7019s
I0916 16:12:26.530537 19004 solver.cpp:314] Iteration 106000 (2.99394 iter/s, 33.4008s/100 iter), loss = 0.0662408
I0916 16:12:26.530639 19004 solver.cpp:336]     Train net output #0: loss = 0.0662404 (* 1 = 0.0662404 loss)
I0916 16:12:26.530664 19004 sgd_solver.cpp:136] Iteration 106000, lr = 0.0001, m = 0.9
I0916 16:12:46.439471 19004 solver.cpp:314] Iteration 106100 (5.02301 iter/s, 19.9084s/100 iter), loss = 0.0259577
I0916 16:12:46.439499 19004 solver.cpp:336]     Train net output #0: loss = 0.0259574 (* 1 = 0.0259574 loss)
I0916 16:12:46.439505 19004 sgd_solver.cpp:136] Iteration 106100, lr = 0.0001, m = 0.9
I0916 16:12:47.490658 19010 data_reader.cpp:305] Starting prefetch of epoch 62
I0916 16:13:07.163223 19004 solver.cpp:314] Iteration 106200 (4.82552 iter/s, 20.7232s/100 iter), loss = 0.0588315
I0916 16:13:07.163338 19004 solver.cpp:336]     Train net output #0: loss = 0.0588311 (* 1 = 0.0588311 loss)
I0916 16:13:07.163365 19004 sgd_solver.cpp:136] Iteration 106200, lr = 0.0001, m = 0.9
I0916 16:13:27.596580 19004 solver.cpp:314] Iteration 106300 (4.8941 iter/s, 20.4328s/100 iter), loss = 0.0736049
I0916 16:13:27.596647 19004 solver.cpp:336]     Train net output #0: loss = 0.0736046 (* 1 = 0.0736046 loss)
I0916 16:13:27.596669 19004 sgd_solver.cpp:136] Iteration 106300, lr = 0.0001, m = 0.9
I0916 16:13:47.533643 19004 solver.cpp:314] Iteration 106400 (5.01593 iter/s, 19.9365s/100 iter), loss = 0.0480252
I0916 16:13:47.533689 19004 solver.cpp:336]     Train net output #0: loss = 0.0480249 (* 1 = 0.0480249 loss)
I0916 16:13:47.533696 19004 sgd_solver.cpp:136] Iteration 106400, lr = 0.0001, m = 0.9
I0916 16:13:54.956434 19012 data_reader.cpp:305] Starting prefetch of epoch 73
I0916 16:14:08.556210 19004 solver.cpp:314] Iteration 106500 (4.75693 iter/s, 21.022s/100 iter), loss = 0.0392958
I0916 16:14:08.556263 19004 solver.cpp:336]     Train net output #0: loss = 0.0392954 (* 1 = 0.0392954 loss)
I0916 16:14:08.556275 19004 sgd_solver.cpp:136] Iteration 106500, lr = 0.0001, m = 0.9
I0916 16:14:28.977916 19004 solver.cpp:314] Iteration 106600 (4.89689 iter/s, 20.4211s/100 iter), loss = 0.0474557
I0916 16:14:28.977991 19004 solver.cpp:336]     Train net output #0: loss = 0.0474553 (* 1 = 0.0474553 loss)
I0916 16:14:28.977998 19004 sgd_solver.cpp:136] Iteration 106600, lr = 0.0001, m = 0.9
I0916 16:14:29.205706 18963 data_reader.cpp:305] Starting prefetch of epoch 78
I0916 16:14:48.992615 19004 solver.cpp:314] Iteration 106700 (4.99647 iter/s, 20.0141s/100 iter), loss = 0.0481098
I0916 16:14:48.992640 19004 solver.cpp:336]     Train net output #0: loss = 0.0481095 (* 1 = 0.0481095 loss)
I0916 16:14:48.992645 19004 sgd_solver.cpp:136] Iteration 106700, lr = 0.0001, m = 0.9
I0916 16:15:08.857445 19004 solver.cpp:314] Iteration 106800 (5.03417 iter/s, 19.8643s/100 iter), loss = 0.0568861
I0916 16:15:08.857554 19004 solver.cpp:336]     Train net output #0: loss = 0.0568858 (* 1 = 0.0568858 loss)
I0916 16:15:08.857569 19004 sgd_solver.cpp:136] Iteration 106800, lr = 0.0001, m = 0.9
I0916 16:15:28.885907 19004 solver.cpp:314] Iteration 106900 (4.99304 iter/s, 20.0279s/100 iter), loss = 0.0290014
I0916 16:15:28.885980 19004 solver.cpp:336]     Train net output #0: loss = 0.0290011 (* 1 = 0.0290011 loss)
I0916 16:15:28.885996 19004 sgd_solver.cpp:136] Iteration 106900, lr = 0.0001, m = 0.9
I0916 16:15:35.385184 18963 data_reader.cpp:305] Starting prefetch of epoch 79
I0916 16:15:49.368435 19004 solver.cpp:314] Iteration 107000 (4.88235 iter/s, 20.482s/100 iter), loss = 0.0585538
I0916 16:15:49.368489 19004 solver.cpp:336]     Train net output #0: loss = 0.0585535 (* 1 = 0.0585535 loss)
I0916 16:15:49.368495 19004 sgd_solver.cpp:136] Iteration 107000, lr = 0.0001, m = 0.9
I0916 16:16:09.245507 19004 solver.cpp:314] Iteration 107100 (5.03106 iter/s, 19.8765s/100 iter), loss = 0.0445427
I0916 16:16:09.245533 19004 solver.cpp:336]     Train net output #0: loss = 0.0445423 (* 1 = 0.0445423 loss)
I0916 16:16:09.245539 19004 sgd_solver.cpp:136] Iteration 107100, lr = 0.0001, m = 0.9
I0916 16:16:29.679343 19004 solver.cpp:314] Iteration 107200 (4.89398 iter/s, 20.4333s/100 iter), loss = 0.0561912
I0916 16:16:29.679400 19004 solver.cpp:336]     Train net output #0: loss = 0.0561908 (* 1 = 0.0561908 loss)
I0916 16:16:29.679407 19004 sgd_solver.cpp:136] Iteration 107200, lr = 0.0001, m = 0.9
I0916 16:16:42.472653 19012 data_reader.cpp:305] Starting prefetch of epoch 74
I0916 16:16:49.990216 19004 solver.cpp:314] Iteration 107300 (4.92361 iter/s, 20.3103s/100 iter), loss = 0.0497623
I0916 16:16:49.990255 19004 solver.cpp:336]     Train net output #0: loss = 0.0497619 (* 1 = 0.0497619 loss)
I0916 16:16:49.990267 19004 sgd_solver.cpp:136] Iteration 107300, lr = 0.0001, m = 0.9
I0916 16:17:09.864794 19004 solver.cpp:314] Iteration 107400 (5.03169 iter/s, 19.874s/100 iter), loss = 0.0645346
I0916 16:17:09.864843 19004 solver.cpp:336]     Train net output #0: loss = 0.0645343 (* 1 = 0.0645343 loss)
I0916 16:17:09.864848 19004 sgd_solver.cpp:136] Iteration 107400, lr = 0.0001, m = 0.9
I0916 16:17:15.347136 19008 data_reader.cpp:305] Starting prefetch of epoch 54
I0916 16:17:30.032866 19004 solver.cpp:314] Iteration 107500 (4.95847 iter/s, 20.1675s/100 iter), loss = 0.0466978
I0916 16:17:30.032888 19004 solver.cpp:336]     Train net output #0: loss = 0.0466975 (* 1 = 0.0466975 loss)
I0916 16:17:30.032892 19004 sgd_solver.cpp:136] Iteration 107500, lr = 0.0001, m = 0.9
I0916 16:17:50.243311 19004 solver.cpp:314] Iteration 107600 (4.94808 iter/s, 20.2099s/100 iter), loss = 0.048678
I0916 16:17:50.243584 19004 solver.cpp:336]     Train net output #0: loss = 0.0486777 (* 1 = 0.0486777 loss)
I0916 16:17:50.243605 19004 sgd_solver.cpp:136] Iteration 107600, lr = 0.0001, m = 0.9
I0916 16:18:10.777269 19004 solver.cpp:314] Iteration 107700 (4.87012 iter/s, 20.5334s/100 iter), loss = 0.0389895
I0916 16:18:10.777295 19004 solver.cpp:336]     Train net output #0: loss = 0.0389892 (* 1 = 0.0389892 loss)
I0916 16:18:10.777299 19004 sgd_solver.cpp:136] Iteration 107700, lr = 0.0001, m = 0.9
I0916 16:18:22.210901 19008 data_reader.cpp:305] Starting prefetch of epoch 55
I0916 16:18:30.672976 19004 solver.cpp:314] Iteration 107800 (5.02635 iter/s, 19.8951s/100 iter), loss = 0.030834
I0916 16:18:30.673001 19004 solver.cpp:336]     Train net output #0: loss = 0.0308337 (* 1 = 0.0308337 loss)
I0916 16:18:30.673004 19004 sgd_solver.cpp:136] Iteration 107800, lr = 0.0001, m = 0.9
I0916 16:18:50.653072 19004 solver.cpp:314] Iteration 107900 (5.00512 iter/s, 19.9795s/100 iter), loss = 0.0644519
I0916 16:18:50.653103 19004 solver.cpp:336]     Train net output #0: loss = 0.0644516 (* 1 = 0.0644516 loss)
I0916 16:18:50.653110 19004 sgd_solver.cpp:136] Iteration 107900, lr = 0.0001, m = 0.9
I0916 16:19:10.662040 19004 solver.cpp:563] Iteration 108000, Testing net (#0)
I0916 16:19:14.333744 19029 data_reader.cpp:305] Starting prefetch of epoch 11
I0916 16:19:22.664018 19002 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 16:19:23.020076 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.956481
I0916 16:19:23.020120 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 16:19:23.020133 19004 solver.cpp:655]     Test net output #2: loss = 0.155657 (* 1 = 0.155657 loss)
I0916 16:19:23.020170 19004 solver.cpp:265] [MultiGPU] Tests completed in 12.3578s
I0916 16:19:23.231250 19004 solver.cpp:314] Iteration 108000 (3.06963 iter/s, 32.5773s/100 iter), loss = 0.0462406
I0916 16:19:23.231273 19004 solver.cpp:336]     Train net output #0: loss = 0.0462403 (* 1 = 0.0462403 loss)
I0916 16:19:23.231277 19004 sgd_solver.cpp:136] Iteration 108000, lr = 0.0001, m = 0.9
I0916 16:19:42.905634 19004 solver.cpp:314] Iteration 108100 (5.0829 iter/s, 19.6738s/100 iter), loss = 0.048601
I0916 16:19:42.905730 19004 solver.cpp:336]     Train net output #0: loss = 0.0486007 (* 1 = 0.0486007 loss)
I0916 16:19:42.905745 19004 sgd_solver.cpp:136] Iteration 108100, lr = 0.0001, m = 0.9
I0916 16:20:03.111753 19004 solver.cpp:314] Iteration 108200 (4.94914 iter/s, 20.2055s/100 iter), loss = 0.0435218
I0916 16:20:03.111775 19004 solver.cpp:336]     Train net output #0: loss = 0.0435215 (* 1 = 0.0435215 loss)
I0916 16:20:03.111779 19004 sgd_solver.cpp:136] Iteration 108200, lr = 0.0001, m = 0.9
I0916 16:20:13.722592 19012 data_reader.cpp:305] Starting prefetch of epoch 75
I0916 16:20:23.047102 19004 solver.cpp:314] Iteration 108300 (5.01636 iter/s, 19.9348s/100 iter), loss = 0.0511423
I0916 16:20:23.047123 19004 solver.cpp:336]     Train net output #0: loss = 0.051142 (* 1 = 0.051142 loss)
I0916 16:20:23.047127 19004 sgd_solver.cpp:136] Iteration 108300, lr = 0.0001, m = 0.9
I0916 16:20:42.957442 19004 solver.cpp:314] Iteration 108400 (5.02266 iter/s, 19.9098s/100 iter), loss = 0.0518152
I0916 16:20:42.957465 19004 solver.cpp:336]     Train net output #0: loss = 0.0518149 (* 1 = 0.0518149 loss)
I0916 16:20:42.957471 19004 sgd_solver.cpp:136] Iteration 108400, lr = 0.0001, m = 0.9
I0916 16:21:03.398000 19004 solver.cpp:314] Iteration 108500 (4.89237 iter/s, 20.44s/100 iter), loss = 0.052137
I0916 16:21:03.398098 19004 solver.cpp:336]     Train net output #0: loss = 0.0521366 (* 1 = 0.0521366 loss)
I0916 16:21:03.398109 19004 sgd_solver.cpp:136] Iteration 108500, lr = 0.0001, m = 0.9
I0916 16:21:20.590014 18963 data_reader.cpp:305] Starting prefetch of epoch 80
I0916 16:21:24.015151 19004 solver.cpp:314] Iteration 108600 (4.85047 iter/s, 20.6166s/100 iter), loss = 0.0416491
I0916 16:21:24.015172 19004 solver.cpp:336]     Train net output #0: loss = 0.0416488 (* 1 = 0.0416488 loss)
I0916 16:21:24.015177 19004 sgd_solver.cpp:136] Iteration 108600, lr = 0.0001, m = 0.9
I0916 16:21:44.557803 19004 solver.cpp:314] Iteration 108700 (4.86806 iter/s, 20.5421s/100 iter), loss = 0.0555873
I0916 16:21:44.557873 19004 solver.cpp:336]     Train net output #0: loss = 0.055587 (* 1 = 0.055587 loss)
I0916 16:21:44.557878 19004 sgd_solver.cpp:136] Iteration 108700, lr = 0.0001, m = 0.9
I0916 16:21:54.343631 18961 data_reader.cpp:305] Starting prefetch of epoch 55
I0916 16:22:04.711398 19004 solver.cpp:314] Iteration 108800 (4.96203 iter/s, 20.153s/100 iter), loss = 0.0546217
I0916 16:22:04.711424 19004 solver.cpp:336]     Train net output #0: loss = 0.0546214 (* 1 = 0.0546214 loss)
I0916 16:22:04.711428 19004 sgd_solver.cpp:136] Iteration 108800, lr = 0.0001, m = 0.9
I0916 16:22:25.504143 19004 solver.cpp:314] Iteration 108900 (4.80951 iter/s, 20.7922s/100 iter), loss = 0.0430708
I0916 16:22:25.504225 19004 solver.cpp:336]     Train net output #0: loss = 0.0430705 (* 1 = 0.0430705 loss)
I0916 16:22:25.504326 19004 sgd_solver.cpp:136] Iteration 108900, lr = 0.0001, m = 0.9
I0916 16:22:46.424628 19004 solver.cpp:314] Iteration 109000 (4.78014 iter/s, 20.9199s/100 iter), loss = 0.0539738
I0916 16:22:46.424672 19004 solver.cpp:336]     Train net output #0: loss = 0.0539735 (* 1 = 0.0539735 loss)
I0916 16:22:46.424687 19004 sgd_solver.cpp:136] Iteration 109000, lr = 0.0001, m = 0.9
I0916 16:23:02.640224 19010 data_reader.cpp:305] Starting prefetch of epoch 63
I0916 16:23:06.650034 19004 solver.cpp:314] Iteration 109100 (4.94442 iter/s, 20.2248s/100 iter), loss = 0.0568815
I0916 16:23:06.650063 19004 solver.cpp:336]     Train net output #0: loss = 0.0568812 (* 1 = 0.0568812 loss)
I0916 16:23:06.650068 19004 sgd_solver.cpp:136] Iteration 109100, lr = 0.0001, m = 0.9
I0916 16:23:27.259109 19004 solver.cpp:314] Iteration 109200 (4.85237 iter/s, 20.6085s/100 iter), loss = 0.0665929
I0916 16:23:27.259140 19004 solver.cpp:336]     Train net output #0: loss = 0.0665926 (* 1 = 0.0665926 loss)
I0916 16:23:27.259146 19004 sgd_solver.cpp:136] Iteration 109200, lr = 0.0001, m = 0.9
I0916 16:23:47.987120 19004 solver.cpp:314] Iteration 109300 (4.82453 iter/s, 20.7274s/100 iter), loss = 0.0749908
I0916 16:23:47.987172 19004 solver.cpp:336]     Train net output #0: loss = 0.0749905 (* 1 = 0.0749905 loss)
I0916 16:23:47.987179 19004 sgd_solver.cpp:136] Iteration 109300, lr = 0.0001, m = 0.9
I0916 16:24:08.534464 19004 solver.cpp:314] Iteration 109400 (4.86695 iter/s, 20.5468s/100 iter), loss = 0.0774284
I0916 16:24:08.534725 19004 solver.cpp:336]     Train net output #0: loss = 0.0774281 (* 1 = 0.0774281 loss)
I0916 16:24:08.545328 19004 sgd_solver.cpp:136] Iteration 109400, lr = 0.0001, m = 0.9
I0916 16:24:10.639511 18963 data_reader.cpp:305] Starting prefetch of epoch 81
I0916 16:24:29.078860 19004 solver.cpp:314] Iteration 109500 (4.86764 iter/s, 20.5438s/100 iter), loss = 0.0393652
I0916 16:24:29.078913 19004 solver.cpp:336]     Train net output #0: loss = 0.0393648 (* 1 = 0.0393648 loss)
I0916 16:24:29.078920 19004 sgd_solver.cpp:136] Iteration 109500, lr = 0.0001, m = 0.9
I0916 16:24:44.732089 19012 data_reader.cpp:305] Starting prefetch of epoch 76
I0916 16:24:49.730614 19004 solver.cpp:314] Iteration 109600 (4.84234 iter/s, 20.6512s/100 iter), loss = 0.0631224
I0916 16:24:49.730643 19004 solver.cpp:336]     Train net output #0: loss = 0.0631221 (* 1 = 0.0631221 loss)
I0916 16:24:49.730648 19004 sgd_solver.cpp:136] Iteration 109600, lr = 0.0001, m = 0.9
I0916 16:25:10.454131 19004 solver.cpp:314] Iteration 109700 (4.82557 iter/s, 20.7229s/100 iter), loss = 0.0692018
I0916 16:25:10.454222 19004 solver.cpp:336]     Train net output #0: loss = 0.0692014 (* 1 = 0.0692014 loss)
I0916 16:25:10.454233 19004 sgd_solver.cpp:136] Iteration 109700, lr = 0.0001, m = 0.9
I0916 16:25:30.682319 19004 solver.cpp:314] Iteration 109800 (4.94374 iter/s, 20.2276s/100 iter), loss = 0.0422902
I0916 16:25:30.682361 19004 solver.cpp:336]     Train net output #0: loss = 0.0422898 (* 1 = 0.0422898 loss)
I0916 16:25:30.682384 19004 sgd_solver.cpp:136] Iteration 109800, lr = 0.0001, m = 0.9
I0916 16:25:51.476224 19004 solver.cpp:314] Iteration 109900 (4.80924 iter/s, 20.7933s/100 iter), loss = 0.0488777
I0916 16:25:51.477919 19004 solver.cpp:336]     Train net output #0: loss = 0.0488774 (* 1 = 0.0488774 loss)
I0916 16:25:51.477937 19004 sgd_solver.cpp:136] Iteration 109900, lr = 0.0001, m = 0.9
I0916 16:25:52.766191 19010 data_reader.cpp:305] Starting prefetch of epoch 64
I0916 16:26:11.854504 19004 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/cityscapes5_jsegnet21v2_iter_110000.caffemodel
I0916 16:26:11.917058 19004 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/cityscapes5_jsegnet21v2_iter_110000.solverstate
I0916 16:26:11.926095 19004 solver.cpp:563] Iteration 110000, Testing net (#0)
I0916 16:26:24.203721 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.956687
I0916 16:26:24.203755 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.999722
I0916 16:26:24.203761 19004 solver.cpp:655]     Test net output #2: loss = 0.19357 (* 1 = 0.19357 loss)
I0916 16:26:24.203817 19004 solver.cpp:265] [MultiGPU] Tests completed in 12.2806s
I0916 16:26:24.418159 19004 solver.cpp:314] Iteration 110000 (3.03573 iter/s, 32.941s/100 iter), loss = 0.0668531
I0916 16:26:24.418180 19004 solver.cpp:336]     Train net output #0: loss = 0.0668527 (* 1 = 0.0668527 loss)
I0916 16:26:24.418186 19004 sgd_solver.cpp:136] Iteration 110000, lr = 0.0001, m = 0.9
I0916 16:26:38.509276 19010 data_reader.cpp:305] Starting prefetch of epoch 65
I0916 16:26:44.381496 19004 solver.cpp:314] Iteration 110100 (5.00932 iter/s, 19.9628s/100 iter), loss = 0.0688438
I0916 16:26:44.381525 19004 solver.cpp:336]     Train net output #0: loss = 0.0688435 (* 1 = 0.0688435 loss)
I0916 16:26:44.381531 19004 sgd_solver.cpp:136] Iteration 110100, lr = 0.0001, m = 0.9
I0916 16:27:04.830302 19004 solver.cpp:314] Iteration 110200 (4.8904 iter/s, 20.4482s/100 iter), loss = 0.0495217
I0916 16:27:04.830407 19004 solver.cpp:336]     Train net output #0: loss = 0.0495213 (* 1 = 0.0495213 loss)
I0916 16:27:04.830430 19004 sgd_solver.cpp:136] Iteration 110200, lr = 0.0001, m = 0.9
I0916 16:27:12.581038 18961 data_reader.cpp:305] Starting prefetch of epoch 56
I0916 16:27:25.644646 19004 solver.cpp:314] Iteration 110300 (4.80451 iter/s, 20.8138s/100 iter), loss = 0.0715073
I0916 16:27:25.644666 19004 solver.cpp:336]     Train net output #0: loss = 0.071507 (* 1 = 0.071507 loss)
I0916 16:27:25.644670 19004 sgd_solver.cpp:136] Iteration 110300, lr = 0.0001, m = 0.9
I0916 16:27:45.698643 19004 solver.cpp:314] Iteration 110400 (4.98668 iter/s, 20.0534s/100 iter), loss = 0.0484259
I0916 16:27:45.698695 19004 solver.cpp:336]     Train net output #0: loss = 0.0484255 (* 1 = 0.0484255 loss)
I0916 16:27:45.698700 19004 sgd_solver.cpp:136] Iteration 110400, lr = 0.0001, m = 0.9
I0916 16:28:06.134049 19004 solver.cpp:314] Iteration 110500 (4.8936 iter/s, 20.4348s/100 iter), loss = 0.0331842
I0916 16:28:06.134079 19004 solver.cpp:336]     Train net output #0: loss = 0.0331839 (* 1 = 0.0331839 loss)
I0916 16:28:06.134085 19004 sgd_solver.cpp:136] Iteration 110500, lr = 0.0001, m = 0.9
I0916 16:28:19.798758 19012 data_reader.cpp:305] Starting prefetch of epoch 77
I0916 16:28:26.511209 19004 solver.cpp:314] Iteration 110600 (4.9076 iter/s, 20.3766s/100 iter), loss = 0.0462223
I0916 16:28:26.511262 19004 solver.cpp:336]     Train net output #0: loss = 0.0462219 (* 1 = 0.0462219 loss)
I0916 16:28:26.511281 19004 sgd_solver.cpp:136] Iteration 110600, lr = 0.0001, m = 0.9
I0916 16:28:47.070705 19004 solver.cpp:314] Iteration 110700 (4.86407 iter/s, 20.5589s/100 iter), loss = 0.0484662
I0916 16:28:47.070726 19004 solver.cpp:336]     Train net output #0: loss = 0.0484659 (* 1 = 0.0484659 loss)
I0916 16:28:47.070730 19004 sgd_solver.cpp:136] Iteration 110700, lr = 0.0001, m = 0.9
I0916 16:29:07.416952 19004 solver.cpp:314] Iteration 110800 (4.91505 iter/s, 20.3457s/100 iter), loss = 0.0414923
I0916 16:29:07.417004 19004 solver.cpp:336]     Train net output #0: loss = 0.0414919 (* 1 = 0.0414919 loss)
I0916 16:29:07.417011 19004 sgd_solver.cpp:136] Iteration 110800, lr = 0.0001, m = 0.9
I0916 16:29:27.731345 18963 data_reader.cpp:305] Starting prefetch of epoch 82
I0916 16:29:28.166638 19004 solver.cpp:314] Iteration 110900 (4.81949 iter/s, 20.7491s/100 iter), loss = 0.0482179
I0916 16:29:28.166692 19004 solver.cpp:336]     Train net output #0: loss = 0.0482175 (* 1 = 0.0482175 loss)
I0916 16:29:28.166705 19004 sgd_solver.cpp:136] Iteration 110900, lr = 0.0001, m = 0.9
I0916 16:29:48.360025 19004 solver.cpp:314] Iteration 111000 (4.95225 iter/s, 20.1928s/100 iter), loss = 0.0429632
I0916 16:29:48.360110 19004 solver.cpp:336]     Train net output #0: loss = 0.0429628 (* 1 = 0.0429628 loss)
I0916 16:29:48.360118 19004 sgd_solver.cpp:136] Iteration 111000, lr = 0.0001, m = 0.9
I0916 16:30:01.274518 19008 data_reader.cpp:305] Starting prefetch of epoch 56
I0916 16:30:08.577975 19004 solver.cpp:314] Iteration 111100 (4.94624 iter/s, 20.2174s/100 iter), loss = 0.0395185
I0916 16:30:08.578014 19004 solver.cpp:336]     Train net output #0: loss = 0.0395182 (* 1 = 0.0395182 loss)
I0916 16:30:08.578037 19004 sgd_solver.cpp:136] Iteration 111100, lr = 0.0001, m = 0.9
I0916 16:30:29.249687 19004 solver.cpp:314] Iteration 111200 (4.83766 iter/s, 20.6711s/100 iter), loss = 0.0468051
I0916 16:30:29.249763 19004 solver.cpp:336]     Train net output #0: loss = 0.0468047 (* 1 = 0.0468047 loss)
I0916 16:30:29.249770 19004 sgd_solver.cpp:136] Iteration 111200, lr = 0.0001, m = 0.9
I0916 16:30:49.439087 19004 solver.cpp:314] Iteration 111300 (4.95323 iter/s, 20.1888s/100 iter), loss = 0.0540793
I0916 16:30:49.439119 19004 solver.cpp:336]     Train net output #0: loss = 0.0540789 (* 1 = 0.0540789 loss)
I0916 16:30:49.439127 19004 sgd_solver.cpp:136] Iteration 111300, lr = 0.0001, m = 0.9
I0916 16:31:08.534086 19010 data_reader.cpp:305] Starting prefetch of epoch 66
I0916 16:31:09.828603 19004 solver.cpp:314] Iteration 111400 (4.90462 iter/s, 20.3889s/100 iter), loss = 0.0516833
I0916 16:31:09.828629 19004 solver.cpp:336]     Train net output #0: loss = 0.0516829 (* 1 = 0.0516829 loss)
I0916 16:31:09.828635 19004 sgd_solver.cpp:136] Iteration 111400, lr = 0.0001, m = 0.9
I0916 16:31:29.941463 19004 solver.cpp:314] Iteration 111500 (4.97208 iter/s, 20.1123s/100 iter), loss = 0.0583951
I0916 16:31:29.941493 19004 solver.cpp:336]     Train net output #0: loss = 0.0583948 (* 1 = 0.0583948 loss)
I0916 16:31:29.941499 19004 sgd_solver.cpp:136] Iteration 111500, lr = 0.0001, m = 0.9
I0916 16:31:50.310290 19004 solver.cpp:314] Iteration 111600 (4.9096 iter/s, 20.3683s/100 iter), loss = 0.0441662
I0916 16:31:50.310359 19004 solver.cpp:336]     Train net output #0: loss = 0.0441658 (* 1 = 0.0441658 loss)
I0916 16:31:50.310367 19004 sgd_solver.cpp:136] Iteration 111600, lr = 0.0001, m = 0.9
I0916 16:32:10.842003 19004 solver.cpp:314] Iteration 111700 (4.87065 iter/s, 20.5311s/100 iter), loss = 0.0424188
I0916 16:32:10.842053 19004 solver.cpp:336]     Train net output #0: loss = 0.0424185 (* 1 = 0.0424185 loss)
I0916 16:32:10.842066 19004 sgd_solver.cpp:136] Iteration 111700, lr = 0.0001, m = 0.9
I0916 16:32:15.584858 18963 data_reader.cpp:305] Starting prefetch of epoch 83
I0916 16:32:30.891427 19004 solver.cpp:314] Iteration 111800 (4.98781 iter/s, 20.0489s/100 iter), loss = 0.0539426
I0916 16:32:30.891472 19004 solver.cpp:336]     Train net output #0: loss = 0.0539422 (* 1 = 0.0539422 loss)
I0916 16:32:30.891477 19004 sgd_solver.cpp:136] Iteration 111800, lr = 0.0001, m = 0.9
I0916 16:32:49.197968 19008 data_reader.cpp:305] Starting prefetch of epoch 57
I0916 16:32:51.183843 19004 solver.cpp:314] Iteration 111900 (4.92809 iter/s, 20.2919s/100 iter), loss = 0.0422423
I0916 16:32:51.183868 19004 solver.cpp:336]     Train net output #0: loss = 0.0422419 (* 1 = 0.0422419 loss)
I0916 16:32:51.183874 19004 sgd_solver.cpp:136] Iteration 111900, lr = 0.0001, m = 0.9
I0916 16:33:11.122193 19004 solver.cpp:563] Iteration 112000, Testing net (#0)
I0916 16:33:23.198330 19002 data_reader.cpp:305] Starting prefetch of epoch 10
I0916 16:33:23.732610 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.956347
I0916 16:33:23.732630 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 16:33:23.732635 19004 solver.cpp:655]     Test net output #2: loss = 0.156045 (* 1 = 0.156045 loss)
I0916 16:33:23.732714 19004 solver.cpp:265] [MultiGPU] Tests completed in 12.6102s
I0916 16:33:23.943732 19004 solver.cpp:314] Iteration 112000 (3.0526 iter/s, 32.759s/100 iter), loss = 0.0594966
I0916 16:33:23.943756 19004 solver.cpp:336]     Train net output #0: loss = 0.0594962 (* 1 = 0.0594962 loss)
I0916 16:33:23.943760 19004 sgd_solver.cpp:136] Iteration 112000, lr = 0.0001, m = 0.9
I0916 16:33:43.853318 19004 solver.cpp:314] Iteration 112100 (5.02285 iter/s, 19.909s/100 iter), loss = 0.0633211
I0916 16:33:43.853397 19004 solver.cpp:336]     Train net output #0: loss = 0.0633207 (* 1 = 0.0633207 loss)
I0916 16:33:43.853404 19004 sgd_solver.cpp:136] Iteration 112100, lr = 0.0001, m = 0.9
I0916 16:34:03.793753 19004 solver.cpp:314] Iteration 112200 (5.01508 iter/s, 19.9399s/100 iter), loss = 0.0640702
I0916 16:34:03.793776 19004 solver.cpp:336]     Train net output #0: loss = 0.0640698 (* 1 = 0.0640698 loss)
I0916 16:34:03.793781 19004 sgd_solver.cpp:136] Iteration 112200, lr = 0.0001, m = 0.9
I0916 16:34:07.738790 19012 data_reader.cpp:305] Starting prefetch of epoch 78
I0916 16:34:23.787787 19004 solver.cpp:314] Iteration 112300 (5.00163 iter/s, 19.9935s/100 iter), loss = 0.0677184
I0916 16:34:23.787840 19004 solver.cpp:336]     Train net output #0: loss = 0.067718 (* 1 = 0.067718 loss)
I0916 16:34:23.787849 19004 sgd_solver.cpp:136] Iteration 112300, lr = 0.0001, m = 0.9
I0916 16:34:40.859587 19007 data_reader.cpp:305] Starting prefetch of epoch 69
I0916 16:34:43.801149 19004 solver.cpp:314] Iteration 112400 (4.9968 iter/s, 20.0128s/100 iter), loss = 0.0471109
I0916 16:34:43.801174 19004 solver.cpp:336]     Train net output #0: loss = 0.0471106 (* 1 = 0.0471106 loss)
I0916 16:34:43.801178 19004 sgd_solver.cpp:136] Iteration 112400, lr = 0.0001, m = 0.9
I0916 16:35:04.083443 19004 solver.cpp:314] Iteration 112500 (4.93055 iter/s, 20.2817s/100 iter), loss = 0.042599
I0916 16:35:04.083498 19004 solver.cpp:336]     Train net output #0: loss = 0.0425986 (* 1 = 0.0425986 loss)
I0916 16:35:04.083503 19004 sgd_solver.cpp:136] Iteration 112500, lr = 0.0001, m = 0.9
I0916 16:35:24.276998 19004 solver.cpp:314] Iteration 112600 (4.95221 iter/s, 20.193s/100 iter), loss = 0.0418317
I0916 16:35:24.277025 19004 solver.cpp:336]     Train net output #0: loss = 0.0418313 (* 1 = 0.0418313 loss)
I0916 16:35:24.277029 19004 sgd_solver.cpp:136] Iteration 112600, lr = 0.0001, m = 0.9
I0916 16:35:44.332830 19004 solver.cpp:314] Iteration 112700 (4.98622 iter/s, 20.0553s/100 iter), loss = 0.0532021
I0916 16:35:44.334162 19004 solver.cpp:336]     Train net output #0: loss = 0.0532018 (* 1 = 0.0532018 loss)
I0916 16:35:44.334188 19004 sgd_solver.cpp:136] Iteration 112700, lr = 0.0001, m = 0.9
I0916 16:35:47.465008 18963 data_reader.cpp:305] Starting prefetch of epoch 84
I0916 16:36:04.124006 19004 solver.cpp:314] Iteration 112800 (5.0529 iter/s, 19.7906s/100 iter), loss = 0.0641755
I0916 16:36:04.124034 19004 solver.cpp:336]     Train net output #0: loss = 0.0641751 (* 1 = 0.0641751 loss)
I0916 16:36:04.124040 19004 sgd_solver.cpp:136] Iteration 112800, lr = 0.0001, m = 0.9
I0916 16:36:24.293087 19004 solver.cpp:314] Iteration 112900 (4.95822 iter/s, 20.1685s/100 iter), loss = 0.0577536
I0916 16:36:24.293167 19004 solver.cpp:336]     Train net output #0: loss = 0.0577532 (* 1 = 0.0577532 loss)
I0916 16:36:24.293174 19004 sgd_solver.cpp:136] Iteration 112900, lr = 0.0001, m = 0.9
I0916 16:36:44.463177 19004 solver.cpp:314] Iteration 113000 (4.95797 iter/s, 20.1695s/100 iter), loss = 0.0369186
I0916 16:36:44.463203 19004 solver.cpp:336]     Train net output #0: loss = 0.0369183 (* 1 = 0.0369183 loss)
I0916 16:36:44.463209 19004 sgd_solver.cpp:136] Iteration 113000, lr = 0.0001, m = 0.9
I0916 16:36:53.680371 19010 data_reader.cpp:305] Starting prefetch of epoch 67
I0916 16:37:04.796676 19004 solver.cpp:314] Iteration 113100 (4.91813 iter/s, 20.3329s/100 iter), loss = 0.0543631
I0916 16:37:04.796752 19004 solver.cpp:336]     Train net output #0: loss = 0.0543627 (* 1 = 0.0543627 loss)
I0916 16:37:04.796757 19004 sgd_solver.cpp:136] Iteration 113100, lr = 0.0001, m = 0.9
I0916 16:37:25.290343 19004 solver.cpp:314] Iteration 113200 (4.8797 iter/s, 20.4931s/100 iter), loss = 0.0491233
I0916 16:37:25.290397 19004 solver.cpp:336]     Train net output #0: loss = 0.0491229 (* 1 = 0.0491229 loss)
I0916 16:37:25.290405 19004 sgd_solver.cpp:136] Iteration 113200, lr = 0.0001, m = 0.9
I0916 16:37:27.870654 18963 data_reader.cpp:305] Starting prefetch of epoch 85
I0916 16:37:45.767195 19004 solver.cpp:314] Iteration 113300 (4.8837 iter/s, 20.4763s/100 iter), loss = 0.0501092
I0916 16:37:45.767248 19004 solver.cpp:336]     Train net output #0: loss = 0.0501089 (* 1 = 0.0501089 loss)
I0916 16:37:45.767253 19004 sgd_solver.cpp:136] Iteration 113300, lr = 0.0001, m = 0.9
I0916 16:38:06.591863 19004 solver.cpp:314] Iteration 113400 (4.80213 iter/s, 20.8241s/100 iter), loss = 0.0439409
I0916 16:38:06.591886 19004 solver.cpp:336]     Train net output #0: loss = 0.0439405 (* 1 = 0.0439405 loss)
I0916 16:38:06.591891 19004 sgd_solver.cpp:136] Iteration 113400, lr = 0.0001, m = 0.9
I0916 16:38:27.209161 19004 solver.cpp:314] Iteration 113500 (4.85043 iter/s, 20.6167s/100 iter), loss = 0.0602266
I0916 16:38:27.209209 19004 solver.cpp:336]     Train net output #0: loss = 0.0602262 (* 1 = 0.0602262 loss)
I0916 16:38:27.209216 19004 sgd_solver.cpp:136] Iteration 113500, lr = 0.0001, m = 0.9
I0916 16:38:35.863060 18961 data_reader.cpp:305] Starting prefetch of epoch 57
I0916 16:38:47.721130 19004 solver.cpp:314] Iteration 113600 (4.87534 iter/s, 20.5114s/100 iter), loss = 0.0710592
I0916 16:38:47.721158 19004 solver.cpp:336]     Train net output #0: loss = 0.0710589 (* 1 = 0.0710589 loss)
I0916 16:38:47.721163 19004 sgd_solver.cpp:136] Iteration 113600, lr = 0.0001, m = 0.9
I0916 16:39:08.085144 19004 solver.cpp:314] Iteration 113700 (4.91076 iter/s, 20.3634s/100 iter), loss = 0.0563112
I0916 16:39:08.085191 19004 solver.cpp:336]     Train net output #0: loss = 0.0563108 (* 1 = 0.0563108 loss)
I0916 16:39:08.085197 19004 sgd_solver.cpp:136] Iteration 113700, lr = 0.0001, m = 0.9
I0916 16:39:28.694466 19004 solver.cpp:314] Iteration 113800 (4.85231 iter/s, 20.6087s/100 iter), loss = 0.0575046
I0916 16:39:28.694499 19004 solver.cpp:336]     Train net output #0: loss = 0.0575042 (* 1 = 0.0575042 loss)
I0916 16:39:28.694507 19004 sgd_solver.cpp:136] Iteration 113800, lr = 0.0001, m = 0.9
I0916 16:39:43.626754 19010 data_reader.cpp:305] Starting prefetch of epoch 68
I0916 16:39:49.116885 19004 solver.cpp:314] Iteration 113900 (4.89672 iter/s, 20.4218s/100 iter), loss = 0.0459123
I0916 16:39:49.116909 19004 solver.cpp:336]     Train net output #0: loss = 0.0459119 (* 1 = 0.0459119 loss)
I0916 16:39:49.116914 19004 sgd_solver.cpp:136] Iteration 113900, lr = 0.0001, m = 0.9
I0916 16:40:09.546581 19004 solver.cpp:563] Iteration 114000, Testing net (#0)
I0916 16:40:18.022423 19029 data_reader.cpp:305] Starting prefetch of epoch 12
I0916 16:40:22.905330 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.956694
I0916 16:40:22.905349 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.999699
I0916 16:40:22.905354 19004 solver.cpp:655]     Test net output #2: loss = 0.194379 (* 1 = 0.194379 loss)
I0916 16:40:22.905418 19004 solver.cpp:265] [MultiGPU] Tests completed in 13.3585s
I0916 16:40:23.118108 19004 solver.cpp:314] Iteration 114000 (2.94115 iter/s, 34.0003s/100 iter), loss = 0.0517097
I0916 16:40:23.118129 19004 solver.cpp:336]     Train net output #0: loss = 0.0517093 (* 1 = 0.0517093 loss)
I0916 16:40:23.118134 19004 sgd_solver.cpp:136] Iteration 114000, lr = 0.0001, m = 0.9
I0916 16:40:43.501838 19004 solver.cpp:314] Iteration 114100 (4.90601 iter/s, 20.3832s/100 iter), loss = 0.0688129
I0916 16:40:43.501864 19004 solver.cpp:336]     Train net output #0: loss = 0.0688125 (* 1 = 0.0688125 loss)
I0916 16:40:43.501870 19004 sgd_solver.cpp:136] Iteration 114100, lr = 0.0001, m = 0.9
I0916 16:41:03.515836 19004 solver.cpp:314] Iteration 114200 (4.99665 iter/s, 20.0134s/100 iter), loss = 0.047362
I0916 16:41:03.515933 19004 solver.cpp:336]     Train net output #0: loss = 0.0473616 (* 1 = 0.0473616 loss)
I0916 16:41:03.515941 19004 sgd_solver.cpp:136] Iteration 114200, lr = 0.0001, m = 0.9
I0916 16:41:04.167326 18961 data_reader.cpp:305] Starting prefetch of epoch 58
I0916 16:41:23.890743 19004 solver.cpp:314] Iteration 114300 (4.90814 iter/s, 20.3743s/100 iter), loss = 0.0412987
I0916 16:41:23.890771 19004 solver.cpp:336]     Train net output #0: loss = 0.0412983 (* 1 = 0.0412983 loss)
I0916 16:41:23.890777 19004 sgd_solver.cpp:136] Iteration 114300, lr = 0.0001, m = 0.9
I0916 16:41:44.058096 19004 solver.cpp:314] Iteration 114400 (4.95865 iter/s, 20.1668s/100 iter), loss = 0.040952
I0916 16:41:44.058142 19004 solver.cpp:336]     Train net output #0: loss = 0.0409516 (* 1 = 0.0409516 loss)
I0916 16:41:44.058147 19004 sgd_solver.cpp:136] Iteration 114400, lr = 0.0001, m = 0.9
I0916 16:42:03.612663 19004 solver.cpp:314] Iteration 114500 (5.11404 iter/s, 19.554s/100 iter), loss = 0.0597344
I0916 16:42:03.612687 19004 solver.cpp:336]     Train net output #0: loss = 0.059734 (* 1 = 0.059734 loss)
I0916 16:42:03.612692 19004 sgd_solver.cpp:136] Iteration 114500, lr = 0.0001, m = 0.9
I0916 16:42:10.226924 18963 data_reader.cpp:305] Starting prefetch of epoch 86
I0916 16:42:22.937805 19004 solver.cpp:314] Iteration 114600 (5.17475 iter/s, 19.3246s/100 iter), loss = 0.0918922
I0916 16:42:22.937860 19004 solver.cpp:336]     Train net output #0: loss = 0.0918918 (* 1 = 0.0918918 loss)
I0916 16:42:22.937866 19004 sgd_solver.cpp:136] Iteration 114600, lr = 0.0001, m = 0.9
I0916 16:42:42.095830 18961 data_reader.cpp:305] Starting prefetch of epoch 59
I0916 16:42:42.251425 19004 solver.cpp:314] Iteration 114700 (5.17784 iter/s, 19.3131s/100 iter), loss = 0.0558432
I0916 16:42:42.251454 19004 solver.cpp:336]     Train net output #0: loss = 0.0558428 (* 1 = 0.0558428 loss)
I0916 16:42:42.251461 19004 sgd_solver.cpp:136] Iteration 114700, lr = 0.0001, m = 0.9
I0916 16:43:01.456848 19004 solver.cpp:314] Iteration 114800 (5.20701 iter/s, 19.2049s/100 iter), loss = 0.0541908
I0916 16:43:01.456892 19004 solver.cpp:336]     Train net output #0: loss = 0.0541905 (* 1 = 0.0541905 loss)
I0916 16:43:01.456898 19004 sgd_solver.cpp:136] Iteration 114800, lr = 0.0001, m = 0.9
I0916 16:43:20.988469 19004 solver.cpp:314] Iteration 114900 (5.12005 iter/s, 19.5311s/100 iter), loss = 0.113789
I0916 16:43:20.988495 19004 solver.cpp:336]     Train net output #0: loss = 0.113788 (* 1 = 0.113788 loss)
I0916 16:43:20.988500 19004 sgd_solver.cpp:136] Iteration 114900, lr = 0.0001, m = 0.9
I0916 16:43:40.370057 19004 solver.cpp:314] Iteration 115000 (5.15968 iter/s, 19.381s/100 iter), loss = 0.0536801
I0916 16:43:40.386133 19004 solver.cpp:336]     Train net output #0: loss = 0.0536797 (* 1 = 0.0536797 loss)
I0916 16:43:40.386167 19004 sgd_solver.cpp:136] Iteration 115000, lr = 0.0001, m = 0.9
I0916 16:43:46.279278 19008 data_reader.cpp:305] Starting prefetch of epoch 58
I0916 16:43:59.843773 19004 solver.cpp:314] Iteration 115100 (5.13527 iter/s, 19.4732s/100 iter), loss = 0.0677222
I0916 16:43:59.843801 19004 solver.cpp:336]     Train net output #0: loss = 0.0677218 (* 1 = 0.0677218 loss)
I0916 16:43:59.843807 19004 sgd_solver.cpp:136] Iteration 115100, lr = 0.0001, m = 0.9
I0916 16:44:19.370550 19004 solver.cpp:314] Iteration 115200 (5.12132 iter/s, 19.5262s/100 iter), loss = 0.0377472
I0916 16:44:19.370602 19004 solver.cpp:336]     Train net output #0: loss = 0.0377468 (* 1 = 0.0377468 loss)
I0916 16:44:19.370606 19004 sgd_solver.cpp:136] Iteration 115200, lr = 0.0001, m = 0.9
I0916 16:44:38.822284 19004 solver.cpp:314] Iteration 115300 (5.14107 iter/s, 19.4512s/100 iter), loss = 0.0328437
I0916 16:44:38.822312 19004 solver.cpp:336]     Train net output #0: loss = 0.0328433 (* 1 = 0.0328433 loss)
I0916 16:44:38.822319 19004 sgd_solver.cpp:136] Iteration 115300, lr = 0.0001, m = 0.9
I0916 16:44:50.387158 19012 data_reader.cpp:305] Starting prefetch of epoch 79
I0916 16:44:57.965389 19004 solver.cpp:314] Iteration 115400 (5.22396 iter/s, 19.1426s/100 iter), loss = 0.0665018
I0916 16:44:57.965414 19004 solver.cpp:336]     Train net output #0: loss = 0.0665014 (* 1 = 0.0665014 loss)
I0916 16:44:57.965420 19004 sgd_solver.cpp:136] Iteration 115400, lr = 0.0001, m = 0.9
I0916 16:45:17.336043 19004 solver.cpp:314] Iteration 115500 (5.16259 iter/s, 19.3701s/100 iter), loss = 0.0518676
I0916 16:45:17.336071 19004 solver.cpp:336]     Train net output #0: loss = 0.0518672 (* 1 = 0.0518672 loss)
I0916 16:45:17.336078 19004 sgd_solver.cpp:136] Iteration 115500, lr = 0.0001, m = 0.9
I0916 16:45:22.375409 19008 data_reader.cpp:305] Starting prefetch of epoch 59
I0916 16:45:36.970415 19004 solver.cpp:314] Iteration 115600 (5.09325 iter/s, 19.6338s/100 iter), loss = 0.0488687
I0916 16:45:36.970438 19004 solver.cpp:336]     Train net output #0: loss = 0.0488683 (* 1 = 0.0488683 loss)
I0916 16:45:36.970443 19004 sgd_solver.cpp:136] Iteration 115600, lr = 0.0001, m = 0.9
I0916 16:45:57.258497 19004 solver.cpp:314] Iteration 115700 (4.92914 iter/s, 20.2875s/100 iter), loss = 0.0583985
I0916 16:45:57.258599 19004 solver.cpp:336]     Train net output #0: loss = 0.0583981 (* 1 = 0.0583981 loss)
I0916 16:45:57.258605 19004 sgd_solver.cpp:136] Iteration 115700, lr = 0.0001, m = 0.9
I0916 16:46:17.829944 19004 solver.cpp:314] Iteration 115800 (4.86124 iter/s, 20.5709s/100 iter), loss = 0.0443309
I0916 16:46:17.829968 19004 solver.cpp:336]     Train net output #0: loss = 0.0443305 (* 1 = 0.0443305 loss)
I0916 16:46:17.829972 19004 sgd_solver.cpp:136] Iteration 115800, lr = 0.0001, m = 0.9
I0916 16:46:29.379106 19007 data_reader.cpp:305] Starting prefetch of epoch 70
I0916 16:46:38.160959 19004 solver.cpp:314] Iteration 115900 (4.91873 iter/s, 20.3304s/100 iter), loss = 0.0822379
I0916 16:46:38.160980 19004 solver.cpp:336]     Train net output #0: loss = 0.0822375 (* 1 = 0.0822375 loss)
I0916 16:46:38.160985 19004 sgd_solver.cpp:136] Iteration 115900, lr = 0.0001, m = 0.9
I0916 16:46:57.749688 19004 solver.cpp:563] Iteration 116000, Testing net (#0)
I0916 16:47:13.121634 19015 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 16:47:13.916100 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.956443
I0916 16:47:13.916127 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 16:47:13.916133 19004 solver.cpp:655]     Test net output #2: loss = 0.15495 (* 1 = 0.15495 loss)
I0916 16:47:13.916167 19004 solver.cpp:265] [MultiGPU] Tests completed in 16.166s
I0916 16:47:14.150173 19004 solver.cpp:314] Iteration 116000 (2.77869 iter/s, 35.9882s/100 iter), loss = 0.0486226
I0916 16:47:14.150264 19004 solver.cpp:336]     Train net output #0: loss = 0.0486222 (* 1 = 0.0486222 loss)
I0916 16:47:14.150288 19004 sgd_solver.cpp:136] Iteration 116000, lr = 0.0001, m = 0.9
I0916 16:47:18.335124 19008 data_reader.cpp:305] Starting prefetch of epoch 60
I0916 16:47:34.032586 19004 solver.cpp:314] Iteration 116100 (5.02971 iter/s, 19.8819s/100 iter), loss = 0.0643142
I0916 16:47:34.032609 19004 solver.cpp:336]     Train net output #0: loss = 0.0643138 (* 1 = 0.0643138 loss)
I0916 16:47:34.032616 19004 sgd_solver.cpp:136] Iteration 116100, lr = 0.0001, m = 0.9
I0916 16:47:54.085475 19004 solver.cpp:314] Iteration 116200 (4.98695 iter/s, 20.0523s/100 iter), loss = 0.0759626
I0916 16:47:54.101667 19004 solver.cpp:336]     Train net output #0: loss = 0.0759622 (* 1 = 0.0759622 loss)
I0916 16:47:54.101706 19004 sgd_solver.cpp:136] Iteration 116200, lr = 0.0001, m = 0.9
I0916 16:48:14.304991 19004 solver.cpp:314] Iteration 116300 (4.94586 iter/s, 20.2189s/100 iter), loss = 0.0485911
I0916 16:48:14.305480 19004 solver.cpp:336]     Train net output #0: loss = 0.0485907 (* 1 = 0.0485907 loss)
I0916 16:48:14.305501 19004 sgd_solver.cpp:136] Iteration 116300, lr = 0.0001, m = 0.9
I0916 16:48:25.091794 18961 data_reader.cpp:305] Starting prefetch of epoch 60
I0916 16:48:34.644172 19004 solver.cpp:314] Iteration 116400 (4.91676 iter/s, 20.3386s/100 iter), loss = 0.055825
I0916 16:48:34.644196 19004 solver.cpp:336]     Train net output #0: loss = 0.0558246 (* 1 = 0.0558246 loss)
I0916 16:48:34.644199 19004 sgd_solver.cpp:136] Iteration 116400, lr = 0.0001, m = 0.9
I0916 16:48:55.096567 19004 solver.cpp:314] Iteration 116500 (4.88954 iter/s, 20.4518s/100 iter), loss = 0.0834082
I0916 16:48:55.096626 19004 solver.cpp:336]     Train net output #0: loss = 0.0834078 (* 1 = 0.0834078 loss)
I0916 16:48:55.096631 19004 sgd_solver.cpp:136] Iteration 116500, lr = 0.0001, m = 0.9
I0916 16:49:14.766021 19004 solver.cpp:314] Iteration 116600 (5.08417 iter/s, 19.6689s/100 iter), loss = 0.0390472
I0916 16:49:14.766047 19004 solver.cpp:336]     Train net output #0: loss = 0.0390467 (* 1 = 0.0390467 loss)
I0916 16:49:14.766052 19004 sgd_solver.cpp:136] Iteration 116600, lr = 0.0001, m = 0.9
I0916 16:49:30.828110 19010 data_reader.cpp:305] Starting prefetch of epoch 69
I0916 16:49:34.115053 19004 solver.cpp:314] Iteration 116700 (5.16836 iter/s, 19.3485s/100 iter), loss = 0.037669
I0916 16:49:34.115074 19004 solver.cpp:336]     Train net output #0: loss = 0.0376686 (* 1 = 0.0376686 loss)
I0916 16:49:34.115078 19004 sgd_solver.cpp:136] Iteration 116700, lr = 0.0001, m = 0.9
I0916 16:49:53.459558 19004 solver.cpp:314] Iteration 116800 (5.16957 iter/s, 19.344s/100 iter), loss = 0.0504628
I0916 16:49:53.459615 19004 solver.cpp:336]     Train net output #0: loss = 0.0504624 (* 1 = 0.0504624 loss)
I0916 16:49:53.459627 19004 sgd_solver.cpp:136] Iteration 116800, lr = 0.0001, m = 0.9
I0916 16:50:03.003757 19008 data_reader.cpp:305] Starting prefetch of epoch 61
I0916 16:50:13.304250 19004 solver.cpp:314] Iteration 116900 (5.03927 iter/s, 19.8441s/100 iter), loss = 0.0542912
I0916 16:50:13.304276 19004 solver.cpp:336]     Train net output #0: loss = 0.0542907 (* 1 = 0.0542907 loss)
I0916 16:50:13.304283 19004 sgd_solver.cpp:136] Iteration 116900, lr = 0.0001, m = 0.9
I0916 16:50:32.704568 19004 solver.cpp:314] Iteration 117000 (5.1547 iter/s, 19.3998s/100 iter), loss = 0.063139
I0916 16:50:32.704594 19004 solver.cpp:336]     Train net output #0: loss = 0.0631386 (* 1 = 0.0631386 loss)
I0916 16:50:32.704601 19004 sgd_solver.cpp:136] Iteration 117000, lr = 0.0001, m = 0.9
I0916 16:50:52.242532 19004 solver.cpp:314] Iteration 117100 (5.11838 iter/s, 19.5374s/100 iter), loss = 0.119145
I0916 16:50:52.242588 19004 solver.cpp:336]     Train net output #0: loss = 0.119145 (* 1 = 0.119145 loss)
I0916 16:50:52.242594 19004 sgd_solver.cpp:136] Iteration 117100, lr = 0.0001, m = 0.9
I0916 16:51:07.332041 19007 data_reader.cpp:305] Starting prefetch of epoch 71
I0916 16:51:11.473675 19004 solver.cpp:314] Iteration 117200 (5.20004 iter/s, 19.2306s/100 iter), loss = 0.0571768
I0916 16:51:11.473700 19004 solver.cpp:336]     Train net output #0: loss = 0.0571763 (* 1 = 0.0571763 loss)
I0916 16:51:11.473703 19004 sgd_solver.cpp:136] Iteration 117200, lr = 0.0001, m = 0.9
I0916 16:51:30.715137 19004 solver.cpp:314] Iteration 117300 (5.19726 iter/s, 19.2409s/100 iter), loss = 0.0379733
I0916 16:51:30.715190 19004 solver.cpp:336]     Train net output #0: loss = 0.0379729 (* 1 = 0.0379729 loss)
I0916 16:51:30.715196 19004 sgd_solver.cpp:136] Iteration 117300, lr = 0.0001, m = 0.9
I0916 16:51:51.161736 19004 solver.cpp:314] Iteration 117400 (4.89092 iter/s, 20.446s/100 iter), loss = 0.0431454
I0916 16:51:51.161763 19004 solver.cpp:336]     Train net output #0: loss = 0.0431449 (* 1 = 0.0431449 loss)
I0916 16:51:51.161770 19004 sgd_solver.cpp:136] Iteration 117400, lr = 0.0001, m = 0.9
I0916 16:52:10.745759 19004 solver.cpp:314] Iteration 117500 (5.10635 iter/s, 19.5835s/100 iter), loss = 0.0336937
I0916 16:52:10.745811 19004 solver.cpp:336]     Train net output #0: loss = 0.0336933 (* 1 = 0.0336933 loss)
I0916 16:52:10.745817 19004 sgd_solver.cpp:136] Iteration 117500, lr = 0.0001, m = 0.9
I0916 16:52:12.461714 19012 data_reader.cpp:305] Starting prefetch of epoch 80
I0916 16:52:30.009611 19004 solver.cpp:314] Iteration 117600 (5.19121 iter/s, 19.2633s/100 iter), loss = 0.0407957
I0916 16:52:30.009636 19004 solver.cpp:336]     Train net output #0: loss = 0.0407953 (* 1 = 0.0407953 loss)
I0916 16:52:30.009640 19004 sgd_solver.cpp:136] Iteration 117600, lr = 0.0001, m = 0.9
I0916 16:52:44.492586 18961 data_reader.cpp:305] Starting prefetch of epoch 61
I0916 16:52:49.490106 19004 solver.cpp:314] Iteration 117700 (5.13348 iter/s, 19.48s/100 iter), loss = 0.0601613
I0916 16:52:49.490131 19004 solver.cpp:336]     Train net output #0: loss = 0.0601609 (* 1 = 0.0601609 loss)
I0916 16:52:49.490135 19004 sgd_solver.cpp:136] Iteration 117700, lr = 0.0001, m = 0.9
I0916 16:53:09.080361 19004 solver.cpp:314] Iteration 117800 (5.10472 iter/s, 19.5897s/100 iter), loss = 0.0356718
I0916 16:53:09.080387 19004 solver.cpp:336]     Train net output #0: loss = 0.0356713 (* 1 = 0.0356713 loss)
I0916 16:53:09.080391 19004 sgd_solver.cpp:136] Iteration 117800, lr = 0.0001, m = 0.9
I0916 16:53:28.504477 19004 solver.cpp:314] Iteration 117900 (5.14838 iter/s, 19.4236s/100 iter), loss = 0.0575099
I0916 16:53:28.504559 19004 solver.cpp:336]     Train net output #0: loss = 0.0575095 (* 1 = 0.0575095 loss)
I0916 16:53:28.504564 19004 sgd_solver.cpp:136] Iteration 117900, lr = 0.0001, m = 0.9
I0916 16:53:47.822304 19004 solver.cpp:563] Iteration 118000, Testing net (#0)
I0916 16:53:56.634678 19015 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 16:54:03.294821 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.956603
I0916 16:54:03.294888 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.999716
I0916 16:54:03.294895 19004 solver.cpp:655]     Test net output #2: loss = 0.193796 (* 1 = 0.193796 loss)
I0916 16:54:03.294920 19004 solver.cpp:265] [MultiGPU] Tests completed in 15.4722s
I0916 16:54:03.491699 19004 solver.cpp:314] Iteration 118000 (2.85827 iter/s, 34.9862s/100 iter), loss = 0.0433662
I0916 16:54:03.491727 19004 solver.cpp:336]     Train net output #0: loss = 0.0433658 (* 1 = 0.0433658 loss)
I0916 16:54:03.491731 19004 sgd_solver.cpp:136] Iteration 118000, lr = 0.0001, m = 0.9
I0916 16:54:22.769381 19004 solver.cpp:314] Iteration 118100 (5.18749 iter/s, 19.2771s/100 iter), loss = 0.0565155
I0916 16:54:22.769402 19004 solver.cpp:336]     Train net output #0: loss = 0.0565151 (* 1 = 0.0565151 loss)
I0916 16:54:22.769407 19004 sgd_solver.cpp:136] Iteration 118100, lr = 0.0001, m = 0.9
I0916 16:54:36.258391 18963 data_reader.cpp:305] Starting prefetch of epoch 87
I0916 16:54:41.977349 19004 solver.cpp:314] Iteration 118200 (5.20632 iter/s, 19.2074s/100 iter), loss = 0.064086
I0916 16:54:41.977383 19004 solver.cpp:336]     Train net output #0: loss = 0.0640856 (* 1 = 0.0640856 loss)
I0916 16:54:41.977390 19004 sgd_solver.cpp:136] Iteration 118200, lr = 0.0001, m = 0.9
I0916 16:55:01.378921 19004 solver.cpp:314] Iteration 118300 (5.15437 iter/s, 19.401s/100 iter), loss = 0.0409442
I0916 16:55:01.378945 19004 solver.cpp:336]     Train net output #0: loss = 0.0409438 (* 1 = 0.0409438 loss)
I0916 16:55:01.378950 19004 sgd_solver.cpp:136] Iteration 118300, lr = 0.0001, m = 0.9
I0916 16:55:08.281795 18961 data_reader.cpp:305] Starting prefetch of epoch 62
I0916 16:55:20.887598 19004 solver.cpp:314] Iteration 118400 (5.12607 iter/s, 19.5081s/100 iter), loss = 0.0484923
I0916 16:55:20.887629 19004 solver.cpp:336]     Train net output #0: loss = 0.0484919 (* 1 = 0.0484919 loss)
I0916 16:55:20.887636 19004 sgd_solver.cpp:136] Iteration 118400, lr = 0.0001, m = 0.9
I0916 16:55:40.485797 19004 solver.cpp:314] Iteration 118500 (5.10265 iter/s, 19.5977s/100 iter), loss = 0.0507094
I0916 16:55:40.485846 19004 solver.cpp:336]     Train net output #0: loss = 0.050709 (* 1 = 0.050709 loss)
I0916 16:55:40.485853 19004 sgd_solver.cpp:136] Iteration 118500, lr = 0.0001, m = 0.9
I0916 16:56:00.043229 19004 solver.cpp:314] Iteration 118600 (5.11329 iter/s, 19.5569s/100 iter), loss = 0.0513517
I0916 16:56:00.043251 19004 solver.cpp:336]     Train net output #0: loss = 0.0513512 (* 1 = 0.0513512 loss)
I0916 16:56:00.043256 19004 sgd_solver.cpp:136] Iteration 118600, lr = 0.0001, m = 0.9
I0916 16:56:12.820020 18961 data_reader.cpp:305] Starting prefetch of epoch 63
I0916 16:56:19.320718 19004 solver.cpp:314] Iteration 118700 (5.18754 iter/s, 19.2769s/100 iter), loss = 0.0694971
I0916 16:56:19.320785 19004 solver.cpp:336]     Train net output #0: loss = 0.0694966 (* 1 = 0.0694966 loss)
I0916 16:56:19.320811 19004 sgd_solver.cpp:136] Iteration 118700, lr = 0.0001, m = 0.9
I0916 16:56:38.762763 19004 solver.cpp:314] Iteration 118800 (5.14364 iter/s, 19.4415s/100 iter), loss = 0.0312368
I0916 16:56:38.762789 19004 solver.cpp:336]     Train net output #0: loss = 0.0312364 (* 1 = 0.0312364 loss)
I0916 16:56:38.762796 19004 sgd_solver.cpp:136] Iteration 118800, lr = 0.0001, m = 0.9
I0916 16:56:58.057693 19004 solver.cpp:314] Iteration 118900 (5.18285 iter/s, 19.2944s/100 iter), loss = 0.0473003
I0916 16:56:58.057744 19004 solver.cpp:336]     Train net output #0: loss = 0.0472998 (* 1 = 0.0472998 loss)
I0916 16:56:58.057751 19004 sgd_solver.cpp:136] Iteration 118900, lr = 0.0001, m = 0.9
I0916 16:57:16.715595 19010 data_reader.cpp:305] Starting prefetch of epoch 70
I0916 16:57:17.473639 19004 solver.cpp:314] Iteration 119000 (5.15055 iter/s, 19.4154s/100 iter), loss = 0.0442456
I0916 16:57:17.473664 19004 solver.cpp:336]     Train net output #0: loss = 0.0442452 (* 1 = 0.0442452 loss)
I0916 16:57:17.473667 19004 sgd_solver.cpp:136] Iteration 119000, lr = 0.0001, m = 0.9
I0916 16:57:36.789942 19004 solver.cpp:314] Iteration 119100 (5.17712 iter/s, 19.3158s/100 iter), loss = 0.0524433
I0916 16:57:36.789997 19004 solver.cpp:336]     Train net output #0: loss = 0.0524429 (* 1 = 0.0524429 loss)
I0916 16:57:36.790002 19004 sgd_solver.cpp:136] Iteration 119100, lr = 0.0001, m = 0.9
I0916 16:57:48.955432 19007 data_reader.cpp:305] Starting prefetch of epoch 72
I0916 16:57:56.239804 19004 solver.cpp:314] Iteration 119200 (5.14157 iter/s, 19.4493s/100 iter), loss = 0.0613444
I0916 16:57:56.239833 19004 solver.cpp:336]     Train net output #0: loss = 0.0613439 (* 1 = 0.0613439 loss)
I0916 16:57:56.239840 19004 sgd_solver.cpp:136] Iteration 119200, lr = 0.0001, m = 0.9
I0916 16:58:15.696269 19004 solver.cpp:314] Iteration 119300 (5.13982 iter/s, 19.4559s/100 iter), loss = 0.0411234
I0916 16:58:15.696318 19004 solver.cpp:336]     Train net output #0: loss = 0.041123 (* 1 = 0.041123 loss)
I0916 16:58:15.696326 19004 sgd_solver.cpp:136] Iteration 119300, lr = 0.0001, m = 0.9
I0916 16:58:34.791791 19004 solver.cpp:314] Iteration 119400 (5.23698 iter/s, 19.095s/100 iter), loss = 0.0524791
I0916 16:58:34.791817 19004 solver.cpp:336]     Train net output #0: loss = 0.0524786 (* 1 = 0.0524786 loss)
I0916 16:58:34.791822 19004 sgd_solver.cpp:136] Iteration 119400, lr = 0.0001, m = 0.9
I0916 16:58:52.679337 19008 data_reader.cpp:305] Starting prefetch of epoch 62
I0916 16:58:54.240299 19004 solver.cpp:314] Iteration 119500 (5.14193 iter/s, 19.448s/100 iter), loss = 0.0565208
I0916 16:58:54.240322 19004 solver.cpp:336]     Train net output #0: loss = 0.0565204 (* 1 = 0.0565204 loss)
I0916 16:58:54.240326 19004 sgd_solver.cpp:136] Iteration 119500, lr = 0.0001, m = 0.9
I0916 16:59:13.686856 19004 solver.cpp:314] Iteration 119600 (5.14244 iter/s, 19.446s/100 iter), loss = 0.0712672
I0916 16:59:13.686877 19004 solver.cpp:336]     Train net output #0: loss = 0.0712668 (* 1 = 0.0712668 loss)
I0916 16:59:13.686882 19004 sgd_solver.cpp:136] Iteration 119600, lr = 0.0001, m = 0.9
I0916 16:59:33.474424 19004 solver.cpp:314] Iteration 119700 (5.05382 iter/s, 19.787s/100 iter), loss = 0.0382507
I0916 16:59:33.474476 19004 solver.cpp:336]     Train net output #0: loss = 0.0382503 (* 1 = 0.0382503 loss)
I0916 16:59:33.474481 19004 sgd_solver.cpp:136] Iteration 119700, lr = 0.0001, m = 0.9
I0916 16:59:52.786160 19004 solver.cpp:314] Iteration 119800 (5.17834 iter/s, 19.3112s/100 iter), loss = 0.0693584
I0916 16:59:52.786190 19004 solver.cpp:336]     Train net output #0: loss = 0.069358 (* 1 = 0.069358 loss)
I0916 16:59:52.786195 19004 sgd_solver.cpp:136] Iteration 119800, lr = 0.0001, m = 0.9
I0916 16:59:57.443723 19010 data_reader.cpp:305] Starting prefetch of epoch 71
I0916 17:00:13.045019 19004 solver.cpp:314] Iteration 119900 (4.93625 iter/s, 20.2583s/100 iter), loss = 0.0436027
I0916 17:00:13.045111 19004 solver.cpp:336]     Train net output #0: loss = 0.0436023 (* 1 = 0.0436023 loss)
I0916 17:00:13.045117 19004 sgd_solver.cpp:136] Iteration 119900, lr = 0.0001, m = 0.9
I0916 17:00:30.347921 19008 data_reader.cpp:305] Starting prefetch of epoch 63
I0916 17:00:32.404233 19004 solver.cpp:314] Iteration 119999 (5.11399 iter/s, 19.3587s/99 iter), loss = 0.0511534
I0916 17:00:32.404256 19004 solver.cpp:336]     Train net output #0: loss = 0.051153 (* 1 = 0.051153 loss)
I0916 17:00:32.427646 19004 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/cityscapes5_jsegnet21v2_iter_120000.caffemodel
I0916 17:00:32.585093 19004 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/cityscapes5_jsegnet21v2_iter_120000.solverstate
I0916 17:00:32.653252 19004 solver.cpp:538] Iteration 120000, loss = 0.0656305
I0916 17:00:32.653275 19004 solver.cpp:563] Iteration 120000, Testing net (#0)
I0916 17:00:53.020601 19016 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 17:00:53.453953 19004 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.956609
I0916 17:00:53.453970 19004 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 17:00:53.453975 19004 solver.cpp:655]     Test net output #2: loss = 0.154177 (* 1 = 0.154177 loss)
I0916 17:00:53.569844 18930 parallel.cpp:71] Root Solver performance on device 0: 4.835 * 6 = 29.01 img/sec (120000 itr in 2.482e+04 sec)
I0916 17:00:53.569862 18930 parallel.cpp:76]      Solver performance on device 1: 4.835 * 6 = 29.01 img/sec (120000 itr in 2.482e+04 sec)
I0916 17:00:53.569867 18930 parallel.cpp:76]      Solver performance on device 2: 4.835 * 6 = 29.01 img/sec (120000 itr in 2.482e+04 sec)
I0916 17:00:53.569869 18930 parallel.cpp:79] Overall multi-GPU performance: 87.0277 img/sec
I0916 17:00:55.085913 18930 caffe.cpp:253] Optimization Done in 6h 54m 8s
training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/run.sh: line 1: cd: /user/a0393608/files/work/code/vision/ti/bitbucket/algoref/caffe-jacinto/build/tools/caffe.bin: Not a directory
I0916 17:01:07.133924 20128 caffe.cpp:807] This is NVCaffe 0.16.4 started at Sat Sep 16 17:01:06 2017
I0916 17:01:07.134588 20128 caffe.cpp:810] CuDNN version: 6021
I0916 17:01:07.134594 20128 caffe.cpp:811] CuBLAS version: 8000
I0916 17:01:07.134598 20128 caffe.cpp:812] CUDA version: 8000
I0916 17:01:07.134600 20128 caffe.cpp:813] CUDA driver version: 8000
I0916 17:01:07.625830 20128 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0916 17:01:07.626406 20128 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8278441984, dev_info[0]: total=8506769408 free=8278441984
I0916 17:01:07.626929 20128 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8278441984, dev_info[1]: total=8508145664 free=8379236352
I0916 17:01:07.627446 20128 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8278441984, dev_info[2]: total=8508145664 free=8379236352
I0916 17:01:07.627454 20128 caffe.cpp:214] Using GPUs 0, 1, 2
I0916 17:01:07.627786 20128 caffe.cpp:219] GPU 0: GeForce GTX 1080
I0916 17:01:07.628127 20128 caffe.cpp:219] GPU 1: GeForce GTX 1080
I0916 17:01:07.628458 20128 caffe.cpp:219] GPU 2: GeForce GTX 1080
I0916 17:01:07.628496 20128 solver.cpp:43] Solver data type: FLOAT
I0916 17:01:07.628531 20128 solver.cpp:46] Initializing solver from parameters: 
train_net: "training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/train.prototxt"
test_net: "training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/test.prototxt"
test_iter: 125
test_interval: 2000
base_lr: 0.01
display: 100
max_iter: 60000
lr_policy: "multistep"
gamma: 0.1
power: 1
momentum: 0.9
weight_decay: 1e-05
snapshot: 10000
snapshot_prefix: "training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/cityscapes5_jsegnet21v2"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
snapshot_after_train: true
regularization_type: "L1"
test_initialization: false
stepvalue: 30000
stepvalue: 45000
iter_size: 1
type: "SGD"
I0916 17:01:07.647444 20128 solver.cpp:78] Creating training net from train_net file: training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/train.prototxt
I0916 17:01:07.660696 20128 net.cpp:443] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top1
I0916 17:01:07.660712 20128 net.cpp:443] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top5
W0916 17:01:07.660763 20128 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 16 to 18
I0916 17:01:07.661136 20128 net.cpp:72] Initializing net from parameters: 
name: "jsegnet21v2_train"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageLabelData"
  top: "data"
  top: "label"
  transform_param {
    mirror: true
    crop_size: 640
    mean_value: 0
  }
  image_label_data_param {
    image_list_path: "data/train-image-lmdb"
    label_list_path: "data/train-label-lmdb"
    batch_size: 6
    shuffle: true
    threads: 1
    backend: LMDB
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "out5a"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "out5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "out5a/bn"
  type: "BatchNorm"
  bottom: "out5a"
  top: "out5a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out5a/relu"
  type: "ReLU"
  bottom: "out5a"
  top: "out5a"
}
layer {
  name: "out5a_up2"
  type: "Deconvolution"
  bottom: "out5a"
  top: "out5a_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 64
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out3a"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "out3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "out3a/bn"
  type: "BatchNorm"
  bottom: "out3a"
  top: "out3a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out3a/relu"
  type: "ReLU"
  bottom: "out3a"
  top: "out3a"
}
layer {
  name: "out3_out5_combined"
  type: "Eltwise"
  bottom: "out5a_up2"
  bottom: "out3a"
  top: "out3_out5_combined"
}
layer {
  name: "ctx_conv1"
  type: "Convolution"
  bottom: "out3_out5_combined"
  top: "ctx_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_conv1/bn"
  type: "BatchNorm"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv1/relu"
  type: "ReLU"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
}
layer {
  name: "ctx_conv2"
  type: "Convolution"
  bottom: "ctx_conv1"
  top: "ctx_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv2/bn"
  type: "BatchNorm"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv2/relu"
  type: "ReLU"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
}
layer {
  name: "ctx_conv3"
  type: "Convolution"
  bottom: "ctx_conv2"
  top: "ctx_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv3/bn"
  type: "BatchNorm"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv3/relu"
  type: "ReLU"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
}
layer {
  name: "ctx_conv4"
  type: "Convolution"
  bottom: "ctx_conv3"
  top: "ctx_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv4/bn"
  type: "BatchNorm"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv4/relu"
  type: "ReLU"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
}
layer {
  name: "ctx_final"
  type: "Convolution"
  bottom: "ctx_conv4"
  top: "ctx_final"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_final/relu"
  type: "ReLU"
  bottom: "ctx_final"
  top: "ctx_final"
}
layer {
  name: "out_deconv_final_up2"
  type: "Deconvolution"
  bottom: "ctx_final"
  top: "out_deconv_final_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up4"
  type: "Deconvolution"
  bottom: "out_deconv_final_up2"
  top: "out_deconv_final_up4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up8"
  type: "Deconvolution"
  bottom: "out_deconv_final_up4"
  top: "out_deconv_final_up8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: 255
    normalization: VALID
  }
}
I0916 17:01:07.661348 20128 net.cpp:104] Using FLOAT as default forward math type
I0916 17:01:07.661355 20128 net.cpp:110] Using FLOAT as default backward math type
I0916 17:01:07.661358 20128 layer_factory.hpp:136] Creating layer 'data' of type 'ImageLabelData'
I0916 17:01:07.661363 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:07.661377 20128 net.cpp:184] Created Layer data (0)
I0916 17:01:07.661382 20128 net.cpp:530] data -> data
I0916 17:01:07.661398 20128 net.cpp:530] data -> label
I0916 17:01:07.684540 20128 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0916 17:01:07.684571 20128 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 17:01:07.736806 20195 db_lmdb.cpp:24] Opened lmdb data/train-image-lmdb
I0916 17:01:07.739987 20128 data_layer.cpp:187] [0] ReshapePrefetch 6, 3, 640, 640
I0916 17:01:07.740047 20128 data_layer.cpp:211] [0] Output data size: 6, 3, 640, 640
I0916 17:01:07.740054 20128 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 17:01:07.740108 20128 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0916 17:01:07.740119 20128 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 17:01:07.740808 20196 data_layer.cpp:101] [0] Parser threads: 1
I0916 17:01:07.740818 20196 data_layer.cpp:103] [0] Transformer threads: 1
I0916 17:01:07.763118 20197 db_lmdb.cpp:24] Opened lmdb data/train-label-lmdb
I0916 17:01:07.764173 20128 data_layer.cpp:187] [0] ReshapePrefetch 6, 1, 640, 640
I0916 17:01:07.764225 20128 data_layer.cpp:211] [0] Output data size: 6, 1, 640, 640
I0916 17:01:07.764232 20128 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 17:01:07.764292 20128 net.cpp:245] Setting up data
I0916 17:01:07.764305 20128 net.cpp:252] TRAIN Top shape for layer 0 'data' 6 3 640 640 (7372800)
I0916 17:01:07.764314 20128 net.cpp:252] TRAIN Top shape for layer 0 'data' 6 1 640 640 (2457600)
I0916 17:01:07.764322 20128 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0916 17:01:07.764328 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:07.764350 20128 net.cpp:184] Created Layer data/bias (1)
I0916 17:01:07.764355 20128 net.cpp:561] data/bias <- data
I0916 17:01:07.764366 20128 net.cpp:530] data/bias -> data/bias
I0916 17:01:07.766208 20198 data_layer.cpp:101] [0] Parser threads: 1
I0916 17:01:07.766227 20198 data_layer.cpp:103] [0] Transformer threads: 1
I0916 17:01:07.780812 20128 net.cpp:245] Setting up data/bias
I0916 17:01:07.780838 20128 net.cpp:252] TRAIN Top shape for layer 1 'data/bias' 6 3 640 640 (7372800)
I0916 17:01:07.780853 20128 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0916 17:01:07.780859 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:07.780890 20128 net.cpp:184] Created Layer conv1a (2)
I0916 17:01:07.780896 20128 net.cpp:561] conv1a <- data/bias
I0916 17:01:07.780902 20128 net.cpp:530] conv1a -> conv1a
I0916 17:01:08.431376 20128 net.cpp:245] Setting up conv1a
I0916 17:01:08.431404 20128 net.cpp:252] TRAIN Top shape for layer 2 'conv1a' 6 32 320 320 (19660800)
I0916 17:01:08.431418 20128 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0916 17:01:08.431424 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.431438 20128 net.cpp:184] Created Layer conv1a/bn (3)
I0916 17:01:08.431442 20128 net.cpp:561] conv1a/bn <- conv1a
I0916 17:01:08.431448 20128 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0916 17:01:08.432309 20128 net.cpp:245] Setting up conv1a/bn
I0916 17:01:08.432319 20128 net.cpp:252] TRAIN Top shape for layer 3 'conv1a/bn' 6 32 320 320 (19660800)
I0916 17:01:08.432329 20128 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0916 17:01:08.432333 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.432341 20128 net.cpp:184] Created Layer conv1a/relu (4)
I0916 17:01:08.432344 20128 net.cpp:561] conv1a/relu <- conv1a
I0916 17:01:08.432348 20128 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0916 17:01:08.432654 20128 net.cpp:245] Setting up conv1a/relu
I0916 17:01:08.432662 20128 net.cpp:252] TRAIN Top shape for layer 4 'conv1a/relu' 6 32 320 320 (19660800)
I0916 17:01:08.432665 20128 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0916 17:01:08.432669 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.432689 20128 net.cpp:184] Created Layer conv1b (5)
I0916 17:01:08.432693 20128 net.cpp:561] conv1b <- conv1a
I0916 17:01:08.432698 20128 net.cpp:530] conv1b -> conv1b
I0916 17:01:08.435050 20128 net.cpp:245] Setting up conv1b
I0916 17:01:08.435062 20128 net.cpp:252] TRAIN Top shape for layer 5 'conv1b' 6 32 320 320 (19660800)
I0916 17:01:08.435070 20128 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0916 17:01:08.435075 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.435081 20128 net.cpp:184] Created Layer conv1b/bn (6)
I0916 17:01:08.435083 20128 net.cpp:561] conv1b/bn <- conv1b
I0916 17:01:08.435087 20128 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0916 17:01:08.435864 20128 net.cpp:245] Setting up conv1b/bn
I0916 17:01:08.435873 20128 net.cpp:252] TRAIN Top shape for layer 6 'conv1b/bn' 6 32 320 320 (19660800)
I0916 17:01:08.435881 20128 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0916 17:01:08.435885 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.435889 20128 net.cpp:184] Created Layer conv1b/relu (7)
I0916 17:01:08.435892 20128 net.cpp:561] conv1b/relu <- conv1b
I0916 17:01:08.435896 20128 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0916 17:01:08.435901 20128 net.cpp:245] Setting up conv1b/relu
I0916 17:01:08.435905 20128 net.cpp:252] TRAIN Top shape for layer 7 'conv1b/relu' 6 32 320 320 (19660800)
I0916 17:01:08.435909 20128 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0916 17:01:08.435912 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.435920 20128 net.cpp:184] Created Layer pool1 (8)
I0916 17:01:08.435923 20128 net.cpp:561] pool1 <- conv1b
I0916 17:01:08.435927 20128 net.cpp:530] pool1 -> pool1
I0916 17:01:08.436015 20128 net.cpp:245] Setting up pool1
I0916 17:01:08.436022 20128 net.cpp:252] TRAIN Top shape for layer 8 'pool1' 6 32 160 160 (4915200)
I0916 17:01:08.436025 20128 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0916 17:01:08.436029 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.436036 20128 net.cpp:184] Created Layer res2a_branch2a (9)
I0916 17:01:08.436050 20128 net.cpp:561] res2a_branch2a <- pool1
I0916 17:01:08.436054 20128 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0916 17:01:08.438700 20128 net.cpp:245] Setting up res2a_branch2a
I0916 17:01:08.438711 20128 net.cpp:252] TRAIN Top shape for layer 9 'res2a_branch2a' 6 64 160 160 (9830400)
I0916 17:01:08.438720 20128 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0916 17:01:08.438724 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.438730 20128 net.cpp:184] Created Layer res2a_branch2a/bn (10)
I0916 17:01:08.438733 20128 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0916 17:01:08.438737 20128 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0916 17:01:08.440078 20128 net.cpp:245] Setting up res2a_branch2a/bn
I0916 17:01:08.440088 20128 net.cpp:252] TRAIN Top shape for layer 10 'res2a_branch2a/bn' 6 64 160 160 (9830400)
I0916 17:01:08.440096 20128 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0916 17:01:08.440100 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.440104 20128 net.cpp:184] Created Layer res2a_branch2a/relu (11)
I0916 17:01:08.440109 20128 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0916 17:01:08.440111 20128 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0916 17:01:08.440119 20128 net.cpp:245] Setting up res2a_branch2a/relu
I0916 17:01:08.440124 20128 net.cpp:252] TRAIN Top shape for layer 11 'res2a_branch2a/relu' 6 64 160 160 (9830400)
I0916 17:01:08.440127 20128 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0916 17:01:08.440131 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.440142 20128 net.cpp:184] Created Layer res2a_branch2b (12)
I0916 17:01:08.440146 20128 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0916 17:01:08.440150 20128 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0916 17:01:08.441963 20128 net.cpp:245] Setting up res2a_branch2b
I0916 17:01:08.441975 20128 net.cpp:252] TRAIN Top shape for layer 12 'res2a_branch2b' 6 64 160 160 (9830400)
I0916 17:01:08.441982 20128 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0916 17:01:08.441985 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.441992 20128 net.cpp:184] Created Layer res2a_branch2b/bn (13)
I0916 17:01:08.441994 20128 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0916 17:01:08.441998 20128 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0916 17:01:08.442667 20128 net.cpp:245] Setting up res2a_branch2b/bn
I0916 17:01:08.442677 20128 net.cpp:252] TRAIN Top shape for layer 13 'res2a_branch2b/bn' 6 64 160 160 (9830400)
I0916 17:01:08.442684 20128 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0916 17:01:08.442688 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.442692 20128 net.cpp:184] Created Layer res2a_branch2b/relu (14)
I0916 17:01:08.442694 20128 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0916 17:01:08.442698 20128 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0916 17:01:08.442701 20128 net.cpp:245] Setting up res2a_branch2b/relu
I0916 17:01:08.442704 20128 net.cpp:252] TRAIN Top shape for layer 14 'res2a_branch2b/relu' 6 64 160 160 (9830400)
I0916 17:01:08.442708 20128 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0916 17:01:08.442709 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.442713 20128 net.cpp:184] Created Layer pool2 (15)
I0916 17:01:08.442716 20128 net.cpp:561] pool2 <- res2a_branch2b
I0916 17:01:08.442720 20128 net.cpp:530] pool2 -> pool2
I0916 17:01:08.442785 20128 net.cpp:245] Setting up pool2
I0916 17:01:08.442790 20128 net.cpp:252] TRAIN Top shape for layer 15 'pool2' 6 64 80 80 (2457600)
I0916 17:01:08.442800 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0916 17:01:08.442803 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.442809 20128 net.cpp:184] Created Layer res3a_branch2a (16)
I0916 17:01:08.442812 20128 net.cpp:561] res3a_branch2a <- pool2
I0916 17:01:08.442814 20128 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0916 17:01:08.444597 20128 net.cpp:245] Setting up res3a_branch2a
I0916 17:01:08.444605 20128 net.cpp:252] TRAIN Top shape for layer 16 'res3a_branch2a' 6 128 80 80 (4915200)
I0916 17:01:08.444610 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0916 17:01:08.444612 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.444617 20128 net.cpp:184] Created Layer res3a_branch2a/bn (17)
I0916 17:01:08.444620 20128 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0916 17:01:08.444622 20128 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0916 17:01:08.445622 20128 net.cpp:245] Setting up res3a_branch2a/bn
I0916 17:01:08.445632 20128 net.cpp:252] TRAIN Top shape for layer 17 'res3a_branch2a/bn' 6 128 80 80 (4915200)
I0916 17:01:08.445643 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0916 17:01:08.445647 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.445657 20128 net.cpp:184] Created Layer res3a_branch2a/relu (18)
I0916 17:01:08.445662 20128 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0916 17:01:08.445664 20128 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0916 17:01:08.445670 20128 net.cpp:245] Setting up res3a_branch2a/relu
I0916 17:01:08.445675 20128 net.cpp:252] TRAIN Top shape for layer 18 'res3a_branch2a/relu' 6 128 80 80 (4915200)
I0916 17:01:08.445679 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0916 17:01:08.445683 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.445694 20128 net.cpp:184] Created Layer res3a_branch2b (19)
I0916 17:01:08.445698 20128 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0916 17:01:08.445703 20128 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0916 17:01:08.447105 20128 net.cpp:245] Setting up res3a_branch2b
I0916 17:01:08.447115 20128 net.cpp:252] TRAIN Top shape for layer 19 'res3a_branch2b' 6 128 80 80 (4915200)
I0916 17:01:08.447121 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0916 17:01:08.447125 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.447131 20128 net.cpp:184] Created Layer res3a_branch2b/bn (20)
I0916 17:01:08.447134 20128 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0916 17:01:08.447139 20128 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0916 17:01:08.447906 20128 net.cpp:245] Setting up res3a_branch2b/bn
I0916 17:01:08.447916 20128 net.cpp:252] TRAIN Top shape for layer 20 'res3a_branch2b/bn' 6 128 80 80 (4915200)
I0916 17:01:08.447924 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0916 17:01:08.447927 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.447932 20128 net.cpp:184] Created Layer res3a_branch2b/relu (21)
I0916 17:01:08.447935 20128 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0916 17:01:08.447938 20128 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0916 17:01:08.447943 20128 net.cpp:245] Setting up res3a_branch2b/relu
I0916 17:01:08.447947 20128 net.cpp:252] TRAIN Top shape for layer 21 'res3a_branch2b/relu' 6 128 80 80 (4915200)
I0916 17:01:08.447952 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0916 17:01:08.447955 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.447971 20128 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (22)
I0916 17:01:08.447975 20128 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0916 17:01:08.447980 20128 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0916 17:01:08.447985 20128 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0916 17:01:08.448040 20128 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0916 17:01:08.448046 20128 net.cpp:252] TRAIN Top shape for layer 22 'res3a_branch2b_res3a_branch2b/relu_0_split' 6 128 80 80 (4915200)
I0916 17:01:08.448051 20128 net.cpp:252] TRAIN Top shape for layer 22 'res3a_branch2b_res3a_branch2b/relu_0_split' 6 128 80 80 (4915200)
I0916 17:01:08.448055 20128 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0916 17:01:08.448060 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.448065 20128 net.cpp:184] Created Layer pool3 (23)
I0916 17:01:08.448070 20128 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0916 17:01:08.448074 20128 net.cpp:530] pool3 -> pool3
I0916 17:01:08.448151 20128 net.cpp:245] Setting up pool3
I0916 17:01:08.448158 20128 net.cpp:252] TRAIN Top shape for layer 23 'pool3' 6 128 40 40 (1228800)
I0916 17:01:08.448161 20128 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0916 17:01:08.448166 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.448175 20128 net.cpp:184] Created Layer res4a_branch2a (24)
I0916 17:01:08.448180 20128 net.cpp:561] res4a_branch2a <- pool3
I0916 17:01:08.448184 20128 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0916 17:01:08.458075 20128 net.cpp:245] Setting up res4a_branch2a
I0916 17:01:08.458086 20128 net.cpp:252] TRAIN Top shape for layer 24 'res4a_branch2a' 6 256 40 40 (2457600)
I0916 17:01:08.458094 20128 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0916 17:01:08.458098 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.458106 20128 net.cpp:184] Created Layer res4a_branch2a/bn (25)
I0916 17:01:08.458111 20128 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0916 17:01:08.458114 20128 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0916 17:01:08.458920 20128 net.cpp:245] Setting up res4a_branch2a/bn
I0916 17:01:08.458930 20128 net.cpp:252] TRAIN Top shape for layer 25 'res4a_branch2a/bn' 6 256 40 40 (2457600)
I0916 17:01:08.458940 20128 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0916 17:01:08.458943 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.458950 20128 net.cpp:184] Created Layer res4a_branch2a/relu (26)
I0916 17:01:08.458953 20128 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0916 17:01:08.458957 20128 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0916 17:01:08.458974 20128 net.cpp:245] Setting up res4a_branch2a/relu
I0916 17:01:08.458981 20128 net.cpp:252] TRAIN Top shape for layer 26 'res4a_branch2a/relu' 6 256 40 40 (2457600)
I0916 17:01:08.458984 20128 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0916 17:01:08.458988 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.458997 20128 net.cpp:184] Created Layer res4a_branch2b (27)
I0916 17:01:08.459002 20128 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0916 17:01:08.459005 20128 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0916 17:01:08.463346 20128 net.cpp:245] Setting up res4a_branch2b
I0916 17:01:08.463362 20128 net.cpp:252] TRAIN Top shape for layer 27 'res4a_branch2b' 6 256 40 40 (2457600)
I0916 17:01:08.463371 20128 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0916 17:01:08.463374 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.463397 20128 net.cpp:184] Created Layer res4a_branch2b/bn (28)
I0916 17:01:08.463400 20128 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0916 17:01:08.463405 20128 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0916 17:01:08.464203 20128 net.cpp:245] Setting up res4a_branch2b/bn
I0916 17:01:08.464212 20128 net.cpp:252] TRAIN Top shape for layer 28 'res4a_branch2b/bn' 6 256 40 40 (2457600)
I0916 17:01:08.464221 20128 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0916 17:01:08.464226 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.464229 20128 net.cpp:184] Created Layer res4a_branch2b/relu (29)
I0916 17:01:08.464232 20128 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0916 17:01:08.464236 20128 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0916 17:01:08.464241 20128 net.cpp:245] Setting up res4a_branch2b/relu
I0916 17:01:08.464246 20128 net.cpp:252] TRAIN Top shape for layer 29 'res4a_branch2b/relu' 6 256 40 40 (2457600)
I0916 17:01:08.464251 20128 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0916 17:01:08.464253 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.464259 20128 net.cpp:184] Created Layer pool4 (30)
I0916 17:01:08.464263 20128 net.cpp:561] pool4 <- res4a_branch2b
I0916 17:01:08.464267 20128 net.cpp:530] pool4 -> pool4
I0916 17:01:08.464352 20128 net.cpp:245] Setting up pool4
I0916 17:01:08.464359 20128 net.cpp:252] TRAIN Top shape for layer 30 'pool4' 6 256 40 40 (2457600)
I0916 17:01:08.464362 20128 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0916 17:01:08.464366 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.464380 20128 net.cpp:184] Created Layer res5a_branch2a (31)
I0916 17:01:08.464383 20128 net.cpp:561] res5a_branch2a <- pool4
I0916 17:01:08.464387 20128 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0916 17:01:08.490763 20128 net.cpp:245] Setting up res5a_branch2a
I0916 17:01:08.490793 20128 net.cpp:252] TRAIN Top shape for layer 31 'res5a_branch2a' 6 512 40 40 (4915200)
I0916 17:01:08.490803 20128 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0916 17:01:08.490808 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.490828 20128 net.cpp:184] Created Layer res5a_branch2a/bn (32)
I0916 17:01:08.490833 20128 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0916 17:01:08.490840 20128 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0916 17:01:08.491541 20128 net.cpp:245] Setting up res5a_branch2a/bn
I0916 17:01:08.491551 20128 net.cpp:252] TRAIN Top shape for layer 32 'res5a_branch2a/bn' 6 512 40 40 (4915200)
I0916 17:01:08.491559 20128 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0916 17:01:08.491561 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.491565 20128 net.cpp:184] Created Layer res5a_branch2a/relu (33)
I0916 17:01:08.491569 20128 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0916 17:01:08.491570 20128 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0916 17:01:08.491575 20128 net.cpp:245] Setting up res5a_branch2a/relu
I0916 17:01:08.491577 20128 net.cpp:252] TRAIN Top shape for layer 33 'res5a_branch2a/relu' 6 512 40 40 (4915200)
I0916 17:01:08.491580 20128 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0916 17:01:08.491583 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.491595 20128 net.cpp:184] Created Layer res5a_branch2b (34)
I0916 17:01:08.491606 20128 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0916 17:01:08.491628 20128 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0916 17:01:08.504639 20128 net.cpp:245] Setting up res5a_branch2b
I0916 17:01:08.504657 20128 net.cpp:252] TRAIN Top shape for layer 34 'res5a_branch2b' 6 512 40 40 (4915200)
I0916 17:01:08.504667 20128 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0916 17:01:08.504669 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.504676 20128 net.cpp:184] Created Layer res5a_branch2b/bn (35)
I0916 17:01:08.504679 20128 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0916 17:01:08.504683 20128 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0916 17:01:08.505385 20128 net.cpp:245] Setting up res5a_branch2b/bn
I0916 17:01:08.505395 20128 net.cpp:252] TRAIN Top shape for layer 35 'res5a_branch2b/bn' 6 512 40 40 (4915200)
I0916 17:01:08.505409 20128 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0916 17:01:08.505414 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.505421 20128 net.cpp:184] Created Layer res5a_branch2b/relu (36)
I0916 17:01:08.505426 20128 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0916 17:01:08.505430 20128 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0916 17:01:08.505437 20128 net.cpp:245] Setting up res5a_branch2b/relu
I0916 17:01:08.505441 20128 net.cpp:252] TRAIN Top shape for layer 36 'res5a_branch2b/relu' 6 512 40 40 (4915200)
I0916 17:01:08.505446 20128 layer_factory.hpp:136] Creating layer 'out5a' of type 'Convolution'
I0916 17:01:08.505450 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.505461 20128 net.cpp:184] Created Layer out5a (37)
I0916 17:01:08.505465 20128 net.cpp:561] out5a <- res5a_branch2b
I0916 17:01:08.505470 20128 net.cpp:530] out5a -> out5a
I0916 17:01:08.509696 20128 net.cpp:245] Setting up out5a
I0916 17:01:08.509706 20128 net.cpp:252] TRAIN Top shape for layer 37 'out5a' 6 64 40 40 (614400)
I0916 17:01:08.509714 20128 layer_factory.hpp:136] Creating layer 'out5a/bn' of type 'BatchNorm'
I0916 17:01:08.509721 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.509728 20128 net.cpp:184] Created Layer out5a/bn (38)
I0916 17:01:08.509732 20128 net.cpp:561] out5a/bn <- out5a
I0916 17:01:08.509738 20128 net.cpp:513] out5a/bn -> out5a (in-place)
I0916 17:01:08.510391 20128 net.cpp:245] Setting up out5a/bn
I0916 17:01:08.510401 20128 net.cpp:252] TRAIN Top shape for layer 38 'out5a/bn' 6 64 40 40 (614400)
I0916 17:01:08.510409 20128 layer_factory.hpp:136] Creating layer 'out5a/relu' of type 'ReLU'
I0916 17:01:08.510414 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.510421 20128 net.cpp:184] Created Layer out5a/relu (39)
I0916 17:01:08.510424 20128 net.cpp:561] out5a/relu <- out5a
I0916 17:01:08.510429 20128 net.cpp:513] out5a/relu -> out5a (in-place)
I0916 17:01:08.510437 20128 net.cpp:245] Setting up out5a/relu
I0916 17:01:08.510442 20128 net.cpp:252] TRAIN Top shape for layer 39 'out5a/relu' 6 64 40 40 (614400)
I0916 17:01:08.510445 20128 layer_factory.hpp:136] Creating layer 'out5a_up2' of type 'Deconvolution'
I0916 17:01:08.510450 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.510464 20128 net.cpp:184] Created Layer out5a_up2 (40)
I0916 17:01:08.510468 20128 net.cpp:561] out5a_up2 <- out5a
I0916 17:01:08.510473 20128 net.cpp:530] out5a_up2 -> out5a_up2
I0916 17:01:08.510759 20128 net.cpp:245] Setting up out5a_up2
I0916 17:01:08.510766 20128 net.cpp:252] TRAIN Top shape for layer 40 'out5a_up2' 6 64 80 80 (2457600)
I0916 17:01:08.510771 20128 layer_factory.hpp:136] Creating layer 'out3a' of type 'Convolution'
I0916 17:01:08.510776 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.510785 20128 net.cpp:184] Created Layer out3a (41)
I0916 17:01:08.510789 20128 net.cpp:561] out3a <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0916 17:01:08.510803 20128 net.cpp:530] out3a -> out3a
I0916 17:01:08.511899 20128 net.cpp:245] Setting up out3a
I0916 17:01:08.511907 20128 net.cpp:252] TRAIN Top shape for layer 41 'out3a' 6 64 80 80 (2457600)
I0916 17:01:08.511914 20128 layer_factory.hpp:136] Creating layer 'out3a/bn' of type 'BatchNorm'
I0916 17:01:08.511920 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.511927 20128 net.cpp:184] Created Layer out3a/bn (42)
I0916 17:01:08.511932 20128 net.cpp:561] out3a/bn <- out3a
I0916 17:01:08.511937 20128 net.cpp:513] out3a/bn -> out3a (in-place)
I0916 17:01:08.512575 20128 net.cpp:245] Setting up out3a/bn
I0916 17:01:08.512583 20128 net.cpp:252] TRAIN Top shape for layer 42 'out3a/bn' 6 64 80 80 (2457600)
I0916 17:01:08.512593 20128 layer_factory.hpp:136] Creating layer 'out3a/relu' of type 'ReLU'
I0916 17:01:08.512598 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.512603 20128 net.cpp:184] Created Layer out3a/relu (43)
I0916 17:01:08.512607 20128 net.cpp:561] out3a/relu <- out3a
I0916 17:01:08.512612 20128 net.cpp:513] out3a/relu -> out3a (in-place)
I0916 17:01:08.512619 20128 net.cpp:245] Setting up out3a/relu
I0916 17:01:08.512624 20128 net.cpp:252] TRAIN Top shape for layer 43 'out3a/relu' 6 64 80 80 (2457600)
I0916 17:01:08.512629 20128 layer_factory.hpp:136] Creating layer 'out3_out5_combined' of type 'Eltwise'
I0916 17:01:08.512634 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.513010 20128 net.cpp:184] Created Layer out3_out5_combined (44)
I0916 17:01:08.513015 20128 net.cpp:561] out3_out5_combined <- out5a_up2
I0916 17:01:08.513020 20128 net.cpp:561] out3_out5_combined <- out3a
I0916 17:01:08.513025 20128 net.cpp:530] out3_out5_combined -> out3_out5_combined
I0916 17:01:08.513056 20128 net.cpp:245] Setting up out3_out5_combined
I0916 17:01:08.513062 20128 net.cpp:252] TRAIN Top shape for layer 44 'out3_out5_combined' 6 64 80 80 (2457600)
I0916 17:01:08.513067 20128 layer_factory.hpp:136] Creating layer 'ctx_conv1' of type 'Convolution'
I0916 17:01:08.513070 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.513084 20128 net.cpp:184] Created Layer ctx_conv1 (45)
I0916 17:01:08.513088 20128 net.cpp:561] ctx_conv1 <- out3_out5_combined
I0916 17:01:08.513093 20128 net.cpp:530] ctx_conv1 -> ctx_conv1
I0916 17:01:08.514189 20128 net.cpp:245] Setting up ctx_conv1
I0916 17:01:08.514199 20128 net.cpp:252] TRAIN Top shape for layer 45 'ctx_conv1' 6 64 80 80 (2457600)
I0916 17:01:08.514205 20128 layer_factory.hpp:136] Creating layer 'ctx_conv1/bn' of type 'BatchNorm'
I0916 17:01:08.514210 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.514217 20128 net.cpp:184] Created Layer ctx_conv1/bn (46)
I0916 17:01:08.514222 20128 net.cpp:561] ctx_conv1/bn <- ctx_conv1
I0916 17:01:08.514227 20128 net.cpp:513] ctx_conv1/bn -> ctx_conv1 (in-place)
I0916 17:01:08.514879 20128 net.cpp:245] Setting up ctx_conv1/bn
I0916 17:01:08.514888 20128 net.cpp:252] TRAIN Top shape for layer 46 'ctx_conv1/bn' 6 64 80 80 (2457600)
I0916 17:01:08.514896 20128 layer_factory.hpp:136] Creating layer 'ctx_conv1/relu' of type 'ReLU'
I0916 17:01:08.514901 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.514906 20128 net.cpp:184] Created Layer ctx_conv1/relu (47)
I0916 17:01:08.514911 20128 net.cpp:561] ctx_conv1/relu <- ctx_conv1
I0916 17:01:08.514916 20128 net.cpp:513] ctx_conv1/relu -> ctx_conv1 (in-place)
I0916 17:01:08.514922 20128 net.cpp:245] Setting up ctx_conv1/relu
I0916 17:01:08.514928 20128 net.cpp:252] TRAIN Top shape for layer 47 'ctx_conv1/relu' 6 64 80 80 (2457600)
I0916 17:01:08.514931 20128 layer_factory.hpp:136] Creating layer 'ctx_conv2' of type 'Convolution'
I0916 17:01:08.514933 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.514946 20128 net.cpp:184] Created Layer ctx_conv2 (48)
I0916 17:01:08.514948 20128 net.cpp:561] ctx_conv2 <- ctx_conv1
I0916 17:01:08.514950 20128 net.cpp:530] ctx_conv2 -> ctx_conv2
I0916 17:01:08.516031 20128 net.cpp:245] Setting up ctx_conv2
I0916 17:01:08.516038 20128 net.cpp:252] TRAIN Top shape for layer 48 'ctx_conv2' 6 64 80 80 (2457600)
I0916 17:01:08.516042 20128 layer_factory.hpp:136] Creating layer 'ctx_conv2/bn' of type 'BatchNorm'
I0916 17:01:08.516046 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.516049 20128 net.cpp:184] Created Layer ctx_conv2/bn (49)
I0916 17:01:08.516052 20128 net.cpp:561] ctx_conv2/bn <- ctx_conv2
I0916 17:01:08.516053 20128 net.cpp:513] ctx_conv2/bn -> ctx_conv2 (in-place)
I0916 17:01:08.516685 20128 net.cpp:245] Setting up ctx_conv2/bn
I0916 17:01:08.516691 20128 net.cpp:252] TRAIN Top shape for layer 49 'ctx_conv2/bn' 6 64 80 80 (2457600)
I0916 17:01:08.516697 20128 layer_factory.hpp:136] Creating layer 'ctx_conv2/relu' of type 'ReLU'
I0916 17:01:08.516700 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.516702 20128 net.cpp:184] Created Layer ctx_conv2/relu (50)
I0916 17:01:08.516705 20128 net.cpp:561] ctx_conv2/relu <- ctx_conv2
I0916 17:01:08.516706 20128 net.cpp:513] ctx_conv2/relu -> ctx_conv2 (in-place)
I0916 17:01:08.516710 20128 net.cpp:245] Setting up ctx_conv2/relu
I0916 17:01:08.516712 20128 net.cpp:252] TRAIN Top shape for layer 50 'ctx_conv2/relu' 6 64 80 80 (2457600)
I0916 17:01:08.516715 20128 layer_factory.hpp:136] Creating layer 'ctx_conv3' of type 'Convolution'
I0916 17:01:08.516716 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.516729 20128 net.cpp:184] Created Layer ctx_conv3 (51)
I0916 17:01:08.516733 20128 net.cpp:561] ctx_conv3 <- ctx_conv2
I0916 17:01:08.516737 20128 net.cpp:530] ctx_conv3 -> ctx_conv3
I0916 17:01:08.517874 20128 net.cpp:245] Setting up ctx_conv3
I0916 17:01:08.517881 20128 net.cpp:252] TRAIN Top shape for layer 51 'ctx_conv3' 6 64 80 80 (2457600)
I0916 17:01:08.517885 20128 layer_factory.hpp:136] Creating layer 'ctx_conv3/bn' of type 'BatchNorm'
I0916 17:01:08.517887 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.517891 20128 net.cpp:184] Created Layer ctx_conv3/bn (52)
I0916 17:01:08.517894 20128 net.cpp:561] ctx_conv3/bn <- ctx_conv3
I0916 17:01:08.517896 20128 net.cpp:513] ctx_conv3/bn -> ctx_conv3 (in-place)
I0916 17:01:08.518534 20128 net.cpp:245] Setting up ctx_conv3/bn
I0916 17:01:08.518543 20128 net.cpp:252] TRAIN Top shape for layer 52 'ctx_conv3/bn' 6 64 80 80 (2457600)
I0916 17:01:08.518548 20128 layer_factory.hpp:136] Creating layer 'ctx_conv3/relu' of type 'ReLU'
I0916 17:01:08.518550 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.518554 20128 net.cpp:184] Created Layer ctx_conv3/relu (53)
I0916 17:01:08.518556 20128 net.cpp:561] ctx_conv3/relu <- ctx_conv3
I0916 17:01:08.518558 20128 net.cpp:513] ctx_conv3/relu -> ctx_conv3 (in-place)
I0916 17:01:08.518566 20128 net.cpp:245] Setting up ctx_conv3/relu
I0916 17:01:08.518569 20128 net.cpp:252] TRAIN Top shape for layer 53 'ctx_conv3/relu' 6 64 80 80 (2457600)
I0916 17:01:08.518571 20128 layer_factory.hpp:136] Creating layer 'ctx_conv4' of type 'Convolution'
I0916 17:01:08.518574 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.518585 20128 net.cpp:184] Created Layer ctx_conv4 (54)
I0916 17:01:08.518590 20128 net.cpp:561] ctx_conv4 <- ctx_conv3
I0916 17:01:08.518594 20128 net.cpp:530] ctx_conv4 -> ctx_conv4
I0916 17:01:08.519671 20128 net.cpp:245] Setting up ctx_conv4
I0916 17:01:08.519678 20128 net.cpp:252] TRAIN Top shape for layer 54 'ctx_conv4' 6 64 80 80 (2457600)
I0916 17:01:08.519682 20128 layer_factory.hpp:136] Creating layer 'ctx_conv4/bn' of type 'BatchNorm'
I0916 17:01:08.519691 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.519695 20128 net.cpp:184] Created Layer ctx_conv4/bn (55)
I0916 17:01:08.519698 20128 net.cpp:561] ctx_conv4/bn <- ctx_conv4
I0916 17:01:08.519701 20128 net.cpp:513] ctx_conv4/bn -> ctx_conv4 (in-place)
I0916 17:01:08.520344 20128 net.cpp:245] Setting up ctx_conv4/bn
I0916 17:01:08.520351 20128 net.cpp:252] TRAIN Top shape for layer 55 'ctx_conv4/bn' 6 64 80 80 (2457600)
I0916 17:01:08.520357 20128 layer_factory.hpp:136] Creating layer 'ctx_conv4/relu' of type 'ReLU'
I0916 17:01:08.520359 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.520362 20128 net.cpp:184] Created Layer ctx_conv4/relu (56)
I0916 17:01:08.520364 20128 net.cpp:561] ctx_conv4/relu <- ctx_conv4
I0916 17:01:08.520366 20128 net.cpp:513] ctx_conv4/relu -> ctx_conv4 (in-place)
I0916 17:01:08.520370 20128 net.cpp:245] Setting up ctx_conv4/relu
I0916 17:01:08.520372 20128 net.cpp:252] TRAIN Top shape for layer 56 'ctx_conv4/relu' 6 64 80 80 (2457600)
I0916 17:01:08.520375 20128 layer_factory.hpp:136] Creating layer 'ctx_final' of type 'Convolution'
I0916 17:01:08.520376 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.520387 20128 net.cpp:184] Created Layer ctx_final (57)
I0916 17:01:08.520392 20128 net.cpp:561] ctx_final <- ctx_conv4
I0916 17:01:08.520396 20128 net.cpp:530] ctx_final -> ctx_final
I0916 17:01:08.520849 20128 net.cpp:245] Setting up ctx_final
I0916 17:01:08.520856 20128 net.cpp:252] TRAIN Top shape for layer 57 'ctx_final' 6 8 80 80 (307200)
I0916 17:01:08.520860 20128 layer_factory.hpp:136] Creating layer 'ctx_final/relu' of type 'ReLU'
I0916 17:01:08.520864 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.520866 20128 net.cpp:184] Created Layer ctx_final/relu (58)
I0916 17:01:08.520869 20128 net.cpp:561] ctx_final/relu <- ctx_final
I0916 17:01:08.520870 20128 net.cpp:513] ctx_final/relu -> ctx_final (in-place)
I0916 17:01:08.520874 20128 net.cpp:245] Setting up ctx_final/relu
I0916 17:01:08.520876 20128 net.cpp:252] TRAIN Top shape for layer 58 'ctx_final/relu' 6 8 80 80 (307200)
I0916 17:01:08.520879 20128 layer_factory.hpp:136] Creating layer 'out_deconv_final_up2' of type 'Deconvolution'
I0916 17:01:08.520880 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.520885 20128 net.cpp:184] Created Layer out_deconv_final_up2 (59)
I0916 17:01:08.520889 20128 net.cpp:561] out_deconv_final_up2 <- ctx_final
I0916 17:01:08.520894 20128 net.cpp:530] out_deconv_final_up2 -> out_deconv_final_up2
I0916 17:01:08.521163 20128 net.cpp:245] Setting up out_deconv_final_up2
I0916 17:01:08.521169 20128 net.cpp:252] TRAIN Top shape for layer 59 'out_deconv_final_up2' 6 8 160 160 (1228800)
I0916 17:01:08.521173 20128 layer_factory.hpp:136] Creating layer 'out_deconv_final_up4' of type 'Deconvolution'
I0916 17:01:08.521174 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.521178 20128 net.cpp:184] Created Layer out_deconv_final_up4 (60)
I0916 17:01:08.521180 20128 net.cpp:561] out_deconv_final_up4 <- out_deconv_final_up2
I0916 17:01:08.521183 20128 net.cpp:530] out_deconv_final_up4 -> out_deconv_final_up4
I0916 17:01:08.521458 20128 net.cpp:245] Setting up out_deconv_final_up4
I0916 17:01:08.521464 20128 net.cpp:252] TRAIN Top shape for layer 60 'out_deconv_final_up4' 6 8 320 320 (4915200)
I0916 17:01:08.521467 20128 layer_factory.hpp:136] Creating layer 'out_deconv_final_up8' of type 'Deconvolution'
I0916 17:01:08.521471 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.521474 20128 net.cpp:184] Created Layer out_deconv_final_up8 (61)
I0916 17:01:08.521476 20128 net.cpp:561] out_deconv_final_up8 <- out_deconv_final_up4
I0916 17:01:08.521478 20128 net.cpp:530] out_deconv_final_up8 -> out_deconv_final_up8
I0916 17:01:08.521746 20128 net.cpp:245] Setting up out_deconv_final_up8
I0916 17:01:08.521752 20128 net.cpp:252] TRAIN Top shape for layer 61 'out_deconv_final_up8' 6 8 640 640 (19660800)
I0916 17:01:08.521756 20128 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0916 17:01:08.521759 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.521767 20128 net.cpp:184] Created Layer loss (62)
I0916 17:01:08.521770 20128 net.cpp:561] loss <- out_deconv_final_up8
I0916 17:01:08.521772 20128 net.cpp:561] loss <- label
I0916 17:01:08.521776 20128 net.cpp:530] loss -> loss
I0916 17:01:08.523178 20128 net.cpp:245] Setting up loss
I0916 17:01:08.523195 20128 net.cpp:252] TRAIN Top shape for layer 62 'loss' (1)
I0916 17:01:08.523197 20128 net.cpp:256]     with loss weight 1
I0916 17:01:08.523208 20128 net.cpp:323] loss needs backward computation.
I0916 17:01:08.523211 20128 net.cpp:323] out_deconv_final_up8 needs backward computation.
I0916 17:01:08.523213 20128 net.cpp:323] out_deconv_final_up4 needs backward computation.
I0916 17:01:08.523223 20128 net.cpp:323] out_deconv_final_up2 needs backward computation.
I0916 17:01:08.523226 20128 net.cpp:323] ctx_final/relu needs backward computation.
I0916 17:01:08.523229 20128 net.cpp:323] ctx_final needs backward computation.
I0916 17:01:08.523231 20128 net.cpp:323] ctx_conv4/relu needs backward computation.
I0916 17:01:08.523236 20128 net.cpp:323] ctx_conv4/bn needs backward computation.
I0916 17:01:08.523239 20128 net.cpp:323] ctx_conv4 needs backward computation.
I0916 17:01:08.523243 20128 net.cpp:323] ctx_conv3/relu needs backward computation.
I0916 17:01:08.523247 20128 net.cpp:323] ctx_conv3/bn needs backward computation.
I0916 17:01:08.523259 20128 net.cpp:323] ctx_conv3 needs backward computation.
I0916 17:01:08.523265 20128 net.cpp:323] ctx_conv2/relu needs backward computation.
I0916 17:01:08.523269 20128 net.cpp:323] ctx_conv2/bn needs backward computation.
I0916 17:01:08.523273 20128 net.cpp:323] ctx_conv2 needs backward computation.
I0916 17:01:08.523278 20128 net.cpp:323] ctx_conv1/relu needs backward computation.
I0916 17:01:08.523283 20128 net.cpp:323] ctx_conv1/bn needs backward computation.
I0916 17:01:08.523288 20128 net.cpp:323] ctx_conv1 needs backward computation.
I0916 17:01:08.523291 20128 net.cpp:323] out3_out5_combined needs backward computation.
I0916 17:01:08.523296 20128 net.cpp:323] out3a/relu needs backward computation.
I0916 17:01:08.523301 20128 net.cpp:323] out3a/bn needs backward computation.
I0916 17:01:08.523305 20128 net.cpp:323] out3a needs backward computation.
I0916 17:01:08.523310 20128 net.cpp:323] out5a_up2 needs backward computation.
I0916 17:01:08.523314 20128 net.cpp:323] out5a/relu needs backward computation.
I0916 17:01:08.523319 20128 net.cpp:323] out5a/bn needs backward computation.
I0916 17:01:08.523322 20128 net.cpp:323] out5a needs backward computation.
I0916 17:01:08.523327 20128 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0916 17:01:08.523331 20128 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0916 17:01:08.523336 20128 net.cpp:323] res5a_branch2b needs backward computation.
I0916 17:01:08.523340 20128 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0916 17:01:08.523344 20128 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0916 17:01:08.523350 20128 net.cpp:323] res5a_branch2a needs backward computation.
I0916 17:01:08.523353 20128 net.cpp:323] pool4 needs backward computation.
I0916 17:01:08.523358 20128 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0916 17:01:08.523362 20128 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0916 17:01:08.523366 20128 net.cpp:323] res4a_branch2b needs backward computation.
I0916 17:01:08.523370 20128 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0916 17:01:08.523375 20128 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0916 17:01:08.523380 20128 net.cpp:323] res4a_branch2a needs backward computation.
I0916 17:01:08.523391 20128 net.cpp:323] pool3 needs backward computation.
I0916 17:01:08.523396 20128 net.cpp:323] res3a_branch2b_res3a_branch2b/relu_0_split needs backward computation.
I0916 17:01:08.523401 20128 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0916 17:01:08.523406 20128 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0916 17:01:08.523411 20128 net.cpp:323] res3a_branch2b needs backward computation.
I0916 17:01:08.523414 20128 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0916 17:01:08.523419 20128 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0916 17:01:08.523423 20128 net.cpp:323] res3a_branch2a needs backward computation.
I0916 17:01:08.523427 20128 net.cpp:323] pool2 needs backward computation.
I0916 17:01:08.523432 20128 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0916 17:01:08.523437 20128 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0916 17:01:08.523442 20128 net.cpp:323] res2a_branch2b needs backward computation.
I0916 17:01:08.523445 20128 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0916 17:01:08.523450 20128 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0916 17:01:08.523454 20128 net.cpp:323] res2a_branch2a needs backward computation.
I0916 17:01:08.523459 20128 net.cpp:323] pool1 needs backward computation.
I0916 17:01:08.523463 20128 net.cpp:323] conv1b/relu needs backward computation.
I0916 17:01:08.523468 20128 net.cpp:323] conv1b/bn needs backward computation.
I0916 17:01:08.523473 20128 net.cpp:323] conv1b needs backward computation.
I0916 17:01:08.523478 20128 net.cpp:323] conv1a/relu needs backward computation.
I0916 17:01:08.523481 20128 net.cpp:323] conv1a/bn needs backward computation.
I0916 17:01:08.523485 20128 net.cpp:323] conv1a needs backward computation.
I0916 17:01:08.523490 20128 net.cpp:325] data/bias does not need backward computation.
I0916 17:01:08.523495 20128 net.cpp:325] data does not need backward computation.
I0916 17:01:08.523500 20128 net.cpp:367] This network produces output loss
I0916 17:01:08.523547 20128 net.cpp:389] Top memory (TRAIN) required for data: 1435238408 diff: 1435238408
I0916 17:01:08.523551 20128 net.cpp:392] Bottom memory (TRAIN) required for data: 1435238400 diff: 1435238400
I0916 17:01:08.523555 20128 net.cpp:395] Shared (in-place) memory (TRAIN) by data: 772915200 diff: 772915200
I0916 17:01:08.523560 20128 net.cpp:398] Parameters memory (TRAIN) required for data: 10817840 diff: 10817840
I0916 17:01:08.523563 20128 net.cpp:401] Parameters shared memory (TRAIN) by data: 0 diff: 0
I0916 17:01:08.523567 20128 net.cpp:407] Network initialization done.
I0916 17:01:08.524612 20128 solver.cpp:177] Creating test net (#0) specified by test_net file: training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/test.prototxt
W0916 17:01:08.524713 20128 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 4 to 6
I0916 17:01:08.525012 20128 net.cpp:72] Initializing net from parameters: 
name: "jsegnet21v2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageLabelData"
  top: "data"
  top: "label"
  transform_param {
    mirror: false
    crop_size: 640
    mean_value: 0
  }
  image_label_data_param {
    image_list_path: "data/val-image-lmdb"
    label_list_path: "data/val-label-lmdb"
    batch_size: 2
    threads: 1
    backend: LMDB
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "out5a"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "out5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "out5a/bn"
  type: "BatchNorm"
  bottom: "out5a"
  top: "out5a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out5a/relu"
  type: "ReLU"
  bottom: "out5a"
  top: "out5a"
}
layer {
  name: "out5a_up2"
  type: "Deconvolution"
  bottom: "out5a"
  top: "out5a_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 64
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out3a"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "out3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "out3a/bn"
  type: "BatchNorm"
  bottom: "out3a"
  top: "out3a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out3a/relu"
  type: "ReLU"
  bottom: "out3a"
  top: "out3a"
}
layer {
  name: "out3_out5_combined"
  type: "Eltwise"
  bottom: "out5a_up2"
  bottom: "out3a"
  top: "out3_out5_combined"
}
layer {
  name: "ctx_conv1"
  type: "Convolution"
  bottom: "out3_out5_combined"
  top: "ctx_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_conv1/bn"
  type: "BatchNorm"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv1/relu"
  type: "ReLU"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
}
layer {
  name: "ctx_conv2"
  type: "Convolution"
  bottom: "ctx_conv1"
  top: "ctx_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv2/bn"
  type: "BatchNorm"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv2/relu"
  type: "ReLU"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
}
layer {
  name: "ctx_conv3"
  type: "Convolution"
  bottom: "ctx_conv2"
  top: "ctx_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv3/bn"
  type: "BatchNorm"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv3/relu"
  type: "ReLU"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
}
layer {
  name: "ctx_conv4"
  type: "Convolution"
  bottom: "ctx_conv3"
  top: "ctx_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv4/bn"
  type: "BatchNorm"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv4/relu"
  type: "ReLU"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
}
layer {
  name: "ctx_final"
  type: "Convolution"
  bottom: "ctx_conv4"
  top: "ctx_final"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_final/relu"
  type: "ReLU"
  bottom: "ctx_final"
  top: "ctx_final"
}
layer {
  name: "out_deconv_final_up2"
  type: "Deconvolution"
  bottom: "ctx_final"
  top: "out_deconv_final_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up4"
  type: "Deconvolution"
  bottom: "out_deconv_final_up2"
  top: "out_deconv_final_up4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up8"
  type: "Deconvolution"
  bottom: "out_deconv_final_up4"
  top: "out_deconv_final_up8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: 255
    normalization: VALID
  }
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "accuracy/top1"
  include {
    phase: TEST
  }
  accuracy_param {
    ignore_label: 255
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "accuracy/top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
    ignore_label: 255
  }
}
I0916 17:01:08.525225 20128 net.cpp:104] Using FLOAT as default forward math type
I0916 17:01:08.525231 20128 net.cpp:110] Using FLOAT as default backward math type
I0916 17:01:08.525235 20128 layer_factory.hpp:136] Creating layer 'data' of type 'ImageLabelData'
I0916 17:01:08.525241 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.525249 20128 net.cpp:184] Created Layer data (0)
I0916 17:01:08.525252 20128 net.cpp:530] data -> data
I0916 17:01:08.525259 20128 net.cpp:530] data -> label
I0916 17:01:08.525295 20128 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 2
I0916 17:01:08.525302 20128 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 17:01:08.549280 20202 db_lmdb.cpp:24] Opened lmdb data/val-image-lmdb
I0916 17:01:08.550817 20128 data_layer.cpp:187] (0) ReshapePrefetch 2, 3, 640, 640
I0916 17:01:08.550870 20128 data_layer.cpp:211] (0) Output data size: 2, 3, 640, 640
I0916 17:01:08.550876 20128 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 17:01:08.550915 20128 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 2
I0916 17:01:08.550925 20128 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 17:01:08.551724 20203 data_layer.cpp:101] (0) Parser threads: 1
I0916 17:01:08.551743 20203 data_layer.cpp:103] (0) Transformer threads: 1
I0916 17:01:08.560511 20204 db_lmdb.cpp:24] Opened lmdb data/val-label-lmdb
I0916 17:01:08.561828 20128 data_layer.cpp:187] (0) ReshapePrefetch 2, 1, 640, 640
I0916 17:01:08.561946 20128 data_layer.cpp:211] (0) Output data size: 2, 1, 640, 640
I0916 17:01:08.561956 20128 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 17:01:08.562018 20128 net.cpp:245] Setting up data
I0916 17:01:08.562048 20128 net.cpp:252] TEST Top shape for layer 0 'data' 2 3 640 640 (2457600)
I0916 17:01:08.562106 20128 net.cpp:252] TEST Top shape for layer 0 'data' 2 1 640 640 (819200)
I0916 17:01:08.562121 20128 layer_factory.hpp:136] Creating layer 'label_data_1_split' of type 'Split'
I0916 17:01:08.562135 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.562151 20128 net.cpp:184] Created Layer label_data_1_split (1)
I0916 17:01:08.562161 20128 net.cpp:561] label_data_1_split <- label
I0916 17:01:08.562173 20128 net.cpp:530] label_data_1_split -> label_data_1_split_0
I0916 17:01:08.562189 20128 net.cpp:530] label_data_1_split -> label_data_1_split_1
I0916 17:01:08.562204 20128 net.cpp:530] label_data_1_split -> label_data_1_split_2
I0916 17:01:08.562336 20128 net.cpp:245] Setting up label_data_1_split
I0916 17:01:08.562360 20128 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 2 1 640 640 (819200)
I0916 17:01:08.562371 20128 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 2 1 640 640 (819200)
I0916 17:01:08.562387 20128 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 2 1 640 640 (819200)
I0916 17:01:08.562405 20128 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0916 17:01:08.562425 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.562443 20128 net.cpp:184] Created Layer data/bias (2)
I0916 17:01:08.562453 20128 net.cpp:561] data/bias <- data
I0916 17:01:08.562463 20128 net.cpp:530] data/bias -> data/bias
I0916 17:01:08.564023 20205 data_layer.cpp:101] (0) Parser threads: 1
I0916 17:01:08.564043 20205 data_layer.cpp:103] (0) Transformer threads: 1
I0916 17:01:08.565803 20128 net.cpp:245] Setting up data/bias
I0916 17:01:08.565817 20128 net.cpp:252] TEST Top shape for layer 2 'data/bias' 2 3 640 640 (2457600)
I0916 17:01:08.565826 20128 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0916 17:01:08.565834 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.565847 20128 net.cpp:184] Created Layer conv1a (3)
I0916 17:01:08.565851 20128 net.cpp:561] conv1a <- data/bias
I0916 17:01:08.565856 20128 net.cpp:530] conv1a -> conv1a
I0916 17:01:08.566372 20128 net.cpp:245] Setting up conv1a
I0916 17:01:08.566381 20128 net.cpp:252] TEST Top shape for layer 3 'conv1a' 2 32 320 320 (6553600)
I0916 17:01:08.566386 20128 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0916 17:01:08.566390 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.566396 20128 net.cpp:184] Created Layer conv1a/bn (4)
I0916 17:01:08.566398 20128 net.cpp:561] conv1a/bn <- conv1a
I0916 17:01:08.566401 20128 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0916 17:01:08.567113 20128 net.cpp:245] Setting up conv1a/bn
I0916 17:01:08.567122 20128 net.cpp:252] TEST Top shape for layer 4 'conv1a/bn' 2 32 320 320 (6553600)
I0916 17:01:08.567131 20128 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0916 17:01:08.567136 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.567142 20128 net.cpp:184] Created Layer conv1a/relu (5)
I0916 17:01:08.567145 20128 net.cpp:561] conv1a/relu <- conv1a
I0916 17:01:08.567148 20128 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0916 17:01:08.567154 20128 net.cpp:245] Setting up conv1a/relu
I0916 17:01:08.567159 20128 net.cpp:252] TEST Top shape for layer 5 'conv1a/relu' 2 32 320 320 (6553600)
I0916 17:01:08.567162 20128 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0916 17:01:08.567167 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.567175 20128 net.cpp:184] Created Layer conv1b (6)
I0916 17:01:08.567178 20128 net.cpp:561] conv1b <- conv1a
I0916 17:01:08.567180 20128 net.cpp:530] conv1b -> conv1b
I0916 17:01:08.568224 20128 net.cpp:245] Setting up conv1b
I0916 17:01:08.568233 20128 net.cpp:252] TEST Top shape for layer 6 'conv1b' 2 32 320 320 (6553600)
I0916 17:01:08.568250 20128 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0916 17:01:08.568256 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.568270 20128 net.cpp:184] Created Layer conv1b/bn (7)
I0916 17:01:08.568274 20128 net.cpp:561] conv1b/bn <- conv1b
I0916 17:01:08.568276 20128 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0916 17:01:08.568989 20128 net.cpp:245] Setting up conv1b/bn
I0916 17:01:08.568996 20128 net.cpp:252] TEST Top shape for layer 7 'conv1b/bn' 2 32 320 320 (6553600)
I0916 17:01:08.569003 20128 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0916 17:01:08.569008 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.569013 20128 net.cpp:184] Created Layer conv1b/relu (8)
I0916 17:01:08.569016 20128 net.cpp:561] conv1b/relu <- conv1b
I0916 17:01:08.569020 20128 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0916 17:01:08.569025 20128 net.cpp:245] Setting up conv1b/relu
I0916 17:01:08.569030 20128 net.cpp:252] TEST Top shape for layer 8 'conv1b/relu' 2 32 320 320 (6553600)
I0916 17:01:08.569033 20128 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0916 17:01:08.569037 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.569042 20128 net.cpp:184] Created Layer pool1 (9)
I0916 17:01:08.569046 20128 net.cpp:561] pool1 <- conv1b
I0916 17:01:08.569049 20128 net.cpp:530] pool1 -> pool1
I0916 17:01:08.569113 20128 net.cpp:245] Setting up pool1
I0916 17:01:08.569118 20128 net.cpp:252] TEST Top shape for layer 9 'pool1' 2 32 160 160 (1638400)
I0916 17:01:08.569121 20128 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0916 17:01:08.569125 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.569136 20128 net.cpp:184] Created Layer res2a_branch2a (10)
I0916 17:01:08.569139 20128 net.cpp:561] res2a_branch2a <- pool1
I0916 17:01:08.569142 20128 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0916 17:01:08.569885 20128 net.cpp:245] Setting up res2a_branch2a
I0916 17:01:08.569896 20128 net.cpp:252] TEST Top shape for layer 10 'res2a_branch2a' 2 64 160 160 (3276800)
I0916 17:01:08.569907 20128 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0916 17:01:08.569911 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.569921 20128 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0916 17:01:08.569924 20128 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0916 17:01:08.569927 20128 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0916 17:01:08.570601 20128 net.cpp:245] Setting up res2a_branch2a/bn
I0916 17:01:08.570608 20128 net.cpp:252] TEST Top shape for layer 11 'res2a_branch2a/bn' 2 64 160 160 (3276800)
I0916 17:01:08.570616 20128 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0916 17:01:08.570621 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.570626 20128 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0916 17:01:08.570629 20128 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0916 17:01:08.570633 20128 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0916 17:01:08.570638 20128 net.cpp:245] Setting up res2a_branch2a/relu
I0916 17:01:08.570643 20128 net.cpp:252] TEST Top shape for layer 12 'res2a_branch2a/relu' 2 64 160 160 (3276800)
I0916 17:01:08.570647 20128 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0916 17:01:08.570650 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.570657 20128 net.cpp:184] Created Layer res2a_branch2b (13)
I0916 17:01:08.570660 20128 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0916 17:01:08.570663 20128 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0916 17:01:08.571221 20128 net.cpp:245] Setting up res2a_branch2b
I0916 17:01:08.571228 20128 net.cpp:252] TEST Top shape for layer 13 'res2a_branch2b' 2 64 160 160 (3276800)
I0916 17:01:08.571234 20128 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0916 17:01:08.571238 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.571244 20128 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0916 17:01:08.571247 20128 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0916 17:01:08.571251 20128 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0916 17:01:08.571964 20128 net.cpp:245] Setting up res2a_branch2b/bn
I0916 17:01:08.571971 20128 net.cpp:252] TEST Top shape for layer 14 'res2a_branch2b/bn' 2 64 160 160 (3276800)
I0916 17:01:08.571980 20128 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0916 17:01:08.571983 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.571995 20128 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0916 17:01:08.571998 20128 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0916 17:01:08.572000 20128 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0916 17:01:08.572006 20128 net.cpp:245] Setting up res2a_branch2b/relu
I0916 17:01:08.572010 20128 net.cpp:252] TEST Top shape for layer 15 'res2a_branch2b/relu' 2 64 160 160 (3276800)
I0916 17:01:08.572015 20128 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0916 17:01:08.572017 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.572023 20128 net.cpp:184] Created Layer pool2 (16)
I0916 17:01:08.572027 20128 net.cpp:561] pool2 <- res2a_branch2b
I0916 17:01:08.572029 20128 net.cpp:530] pool2 -> pool2
I0916 17:01:08.572093 20128 net.cpp:245] Setting up pool2
I0916 17:01:08.572098 20128 net.cpp:252] TEST Top shape for layer 16 'pool2' 2 64 80 80 (819200)
I0916 17:01:08.572101 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0916 17:01:08.572105 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.572113 20128 net.cpp:184] Created Layer res3a_branch2a (17)
I0916 17:01:08.572116 20128 net.cpp:561] res3a_branch2a <- pool2
I0916 17:01:08.572118 20128 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0916 17:01:08.573937 20128 net.cpp:245] Setting up res3a_branch2a
I0916 17:01:08.573945 20128 net.cpp:252] TEST Top shape for layer 17 'res3a_branch2a' 2 128 80 80 (1638400)
I0916 17:01:08.573951 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0916 17:01:08.573954 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.573961 20128 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0916 17:01:08.573964 20128 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0916 17:01:08.573967 20128 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0916 17:01:08.574611 20128 net.cpp:245] Setting up res3a_branch2a/bn
I0916 17:01:08.574620 20128 net.cpp:252] TEST Top shape for layer 18 'res3a_branch2a/bn' 2 128 80 80 (1638400)
I0916 17:01:08.574632 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0916 17:01:08.574635 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.574640 20128 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0916 17:01:08.574643 20128 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0916 17:01:08.574647 20128 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0916 17:01:08.574652 20128 net.cpp:245] Setting up res3a_branch2a/relu
I0916 17:01:08.574656 20128 net.cpp:252] TEST Top shape for layer 19 'res3a_branch2a/relu' 2 128 80 80 (1638400)
I0916 17:01:08.574661 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0916 17:01:08.574664 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.574686 20128 net.cpp:184] Created Layer res3a_branch2b (20)
I0916 17:01:08.574688 20128 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0916 17:01:08.574692 20128 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0916 17:01:08.575778 20128 net.cpp:245] Setting up res3a_branch2b
I0916 17:01:08.575784 20128 net.cpp:252] TEST Top shape for layer 20 'res3a_branch2b' 2 128 80 80 (1638400)
I0916 17:01:08.575790 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0916 17:01:08.575794 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.575800 20128 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0916 17:01:08.575804 20128 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0916 17:01:08.575808 20128 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0916 17:01:08.576436 20128 net.cpp:245] Setting up res3a_branch2b/bn
I0916 17:01:08.576443 20128 net.cpp:252] TEST Top shape for layer 21 'res3a_branch2b/bn' 2 128 80 80 (1638400)
I0916 17:01:08.576452 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0916 17:01:08.576455 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.576458 20128 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0916 17:01:08.576462 20128 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0916 17:01:08.576465 20128 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0916 17:01:08.576470 20128 net.cpp:245] Setting up res3a_branch2b/relu
I0916 17:01:08.576475 20128 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b/relu' 2 128 80 80 (1638400)
I0916 17:01:08.576478 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0916 17:01:08.576483 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.576488 20128 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (23)
I0916 17:01:08.576491 20128 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0916 17:01:08.576494 20128 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0916 17:01:08.576499 20128 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0916 17:01:08.576550 20128 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0916 17:01:08.576555 20128 net.cpp:252] TEST Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 2 128 80 80 (1638400)
I0916 17:01:08.576560 20128 net.cpp:252] TEST Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 2 128 80 80 (1638400)
I0916 17:01:08.576562 20128 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0916 17:01:08.576566 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.576572 20128 net.cpp:184] Created Layer pool3 (24)
I0916 17:01:08.576575 20128 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0916 17:01:08.576580 20128 net.cpp:530] pool3 -> pool3
I0916 17:01:08.576640 20128 net.cpp:245] Setting up pool3
I0916 17:01:08.576645 20128 net.cpp:252] TEST Top shape for layer 24 'pool3' 2 128 40 40 (409600)
I0916 17:01:08.576649 20128 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0916 17:01:08.576653 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.576660 20128 net.cpp:184] Created Layer res4a_branch2a (25)
I0916 17:01:08.576664 20128 net.cpp:561] res4a_branch2a <- pool3
I0916 17:01:08.576666 20128 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0916 17:01:08.582860 20128 net.cpp:245] Setting up res4a_branch2a
I0916 17:01:08.582870 20128 net.cpp:252] TEST Top shape for layer 25 'res4a_branch2a' 2 256 40 40 (819200)
I0916 17:01:08.582875 20128 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0916 17:01:08.582886 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.582890 20128 net.cpp:184] Created Layer res4a_branch2a/bn (26)
I0916 17:01:08.582893 20128 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0916 17:01:08.582895 20128 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0916 17:01:08.583547 20128 net.cpp:245] Setting up res4a_branch2a/bn
I0916 17:01:08.583555 20128 net.cpp:252] TEST Top shape for layer 26 'res4a_branch2a/bn' 2 256 40 40 (819200)
I0916 17:01:08.583561 20128 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0916 17:01:08.583564 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.583567 20128 net.cpp:184] Created Layer res4a_branch2a/relu (27)
I0916 17:01:08.583570 20128 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0916 17:01:08.583571 20128 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0916 17:01:08.583575 20128 net.cpp:245] Setting up res4a_branch2a/relu
I0916 17:01:08.583577 20128 net.cpp:252] TEST Top shape for layer 27 'res4a_branch2a/relu' 2 256 40 40 (819200)
I0916 17:01:08.583580 20128 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0916 17:01:08.583581 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.583595 20128 net.cpp:184] Created Layer res4a_branch2b (28)
I0916 17:01:08.583597 20128 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0916 17:01:08.583600 20128 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0916 17:01:08.588017 20128 net.cpp:245] Setting up res4a_branch2b
I0916 17:01:08.588034 20128 net.cpp:252] TEST Top shape for layer 28 'res4a_branch2b' 2 256 40 40 (819200)
I0916 17:01:08.588040 20128 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0916 17:01:08.588043 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.588049 20128 net.cpp:184] Created Layer res4a_branch2b/bn (29)
I0916 17:01:08.588052 20128 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0916 17:01:08.588054 20128 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0916 17:01:08.588707 20128 net.cpp:245] Setting up res4a_branch2b/bn
I0916 17:01:08.588714 20128 net.cpp:252] TEST Top shape for layer 29 'res4a_branch2b/bn' 2 256 40 40 (819200)
I0916 17:01:08.588721 20128 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0916 17:01:08.588722 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.588726 20128 net.cpp:184] Created Layer res4a_branch2b/relu (30)
I0916 17:01:08.588728 20128 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0916 17:01:08.588731 20128 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0916 17:01:08.588734 20128 net.cpp:245] Setting up res4a_branch2b/relu
I0916 17:01:08.588737 20128 net.cpp:252] TEST Top shape for layer 30 'res4a_branch2b/relu' 2 256 40 40 (819200)
I0916 17:01:08.588739 20128 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0916 17:01:08.588742 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.588745 20128 net.cpp:184] Created Layer pool4 (31)
I0916 17:01:08.588748 20128 net.cpp:561] pool4 <- res4a_branch2b
I0916 17:01:08.588750 20128 net.cpp:530] pool4 -> pool4
I0916 17:01:08.588819 20128 net.cpp:245] Setting up pool4
I0916 17:01:08.588822 20128 net.cpp:252] TEST Top shape for layer 31 'pool4' 2 256 40 40 (819200)
I0916 17:01:08.588825 20128 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0916 17:01:08.588827 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.588835 20128 net.cpp:184] Created Layer res5a_branch2a (32)
I0916 17:01:08.588836 20128 net.cpp:561] res5a_branch2a <- pool4
I0916 17:01:08.588848 20128 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0916 17:01:08.613878 20128 net.cpp:245] Setting up res5a_branch2a
I0916 17:01:08.613906 20128 net.cpp:252] TEST Top shape for layer 32 'res5a_branch2a' 2 512 40 40 (1638400)
I0916 17:01:08.613915 20128 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0916 17:01:08.613920 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.613932 20128 net.cpp:184] Created Layer res5a_branch2a/bn (33)
I0916 17:01:08.613936 20128 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0916 17:01:08.613941 20128 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0916 17:01:08.614737 20128 net.cpp:245] Setting up res5a_branch2a/bn
I0916 17:01:08.614749 20128 net.cpp:252] TEST Top shape for layer 33 'res5a_branch2a/bn' 2 512 40 40 (1638400)
I0916 17:01:08.614759 20128 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0916 17:01:08.614763 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.614768 20128 net.cpp:184] Created Layer res5a_branch2a/relu (34)
I0916 17:01:08.614770 20128 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0916 17:01:08.614773 20128 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0916 17:01:08.614778 20128 net.cpp:245] Setting up res5a_branch2a/relu
I0916 17:01:08.614779 20128 net.cpp:252] TEST Top shape for layer 34 'res5a_branch2a/relu' 2 512 40 40 (1638400)
I0916 17:01:08.614781 20128 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0916 17:01:08.614784 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.614791 20128 net.cpp:184] Created Layer res5a_branch2b (35)
I0916 17:01:08.614795 20128 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0916 17:01:08.614800 20128 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0916 17:01:08.627890 20128 net.cpp:245] Setting up res5a_branch2b
I0916 17:01:08.627907 20128 net.cpp:252] TEST Top shape for layer 35 'res5a_branch2b' 2 512 40 40 (1638400)
I0916 17:01:08.627915 20128 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0916 17:01:08.627919 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.627925 20128 net.cpp:184] Created Layer res5a_branch2b/bn (36)
I0916 17:01:08.627928 20128 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0916 17:01:08.627931 20128 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0916 17:01:08.628584 20128 net.cpp:245] Setting up res5a_branch2b/bn
I0916 17:01:08.628592 20128 net.cpp:252] TEST Top shape for layer 36 'res5a_branch2b/bn' 2 512 40 40 (1638400)
I0916 17:01:08.628597 20128 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0916 17:01:08.628599 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.628602 20128 net.cpp:184] Created Layer res5a_branch2b/relu (37)
I0916 17:01:08.628605 20128 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0916 17:01:08.628607 20128 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0916 17:01:08.628612 20128 net.cpp:245] Setting up res5a_branch2b/relu
I0916 17:01:08.628613 20128 net.cpp:252] TEST Top shape for layer 37 'res5a_branch2b/relu' 2 512 40 40 (1638400)
I0916 17:01:08.628615 20128 layer_factory.hpp:136] Creating layer 'out5a' of type 'Convolution'
I0916 17:01:08.628618 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.628628 20128 net.cpp:184] Created Layer out5a (38)
I0916 17:01:08.628630 20128 net.cpp:561] out5a <- res5a_branch2b
I0916 17:01:08.628633 20128 net.cpp:530] out5a -> out5a
I0916 17:01:08.631914 20128 net.cpp:245] Setting up out5a
I0916 17:01:08.631922 20128 net.cpp:252] TEST Top shape for layer 38 'out5a' 2 64 40 40 (204800)
I0916 17:01:08.631927 20128 layer_factory.hpp:136] Creating layer 'out5a/bn' of type 'BatchNorm'
I0916 17:01:08.631938 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.631942 20128 net.cpp:184] Created Layer out5a/bn (39)
I0916 17:01:08.631945 20128 net.cpp:561] out5a/bn <- out5a
I0916 17:01:08.631947 20128 net.cpp:513] out5a/bn -> out5a (in-place)
I0916 17:01:08.632616 20128 net.cpp:245] Setting up out5a/bn
I0916 17:01:08.632623 20128 net.cpp:252] TEST Top shape for layer 39 'out5a/bn' 2 64 40 40 (204800)
I0916 17:01:08.632628 20128 layer_factory.hpp:136] Creating layer 'out5a/relu' of type 'ReLU'
I0916 17:01:08.632632 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.632634 20128 net.cpp:184] Created Layer out5a/relu (40)
I0916 17:01:08.632637 20128 net.cpp:561] out5a/relu <- out5a
I0916 17:01:08.632638 20128 net.cpp:513] out5a/relu -> out5a (in-place)
I0916 17:01:08.632642 20128 net.cpp:245] Setting up out5a/relu
I0916 17:01:08.632644 20128 net.cpp:252] TEST Top shape for layer 40 'out5a/relu' 2 64 40 40 (204800)
I0916 17:01:08.632647 20128 layer_factory.hpp:136] Creating layer 'out5a_up2' of type 'Deconvolution'
I0916 17:01:08.632648 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.632653 20128 net.cpp:184] Created Layer out5a_up2 (41)
I0916 17:01:08.632655 20128 net.cpp:561] out5a_up2 <- out5a
I0916 17:01:08.632658 20128 net.cpp:530] out5a_up2 -> out5a_up2
I0916 17:01:08.632949 20128 net.cpp:245] Setting up out5a_up2
I0916 17:01:08.632954 20128 net.cpp:252] TEST Top shape for layer 41 'out5a_up2' 2 64 80 80 (819200)
I0916 17:01:08.632957 20128 layer_factory.hpp:136] Creating layer 'out3a' of type 'Convolution'
I0916 17:01:08.632961 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.632968 20128 net.cpp:184] Created Layer out3a (42)
I0916 17:01:08.632972 20128 net.cpp:561] out3a <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0916 17:01:08.632973 20128 net.cpp:530] out3a -> out3a
I0916 17:01:08.634084 20128 net.cpp:245] Setting up out3a
I0916 17:01:08.634093 20128 net.cpp:252] TEST Top shape for layer 42 'out3a' 2 64 80 80 (819200)
I0916 17:01:08.634096 20128 layer_factory.hpp:136] Creating layer 'out3a/bn' of type 'BatchNorm'
I0916 17:01:08.634099 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.634102 20128 net.cpp:184] Created Layer out3a/bn (43)
I0916 17:01:08.634105 20128 net.cpp:561] out3a/bn <- out3a
I0916 17:01:08.634107 20128 net.cpp:513] out3a/bn -> out3a (in-place)
I0916 17:01:08.634781 20128 net.cpp:245] Setting up out3a/bn
I0916 17:01:08.634788 20128 net.cpp:252] TEST Top shape for layer 43 'out3a/bn' 2 64 80 80 (819200)
I0916 17:01:08.634793 20128 layer_factory.hpp:136] Creating layer 'out3a/relu' of type 'ReLU'
I0916 17:01:08.634795 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.634799 20128 net.cpp:184] Created Layer out3a/relu (44)
I0916 17:01:08.634800 20128 net.cpp:561] out3a/relu <- out3a
I0916 17:01:08.634804 20128 net.cpp:513] out3a/relu -> out3a (in-place)
I0916 17:01:08.634806 20128 net.cpp:245] Setting up out3a/relu
I0916 17:01:08.634809 20128 net.cpp:252] TEST Top shape for layer 44 'out3a/relu' 2 64 80 80 (819200)
I0916 17:01:08.634810 20128 layer_factory.hpp:136] Creating layer 'out3_out5_combined' of type 'Eltwise'
I0916 17:01:08.634814 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.634816 20128 net.cpp:184] Created Layer out3_out5_combined (45)
I0916 17:01:08.634819 20128 net.cpp:561] out3_out5_combined <- out5a_up2
I0916 17:01:08.634820 20128 net.cpp:561] out3_out5_combined <- out3a
I0916 17:01:08.634824 20128 net.cpp:530] out3_out5_combined -> out3_out5_combined
I0916 17:01:08.634848 20128 net.cpp:245] Setting up out3_out5_combined
I0916 17:01:08.634852 20128 net.cpp:252] TEST Top shape for layer 45 'out3_out5_combined' 2 64 80 80 (819200)
I0916 17:01:08.634860 20128 layer_factory.hpp:136] Creating layer 'ctx_conv1' of type 'Convolution'
I0916 17:01:08.634863 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.634868 20128 net.cpp:184] Created Layer ctx_conv1 (46)
I0916 17:01:08.634871 20128 net.cpp:561] ctx_conv1 <- out3_out5_combined
I0916 17:01:08.634873 20128 net.cpp:530] ctx_conv1 -> ctx_conv1
I0916 17:01:08.635972 20128 net.cpp:245] Setting up ctx_conv1
I0916 17:01:08.635978 20128 net.cpp:252] TEST Top shape for layer 46 'ctx_conv1' 2 64 80 80 (819200)
I0916 17:01:08.635983 20128 layer_factory.hpp:136] Creating layer 'ctx_conv1/bn' of type 'BatchNorm'
I0916 17:01:08.635985 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.635998 20128 net.cpp:184] Created Layer ctx_conv1/bn (47)
I0916 17:01:08.636001 20128 net.cpp:561] ctx_conv1/bn <- ctx_conv1
I0916 17:01:08.636003 20128 net.cpp:513] ctx_conv1/bn -> ctx_conv1 (in-place)
I0916 17:01:08.636662 20128 net.cpp:245] Setting up ctx_conv1/bn
I0916 17:01:08.636670 20128 net.cpp:252] TEST Top shape for layer 47 'ctx_conv1/bn' 2 64 80 80 (819200)
I0916 17:01:08.636675 20128 layer_factory.hpp:136] Creating layer 'ctx_conv1/relu' of type 'ReLU'
I0916 17:01:08.636678 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.636682 20128 net.cpp:184] Created Layer ctx_conv1/relu (48)
I0916 17:01:08.636683 20128 net.cpp:561] ctx_conv1/relu <- ctx_conv1
I0916 17:01:08.636685 20128 net.cpp:513] ctx_conv1/relu -> ctx_conv1 (in-place)
I0916 17:01:08.636688 20128 net.cpp:245] Setting up ctx_conv1/relu
I0916 17:01:08.636692 20128 net.cpp:252] TEST Top shape for layer 48 'ctx_conv1/relu' 2 64 80 80 (819200)
I0916 17:01:08.636693 20128 layer_factory.hpp:136] Creating layer 'ctx_conv2' of type 'Convolution'
I0916 17:01:08.636695 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.636699 20128 net.cpp:184] Created Layer ctx_conv2 (49)
I0916 17:01:08.636703 20128 net.cpp:561] ctx_conv2 <- ctx_conv1
I0916 17:01:08.636704 20128 net.cpp:530] ctx_conv2 -> ctx_conv2
I0916 17:01:08.637853 20128 net.cpp:245] Setting up ctx_conv2
I0916 17:01:08.637861 20128 net.cpp:252] TEST Top shape for layer 49 'ctx_conv2' 2 64 80 80 (819200)
I0916 17:01:08.637866 20128 layer_factory.hpp:136] Creating layer 'ctx_conv2/bn' of type 'BatchNorm'
I0916 17:01:08.637868 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.637873 20128 net.cpp:184] Created Layer ctx_conv2/bn (50)
I0916 17:01:08.637876 20128 net.cpp:561] ctx_conv2/bn <- ctx_conv2
I0916 17:01:08.637877 20128 net.cpp:513] ctx_conv2/bn -> ctx_conv2 (in-place)
I0916 17:01:08.638550 20128 net.cpp:245] Setting up ctx_conv2/bn
I0916 17:01:08.638558 20128 net.cpp:252] TEST Top shape for layer 50 'ctx_conv2/bn' 2 64 80 80 (819200)
I0916 17:01:08.638563 20128 layer_factory.hpp:136] Creating layer 'ctx_conv2/relu' of type 'ReLU'
I0916 17:01:08.638566 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.638569 20128 net.cpp:184] Created Layer ctx_conv2/relu (51)
I0916 17:01:08.638571 20128 net.cpp:561] ctx_conv2/relu <- ctx_conv2
I0916 17:01:08.638573 20128 net.cpp:513] ctx_conv2/relu -> ctx_conv2 (in-place)
I0916 17:01:08.638577 20128 net.cpp:245] Setting up ctx_conv2/relu
I0916 17:01:08.638579 20128 net.cpp:252] TEST Top shape for layer 51 'ctx_conv2/relu' 2 64 80 80 (819200)
I0916 17:01:08.638581 20128 layer_factory.hpp:136] Creating layer 'ctx_conv3' of type 'Convolution'
I0916 17:01:08.638583 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.638588 20128 net.cpp:184] Created Layer ctx_conv3 (52)
I0916 17:01:08.638590 20128 net.cpp:561] ctx_conv3 <- ctx_conv2
I0916 17:01:08.638593 20128 net.cpp:530] ctx_conv3 -> ctx_conv3
I0916 17:01:08.639729 20128 net.cpp:245] Setting up ctx_conv3
I0916 17:01:08.639747 20128 net.cpp:252] TEST Top shape for layer 52 'ctx_conv3' 2 64 80 80 (819200)
I0916 17:01:08.639753 20128 layer_factory.hpp:136] Creating layer 'ctx_conv3/bn' of type 'BatchNorm'
I0916 17:01:08.639756 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.639770 20128 net.cpp:184] Created Layer ctx_conv3/bn (53)
I0916 17:01:08.639773 20128 net.cpp:561] ctx_conv3/bn <- ctx_conv3
I0916 17:01:08.639776 20128 net.cpp:513] ctx_conv3/bn -> ctx_conv3 (in-place)
I0916 17:01:08.640477 20128 net.cpp:245] Setting up ctx_conv3/bn
I0916 17:01:08.640491 20128 net.cpp:252] TEST Top shape for layer 53 'ctx_conv3/bn' 2 64 80 80 (819200)
I0916 17:01:08.640497 20128 layer_factory.hpp:136] Creating layer 'ctx_conv3/relu' of type 'ReLU'
I0916 17:01:08.640501 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.640508 20128 net.cpp:184] Created Layer ctx_conv3/relu (54)
I0916 17:01:08.640511 20128 net.cpp:561] ctx_conv3/relu <- ctx_conv3
I0916 17:01:08.640516 20128 net.cpp:513] ctx_conv3/relu -> ctx_conv3 (in-place)
I0916 17:01:08.640522 20128 net.cpp:245] Setting up ctx_conv3/relu
I0916 17:01:08.640527 20128 net.cpp:252] TEST Top shape for layer 54 'ctx_conv3/relu' 2 64 80 80 (819200)
I0916 17:01:08.640530 20128 layer_factory.hpp:136] Creating layer 'ctx_conv4' of type 'Convolution'
I0916 17:01:08.640533 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.640543 20128 net.cpp:184] Created Layer ctx_conv4 (55)
I0916 17:01:08.640547 20128 net.cpp:561] ctx_conv4 <- ctx_conv3
I0916 17:01:08.640549 20128 net.cpp:530] ctx_conv4 -> ctx_conv4
I0916 17:01:08.641708 20128 net.cpp:245] Setting up ctx_conv4
I0916 17:01:08.641719 20128 net.cpp:252] TEST Top shape for layer 55 'ctx_conv4' 2 64 80 80 (819200)
I0916 17:01:08.641724 20128 layer_factory.hpp:136] Creating layer 'ctx_conv4/bn' of type 'BatchNorm'
I0916 17:01:08.641727 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.641733 20128 net.cpp:184] Created Layer ctx_conv4/bn (56)
I0916 17:01:08.641736 20128 net.cpp:561] ctx_conv4/bn <- ctx_conv4
I0916 17:01:08.641739 20128 net.cpp:513] ctx_conv4/bn -> ctx_conv4 (in-place)
I0916 17:01:08.642490 20128 net.cpp:245] Setting up ctx_conv4/bn
I0916 17:01:08.642518 20128 net.cpp:252] TEST Top shape for layer 56 'ctx_conv4/bn' 2 64 80 80 (819200)
I0916 17:01:08.642530 20128 layer_factory.hpp:136] Creating layer 'ctx_conv4/relu' of type 'ReLU'
I0916 17:01:08.642535 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.642544 20128 net.cpp:184] Created Layer ctx_conv4/relu (57)
I0916 17:01:08.642549 20128 net.cpp:561] ctx_conv4/relu <- ctx_conv4
I0916 17:01:08.642554 20128 net.cpp:513] ctx_conv4/relu -> ctx_conv4 (in-place)
I0916 17:01:08.642558 20128 net.cpp:245] Setting up ctx_conv4/relu
I0916 17:01:08.642561 20128 net.cpp:252] TEST Top shape for layer 57 'ctx_conv4/relu' 2 64 80 80 (819200)
I0916 17:01:08.642563 20128 layer_factory.hpp:136] Creating layer 'ctx_final' of type 'Convolution'
I0916 17:01:08.642565 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.642580 20128 net.cpp:184] Created Layer ctx_final (58)
I0916 17:01:08.642583 20128 net.cpp:561] ctx_final <- ctx_conv4
I0916 17:01:08.642586 20128 net.cpp:530] ctx_final -> ctx_final
I0916 17:01:08.643231 20128 net.cpp:245] Setting up ctx_final
I0916 17:01:08.643250 20128 net.cpp:252] TEST Top shape for layer 58 'ctx_final' 2 8 80 80 (102400)
I0916 17:01:08.643255 20128 layer_factory.hpp:136] Creating layer 'ctx_final/relu' of type 'ReLU'
I0916 17:01:08.643260 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.643265 20128 net.cpp:184] Created Layer ctx_final/relu (59)
I0916 17:01:08.643267 20128 net.cpp:561] ctx_final/relu <- ctx_final
I0916 17:01:08.643270 20128 net.cpp:513] ctx_final/relu -> ctx_final (in-place)
I0916 17:01:08.643286 20128 net.cpp:245] Setting up ctx_final/relu
I0916 17:01:08.643290 20128 net.cpp:252] TEST Top shape for layer 59 'ctx_final/relu' 2 8 80 80 (102400)
I0916 17:01:08.643292 20128 layer_factory.hpp:136] Creating layer 'out_deconv_final_up2' of type 'Deconvolution'
I0916 17:01:08.643295 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.643306 20128 net.cpp:184] Created Layer out_deconv_final_up2 (60)
I0916 17:01:08.643309 20128 net.cpp:561] out_deconv_final_up2 <- ctx_final
I0916 17:01:08.643312 20128 net.cpp:530] out_deconv_final_up2 -> out_deconv_final_up2
I0916 17:01:08.643599 20128 net.cpp:245] Setting up out_deconv_final_up2
I0916 17:01:08.643604 20128 net.cpp:252] TEST Top shape for layer 60 'out_deconv_final_up2' 2 8 160 160 (409600)
I0916 17:01:08.643607 20128 layer_factory.hpp:136] Creating layer 'out_deconv_final_up4' of type 'Deconvolution'
I0916 17:01:08.643610 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.643615 20128 net.cpp:184] Created Layer out_deconv_final_up4 (61)
I0916 17:01:08.643617 20128 net.cpp:561] out_deconv_final_up4 <- out_deconv_final_up2
I0916 17:01:08.643620 20128 net.cpp:530] out_deconv_final_up4 -> out_deconv_final_up4
I0916 17:01:08.643903 20128 net.cpp:245] Setting up out_deconv_final_up4
I0916 17:01:08.643908 20128 net.cpp:252] TEST Top shape for layer 61 'out_deconv_final_up4' 2 8 320 320 (1638400)
I0916 17:01:08.643911 20128 layer_factory.hpp:136] Creating layer 'out_deconv_final_up8' of type 'Deconvolution'
I0916 17:01:08.643914 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.643919 20128 net.cpp:184] Created Layer out_deconv_final_up8 (62)
I0916 17:01:08.643924 20128 net.cpp:561] out_deconv_final_up8 <- out_deconv_final_up4
I0916 17:01:08.643929 20128 net.cpp:530] out_deconv_final_up8 -> out_deconv_final_up8
I0916 17:01:08.644207 20128 net.cpp:245] Setting up out_deconv_final_up8
I0916 17:01:08.644212 20128 net.cpp:252] TEST Top shape for layer 62 'out_deconv_final_up8' 2 8 640 640 (6553600)
I0916 17:01:08.644215 20128 layer_factory.hpp:136] Creating layer 'out_deconv_final_up8_out_deconv_final_up8_0_split' of type 'Split'
I0916 17:01:08.644218 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.644222 20128 net.cpp:184] Created Layer out_deconv_final_up8_out_deconv_final_up8_0_split (63)
I0916 17:01:08.644227 20128 net.cpp:561] out_deconv_final_up8_out_deconv_final_up8_0_split <- out_deconv_final_up8
I0916 17:01:08.644229 20128 net.cpp:530] out_deconv_final_up8_out_deconv_final_up8_0_split -> out_deconv_final_up8_out_deconv_final_up8_0_split_0
I0916 17:01:08.644233 20128 net.cpp:530] out_deconv_final_up8_out_deconv_final_up8_0_split -> out_deconv_final_up8_out_deconv_final_up8_0_split_1
I0916 17:01:08.644237 20128 net.cpp:530] out_deconv_final_up8_out_deconv_final_up8_0_split -> out_deconv_final_up8_out_deconv_final_up8_0_split_2
I0916 17:01:08.644304 20128 net.cpp:245] Setting up out_deconv_final_up8_out_deconv_final_up8_0_split
I0916 17:01:08.644309 20128 net.cpp:252] TEST Top shape for layer 63 'out_deconv_final_up8_out_deconv_final_up8_0_split' 2 8 640 640 (6553600)
I0916 17:01:08.644311 20128 net.cpp:252] TEST Top shape for layer 63 'out_deconv_final_up8_out_deconv_final_up8_0_split' 2 8 640 640 (6553600)
I0916 17:01:08.644314 20128 net.cpp:252] TEST Top shape for layer 63 'out_deconv_final_up8_out_deconv_final_up8_0_split' 2 8 640 640 (6553600)
I0916 17:01:08.644316 20128 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0916 17:01:08.644320 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.644331 20128 net.cpp:184] Created Layer loss (64)
I0916 17:01:08.644335 20128 net.cpp:561] loss <- out_deconv_final_up8_out_deconv_final_up8_0_split_0
I0916 17:01:08.644338 20128 net.cpp:561] loss <- label_data_1_split_0
I0916 17:01:08.644346 20128 net.cpp:530] loss -> loss
I0916 17:01:08.645406 20128 net.cpp:245] Setting up loss
I0916 17:01:08.645450 20128 net.cpp:252] TEST Top shape for layer 64 'loss' (1)
I0916 17:01:08.645455 20128 net.cpp:256]     with loss weight 1
I0916 17:01:08.645470 20128 layer_factory.hpp:136] Creating layer 'accuracy/top1' of type 'Accuracy'
I0916 17:01:08.645476 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.645505 20128 net.cpp:184] Created Layer accuracy/top1 (65)
I0916 17:01:08.645512 20128 net.cpp:561] accuracy/top1 <- out_deconv_final_up8_out_deconv_final_up8_0_split_1
I0916 17:01:08.645520 20128 net.cpp:561] accuracy/top1 <- label_data_1_split_1
I0916 17:01:08.645525 20128 net.cpp:530] accuracy/top1 -> accuracy/top1
I0916 17:01:08.645535 20128 net.cpp:245] Setting up accuracy/top1
I0916 17:01:08.645539 20128 net.cpp:252] TEST Top shape for layer 65 'accuracy/top1' (1)
I0916 17:01:08.645541 20128 layer_factory.hpp:136] Creating layer 'accuracy/top5' of type 'Accuracy'
I0916 17:01:08.645543 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.645547 20128 net.cpp:184] Created Layer accuracy/top5 (66)
I0916 17:01:08.645550 20128 net.cpp:561] accuracy/top5 <- out_deconv_final_up8_out_deconv_final_up8_0_split_2
I0916 17:01:08.645552 20128 net.cpp:561] accuracy/top5 <- label_data_1_split_2
I0916 17:01:08.645555 20128 net.cpp:530] accuracy/top5 -> accuracy/top5
I0916 17:01:08.645570 20128 net.cpp:245] Setting up accuracy/top5
I0916 17:01:08.645575 20128 net.cpp:252] TEST Top shape for layer 66 'accuracy/top5' (1)
I0916 17:01:08.645576 20128 net.cpp:325] accuracy/top5 does not need backward computation.
I0916 17:01:08.645579 20128 net.cpp:325] accuracy/top1 does not need backward computation.
I0916 17:01:08.645582 20128 net.cpp:323] loss needs backward computation.
I0916 17:01:08.645586 20128 net.cpp:323] out_deconv_final_up8_out_deconv_final_up8_0_split needs backward computation.
I0916 17:01:08.645588 20128 net.cpp:323] out_deconv_final_up8 needs backward computation.
I0916 17:01:08.645591 20128 net.cpp:323] out_deconv_final_up4 needs backward computation.
I0916 17:01:08.645592 20128 net.cpp:323] out_deconv_final_up2 needs backward computation.
I0916 17:01:08.645596 20128 net.cpp:323] ctx_final/relu needs backward computation.
I0916 17:01:08.645597 20128 net.cpp:323] ctx_final needs backward computation.
I0916 17:01:08.645601 20128 net.cpp:323] ctx_conv4/relu needs backward computation.
I0916 17:01:08.645602 20128 net.cpp:323] ctx_conv4/bn needs backward computation.
I0916 17:01:08.645604 20128 net.cpp:323] ctx_conv4 needs backward computation.
I0916 17:01:08.645606 20128 net.cpp:323] ctx_conv3/relu needs backward computation.
I0916 17:01:08.645608 20128 net.cpp:323] ctx_conv3/bn needs backward computation.
I0916 17:01:08.645611 20128 net.cpp:323] ctx_conv3 needs backward computation.
I0916 17:01:08.645612 20128 net.cpp:323] ctx_conv2/relu needs backward computation.
I0916 17:01:08.645614 20128 net.cpp:323] ctx_conv2/bn needs backward computation.
I0916 17:01:08.645617 20128 net.cpp:323] ctx_conv2 needs backward computation.
I0916 17:01:08.645619 20128 net.cpp:323] ctx_conv1/relu needs backward computation.
I0916 17:01:08.645622 20128 net.cpp:323] ctx_conv1/bn needs backward computation.
I0916 17:01:08.645623 20128 net.cpp:323] ctx_conv1 needs backward computation.
I0916 17:01:08.645625 20128 net.cpp:323] out3_out5_combined needs backward computation.
I0916 17:01:08.645628 20128 net.cpp:323] out3a/relu needs backward computation.
I0916 17:01:08.645630 20128 net.cpp:323] out3a/bn needs backward computation.
I0916 17:01:08.645632 20128 net.cpp:323] out3a needs backward computation.
I0916 17:01:08.645634 20128 net.cpp:323] out5a_up2 needs backward computation.
I0916 17:01:08.645637 20128 net.cpp:323] out5a/relu needs backward computation.
I0916 17:01:08.645640 20128 net.cpp:323] out5a/bn needs backward computation.
I0916 17:01:08.645642 20128 net.cpp:323] out5a needs backward computation.
I0916 17:01:08.645655 20128 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0916 17:01:08.645658 20128 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0916 17:01:08.645659 20128 net.cpp:323] res5a_branch2b needs backward computation.
I0916 17:01:08.645661 20128 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0916 17:01:08.645663 20128 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0916 17:01:08.645665 20128 net.cpp:323] res5a_branch2a needs backward computation.
I0916 17:01:08.645668 20128 net.cpp:323] pool4 needs backward computation.
I0916 17:01:08.645669 20128 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0916 17:01:08.645671 20128 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0916 17:01:08.645673 20128 net.cpp:323] res4a_branch2b needs backward computation.
I0916 17:01:08.645675 20128 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0916 17:01:08.645678 20128 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0916 17:01:08.645679 20128 net.cpp:323] res4a_branch2a needs backward computation.
I0916 17:01:08.645681 20128 net.cpp:323] pool3 needs backward computation.
I0916 17:01:08.645684 20128 net.cpp:323] res3a_branch2b_res3a_branch2b/relu_0_split needs backward computation.
I0916 17:01:08.645685 20128 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0916 17:01:08.645687 20128 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0916 17:01:08.645689 20128 net.cpp:323] res3a_branch2b needs backward computation.
I0916 17:01:08.645691 20128 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0916 17:01:08.645694 20128 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0916 17:01:08.645696 20128 net.cpp:323] res3a_branch2a needs backward computation.
I0916 17:01:08.645699 20128 net.cpp:323] pool2 needs backward computation.
I0916 17:01:08.645701 20128 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0916 17:01:08.645704 20128 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0916 17:01:08.645705 20128 net.cpp:323] res2a_branch2b needs backward computation.
I0916 17:01:08.645707 20128 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0916 17:01:08.645709 20128 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0916 17:01:08.645711 20128 net.cpp:323] res2a_branch2a needs backward computation.
I0916 17:01:08.645720 20128 net.cpp:323] pool1 needs backward computation.
I0916 17:01:08.645721 20128 net.cpp:323] conv1b/relu needs backward computation.
I0916 17:01:08.645725 20128 net.cpp:323] conv1b/bn needs backward computation.
I0916 17:01:08.645726 20128 net.cpp:323] conv1b needs backward computation.
I0916 17:01:08.645728 20128 net.cpp:323] conv1a/relu needs backward computation.
I0916 17:01:08.645730 20128 net.cpp:323] conv1a/bn needs backward computation.
I0916 17:01:08.645732 20128 net.cpp:323] conv1a needs backward computation.
I0916 17:01:08.645735 20128 net.cpp:325] data/bias does not need backward computation.
I0916 17:01:08.645736 20128 net.cpp:325] label_data_1_split does not need backward computation.
I0916 17:01:08.645740 20128 net.cpp:325] data does not need backward computation.
I0916 17:01:08.645741 20128 net.cpp:367] This network produces output accuracy/top1
I0916 17:01:08.645743 20128 net.cpp:367] This network produces output accuracy/top5
I0916 17:01:08.645745 20128 net.cpp:367] This network produces output loss
I0916 17:01:08.645803 20128 net.cpp:389] Top memory (TEST) required for data: 566886424 diff: 566886424
I0916 17:01:08.645807 20128 net.cpp:392] Bottom memory (TEST) required for data: 566886400 diff: 566886400
I0916 17:01:08.645809 20128 net.cpp:395] Shared (in-place) memory (TEST) by data: 257638400 diff: 257638400
I0916 17:01:08.645812 20128 net.cpp:398] Parameters memory (TEST) required for data: 10817840 diff: 10817840
I0916 17:01:08.645813 20128 net.cpp:401] Parameters shared memory (TEST) by data: 0 diff: 0
I0916 17:01:08.645815 20128 net.cpp:407] Network initialization done.
I0916 17:01:08.645946 20128 solver.cpp:57] Solver scaffolding done.
I0916 17:01:08.653220 20128 caffe.cpp:143] Finetuning from training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/cityscapes5_jsegnet21v2_iter_120000.caffemodel
I0916 17:01:08.657879 20128 net.cpp:1094] Copying source layer data Type:ImageLabelData #blobs=0
I0916 17:01:08.657902 20128 net.cpp:1094] Copying source layer data/bias Type:Bias #blobs=1
I0916 17:01:08.657930 20128 net.cpp:1094] Copying source layer conv1a Type:Convolution #blobs=2
I0916 17:01:08.657941 20128 net.cpp:1094] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.658216 20128 net.cpp:1094] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0916 17:01:08.658223 20128 net.cpp:1094] Copying source layer conv1b Type:Convolution #blobs=2
I0916 17:01:08.658233 20128 net.cpp:1094] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0916 17:01:08.658380 20128 net.cpp:1094] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0916 17:01:08.658383 20128 net.cpp:1094] Copying source layer pool1 Type:Pooling #blobs=0
I0916 17:01:08.658385 20128 net.cpp:1094] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0916 17:01:08.658401 20128 net.cpp:1094] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.658552 20128 net.cpp:1094] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0916 17:01:08.658556 20128 net.cpp:1094] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0916 17:01:08.658568 20128 net.cpp:1094] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0916 17:01:08.658707 20128 net.cpp:1094] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0916 17:01:08.658712 20128 net.cpp:1094] Copying source layer pool2 Type:Pooling #blobs=0
I0916 17:01:08.658715 20128 net.cpp:1094] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0916 17:01:08.658756 20128 net.cpp:1094] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.658890 20128 net.cpp:1094] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0916 17:01:08.658893 20128 net.cpp:1094] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0916 17:01:08.658916 20128 net.cpp:1094] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0916 17:01:08.659034 20128 net.cpp:1094] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0916 17:01:08.659039 20128 net.cpp:1094] Copying source layer res3a_branch2b_res3a_branch2b/relu_0_split Type:Split #blobs=0
I0916 17:01:08.659041 20128 net.cpp:1094] Copying source layer pool3 Type:Pooling #blobs=0
I0916 17:01:08.659044 20128 net.cpp:1094] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0916 17:01:08.659155 20128 net.cpp:1094] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.659276 20128 net.cpp:1094] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0916 17:01:08.659281 20128 net.cpp:1094] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0916 17:01:08.659339 20128 net.cpp:1094] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0916 17:01:08.659459 20128 net.cpp:1094] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0916 17:01:08.659464 20128 net.cpp:1094] Copying source layer pool4 Type:Pooling #blobs=0
I0916 17:01:08.659466 20128 net.cpp:1094] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0916 17:01:08.659812 20128 net.cpp:1094] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.659935 20128 net.cpp:1094] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0916 17:01:08.659940 20128 net.cpp:1094] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0916 17:01:08.660114 20128 net.cpp:1094] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0916 17:01:08.660230 20128 net.cpp:1094] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0916 17:01:08.660235 20128 net.cpp:1094] Copying source layer out5a Type:Convolution #blobs=2
I0916 17:01:08.660277 20128 net.cpp:1094] Copying source layer out5a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.660437 20128 net.cpp:1094] Copying source layer out5a/relu Type:ReLU #blobs=0
I0916 17:01:08.660442 20128 net.cpp:1094] Copying source layer out5a_up2 Type:Deconvolution #blobs=1
I0916 17:01:08.660449 20128 net.cpp:1094] Copying source layer out3a Type:Convolution #blobs=2
I0916 17:01:08.660466 20128 net.cpp:1094] Copying source layer out3a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.660610 20128 net.cpp:1094] Copying source layer out3a/relu Type:ReLU #blobs=0
I0916 17:01:08.660615 20128 net.cpp:1094] Copying source layer out3_out5_combined Type:Eltwise #blobs=0
I0916 17:01:08.660617 20128 net.cpp:1094] Copying source layer ctx_conv1 Type:Convolution #blobs=2
I0916 17:01:08.660634 20128 net.cpp:1094] Copying source layer ctx_conv1/bn Type:BatchNorm #blobs=5
I0916 17:01:08.660779 20128 net.cpp:1094] Copying source layer ctx_conv1/relu Type:ReLU #blobs=0
I0916 17:01:08.660784 20128 net.cpp:1094] Copying source layer ctx_conv2 Type:Convolution #blobs=2
I0916 17:01:08.660801 20128 net.cpp:1094] Copying source layer ctx_conv2/bn Type:BatchNorm #blobs=5
I0916 17:01:08.660946 20128 net.cpp:1094] Copying source layer ctx_conv2/relu Type:ReLU #blobs=0
I0916 17:01:08.660951 20128 net.cpp:1094] Copying source layer ctx_conv3 Type:Convolution #blobs=2
I0916 17:01:08.660969 20128 net.cpp:1094] Copying source layer ctx_conv3/bn Type:BatchNorm #blobs=5
I0916 17:01:08.661113 20128 net.cpp:1094] Copying source layer ctx_conv3/relu Type:ReLU #blobs=0
I0916 17:01:08.661118 20128 net.cpp:1094] Copying source layer ctx_conv4 Type:Convolution #blobs=2
I0916 17:01:08.661134 20128 net.cpp:1094] Copying source layer ctx_conv4/bn Type:BatchNorm #blobs=5
I0916 17:01:08.661276 20128 net.cpp:1094] Copying source layer ctx_conv4/relu Type:ReLU #blobs=0
I0916 17:01:08.661281 20128 net.cpp:1094] Copying source layer ctx_final Type:Convolution #blobs=2
I0916 17:01:08.661290 20128 net.cpp:1094] Copying source layer ctx_final/relu Type:ReLU #blobs=0
I0916 17:01:08.661294 20128 net.cpp:1094] Copying source layer out_deconv_final_up2 Type:Deconvolution #blobs=1
I0916 17:01:08.661298 20128 net.cpp:1094] Copying source layer out_deconv_final_up4 Type:Deconvolution #blobs=1
I0916 17:01:08.661305 20128 net.cpp:1094] Copying source layer out_deconv_final_up8 Type:Deconvolution #blobs=1
I0916 17:01:08.661311 20128 net.cpp:1094] Copying source layer loss Type:SoftmaxWithLoss #blobs=0
I0916 17:01:08.664500 20128 net.cpp:1094] Copying source layer data Type:ImageLabelData #blobs=0
I0916 17:01:08.664521 20128 net.cpp:1094] Copying source layer data/bias Type:Bias #blobs=1
I0916 17:01:08.664547 20128 net.cpp:1094] Copying source layer conv1a Type:Convolution #blobs=2
I0916 17:01:08.664561 20128 net.cpp:1094] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.664815 20128 net.cpp:1094] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0916 17:01:08.664821 20128 net.cpp:1094] Copying source layer conv1b Type:Convolution #blobs=2
I0916 17:01:08.664831 20128 net.cpp:1094] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0916 17:01:08.664983 20128 net.cpp:1094] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0916 17:01:08.664988 20128 net.cpp:1094] Copying source layer pool1 Type:Pooling #blobs=0
I0916 17:01:08.664989 20128 net.cpp:1094] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0916 17:01:08.665005 20128 net.cpp:1094] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.665156 20128 net.cpp:1094] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0916 17:01:08.665161 20128 net.cpp:1094] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0916 17:01:08.665174 20128 net.cpp:1094] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0916 17:01:08.665319 20128 net.cpp:1094] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0916 17:01:08.665324 20128 net.cpp:1094] Copying source layer pool2 Type:Pooling #blobs=0
I0916 17:01:08.665326 20128 net.cpp:1094] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0916 17:01:08.665374 20128 net.cpp:1094] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.665510 20128 net.cpp:1094] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0916 17:01:08.665515 20128 net.cpp:1094] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0916 17:01:08.665539 20128 net.cpp:1094] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0916 17:01:08.665658 20128 net.cpp:1094] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0916 17:01:08.665664 20128 net.cpp:1094] Copying source layer res3a_branch2b_res3a_branch2b/relu_0_split Type:Split #blobs=0
I0916 17:01:08.665666 20128 net.cpp:1094] Copying source layer pool3 Type:Pooling #blobs=0
I0916 17:01:08.665669 20128 net.cpp:1094] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0916 17:01:08.665783 20128 net.cpp:1094] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.665906 20128 net.cpp:1094] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0916 17:01:08.665910 20128 net.cpp:1094] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0916 17:01:08.665969 20128 net.cpp:1094] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0916 17:01:08.666097 20128 net.cpp:1094] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0916 17:01:08.666102 20128 net.cpp:1094] Copying source layer pool4 Type:Pooling #blobs=0
I0916 17:01:08.666105 20128 net.cpp:1094] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0916 17:01:08.666450 20128 net.cpp:1094] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.666575 20128 net.cpp:1094] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0916 17:01:08.666580 20128 net.cpp:1094] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0916 17:01:08.666755 20128 net.cpp:1094] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0916 17:01:08.666873 20128 net.cpp:1094] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0916 17:01:08.666877 20128 net.cpp:1094] Copying source layer out5a Type:Convolution #blobs=2
I0916 17:01:08.666921 20128 net.cpp:1094] Copying source layer out5a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.667079 20128 net.cpp:1094] Copying source layer out5a/relu Type:ReLU #blobs=0
I0916 17:01:08.667084 20128 net.cpp:1094] Copying source layer out5a_up2 Type:Deconvolution #blobs=1
I0916 17:01:08.667091 20128 net.cpp:1094] Copying source layer out3a Type:Convolution #blobs=2
I0916 17:01:08.667110 20128 net.cpp:1094] Copying source layer out3a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.667255 20128 net.cpp:1094] Copying source layer out3a/relu Type:ReLU #blobs=0
I0916 17:01:08.667260 20128 net.cpp:1094] Copying source layer out3_out5_combined Type:Eltwise #blobs=0
I0916 17:01:08.667263 20128 net.cpp:1094] Copying source layer ctx_conv1 Type:Convolution #blobs=2
I0916 17:01:08.667281 20128 net.cpp:1094] Copying source layer ctx_conv1/bn Type:BatchNorm #blobs=5
I0916 17:01:08.667425 20128 net.cpp:1094] Copying source layer ctx_conv1/relu Type:ReLU #blobs=0
I0916 17:01:08.667429 20128 net.cpp:1094] Copying source layer ctx_conv2 Type:Convolution #blobs=2
I0916 17:01:08.667448 20128 net.cpp:1094] Copying source layer ctx_conv2/bn Type:BatchNorm #blobs=5
I0916 17:01:08.667592 20128 net.cpp:1094] Copying source layer ctx_conv2/relu Type:ReLU #blobs=0
I0916 17:01:08.667596 20128 net.cpp:1094] Copying source layer ctx_conv3 Type:Convolution #blobs=2
I0916 17:01:08.667614 20128 net.cpp:1094] Copying source layer ctx_conv3/bn Type:BatchNorm #blobs=5
I0916 17:01:08.667757 20128 net.cpp:1094] Copying source layer ctx_conv3/relu Type:ReLU #blobs=0
I0916 17:01:08.667762 20128 net.cpp:1094] Copying source layer ctx_conv4 Type:Convolution #blobs=2
I0916 17:01:08.667779 20128 net.cpp:1094] Copying source layer ctx_conv4/bn Type:BatchNorm #blobs=5
I0916 17:01:08.667922 20128 net.cpp:1094] Copying source layer ctx_conv4/relu Type:ReLU #blobs=0
I0916 17:01:08.667927 20128 net.cpp:1094] Copying source layer ctx_final Type:Convolution #blobs=2
I0916 17:01:08.667943 20128 net.cpp:1094] Copying source layer ctx_final/relu Type:ReLU #blobs=0
I0916 17:01:08.667946 20128 net.cpp:1094] Copying source layer out_deconv_final_up2 Type:Deconvolution #blobs=1
I0916 17:01:08.667951 20128 net.cpp:1094] Copying source layer out_deconv_final_up4 Type:Deconvolution #blobs=1
I0916 17:01:08.667959 20128 net.cpp:1094] Copying source layer out_deconv_final_up8 Type:Deconvolution #blobs=1
I0916 17:01:08.667968 20128 net.cpp:1094] Copying source layer loss Type:SoftmaxWithLoss #blobs=0
I0916 17:01:08.668063 20128 parallel.cpp:106] [0 - 0] P2pSync adding callback
I0916 17:01:08.668068 20128 parallel.cpp:106] [1 - 1] P2pSync adding callback
I0916 17:01:08.668072 20128 parallel.cpp:106] [2 - 2] P2pSync adding callback
I0916 17:01:08.668076 20128 parallel.cpp:59] Starting Optimization
I0916 17:01:08.668081 20128 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 17:01:08.668108 20128 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 17:01:08.668123 20128 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 17:01:08.668817 20216 device_alternate.hpp:116] NVML initialized on thread 136238948763392
I0916 17:01:08.690589 20216 common.cpp:585] NVML succeeded to set CPU affinity on device 0
I0916 17:01:08.690649 20217 device_alternate.hpp:116] NVML initialized on thread 136238940370688
I0916 17:01:08.691726 20217 common.cpp:585] NVML succeeded to set CPU affinity on device 1
I0916 17:01:08.691764 20218 device_alternate.hpp:116] NVML initialized on thread 136238931977984
I0916 17:01:08.692556 20218 common.cpp:585] NVML succeeded to set CPU affinity on device 2
I0916 17:01:08.696141 20217 solver.cpp:43] Solver data type: FLOAT
W0916 17:01:08.696712 20217 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 16 to 18
I0916 17:01:08.696846 20217 net.cpp:104] Using FLOAT as default forward math type
I0916 17:01:08.696851 20217 net.cpp:110] Using FLOAT as default backward math type
I0916 17:01:08.696887 20217 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0916 17:01:08.696895 20217 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 17:01:08.700120 20218 solver.cpp:43] Solver data type: FLOAT
W0916 17:01:08.700634 20218 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 16 to 18
I0916 17:01:08.700740 20218 net.cpp:104] Using FLOAT as default forward math type
I0916 17:01:08.700747 20218 net.cpp:110] Using FLOAT as default backward math type
I0916 17:01:08.700775 20218 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0916 17:01:08.700783 20218 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 17:01:08.700898 20219 db_lmdb.cpp:24] Opened lmdb data/train-image-lmdb
I0916 17:01:08.701552 20220 db_lmdb.cpp:24] Opened lmdb data/train-image-lmdb
I0916 17:01:08.705286 20217 data_layer.cpp:187] [1] ReshapePrefetch 6, 3, 640, 640
I0916 17:01:08.705651 20218 data_layer.cpp:187] [2] ReshapePrefetch 6, 3, 640, 640
I0916 17:01:08.705708 20217 data_layer.cpp:211] [1] Output data size: 6, 3, 640, 640
I0916 17:01:08.705724 20217 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 17:01:08.705744 20218 data_layer.cpp:211] [2] Output data size: 6, 3, 640, 640
I0916 17:01:08.705754 20218 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 17:01:08.705811 20218 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0916 17:01:08.705811 20217 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0916 17:01:08.705823 20218 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 17:01:08.705904 20217 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 17:01:08.707024 20223 db_lmdb.cpp:24] Opened lmdb data/train-label-lmdb
I0916 17:01:08.707909 20221 data_layer.cpp:101] [1] Parser threads: 1
I0916 17:01:08.707936 20221 data_layer.cpp:103] [1] Transformer threads: 1
I0916 17:01:08.713850 20218 data_layer.cpp:187] [2] ReshapePrefetch 6, 1, 640, 640
I0916 17:01:08.714679 20218 data_layer.cpp:211] [2] Output data size: 6, 1, 640, 640
I0916 17:01:08.714694 20218 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 17:01:08.718097 20224 db_lmdb.cpp:24] Opened lmdb data/train-label-lmdb
I0916 17:01:08.720157 20222 data_layer.cpp:101] [2] Parser threads: 1
I0916 17:01:08.720204 20222 data_layer.cpp:103] [2] Transformer threads: 1
I0916 17:01:08.721855 20221 blocking_queue.cpp:40] Waiting for datum
I0916 17:01:08.728801 20217 data_layer.cpp:187] [1] ReshapePrefetch 6, 1, 640, 640
I0916 17:01:08.728780 20225 data_layer.cpp:101] [2] Parser threads: 1
I0916 17:01:08.729179 20225 data_layer.cpp:103] [2] Transformer threads: 1
I0916 17:01:08.732703 20217 data_layer.cpp:211] [1] Output data size: 6, 1, 640, 640
I0916 17:01:08.732743 20217 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 17:01:08.744824 20226 data_layer.cpp:101] [1] Parser threads: 1
I0916 17:01:08.744922 20226 data_layer.cpp:103] [1] Transformer threads: 1
I0916 17:01:09.412298 20218 solver.cpp:177] Creating test net (#0) specified by test_net file: training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/test.prototxt
W0916 17:01:09.412379 20218 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 4 to 6
I0916 17:01:09.412595 20218 net.cpp:104] Using FLOAT as default forward math type
I0916 17:01:09.412601 20218 net.cpp:110] Using FLOAT as default backward math type
I0916 17:01:09.412629 20218 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 2
I0916 17:01:09.412639 20218 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 17:01:09.413552 20241 db_lmdb.cpp:24] Opened lmdb data/val-image-lmdb
I0916 17:01:09.418262 20218 data_layer.cpp:187] (2) ReshapePrefetch 2, 3, 640, 640
I0916 17:01:09.418324 20218 data_layer.cpp:211] (2) Output data size: 2, 3, 640, 640
I0916 17:01:09.418331 20218 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 17:01:09.418385 20218 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 2
I0916 17:01:09.418392 20218 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 17:01:09.421582 20242 data_layer.cpp:101] (2) Parser threads: 1
I0916 17:01:09.421610 20242 data_layer.cpp:103] (2) Transformer threads: 1
I0916 17:01:09.422456 20243 db_lmdb.cpp:24] Opened lmdb data/val-label-lmdb
I0916 17:01:09.425357 20218 data_layer.cpp:187] (2) ReshapePrefetch 2, 1, 640, 640
I0916 17:01:09.425622 20218 data_layer.cpp:211] (2) Output data size: 2, 1, 640, 640
I0916 17:01:09.425699 20218 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 17:01:09.427683 20244 data_layer.cpp:101] (2) Parser threads: 1
I0916 17:01:09.427713 20244 data_layer.cpp:103] (2) Transformer threads: 1
I0916 17:01:09.439486 20217 solver.cpp:177] Creating test net (#0) specified by test_net file: training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/test.prototxt
W0916 17:01:09.439612 20217 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 4 to 6
I0916 17:01:09.439821 20217 net.cpp:104] Using FLOAT as default forward math type
I0916 17:01:09.439831 20217 net.cpp:110] Using FLOAT as default backward math type
I0916 17:01:09.439869 20217 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 2
I0916 17:01:09.439879 20217 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 17:01:09.440915 20248 db_lmdb.cpp:24] Opened lmdb data/val-image-lmdb
I0916 17:01:09.446621 20217 data_layer.cpp:187] (1) ReshapePrefetch 2, 3, 640, 640
I0916 17:01:09.446789 20217 data_layer.cpp:211] (1) Output data size: 2, 3, 640, 640
I0916 17:01:09.446799 20217 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 17:01:09.446840 20217 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 2
I0916 17:01:09.446877 20217 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 17:01:09.450449 20249 data_layer.cpp:101] (1) Parser threads: 1
I0916 17:01:09.450474 20249 data_layer.cpp:103] (1) Transformer threads: 1
I0916 17:01:09.451863 20250 db_lmdb.cpp:24] Opened lmdb data/val-label-lmdb
I0916 17:01:09.457919 20217 data_layer.cpp:187] (1) ReshapePrefetch 2, 1, 640, 640
I0916 17:01:09.458359 20217 data_layer.cpp:211] (1) Output data size: 2, 1, 640, 640
I0916 17:01:09.458495 20217 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 17:01:09.460402 20251 data_layer.cpp:101] (1) Parser threads: 1
I0916 17:01:09.460417 20251 data_layer.cpp:103] (1) Transformer threads: 1
I0916 17:01:09.531520 20218 solver.cpp:57] Solver scaffolding done.
I0916 17:01:09.553792 20217 solver.cpp:57] Solver scaffolding done.
I0916 17:01:09.582753 20216 parallel.cpp:161] [0 - 0] P2pSync adding callback
I0916 17:01:09.582778 20217 parallel.cpp:161] [1 - 1] P2pSync adding callback
I0916 17:01:09.582753 20218 parallel.cpp:161] [2 - 2] P2pSync adding callback
I0916 17:01:09.853294 20218 solver.cpp:490] Solving jsegnet21v2_train
I0916 17:01:09.853315 20216 solver.cpp:490] Solving jsegnet21v2_train
I0916 17:01:09.853317 20217 solver.cpp:490] Solving jsegnet21v2_train
I0916 17:01:09.853335 20216 solver.cpp:491] Learning Rate Policy: multistep
I0916 17:01:09.853341 20217 solver.cpp:491] Learning Rate Policy: multistep
I0916 17:01:09.853327 20218 solver.cpp:491] Learning Rate Policy: multistep
I0916 17:01:09.868331 20218 net.cpp:1412] [2] Reserving 10800128 bytes of shared learnable space
I0916 17:01:09.868337 20217 net.cpp:1412] [1] Reserving 10800128 bytes of shared learnable space
I0916 17:01:09.872915 20216 net.cpp:1412] [0] Reserving 10800128 bytes of shared learnable space
I0916 17:01:09.880023 20216 solver.cpp:228] Starting Optimization on GPU 0
I0916 17:01:09.880026 20218 solver.cpp:228] Starting Optimization on GPU 2
I0916 17:01:09.880110 20216 solver.cpp:563] Iteration 0, Testing net (#0)
I0916 17:01:09.880132 20266 device_alternate.hpp:116] NVML initialized on thread 128238780503808
I0916 17:01:09.880156 20266 common.cpp:585] NVML succeeded to set CPU affinity on device 0
I0916 17:01:09.880026 20217 solver.cpp:228] Starting Optimization on GPU 1
I0916 17:01:09.880278 20268 device_alternate.hpp:116] NVML initialized on thread 128238763718400
I0916 17:01:09.880290 20268 common.cpp:585] NVML succeeded to set CPU affinity on device 1
I0916 17:01:09.880414 20267 device_alternate.hpp:116] NVML initialized on thread 128238772111104
I0916 17:01:09.880431 20267 common.cpp:585] NVML succeeded to set CPU affinity on device 2
I0916 17:01:10.128381 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.85041
I0916 17:01:10.128402 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 17:01:10.128407 20216 solver.cpp:655]     Test net output #2: loss = 0.553253 (* 1 = 0.553253 loss)
I0916 17:01:10.128412 20216 solver.cpp:255] [MultiGPU] Initial Test completed
I0916 17:01:10.526026 20216 solver.cpp:319] Iteration 0 (0.397575 s), loss = 0.0770469
I0916 17:01:10.526052 20216 solver.cpp:336]     Train net output #0: loss = 0.0770469 (* 1 = 0.0770469 loss)
I0916 17:01:10.526058 20216 sgd_solver.cpp:136] Iteration 0, lr = 0.01, m = 0.9
I0916 17:01:10.735280 20216 solver.cpp:319] Iteration 1 (0.209235 s), loss = 0.0552685
I0916 17:01:10.735325 20216 solver.cpp:336]     Train net output #0: loss = 0.0552685 (* 1 = 0.0552685 loss)
I0916 17:01:10.902369 20216 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'conv1a' with space 4.24G 3/1 1 0 3 	(avail 0.07G, req 0G)	t: 0 2.85 2.6
I0916 17:01:10.910156 20218 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'conv1a' with space 4.24G 3/1 1 0 0 	(avail 0.14G, req 0G)	t: 0 2.99 2.6
I0916 17:01:10.922483 20217 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'conv1a' with space 4.24G 3/1 1 0 0 	(avail 0.14G, req 0G)	t: 0 3.05 2.62
I0916 17:01:11.022840 20216 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'conv1b' with space 4.24G 32/4 6 4 3 	(avail 0.07G, req 0G)	t: 0 0.6 1.25
I0916 17:01:11.028100 20218 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'conv1b' with space 4.24G 32/4 6 4 3 	(avail 0.14G, req 0G)	t: 0 0.64 1.28
I0916 17:01:11.036377 20217 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'conv1b' with space 4.24G 32/4 6 4 3 	(avail 0.14G, req 0G)	t: 0 0.65 1.37
I0916 17:01:11.270355 20216 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 4.24G 32/1 6 4 3 	(avail 0.07G, req 0G)	t: 0 0.74 1.47
I0916 17:01:11.280431 20218 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 4.24G 32/1 6 4 3 	(avail 0.14G, req 0G)	t: 0 0.75 1.51
I0916 17:01:11.315793 20217 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 4.24G 32/1 6 4 3 	(avail 0.14G, req 0G)	t: 0 0.74 1.53
I0916 17:01:11.378304 20216 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 4.24G 64/4 6 4 3 	(avail 0.07G, req 0G)	t: 0 0.27 0.62
I0916 17:01:11.380890 20218 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 4.24G 64/4 6 4 3 	(avail 0.14G, req 0G)	t: 0 0.27 0.65
I0916 17:01:11.398882 20217 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 4.24G 64/4 6 4 3 	(avail 0.14G, req 0G)	t: 0 0.27 0.66
I0916 17:01:11.566035 20216 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 4.24G 64/1 6 4 5 	(avail 0.07G, req 0.07G)	t: 0 0.45 0.92
I0916 17:01:11.573259 20218 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 4.24G 64/1 6 4 5 	(avail 0.14G, req 0.07G)	t: 0 0.48 0.94
I0916 17:01:11.607038 20217 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 4.24G 64/1 6 4 5 	(avail 0.14G, req 0.07G)	t: 0 0.46 0.95
I0916 17:01:11.613423 20216 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 4.24G 128/4 6 4 3 	(avail 0.07G, req 0.07G)	t: 0 0.14 0.28
I0916 17:01:11.623404 20218 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 4.24G 128/4 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.14 0.3
I0916 17:01:11.667399 20217 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 4.24G 128/4 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.18 0.29
I0916 17:01:11.750689 20216 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 4.24G 128/1 6 4 5 	(avail 0.07G, req 0.07G)	t: 0 0.45 0.55
I0916 17:01:11.781801 20216 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 4.24G 256/4 6 4 5 	(avail 0.07G, req 0.07G)	t: 0 0.11 0.21
I0916 17:01:11.813982 20218 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 4.24G 128/1 6 4 5 	(avail 0.14G, req 0.07G)	t: 0 0.48 0.55
I0916 17:01:11.820802 20217 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 4.24G 128/1 6 4 5 	(avail 0.14G, req 0.07G)	t: 0 0.48 0.56
I0916 17:01:11.848260 20218 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 4.24G 256/4 6 4 5 	(avail 0.14G, req 0.07G)	t: 0 0.11 0.21
I0916 17:01:11.851670 20217 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 4.24G 256/4 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.11 0.2
I0916 17:01:11.878221 20216 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'out3a' with space 4.24G 128/2 6 4 3 	(avail 0.07G, req 0.07G)	t: 0 0.22 0.42
I0916 17:01:11.947870 20218 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'out3a' with space 4.24G 128/2 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.24 0.43
I0916 17:01:11.949642 20217 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'out3a' with space 4.24G 128/2 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.22 0.43
I0916 17:01:11.988658 20216 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_conv1' with space 4.24G 64/1 6 4 3 	(avail 0.07G, req 0.07G)	t: 0 0.28 0.62
I0916 17:01:12.052358 20216 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_final' with space 4.24G 64/1 6 1 3 	(avail 0.07G, req 0.07G)	t: 0 0.11 0.35
I0916 17:01:12.072341 20218 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'ctx_conv1' with space 4.24G 64/1 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.29 0.62
I0916 17:01:12.078866 20217 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_conv1' with space 4.24G 64/1 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.3 0.63
I0916 17:01:12.120690 20218 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'ctx_final' with space 4.24G 64/1 6 1 5 	(avail 0.14G, req 0.07G)	t: 0 0.11 0.36
I0916 17:01:12.131413 20217 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_final' with space 4.24G 64/1 6 1 5 	(avail 0.14G, req 0.07G)	t: 0 0.11 0.36
I0916 17:01:12.257953 20216 solver.cpp:319] Iteration 2 (1.52263 s), loss = 0.0501653
I0916 17:01:12.257979 20216 solver.cpp:336]     Train net output #0: loss = 0.0501653 (* 1 = 0.0501653 loss)
I0916 17:01:12.258620 20217 cudnn_conv_layer.cpp:474] [1] Layer 'conv1a' reallocating workspace 4.24G to 0.14G
I0916 17:01:12.277644 20218 cudnn_conv_layer.cpp:474] [2] Layer 'conv1a' reallocating workspace 4.24G to 0.14G
I0916 17:01:12.279466 20216 cudnn_conv_layer.cpp:474] [0] Layer 'conv1a' reallocating workspace 4.24G to 0.14G
I0916 17:01:31.872104 20216 solver.cpp:314] Iteration 100 (4.99653 iter/s, 19.6136s/98 iter), loss = 0.0711057
I0916 17:01:31.872133 20216 solver.cpp:336]     Train net output #0: loss = 0.0711057 (* 1 = 0.0711057 loss)
I0916 17:01:31.872138 20216 sgd_solver.cpp:136] Iteration 100, lr = 0.01, m = 0.9
I0916 17:01:43.604835 20223 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 17:01:51.006911 20216 solver.cpp:314] Iteration 200 (5.22623 iter/s, 19.1343s/100 iter), loss = 0.138968
I0916 17:01:51.006935 20216 solver.cpp:336]     Train net output #0: loss = 0.138968 (* 1 = 0.138968 loss)
I0916 17:01:51.006940 20216 sgd_solver.cpp:136] Iteration 200, lr = 0.01, m = 0.9
I0916 17:02:10.141578 20216 solver.cpp:314] Iteration 300 (5.22626 iter/s, 19.1341s/100 iter), loss = 0.0643851
I0916 17:02:10.141602 20216 solver.cpp:336]     Train net output #0: loss = 0.0643851 (* 1 = 0.0643851 loss)
I0916 17:02:10.141607 20216 sgd_solver.cpp:136] Iteration 300, lr = 0.01, m = 0.9
I0916 17:02:15.544680 20219 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 17:02:29.578482 20216 solver.cpp:314] Iteration 400 (5.145 iter/s, 19.4364s/100 iter), loss = 0.0747495
I0916 17:02:29.578506 20216 solver.cpp:336]     Train net output #0: loss = 0.0747495 (* 1 = 0.0747495 loss)
I0916 17:02:29.578511 20216 sgd_solver.cpp:136] Iteration 400, lr = 0.01, m = 0.9
I0916 17:02:48.696818 20216 solver.cpp:314] Iteration 500 (5.23073 iter/s, 19.1178s/100 iter), loss = 0.2153
I0916 17:02:48.696869 20216 solver.cpp:336]     Train net output #0: loss = 0.2153 (* 1 = 0.2153 loss)
I0916 17:02:48.696876 20216 sgd_solver.cpp:136] Iteration 500, lr = 0.01, m = 0.9
I0916 17:03:08.239327 20216 solver.cpp:314] Iteration 600 (5.1172 iter/s, 19.542s/100 iter), loss = 0.0720644
I0916 17:03:08.239356 20216 solver.cpp:336]     Train net output #0: loss = 0.0720644 (* 1 = 0.0720644 loss)
I0916 17:03:08.239362 20216 sgd_solver.cpp:136] Iteration 600, lr = 0.01, m = 0.9
I0916 17:03:19.547545 20220 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 17:03:27.584372 20216 solver.cpp:314] Iteration 700 (5.16943 iter/s, 19.3445s/100 iter), loss = 0.0681331
I0916 17:03:27.584398 20216 solver.cpp:336]     Train net output #0: loss = 0.0681331 (* 1 = 0.0681331 loss)
I0916 17:03:27.584403 20216 sgd_solver.cpp:136] Iteration 700, lr = 0.01, m = 0.9
I0916 17:03:47.418560 20216 solver.cpp:314] Iteration 800 (5.04194 iter/s, 19.8336s/100 iter), loss = 0.121633
I0916 17:03:47.418587 20216 solver.cpp:336]     Train net output #0: loss = 0.121633 (* 1 = 0.121633 loss)
I0916 17:03:47.418593 20216 sgd_solver.cpp:136] Iteration 800, lr = 0.01, m = 0.9
I0916 17:04:06.791327 20216 solver.cpp:314] Iteration 900 (5.16203 iter/s, 19.3722s/100 iter), loss = 0.0570977
I0916 17:04:06.791404 20216 solver.cpp:336]     Train net output #0: loss = 0.0570977 (* 1 = 0.0570977 loss)
I0916 17:04:06.791411 20216 sgd_solver.cpp:136] Iteration 900, lr = 0.01, m = 0.9
I0916 17:04:24.137939 20224 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 17:04:26.471331 20216 solver.cpp:314] Iteration 1000 (5.08144 iter/s, 19.6794s/100 iter), loss = 0.107357
I0916 17:04:26.471360 20216 solver.cpp:336]     Train net output #0: loss = 0.107357 (* 1 = 0.107357 loss)
I0916 17:04:26.471369 20216 sgd_solver.cpp:136] Iteration 1000, lr = 0.01, m = 0.9
I0916 17:04:45.892304 20216 solver.cpp:314] Iteration 1100 (5.14922 iter/s, 19.4204s/100 iter), loss = 0.0685477
I0916 17:04:45.892361 20216 solver.cpp:336]     Train net output #0: loss = 0.0685477 (* 1 = 0.0685477 loss)
I0916 17:04:45.892367 20216 sgd_solver.cpp:136] Iteration 1100, lr = 0.01, m = 0.9
I0916 17:04:56.321072 20220 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 17:05:05.903656 20216 solver.cpp:314] Iteration 1200 (4.99731 iter/s, 20.0108s/100 iter), loss = 0.0857634
I0916 17:05:05.903751 20216 solver.cpp:336]     Train net output #0: loss = 0.0857633 (* 1 = 0.0857633 loss)
I0916 17:05:05.903780 20216 sgd_solver.cpp:136] Iteration 1200, lr = 0.01, m = 0.9
I0916 17:05:26.150696 20216 solver.cpp:314] Iteration 1300 (4.93913 iter/s, 20.2465s/100 iter), loss = 0.0913946
I0916 17:05:26.150746 20216 solver.cpp:336]     Train net output #0: loss = 0.0913945 (* 1 = 0.0913945 loss)
I0916 17:05:26.150753 20216 sgd_solver.cpp:136] Iteration 1300, lr = 0.01, m = 0.9
I0916 17:05:46.773881 20216 solver.cpp:314] Iteration 1400 (4.84905 iter/s, 20.6226s/100 iter), loss = 0.113304
I0916 17:05:46.773912 20216 solver.cpp:336]     Train net output #0: loss = 0.113304 (* 1 = 0.113304 loss)
I0916 17:05:46.773918 20216 sgd_solver.cpp:136] Iteration 1400, lr = 0.01, m = 0.9
I0916 17:06:03.250057 20197 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 17:06:06.460095 20216 solver.cpp:314] Iteration 1500 (5.07984 iter/s, 19.6857s/100 iter), loss = 0.099099
I0916 17:06:06.460119 20216 solver.cpp:336]     Train net output #0: loss = 0.0990989 (* 1 = 0.0990989 loss)
I0916 17:06:06.460124 20216 sgd_solver.cpp:136] Iteration 1500, lr = 0.01, m = 0.9
I0916 17:06:26.529528 20216 solver.cpp:314] Iteration 1600 (4.98284 iter/s, 20.0689s/100 iter), loss = 0.0729654
I0916 17:06:26.529553 20216 solver.cpp:336]     Train net output #0: loss = 0.0729653 (* 1 = 0.0729653 loss)
I0916 17:06:26.529559 20216 sgd_solver.cpp:136] Iteration 1600, lr = 0.01, m = 0.9
I0916 17:06:47.050789 20216 solver.cpp:314] Iteration 1700 (4.87313 iter/s, 20.5207s/100 iter), loss = 0.0887681
I0916 17:06:47.050865 20216 solver.cpp:336]     Train net output #0: loss = 0.088768 (* 1 = 0.088768 loss)
I0916 17:06:47.050886 20216 sgd_solver.cpp:136] Iteration 1700, lr = 0.01, m = 0.9
I0916 17:07:07.862329 20216 solver.cpp:314] Iteration 1800 (4.80516 iter/s, 20.811s/100 iter), loss = 0.0591615
I0916 17:07:07.862359 20216 solver.cpp:336]     Train net output #0: loss = 0.0591613 (* 1 = 0.0591613 loss)
I0916 17:07:07.862365 20216 sgd_solver.cpp:136] Iteration 1800, lr = 0.01, m = 0.9
I0916 17:07:10.778779 20197 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 17:07:27.851717 20216 solver.cpp:314] Iteration 1900 (5.00279 iter/s, 19.9888s/100 iter), loss = 0.0568081
I0916 17:07:27.851768 20216 solver.cpp:336]     Train net output #0: loss = 0.056808 (* 1 = 0.056808 loss)
I0916 17:07:27.851774 20216 sgd_solver.cpp:136] Iteration 1900, lr = 0.01, m = 0.9
I0916 17:07:44.463848 20220 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 17:07:48.255661 20216 solver.cpp:563] Iteration 2000, Testing net (#0)
I0916 17:07:48.405552 20218 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'conv1a' with space 0.14G 3/1 1 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.409044 20217 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'conv1a' with space 0.14G 3/1 1 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.421433 20216 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1a' with space 0.14G 3/1 1 	(avail 4.17G, req 0G)	t: 0
I0916 17:07:48.436369 20218 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'conv1b' with space 0.14G 32/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.437356 20217 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'conv1b' with space 0.14G 32/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.448125 20216 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1b' with space 0.14G 32/4 6 	(avail 4.17G, req 0G)	t: 0
I0916 17:07:48.453173 20218 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'res2a_branch2a' with space 0.14G 32/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.453707 20217 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res2a_branch2a' with space 0.14G 32/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.463475 20216 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2a' with space 0.14G 32/1 6 	(avail 4.17G, req 0G)	t: 0
I0916 17:07:48.466066 20217 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res2a_branch2b' with space 0.14G 64/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.466229 20218 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'res2a_branch2b' with space 0.14G 64/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.474311 20216 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2b' with space 0.14G 64/4 6 	(avail 4.17G, req 0G)	t: 0
I0916 17:07:48.478147 20218 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'res3a_branch2a' with space 0.14G 64/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.478654 20217 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res3a_branch2a' with space 0.14G 64/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.485363 20218 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'res3a_branch2b' with space 0.14G 128/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.485513 20216 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2a' with space 0.14G 64/1 6 	(avail 4.17G, req 0G)	t: 0
I0916 17:07:48.485904 20217 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res3a_branch2b' with space 0.14G 128/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.493932 20216 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2b' with space 0.14G 128/4 6 	(avail 4.17G, req 0G)	t: 0
I0916 17:07:48.494494 20218 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'res4a_branch2a' with space 0.14G 128/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.497350 20217 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res4a_branch2a' with space 0.14G 128/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.499073 20218 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'res4a_branch2b' with space 0.14G 256/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.502584 20216 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2a' with space 0.14G 128/1 6 	(avail 4.17G, req 0G)	t: 0
I0916 17:07:48.502714 20217 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res4a_branch2b' with space 0.14G 256/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.506958 20216 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2b' with space 0.14G 256/4 6 	(avail 4.17G, req 0G)	t: 0
I0916 17:07:48.512787 20218 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'out3a' with space 0.14G 128/2 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.517554 20217 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'out3a' with space 0.14G 128/2 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.519292 20216 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'out3a' with space 0.14G 128/2 6 	(avail 4.17G, req 0G)	t: 0
I0916 17:07:48.522647 20218 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'ctx_conv1' with space 0.14G 64/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.529104 20216 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_conv1' with space 0.14G 64/1 6 	(avail 4.17G, req 0G)	t: 0
I0916 17:07:48.531992 20217 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_conv1' with space 0.14G 64/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.537729 20218 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'ctx_final' with space 0.14G 64/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.542989 20216 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_final' with space 0.14G 64/1 6 	(avail 4.17G, req 0G)	t: 0
I0916 17:07:48.548434 20217 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_final' with space 0.14G 64/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.786357 20218 blocking_queue.cpp:40] Data layer prefetch queue empty
I0916 17:08:13.006459 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.945378
I0916 17:08:13.006588 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 17:08:13.006598 20216 solver.cpp:655]     Test net output #2: loss = 0.164353 (* 1 = 0.164353 loss)
I0916 17:08:13.006664 20216 solver.cpp:265] [MultiGPU] Tests completed in 24.7503s
I0916 17:08:13.239820 20216 solver.cpp:314] Iteration 2000 (2.20328 iter/s, 45.3868s/100 iter), loss = 0.0703897
I0916 17:08:13.239850 20216 solver.cpp:336]     Train net output #0: loss = 0.0703895 (* 1 = 0.0703895 loss)
I0916 17:08:13.239857 20216 sgd_solver.cpp:136] Iteration 2000, lr = 0.01, m = 0.9
I0916 17:08:32.851845 20216 solver.cpp:314] Iteration 2100 (5.09906 iter/s, 19.6115s/100 iter), loss = 0.0557726
I0916 17:08:32.851874 20216 solver.cpp:336]     Train net output #0: loss = 0.0557724 (* 1 = 0.0557724 loss)
I0916 17:08:32.851881 20216 sgd_solver.cpp:136] Iteration 2100, lr = 0.01, m = 0.9
I0916 17:08:52.494669 20216 solver.cpp:314] Iteration 2200 (5.09106 iter/s, 19.6423s/100 iter), loss = 0.126393
I0916 17:08:52.494719 20216 solver.cpp:336]     Train net output #0: loss = 0.126393 (* 1 = 0.126393 loss)
I0916 17:08:52.494724 20216 sgd_solver.cpp:136] Iteration 2200, lr = 0.01, m = 0.9
I0916 17:09:12.793864 20216 solver.cpp:314] Iteration 2300 (4.92644 iter/s, 20.2986s/100 iter), loss = 0.059445
I0916 17:09:12.793893 20216 solver.cpp:336]     Train net output #0: loss = 0.0594448 (* 1 = 0.0594448 loss)
I0916 17:09:12.793900 20216 sgd_solver.cpp:136] Iteration 2300, lr = 0.01, m = 0.9
I0916 17:09:14.875787 20197 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 17:09:32.981691 20216 solver.cpp:314] Iteration 2400 (4.95362 iter/s, 20.1873s/100 iter), loss = 0.0690486
I0916 17:09:32.981751 20216 solver.cpp:336]     Train net output #0: loss = 0.0690484 (* 1 = 0.0690484 loss)
I0916 17:09:32.981758 20216 sgd_solver.cpp:136] Iteration 2400, lr = 0.01, m = 0.9
I0916 17:09:48.169400 20220 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 17:09:52.736311 20216 solver.cpp:314] Iteration 2500 (5.06225 iter/s, 19.7541s/100 iter), loss = 0.0868975
I0916 17:09:52.736335 20216 solver.cpp:336]     Train net output #0: loss = 0.0868973 (* 1 = 0.0868973 loss)
I0916 17:09:52.736340 20216 sgd_solver.cpp:136] Iteration 2500, lr = 0.01, m = 0.9
I0916 17:10:12.918685 20216 solver.cpp:314] Iteration 2600 (4.95496 iter/s, 20.1818s/100 iter), loss = 0.0749141
I0916 17:10:12.918748 20216 solver.cpp:336]     Train net output #0: loss = 0.0749138 (* 1 = 0.0749138 loss)
I0916 17:10:12.918756 20216 sgd_solver.cpp:136] Iteration 2600, lr = 0.01, m = 0.9
I0916 17:10:33.108183 20216 solver.cpp:314] Iteration 2700 (4.95321 iter/s, 20.1889s/100 iter), loss = 0.0715937
I0916 17:10:33.108204 20216 solver.cpp:336]     Train net output #0: loss = 0.0715935 (* 1 = 0.0715935 loss)
I0916 17:10:33.108209 20216 sgd_solver.cpp:136] Iteration 2700, lr = 0.01, m = 0.9
I0916 17:10:52.969238 20216 solver.cpp:314] Iteration 2800 (5.03512 iter/s, 19.8605s/100 iter), loss = 0.0502637
I0916 17:10:52.969295 20216 solver.cpp:336]     Train net output #0: loss = 0.0502635 (* 1 = 0.0502635 loss)
I0916 17:10:52.969301 20216 sgd_solver.cpp:136] Iteration 2800, lr = 0.01, m = 0.9
I0916 17:10:54.196893 20223 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 17:11:12.922165 20216 solver.cpp:314] Iteration 2900 (5.01194 iter/s, 19.9524s/100 iter), loss = 0.0996417
I0916 17:11:12.922189 20216 solver.cpp:336]     Train net output #0: loss = 0.0996415 (* 1 = 0.0996415 loss)
I0916 17:11:12.922194 20216 sgd_solver.cpp:136] Iteration 2900, lr = 0.01, m = 0.9
I0916 17:11:33.148785 20216 solver.cpp:314] Iteration 3000 (4.94412 iter/s, 20.2261s/100 iter), loss = 0.1
I0916 17:11:33.148867 20216 solver.cpp:336]     Train net output #0: loss = 0.1 (* 1 = 0.1 loss)
I0916 17:11:33.148875 20216 sgd_solver.cpp:136] Iteration 3000, lr = 0.01, m = 0.9
I0916 17:11:53.450981 20216 solver.cpp:314] Iteration 3100 (4.92571 iter/s, 20.3016s/100 iter), loss = 0.0623326
I0916 17:11:53.451016 20216 solver.cpp:336]     Train net output #0: loss = 0.0623324 (* 1 = 0.0623324 loss)
I0916 17:11:53.451025 20216 sgd_solver.cpp:136] Iteration 3100, lr = 0.01, m = 0.9
I0916 17:12:00.817440 20223 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 17:12:13.219429 20216 solver.cpp:314] Iteration 3200 (5.05871 iter/s, 19.7679s/100 iter), loss = 0.19464
I0916 17:12:13.219506 20216 solver.cpp:336]     Train net output #0: loss = 0.19464 (* 1 = 0.19464 loss)
I0916 17:12:13.219511 20216 sgd_solver.cpp:136] Iteration 3200, lr = 0.01, m = 0.9
I0916 17:12:33.663414 20216 solver.cpp:314] Iteration 3300 (4.89155 iter/s, 20.4434s/100 iter), loss = 0.0852514
I0916 17:12:33.663435 20216 solver.cpp:336]     Train net output #0: loss = 0.0852513 (* 1 = 0.0852513 loss)
I0916 17:12:33.663440 20216 sgd_solver.cpp:136] Iteration 3300, lr = 0.01, m = 0.9
I0916 17:12:34.069646 20197 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 17:12:54.086925 20216 solver.cpp:314] Iteration 3400 (4.89645 iter/s, 20.4229s/100 iter), loss = 0.0507501
I0916 17:12:54.087002 20216 solver.cpp:336]     Train net output #0: loss = 0.0507499 (* 1 = 0.0507499 loss)
I0916 17:12:54.087009 20216 sgd_solver.cpp:136] Iteration 3400, lr = 0.01, m = 0.9
I0916 17:13:14.129034 20216 solver.cpp:314] Iteration 3500 (4.98963 iter/s, 20.0415s/100 iter), loss = 0.11384
I0916 17:13:14.129062 20216 solver.cpp:336]     Train net output #0: loss = 0.113839 (* 1 = 0.113839 loss)
I0916 17:13:14.129068 20216 sgd_solver.cpp:136] Iteration 3500, lr = 0.01, m = 0.9
I0916 17:13:34.054585 20216 solver.cpp:314] Iteration 3600 (5.01882 iter/s, 19.925s/100 iter), loss = 0.094554
I0916 17:13:34.054636 20216 solver.cpp:336]     Train net output #0: loss = 0.0945538 (* 1 = 0.0945538 loss)
I0916 17:13:34.054641 20216 sgd_solver.cpp:136] Iteration 3600, lr = 0.01, m = 0.9
I0916 17:13:40.699476 20220 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 17:13:54.297402 20216 solver.cpp:314] Iteration 3700 (4.94016 iter/s, 20.2423s/100 iter), loss = 0.0670862
I0916 17:13:54.297428 20216 solver.cpp:336]     Train net output #0: loss = 0.0670861 (* 1 = 0.0670861 loss)
I0916 17:13:54.297435 20216 sgd_solver.cpp:136] Iteration 3700, lr = 0.01, m = 0.9
I0916 17:14:14.385627 20216 solver.cpp:314] Iteration 3800 (4.97818 iter/s, 20.0877s/100 iter), loss = 0.154844
I0916 17:14:14.385677 20216 solver.cpp:336]     Train net output #0: loss = 0.154843 (* 1 = 0.154843 loss)
I0916 17:14:14.385684 20216 sgd_solver.cpp:136] Iteration 3800, lr = 0.01, m = 0.9
I0916 17:14:34.224048 20216 solver.cpp:314] Iteration 3900 (5.04087 iter/s, 19.8379s/100 iter), loss = 0.0910186
I0916 17:14:34.224074 20216 solver.cpp:336]     Train net output #0: loss = 0.0910185 (* 1 = 0.0910185 loss)
I0916 17:14:34.224078 20216 sgd_solver.cpp:136] Iteration 3900, lr = 0.01, m = 0.9
I0916 17:14:47.211580 20197 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 17:14:54.576632 20216 solver.cpp:563] Iteration 4000, Testing net (#0)
I0916 17:15:26.565824 20204 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 17:15:27.170097 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.940676
I0916 17:15:27.170121 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 17:15:27.170126 20216 solver.cpp:655]     Test net output #2: loss = 0.178434 (* 1 = 0.178434 loss)
I0916 17:15:27.170156 20216 solver.cpp:265] [MultiGPU] Tests completed in 32.5926s
I0916 17:15:27.369248 20216 solver.cpp:314] Iteration 4000 (1.88169 iter/s, 53.1437s/100 iter), loss = 0.0611546
I0916 17:15:27.369277 20216 solver.cpp:336]     Train net output #0: loss = 0.0611545 (* 1 = 0.0611545 loss)
I0916 17:15:27.369284 20216 sgd_solver.cpp:136] Iteration 4000, lr = 0.01, m = 0.9
I0916 17:15:46.942544 20216 solver.cpp:314] Iteration 4100 (5.10915 iter/s, 19.5727s/100 iter), loss = 0.170168
I0916 17:15:46.942571 20216 solver.cpp:336]     Train net output #0: loss = 0.170168 (* 1 = 0.170168 loss)
I0916 17:15:46.942577 20216 sgd_solver.cpp:136] Iteration 4100, lr = 0.01, m = 0.9
I0916 17:15:52.477354 20219 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 17:16:06.815688 20216 solver.cpp:314] Iteration 4200 (5.03206 iter/s, 19.8726s/100 iter), loss = 0.0688574
I0916 17:16:06.815757 20216 solver.cpp:336]     Train net output #0: loss = 0.0688573 (* 1 = 0.0688573 loss)
I0916 17:16:06.815762 20216 sgd_solver.cpp:136] Iteration 4200, lr = 0.01, m = 0.9
I0916 17:16:26.733546 20216 solver.cpp:314] Iteration 4300 (5.02076 iter/s, 19.9173s/100 iter), loss = 0.0766944
I0916 17:16:26.733584 20216 solver.cpp:336]     Train net output #0: loss = 0.0766943 (* 1 = 0.0766943 loss)
I0916 17:16:26.733592 20216 sgd_solver.cpp:136] Iteration 4300, lr = 0.01, m = 0.9
I0916 17:16:46.557196 20216 solver.cpp:314] Iteration 4400 (5.04462 iter/s, 19.8231s/100 iter), loss = 0.0633302
I0916 17:16:46.557283 20216 solver.cpp:336]     Train net output #0: loss = 0.06333 (* 1 = 0.06333 loss)
I0916 17:16:46.557291 20216 sgd_solver.cpp:136] Iteration 4400, lr = 0.01, m = 0.9
I0916 17:16:58.059345 20224 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 17:17:06.353163 20216 solver.cpp:314] Iteration 4500 (5.05168 iter/s, 19.7954s/100 iter), loss = 0.0464319
I0916 17:17:06.353194 20216 solver.cpp:336]     Train net output #0: loss = 0.0464317 (* 1 = 0.0464317 loss)
I0916 17:17:06.353201 20216 sgd_solver.cpp:136] Iteration 4500, lr = 0.01, m = 0.9
I0916 17:17:26.320341 20216 solver.cpp:314] Iteration 4600 (5.00836 iter/s, 19.9666s/100 iter), loss = 0.101606
I0916 17:17:26.320448 20216 solver.cpp:336]     Train net output #0: loss = 0.101606 (* 1 = 0.101606 loss)
I0916 17:17:26.320456 20216 sgd_solver.cpp:136] Iteration 4600, lr = 0.01, m = 0.9
I0916 17:17:46.274945 20216 solver.cpp:314] Iteration 4700 (5.01152 iter/s, 19.954s/100 iter), loss = 0.0938497
I0916 17:17:46.274972 20216 solver.cpp:336]     Train net output #0: loss = 0.0938496 (* 1 = 0.0938496 loss)
I0916 17:17:46.274978 20216 sgd_solver.cpp:136] Iteration 4700, lr = 0.01, m = 0.9
I0916 17:18:03.877588 20219 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 17:18:05.813802 20216 solver.cpp:314] Iteration 4800 (5.11815 iter/s, 19.5383s/100 iter), loss = 0.0952472
I0916 17:18:05.813834 20216 solver.cpp:336]     Train net output #0: loss = 0.0952471 (* 1 = 0.0952471 loss)
I0916 17:18:05.813841 20216 sgd_solver.cpp:136] Iteration 4800, lr = 0.01, m = 0.9
I0916 17:18:25.605921 20216 solver.cpp:314] Iteration 4900 (5.05266 iter/s, 19.7916s/100 iter), loss = 0.0969652
I0916 17:18:25.605944 20216 solver.cpp:336]     Train net output #0: loss = 0.096965 (* 1 = 0.096965 loss)
I0916 17:18:25.605949 20216 sgd_solver.cpp:136] Iteration 4900, lr = 0.01, m = 0.9
I0916 17:18:36.501451 20220 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 17:18:45.411703 20216 solver.cpp:314] Iteration 5000 (5.04917 iter/s, 19.8052s/100 iter), loss = 0.112146
I0916 17:18:45.411727 20216 solver.cpp:336]     Train net output #0: loss = 0.112146 (* 1 = 0.112146 loss)
I0916 17:18:45.411732 20216 sgd_solver.cpp:136] Iteration 5000, lr = 0.01, m = 0.9
I0916 17:19:04.898316 20216 solver.cpp:314] Iteration 5100 (5.13187 iter/s, 19.4861s/100 iter), loss = 0.115609
I0916 17:19:04.898342 20216 solver.cpp:336]     Train net output #0: loss = 0.115609 (* 1 = 0.115609 loss)
I0916 17:19:04.898350 20216 sgd_solver.cpp:136] Iteration 5100, lr = 0.01, m = 0.9
I0916 17:19:24.674283 20216 solver.cpp:314] Iteration 5200 (5.05679 iter/s, 19.7754s/100 iter), loss = 0.0918244
I0916 17:19:24.674360 20216 solver.cpp:336]     Train net output #0: loss = 0.0918243 (* 1 = 0.0918243 loss)
I0916 17:19:24.674368 20216 sgd_solver.cpp:136] Iteration 5200, lr = 0.01, m = 0.9
I0916 17:19:41.645246 20220 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 17:19:44.490795 20216 solver.cpp:314] Iteration 5300 (5.04644 iter/s, 19.816s/100 iter), loss = 0.068944
I0916 17:19:44.490821 20216 solver.cpp:336]     Train net output #0: loss = 0.0689439 (* 1 = 0.0689439 loss)
I0916 17:19:44.490828 20216 sgd_solver.cpp:136] Iteration 5300, lr = 0.01, m = 0.9
I0916 17:20:04.359000 20216 solver.cpp:314] Iteration 5400 (5.03331 iter/s, 19.8676s/100 iter), loss = 0.0621616
I0916 17:20:04.359077 20216 solver.cpp:336]     Train net output #0: loss = 0.0621615 (* 1 = 0.0621615 loss)
I0916 17:20:04.359086 20216 sgd_solver.cpp:136] Iteration 5400, lr = 0.01, m = 0.9
I0916 17:20:24.254957 20216 solver.cpp:314] Iteration 5500 (5.02629 iter/s, 19.8954s/100 iter), loss = 0.0760806
I0916 17:20:24.254981 20216 solver.cpp:336]     Train net output #0: loss = 0.0760805 (* 1 = 0.0760805 loss)
I0916 17:20:24.254987 20216 sgd_solver.cpp:136] Iteration 5500, lr = 0.01, m = 0.9
I0916 17:20:43.809629 20216 solver.cpp:314] Iteration 5600 (5.11401 iter/s, 19.5541s/100 iter), loss = 0.0385456
I0916 17:20:43.809689 20216 solver.cpp:336]     Train net output #0: loss = 0.0385455 (* 1 = 0.0385455 loss)
I0916 17:20:43.809697 20216 sgd_solver.cpp:136] Iteration 5600, lr = 0.01, m = 0.9
I0916 17:20:47.080631 20224 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 17:21:04.003371 20216 solver.cpp:314] Iteration 5700 (4.95217 iter/s, 20.1932s/100 iter), loss = 0.128877
I0916 17:21:04.003430 20216 solver.cpp:336]     Train net output #0: loss = 0.128877 (* 1 = 0.128877 loss)
I0916 17:21:04.003446 20216 sgd_solver.cpp:136] Iteration 5700, lr = 0.01, m = 0.9
I0916 17:21:23.878000 20216 solver.cpp:314] Iteration 5800 (5.03168 iter/s, 19.8741s/100 iter), loss = 0.0713308
I0916 17:21:23.878087 20216 solver.cpp:336]     Train net output #0: loss = 0.0713307 (* 1 = 0.0713307 loss)
I0916 17:21:23.878100 20216 sgd_solver.cpp:136] Iteration 5800, lr = 0.01, m = 0.9
I0916 17:21:43.520931 20216 solver.cpp:314] Iteration 5900 (5.09103 iter/s, 19.6424s/100 iter), loss = 0.158409
I0916 17:21:43.520956 20216 solver.cpp:336]     Train net output #0: loss = 0.158409 (* 1 = 0.158409 loss)
I0916 17:21:43.520961 20216 sgd_solver.cpp:136] Iteration 5900, lr = 0.01, m = 0.9
I0916 17:21:52.712836 20224 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 17:22:03.406215 20216 solver.cpp:563] Iteration 6000, Testing net (#0)
I0916 17:22:13.107606 20250 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 17:22:17.430575 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.94797
I0916 17:22:17.430599 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 17:22:17.430605 20216 solver.cpp:655]     Test net output #2: loss = 0.157664 (* 1 = 0.157664 loss)
I0916 17:22:17.430697 20216 solver.cpp:265] [MultiGPU] Tests completed in 14.0241s
I0916 17:22:17.641198 20216 solver.cpp:314] Iteration 6000 (2.93089 iter/s, 34.1193s/100 iter), loss = 0.110208
I0916 17:22:17.641227 20216 solver.cpp:336]     Train net output #0: loss = 0.110208 (* 1 = 0.110208 loss)
I0916 17:22:17.641234 20216 sgd_solver.cpp:136] Iteration 6000, lr = 0.01, m = 0.9
I0916 17:22:37.093201 20216 solver.cpp:314] Iteration 6100 (5.14101 iter/s, 19.4515s/100 iter), loss = 0.249439
I0916 17:22:37.093252 20216 solver.cpp:336]     Train net output #0: loss = 0.249439 (* 1 = 0.249439 loss)
I0916 17:22:37.093260 20216 sgd_solver.cpp:136] Iteration 6100, lr = 0.01, m = 0.9
I0916 17:22:56.542809 20216 solver.cpp:314] Iteration 6200 (5.14164 iter/s, 19.4491s/100 iter), loss = 0.0887299
I0916 17:22:56.542834 20216 solver.cpp:336]     Train net output #0: loss = 0.0887299 (* 1 = 0.0887299 loss)
I0916 17:22:56.542839 20216 sgd_solver.cpp:136] Iteration 6200, lr = 0.01, m = 0.9
I0916 17:23:11.475636 20224 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 17:23:15.949113 20216 solver.cpp:314] Iteration 6300 (5.15311 iter/s, 19.4058s/100 iter), loss = 0.0904803
I0916 17:23:15.949143 20216 solver.cpp:336]     Train net output #0: loss = 0.0904803 (* 1 = 0.0904803 loss)
I0916 17:23:15.949151 20216 sgd_solver.cpp:136] Iteration 6300, lr = 0.01, m = 0.9
I0916 17:23:35.546825 20216 solver.cpp:314] Iteration 6400 (5.10278 iter/s, 19.5972s/100 iter), loss = 0.0796616
I0916 17:23:35.546852 20216 solver.cpp:336]     Train net output #0: loss = 0.0796615 (* 1 = 0.0796615 loss)
I0916 17:23:35.546859 20216 sgd_solver.cpp:136] Iteration 6400, lr = 0.01, m = 0.9
I0916 17:23:55.024096 20216 solver.cpp:314] Iteration 6500 (5.13433 iter/s, 19.4767s/100 iter), loss = 0.113316
I0916 17:23:55.024595 20216 solver.cpp:336]     Train net output #0: loss = 0.113316 (* 1 = 0.113316 loss)
I0916 17:23:55.024611 20216 sgd_solver.cpp:136] Iteration 6500, lr = 0.01, m = 0.9
I0916 17:24:14.789343 20216 solver.cpp:314] Iteration 6600 (5.05953 iter/s, 19.7647s/100 iter), loss = 0.114017
I0916 17:24:14.789371 20216 solver.cpp:336]     Train net output #0: loss = 0.114017 (* 1 = 0.114017 loss)
I0916 17:24:14.789377 20216 sgd_solver.cpp:136] Iteration 6600, lr = 0.01, m = 0.9
I0916 17:24:16.368454 20223 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 17:24:34.407810 20216 solver.cpp:314] Iteration 6700 (5.09738 iter/s, 19.6179s/100 iter), loss = 0.113417
I0916 17:24:34.407869 20216 solver.cpp:336]     Train net output #0: loss = 0.113417 (* 1 = 0.113417 loss)
I0916 17:24:34.407876 20216 sgd_solver.cpp:136] Iteration 6700, lr = 0.01, m = 0.9
I0916 17:24:53.796352 20216 solver.cpp:314] Iteration 6800 (5.15783 iter/s, 19.388s/100 iter), loss = 0.0456348
I0916 17:24:53.796377 20216 solver.cpp:336]     Train net output #0: loss = 0.0456348 (* 1 = 0.0456348 loss)
I0916 17:24:53.796382 20216 sgd_solver.cpp:136] Iteration 6800, lr = 0.01, m = 0.9
I0916 17:25:13.279264 20216 solver.cpp:314] Iteration 6900 (5.13285 iter/s, 19.4824s/100 iter), loss = 0.106546
I0916 17:25:13.279312 20216 solver.cpp:336]     Train net output #0: loss = 0.106546 (* 1 = 0.106546 loss)
I0916 17:25:13.279317 20216 sgd_solver.cpp:136] Iteration 6900, lr = 0.01, m = 0.9
I0916 17:25:21.004822 20223 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 17:25:33.893582 20216 solver.cpp:314] Iteration 7000 (4.85113 iter/s, 20.6137s/100 iter), loss = 0.126016
I0916 17:25:33.893609 20216 solver.cpp:336]     Train net output #0: loss = 0.126016 (* 1 = 0.126016 loss)
I0916 17:25:33.893615 20216 sgd_solver.cpp:136] Iteration 7000, lr = 0.01, m = 0.9
I0916 17:25:54.113678 20216 solver.cpp:314] Iteration 7100 (4.94571 iter/s, 20.2195s/100 iter), loss = 0.0802786
I0916 17:25:54.113737 20216 solver.cpp:336]     Train net output #0: loss = 0.0802785 (* 1 = 0.0802785 loss)
I0916 17:25:54.113744 20216 sgd_solver.cpp:136] Iteration 7100, lr = 0.01, m = 0.9
I0916 17:25:54.808028 20219 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 17:26:14.121845 20216 solver.cpp:314] Iteration 7200 (4.9981 iter/s, 20.0076s/100 iter), loss = 0.0883156
I0916 17:26:14.121872 20216 solver.cpp:336]     Train net output #0: loss = 0.0883155 (* 1 = 0.0883155 loss)
I0916 17:26:14.121879 20216 sgd_solver.cpp:136] Iteration 7200, lr = 0.01, m = 0.9
I0916 17:26:34.148424 20216 solver.cpp:314] Iteration 7300 (4.9935 iter/s, 20.026s/100 iter), loss = 0.0662843
I0916 17:26:34.148475 20216 solver.cpp:336]     Train net output #0: loss = 0.0662842 (* 1 = 0.0662842 loss)
I0916 17:26:34.148481 20216 sgd_solver.cpp:136] Iteration 7300, lr = 0.01, m = 0.9
I0916 17:26:54.488734 20216 solver.cpp:314] Iteration 7400 (4.91648 iter/s, 20.3397s/100 iter), loss = 0.147958
I0916 17:26:54.488790 20216 solver.cpp:336]     Train net output #0: loss = 0.147958 (* 1 = 0.147958 loss)
I0916 17:26:54.488812 20216 sgd_solver.cpp:136] Iteration 7400, lr = 0.01, m = 0.9
I0916 17:27:01.487717 20224 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 17:27:14.738914 20216 solver.cpp:314] Iteration 7500 (4.93837 iter/s, 20.2496s/100 iter), loss = 0.0945349
I0916 17:27:14.738978 20216 solver.cpp:336]     Train net output #0: loss = 0.0945348 (* 1 = 0.0945348 loss)
I0916 17:27:14.738987 20216 sgd_solver.cpp:136] Iteration 7500, lr = 0.01, m = 0.9
I0916 17:27:34.916519 20216 solver.cpp:314] Iteration 7600 (4.95613 iter/s, 20.177s/100 iter), loss = 0.057806
I0916 17:27:34.916543 20216 solver.cpp:336]     Train net output #0: loss = 0.0578059 (* 1 = 0.0578059 loss)
I0916 17:27:34.916548 20216 sgd_solver.cpp:136] Iteration 7600, lr = 0.01, m = 0.9
I0916 17:27:55.125870 20216 solver.cpp:314] Iteration 7700 (4.94834 iter/s, 20.2088s/100 iter), loss = 0.0631604
I0916 17:27:55.125954 20216 solver.cpp:336]     Train net output #0: loss = 0.0631604 (* 1 = 0.0631604 loss)
I0916 17:27:55.125962 20216 sgd_solver.cpp:136] Iteration 7700, lr = 0.01, m = 0.9
I0916 17:28:08.518646 20223 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 17:28:15.585372 20216 solver.cpp:314] Iteration 7800 (4.88784 iter/s, 20.4589s/100 iter), loss = 0.15585
I0916 17:28:15.585393 20216 solver.cpp:336]     Train net output #0: loss = 0.15585 (* 1 = 0.15585 loss)
I0916 17:28:15.585398 20216 sgd_solver.cpp:136] Iteration 7800, lr = 0.01, m = 0.9
I0916 17:28:35.611838 20216 solver.cpp:314] Iteration 7900 (4.99353 iter/s, 20.0259s/100 iter), loss = 0.119486
I0916 17:28:35.612126 20216 solver.cpp:336]     Train net output #0: loss = 0.119486 (* 1 = 0.119486 loss)
I0916 17:28:35.612238 20216 sgd_solver.cpp:136] Iteration 7900, lr = 0.01, m = 0.9
I0916 17:28:41.490084 20220 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 17:28:55.568976 20216 solver.cpp:563] Iteration 8000, Testing net (#0)
I0916 17:29:14.059849 20202 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 17:29:14.867595 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.916309
I0916 17:29:14.867624 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.999998
I0916 17:29:14.867630 20216 solver.cpp:655]     Test net output #2: loss = 0.249231 (* 1 = 0.249231 loss)
I0916 17:29:14.867663 20216 solver.cpp:265] [MultiGPU] Tests completed in 19.2982s
I0916 17:29:15.094511 20216 solver.cpp:314] Iteration 8000 (2.53283 iter/s, 39.4816s/100 iter), loss = 0.098198
I0916 17:29:15.094534 20216 solver.cpp:336]     Train net output #0: loss = 0.0981979 (* 1 = 0.0981979 loss)
I0916 17:29:15.094539 20216 sgd_solver.cpp:136] Iteration 8000, lr = 0.01, m = 0.9
I0916 17:29:34.621361 20216 solver.cpp:314] Iteration 8100 (5.1213 iter/s, 19.5263s/100 iter), loss = 0.0675431
I0916 17:29:34.621387 20216 solver.cpp:336]     Train net output #0: loss = 0.067543 (* 1 = 0.067543 loss)
I0916 17:29:34.621392 20216 sgd_solver.cpp:136] Iteration 8100, lr = 0.01, m = 0.9
I0916 17:29:54.231922 20216 solver.cpp:314] Iteration 8200 (5.09944 iter/s, 19.61s/100 iter), loss = 0.0709209
I0916 17:29:54.231984 20216 solver.cpp:336]     Train net output #0: loss = 0.0709208 (* 1 = 0.0709208 loss)
I0916 17:29:54.231992 20216 sgd_solver.cpp:136] Iteration 8200, lr = 0.01, m = 0.9
I0916 17:30:05.968854 20224 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 17:30:13.825264 20216 solver.cpp:314] Iteration 8300 (5.10392 iter/s, 19.5928s/100 iter), loss = 0.22628
I0916 17:30:13.825290 20216 solver.cpp:336]     Train net output #0: loss = 0.22628 (* 1 = 0.22628 loss)
I0916 17:30:13.825296 20216 sgd_solver.cpp:136] Iteration 8300, lr = 0.01, m = 0.9
I0916 17:30:33.230700 20216 solver.cpp:314] Iteration 8400 (5.15334 iter/s, 19.4049s/100 iter), loss = 0.070129
I0916 17:30:33.230764 20216 solver.cpp:336]     Train net output #0: loss = 0.0701289 (* 1 = 0.0701289 loss)
I0916 17:30:33.230773 20216 sgd_solver.cpp:136] Iteration 8400, lr = 0.01, m = 0.9
I0916 17:30:38.317651 20219 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 17:30:52.799983 20216 solver.cpp:314] Iteration 8500 (5.11019 iter/s, 19.5687s/100 iter), loss = 0.066922
I0916 17:30:52.800007 20216 solver.cpp:336]     Train net output #0: loss = 0.0669219 (* 1 = 0.0669219 loss)
I0916 17:30:52.800014 20216 sgd_solver.cpp:136] Iteration 8500, lr = 0.01, m = 0.9
I0916 17:31:12.381579 20216 solver.cpp:314] Iteration 8600 (5.10698 iter/s, 19.581s/100 iter), loss = 0.0859915
I0916 17:31:12.381633 20216 solver.cpp:336]     Train net output #0: loss = 0.0859914 (* 1 = 0.0859914 loss)
I0916 17:31:12.381639 20216 sgd_solver.cpp:136] Iteration 8600, lr = 0.01, m = 0.9
I0916 17:31:32.121379 20216 solver.cpp:314] Iteration 8700 (5.06605 iter/s, 19.7392s/100 iter), loss = 0.0679814
I0916 17:31:32.121400 20216 solver.cpp:336]     Train net output #0: loss = 0.0679813 (* 1 = 0.0679813 loss)
I0916 17:31:32.121404 20216 sgd_solver.cpp:136] Iteration 8700, lr = 0.01, m = 0.9
I0916 17:31:43.117573 20224 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 17:31:51.622787 20216 solver.cpp:314] Iteration 8800 (5.12798 iter/s, 19.5009s/100 iter), loss = 0.0679392
I0916 17:31:51.622817 20216 solver.cpp:336]     Train net output #0: loss = 0.0679392 (* 1 = 0.0679392 loss)
I0916 17:31:51.622824 20216 sgd_solver.cpp:136] Iteration 8800, lr = 0.01, m = 0.9
I0916 17:32:11.224231 20216 solver.cpp:314] Iteration 8900 (5.10181 iter/s, 19.6009s/100 iter), loss = 0.0701668
I0916 17:32:11.224258 20216 solver.cpp:336]     Train net output #0: loss = 0.0701668 (* 1 = 0.0701668 loss)
I0916 17:32:11.224264 20216 sgd_solver.cpp:136] Iteration 8900, lr = 0.01, m = 0.9
I0916 17:32:30.933195 20216 solver.cpp:314] Iteration 9000 (5.07398 iter/s, 19.7084s/100 iter), loss = 0.0844631
I0916 17:32:30.933244 20216 solver.cpp:336]     Train net output #0: loss = 0.0844631 (* 1 = 0.0844631 loss)
I0916 17:32:30.933249 20216 sgd_solver.cpp:136] Iteration 9000, lr = 0.01, m = 0.9
I0916 17:32:48.105202 20197 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 17:32:50.563141 20216 solver.cpp:314] Iteration 9100 (5.0944 iter/s, 19.6294s/100 iter), loss = 0.103181
I0916 17:32:50.563169 20216 solver.cpp:336]     Train net output #0: loss = 0.103181 (* 1 = 0.103181 loss)
I0916 17:32:50.563174 20216 sgd_solver.cpp:136] Iteration 9100, lr = 0.01, m = 0.9
I0916 17:33:10.322782 20216 solver.cpp:314] Iteration 9200 (5.06096 iter/s, 19.7591s/100 iter), loss = 0.0863194
I0916 17:33:10.322841 20216 solver.cpp:336]     Train net output #0: loss = 0.0863192 (* 1 = 0.0863192 loss)
I0916 17:33:10.322849 20216 sgd_solver.cpp:136] Iteration 9200, lr = 0.01, m = 0.9
I0916 17:33:20.381431 20219 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 17:33:29.703932 20216 solver.cpp:314] Iteration 9300 (5.1598 iter/s, 19.3806s/100 iter), loss = 0.086032
I0916 17:33:29.703958 20216 solver.cpp:336]     Train net output #0: loss = 0.0860318 (* 1 = 0.0860318 loss)
I0916 17:33:29.703964 20216 sgd_solver.cpp:136] Iteration 9300, lr = 0.01, m = 0.9
I0916 17:33:48.964045 20216 solver.cpp:314] Iteration 9400 (5.19222 iter/s, 19.2596s/100 iter), loss = 0.0968377
I0916 17:33:48.964090 20216 solver.cpp:336]     Train net output #0: loss = 0.0968375 (* 1 = 0.0968375 loss)
I0916 17:33:48.964095 20216 sgd_solver.cpp:136] Iteration 9400, lr = 0.01, m = 0.9
I0916 17:34:08.132643 20216 solver.cpp:314] Iteration 9500 (5.21701 iter/s, 19.1681s/100 iter), loss = 0.0649179
I0916 17:34:08.132668 20216 solver.cpp:336]     Train net output #0: loss = 0.0649177 (* 1 = 0.0649177 loss)
I0916 17:34:08.132674 20216 sgd_solver.cpp:136] Iteration 9500, lr = 0.01, m = 0.9
I0916 17:34:24.488903 20195 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 17:34:27.817129 20216 solver.cpp:314] Iteration 9600 (5.08029 iter/s, 19.6839s/100 iter), loss = 0.0893848
I0916 17:34:27.817155 20216 solver.cpp:336]     Train net output #0: loss = 0.0893845 (* 1 = 0.0893845 loss)
I0916 17:34:27.817162 20216 sgd_solver.cpp:136] Iteration 9600, lr = 0.01, m = 0.9
I0916 17:34:47.264158 20216 solver.cpp:314] Iteration 9700 (5.14232 iter/s, 19.4465s/100 iter), loss = 0.0690491
I0916 17:34:47.264183 20216 solver.cpp:336]     Train net output #0: loss = 0.0690489 (* 1 = 0.0690489 loss)
I0916 17:34:47.264189 20216 sgd_solver.cpp:136] Iteration 9700, lr = 0.01, m = 0.9
I0916 17:35:06.582811 20216 solver.cpp:314] Iteration 9800 (5.17649 iter/s, 19.3181s/100 iter), loss = 0.0663428
I0916 17:35:06.582891 20216 solver.cpp:336]     Train net output #0: loss = 0.0663425 (* 1 = 0.0663425 loss)
I0916 17:35:06.582898 20216 sgd_solver.cpp:136] Iteration 9800, lr = 0.01, m = 0.9
I0916 17:35:25.916343 20216 solver.cpp:314] Iteration 9900 (5.17251 iter/s, 19.333s/100 iter), loss = 0.101346
I0916 17:35:25.916374 20216 solver.cpp:336]     Train net output #0: loss = 0.101346 (* 1 = 0.101346 loss)
I0916 17:35:25.916380 20216 sgd_solver.cpp:136] Iteration 9900, lr = 0.01, m = 0.9
I0916 17:35:28.489147 20223 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 17:35:45.318506 20216 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/cityscapes5_jsegnet21v2_iter_10000.caffemodel
I0916 17:35:45.432381 20216 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/cityscapes5_jsegnet21v2_iter_10000.solverstate
I0916 17:35:45.438395 20216 solver.cpp:563] Iteration 10000, Testing net (#0)
I0916 17:35:52.720719 20202 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 17:35:56.563422 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.928857
I0916 17:35:56.563443 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 17:35:56.563449 20216 solver.cpp:655]     Test net output #2: loss = 0.219072 (* 1 = 0.219072 loss)
I0916 17:35:56.563475 20216 solver.cpp:265] [MultiGPU] Tests completed in 11.1248s
I0916 17:35:56.767657 20216 solver.cpp:314] Iteration 10000 (3.24144 iter/s, 30.8504s/100 iter), loss = 0.0681242
I0916 17:35:56.767684 20216 solver.cpp:336]     Train net output #0: loss = 0.0681239 (* 1 = 0.0681239 loss)
I0916 17:35:56.767691 20216 sgd_solver.cpp:136] Iteration 10000, lr = 0.01, m = 0.9
I0916 17:36:16.069154 20216 solver.cpp:314] Iteration 10100 (5.18109 iter/s, 19.3009s/100 iter), loss = 0.0752725
I0916 17:36:16.069212 20216 solver.cpp:336]     Train net output #0: loss = 0.0752721 (* 1 = 0.0752721 loss)
I0916 17:36:16.069221 20216 sgd_solver.cpp:136] Iteration 10100, lr = 0.01, m = 0.9
I0916 17:36:35.430485 20216 solver.cpp:314] Iteration 10200 (5.16508 iter/s, 19.3608s/100 iter), loss = 0.12103
I0916 17:36:35.430511 20216 solver.cpp:336]     Train net output #0: loss = 0.12103 (* 1 = 0.12103 loss)
I0916 17:36:35.430517 20216 sgd_solver.cpp:136] Iteration 10200, lr = 0.01, m = 0.9
I0916 17:36:43.945358 20195 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 17:36:55.031854 20216 solver.cpp:314] Iteration 10300 (5.10405 iter/s, 19.5923s/100 iter), loss = 0.0844408
I0916 17:36:55.032376 20216 solver.cpp:336]     Train net output #0: loss = 0.0844404 (* 1 = 0.0844404 loss)
I0916 17:36:55.032498 20216 sgd_solver.cpp:136] Iteration 10300, lr = 0.01, m = 0.9
I0916 17:37:14.811975 20216 solver.cpp:314] Iteration 10400 (5.05572 iter/s, 19.7796s/100 iter), loss = 0.0557976
I0916 17:37:14.812003 20216 solver.cpp:336]     Train net output #0: loss = 0.0557972 (* 1 = 0.0557972 loss)
I0916 17:37:14.812008 20216 sgd_solver.cpp:136] Iteration 10400, lr = 0.01, m = 0.9
I0916 17:37:34.319171 20216 solver.cpp:314] Iteration 10500 (5.12646 iter/s, 19.5066s/100 iter), loss = 0.0617972
I0916 17:37:34.325795 20216 solver.cpp:336]     Train net output #0: loss = 0.0617968 (* 1 = 0.0617968 loss)
I0916 17:37:34.325867 20216 sgd_solver.cpp:136] Iteration 10500, lr = 0.01, m = 0.9
I0916 17:37:48.588306 20224 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 17:37:53.568374 20216 solver.cpp:314] Iteration 10600 (5.19517 iter/s, 19.2487s/100 iter), loss = 0.0949798
I0916 17:37:53.568398 20216 solver.cpp:336]     Train net output #0: loss = 0.0949795 (* 1 = 0.0949795 loss)
I0916 17:37:53.568403 20216 sgd_solver.cpp:136] Iteration 10600, lr = 0.01, m = 0.9
I0916 17:38:12.855937 20216 solver.cpp:314] Iteration 10700 (5.18483 iter/s, 19.287s/100 iter), loss = 0.0467802
I0916 17:38:12.856024 20216 solver.cpp:336]     Train net output #0: loss = 0.0467799 (* 1 = 0.0467799 loss)
I0916 17:38:12.856030 20216 sgd_solver.cpp:136] Iteration 10700, lr = 0.01, m = 0.9
I0916 17:38:20.659703 20195 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 17:38:32.320540 20216 solver.cpp:314] Iteration 10800 (5.13768 iter/s, 19.4641s/100 iter), loss = 0.109642
I0916 17:38:32.320562 20216 solver.cpp:336]     Train net output #0: loss = 0.109641 (* 1 = 0.109641 loss)
I0916 17:38:32.320567 20216 sgd_solver.cpp:136] Iteration 10800, lr = 0.01, m = 0.9
I0916 17:38:51.738890 20216 solver.cpp:314] Iteration 10900 (5.14991 iter/s, 19.4178s/100 iter), loss = 0.0469256
I0916 17:38:51.738945 20216 solver.cpp:336]     Train net output #0: loss = 0.0469253 (* 1 = 0.0469253 loss)
I0916 17:38:51.738950 20216 sgd_solver.cpp:136] Iteration 10900, lr = 0.01, m = 0.9
I0916 17:39:11.118367 20216 solver.cpp:314] Iteration 11000 (5.16024 iter/s, 19.3789s/100 iter), loss = 0.082404
I0916 17:39:11.118393 20216 solver.cpp:336]     Train net output #0: loss = 0.0824037 (* 1 = 0.0824037 loss)
I0916 17:39:11.118401 20216 sgd_solver.cpp:136] Iteration 11000, lr = 0.01, m = 0.9
I0916 17:39:24.736809 20220 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 17:39:30.588650 20216 solver.cpp:314] Iteration 11100 (5.13618 iter/s, 19.4697s/100 iter), loss = 0.0820266
I0916 17:39:30.588675 20216 solver.cpp:336]     Train net output #0: loss = 0.0820263 (* 1 = 0.0820263 loss)
I0916 17:39:30.588681 20216 sgd_solver.cpp:136] Iteration 11100, lr = 0.01, m = 0.9
I0916 17:39:50.015389 20216 solver.cpp:314] Iteration 11200 (5.14769 iter/s, 19.4262s/100 iter), loss = 0.0864309
I0916 17:39:50.015417 20216 solver.cpp:336]     Train net output #0: loss = 0.0864306 (* 1 = 0.0864306 loss)
I0916 17:39:50.015424 20216 sgd_solver.cpp:136] Iteration 11200, lr = 0.01, m = 0.9
I0916 17:40:09.482028 20216 solver.cpp:314] Iteration 11300 (5.13714 iter/s, 19.4661s/100 iter), loss = 0.0823764
I0916 17:40:09.482080 20216 solver.cpp:336]     Train net output #0: loss = 0.0823762 (* 1 = 0.0823762 loss)
I0916 17:40:09.482087 20216 sgd_solver.cpp:136] Iteration 11300, lr = 0.01, m = 0.9
I0916 17:40:28.498455 20216 solver.cpp:314] Iteration 11400 (5.25876 iter/s, 19.0159s/100 iter), loss = 0.0554919
I0916 17:40:28.498477 20216 solver.cpp:336]     Train net output #0: loss = 0.0554917 (* 1 = 0.0554917 loss)
I0916 17:40:28.498483 20216 sgd_solver.cpp:136] Iteration 11400, lr = 0.01, m = 0.9
I0916 17:40:28.725814 20219 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 17:40:48.497755 20216 solver.cpp:314] Iteration 11500 (5.00032 iter/s, 19.9987s/100 iter), loss = 0.0869469
I0916 17:40:48.497826 20216 solver.cpp:336]     Train net output #0: loss = 0.0869466 (* 1 = 0.0869466 loss)
I0916 17:40:48.497834 20216 sgd_solver.cpp:136] Iteration 11500, lr = 0.01, m = 0.9
I0916 17:41:08.779372 20216 solver.cpp:314] Iteration 11600 (4.93071 iter/s, 20.281s/100 iter), loss = 0.0977212
I0916 17:41:08.779407 20216 solver.cpp:336]     Train net output #0: loss = 0.0977209 (* 1 = 0.0977209 loss)
I0916 17:41:08.779412 20216 sgd_solver.cpp:136] Iteration 11600, lr = 0.01, m = 0.9
I0916 17:41:29.069613 20216 solver.cpp:314] Iteration 11700 (4.92862 iter/s, 20.2897s/100 iter), loss = 0.0433001
I0916 17:41:29.069669 20216 solver.cpp:336]     Train net output #0: loss = 0.0432998 (* 1 = 0.0432998 loss)
I0916 17:41:29.069676 20216 sgd_solver.cpp:136] Iteration 11700, lr = 0.01, m = 0.9
I0916 17:41:35.367566 20197 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 17:41:49.081416 20216 solver.cpp:314] Iteration 11800 (4.99719 iter/s, 20.0112s/100 iter), loss = 0.0677215
I0916 17:41:49.081444 20216 solver.cpp:336]     Train net output #0: loss = 0.0677212 (* 1 = 0.0677212 loss)
I0916 17:41:49.081450 20216 sgd_solver.cpp:136] Iteration 11800, lr = 0.01, m = 0.9
I0916 17:42:08.512344 20219 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 17:42:09.288568 20216 solver.cpp:314] Iteration 11900 (4.94888 iter/s, 20.2066s/100 iter), loss = 0.0669838
I0916 17:42:09.288594 20216 solver.cpp:336]     Train net output #0: loss = 0.0669835 (* 1 = 0.0669835 loss)
I0916 17:42:09.288597 20216 sgd_solver.cpp:136] Iteration 11900, lr = 0.01, m = 0.9
I0916 17:42:29.459095 20216 solver.cpp:563] Iteration 12000, Testing net (#0)
I0916 17:42:41.260184 20204 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 17:42:41.756243 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.936579
I0916 17:42:41.756264 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.999998
I0916 17:42:41.756269 20216 solver.cpp:655]     Test net output #2: loss = 0.185516 (* 1 = 0.185516 loss)
I0916 17:42:41.756301 20216 solver.cpp:265] [MultiGPU] Tests completed in 12.2969s
I0916 17:42:41.941153 20216 solver.cpp:314] Iteration 12000 (3.06263 iter/s, 32.6517s/100 iter), loss = 0.0463821
I0916 17:42:41.941180 20216 solver.cpp:336]     Train net output #0: loss = 0.0463818 (* 1 = 0.0463818 loss)
I0916 17:42:41.941187 20216 sgd_solver.cpp:136] Iteration 12000, lr = 0.01, m = 0.9
I0916 17:43:01.831161 20216 solver.cpp:314] Iteration 12100 (5.02779 iter/s, 19.8894s/100 iter), loss = 0.11638
I0916 17:43:01.831187 20216 solver.cpp:336]     Train net output #0: loss = 0.11638 (* 1 = 0.11638 loss)
I0916 17:43:01.831193 20216 sgd_solver.cpp:136] Iteration 12100, lr = 0.01, m = 0.9
I0916 17:43:22.169139 20216 solver.cpp:314] Iteration 12200 (4.91705 iter/s, 20.3374s/100 iter), loss = 0.0677313
I0916 17:43:22.169240 20216 solver.cpp:336]     Train net output #0: loss = 0.0677309 (* 1 = 0.0677309 loss)
I0916 17:43:22.169248 20216 sgd_solver.cpp:136] Iteration 12200, lr = 0.01, m = 0.9
I0916 17:43:27.700543 20197 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 17:43:42.312300 20216 solver.cpp:314] Iteration 12300 (4.9646 iter/s, 20.1426s/100 iter), loss = 0.0661459
I0916 17:43:42.312325 20216 solver.cpp:336]     Train net output #0: loss = 0.0661456 (* 1 = 0.0661456 loss)
I0916 17:43:42.312330 20216 sgd_solver.cpp:136] Iteration 12300, lr = 0.01, m = 0.9
I0916 17:44:01.016595 20220 data_reader.cpp:305] Starting prefetch of epoch 10
I0916 17:44:02.552428 20216 solver.cpp:314] Iteration 12400 (4.94082 iter/s, 20.2396s/100 iter), loss = 0.0682469
I0916 17:44:02.552453 20216 solver.cpp:336]     Train net output #0: loss = 0.0682465 (* 1 = 0.0682465 loss)
I0916 17:44:02.552459 20216 sgd_solver.cpp:136] Iteration 12400, lr = 0.01, m = 0.9
I0916 17:44:22.343866 20216 solver.cpp:314] Iteration 12500 (5.05283 iter/s, 19.7909s/100 iter), loss = 0.0870621
I0916 17:44:22.343891 20216 solver.cpp:336]     Train net output #0: loss = 0.0870617 (* 1 = 0.0870617 loss)
I0916 17:44:22.343896 20216 sgd_solver.cpp:136] Iteration 12500, lr = 0.01, m = 0.9
I0916 17:44:41.771278 20216 solver.cpp:314] Iteration 12600 (5.14751 iter/s, 19.4269s/100 iter), loss = 0.0512303
I0916 17:44:41.771327 20216 solver.cpp:336]     Train net output #0: loss = 0.0512299 (* 1 = 0.0512299 loss)
I0916 17:44:41.771334 20216 sgd_solver.cpp:136] Iteration 12600, lr = 0.01, m = 0.9
I0916 17:45:01.452935 20216 solver.cpp:314] Iteration 12700 (5.08102 iter/s, 19.6811s/100 iter), loss = 0.191793
I0916 17:45:01.452963 20216 solver.cpp:336]     Train net output #0: loss = 0.191793 (* 1 = 0.191793 loss)
I0916 17:45:01.452968 20216 sgd_solver.cpp:136] Iteration 12700, lr = 0.01, m = 0.9
I0916 17:45:06.041791 20220 data_reader.cpp:305] Starting prefetch of epoch 11
I0916 17:45:20.786303 20216 solver.cpp:314] Iteration 12800 (5.17255 iter/s, 19.3328s/100 iter), loss = 0.0614057
I0916 17:45:20.786352 20216 solver.cpp:336]     Train net output #0: loss = 0.0614054 (* 1 = 0.0614054 loss)
I0916 17:45:20.786357 20216 sgd_solver.cpp:136] Iteration 12800, lr = 0.01, m = 0.9
I0916 17:45:40.452123 20216 solver.cpp:314] Iteration 12900 (5.08511 iter/s, 19.6653s/100 iter), loss = 0.0780624
I0916 17:45:40.452153 20216 solver.cpp:336]     Train net output #0: loss = 0.078062 (* 1 = 0.078062 loss)
I0916 17:45:40.452160 20216 sgd_solver.cpp:136] Iteration 12900, lr = 0.01, m = 0.9
I0916 17:46:00.072892 20216 solver.cpp:314] Iteration 13000 (5.09678 iter/s, 19.6202s/100 iter), loss = 0.0569269
I0916 17:46:00.072978 20216 solver.cpp:336]     Train net output #0: loss = 0.0569265 (* 1 = 0.0569265 loss)
I0916 17:46:00.072986 20216 sgd_solver.cpp:136] Iteration 13000, lr = 0.01, m = 0.9
I0916 17:46:10.428333 20197 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 17:46:19.561451 20216 solver.cpp:314] Iteration 13100 (5.13136 iter/s, 19.488s/100 iter), loss = 0.101684
I0916 17:46:19.561473 20216 solver.cpp:336]     Train net output #0: loss = 0.101684 (* 1 = 0.101684 loss)
I0916 17:46:19.561477 20216 sgd_solver.cpp:136] Iteration 13100, lr = 0.01, m = 0.9
I0916 17:46:39.161173 20216 solver.cpp:314] Iteration 13200 (5.10226 iter/s, 19.5992s/100 iter), loss = 0.0530747
I0916 17:46:39.161228 20216 solver.cpp:336]     Train net output #0: loss = 0.0530743 (* 1 = 0.0530743 loss)
I0916 17:46:39.161234 20216 sgd_solver.cpp:136] Iteration 13200, lr = 0.01, m = 0.9
I0916 17:46:42.866981 20219 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 17:46:58.484273 20216 solver.cpp:314] Iteration 13300 (5.1753 iter/s, 19.3226s/100 iter), loss = 0.0669893
I0916 17:46:58.484300 20216 solver.cpp:336]     Train net output #0: loss = 0.0669889 (* 1 = 0.0669889 loss)
I0916 17:46:58.484307 20216 sgd_solver.cpp:136] Iteration 13300, lr = 0.01, m = 0.9
I0916 17:47:18.417423 20216 solver.cpp:314] Iteration 13400 (5.01691 iter/s, 19.9326s/100 iter), loss = 0.0647814
I0916 17:47:18.417508 20216 solver.cpp:336]     Train net output #0: loss = 0.0647811 (* 1 = 0.0647811 loss)
I0916 17:47:18.417515 20216 sgd_solver.cpp:136] Iteration 13400, lr = 0.01, m = 0.9
I0916 17:47:38.025936 20216 solver.cpp:314] Iteration 13500 (5.09997 iter/s, 19.608s/100 iter), loss = 0.0973614
I0916 17:47:38.025959 20216 solver.cpp:336]     Train net output #0: loss = 0.097361 (* 1 = 0.097361 loss)
I0916 17:47:38.025962 20216 sgd_solver.cpp:136] Iteration 13500, lr = 0.01, m = 0.9
I0916 17:47:47.592839 20219 data_reader.cpp:305] Starting prefetch of epoch 10
I0916 17:47:57.530673 20216 solver.cpp:314] Iteration 13600 (5.1271 iter/s, 19.5042s/100 iter), loss = 0.0779749
I0916 17:47:57.530724 20216 solver.cpp:336]     Train net output #0: loss = 0.0779746 (* 1 = 0.0779746 loss)
I0916 17:47:57.530730 20216 sgd_solver.cpp:136] Iteration 13600, lr = 0.01, m = 0.9
I0916 17:48:16.975174 20216 solver.cpp:314] Iteration 13700 (5.14299 iter/s, 19.444s/100 iter), loss = 0.0591573
I0916 17:48:16.975196 20216 solver.cpp:336]     Train net output #0: loss = 0.0591569 (* 1 = 0.0591569 loss)
I0916 17:48:16.975203 20216 sgd_solver.cpp:136] Iteration 13700, lr = 0.01, m = 0.9
I0916 17:48:36.692287 20216 solver.cpp:314] Iteration 13800 (5.07188 iter/s, 19.7166s/100 iter), loss = 0.0857937
I0916 17:48:36.692342 20216 solver.cpp:336]     Train net output #0: loss = 0.0857933 (* 1 = 0.0857933 loss)
I0916 17:48:36.692348 20216 sgd_solver.cpp:136] Iteration 13800, lr = 0.01, m = 0.9
I0916 17:48:52.209857 20223 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 17:48:56.142163 20216 solver.cpp:314] Iteration 13900 (5.14156 iter/s, 19.4493s/100 iter), loss = 0.0892602
I0916 17:48:56.142186 20216 solver.cpp:336]     Train net output #0: loss = 0.0892599 (* 1 = 0.0892599 loss)
I0916 17:48:56.142194 20216 sgd_solver.cpp:136] Iteration 13900, lr = 0.01, m = 0.9
I0916 17:49:15.851693 20216 solver.cpp:563] Iteration 14000, Testing net (#0)
I0916 17:49:23.648319 20202 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 17:49:27.864349 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.946475
I0916 17:49:27.864370 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 17:49:27.864377 20216 solver.cpp:655]     Test net output #2: loss = 0.165586 (* 1 = 0.165586 loss)
I0916 17:49:27.864405 20216 solver.cpp:265] [MultiGPU] Tests completed in 12.0124s
I0916 17:49:28.079048 20216 solver.cpp:314] Iteration 14000 (3.13126 iter/s, 31.936s/100 iter), loss = 0.114693
I0916 17:49:28.079087 20216 solver.cpp:336]     Train net output #0: loss = 0.114693 (* 1 = 0.114693 loss)
I0916 17:49:28.079094 20216 sgd_solver.cpp:136] Iteration 14000, lr = 0.01, m = 0.9
I0916 17:49:48.091027 20216 solver.cpp:314] Iteration 14100 (4.99715 iter/s, 20.0114s/100 iter), loss = 0.104047
I0916 17:49:48.091087 20216 solver.cpp:336]     Train net output #0: loss = 0.104047 (* 1 = 0.104047 loss)
I0916 17:49:48.091095 20216 sgd_solver.cpp:136] Iteration 14100, lr = 0.01, m = 0.9
I0916 17:50:07.922500 20216 solver.cpp:314] Iteration 14200 (5.04263 iter/s, 19.8309s/100 iter), loss = 0.0734515
I0916 17:50:07.922549 20216 solver.cpp:336]     Train net output #0: loss = 0.0734512 (* 1 = 0.0734512 loss)
I0916 17:50:07.922564 20216 sgd_solver.cpp:136] Iteration 14200, lr = 0.01, m = 0.9
I0916 17:50:09.894647 20195 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 17:50:27.788020 20216 solver.cpp:314] Iteration 14300 (5.03399 iter/s, 19.865s/100 iter), loss = 0.0918481
I0916 17:50:27.788076 20216 solver.cpp:336]     Train net output #0: loss = 0.0918477 (* 1 = 0.0918477 loss)
I0916 17:50:27.788084 20216 sgd_solver.cpp:136] Iteration 14300, lr = 0.01, m = 0.9
I0916 17:50:47.966452 20216 solver.cpp:314] Iteration 14400 (4.95592 iter/s, 20.1779s/100 iter), loss = 0.0830364
I0916 17:50:47.966480 20216 solver.cpp:336]     Train net output #0: loss = 0.0830361 (* 1 = 0.0830361 loss)
I0916 17:50:47.966486 20216 sgd_solver.cpp:136] Iteration 14400, lr = 0.01, m = 0.9
I0916 17:51:08.094210 20216 solver.cpp:314] Iteration 14500 (4.9684 iter/s, 20.1272s/100 iter), loss = 0.0892277
I0916 17:51:08.094305 20216 solver.cpp:336]     Train net output #0: loss = 0.0892274 (* 1 = 0.0892274 loss)
I0916 17:51:08.094321 20216 sgd_solver.cpp:136] Iteration 14500, lr = 0.01, m = 0.9
I0916 17:51:16.211709 20224 data_reader.cpp:305] Starting prefetch of epoch 10
I0916 17:51:27.983129 20216 solver.cpp:314] Iteration 14600 (5.02807 iter/s, 19.8884s/100 iter), loss = 0.0817998
I0916 17:51:27.983151 20216 solver.cpp:336]     Train net output #0: loss = 0.0817995 (* 1 = 0.0817995 loss)
I0916 17:51:27.983155 20216 sgd_solver.cpp:136] Iteration 14600, lr = 0.01, m = 0.9
I0916 17:51:48.108212 20216 solver.cpp:314] Iteration 14700 (4.96906 iter/s, 20.1245s/100 iter), loss = 0.0899649
I0916 17:51:48.108297 20216 solver.cpp:336]     Train net output #0: loss = 0.0899646 (* 1 = 0.0899646 loss)
I0916 17:51:48.108311 20216 sgd_solver.cpp:136] Iteration 14700, lr = 0.01, m = 0.9
I0916 17:51:49.359139 20219 data_reader.cpp:305] Starting prefetch of epoch 11
I0916 17:52:08.118484 20216 solver.cpp:314] Iteration 14800 (4.99757 iter/s, 20.0097s/100 iter), loss = 0.0671742
I0916 17:52:08.118517 20216 solver.cpp:336]     Train net output #0: loss = 0.067174 (* 1 = 0.067174 loss)
I0916 17:52:08.118523 20216 sgd_solver.cpp:136] Iteration 14800, lr = 0.01, m = 0.9
I0916 17:52:27.968421 20216 solver.cpp:314] Iteration 14900 (5.03794 iter/s, 19.8494s/100 iter), loss = 0.236483
I0916 17:52:27.968508 20216 solver.cpp:336]     Train net output #0: loss = 0.236483 (* 1 = 0.236483 loss)
I0916 17:52:27.968516 20216 sgd_solver.cpp:136] Iteration 14900, lr = 0.01, m = 0.9
I0916 17:52:47.826380 20216 solver.cpp:314] Iteration 15000 (5.03591 iter/s, 19.8574s/100 iter), loss = 0.0892772
I0916 17:52:47.826407 20216 solver.cpp:336]     Train net output #0: loss = 0.089277 (* 1 = 0.089277 loss)
I0916 17:52:47.826414 20216 sgd_solver.cpp:136] Iteration 15000, lr = 0.01, m = 0.9
I0916 17:52:55.056923 20220 data_reader.cpp:305] Starting prefetch of epoch 12
I0916 17:53:07.334544 20216 solver.cpp:314] Iteration 15100 (5.1262 iter/s, 19.5076s/100 iter), loss = 0.142289
I0916 17:53:07.334599 20216 solver.cpp:336]     Train net output #0: loss = 0.142289 (* 1 = 0.142289 loss)
I0916 17:53:07.334605 20216 sgd_solver.cpp:136] Iteration 15100, lr = 0.01, m = 0.9
I0916 17:53:26.745555 20216 solver.cpp:314] Iteration 15200 (5.15226 iter/s, 19.409s/100 iter), loss = 0.0876849
I0916 17:53:26.745640 20216 solver.cpp:336]     Train net output #0: loss = 0.0876847 (* 1 = 0.0876847 loss)
I0916 17:53:26.745661 20216 sgd_solver.cpp:136] Iteration 15200, lr = 0.01, m = 0.9
I0916 17:53:46.069818 20216 solver.cpp:314] Iteration 15300 (5.17499 iter/s, 19.3237s/100 iter), loss = 0.0466966
I0916 17:53:46.069871 20216 solver.cpp:336]     Train net output #0: loss = 0.0466964 (* 1 = 0.0466964 loss)
I0916 17:53:46.069876 20216 sgd_solver.cpp:136] Iteration 15300, lr = 0.01, m = 0.9
I0916 17:53:59.199497 20224 data_reader.cpp:305] Starting prefetch of epoch 11
I0916 17:54:05.505010 20216 solver.cpp:314] Iteration 15400 (5.14545 iter/s, 19.4346s/100 iter), loss = 0.0750829
I0916 17:54:05.505034 20216 solver.cpp:336]     Train net output #0: loss = 0.0750826 (* 1 = 0.0750826 loss)
I0916 17:54:05.505039 20216 sgd_solver.cpp:136] Iteration 15400, lr = 0.01, m = 0.9
I0916 17:54:25.009024 20216 solver.cpp:314] Iteration 15500 (5.12729 iter/s, 19.5035s/100 iter), loss = 0.0756028
I0916 17:54:25.009083 20216 solver.cpp:336]     Train net output #0: loss = 0.0756026 (* 1 = 0.0756026 loss)
I0916 17:54:25.009089 20216 sgd_solver.cpp:136] Iteration 15500, lr = 0.01, m = 0.9
I0916 17:54:31.472761 20195 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 17:54:44.309609 20216 solver.cpp:314] Iteration 15600 (5.18133 iter/s, 19.3s/100 iter), loss = 0.0676534
I0916 17:54:44.309630 20216 solver.cpp:336]     Train net output #0: loss = 0.0676532 (* 1 = 0.0676532 loss)
I0916 17:54:44.309635 20216 sgd_solver.cpp:136] Iteration 15600, lr = 0.01, m = 0.9
I0916 17:55:03.709817 20216 solver.cpp:314] Iteration 15700 (5.15473 iter/s, 19.3997s/100 iter), loss = 0.101651
I0916 17:55:03.709892 20216 solver.cpp:336]     Train net output #0: loss = 0.10165 (* 1 = 0.10165 loss)
I0916 17:55:03.709897 20216 sgd_solver.cpp:136] Iteration 15700, lr = 0.01, m = 0.9
I0916 17:55:23.206876 20216 solver.cpp:314] Iteration 15800 (5.12912 iter/s, 19.4965s/100 iter), loss = 0.0815011
I0916 17:55:23.206902 20216 solver.cpp:336]     Train net output #0: loss = 0.0815009 (* 1 = 0.0815009 loss)
I0916 17:55:23.206907 20216 sgd_solver.cpp:136] Iteration 15800, lr = 0.01, m = 0.9
I0916 17:55:35.598996 20219 data_reader.cpp:305] Starting prefetch of epoch 12
I0916 17:55:42.750195 20216 solver.cpp:314] Iteration 15900 (5.11698 iter/s, 19.5428s/100 iter), loss = 0.0510579
I0916 17:55:42.750222 20216 solver.cpp:336]     Train net output #0: loss = 0.0510576 (* 1 = 0.0510576 loss)
I0916 17:55:42.750229 20216 sgd_solver.cpp:136] Iteration 15900, lr = 0.01, m = 0.9
I0916 17:56:02.018666 20216 solver.cpp:563] Iteration 16000, Testing net (#0)
I0916 17:56:12.290490 20248 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 17:56:12.810972 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.945786
I0916 17:56:12.810993 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 17:56:12.810998 20216 solver.cpp:655]     Test net output #2: loss = 0.177928 (* 1 = 0.177928 loss)
I0916 17:56:12.811079 20216 solver.cpp:265] [MultiGPU] Tests completed in 10.7921s
I0916 17:56:13.035038 20216 solver.cpp:314] Iteration 16000 (3.30207 iter/s, 30.284s/100 iter), loss = 0.087145
I0916 17:56:13.035063 20216 solver.cpp:336]     Train net output #0: loss = 0.0871447 (* 1 = 0.0871447 loss)
I0916 17:56:13.035068 20216 sgd_solver.cpp:136] Iteration 16000, lr = 0.01, m = 0.9
I0916 17:56:18.509675 20195 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 17:56:32.359614 20216 solver.cpp:314] Iteration 16100 (5.1749 iter/s, 19.324s/100 iter), loss = 0.102278
I0916 17:56:32.359642 20216 solver.cpp:336]     Train net output #0: loss = 0.102278 (* 1 = 0.102278 loss)
I0916 17:56:32.359649 20216 sgd_solver.cpp:136] Iteration 16100, lr = 0.01, m = 0.9
I0916 17:56:51.831537 20216 solver.cpp:314] Iteration 16200 (5.13575 iter/s, 19.4714s/100 iter), loss = 0.125623
I0916 17:56:51.831589 20216 solver.cpp:336]     Train net output #0: loss = 0.125622 (* 1 = 0.125622 loss)
I0916 17:56:51.831596 20216 sgd_solver.cpp:136] Iteration 16200, lr = 0.01, m = 0.9
I0916 17:57:11.104058 20216 solver.cpp:314] Iteration 16300 (5.18888 iter/s, 19.272s/100 iter), loss = 0.068096
I0916 17:57:11.104079 20216 solver.cpp:336]     Train net output #0: loss = 0.0680959 (* 1 = 0.0680959 loss)
I0916 17:57:11.104084 20216 sgd_solver.cpp:136] Iteration 16300, lr = 0.01, m = 0.9
I0916 17:57:22.624392 20195 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 17:57:30.429483 20216 solver.cpp:314] Iteration 16400 (5.17468 iter/s, 19.3249s/100 iter), loss = 0.065664
I0916 17:57:30.429513 20216 solver.cpp:336]     Train net output #0: loss = 0.0656639 (* 1 = 0.0656639 loss)
I0916 17:57:30.429520 20216 sgd_solver.cpp:136] Iteration 16400, lr = 0.01, m = 0.9
I0916 17:57:49.970305 20216 solver.cpp:314] Iteration 16500 (5.11764 iter/s, 19.5403s/100 iter), loss = 0.0735381
I0916 17:57:49.970331 20216 solver.cpp:336]     Train net output #0: loss = 0.0735379 (* 1 = 0.0735379 loss)
I0916 17:57:49.970335 20216 sgd_solver.cpp:136] Iteration 16500, lr = 0.01, m = 0.9
I0916 17:58:09.599433 20216 solver.cpp:314] Iteration 16600 (5.09461 iter/s, 19.6286s/100 iter), loss = 0.0760547
I0916 17:58:09.599510 20216 solver.cpp:336]     Train net output #0: loss = 0.0760545 (* 1 = 0.0760545 loss)
I0916 17:58:09.599519 20216 sgd_solver.cpp:136] Iteration 16600, lr = 0.01, m = 0.9
I0916 17:58:27.047715 20219 data_reader.cpp:305] Starting prefetch of epoch 13
I0916 17:58:29.076601 20216 solver.cpp:314] Iteration 16700 (5.13436 iter/s, 19.4766s/100 iter), loss = 0.19043
I0916 17:58:29.076650 20216 solver.cpp:336]     Train net output #0: loss = 0.19043 (* 1 = 0.19043 loss)
I0916 17:58:29.076663 20216 sgd_solver.cpp:136] Iteration 16700, lr = 0.01, m = 0.9
I0916 17:58:49.168865 20216 solver.cpp:314] Iteration 16800 (4.97718 iter/s, 20.0917s/100 iter), loss = 0.134322
I0916 17:58:49.168937 20216 solver.cpp:336]     Train net output #0: loss = 0.134322 (* 1 = 0.134322 loss)
I0916 17:58:49.168946 20216 sgd_solver.cpp:136] Iteration 16800, lr = 0.01, m = 0.9
I0916 17:59:09.435042 20216 solver.cpp:314] Iteration 16900 (4.93447 iter/s, 20.2656s/100 iter), loss = 0.0690393
I0916 17:59:09.435075 20216 solver.cpp:336]     Train net output #0: loss = 0.0690392 (* 1 = 0.0690392 loss)
I0916 17:59:09.435081 20216 sgd_solver.cpp:136] Iteration 16900, lr = 0.01, m = 0.9
I0916 17:59:29.441757 20216 solver.cpp:314] Iteration 17000 (4.99846 iter/s, 20.0062s/100 iter), loss = 0.137397
I0916 17:59:29.441884 20216 solver.cpp:336]     Train net output #0: loss = 0.137397 (* 1 = 0.137397 loss)
I0916 17:59:29.441892 20216 sgd_solver.cpp:136] Iteration 17000, lr = 0.01, m = 0.9
I0916 17:59:33.496917 20224 data_reader.cpp:305] Starting prefetch of epoch 12
I0916 17:59:49.373986 20216 solver.cpp:314] Iteration 17100 (5.01714 iter/s, 19.9317s/100 iter), loss = 0.0753106
I0916 17:59:49.374012 20216 solver.cpp:336]     Train net output #0: loss = 0.0753104 (* 1 = 0.0753104 loss)
I0916 17:59:49.374018 20216 sgd_solver.cpp:136] Iteration 17100, lr = 0.01, m = 0.9
I0916 18:00:06.620605 20219 data_reader.cpp:305] Starting prefetch of epoch 14
I0916 18:00:09.596313 20216 solver.cpp:314] Iteration 17200 (4.94517 iter/s, 20.2218s/100 iter), loss = 0.086843
I0916 18:00:09.596340 20216 solver.cpp:336]     Train net output #0: loss = 0.0868429 (* 1 = 0.0868429 loss)
I0916 18:00:09.596345 20216 sgd_solver.cpp:136] Iteration 17200, lr = 0.01, m = 0.9
I0916 18:00:29.745640 20216 solver.cpp:314] Iteration 17300 (4.96309 iter/s, 20.1488s/100 iter), loss = 0.078741
I0916 18:00:29.745697 20216 solver.cpp:336]     Train net output #0: loss = 0.0787408 (* 1 = 0.0787408 loss)
I0916 18:00:29.745724 20216 sgd_solver.cpp:136] Iteration 17300, lr = 0.01, m = 0.9
I0916 18:00:49.871052 20216 solver.cpp:314] Iteration 17400 (4.96898 iter/s, 20.1248s/100 iter), loss = 0.0529712
I0916 18:00:49.871106 20216 solver.cpp:336]     Train net output #0: loss = 0.052971 (* 1 = 0.052971 loss)
I0916 18:00:49.871117 20216 sgd_solver.cpp:136] Iteration 17400, lr = 0.01, m = 0.9
I0916 18:01:10.059880 20216 solver.cpp:314] Iteration 17500 (4.95337 iter/s, 20.1883s/100 iter), loss = 0.063841
I0916 18:01:10.059906 20216 solver.cpp:336]     Train net output #0: loss = 0.0638409 (* 1 = 0.0638409 loss)
I0916 18:01:10.059913 20216 sgd_solver.cpp:136] Iteration 17500, lr = 0.01, m = 0.9
I0916 18:01:13.318928 20195 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 18:01:30.453135 20216 solver.cpp:314] Iteration 17600 (4.90372 iter/s, 20.3927s/100 iter), loss = 0.0858521
I0916 18:01:30.453219 20216 solver.cpp:336]     Train net output #0: loss = 0.0858519 (* 1 = 0.0858519 loss)
I0916 18:01:30.453227 20216 sgd_solver.cpp:136] Iteration 17600, lr = 0.01, m = 0.9
I0916 18:01:50.430434 20216 solver.cpp:314] Iteration 17700 (5.00582 iter/s, 19.9767s/100 iter), loss = 0.0707769
I0916 18:01:50.430464 20216 solver.cpp:336]     Train net output #0: loss = 0.0707767 (* 1 = 0.0707767 loss)
I0916 18:01:50.430470 20216 sgd_solver.cpp:136] Iteration 17700, lr = 0.01, m = 0.9
I0916 18:02:10.249703 20216 solver.cpp:314] Iteration 17800 (5.04574 iter/s, 19.8187s/100 iter), loss = 0.0787063
I0916 18:02:10.249824 20216 solver.cpp:336]     Train net output #0: loss = 0.0787062 (* 1 = 0.0787062 loss)
I0916 18:02:10.249830 20216 sgd_solver.cpp:136] Iteration 17800, lr = 0.01, m = 0.9
I0916 18:02:19.606284 20223 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 18:02:30.306793 20216 solver.cpp:314] Iteration 17900 (4.98591 iter/s, 20.0565s/100 iter), loss = 0.0890306
I0916 18:02:30.306823 20216 solver.cpp:336]     Train net output #0: loss = 0.0890304 (* 1 = 0.0890304 loss)
I0916 18:02:30.306829 20216 sgd_solver.cpp:136] Iteration 17900, lr = 0.01, m = 0.9
I0916 18:02:50.170586 20216 solver.cpp:563] Iteration 18000, Testing net (#0)
I0916 18:02:57.594008 20202 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 18:03:01.805646 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.941738
I0916 18:03:01.805670 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 18:03:01.805676 20216 solver.cpp:655]     Test net output #2: loss = 0.197965 (* 1 = 0.197965 loss)
I0916 18:03:01.805704 20216 solver.cpp:265] [MultiGPU] Tests completed in 11.6348s
I0916 18:03:02.016052 20216 solver.cpp:314] Iteration 18000 (3.15374 iter/s, 31.7084s/100 iter), loss = 0.141896
I0916 18:03:02.016077 20216 solver.cpp:336]     Train net output #0: loss = 0.141896 (* 1 = 0.141896 loss)
I0916 18:03:02.016083 20216 sgd_solver.cpp:136] Iteration 18000, lr = 0.01, m = 0.9
I0916 18:03:21.803602 20216 solver.cpp:314] Iteration 18100 (5.05383 iter/s, 19.787s/100 iter), loss = 0.0748648
I0916 18:03:21.803653 20216 solver.cpp:336]     Train net output #0: loss = 0.0748647 (* 1 = 0.0748647 loss)
I0916 18:03:21.803658 20216 sgd_solver.cpp:136] Iteration 18100, lr = 0.01, m = 0.9
I0916 18:03:37.230576 20220 data_reader.cpp:305] Starting prefetch of epoch 13
I0916 18:03:41.851393 20216 solver.cpp:314] Iteration 18200 (4.98822 iter/s, 20.0472s/100 iter), loss = 0.0710703
I0916 18:03:41.851419 20216 solver.cpp:336]     Train net output #0: loss = 0.0710701 (* 1 = 0.0710701 loss)
I0916 18:03:41.851425 20216 sgd_solver.cpp:136] Iteration 18200, lr = 0.01, m = 0.9
I0916 18:04:02.095932 20216 solver.cpp:314] Iteration 18300 (4.93974 iter/s, 20.244s/100 iter), loss = 0.104358
I0916 18:04:02.096012 20216 solver.cpp:336]     Train net output #0: loss = 0.104358 (* 1 = 0.104358 loss)
I0916 18:04:02.096019 20216 sgd_solver.cpp:136] Iteration 18300, lr = 0.01, m = 0.9
I0916 18:04:21.789393 20216 solver.cpp:314] Iteration 18400 (5.07797 iter/s, 19.6929s/100 iter), loss = 0.0708261
I0916 18:04:21.789422 20216 solver.cpp:336]     Train net output #0: loss = 0.0708259 (* 1 = 0.0708259 loss)
I0916 18:04:21.789427 20216 sgd_solver.cpp:136] Iteration 18400, lr = 0.01, m = 0.9
I0916 18:04:41.784521 20216 solver.cpp:314] Iteration 18500 (5.00136 iter/s, 19.9946s/100 iter), loss = 0.098051
I0916 18:04:41.784580 20216 solver.cpp:336]     Train net output #0: loss = 0.0980508 (* 1 = 0.0980508 loss)
I0916 18:04:41.784587 20216 sgd_solver.cpp:136] Iteration 18500, lr = 0.01, m = 0.9
I0916 18:04:43.398036 20224 data_reader.cpp:305] Starting prefetch of epoch 13
I0916 18:05:01.721658 20216 solver.cpp:314] Iteration 18600 (5.01591 iter/s, 19.9366s/100 iter), loss = 0.101695
I0916 18:05:01.721683 20216 solver.cpp:336]     Train net output #0: loss = 0.101695 (* 1 = 0.101695 loss)
I0916 18:05:01.721688 20216 sgd_solver.cpp:136] Iteration 18600, lr = 0.01, m = 0.9
I0916 18:05:16.344594 20195 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 18:05:21.567337 20216 solver.cpp:314] Iteration 18700 (5.03902 iter/s, 19.8451s/100 iter), loss = 0.0514444
I0916 18:05:21.567438 20216 solver.cpp:336]     Train net output #0: loss = 0.0514443 (* 1 = 0.0514443 loss)
I0916 18:05:21.567477 20216 sgd_solver.cpp:136] Iteration 18700, lr = 0.01, m = 0.9
I0916 18:05:41.452039 20216 solver.cpp:314] Iteration 18800 (5.02913 iter/s, 19.8841s/100 iter), loss = 0.240441
I0916 18:05:41.452065 20216 solver.cpp:336]     Train net output #0: loss = 0.24044 (* 1 = 0.24044 loss)
I0916 18:05:41.452071 20216 sgd_solver.cpp:136] Iteration 18800, lr = 0.01, m = 0.9
I0916 18:06:01.422524 20216 solver.cpp:314] Iteration 18900 (5.00753 iter/s, 19.9699s/100 iter), loss = 0.083131
I0916 18:06:01.422621 20216 solver.cpp:336]     Train net output #0: loss = 0.0831308 (* 1 = 0.0831308 loss)
I0916 18:06:01.422638 20216 sgd_solver.cpp:136] Iteration 18900, lr = 0.01, m = 0.9
I0916 18:06:22.117764 20216 solver.cpp:314] Iteration 19000 (4.83216 iter/s, 20.6947s/100 iter), loss = 0.178727
I0916 18:06:22.117785 20216 solver.cpp:336]     Train net output #0: loss = 0.178727 (* 1 = 0.178727 loss)
I0916 18:06:22.117790 20216 sgd_solver.cpp:136] Iteration 19000, lr = 0.01, m = 0.9
I0916 18:06:22.741112 20219 data_reader.cpp:305] Starting prefetch of epoch 15
I0916 18:06:41.967100 20216 solver.cpp:314] Iteration 19100 (5.03809 iter/s, 19.8488s/100 iter), loss = 0.0592058
I0916 18:06:41.967166 20216 solver.cpp:336]     Train net output #0: loss = 0.0592057 (* 1 = 0.0592057 loss)
I0916 18:06:41.967173 20216 sgd_solver.cpp:136] Iteration 19100, lr = 0.01, m = 0.9
I0916 18:07:02.281898 20216 solver.cpp:314] Iteration 19200 (4.92266 iter/s, 20.3142s/100 iter), loss = 0.105693
I0916 18:07:02.281921 20216 solver.cpp:336]     Train net output #0: loss = 0.105693 (* 1 = 0.105693 loss)
I0916 18:07:02.281927 20216 sgd_solver.cpp:136] Iteration 19200, lr = 0.01, m = 0.9
I0916 18:07:21.748831 20216 solver.cpp:314] Iteration 19300 (5.13706 iter/s, 19.4664s/100 iter), loss = 0.0943788
I0916 18:07:21.748913 20216 solver.cpp:336]     Train net output #0: loss = 0.0943786 (* 1 = 0.0943786 loss)
I0916 18:07:21.748920 20216 sgd_solver.cpp:136] Iteration 19300, lr = 0.01, m = 0.9
I0916 18:07:28.375494 20197 data_reader.cpp:305] Starting prefetch of epoch 10
I0916 18:07:41.021060 20216 solver.cpp:314] Iteration 19400 (5.18896 iter/s, 19.2717s/100 iter), loss = 0.114119
I0916 18:07:41.021091 20216 solver.cpp:336]     Train net output #0: loss = 0.114119 (* 1 = 0.114119 loss)
I0916 18:07:41.021097 20216 sgd_solver.cpp:136] Iteration 19400, lr = 0.01, m = 0.9
I0916 18:08:00.363957 20220 data_reader.cpp:305] Starting prefetch of epoch 14
I0916 18:08:00.512583 20216 solver.cpp:314] Iteration 19500 (5.13058 iter/s, 19.491s/100 iter), loss = 0.0747218
I0916 18:08:00.512609 20216 solver.cpp:336]     Train net output #0: loss = 0.0747217 (* 1 = 0.0747217 loss)
I0916 18:08:00.512615 20216 sgd_solver.cpp:136] Iteration 19500, lr = 0.01, m = 0.9
I0916 18:08:19.957547 20216 solver.cpp:314] Iteration 19600 (5.14286 iter/s, 19.4444s/100 iter), loss = 0.0742194
I0916 18:08:19.957578 20216 solver.cpp:336]     Train net output #0: loss = 0.0742193 (* 1 = 0.0742193 loss)
I0916 18:08:19.957586 20216 sgd_solver.cpp:136] Iteration 19600, lr = 0.01, m = 0.9
I0916 18:08:39.606406 20216 solver.cpp:314] Iteration 19700 (5.0895 iter/s, 19.6483s/100 iter), loss = 0.711585
I0916 18:08:39.606515 20216 solver.cpp:336]     Train net output #0: loss = 0.711585 (* 1 = 0.711585 loss)
I0916 18:08:39.606526 20216 sgd_solver.cpp:136] Iteration 19700, lr = 0.01, m = 0.9
I0916 18:08:59.276347 20216 solver.cpp:314] Iteration 19800 (5.08404 iter/s, 19.6694s/100 iter), loss = 0.102435
I0916 18:08:59.276366 20216 solver.cpp:336]     Train net output #0: loss = 0.102434 (* 1 = 0.102434 loss)
I0916 18:08:59.276371 20216 sgd_solver.cpp:136] Iteration 19800, lr = 0.01, m = 0.9
I0916 18:09:05.020537 20219 data_reader.cpp:305] Starting prefetch of epoch 16
I0916 18:09:18.658861 20216 solver.cpp:314] Iteration 19900 (5.15943 iter/s, 19.382s/100 iter), loss = 0.0996114
I0916 18:09:18.658946 20216 solver.cpp:336]     Train net output #0: loss = 0.0996113 (* 1 = 0.0996113 loss)
I0916 18:09:18.658954 20216 sgd_solver.cpp:136] Iteration 19900, lr = 0.01, m = 0.9
I0916 18:09:37.973647 20216 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/cityscapes5_jsegnet21v2_iter_20000.caffemodel
I0916 18:09:37.997355 20216 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/cityscapes5_jsegnet21v2_iter_20000.solverstate
I0916 18:09:38.002852 20216 solver.cpp:563] Iteration 20000, Testing net (#0)
I0916 18:09:41.280521 20241 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 18:09:48.676574 20202 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 18:09:48.982574 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.931713
I0916 18:09:48.982595 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 18:09:48.982600 20216 solver.cpp:655]     Test net output #2: loss = 0.1935 (* 1 = 0.1935 loss)
I0916 18:09:48.982626 20216 solver.cpp:265] [MultiGPU] Tests completed in 10.9795s
I0916 18:09:49.207232 20216 solver.cpp:314] Iteration 20000 (3.27361 iter/s, 30.5473s/100 iter), loss = 0.0641762
I0916 18:09:49.207257 20216 solver.cpp:336]     Train net output #0: loss = 0.0641761 (* 1 = 0.0641761 loss)
I0916 18:09:49.207262 20216 sgd_solver.cpp:136] Iteration 20000, lr = 0.01, m = 0.9
I0916 18:10:08.559284 20216 solver.cpp:314] Iteration 20100 (5.16756 iter/s, 19.3515s/100 iter), loss = 0.057958
I0916 18:10:08.559317 20216 solver.cpp:336]     Train net output #0: loss = 0.0579579 (* 1 = 0.0579579 loss)
I0916 18:10:08.559324 20216 sgd_solver.cpp:136] Iteration 20100, lr = 0.01, m = 0.9
I0916 18:10:28.324395 20216 solver.cpp:314] Iteration 20200 (5.05956 iter/s, 19.7646s/100 iter), loss = 0.0993884
I0916 18:10:28.330124 20216 solver.cpp:336]     Train net output #0: loss = 0.0993884 (* 1 = 0.0993884 loss)
I0916 18:10:28.330152 20216 sgd_solver.cpp:136] Iteration 20200, lr = 0.01, m = 0.9
I0916 18:10:47.759388 20216 solver.cpp:314] Iteration 20300 (5.1455 iter/s, 19.4345s/100 iter), loss = 0.0702966
I0916 18:10:47.759414 20216 solver.cpp:336]     Train net output #0: loss = 0.0702965 (* 1 = 0.0702965 loss)
I0916 18:10:47.759419 20216 sgd_solver.cpp:136] Iteration 20300, lr = 0.01, m = 0.9
I0916 18:10:52.806346 20220 data_reader.cpp:305] Starting prefetch of epoch 15
I0916 18:11:07.220510 20216 solver.cpp:314] Iteration 20400 (5.13859 iter/s, 19.4606s/100 iter), loss = 0.0981854
I0916 18:11:07.220602 20216 solver.cpp:336]     Train net output #0: loss = 0.0981853 (* 1 = 0.0981853 loss)
I0916 18:11:07.220608 20216 sgd_solver.cpp:136] Iteration 20400, lr = 0.01, m = 0.9
I0916 18:11:26.640249 20216 solver.cpp:314] Iteration 20500 (5.14954 iter/s, 19.4192s/100 iter), loss = 0.0723137
I0916 18:11:26.640275 20216 solver.cpp:336]     Train net output #0: loss = 0.0723136 (* 1 = 0.0723136 loss)
I0916 18:11:26.640281 20216 sgd_solver.cpp:136] Iteration 20500, lr = 0.01, m = 0.9
I0916 18:11:46.132048 20216 solver.cpp:314] Iteration 20600 (5.13051 iter/s, 19.4913s/100 iter), loss = 0.0759239
I0916 18:11:46.132104 20216 solver.cpp:336]     Train net output #0: loss = 0.0759239 (* 1 = 0.0759239 loss)
I0916 18:11:46.132112 20216 sgd_solver.cpp:136] Iteration 20600, lr = 0.01, m = 0.9
I0916 18:11:57.073192 20224 data_reader.cpp:305] Starting prefetch of epoch 14
I0916 18:12:05.618557 20216 solver.cpp:314] Iteration 20700 (5.1319 iter/s, 19.486s/100 iter), loss = 0.0626716
I0916 18:12:05.618579 20216 solver.cpp:336]     Train net output #0: loss = 0.0626716 (* 1 = 0.0626716 loss)
I0916 18:12:05.618583 20216 sgd_solver.cpp:136] Iteration 20700, lr = 0.01, m = 0.9
I0916 18:12:24.921635 20216 solver.cpp:314] Iteration 20800 (5.18067 iter/s, 19.3025s/100 iter), loss = 0.0886055
I0916 18:12:24.921690 20216 solver.cpp:336]     Train net output #0: loss = 0.0886055 (* 1 = 0.0886055 loss)
I0916 18:12:24.921697 20216 sgd_solver.cpp:136] Iteration 20800, lr = 0.01, m = 0.9
I0916 18:12:44.434221 20216 solver.cpp:314] Iteration 20900 (5.12504 iter/s, 19.512s/100 iter), loss = 0.062091
I0916 18:12:44.434248 20216 solver.cpp:336]     Train net output #0: loss = 0.0620909 (* 1 = 0.0620909 loss)
I0916 18:12:44.434253 20216 sgd_solver.cpp:136] Iteration 20900, lr = 0.01, m = 0.9
I0916 18:13:01.186573 20223 data_reader.cpp:305] Starting prefetch of epoch 10
I0916 18:13:03.642938 20216 solver.cpp:314] Iteration 21000 (5.20612 iter/s, 19.2082s/100 iter), loss = 0.399974
I0916 18:13:03.642962 20216 solver.cpp:336]     Train net output #0: loss = 0.399974 (* 1 = 0.399974 loss)
I0916 18:13:03.642968 20216 sgd_solver.cpp:136] Iteration 21000, lr = 0.01, m = 0.9
I0916 18:13:22.966612 20216 solver.cpp:314] Iteration 21100 (5.17514 iter/s, 19.3231s/100 iter), loss = 0.0623929
I0916 18:13:22.966635 20216 solver.cpp:336]     Train net output #0: loss = 0.0623928 (* 1 = 0.0623928 loss)
I0916 18:13:22.966639 20216 sgd_solver.cpp:136] Iteration 21100, lr = 0.01, m = 0.9
I0916 18:13:33.085875 20220 data_reader.cpp:305] Starting prefetch of epoch 16
I0916 18:13:42.460515 20216 solver.cpp:314] Iteration 21200 (5.12995 iter/s, 19.4934s/100 iter), loss = 0.0981262
I0916 18:13:42.460541 20216 solver.cpp:336]     Train net output #0: loss = 0.0981261 (* 1 = 0.0981261 loss)
I0916 18:13:42.460546 20216 sgd_solver.cpp:136] Iteration 21200, lr = 0.01, m = 0.9
I0916 18:14:01.927284 20216 solver.cpp:314] Iteration 21300 (5.1371 iter/s, 19.4662s/100 iter), loss = 0.0898188
I0916 18:14:01.927309 20216 solver.cpp:336]     Train net output #0: loss = 0.0898188 (* 1 = 0.0898188 loss)
I0916 18:14:01.927314 20216 sgd_solver.cpp:136] Iteration 21300, lr = 0.01, m = 0.9
I0916 18:14:21.282480 20216 solver.cpp:314] Iteration 21400 (5.16672 iter/s, 19.3547s/100 iter), loss = 0.105858
I0916 18:14:21.282541 20216 solver.cpp:336]     Train net output #0: loss = 0.105858 (* 1 = 0.105858 loss)
I0916 18:14:21.282547 20216 sgd_solver.cpp:136] Iteration 21400, lr = 0.01, m = 0.9
I0916 18:14:37.476773 20220 data_reader.cpp:305] Starting prefetch of epoch 17
I0916 18:14:40.853727 20216 solver.cpp:314] Iteration 21500 (5.10968 iter/s, 19.5707s/100 iter), loss = 0.0940993
I0916 18:14:40.853754 20216 solver.cpp:336]     Train net output #0: loss = 0.0940992 (* 1 = 0.0940992 loss)
I0916 18:14:40.853760 20216 sgd_solver.cpp:136] Iteration 21500, lr = 0.01, m = 0.9
I0916 18:15:00.376976 20216 solver.cpp:314] Iteration 21600 (5.12224 iter/s, 19.5227s/100 iter), loss = 0.100378
I0916 18:15:00.377035 20216 solver.cpp:336]     Train net output #0: loss = 0.100378 (* 1 = 0.100378 loss)
I0916 18:15:00.377043 20216 sgd_solver.cpp:136] Iteration 21600, lr = 0.01, m = 0.9
I0916 18:15:19.909394 20216 solver.cpp:314] Iteration 21700 (5.11984 iter/s, 19.5319s/100 iter), loss = 0.0794934
I0916 18:15:19.909415 20216 solver.cpp:336]     Train net output #0: loss = 0.0794933 (* 1 = 0.0794933 loss)
I0916 18:15:19.909420 20216 sgd_solver.cpp:136] Iteration 21700, lr = 0.01, m = 0.9
I0916 18:15:39.420907 20216 solver.cpp:314] Iteration 21800 (5.12532 iter/s, 19.511s/100 iter), loss = 0.222141
I0916 18:15:39.420958 20216 solver.cpp:336]     Train net output #0: loss = 0.222141 (* 1 = 0.222141 loss)
I0916 18:15:39.420965 20216 sgd_solver.cpp:136] Iteration 21800, lr = 0.01, m = 0.9
I0916 18:15:41.874260 20224 data_reader.cpp:305] Starting prefetch of epoch 15
I0916 18:15:58.769665 20216 solver.cpp:314] Iteration 21900 (5.16844 iter/s, 19.3482s/100 iter), loss = 0.0791143
I0916 18:15:58.769690 20216 solver.cpp:336]     Train net output #0: loss = 0.0791143 (* 1 = 0.0791143 loss)
I0916 18:15:58.769696 20216 sgd_solver.cpp:136] Iteration 21900, lr = 0.01, m = 0.9
I0916 18:16:13.939558 20195 data_reader.cpp:305] Starting prefetch of epoch 10
I0916 18:16:17.951642 20216 solver.cpp:563] Iteration 22000, Testing net (#0)
I0916 18:16:28.625697 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.942431
I0916 18:16:28.625716 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 18:16:28.625723 20216 solver.cpp:655]     Test net output #2: loss = 0.167626 (* 1 = 0.167626 loss)
I0916 18:16:28.625749 20216 solver.cpp:265] [MultiGPU] Tests completed in 10.6738s
I0916 18:16:28.842542 20216 solver.cpp:314] Iteration 22000 (3.32535 iter/s, 30.072s/100 iter), loss = 0.0939352
I0916 18:16:28.842566 20216 solver.cpp:336]     Train net output #0: loss = 0.0939351 (* 1 = 0.0939351 loss)
I0916 18:16:28.842571 20216 sgd_solver.cpp:136] Iteration 22000, lr = 0.01, m = 0.9
I0916 18:16:48.059376 20216 solver.cpp:314] Iteration 22100 (5.20392 iter/s, 19.2163s/100 iter), loss = 0.0829897
I0916 18:16:48.059427 20216 solver.cpp:336]     Train net output #0: loss = 0.0829896 (* 1 = 0.0829896 loss)
I0916 18:16:48.059433 20216 sgd_solver.cpp:136] Iteration 22100, lr = 0.01, m = 0.9
I0916 18:16:56.499188 20223 data_reader.cpp:305] Starting prefetch of epoch 11
I0916 18:17:07.138917 20216 solver.cpp:314] Iteration 22200 (5.24136 iter/s, 19.079s/100 iter), loss = 0.0744715
I0916 18:17:07.138939 20216 solver.cpp:336]     Train net output #0: loss = 0.0744714 (* 1 = 0.0744714 loss)
I0916 18:17:07.138943 20216 sgd_solver.cpp:136] Iteration 22200, lr = 0.01, m = 0.9
I0916 18:17:26.534307 20216 solver.cpp:314] Iteration 22300 (5.15601 iter/s, 19.3948s/100 iter), loss = 0.0557851
I0916 18:17:26.534417 20216 solver.cpp:336]     Train net output #0: loss = 0.055785 (* 1 = 0.055785 loss)
I0916 18:17:26.534425 20216 sgd_solver.cpp:136] Iteration 22300, lr = 0.01, m = 0.9
I0916 18:17:45.850251 20216 solver.cpp:314] Iteration 22400 (5.17721 iter/s, 19.3154s/100 iter), loss = 0.0783654
I0916 18:17:45.850325 20216 solver.cpp:336]     Train net output #0: loss = 0.0783652 (* 1 = 0.0783652 loss)
I0916 18:17:45.850345 20216 sgd_solver.cpp:136] Iteration 22400, lr = 0.01, m = 0.9
I0916 18:18:00.372755 20224 data_reader.cpp:305] Starting prefetch of epoch 16
I0916 18:18:05.388422 20216 solver.cpp:314] Iteration 22500 (5.11833 iter/s, 19.5376s/100 iter), loss = 0.143084
I0916 18:18:05.388480 20216 solver.cpp:336]     Train net output #0: loss = 0.143084 (* 1 = 0.143084 loss)
I0916 18:18:05.388499 20216 sgd_solver.cpp:136] Iteration 22500, lr = 0.01, m = 0.9
I0916 18:18:24.740048 20216 solver.cpp:314] Iteration 22600 (5.16767 iter/s, 19.3511s/100 iter), loss = 0.0734221
I0916 18:18:24.740073 20216 solver.cpp:336]     Train net output #0: loss = 0.0734219 (* 1 = 0.0734219 loss)
I0916 18:18:24.740078 20216 sgd_solver.cpp:136] Iteration 22600, lr = 0.01, m = 0.9
I0916 18:18:32.449525 20220 data_reader.cpp:305] Starting prefetch of epoch 18
I0916 18:18:43.938145 20216 solver.cpp:314] Iteration 22700 (5.209 iter/s, 19.1976s/100 iter), loss = 0.0945848
I0916 18:18:43.938171 20216 solver.cpp:336]     Train net output #0: loss = 0.0945847 (* 1 = 0.0945847 loss)
I0916 18:18:43.938177 20216 sgd_solver.cpp:136] Iteration 22700, lr = 0.01, m = 0.9
I0916 18:19:03.387431 20216 solver.cpp:314] Iteration 22800 (5.14172 iter/s, 19.4487s/100 iter), loss = 0.0448582
I0916 18:19:03.387807 20216 solver.cpp:336]     Train net output #0: loss = 0.0448581 (* 1 = 0.0448581 loss)
I0916 18:19:03.387825 20216 sgd_solver.cpp:136] Iteration 22800, lr = 0.01, m = 0.9
I0916 18:19:23.191980 20216 solver.cpp:314] Iteration 22900 (5.04949 iter/s, 19.804s/100 iter), loss = 0.072031
I0916 18:19:23.192006 20216 solver.cpp:336]     Train net output #0: loss = 0.0720309 (* 1 = 0.0720309 loss)
I0916 18:19:23.192013 20216 sgd_solver.cpp:136] Iteration 22900, lr = 0.01, m = 0.9
I0916 18:19:36.774101 20197 data_reader.cpp:305] Starting prefetch of epoch 11
I0916 18:19:42.623795 20216 solver.cpp:314] Iteration 23000 (5.14634 iter/s, 19.4313s/100 iter), loss = 0.149682
I0916 18:19:42.623818 20216 solver.cpp:336]     Train net output #0: loss = 0.149682 (* 1 = 0.149682 loss)
I0916 18:19:42.623822 20216 sgd_solver.cpp:136] Iteration 23000, lr = 0.01, m = 0.9
I0916 18:20:02.029603 20216 solver.cpp:314] Iteration 23100 (5.15324 iter/s, 19.4053s/100 iter), loss = 0.0880017
I0916 18:20:02.029626 20216 solver.cpp:336]     Train net output #0: loss = 0.0880015 (* 1 = 0.0880015 loss)
I0916 18:20:02.029630 20216 sgd_solver.cpp:136] Iteration 23100, lr = 0.01, m = 0.9
I0916 18:20:21.333549 20216 solver.cpp:314] Iteration 23200 (5.18043 iter/s, 19.3034s/100 iter), loss = 0.105589
I0916 18:20:21.333602 20216 solver.cpp:336]     Train net output #0: loss = 0.105589 (* 1 = 0.105589 loss)
I0916 18:20:21.333607 20216 sgd_solver.cpp:136] Iteration 23200, lr = 0.01, m = 0.9
I0916 18:20:40.839179 20216 solver.cpp:314] Iteration 23300 (5.12687 iter/s, 19.5051s/100 iter), loss = 0.0552198
I0916 18:20:40.839205 20216 solver.cpp:336]     Train net output #0: loss = 0.0552197 (* 1 = 0.0552197 loss)
I0916 18:20:40.839211 20216 sgd_solver.cpp:136] Iteration 23300, lr = 0.01, m = 0.9
I0916 18:20:41.027537 20197 data_reader.cpp:305] Starting prefetch of epoch 12
I0916 18:21:00.167559 20216 solver.cpp:314] Iteration 23400 (5.17388 iter/s, 19.3278s/100 iter), loss = 0.0913001
I0916 18:21:00.167629 20216 solver.cpp:336]     Train net output #0: loss = 0.0913 (* 1 = 0.0913 loss)
I0916 18:21:00.167637 20216 sgd_solver.cpp:136] Iteration 23400, lr = 0.01, m = 0.9
I0916 18:21:13.255970 20219 data_reader.cpp:305] Starting prefetch of epoch 17
I0916 18:21:19.910956 20216 solver.cpp:314] Iteration 23500 (5.06513 iter/s, 19.7428s/100 iter), loss = 0.335162
I0916 18:21:19.910986 20216 solver.cpp:336]     Train net output #0: loss = 0.335161 (* 1 = 0.335161 loss)
I0916 18:21:19.910993 20216 sgd_solver.cpp:136] Iteration 23500, lr = 0.01, m = 0.9
I0916 18:21:39.544318 20216 solver.cpp:314] Iteration 23600 (5.09351 iter/s, 19.6328s/100 iter), loss = 0.135992
I0916 18:21:39.544378 20216 solver.cpp:336]     Train net output #0: loss = 0.135992 (* 1 = 0.135992 loss)
I0916 18:21:39.544384 20216 sgd_solver.cpp:136] Iteration 23600, lr = 0.01, m = 0.9
I0916 18:21:58.942833 20216 solver.cpp:314] Iteration 23700 (5.15518 iter/s, 19.398s/100 iter), loss = 0.0638801
I0916 18:21:58.942863 20216 solver.cpp:336]     Train net output #0: loss = 0.0638799 (* 1 = 0.0638799 loss)
I0916 18:21:58.942870 20216 sgd_solver.cpp:136] Iteration 23700, lr = 0.01, m = 0.9
I0916 18:22:17.519209 20223 data_reader.cpp:305] Starting prefetch of epoch 12
I0916 18:22:18.309865 20216 solver.cpp:314] Iteration 23800 (5.16356 iter/s, 19.3665s/100 iter), loss = 0.11343
I0916 18:22:18.309886 20216 solver.cpp:336]     Train net output #0: loss = 0.11343 (* 1 = 0.11343 loss)
I0916 18:22:18.309891 20216 sgd_solver.cpp:136] Iteration 23800, lr = 0.01, m = 0.9
I0916 18:22:37.989051 20216 solver.cpp:314] Iteration 23900 (5.08165 iter/s, 19.6786s/100 iter), loss = 0.0687884
I0916 18:22:37.989081 20216 solver.cpp:336]     Train net output #0: loss = 0.0687883 (* 1 = 0.0687883 loss)
I0916 18:22:37.989089 20216 sgd_solver.cpp:136] Iteration 23900, lr = 0.01, m = 0.9
I0916 18:22:57.136773 20216 solver.cpp:563] Iteration 24000, Testing net (#0)
I0916 18:23:00.525503 20250 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 18:23:11.029795 20243 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 18:23:11.365911 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.929268
I0916 18:23:11.365932 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 18:23:11.365937 20216 solver.cpp:655]     Test net output #2: loss = 0.199519 (* 1 = 0.199519 loss)
I0916 18:23:11.366005 20216 solver.cpp:265] [MultiGPU] Tests completed in 14.2288s
I0916 18:23:11.578400 20216 solver.cpp:314] Iteration 24000 (2.97722 iter/s, 33.5884s/100 iter), loss = 0.0860809
I0916 18:23:11.578451 20216 solver.cpp:336]     Train net output #0: loss = 0.0860807 (* 1 = 0.0860807 loss)
I0916 18:23:11.578464 20216 sgd_solver.cpp:136] Iteration 24000, lr = 0.01, m = 0.9
I0916 18:23:30.905170 20216 solver.cpp:314] Iteration 24100 (5.17432 iter/s, 19.3262s/100 iter), loss = 0.0977296
I0916 18:23:30.905223 20216 solver.cpp:336]     Train net output #0: loss = 0.0977294 (* 1 = 0.0977294 loss)
I0916 18:23:30.905230 20216 sgd_solver.cpp:136] Iteration 24100, lr = 0.01, m = 0.9
I0916 18:23:50.517299 20216 solver.cpp:314] Iteration 24200 (5.09903 iter/s, 19.6116s/100 iter), loss = 0.226808
I0916 18:23:50.517328 20216 solver.cpp:336]     Train net output #0: loss = 0.226808 (* 1 = 0.226808 loss)
I0916 18:23:50.517334 20216 sgd_solver.cpp:136] Iteration 24200, lr = 0.01, m = 0.9
I0916 18:24:08.742429 20197 data_reader.cpp:305] Starting prefetch of epoch 13
I0916 18:24:10.229096 20216 solver.cpp:314] Iteration 24300 (5.07325 iter/s, 19.7112s/100 iter), loss = 0.0562733
I0916 18:24:10.229121 20216 solver.cpp:336]     Train net output #0: loss = 0.0562731 (* 1 = 0.0562731 loss)
I0916 18:24:10.229127 20216 sgd_solver.cpp:136] Iteration 24300, lr = 0.01, m = 0.9
I0916 18:24:30.030309 20216 solver.cpp:314] Iteration 24400 (5.05034 iter/s, 19.8007s/100 iter), loss = 0.155323
I0916 18:24:30.030333 20216 solver.cpp:336]     Train net output #0: loss = 0.155323 (* 1 = 0.155323 loss)
I0916 18:24:30.030339 20216 sgd_solver.cpp:136] Iteration 24400, lr = 0.01, m = 0.9
I0916 18:24:49.780738 20216 solver.cpp:314] Iteration 24500 (5.06332 iter/s, 19.7499s/100 iter), loss = 0.0810393
I0916 18:24:49.781255 20216 solver.cpp:336]     Train net output #0: loss = 0.0810391 (* 1 = 0.0810391 loss)
I0916 18:24:49.781283 20216 sgd_solver.cpp:136] Iteration 24500, lr = 0.01, m = 0.9
I0916 18:25:09.388394 20216 solver.cpp:314] Iteration 24600 (5.10019 iter/s, 19.6071s/100 iter), loss = 0.16717
I0916 18:25:09.388422 20216 solver.cpp:336]     Train net output #0: loss = 0.16717 (* 1 = 0.16717 loss)
I0916 18:25:09.388427 20216 sgd_solver.cpp:136] Iteration 24600, lr = 0.01, m = 0.9
I0916 18:25:13.904758 20224 data_reader.cpp:305] Starting prefetch of epoch 17
I0916 18:25:28.794512 20216 solver.cpp:314] Iteration 24700 (5.15316 iter/s, 19.4056s/100 iter), loss = 0.0678228
I0916 18:25:28.794570 20216 solver.cpp:336]     Train net output #0: loss = 0.0678227 (* 1 = 0.0678227 loss)
I0916 18:25:28.794579 20216 sgd_solver.cpp:136] Iteration 24700, lr = 0.01, m = 0.9
I0916 18:25:45.979974 20220 data_reader.cpp:305] Starting prefetch of epoch 19
I0916 18:25:48.347796 20216 solver.cpp:314] Iteration 24800 (5.11437 iter/s, 19.5527s/100 iter), loss = 0.0959877
I0916 18:25:48.347821 20216 solver.cpp:336]     Train net output #0: loss = 0.0959876 (* 1 = 0.0959876 loss)
I0916 18:25:48.347827 20216 sgd_solver.cpp:136] Iteration 24800, lr = 0.01, m = 0.9
I0916 18:26:07.809923 20216 solver.cpp:314] Iteration 24900 (5.13833 iter/s, 19.4616s/100 iter), loss = 0.0657845
I0916 18:26:07.809983 20216 solver.cpp:336]     Train net output #0: loss = 0.0657844 (* 1 = 0.0657844 loss)
I0916 18:26:07.809988 20216 sgd_solver.cpp:136] Iteration 24900, lr = 0.01, m = 0.9
I0916 18:26:27.106564 20216 solver.cpp:314] Iteration 25000 (5.18239 iter/s, 19.2961s/100 iter), loss = 0.0965429
I0916 18:26:27.106592 20216 solver.cpp:336]     Train net output #0: loss = 0.0965428 (* 1 = 0.0965428 loss)
I0916 18:26:27.106600 20216 sgd_solver.cpp:136] Iteration 25000, lr = 0.01, m = 0.9
I0916 18:26:46.491710 20216 solver.cpp:314] Iteration 25100 (5.15873 iter/s, 19.3846s/100 iter), loss = 0.084208
I0916 18:26:46.491770 20216 solver.cpp:336]     Train net output #0: loss = 0.0842079 (* 1 = 0.0842079 loss)
I0916 18:26:46.491780 20216 sgd_solver.cpp:136] Iteration 25100, lr = 0.01, m = 0.9
I0916 18:26:50.260960 20224 data_reader.cpp:305] Starting prefetch of epoch 18
I0916 18:27:06.115773 20216 solver.cpp:314] Iteration 25200 (5.09593 iter/s, 19.6235s/100 iter), loss = 0.0940382
I0916 18:27:06.115797 20216 solver.cpp:336]     Train net output #0: loss = 0.0940381 (* 1 = 0.0940381 loss)
I0916 18:27:06.115803 20216 sgd_solver.cpp:136] Iteration 25200, lr = 0.01, m = 0.9
I0916 18:27:25.733495 20216 solver.cpp:314] Iteration 25300 (5.09757 iter/s, 19.6172s/100 iter), loss = 0.0848853
I0916 18:27:25.733546 20216 solver.cpp:336]     Train net output #0: loss = 0.0848851 (* 1 = 0.0848851 loss)
I0916 18:27:25.733552 20216 sgd_solver.cpp:136] Iteration 25300, lr = 0.01, m = 0.9
I0916 18:27:45.200810 20216 solver.cpp:314] Iteration 25400 (5.13696 iter/s, 19.4668s/100 iter), loss = 0.0880736
I0916 18:27:45.200842 20216 solver.cpp:336]     Train net output #0: loss = 0.0880734 (* 1 = 0.0880734 loss)
I0916 18:27:45.200848 20216 sgd_solver.cpp:136] Iteration 25400, lr = 0.01, m = 0.9
I0916 18:27:54.700268 20223 data_reader.cpp:305] Starting prefetch of epoch 13
I0916 18:28:04.640081 20216 solver.cpp:314] Iteration 25500 (5.14437 iter/s, 19.4387s/100 iter), loss = 0.0572578
I0916 18:28:04.640128 20216 solver.cpp:336]     Train net output #0: loss = 0.0572576 (* 1 = 0.0572576 loss)
I0916 18:28:04.640135 20216 sgd_solver.cpp:136] Iteration 25500, lr = 0.01, m = 0.9
I0916 18:28:24.174603 20216 solver.cpp:314] Iteration 25600 (5.11928 iter/s, 19.534s/100 iter), loss = 0.104715
I0916 18:28:24.174628 20216 solver.cpp:336]     Train net output #0: loss = 0.104715 (* 1 = 0.104715 loss)
I0916 18:28:24.174633 20216 sgd_solver.cpp:136] Iteration 25600, lr = 0.01, m = 0.9
I0916 18:28:27.149354 20220 data_reader.cpp:305] Starting prefetch of epoch 20
I0916 18:28:43.772878 20216 solver.cpp:314] Iteration 25700 (5.10263 iter/s, 19.5977s/100 iter), loss = 0.0536044
I0916 18:28:43.772946 20216 solver.cpp:336]     Train net output #0: loss = 0.0536043 (* 1 = 0.0536043 loss)
I0916 18:28:43.772951 20216 sgd_solver.cpp:136] Iteration 25700, lr = 0.01, m = 0.9
I0916 18:29:03.232700 20216 solver.cpp:314] Iteration 25800 (5.13894 iter/s, 19.4593s/100 iter), loss = 0.0741796
I0916 18:29:03.232729 20216 solver.cpp:336]     Train net output #0: loss = 0.0741794 (* 1 = 0.0741794 loss)
I0916 18:29:03.232736 20216 sgd_solver.cpp:136] Iteration 25800, lr = 0.01, m = 0.9
I0916 18:29:22.689258 20216 solver.cpp:314] Iteration 25900 (5.1398 iter/s, 19.456s/100 iter), loss = 0.0675953
I0916 18:29:22.689314 20216 solver.cpp:336]     Train net output #0: loss = 0.0675951 (* 1 = 0.0675951 loss)
I0916 18:29:22.689321 20216 sgd_solver.cpp:136] Iteration 25900, lr = 0.01, m = 0.9
I0916 18:29:31.584825 20219 data_reader.cpp:305] Starting prefetch of epoch 18
I0916 18:29:42.328706 20216 solver.cpp:563] Iteration 26000, Testing net (#0)
I0916 18:30:00.544147 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.952049
I0916 18:30:00.544199 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 18:30:00.544208 20216 solver.cpp:655]     Test net output #2: loss = 0.152382 (* 1 = 0.152382 loss)
I0916 18:30:00.544770 20216 solver.cpp:265] [MultiGPU] Tests completed in 18.2156s
I0916 18:30:00.767398 20216 solver.cpp:314] Iteration 26000 (2.62625 iter/s, 38.0771s/100 iter), loss = 0.12312
I0916 18:30:00.767421 20216 solver.cpp:336]     Train net output #0: loss = 0.12312 (* 1 = 0.12312 loss)
I0916 18:30:00.767426 20216 sgd_solver.cpp:136] Iteration 26000, lr = 0.01, m = 0.9
I0916 18:30:20.070683 20216 solver.cpp:314] Iteration 26100 (5.18061 iter/s, 19.3027s/100 iter), loss = 0.0590496
I0916 18:30:20.070710 20216 solver.cpp:336]     Train net output #0: loss = 0.0590495 (* 1 = 0.0590495 loss)
I0916 18:30:20.070718 20216 sgd_solver.cpp:136] Iteration 26100, lr = 0.01, m = 0.9
I0916 18:30:21.987054 20224 data_reader.cpp:305] Starting prefetch of epoch 19
I0916 18:30:39.586000 20216 solver.cpp:314] Iteration 26200 (5.12432 iter/s, 19.5148s/100 iter), loss = 0.101331
I0916 18:30:39.586055 20216 solver.cpp:336]     Train net output #0: loss = 0.101331 (* 1 = 0.101331 loss)
I0916 18:30:39.586061 20216 sgd_solver.cpp:136] Iteration 26200, lr = 0.01, m = 0.9
I0916 18:30:54.411337 20219 data_reader.cpp:305] Starting prefetch of epoch 19
I0916 18:30:59.021880 20216 solver.cpp:314] Iteration 26300 (5.14527 iter/s, 19.4353s/100 iter), loss = 0.0833558
I0916 18:30:59.021901 20216 solver.cpp:336]     Train net output #0: loss = 0.0833557 (* 1 = 0.0833557 loss)
I0916 18:30:59.021905 20216 sgd_solver.cpp:136] Iteration 26300, lr = 0.01, m = 0.9
I0916 18:31:18.614497 20216 solver.cpp:314] Iteration 26400 (5.10411 iter/s, 19.5921s/100 iter), loss = 0.0949952
I0916 18:31:18.614554 20216 solver.cpp:336]     Train net output #0: loss = 0.0949951 (* 1 = 0.0949951 loss)
I0916 18:31:18.614562 20216 sgd_solver.cpp:136] Iteration 26400, lr = 0.01, m = 0.9
I0916 18:31:38.315135 20216 solver.cpp:314] Iteration 26500 (5.07612 iter/s, 19.7001s/100 iter), loss = 0.0639697
I0916 18:31:38.315165 20216 solver.cpp:336]     Train net output #0: loss = 0.0639695 (* 1 = 0.0639695 loss)
I0916 18:31:38.315168 20216 sgd_solver.cpp:136] Iteration 26500, lr = 0.01, m = 0.9
I0916 18:31:57.864563 20216 solver.cpp:314] Iteration 26600 (5.11538 iter/s, 19.5489s/100 iter), loss = 0.0728599
I0916 18:31:57.864619 20216 solver.cpp:336]     Train net output #0: loss = 0.0728599 (* 1 = 0.0728599 loss)
I0916 18:31:57.864626 20216 sgd_solver.cpp:136] Iteration 26600, lr = 0.01, m = 0.9
I0916 18:31:59.086907 20219 data_reader.cpp:305] Starting prefetch of epoch 20
I0916 18:32:17.036933 20216 solver.cpp:314] Iteration 26700 (5.21599 iter/s, 19.1718s/100 iter), loss = 0.07899
I0916 18:32:17.036954 20216 solver.cpp:336]     Train net output #0: loss = 0.0789899 (* 1 = 0.0789899 loss)
I0916 18:32:17.036959 20216 sgd_solver.cpp:136] Iteration 26700, lr = 0.01, m = 0.9
I0916 18:32:36.232961 20216 solver.cpp:314] Iteration 26800 (5.20956 iter/s, 19.1955s/100 iter), loss = 0.0907153
I0916 18:32:36.233053 20216 solver.cpp:336]     Train net output #0: loss = 0.0907152 (* 1 = 0.0907152 loss)
I0916 18:32:36.233062 20216 sgd_solver.cpp:136] Iteration 26800, lr = 0.01, m = 0.9
I0916 18:32:55.717803 20216 solver.cpp:314] Iteration 26900 (5.13234 iter/s, 19.4843s/100 iter), loss = 0.0546463
I0916 18:32:55.717828 20216 solver.cpp:336]     Train net output #0: loss = 0.0546462 (* 1 = 0.0546462 loss)
I0916 18:32:55.717831 20216 sgd_solver.cpp:136] Iteration 26900, lr = 0.01, m = 0.9
I0916 18:33:02.939129 20197 data_reader.cpp:305] Starting prefetch of epoch 14
I0916 18:33:15.137692 20216 solver.cpp:314] Iteration 27000 (5.1495 iter/s, 19.4193s/100 iter), loss = 0.133019
I0916 18:33:15.137743 20216 solver.cpp:336]     Train net output #0: loss = 0.133019 (* 1 = 0.133019 loss)
I0916 18:33:15.137750 20216 sgd_solver.cpp:136] Iteration 27000, lr = 0.01, m = 0.9
I0916 18:33:34.752406 20216 solver.cpp:314] Iteration 27100 (5.09836 iter/s, 19.6142s/100 iter), loss = 0.073498
I0916 18:33:34.752431 20216 solver.cpp:336]     Train net output #0: loss = 0.0734979 (* 1 = 0.0734979 loss)
I0916 18:33:34.752435 20216 sgd_solver.cpp:136] Iteration 27100, lr = 0.01, m = 0.9
I0916 18:33:35.185250 20220 data_reader.cpp:305] Starting prefetch of epoch 21
I0916 18:33:54.131327 20216 solver.cpp:314] Iteration 27200 (5.16039 iter/s, 19.3784s/100 iter), loss = 0.0489
I0916 18:33:54.131598 20216 solver.cpp:336]     Train net output #0: loss = 0.0488999 (* 1 = 0.0488999 loss)
I0916 18:33:54.131608 20216 sgd_solver.cpp:136] Iteration 27200, lr = 0.01, m = 0.9
I0916 18:34:13.684103 20216 solver.cpp:314] Iteration 27300 (5.11451 iter/s, 19.5522s/100 iter), loss = 0.0833308
I0916 18:34:13.684129 20216 solver.cpp:336]     Train net output #0: loss = 0.0833307 (* 1 = 0.0833307 loss)
I0916 18:34:13.684135 20216 sgd_solver.cpp:136] Iteration 27300, lr = 0.01, m = 0.9
I0916 18:34:32.955271 20216 solver.cpp:314] Iteration 27400 (5.18925 iter/s, 19.2706s/100 iter), loss = 0.125643
I0916 18:34:32.955354 20216 solver.cpp:336]     Train net output #0: loss = 0.125643 (* 1 = 0.125643 loss)
I0916 18:34:32.955363 20216 sgd_solver.cpp:136] Iteration 27400, lr = 0.01, m = 0.9
I0916 18:34:39.306468 20220 data_reader.cpp:305] Starting prefetch of epoch 22
I0916 18:34:52.264324 20216 solver.cpp:314] Iteration 27500 (5.17906 iter/s, 19.3085s/100 iter), loss = 0.0726224
I0916 18:34:52.264353 20216 solver.cpp:336]     Train net output #0: loss = 0.0726223 (* 1 = 0.0726223 loss)
I0916 18:34:52.264358 20216 sgd_solver.cpp:136] Iteration 27500, lr = 0.01, m = 0.9
I0916 18:35:12.743260 20216 solver.cpp:314] Iteration 27600 (4.8832 iter/s, 20.4784s/100 iter), loss = 0.0931627
I0916 18:35:12.743320 20216 solver.cpp:336]     Train net output #0: loss = 0.0931626 (* 1 = 0.0931626 loss)
I0916 18:35:12.743329 20216 sgd_solver.cpp:136] Iteration 27600, lr = 0.01, m = 0.9
I0916 18:35:32.945623 20216 solver.cpp:314] Iteration 27700 (4.95006 iter/s, 20.2018s/100 iter), loss = 0.0829781
I0916 18:35:32.945650 20216 solver.cpp:336]     Train net output #0: loss = 0.082978 (* 1 = 0.082978 loss)
I0916 18:35:32.945657 20216 sgd_solver.cpp:136] Iteration 27700, lr = 0.01, m = 0.9
I0916 18:35:45.748052 20220 data_reader.cpp:305] Starting prefetch of epoch 23
I0916 18:35:53.246608 20216 solver.cpp:314] Iteration 27800 (4.92601 iter/s, 20.3004s/100 iter), loss = 0.0499002
I0916 18:35:53.246631 20216 solver.cpp:336]     Train net output #0: loss = 0.0499001 (* 1 = 0.0499001 loss)
I0916 18:35:53.246637 20216 sgd_solver.cpp:136] Iteration 27800, lr = 0.01, m = 0.9
I0916 18:36:13.390928 20216 solver.cpp:314] Iteration 27900 (4.96432 iter/s, 20.1438s/100 iter), loss = 0.0880518
I0916 18:36:13.390969 20216 solver.cpp:336]     Train net output #0: loss = 0.0880517 (* 1 = 0.0880517 loss)
I0916 18:36:13.390980 20216 sgd_solver.cpp:136] Iteration 27900, lr = 0.01, m = 0.9
I0916 18:36:33.784565 20216 solver.cpp:563] Iteration 28000, Testing net (#0)
I0916 18:36:45.762359 20202 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 18:36:45.762359 20241 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 18:37:06.462535 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.938414
I0916 18:37:06.462658 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 18:37:06.462668 20216 solver.cpp:655]     Test net output #2: loss = 0.181639 (* 1 = 0.181639 loss)
I0916 18:37:06.462694 20216 solver.cpp:265] [MultiGPU] Tests completed in 32.6772s
I0916 18:37:06.674069 20216 solver.cpp:314] Iteration 28000 (1.87682 iter/s, 53.2816s/100 iter), loss = 0.0940403
I0916 18:37:06.674099 20216 solver.cpp:336]     Train net output #0: loss = 0.0940402 (* 1 = 0.0940402 loss)
I0916 18:37:06.674104 20216 sgd_solver.cpp:136] Iteration 28000, lr = 0.01, m = 0.9
I0916 18:37:24.709111 20224 data_reader.cpp:305] Starting prefetch of epoch 20
I0916 18:37:25.843905 20216 solver.cpp:314] Iteration 28100 (5.21668 iter/s, 19.1693s/100 iter), loss = 0.0715187
I0916 18:37:25.843930 20216 solver.cpp:336]     Train net output #0: loss = 0.0715186 (* 1 = 0.0715186 loss)
I0916 18:37:25.843935 20216 sgd_solver.cpp:136] Iteration 28100, lr = 0.01, m = 0.9
I0916 18:37:44.995159 20216 solver.cpp:314] Iteration 28200 (5.22174 iter/s, 19.1507s/100 iter), loss = 0.0902162
I0916 18:37:44.995219 20216 solver.cpp:336]     Train net output #0: loss = 0.0902162 (* 1 = 0.0902162 loss)
I0916 18:37:44.995224 20216 sgd_solver.cpp:136] Iteration 28200, lr = 0.01, m = 0.9
I0916 18:38:04.207305 20216 solver.cpp:314] Iteration 28300 (5.20519 iter/s, 19.2116s/100 iter), loss = 0.06866
I0916 18:38:04.207332 20216 solver.cpp:336]     Train net output #0: loss = 0.0686599 (* 1 = 0.0686599 loss)
I0916 18:38:04.207337 20216 sgd_solver.cpp:136] Iteration 28300, lr = 0.01, m = 0.9
I0916 18:38:23.641163 20216 solver.cpp:314] Iteration 28400 (5.1458 iter/s, 19.4333s/100 iter), loss = 0.0856421
I0916 18:38:23.641225 20216 solver.cpp:336]     Train net output #0: loss = 0.0856421 (* 1 = 0.0856421 loss)
I0916 18:38:23.641233 20216 sgd_solver.cpp:136] Iteration 28400, lr = 0.01, m = 0.9
I0916 18:38:28.437764 20197 data_reader.cpp:305] Starting prefetch of epoch 15
I0916 18:38:43.312618 20216 solver.cpp:314] Iteration 28500 (5.08365 iter/s, 19.6709s/100 iter), loss = 0.229064
I0916 18:38:43.312667 20216 solver.cpp:336]     Train net output #0: loss = 0.229064 (* 1 = 0.229064 loss)
I0916 18:38:43.312690 20216 sgd_solver.cpp:136] Iteration 28500, lr = 0.01, m = 0.9
I0916 18:39:01.107282 20220 data_reader.cpp:305] Starting prefetch of epoch 24
I0916 18:39:02.983024 20216 solver.cpp:314] Iteration 28600 (5.08392 iter/s, 19.6699s/100 iter), loss = 0.133703
I0916 18:39:02.983052 20216 solver.cpp:336]     Train net output #0: loss = 0.133703 (* 1 = 0.133703 loss)
I0916 18:39:02.983058 20216 sgd_solver.cpp:136] Iteration 28600, lr = 0.01, m = 0.9
I0916 18:39:22.556768 20216 solver.cpp:314] Iteration 28700 (5.10903 iter/s, 19.5732s/100 iter), loss = 0.127712
I0916 18:39:22.556797 20216 solver.cpp:336]     Train net output #0: loss = 0.127712 (* 1 = 0.127712 loss)
I0916 18:39:22.556802 20216 sgd_solver.cpp:136] Iteration 28700, lr = 0.01, m = 0.9
I0916 18:39:41.955832 20216 solver.cpp:314] Iteration 28800 (5.15503 iter/s, 19.3985s/100 iter), loss = 0.0819333
I0916 18:39:41.955884 20216 solver.cpp:336]     Train net output #0: loss = 0.0819333 (* 1 = 0.0819333 loss)
I0916 18:39:41.955890 20216 sgd_solver.cpp:136] Iteration 28800, lr = 0.01, m = 0.9
I0916 18:40:01.354840 20216 solver.cpp:314] Iteration 28900 (5.15505 iter/s, 19.3985s/100 iter), loss = 0.161948
I0916 18:40:01.354867 20216 solver.cpp:336]     Train net output #0: loss = 0.161948 (* 1 = 0.161948 loss)
I0916 18:40:01.354871 20216 sgd_solver.cpp:136] Iteration 28900, lr = 0.01, m = 0.9
I0916 18:40:05.256429 20219 data_reader.cpp:305] Starting prefetch of epoch 21
I0916 18:40:20.864804 20216 solver.cpp:314] Iteration 29000 (5.12573 iter/s, 19.5094s/100 iter), loss = 0.0824135
I0916 18:40:20.864859 20216 solver.cpp:336]     Train net output #0: loss = 0.0824136 (* 1 = 0.0824136 loss)
I0916 18:40:20.864866 20216 sgd_solver.cpp:136] Iteration 29000, lr = 0.01, m = 0.9
I0916 18:40:40.454286 20216 solver.cpp:314] Iteration 29100 (5.10492 iter/s, 19.5889s/100 iter), loss = 0.0775144
I0916 18:40:40.454310 20216 solver.cpp:336]     Train net output #0: loss = 0.0775145 (* 1 = 0.0775145 loss)
I0916 18:40:40.454316 20216 sgd_solver.cpp:136] Iteration 29100, lr = 0.01, m = 0.9
I0916 18:40:59.819272 20216 solver.cpp:314] Iteration 29200 (5.1641 iter/s, 19.3644s/100 iter), loss = 0.0631669
I0916 18:40:59.819454 20216 solver.cpp:336]     Train net output #0: loss = 0.063167 (* 1 = 0.063167 loss)
I0916 18:40:59.819463 20216 sgd_solver.cpp:136] Iteration 29200, lr = 0.01, m = 0.9
I0916 18:41:09.541152 20220 data_reader.cpp:305] Starting prefetch of epoch 25
I0916 18:41:19.090515 20216 solver.cpp:314] Iteration 29300 (5.18922 iter/s, 19.2707s/100 iter), loss = 0.0595184
I0916 18:41:19.090539 20216 solver.cpp:336]     Train net output #0: loss = 0.0595185 (* 1 = 0.0595185 loss)
I0916 18:41:19.090545 20216 sgd_solver.cpp:136] Iteration 29300, lr = 0.01, m = 0.9
I0916 18:41:38.828028 20216 solver.cpp:314] Iteration 29400 (5.06664 iter/s, 19.737s/100 iter), loss = 0.0599829
I0916 18:41:38.828114 20216 solver.cpp:336]     Train net output #0: loss = 0.0599829 (* 1 = 0.0599829 loss)
I0916 18:41:38.828122 20216 sgd_solver.cpp:136] Iteration 29400, lr = 0.01, m = 0.9
I0916 18:41:58.244016 20216 solver.cpp:314] Iteration 29500 (5.15054 iter/s, 19.4154s/100 iter), loss = 0.144637
I0916 18:41:58.244045 20216 solver.cpp:336]     Train net output #0: loss = 0.144637 (* 1 = 0.144637 loss)
I0916 18:41:58.244051 20216 sgd_solver.cpp:136] Iteration 29500, lr = 0.01, m = 0.9
I0916 18:42:14.072659 20224 data_reader.cpp:305] Starting prefetch of epoch 21
I0916 18:42:17.614300 20216 solver.cpp:314] Iteration 29600 (5.16269 iter/s, 19.3697s/100 iter), loss = 0.067109
I0916 18:42:17.614321 20216 solver.cpp:336]     Train net output #0: loss = 0.0671091 (* 1 = 0.0671091 loss)
I0916 18:42:17.614327 20216 sgd_solver.cpp:136] Iteration 29600, lr = 0.01, m = 0.9
I0916 18:42:37.149590 20216 solver.cpp:314] Iteration 29700 (5.11908 iter/s, 19.5347s/100 iter), loss = 0.0729557
I0916 18:42:37.149619 20216 solver.cpp:336]     Train net output #0: loss = 0.0729558 (* 1 = 0.0729558 loss)
I0916 18:42:37.149627 20216 sgd_solver.cpp:136] Iteration 29700, lr = 0.01, m = 0.9
I0916 18:42:56.610298 20216 solver.cpp:314] Iteration 29800 (5.1387 iter/s, 19.4602s/100 iter), loss = 0.141528
I0916 18:42:56.617969 20216 solver.cpp:336]     Train net output #0: loss = 0.141528 (* 1 = 0.141528 loss)
I0916 18:42:56.618001 20216 sgd_solver.cpp:136] Iteration 29800, lr = 0.01, m = 0.9
I0916 18:43:16.322773 20216 solver.cpp:314] Iteration 29900 (5.07307 iter/s, 19.7119s/100 iter), loss = 0.0784908
I0916 18:43:16.322799 20216 solver.cpp:336]     Train net output #0: loss = 0.0784909 (* 1 = 0.0784909 loss)
I0916 18:43:16.322808 20216 sgd_solver.cpp:136] Iteration 29900, lr = 0.01, m = 0.9
I0916 18:43:18.745353 20197 data_reader.cpp:305] Starting prefetch of epoch 16
I0916 18:43:35.965090 20216 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/cityscapes5_jsegnet21v2_iter_30000.caffemodel
I0916 18:43:36.354102 20216 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/cityscapes5_jsegnet21v2_iter_30000.solverstate
I0916 18:43:36.358435 20216 solver.cpp:563] Iteration 30000, Testing net (#0)
I0916 18:43:43.389469 20204 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 18:43:47.407966 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.952704
I0916 18:43:47.407989 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 18:43:47.407994 20216 solver.cpp:655]     Test net output #2: loss = 0.162434 (* 1 = 0.162434 loss)
I0916 18:43:47.408021 20216 solver.cpp:265] [MultiGPU] Tests completed in 11.0493s
I0916 18:43:47.526149 20266 sgd_solver.cpp:48] MultiStep Status: Iteration 30000, step = 1
I0916 18:43:47.526149 20267 sgd_solver.cpp:48] MultiStep Status: Iteration 30000, step = 1
I0916 18:43:47.526245 20268 sgd_solver.cpp:48] MultiStep Status: Iteration 30000, step = 1
I0916 18:43:47.621229 20216 solver.cpp:314] Iteration 30000 (3.19513 iter/s, 31.2976s/100 iter), loss = 0.200347
I0916 18:43:47.621258 20216 solver.cpp:336]     Train net output #0: loss = 0.200348 (* 1 = 0.200348 loss)
I0916 18:43:47.621263 20216 sgd_solver.cpp:136] Iteration 30000, lr = 0.001, m = 0.9
I0916 18:44:06.943439 20216 solver.cpp:314] Iteration 30100 (5.17554 iter/s, 19.3217s/100 iter), loss = 0.0622953
I0916 18:44:06.943524 20216 solver.cpp:336]     Train net output #0: loss = 0.0622954 (* 1 = 0.0622954 loss)
I0916 18:44:06.943531 20216 sgd_solver.cpp:136] Iteration 30100, lr = 0.001, m = 0.9
I0916 18:44:26.171859 20216 solver.cpp:314] Iteration 30200 (5.20078 iter/s, 19.2279s/100 iter), loss = 0.0659689
I0916 18:44:26.171882 20216 solver.cpp:336]     Train net output #0: loss = 0.065969 (* 1 = 0.065969 loss)
I0916 18:44:26.171888 20216 sgd_solver.cpp:136] Iteration 30200, lr = 0.001, m = 0.9
I0916 18:44:34.295228 20224 data_reader.cpp:305] Starting prefetch of epoch 22
I0916 18:44:45.696749 20216 solver.cpp:314] Iteration 30300 (5.12181 iter/s, 19.5243s/100 iter), loss = 0.0770236
I0916 18:44:45.696801 20216 solver.cpp:336]     Train net output #0: loss = 0.0770237 (* 1 = 0.0770237 loss)
I0916 18:44:45.696808 20216 sgd_solver.cpp:136] Iteration 30300, lr = 0.001, m = 0.9
I0916 18:45:05.374202 20216 solver.cpp:314] Iteration 30400 (5.0821 iter/s, 19.6769s/100 iter), loss = 0.0713458
I0916 18:45:05.374228 20216 solver.cpp:336]     Train net output #0: loss = 0.0713459 (* 1 = 0.0713459 loss)
I0916 18:45:05.374231 20216 sgd_solver.cpp:136] Iteration 30400, lr = 0.001, m = 0.9
I0916 18:45:24.909066 20216 solver.cpp:314] Iteration 30500 (5.11919 iter/s, 19.5343s/100 iter), loss = 0.0847558
I0916 18:45:24.909116 20216 solver.cpp:336]     Train net output #0: loss = 0.0847559 (* 1 = 0.0847559 loss)
I0916 18:45:24.909121 20216 sgd_solver.cpp:136] Iteration 30500, lr = 0.001, m = 0.9
I0916 18:45:39.257985 20197 data_reader.cpp:305] Starting prefetch of epoch 17
I0916 18:45:44.686408 20216 solver.cpp:314] Iteration 30600 (5.05643 iter/s, 19.7768s/100 iter), loss = 0.0555314
I0916 18:45:44.686435 20216 solver.cpp:336]     Train net output #0: loss = 0.0555314 (* 1 = 0.0555314 loss)
I0916 18:45:44.686441 20216 sgd_solver.cpp:136] Iteration 30600, lr = 0.001, m = 0.9
I0916 18:46:04.542682 20216 solver.cpp:314] Iteration 30700 (5.03633 iter/s, 19.8557s/100 iter), loss = 0.178002
I0916 18:46:04.542737 20216 solver.cpp:336]     Train net output #0: loss = 0.178002 (* 1 = 0.178002 loss)
I0916 18:46:04.542742 20216 sgd_solver.cpp:136] Iteration 30700, lr = 0.001, m = 0.9
I0916 18:46:12.135844 20197 data_reader.cpp:305] Starting prefetch of epoch 18
I0916 18:46:24.301138 20216 solver.cpp:314] Iteration 30800 (5.06126 iter/s, 19.7579s/100 iter), loss = 0.0567264
I0916 18:46:24.301162 20216 solver.cpp:336]     Train net output #0: loss = 0.0567265 (* 1 = 0.0567265 loss)
I0916 18:46:24.301167 20216 sgd_solver.cpp:136] Iteration 30800, lr = 0.001, m = 0.9
I0916 18:46:43.694195 20216 solver.cpp:314] Iteration 30900 (5.15663 iter/s, 19.3925s/100 iter), loss = 0.0817302
I0916 18:46:43.694278 20216 solver.cpp:336]     Train net output #0: loss = 0.0817302 (* 1 = 0.0817302 loss)
I0916 18:46:43.694285 20216 sgd_solver.cpp:136] Iteration 30900, lr = 0.001, m = 0.9
I0916 18:47:03.432962 20216 solver.cpp:314] Iteration 31000 (5.06631 iter/s, 19.7382s/100 iter), loss = 0.070202
I0916 18:47:03.432991 20216 solver.cpp:336]     Train net output #0: loss = 0.0702021 (* 1 = 0.0702021 loss)
I0916 18:47:03.432996 20216 sgd_solver.cpp:136] Iteration 31000, lr = 0.001, m = 0.9
I0916 18:47:16.818208 20224 data_reader.cpp:305] Starting prefetch of epoch 23
I0916 18:47:22.706475 20216 solver.cpp:314] Iteration 31100 (5.18861 iter/s, 19.273s/100 iter), loss = 0.0653389
I0916 18:47:22.706571 20216 solver.cpp:336]     Train net output #0: loss = 0.065339 (* 1 = 0.065339 loss)
I0916 18:47:22.706595 20216 sgd_solver.cpp:136] Iteration 31100, lr = 0.001, m = 0.9
I0916 18:47:42.138851 20216 solver.cpp:314] Iteration 31200 (5.14619 iter/s, 19.4318s/100 iter), loss = 0.10858
I0916 18:47:42.138873 20216 solver.cpp:336]     Train net output #0: loss = 0.10858 (* 1 = 0.10858 loss)
I0916 18:47:42.138877 20216 sgd_solver.cpp:136] Iteration 31200, lr = 0.001, m = 0.9
I0916 18:48:01.829407 20216 solver.cpp:314] Iteration 31300 (5.07872 iter/s, 19.69s/100 iter), loss = 0.0884442
I0916 18:48:01.829484 20216 solver.cpp:336]     Train net output #0: loss = 0.0884443 (* 1 = 0.0884443 loss)
I0916 18:48:01.829491 20216 sgd_solver.cpp:136] Iteration 31300, lr = 0.001, m = 0.9
I0916 18:48:21.016893 20197 data_reader.cpp:305] Starting prefetch of epoch 19
I0916 18:48:21.201232 20216 solver.cpp:314] Iteration 31400 (5.16228 iter/s, 19.3713s/100 iter), loss = 0.0521486
I0916 18:48:21.201258 20216 solver.cpp:336]     Train net output #0: loss = 0.0521487 (* 1 = 0.0521487 loss)
I0916 18:48:21.201262 20216 sgd_solver.cpp:136] Iteration 31400, lr = 0.001, m = 0.9
I0916 18:48:40.684855 20216 solver.cpp:314] Iteration 31500 (5.13266 iter/s, 19.4831s/100 iter), loss = 0.0500479
I0916 18:48:40.684911 20216 solver.cpp:336]     Train net output #0: loss = 0.050048 (* 1 = 0.050048 loss)
I0916 18:48:40.684917 20216 sgd_solver.cpp:136] Iteration 31500, lr = 0.001, m = 0.9
I0916 18:48:53.332856 20220 data_reader.cpp:305] Starting prefetch of epoch 26
I0916 18:49:00.247565 20216 solver.cpp:314] Iteration 31600 (5.11191 iter/s, 19.5622s/100 iter), loss = 0.229671
I0916 18:49:00.247589 20216 solver.cpp:336]     Train net output #0: loss = 0.229671 (* 1 = 0.229671 loss)
I0916 18:49:00.247594 20216 sgd_solver.cpp:136] Iteration 31600, lr = 0.001, m = 0.9
I0916 18:49:19.849268 20216 solver.cpp:314] Iteration 31700 (5.10174 iter/s, 19.6012s/100 iter), loss = 0.0510296
I0916 18:49:19.849320 20216 solver.cpp:336]     Train net output #0: loss = 0.0510297 (* 1 = 0.0510297 loss)
I0916 18:49:19.849328 20216 sgd_solver.cpp:136] Iteration 31700, lr = 0.001, m = 0.9
I0916 18:49:39.359239 20216 solver.cpp:314] Iteration 31800 (5.12573 iter/s, 19.5094s/100 iter), loss = 0.0714204
I0916 18:49:39.359269 20216 solver.cpp:336]     Train net output #0: loss = 0.0714205 (* 1 = 0.0714205 loss)
I0916 18:49:39.359277 20216 sgd_solver.cpp:136] Iteration 31800, lr = 0.001, m = 0.9
I0916 18:49:57.827383 20219 data_reader.cpp:305] Starting prefetch of epoch 22
I0916 18:49:58.776474 20216 solver.cpp:314] Iteration 31900 (5.15021 iter/s, 19.4167s/100 iter), loss = 0.0340111
I0916 18:49:58.776500 20216 solver.cpp:336]     Train net output #0: loss = 0.0340112 (* 1 = 0.0340112 loss)
I0916 18:49:58.776505 20216 sgd_solver.cpp:136] Iteration 31900, lr = 0.001, m = 0.9
I0916 18:50:17.910006 20216 solver.cpp:563] Iteration 32000, Testing net (#0)
I0916 18:50:35.245177 20241 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 18:50:35.703531 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.952376
I0916 18:50:35.703553 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 18:50:35.703559 20216 solver.cpp:655]     Test net output #2: loss = 0.139993 (* 1 = 0.139993 loss)
I0916 18:50:35.703605 20216 solver.cpp:265] [MultiGPU] Tests completed in 17.7931s
I0916 18:50:35.917285 20216 solver.cpp:314] Iteration 32000 (2.69253 iter/s, 37.1398s/100 iter), loss = 0.0556578
I0916 18:50:35.917311 20216 solver.cpp:336]     Train net output #0: loss = 0.0556579 (* 1 = 0.0556579 loss)
I0916 18:50:35.917317 20216 sgd_solver.cpp:136] Iteration 32000, lr = 0.001, m = 0.9
I0916 18:50:47.484015 20219 data_reader.cpp:305] Starting prefetch of epoch 23
I0916 18:50:55.056968 20216 solver.cpp:314] Iteration 32100 (5.2249 iter/s, 19.1391s/100 iter), loss = 0.0941514
I0916 18:50:55.056993 20216 solver.cpp:336]     Train net output #0: loss = 0.0941515 (* 1 = 0.0941515 loss)
I0916 18:50:55.056999 20216 sgd_solver.cpp:136] Iteration 32100, lr = 0.001, m = 0.9
I0916 18:51:14.609938 20216 solver.cpp:314] Iteration 32200 (5.11446 iter/s, 19.5524s/100 iter), loss = 0.0559827
I0916 18:51:14.610002 20216 solver.cpp:336]     Train net output #0: loss = 0.0559828 (* 1 = 0.0559828 loss)
I0916 18:51:14.610008 20216 sgd_solver.cpp:136] Iteration 32200, lr = 0.001, m = 0.9
I0916 18:51:34.218010 20216 solver.cpp:314] Iteration 32300 (5.10008 iter/s, 19.6075s/100 iter), loss = 0.0632078
I0916 18:51:34.218034 20216 solver.cpp:336]     Train net output #0: loss = 0.0632079 (* 1 = 0.0632079 loss)
I0916 18:51:34.218040 20216 sgd_solver.cpp:136] Iteration 32300, lr = 0.001, m = 0.9
I0916 18:51:51.850239 20219 data_reader.cpp:305] Starting prefetch of epoch 24
I0916 18:51:53.549710 20216 solver.cpp:314] Iteration 32400 (5.173 iter/s, 19.3312s/100 iter), loss = 0.0568432
I0916 18:51:53.549736 20216 solver.cpp:336]     Train net output #0: loss = 0.0568433 (* 1 = 0.0568433 loss)
I0916 18:51:53.549741 20216 sgd_solver.cpp:136] Iteration 32400, lr = 0.001, m = 0.9
I0916 18:52:12.844264 20216 solver.cpp:314] Iteration 32500 (5.18296 iter/s, 19.294s/100 iter), loss = 0.0594617
I0916 18:52:12.844288 20216 solver.cpp:336]     Train net output #0: loss = 0.0594618 (* 1 = 0.0594618 loss)
I0916 18:52:12.844295 20216 sgd_solver.cpp:136] Iteration 32500, lr = 0.001, m = 0.9
I0916 18:52:32.214092 20216 solver.cpp:314] Iteration 32600 (5.16281 iter/s, 19.3693s/100 iter), loss = 0.0463058
I0916 18:52:32.214143 20216 solver.cpp:336]     Train net output #0: loss = 0.0463059 (* 1 = 0.0463059 loss)
I0916 18:52:32.214149 20216 sgd_solver.cpp:136] Iteration 32600, lr = 0.001, m = 0.9
I0916 18:52:51.698633 20216 solver.cpp:314] Iteration 32700 (5.13242 iter/s, 19.484s/100 iter), loss = 0.0627425
I0916 18:52:51.698664 20216 solver.cpp:336]     Train net output #0: loss = 0.0627426 (* 1 = 0.0627426 loss)
I0916 18:52:51.698671 20216 sgd_solver.cpp:136] Iteration 32700, lr = 0.001, m = 0.9
I0916 18:52:55.682122 20224 data_reader.cpp:305] Starting prefetch of epoch 24
I0916 18:53:11.244705 20216 solver.cpp:314] Iteration 32800 (5.11626 iter/s, 19.5455s/100 iter), loss = 0.0591683
I0916 18:53:11.244959 20216 solver.cpp:336]     Train net output #0: loss = 0.0591684 (* 1 = 0.0591684 loss)
I0916 18:53:11.255120 20216 sgd_solver.cpp:136] Iteration 32800, lr = 0.001, m = 0.9
I0916 18:53:28.392000 20219 data_reader.cpp:305] Starting prefetch of epoch 25
I0916 18:53:30.833562 20216 solver.cpp:314] Iteration 32900 (5.10509 iter/s, 19.5883s/100 iter), loss = 0.0796334
I0916 18:53:30.833591 20216 solver.cpp:336]     Train net output #0: loss = 0.0796335 (* 1 = 0.0796335 loss)
I0916 18:53:30.833598 20216 sgd_solver.cpp:136] Iteration 32900, lr = 0.001, m = 0.9
I0916 18:53:50.278328 20216 solver.cpp:314] Iteration 33000 (5.14292 iter/s, 19.4442s/100 iter), loss = 0.0633031
I0916 18:53:50.278388 20216 solver.cpp:336]     Train net output #0: loss = 0.0633033 (* 1 = 0.0633033 loss)
I0916 18:53:50.278393 20216 sgd_solver.cpp:136] Iteration 33000, lr = 0.001, m = 0.9
I0916 18:54:09.695581 20216 solver.cpp:314] Iteration 33100 (5.15021 iter/s, 19.4167s/100 iter), loss = 0.0677081
I0916 18:54:09.695602 20216 solver.cpp:336]     Train net output #0: loss = 0.0677082 (* 1 = 0.0677082 loss)
I0916 18:54:09.695607 20216 sgd_solver.cpp:136] Iteration 33100, lr = 0.001, m = 0.9
I0916 18:54:29.070919 20216 solver.cpp:314] Iteration 33200 (5.16135 iter/s, 19.3748s/100 iter), loss = 0.0818252
I0916 18:54:29.070973 20216 solver.cpp:336]     Train net output #0: loss = 0.0818253 (* 1 = 0.0818253 loss)
I0916 18:54:29.070979 20216 sgd_solver.cpp:136] Iteration 33200, lr = 0.001, m = 0.9
I0916 18:54:32.408188 20219 data_reader.cpp:305] Starting prefetch of epoch 26
I0916 18:54:48.605355 20216 solver.cpp:314] Iteration 33300 (5.11931 iter/s, 19.5339s/100 iter), loss = 0.0649468
I0916 18:54:48.605377 20216 solver.cpp:336]     Train net output #0: loss = 0.064947 (* 1 = 0.064947 loss)
I0916 18:54:48.605383 20216 sgd_solver.cpp:136] Iteration 33300, lr = 0.001, m = 0.9
I0916 18:55:08.102262 20216 solver.cpp:314] Iteration 33400 (5.12916 iter/s, 19.4964s/100 iter), loss = 0.053372
I0916 18:55:08.102319 20216 solver.cpp:336]     Train net output #0: loss = 0.0533722 (* 1 = 0.0533722 loss)
I0916 18:55:08.102326 20216 sgd_solver.cpp:136] Iteration 33400, lr = 0.001, m = 0.9
I0916 18:55:27.520299 20216 solver.cpp:314] Iteration 33500 (5.15 iter/s, 19.4175s/100 iter), loss = 0.0650325
I0916 18:55:27.520361 20216 solver.cpp:336]     Train net output #0: loss = 0.0650327 (* 1 = 0.0650327 loss)
I0916 18:55:27.520375 20216 sgd_solver.cpp:136] Iteration 33500, lr = 0.001, m = 0.9
I0916 18:55:36.966827 20223 data_reader.cpp:305] Starting prefetch of epoch 14
I0916 18:55:47.317200 20216 solver.cpp:314] Iteration 33600 (5.05144 iter/s, 19.7963s/100 iter), loss = 0.0559228
I0916 18:55:47.317314 20216 solver.cpp:336]     Train net output #0: loss = 0.0559229 (* 1 = 0.0559229 loss)
I0916 18:55:47.317322 20216 sgd_solver.cpp:136] Iteration 33600, lr = 0.001, m = 0.9
I0916 18:56:06.937256 20216 solver.cpp:314] Iteration 33700 (5.09697 iter/s, 19.6195s/100 iter), loss = 0.11815
I0916 18:56:06.937288 20216 solver.cpp:336]     Train net output #0: loss = 0.11815 (* 1 = 0.11815 loss)
I0916 18:56:06.937295 20216 sgd_solver.cpp:136] Iteration 33700, lr = 0.001, m = 0.9
I0916 18:56:09.580379 20195 data_reader.cpp:305] Starting prefetch of epoch 11
I0916 18:56:26.542970 20216 solver.cpp:314] Iteration 33800 (5.1007 iter/s, 19.6052s/100 iter), loss = 0.0527528
I0916 18:56:26.543043 20216 solver.cpp:336]     Train net output #0: loss = 0.0527529 (* 1 = 0.0527529 loss)
I0916 18:56:26.543051 20216 sgd_solver.cpp:136] Iteration 33800, lr = 0.001, m = 0.9
I0916 18:56:46.046152 20216 solver.cpp:314] Iteration 33900 (5.12751 iter/s, 19.5026s/100 iter), loss = 0.0480229
I0916 18:56:46.046174 20216 solver.cpp:336]     Train net output #0: loss = 0.048023 (* 1 = 0.048023 loss)
I0916 18:56:46.046178 20216 sgd_solver.cpp:136] Iteration 33900, lr = 0.001, m = 0.9
I0916 18:57:05.250099 20216 solver.cpp:563] Iteration 34000, Testing net (#0)
I0916 18:57:12.174511 20250 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 18:57:16.190225 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.95642
I0916 18:57:16.190248 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 18:57:16.190253 20216 solver.cpp:655]     Test net output #2: loss = 0.154197 (* 1 = 0.154197 loss)
I0916 18:57:16.190279 20216 solver.cpp:265] [MultiGPU] Tests completed in 10.9399s
I0916 18:57:16.399001 20216 solver.cpp:314] Iteration 34000 (3.29468 iter/s, 30.352s/100 iter), loss = 0.0933967
I0916 18:57:16.399025 20216 solver.cpp:336]     Train net output #0: loss = 0.0933968 (* 1 = 0.0933968 loss)
I0916 18:57:16.399030 20216 sgd_solver.cpp:136] Iteration 34000, lr = 0.001, m = 0.9
I0916 18:57:35.853349 20216 solver.cpp:314] Iteration 34100 (5.14038 iter/s, 19.4538s/100 iter), loss = 0.0569183
I0916 18:57:35.853622 20216 solver.cpp:336]     Train net output #0: loss = 0.0569184 (* 1 = 0.0569184 loss)
I0916 18:57:35.853629 20216 sgd_solver.cpp:136] Iteration 34100, lr = 0.001, m = 0.9
I0916 18:57:55.372088 20216 solver.cpp:314] Iteration 34200 (5.12343 iter/s, 19.5182s/100 iter), loss = 0.043982
I0916 18:57:55.372115 20216 solver.cpp:336]     Train net output #0: loss = 0.0439822 (* 1 = 0.0439822 loss)
I0916 18:57:55.372120 20216 sgd_solver.cpp:136] Iteration 34200, lr = 0.001, m = 0.9
I0916 18:57:57.127060 20197 data_reader.cpp:305] Starting prefetch of epoch 20
I0916 18:58:14.684836 20216 solver.cpp:314] Iteration 34300 (5.17807 iter/s, 19.3122s/100 iter), loss = 0.0531904
I0916 18:58:14.698179 20216 solver.cpp:336]     Train net output #0: loss = 0.0531906 (* 1 = 0.0531906 loss)
I0916 18:58:14.698232 20216 sgd_solver.cpp:136] Iteration 34300, lr = 0.001, m = 0.9
I0916 18:58:34.064692 20216 solver.cpp:314] Iteration 34400 (5.16014 iter/s, 19.3793s/100 iter), loss = 0.0598831
I0916 18:58:34.064713 20216 solver.cpp:336]     Train net output #0: loss = 0.0598833 (* 1 = 0.0598833 loss)
I0916 18:58:34.064718 20216 sgd_solver.cpp:136] Iteration 34400, lr = 0.001, m = 0.9
I0916 18:58:53.381711 20216 solver.cpp:314] Iteration 34500 (5.17693 iter/s, 19.3165s/100 iter), loss = 0.138205
I0916 18:58:53.381773 20216 solver.cpp:336]     Train net output #0: loss = 0.138205 (* 1 = 0.138205 loss)
I0916 18:58:53.381780 20216 sgd_solver.cpp:136] Iteration 34500, lr = 0.001, m = 0.9
I0916 18:59:01.103173 20197 data_reader.cpp:305] Starting prefetch of epoch 21
I0916 18:59:12.627598 20216 solver.cpp:314] Iteration 34600 (5.19606 iter/s, 19.2453s/100 iter), loss = 0.0783648
I0916 18:59:12.627634 20216 solver.cpp:336]     Train net output #0: loss = 0.0783649 (* 1 = 0.0783649 loss)
I0916 18:59:12.627640 20216 sgd_solver.cpp:136] Iteration 34600, lr = 0.001, m = 0.9
I0916 18:59:32.405452 20216 solver.cpp:314] Iteration 34700 (5.05635 iter/s, 19.7771s/100 iter), loss = 0.0466685
I0916 18:59:32.405563 20216 solver.cpp:336]     Train net output #0: loss = 0.0466686 (* 1 = 0.0466686 loss)
I0916 18:59:32.405571 20216 sgd_solver.cpp:136] Iteration 34700, lr = 0.001, m = 0.9
I0916 18:59:33.497597 20219 data_reader.cpp:305] Starting prefetch of epoch 27
I0916 18:59:51.871831 20216 solver.cpp:314] Iteration 34800 (5.13721 iter/s, 19.4658s/100 iter), loss = 0.064645
I0916 18:59:51.871867 20216 solver.cpp:336]     Train net output #0: loss = 0.0646451 (* 1 = 0.0646451 loss)
I0916 18:59:51.871872 20216 sgd_solver.cpp:136] Iteration 34800, lr = 0.001, m = 0.9
I0916 19:00:11.299962 20216 solver.cpp:314] Iteration 34900 (5.14732 iter/s, 19.4276s/100 iter), loss = 0.0731461
I0916 19:00:11.300019 20216 solver.cpp:336]     Train net output #0: loss = 0.0731462 (* 1 = 0.0731462 loss)
I0916 19:00:11.300026 20216 sgd_solver.cpp:136] Iteration 34900, lr = 0.001, m = 0.9
I0916 19:00:30.968544 20216 solver.cpp:314] Iteration 35000 (5.08439 iter/s, 19.668s/100 iter), loss = 0.0612922
I0916 19:00:30.968566 20216 solver.cpp:336]     Train net output #0: loss = 0.0612924 (* 1 = 0.0612924 loss)
I0916 19:00:30.968572 20216 sgd_solver.cpp:136] Iteration 35000, lr = 0.001, m = 0.9
I0916 19:00:37.897804 20219 data_reader.cpp:305] Starting prefetch of epoch 28
I0916 19:00:50.517982 20216 solver.cpp:314] Iteration 35100 (5.11538 iter/s, 19.5489s/100 iter), loss = 0.0661126
I0916 19:00:50.518085 20216 solver.cpp:336]     Train net output #0: loss = 0.0661128 (* 1 = 0.0661128 loss)
I0916 19:00:50.518091 20216 sgd_solver.cpp:136] Iteration 35100, lr = 0.001, m = 0.9
I0916 19:01:10.123559 20216 solver.cpp:314] Iteration 35200 (5.10073 iter/s, 19.605s/100 iter), loss = 0.0456435
I0916 19:01:10.123586 20216 solver.cpp:336]     Train net output #0: loss = 0.0456436 (* 1 = 0.0456436 loss)
I0916 19:01:10.123592 20216 sgd_solver.cpp:136] Iteration 35200, lr = 0.001, m = 0.9
I0916 19:01:29.660202 20216 solver.cpp:314] Iteration 35300 (5.11873 iter/s, 19.5361s/100 iter), loss = 0.0703739
I0916 19:01:29.660286 20216 solver.cpp:336]     Train net output #0: loss = 0.070374 (* 1 = 0.070374 loss)
I0916 19:01:29.660291 20216 sgd_solver.cpp:136] Iteration 35300, lr = 0.001, m = 0.9
I0916 19:01:42.645586 20224 data_reader.cpp:305] Starting prefetch of epoch 25
I0916 19:01:49.220105 20216 solver.cpp:314] Iteration 35400 (5.11264 iter/s, 19.5594s/100 iter), loss = 0.0625583
I0916 19:01:49.220134 20216 solver.cpp:336]     Train net output #0: loss = 0.0625584 (* 1 = 0.0625584 loss)
I0916 19:01:49.220141 20216 sgd_solver.cpp:136] Iteration 35400, lr = 0.001, m = 0.9
I0916 19:02:08.755250 20216 solver.cpp:314] Iteration 35500 (5.11912 iter/s, 19.5346s/100 iter), loss = 0.041792
I0916 19:02:08.755306 20216 solver.cpp:336]     Train net output #0: loss = 0.0417921 (* 1 = 0.0417921 loss)
I0916 19:02:08.755313 20216 sgd_solver.cpp:136] Iteration 35500, lr = 0.001, m = 0.9
I0916 19:02:14.766671 20220 data_reader.cpp:305] Starting prefetch of epoch 27
I0916 19:02:28.143056 20216 solver.cpp:314] Iteration 35600 (5.15802 iter/s, 19.3873s/100 iter), loss = 0.073099
I0916 19:02:28.143080 20216 solver.cpp:336]     Train net output #0: loss = 0.0730992 (* 1 = 0.0730992 loss)
I0916 19:02:28.143086 20216 sgd_solver.cpp:136] Iteration 35600, lr = 0.001, m = 0.9
I0916 19:02:47.506088 20216 solver.cpp:314] Iteration 35700 (5.16463 iter/s, 19.3625s/100 iter), loss = 0.0489297
I0916 19:02:47.506145 20216 solver.cpp:336]     Train net output #0: loss = 0.0489299 (* 1 = 0.0489299 loss)
I0916 19:02:47.506152 20216 sgd_solver.cpp:136] Iteration 35700, lr = 0.001, m = 0.9
I0916 19:03:06.879691 20216 solver.cpp:314] Iteration 35800 (5.16181 iter/s, 19.3731s/100 iter), loss = 0.0567843
I0916 19:03:06.879716 20216 solver.cpp:336]     Train net output #0: loss = 0.0567844 (* 1 = 0.0567844 loss)
I0916 19:03:06.879721 20216 sgd_solver.cpp:136] Iteration 35800, lr = 0.001, m = 0.9
I0916 19:03:19.028264 20224 data_reader.cpp:305] Starting prefetch of epoch 26
I0916 19:03:26.312796 20216 solver.cpp:314] Iteration 35900 (5.146 iter/s, 19.4326s/100 iter), loss = 0.062649
I0916 19:03:26.312822 20216 solver.cpp:336]     Train net output #0: loss = 0.0626492 (* 1 = 0.0626492 loss)
I0916 19:03:26.312829 20216 sgd_solver.cpp:136] Iteration 35900, lr = 0.001, m = 0.9
I0916 19:03:45.443786 20216 solver.cpp:563] Iteration 36000, Testing net (#0)
I0916 19:04:00.039221 20202 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 19:04:00.505813 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.953803
I0916 19:04:00.505836 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 19:04:00.505841 20216 solver.cpp:655]     Test net output #2: loss = 0.142396 (* 1 = 0.142396 loss)
I0916 19:04:00.505913 20216 solver.cpp:265] [MultiGPU] Tests completed in 15.0617s
I0916 19:04:00.703058 20216 solver.cpp:314] Iteration 36000 (2.90788 iter/s, 34.3893s/100 iter), loss = 0.0729639
I0916 19:04:00.703084 20216 solver.cpp:336]     Train net output #0: loss = 0.072964 (* 1 = 0.072964 loss)
I0916 19:04:00.703089 20216 sgd_solver.cpp:136] Iteration 36000, lr = 0.001, m = 0.9
I0916 19:04:05.977577 20195 data_reader.cpp:305] Starting prefetch of epoch 12
I0916 19:04:20.075834 20216 solver.cpp:314] Iteration 36100 (5.16203 iter/s, 19.3722s/100 iter), loss = 0.118119
I0916 19:04:20.075858 20216 solver.cpp:336]     Train net output #0: loss = 0.118119 (* 1 = 0.118119 loss)
I0916 19:04:20.075865 20216 sgd_solver.cpp:136] Iteration 36100, lr = 0.001, m = 0.9
I0916 19:04:39.523936 20216 solver.cpp:314] Iteration 36200 (5.14203 iter/s, 19.4476s/100 iter), loss = 0.0430572
I0916 19:04:39.524057 20216 solver.cpp:336]     Train net output #0: loss = 0.0430573 (* 1 = 0.0430573 loss)
I0916 19:04:39.524066 20216 sgd_solver.cpp:136] Iteration 36200, lr = 0.001, m = 0.9
I0916 19:04:58.848348 20216 solver.cpp:314] Iteration 36300 (5.17495 iter/s, 19.3239s/100 iter), loss = 0.0511251
I0916 19:04:58.848374 20216 solver.cpp:336]     Train net output #0: loss = 0.0511253 (* 1 = 0.0511253 loss)
I0916 19:04:58.848379 20216 sgd_solver.cpp:136] Iteration 36300, lr = 0.001, m = 0.9
I0916 19:05:10.185422 20195 data_reader.cpp:305] Starting prefetch of epoch 13
I0916 19:05:18.291105 20216 solver.cpp:314] Iteration 36400 (5.14345 iter/s, 19.4422s/100 iter), loss = 0.0479042
I0916 19:05:18.291127 20216 solver.cpp:336]     Train net output #0: loss = 0.0479043 (* 1 = 0.0479043 loss)
I0916 19:05:18.291133 20216 sgd_solver.cpp:136] Iteration 36400, lr = 0.001, m = 0.9
I0916 19:05:37.694006 20216 solver.cpp:314] Iteration 36500 (5.15401 iter/s, 19.4024s/100 iter), loss = 0.0795036
I0916 19:05:37.694034 20216 solver.cpp:336]     Train net output #0: loss = 0.0795038 (* 1 = 0.0795038 loss)
I0916 19:05:37.694041 20216 sgd_solver.cpp:136] Iteration 36500, lr = 0.001, m = 0.9
I0916 19:05:57.338719 20216 solver.cpp:314] Iteration 36600 (5.09057 iter/s, 19.6442s/100 iter), loss = 0.0641449
I0916 19:05:57.338799 20216 solver.cpp:336]     Train net output #0: loss = 0.0641451 (* 1 = 0.0641451 loss)
I0916 19:05:57.338806 20216 sgd_solver.cpp:136] Iteration 36600, lr = 0.001, m = 0.9
I0916 19:06:14.483000 20223 data_reader.cpp:305] Starting prefetch of epoch 15
I0916 19:06:16.764622 20216 solver.cpp:314] Iteration 36700 (5.14791 iter/s, 19.4254s/100 iter), loss = 0.0576656
I0916 19:06:16.764652 20216 solver.cpp:336]     Train net output #0: loss = 0.0576657 (* 1 = 0.0576657 loss)
I0916 19:06:16.764659 20216 sgd_solver.cpp:136] Iteration 36700, lr = 0.001, m = 0.9
I0916 19:06:36.179425 20216 solver.cpp:314] Iteration 36800 (5.15085 iter/s, 19.4143s/100 iter), loss = 0.0554914
I0916 19:06:36.179499 20216 solver.cpp:336]     Train net output #0: loss = 0.0554916 (* 1 = 0.0554916 loss)
I0916 19:06:36.179507 20216 sgd_solver.cpp:136] Iteration 36800, lr = 0.001, m = 0.9
I0916 19:06:46.577702 20219 data_reader.cpp:305] Starting prefetch of epoch 29
I0916 19:06:55.701792 20216 solver.cpp:314] Iteration 36900 (5.12247 iter/s, 19.5218s/100 iter), loss = 0.0575411
I0916 19:06:55.701819 20216 solver.cpp:336]     Train net output #0: loss = 0.0575413 (* 1 = 0.0575413 loss)
I0916 19:06:55.701825 20216 sgd_solver.cpp:136] Iteration 36900, lr = 0.001, m = 0.9
I0916 19:07:15.482702 20216 solver.cpp:314] Iteration 37000 (5.05552 iter/s, 19.7804s/100 iter), loss = 0.0601313
I0916 19:07:15.482754 20216 solver.cpp:336]     Train net output #0: loss = 0.0601315 (* 1 = 0.0601315 loss)
I0916 19:07:15.482761 20216 sgd_solver.cpp:136] Iteration 37000, lr = 0.001, m = 0.9
I0916 19:07:35.108541 20216 solver.cpp:314] Iteration 37100 (5.09547 iter/s, 19.6253s/100 iter), loss = 0.0715058
I0916 19:07:35.108563 20216 solver.cpp:336]     Train net output #0: loss = 0.071506 (* 1 = 0.071506 loss)
I0916 19:07:35.108569 20216 sgd_solver.cpp:136] Iteration 37100, lr = 0.001, m = 0.9
I0916 19:07:51.225901 20195 data_reader.cpp:305] Starting prefetch of epoch 14
I0916 19:07:54.277974 20216 solver.cpp:314] Iteration 37200 (5.21678 iter/s, 19.1689s/100 iter), loss = 0.0514527
I0916 19:07:54.277999 20216 solver.cpp:336]     Train net output #0: loss = 0.0514529 (* 1 = 0.0514529 loss)
I0916 19:07:54.278003 20216 sgd_solver.cpp:136] Iteration 37200, lr = 0.001, m = 0.9
I0916 19:08:13.593729 20216 solver.cpp:314] Iteration 37300 (5.17727 iter/s, 19.3152s/100 iter), loss = 0.0636414
I0916 19:08:13.593758 20216 solver.cpp:336]     Train net output #0: loss = 0.0636416 (* 1 = 0.0636416 loss)
I0916 19:08:13.593765 20216 sgd_solver.cpp:136] Iteration 37300, lr = 0.001, m = 0.9
I0916 19:08:33.094812 20216 solver.cpp:314] Iteration 37400 (5.12806 iter/s, 19.5005s/100 iter), loss = 0.0738609
I0916 19:08:33.094866 20216 solver.cpp:336]     Train net output #0: loss = 0.0738611 (* 1 = 0.0738611 loss)
I0916 19:08:33.094871 20216 sgd_solver.cpp:136] Iteration 37400, lr = 0.001, m = 0.9
I0916 19:08:52.526270 20216 solver.cpp:314] Iteration 37500 (5.14644 iter/s, 19.4309s/100 iter), loss = 0.043533
I0916 19:08:52.526296 20216 solver.cpp:336]     Train net output #0: loss = 0.0435332 (* 1 = 0.0435332 loss)
I0916 19:08:52.526304 20216 sgd_solver.cpp:136] Iteration 37500, lr = 0.001, m = 0.9
I0916 19:08:55.465584 20197 data_reader.cpp:305] Starting prefetch of epoch 22
I0916 19:09:12.054749 20216 solver.cpp:314] Iteration 37600 (5.12087 iter/s, 19.5279s/100 iter), loss = 0.0378196
I0916 19:09:12.054800 20216 solver.cpp:336]     Train net output #0: loss = 0.0378198 (* 1 = 0.0378198 loss)
I0916 19:09:12.054806 20216 sgd_solver.cpp:136] Iteration 37600, lr = 0.001, m = 0.9
I0916 19:09:31.778599 20216 solver.cpp:314] Iteration 37700 (5.07015 iter/s, 19.7233s/100 iter), loss = 0.0636438
I0916 19:09:31.778625 20216 solver.cpp:336]     Train net output #0: loss = 0.0636439 (* 1 = 0.0636439 loss)
I0916 19:09:31.778630 20216 sgd_solver.cpp:136] Iteration 37700, lr = 0.001, m = 0.9
I0916 19:09:51.130893 20216 solver.cpp:314] Iteration 37800 (5.16749 iter/s, 19.3518s/100 iter), loss = 0.0462049
I0916 19:09:51.130981 20216 solver.cpp:336]     Train net output #0: loss = 0.0462051 (* 1 = 0.0462051 loss)
I0916 19:09:51.130990 20216 sgd_solver.cpp:136] Iteration 37800, lr = 0.001, m = 0.9
I0916 19:09:59.730793 20223 data_reader.cpp:305] Starting prefetch of epoch 16
I0916 19:10:10.435570 20216 solver.cpp:314] Iteration 37900 (5.18024 iter/s, 19.3041s/100 iter), loss = 0.0665248
I0916 19:10:10.435603 20216 solver.cpp:336]     Train net output #0: loss = 0.066525 (* 1 = 0.066525 loss)
I0916 19:10:10.435611 20216 sgd_solver.cpp:136] Iteration 37900, lr = 0.001, m = 0.9
I0916 19:10:29.676525 20216 solver.cpp:563] Iteration 38000, Testing net (#0)
I0916 19:10:38.613641 20243 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 19:10:42.411550 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.956852
I0916 19:10:42.411576 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 19:10:42.411582 20216 solver.cpp:655]     Test net output #2: loss = 0.163453 (* 1 = 0.163453 loss)
I0916 19:10:42.411608 20216 solver.cpp:265] [MultiGPU] Tests completed in 12.7347s
I0916 19:10:42.615193 20216 solver.cpp:314] Iteration 38000 (3.10764 iter/s, 32.1787s/100 iter), loss = 0.0555672
I0916 19:10:42.615218 20216 solver.cpp:336]     Train net output #0: loss = 0.0555674 (* 1 = 0.0555674 loss)
I0916 19:10:42.615226 20216 sgd_solver.cpp:136] Iteration 38000, lr = 0.001, m = 0.9
I0916 19:11:02.000867 20216 solver.cpp:314] Iteration 38100 (5.1586 iter/s, 19.3851s/100 iter), loss = 0.0749946
I0916 19:11:02.000962 20216 solver.cpp:336]     Train net output #0: loss = 0.0749948 (* 1 = 0.0749948 loss)
I0916 19:11:02.000969 20216 sgd_solver.cpp:136] Iteration 38100, lr = 0.001, m = 0.9
I0916 19:11:16.948406 20195 data_reader.cpp:305] Starting prefetch of epoch 15
I0916 19:11:21.518239 20216 solver.cpp:314] Iteration 38200 (5.12379 iter/s, 19.5168s/100 iter), loss = 0.0745441
I0916 19:11:21.518265 20216 solver.cpp:336]     Train net output #0: loss = 0.0745442 (* 1 = 0.0745442 loss)
I0916 19:11:21.518270 20216 sgd_solver.cpp:136] Iteration 38200, lr = 0.001, m = 0.9
I0916 19:11:41.010331 20216 solver.cpp:314] Iteration 38300 (5.13043 iter/s, 19.4915s/100 iter), loss = 0.0572347
I0916 19:11:41.010421 20216 solver.cpp:336]     Train net output #0: loss = 0.0572349 (* 1 = 0.0572349 loss)
I0916 19:11:41.010429 20216 sgd_solver.cpp:136] Iteration 38300, lr = 0.001, m = 0.9
I0916 19:12:00.362439 20216 solver.cpp:314] Iteration 38400 (5.16754 iter/s, 19.3516s/100 iter), loss = 0.0605259
I0916 19:12:00.362462 20216 solver.cpp:336]     Train net output #0: loss = 0.060526 (* 1 = 0.060526 loss)
I0916 19:12:00.362468 20216 sgd_solver.cpp:136] Iteration 38400, lr = 0.001, m = 0.9
I0916 19:12:19.758021 20216 solver.cpp:314] Iteration 38500 (5.15596 iter/s, 19.395s/100 iter), loss = 0.0571834
I0916 19:12:19.758075 20216 solver.cpp:336]     Train net output #0: loss = 0.0571836 (* 1 = 0.0571836 loss)
I0916 19:12:19.758083 20216 sgd_solver.cpp:136] Iteration 38500, lr = 0.001, m = 0.9
I0916 19:12:20.891371 20224 data_reader.cpp:305] Starting prefetch of epoch 27
I0916 19:12:39.098579 20216 solver.cpp:314] Iteration 38600 (5.17063 iter/s, 19.34s/100 iter), loss = 0.0494841
I0916 19:12:39.098604 20216 solver.cpp:336]     Train net output #0: loss = 0.0494843 (* 1 = 0.0494843 loss)
I0916 19:12:39.098613 20216 sgd_solver.cpp:136] Iteration 38600, lr = 0.001, m = 0.9
I0916 19:12:52.906915 20220 data_reader.cpp:305] Starting prefetch of epoch 28
I0916 19:12:58.501399 20216 solver.cpp:314] Iteration 38700 (5.15403 iter/s, 19.4023s/100 iter), loss = 0.081061
I0916 19:12:58.501426 20216 solver.cpp:336]     Train net output #0: loss = 0.0810612 (* 1 = 0.0810612 loss)
I0916 19:12:58.501432 20216 sgd_solver.cpp:136] Iteration 38700, lr = 0.001, m = 0.9
I0916 19:13:17.962388 20216 solver.cpp:314] Iteration 38800 (5.13863 iter/s, 19.4604s/100 iter), loss = 0.0760306
I0916 19:13:17.962414 20216 solver.cpp:336]     Train net output #0: loss = 0.0760307 (* 1 = 0.0760307 loss)
I0916 19:13:17.962420 20216 sgd_solver.cpp:136] Iteration 38800, lr = 0.001, m = 0.9
I0916 19:13:37.567113 20216 solver.cpp:314] Iteration 38900 (5.10096 iter/s, 19.6042s/100 iter), loss = 0.143033
I0916 19:13:37.567174 20216 solver.cpp:336]     Train net output #0: loss = 0.143033 (* 1 = 0.143033 loss)
I0916 19:13:37.567181 20216 sgd_solver.cpp:136] Iteration 38900, lr = 0.001, m = 0.9
I0916 19:13:57.003072 20216 solver.cpp:314] Iteration 39000 (5.14525 iter/s, 19.4354s/100 iter), loss = 0.0601723
I0916 19:13:57.003096 20216 solver.cpp:336]     Train net output #0: loss = 0.0601724 (* 1 = 0.0601724 loss)
I0916 19:13:57.003101 20216 sgd_solver.cpp:136] Iteration 39000, lr = 0.001, m = 0.9
I0916 19:13:57.417217 20195 data_reader.cpp:305] Starting prefetch of epoch 16
I0916 19:14:16.537184 20216 solver.cpp:314] Iteration 39100 (5.11939 iter/s, 19.5336s/100 iter), loss = 0.03149
I0916 19:14:16.537292 20216 solver.cpp:336]     Train net output #0: loss = 0.0314901 (* 1 = 0.0314901 loss)
I0916 19:14:16.537299 20216 sgd_solver.cpp:136] Iteration 39100, lr = 0.001, m = 0.9
I0916 19:14:36.041937 20216 solver.cpp:314] Iteration 39200 (5.1271 iter/s, 19.5042s/100 iter), loss = 0.0667224
I0916 19:14:36.041960 20216 solver.cpp:336]     Train net output #0: loss = 0.0667225 (* 1 = 0.0667225 loss)
I0916 19:14:36.041965 20216 sgd_solver.cpp:136] Iteration 39200, lr = 0.001, m = 0.9
I0916 19:14:55.657625 20216 solver.cpp:314] Iteration 39300 (5.0981 iter/s, 19.6151s/100 iter), loss = 0.0548848
I0916 19:14:55.657686 20216 solver.cpp:336]     Train net output #0: loss = 0.0548849 (* 1 = 0.0548849 loss)
I0916 19:14:55.657693 20216 sgd_solver.cpp:136] Iteration 39300, lr = 0.001, m = 0.9
I0916 19:15:02.093142 20197 data_reader.cpp:305] Starting prefetch of epoch 23
I0916 19:15:15.268862 20216 solver.cpp:314] Iteration 39400 (5.09926 iter/s, 19.6107s/100 iter), loss = 0.0540241
I0916 19:15:15.268887 20216 solver.cpp:336]     Train net output #0: loss = 0.0540242 (* 1 = 0.0540242 loss)
I0916 19:15:15.268892 20216 sgd_solver.cpp:136] Iteration 39400, lr = 0.001, m = 0.9
I0916 19:15:34.408946 20220 data_reader.cpp:305] Starting prefetch of epoch 29
I0916 19:15:34.754010 20216 solver.cpp:314] Iteration 39500 (5.13226 iter/s, 19.4846s/100 iter), loss = 0.0514948
I0916 19:15:34.754037 20216 solver.cpp:336]     Train net output #0: loss = 0.051495 (* 1 = 0.051495 loss)
I0916 19:15:34.754043 20216 sgd_solver.cpp:136] Iteration 39500, lr = 0.001, m = 0.9
I0916 19:15:54.409126 20216 solver.cpp:314] Iteration 39600 (5.08828 iter/s, 19.653s/100 iter), loss = 0.0649157
I0916 19:15:54.409160 20216 solver.cpp:336]     Train net output #0: loss = 0.0649159 (* 1 = 0.0649159 loss)
I0916 19:15:54.409166 20216 sgd_solver.cpp:136] Iteration 39600, lr = 0.001, m = 0.9
I0916 19:16:14.285799 20216 solver.cpp:314] Iteration 39700 (5.03117 iter/s, 19.8761s/100 iter), loss = 0.0608769
I0916 19:16:14.285888 20216 solver.cpp:336]     Train net output #0: loss = 0.0608771 (* 1 = 0.0608771 loss)
I0916 19:16:14.285903 20216 sgd_solver.cpp:136] Iteration 39700, lr = 0.001, m = 0.9
I0916 19:16:34.171052 20216 solver.cpp:314] Iteration 39800 (5.02899 iter/s, 19.8847s/100 iter), loss = 0.0497209
I0916 19:16:34.171077 20216 solver.cpp:336]     Train net output #0: loss = 0.049721 (* 1 = 0.049721 loss)
I0916 19:16:34.171084 20216 sgd_solver.cpp:136] Iteration 39800, lr = 0.001, m = 0.9
I0916 19:16:39.620805 20220 data_reader.cpp:305] Starting prefetch of epoch 30
I0916 19:16:53.798207 20216 solver.cpp:314] Iteration 39900 (5.09512 iter/s, 19.6266s/100 iter), loss = 0.0643509
I0916 19:16:53.798295 20216 solver.cpp:336]     Train net output #0: loss = 0.064351 (* 1 = 0.064351 loss)
I0916 19:16:53.798301 20216 sgd_solver.cpp:136] Iteration 39900, lr = 0.001, m = 0.9
I0916 19:17:13.119015 20216 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/cityscapes5_jsegnet21v2_iter_40000.caffemodel
I0916 19:17:13.263355 20216 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/cityscapes5_jsegnet21v2_iter_40000.solverstate
I0916 19:17:13.269207 20216 solver.cpp:563] Iteration 40000, Testing net (#0)
I0916 19:17:24.253942 20250 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 19:17:24.253942 20243 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 19:17:40.301115 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.954239
I0916 19:17:40.301137 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 19:17:40.301144 20216 solver.cpp:655]     Test net output #2: loss = 0.145345 (* 1 = 0.145345 loss)
I0916 19:17:40.301174 20216 solver.cpp:265] [MultiGPU] Tests completed in 27.0312s
I0916 19:17:40.507498 20216 solver.cpp:314] Iteration 40000 (2.14096 iter/s, 46.708s/100 iter), loss = 0.0899561
I0916 19:17:40.507524 20216 solver.cpp:336]     Train net output #0: loss = 0.0899562 (* 1 = 0.0899562 loss)
I0916 19:17:40.507530 20216 sgd_solver.cpp:136] Iteration 40000, lr = 0.001, m = 0.9
I0916 19:18:00.011442 20216 solver.cpp:314] Iteration 40100 (5.12731 iter/s, 19.5034s/100 iter), loss = 0.0591968
I0916 19:18:00.011521 20216 solver.cpp:336]     Train net output #0: loss = 0.0591969 (* 1 = 0.0591969 loss)
I0916 19:18:00.011529 20216 sgd_solver.cpp:136] Iteration 40100, lr = 0.001, m = 0.9
I0916 19:18:11.609560 20224 data_reader.cpp:305] Starting prefetch of epoch 28
I0916 19:18:19.810853 20216 solver.cpp:314] Iteration 40200 (5.0508 iter/s, 19.7989s/100 iter), loss = 0.0403331
I0916 19:18:19.810881 20216 solver.cpp:336]     Train net output #0: loss = 0.0403333 (* 1 = 0.0403333 loss)
I0916 19:18:19.810887 20216 sgd_solver.cpp:136] Iteration 40200, lr = 0.001, m = 0.9
I0916 19:18:39.767352 20216 solver.cpp:314] Iteration 40300 (5.01104 iter/s, 19.9559s/100 iter), loss = 0.0712959
I0916 19:18:39.767444 20216 solver.cpp:336]     Train net output #0: loss = 0.0712961 (* 1 = 0.0712961 loss)
I0916 19:18:39.767452 20216 sgd_solver.cpp:136] Iteration 40300, lr = 0.001, m = 0.9
I0916 19:18:44.562410 20195 data_reader.cpp:305] Starting prefetch of epoch 17
I0916 19:18:59.905891 20216 solver.cpp:314] Iteration 40400 (4.96574 iter/s, 20.138s/100 iter), loss = 0.078479
I0916 19:18:59.905920 20216 solver.cpp:336]     Train net output #0: loss = 0.0784791 (* 1 = 0.0784791 loss)
I0916 19:18:59.905927 20216 sgd_solver.cpp:136] Iteration 40400, lr = 0.001, m = 0.9
I0916 19:19:19.723223 20216 solver.cpp:314] Iteration 40500 (5.04623 iter/s, 19.8168s/100 iter), loss = 0.0650843
I0916 19:19:19.723284 20216 solver.cpp:336]     Train net output #0: loss = 0.0650845 (* 1 = 0.0650845 loss)
I0916 19:19:19.723289 20216 sgd_solver.cpp:136] Iteration 40500, lr = 0.001, m = 0.9
I0916 19:19:39.766801 20216 solver.cpp:314] Iteration 40600 (4.98927 iter/s, 20.043s/100 iter), loss = 0.0635055
I0916 19:19:39.766829 20216 solver.cpp:336]     Train net output #0: loss = 0.0635056 (* 1 = 0.0635056 loss)
I0916 19:19:39.766835 20216 sgd_solver.cpp:136] Iteration 40600, lr = 0.001, m = 0.9
I0916 19:19:50.880558 20219 data_reader.cpp:305] Starting prefetch of epoch 30
I0916 19:19:59.599300 20216 solver.cpp:314] Iteration 40700 (5.04237 iter/s, 19.8319s/100 iter), loss = 0.0655935
I0916 19:19:59.599325 20216 solver.cpp:336]     Train net output #0: loss = 0.0655936 (* 1 = 0.0655936 loss)
I0916 19:19:59.599331 20216 sgd_solver.cpp:136] Iteration 40700, lr = 0.001, m = 0.9
I0916 19:20:19.219476 20216 solver.cpp:314] Iteration 40800 (5.09694 iter/s, 19.6196s/100 iter), loss = 0.098044
I0916 19:20:19.219506 20216 solver.cpp:336]     Train net output #0: loss = 0.0980442 (* 1 = 0.0980442 loss)
I0916 19:20:19.219512 20216 sgd_solver.cpp:136] Iteration 40800, lr = 0.001, m = 0.9
I0916 19:20:38.695466 20216 solver.cpp:314] Iteration 40900 (5.13467 iter/s, 19.4754s/100 iter), loss = 0.0508452
I0916 19:20:38.695519 20216 solver.cpp:336]     Train net output #0: loss = 0.0508453 (* 1 = 0.0508453 loss)
I0916 19:20:38.695524 20216 sgd_solver.cpp:136] Iteration 40900, lr = 0.001, m = 0.9
I0916 19:20:55.308068 20224 data_reader.cpp:305] Starting prefetch of epoch 29
I0916 19:20:58.209605 20216 solver.cpp:314] Iteration 41000 (5.12463 iter/s, 19.5136s/100 iter), loss = 0.0562186
I0916 19:20:58.209630 20216 solver.cpp:336]     Train net output #0: loss = 0.0562187 (* 1 = 0.0562187 loss)
I0916 19:20:58.209635 20216 sgd_solver.cpp:136] Iteration 41000, lr = 0.001, m = 0.9
I0916 19:21:17.719581 20216 solver.cpp:314] Iteration 41100 (5.12573 iter/s, 19.5094s/100 iter), loss = 0.0494201
I0916 19:21:17.719640 20216 solver.cpp:336]     Train net output #0: loss = 0.0494202 (* 1 = 0.0494202 loss)
I0916 19:21:17.719646 20216 sgd_solver.cpp:136] Iteration 41100, lr = 0.001, m = 0.9
I0916 19:21:27.796334 20220 data_reader.cpp:305] Starting prefetch of epoch 31
I0916 19:21:37.446902 20216 solver.cpp:314] Iteration 41200 (5.06925 iter/s, 19.7268s/100 iter), loss = 0.0466859
I0916 19:21:37.446933 20216 solver.cpp:336]     Train net output #0: loss = 0.0466861 (* 1 = 0.0466861 loss)
I0916 19:21:37.446940 20216 sgd_solver.cpp:136] Iteration 41200, lr = 0.001, m = 0.9
I0916 19:21:56.979166 20216 solver.cpp:314] Iteration 41300 (5.11988 iter/s, 19.5317s/100 iter), loss = 0.0296535
I0916 19:21:56.979305 20216 solver.cpp:336]     Train net output #0: loss = 0.0296537 (* 1 = 0.0296537 loss)
I0916 19:21:56.979326 20216 sgd_solver.cpp:136] Iteration 41300, lr = 0.001, m = 0.9
I0916 19:22:16.311303 20216 solver.cpp:314] Iteration 41400 (5.17288 iter/s, 19.3316s/100 iter), loss = 0.0931662
I0916 19:22:16.311331 20216 solver.cpp:336]     Train net output #0: loss = 0.0931663 (* 1 = 0.0931663 loss)
I0916 19:22:16.311336 20216 sgd_solver.cpp:136] Iteration 41400, lr = 0.001, m = 0.9
I0916 19:22:32.178009 20219 data_reader.cpp:305] Starting prefetch of epoch 31
I0916 19:22:35.799299 20216 solver.cpp:314] Iteration 41500 (5.13151 iter/s, 19.4875s/100 iter), loss = 0.0683348
I0916 19:22:35.799326 20216 solver.cpp:336]     Train net output #0: loss = 0.0683349 (* 1 = 0.0683349 loss)
I0916 19:22:35.799334 20216 sgd_solver.cpp:136] Iteration 41500, lr = 0.001, m = 0.9
I0916 19:22:55.687737 20216 solver.cpp:314] Iteration 41600 (5.02819 iter/s, 19.8879s/100 iter), loss = 0.0419055
I0916 19:22:55.687759 20216 solver.cpp:336]     Train net output #0: loss = 0.0419056 (* 1 = 0.0419056 loss)
I0916 19:22:55.687765 20216 sgd_solver.cpp:136] Iteration 41600, lr = 0.001, m = 0.9
I0916 19:23:16.031281 20216 solver.cpp:314] Iteration 41700 (4.9157 iter/s, 20.343s/100 iter), loss = 0.0798878
I0916 19:23:16.031335 20216 solver.cpp:336]     Train net output #0: loss = 0.0798879 (* 1 = 0.0798879 loss)
I0916 19:23:16.031342 20216 sgd_solver.cpp:136] Iteration 41700, lr = 0.001, m = 0.9
I0916 19:23:36.316645 20216 solver.cpp:314] Iteration 41800 (4.9298 iter/s, 20.2848s/100 iter), loss = 0.0550721
I0916 19:23:36.316673 20216 solver.cpp:336]     Train net output #0: loss = 0.0550722 (* 1 = 0.0550722 loss)
I0916 19:23:36.316679 20216 sgd_solver.cpp:136] Iteration 41800, lr = 0.001, m = 0.9
I0916 19:23:38.721918 20197 data_reader.cpp:305] Starting prefetch of epoch 24
I0916 19:23:56.106935 20216 solver.cpp:314] Iteration 41900 (5.05312 iter/s, 19.7897s/100 iter), loss = 0.0631242
I0916 19:23:56.106990 20216 solver.cpp:336]     Train net output #0: loss = 0.0631243 (* 1 = 0.0631243 loss)
I0916 19:23:56.106997 20216 sgd_solver.cpp:136] Iteration 41900, lr = 0.001, m = 0.9
I0916 19:24:12.017446 20219 data_reader.cpp:305] Starting prefetch of epoch 32
I0916 19:24:16.467857 20216 solver.cpp:563] Iteration 42000, Testing net (#0)
I0916 19:24:28.450134 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.956798
I0916 19:24:28.450191 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 19:24:28.450198 20216 solver.cpp:655]     Test net output #2: loss = 0.164333 (* 1 = 0.164333 loss)
I0916 19:24:28.450227 20216 solver.cpp:265] [MultiGPU] Tests completed in 11.982s
I0916 19:24:28.715129 20216 solver.cpp:314] Iteration 42000 (3.0668 iter/s, 32.6073s/100 iter), loss = 0.0483215
I0916 19:24:28.715160 20216 solver.cpp:336]     Train net output #0: loss = 0.0483216 (* 1 = 0.0483216 loss)
I0916 19:24:28.715167 20216 sgd_solver.cpp:136] Iteration 42000, lr = 0.001, m = 0.9
I0916 19:24:48.807770 20216 solver.cpp:314] Iteration 42100 (4.97709 iter/s, 20.0921s/100 iter), loss = 0.0420584
I0916 19:24:48.807793 20216 solver.cpp:336]     Train net output #0: loss = 0.0420586 (* 1 = 0.0420586 loss)
I0916 19:24:48.807799 20216 sgd_solver.cpp:136] Iteration 42100, lr = 0.001, m = 0.9
I0916 19:24:57.132053 20220 data_reader.cpp:305] Starting prefetch of epoch 32
I0916 19:25:08.507392 20216 solver.cpp:314] Iteration 42200 (5.07638 iter/s, 19.6991s/100 iter), loss = 0.0539177
I0916 19:25:08.507447 20216 solver.cpp:336]     Train net output #0: loss = 0.0539178 (* 1 = 0.0539178 loss)
I0916 19:25:08.507454 20216 sgd_solver.cpp:136] Iteration 42200, lr = 0.001, m = 0.9
I0916 19:25:28.522318 20216 solver.cpp:314] Iteration 42300 (4.99641 iter/s, 20.0144s/100 iter), loss = 0.0667785
I0916 19:25:28.522346 20216 solver.cpp:336]     Train net output #0: loss = 0.0667786 (* 1 = 0.0667786 loss)
I0916 19:25:28.522351 20216 sgd_solver.cpp:136] Iteration 42300, lr = 0.001, m = 0.9
I0916 19:25:48.803905 20216 solver.cpp:314] Iteration 42400 (4.93072 iter/s, 20.281s/100 iter), loss = 0.0505098
I0916 19:25:48.803977 20216 solver.cpp:336]     Train net output #0: loss = 0.0505099 (* 1 = 0.0505099 loss)
I0916 19:25:48.803985 20216 sgd_solver.cpp:136] Iteration 42400, lr = 0.001, m = 0.9
I0916 19:26:03.464998 20224 data_reader.cpp:305] Starting prefetch of epoch 30
I0916 19:26:08.704375 20216 solver.cpp:314] Iteration 42500 (5.02515 iter/s, 19.8999s/100 iter), loss = 0.0531794
I0916 19:26:08.704397 20216 solver.cpp:336]     Train net output #0: loss = 0.0531795 (* 1 = 0.0531795 loss)
I0916 19:26:08.704401 20216 sgd_solver.cpp:136] Iteration 42500, lr = 0.001, m = 0.9
I0916 19:26:28.443922 20216 solver.cpp:314] Iteration 42600 (5.06611 iter/s, 19.739s/100 iter), loss = 0.0733216
I0916 19:26:28.443982 20216 solver.cpp:336]     Train net output #0: loss = 0.0733218 (* 1 = 0.0733218 loss)
I0916 19:26:28.443989 20216 sgd_solver.cpp:136] Iteration 42600, lr = 0.001, m = 0.9
I0916 19:26:36.024938 20219 data_reader.cpp:305] Starting prefetch of epoch 33
I0916 19:26:48.385996 20216 solver.cpp:314] Iteration 42700 (5.01466 iter/s, 19.9415s/100 iter), loss = 0.0479362
I0916 19:26:48.386026 20216 solver.cpp:336]     Train net output #0: loss = 0.0479364 (* 1 = 0.0479364 loss)
I0916 19:26:48.386032 20216 sgd_solver.cpp:136] Iteration 42700, lr = 0.001, m = 0.9
I0916 19:27:08.419466 20216 solver.cpp:314] Iteration 42800 (4.99179 iter/s, 20.0329s/100 iter), loss = 0.0513236
I0916 19:27:08.419776 20216 solver.cpp:336]     Train net output #0: loss = 0.0513238 (* 1 = 0.0513238 loss)
I0916 19:27:08.419792 20216 sgd_solver.cpp:136] Iteration 42800, lr = 0.001, m = 0.9
I0916 19:27:28.385995 20216 solver.cpp:314] Iteration 42900 (5.00852 iter/s, 19.966s/100 iter), loss = 0.0425653
I0916 19:27:28.386023 20216 solver.cpp:336]     Train net output #0: loss = 0.0425655 (* 1 = 0.0425655 loss)
I0916 19:27:28.386027 20216 sgd_solver.cpp:136] Iteration 42900, lr = 0.001, m = 0.9
I0916 19:27:42.469509 20219 data_reader.cpp:305] Starting prefetch of epoch 34
I0916 19:27:48.489513 20216 solver.cpp:314] Iteration 43000 (4.97439 iter/s, 20.103s/100 iter), loss = 0.040863
I0916 19:27:48.489538 20216 solver.cpp:336]     Train net output #0: loss = 0.0408631 (* 1 = 0.0408631 loss)
I0916 19:27:48.489544 20216 sgd_solver.cpp:136] Iteration 43000, lr = 0.001, m = 0.9
I0916 19:28:08.481428 20216 solver.cpp:314] Iteration 43100 (5.00216 iter/s, 19.9914s/100 iter), loss = 0.0793262
I0916 19:28:08.481457 20216 solver.cpp:336]     Train net output #0: loss = 0.0793264 (* 1 = 0.0793264 loss)
I0916 19:28:08.481462 20216 sgd_solver.cpp:136] Iteration 43100, lr = 0.001, m = 0.9
I0916 19:28:28.469324 20216 solver.cpp:314] Iteration 43200 (5.00317 iter/s, 19.9873s/100 iter), loss = 0.0777677
I0916 19:28:28.469377 20216 solver.cpp:336]     Train net output #0: loss = 0.0777679 (* 1 = 0.0777679 loss)
I0916 19:28:28.469383 20216 sgd_solver.cpp:136] Iteration 43200, lr = 0.001, m = 0.9
I0916 19:28:47.800300 20197 data_reader.cpp:305] Starting prefetch of epoch 25
I0916 19:28:47.995169 20216 solver.cpp:314] Iteration 43300 (5.12156 iter/s, 19.5253s/100 iter), loss = 0.0438524
I0916 19:28:47.995195 20216 solver.cpp:336]     Train net output #0: loss = 0.0438525 (* 1 = 0.0438525 loss)
I0916 19:28:47.995199 20216 sgd_solver.cpp:136] Iteration 43300, lr = 0.001, m = 0.9
I0916 19:29:07.901747 20216 solver.cpp:314] Iteration 43400 (5.02361 iter/s, 19.906s/100 iter), loss = 0.0716235
I0916 19:29:07.901829 20216 solver.cpp:336]     Train net output #0: loss = 0.0716237 (* 1 = 0.0716237 loss)
I0916 19:29:07.901841 20216 sgd_solver.cpp:136] Iteration 43400, lr = 0.001, m = 0.9
I0916 19:29:20.802422 20220 data_reader.cpp:305] Starting prefetch of epoch 33
I0916 19:29:27.859405 20216 solver.cpp:314] Iteration 43500 (5.01075 iter/s, 19.9571s/100 iter), loss = 0.0885851
I0916 19:29:27.859436 20216 solver.cpp:336]     Train net output #0: loss = 0.0885853 (* 1 = 0.0885853 loss)
I0916 19:29:27.859441 20216 sgd_solver.cpp:136] Iteration 43500, lr = 0.001, m = 0.9
I0916 19:29:47.606608 20216 solver.cpp:314] Iteration 43600 (5.06415 iter/s, 19.7466s/100 iter), loss = 0.0506257
I0916 19:29:47.606688 20216 solver.cpp:336]     Train net output #0: loss = 0.0506259 (* 1 = 0.0506259 loss)
I0916 19:29:47.606698 20216 sgd_solver.cpp:136] Iteration 43600, lr = 0.001, m = 0.9
I0916 19:30:07.306819 20216 solver.cpp:314] Iteration 43700 (5.07623 iter/s, 19.6997s/100 iter), loss = 0.0801471
I0916 19:30:07.306849 20216 solver.cpp:336]     Train net output #0: loss = 0.0801472 (* 1 = 0.0801472 loss)
I0916 19:30:07.306855 20216 sgd_solver.cpp:136] Iteration 43700, lr = 0.001, m = 0.9
I0916 19:30:25.972018 20219 data_reader.cpp:305] Starting prefetch of epoch 35
I0916 19:30:26.899343 20216 solver.cpp:314] Iteration 43800 (5.10413 iter/s, 19.592s/100 iter), loss = 0.0328851
I0916 19:30:26.899381 20216 solver.cpp:336]     Train net output #0: loss = 0.0328853 (* 1 = 0.0328853 loss)
I0916 19:30:26.899389 20216 sgd_solver.cpp:136] Iteration 43800, lr = 0.001, m = 0.9
I0916 19:30:46.700165 20216 solver.cpp:314] Iteration 43900 (5.05044 iter/s, 19.8003s/100 iter), loss = 0.0419999
I0916 19:30:46.700191 20216 solver.cpp:336]     Train net output #0: loss = 0.042 (* 1 = 0.042 loss)
I0916 19:30:46.700196 20216 sgd_solver.cpp:136] Iteration 43900, lr = 0.001, m = 0.9
I0916 19:31:06.345010 20216 solver.cpp:563] Iteration 44000, Testing net (#0)
I0916 19:31:09.578774 20248 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 19:31:17.116742 20202 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 19:31:17.434168 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.954245
I0916 19:31:17.434190 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 19:31:17.434195 20216 solver.cpp:655]     Test net output #2: loss = 0.146614 (* 1 = 0.146614 loss)
I0916 19:31:17.434222 20216 solver.cpp:265] [MultiGPU] Tests completed in 11.0889s
I0916 19:31:17.653337 20216 solver.cpp:314] Iteration 44000 (3.23078 iter/s, 30.9523s/100 iter), loss = 0.0790999
I0916 19:31:17.653365 20216 solver.cpp:336]     Train net output #0: loss = 0.0791 (* 1 = 0.0791 loss)
I0916 19:31:17.653373 20216 sgd_solver.cpp:136] Iteration 44000, lr = 0.001, m = 0.9
I0916 19:31:36.796557 20216 solver.cpp:314] Iteration 44100 (5.22393 iter/s, 19.1427s/100 iter), loss = 0.0546359
I0916 19:31:36.796615 20216 solver.cpp:336]     Train net output #0: loss = 0.0546361 (* 1 = 0.0546361 loss)
I0916 19:31:36.796622 20216 sgd_solver.cpp:136] Iteration 44100, lr = 0.001, m = 0.9
I0916 19:31:56.281131 20216 solver.cpp:314] Iteration 44200 (5.13241 iter/s, 19.484s/100 iter), loss = 0.0573775
I0916 19:31:56.281157 20216 solver.cpp:336]     Train net output #0: loss = 0.0573776 (* 1 = 0.0573776 loss)
I0916 19:31:56.281164 20216 sgd_solver.cpp:136] Iteration 44200, lr = 0.001, m = 0.9
I0916 19:32:14.099333 20195 data_reader.cpp:305] Starting prefetch of epoch 18
I0916 19:32:15.787106 20216 solver.cpp:314] Iteration 44300 (5.12678 iter/s, 19.5054s/100 iter), loss = 0.0396712
I0916 19:32:15.787132 20216 solver.cpp:336]     Train net output #0: loss = 0.0396713 (* 1 = 0.0396713 loss)
I0916 19:32:15.787137 20216 sgd_solver.cpp:136] Iteration 44300, lr = 0.001, m = 0.9
I0916 19:32:35.013705 20216 solver.cpp:314] Iteration 44400 (5.20132 iter/s, 19.2259s/100 iter), loss = 0.050518
I0916 19:32:35.013757 20216 solver.cpp:336]     Train net output #0: loss = 0.0505181 (* 1 = 0.0505181 loss)
I0916 19:32:35.013770 20216 sgd_solver.cpp:136] Iteration 44400, lr = 0.001, m = 0.9
I0916 19:32:54.727306 20216 solver.cpp:314] Iteration 44500 (5.07278 iter/s, 19.713s/100 iter), loss = 0.0506201
I0916 19:32:54.727423 20216 solver.cpp:336]     Train net output #0: loss = 0.0506202 (* 1 = 0.0506202 loss)
I0916 19:32:54.727432 20216 sgd_solver.cpp:136] Iteration 44500, lr = 0.001, m = 0.9
I0916 19:33:14.227926 20216 solver.cpp:314] Iteration 44600 (5.12819 iter/s, 19.5001s/100 iter), loss = 0.0513007
I0916 19:33:14.227948 20216 solver.cpp:336]     Train net output #0: loss = 0.0513009 (* 1 = 0.0513009 loss)
I0916 19:33:14.227952 20216 sgd_solver.cpp:136] Iteration 44600, lr = 0.001, m = 0.9
I0916 19:33:18.353102 20223 data_reader.cpp:305] Starting prefetch of epoch 17
I0916 19:33:33.817881 20216 solver.cpp:314] Iteration 44700 (5.1048 iter/s, 19.5894s/100 iter), loss = 0.0529278
I0916 19:33:33.817981 20216 solver.cpp:336]     Train net output #0: loss = 0.0529279 (* 1 = 0.0529279 loss)
I0916 19:33:33.817988 20216 sgd_solver.cpp:136] Iteration 44700, lr = 0.001, m = 0.9
I0916 19:33:50.528596 20195 data_reader.cpp:305] Starting prefetch of epoch 19
I0916 19:33:52.914793 20216 solver.cpp:314] Iteration 44800 (5.2366 iter/s, 19.0964s/100 iter), loss = 0.0728593
I0916 19:33:52.914822 20216 solver.cpp:336]     Train net output #0: loss = 0.0728594 (* 1 = 0.0728594 loss)
I0916 19:33:52.914830 20216 sgd_solver.cpp:136] Iteration 44800, lr = 0.001, m = 0.9
I0916 19:34:12.255352 20216 solver.cpp:314] Iteration 44900 (5.17063 iter/s, 19.34s/100 iter), loss = 0.0515324
I0916 19:34:12.255403 20216 solver.cpp:336]     Train net output #0: loss = 0.0515325 (* 1 = 0.0515325 loss)
I0916 19:34:12.255410 20216 sgd_solver.cpp:136] Iteration 44900, lr = 0.001, m = 0.9
I0916 19:34:31.462203 20266 sgd_solver.cpp:48] MultiStep Status: Iteration 45000, step = 2
I0916 19:34:31.462203 20268 sgd_solver.cpp:48] MultiStep Status: Iteration 45000, step = 2
I0916 19:34:31.462208 20267 sgd_solver.cpp:48] MultiStep Status: Iteration 45000, step = 2
I0916 19:34:31.571507 20216 solver.cpp:314] Iteration 45000 (5.17716 iter/s, 19.3156s/100 iter), loss = 0.0606193
I0916 19:34:31.571533 20216 solver.cpp:336]     Train net output #0: loss = 0.0606194 (* 1 = 0.0606194 loss)
I0916 19:34:31.571539 20216 sgd_solver.cpp:136] Iteration 45000, lr = 0.0001, m = 0.9
I0916 19:34:51.051836 20216 solver.cpp:314] Iteration 45100 (5.13353 iter/s, 19.4798s/100 iter), loss = 0.0828582
I0916 19:34:51.051885 20216 solver.cpp:336]     Train net output #0: loss = 0.0828583 (* 1 = 0.0828583 loss)
I0916 19:34:51.051890 20216 sgd_solver.cpp:136] Iteration 45100, lr = 0.0001, m = 0.9
I0916 19:34:54.408318 20223 data_reader.cpp:305] Starting prefetch of epoch 18
I0916 19:35:10.620555 20216 solver.cpp:314] Iteration 45200 (5.11034 iter/s, 19.5682s/100 iter), loss = 0.0511216
I0916 19:35:10.620581 20216 solver.cpp:336]     Train net output #0: loss = 0.0511217 (* 1 = 0.0511217 loss)
I0916 19:35:10.620587 20216 sgd_solver.cpp:136] Iteration 45200, lr = 0.0001, m = 0.9
I0916 19:35:30.060351 20216 solver.cpp:314] Iteration 45300 (5.14423 iter/s, 19.4393s/100 iter), loss = 0.0622558
I0916 19:35:30.060434 20216 solver.cpp:336]     Train net output #0: loss = 0.062256 (* 1 = 0.062256 loss)
I0916 19:35:30.060441 20216 sgd_solver.cpp:136] Iteration 45300, lr = 0.0001, m = 0.9
I0916 19:35:49.574007 20216 solver.cpp:314] Iteration 45400 (5.12476 iter/s, 19.5131s/100 iter), loss = 0.0540446
I0916 19:35:49.574033 20216 solver.cpp:336]     Train net output #0: loss = 0.0540447 (* 1 = 0.0540447 loss)
I0916 19:35:49.574038 20216 sgd_solver.cpp:136] Iteration 45400, lr = 0.0001, m = 0.9
I0916 19:35:58.972699 20197 data_reader.cpp:305] Starting prefetch of epoch 26
I0916 19:36:08.923717 20216 solver.cpp:314] Iteration 45500 (5.16818 iter/s, 19.3492s/100 iter), loss = 0.0607774
I0916 19:36:08.923805 20216 solver.cpp:336]     Train net output #0: loss = 0.0607775 (* 1 = 0.0607775 loss)
I0916 19:36:08.923813 20216 sgd_solver.cpp:136] Iteration 45500, lr = 0.0001, m = 0.9
I0916 19:36:28.275133 20216 solver.cpp:314] Iteration 45600 (5.16772 iter/s, 19.3509s/100 iter), loss = 0.0702267
I0916 19:36:28.275162 20216 solver.cpp:336]     Train net output #0: loss = 0.0702268 (* 1 = 0.0702268 loss)
I0916 19:36:28.275169 20216 sgd_solver.cpp:136] Iteration 45600, lr = 0.0001, m = 0.9
I0916 19:36:30.841073 20195 data_reader.cpp:305] Starting prefetch of epoch 20
I0916 19:36:47.742496 20216 solver.cpp:314] Iteration 45700 (5.13695 iter/s, 19.4668s/100 iter), loss = 0.034348
I0916 19:36:47.742558 20216 solver.cpp:336]     Train net output #0: loss = 0.0343481 (* 1 = 0.0343481 loss)
I0916 19:36:47.742565 20216 sgd_solver.cpp:136] Iteration 45700, lr = 0.0001, m = 0.9
I0916 19:37:07.017997 20216 solver.cpp:314] Iteration 45800 (5.18808 iter/s, 19.275s/100 iter), loss = 0.0780336
I0916 19:37:07.018025 20216 solver.cpp:336]     Train net output #0: loss = 0.0780338 (* 1 = 0.0780338 loss)
I0916 19:37:07.018033 20216 sgd_solver.cpp:136] Iteration 45800, lr = 0.0001, m = 0.9
I0916 19:37:26.584286 20216 solver.cpp:314] Iteration 45900 (5.11097 iter/s, 19.5657s/100 iter), loss = 0.0369362
I0916 19:37:26.584357 20216 solver.cpp:336]     Train net output #0: loss = 0.0369363 (* 1 = 0.0369363 loss)
I0916 19:37:26.584364 20216 sgd_solver.cpp:136] Iteration 45900, lr = 0.0001, m = 0.9
I0916 19:37:35.211249 20219 data_reader.cpp:305] Starting prefetch of epoch 36
I0916 19:37:45.741160 20216 solver.cpp:563] Iteration 46000, Testing net (#0)
I0916 19:37:57.648190 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.957167
I0916 19:37:57.648242 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 19:37:57.648252 20216 solver.cpp:655]     Test net output #2: loss = 0.167751 (* 1 = 0.167751 loss)
I0916 19:37:57.648285 20216 solver.cpp:265] [MultiGPU] Tests completed in 11.9068s
I0916 19:37:57.854068 20216 solver.cpp:314] Iteration 46000 (3.19806 iter/s, 31.2689s/100 iter), loss = 0.048376
I0916 19:37:57.854099 20216 solver.cpp:336]     Train net output #0: loss = 0.0483761 (* 1 = 0.0483761 loss)
I0916 19:37:57.854105 20216 sgd_solver.cpp:136] Iteration 46000, lr = 0.0001, m = 0.9
I0916 19:38:17.041867 20216 solver.cpp:314] Iteration 46100 (5.21179 iter/s, 19.1873s/100 iter), loss = 0.0373107
I0916 19:38:17.041889 20216 solver.cpp:336]     Train net output #0: loss = 0.0373108 (* 1 = 0.0373108 loss)
I0916 19:38:17.041893 20216 sgd_solver.cpp:136] Iteration 46100, lr = 0.0001, m = 0.9
I0916 19:38:18.771662 20197 data_reader.cpp:305] Starting prefetch of epoch 27
I0916 19:38:36.810194 20216 solver.cpp:314] Iteration 46200 (5.05874 iter/s, 19.7678s/100 iter), loss = 0.0361158
I0916 19:38:36.810252 20216 solver.cpp:336]     Train net output #0: loss = 0.036116 (* 1 = 0.036116 loss)
I0916 19:38:36.810258 20216 sgd_solver.cpp:136] Iteration 46200, lr = 0.0001, m = 0.9
I0916 19:38:51.161049 20219 data_reader.cpp:305] Starting prefetch of epoch 37
I0916 19:38:56.142454 20216 solver.cpp:314] Iteration 46300 (5.17285 iter/s, 19.3317s/100 iter), loss = 0.0499427
I0916 19:38:56.142477 20216 solver.cpp:336]     Train net output #0: loss = 0.0499428 (* 1 = 0.0499428 loss)
I0916 19:38:56.142483 20216 sgd_solver.cpp:136] Iteration 46300, lr = 0.0001, m = 0.9
I0916 19:39:15.389133 20216 solver.cpp:314] Iteration 46400 (5.19585 iter/s, 19.2461s/100 iter), loss = 0.0465312
I0916 19:39:15.389192 20216 solver.cpp:336]     Train net output #0: loss = 0.0465313 (* 1 = 0.0465313 loss)
I0916 19:39:15.389199 20216 sgd_solver.cpp:136] Iteration 46400, lr = 0.0001, m = 0.9
I0916 19:39:35.063045 20216 solver.cpp:314] Iteration 46500 (5.08301 iter/s, 19.6734s/100 iter), loss = 0.0801943
I0916 19:39:35.063067 20216 solver.cpp:336]     Train net output #0: loss = 0.0801944 (* 1 = 0.0801944 loss)
I0916 19:39:35.063072 20216 sgd_solver.cpp:136] Iteration 46500, lr = 0.0001, m = 0.9
I0916 19:39:54.345592 20216 solver.cpp:314] Iteration 46600 (5.18618 iter/s, 19.282s/100 iter), loss = 0.0343039
I0916 19:39:54.345649 20216 solver.cpp:336]     Train net output #0: loss = 0.034304 (* 1 = 0.034304 loss)
I0916 19:39:54.345654 20216 sgd_solver.cpp:136] Iteration 46600, lr = 0.0001, m = 0.9
I0916 19:39:55.404551 20195 data_reader.cpp:305] Starting prefetch of epoch 21
I0916 19:40:14.010046 20216 solver.cpp:314] Iteration 46700 (5.08546 iter/s, 19.6639s/100 iter), loss = 0.059381
I0916 19:40:14.010068 20216 solver.cpp:336]     Train net output #0: loss = 0.0593811 (* 1 = 0.0593811 loss)
I0916 19:40:14.010082 20216 sgd_solver.cpp:136] Iteration 46700, lr = 0.0001, m = 0.9
I0916 19:40:33.461313 20216 solver.cpp:314] Iteration 46800 (5.1412 iter/s, 19.4507s/100 iter), loss = 0.0727642
I0916 19:40:33.461401 20216 solver.cpp:336]     Train net output #0: loss = 0.0727643 (* 1 = 0.0727643 loss)
I0916 19:40:33.461410 20216 sgd_solver.cpp:136] Iteration 46800, lr = 0.0001, m = 0.9
I0916 19:40:53.007936 20216 solver.cpp:314] Iteration 46900 (5.11612 iter/s, 19.5461s/100 iter), loss = 0.0639873
I0916 19:40:53.007961 20216 solver.cpp:336]     Train net output #0: loss = 0.0639874 (* 1 = 0.0639874 loss)
I0916 19:40:53.007967 20216 sgd_solver.cpp:136] Iteration 46900, lr = 0.0001, m = 0.9
I0916 19:40:59.826179 20220 data_reader.cpp:305] Starting prefetch of epoch 34
I0916 19:41:12.234274 20216 solver.cpp:314] Iteration 47000 (5.20134 iter/s, 19.2258s/100 iter), loss = 0.0408358
I0916 19:41:12.234336 20216 solver.cpp:336]     Train net output #0: loss = 0.0408359 (* 1 = 0.0408359 loss)
I0916 19:41:12.234344 20216 sgd_solver.cpp:136] Iteration 47000, lr = 0.0001, m = 0.9
I0916 19:41:31.898895 20216 solver.cpp:314] Iteration 47100 (5.08542 iter/s, 19.6641s/100 iter), loss = 0.0581835
I0916 19:41:31.898918 20216 solver.cpp:336]     Train net output #0: loss = 0.0581836 (* 1 = 0.0581836 loss)
I0916 19:41:31.898924 20216 sgd_solver.cpp:136] Iteration 47100, lr = 0.0001, m = 0.9
I0916 19:41:52.013916 20216 solver.cpp:314] Iteration 47200 (4.97155 iter/s, 20.1145s/100 iter), loss = 0.0479227
I0916 19:41:52.013962 20216 solver.cpp:336]     Train net output #0: loss = 0.0479228 (* 1 = 0.0479228 loss)
I0916 19:41:52.013967 20216 sgd_solver.cpp:136] Iteration 47200, lr = 0.0001, m = 0.9
I0916 19:42:05.160537 20197 data_reader.cpp:305] Starting prefetch of epoch 28
I0916 19:42:11.953490 20216 solver.cpp:314] Iteration 47300 (5.01529 iter/s, 19.939s/100 iter), loss = 0.120858
I0916 19:42:11.953521 20216 solver.cpp:336]     Train net output #0: loss = 0.120858 (* 1 = 0.120858 loss)
I0916 19:42:11.953527 20216 sgd_solver.cpp:136] Iteration 47300, lr = 0.0001, m = 0.9
I0916 19:42:31.509690 20216 solver.cpp:314] Iteration 47400 (5.11361 iter/s, 19.5557s/100 iter), loss = 0.0341166
I0916 19:42:31.509748 20216 solver.cpp:336]     Train net output #0: loss = 0.0341167 (* 1 = 0.0341167 loss)
I0916 19:42:31.509755 20216 sgd_solver.cpp:136] Iteration 47400, lr = 0.0001, m = 0.9
I0916 19:42:37.883622 20219 data_reader.cpp:305] Starting prefetch of epoch 38
I0916 19:42:51.591768 20216 solver.cpp:314] Iteration 47500 (4.9797 iter/s, 20.0815s/100 iter), loss = 0.0462127
I0916 19:42:51.591790 20216 solver.cpp:336]     Train net output #0: loss = 0.0462128 (* 1 = 0.0462128 loss)
I0916 19:42:51.591796 20216 sgd_solver.cpp:136] Iteration 47500, lr = 0.0001, m = 0.9
I0916 19:43:11.310124 20216 solver.cpp:314] Iteration 47600 (5.07156 iter/s, 19.7178s/100 iter), loss = 0.0731876
I0916 19:43:11.310178 20216 solver.cpp:336]     Train net output #0: loss = 0.0731877 (* 1 = 0.0731877 loss)
I0916 19:43:11.310184 20216 sgd_solver.cpp:136] Iteration 47600, lr = 0.0001, m = 0.9
I0916 19:43:31.087307 20216 solver.cpp:314] Iteration 47700 (5.05647 iter/s, 19.7766s/100 iter), loss = 0.057329
I0916 19:43:31.087330 20216 solver.cpp:336]     Train net output #0: loss = 0.0573291 (* 1 = 0.0573291 loss)
I0916 19:43:31.087334 20216 sgd_solver.cpp:136] Iteration 47700, lr = 0.0001, m = 0.9
I0916 19:43:43.462625 20219 data_reader.cpp:305] Starting prefetch of epoch 39
I0916 19:43:50.967846 20216 solver.cpp:314] Iteration 47800 (5.03019 iter/s, 19.88s/100 iter), loss = 0.0862389
I0916 19:43:50.967872 20216 solver.cpp:336]     Train net output #0: loss = 0.086239 (* 1 = 0.086239 loss)
I0916 19:43:50.967878 20216 sgd_solver.cpp:136] Iteration 47800, lr = 0.0001, m = 0.9
I0916 19:44:10.787302 20216 solver.cpp:314] Iteration 47900 (5.04569 iter/s, 19.8189s/100 iter), loss = 0.0606068
I0916 19:44:10.787331 20216 solver.cpp:336]     Train net output #0: loss = 0.0606069 (* 1 = 0.0606069 loss)
I0916 19:44:10.787338 20216 sgd_solver.cpp:136] Iteration 47900, lr = 0.0001, m = 0.9
I0916 19:44:30.578368 20216 solver.cpp:563] Iteration 48000, Testing net (#0)
I0916 19:44:33.887399 20248 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 19:44:42.844071 20248 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 19:44:43.274318 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.955081
I0916 19:44:43.274338 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 19:44:43.274343 20216 solver.cpp:655]     Test net output #2: loss = 0.146799 (* 1 = 0.146799 loss)
I0916 19:44:43.274369 20216 solver.cpp:265] [MultiGPU] Tests completed in 12.6956s
I0916 19:44:43.464685 20216 solver.cpp:314] Iteration 48000 (3.06031 iter/s, 32.6765s/100 iter), loss = 0.079719
I0916 19:44:43.464707 20216 solver.cpp:336]     Train net output #0: loss = 0.0797191 (* 1 = 0.0797191 loss)
I0916 19:44:43.464711 20216 sgd_solver.cpp:136] Iteration 48000, lr = 0.0001, m = 0.9
I0916 19:45:02.820216 20216 solver.cpp:314] Iteration 48100 (5.16663 iter/s, 19.355s/100 iter), loss = 0.0357032
I0916 19:45:02.820305 20216 solver.cpp:336]     Train net output #0: loss = 0.0357033 (* 1 = 0.0357033 loss)
I0916 19:45:02.820313 20216 sgd_solver.cpp:136] Iteration 48100, lr = 0.0001, m = 0.9
I0916 19:45:22.871057 20216 solver.cpp:314] Iteration 48200 (4.98746 iter/s, 20.0503s/100 iter), loss = 0.0556976
I0916 19:45:22.871086 20216 solver.cpp:336]     Train net output #0: loss = 0.0556977 (* 1 = 0.0556977 loss)
I0916 19:45:22.871093 20216 sgd_solver.cpp:136] Iteration 48200, lr = 0.0001, m = 0.9
I0916 19:45:34.171511 20219 data_reader.cpp:305] Starting prefetch of epoch 40
I0916 19:45:42.390204 20216 solver.cpp:314] Iteration 48300 (5.12332 iter/s, 19.5186s/100 iter), loss = 0.0307195
I0916 19:45:42.390228 20216 solver.cpp:336]     Train net output #0: loss = 0.0307196 (* 1 = 0.0307196 loss)
I0916 19:45:42.390233 20216 sgd_solver.cpp:136] Iteration 48300, lr = 0.0001, m = 0.9
I0916 19:46:01.955366 20216 solver.cpp:314] Iteration 48400 (5.11127 iter/s, 19.5646s/100 iter), loss = 0.0507358
I0916 19:46:01.955394 20216 solver.cpp:336]     Train net output #0: loss = 0.0507359 (* 1 = 0.0507359 loss)
I0916 19:46:01.955400 20216 sgd_solver.cpp:136] Iteration 48400, lr = 0.0001, m = 0.9
I0916 19:46:21.756500 20216 solver.cpp:314] Iteration 48500 (5.05036 iter/s, 19.8006s/100 iter), loss = 0.0454401
I0916 19:46:21.756546 20216 solver.cpp:336]     Train net output #0: loss = 0.0454402 (* 1 = 0.0454402 loss)
I0916 19:46:21.756552 20216 sgd_solver.cpp:136] Iteration 48500, lr = 0.0001, m = 0.9
I0916 19:46:38.901748 20195 data_reader.cpp:305] Starting prefetch of epoch 22
I0916 19:46:41.232898 20216 solver.cpp:314] Iteration 48600 (5.13456 iter/s, 19.4758s/100 iter), loss = 0.0442247
I0916 19:46:41.232926 20216 solver.cpp:336]     Train net output #0: loss = 0.0442248 (* 1 = 0.0442248 loss)
I0916 19:46:41.232933 20216 sgd_solver.cpp:136] Iteration 48600, lr = 0.0001, m = 0.9
I0916 19:47:00.949406 20216 solver.cpp:314] Iteration 48700 (5.07204 iter/s, 19.716s/100 iter), loss = 0.0442474
I0916 19:47:00.949457 20216 solver.cpp:336]     Train net output #0: loss = 0.0442475 (* 1 = 0.0442475 loss)
I0916 19:47:00.949463 20216 sgd_solver.cpp:136] Iteration 48700, lr = 0.0001, m = 0.9
I0916 19:47:20.411185 20216 solver.cpp:314] Iteration 48800 (5.13842 iter/s, 19.4612s/100 iter), loss = 0.0761857
I0916 19:47:20.411211 20216 solver.cpp:336]     Train net output #0: loss = 0.0761859 (* 1 = 0.0761859 loss)
I0916 19:47:20.411214 20216 sgd_solver.cpp:136] Iteration 48800, lr = 0.0001, m = 0.9
I0916 19:47:40.365365 20216 solver.cpp:314] Iteration 48900 (5.01162 iter/s, 19.9536s/100 iter), loss = 0.0506539
I0916 19:47:40.365440 20216 solver.cpp:336]     Train net output #0: loss = 0.050654 (* 1 = 0.050654 loss)
I0916 19:47:40.365448 20216 sgd_solver.cpp:136] Iteration 48900, lr = 0.0001, m = 0.9
I0916 19:47:44.212476 20224 data_reader.cpp:305] Starting prefetch of epoch 31
I0916 19:48:00.320250 20216 solver.cpp:314] Iteration 49000 (5.01145 iter/s, 19.9543s/100 iter), loss = 0.0693169
I0916 19:48:00.320276 20216 solver.cpp:336]     Train net output #0: loss = 0.069317 (* 1 = 0.069317 loss)
I0916 19:48:00.320282 20216 sgd_solver.cpp:136] Iteration 49000, lr = 0.0001, m = 0.9
I0916 19:48:16.792748 20220 data_reader.cpp:305] Starting prefetch of epoch 35
I0916 19:48:19.845459 20216 solver.cpp:314] Iteration 49100 (5.12173 iter/s, 19.5247s/100 iter), loss = 0.0518335
I0916 19:48:19.845482 20216 solver.cpp:336]     Train net output #0: loss = 0.0518336 (* 1 = 0.0518336 loss)
I0916 19:48:19.845487 20216 sgd_solver.cpp:136] Iteration 49100, lr = 0.0001, m = 0.9
I0916 19:48:40.040357 20216 solver.cpp:314] Iteration 49200 (4.95189 iter/s, 20.1943s/100 iter), loss = 0.0543663
I0916 19:48:40.040388 20216 solver.cpp:336]     Train net output #0: loss = 0.0543664 (* 1 = 0.0543664 loss)
I0916 19:48:40.040392 20216 sgd_solver.cpp:136] Iteration 49200, lr = 0.0001, m = 0.9
I0916 19:48:59.953105 20216 solver.cpp:314] Iteration 49300 (5.02205 iter/s, 19.9122s/100 iter), loss = 0.0732568
I0916 19:48:59.963603 20216 solver.cpp:336]     Train net output #0: loss = 0.0732569 (* 1 = 0.0732569 loss)
I0916 19:48:59.963634 20216 sgd_solver.cpp:136] Iteration 49300, lr = 0.0001, m = 0.9
I0916 19:49:19.905824 20216 solver.cpp:314] Iteration 49400 (5.01199 iter/s, 19.9522s/100 iter), loss = 0.0571453
I0916 19:49:19.905890 20216 solver.cpp:336]     Train net output #0: loss = 0.0571454 (* 1 = 0.0571454 loss)
I0916 19:49:19.905910 20216 sgd_solver.cpp:136] Iteration 49400, lr = 0.0001, m = 0.9
I0916 19:49:22.843848 20195 data_reader.cpp:305] Starting prefetch of epoch 23
I0916 19:49:39.376570 20216 solver.cpp:314] Iteration 49500 (5.13605 iter/s, 19.4702s/100 iter), loss = 0.044314
I0916 19:49:39.376626 20216 solver.cpp:336]     Train net output #0: loss = 0.0443142 (* 1 = 0.0443142 loss)
I0916 19:49:39.376632 20216 sgd_solver.cpp:136] Iteration 49500, lr = 0.0001, m = 0.9
I0916 19:49:59.519239 20216 solver.cpp:314] Iteration 49600 (4.96473 iter/s, 20.1421s/100 iter), loss = 0.0531559
I0916 19:49:59.519266 20216 solver.cpp:336]     Train net output #0: loss = 0.053156 (* 1 = 0.053156 loss)
I0916 19:49:59.519270 20216 sgd_solver.cpp:136] Iteration 49600, lr = 0.0001, m = 0.9
I0916 19:50:19.539409 20216 solver.cpp:314] Iteration 49700 (4.9951 iter/s, 20.0196s/100 iter), loss = 0.0601718
I0916 19:50:19.539639 20216 solver.cpp:336]     Train net output #0: loss = 0.0601719 (* 1 = 0.0601719 loss)
I0916 19:50:19.539649 20216 sgd_solver.cpp:136] Iteration 49700, lr = 0.0001, m = 0.9
I0916 19:50:28.497938 20224 data_reader.cpp:305] Starting prefetch of epoch 32
I0916 19:50:39.407058 20216 solver.cpp:314] Iteration 49800 (5.03345 iter/s, 19.8671s/100 iter), loss = 0.0656823
I0916 19:50:39.407081 20216 solver.cpp:336]     Train net output #0: loss = 0.0656824 (* 1 = 0.0656824 loss)
I0916 19:50:39.407088 20216 sgd_solver.cpp:136] Iteration 49800, lr = 0.0001, m = 0.9
I0916 19:50:59.177528 20216 solver.cpp:314] Iteration 49900 (5.05819 iter/s, 19.7699s/100 iter), loss = 0.0368935
I0916 19:50:59.177608 20216 solver.cpp:336]     Train net output #0: loss = 0.0368937 (* 1 = 0.0368937 loss)
I0916 19:50:59.177613 20216 sgd_solver.cpp:136] Iteration 49900, lr = 0.0001, m = 0.9
I0916 19:51:01.202430 20220 data_reader.cpp:305] Starting prefetch of epoch 36
I0916 19:51:19.012413 20216 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/cityscapes5_jsegnet21v2_iter_50000.caffemodel
I0916 19:51:19.239899 20216 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/cityscapes5_jsegnet21v2_iter_50000.solverstate
I0916 19:51:19.246620 20216 solver.cpp:563] Iteration 50000, Testing net (#0)
I0916 19:51:31.060118 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.957335
I0916 19:51:31.060168 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 19:51:31.060175 20216 solver.cpp:655]     Test net output #2: loss = 0.167795 (* 1 = 0.167795 loss)
I0916 19:51:31.060197 20216 solver.cpp:265] [MultiGPU] Tests completed in 11.8132s
I0916 19:51:31.265677 20216 solver.cpp:314] Iteration 50000 (3.1165 iter/s, 32.0872s/100 iter), loss = 0.0545652
I0916 19:51:31.265703 20216 solver.cpp:336]     Train net output #0: loss = 0.0545653 (* 1 = 0.0545653 loss)
I0916 19:51:31.265709 20216 sgd_solver.cpp:136] Iteration 50000, lr = 0.0001, m = 0.9
I0916 19:51:46.275606 20197 data_reader.cpp:305] Starting prefetch of epoch 29
I0916 19:51:51.129431 20216 solver.cpp:314] Iteration 50100 (5.03444 iter/s, 19.8632s/100 iter), loss = 0.0641584
I0916 19:51:51.129454 20216 solver.cpp:336]     Train net output #0: loss = 0.0641586 (* 1 = 0.0641586 loss)
I0916 19:51:51.129461 20216 sgd_solver.cpp:136] Iteration 50100, lr = 0.0001, m = 0.9
I0916 19:52:10.949658 20216 solver.cpp:314] Iteration 50200 (5.04549 iter/s, 19.8197s/100 iter), loss = 0.0688256
I0916 19:52:10.949759 20216 solver.cpp:336]     Train net output #0: loss = 0.0688258 (* 1 = 0.0688258 loss)
I0916 19:52:10.949766 20216 sgd_solver.cpp:136] Iteration 50200, lr = 0.0001, m = 0.9
I0916 19:52:30.976518 20216 solver.cpp:314] Iteration 50300 (4.99343 iter/s, 20.0263s/100 iter), loss = 0.0376291
I0916 19:52:30.976546 20216 solver.cpp:336]     Train net output #0: loss = 0.0376292 (* 1 = 0.0376292 loss)
I0916 19:52:30.976552 20216 sgd_solver.cpp:136] Iteration 50300, lr = 0.0001, m = 0.9
I0916 19:52:50.852319 20216 solver.cpp:314] Iteration 50400 (5.03139 iter/s, 19.8752s/100 iter), loss = 0.0464863
I0916 19:52:50.852378 20216 solver.cpp:336]     Train net output #0: loss = 0.0464864 (* 1 = 0.0464864 loss)
I0916 19:52:50.852383 20216 sgd_solver.cpp:136] Iteration 50400, lr = 0.0001, m = 0.9
I0916 19:52:52.089648 20223 data_reader.cpp:305] Starting prefetch of epoch 19
I0916 19:53:11.000077 20216 solver.cpp:314] Iteration 50500 (4.96347 iter/s, 20.1472s/100 iter), loss = 0.0593894
I0916 19:53:11.000102 20216 solver.cpp:336]     Train net output #0: loss = 0.0593895 (* 1 = 0.0593895 loss)
I0916 19:53:11.000109 20216 sgd_solver.cpp:136] Iteration 50500, lr = 0.0001, m = 0.9
I0916 19:53:25.530199 20195 data_reader.cpp:305] Starting prefetch of epoch 24
I0916 19:53:31.378013 20216 solver.cpp:314] Iteration 50600 (4.90741 iter/s, 20.3774s/100 iter), loss = 0.0795164
I0916 19:53:31.378043 20216 solver.cpp:336]     Train net output #0: loss = 0.0795165 (* 1 = 0.0795165 loss)
I0916 19:53:31.378049 20216 sgd_solver.cpp:136] Iteration 50600, lr = 0.0001, m = 0.9
I0916 19:53:51.029281 20216 solver.cpp:314] Iteration 50700 (5.08887 iter/s, 19.6507s/100 iter), loss = 0.0430249
I0916 19:53:51.029305 20216 solver.cpp:336]     Train net output #0: loss = 0.043025 (* 1 = 0.043025 loss)
I0916 19:53:51.029314 20216 sgd_solver.cpp:136] Iteration 50700, lr = 0.0001, m = 0.9
I0916 19:54:10.964315 20216 solver.cpp:314] Iteration 50800 (5.01644 iter/s, 19.9345s/100 iter), loss = 0.0779049
I0916 19:54:10.964416 20216 solver.cpp:336]     Train net output #0: loss = 0.077905 (* 1 = 0.077905 loss)
I0916 19:54:10.964422 20216 sgd_solver.cpp:136] Iteration 50800, lr = 0.0001, m = 0.9
I0916 19:54:31.017009 20216 solver.cpp:314] Iteration 50900 (4.987 iter/s, 20.0521s/100 iter), loss = 0.0538926
I0916 19:54:31.017035 20216 solver.cpp:336]     Train net output #0: loss = 0.0538927 (* 1 = 0.0538927 loss)
I0916 19:54:31.017041 20216 sgd_solver.cpp:136] Iteration 50900, lr = 0.0001, m = 0.9
I0916 19:54:31.466584 20197 data_reader.cpp:305] Starting prefetch of epoch 30
I0916 19:54:51.308573 20216 solver.cpp:314] Iteration 51000 (4.9283 iter/s, 20.291s/100 iter), loss = 0.0215775
I0916 19:54:51.308626 20216 solver.cpp:336]     Train net output #0: loss = 0.0215776 (* 1 = 0.0215776 loss)
I0916 19:54:51.308632 20216 sgd_solver.cpp:136] Iteration 51000, lr = 0.0001, m = 0.9
I0916 19:55:11.254516 20216 solver.cpp:314] Iteration 51100 (5.01369 iter/s, 19.9454s/100 iter), loss = 0.0677243
I0916 19:55:11.254541 20216 solver.cpp:336]     Train net output #0: loss = 0.0677244 (* 1 = 0.0677244 loss)
I0916 19:55:11.254547 20216 sgd_solver.cpp:136] Iteration 51100, lr = 0.0001, m = 0.9
I0916 19:55:30.975841 20216 solver.cpp:314] Iteration 51200 (5.0708 iter/s, 19.7208s/100 iter), loss = 0.0681909
I0916 19:55:30.975896 20216 solver.cpp:336]     Train net output #0: loss = 0.068191 (* 1 = 0.068191 loss)
I0916 19:55:30.975905 20216 sgd_solver.cpp:136] Iteration 51200, lr = 0.0001, m = 0.9
I0916 19:55:37.484431 20224 data_reader.cpp:305] Starting prefetch of epoch 33
I0916 19:55:50.835644 20216 solver.cpp:314] Iteration 51300 (5.03544 iter/s, 19.8592s/100 iter), loss = 0.0649089
I0916 19:55:50.835669 20216 solver.cpp:336]     Train net output #0: loss = 0.064909 (* 1 = 0.064909 loss)
I0916 19:55:50.835676 20216 sgd_solver.cpp:136] Iteration 51300, lr = 0.0001, m = 0.9
I0916 19:56:10.639139 20219 data_reader.cpp:305] Starting prefetch of epoch 41
I0916 19:56:10.989797 20216 solver.cpp:314] Iteration 51400 (4.96189 iter/s, 20.1536s/100 iter), loss = 0.0537636
I0916 19:56:10.989826 20216 solver.cpp:336]     Train net output #0: loss = 0.0537637 (* 1 = 0.0537637 loss)
I0916 19:56:10.989833 20216 sgd_solver.cpp:136] Iteration 51400, lr = 0.0001, m = 0.9
I0916 19:56:31.296744 20216 solver.cpp:314] Iteration 51500 (4.92456 iter/s, 20.3064s/100 iter), loss = 0.0342098
I0916 19:56:31.296774 20216 solver.cpp:336]     Train net output #0: loss = 0.0342099 (* 1 = 0.0342099 loss)
I0916 19:56:31.296782 20216 sgd_solver.cpp:136] Iteration 51500, lr = 0.0001, m = 0.9
I0916 19:56:51.508007 20216 solver.cpp:314] Iteration 51600 (4.94787 iter/s, 20.2107s/100 iter), loss = 0.0527578
I0916 19:56:51.508059 20216 solver.cpp:336]     Train net output #0: loss = 0.0527579 (* 1 = 0.0527579 loss)
I0916 19:56:51.508065 20216 sgd_solver.cpp:136] Iteration 51600, lr = 0.0001, m = 0.9
I0916 19:57:11.230521 20216 solver.cpp:314] Iteration 51700 (5.07049 iter/s, 19.722s/100 iter), loss = 0.0549528
I0916 19:57:11.230546 20216 solver.cpp:336]     Train net output #0: loss = 0.0549529 (* 1 = 0.0549529 loss)
I0916 19:57:11.230551 20216 sgd_solver.cpp:136] Iteration 51700, lr = 0.0001, m = 0.9
I0916 19:57:16.881464 20223 data_reader.cpp:305] Starting prefetch of epoch 20
I0916 19:57:31.099666 20216 solver.cpp:314] Iteration 51800 (5.03307 iter/s, 19.8686s/100 iter), loss = 0.0523119
I0916 19:57:31.099758 20216 solver.cpp:336]     Train net output #0: loss = 0.0523121 (* 1 = 0.0523121 loss)
I0916 19:57:31.099766 20216 sgd_solver.cpp:136] Iteration 51800, lr = 0.0001, m = 0.9
I0916 19:57:50.935533 20216 solver.cpp:314] Iteration 51900 (5.04151 iter/s, 19.8353s/100 iter), loss = 0.0725203
I0916 19:57:50.935559 20216 solver.cpp:336]     Train net output #0: loss = 0.0725205 (* 1 = 0.0725205 loss)
I0916 19:57:50.935564 20216 sgd_solver.cpp:136] Iteration 51900, lr = 0.0001, m = 0.9
I0916 19:58:10.534937 20216 solver.cpp:563] Iteration 52000, Testing net (#0)
I0916 19:58:13.886718 20250 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 19:58:21.897552 20204 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 19:58:22.226562 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.954923
I0916 19:58:22.226583 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 19:58:22.226588 20216 solver.cpp:655]     Test net output #2: loss = 0.146935 (* 1 = 0.146935 loss)
I0916 19:58:22.226614 20216 solver.cpp:265] [MultiGPU] Tests completed in 11.6914s
I0916 19:58:22.436189 20216 solver.cpp:314] Iteration 52000 (3.17462 iter/s, 31.4998s/100 iter), loss = 0.0517698
I0916 19:58:22.436216 20216 solver.cpp:336]     Train net output #0: loss = 0.05177 (* 1 = 0.05177 loss)
I0916 19:58:22.436221 20216 sgd_solver.cpp:136] Iteration 52000, lr = 0.0001, m = 0.9
I0916 19:58:42.197443 20216 solver.cpp:314] Iteration 52100 (5.06055 iter/s, 19.7607s/100 iter), loss = 0.0297729
I0916 19:58:42.197501 20216 solver.cpp:336]     Train net output #0: loss = 0.029773 (* 1 = 0.029773 loss)
I0916 19:58:42.197506 20216 sgd_solver.cpp:136] Iteration 52100, lr = 0.0001, m = 0.9
I0916 19:59:01.600831 20216 solver.cpp:314] Iteration 52200 (5.15388 iter/s, 19.4028s/100 iter), loss = 0.053763
I0916 19:59:01.600854 20216 solver.cpp:336]     Train net output #0: loss = 0.0537632 (* 1 = 0.0537632 loss)
I0916 19:59:01.600859 20216 sgd_solver.cpp:136] Iteration 52200, lr = 0.0001, m = 0.9
I0916 19:59:06.411396 20224 data_reader.cpp:305] Starting prefetch of epoch 34
I0916 19:59:21.444191 20216 solver.cpp:314] Iteration 52300 (5.03961 iter/s, 19.8428s/100 iter), loss = 0.0757802
I0916 19:59:21.444254 20216 solver.cpp:336]     Train net output #0: loss = 0.0757803 (* 1 = 0.0757803 loss)
I0916 19:59:21.444260 20216 sgd_solver.cpp:136] Iteration 52300, lr = 0.0001, m = 0.9
I0916 19:59:41.072996 20216 solver.cpp:314] Iteration 52400 (5.0947 iter/s, 19.6283s/100 iter), loss = 0.0438005
I0916 19:59:41.073019 20216 solver.cpp:336]     Train net output #0: loss = 0.0438007 (* 1 = 0.0438007 loss)
I0916 19:59:41.073025 20216 sgd_solver.cpp:136] Iteration 52400, lr = 0.0001, m = 0.9
I0916 20:00:00.807246 20216 solver.cpp:314] Iteration 52500 (5.06747 iter/s, 19.7337s/100 iter), loss = 0.0678241
I0916 20:00:00.807334 20216 solver.cpp:336]     Train net output #0: loss = 0.0678243 (* 1 = 0.0678243 loss)
I0916 20:00:00.807343 20216 sgd_solver.cpp:136] Iteration 52500, lr = 0.0001, m = 0.9
I0916 20:00:11.553490 20223 data_reader.cpp:305] Starting prefetch of epoch 21
I0916 20:00:20.376658 20216 solver.cpp:314] Iteration 52600 (5.11016 iter/s, 19.5689s/100 iter), loss = 0.0650704
I0916 20:00:20.376683 20216 solver.cpp:336]     Train net output #0: loss = 0.0650706 (* 1 = 0.0650706 loss)
I0916 20:00:20.376688 20216 sgd_solver.cpp:136] Iteration 52600, lr = 0.0001, m = 0.9
I0916 20:00:40.031862 20216 solver.cpp:314] Iteration 52700 (5.08785 iter/s, 19.6547s/100 iter), loss = 0.0864689
I0916 20:00:40.031947 20216 solver.cpp:336]     Train net output #0: loss = 0.0864691 (* 1 = 0.0864691 loss)
I0916 20:00:40.031955 20216 sgd_solver.cpp:136] Iteration 52700, lr = 0.0001, m = 0.9
I0916 20:00:44.061483 20195 data_reader.cpp:305] Starting prefetch of epoch 25
I0916 20:00:59.978498 20216 solver.cpp:314] Iteration 52800 (5.01352 iter/s, 19.9461s/100 iter), loss = 0.0675042
I0916 20:00:59.978528 20216 solver.cpp:336]     Train net output #0: loss = 0.0675044 (* 1 = 0.0675044 loss)
I0916 20:00:59.978533 20216 sgd_solver.cpp:136] Iteration 52800, lr = 0.0001, m = 0.9
I0916 20:01:19.468199 20216 solver.cpp:314] Iteration 52900 (5.13106 iter/s, 19.4892s/100 iter), loss = 0.0454022
I0916 20:01:19.468263 20216 solver.cpp:336]     Train net output #0: loss = 0.0454024 (* 1 = 0.0454024 loss)
I0916 20:01:19.468271 20216 sgd_solver.cpp:136] Iteration 52900, lr = 0.0001, m = 0.9
I0916 20:01:39.055238 20216 solver.cpp:314] Iteration 53000 (5.10556 iter/s, 19.5865s/100 iter), loss = 0.045528
I0916 20:01:39.055264 20216 solver.cpp:336]     Train net output #0: loss = 0.0455282 (* 1 = 0.0455282 loss)
I0916 20:01:39.055271 20216 sgd_solver.cpp:136] Iteration 53000, lr = 0.0001, m = 0.9
I0916 20:01:49.104908 20197 data_reader.cpp:305] Starting prefetch of epoch 31
I0916 20:01:58.803562 20216 solver.cpp:314] Iteration 53100 (5.06386 iter/s, 19.7478s/100 iter), loss = 0.0494181
I0916 20:01:58.803648 20216 solver.cpp:336]     Train net output #0: loss = 0.0494183 (* 1 = 0.0494183 loss)
I0916 20:01:58.803656 20216 sgd_solver.cpp:136] Iteration 53100, lr = 0.0001, m = 0.9
I0916 20:02:18.594730 20216 solver.cpp:314] Iteration 53200 (5.0529 iter/s, 19.7906s/100 iter), loss = 0.048279
I0916 20:02:18.594763 20216 solver.cpp:336]     Train net output #0: loss = 0.0482792 (* 1 = 0.0482792 loss)
I0916 20:02:18.594770 20216 sgd_solver.cpp:136] Iteration 53200, lr = 0.0001, m = 0.9
I0916 20:02:38.123630 20216 solver.cpp:314] Iteration 53300 (5.12076 iter/s, 19.5283s/100 iter), loss = 0.055814
I0916 20:02:38.123780 20216 solver.cpp:336]     Train net output #0: loss = 0.0558142 (* 1 = 0.0558142 loss)
I0916 20:02:38.123805 20216 sgd_solver.cpp:136] Iteration 53300, lr = 0.0001, m = 0.9
I0916 20:02:54.074610 20224 data_reader.cpp:305] Starting prefetch of epoch 35
I0916 20:02:57.844539 20216 solver.cpp:314] Iteration 53400 (5.0709 iter/s, 19.7204s/100 iter), loss = 0.0597222
I0916 20:02:57.844609 20216 solver.cpp:336]     Train net output #0: loss = 0.0597224 (* 1 = 0.0597224 loss)
I0916 20:02:57.844635 20216 sgd_solver.cpp:136] Iteration 53400, lr = 0.0001, m = 0.9
I0916 20:03:18.020486 20216 solver.cpp:314] Iteration 53500 (4.95654 iter/s, 20.1754s/100 iter), loss = 0.042818
I0916 20:03:18.020547 20216 solver.cpp:336]     Train net output #0: loss = 0.0428182 (* 1 = 0.0428182 loss)
I0916 20:03:18.020555 20216 sgd_solver.cpp:136] Iteration 53500, lr = 0.0001, m = 0.9
I0916 20:03:27.352751 20219 data_reader.cpp:305] Starting prefetch of epoch 42
I0916 20:03:37.994956 20216 solver.cpp:314] Iteration 53600 (5.00653 iter/s, 19.9739s/100 iter), loss = 0.0827209
I0916 20:03:37.994982 20216 solver.cpp:336]     Train net output #0: loss = 0.0827211 (* 1 = 0.0827211 loss)
I0916 20:03:37.994987 20216 sgd_solver.cpp:136] Iteration 53600, lr = 0.0001, m = 0.9
I0916 20:03:57.956082 20216 solver.cpp:314] Iteration 53700 (5.00988 iter/s, 19.9606s/100 iter), loss = 0.0527835
I0916 20:03:57.956156 20216 solver.cpp:336]     Train net output #0: loss = 0.0527837 (* 1 = 0.0527837 loss)
I0916 20:03:57.956164 20216 sgd_solver.cpp:136] Iteration 53700, lr = 0.0001, m = 0.9
I0916 20:04:18.065117 20216 solver.cpp:314] Iteration 53800 (4.97303 iter/s, 20.1085s/100 iter), loss = 0.0477695
I0916 20:04:18.065141 20216 solver.cpp:336]     Train net output #0: loss = 0.0477696 (* 1 = 0.0477696 loss)
I0916 20:04:18.065148 20216 sgd_solver.cpp:136] Iteration 53800, lr = 0.0001, m = 0.9
I0916 20:04:33.130897 20223 data_reader.cpp:305] Starting prefetch of epoch 22
I0916 20:04:37.671393 20216 solver.cpp:314] Iteration 53900 (5.10055 iter/s, 19.6057s/100 iter), loss = 0.0467622
I0916 20:04:37.671419 20216 solver.cpp:336]     Train net output #0: loss = 0.0467623 (* 1 = 0.0467623 loss)
I0916 20:04:37.671424 20216 sgd_solver.cpp:136] Iteration 53900, lr = 0.0001, m = 0.9
I0916 20:04:57.253887 20216 solver.cpp:563] Iteration 54000, Testing net (#0)
I0916 20:05:09.063454 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.957436
I0916 20:05:09.063560 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 20:05:09.063570 20216 solver.cpp:655]     Test net output #2: loss = 0.168188 (* 1 = 0.168188 loss)
I0916 20:05:09.063597 20216 solver.cpp:265] [MultiGPU] Tests completed in 11.8094s
I0916 20:05:09.264817 20216 solver.cpp:314] Iteration 54000 (3.1653 iter/s, 31.5925s/100 iter), loss = 0.055974
I0916 20:05:09.264848 20216 solver.cpp:336]     Train net output #0: loss = 0.0559741 (* 1 = 0.0559741 loss)
I0916 20:05:09.264854 20216 sgd_solver.cpp:136] Iteration 54000, lr = 0.0001, m = 0.9
I0916 20:05:17.659122 20197 data_reader.cpp:305] Starting prefetch of epoch 32
I0916 20:05:29.302458 20216 solver.cpp:314] Iteration 54100 (4.99075 iter/s, 20.0371s/100 iter), loss = 0.0519949
I0916 20:05:29.302484 20216 solver.cpp:336]     Train net output #0: loss = 0.051995 (* 1 = 0.051995 loss)
I0916 20:05:29.302490 20216 sgd_solver.cpp:136] Iteration 54100, lr = 0.0001, m = 0.9
I0916 20:05:49.038712 20216 solver.cpp:314] Iteration 54200 (5.06696 iter/s, 19.7357s/100 iter), loss = 0.0626577
I0916 20:05:49.038764 20216 solver.cpp:336]     Train net output #0: loss = 0.0626578 (* 1 = 0.0626578 loss)
I0916 20:05:49.038771 20216 sgd_solver.cpp:136] Iteration 54200, lr = 0.0001, m = 0.9
I0916 20:05:50.636569 20220 data_reader.cpp:305] Starting prefetch of epoch 37
I0916 20:06:08.887816 20216 solver.cpp:314] Iteration 54300 (5.03815 iter/s, 19.8485s/100 iter), loss = 0.0719034
I0916 20:06:08.887845 20216 solver.cpp:336]     Train net output #0: loss = 0.0719035 (* 1 = 0.0719035 loss)
I0916 20:06:08.887851 20216 sgd_solver.cpp:136] Iteration 54300, lr = 0.0001, m = 0.9
I0916 20:06:28.697309 20216 solver.cpp:314] Iteration 54400 (5.04823 iter/s, 19.8089s/100 iter), loss = 0.0389455
I0916 20:06:28.697362 20216 solver.cpp:336]     Train net output #0: loss = 0.0389456 (* 1 = 0.0389456 loss)
I0916 20:06:28.697369 20216 sgd_solver.cpp:136] Iteration 54400, lr = 0.0001, m = 0.9
I0916 20:06:48.462004 20216 solver.cpp:314] Iteration 54500 (5.05967 iter/s, 19.7641s/100 iter), loss = 0.102898
I0916 20:06:48.462041 20216 solver.cpp:336]     Train net output #0: loss = 0.102898 (* 1 = 0.102898 loss)
I0916 20:06:48.462049 20216 sgd_solver.cpp:136] Iteration 54500, lr = 0.0001, m = 0.9
I0916 20:06:56.184355 20224 data_reader.cpp:305] Starting prefetch of epoch 36
I0916 20:07:08.401298 20216 solver.cpp:314] Iteration 54600 (5.01536 iter/s, 19.9387s/100 iter), loss = 0.0504665
I0916 20:07:08.401394 20216 solver.cpp:336]     Train net output #0: loss = 0.0504666 (* 1 = 0.0504666 loss)
I0916 20:07:08.401401 20216 sgd_solver.cpp:136] Iteration 54600, lr = 0.0001, m = 0.9
I0916 20:07:28.354248 20216 solver.cpp:314] Iteration 54700 (5.01193 iter/s, 19.9524s/100 iter), loss = 0.06371
I0916 20:07:28.354276 20216 solver.cpp:336]     Train net output #0: loss = 0.0637102 (* 1 = 0.0637102 loss)
I0916 20:07:28.354280 20216 sgd_solver.cpp:136] Iteration 54700, lr = 0.0001, m = 0.9
I0916 20:07:48.452826 20216 solver.cpp:314] Iteration 54800 (4.97562 iter/s, 20.098s/100 iter), loss = 0.0515298
I0916 20:07:48.452901 20216 solver.cpp:336]     Train net output #0: loss = 0.05153 (* 1 = 0.05153 loss)
I0916 20:07:48.452911 20216 sgd_solver.cpp:136] Iteration 54800, lr = 0.0001, m = 0.9
I0916 20:08:02.381479 20223 data_reader.cpp:305] Starting prefetch of epoch 23
I0916 20:08:08.615212 20216 solver.cpp:314] Iteration 54900 (4.95987 iter/s, 20.1618s/100 iter), loss = 0.0551676
I0916 20:08:08.615236 20216 solver.cpp:336]     Train net output #0: loss = 0.0551677 (* 1 = 0.0551677 loss)
I0916 20:08:08.615243 20216 sgd_solver.cpp:136] Iteration 54900, lr = 0.0001, m = 0.9
I0916 20:08:28.584183 20216 solver.cpp:314] Iteration 55000 (5.00791 iter/s, 19.9684s/100 iter), loss = 0.0999661
I0916 20:08:28.584267 20216 solver.cpp:336]     Train net output #0: loss = 0.0999662 (* 1 = 0.0999662 loss)
I0916 20:08:28.584278 20216 sgd_solver.cpp:136] Iteration 55000, lr = 0.0001, m = 0.9
I0916 20:08:35.610749 20220 data_reader.cpp:305] Starting prefetch of epoch 38
I0916 20:08:48.794566 20216 solver.cpp:314] Iteration 55100 (4.94809 iter/s, 20.2098s/100 iter), loss = 0.0725234
I0916 20:08:48.794600 20216 solver.cpp:336]     Train net output #0: loss = 0.0725235 (* 1 = 0.0725235 loss)
I0916 20:08:48.794607 20216 sgd_solver.cpp:136] Iteration 55100, lr = 0.0001, m = 0.9
I0916 20:09:08.749090 20216 solver.cpp:314] Iteration 55200 (5.01154 iter/s, 19.954s/100 iter), loss = 0.0419128
I0916 20:09:08.749397 20216 solver.cpp:336]     Train net output #0: loss = 0.0419129 (* 1 = 0.0419129 loss)
I0916 20:09:08.749408 20216 sgd_solver.cpp:136] Iteration 55200, lr = 0.0001, m = 0.9
I0916 20:09:28.620136 20216 solver.cpp:314] Iteration 55300 (5.03259 iter/s, 19.8705s/100 iter), loss = 0.0616943
I0916 20:09:28.620167 20216 solver.cpp:336]     Train net output #0: loss = 0.0616944 (* 1 = 0.0616944 loss)
I0916 20:09:28.620173 20216 sgd_solver.cpp:136] Iteration 55300, lr = 0.0001, m = 0.9
I0916 20:09:41.529086 20224 data_reader.cpp:305] Starting prefetch of epoch 37
I0916 20:09:48.579453 20216 solver.cpp:314] Iteration 55400 (5.01033 iter/s, 19.9588s/100 iter), loss = 0.042525
I0916 20:09:48.579696 20216 solver.cpp:336]     Train net output #0: loss = 0.0425251 (* 1 = 0.0425251 loss)
I0916 20:09:48.584236 20216 sgd_solver.cpp:136] Iteration 55400, lr = 0.0001, m = 0.9
I0916 20:10:08.337648 20216 solver.cpp:314] Iteration 55500 (5.06133 iter/s, 19.7576s/100 iter), loss = 0.0441657
I0916 20:10:08.337677 20216 solver.cpp:336]     Train net output #0: loss = 0.0441659 (* 1 = 0.0441659 loss)
I0916 20:10:08.337682 20216 sgd_solver.cpp:136] Iteration 55500, lr = 0.0001, m = 0.9
I0916 20:10:28.533582 20216 solver.cpp:314] Iteration 55600 (4.95163 iter/s, 20.1954s/100 iter), loss = 0.057772
I0916 20:10:28.533659 20216 solver.cpp:336]     Train net output #0: loss = 0.0577721 (* 1 = 0.0577721 loss)
I0916 20:10:28.533668 20216 sgd_solver.cpp:136] Iteration 55600, lr = 0.0001, m = 0.9
I0916 20:10:47.532928 20223 data_reader.cpp:305] Starting prefetch of epoch 24
I0916 20:10:48.540740 20216 solver.cpp:314] Iteration 55700 (4.99835 iter/s, 20.0066s/100 iter), loss = 0.0354502
I0916 20:10:48.540828 20216 solver.cpp:336]     Train net output #0: loss = 0.0354503 (* 1 = 0.0354503 loss)
I0916 20:10:48.540848 20216 sgd_solver.cpp:136] Iteration 55700, lr = 0.0001, m = 0.9
I0916 20:11:08.667811 20216 solver.cpp:314] Iteration 55800 (4.96858 iter/s, 20.1265s/100 iter), loss = 0.0479862
I0916 20:11:08.694149 20216 solver.cpp:336]     Train net output #0: loss = 0.0479863 (* 1 = 0.0479863 loss)
I0916 20:11:08.694432 20216 sgd_solver.cpp:136] Iteration 55800, lr = 0.0001, m = 0.9
I0916 20:11:20.603847 20195 data_reader.cpp:305] Starting prefetch of epoch 26
I0916 20:11:28.604326 20216 solver.cpp:314] Iteration 55900 (5.01606 iter/s, 19.936s/100 iter), loss = 0.085463
I0916 20:11:28.604391 20216 solver.cpp:336]     Train net output #0: loss = 0.0854632 (* 1 = 0.0854632 loss)
I0916 20:11:28.604409 20216 sgd_solver.cpp:136] Iteration 55900, lr = 0.0001, m = 0.9
I0916 20:11:48.685719 20216 solver.cpp:563] Iteration 56000, Testing net (#0)
I0916 20:12:02.330919 20241 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 20:12:02.556265 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.95494
I0916 20:12:02.556287 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 20:12:02.556293 20216 solver.cpp:655]     Test net output #2: loss = 0.146093 (* 1 = 0.146093 loss)
I0916 20:12:02.556372 20216 solver.cpp:265] [MultiGPU] Tests completed in 13.8703s
I0916 20:12:02.759585 20216 solver.cpp:314] Iteration 56000 (2.92789 iter/s, 34.1543s/100 iter), loss = 0.0608156
I0916 20:12:02.759611 20216 solver.cpp:336]     Train net output #0: loss = 0.0608158 (* 1 = 0.0608158 loss)
I0916 20:12:02.759615 20216 sgd_solver.cpp:136] Iteration 56000, lr = 0.0001, m = 0.9
I0916 20:12:22.243700 20216 solver.cpp:314] Iteration 56100 (5.13253 iter/s, 19.4836s/100 iter), loss = 0.0744146
I0916 20:12:22.243790 20216 solver.cpp:336]     Train net output #0: loss = 0.0744147 (* 1 = 0.0744147 loss)
I0916 20:12:22.243798 20216 sgd_solver.cpp:136] Iteration 56100, lr = 0.0001, m = 0.9
I0916 20:12:40.371466 20197 data_reader.cpp:305] Starting prefetch of epoch 33
I0916 20:12:42.143050 20216 solver.cpp:314] Iteration 56200 (5.02543 iter/s, 19.8988s/100 iter), loss = 0.0496425
I0916 20:12:42.143074 20216 solver.cpp:336]     Train net output #0: loss = 0.0496426 (* 1 = 0.0496426 loss)
I0916 20:12:42.143079 20216 sgd_solver.cpp:136] Iteration 56200, lr = 0.0001, m = 0.9
I0916 20:13:02.119839 20216 solver.cpp:314] Iteration 56300 (5.00595 iter/s, 19.9762s/100 iter), loss = 0.0504875
I0916 20:13:02.119902 20216 solver.cpp:336]     Train net output #0: loss = 0.0504876 (* 1 = 0.0504876 loss)
I0916 20:13:02.119910 20216 sgd_solver.cpp:136] Iteration 56300, lr = 0.0001, m = 0.9
I0916 20:13:13.416491 20219 data_reader.cpp:305] Starting prefetch of epoch 43
I0916 20:13:22.256814 20216 solver.cpp:314] Iteration 56400 (4.96613 iter/s, 20.1364s/100 iter), loss = 0.0821847
I0916 20:13:22.256839 20216 solver.cpp:336]     Train net output #0: loss = 0.0821848 (* 1 = 0.0821848 loss)
I0916 20:13:22.256844 20216 sgd_solver.cpp:136] Iteration 56400, lr = 0.0001, m = 0.9
I0916 20:13:42.018115 20216 solver.cpp:314] Iteration 56500 (5.06054 iter/s, 19.7607s/100 iter), loss = 0.0624651
I0916 20:13:42.029260 20216 solver.cpp:336]     Train net output #0: loss = 0.0624652 (* 1 = 0.0624652 loss)
I0916 20:13:42.029279 20216 sgd_solver.cpp:136] Iteration 56500, lr = 0.0001, m = 0.9
I0916 20:14:01.851074 20216 solver.cpp:314] Iteration 56600 (5.04225 iter/s, 19.8324s/100 iter), loss = 0.0540481
I0916 20:14:01.851107 20216 solver.cpp:336]     Train net output #0: loss = 0.0540483 (* 1 = 0.0540483 loss)
I0916 20:14:01.851114 20216 sgd_solver.cpp:136] Iteration 56600, lr = 0.0001, m = 0.9
I0916 20:14:19.102849 20219 data_reader.cpp:305] Starting prefetch of epoch 44
I0916 20:14:21.665583 20216 solver.cpp:314] Iteration 56700 (5.04695 iter/s, 19.814s/100 iter), loss = 0.0630405
I0916 20:14:21.665611 20216 solver.cpp:336]     Train net output #0: loss = 0.0630406 (* 1 = 0.0630406 loss)
I0916 20:14:21.665618 20216 sgd_solver.cpp:136] Iteration 56700, lr = 0.0001, m = 0.9
I0916 20:14:41.201230 20216 solver.cpp:314] Iteration 56800 (5.11899 iter/s, 19.5351s/100 iter), loss = 0.0657645
I0916 20:14:41.201257 20216 solver.cpp:336]     Train net output #0: loss = 0.0657646 (* 1 = 0.0657646 loss)
I0916 20:14:41.201262 20216 sgd_solver.cpp:136] Iteration 56800, lr = 0.0001, m = 0.9
I0916 20:15:01.145164 20216 solver.cpp:314] Iteration 56900 (5.0142 iter/s, 19.9434s/100 iter), loss = 0.0435983
I0916 20:15:01.145265 20216 solver.cpp:336]     Train net output #0: loss = 0.0435984 (* 1 = 0.0435984 loss)
I0916 20:15:01.145273 20216 sgd_solver.cpp:136] Iteration 56900, lr = 0.0001, m = 0.9
I0916 20:15:20.967084 20216 solver.cpp:314] Iteration 57000 (5.04506 iter/s, 19.8214s/100 iter), loss = 0.0643915
I0916 20:15:20.967118 20216 solver.cpp:336]     Train net output #0: loss = 0.0643916 (* 1 = 0.0643916 loss)
I0916 20:15:20.967125 20216 sgd_solver.cpp:136] Iteration 57000, lr = 0.0001, m = 0.9
I0916 20:15:24.297533 20224 data_reader.cpp:305] Starting prefetch of epoch 38
I0916 20:15:40.547138 20216 solver.cpp:314] Iteration 57100 (5.10738 iter/s, 19.5795s/100 iter), loss = 0.0698923
I0916 20:15:40.547195 20216 solver.cpp:336]     Train net output #0: loss = 0.0698924 (* 1 = 0.0698924 loss)
I0916 20:15:40.547200 20216 sgd_solver.cpp:136] Iteration 57100, lr = 0.0001, m = 0.9
I0916 20:15:56.997056 20220 data_reader.cpp:305] Starting prefetch of epoch 39
I0916 20:16:00.288813 20216 solver.cpp:314] Iteration 57200 (5.06557 iter/s, 19.7411s/100 iter), loss = 0.0480078
I0916 20:16:00.288837 20216 solver.cpp:336]     Train net output #0: loss = 0.0480079 (* 1 = 0.0480079 loss)
I0916 20:16:00.288842 20216 sgd_solver.cpp:136] Iteration 57200, lr = 0.0001, m = 0.9
I0916 20:16:20.124600 20216 solver.cpp:314] Iteration 57300 (5.04153 iter/s, 19.8352s/100 iter), loss = 0.0632591
I0916 20:16:20.124650 20216 solver.cpp:336]     Train net output #0: loss = 0.0632592 (* 1 = 0.0632592 loss)
I0916 20:16:20.124655 20216 sgd_solver.cpp:136] Iteration 57300, lr = 0.0001, m = 0.9
I0916 20:16:39.968519 20216 solver.cpp:314] Iteration 57400 (5.03947 iter/s, 19.8434s/100 iter), loss = 0.0459265
I0916 20:16:39.968554 20216 solver.cpp:336]     Train net output #0: loss = 0.0459266 (* 1 = 0.0459266 loss)
I0916 20:16:39.968559 20216 sgd_solver.cpp:136] Iteration 57400, lr = 0.0001, m = 0.9
I0916 20:16:59.831657 20216 solver.cpp:314] Iteration 57500 (5.03459 iter/s, 19.8626s/100 iter), loss = 0.0835289
I0916 20:16:59.831712 20216 solver.cpp:336]     Train net output #0: loss = 0.083529 (* 1 = 0.083529 loss)
I0916 20:16:59.831717 20216 sgd_solver.cpp:136] Iteration 57500, lr = 0.0001, m = 0.9
I0916 20:17:02.405951 20195 data_reader.cpp:305] Starting prefetch of epoch 27
I0916 20:17:19.168907 20216 solver.cpp:314] Iteration 57600 (5.17151 iter/s, 19.3367s/100 iter), loss = 0.0427224
I0916 20:17:19.168931 20216 solver.cpp:336]     Train net output #0: loss = 0.0427225 (* 1 = 0.0427225 loss)
I0916 20:17:19.168936 20216 sgd_solver.cpp:136] Iteration 57600, lr = 0.0001, m = 0.9
I0916 20:17:38.725216 20216 solver.cpp:314] Iteration 57700 (5.11358 iter/s, 19.5558s/100 iter), loss = 0.0613167
I0916 20:17:38.725297 20216 solver.cpp:336]     Train net output #0: loss = 0.0613168 (* 1 = 0.0613168 loss)
I0916 20:17:38.725303 20216 sgd_solver.cpp:136] Iteration 57700, lr = 0.0001, m = 0.9
I0916 20:17:58.299479 20216 solver.cpp:314] Iteration 57800 (5.10889 iter/s, 19.5737s/100 iter), loss = 0.0328406
I0916 20:17:58.299510 20216 solver.cpp:336]     Train net output #0: loss = 0.0328407 (* 1 = 0.0328407 loss)
I0916 20:17:58.299516 20216 sgd_solver.cpp:136] Iteration 57800, lr = 0.0001, m = 0.9
I0916 20:18:06.962812 20223 data_reader.cpp:305] Starting prefetch of epoch 25
I0916 20:18:18.077920 20216 solver.cpp:314] Iteration 57900 (5.05615 iter/s, 19.7779s/100 iter), loss = 0.0333292
I0916 20:18:18.078021 20216 solver.cpp:336]     Train net output #0: loss = 0.0333293 (* 1 = 0.0333293 loss)
I0916 20:18:18.078034 20216 sgd_solver.cpp:136] Iteration 57900, lr = 0.0001, m = 0.9
I0916 20:18:37.697520 20216 solver.cpp:563] Iteration 58000, Testing net (#0)
I0916 20:18:46.333200 20241 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 20:18:50.554177 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.957319
I0916 20:18:50.554278 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 20:18:50.554288 20216 solver.cpp:655]     Test net output #2: loss = 0.167713 (* 1 = 0.167713 loss)
I0916 20:18:50.554314 20216 solver.cpp:265] [MultiGPU] Tests completed in 12.8564s
I0916 20:18:50.764966 20216 solver.cpp:314] Iteration 58000 (3.0594 iter/s, 32.6861s/100 iter), loss = 0.0330061
I0916 20:18:50.764991 20216 solver.cpp:336]     Train net output #0: loss = 0.0330062 (* 1 = 0.0330062 loss)
I0916 20:18:50.764994 20216 sgd_solver.cpp:136] Iteration 58000, lr = 0.0001, m = 0.9
I0916 20:19:10.968441 20216 solver.cpp:314] Iteration 58100 (4.94978 iter/s, 20.2029s/100 iter), loss = 0.0458601
I0916 20:19:10.968466 20216 solver.cpp:336]     Train net output #0: loss = 0.0458602 (* 1 = 0.0458602 loss)
I0916 20:19:10.968471 20216 sgd_solver.cpp:136] Iteration 58100, lr = 0.0001, m = 0.9
I0916 20:19:25.726198 20219 data_reader.cpp:305] Starting prefetch of epoch 45
I0916 20:19:30.883913 20216 solver.cpp:314] Iteration 58200 (5.02136 iter/s, 19.9149s/100 iter), loss = 0.066312
I0916 20:19:30.883939 20216 solver.cpp:336]     Train net output #0: loss = 0.0663121 (* 1 = 0.0663121 loss)
I0916 20:19:30.883944 20216 sgd_solver.cpp:136] Iteration 58200, lr = 0.0001, m = 0.9
I0916 20:19:50.750663 20216 solver.cpp:314] Iteration 58300 (5.03368 iter/s, 19.8662s/100 iter), loss = 0.0354339
I0916 20:19:50.750689 20216 solver.cpp:336]     Train net output #0: loss = 0.035434 (* 1 = 0.035434 loss)
I0916 20:19:50.750695 20216 sgd_solver.cpp:136] Iteration 58300, lr = 0.0001, m = 0.9
I0916 20:20:10.806777 20216 solver.cpp:314] Iteration 58400 (4.98615 iter/s, 20.0556s/100 iter), loss = 0.0717984
I0916 20:20:10.806895 20216 solver.cpp:336]     Train net output #0: loss = 0.0717985 (* 1 = 0.0717985 loss)
I0916 20:20:10.806905 20216 sgd_solver.cpp:136] Iteration 58400, lr = 0.0001, m = 0.9
I0916 20:20:30.924041 20216 solver.cpp:314] Iteration 58500 (4.97099 iter/s, 20.1167s/100 iter), loss = 0.0307386
I0916 20:20:30.924068 20216 solver.cpp:336]     Train net output #0: loss = 0.0307387 (* 1 = 0.0307387 loss)
I0916 20:20:30.924072 20216 sgd_solver.cpp:136] Iteration 58500, lr = 0.0001, m = 0.9
I0916 20:20:31.973170 20223 data_reader.cpp:305] Starting prefetch of epoch 26
I0916 20:20:50.670367 20216 solver.cpp:314] Iteration 58600 (5.06438 iter/s, 19.7458s/100 iter), loss = 0.0684625
I0916 20:20:50.670447 20216 solver.cpp:336]     Train net output #0: loss = 0.0684627 (* 1 = 0.0684627 loss)
I0916 20:20:50.670457 20216 sgd_solver.cpp:136] Iteration 58600, lr = 0.0001, m = 0.9
I0916 20:21:05.087064 20195 data_reader.cpp:305] Starting prefetch of epoch 28
I0916 20:21:11.202807 20216 solver.cpp:314] Iteration 58700 (4.87048 iter/s, 20.5319s/100 iter), loss = 0.088402
I0916 20:21:11.202833 20216 solver.cpp:336]     Train net output #0: loss = 0.0884021 (* 1 = 0.0884021 loss)
I0916 20:21:11.202838 20216 sgd_solver.cpp:136] Iteration 58700, lr = 0.0001, m = 0.9
I0916 20:21:31.584801 20216 solver.cpp:314] Iteration 58800 (4.90643 iter/s, 20.3814s/100 iter), loss = 0.0639708
I0916 20:21:31.584847 20216 solver.cpp:336]     Train net output #0: loss = 0.0639709 (* 1 = 0.0639709 loss)
I0916 20:21:31.584853 20216 sgd_solver.cpp:136] Iteration 58800, lr = 0.0001, m = 0.9
I0916 20:21:51.664202 20216 solver.cpp:314] Iteration 58900 (4.98037 iter/s, 20.0788s/100 iter), loss = 0.0495426
I0916 20:21:51.664227 20216 solver.cpp:336]     Train net output #0: loss = 0.0495428 (* 1 = 0.0495428 loss)
I0916 20:21:51.664232 20216 sgd_solver.cpp:136] Iteration 58900, lr = 0.0001, m = 0.9
I0916 20:22:11.837088 20216 solver.cpp:314] Iteration 59000 (4.95729 iter/s, 20.1723s/100 iter), loss = 0.0457402
I0916 20:22:11.837177 20216 solver.cpp:336]     Train net output #0: loss = 0.0457404 (* 1 = 0.0457404 loss)
I0916 20:22:11.837185 20216 sgd_solver.cpp:136] Iteration 59000, lr = 0.0001, m = 0.9
I0916 20:22:12.069550 20224 data_reader.cpp:305] Starting prefetch of epoch 39
I0916 20:22:32.091253 20216 solver.cpp:314] Iteration 59100 (4.93777 iter/s, 20.252s/100 iter), loss = 0.0468025
I0916 20:22:32.091312 20216 solver.cpp:336]     Train net output #0: loss = 0.0468026 (* 1 = 0.0468026 loss)
I0916 20:22:32.091326 20216 sgd_solver.cpp:136] Iteration 59100, lr = 0.0001, m = 0.9
I0916 20:22:52.263814 20216 solver.cpp:314] Iteration 59200 (4.95737 iter/s, 20.172s/100 iter), loss = 0.0520372
I0916 20:22:52.263890 20216 solver.cpp:336]     Train net output #0: loss = 0.0520373 (* 1 = 0.0520373 loss)
I0916 20:22:52.263898 20216 sgd_solver.cpp:136] Iteration 59200, lr = 0.0001, m = 0.9
I0916 20:23:11.911548 20216 solver.cpp:314] Iteration 59300 (5.08979 iter/s, 19.6472s/100 iter), loss = 0.037459
I0916 20:23:11.911578 20216 solver.cpp:336]     Train net output #0: loss = 0.0374591 (* 1 = 0.0374591 loss)
I0916 20:23:11.911586 20216 sgd_solver.cpp:136] Iteration 59300, lr = 0.0001, m = 0.9
I0916 20:23:18.135131 20220 data_reader.cpp:305] Starting prefetch of epoch 40
I0916 20:23:32.026746 20216 solver.cpp:314] Iteration 59400 (4.97151 iter/s, 20.1146s/100 iter), loss = 0.051275
I0916 20:23:32.026804 20216 solver.cpp:336]     Train net output #0: loss = 0.0512751 (* 1 = 0.0512751 loss)
I0916 20:23:32.026810 20216 sgd_solver.cpp:136] Iteration 59400, lr = 0.0001, m = 0.9
I0916 20:23:51.517132 20219 data_reader.cpp:305] Starting prefetch of epoch 46
I0916 20:23:52.257676 20216 solver.cpp:314] Iteration 59500 (4.94306 iter/s, 20.2304s/100 iter), loss = 0.0527432
I0916 20:23:52.257705 20216 solver.cpp:336]     Train net output #0: loss = 0.0527433 (* 1 = 0.0527433 loss)
I0916 20:23:52.257711 20216 sgd_solver.cpp:136] Iteration 59500, lr = 0.0001, m = 0.9
I0916 20:24:12.323619 20216 solver.cpp:314] Iteration 59600 (4.98371 iter/s, 20.0654s/100 iter), loss = 0.0462759
I0916 20:24:12.323678 20216 solver.cpp:336]     Train net output #0: loss = 0.046276 (* 1 = 0.046276 loss)
I0916 20:24:12.323683 20216 sgd_solver.cpp:136] Iteration 59600, lr = 0.0001, m = 0.9
I0916 20:24:32.586323 20216 solver.cpp:314] Iteration 59700 (4.93531 iter/s, 20.2621s/100 iter), loss = 0.0717289
I0916 20:24:32.586345 20216 solver.cpp:336]     Train net output #0: loss = 0.071729 (* 1 = 0.071729 loss)
I0916 20:24:32.586349 20216 sgd_solver.cpp:136] Iteration 59700, lr = 0.0001, m = 0.9
I0916 20:24:53.057204 20216 solver.cpp:314] Iteration 59800 (4.88512 iter/s, 20.4703s/100 iter), loss = 0.0836862
I0916 20:24:53.057303 20216 solver.cpp:336]     Train net output #0: loss = 0.0836863 (* 1 = 0.0836863 loss)
I0916 20:24:53.057312 20216 sgd_solver.cpp:136] Iteration 59800, lr = 0.0001, m = 0.9
I0916 20:24:58.458498 20220 data_reader.cpp:305] Starting prefetch of epoch 41
I0916 20:25:12.763021 20216 solver.cpp:314] Iteration 59900 (5.07479 iter/s, 19.7053s/100 iter), loss = 0.0540514
I0916 20:25:12.763046 20216 solver.cpp:336]     Train net output #0: loss = 0.0540515 (* 1 = 0.0540515 loss)
I0916 20:25:12.763051 20216 sgd_solver.cpp:136] Iteration 59900, lr = 0.0001, m = 0.9
I0916 20:25:32.396756 20216 solver.cpp:314] Iteration 59999 (5.04248 iter/s, 19.6332s/99 iter), loss = 0.054542
I0916 20:25:32.396836 20216 solver.cpp:336]     Train net output #0: loss = 0.0545421 (* 1 = 0.0545421 loss)
I0916 20:25:32.396844 20216 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/cityscapes5_jsegnet21v2_iter_60000.caffemodel
I0916 20:25:32.645040 20216 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/cityscapes5_jsegnet21v2_iter_60000.solverstate
I0916 20:25:32.719274 20216 solver.cpp:538] Iteration 60000, loss = 0.0498918
I0916 20:25:32.719323 20216 solver.cpp:563] Iteration 60000, Testing net (#0)
I0916 20:25:38.061920 20243 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 20:25:48.822120 20241 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 20:25:49.489050 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.954699
I0916 20:25:49.489071 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 20:25:49.489076 20216 solver.cpp:655]     Test net output #2: loss = 0.147399 (* 1 = 0.147399 loss)
I0916 20:25:49.620254 20128 parallel.cpp:71] Root Solver performance on device 0: 4.894 * 6 = 29.36 img/sec (60000 itr in 1.226e+04 sec)
I0916 20:25:49.620367 20128 parallel.cpp:76]      Solver performance on device 1: 4.894 * 6 = 29.36 img/sec (60000 itr in 1.226e+04 sec)
I0916 20:25:49.620376 20128 parallel.cpp:76]      Solver performance on device 2: 4.894 * 6 = 29.36 img/sec (60000 itr in 1.226e+04 sec)
I0916 20:25:49.620380 20128 parallel.cpp:79] Overall multi-GPU performance: 88.0888 img/sec
I0916 20:25:51.277590 20128 caffe.cpp:253] Optimization Done in 3h 24m 45s
training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/sparse/run.sh: line 1: cd: /user/a0393608/files/work/code/vision/ti/bitbucket/algoref/caffe-jacinto/build/tools/caffe.bin: Not a directory
I0916 20:26:03.384778 13475 caffe.cpp:807] This is NVCaffe 0.16.4 started at Sat Sep 16 20:26:02 2017
I0916 20:26:03.385712 13475 caffe.cpp:810] CuDNN version: 6021
I0916 20:26:03.385717 13475 caffe.cpp:811] CuBLAS version: 8000
I0916 20:26:03.385720 13475 caffe.cpp:812] CUDA version: 8000
I0916 20:26:03.385723 13475 caffe.cpp:813] CUDA driver version: 8000
I0916 20:26:03.792191 13475 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0916 20:26:03.792779 13475 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8278441984, dev_info[0]: total=8506769408 free=8278441984
I0916 20:26:03.793313 13475 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8278441984, dev_info[1]: total=8508145664 free=8379236352
I0916 20:26:03.793841 13475 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8278441984, dev_info[2]: total=8508145664 free=8379236352
I0916 20:26:03.793853 13475 caffe.cpp:214] Using GPUs 0, 1, 2
I0916 20:26:03.794181 13475 caffe.cpp:219] GPU 0: GeForce GTX 1080
I0916 20:26:03.794505 13475 caffe.cpp:219] GPU 1: GeForce GTX 1080
I0916 20:26:03.794828 13475 caffe.cpp:219] GPU 2: GeForce GTX 1080
I0916 20:26:03.795560 13475 solver.cpp:43] Solver data type: FLOAT
I0916 20:26:03.795631 13475 solver.cpp:46] Initializing solver from parameters: 
train_net: "training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/sparse/train.prototxt"
test_net: "training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/sparse/test.prototxt"
test_iter: 125
test_interval: 2000
base_lr: 0.01
display: 100
max_iter: 60000
lr_policy: "multistep"
gamma: 0.1
power: 1
momentum: 0.9
weight_decay: 1e-05
snapshot: 10000
snapshot_prefix: "training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/sparse/cityscapes5_jsegnet21v2"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
snapshot_after_train: true
regularization_type: "L1"
test_initialization: false
stepvalue: 30000
stepvalue: 45000
iter_size: 1
type: "SGD"
display_sparsity: 1000
sparse_mode: SPARSE_UPDATE
sparsity_target: 0.8
sparsity_step_factor: 0.01
sparsity_step_iter: 1000
sparsity_start_iter: 3000
sparsity_start_factor: 0.8
I0916 20:26:03.814507 13475 solver.cpp:78] Creating training net from train_net file: training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/sparse/train.prototxt
I0916 20:26:03.815695 13475 net.cpp:443] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top1
I0916 20:26:03.815703 13475 net.cpp:443] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top5
W0916 20:26:03.815739 13475 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 16 to 18
I0916 20:26:03.816107 13475 net.cpp:72] Initializing net from parameters: 
name: "jsegnet21v2_train"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageLabelData"
  top: "data"
  top: "label"
  transform_param {
    mirror: true
    crop_size: 640
    mean_value: 0
  }
  image_label_data_param {
    image_list_path: "data/train-image-lmdb"
    label_list_path: "data/train-label-lmdb"
    batch_size: 6
    shuffle: true
    threads: 1
    backend: LMDB
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "out5a"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "out5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "out5a/bn"
  type: "BatchNorm"
  bottom: "out5a"
  top: "out5a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out5a/relu"
  type: "ReLU"
  bottom: "out5a"
  top: "out5a"
}
layer {
  name: "out5a_up2"
  type: "Deconvolution"
  bottom: "out5a"
  top: "out5a_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 64
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out3a"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "out3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "out3a/bn"
  type: "BatchNorm"
  bottom: "out3a"
  top: "out3a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out3a/relu"
  type: "ReLU"
  bottom: "out3a"
  top: "out3a"
}
layer {
  name: "out3_out5_combined"
  type: "Eltwise"
  bottom: "out5a_up2"
  bottom: "out3a"
  top: "out3_out5_combined"
}
layer {
  name: "ctx_conv1"
  type: "Convolution"
  bottom: "out3_out5_combined"
  top: "ctx_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_conv1/bn"
  type: "BatchNorm"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv1/relu"
  type: "ReLU"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
}
layer {
  name: "ctx_conv2"
  type: "Convolution"
  bottom: "ctx_conv1"
  top: "ctx_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv2/bn"
  type: "BatchNorm"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv2/relu"
  type: "ReLU"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
}
layer {
  name: "ctx_conv3"
  type: "Convolution"
  bottom: "ctx_conv2"
  top: "ctx_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv3/bn"
  type: "BatchNorm"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv3/relu"
  type: "ReLU"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
}
layer {
  name: "ctx_conv4"
  type: "Convolution"
  bottom: "ctx_conv3"
  top: "ctx_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv4/bn"
  type: "BatchNorm"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv4/relu"
  type: "ReLU"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
}
layer {
  name: "ctx_final"
  type: "Convolution"
  bottom: "ctx_conv4"
  top: "ctx_final"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_final/relu"
  type: "ReLU"
  bottom: "ctx_final"
  top: "ctx_final"
}
layer {
  name: "out_deconv_final_up2"
  type: "Deconvolution"
  bottom: "ctx_final"
  top: "out_deconv_final_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up4"
  type: "Deconvolution"
  bottom: "out_deconv_final_up2"
  top: "out_deconv_final_up4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up8"
  type: "Deconvolution"
  bottom: "out_deconv_final_up4"
  top: "out_deconv_final_up8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: 255
    normalization: VALID
  }
}
I0916 20:26:03.816318 13475 net.cpp:104] Using FLOAT as default forward math type
I0916 20:26:03.816323 13475 net.cpp:110] Using FLOAT as default backward math type
I0916 20:26:03.816328 13475 layer_factory.hpp:136] Creating layer 'data' of type 'ImageLabelData'
I0916 20:26:03.816331 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:03.816345 13475 net.cpp:184] Created Layer data (0)
I0916 20:26:03.816350 13475 net.cpp:530] data -> data
I0916 20:26:03.816367 13475 net.cpp:530] data -> label
I0916 20:26:03.843883 13475 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0916 20:26:03.843914 13475 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 20:26:03.879007 13544 db_lmdb.cpp:24] Opened lmdb data/train-image-lmdb
I0916 20:26:03.882166 13475 data_layer.cpp:187] [0] ReshapePrefetch 6, 3, 640, 640
I0916 20:26:03.882225 13475 data_layer.cpp:211] [0] Output data size: 6, 3, 640, 640
I0916 20:26:03.882232 13475 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 20:26:03.882282 13475 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0916 20:26:03.882292 13475 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 20:26:03.883015 13545 data_layer.cpp:101] [0] Parser threads: 1
I0916 20:26:03.883029 13545 data_layer.cpp:103] [0] Transformer threads: 1
I0916 20:26:03.906769 13546 db_lmdb.cpp:24] Opened lmdb data/train-label-lmdb
I0916 20:26:03.907951 13475 data_layer.cpp:187] [0] ReshapePrefetch 6, 1, 640, 640
I0916 20:26:03.908010 13475 data_layer.cpp:211] [0] Output data size: 6, 1, 640, 640
I0916 20:26:03.908017 13475 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 20:26:03.908087 13475 net.cpp:245] Setting up data
I0916 20:26:03.908121 13475 net.cpp:252] TRAIN Top shape for layer 0 'data' 6 3 640 640 (7372800)
I0916 20:26:03.908139 13475 net.cpp:252] TRAIN Top shape for layer 0 'data' 6 1 640 640 (2457600)
I0916 20:26:03.908157 13475 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0916 20:26:03.908172 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:03.908200 13475 net.cpp:184] Created Layer data/bias (1)
I0916 20:26:03.908216 13475 net.cpp:561] data/bias <- data
I0916 20:26:03.908236 13475 net.cpp:530] data/bias -> data/bias
I0916 20:26:03.913107 13547 data_layer.cpp:101] [0] Parser threads: 1
I0916 20:26:03.913128 13547 data_layer.cpp:103] [0] Transformer threads: 1
I0916 20:26:03.916240 13475 net.cpp:245] Setting up data/bias
I0916 20:26:03.916266 13475 net.cpp:252] TRAIN Top shape for layer 1 'data/bias' 6 3 640 640 (7372800)
I0916 20:26:03.916298 13475 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0916 20:26:03.916306 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:03.916329 13475 net.cpp:184] Created Layer conv1a (2)
I0916 20:26:03.916335 13475 net.cpp:561] conv1a <- data/bias
I0916 20:26:03.916339 13475 net.cpp:530] conv1a -> conv1a
I0916 20:26:04.558624 13475 net.cpp:245] Setting up conv1a
I0916 20:26:04.558647 13475 net.cpp:252] TRAIN Top shape for layer 2 'conv1a' 6 32 320 320 (19660800)
I0916 20:26:04.558661 13475 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0916 20:26:04.558666 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.558681 13475 net.cpp:184] Created Layer conv1a/bn (3)
I0916 20:26:04.558686 13475 net.cpp:561] conv1a/bn <- conv1a
I0916 20:26:04.558692 13475 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0916 20:26:04.559540 13475 net.cpp:245] Setting up conv1a/bn
I0916 20:26:04.559551 13475 net.cpp:252] TRAIN Top shape for layer 3 'conv1a/bn' 6 32 320 320 (19660800)
I0916 20:26:04.559561 13475 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0916 20:26:04.559566 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.559573 13475 net.cpp:184] Created Layer conv1a/relu (4)
I0916 20:26:04.559577 13475 net.cpp:561] conv1a/relu <- conv1a
I0916 20:26:04.559581 13475 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0916 20:26:04.577548 13475 net.cpp:245] Setting up conv1a/relu
I0916 20:26:04.577563 13475 net.cpp:252] TRAIN Top shape for layer 4 'conv1a/relu' 6 32 320 320 (19660800)
I0916 20:26:04.577567 13475 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0916 20:26:04.577572 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.577594 13475 net.cpp:184] Created Layer conv1b (5)
I0916 20:26:04.577597 13475 net.cpp:561] conv1b <- conv1a
I0916 20:26:04.577602 13475 net.cpp:530] conv1b -> conv1b
I0916 20:26:04.580039 13475 net.cpp:245] Setting up conv1b
I0916 20:26:04.580051 13475 net.cpp:252] TRAIN Top shape for layer 5 'conv1b' 6 32 320 320 (19660800)
I0916 20:26:04.580060 13475 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0916 20:26:04.580065 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.580072 13475 net.cpp:184] Created Layer conv1b/bn (6)
I0916 20:26:04.580076 13475 net.cpp:561] conv1b/bn <- conv1b
I0916 20:26:04.580080 13475 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0916 20:26:04.580864 13475 net.cpp:245] Setting up conv1b/bn
I0916 20:26:04.580873 13475 net.cpp:252] TRAIN Top shape for layer 6 'conv1b/bn' 6 32 320 320 (19660800)
I0916 20:26:04.580883 13475 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0916 20:26:04.580886 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.580891 13475 net.cpp:184] Created Layer conv1b/relu (7)
I0916 20:26:04.580894 13475 net.cpp:561] conv1b/relu <- conv1b
I0916 20:26:04.580898 13475 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0916 20:26:04.580902 13475 net.cpp:245] Setting up conv1b/relu
I0916 20:26:04.580906 13475 net.cpp:252] TRAIN Top shape for layer 7 'conv1b/relu' 6 32 320 320 (19660800)
I0916 20:26:04.580910 13475 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0916 20:26:04.580914 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.580921 13475 net.cpp:184] Created Layer pool1 (8)
I0916 20:26:04.580924 13475 net.cpp:561] pool1 <- conv1b
I0916 20:26:04.580929 13475 net.cpp:530] pool1 -> pool1
I0916 20:26:04.581018 13475 net.cpp:245] Setting up pool1
I0916 20:26:04.581025 13475 net.cpp:252] TRAIN Top shape for layer 8 'pool1' 6 32 160 160 (4915200)
I0916 20:26:04.581028 13475 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0916 20:26:04.581043 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.581051 13475 net.cpp:184] Created Layer res2a_branch2a (9)
I0916 20:26:04.581054 13475 net.cpp:561] res2a_branch2a <- pool1
I0916 20:26:04.581058 13475 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0916 20:26:04.583695 13475 net.cpp:245] Setting up res2a_branch2a
I0916 20:26:04.583708 13475 net.cpp:252] TRAIN Top shape for layer 9 'res2a_branch2a' 6 64 160 160 (9830400)
I0916 20:26:04.583715 13475 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0916 20:26:04.583719 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.583725 13475 net.cpp:184] Created Layer res2a_branch2a/bn (10)
I0916 20:26:04.583729 13475 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0916 20:26:04.583734 13475 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0916 20:26:04.585078 13475 net.cpp:245] Setting up res2a_branch2a/bn
I0916 20:26:04.585088 13475 net.cpp:252] TRAIN Top shape for layer 10 'res2a_branch2a/bn' 6 64 160 160 (9830400)
I0916 20:26:04.585096 13475 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0916 20:26:04.585100 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.585104 13475 net.cpp:184] Created Layer res2a_branch2a/relu (11)
I0916 20:26:04.585108 13475 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0916 20:26:04.585111 13475 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0916 20:26:04.585119 13475 net.cpp:245] Setting up res2a_branch2a/relu
I0916 20:26:04.585124 13475 net.cpp:252] TRAIN Top shape for layer 11 'res2a_branch2a/relu' 6 64 160 160 (9830400)
I0916 20:26:04.585127 13475 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0916 20:26:04.585130 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.585141 13475 net.cpp:184] Created Layer res2a_branch2b (12)
I0916 20:26:04.585145 13475 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0916 20:26:04.585149 13475 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0916 20:26:04.586973 13475 net.cpp:245] Setting up res2a_branch2b
I0916 20:26:04.586984 13475 net.cpp:252] TRAIN Top shape for layer 12 'res2a_branch2b' 6 64 160 160 (9830400)
I0916 20:26:04.586990 13475 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0916 20:26:04.586994 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.587000 13475 net.cpp:184] Created Layer res2a_branch2b/bn (13)
I0916 20:26:04.587003 13475 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0916 20:26:04.587007 13475 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0916 20:26:04.587779 13475 net.cpp:245] Setting up res2a_branch2b/bn
I0916 20:26:04.587786 13475 net.cpp:252] TRAIN Top shape for layer 13 'res2a_branch2b/bn' 6 64 160 160 (9830400)
I0916 20:26:04.587795 13475 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0916 20:26:04.587798 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.587805 13475 net.cpp:184] Created Layer res2a_branch2b/relu (14)
I0916 20:26:04.587807 13475 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0916 20:26:04.587810 13475 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0916 20:26:04.587815 13475 net.cpp:245] Setting up res2a_branch2b/relu
I0916 20:26:04.587819 13475 net.cpp:252] TRAIN Top shape for layer 14 'res2a_branch2b/relu' 6 64 160 160 (9830400)
I0916 20:26:04.587823 13475 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0916 20:26:04.587826 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.587831 13475 net.cpp:184] Created Layer pool2 (15)
I0916 20:26:04.587836 13475 net.cpp:561] pool2 <- res2a_branch2b
I0916 20:26:04.587847 13475 net.cpp:530] pool2 -> pool2
I0916 20:26:04.587925 13475 net.cpp:245] Setting up pool2
I0916 20:26:04.587931 13475 net.cpp:252] TRAIN Top shape for layer 15 'pool2' 6 64 80 80 (2457600)
I0916 20:26:04.587935 13475 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0916 20:26:04.587939 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.587947 13475 net.cpp:184] Created Layer res3a_branch2a (16)
I0916 20:26:04.587950 13475 net.cpp:561] res3a_branch2a <- pool2
I0916 20:26:04.587954 13475 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0916 20:26:04.590296 13475 net.cpp:245] Setting up res3a_branch2a
I0916 20:26:04.590306 13475 net.cpp:252] TRAIN Top shape for layer 16 'res3a_branch2a' 6 128 80 80 (4915200)
I0916 20:26:04.590312 13475 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0916 20:26:04.590315 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.590320 13475 net.cpp:184] Created Layer res3a_branch2a/bn (17)
I0916 20:26:04.590323 13475 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0916 20:26:04.590327 13475 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0916 20:26:04.591083 13475 net.cpp:245] Setting up res3a_branch2a/bn
I0916 20:26:04.591090 13475 net.cpp:252] TRAIN Top shape for layer 17 'res3a_branch2a/bn' 6 128 80 80 (4915200)
I0916 20:26:04.591102 13475 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0916 20:26:04.591105 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.591110 13475 net.cpp:184] Created Layer res3a_branch2a/relu (18)
I0916 20:26:04.591114 13475 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0916 20:26:04.591117 13475 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0916 20:26:04.591122 13475 net.cpp:245] Setting up res3a_branch2a/relu
I0916 20:26:04.591126 13475 net.cpp:252] TRAIN Top shape for layer 18 'res3a_branch2a/relu' 6 128 80 80 (4915200)
I0916 20:26:04.591130 13475 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0916 20:26:04.591135 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.591141 13475 net.cpp:184] Created Layer res3a_branch2b (19)
I0916 20:26:04.591145 13475 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0916 20:26:04.591148 13475 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0916 20:26:04.592521 13475 net.cpp:245] Setting up res3a_branch2b
I0916 20:26:04.592530 13475 net.cpp:252] TRAIN Top shape for layer 19 'res3a_branch2b' 6 128 80 80 (4915200)
I0916 20:26:04.592536 13475 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0916 20:26:04.592540 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.592545 13475 net.cpp:184] Created Layer res3a_branch2b/bn (20)
I0916 20:26:04.592548 13475 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0916 20:26:04.592551 13475 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0916 20:26:04.593289 13475 net.cpp:245] Setting up res3a_branch2b/bn
I0916 20:26:04.593297 13475 net.cpp:252] TRAIN Top shape for layer 20 'res3a_branch2b/bn' 6 128 80 80 (4915200)
I0916 20:26:04.593305 13475 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0916 20:26:04.593308 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.593312 13475 net.cpp:184] Created Layer res3a_branch2b/relu (21)
I0916 20:26:04.593315 13475 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0916 20:26:04.593319 13475 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0916 20:26:04.593323 13475 net.cpp:245] Setting up res3a_branch2b/relu
I0916 20:26:04.593327 13475 net.cpp:252] TRAIN Top shape for layer 21 'res3a_branch2b/relu' 6 128 80 80 (4915200)
I0916 20:26:04.593331 13475 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0916 20:26:04.593343 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.593349 13475 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (22)
I0916 20:26:04.593353 13475 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0916 20:26:04.593356 13475 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0916 20:26:04.593360 13475 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0916 20:26:04.593415 13475 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0916 20:26:04.593420 13475 net.cpp:252] TRAIN Top shape for layer 22 'res3a_branch2b_res3a_branch2b/relu_0_split' 6 128 80 80 (4915200)
I0916 20:26:04.593425 13475 net.cpp:252] TRAIN Top shape for layer 22 'res3a_branch2b_res3a_branch2b/relu_0_split' 6 128 80 80 (4915200)
I0916 20:26:04.593428 13475 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0916 20:26:04.593431 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.593436 13475 net.cpp:184] Created Layer pool3 (23)
I0916 20:26:04.593439 13475 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0916 20:26:04.593442 13475 net.cpp:530] pool3 -> pool3
I0916 20:26:04.593515 13475 net.cpp:245] Setting up pool3
I0916 20:26:04.593521 13475 net.cpp:252] TRAIN Top shape for layer 23 'pool3' 6 128 40 40 (1228800)
I0916 20:26:04.593525 13475 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0916 20:26:04.593528 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.593536 13475 net.cpp:184] Created Layer res4a_branch2a (24)
I0916 20:26:04.593539 13475 net.cpp:561] res4a_branch2a <- pool3
I0916 20:26:04.593544 13475 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0916 20:26:04.603111 13475 net.cpp:245] Setting up res4a_branch2a
I0916 20:26:04.603122 13475 net.cpp:252] TRAIN Top shape for layer 24 'res4a_branch2a' 6 256 40 40 (2457600)
I0916 20:26:04.603128 13475 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0916 20:26:04.603132 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.603137 13475 net.cpp:184] Created Layer res4a_branch2a/bn (25)
I0916 20:26:04.603138 13475 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0916 20:26:04.603142 13475 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0916 20:26:04.603752 13475 net.cpp:245] Setting up res4a_branch2a/bn
I0916 20:26:04.603760 13475 net.cpp:252] TRAIN Top shape for layer 25 'res4a_branch2a/bn' 6 256 40 40 (2457600)
I0916 20:26:04.603765 13475 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0916 20:26:04.603767 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.603770 13475 net.cpp:184] Created Layer res4a_branch2a/relu (26)
I0916 20:26:04.603772 13475 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0916 20:26:04.603775 13475 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0916 20:26:04.603778 13475 net.cpp:245] Setting up res4a_branch2a/relu
I0916 20:26:04.603781 13475 net.cpp:252] TRAIN Top shape for layer 26 'res4a_branch2a/relu' 6 256 40 40 (2457600)
I0916 20:26:04.603783 13475 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0916 20:26:04.603785 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.603791 13475 net.cpp:184] Created Layer res4a_branch2b (27)
I0916 20:26:04.603794 13475 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0916 20:26:04.603796 13475 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0916 20:26:04.607446 13475 net.cpp:245] Setting up res4a_branch2b
I0916 20:26:04.607461 13475 net.cpp:252] TRAIN Top shape for layer 27 'res4a_branch2b' 6 256 40 40 (2457600)
I0916 20:26:04.607482 13475 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0916 20:26:04.607486 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.607494 13475 net.cpp:184] Created Layer res4a_branch2b/bn (28)
I0916 20:26:04.607498 13475 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0916 20:26:04.607503 13475 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0916 20:26:04.608333 13475 net.cpp:245] Setting up res4a_branch2b/bn
I0916 20:26:04.608343 13475 net.cpp:252] TRAIN Top shape for layer 28 'res4a_branch2b/bn' 6 256 40 40 (2457600)
I0916 20:26:04.608352 13475 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0916 20:26:04.608356 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.608361 13475 net.cpp:184] Created Layer res4a_branch2b/relu (29)
I0916 20:26:04.608364 13475 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0916 20:26:04.608368 13475 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0916 20:26:04.608373 13475 net.cpp:245] Setting up res4a_branch2b/relu
I0916 20:26:04.608378 13475 net.cpp:252] TRAIN Top shape for layer 29 'res4a_branch2b/relu' 6 256 40 40 (2457600)
I0916 20:26:04.608381 13475 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0916 20:26:04.608386 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.608392 13475 net.cpp:184] Created Layer pool4 (30)
I0916 20:26:04.608395 13475 net.cpp:561] pool4 <- res4a_branch2b
I0916 20:26:04.608399 13475 net.cpp:530] pool4 -> pool4
I0916 20:26:04.608486 13475 net.cpp:245] Setting up pool4
I0916 20:26:04.608492 13475 net.cpp:252] TRAIN Top shape for layer 30 'pool4' 6 256 40 40 (2457600)
I0916 20:26:04.608497 13475 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0916 20:26:04.608505 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.608517 13475 net.cpp:184] Created Layer res5a_branch2a (31)
I0916 20:26:04.608522 13475 net.cpp:561] res5a_branch2a <- pool4
I0916 20:26:04.608526 13475 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0916 20:26:04.636540 13475 net.cpp:245] Setting up res5a_branch2a
I0916 20:26:04.636560 13475 net.cpp:252] TRAIN Top shape for layer 31 'res5a_branch2a' 6 512 40 40 (4915200)
I0916 20:26:04.636567 13475 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0916 20:26:04.636571 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.636584 13475 net.cpp:184] Created Layer res5a_branch2a/bn (32)
I0916 20:26:04.636589 13475 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0916 20:26:04.636591 13475 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0916 20:26:04.637228 13475 net.cpp:245] Setting up res5a_branch2a/bn
I0916 20:26:04.637234 13475 net.cpp:252] TRAIN Top shape for layer 32 'res5a_branch2a/bn' 6 512 40 40 (4915200)
I0916 20:26:04.637240 13475 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0916 20:26:04.637243 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.637246 13475 net.cpp:184] Created Layer res5a_branch2a/relu (33)
I0916 20:26:04.637248 13475 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0916 20:26:04.637251 13475 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0916 20:26:04.637255 13475 net.cpp:245] Setting up res5a_branch2a/relu
I0916 20:26:04.637257 13475 net.cpp:252] TRAIN Top shape for layer 33 'res5a_branch2a/relu' 6 512 40 40 (4915200)
I0916 20:26:04.637259 13475 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0916 20:26:04.637262 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.637269 13475 net.cpp:184] Created Layer res5a_branch2b (34)
I0916 20:26:04.637279 13475 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0916 20:26:04.637282 13475 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0916 20:26:04.651511 13475 net.cpp:245] Setting up res5a_branch2b
I0916 20:26:04.651536 13475 net.cpp:252] TRAIN Top shape for layer 34 'res5a_branch2b' 6 512 40 40 (4915200)
I0916 20:26:04.651548 13475 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0916 20:26:04.651553 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.651562 13475 net.cpp:184] Created Layer res5a_branch2b/bn (35)
I0916 20:26:04.651567 13475 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0916 20:26:04.651571 13475 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0916 20:26:04.652423 13475 net.cpp:245] Setting up res5a_branch2b/bn
I0916 20:26:04.652433 13475 net.cpp:252] TRAIN Top shape for layer 35 'res5a_branch2b/bn' 6 512 40 40 (4915200)
I0916 20:26:04.652448 13475 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0916 20:26:04.652453 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.652458 13475 net.cpp:184] Created Layer res5a_branch2b/relu (36)
I0916 20:26:04.652462 13475 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0916 20:26:04.652467 13475 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0916 20:26:04.652473 13475 net.cpp:245] Setting up res5a_branch2b/relu
I0916 20:26:04.652477 13475 net.cpp:252] TRAIN Top shape for layer 36 'res5a_branch2b/relu' 6 512 40 40 (4915200)
I0916 20:26:04.652482 13475 layer_factory.hpp:136] Creating layer 'out5a' of type 'Convolution'
I0916 20:26:04.652485 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.652494 13475 net.cpp:184] Created Layer out5a (37)
I0916 20:26:04.652498 13475 net.cpp:561] out5a <- res5a_branch2b
I0916 20:26:04.652501 13475 net.cpp:530] out5a -> out5a
I0916 20:26:04.656940 13475 net.cpp:245] Setting up out5a
I0916 20:26:04.656951 13475 net.cpp:252] TRAIN Top shape for layer 37 'out5a' 6 64 40 40 (614400)
I0916 20:26:04.656956 13475 layer_factory.hpp:136] Creating layer 'out5a/bn' of type 'BatchNorm'
I0916 20:26:04.656960 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.656963 13475 net.cpp:184] Created Layer out5a/bn (38)
I0916 20:26:04.656966 13475 net.cpp:561] out5a/bn <- out5a
I0916 20:26:04.656970 13475 net.cpp:513] out5a/bn -> out5a (in-place)
I0916 20:26:04.657615 13475 net.cpp:245] Setting up out5a/bn
I0916 20:26:04.657622 13475 net.cpp:252] TRAIN Top shape for layer 38 'out5a/bn' 6 64 40 40 (614400)
I0916 20:26:04.657627 13475 layer_factory.hpp:136] Creating layer 'out5a/relu' of type 'ReLU'
I0916 20:26:04.657630 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.657634 13475 net.cpp:184] Created Layer out5a/relu (39)
I0916 20:26:04.657635 13475 net.cpp:561] out5a/relu <- out5a
I0916 20:26:04.657637 13475 net.cpp:513] out5a/relu -> out5a (in-place)
I0916 20:26:04.657640 13475 net.cpp:245] Setting up out5a/relu
I0916 20:26:04.657644 13475 net.cpp:252] TRAIN Top shape for layer 39 'out5a/relu' 6 64 40 40 (614400)
I0916 20:26:04.657645 13475 layer_factory.hpp:136] Creating layer 'out5a_up2' of type 'Deconvolution'
I0916 20:26:04.657647 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.657660 13475 net.cpp:184] Created Layer out5a_up2 (40)
I0916 20:26:04.657663 13475 net.cpp:561] out5a_up2 <- out5a
I0916 20:26:04.657665 13475 net.cpp:530] out5a_up2 -> out5a_up2
I0916 20:26:04.657950 13475 net.cpp:245] Setting up out5a_up2
I0916 20:26:04.657955 13475 net.cpp:252] TRAIN Top shape for layer 40 'out5a_up2' 6 64 80 80 (2457600)
I0916 20:26:04.657958 13475 layer_factory.hpp:136] Creating layer 'out3a' of type 'Convolution'
I0916 20:26:04.657961 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.657975 13475 net.cpp:184] Created Layer out3a (41)
I0916 20:26:04.657977 13475 net.cpp:561] out3a <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0916 20:26:04.657980 13475 net.cpp:530] out3a -> out3a
I0916 20:26:04.659077 13475 net.cpp:245] Setting up out3a
I0916 20:26:04.659085 13475 net.cpp:252] TRAIN Top shape for layer 41 'out3a' 6 64 80 80 (2457600)
I0916 20:26:04.659088 13475 layer_factory.hpp:136] Creating layer 'out3a/bn' of type 'BatchNorm'
I0916 20:26:04.659091 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.659096 13475 net.cpp:184] Created Layer out3a/bn (42)
I0916 20:26:04.659097 13475 net.cpp:561] out3a/bn <- out3a
I0916 20:26:04.659099 13475 net.cpp:513] out3a/bn -> out3a (in-place)
I0916 20:26:04.660078 13475 net.cpp:245] Setting up out3a/bn
I0916 20:26:04.660085 13475 net.cpp:252] TRAIN Top shape for layer 42 'out3a/bn' 6 64 80 80 (2457600)
I0916 20:26:04.660091 13475 layer_factory.hpp:136] Creating layer 'out3a/relu' of type 'ReLU'
I0916 20:26:04.660094 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.660096 13475 net.cpp:184] Created Layer out3a/relu (43)
I0916 20:26:04.660099 13475 net.cpp:561] out3a/relu <- out3a
I0916 20:26:04.660100 13475 net.cpp:513] out3a/relu -> out3a (in-place)
I0916 20:26:04.660104 13475 net.cpp:245] Setting up out3a/relu
I0916 20:26:04.660106 13475 net.cpp:252] TRAIN Top shape for layer 43 'out3a/relu' 6 64 80 80 (2457600)
I0916 20:26:04.660109 13475 layer_factory.hpp:136] Creating layer 'out3_out5_combined' of type 'Eltwise'
I0916 20:26:04.660110 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.660606 13475 net.cpp:184] Created Layer out3_out5_combined (44)
I0916 20:26:04.660611 13475 net.cpp:561] out3_out5_combined <- out5a_up2
I0916 20:26:04.660614 13475 net.cpp:561] out3_out5_combined <- out3a
I0916 20:26:04.660615 13475 net.cpp:530] out3_out5_combined -> out3_out5_combined
I0916 20:26:04.660645 13475 net.cpp:245] Setting up out3_out5_combined
I0916 20:26:04.660650 13475 net.cpp:252] TRAIN Top shape for layer 44 'out3_out5_combined' 6 64 80 80 (2457600)
I0916 20:26:04.660652 13475 layer_factory.hpp:136] Creating layer 'ctx_conv1' of type 'Convolution'
I0916 20:26:04.660655 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.660665 13475 net.cpp:184] Created Layer ctx_conv1 (45)
I0916 20:26:04.660668 13475 net.cpp:561] ctx_conv1 <- out3_out5_combined
I0916 20:26:04.660671 13475 net.cpp:530] ctx_conv1 -> ctx_conv1
I0916 20:26:04.661744 13475 net.cpp:245] Setting up ctx_conv1
I0916 20:26:04.661751 13475 net.cpp:252] TRAIN Top shape for layer 45 'ctx_conv1' 6 64 80 80 (2457600)
I0916 20:26:04.661756 13475 layer_factory.hpp:136] Creating layer 'ctx_conv1/bn' of type 'BatchNorm'
I0916 20:26:04.661757 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.661761 13475 net.cpp:184] Created Layer ctx_conv1/bn (46)
I0916 20:26:04.661763 13475 net.cpp:561] ctx_conv1/bn <- ctx_conv1
I0916 20:26:04.661767 13475 net.cpp:513] ctx_conv1/bn -> ctx_conv1 (in-place)
I0916 20:26:04.662420 13475 net.cpp:245] Setting up ctx_conv1/bn
I0916 20:26:04.662427 13475 net.cpp:252] TRAIN Top shape for layer 46 'ctx_conv1/bn' 6 64 80 80 (2457600)
I0916 20:26:04.662432 13475 layer_factory.hpp:136] Creating layer 'ctx_conv1/relu' of type 'ReLU'
I0916 20:26:04.662436 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.662437 13475 net.cpp:184] Created Layer ctx_conv1/relu (47)
I0916 20:26:04.662439 13475 net.cpp:561] ctx_conv1/relu <- ctx_conv1
I0916 20:26:04.662442 13475 net.cpp:513] ctx_conv1/relu -> ctx_conv1 (in-place)
I0916 20:26:04.662446 13475 net.cpp:245] Setting up ctx_conv1/relu
I0916 20:26:04.662447 13475 net.cpp:252] TRAIN Top shape for layer 47 'ctx_conv1/relu' 6 64 80 80 (2457600)
I0916 20:26:04.662456 13475 layer_factory.hpp:136] Creating layer 'ctx_conv2' of type 'Convolution'
I0916 20:26:04.662458 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.662463 13475 net.cpp:184] Created Layer ctx_conv2 (48)
I0916 20:26:04.662467 13475 net.cpp:561] ctx_conv2 <- ctx_conv1
I0916 20:26:04.662468 13475 net.cpp:530] ctx_conv2 -> ctx_conv2
I0916 20:26:04.663533 13475 net.cpp:245] Setting up ctx_conv2
I0916 20:26:04.663540 13475 net.cpp:252] TRAIN Top shape for layer 48 'ctx_conv2' 6 64 80 80 (2457600)
I0916 20:26:04.663543 13475 layer_factory.hpp:136] Creating layer 'ctx_conv2/bn' of type 'BatchNorm'
I0916 20:26:04.663547 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.663549 13475 net.cpp:184] Created Layer ctx_conv2/bn (49)
I0916 20:26:04.663552 13475 net.cpp:561] ctx_conv2/bn <- ctx_conv2
I0916 20:26:04.663554 13475 net.cpp:513] ctx_conv2/bn -> ctx_conv2 (in-place)
I0916 20:26:04.664183 13475 net.cpp:245] Setting up ctx_conv2/bn
I0916 20:26:04.664191 13475 net.cpp:252] TRAIN Top shape for layer 49 'ctx_conv2/bn' 6 64 80 80 (2457600)
I0916 20:26:04.664196 13475 layer_factory.hpp:136] Creating layer 'ctx_conv2/relu' of type 'ReLU'
I0916 20:26:04.664198 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.664201 13475 net.cpp:184] Created Layer ctx_conv2/relu (50)
I0916 20:26:04.664203 13475 net.cpp:561] ctx_conv2/relu <- ctx_conv2
I0916 20:26:04.664206 13475 net.cpp:513] ctx_conv2/relu -> ctx_conv2 (in-place)
I0916 20:26:04.664208 13475 net.cpp:245] Setting up ctx_conv2/relu
I0916 20:26:04.664211 13475 net.cpp:252] TRAIN Top shape for layer 50 'ctx_conv2/relu' 6 64 80 80 (2457600)
I0916 20:26:04.664213 13475 layer_factory.hpp:136] Creating layer 'ctx_conv3' of type 'Convolution'
I0916 20:26:04.664214 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.664224 13475 net.cpp:184] Created Layer ctx_conv3 (51)
I0916 20:26:04.664227 13475 net.cpp:561] ctx_conv3 <- ctx_conv2
I0916 20:26:04.664229 13475 net.cpp:530] ctx_conv3 -> ctx_conv3
I0916 20:26:04.665297 13475 net.cpp:245] Setting up ctx_conv3
I0916 20:26:04.665304 13475 net.cpp:252] TRAIN Top shape for layer 51 'ctx_conv3' 6 64 80 80 (2457600)
I0916 20:26:04.665307 13475 layer_factory.hpp:136] Creating layer 'ctx_conv3/bn' of type 'BatchNorm'
I0916 20:26:04.665310 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.665314 13475 net.cpp:184] Created Layer ctx_conv3/bn (52)
I0916 20:26:04.665316 13475 net.cpp:561] ctx_conv3/bn <- ctx_conv3
I0916 20:26:04.665318 13475 net.cpp:513] ctx_conv3/bn -> ctx_conv3 (in-place)
I0916 20:26:04.665943 13475 net.cpp:245] Setting up ctx_conv3/bn
I0916 20:26:04.665949 13475 net.cpp:252] TRAIN Top shape for layer 52 'ctx_conv3/bn' 6 64 80 80 (2457600)
I0916 20:26:04.665954 13475 layer_factory.hpp:136] Creating layer 'ctx_conv3/relu' of type 'ReLU'
I0916 20:26:04.665957 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.665961 13475 net.cpp:184] Created Layer ctx_conv3/relu (53)
I0916 20:26:04.665962 13475 net.cpp:561] ctx_conv3/relu <- ctx_conv3
I0916 20:26:04.665964 13475 net.cpp:513] ctx_conv3/relu -> ctx_conv3 (in-place)
I0916 20:26:04.665971 13475 net.cpp:245] Setting up ctx_conv3/relu
I0916 20:26:04.665974 13475 net.cpp:252] TRAIN Top shape for layer 53 'ctx_conv3/relu' 6 64 80 80 (2457600)
I0916 20:26:04.665977 13475 layer_factory.hpp:136] Creating layer 'ctx_conv4' of type 'Convolution'
I0916 20:26:04.665978 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.665987 13475 net.cpp:184] Created Layer ctx_conv4 (54)
I0916 20:26:04.665990 13475 net.cpp:561] ctx_conv4 <- ctx_conv3
I0916 20:26:04.665992 13475 net.cpp:530] ctx_conv4 -> ctx_conv4
I0916 20:26:04.667327 13475 net.cpp:245] Setting up ctx_conv4
I0916 20:26:04.667354 13475 net.cpp:252] TRAIN Top shape for layer 54 'ctx_conv4' 6 64 80 80 (2457600)
I0916 20:26:04.667363 13475 layer_factory.hpp:136] Creating layer 'ctx_conv4/bn' of type 'BatchNorm'
I0916 20:26:04.667369 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.667378 13475 net.cpp:184] Created Layer ctx_conv4/bn (55)
I0916 20:26:04.667384 13475 net.cpp:561] ctx_conv4/bn <- ctx_conv4
I0916 20:26:04.667392 13475 net.cpp:513] ctx_conv4/bn -> ctx_conv4 (in-place)
I0916 20:26:04.668269 13475 net.cpp:245] Setting up ctx_conv4/bn
I0916 20:26:04.668278 13475 net.cpp:252] TRAIN Top shape for layer 55 'ctx_conv4/bn' 6 64 80 80 (2457600)
I0916 20:26:04.668287 13475 layer_factory.hpp:136] Creating layer 'ctx_conv4/relu' of type 'ReLU'
I0916 20:26:04.668290 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.668295 13475 net.cpp:184] Created Layer ctx_conv4/relu (56)
I0916 20:26:04.668298 13475 net.cpp:561] ctx_conv4/relu <- ctx_conv4
I0916 20:26:04.668301 13475 net.cpp:513] ctx_conv4/relu -> ctx_conv4 (in-place)
I0916 20:26:04.668306 13475 net.cpp:245] Setting up ctx_conv4/relu
I0916 20:26:04.668311 13475 net.cpp:252] TRAIN Top shape for layer 56 'ctx_conv4/relu' 6 64 80 80 (2457600)
I0916 20:26:04.668314 13475 layer_factory.hpp:136] Creating layer 'ctx_final' of type 'Convolution'
I0916 20:26:04.668319 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.668334 13475 net.cpp:184] Created Layer ctx_final (57)
I0916 20:26:04.668337 13475 net.cpp:561] ctx_final <- ctx_conv4
I0916 20:26:04.668340 13475 net.cpp:530] ctx_final -> ctx_final
I0916 20:26:04.668964 13475 net.cpp:245] Setting up ctx_final
I0916 20:26:04.668973 13475 net.cpp:252] TRAIN Top shape for layer 57 'ctx_final' 6 8 80 80 (307200)
I0916 20:26:04.668979 13475 layer_factory.hpp:136] Creating layer 'ctx_final/relu' of type 'ReLU'
I0916 20:26:04.668982 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.668987 13475 net.cpp:184] Created Layer ctx_final/relu (58)
I0916 20:26:04.668990 13475 net.cpp:561] ctx_final/relu <- ctx_final
I0916 20:26:04.668993 13475 net.cpp:513] ctx_final/relu -> ctx_final (in-place)
I0916 20:26:04.669000 13475 net.cpp:245] Setting up ctx_final/relu
I0916 20:26:04.669004 13475 net.cpp:252] TRAIN Top shape for layer 58 'ctx_final/relu' 6 8 80 80 (307200)
I0916 20:26:04.669008 13475 layer_factory.hpp:136] Creating layer 'out_deconv_final_up2' of type 'Deconvolution'
I0916 20:26:04.669013 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.669020 13475 net.cpp:184] Created Layer out_deconv_final_up2 (59)
I0916 20:26:04.669024 13475 net.cpp:561] out_deconv_final_up2 <- ctx_final
I0916 20:26:04.669029 13475 net.cpp:530] out_deconv_final_up2 -> out_deconv_final_up2
I0916 20:26:04.669391 13475 net.cpp:245] Setting up out_deconv_final_up2
I0916 20:26:04.669399 13475 net.cpp:252] TRAIN Top shape for layer 59 'out_deconv_final_up2' 6 8 160 160 (1228800)
I0916 20:26:04.669404 13475 layer_factory.hpp:136] Creating layer 'out_deconv_final_up4' of type 'Deconvolution'
I0916 20:26:04.669409 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.669414 13475 net.cpp:184] Created Layer out_deconv_final_up4 (60)
I0916 20:26:04.669420 13475 net.cpp:561] out_deconv_final_up4 <- out_deconv_final_up2
I0916 20:26:04.669425 13475 net.cpp:530] out_deconv_final_up4 -> out_deconv_final_up4
I0916 20:26:04.669870 13475 net.cpp:245] Setting up out_deconv_final_up4
I0916 20:26:04.669878 13475 net.cpp:252] TRAIN Top shape for layer 60 'out_deconv_final_up4' 6 8 320 320 (4915200)
I0916 20:26:04.669884 13475 layer_factory.hpp:136] Creating layer 'out_deconv_final_up8' of type 'Deconvolution'
I0916 20:26:04.669888 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.669895 13475 net.cpp:184] Created Layer out_deconv_final_up8 (61)
I0916 20:26:04.669906 13475 net.cpp:561] out_deconv_final_up8 <- out_deconv_final_up4
I0916 20:26:04.669911 13475 net.cpp:530] out_deconv_final_up8 -> out_deconv_final_up8
I0916 20:26:04.670281 13475 net.cpp:245] Setting up out_deconv_final_up8
I0916 20:26:04.670289 13475 net.cpp:252] TRAIN Top shape for layer 61 'out_deconv_final_up8' 6 8 640 640 (19660800)
I0916 20:26:04.670295 13475 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0916 20:26:04.670300 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.670311 13475 net.cpp:184] Created Layer loss (62)
I0916 20:26:04.670316 13475 net.cpp:561] loss <- out_deconv_final_up8
I0916 20:26:04.670320 13475 net.cpp:561] loss <- label
I0916 20:26:04.670326 13475 net.cpp:530] loss -> loss
I0916 20:26:04.671946 13475 net.cpp:245] Setting up loss
I0916 20:26:04.671957 13475 net.cpp:252] TRAIN Top shape for layer 62 'loss' (1)
I0916 20:26:04.671960 13475 net.cpp:256]     with loss weight 1
I0916 20:26:04.671977 13475 net.cpp:323] loss needs backward computation.
I0916 20:26:04.671982 13475 net.cpp:323] out_deconv_final_up8 needs backward computation.
I0916 20:26:04.671985 13475 net.cpp:323] out_deconv_final_up4 needs backward computation.
I0916 20:26:04.671988 13475 net.cpp:323] out_deconv_final_up2 needs backward computation.
I0916 20:26:04.671998 13475 net.cpp:323] ctx_final/relu needs backward computation.
I0916 20:26:04.672003 13475 net.cpp:323] ctx_final needs backward computation.
I0916 20:26:04.672006 13475 net.cpp:323] ctx_conv4/relu needs backward computation.
I0916 20:26:04.672009 13475 net.cpp:323] ctx_conv4/bn needs backward computation.
I0916 20:26:04.672014 13475 net.cpp:323] ctx_conv4 needs backward computation.
I0916 20:26:04.672019 13475 net.cpp:323] ctx_conv3/relu needs backward computation.
I0916 20:26:04.672022 13475 net.cpp:323] ctx_conv3/bn needs backward computation.
I0916 20:26:04.672026 13475 net.cpp:323] ctx_conv3 needs backward computation.
I0916 20:26:04.672030 13475 net.cpp:323] ctx_conv2/relu needs backward computation.
I0916 20:26:04.672034 13475 net.cpp:323] ctx_conv2/bn needs backward computation.
I0916 20:26:04.672037 13475 net.cpp:323] ctx_conv2 needs backward computation.
I0916 20:26:04.672041 13475 net.cpp:323] ctx_conv1/relu needs backward computation.
I0916 20:26:04.672045 13475 net.cpp:323] ctx_conv1/bn needs backward computation.
I0916 20:26:04.672049 13475 net.cpp:323] ctx_conv1 needs backward computation.
I0916 20:26:04.672052 13475 net.cpp:323] out3_out5_combined needs backward computation.
I0916 20:26:04.672057 13475 net.cpp:323] out3a/relu needs backward computation.
I0916 20:26:04.672060 13475 net.cpp:323] out3a/bn needs backward computation.
I0916 20:26:04.672063 13475 net.cpp:323] out3a needs backward computation.
I0916 20:26:04.672067 13475 net.cpp:323] out5a_up2 needs backward computation.
I0916 20:26:04.672071 13475 net.cpp:323] out5a/relu needs backward computation.
I0916 20:26:04.672075 13475 net.cpp:323] out5a/bn needs backward computation.
I0916 20:26:04.672078 13475 net.cpp:323] out5a needs backward computation.
I0916 20:26:04.672081 13475 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0916 20:26:04.672086 13475 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0916 20:26:04.672088 13475 net.cpp:323] res5a_branch2b needs backward computation.
I0916 20:26:04.672091 13475 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0916 20:26:04.672096 13475 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0916 20:26:04.672098 13475 net.cpp:323] res5a_branch2a needs backward computation.
I0916 20:26:04.672102 13475 net.cpp:323] pool4 needs backward computation.
I0916 20:26:04.672107 13475 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0916 20:26:04.672111 13475 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0916 20:26:04.672114 13475 net.cpp:323] res4a_branch2b needs backward computation.
I0916 20:26:04.672117 13475 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0916 20:26:04.672127 13475 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0916 20:26:04.672132 13475 net.cpp:323] res4a_branch2a needs backward computation.
I0916 20:26:04.672135 13475 net.cpp:323] pool3 needs backward computation.
I0916 20:26:04.672139 13475 net.cpp:323] res3a_branch2b_res3a_branch2b/relu_0_split needs backward computation.
I0916 20:26:04.672143 13475 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0916 20:26:04.672147 13475 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0916 20:26:04.672150 13475 net.cpp:323] res3a_branch2b needs backward computation.
I0916 20:26:04.672154 13475 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0916 20:26:04.672158 13475 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0916 20:26:04.672161 13475 net.cpp:323] res3a_branch2a needs backward computation.
I0916 20:26:04.672165 13475 net.cpp:323] pool2 needs backward computation.
I0916 20:26:04.672169 13475 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0916 20:26:04.672173 13475 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0916 20:26:04.672176 13475 net.cpp:323] res2a_branch2b needs backward computation.
I0916 20:26:04.672180 13475 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0916 20:26:04.672184 13475 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0916 20:26:04.672188 13475 net.cpp:323] res2a_branch2a needs backward computation.
I0916 20:26:04.672190 13475 net.cpp:323] pool1 needs backward computation.
I0916 20:26:04.672194 13475 net.cpp:323] conv1b/relu needs backward computation.
I0916 20:26:04.672197 13475 net.cpp:323] conv1b/bn needs backward computation.
I0916 20:26:04.672200 13475 net.cpp:323] conv1b needs backward computation.
I0916 20:26:04.672204 13475 net.cpp:323] conv1a/relu needs backward computation.
I0916 20:26:04.672207 13475 net.cpp:323] conv1a/bn needs backward computation.
I0916 20:26:04.672211 13475 net.cpp:323] conv1a needs backward computation.
I0916 20:26:04.672216 13475 net.cpp:325] data/bias does not need backward computation.
I0916 20:26:04.672220 13475 net.cpp:325] data does not need backward computation.
I0916 20:26:04.672224 13475 net.cpp:367] This network produces output loss
I0916 20:26:04.672278 13475 net.cpp:389] Top memory (TRAIN) required for data: 1435238408 diff: 1435238408
I0916 20:26:04.672283 13475 net.cpp:392] Bottom memory (TRAIN) required for data: 1435238400 diff: 1435238400
I0916 20:26:04.672287 13475 net.cpp:395] Shared (in-place) memory (TRAIN) by data: 772915200 diff: 772915200
I0916 20:26:04.672291 13475 net.cpp:398] Parameters memory (TRAIN) required for data: 10817840 diff: 10817840
I0916 20:26:04.672294 13475 net.cpp:401] Parameters shared memory (TRAIN) by data: 0 diff: 0
I0916 20:26:04.672297 13475 net.cpp:407] Network initialization done.
I0916 20:26:04.673413 13475 solver.cpp:177] Creating test net (#0) specified by test_net file: training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/sparse/test.prototxt
W0916 20:26:04.673502 13475 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 4 to 6
I0916 20:26:04.673785 13475 net.cpp:72] Initializing net from parameters: 
name: "jsegnet21v2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageLabelData"
  top: "data"
  top: "label"
  transform_param {
    mirror: false
    crop_size: 640
    mean_value: 0
  }
  image_label_data_param {
    image_list_path: "data/val-image-lmdb"
    label_list_path: "data/val-label-lmdb"
    batch_size: 2
    threads: 1
    backend: LMDB
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "out5a"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "out5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "out5a/bn"
  type: "BatchNorm"
  bottom: "out5a"
  top: "out5a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out5a/relu"
  type: "ReLU"
  bottom: "out5a"
  top: "out5a"
}
layer {
  name: "out5a_up2"
  type: "Deconvolution"
  bottom: "out5a"
  top: "out5a_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 64
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out3a"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "out3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "out3a/bn"
  type: "BatchNorm"
  bottom: "out3a"
  top: "out3a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out3a/relu"
  type: "ReLU"
  bottom: "out3a"
  top: "out3a"
}
layer {
  name: "out3_out5_combined"
  type: "Eltwise"
  bottom: "out5a_up2"
  bottom: "out3a"
  top: "out3_out5_combined"
}
layer {
  name: "ctx_conv1"
  type: "Convolution"
  bottom: "out3_out5_combined"
  top: "ctx_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_conv1/bn"
  type: "BatchNorm"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv1/relu"
  type: "ReLU"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
}
layer {
  name: "ctx_conv2"
  type: "Convolution"
  bottom: "ctx_conv1"
  top: "ctx_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv2/bn"
  type: "BatchNorm"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv2/relu"
  type: "ReLU"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
}
layer {
  name: "ctx_conv3"
  type: "Convolution"
  bottom: "ctx_conv2"
  top: "ctx_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv3/bn"
  type: "BatchNorm"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv3/relu"
  type: "ReLU"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
}
layer {
  name: "ctx_conv4"
  type: "Convolution"
  bottom: "ctx_conv3"
  top: "ctx_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv4/bn"
  type: "BatchNorm"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv4/relu"
  type: "ReLU"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
}
layer {
  name: "ctx_final"
  type: "Convolution"
  bottom: "ctx_conv4"
  top: "ctx_final"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_final/relu"
  type: "ReLU"
  bottom: "ctx_final"
  top: "ctx_final"
}
layer {
  name: "out_deconv_final_up2"
  type: "Deconvolution"
  bottom: "ctx_final"
  top: "out_deconv_final_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up4"
  type: "Deconvolution"
  bottom: "out_deconv_final_up2"
  top: "out_deconv_final_up4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up8"
  type: "Deconvolution"
  bottom: "out_deconv_final_up4"
  top: "out_deconv_final_up8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: 255
    normalization: VALID
  }
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "accuracy/top1"
  include {
    phase: TEST
  }
  accuracy_param {
    ignore_label: 255
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "accuracy/top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
    ignore_label: 255
  }
}
I0916 20:26:04.673966 13475 net.cpp:104] Using FLOAT as default forward math type
I0916 20:26:04.673972 13475 net.cpp:110] Using FLOAT as default backward math type
I0916 20:26:04.673975 13475 layer_factory.hpp:136] Creating layer 'data' of type 'ImageLabelData'
I0916 20:26:04.673979 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.673985 13475 net.cpp:184] Created Layer data (0)
I0916 20:26:04.673988 13475 net.cpp:530] data -> data
I0916 20:26:04.673992 13475 net.cpp:530] data -> label
I0916 20:26:04.674023 13475 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 2
I0916 20:26:04.674031 13475 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 20:26:04.674778 13566 db_lmdb.cpp:24] Opened lmdb data/val-image-lmdb
I0916 20:26:04.676133 13475 data_layer.cpp:187] (0) ReshapePrefetch 2, 3, 640, 640
I0916 20:26:04.676244 13475 data_layer.cpp:211] (0) Output data size: 2, 3, 640, 640
I0916 20:26:04.676250 13475 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 20:26:04.676292 13475 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 2
I0916 20:26:04.676300 13475 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 20:26:04.677043 13567 data_layer.cpp:101] (0) Parser threads: 1
I0916 20:26:04.677057 13567 data_layer.cpp:103] (0) Transformer threads: 1
I0916 20:26:04.679478 13568 db_lmdb.cpp:24] Opened lmdb data/val-label-lmdb
I0916 20:26:04.680451 13475 data_layer.cpp:187] (0) ReshapePrefetch 2, 1, 640, 640
I0916 20:26:04.680532 13475 data_layer.cpp:211] (0) Output data size: 2, 1, 640, 640
I0916 20:26:04.680541 13475 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 20:26:04.680613 13475 net.cpp:245] Setting up data
I0916 20:26:04.680625 13475 net.cpp:252] TEST Top shape for layer 0 'data' 2 3 640 640 (2457600)
I0916 20:26:04.680631 13475 net.cpp:252] TEST Top shape for layer 0 'data' 2 1 640 640 (819200)
I0916 20:26:04.680640 13475 layer_factory.hpp:136] Creating layer 'label_data_1_split' of type 'Split'
I0916 20:26:04.680647 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.680658 13475 net.cpp:184] Created Layer label_data_1_split (1)
I0916 20:26:04.680662 13475 net.cpp:561] label_data_1_split <- label
I0916 20:26:04.680670 13475 net.cpp:530] label_data_1_split -> label_data_1_split_0
I0916 20:26:04.680677 13475 net.cpp:530] label_data_1_split -> label_data_1_split_1
I0916 20:26:04.680681 13475 net.cpp:530] label_data_1_split -> label_data_1_split_2
I0916 20:26:04.680764 13475 net.cpp:245] Setting up label_data_1_split
I0916 20:26:04.680770 13475 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 2 1 640 640 (819200)
I0916 20:26:04.680776 13475 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 2 1 640 640 (819200)
I0916 20:26:04.680780 13475 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 2 1 640 640 (819200)
I0916 20:26:04.680785 13475 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0916 20:26:04.680789 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.680799 13475 net.cpp:184] Created Layer data/bias (2)
I0916 20:26:04.680801 13475 net.cpp:561] data/bias <- data
I0916 20:26:04.680805 13475 net.cpp:530] data/bias -> data/bias
I0916 20:26:04.681757 13569 data_layer.cpp:101] (0) Parser threads: 1
I0916 20:26:04.681771 13569 data_layer.cpp:103] (0) Transformer threads: 1
I0916 20:26:04.683601 13475 net.cpp:245] Setting up data/bias
I0916 20:26:04.683625 13475 net.cpp:252] TEST Top shape for layer 2 'data/bias' 2 3 640 640 (2457600)
I0916 20:26:04.683642 13475 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0916 20:26:04.683650 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.683673 13475 net.cpp:184] Created Layer conv1a (3)
I0916 20:26:04.683679 13475 net.cpp:561] conv1a <- data/bias
I0916 20:26:04.683686 13475 net.cpp:530] conv1a -> conv1a
I0916 20:26:04.684249 13475 net.cpp:245] Setting up conv1a
I0916 20:26:04.684259 13475 net.cpp:252] TEST Top shape for layer 3 'conv1a' 2 32 320 320 (6553600)
I0916 20:26:04.684268 13475 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0916 20:26:04.684281 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.684291 13475 net.cpp:184] Created Layer conv1a/bn (4)
I0916 20:26:04.684296 13475 net.cpp:561] conv1a/bn <- conv1a
I0916 20:26:04.684305 13475 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0916 20:26:04.685003 13475 net.cpp:245] Setting up conv1a/bn
I0916 20:26:04.685012 13475 net.cpp:252] TEST Top shape for layer 4 'conv1a/bn' 2 32 320 320 (6553600)
I0916 20:26:04.685022 13475 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0916 20:26:04.685027 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.685039 13475 net.cpp:184] Created Layer conv1a/relu (5)
I0916 20:26:04.685044 13475 net.cpp:561] conv1a/relu <- conv1a
I0916 20:26:04.685047 13475 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0916 20:26:04.685058 13475 net.cpp:245] Setting up conv1a/relu
I0916 20:26:04.685063 13475 net.cpp:252] TEST Top shape for layer 5 'conv1a/relu' 2 32 320 320 (6553600)
I0916 20:26:04.685071 13475 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0916 20:26:04.685076 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.685096 13475 net.cpp:184] Created Layer conv1b (6)
I0916 20:26:04.685101 13475 net.cpp:561] conv1b <- conv1a
I0916 20:26:04.685113 13475 net.cpp:530] conv1b -> conv1b
I0916 20:26:04.686100 13475 net.cpp:245] Setting up conv1b
I0916 20:26:04.686110 13475 net.cpp:252] TEST Top shape for layer 6 'conv1b' 2 32 320 320 (6553600)
I0916 20:26:04.686120 13475 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0916 20:26:04.686131 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.686152 13475 net.cpp:184] Created Layer conv1b/bn (7)
I0916 20:26:04.686156 13475 net.cpp:561] conv1b/bn <- conv1b
I0916 20:26:04.686166 13475 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0916 20:26:04.689126 13475 net.cpp:245] Setting up conv1b/bn
I0916 20:26:04.689136 13475 net.cpp:252] TEST Top shape for layer 7 'conv1b/bn' 2 32 320 320 (6553600)
I0916 20:26:04.689144 13475 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0916 20:26:04.689148 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.689153 13475 net.cpp:184] Created Layer conv1b/relu (8)
I0916 20:26:04.689157 13475 net.cpp:561] conv1b/relu <- conv1b
I0916 20:26:04.689162 13475 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0916 20:26:04.689167 13475 net.cpp:245] Setting up conv1b/relu
I0916 20:26:04.689172 13475 net.cpp:252] TEST Top shape for layer 8 'conv1b/relu' 2 32 320 320 (6553600)
I0916 20:26:04.689175 13475 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0916 20:26:04.689179 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.689185 13475 net.cpp:184] Created Layer pool1 (9)
I0916 20:26:04.689188 13475 net.cpp:561] pool1 <- conv1b
I0916 20:26:04.689193 13475 net.cpp:530] pool1 -> pool1
I0916 20:26:04.689257 13475 net.cpp:245] Setting up pool1
I0916 20:26:04.689263 13475 net.cpp:252] TEST Top shape for layer 9 'pool1' 2 32 160 160 (1638400)
I0916 20:26:04.689267 13475 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0916 20:26:04.689271 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.689280 13475 net.cpp:184] Created Layer res2a_branch2a (10)
I0916 20:26:04.689285 13475 net.cpp:561] res2a_branch2a <- pool1
I0916 20:26:04.689288 13475 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0916 20:26:04.690331 13475 net.cpp:245] Setting up res2a_branch2a
I0916 20:26:04.690347 13475 net.cpp:252] TEST Top shape for layer 10 'res2a_branch2a' 2 64 160 160 (3276800)
I0916 20:26:04.690368 13475 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0916 20:26:04.690376 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.690393 13475 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0916 20:26:04.690399 13475 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0916 20:26:04.690404 13475 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0916 20:26:04.691308 13475 net.cpp:245] Setting up res2a_branch2a/bn
I0916 20:26:04.691316 13475 net.cpp:252] TEST Top shape for layer 11 'res2a_branch2a/bn' 2 64 160 160 (3276800)
I0916 20:26:04.691324 13475 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0916 20:26:04.691329 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.691334 13475 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0916 20:26:04.691336 13475 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0916 20:26:04.691340 13475 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0916 20:26:04.691345 13475 net.cpp:245] Setting up res2a_branch2a/relu
I0916 20:26:04.691354 13475 net.cpp:252] TEST Top shape for layer 12 'res2a_branch2a/relu' 2 64 160 160 (3276800)
I0916 20:26:04.691357 13475 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0916 20:26:04.691360 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.691368 13475 net.cpp:184] Created Layer res2a_branch2b (13)
I0916 20:26:04.691382 13475 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0916 20:26:04.691386 13475 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0916 20:26:04.692164 13475 net.cpp:245] Setting up res2a_branch2b
I0916 20:26:04.692174 13475 net.cpp:252] TEST Top shape for layer 13 'res2a_branch2b' 2 64 160 160 (3276800)
I0916 20:26:04.692181 13475 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0916 20:26:04.692185 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.692191 13475 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0916 20:26:04.692194 13475 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0916 20:26:04.692198 13475 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0916 20:26:04.693068 13475 net.cpp:245] Setting up res2a_branch2b/bn
I0916 20:26:04.693078 13475 net.cpp:252] TEST Top shape for layer 14 'res2a_branch2b/bn' 2 64 160 160 (3276800)
I0916 20:26:04.693085 13475 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0916 20:26:04.693089 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.693099 13475 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0916 20:26:04.693101 13475 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0916 20:26:04.693105 13475 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0916 20:26:04.693111 13475 net.cpp:245] Setting up res2a_branch2b/relu
I0916 20:26:04.693116 13475 net.cpp:252] TEST Top shape for layer 15 'res2a_branch2b/relu' 2 64 160 160 (3276800)
I0916 20:26:04.693120 13475 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0916 20:26:04.693125 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.693130 13475 net.cpp:184] Created Layer pool2 (16)
I0916 20:26:04.693135 13475 net.cpp:561] pool2 <- res2a_branch2b
I0916 20:26:04.693138 13475 net.cpp:530] pool2 -> pool2
I0916 20:26:04.693223 13475 net.cpp:245] Setting up pool2
I0916 20:26:04.693229 13475 net.cpp:252] TEST Top shape for layer 16 'pool2' 2 64 80 80 (819200)
I0916 20:26:04.693233 13475 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0916 20:26:04.693236 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.693243 13475 net.cpp:184] Created Layer res3a_branch2a (17)
I0916 20:26:04.693246 13475 net.cpp:561] res3a_branch2a <- pool2
I0916 20:26:04.693249 13475 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0916 20:26:04.695817 13475 net.cpp:245] Setting up res3a_branch2a
I0916 20:26:04.695827 13475 net.cpp:252] TEST Top shape for layer 17 'res3a_branch2a' 2 128 80 80 (1638400)
I0916 20:26:04.695833 13475 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0916 20:26:04.695837 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.695843 13475 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0916 20:26:04.695847 13475 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0916 20:26:04.695850 13475 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0916 20:26:04.696707 13475 net.cpp:245] Setting up res3a_branch2a/bn
I0916 20:26:04.696717 13475 net.cpp:252] TEST Top shape for layer 18 'res3a_branch2a/bn' 2 128 80 80 (1638400)
I0916 20:26:04.696727 13475 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0916 20:26:04.696732 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.696735 13475 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0916 20:26:04.696738 13475 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0916 20:26:04.696743 13475 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0916 20:26:04.696748 13475 net.cpp:245] Setting up res3a_branch2a/relu
I0916 20:26:04.696753 13475 net.cpp:252] TEST Top shape for layer 19 'res3a_branch2a/relu' 2 128 80 80 (1638400)
I0916 20:26:04.696764 13475 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0916 20:26:04.696768 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.696786 13475 net.cpp:184] Created Layer res3a_branch2b (20)
I0916 20:26:04.696790 13475 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0916 20:26:04.696794 13475 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0916 20:26:04.698109 13475 net.cpp:245] Setting up res3a_branch2b
I0916 20:26:04.698117 13475 net.cpp:252] TEST Top shape for layer 20 'res3a_branch2b' 2 128 80 80 (1638400)
I0916 20:26:04.698122 13475 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0916 20:26:04.698124 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.698128 13475 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0916 20:26:04.698130 13475 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0916 20:26:04.698133 13475 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0916 20:26:04.698768 13475 net.cpp:245] Setting up res3a_branch2b/bn
I0916 20:26:04.698776 13475 net.cpp:252] TEST Top shape for layer 21 'res3a_branch2b/bn' 2 128 80 80 (1638400)
I0916 20:26:04.698781 13475 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0916 20:26:04.698783 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.698786 13475 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0916 20:26:04.698788 13475 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0916 20:26:04.698791 13475 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0916 20:26:04.698793 13475 net.cpp:245] Setting up res3a_branch2b/relu
I0916 20:26:04.698796 13475 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b/relu' 2 128 80 80 (1638400)
I0916 20:26:04.698797 13475 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0916 20:26:04.698801 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.698803 13475 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (23)
I0916 20:26:04.698806 13475 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0916 20:26:04.698808 13475 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0916 20:26:04.698812 13475 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0916 20:26:04.698859 13475 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0916 20:26:04.698863 13475 net.cpp:252] TEST Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 2 128 80 80 (1638400)
I0916 20:26:04.698868 13475 net.cpp:252] TEST Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 2 128 80 80 (1638400)
I0916 20:26:04.698869 13475 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0916 20:26:04.698873 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.698876 13475 net.cpp:184] Created Layer pool3 (24)
I0916 20:26:04.698879 13475 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0916 20:26:04.698882 13475 net.cpp:530] pool3 -> pool3
I0916 20:26:04.698941 13475 net.cpp:245] Setting up pool3
I0916 20:26:04.698945 13475 net.cpp:252] TEST Top shape for layer 24 'pool3' 2 128 40 40 (409600)
I0916 20:26:04.698948 13475 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0916 20:26:04.698951 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.698957 13475 net.cpp:184] Created Layer res4a_branch2a (25)
I0916 20:26:04.698961 13475 net.cpp:561] res4a_branch2a <- pool3
I0916 20:26:04.698963 13475 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0916 20:26:04.705145 13475 net.cpp:245] Setting up res4a_branch2a
I0916 20:26:04.705160 13475 net.cpp:252] TEST Top shape for layer 25 'res4a_branch2a' 2 256 40 40 (819200)
I0916 20:26:04.705165 13475 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0916 20:26:04.705168 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.705173 13475 net.cpp:184] Created Layer res4a_branch2a/bn (26)
I0916 20:26:04.705175 13475 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0916 20:26:04.705178 13475 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0916 20:26:04.705818 13475 net.cpp:245] Setting up res4a_branch2a/bn
I0916 20:26:04.705826 13475 net.cpp:252] TEST Top shape for layer 26 'res4a_branch2a/bn' 2 256 40 40 (819200)
I0916 20:26:04.705832 13475 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0916 20:26:04.705834 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.705838 13475 net.cpp:184] Created Layer res4a_branch2a/relu (27)
I0916 20:26:04.705840 13475 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0916 20:26:04.705843 13475 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0916 20:26:04.705847 13475 net.cpp:245] Setting up res4a_branch2a/relu
I0916 20:26:04.705850 13475 net.cpp:252] TEST Top shape for layer 27 'res4a_branch2a/relu' 2 256 40 40 (819200)
I0916 20:26:04.705852 13475 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0916 20:26:04.705855 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.705864 13475 net.cpp:184] Created Layer res4a_branch2b (28)
I0916 20:26:04.705868 13475 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0916 20:26:04.705870 13475 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0916 20:26:04.710131 13475 net.cpp:245] Setting up res4a_branch2b
I0916 20:26:04.710141 13475 net.cpp:252] TEST Top shape for layer 28 'res4a_branch2b' 2 256 40 40 (819200)
I0916 20:26:04.710146 13475 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0916 20:26:04.710150 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.710153 13475 net.cpp:184] Created Layer res4a_branch2b/bn (29)
I0916 20:26:04.710156 13475 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0916 20:26:04.710160 13475 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0916 20:26:04.710789 13475 net.cpp:245] Setting up res4a_branch2b/bn
I0916 20:26:04.710796 13475 net.cpp:252] TEST Top shape for layer 29 'res4a_branch2b/bn' 2 256 40 40 (819200)
I0916 20:26:04.710801 13475 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0916 20:26:04.710804 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.710808 13475 net.cpp:184] Created Layer res4a_branch2b/relu (30)
I0916 20:26:04.710809 13475 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0916 20:26:04.710813 13475 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0916 20:26:04.710815 13475 net.cpp:245] Setting up res4a_branch2b/relu
I0916 20:26:04.710819 13475 net.cpp:252] TEST Top shape for layer 30 'res4a_branch2b/relu' 2 256 40 40 (819200)
I0916 20:26:04.710820 13475 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0916 20:26:04.710824 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.710827 13475 net.cpp:184] Created Layer pool4 (31)
I0916 20:26:04.710829 13475 net.cpp:561] pool4 <- res4a_branch2b
I0916 20:26:04.710832 13475 net.cpp:530] pool4 -> pool4
I0916 20:26:04.710897 13475 net.cpp:245] Setting up pool4
I0916 20:26:04.710902 13475 net.cpp:252] TEST Top shape for layer 31 'pool4' 2 256 40 40 (819200)
I0916 20:26:04.710904 13475 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0916 20:26:04.710907 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.710921 13475 net.cpp:184] Created Layer res5a_branch2a (32)
I0916 20:26:04.710923 13475 net.cpp:561] res5a_branch2a <- pool4
I0916 20:26:04.710927 13475 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0916 20:26:04.738029 13475 net.cpp:245] Setting up res5a_branch2a
I0916 20:26:04.738050 13475 net.cpp:252] TEST Top shape for layer 32 'res5a_branch2a' 2 512 40 40 (1638400)
I0916 20:26:04.738056 13475 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0916 20:26:04.738060 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.738068 13475 net.cpp:184] Created Layer res5a_branch2a/bn (33)
I0916 20:26:04.738075 13475 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0916 20:26:04.738078 13475 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0916 20:26:04.738735 13475 net.cpp:245] Setting up res5a_branch2a/bn
I0916 20:26:04.738742 13475 net.cpp:252] TEST Top shape for layer 33 'res5a_branch2a/bn' 2 512 40 40 (1638400)
I0916 20:26:04.738749 13475 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0916 20:26:04.738752 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.738756 13475 net.cpp:184] Created Layer res5a_branch2a/relu (34)
I0916 20:26:04.738759 13475 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0916 20:26:04.738760 13475 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0916 20:26:04.738765 13475 net.cpp:245] Setting up res5a_branch2a/relu
I0916 20:26:04.738767 13475 net.cpp:252] TEST Top shape for layer 34 'res5a_branch2a/relu' 2 512 40 40 (1638400)
I0916 20:26:04.738770 13475 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0916 20:26:04.738771 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.738777 13475 net.cpp:184] Created Layer res5a_branch2b (35)
I0916 20:26:04.738780 13475 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0916 20:26:04.738782 13475 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0916 20:26:04.751868 13475 net.cpp:245] Setting up res5a_branch2b
I0916 20:26:04.751883 13475 net.cpp:252] TEST Top shape for layer 35 'res5a_branch2b' 2 512 40 40 (1638400)
I0916 20:26:04.751891 13475 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0916 20:26:04.751894 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.751899 13475 net.cpp:184] Created Layer res5a_branch2b/bn (36)
I0916 20:26:04.751902 13475 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0916 20:26:04.751904 13475 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0916 20:26:04.752605 13475 net.cpp:245] Setting up res5a_branch2b/bn
I0916 20:26:04.752614 13475 net.cpp:252] TEST Top shape for layer 36 'res5a_branch2b/bn' 2 512 40 40 (1638400)
I0916 20:26:04.752620 13475 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0916 20:26:04.752624 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.752626 13475 net.cpp:184] Created Layer res5a_branch2b/relu (37)
I0916 20:26:04.752629 13475 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0916 20:26:04.752631 13475 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0916 20:26:04.752635 13475 net.cpp:245] Setting up res5a_branch2b/relu
I0916 20:26:04.752637 13475 net.cpp:252] TEST Top shape for layer 37 'res5a_branch2b/relu' 2 512 40 40 (1638400)
I0916 20:26:04.752640 13475 layer_factory.hpp:136] Creating layer 'out5a' of type 'Convolution'
I0916 20:26:04.752642 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.752651 13475 net.cpp:184] Created Layer out5a (38)
I0916 20:26:04.752655 13475 net.cpp:561] out5a <- res5a_branch2b
I0916 20:26:04.752657 13475 net.cpp:530] out5a -> out5a
I0916 20:26:04.755935 13475 net.cpp:245] Setting up out5a
I0916 20:26:04.755950 13475 net.cpp:252] TEST Top shape for layer 38 'out5a' 2 64 40 40 (204800)
I0916 20:26:04.755954 13475 layer_factory.hpp:136] Creating layer 'out5a/bn' of type 'BatchNorm'
I0916 20:26:04.755957 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.755962 13475 net.cpp:184] Created Layer out5a/bn (39)
I0916 20:26:04.755964 13475 net.cpp:561] out5a/bn <- out5a
I0916 20:26:04.755967 13475 net.cpp:513] out5a/bn -> out5a (in-place)
I0916 20:26:04.756628 13475 net.cpp:245] Setting up out5a/bn
I0916 20:26:04.756634 13475 net.cpp:252] TEST Top shape for layer 39 'out5a/bn' 2 64 40 40 (204800)
I0916 20:26:04.756639 13475 layer_factory.hpp:136] Creating layer 'out5a/relu' of type 'ReLU'
I0916 20:26:04.756641 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.756644 13475 net.cpp:184] Created Layer out5a/relu (40)
I0916 20:26:04.756646 13475 net.cpp:561] out5a/relu <- out5a
I0916 20:26:04.756649 13475 net.cpp:513] out5a/relu -> out5a (in-place)
I0916 20:26:04.756651 13475 net.cpp:245] Setting up out5a/relu
I0916 20:26:04.756654 13475 net.cpp:252] TEST Top shape for layer 40 'out5a/relu' 2 64 40 40 (204800)
I0916 20:26:04.756656 13475 layer_factory.hpp:136] Creating layer 'out5a_up2' of type 'Deconvolution'
I0916 20:26:04.756659 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.756664 13475 net.cpp:184] Created Layer out5a_up2 (41)
I0916 20:26:04.756665 13475 net.cpp:561] out5a_up2 <- out5a
I0916 20:26:04.756667 13475 net.cpp:530] out5a_up2 -> out5a_up2
I0916 20:26:04.756959 13475 net.cpp:245] Setting up out5a_up2
I0916 20:26:04.756965 13475 net.cpp:252] TEST Top shape for layer 41 'out5a_up2' 2 64 80 80 (819200)
I0916 20:26:04.756968 13475 layer_factory.hpp:136] Creating layer 'out3a' of type 'Convolution'
I0916 20:26:04.756970 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.756978 13475 net.cpp:184] Created Layer out3a (42)
I0916 20:26:04.756981 13475 net.cpp:561] out3a <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0916 20:26:04.756983 13475 net.cpp:530] out3a -> out3a
I0916 20:26:04.758087 13475 net.cpp:245] Setting up out3a
I0916 20:26:04.758095 13475 net.cpp:252] TEST Top shape for layer 42 'out3a' 2 64 80 80 (819200)
I0916 20:26:04.758098 13475 layer_factory.hpp:136] Creating layer 'out3a/bn' of type 'BatchNorm'
I0916 20:26:04.758101 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.758105 13475 net.cpp:184] Created Layer out3a/bn (43)
I0916 20:26:04.758107 13475 net.cpp:561] out3a/bn <- out3a
I0916 20:26:04.758111 13475 net.cpp:513] out3a/bn -> out3a (in-place)
I0916 20:26:04.758782 13475 net.cpp:245] Setting up out3a/bn
I0916 20:26:04.758790 13475 net.cpp:252] TEST Top shape for layer 43 'out3a/bn' 2 64 80 80 (819200)
I0916 20:26:04.758795 13475 layer_factory.hpp:136] Creating layer 'out3a/relu' of type 'ReLU'
I0916 20:26:04.758796 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.758800 13475 net.cpp:184] Created Layer out3a/relu (44)
I0916 20:26:04.758801 13475 net.cpp:561] out3a/relu <- out3a
I0916 20:26:04.758803 13475 net.cpp:513] out3a/relu -> out3a (in-place)
I0916 20:26:04.758807 13475 net.cpp:245] Setting up out3a/relu
I0916 20:26:04.758810 13475 net.cpp:252] TEST Top shape for layer 44 'out3a/relu' 2 64 80 80 (819200)
I0916 20:26:04.758811 13475 layer_factory.hpp:136] Creating layer 'out3_out5_combined' of type 'Eltwise'
I0916 20:26:04.758813 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.758817 13475 net.cpp:184] Created Layer out3_out5_combined (45)
I0916 20:26:04.758819 13475 net.cpp:561] out3_out5_combined <- out5a_up2
I0916 20:26:04.758821 13475 net.cpp:561] out3_out5_combined <- out3a
I0916 20:26:04.758823 13475 net.cpp:530] out3_out5_combined -> out3_out5_combined
I0916 20:26:04.758855 13475 net.cpp:245] Setting up out3_out5_combined
I0916 20:26:04.758860 13475 net.cpp:252] TEST Top shape for layer 45 'out3_out5_combined' 2 64 80 80 (819200)
I0916 20:26:04.758862 13475 layer_factory.hpp:136] Creating layer 'ctx_conv1' of type 'Convolution'
I0916 20:26:04.758864 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.758870 13475 net.cpp:184] Created Layer ctx_conv1 (46)
I0916 20:26:04.758872 13475 net.cpp:561] ctx_conv1 <- out3_out5_combined
I0916 20:26:04.758875 13475 net.cpp:530] ctx_conv1 -> ctx_conv1
I0916 20:26:04.759973 13475 net.cpp:245] Setting up ctx_conv1
I0916 20:26:04.759979 13475 net.cpp:252] TEST Top shape for layer 46 'ctx_conv1' 2 64 80 80 (819200)
I0916 20:26:04.759984 13475 layer_factory.hpp:136] Creating layer 'ctx_conv1/bn' of type 'BatchNorm'
I0916 20:26:04.759985 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.759999 13475 net.cpp:184] Created Layer ctx_conv1/bn (47)
I0916 20:26:04.760001 13475 net.cpp:561] ctx_conv1/bn <- ctx_conv1
I0916 20:26:04.760004 13475 net.cpp:513] ctx_conv1/bn -> ctx_conv1 (in-place)
I0916 20:26:04.760658 13475 net.cpp:245] Setting up ctx_conv1/bn
I0916 20:26:04.760665 13475 net.cpp:252] TEST Top shape for layer 47 'ctx_conv1/bn' 2 64 80 80 (819200)
I0916 20:26:04.760670 13475 layer_factory.hpp:136] Creating layer 'ctx_conv1/relu' of type 'ReLU'
I0916 20:26:04.760673 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.760675 13475 net.cpp:184] Created Layer ctx_conv1/relu (48)
I0916 20:26:04.760677 13475 net.cpp:561] ctx_conv1/relu <- ctx_conv1
I0916 20:26:04.760680 13475 net.cpp:513] ctx_conv1/relu -> ctx_conv1 (in-place)
I0916 20:26:04.760684 13475 net.cpp:245] Setting up ctx_conv1/relu
I0916 20:26:04.760685 13475 net.cpp:252] TEST Top shape for layer 48 'ctx_conv1/relu' 2 64 80 80 (819200)
I0916 20:26:04.760687 13475 layer_factory.hpp:136] Creating layer 'ctx_conv2' of type 'Convolution'
I0916 20:26:04.760689 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.760694 13475 net.cpp:184] Created Layer ctx_conv2 (49)
I0916 20:26:04.760696 13475 net.cpp:561] ctx_conv2 <- ctx_conv1
I0916 20:26:04.760699 13475 net.cpp:530] ctx_conv2 -> ctx_conv2
I0916 20:26:04.761792 13475 net.cpp:245] Setting up ctx_conv2
I0916 20:26:04.761798 13475 net.cpp:252] TEST Top shape for layer 49 'ctx_conv2' 2 64 80 80 (819200)
I0916 20:26:04.761802 13475 layer_factory.hpp:136] Creating layer 'ctx_conv2/bn' of type 'BatchNorm'
I0916 20:26:04.761804 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.761808 13475 net.cpp:184] Created Layer ctx_conv2/bn (50)
I0916 20:26:04.761811 13475 net.cpp:561] ctx_conv2/bn <- ctx_conv2
I0916 20:26:04.761812 13475 net.cpp:513] ctx_conv2/bn -> ctx_conv2 (in-place)
I0916 20:26:04.762473 13475 net.cpp:245] Setting up ctx_conv2/bn
I0916 20:26:04.762481 13475 net.cpp:252] TEST Top shape for layer 50 'ctx_conv2/bn' 2 64 80 80 (819200)
I0916 20:26:04.762486 13475 layer_factory.hpp:136] Creating layer 'ctx_conv2/relu' of type 'ReLU'
I0916 20:26:04.762488 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.762491 13475 net.cpp:184] Created Layer ctx_conv2/relu (51)
I0916 20:26:04.762493 13475 net.cpp:561] ctx_conv2/relu <- ctx_conv2
I0916 20:26:04.762495 13475 net.cpp:513] ctx_conv2/relu -> ctx_conv2 (in-place)
I0916 20:26:04.762498 13475 net.cpp:245] Setting up ctx_conv2/relu
I0916 20:26:04.762501 13475 net.cpp:252] TEST Top shape for layer 51 'ctx_conv2/relu' 2 64 80 80 (819200)
I0916 20:26:04.762503 13475 layer_factory.hpp:136] Creating layer 'ctx_conv3' of type 'Convolution'
I0916 20:26:04.762506 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.762511 13475 net.cpp:184] Created Layer ctx_conv3 (52)
I0916 20:26:04.762512 13475 net.cpp:561] ctx_conv3 <- ctx_conv2
I0916 20:26:04.762521 13475 net.cpp:530] ctx_conv3 -> ctx_conv3
I0916 20:26:04.763665 13475 net.cpp:245] Setting up ctx_conv3
I0916 20:26:04.763672 13475 net.cpp:252] TEST Top shape for layer 52 'ctx_conv3' 2 64 80 80 (819200)
I0916 20:26:04.763676 13475 layer_factory.hpp:136] Creating layer 'ctx_conv3/bn' of type 'BatchNorm'
I0916 20:26:04.763679 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.763687 13475 net.cpp:184] Created Layer ctx_conv3/bn (53)
I0916 20:26:04.763689 13475 net.cpp:561] ctx_conv3/bn <- ctx_conv3
I0916 20:26:04.763691 13475 net.cpp:513] ctx_conv3/bn -> ctx_conv3 (in-place)
I0916 20:26:04.764358 13475 net.cpp:245] Setting up ctx_conv3/bn
I0916 20:26:04.764365 13475 net.cpp:252] TEST Top shape for layer 53 'ctx_conv3/bn' 2 64 80 80 (819200)
I0916 20:26:04.764370 13475 layer_factory.hpp:136] Creating layer 'ctx_conv3/relu' of type 'ReLU'
I0916 20:26:04.764374 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.764376 13475 net.cpp:184] Created Layer ctx_conv3/relu (54)
I0916 20:26:04.764379 13475 net.cpp:561] ctx_conv3/relu <- ctx_conv3
I0916 20:26:04.764380 13475 net.cpp:513] ctx_conv3/relu -> ctx_conv3 (in-place)
I0916 20:26:04.764384 13475 net.cpp:245] Setting up ctx_conv3/relu
I0916 20:26:04.764385 13475 net.cpp:252] TEST Top shape for layer 54 'ctx_conv3/relu' 2 64 80 80 (819200)
I0916 20:26:04.764387 13475 layer_factory.hpp:136] Creating layer 'ctx_conv4' of type 'Convolution'
I0916 20:26:04.764389 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.764394 13475 net.cpp:184] Created Layer ctx_conv4 (55)
I0916 20:26:04.764396 13475 net.cpp:561] ctx_conv4 <- ctx_conv3
I0916 20:26:04.764398 13475 net.cpp:530] ctx_conv4 -> ctx_conv4
I0916 20:26:04.765486 13475 net.cpp:245] Setting up ctx_conv4
I0916 20:26:04.765493 13475 net.cpp:252] TEST Top shape for layer 55 'ctx_conv4' 2 64 80 80 (819200)
I0916 20:26:04.765496 13475 layer_factory.hpp:136] Creating layer 'ctx_conv4/bn' of type 'BatchNorm'
I0916 20:26:04.765499 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.765502 13475 net.cpp:184] Created Layer ctx_conv4/bn (56)
I0916 20:26:04.765506 13475 net.cpp:561] ctx_conv4/bn <- ctx_conv4
I0916 20:26:04.765507 13475 net.cpp:513] ctx_conv4/bn -> ctx_conv4 (in-place)
I0916 20:26:04.766186 13475 net.cpp:245] Setting up ctx_conv4/bn
I0916 20:26:04.766194 13475 net.cpp:252] TEST Top shape for layer 56 'ctx_conv4/bn' 2 64 80 80 (819200)
I0916 20:26:04.766199 13475 layer_factory.hpp:136] Creating layer 'ctx_conv4/relu' of type 'ReLU'
I0916 20:26:04.766201 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.766204 13475 net.cpp:184] Created Layer ctx_conv4/relu (57)
I0916 20:26:04.766206 13475 net.cpp:561] ctx_conv4/relu <- ctx_conv4
I0916 20:26:04.766208 13475 net.cpp:513] ctx_conv4/relu -> ctx_conv4 (in-place)
I0916 20:26:04.766212 13475 net.cpp:245] Setting up ctx_conv4/relu
I0916 20:26:04.766214 13475 net.cpp:252] TEST Top shape for layer 57 'ctx_conv4/relu' 2 64 80 80 (819200)
I0916 20:26:04.766216 13475 layer_factory.hpp:136] Creating layer 'ctx_final' of type 'Convolution'
I0916 20:26:04.766218 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.766223 13475 net.cpp:184] Created Layer ctx_final (58)
I0916 20:26:04.766225 13475 net.cpp:561] ctx_final <- ctx_conv4
I0916 20:26:04.766227 13475 net.cpp:530] ctx_final -> ctx_final
I0916 20:26:04.766691 13475 net.cpp:245] Setting up ctx_final
I0916 20:26:04.766698 13475 net.cpp:252] TEST Top shape for layer 58 'ctx_final' 2 8 80 80 (102400)
I0916 20:26:04.766702 13475 layer_factory.hpp:136] Creating layer 'ctx_final/relu' of type 'ReLU'
I0916 20:26:04.766705 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.766707 13475 net.cpp:184] Created Layer ctx_final/relu (59)
I0916 20:26:04.766715 13475 net.cpp:561] ctx_final/relu <- ctx_final
I0916 20:26:04.766717 13475 net.cpp:513] ctx_final/relu -> ctx_final (in-place)
I0916 20:26:04.766721 13475 net.cpp:245] Setting up ctx_final/relu
I0916 20:26:04.766723 13475 net.cpp:252] TEST Top shape for layer 59 'ctx_final/relu' 2 8 80 80 (102400)
I0916 20:26:04.766726 13475 layer_factory.hpp:136] Creating layer 'out_deconv_final_up2' of type 'Deconvolution'
I0916 20:26:04.766727 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.766736 13475 net.cpp:184] Created Layer out_deconv_final_up2 (60)
I0916 20:26:04.766739 13475 net.cpp:561] out_deconv_final_up2 <- ctx_final
I0916 20:26:04.766741 13475 net.cpp:530] out_deconv_final_up2 -> out_deconv_final_up2
I0916 20:26:04.767012 13475 net.cpp:245] Setting up out_deconv_final_up2
I0916 20:26:04.767017 13475 net.cpp:252] TEST Top shape for layer 60 'out_deconv_final_up2' 2 8 160 160 (409600)
I0916 20:26:04.767020 13475 layer_factory.hpp:136] Creating layer 'out_deconv_final_up4' of type 'Deconvolution'
I0916 20:26:04.767022 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.767026 13475 net.cpp:184] Created Layer out_deconv_final_up4 (61)
I0916 20:26:04.767029 13475 net.cpp:561] out_deconv_final_up4 <- out_deconv_final_up2
I0916 20:26:04.767031 13475 net.cpp:530] out_deconv_final_up4 -> out_deconv_final_up4
I0916 20:26:04.767308 13475 net.cpp:245] Setting up out_deconv_final_up4
I0916 20:26:04.767313 13475 net.cpp:252] TEST Top shape for layer 61 'out_deconv_final_up4' 2 8 320 320 (1638400)
I0916 20:26:04.767316 13475 layer_factory.hpp:136] Creating layer 'out_deconv_final_up8' of type 'Deconvolution'
I0916 20:26:04.767318 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.767323 13475 net.cpp:184] Created Layer out_deconv_final_up8 (62)
I0916 20:26:04.767324 13475 net.cpp:561] out_deconv_final_up8 <- out_deconv_final_up4
I0916 20:26:04.767326 13475 net.cpp:530] out_deconv_final_up8 -> out_deconv_final_up8
I0916 20:26:04.767598 13475 net.cpp:245] Setting up out_deconv_final_up8
I0916 20:26:04.767603 13475 net.cpp:252] TEST Top shape for layer 62 'out_deconv_final_up8' 2 8 640 640 (6553600)
I0916 20:26:04.767606 13475 layer_factory.hpp:136] Creating layer 'out_deconv_final_up8_out_deconv_final_up8_0_split' of type 'Split'
I0916 20:26:04.767608 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.767611 13475 net.cpp:184] Created Layer out_deconv_final_up8_out_deconv_final_up8_0_split (63)
I0916 20:26:04.767613 13475 net.cpp:561] out_deconv_final_up8_out_deconv_final_up8_0_split <- out_deconv_final_up8
I0916 20:26:04.767616 13475 net.cpp:530] out_deconv_final_up8_out_deconv_final_up8_0_split -> out_deconv_final_up8_out_deconv_final_up8_0_split_0
I0916 20:26:04.767618 13475 net.cpp:530] out_deconv_final_up8_out_deconv_final_up8_0_split -> out_deconv_final_up8_out_deconv_final_up8_0_split_1
I0916 20:26:04.767621 13475 net.cpp:530] out_deconv_final_up8_out_deconv_final_up8_0_split -> out_deconv_final_up8_out_deconv_final_up8_0_split_2
I0916 20:26:04.767683 13475 net.cpp:245] Setting up out_deconv_final_up8_out_deconv_final_up8_0_split
I0916 20:26:04.767686 13475 net.cpp:252] TEST Top shape for layer 63 'out_deconv_final_up8_out_deconv_final_up8_0_split' 2 8 640 640 (6553600)
I0916 20:26:04.767688 13475 net.cpp:252] TEST Top shape for layer 63 'out_deconv_final_up8_out_deconv_final_up8_0_split' 2 8 640 640 (6553600)
I0916 20:26:04.767690 13475 net.cpp:252] TEST Top shape for layer 63 'out_deconv_final_up8_out_deconv_final_up8_0_split' 2 8 640 640 (6553600)
I0916 20:26:04.767693 13475 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0916 20:26:04.767695 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.767704 13475 net.cpp:184] Created Layer loss (64)
I0916 20:26:04.767712 13475 net.cpp:561] loss <- out_deconv_final_up8_out_deconv_final_up8_0_split_0
I0916 20:26:04.767714 13475 net.cpp:561] loss <- label_data_1_split_0
I0916 20:26:04.767717 13475 net.cpp:530] loss -> loss
I0916 20:26:04.768613 13475 net.cpp:245] Setting up loss
I0916 20:26:04.768621 13475 net.cpp:252] TEST Top shape for layer 64 'loss' (1)
I0916 20:26:04.768625 13475 net.cpp:256]     with loss weight 1
I0916 20:26:04.768630 13475 layer_factory.hpp:136] Creating layer 'accuracy/top1' of type 'Accuracy'
I0916 20:26:04.768632 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.768642 13475 net.cpp:184] Created Layer accuracy/top1 (65)
I0916 20:26:04.768645 13475 net.cpp:561] accuracy/top1 <- out_deconv_final_up8_out_deconv_final_up8_0_split_1
I0916 20:26:04.768647 13475 net.cpp:561] accuracy/top1 <- label_data_1_split_1
I0916 20:26:04.768651 13475 net.cpp:530] accuracy/top1 -> accuracy/top1
I0916 20:26:04.768656 13475 net.cpp:245] Setting up accuracy/top1
I0916 20:26:04.768658 13475 net.cpp:252] TEST Top shape for layer 65 'accuracy/top1' (1)
I0916 20:26:04.768661 13475 layer_factory.hpp:136] Creating layer 'accuracy/top5' of type 'Accuracy'
I0916 20:26:04.768662 13475 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 20:26:04.768666 13475 net.cpp:184] Created Layer accuracy/top5 (66)
I0916 20:26:04.768667 13475 net.cpp:561] accuracy/top5 <- out_deconv_final_up8_out_deconv_final_up8_0_split_2
I0916 20:26:04.768671 13475 net.cpp:561] accuracy/top5 <- label_data_1_split_2
I0916 20:26:04.768673 13475 net.cpp:530] accuracy/top5 -> accuracy/top5
I0916 20:26:04.768682 13475 net.cpp:245] Setting up accuracy/top5
I0916 20:26:04.768685 13475 net.cpp:252] TEST Top shape for layer 66 'accuracy/top5' (1)
I0916 20:26:04.768687 13475 net.cpp:325] accuracy/top5 does not need backward computation.
I0916 20:26:04.768689 13475 net.cpp:325] accuracy/top1 does not need backward computation.
I0916 20:26:04.768692 13475 net.cpp:323] loss needs backward computation.
I0916 20:26:04.768693 13475 net.cpp:323] out_deconv_final_up8_out_deconv_final_up8_0_split needs backward computation.
I0916 20:26:04.768695 13475 net.cpp:323] out_deconv_final_up8 needs backward computation.
I0916 20:26:04.768697 13475 net.cpp:323] out_deconv_final_up4 needs backward computation.
I0916 20:26:04.768699 13475 net.cpp:323] out_deconv_final_up2 needs backward computation.
I0916 20:26:04.768702 13475 net.cpp:323] ctx_final/relu needs backward computation.
I0916 20:26:04.768703 13475 net.cpp:323] ctx_final needs backward computation.
I0916 20:26:04.768704 13475 net.cpp:323] ctx_conv4/relu needs backward computation.
I0916 20:26:04.768707 13475 net.cpp:323] ctx_conv4/bn needs backward computation.
I0916 20:26:04.768708 13475 net.cpp:323] ctx_conv4 needs backward computation.
I0916 20:26:04.768710 13475 net.cpp:323] ctx_conv3/relu needs backward computation.
I0916 20:26:04.768712 13475 net.cpp:323] ctx_conv3/bn needs backward computation.
I0916 20:26:04.768713 13475 net.cpp:323] ctx_conv3 needs backward computation.
I0916 20:26:04.768715 13475 net.cpp:323] ctx_conv2/relu needs backward computation.
I0916 20:26:04.768717 13475 net.cpp:323] ctx_conv2/bn needs backward computation.
I0916 20:26:04.768718 13475 net.cpp:323] ctx_conv2 needs backward computation.
I0916 20:26:04.768720 13475 net.cpp:323] ctx_conv1/relu needs backward computation.
I0916 20:26:04.768723 13475 net.cpp:323] ctx_conv1/bn needs backward computation.
I0916 20:26:04.768725 13475 net.cpp:323] ctx_conv1 needs backward computation.
I0916 20:26:04.768728 13475 net.cpp:323] out3_out5_combined needs backward computation.
I0916 20:26:04.768730 13475 net.cpp:323] out3a/relu needs backward computation.
I0916 20:26:04.768733 13475 net.cpp:323] out3a/bn needs backward computation.
I0916 20:26:04.768735 13475 net.cpp:323] out3a needs backward computation.
I0916 20:26:04.768738 13475 net.cpp:323] out5a_up2 needs backward computation.
I0916 20:26:04.768739 13475 net.cpp:323] out5a/relu needs backward computation.
I0916 20:26:04.768748 13475 net.cpp:323] out5a/bn needs backward computation.
I0916 20:26:04.768749 13475 net.cpp:323] out5a needs backward computation.
I0916 20:26:04.768752 13475 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0916 20:26:04.768754 13475 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0916 20:26:04.768756 13475 net.cpp:323] res5a_branch2b needs backward computation.
I0916 20:26:04.768759 13475 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0916 20:26:04.768760 13475 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0916 20:26:04.768764 13475 net.cpp:323] res5a_branch2a needs backward computation.
I0916 20:26:04.768765 13475 net.cpp:323] pool4 needs backward computation.
I0916 20:26:04.768767 13475 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0916 20:26:04.768770 13475 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0916 20:26:04.768772 13475 net.cpp:323] res4a_branch2b needs backward computation.
I0916 20:26:04.768775 13475 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0916 20:26:04.768777 13475 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0916 20:26:04.768780 13475 net.cpp:323] res4a_branch2a needs backward computation.
I0916 20:26:04.768784 13475 net.cpp:323] pool3 needs backward computation.
I0916 20:26:04.768785 13475 net.cpp:323] res3a_branch2b_res3a_branch2b/relu_0_split needs backward computation.
I0916 20:26:04.768788 13475 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0916 20:26:04.768790 13475 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0916 20:26:04.768792 13475 net.cpp:323] res3a_branch2b needs backward computation.
I0916 20:26:04.768795 13475 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0916 20:26:04.768797 13475 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0916 20:26:04.768800 13475 net.cpp:323] res3a_branch2a needs backward computation.
I0916 20:26:04.768801 13475 net.cpp:323] pool2 needs backward computation.
I0916 20:26:04.768805 13475 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0916 20:26:04.768807 13475 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0916 20:26:04.768810 13475 net.cpp:323] res2a_branch2b needs backward computation.
I0916 20:26:04.768811 13475 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0916 20:26:04.768813 13475 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0916 20:26:04.768815 13475 net.cpp:323] res2a_branch2a needs backward computation.
I0916 20:26:04.768818 13475 net.cpp:323] pool1 needs backward computation.
I0916 20:26:04.768821 13475 net.cpp:323] conv1b/relu needs backward computation.
I0916 20:26:04.768823 13475 net.cpp:323] conv1b/bn needs backward computation.
I0916 20:26:04.768826 13475 net.cpp:323] conv1b needs backward computation.
I0916 20:26:04.768828 13475 net.cpp:323] conv1a/relu needs backward computation.
I0916 20:26:04.768831 13475 net.cpp:323] conv1a/bn needs backward computation.
I0916 20:26:04.768832 13475 net.cpp:323] conv1a needs backward computation.
I0916 20:26:04.768838 13475 net.cpp:325] data/bias does not need backward computation.
I0916 20:26:04.768841 13475 net.cpp:325] label_data_1_split does not need backward computation.
I0916 20:26:04.768844 13475 net.cpp:325] data does not need backward computation.
I0916 20:26:04.768846 13475 net.cpp:367] This network produces output accuracy/top1
I0916 20:26:04.768848 13475 net.cpp:367] This network produces output accuracy/top5
I0916 20:26:04.768851 13475 net.cpp:367] This network produces output loss
I0916 20:26:04.768887 13475 net.cpp:389] Top memory (TEST) required for data: 566886424 diff: 566886424
I0916 20:26:04.768892 13475 net.cpp:392] Bottom memory (TEST) required for data: 566886400 diff: 566886400
I0916 20:26:04.768893 13475 net.cpp:395] Shared (in-place) memory (TEST) by data: 257638400 diff: 257638400
I0916 20:26:04.768896 13475 net.cpp:398] Parameters memory (TEST) required for data: 10817840 diff: 10817840
I0916 20:26:04.768898 13475 net.cpp:401] Parameters shared memory (TEST) by data: 0 diff: 0
I0916 20:26:04.768904 13475 net.cpp:407] Network initialization done.
I0916 20:26:04.768973 13475 solver.cpp:57] Solver scaffolding done.
I0916 20:26:04.777775 13475 caffe.cpp:143] Finetuning from training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/cityscapes5_jsegnet21v2_iter_60000.caffemodel
I0916 20:26:04.782775 13475 net.cpp:1094] Copying source layer data Type:ImageLabelData #blobs=0
I0916 20:26:04.782794 13475 net.cpp:1094] Copying source layer data/bias Type:Bias #blobs=1
I0916 20:26:04.782824 13475 net.cpp:1094] Copying source layer conv1a Type:Convolution #blobs=2
I0916 20:26:04.782836 13475 net.cpp:1094] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0916 20:26:04.783092 13475 net.cpp:1094] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0916 20:26:04.783095 13475 net.cpp:1094] Copying source layer conv1b Type:Convolution #blobs=2
I0916 20:26:04.783104 13475 net.cpp:1094] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0916 20:26:04.783252 13475 net.cpp:1094] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0916 20:26:04.783255 13475 net.cpp:1094] Copying source layer pool1 Type:Pooling #blobs=0
I0916 20:26:04.783257 13475 net.cpp:1094] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0916 20:26:04.783272 13475 net.cpp:1094] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0916 20:26:04.783426 13475 net.cpp:1094] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0916 20:26:04.783430 13475 net.cpp:1094] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0916 20:26:04.783442 13475 net.cpp:1094] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0916 20:26:04.783582 13475 net.cpp:1094] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0916 20:26:04.783586 13475 net.cpp:1094] Copying source layer pool2 Type:Pooling #blobs=0
I0916 20:26:04.783588 13475 net.cpp:1094] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0916 20:26:04.783625 13475 net.cpp:1094] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0916 20:26:04.783761 13475 net.cpp:1094] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0916 20:26:04.783764 13475 net.cpp:1094] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0916 20:26:04.783785 13475 net.cpp:1094] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0916 20:26:04.783907 13475 net.cpp:1094] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0916 20:26:04.783911 13475 net.cpp:1094] Copying source layer res3a_branch2b_res3a_branch2b/relu_0_split Type:Split #blobs=0
I0916 20:26:04.783913 13475 net.cpp:1094] Copying source layer pool3 Type:Pooling #blobs=0
I0916 20:26:04.783915 13475 net.cpp:1094] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0916 20:26:04.784027 13475 net.cpp:1094] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0916 20:26:04.784148 13475 net.cpp:1094] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0916 20:26:04.784153 13475 net.cpp:1094] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0916 20:26:04.784210 13475 net.cpp:1094] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0916 20:26:04.784332 13475 net.cpp:1094] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0916 20:26:04.784335 13475 net.cpp:1094] Copying source layer pool4 Type:Pooling #blobs=0
I0916 20:26:04.784337 13475 net.cpp:1094] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0916 20:26:04.784700 13475 net.cpp:1094] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0916 20:26:04.784823 13475 net.cpp:1094] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0916 20:26:04.784827 13475 net.cpp:1094] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0916 20:26:04.784993 13475 net.cpp:1094] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0916 20:26:04.785109 13475 net.cpp:1094] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0916 20:26:04.785122 13475 net.cpp:1094] Copying source layer out5a Type:Convolution #blobs=2
I0916 20:26:04.785171 13475 net.cpp:1094] Copying source layer out5a/bn Type:BatchNorm #blobs=5
I0916 20:26:04.785323 13475 net.cpp:1094] Copying source layer out5a/relu Type:ReLU #blobs=0
I0916 20:26:04.785327 13475 net.cpp:1094] Copying source layer out5a_up2 Type:Deconvolution #blobs=1
I0916 20:26:04.785333 13475 net.cpp:1094] Copying source layer out3a Type:Convolution #blobs=2
I0916 20:26:04.785349 13475 net.cpp:1094] Copying source layer out3a/bn Type:BatchNorm #blobs=5
I0916 20:26:04.785495 13475 net.cpp:1094] Copying source layer out3a/relu Type:ReLU #blobs=0
I0916 20:26:04.785498 13475 net.cpp:1094] Copying source layer out3_out5_combined Type:Eltwise #blobs=0
I0916 20:26:04.785501 13475 net.cpp:1094] Copying source layer ctx_conv1 Type:Convolution #blobs=2
I0916 20:26:04.785516 13475 net.cpp:1094] Copying source layer ctx_conv1/bn Type:BatchNorm #blobs=5
I0916 20:26:04.785660 13475 net.cpp:1094] Copying source layer ctx_conv1/relu Type:ReLU #blobs=0
I0916 20:26:04.785665 13475 net.cpp:1094] Copying source layer ctx_conv2 Type:Convolution #blobs=2
I0916 20:26:04.785681 13475 net.cpp:1094] Copying source layer ctx_conv2/bn Type:BatchNorm #blobs=5
I0916 20:26:04.785823 13475 net.cpp:1094] Copying source layer ctx_conv2/relu Type:ReLU #blobs=0
I0916 20:26:04.785827 13475 net.cpp:1094] Copying source layer ctx_conv3 Type:Convolution #blobs=2
I0916 20:26:04.785845 13475 net.cpp:1094] Copying source layer ctx_conv3/bn Type:BatchNorm #blobs=5
I0916 20:26:04.785989 13475 net.cpp:1094] Copying source layer ctx_conv3/relu Type:ReLU #blobs=0
I0916 20:26:04.785992 13475 net.cpp:1094] Copying source layer ctx_conv4 Type:Convolution #blobs=2
I0916 20:26:04.786007 13475 net.cpp:1094] Copying source layer ctx_conv4/bn Type:BatchNorm #blobs=5
I0916 20:26:04.786160 13475 net.cpp:1094] Copying source layer ctx_conv4/relu Type:ReLU #blobs=0
I0916 20:26:04.786165 13475 net.cpp:1094] Copying source layer ctx_final Type:Convolution #blobs=2
I0916 20:26:04.786175 13475 net.cpp:1094] Copying source layer ctx_final/relu Type:ReLU #blobs=0
I0916 20:26:04.786177 13475 net.cpp:1094] Copying source layer out_deconv_final_up2 Type:Deconvolution #blobs=1
I0916 20:26:04.786182 13475 net.cpp:1094] Copying source layer out_deconv_final_up4 Type:Deconvolution #blobs=1
I0916 20:26:04.786187 13475 net.cpp:1094] Copying source layer out_deconv_final_up8 Type:Deconvolution #blobs=1
I0916 20:26:04.786192 13475 net.cpp:1094] Copying source layer loss Type:SoftmaxWithLoss #blobs=0
I0916 20:26:04.789723 13475 net.cpp:1094] Copying source layer data Type:ImageLabelData #blobs=0
I0916 20:26:04.789739 13475 net.cpp:1094] Copying source layer data/bias Type:Bias #blobs=1
I0916 20:26:04.789764 13475 net.cpp:1094] Copying source layer conv1a Type:Convolution #blobs=2
I0916 20:26:04.789775 13475 net.cpp:1094] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0916 20:26:04.790025 13475 net.cpp:1094] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0916 20:26:04.790030 13475 net.cpp:1094] Copying source layer conv1b Type:Convolution #blobs=2
I0916 20:26:04.790040 13475 net.cpp:1094] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0916 20:26:04.790199 13475 net.cpp:1094] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0916 20:26:04.790205 13475 net.cpp:1094] Copying source layer pool1 Type:Pooling #blobs=0
I0916 20:26:04.790206 13475 net.cpp:1094] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0916 20:26:04.790223 13475 net.cpp:1094] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0916 20:26:04.790371 13475 net.cpp:1094] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0916 20:26:04.790375 13475 net.cpp:1094] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0916 20:26:04.790387 13475 net.cpp:1094] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0916 20:26:04.790529 13475 net.cpp:1094] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0916 20:26:04.790534 13475 net.cpp:1094] Copying source layer pool2 Type:Pooling #blobs=0
I0916 20:26:04.790547 13475 net.cpp:1094] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0916 20:26:04.790587 13475 net.cpp:1094] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0916 20:26:04.790724 13475 net.cpp:1094] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0916 20:26:04.790727 13475 net.cpp:1094] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0916 20:26:04.790750 13475 net.cpp:1094] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0916 20:26:04.790869 13475 net.cpp:1094] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0916 20:26:04.790874 13475 net.cpp:1094] Copying source layer res3a_branch2b_res3a_branch2b/relu_0_split Type:Split #blobs=0
I0916 20:26:04.790876 13475 net.cpp:1094] Copying source layer pool3 Type:Pooling #blobs=0
I0916 20:26:04.790879 13475 net.cpp:1094] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0916 20:26:04.790992 13475 net.cpp:1094] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0916 20:26:04.791112 13475 net.cpp:1094] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0916 20:26:04.791116 13475 net.cpp:1094] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0916 20:26:04.791172 13475 net.cpp:1094] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0916 20:26:04.791292 13475 net.cpp:1094] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0916 20:26:04.791296 13475 net.cpp:1094] Copying source layer pool4 Type:Pooling #blobs=0
I0916 20:26:04.791299 13475 net.cpp:1094] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0916 20:26:04.791671 13475 net.cpp:1094] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0916 20:26:04.791829 13475 net.cpp:1094] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0916 20:26:04.791837 13475 net.cpp:1094] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0916 20:26:04.792047 13475 net.cpp:1094] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0916 20:26:04.792176 13475 net.cpp:1094] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0916 20:26:04.792181 13475 net.cpp:1094] Copying source layer out5a Type:Convolution #blobs=2
I0916 20:26:04.792230 13475 net.cpp:1094] Copying source layer out5a/bn Type:BatchNorm #blobs=5
I0916 20:26:04.792387 13475 net.cpp:1094] Copying source layer out5a/relu Type:ReLU #blobs=0
I0916 20:26:04.792392 13475 net.cpp:1094] Copying source layer out5a_up2 Type:Deconvolution #blobs=1
I0916 20:26:04.792400 13475 net.cpp:1094] Copying source layer out3a Type:Convolution #blobs=2
I0916 20:26:04.792420 13475 net.cpp:1094] Copying source layer out3a/bn Type:BatchNorm #blobs=5
I0916 20:26:04.792568 13475 net.cpp:1094] Copying source layer out3a/relu Type:ReLU #blobs=0
I0916 20:26:04.792573 13475 net.cpp:1094] Copying source layer out3_out5_combined Type:Eltwise #blobs=0
I0916 20:26:04.792577 13475 net.cpp:1094] Copying source layer ctx_conv1 Type:Convolution #blobs=2
I0916 20:26:04.792601 13475 net.cpp:1094] Copying source layer ctx_conv1/bn Type:BatchNorm #blobs=5
I0916 20:26:04.792748 13475 net.cpp:1094] Copying source layer ctx_conv1/relu Type:ReLU #blobs=0
I0916 20:26:04.792752 13475 net.cpp:1094] Copying source layer ctx_conv2 Type:Convolution #blobs=2
I0916 20:26:04.792771 13475 net.cpp:1094] Copying source layer ctx_conv2/bn Type:BatchNorm #blobs=5
I0916 20:26:04.792918 13475 net.cpp:1094] Copying source layer ctx_conv2/relu Type:ReLU #blobs=0
I0916 20:26:04.792923 13475 net.cpp:1094] Copying source layer ctx_conv3 Type:Convolution #blobs=2
I0916 20:26:04.792944 13475 net.cpp:1094] Copying source layer ctx_conv3/bn Type:BatchNorm #blobs=5
I0916 20:26:04.793092 13475 net.cpp:1094] Copying source layer ctx_conv3/relu Type:ReLU #blobs=0
I0916 20:26:04.793097 13475 net.cpp:1094] Copying source layer ctx_conv4 Type:Convolution #blobs=2
I0916 20:26:04.793118 13475 net.cpp:1094] Copying source layer ctx_conv4/bn Type:BatchNorm #blobs=5
I0916 20:26:04.793273 13475 net.cpp:1094] Copying source layer ctx_conv4/relu Type:ReLU #blobs=0
I0916 20:26:04.793278 13475 net.cpp:1094] Copying source layer ctx_final Type:Convolution #blobs=2
I0916 20:26:04.793290 13475 net.cpp:1094] Copying source layer ctx_final/relu Type:ReLU #blobs=0
I0916 20:26:04.793294 13475 net.cpp:1094] Copying source layer out_deconv_final_up2 Type:Deconvolution #blobs=1
I0916 20:26:04.793301 13475 net.cpp:1094] Copying source layer out_deconv_final_up4 Type:Deconvolution #blobs=1
I0916 20:26:04.793309 13475 net.cpp:1094] Copying source layer out_deconv_final_up8 Type:Deconvolution #blobs=1
I0916 20:26:04.793318 13475 net.cpp:1094] Copying source layer loss Type:SoftmaxWithLoss #blobs=0
I0916 20:26:04.793424 13475 parallel.cpp:106] [0 - 0] P2pSync adding callback
I0916 20:26:04.793431 13475 parallel.cpp:106] [1 - 1] P2pSync adding callback
I0916 20:26:04.793434 13475 parallel.cpp:106] [2 - 2] P2pSync adding callback
I0916 20:26:04.793438 13475 parallel.cpp:59] Starting Optimization
I0916 20:26:04.793442 13475 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 20:26:04.793470 13475 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 20:26:04.793483 13475 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 20:26:04.794203 13570 device_alternate.hpp:116] NVML initialized on thread 135888480253696
I0916 20:26:04.812832 13570 common.cpp:585] NVML succeeded to set CPU affinity on device 0
I0916 20:26:04.812893 13571 device_alternate.hpp:116] NVML initialized on thread 135888471860992
I0916 20:26:04.813771 13571 common.cpp:585] NVML succeeded to set CPU affinity on device 1
I0916 20:26:04.813786 13572 device_alternate.hpp:116] NVML initialized on thread 135888463468288
I0916 20:26:04.814241 13572 common.cpp:585] NVML succeeded to set CPU affinity on device 2
I0916 20:26:04.818327 13571 solver.cpp:43] Solver data type: FLOAT
W0916 20:26:04.819209 13571 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 16 to 18
I0916 20:26:04.819382 13571 net.cpp:104] Using FLOAT as default forward math type
I0916 20:26:04.819391 13571 net.cpp:110] Using FLOAT as default backward math type
I0916 20:26:04.819438 13571 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0916 20:26:04.819450 13571 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 20:26:04.822481 13572 solver.cpp:43] Solver data type: FLOAT
W0916 20:26:04.822999 13572 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 16 to 18
I0916 20:26:04.823106 13572 net.cpp:104] Using FLOAT as default forward math type
I0916 20:26:04.823109 13572 net.cpp:110] Using FLOAT as default backward math type
I0916 20:26:04.823133 13572 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0916 20:26:04.823138 13572 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 20:26:04.823155 13573 db_lmdb.cpp:24] Opened lmdb data/train-image-lmdb
I0916 20:26:04.823920 13574 db_lmdb.cpp:24] Opened lmdb data/train-image-lmdb
I0916 20:26:04.826421 13571 data_layer.cpp:187] [1] ReshapePrefetch 6, 3, 640, 640
I0916 20:26:04.827399 13571 data_layer.cpp:211] [1] Output data size: 6, 3, 640, 640
I0916 20:26:04.827419 13571 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 20:26:04.827471 13571 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0916 20:26:04.827486 13571 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 20:26:04.827895 13572 data_layer.cpp:187] [2] ReshapePrefetch 6, 3, 640, 640
I0916 20:26:04.828055 13572 data_layer.cpp:211] [2] Output data size: 6, 3, 640, 640
I0916 20:26:04.828064 13572 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 20:26:04.828111 13572 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0916 20:26:04.828142 13572 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 20:26:04.828608 13575 data_layer.cpp:101] [1] Parser threads: 1
I0916 20:26:04.828644 13575 data_layer.cpp:103] [1] Transformer threads: 1
I0916 20:26:04.835206 13576 db_lmdb.cpp:24] Opened lmdb data/train-label-lmdb
I0916 20:26:04.836467 13577 data_layer.cpp:101] [2] Parser threads: 1
I0916 20:26:04.836494 13577 data_layer.cpp:103] [2] Transformer threads: 1
I0916 20:26:04.843201 13571 data_layer.cpp:187] [1] ReshapePrefetch 6, 1, 640, 640
I0916 20:26:04.844399 13571 data_layer.cpp:211] [1] Output data size: 6, 1, 640, 640
I0916 20:26:04.844408 13578 db_lmdb.cpp:24] Opened lmdb data/train-label-lmdb
I0916 20:26:04.844424 13571 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 20:26:04.846750 13579 data_layer.cpp:101] [1] Parser threads: 1
I0916 20:26:04.846871 13579 data_layer.cpp:103] [1] Transformer threads: 1
I0916 20:26:04.852236 13572 data_layer.cpp:187] [2] ReshapePrefetch 6, 1, 640, 640
I0916 20:26:04.854053 13572 data_layer.cpp:211] [2] Output data size: 6, 1, 640, 640
I0916 20:26:04.854279 13572 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 20:26:04.859596 13580 data_layer.cpp:101] [2] Parser threads: 1
I0916 20:26:04.860193 13580 data_layer.cpp:103] [2] Transformer threads: 1
I0916 20:26:04.860373 13575 blocking_queue.cpp:40] Waiting for datum
I0916 20:26:05.555249 13571 solver.cpp:177] Creating test net (#0) specified by test_net file: training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/sparse/test.prototxt
W0916 20:26:05.555357 13571 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 4 to 6
I0916 20:26:05.555634 13571 net.cpp:104] Using FLOAT as default forward math type
I0916 20:26:05.555644 13571 net.cpp:110] Using FLOAT as default backward math type
I0916 20:26:05.555677 13571 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 2
I0916 20:26:05.555686 13571 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 20:26:05.558573 13594 db_lmdb.cpp:24] Opened lmdb data/val-image-lmdb
I0916 20:26:05.560694 13572 solver.cpp:177] Creating test net (#0) specified by test_net file: training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/sparse/test.prototxt
W0916 20:26:05.560768 13572 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 4 to 6
I0916 20:26:05.560899 13572 net.cpp:104] Using FLOAT as default forward math type
I0916 20:26:05.560905 13572 net.cpp:110] Using FLOAT as default backward math type
I0916 20:26:05.560930 13572 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 2
I0916 20:26:05.560936 13572 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 20:26:05.564471 13596 db_lmdb.cpp:24] Opened lmdb data/val-image-lmdb
I0916 20:26:05.566169 13571 data_layer.cpp:187] (1) ReshapePrefetch 2, 3, 640, 640
I0916 20:26:05.566258 13571 data_layer.cpp:211] (1) Output data size: 2, 3, 640, 640
I0916 20:26:05.566267 13571 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 20:26:05.567446 13571 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 2
I0916 20:26:05.567482 13571 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 20:26:05.572091 13599 data_layer.cpp:101] (1) Parser threads: 1
I0916 20:26:05.572113 13599 data_layer.cpp:103] (1) Transformer threads: 1
I0916 20:26:05.573895 13600 db_lmdb.cpp:24] Opened lmdb data/val-label-lmdb
I0916 20:26:05.575371 13571 data_layer.cpp:187] (1) ReshapePrefetch 2, 1, 640, 640
I0916 20:26:05.579069 13572 data_layer.cpp:187] (2) ReshapePrefetch 2, 3, 640, 640
I0916 20:26:05.579206 13571 data_layer.cpp:211] (1) Output data size: 2, 1, 640, 640
I0916 20:26:05.579249 13572 data_layer.cpp:211] (2) Output data size: 2, 3, 640, 640
I0916 20:26:05.579277 13572 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 20:26:05.579241 13571 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 20:26:05.581725 13572 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 2
I0916 20:26:05.581755 13572 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 20:26:05.587541 13602 data_layer.cpp:101] (2) Parser threads: 1
I0916 20:26:05.587558 13602 data_layer.cpp:103] (2) Transformer threads: 1
I0916 20:26:05.590925 13603 data_layer.cpp:101] (1) Parser threads: 1
I0916 20:26:05.590971 13603 data_layer.cpp:103] (1) Transformer threads: 1
I0916 20:26:05.592893 13604 db_lmdb.cpp:24] Opened lmdb data/val-label-lmdb
I0916 20:26:05.594987 13572 data_layer.cpp:187] (2) ReshapePrefetch 2, 1, 640, 640
I0916 20:26:05.595340 13572 data_layer.cpp:211] (2) Output data size: 2, 1, 640, 640
I0916 20:26:05.595520 13572 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 20:26:05.603196 13605 data_layer.cpp:101] (2) Parser threads: 1
I0916 20:26:05.603217 13605 data_layer.cpp:103] (2) Transformer threads: 1
I0916 20:26:05.691479 13571 solver.cpp:57] Solver scaffolding done.
I0916 20:26:05.698357 13572 solver.cpp:57] Solver scaffolding done.
I0916 20:26:05.733371 13571 parallel.cpp:161] [1 - 1] P2pSync adding callback
I0916 20:26:05.733394 13570 parallel.cpp:161] [0 - 0] P2pSync adding callback
I0916 20:26:05.733413 13572 parallel.cpp:161] [2 - 2] P2pSync adding callback
I0916 20:26:05.936872 13570 net.cpp:2245] All zero weights of convolution layers are frozen
I0916 20:26:05.957839 13571 solver.cpp:490] Solving jsegnet21v2_train
I0916 20:26:05.957857 13571 solver.cpp:491] Learning Rate Policy: multistep
I0916 20:26:05.960305 13570 solver.cpp:490] Solving jsegnet21v2_train
I0916 20:26:05.960321 13570 solver.cpp:491] Learning Rate Policy: multistep
I0916 20:26:05.961205 13572 solver.cpp:490] Solving jsegnet21v2_train
I0916 20:26:05.961213 13572 solver.cpp:491] Learning Rate Policy: multistep
I0916 20:26:05.974102 13571 net.cpp:1412] [1] Reserving 10800128 bytes of shared learnable space
I0916 20:26:05.974112 13572 net.cpp:1412] [2] Reserving 10800128 bytes of shared learnable space
I0916 20:26:05.975805 13570 net.cpp:1412] [0] Reserving 10800128 bytes of shared learnable space
I0916 20:26:05.980725 13571 solver.cpp:228] Starting Optimization on GPU 1
I0916 20:26:05.980726 13572 solver.cpp:228] Starting Optimization on GPU 2
I0916 20:26:05.980726 13570 solver.cpp:228] Starting Optimization on GPU 0
I0916 20:26:05.982080 13570 solver.cpp:563] Iteration 0, Testing net (#0)
I0916 20:26:05.982156 13625 device_alternate.hpp:116] NVML initialized on thread 127888293107456
I0916 20:26:05.982170 13625 common.cpp:585] NVML succeeded to set CPU affinity on device 0
I0916 20:26:05.982180 13624 device_alternate.hpp:116] NVML initialized on thread 127888301500160
I0916 20:26:05.982197 13624 common.cpp:585] NVML succeeded to set CPU affinity on device 1
I0916 20:26:05.982208 13623 device_alternate.hpp:116] NVML initialized on thread 127888309892864
I0916 20:26:05.982216 13623 common.cpp:585] NVML succeeded to set CPU affinity on device 2
I0916 20:26:06.257452 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.873999
I0916 20:26:06.257472 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 20:26:06.257478 13570 solver.cpp:655]     Test net output #2: loss = 0.499414 (* 1 = 0.499414 loss)
I0916 20:26:06.257483 13570 solver.cpp:255] [MultiGPU] Initial Test completed
I0916 20:26:06.694293 13570 solver.cpp:319] Iteration 0 (0.436766 s), loss = 0.0710956
I0916 20:26:06.694319 13570 solver.cpp:336]     Train net output #0: loss = 0.0710956 (* 1 = 0.0710956 loss)
I0916 20:26:06.694324 13570 sgd_solver.cpp:136] Iteration 0, lr = 0.01, m = 0.9
I0916 20:26:06.899049 13570 solver.cpp:319] Iteration 1 (0.204746 s), loss = 0.0594583
I0916 20:26:06.899070 13570 solver.cpp:336]     Train net output #0: loss = 0.0594583 (* 1 = 0.0594583 loss)
I0916 20:26:07.055265 13570 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'conv1a' with space 4.24G 3/1 1 0 3 	(avail 0.06G, req 0G)	t: 0 2.84 2.5
I0916 20:26:07.071058 13571 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'conv1a' with space 4.24G 3/1 1 0 3 	(avail 0.14G, req 0G)	t: 0 3.04 2.57
I0916 20:26:07.090965 13572 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'conv1a' with space 4.24G 3/1 1 0 0 	(avail 0.14G, req 0G)	t: 0 3.32 2.61
I0916 20:26:07.192945 13570 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'conv1b' with space 4.24G 32/4 6 4 3 	(avail 0.06G, req 0G)	t: 0 0.6 1.26
I0916 20:26:07.199384 13571 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'conv1b' with space 4.24G 32/4 6 4 3 	(avail 0.14G, req 0G)	t: 0 0.65 1.32
I0916 20:26:07.215052 13572 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'conv1b' with space 4.24G 32/4 6 4 3 	(avail 0.14G, req 0G)	t: 0 0.71 1.41
I0916 20:26:07.449370 13570 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 4.24G 32/1 6 4 3 	(avail 0.06G, req 0G)	t: 0 0.73 1.46
I0916 20:26:07.458328 13571 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 4.24G 32/1 6 4 3 	(avail 0.14G, req 0G)	t: 0 0.74 1.52
I0916 20:26:07.503811 13572 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 4.24G 32/1 6 4 3 	(avail 0.14G, req 0G)	t: 0 0.77 1.57
I0916 20:26:07.531684 13570 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 4.24G 64/4 6 4 3 	(avail 0.06G, req 0G)	t: 0 0.27 0.64
I0916 20:26:07.566438 13571 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 4.24G 64/4 6 4 3 	(avail 0.14G, req 0G)	t: 0 0.28 0.65
I0916 20:26:07.594005 13572 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 4.24G 64/4 6 4 3 	(avail 0.14G, req 0G)	t: 0 0.28 0.72
I0916 20:26:07.761878 13571 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 4.24G 64/1 6 4 5 	(avail 0.14G, req 0.07G)	t: 0 0.47 0.94
I0916 20:26:07.784217 13570 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 4.24G 64/1 6 4 3 	(avail 0.06G, req 0G)	t: 0 0.45 0.91
I0916 20:26:07.802799 13572 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 4.24G 64/1 6 4 5 	(avail 0.14G, req 0.07G)	t: 0 0.5 0.98
I0916 20:26:07.823887 13571 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 4.24G 128/4 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.14 0.29
I0916 20:26:07.841420 13570 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 4.24G 128/4 6 4 3 	(avail 0.06G, req 0G)	t: 0 0.13 0.27
I0916 20:26:07.854310 13572 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 4.24G 128/4 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.14 0.33
I0916 20:26:07.961580 13571 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 4.24G 128/1 6 4 5 	(avail 0.14G, req 0.07G)	t: 0 0.48 0.55
I0916 20:26:07.978808 13570 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 4.24G 128/1 6 4 5 	(avail 0.06G, req 0.04G)	t: 0 0.45 0.54
I0916 20:26:08.000398 13571 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 4.24G 256/4 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.11 0.2
I0916 20:26:08.001756 13572 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 4.24G 128/1 6 4 5 	(avail 0.14G, req 0.07G)	t: 0 0.52 0.58
I0916 20:26:08.023416 13570 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 4.24G 256/4 6 4 3 	(avail 0.06G, req 0.04G)	t: 0 0.1 0.18
I0916 20:26:08.031792 13572 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 4.24G 256/4 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.11 0.22
I0916 20:26:08.088630 13571 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'out3a' with space 4.24G 128/2 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.22 0.44
I0916 20:26:08.113046 13570 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'out3a' with space 4.24G 128/2 6 4 3 	(avail 0.06G, req 0.04G)	t: 0 0.24 0.4
I0916 20:26:08.132021 13572 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'out3a' with space 4.24G 128/2 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.23 0.47
I0916 20:26:08.205206 13571 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_conv1' with space 4.24G 64/1 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.29 0.63
I0916 20:26:08.228204 13570 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_conv1' with space 4.24G 64/1 6 4 3 	(avail 0.06G, req 0.04G)	t: 0 0.28 0.61
I0916 20:26:08.255657 13572 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'ctx_conv1' with space 4.24G 64/1 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.31 0.67
I0916 20:26:08.267278 13571 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_final' with space 4.24G 64/1 6 1 5 	(avail 0.14G, req 0.07G)	t: 0 0.11 0.35
I0916 20:26:08.281013 13570 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_final' with space 4.24G 64/1 6 1 5 	(avail 0.06G, req 0.04G)	t: 0 0.11 0.35
I0916 20:26:08.307013 13572 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'ctx_final' with space 4.24G 64/1 6 1 5 	(avail 0.14G, req 0.07G)	t: 0 0.12 0.37
I0916 20:26:08.436226 13570 solver.cpp:319] Iteration 2 (1.53713 s), loss = 0.0522841
I0916 20:26:08.436251 13570 solver.cpp:336]     Train net output #0: loss = 0.0522841 (* 1 = 0.0522841 loss)
I0916 20:26:08.436882 13572 cudnn_conv_layer.cpp:474] [2] Layer 'conv1a' reallocating workspace 4.24G to 0.14G
I0916 20:26:08.444725 13570 cudnn_conv_layer.cpp:474] [0] Layer 'conv1a' reallocating workspace 4.24G to 0.08G
I0916 20:26:08.454316 13571 cudnn_conv_layer.cpp:474] [1] Layer 'conv1a' reallocating workspace 4.24G to 0.14G
I0916 20:26:27.207232 13570 solver.cpp:314] Iteration 100 (5.22097 iter/s, 18.7705s/98 iter), loss = 0.0626877
I0916 20:26:27.207257 13570 solver.cpp:336]     Train net output #0: loss = 0.0626877 (* 1 = 0.0626877 loss)
I0916 20:26:27.207262 13570 sgd_solver.cpp:136] Iteration 100, lr = 0.01, m = 0.9
I0916 20:26:39.107138 13578 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 20:26:46.354437 13570 solver.cpp:314] Iteration 200 (5.22284 iter/s, 19.1467s/100 iter), loss = 0.10835
I0916 20:26:46.354467 13570 solver.cpp:336]     Train net output #0: loss = 0.10835 (* 1 = 0.10835 loss)
I0916 20:26:46.354473 13570 sgd_solver.cpp:136] Iteration 200, lr = 0.01, m = 0.9
I0916 20:27:05.671445 13570 solver.cpp:314] Iteration 300 (5.17693 iter/s, 19.3165s/100 iter), loss = 0.0914005
I0916 20:27:05.671465 13570 solver.cpp:336]     Train net output #0: loss = 0.0914004 (* 1 = 0.0914004 loss)
I0916 20:27:05.671470 13570 sgd_solver.cpp:136] Iteration 300, lr = 0.01, m = 0.9
I0916 20:27:24.791748 13570 solver.cpp:314] Iteration 400 (5.23019 iter/s, 19.1198s/100 iter), loss = 0.0800138
I0916 20:27:24.791798 13570 solver.cpp:336]     Train net output #0: loss = 0.0800138 (* 1 = 0.0800138 loss)
I0916 20:27:24.791803 13570 sgd_solver.cpp:136] Iteration 400, lr = 0.01, m = 0.9
I0916 20:27:42.919237 13574 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 20:27:44.450038 13570 solver.cpp:314] Iteration 500 (5.08706 iter/s, 19.6577s/100 iter), loss = 0.127362
I0916 20:27:44.450063 13570 solver.cpp:336]     Train net output #0: loss = 0.127362 (* 1 = 0.127362 loss)
I0916 20:27:44.450069 13570 sgd_solver.cpp:136] Iteration 500, lr = 0.01, m = 0.9
I0916 20:28:03.478564 13570 solver.cpp:314] Iteration 600 (5.25542 iter/s, 19.028s/100 iter), loss = 0.0829966
I0916 20:28:03.478621 13570 solver.cpp:336]     Train net output #0: loss = 0.0829965 (* 1 = 0.0829965 loss)
I0916 20:28:03.478628 13570 sgd_solver.cpp:136] Iteration 600, lr = 0.01, m = 0.9
I0916 20:28:22.781175 13570 solver.cpp:314] Iteration 700 (5.18079 iter/s, 19.3021s/100 iter), loss = 0.0879114
I0916 20:28:22.781198 13570 solver.cpp:336]     Train net output #0: loss = 0.0879113 (* 1 = 0.0879113 loss)
I0916 20:28:22.781205 13570 sgd_solver.cpp:136] Iteration 700, lr = 0.01, m = 0.9
I0916 20:28:42.035109 13570 solver.cpp:314] Iteration 800 (5.19389 iter/s, 19.2534s/100 iter), loss = 0.195807
I0916 20:28:42.035168 13570 solver.cpp:336]     Train net output #0: loss = 0.195807 (* 1 = 0.195807 loss)
I0916 20:28:42.035176 13570 sgd_solver.cpp:136] Iteration 800, lr = 0.01, m = 0.9
I0916 20:28:46.506585 13576 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 20:29:01.453392 13570 solver.cpp:314] Iteration 900 (5.14993 iter/s, 19.4177s/100 iter), loss = 0.0800309
I0916 20:29:01.453418 13570 solver.cpp:336]     Train net output #0: loss = 0.0800309 (* 1 = 0.0800309 loss)
I0916 20:29:01.453424 13570 sgd_solver.cpp:136] Iteration 900, lr = 0.01, m = 0.9
I0916 20:29:18.643040 13544 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 20:29:20.704495 13570 solver.cpp:368] Sparsity after update:
I0916 20:29:20.727072 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 20:29:20.727166 13570 net.cpp:2304] conv1a_param_0(0) 
I0916 20:29:20.727195 13570 net.cpp:2304] conv1b_param_0(0) 
I0916 20:29:20.727205 13570 net.cpp:2304] ctx_conv1_param_0(0) 
I0916 20:29:20.727213 13570 net.cpp:2304] ctx_conv2_param_0(0) 
I0916 20:29:20.727221 13570 net.cpp:2304] ctx_conv3_param_0(0) 
I0916 20:29:20.727229 13570 net.cpp:2304] ctx_conv4_param_0(0) 
I0916 20:29:20.727238 13570 net.cpp:2304] ctx_final_param_0(0) 
I0916 20:29:20.727247 13570 net.cpp:2304] out3a_param_0(0) 
I0916 20:29:20.727257 13570 net.cpp:2304] out5a_param_0(0) 
I0916 20:29:20.727265 13570 net.cpp:2304] res2a_branch2a_param_0(0) 
I0916 20:29:20.727274 13570 net.cpp:2304] res2a_branch2b_param_0(0) 
I0916 20:29:20.727285 13570 net.cpp:2304] res3a_branch2a_param_0(0) 
I0916 20:29:20.727295 13570 net.cpp:2304] res3a_branch2b_param_0(0) 
I0916 20:29:20.727304 13570 net.cpp:2304] res4a_branch2a_param_0(0) 
I0916 20:29:20.727313 13570 net.cpp:2304] res4a_branch2b_param_0(0) 
I0916 20:29:20.727321 13570 net.cpp:2304] res5a_branch2a_param_0(0) 
I0916 20:29:20.727330 13570 net.cpp:2304] res5a_branch2b_param_0(0) 
I0916 20:29:20.727339 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (0/2.69117e+06) 0
I0916 20:29:20.907929 13570 solver.cpp:314] Iteration 1000 (5.14033 iter/s, 19.454s/100 iter), loss = 0.0972464
I0916 20:29:20.907953 13570 solver.cpp:336]     Train net output #0: loss = 0.0972463 (* 1 = 0.0972463 loss)
I0916 20:29:20.907958 13570 sgd_solver.cpp:136] Iteration 1000, lr = 0.01, m = 0.9
I0916 20:29:40.589984 13570 solver.cpp:314] Iteration 1100 (5.08091 iter/s, 19.6815s/100 iter), loss = 0.0659606
I0916 20:29:40.590009 13570 solver.cpp:336]     Train net output #0: loss = 0.0659605 (* 1 = 0.0659605 loss)
I0916 20:29:40.590016 13570 sgd_solver.cpp:136] Iteration 1100, lr = 0.01, m = 0.9
I0916 20:30:00.113064 13570 solver.cpp:314] Iteration 1200 (5.12229 iter/s, 19.5225s/100 iter), loss = 0.0697681
I0916 20:30:00.113144 13570 solver.cpp:336]     Train net output #0: loss = 0.069768 (* 1 = 0.069768 loss)
I0916 20:30:00.113152 13570 sgd_solver.cpp:136] Iteration 1200, lr = 0.01, m = 0.9
I0916 20:30:19.479243 13570 solver.cpp:314] Iteration 1300 (5.16379 iter/s, 19.3656s/100 iter), loss = 0.0953907
I0916 20:30:19.479269 13570 solver.cpp:336]     Train net output #0: loss = 0.0953906 (* 1 = 0.0953906 loss)
I0916 20:30:19.479276 13570 sgd_solver.cpp:136] Iteration 1300, lr = 0.01, m = 0.9
I0916 20:30:23.190732 13573 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 20:30:39.311841 13570 solver.cpp:314] Iteration 1400 (5.04235 iter/s, 19.832s/100 iter), loss = 0.114281
I0916 20:30:39.311889 13570 solver.cpp:336]     Train net output #0: loss = 0.114281 (* 1 = 0.114281 loss)
I0916 20:30:39.311894 13570 sgd_solver.cpp:136] Iteration 1400, lr = 0.01, m = 0.9
I0916 20:30:58.876444 13570 solver.cpp:314] Iteration 1500 (5.11142 iter/s, 19.5641s/100 iter), loss = 0.0907609
I0916 20:30:58.876480 13570 solver.cpp:336]     Train net output #0: loss = 0.0907608 (* 1 = 0.0907608 loss)
I0916 20:30:58.876487 13570 sgd_solver.cpp:136] Iteration 1500, lr = 0.01, m = 0.9
I0916 20:31:18.400101 13570 solver.cpp:314] Iteration 1600 (5.12213 iter/s, 19.5231s/100 iter), loss = 0.076425
I0916 20:31:18.400204 13570 solver.cpp:336]     Train net output #0: loss = 0.0764249 (* 1 = 0.0764249 loss)
I0916 20:31:18.400213 13570 sgd_solver.cpp:136] Iteration 1600, lr = 0.01, m = 0.9
I0916 20:31:28.147564 13546 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 20:31:38.465708 13570 solver.cpp:314] Iteration 1700 (4.98379 iter/s, 20.065s/100 iter), loss = 0.118047
I0916 20:31:38.465734 13570 solver.cpp:336]     Train net output #0: loss = 0.118047 (* 1 = 0.118047 loss)
I0916 20:31:38.465740 13570 sgd_solver.cpp:136] Iteration 1700, lr = 0.01, m = 0.9
I0916 20:31:58.127096 13570 solver.cpp:314] Iteration 1800 (5.08625 iter/s, 19.6608s/100 iter), loss = 0.0790432
I0916 20:31:58.127198 13570 solver.cpp:336]     Train net output #0: loss = 0.0790431 (* 1 = 0.0790431 loss)
I0916 20:31:58.127207 13570 sgd_solver.cpp:136] Iteration 1800, lr = 0.01, m = 0.9
I0916 20:32:01.102394 13578 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 20:32:17.641944 13570 solver.cpp:314] Iteration 1900 (5.12445 iter/s, 19.5143s/100 iter), loss = 0.0668538
I0916 20:32:17.641968 13570 solver.cpp:336]     Train net output #0: loss = 0.0668537 (* 1 = 0.0668537 loss)
I0916 20:32:17.641973 13570 sgd_solver.cpp:136] Iteration 1900, lr = 0.01, m = 0.9
I0916 20:32:36.953130 13570 solver.cpp:368] Sparsity after update:
I0916 20:32:36.958254 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 20:32:36.958370 13570 net.cpp:2304] conv1a_param_0(0) 
I0916 20:32:36.958407 13570 net.cpp:2304] conv1b_param_0(0) 
I0916 20:32:36.958420 13570 net.cpp:2304] ctx_conv1_param_0(0) 
I0916 20:32:36.958431 13570 net.cpp:2304] ctx_conv2_param_0(0) 
I0916 20:32:36.958442 13570 net.cpp:2304] ctx_conv3_param_0(0) 
I0916 20:32:36.958454 13570 net.cpp:2304] ctx_conv4_param_0(0) 
I0916 20:32:36.958467 13570 net.cpp:2304] ctx_final_param_0(0) 
I0916 20:32:36.958477 13570 net.cpp:2304] out3a_param_0(0) 
I0916 20:32:36.958489 13570 net.cpp:2304] out5a_param_0(0) 
I0916 20:32:36.958500 13570 net.cpp:2304] res2a_branch2a_param_0(0) 
I0916 20:32:36.958513 13570 net.cpp:2304] res2a_branch2b_param_0(0) 
I0916 20:32:36.958523 13570 net.cpp:2304] res3a_branch2a_param_0(0) 
I0916 20:32:36.958534 13570 net.cpp:2304] res3a_branch2b_param_0(0) 
I0916 20:32:36.958546 13570 net.cpp:2304] res4a_branch2a_param_0(0) 
I0916 20:32:36.958560 13570 net.cpp:2304] res4a_branch2b_param_0(0) 
I0916 20:32:36.958571 13570 net.cpp:2304] res5a_branch2a_param_0(0) 
I0916 20:32:36.958582 13570 net.cpp:2304] res5a_branch2b_param_0(0) 
I0916 20:32:36.958593 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (0/2.69117e+06) 0
I0916 20:32:36.958619 13570 solver.cpp:563] Iteration 2000, Testing net (#0)
I0916 20:32:37.054013 13570 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1a' with space 0.08G 3/1 1 	(avail 4.2G, req 0G)	t: 0
I0916 20:32:37.061952 13571 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'conv1a' with space 0.14G 3/1 1 	(avail 4.24G, req 0G)	t: 0
I0916 20:32:37.073221 13572 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'conv1a' with space 0.14G 3/1 1 	(avail 4.24G, req 0G)	t: 0
I0916 20:32:37.091454 13570 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1b' with space 0.08G 32/4 6 	(avail 4.2G, req 0G)	t: 0
I0916 20:32:37.107632 13570 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2a' with space 0.08G 32/1 6 	(avail 4.2G, req 0G)	t: 0
I0916 20:32:37.118402 13571 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'conv1b' with space 0.14G 32/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 20:32:37.119091 13572 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'conv1b' with space 0.14G 32/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 20:32:37.119379 13570 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2b' with space 0.08G 64/4 6 	(avail 4.2G, req 0G)	t: 0
I0916 20:32:37.130568 13570 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2a' with space 0.08G 64/1 6 	(avail 4.2G, req 0G)	t: 0
I0916 20:32:37.136071 13572 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'res2a_branch2a' with space 0.14G 32/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 20:32:37.138041 13570 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2b' with space 0.08G 128/4 1 	(avail 4.2G, req 0G)	t: 0
I0916 20:32:37.141135 13571 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res2a_branch2a' with space 0.14G 32/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 20:32:37.144132 13570 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2a' with space 0.08G 128/1 6 	(avail 4.2G, req 0G)	t: 0
I0916 20:32:37.148849 13572 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'res2a_branch2b' with space 0.14G 64/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 20:32:37.149101 13570 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2b' with space 0.08G 256/4 6 	(avail 4.2G, req 0G)	t: 0
I0916 20:32:37.161109 13572 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'res3a_branch2a' with space 0.14G 64/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 20:32:37.162648 13570 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'out3a' with space 0.08G 128/2 6 	(avail 4.2G, req 0G)	t: 0
I0916 20:32:37.165089 13571 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res2a_branch2b' with space 0.14G 64/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 20:32:37.168443 13572 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'res3a_branch2b' with space 0.14G 128/4 1 	(avail 4.24G, req 0G)	t: 0
I0916 20:32:37.169960 13570 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_conv1' with space 0.08G 64/1 6 	(avail 4.2G, req 0G)	t: 0
I0916 20:32:37.177242 13571 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res3a_branch2a' with space 0.14G 64/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 20:32:37.177745 13572 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'res4a_branch2a' with space 0.14G 128/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 20:32:37.179857 13570 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_final' with space 0.08G 64/1 6 	(avail 4.2G, req 0G)	t: 0
I0916 20:32:37.182445 13572 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'res4a_branch2b' with space 0.14G 256/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 20:32:37.183912 13571 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res3a_branch2b' with space 0.14G 128/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 20:32:37.194756 13571 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res4a_branch2a' with space 0.14G 128/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 20:32:37.197062 13572 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'out3a' with space 0.14G 128/2 6 	(avail 4.24G, req 0G)	t: 0
I0916 20:32:37.199546 13571 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res4a_branch2b' with space 0.14G 256/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 20:32:37.206977 13572 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'ctx_conv1' with space 0.14G 64/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 20:32:37.213174 13571 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'out3a' with space 0.14G 128/2 6 	(avail 4.24G, req 0G)	t: 0
I0916 20:32:37.224254 13572 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'ctx_final' with space 0.14G 64/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 20:32:37.224911 13571 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_conv1' with space 0.14G 64/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 20:32:37.239892 13571 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_final' with space 0.14G 64/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 20:32:44.091719 13566 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 20:32:48.376057 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.93846
I0916 20:32:48.376085 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.999999
I0916 20:32:48.376094 13570 solver.cpp:655]     Test net output #2: loss = 0.185009 (* 1 = 0.185009 loss)
I0916 20:32:48.376152 13570 solver.cpp:265] [MultiGPU] Tests completed in 11.4172s
I0916 20:32:48.598438 13570 solver.cpp:314] Iteration 2000 (3.23043 iter/s, 30.9556s/100 iter), loss = 0.190298
I0916 20:32:48.598500 13570 solver.cpp:336]     Train net output #0: loss = 0.190298 (* 1 = 0.190298 loss)
I0916 20:32:48.598516 13570 sgd_solver.cpp:136] Iteration 2000, lr = 0.01, m = 0.9
I0916 20:33:08.242048 13570 solver.cpp:314] Iteration 2100 (5.09086 iter/s, 19.6431s/100 iter), loss = 0.0758436
I0916 20:33:08.242148 13570 solver.cpp:336]     Train net output #0: loss = 0.0758435 (* 1 = 0.0758435 loss)
I0916 20:33:08.242156 13570 sgd_solver.cpp:136] Iteration 2100, lr = 0.01, m = 0.9
I0916 20:33:27.960248 13570 solver.cpp:314] Iteration 2200 (5.0716 iter/s, 19.7177s/100 iter), loss = 0.131059
I0916 20:33:27.960273 13570 solver.cpp:336]     Train net output #0: loss = 0.131059 (* 1 = 0.131059 loss)
I0916 20:33:27.960278 13570 sgd_solver.cpp:136] Iteration 2200, lr = 0.01, m = 0.9
I0916 20:33:47.721277 13570 solver.cpp:314] Iteration 2300 (5.06061 iter/s, 19.7605s/100 iter), loss = 0.0804817
I0916 20:33:47.721362 13570 solver.cpp:336]     Train net output #0: loss = 0.0804817 (* 1 = 0.0804817 loss)
I0916 20:33:47.721370 13570 sgd_solver.cpp:136] Iteration 2300, lr = 0.01, m = 0.9
I0916 20:33:49.788101 13546 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 20:34:07.996366 13570 solver.cpp:314] Iteration 2400 (4.9323 iter/s, 20.2745s/100 iter), loss = 0.0711275
I0916 20:34:07.996392 13570 solver.cpp:336]     Train net output #0: loss = 0.0711275 (* 1 = 0.0711275 loss)
I0916 20:34:07.996399 13570 sgd_solver.cpp:136] Iteration 2400, lr = 0.01, m = 0.9
I0916 20:34:23.174016 13544 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 20:34:27.821038 13570 solver.cpp:314] Iteration 2500 (5.04436 iter/s, 19.8241s/100 iter), loss = 0.0904692
I0916 20:34:27.821069 13570 solver.cpp:336]     Train net output #0: loss = 0.0904692 (* 1 = 0.0904692 loss)
I0916 20:34:27.821077 13570 sgd_solver.cpp:136] Iteration 2500, lr = 0.01, m = 0.9
I0916 20:34:47.511258 13570 solver.cpp:314] Iteration 2600 (5.0788 iter/s, 19.6897s/100 iter), loss = 0.0796041
I0916 20:34:47.511283 13570 solver.cpp:336]     Train net output #0: loss = 0.079604 (* 1 = 0.079604 loss)
I0916 20:34:47.511289 13570 sgd_solver.cpp:136] Iteration 2600, lr = 0.01, m = 0.9
I0916 20:35:07.541353 13570 solver.cpp:314] Iteration 2700 (4.99263 iter/s, 20.0295s/100 iter), loss = 0.0736584
I0916 20:35:07.541509 13570 solver.cpp:336]     Train net output #0: loss = 0.0736582 (* 1 = 0.0736582 loss)
I0916 20:35:07.541517 13570 sgd_solver.cpp:136] Iteration 2700, lr = 0.01, m = 0.9
I0916 20:35:27.690789 13570 solver.cpp:314] Iteration 2800 (4.96306 iter/s, 20.1489s/100 iter), loss = 0.0603484
I0916 20:35:27.690814 13570 solver.cpp:336]     Train net output #0: loss = 0.0603483 (* 1 = 0.0603483 loss)
I0916 20:35:27.690820 13570 sgd_solver.cpp:136] Iteration 2800, lr = 0.01, m = 0.9
I0916 20:35:28.918642 13573 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 20:35:47.448968 13570 solver.cpp:314] Iteration 2900 (5.06134 iter/s, 19.7576s/100 iter), loss = 0.096287
I0916 20:35:47.449048 13570 solver.cpp:336]     Train net output #0: loss = 0.0962868 (* 1 = 0.0962868 loss)
I0916 20:35:47.449055 13570 sgd_solver.cpp:136] Iteration 2900, lr = 0.01, m = 0.9
I0916 20:36:07.070559 13570 solver.cpp:424] Finding and applying sparsity: sparsity_target=0.8 sparsity_factor=0.8 sparsity_achieved=0 iter=3000
I0916 20:36:48.112462 13570 net.cpp:2245] All zero weights of convolution layers are frozen
I0916 20:36:48.116446 13570 solver.cpp:368] Sparsity after update:
I0916 20:36:48.118016 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 20:36:48.118023 13570 net.cpp:2304] conv1a_param_0(0.322) 
I0916 20:36:48.118028 13570 net.cpp:2304] conv1b_param_0(0.724) 
I0916 20:36:48.118031 13570 net.cpp:2304] ctx_conv1_param_0(0.797) 
I0916 20:36:48.118032 13570 net.cpp:2304] ctx_conv2_param_0(0.798) 
I0916 20:36:48.118034 13570 net.cpp:2304] ctx_conv3_param_0(0.797) 
I0916 20:36:48.118036 13570 net.cpp:2304] ctx_conv4_param_0(0.798) 
I0916 20:36:48.118038 13570 net.cpp:2304] ctx_final_param_0(0.333) 
I0916 20:36:48.118041 13570 net.cpp:2304] out3a_param_0(0.799) 
I0916 20:36:48.118042 13570 net.cpp:2304] out5a_param_0(0.8) 
I0916 20:36:48.118044 13570 net.cpp:2304] res2a_branch2a_param_0(0.79) 
I0916 20:36:48.118046 13570 net.cpp:2304] res2a_branch2b_param_0(0.687) 
I0916 20:36:48.118048 13570 net.cpp:2304] res3a_branch2a_param_0(0.794) 
I0916 20:36:48.118050 13570 net.cpp:2304] res3a_branch2b_param_0(0.771) 
I0916 20:36:48.118052 13570 net.cpp:2304] res4a_branch2a_param_0(0.799) 
I0916 20:36:48.118054 13570 net.cpp:2304] res4a_branch2b_param_0(0.79) 
I0916 20:36:48.118057 13570 net.cpp:2304] res5a_branch2a_param_0(0.798) 
I0916 20:36:48.118058 13570 net.cpp:2304] res5a_branch2b_param_0(0.799) 
I0916 20:36:48.118059 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.14224e+06/2.69117e+06) 0.796
I0916 20:36:48.295306 13570 solver.cpp:314] Iteration 3000 (1.64353 iter/s, 60.8446s/100 iter), loss = 0.140066
I0916 20:36:48.295331 13570 solver.cpp:336]     Train net output #0: loss = 0.140066 (* 1 = 0.140066 loss)
I0916 20:36:48.295336 13570 sgd_solver.cpp:136] Iteration 3000, lr = 0.01, m = 0.9
I0916 20:37:07.411907 13570 solver.cpp:314] Iteration 3100 (5.2312 iter/s, 19.1161s/100 iter), loss = 0.0875209
I0916 20:37:07.411931 13570 solver.cpp:336]     Train net output #0: loss = 0.0875207 (* 1 = 0.0875207 loss)
I0916 20:37:07.411937 13570 sgd_solver.cpp:136] Iteration 3100, lr = 0.01, m = 0.9
I0916 20:37:14.608629 13576 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 20:37:26.809803 13570 solver.cpp:314] Iteration 3200 (5.15535 iter/s, 19.3973s/100 iter), loss = 0.195793
I0916 20:37:26.810758 13570 solver.cpp:336]     Train net output #0: loss = 0.195793 (* 1 = 0.195793 loss)
I0916 20:37:26.810828 13570 sgd_solver.cpp:136] Iteration 3200, lr = 0.01, m = 0.9
I0916 20:37:46.103037 13570 solver.cpp:314] Iteration 3300 (5.18331 iter/s, 19.2927s/100 iter), loss = 0.0855092
I0916 20:37:46.103061 13570 solver.cpp:336]     Train net output #0: loss = 0.085509 (* 1 = 0.085509 loss)
I0916 20:37:46.103067 13570 sgd_solver.cpp:136] Iteration 3300, lr = 0.01, m = 0.9
I0916 20:38:05.728325 13570 solver.cpp:314] Iteration 3400 (5.09561 iter/s, 19.6247s/100 iter), loss = 0.0499423
I0916 20:38:05.728379 13570 solver.cpp:336]     Train net output #0: loss = 0.0499421 (* 1 = 0.0499421 loss)
I0916 20:38:05.728384 13570 sgd_solver.cpp:136] Iteration 3400, lr = 0.01, m = 0.9
I0916 20:38:18.708616 13578 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 20:38:25.220371 13570 solver.cpp:314] Iteration 3500 (5.13044 iter/s, 19.4915s/100 iter), loss = 0.13982
I0916 20:38:25.220398 13570 solver.cpp:336]     Train net output #0: loss = 0.13982 (* 1 = 0.13982 loss)
I0916 20:38:25.220404 13570 sgd_solver.cpp:136] Iteration 3500, lr = 0.01, m = 0.9
I0916 20:38:44.839262 13570 solver.cpp:314] Iteration 3600 (5.09727 iter/s, 19.6183s/100 iter), loss = 0.097058
I0916 20:38:44.839324 13570 solver.cpp:336]     Train net output #0: loss = 0.0970579 (* 1 = 0.0970579 loss)
I0916 20:38:44.839332 13570 sgd_solver.cpp:136] Iteration 3600, lr = 0.01, m = 0.9
I0916 20:38:51.470559 13574 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 20:39:04.567071 13570 solver.cpp:314] Iteration 3700 (5.06913 iter/s, 19.7273s/100 iter), loss = 0.0785237
I0916 20:39:04.567095 13570 solver.cpp:336]     Train net output #0: loss = 0.0785236 (* 1 = 0.0785236 loss)
I0916 20:39:04.567101 13570 sgd_solver.cpp:136] Iteration 3700, lr = 0.01, m = 0.9
I0916 20:39:23.848279 13570 solver.cpp:314] Iteration 3800 (5.18654 iter/s, 19.2807s/100 iter), loss = 0.114514
I0916 20:39:23.848332 13570 solver.cpp:336]     Train net output #0: loss = 0.114514 (* 1 = 0.114514 loss)
I0916 20:39:23.848340 13570 sgd_solver.cpp:136] Iteration 3800, lr = 0.01, m = 0.9
I0916 20:39:43.713968 13570 solver.cpp:314] Iteration 3900 (5.03395 iter/s, 19.8651s/100 iter), loss = 0.0800754
I0916 20:39:43.713989 13570 solver.cpp:336]     Train net output #0: loss = 0.0800753 (* 1 = 0.0800753 loss)
I0916 20:39:43.713994 13570 sgd_solver.cpp:136] Iteration 3900, lr = 0.01, m = 0.9
I0916 20:39:55.976768 13574 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 20:40:03.005611 13570 solver.cpp:424] Finding and applying sparsity: sparsity_target=0.8 sparsity_factor=0.81 sparsity_achieved=0.796027 iter=4000
I0916 20:40:03.208127 13571 blocking_queue.cpp:40] Data layer prefetch queue empty
I0916 20:40:21.903847 13596 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 20:40:45.180069 13570 net.cpp:2245] All zero weights of convolution layers are frozen
I0916 20:40:45.184073 13570 solver.cpp:368] Sparsity after update:
I0916 20:40:45.185679 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 20:40:45.185686 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 20:40:45.185693 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 20:40:45.185694 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 20:40:45.185696 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 20:40:45.185698 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 20:40:45.185700 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 20:40:45.185703 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 20:40:45.185704 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 20:40:45.185705 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 20:40:45.185708 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 20:40:45.185709 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 20:40:45.185711 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 20:40:45.185714 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 20:40:45.185715 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 20:40:45.185717 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 20:40:45.185719 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 20:40:45.185721 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 20:40:45.185724 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 20:40:45.185732 13570 solver.cpp:563] Iteration 4000, Testing net (#0)
I0916 20:40:54.782819 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.949551
I0916 20:40:54.782840 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 20:40:54.782845 13570 solver.cpp:655]     Test net output #2: loss = 0.137472 (* 1 = 0.137472 loss)
I0916 20:40:54.782863 13570 solver.cpp:265] [MultiGPU] Tests completed in 9.59685s
I0916 20:40:54.995769 13570 solver.cpp:314] Iteration 4000 (1.40292 iter/s, 71.2798s/100 iter), loss = 0.0656239
I0916 20:40:54.995793 13570 solver.cpp:336]     Train net output #0: loss = 0.0656237 (* 1 = 0.0656237 loss)
I0916 20:40:54.995797 13570 sgd_solver.cpp:136] Iteration 4000, lr = 0.01, m = 0.9
I0916 20:41:13.925750 13570 solver.cpp:314] Iteration 4100 (5.28278 iter/s, 18.9294s/100 iter), loss = 0.0945595
I0916 20:41:13.925774 13570 solver.cpp:336]     Train net output #0: loss = 0.0945594 (* 1 = 0.0945594 loss)
I0916 20:41:13.925781 13570 sgd_solver.cpp:136] Iteration 4100, lr = 0.01, m = 0.9
I0916 20:41:19.247923 13574 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 20:41:32.778542 13570 solver.cpp:314] Iteration 4200 (5.30441 iter/s, 18.8523s/100 iter), loss = 0.0783329
I0916 20:41:32.778563 13570 solver.cpp:336]     Train net output #0: loss = 0.0783328 (* 1 = 0.0783328 loss)
I0916 20:41:32.778566 13570 sgd_solver.cpp:136] Iteration 4200, lr = 0.01, m = 0.9
I0916 20:41:51.645117 13570 solver.cpp:314] Iteration 4300 (5.30053 iter/s, 18.866s/100 iter), loss = 0.0856312
I0916 20:41:51.645169 13570 solver.cpp:336]     Train net output #0: loss = 0.0856311 (* 1 = 0.0856311 loss)
I0916 20:41:51.645175 13570 sgd_solver.cpp:136] Iteration 4300, lr = 0.01, m = 0.9
I0916 20:42:10.694687 13570 solver.cpp:314] Iteration 4400 (5.24961 iter/s, 19.049s/100 iter), loss = 0.0738094
I0916 20:42:10.694710 13570 solver.cpp:336]     Train net output #0: loss = 0.0738093 (* 1 = 0.0738093 loss)
I0916 20:42:10.694715 13570 sgd_solver.cpp:136] Iteration 4400, lr = 0.01, m = 0.9
I0916 20:42:22.090618 13574 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 20:42:29.873947 13570 solver.cpp:314] Iteration 4500 (5.21411 iter/s, 19.1787s/100 iter), loss = 0.053061
I0916 20:42:29.873977 13570 solver.cpp:336]     Train net output #0: loss = 0.0530608 (* 1 = 0.0530608 loss)
I0916 20:42:29.873982 13570 sgd_solver.cpp:136] Iteration 4500, lr = 0.01, m = 0.9
I0916 20:42:49.007956 13570 solver.cpp:314] Iteration 4600 (5.22644 iter/s, 19.1335s/100 iter), loss = 0.103944
I0916 20:42:49.007977 13570 solver.cpp:336]     Train net output #0: loss = 0.103944 (* 1 = 0.103944 loss)
I0916 20:42:49.007982 13570 sgd_solver.cpp:136] Iteration 4600, lr = 0.01, m = 0.9
I0916 20:43:08.154480 13570 solver.cpp:314] Iteration 4700 (5.22303 iter/s, 19.146s/100 iter), loss = 0.0785829
I0916 20:43:08.154556 13570 solver.cpp:336]     Train net output #0: loss = 0.0785828 (* 1 = 0.0785828 loss)
I0916 20:43:08.154562 13570 sgd_solver.cpp:136] Iteration 4700, lr = 0.01, m = 0.9
I0916 20:43:25.385401 13544 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 20:43:27.274410 13570 solver.cpp:314] Iteration 4800 (5.23029 iter/s, 19.1194s/100 iter), loss = 0.109161
I0916 20:43:27.274435 13570 solver.cpp:336]     Train net output #0: loss = 0.109161 (* 1 = 0.109161 loss)
I0916 20:43:27.274441 13570 sgd_solver.cpp:136] Iteration 4800, lr = 0.01, m = 0.9
I0916 20:43:46.152457 13570 solver.cpp:314] Iteration 4900 (5.29731 iter/s, 18.8775s/100 iter), loss = 0.0804116
I0916 20:43:46.152510 13570 solver.cpp:336]     Train net output #0: loss = 0.0804114 (* 1 = 0.0804114 loss)
I0916 20:43:46.152516 13570 sgd_solver.cpp:136] Iteration 4900, lr = 0.01, m = 0.9
I0916 20:43:56.786227 13574 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 20:44:05.225204 13570 solver.cpp:368] Sparsity after update:
I0916 20:44:05.235925 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 20:44:05.235936 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 20:44:05.235944 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 20:44:05.235947 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 20:44:05.235951 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 20:44:05.235954 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 20:44:05.235957 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 20:44:05.235960 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 20:44:05.235965 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 20:44:05.235967 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 20:44:05.235970 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 20:44:05.235973 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 20:44:05.235982 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 20:44:05.235988 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 20:44:05.235994 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 20:44:05.235999 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 20:44:05.236003 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 20:44:05.236007 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 20:44:05.236011 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 20:44:05.409207 13570 solver.cpp:314] Iteration 5000 (5.19313 iter/s, 19.2562s/100 iter), loss = 0.0795035
I0916 20:44:05.409235 13570 solver.cpp:336]     Train net output #0: loss = 0.0795033 (* 1 = 0.0795033 loss)
I0916 20:44:05.409242 13570 sgd_solver.cpp:136] Iteration 5000, lr = 0.01, m = 0.9
I0916 20:44:24.574054 13570 solver.cpp:314] Iteration 5100 (5.21803 iter/s, 19.1643s/100 iter), loss = 0.140494
I0916 20:44:24.574138 13570 solver.cpp:336]     Train net output #0: loss = 0.140494 (* 1 = 0.140494 loss)
I0916 20:44:24.574146 13570 sgd_solver.cpp:136] Iteration 5100, lr = 0.01, m = 0.9
I0916 20:44:43.988596 13570 solver.cpp:314] Iteration 5200 (5.15092 iter/s, 19.414s/100 iter), loss = 0.0838882
I0916 20:44:43.988622 13570 solver.cpp:336]     Train net output #0: loss = 0.0838881 (* 1 = 0.0838881 loss)
I0916 20:44:43.988626 13570 sgd_solver.cpp:136] Iteration 5200, lr = 0.01, m = 0.9
I0916 20:45:00.501806 13544 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 20:45:03.330526 13570 solver.cpp:314] Iteration 5300 (5.17026 iter/s, 19.3414s/100 iter), loss = 0.0588417
I0916 20:45:03.330554 13570 solver.cpp:336]     Train net output #0: loss = 0.0588415 (* 1 = 0.0588415 loss)
I0916 20:45:03.330560 13570 sgd_solver.cpp:136] Iteration 5300, lr = 0.01, m = 0.9
I0916 20:45:22.737607 13570 solver.cpp:314] Iteration 5400 (5.1529 iter/s, 19.4065s/100 iter), loss = 0.0579417
I0916 20:45:22.737632 13570 solver.cpp:336]     Train net output #0: loss = 0.0579416 (* 1 = 0.0579416 loss)
I0916 20:45:22.737637 13570 sgd_solver.cpp:136] Iteration 5400, lr = 0.01, m = 0.9
I0916 20:45:42.013429 13570 solver.cpp:314] Iteration 5500 (5.18799 iter/s, 19.2753s/100 iter), loss = 0.0605065
I0916 20:45:42.013535 13570 solver.cpp:336]     Train net output #0: loss = 0.0605064 (* 1 = 0.0605064 loss)
I0916 20:45:42.013542 13570 sgd_solver.cpp:136] Iteration 5500, lr = 0.01, m = 0.9
I0916 20:46:01.388849 13570 solver.cpp:314] Iteration 5600 (5.16132 iter/s, 19.3749s/100 iter), loss = 0.0456507
I0916 20:46:01.388875 13570 solver.cpp:336]     Train net output #0: loss = 0.0456506 (* 1 = 0.0456506 loss)
I0916 20:46:01.388880 13570 sgd_solver.cpp:136] Iteration 5600, lr = 0.01, m = 0.9
I0916 20:46:04.574499 13576 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 20:46:20.927963 13570 solver.cpp:314] Iteration 5700 (5.11808 iter/s, 19.5386s/100 iter), loss = 0.124146
I0916 20:46:20.928048 13570 solver.cpp:336]     Train net output #0: loss = 0.124146 (* 1 = 0.124146 loss)
I0916 20:46:20.928056 13570 sgd_solver.cpp:136] Iteration 5700, lr = 0.01, m = 0.9
I0916 20:46:36.535387 13544 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 20:46:40.163218 13570 solver.cpp:314] Iteration 5800 (5.19893 iter/s, 19.2347s/100 iter), loss = 0.0687667
I0916 20:46:40.163239 13570 solver.cpp:336]     Train net output #0: loss = 0.0687666 (* 1 = 0.0687666 loss)
I0916 20:46:40.163244 13570 sgd_solver.cpp:136] Iteration 5800, lr = 0.01, m = 0.9
I0916 20:46:59.475793 13570 solver.cpp:314] Iteration 5900 (5.17812 iter/s, 19.312s/100 iter), loss = 0.135915
I0916 20:46:59.475850 13570 solver.cpp:336]     Train net output #0: loss = 0.135915 (* 1 = 0.135915 loss)
I0916 20:46:59.475857 13570 sgd_solver.cpp:136] Iteration 5900, lr = 0.01, m = 0.9
I0916 20:47:18.462354 13570 solver.cpp:368] Sparsity after update:
I0916 20:47:18.468255 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 20:47:18.468264 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 20:47:18.468272 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 20:47:18.468277 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 20:47:18.468281 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 20:47:18.468286 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 20:47:18.468288 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 20:47:18.468292 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 20:47:18.468297 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 20:47:18.468299 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 20:47:18.468304 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 20:47:18.468308 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 20:47:18.468312 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 20:47:18.468315 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 20:47:18.468318 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 20:47:18.468322 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 20:47:18.468325 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 20:47:18.468328 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 20:47:18.468333 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 20:47:18.468343 13570 solver.cpp:563] Iteration 6000, Testing net (#0)
I0916 20:47:35.940654 13596 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 20:47:45.046319 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.951612
I0916 20:47:45.046341 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 20:47:45.046347 13570 solver.cpp:655]     Test net output #2: loss = 0.142208 (* 1 = 0.142208 loss)
I0916 20:47:45.046377 13570 solver.cpp:265] [MultiGPU] Tests completed in 26.5773s
I0916 20:47:45.240257 13570 solver.cpp:314] Iteration 6000 (2.18516 iter/s, 45.7632s/100 iter), loss = 0.0974221
I0916 20:47:45.240324 13570 solver.cpp:336]     Train net output #0: loss = 0.0974219 (* 1 = 0.0974219 loss)
I0916 20:47:45.240347 13570 sgd_solver.cpp:136] Iteration 6000, lr = 0.01, m = 0.9
I0916 20:48:04.514008 13570 solver.cpp:314] Iteration 6100 (5.18855 iter/s, 19.2732s/100 iter), loss = 0.0860933
I0916 20:48:04.514037 13570 solver.cpp:336]     Train net output #0: loss = 0.0860932 (* 1 = 0.0860932 loss)
I0916 20:48:04.514042 13570 sgd_solver.cpp:136] Iteration 6100, lr = 0.01, m = 0.9
I0916 20:48:23.972162 13570 solver.cpp:314] Iteration 6200 (5.13938 iter/s, 19.4576s/100 iter), loss = 0.0780754
I0916 20:48:23.972236 13570 solver.cpp:336]     Train net output #0: loss = 0.0780753 (* 1 = 0.0780753 loss)
I0916 20:48:23.972244 13570 sgd_solver.cpp:136] Iteration 6200, lr = 0.01, m = 0.9
I0916 20:48:38.791561 13576 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 20:48:43.318373 13570 solver.cpp:314] Iteration 6300 (5.16912 iter/s, 19.3457s/100 iter), loss = 0.0723286
I0916 20:48:43.318403 13570 solver.cpp:336]     Train net output #0: loss = 0.0723285 (* 1 = 0.0723285 loss)
I0916 20:48:43.318408 13570 sgd_solver.cpp:136] Iteration 6300, lr = 0.01, m = 0.9
I0916 20:49:02.920280 13570 solver.cpp:314] Iteration 6400 (5.10169 iter/s, 19.6014s/100 iter), loss = 0.0976418
I0916 20:49:02.920341 13570 solver.cpp:336]     Train net output #0: loss = 0.0976417 (* 1 = 0.0976417 loss)
I0916 20:49:02.920346 13570 sgd_solver.cpp:136] Iteration 6400, lr = 0.01, m = 0.9
I0916 20:49:23.422045 13570 solver.cpp:314] Iteration 6500 (4.87777 iter/s, 20.5012s/100 iter), loss = 0.0920015
I0916 20:49:23.422070 13570 solver.cpp:336]     Train net output #0: loss = 0.0920014 (* 1 = 0.0920014 loss)
I0916 20:49:23.422082 13570 sgd_solver.cpp:136] Iteration 6500, lr = 0.01, m = 0.9
I0916 20:49:43.037266 13570 solver.cpp:314] Iteration 6600 (5.09822 iter/s, 19.6147s/100 iter), loss = 0.104437
I0916 20:49:43.037356 13570 solver.cpp:336]     Train net output #0: loss = 0.104437 (* 1 = 0.104437 loss)
I0916 20:49:43.037369 13570 sgd_solver.cpp:136] Iteration 6600, lr = 0.01, m = 0.9
I0916 20:49:44.603792 13576 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 20:50:02.159435 13570 solver.cpp:314] Iteration 6700 (5.22968 iter/s, 19.1216s/100 iter), loss = 0.11876
I0916 20:50:02.159458 13570 solver.cpp:336]     Train net output #0: loss = 0.11876 (* 1 = 0.11876 loss)
I0916 20:50:02.159462 13570 sgd_solver.cpp:136] Iteration 6700, lr = 0.01, m = 0.9
I0916 20:50:16.145412 13544 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 20:50:21.399891 13570 solver.cpp:314] Iteration 6800 (5.19753 iter/s, 19.2399s/100 iter), loss = 0.0470434
I0916 20:50:21.399914 13570 solver.cpp:336]     Train net output #0: loss = 0.0470433 (* 1 = 0.0470433 loss)
I0916 20:50:21.399919 13570 sgd_solver.cpp:136] Iteration 6800, lr = 0.01, m = 0.9
I0916 20:50:40.666465 13570 solver.cpp:314] Iteration 6900 (5.19048 iter/s, 19.266s/100 iter), loss = 0.0970809
I0916 20:50:40.666493 13570 solver.cpp:336]     Train net output #0: loss = 0.0970807 (* 1 = 0.0970807 loss)
I0916 20:50:40.666501 13570 sgd_solver.cpp:136] Iteration 6900, lr = 0.01, m = 0.9
I0916 20:50:59.665386 13570 solver.cpp:368] Sparsity after update:
I0916 20:50:59.688340 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 20:50:59.688361 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 20:50:59.688371 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 20:50:59.688374 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 20:50:59.688377 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 20:50:59.688380 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 20:50:59.688383 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 20:50:59.688390 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 20:50:59.688396 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 20:50:59.688403 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 20:50:59.688410 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 20:50:59.688417 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 20:50:59.688426 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 20:50:59.688436 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 20:50:59.688446 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 20:50:59.688452 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 20:50:59.688462 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 20:50:59.688472 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 20:50:59.688478 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 20:50:59.864994 13570 solver.cpp:314] Iteration 7000 (5.20888 iter/s, 19.198s/100 iter), loss = 0.121334
I0916 20:50:59.865022 13570 solver.cpp:336]     Train net output #0: loss = 0.121334 (* 1 = 0.121334 loss)
I0916 20:50:59.865030 13570 sgd_solver.cpp:136] Iteration 7000, lr = 0.01, m = 0.9
I0916 20:51:19.692831 13570 solver.cpp:314] Iteration 7100 (5.04356 iter/s, 19.8273s/100 iter), loss = 0.0898811
I0916 20:51:19.692854 13570 solver.cpp:336]     Train net output #0: loss = 0.089881 (* 1 = 0.089881 loss)
I0916 20:51:19.692862 13570 sgd_solver.cpp:136] Iteration 7100, lr = 0.01, m = 0.9
I0916 20:51:20.348786 13576 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 20:51:39.245790 13570 solver.cpp:314] Iteration 7200 (5.11446 iter/s, 19.5524s/100 iter), loss = 0.0990547
I0916 20:51:39.245896 13570 solver.cpp:336]     Train net output #0: loss = 0.0990545 (* 1 = 0.0990545 loss)
I0916 20:51:39.245905 13570 sgd_solver.cpp:136] Iteration 7200, lr = 0.01, m = 0.9
I0916 20:51:58.723423 13570 solver.cpp:314] Iteration 7300 (5.13424 iter/s, 19.4771s/100 iter), loss = 0.0688318
I0916 20:51:58.723448 13570 solver.cpp:336]     Train net output #0: loss = 0.0688316 (* 1 = 0.0688316 loss)
I0916 20:51:58.723453 13570 sgd_solver.cpp:136] Iteration 7300, lr = 0.01, m = 0.9
I0916 20:52:18.059661 13570 solver.cpp:314] Iteration 7400 (5.17178 iter/s, 19.3357s/100 iter), loss = 0.135724
I0916 20:52:18.059708 13570 solver.cpp:336]     Train net output #0: loss = 0.135723 (* 1 = 0.135723 loss)
I0916 20:52:18.059715 13570 sgd_solver.cpp:136] Iteration 7400, lr = 0.01, m = 0.9
I0916 20:52:24.657635 13576 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 20:52:37.601938 13570 solver.cpp:314] Iteration 7500 (5.11725 iter/s, 19.5417s/100 iter), loss = 0.0933494
I0916 20:52:37.601971 13570 solver.cpp:336]     Train net output #0: loss = 0.0933493 (* 1 = 0.0933493 loss)
I0916 20:52:37.601979 13570 sgd_solver.cpp:136] Iteration 7500, lr = 0.01, m = 0.9
I0916 20:52:57.212220 13573 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 20:52:57.373646 13570 solver.cpp:314] Iteration 7600 (5.05787 iter/s, 19.7712s/100 iter), loss = 0.0627605
I0916 20:52:57.373672 13570 solver.cpp:336]     Train net output #0: loss = 0.0627603 (* 1 = 0.0627603 loss)
I0916 20:52:57.373678 13570 sgd_solver.cpp:136] Iteration 7600, lr = 0.01, m = 0.9
I0916 20:53:17.102192 13570 solver.cpp:314] Iteration 7700 (5.06894 iter/s, 19.728s/100 iter), loss = 0.0649859
I0916 20:53:17.102213 13570 solver.cpp:336]     Train net output #0: loss = 0.0649858 (* 1 = 0.0649858 loss)
I0916 20:53:17.102217 13570 sgd_solver.cpp:136] Iteration 7700, lr = 0.01, m = 0.9
I0916 20:53:36.600600 13570 solver.cpp:314] Iteration 7800 (5.12877 iter/s, 19.4979s/100 iter), loss = 0.118634
I0916 20:53:36.600662 13570 solver.cpp:336]     Train net output #0: loss = 0.118633 (* 1 = 0.118633 loss)
I0916 20:53:36.600672 13570 sgd_solver.cpp:136] Iteration 7800, lr = 0.01, m = 0.9
I0916 20:53:56.229694 13570 solver.cpp:314] Iteration 7900 (5.09462 iter/s, 19.6286s/100 iter), loss = 0.0764244
I0916 20:53:56.229717 13570 solver.cpp:336]     Train net output #0: loss = 0.0764243 (* 1 = 0.0764243 loss)
I0916 20:53:56.229722 13570 sgd_solver.cpp:136] Iteration 7900, lr = 0.01, m = 0.9
I0916 20:54:02.159503 13576 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 20:54:15.745522 13570 solver.cpp:368] Sparsity after update:
I0916 20:54:15.749979 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 20:54:15.749989 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 20:54:15.749997 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 20:54:15.750001 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 20:54:15.750006 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 20:54:15.750010 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 20:54:15.750013 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 20:54:15.750017 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 20:54:15.750022 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 20:54:15.750026 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 20:54:15.750030 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 20:54:15.750033 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 20:54:15.750037 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 20:54:15.750041 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 20:54:15.750046 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 20:54:15.750048 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 20:54:15.750052 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 20:54:15.750056 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 20:54:15.750061 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 20:54:15.750079 13570 solver.cpp:563] Iteration 8000, Testing net (#0)
I0916 20:54:33.951526 13604 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 20:54:34.362218 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.948542
I0916 20:54:34.362238 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 20:54:34.362243 13570 solver.cpp:655]     Test net output #2: loss = 0.139985 (* 1 = 0.139985 loss)
I0916 20:54:34.362262 13570 solver.cpp:265] [MultiGPU] Tests completed in 18.6117s
I0916 20:54:34.560808 13570 solver.cpp:314] Iteration 8000 (2.60892 iter/s, 38.3301s/100 iter), loss = 0.0943083
I0916 20:54:34.560830 13570 solver.cpp:336]     Train net output #0: loss = 0.0943081 (* 1 = 0.0943081 loss)
I0916 20:54:34.560837 13570 sgd_solver.cpp:136] Iteration 8000, lr = 0.01, m = 0.9
I0916 20:54:52.666412 13573 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 20:54:53.617607 13570 solver.cpp:314] Iteration 8100 (5.24762 iter/s, 19.0563s/100 iter), loss = 0.0759972
I0916 20:54:53.617641 13570 solver.cpp:336]     Train net output #0: loss = 0.075997 (* 1 = 0.075997 loss)
I0916 20:54:53.617647 13570 sgd_solver.cpp:136] Iteration 8100, lr = 0.01, m = 0.9
I0916 20:55:12.998772 13570 solver.cpp:314] Iteration 8200 (5.15979 iter/s, 19.3806s/100 iter), loss = 0.0637579
I0916 20:55:12.998793 13570 solver.cpp:336]     Train net output #0: loss = 0.0637578 (* 1 = 0.0637578 loss)
I0916 20:55:12.998797 13570 sgd_solver.cpp:136] Iteration 8200, lr = 0.01, m = 0.9
I0916 20:55:32.567441 13570 solver.cpp:314] Iteration 8300 (5.11036 iter/s, 19.5681s/100 iter), loss = 0.136909
I0916 20:55:32.567596 13570 solver.cpp:336]     Train net output #0: loss = 0.136909 (* 1 = 0.136909 loss)
I0916 20:55:32.567615 13570 sgd_solver.cpp:136] Iteration 8300, lr = 0.01, m = 0.9
I0916 20:55:52.019778 13570 solver.cpp:314] Iteration 8400 (5.14091 iter/s, 19.4518s/100 iter), loss = 0.0724969
I0916 20:55:52.019803 13570 solver.cpp:336]     Train net output #0: loss = 0.0724967 (* 1 = 0.0724967 loss)
I0916 20:55:52.019809 13570 sgd_solver.cpp:136] Iteration 8400, lr = 0.01, m = 0.9
I0916 20:55:57.230567 13544 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 20:56:11.614483 13570 solver.cpp:314] Iteration 8500 (5.10356 iter/s, 19.5942s/100 iter), loss = 0.058328
I0916 20:56:11.614544 13570 solver.cpp:336]     Train net output #0: loss = 0.0583278 (* 1 = 0.0583278 loss)
I0916 20:56:11.614552 13570 sgd_solver.cpp:136] Iteration 8500, lr = 0.01, m = 0.9
I0916 20:56:31.167523 13570 solver.cpp:314] Iteration 8600 (5.11444 iter/s, 19.5525s/100 iter), loss = 0.0976596
I0916 20:56:31.167548 13570 solver.cpp:336]     Train net output #0: loss = 0.0976595 (* 1 = 0.0976595 loss)
I0916 20:56:31.167554 13570 sgd_solver.cpp:136] Iteration 8600, lr = 0.01, m = 0.9
I0916 20:56:50.728050 13570 solver.cpp:314] Iteration 8700 (5.11248 iter/s, 19.56s/100 iter), loss = 0.0706931
I0916 20:56:50.728134 13570 solver.cpp:336]     Train net output #0: loss = 0.0706929 (* 1 = 0.0706929 loss)
I0916 20:56:50.728144 13570 sgd_solver.cpp:136] Iteration 8700, lr = 0.01, m = 0.9
I0916 20:57:01.528010 13546 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 20:57:10.072648 13570 solver.cpp:314] Iteration 8800 (5.16955 iter/s, 19.3441s/100 iter), loss = 0.0807629
I0916 20:57:10.072671 13570 solver.cpp:336]     Train net output #0: loss = 0.0807628 (* 1 = 0.0807628 loss)
I0916 20:57:10.072676 13570 sgd_solver.cpp:136] Iteration 8800, lr = 0.01, m = 0.9
I0916 20:57:29.814123 13570 solver.cpp:314] Iteration 8900 (5.06562 iter/s, 19.7409s/100 iter), loss = 0.0671901
I0916 20:57:29.814265 13570 solver.cpp:336]     Train net output #0: loss = 0.0671899 (* 1 = 0.0671899 loss)
I0916 20:57:29.814283 13570 sgd_solver.cpp:136] Iteration 8900, lr = 0.01, m = 0.9
I0916 20:57:34.070785 13574 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 20:57:49.365447 13570 solver.cpp:368] Sparsity after update:
I0916 20:57:49.386656 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 20:57:49.386675 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 20:57:49.386683 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 20:57:49.386687 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 20:57:49.386690 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 20:57:49.386693 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 20:57:49.386704 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 20:57:49.386713 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 20:57:49.386721 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 20:57:49.386729 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 20:57:49.386740 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 20:57:49.386746 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 20:57:49.386750 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 20:57:49.386759 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 20:57:49.386764 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 20:57:49.386766 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 20:57:49.386775 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 20:57:49.386785 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 20:57:49.386793 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 20:57:49.559442 13570 solver.cpp:314] Iteration 9000 (5.06463 iter/s, 19.7448s/100 iter), loss = 0.0760027
I0916 20:57:49.559468 13570 solver.cpp:336]     Train net output #0: loss = 0.0760026 (* 1 = 0.0760026 loss)
I0916 20:57:49.559474 13570 sgd_solver.cpp:136] Iteration 9000, lr = 0.01, m = 0.9
I0916 20:58:08.994613 13570 solver.cpp:314] Iteration 9100 (5.14545 iter/s, 19.4346s/100 iter), loss = 0.103087
I0916 20:58:08.994665 13570 solver.cpp:336]     Train net output #0: loss = 0.103086 (* 1 = 0.103086 loss)
I0916 20:58:08.994673 13570 sgd_solver.cpp:136] Iteration 9100, lr = 0.01, m = 0.9
I0916 20:58:28.720744 13570 solver.cpp:314] Iteration 9200 (5.06956 iter/s, 19.7256s/100 iter), loss = 0.0682991
I0916 20:58:28.720769 13570 solver.cpp:336]     Train net output #0: loss = 0.068299 (* 1 = 0.068299 loss)
I0916 20:58:28.720774 13570 sgd_solver.cpp:136] Iteration 9200, lr = 0.01, m = 0.9
I0916 20:58:39.045441 13544 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 20:58:48.406755 13570 solver.cpp:314] Iteration 9300 (5.07989 iter/s, 19.6855s/100 iter), loss = 0.0983355
I0916 20:58:48.406780 13570 solver.cpp:336]     Train net output #0: loss = 0.0983353 (* 1 = 0.0983353 loss)
I0916 20:58:48.406783 13570 sgd_solver.cpp:136] Iteration 9300, lr = 0.01, m = 0.9
I0916 20:59:07.635238 13570 solver.cpp:314] Iteration 9400 (5.20076 iter/s, 19.2279s/100 iter), loss = 0.0957308
I0916 20:59:07.635262 13570 solver.cpp:336]     Train net output #0: loss = 0.0957307 (* 1 = 0.0957307 loss)
I0916 20:59:07.635265 13570 sgd_solver.cpp:136] Iteration 9400, lr = 0.01, m = 0.9
I0916 20:59:26.703521 13570 solver.cpp:314] Iteration 9500 (5.24446 iter/s, 19.0678s/100 iter), loss = 0.0671488
I0916 20:59:26.703585 13570 solver.cpp:336]     Train net output #0: loss = 0.0671486 (* 1 = 0.0671486 loss)
I0916 20:59:26.703594 13570 sgd_solver.cpp:136] Iteration 9500, lr = 0.01, m = 0.9
I0916 20:59:42.969084 13578 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 20:59:46.224812 13570 solver.cpp:314] Iteration 9600 (5.12276 iter/s, 19.5207s/100 iter), loss = 0.0760185
I0916 20:59:46.224839 13570 solver.cpp:336]     Train net output #0: loss = 0.0760184 (* 1 = 0.0760184 loss)
I0916 20:59:46.224845 13570 sgd_solver.cpp:136] Iteration 9600, lr = 0.01, m = 0.9
I0916 21:00:05.707614 13570 solver.cpp:314] Iteration 9700 (5.13287 iter/s, 19.4823s/100 iter), loss = 0.065742
I0916 21:00:05.707686 13570 solver.cpp:336]     Train net output #0: loss = 0.0657418 (* 1 = 0.0657418 loss)
I0916 21:00:05.707693 13570 sgd_solver.cpp:136] Iteration 9700, lr = 0.01, m = 0.9
I0916 21:00:15.103310 13544 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 21:00:24.978108 13570 solver.cpp:314] Iteration 9800 (5.18943 iter/s, 19.27s/100 iter), loss = 0.0613421
I0916 21:00:24.978133 13570 solver.cpp:336]     Train net output #0: loss = 0.061342 (* 1 = 0.061342 loss)
I0916 21:00:24.978139 13570 sgd_solver.cpp:136] Iteration 9800, lr = 0.01, m = 0.9
I0916 21:00:44.559478 13570 solver.cpp:314] Iteration 9900 (5.10704 iter/s, 19.5808s/100 iter), loss = 0.116828
I0916 21:00:44.559540 13570 solver.cpp:336]     Train net output #0: loss = 0.116828 (* 1 = 0.116828 loss)
I0916 21:00:44.559546 13570 sgd_solver.cpp:136] Iteration 9900, lr = 0.01, m = 0.9
I0916 21:01:04.027935 13570 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/sparse/cityscapes5_jsegnet21v2_iter_10000.caffemodel
I0916 21:01:04.445638 13570 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/sparse/cityscapes5_jsegnet21v2_iter_10000.solverstate
I0916 21:01:04.451661 13570 solver.cpp:368] Sparsity after update:
I0916 21:01:04.453209 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 21:01:04.453218 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 21:01:04.453227 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 21:01:04.453233 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 21:01:04.453235 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 21:01:04.453248 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 21:01:04.453253 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 21:01:04.453258 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 21:01:04.453261 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 21:01:04.453265 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 21:01:04.453269 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 21:01:04.453274 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 21:01:04.453277 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 21:01:04.453281 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 21:01:04.453285 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 21:01:04.453289 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 21:01:04.453294 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 21:01:04.453299 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 21:01:04.453302 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 21:01:04.453315 13570 solver.cpp:563] Iteration 10000, Testing net (#0)
I0916 21:01:22.007033 13596 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 21:01:29.677130 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.954075
I0916 21:01:29.677156 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 21:01:29.677162 13570 solver.cpp:655]     Test net output #2: loss = 0.141268 (* 1 = 0.141268 loss)
I0916 21:01:29.677184 13570 solver.cpp:265] [MultiGPU] Tests completed in 25.2232s
I0916 21:01:29.871860 13570 solver.cpp:314] Iteration 10000 (2.20696 iter/s, 45.3111s/100 iter), loss = 0.0656963
I0916 21:01:29.871886 13570 solver.cpp:336]     Train net output #0: loss = 0.0656961 (* 1 = 0.0656961 loss)
I0916 21:01:29.871891 13570 sgd_solver.cpp:136] Iteration 10000, lr = 0.01, m = 0.9
I0916 21:01:48.867985 13570 solver.cpp:314] Iteration 10100 (5.26438 iter/s, 18.9956s/100 iter), loss = 0.0723629
I0916 21:01:48.868010 13570 solver.cpp:336]     Train net output #0: loss = 0.0723627 (* 1 = 0.0723627 loss)
I0916 21:01:48.868015 13570 sgd_solver.cpp:136] Iteration 10100, lr = 0.01, m = 0.9
I0916 21:02:07.709514 13570 solver.cpp:314] Iteration 10200 (5.30757 iter/s, 18.841s/100 iter), loss = 0.130504
I0916 21:02:07.709594 13570 solver.cpp:336]     Train net output #0: loss = 0.130504 (* 1 = 0.130504 loss)
I0916 21:02:07.709599 13570 sgd_solver.cpp:136] Iteration 10200, lr = 0.01, m = 0.9
I0916 21:02:16.025394 13576 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 21:02:26.596921 13570 solver.cpp:314] Iteration 10300 (5.29468 iter/s, 18.8869s/100 iter), loss = 0.0596175
I0916 21:02:26.596949 13570 solver.cpp:336]     Train net output #0: loss = 0.0596174 (* 1 = 0.0596174 loss)
I0916 21:02:26.596956 13570 sgd_solver.cpp:136] Iteration 10300, lr = 0.01, m = 0.9
I0916 21:02:45.835069 13570 solver.cpp:314] Iteration 10400 (5.19815 iter/s, 19.2376s/100 iter), loss = 0.0571445
I0916 21:02:45.835129 13570 solver.cpp:336]     Train net output #0: loss = 0.0571443 (* 1 = 0.0571443 loss)
I0916 21:02:45.835135 13570 sgd_solver.cpp:136] Iteration 10400, lr = 0.01, m = 0.9
I0916 21:02:47.611948 13574 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 21:03:04.988039 13570 solver.cpp:314] Iteration 10500 (5.22127 iter/s, 19.1524s/100 iter), loss = 0.0594255
I0916 21:03:04.988066 13570 solver.cpp:336]     Train net output #0: loss = 0.0594253 (* 1 = 0.0594253 loss)
I0916 21:03:04.988073 13570 sgd_solver.cpp:136] Iteration 10500, lr = 0.01, m = 0.9
I0916 21:03:24.177434 13570 solver.cpp:314] Iteration 10600 (5.21136 iter/s, 19.1889s/100 iter), loss = 0.0869555
I0916 21:03:24.177510 13570 solver.cpp:336]     Train net output #0: loss = 0.0869553 (* 1 = 0.0869553 loss)
I0916 21:03:24.177518 13570 sgd_solver.cpp:136] Iteration 10600, lr = 0.01, m = 0.9
I0916 21:03:43.419411 13570 solver.cpp:314] Iteration 10700 (5.19712 iter/s, 19.2414s/100 iter), loss = 0.0519495
I0916 21:03:43.419435 13570 solver.cpp:336]     Train net output #0: loss = 0.0519493 (* 1 = 0.0519493 loss)
I0916 21:03:43.419440 13570 sgd_solver.cpp:136] Iteration 10700, lr = 0.01, m = 0.9
I0916 21:03:51.239315 13544 data_reader.cpp:305] Starting prefetch of epoch 10
I0916 21:04:02.940167 13570 solver.cpp:314] Iteration 10800 (5.1229 iter/s, 19.5202s/100 iter), loss = 0.088924
I0916 21:04:02.940219 13570 solver.cpp:336]     Train net output #0: loss = 0.0889238 (* 1 = 0.0889238 loss)
I0916 21:04:02.940227 13570 sgd_solver.cpp:136] Iteration 10800, lr = 0.01, m = 0.9
I0916 21:04:22.218364 13570 solver.cpp:314] Iteration 10900 (5.18735 iter/s, 19.2777s/100 iter), loss = 0.0477844
I0916 21:04:22.218387 13570 solver.cpp:336]     Train net output #0: loss = 0.0477843 (* 1 = 0.0477843 loss)
I0916 21:04:22.218395 13570 sgd_solver.cpp:136] Iteration 10900, lr = 0.01, m = 0.9
I0916 21:04:40.974375 13570 solver.cpp:368] Sparsity after update:
I0916 21:04:40.996049 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 21:04:40.996071 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 21:04:40.996079 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 21:04:40.996083 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 21:04:40.996086 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 21:04:40.996089 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 21:04:40.996093 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 21:04:40.996095 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 21:04:40.996099 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 21:04:40.996103 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 21:04:40.996105 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 21:04:40.996109 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 21:04:40.996111 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 21:04:40.996114 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 21:04:40.996117 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 21:04:40.996120 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 21:04:40.996124 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 21:04:40.996126 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 21:04:40.996130 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 21:04:41.168543 13570 solver.cpp:314] Iteration 11000 (5.27714 iter/s, 18.9497s/100 iter), loss = 0.0631827
I0916 21:04:41.168565 13570 solver.cpp:336]     Train net output #0: loss = 0.0631826 (* 1 = 0.0631826 loss)
I0916 21:04:41.168570 13570 sgd_solver.cpp:136] Iteration 11000, lr = 0.01, m = 0.9
I0916 21:04:54.841648 13578 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 21:05:00.571024 13570 solver.cpp:314] Iteration 11100 (5.15412 iter/s, 19.4019s/100 iter), loss = 0.0860252
I0916 21:05:00.571048 13570 solver.cpp:336]     Train net output #0: loss = 0.0860251 (* 1 = 0.0860251 loss)
I0916 21:05:00.571053 13570 sgd_solver.cpp:136] Iteration 11100, lr = 0.01, m = 0.9
I0916 21:05:19.583137 13570 solver.cpp:314] Iteration 11200 (5.25995 iter/s, 19.0116s/100 iter), loss = 0.0768156
I0916 21:05:19.583210 13570 solver.cpp:336]     Train net output #0: loss = 0.0768155 (* 1 = 0.0768155 loss)
I0916 21:05:19.583217 13570 sgd_solver.cpp:136] Iteration 11200, lr = 0.01, m = 0.9
I0916 21:05:26.285393 13573 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 21:05:38.695966 13570 solver.cpp:314] Iteration 11300 (5.23223 iter/s, 19.1123s/100 iter), loss = 0.103171
I0916 21:05:38.695991 13570 solver.cpp:336]     Train net output #0: loss = 0.10317 (* 1 = 0.10317 loss)
I0916 21:05:38.695997 13570 sgd_solver.cpp:136] Iteration 11300, lr = 0.01, m = 0.9
I0916 21:05:57.622658 13570 solver.cpp:314] Iteration 11400 (5.28369 iter/s, 18.9262s/100 iter), loss = 0.0588841
I0916 21:05:57.622711 13570 solver.cpp:336]     Train net output #0: loss = 0.0588839 (* 1 = 0.0588839 loss)
I0916 21:05:57.622720 13570 sgd_solver.cpp:136] Iteration 11400, lr = 0.01, m = 0.9
I0916 21:06:16.740694 13570 solver.cpp:314] Iteration 11500 (5.23081 iter/s, 19.1175s/100 iter), loss = 0.0792103
I0916 21:06:16.740717 13570 solver.cpp:336]     Train net output #0: loss = 0.0792102 (* 1 = 0.0792102 loss)
I0916 21:06:16.740721 13570 sgd_solver.cpp:136] Iteration 11500, lr = 0.01, m = 0.9
I0916 21:06:29.325417 13574 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 21:06:35.784657 13570 solver.cpp:314] Iteration 11600 (5.25115 iter/s, 19.0434s/100 iter), loss = 0.10253
I0916 21:06:35.784687 13570 solver.cpp:336]     Train net output #0: loss = 0.10253 (* 1 = 0.10253 loss)
I0916 21:06:35.784693 13570 sgd_solver.cpp:136] Iteration 11600, lr = 0.01, m = 0.9
I0916 21:06:54.931403 13570 solver.cpp:314] Iteration 11700 (5.22296 iter/s, 19.1462s/100 iter), loss = 0.0467354
I0916 21:06:54.931428 13570 solver.cpp:336]     Train net output #0: loss = 0.0467353 (* 1 = 0.0467353 loss)
I0916 21:06:54.931432 13570 sgd_solver.cpp:136] Iteration 11700, lr = 0.01, m = 0.9
I0916 21:07:14.281004 13570 solver.cpp:314] Iteration 11800 (5.16821 iter/s, 19.3491s/100 iter), loss = 0.0561401
I0916 21:07:14.281993 13570 solver.cpp:336]     Train net output #0: loss = 0.05614 (* 1 = 0.05614 loss)
I0916 21:07:14.282002 13570 sgd_solver.cpp:136] Iteration 11800, lr = 0.01, m = 0.9
I0916 21:07:32.593854 13576 data_reader.cpp:305] Starting prefetch of epoch 10
I0916 21:07:33.309309 13570 solver.cpp:314] Iteration 11900 (5.25548 iter/s, 19.0278s/100 iter), loss = 0.0666576
I0916 21:07:33.309332 13570 solver.cpp:336]     Train net output #0: loss = 0.0666575 (* 1 = 0.0666575 loss)
I0916 21:07:33.309336 13570 sgd_solver.cpp:136] Iteration 11900, lr = 0.01, m = 0.9
I0916 21:07:52.164640 13570 solver.cpp:368] Sparsity after update:
I0916 21:07:52.167912 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 21:07:52.167919 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 21:07:52.167925 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 21:07:52.167928 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 21:07:52.167932 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 21:07:52.167934 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 21:07:52.167937 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 21:07:52.167939 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 21:07:52.167943 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 21:07:52.167945 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 21:07:52.167948 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 21:07:52.167953 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 21:07:52.167955 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 21:07:52.167960 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 21:07:52.167963 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 21:07:52.167968 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 21:07:52.167970 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 21:07:52.167973 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 21:07:52.167976 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 21:07:52.167987 13570 solver.cpp:563] Iteration 12000, Testing net (#0)
I0916 21:07:55.478461 13596 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 21:08:06.599689 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.949717
I0916 21:08:06.599709 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 21:08:06.599714 13570 solver.cpp:655]     Test net output #2: loss = 0.144888 (* 1 = 0.144888 loss)
I0916 21:08:06.599738 13570 solver.cpp:265] [MultiGPU] Tests completed in 14.4313s
I0916 21:08:06.797066 13570 solver.cpp:314] Iteration 12000 (2.98625 iter/s, 33.4868s/100 iter), loss = 0.0449524
I0916 21:08:06.797087 13570 solver.cpp:336]     Train net output #0: loss = 0.0449523 (* 1 = 0.0449523 loss)
I0916 21:08:06.797091 13570 sgd_solver.cpp:136] Iteration 12000, lr = 0.01, m = 0.9
I0916 21:08:25.692981 13570 solver.cpp:314] Iteration 12100 (5.2923 iter/s, 18.8954s/100 iter), loss = 0.101199
I0916 21:08:25.693053 13570 solver.cpp:336]     Train net output #0: loss = 0.101199 (* 1 = 0.101199 loss)
I0916 21:08:25.693059 13570 sgd_solver.cpp:136] Iteration 12100, lr = 0.01, m = 0.9
I0916 21:08:44.979054 13570 solver.cpp:314] Iteration 12200 (5.18523 iter/s, 19.2855s/100 iter), loss = 0.0627368
I0916 21:08:44.979079 13570 solver.cpp:336]     Train net output #0: loss = 0.0627367 (* 1 = 0.0627367 loss)
I0916 21:08:44.979082 13570 sgd_solver.cpp:136] Iteration 12200, lr = 0.01, m = 0.9
I0916 21:08:50.178051 13546 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 21:09:04.027740 13570 solver.cpp:314] Iteration 12300 (5.24985 iter/s, 19.0482s/100 iter), loss = 0.0584331
I0916 21:09:04.027788 13570 solver.cpp:336]     Train net output #0: loss = 0.058433 (* 1 = 0.058433 loss)
I0916 21:09:04.027794 13570 sgd_solver.cpp:136] Iteration 12300, lr = 0.01, m = 0.9
I0916 21:09:21.743950 13573 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 21:09:23.253962 13570 solver.cpp:314] Iteration 12400 (5.20138 iter/s, 19.2257s/100 iter), loss = 0.0607438
I0916 21:09:23.253988 13570 solver.cpp:336]     Train net output #0: loss = 0.0607437 (* 1 = 0.0607437 loss)
I0916 21:09:23.253993 13570 sgd_solver.cpp:136] Iteration 12400, lr = 0.01, m = 0.9
I0916 21:09:42.479306 13570 solver.cpp:314] Iteration 12500 (5.20161 iter/s, 19.2248s/100 iter), loss = 0.0887276
I0916 21:09:42.479365 13570 solver.cpp:336]     Train net output #0: loss = 0.0887275 (* 1 = 0.0887275 loss)
I0916 21:09:42.479370 13570 sgd_solver.cpp:136] Iteration 12500, lr = 0.01, m = 0.9
I0916 21:10:01.794705 13570 solver.cpp:314] Iteration 12600 (5.17736 iter/s, 19.3149s/100 iter), loss = 0.0426616
I0916 21:10:01.794728 13570 solver.cpp:336]     Train net output #0: loss = 0.0426615 (* 1 = 0.0426615 loss)
I0916 21:10:01.794734 13570 sgd_solver.cpp:136] Iteration 12600, lr = 0.01, m = 0.9
I0916 21:10:20.833205 13570 solver.cpp:314] Iteration 12700 (5.25266 iter/s, 19.038s/100 iter), loss = 0.154003
I0916 21:10:20.833261 13570 solver.cpp:336]     Train net output #0: loss = 0.154003 (* 1 = 0.154003 loss)
I0916 21:10:20.833268 13570 sgd_solver.cpp:136] Iteration 12700, lr = 0.01, m = 0.9
I0916 21:10:25.381170 13544 data_reader.cpp:305] Starting prefetch of epoch 11
I0916 21:10:40.209805 13570 solver.cpp:314] Iteration 12800 (5.16101 iter/s, 19.3761s/100 iter), loss = 0.0517557
I0916 21:10:40.209830 13570 solver.cpp:336]     Train net output #0: loss = 0.0517556 (* 1 = 0.0517556 loss)
I0916 21:10:40.209833 13570 sgd_solver.cpp:136] Iteration 12800, lr = 0.01, m = 0.9
I0916 21:10:59.336345 13570 solver.cpp:314] Iteration 12900 (5.22848 iter/s, 19.126s/100 iter), loss = 0.0757267
I0916 21:10:59.336428 13570 solver.cpp:336]     Train net output #0: loss = 0.0757266 (* 1 = 0.0757266 loss)
I0916 21:10:59.336433 13570 sgd_solver.cpp:136] Iteration 12900, lr = 0.01, m = 0.9
I0916 21:11:18.564862 13570 solver.cpp:368] Sparsity after update:
I0916 21:11:18.575023 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 21:11:18.575039 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 21:11:18.575049 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 21:11:18.575052 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 21:11:18.575055 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 21:11:18.575059 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 21:11:18.575068 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 21:11:18.575073 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 21:11:18.575079 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 21:11:18.575083 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 21:11:18.575085 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 21:11:18.575088 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 21:11:18.575091 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 21:11:18.575094 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 21:11:18.575096 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 21:11:18.575101 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 21:11:18.575104 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 21:11:18.575107 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 21:11:18.575109 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 21:11:18.748404 13570 solver.cpp:314] Iteration 13000 (5.15158 iter/s, 19.4115s/100 iter), loss = 0.0557747
I0916 21:11:18.748436 13570 solver.cpp:336]     Train net output #0: loss = 0.0557745 (* 1 = 0.0557745 loss)
I0916 21:11:18.748442 13570 sgd_solver.cpp:136] Iteration 13000, lr = 0.01, m = 0.9
I0916 21:11:29.199301 13546 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 21:11:38.599184 13570 solver.cpp:314] Iteration 13100 (5.03772 iter/s, 19.8502s/100 iter), loss = 0.0857933
I0916 21:11:38.599287 13570 solver.cpp:336]     Train net output #0: loss = 0.0857932 (* 1 = 0.0857932 loss)
I0916 21:11:38.599294 13570 sgd_solver.cpp:136] Iteration 13100, lr = 0.01, m = 0.9
I0916 21:11:58.224076 13570 solver.cpp:314] Iteration 13200 (5.09571 iter/s, 19.6243s/100 iter), loss = 0.0508496
I0916 21:11:58.224104 13570 solver.cpp:336]     Train net output #0: loss = 0.0508495 (* 1 = 0.0508495 loss)
I0916 21:11:58.224112 13570 sgd_solver.cpp:136] Iteration 13200, lr = 0.01, m = 0.9
I0916 21:12:02.025123 13544 data_reader.cpp:305] Starting prefetch of epoch 12
I0916 21:12:17.550422 13570 solver.cpp:314] Iteration 13300 (5.17443 iter/s, 19.3258s/100 iter), loss = 0.062153
I0916 21:12:17.550477 13570 solver.cpp:336]     Train net output #0: loss = 0.062153 (* 1 = 0.062153 loss)
I0916 21:12:17.550483 13570 sgd_solver.cpp:136] Iteration 13300, lr = 0.01, m = 0.9
I0916 21:12:37.070303 13570 solver.cpp:314] Iteration 13400 (5.12312 iter/s, 19.5193s/100 iter), loss = 0.0517103
I0916 21:12:37.070360 13570 solver.cpp:336]     Train net output #0: loss = 0.0517103 (* 1 = 0.0517103 loss)
I0916 21:12:37.070375 13570 sgd_solver.cpp:136] Iteration 13400, lr = 0.01, m = 0.9
I0916 21:12:56.845659 13570 solver.cpp:314] Iteration 13500 (5.05694 iter/s, 19.7748s/100 iter), loss = 0.0984877
I0916 21:12:56.845736 13570 solver.cpp:336]     Train net output #0: loss = 0.0984876 (* 1 = 0.0984876 loss)
I0916 21:12:56.845743 13570 sgd_solver.cpp:136] Iteration 13500, lr = 0.01, m = 0.9
I0916 21:13:06.383947 13578 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 21:13:16.155647 13570 solver.cpp:314] Iteration 13600 (5.17881 iter/s, 19.3095s/100 iter), loss = 0.0755642
I0916 21:13:16.155673 13570 solver.cpp:336]     Train net output #0: loss = 0.0755642 (* 1 = 0.0755642 loss)
I0916 21:13:16.155680 13570 sgd_solver.cpp:136] Iteration 13600, lr = 0.01, m = 0.9
I0916 21:13:35.658274 13570 solver.cpp:314] Iteration 13700 (5.12766 iter/s, 19.5021s/100 iter), loss = 0.062329
I0916 21:13:35.658397 13570 solver.cpp:336]     Train net output #0: loss = 0.062329 (* 1 = 0.062329 loss)
I0916 21:13:35.658414 13570 sgd_solver.cpp:136] Iteration 13700, lr = 0.01, m = 0.9
I0916 21:13:55.145653 13570 solver.cpp:314] Iteration 13800 (5.13167 iter/s, 19.4868s/100 iter), loss = 0.0621055
I0916 21:13:55.145679 13570 solver.cpp:336]     Train net output #0: loss = 0.0621054 (* 1 = 0.0621054 loss)
I0916 21:13:55.145684 13570 sgd_solver.cpp:136] Iteration 13800, lr = 0.01, m = 0.9
I0916 21:14:10.939606 13576 data_reader.cpp:305] Starting prefetch of epoch 11
I0916 21:14:14.823935 13570 solver.cpp:314] Iteration 13900 (5.08189 iter/s, 19.6777s/100 iter), loss = 0.0690783
I0916 21:14:14.823961 13570 solver.cpp:336]     Train net output #0: loss = 0.0690783 (* 1 = 0.0690783 loss)
I0916 21:14:14.823966 13570 sgd_solver.cpp:136] Iteration 13900, lr = 0.01, m = 0.9
I0916 21:14:33.984786 13570 solver.cpp:368] Sparsity after update:
I0916 21:14:33.993494 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 21:14:33.993676 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 21:14:33.993778 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 21:14:33.993840 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 21:14:33.993858 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 21:14:33.993875 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 21:14:33.993891 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 21:14:33.993906 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 21:14:33.993921 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 21:14:33.993937 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 21:14:33.993953 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 21:14:33.993968 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 21:14:33.993983 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 21:14:33.993999 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 21:14:33.994014 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 21:14:33.994029 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 21:14:33.994045 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 21:14:33.994058 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 21:14:33.994083 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 21:14:33.994112 13570 solver.cpp:563] Iteration 14000, Testing net (#0)
I0916 21:14:45.217376 13604 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 21:14:49.127707 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.948661
I0916 21:14:49.127725 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 21:14:49.127730 13570 solver.cpp:655]     Test net output #2: loss = 0.161936 (* 1 = 0.161936 loss)
I0916 21:14:49.127790 13570 solver.cpp:265] [MultiGPU] Tests completed in 15.1333s
I0916 21:14:49.338237 13570 solver.cpp:314] Iteration 14000 (2.89743 iter/s, 34.5133s/100 iter), loss = 0.110669
I0916 21:14:49.338260 13570 solver.cpp:336]     Train net output #0: loss = 0.110669 (* 1 = 0.110669 loss)
I0916 21:14:49.338266 13570 sgd_solver.cpp:136] Iteration 14000, lr = 0.01, m = 0.9
I0916 21:15:08.151237 13570 solver.cpp:314] Iteration 14100 (5.31562 iter/s, 18.8125s/100 iter), loss = 0.101745
I0916 21:15:08.151262 13570 solver.cpp:336]     Train net output #0: loss = 0.101745 (* 1 = 0.101745 loss)
I0916 21:15:08.151266 13570 sgd_solver.cpp:136] Iteration 14100, lr = 0.01, m = 0.9
I0916 21:15:27.527534 13570 solver.cpp:314] Iteration 14200 (5.16109 iter/s, 19.3758s/100 iter), loss = 0.0611564
I0916 21:15:27.527633 13570 solver.cpp:336]     Train net output #0: loss = 0.0611564 (* 1 = 0.0611564 loss)
I0916 21:15:27.527640 13570 sgd_solver.cpp:136] Iteration 14200, lr = 0.01, m = 0.9
I0916 21:15:29.481547 13576 data_reader.cpp:305] Starting prefetch of epoch 12
I0916 21:15:46.518436 13570 solver.cpp:314] Iteration 14300 (5.26583 iter/s, 18.9904s/100 iter), loss = 0.083291
I0916 21:15:46.518461 13570 solver.cpp:336]     Train net output #0: loss = 0.0832909 (* 1 = 0.0832909 loss)
I0916 21:15:46.518465 13570 sgd_solver.cpp:136] Iteration 14300, lr = 0.01, m = 0.9
I0916 21:16:05.594211 13570 solver.cpp:314] Iteration 14400 (5.2424 iter/s, 19.0752s/100 iter), loss = 0.0749015
I0916 21:16:05.594275 13570 solver.cpp:336]     Train net output #0: loss = 0.0749015 (* 1 = 0.0749015 loss)
I0916 21:16:05.594282 13570 sgd_solver.cpp:136] Iteration 14400, lr = 0.01, m = 0.9
I0916 21:16:24.527070 13570 solver.cpp:314] Iteration 14500 (5.28197 iter/s, 18.9323s/100 iter), loss = 0.0809877
I0916 21:16:24.527099 13570 solver.cpp:336]     Train net output #0: loss = 0.0809876 (* 1 = 0.0809876 loss)
I0916 21:16:24.527107 13570 sgd_solver.cpp:136] Iteration 14500, lr = 0.01, m = 0.9
I0916 21:16:32.353443 13578 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 21:16:43.623692 13570 solver.cpp:314] Iteration 14600 (5.23667 iter/s, 19.0961s/100 iter), loss = 0.09436
I0916 21:16:43.623745 13570 solver.cpp:336]     Train net output #0: loss = 0.09436 (* 1 = 0.09436 loss)
I0916 21:16:43.623750 13570 sgd_solver.cpp:136] Iteration 14600, lr = 0.01, m = 0.9
I0916 21:17:02.716358 13570 solver.cpp:314] Iteration 14700 (5.23776 iter/s, 19.0921s/100 iter), loss = 0.0764878
I0916 21:17:02.716383 13570 solver.cpp:336]     Train net output #0: loss = 0.0764878 (* 1 = 0.0764878 loss)
I0916 21:17:02.716388 13570 sgd_solver.cpp:136] Iteration 14700, lr = 0.01, m = 0.9
I0916 21:17:03.951922 13573 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 21:17:21.981930 13570 solver.cpp:314] Iteration 14800 (5.19075 iter/s, 19.265s/100 iter), loss = 0.0661202
I0916 21:17:21.981979 13570 solver.cpp:336]     Train net output #0: loss = 0.0661202 (* 1 = 0.0661202 loss)
I0916 21:17:21.981984 13570 sgd_solver.cpp:136] Iteration 14800, lr = 0.01, m = 0.9
I0916 21:17:40.898243 13570 solver.cpp:314] Iteration 14900 (5.28659 iter/s, 18.9158s/100 iter), loss = 0.105374
I0916 21:17:40.898272 13570 solver.cpp:336]     Train net output #0: loss = 0.105374 (* 1 = 0.105374 loss)
I0916 21:17:40.898279 13570 sgd_solver.cpp:136] Iteration 14900, lr = 0.01, m = 0.9
I0916 21:17:59.878660 13570 solver.cpp:368] Sparsity after update:
I0916 21:17:59.886874 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 21:17:59.886884 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 21:17:59.886891 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 21:17:59.886893 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 21:17:59.886895 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 21:17:59.886898 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 21:17:59.886899 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 21:17:59.886901 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 21:17:59.886905 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 21:17:59.886907 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 21:17:59.886910 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 21:17:59.886914 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 21:17:59.886916 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 21:17:59.886921 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 21:17:59.886924 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 21:17:59.886929 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 21:17:59.886931 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 21:17:59.886934 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 21:17:59.886940 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 21:18:00.059818 13570 solver.cpp:314] Iteration 15000 (5.21892 iter/s, 19.161s/100 iter), loss = 0.0581385
I0916 21:18:00.059839 13570 solver.cpp:336]     Train net output #0: loss = 0.0581384 (* 1 = 0.0581384 loss)
I0916 21:18:00.059844 13570 sgd_solver.cpp:136] Iteration 15000, lr = 0.01, m = 0.9
I0916 21:18:07.243908 13574 data_reader.cpp:305] Starting prefetch of epoch 10
I0916 21:18:19.244745 13570 solver.cpp:314] Iteration 15100 (5.21257 iter/s, 19.1844s/100 iter), loss = 0.105216
I0916 21:18:19.244768 13570 solver.cpp:336]     Train net output #0: loss = 0.105216 (* 1 = 0.105216 loss)
I0916 21:18:19.244774 13570 sgd_solver.cpp:136] Iteration 15100, lr = 0.01, m = 0.9
I0916 21:18:38.528995 13570 solver.cpp:314] Iteration 15200 (5.18572 iter/s, 19.2837s/100 iter), loss = 0.0863372
I0916 21:18:38.529533 13570 solver.cpp:336]     Train net output #0: loss = 0.0863371 (* 1 = 0.0863371 loss)
I0916 21:18:38.529543 13570 sgd_solver.cpp:136] Iteration 15200, lr = 0.01, m = 0.9
I0916 21:18:57.692705 13570 solver.cpp:314] Iteration 15300 (5.21834 iter/s, 19.1632s/100 iter), loss = 0.0408159
I0916 21:18:57.692729 13570 solver.cpp:336]     Train net output #0: loss = 0.0408159 (* 1 = 0.0408159 loss)
I0916 21:18:57.692734 13570 sgd_solver.cpp:136] Iteration 15300, lr = 0.01, m = 0.9
I0916 21:19:10.737325 13576 data_reader.cpp:305] Starting prefetch of epoch 13
I0916 21:19:17.161605 13570 solver.cpp:314] Iteration 15400 (5.13654 iter/s, 19.4684s/100 iter), loss = 0.0722576
I0916 21:19:17.161631 13570 solver.cpp:336]     Train net output #0: loss = 0.0722576 (* 1 = 0.0722576 loss)
I0916 21:19:17.161638 13570 sgd_solver.cpp:136] Iteration 15400, lr = 0.01, m = 0.9
I0916 21:19:36.473999 13570 solver.cpp:314] Iteration 15500 (5.17817 iter/s, 19.3119s/100 iter), loss = 0.0671703
I0916 21:19:36.474023 13570 solver.cpp:336]     Train net output #0: loss = 0.0671703 (* 1 = 0.0671703 loss)
I0916 21:19:36.474027 13570 sgd_solver.cpp:136] Iteration 15500, lr = 0.01, m = 0.9
I0916 21:19:42.916306 13544 data_reader.cpp:305] Starting prefetch of epoch 13
I0916 21:19:55.653688 13570 solver.cpp:314] Iteration 15600 (5.21399 iter/s, 19.1792s/100 iter), loss = 0.0885722
I0916 21:19:55.653713 13570 solver.cpp:336]     Train net output #0: loss = 0.0885721 (* 1 = 0.0885721 loss)
I0916 21:19:55.653719 13570 sgd_solver.cpp:136] Iteration 15600, lr = 0.01, m = 0.9
I0916 21:20:14.553793 13570 solver.cpp:314] Iteration 15700 (5.29112 iter/s, 18.8996s/100 iter), loss = 0.085968
I0916 21:20:14.553845 13570 solver.cpp:336]     Train net output #0: loss = 0.0859679 (* 1 = 0.0859679 loss)
I0916 21:20:14.553851 13570 sgd_solver.cpp:136] Iteration 15700, lr = 0.01, m = 0.9
I0916 21:20:33.524229 13570 solver.cpp:314] Iteration 15800 (5.27151 iter/s, 18.9699s/100 iter), loss = 0.0992197
I0916 21:20:33.524253 13570 solver.cpp:336]     Train net output #0: loss = 0.0992196 (* 1 = 0.0992196 loss)
I0916 21:20:33.524260 13570 sgd_solver.cpp:136] Iteration 15800, lr = 0.01, m = 0.9
I0916 21:20:45.567572 13574 data_reader.cpp:305] Starting prefetch of epoch 11
I0916 21:20:52.608018 13570 solver.cpp:314] Iteration 15900 (5.24019 iter/s, 19.0833s/100 iter), loss = 0.0543638
I0916 21:20:52.608043 13570 solver.cpp:336]     Train net output #0: loss = 0.0543637 (* 1 = 0.0543637 loss)
I0916 21:20:52.608049 13570 sgd_solver.cpp:136] Iteration 15900, lr = 0.01, m = 0.9
I0916 21:21:11.617687 13570 solver.cpp:368] Sparsity after update:
I0916 21:21:11.623600 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 21:21:11.623610 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 21:21:11.623617 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 21:21:11.623620 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 21:21:11.623621 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 21:21:11.623623 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 21:21:11.623625 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 21:21:11.623627 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 21:21:11.623630 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 21:21:11.623631 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 21:21:11.623636 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 21:21:11.623637 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 21:21:11.623641 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 21:21:11.623643 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 21:21:11.623646 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 21:21:11.623649 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 21:21:11.623652 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 21:21:11.623656 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 21:21:11.623659 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 21:21:11.623672 13570 solver.cpp:563] Iteration 16000, Testing net (#0)
I0916 21:21:28.668387 13604 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 21:21:29.043851 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.945807
I0916 21:21:29.043869 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 21:21:29.043874 13570 solver.cpp:655]     Test net output #2: loss = 0.155071 (* 1 = 0.155071 loss)
I0916 21:21:29.043933 13570 solver.cpp:265] [MultiGPU] Tests completed in 17.4198s
I0916 21:21:29.242599 13570 solver.cpp:314] Iteration 16000 (2.72974 iter/s, 36.6336s/100 iter), loss = 0.082639
I0916 21:21:29.242625 13570 solver.cpp:336]     Train net output #0: loss = 0.0826389 (* 1 = 0.0826389 loss)
I0916 21:21:29.242630 13570 sgd_solver.cpp:136] Iteration 16000, lr = 0.01, m = 0.9
I0916 21:21:34.772779 13573 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 21:21:48.625243 13570 solver.cpp:314] Iteration 16100 (5.1594 iter/s, 19.3821s/100 iter), loss = 0.0735314
I0916 21:21:48.625268 13570 solver.cpp:336]     Train net output #0: loss = 0.0735314 (* 1 = 0.0735314 loss)
I0916 21:21:48.625273 13570 sgd_solver.cpp:136] Iteration 16100, lr = 0.01, m = 0.9
I0916 21:22:08.140035 13570 solver.cpp:314] Iteration 16200 (5.12446 iter/s, 19.5142s/100 iter), loss = 0.104279
I0916 21:22:08.140082 13570 solver.cpp:336]     Train net output #0: loss = 0.104279 (* 1 = 0.104279 loss)
I0916 21:22:08.140089 13570 sgd_solver.cpp:136] Iteration 16200, lr = 0.01, m = 0.9
I0916 21:22:27.890805 13570 solver.cpp:314] Iteration 16300 (5.06324 iter/s, 19.7502s/100 iter), loss = 0.0691547
I0916 21:22:27.890830 13570 solver.cpp:336]     Train net output #0: loss = 0.0691546 (* 1 = 0.0691546 loss)
I0916 21:22:27.890836 13570 sgd_solver.cpp:136] Iteration 16300, lr = 0.01, m = 0.9
I0916 21:22:39.545912 13573 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 21:22:47.539193 13570 solver.cpp:314] Iteration 16400 (5.08962 iter/s, 19.6478s/100 iter), loss = 0.0597028
I0916 21:22:47.539216 13570 solver.cpp:336]     Train net output #0: loss = 0.0597027 (* 1 = 0.0597027 loss)
I0916 21:22:47.539222 13570 sgd_solver.cpp:136] Iteration 16400, lr = 0.01, m = 0.9
I0916 21:23:06.896610 13570 solver.cpp:314] Iteration 16500 (5.16612 iter/s, 19.3569s/100 iter), loss = 0.060235
I0916 21:23:06.896637 13570 solver.cpp:336]     Train net output #0: loss = 0.0602349 (* 1 = 0.0602349 loss)
I0916 21:23:06.896644 13570 sgd_solver.cpp:136] Iteration 16500, lr = 0.01, m = 0.9
I0916 21:23:26.121656 13570 solver.cpp:314] Iteration 16600 (5.20169 iter/s, 19.2245s/100 iter), loss = 0.0709967
I0916 21:23:26.121738 13570 solver.cpp:336]     Train net output #0: loss = 0.0709967 (* 1 = 0.0709967 loss)
I0916 21:23:26.121747 13570 sgd_solver.cpp:136] Iteration 16600, lr = 0.01, m = 0.9
I0916 21:23:43.341223 13576 data_reader.cpp:305] Starting prefetch of epoch 14
I0916 21:23:45.266979 13570 solver.cpp:314] Iteration 16700 (5.22335 iter/s, 19.1448s/100 iter), loss = 0.0940214
I0916 21:23:45.267007 13570 solver.cpp:336]     Train net output #0: loss = 0.0940214 (* 1 = 0.0940214 loss)
I0916 21:23:45.267014 13570 sgd_solver.cpp:136] Iteration 16700, lr = 0.01, m = 0.9
I0916 21:24:04.671581 13570 solver.cpp:314] Iteration 16800 (5.15356 iter/s, 19.4041s/100 iter), loss = 0.0855164
I0916 21:24:04.671660 13570 solver.cpp:336]     Train net output #0: loss = 0.0855163 (* 1 = 0.0855163 loss)
I0916 21:24:04.671669 13570 sgd_solver.cpp:136] Iteration 16800, lr = 0.01, m = 0.9
I0916 21:24:15.223477 13544 data_reader.cpp:305] Starting prefetch of epoch 14
I0916 21:24:23.819828 13570 solver.cpp:314] Iteration 16900 (5.22256 iter/s, 19.1477s/100 iter), loss = 0.0649248
I0916 21:24:23.819854 13570 solver.cpp:336]     Train net output #0: loss = 0.0649248 (* 1 = 0.0649248 loss)
I0916 21:24:23.819859 13570 sgd_solver.cpp:136] Iteration 16900, lr = 0.01, m = 0.9
I0916 21:24:42.569404 13570 solver.cpp:368] Sparsity after update:
I0916 21:24:42.584130 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 21:24:42.584146 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 21:24:42.584152 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 21:24:42.584154 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 21:24:42.584156 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 21:24:42.584158 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 21:24:42.584161 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 21:24:42.584162 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 21:24:42.584164 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 21:24:42.584167 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 21:24:42.584172 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 21:24:42.584174 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 21:24:42.584177 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 21:24:42.584180 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 21:24:42.584193 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 21:24:42.584198 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 21:24:42.584203 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 21:24:42.584208 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 21:24:42.584213 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 21:24:42.754024 13570 solver.cpp:314] Iteration 17000 (5.2816 iter/s, 18.9337s/100 iter), loss = 0.144899
I0916 21:24:42.754046 13570 solver.cpp:336]     Train net output #0: loss = 0.144898 (* 1 = 0.144898 loss)
I0916 21:24:42.754052 13570 sgd_solver.cpp:136] Iteration 17000, lr = 0.01, m = 0.9
I0916 21:25:01.762704 13570 solver.cpp:314] Iteration 17100 (5.2609 iter/s, 19.0082s/100 iter), loss = 0.0826382
I0916 21:25:01.762727 13570 solver.cpp:336]     Train net output #0: loss = 0.0826381 (* 1 = 0.0826381 loss)
I0916 21:25:01.762732 13570 sgd_solver.cpp:136] Iteration 17100, lr = 0.01, m = 0.9
I0916 21:25:18.104800 13576 data_reader.cpp:305] Starting prefetch of epoch 15
I0916 21:25:20.989204 13570 solver.cpp:314] Iteration 17200 (5.2013 iter/s, 19.226s/100 iter), loss = 0.0878394
I0916 21:25:20.989229 13570 solver.cpp:336]     Train net output #0: loss = 0.0878393 (* 1 = 0.0878393 loss)
I0916 21:25:20.989235 13570 sgd_solver.cpp:136] Iteration 17200, lr = 0.01, m = 0.9
I0916 21:25:40.132177 13570 solver.cpp:314] Iteration 17300 (5.22399 iter/s, 19.1424s/100 iter), loss = 0.0560185
I0916 21:25:40.132201 13570 solver.cpp:336]     Train net output #0: loss = 0.0560184 (* 1 = 0.0560184 loss)
I0916 21:25:40.132208 13570 sgd_solver.cpp:136] Iteration 17300, lr = 0.01, m = 0.9
I0916 21:25:59.125465 13570 solver.cpp:314] Iteration 17400 (5.26516 iter/s, 18.9928s/100 iter), loss = 0.0525275
I0916 21:25:59.125519 13570 solver.cpp:336]     Train net output #0: loss = 0.0525274 (* 1 = 0.0525274 loss)
I0916 21:25:59.125524 13570 sgd_solver.cpp:136] Iteration 17400, lr = 0.01, m = 0.9
I0916 21:26:18.140785 13570 solver.cpp:314] Iteration 17500 (5.25906 iter/s, 19.0148s/100 iter), loss = 0.0486733
I0916 21:26:18.140807 13570 solver.cpp:336]     Train net output #0: loss = 0.0486732 (* 1 = 0.0486732 loss)
I0916 21:26:18.140811 13570 sgd_solver.cpp:136] Iteration 17500, lr = 0.01, m = 0.9
I0916 21:26:21.212550 13578 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 21:26:37.301163 13570 solver.cpp:314] Iteration 17600 (5.21925 iter/s, 19.1598s/100 iter), loss = 0.081201
I0916 21:26:37.301249 13570 solver.cpp:336]     Train net output #0: loss = 0.0812009 (* 1 = 0.0812009 loss)
I0916 21:26:37.301256 13570 sgd_solver.cpp:136] Iteration 17600, lr = 0.01, m = 0.9
I0916 21:26:53.088529 13573 data_reader.cpp:305] Starting prefetch of epoch 10
I0916 21:26:56.729493 13570 solver.cpp:314] Iteration 17700 (5.14726 iter/s, 19.4278s/100 iter), loss = 0.0691581
I0916 21:26:56.729518 13570 solver.cpp:336]     Train net output #0: loss = 0.069158 (* 1 = 0.069158 loss)
I0916 21:26:56.729524 13570 sgd_solver.cpp:136] Iteration 17700, lr = 0.01, m = 0.9
I0916 21:27:16.184383 13570 solver.cpp:314] Iteration 17800 (5.14024 iter/s, 19.4543s/100 iter), loss = 0.0624589
I0916 21:27:16.184473 13570 solver.cpp:336]     Train net output #0: loss = 0.0624588 (* 1 = 0.0624588 loss)
I0916 21:27:16.184480 13570 sgd_solver.cpp:136] Iteration 17800, lr = 0.01, m = 0.9
I0916 21:27:35.619781 13570 solver.cpp:314] Iteration 17900 (5.14539 iter/s, 19.4349s/100 iter), loss = 0.0814559
I0916 21:27:35.619858 13570 solver.cpp:336]     Train net output #0: loss = 0.0814558 (* 1 = 0.0814558 loss)
I0916 21:27:35.619877 13570 sgd_solver.cpp:136] Iteration 17900, lr = 0.01, m = 0.9
I0916 21:27:54.752755 13570 solver.cpp:368] Sparsity after update:
I0916 21:27:54.762650 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 21:27:54.762703 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 21:27:54.762722 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 21:27:54.762734 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 21:27:54.762747 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 21:27:54.762758 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 21:27:54.762770 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 21:27:54.762783 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 21:27:54.762794 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 21:27:54.762806 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 21:27:54.762818 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 21:27:54.762830 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 21:27:54.762842 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 21:27:54.762854 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 21:27:54.762866 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 21:27:54.762878 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 21:27:54.762889 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 21:27:54.762902 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 21:27:54.762913 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 21:27:54.762936 13570 solver.cpp:563] Iteration 18000, Testing net (#0)
I0916 21:28:03.911329 13600 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 21:28:07.836987 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.94925
I0916 21:28:07.837003 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 21:28:07.837008 13570 solver.cpp:655]     Test net output #2: loss = 0.165083 (* 1 = 0.165083 loss)
I0916 21:28:07.837035 13570 solver.cpp:265] [MultiGPU] Tests completed in 13.0737s
I0916 21:28:08.043509 13570 solver.cpp:314] Iteration 18000 (3.08425 iter/s, 32.4228s/100 iter), loss = 0.0665594
I0916 21:28:08.043530 13570 solver.cpp:336]     Train net output #0: loss = 0.0665593 (* 1 = 0.0665593 loss)
I0916 21:28:08.043534 13570 sgd_solver.cpp:136] Iteration 18000, lr = 0.01, m = 0.9
I0916 21:28:27.199630 13570 solver.cpp:314] Iteration 18100 (5.22041 iter/s, 19.1556s/100 iter), loss = 0.0658514
I0916 21:28:27.199684 13570 solver.cpp:336]     Train net output #0: loss = 0.0658513 (* 1 = 0.0658513 loss)
I0916 21:28:27.199690 13570 sgd_solver.cpp:136] Iteration 18100, lr = 0.01, m = 0.9
I0916 21:28:42.081938 13576 data_reader.cpp:305] Starting prefetch of epoch 16
I0916 21:28:46.473343 13570 solver.cpp:314] Iteration 18200 (5.18856 iter/s, 19.2732s/100 iter), loss = 0.0640518
I0916 21:28:46.473366 13570 solver.cpp:336]     Train net output #0: loss = 0.0640517 (* 1 = 0.0640517 loss)
I0916 21:28:46.473371 13570 sgd_solver.cpp:136] Iteration 18200, lr = 0.01, m = 0.9
I0916 21:29:05.772264 13570 solver.cpp:314] Iteration 18300 (5.18178 iter/s, 19.2984s/100 iter), loss = 0.0819666
I0916 21:29:05.772348 13570 solver.cpp:336]     Train net output #0: loss = 0.0819664 (* 1 = 0.0819664 loss)
I0916 21:29:05.772356 13570 sgd_solver.cpp:136] Iteration 18300, lr = 0.01, m = 0.9
I0916 21:29:13.939270 13574 data_reader.cpp:305] Starting prefetch of epoch 12
I0916 21:29:25.045374 13570 solver.cpp:314] Iteration 18400 (5.18872 iter/s, 19.2726s/100 iter), loss = 0.0614444
I0916 21:29:25.045397 13570 solver.cpp:336]     Train net output #0: loss = 0.0614442 (* 1 = 0.0614442 loss)
I0916 21:29:25.045403 13570 sgd_solver.cpp:136] Iteration 18400, lr = 0.01, m = 0.9
I0916 21:29:44.175652 13570 solver.cpp:314] Iteration 18500 (5.22746 iter/s, 19.1297s/100 iter), loss = 0.0910969
I0916 21:29:44.175724 13570 solver.cpp:336]     Train net output #0: loss = 0.0910968 (* 1 = 0.0910968 loss)
I0916 21:29:44.175731 13570 sgd_solver.cpp:136] Iteration 18500, lr = 0.01, m = 0.9
I0916 21:30:03.370318 13570 solver.cpp:314] Iteration 18600 (5.20992 iter/s, 19.1941s/100 iter), loss = 0.0834138
I0916 21:30:03.370347 13570 solver.cpp:336]     Train net output #0: loss = 0.0834137 (* 1 = 0.0834137 loss)
I0916 21:30:03.370352 13570 sgd_solver.cpp:136] Iteration 18600, lr = 0.01, m = 0.9
I0916 21:30:17.215520 13574 data_reader.cpp:305] Starting prefetch of epoch 13
I0916 21:30:22.266240 13570 solver.cpp:314] Iteration 18700 (5.29229 iter/s, 18.8954s/100 iter), loss = 0.0461382
I0916 21:30:22.266265 13570 solver.cpp:336]     Train net output #0: loss = 0.0461381 (* 1 = 0.0461381 loss)
I0916 21:30:22.266271 13570 sgd_solver.cpp:136] Iteration 18700, lr = 0.01, m = 0.9
I0916 21:30:41.509156 13570 solver.cpp:314] Iteration 18800 (5.19686 iter/s, 19.2424s/100 iter), loss = 0.186511
I0916 21:30:41.509186 13570 solver.cpp:336]     Train net output #0: loss = 0.186511 (* 1 = 0.186511 loss)
I0916 21:30:41.509191 13570 sgd_solver.cpp:136] Iteration 18800, lr = 0.01, m = 0.9
I0916 21:31:00.729890 13570 solver.cpp:314] Iteration 18900 (5.20286 iter/s, 19.2202s/100 iter), loss = 0.0713475
I0916 21:31:00.729946 13570 solver.cpp:336]     Train net output #0: loss = 0.0713473 (* 1 = 0.0713473 loss)
I0916 21:31:00.729953 13570 sgd_solver.cpp:136] Iteration 18900, lr = 0.01, m = 0.9
I0916 21:31:19.476356 13570 solver.cpp:368] Sparsity after update:
I0916 21:31:19.497900 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 21:31:19.497920 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 21:31:19.497928 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 21:31:19.497931 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 21:31:19.497934 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 21:31:19.497937 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 21:31:19.497948 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 21:31:19.498088 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 21:31:19.498092 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 21:31:19.498095 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 21:31:19.498106 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 21:31:19.498119 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 21:31:19.498124 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 21:31:19.498128 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 21:31:19.498138 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 21:31:19.498143 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 21:31:19.498147 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 21:31:19.498157 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 21:31:19.498162 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 21:31:19.667888 13570 solver.cpp:314] Iteration 19000 (5.28053 iter/s, 18.9375s/100 iter), loss = 0.130745
I0916 21:31:19.667913 13570 solver.cpp:336]     Train net output #0: loss = 0.130745 (* 1 = 0.130745 loss)
I0916 21:31:19.667918 13570 sgd_solver.cpp:136] Iteration 19000, lr = 0.01, m = 0.9
I0916 21:31:20.259241 13578 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 21:31:38.842332 13570 solver.cpp:314] Iteration 19100 (5.21542 iter/s, 19.1739s/100 iter), loss = 0.0577735
I0916 21:31:38.842430 13570 solver.cpp:336]     Train net output #0: loss = 0.0577733 (* 1 = 0.0577733 loss)
I0916 21:31:38.842440 13570 sgd_solver.cpp:136] Iteration 19100, lr = 0.01, m = 0.9
I0916 21:31:52.132647 13574 data_reader.cpp:305] Starting prefetch of epoch 14
I0916 21:31:58.047056 13570 solver.cpp:314] Iteration 19200 (5.2072 iter/s, 19.2042s/100 iter), loss = 0.101265
I0916 21:31:58.047078 13570 solver.cpp:336]     Train net output #0: loss = 0.101264 (* 1 = 0.101264 loss)
I0916 21:31:58.047082 13570 sgd_solver.cpp:136] Iteration 19200, lr = 0.01, m = 0.9
I0916 21:32:17.266243 13570 solver.cpp:314] Iteration 19300 (5.20328 iter/s, 19.2187s/100 iter), loss = 0.0882747
I0916 21:32:17.266299 13570 solver.cpp:336]     Train net output #0: loss = 0.0882745 (* 1 = 0.0882745 loss)
I0916 21:32:17.266304 13570 sgd_solver.cpp:136] Iteration 19300, lr = 0.01, m = 0.9
I0916 21:32:36.505601 13570 solver.cpp:314] Iteration 19400 (5.19782 iter/s, 19.2388s/100 iter), loss = 0.109641
I0916 21:32:36.505625 13570 solver.cpp:336]     Train net output #0: loss = 0.109641 (* 1 = 0.109641 loss)
I0916 21:32:36.505630 13570 sgd_solver.cpp:136] Iteration 19400, lr = 0.01, m = 0.9
I0916 21:32:55.393311 13546 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 21:32:55.560228 13570 solver.cpp:314] Iteration 19500 (5.24821 iter/s, 19.0541s/100 iter), loss = 0.0734464
I0916 21:32:55.560256 13570 solver.cpp:336]     Train net output #0: loss = 0.0734463 (* 1 = 0.0734463 loss)
I0916 21:32:55.560262 13570 sgd_solver.cpp:136] Iteration 19500, lr = 0.01, m = 0.9
I0916 21:33:14.916766 13570 solver.cpp:314] Iteration 19600 (5.16636 iter/s, 19.356s/100 iter), loss = 0.0778947
I0916 21:33:14.916790 13570 solver.cpp:336]     Train net output #0: loss = 0.0778946 (* 1 = 0.0778946 loss)
I0916 21:33:14.916796 13570 sgd_solver.cpp:136] Iteration 19600, lr = 0.01, m = 0.9
I0916 21:33:34.336952 13570 solver.cpp:314] Iteration 19700 (5.14942 iter/s, 19.4196s/100 iter), loss = 0.387243
I0916 21:33:34.337055 13570 solver.cpp:336]     Train net output #0: loss = 0.387243 (* 1 = 0.387243 loss)
I0916 21:33:34.337062 13570 sgd_solver.cpp:136] Iteration 19700, lr = 0.01, m = 0.9
I0916 21:33:53.717381 13570 solver.cpp:314] Iteration 19800 (5.15999 iter/s, 19.3799s/100 iter), loss = 0.0835243
I0916 21:33:53.717413 13570 solver.cpp:336]     Train net output #0: loss = 0.0835242 (* 1 = 0.0835242 loss)
I0916 21:33:53.717419 13570 sgd_solver.cpp:136] Iteration 19800, lr = 0.01, m = 0.9
I0916 21:33:59.541226 13578 data_reader.cpp:305] Starting prefetch of epoch 10
I0916 21:34:12.745961 13570 solver.cpp:314] Iteration 19900 (5.2554 iter/s, 19.0281s/100 iter), loss = 0.0680409
I0916 21:34:12.746011 13570 solver.cpp:336]     Train net output #0: loss = 0.0680408 (* 1 = 0.0680408 loss)
I0916 21:34:12.746017 13570 sgd_solver.cpp:136] Iteration 19900, lr = 0.01, m = 0.9
I0916 21:34:30.968166 13573 data_reader.cpp:305] Starting prefetch of epoch 11
I0916 21:34:31.704252 13570 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/sparse/cityscapes5_jsegnet21v2_iter_20000.caffemodel
I0916 21:34:31.845266 13570 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/sparse/cityscapes5_jsegnet21v2_iter_20000.solverstate
I0916 21:34:31.860409 13570 solver.cpp:368] Sparsity after update:
I0916 21:34:31.865726 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 21:34:31.865738 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 21:34:31.865747 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 21:34:31.865751 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 21:34:31.865754 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 21:34:31.865767 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 21:34:31.865772 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 21:34:31.865777 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 21:34:31.865782 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 21:34:31.865787 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 21:34:31.865792 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 21:34:31.865797 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 21:34:31.865799 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 21:34:31.865803 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 21:34:31.865804 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 21:34:31.865808 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 21:34:31.865811 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 21:34:31.865816 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 21:34:31.865820 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 21:34:31.865833 13570 solver.cpp:563] Iteration 20000, Testing net (#0)
I0916 21:34:42.913796 13596 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 21:34:43.198057 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.952837
I0916 21:34:43.198087 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 21:34:43.198093 13570 solver.cpp:655]     Test net output #2: loss = 0.136725 (* 1 = 0.136725 loss)
I0916 21:34:43.198119 13570 solver.cpp:265] [MultiGPU] Tests completed in 11.332s
I0916 21:34:43.416617 13570 solver.cpp:314] Iteration 20000 (3.26054 iter/s, 30.6698s/100 iter), loss = 0.0504049
I0916 21:34:43.416638 13570 solver.cpp:336]     Train net output #0: loss = 0.0504048 (* 1 = 0.0504048 loss)
I0916 21:34:43.416643 13570 sgd_solver.cpp:136] Iteration 20000, lr = 0.01, m = 0.9
I0916 21:35:02.599643 13570 solver.cpp:314] Iteration 20100 (5.21309 iter/s, 19.1825s/100 iter), loss = 0.0493404
I0916 21:35:02.599675 13570 solver.cpp:336]     Train net output #0: loss = 0.0493403 (* 1 = 0.0493403 loss)
I0916 21:35:02.599684 13570 sgd_solver.cpp:136] Iteration 20100, lr = 0.01, m = 0.9
I0916 21:35:21.690340 13570 solver.cpp:314] Iteration 20200 (5.2383 iter/s, 19.0902s/100 iter), loss = 0.0894915
I0916 21:35:21.690388 13570 solver.cpp:336]     Train net output #0: loss = 0.0894914 (* 1 = 0.0894914 loss)
I0916 21:35:21.690394 13570 sgd_solver.cpp:136] Iteration 20200, lr = 0.01, m = 0.9
I0916 21:35:40.663727 13570 solver.cpp:314] Iteration 20300 (5.27069 iter/s, 18.9729s/100 iter), loss = 0.065241
I0916 21:35:40.663753 13570 solver.cpp:336]     Train net output #0: loss = 0.065241 (* 1 = 0.065241 loss)
I0916 21:35:40.663756 13570 sgd_solver.cpp:136] Iteration 20300, lr = 0.01, m = 0.9
I0916 21:35:45.589361 13578 data_reader.cpp:305] Starting prefetch of epoch 11
I0916 21:35:59.836444 13570 solver.cpp:314] Iteration 20400 (5.21589 iter/s, 19.1722s/100 iter), loss = 0.0652461
I0916 21:35:59.836500 13570 solver.cpp:336]     Train net output #0: loss = 0.065246 (* 1 = 0.065246 loss)
I0916 21:35:59.836505 13570 sgd_solver.cpp:136] Iteration 20400, lr = 0.01, m = 0.9
I0916 21:36:17.032059 13544 data_reader.cpp:305] Starting prefetch of epoch 15
I0916 21:36:18.705744 13570 solver.cpp:314] Iteration 20500 (5.29976 iter/s, 18.8688s/100 iter), loss = 0.0628669
I0916 21:36:18.705768 13570 solver.cpp:336]     Train net output #0: loss = 0.0628668 (* 1 = 0.0628668 loss)
I0916 21:36:18.705775 13570 sgd_solver.cpp:136] Iteration 20500, lr = 0.01, m = 0.9
I0916 21:36:37.971015 13570 solver.cpp:314] Iteration 20600 (5.19083 iter/s, 19.2647s/100 iter), loss = 0.0573044
I0916 21:36:37.971122 13570 solver.cpp:336]     Train net output #0: loss = 0.0573044 (* 1 = 0.0573044 loss)
I0916 21:36:37.971128 13570 sgd_solver.cpp:136] Iteration 20600, lr = 0.01, m = 0.9
I0916 21:36:57.210741 13570 solver.cpp:314] Iteration 20700 (5.19772 iter/s, 19.2392s/100 iter), loss = 0.0561842
I0916 21:36:57.210769 13570 solver.cpp:336]     Train net output #0: loss = 0.0561841 (* 1 = 0.0561841 loss)
I0916 21:36:57.210777 13570 sgd_solver.cpp:136] Iteration 20700, lr = 0.01, m = 0.9
I0916 21:37:16.229621 13570 solver.cpp:314] Iteration 20800 (5.25808 iter/s, 19.0184s/100 iter), loss = 0.0440697
I0916 21:37:16.229673 13570 solver.cpp:336]     Train net output #0: loss = 0.0440697 (* 1 = 0.0440697 loss)
I0916 21:37:16.229681 13570 sgd_solver.cpp:136] Iteration 20800, lr = 0.01, m = 0.9
I0916 21:37:20.249635 13573 data_reader.cpp:305] Starting prefetch of epoch 12
I0916 21:37:35.115010 13570 solver.cpp:314] Iteration 20900 (5.29525 iter/s, 18.8849s/100 iter), loss = 0.0538882
I0916 21:37:35.115031 13570 solver.cpp:336]     Train net output #0: loss = 0.0538881 (* 1 = 0.0538881 loss)
I0916 21:37:35.115036 13570 sgd_solver.cpp:136] Iteration 20900, lr = 0.01, m = 0.9
I0916 21:37:54.361335 13570 solver.cpp:368] Sparsity after update:
I0916 21:37:54.370065 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 21:37:54.370079 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 21:37:54.370085 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 21:37:54.370087 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 21:37:54.370088 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 21:37:54.370090 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 21:37:54.370092 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 21:37:54.370095 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 21:37:54.370096 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 21:37:54.370098 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 21:37:54.370100 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 21:37:54.370102 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 21:37:54.370105 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 21:37:54.370105 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 21:37:54.370107 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 21:37:54.370110 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 21:37:54.370111 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 21:37:54.370113 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 21:37:54.370115 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 21:37:54.542327 13570 solver.cpp:314] Iteration 21000 (5.14753 iter/s, 19.4268s/100 iter), loss = 0.0918613
I0916 21:37:54.542353 13570 solver.cpp:336]     Train net output #0: loss = 0.0918613 (* 1 = 0.0918613 loss)
I0916 21:37:54.542359 13570 sgd_solver.cpp:136] Iteration 21000, lr = 0.01, m = 0.9
I0916 21:38:13.843861 13570 solver.cpp:314] Iteration 21100 (5.18108 iter/s, 19.301s/100 iter), loss = 0.0568948
I0916 21:38:13.843886 13570 solver.cpp:336]     Train net output #0: loss = 0.0568948 (* 1 = 0.0568948 loss)
I0916 21:38:13.843892 13570 sgd_solver.cpp:136] Iteration 21100, lr = 0.01, m = 0.9
I0916 21:38:23.852211 13578 data_reader.cpp:305] Starting prefetch of epoch 12
I0916 21:38:33.041299 13570 solver.cpp:314] Iteration 21200 (5.20917 iter/s, 19.1969s/100 iter), loss = 0.0946441
I0916 21:38:33.041381 13570 solver.cpp:336]     Train net output #0: loss = 0.0946441 (* 1 = 0.0946441 loss)
I0916 21:38:33.041388 13570 sgd_solver.cpp:136] Iteration 21200, lr = 0.01, m = 0.9
I0916 21:38:52.214087 13570 solver.cpp:314] Iteration 21300 (5.21587 iter/s, 19.1723s/100 iter), loss = 0.0806111
I0916 21:38:52.214110 13570 solver.cpp:336]     Train net output #0: loss = 0.080611 (* 1 = 0.080611 loss)
I0916 21:38:52.214114 13570 sgd_solver.cpp:136] Iteration 21300, lr = 0.01, m = 0.9
I0916 21:38:55.613209 13574 data_reader.cpp:305] Starting prefetch of epoch 15
I0916 21:39:11.492522 13570 solver.cpp:314] Iteration 21400 (5.18729 iter/s, 19.2779s/100 iter), loss = 0.0549161
I0916 21:39:11.492583 13570 solver.cpp:336]     Train net output #0: loss = 0.0549161 (* 1 = 0.0549161 loss)
I0916 21:39:11.492588 13570 sgd_solver.cpp:136] Iteration 21400, lr = 0.01, m = 0.9
I0916 21:39:30.673200 13570 solver.cpp:314] Iteration 21500 (5.21372 iter/s, 19.1801s/100 iter), loss = 0.0562319
I0916 21:39:30.673224 13570 solver.cpp:336]     Train net output #0: loss = 0.0562318 (* 1 = 0.0562318 loss)
I0916 21:39:30.673233 13570 sgd_solver.cpp:136] Iteration 21500, lr = 0.01, m = 0.9
I0916 21:39:49.763222 13570 solver.cpp:314] Iteration 21600 (5.23848 iter/s, 19.0895s/100 iter), loss = 0.0873113
I0916 21:39:49.763300 13570 solver.cpp:336]     Train net output #0: loss = 0.0873112 (* 1 = 0.0873112 loss)
I0916 21:39:49.763309 13570 sgd_solver.cpp:136] Iteration 21600, lr = 0.01, m = 0.9
I0916 21:39:58.999922 13544 data_reader.cpp:305] Starting prefetch of epoch 16
I0916 21:40:08.927502 13570 solver.cpp:314] Iteration 21700 (5.21819 iter/s, 19.1637s/100 iter), loss = 0.0702146
I0916 21:40:08.927527 13570 solver.cpp:336]     Train net output #0: loss = 0.0702145 (* 1 = 0.0702145 loss)
I0916 21:40:08.927533 13570 sgd_solver.cpp:136] Iteration 21700, lr = 0.01, m = 0.9
I0916 21:40:28.158970 13570 solver.cpp:314] Iteration 21800 (5.19996 iter/s, 19.2309s/100 iter), loss = 0.0755476
I0916 21:40:28.167224 13570 solver.cpp:336]     Train net output #0: loss = 0.0755475 (* 1 = 0.0755475 loss)
I0916 21:40:28.167264 13570 sgd_solver.cpp:136] Iteration 21800, lr = 0.01, m = 0.9
I0916 21:40:47.475782 13570 solver.cpp:314] Iteration 21900 (5.17698 iter/s, 19.3163s/100 iter), loss = 0.0616839
I0916 21:40:47.475811 13570 solver.cpp:336]     Train net output #0: loss = 0.0616838 (* 1 = 0.0616838 loss)
I0916 21:40:47.475818 13570 sgd_solver.cpp:136] Iteration 21900, lr = 0.01, m = 0.9
I0916 21:41:02.415021 13546 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 21:41:06.370694 13570 solver.cpp:368] Sparsity after update:
I0916 21:41:06.377806 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 21:41:06.377817 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 21:41:06.377826 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 21:41:06.377830 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 21:41:06.377842 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 21:41:06.377851 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 21:41:06.377859 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 21:41:06.377872 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 21:41:06.377882 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 21:41:06.377892 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 21:41:06.377897 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 21:41:06.377907 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 21:41:06.377918 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 21:41:06.377923 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 21:41:06.377926 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 21:41:06.377934 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 21:41:06.377943 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 21:41:06.377948 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 21:41:06.377956 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 21:41:06.377970 13570 solver.cpp:563] Iteration 22000, Testing net (#0)
I0916 21:41:24.071929 13596 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 21:41:30.516649 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.953003
I0916 21:41:30.516687 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 21:41:30.516692 13570 solver.cpp:655]     Test net output #2: loss = 0.14585 (* 1 = 0.14585 loss)
I0916 21:41:30.516719 13570 solver.cpp:265] [MultiGPU] Tests completed in 24.1381s
I0916 21:41:30.710103 13570 solver.cpp:314] Iteration 22000 (2.31304 iter/s, 43.2331s/100 iter), loss = 0.0924981
I0916 21:41:30.710132 13570 solver.cpp:336]     Train net output #0: loss = 0.092498 (* 1 = 0.092498 loss)
I0916 21:41:30.710139 13570 sgd_solver.cpp:136] Iteration 22000, lr = 0.01, m = 0.9
I0916 21:41:49.751557 13570 solver.cpp:314] Iteration 22100 (5.25185 iter/s, 19.0409s/100 iter), loss = 0.211635
I0916 21:41:49.751607 13570 solver.cpp:336]     Train net output #0: loss = 0.211635 (* 1 = 0.211635 loss)
I0916 21:41:49.751616 13570 sgd_solver.cpp:136] Iteration 22100, lr = 0.01, m = 0.9
I0916 21:42:08.817240 13570 solver.cpp:314] Iteration 22200 (5.24517 iter/s, 19.0651s/100 iter), loss = 0.0637696
I0916 21:42:08.817271 13570 solver.cpp:336]     Train net output #0: loss = 0.0637695 (* 1 = 0.0637695 loss)
I0916 21:42:08.817278 13570 sgd_solver.cpp:136] Iteration 22200, lr = 0.01, m = 0.9
I0916 21:42:28.049919 13570 solver.cpp:314] Iteration 22300 (5.19963 iter/s, 19.2321s/100 iter), loss = 0.0520868
I0916 21:42:28.049988 13570 solver.cpp:336]     Train net output #0: loss = 0.0520867 (* 1 = 0.0520867 loss)
I0916 21:42:28.049994 13570 sgd_solver.cpp:136] Iteration 22300, lr = 0.01, m = 0.9
I0916 21:42:29.888368 13546 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 21:42:47.424401 13570 solver.cpp:314] Iteration 22400 (5.16157 iter/s, 19.3739s/100 iter), loss = 0.0849994
I0916 21:42:47.424430 13570 solver.cpp:336]     Train net output #0: loss = 0.0849994 (* 1 = 0.0849994 loss)
I0916 21:42:47.424437 13570 sgd_solver.cpp:136] Iteration 22400, lr = 0.01, m = 0.9
I0916 21:43:06.407027 13570 solver.cpp:314] Iteration 22500 (5.26812 iter/s, 18.9821s/100 iter), loss = 0.131864
I0916 21:43:06.407084 13570 solver.cpp:336]     Train net output #0: loss = 0.131864 (* 1 = 0.131864 loss)
I0916 21:43:06.407089 13570 sgd_solver.cpp:136] Iteration 22500, lr = 0.01, m = 0.9
I0916 21:43:25.668467 13570 solver.cpp:314] Iteration 22600 (5.19186 iter/s, 19.2609s/100 iter), loss = 0.0603681
I0916 21:43:25.668490 13570 solver.cpp:336]     Train net output #0: loss = 0.060368 (* 1 = 0.060368 loss)
I0916 21:43:25.668495 13570 sgd_solver.cpp:136] Iteration 22600, lr = 0.01, m = 0.9
I0916 21:43:33.326316 13576 data_reader.cpp:305] Starting prefetch of epoch 17
I0916 21:43:44.834463 13570 solver.cpp:314] Iteration 22700 (5.21772 iter/s, 19.1655s/100 iter), loss = 0.0834207
I0916 21:43:44.834518 13570 solver.cpp:336]     Train net output #0: loss = 0.0834206 (* 1 = 0.0834206 loss)
I0916 21:43:44.834523 13570 sgd_solver.cpp:136] Iteration 22700, lr = 0.01, m = 0.9
I0916 21:44:03.909570 13570 solver.cpp:314] Iteration 22800 (5.24258 iter/s, 19.0746s/100 iter), loss = 0.0445609
I0916 21:44:03.909596 13570 solver.cpp:336]     Train net output #0: loss = 0.0445608 (* 1 = 0.0445608 loss)
I0916 21:44:03.909602 13570 sgd_solver.cpp:136] Iteration 22800, lr = 0.01, m = 0.9
I0916 21:44:04.941170 13544 data_reader.cpp:305] Starting prefetch of epoch 17
I0916 21:44:23.108906 13570 solver.cpp:314] Iteration 22900 (5.20866 iter/s, 19.1988s/100 iter), loss = 0.0653097
I0916 21:44:23.108990 13570 solver.cpp:336]     Train net output #0: loss = 0.0653096 (* 1 = 0.0653096 loss)
I0916 21:44:23.108999 13570 sgd_solver.cpp:136] Iteration 22900, lr = 0.01, m = 0.9
I0916 21:44:41.995472 13570 solver.cpp:368] Sparsity after update:
I0916 21:44:42.013306 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 21:44:42.013330 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 21:44:42.013340 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 21:44:42.013344 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 21:44:42.013346 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 21:44:42.013368 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 21:44:42.013382 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 21:44:42.013392 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 21:44:42.013401 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 21:44:42.013408 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 21:44:42.013417 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 21:44:42.013422 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 21:44:42.013425 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 21:44:42.013433 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 21:44:42.013444 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 21:44:42.013449 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 21:44:42.013453 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 21:44:42.013461 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 21:44:42.013470 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 21:44:42.185396 13570 solver.cpp:314] Iteration 23000 (5.2422 iter/s, 19.076s/100 iter), loss = 0.0919014
I0916 21:44:42.185425 13570 solver.cpp:336]     Train net output #0: loss = 0.0919013 (* 1 = 0.0919013 loss)
I0916 21:44:42.185432 13570 sgd_solver.cpp:136] Iteration 23000, lr = 0.01, m = 0.9
I0916 21:45:01.338862 13570 solver.cpp:314] Iteration 23100 (5.22113 iter/s, 19.1529s/100 iter), loss = 0.0721674
I0916 21:45:01.338935 13570 solver.cpp:336]     Train net output #0: loss = 0.0721672 (* 1 = 0.0721672 loss)
I0916 21:45:01.338943 13570 sgd_solver.cpp:136] Iteration 23100, lr = 0.01, m = 0.9
I0916 21:45:08.221801 13574 data_reader.cpp:305] Starting prefetch of epoch 16
I0916 21:45:20.845337 13570 solver.cpp:314] Iteration 23200 (5.12665 iter/s, 19.5059s/100 iter), loss = 0.05273
I0916 21:45:20.845366 13570 solver.cpp:336]     Train net output #0: loss = 0.0527298 (* 1 = 0.0527298 loss)
I0916 21:45:20.845373 13570 sgd_solver.cpp:136] Iteration 23200, lr = 0.01, m = 0.9
I0916 21:45:40.041214 13570 solver.cpp:314] Iteration 23300 (5.2096 iter/s, 19.1953s/100 iter), loss = 0.0457525
I0916 21:45:40.041265 13570 solver.cpp:336]     Train net output #0: loss = 0.0457524 (* 1 = 0.0457524 loss)
I0916 21:45:40.041271 13570 sgd_solver.cpp:136] Iteration 23300, lr = 0.01, m = 0.9
I0916 21:45:59.289955 13570 solver.cpp:314] Iteration 23400 (5.19529 iter/s, 19.2482s/100 iter), loss = 0.0547238
I0916 21:45:59.289981 13570 solver.cpp:336]     Train net output #0: loss = 0.0547237 (* 1 = 0.0547237 loss)
I0916 21:45:59.289988 13570 sgd_solver.cpp:136] Iteration 23400, lr = 0.01, m = 0.9
I0916 21:46:11.885146 13578 data_reader.cpp:305] Starting prefetch of epoch 13
I0916 21:46:18.370645 13570 solver.cpp:314] Iteration 23500 (5.24105 iter/s, 19.0802s/100 iter), loss = 0.224558
I0916 21:46:18.370668 13570 solver.cpp:336]     Train net output #0: loss = 0.224558 (* 1 = 0.224558 loss)
I0916 21:46:18.370674 13570 sgd_solver.cpp:136] Iteration 23500, lr = 0.01, m = 0.9
I0916 21:46:37.618578 13570 solver.cpp:314] Iteration 23600 (5.19551 iter/s, 19.2474s/100 iter), loss = 0.0491775
I0916 21:46:37.618600 13570 solver.cpp:336]     Train net output #0: loss = 0.0491774 (* 1 = 0.0491774 loss)
I0916 21:46:37.618604 13570 sgd_solver.cpp:136] Iteration 23600, lr = 0.01, m = 0.9
I0916 21:46:43.604910 13574 data_reader.cpp:305] Starting prefetch of epoch 17
I0916 21:46:56.746809 13570 solver.cpp:314] Iteration 23700 (5.22802 iter/s, 19.1277s/100 iter), loss = 0.0639243
I0916 21:46:56.746836 13570 solver.cpp:336]     Train net output #0: loss = 0.0639242 (* 1 = 0.0639242 loss)
I0916 21:46:56.746843 13570 sgd_solver.cpp:136] Iteration 23700, lr = 0.01, m = 0.9
I0916 21:47:15.655366 13570 solver.cpp:314] Iteration 23800 (5.28876 iter/s, 18.908s/100 iter), loss = 0.106715
I0916 21:47:15.655419 13570 solver.cpp:336]     Train net output #0: loss = 0.106714 (* 1 = 0.106714 loss)
I0916 21:47:15.655423 13570 sgd_solver.cpp:136] Iteration 23800, lr = 0.01, m = 0.9
I0916 21:47:34.789366 13570 solver.cpp:314] Iteration 23900 (5.22644 iter/s, 19.1335s/100 iter), loss = 0.0650351
I0916 21:47:34.789392 13570 solver.cpp:336]     Train net output #0: loss = 0.0650351 (* 1 = 0.0650351 loss)
I0916 21:47:34.789398 13570 sgd_solver.cpp:136] Iteration 23900, lr = 0.01, m = 0.9
I0916 21:47:46.732476 13573 data_reader.cpp:305] Starting prefetch of epoch 13
I0916 21:47:53.727329 13570 solver.cpp:368] Sparsity after update:
I0916 21:47:53.733700 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 21:47:53.733710 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 21:47:53.733718 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 21:47:53.733722 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 21:47:53.733734 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 21:47:53.733748 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 21:47:53.733754 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 21:47:53.733758 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 21:47:53.733767 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 21:47:53.733777 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 21:47:53.733781 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 21:47:53.733785 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 21:47:53.733793 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 21:47:53.733798 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 21:47:53.733803 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 21:47:53.733805 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 21:47:53.733809 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 21:47:53.733817 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 21:47:53.733822 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 21:47:53.733839 13570 solver.cpp:563] Iteration 24000, Testing net (#0)
I0916 21:48:12.211954 13594 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 21:48:12.554628 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.951081
I0916 21:48:12.554647 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 21:48:12.554652 13570 solver.cpp:655]     Test net output #2: loss = 0.142625 (* 1 = 0.142625 loss)
I0916 21:48:12.554687 13570 solver.cpp:265] [MultiGPU] Tests completed in 18.8203s
I0916 21:48:12.762351 13570 solver.cpp:314] Iteration 24000 (2.63352 iter/s, 37.9719s/100 iter), loss = 0.0680527
I0916 21:48:12.762382 13570 solver.cpp:336]     Train net output #0: loss = 0.0680526 (* 1 = 0.0680526 loss)
I0916 21:48:12.762388 13570 sgd_solver.cpp:136] Iteration 24000, lr = 0.01, m = 0.9
I0916 21:48:31.795590 13570 solver.cpp:314] Iteration 24100 (5.25411 iter/s, 19.0327s/100 iter), loss = 0.0882601
I0916 21:48:31.795691 13570 solver.cpp:336]     Train net output #0: loss = 0.08826 (* 1 = 0.08826 loss)
I0916 21:48:31.795703 13570 sgd_solver.cpp:136] Iteration 24100, lr = 0.01, m = 0.9
I0916 21:48:50.904335 13570 solver.cpp:314] Iteration 24200 (5.23335 iter/s, 19.1082s/100 iter), loss = 0.208525
I0916 21:48:50.904371 13570 solver.cpp:336]     Train net output #0: loss = 0.208525 (* 1 = 0.208525 loss)
I0916 21:48:50.904376 13570 sgd_solver.cpp:136] Iteration 24200, lr = 0.01, m = 0.9
I0916 21:49:08.606747 13546 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 21:49:10.130388 13570 solver.cpp:314] Iteration 24300 (5.20142 iter/s, 19.2255s/100 iter), loss = 0.053348
I0916 21:49:10.130414 13570 solver.cpp:336]     Train net output #0: loss = 0.0533479 (* 1 = 0.0533479 loss)
I0916 21:49:10.130419 13570 sgd_solver.cpp:136] Iteration 24300, lr = 0.01, m = 0.9
I0916 21:49:29.229533 13570 solver.cpp:314] Iteration 24400 (5.23598 iter/s, 19.0986s/100 iter), loss = 0.0725523
I0916 21:49:29.229562 13570 solver.cpp:336]     Train net output #0: loss = 0.0725522 (* 1 = 0.0725522 loss)
I0916 21:49:29.229569 13570 sgd_solver.cpp:136] Iteration 24400, lr = 0.01, m = 0.9
I0916 21:49:40.523046 13573 data_reader.cpp:305] Starting prefetch of epoch 14
I0916 21:49:48.425725 13570 solver.cpp:314] Iteration 24500 (5.20951 iter/s, 19.1957s/100 iter), loss = 0.0479609
I0916 21:49:48.425747 13570 solver.cpp:336]     Train net output #0: loss = 0.0479607 (* 1 = 0.0479607 loss)
I0916 21:49:48.425751 13570 sgd_solver.cpp:136] Iteration 24500, lr = 0.01, m = 0.9
I0916 21:50:07.323480 13570 solver.cpp:314] Iteration 24600 (5.29178 iter/s, 18.8972s/100 iter), loss = 0.0959472
I0916 21:50:07.323509 13570 solver.cpp:336]     Train net output #0: loss = 0.0959471 (* 1 = 0.0959471 loss)
I0916 21:50:07.323516 13570 sgd_solver.cpp:136] Iteration 24600, lr = 0.01, m = 0.9
I0916 21:50:26.363586 13570 solver.cpp:314] Iteration 24700 (5.25222 iter/s, 19.0396s/100 iter), loss = 0.0558342
I0916 21:50:26.363644 13570 solver.cpp:336]     Train net output #0: loss = 0.055834 (* 1 = 0.055834 loss)
I0916 21:50:26.363651 13570 sgd_solver.cpp:136] Iteration 24700, lr = 0.01, m = 0.9
I0916 21:50:43.159019 13573 data_reader.cpp:305] Starting prefetch of epoch 15
I0916 21:50:45.467906 13570 solver.cpp:314] Iteration 24800 (5.23456 iter/s, 19.1038s/100 iter), loss = 0.0738396
I0916 21:50:45.467931 13570 solver.cpp:336]     Train net output #0: loss = 0.0738394 (* 1 = 0.0738394 loss)
I0916 21:50:45.467937 13570 sgd_solver.cpp:136] Iteration 24800, lr = 0.01, m = 0.9
I0916 21:51:04.645314 13570 solver.cpp:314] Iteration 24900 (5.21461 iter/s, 19.1769s/100 iter), loss = 0.0624406
I0916 21:51:04.645390 13570 solver.cpp:336]     Train net output #0: loss = 0.0624404 (* 1 = 0.0624404 loss)
I0916 21:51:04.645397 13570 sgd_solver.cpp:136] Iteration 24900, lr = 0.01, m = 0.9
I0916 21:51:23.746367 13570 solver.cpp:368] Sparsity after update:
I0916 21:51:23.771594 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 21:51:23.771608 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 21:51:23.771615 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 21:51:23.771616 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 21:51:23.771618 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 21:51:23.771620 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 21:51:23.771622 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 21:51:23.771625 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 21:51:23.771625 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 21:51:23.771627 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 21:51:23.771630 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 21:51:23.771631 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 21:51:23.771633 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 21:51:23.771636 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 21:51:23.771637 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 21:51:23.771639 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 21:51:23.771641 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 21:51:23.771643 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 21:51:23.771644 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 21:51:23.942112 13570 solver.cpp:314] Iteration 25000 (5.18235 iter/s, 19.2963s/100 iter), loss = 0.0798817
I0916 21:51:23.942139 13570 solver.cpp:336]     Train net output #0: loss = 0.0798816 (* 1 = 0.0798816 loss)
I0916 21:51:23.942144 13570 sgd_solver.cpp:136] Iteration 25000, lr = 0.01, m = 0.9
I0916 21:51:43.215754 13570 solver.cpp:314] Iteration 25100 (5.18858 iter/s, 19.2731s/100 iter), loss = 0.0627536
I0916 21:51:43.215839 13570 solver.cpp:336]     Train net output #0: loss = 0.0627535 (* 1 = 0.0627535 loss)
I0916 21:51:43.215847 13570 sgd_solver.cpp:136] Iteration 25100, lr = 0.01, m = 0.9
I0916 21:51:46.921615 13576 data_reader.cpp:305] Starting prefetch of epoch 18
I0916 21:52:02.643704 13570 solver.cpp:314] Iteration 25200 (5.14737 iter/s, 19.4274s/100 iter), loss = 0.080083
I0916 21:52:02.643728 13570 solver.cpp:336]     Train net output #0: loss = 0.0800828 (* 1 = 0.0800828 loss)
I0916 21:52:02.643733 13570 sgd_solver.cpp:136] Iteration 25200, lr = 0.01, m = 0.9
I0916 21:52:18.585271 13544 data_reader.cpp:305] Starting prefetch of epoch 18
I0916 21:52:21.577838 13570 solver.cpp:314] Iteration 25300 (5.28161 iter/s, 18.9336s/100 iter), loss = 0.0655013
I0916 21:52:21.577888 13570 solver.cpp:336]     Train net output #0: loss = 0.0655012 (* 1 = 0.0655012 loss)
I0916 21:52:21.577901 13570 sgd_solver.cpp:136] Iteration 25300, lr = 0.01, m = 0.9
I0916 21:52:40.883590 13570 solver.cpp:314] Iteration 25400 (5.17995 iter/s, 19.3052s/100 iter), loss = 0.0809528
I0916 21:52:40.883618 13570 solver.cpp:336]     Train net output #0: loss = 0.0809527 (* 1 = 0.0809527 loss)
I0916 21:52:40.883625 13570 sgd_solver.cpp:136] Iteration 25400, lr = 0.01, m = 0.9
I0916 21:53:00.165405 13570 solver.cpp:314] Iteration 25500 (5.18638 iter/s, 19.2813s/100 iter), loss = 0.0560368
I0916 21:53:00.165460 13570 solver.cpp:336]     Train net output #0: loss = 0.0560367 (* 1 = 0.0560367 loss)
I0916 21:53:00.165467 13570 sgd_solver.cpp:136] Iteration 25500, lr = 0.01, m = 0.9
I0916 21:53:19.388522 13570 solver.cpp:314] Iteration 25600 (5.20221 iter/s, 19.2226s/100 iter), loss = 0.0708832
I0916 21:53:19.388551 13570 solver.cpp:336]     Train net output #0: loss = 0.0708831 (* 1 = 0.0708831 loss)
I0916 21:53:19.388558 13570 sgd_solver.cpp:136] Iteration 25600, lr = 0.01, m = 0.9
I0916 21:53:22.241274 13573 data_reader.cpp:305] Starting prefetch of epoch 16
I0916 21:53:38.468493 13570 solver.cpp:314] Iteration 25700 (5.24124 iter/s, 19.0794s/100 iter), loss = 0.0466765
I0916 21:53:38.468605 13570 solver.cpp:336]     Train net output #0: loss = 0.0466764 (* 1 = 0.0466764 loss)
I0916 21:53:38.468612 13570 sgd_solver.cpp:136] Iteration 25700, lr = 0.01, m = 0.9
I0916 21:53:57.634166 13570 solver.cpp:314] Iteration 25800 (5.21781 iter/s, 19.1651s/100 iter), loss = 0.0648972
I0916 21:53:57.634189 13570 solver.cpp:336]     Train net output #0: loss = 0.0648971 (* 1 = 0.0648971 loss)
I0916 21:53:57.634194 13570 sgd_solver.cpp:136] Iteration 25800, lr = 0.01, m = 0.9
I0916 21:54:16.839838 13570 solver.cpp:314] Iteration 25900 (5.20694 iter/s, 19.2051s/100 iter), loss = 0.0485559
I0916 21:54:16.839887 13570 solver.cpp:336]     Train net output #0: loss = 0.0485558 (* 1 = 0.0485558 loss)
I0916 21:54:16.839893 13570 sgd_solver.cpp:136] Iteration 25900, lr = 0.01, m = 0.9
I0916 21:54:25.490916 13576 data_reader.cpp:305] Starting prefetch of epoch 19
I0916 21:54:35.947676 13570 solver.cpp:368] Sparsity after update:
I0916 21:54:35.953603 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 21:54:35.953613 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 21:54:35.953621 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 21:54:35.953634 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 21:54:35.953642 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 21:54:35.953651 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 21:54:35.953661 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 21:54:35.953671 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 21:54:35.953682 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 21:54:35.953688 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 21:54:35.953696 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 21:54:35.953707 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 21:54:35.953712 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 21:54:35.953716 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 21:54:35.953723 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 21:54:35.953732 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 21:54:35.953742 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 21:54:35.953749 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 21:54:35.953758 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 21:54:35.953771 13570 solver.cpp:563] Iteration 26000, Testing net (#0)
I0916 21:54:47.971915 13566 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 21:54:51.984083 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.954274
I0916 21:54:51.984104 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 21:54:51.984109 13570 solver.cpp:655]     Test net output #2: loss = 0.157197 (* 1 = 0.157197 loss)
I0916 21:54:51.984128 13570 solver.cpp:265] [MultiGPU] Tests completed in 16.0299s
I0916 21:54:52.199852 13570 solver.cpp:314] Iteration 26000 (2.82813 iter/s, 35.359s/100 iter), loss = 0.0837243
I0916 21:54:52.199874 13570 solver.cpp:336]     Train net output #0: loss = 0.0837242 (* 1 = 0.0837242 loss)
I0916 21:54:52.199880 13570 sgd_solver.cpp:136] Iteration 26000, lr = 0.01, m = 0.9
I0916 21:55:11.005833 13570 solver.cpp:314] Iteration 26100 (5.31761 iter/s, 18.8055s/100 iter), loss = 0.0490528
I0916 21:55:11.005859 13570 solver.cpp:336]     Train net output #0: loss = 0.0490527 (* 1 = 0.0490527 loss)
I0916 21:55:11.005866 13570 sgd_solver.cpp:136] Iteration 26100, lr = 0.01, m = 0.9
I0916 21:55:30.242089 13570 solver.cpp:314] Iteration 26200 (5.19866 iter/s, 19.2357s/100 iter), loss = 0.086788
I0916 21:55:30.242147 13570 solver.cpp:336]     Train net output #0: loss = 0.0867879 (* 1 = 0.0867879 loss)
I0916 21:55:30.242152 13570 sgd_solver.cpp:136] Iteration 26200, lr = 0.01, m = 0.9
I0916 21:55:44.931910 13574 data_reader.cpp:305] Starting prefetch of epoch 18
I0916 21:55:49.457084 13570 solver.cpp:314] Iteration 26300 (5.20441 iter/s, 19.2145s/100 iter), loss = 0.0636526
I0916 21:55:49.457108 13570 solver.cpp:336]     Train net output #0: loss = 0.0636525 (* 1 = 0.0636525 loss)
I0916 21:55:49.457111 13570 sgd_solver.cpp:136] Iteration 26300, lr = 0.01, m = 0.9
I0916 21:56:08.643487 13570 solver.cpp:314] Iteration 26400 (5.21217 iter/s, 19.1859s/100 iter), loss = 0.0878349
I0916 21:56:08.643566 13570 solver.cpp:336]     Train net output #0: loss = 0.0878348 (* 1 = 0.0878348 loss)
I0916 21:56:08.643573 13570 sgd_solver.cpp:136] Iteration 26400, lr = 0.01, m = 0.9
I0916 21:56:27.849926 13570 solver.cpp:314] Iteration 26500 (5.20673 iter/s, 19.2059s/100 iter), loss = 0.0516267
I0916 21:56:27.849956 13570 solver.cpp:336]     Train net output #0: loss = 0.0516265 (* 1 = 0.0516265 loss)
I0916 21:56:27.849961 13570 sgd_solver.cpp:136] Iteration 26500, lr = 0.01, m = 0.9
I0916 21:56:46.870296 13570 solver.cpp:314] Iteration 26600 (5.25767 iter/s, 19.0198s/100 iter), loss = 0.0767204
I0916 21:56:46.870355 13570 solver.cpp:336]     Train net output #0: loss = 0.0767203 (* 1 = 0.0767203 loss)
I0916 21:56:46.870362 13570 sgd_solver.cpp:136] Iteration 26600, lr = 0.01, m = 0.9
I0916 21:56:48.040565 13578 data_reader.cpp:305] Starting prefetch of epoch 14
I0916 21:57:05.723798 13570 solver.cpp:314] Iteration 26700 (5.3042 iter/s, 18.853s/100 iter), loss = 0.0551436
I0916 21:57:05.723822 13570 solver.cpp:336]     Train net output #0: loss = 0.0551435 (* 1 = 0.0551435 loss)
I0916 21:57:05.723827 13570 sgd_solver.cpp:136] Iteration 26700, lr = 0.01, m = 0.9
I0916 21:57:19.131091 13573 data_reader.cpp:305] Starting prefetch of epoch 17
I0916 21:57:24.689271 13570 solver.cpp:314] Iteration 26800 (5.27289 iter/s, 18.9649s/100 iter), loss = 0.0956385
I0916 21:57:24.689298 13570 solver.cpp:336]     Train net output #0: loss = 0.0956383 (* 1 = 0.0956383 loss)
I0916 21:57:24.689304 13570 sgd_solver.cpp:136] Iteration 26800, lr = 0.01, m = 0.9
I0916 21:57:43.904880 13570 solver.cpp:314] Iteration 26900 (5.20425 iter/s, 19.2151s/100 iter), loss = 0.0544619
I0916 21:57:43.904902 13570 solver.cpp:336]     Train net output #0: loss = 0.0544617 (* 1 = 0.0544617 loss)
I0916 21:57:43.904906 13570 sgd_solver.cpp:136] Iteration 26900, lr = 0.01, m = 0.9
I0916 21:58:02.909230 13570 solver.cpp:368] Sparsity after update:
I0916 21:58:02.928885 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 21:58:02.928903 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 21:58:02.928913 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 21:58:02.928916 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 21:58:02.928920 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 21:58:02.928922 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 21:58:02.928926 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 21:58:02.928930 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 21:58:02.928935 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 21:58:02.928938 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 21:58:02.928942 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 21:58:02.928946 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 21:58:02.928949 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 21:58:02.928963 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 21:58:02.928967 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 21:58:02.928970 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 21:58:02.928973 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 21:58:02.928977 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 21:58:02.928979 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 21:58:03.101550 13570 solver.cpp:314] Iteration 27000 (5.20938 iter/s, 19.1961s/100 iter), loss = 0.127998
I0916 21:58:03.101572 13570 solver.cpp:336]     Train net output #0: loss = 0.127998 (* 1 = 0.127998 loss)
I0916 21:58:03.101578 13570 sgd_solver.cpp:136] Iteration 27000, lr = 0.01, m = 0.9
I0916 21:58:22.198768 13570 solver.cpp:314] Iteration 27100 (5.23651 iter/s, 19.0967s/100 iter), loss = 0.0706217
I0916 21:58:22.198792 13570 solver.cpp:336]     Train net output #0: loss = 0.0706216 (* 1 = 0.0706216 loss)
I0916 21:58:22.198796 13570 sgd_solver.cpp:136] Iteration 27100, lr = 0.01, m = 0.9
I0916 21:58:22.610453 13574 data_reader.cpp:305] Starting prefetch of epoch 19
I0916 21:58:41.060063 13570 solver.cpp:314] Iteration 27200 (5.30201 iter/s, 18.8608s/100 iter), loss = 0.0427336
I0916 21:58:41.060138 13570 solver.cpp:336]     Train net output #0: loss = 0.0427335 (* 1 = 0.0427335 loss)
I0916 21:58:41.060144 13570 sgd_solver.cpp:136] Iteration 27200, lr = 0.01, m = 0.9
I0916 21:59:00.267905 13570 solver.cpp:314] Iteration 27300 (5.20636 iter/s, 19.2073s/100 iter), loss = 0.0638019
I0916 21:59:00.267958 13570 solver.cpp:336]     Train net output #0: loss = 0.0638018 (* 1 = 0.0638018 loss)
I0916 21:59:00.267973 13570 sgd_solver.cpp:136] Iteration 27300, lr = 0.01, m = 0.9
I0916 21:59:19.436167 13570 solver.cpp:314] Iteration 27400 (5.2171 iter/s, 19.1677s/100 iter), loss = 0.138298
I0916 21:59:19.436269 13570 solver.cpp:336]     Train net output #0: loss = 0.138298 (* 1 = 0.138298 loss)
I0916 21:59:19.436276 13570 sgd_solver.cpp:136] Iteration 27400, lr = 0.01, m = 0.9
I0916 21:59:25.692271 13578 data_reader.cpp:305] Starting prefetch of epoch 15
I0916 21:59:38.637157 13570 solver.cpp:314] Iteration 27500 (5.20821 iter/s, 19.2005s/100 iter), loss = 0.0588674
I0916 21:59:38.637182 13570 solver.cpp:336]     Train net output #0: loss = 0.0588672 (* 1 = 0.0588672 loss)
I0916 21:59:38.637187 13570 sgd_solver.cpp:136] Iteration 27500, lr = 0.01, m = 0.9
I0916 21:59:57.576212 13544 data_reader.cpp:305] Starting prefetch of epoch 19
I0916 21:59:57.907987 13570 solver.cpp:314] Iteration 27600 (5.18933 iter/s, 19.2703s/100 iter), loss = 0.0782802
I0916 21:59:57.908012 13570 solver.cpp:336]     Train net output #0: loss = 0.0782801 (* 1 = 0.0782801 loss)
I0916 21:59:57.908018 13570 sgd_solver.cpp:136] Iteration 27600, lr = 0.01, m = 0.9
I0916 22:00:16.948281 13570 solver.cpp:314] Iteration 27700 (5.25217 iter/s, 19.0398s/100 iter), loss = 0.0938956
I0916 22:00:16.948307 13570 solver.cpp:336]     Train net output #0: loss = 0.0938955 (* 1 = 0.0938955 loss)
I0916 22:00:16.948314 13570 sgd_solver.cpp:136] Iteration 27700, lr = 0.01, m = 0.9
I0916 22:00:36.203696 13570 solver.cpp:314] Iteration 27800 (5.19349 iter/s, 19.2549s/100 iter), loss = 0.042848
I0916 22:00:36.203749 13570 solver.cpp:336]     Train net output #0: loss = 0.0428479 (* 1 = 0.0428479 loss)
I0916 22:00:36.203754 13570 sgd_solver.cpp:136] Iteration 27800, lr = 0.01, m = 0.9
I0916 22:00:55.266743 13570 solver.cpp:314] Iteration 27900 (5.2459 iter/s, 19.0625s/100 iter), loss = 0.066426
I0916 22:00:55.266768 13570 solver.cpp:336]     Train net output #0: loss = 0.0664259 (* 1 = 0.0664259 loss)
I0916 22:00:55.266775 13570 sgd_solver.cpp:136] Iteration 27900, lr = 0.01, m = 0.9
I0916 22:01:00.658792 13573 data_reader.cpp:305] Starting prefetch of epoch 18
I0916 22:01:14.298081 13570 solver.cpp:368] Sparsity after update:
I0916 22:01:14.305264 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 22:01:14.305275 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 22:01:14.305284 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 22:01:14.305292 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 22:01:14.305296 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 22:01:14.305300 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 22:01:14.305304 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 22:01:14.305306 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 22:01:14.305310 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 22:01:14.305312 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 22:01:14.305315 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 22:01:14.305320 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 22:01:14.305322 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 22:01:14.305325 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 22:01:14.305328 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 22:01:14.305331 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 22:01:14.305335 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 22:01:14.305337 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 22:01:14.305341 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 22:01:14.305351 13570 solver.cpp:563] Iteration 28000, Testing net (#0)
I0916 22:01:30.308620 13566 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 22:01:30.700562 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.947207
I0916 22:01:30.700584 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 22:01:30.700589 13570 solver.cpp:655]     Test net output #2: loss = 0.154768 (* 1 = 0.154768 loss)
I0916 22:01:30.700620 13570 solver.cpp:265] [MultiGPU] Tests completed in 16.3948s
I0916 22:01:30.901274 13570 solver.cpp:314] Iteration 28000 (2.80634 iter/s, 35.6336s/100 iter), loss = 0.0797404
I0916 22:01:30.901300 13570 solver.cpp:336]     Train net output #0: loss = 0.0797403 (* 1 = 0.0797403 loss)
I0916 22:01:30.901305 13570 sgd_solver.cpp:136] Iteration 28000, lr = 0.01, m = 0.9
I0916 22:01:48.713807 13544 data_reader.cpp:305] Starting prefetch of epoch 20
I0916 22:01:49.859357 13570 solver.cpp:314] Iteration 28100 (5.27494 iter/s, 18.9576s/100 iter), loss = 0.0824409
I0916 22:01:49.859381 13570 solver.cpp:336]     Train net output #0: loss = 0.0824408 (* 1 = 0.0824408 loss)
I0916 22:01:49.859385 13570 sgd_solver.cpp:136] Iteration 28100, lr = 0.01, m = 0.9
I0916 22:02:08.909940 13570 solver.cpp:314] Iteration 28200 (5.24933 iter/s, 19.0501s/100 iter), loss = 0.0833704
I0916 22:02:08.909965 13570 solver.cpp:336]     Train net output #0: loss = 0.0833703 (* 1 = 0.0833703 loss)
I0916 22:02:08.909970 13570 sgd_solver.cpp:136] Iteration 28200, lr = 0.01, m = 0.9
I0916 22:02:28.048269 13570 solver.cpp:314] Iteration 28300 (5.22526 iter/s, 19.1378s/100 iter), loss = 0.0572312
I0916 22:02:28.048321 13570 solver.cpp:336]     Train net output #0: loss = 0.0572311 (* 1 = 0.0572311 loss)
I0916 22:02:28.048326 13570 sgd_solver.cpp:136] Iteration 28300, lr = 0.01, m = 0.9
I0916 22:02:47.368734 13570 solver.cpp:314] Iteration 28400 (5.176 iter/s, 19.3199s/100 iter), loss = 0.0768875
I0916 22:02:47.368760 13570 solver.cpp:336]     Train net output #0: loss = 0.0768874 (* 1 = 0.0768874 loss)
I0916 22:02:47.368767 13570 sgd_solver.cpp:136] Iteration 28400, lr = 0.01, m = 0.9
I0916 22:02:52.001020 13573 data_reader.cpp:305] Starting prefetch of epoch 19
I0916 22:03:06.417215 13570 solver.cpp:314] Iteration 28500 (5.24991 iter/s, 19.048s/100 iter), loss = 0.079399
I0916 22:03:06.417268 13570 solver.cpp:336]     Train net output #0: loss = 0.0793989 (* 1 = 0.0793989 loss)
I0916 22:03:06.417273 13570 sgd_solver.cpp:136] Iteration 28500, lr = 0.01, m = 0.9
I0916 22:03:25.746719 13570 solver.cpp:314] Iteration 28600 (5.17358 iter/s, 19.329s/100 iter), loss = 0.132582
I0916 22:03:25.746749 13570 solver.cpp:336]     Train net output #0: loss = 0.132582 (* 1 = 0.132582 loss)
I0916 22:03:25.746757 13570 sgd_solver.cpp:136] Iteration 28600, lr = 0.01, m = 0.9
I0916 22:03:45.076239 13570 solver.cpp:314] Iteration 28700 (5.17358 iter/s, 19.329s/100 iter), loss = 0.101226
I0916 22:03:45.076297 13570 solver.cpp:336]     Train net output #0: loss = 0.101226 (* 1 = 0.101226 loss)
I0916 22:03:45.076303 13570 sgd_solver.cpp:136] Iteration 28700, lr = 0.01, m = 0.9
I0916 22:03:55.520680 13578 data_reader.cpp:305] Starting prefetch of epoch 16
I0916 22:04:04.081390 13570 solver.cpp:314] Iteration 28800 (5.26188 iter/s, 19.0046s/100 iter), loss = 0.0604189
I0916 22:04:04.081411 13570 solver.cpp:336]     Train net output #0: loss = 0.0604188 (* 1 = 0.0604188 loss)
I0916 22:04:04.081415 13570 sgd_solver.cpp:136] Iteration 28800, lr = 0.01, m = 0.9
I0916 22:04:23.037956 13570 solver.cpp:314] Iteration 28900 (5.27536 iter/s, 18.956s/100 iter), loss = 0.139569
I0916 22:04:23.038008 13570 solver.cpp:336]     Train net output #0: loss = 0.139569 (* 1 = 0.139569 loss)
I0916 22:04:23.038012 13570 sgd_solver.cpp:136] Iteration 28900, lr = 0.01, m = 0.9
I0916 22:04:42.263219 13570 solver.cpp:368] Sparsity after update:
I0916 22:04:42.277962 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 22:04:42.277981 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 22:04:42.277988 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 22:04:42.277992 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 22:04:42.277994 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 22:04:42.277998 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 22:04:42.278002 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 22:04:42.278004 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 22:04:42.278007 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 22:04:42.278012 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 22:04:42.278017 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 22:04:42.278019 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 22:04:42.278023 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 22:04:42.278025 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 22:04:42.278028 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 22:04:42.278031 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 22:04:42.278034 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 22:04:42.278038 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 22:04:42.278041 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 22:04:42.458483 13570 solver.cpp:314] Iteration 29000 (5.14933 iter/s, 19.42s/100 iter), loss = 0.0658374
I0916 22:04:42.458505 13570 solver.cpp:336]     Train net output #0: loss = 0.0658373 (* 1 = 0.0658373 loss)
I0916 22:04:42.458509 13570 sgd_solver.cpp:136] Iteration 29000, lr = 0.01, m = 0.9
I0916 22:04:58.792340 13546 data_reader.cpp:305] Starting prefetch of epoch 10
I0916 22:05:01.537931 13570 solver.cpp:314] Iteration 29100 (5.24139 iter/s, 19.0789s/100 iter), loss = 0.0727181
I0916 22:05:01.537955 13570 solver.cpp:336]     Train net output #0: loss = 0.072718 (* 1 = 0.072718 loss)
I0916 22:05:01.537959 13570 sgd_solver.cpp:136] Iteration 29100, lr = 0.01, m = 0.9
I0916 22:05:20.775977 13570 solver.cpp:314] Iteration 29200 (5.19818 iter/s, 19.2375s/100 iter), loss = 0.0537239
I0916 22:05:20.776001 13570 solver.cpp:336]     Train net output #0: loss = 0.0537238 (* 1 = 0.0537238 loss)
I0916 22:05:20.776007 13570 sgd_solver.cpp:136] Iteration 29200, lr = 0.01, m = 0.9
I0916 22:05:30.432510 13573 data_reader.cpp:305] Starting prefetch of epoch 20
I0916 22:05:39.850898 13570 solver.cpp:314] Iteration 29300 (5.24263 iter/s, 19.0744s/100 iter), loss = 0.0524465
I0916 22:05:39.850922 13570 solver.cpp:336]     Train net output #0: loss = 0.0524464 (* 1 = 0.0524464 loss)
I0916 22:05:39.850926 13570 sgd_solver.cpp:136] Iteration 29300, lr = 0.01, m = 0.9
I0916 22:05:58.899166 13570 solver.cpp:314] Iteration 29400 (5.24997 iter/s, 19.0477s/100 iter), loss = 0.0575208
I0916 22:05:58.899194 13570 solver.cpp:336]     Train net output #0: loss = 0.0575208 (* 1 = 0.0575208 loss)
I0916 22:05:58.899199 13570 sgd_solver.cpp:136] Iteration 29400, lr = 0.01, m = 0.9
I0916 22:06:18.334082 13570 solver.cpp:314] Iteration 29500 (5.14552 iter/s, 19.4344s/100 iter), loss = 0.0959105
I0916 22:06:18.334139 13570 solver.cpp:336]     Train net output #0: loss = 0.0959104 (* 1 = 0.0959104 loss)
I0916 22:06:18.334146 13570 sgd_solver.cpp:136] Iteration 29500, lr = 0.01, m = 0.9
I0916 22:06:34.062237 13546 data_reader.cpp:305] Starting prefetch of epoch 11
I0916 22:06:37.621903 13570 solver.cpp:314] Iteration 29600 (5.18476 iter/s, 19.2873s/100 iter), loss = 0.06616
I0916 22:06:37.621925 13570 solver.cpp:336]     Train net output #0: loss = 0.0661599 (* 1 = 0.0661599 loss)
I0916 22:06:37.621930 13570 sgd_solver.cpp:136] Iteration 29600, lr = 0.01, m = 0.9
I0916 22:06:56.672991 13570 solver.cpp:314] Iteration 29700 (5.24919 iter/s, 19.0506s/100 iter), loss = 0.0592061
I0916 22:06:56.673040 13570 solver.cpp:336]     Train net output #0: loss = 0.059206 (* 1 = 0.059206 loss)
I0916 22:06:56.673044 13570 sgd_solver.cpp:136] Iteration 29700, lr = 0.01, m = 0.9
I0916 22:07:16.073288 13570 solver.cpp:314] Iteration 29800 (5.1547 iter/s, 19.3998s/100 iter), loss = 0.121634
I0916 22:07:16.073309 13570 solver.cpp:336]     Train net output #0: loss = 0.121634 (* 1 = 0.121634 loss)
I0916 22:07:16.073313 13570 sgd_solver.cpp:136] Iteration 29800, lr = 0.01, m = 0.9
I0916 22:07:35.531066 13570 solver.cpp:314] Iteration 29900 (5.13948 iter/s, 19.4572s/100 iter), loss = 0.0760968
I0916 22:07:35.531143 13570 solver.cpp:336]     Train net output #0: loss = 0.0760968 (* 1 = 0.0760968 loss)
I0916 22:07:35.531150 13570 sgd_solver.cpp:136] Iteration 29900, lr = 0.01, m = 0.9
I0916 22:07:37.832670 13578 data_reader.cpp:305] Starting prefetch of epoch 17
I0916 22:07:54.517983 13570 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/sparse/cityscapes5_jsegnet21v2_iter_30000.caffemodel
I0916 22:07:54.669529 13570 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/sparse/cityscapes5_jsegnet21v2_iter_30000.solverstate
I0916 22:07:54.679026 13570 solver.cpp:368] Sparsity after update:
I0916 22:07:54.686975 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 22:07:54.687021 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 22:07:54.687039 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 22:07:54.687052 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 22:07:54.687062 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 22:07:54.687073 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 22:07:54.687084 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 22:07:54.687095 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 22:07:54.687106 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 22:07:54.687117 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 22:07:54.687129 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 22:07:54.687140 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 22:07:54.687151 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 22:07:54.687162 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 22:07:54.687173 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 22:07:54.687185 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 22:07:54.687196 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 22:07:54.687206 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 22:07:54.687217 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 22:07:54.687238 13570 solver.cpp:563] Iteration 30000, Testing net (#0)
I0916 22:08:01.274153 13568 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 22:08:06.306603 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.952079
I0916 22:08:06.306705 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 22:08:06.306715 13570 solver.cpp:655]     Test net output #2: loss = 0.158065 (* 1 = 0.158065 loss)
I0916 22:08:06.306735 13570 solver.cpp:265] [MultiGPU] Tests completed in 11.6192s
I0916 22:08:06.422168 13625 sgd_solver.cpp:48] MultiStep Status: Iteration 30000, step = 1
I0916 22:08:06.422168 13623 sgd_solver.cpp:48] MultiStep Status: Iteration 30000, step = 1
I0916 22:08:06.422258 13624 sgd_solver.cpp:48] MultiStep Status: Iteration 30000, step = 1
I0916 22:08:06.516161 13570 solver.cpp:314] Iteration 30000 (3.22745 iter/s, 30.9842s/100 iter), loss = 0.109009
I0916 22:08:06.516189 13570 solver.cpp:336]     Train net output #0: loss = 0.109009 (* 1 = 0.109009 loss)
I0916 22:08:06.516193 13570 sgd_solver.cpp:136] Iteration 30000, lr = 0.001, m = 0.9
I0916 22:08:25.553102 13570 solver.cpp:314] Iteration 30100 (5.25309 iter/s, 19.0364s/100 iter), loss = 0.0573109
I0916 22:08:25.553135 13570 solver.cpp:336]     Train net output #0: loss = 0.0573108 (* 1 = 0.0573108 loss)
I0916 22:08:25.553141 13570 sgd_solver.cpp:136] Iteration 30100, lr = 0.001, m = 0.9
I0916 22:08:44.690786 13570 solver.cpp:314] Iteration 30200 (5.22544 iter/s, 19.1372s/100 iter), loss = 0.0645365
I0916 22:08:44.690865 13570 solver.cpp:336]     Train net output #0: loss = 0.0645365 (* 1 = 0.0645365 loss)
I0916 22:08:44.690872 13570 sgd_solver.cpp:136] Iteration 30200, lr = 0.001, m = 0.9
I0916 22:08:52.740566 13576 data_reader.cpp:305] Starting prefetch of epoch 20
I0916 22:09:04.000334 13570 solver.cpp:314] Iteration 30300 (5.17893 iter/s, 19.309s/100 iter), loss = 0.0777636
I0916 22:09:04.000357 13570 solver.cpp:336]     Train net output #0: loss = 0.0777635 (* 1 = 0.0777635 loss)
I0916 22:09:04.000362 13570 sgd_solver.cpp:136] Iteration 30300, lr = 0.001, m = 0.9
I0916 22:09:23.138027 13570 solver.cpp:314] Iteration 30400 (5.22544 iter/s, 19.1372s/100 iter), loss = 0.0703033
I0916 22:09:23.138140 13570 solver.cpp:336]     Train net output #0: loss = 0.0703032 (* 1 = 0.0703032 loss)
I0916 22:09:23.138147 13570 sgd_solver.cpp:136] Iteration 30400, lr = 0.001, m = 0.9
I0916 22:09:42.477707 13570 solver.cpp:314] Iteration 30500 (5.17086 iter/s, 19.3391s/100 iter), loss = 0.0921916
I0916 22:09:42.477738 13570 solver.cpp:336]     Train net output #0: loss = 0.0921915 (* 1 = 0.0921915 loss)
I0916 22:09:42.477744 13570 sgd_solver.cpp:136] Iteration 30500, lr = 0.001, m = 0.9
I0916 22:09:56.635658 13576 data_reader.cpp:305] Starting prefetch of epoch 21
I0916 22:10:01.787298 13570 solver.cpp:314] Iteration 30600 (5.17892 iter/s, 19.3091s/100 iter), loss = 0.0527453
I0916 22:10:01.787322 13570 solver.cpp:336]     Train net output #0: loss = 0.0527452 (* 1 = 0.0527452 loss)
I0916 22:10:01.787328 13570 sgd_solver.cpp:136] Iteration 30600, lr = 0.001, m = 0.9
I0916 22:10:21.262970 13570 solver.cpp:314] Iteration 30700 (5.13475 iter/s, 19.4751s/100 iter), loss = 0.156749
I0916 22:10:21.262994 13570 solver.cpp:336]     Train net output #0: loss = 0.156749 (* 1 = 0.156749 loss)
I0916 22:10:21.262997 13570 sgd_solver.cpp:136] Iteration 30700, lr = 0.001, m = 0.9
I0916 22:10:28.815296 13574 data_reader.cpp:305] Starting prefetch of epoch 20
I0916 22:10:40.777866 13570 solver.cpp:314] Iteration 30800 (5.12443 iter/s, 19.5144s/100 iter), loss = 0.0637417
I0916 22:10:40.777890 13570 solver.cpp:336]     Train net output #0: loss = 0.0637416 (* 1 = 0.0637416 loss)
I0916 22:10:40.777897 13570 sgd_solver.cpp:136] Iteration 30800, lr = 0.001, m = 0.9
I0916 22:11:00.301539 13570 solver.cpp:314] Iteration 30900 (5.12213 iter/s, 19.5231s/100 iter), loss = 0.0821883
I0916 22:11:00.301617 13570 solver.cpp:336]     Train net output #0: loss = 0.0821882 (* 1 = 0.0821882 loss)
I0916 22:11:00.301622 13570 sgd_solver.cpp:136] Iteration 30900, lr = 0.001, m = 0.9
I0916 22:11:19.292029 13570 solver.cpp:368] Sparsity after update:
I0916 22:11:19.307998 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 22:11:19.308019 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 22:11:19.308027 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 22:11:19.308032 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 22:11:19.308034 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 22:11:19.308059 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 22:11:19.308070 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 22:11:19.308079 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 22:11:19.308087 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 22:11:19.308096 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 22:11:19.308105 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 22:11:19.308113 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 22:11:19.308122 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 22:11:19.308130 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 22:11:19.308140 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 22:11:19.308147 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 22:11:19.308156 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 22:11:19.308164 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 22:11:19.308173 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 22:11:19.481791 13570 solver.cpp:314] Iteration 31000 (5.21384 iter/s, 19.1797s/100 iter), loss = 0.0538004
I0916 22:11:19.481817 13570 solver.cpp:336]     Train net output #0: loss = 0.0538003 (* 1 = 0.0538003 loss)
I0916 22:11:19.481824 13570 sgd_solver.cpp:136] Iteration 31000, lr = 0.001, m = 0.9
I0916 22:11:32.843065 13578 data_reader.cpp:305] Starting prefetch of epoch 18
I0916 22:11:38.839906 13570 solver.cpp:314] Iteration 31100 (5.16593 iter/s, 19.3576s/100 iter), loss = 0.0570479
I0916 22:11:38.839934 13570 solver.cpp:336]     Train net output #0: loss = 0.0570479 (* 1 = 0.0570479 loss)
I0916 22:11:38.839941 13570 sgd_solver.cpp:136] Iteration 31100, lr = 0.001, m = 0.9
I0916 22:11:58.223625 13570 solver.cpp:314] Iteration 31200 (5.15911 iter/s, 19.3832s/100 iter), loss = 0.124594
I0916 22:11:58.223647 13570 solver.cpp:336]     Train net output #0: loss = 0.124594 (* 1 = 0.124594 loss)
I0916 22:11:58.223652 13570 sgd_solver.cpp:136] Iteration 31200, lr = 0.001, m = 0.9
I0916 22:12:17.683639 13570 solver.cpp:314] Iteration 31300 (5.13889 iter/s, 19.4595s/100 iter), loss = 0.0962442
I0916 22:12:17.683753 13570 solver.cpp:336]     Train net output #0: loss = 0.0962442 (* 1 = 0.0962442 loss)
I0916 22:12:17.683761 13570 sgd_solver.cpp:136] Iteration 31300, lr = 0.001, m = 0.9
I0916 22:12:36.837079 13546 data_reader.cpp:305] Starting prefetch of epoch 12
I0916 22:12:37.010493 13570 solver.cpp:314] Iteration 31400 (5.17429 iter/s, 19.3263s/100 iter), loss = 0.0577421
I0916 22:12:37.010520 13570 solver.cpp:336]     Train net output #0: loss = 0.0577421 (* 1 = 0.0577421 loss)
I0916 22:12:37.010527 13570 sgd_solver.cpp:136] Iteration 31400, lr = 0.001, m = 0.9
I0916 22:12:56.582424 13570 solver.cpp:314] Iteration 31500 (5.1095 iter/s, 19.5714s/100 iter), loss = 0.0569322
I0916 22:12:56.582470 13570 solver.cpp:336]     Train net output #0: loss = 0.0569321 (* 1 = 0.0569321 loss)
I0916 22:12:56.582475 13570 sgd_solver.cpp:136] Iteration 31500, lr = 0.001, m = 0.9
I0916 22:13:15.951261 13570 solver.cpp:314] Iteration 31600 (5.16308 iter/s, 19.3683s/100 iter), loss = 0.204615
I0916 22:13:15.951287 13570 solver.cpp:336]     Train net output #0: loss = 0.204615 (* 1 = 0.204615 loss)
I0916 22:13:15.951294 13570 sgd_solver.cpp:136] Iteration 31600, lr = 0.001, m = 0.9
I0916 22:13:35.415802 13570 solver.cpp:314] Iteration 31700 (5.13769 iter/s, 19.464s/100 iter), loss = 0.0687517
I0916 22:13:35.415884 13570 solver.cpp:336]     Train net output #0: loss = 0.0687517 (* 1 = 0.0687517 loss)
I0916 22:13:35.415899 13570 sgd_solver.cpp:136] Iteration 31700, lr = 0.001, m = 0.9
I0916 22:13:41.267868 13578 data_reader.cpp:305] Starting prefetch of epoch 19
I0916 22:13:55.100805 13570 solver.cpp:314] Iteration 31800 (5.08015 iter/s, 19.6845s/100 iter), loss = 0.0714063
I0916 22:13:55.101091 13570 solver.cpp:336]     Train net output #0: loss = 0.0714062 (* 1 = 0.0714062 loss)
I0916 22:13:55.101234 13570 sgd_solver.cpp:136] Iteration 31800, lr = 0.001, m = 0.9
I0916 22:14:13.689108 13574 data_reader.cpp:305] Starting prefetch of epoch 21
I0916 22:14:14.581593 13570 solver.cpp:314] Iteration 31900 (5.13341 iter/s, 19.4802s/100 iter), loss = 0.0434854
I0916 22:14:14.581621 13570 solver.cpp:336]     Train net output #0: loss = 0.0434853 (* 1 = 0.0434853 loss)
I0916 22:14:14.581629 13570 sgd_solver.cpp:136] Iteration 31900, lr = 0.001, m = 0.9
I0916 22:14:33.629469 13570 solver.cpp:368] Sparsity after update:
I0916 22:14:33.634842 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 22:14:33.634850 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 22:14:33.634860 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 22:14:33.634865 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 22:14:33.634868 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 22:14:33.634872 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 22:14:33.634876 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 22:14:33.634881 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 22:14:33.634886 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 22:14:33.634889 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 22:14:33.634893 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 22:14:33.634897 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 22:14:33.634902 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 22:14:33.634905 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 22:14:33.634909 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 22:14:33.634912 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 22:14:33.634915 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 22:14:33.634919 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 22:14:33.634923 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 22:14:33.634934 13570 solver.cpp:563] Iteration 32000, Testing net (#0)
I0916 22:14:54.022379 13596 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 22:14:54.300158 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.949979
I0916 22:14:54.300176 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 22:14:54.300181 13570 solver.cpp:655]     Test net output #2: loss = 0.146839 (* 1 = 0.146839 loss)
I0916 22:14:54.300227 13570 solver.cpp:265] [MultiGPU] Tests completed in 20.6647s
I0916 22:14:54.509891 13570 solver.cpp:314] Iteration 32000 (2.50456 iter/s, 39.9272s/100 iter), loss = 0.0629731
I0916 22:14:54.509917 13570 solver.cpp:336]     Train net output #0: loss = 0.062973 (* 1 = 0.062973 loss)
I0916 22:14:54.509922 13570 sgd_solver.cpp:136] Iteration 32000, lr = 0.001, m = 0.9
I0916 22:15:13.475605 13570 solver.cpp:314] Iteration 32100 (5.27282 iter/s, 18.9652s/100 iter), loss = 0.088553
I0916 22:15:13.475633 13570 solver.cpp:336]     Train net output #0: loss = 0.0885529 (* 1 = 0.0885529 loss)
I0916 22:15:13.475641 13570 sgd_solver.cpp:136] Iteration 32100, lr = 0.001, m = 0.9
I0916 22:15:32.728597 13570 solver.cpp:314] Iteration 32200 (5.19414 iter/s, 19.2525s/100 iter), loss = 0.0626736
I0916 22:15:32.728653 13570 solver.cpp:336]     Train net output #0: loss = 0.0626736 (* 1 = 0.0626736 loss)
I0916 22:15:32.728659 13570 sgd_solver.cpp:136] Iteration 32200, lr = 0.001, m = 0.9
I0916 22:15:37.683387 13578 data_reader.cpp:305] Starting prefetch of epoch 20
I0916 22:15:51.862829 13570 solver.cpp:314] Iteration 32300 (5.22638 iter/s, 19.1337s/100 iter), loss = 0.0716631
I0916 22:15:51.862854 13570 solver.cpp:336]     Train net output #0: loss = 0.0716631 (* 1 = 0.0716631 loss)
I0916 22:15:51.862860 13570 sgd_solver.cpp:136] Iteration 32300, lr = 0.001, m = 0.9
I0916 22:16:09.333096 13573 data_reader.cpp:305] Starting prefetch of epoch 21
I0916 22:16:11.021448 13570 solver.cpp:314] Iteration 32400 (5.21973 iter/s, 19.1581s/100 iter), loss = 0.0603324
I0916 22:16:11.021473 13570 solver.cpp:336]     Train net output #0: loss = 0.0603324 (* 1 = 0.0603324 loss)
I0916 22:16:11.021479 13570 sgd_solver.cpp:136] Iteration 32400, lr = 0.001, m = 0.9
I0916 22:16:30.326645 13570 solver.cpp:314] Iteration 32500 (5.1801 iter/s, 19.3047s/100 iter), loss = 0.0622925
I0916 22:16:30.326665 13570 solver.cpp:336]     Train net output #0: loss = 0.0622924 (* 1 = 0.0622924 loss)
I0916 22:16:30.326669 13570 sgd_solver.cpp:136] Iteration 32500, lr = 0.001, m = 0.9
I0916 22:16:49.586149 13570 solver.cpp:314] Iteration 32600 (5.19239 iter/s, 19.259s/100 iter), loss = 0.0509195
I0916 22:16:49.586200 13570 solver.cpp:336]     Train net output #0: loss = 0.0509195 (* 1 = 0.0509195 loss)
I0916 22:16:49.586207 13570 sgd_solver.cpp:136] Iteration 32600, lr = 0.001, m = 0.9
I0916 22:17:08.849230 13570 solver.cpp:314] Iteration 32700 (5.19142 iter/s, 19.2625s/100 iter), loss = 0.0661896
I0916 22:17:08.849256 13570 solver.cpp:336]     Train net output #0: loss = 0.0661896 (* 1 = 0.0661896 loss)
I0916 22:17:08.849261 13570 sgd_solver.cpp:136] Iteration 32700, lr = 0.001, m = 0.9
I0916 22:17:12.930404 13576 data_reader.cpp:305] Starting prefetch of epoch 22
I0916 22:17:27.984524 13570 solver.cpp:314] Iteration 32800 (5.22609 iter/s, 19.1348s/100 iter), loss = 0.0752387
I0916 22:17:27.984577 13570 solver.cpp:336]     Train net output #0: loss = 0.0752387 (* 1 = 0.0752387 loss)
I0916 22:17:27.984585 13570 sgd_solver.cpp:136] Iteration 32800, lr = 0.001, m = 0.9
I0916 22:17:47.213838 13570 solver.cpp:314] Iteration 32900 (5.20054 iter/s, 19.2288s/100 iter), loss = 0.084101
I0916 22:17:47.213865 13570 solver.cpp:336]     Train net output #0: loss = 0.084101 (* 1 = 0.084101 loss)
I0916 22:17:47.213870 13570 sgd_solver.cpp:136] Iteration 32900, lr = 0.001, m = 0.9
I0916 22:18:06.254482 13570 solver.cpp:368] Sparsity after update:
I0916 22:18:06.261256 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 22:18:06.261265 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 22:18:06.261271 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 22:18:06.261273 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 22:18:06.261276 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 22:18:06.261277 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 22:18:06.261279 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 22:18:06.261281 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 22:18:06.261283 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 22:18:06.261286 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 22:18:06.261286 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 22:18:06.261288 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 22:18:06.261291 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 22:18:06.261292 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 22:18:06.261294 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 22:18:06.261296 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 22:18:06.261298 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 22:18:06.261301 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 22:18:06.261302 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 22:18:06.432219 13570 solver.cpp:314] Iteration 33000 (5.2035 iter/s, 19.2178s/100 iter), loss = 0.0690769
I0916 22:18:06.432240 13570 solver.cpp:336]     Train net output #0: loss = 0.0690769 (* 1 = 0.0690769 loss)
I0916 22:18:06.432245 13570 sgd_solver.cpp:136] Iteration 33000, lr = 0.001, m = 0.9
I0916 22:18:16.482007 13546 data_reader.cpp:305] Starting prefetch of epoch 13
I0916 22:18:25.831450 13570 solver.cpp:314] Iteration 33100 (5.15499 iter/s, 19.3987s/100 iter), loss = 0.0722062
I0916 22:18:25.831475 13570 solver.cpp:336]     Train net output #0: loss = 0.0722061 (* 1 = 0.0722061 loss)
I0916 22:18:25.831478 13570 sgd_solver.cpp:136] Iteration 33100, lr = 0.001, m = 0.9
I0916 22:18:45.340806 13570 solver.cpp:314] Iteration 33200 (5.12589 iter/s, 19.5088s/100 iter), loss = 0.0824262
I0916 22:18:45.340859 13570 solver.cpp:336]     Train net output #0: loss = 0.0824261 (* 1 = 0.0824261 loss)
I0916 22:18:45.340867 13570 sgd_solver.cpp:136] Iteration 33200, lr = 0.001, m = 0.9
I0916 22:18:48.800302 13544 data_reader.cpp:305] Starting prefetch of epoch 21
I0916 22:19:05.195701 13570 solver.cpp:314] Iteration 33300 (5.03668 iter/s, 19.8543s/100 iter), loss = 0.0741907
I0916 22:19:05.195726 13570 solver.cpp:336]     Train net output #0: loss = 0.0741907 (* 1 = 0.0741907 loss)
I0916 22:19:05.195732 13570 sgd_solver.cpp:136] Iteration 33300, lr = 0.001, m = 0.9
I0916 22:19:25.024016 13570 solver.cpp:314] Iteration 33400 (5.04343 iter/s, 19.8278s/100 iter), loss = 0.0555021
I0916 22:19:25.024068 13570 solver.cpp:336]     Train net output #0: loss = 0.055502 (* 1 = 0.055502 loss)
I0916 22:19:25.024075 13570 sgd_solver.cpp:136] Iteration 33400, lr = 0.001, m = 0.9
I0916 22:19:44.655642 13570 solver.cpp:314] Iteration 33500 (5.09396 iter/s, 19.6311s/100 iter), loss = 0.0722521
I0916 22:19:44.655664 13570 solver.cpp:336]     Train net output #0: loss = 0.072252 (* 1 = 0.072252 loss)
I0916 22:19:44.655668 13570 sgd_solver.cpp:136] Iteration 33500, lr = 0.001, m = 0.9
I0916 22:19:54.071991 13574 data_reader.cpp:305] Starting prefetch of epoch 22
I0916 22:20:04.397706 13570 solver.cpp:314] Iteration 33600 (5.06547 iter/s, 19.7415s/100 iter), loss = 0.0637757
I0916 22:20:04.397794 13570 solver.cpp:336]     Train net output #0: loss = 0.0637756 (* 1 = 0.0637756 loss)
I0916 22:20:04.397801 13570 sgd_solver.cpp:136] Iteration 33600, lr = 0.001, m = 0.9
I0916 22:20:24.050545 13570 solver.cpp:314] Iteration 33700 (5.08846 iter/s, 19.6523s/100 iter), loss = 0.113522
I0916 22:20:24.050565 13570 solver.cpp:336]     Train net output #0: loss = 0.113522 (* 1 = 0.113522 loss)
I0916 22:20:24.050570 13570 sgd_solver.cpp:136] Iteration 33700, lr = 0.001, m = 0.9
I0916 22:20:43.553414 13570 solver.cpp:314] Iteration 33800 (5.12759 iter/s, 19.5023s/100 iter), loss = 0.0569467
I0916 22:20:43.553565 13570 solver.cpp:336]     Train net output #0: loss = 0.0569466 (* 1 = 0.0569466 loss)
I0916 22:20:43.553581 13570 sgd_solver.cpp:136] Iteration 33800, lr = 0.001, m = 0.9
I0916 22:20:58.973057 13546 data_reader.cpp:305] Starting prefetch of epoch 14
I0916 22:21:03.328374 13570 solver.cpp:314] Iteration 33900 (5.05704 iter/s, 19.7744s/100 iter), loss = 0.0548456
I0916 22:21:03.328402 13570 solver.cpp:336]     Train net output #0: loss = 0.0548455 (* 1 = 0.0548455 loss)
I0916 22:21:03.328408 13570 sgd_solver.cpp:136] Iteration 33900, lr = 0.001, m = 0.9
I0916 22:21:22.918221 13570 solver.cpp:368] Sparsity after update:
I0916 22:21:22.926574 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 22:21:22.926589 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 22:21:22.926596 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 22:21:22.926599 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 22:21:22.926604 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 22:21:22.926668 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 22:21:22.926674 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 22:21:22.926677 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 22:21:22.926681 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 22:21:22.926692 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 22:21:22.926697 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 22:21:22.926702 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 22:21:22.926712 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 22:21:22.926717 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 22:21:22.926719 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 22:21:22.926729 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 22:21:22.926734 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 22:21:22.926744 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 22:21:22.926748 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 22:21:22.926765 13570 solver.cpp:563] Iteration 34000, Testing net (#0)
I0916 22:21:34.292677 13568 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 22:21:39.257408 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.954052
I0916 22:21:39.257437 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 22:21:39.257444 13570 solver.cpp:655]     Test net output #2: loss = 0.158289 (* 1 = 0.158289 loss)
I0916 22:21:39.257519 13570 solver.cpp:265] [MultiGPU] Tests completed in 16.3303s
I0916 22:21:39.466295 13570 solver.cpp:314] Iteration 34000 (2.76725 iter/s, 36.1369s/100 iter), loss = 0.158046
I0916 22:21:39.466325 13570 solver.cpp:336]     Train net output #0: loss = 0.158046 (* 1 = 0.158046 loss)
I0916 22:21:39.466331 13570 sgd_solver.cpp:136] Iteration 34000, lr = 0.001, m = 0.9
I0916 22:21:58.783859 13570 solver.cpp:314] Iteration 34100 (5.17678 iter/s, 19.317s/100 iter), loss = 0.055249
I0916 22:21:58.783951 13570 solver.cpp:336]     Train net output #0: loss = 0.0552489 (* 1 = 0.0552489 loss)
I0916 22:21:58.783959 13570 sgd_solver.cpp:136] Iteration 34100, lr = 0.001, m = 0.9
I0916 22:22:18.356523 13570 solver.cpp:314] Iteration 34200 (5.10931 iter/s, 19.5721s/100 iter), loss = 0.0500774
I0916 22:22:18.356550 13570 solver.cpp:336]     Train net output #0: loss = 0.0500773 (* 1 = 0.0500773 loss)
I0916 22:22:18.356557 13570 sgd_solver.cpp:136] Iteration 34200, lr = 0.001, m = 0.9
I0916 22:22:20.134627 13573 data_reader.cpp:305] Starting prefetch of epoch 22
I0916 22:22:38.243322 13570 solver.cpp:314] Iteration 34300 (5.0286 iter/s, 19.8862s/100 iter), loss = 0.0626318
I0916 22:22:38.243418 13570 solver.cpp:336]     Train net output #0: loss = 0.0626317 (* 1 = 0.0626317 loss)
I0916 22:22:38.243423 13570 sgd_solver.cpp:136] Iteration 34300, lr = 0.001, m = 0.9
I0916 22:22:57.666724 13570 solver.cpp:314] Iteration 34400 (5.14857 iter/s, 19.4229s/100 iter), loss = 0.0629678
I0916 22:22:57.666781 13570 solver.cpp:336]     Train net output #0: loss = 0.0629677 (* 1 = 0.0629677 loss)
I0916 22:22:57.666795 13570 sgd_solver.cpp:136] Iteration 34400, lr = 0.001, m = 0.9
I0916 22:23:17.347065 13570 solver.cpp:314] Iteration 34500 (5.08135 iter/s, 19.6798s/100 iter), loss = 0.172233
I0916 22:23:17.347146 13570 solver.cpp:336]     Train net output #0: loss = 0.172233 (* 1 = 0.172233 loss)
I0916 22:23:17.347153 13570 sgd_solver.cpp:136] Iteration 34500, lr = 0.001, m = 0.9
I0916 22:23:25.295020 13544 data_reader.cpp:305] Starting prefetch of epoch 22
I0916 22:23:37.085125 13570 solver.cpp:314] Iteration 34600 (5.06649 iter/s, 19.7375s/100 iter), loss = 0.0885575
I0916 22:23:37.085150 13570 solver.cpp:336]     Train net output #0: loss = 0.0885573 (* 1 = 0.0885573 loss)
I0916 22:23:37.085155 13570 sgd_solver.cpp:136] Iteration 34600, lr = 0.001, m = 0.9
I0916 22:23:56.693447 13570 solver.cpp:314] Iteration 34700 (5.10002 iter/s, 19.6078s/100 iter), loss = 0.0492809
I0916 22:23:56.693558 13570 solver.cpp:336]     Train net output #0: loss = 0.0492808 (* 1 = 0.0492808 loss)
I0916 22:23:56.693565 13570 sgd_solver.cpp:136] Iteration 34700, lr = 0.001, m = 0.9
I0916 22:23:57.688139 13544 data_reader.cpp:305] Starting prefetch of epoch 23
I0916 22:24:15.970335 13570 solver.cpp:314] Iteration 34800 (5.18771 iter/s, 19.2763s/100 iter), loss = 0.0660576
I0916 22:24:15.970376 13570 solver.cpp:336]     Train net output #0: loss = 0.0660575 (* 1 = 0.0660575 loss)
I0916 22:24:15.970388 13570 sgd_solver.cpp:136] Iteration 34800, lr = 0.001, m = 0.9
I0916 22:24:35.380807 13570 solver.cpp:314] Iteration 34900 (5.152 iter/s, 19.4099s/100 iter), loss = 0.07826
I0916 22:24:35.380861 13570 solver.cpp:336]     Train net output #0: loss = 0.0782599 (* 1 = 0.0782599 loss)
I0916 22:24:35.380867 13570 sgd_solver.cpp:136] Iteration 34900, lr = 0.001, m = 0.9
I0916 22:24:54.774186 13570 solver.cpp:368] Sparsity after update:
I0916 22:24:54.792433 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 22:24:54.792450 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 22:24:54.792456 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 22:24:54.792459 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 22:24:54.792461 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 22:24:54.792462 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 22:24:54.792464 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 22:24:54.792466 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 22:24:54.792469 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 22:24:54.792470 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 22:24:54.792472 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 22:24:54.792474 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 22:24:54.792476 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 22:24:54.792477 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 22:24:54.792479 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 22:24:54.792481 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 22:24:54.792484 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 22:24:54.792485 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 22:24:54.792487 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 22:24:54.964529 13570 solver.cpp:314] Iteration 35000 (5.10642 iter/s, 19.5832s/100 iter), loss = 0.0653202
I0916 22:24:54.964551 13570 solver.cpp:336]     Train net output #0: loss = 0.0653201 (* 1 = 0.0653201 loss)
I0916 22:24:54.964555 13570 sgd_solver.cpp:136] Iteration 35000, lr = 0.001, m = 0.9
I0916 22:25:01.721504 13574 data_reader.cpp:305] Starting prefetch of epoch 23
I0916 22:25:14.286095 13570 solver.cpp:314] Iteration 35100 (5.17571 iter/s, 19.321s/100 iter), loss = 0.0662967
I0916 22:25:14.286214 13570 solver.cpp:336]     Train net output #0: loss = 0.0662966 (* 1 = 0.0662966 loss)
I0916 22:25:14.286233 13570 sgd_solver.cpp:136] Iteration 35100, lr = 0.001, m = 0.9
I0916 22:25:33.901113 13570 solver.cpp:314] Iteration 35200 (5.09828 iter/s, 19.6145s/100 iter), loss = 0.0539222
I0916 22:25:33.901142 13570 solver.cpp:336]     Train net output #0: loss = 0.0539221 (* 1 = 0.0539221 loss)
I0916 22:25:33.901149 13570 sgd_solver.cpp:136] Iteration 35200, lr = 0.001, m = 0.9
I0916 22:25:53.056244 13570 solver.cpp:314] Iteration 35300 (5.22068 iter/s, 19.1546s/100 iter), loss = 0.0842631
I0916 22:25:53.062131 13570 solver.cpp:336]     Train net output #0: loss = 0.084263 (* 1 = 0.084263 loss)
I0916 22:25:53.062160 13570 sgd_solver.cpp:136] Iteration 35300, lr = 0.001, m = 0.9
I0916 22:26:05.812997 13576 data_reader.cpp:305] Starting prefetch of epoch 23
I0916 22:26:12.443032 13570 solver.cpp:314] Iteration 35400 (5.15829 iter/s, 19.3863s/100 iter), loss = 0.0734963
I0916 22:26:12.443060 13570 solver.cpp:336]     Train net output #0: loss = 0.0734962 (* 1 = 0.0734962 loss)
I0916 22:26:12.443068 13570 sgd_solver.cpp:136] Iteration 35400, lr = 0.001, m = 0.9
I0916 22:26:31.924829 13570 solver.cpp:314] Iteration 35500 (5.13314 iter/s, 19.4813s/100 iter), loss = 0.0419888
I0916 22:26:31.924890 13570 solver.cpp:336]     Train net output #0: loss = 0.0419887 (* 1 = 0.0419887 loss)
I0916 22:26:31.924896 13570 sgd_solver.cpp:136] Iteration 35500, lr = 0.001, m = 0.9
I0916 22:26:51.385061 13570 solver.cpp:314] Iteration 35600 (5.13883 iter/s, 19.4597s/100 iter), loss = 0.0701667
I0916 22:26:51.385084 13570 solver.cpp:336]     Train net output #0: loss = 0.0701666 (* 1 = 0.0701666 loss)
I0916 22:26:51.385089 13570 sgd_solver.cpp:136] Iteration 35600, lr = 0.001, m = 0.9
I0916 22:27:09.908689 13576 data_reader.cpp:305] Starting prefetch of epoch 24
I0916 22:27:10.622586 13570 solver.cpp:314] Iteration 35700 (5.19832 iter/s, 19.237s/100 iter), loss = 0.0549248
I0916 22:27:10.622611 13570 solver.cpp:336]     Train net output #0: loss = 0.0549247 (* 1 = 0.0549247 loss)
I0916 22:27:10.622615 13570 sgd_solver.cpp:136] Iteration 35700, lr = 0.001, m = 0.9
I0916 22:27:30.167976 13570 solver.cpp:314] Iteration 35800 (5.11644 iter/s, 19.5449s/100 iter), loss = 0.0596856
I0916 22:27:30.167999 13570 solver.cpp:336]     Train net output #0: loss = 0.0596854 (* 1 = 0.0596854 loss)
I0916 22:27:30.168004 13570 sgd_solver.cpp:136] Iteration 35800, lr = 0.001, m = 0.9
I0916 22:27:41.948842 13574 data_reader.cpp:305] Starting prefetch of epoch 24
I0916 22:27:49.164741 13570 solver.cpp:314] Iteration 35900 (5.2642 iter/s, 18.9962s/100 iter), loss = 0.070015
I0916 22:27:49.164765 13570 solver.cpp:336]     Train net output #0: loss = 0.0700149 (* 1 = 0.0700149 loss)
I0916 22:27:49.164770 13570 sgd_solver.cpp:136] Iteration 35900, lr = 0.001, m = 0.9
I0916 22:28:08.357271 13570 solver.cpp:368] Sparsity after update:
I0916 22:28:08.362357 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 22:28:08.362367 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 22:28:08.362376 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 22:28:08.362388 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 22:28:08.362397 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 22:28:08.362414 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 22:28:08.362424 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 22:28:08.362433 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 22:28:08.362443 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 22:28:08.362453 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 22:28:08.362463 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 22:28:08.362469 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 22:28:08.362473 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 22:28:08.362480 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 22:28:08.362489 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 22:28:08.362498 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 22:28:08.362504 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 22:28:08.362507 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 22:28:08.362510 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 22:28:08.362527 13570 solver.cpp:563] Iteration 36000, Testing net (#0)
I0916 22:28:18.584825 13604 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 22:28:18.926913 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.951293
I0916 22:28:18.926934 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 22:28:18.926940 13570 solver.cpp:655]     Test net output #2: loss = 0.147453 (* 1 = 0.147453 loss)
I0916 22:28:18.926964 13570 solver.cpp:265] [MultiGPU] Tests completed in 10.5641s
I0916 22:28:19.122109 13570 solver.cpp:314] Iteration 36000 (3.33817 iter/s, 29.9565s/100 iter), loss = 0.0788283
I0916 22:28:19.122133 13570 solver.cpp:336]     Train net output #0: loss = 0.0788282 (* 1 = 0.0788282 loss)
I0916 22:28:19.122138 13570 sgd_solver.cpp:136] Iteration 36000, lr = 0.001, m = 0.9
I0916 22:28:38.677208 13570 solver.cpp:314] Iteration 36100 (5.1139 iter/s, 19.5546s/100 iter), loss = 0.178148
I0916 22:28:38.677233 13570 solver.cpp:336]     Train net output #0: loss = 0.178148 (* 1 = 0.178148 loss)
I0916 22:28:38.677239 13570 sgd_solver.cpp:136] Iteration 36100, lr = 0.001, m = 0.9
I0916 22:28:56.537634 13578 data_reader.cpp:305] Starting prefetch of epoch 21
I0916 22:28:58.085917 13570 solver.cpp:314] Iteration 36200 (5.15247 iter/s, 19.4082s/100 iter), loss = 0.0482803
I0916 22:28:58.086030 13570 solver.cpp:336]     Train net output #0: loss = 0.0482802 (* 1 = 0.0482802 loss)
I0916 22:28:58.086055 13570 sgd_solver.cpp:136] Iteration 36200, lr = 0.001, m = 0.9
I0916 22:29:17.680061 13570 solver.cpp:314] Iteration 36300 (5.10371 iter/s, 19.5936s/100 iter), loss = 0.0549617
I0916 22:29:17.680083 13570 solver.cpp:336]     Train net output #0: loss = 0.0549615 (* 1 = 0.0549615 loss)
I0916 22:29:17.680088 13570 sgd_solver.cpp:136] Iteration 36300, lr = 0.001, m = 0.9
I0916 22:29:29.057924 13573 data_reader.cpp:305] Starting prefetch of epoch 23
I0916 22:29:37.220197 13570 solver.cpp:314] Iteration 36400 (5.11782 iter/s, 19.5396s/100 iter), loss = 0.0643352
I0916 22:29:37.220227 13570 solver.cpp:336]     Train net output #0: loss = 0.064335 (* 1 = 0.064335 loss)
I0916 22:29:37.220234 13570 sgd_solver.cpp:136] Iteration 36400, lr = 0.001, m = 0.9
I0916 22:29:57.008008 13570 solver.cpp:314] Iteration 36500 (5.05376 iter/s, 19.7873s/100 iter), loss = 0.0866666
I0916 22:29:57.008033 13570 solver.cpp:336]     Train net output #0: loss = 0.0866664 (* 1 = 0.0866664 loss)
I0916 22:29:57.008038 13570 sgd_solver.cpp:136] Iteration 36500, lr = 0.001, m = 0.9
I0916 22:30:16.482964 13570 solver.cpp:314] Iteration 36600 (5.13494 iter/s, 19.4744s/100 iter), loss = 0.0663875
I0916 22:30:16.483018 13570 solver.cpp:336]     Train net output #0: loss = 0.0663874 (* 1 = 0.0663874 loss)
I0916 22:30:16.483023 13570 sgd_solver.cpp:136] Iteration 36600, lr = 0.001, m = 0.9
I0916 22:30:33.801353 13546 data_reader.cpp:305] Starting prefetch of epoch 15
I0916 22:30:36.140790 13570 solver.cpp:314] Iteration 36700 (5.08717 iter/s, 19.6573s/100 iter), loss = 0.0687121
I0916 22:30:36.140816 13570 solver.cpp:336]     Train net output #0: loss = 0.068712 (* 1 = 0.068712 loss)
I0916 22:30:36.140823 13570 sgd_solver.cpp:136] Iteration 36700, lr = 0.001, m = 0.9
I0916 22:30:55.734346 13570 solver.cpp:314] Iteration 36800 (5.10386 iter/s, 19.593s/100 iter), loss = 0.0568472
I0916 22:30:55.734428 13570 solver.cpp:336]     Train net output #0: loss = 0.0568471 (* 1 = 0.0568471 loss)
I0916 22:30:55.734436 13570 sgd_solver.cpp:136] Iteration 36800, lr = 0.001, m = 0.9
I0916 22:31:15.374603 13570 solver.cpp:314] Iteration 36900 (5.09172 iter/s, 19.6397s/100 iter), loss = 0.0671254
I0916 22:31:15.374626 13570 solver.cpp:336]     Train net output #0: loss = 0.0671253 (* 1 = 0.0671253 loss)
I0916 22:31:15.374634 13570 sgd_solver.cpp:136] Iteration 36900, lr = 0.001, m = 0.9
I0916 22:31:35.136399 13570 solver.cpp:368] Sparsity after update:
I0916 22:31:35.159327 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 22:31:35.159346 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 22:31:35.159355 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 22:31:35.159358 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 22:31:35.159361 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 22:31:35.159363 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 22:31:35.159366 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 22:31:35.159379 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 22:31:35.159387 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 22:31:35.159396 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 22:31:35.159404 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 22:31:35.159412 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 22:31:35.159420 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 22:31:35.159428 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 22:31:35.159437 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 22:31:35.159446 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 22:31:35.159461 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 22:31:35.159471 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 22:31:35.159481 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 22:31:35.331732 13570 solver.cpp:314] Iteration 37000 (5.01088 iter/s, 19.9566s/100 iter), loss = 0.0589063
I0916 22:31:35.331753 13570 solver.cpp:336]     Train net output #0: loss = 0.0589062 (* 1 = 0.0589062 loss)
I0916 22:31:35.331759 13570 sgd_solver.cpp:136] Iteration 37000, lr = 0.001, m = 0.9
I0916 22:31:39.048897 13578 data_reader.cpp:305] Starting prefetch of epoch 22
I0916 22:31:54.903327 13570 solver.cpp:314] Iteration 37100 (5.10959 iter/s, 19.571s/100 iter), loss = 0.0813027
I0916 22:31:54.903354 13570 solver.cpp:336]     Train net output #0: loss = 0.0813026 (* 1 = 0.0813026 loss)
I0916 22:31:54.903358 13570 sgd_solver.cpp:136] Iteration 37100, lr = 0.001, m = 0.9
I0916 22:32:14.282011 13570 solver.cpp:314] Iteration 37200 (5.16045 iter/s, 19.3781s/100 iter), loss = 0.0560242
I0916 22:32:14.282109 13570 solver.cpp:336]     Train net output #0: loss = 0.0560241 (* 1 = 0.0560241 loss)
I0916 22:32:14.282130 13570 sgd_solver.cpp:136] Iteration 37200, lr = 0.001, m = 0.9
I0916 22:32:34.007910 13570 solver.cpp:314] Iteration 37300 (5.06962 iter/s, 19.7254s/100 iter), loss = 0.0646096
I0916 22:32:34.007932 13570 solver.cpp:336]     Train net output #0: loss = 0.0646095 (* 1 = 0.0646095 loss)
I0916 22:32:34.007936 13570 sgd_solver.cpp:136] Iteration 37300, lr = 0.001, m = 0.9
I0916 22:32:43.756772 13576 data_reader.cpp:305] Starting prefetch of epoch 25
I0916 22:32:53.912307 13570 solver.cpp:314] Iteration 37400 (5.02416 iter/s, 19.9038s/100 iter), loss = 0.093204
I0916 22:32:53.912729 13570 solver.cpp:336]     Train net output #0: loss = 0.0932038 (* 1 = 0.0932038 loss)
I0916 22:32:53.912735 13570 sgd_solver.cpp:136] Iteration 37400, lr = 0.001, m = 0.9
I0916 22:33:13.760723 13570 solver.cpp:314] Iteration 37500 (5.03833 iter/s, 19.8479s/100 iter), loss = 0.0494654
I0916 22:33:13.760761 13570 solver.cpp:336]     Train net output #0: loss = 0.0494653 (* 1 = 0.0494653 loss)
I0916 22:33:13.760767 13570 sgd_solver.cpp:136] Iteration 37500, lr = 0.001, m = 0.9
I0916 22:33:16.818363 13573 data_reader.cpp:305] Starting prefetch of epoch 24
I0916 22:33:33.639519 13570 solver.cpp:314] Iteration 37600 (5.03062 iter/s, 19.8782s/100 iter), loss = 0.0400998
I0916 22:33:33.639577 13570 solver.cpp:336]     Train net output #0: loss = 0.0400997 (* 1 = 0.0400997 loss)
I0916 22:33:33.639585 13570 sgd_solver.cpp:136] Iteration 37600, lr = 0.001, m = 0.9
I0916 22:33:53.481724 13570 solver.cpp:314] Iteration 37700 (5.0399 iter/s, 19.8417s/100 iter), loss = 0.0686033
I0916 22:33:53.481752 13570 solver.cpp:336]     Train net output #0: loss = 0.0686031 (* 1 = 0.0686031 loss)
I0916 22:33:53.481758 13570 sgd_solver.cpp:136] Iteration 37700, lr = 0.001, m = 0.9
I0916 22:34:13.681721 13570 solver.cpp:314] Iteration 37800 (4.95063 iter/s, 20.1994s/100 iter), loss = 0.0549695
I0916 22:34:13.681787 13570 solver.cpp:336]     Train net output #0: loss = 0.0549693 (* 1 = 0.0549693 loss)
I0916 22:34:13.681793 13570 sgd_solver.cpp:136] Iteration 37800, lr = 0.001, m = 0.9
I0916 22:34:22.506886 13574 data_reader.cpp:305] Starting prefetch of epoch 25
I0916 22:34:33.315883 13570 solver.cpp:314] Iteration 37900 (5.0933 iter/s, 19.6336s/100 iter), loss = 0.0788437
I0916 22:34:33.315907 13570 solver.cpp:336]     Train net output #0: loss = 0.0788435 (* 1 = 0.0788435 loss)
I0916 22:34:33.315912 13570 sgd_solver.cpp:136] Iteration 37900, lr = 0.001, m = 0.9
I0916 22:34:52.855890 13570 solver.cpp:368] Sparsity after update:
I0916 22:34:52.864219 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 22:34:52.864291 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 22:34:52.864306 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 22:34:52.864315 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 22:34:52.864323 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 22:34:52.864331 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 22:34:52.864339 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 22:34:52.864347 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 22:34:52.864356 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 22:34:52.864363 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 22:34:52.864372 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 22:34:52.864379 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 22:34:52.864387 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 22:34:52.864395 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 22:34:52.864403 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 22:34:52.864411 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 22:34:52.864418 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 22:34:52.864426 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 22:34:52.864434 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 22:34:52.864454 13570 solver.cpp:563] Iteration 38000, Testing net (#0)
I0916 22:35:04.543647 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.95415
I0916 22:35:04.543671 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 22:35:04.543679 13570 solver.cpp:655]     Test net output #2: loss = 0.161011 (* 1 = 0.161011 loss)
I0916 22:35:04.543699 13570 solver.cpp:265] [MultiGPU] Tests completed in 11.6789s
I0916 22:35:04.730865 13570 solver.cpp:314] Iteration 38000 (3.18328 iter/s, 31.4141s/100 iter), loss = 0.0915211
I0916 22:35:04.730895 13570 solver.cpp:336]     Train net output #0: loss = 0.091521 (* 1 = 0.091521 loss)
I0916 22:35:04.730901 13570 sgd_solver.cpp:136] Iteration 38000, lr = 0.001, m = 0.9
I0916 22:35:06.735465 13576 data_reader.cpp:305] Starting prefetch of epoch 26
I0916 22:35:24.192911 13570 solver.cpp:314] Iteration 38100 (5.13835 iter/s, 19.4615s/100 iter), loss = 0.0797218
I0916 22:35:24.192963 13570 solver.cpp:336]     Train net output #0: loss = 0.0797217 (* 1 = 0.0797217 loss)
I0916 22:35:24.192968 13570 sgd_solver.cpp:136] Iteration 38100, lr = 0.001, m = 0.9
I0916 22:35:39.099952 13573 data_reader.cpp:305] Starting prefetch of epoch 25
I0916 22:35:43.682725 13570 solver.cpp:314] Iteration 38200 (5.13103 iter/s, 19.4893s/100 iter), loss = 0.0878149
I0916 22:35:43.682763 13570 solver.cpp:336]     Train net output #0: loss = 0.0878147 (* 1 = 0.0878147 loss)
I0916 22:35:43.682771 13570 sgd_solver.cpp:136] Iteration 38200, lr = 0.001, m = 0.9
I0916 22:36:03.262764 13570 solver.cpp:314] Iteration 38300 (5.10738 iter/s, 19.5795s/100 iter), loss = 0.0659254
I0916 22:36:03.262820 13570 solver.cpp:336]     Train net output #0: loss = 0.0659252 (* 1 = 0.0659252 loss)
I0916 22:36:03.262827 13570 sgd_solver.cpp:136] Iteration 38300, lr = 0.001, m = 0.9
I0916 22:36:23.044409 13570 solver.cpp:314] Iteration 38400 (5.05533 iter/s, 19.7811s/100 iter), loss = 0.0620498
I0916 22:36:23.044430 13570 solver.cpp:336]     Train net output #0: loss = 0.0620496 (* 1 = 0.0620496 loss)
I0916 22:36:23.044433 13570 sgd_solver.cpp:136] Iteration 38400, lr = 0.001, m = 0.9
I0916 22:36:42.782371 13570 solver.cpp:314] Iteration 38500 (5.06652 iter/s, 19.7374s/100 iter), loss = 0.0568931
I0916 22:36:42.782445 13570 solver.cpp:336]     Train net output #0: loss = 0.056893 (* 1 = 0.056893 loss)
I0916 22:36:42.782451 13570 sgd_solver.cpp:136] Iteration 38500, lr = 0.001, m = 0.9
I0916 22:36:44.052026 13544 data_reader.cpp:305] Starting prefetch of epoch 24
I0916 22:37:02.301138 13570 solver.cpp:314] Iteration 38600 (5.12342 iter/s, 19.5182s/100 iter), loss = 0.0548144
I0916 22:37:02.301167 13570 solver.cpp:336]     Train net output #0: loss = 0.0548142 (* 1 = 0.0548142 loss)
I0916 22:37:02.301172 13570 sgd_solver.cpp:136] Iteration 38600, lr = 0.001, m = 0.9
I0916 22:37:22.186328 13570 solver.cpp:314] Iteration 38700 (5.02901 iter/s, 19.8846s/100 iter), loss = 0.0818416
I0916 22:37:22.186414 13570 solver.cpp:336]     Train net output #0: loss = 0.0818415 (* 1 = 0.0818415 loss)
I0916 22:37:22.186421 13570 sgd_solver.cpp:136] Iteration 38700, lr = 0.001, m = 0.9
I0916 22:37:41.929927 13570 solver.cpp:314] Iteration 38800 (5.06507 iter/s, 19.743s/100 iter), loss = 0.0676718
I0916 22:37:41.929955 13570 solver.cpp:336]     Train net output #0: loss = 0.0676717 (* 1 = 0.0676717 loss)
I0916 22:37:41.929961 13570 sgd_solver.cpp:136] Iteration 38800, lr = 0.001, m = 0.9
I0916 22:37:49.333583 13576 data_reader.cpp:305] Starting prefetch of epoch 27
I0916 22:38:01.898811 13570 solver.cpp:314] Iteration 38900 (5.00793 iter/s, 19.9683s/100 iter), loss = 0.145101
I0916 22:38:01.898859 13570 solver.cpp:336]     Train net output #0: loss = 0.1451 (* 1 = 0.1451 loss)
I0916 22:38:01.898864 13570 sgd_solver.cpp:136] Iteration 38900, lr = 0.001, m = 0.9
I0916 22:38:21.411255 13570 solver.cpp:368] Sparsity after update:
I0916 22:38:21.416158 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 22:38:21.416330 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 22:38:21.416405 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 22:38:21.416438 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 22:38:21.416471 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 22:38:21.416503 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 22:38:21.416538 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 22:38:21.416570 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 22:38:21.416602 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 22:38:21.416636 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 22:38:21.416666 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 22:38:21.416697 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 22:38:21.416730 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 22:38:21.416762 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 22:38:21.416798 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 22:38:21.416829 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 22:38:21.416863 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 22:38:21.416893 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 22:38:21.416926 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 22:38:21.601426 13570 solver.cpp:314] Iteration 39000 (5.07561 iter/s, 19.7021s/100 iter), loss = 0.0644456
I0916 22:38:21.601451 13570 solver.cpp:336]     Train net output #0: loss = 0.0644454 (* 1 = 0.0644454 loss)
I0916 22:38:21.601456 13570 sgd_solver.cpp:136] Iteration 39000, lr = 0.001, m = 0.9
I0916 22:38:22.020211 13544 data_reader.cpp:305] Starting prefetch of epoch 25
I0916 22:38:41.511312 13570 solver.cpp:314] Iteration 39100 (5.02277 iter/s, 19.9093s/100 iter), loss = 0.0328501
I0916 22:38:41.511392 13570 solver.cpp:336]     Train net output #0: loss = 0.03285 (* 1 = 0.03285 loss)
I0916 22:38:41.511400 13570 sgd_solver.cpp:136] Iteration 39100, lr = 0.001, m = 0.9
I0916 22:39:00.852854 13570 solver.cpp:314] Iteration 39200 (5.17036 iter/s, 19.341s/100 iter), loss = 0.0839714
I0916 22:39:00.852893 13570 solver.cpp:336]     Train net output #0: loss = 0.0839713 (* 1 = 0.0839713 loss)
I0916 22:39:00.852900 13570 sgd_solver.cpp:136] Iteration 39200, lr = 0.001, m = 0.9
I0916 22:39:20.493901 13570 solver.cpp:314] Iteration 39300 (5.09152 iter/s, 19.6405s/100 iter), loss = 0.0632892
I0916 22:39:20.493976 13570 solver.cpp:336]     Train net output #0: loss = 0.0632891 (* 1 = 0.0632891 loss)
I0916 22:39:20.493983 13570 sgd_solver.cpp:136] Iteration 39300, lr = 0.001, m = 0.9
I0916 22:39:26.942786 13574 data_reader.cpp:305] Starting prefetch of epoch 26
I0916 22:39:39.910593 13570 solver.cpp:314] Iteration 39400 (5.15035 iter/s, 19.4162s/100 iter), loss = 0.0569796
I0916 22:39:39.910614 13570 solver.cpp:336]     Train net output #0: loss = 0.0569795 (* 1 = 0.0569795 loss)
I0916 22:39:39.910617 13570 sgd_solver.cpp:136] Iteration 39400, lr = 0.001, m = 0.9
I0916 22:39:59.526844 13570 solver.cpp:314] Iteration 39500 (5.09796 iter/s, 19.6157s/100 iter), loss = 0.0567595
I0916 22:39:59.526898 13570 solver.cpp:336]     Train net output #0: loss = 0.0567594 (* 1 = 0.0567594 loss)
I0916 22:39:59.526906 13570 sgd_solver.cpp:136] Iteration 39500, lr = 0.001, m = 0.9
I0916 22:40:19.062733 13570 solver.cpp:314] Iteration 39600 (5.11893 iter/s, 19.5353s/100 iter), loss = 0.072267
I0916 22:40:19.062760 13570 solver.cpp:336]     Train net output #0: loss = 0.0722669 (* 1 = 0.0722669 loss)
I0916 22:40:19.062764 13570 sgd_solver.cpp:136] Iteration 39600, lr = 0.001, m = 0.9
I0916 22:40:31.193922 13578 data_reader.cpp:305] Starting prefetch of epoch 23
I0916 22:40:38.317818 13570 solver.cpp:314] Iteration 39700 (5.19358 iter/s, 19.2546s/100 iter), loss = 0.0702501
I0916 22:40:38.317843 13570 solver.cpp:336]     Train net output #0: loss = 0.07025 (* 1 = 0.07025 loss)
I0916 22:40:38.317847 13570 sgd_solver.cpp:136] Iteration 39700, lr = 0.001, m = 0.9
I0916 22:40:57.647900 13570 solver.cpp:314] Iteration 39800 (5.17343 iter/s, 19.3295s/100 iter), loss = 0.057859
I0916 22:40:57.647935 13570 solver.cpp:336]     Train net output #0: loss = 0.0578589 (* 1 = 0.0578589 loss)
I0916 22:40:57.647941 13570 sgd_solver.cpp:136] Iteration 39800, lr = 0.001, m = 0.9
I0916 22:41:03.136008 13544 data_reader.cpp:305] Starting prefetch of epoch 26
I0916 22:41:17.397245 13570 solver.cpp:314] Iteration 39900 (5.0636 iter/s, 19.7488s/100 iter), loss = 0.0695099
I0916 22:41:17.397274 13570 solver.cpp:336]     Train net output #0: loss = 0.0695097 (* 1 = 0.0695097 loss)
I0916 22:41:17.397280 13570 sgd_solver.cpp:136] Iteration 39900, lr = 0.001, m = 0.9
I0916 22:41:36.921422 13570 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/sparse/cityscapes5_jsegnet21v2_iter_40000.caffemodel
I0916 22:41:36.989200 13570 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/sparse/cityscapes5_jsegnet21v2_iter_40000.solverstate
I0916 22:41:36.996978 13570 solver.cpp:368] Sparsity after update:
I0916 22:41:36.998790 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 22:41:36.998800 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 22:41:36.998805 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 22:41:36.998809 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 22:41:36.998812 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 22:41:36.998816 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 22:41:36.998818 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 22:41:36.998822 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 22:41:36.998826 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 22:41:36.998828 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 22:41:36.998831 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 22:41:36.998834 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 22:41:36.998843 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 22:41:36.998847 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 22:41:36.998849 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 22:41:36.998852 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 22:41:36.998855 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 22:41:36.998858 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 22:41:36.998862 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 22:41:36.998873 13570 solver.cpp:563] Iteration 40000, Testing net (#0)
I0916 22:41:40.111858 13596 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 22:41:48.228368 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.952269
I0916 22:41:48.228386 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 22:41:48.228391 13570 solver.cpp:655]     Test net output #2: loss = 0.142443 (* 1 = 0.142443 loss)
I0916 22:41:48.228420 13570 solver.cpp:265] [MultiGPU] Tests completed in 11.2292s
I0916 22:41:48.438877 13570 solver.cpp:314] Iteration 40000 (3.22157 iter/s, 31.0408s/100 iter), loss = 0.0781242
I0916 22:41:48.438905 13570 solver.cpp:336]     Train net output #0: loss = 0.0781241 (* 1 = 0.0781241 loss)
I0916 22:41:48.438912 13570 sgd_solver.cpp:136] Iteration 40000, lr = 0.001, m = 0.9
I0916 22:42:07.413648 13570 solver.cpp:314] Iteration 40100 (5.2703 iter/s, 18.9742s/100 iter), loss = 0.062461
I0916 22:42:07.437260 13570 solver.cpp:336]     Train net output #0: loss = 0.0624608 (* 1 = 0.0624608 loss)
I0916 22:42:07.437286 13570 sgd_solver.cpp:136] Iteration 40100, lr = 0.001, m = 0.9
I0916 22:42:18.783710 13546 data_reader.cpp:305] Starting prefetch of epoch 16
I0916 22:42:26.679811 13570 solver.cpp:314] Iteration 40200 (5.19059 iter/s, 19.2656s/100 iter), loss = 0.0452116
I0916 22:42:26.679833 13570 solver.cpp:336]     Train net output #0: loss = 0.0452115 (* 1 = 0.0452115 loss)
I0916 22:42:26.679837 13570 sgd_solver.cpp:136] Iteration 40200, lr = 0.001, m = 0.9
I0916 22:42:45.943516 13570 solver.cpp:314] Iteration 40300 (5.19125 iter/s, 19.2632s/100 iter), loss = 0.0781107
I0916 22:42:45.943568 13570 solver.cpp:336]     Train net output #0: loss = 0.0781106 (* 1 = 0.0781106 loss)
I0916 22:42:45.943573 13570 sgd_solver.cpp:136] Iteration 40300, lr = 0.001, m = 0.9
I0916 22:42:50.653384 13573 data_reader.cpp:305] Starting prefetch of epoch 26
I0916 22:43:05.583230 13570 solver.cpp:314] Iteration 40400 (5.09187 iter/s, 19.6392s/100 iter), loss = 0.0803965
I0916 22:43:05.583256 13570 solver.cpp:336]     Train net output #0: loss = 0.0803963 (* 1 = 0.0803963 loss)
I0916 22:43:05.583261 13570 sgd_solver.cpp:136] Iteration 40400, lr = 0.001, m = 0.9
I0916 22:43:24.887627 13570 solver.cpp:314] Iteration 40500 (5.18031 iter/s, 19.3039s/100 iter), loss = 0.0725264
I0916 22:43:24.902150 13570 solver.cpp:336]     Train net output #0: loss = 0.0725263 (* 1 = 0.0725263 loss)
I0916 22:43:24.902330 13570 sgd_solver.cpp:136] Iteration 40500, lr = 0.001, m = 0.9
I0916 22:43:44.530555 13570 solver.cpp:314] Iteration 40600 (5.09103 iter/s, 19.6424s/100 iter), loss = 0.072069
I0916 22:43:44.530580 13570 solver.cpp:336]     Train net output #0: loss = 0.0720688 (* 1 = 0.0720688 loss)
I0916 22:43:44.530586 13570 sgd_solver.cpp:136] Iteration 40600, lr = 0.001, m = 0.9
I0916 22:43:55.207365 13546 data_reader.cpp:305] Starting prefetch of epoch 17
I0916 22:44:03.863397 13570 solver.cpp:314] Iteration 40700 (5.17269 iter/s, 19.3323s/100 iter), loss = 0.0743773
I0916 22:44:03.863427 13570 solver.cpp:336]     Train net output #0: loss = 0.0743771 (* 1 = 0.0743771 loss)
I0916 22:44:03.863435 13570 sgd_solver.cpp:136] Iteration 40700, lr = 0.001, m = 0.9
I0916 22:44:23.704002 13570 solver.cpp:314] Iteration 40800 (5.04031 iter/s, 19.8401s/100 iter), loss = 0.11675
I0916 22:44:23.704027 13570 solver.cpp:336]     Train net output #0: loss = 0.11675 (* 1 = 0.11675 loss)
I0916 22:44:23.704033 13570 sgd_solver.cpp:136] Iteration 40800, lr = 0.001, m = 0.9
I0916 22:44:43.701822 13570 solver.cpp:314] Iteration 40900 (5.00068 iter/s, 19.9973s/100 iter), loss = 0.0648626
I0916 22:44:43.718503 13570 solver.cpp:336]     Train net output #0: loss = 0.0648624 (* 1 = 0.0648624 loss)
I0916 22:44:43.718703 13570 sgd_solver.cpp:136] Iteration 40900, lr = 0.001, m = 0.9
I0916 22:45:00.677501 13576 data_reader.cpp:305] Starting prefetch of epoch 28
I0916 22:45:03.389329 13570 solver.cpp:368] Sparsity after update:
I0916 22:45:03.397192 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 22:45:03.397204 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 22:45:03.397213 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 22:45:03.397217 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 22:45:03.397222 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 22:45:03.397225 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 22:45:03.397229 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 22:45:03.397233 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 22:45:03.397236 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 22:45:03.397239 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 22:45:03.397251 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 22:45:03.397255 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 22:45:03.397259 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 22:45:03.397263 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 22:45:03.397265 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 22:45:03.397269 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 22:45:03.397274 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 22:45:03.397277 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 22:45:03.397280 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 22:45:03.570483 13570 solver.cpp:314] Iteration 41000 (5.03319 iter/s, 19.8681s/100 iter), loss = 0.0866997
I0916 22:45:03.570507 13570 solver.cpp:336]     Train net output #0: loss = 0.0866996 (* 1 = 0.0866996 loss)
I0916 22:45:03.570510 13570 sgd_solver.cpp:136] Iteration 41000, lr = 0.001, m = 0.9
I0916 22:45:22.974095 13570 solver.cpp:314] Iteration 41100 (5.15382 iter/s, 19.4031s/100 iter), loss = 0.0539991
I0916 22:45:22.974565 13570 solver.cpp:336]     Train net output #0: loss = 0.053999 (* 1 = 0.053999 loss)
I0916 22:45:22.974575 13570 sgd_solver.cpp:136] Iteration 41100, lr = 0.001, m = 0.9
I0916 22:45:42.808414 13570 solver.cpp:314] Iteration 41200 (5.04191 iter/s, 19.8338s/100 iter), loss = 0.0547939
I0916 22:45:42.808439 13570 solver.cpp:336]     Train net output #0: loss = 0.0547938 (* 1 = 0.0547938 loss)
I0916 22:45:42.808444 13570 sgd_solver.cpp:136] Iteration 41200, lr = 0.001, m = 0.9
I0916 22:46:02.381341 13570 solver.cpp:314] Iteration 41300 (5.10924 iter/s, 19.5724s/100 iter), loss = 0.0330257
I0916 22:46:02.381443 13570 solver.cpp:336]     Train net output #0: loss = 0.0330256 (* 1 = 0.0330256 loss)
I0916 22:46:02.381456 13570 sgd_solver.cpp:136] Iteration 41300, lr = 0.001, m = 0.9
I0916 22:46:05.672762 13578 data_reader.cpp:305] Starting prefetch of epoch 24
I0916 22:46:22.138162 13570 solver.cpp:314] Iteration 41400 (5.06168 iter/s, 19.7563s/100 iter), loss = 0.0955008
I0916 22:46:22.138185 13570 solver.cpp:336]     Train net output #0: loss = 0.0955007 (* 1 = 0.0955007 loss)
I0916 22:46:22.138191 13570 sgd_solver.cpp:136] Iteration 41400, lr = 0.001, m = 0.9
I0916 22:46:37.922792 13574 data_reader.cpp:305] Starting prefetch of epoch 27
I0916 22:46:41.680539 13570 solver.cpp:314] Iteration 41500 (5.11723 iter/s, 19.5418s/100 iter), loss = 0.0816391
I0916 22:46:41.680624 13570 solver.cpp:336]     Train net output #0: loss = 0.081639 (* 1 = 0.081639 loss)
I0916 22:46:41.680645 13570 sgd_solver.cpp:136] Iteration 41500, lr = 0.001, m = 0.9
I0916 22:47:01.457968 13570 solver.cpp:314] Iteration 41600 (5.05641 iter/s, 19.7769s/100 iter), loss = 0.0454548
I0916 22:47:01.457998 13570 solver.cpp:336]     Train net output #0: loss = 0.0454546 (* 1 = 0.0454546 loss)
I0916 22:47:01.458003 13570 sgd_solver.cpp:136] Iteration 41600, lr = 0.001, m = 0.9
I0916 22:47:21.110638 13570 solver.cpp:314] Iteration 41700 (5.08851 iter/s, 19.6521s/100 iter), loss = 0.0940945
I0916 22:47:21.110711 13570 solver.cpp:336]     Train net output #0: loss = 0.0940943 (* 1 = 0.0940943 loss)
I0916 22:47:21.110716 13570 sgd_solver.cpp:136] Iteration 41700, lr = 0.001, m = 0.9
I0916 22:47:40.552846 13570 solver.cpp:314] Iteration 41800 (5.14359 iter/s, 19.4417s/100 iter), loss = 0.0820077
I0916 22:47:40.552870 13570 solver.cpp:336]     Train net output #0: loss = 0.0820076 (* 1 = 0.0820076 loss)
I0916 22:47:40.552873 13570 sgd_solver.cpp:136] Iteration 41800, lr = 0.001, m = 0.9
I0916 22:47:42.812830 13576 data_reader.cpp:305] Starting prefetch of epoch 29
I0916 22:48:00.029337 13570 solver.cpp:314] Iteration 41900 (5.13454 iter/s, 19.4759s/100 iter), loss = 0.0767126
I0916 22:48:00.030187 13570 solver.cpp:336]     Train net output #0: loss = 0.0767125 (* 1 = 0.0767125 loss)
I0916 22:48:00.030205 13570 sgd_solver.cpp:136] Iteration 41900, lr = 0.001, m = 0.9
I0916 22:48:19.654906 13570 solver.cpp:368] Sparsity after update:
I0916 22:48:19.663115 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 22:48:19.663133 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 22:48:19.663142 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 22:48:19.663146 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 22:48:19.663148 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 22:48:19.663152 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 22:48:19.663172 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 22:48:19.663182 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 22:48:19.663189 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 22:48:19.663198 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 22:48:19.663206 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 22:48:19.663218 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 22:48:19.663228 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 22:48:19.663239 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 22:48:19.663244 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 22:48:19.663247 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 22:48:19.663255 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 22:48:19.663264 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 22:48:19.663269 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 22:48:19.663285 13570 solver.cpp:563] Iteration 42000, Testing net (#0)
I0916 22:48:27.008527 13600 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 22:48:31.419229 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.954198
I0916 22:48:31.419289 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 22:48:31.419297 13570 solver.cpp:655]     Test net output #2: loss = 0.159733 (* 1 = 0.159733 loss)
I0916 22:48:31.419329 13570 solver.cpp:265] [MultiGPU] Tests completed in 11.7557s
I0916 22:48:31.649610 13570 solver.cpp:314] Iteration 42000 (3.16262 iter/s, 31.6194s/100 iter), loss = 0.0516812
I0916 22:48:31.649663 13570 solver.cpp:336]     Train net output #0: loss = 0.0516811 (* 1 = 0.0516811 loss)
I0916 22:48:31.649682 13570 sgd_solver.cpp:136] Iteration 42000, lr = 0.001, m = 0.9
I0916 22:48:50.899164 13570 solver.cpp:314] Iteration 42100 (5.19507 iter/s, 19.249s/100 iter), loss = 0.0565575
I0916 22:48:50.899188 13570 solver.cpp:336]     Train net output #0: loss = 0.0565574 (* 1 = 0.0565574 loss)
I0916 22:48:50.899193 13570 sgd_solver.cpp:136] Iteration 42100, lr = 0.001, m = 0.9
I0916 22:48:58.976613 13573 data_reader.cpp:305] Starting prefetch of epoch 27
I0916 22:49:10.321295 13570 solver.cpp:314] Iteration 42200 (5.14891 iter/s, 19.4216s/100 iter), loss = 0.0592744
I0916 22:49:10.321350 13570 solver.cpp:336]     Train net output #0: loss = 0.0592742 (* 1 = 0.0592742 loss)
I0916 22:49:10.321357 13570 sgd_solver.cpp:136] Iteration 42200, lr = 0.001, m = 0.9
I0916 22:49:29.957427 13570 solver.cpp:314] Iteration 42300 (5.09279 iter/s, 19.6356s/100 iter), loss = 0.0802638
I0916 22:49:29.957449 13570 solver.cpp:336]     Train net output #0: loss = 0.0802637 (* 1 = 0.0802637 loss)
I0916 22:49:29.957453 13570 sgd_solver.cpp:136] Iteration 42300, lr = 0.001, m = 0.9
I0916 22:49:49.541329 13570 solver.cpp:314] Iteration 42400 (5.10638 iter/s, 19.5834s/100 iter), loss = 0.0598143
I0916 22:49:49.541401 13570 solver.cpp:336]     Train net output #0: loss = 0.0598142 (* 1 = 0.0598142 loss)
I0916 22:49:49.541409 13570 sgd_solver.cpp:136] Iteration 42400, lr = 0.001, m = 0.9
I0916 22:50:03.840003 13546 data_reader.cpp:305] Starting prefetch of epoch 18
I0916 22:50:09.081315 13570 solver.cpp:314] Iteration 42500 (5.11785 iter/s, 19.5394s/100 iter), loss = 0.0492221
I0916 22:50:09.081339 13570 solver.cpp:336]     Train net output #0: loss = 0.0492219 (* 1 = 0.0492219 loss)
I0916 22:50:09.081344 13570 sgd_solver.cpp:136] Iteration 42500, lr = 0.001, m = 0.9
I0916 22:50:28.526091 13570 solver.cpp:314] Iteration 42600 (5.14292 iter/s, 19.4442s/100 iter), loss = 0.084746
I0916 22:50:28.526149 13570 solver.cpp:336]     Train net output #0: loss = 0.0847459 (* 1 = 0.0847459 loss)
I0916 22:50:28.526167 13570 sgd_solver.cpp:136] Iteration 42600, lr = 0.001, m = 0.9
I0916 22:50:48.327483 13570 solver.cpp:314] Iteration 42700 (5.05029 iter/s, 19.8008s/100 iter), loss = 0.0593378
I0916 22:50:48.327507 13570 solver.cpp:336]     Train net output #0: loss = 0.0593377 (* 1 = 0.0593377 loss)
I0916 22:50:48.327510 13570 sgd_solver.cpp:136] Iteration 42700, lr = 0.001, m = 0.9
I0916 22:51:08.133787 13570 solver.cpp:314] Iteration 42800 (5.04904 iter/s, 19.8058s/100 iter), loss = 0.0551964
I0916 22:51:08.133839 13570 solver.cpp:336]     Train net output #0: loss = 0.0551962 (* 1 = 0.0551962 loss)
I0916 22:51:08.133846 13570 sgd_solver.cpp:136] Iteration 42800, lr = 0.001, m = 0.9
I0916 22:51:08.725590 13578 data_reader.cpp:305] Starting prefetch of epoch 25
I0916 22:51:27.407416 13570 solver.cpp:314] Iteration 42900 (5.18858 iter/s, 19.2731s/100 iter), loss = 0.0494708
I0916 22:51:27.407443 13570 solver.cpp:336]     Train net output #0: loss = 0.0494707 (* 1 = 0.0494707 loss)
I0916 22:51:27.407449 13570 sgd_solver.cpp:136] Iteration 42900, lr = 0.001, m = 0.9
I0916 22:51:41.091259 13574 data_reader.cpp:305] Starting prefetch of epoch 28
I0916 22:51:46.942561 13570 solver.cpp:368] Sparsity after update:
I0916 22:51:46.958097 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 22:51:46.958149 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 22:51:46.958174 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 22:51:46.958187 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 22:51:46.958200 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 22:51:46.958214 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 22:51:46.958227 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 22:51:46.958240 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 22:51:46.958251 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 22:51:46.958263 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 22:51:46.958274 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 22:51:46.958287 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 22:51:46.958298 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 22:51:46.958310 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 22:51:46.958323 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 22:51:46.958338 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 22:51:46.958351 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 22:51:46.958364 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 22:51:46.958376 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 22:51:47.128099 13570 solver.cpp:314] Iteration 43000 (5.07096 iter/s, 19.7201s/100 iter), loss = 0.0503758
I0916 22:51:47.128124 13570 solver.cpp:336]     Train net output #0: loss = 0.0503757 (* 1 = 0.0503757 loss)
I0916 22:51:47.128130 13570 sgd_solver.cpp:136] Iteration 43000, lr = 0.001, m = 0.9
I0916 22:52:06.897240 13570 solver.cpp:314] Iteration 43100 (5.05853 iter/s, 19.7686s/100 iter), loss = 0.0962716
I0916 22:52:06.897265 13570 solver.cpp:336]     Train net output #0: loss = 0.0962714 (* 1 = 0.0962714 loss)
I0916 22:52:06.897271 13570 sgd_solver.cpp:136] Iteration 43100, lr = 0.001, m = 0.9
I0916 22:52:26.165985 13570 solver.cpp:314] Iteration 43200 (5.1899 iter/s, 19.2682s/100 iter), loss = 0.0877511
I0916 22:52:26.166059 13570 solver.cpp:336]     Train net output #0: loss = 0.087751 (* 1 = 0.087751 loss)
I0916 22:52:26.166065 13570 sgd_solver.cpp:136] Iteration 43200, lr = 0.001, m = 0.9
I0916 22:52:45.267606 13546 data_reader.cpp:305] Starting prefetch of epoch 19
I0916 22:52:45.422863 13570 solver.cpp:314] Iteration 43300 (5.19309 iter/s, 19.2563s/100 iter), loss = 0.049812
I0916 22:52:45.422888 13570 solver.cpp:336]     Train net output #0: loss = 0.0498119 (* 1 = 0.0498119 loss)
I0916 22:52:45.422894 13570 sgd_solver.cpp:136] Iteration 43300, lr = 0.001, m = 0.9
I0916 22:53:04.809875 13570 solver.cpp:314] Iteration 43400 (5.15824 iter/s, 19.3865s/100 iter), loss = 0.078804
I0916 22:53:04.809938 13570 solver.cpp:336]     Train net output #0: loss = 0.0788039 (* 1 = 0.0788039 loss)
I0916 22:53:04.809947 13570 sgd_solver.cpp:136] Iteration 43400, lr = 0.001, m = 0.9
I0916 22:53:24.358940 13570 solver.cpp:314] Iteration 43500 (5.11548 iter/s, 19.5485s/100 iter), loss = 0.0882238
I0916 22:53:24.358964 13570 solver.cpp:336]     Train net output #0: loss = 0.0882236 (* 1 = 0.0882236 loss)
I0916 22:53:24.358969 13570 sgd_solver.cpp:136] Iteration 43500, lr = 0.001, m = 0.9
I0916 22:53:43.846901 13570 solver.cpp:314] Iteration 43600 (5.13152 iter/s, 19.4874s/100 iter), loss = 0.0624362
I0916 22:53:43.846961 13570 solver.cpp:336]     Train net output #0: loss = 0.0624361 (* 1 = 0.0624361 loss)
I0916 22:53:43.846966 13570 sgd_solver.cpp:136] Iteration 43600, lr = 0.001, m = 0.9
I0916 22:53:49.587294 13546 data_reader.cpp:305] Starting prefetch of epoch 20
I0916 22:54:03.088802 13570 solver.cpp:314] Iteration 43700 (5.19714 iter/s, 19.2414s/100 iter), loss = 0.101973
I0916 22:54:03.088824 13570 solver.cpp:336]     Train net output #0: loss = 0.101973 (* 1 = 0.101973 loss)
I0916 22:54:03.088829 13570 sgd_solver.cpp:136] Iteration 43700, lr = 0.001, m = 0.9
I0916 22:54:21.680814 13573 data_reader.cpp:305] Starting prefetch of epoch 28
I0916 22:54:22.651444 13570 solver.cpp:314] Iteration 43800 (5.11193 iter/s, 19.5621s/100 iter), loss = 0.0381728
I0916 22:54:22.651468 13570 solver.cpp:336]     Train net output #0: loss = 0.0381726 (* 1 = 0.0381726 loss)
I0916 22:54:22.651473 13570 sgd_solver.cpp:136] Iteration 43800, lr = 0.001, m = 0.9
I0916 22:54:42.130373 13570 solver.cpp:314] Iteration 43900 (5.13389 iter/s, 19.4784s/100 iter), loss = 0.048848
I0916 22:54:42.130398 13570 solver.cpp:336]     Train net output #0: loss = 0.0488478 (* 1 = 0.0488478 loss)
I0916 22:54:42.130403 13570 sgd_solver.cpp:136] Iteration 43900, lr = 0.001, m = 0.9
I0916 22:55:01.356218 13570 solver.cpp:368] Sparsity after update:
I0916 22:55:01.365273 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 22:55:01.365288 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 22:55:01.365294 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 22:55:01.365298 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 22:55:01.365299 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 22:55:01.365300 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 22:55:01.365303 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 22:55:01.365304 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 22:55:01.365306 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 22:55:01.365309 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 22:55:01.365310 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 22:55:01.365312 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 22:55:01.365314 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 22:55:01.365316 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 22:55:01.365319 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 22:55:01.365320 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 22:55:01.365322 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 22:55:01.365324 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 22:55:01.365325 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 22:55:01.365334 13570 solver.cpp:563] Iteration 44000, Testing net (#0)
I0916 22:55:04.870558 13568 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 22:55:12.785444 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.951627
I0916 22:55:12.785470 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 22:55:12.785475 13570 solver.cpp:655]     Test net output #2: loss = 0.148007 (* 1 = 0.148007 loss)
I0916 22:55:12.785508 13570 solver.cpp:265] [MultiGPU] Tests completed in 11.4199s
I0916 22:55:13.008673 13570 solver.cpp:314] Iteration 44000 (3.23861 iter/s, 30.8774s/100 iter), loss = 0.0918156
I0916 22:55:13.008698 13570 solver.cpp:336]     Train net output #0: loss = 0.0918154 (* 1 = 0.0918154 loss)
I0916 22:55:13.008704 13570 sgd_solver.cpp:136] Iteration 44000, lr = 0.001, m = 0.9
I0916 22:55:32.392392 13570 solver.cpp:314] Iteration 44100 (5.15911 iter/s, 19.3832s/100 iter), loss = 0.0734994
I0916 22:55:32.392529 13570 solver.cpp:336]     Train net output #0: loss = 0.0734993 (* 1 = 0.0734993 loss)
I0916 22:55:32.392536 13570 sgd_solver.cpp:136] Iteration 44100, lr = 0.001, m = 0.9
I0916 22:55:37.508002 13576 data_reader.cpp:305] Starting prefetch of epoch 30
I0916 22:55:51.602455 13570 solver.cpp:314] Iteration 44200 (5.20575 iter/s, 19.2095s/100 iter), loss = 0.0611329
I0916 22:55:51.602479 13570 solver.cpp:336]     Train net output #0: loss = 0.0611328 (* 1 = 0.0611328 loss)
I0916 22:55:51.602483 13570 sgd_solver.cpp:136] Iteration 44200, lr = 0.001, m = 0.9
I0916 22:56:09.303495 13573 data_reader.cpp:305] Starting prefetch of epoch 29
I0916 22:56:10.980659 13570 solver.cpp:314] Iteration 44300 (5.16058 iter/s, 19.3777s/100 iter), loss = 0.0430401
I0916 22:56:10.980679 13570 solver.cpp:336]     Train net output #0: loss = 0.0430399 (* 1 = 0.0430399 loss)
I0916 22:56:10.980684 13570 sgd_solver.cpp:136] Iteration 44300, lr = 0.001, m = 0.9
I0916 22:56:30.650393 13570 solver.cpp:314] Iteration 44400 (5.08409 iter/s, 19.6692s/100 iter), loss = 0.0543779
I0916 22:56:30.650413 13570 solver.cpp:336]     Train net output #0: loss = 0.0543778 (* 1 = 0.0543778 loss)
I0916 22:56:30.650419 13570 sgd_solver.cpp:136] Iteration 44400, lr = 0.001, m = 0.9
I0916 22:56:50.098057 13570 solver.cpp:314] Iteration 44500 (5.14215 iter/s, 19.4471s/100 iter), loss = 0.0567879
I0916 22:56:50.098112 13570 solver.cpp:336]     Train net output #0: loss = 0.0567878 (* 1 = 0.0567878 loss)
I0916 22:56:50.098119 13570 sgd_solver.cpp:136] Iteration 44500, lr = 0.001, m = 0.9
I0916 22:57:09.195767 13570 solver.cpp:314] Iteration 44600 (5.23638 iter/s, 19.0972s/100 iter), loss = 0.0703127
I0916 22:57:09.195793 13570 solver.cpp:336]     Train net output #0: loss = 0.0703126 (* 1 = 0.0703126 loss)
I0916 22:57:09.195799 13570 sgd_solver.cpp:136] Iteration 44600, lr = 0.001, m = 0.9
I0916 22:57:13.405563 13578 data_reader.cpp:305] Starting prefetch of epoch 26
I0916 22:57:28.657826 13570 solver.cpp:314] Iteration 44700 (5.13835 iter/s, 19.4615s/100 iter), loss = 0.0627093
I0916 22:57:28.657907 13570 solver.cpp:336]     Train net output #0: loss = 0.0627092 (* 1 = 0.0627092 loss)
I0916 22:57:28.657912 13570 sgd_solver.cpp:136] Iteration 44700, lr = 0.001, m = 0.9
I0916 22:57:48.126631 13570 solver.cpp:314] Iteration 44800 (5.13656 iter/s, 19.4683s/100 iter), loss = 0.0855177
I0916 22:57:48.126658 13570 solver.cpp:336]     Train net output #0: loss = 0.0855176 (* 1 = 0.0855176 loss)
I0916 22:57:48.126663 13570 sgd_solver.cpp:136] Iteration 44800, lr = 0.001, m = 0.9
I0916 22:58:07.719213 13570 solver.cpp:314] Iteration 44900 (5.10412 iter/s, 19.592s/100 iter), loss = 0.0528402
I0916 22:58:07.719298 13570 solver.cpp:336]     Train net output #0: loss = 0.0528401 (* 1 = 0.0528401 loss)
I0916 22:58:07.719313 13570 sgd_solver.cpp:136] Iteration 44900, lr = 0.001, m = 0.9
I0916 22:58:17.941295 13576 data_reader.cpp:305] Starting prefetch of epoch 31
I0916 22:58:26.843730 13570 solver.cpp:368] Sparsity after update:
I0916 22:58:26.851810 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 22:58:26.851828 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 22:58:26.851836 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 22:58:26.851841 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 22:58:26.851845 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 22:58:26.851847 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 22:58:26.851850 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 22:58:26.851855 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 22:58:26.851857 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 22:58:26.851861 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 22:58:26.851864 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 22:58:26.851867 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 22:58:26.851871 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 22:58:26.851879 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 22:58:26.851886 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 22:58:26.851891 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 22:58:26.851896 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 22:58:26.851900 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 22:58:26.851903 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 22:58:26.938170 13623 sgd_solver.cpp:48] MultiStep Status: Iteration 45000, step = 2
I0916 22:58:26.938171 13624 sgd_solver.cpp:48] MultiStep Status: Iteration 45000, step = 2
I0916 22:58:26.938172 13625 sgd_solver.cpp:48] MultiStep Status: Iteration 45000, step = 2
I0916 22:58:27.026938 13570 solver.cpp:314] Iteration 45000 (5.17942 iter/s, 19.3072s/100 iter), loss = 0.078834
I0916 22:58:27.026963 13570 solver.cpp:336]     Train net output #0: loss = 0.0788338 (* 1 = 0.0788338 loss)
I0916 22:58:27.026968 13570 sgd_solver.cpp:136] Iteration 45000, lr = 0.0001, m = 0.9
I0916 22:58:46.492411 13570 solver.cpp:314] Iteration 45100 (5.13744 iter/s, 19.4649s/100 iter), loss = 0.102599
I0916 22:58:46.492486 13570 solver.cpp:336]     Train net output #0: loss = 0.102599 (* 1 = 0.102599 loss)
I0916 22:58:46.492491 13570 sgd_solver.cpp:136] Iteration 45100, lr = 0.0001, m = 0.9
I0916 22:58:49.800247 13544 data_reader.cpp:305] Starting prefetch of epoch 27
I0916 22:59:05.749977 13570 solver.cpp:314] Iteration 45200 (5.19291 iter/s, 19.257s/100 iter), loss = 0.0652478
I0916 22:59:05.750003 13570 solver.cpp:336]     Train net output #0: loss = 0.0652476 (* 1 = 0.0652476 loss)
I0916 22:59:05.750010 13570 sgd_solver.cpp:136] Iteration 45200, lr = 0.0001, m = 0.9
I0916 22:59:25.336900 13570 solver.cpp:314] Iteration 45300 (5.10559 iter/s, 19.5864s/100 iter), loss = 0.0730647
I0916 22:59:25.336997 13570 solver.cpp:336]     Train net output #0: loss = 0.0730645 (* 1 = 0.0730645 loss)
I0916 22:59:25.337014 13570 sgd_solver.cpp:136] Iteration 45300, lr = 0.0001, m = 0.9
I0916 22:59:45.102131 13570 solver.cpp:314] Iteration 45400 (5.05953 iter/s, 19.7647s/100 iter), loss = 0.065586
I0916 22:59:45.102341 13570 solver.cpp:336]     Train net output #0: loss = 0.0655859 (* 1 = 0.0655859 loss)
I0916 22:59:45.102398 13570 sgd_solver.cpp:136] Iteration 45400, lr = 0.0001, m = 0.9
I0916 22:59:54.487807 13578 data_reader.cpp:305] Starting prefetch of epoch 27
I0916 23:00:04.648216 13570 solver.cpp:314] Iteration 45500 (5.11625 iter/s, 19.5456s/100 iter), loss = 0.0766896
I0916 23:00:04.648432 13570 solver.cpp:336]     Train net output #0: loss = 0.0766894 (* 1 = 0.0766894 loss)
I0916 23:00:04.648439 13570 sgd_solver.cpp:136] Iteration 45500, lr = 0.0001, m = 0.9
I0916 23:00:24.368736 13570 solver.cpp:314] Iteration 45600 (5.071 iter/s, 19.72s/100 iter), loss = 0.0966067
I0916 23:00:24.368760 13570 solver.cpp:336]     Train net output #0: loss = 0.0966066 (* 1 = 0.0966066 loss)
I0916 23:00:24.368767 13570 sgd_solver.cpp:136] Iteration 45600, lr = 0.0001, m = 0.9
I0916 23:00:44.123468 13570 solver.cpp:314] Iteration 45700 (5.06222 iter/s, 19.7542s/100 iter), loss = 0.0405651
I0916 23:00:44.123540 13570 solver.cpp:336]     Train net output #0: loss = 0.040565 (* 1 = 0.040565 loss)
I0916 23:00:44.123548 13570 sgd_solver.cpp:136] Iteration 45700, lr = 0.0001, m = 0.9
I0916 23:00:59.373009 13578 data_reader.cpp:305] Starting prefetch of epoch 28
I0916 23:01:03.660224 13570 solver.cpp:314] Iteration 45800 (5.1187 iter/s, 19.5362s/100 iter), loss = 0.1034
I0916 23:01:03.660248 13570 solver.cpp:336]     Train net output #0: loss = 0.103399 (* 1 = 0.103399 loss)
I0916 23:01:03.660254 13570 sgd_solver.cpp:136] Iteration 45800, lr = 0.0001, m = 0.9
I0916 23:01:23.210969 13570 solver.cpp:314] Iteration 45900 (5.11504 iter/s, 19.5502s/100 iter), loss = 0.0451688
I0916 23:01:23.217470 13570 solver.cpp:336]     Train net output #0: loss = 0.0451686 (* 1 = 0.0451686 loss)
I0916 23:01:23.217505 13570 sgd_solver.cpp:136] Iteration 45900, lr = 0.0001, m = 0.9
I0916 23:01:31.964310 13574 data_reader.cpp:305] Starting prefetch of epoch 29
I0916 23:01:42.889168 13570 solver.cpp:368] Sparsity after update:
I0916 23:01:42.894881 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 23:01:42.894896 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 23:01:42.894906 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 23:01:42.894908 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 23:01:42.894912 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 23:01:42.894917 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 23:01:42.894919 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 23:01:42.894922 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 23:01:42.894925 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 23:01:42.894928 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 23:01:42.894932 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 23:01:42.894937 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 23:01:42.894939 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 23:01:42.894943 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 23:01:42.894948 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 23:01:42.894951 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 23:01:42.894955 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 23:01:42.894959 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 23:01:42.894963 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 23:01:42.894976 13570 solver.cpp:563] Iteration 46000, Testing net (#0)
I0916 23:01:54.388907 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.954587
I0916 23:01:54.388998 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 23:01:54.389006 13570 solver.cpp:655]     Test net output #2: loss = 0.161903 (* 1 = 0.161903 loss)
I0916 23:01:54.389034 13570 solver.cpp:265] [MultiGPU] Tests completed in 11.4937s
I0916 23:01:54.593240 13570 solver.cpp:314] Iteration 46000 (3.1866 iter/s, 31.3814s/100 iter), loss = 0.0616718
I0916 23:01:54.593266 13570 solver.cpp:336]     Train net output #0: loss = 0.0616716 (* 1 = 0.0616716 loss)
I0916 23:01:54.593271 13570 sgd_solver.cpp:136] Iteration 46000, lr = 0.0001, m = 0.9
I0916 23:02:14.068815 13570 solver.cpp:314] Iteration 46100 (5.13478 iter/s, 19.475s/100 iter), loss = 0.0465749
I0916 23:02:14.068836 13570 solver.cpp:336]     Train net output #0: loss = 0.0465748 (* 1 = 0.0465748 loss)
I0916 23:02:14.068841 13570 sgd_solver.cpp:136] Iteration 46100, lr = 0.0001, m = 0.9
I0916 23:02:15.894227 13546 data_reader.cpp:305] Starting prefetch of epoch 21
I0916 23:02:33.664311 13570 solver.cpp:314] Iteration 46200 (5.10336 iter/s, 19.5949s/100 iter), loss = 0.0416221
I0916 23:02:33.664376 13570 solver.cpp:336]     Train net output #0: loss = 0.0416218 (* 1 = 0.0416218 loss)
I0916 23:02:33.664381 13570 sgd_solver.cpp:136] Iteration 46200, lr = 0.0001, m = 0.9
I0916 23:02:53.357906 13570 solver.cpp:314] Iteration 46300 (5.07794 iter/s, 19.693s/100 iter), loss = 0.0599367
I0916 23:02:53.357996 13570 solver.cpp:336]     Train net output #0: loss = 0.0599365 (* 1 = 0.0599365 loss)
I0916 23:02:53.358031 13570 sgd_solver.cpp:136] Iteration 46300, lr = 0.0001, m = 0.9
I0916 23:03:12.994031 13570 solver.cpp:314] Iteration 46400 (5.0928 iter/s, 19.6356s/100 iter), loss = 0.0679505
I0916 23:03:12.994102 13570 solver.cpp:336]     Train net output #0: loss = 0.0679503 (* 1 = 0.0679503 loss)
I0916 23:03:12.994107 13570 sgd_solver.cpp:136] Iteration 46400, lr = 0.0001, m = 0.9
I0916 23:03:20.941064 13578 data_reader.cpp:305] Starting prefetch of epoch 29
I0916 23:03:32.515727 13570 solver.cpp:314] Iteration 46500 (5.12265 iter/s, 19.5212s/100 iter), loss = 0.0923736
I0916 23:03:32.515756 13570 solver.cpp:336]     Train net output #0: loss = 0.0923734 (* 1 = 0.0923734 loss)
I0916 23:03:32.515763 13570 sgd_solver.cpp:136] Iteration 46500, lr = 0.0001, m = 0.9
I0916 23:03:52.313277 13570 solver.cpp:314] Iteration 46600 (5.05127 iter/s, 19.797s/100 iter), loss = 0.040538
I0916 23:03:52.313330 13570 solver.cpp:336]     Train net output #0: loss = 0.0405378 (* 1 = 0.0405378 loss)
I0916 23:03:52.313335 13570 sgd_solver.cpp:136] Iteration 46600, lr = 0.0001, m = 0.9
I0916 23:03:53.382633 13573 data_reader.cpp:305] Starting prefetch of epoch 30
I0916 23:04:11.977183 13570 solver.cpp:314] Iteration 46700 (5.0856 iter/s, 19.6634s/100 iter), loss = 0.0771628
I0916 23:04:11.977212 13570 solver.cpp:336]     Train net output #0: loss = 0.0771626 (* 1 = 0.0771626 loss)
I0916 23:04:11.977219 13570 sgd_solver.cpp:136] Iteration 46700, lr = 0.0001, m = 0.9
I0916 23:04:31.718873 13570 solver.cpp:314] Iteration 46800 (5.06556 iter/s, 19.7411s/100 iter), loss = 0.0840155
I0916 23:04:31.718932 13570 solver.cpp:336]     Train net output #0: loss = 0.0840153 (* 1 = 0.0840153 loss)
I0916 23:04:31.718937 13570 sgd_solver.cpp:136] Iteration 46800, lr = 0.0001, m = 0.9
I0916 23:04:51.263238 13570 solver.cpp:314] Iteration 46900 (5.11671 iter/s, 19.5438s/100 iter), loss = 0.108085
I0916 23:04:51.263265 13570 solver.cpp:336]     Train net output #0: loss = 0.108084 (* 1 = 0.108084 loss)
I0916 23:04:51.263272 13570 sgd_solver.cpp:136] Iteration 46900, lr = 0.0001, m = 0.9
I0916 23:04:58.283468 13576 data_reader.cpp:305] Starting prefetch of epoch 32
I0916 23:05:11.095844 13570 solver.cpp:368] Sparsity after update:
I0916 23:05:11.102035 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 23:05:11.102046 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 23:05:11.102052 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 23:05:11.102056 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 23:05:11.102059 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 23:05:11.102063 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 23:05:11.102066 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 23:05:11.102069 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 23:05:11.102078 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 23:05:11.102082 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 23:05:11.102085 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 23:05:11.102093 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 23:05:11.102097 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 23:05:11.102100 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 23:05:11.102103 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 23:05:11.102107 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 23:05:11.102110 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 23:05:11.102113 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 23:05:11.102116 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 23:05:11.271620 13570 solver.cpp:314] Iteration 47000 (4.99804 iter/s, 20.0078s/100 iter), loss = 0.044046
I0916 23:05:11.271666 13570 solver.cpp:336]     Train net output #0: loss = 0.0440458 (* 1 = 0.0440458 loss)
I0916 23:05:11.271677 13570 sgd_solver.cpp:136] Iteration 47000, lr = 0.0001, m = 0.9
I0916 23:05:31.018438 13570 solver.cpp:314] Iteration 47100 (5.06425 iter/s, 19.7463s/100 iter), loss = 0.0639589
I0916 23:05:31.018465 13570 solver.cpp:336]     Train net output #0: loss = 0.0639587 (* 1 = 0.0639587 loss)
I0916 23:05:31.018472 13570 sgd_solver.cpp:136] Iteration 47100, lr = 0.0001, m = 0.9
I0916 23:05:51.124106 13570 solver.cpp:314] Iteration 47200 (4.97386 iter/s, 20.1051s/100 iter), loss = 0.0573039
I0916 23:05:51.124186 13570 solver.cpp:336]     Train net output #0: loss = 0.0573037 (* 1 = 0.0573037 loss)
I0916 23:05:51.124194 13570 sgd_solver.cpp:136] Iteration 47200, lr = 0.0001, m = 0.9
I0916 23:06:04.267562 13576 data_reader.cpp:305] Starting prefetch of epoch 33
I0916 23:06:11.073324 13570 solver.cpp:314] Iteration 47300 (5.01287 iter/s, 19.9487s/100 iter), loss = 0.183567
I0916 23:06:11.073348 13570 solver.cpp:336]     Train net output #0: loss = 0.183567 (* 1 = 0.183567 loss)
I0916 23:06:11.073354 13570 sgd_solver.cpp:136] Iteration 47300, lr = 0.0001, m = 0.9
I0916 23:06:30.985306 13570 solver.cpp:314] Iteration 47400 (5.02224 iter/s, 19.9114s/100 iter), loss = 0.0413993
I0916 23:06:30.985384 13570 solver.cpp:336]     Train net output #0: loss = 0.0413991 (* 1 = 0.0413991 loss)
I0916 23:06:30.985393 13570 sgd_solver.cpp:136] Iteration 47400, lr = 0.0001, m = 0.9
I0916 23:06:37.222122 13544 data_reader.cpp:305] Starting prefetch of epoch 28
I0916 23:06:50.784062 13570 solver.cpp:314] Iteration 47500 (5.05096 iter/s, 19.7982s/100 iter), loss = 0.0486552
I0916 23:06:50.784086 13570 solver.cpp:336]     Train net output #0: loss = 0.048655 (* 1 = 0.048655 loss)
I0916 23:06:50.784093 13570 sgd_solver.cpp:136] Iteration 47500, lr = 0.0001, m = 0.9
I0916 23:07:10.250844 13570 solver.cpp:314] Iteration 47600 (5.1371 iter/s, 19.4662s/100 iter), loss = 0.0829392
I0916 23:07:10.254142 13570 solver.cpp:336]     Train net output #0: loss = 0.0829389 (* 1 = 0.0829389 loss)
I0916 23:07:10.254163 13570 sgd_solver.cpp:136] Iteration 47600, lr = 0.0001, m = 0.9
I0916 23:07:30.057180 13570 solver.cpp:314] Iteration 47700 (5.04903 iter/s, 19.8058s/100 iter), loss = 0.0675972
I0916 23:07:30.057205 13570 solver.cpp:336]     Train net output #0: loss = 0.067597 (* 1 = 0.067597 loss)
I0916 23:07:30.057210 13570 sgd_solver.cpp:136] Iteration 47700, lr = 0.0001, m = 0.9
I0916 23:07:42.585299 13546 data_reader.cpp:305] Starting prefetch of epoch 22
I0916 23:07:50.109248 13570 solver.cpp:314] Iteration 47800 (4.98716 iter/s, 20.0515s/100 iter), loss = 0.0875142
I0916 23:07:50.109292 13570 solver.cpp:336]     Train net output #0: loss = 0.087514 (* 1 = 0.087514 loss)
I0916 23:07:50.109300 13570 sgd_solver.cpp:136] Iteration 47800, lr = 0.0001, m = 0.9
I0916 23:08:09.836457 13570 solver.cpp:314] Iteration 47900 (5.06928 iter/s, 19.7267s/100 iter), loss = 0.0686748
I0916 23:08:09.836482 13570 solver.cpp:336]     Train net output #0: loss = 0.0686746 (* 1 = 0.0686746 loss)
I0916 23:08:09.836485 13570 sgd_solver.cpp:136] Iteration 47900, lr = 0.0001, m = 0.9
I0916 23:08:29.165701 13570 solver.cpp:368] Sparsity after update:
I0916 23:08:29.170028 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 23:08:29.170038 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 23:08:29.170047 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 23:08:29.170051 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 23:08:29.170055 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 23:08:29.170058 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 23:08:29.170063 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 23:08:29.170066 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 23:08:29.170070 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 23:08:29.170079 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 23:08:29.170083 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 23:08:29.170087 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 23:08:29.170091 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 23:08:29.170095 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 23:08:29.170099 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 23:08:29.170102 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 23:08:29.170107 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 23:08:29.170110 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 23:08:29.170114 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 23:08:29.170126 13570 solver.cpp:563] Iteration 48000, Testing net (#0)
I0916 23:08:32.575701 13600 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 23:08:40.473817 13568 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 23:08:40.830111 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.951723
I0916 23:08:40.830137 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 23:08:40.830142 13570 solver.cpp:655]     Test net output #2: loss = 0.148438 (* 1 = 0.148438 loss)
I0916 23:08:40.830174 13570 solver.cpp:265] [MultiGPU] Tests completed in 11.6597s
I0916 23:08:41.047111 13570 solver.cpp:314] Iteration 48000 (3.20412 iter/s, 31.2098s/100 iter), loss = 0.167298
I0916 23:08:41.047134 13570 solver.cpp:336]     Train net output #0: loss = 0.167297 (* 1 = 0.167297 loss)
I0916 23:08:41.047140 13570 sgd_solver.cpp:136] Iteration 48000, lr = 0.0001, m = 0.9
I0916 23:09:00.545398 13570 solver.cpp:314] Iteration 48100 (5.1288 iter/s, 19.4977s/100 iter), loss = 0.0403825
I0916 23:09:00.545506 13570 solver.cpp:336]     Train net output #0: loss = 0.0403823 (* 1 = 0.0403823 loss)
I0916 23:09:00.545513 13570 sgd_solver.cpp:136] Iteration 48100, lr = 0.0001, m = 0.9
I0916 23:09:20.007033 13570 solver.cpp:314] Iteration 48200 (5.13846 iter/s, 19.4611s/100 iter), loss = 0.0581615
I0916 23:09:20.007061 13570 solver.cpp:336]     Train net output #0: loss = 0.0581613 (* 1 = 0.0581613 loss)
I0916 23:09:20.007066 13570 sgd_solver.cpp:136] Iteration 48200, lr = 0.0001, m = 0.9
I0916 23:09:31.376377 13574 data_reader.cpp:305] Starting prefetch of epoch 30
I0916 23:09:39.615453 13570 solver.cpp:314] Iteration 48300 (5.09999 iter/s, 19.6079s/100 iter), loss = 0.0396142
I0916 23:09:39.615475 13570 solver.cpp:336]     Train net output #0: loss = 0.039614 (* 1 = 0.039614 loss)
I0916 23:09:39.615481 13570 sgd_solver.cpp:136] Iteration 48300, lr = 0.0001, m = 0.9
I0916 23:09:59.044149 13570 solver.cpp:314] Iteration 48400 (5.14717 iter/s, 19.4282s/100 iter), loss = 0.0550134
I0916 23:09:59.044173 13570 solver.cpp:336]     Train net output #0: loss = 0.0550132 (* 1 = 0.0550132 loss)
I0916 23:09:59.044178 13570 sgd_solver.cpp:136] Iteration 48400, lr = 0.0001, m = 0.9
I0916 23:10:18.462633 13570 solver.cpp:314] Iteration 48500 (5.14988 iter/s, 19.4179s/100 iter), loss = 0.0494246
I0916 23:10:18.462688 13570 solver.cpp:336]     Train net output #0: loss = 0.0494244 (* 1 = 0.0494244 loss)
I0916 23:10:18.462693 13570 sgd_solver.cpp:136] Iteration 48500, lr = 0.0001, m = 0.9
I0916 23:10:35.382484 13578 data_reader.cpp:305] Starting prefetch of epoch 30
I0916 23:10:37.709789 13570 solver.cpp:314] Iteration 48600 (5.19572 iter/s, 19.2466s/100 iter), loss = 0.0486367
I0916 23:10:37.709813 13570 solver.cpp:336]     Train net output #0: loss = 0.0486365 (* 1 = 0.0486365 loss)
I0916 23:10:37.709817 13570 sgd_solver.cpp:136] Iteration 48600, lr = 0.0001, m = 0.9
I0916 23:10:57.235476 13570 solver.cpp:314] Iteration 48700 (5.1216 iter/s, 19.5251s/100 iter), loss = 0.0513759
I0916 23:10:57.235545 13570 solver.cpp:336]     Train net output #0: loss = 0.0513757 (* 1 = 0.0513757 loss)
I0916 23:10:57.235554 13570 sgd_solver.cpp:136] Iteration 48700, lr = 0.0001, m = 0.9
I0916 23:11:07.572787 13544 data_reader.cpp:305] Starting prefetch of epoch 29
I0916 23:11:16.763175 13570 solver.cpp:314] Iteration 48800 (5.12107 iter/s, 19.5272s/100 iter), loss = 0.0914929
I0916 23:11:16.763200 13570 solver.cpp:336]     Train net output #0: loss = 0.0914926 (* 1 = 0.0914926 loss)
I0916 23:11:16.763206 13570 sgd_solver.cpp:136] Iteration 48800, lr = 0.0001, m = 0.9
I0916 23:11:36.442697 13570 solver.cpp:314] Iteration 48900 (5.08157 iter/s, 19.679s/100 iter), loss = 0.0566771
I0916 23:11:36.442996 13570 solver.cpp:336]     Train net output #0: loss = 0.0566769 (* 1 = 0.0566769 loss)
I0916 23:11:36.443004 13570 sgd_solver.cpp:136] Iteration 48900, lr = 0.0001, m = 0.9
I0916 23:11:55.719204 13570 solver.cpp:368] Sparsity after update:
I0916 23:11:55.726717 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 23:11:55.726727 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 23:11:55.726735 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 23:11:55.726738 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 23:11:55.726742 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 23:11:55.726744 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 23:11:55.726747 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 23:11:55.726752 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 23:11:55.726754 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 23:11:55.726758 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 23:11:55.726760 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 23:11:55.726763 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 23:11:55.726773 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 23:11:55.726778 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 23:11:55.726783 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 23:11:55.726789 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 23:11:55.726795 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 23:11:55.726801 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 23:11:55.726806 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 23:11:55.897008 13570 solver.cpp:314] Iteration 49000 (5.14039 iter/s, 19.4538s/100 iter), loss = 0.0785737
I0916 23:11:55.897044 13570 solver.cpp:336]     Train net output #0: loss = 0.0785734 (* 1 = 0.0785734 loss)
I0916 23:11:55.897050 13570 sgd_solver.cpp:136] Iteration 49000, lr = 0.0001, m = 0.9
I0916 23:12:12.282450 13573 data_reader.cpp:305] Starting prefetch of epoch 31
I0916 23:12:15.379884 13570 solver.cpp:314] Iteration 49100 (5.13286 iter/s, 19.4823s/100 iter), loss = 0.0629482
I0916 23:12:15.379910 13570 solver.cpp:336]     Train net output #0: loss = 0.062948 (* 1 = 0.062948 loss)
I0916 23:12:15.379915 13570 sgd_solver.cpp:136] Iteration 49100, lr = 0.0001, m = 0.9
I0916 23:12:34.906216 13570 solver.cpp:314] Iteration 49200 (5.12143 iter/s, 19.5258s/100 iter), loss = 0.0652519
I0916 23:12:34.906241 13570 solver.cpp:336]     Train net output #0: loss = 0.0652517 (* 1 = 0.0652517 loss)
I0916 23:12:34.906249 13570 sgd_solver.cpp:136] Iteration 49200, lr = 0.0001, m = 0.9
I0916 23:12:54.302448 13570 solver.cpp:314] Iteration 49300 (5.15579 iter/s, 19.3957s/100 iter), loss = 0.0820813
I0916 23:12:54.302505 13570 solver.cpp:336]     Train net output #0: loss = 0.0820811 (* 1 = 0.0820811 loss)
I0916 23:12:54.302510 13570 sgd_solver.cpp:136] Iteration 49300, lr = 0.0001, m = 0.9
I0916 23:13:13.610623 13570 solver.cpp:314] Iteration 49400 (5.1793 iter/s, 19.3076s/100 iter), loss = 0.0663275
I0916 23:13:13.610647 13570 solver.cpp:336]     Train net output #0: loss = 0.0663273 (* 1 = 0.0663273 loss)
I0916 23:13:13.610653 13570 sgd_solver.cpp:136] Iteration 49400, lr = 0.0001, m = 0.9
I0916 23:13:16.499266 13573 data_reader.cpp:305] Starting prefetch of epoch 32
I0916 23:13:33.137508 13570 solver.cpp:314] Iteration 49500 (5.12129 iter/s, 19.5263s/100 iter), loss = 0.0541801
I0916 23:13:33.150156 13570 solver.cpp:336]     Train net output #0: loss = 0.0541799 (* 1 = 0.0541799 loss)
I0916 23:13:33.150194 13570 sgd_solver.cpp:136] Iteration 49500, lr = 0.0001, m = 0.9
I0916 23:13:52.759220 13570 solver.cpp:314] Iteration 49600 (5.09654 iter/s, 19.6212s/100 iter), loss = 0.0557167
I0916 23:13:52.759246 13570 solver.cpp:336]     Train net output #0: loss = 0.0557165 (* 1 = 0.0557165 loss)
I0916 23:13:52.759253 13570 sgd_solver.cpp:136] Iteration 49600, lr = 0.0001, m = 0.9
I0916 23:14:12.276197 13570 solver.cpp:314] Iteration 49700 (5.12389 iter/s, 19.5164s/100 iter), loss = 0.0681595
I0916 23:14:12.276252 13570 solver.cpp:336]     Train net output #0: loss = 0.0681593 (* 1 = 0.0681593 loss)
I0916 23:14:12.276260 13570 sgd_solver.cpp:136] Iteration 49700, lr = 0.0001, m = 0.9
I0916 23:14:21.078595 13576 data_reader.cpp:305] Starting prefetch of epoch 34
I0916 23:14:31.795933 13570 solver.cpp:314] Iteration 49800 (5.12316 iter/s, 19.5192s/100 iter), loss = 0.0772982
I0916 23:14:31.795963 13570 solver.cpp:336]     Train net output #0: loss = 0.077298 (* 1 = 0.077298 loss)
I0916 23:14:31.795969 13570 sgd_solver.cpp:136] Iteration 49800, lr = 0.0001, m = 0.9
I0916 23:14:51.565454 13570 solver.cpp:314] Iteration 49900 (5.05843 iter/s, 19.769s/100 iter), loss = 0.0449232
I0916 23:14:51.565521 13570 solver.cpp:336]     Train net output #0: loss = 0.0449229 (* 1 = 0.0449229 loss)
I0916 23:14:51.565526 13570 sgd_solver.cpp:136] Iteration 49900, lr = 0.0001, m = 0.9
I0916 23:14:53.557945 13544 data_reader.cpp:305] Starting prefetch of epoch 30
I0916 23:15:10.905803 13570 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/sparse/cityscapes5_jsegnet21v2_iter_50000.caffemodel
I0916 23:15:11.081578 13570 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/sparse/cityscapes5_jsegnet21v2_iter_50000.solverstate
I0916 23:15:11.092876 13570 solver.cpp:368] Sparsity after update:
I0916 23:15:11.097492 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 23:15:11.097554 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 23:15:11.097584 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 23:15:11.097600 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 23:15:11.097615 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 23:15:11.097630 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 23:15:11.097645 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 23:15:11.097661 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 23:15:11.097676 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 23:15:11.097690 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 23:15:11.097707 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 23:15:11.097721 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 23:15:11.097735 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 23:15:11.097751 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 23:15:11.097765 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 23:15:11.097781 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 23:15:11.097796 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 23:15:11.097811 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 23:15:11.097826 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 23:15:11.097853 13570 solver.cpp:563] Iteration 50000, Testing net (#0)
I0916 23:15:21.944682 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.954443
I0916 23:15:21.944780 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 23:15:21.944789 13570 solver.cpp:655]     Test net output #2: loss = 0.161965 (* 1 = 0.161965 loss)
I0916 23:15:21.944808 13570 solver.cpp:265] [MultiGPU] Tests completed in 10.8467s
I0916 23:15:22.147406 13570 solver.cpp:314] Iteration 50000 (3.26999 iter/s, 30.5811s/100 iter), loss = 0.0657246
I0916 23:15:22.147440 13570 solver.cpp:336]     Train net output #0: loss = 0.0657243 (* 1 = 0.0657243 loss)
I0916 23:15:22.147444 13570 sgd_solver.cpp:136] Iteration 50000, lr = 0.0001, m = 0.9
I0916 23:15:37.047281 13574 data_reader.cpp:305] Starting prefetch of epoch 31
I0916 23:15:41.935648 13570 solver.cpp:314] Iteration 50100 (5.05365 iter/s, 19.7877s/100 iter), loss = 0.0752785
I0916 23:15:41.935678 13570 solver.cpp:336]     Train net output #0: loss = 0.0752783 (* 1 = 0.0752783 loss)
I0916 23:15:41.935685 13570 sgd_solver.cpp:136] Iteration 50100, lr = 0.0001, m = 0.9
I0916 23:16:01.617537 13570 solver.cpp:314] Iteration 50200 (5.08096 iter/s, 19.6813s/100 iter), loss = 0.0778879
I0916 23:16:01.617583 13570 solver.cpp:336]     Train net output #0: loss = 0.0778877 (* 1 = 0.0778877 loss)
I0916 23:16:01.617586 13570 sgd_solver.cpp:136] Iteration 50200, lr = 0.0001, m = 0.9
I0916 23:16:21.540587 13570 solver.cpp:314] Iteration 50300 (5.01945 iter/s, 19.9225s/100 iter), loss = 0.0407254
I0916 23:16:21.540616 13570 solver.cpp:336]     Train net output #0: loss = 0.0407252 (* 1 = 0.0407252 loss)
I0916 23:16:21.540619 13570 sgd_solver.cpp:136] Iteration 50300, lr = 0.0001, m = 0.9
I0916 23:16:41.208789 13570 solver.cpp:314] Iteration 50400 (5.08449 iter/s, 19.6676s/100 iter), loss = 0.0531592
I0916 23:16:41.208940 13570 solver.cpp:336]     Train net output #0: loss = 0.053159 (* 1 = 0.053159 loss)
I0916 23:16:41.208961 13570 sgd_solver.cpp:136] Iteration 50400, lr = 0.0001, m = 0.9
I0916 23:16:42.418776 13574 data_reader.cpp:305] Starting prefetch of epoch 32
I0916 23:17:00.890491 13570 solver.cpp:314] Iteration 50500 (5.081 iter/s, 19.6812s/100 iter), loss = 0.073773
I0916 23:17:00.890517 13570 solver.cpp:336]     Train net output #0: loss = 0.0737728 (* 1 = 0.0737728 loss)
I0916 23:17:00.890522 13570 sgd_solver.cpp:136] Iteration 50500, lr = 0.0001, m = 0.9
I0916 23:17:20.560623 13570 solver.cpp:314] Iteration 50600 (5.08399 iter/s, 19.6696s/100 iter), loss = 0.0679126
I0916 23:17:20.560688 13570 solver.cpp:336]     Train net output #0: loss = 0.0679124 (* 1 = 0.0679124 loss)
I0916 23:17:20.560695 13570 sgd_solver.cpp:136] Iteration 50600, lr = 0.0001, m = 0.9
I0916 23:17:40.067713 13570 solver.cpp:314] Iteration 50700 (5.12648 iter/s, 19.5065s/100 iter), loss = 0.0465317
I0916 23:17:40.067735 13570 solver.cpp:336]     Train net output #0: loss = 0.0465315 (* 1 = 0.0465315 loss)
I0916 23:17:40.067741 13570 sgd_solver.cpp:136] Iteration 50700, lr = 0.0001, m = 0.9
I0916 23:17:47.345473 13578 data_reader.cpp:305] Starting prefetch of epoch 31
I0916 23:17:59.768790 13570 solver.cpp:314] Iteration 50800 (5.07601 iter/s, 19.7005s/100 iter), loss = 0.0954666
I0916 23:17:59.768846 13570 solver.cpp:336]     Train net output #0: loss = 0.0954664 (* 1 = 0.0954664 loss)
I0916 23:17:59.768853 13570 sgd_solver.cpp:136] Iteration 50800, lr = 0.0001, m = 0.9
I0916 23:18:19.484334 13570 solver.cpp:314] Iteration 50900 (5.07228 iter/s, 19.715s/100 iter), loss = 0.0642493
I0916 23:18:19.484369 13570 solver.cpp:336]     Train net output #0: loss = 0.0642491 (* 1 = 0.0642491 loss)
I0916 23:18:19.484377 13570 sgd_solver.cpp:136] Iteration 50900, lr = 0.0001, m = 0.9
I0916 23:18:19.951032 13573 data_reader.cpp:305] Starting prefetch of epoch 33
I0916 23:18:39.156882 13570 solver.cpp:368] Sparsity after update:
I0916 23:18:39.161609 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 23:18:39.161702 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 23:18:39.161733 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 23:18:39.161747 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 23:18:39.161759 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 23:18:39.161772 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 23:18:39.161782 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 23:18:39.161794 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 23:18:39.161806 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 23:18:39.161818 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 23:18:39.161830 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 23:18:39.161841 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 23:18:39.161854 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 23:18:39.161865 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 23:18:39.161877 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 23:18:39.161888 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 23:18:39.161900 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 23:18:39.161916 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 23:18:39.161928 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 23:18:39.350407 13570 solver.cpp:314] Iteration 51000 (5.03385 iter/s, 19.8655s/100 iter), loss = 0.0254339
I0916 23:18:39.350471 13570 solver.cpp:336]     Train net output #0: loss = 0.0254337 (* 1 = 0.0254337 loss)
I0916 23:18:39.350488 13570 sgd_solver.cpp:136] Iteration 51000, lr = 0.0001, m = 0.9
I0916 23:18:58.812929 13570 solver.cpp:314] Iteration 51100 (5.13822 iter/s, 19.462s/100 iter), loss = 0.0775203
I0916 23:18:58.812957 13570 solver.cpp:336]     Train net output #0: loss = 0.0775201 (* 1 = 0.0775201 loss)
I0916 23:18:58.812963 13570 sgd_solver.cpp:136] Iteration 51100, lr = 0.0001, m = 0.9
I0916 23:19:18.717762 13570 solver.cpp:314] Iteration 51200 (5.02405 iter/s, 19.9043s/100 iter), loss = 0.0628552
I0916 23:19:18.717829 13570 solver.cpp:336]     Train net output #0: loss = 0.062855 (* 1 = 0.062855 loss)
I0916 23:19:18.717836 13570 sgd_solver.cpp:136] Iteration 51200, lr = 0.0001, m = 0.9
I0916 23:19:25.179272 13574 data_reader.cpp:305] Starting prefetch of epoch 33
I0916 23:19:38.640662 13570 solver.cpp:314] Iteration 51300 (5.01949 iter/s, 19.9223s/100 iter), loss = 0.0858505
I0916 23:19:38.640687 13570 solver.cpp:336]     Train net output #0: loss = 0.0858504 (* 1 = 0.0858504 loss)
I0916 23:19:38.640694 13570 sgd_solver.cpp:136] Iteration 51300, lr = 0.0001, m = 0.9
I0916 23:19:58.380908 13570 solver.cpp:314] Iteration 51400 (5.06593 iter/s, 19.7397s/100 iter), loss = 0.0662465
I0916 23:19:58.380959 13570 solver.cpp:336]     Train net output #0: loss = 0.0662463 (* 1 = 0.0662463 loss)
I0916 23:19:58.380964 13570 sgd_solver.cpp:136] Iteration 51400, lr = 0.0001, m = 0.9
I0916 23:20:18.494060 13570 solver.cpp:314] Iteration 51500 (4.97201 iter/s, 20.1126s/100 iter), loss = 0.0435035
I0916 23:20:18.494104 13570 solver.cpp:336]     Train net output #0: loss = 0.0435033 (* 1 = 0.0435033 loss)
I0916 23:20:18.494112 13570 sgd_solver.cpp:136] Iteration 51500, lr = 0.0001, m = 0.9
I0916 23:20:30.957211 13546 data_reader.cpp:305] Starting prefetch of epoch 23
I0916 23:20:38.390995 13570 solver.cpp:314] Iteration 51600 (5.02604 iter/s, 19.8964s/100 iter), loss = 0.0658213
I0916 23:20:38.391019 13570 solver.cpp:336]     Train net output #0: loss = 0.0658211 (* 1 = 0.0658211 loss)
I0916 23:20:38.391024 13570 sgd_solver.cpp:136] Iteration 51600, lr = 0.0001, m = 0.9
I0916 23:20:57.935497 13570 solver.cpp:314] Iteration 51700 (5.11667 iter/s, 19.544s/100 iter), loss = 0.0633818
I0916 23:20:57.935570 13570 solver.cpp:336]     Train net output #0: loss = 0.0633816 (* 1 = 0.0633816 loss)
I0916 23:20:57.935587 13570 sgd_solver.cpp:136] Iteration 51700, lr = 0.0001, m = 0.9
I0916 23:21:03.521184 13544 data_reader.cpp:305] Starting prefetch of epoch 31
I0916 23:21:17.717602 13570 solver.cpp:314] Iteration 51800 (5.05521 iter/s, 19.7816s/100 iter), loss = 0.0672557
I0916 23:21:17.717625 13570 solver.cpp:336]     Train net output #0: loss = 0.0672556 (* 1 = 0.0672556 loss)
I0916 23:21:17.717631 13570 sgd_solver.cpp:136] Iteration 51800, lr = 0.0001, m = 0.9
I0916 23:21:36.991909 13570 solver.cpp:314] Iteration 51900 (5.1884 iter/s, 19.2738s/100 iter), loss = 0.0854909
I0916 23:21:36.991966 13570 solver.cpp:336]     Train net output #0: loss = 0.0854907 (* 1 = 0.0854907 loss)
I0916 23:21:36.991973 13570 sgd_solver.cpp:136] Iteration 51900, lr = 0.0001, m = 0.9
I0916 23:21:56.403803 13570 solver.cpp:368] Sparsity after update:
I0916 23:21:56.409811 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 23:21:56.409826 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 23:21:56.409834 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 23:21:56.409838 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 23:21:56.409842 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 23:21:56.409845 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 23:21:56.409849 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 23:21:56.409853 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 23:21:56.409857 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 23:21:56.409860 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 23:21:56.409864 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 23:21:56.409868 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 23:21:56.409870 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 23:21:56.409873 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 23:21:56.409876 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 23:21:56.409879 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 23:21:56.409883 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 23:21:56.409885 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 23:21:56.409888 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 23:21:56.409899 13570 solver.cpp:563] Iteration 52000, Testing net (#0)
I0916 23:22:00.038476 13594 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 23:22:08.191260 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.951679
I0916 23:22:08.192102 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 23:22:08.192112 13570 solver.cpp:655]     Test net output #2: loss = 0.148512 (* 1 = 0.148512 loss)
I0916 23:22:08.192142 13570 solver.cpp:265] [MultiGPU] Tests completed in 11.7819s
I0916 23:22:08.398875 13570 solver.cpp:314] Iteration 52000 (3.1841 iter/s, 31.4061s/100 iter), loss = 0.0566424
I0916 23:22:08.398900 13570 solver.cpp:336]     Train net output #0: loss = 0.0566423 (* 1 = 0.0566423 loss)
I0916 23:22:08.398905 13570 sgd_solver.cpp:136] Iteration 52000, lr = 0.0001, m = 0.9
I0916 23:22:19.972374 13578 data_reader.cpp:305] Starting prefetch of epoch 32
I0916 23:22:28.007223 13570 solver.cpp:314] Iteration 52100 (5.10001 iter/s, 19.6078s/100 iter), loss = 0.0336577
I0916 23:22:28.007247 13570 solver.cpp:336]     Train net output #0: loss = 0.0336576 (* 1 = 0.0336576 loss)
I0916 23:22:28.007251 13570 sgd_solver.cpp:136] Iteration 52100, lr = 0.0001, m = 0.9
I0916 23:22:47.796671 13570 solver.cpp:314] Iteration 52200 (5.05334 iter/s, 19.7889s/100 iter), loss = 0.0623757
I0916 23:22:47.796739 13570 solver.cpp:336]     Train net output #0: loss = 0.0623756 (* 1 = 0.0623756 loss)
I0916 23:22:47.796746 13570 sgd_solver.cpp:136] Iteration 52200, lr = 0.0001, m = 0.9
I0916 23:22:52.506954 13544 data_reader.cpp:305] Starting prefetch of epoch 32
I0916 23:23:07.529757 13570 solver.cpp:314] Iteration 52300 (5.06777 iter/s, 19.7325s/100 iter), loss = 0.0887764
I0916 23:23:07.529780 13570 solver.cpp:336]     Train net output #0: loss = 0.0887762 (* 1 = 0.0887762 loss)
I0916 23:23:07.529784 13570 sgd_solver.cpp:136] Iteration 52300, lr = 0.0001, m = 0.9
I0916 23:23:27.206051 13570 solver.cpp:314] Iteration 52400 (5.0824 iter/s, 19.6757s/100 iter), loss = 0.0562745
I0916 23:23:27.206120 13570 solver.cpp:336]     Train net output #0: loss = 0.0562743 (* 1 = 0.0562743 loss)
I0916 23:23:27.206126 13570 sgd_solver.cpp:136] Iteration 52400, lr = 0.0001, m = 0.9
I0916 23:23:46.933117 13570 solver.cpp:314] Iteration 52500 (5.06932 iter/s, 19.7265s/100 iter), loss = 0.0738185
I0916 23:23:46.933143 13570 solver.cpp:336]     Train net output #0: loss = 0.0738183 (* 1 = 0.0738183 loss)
I0916 23:23:46.933151 13570 sgd_solver.cpp:136] Iteration 52500, lr = 0.0001, m = 0.9
I0916 23:23:57.683063 13573 data_reader.cpp:305] Starting prefetch of epoch 34
I0916 23:24:06.408330 13570 solver.cpp:314] Iteration 52600 (5.13488 iter/s, 19.4747s/100 iter), loss = 0.0765972
I0916 23:24:06.408362 13570 solver.cpp:336]     Train net output #0: loss = 0.0765971 (* 1 = 0.0765971 loss)
I0916 23:24:06.408368 13570 sgd_solver.cpp:136] Iteration 52600, lr = 0.0001, m = 0.9
I0916 23:24:25.928385 13570 solver.cpp:314] Iteration 52700 (5.12308 iter/s, 19.5195s/100 iter), loss = 0.120942
I0916 23:24:25.928407 13570 solver.cpp:336]     Train net output #0: loss = 0.120942 (* 1 = 0.120942 loss)
I0916 23:24:25.928411 13570 sgd_solver.cpp:136] Iteration 52700, lr = 0.0001, m = 0.9
I0916 23:24:45.386718 13570 solver.cpp:314] Iteration 52800 (5.13933 iter/s, 19.4578s/100 iter), loss = 0.0744007
I0916 23:24:45.386787 13570 solver.cpp:336]     Train net output #0: loss = 0.0744006 (* 1 = 0.0744006 loss)
I0916 23:24:45.386796 13570 sgd_solver.cpp:136] Iteration 52800, lr = 0.0001, m = 0.9
I0916 23:25:01.952246 13576 data_reader.cpp:305] Starting prefetch of epoch 35
I0916 23:25:04.884891 13570 solver.cpp:314] Iteration 52900 (5.12883 iter/s, 19.4976s/100 iter), loss = 0.0575038
I0916 23:25:04.884914 13570 solver.cpp:336]     Train net output #0: loss = 0.0575037 (* 1 = 0.0575037 loss)
I0916 23:25:04.884918 13570 sgd_solver.cpp:136] Iteration 52900, lr = 0.0001, m = 0.9
I0916 23:25:24.362637 13570 solver.cpp:368] Sparsity after update:
I0916 23:25:24.365430 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 23:25:24.365486 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 23:25:24.365515 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 23:25:24.365525 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 23:25:24.365532 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 23:25:24.365540 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 23:25:24.365548 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 23:25:24.365556 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 23:25:24.365564 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 23:25:24.365572 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 23:25:24.365581 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 23:25:24.365589 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 23:25:24.365597 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 23:25:24.365605 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 23:25:24.365613 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 23:25:24.365622 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 23:25:24.365630 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 23:25:24.365639 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 23:25:24.365648 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 23:25:24.551681 13570 solver.cpp:314] Iteration 53000 (5.08486 iter/s, 19.6662s/100 iter), loss = 0.0500414
I0916 23:25:24.551708 13570 solver.cpp:336]     Train net output #0: loss = 0.0500412 (* 1 = 0.0500412 loss)
I0916 23:25:24.551715 13570 sgd_solver.cpp:136] Iteration 53000, lr = 0.0001, m = 0.9
I0916 23:25:34.518801 13574 data_reader.cpp:305] Starting prefetch of epoch 34
I0916 23:25:43.958899 13570 solver.cpp:314] Iteration 53100 (5.15287 iter/s, 19.4067s/100 iter), loss = 0.0604412
I0916 23:25:43.958923 13570 solver.cpp:336]     Train net output #0: loss = 0.0604411 (* 1 = 0.0604411 loss)
I0916 23:25:43.958927 13570 sgd_solver.cpp:136] Iteration 53100, lr = 0.0001, m = 0.9
I0916 23:26:03.614876 13570 solver.cpp:314] Iteration 53200 (5.08765 iter/s, 19.6554s/100 iter), loss = 0.0505332
I0916 23:26:03.614962 13570 solver.cpp:336]     Train net output #0: loss = 0.0505331 (* 1 = 0.0505331 loss)
I0916 23:26:03.614969 13570 sgd_solver.cpp:136] Iteration 53200, lr = 0.0001, m = 0.9
I0916 23:26:23.051179 13570 solver.cpp:314] Iteration 53300 (5.14515 iter/s, 19.4358s/100 iter), loss = 0.0616834
I0916 23:26:23.051200 13570 solver.cpp:336]     Train net output #0: loss = 0.0616833 (* 1 = 0.0616833 loss)
I0916 23:26:23.051204 13570 sgd_solver.cpp:136] Iteration 53300, lr = 0.0001, m = 0.9
I0916 23:26:38.807606 13573 data_reader.cpp:305] Starting prefetch of epoch 35
I0916 23:26:42.484577 13570 solver.cpp:314] Iteration 53400 (5.14592 iter/s, 19.4329s/100 iter), loss = 0.0658367
I0916 23:26:42.484598 13570 solver.cpp:336]     Train net output #0: loss = 0.0658366 (* 1 = 0.0658366 loss)
I0916 23:26:42.484602 13570 sgd_solver.cpp:136] Iteration 53400, lr = 0.0001, m = 0.9
I0916 23:27:02.139518 13570 solver.cpp:314] Iteration 53500 (5.08792 iter/s, 19.6544s/100 iter), loss = 0.0482583
I0916 23:27:02.139544 13570 solver.cpp:336]     Train net output #0: loss = 0.0482582 (* 1 = 0.0482582 loss)
I0916 23:27:02.139549 13570 sgd_solver.cpp:136] Iteration 53500, lr = 0.0001, m = 0.9
I0916 23:27:21.714706 13570 solver.cpp:314] Iteration 53600 (5.10865 iter/s, 19.5746s/100 iter), loss = 0.0949052
I0916 23:27:21.714818 13570 solver.cpp:336]     Train net output #0: loss = 0.0949051 (* 1 = 0.0949051 loss)
I0916 23:27:21.714828 13570 sgd_solver.cpp:136] Iteration 53600, lr = 0.0001, m = 0.9
I0916 23:27:41.183176 13570 solver.cpp:314] Iteration 53700 (5.13665 iter/s, 19.4679s/100 iter), loss = 0.0619753
I0916 23:27:41.183197 13570 solver.cpp:336]     Train net output #0: loss = 0.0619751 (* 1 = 0.0619751 loss)
I0916 23:27:41.183202 13570 sgd_solver.cpp:136] Iteration 53700, lr = 0.0001, m = 0.9
I0916 23:27:43.454995 13578 data_reader.cpp:305] Starting prefetch of epoch 33
I0916 23:28:00.439756 13570 solver.cpp:314] Iteration 53800 (5.19317 iter/s, 19.256s/100 iter), loss = 0.0583221
I0916 23:28:00.439844 13570 solver.cpp:336]     Train net output #0: loss = 0.0583219 (* 1 = 0.0583219 loss)
I0916 23:28:00.439851 13570 sgd_solver.cpp:136] Iteration 53800, lr = 0.0001, m = 0.9
I0916 23:28:15.476945 13544 data_reader.cpp:305] Starting prefetch of epoch 33
I0916 23:28:20.052345 13570 solver.cpp:314] Iteration 53900 (5.09891 iter/s, 19.612s/100 iter), loss = 0.0544164
I0916 23:28:20.052364 13570 solver.cpp:336]     Train net output #0: loss = 0.0544163 (* 1 = 0.0544163 loss)
I0916 23:28:20.052369 13570 sgd_solver.cpp:136] Iteration 53900, lr = 0.0001, m = 0.9
I0916 23:28:39.232985 13570 solver.cpp:368] Sparsity after update:
I0916 23:28:39.237515 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 23:28:39.237524 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 23:28:39.237530 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 23:28:39.237532 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 23:28:39.237534 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 23:28:39.237536 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 23:28:39.237538 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 23:28:39.237540 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 23:28:39.237542 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 23:28:39.237546 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 23:28:39.237550 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 23:28:39.237553 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 23:28:39.237556 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 23:28:39.237560 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 23:28:39.237562 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 23:28:39.237566 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 23:28:39.237570 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 23:28:39.237573 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 23:28:39.237576 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 23:28:39.237587 13570 solver.cpp:563] Iteration 54000, Testing net (#0)
I0916 23:28:49.964313 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.954399
I0916 23:28:49.964334 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 23:28:49.964341 13570 solver.cpp:655]     Test net output #2: loss = 0.161996 (* 1 = 0.161996 loss)
I0916 23:28:49.964408 13570 solver.cpp:265] [MultiGPU] Tests completed in 10.7265s
I0916 23:28:50.166337 13570 solver.cpp:314] Iteration 54000 (3.32081 iter/s, 30.1132s/100 iter), loss = 0.0641261
I0916 23:28:50.166359 13570 solver.cpp:336]     Train net output #0: loss = 0.0641259 (* 1 = 0.0641259 loss)
I0916 23:28:50.166365 13570 sgd_solver.cpp:136] Iteration 54000, lr = 0.0001, m = 0.9
I0916 23:28:58.141427 13544 data_reader.cpp:305] Starting prefetch of epoch 34
I0916 23:29:09.013941 13570 solver.cpp:314] Iteration 54100 (5.30586 iter/s, 18.8471s/100 iter), loss = 0.056865
I0916 23:29:09.014009 13570 solver.cpp:336]     Train net output #0: loss = 0.0568649 (* 1 = 0.0568649 loss)
I0916 23:29:09.014032 13570 sgd_solver.cpp:136] Iteration 54100, lr = 0.0001, m = 0.9
I0916 23:29:28.555018 13570 solver.cpp:314] Iteration 54200 (5.11757 iter/s, 19.5405s/100 iter), loss = 0.0701729
I0916 23:29:28.555101 13570 solver.cpp:336]     Train net output #0: loss = 0.0701728 (* 1 = 0.0701728 loss)
I0916 23:29:28.555109 13570 sgd_solver.cpp:136] Iteration 54200, lr = 0.0001, m = 0.9
I0916 23:29:48.540256 13570 solver.cpp:314] Iteration 54300 (5.00383 iter/s, 19.9847s/100 iter), loss = 0.0860544
I0916 23:29:48.540280 13570 solver.cpp:336]     Train net output #0: loss = 0.0860543 (* 1 = 0.0860543 loss)
I0916 23:29:48.540284 13570 sgd_solver.cpp:136] Iteration 54300, lr = 0.0001, m = 0.9
I0916 23:30:03.192376 13578 data_reader.cpp:305] Starting prefetch of epoch 34
I0916 23:30:08.362494 13570 solver.cpp:314] Iteration 54400 (5.04498 iter/s, 19.8217s/100 iter), loss = 0.0426577
I0916 23:30:08.362516 13570 solver.cpp:336]     Train net output #0: loss = 0.0426576 (* 1 = 0.0426576 loss)
I0916 23:30:08.362522 13570 sgd_solver.cpp:136] Iteration 54400, lr = 0.0001, m = 0.9
I0916 23:30:27.957435 13570 solver.cpp:314] Iteration 54500 (5.1035 iter/s, 19.5944s/100 iter), loss = 0.141335
I0916 23:30:27.957459 13570 solver.cpp:336]     Train net output #0: loss = 0.141335 (* 1 = 0.141335 loss)
I0916 23:30:27.957466 13570 sgd_solver.cpp:136] Iteration 54500, lr = 0.0001, m = 0.9
I0916 23:30:35.565091 13573 data_reader.cpp:305] Starting prefetch of epoch 36
I0916 23:30:47.922407 13570 solver.cpp:314] Iteration 54600 (5.00891 iter/s, 19.9644s/100 iter), loss = 0.0588434
I0916 23:30:47.922435 13570 solver.cpp:336]     Train net output #0: loss = 0.0588432 (* 1 = 0.0588432 loss)
I0916 23:30:47.922441 13570 sgd_solver.cpp:136] Iteration 54600, lr = 0.0001, m = 0.9
I0916 23:31:07.353412 13570 solver.cpp:314] Iteration 54700 (5.14656 iter/s, 19.4305s/100 iter), loss = 0.0716686
I0916 23:31:07.353490 13570 solver.cpp:336]     Train net output #0: loss = 0.0716684 (* 1 = 0.0716684 loss)
I0916 23:31:07.353497 13570 sgd_solver.cpp:136] Iteration 54700, lr = 0.0001, m = 0.9
I0916 23:31:26.726977 13570 solver.cpp:314] Iteration 54800 (5.16182 iter/s, 19.373s/100 iter), loss = 0.0567633
I0916 23:31:26.727001 13570 solver.cpp:336]     Train net output #0: loss = 0.0567632 (* 1 = 0.0567632 loss)
I0916 23:31:26.727006 13570 sgd_solver.cpp:136] Iteration 54800, lr = 0.0001, m = 0.9
I0916 23:31:40.175973 13574 data_reader.cpp:305] Starting prefetch of epoch 35
I0916 23:31:46.267349 13570 solver.cpp:314] Iteration 54900 (5.11775 iter/s, 19.5398s/100 iter), loss = 0.061319
I0916 23:31:46.267374 13570 solver.cpp:336]     Train net output #0: loss = 0.0613188 (* 1 = 0.0613188 loss)
I0916 23:31:46.267379 13570 sgd_solver.cpp:136] Iteration 54900, lr = 0.0001, m = 0.9
I0916 23:32:05.787163 13570 solver.cpp:368] Sparsity after update:
I0916 23:32:05.808279 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 23:32:05.808297 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 23:32:05.808306 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 23:32:05.808310 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 23:32:05.808312 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 23:32:05.808315 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 23:32:05.808318 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 23:32:05.808328 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 23:32:05.808333 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 23:32:05.808338 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 23:32:05.808343 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 23:32:05.808348 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 23:32:05.808353 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 23:32:05.808357 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 23:32:05.808360 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 23:32:05.808363 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 23:32:05.808367 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 23:32:05.808369 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 23:32:05.808373 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 23:32:05.978837 13570 solver.cpp:314] Iteration 55000 (5.07332 iter/s, 19.7109s/100 iter), loss = 0.106456
I0916 23:32:05.978860 13570 solver.cpp:336]     Train net output #0: loss = 0.106456 (* 1 = 0.106456 loss)
I0916 23:32:05.978865 13570 sgd_solver.cpp:136] Iteration 55000, lr = 0.0001, m = 0.9
I0916 23:32:25.612728 13570 solver.cpp:314] Iteration 55100 (5.09338 iter/s, 19.6333s/100 iter), loss = 0.0884568
I0916 23:32:25.612830 13570 solver.cpp:336]     Train net output #0: loss = 0.0884567 (* 1 = 0.0884567 loss)
I0916 23:32:25.612838 13570 sgd_solver.cpp:136] Iteration 55100, lr = 0.0001, m = 0.9
I0916 23:32:45.353472 13576 data_reader.cpp:305] Starting prefetch of epoch 36
I0916 23:32:45.541504 13570 solver.cpp:314] Iteration 55200 (5.01801 iter/s, 19.9282s/100 iter), loss = 0.0488045
I0916 23:32:45.541527 13570 solver.cpp:336]     Train net output #0: loss = 0.0488044 (* 1 = 0.0488044 loss)
I0916 23:32:45.541532 13570 sgd_solver.cpp:136] Iteration 55200, lr = 0.0001, m = 0.9
I0916 23:33:05.556730 13570 solver.cpp:314] Iteration 55300 (4.99634 iter/s, 20.0147s/100 iter), loss = 0.0790197
I0916 23:33:05.556816 13570 solver.cpp:336]     Train net output #0: loss = 0.0790196 (* 1 = 0.0790196 loss)
I0916 23:33:05.556826 13570 sgd_solver.cpp:136] Iteration 55300, lr = 0.0001, m = 0.9
I0916 23:33:18.454634 13578 data_reader.cpp:305] Starting prefetch of epoch 35
I0916 23:33:25.411347 13570 solver.cpp:314] Iteration 55400 (5.03675 iter/s, 19.8541s/100 iter), loss = 0.0455171
I0916 23:33:25.411629 13570 solver.cpp:336]     Train net output #0: loss = 0.045517 (* 1 = 0.045517 loss)
I0916 23:33:25.411744 13570 sgd_solver.cpp:136] Iteration 55400, lr = 0.0001, m = 0.9
I0916 23:33:45.160996 13570 solver.cpp:314] Iteration 55500 (5.06352 iter/s, 19.7491s/100 iter), loss = 0.0560366
I0916 23:33:45.161099 13570 solver.cpp:336]     Train net output #0: loss = 0.0560364 (* 1 = 0.0560364 loss)
I0916 23:33:45.161105 13570 sgd_solver.cpp:136] Iteration 55500, lr = 0.0001, m = 0.9
I0916 23:34:04.747025 13570 solver.cpp:314] Iteration 55600 (5.10582 iter/s, 19.5855s/100 iter), loss = 0.0691788
I0916 23:34:04.747062 13570 solver.cpp:336]     Train net output #0: loss = 0.0691787 (* 1 = 0.0691787 loss)
I0916 23:34:04.747069 13570 sgd_solver.cpp:136] Iteration 55600, lr = 0.0001, m = 0.9
I0916 23:34:23.517343 13573 data_reader.cpp:305] Starting prefetch of epoch 37
I0916 23:34:24.502827 13570 solver.cpp:314] Iteration 55700 (5.06194 iter/s, 19.7553s/100 iter), loss = 0.0388919
I0916 23:34:24.502943 13570 solver.cpp:336]     Train net output #0: loss = 0.0388918 (* 1 = 0.0388918 loss)
I0916 23:34:24.502964 13570 sgd_solver.cpp:136] Iteration 55700, lr = 0.0001, m = 0.9
I0916 23:34:44.236162 13570 solver.cpp:314] Iteration 55800 (5.06771 iter/s, 19.7328s/100 iter), loss = 0.0611894
I0916 23:34:44.236186 13570 solver.cpp:336]     Train net output #0: loss = 0.0611892 (* 1 = 0.0611892 loss)
I0916 23:34:44.236191 13570 sgd_solver.cpp:136] Iteration 55800, lr = 0.0001, m = 0.9
I0916 23:35:04.062387 13570 solver.cpp:314] Iteration 55900 (5.04396 iter/s, 19.8257s/100 iter), loss = 0.101901
I0916 23:35:04.062441 13570 solver.cpp:336]     Train net output #0: loss = 0.101901 (* 1 = 0.101901 loss)
I0916 23:35:04.062448 13570 sgd_solver.cpp:136] Iteration 55900, lr = 0.0001, m = 0.9
I0916 23:35:23.503945 13570 solver.cpp:368] Sparsity after update:
I0916 23:35:23.505771 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 23:35:23.505789 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 23:35:23.505800 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 23:35:23.505805 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 23:35:23.505810 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 23:35:23.505813 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 23:35:23.505817 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 23:35:23.505820 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 23:35:23.505828 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 23:35:23.505832 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 23:35:23.505836 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 23:35:23.505839 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 23:35:23.505843 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 23:35:23.505847 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 23:35:23.505851 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 23:35:23.505853 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 23:35:23.505857 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 23:35:23.505861 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 23:35:23.505864 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 23:35:23.505879 13570 solver.cpp:563] Iteration 56000, Testing net (#0)
I0916 23:35:26.967032 13594 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 23:35:34.805594 13596 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 23:35:35.115731 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.95168
I0916 23:35:35.115752 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 23:35:35.115759 13570 solver.cpp:655]     Test net output #2: loss = 0.148033 (* 1 = 0.148033 loss)
I0916 23:35:35.115787 13570 solver.cpp:265] [MultiGPU] Tests completed in 11.6096s
I0916 23:35:35.311899 13570 solver.cpp:314] Iteration 56000 (3.20014 iter/s, 31.2486s/100 iter), loss = 0.0671015
I0916 23:35:35.311923 13570 solver.cpp:336]     Train net output #0: loss = 0.0671013 (* 1 = 0.0671013 loss)
I0916 23:35:35.311928 13570 sgd_solver.cpp:136] Iteration 56000, lr = 0.0001, m = 0.9
I0916 23:35:54.721922 13570 solver.cpp:314] Iteration 56100 (5.15212 iter/s, 19.4095s/100 iter), loss = 0.0841791
I0916 23:35:54.721946 13570 solver.cpp:336]     Train net output #0: loss = 0.0841789 (* 1 = 0.0841789 loss)
I0916 23:35:54.721952 13570 sgd_solver.cpp:136] Iteration 56100, lr = 0.0001, m = 0.9
I0916 23:36:12.372169 13573 data_reader.cpp:305] Starting prefetch of epoch 38
I0916 23:36:14.177337 13570 solver.cpp:314] Iteration 56200 (5.1401 iter/s, 19.4549s/100 iter), loss = 0.0633555
I0916 23:36:14.177366 13570 solver.cpp:336]     Train net output #0: loss = 0.0633553 (* 1 = 0.0633553 loss)
I0916 23:36:14.177371 13570 sgd_solver.cpp:136] Iteration 56200, lr = 0.0001, m = 0.9
I0916 23:36:33.714704 13570 solver.cpp:314] Iteration 56300 (5.11854 iter/s, 19.5368s/100 iter), loss = 0.0594908
I0916 23:36:33.714758 13570 solver.cpp:336]     Train net output #0: loss = 0.0594906 (* 1 = 0.0594906 loss)
I0916 23:36:33.714895 13570 sgd_solver.cpp:136] Iteration 56300, lr = 0.0001, m = 0.9
I0916 23:36:53.438668 13570 solver.cpp:314] Iteration 56400 (5.07012 iter/s, 19.7234s/100 iter), loss = 0.0596627
I0916 23:36:53.438732 13570 solver.cpp:336]     Train net output #0: loss = 0.0596625 (* 1 = 0.0596625 loss)
I0916 23:36:53.438740 13570 sgd_solver.cpp:136] Iteration 56400, lr = 0.0001, m = 0.9
I0916 23:37:13.016640 13570 solver.cpp:314] Iteration 56500 (5.10792 iter/s, 19.5774s/100 iter), loss = 0.0726347
I0916 23:37:13.016666 13570 solver.cpp:336]     Train net output #0: loss = 0.0726346 (* 1 = 0.0726346 loss)
I0916 23:37:13.016671 13570 sgd_solver.cpp:136] Iteration 56500, lr = 0.0001, m = 0.9
I0916 23:37:17.002900 13546 data_reader.cpp:305] Starting prefetch of epoch 24
I0916 23:37:32.613926 13570 solver.cpp:314] Iteration 56600 (5.10289 iter/s, 19.5967s/100 iter), loss = 0.0619634
I0916 23:37:32.618101 13570 solver.cpp:336]     Train net output #0: loss = 0.0619633 (* 1 = 0.0619633 loss)
I0916 23:37:32.618109 13570 sgd_solver.cpp:136] Iteration 56600, lr = 0.0001, m = 0.9
I0916 23:37:50.019104 13573 data_reader.cpp:305] Starting prefetch of epoch 39
I0916 23:37:52.557190 13570 solver.cpp:314] Iteration 56700 (5.01436 iter/s, 19.9427s/100 iter), loss = 0.0875407
I0916 23:37:52.557219 13570 solver.cpp:336]     Train net output #0: loss = 0.0875405 (* 1 = 0.0875405 loss)
I0916 23:37:52.557224 13570 sgd_solver.cpp:136] Iteration 56700, lr = 0.0001, m = 0.9
I0916 23:38:12.509064 13570 solver.cpp:314] Iteration 56800 (5.0122 iter/s, 19.9513s/100 iter), loss = 0.0719758
I0916 23:38:12.509147 13570 solver.cpp:336]     Train net output #0: loss = 0.0719756 (* 1 = 0.0719756 loss)
I0916 23:38:12.509156 13570 sgd_solver.cpp:136] Iteration 56800, lr = 0.0001, m = 0.9
I0916 23:38:31.884866 13570 solver.cpp:314] Iteration 56900 (5.16122 iter/s, 19.3753s/100 iter), loss = 0.0522817
I0916 23:38:31.884898 13570 solver.cpp:336]     Train net output #0: loss = 0.0522816 (* 1 = 0.0522816 loss)
I0916 23:38:31.884907 13570 sgd_solver.cpp:136] Iteration 56900, lr = 0.0001, m = 0.9
I0916 23:38:51.340003 13570 solver.cpp:368] Sparsity after update:
I0916 23:38:51.344872 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 23:38:51.344976 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 23:38:51.345002 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 23:38:51.345011 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 23:38:51.345021 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 23:38:51.345031 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 23:38:51.345039 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 23:38:51.345048 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 23:38:51.345057 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 23:38:51.345067 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 23:38:51.345075 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 23:38:51.345083 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 23:38:51.345090 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 23:38:51.345099 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 23:38:51.345108 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 23:38:51.345116 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 23:38:51.345125 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 23:38:51.345134 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 23:38:51.345144 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 23:38:51.533615 13570 solver.cpp:314] Iteration 57000 (5.08952 iter/s, 19.6482s/100 iter), loss = 0.0796724
I0916 23:38:51.533643 13570 solver.cpp:336]     Train net output #0: loss = 0.0796722 (* 1 = 0.0796722 loss)
I0916 23:38:51.533649 13570 sgd_solver.cpp:136] Iteration 57000, lr = 0.0001, m = 0.9
I0916 23:38:54.865566 13574 data_reader.cpp:305] Starting prefetch of epoch 36
I0916 23:39:11.154013 13570 solver.cpp:314] Iteration 57100 (5.09688 iter/s, 19.6199s/100 iter), loss = 0.0805147
I0916 23:39:11.154038 13570 solver.cpp:336]     Train net output #0: loss = 0.0805146 (* 1 = 0.0805146 loss)
I0916 23:39:11.154088 13570 sgd_solver.cpp:136] Iteration 57100, lr = 0.0001, m = 0.9
I0916 23:39:30.616487 13570 solver.cpp:314] Iteration 57200 (5.13824 iter/s, 19.4619s/100 iter), loss = 0.0523767
I0916 23:39:30.616544 13570 solver.cpp:336]     Train net output #0: loss = 0.0523765 (* 1 = 0.0523765 loss)
I0916 23:39:30.616549 13570 sgd_solver.cpp:136] Iteration 57200, lr = 0.0001, m = 0.9
I0916 23:39:50.087532 13570 solver.cpp:314] Iteration 57300 (5.13597 iter/s, 19.4705s/100 iter), loss = 0.0869511
I0916 23:39:50.087554 13570 solver.cpp:336]     Train net output #0: loss = 0.086951 (* 1 = 0.086951 loss)
I0916 23:39:50.087558 13570 sgd_solver.cpp:136] Iteration 57300, lr = 0.0001, m = 0.9
I0916 23:39:59.369529 13576 data_reader.cpp:305] Starting prefetch of epoch 37
I0916 23:40:09.484946 13570 solver.cpp:314] Iteration 57400 (5.15547 iter/s, 19.3969s/100 iter), loss = 0.0556181
I0916 23:40:09.485026 13570 solver.cpp:336]     Train net output #0: loss = 0.055618 (* 1 = 0.055618 loss)
I0916 23:40:09.485034 13570 sgd_solver.cpp:136] Iteration 57400, lr = 0.0001, m = 0.9
I0916 23:40:28.883551 13570 solver.cpp:314] Iteration 57500 (5.15515 iter/s, 19.3981s/100 iter), loss = 0.10784
I0916 23:40:28.883577 13570 solver.cpp:336]     Train net output #0: loss = 0.10784 (* 1 = 0.10784 loss)
I0916 23:40:28.883582 13570 sgd_solver.cpp:136] Iteration 57500, lr = 0.0001, m = 0.9
I0916 23:40:48.230381 13570 solver.cpp:314] Iteration 57600 (5.16895 iter/s, 19.3463s/100 iter), loss = 0.0467867
I0916 23:40:48.230437 13570 solver.cpp:336]     Train net output #0: loss = 0.0467866 (* 1 = 0.0467866 loss)
I0916 23:40:48.230443 13570 sgd_solver.cpp:136] Iteration 57600, lr = 0.0001, m = 0.9
I0916 23:41:03.266942 13576 data_reader.cpp:305] Starting prefetch of epoch 38
I0916 23:41:07.517379 13570 solver.cpp:314] Iteration 57700 (5.18498 iter/s, 19.2865s/100 iter), loss = 0.0838724
I0916 23:41:07.517406 13570 solver.cpp:336]     Train net output #0: loss = 0.0838723 (* 1 = 0.0838723 loss)
I0916 23:41:07.517413 13570 sgd_solver.cpp:136] Iteration 57700, lr = 0.0001, m = 0.9
I0916 23:41:27.397353 13570 solver.cpp:314] Iteration 57800 (5.03033 iter/s, 19.8794s/100 iter), loss = 0.0409428
I0916 23:41:27.397462 13570 solver.cpp:336]     Train net output #0: loss = 0.0409427 (* 1 = 0.0409427 loss)
I0916 23:41:27.397469 13570 sgd_solver.cpp:136] Iteration 57800, lr = 0.0001, m = 0.9
I0916 23:41:36.111444 13544 data_reader.cpp:305] Starting prefetch of epoch 35
I0916 23:41:46.904932 13570 solver.cpp:314] Iteration 57900 (5.12636 iter/s, 19.507s/100 iter), loss = 0.0427548
I0916 23:41:46.904956 13570 solver.cpp:336]     Train net output #0: loss = 0.0427547 (* 1 = 0.0427547 loss)
I0916 23:41:46.904964 13570 sgd_solver.cpp:136] Iteration 57900, lr = 0.0001, m = 0.9
I0916 23:42:06.045259 13570 solver.cpp:368] Sparsity after update:
I0916 23:42:06.049607 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 23:42:06.049634 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 23:42:06.049644 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 23:42:06.049649 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 23:42:06.049652 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 23:42:06.049655 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 23:42:06.049660 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 23:42:06.049664 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 23:42:06.049667 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 23:42:06.049670 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 23:42:06.049674 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 23:42:06.049676 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 23:42:06.049679 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 23:42:06.049682 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 23:42:06.049685 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 23:42:06.049688 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 23:42:06.049691 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 23:42:06.049695 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 23:42:06.049697 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 23:42:06.049711 13570 solver.cpp:563] Iteration 58000, Testing net (#0)
I0916 23:42:17.341150 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.95427
I0916 23:42:17.341168 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 23:42:17.341173 13570 solver.cpp:655]     Test net output #2: loss = 0.161728 (* 1 = 0.161728 loss)
I0916 23:42:17.341233 13570 solver.cpp:265] [MultiGPU] Tests completed in 11.2912s
I0916 23:42:17.554136 13570 solver.cpp:314] Iteration 58000 (3.26282 iter/s, 30.6483s/100 iter), loss = 0.0397973
I0916 23:42:17.554260 13570 solver.cpp:336]     Train net output #0: loss = 0.0397972 (* 1 = 0.0397972 loss)
I0916 23:42:17.554280 13570 sgd_solver.cpp:136] Iteration 58000, lr = 0.0001, m = 0.9
I0916 23:42:19.298676 13576 data_reader.cpp:305] Starting prefetch of epoch 39
I0916 23:42:37.110721 13570 solver.cpp:314] Iteration 58100 (5.11351 iter/s, 19.556s/100 iter), loss = 0.0668931
I0916 23:42:37.110796 13570 solver.cpp:336]     Train net output #0: loss = 0.066893 (* 1 = 0.066893 loss)
I0916 23:42:37.110811 13570 sgd_solver.cpp:136] Iteration 58100, lr = 0.0001, m = 0.9
I0916 23:42:56.360340 13570 solver.cpp:314] Iteration 58200 (5.19505 iter/s, 19.2491s/100 iter), loss = 0.0758625
I0916 23:42:56.360365 13570 solver.cpp:336]     Train net output #0: loss = 0.0758624 (* 1 = 0.0758624 loss)
I0916 23:42:56.360369 13570 sgd_solver.cpp:136] Iteration 58200, lr = 0.0001, m = 0.9
I0916 23:43:15.652881 13570 solver.cpp:314] Iteration 58300 (5.18349 iter/s, 19.292s/100 iter), loss = 0.0353228
I0916 23:43:15.652932 13570 solver.cpp:336]     Train net output #0: loss = 0.0353227 (* 1 = 0.0353227 loss)
I0916 23:43:15.652937 13570 sgd_solver.cpp:136] Iteration 58300, lr = 0.0001, m = 0.9
I0916 23:43:23.399142 13574 data_reader.cpp:305] Starting prefetch of epoch 37
I0916 23:43:35.019021 13570 solver.cpp:314] Iteration 58400 (5.16379 iter/s, 19.3656s/100 iter), loss = 0.0945347
I0916 23:43:35.019048 13570 solver.cpp:336]     Train net output #0: loss = 0.0945346 (* 1 = 0.0945346 loss)
I0916 23:43:35.019053 13570 sgd_solver.cpp:136] Iteration 58400, lr = 0.0001, m = 0.9
I0916 23:43:54.589736 13570 solver.cpp:314] Iteration 58500 (5.10982 iter/s, 19.5702s/100 iter), loss = 0.0347936
I0916 23:43:54.589844 13570 solver.cpp:336]     Train net output #0: loss = 0.0347935 (* 1 = 0.0347935 loss)
I0916 23:43:54.589854 13570 sgd_solver.cpp:136] Iteration 58500, lr = 0.0001, m = 0.9
I0916 23:43:55.593966 13574 data_reader.cpp:305] Starting prefetch of epoch 38
I0916 23:44:14.194973 13570 solver.cpp:314] Iteration 58600 (5.10082 iter/s, 19.6047s/100 iter), loss = 0.0838758
I0916 23:44:14.195001 13570 solver.cpp:336]     Train net output #0: loss = 0.0838757 (* 1 = 0.0838757 loss)
I0916 23:44:14.195008 13570 sgd_solver.cpp:136] Iteration 58600, lr = 0.0001, m = 0.9
I0916 23:44:33.514062 13570 solver.cpp:314] Iteration 58700 (5.17637 iter/s, 19.3185s/100 iter), loss = 0.10089
I0916 23:44:33.514124 13570 solver.cpp:336]     Train net output #0: loss = 0.10089 (* 1 = 0.10089 loss)
I0916 23:44:33.514129 13570 sgd_solver.cpp:136] Iteration 58700, lr = 0.0001, m = 0.9
I0916 23:44:53.203232 13570 solver.cpp:314] Iteration 58800 (5.07908 iter/s, 19.6886s/100 iter), loss = 0.0786024
I0916 23:44:53.203259 13570 solver.cpp:336]     Train net output #0: loss = 0.0786023 (* 1 = 0.0786023 loss)
I0916 23:44:53.203264 13570 sgd_solver.cpp:136] Iteration 58800, lr = 0.0001, m = 0.9
I0916 23:45:00.139621 13546 data_reader.cpp:305] Starting prefetch of epoch 25
I0916 23:45:12.848071 13570 solver.cpp:314] Iteration 58900 (5.09054 iter/s, 19.6443s/100 iter), loss = 0.0637009
I0916 23:45:12.848129 13570 solver.cpp:336]     Train net output #0: loss = 0.0637008 (* 1 = 0.0637008 loss)
I0916 23:45:12.848134 13570 sgd_solver.cpp:136] Iteration 58900, lr = 0.0001, m = 0.9
I0916 23:45:31.912201 13570 solver.cpp:368] Sparsity after update:
I0916 23:45:31.934833 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 23:45:31.934849 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 23:45:31.934855 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 23:45:31.934859 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 23:45:31.934860 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 23:45:31.934862 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 23:45:31.934864 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 23:45:31.934866 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 23:45:31.934869 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 23:45:31.934870 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 23:45:31.934872 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 23:45:31.934881 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 23:45:31.934883 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 23:45:31.934885 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 23:45:31.934887 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 23:45:31.934891 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 23:45:31.934893 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 23:45:31.934895 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 23:45:31.934900 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 23:45:32.107666 13570 solver.cpp:314] Iteration 59000 (5.19236 iter/s, 19.2591s/100 iter), loss = 0.0507515
I0916 23:45:32.107692 13570 solver.cpp:336]     Train net output #0: loss = 0.0507514 (* 1 = 0.0507514 loss)
I0916 23:45:32.107699 13570 sgd_solver.cpp:136] Iteration 59000, lr = 0.0001, m = 0.9
I0916 23:45:51.735883 13570 solver.cpp:314] Iteration 59100 (5.09485 iter/s, 19.6277s/100 iter), loss = 0.0537824
I0916 23:45:51.735944 13570 solver.cpp:336]     Train net output #0: loss = 0.0537823 (* 1 = 0.0537823 loss)
I0916 23:45:51.735949 13570 sgd_solver.cpp:136] Iteration 59100, lr = 0.0001, m = 0.9
I0916 23:46:04.661067 13576 data_reader.cpp:305] Starting prefetch of epoch 40
I0916 23:46:11.462121 13570 solver.cpp:314] Iteration 59200 (5.06953 iter/s, 19.7257s/100 iter), loss = 0.0603915
I0916 23:46:11.462144 13570 solver.cpp:336]     Train net output #0: loss = 0.0603914 (* 1 = 0.0603914 loss)
I0916 23:46:11.462149 13570 sgd_solver.cpp:136] Iteration 59200, lr = 0.0001, m = 0.9
I0916 23:46:31.078999 13570 solver.cpp:314] Iteration 59300 (5.09779 iter/s, 19.6163s/100 iter), loss = 0.0427293
I0916 23:46:31.079105 13570 solver.cpp:336]     Train net output #0: loss = 0.0427292 (* 1 = 0.0427292 loss)
I0916 23:46:31.079113 13570 sgd_solver.cpp:136] Iteration 59300, lr = 0.0001, m = 0.9
I0916 23:46:37.202098 13544 data_reader.cpp:305] Starting prefetch of epoch 36
I0916 23:46:50.704800 13570 solver.cpp:314] Iteration 59400 (5.09548 iter/s, 19.6253s/100 iter), loss = 0.0593776
I0916 23:46:50.704828 13570 solver.cpp:336]     Train net output #0: loss = 0.0593775 (* 1 = 0.0593775 loss)
I0916 23:46:50.704833 13570 sgd_solver.cpp:136] Iteration 59400, lr = 0.0001, m = 0.9
I0916 23:47:10.479602 13570 solver.cpp:314] Iteration 59500 (5.05708 iter/s, 19.7743s/100 iter), loss = 0.0603493
I0916 23:47:10.511178 13570 solver.cpp:336]     Train net output #0: loss = 0.0603492 (* 1 = 0.0603492 loss)
I0916 23:47:10.511212 13570 sgd_solver.cpp:136] Iteration 59500, lr = 0.0001, m = 0.9
I0916 23:47:30.112824 13570 solver.cpp:314] Iteration 59600 (5.09355 iter/s, 19.6327s/100 iter), loss = 0.0487224
I0916 23:47:30.112850 13570 solver.cpp:336]     Train net output #0: loss = 0.0487223 (* 1 = 0.0487223 loss)
I0916 23:47:30.112854 13570 sgd_solver.cpp:136] Iteration 59600, lr = 0.0001, m = 0.9
I0916 23:47:42.220775 13546 data_reader.cpp:305] Starting prefetch of epoch 26
I0916 23:47:49.468168 13570 solver.cpp:314] Iteration 59700 (5.16668 iter/s, 19.3548s/100 iter), loss = 0.0812413
I0916 23:47:49.468190 13570 solver.cpp:336]     Train net output #0: loss = 0.0812412 (* 1 = 0.0812412 loss)
I0916 23:47:49.468196 13570 sgd_solver.cpp:136] Iteration 59700, lr = 0.0001, m = 0.9
I0916 23:48:09.442443 13570 solver.cpp:314] Iteration 59800 (5.00658 iter/s, 19.9737s/100 iter), loss = 0.102624
I0916 23:48:09.442550 13570 solver.cpp:336]     Train net output #0: loss = 0.102624 (* 1 = 0.102624 loss)
I0916 23:48:09.442571 13570 sgd_solver.cpp:136] Iteration 59800, lr = 0.0001, m = 0.9
I0916 23:48:28.925127 13570 solver.cpp:314] Iteration 59900 (5.13291 iter/s, 19.4821s/100 iter), loss = 0.0796353
I0916 23:48:28.925178 13570 solver.cpp:336]     Train net output #0: loss = 0.0796352 (* 1 = 0.0796352 loss)
I0916 23:48:28.925184 13570 sgd_solver.cpp:136] Iteration 59900, lr = 0.0001, m = 0.9
I0916 23:48:47.285440 13546 data_reader.cpp:305] Starting prefetch of epoch 27
I0916 23:48:48.618367 13570 solver.cpp:314] Iteration 59999 (5.02725 iter/s, 19.6927s/99 iter), loss = 0.0596415
I0916 23:48:48.618391 13570 solver.cpp:336]     Train net output #0: loss = 0.0596414 (* 1 = 0.0596414 loss)
I0916 23:48:48.618397 13570 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/sparse/cityscapes5_jsegnet21v2_iter_60000.caffemodel
I0916 23:48:48.632429 13570 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/sparse/cityscapes5_jsegnet21v2_iter_60000.solverstate
I0916 23:48:48.640441 13570 solver.cpp:368] Sparsity after update:
I0916 23:48:48.642267 13570 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 23:48:48.642277 13570 net.cpp:2304] conv1a_param_0(0.326) 
I0916 23:48:48.642285 13570 net.cpp:2304] conv1b_param_0(0.733) 
I0916 23:48:48.642289 13570 net.cpp:2304] ctx_conv1_param_0(0.807) 
I0916 23:48:48.642292 13570 net.cpp:2304] ctx_conv2_param_0(0.808) 
I0916 23:48:48.642295 13570 net.cpp:2304] ctx_conv3_param_0(0.808) 
I0916 23:48:48.642298 13570 net.cpp:2304] ctx_conv4_param_0(0.808) 
I0916 23:48:48.642302 13570 net.cpp:2304] ctx_final_param_0(0.253) 
I0916 23:48:48.642304 13570 net.cpp:2304] out3a_param_0(0.809) 
I0916 23:48:48.642307 13570 net.cpp:2304] out5a_param_0(0.81) 
I0916 23:48:48.642312 13570 net.cpp:2304] res2a_branch2a_param_0(0.801) 
I0916 23:48:48.642314 13570 net.cpp:2304] res2a_branch2b_param_0(0.702) 
I0916 23:48:48.642318 13570 net.cpp:2304] res3a_branch2a_param_0(0.805) 
I0916 23:48:48.642320 13570 net.cpp:2304] res3a_branch2b_param_0(0.784) 
I0916 23:48:48.642324 13570 net.cpp:2304] res4a_branch2a_param_0(0.81) 
I0916 23:48:48.642328 13570 net.cpp:2304] res4a_branch2b_param_0(0.803) 
I0916 23:48:48.642333 13570 net.cpp:2304] res5a_branch2a_param_0(0.808) 
I0916 23:48:48.642336 13570 net.cpp:2304] res5a_branch2b_param_0(0.81) 
I0916 23:48:48.642339 13570 net.cpp:2308] Total Sparsity (zero_weights/count) =  (2.16983e+06/2.69117e+06) 0.806
I0916 23:48:48.737375 13570 solver.cpp:538] Iteration 60000, loss = 0.0525384
I0916 23:48:48.737648 13570 solver.cpp:563] Iteration 60000, Testing net (#0)
I0916 23:48:52.371510 13568 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 23:49:01.092190 13570 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.951396
I0916 23:49:01.092320 13570 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 23:49:01.092330 13570 solver.cpp:655]     Test net output #2: loss = 0.14866 (* 1 = 0.14866 loss)
I0916 23:49:01.188536 13475 parallel.cpp:71] Root Solver performance on device 0: 4.934 * 6 = 29.6 img/sec (60000 itr in 1.216e+04 sec)
I0916 23:49:01.188556 13475 parallel.cpp:76]      Solver performance on device 1: 4.934 * 6 = 29.6 img/sec (60000 itr in 1.216e+04 sec)
I0916 23:49:01.188561 13475 parallel.cpp:76]      Solver performance on device 2: 4.934 * 6 = 29.6 img/sec (60000 itr in 1.216e+04 sec)
I0916 23:49:01.188563 13475 parallel.cpp:79] Overall multi-GPU performance: 88.8128 img/sec
I0916 23:49:02.822319 13475 caffe.cpp:253] Optimization Done in 3h 23m 0s
training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/test/run.sh: line 1: cd: /user/a0393608/files/work/code/vision/ti/bitbucket/algoref/caffe-jacinto/build/tools/caffe.bin: Not a directory
I0916 23:49:14.451709  4353 caffe.cpp:807] This is NVCaffe 0.16.4 started at Sat Sep 16 23:49:13 2017
I0916 23:49:14.452617  4353 caffe.cpp:810] CuDNN version: 6021
I0916 23:49:14.452623  4353 caffe.cpp:811] CuBLAS version: 8000
I0916 23:49:14.452627  4353 caffe.cpp:812] CUDA version: 8000
I0916 23:49:14.452630  4353 caffe.cpp:813] CUDA driver version: 8000
I0916 23:49:14.452636  4353 caffe.cpp:269] Not using GPU #2 for single-GPU function
I0916 23:49:14.452641  4353 caffe.cpp:269] Not using GPU #1 for single-GPU function
I0916 23:49:14.596767  4353 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0916 23:49:14.597350  4353 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8278441984, dev_info[0]: total=8506769408 free=8278441984
I0916 23:49:14.597358  4353 caffe.cpp:281] Use GPU with device ID 0
I0916 23:49:14.597690  4353 caffe.cpp:285] GPU device name: GeForce GTX 1080
I0916 23:49:14.634912  4353 net.cpp:72] Initializing net from parameters: 
name: "jsegnet21v2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageLabelData"
  top: "data"
  top: "label"
  transform_param {
    mirror: false
    crop_size: 640
    mean_value: 0
  }
  image_label_data_param {
    image_list_path: "data/val-image-lmdb"
    label_list_path: "data/val-label-lmdb"
    batch_size: 4
    threads: 1
    backend: LMDB
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "out5a"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "out5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "out5a/bn"
  type: "BatchNorm"
  bottom: "out5a"
  top: "out5a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out5a/relu"
  type: "ReLU"
  bottom: "out5a"
  top: "out5a"
}
layer {
  name: "out5a_up2"
  type: "Deconvolution"
  bottom: "out5a"
  top: "out5a_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 64
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out3a"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "out3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "out3a/bn"
  type: "BatchNorm"
  bottom: "out3a"
  top: "out3a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out3a/relu"
  type: "ReLU"
  bottom: "out3a"
  top: "out3a"
}
layer {
  name: "out3_out5_combined"
  type: "Eltwise"
  bottom: "out5a_up2"
  bottom: "out3a"
  top: "out3_out5_combined"
}
layer {
  name: "ctx_conv1"
  type: "Convolution"
  bottom: "out3_out5_combined"
  top: "ctx_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_conv1/bn"
  type: "BatchNorm"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv1/relu"
  type: "ReLU"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
}
layer {
  name: "ctx_conv2"
  type: "Convolution"
  bottom: "ctx_conv1"
  top: "ctx_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv2/bn"
  type: "BatchNorm"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv2/relu"
  type: "ReLU"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
}
layer {
  name: "ctx_conv3"
  type: "Convolution"
  bottom: "ctx_conv2"
  top: "ctx_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv3/bn"
  type: "BatchNorm"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv3/relu"
  type: "ReLU"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
}
layer {
  name: "ctx_conv4"
  type: "Convolution"
  bottom: "ctx_conv3"
  top: "ctx_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv4/bn"
  type: "BatchNorm"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv4/relu"
  type: "ReLU"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
}
layer {
  name: "ctx_final"
  type: "Convolution"
  bottom: "ctx_conv4"
  top: "ctx_final"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_final/relu"
  type: "ReLU"
  bottom: "ctx_final"
  top: "ctx_final"
}
layer {
  name: "out_deconv_final_up2"
  type: "Deconvolution"
  bottom: "ctx_final"
  top: "out_deconv_final_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up4"
  type: "Deconvolution"
  bottom: "out_deconv_final_up2"
  top: "out_deconv_final_up4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up8"
  type: "Deconvolution"
  bottom: "out_deconv_final_up4"
  top: "out_deconv_final_up8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: 255
    normalization: VALID
  }
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "accuracy/top1"
  include {
    phase: TEST
  }
  accuracy_param {
    ignore_label: 255
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "accuracy/top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
    ignore_label: 255
  }
}
I0916 23:49:14.635275  4353 net.cpp:104] Using FLOAT as default forward math type
I0916 23:49:14.635284  4353 net.cpp:110] Using FLOAT as default backward math type
I0916 23:49:14.635288  4353 layer_factory.hpp:136] Creating layer 'data' of type 'ImageLabelData'
I0916 23:49:14.635293  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:14.643733  4353 net.cpp:184] Created Layer data (0)
I0916 23:49:14.643743  4353 net.cpp:530] data -> data
I0916 23:49:14.643759  4353 net.cpp:530] data -> label
I0916 23:49:14.649324  4353 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 4
I0916 23:49:14.649341  4353 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 23:49:14.687221  4384 db_lmdb.cpp:24] Opened lmdb data/val-image-lmdb
I0916 23:49:14.689394  4353 data_layer.cpp:187] (0) ReshapePrefetch 4, 3, 640, 640
I0916 23:49:14.689432  4353 data_layer.cpp:211] (0) Output data size: 4, 3, 640, 640
I0916 23:49:14.689438  4353 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 23:49:14.689491  4353 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 4
I0916 23:49:14.689502  4353 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 23:49:14.690861  4385 data_layer.cpp:101] (0) Parser threads: 1
I0916 23:49:14.690884  4385 data_layer.cpp:103] (0) Transformer threads: 1
I0916 23:49:14.709899  4386 db_lmdb.cpp:24] Opened lmdb data/val-label-lmdb
I0916 23:49:14.710665  4353 data_layer.cpp:187] (0) ReshapePrefetch 4, 1, 640, 640
I0916 23:49:14.710685  4353 data_layer.cpp:211] (0) Output data size: 4, 1, 640, 640
I0916 23:49:14.710691  4353 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 23:49:14.710741  4353 net.cpp:245] Setting up data
I0916 23:49:14.710757  4353 net.cpp:252] TEST Top shape for layer 0 'data' 4 3 640 640 (4915200)
I0916 23:49:14.711046  4353 net.cpp:252] TEST Top shape for layer 0 'data' 4 1 640 640 (1638400)
I0916 23:49:14.711055  4353 layer_factory.hpp:136] Creating layer 'label_data_1_split' of type 'Split'
I0916 23:49:14.711062  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:14.711077  4353 net.cpp:184] Created Layer label_data_1_split (1)
I0916 23:49:14.711084  4353 net.cpp:561] label_data_1_split <- label
I0916 23:49:14.711098  4353 net.cpp:530] label_data_1_split -> label_data_1_split_0
I0916 23:49:14.711105  4353 net.cpp:530] label_data_1_split -> label_data_1_split_1
I0916 23:49:14.711112  4353 net.cpp:530] label_data_1_split -> label_data_1_split_2
I0916 23:49:14.711156  4353 net.cpp:245] Setting up label_data_1_split
I0916 23:49:14.711163  4353 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 4 1 640 640 (1638400)
I0916 23:49:14.711166  4353 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 4 1 640 640 (1638400)
I0916 23:49:14.711171  4353 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 4 1 640 640 (1638400)
I0916 23:49:14.711176  4353 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0916 23:49:14.711181  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:14.711194  4353 net.cpp:184] Created Layer data/bias (2)
I0916 23:49:14.711196  4353 net.cpp:561] data/bias <- data
I0916 23:49:14.711201  4353 net.cpp:530] data/bias -> data/bias
I0916 23:49:14.711499  4387 data_layer.cpp:101] (0) Parser threads: 1
I0916 23:49:14.711509  4387 data_layer.cpp:103] (0) Transformer threads: 1
I0916 23:49:14.726508  4353 net.cpp:245] Setting up data/bias
I0916 23:49:14.726531  4353 net.cpp:252] TEST Top shape for layer 2 'data/bias' 4 3 640 640 (4915200)
I0916 23:49:14.726544  4353 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0916 23:49:14.726550  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:14.726567  4353 net.cpp:184] Created Layer conv1a (3)
I0916 23:49:14.726572  4353 net.cpp:561] conv1a <- data/bias
I0916 23:49:14.726577  4353 net.cpp:530] conv1a -> conv1a
I0916 23:49:15.341706  4353 net.cpp:245] Setting up conv1a
I0916 23:49:15.341732  4353 net.cpp:252] TEST Top shape for layer 3 'conv1a' 4 32 320 320 (13107200)
I0916 23:49:15.341743  4353 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0916 23:49:15.341748  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.341760  4353 net.cpp:184] Created Layer conv1a/bn (4)
I0916 23:49:15.341764  4353 net.cpp:561] conv1a/bn <- conv1a
I0916 23:49:15.341768  4353 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0916 23:49:15.342231  4353 net.cpp:245] Setting up conv1a/bn
I0916 23:49:15.342238  4353 net.cpp:252] TEST Top shape for layer 4 'conv1a/bn' 4 32 320 320 (13107200)
I0916 23:49:15.342245  4353 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0916 23:49:15.342247  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.342252  4353 net.cpp:184] Created Layer conv1a/relu (5)
I0916 23:49:15.342254  4353 net.cpp:561] conv1a/relu <- conv1a
I0916 23:49:15.342257  4353 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0916 23:49:15.342566  4353 net.cpp:245] Setting up conv1a/relu
I0916 23:49:15.342571  4353 net.cpp:252] TEST Top shape for layer 5 'conv1a/relu' 4 32 320 320 (13107200)
I0916 23:49:15.342573  4353 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0916 23:49:15.342576  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.342586  4353 net.cpp:184] Created Layer conv1b (6)
I0916 23:49:15.342587  4353 net.cpp:561] conv1b <- conv1a
I0916 23:49:15.342591  4353 net.cpp:530] conv1b -> conv1b
I0916 23:49:15.343746  4353 net.cpp:245] Setting up conv1b
I0916 23:49:15.343755  4353 net.cpp:252] TEST Top shape for layer 6 'conv1b' 4 32 320 320 (13107200)
I0916 23:49:15.343760  4353 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0916 23:49:15.343763  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.343768  4353 net.cpp:184] Created Layer conv1b/bn (7)
I0916 23:49:15.343770  4353 net.cpp:561] conv1b/bn <- conv1b
I0916 23:49:15.343772  4353 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0916 23:49:15.344524  4353 net.cpp:245] Setting up conv1b/bn
I0916 23:49:15.344533  4353 net.cpp:252] TEST Top shape for layer 7 'conv1b/bn' 4 32 320 320 (13107200)
I0916 23:49:15.344539  4353 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0916 23:49:15.344542  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.344545  4353 net.cpp:184] Created Layer conv1b/relu (8)
I0916 23:49:15.344547  4353 net.cpp:561] conv1b/relu <- conv1b
I0916 23:49:15.344550  4353 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0916 23:49:15.344553  4353 net.cpp:245] Setting up conv1b/relu
I0916 23:49:15.344557  4353 net.cpp:252] TEST Top shape for layer 8 'conv1b/relu' 4 32 320 320 (13107200)
I0916 23:49:15.344558  4353 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0916 23:49:15.344560  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.344568  4353 net.cpp:184] Created Layer pool1 (9)
I0916 23:49:15.344571  4353 net.cpp:561] pool1 <- conv1b
I0916 23:49:15.344573  4353 net.cpp:530] pool1 -> pool1
I0916 23:49:15.344616  4353 net.cpp:245] Setting up pool1
I0916 23:49:15.344620  4353 net.cpp:252] TEST Top shape for layer 9 'pool1' 4 32 160 160 (3276800)
I0916 23:49:15.344624  4353 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0916 23:49:15.344627  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.344632  4353 net.cpp:184] Created Layer res2a_branch2a (10)
I0916 23:49:15.344635  4353 net.cpp:561] res2a_branch2a <- pool1
I0916 23:49:15.344638  4353 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0916 23:49:15.346084  4353 net.cpp:245] Setting up res2a_branch2a
I0916 23:49:15.346103  4353 net.cpp:252] TEST Top shape for layer 10 'res2a_branch2a' 4 64 160 160 (6553600)
I0916 23:49:15.346110  4353 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0916 23:49:15.346113  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.346117  4353 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0916 23:49:15.346120  4353 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0916 23:49:15.346123  4353 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0916 23:49:15.346539  4353 net.cpp:245] Setting up res2a_branch2a/bn
I0916 23:49:15.346546  4353 net.cpp:252] TEST Top shape for layer 11 'res2a_branch2a/bn' 4 64 160 160 (6553600)
I0916 23:49:15.346552  4353 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0916 23:49:15.346555  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.346559  4353 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0916 23:49:15.346561  4353 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0916 23:49:15.346565  4353 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0916 23:49:15.346568  4353 net.cpp:245] Setting up res2a_branch2a/relu
I0916 23:49:15.346571  4353 net.cpp:252] TEST Top shape for layer 12 'res2a_branch2a/relu' 4 64 160 160 (6553600)
I0916 23:49:15.346573  4353 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0916 23:49:15.346576  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.346582  4353 net.cpp:184] Created Layer res2a_branch2b (13)
I0916 23:49:15.346586  4353 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0916 23:49:15.346590  4353 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0916 23:49:15.347493  4353 net.cpp:245] Setting up res2a_branch2b
I0916 23:49:15.347503  4353 net.cpp:252] TEST Top shape for layer 13 'res2a_branch2b' 4 64 160 160 (6553600)
I0916 23:49:15.347510  4353 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0916 23:49:15.347514  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.347522  4353 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0916 23:49:15.347524  4353 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0916 23:49:15.347528  4353 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0916 23:49:15.347941  4353 net.cpp:245] Setting up res2a_branch2b/bn
I0916 23:49:15.347949  4353 net.cpp:252] TEST Top shape for layer 14 'res2a_branch2b/bn' 4 64 160 160 (6553600)
I0916 23:49:15.347957  4353 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0916 23:49:15.347961  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.347965  4353 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0916 23:49:15.347970  4353 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0916 23:49:15.347973  4353 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0916 23:49:15.347980  4353 net.cpp:245] Setting up res2a_branch2b/relu
I0916 23:49:15.347985  4353 net.cpp:252] TEST Top shape for layer 15 'res2a_branch2b/relu' 4 64 160 160 (6553600)
I0916 23:49:15.347988  4353 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0916 23:49:15.347993  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.348000  4353 net.cpp:184] Created Layer pool2 (16)
I0916 23:49:15.348003  4353 net.cpp:561] pool2 <- res2a_branch2b
I0916 23:49:15.348007  4353 net.cpp:530] pool2 -> pool2
I0916 23:49:15.348039  4353 net.cpp:245] Setting up pool2
I0916 23:49:15.348045  4353 net.cpp:252] TEST Top shape for layer 16 'pool2' 4 64 80 80 (1638400)
I0916 23:49:15.348049  4353 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0916 23:49:15.348053  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.348068  4353 net.cpp:184] Created Layer res3a_branch2a (17)
I0916 23:49:15.348073  4353 net.cpp:561] res3a_branch2a <- pool2
I0916 23:49:15.348076  4353 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0916 23:49:15.349695  4353 net.cpp:245] Setting up res3a_branch2a
I0916 23:49:15.349704  4353 net.cpp:252] TEST Top shape for layer 17 'res3a_branch2a' 4 128 80 80 (3276800)
I0916 23:49:15.349711  4353 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0916 23:49:15.349715  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.349722  4353 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0916 23:49:15.349726  4353 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0916 23:49:15.349730  4353 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0916 23:49:15.350499  4353 net.cpp:245] Setting up res3a_branch2a/bn
I0916 23:49:15.350509  4353 net.cpp:252] TEST Top shape for layer 18 'res3a_branch2a/bn' 4 128 80 80 (3276800)
I0916 23:49:15.350519  4353 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0916 23:49:15.350523  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.350528  4353 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0916 23:49:15.350533  4353 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0916 23:49:15.350536  4353 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0916 23:49:15.350543  4353 net.cpp:245] Setting up res3a_branch2a/relu
I0916 23:49:15.350548  4353 net.cpp:252] TEST Top shape for layer 19 'res3a_branch2a/relu' 4 128 80 80 (3276800)
I0916 23:49:15.350553  4353 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0916 23:49:15.350556  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.350564  4353 net.cpp:184] Created Layer res3a_branch2b (20)
I0916 23:49:15.350569  4353 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0916 23:49:15.350572  4353 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0916 23:49:15.351467  4353 net.cpp:245] Setting up res3a_branch2b
I0916 23:49:15.351477  4353 net.cpp:252] TEST Top shape for layer 20 'res3a_branch2b' 4 128 80 80 (3276800)
I0916 23:49:15.351485  4353 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0916 23:49:15.351488  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.351495  4353 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0916 23:49:15.351498  4353 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0916 23:49:15.351502  4353 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0916 23:49:15.351884  4353 net.cpp:245] Setting up res3a_branch2b/bn
I0916 23:49:15.351892  4353 net.cpp:252] TEST Top shape for layer 21 'res3a_branch2b/bn' 4 128 80 80 (3276800)
I0916 23:49:15.351902  4353 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0916 23:49:15.351905  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.351910  4353 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0916 23:49:15.351914  4353 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0916 23:49:15.351918  4353 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0916 23:49:15.351924  4353 net.cpp:245] Setting up res3a_branch2b/relu
I0916 23:49:15.351929  4353 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b/relu' 4 128 80 80 (3276800)
I0916 23:49:15.351933  4353 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0916 23:49:15.351936  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.351941  4353 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (23)
I0916 23:49:15.351945  4353 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0916 23:49:15.351955  4353 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0916 23:49:15.351961  4353 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0916 23:49:15.351986  4353 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0916 23:49:15.351991  4353 net.cpp:252] TEST Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 4 128 80 80 (3276800)
I0916 23:49:15.351996  4353 net.cpp:252] TEST Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 4 128 80 80 (3276800)
I0916 23:49:15.352000  4353 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0916 23:49:15.352005  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.352011  4353 net.cpp:184] Created Layer pool3 (24)
I0916 23:49:15.352015  4353 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0916 23:49:15.352020  4353 net.cpp:530] pool3 -> pool3
I0916 23:49:15.352051  4353 net.cpp:245] Setting up pool3
I0916 23:49:15.352057  4353 net.cpp:252] TEST Top shape for layer 24 'pool3' 4 128 40 40 (819200)
I0916 23:49:15.352062  4353 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0916 23:49:15.352066  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.352074  4353 net.cpp:184] Created Layer res4a_branch2a (25)
I0916 23:49:15.352078  4353 net.cpp:561] res4a_branch2a <- pool3
I0916 23:49:15.352082  4353 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0916 23:49:15.358940  4353 net.cpp:245] Setting up res4a_branch2a
I0916 23:49:15.358950  4353 net.cpp:252] TEST Top shape for layer 25 'res4a_branch2a' 4 256 40 40 (1638400)
I0916 23:49:15.358958  4353 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0916 23:49:15.358963  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.358969  4353 net.cpp:184] Created Layer res4a_branch2a/bn (26)
I0916 23:49:15.358973  4353 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0916 23:49:15.358978  4353 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0916 23:49:15.359382  4353 net.cpp:245] Setting up res4a_branch2a/bn
I0916 23:49:15.359390  4353 net.cpp:252] TEST Top shape for layer 26 'res4a_branch2a/bn' 4 256 40 40 (1638400)
I0916 23:49:15.359398  4353 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0916 23:49:15.359402  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.359407  4353 net.cpp:184] Created Layer res4a_branch2a/relu (27)
I0916 23:49:15.359411  4353 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0916 23:49:15.359414  4353 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0916 23:49:15.359421  4353 net.cpp:245] Setting up res4a_branch2a/relu
I0916 23:49:15.359426  4353 net.cpp:252] TEST Top shape for layer 27 'res4a_branch2a/relu' 4 256 40 40 (1638400)
I0916 23:49:15.359429  4353 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0916 23:49:15.359433  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.359441  4353 net.cpp:184] Created Layer res4a_branch2b (28)
I0916 23:49:15.359444  4353 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0916 23:49:15.359449  4353 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0916 23:49:15.362553  4353 net.cpp:245] Setting up res4a_branch2b
I0916 23:49:15.362563  4353 net.cpp:252] TEST Top shape for layer 28 'res4a_branch2b' 4 256 40 40 (1638400)
I0916 23:49:15.362571  4353 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0916 23:49:15.362574  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.362586  4353 net.cpp:184] Created Layer res4a_branch2b/bn (29)
I0916 23:49:15.362589  4353 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0916 23:49:15.362601  4353 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0916 23:49:15.362994  4353 net.cpp:245] Setting up res4a_branch2b/bn
I0916 23:49:15.363003  4353 net.cpp:252] TEST Top shape for layer 29 'res4a_branch2b/bn' 4 256 40 40 (1638400)
I0916 23:49:15.363011  4353 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0916 23:49:15.363015  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.363021  4353 net.cpp:184] Created Layer res4a_branch2b/relu (30)
I0916 23:49:15.363024  4353 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0916 23:49:15.363029  4353 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0916 23:49:15.363035  4353 net.cpp:245] Setting up res4a_branch2b/relu
I0916 23:49:15.363039  4353 net.cpp:252] TEST Top shape for layer 30 'res4a_branch2b/relu' 4 256 40 40 (1638400)
I0916 23:49:15.363044  4353 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0916 23:49:15.363047  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.363054  4353 net.cpp:184] Created Layer pool4 (31)
I0916 23:49:15.363057  4353 net.cpp:561] pool4 <- res4a_branch2b
I0916 23:49:15.363061  4353 net.cpp:530] pool4 -> pool4
I0916 23:49:15.363093  4353 net.cpp:245] Setting up pool4
I0916 23:49:15.363099  4353 net.cpp:252] TEST Top shape for layer 31 'pool4' 4 256 40 40 (1638400)
I0916 23:49:15.363103  4353 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0916 23:49:15.363107  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.363118  4353 net.cpp:184] Created Layer res5a_branch2a (32)
I0916 23:49:15.363122  4353 net.cpp:561] res5a_branch2a <- pool4
I0916 23:49:15.363126  4353 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0916 23:49:15.388260  4353 net.cpp:245] Setting up res5a_branch2a
I0916 23:49:15.388283  4353 net.cpp:252] TEST Top shape for layer 32 'res5a_branch2a' 4 512 40 40 (3276800)
I0916 23:49:15.388293  4353 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0916 23:49:15.388298  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.388309  4353 net.cpp:184] Created Layer res5a_branch2a/bn (33)
I0916 23:49:15.388314  4353 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0916 23:49:15.388319  4353 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0916 23:49:15.388761  4353 net.cpp:245] Setting up res5a_branch2a/bn
I0916 23:49:15.388768  4353 net.cpp:252] TEST Top shape for layer 33 'res5a_branch2a/bn' 4 512 40 40 (3276800)
I0916 23:49:15.388777  4353 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0916 23:49:15.388782  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.388794  4353 net.cpp:184] Created Layer res5a_branch2a/relu (34)
I0916 23:49:15.388798  4353 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0916 23:49:15.388803  4353 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0916 23:49:15.388810  4353 net.cpp:245] Setting up res5a_branch2a/relu
I0916 23:49:15.388814  4353 net.cpp:252] TEST Top shape for layer 34 'res5a_branch2a/relu' 4 512 40 40 (3276800)
I0916 23:49:15.388818  4353 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0916 23:49:15.388823  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.388833  4353 net.cpp:184] Created Layer res5a_branch2b (35)
I0916 23:49:15.388835  4353 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0916 23:49:15.388840  4353 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0916 23:49:15.401312  4353 net.cpp:245] Setting up res5a_branch2b
I0916 23:49:15.401330  4353 net.cpp:252] TEST Top shape for layer 35 'res5a_branch2b' 4 512 40 40 (3276800)
I0916 23:49:15.401345  4353 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0916 23:49:15.401360  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.401370  4353 net.cpp:184] Created Layer res5a_branch2b/bn (36)
I0916 23:49:15.401373  4353 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0916 23:49:15.401378  4353 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0916 23:49:15.401798  4353 net.cpp:245] Setting up res5a_branch2b/bn
I0916 23:49:15.401808  4353 net.cpp:252] TEST Top shape for layer 36 'res5a_branch2b/bn' 4 512 40 40 (3276800)
I0916 23:49:15.401815  4353 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0916 23:49:15.401819  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.401825  4353 net.cpp:184] Created Layer res5a_branch2b/relu (37)
I0916 23:49:15.401829  4353 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0916 23:49:15.401834  4353 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0916 23:49:15.401841  4353 net.cpp:245] Setting up res5a_branch2b/relu
I0916 23:49:15.401845  4353 net.cpp:252] TEST Top shape for layer 37 'res5a_branch2b/relu' 4 512 40 40 (3276800)
I0916 23:49:15.401849  4353 layer_factory.hpp:136] Creating layer 'out5a' of type 'Convolution'
I0916 23:49:15.401854  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.401863  4353 net.cpp:184] Created Layer out5a (38)
I0916 23:49:15.401866  4353 net.cpp:561] out5a <- res5a_branch2b
I0916 23:49:15.401870  4353 net.cpp:530] out5a -> out5a
I0916 23:49:15.405737  4353 net.cpp:245] Setting up out5a
I0916 23:49:15.405756  4353 net.cpp:252] TEST Top shape for layer 38 'out5a' 4 64 40 40 (409600)
I0916 23:49:15.405764  4353 layer_factory.hpp:136] Creating layer 'out5a/bn' of type 'BatchNorm'
I0916 23:49:15.405771  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.405778  4353 net.cpp:184] Created Layer out5a/bn (39)
I0916 23:49:15.405782  4353 net.cpp:561] out5a/bn <- out5a
I0916 23:49:15.405788  4353 net.cpp:513] out5a/bn -> out5a (in-place)
I0916 23:49:15.406229  4353 net.cpp:245] Setting up out5a/bn
I0916 23:49:15.406236  4353 net.cpp:252] TEST Top shape for layer 39 'out5a/bn' 4 64 40 40 (409600)
I0916 23:49:15.406245  4353 layer_factory.hpp:136] Creating layer 'out5a/relu' of type 'ReLU'
I0916 23:49:15.406250  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.406255  4353 net.cpp:184] Created Layer out5a/relu (40)
I0916 23:49:15.406260  4353 net.cpp:561] out5a/relu <- out5a
I0916 23:49:15.406265  4353 net.cpp:513] out5a/relu -> out5a (in-place)
I0916 23:49:15.406270  4353 net.cpp:245] Setting up out5a/relu
I0916 23:49:15.406275  4353 net.cpp:252] TEST Top shape for layer 40 'out5a/relu' 4 64 40 40 (409600)
I0916 23:49:15.406278  4353 layer_factory.hpp:136] Creating layer 'out5a_up2' of type 'Deconvolution'
I0916 23:49:15.406282  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.406297  4353 net.cpp:184] Created Layer out5a_up2 (41)
I0916 23:49:15.406301  4353 net.cpp:561] out5a_up2 <- out5a
I0916 23:49:15.406304  4353 net.cpp:530] out5a_up2 -> out5a_up2
I0916 23:49:15.406448  4353 net.cpp:245] Setting up out5a_up2
I0916 23:49:15.406455  4353 net.cpp:252] TEST Top shape for layer 41 'out5a_up2' 4 64 80 80 (1638400)
I0916 23:49:15.406461  4353 layer_factory.hpp:136] Creating layer 'out3a' of type 'Convolution'
I0916 23:49:15.406464  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.406473  4353 net.cpp:184] Created Layer out3a (42)
I0916 23:49:15.406477  4353 net.cpp:561] out3a <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0916 23:49:15.406482  4353 net.cpp:530] out3a -> out3a
I0916 23:49:15.407402  4353 net.cpp:245] Setting up out3a
I0916 23:49:15.407409  4353 net.cpp:252] TEST Top shape for layer 42 'out3a' 4 64 80 80 (1638400)
I0916 23:49:15.407425  4353 layer_factory.hpp:136] Creating layer 'out3a/bn' of type 'BatchNorm'
I0916 23:49:15.407429  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.407438  4353 net.cpp:184] Created Layer out3a/bn (43)
I0916 23:49:15.407440  4353 net.cpp:561] out3a/bn <- out3a
I0916 23:49:15.407445  4353 net.cpp:513] out3a/bn -> out3a (in-place)
I0916 23:49:15.407852  4353 net.cpp:245] Setting up out3a/bn
I0916 23:49:15.407860  4353 net.cpp:252] TEST Top shape for layer 43 'out3a/bn' 4 64 80 80 (1638400)
I0916 23:49:15.407869  4353 layer_factory.hpp:136] Creating layer 'out3a/relu' of type 'ReLU'
I0916 23:49:15.407872  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.407878  4353 net.cpp:184] Created Layer out3a/relu (44)
I0916 23:49:15.407881  4353 net.cpp:561] out3a/relu <- out3a
I0916 23:49:15.407886  4353 net.cpp:513] out3a/relu -> out3a (in-place)
I0916 23:49:15.407891  4353 net.cpp:245] Setting up out3a/relu
I0916 23:49:15.407896  4353 net.cpp:252] TEST Top shape for layer 44 'out3a/relu' 4 64 80 80 (1638400)
I0916 23:49:15.407901  4353 layer_factory.hpp:136] Creating layer 'out3_out5_combined' of type 'Eltwise'
I0916 23:49:15.407904  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.408342  4353 net.cpp:184] Created Layer out3_out5_combined (45)
I0916 23:49:15.408349  4353 net.cpp:561] out3_out5_combined <- out5a_up2
I0916 23:49:15.408351  4353 net.cpp:561] out3_out5_combined <- out3a
I0916 23:49:15.408354  4353 net.cpp:530] out3_out5_combined -> out3_out5_combined
I0916 23:49:15.408375  4353 net.cpp:245] Setting up out3_out5_combined
I0916 23:49:15.408378  4353 net.cpp:252] TEST Top shape for layer 45 'out3_out5_combined' 4 64 80 80 (1638400)
I0916 23:49:15.408380  4353 layer_factory.hpp:136] Creating layer 'ctx_conv1' of type 'Convolution'
I0916 23:49:15.408383  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.408390  4353 net.cpp:184] Created Layer ctx_conv1 (46)
I0916 23:49:15.408394  4353 net.cpp:561] ctx_conv1 <- out3_out5_combined
I0916 23:49:15.408396  4353 net.cpp:530] ctx_conv1 -> ctx_conv1
I0916 23:49:15.409301  4353 net.cpp:245] Setting up ctx_conv1
I0916 23:49:15.409308  4353 net.cpp:252] TEST Top shape for layer 46 'ctx_conv1' 4 64 80 80 (1638400)
I0916 23:49:15.409312  4353 layer_factory.hpp:136] Creating layer 'ctx_conv1/bn' of type 'BatchNorm'
I0916 23:49:15.409315  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.409319  4353 net.cpp:184] Created Layer ctx_conv1/bn (47)
I0916 23:49:15.409322  4353 net.cpp:561] ctx_conv1/bn <- ctx_conv1
I0916 23:49:15.409323  4353 net.cpp:513] ctx_conv1/bn -> ctx_conv1 (in-place)
I0916 23:49:15.409724  4353 net.cpp:245] Setting up ctx_conv1/bn
I0916 23:49:15.409730  4353 net.cpp:252] TEST Top shape for layer 47 'ctx_conv1/bn' 4 64 80 80 (1638400)
I0916 23:49:15.409736  4353 layer_factory.hpp:136] Creating layer 'ctx_conv1/relu' of type 'ReLU'
I0916 23:49:15.409739  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.409741  4353 net.cpp:184] Created Layer ctx_conv1/relu (48)
I0916 23:49:15.409744  4353 net.cpp:561] ctx_conv1/relu <- ctx_conv1
I0916 23:49:15.409745  4353 net.cpp:513] ctx_conv1/relu -> ctx_conv1 (in-place)
I0916 23:49:15.409749  4353 net.cpp:245] Setting up ctx_conv1/relu
I0916 23:49:15.409751  4353 net.cpp:252] TEST Top shape for layer 48 'ctx_conv1/relu' 4 64 80 80 (1638400)
I0916 23:49:15.409754  4353 layer_factory.hpp:136] Creating layer 'ctx_conv2' of type 'Convolution'
I0916 23:49:15.409755  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.409759  4353 net.cpp:184] Created Layer ctx_conv2 (49)
I0916 23:49:15.409762  4353 net.cpp:561] ctx_conv2 <- ctx_conv1
I0916 23:49:15.409765  4353 net.cpp:530] ctx_conv2 -> ctx_conv2
I0916 23:49:15.410678  4353 net.cpp:245] Setting up ctx_conv2
I0916 23:49:15.410686  4353 net.cpp:252] TEST Top shape for layer 49 'ctx_conv2' 4 64 80 80 (1638400)
I0916 23:49:15.410689  4353 layer_factory.hpp:136] Creating layer 'ctx_conv2/bn' of type 'BatchNorm'
I0916 23:49:15.410692  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.410696  4353 net.cpp:184] Created Layer ctx_conv2/bn (50)
I0916 23:49:15.410698  4353 net.cpp:561] ctx_conv2/bn <- ctx_conv2
I0916 23:49:15.410701  4353 net.cpp:513] ctx_conv2/bn -> ctx_conv2 (in-place)
I0916 23:49:15.411103  4353 net.cpp:245] Setting up ctx_conv2/bn
I0916 23:49:15.411109  4353 net.cpp:252] TEST Top shape for layer 50 'ctx_conv2/bn' 4 64 80 80 (1638400)
I0916 23:49:15.411114  4353 layer_factory.hpp:136] Creating layer 'ctx_conv2/relu' of type 'ReLU'
I0916 23:49:15.411118  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.411120  4353 net.cpp:184] Created Layer ctx_conv2/relu (51)
I0916 23:49:15.411123  4353 net.cpp:561] ctx_conv2/relu <- ctx_conv2
I0916 23:49:15.411124  4353 net.cpp:513] ctx_conv2/relu -> ctx_conv2 (in-place)
I0916 23:49:15.411128  4353 net.cpp:245] Setting up ctx_conv2/relu
I0916 23:49:15.411130  4353 net.cpp:252] TEST Top shape for layer 51 'ctx_conv2/relu' 4 64 80 80 (1638400)
I0916 23:49:15.411133  4353 layer_factory.hpp:136] Creating layer 'ctx_conv3' of type 'Convolution'
I0916 23:49:15.411134  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.411140  4353 net.cpp:184] Created Layer ctx_conv3 (52)
I0916 23:49:15.411144  4353 net.cpp:561] ctx_conv3 <- ctx_conv2
I0916 23:49:15.411146  4353 net.cpp:530] ctx_conv3 -> ctx_conv3
I0916 23:49:15.412045  4353 net.cpp:245] Setting up ctx_conv3
I0916 23:49:15.412052  4353 net.cpp:252] TEST Top shape for layer 52 'ctx_conv3' 4 64 80 80 (1638400)
I0916 23:49:15.412055  4353 layer_factory.hpp:136] Creating layer 'ctx_conv3/bn' of type 'BatchNorm'
I0916 23:49:15.412058  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.412061  4353 net.cpp:184] Created Layer ctx_conv3/bn (53)
I0916 23:49:15.412065  4353 net.cpp:561] ctx_conv3/bn <- ctx_conv3
I0916 23:49:15.412066  4353 net.cpp:513] ctx_conv3/bn -> ctx_conv3 (in-place)
I0916 23:49:15.412459  4353 net.cpp:245] Setting up ctx_conv3/bn
I0916 23:49:15.412466  4353 net.cpp:252] TEST Top shape for layer 53 'ctx_conv3/bn' 4 64 80 80 (1638400)
I0916 23:49:15.412470  4353 layer_factory.hpp:136] Creating layer 'ctx_conv3/relu' of type 'ReLU'
I0916 23:49:15.412473  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.412477  4353 net.cpp:184] Created Layer ctx_conv3/relu (54)
I0916 23:49:15.412478  4353 net.cpp:561] ctx_conv3/relu <- ctx_conv3
I0916 23:49:15.412480  4353 net.cpp:513] ctx_conv3/relu -> ctx_conv3 (in-place)
I0916 23:49:15.412483  4353 net.cpp:245] Setting up ctx_conv3/relu
I0916 23:49:15.412485  4353 net.cpp:252] TEST Top shape for layer 54 'ctx_conv3/relu' 4 64 80 80 (1638400)
I0916 23:49:15.412487  4353 layer_factory.hpp:136] Creating layer 'ctx_conv4' of type 'Convolution'
I0916 23:49:15.412489  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.412494  4353 net.cpp:184] Created Layer ctx_conv4 (55)
I0916 23:49:15.412497  4353 net.cpp:561] ctx_conv4 <- ctx_conv3
I0916 23:49:15.412498  4353 net.cpp:530] ctx_conv4 -> ctx_conv4
I0916 23:49:15.413398  4353 net.cpp:245] Setting up ctx_conv4
I0916 23:49:15.413404  4353 net.cpp:252] TEST Top shape for layer 55 'ctx_conv4' 4 64 80 80 (1638400)
I0916 23:49:15.413408  4353 layer_factory.hpp:136] Creating layer 'ctx_conv4/bn' of type 'BatchNorm'
I0916 23:49:15.413410  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.413414  4353 net.cpp:184] Created Layer ctx_conv4/bn (56)
I0916 23:49:15.413415  4353 net.cpp:561] ctx_conv4/bn <- ctx_conv4
I0916 23:49:15.413424  4353 net.cpp:513] ctx_conv4/bn -> ctx_conv4 (in-place)
I0916 23:49:15.413836  4353 net.cpp:245] Setting up ctx_conv4/bn
I0916 23:49:15.413843  4353 net.cpp:252] TEST Top shape for layer 56 'ctx_conv4/bn' 4 64 80 80 (1638400)
I0916 23:49:15.413848  4353 layer_factory.hpp:136] Creating layer 'ctx_conv4/relu' of type 'ReLU'
I0916 23:49:15.413851  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.413853  4353 net.cpp:184] Created Layer ctx_conv4/relu (57)
I0916 23:49:15.413856  4353 net.cpp:561] ctx_conv4/relu <- ctx_conv4
I0916 23:49:15.413857  4353 net.cpp:513] ctx_conv4/relu -> ctx_conv4 (in-place)
I0916 23:49:15.413862  4353 net.cpp:245] Setting up ctx_conv4/relu
I0916 23:49:15.413866  4353 net.cpp:252] TEST Top shape for layer 57 'ctx_conv4/relu' 4 64 80 80 (1638400)
I0916 23:49:15.413867  4353 layer_factory.hpp:136] Creating layer 'ctx_final' of type 'Convolution'
I0916 23:49:15.413869  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.413877  4353 net.cpp:184] Created Layer ctx_final (58)
I0916 23:49:15.413879  4353 net.cpp:561] ctx_final <- ctx_conv4
I0916 23:49:15.413882  4353 net.cpp:530] ctx_final -> ctx_final
I0916 23:49:15.414157  4353 net.cpp:245] Setting up ctx_final
I0916 23:49:15.414165  4353 net.cpp:252] TEST Top shape for layer 58 'ctx_final' 4 8 80 80 (204800)
I0916 23:49:15.414171  4353 layer_factory.hpp:136] Creating layer 'ctx_final/relu' of type 'ReLU'
I0916 23:49:15.414175  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.414177  4353 net.cpp:184] Created Layer ctx_final/relu (59)
I0916 23:49:15.414180  4353 net.cpp:561] ctx_final/relu <- ctx_final
I0916 23:49:15.414181  4353 net.cpp:513] ctx_final/relu -> ctx_final (in-place)
I0916 23:49:15.414185  4353 net.cpp:245] Setting up ctx_final/relu
I0916 23:49:15.414187  4353 net.cpp:252] TEST Top shape for layer 59 'ctx_final/relu' 4 8 80 80 (204800)
I0916 23:49:15.414189  4353 layer_factory.hpp:136] Creating layer 'out_deconv_final_up2' of type 'Deconvolution'
I0916 23:49:15.414191  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.414196  4353 net.cpp:184] Created Layer out_deconv_final_up2 (60)
I0916 23:49:15.414199  4353 net.cpp:561] out_deconv_final_up2 <- ctx_final
I0916 23:49:15.414201  4353 net.cpp:530] out_deconv_final_up2 -> out_deconv_final_up2
I0916 23:49:15.414326  4353 net.cpp:245] Setting up out_deconv_final_up2
I0916 23:49:15.414331  4353 net.cpp:252] TEST Top shape for layer 60 'out_deconv_final_up2' 4 8 160 160 (819200)
I0916 23:49:15.414335  4353 layer_factory.hpp:136] Creating layer 'out_deconv_final_up4' of type 'Deconvolution'
I0916 23:49:15.414337  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.414341  4353 net.cpp:184] Created Layer out_deconv_final_up4 (61)
I0916 23:49:15.414345  4353 net.cpp:561] out_deconv_final_up4 <- out_deconv_final_up2
I0916 23:49:15.414347  4353 net.cpp:530] out_deconv_final_up4 -> out_deconv_final_up4
I0916 23:49:15.414463  4353 net.cpp:245] Setting up out_deconv_final_up4
I0916 23:49:15.414469  4353 net.cpp:252] TEST Top shape for layer 61 'out_deconv_final_up4' 4 8 320 320 (3276800)
I0916 23:49:15.414471  4353 layer_factory.hpp:136] Creating layer 'out_deconv_final_up8' of type 'Deconvolution'
I0916 23:49:15.414474  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.414479  4353 net.cpp:184] Created Layer out_deconv_final_up8 (62)
I0916 23:49:15.414481  4353 net.cpp:561] out_deconv_final_up8 <- out_deconv_final_up4
I0916 23:49:15.414484  4353 net.cpp:530] out_deconv_final_up8 -> out_deconv_final_up8
I0916 23:49:15.414598  4353 net.cpp:245] Setting up out_deconv_final_up8
I0916 23:49:15.414603  4353 net.cpp:252] TEST Top shape for layer 62 'out_deconv_final_up8' 4 8 640 640 (13107200)
I0916 23:49:15.414613  4353 layer_factory.hpp:136] Creating layer 'out_deconv_final_up8_out_deconv_final_up8_0_split' of type 'Split'
I0916 23:49:15.414615  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.414618  4353 net.cpp:184] Created Layer out_deconv_final_up8_out_deconv_final_up8_0_split (63)
I0916 23:49:15.414621  4353 net.cpp:561] out_deconv_final_up8_out_deconv_final_up8_0_split <- out_deconv_final_up8
I0916 23:49:15.414623  4353 net.cpp:530] out_deconv_final_up8_out_deconv_final_up8_0_split -> out_deconv_final_up8_out_deconv_final_up8_0_split_0
I0916 23:49:15.414626  4353 net.cpp:530] out_deconv_final_up8_out_deconv_final_up8_0_split -> out_deconv_final_up8_out_deconv_final_up8_0_split_1
I0916 23:49:15.414629  4353 net.cpp:530] out_deconv_final_up8_out_deconv_final_up8_0_split -> out_deconv_final_up8_out_deconv_final_up8_0_split_2
I0916 23:49:15.414660  4353 net.cpp:245] Setting up out_deconv_final_up8_out_deconv_final_up8_0_split
I0916 23:49:15.414664  4353 net.cpp:252] TEST Top shape for layer 63 'out_deconv_final_up8_out_deconv_final_up8_0_split' 4 8 640 640 (13107200)
I0916 23:49:15.414666  4353 net.cpp:252] TEST Top shape for layer 63 'out_deconv_final_up8_out_deconv_final_up8_0_split' 4 8 640 640 (13107200)
I0916 23:49:15.414669  4353 net.cpp:252] TEST Top shape for layer 63 'out_deconv_final_up8_out_deconv_final_up8_0_split' 4 8 640 640 (13107200)
I0916 23:49:15.414672  4353 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0916 23:49:15.414674  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.414683  4353 net.cpp:184] Created Layer loss (64)
I0916 23:49:15.414686  4353 net.cpp:561] loss <- out_deconv_final_up8_out_deconv_final_up8_0_split_0
I0916 23:49:15.414690  4353 net.cpp:561] loss <- label_data_1_split_0
I0916 23:49:15.414693  4353 net.cpp:530] loss -> loss
I0916 23:49:15.415697  4353 net.cpp:245] Setting up loss
I0916 23:49:15.415705  4353 net.cpp:252] TEST Top shape for layer 64 'loss' (1)
I0916 23:49:15.415709  4353 net.cpp:256]     with loss weight 1
I0916 23:49:15.415720  4353 layer_factory.hpp:136] Creating layer 'accuracy/top1' of type 'Accuracy'
I0916 23:49:15.415724  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.415729  4353 net.cpp:184] Created Layer accuracy/top1 (65)
I0916 23:49:15.415732  4353 net.cpp:561] accuracy/top1 <- out_deconv_final_up8_out_deconv_final_up8_0_split_1
I0916 23:49:15.415735  4353 net.cpp:561] accuracy/top1 <- label_data_1_split_1
I0916 23:49:15.415740  4353 net.cpp:530] accuracy/top1 -> accuracy/top1
I0916 23:49:15.415743  4353 net.cpp:245] Setting up accuracy/top1
I0916 23:49:15.415746  4353 net.cpp:252] TEST Top shape for layer 65 'accuracy/top1' (1)
I0916 23:49:15.415750  4353 layer_factory.hpp:136] Creating layer 'accuracy/top5' of type 'Accuracy'
I0916 23:49:15.415752  4353 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:15.415755  4353 net.cpp:184] Created Layer accuracy/top5 (66)
I0916 23:49:15.415758  4353 net.cpp:561] accuracy/top5 <- out_deconv_final_up8_out_deconv_final_up8_0_split_2
I0916 23:49:15.415761  4353 net.cpp:561] accuracy/top5 <- label_data_1_split_2
I0916 23:49:15.415765  4353 net.cpp:530] accuracy/top5 -> accuracy/top5
I0916 23:49:15.415768  4353 net.cpp:245] Setting up accuracy/top5
I0916 23:49:15.415771  4353 net.cpp:252] TEST Top shape for layer 66 'accuracy/top5' (1)
I0916 23:49:15.415774  4353 net.cpp:325] accuracy/top5 does not need backward computation.
I0916 23:49:15.415776  4353 net.cpp:325] accuracy/top1 does not need backward computation.
I0916 23:49:15.415778  4353 net.cpp:323] loss needs backward computation.
I0916 23:49:15.415781  4353 net.cpp:323] out_deconv_final_up8_out_deconv_final_up8_0_split needs backward computation.
I0916 23:49:15.415784  4353 net.cpp:323] out_deconv_final_up8 needs backward computation.
I0916 23:49:15.415786  4353 net.cpp:323] out_deconv_final_up4 needs backward computation.
I0916 23:49:15.415794  4353 net.cpp:323] out_deconv_final_up2 needs backward computation.
I0916 23:49:15.415797  4353 net.cpp:323] ctx_final/relu needs backward computation.
I0916 23:49:15.415799  4353 net.cpp:323] ctx_final needs backward computation.
I0916 23:49:15.415802  4353 net.cpp:323] ctx_conv4/relu needs backward computation.
I0916 23:49:15.415803  4353 net.cpp:323] ctx_conv4/bn needs backward computation.
I0916 23:49:15.415805  4353 net.cpp:323] ctx_conv4 needs backward computation.
I0916 23:49:15.415807  4353 net.cpp:323] ctx_conv3/relu needs backward computation.
I0916 23:49:15.415809  4353 net.cpp:323] ctx_conv3/bn needs backward computation.
I0916 23:49:15.415812  4353 net.cpp:323] ctx_conv3 needs backward computation.
I0916 23:49:15.415813  4353 net.cpp:323] ctx_conv2/relu needs backward computation.
I0916 23:49:15.415815  4353 net.cpp:323] ctx_conv2/bn needs backward computation.
I0916 23:49:15.415817  4353 net.cpp:323] ctx_conv2 needs backward computation.
I0916 23:49:15.415819  4353 net.cpp:323] ctx_conv1/relu needs backward computation.
I0916 23:49:15.415822  4353 net.cpp:323] ctx_conv1/bn needs backward computation.
I0916 23:49:15.415823  4353 net.cpp:323] ctx_conv1 needs backward computation.
I0916 23:49:15.415827  4353 net.cpp:323] out3_out5_combined needs backward computation.
I0916 23:49:15.415829  4353 net.cpp:323] out3a/relu needs backward computation.
I0916 23:49:15.415832  4353 net.cpp:323] out3a/bn needs backward computation.
I0916 23:49:15.415833  4353 net.cpp:323] out3a needs backward computation.
I0916 23:49:15.415837  4353 net.cpp:323] out5a_up2 needs backward computation.
I0916 23:49:15.415838  4353 net.cpp:323] out5a/relu needs backward computation.
I0916 23:49:15.415840  4353 net.cpp:323] out5a/bn needs backward computation.
I0916 23:49:15.415843  4353 net.cpp:323] out5a needs backward computation.
I0916 23:49:15.415845  4353 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0916 23:49:15.415849  4353 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0916 23:49:15.415853  4353 net.cpp:323] res5a_branch2b needs backward computation.
I0916 23:49:15.415858  4353 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0916 23:49:15.415861  4353 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0916 23:49:15.415863  4353 net.cpp:323] res5a_branch2a needs backward computation.
I0916 23:49:15.415866  4353 net.cpp:323] pool4 needs backward computation.
I0916 23:49:15.415869  4353 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0916 23:49:15.415871  4353 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0916 23:49:15.415874  4353 net.cpp:323] res4a_branch2b needs backward computation.
I0916 23:49:15.415875  4353 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0916 23:49:15.415877  4353 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0916 23:49:15.415879  4353 net.cpp:323] res4a_branch2a needs backward computation.
I0916 23:49:15.415882  4353 net.cpp:323] pool3 needs backward computation.
I0916 23:49:15.415885  4353 net.cpp:323] res3a_branch2b_res3a_branch2b/relu_0_split needs backward computation.
I0916 23:49:15.415887  4353 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0916 23:49:15.415889  4353 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0916 23:49:15.415891  4353 net.cpp:323] res3a_branch2b needs backward computation.
I0916 23:49:15.415894  4353 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0916 23:49:15.415896  4353 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0916 23:49:15.415899  4353 net.cpp:323] res3a_branch2a needs backward computation.
I0916 23:49:15.415901  4353 net.cpp:323] pool2 needs backward computation.
I0916 23:49:15.415904  4353 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0916 23:49:15.415906  4353 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0916 23:49:15.415908  4353 net.cpp:323] res2a_branch2b needs backward computation.
I0916 23:49:15.415911  4353 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0916 23:49:15.415917  4353 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0916 23:49:15.415920  4353 net.cpp:323] res2a_branch2a needs backward computation.
I0916 23:49:15.415921  4353 net.cpp:323] pool1 needs backward computation.
I0916 23:49:15.415925  4353 net.cpp:323] conv1b/relu needs backward computation.
I0916 23:49:15.415927  4353 net.cpp:323] conv1b/bn needs backward computation.
I0916 23:49:15.415928  4353 net.cpp:323] conv1b needs backward computation.
I0916 23:49:15.415930  4353 net.cpp:323] conv1a/relu needs backward computation.
I0916 23:49:15.415933  4353 net.cpp:323] conv1a/bn needs backward computation.
I0916 23:49:15.415935  4353 net.cpp:323] conv1a needs backward computation.
I0916 23:49:15.415937  4353 net.cpp:325] data/bias does not need backward computation.
I0916 23:49:15.415940  4353 net.cpp:325] label_data_1_split does not need backward computation.
I0916 23:49:15.415943  4353 net.cpp:325] data does not need backward computation.
I0916 23:49:15.415946  4353 net.cpp:367] This network produces output accuracy/top1
I0916 23:49:15.415948  4353 net.cpp:367] This network produces output accuracy/top5
I0916 23:49:15.415951  4353 net.cpp:367] This network produces output loss
I0916 23:49:15.415990  4353 net.cpp:389] Top memory (TEST) required for data: 1133772824 diff: 1133772824
I0916 23:49:15.415993  4353 net.cpp:392] Bottom memory (TEST) required for data: 1133772800 diff: 1133772800
I0916 23:49:15.415995  4353 net.cpp:395] Shared (in-place) memory (TEST) by data: 515276800 diff: 515276800
I0916 23:49:15.415997  4353 net.cpp:398] Parameters memory (TEST) required for data: 10817840 diff: 10817840
I0916 23:49:15.415999  4353 net.cpp:401] Parameters shared memory (TEST) by data: 0 diff: 0
I0916 23:49:15.416002  4353 net.cpp:407] Network initialization done.
I0916 23:49:15.420356  4353 net.cpp:1094] Copying source layer data Type:ImageLabelData #blobs=0
I0916 23:49:15.420377  4353 net.cpp:1094] Copying source layer data/bias Type:Bias #blobs=1
I0916 23:49:15.420409  4353 net.cpp:1094] Copying source layer conv1a Type:Convolution #blobs=2
I0916 23:49:15.420420  4353 net.cpp:1094] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0916 23:49:15.420567  4353 net.cpp:1094] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0916 23:49:15.420572  4353 net.cpp:1094] Copying source layer conv1b Type:Convolution #blobs=2
I0916 23:49:15.420580  4353 net.cpp:1094] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0916 23:49:15.420668  4353 net.cpp:1094] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0916 23:49:15.420672  4353 net.cpp:1094] Copying source layer pool1 Type:Pooling #blobs=0
I0916 23:49:15.420675  4353 net.cpp:1094] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0916 23:49:15.420691  4353 net.cpp:1094] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0916 23:49:15.420781  4353 net.cpp:1094] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0916 23:49:15.420785  4353 net.cpp:1094] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0916 23:49:15.420796  4353 net.cpp:1094] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0916 23:49:15.420882  4353 net.cpp:1094] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0916 23:49:15.420886  4353 net.cpp:1094] Copying source layer pool2 Type:Pooling #blobs=0
I0916 23:49:15.420889  4353 net.cpp:1094] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0916 23:49:15.420927  4353 net.cpp:1094] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0916 23:49:15.421010  4353 net.cpp:1094] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0916 23:49:15.421013  4353 net.cpp:1094] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0916 23:49:15.421036  4353 net.cpp:1094] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0916 23:49:15.421111  4353 net.cpp:1094] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0916 23:49:15.421116  4353 net.cpp:1094] Copying source layer res3a_branch2b_res3a_branch2b/relu_0_split Type:Split #blobs=0
I0916 23:49:15.421129  4353 net.cpp:1094] Copying source layer pool3 Type:Pooling #blobs=0
I0916 23:49:15.421133  4353 net.cpp:1094] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0916 23:49:15.421247  4353 net.cpp:1094] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0916 23:49:15.421329  4353 net.cpp:1094] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0916 23:49:15.421332  4353 net.cpp:1094] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0916 23:49:15.421394  4353 net.cpp:1094] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0916 23:49:15.421473  4353 net.cpp:1094] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0916 23:49:15.421478  4353 net.cpp:1094] Copying source layer pool4 Type:Pooling #blobs=0
I0916 23:49:15.421479  4353 net.cpp:1094] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0916 23:49:15.421844  4353 net.cpp:1094] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0916 23:49:15.421922  4353 net.cpp:1094] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0916 23:49:15.421927  4353 net.cpp:1094] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0916 23:49:15.422099  4353 net.cpp:1094] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0916 23:49:15.422184  4353 net.cpp:1094] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0916 23:49:15.422188  4353 net.cpp:1094] Copying source layer out5a Type:Convolution #blobs=2
I0916 23:49:15.422231  4353 net.cpp:1094] Copying source layer out5a/bn Type:BatchNorm #blobs=5
I0916 23:49:15.422320  4353 net.cpp:1094] Copying source layer out5a/relu Type:ReLU #blobs=0
I0916 23:49:15.422324  4353 net.cpp:1094] Copying source layer out5a_up2 Type:Deconvolution #blobs=1
I0916 23:49:15.422330  4353 net.cpp:1094] Copying source layer out3a Type:Convolution #blobs=2
I0916 23:49:15.422346  4353 net.cpp:1094] Copying source layer out3a/bn Type:BatchNorm #blobs=5
I0916 23:49:15.422439  4353 net.cpp:1094] Copying source layer out3a/relu Type:ReLU #blobs=0
I0916 23:49:15.422444  4353 net.cpp:1094] Copying source layer out3_out5_combined Type:Eltwise #blobs=0
I0916 23:49:15.422446  4353 net.cpp:1094] Copying source layer ctx_conv1 Type:Convolution #blobs=2
I0916 23:49:15.422464  4353 net.cpp:1094] Copying source layer ctx_conv1/bn Type:BatchNorm #blobs=5
I0916 23:49:15.422549  4353 net.cpp:1094] Copying source layer ctx_conv1/relu Type:ReLU #blobs=0
I0916 23:49:15.422552  4353 net.cpp:1094] Copying source layer ctx_conv2 Type:Convolution #blobs=2
I0916 23:49:15.422571  4353 net.cpp:1094] Copying source layer ctx_conv2/bn Type:BatchNorm #blobs=5
I0916 23:49:15.422659  4353 net.cpp:1094] Copying source layer ctx_conv2/relu Type:ReLU #blobs=0
I0916 23:49:15.422663  4353 net.cpp:1094] Copying source layer ctx_conv3 Type:Convolution #blobs=2
I0916 23:49:15.422680  4353 net.cpp:1094] Copying source layer ctx_conv3/bn Type:BatchNorm #blobs=5
I0916 23:49:15.422763  4353 net.cpp:1094] Copying source layer ctx_conv3/relu Type:ReLU #blobs=0
I0916 23:49:15.422767  4353 net.cpp:1094] Copying source layer ctx_conv4 Type:Convolution #blobs=2
I0916 23:49:15.422785  4353 net.cpp:1094] Copying source layer ctx_conv4/bn Type:BatchNorm #blobs=5
I0916 23:49:15.422868  4353 net.cpp:1094] Copying source layer ctx_conv4/relu Type:ReLU #blobs=0
I0916 23:49:15.422871  4353 net.cpp:1094] Copying source layer ctx_final Type:Convolution #blobs=2
I0916 23:49:15.422879  4353 net.cpp:1094] Copying source layer ctx_final/relu Type:ReLU #blobs=0
I0916 23:49:15.422883  4353 net.cpp:1094] Copying source layer out_deconv_final_up2 Type:Deconvolution #blobs=1
I0916 23:49:15.422888  4353 net.cpp:1094] Copying source layer out_deconv_final_up4 Type:Deconvolution #blobs=1
I0916 23:49:15.422894  4353 net.cpp:1094] Copying source layer out_deconv_final_up8 Type:Deconvolution #blobs=1
I0916 23:49:15.422899  4353 net.cpp:1094] Copying source layer loss Type:SoftmaxWithLoss #blobs=0
I0916 23:49:15.422987  4353 caffe.cpp:296] Running for 50 iterations.
I0916 23:49:15.630081  4353 caffe.cpp:319] Batch 0, accuracy/top1 = 0.907202
I0916 23:49:15.630105  4353 caffe.cpp:319] Batch 0, accuracy/top5 = 1
I0916 23:49:15.630108  4353 caffe.cpp:319] Batch 0, loss = 0.403046
I0916 23:49:15.781394  4353 caffe.cpp:319] Batch 1, accuracy/top1 = 0.917131
I0916 23:49:15.781415  4353 caffe.cpp:319] Batch 1, accuracy/top5 = 1
I0916 23:49:15.781419  4353 caffe.cpp:319] Batch 1, loss = 0.213055
I0916 23:49:15.787607  4353 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1a' with space 0G 3/1 1 	(avail 6.7G, req 0G)	t: 0
I0916 23:49:15.797245  4353 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1b' with space 0G 32/4 6 	(avail 6.7G, req 0G)	t: 0
I0916 23:49:15.811437  4353 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2a' with space 0G 32/1 6 	(avail 6.7G, req 0G)	t: 0
I0916 23:49:15.816717  4353 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2b' with space 0G 64/4 6 	(avail 6.7G, req 0G)	t: 0
I0916 23:49:15.825498  4353 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2a' with space 0G 64/1 6 	(avail 6.7G, req 0G)	t: 0
I0916 23:49:15.828804  4353 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2b' with space 0G 128/4 6 	(avail 6.7G, req 0G)	t: 0
I0916 23:49:15.836091  4353 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2a' with space 0G 128/1 1 	(avail 6.7G, req 0G)	t: 0
I0916 23:49:15.839385  4353 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2b' with space 0G 256/4 6 	(avail 6.7G, req 0G)	t: 0
I0916 23:49:15.856842  4353 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'out3a' with space 0G 128/2 6 	(avail 6.7G, req 0G)	t: 0
I0916 23:49:15.862576  4353 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_conv1' with space 0G 64/1 6 	(avail 6.7G, req 0G)	t: 0
I0916 23:49:15.869936  4353 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_final' with space 0G 64/1 6 	(avail 6.7G, req 0G)	t: 0
I0916 23:49:15.991693  4353 caffe.cpp:319] Batch 2, accuracy/top1 = 0.952279
I0916 23:49:15.991714  4353 caffe.cpp:319] Batch 2, accuracy/top5 = 1
I0916 23:49:15.991719  4353 caffe.cpp:319] Batch 2, loss = 0.125531
I0916 23:49:16.142786  4353 caffe.cpp:319] Batch 3, accuracy/top1 = 0.974437
I0916 23:49:16.142809  4353 caffe.cpp:319] Batch 3, accuracy/top5 = 1
I0916 23:49:16.142814  4353 caffe.cpp:319] Batch 3, loss = 0.0727413
I0916 23:49:16.290361  4353 caffe.cpp:319] Batch 4, accuracy/top1 = 0.971864
I0916 23:49:16.290385  4353 caffe.cpp:319] Batch 4, accuracy/top5 = 1
I0916 23:49:16.290390  4353 caffe.cpp:319] Batch 4, loss = 0.0942171
I0916 23:49:16.441831  4353 caffe.cpp:319] Batch 5, accuracy/top1 = 0.859687
I0916 23:49:16.441853  4353 caffe.cpp:319] Batch 5, accuracy/top5 = 1
I0916 23:49:16.441856  4353 caffe.cpp:319] Batch 5, loss = 0.612788
I0916 23:49:16.593804  4353 caffe.cpp:319] Batch 6, accuracy/top1 = 0.960686
I0916 23:49:16.593827  4353 caffe.cpp:319] Batch 6, accuracy/top5 = 1
I0916 23:49:16.593832  4353 caffe.cpp:319] Batch 6, loss = 0.108027
I0916 23:49:16.742034  4353 caffe.cpp:319] Batch 7, accuracy/top1 = 0.896315
I0916 23:49:16.742058  4353 caffe.cpp:319] Batch 7, accuracy/top5 = 1
I0916 23:49:16.742061  4353 caffe.cpp:319] Batch 7, loss = 0.268237
I0916 23:49:16.891021  4353 caffe.cpp:319] Batch 8, accuracy/top1 = 0.973945
I0916 23:49:16.891041  4353 caffe.cpp:319] Batch 8, accuracy/top5 = 1
I0916 23:49:16.891046  4353 caffe.cpp:319] Batch 8, loss = 0.0676959
I0916 23:49:17.039310  4353 caffe.cpp:319] Batch 9, accuracy/top1 = 0.985135
I0916 23:49:17.039330  4353 caffe.cpp:319] Batch 9, accuracy/top5 = 1
I0916 23:49:17.039333  4353 caffe.cpp:319] Batch 9, loss = 0.0424442
I0916 23:49:17.189702  4353 caffe.cpp:319] Batch 10, accuracy/top1 = 0.962302
I0916 23:49:17.189723  4353 caffe.cpp:319] Batch 10, accuracy/top5 = 1
I0916 23:49:17.189726  4353 caffe.cpp:319] Batch 10, loss = 0.114245
I0916 23:49:17.338799  4353 caffe.cpp:319] Batch 11, accuracy/top1 = 0.97941
I0916 23:49:17.338817  4353 caffe.cpp:319] Batch 11, accuracy/top5 = 1
I0916 23:49:17.338821  4353 caffe.cpp:319] Batch 11, loss = 0.0592207
I0916 23:49:17.488739  4353 caffe.cpp:319] Batch 12, accuracy/top1 = 0.969529
I0916 23:49:17.488762  4353 caffe.cpp:319] Batch 12, accuracy/top5 = 1
I0916 23:49:17.488766  4353 caffe.cpp:319] Batch 12, loss = 0.0891918
I0916 23:49:17.637183  4353 caffe.cpp:319] Batch 13, accuracy/top1 = 0.968117
I0916 23:49:17.637204  4353 caffe.cpp:319] Batch 13, accuracy/top5 = 1
I0916 23:49:17.637208  4353 caffe.cpp:319] Batch 13, loss = 0.0869573
I0916 23:49:17.795001  4353 caffe.cpp:319] Batch 14, accuracy/top1 = 0.985565
I0916 23:49:17.795022  4353 caffe.cpp:319] Batch 14, accuracy/top5 = 1
I0916 23:49:17.795025  4353 caffe.cpp:319] Batch 14, loss = 0.0443023
I0916 23:49:17.945377  4353 caffe.cpp:319] Batch 15, accuracy/top1 = 0.969195
I0916 23:49:17.945400  4353 caffe.cpp:319] Batch 15, accuracy/top5 = 1
I0916 23:49:17.945403  4353 caffe.cpp:319] Batch 15, loss = 0.0874368
I0916 23:49:18.095198  4353 caffe.cpp:319] Batch 16, accuracy/top1 = 0.954189
I0916 23:49:18.095218  4353 caffe.cpp:319] Batch 16, accuracy/top5 = 1
I0916 23:49:18.095222  4353 caffe.cpp:319] Batch 16, loss = 0.146848
I0916 23:49:18.245249  4353 caffe.cpp:319] Batch 17, accuracy/top1 = 0.885104
I0916 23:49:18.245272  4353 caffe.cpp:319] Batch 17, accuracy/top5 = 1
I0916 23:49:18.245275  4353 caffe.cpp:319] Batch 17, loss = 0.569636
I0916 23:49:18.395750  4353 caffe.cpp:319] Batch 18, accuracy/top1 = 0.981837
I0916 23:49:18.395769  4353 caffe.cpp:319] Batch 18, accuracy/top5 = 1
I0916 23:49:18.395772  4353 caffe.cpp:319] Batch 18, loss = 0.0445366
I0916 23:49:18.545974  4353 caffe.cpp:319] Batch 19, accuracy/top1 = 0.984738
I0916 23:49:18.545996  4353 caffe.cpp:319] Batch 19, accuracy/top5 = 1
I0916 23:49:18.546000  4353 caffe.cpp:319] Batch 19, loss = 0.0417092
I0916 23:49:18.696482  4353 caffe.cpp:319] Batch 20, accuracy/top1 = 0.9695
I0916 23:49:18.696506  4353 caffe.cpp:319] Batch 20, accuracy/top5 = 1
I0916 23:49:18.696508  4353 caffe.cpp:319] Batch 20, loss = 0.0828979
I0916 23:49:18.844960  4353 caffe.cpp:319] Batch 21, accuracy/top1 = 0.891103
I0916 23:49:18.844983  4353 caffe.cpp:319] Batch 21, accuracy/top5 = 1
I0916 23:49:18.844986  4353 caffe.cpp:319] Batch 21, loss = 0.557414
I0916 23:49:18.994990  4353 caffe.cpp:319] Batch 22, accuracy/top1 = 0.958133
I0916 23:49:18.995007  4353 caffe.cpp:319] Batch 22, accuracy/top5 = 1
I0916 23:49:18.995010  4353 caffe.cpp:319] Batch 22, loss = 0.105029
I0916 23:49:19.081622  4385 blocking_queue.cpp:40] Waiting for datum
I0916 23:49:19.146071  4353 caffe.cpp:319] Batch 23, accuracy/top1 = 0.979682
I0916 23:49:19.146097  4353 caffe.cpp:319] Batch 23, accuracy/top5 = 1
I0916 23:49:19.146100  4353 caffe.cpp:319] Batch 23, loss = 0.0546984
I0916 23:49:19.146107  4353 blocking_queue.cpp:40] Data layer prefetch queue empty
I0916 23:49:19.339174  4353 caffe.cpp:319] Batch 24, accuracy/top1 = 0.952581
I0916 23:49:19.339195  4353 caffe.cpp:319] Batch 24, accuracy/top5 = 1
I0916 23:49:19.339197  4353 caffe.cpp:319] Batch 24, loss = 0.134876
I0916 23:49:19.489512  4353 caffe.cpp:319] Batch 25, accuracy/top1 = 0.975936
I0916 23:49:19.489536  4353 caffe.cpp:319] Batch 25, accuracy/top5 = 1
I0916 23:49:19.489539  4353 caffe.cpp:319] Batch 25, loss = 0.0665566
I0916 23:49:19.639865  4353 caffe.cpp:319] Batch 26, accuracy/top1 = 0.950284
I0916 23:49:19.639888  4353 caffe.cpp:319] Batch 26, accuracy/top5 = 1
I0916 23:49:19.639890  4353 caffe.cpp:319] Batch 26, loss = 0.121923
I0916 23:49:19.788547  4353 caffe.cpp:319] Batch 27, accuracy/top1 = 0.96765
I0916 23:49:19.788570  4353 caffe.cpp:319] Batch 27, accuracy/top5 = 1
I0916 23:49:19.788573  4353 caffe.cpp:319] Batch 27, loss = 0.0856242
I0916 23:49:19.938472  4353 caffe.cpp:319] Batch 28, accuracy/top1 = 0.961145
I0916 23:49:19.938494  4353 caffe.cpp:319] Batch 28, accuracy/top5 = 1
I0916 23:49:19.938498  4353 caffe.cpp:319] Batch 28, loss = 0.102337
I0916 23:49:20.085546  4353 caffe.cpp:319] Batch 29, accuracy/top1 = 0.965208
I0916 23:49:20.085568  4353 caffe.cpp:319] Batch 29, accuracy/top5 = 1
I0916 23:49:20.085572  4353 caffe.cpp:319] Batch 29, loss = 0.11486
I0916 23:49:20.234863  4353 caffe.cpp:319] Batch 30, accuracy/top1 = 0.903676
I0916 23:49:20.234886  4353 caffe.cpp:319] Batch 30, accuracy/top5 = 1
I0916 23:49:20.234889  4353 caffe.cpp:319] Batch 30, loss = 0.212137
I0916 23:49:20.387248  4353 caffe.cpp:319] Batch 31, accuracy/top1 = 0.966021
I0916 23:49:20.387267  4353 caffe.cpp:319] Batch 31, accuracy/top5 = 1
I0916 23:49:20.387270  4353 caffe.cpp:319] Batch 31, loss = 0.101854
I0916 23:49:20.538467  4353 caffe.cpp:319] Batch 32, accuracy/top1 = 0.95798
I0916 23:49:20.538491  4353 caffe.cpp:319] Batch 32, accuracy/top5 = 1
I0916 23:49:20.538493  4353 caffe.cpp:319] Batch 32, loss = 0.113072
I0916 23:49:20.688055  4353 caffe.cpp:319] Batch 33, accuracy/top1 = 0.953395
I0916 23:49:20.688078  4353 caffe.cpp:319] Batch 33, accuracy/top5 = 1
I0916 23:49:20.688081  4353 caffe.cpp:319] Batch 33, loss = 0.126222
I0916 23:49:20.837195  4353 caffe.cpp:319] Batch 34, accuracy/top1 = 0.97903
I0916 23:49:20.837218  4353 caffe.cpp:319] Batch 34, accuracy/top5 = 1
I0916 23:49:20.837221  4353 caffe.cpp:319] Batch 34, loss = 0.0644538
I0916 23:49:20.986402  4353 caffe.cpp:319] Batch 35, accuracy/top1 = 0.934601
I0916 23:49:20.986424  4353 caffe.cpp:319] Batch 35, accuracy/top5 = 1
I0916 23:49:20.986428  4353 caffe.cpp:319] Batch 35, loss = 0.15669
I0916 23:49:21.136126  4353 caffe.cpp:319] Batch 36, accuracy/top1 = 0.965123
I0916 23:49:21.136147  4353 caffe.cpp:319] Batch 36, accuracy/top5 = 1
I0916 23:49:21.136149  4353 caffe.cpp:319] Batch 36, loss = 0.100566
I0916 23:49:21.284237  4353 caffe.cpp:319] Batch 37, accuracy/top1 = 0.965166
I0916 23:49:21.284260  4353 caffe.cpp:319] Batch 37, accuracy/top5 = 1
I0916 23:49:21.284263  4353 caffe.cpp:319] Batch 37, loss = 0.0890448
I0916 23:49:21.433374  4353 caffe.cpp:319] Batch 38, accuracy/top1 = 0.919617
I0916 23:49:21.433395  4353 caffe.cpp:319] Batch 38, accuracy/top5 = 1
I0916 23:49:21.433398  4353 caffe.cpp:319] Batch 38, loss = 0.181464
I0916 23:49:21.584856  4353 caffe.cpp:319] Batch 39, accuracy/top1 = 0.939529
I0916 23:49:21.584875  4353 caffe.cpp:319] Batch 39, accuracy/top5 = 1
I0916 23:49:21.584878  4353 caffe.cpp:319] Batch 39, loss = 0.166956
I0916 23:49:21.733114  4353 caffe.cpp:319] Batch 40, accuracy/top1 = 0.981555
I0916 23:49:21.733136  4353 caffe.cpp:319] Batch 40, accuracy/top5 = 1
I0916 23:49:21.733139  4353 caffe.cpp:319] Batch 40, loss = 0.0571738
I0916 23:49:21.883808  4353 caffe.cpp:319] Batch 41, accuracy/top1 = 0.977773
I0916 23:49:21.883831  4353 caffe.cpp:319] Batch 41, accuracy/top5 = 1
I0916 23:49:21.883834  4353 caffe.cpp:319] Batch 41, loss = 0.0632484
I0916 23:49:22.032061  4353 caffe.cpp:319] Batch 42, accuracy/top1 = 0.979678
I0916 23:49:22.032080  4353 caffe.cpp:319] Batch 42, accuracy/top5 = 1
I0916 23:49:22.032083  4353 caffe.cpp:319] Batch 42, loss = 0.0589289
I0916 23:49:22.180515  4353 caffe.cpp:319] Batch 43, accuracy/top1 = 0.97662
I0916 23:49:22.180537  4353 caffe.cpp:319] Batch 43, accuracy/top5 = 1
I0916 23:49:22.180541  4353 caffe.cpp:319] Batch 43, loss = 0.0645159
I0916 23:49:22.330930  4353 caffe.cpp:319] Batch 44, accuracy/top1 = 0.966699
I0916 23:49:22.330947  4353 caffe.cpp:319] Batch 44, accuracy/top5 = 1
I0916 23:49:22.330950  4353 caffe.cpp:319] Batch 44, loss = 0.0968729
I0916 23:49:22.481355  4353 caffe.cpp:319] Batch 45, accuracy/top1 = 0.977871
I0916 23:49:22.481379  4353 caffe.cpp:319] Batch 45, accuracy/top5 = 1
I0916 23:49:22.481381  4353 caffe.cpp:319] Batch 45, loss = 0.0669573
I0916 23:49:22.631604  4353 caffe.cpp:319] Batch 46, accuracy/top1 = 0.974417
I0916 23:49:22.631628  4353 caffe.cpp:319] Batch 46, accuracy/top5 = 1
I0916 23:49:22.631630  4353 caffe.cpp:319] Batch 46, loss = 0.0687818
I0916 23:49:22.781129  4353 caffe.cpp:319] Batch 47, accuracy/top1 = 0.961847
I0916 23:49:22.781152  4353 caffe.cpp:319] Batch 47, accuracy/top5 = 1
I0916 23:49:22.781154  4353 caffe.cpp:319] Batch 47, loss = 0.13113
I0916 23:49:22.932878  4353 caffe.cpp:319] Batch 48, accuracy/top1 = 0.904788
I0916 23:49:22.932901  4353 caffe.cpp:319] Batch 48, accuracy/top5 = 1
I0916 23:49:22.932915  4353 caffe.cpp:319] Batch 48, loss = 0.349975
I0916 23:49:23.085650  4353 caffe.cpp:319] Batch 49, accuracy/top1 = 0.951649
I0916 23:49:23.085669  4353 caffe.cpp:319] Batch 49, accuracy/top5 = 1
I0916 23:49:23.085671  4353 caffe.cpp:319] Batch 49, loss = 0.12974
I0916 23:49:23.085675  4353 caffe.cpp:324] Loss: 0.142357
I0916 23:49:23.085676  4353 caffe.cpp:336] accuracy/top1 = 0.954938
I0916 23:49:23.085680  4353 caffe.cpp:336] accuracy/top5 = 1
I0916 23:49:23.085683  4353 caffe.cpp:336] loss = 0.142357 (* 1 = 0.142357 loss)
I0916 23:49:23.085685  4353 caffe.cpp:340] =========================
I0916 23:49:23.085687  4353 caffe.cpp:341] Sparsity of the test net:
I0916 23:49:23.087453  4353 net.cpp:2293] Num Params(17), Sparsity (zero_weights/count): 
I0916 23:49:23.087461  4353 net.cpp:2304] conv1a_param_0(0) 
I0916 23:49:23.087467  4353 net.cpp:2304] conv1b_param_0(0) 
I0916 23:49:23.087469  4353 net.cpp:2304] ctx_conv1_param_0(0) 
I0916 23:49:23.087471  4353 net.cpp:2304] ctx_conv2_param_0(0) 
I0916 23:49:23.087473  4353 net.cpp:2304] ctx_conv3_param_0(0) 
I0916 23:49:23.087476  4353 net.cpp:2304] ctx_conv4_param_0(0) 
I0916 23:49:23.087477  4353 net.cpp:2304] ctx_final_param_0(0) 
I0916 23:49:23.087479  4353 net.cpp:2304] out3a_param_0(0) 
I0916 23:49:23.087481  4353 net.cpp:2304] out5a_param_0(0) 
I0916 23:49:23.087482  4353 net.cpp:2304] res2a_branch2a_param_0(0) 
I0916 23:49:23.087484  4353 net.cpp:2304] res2a_branch2b_param_0(0) 
I0916 23:49:23.087486  4353 net.cpp:2304] res3a_branch2a_param_0(0) 
I0916 23:49:23.087488  4353 net.cpp:2304] res3a_branch2b_param_0(0) 
I0916 23:49:23.087491  4353 net.cpp:2304] res4a_branch2a_param_0(0) 
I0916 23:49:23.087492  4353 net.cpp:2304] res4a_branch2b_param_0(0) 
I0916 23:49:23.087493  4353 net.cpp:2304] res5a_branch2a_param_0(0) 
I0916 23:49:23.087496  4353 net.cpp:2304] res5a_branch2b_param_0(0) 
I0916 23:49:23.087497  4353 net.cpp:2308] Total Sparsity (zero_weights/count) =  (0/2.69117e+06) 0
I0916 23:49:23.087502  4353 caffe.cpp:343] =========================
training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/test_quantize/run.sh: line 1: cd: /user/a0393608/files/work/code/vision/ti/bitbucket/algoref/caffe-jacinto/build/tools/caffe.bin: Not a directory
I0916 23:49:23.819829  4612 caffe.cpp:807] This is NVCaffe 0.16.4 started at Sat Sep 16 23:49:23 2017
I0916 23:49:23.819926  4612 caffe.cpp:810] CuDNN version: 6021
I0916 23:49:23.819931  4612 caffe.cpp:811] CuBLAS version: 8000
I0916 23:49:23.819931  4612 caffe.cpp:812] CUDA version: 8000
I0916 23:49:23.819933  4612 caffe.cpp:813] CUDA driver version: 8000
I0916 23:49:23.819937  4612 caffe.cpp:269] Not using GPU #2 for single-GPU function
I0916 23:49:23.819939  4612 caffe.cpp:269] Not using GPU #1 for single-GPU function
I0916 23:49:23.837633  4612 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0916 23:49:23.838244  4612 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8278441984, dev_info[0]: total=8506769408 free=8278441984
I0916 23:49:23.838250  4612 caffe.cpp:281] Use GPU with device ID 0
I0916 23:49:23.838618  4612 caffe.cpp:285] GPU device name: GeForce GTX 1080
I0916 23:49:23.841143  4612 net.cpp:72] Initializing net from parameters: 
name: "jsegnet21v2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageLabelData"
  top: "data"
  top: "label"
  transform_param {
    mirror: false
    crop_size: 640
    mean_value: 0
  }
  image_label_data_param {
    image_list_path: "data/val-image-lmdb"
    label_list_path: "data/val-label-lmdb"
    batch_size: 4
    threads: 1
    backend: LMDB
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "out5a"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "out5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "out5a/bn"
  type: "BatchNorm"
  bottom: "out5a"
  top: "out5a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out5a/relu"
  type: "ReLU"
  bottom: "out5a"
  top: "out5a"
}
layer {
  name: "out5a_up2"
  type: "Deconvolution"
  bottom: "out5a"
  top: "out5a_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 64
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out3a"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "out3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "out3a/bn"
  type: "BatchNorm"
  bottom: "out3a"
  top: "out3a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out3a/relu"
  type: "ReLU"
  bottom: "out3a"
  top: "out3a"
}
layer {
  name: "out3_out5_combined"
  type: "Eltwise"
  bottom: "out5a_up2"
  bottom: "out3a"
  top: "out3_out5_combined"
}
layer {
  name: "ctx_conv1"
  type: "Convolution"
  bottom: "out3_out5_combined"
  top: "ctx_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_conv1/bn"
  type: "BatchNorm"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv1/relu"
  type: "ReLU"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
}
layer {
  name: "ctx_conv2"
  type: "Convolution"
  bottom: "ctx_conv1"
  top: "ctx_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv2/bn"
  type: "BatchNorm"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv2/relu"
  type: "ReLU"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
}
layer {
  name: "ctx_conv3"
  type: "Convolution"
  bottom: "ctx_conv2"
  top: "ctx_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv3/bn"
  type: "BatchNorm"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv3/relu"
  type: "ReLU"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
}
layer {
  name: "ctx_conv4"
  type: "Convolution"
  bottom: "ctx_conv3"
  top: "ctx_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv4/bn"
  type: "BatchNorm"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv4/relu"
  type: "ReLU"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
}
layer {
  name: "ctx_final"
  type: "Convolution"
  bottom: "ctx_conv4"
  top: "ctx_final"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_final/relu"
  type: "ReLU"
  bottom: "ctx_final"
  top: "ctx_final"
}
layer {
  name: "out_deconv_final_up2"
  type: "Deconvolution"
  bottom: "ctx_final"
  top: "out_deconv_final_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up4"
  type: "Deconvolution"
  bottom: "out_deconv_final_up2"
  top: "out_deconv_final_up4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up8"
  type: "Deconvolution"
  bottom: "out_deconv_final_up4"
  top: "out_deconv_final_up8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: 255
    normalization: VALID
  }
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "accuracy/top1"
  include {
    phase: TEST
  }
  accuracy_param {
    ignore_label: 255
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "accuracy/top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
    ignore_label: 255
  }
}
quantize: true
I0916 23:49:23.841348  4612 net.cpp:104] Using FLOAT as default forward math type
I0916 23:49:23.841356  4612 net.cpp:110] Using FLOAT as default backward math type
I0916 23:49:23.841359  4612 layer_factory.hpp:136] Creating layer 'data' of type 'ImageLabelData'
I0916 23:49:23.841363  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:23.841377  4612 net.cpp:184] Created Layer data (0)
I0916 23:49:23.841382  4612 net.cpp:530] data -> data
I0916 23:49:23.841397  4612 net.cpp:530] data -> label
I0916 23:49:23.841809  4612 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 4
I0916 23:49:23.841823  4612 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 23:49:23.849161  4646 db_lmdb.cpp:24] Opened lmdb data/val-image-lmdb
I0916 23:49:23.851449  4612 data_layer.cpp:187] (0) ReshapePrefetch 4, 3, 640, 640
I0916 23:49:23.851505  4612 data_layer.cpp:211] (0) Output data size: 4, 3, 640, 640
I0916 23:49:23.851513  4612 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 23:49:23.851579  4612 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 4
I0916 23:49:23.851594  4612 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 23:49:23.852391  4647 data_layer.cpp:101] (0) Parser threads: 1
I0916 23:49:23.852403  4647 data_layer.cpp:103] (0) Transformer threads: 1
I0916 23:49:23.856673  4648 db_lmdb.cpp:24] Opened lmdb data/val-label-lmdb
I0916 23:49:23.857803  4612 data_layer.cpp:187] (0) ReshapePrefetch 4, 1, 640, 640
I0916 23:49:23.857838  4612 data_layer.cpp:211] (0) Output data size: 4, 1, 640, 640
I0916 23:49:23.857846  4612 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 23:49:23.858032  4612 net.cpp:245] Setting up data
I0916 23:49:23.858069  4612 net.cpp:252] TEST Top shape for layer 0 'data' 4 3 640 640 (4915200)
I0916 23:49:23.858098  4612 net.cpp:252] TEST Top shape for layer 0 'data' 4 1 640 640 (1638400)
I0916 23:49:23.858109  4612 layer_factory.hpp:136] Creating layer 'label_data_1_split' of type 'Split'
I0916 23:49:23.858117  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:23.858137  4612 net.cpp:184] Created Layer label_data_1_split (1)
I0916 23:49:23.858144  4612 net.cpp:561] label_data_1_split <- label
I0916 23:49:23.858155  4612 net.cpp:530] label_data_1_split -> label_data_1_split_0
I0916 23:49:23.858165  4612 net.cpp:530] label_data_1_split -> label_data_1_split_1
I0916 23:49:23.858170  4612 net.cpp:530] label_data_1_split -> label_data_1_split_2
I0916 23:49:23.858232  4612 net.cpp:245] Setting up label_data_1_split
I0916 23:49:23.858240  4612 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 4 1 640 640 (1638400)
I0916 23:49:23.858247  4612 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 4 1 640 640 (1638400)
I0916 23:49:23.858250  4612 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 4 1 640 640 (1638400)
I0916 23:49:23.858255  4612 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0916 23:49:23.858261  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:23.858280  4612 net.cpp:184] Created Layer data/bias (2)
I0916 23:49:23.858285  4612 net.cpp:561] data/bias <- data
I0916 23:49:23.858292  4612 net.cpp:530] data/bias -> data/bias
I0916 23:49:23.859598  4649 data_layer.cpp:101] (0) Parser threads: 1
I0916 23:49:23.859627  4649 data_layer.cpp:103] (0) Transformer threads: 1
I0916 23:49:23.862989  4612 net.cpp:245] Setting up data/bias
I0916 23:49:23.863036  4612 net.cpp:252] TEST Top shape for layer 2 'data/bias' 4 3 640 640 (4915200)
I0916 23:49:23.863062  4612 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0916 23:49:23.863070  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:23.863099  4612 net.cpp:184] Created Layer conv1a (3)
I0916 23:49:23.863104  4612 net.cpp:561] conv1a <- data/bias
I0916 23:49:23.863123  4612 net.cpp:530] conv1a -> conv1a
I0916 23:49:24.163347  4612 net.cpp:245] Setting up conv1a
I0916 23:49:24.163369  4612 net.cpp:252] TEST Top shape for layer 3 'conv1a' 4 32 320 320 (13107200)
I0916 23:49:24.163381  4612 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0916 23:49:24.163385  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.163398  4612 net.cpp:184] Created Layer conv1a/bn (4)
I0916 23:49:24.163400  4612 net.cpp:561] conv1a/bn <- conv1a
I0916 23:49:24.163404  4612 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0916 23:49:24.163902  4612 net.cpp:245] Setting up conv1a/bn
I0916 23:49:24.163911  4612 net.cpp:252] TEST Top shape for layer 4 'conv1a/bn' 4 32 320 320 (13107200)
I0916 23:49:24.163918  4612 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0916 23:49:24.163921  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.163925  4612 net.cpp:184] Created Layer conv1a/relu (5)
I0916 23:49:24.163928  4612 net.cpp:561] conv1a/relu <- conv1a
I0916 23:49:24.163930  4612 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0916 23:49:24.163938  4612 net.cpp:245] Setting up conv1a/relu
I0916 23:49:24.163941  4612 net.cpp:252] TEST Top shape for layer 5 'conv1a/relu' 4 32 320 320 (13107200)
I0916 23:49:24.163944  4612 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0916 23:49:24.163945  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.163956  4612 net.cpp:184] Created Layer conv1b (6)
I0916 23:49:24.163959  4612 net.cpp:561] conv1b <- conv1a
I0916 23:49:24.163962  4612 net.cpp:530] conv1b -> conv1b
I0916 23:49:24.165208  4612 net.cpp:245] Setting up conv1b
I0916 23:49:24.165217  4612 net.cpp:252] TEST Top shape for layer 6 'conv1b' 4 32 320 320 (13107200)
I0916 23:49:24.165223  4612 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0916 23:49:24.165226  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.165231  4612 net.cpp:184] Created Layer conv1b/bn (7)
I0916 23:49:24.165233  4612 net.cpp:561] conv1b/bn <- conv1b
I0916 23:49:24.165236  4612 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0916 23:49:24.165621  4612 net.cpp:245] Setting up conv1b/bn
I0916 23:49:24.165628  4612 net.cpp:252] TEST Top shape for layer 7 'conv1b/bn' 4 32 320 320 (13107200)
I0916 23:49:24.165633  4612 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0916 23:49:24.165637  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.165639  4612 net.cpp:184] Created Layer conv1b/relu (8)
I0916 23:49:24.165642  4612 net.cpp:561] conv1b/relu <- conv1b
I0916 23:49:24.165643  4612 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0916 23:49:24.165647  4612 net.cpp:245] Setting up conv1b/relu
I0916 23:49:24.165649  4612 net.cpp:252] TEST Top shape for layer 8 'conv1b/relu' 4 32 320 320 (13107200)
I0916 23:49:24.165652  4612 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0916 23:49:24.165654  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.165662  4612 net.cpp:184] Created Layer pool1 (9)
I0916 23:49:24.165664  4612 net.cpp:561] pool1 <- conv1b
I0916 23:49:24.165668  4612 net.cpp:530] pool1 -> pool1
I0916 23:49:24.165714  4612 net.cpp:245] Setting up pool1
I0916 23:49:24.165721  4612 net.cpp:252] TEST Top shape for layer 9 'pool1' 4 32 160 160 (3276800)
I0916 23:49:24.165725  4612 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0916 23:49:24.165729  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.165740  4612 net.cpp:184] Created Layer res2a_branch2a (10)
I0916 23:49:24.165745  4612 net.cpp:561] res2a_branch2a <- pool1
I0916 23:49:24.165748  4612 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0916 23:49:24.167438  4612 net.cpp:245] Setting up res2a_branch2a
I0916 23:49:24.167446  4612 net.cpp:252] TEST Top shape for layer 10 'res2a_branch2a' 4 64 160 160 (6553600)
I0916 23:49:24.167454  4612 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0916 23:49:24.167456  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.167461  4612 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0916 23:49:24.167464  4612 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0916 23:49:24.167469  4612 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0916 23:49:24.167914  4612 net.cpp:245] Setting up res2a_branch2a/bn
I0916 23:49:24.167922  4612 net.cpp:252] TEST Top shape for layer 11 'res2a_branch2a/bn' 4 64 160 160 (6553600)
I0916 23:49:24.167928  4612 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0916 23:49:24.167932  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.167935  4612 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0916 23:49:24.167938  4612 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0916 23:49:24.167942  4612 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0916 23:49:24.167945  4612 net.cpp:245] Setting up res2a_branch2a/relu
I0916 23:49:24.167949  4612 net.cpp:252] TEST Top shape for layer 12 'res2a_branch2a/relu' 4 64 160 160 (6553600)
I0916 23:49:24.167951  4612 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0916 23:49:24.167954  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.167963  4612 net.cpp:184] Created Layer res2a_branch2b (13)
I0916 23:49:24.167968  4612 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0916 23:49:24.167973  4612 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0916 23:49:24.169011  4612 net.cpp:245] Setting up res2a_branch2b
I0916 23:49:24.169020  4612 net.cpp:252] TEST Top shape for layer 13 'res2a_branch2b' 4 64 160 160 (6553600)
I0916 23:49:24.169025  4612 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0916 23:49:24.169029  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.169034  4612 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0916 23:49:24.169037  4612 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0916 23:49:24.169040  4612 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0916 23:49:24.169493  4612 net.cpp:245] Setting up res2a_branch2b/bn
I0916 23:49:24.169502  4612 net.cpp:252] TEST Top shape for layer 14 'res2a_branch2b/bn' 4 64 160 160 (6553600)
I0916 23:49:24.169508  4612 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0916 23:49:24.169512  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.169515  4612 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0916 23:49:24.169518  4612 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0916 23:49:24.169522  4612 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0916 23:49:24.169525  4612 net.cpp:245] Setting up res2a_branch2b/relu
I0916 23:49:24.169528  4612 net.cpp:252] TEST Top shape for layer 15 'res2a_branch2b/relu' 4 64 160 160 (6553600)
I0916 23:49:24.169531  4612 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0916 23:49:24.169534  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.169539  4612 net.cpp:184] Created Layer pool2 (16)
I0916 23:49:24.169544  4612 net.cpp:561] pool2 <- res2a_branch2b
I0916 23:49:24.169548  4612 net.cpp:530] pool2 -> pool2
I0916 23:49:24.169589  4612 net.cpp:245] Setting up pool2
I0916 23:49:24.169595  4612 net.cpp:252] TEST Top shape for layer 16 'pool2' 4 64 80 80 (1638400)
I0916 23:49:24.169600  4612 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0916 23:49:24.169605  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.169622  4612 net.cpp:184] Created Layer res3a_branch2a (17)
I0916 23:49:24.169627  4612 net.cpp:561] res3a_branch2a <- pool2
I0916 23:49:24.169632  4612 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0916 23:49:24.171386  4612 net.cpp:245] Setting up res3a_branch2a
I0916 23:49:24.171394  4612 net.cpp:252] TEST Top shape for layer 17 'res3a_branch2a' 4 128 80 80 (3276800)
I0916 23:49:24.171399  4612 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0916 23:49:24.171402  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.171407  4612 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0916 23:49:24.171411  4612 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0916 23:49:24.171413  4612 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0916 23:49:24.172243  4612 net.cpp:245] Setting up res3a_branch2a/bn
I0916 23:49:24.172251  4612 net.cpp:252] TEST Top shape for layer 18 'res3a_branch2a/bn' 4 128 80 80 (3276800)
I0916 23:49:24.172260  4612 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0916 23:49:24.172263  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.172267  4612 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0916 23:49:24.172271  4612 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0916 23:49:24.172273  4612 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0916 23:49:24.172277  4612 net.cpp:245] Setting up res3a_branch2a/relu
I0916 23:49:24.172281  4612 net.cpp:252] TEST Top shape for layer 19 'res3a_branch2a/relu' 4 128 80 80 (3276800)
I0916 23:49:24.172283  4612 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0916 23:49:24.172287  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.172300  4612 net.cpp:184] Created Layer res3a_branch2b (20)
I0916 23:49:24.172305  4612 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0916 23:49:24.172309  4612 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0916 23:49:24.173300  4612 net.cpp:245] Setting up res3a_branch2b
I0916 23:49:24.173307  4612 net.cpp:252] TEST Top shape for layer 20 'res3a_branch2b' 4 128 80 80 (3276800)
I0916 23:49:24.173312  4612 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0916 23:49:24.173316  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.173321  4612 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0916 23:49:24.173323  4612 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0916 23:49:24.173326  4612 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0916 23:49:24.173754  4612 net.cpp:245] Setting up res3a_branch2b/bn
I0916 23:49:24.173763  4612 net.cpp:252] TEST Top shape for layer 21 'res3a_branch2b/bn' 4 128 80 80 (3276800)
I0916 23:49:24.173768  4612 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0916 23:49:24.173771  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.173775  4612 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0916 23:49:24.173779  4612 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0916 23:49:24.173781  4612 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0916 23:49:24.173785  4612 net.cpp:245] Setting up res3a_branch2b/relu
I0916 23:49:24.173789  4612 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b/relu' 4 128 80 80 (3276800)
I0916 23:49:24.173792  4612 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0916 23:49:24.173796  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.173802  4612 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (23)
I0916 23:49:24.173806  4612 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0916 23:49:24.173818  4612 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0916 23:49:24.173825  4612 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0916 23:49:24.173856  4612 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0916 23:49:24.173861  4612 net.cpp:252] TEST Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 4 128 80 80 (3276800)
I0916 23:49:24.173867  4612 net.cpp:252] TEST Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 4 128 80 80 (3276800)
I0916 23:49:24.173871  4612 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0916 23:49:24.173877  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.173882  4612 net.cpp:184] Created Layer pool3 (24)
I0916 23:49:24.173887  4612 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0916 23:49:24.173890  4612 net.cpp:530] pool3 -> pool3
I0916 23:49:24.173931  4612 net.cpp:245] Setting up pool3
I0916 23:49:24.173938  4612 net.cpp:252] TEST Top shape for layer 24 'pool3' 4 128 40 40 (819200)
I0916 23:49:24.173943  4612 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0916 23:49:24.173948  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.173956  4612 net.cpp:184] Created Layer res4a_branch2a (25)
I0916 23:49:24.173961  4612 net.cpp:561] res4a_branch2a <- pool3
I0916 23:49:24.173965  4612 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0916 23:49:24.181043  4612 net.cpp:245] Setting up res4a_branch2a
I0916 23:49:24.181054  4612 net.cpp:252] TEST Top shape for layer 25 'res4a_branch2a' 4 256 40 40 (1638400)
I0916 23:49:24.181059  4612 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0916 23:49:24.181064  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.181072  4612 net.cpp:184] Created Layer res4a_branch2a/bn (26)
I0916 23:49:24.181077  4612 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0916 23:49:24.181082  4612 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0916 23:49:24.181522  4612 net.cpp:245] Setting up res4a_branch2a/bn
I0916 23:49:24.181530  4612 net.cpp:252] TEST Top shape for layer 26 'res4a_branch2a/bn' 4 256 40 40 (1638400)
I0916 23:49:24.181538  4612 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0916 23:49:24.181543  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.181550  4612 net.cpp:184] Created Layer res4a_branch2a/relu (27)
I0916 23:49:24.181555  4612 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0916 23:49:24.181558  4612 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0916 23:49:24.181565  4612 net.cpp:245] Setting up res4a_branch2a/relu
I0916 23:49:24.181571  4612 net.cpp:252] TEST Top shape for layer 27 'res4a_branch2a/relu' 4 256 40 40 (1638400)
I0916 23:49:24.181576  4612 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0916 23:49:24.181579  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.181588  4612 net.cpp:184] Created Layer res4a_branch2b (28)
I0916 23:49:24.181592  4612 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0916 23:49:24.181596  4612 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0916 23:49:24.184746  4612 net.cpp:245] Setting up res4a_branch2b
I0916 23:49:24.184754  4612 net.cpp:252] TEST Top shape for layer 28 'res4a_branch2b' 4 256 40 40 (1638400)
I0916 23:49:24.184761  4612 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0916 23:49:24.184764  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.184772  4612 net.cpp:184] Created Layer res4a_branch2b/bn (29)
I0916 23:49:24.184777  4612 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0916 23:49:24.184790  4612 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0916 23:49:24.185238  4612 net.cpp:245] Setting up res4a_branch2b/bn
I0916 23:49:24.185245  4612 net.cpp:252] TEST Top shape for layer 29 'res4a_branch2b/bn' 4 256 40 40 (1638400)
I0916 23:49:24.185253  4612 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0916 23:49:24.185258  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.185264  4612 net.cpp:184] Created Layer res4a_branch2b/relu (30)
I0916 23:49:24.185269  4612 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0916 23:49:24.185274  4612 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0916 23:49:24.185281  4612 net.cpp:245] Setting up res4a_branch2b/relu
I0916 23:49:24.185286  4612 net.cpp:252] TEST Top shape for layer 30 'res4a_branch2b/relu' 4 256 40 40 (1638400)
I0916 23:49:24.185290  4612 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0916 23:49:24.185294  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.185302  4612 net.cpp:184] Created Layer pool4 (31)
I0916 23:49:24.185305  4612 net.cpp:561] pool4 <- res4a_branch2b
I0916 23:49:24.185310  4612 net.cpp:530] pool4 -> pool4
I0916 23:49:24.185351  4612 net.cpp:245] Setting up pool4
I0916 23:49:24.185359  4612 net.cpp:252] TEST Top shape for layer 31 'pool4' 4 256 40 40 (1638400)
I0916 23:49:24.185362  4612 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0916 23:49:24.185367  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.185379  4612 net.cpp:184] Created Layer res5a_branch2a (32)
I0916 23:49:24.185384  4612 net.cpp:561] res5a_branch2a <- pool4
I0916 23:49:24.185387  4612 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0916 23:49:24.210741  4612 net.cpp:245] Setting up res5a_branch2a
I0916 23:49:24.210759  4612 net.cpp:252] TEST Top shape for layer 32 'res5a_branch2a' 4 512 40 40 (3276800)
I0916 23:49:24.210767  4612 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0916 23:49:24.210772  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.210778  4612 net.cpp:184] Created Layer res5a_branch2a/bn (33)
I0916 23:49:24.210781  4612 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0916 23:49:24.210785  4612 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0916 23:49:24.211252  4612 net.cpp:245] Setting up res5a_branch2a/bn
I0916 23:49:24.211261  4612 net.cpp:252] TEST Top shape for layer 33 'res5a_branch2a/bn' 4 512 40 40 (3276800)
I0916 23:49:24.211267  4612 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0916 23:49:24.211271  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.211273  4612 net.cpp:184] Created Layer res5a_branch2a/relu (34)
I0916 23:49:24.211277  4612 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0916 23:49:24.211278  4612 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0916 23:49:24.211282  4612 net.cpp:245] Setting up res5a_branch2a/relu
I0916 23:49:24.211285  4612 net.cpp:252] TEST Top shape for layer 34 'res5a_branch2a/relu' 4 512 40 40 (3276800)
I0916 23:49:24.211287  4612 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0916 23:49:24.211289  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.211295  4612 net.cpp:184] Created Layer res5a_branch2b (35)
I0916 23:49:24.211299  4612 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0916 23:49:24.211303  4612 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0916 23:49:24.223875  4612 net.cpp:245] Setting up res5a_branch2b
I0916 23:49:24.223896  4612 net.cpp:252] TEST Top shape for layer 35 'res5a_branch2b' 4 512 40 40 (3276800)
I0916 23:49:24.223906  4612 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0916 23:49:24.223924  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.223933  4612 net.cpp:184] Created Layer res5a_branch2b/bn (36)
I0916 23:49:24.223937  4612 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0916 23:49:24.223940  4612 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0916 23:49:24.224409  4612 net.cpp:245] Setting up res5a_branch2b/bn
I0916 23:49:24.224417  4612 net.cpp:252] TEST Top shape for layer 36 'res5a_branch2b/bn' 4 512 40 40 (3276800)
I0916 23:49:24.224423  4612 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0916 23:49:24.224426  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.224431  4612 net.cpp:184] Created Layer res5a_branch2b/relu (37)
I0916 23:49:24.224432  4612 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0916 23:49:24.224434  4612 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0916 23:49:24.224439  4612 net.cpp:245] Setting up res5a_branch2b/relu
I0916 23:49:24.224442  4612 net.cpp:252] TEST Top shape for layer 37 'res5a_branch2b/relu' 4 512 40 40 (3276800)
I0916 23:49:24.224443  4612 layer_factory.hpp:136] Creating layer 'out5a' of type 'Convolution'
I0916 23:49:24.224447  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.224452  4612 net.cpp:184] Created Layer out5a (38)
I0916 23:49:24.224454  4612 net.cpp:561] out5a <- res5a_branch2b
I0916 23:49:24.224457  4612 net.cpp:530] out5a -> out5a
I0916 23:49:24.228299  4612 net.cpp:245] Setting up out5a
I0916 23:49:24.228309  4612 net.cpp:252] TEST Top shape for layer 38 'out5a' 4 64 40 40 (409600)
I0916 23:49:24.228314  4612 layer_factory.hpp:136] Creating layer 'out5a/bn' of type 'BatchNorm'
I0916 23:49:24.228317  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.228322  4612 net.cpp:184] Created Layer out5a/bn (39)
I0916 23:49:24.228323  4612 net.cpp:561] out5a/bn <- out5a
I0916 23:49:24.228327  4612 net.cpp:513] out5a/bn -> out5a (in-place)
I0916 23:49:24.228778  4612 net.cpp:245] Setting up out5a/bn
I0916 23:49:24.228786  4612 net.cpp:252] TEST Top shape for layer 39 'out5a/bn' 4 64 40 40 (409600)
I0916 23:49:24.228791  4612 layer_factory.hpp:136] Creating layer 'out5a/relu' of type 'ReLU'
I0916 23:49:24.228794  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.228797  4612 net.cpp:184] Created Layer out5a/relu (40)
I0916 23:49:24.228799  4612 net.cpp:561] out5a/relu <- out5a
I0916 23:49:24.228801  4612 net.cpp:513] out5a/relu -> out5a (in-place)
I0916 23:49:24.228806  4612 net.cpp:245] Setting up out5a/relu
I0916 23:49:24.228807  4612 net.cpp:252] TEST Top shape for layer 40 'out5a/relu' 4 64 40 40 (409600)
I0916 23:49:24.228809  4612 layer_factory.hpp:136] Creating layer 'out5a_up2' of type 'Deconvolution'
I0916 23:49:24.228812  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.228823  4612 net.cpp:184] Created Layer out5a_up2 (41)
I0916 23:49:24.228826  4612 net.cpp:561] out5a_up2 <- out5a
I0916 23:49:24.228829  4612 net.cpp:530] out5a_up2 -> out5a_up2
I0916 23:49:24.228991  4612 net.cpp:245] Setting up out5a_up2
I0916 23:49:24.229001  4612 net.cpp:252] TEST Top shape for layer 41 'out5a_up2' 4 64 80 80 (1638400)
I0916 23:49:24.229005  4612 layer_factory.hpp:136] Creating layer 'out3a' of type 'Convolution'
I0916 23:49:24.229009  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.229018  4612 net.cpp:184] Created Layer out3a (42)
I0916 23:49:24.229022  4612 net.cpp:561] out3a <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0916 23:49:24.229027  4612 net.cpp:530] out3a -> out3a
I0916 23:49:24.230062  4612 net.cpp:245] Setting up out3a
I0916 23:49:24.230070  4612 net.cpp:252] TEST Top shape for layer 42 'out3a' 4 64 80 80 (1638400)
I0916 23:49:24.230087  4612 layer_factory.hpp:136] Creating layer 'out3a/bn' of type 'BatchNorm'
I0916 23:49:24.230090  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.230095  4612 net.cpp:184] Created Layer out3a/bn (43)
I0916 23:49:24.230098  4612 net.cpp:561] out3a/bn <- out3a
I0916 23:49:24.230100  4612 net.cpp:513] out3a/bn -> out3a (in-place)
I0916 23:49:24.230556  4612 net.cpp:245] Setting up out3a/bn
I0916 23:49:24.230564  4612 net.cpp:252] TEST Top shape for layer 43 'out3a/bn' 4 64 80 80 (1638400)
I0916 23:49:24.230571  4612 layer_factory.hpp:136] Creating layer 'out3a/relu' of type 'ReLU'
I0916 23:49:24.230572  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.230576  4612 net.cpp:184] Created Layer out3a/relu (44)
I0916 23:49:24.230578  4612 net.cpp:561] out3a/relu <- out3a
I0916 23:49:24.230581  4612 net.cpp:513] out3a/relu -> out3a (in-place)
I0916 23:49:24.230584  4612 net.cpp:245] Setting up out3a/relu
I0916 23:49:24.230587  4612 net.cpp:252] TEST Top shape for layer 44 'out3a/relu' 4 64 80 80 (1638400)
I0916 23:49:24.230588  4612 layer_factory.hpp:136] Creating layer 'out3_out5_combined' of type 'Eltwise'
I0916 23:49:24.230592  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.230598  4612 net.cpp:184] Created Layer out3_out5_combined (45)
I0916 23:49:24.230602  4612 net.cpp:561] out3_out5_combined <- out5a_up2
I0916 23:49:24.230604  4612 net.cpp:561] out3_out5_combined <- out3a
I0916 23:49:24.230607  4612 net.cpp:530] out3_out5_combined -> out3_out5_combined
I0916 23:49:24.230623  4612 net.cpp:245] Setting up out3_out5_combined
I0916 23:49:24.230626  4612 net.cpp:252] TEST Top shape for layer 45 'out3_out5_combined' 4 64 80 80 (1638400)
I0916 23:49:24.230628  4612 layer_factory.hpp:136] Creating layer 'ctx_conv1' of type 'Convolution'
I0916 23:49:24.230630  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.230640  4612 net.cpp:184] Created Layer ctx_conv1 (46)
I0916 23:49:24.230644  4612 net.cpp:561] ctx_conv1 <- out3_out5_combined
I0916 23:49:24.230649  4612 net.cpp:530] ctx_conv1 -> ctx_conv1
I0916 23:49:24.231606  4612 net.cpp:245] Setting up ctx_conv1
I0916 23:49:24.231613  4612 net.cpp:252] TEST Top shape for layer 46 'ctx_conv1' 4 64 80 80 (1638400)
I0916 23:49:24.231617  4612 layer_factory.hpp:136] Creating layer 'ctx_conv1/bn' of type 'BatchNorm'
I0916 23:49:24.231621  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.231624  4612 net.cpp:184] Created Layer ctx_conv1/bn (47)
I0916 23:49:24.231626  4612 net.cpp:561] ctx_conv1/bn <- ctx_conv1
I0916 23:49:24.231629  4612 net.cpp:513] ctx_conv1/bn -> ctx_conv1 (in-place)
I0916 23:49:24.232045  4612 net.cpp:245] Setting up ctx_conv1/bn
I0916 23:49:24.232053  4612 net.cpp:252] TEST Top shape for layer 47 'ctx_conv1/bn' 4 64 80 80 (1638400)
I0916 23:49:24.232059  4612 layer_factory.hpp:136] Creating layer 'ctx_conv1/relu' of type 'ReLU'
I0916 23:49:24.232061  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.232064  4612 net.cpp:184] Created Layer ctx_conv1/relu (48)
I0916 23:49:24.232066  4612 net.cpp:561] ctx_conv1/relu <- ctx_conv1
I0916 23:49:24.232069  4612 net.cpp:513] ctx_conv1/relu -> ctx_conv1 (in-place)
I0916 23:49:24.232072  4612 net.cpp:245] Setting up ctx_conv1/relu
I0916 23:49:24.232075  4612 net.cpp:252] TEST Top shape for layer 48 'ctx_conv1/relu' 4 64 80 80 (1638400)
I0916 23:49:24.232076  4612 layer_factory.hpp:136] Creating layer 'ctx_conv2' of type 'Convolution'
I0916 23:49:24.232079  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.232084  4612 net.cpp:184] Created Layer ctx_conv2 (49)
I0916 23:49:24.232086  4612 net.cpp:561] ctx_conv2 <- ctx_conv1
I0916 23:49:24.232089  4612 net.cpp:530] ctx_conv2 -> ctx_conv2
I0916 23:49:24.233036  4612 net.cpp:245] Setting up ctx_conv2
I0916 23:49:24.233043  4612 net.cpp:252] TEST Top shape for layer 49 'ctx_conv2' 4 64 80 80 (1638400)
I0916 23:49:24.233047  4612 layer_factory.hpp:136] Creating layer 'ctx_conv2/bn' of type 'BatchNorm'
I0916 23:49:24.233050  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.233054  4612 net.cpp:184] Created Layer ctx_conv2/bn (50)
I0916 23:49:24.233057  4612 net.cpp:561] ctx_conv2/bn <- ctx_conv2
I0916 23:49:24.233058  4612 net.cpp:513] ctx_conv2/bn -> ctx_conv2 (in-place)
I0916 23:49:24.233541  4612 net.cpp:245] Setting up ctx_conv2/bn
I0916 23:49:24.233548  4612 net.cpp:252] TEST Top shape for layer 50 'ctx_conv2/bn' 4 64 80 80 (1638400)
I0916 23:49:24.233553  4612 layer_factory.hpp:136] Creating layer 'ctx_conv2/relu' of type 'ReLU'
I0916 23:49:24.233556  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.233559  4612 net.cpp:184] Created Layer ctx_conv2/relu (51)
I0916 23:49:24.233562  4612 net.cpp:561] ctx_conv2/relu <- ctx_conv2
I0916 23:49:24.233564  4612 net.cpp:513] ctx_conv2/relu -> ctx_conv2 (in-place)
I0916 23:49:24.233568  4612 net.cpp:245] Setting up ctx_conv2/relu
I0916 23:49:24.233570  4612 net.cpp:252] TEST Top shape for layer 51 'ctx_conv2/relu' 4 64 80 80 (1638400)
I0916 23:49:24.233572  4612 layer_factory.hpp:136] Creating layer 'ctx_conv3' of type 'Convolution'
I0916 23:49:24.233574  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.233582  4612 net.cpp:184] Created Layer ctx_conv3 (52)
I0916 23:49:24.233583  4612 net.cpp:561] ctx_conv3 <- ctx_conv2
I0916 23:49:24.233587  4612 net.cpp:530] ctx_conv3 -> ctx_conv3
I0916 23:49:24.234589  4612 net.cpp:245] Setting up ctx_conv3
I0916 23:49:24.234597  4612 net.cpp:252] TEST Top shape for layer 52 'ctx_conv3' 4 64 80 80 (1638400)
I0916 23:49:24.234601  4612 layer_factory.hpp:136] Creating layer 'ctx_conv3/bn' of type 'BatchNorm'
I0916 23:49:24.234604  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.234608  4612 net.cpp:184] Created Layer ctx_conv3/bn (53)
I0916 23:49:24.234611  4612 net.cpp:561] ctx_conv3/bn <- ctx_conv3
I0916 23:49:24.234613  4612 net.cpp:513] ctx_conv3/bn -> ctx_conv3 (in-place)
I0916 23:49:24.235077  4612 net.cpp:245] Setting up ctx_conv3/bn
I0916 23:49:24.235085  4612 net.cpp:252] TEST Top shape for layer 53 'ctx_conv3/bn' 4 64 80 80 (1638400)
I0916 23:49:24.235091  4612 layer_factory.hpp:136] Creating layer 'ctx_conv3/relu' of type 'ReLU'
I0916 23:49:24.235093  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.235097  4612 net.cpp:184] Created Layer ctx_conv3/relu (54)
I0916 23:49:24.235100  4612 net.cpp:561] ctx_conv3/relu <- ctx_conv3
I0916 23:49:24.235102  4612 net.cpp:513] ctx_conv3/relu -> ctx_conv3 (in-place)
I0916 23:49:24.235106  4612 net.cpp:245] Setting up ctx_conv3/relu
I0916 23:49:24.235110  4612 net.cpp:252] TEST Top shape for layer 54 'ctx_conv3/relu' 4 64 80 80 (1638400)
I0916 23:49:24.235111  4612 layer_factory.hpp:136] Creating layer 'ctx_conv4' of type 'Convolution'
I0916 23:49:24.235113  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.235121  4612 net.cpp:184] Created Layer ctx_conv4 (55)
I0916 23:49:24.235122  4612 net.cpp:561] ctx_conv4 <- ctx_conv3
I0916 23:49:24.235126  4612 net.cpp:530] ctx_conv4 -> ctx_conv4
I0916 23:49:24.236124  4612 net.cpp:245] Setting up ctx_conv4
I0916 23:49:24.236131  4612 net.cpp:252] TEST Top shape for layer 55 'ctx_conv4' 4 64 80 80 (1638400)
I0916 23:49:24.236136  4612 layer_factory.hpp:136] Creating layer 'ctx_conv4/bn' of type 'BatchNorm'
I0916 23:49:24.236140  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.236145  4612 net.cpp:184] Created Layer ctx_conv4/bn (56)
I0916 23:49:24.236155  4612 net.cpp:561] ctx_conv4/bn <- ctx_conv4
I0916 23:49:24.236157  4612 net.cpp:513] ctx_conv4/bn -> ctx_conv4 (in-place)
I0916 23:49:24.236630  4612 net.cpp:245] Setting up ctx_conv4/bn
I0916 23:49:24.236639  4612 net.cpp:252] TEST Top shape for layer 56 'ctx_conv4/bn' 4 64 80 80 (1638400)
I0916 23:49:24.236644  4612 layer_factory.hpp:136] Creating layer 'ctx_conv4/relu' of type 'ReLU'
I0916 23:49:24.236647  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.236650  4612 net.cpp:184] Created Layer ctx_conv4/relu (57)
I0916 23:49:24.236654  4612 net.cpp:561] ctx_conv4/relu <- ctx_conv4
I0916 23:49:24.236656  4612 net.cpp:513] ctx_conv4/relu -> ctx_conv4 (in-place)
I0916 23:49:24.236660  4612 net.cpp:245] Setting up ctx_conv4/relu
I0916 23:49:24.236663  4612 net.cpp:252] TEST Top shape for layer 57 'ctx_conv4/relu' 4 64 80 80 (1638400)
I0916 23:49:24.236665  4612 layer_factory.hpp:136] Creating layer 'ctx_final' of type 'Convolution'
I0916 23:49:24.236668  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.236680  4612 net.cpp:184] Created Layer ctx_final (58)
I0916 23:49:24.236685  4612 net.cpp:561] ctx_final <- ctx_conv4
I0916 23:49:24.236688  4612 net.cpp:530] ctx_final -> ctx_final
I0916 23:49:24.237036  4612 net.cpp:245] Setting up ctx_final
I0916 23:49:24.237045  4612 net.cpp:252] TEST Top shape for layer 58 'ctx_final' 4 8 80 80 (204800)
I0916 23:49:24.237049  4612 layer_factory.hpp:136] Creating layer 'ctx_final/relu' of type 'ReLU'
I0916 23:49:24.237052  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.237056  4612 net.cpp:184] Created Layer ctx_final/relu (59)
I0916 23:49:24.237058  4612 net.cpp:561] ctx_final/relu <- ctx_final
I0916 23:49:24.237062  4612 net.cpp:513] ctx_final/relu -> ctx_final (in-place)
I0916 23:49:24.237069  4612 net.cpp:245] Setting up ctx_final/relu
I0916 23:49:24.237074  4612 net.cpp:252] TEST Top shape for layer 59 'ctx_final/relu' 4 8 80 80 (204800)
I0916 23:49:24.237079  4612 layer_factory.hpp:136] Creating layer 'out_deconv_final_up2' of type 'Deconvolution'
I0916 23:49:24.237083  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.237092  4612 net.cpp:184] Created Layer out_deconv_final_up2 (60)
I0916 23:49:24.237097  4612 net.cpp:561] out_deconv_final_up2 <- ctx_final
I0916 23:49:24.237102  4612 net.cpp:530] out_deconv_final_up2 -> out_deconv_final_up2
I0916 23:49:24.237234  4612 net.cpp:245] Setting up out_deconv_final_up2
I0916 23:49:24.237242  4612 net.cpp:252] TEST Top shape for layer 60 'out_deconv_final_up2' 4 8 160 160 (819200)
I0916 23:49:24.237248  4612 layer_factory.hpp:136] Creating layer 'out_deconv_final_up4' of type 'Deconvolution'
I0916 23:49:24.237253  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.237262  4612 net.cpp:184] Created Layer out_deconv_final_up4 (61)
I0916 23:49:24.237265  4612 net.cpp:561] out_deconv_final_up4 <- out_deconv_final_up2
I0916 23:49:24.237270  4612 net.cpp:530] out_deconv_final_up4 -> out_deconv_final_up4
I0916 23:49:24.237435  4612 net.cpp:245] Setting up out_deconv_final_up4
I0916 23:49:24.237442  4612 net.cpp:252] TEST Top shape for layer 61 'out_deconv_final_up4' 4 8 320 320 (3276800)
I0916 23:49:24.237447  4612 layer_factory.hpp:136] Creating layer 'out_deconv_final_up8' of type 'Deconvolution'
I0916 23:49:24.237452  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.237459  4612 net.cpp:184] Created Layer out_deconv_final_up8 (62)
I0916 23:49:24.237463  4612 net.cpp:561] out_deconv_final_up8 <- out_deconv_final_up4
I0916 23:49:24.237468  4612 net.cpp:530] out_deconv_final_up8 -> out_deconv_final_up8
I0916 23:49:24.237596  4612 net.cpp:245] Setting up out_deconv_final_up8
I0916 23:49:24.237603  4612 net.cpp:252] TEST Top shape for layer 62 'out_deconv_final_up8' 4 8 640 640 (13107200)
I0916 23:49:24.237615  4612 layer_factory.hpp:136] Creating layer 'out_deconv_final_up8_out_deconv_final_up8_0_split' of type 'Split'
I0916 23:49:24.237620  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.237627  4612 net.cpp:184] Created Layer out_deconv_final_up8_out_deconv_final_up8_0_split (63)
I0916 23:49:24.237632  4612 net.cpp:561] out_deconv_final_up8_out_deconv_final_up8_0_split <- out_deconv_final_up8
I0916 23:49:24.237635  4612 net.cpp:530] out_deconv_final_up8_out_deconv_final_up8_0_split -> out_deconv_final_up8_out_deconv_final_up8_0_split_0
I0916 23:49:24.237642  4612 net.cpp:530] out_deconv_final_up8_out_deconv_final_up8_0_split -> out_deconv_final_up8_out_deconv_final_up8_0_split_1
I0916 23:49:24.237646  4612 net.cpp:530] out_deconv_final_up8_out_deconv_final_up8_0_split -> out_deconv_final_up8_out_deconv_final_up8_0_split_2
I0916 23:49:24.237687  4612 net.cpp:245] Setting up out_deconv_final_up8_out_deconv_final_up8_0_split
I0916 23:49:24.237694  4612 net.cpp:252] TEST Top shape for layer 63 'out_deconv_final_up8_out_deconv_final_up8_0_split' 4 8 640 640 (13107200)
I0916 23:49:24.237699  4612 net.cpp:252] TEST Top shape for layer 63 'out_deconv_final_up8_out_deconv_final_up8_0_split' 4 8 640 640 (13107200)
I0916 23:49:24.237704  4612 net.cpp:252] TEST Top shape for layer 63 'out_deconv_final_up8_out_deconv_final_up8_0_split' 4 8 640 640 (13107200)
I0916 23:49:24.237709  4612 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0916 23:49:24.237712  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.237726  4612 net.cpp:184] Created Layer loss (64)
I0916 23:49:24.237731  4612 net.cpp:561] loss <- out_deconv_final_up8_out_deconv_final_up8_0_split_0
I0916 23:49:24.237737  4612 net.cpp:561] loss <- label_data_1_split_0
I0916 23:49:24.237742  4612 net.cpp:530] loss -> loss
I0916 23:49:24.238890  4612 net.cpp:245] Setting up loss
I0916 23:49:24.238900  4612 net.cpp:252] TEST Top shape for layer 64 'loss' (1)
I0916 23:49:24.238905  4612 net.cpp:256]     with loss weight 1
I0916 23:49:24.238921  4612 layer_factory.hpp:136] Creating layer 'accuracy/top1' of type 'Accuracy'
I0916 23:49:24.238926  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.238935  4612 net.cpp:184] Created Layer accuracy/top1 (65)
I0916 23:49:24.238940  4612 net.cpp:561] accuracy/top1 <- out_deconv_final_up8_out_deconv_final_up8_0_split_1
I0916 23:49:24.238946  4612 net.cpp:561] accuracy/top1 <- label_data_1_split_1
I0916 23:49:24.238951  4612 net.cpp:530] accuracy/top1 -> accuracy/top1
I0916 23:49:24.238960  4612 net.cpp:245] Setting up accuracy/top1
I0916 23:49:24.238965  4612 net.cpp:252] TEST Top shape for layer 65 'accuracy/top1' (1)
I0916 23:49:24.238970  4612 layer_factory.hpp:136] Creating layer 'accuracy/top5' of type 'Accuracy'
I0916 23:49:24.238976  4612 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 23:49:24.238981  4612 net.cpp:184] Created Layer accuracy/top5 (66)
I0916 23:49:24.238986  4612 net.cpp:561] accuracy/top5 <- out_deconv_final_up8_out_deconv_final_up8_0_split_2
I0916 23:49:24.238989  4612 net.cpp:561] accuracy/top5 <- label_data_1_split_2
I0916 23:49:24.238994  4612 net.cpp:530] accuracy/top5 -> accuracy/top5
I0916 23:49:24.239001  4612 net.cpp:245] Setting up accuracy/top5
I0916 23:49:24.239006  4612 net.cpp:252] TEST Top shape for layer 66 'accuracy/top5' (1)
I0916 23:49:24.239007  4612 net.cpp:325] accuracy/top5 does not need backward computation.
I0916 23:49:24.239011  4612 net.cpp:325] accuracy/top1 does not need backward computation.
I0916 23:49:24.239012  4612 net.cpp:323] loss needs backward computation.
I0916 23:49:24.239015  4612 net.cpp:323] out_deconv_final_up8_out_deconv_final_up8_0_split needs backward computation.
I0916 23:49:24.239018  4612 net.cpp:323] out_deconv_final_up8 needs backward computation.
I0916 23:49:24.239020  4612 net.cpp:323] out_deconv_final_up4 needs backward computation.
I0916 23:49:24.239028  4612 net.cpp:323] out_deconv_final_up2 needs backward computation.
I0916 23:49:24.239032  4612 net.cpp:323] ctx_final/relu needs backward computation.
I0916 23:49:24.239033  4612 net.cpp:323] ctx_final needs backward computation.
I0916 23:49:24.239035  4612 net.cpp:323] ctx_conv4/relu needs backward computation.
I0916 23:49:24.239037  4612 net.cpp:323] ctx_conv4/bn needs backward computation.
I0916 23:49:24.239039  4612 net.cpp:323] ctx_conv4 needs backward computation.
I0916 23:49:24.239042  4612 net.cpp:323] ctx_conv3/relu needs backward computation.
I0916 23:49:24.239043  4612 net.cpp:323] ctx_conv3/bn needs backward computation.
I0916 23:49:24.239045  4612 net.cpp:323] ctx_conv3 needs backward computation.
I0916 23:49:24.239048  4612 net.cpp:323] ctx_conv2/relu needs backward computation.
I0916 23:49:24.239050  4612 net.cpp:323] ctx_conv2/bn needs backward computation.
I0916 23:49:24.239051  4612 net.cpp:323] ctx_conv2 needs backward computation.
I0916 23:49:24.239053  4612 net.cpp:323] ctx_conv1/relu needs backward computation.
I0916 23:49:24.239056  4612 net.cpp:323] ctx_conv1/bn needs backward computation.
I0916 23:49:24.239058  4612 net.cpp:323] ctx_conv1 needs backward computation.
I0916 23:49:24.239060  4612 net.cpp:323] out3_out5_combined needs backward computation.
I0916 23:49:24.239063  4612 net.cpp:323] out3a/relu needs backward computation.
I0916 23:49:24.239065  4612 net.cpp:323] out3a/bn needs backward computation.
I0916 23:49:24.239068  4612 net.cpp:323] out3a needs backward computation.
I0916 23:49:24.239070  4612 net.cpp:323] out5a_up2 needs backward computation.
I0916 23:49:24.239073  4612 net.cpp:323] out5a/relu needs backward computation.
I0916 23:49:24.239075  4612 net.cpp:323] out5a/bn needs backward computation.
I0916 23:49:24.239078  4612 net.cpp:323] out5a needs backward computation.
I0916 23:49:24.239079  4612 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0916 23:49:24.239084  4612 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0916 23:49:24.239087  4612 net.cpp:323] res5a_branch2b needs backward computation.
I0916 23:49:24.239091  4612 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0916 23:49:24.239096  4612 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0916 23:49:24.239100  4612 net.cpp:323] res5a_branch2a needs backward computation.
I0916 23:49:24.239105  4612 net.cpp:323] pool4 needs backward computation.
I0916 23:49:24.239109  4612 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0916 23:49:24.239114  4612 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0916 23:49:24.239117  4612 net.cpp:323] res4a_branch2b needs backward computation.
I0916 23:49:24.239121  4612 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0916 23:49:24.239125  4612 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0916 23:49:24.239128  4612 net.cpp:323] res4a_branch2a needs backward computation.
I0916 23:49:24.239132  4612 net.cpp:323] pool3 needs backward computation.
I0916 23:49:24.239137  4612 net.cpp:323] res3a_branch2b_res3a_branch2b/relu_0_split needs backward computation.
I0916 23:49:24.239142  4612 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0916 23:49:24.239146  4612 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0916 23:49:24.239150  4612 net.cpp:323] res3a_branch2b needs backward computation.
I0916 23:49:24.239154  4612 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0916 23:49:24.239158  4612 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0916 23:49:24.239162  4612 net.cpp:323] res3a_branch2a needs backward computation.
I0916 23:49:24.239166  4612 net.cpp:323] pool2 needs backward computation.
I0916 23:49:24.239171  4612 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0916 23:49:24.239174  4612 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0916 23:49:24.239178  4612 net.cpp:323] res2a_branch2b needs backward computation.
I0916 23:49:24.239182  4612 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0916 23:49:24.239189  4612 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0916 23:49:24.239194  4612 net.cpp:323] res2a_branch2a needs backward computation.
I0916 23:49:24.239198  4612 net.cpp:323] pool1 needs backward computation.
I0916 23:49:24.239202  4612 net.cpp:323] conv1b/relu needs backward computation.
I0916 23:49:24.239207  4612 net.cpp:323] conv1b/bn needs backward computation.
I0916 23:49:24.239210  4612 net.cpp:323] conv1b needs backward computation.
I0916 23:49:24.239214  4612 net.cpp:323] conv1a/relu needs backward computation.
I0916 23:49:24.239219  4612 net.cpp:323] conv1a/bn needs backward computation.
I0916 23:49:24.239223  4612 net.cpp:323] conv1a needs backward computation.
I0916 23:49:24.239228  4612 net.cpp:325] data/bias does not need backward computation.
I0916 23:49:24.239233  4612 net.cpp:325] label_data_1_split does not need backward computation.
I0916 23:49:24.239238  4612 net.cpp:325] data does not need backward computation.
I0916 23:49:24.239240  4612 net.cpp:367] This network produces output accuracy/top1
I0916 23:49:24.239244  4612 net.cpp:367] This network produces output accuracy/top5
I0916 23:49:24.239248  4612 net.cpp:367] This network produces output loss
I0916 23:49:24.239307  4612 net.cpp:389] Top memory (TEST) required for data: 1133772824 diff: 1133772824
I0916 23:49:24.239313  4612 net.cpp:392] Bottom memory (TEST) required for data: 1133772800 diff: 1133772800
I0916 23:49:24.239316  4612 net.cpp:395] Shared (in-place) memory (TEST) by data: 515276800 diff: 515276800
I0916 23:49:24.239320  4612 net.cpp:398] Parameters memory (TEST) required for data: 10817840 diff: 10817840
I0916 23:49:24.239323  4612 net.cpp:401] Parameters shared memory (TEST) by data: 0 diff: 0
I0916 23:49:24.239327  4612 net.cpp:407] Network initialization done.
I0916 23:49:24.244036  4612 net.cpp:1094] Copying source layer data Type:ImageLabelData #blobs=0
I0916 23:49:24.244058  4612 net.cpp:1094] Copying source layer data/bias Type:Bias #blobs=1
I0916 23:49:24.244096  4612 net.cpp:1094] Copying source layer conv1a Type:Convolution #blobs=2
I0916 23:49:24.244113  4612 net.cpp:1094] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0916 23:49:24.244285  4612 net.cpp:1094] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0916 23:49:24.244292  4612 net.cpp:1094] Copying source layer conv1b Type:Convolution #blobs=2
I0916 23:49:24.244302  4612 net.cpp:1094] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0916 23:49:24.244405  4612 net.cpp:1094] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0916 23:49:24.244412  4612 net.cpp:1094] Copying source layer pool1 Type:Pooling #blobs=0
I0916 23:49:24.244416  4612 net.cpp:1094] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0916 23:49:24.244436  4612 net.cpp:1094] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0916 23:49:24.244554  4612 net.cpp:1094] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0916 23:49:24.244560  4612 net.cpp:1094] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0916 23:49:24.244575  4612 net.cpp:1094] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0916 23:49:24.244678  4612 net.cpp:1094] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0916 23:49:24.244684  4612 net.cpp:1094] Copying source layer pool2 Type:Pooling #blobs=0
I0916 23:49:24.244688  4612 net.cpp:1094] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0916 23:49:24.244729  4612 net.cpp:1094] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0916 23:49:24.244834  4612 net.cpp:1094] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0916 23:49:24.244841  4612 net.cpp:1094] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0916 23:49:24.244868  4612 net.cpp:1094] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0916 23:49:24.244967  4612 net.cpp:1094] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0916 23:49:24.244974  4612 net.cpp:1094] Copying source layer res3a_branch2b_res3a_branch2b/relu_0_split Type:Split #blobs=0
I0916 23:49:24.244989  4612 net.cpp:1094] Copying source layer pool3 Type:Pooling #blobs=0
I0916 23:49:24.244992  4612 net.cpp:1094] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0916 23:49:24.245113  4612 net.cpp:1094] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0916 23:49:24.245218  4612 net.cpp:1094] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0916 23:49:24.245223  4612 net.cpp:1094] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0916 23:49:24.245280  4612 net.cpp:1094] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0916 23:49:24.245383  4612 net.cpp:1094] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0916 23:49:24.245390  4612 net.cpp:1094] Copying source layer pool4 Type:Pooling #blobs=0
I0916 23:49:24.245393  4612 net.cpp:1094] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0916 23:49:24.245750  4612 net.cpp:1094] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0916 23:49:24.245846  4612 net.cpp:1094] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0916 23:49:24.245851  4612 net.cpp:1094] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0916 23:49:24.246017  4612 net.cpp:1094] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0916 23:49:24.246117  4612 net.cpp:1094] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0916 23:49:24.246122  4612 net.cpp:1094] Copying source layer out5a Type:Convolution #blobs=2
I0916 23:49:24.246162  4612 net.cpp:1094] Copying source layer out5a/bn Type:BatchNorm #blobs=5
I0916 23:49:24.246263  4612 net.cpp:1094] Copying source layer out5a/relu Type:ReLU #blobs=0
I0916 23:49:24.246268  4612 net.cpp:1094] Copying source layer out5a_up2 Type:Deconvolution #blobs=1
I0916 23:49:24.246274  4612 net.cpp:1094] Copying source layer out3a Type:Convolution #blobs=2
I0916 23:49:24.246289  4612 net.cpp:1094] Copying source layer out3a/bn Type:BatchNorm #blobs=5
I0916 23:49:24.246397  4612 net.cpp:1094] Copying source layer out3a/relu Type:ReLU #blobs=0
I0916 23:49:24.246404  4612 net.cpp:1094] Copying source layer out3_out5_combined Type:Eltwise #blobs=0
I0916 23:49:24.246408  4612 net.cpp:1094] Copying source layer ctx_conv1 Type:Convolution #blobs=2
I0916 23:49:24.246430  4612 net.cpp:1094] Copying source layer ctx_conv1/bn Type:BatchNorm #blobs=5
I0916 23:49:24.246543  4612 net.cpp:1094] Copying source layer ctx_conv1/relu Type:ReLU #blobs=0
I0916 23:49:24.246551  4612 net.cpp:1094] Copying source layer ctx_conv2 Type:Convolution #blobs=2
I0916 23:49:24.246570  4612 net.cpp:1094] Copying source layer ctx_conv2/bn Type:BatchNorm #blobs=5
I0916 23:49:24.246685  4612 net.cpp:1094] Copying source layer ctx_conv2/relu Type:ReLU #blobs=0
I0916 23:49:24.246691  4612 net.cpp:1094] Copying source layer ctx_conv3 Type:Convolution #blobs=2
I0916 23:49:24.246716  4612 net.cpp:1094] Copying source layer ctx_conv3/bn Type:BatchNorm #blobs=5
I0916 23:49:24.246829  4612 net.cpp:1094] Copying source layer ctx_conv3/relu Type:ReLU #blobs=0
I0916 23:49:24.246836  4612 net.cpp:1094] Copying source layer ctx_conv4 Type:Convolution #blobs=2
I0916 23:49:24.246857  4612 net.cpp:1094] Copying source layer ctx_conv4/bn Type:BatchNorm #blobs=5
I0916 23:49:24.246968  4612 net.cpp:1094] Copying source layer ctx_conv4/relu Type:ReLU #blobs=0
I0916 23:49:24.246973  4612 net.cpp:1094] Copying source layer ctx_final Type:Convolution #blobs=2
I0916 23:49:24.246980  4612 net.cpp:1094] Copying source layer ctx_final/relu Type:ReLU #blobs=0
I0916 23:49:24.246982  4612 net.cpp:1094] Copying source layer out_deconv_final_up2 Type:Deconvolution #blobs=1
I0916 23:49:24.246986  4612 net.cpp:1094] Copying source layer out_deconv_final_up4 Type:Deconvolution #blobs=1
I0916 23:49:24.246991  4612 net.cpp:1094] Copying source layer out_deconv_final_up8 Type:Deconvolution #blobs=1
I0916 23:49:24.246996  4612 net.cpp:1094] Copying source layer loss Type:SoftmaxWithLoss #blobs=0
I0916 23:49:24.247104  4612 caffe.cpp:296] Running for 50 iterations.
I0916 23:49:24.506422  4612 caffe.cpp:319] Batch 0, accuracy/top1 = 0.907202
I0916 23:49:24.506443  4612 caffe.cpp:319] Batch 0, accuracy/top5 = 1
I0916 23:49:24.506446  4612 caffe.cpp:319] Batch 0, loss = 0.403046
I0916 23:49:24.506449  4612 net.cpp:1597] Adding quantization params at infer/iter index: 1
I0916 23:49:24.705137  4612 caffe.cpp:319] Batch 1, accuracy/top1 = 0.928734
I0916 23:49:24.705157  4612 caffe.cpp:319] Batch 1, accuracy/top5 = 1
I0916 23:49:24.705160  4612 caffe.cpp:319] Batch 1, loss = 0.187661
I0916 23:49:24.710960  4612 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1a' with space 0G 3/1 1 	(avail 6.69G, req 0G)	t: 0
I0916 23:49:24.721171  4612 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1b' with space 0G 32/4 6 	(avail 6.69G, req 0G)	t: 0
I0916 23:49:24.738921  4612 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2a' with space 0G 32/1 6 	(avail 6.69G, req 0G)	t: 0
I0916 23:49:24.744678  4612 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2b' with space 0G 64/4 6 	(avail 6.69G, req 0G)	t: 0
I0916 23:49:24.753726  4612 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2a' with space 0G 64/1 6 	(avail 6.69G, req 0G)	t: 0
I0916 23:49:24.757376  4612 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2b' with space 0G 128/4 6 	(avail 6.69G, req 0G)	t: 0
I0916 23:49:24.764387  4612 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2a' with space 0G 128/1 1 	(avail 6.69G, req 0G)	t: 0
I0916 23:49:24.767644  4612 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2b' with space 0G 256/4 6 	(avail 6.69G, req 0G)	t: 0
I0916 23:49:24.783002  4612 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'out3a' with space 0G 128/2 6 	(avail 6.69G, req 0G)	t: 0
I0916 23:49:24.788745  4612 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_conv1' with space 0G 64/1 6 	(avail 6.69G, req 0G)	t: 0
I0916 23:49:24.796236  4612 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_final' with space 0G 64/1 6 	(avail 6.69G, req 0G)	t: 0
I0916 23:49:24.962800  4612 caffe.cpp:319] Batch 2, accuracy/top1 = 0.947719
I0916 23:49:24.962823  4612 caffe.cpp:319] Batch 2, accuracy/top5 = 1
I0916 23:49:24.962826  4612 caffe.cpp:319] Batch 2, loss = 0.133824
I0916 23:49:25.163494  4612 caffe.cpp:319] Batch 3, accuracy/top1 = 0.974428
I0916 23:49:25.163512  4612 caffe.cpp:319] Batch 3, accuracy/top5 = 1
I0916 23:49:25.163516  4612 caffe.cpp:319] Batch 3, loss = 0.0738617
I0916 23:49:25.360767  4612 caffe.cpp:319] Batch 4, accuracy/top1 = 0.970425
I0916 23:49:25.360786  4612 caffe.cpp:319] Batch 4, accuracy/top5 = 1
I0916 23:49:25.360790  4612 caffe.cpp:319] Batch 4, loss = 0.110343
I0916 23:49:25.559651  4612 caffe.cpp:319] Batch 5, accuracy/top1 = 0.859474
I0916 23:49:25.559674  4612 caffe.cpp:319] Batch 5, accuracy/top5 = 1
I0916 23:49:25.559677  4612 caffe.cpp:319] Batch 5, loss = 0.61336
I0916 23:49:25.759739  4612 caffe.cpp:319] Batch 6, accuracy/top1 = 0.9604
I0916 23:49:25.759759  4612 caffe.cpp:319] Batch 6, accuracy/top5 = 1
I0916 23:49:25.759763  4612 caffe.cpp:319] Batch 6, loss = 0.10643
I0916 23:49:25.956859  4612 caffe.cpp:319] Batch 7, accuracy/top1 = 0.903278
I0916 23:49:25.956881  4612 caffe.cpp:319] Batch 7, accuracy/top5 = 1
I0916 23:49:25.956884  4612 caffe.cpp:319] Batch 7, loss = 0.246364
I0916 23:49:26.154314  4612 caffe.cpp:319] Batch 8, accuracy/top1 = 0.973939
I0916 23:49:26.154335  4612 caffe.cpp:319] Batch 8, accuracy/top5 = 1
I0916 23:49:26.154338  4612 caffe.cpp:319] Batch 8, loss = 0.0681054
I0916 23:49:26.351908  4612 caffe.cpp:319] Batch 9, accuracy/top1 = 0.984796
I0916 23:49:26.351927  4612 caffe.cpp:319] Batch 9, accuracy/top5 = 1
I0916 23:49:26.351929  4612 caffe.cpp:319] Batch 9, loss = 0.0424931
I0916 23:49:26.550637  4612 caffe.cpp:319] Batch 10, accuracy/top1 = 0.962515
I0916 23:49:26.550657  4612 caffe.cpp:319] Batch 10, accuracy/top5 = 1
I0916 23:49:26.550662  4612 caffe.cpp:319] Batch 10, loss = 0.109119
I0916 23:49:26.747540  4612 caffe.cpp:319] Batch 11, accuracy/top1 = 0.978657
I0916 23:49:26.747576  4612 caffe.cpp:319] Batch 11, accuracy/top5 = 1
I0916 23:49:26.747581  4612 caffe.cpp:319] Batch 11, loss = 0.0598643
I0916 23:49:26.945935  4612 caffe.cpp:319] Batch 12, accuracy/top1 = 0.969737
I0916 23:49:26.945958  4612 caffe.cpp:319] Batch 12, accuracy/top5 = 1
I0916 23:49:26.945961  4612 caffe.cpp:319] Batch 12, loss = 0.0890483
I0916 23:49:27.144628  4612 caffe.cpp:319] Batch 13, accuracy/top1 = 0.968335
I0916 23:49:27.144645  4612 caffe.cpp:319] Batch 13, accuracy/top5 = 1
I0916 23:49:27.144649  4612 caffe.cpp:319] Batch 13, loss = 0.0903139
I0916 23:49:27.346705  4612 caffe.cpp:319] Batch 14, accuracy/top1 = 0.985795
I0916 23:49:27.346724  4612 caffe.cpp:319] Batch 14, accuracy/top5 = 1
I0916 23:49:27.346727  4612 caffe.cpp:319] Batch 14, loss = 0.0439784
I0916 23:49:27.545505  4612 caffe.cpp:319] Batch 15, accuracy/top1 = 0.969001
I0916 23:49:27.545526  4612 caffe.cpp:319] Batch 15, accuracy/top5 = 1
I0916 23:49:27.545528  4612 caffe.cpp:319] Batch 15, loss = 0.088619
I0916 23:49:27.746603  4612 caffe.cpp:319] Batch 16, accuracy/top1 = 0.952099
I0916 23:49:27.746624  4612 caffe.cpp:319] Batch 16, accuracy/top5 = 1
I0916 23:49:27.746628  4612 caffe.cpp:319] Batch 16, loss = 0.155637
I0916 23:49:27.946168  4612 caffe.cpp:319] Batch 17, accuracy/top1 = 0.884619
I0916 23:49:27.946189  4612 caffe.cpp:319] Batch 17, accuracy/top5 = 1
I0916 23:49:27.946192  4612 caffe.cpp:319] Batch 17, loss = 0.578388
I0916 23:49:28.145225  4612 caffe.cpp:319] Batch 18, accuracy/top1 = 0.981697
I0916 23:49:28.145246  4612 caffe.cpp:319] Batch 18, accuracy/top5 = 1
I0916 23:49:28.145248  4612 caffe.cpp:319] Batch 18, loss = 0.0446604
I0916 23:49:28.345790  4612 caffe.cpp:319] Batch 19, accuracy/top1 = 0.984482
I0916 23:49:28.345808  4612 caffe.cpp:319] Batch 19, accuracy/top5 = 1
I0916 23:49:28.345811  4612 caffe.cpp:319] Batch 19, loss = 0.0419858
I0916 23:49:28.543668  4612 caffe.cpp:319] Batch 20, accuracy/top1 = 0.968995
I0916 23:49:28.543690  4612 caffe.cpp:319] Batch 20, accuracy/top5 = 1
I0916 23:49:28.543694  4612 caffe.cpp:319] Batch 20, loss = 0.085666
I0916 23:49:28.740341  4612 caffe.cpp:319] Batch 21, accuracy/top1 = 0.892113
I0916 23:49:28.740365  4612 caffe.cpp:319] Batch 21, accuracy/top5 = 1
I0916 23:49:28.740367  4612 caffe.cpp:319] Batch 21, loss = 0.558648
I0916 23:49:28.938748  4612 caffe.cpp:319] Batch 22, accuracy/top1 = 0.961987
I0916 23:49:28.938771  4612 caffe.cpp:319] Batch 22, accuracy/top5 = 1
I0916 23:49:28.938774  4612 caffe.cpp:319] Batch 22, loss = 0.0968617
I0916 23:49:29.138007  4612 caffe.cpp:319] Batch 23, accuracy/top1 = 0.979724
I0916 23:49:29.138026  4612 caffe.cpp:319] Batch 23, accuracy/top5 = 1
I0916 23:49:29.138029  4612 caffe.cpp:319] Batch 23, loss = 0.0542293
I0916 23:49:29.334923  4612 caffe.cpp:319] Batch 24, accuracy/top1 = 0.953143
I0916 23:49:29.334945  4612 caffe.cpp:319] Batch 24, accuracy/top5 = 1
I0916 23:49:29.334949  4612 caffe.cpp:319] Batch 24, loss = 0.134185
I0916 23:49:29.533252  4612 caffe.cpp:319] Batch 25, accuracy/top1 = 0.975838
I0916 23:49:29.533274  4612 caffe.cpp:319] Batch 25, accuracy/top5 = 1
I0916 23:49:29.533277  4612 caffe.cpp:319] Batch 25, loss = 0.0667558
I0916 23:49:29.731993  4612 caffe.cpp:319] Batch 26, accuracy/top1 = 0.953564
I0916 23:49:29.732017  4612 caffe.cpp:319] Batch 26, accuracy/top5 = 1
I0916 23:49:29.732020  4612 caffe.cpp:319] Batch 26, loss = 0.117112
I0916 23:49:29.929107  4612 caffe.cpp:319] Batch 27, accuracy/top1 = 0.966469
I0916 23:49:29.929131  4612 caffe.cpp:319] Batch 27, accuracy/top5 = 1
I0916 23:49:29.929134  4612 caffe.cpp:319] Batch 27, loss = 0.0905478
I0916 23:49:30.127028  4612 caffe.cpp:319] Batch 28, accuracy/top1 = 0.9615
I0916 23:49:30.127049  4612 caffe.cpp:319] Batch 28, accuracy/top5 = 1
I0916 23:49:30.127053  4612 caffe.cpp:319] Batch 28, loss = 0.101391
I0916 23:49:30.323457  4612 caffe.cpp:319] Batch 29, accuracy/top1 = 0.965552
I0916 23:49:30.323488  4612 caffe.cpp:319] Batch 29, accuracy/top5 = 1
I0916 23:49:30.323493  4612 caffe.cpp:319] Batch 29, loss = 0.115583
I0916 23:49:30.520426  4612 caffe.cpp:319] Batch 30, accuracy/top1 = 0.900292
I0916 23:49:30.520449  4612 caffe.cpp:319] Batch 30, accuracy/top5 = 1
I0916 23:49:30.520453  4612 caffe.cpp:319] Batch 30, loss = 0.241456
I0916 23:49:30.719368  4612 caffe.cpp:319] Batch 31, accuracy/top1 = 0.965754
I0916 23:49:30.719391  4612 caffe.cpp:319] Batch 31, accuracy/top5 = 1
I0916 23:49:30.719395  4612 caffe.cpp:319] Batch 31, loss = 0.100226
I0916 23:49:30.917676  4612 caffe.cpp:319] Batch 32, accuracy/top1 = 0.959601
I0916 23:49:30.917701  4612 caffe.cpp:319] Batch 32, accuracy/top5 = 1
I0916 23:49:30.917704  4612 caffe.cpp:319] Batch 32, loss = 0.110013
I0916 23:49:31.115180  4612 caffe.cpp:319] Batch 33, accuracy/top1 = 0.956376
I0916 23:49:31.115200  4612 caffe.cpp:319] Batch 33, accuracy/top5 = 1
I0916 23:49:31.115206  4612 caffe.cpp:319] Batch 33, loss = 0.118162
I0916 23:49:31.312853  4612 caffe.cpp:319] Batch 34, accuracy/top1 = 0.979011
I0916 23:49:31.312873  4612 caffe.cpp:319] Batch 34, accuracy/top5 = 1
I0916 23:49:31.312877  4612 caffe.cpp:319] Batch 34, loss = 0.0641107
I0916 23:49:31.511052  4612 caffe.cpp:319] Batch 35, accuracy/top1 = 0.94135
I0916 23:49:31.511075  4612 caffe.cpp:319] Batch 35, accuracy/top5 = 1
I0916 23:49:31.511080  4612 caffe.cpp:319] Batch 35, loss = 0.133327
I0916 23:49:31.708426  4612 caffe.cpp:319] Batch 36, accuracy/top1 = 0.965212
I0916 23:49:31.708448  4612 caffe.cpp:319] Batch 36, accuracy/top5 = 1
I0916 23:49:31.708453  4612 caffe.cpp:319] Batch 36, loss = 0.101406
I0916 23:49:31.904709  4612 caffe.cpp:319] Batch 37, accuracy/top1 = 0.963795
I0916 23:49:31.904731  4612 caffe.cpp:319] Batch 37, accuracy/top5 = 1
I0916 23:49:31.904736  4612 caffe.cpp:319] Batch 37, loss = 0.0946629
I0916 23:49:32.100903  4612 caffe.cpp:319] Batch 38, accuracy/top1 = 0.931799
I0916 23:49:32.100922  4612 caffe.cpp:319] Batch 38, accuracy/top5 = 1
I0916 23:49:32.100926  4612 caffe.cpp:319] Batch 38, loss = 0.162876
I0916 23:49:32.300437  4612 caffe.cpp:319] Batch 39, accuracy/top1 = 0.940802
I0916 23:49:32.300459  4612 caffe.cpp:319] Batch 39, accuracy/top5 = 1
I0916 23:49:32.300463  4612 caffe.cpp:319] Batch 39, loss = 0.161824
I0916 23:49:32.496829  4612 caffe.cpp:319] Batch 40, accuracy/top1 = 0.981793
I0916 23:49:32.496851  4612 caffe.cpp:319] Batch 40, accuracy/top5 = 1
I0916 23:49:32.496856  4612 caffe.cpp:319] Batch 40, loss = 0.0575013
I0916 23:49:32.694810  4612 caffe.cpp:319] Batch 41, accuracy/top1 = 0.978013
I0916 23:49:32.694831  4612 caffe.cpp:319] Batch 41, accuracy/top5 = 1
I0916 23:49:32.694836  4612 caffe.cpp:319] Batch 41, loss = 0.0635415
I0916 23:49:32.891273  4612 caffe.cpp:319] Batch 42, accuracy/top1 = 0.978923
I0916 23:49:32.891296  4612 caffe.cpp:319] Batch 42, accuracy/top5 = 1
I0916 23:49:32.891300  4612 caffe.cpp:319] Batch 42, loss = 0.0605742
I0916 23:49:33.088814  4612 caffe.cpp:319] Batch 43, accuracy/top1 = 0.976422
I0916 23:49:33.088834  4612 caffe.cpp:319] Batch 43, accuracy/top5 = 1
I0916 23:49:33.088837  4612 caffe.cpp:319] Batch 43, loss = 0.0635508
I0916 23:49:33.285763  4612 caffe.cpp:319] Batch 44, accuracy/top1 = 0.966977
I0916 23:49:33.285781  4612 caffe.cpp:319] Batch 44, accuracy/top5 = 1
I0916 23:49:33.285785  4612 caffe.cpp:319] Batch 44, loss = 0.0959525
I0916 23:49:33.483897  4612 caffe.cpp:319] Batch 45, accuracy/top1 = 0.977894
I0916 23:49:33.483918  4612 caffe.cpp:319] Batch 45, accuracy/top5 = 1
I0916 23:49:33.483923  4612 caffe.cpp:319] Batch 45, loss = 0.0683861
I0916 23:49:33.682404  4612 caffe.cpp:319] Batch 46, accuracy/top1 = 0.974327
I0916 23:49:33.682425  4612 caffe.cpp:319] Batch 46, accuracy/top5 = 1
I0916 23:49:33.682428  4612 caffe.cpp:319] Batch 46, loss = 0.0686439
I0916 23:49:33.878865  4612 caffe.cpp:319] Batch 47, accuracy/top1 = 0.962194
I0916 23:49:33.878887  4612 caffe.cpp:319] Batch 47, accuracy/top5 = 1
I0916 23:49:33.878891  4612 caffe.cpp:319] Batch 47, loss = 0.129681
I0916 23:49:34.076534  4612 caffe.cpp:319] Batch 48, accuracy/top1 = 0.904674
I0916 23:49:34.076553  4612 caffe.cpp:319] Batch 48, accuracy/top5 = 1
I0916 23:49:34.076557  4612 caffe.cpp:319] Batch 48, loss = 0.358865
I0916 23:49:34.275909  4612 caffe.cpp:319] Batch 49, accuracy/top1 = 0.951839
I0916 23:49:34.275929  4612 caffe.cpp:319] Batch 49, accuracy/top5 = 1
I0916 23:49:34.275933  4612 caffe.cpp:319] Batch 49, loss = 0.128622
I0916 23:49:34.275938  4612 caffe.cpp:324] Loss: 0.141829
I0916 23:49:34.275941  4612 caffe.cpp:336] accuracy/top1 = 0.955665
I0916 23:49:34.275944  4612 caffe.cpp:336] accuracy/top5 = 1
I0916 23:49:34.275952  4612 caffe.cpp:336] loss = 0.141829 (* 1 = 0.141829 loss)
