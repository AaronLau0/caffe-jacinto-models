Logging output to training/eval-log-2017-09-25_09-56-32.txt
I0925 09:56:33.727879  8172 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0925 09:56:33.730120  8172 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8278441984, dev_info[0]: total=8506769408 free=8278441984
I0925 09:56:33.730711  8172 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0925 09:56:33.731304  8172 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8278441984, dev_info[0]: total=8506769408 free=8278441984
I0925 09:56:33.732883  8172 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: ../trained/image_segmentation/cityscapes5_jsegnet21v2/initial/deploy.prototxt
I0925 09:56:33.732897  8172 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0925 09:56:33.732900  8172 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0925 09:56:33.733175  8172 net.cpp:72] Initializing net from parameters: 
name: "jsegnet21v2_deploy"
state {
  phase: TEST
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 1024
      dim: 2048
    }
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "out5a"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "out5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "out5a/bn"
  type: "BatchNorm"
  bottom: "out5a"
  top: "out5a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out5a/relu"
  type: "ReLU"
  bottom: "out5a"
  top: "out5a"
}
layer {
  name: "out5a_up2"
  type: "Deconvolution"
  bottom: "out5a"
  top: "out5a_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 64
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out3a"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "out3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "out3a/bn"
  type: "BatchNorm"
  bottom: "out3a"
  top: "out3a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out3a/relu"
  type: "ReLU"
  bottom: "out3a"
  top: "out3a"
}
layer {
  name: "out3_out5_combined"
  type: "Eltwise"
  bottom: "out5a_up2"
  bottom: "out3a"
  top: "out3_out5_combined"
}
layer {
  name: "ctx_conv1"
  type: "Convolution"
  bottom: "out3_out5_combined"
  top: "ctx_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_conv1/bn"
  type: "BatchNorm"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv1/relu"
  type: "ReLU"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
}
layer {
  name: "ctx_conv2"
  type: "Convolution"
  bottom: "ctx_conv1"
  top: "ctx_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv2/bn"
  type: "BatchNorm"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv2/relu"
  type: "ReLU"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
}
layer {
  name: "ctx_conv3"
  type: "Convolution"
  bottom: "ctx_conv2"
  top: "ctx_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv3/bn"
  type: "BatchNorm"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv3/relu"
  type: "ReLU"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
}
layer {
  name: "ctx_conv4"
  type: "Convolution"
  bottom: "ctx_conv3"
  top: "ctx_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv4/bn"
  type: "BatchNorm"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv4/relu"
  type: "ReLU"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
}
layer {
  name: "ctx_final"
  type: "Convolution"
  bottom: "ctx_conv4"
  top: "ctx_final"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_final/relu"
  type: "ReLU"
  bottom: "ctx_final"
  top: "ctx_final"
}
layer {
  name: "out_deconv_final_up2"
  type: "Deconvolution"
  bottom: "ctx_final"
  top: "out_deconv_final_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up4"
  type: "Deconvolution"
  bottom: "out_deconv_final_up2"
  top: "out_deconv_final_up4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up8"
  type: "Deconvolution"
  bottom: "out_deconv_final_up4"
  top: "out_deconv_final_up8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "argMaxOut"
  type: "ArgMax"
  bottom: "out_deconv_final_up8"
  top: "argMaxOut"
  argmax_param {
    axis: 1
  }
}
I0925 09:56:33.733330  8172 net.cpp:104] Using FLOAT as default forward math type
I0925 09:56:33.733337  8172 net.cpp:110] Using FLOAT as default backward math type
I0925 09:56:33.733341  8172 layer_factory.hpp:136] Creating layer 'input' of type 'Input'
I0925 09:56:33.733345  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:33.733355  8172 net.cpp:184] Created Layer input (0)
I0925 09:56:33.733359  8172 net.cpp:530] input -> data
I0925 09:56:33.734153  8172 net.cpp:245] Setting up input
I0925 09:56:33.734163  8172 net.cpp:252] TEST Top shape for layer 0 'input' 1 3 1024 2048 (6291456)
I0925 09:56:33.734166  8172 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0925 09:56:33.734177  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:33.734190  8172 net.cpp:184] Created Layer data/bias (1)
I0925 09:56:33.734195  8172 net.cpp:561] data/bias <- data
I0925 09:56:33.734200  8172 net.cpp:530] data/bias -> data/bias
I0925 09:56:33.738687  8172 net.cpp:245] Setting up data/bias
I0925 09:56:33.738706  8172 net.cpp:252] TEST Top shape for layer 1 'data/bias' 1 3 1024 2048 (6291456)
I0925 09:56:33.738715  8172 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0925 09:56:33.738719  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:33.738739  8172 net.cpp:184] Created Layer conv1a (2)
I0925 09:56:33.738742  8172 net.cpp:561] conv1a <- data/bias
I0925 09:56:33.738746  8172 net.cpp:530] conv1a -> conv1a
I0925 09:56:34.102964  8172 net.cpp:245] Setting up conv1a
I0925 09:56:34.102988  8172 net.cpp:252] TEST Top shape for layer 2 'conv1a' 1 32 512 1024 (16777216)
I0925 09:56:34.102998  8172 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0925 09:56:34.103003  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.103011  8172 net.cpp:184] Created Layer conv1a/bn (3)
I0925 09:56:34.103014  8172 net.cpp:561] conv1a/bn <- conv1a
I0925 09:56:34.103018  8172 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0925 09:56:34.103894  8172 net.cpp:245] Setting up conv1a/bn
I0925 09:56:34.103904  8172 net.cpp:252] TEST Top shape for layer 3 'conv1a/bn' 1 32 512 1024 (16777216)
I0925 09:56:34.103911  8172 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0925 09:56:34.103914  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.103919  8172 net.cpp:184] Created Layer conv1a/relu (4)
I0925 09:56:34.103921  8172 net.cpp:561] conv1a/relu <- conv1a
I0925 09:56:34.103924  8172 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0925 09:56:34.103932  8172 net.cpp:245] Setting up conv1a/relu
I0925 09:56:34.103936  8172 net.cpp:252] TEST Top shape for layer 4 'conv1a/relu' 1 32 512 1024 (16777216)
I0925 09:56:34.103940  8172 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0925 09:56:34.103942  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.103956  8172 net.cpp:184] Created Layer conv1b (5)
I0925 09:56:34.103961  8172 net.cpp:561] conv1b <- conv1a
I0925 09:56:34.103965  8172 net.cpp:530] conv1b -> conv1b
I0925 09:56:34.105576  8172 net.cpp:245] Setting up conv1b
I0925 09:56:34.105585  8172 net.cpp:252] TEST Top shape for layer 5 'conv1b' 1 32 512 1024 (16777216)
I0925 09:56:34.105592  8172 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0925 09:56:34.105593  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.105599  8172 net.cpp:184] Created Layer conv1b/bn (6)
I0925 09:56:34.105602  8172 net.cpp:561] conv1b/bn <- conv1b
I0925 09:56:34.105604  8172 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0925 09:56:34.106446  8172 net.cpp:245] Setting up conv1b/bn
I0925 09:56:34.106454  8172 net.cpp:252] TEST Top shape for layer 6 'conv1b/bn' 1 32 512 1024 (16777216)
I0925 09:56:34.106461  8172 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0925 09:56:34.106462  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.106465  8172 net.cpp:184] Created Layer conv1b/relu (7)
I0925 09:56:34.106468  8172 net.cpp:561] conv1b/relu <- conv1b
I0925 09:56:34.106470  8172 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0925 09:56:34.106474  8172 net.cpp:245] Setting up conv1b/relu
I0925 09:56:34.106477  8172 net.cpp:252] TEST Top shape for layer 7 'conv1b/relu' 1 32 512 1024 (16777216)
I0925 09:56:34.106478  8172 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0925 09:56:34.106492  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.106499  8172 net.cpp:184] Created Layer pool1 (8)
I0925 09:56:34.106520  8172 net.cpp:561] pool1 <- conv1b
I0925 09:56:34.106528  8172 net.cpp:530] pool1 -> pool1
I0925 09:56:34.106583  8172 net.cpp:245] Setting up pool1
I0925 09:56:34.106590  8172 net.cpp:252] TEST Top shape for layer 8 'pool1' 1 32 256 512 (4194304)
I0925 09:56:34.106593  8172 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0925 09:56:34.106597  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.106606  8172 net.cpp:184] Created Layer res2a_branch2a (9)
I0925 09:56:34.106608  8172 net.cpp:561] res2a_branch2a <- pool1
I0925 09:56:34.106612  8172 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0925 09:56:34.107875  8172 net.cpp:245] Setting up res2a_branch2a
I0925 09:56:34.107885  8172 net.cpp:252] TEST Top shape for layer 9 'res2a_branch2a' 1 64 256 512 (8388608)
I0925 09:56:34.107892  8172 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0925 09:56:34.107895  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.107905  8172 net.cpp:184] Created Layer res2a_branch2a/bn (10)
I0925 09:56:34.107910  8172 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0925 09:56:34.107914  8172 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0925 09:56:34.108387  8172 net.cpp:245] Setting up res2a_branch2a/bn
I0925 09:56:34.108397  8172 net.cpp:252] TEST Top shape for layer 10 'res2a_branch2a/bn' 1 64 256 512 (8388608)
I0925 09:56:34.108402  8172 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0925 09:56:34.108404  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.108408  8172 net.cpp:184] Created Layer res2a_branch2a/relu (11)
I0925 09:56:34.108410  8172 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0925 09:56:34.108412  8172 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0925 09:56:34.108417  8172 net.cpp:245] Setting up res2a_branch2a/relu
I0925 09:56:34.108419  8172 net.cpp:252] TEST Top shape for layer 11 'res2a_branch2a/relu' 1 64 256 512 (8388608)
I0925 09:56:34.108422  8172 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0925 09:56:34.108423  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.108433  8172 net.cpp:184] Created Layer res2a_branch2b (12)
I0925 09:56:34.108436  8172 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0925 09:56:34.108440  8172 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0925 09:56:34.109580  8172 net.cpp:245] Setting up res2a_branch2b
I0925 09:56:34.109593  8172 net.cpp:252] TEST Top shape for layer 12 'res2a_branch2b' 1 64 256 512 (8388608)
I0925 09:56:34.109598  8172 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0925 09:56:34.109601  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.109609  8172 net.cpp:184] Created Layer res2a_branch2b/bn (13)
I0925 09:56:34.109612  8172 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0925 09:56:34.109614  8172 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0925 09:56:34.110486  8172 net.cpp:245] Setting up res2a_branch2b/bn
I0925 09:56:34.110496  8172 net.cpp:252] TEST Top shape for layer 13 'res2a_branch2b/bn' 1 64 256 512 (8388608)
I0925 09:56:34.110502  8172 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0925 09:56:34.110505  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.110509  8172 net.cpp:184] Created Layer res2a_branch2b/relu (14)
I0925 09:56:34.110512  8172 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0925 09:56:34.110514  8172 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0925 09:56:34.110535  8172 net.cpp:245] Setting up res2a_branch2b/relu
I0925 09:56:34.110541  8172 net.cpp:252] TEST Top shape for layer 14 'res2a_branch2b/relu' 1 64 256 512 (8388608)
I0925 09:56:34.110546  8172 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0925 09:56:34.110549  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.110558  8172 net.cpp:184] Created Layer pool2 (15)
I0925 09:56:34.110561  8172 net.cpp:561] pool2 <- res2a_branch2b
I0925 09:56:34.110565  8172 net.cpp:530] pool2 -> pool2
I0925 09:56:34.110616  8172 net.cpp:245] Setting up pool2
I0925 09:56:34.110622  8172 net.cpp:252] TEST Top shape for layer 15 'pool2' 1 64 128 256 (2097152)
I0925 09:56:34.110626  8172 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0925 09:56:34.110630  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.110641  8172 net.cpp:184] Created Layer res3a_branch2a (16)
I0925 09:56:34.110644  8172 net.cpp:561] res3a_branch2a <- pool2
I0925 09:56:34.110648  8172 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0925 09:56:34.113481  8172 net.cpp:245] Setting up res3a_branch2a
I0925 09:56:34.113499  8172 net.cpp:252] TEST Top shape for layer 16 'res3a_branch2a' 1 128 128 256 (4194304)
I0925 09:56:34.113507  8172 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0925 09:56:34.113513  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.113523  8172 net.cpp:184] Created Layer res3a_branch2a/bn (17)
I0925 09:56:34.113528  8172 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0925 09:56:34.113533  8172 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0925 09:56:34.113961  8172 net.cpp:245] Setting up res3a_branch2a/bn
I0925 09:56:34.113970  8172 net.cpp:252] TEST Top shape for layer 17 'res3a_branch2a/bn' 1 128 128 256 (4194304)
I0925 09:56:34.113981  8172 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0925 09:56:34.113986  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.113991  8172 net.cpp:184] Created Layer res3a_branch2a/relu (18)
I0925 09:56:34.114004  8172 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0925 09:56:34.114009  8172 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0925 09:56:34.114017  8172 net.cpp:245] Setting up res3a_branch2a/relu
I0925 09:56:34.114022  8172 net.cpp:252] TEST Top shape for layer 18 'res3a_branch2a/relu' 1 128 128 256 (4194304)
I0925 09:56:34.114027  8172 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0925 09:56:34.114032  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.114042  8172 net.cpp:184] Created Layer res3a_branch2b (19)
I0925 09:56:34.114047  8172 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0925 09:56:34.114050  8172 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0925 09:56:34.114998  8172 net.cpp:245] Setting up res3a_branch2b
I0925 09:56:34.115008  8172 net.cpp:252] TEST Top shape for layer 19 'res3a_branch2b' 1 128 128 256 (4194304)
I0925 09:56:34.115015  8172 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0925 09:56:34.115020  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.115027  8172 net.cpp:184] Created Layer res3a_branch2b/bn (20)
I0925 09:56:34.115031  8172 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0925 09:56:34.115036  8172 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0925 09:56:34.115445  8172 net.cpp:245] Setting up res3a_branch2b/bn
I0925 09:56:34.115453  8172 net.cpp:252] TEST Top shape for layer 20 'res3a_branch2b/bn' 1 128 128 256 (4194304)
I0925 09:56:34.115461  8172 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0925 09:56:34.115465  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.115483  8172 net.cpp:184] Created Layer res3a_branch2b/relu (21)
I0925 09:56:34.115487  8172 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0925 09:56:34.115491  8172 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0925 09:56:34.115502  8172 net.cpp:245] Setting up res3a_branch2b/relu
I0925 09:56:34.115507  8172 net.cpp:252] TEST Top shape for layer 21 'res3a_branch2b/relu' 1 128 128 256 (4194304)
I0925 09:56:34.115511  8172 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0925 09:56:34.115516  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.115526  8172 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (22)
I0925 09:56:34.115530  8172 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0925 09:56:34.115535  8172 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0925 09:56:34.115540  8172 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0925 09:56:34.115571  8172 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0925 09:56:34.115576  8172 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b_res3a_branch2b/relu_0_split' 1 128 128 256 (4194304)
I0925 09:56:34.115582  8172 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b_res3a_branch2b/relu_0_split' 1 128 128 256 (4194304)
I0925 09:56:34.115586  8172 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0925 09:56:34.115592  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.115597  8172 net.cpp:184] Created Layer pool3 (23)
I0925 09:56:34.115602  8172 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0925 09:56:34.115607  8172 net.cpp:530] pool3 -> pool3
I0925 09:56:34.115641  8172 net.cpp:245] Setting up pool3
I0925 09:56:34.115646  8172 net.cpp:252] TEST Top shape for layer 23 'pool3' 1 128 64 128 (1048576)
I0925 09:56:34.115651  8172 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0925 09:56:34.115655  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.115666  8172 net.cpp:184] Created Layer res4a_branch2a (24)
I0925 09:56:34.115669  8172 net.cpp:561] res4a_branch2a <- pool3
I0925 09:56:34.115674  8172 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0925 09:56:34.121865  8172 net.cpp:245] Setting up res4a_branch2a
I0925 09:56:34.121876  8172 net.cpp:252] TEST Top shape for layer 24 'res4a_branch2a' 1 256 64 128 (2097152)
I0925 09:56:34.121882  8172 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0925 09:56:34.121887  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.121896  8172 net.cpp:184] Created Layer res4a_branch2a/bn (25)
I0925 09:56:34.121901  8172 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0925 09:56:34.121906  8172 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0925 09:56:34.122306  8172 net.cpp:245] Setting up res4a_branch2a/bn
I0925 09:56:34.122314  8172 net.cpp:252] TEST Top shape for layer 25 'res4a_branch2a/bn' 1 256 64 128 (2097152)
I0925 09:56:34.122323  8172 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0925 09:56:34.122328  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.122333  8172 net.cpp:184] Created Layer res4a_branch2a/relu (26)
I0925 09:56:34.122337  8172 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0925 09:56:34.122341  8172 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0925 09:56:34.122347  8172 net.cpp:245] Setting up res4a_branch2a/relu
I0925 09:56:34.122354  8172 net.cpp:252] TEST Top shape for layer 26 'res4a_branch2a/relu' 1 256 64 128 (2097152)
I0925 09:56:34.122359  8172 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0925 09:56:34.122370  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.122380  8172 net.cpp:184] Created Layer res4a_branch2b (27)
I0925 09:56:34.122385  8172 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0925 09:56:34.122388  8172 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0925 09:56:34.125473  8172 net.cpp:245] Setting up res4a_branch2b
I0925 09:56:34.125483  8172 net.cpp:252] TEST Top shape for layer 27 'res4a_branch2b' 1 256 64 128 (2097152)
I0925 09:56:34.125488  8172 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0925 09:56:34.125494  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.125501  8172 net.cpp:184] Created Layer res4a_branch2b/bn (28)
I0925 09:56:34.125505  8172 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0925 09:56:34.125510  8172 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0925 09:56:34.125900  8172 net.cpp:245] Setting up res4a_branch2b/bn
I0925 09:56:34.125908  8172 net.cpp:252] TEST Top shape for layer 28 'res4a_branch2b/bn' 1 256 64 128 (2097152)
I0925 09:56:34.125916  8172 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0925 09:56:34.125921  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.125926  8172 net.cpp:184] Created Layer res4a_branch2b/relu (29)
I0925 09:56:34.125931  8172 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0925 09:56:34.125934  8172 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0925 09:56:34.125941  8172 net.cpp:245] Setting up res4a_branch2b/relu
I0925 09:56:34.125946  8172 net.cpp:252] TEST Top shape for layer 29 'res4a_branch2b/relu' 1 256 64 128 (2097152)
I0925 09:56:34.125952  8172 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0925 09:56:34.125955  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.125962  8172 net.cpp:184] Created Layer pool4 (30)
I0925 09:56:34.125967  8172 net.cpp:561] pool4 <- res4a_branch2b
I0925 09:56:34.125970  8172 net.cpp:530] pool4 -> pool4
I0925 09:56:34.126003  8172 net.cpp:245] Setting up pool4
I0925 09:56:34.126009  8172 net.cpp:252] TEST Top shape for layer 30 'pool4' 1 256 64 128 (2097152)
I0925 09:56:34.126013  8172 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0925 09:56:34.126018  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.126026  8172 net.cpp:184] Created Layer res5a_branch2a (31)
I0925 09:56:34.126030  8172 net.cpp:561] res5a_branch2a <- pool4
I0925 09:56:34.126034  8172 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0925 09:56:34.151209  8172 net.cpp:245] Setting up res5a_branch2a
I0925 09:56:34.151232  8172 net.cpp:252] TEST Top shape for layer 31 'res5a_branch2a' 1 512 64 128 (4194304)
I0925 09:56:34.151242  8172 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0925 09:56:34.151247  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.151258  8172 net.cpp:184] Created Layer res5a_branch2a/bn (32)
I0925 09:56:34.151263  8172 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0925 09:56:34.151269  8172 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0925 09:56:34.151677  8172 net.cpp:245] Setting up res5a_branch2a/bn
I0925 09:56:34.151685  8172 net.cpp:252] TEST Top shape for layer 32 'res5a_branch2a/bn' 1 512 64 128 (4194304)
I0925 09:56:34.151695  8172 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0925 09:56:34.151700  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.151705  8172 net.cpp:184] Created Layer res5a_branch2a/relu (33)
I0925 09:56:34.151708  8172 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0925 09:56:34.151721  8172 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0925 09:56:34.151727  8172 net.cpp:245] Setting up res5a_branch2a/relu
I0925 09:56:34.151732  8172 net.cpp:252] TEST Top shape for layer 33 'res5a_branch2a/relu' 1 512 64 128 (4194304)
I0925 09:56:34.151736  8172 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0925 09:56:34.151741  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.151756  8172 net.cpp:184] Created Layer res5a_branch2b (34)
I0925 09:56:34.151759  8172 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0925 09:56:34.151763  8172 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0925 09:56:34.164183  8172 net.cpp:245] Setting up res5a_branch2b
I0925 09:56:34.164207  8172 net.cpp:252] TEST Top shape for layer 34 'res5a_branch2b' 1 512 64 128 (4194304)
I0925 09:56:34.164222  8172 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0925 09:56:34.164228  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.164238  8172 net.cpp:184] Created Layer res5a_branch2b/bn (35)
I0925 09:56:34.164243  8172 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0925 09:56:34.164248  8172 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0925 09:56:34.164652  8172 net.cpp:245] Setting up res5a_branch2b/bn
I0925 09:56:34.164659  8172 net.cpp:252] TEST Top shape for layer 35 'res5a_branch2b/bn' 1 512 64 128 (4194304)
I0925 09:56:34.164669  8172 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0925 09:56:34.164674  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.164680  8172 net.cpp:184] Created Layer res5a_branch2b/relu (36)
I0925 09:56:34.164685  8172 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0925 09:56:34.164688  8172 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0925 09:56:34.164695  8172 net.cpp:245] Setting up res5a_branch2b/relu
I0925 09:56:34.164700  8172 net.cpp:252] TEST Top shape for layer 36 'res5a_branch2b/relu' 1 512 64 128 (4194304)
I0925 09:56:34.164705  8172 layer_factory.hpp:136] Creating layer 'out5a' of type 'Convolution'
I0925 09:56:34.164708  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.164719  8172 net.cpp:184] Created Layer out5a (37)
I0925 09:56:34.164723  8172 net.cpp:561] out5a <- res5a_branch2b
I0925 09:56:34.164727  8172 net.cpp:530] out5a -> out5a
I0925 09:56:34.168455  8172 net.cpp:245] Setting up out5a
I0925 09:56:34.168467  8172 net.cpp:252] TEST Top shape for layer 37 'out5a' 1 64 64 128 (524288)
I0925 09:56:34.168474  8172 layer_factory.hpp:136] Creating layer 'out5a/bn' of type 'BatchNorm'
I0925 09:56:34.168480  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.168489  8172 net.cpp:184] Created Layer out5a/bn (38)
I0925 09:56:34.168494  8172 net.cpp:561] out5a/bn <- out5a
I0925 09:56:34.168499  8172 net.cpp:513] out5a/bn -> out5a (in-place)
I0925 09:56:34.168927  8172 net.cpp:245] Setting up out5a/bn
I0925 09:56:34.168936  8172 net.cpp:252] TEST Top shape for layer 38 'out5a/bn' 1 64 64 128 (524288)
I0925 09:56:34.168944  8172 layer_factory.hpp:136] Creating layer 'out5a/relu' of type 'ReLU'
I0925 09:56:34.168949  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.168954  8172 net.cpp:184] Created Layer out5a/relu (39)
I0925 09:56:34.168959  8172 net.cpp:561] out5a/relu <- out5a
I0925 09:56:34.168963  8172 net.cpp:513] out5a/relu -> out5a (in-place)
I0925 09:56:34.168969  8172 net.cpp:245] Setting up out5a/relu
I0925 09:56:34.168975  8172 net.cpp:252] TEST Top shape for layer 39 'out5a/relu' 1 64 64 128 (524288)
I0925 09:56:34.168978  8172 layer_factory.hpp:136] Creating layer 'out5a_up2' of type 'Deconvolution'
I0925 09:56:34.168982  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.169008  8172 net.cpp:184] Created Layer out5a_up2 (40)
I0925 09:56:34.169013  8172 net.cpp:561] out5a_up2 <- out5a
I0925 09:56:34.169016  8172 net.cpp:530] out5a_up2 -> out5a_up2
I0925 09:56:34.169160  8172 net.cpp:245] Setting up out5a_up2
I0925 09:56:34.169167  8172 net.cpp:252] TEST Top shape for layer 40 'out5a_up2' 1 64 128 256 (2097152)
I0925 09:56:34.169173  8172 layer_factory.hpp:136] Creating layer 'out3a' of type 'Convolution'
I0925 09:56:34.169178  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.169186  8172 net.cpp:184] Created Layer out3a (41)
I0925 09:56:34.169190  8172 net.cpp:561] out3a <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0925 09:56:34.169195  8172 net.cpp:530] out3a -> out3a
I0925 09:56:34.170255  8172 net.cpp:245] Setting up out3a
I0925 09:56:34.170265  8172 net.cpp:252] TEST Top shape for layer 41 'out3a' 1 64 128 256 (2097152)
I0925 09:56:34.170272  8172 layer_factory.hpp:136] Creating layer 'out3a/bn' of type 'BatchNorm'
I0925 09:56:34.170277  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.170286  8172 net.cpp:184] Created Layer out3a/bn (42)
I0925 09:56:34.170291  8172 net.cpp:561] out3a/bn <- out3a
I0925 09:56:34.170295  8172 net.cpp:513] out3a/bn -> out3a (in-place)
I0925 09:56:34.170722  8172 net.cpp:245] Setting up out3a/bn
I0925 09:56:34.170730  8172 net.cpp:252] TEST Top shape for layer 42 'out3a/bn' 1 64 128 256 (2097152)
I0925 09:56:34.170738  8172 layer_factory.hpp:136] Creating layer 'out3a/relu' of type 'ReLU'
I0925 09:56:34.170743  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.170748  8172 net.cpp:184] Created Layer out3a/relu (43)
I0925 09:56:34.170753  8172 net.cpp:561] out3a/relu <- out3a
I0925 09:56:34.170758  8172 net.cpp:513] out3a/relu -> out3a (in-place)
I0925 09:56:34.170764  8172 net.cpp:245] Setting up out3a/relu
I0925 09:56:34.170769  8172 net.cpp:252] TEST Top shape for layer 43 'out3a/relu' 1 64 128 256 (2097152)
I0925 09:56:34.170773  8172 layer_factory.hpp:136] Creating layer 'out3_out5_combined' of type 'Eltwise'
I0925 09:56:34.170778  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.170789  8172 net.cpp:184] Created Layer out3_out5_combined (44)
I0925 09:56:34.170792  8172 net.cpp:561] out3_out5_combined <- out5a_up2
I0925 09:56:34.170796  8172 net.cpp:561] out3_out5_combined <- out3a
I0925 09:56:34.170800  8172 net.cpp:530] out3_out5_combined -> out3_out5_combined
I0925 09:56:34.170819  8172 net.cpp:245] Setting up out3_out5_combined
I0925 09:56:34.170824  8172 net.cpp:252] TEST Top shape for layer 44 'out3_out5_combined' 1 64 128 256 (2097152)
I0925 09:56:34.170827  8172 layer_factory.hpp:136] Creating layer 'ctx_conv1' of type 'Convolution'
I0925 09:56:34.170831  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.170841  8172 net.cpp:184] Created Layer ctx_conv1 (45)
I0925 09:56:34.170845  8172 net.cpp:561] ctx_conv1 <- out3_out5_combined
I0925 09:56:34.170848  8172 net.cpp:530] ctx_conv1 -> ctx_conv1
I0925 09:56:34.171763  8172 net.cpp:245] Setting up ctx_conv1
I0925 09:56:34.171772  8172 net.cpp:252] TEST Top shape for layer 45 'ctx_conv1' 1 64 128 256 (2097152)
I0925 09:56:34.171777  8172 layer_factory.hpp:136] Creating layer 'ctx_conv1/bn' of type 'BatchNorm'
I0925 09:56:34.171783  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.171789  8172 net.cpp:184] Created Layer ctx_conv1/bn (46)
I0925 09:56:34.171793  8172 net.cpp:561] ctx_conv1/bn <- ctx_conv1
I0925 09:56:34.171797  8172 net.cpp:513] ctx_conv1/bn -> ctx_conv1 (in-place)
I0925 09:56:34.172230  8172 net.cpp:245] Setting up ctx_conv1/bn
I0925 09:56:34.172238  8172 net.cpp:252] TEST Top shape for layer 46 'ctx_conv1/bn' 1 64 128 256 (2097152)
I0925 09:56:34.172247  8172 layer_factory.hpp:136] Creating layer 'ctx_conv1/relu' of type 'ReLU'
I0925 09:56:34.172258  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.172264  8172 net.cpp:184] Created Layer ctx_conv1/relu (47)
I0925 09:56:34.172268  8172 net.cpp:561] ctx_conv1/relu <- ctx_conv1
I0925 09:56:34.172272  8172 net.cpp:513] ctx_conv1/relu -> ctx_conv1 (in-place)
I0925 09:56:34.172279  8172 net.cpp:245] Setting up ctx_conv1/relu
I0925 09:56:34.172284  8172 net.cpp:252] TEST Top shape for layer 47 'ctx_conv1/relu' 1 64 128 256 (2097152)
I0925 09:56:34.172288  8172 layer_factory.hpp:136] Creating layer 'ctx_conv2' of type 'Convolution'
I0925 09:56:34.172293  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.172304  8172 net.cpp:184] Created Layer ctx_conv2 (48)
I0925 09:56:34.172308  8172 net.cpp:561] ctx_conv2 <- ctx_conv1
I0925 09:56:34.172312  8172 net.cpp:530] ctx_conv2 -> ctx_conv2
I0925 09:56:34.173211  8172 net.cpp:245] Setting up ctx_conv2
I0925 09:56:34.173219  8172 net.cpp:252] TEST Top shape for layer 48 'ctx_conv2' 1 64 128 256 (2097152)
I0925 09:56:34.173225  8172 layer_factory.hpp:136] Creating layer 'ctx_conv2/bn' of type 'BatchNorm'
I0925 09:56:34.173230  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.173236  8172 net.cpp:184] Created Layer ctx_conv2/bn (49)
I0925 09:56:34.173240  8172 net.cpp:561] ctx_conv2/bn <- ctx_conv2
I0925 09:56:34.173244  8172 net.cpp:513] ctx_conv2/bn -> ctx_conv2 (in-place)
I0925 09:56:34.173650  8172 net.cpp:245] Setting up ctx_conv2/bn
I0925 09:56:34.173657  8172 net.cpp:252] TEST Top shape for layer 49 'ctx_conv2/bn' 1 64 128 256 (2097152)
I0925 09:56:34.173666  8172 layer_factory.hpp:136] Creating layer 'ctx_conv2/relu' of type 'ReLU'
I0925 09:56:34.173671  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.173676  8172 net.cpp:184] Created Layer ctx_conv2/relu (50)
I0925 09:56:34.173679  8172 net.cpp:561] ctx_conv2/relu <- ctx_conv2
I0925 09:56:34.173683  8172 net.cpp:513] ctx_conv2/relu -> ctx_conv2 (in-place)
I0925 09:56:34.173689  8172 net.cpp:245] Setting up ctx_conv2/relu
I0925 09:56:34.173696  8172 net.cpp:252] TEST Top shape for layer 50 'ctx_conv2/relu' 1 64 128 256 (2097152)
I0925 09:56:34.173699  8172 layer_factory.hpp:136] Creating layer 'ctx_conv3' of type 'Convolution'
I0925 09:56:34.173704  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.173714  8172 net.cpp:184] Created Layer ctx_conv3 (51)
I0925 09:56:34.173718  8172 net.cpp:561] ctx_conv3 <- ctx_conv2
I0925 09:56:34.173722  8172 net.cpp:530] ctx_conv3 -> ctx_conv3
I0925 09:56:34.174619  8172 net.cpp:245] Setting up ctx_conv3
I0925 09:56:34.174626  8172 net.cpp:252] TEST Top shape for layer 51 'ctx_conv3' 1 64 128 256 (2097152)
I0925 09:56:34.174633  8172 layer_factory.hpp:136] Creating layer 'ctx_conv3/bn' of type 'BatchNorm'
I0925 09:56:34.174638  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.174644  8172 net.cpp:184] Created Layer ctx_conv3/bn (52)
I0925 09:56:34.174649  8172 net.cpp:561] ctx_conv3/bn <- ctx_conv3
I0925 09:56:34.174654  8172 net.cpp:513] ctx_conv3/bn -> ctx_conv3 (in-place)
I0925 09:56:34.175057  8172 net.cpp:245] Setting up ctx_conv3/bn
I0925 09:56:34.175065  8172 net.cpp:252] TEST Top shape for layer 52 'ctx_conv3/bn' 1 64 128 256 (2097152)
I0925 09:56:34.175073  8172 layer_factory.hpp:136] Creating layer 'ctx_conv3/relu' of type 'ReLU'
I0925 09:56:34.175077  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.175083  8172 net.cpp:184] Created Layer ctx_conv3/relu (53)
I0925 09:56:34.175087  8172 net.cpp:561] ctx_conv3/relu <- ctx_conv3
I0925 09:56:34.175091  8172 net.cpp:513] ctx_conv3/relu -> ctx_conv3 (in-place)
I0925 09:56:34.175097  8172 net.cpp:245] Setting up ctx_conv3/relu
I0925 09:56:34.175112  8172 net.cpp:252] TEST Top shape for layer 53 'ctx_conv3/relu' 1 64 128 256 (2097152)
I0925 09:56:34.175122  8172 layer_factory.hpp:136] Creating layer 'ctx_conv4' of type 'Convolution'
I0925 09:56:34.175127  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.175134  8172 net.cpp:184] Created Layer ctx_conv4 (54)
I0925 09:56:34.175139  8172 net.cpp:561] ctx_conv4 <- ctx_conv3
I0925 09:56:34.175144  8172 net.cpp:530] ctx_conv4 -> ctx_conv4
I0925 09:56:34.176046  8172 net.cpp:245] Setting up ctx_conv4
I0925 09:56:34.176054  8172 net.cpp:252] TEST Top shape for layer 54 'ctx_conv4' 1 64 128 256 (2097152)
I0925 09:56:34.176060  8172 layer_factory.hpp:136] Creating layer 'ctx_conv4/bn' of type 'BatchNorm'
I0925 09:56:34.176065  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.176071  8172 net.cpp:184] Created Layer ctx_conv4/bn (55)
I0925 09:56:34.176075  8172 net.cpp:561] ctx_conv4/bn <- ctx_conv4
I0925 09:56:34.176079  8172 net.cpp:513] ctx_conv4/bn -> ctx_conv4 (in-place)
I0925 09:56:34.176575  8172 net.cpp:245] Setting up ctx_conv4/bn
I0925 09:56:34.176584  8172 net.cpp:252] TEST Top shape for layer 55 'ctx_conv4/bn' 1 64 128 256 (2097152)
I0925 09:56:34.176594  8172 layer_factory.hpp:136] Creating layer 'ctx_conv4/relu' of type 'ReLU'
I0925 09:56:34.176599  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.176604  8172 net.cpp:184] Created Layer ctx_conv4/relu (56)
I0925 09:56:34.176606  8172 net.cpp:561] ctx_conv4/relu <- ctx_conv4
I0925 09:56:34.176611  8172 net.cpp:513] ctx_conv4/relu -> ctx_conv4 (in-place)
I0925 09:56:34.176617  8172 net.cpp:245] Setting up ctx_conv4/relu
I0925 09:56:34.176622  8172 net.cpp:252] TEST Top shape for layer 56 'ctx_conv4/relu' 1 64 128 256 (2097152)
I0925 09:56:34.176626  8172 layer_factory.hpp:136] Creating layer 'ctx_final' of type 'Convolution'
I0925 09:56:34.176630  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.176648  8172 net.cpp:184] Created Layer ctx_final (57)
I0925 09:56:34.176653  8172 net.cpp:561] ctx_final <- ctx_conv4
I0925 09:56:34.176657  8172 net.cpp:530] ctx_final -> ctx_final
I0925 09:56:34.176933  8172 net.cpp:245] Setting up ctx_final
I0925 09:56:34.176940  8172 net.cpp:252] TEST Top shape for layer 57 'ctx_final' 1 8 128 256 (262144)
I0925 09:56:34.176947  8172 layer_factory.hpp:136] Creating layer 'ctx_final/relu' of type 'ReLU'
I0925 09:56:34.176951  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.176956  8172 net.cpp:184] Created Layer ctx_final/relu (58)
I0925 09:56:34.176959  8172 net.cpp:561] ctx_final/relu <- ctx_final
I0925 09:56:34.176964  8172 net.cpp:513] ctx_final/relu -> ctx_final (in-place)
I0925 09:56:34.176971  8172 net.cpp:245] Setting up ctx_final/relu
I0925 09:56:34.176976  8172 net.cpp:252] TEST Top shape for layer 58 'ctx_final/relu' 1 8 128 256 (262144)
I0925 09:56:34.176980  8172 layer_factory.hpp:136] Creating layer 'out_deconv_final_up2' of type 'Deconvolution'
I0925 09:56:34.176985  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.176991  8172 net.cpp:184] Created Layer out_deconv_final_up2 (59)
I0925 09:56:34.176995  8172 net.cpp:561] out_deconv_final_up2 <- ctx_final
I0925 09:56:34.176998  8172 net.cpp:530] out_deconv_final_up2 -> out_deconv_final_up2
I0925 09:56:34.177124  8172 net.cpp:245] Setting up out_deconv_final_up2
I0925 09:56:34.177130  8172 net.cpp:252] TEST Top shape for layer 59 'out_deconv_final_up2' 1 8 256 512 (1048576)
I0925 09:56:34.177135  8172 layer_factory.hpp:136] Creating layer 'out_deconv_final_up4' of type 'Deconvolution'
I0925 09:56:34.177139  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.177146  8172 net.cpp:184] Created Layer out_deconv_final_up4 (60)
I0925 09:56:34.177150  8172 net.cpp:561] out_deconv_final_up4 <- out_deconv_final_up2
I0925 09:56:34.177160  8172 net.cpp:530] out_deconv_final_up4 -> out_deconv_final_up4
I0925 09:56:34.177287  8172 net.cpp:245] Setting up out_deconv_final_up4
I0925 09:56:34.177294  8172 net.cpp:252] TEST Top shape for layer 60 'out_deconv_final_up4' 1 8 512 1024 (4194304)
I0925 09:56:34.177300  8172 layer_factory.hpp:136] Creating layer 'out_deconv_final_up8' of type 'Deconvolution'
I0925 09:56:34.177304  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.177310  8172 net.cpp:184] Created Layer out_deconv_final_up8 (61)
I0925 09:56:34.177314  8172 net.cpp:561] out_deconv_final_up8 <- out_deconv_final_up4
I0925 09:56:34.177319  8172 net.cpp:530] out_deconv_final_up8 -> out_deconv_final_up8
I0925 09:56:34.177448  8172 net.cpp:245] Setting up out_deconv_final_up8
I0925 09:56:34.177453  8172 net.cpp:252] TEST Top shape for layer 61 'out_deconv_final_up8' 1 8 1024 2048 (16777216)
I0925 09:56:34.177459  8172 layer_factory.hpp:136] Creating layer 'argMaxOut' of type 'ArgMax'
I0925 09:56:34.177462  8172 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:56:34.177474  8172 net.cpp:184] Created Layer argMaxOut (62)
I0925 09:56:34.177477  8172 net.cpp:561] argMaxOut <- out_deconv_final_up8
I0925 09:56:34.177481  8172 net.cpp:530] argMaxOut -> argMaxOut
I0925 09:56:34.177500  8172 net.cpp:245] Setting up argMaxOut
I0925 09:56:34.177505  8172 net.cpp:252] TEST Top shape for layer 62 'argMaxOut' 1 1 1024 2048 (2097152)
I0925 09:56:34.177508  8172 net.cpp:325] argMaxOut does not need backward computation.
I0925 09:56:34.177513  8172 net.cpp:325] out_deconv_final_up8 does not need backward computation.
I0925 09:56:34.177517  8172 net.cpp:325] out_deconv_final_up4 does not need backward computation.
I0925 09:56:34.177521  8172 net.cpp:325] out_deconv_final_up2 does not need backward computation.
I0925 09:56:34.177525  8172 net.cpp:325] ctx_final/relu does not need backward computation.
I0925 09:56:34.177528  8172 net.cpp:325] ctx_final does not need backward computation.
I0925 09:56:34.177538  8172 net.cpp:325] ctx_conv4/relu does not need backward computation.
I0925 09:56:34.177541  8172 net.cpp:325] ctx_conv4/bn does not need backward computation.
I0925 09:56:34.177544  8172 net.cpp:325] ctx_conv4 does not need backward computation.
I0925 09:56:34.177547  8172 net.cpp:325] ctx_conv3/relu does not need backward computation.
I0925 09:56:34.177551  8172 net.cpp:325] ctx_conv3/bn does not need backward computation.
I0925 09:56:34.177556  8172 net.cpp:325] ctx_conv3 does not need backward computation.
I0925 09:56:34.177558  8172 net.cpp:325] ctx_conv2/relu does not need backward computation.
I0925 09:56:34.177562  8172 net.cpp:325] ctx_conv2/bn does not need backward computation.
I0925 09:56:34.177565  8172 net.cpp:325] ctx_conv2 does not need backward computation.
I0925 09:56:34.177568  8172 net.cpp:325] ctx_conv1/relu does not need backward computation.
I0925 09:56:34.177572  8172 net.cpp:325] ctx_conv1/bn does not need backward computation.
I0925 09:56:34.177577  8172 net.cpp:325] ctx_conv1 does not need backward computation.
I0925 09:56:34.177580  8172 net.cpp:325] out3_out5_combined does not need backward computation.
I0925 09:56:34.177585  8172 net.cpp:325] out3a/relu does not need backward computation.
I0925 09:56:34.177589  8172 net.cpp:325] out3a/bn does not need backward computation.
I0925 09:56:34.177593  8172 net.cpp:325] out3a does not need backward computation.
I0925 09:56:34.177597  8172 net.cpp:325] out5a_up2 does not need backward computation.
I0925 09:56:34.177603  8172 net.cpp:325] out5a/relu does not need backward computation.
I0925 09:56:34.177606  8172 net.cpp:325] out5a/bn does not need backward computation.
I0925 09:56:34.177610  8172 net.cpp:325] out5a does not need backward computation.
I0925 09:56:34.177614  8172 net.cpp:325] res5a_branch2b/relu does not need backward computation.
I0925 09:56:34.177618  8172 net.cpp:325] res5a_branch2b/bn does not need backward computation.
I0925 09:56:34.177626  8172 net.cpp:325] res5a_branch2b does not need backward computation.
I0925 09:56:34.177630  8172 net.cpp:325] res5a_branch2a/relu does not need backward computation.
I0925 09:56:34.177635  8172 net.cpp:325] res5a_branch2a/bn does not need backward computation.
I0925 09:56:34.177639  8172 net.cpp:325] res5a_branch2a does not need backward computation.
I0925 09:56:34.177644  8172 net.cpp:325] pool4 does not need backward computation.
I0925 09:56:34.177649  8172 net.cpp:325] res4a_branch2b/relu does not need backward computation.
I0925 09:56:34.177654  8172 net.cpp:325] res4a_branch2b/bn does not need backward computation.
I0925 09:56:34.177657  8172 net.cpp:325] res4a_branch2b does not need backward computation.
I0925 09:56:34.177661  8172 net.cpp:325] res4a_branch2a/relu does not need backward computation.
I0925 09:56:34.177665  8172 net.cpp:325] res4a_branch2a/bn does not need backward computation.
I0925 09:56:34.177670  8172 net.cpp:325] res4a_branch2a does not need backward computation.
I0925 09:56:34.177675  8172 net.cpp:325] pool3 does not need backward computation.
I0925 09:56:34.177680  8172 net.cpp:325] res3a_branch2b_res3a_branch2b/relu_0_split does not need backward computation.
I0925 09:56:34.177683  8172 net.cpp:325] res3a_branch2b/relu does not need backward computation.
I0925 09:56:34.177688  8172 net.cpp:325] res3a_branch2b/bn does not need backward computation.
I0925 09:56:34.177692  8172 net.cpp:325] res3a_branch2b does not need backward computation.
I0925 09:56:34.177695  8172 net.cpp:325] res3a_branch2a/relu does not need backward computation.
I0925 09:56:34.177700  8172 net.cpp:325] res3a_branch2a/bn does not need backward computation.
I0925 09:56:34.177703  8172 net.cpp:325] res3a_branch2a does not need backward computation.
I0925 09:56:34.177707  8172 net.cpp:325] pool2 does not need backward computation.
I0925 09:56:34.177711  8172 net.cpp:325] res2a_branch2b/relu does not need backward computation.
I0925 09:56:34.177716  8172 net.cpp:325] res2a_branch2b/bn does not need backward computation.
I0925 09:56:34.177721  8172 net.cpp:325] res2a_branch2b does not need backward computation.
I0925 09:56:34.177726  8172 net.cpp:325] res2a_branch2a/relu does not need backward computation.
I0925 09:56:34.177729  8172 net.cpp:325] res2a_branch2a/bn does not need backward computation.
I0925 09:56:34.177733  8172 net.cpp:325] res2a_branch2a does not need backward computation.
I0925 09:56:34.177738  8172 net.cpp:325] pool1 does not need backward computation.
I0925 09:56:34.177742  8172 net.cpp:325] conv1b/relu does not need backward computation.
I0925 09:56:34.177747  8172 net.cpp:325] conv1b/bn does not need backward computation.
I0925 09:56:34.177750  8172 net.cpp:325] conv1b does not need backward computation.
I0925 09:56:34.177754  8172 net.cpp:325] conv1a/relu does not need backward computation.
I0925 09:56:34.177758  8172 net.cpp:325] conv1a/bn does not need backward computation.
I0925 09:56:34.177762  8172 net.cpp:325] conv1a does not need backward computation.
I0925 09:56:34.177767  8172 net.cpp:325] data/bias does not need backward computation.
I0925 09:56:34.177770  8172 net.cpp:325] input does not need backward computation.
I0925 09:56:34.177774  8172 net.cpp:367] This network produces output argMaxOut
I0925 09:56:34.177814  8172 net.cpp:389] Top memory (TEST) required for data: 1224736768 diff: 1224736768
I0925 09:56:34.177817  8172 net.cpp:392] Bottom memory (TEST) required for data: 1216348160 diff: 1216348160
I0925 09:56:34.177820  8172 net.cpp:395] Shared (in-place) memory (TEST) by data: 659554304 diff: 659554304
I0925 09:56:34.177824  8172 net.cpp:398] Parameters memory (TEST) required for data: 10817840 diff: 10817840
I0925 09:56:34.177827  8172 net.cpp:401] Parameters shared memory (TEST) by data: 0 diff: 0
I0925 09:56:34.177831  8172 net.cpp:407] Network initialization done.
I0925 09:56:34.182829  8172 net.cpp:1078] Ignoring source layer data
I0925 09:56:34.182848  8172 net.cpp:1094] Copying source layer data/bias Type:Bias #blobs=1
I0925 09:56:34.182880  8172 net.cpp:1094] Copying source layer conv1a Type:Convolution #blobs=2
I0925 09:56:34.182902  8172 net.cpp:1094] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0925 09:56:34.183048  8172 net.cpp:1094] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0925 09:56:34.183053  8172 net.cpp:1094] Copying source layer conv1b Type:Convolution #blobs=2
I0925 09:56:34.183065  8172 net.cpp:1094] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0925 09:56:34.183161  8172 net.cpp:1094] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0925 09:56:34.183167  8172 net.cpp:1094] Copying source layer pool1 Type:Pooling #blobs=0
I0925 09:56:34.183171  8172 net.cpp:1094] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0925 09:56:34.183187  8172 net.cpp:1094] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0925 09:56:34.183282  8172 net.cpp:1094] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0925 09:56:34.183287  8172 net.cpp:1094] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0925 09:56:34.183302  8172 net.cpp:1094] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0925 09:56:34.183392  8172 net.cpp:1094] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0925 09:56:34.183396  8172 net.cpp:1094] Copying source layer pool2 Type:Pooling #blobs=0
I0925 09:56:34.183400  8172 net.cpp:1094] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0925 09:56:34.183439  8172 net.cpp:1094] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0925 09:56:34.183526  8172 net.cpp:1094] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0925 09:56:34.183531  8172 net.cpp:1094] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0925 09:56:34.183555  8172 net.cpp:1094] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0925 09:56:34.183634  8172 net.cpp:1094] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0925 09:56:34.183640  8172 net.cpp:1094] Copying source layer res3a_branch2b_res3a_branch2b/relu_0_split Type:Split #blobs=0
I0925 09:56:34.183642  8172 net.cpp:1094] Copying source layer pool3 Type:Pooling #blobs=0
I0925 09:56:34.183645  8172 net.cpp:1094] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0925 09:56:34.183755  8172 net.cpp:1094] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0925 09:56:34.183838  8172 net.cpp:1094] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0925 09:56:34.183843  8172 net.cpp:1094] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0925 09:56:34.183903  8172 net.cpp:1094] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0925 09:56:34.183984  8172 net.cpp:1094] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0925 09:56:34.183989  8172 net.cpp:1094] Copying source layer pool4 Type:Pooling #blobs=0
I0925 09:56:34.183992  8172 net.cpp:1094] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0925 09:56:34.184329  8172 net.cpp:1094] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0925 09:56:34.184413  8172 net.cpp:1094] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0925 09:56:34.184419  8172 net.cpp:1094] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0925 09:56:34.184602  8172 net.cpp:1094] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0925 09:56:34.184682  8172 net.cpp:1094] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0925 09:56:34.184687  8172 net.cpp:1094] Copying source layer out5a Type:Convolution #blobs=2
I0925 09:56:34.184741  8172 net.cpp:1094] Copying source layer out5a/bn Type:BatchNorm #blobs=5
I0925 09:56:34.184834  8172 net.cpp:1094] Copying source layer out5a/relu Type:ReLU #blobs=0
I0925 09:56:34.184839  8172 net.cpp:1094] Copying source layer out5a_up2 Type:Deconvolution #blobs=1
I0925 09:56:34.184847  8172 net.cpp:1094] Copying source layer out3a Type:Convolution #blobs=2
I0925 09:56:34.184870  8172 net.cpp:1094] Copying source layer out3a/bn Type:BatchNorm #blobs=5
I0925 09:56:34.184967  8172 net.cpp:1094] Copying source layer out3a/relu Type:ReLU #blobs=0
I0925 09:56:34.184973  8172 net.cpp:1094] Copying source layer out3_out5_combined Type:Eltwise #blobs=0
I0925 09:56:34.184975  8172 net.cpp:1094] Copying source layer ctx_conv1 Type:Convolution #blobs=2
I0925 09:56:34.184996  8172 net.cpp:1094] Copying source layer ctx_conv1/bn Type:BatchNorm #blobs=5
I0925 09:56:34.185084  8172 net.cpp:1094] Copying source layer ctx_conv1/relu Type:ReLU #blobs=0
I0925 09:56:34.185091  8172 net.cpp:1094] Copying source layer ctx_conv2 Type:Convolution #blobs=2
I0925 09:56:34.185111  8172 net.cpp:1094] Copying source layer ctx_conv2/bn Type:BatchNorm #blobs=5
I0925 09:56:34.185201  8172 net.cpp:1094] Copying source layer ctx_conv2/relu Type:ReLU #blobs=0
I0925 09:56:34.185206  8172 net.cpp:1094] Copying source layer ctx_conv3 Type:Convolution #blobs=2
I0925 09:56:34.185226  8172 net.cpp:1094] Copying source layer ctx_conv3/bn Type:BatchNorm #blobs=5
I0925 09:56:34.185314  8172 net.cpp:1094] Copying source layer ctx_conv3/relu Type:ReLU #blobs=0
I0925 09:56:34.185319  8172 net.cpp:1094] Copying source layer ctx_conv4 Type:Convolution #blobs=2
I0925 09:56:34.185340  8172 net.cpp:1094] Copying source layer ctx_conv4/bn Type:BatchNorm #blobs=5
I0925 09:56:34.185427  8172 net.cpp:1094] Copying source layer ctx_conv4/relu Type:ReLU #blobs=0
I0925 09:56:34.185432  8172 net.cpp:1094] Copying source layer ctx_final Type:Convolution #blobs=2
I0925 09:56:34.185444  8172 net.cpp:1094] Copying source layer ctx_final/relu Type:ReLU #blobs=0
I0925 09:56:34.185448  8172 net.cpp:1094] Copying source layer out_deconv_final_up2 Type:Deconvolution #blobs=1
I0925 09:56:34.185456  8172 net.cpp:1094] Copying source layer out_deconv_final_up4 Type:Deconvolution #blobs=1
I0925 09:56:34.185464  8172 net.cpp:1094] Copying source layer out_deconv_final_up8 Type:Deconvolution #blobs=1
I0925 09:56:34.185472  8172 net.cpp:1078] Ignoring source layer loss
Namespace(batch_size=1, blend=False, class_dict='', crop=['0'], input='./data/val-image-list.txt', label='./data/val-label-list.txt', label_dict='', model='../trained/image_segmentation/cityscapes5_jsegnet21v2/initial/deploy.prototxt', num_classes=5, num_images=500, output=None, palette='', resize=['0'], resize_back=True, search='*.png', weights='../trained/image_segmentation/cityscapes5_jsegnet21v2/initial/cityscapes5_jsegnet21v2_iter_120000.caffemodel')
Infering list
Getting list of images...running inference for  500  images...
('frankfurt_000000_000294_leftImg8bit.png', 'frankfurt_000000_000294_gtFine_labelIds.png', 0)
('frankfurt_000000_000576_leftImg8bit.png', 'frankfurt_000000_000576_gtFine_labelIds.png', 0)
('frankfurt_000000_001016_leftImg8bit.png', 'frankfurt_000000_001016_gtFine_labelIds.png', 0)
I0925 09:56:35.043177  8172 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1a' with space 0.01G 3/1 1 	(avail 5.89G, req 0.01G)	t: 0
I0925 09:56:35.168820  8172 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1b' with space 0.01G 32/4 6 	(avail 5.89G, req 0.01G)	t: 0
I0925 09:56:35.184653  8172 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2a' with space 0.01G 32/1 6 	(avail 5.89G, req 0.01G)	t: 0
I0925 09:56:35.222738  8172 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2b' with space 0.01G 64/4 6 	(avail 5.89G, req 0.01G)	t: 0
I0925 09:56:35.233587  8172 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2a' with space 0.01G 64/1 6 	(avail 5.89G, req 0.01G)	t: 0
I0925 09:56:35.237568  8172 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2b' with space 0.01G 128/4 6 	(avail 5.89G, req 0.01G)	t: 0
I0925 09:56:35.246683  8172 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2a' with space 0.01G 128/1 6 	(avail 5.89G, req 0.01G)	t: 0
I0925 09:56:35.250171  8172 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2b' with space 0.01G 256/4 6 	(avail 5.89G, req 0.01G)	t: 0
I0925 09:56:35.274087  8172 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'out3a' with space 0.01G 128/2 6 	(avail 5.89G, req 0.01G)	t: 0
I0925 09:56:35.280915  8172 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_conv1' with space 0.01G 64/1 6 	(avail 5.89G, req 0.01G)	t: 0
I0925 09:56:35.306200  8172 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_final' with space 0.01G 64/1 6 	(avail 5.89G, req 0.01G)	t: 0
('frankfurt_000000_001236_leftImg8bit.png', 'frankfurt_000000_001236_gtFine_labelIds.png', 0)
('frankfurt_000000_001751_leftImg8bit.png', 'frankfurt_000000_001751_gtFine_labelIds.png', 0)
('frankfurt_000000_002196_leftImg8bit.png', 'frankfurt_000000_002196_gtFine_labelIds.png', 1)
('frankfurt_000000_002963_leftImg8bit.png', 'frankfurt_000000_002963_gtFine_labelIds.png', 1)
('frankfurt_000000_003025_leftImg8bit.png', 'frankfurt_000000_003025_gtFine_labelIds.png', 1)
('frankfurt_000000_003357_leftImg8bit.png', 'frankfurt_000000_003357_gtFine_labelIds.png', 1)
('frankfurt_000000_003920_leftImg8bit.png', 'frankfurt_000000_003920_gtFine_labelIds.png', 1)
('frankfurt_000000_004617_leftImg8bit.png', 'frankfurt_000000_004617_gtFine_labelIds.png', 2)
('frankfurt_000000_005543_leftImg8bit.png', 'frankfurt_000000_005543_gtFine_labelIds.png', 2)
('frankfurt_000000_005898_leftImg8bit.png', 'frankfurt_000000_005898_gtFine_labelIds.png', 2)
('frankfurt_000000_006589_leftImg8bit.png', 'frankfurt_000000_006589_gtFine_labelIds.png', 2)
('frankfurt_000000_007365_leftImg8bit.png', 'frankfurt_000000_007365_gtFine_labelIds.png', 2)
('frankfurt_000000_008206_leftImg8bit.png', 'frankfurt_000000_008206_gtFine_labelIds.png', 3)
('frankfurt_000000_008451_leftImg8bit.png', 'frankfurt_000000_008451_gtFine_labelIds.png', 3)
('frankfurt_000000_009291_leftImg8bit.png', 'frankfurt_000000_009291_gtFine_labelIds.png', 3)
('frankfurt_000000_009561_leftImg8bit.png', 'frankfurt_000000_009561_gtFine_labelIds.png', 3)
('frankfurt_000000_009688_leftImg8bit.png', 'frankfurt_000000_009688_gtFine_labelIds.png', 3)
('frankfurt_000000_009969_leftImg8bit.png', 'frankfurt_000000_009969_gtFine_labelIds.png', 4)
('frankfurt_000000_010351_leftImg8bit.png', 'frankfurt_000000_010351_gtFine_labelIds.png', 4)
('frankfurt_000000_010763_leftImg8bit.png', 'frankfurt_000000_010763_gtFine_labelIds.png', 4)
('frankfurt_000000_011007_leftImg8bit.png', 'frankfurt_000000_011007_gtFine_labelIds.png', 4)
('frankfurt_000000_011074_leftImg8bit.png', 'frankfurt_000000_011074_gtFine_labelIds.png', 4)
pixel_accuracy=0.97455676307, mean_iou=0.825654093029, iou=[ 0.95761541  0.96552323  0.77736137  0.55684367  0.87092677]
('frankfurt_000000_011461_leftImg8bit.png', 'frankfurt_000000_011461_gtFine_labelIds.png', 5)
('frankfurt_000000_011810_leftImg8bit.png', 'frankfurt_000000_011810_gtFine_labelIds.png', 5)
('frankfurt_000000_012009_leftImg8bit.png', 'frankfurt_000000_012009_gtFine_labelIds.png', 5)
('frankfurt_000000_012121_leftImg8bit.png', 'frankfurt_000000_012121_gtFine_labelIds.png', 5)
('frankfurt_000000_012868_leftImg8bit.png', 'frankfurt_000000_012868_gtFine_labelIds.png', 5)
('frankfurt_000000_013067_leftImg8bit.png', 'frankfurt_000000_013067_gtFine_labelIds.png', 6)
('frankfurt_000000_013240_leftImg8bit.png', 'frankfurt_000000_013240_gtFine_labelIds.png', 6)
('frankfurt_000000_013382_leftImg8bit.png', 'frankfurt_000000_013382_gtFine_labelIds.png', 6)
('frankfurt_000000_013942_leftImg8bit.png', 'frankfurt_000000_013942_gtFine_labelIds.png', 6)
('frankfurt_000000_014480_leftImg8bit.png', 'frankfurt_000000_014480_gtFine_labelIds.png', 6)
('frankfurt_000000_015389_leftImg8bit.png', 'frankfurt_000000_015389_gtFine_labelIds.png', 7)
('frankfurt_000000_015676_leftImg8bit.png', 'frankfurt_000000_015676_gtFine_labelIds.png', 7)
('frankfurt_000000_016005_leftImg8bit.png', 'frankfurt_000000_016005_gtFine_labelIds.png', 7)
('frankfurt_000000_016286_leftImg8bit.png', 'frankfurt_000000_016286_gtFine_labelIds.png', 7)
('frankfurt_000000_017228_leftImg8bit.png', 'frankfurt_000000_017228_gtFine_labelIds.png', 7)
('frankfurt_000000_017476_leftImg8bit.png', 'frankfurt_000000_017476_gtFine_labelIds.png', 8)
('frankfurt_000000_018797_leftImg8bit.png', 'frankfurt_000000_018797_gtFine_labelIds.png', 8)
('frankfurt_000000_019607_leftImg8bit.png', 'frankfurt_000000_019607_gtFine_labelIds.png', 8)
('frankfurt_000000_020215_leftImg8bit.png', 'frankfurt_000000_020215_gtFine_labelIds.png', 8)
('frankfurt_000000_020321_leftImg8bit.png', 'frankfurt_000000_020321_gtFine_labelIds.png', 8)
('frankfurt_000000_020880_leftImg8bit.png', 'frankfurt_000000_020880_gtFine_labelIds.png', 9)
('frankfurt_000000_021667_leftImg8bit.png', 'frankfurt_000000_021667_gtFine_labelIds.png', 9)
('frankfurt_000000_021879_leftImg8bit.png', 'frankfurt_000000_021879_gtFine_labelIds.png', 9)
('frankfurt_000000_022254_leftImg8bit.png', 'frankfurt_000000_022254_gtFine_labelIds.png', 9)
('frankfurt_000000_022797_leftImg8bit.png', 'frankfurt_000000_022797_gtFine_labelIds.png', 9)
pixel_accuracy=0.974087220335, mean_iou=0.835573666559, iou=[ 0.95694168  0.96616225  0.77317111  0.60001612  0.88157717]
('frankfurt_000001_000538_leftImg8bit.png', 'frankfurt_000001_000538_gtFine_labelIds.png', 10)
('frankfurt_000001_001464_leftImg8bit.png', 'frankfurt_000001_001464_gtFine_labelIds.png', 10)
('frankfurt_000001_002512_leftImg8bit.png', 'frankfurt_000001_002512_gtFine_labelIds.png', 10)
('frankfurt_000001_002646_leftImg8bit.png', 'frankfurt_000001_002646_gtFine_labelIds.png', 10)
('frankfurt_000001_002759_leftImg8bit.png', 'frankfurt_000001_002759_gtFine_labelIds.png', 10)
('frankfurt_000001_003056_leftImg8bit.png', 'frankfurt_000001_003056_gtFine_labelIds.png', 11)
('frankfurt_000001_003588_leftImg8bit.png', 'frankfurt_000001_003588_gtFine_labelIds.png', 11)
('frankfurt_000001_004327_leftImg8bit.png', 'frankfurt_000001_004327_gtFine_labelIds.png', 11)
('frankfurt_000001_004736_leftImg8bit.png', 'frankfurt_000001_004736_gtFine_labelIds.png', 11)
('frankfurt_000001_004859_leftImg8bit.png', 'frankfurt_000001_004859_gtFine_labelIds.png', 11)
('frankfurt_000001_005184_leftImg8bit.png', 'frankfurt_000001_005184_gtFine_labelIds.png', 12)
('frankfurt_000001_005410_leftImg8bit.png', 'frankfurt_000001_005410_gtFine_labelIds.png', 12)
('frankfurt_000001_005703_leftImg8bit.png', 'frankfurt_000001_005703_gtFine_labelIds.png', 12)
('frankfurt_000001_005898_leftImg8bit.png', 'frankfurt_000001_005898_gtFine_labelIds.png', 12)
('frankfurt_000001_007285_leftImg8bit.png', 'frankfurt_000001_007285_gtFine_labelIds.png', 12)
('frankfurt_000001_007407_leftImg8bit.png', 'frankfurt_000001_007407_gtFine_labelIds.png', 13)
('frankfurt_000001_007622_leftImg8bit.png', 'frankfurt_000001_007622_gtFine_labelIds.png', 13)
('frankfurt_000001_007857_leftImg8bit.png', 'frankfurt_000001_007857_gtFine_labelIds.png', 13)
('frankfurt_000001_007973_leftImg8bit.png', 'frankfurt_000001_007973_gtFine_labelIds.png', 13)
('frankfurt_000001_008200_leftImg8bit.png', 'frankfurt_000001_008200_gtFine_labelIds.png', 13)
('frankfurt_000001_008688_leftImg8bit.png', 'frankfurt_000001_008688_gtFine_labelIds.png', 14)
('frankfurt_000001_009058_leftImg8bit.png', 'frankfurt_000001_009058_gtFine_labelIds.png', 14)
('frankfurt_000001_009504_leftImg8bit.png', 'frankfurt_000001_009504_gtFine_labelIds.png', 14)
('frankfurt_000001_009854_leftImg8bit.png', 'frankfurt_000001_009854_gtFine_labelIds.png', 14)
('frankfurt_000001_010156_leftImg8bit.png', 'frankfurt_000001_010156_gtFine_labelIds.png', 14)
pixel_accuracy=0.972279479265, mean_iou=0.831190916937, iou=[ 0.95383573  0.96290285  0.75695414  0.5989778   0.88328406]
('frankfurt_000001_010444_leftImg8bit.png', 'frankfurt_000001_010444_gtFine_labelIds.png', 15)
('frankfurt_000001_010600_leftImg8bit.png', 'frankfurt_000001_010600_gtFine_labelIds.png', 15)
('frankfurt_000001_010830_leftImg8bit.png', 'frankfurt_000001_010830_gtFine_labelIds.png', 15)
('frankfurt_000001_011162_leftImg8bit.png', 'frankfurt_000001_011162_gtFine_labelIds.png', 15)
('frankfurt_000001_011715_leftImg8bit.png', 'frankfurt_000001_011715_gtFine_labelIds.png', 15)
('frankfurt_000001_011835_leftImg8bit.png', 'frankfurt_000001_011835_gtFine_labelIds.png', 16)
('frankfurt_000001_012038_leftImg8bit.png', 'frankfurt_000001_012038_gtFine_labelIds.png', 16)
('frankfurt_000001_012519_leftImg8bit.png', 'frankfurt_000001_012519_gtFine_labelIds.png', 16)
('frankfurt_000001_012699_leftImg8bit.png', 'frankfurt_000001_012699_gtFine_labelIds.png', 16)
('frankfurt_000001_012738_leftImg8bit.png', 'frankfurt_000001_012738_gtFine_labelIds.png', 16)
('frankfurt_000001_012870_leftImg8bit.png', 'frankfurt_000001_012870_gtFine_labelIds.png', 17)
('frankfurt_000001_013016_leftImg8bit.png', 'frankfurt_000001_013016_gtFine_labelIds.png', 17)
('frankfurt_000001_013496_leftImg8bit.png', 'frankfurt_000001_013496_gtFine_labelIds.png', 17)
('frankfurt_000001_013710_leftImg8bit.png', 'frankfurt_000001_013710_gtFine_labelIds.png', 17)
('frankfurt_000001_014221_leftImg8bit.png', 'frankfurt_000001_014221_gtFine_labelIds.png', 17)
('frankfurt_000001_014406_leftImg8bit.png', 'frankfurt_000001_014406_gtFine_labelIds.png', 18)
('frankfurt_000001_014565_leftImg8bit.png', 'frankfurt_000001_014565_gtFine_labelIds.png', 18)
('frankfurt_000001_014741_leftImg8bit.png', 'frankfurt_000001_014741_gtFine_labelIds.png', 18)
('frankfurt_000001_015091_leftImg8bit.png', 'frankfurt_000001_015091_gtFine_labelIds.png', 18)
('frankfurt_000001_015328_leftImg8bit.png', 'frankfurt_000001_015328_gtFine_labelIds.png', 18)
('frankfurt_000001_015768_leftImg8bit.png', 'frankfurt_000001_015768_gtFine_labelIds.png', 19)
('frankfurt_000001_016029_leftImg8bit.png', 'frankfurt_000001_016029_gtFine_labelIds.png', 19)
('frankfurt_000001_016273_leftImg8bit.png', 'frankfurt_000001_016273_gtFine_labelIds.png', 19)
('frankfurt_000001_016462_leftImg8bit.png', 'frankfurt_000001_016462_gtFine_labelIds.png', 19)
('frankfurt_000001_017101_leftImg8bit.png', 'frankfurt_000001_017101_gtFine_labelIds.png', 19)
pixel_accuracy=0.968052986999, mean_iou=0.834122352618, iou=[ 0.94755897  0.95598472  0.7779777   0.61160269  0.87748767]
('frankfurt_000001_017459_leftImg8bit.png', 'frankfurt_000001_017459_gtFine_labelIds.png', 20)
('frankfurt_000001_017842_leftImg8bit.png', 'frankfurt_000001_017842_gtFine_labelIds.png', 20)
('frankfurt_000001_018113_leftImg8bit.png', 'frankfurt_000001_018113_gtFine_labelIds.png', 20)
('frankfurt_000001_019698_leftImg8bit.png', 'frankfurt_000001_019698_gtFine_labelIds.png', 20)
('frankfurt_000001_019854_leftImg8bit.png', 'frankfurt_000001_019854_gtFine_labelIds.png', 20)
('frankfurt_000001_019969_leftImg8bit.png', 'frankfurt_000001_019969_gtFine_labelIds.png', 21)
('frankfurt_000001_020046_leftImg8bit.png', 'frankfurt_000001_020046_gtFine_labelIds.png', 21)
('frankfurt_000001_020287_leftImg8bit.png', 'frankfurt_000001_020287_gtFine_labelIds.png', 21)
('frankfurt_000001_020693_leftImg8bit.png', 'frankfurt_000001_020693_gtFine_labelIds.png', 21)
('frankfurt_000001_021406_leftImg8bit.png', 'frankfurt_000001_021406_gtFine_labelIds.png', 21)
('frankfurt_000001_021825_leftImg8bit.png', 'frankfurt_000001_021825_gtFine_labelIds.png', 22)
('frankfurt_000001_023235_leftImg8bit.png', 'frankfurt_000001_023235_gtFine_labelIds.png', 22)
('frankfurt_000001_023369_leftImg8bit.png', 'frankfurt_000001_023369_gtFine_labelIds.png', 22)
('frankfurt_000001_023769_leftImg8bit.png', 'frankfurt_000001_023769_gtFine_labelIds.png', 22)
('frankfurt_000001_024927_leftImg8bit.png', 'frankfurt_000001_024927_gtFine_labelIds.png', 22)
('frankfurt_000001_025512_leftImg8bit.png', 'frankfurt_000001_025512_gtFine_labelIds.png', 23)
('frankfurt_000001_025713_leftImg8bit.png', 'frankfurt_000001_025713_gtFine_labelIds.png', 23)
('frankfurt_000001_025921_leftImg8bit.png', 'frankfurt_000001_025921_gtFine_labelIds.png', 23)
('frankfurt_000001_027325_leftImg8bit.png', 'frankfurt_000001_027325_gtFine_labelIds.png', 23)
('frankfurt_000001_028232_leftImg8bit.png', 'frankfurt_000001_028232_gtFine_labelIds.png', 23)
('frankfurt_000001_028335_leftImg8bit.png', 'frankfurt_000001_028335_gtFine_labelIds.png', 24)
('frankfurt_000001_028590_leftImg8bit.png', 'frankfurt_000001_028590_gtFine_labelIds.png', 24)
('frankfurt_000001_028854_leftImg8bit.png', 'frankfurt_000001_028854_gtFine_labelIds.png', 24)
('frankfurt_000001_029086_leftImg8bit.png', 'frankfurt_000001_029086_gtFine_labelIds.png', 24)
('frankfurt_000001_029236_leftImg8bit.png', 'frankfurt_000001_029236_gtFine_labelIds.png', 24)
pixel_accuracy=0.968415051219, mean_iou=0.832107341958, iou=[ 0.94849567  0.95594567  0.77530833  0.60325509  0.87753194]
('frankfurt_000001_029600_leftImg8bit.png', 'frankfurt_000001_029600_gtFine_labelIds.png', 25)
('frankfurt_000001_030067_leftImg8bit.png', 'frankfurt_000001_030067_gtFine_labelIds.png', 25)
('frankfurt_000001_030310_leftImg8bit.png', 'frankfurt_000001_030310_gtFine_labelIds.png', 25)
('frankfurt_000001_030669_leftImg8bit.png', 'frankfurt_000001_030669_gtFine_labelIds.png', 25)
('frankfurt_000001_031266_leftImg8bit.png', 'frankfurt_000001_031266_gtFine_labelIds.png', 25)
('frankfurt_000001_031416_leftImg8bit.png', 'frankfurt_000001_031416_gtFine_labelIds.png', 26)
('frankfurt_000001_032018_leftImg8bit.png', 'frankfurt_000001_032018_gtFine_labelIds.png', 26)
('frankfurt_000001_032556_leftImg8bit.png', 'frankfurt_000001_032556_gtFine_labelIds.png', 26)
('frankfurt_000001_032711_leftImg8bit.png', 'frankfurt_000001_032711_gtFine_labelIds.png', 26)
('frankfurt_000001_032942_leftImg8bit.png', 'frankfurt_000001_032942_gtFine_labelIds.png', 26)
('frankfurt_000001_033655_leftImg8bit.png', 'frankfurt_000001_033655_gtFine_labelIds.png', 27)
('frankfurt_000001_034047_leftImg8bit.png', 'frankfurt_000001_034047_gtFine_labelIds.png', 27)
('frankfurt_000001_034816_leftImg8bit.png', 'frankfurt_000001_034816_gtFine_labelIds.png', 27)
('frankfurt_000001_035144_leftImg8bit.png', 'frankfurt_000001_035144_gtFine_labelIds.png', 27)
('frankfurt_000001_035864_leftImg8bit.png', 'frankfurt_000001_035864_gtFine_labelIds.png', 27)
('frankfurt_000001_037705_leftImg8bit.png', 'frankfurt_000001_037705_gtFine_labelIds.png', 28)
('frankfurt_000001_038245_leftImg8bit.png', 'frankfurt_000001_038245_gtFine_labelIds.png', 28)
('frankfurt_000001_038418_leftImg8bit.png', 'frankfurt_000001_038418_gtFine_labelIds.png', 28)
('frankfurt_000001_038645_leftImg8bit.png', 'frankfurt_000001_038645_gtFine_labelIds.png', 28)
('frankfurt_000001_038844_leftImg8bit.png', 'frankfurt_000001_038844_gtFine_labelIds.png', 28)
('frankfurt_000001_039895_leftImg8bit.png', 'frankfurt_000001_039895_gtFine_labelIds.png', 29)
('frankfurt_000001_040575_leftImg8bit.png', 'frankfurt_000001_040575_gtFine_labelIds.png', 29)
('frankfurt_000001_040732_leftImg8bit.png', 'frankfurt_000001_040732_gtFine_labelIds.png', 29)
('frankfurt_000001_041074_leftImg8bit.png', 'frankfurt_000001_041074_gtFine_labelIds.png', 29)
('frankfurt_000001_041354_leftImg8bit.png', 'frankfurt_000001_041354_gtFine_labelIds.png', 29)
pixel_accuracy=0.968699133756, mean_iou=0.831438460416, iou=[ 0.94871221  0.95732821  0.76329873  0.60415327  0.88369987]
('frankfurt_000001_041517_leftImg8bit.png', 'frankfurt_000001_041517_gtFine_labelIds.png', 30)
('frankfurt_000001_041664_leftImg8bit.png', 'frankfurt_000001_041664_gtFine_labelIds.png', 30)
('frankfurt_000001_042098_leftImg8bit.png', 'frankfurt_000001_042098_gtFine_labelIds.png', 30)
('frankfurt_000001_042384_leftImg8bit.png', 'frankfurt_000001_042384_gtFine_labelIds.png', 30)
('frankfurt_000001_042733_leftImg8bit.png', 'frankfurt_000001_042733_gtFine_labelIds.png', 30)
('frankfurt_000001_043395_leftImg8bit.png', 'frankfurt_000001_043395_gtFine_labelIds.png', 31)
('frankfurt_000001_043564_leftImg8bit.png', 'frankfurt_000001_043564_gtFine_labelIds.png', 31)
('frankfurt_000001_044227_leftImg8bit.png', 'frankfurt_000001_044227_gtFine_labelIds.png', 31)
('frankfurt_000001_044413_leftImg8bit.png', 'frankfurt_000001_044413_gtFine_labelIds.png', 31)
('frankfurt_000001_044525_leftImg8bit.png', 'frankfurt_000001_044525_gtFine_labelIds.png', 31)
('frankfurt_000001_044658_leftImg8bit.png', 'frankfurt_000001_044658_gtFine_labelIds.png', 32)
('frankfurt_000001_044787_leftImg8bit.png', 'frankfurt_000001_044787_gtFine_labelIds.png', 32)
('frankfurt_000001_046126_leftImg8bit.png', 'frankfurt_000001_046126_gtFine_labelIds.png', 32)
('frankfurt_000001_046272_leftImg8bit.png', 'frankfurt_000001_046272_gtFine_labelIds.png', 32)
('frankfurt_000001_046504_leftImg8bit.png', 'frankfurt_000001_046504_gtFine_labelIds.png', 32)
('frankfurt_000001_046779_leftImg8bit.png', 'frankfurt_000001_046779_gtFine_labelIds.png', 33)
('frankfurt_000001_047178_leftImg8bit.png', 'frankfurt_000001_047178_gtFine_labelIds.png', 33)
('frankfurt_000001_047552_leftImg8bit.png', 'frankfurt_000001_047552_gtFine_labelIds.png', 33)
('frankfurt_000001_048196_leftImg8bit.png', 'frankfurt_000001_048196_gtFine_labelIds.png', 33)
('frankfurt_000001_048355_leftImg8bit.png', 'frankfurt_000001_048355_gtFine_labelIds.png', 33)
('frankfurt_000001_048654_leftImg8bit.png', 'frankfurt_000001_048654_gtFine_labelIds.png', 34)
('frankfurt_000001_049078_leftImg8bit.png', 'frankfurt_000001_049078_gtFine_labelIds.png', 34)
('frankfurt_000001_049209_leftImg8bit.png', 'frankfurt_000001_049209_gtFine_labelIds.png', 34)
('frankfurt_000001_049298_leftImg8bit.png', 'frankfurt_000001_049298_gtFine_labelIds.png', 34)
('frankfurt_000001_049698_leftImg8bit.png', 'frankfurt_000001_049698_gtFine_labelIds.png', 34)
pixel_accuracy=0.970359993272, mean_iou=0.833659281884, iou=[ 0.95158456  0.95964065  0.76359984  0.60063193  0.89283943]
('frankfurt_000001_049770_leftImg8bit.png', 'frankfurt_000001_049770_gtFine_labelIds.png', 35)
('frankfurt_000001_050149_leftImg8bit.png', 'frankfurt_000001_050149_gtFine_labelIds.png', 35)
('frankfurt_000001_050686_leftImg8bit.png', 'frankfurt_000001_050686_gtFine_labelIds.png', 35)
('frankfurt_000001_051516_leftImg8bit.png', 'frankfurt_000001_051516_gtFine_labelIds.png', 35)
('frankfurt_000001_051737_leftImg8bit.png', 'frankfurt_000001_051737_gtFine_labelIds.png', 35)
('frankfurt_000001_051807_leftImg8bit.png', 'frankfurt_000001_051807_gtFine_labelIds.png', 36)
('frankfurt_000001_052120_leftImg8bit.png', 'frankfurt_000001_052120_gtFine_labelIds.png', 36)
('frankfurt_000001_052594_leftImg8bit.png', 'frankfurt_000001_052594_gtFine_labelIds.png', 36)
('frankfurt_000001_053102_leftImg8bit.png', 'frankfurt_000001_053102_gtFine_labelIds.png', 36)
('frankfurt_000001_054077_leftImg8bit.png', 'frankfurt_000001_054077_gtFine_labelIds.png', 36)
('frankfurt_000001_054219_leftImg8bit.png', 'frankfurt_000001_054219_gtFine_labelIds.png', 37)
('frankfurt_000001_054415_leftImg8bit.png', 'frankfurt_000001_054415_gtFine_labelIds.png', 37)
('frankfurt_000001_054640_leftImg8bit.png', 'frankfurt_000001_054640_gtFine_labelIds.png', 37)
('frankfurt_000001_054884_leftImg8bit.png', 'frankfurt_000001_054884_gtFine_labelIds.png', 37)
('frankfurt_000001_055062_leftImg8bit.png', 'frankfurt_000001_055062_gtFine_labelIds.png', 37)
('frankfurt_000001_055172_leftImg8bit.png', 'frankfurt_000001_055172_gtFine_labelIds.png', 38)
('frankfurt_000001_055306_leftImg8bit.png', 'frankfurt_000001_055306_gtFine_labelIds.png', 38)
('frankfurt_000001_055387_leftImg8bit.png', 'frankfurt_000001_055387_gtFine_labelIds.png', 38)
('frankfurt_000001_055538_leftImg8bit.png', 'frankfurt_000001_055538_gtFine_labelIds.png', 38)
('frankfurt_000001_055603_leftImg8bit.png', 'frankfurt_000001_055603_gtFine_labelIds.png', 38)
('frankfurt_000001_055709_leftImg8bit.png', 'frankfurt_000001_055709_gtFine_labelIds.png', 39)
('frankfurt_000001_056580_leftImg8bit.png', 'frankfurt_000001_056580_gtFine_labelIds.png', 39)
('frankfurt_000001_057181_leftImg8bit.png', 'frankfurt_000001_057181_gtFine_labelIds.png', 39)
('frankfurt_000001_057478_leftImg8bit.png', 'frankfurt_000001_057478_gtFine_labelIds.png', 39)
('frankfurt_000001_057954_leftImg8bit.png', 'frankfurt_000001_057954_gtFine_labelIds.png', 39)
pixel_accuracy=0.970072399923, mean_iou=0.836577431454, iou=[ 0.95109814  0.96016518  0.77522614  0.60331524  0.89308245]
('frankfurt_000001_058057_leftImg8bit.png', 'frankfurt_000001_058057_gtFine_labelIds.png', 40)
('frankfurt_000001_058176_leftImg8bit.png', 'frankfurt_000001_058176_gtFine_labelIds.png', 40)
('frankfurt_000001_058504_leftImg8bit.png', 'frankfurt_000001_058504_gtFine_labelIds.png', 40)
('frankfurt_000001_058914_leftImg8bit.png', 'frankfurt_000001_058914_gtFine_labelIds.png', 40)
('frankfurt_000001_059119_leftImg8bit.png', 'frankfurt_000001_059119_gtFine_labelIds.png', 40)
('frankfurt_000001_059642_leftImg8bit.png', 'frankfurt_000001_059642_gtFine_labelIds.png', 41)
('frankfurt_000001_059789_leftImg8bit.png', 'frankfurt_000001_059789_gtFine_labelIds.png', 41)
('frankfurt_000001_060135_leftImg8bit.png', 'frankfurt_000001_060135_gtFine_labelIds.png', 41)
('frankfurt_000001_060422_leftImg8bit.png', 'frankfurt_000001_060422_gtFine_labelIds.png', 41)
('frankfurt_000001_060545_leftImg8bit.png', 'frankfurt_000001_060545_gtFine_labelIds.png', 41)
('frankfurt_000001_060906_leftImg8bit.png', 'frankfurt_000001_060906_gtFine_labelIds.png', 42)
('frankfurt_000001_061682_leftImg8bit.png', 'frankfurt_000001_061682_gtFine_labelIds.png', 42)
('frankfurt_000001_061763_leftImg8bit.png', 'frankfurt_000001_061763_gtFine_labelIds.png', 42)
('frankfurt_000001_062016_leftImg8bit.png', 'frankfurt_000001_062016_gtFine_labelIds.png', 42)
('frankfurt_000001_062250_leftImg8bit.png', 'frankfurt_000001_062250_gtFine_labelIds.png', 42)
('frankfurt_000001_062396_leftImg8bit.png', 'frankfurt_000001_062396_gtFine_labelIds.png', 43)
('frankfurt_000001_062509_leftImg8bit.png', 'frankfurt_000001_062509_gtFine_labelIds.png', 43)
('frankfurt_000001_062653_leftImg8bit.png', 'frankfurt_000001_062653_gtFine_labelIds.png', 43)
('frankfurt_000001_062793_leftImg8bit.png', 'frankfurt_000001_062793_gtFine_labelIds.png', 43)
('frankfurt_000001_063045_leftImg8bit.png', 'frankfurt_000001_063045_gtFine_labelIds.png', 43)
('frankfurt_000001_064130_leftImg8bit.png', 'frankfurt_000001_064130_gtFine_labelIds.png', 44)
('frankfurt_000001_064305_leftImg8bit.png', 'frankfurt_000001_064305_gtFine_labelIds.png', 44)
('frankfurt_000001_064651_leftImg8bit.png', 'frankfurt_000001_064651_gtFine_labelIds.png', 44)
('frankfurt_000001_064798_leftImg8bit.png', 'frankfurt_000001_064798_gtFine_labelIds.png', 44)
('frankfurt_000001_064925_leftImg8bit.png', 'frankfurt_000001_064925_gtFine_labelIds.png', 44)
pixel_accuracy=0.970829195916, mean_iou=0.836909934376, iou=[ 0.95236795  0.96181186  0.77214726  0.60211117  0.89611143]
('frankfurt_000001_065160_leftImg8bit.png', 'frankfurt_000001_065160_gtFine_labelIds.png', 45)
('frankfurt_000001_065617_leftImg8bit.png', 'frankfurt_000001_065617_gtFine_labelIds.png', 45)
('frankfurt_000001_065850_leftImg8bit.png', 'frankfurt_000001_065850_gtFine_labelIds.png', 45)
('frankfurt_000001_066092_leftImg8bit.png', 'frankfurt_000001_066092_gtFine_labelIds.png', 45)
('frankfurt_000001_066438_leftImg8bit.png', 'frankfurt_000001_066438_gtFine_labelIds.png', 45)
('frankfurt_000001_066574_leftImg8bit.png', 'frankfurt_000001_066574_gtFine_labelIds.png', 46)
('frankfurt_000001_066832_leftImg8bit.png', 'frankfurt_000001_066832_gtFine_labelIds.png', 46)
('frankfurt_000001_067092_leftImg8bit.png', 'frankfurt_000001_067092_gtFine_labelIds.png', 46)
('frankfurt_000001_067178_leftImg8bit.png', 'frankfurt_000001_067178_gtFine_labelIds.png', 46)
('frankfurt_000001_067295_leftImg8bit.png', 'frankfurt_000001_067295_gtFine_labelIds.png', 46)
('frankfurt_000001_067474_leftImg8bit.png', 'frankfurt_000001_067474_gtFine_labelIds.png', 47)
('frankfurt_000001_067735_leftImg8bit.png', 'frankfurt_000001_067735_gtFine_labelIds.png', 47)
('frankfurt_000001_068063_leftImg8bit.png', 'frankfurt_000001_068063_gtFine_labelIds.png', 47)
('frankfurt_000001_068208_leftImg8bit.png', 'frankfurt_000001_068208_gtFine_labelIds.png', 47)
('frankfurt_000001_068682_leftImg8bit.png', 'frankfurt_000001_068682_gtFine_labelIds.png', 47)
('frankfurt_000001_068772_leftImg8bit.png', 'frankfurt_000001_068772_gtFine_labelIds.png', 48)
('frankfurt_000001_069633_leftImg8bit.png', 'frankfurt_000001_069633_gtFine_labelIds.png', 48)
('frankfurt_000001_070099_leftImg8bit.png', 'frankfurt_000001_070099_gtFine_labelIds.png', 48)
('frankfurt_000001_071288_leftImg8bit.png', 'frankfurt_000001_071288_gtFine_labelIds.png', 48)
('frankfurt_000001_071781_leftImg8bit.png', 'frankfurt_000001_071781_gtFine_labelIds.png', 48)
('frankfurt_000001_072155_leftImg8bit.png', 'frankfurt_000001_072155_gtFine_labelIds.png', 49)
('frankfurt_000001_072295_leftImg8bit.png', 'frankfurt_000001_072295_gtFine_labelIds.png', 49)
('frankfurt_000001_073088_leftImg8bit.png', 'frankfurt_000001_073088_gtFine_labelIds.png', 49)
('frankfurt_000001_073243_leftImg8bit.png', 'frankfurt_000001_073243_gtFine_labelIds.png', 49)
('frankfurt_000001_073464_leftImg8bit.png', 'frankfurt_000001_073464_gtFine_labelIds.png', 49)
pixel_accuracy=0.970090030393, mean_iou=0.834795998338, iou=[ 0.95095104  0.96003117  0.76996983  0.59613745  0.8968905 ]
('frankfurt_000001_073911_leftImg8bit.png', 'frankfurt_000001_073911_gtFine_labelIds.png', 50)
('frankfurt_000001_075296_leftImg8bit.png', 'frankfurt_000001_075296_gtFine_labelIds.png', 50)
('frankfurt_000001_075984_leftImg8bit.png', 'frankfurt_000001_075984_gtFine_labelIds.png', 50)
('frankfurt_000001_076502_leftImg8bit.png', 'frankfurt_000001_076502_gtFine_labelIds.png', 50)
('frankfurt_000001_077092_leftImg8bit.png', 'frankfurt_000001_077092_gtFine_labelIds.png', 50)
('frankfurt_000001_077233_leftImg8bit.png', 'frankfurt_000001_077233_gtFine_labelIds.png', 51)
('frankfurt_000001_077434_leftImg8bit.png', 'frankfurt_000001_077434_gtFine_labelIds.png', 51)
('frankfurt_000001_078803_leftImg8bit.png', 'frankfurt_000001_078803_gtFine_labelIds.png', 51)
('frankfurt_000001_079206_leftImg8bit.png', 'frankfurt_000001_079206_gtFine_labelIds.png', 51)
('frankfurt_000001_080091_leftImg8bit.png', 'frankfurt_000001_080091_gtFine_labelIds.png', 51)
('frankfurt_000001_080391_leftImg8bit.png', 'frankfurt_000001_080391_gtFine_labelIds.png', 52)
('frankfurt_000001_080830_leftImg8bit.png', 'frankfurt_000001_080830_gtFine_labelIds.png', 52)
('frankfurt_000001_082087_leftImg8bit.png', 'frankfurt_000001_082087_gtFine_labelIds.png', 52)
('frankfurt_000001_082466_leftImg8bit.png', 'frankfurt_000001_082466_gtFine_labelIds.png', 52)
('frankfurt_000001_083029_leftImg8bit.png', 'frankfurt_000001_083029_gtFine_labelIds.png', 52)
('frankfurt_000001_083199_leftImg8bit.png', 'frankfurt_000001_083199_gtFine_labelIds.png', 53)
('frankfurt_000001_083852_leftImg8bit.png', 'frankfurt_000001_083852_gtFine_labelIds.png', 53)
('lindau_000000_000019_leftImg8bit.png', 'lindau_000000_000019_gtFine_labelIds.png', 53)
('lindau_000001_000019_leftImg8bit.png', 'lindau_000001_000019_gtFine_labelIds.png', 53)
('lindau_000002_000019_leftImg8bit.png', 'lindau_000002_000019_gtFine_labelIds.png', 53)
('lindau_000003_000019_leftImg8bit.png', 'lindau_000003_000019_gtFine_labelIds.png', 54)
('lindau_000004_000019_leftImg8bit.png', 'lindau_000004_000019_gtFine_labelIds.png', 54)
('lindau_000005_000019_leftImg8bit.png', 'lindau_000005_000019_gtFine_labelIds.png', 54)
('lindau_000006_000019_leftImg8bit.png', 'lindau_000006_000019_gtFine_labelIds.png', 54)
('lindau_000007_000019_leftImg8bit.png', 'lindau_000007_000019_gtFine_labelIds.png', 54)
pixel_accuracy=0.970688072964, mean_iou=0.83419376851, iou=[ 0.9519074   0.96142499  0.76600342  0.59530888  0.89632416]
('lindau_000008_000019_leftImg8bit.png', 'lindau_000008_000019_gtFine_labelIds.png', 55)
('lindau_000009_000019_leftImg8bit.png', 'lindau_000009_000019_gtFine_labelIds.png', 55)
('lindau_000010_000019_leftImg8bit.png', 'lindau_000010_000019_gtFine_labelIds.png', 55)
('lindau_000011_000019_leftImg8bit.png', 'lindau_000011_000019_gtFine_labelIds.png', 55)
('lindau_000012_000019_leftImg8bit.png', 'lindau_000012_000019_gtFine_labelIds.png', 55)
('lindau_000013_000019_leftImg8bit.png', 'lindau_000013_000019_gtFine_labelIds.png', 56)
('lindau_000014_000019_leftImg8bit.png', 'lindau_000014_000019_gtFine_labelIds.png', 56)
('lindau_000015_000019_leftImg8bit.png', 'lindau_000015_000019_gtFine_labelIds.png', 56)
('lindau_000016_000019_leftImg8bit.png', 'lindau_000016_000019_gtFine_labelIds.png', 56)
('lindau_000017_000019_leftImg8bit.png', 'lindau_000017_000019_gtFine_labelIds.png', 56)
('lindau_000018_000019_leftImg8bit.png', 'lindau_000018_000019_gtFine_labelIds.png', 57)
('lindau_000019_000019_leftImg8bit.png', 'lindau_000019_000019_gtFine_labelIds.png', 57)
('lindau_000020_000019_leftImg8bit.png', 'lindau_000020_000019_gtFine_labelIds.png', 57)
('lindau_000021_000019_leftImg8bit.png', 'lindau_000021_000019_gtFine_labelIds.png', 57)
('lindau_000022_000019_leftImg8bit.png', 'lindau_000022_000019_gtFine_labelIds.png', 57)
('lindau_000023_000019_leftImg8bit.png', 'lindau_000023_000019_gtFine_labelIds.png', 58)
('lindau_000024_000019_leftImg8bit.png', 'lindau_000024_000019_gtFine_labelIds.png', 58)
('lindau_000025_000019_leftImg8bit.png', 'lindau_000025_000019_gtFine_labelIds.png', 58)
('lindau_000026_000019_leftImg8bit.png', 'lindau_000026_000019_gtFine_labelIds.png', 58)
('lindau_000027_000019_leftImg8bit.png', 'lindau_000027_000019_gtFine_labelIds.png', 58)
('lindau_000028_000019_leftImg8bit.png', 'lindau_000028_000019_gtFine_labelIds.png', 59)
('lindau_000029_000019_leftImg8bit.png', 'lindau_000029_000019_gtFine_labelIds.png', 59)
('lindau_000030_000019_leftImg8bit.png', 'lindau_000030_000019_gtFine_labelIds.png', 59)
('lindau_000031_000019_leftImg8bit.png', 'lindau_000031_000019_gtFine_labelIds.png', 59)
('lindau_000032_000019_leftImg8bit.png', 'lindau_000032_000019_gtFine_labelIds.png', 59)
pixel_accuracy=0.966411284777, mean_iou=0.829865895596, iou=[ 0.94531399  0.94781238  0.76353566  0.59883879  0.89382866]
('lindau_000033_000019_leftImg8bit.png', 'lindau_000033_000019_gtFine_labelIds.png', 60)
('lindau_000034_000019_leftImg8bit.png', 'lindau_000034_000019_gtFine_labelIds.png', 60)
('lindau_000035_000019_leftImg8bit.png', 'lindau_000035_000019_gtFine_labelIds.png', 60)
('lindau_000036_000019_leftImg8bit.png', 'lindau_000036_000019_gtFine_labelIds.png', 60)
('lindau_000037_000019_leftImg8bit.png', 'lindau_000037_000019_gtFine_labelIds.png', 60)
('lindau_000038_000019_leftImg8bit.png', 'lindau_000038_000019_gtFine_labelIds.png', 61)
('lindau_000039_000019_leftImg8bit.png', 'lindau_000039_000019_gtFine_labelIds.png', 61)
('lindau_000040_000019_leftImg8bit.png', 'lindau_000040_000019_gtFine_labelIds.png', 61)
('lindau_000041_000019_leftImg8bit.png', 'lindau_000041_000019_gtFine_labelIds.png', 61)
('lindau_000042_000019_leftImg8bit.png', 'lindau_000042_000019_gtFine_labelIds.png', 61)
('lindau_000043_000019_leftImg8bit.png', 'lindau_000043_000019_gtFine_labelIds.png', 62)
('lindau_000044_000019_leftImg8bit.png', 'lindau_000044_000019_gtFine_labelIds.png', 62)
('lindau_000045_000019_leftImg8bit.png', 'lindau_000045_000019_gtFine_labelIds.png', 62)
('lindau_000046_000019_leftImg8bit.png', 'lindau_000046_000019_gtFine_labelIds.png', 62)
('lindau_000047_000019_leftImg8bit.png', 'lindau_000047_000019_gtFine_labelIds.png', 62)
('lindau_000048_000019_leftImg8bit.png', 'lindau_000048_000019_gtFine_labelIds.png', 63)
('lindau_000049_000019_leftImg8bit.png', 'lindau_000049_000019_gtFine_labelIds.png', 63)
('lindau_000050_000019_leftImg8bit.png', 'lindau_000050_000019_gtFine_labelIds.png', 63)
('lindau_000051_000019_leftImg8bit.png', 'lindau_000051_000019_gtFine_labelIds.png', 63)
('lindau_000052_000019_leftImg8bit.png', 'lindau_000052_000019_gtFine_labelIds.png', 63)
('lindau_000053_000019_leftImg8bit.png', 'lindau_000053_000019_gtFine_labelIds.png', 64)
('lindau_000054_000019_leftImg8bit.png', 'lindau_000054_000019_gtFine_labelIds.png', 64)
('lindau_000055_000019_leftImg8bit.png', 'lindau_000055_000019_gtFine_labelIds.png', 64)
('lindau_000056_000019_leftImg8bit.png', 'lindau_000056_000019_gtFine_labelIds.png', 64)
('lindau_000057_000019_leftImg8bit.png', 'lindau_000057_000019_gtFine_labelIds.png', 64)
pixel_accuracy=0.956796906605, mean_iou=0.820687013607, iou=[ 0.93037939  0.91851504  0.76018755  0.59997672  0.89437636]
('lindau_000058_000019_leftImg8bit.png', 'lindau_000058_000019_gtFine_labelIds.png', 65)
('munster_000000_000019_leftImg8bit.png', 'munster_000000_000019_gtFine_labelIds.png', 65)
('munster_000001_000019_leftImg8bit.png', 'munster_000001_000019_gtFine_labelIds.png', 65)
('munster_000002_000019_leftImg8bit.png', 'munster_000002_000019_gtFine_labelIds.png', 65)
('munster_000003_000019_leftImg8bit.png', 'munster_000003_000019_gtFine_labelIds.png', 65)
('munster_000004_000019_leftImg8bit.png', 'munster_000004_000019_gtFine_labelIds.png', 66)
('munster_000005_000019_leftImg8bit.png', 'munster_000005_000019_gtFine_labelIds.png', 66)
('munster_000006_000019_leftImg8bit.png', 'munster_000006_000019_gtFine_labelIds.png', 66)
('munster_000007_000019_leftImg8bit.png', 'munster_000007_000019_gtFine_labelIds.png', 66)
('munster_000008_000019_leftImg8bit.png', 'munster_000008_000019_gtFine_labelIds.png', 66)
('munster_000009_000019_leftImg8bit.png', 'munster_000009_000019_gtFine_labelIds.png', 67)
('munster_000010_000019_leftImg8bit.png', 'munster_000010_000019_gtFine_labelIds.png', 67)
('munster_000011_000019_leftImg8bit.png', 'munster_000011_000019_gtFine_labelIds.png', 67)
('munster_000012_000019_leftImg8bit.png', 'munster_000012_000019_gtFine_labelIds.png', 67)
('munster_000013_000019_leftImg8bit.png', 'munster_000013_000019_gtFine_labelIds.png', 67)
('munster_000014_000019_leftImg8bit.png', 'munster_000014_000019_gtFine_labelIds.png', 68)
('munster_000015_000019_leftImg8bit.png', 'munster_000015_000019_gtFine_labelIds.png', 68)
('munster_000016_000019_leftImg8bit.png', 'munster_000016_000019_gtFine_labelIds.png', 68)
('munster_000017_000019_leftImg8bit.png', 'munster_000017_000019_gtFine_labelIds.png', 68)
('munster_000018_000019_leftImg8bit.png', 'munster_000018_000019_gtFine_labelIds.png', 68)
('munster_000019_000019_leftImg8bit.png', 'munster_000019_000019_gtFine_labelIds.png', 69)
('munster_000020_000019_leftImg8bit.png', 'munster_000020_000019_gtFine_labelIds.png', 69)
('munster_000021_000019_leftImg8bit.png', 'munster_000021_000019_gtFine_labelIds.png', 69)
('munster_000022_000019_leftImg8bit.png', 'munster_000022_000019_gtFine_labelIds.png', 69)
('munster_000023_000019_leftImg8bit.png', 'munster_000023_000019_gtFine_labelIds.png', 69)
pixel_accuracy=0.958541529725, mean_iou=0.823647375804, iou=[ 0.9330663   0.92254256  0.75990567  0.60525262  0.89746974]
('munster_000024_000019_leftImg8bit.png', 'munster_000024_000019_gtFine_labelIds.png', 70)
('munster_000025_000019_leftImg8bit.png', 'munster_000025_000019_gtFine_labelIds.png', 70)
('munster_000026_000019_leftImg8bit.png', 'munster_000026_000019_gtFine_labelIds.png', 70)
('munster_000027_000019_leftImg8bit.png', 'munster_000027_000019_gtFine_labelIds.png', 70)
('munster_000028_000019_leftImg8bit.png', 'munster_000028_000019_gtFine_labelIds.png', 70)
('munster_000029_000019_leftImg8bit.png', 'munster_000029_000019_gtFine_labelIds.png', 71)
('munster_000030_000019_leftImg8bit.png', 'munster_000030_000019_gtFine_labelIds.png', 71)
('munster_000031_000019_leftImg8bit.png', 'munster_000031_000019_gtFine_labelIds.png', 71)
('munster_000032_000019_leftImg8bit.png', 'munster_000032_000019_gtFine_labelIds.png', 71)
('munster_000033_000019_leftImg8bit.png', 'munster_000033_000019_gtFine_labelIds.png', 71)
('munster_000034_000019_leftImg8bit.png', 'munster_000034_000019_gtFine_labelIds.png', 72)
('munster_000035_000019_leftImg8bit.png', 'munster_000035_000019_gtFine_labelIds.png', 72)
('munster_000036_000019_leftImg8bit.png', 'munster_000036_000019_gtFine_labelIds.png', 72)
('munster_000037_000019_leftImg8bit.png', 'munster_000037_000019_gtFine_labelIds.png', 72)
('munster_000038_000019_leftImg8bit.png', 'munster_000038_000019_gtFine_labelIds.png', 72)
('munster_000039_000019_leftImg8bit.png', 'munster_000039_000019_gtFine_labelIds.png', 73)
('munster_000040_000019_leftImg8bit.png', 'munster_000040_000019_gtFine_labelIds.png', 73)
('munster_000041_000019_leftImg8bit.png', 'munster_000041_000019_gtFine_labelIds.png', 73)
('munster_000042_000019_leftImg8bit.png', 'munster_000042_000019_gtFine_labelIds.png', 73)
('munster_000043_000019_leftImg8bit.png', 'munster_000043_000019_gtFine_labelIds.png', 73)
('munster_000044_000019_leftImg8bit.png', 'munster_000044_000019_gtFine_labelIds.png', 74)
('munster_000045_000019_leftImg8bit.png', 'munster_000045_000019_gtFine_labelIds.png', 74)
('munster_000046_000019_leftImg8bit.png', 'munster_000046_000019_gtFine_labelIds.png', 74)
('munster_000047_000019_leftImg8bit.png', 'munster_000047_000019_gtFine_labelIds.png', 74)
('munster_000048_000019_leftImg8bit.png', 'munster_000048_000019_gtFine_labelIds.png', 74)
pixel_accuracy=0.959750649819, mean_iou=0.827369767594, iou=[ 0.93499136  0.92570648  0.76819407  0.61111176  0.89684516]
('munster_000049_000019_leftImg8bit.png', 'munster_000049_000019_gtFine_labelIds.png', 75)
('munster_000050_000019_leftImg8bit.png', 'munster_000050_000019_gtFine_labelIds.png', 75)
('munster_000051_000019_leftImg8bit.png', 'munster_000051_000019_gtFine_labelIds.png', 75)
('munster_000052_000019_leftImg8bit.png', 'munster_000052_000019_gtFine_labelIds.png', 75)
('munster_000053_000019_leftImg8bit.png', 'munster_000053_000019_gtFine_labelIds.png', 75)
('munster_000054_000019_leftImg8bit.png', 'munster_000054_000019_gtFine_labelIds.png', 76)
('munster_000055_000019_leftImg8bit.png', 'munster_000055_000019_gtFine_labelIds.png', 76)
('munster_000056_000019_leftImg8bit.png', 'munster_000056_000019_gtFine_labelIds.png', 76)
('munster_000057_000019_leftImg8bit.png', 'munster_000057_000019_gtFine_labelIds.png', 76)
('munster_000058_000019_leftImg8bit.png', 'munster_000058_000019_gtFine_labelIds.png', 76)
('munster_000059_000019_leftImg8bit.png', 'munster_000059_000019_gtFine_labelIds.png', 77)
('munster_000060_000019_leftImg8bit.png', 'munster_000060_000019_gtFine_labelIds.png', 77)
('munster_000061_000019_leftImg8bit.png', 'munster_000061_000019_gtFine_labelIds.png', 77)
('munster_000062_000019_leftImg8bit.png', 'munster_000062_000019_gtFine_labelIds.png', 77)
('munster_000063_000019_leftImg8bit.png', 'munster_000063_000019_gtFine_labelIds.png', 77)
('munster_000064_000019_leftImg8bit.png', 'munster_000064_000019_gtFine_labelIds.png', 78)
('munster_000065_000019_leftImg8bit.png', 'munster_000065_000019_gtFine_labelIds.png', 78)
('munster_000066_000019_leftImg8bit.png', 'munster_000066_000019_gtFine_labelIds.png', 78)
('munster_000067_000019_leftImg8bit.png', 'munster_000067_000019_gtFine_labelIds.png', 78)
('munster_000068_000019_leftImg8bit.png', 'munster_000068_000019_gtFine_labelIds.png', 78)
('munster_000069_000019_leftImg8bit.png', 'munster_000069_000019_gtFine_labelIds.png', 79)
('munster_000070_000019_leftImg8bit.png', 'munster_000070_000019_gtFine_labelIds.png', 79)
('munster_000071_000019_leftImg8bit.png', 'munster_000071_000019_gtFine_labelIds.png', 79)
('munster_000072_000019_leftImg8bit.png', 'munster_000072_000019_gtFine_labelIds.png', 79)
('munster_000073_000019_leftImg8bit.png', 'munster_000073_000019_gtFine_labelIds.png', 79)
pixel_accuracy=0.960953154021, mean_iou=0.829570079657, iou=[ 0.93684065  0.92900417  0.76911842  0.61402358  0.89886357]
('munster_000074_000019_leftImg8bit.png', 'munster_000074_000019_gtFine_labelIds.png', 80)
('munster_000075_000019_leftImg8bit.png', 'munster_000075_000019_gtFine_labelIds.png', 80)
('munster_000076_000019_leftImg8bit.png', 'munster_000076_000019_gtFine_labelIds.png', 80)
('munster_000077_000019_leftImg8bit.png', 'munster_000077_000019_gtFine_labelIds.png', 80)
('munster_000078_000019_leftImg8bit.png', 'munster_000078_000019_gtFine_labelIds.png', 80)
('munster_000079_000019_leftImg8bit.png', 'munster_000079_000019_gtFine_labelIds.png', 81)
('munster_000080_000019_leftImg8bit.png', 'munster_000080_000019_gtFine_labelIds.png', 81)
('munster_000081_000019_leftImg8bit.png', 'munster_000081_000019_gtFine_labelIds.png', 81)
('munster_000082_000019_leftImg8bit.png', 'munster_000082_000019_gtFine_labelIds.png', 81)
('munster_000083_000019_leftImg8bit.png', 'munster_000083_000019_gtFine_labelIds.png', 81)
('munster_000084_000019_leftImg8bit.png', 'munster_000084_000019_gtFine_labelIds.png', 82)
('munster_000085_000019_leftImg8bit.png', 'munster_000085_000019_gtFine_labelIds.png', 82)
('munster_000086_000019_leftImg8bit.png', 'munster_000086_000019_gtFine_labelIds.png', 82)
('munster_000087_000019_leftImg8bit.png', 'munster_000087_000019_gtFine_labelIds.png', 82)
('munster_000088_000019_leftImg8bit.png', 'munster_000088_000019_gtFine_labelIds.png', 82)
('munster_000089_000019_leftImg8bit.png', 'munster_000089_000019_gtFine_labelIds.png', 83)
('munster_000090_000019_leftImg8bit.png', 'munster_000090_000019_gtFine_labelIds.png', 83)
('munster_000091_000019_leftImg8bit.png', 'munster_000091_000019_gtFine_labelIds.png', 83)
('munster_000092_000019_leftImg8bit.png', 'munster_000092_000019_gtFine_labelIds.png', 83)
('munster_000093_000019_leftImg8bit.png', 'munster_000093_000019_gtFine_labelIds.png', 83)
('munster_000094_000019_leftImg8bit.png', 'munster_000094_000019_gtFine_labelIds.png', 84)
('munster_000095_000019_leftImg8bit.png', 'munster_000095_000019_gtFine_labelIds.png', 84)
('munster_000096_000019_leftImg8bit.png', 'munster_000096_000019_gtFine_labelIds.png', 84)
('munster_000097_000019_leftImg8bit.png', 'munster_000097_000019_gtFine_labelIds.png', 84)
('munster_000098_000019_leftImg8bit.png', 'munster_000098_000019_gtFine_labelIds.png', 84)
pixel_accuracy=0.96223073922, mean_iou=0.831926170326, iou=[ 0.93875248  0.93172754  0.76830677  0.61649376  0.9043503 ]
('munster_000099_000019_leftImg8bit.png', 'munster_000099_000019_gtFine_labelIds.png', 85)
('munster_000100_000019_leftImg8bit.png', 'munster_000100_000019_gtFine_labelIds.png', 85)
('munster_000101_000019_leftImg8bit.png', 'munster_000101_000019_gtFine_labelIds.png', 85)
('munster_000102_000019_leftImg8bit.png', 'munster_000102_000019_gtFine_labelIds.png', 85)
('munster_000103_000019_leftImg8bit.png', 'munster_000103_000019_gtFine_labelIds.png', 85)
('munster_000104_000019_leftImg8bit.png', 'munster_000104_000019_gtFine_labelIds.png', 86)
('munster_000105_000019_leftImg8bit.png', 'munster_000105_000019_gtFine_labelIds.png', 86)
('munster_000106_000019_leftImg8bit.png', 'munster_000106_000019_gtFine_labelIds.png', 86)
('munster_000107_000019_leftImg8bit.png', 'munster_000107_000019_gtFine_labelIds.png', 86)
('munster_000108_000019_leftImg8bit.png', 'munster_000108_000019_gtFine_labelIds.png', 86)
('munster_000109_000019_leftImg8bit.png', 'munster_000109_000019_gtFine_labelIds.png', 87)
('munster_000110_000019_leftImg8bit.png', 'munster_000110_000019_gtFine_labelIds.png', 87)
('munster_000111_000019_leftImg8bit.png', 'munster_000111_000019_gtFine_labelIds.png', 87)
('munster_000112_000019_leftImg8bit.png', 'munster_000112_000019_gtFine_labelIds.png', 87)
('munster_000113_000019_leftImg8bit.png', 'munster_000113_000019_gtFine_labelIds.png', 87)
('munster_000114_000019_leftImg8bit.png', 'munster_000114_000019_gtFine_labelIds.png', 88)
('munster_000115_000019_leftImg8bit.png', 'munster_000115_000019_gtFine_labelIds.png', 88)
('munster_000116_000019_leftImg8bit.png', 'munster_000116_000019_gtFine_labelIds.png', 88)
('munster_000117_000019_leftImg8bit.png', 'munster_000117_000019_gtFine_labelIds.png', 88)
('munster_000118_000019_leftImg8bit.png', 'munster_000118_000019_gtFine_labelIds.png', 88)
('munster_000119_000019_leftImg8bit.png', 'munster_000119_000019_gtFine_labelIds.png', 89)
('munster_000120_000019_leftImg8bit.png', 'munster_000120_000019_gtFine_labelIds.png', 89)
('munster_000121_000019_leftImg8bit.png', 'munster_000121_000019_gtFine_labelIds.png', 89)
('munster_000122_000019_leftImg8bit.png', 'munster_000122_000019_gtFine_labelIds.png', 89)
('munster_000123_000019_leftImg8bit.png', 'munster_000123_000019_gtFine_labelIds.png', 89)
pixel_accuracy=0.963611155642, mean_iou=0.832859802092, iou=[ 0.9409029   0.93473389  0.76774481  0.61393505  0.90698236]
('munster_000124_000019_leftImg8bit.png', 'munster_000124_000019_gtFine_labelIds.png', 90)
('munster_000125_000019_leftImg8bit.png', 'munster_000125_000019_gtFine_labelIds.png', 90)
('munster_000126_000019_leftImg8bit.png', 'munster_000126_000019_gtFine_labelIds.png', 90)
('munster_000127_000019_leftImg8bit.png', 'munster_000127_000019_gtFine_labelIds.png', 90)
('munster_000128_000019_leftImg8bit.png', 'munster_000128_000019_gtFine_labelIds.png', 90)
('munster_000129_000019_leftImg8bit.png', 'munster_000129_000019_gtFine_labelIds.png', 91)
('munster_000130_000019_leftImg8bit.png', 'munster_000130_000019_gtFine_labelIds.png', 91)
('munster_000131_000019_leftImg8bit.png', 'munster_000131_000019_gtFine_labelIds.png', 91)
('munster_000132_000019_leftImg8bit.png', 'munster_000132_000019_gtFine_labelIds.png', 91)
('munster_000133_000019_leftImg8bit.png', 'munster_000133_000019_gtFine_labelIds.png', 91)
('munster_000134_000019_leftImg8bit.png', 'munster_000134_000019_gtFine_labelIds.png', 92)
('munster_000135_000019_leftImg8bit.png', 'munster_000135_000019_gtFine_labelIds.png', 92)
('munster_000136_000019_leftImg8bit.png', 'munster_000136_000019_gtFine_labelIds.png', 92)
('munster_000137_000019_leftImg8bit.png', 'munster_000137_000019_gtFine_labelIds.png', 92)
('munster_000138_000019_leftImg8bit.png', 'munster_000138_000019_gtFine_labelIds.png', 92)
('munster_000139_000019_leftImg8bit.png', 'munster_000139_000019_gtFine_labelIds.png', 93)
('munster_000140_000019_leftImg8bit.png', 'munster_000140_000019_gtFine_labelIds.png', 93)
('munster_000141_000019_leftImg8bit.png', 'munster_000141_000019_gtFine_labelIds.png', 93)
('munster_000142_000019_leftImg8bit.png', 'munster_000142_000019_gtFine_labelIds.png', 93)
('munster_000143_000019_leftImg8bit.png', 'munster_000143_000019_gtFine_labelIds.png', 93)
('munster_000144_000019_leftImg8bit.png', 'munster_000144_000019_gtFine_labelIds.png', 94)
('munster_000145_000019_leftImg8bit.png', 'munster_000145_000019_gtFine_labelIds.png', 94)
('munster_000146_000019_leftImg8bit.png', 'munster_000146_000019_gtFine_labelIds.png', 94)
('munster_000147_000019_leftImg8bit.png', 'munster_000147_000019_gtFine_labelIds.png', 94)
('munster_000148_000019_leftImg8bit.png', 'munster_000148_000019_gtFine_labelIds.png', 94)
pixel_accuracy=0.960983104341, mean_iou=0.831626139192, iou=[ 0.93662951  0.92718749  0.7718439   0.61488053  0.90758926]
('munster_000149_000019_leftImg8bit.png', 'munster_000149_000019_gtFine_labelIds.png', 95)
('munster_000150_000019_leftImg8bit.png', 'munster_000150_000019_gtFine_labelIds.png', 95)
('munster_000151_000019_leftImg8bit.png', 'munster_000151_000019_gtFine_labelIds.png', 95)
('munster_000152_000019_leftImg8bit.png', 'munster_000152_000019_gtFine_labelIds.png', 95)
('munster_000153_000019_leftImg8bit.png', 'munster_000153_000019_gtFine_labelIds.png', 95)
('munster_000154_000019_leftImg8bit.png', 'munster_000154_000019_gtFine_labelIds.png', 96)
('munster_000155_000019_leftImg8bit.png', 'munster_000155_000019_gtFine_labelIds.png', 96)
('munster_000156_000019_leftImg8bit.png', 'munster_000156_000019_gtFine_labelIds.png', 96)
('munster_000157_000019_leftImg8bit.png', 'munster_000157_000019_gtFine_labelIds.png', 96)
('munster_000158_000019_leftImg8bit.png', 'munster_000158_000019_gtFine_labelIds.png', 96)
('munster_000159_000019_leftImg8bit.png', 'munster_000159_000019_gtFine_labelIds.png', 97)
('munster_000160_000019_leftImg8bit.png', 'munster_000160_000019_gtFine_labelIds.png', 97)
('munster_000161_000019_leftImg8bit.png', 'munster_000161_000019_gtFine_labelIds.png', 97)
('munster_000162_000019_leftImg8bit.png', 'munster_000162_000019_gtFine_labelIds.png', 97)
('munster_000163_000019_leftImg8bit.png', 'munster_000163_000019_gtFine_labelIds.png', 97)
('munster_000164_000019_leftImg8bit.png', 'munster_000164_000019_gtFine_labelIds.png', 98)
('munster_000165_000019_leftImg8bit.png', 'munster_000165_000019_gtFine_labelIds.png', 98)
('munster_000166_000019_leftImg8bit.png', 'munster_000166_000019_gtFine_labelIds.png', 98)
('munster_000167_000019_leftImg8bit.png', 'munster_000167_000019_gtFine_labelIds.png', 98)
('munster_000168_000019_leftImg8bit.png', 'munster_000168_000019_gtFine_labelIds.png', 98)
('munster_000169_000019_leftImg8bit.png', 'munster_000169_000019_gtFine_labelIds.png', 99)
('munster_000170_000019_leftImg8bit.png', 'munster_000170_000019_gtFine_labelIds.png', 99)
('munster_000171_000019_leftImg8bit.png', 'munster_000171_000019_gtFine_labelIds.png', 99)
('munster_000172_000019_leftImg8bit.png', 'munster_000172_000019_gtFine_labelIds.png', 99)
('munster_000173_000019_leftImg8bit.png', 'munster_000173_000019_gtFine_labelIds.png', 99)
pixel_accuracy=0.96181507313, mean_iou=0.833717946324, iou=[ 0.93801851  0.92912061  0.77197472  0.62122001  0.90825587]
-------------------------------------------------------------
Final: pixel_accuracy=0.96181507313, mean_iou=0.833717946324, iou=[ 0.93801851  0.92912061  0.77197472  0.62122001  0.90825587]
-------------------------------------------------------------
initial eval.
I0925 09:59:11.042970 11505 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0925 09:59:11.043655 11505 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8278441984, dev_info[0]: total=8506769408 free=8278441984
I0925 09:59:11.044239 11505 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0925 09:59:11.044805 11505 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8278441984, dev_info[0]: total=8506769408 free=8278441984
I0925 09:59:11.046473 11505 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: ../trained/image_segmentation/cityscapes5_jsegnet21v2/l1reg/deploy.prototxt
I0925 09:59:11.046485 11505 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0925 09:59:11.046489 11505 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0925 09:59:11.046824 11505 net.cpp:72] Initializing net from parameters: 
name: "jsegnet21v2_deploy"
state {
  phase: TEST
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 1024
      dim: 2048
    }
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "out5a"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "out5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "out5a/bn"
  type: "BatchNorm"
  bottom: "out5a"
  top: "out5a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out5a/relu"
  type: "ReLU"
  bottom: "out5a"
  top: "out5a"
}
layer {
  name: "out5a_up2"
  type: "Deconvolution"
  bottom: "out5a"
  top: "out5a_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 64
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out3a"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "out3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "out3a/bn"
  type: "BatchNorm"
  bottom: "out3a"
  top: "out3a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out3a/relu"
  type: "ReLU"
  bottom: "out3a"
  top: "out3a"
}
layer {
  name: "out3_out5_combined"
  type: "Eltwise"
  bottom: "out5a_up2"
  bottom: "out3a"
  top: "out3_out5_combined"
}
layer {
  name: "ctx_conv1"
  type: "Convolution"
  bottom: "out3_out5_combined"
  top: "ctx_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_conv1/bn"
  type: "BatchNorm"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv1/relu"
  type: "ReLU"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
}
layer {
  name: "ctx_conv2"
  type: "Convolution"
  bottom: "ctx_conv1"
  top: "ctx_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv2/bn"
  type: "BatchNorm"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv2/relu"
  type: "ReLU"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
}
layer {
  name: "ctx_conv3"
  type: "Convolution"
  bottom: "ctx_conv2"
  top: "ctx_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv3/bn"
  type: "BatchNorm"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv3/relu"
  type: "ReLU"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
}
layer {
  name: "ctx_conv4"
  type: "Convolution"
  bottom: "ctx_conv3"
  top: "ctx_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv4/bn"
  type: "BatchNorm"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv4/relu"
  type: "ReLU"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
}
layer {
  name: "ctx_final"
  type: "Convolution"
  bottom: "ctx_conv4"
  top: "ctx_final"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_final/relu"
  type: "ReLU"
  bottom: "ctx_final"
  top: "ctx_final"
}
layer {
  name: "out_deconv_final_up2"
  type: "Deconvolution"
  bottom: "ctx_final"
  top: "out_deconv_final_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up4"
  type: "Deconvolution"
  bottom: "out_deconv_final_up2"
  top: "out_deconv_final_up4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up8"
  type: "Deconvolution"
  bottom: "out_deconv_final_up4"
  top: "out_deconv_final_up8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "argMaxOut"
  type: "ArgMax"
  bottom: "out_deconv_final_up8"
  top: "argMaxOut"
  argmax_param {
    axis: 1
  }
}
I0925 09:59:11.046974 11505 net.cpp:104] Using FLOAT as default forward math type
I0925 09:59:11.046982 11505 net.cpp:110] Using FLOAT as default backward math type
I0925 09:59:11.046984 11505 layer_factory.hpp:136] Creating layer 'input' of type 'Input'
I0925 09:59:11.046989 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.046998 11505 net.cpp:184] Created Layer input (0)
I0925 09:59:11.047003 11505 net.cpp:530] input -> data
I0925 09:59:11.047739 11505 net.cpp:245] Setting up input
I0925 09:59:11.047749 11505 net.cpp:252] TEST Top shape for layer 0 'input' 1 3 1024 2048 (6291456)
I0925 09:59:11.047754 11505 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0925 09:59:11.047761 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.047770 11505 net.cpp:184] Created Layer data/bias (1)
I0925 09:59:11.047771 11505 net.cpp:561] data/bias <- data
I0925 09:59:11.047775 11505 net.cpp:530] data/bias -> data/bias
I0925 09:59:11.052477 11505 net.cpp:245] Setting up data/bias
I0925 09:59:11.052501 11505 net.cpp:252] TEST Top shape for layer 1 'data/bias' 1 3 1024 2048 (6291456)
I0925 09:59:11.052511 11505 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0925 09:59:11.052516 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.052539 11505 net.cpp:184] Created Layer conv1a (2)
I0925 09:59:11.052546 11505 net.cpp:561] conv1a <- data/bias
I0925 09:59:11.052551 11505 net.cpp:530] conv1a -> conv1a
I0925 09:59:11.414275 11505 net.cpp:245] Setting up conv1a
I0925 09:59:11.414299 11505 net.cpp:252] TEST Top shape for layer 2 'conv1a' 1 32 512 1024 (16777216)
I0925 09:59:11.414310 11505 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0925 09:59:11.414314 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.414322 11505 net.cpp:184] Created Layer conv1a/bn (3)
I0925 09:59:11.414325 11505 net.cpp:561] conv1a/bn <- conv1a
I0925 09:59:11.414330 11505 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0925 09:59:11.415200 11505 net.cpp:245] Setting up conv1a/bn
I0925 09:59:11.415210 11505 net.cpp:252] TEST Top shape for layer 3 'conv1a/bn' 1 32 512 1024 (16777216)
I0925 09:59:11.415217 11505 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0925 09:59:11.415220 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.415225 11505 net.cpp:184] Created Layer conv1a/relu (4)
I0925 09:59:11.415226 11505 net.cpp:561] conv1a/relu <- conv1a
I0925 09:59:11.415228 11505 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0925 09:59:11.415238 11505 net.cpp:245] Setting up conv1a/relu
I0925 09:59:11.415241 11505 net.cpp:252] TEST Top shape for layer 4 'conv1a/relu' 1 32 512 1024 (16777216)
I0925 09:59:11.415243 11505 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0925 09:59:11.415246 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.415257 11505 net.cpp:184] Created Layer conv1b (5)
I0925 09:59:11.415261 11505 net.cpp:561] conv1b <- conv1a
I0925 09:59:11.415263 11505 net.cpp:530] conv1b -> conv1b
I0925 09:59:11.416893 11505 net.cpp:245] Setting up conv1b
I0925 09:59:11.416903 11505 net.cpp:252] TEST Top shape for layer 5 'conv1b' 1 32 512 1024 (16777216)
I0925 09:59:11.416908 11505 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0925 09:59:11.416910 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.416919 11505 net.cpp:184] Created Layer conv1b/bn (6)
I0925 09:59:11.416923 11505 net.cpp:561] conv1b/bn <- conv1b
I0925 09:59:11.416924 11505 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0925 09:59:11.417776 11505 net.cpp:245] Setting up conv1b/bn
I0925 09:59:11.417785 11505 net.cpp:252] TEST Top shape for layer 6 'conv1b/bn' 1 32 512 1024 (16777216)
I0925 09:59:11.417791 11505 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0925 09:59:11.417793 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.417798 11505 net.cpp:184] Created Layer conv1b/relu (7)
I0925 09:59:11.417799 11505 net.cpp:561] conv1b/relu <- conv1b
I0925 09:59:11.417803 11505 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0925 09:59:11.417805 11505 net.cpp:245] Setting up conv1b/relu
I0925 09:59:11.417809 11505 net.cpp:252] TEST Top shape for layer 7 'conv1b/relu' 1 32 512 1024 (16777216)
I0925 09:59:11.417810 11505 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0925 09:59:11.417821 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.417826 11505 net.cpp:184] Created Layer pool1 (8)
I0925 09:59:11.417829 11505 net.cpp:561] pool1 <- conv1b
I0925 09:59:11.417832 11505 net.cpp:530] pool1 -> pool1
I0925 09:59:11.417877 11505 net.cpp:245] Setting up pool1
I0925 09:59:11.417886 11505 net.cpp:252] TEST Top shape for layer 8 'pool1' 1 32 256 512 (4194304)
I0925 09:59:11.417889 11505 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0925 09:59:11.417893 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.417901 11505 net.cpp:184] Created Layer res2a_branch2a (9)
I0925 09:59:11.417904 11505 net.cpp:561] res2a_branch2a <- pool1
I0925 09:59:11.417908 11505 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0925 09:59:11.419170 11505 net.cpp:245] Setting up res2a_branch2a
I0925 09:59:11.419180 11505 net.cpp:252] TEST Top shape for layer 9 'res2a_branch2a' 1 64 256 512 (8388608)
I0925 09:59:11.419186 11505 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0925 09:59:11.419188 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.419193 11505 net.cpp:184] Created Layer res2a_branch2a/bn (10)
I0925 09:59:11.419196 11505 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0925 09:59:11.419198 11505 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0925 09:59:11.419667 11505 net.cpp:245] Setting up res2a_branch2a/bn
I0925 09:59:11.419677 11505 net.cpp:252] TEST Top shape for layer 10 'res2a_branch2a/bn' 1 64 256 512 (8388608)
I0925 09:59:11.419682 11505 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0925 09:59:11.419685 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.419688 11505 net.cpp:184] Created Layer res2a_branch2a/relu (11)
I0925 09:59:11.419690 11505 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0925 09:59:11.419692 11505 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0925 09:59:11.419697 11505 net.cpp:245] Setting up res2a_branch2a/relu
I0925 09:59:11.419699 11505 net.cpp:252] TEST Top shape for layer 11 'res2a_branch2a/relu' 1 64 256 512 (8388608)
I0925 09:59:11.419701 11505 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0925 09:59:11.419703 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.419716 11505 net.cpp:184] Created Layer res2a_branch2b (12)
I0925 09:59:11.419719 11505 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0925 09:59:11.419723 11505 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0925 09:59:11.420788 11505 net.cpp:245] Setting up res2a_branch2b
I0925 09:59:11.420796 11505 net.cpp:252] TEST Top shape for layer 12 'res2a_branch2b' 1 64 256 512 (8388608)
I0925 09:59:11.420801 11505 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0925 09:59:11.420804 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.420812 11505 net.cpp:184] Created Layer res2a_branch2b/bn (13)
I0925 09:59:11.420815 11505 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0925 09:59:11.420817 11505 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0925 09:59:11.421643 11505 net.cpp:245] Setting up res2a_branch2b/bn
I0925 09:59:11.421651 11505 net.cpp:252] TEST Top shape for layer 13 'res2a_branch2b/bn' 1 64 256 512 (8388608)
I0925 09:59:11.421658 11505 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0925 09:59:11.421660 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.421667 11505 net.cpp:184] Created Layer res2a_branch2b/relu (14)
I0925 09:59:11.421669 11505 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0925 09:59:11.421672 11505 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0925 09:59:11.421682 11505 net.cpp:245] Setting up res2a_branch2b/relu
I0925 09:59:11.421686 11505 net.cpp:252] TEST Top shape for layer 14 'res2a_branch2b/relu' 1 64 256 512 (8388608)
I0925 09:59:11.421689 11505 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0925 09:59:11.421690 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.421694 11505 net.cpp:184] Created Layer pool2 (15)
I0925 09:59:11.421697 11505 net.cpp:561] pool2 <- res2a_branch2b
I0925 09:59:11.421700 11505 net.cpp:530] pool2 -> pool2
I0925 09:59:11.421746 11505 net.cpp:245] Setting up pool2
I0925 09:59:11.421753 11505 net.cpp:252] TEST Top shape for layer 15 'pool2' 1 64 128 256 (2097152)
I0925 09:59:11.421757 11505 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0925 09:59:11.421761 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.421773 11505 net.cpp:184] Created Layer res3a_branch2a (16)
I0925 09:59:11.421777 11505 net.cpp:561] res3a_branch2a <- pool2
I0925 09:59:11.421782 11505 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0925 09:59:11.424458 11505 net.cpp:245] Setting up res3a_branch2a
I0925 09:59:11.424469 11505 net.cpp:252] TEST Top shape for layer 16 'res3a_branch2a' 1 128 128 256 (4194304)
I0925 09:59:11.424474 11505 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0925 09:59:11.424477 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.424481 11505 net.cpp:184] Created Layer res3a_branch2a/bn (17)
I0925 09:59:11.424485 11505 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0925 09:59:11.424489 11505 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0925 09:59:11.424952 11505 net.cpp:245] Setting up res3a_branch2a/bn
I0925 09:59:11.424960 11505 net.cpp:252] TEST Top shape for layer 17 'res3a_branch2a/bn' 1 128 128 256 (4194304)
I0925 09:59:11.424968 11505 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0925 09:59:11.424970 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.424973 11505 net.cpp:184] Created Layer res3a_branch2a/relu (18)
I0925 09:59:11.424975 11505 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0925 09:59:11.424978 11505 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0925 09:59:11.424981 11505 net.cpp:245] Setting up res3a_branch2a/relu
I0925 09:59:11.424983 11505 net.cpp:252] TEST Top shape for layer 18 'res3a_branch2a/relu' 1 128 128 256 (4194304)
I0925 09:59:11.424985 11505 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0925 09:59:11.424988 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.424993 11505 net.cpp:184] Created Layer res3a_branch2b (19)
I0925 09:59:11.424995 11505 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0925 09:59:11.424998 11505 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0925 09:59:11.426005 11505 net.cpp:245] Setting up res3a_branch2b
I0925 09:59:11.426013 11505 net.cpp:252] TEST Top shape for layer 19 'res3a_branch2b' 1 128 128 256 (4194304)
I0925 09:59:11.426018 11505 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0925 09:59:11.426020 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.426024 11505 net.cpp:184] Created Layer res3a_branch2b/bn (20)
I0925 09:59:11.426028 11505 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0925 09:59:11.426031 11505 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0925 09:59:11.426434 11505 net.cpp:245] Setting up res3a_branch2b/bn
I0925 09:59:11.426441 11505 net.cpp:252] TEST Top shape for layer 20 'res3a_branch2b/bn' 1 128 128 256 (4194304)
I0925 09:59:11.426447 11505 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0925 09:59:11.426450 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.426460 11505 net.cpp:184] Created Layer res3a_branch2b/relu (21)
I0925 09:59:11.426462 11505 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0925 09:59:11.426465 11505 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0925 09:59:11.426468 11505 net.cpp:245] Setting up res3a_branch2b/relu
I0925 09:59:11.426472 11505 net.cpp:252] TEST Top shape for layer 21 'res3a_branch2b/relu' 1 128 128 256 (4194304)
I0925 09:59:11.426476 11505 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0925 09:59:11.426478 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.426492 11505 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (22)
I0925 09:59:11.426496 11505 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0925 09:59:11.426499 11505 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0925 09:59:11.426503 11505 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0925 09:59:11.426532 11505 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0925 09:59:11.426537 11505 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b_res3a_branch2b/relu_0_split' 1 128 128 256 (4194304)
I0925 09:59:11.426539 11505 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b_res3a_branch2b/relu_0_split' 1 128 128 256 (4194304)
I0925 09:59:11.426542 11505 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0925 09:59:11.426544 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.426548 11505 net.cpp:184] Created Layer pool3 (23)
I0925 09:59:11.426550 11505 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0925 09:59:11.426553 11505 net.cpp:530] pool3 -> pool3
I0925 09:59:11.426580 11505 net.cpp:245] Setting up pool3
I0925 09:59:11.426584 11505 net.cpp:252] TEST Top shape for layer 23 'pool3' 1 128 64 128 (1048576)
I0925 09:59:11.426586 11505 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0925 09:59:11.426589 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.426594 11505 net.cpp:184] Created Layer res4a_branch2a (24)
I0925 09:59:11.426597 11505 net.cpp:561] res4a_branch2a <- pool3
I0925 09:59:11.426599 11505 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0925 09:59:11.432586 11505 net.cpp:245] Setting up res4a_branch2a
I0925 09:59:11.432595 11505 net.cpp:252] TEST Top shape for layer 24 'res4a_branch2a' 1 256 64 128 (2097152)
I0925 09:59:11.432598 11505 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0925 09:59:11.432601 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.432605 11505 net.cpp:184] Created Layer res4a_branch2a/bn (25)
I0925 09:59:11.432607 11505 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0925 09:59:11.432610 11505 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0925 09:59:11.433089 11505 net.cpp:245] Setting up res4a_branch2a/bn
I0925 09:59:11.433097 11505 net.cpp:252] TEST Top shape for layer 25 'res4a_branch2a/bn' 1 256 64 128 (2097152)
I0925 09:59:11.433104 11505 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0925 09:59:11.433105 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.433109 11505 net.cpp:184] Created Layer res4a_branch2a/relu (26)
I0925 09:59:11.433110 11505 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0925 09:59:11.433113 11505 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0925 09:59:11.433116 11505 net.cpp:245] Setting up res4a_branch2a/relu
I0925 09:59:11.433120 11505 net.cpp:252] TEST Top shape for layer 26 'res4a_branch2a/relu' 1 256 64 128 (2097152)
I0925 09:59:11.433121 11505 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0925 09:59:11.433130 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.433140 11505 net.cpp:184] Created Layer res4a_branch2b (27)
I0925 09:59:11.433142 11505 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0925 09:59:11.433145 11505 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0925 09:59:11.436223 11505 net.cpp:245] Setting up res4a_branch2b
I0925 09:59:11.436229 11505 net.cpp:252] TEST Top shape for layer 27 'res4a_branch2b' 1 256 64 128 (2097152)
I0925 09:59:11.436234 11505 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0925 09:59:11.436236 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.436240 11505 net.cpp:184] Created Layer res4a_branch2b/bn (28)
I0925 09:59:11.436242 11505 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0925 09:59:11.436245 11505 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0925 09:59:11.436630 11505 net.cpp:245] Setting up res4a_branch2b/bn
I0925 09:59:11.436635 11505 net.cpp:252] TEST Top shape for layer 28 'res4a_branch2b/bn' 1 256 64 128 (2097152)
I0925 09:59:11.436641 11505 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0925 09:59:11.436643 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.436646 11505 net.cpp:184] Created Layer res4a_branch2b/relu (29)
I0925 09:59:11.436648 11505 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0925 09:59:11.436650 11505 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0925 09:59:11.436655 11505 net.cpp:245] Setting up res4a_branch2b/relu
I0925 09:59:11.436656 11505 net.cpp:252] TEST Top shape for layer 29 'res4a_branch2b/relu' 1 256 64 128 (2097152)
I0925 09:59:11.436658 11505 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0925 09:59:11.436661 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.436664 11505 net.cpp:184] Created Layer pool4 (30)
I0925 09:59:11.436666 11505 net.cpp:561] pool4 <- res4a_branch2b
I0925 09:59:11.436668 11505 net.cpp:530] pool4 -> pool4
I0925 09:59:11.436697 11505 net.cpp:245] Setting up pool4
I0925 09:59:11.436702 11505 net.cpp:252] TEST Top shape for layer 30 'pool4' 1 256 64 128 (2097152)
I0925 09:59:11.436704 11505 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0925 09:59:11.436707 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.436712 11505 net.cpp:184] Created Layer res5a_branch2a (31)
I0925 09:59:11.436714 11505 net.cpp:561] res5a_branch2a <- pool4
I0925 09:59:11.436717 11505 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0925 09:59:11.461827 11505 net.cpp:245] Setting up res5a_branch2a
I0925 09:59:11.461849 11505 net.cpp:252] TEST Top shape for layer 31 'res5a_branch2a' 1 512 64 128 (4194304)
I0925 09:59:11.461856 11505 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0925 09:59:11.461860 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.461869 11505 net.cpp:184] Created Layer res5a_branch2a/bn (32)
I0925 09:59:11.461874 11505 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0925 09:59:11.461876 11505 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0925 09:59:11.462292 11505 net.cpp:245] Setting up res5a_branch2a/bn
I0925 09:59:11.462299 11505 net.cpp:252] TEST Top shape for layer 32 'res5a_branch2a/bn' 1 512 64 128 (4194304)
I0925 09:59:11.462306 11505 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0925 09:59:11.462308 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.462311 11505 net.cpp:184] Created Layer res5a_branch2a/relu (33)
I0925 09:59:11.462313 11505 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0925 09:59:11.462328 11505 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0925 09:59:11.462333 11505 net.cpp:245] Setting up res5a_branch2a/relu
I0925 09:59:11.462335 11505 net.cpp:252] TEST Top shape for layer 33 'res5a_branch2a/relu' 1 512 64 128 (4194304)
I0925 09:59:11.462338 11505 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0925 09:59:11.462340 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.462357 11505 net.cpp:184] Created Layer res5a_branch2b (34)
I0925 09:59:11.462360 11505 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0925 09:59:11.462363 11505 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0925 09:59:11.474884 11505 net.cpp:245] Setting up res5a_branch2b
I0925 09:59:11.474915 11505 net.cpp:252] TEST Top shape for layer 34 'res5a_branch2b' 1 512 64 128 (4194304)
I0925 09:59:11.474941 11505 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0925 09:59:11.474947 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.474959 11505 net.cpp:184] Created Layer res5a_branch2b/bn (35)
I0925 09:59:11.474964 11505 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0925 09:59:11.474968 11505 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0925 09:59:11.475414 11505 net.cpp:245] Setting up res5a_branch2b/bn
I0925 09:59:11.475421 11505 net.cpp:252] TEST Top shape for layer 35 'res5a_branch2b/bn' 1 512 64 128 (4194304)
I0925 09:59:11.475427 11505 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0925 09:59:11.475430 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.475435 11505 net.cpp:184] Created Layer res5a_branch2b/relu (36)
I0925 09:59:11.475437 11505 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0925 09:59:11.475440 11505 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0925 09:59:11.475445 11505 net.cpp:245] Setting up res5a_branch2b/relu
I0925 09:59:11.475446 11505 net.cpp:252] TEST Top shape for layer 36 'res5a_branch2b/relu' 1 512 64 128 (4194304)
I0925 09:59:11.475450 11505 layer_factory.hpp:136] Creating layer 'out5a' of type 'Convolution'
I0925 09:59:11.475451 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.475466 11505 net.cpp:184] Created Layer out5a (37)
I0925 09:59:11.475476 11505 net.cpp:561] out5a <- res5a_branch2b
I0925 09:59:11.475478 11505 net.cpp:530] out5a -> out5a
I0925 09:59:11.480990 11505 net.cpp:245] Setting up out5a
I0925 09:59:11.481009 11505 net.cpp:252] TEST Top shape for layer 37 'out5a' 1 64 64 128 (524288)
I0925 09:59:11.481016 11505 layer_factory.hpp:136] Creating layer 'out5a/bn' of type 'BatchNorm'
I0925 09:59:11.481020 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.481027 11505 net.cpp:184] Created Layer out5a/bn (38)
I0925 09:59:11.481030 11505 net.cpp:561] out5a/bn <- out5a
I0925 09:59:11.481034 11505 net.cpp:513] out5a/bn -> out5a (in-place)
I0925 09:59:11.481472 11505 net.cpp:245] Setting up out5a/bn
I0925 09:59:11.481478 11505 net.cpp:252] TEST Top shape for layer 38 'out5a/bn' 1 64 64 128 (524288)
I0925 09:59:11.481484 11505 layer_factory.hpp:136] Creating layer 'out5a/relu' of type 'ReLU'
I0925 09:59:11.481487 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.481490 11505 net.cpp:184] Created Layer out5a/relu (39)
I0925 09:59:11.481492 11505 net.cpp:561] out5a/relu <- out5a
I0925 09:59:11.481494 11505 net.cpp:513] out5a/relu -> out5a (in-place)
I0925 09:59:11.481499 11505 net.cpp:245] Setting up out5a/relu
I0925 09:59:11.481501 11505 net.cpp:252] TEST Top shape for layer 39 'out5a/relu' 1 64 64 128 (524288)
I0925 09:59:11.481503 11505 layer_factory.hpp:136] Creating layer 'out5a_up2' of type 'Deconvolution'
I0925 09:59:11.481505 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.481528 11505 net.cpp:184] Created Layer out5a_up2 (40)
I0925 09:59:11.481530 11505 net.cpp:561] out5a_up2 <- out5a
I0925 09:59:11.481533 11505 net.cpp:530] out5a_up2 -> out5a_up2
I0925 09:59:11.481673 11505 net.cpp:245] Setting up out5a_up2
I0925 09:59:11.481678 11505 net.cpp:252] TEST Top shape for layer 40 'out5a_up2' 1 64 128 256 (2097152)
I0925 09:59:11.481683 11505 layer_factory.hpp:136] Creating layer 'out3a' of type 'Convolution'
I0925 09:59:11.481684 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.481691 11505 net.cpp:184] Created Layer out3a (41)
I0925 09:59:11.481693 11505 net.cpp:561] out3a <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0925 09:59:11.481696 11505 net.cpp:530] out3a -> out3a
I0925 09:59:11.482615 11505 net.cpp:245] Setting up out3a
I0925 09:59:11.482625 11505 net.cpp:252] TEST Top shape for layer 41 'out3a' 1 64 128 256 (2097152)
I0925 09:59:11.482628 11505 layer_factory.hpp:136] Creating layer 'out3a/bn' of type 'BatchNorm'
I0925 09:59:11.482631 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.482642 11505 net.cpp:184] Created Layer out3a/bn (42)
I0925 09:59:11.482645 11505 net.cpp:561] out3a/bn <- out3a
I0925 09:59:11.482648 11505 net.cpp:513] out3a/bn -> out3a (in-place)
I0925 09:59:11.483063 11505 net.cpp:245] Setting up out3a/bn
I0925 09:59:11.483069 11505 net.cpp:252] TEST Top shape for layer 42 'out3a/bn' 1 64 128 256 (2097152)
I0925 09:59:11.483074 11505 layer_factory.hpp:136] Creating layer 'out3a/relu' of type 'ReLU'
I0925 09:59:11.483078 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.483080 11505 net.cpp:184] Created Layer out3a/relu (43)
I0925 09:59:11.483083 11505 net.cpp:561] out3a/relu <- out3a
I0925 09:59:11.483085 11505 net.cpp:513] out3a/relu -> out3a (in-place)
I0925 09:59:11.483088 11505 net.cpp:245] Setting up out3a/relu
I0925 09:59:11.483091 11505 net.cpp:252] TEST Top shape for layer 43 'out3a/relu' 1 64 128 256 (2097152)
I0925 09:59:11.483093 11505 layer_factory.hpp:136] Creating layer 'out3_out5_combined' of type 'Eltwise'
I0925 09:59:11.483095 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.483101 11505 net.cpp:184] Created Layer out3_out5_combined (44)
I0925 09:59:11.483103 11505 net.cpp:561] out3_out5_combined <- out5a_up2
I0925 09:59:11.483106 11505 net.cpp:561] out3_out5_combined <- out3a
I0925 09:59:11.483108 11505 net.cpp:530] out3_out5_combined -> out3_out5_combined
I0925 09:59:11.483126 11505 net.cpp:245] Setting up out3_out5_combined
I0925 09:59:11.483131 11505 net.cpp:252] TEST Top shape for layer 44 'out3_out5_combined' 1 64 128 256 (2097152)
I0925 09:59:11.483134 11505 layer_factory.hpp:136] Creating layer 'ctx_conv1' of type 'Convolution'
I0925 09:59:11.483135 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.483144 11505 net.cpp:184] Created Layer ctx_conv1 (45)
I0925 09:59:11.483147 11505 net.cpp:561] ctx_conv1 <- out3_out5_combined
I0925 09:59:11.483150 11505 net.cpp:530] ctx_conv1 -> ctx_conv1
I0925 09:59:11.484069 11505 net.cpp:245] Setting up ctx_conv1
I0925 09:59:11.484078 11505 net.cpp:252] TEST Top shape for layer 45 'ctx_conv1' 1 64 128 256 (2097152)
I0925 09:59:11.484082 11505 layer_factory.hpp:136] Creating layer 'ctx_conv1/bn' of type 'BatchNorm'
I0925 09:59:11.484086 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.484091 11505 net.cpp:184] Created Layer ctx_conv1/bn (46)
I0925 09:59:11.484093 11505 net.cpp:561] ctx_conv1/bn <- ctx_conv1
I0925 09:59:11.484096 11505 net.cpp:513] ctx_conv1/bn -> ctx_conv1 (in-place)
I0925 09:59:11.484498 11505 net.cpp:245] Setting up ctx_conv1/bn
I0925 09:59:11.484505 11505 net.cpp:252] TEST Top shape for layer 46 'ctx_conv1/bn' 1 64 128 256 (2097152)
I0925 09:59:11.484510 11505 layer_factory.hpp:136] Creating layer 'ctx_conv1/relu' of type 'ReLU'
I0925 09:59:11.484519 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.484524 11505 net.cpp:184] Created Layer ctx_conv1/relu (47)
I0925 09:59:11.484526 11505 net.cpp:561] ctx_conv1/relu <- ctx_conv1
I0925 09:59:11.484529 11505 net.cpp:513] ctx_conv1/relu -> ctx_conv1 (in-place)
I0925 09:59:11.484532 11505 net.cpp:245] Setting up ctx_conv1/relu
I0925 09:59:11.484534 11505 net.cpp:252] TEST Top shape for layer 47 'ctx_conv1/relu' 1 64 128 256 (2097152)
I0925 09:59:11.484539 11505 layer_factory.hpp:136] Creating layer 'ctx_conv2' of type 'Convolution'
I0925 09:59:11.484540 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.484549 11505 net.cpp:184] Created Layer ctx_conv2 (48)
I0925 09:59:11.484552 11505 net.cpp:561] ctx_conv2 <- ctx_conv1
I0925 09:59:11.484555 11505 net.cpp:530] ctx_conv2 -> ctx_conv2
I0925 09:59:11.485455 11505 net.cpp:245] Setting up ctx_conv2
I0925 09:59:11.485462 11505 net.cpp:252] TEST Top shape for layer 48 'ctx_conv2' 1 64 128 256 (2097152)
I0925 09:59:11.485466 11505 layer_factory.hpp:136] Creating layer 'ctx_conv2/bn' of type 'BatchNorm'
I0925 09:59:11.485468 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.485472 11505 net.cpp:184] Created Layer ctx_conv2/bn (49)
I0925 09:59:11.485474 11505 net.cpp:561] ctx_conv2/bn <- ctx_conv2
I0925 09:59:11.485477 11505 net.cpp:513] ctx_conv2/bn -> ctx_conv2 (in-place)
I0925 09:59:11.485880 11505 net.cpp:245] Setting up ctx_conv2/bn
I0925 09:59:11.485888 11505 net.cpp:252] TEST Top shape for layer 49 'ctx_conv2/bn' 1 64 128 256 (2097152)
I0925 09:59:11.485893 11505 layer_factory.hpp:136] Creating layer 'ctx_conv2/relu' of type 'ReLU'
I0925 09:59:11.485895 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.485898 11505 net.cpp:184] Created Layer ctx_conv2/relu (50)
I0925 09:59:11.485900 11505 net.cpp:561] ctx_conv2/relu <- ctx_conv2
I0925 09:59:11.485903 11505 net.cpp:513] ctx_conv2/relu -> ctx_conv2 (in-place)
I0925 09:59:11.485906 11505 net.cpp:245] Setting up ctx_conv2/relu
I0925 09:59:11.485908 11505 net.cpp:252] TEST Top shape for layer 50 'ctx_conv2/relu' 1 64 128 256 (2097152)
I0925 09:59:11.485910 11505 layer_factory.hpp:136] Creating layer 'ctx_conv3' of type 'Convolution'
I0925 09:59:11.485913 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.485921 11505 net.cpp:184] Created Layer ctx_conv3 (51)
I0925 09:59:11.485925 11505 net.cpp:561] ctx_conv3 <- ctx_conv2
I0925 09:59:11.485927 11505 net.cpp:530] ctx_conv3 -> ctx_conv3
I0925 09:59:11.486832 11505 net.cpp:245] Setting up ctx_conv3
I0925 09:59:11.486840 11505 net.cpp:252] TEST Top shape for layer 51 'ctx_conv3' 1 64 128 256 (2097152)
I0925 09:59:11.486845 11505 layer_factory.hpp:136] Creating layer 'ctx_conv3/bn' of type 'BatchNorm'
I0925 09:59:11.486848 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.486852 11505 net.cpp:184] Created Layer ctx_conv3/bn (52)
I0925 09:59:11.486855 11505 net.cpp:561] ctx_conv3/bn <- ctx_conv3
I0925 09:59:11.486857 11505 net.cpp:513] ctx_conv3/bn -> ctx_conv3 (in-place)
I0925 09:59:11.487257 11505 net.cpp:245] Setting up ctx_conv3/bn
I0925 09:59:11.487263 11505 net.cpp:252] TEST Top shape for layer 52 'ctx_conv3/bn' 1 64 128 256 (2097152)
I0925 09:59:11.487269 11505 layer_factory.hpp:136] Creating layer 'ctx_conv3/relu' of type 'ReLU'
I0925 09:59:11.487273 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.487277 11505 net.cpp:184] Created Layer ctx_conv3/relu (53)
I0925 09:59:11.487278 11505 net.cpp:561] ctx_conv3/relu <- ctx_conv3
I0925 09:59:11.487280 11505 net.cpp:513] ctx_conv3/relu -> ctx_conv3 (in-place)
I0925 09:59:11.487283 11505 net.cpp:245] Setting up ctx_conv3/relu
I0925 09:59:11.487287 11505 net.cpp:252] TEST Top shape for layer 53 'ctx_conv3/relu' 1 64 128 256 (2097152)
I0925 09:59:11.487294 11505 layer_factory.hpp:136] Creating layer 'ctx_conv4' of type 'Convolution'
I0925 09:59:11.487298 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.487303 11505 net.cpp:184] Created Layer ctx_conv4 (54)
I0925 09:59:11.487305 11505 net.cpp:561] ctx_conv4 <- ctx_conv3
I0925 09:59:11.487308 11505 net.cpp:530] ctx_conv4 -> ctx_conv4
I0925 09:59:11.488204 11505 net.cpp:245] Setting up ctx_conv4
I0925 09:59:11.488211 11505 net.cpp:252] TEST Top shape for layer 54 'ctx_conv4' 1 64 128 256 (2097152)
I0925 09:59:11.488215 11505 layer_factory.hpp:136] Creating layer 'ctx_conv4/bn' of type 'BatchNorm'
I0925 09:59:11.488219 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.488222 11505 net.cpp:184] Created Layer ctx_conv4/bn (55)
I0925 09:59:11.488224 11505 net.cpp:561] ctx_conv4/bn <- ctx_conv4
I0925 09:59:11.488227 11505 net.cpp:513] ctx_conv4/bn -> ctx_conv4 (in-place)
I0925 09:59:11.488713 11505 net.cpp:245] Setting up ctx_conv4/bn
I0925 09:59:11.488721 11505 net.cpp:252] TEST Top shape for layer 55 'ctx_conv4/bn' 1 64 128 256 (2097152)
I0925 09:59:11.488728 11505 layer_factory.hpp:136] Creating layer 'ctx_conv4/relu' of type 'ReLU'
I0925 09:59:11.488730 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.488734 11505 net.cpp:184] Created Layer ctx_conv4/relu (56)
I0925 09:59:11.488735 11505 net.cpp:561] ctx_conv4/relu <- ctx_conv4
I0925 09:59:11.488739 11505 net.cpp:513] ctx_conv4/relu -> ctx_conv4 (in-place)
I0925 09:59:11.488741 11505 net.cpp:245] Setting up ctx_conv4/relu
I0925 09:59:11.488745 11505 net.cpp:252] TEST Top shape for layer 56 'ctx_conv4/relu' 1 64 128 256 (2097152)
I0925 09:59:11.488747 11505 layer_factory.hpp:136] Creating layer 'ctx_final' of type 'Convolution'
I0925 09:59:11.488749 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.488762 11505 net.cpp:184] Created Layer ctx_final (57)
I0925 09:59:11.488765 11505 net.cpp:561] ctx_final <- ctx_conv4
I0925 09:59:11.488767 11505 net.cpp:530] ctx_final -> ctx_final
I0925 09:59:11.489037 11505 net.cpp:245] Setting up ctx_final
I0925 09:59:11.489044 11505 net.cpp:252] TEST Top shape for layer 57 'ctx_final' 1 8 128 256 (262144)
I0925 09:59:11.489048 11505 layer_factory.hpp:136] Creating layer 'ctx_final/relu' of type 'ReLU'
I0925 09:59:11.489051 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.489054 11505 net.cpp:184] Created Layer ctx_final/relu (58)
I0925 09:59:11.489056 11505 net.cpp:561] ctx_final/relu <- ctx_final
I0925 09:59:11.489059 11505 net.cpp:513] ctx_final/relu -> ctx_final (in-place)
I0925 09:59:11.489063 11505 net.cpp:245] Setting up ctx_final/relu
I0925 09:59:11.489064 11505 net.cpp:252] TEST Top shape for layer 58 'ctx_final/relu' 1 8 128 256 (262144)
I0925 09:59:11.489068 11505 layer_factory.hpp:136] Creating layer 'out_deconv_final_up2' of type 'Deconvolution'
I0925 09:59:11.489070 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.489074 11505 net.cpp:184] Created Layer out_deconv_final_up2 (59)
I0925 09:59:11.489078 11505 net.cpp:561] out_deconv_final_up2 <- ctx_final
I0925 09:59:11.489079 11505 net.cpp:530] out_deconv_final_up2 -> out_deconv_final_up2
I0925 09:59:11.489197 11505 net.cpp:245] Setting up out_deconv_final_up2
I0925 09:59:11.489202 11505 net.cpp:252] TEST Top shape for layer 59 'out_deconv_final_up2' 1 8 256 512 (1048576)
I0925 09:59:11.489205 11505 layer_factory.hpp:136] Creating layer 'out_deconv_final_up4' of type 'Deconvolution'
I0925 09:59:11.489207 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.489212 11505 net.cpp:184] Created Layer out_deconv_final_up4 (60)
I0925 09:59:11.489214 11505 net.cpp:561] out_deconv_final_up4 <- out_deconv_final_up2
I0925 09:59:11.489223 11505 net.cpp:530] out_deconv_final_up4 -> out_deconv_final_up4
I0925 09:59:11.489344 11505 net.cpp:245] Setting up out_deconv_final_up4
I0925 09:59:11.489349 11505 net.cpp:252] TEST Top shape for layer 60 'out_deconv_final_up4' 1 8 512 1024 (4194304)
I0925 09:59:11.489352 11505 layer_factory.hpp:136] Creating layer 'out_deconv_final_up8' of type 'Deconvolution'
I0925 09:59:11.489354 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.489358 11505 net.cpp:184] Created Layer out_deconv_final_up8 (61)
I0925 09:59:11.489362 11505 net.cpp:561] out_deconv_final_up8 <- out_deconv_final_up4
I0925 09:59:11.489363 11505 net.cpp:530] out_deconv_final_up8 -> out_deconv_final_up8
I0925 09:59:11.489480 11505 net.cpp:245] Setting up out_deconv_final_up8
I0925 09:59:11.489485 11505 net.cpp:252] TEST Top shape for layer 61 'out_deconv_final_up8' 1 8 1024 2048 (16777216)
I0925 09:59:11.489487 11505 layer_factory.hpp:136] Creating layer 'argMaxOut' of type 'ArgMax'
I0925 09:59:11.489490 11505 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 09:59:11.489498 11505 net.cpp:184] Created Layer argMaxOut (62)
I0925 09:59:11.489501 11505 net.cpp:561] argMaxOut <- out_deconv_final_up8
I0925 09:59:11.489504 11505 net.cpp:530] argMaxOut -> argMaxOut
I0925 09:59:11.489517 11505 net.cpp:245] Setting up argMaxOut
I0925 09:59:11.489521 11505 net.cpp:252] TEST Top shape for layer 62 'argMaxOut' 1 1 1024 2048 (2097152)
I0925 09:59:11.489524 11505 net.cpp:325] argMaxOut does not need backward computation.
I0925 09:59:11.489526 11505 net.cpp:325] out_deconv_final_up8 does not need backward computation.
I0925 09:59:11.489528 11505 net.cpp:325] out_deconv_final_up4 does not need backward computation.
I0925 09:59:11.489531 11505 net.cpp:325] out_deconv_final_up2 does not need backward computation.
I0925 09:59:11.489531 11505 net.cpp:325] ctx_final/relu does not need backward computation.
I0925 09:59:11.489533 11505 net.cpp:325] ctx_final does not need backward computation.
I0925 09:59:11.489539 11505 net.cpp:325] ctx_conv4/relu does not need backward computation.
I0925 09:59:11.489542 11505 net.cpp:325] ctx_conv4/bn does not need backward computation.
I0925 09:59:11.489544 11505 net.cpp:325] ctx_conv4 does not need backward computation.
I0925 09:59:11.489547 11505 net.cpp:325] ctx_conv3/relu does not need backward computation.
I0925 09:59:11.489547 11505 net.cpp:325] ctx_conv3/bn does not need backward computation.
I0925 09:59:11.489549 11505 net.cpp:325] ctx_conv3 does not need backward computation.
I0925 09:59:11.489552 11505 net.cpp:325] ctx_conv2/relu does not need backward computation.
I0925 09:59:11.489553 11505 net.cpp:325] ctx_conv2/bn does not need backward computation.
I0925 09:59:11.489555 11505 net.cpp:325] ctx_conv2 does not need backward computation.
I0925 09:59:11.489557 11505 net.cpp:325] ctx_conv1/relu does not need backward computation.
I0925 09:59:11.489558 11505 net.cpp:325] ctx_conv1/bn does not need backward computation.
I0925 09:59:11.489560 11505 net.cpp:325] ctx_conv1 does not need backward computation.
I0925 09:59:11.489562 11505 net.cpp:325] out3_out5_combined does not need backward computation.
I0925 09:59:11.489564 11505 net.cpp:325] out3a/relu does not need backward computation.
I0925 09:59:11.489567 11505 net.cpp:325] out3a/bn does not need backward computation.
I0925 09:59:11.489568 11505 net.cpp:325] out3a does not need backward computation.
I0925 09:59:11.489570 11505 net.cpp:325] out5a_up2 does not need backward computation.
I0925 09:59:11.489573 11505 net.cpp:325] out5a/relu does not need backward computation.
I0925 09:59:11.489574 11505 net.cpp:325] out5a/bn does not need backward computation.
I0925 09:59:11.489576 11505 net.cpp:325] out5a does not need backward computation.
I0925 09:59:11.489578 11505 net.cpp:325] res5a_branch2b/relu does not need backward computation.
I0925 09:59:11.489580 11505 net.cpp:325] res5a_branch2b/bn does not need backward computation.
I0925 09:59:11.489586 11505 net.cpp:325] res5a_branch2b does not need backward computation.
I0925 09:59:11.489588 11505 net.cpp:325] res5a_branch2a/relu does not need backward computation.
I0925 09:59:11.489590 11505 net.cpp:325] res5a_branch2a/bn does not need backward computation.
I0925 09:59:11.489593 11505 net.cpp:325] res5a_branch2a does not need backward computation.
I0925 09:59:11.489594 11505 net.cpp:325] pool4 does not need backward computation.
I0925 09:59:11.489596 11505 net.cpp:325] res4a_branch2b/relu does not need backward computation.
I0925 09:59:11.489598 11505 net.cpp:325] res4a_branch2b/bn does not need backward computation.
I0925 09:59:11.489600 11505 net.cpp:325] res4a_branch2b does not need backward computation.
I0925 09:59:11.489603 11505 net.cpp:325] res4a_branch2a/relu does not need backward computation.
I0925 09:59:11.489604 11505 net.cpp:325] res4a_branch2a/bn does not need backward computation.
I0925 09:59:11.489606 11505 net.cpp:325] res4a_branch2a does not need backward computation.
I0925 09:59:11.489609 11505 net.cpp:325] pool3 does not need backward computation.
I0925 09:59:11.489611 11505 net.cpp:325] res3a_branch2b_res3a_branch2b/relu_0_split does not need backward computation.
I0925 09:59:11.489614 11505 net.cpp:325] res3a_branch2b/relu does not need backward computation.
I0925 09:59:11.489615 11505 net.cpp:325] res3a_branch2b/bn does not need backward computation.
I0925 09:59:11.489617 11505 net.cpp:325] res3a_branch2b does not need backward computation.
I0925 09:59:11.489619 11505 net.cpp:325] res3a_branch2a/relu does not need backward computation.
I0925 09:59:11.489621 11505 net.cpp:325] res3a_branch2a/bn does not need backward computation.
I0925 09:59:11.489624 11505 net.cpp:325] res3a_branch2a does not need backward computation.
I0925 09:59:11.489625 11505 net.cpp:325] pool2 does not need backward computation.
I0925 09:59:11.489627 11505 net.cpp:325] res2a_branch2b/relu does not need backward computation.
I0925 09:59:11.489629 11505 net.cpp:325] res2a_branch2b/bn does not need backward computation.
I0925 09:59:11.489631 11505 net.cpp:325] res2a_branch2b does not need backward computation.
I0925 09:59:11.489634 11505 net.cpp:325] res2a_branch2a/relu does not need backward computation.
I0925 09:59:11.489635 11505 net.cpp:325] res2a_branch2a/bn does not need backward computation.
I0925 09:59:11.489639 11505 net.cpp:325] res2a_branch2a does not need backward computation.
I0925 09:59:11.489640 11505 net.cpp:325] pool1 does not need backward computation.
I0925 09:59:11.489642 11505 net.cpp:325] conv1b/relu does not need backward computation.
I0925 09:59:11.489645 11505 net.cpp:325] conv1b/bn does not need backward computation.
I0925 09:59:11.489646 11505 net.cpp:325] conv1b does not need backward computation.
I0925 09:59:11.489648 11505 net.cpp:325] conv1a/relu does not need backward computation.
I0925 09:59:11.489650 11505 net.cpp:325] conv1a/bn does not need backward computation.
I0925 09:59:11.489652 11505 net.cpp:325] conv1a does not need backward computation.
I0925 09:59:11.489655 11505 net.cpp:325] data/bias does not need backward computation.
I0925 09:59:11.489656 11505 net.cpp:325] input does not need backward computation.
I0925 09:59:11.489658 11505 net.cpp:367] This network produces output argMaxOut
I0925 09:59:11.489692 11505 net.cpp:389] Top memory (TEST) required for data: 1224736768 diff: 1224736768
I0925 09:59:11.489696 11505 net.cpp:392] Bottom memory (TEST) required for data: 1216348160 diff: 1216348160
I0925 09:59:11.489697 11505 net.cpp:395] Shared (in-place) memory (TEST) by data: 659554304 diff: 659554304
I0925 09:59:11.489699 11505 net.cpp:398] Parameters memory (TEST) required for data: 10817840 diff: 10817840
I0925 09:59:11.489701 11505 net.cpp:401] Parameters shared memory (TEST) by data: 0 diff: 0
I0925 09:59:11.489703 11505 net.cpp:407] Network initialization done.
I0925 09:59:11.494400 11505 net.cpp:1078] Ignoring source layer data
I0925 09:59:11.494419 11505 net.cpp:1094] Copying source layer data/bias Type:Bias #blobs=1
I0925 09:59:11.494451 11505 net.cpp:1094] Copying source layer conv1a Type:Convolution #blobs=2
I0925 09:59:11.494474 11505 net.cpp:1094] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0925 09:59:11.494619 11505 net.cpp:1094] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0925 09:59:11.494623 11505 net.cpp:1094] Copying source layer conv1b Type:Convolution #blobs=2
I0925 09:59:11.494632 11505 net.cpp:1094] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0925 09:59:11.494729 11505 net.cpp:1094] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0925 09:59:11.494735 11505 net.cpp:1094] Copying source layer pool1 Type:Pooling #blobs=0
I0925 09:59:11.494736 11505 net.cpp:1094] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0925 09:59:11.494752 11505 net.cpp:1094] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0925 09:59:11.494843 11505 net.cpp:1094] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0925 09:59:11.494848 11505 net.cpp:1094] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0925 09:59:11.494859 11505 net.cpp:1094] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0925 09:59:11.494943 11505 net.cpp:1094] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0925 09:59:11.494947 11505 net.cpp:1094] Copying source layer pool2 Type:Pooling #blobs=0
I0925 09:59:11.494951 11505 net.cpp:1094] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0925 09:59:11.494987 11505 net.cpp:1094] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0925 09:59:11.495072 11505 net.cpp:1094] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0925 09:59:11.495076 11505 net.cpp:1094] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0925 09:59:11.495097 11505 net.cpp:1094] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0925 09:59:11.495173 11505 net.cpp:1094] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0925 09:59:11.495177 11505 net.cpp:1094] Copying source layer res3a_branch2b_res3a_branch2b/relu_0_split Type:Split #blobs=0
I0925 09:59:11.495179 11505 net.cpp:1094] Copying source layer pool3 Type:Pooling #blobs=0
I0925 09:59:11.495182 11505 net.cpp:1094] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0925 09:59:11.495292 11505 net.cpp:1094] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0925 09:59:11.495370 11505 net.cpp:1094] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0925 09:59:11.495374 11505 net.cpp:1094] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0925 09:59:11.495436 11505 net.cpp:1094] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0925 09:59:11.495512 11505 net.cpp:1094] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0925 09:59:11.495515 11505 net.cpp:1094] Copying source layer pool4 Type:Pooling #blobs=0
I0925 09:59:11.495518 11505 net.cpp:1094] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0925 09:59:11.495867 11505 net.cpp:1094] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0925 09:59:11.495951 11505 net.cpp:1094] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0925 09:59:11.495956 11505 net.cpp:1094] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0925 09:59:11.496134 11505 net.cpp:1094] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0925 09:59:11.496212 11505 net.cpp:1094] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0925 09:59:11.496217 11505 net.cpp:1094] Copying source layer out5a Type:Convolution #blobs=2
I0925 09:59:11.496270 11505 net.cpp:1094] Copying source layer out5a/bn Type:BatchNorm #blobs=5
I0925 09:59:11.496362 11505 net.cpp:1094] Copying source layer out5a/relu Type:ReLU #blobs=0
I0925 09:59:11.496366 11505 net.cpp:1094] Copying source layer out5a_up2 Type:Deconvolution #blobs=1
I0925 09:59:11.496372 11505 net.cpp:1094] Copying source layer out3a Type:Convolution #blobs=2
I0925 09:59:11.496402 11505 net.cpp:1094] Copying source layer out3a/bn Type:BatchNorm #blobs=5
I0925 09:59:11.496496 11505 net.cpp:1094] Copying source layer out3a/relu Type:ReLU #blobs=0
I0925 09:59:11.496500 11505 net.cpp:1094] Copying source layer out3_out5_combined Type:Eltwise #blobs=0
I0925 09:59:11.496503 11505 net.cpp:1094] Copying source layer ctx_conv1 Type:Convolution #blobs=2
I0925 09:59:11.496525 11505 net.cpp:1094] Copying source layer ctx_conv1/bn Type:BatchNorm #blobs=5
I0925 09:59:11.496608 11505 net.cpp:1094] Copying source layer ctx_conv1/relu Type:ReLU #blobs=0
I0925 09:59:11.496613 11505 net.cpp:1094] Copying source layer ctx_conv2 Type:Convolution #blobs=2
I0925 09:59:11.496634 11505 net.cpp:1094] Copying source layer ctx_conv2/bn Type:BatchNorm #blobs=5
I0925 09:59:11.496721 11505 net.cpp:1094] Copying source layer ctx_conv2/relu Type:ReLU #blobs=0
I0925 09:59:11.496726 11505 net.cpp:1094] Copying source layer ctx_conv3 Type:Convolution #blobs=2
I0925 09:59:11.496749 11505 net.cpp:1094] Copying source layer ctx_conv3/bn Type:BatchNorm #blobs=5
I0925 09:59:11.496837 11505 net.cpp:1094] Copying source layer ctx_conv3/relu Type:ReLU #blobs=0
I0925 09:59:11.496841 11505 net.cpp:1094] Copying source layer ctx_conv4 Type:Convolution #blobs=2
I0925 09:59:11.496863 11505 net.cpp:1094] Copying source layer ctx_conv4/bn Type:BatchNorm #blobs=5
I0925 09:59:11.496947 11505 net.cpp:1094] Copying source layer ctx_conv4/relu Type:ReLU #blobs=0
I0925 09:59:11.496950 11505 net.cpp:1094] Copying source layer ctx_final Type:Convolution #blobs=2
I0925 09:59:11.496959 11505 net.cpp:1094] Copying source layer ctx_final/relu Type:ReLU #blobs=0
I0925 09:59:11.496963 11505 net.cpp:1094] Copying source layer out_deconv_final_up2 Type:Deconvolution #blobs=1
I0925 09:59:11.496968 11505 net.cpp:1094] Copying source layer out_deconv_final_up4 Type:Deconvolution #blobs=1
I0925 09:59:11.496973 11505 net.cpp:1094] Copying source layer out_deconv_final_up8 Type:Deconvolution #blobs=1
I0925 09:59:11.496979 11505 net.cpp:1078] Ignoring source layer loss
Namespace(batch_size=1, blend=False, class_dict='', crop=['0'], input='./data/val-image-list.txt', label='./data/val-label-list.txt', label_dict='', model='../trained/image_segmentation/cityscapes5_jsegnet21v2/l1reg/deploy.prototxt', num_classes=5, num_images=500, output=None, palette='', resize=['0'], resize_back=True, search='*.png', weights='../trained/image_segmentation/cityscapes5_jsegnet21v2/l1reg/cityscapes5_jsegnet21v2_iter_60000.caffemodel')
Infering list
Getting list of images...running inference for  500  images...
('frankfurt_000000_000294_leftImg8bit.png', 'frankfurt_000000_000294_gtFine_labelIds.png', 0)
('frankfurt_000000_000576_leftImg8bit.png', 'frankfurt_000000_000576_gtFine_labelIds.png', 0)
('frankfurt_000000_001016_leftImg8bit.png', 'frankfurt_000000_001016_gtFine_labelIds.png', 0)
I0925 09:59:12.309959 11505 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1a' with space 0.01G 3/1 1 	(avail 5.89G, req 0.01G)	t: 0
I0925 09:59:12.439108 11505 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1b' with space 0.01G 32/4 6 	(avail 5.89G, req 0.01G)	t: 0
I0925 09:59:12.456341 11505 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2a' with space 0.01G 32/1 6 	(avail 5.89G, req 0.01G)	t: 0
I0925 09:59:12.497534 11505 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2b' with space 0.01G 64/4 6 	(avail 5.89G, req 0.01G)	t: 0
I0925 09:59:12.508947 11505 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2a' with space 0.01G 64/1 6 	(avail 5.89G, req 0.01G)	t: 0
I0925 09:59:12.513072 11505 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2b' with space 0.01G 128/4 6 	(avail 5.89G, req 0.01G)	t: 0
I0925 09:59:12.524942 11505 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2a' with space 0.01G 128/1 6 	(avail 5.89G, req 0.01G)	t: 0
I0925 09:59:12.528360 11505 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2b' with space 0.01G 256/4 6 	(avail 5.89G, req 0.01G)	t: 0
I0925 09:59:12.542596 11505 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'out3a' with space 0.01G 128/2 6 	(avail 5.89G, req 0.01G)	t: 0
I0925 09:59:12.549403 11505 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_conv1' with space 0.01G 64/1 6 	(avail 5.89G, req 0.01G)	t: 0
I0925 09:59:12.574857 11505 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_final' with space 0.01G 64/1 6 	(avail 5.89G, req 0.01G)	t: 0
('frankfurt_000000_001236_leftImg8bit.png', 'frankfurt_000000_001236_gtFine_labelIds.png', 0)
('frankfurt_000000_001751_leftImg8bit.png', 'frankfurt_000000_001751_gtFine_labelIds.png', 0)
('frankfurt_000000_002196_leftImg8bit.png', 'frankfurt_000000_002196_gtFine_labelIds.png', 1)
('frankfurt_000000_002963_leftImg8bit.png', 'frankfurt_000000_002963_gtFine_labelIds.png', 1)
('frankfurt_000000_003025_leftImg8bit.png', 'frankfurt_000000_003025_gtFine_labelIds.png', 1)
('frankfurt_000000_003357_leftImg8bit.png', 'frankfurt_000000_003357_gtFine_labelIds.png', 1)
('frankfurt_000000_003920_leftImg8bit.png', 'frankfurt_000000_003920_gtFine_labelIds.png', 1)
('frankfurt_000000_004617_leftImg8bit.png', 'frankfurt_000000_004617_gtFine_labelIds.png', 2)
('frankfurt_000000_005543_leftImg8bit.png', 'frankfurt_000000_005543_gtFine_labelIds.png', 2)
('frankfurt_000000_005898_leftImg8bit.png', 'frankfurt_000000_005898_gtFine_labelIds.png', 2)
('frankfurt_000000_006589_leftImg8bit.png', 'frankfurt_000000_006589_gtFine_labelIds.png', 2)
('frankfurt_000000_007365_leftImg8bit.png', 'frankfurt_000000_007365_gtFine_labelIds.png', 2)
('frankfurt_000000_008206_leftImg8bit.png', 'frankfurt_000000_008206_gtFine_labelIds.png', 3)
('frankfurt_000000_008451_leftImg8bit.png', 'frankfurt_000000_008451_gtFine_labelIds.png', 3)
('frankfurt_000000_009291_leftImg8bit.png', 'frankfurt_000000_009291_gtFine_labelIds.png', 3)
('frankfurt_000000_009561_leftImg8bit.png', 'frankfurt_000000_009561_gtFine_labelIds.png', 3)
('frankfurt_000000_009688_leftImg8bit.png', 'frankfurt_000000_009688_gtFine_labelIds.png', 3)
('frankfurt_000000_009969_leftImg8bit.png', 'frankfurt_000000_009969_gtFine_labelIds.png', 4)
('frankfurt_000000_010351_leftImg8bit.png', 'frankfurt_000000_010351_gtFine_labelIds.png', 4)
('frankfurt_000000_010763_leftImg8bit.png', 'frankfurt_000000_010763_gtFine_labelIds.png', 4)
('frankfurt_000000_011007_leftImg8bit.png', 'frankfurt_000000_011007_gtFine_labelIds.png', 4)
('frankfurt_000000_011074_leftImg8bit.png', 'frankfurt_000000_011074_gtFine_labelIds.png', 4)
pixel_accuracy=0.974895376059, mean_iou=0.830725874432, iou=[ 0.95835131  0.96192297  0.76209772  0.57632984  0.89492754]
('frankfurt_000000_011461_leftImg8bit.png', 'frankfurt_000000_011461_gtFine_labelIds.png', 5)
('frankfurt_000000_011810_leftImg8bit.png', 'frankfurt_000000_011810_gtFine_labelIds.png', 5)
('frankfurt_000000_012009_leftImg8bit.png', 'frankfurt_000000_012009_gtFine_labelIds.png', 5)
('frankfurt_000000_012121_leftImg8bit.png', 'frankfurt_000000_012121_gtFine_labelIds.png', 5)
('frankfurt_000000_012868_leftImg8bit.png', 'frankfurt_000000_012868_gtFine_labelIds.png', 5)
('frankfurt_000000_013067_leftImg8bit.png', 'frankfurt_000000_013067_gtFine_labelIds.png', 6)
('frankfurt_000000_013240_leftImg8bit.png', 'frankfurt_000000_013240_gtFine_labelIds.png', 6)
('frankfurt_000000_013382_leftImg8bit.png', 'frankfurt_000000_013382_gtFine_labelIds.png', 6)
('frankfurt_000000_013942_leftImg8bit.png', 'frankfurt_000000_013942_gtFine_labelIds.png', 6)
('frankfurt_000000_014480_leftImg8bit.png', 'frankfurt_000000_014480_gtFine_labelIds.png', 6)
('frankfurt_000000_015389_leftImg8bit.png', 'frankfurt_000000_015389_gtFine_labelIds.png', 7)
('frankfurt_000000_015676_leftImg8bit.png', 'frankfurt_000000_015676_gtFine_labelIds.png', 7)
('frankfurt_000000_016005_leftImg8bit.png', 'frankfurt_000000_016005_gtFine_labelIds.png', 7)
('frankfurt_000000_016286_leftImg8bit.png', 'frankfurt_000000_016286_gtFine_labelIds.png', 7)
('frankfurt_000000_017228_leftImg8bit.png', 'frankfurt_000000_017228_gtFine_labelIds.png', 7)
('frankfurt_000000_017476_leftImg8bit.png', 'frankfurt_000000_017476_gtFine_labelIds.png', 8)
('frankfurt_000000_018797_leftImg8bit.png', 'frankfurt_000000_018797_gtFine_labelIds.png', 8)
('frankfurt_000000_019607_leftImg8bit.png', 'frankfurt_000000_019607_gtFine_labelIds.png', 8)
('frankfurt_000000_020215_leftImg8bit.png', 'frankfurt_000000_020215_gtFine_labelIds.png', 8)
('frankfurt_000000_020321_leftImg8bit.png', 'frankfurt_000000_020321_gtFine_labelIds.png', 8)
('frankfurt_000000_020880_leftImg8bit.png', 'frankfurt_000000_020880_gtFine_labelIds.png', 9)
('frankfurt_000000_021667_leftImg8bit.png', 'frankfurt_000000_021667_gtFine_labelIds.png', 9)
('frankfurt_000000_021879_leftImg8bit.png', 'frankfurt_000000_021879_gtFine_labelIds.png', 9)
('frankfurt_000000_022254_leftImg8bit.png', 'frankfurt_000000_022254_gtFine_labelIds.png', 9)
('frankfurt_000000_022797_leftImg8bit.png', 'frankfurt_000000_022797_gtFine_labelIds.png', 9)
pixel_accuracy=0.974940431396, mean_iou=0.842585442508, iou=[ 0.95851373  0.9654392   0.77501327  0.61850047  0.89546054]
('frankfurt_000001_000538_leftImg8bit.png', 'frankfurt_000001_000538_gtFine_labelIds.png', 10)
('frankfurt_000001_001464_leftImg8bit.png', 'frankfurt_000001_001464_gtFine_labelIds.png', 10)
('frankfurt_000001_002512_leftImg8bit.png', 'frankfurt_000001_002512_gtFine_labelIds.png', 10)
('frankfurt_000001_002646_leftImg8bit.png', 'frankfurt_000001_002646_gtFine_labelIds.png', 10)
('frankfurt_000001_002759_leftImg8bit.png', 'frankfurt_000001_002759_gtFine_labelIds.png', 10)
('frankfurt_000001_003056_leftImg8bit.png', 'frankfurt_000001_003056_gtFine_labelIds.png', 11)
('frankfurt_000001_003588_leftImg8bit.png', 'frankfurt_000001_003588_gtFine_labelIds.png', 11)
('frankfurt_000001_004327_leftImg8bit.png', 'frankfurt_000001_004327_gtFine_labelIds.png', 11)
('frankfurt_000001_004736_leftImg8bit.png', 'frankfurt_000001_004736_gtFine_labelIds.png', 11)
('frankfurt_000001_004859_leftImg8bit.png', 'frankfurt_000001_004859_gtFine_labelIds.png', 11)
('frankfurt_000001_005184_leftImg8bit.png', 'frankfurt_000001_005184_gtFine_labelIds.png', 12)
('frankfurt_000001_005410_leftImg8bit.png', 'frankfurt_000001_005410_gtFine_labelIds.png', 12)
('frankfurt_000001_005703_leftImg8bit.png', 'frankfurt_000001_005703_gtFine_labelIds.png', 12)
('frankfurt_000001_005898_leftImg8bit.png', 'frankfurt_000001_005898_gtFine_labelIds.png', 12)
('frankfurt_000001_007285_leftImg8bit.png', 'frankfurt_000001_007285_gtFine_labelIds.png', 12)
('frankfurt_000001_007407_leftImg8bit.png', 'frankfurt_000001_007407_gtFine_labelIds.png', 13)
('frankfurt_000001_007622_leftImg8bit.png', 'frankfurt_000001_007622_gtFine_labelIds.png', 13)
('frankfurt_000001_007857_leftImg8bit.png', 'frankfurt_000001_007857_gtFine_labelIds.png', 13)
('frankfurt_000001_007973_leftImg8bit.png', 'frankfurt_000001_007973_gtFine_labelIds.png', 13)
('frankfurt_000001_008200_leftImg8bit.png', 'frankfurt_000001_008200_gtFine_labelIds.png', 13)
('frankfurt_000001_008688_leftImg8bit.png', 'frankfurt_000001_008688_gtFine_labelIds.png', 14)
('frankfurt_000001_009058_leftImg8bit.png', 'frankfurt_000001_009058_gtFine_labelIds.png', 14)
('frankfurt_000001_009504_leftImg8bit.png', 'frankfurt_000001_009504_gtFine_labelIds.png', 14)
('frankfurt_000001_009854_leftImg8bit.png', 'frankfurt_000001_009854_gtFine_labelIds.png', 14)
('frankfurt_000001_010156_leftImg8bit.png', 'frankfurt_000001_010156_gtFine_labelIds.png', 14)
pixel_accuracy=0.973365629312, mean_iou=0.838990334377, iou=[ 0.9558037   0.96321194  0.76492054  0.6177781   0.89323739]
('frankfurt_000001_010444_leftImg8bit.png', 'frankfurt_000001_010444_gtFine_labelIds.png', 15)
('frankfurt_000001_010600_leftImg8bit.png', 'frankfurt_000001_010600_gtFine_labelIds.png', 15)
('frankfurt_000001_010830_leftImg8bit.png', 'frankfurt_000001_010830_gtFine_labelIds.png', 15)
('frankfurt_000001_011162_leftImg8bit.png', 'frankfurt_000001_011162_gtFine_labelIds.png', 15)
('frankfurt_000001_011715_leftImg8bit.png', 'frankfurt_000001_011715_gtFine_labelIds.png', 15)
('frankfurt_000001_011835_leftImg8bit.png', 'frankfurt_000001_011835_gtFine_labelIds.png', 16)
('frankfurt_000001_012038_leftImg8bit.png', 'frankfurt_000001_012038_gtFine_labelIds.png', 16)
('frankfurt_000001_012519_leftImg8bit.png', 'frankfurt_000001_012519_gtFine_labelIds.png', 16)
('frankfurt_000001_012699_leftImg8bit.png', 'frankfurt_000001_012699_gtFine_labelIds.png', 16)
('frankfurt_000001_012738_leftImg8bit.png', 'frankfurt_000001_012738_gtFine_labelIds.png', 16)
('frankfurt_000001_012870_leftImg8bit.png', 'frankfurt_000001_012870_gtFine_labelIds.png', 17)
('frankfurt_000001_013016_leftImg8bit.png', 'frankfurt_000001_013016_gtFine_labelIds.png', 17)
('frankfurt_000001_013496_leftImg8bit.png', 'frankfurt_000001_013496_gtFine_labelIds.png', 17)
('frankfurt_000001_013710_leftImg8bit.png', 'frankfurt_000001_013710_gtFine_labelIds.png', 17)
('frankfurt_000001_014221_leftImg8bit.png', 'frankfurt_000001_014221_gtFine_labelIds.png', 17)
('frankfurt_000001_014406_leftImg8bit.png', 'frankfurt_000001_014406_gtFine_labelIds.png', 18)
('frankfurt_000001_014565_leftImg8bit.png', 'frankfurt_000001_014565_gtFine_labelIds.png', 18)
('frankfurt_000001_014741_leftImg8bit.png', 'frankfurt_000001_014741_gtFine_labelIds.png', 18)
('frankfurt_000001_015091_leftImg8bit.png', 'frankfurt_000001_015091_gtFine_labelIds.png', 18)
('frankfurt_000001_015328_leftImg8bit.png', 'frankfurt_000001_015328_gtFine_labelIds.png', 18)
('frankfurt_000001_015768_leftImg8bit.png', 'frankfurt_000001_015768_gtFine_labelIds.png', 19)
('frankfurt_000001_016029_leftImg8bit.png', 'frankfurt_000001_016029_gtFine_labelIds.png', 19)
('frankfurt_000001_016273_leftImg8bit.png', 'frankfurt_000001_016273_gtFine_labelIds.png', 19)
('frankfurt_000001_016462_leftImg8bit.png', 'frankfurt_000001_016462_gtFine_labelIds.png', 19)
('frankfurt_000001_017101_leftImg8bit.png', 'frankfurt_000001_017101_gtFine_labelIds.png', 19)
pixel_accuracy=0.969792194239, mean_iou=0.842326522189, iou=[ 0.9507911   0.95792195  0.78721321  0.63172349  0.88398287]
('frankfurt_000001_017459_leftImg8bit.png', 'frankfurt_000001_017459_gtFine_labelIds.png', 20)
('frankfurt_000001_017842_leftImg8bit.png', 'frankfurt_000001_017842_gtFine_labelIds.png', 20)
('frankfurt_000001_018113_leftImg8bit.png', 'frankfurt_000001_018113_gtFine_labelIds.png', 20)
('frankfurt_000001_019698_leftImg8bit.png', 'frankfurt_000001_019698_gtFine_labelIds.png', 20)
('frankfurt_000001_019854_leftImg8bit.png', 'frankfurt_000001_019854_gtFine_labelIds.png', 20)
('frankfurt_000001_019969_leftImg8bit.png', 'frankfurt_000001_019969_gtFine_labelIds.png', 21)
('frankfurt_000001_020046_leftImg8bit.png', 'frankfurt_000001_020046_gtFine_labelIds.png', 21)
('frankfurt_000001_020287_leftImg8bit.png', 'frankfurt_000001_020287_gtFine_labelIds.png', 21)
('frankfurt_000001_020693_leftImg8bit.png', 'frankfurt_000001_020693_gtFine_labelIds.png', 21)
('frankfurt_000001_021406_leftImg8bit.png', 'frankfurt_000001_021406_gtFine_labelIds.png', 21)
('frankfurt_000001_021825_leftImg8bit.png', 'frankfurt_000001_021825_gtFine_labelIds.png', 22)
('frankfurt_000001_023235_leftImg8bit.png', 'frankfurt_000001_023235_gtFine_labelIds.png', 22)
('frankfurt_000001_023369_leftImg8bit.png', 'frankfurt_000001_023369_gtFine_labelIds.png', 22)
('frankfurt_000001_023769_leftImg8bit.png', 'frankfurt_000001_023769_gtFine_labelIds.png', 22)
('frankfurt_000001_024927_leftImg8bit.png', 'frankfurt_000001_024927_gtFine_labelIds.png', 22)
('frankfurt_000001_025512_leftImg8bit.png', 'frankfurt_000001_025512_gtFine_labelIds.png', 23)
('frankfurt_000001_025713_leftImg8bit.png', 'frankfurt_000001_025713_gtFine_labelIds.png', 23)
('frankfurt_000001_025921_leftImg8bit.png', 'frankfurt_000001_025921_gtFine_labelIds.png', 23)
('frankfurt_000001_027325_leftImg8bit.png', 'frankfurt_000001_027325_gtFine_labelIds.png', 23)
('frankfurt_000001_028232_leftImg8bit.png', 'frankfurt_000001_028232_gtFine_labelIds.png', 23)
('frankfurt_000001_028335_leftImg8bit.png', 'frankfurt_000001_028335_gtFine_labelIds.png', 24)
('frankfurt_000001_028590_leftImg8bit.png', 'frankfurt_000001_028590_gtFine_labelIds.png', 24)
('frankfurt_000001_028854_leftImg8bit.png', 'frankfurt_000001_028854_gtFine_labelIds.png', 24)
('frankfurt_000001_029086_leftImg8bit.png', 'frankfurt_000001_029086_gtFine_labelIds.png', 24)
('frankfurt_000001_029236_leftImg8bit.png', 'frankfurt_000001_029236_gtFine_labelIds.png', 24)
pixel_accuracy=0.969829148462, mean_iou=0.8407784266, iou=[ 0.95095913  0.95686799  0.78552621  0.62466419  0.88587461]
('frankfurt_000001_029600_leftImg8bit.png', 'frankfurt_000001_029600_gtFine_labelIds.png', 25)
('frankfurt_000001_030067_leftImg8bit.png', 'frankfurt_000001_030067_gtFine_labelIds.png', 25)
('frankfurt_000001_030310_leftImg8bit.png', 'frankfurt_000001_030310_gtFine_labelIds.png', 25)
('frankfurt_000001_030669_leftImg8bit.png', 'frankfurt_000001_030669_gtFine_labelIds.png', 25)
('frankfurt_000001_031266_leftImg8bit.png', 'frankfurt_000001_031266_gtFine_labelIds.png', 25)
('frankfurt_000001_031416_leftImg8bit.png', 'frankfurt_000001_031416_gtFine_labelIds.png', 26)
('frankfurt_000001_032018_leftImg8bit.png', 'frankfurt_000001_032018_gtFine_labelIds.png', 26)
('frankfurt_000001_032556_leftImg8bit.png', 'frankfurt_000001_032556_gtFine_labelIds.png', 26)
('frankfurt_000001_032711_leftImg8bit.png', 'frankfurt_000001_032711_gtFine_labelIds.png', 26)
('frankfurt_000001_032942_leftImg8bit.png', 'frankfurt_000001_032942_gtFine_labelIds.png', 26)
('frankfurt_000001_033655_leftImg8bit.png', 'frankfurt_000001_033655_gtFine_labelIds.png', 27)
('frankfurt_000001_034047_leftImg8bit.png', 'frankfurt_000001_034047_gtFine_labelIds.png', 27)
('frankfurt_000001_034816_leftImg8bit.png', 'frankfurt_000001_034816_gtFine_labelIds.png', 27)
('frankfurt_000001_035144_leftImg8bit.png', 'frankfurt_000001_035144_gtFine_labelIds.png', 27)
('frankfurt_000001_035864_leftImg8bit.png', 'frankfurt_000001_035864_gtFine_labelIds.png', 27)
('frankfurt_000001_037705_leftImg8bit.png', 'frankfurt_000001_037705_gtFine_labelIds.png', 28)
('frankfurt_000001_038245_leftImg8bit.png', 'frankfurt_000001_038245_gtFine_labelIds.png', 28)
('frankfurt_000001_038418_leftImg8bit.png', 'frankfurt_000001_038418_gtFine_labelIds.png', 28)
('frankfurt_000001_038645_leftImg8bit.png', 'frankfurt_000001_038645_gtFine_labelIds.png', 28)
('frankfurt_000001_038844_leftImg8bit.png', 'frankfurt_000001_038844_gtFine_labelIds.png', 28)
('frankfurt_000001_039895_leftImg8bit.png', 'frankfurt_000001_039895_gtFine_labelIds.png', 29)
('frankfurt_000001_040575_leftImg8bit.png', 'frankfurt_000001_040575_gtFine_labelIds.png', 29)
('frankfurt_000001_040732_leftImg8bit.png', 'frankfurt_000001_040732_gtFine_labelIds.png', 29)
('frankfurt_000001_041074_leftImg8bit.png', 'frankfurt_000001_041074_gtFine_labelIds.png', 29)
('frankfurt_000001_041354_leftImg8bit.png', 'frankfurt_000001_041354_gtFine_labelIds.png', 29)
pixel_accuracy=0.970399632244, mean_iou=0.839846558827, iou=[ 0.95164908  0.95867018  0.77524078  0.6197995   0.89387326]
('frankfurt_000001_041517_leftImg8bit.png', 'frankfurt_000001_041517_gtFine_labelIds.png', 30)
('frankfurt_000001_041664_leftImg8bit.png', 'frankfurt_000001_041664_gtFine_labelIds.png', 30)
('frankfurt_000001_042098_leftImg8bit.png', 'frankfurt_000001_042098_gtFine_labelIds.png', 30)
('frankfurt_000001_042384_leftImg8bit.png', 'frankfurt_000001_042384_gtFine_labelIds.png', 30)
('frankfurt_000001_042733_leftImg8bit.png', 'frankfurt_000001_042733_gtFine_labelIds.png', 30)
('frankfurt_000001_043395_leftImg8bit.png', 'frankfurt_000001_043395_gtFine_labelIds.png', 31)
('frankfurt_000001_043564_leftImg8bit.png', 'frankfurt_000001_043564_gtFine_labelIds.png', 31)
('frankfurt_000001_044227_leftImg8bit.png', 'frankfurt_000001_044227_gtFine_labelIds.png', 31)
('frankfurt_000001_044413_leftImg8bit.png', 'frankfurt_000001_044413_gtFine_labelIds.png', 31)
('frankfurt_000001_044525_leftImg8bit.png', 'frankfurt_000001_044525_gtFine_labelIds.png', 31)
('frankfurt_000001_044658_leftImg8bit.png', 'frankfurt_000001_044658_gtFine_labelIds.png', 32)
('frankfurt_000001_044787_leftImg8bit.png', 'frankfurt_000001_044787_gtFine_labelIds.png', 32)
('frankfurt_000001_046126_leftImg8bit.png', 'frankfurt_000001_046126_gtFine_labelIds.png', 32)
('frankfurt_000001_046272_leftImg8bit.png', 'frankfurt_000001_046272_gtFine_labelIds.png', 32)
('frankfurt_000001_046504_leftImg8bit.png', 'frankfurt_000001_046504_gtFine_labelIds.png', 32)
('frankfurt_000001_046779_leftImg8bit.png', 'frankfurt_000001_046779_gtFine_labelIds.png', 33)
('frankfurt_000001_047178_leftImg8bit.png', 'frankfurt_000001_047178_gtFine_labelIds.png', 33)
('frankfurt_000001_047552_leftImg8bit.png', 'frankfurt_000001_047552_gtFine_labelIds.png', 33)
('frankfurt_000001_048196_leftImg8bit.png', 'frankfurt_000001_048196_gtFine_labelIds.png', 33)
('frankfurt_000001_048355_leftImg8bit.png', 'frankfurt_000001_048355_gtFine_labelIds.png', 33)
('frankfurt_000001_048654_leftImg8bit.png', 'frankfurt_000001_048654_gtFine_labelIds.png', 34)
('frankfurt_000001_049078_leftImg8bit.png', 'frankfurt_000001_049078_gtFine_labelIds.png', 34)
('frankfurt_000001_049209_leftImg8bit.png', 'frankfurt_000001_049209_gtFine_labelIds.png', 34)
('frankfurt_000001_049298_leftImg8bit.png', 'frankfurt_000001_049298_gtFine_labelIds.png', 34)
('frankfurt_000001_049698_leftImg8bit.png', 'frankfurt_000001_049698_gtFine_labelIds.png', 34)
pixel_accuracy=0.971826848895, mean_iou=0.841308593818, iou=[ 0.95410677  0.96075466  0.77492692  0.6153653   0.90138933]
('frankfurt_000001_049770_leftImg8bit.png', 'frankfurt_000001_049770_gtFine_labelIds.png', 35)
('frankfurt_000001_050149_leftImg8bit.png', 'frankfurt_000001_050149_gtFine_labelIds.png', 35)
('frankfurt_000001_050686_leftImg8bit.png', 'frankfurt_000001_050686_gtFine_labelIds.png', 35)
('frankfurt_000001_051516_leftImg8bit.png', 'frankfurt_000001_051516_gtFine_labelIds.png', 35)
('frankfurt_000001_051737_leftImg8bit.png', 'frankfurt_000001_051737_gtFine_labelIds.png', 35)
('frankfurt_000001_051807_leftImg8bit.png', 'frankfurt_000001_051807_gtFine_labelIds.png', 36)
('frankfurt_000001_052120_leftImg8bit.png', 'frankfurt_000001_052120_gtFine_labelIds.png', 36)
('frankfurt_000001_052594_leftImg8bit.png', 'frankfurt_000001_052594_gtFine_labelIds.png', 36)
('frankfurt_000001_053102_leftImg8bit.png', 'frankfurt_000001_053102_gtFine_labelIds.png', 36)
('frankfurt_000001_054077_leftImg8bit.png', 'frankfurt_000001_054077_gtFine_labelIds.png', 36)
('frankfurt_000001_054219_leftImg8bit.png', 'frankfurt_000001_054219_gtFine_labelIds.png', 37)
('frankfurt_000001_054415_leftImg8bit.png', 'frankfurt_000001_054415_gtFine_labelIds.png', 37)
('frankfurt_000001_054640_leftImg8bit.png', 'frankfurt_000001_054640_gtFine_labelIds.png', 37)
('frankfurt_000001_054884_leftImg8bit.png', 'frankfurt_000001_054884_gtFine_labelIds.png', 37)
('frankfurt_000001_055062_leftImg8bit.png', 'frankfurt_000001_055062_gtFine_labelIds.png', 37)
('frankfurt_000001_055172_leftImg8bit.png', 'frankfurt_000001_055172_gtFine_labelIds.png', 38)
('frankfurt_000001_055306_leftImg8bit.png', 'frankfurt_000001_055306_gtFine_labelIds.png', 38)
('frankfurt_000001_055387_leftImg8bit.png', 'frankfurt_000001_055387_gtFine_labelIds.png', 38)
('frankfurt_000001_055538_leftImg8bit.png', 'frankfurt_000001_055538_gtFine_labelIds.png', 38)
('frankfurt_000001_055603_leftImg8bit.png', 'frankfurt_000001_055603_gtFine_labelIds.png', 38)
('frankfurt_000001_055709_leftImg8bit.png', 'frankfurt_000001_055709_gtFine_labelIds.png', 39)
('frankfurt_000001_056580_leftImg8bit.png', 'frankfurt_000001_056580_gtFine_labelIds.png', 39)
('frankfurt_000001_057181_leftImg8bit.png', 'frankfurt_000001_057181_gtFine_labelIds.png', 39)
('frankfurt_000001_057478_leftImg8bit.png', 'frankfurt_000001_057478_gtFine_labelIds.png', 39)
('frankfurt_000001_057954_leftImg8bit.png', 'frankfurt_000001_057954_gtFine_labelIds.png', 39)
pixel_accuracy=0.97147181353, mean_iou=0.843970618086, iou=[ 0.9534511   0.96125984  0.78457955  0.61906035  0.90150225]
('frankfurt_000001_058057_leftImg8bit.png', 'frankfurt_000001_058057_gtFine_labelIds.png', 40)
('frankfurt_000001_058176_leftImg8bit.png', 'frankfurt_000001_058176_gtFine_labelIds.png', 40)
('frankfurt_000001_058504_leftImg8bit.png', 'frankfurt_000001_058504_gtFine_labelIds.png', 40)
('frankfurt_000001_058914_leftImg8bit.png', 'frankfurt_000001_058914_gtFine_labelIds.png', 40)
('frankfurt_000001_059119_leftImg8bit.png', 'frankfurt_000001_059119_gtFine_labelIds.png', 40)
('frankfurt_000001_059642_leftImg8bit.png', 'frankfurt_000001_059642_gtFine_labelIds.png', 41)
('frankfurt_000001_059789_leftImg8bit.png', 'frankfurt_000001_059789_gtFine_labelIds.png', 41)
('frankfurt_000001_060135_leftImg8bit.png', 'frankfurt_000001_060135_gtFine_labelIds.png', 41)
('frankfurt_000001_060422_leftImg8bit.png', 'frankfurt_000001_060422_gtFine_labelIds.png', 41)
('frankfurt_000001_060545_leftImg8bit.png', 'frankfurt_000001_060545_gtFine_labelIds.png', 41)
('frankfurt_000001_060906_leftImg8bit.png', 'frankfurt_000001_060906_gtFine_labelIds.png', 42)
('frankfurt_000001_061682_leftImg8bit.png', 'frankfurt_000001_061682_gtFine_labelIds.png', 42)
('frankfurt_000001_061763_leftImg8bit.png', 'frankfurt_000001_061763_gtFine_labelIds.png', 42)
('frankfurt_000001_062016_leftImg8bit.png', 'frankfurt_000001_062016_gtFine_labelIds.png', 42)
('frankfurt_000001_062250_leftImg8bit.png', 'frankfurt_000001_062250_gtFine_labelIds.png', 42)
('frankfurt_000001_062396_leftImg8bit.png', 'frankfurt_000001_062396_gtFine_labelIds.png', 43)
('frankfurt_000001_062509_leftImg8bit.png', 'frankfurt_000001_062509_gtFine_labelIds.png', 43)
('frankfurt_000001_062653_leftImg8bit.png', 'frankfurt_000001_062653_gtFine_labelIds.png', 43)
('frankfurt_000001_062793_leftImg8bit.png', 'frankfurt_000001_062793_gtFine_labelIds.png', 43)
('frankfurt_000001_063045_leftImg8bit.png', 'frankfurt_000001_063045_gtFine_labelIds.png', 43)
('frankfurt_000001_064130_leftImg8bit.png', 'frankfurt_000001_064130_gtFine_labelIds.png', 44)
('frankfurt_000001_064305_leftImg8bit.png', 'frankfurt_000001_064305_gtFine_labelIds.png', 44)
('frankfurt_000001_064651_leftImg8bit.png', 'frankfurt_000001_064651_gtFine_labelIds.png', 44)
('frankfurt_000001_064798_leftImg8bit.png', 'frankfurt_000001_064798_gtFine_labelIds.png', 44)
('frankfurt_000001_064925_leftImg8bit.png', 'frankfurt_000001_064925_gtFine_labelIds.png', 44)
pixel_accuracy=0.972165665566, mean_iou=0.843972935061, iou=[ 0.9546116   0.96292011  0.78016491  0.6181776   0.90399045]
('frankfurt_000001_065160_leftImg8bit.png', 'frankfurt_000001_065160_gtFine_labelIds.png', 45)
('frankfurt_000001_065617_leftImg8bit.png', 'frankfurt_000001_065617_gtFine_labelIds.png', 45)
('frankfurt_000001_065850_leftImg8bit.png', 'frankfurt_000001_065850_gtFine_labelIds.png', 45)
('frankfurt_000001_066092_leftImg8bit.png', 'frankfurt_000001_066092_gtFine_labelIds.png', 45)
('frankfurt_000001_066438_leftImg8bit.png', 'frankfurt_000001_066438_gtFine_labelIds.png', 45)
('frankfurt_000001_066574_leftImg8bit.png', 'frankfurt_000001_066574_gtFine_labelIds.png', 46)
('frankfurt_000001_066832_leftImg8bit.png', 'frankfurt_000001_066832_gtFine_labelIds.png', 46)
('frankfurt_000001_067092_leftImg8bit.png', 'frankfurt_000001_067092_gtFine_labelIds.png', 46)
('frankfurt_000001_067178_leftImg8bit.png', 'frankfurt_000001_067178_gtFine_labelIds.png', 46)
('frankfurt_000001_067295_leftImg8bit.png', 'frankfurt_000001_067295_gtFine_labelIds.png', 46)
('frankfurt_000001_067474_leftImg8bit.png', 'frankfurt_000001_067474_gtFine_labelIds.png', 47)
('frankfurt_000001_067735_leftImg8bit.png', 'frankfurt_000001_067735_gtFine_labelIds.png', 47)
('frankfurt_000001_068063_leftImg8bit.png', 'frankfurt_000001_068063_gtFine_labelIds.png', 47)
('frankfurt_000001_068208_leftImg8bit.png', 'frankfurt_000001_068208_gtFine_labelIds.png', 47)
('frankfurt_000001_068682_leftImg8bit.png', 'frankfurt_000001_068682_gtFine_labelIds.png', 47)
('frankfurt_000001_068772_leftImg8bit.png', 'frankfurt_000001_068772_gtFine_labelIds.png', 48)
('frankfurt_000001_069633_leftImg8bit.png', 'frankfurt_000001_069633_gtFine_labelIds.png', 48)
('frankfurt_000001_070099_leftImg8bit.png', 'frankfurt_000001_070099_gtFine_labelIds.png', 48)
('frankfurt_000001_071288_leftImg8bit.png', 'frankfurt_000001_071288_gtFine_labelIds.png', 48)
('frankfurt_000001_071781_leftImg8bit.png', 'frankfurt_000001_071781_gtFine_labelIds.png', 48)
('frankfurt_000001_072155_leftImg8bit.png', 'frankfurt_000001_072155_gtFine_labelIds.png', 49)
('frankfurt_000001_072295_leftImg8bit.png', 'frankfurt_000001_072295_gtFine_labelIds.png', 49)
('frankfurt_000001_073088_leftImg8bit.png', 'frankfurt_000001_073088_gtFine_labelIds.png', 49)
('frankfurt_000001_073243_leftImg8bit.png', 'frankfurt_000001_073243_gtFine_labelIds.png', 49)
('frankfurt_000001_073464_leftImg8bit.png', 'frankfurt_000001_073464_gtFine_labelIds.png', 49)
pixel_accuracy=0.971554478501, mean_iou=0.841843411668, iou=[ 0.95345149  0.96149347  0.77825049  0.61172892  0.90429269]
('frankfurt_000001_073911_leftImg8bit.png', 'frankfurt_000001_073911_gtFine_labelIds.png', 50)
('frankfurt_000001_075296_leftImg8bit.png', 'frankfurt_000001_075296_gtFine_labelIds.png', 50)
('frankfurt_000001_075984_leftImg8bit.png', 'frankfurt_000001_075984_gtFine_labelIds.png', 50)
('frankfurt_000001_076502_leftImg8bit.png', 'frankfurt_000001_076502_gtFine_labelIds.png', 50)
('frankfurt_000001_077092_leftImg8bit.png', 'frankfurt_000001_077092_gtFine_labelIds.png', 50)
('frankfurt_000001_077233_leftImg8bit.png', 'frankfurt_000001_077233_gtFine_labelIds.png', 51)
('frankfurt_000001_077434_leftImg8bit.png', 'frankfurt_000001_077434_gtFine_labelIds.png', 51)
('frankfurt_000001_078803_leftImg8bit.png', 'frankfurt_000001_078803_gtFine_labelIds.png', 51)
('frankfurt_000001_079206_leftImg8bit.png', 'frankfurt_000001_079206_gtFine_labelIds.png', 51)
('frankfurt_000001_080091_leftImg8bit.png', 'frankfurt_000001_080091_gtFine_labelIds.png', 51)
('frankfurt_000001_080391_leftImg8bit.png', 'frankfurt_000001_080391_gtFine_labelIds.png', 52)
('frankfurt_000001_080830_leftImg8bit.png', 'frankfurt_000001_080830_gtFine_labelIds.png', 52)
('frankfurt_000001_082087_leftImg8bit.png', 'frankfurt_000001_082087_gtFine_labelIds.png', 52)
('frankfurt_000001_082466_leftImg8bit.png', 'frankfurt_000001_082466_gtFine_labelIds.png', 52)
('frankfurt_000001_083029_leftImg8bit.png', 'frankfurt_000001_083029_gtFine_labelIds.png', 52)
('frankfurt_000001_083199_leftImg8bit.png', 'frankfurt_000001_083199_gtFine_labelIds.png', 53)
('frankfurt_000001_083852_leftImg8bit.png', 'frankfurt_000001_083852_gtFine_labelIds.png', 53)
('lindau_000000_000019_leftImg8bit.png', 'lindau_000000_000019_gtFine_labelIds.png', 53)
('lindau_000001_000019_leftImg8bit.png', 'lindau_000001_000019_gtFine_labelIds.png', 53)
('lindau_000002_000019_leftImg8bit.png', 'lindau_000002_000019_gtFine_labelIds.png', 53)
('lindau_000003_000019_leftImg8bit.png', 'lindau_000003_000019_gtFine_labelIds.png', 54)
('lindau_000004_000019_leftImg8bit.png', 'lindau_000004_000019_gtFine_labelIds.png', 54)
('lindau_000005_000019_leftImg8bit.png', 'lindau_000005_000019_gtFine_labelIds.png', 54)
('lindau_000006_000019_leftImg8bit.png', 'lindau_000006_000019_gtFine_labelIds.png', 54)
('lindau_000007_000019_leftImg8bit.png', 'lindau_000007_000019_gtFine_labelIds.png', 54)
pixel_accuracy=0.97188773219, mean_iou=0.840700260474, iou=[ 0.95400066  0.96212386  0.77387782  0.60944114  0.90405783]
('lindau_000008_000019_leftImg8bit.png', 'lindau_000008_000019_gtFine_labelIds.png', 55)
('lindau_000009_000019_leftImg8bit.png', 'lindau_000009_000019_gtFine_labelIds.png', 55)
('lindau_000010_000019_leftImg8bit.png', 'lindau_000010_000019_gtFine_labelIds.png', 55)
('lindau_000011_000019_leftImg8bit.png', 'lindau_000011_000019_gtFine_labelIds.png', 55)
('lindau_000012_000019_leftImg8bit.png', 'lindau_000012_000019_gtFine_labelIds.png', 55)
('lindau_000013_000019_leftImg8bit.png', 'lindau_000013_000019_gtFine_labelIds.png', 56)
('lindau_000014_000019_leftImg8bit.png', 'lindau_000014_000019_gtFine_labelIds.png', 56)
('lindau_000015_000019_leftImg8bit.png', 'lindau_000015_000019_gtFine_labelIds.png', 56)
('lindau_000016_000019_leftImg8bit.png', 'lindau_000016_000019_gtFine_labelIds.png', 56)
('lindau_000017_000019_leftImg8bit.png', 'lindau_000017_000019_gtFine_labelIds.png', 56)
('lindau_000018_000019_leftImg8bit.png', 'lindau_000018_000019_gtFine_labelIds.png', 57)
('lindau_000019_000019_leftImg8bit.png', 'lindau_000019_000019_gtFine_labelIds.png', 57)
('lindau_000020_000019_leftImg8bit.png', 'lindau_000020_000019_gtFine_labelIds.png', 57)
('lindau_000021_000019_leftImg8bit.png', 'lindau_000021_000019_gtFine_labelIds.png', 57)
('lindau_000022_000019_leftImg8bit.png', 'lindau_000022_000019_gtFine_labelIds.png', 57)
('lindau_000023_000019_leftImg8bit.png', 'lindau_000023_000019_gtFine_labelIds.png', 58)
('lindau_000024_000019_leftImg8bit.png', 'lindau_000024_000019_gtFine_labelIds.png', 58)
('lindau_000025_000019_leftImg8bit.png', 'lindau_000025_000019_gtFine_labelIds.png', 58)
('lindau_000026_000019_leftImg8bit.png', 'lindau_000026_000019_gtFine_labelIds.png', 58)
('lindau_000027_000019_leftImg8bit.png', 'lindau_000027_000019_gtFine_labelIds.png', 58)
('lindau_000028_000019_leftImg8bit.png', 'lindau_000028_000019_gtFine_labelIds.png', 59)
('lindau_000029_000019_leftImg8bit.png', 'lindau_000029_000019_gtFine_labelIds.png', 59)
('lindau_000030_000019_leftImg8bit.png', 'lindau_000030_000019_gtFine_labelIds.png', 59)
('lindau_000031_000019_leftImg8bit.png', 'lindau_000031_000019_gtFine_labelIds.png', 59)
('lindau_000032_000019_leftImg8bit.png', 'lindau_000032_000019_gtFine_labelIds.png', 59)
pixel_accuracy=0.96731822367, mean_iou=0.836409640531, iou=[ 0.94692036  0.94779734  0.77115099  0.61516093  0.90101858]
('lindau_000033_000019_leftImg8bit.png', 'lindau_000033_000019_gtFine_labelIds.png', 60)
('lindau_000034_000019_leftImg8bit.png', 'lindau_000034_000019_gtFine_labelIds.png', 60)
('lindau_000035_000019_leftImg8bit.png', 'lindau_000035_000019_gtFine_labelIds.png', 60)
('lindau_000036_000019_leftImg8bit.png', 'lindau_000036_000019_gtFine_labelIds.png', 60)
('lindau_000037_000019_leftImg8bit.png', 'lindau_000037_000019_gtFine_labelIds.png', 60)
('lindau_000038_000019_leftImg8bit.png', 'lindau_000038_000019_gtFine_labelIds.png', 61)
('lindau_000039_000019_leftImg8bit.png', 'lindau_000039_000019_gtFine_labelIds.png', 61)
('lindau_000040_000019_leftImg8bit.png', 'lindau_000040_000019_gtFine_labelIds.png', 61)
('lindau_000041_000019_leftImg8bit.png', 'lindau_000041_000019_gtFine_labelIds.png', 61)
('lindau_000042_000019_leftImg8bit.png', 'lindau_000042_000019_gtFine_labelIds.png', 61)
('lindau_000043_000019_leftImg8bit.png', 'lindau_000043_000019_gtFine_labelIds.png', 62)
('lindau_000044_000019_leftImg8bit.png', 'lindau_000044_000019_gtFine_labelIds.png', 62)
('lindau_000045_000019_leftImg8bit.png', 'lindau_000045_000019_gtFine_labelIds.png', 62)
('lindau_000046_000019_leftImg8bit.png', 'lindau_000046_000019_gtFine_labelIds.png', 62)
('lindau_000047_000019_leftImg8bit.png', 'lindau_000047_000019_gtFine_labelIds.png', 62)
('lindau_000048_000019_leftImg8bit.png', 'lindau_000048_000019_gtFine_labelIds.png', 63)
('lindau_000049_000019_leftImg8bit.png', 'lindau_000049_000019_gtFine_labelIds.png', 63)
('lindau_000050_000019_leftImg8bit.png', 'lindau_000050_000019_gtFine_labelIds.png', 63)
('lindau_000051_000019_leftImg8bit.png', 'lindau_000051_000019_gtFine_labelIds.png', 63)
('lindau_000052_000019_leftImg8bit.png', 'lindau_000052_000019_gtFine_labelIds.png', 63)
('lindau_000053_000019_leftImg8bit.png', 'lindau_000053_000019_gtFine_labelIds.png', 64)
('lindau_000054_000019_leftImg8bit.png', 'lindau_000054_000019_gtFine_labelIds.png', 64)
('lindau_000055_000019_leftImg8bit.png', 'lindau_000055_000019_gtFine_labelIds.png', 64)
('lindau_000056_000019_leftImg8bit.png', 'lindau_000056_000019_gtFine_labelIds.png', 64)
('lindau_000057_000019_leftImg8bit.png', 'lindau_000057_000019_gtFine_labelIds.png', 64)
pixel_accuracy=0.958405435286, mean_iou=0.827825409707, iou=[ 0.93302602  0.92037946  0.76762549  0.61545232  0.90264376]
('lindau_000058_000019_leftImg8bit.png', 'lindau_000058_000019_gtFine_labelIds.png', 65)
('munster_000000_000019_leftImg8bit.png', 'munster_000000_000019_gtFine_labelIds.png', 65)
('munster_000001_000019_leftImg8bit.png', 'munster_000001_000019_gtFine_labelIds.png', 65)
('munster_000002_000019_leftImg8bit.png', 'munster_000002_000019_gtFine_labelIds.png', 65)
('munster_000003_000019_leftImg8bit.png', 'munster_000003_000019_gtFine_labelIds.png', 65)
('munster_000004_000019_leftImg8bit.png', 'munster_000004_000019_gtFine_labelIds.png', 66)
('munster_000005_000019_leftImg8bit.png', 'munster_000005_000019_gtFine_labelIds.png', 66)
('munster_000006_000019_leftImg8bit.png', 'munster_000006_000019_gtFine_labelIds.png', 66)
('munster_000007_000019_leftImg8bit.png', 'munster_000007_000019_gtFine_labelIds.png', 66)
('munster_000008_000019_leftImg8bit.png', 'munster_000008_000019_gtFine_labelIds.png', 66)
('munster_000009_000019_leftImg8bit.png', 'munster_000009_000019_gtFine_labelIds.png', 67)
('munster_000010_000019_leftImg8bit.png', 'munster_000010_000019_gtFine_labelIds.png', 67)
('munster_000011_000019_leftImg8bit.png', 'munster_000011_000019_gtFine_labelIds.png', 67)
('munster_000012_000019_leftImg8bit.png', 'munster_000012_000019_gtFine_labelIds.png', 67)
('munster_000013_000019_leftImg8bit.png', 'munster_000013_000019_gtFine_labelIds.png', 67)
('munster_000014_000019_leftImg8bit.png', 'munster_000014_000019_gtFine_labelIds.png', 68)
('munster_000015_000019_leftImg8bit.png', 'munster_000015_000019_gtFine_labelIds.png', 68)
('munster_000016_000019_leftImg8bit.png', 'munster_000016_000019_gtFine_labelIds.png', 68)
('munster_000017_000019_leftImg8bit.png', 'munster_000017_000019_gtFine_labelIds.png', 68)
('munster_000018_000019_leftImg8bit.png', 'munster_000018_000019_gtFine_labelIds.png', 68)
('munster_000019_000019_leftImg8bit.png', 'munster_000019_000019_gtFine_labelIds.png', 69)
('munster_000020_000019_leftImg8bit.png', 'munster_000020_000019_gtFine_labelIds.png', 69)
('munster_000021_000019_leftImg8bit.png', 'munster_000021_000019_gtFine_labelIds.png', 69)
('munster_000022_000019_leftImg8bit.png', 'munster_000022_000019_gtFine_labelIds.png', 69)
('munster_000023_000019_leftImg8bit.png', 'munster_000023_000019_gtFine_labelIds.png', 69)
pixel_accuracy=0.960045412699, mean_iou=0.830461133707, iou=[ 0.9355459   0.92424638  0.76665229  0.6204114   0.9054497 ]
('munster_000024_000019_leftImg8bit.png', 'munster_000024_000019_gtFine_labelIds.png', 70)
('munster_000025_000019_leftImg8bit.png', 'munster_000025_000019_gtFine_labelIds.png', 70)
('munster_000026_000019_leftImg8bit.png', 'munster_000026_000019_gtFine_labelIds.png', 70)
('munster_000027_000019_leftImg8bit.png', 'munster_000027_000019_gtFine_labelIds.png', 70)
('munster_000028_000019_leftImg8bit.png', 'munster_000028_000019_gtFine_labelIds.png', 70)
('munster_000029_000019_leftImg8bit.png', 'munster_000029_000019_gtFine_labelIds.png', 71)
('munster_000030_000019_leftImg8bit.png', 'munster_000030_000019_gtFine_labelIds.png', 71)
('munster_000031_000019_leftImg8bit.png', 'munster_000031_000019_gtFine_labelIds.png', 71)
('munster_000032_000019_leftImg8bit.png', 'munster_000032_000019_gtFine_labelIds.png', 71)
('munster_000033_000019_leftImg8bit.png', 'munster_000033_000019_gtFine_labelIds.png', 71)
('munster_000034_000019_leftImg8bit.png', 'munster_000034_000019_gtFine_labelIds.png', 72)
('munster_000035_000019_leftImg8bit.png', 'munster_000035_000019_gtFine_labelIds.png', 72)
('munster_000036_000019_leftImg8bit.png', 'munster_000036_000019_gtFine_labelIds.png', 72)
('munster_000037_000019_leftImg8bit.png', 'munster_000037_000019_gtFine_labelIds.png', 72)
('munster_000038_000019_leftImg8bit.png', 'munster_000038_000019_gtFine_labelIds.png', 72)
('munster_000039_000019_leftImg8bit.png', 'munster_000039_000019_gtFine_labelIds.png', 73)
('munster_000040_000019_leftImg8bit.png', 'munster_000040_000019_gtFine_labelIds.png', 73)
('munster_000041_000019_leftImg8bit.png', 'munster_000041_000019_gtFine_labelIds.png', 73)
('munster_000042_000019_leftImg8bit.png', 'munster_000042_000019_gtFine_labelIds.png', 73)
('munster_000043_000019_leftImg8bit.png', 'munster_000043_000019_gtFine_labelIds.png', 73)
('munster_000044_000019_leftImg8bit.png', 'munster_000044_000019_gtFine_labelIds.png', 74)
('munster_000045_000019_leftImg8bit.png', 'munster_000045_000019_gtFine_labelIds.png', 74)
('munster_000046_000019_leftImg8bit.png', 'munster_000046_000019_gtFine_labelIds.png', 74)
('munster_000047_000019_leftImg8bit.png', 'munster_000047_000019_gtFine_labelIds.png', 74)
('munster_000048_000019_leftImg8bit.png', 'munster_000048_000019_gtFine_labelIds.png', 74)
pixel_accuracy=0.961181643347, mean_iou=0.833986862354, iou=[ 0.93737181  0.92718015  0.77477301  0.62557802  0.90503132]
('munster_000049_000019_leftImg8bit.png', 'munster_000049_000019_gtFine_labelIds.png', 75)
('munster_000050_000019_leftImg8bit.png', 'munster_000050_000019_gtFine_labelIds.png', 75)
('munster_000051_000019_leftImg8bit.png', 'munster_000051_000019_gtFine_labelIds.png', 75)
('munster_000052_000019_leftImg8bit.png', 'munster_000052_000019_gtFine_labelIds.png', 75)
('munster_000053_000019_leftImg8bit.png', 'munster_000053_000019_gtFine_labelIds.png', 75)
('munster_000054_000019_leftImg8bit.png', 'munster_000054_000019_gtFine_labelIds.png', 76)
('munster_000055_000019_leftImg8bit.png', 'munster_000055_000019_gtFine_labelIds.png', 76)
('munster_000056_000019_leftImg8bit.png', 'munster_000056_000019_gtFine_labelIds.png', 76)
('munster_000057_000019_leftImg8bit.png', 'munster_000057_000019_gtFine_labelIds.png', 76)
('munster_000058_000019_leftImg8bit.png', 'munster_000058_000019_gtFine_labelIds.png', 76)
('munster_000059_000019_leftImg8bit.png', 'munster_000059_000019_gtFine_labelIds.png', 77)
('munster_000060_000019_leftImg8bit.png', 'munster_000060_000019_gtFine_labelIds.png', 77)
('munster_000061_000019_leftImg8bit.png', 'munster_000061_000019_gtFine_labelIds.png', 77)
('munster_000062_000019_leftImg8bit.png', 'munster_000062_000019_gtFine_labelIds.png', 77)
('munster_000063_000019_leftImg8bit.png', 'munster_000063_000019_gtFine_labelIds.png', 77)
('munster_000064_000019_leftImg8bit.png', 'munster_000064_000019_gtFine_labelIds.png', 78)
('munster_000065_000019_leftImg8bit.png', 'munster_000065_000019_gtFine_labelIds.png', 78)
('munster_000066_000019_leftImg8bit.png', 'munster_000066_000019_gtFine_labelIds.png', 78)
('munster_000067_000019_leftImg8bit.png', 'munster_000067_000019_gtFine_labelIds.png', 78)
('munster_000068_000019_leftImg8bit.png', 'munster_000068_000019_gtFine_labelIds.png', 78)
('munster_000069_000019_leftImg8bit.png', 'munster_000069_000019_gtFine_labelIds.png', 79)
('munster_000070_000019_leftImg8bit.png', 'munster_000070_000019_gtFine_labelIds.png', 79)
('munster_000071_000019_leftImg8bit.png', 'munster_000071_000019_gtFine_labelIds.png', 79)
('munster_000072_000019_leftImg8bit.png', 'munster_000072_000019_gtFine_labelIds.png', 79)
('munster_000073_000019_leftImg8bit.png', 'munster_000073_000019_gtFine_labelIds.png', 79)
pixel_accuracy=0.96228167395, mean_iou=0.836059045034, iou=[ 0.93905244  0.93027608  0.77454606  0.62946785  0.9069528 ]
('munster_000074_000019_leftImg8bit.png', 'munster_000074_000019_gtFine_labelIds.png', 80)
('munster_000075_000019_leftImg8bit.png', 'munster_000075_000019_gtFine_labelIds.png', 80)
('munster_000076_000019_leftImg8bit.png', 'munster_000076_000019_gtFine_labelIds.png', 80)
('munster_000077_000019_leftImg8bit.png', 'munster_000077_000019_gtFine_labelIds.png', 80)
('munster_000078_000019_leftImg8bit.png', 'munster_000078_000019_gtFine_labelIds.png', 80)
('munster_000079_000019_leftImg8bit.png', 'munster_000079_000019_gtFine_labelIds.png', 81)
('munster_000080_000019_leftImg8bit.png', 'munster_000080_000019_gtFine_labelIds.png', 81)
('munster_000081_000019_leftImg8bit.png', 'munster_000081_000019_gtFine_labelIds.png', 81)
('munster_000082_000019_leftImg8bit.png', 'munster_000082_000019_gtFine_labelIds.png', 81)
('munster_000083_000019_leftImg8bit.png', 'munster_000083_000019_gtFine_labelIds.png', 81)
('munster_000084_000019_leftImg8bit.png', 'munster_000084_000019_gtFine_labelIds.png', 82)
('munster_000085_000019_leftImg8bit.png', 'munster_000085_000019_gtFine_labelIds.png', 82)
('munster_000086_000019_leftImg8bit.png', 'munster_000086_000019_gtFine_labelIds.png', 82)
('munster_000087_000019_leftImg8bit.png', 'munster_000087_000019_gtFine_labelIds.png', 82)
('munster_000088_000019_leftImg8bit.png', 'munster_000088_000019_gtFine_labelIds.png', 82)
('munster_000089_000019_leftImg8bit.png', 'munster_000089_000019_gtFine_labelIds.png', 83)
('munster_000090_000019_leftImg8bit.png', 'munster_000090_000019_gtFine_labelIds.png', 83)
('munster_000091_000019_leftImg8bit.png', 'munster_000091_000019_gtFine_labelIds.png', 83)
('munster_000092_000019_leftImg8bit.png', 'munster_000092_000019_gtFine_labelIds.png', 83)
('munster_000093_000019_leftImg8bit.png', 'munster_000093_000019_gtFine_labelIds.png', 83)
('munster_000094_000019_leftImg8bit.png', 'munster_000094_000019_gtFine_labelIds.png', 84)
('munster_000095_000019_leftImg8bit.png', 'munster_000095_000019_gtFine_labelIds.png', 84)
('munster_000096_000019_leftImg8bit.png', 'munster_000096_000019_gtFine_labelIds.png', 84)
('munster_000097_000019_leftImg8bit.png', 'munster_000097_000019_gtFine_labelIds.png', 84)
('munster_000098_000019_leftImg8bit.png', 'munster_000098_000019_gtFine_labelIds.png', 84)
pixel_accuracy=0.96350338897, mean_iou=0.838305055609, iou=[ 0.94087553  0.93296163  0.77425953  0.63198063  0.91144796]
('munster_000099_000019_leftImg8bit.png', 'munster_000099_000019_gtFine_labelIds.png', 85)
('munster_000100_000019_leftImg8bit.png', 'munster_000100_000019_gtFine_labelIds.png', 85)
('munster_000101_000019_leftImg8bit.png', 'munster_000101_000019_gtFine_labelIds.png', 85)
('munster_000102_000019_leftImg8bit.png', 'munster_000102_000019_gtFine_labelIds.png', 85)
('munster_000103_000019_leftImg8bit.png', 'munster_000103_000019_gtFine_labelIds.png', 85)
('munster_000104_000019_leftImg8bit.png', 'munster_000104_000019_gtFine_labelIds.png', 86)
('munster_000105_000019_leftImg8bit.png', 'munster_000105_000019_gtFine_labelIds.png', 86)
('munster_000106_000019_leftImg8bit.png', 'munster_000106_000019_gtFine_labelIds.png', 86)
('munster_000107_000019_leftImg8bit.png', 'munster_000107_000019_gtFine_labelIds.png', 86)
('munster_000108_000019_leftImg8bit.png', 'munster_000108_000019_gtFine_labelIds.png', 86)
('munster_000109_000019_leftImg8bit.png', 'munster_000109_000019_gtFine_labelIds.png', 87)
('munster_000110_000019_leftImg8bit.png', 'munster_000110_000019_gtFine_labelIds.png', 87)
('munster_000111_000019_leftImg8bit.png', 'munster_000111_000019_gtFine_labelIds.png', 87)
('munster_000112_000019_leftImg8bit.png', 'munster_000112_000019_gtFine_labelIds.png', 87)
('munster_000113_000019_leftImg8bit.png', 'munster_000113_000019_gtFine_labelIds.png', 87)
('munster_000114_000019_leftImg8bit.png', 'munster_000114_000019_gtFine_labelIds.png', 88)
('munster_000115_000019_leftImg8bit.png', 'munster_000115_000019_gtFine_labelIds.png', 88)
('munster_000116_000019_leftImg8bit.png', 'munster_000116_000019_gtFine_labelIds.png', 88)
('munster_000117_000019_leftImg8bit.png', 'munster_000117_000019_gtFine_labelIds.png', 88)
('munster_000118_000019_leftImg8bit.png', 'munster_000118_000019_gtFine_labelIds.png', 88)
('munster_000119_000019_leftImg8bit.png', 'munster_000119_000019_gtFine_labelIds.png', 89)
('munster_000120_000019_leftImg8bit.png', 'munster_000120_000019_gtFine_labelIds.png', 89)
('munster_000121_000019_leftImg8bit.png', 'munster_000121_000019_gtFine_labelIds.png', 89)
('munster_000122_000019_leftImg8bit.png', 'munster_000122_000019_gtFine_labelIds.png', 89)
('munster_000123_000019_leftImg8bit.png', 'munster_000123_000019_gtFine_labelIds.png', 89)
pixel_accuracy=0.964833869587, mean_iou=0.839492197605, iou=[ 0.94295531  0.93594266  0.77350557  0.63168469  0.91337275]
('munster_000124_000019_leftImg8bit.png', 'munster_000124_000019_gtFine_labelIds.png', 90)
('munster_000125_000019_leftImg8bit.png', 'munster_000125_000019_gtFine_labelIds.png', 90)
('munster_000126_000019_leftImg8bit.png', 'munster_000126_000019_gtFine_labelIds.png', 90)
('munster_000127_000019_leftImg8bit.png', 'munster_000127_000019_gtFine_labelIds.png', 90)
('munster_000128_000019_leftImg8bit.png', 'munster_000128_000019_gtFine_labelIds.png', 90)
('munster_000129_000019_leftImg8bit.png', 'munster_000129_000019_gtFine_labelIds.png', 91)
('munster_000130_000019_leftImg8bit.png', 'munster_000130_000019_gtFine_labelIds.png', 91)
('munster_000131_000019_leftImg8bit.png', 'munster_000131_000019_gtFine_labelIds.png', 91)
('munster_000132_000019_leftImg8bit.png', 'munster_000132_000019_gtFine_labelIds.png', 91)
('munster_000133_000019_leftImg8bit.png', 'munster_000133_000019_gtFine_labelIds.png', 91)
('munster_000134_000019_leftImg8bit.png', 'munster_000134_000019_gtFine_labelIds.png', 92)
('munster_000135_000019_leftImg8bit.png', 'munster_000135_000019_gtFine_labelIds.png', 92)
('munster_000136_000019_leftImg8bit.png', 'munster_000136_000019_gtFine_labelIds.png', 92)
('munster_000137_000019_leftImg8bit.png', 'munster_000137_000019_gtFine_labelIds.png', 92)
('munster_000138_000019_leftImg8bit.png', 'munster_000138_000019_gtFine_labelIds.png', 92)
('munster_000139_000019_leftImg8bit.png', 'munster_000139_000019_gtFine_labelIds.png', 93)
('munster_000140_000019_leftImg8bit.png', 'munster_000140_000019_gtFine_labelIds.png', 93)
('munster_000141_000019_leftImg8bit.png', 'munster_000141_000019_gtFine_labelIds.png', 93)
('munster_000142_000019_leftImg8bit.png', 'munster_000142_000019_gtFine_labelIds.png', 93)
('munster_000143_000019_leftImg8bit.png', 'munster_000143_000019_gtFine_labelIds.png', 93)
('munster_000144_000019_leftImg8bit.png', 'munster_000144_000019_gtFine_labelIds.png', 94)
('munster_000145_000019_leftImg8bit.png', 'munster_000145_000019_gtFine_labelIds.png', 94)
('munster_000146_000019_leftImg8bit.png', 'munster_000146_000019_gtFine_labelIds.png', 94)
('munster_000147_000019_leftImg8bit.png', 'munster_000147_000019_gtFine_labelIds.png', 94)
('munster_000148_000019_leftImg8bit.png', 'munster_000148_000019_gtFine_labelIds.png', 94)
pixel_accuracy=0.96160498692, mean_iou=0.837559893079, iou=[ 0.93768933  0.92676659  0.77828509  0.63134555  0.9137129 ]
('munster_000149_000019_leftImg8bit.png', 'munster_000149_000019_gtFine_labelIds.png', 95)
('munster_000150_000019_leftImg8bit.png', 'munster_000150_000019_gtFine_labelIds.png', 95)
('munster_000151_000019_leftImg8bit.png', 'munster_000151_000019_gtFine_labelIds.png', 95)
('munster_000152_000019_leftImg8bit.png', 'munster_000152_000019_gtFine_labelIds.png', 95)
('munster_000153_000019_leftImg8bit.png', 'munster_000153_000019_gtFine_labelIds.png', 95)
('munster_000154_000019_leftImg8bit.png', 'munster_000154_000019_gtFine_labelIds.png', 96)
('munster_000155_000019_leftImg8bit.png', 'munster_000155_000019_gtFine_labelIds.png', 96)
('munster_000156_000019_leftImg8bit.png', 'munster_000156_000019_gtFine_labelIds.png', 96)
('munster_000157_000019_leftImg8bit.png', 'munster_000157_000019_gtFine_labelIds.png', 96)
('munster_000158_000019_leftImg8bit.png', 'munster_000158_000019_gtFine_labelIds.png', 96)
('munster_000159_000019_leftImg8bit.png', 'munster_000159_000019_gtFine_labelIds.png', 97)
('munster_000160_000019_leftImg8bit.png', 'munster_000160_000019_gtFine_labelIds.png', 97)
('munster_000161_000019_leftImg8bit.png', 'munster_000161_000019_gtFine_labelIds.png', 97)
('munster_000162_000019_leftImg8bit.png', 'munster_000162_000019_gtFine_labelIds.png', 97)
('munster_000163_000019_leftImg8bit.png', 'munster_000163_000019_gtFine_labelIds.png', 97)
('munster_000164_000019_leftImg8bit.png', 'munster_000164_000019_gtFine_labelIds.png', 98)
('munster_000165_000019_leftImg8bit.png', 'munster_000165_000019_gtFine_labelIds.png', 98)
('munster_000166_000019_leftImg8bit.png', 'munster_000166_000019_gtFine_labelIds.png', 98)
('munster_000167_000019_leftImg8bit.png', 'munster_000167_000019_gtFine_labelIds.png', 98)
('munster_000168_000019_leftImg8bit.png', 'munster_000168_000019_gtFine_labelIds.png', 98)
('munster_000169_000019_leftImg8bit.png', 'munster_000169_000019_gtFine_labelIds.png', 99)
('munster_000170_000019_leftImg8bit.png', 'munster_000170_000019_gtFine_labelIds.png', 99)
('munster_000171_000019_leftImg8bit.png', 'munster_000171_000019_gtFine_labelIds.png', 99)
('munster_000172_000019_leftImg8bit.png', 'munster_000172_000019_gtFine_labelIds.png', 99)
('munster_000173_000019_leftImg8bit.png', 'munster_000173_000019_gtFine_labelIds.png', 99)
pixel_accuracy=0.962218842053, mean_iou=0.839370371168, iou=[ 0.9387087   0.92810479  0.77845766  0.637117    0.91446371]
-------------------------------------------------------------
Final: pixel_accuracy=0.962218842053, mean_iou=0.839370371168, iou=[ 0.9387087   0.92810479  0.77845766  0.637117    0.91446371]
-------------------------------------------------------------
l1reg eval.
I0925 10:01:47.319156 14808 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0925 10:01:47.319847 14808 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8278441984, dev_info[0]: total=8506769408 free=8278441984
I0925 10:01:47.320421 14808 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0925 10:01:47.320976 14808 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8278441984, dev_info[0]: total=8506769408 free=8278441984
I0925 10:01:47.322618 14808 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: ../trained/image_segmentation/cityscapes5_jsegnet21v2/sparse/deploy.prototxt
I0925 10:01:47.322633 14808 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0925 10:01:47.322634 14808 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0925 10:01:47.322899 14808 net.cpp:72] Initializing net from parameters: 
name: "jsegnet21v2_deploy"
state {
  phase: TEST
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 1024
      dim: 2048
    }
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "out5a"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "out5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "out5a/bn"
  type: "BatchNorm"
  bottom: "out5a"
  top: "out5a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out5a/relu"
  type: "ReLU"
  bottom: "out5a"
  top: "out5a"
}
layer {
  name: "out5a_up2"
  type: "Deconvolution"
  bottom: "out5a"
  top: "out5a_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 64
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out3a"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "out3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "out3a/bn"
  type: "BatchNorm"
  bottom: "out3a"
  top: "out3a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out3a/relu"
  type: "ReLU"
  bottom: "out3a"
  top: "out3a"
}
layer {
  name: "out3_out5_combined"
  type: "Eltwise"
  bottom: "out5a_up2"
  bottom: "out3a"
  top: "out3_out5_combined"
}
layer {
  name: "ctx_conv1"
  type: "Convolution"
  bottom: "out3_out5_combined"
  top: "ctx_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_conv1/bn"
  type: "BatchNorm"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv1/relu"
  type: "ReLU"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
}
layer {
  name: "ctx_conv2"
  type: "Convolution"
  bottom: "ctx_conv1"
  top: "ctx_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv2/bn"
  type: "BatchNorm"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv2/relu"
  type: "ReLU"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
}
layer {
  name: "ctx_conv3"
  type: "Convolution"
  bottom: "ctx_conv2"
  top: "ctx_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv3/bn"
  type: "BatchNorm"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv3/relu"
  type: "ReLU"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
}
layer {
  name: "ctx_conv4"
  type: "Convolution"
  bottom: "ctx_conv3"
  top: "ctx_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv4/bn"
  type: "BatchNorm"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv4/relu"
  type: "ReLU"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
}
layer {
  name: "ctx_final"
  type: "Convolution"
  bottom: "ctx_conv4"
  top: "ctx_final"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_final/relu"
  type: "ReLU"
  bottom: "ctx_final"
  top: "ctx_final"
}
layer {
  name: "out_deconv_final_up2"
  type: "Deconvolution"
  bottom: "ctx_final"
  top: "out_deconv_final_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up4"
  type: "Deconvolution"
  bottom: "out_deconv_final_up2"
  top: "out_deconv_final_up4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up8"
  type: "Deconvolution"
  bottom: "out_deconv_final_up4"
  top: "out_deconv_final_up8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "argMaxOut"
  type: "ArgMax"
  bottom: "out_deconv_final_up8"
  top: "argMaxOut"
  argmax_param {
    axis: 1
  }
}
I0925 10:01:47.323021 14808 net.cpp:104] Using FLOAT as default forward math type
I0925 10:01:47.323026 14808 net.cpp:110] Using FLOAT as default backward math type
I0925 10:01:47.323029 14808 layer_factory.hpp:136] Creating layer 'input' of type 'Input'
I0925 10:01:47.323034 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.323042 14808 net.cpp:184] Created Layer input (0)
I0925 10:01:47.323045 14808 net.cpp:530] input -> data
I0925 10:01:47.323717 14808 net.cpp:245] Setting up input
I0925 10:01:47.323731 14808 net.cpp:252] TEST Top shape for layer 0 'input' 1 3 1024 2048 (6291456)
I0925 10:01:47.323734 14808 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0925 10:01:47.323743 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.323751 14808 net.cpp:184] Created Layer data/bias (1)
I0925 10:01:47.323755 14808 net.cpp:561] data/bias <- data
I0925 10:01:47.323757 14808 net.cpp:530] data/bias -> data/bias
I0925 10:01:47.328070 14808 net.cpp:245] Setting up data/bias
I0925 10:01:47.328088 14808 net.cpp:252] TEST Top shape for layer 1 'data/bias' 1 3 1024 2048 (6291456)
I0925 10:01:47.328096 14808 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0925 10:01:47.328100 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.328117 14808 net.cpp:184] Created Layer conv1a (2)
I0925 10:01:47.328120 14808 net.cpp:561] conv1a <- data/bias
I0925 10:01:47.328125 14808 net.cpp:530] conv1a -> conv1a
I0925 10:01:47.694998 14808 net.cpp:245] Setting up conv1a
I0925 10:01:47.695020 14808 net.cpp:252] TEST Top shape for layer 2 'conv1a' 1 32 512 1024 (16777216)
I0925 10:01:47.695030 14808 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0925 10:01:47.695035 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.695044 14808 net.cpp:184] Created Layer conv1a/bn (3)
I0925 10:01:47.695046 14808 net.cpp:561] conv1a/bn <- conv1a
I0925 10:01:47.695050 14808 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0925 10:01:47.695858 14808 net.cpp:245] Setting up conv1a/bn
I0925 10:01:47.695866 14808 net.cpp:252] TEST Top shape for layer 3 'conv1a/bn' 1 32 512 1024 (16777216)
I0925 10:01:47.695873 14808 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0925 10:01:47.695876 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.695880 14808 net.cpp:184] Created Layer conv1a/relu (4)
I0925 10:01:47.695883 14808 net.cpp:561] conv1a/relu <- conv1a
I0925 10:01:47.695885 14808 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0925 10:01:47.695894 14808 net.cpp:245] Setting up conv1a/relu
I0925 10:01:47.695896 14808 net.cpp:252] TEST Top shape for layer 4 'conv1a/relu' 1 32 512 1024 (16777216)
I0925 10:01:47.695899 14808 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0925 10:01:47.695900 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.695912 14808 net.cpp:184] Created Layer conv1b (5)
I0925 10:01:47.695915 14808 net.cpp:561] conv1b <- conv1a
I0925 10:01:47.695917 14808 net.cpp:530] conv1b -> conv1b
I0925 10:01:47.697434 14808 net.cpp:245] Setting up conv1b
I0925 10:01:47.697443 14808 net.cpp:252] TEST Top shape for layer 5 'conv1b' 1 32 512 1024 (16777216)
I0925 10:01:47.697448 14808 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0925 10:01:47.697450 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.697459 14808 net.cpp:184] Created Layer conv1b/bn (6)
I0925 10:01:47.697461 14808 net.cpp:561] conv1b/bn <- conv1b
I0925 10:01:47.697465 14808 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0925 10:01:47.698246 14808 net.cpp:245] Setting up conv1b/bn
I0925 10:01:47.698254 14808 net.cpp:252] TEST Top shape for layer 6 'conv1b/bn' 1 32 512 1024 (16777216)
I0925 10:01:47.698261 14808 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0925 10:01:47.698263 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.698266 14808 net.cpp:184] Created Layer conv1b/relu (7)
I0925 10:01:47.698268 14808 net.cpp:561] conv1b/relu <- conv1b
I0925 10:01:47.698271 14808 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0925 10:01:47.698274 14808 net.cpp:245] Setting up conv1b/relu
I0925 10:01:47.698276 14808 net.cpp:252] TEST Top shape for layer 7 'conv1b/relu' 1 32 512 1024 (16777216)
I0925 10:01:47.698278 14808 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0925 10:01:47.698290 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.698295 14808 net.cpp:184] Created Layer pool1 (8)
I0925 10:01:47.698297 14808 net.cpp:561] pool1 <- conv1b
I0925 10:01:47.698299 14808 net.cpp:530] pool1 -> pool1
I0925 10:01:47.698338 14808 net.cpp:245] Setting up pool1
I0925 10:01:47.698343 14808 net.cpp:252] TEST Top shape for layer 8 'pool1' 1 32 256 512 (4194304)
I0925 10:01:47.698344 14808 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0925 10:01:47.698346 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.698351 14808 net.cpp:184] Created Layer res2a_branch2a (9)
I0925 10:01:47.698354 14808 net.cpp:561] res2a_branch2a <- pool1
I0925 10:01:47.698355 14808 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0925 10:01:47.699451 14808 net.cpp:245] Setting up res2a_branch2a
I0925 10:01:47.699460 14808 net.cpp:252] TEST Top shape for layer 9 'res2a_branch2a' 1 64 256 512 (8388608)
I0925 10:01:47.699465 14808 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0925 10:01:47.699468 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.699473 14808 net.cpp:184] Created Layer res2a_branch2a/bn (10)
I0925 10:01:47.699476 14808 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0925 10:01:47.699478 14808 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0925 10:01:47.699892 14808 net.cpp:245] Setting up res2a_branch2a/bn
I0925 10:01:47.699898 14808 net.cpp:252] TEST Top shape for layer 10 'res2a_branch2a/bn' 1 64 256 512 (8388608)
I0925 10:01:47.699903 14808 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0925 10:01:47.699906 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.699909 14808 net.cpp:184] Created Layer res2a_branch2a/relu (11)
I0925 10:01:47.699911 14808 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0925 10:01:47.699913 14808 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0925 10:01:47.699918 14808 net.cpp:245] Setting up res2a_branch2a/relu
I0925 10:01:47.699919 14808 net.cpp:252] TEST Top shape for layer 11 'res2a_branch2a/relu' 1 64 256 512 (8388608)
I0925 10:01:47.699921 14808 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0925 10:01:47.699923 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.699936 14808 net.cpp:184] Created Layer res2a_branch2b (12)
I0925 10:01:47.699940 14808 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0925 10:01:47.699944 14808 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0925 10:01:47.700865 14808 net.cpp:245] Setting up res2a_branch2b
I0925 10:01:47.700875 14808 net.cpp:252] TEST Top shape for layer 12 'res2a_branch2b' 1 64 256 512 (8388608)
I0925 10:01:47.700880 14808 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0925 10:01:47.700881 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.700891 14808 net.cpp:184] Created Layer res2a_branch2b/bn (13)
I0925 10:01:47.700892 14808 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0925 10:01:47.700894 14808 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0925 10:01:47.701654 14808 net.cpp:245] Setting up res2a_branch2b/bn
I0925 10:01:47.701663 14808 net.cpp:252] TEST Top shape for layer 13 'res2a_branch2b/bn' 1 64 256 512 (8388608)
I0925 10:01:47.701668 14808 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0925 10:01:47.701671 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.701674 14808 net.cpp:184] Created Layer res2a_branch2b/relu (14)
I0925 10:01:47.701676 14808 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0925 10:01:47.701679 14808 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0925 10:01:47.701690 14808 net.cpp:245] Setting up res2a_branch2b/relu
I0925 10:01:47.701694 14808 net.cpp:252] TEST Top shape for layer 14 'res2a_branch2b/relu' 1 64 256 512 (8388608)
I0925 10:01:47.701695 14808 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0925 10:01:47.701699 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.701701 14808 net.cpp:184] Created Layer pool2 (15)
I0925 10:01:47.701704 14808 net.cpp:561] pool2 <- res2a_branch2b
I0925 10:01:47.701705 14808 net.cpp:530] pool2 -> pool2
I0925 10:01:47.701737 14808 net.cpp:245] Setting up pool2
I0925 10:01:47.701741 14808 net.cpp:252] TEST Top shape for layer 15 'pool2' 1 64 128 256 (2097152)
I0925 10:01:47.701745 14808 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0925 10:01:47.701746 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.701752 14808 net.cpp:184] Created Layer res3a_branch2a (16)
I0925 10:01:47.701755 14808 net.cpp:561] res3a_branch2a <- pool2
I0925 10:01:47.701756 14808 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0925 10:01:47.704262 14808 net.cpp:245] Setting up res3a_branch2a
I0925 10:01:47.704270 14808 net.cpp:252] TEST Top shape for layer 16 'res3a_branch2a' 1 128 128 256 (4194304)
I0925 10:01:47.704275 14808 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0925 10:01:47.704277 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.704282 14808 net.cpp:184] Created Layer res3a_branch2a/bn (17)
I0925 10:01:47.704284 14808 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0925 10:01:47.704286 14808 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0925 10:01:47.704691 14808 net.cpp:245] Setting up res3a_branch2a/bn
I0925 10:01:47.704699 14808 net.cpp:252] TEST Top shape for layer 17 'res3a_branch2a/bn' 1 128 128 256 (4194304)
I0925 10:01:47.704707 14808 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0925 10:01:47.704710 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.704712 14808 net.cpp:184] Created Layer res3a_branch2a/relu (18)
I0925 10:01:47.704715 14808 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0925 10:01:47.704717 14808 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0925 10:01:47.704720 14808 net.cpp:245] Setting up res3a_branch2a/relu
I0925 10:01:47.704722 14808 net.cpp:252] TEST Top shape for layer 18 'res3a_branch2a/relu' 1 128 128 256 (4194304)
I0925 10:01:47.704725 14808 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0925 10:01:47.704727 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.704732 14808 net.cpp:184] Created Layer res3a_branch2b (19)
I0925 10:01:47.704735 14808 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0925 10:01:47.704736 14808 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0925 10:01:47.705624 14808 net.cpp:245] Setting up res3a_branch2b
I0925 10:01:47.705631 14808 net.cpp:252] TEST Top shape for layer 19 'res3a_branch2b' 1 128 128 256 (4194304)
I0925 10:01:47.705634 14808 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0925 10:01:47.705637 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.705641 14808 net.cpp:184] Created Layer res3a_branch2b/bn (20)
I0925 10:01:47.705643 14808 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0925 10:01:47.705646 14808 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0925 10:01:47.706010 14808 net.cpp:245] Setting up res3a_branch2b/bn
I0925 10:01:47.706017 14808 net.cpp:252] TEST Top shape for layer 20 'res3a_branch2b/bn' 1 128 128 256 (4194304)
I0925 10:01:47.706022 14808 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0925 10:01:47.706024 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.706033 14808 net.cpp:184] Created Layer res3a_branch2b/relu (21)
I0925 10:01:47.706037 14808 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0925 10:01:47.706038 14808 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0925 10:01:47.706041 14808 net.cpp:245] Setting up res3a_branch2b/relu
I0925 10:01:47.706044 14808 net.cpp:252] TEST Top shape for layer 21 'res3a_branch2b/relu' 1 128 128 256 (4194304)
I0925 10:01:47.706046 14808 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0925 10:01:47.706049 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.706054 14808 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (22)
I0925 10:01:47.706056 14808 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0925 10:01:47.706058 14808 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0925 10:01:47.706061 14808 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0925 10:01:47.706082 14808 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0925 10:01:47.706087 14808 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b_res3a_branch2b/relu_0_split' 1 128 128 256 (4194304)
I0925 10:01:47.706089 14808 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b_res3a_branch2b/relu_0_split' 1 128 128 256 (4194304)
I0925 10:01:47.706091 14808 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0925 10:01:47.706094 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.706097 14808 net.cpp:184] Created Layer pool3 (23)
I0925 10:01:47.706099 14808 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0925 10:01:47.706102 14808 net.cpp:530] pool3 -> pool3
I0925 10:01:47.706140 14808 net.cpp:245] Setting up pool3
I0925 10:01:47.706145 14808 net.cpp:252] TEST Top shape for layer 23 'pool3' 1 128 64 128 (1048576)
I0925 10:01:47.706148 14808 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0925 10:01:47.706152 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.706161 14808 net.cpp:184] Created Layer res4a_branch2a (24)
I0925 10:01:47.706166 14808 net.cpp:561] res4a_branch2a <- pool3
I0925 10:01:47.706169 14808 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0925 10:01:47.712152 14808 net.cpp:245] Setting up res4a_branch2a
I0925 10:01:47.712162 14808 net.cpp:252] TEST Top shape for layer 24 'res4a_branch2a' 1 256 64 128 (2097152)
I0925 10:01:47.712168 14808 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0925 10:01:47.712174 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.712183 14808 net.cpp:184] Created Layer res4a_branch2a/bn (25)
I0925 10:01:47.712188 14808 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0925 10:01:47.712193 14808 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0925 10:01:47.712599 14808 net.cpp:245] Setting up res4a_branch2a/bn
I0925 10:01:47.712607 14808 net.cpp:252] TEST Top shape for layer 25 'res4a_branch2a/bn' 1 256 64 128 (2097152)
I0925 10:01:47.712615 14808 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0925 10:01:47.712620 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.712626 14808 net.cpp:184] Created Layer res4a_branch2a/relu (26)
I0925 10:01:47.712630 14808 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0925 10:01:47.712635 14808 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0925 10:01:47.712641 14808 net.cpp:245] Setting up res4a_branch2a/relu
I0925 10:01:47.712646 14808 net.cpp:252] TEST Top shape for layer 26 'res4a_branch2a/relu' 1 256 64 128 (2097152)
I0925 10:01:47.712649 14808 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0925 10:01:47.712663 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.712677 14808 net.cpp:184] Created Layer res4a_branch2b (27)
I0925 10:01:47.712682 14808 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0925 10:01:47.712685 14808 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0925 10:01:47.715876 14808 net.cpp:245] Setting up res4a_branch2b
I0925 10:01:47.715894 14808 net.cpp:252] TEST Top shape for layer 27 'res4a_branch2b' 1 256 64 128 (2097152)
I0925 10:01:47.715903 14808 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0925 10:01:47.715908 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.715917 14808 net.cpp:184] Created Layer res4a_branch2b/bn (28)
I0925 10:01:47.715921 14808 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0925 10:01:47.715926 14808 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0925 10:01:47.716338 14808 net.cpp:245] Setting up res4a_branch2b/bn
I0925 10:01:47.716346 14808 net.cpp:252] TEST Top shape for layer 28 'res4a_branch2b/bn' 1 256 64 128 (2097152)
I0925 10:01:47.716356 14808 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0925 10:01:47.716361 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.716365 14808 net.cpp:184] Created Layer res4a_branch2b/relu (29)
I0925 10:01:47.716370 14808 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0925 10:01:47.716373 14808 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0925 10:01:47.716380 14808 net.cpp:245] Setting up res4a_branch2b/relu
I0925 10:01:47.716384 14808 net.cpp:252] TEST Top shape for layer 29 'res4a_branch2b/relu' 1 256 64 128 (2097152)
I0925 10:01:47.716389 14808 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0925 10:01:47.716392 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.716399 14808 net.cpp:184] Created Layer pool4 (30)
I0925 10:01:47.716403 14808 net.cpp:561] pool4 <- res4a_branch2b
I0925 10:01:47.716408 14808 net.cpp:530] pool4 -> pool4
I0925 10:01:47.716442 14808 net.cpp:245] Setting up pool4
I0925 10:01:47.716447 14808 net.cpp:252] TEST Top shape for layer 30 'pool4' 1 256 64 128 (2097152)
I0925 10:01:47.716451 14808 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0925 10:01:47.716455 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.716465 14808 net.cpp:184] Created Layer res5a_branch2a (31)
I0925 10:01:47.716470 14808 net.cpp:561] res5a_branch2a <- pool4
I0925 10:01:47.716473 14808 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0925 10:01:47.741773 14808 net.cpp:245] Setting up res5a_branch2a
I0925 10:01:47.741792 14808 net.cpp:252] TEST Top shape for layer 31 'res5a_branch2a' 1 512 64 128 (4194304)
I0925 10:01:47.741801 14808 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0925 10:01:47.741807 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.741819 14808 net.cpp:184] Created Layer res5a_branch2a/bn (32)
I0925 10:01:47.741823 14808 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0925 10:01:47.741828 14808 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0925 10:01:47.742250 14808 net.cpp:245] Setting up res5a_branch2a/bn
I0925 10:01:47.742259 14808 net.cpp:252] TEST Top shape for layer 32 'res5a_branch2a/bn' 1 512 64 128 (4194304)
I0925 10:01:47.742267 14808 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0925 10:01:47.742272 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.742277 14808 net.cpp:184] Created Layer res5a_branch2a/relu (33)
I0925 10:01:47.742281 14808 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0925 10:01:47.742295 14808 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0925 10:01:47.742301 14808 net.cpp:245] Setting up res5a_branch2a/relu
I0925 10:01:47.742306 14808 net.cpp:252] TEST Top shape for layer 33 'res5a_branch2a/relu' 1 512 64 128 (4194304)
I0925 10:01:47.742311 14808 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0925 10:01:47.742314 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.742328 14808 net.cpp:184] Created Layer res5a_branch2b (34)
I0925 10:01:47.742331 14808 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0925 10:01:47.742336 14808 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0925 10:01:47.754748 14808 net.cpp:245] Setting up res5a_branch2b
I0925 10:01:47.754765 14808 net.cpp:252] TEST Top shape for layer 34 'res5a_branch2b' 1 512 64 128 (4194304)
I0925 10:01:47.754777 14808 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0925 10:01:47.754783 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.754793 14808 net.cpp:184] Created Layer res5a_branch2b/bn (35)
I0925 10:01:47.754797 14808 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0925 10:01:47.754802 14808 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0925 10:01:47.755193 14808 net.cpp:245] Setting up res5a_branch2b/bn
I0925 10:01:47.755200 14808 net.cpp:252] TEST Top shape for layer 35 'res5a_branch2b/bn' 1 512 64 128 (4194304)
I0925 10:01:47.755209 14808 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0925 10:01:47.755214 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.755219 14808 net.cpp:184] Created Layer res5a_branch2b/relu (36)
I0925 10:01:47.755223 14808 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0925 10:01:47.755228 14808 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0925 10:01:47.755234 14808 net.cpp:245] Setting up res5a_branch2b/relu
I0925 10:01:47.755237 14808 net.cpp:252] TEST Top shape for layer 36 'res5a_branch2b/relu' 1 512 64 128 (4194304)
I0925 10:01:47.755244 14808 layer_factory.hpp:136] Creating layer 'out5a' of type 'Convolution'
I0925 10:01:47.755247 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.755259 14808 net.cpp:184] Created Layer out5a (37)
I0925 10:01:47.755261 14808 net.cpp:561] out5a <- res5a_branch2b
I0925 10:01:47.755265 14808 net.cpp:530] out5a -> out5a
I0925 10:01:47.758945 14808 net.cpp:245] Setting up out5a
I0925 10:01:47.758955 14808 net.cpp:252] TEST Top shape for layer 37 'out5a' 1 64 64 128 (524288)
I0925 10:01:47.758962 14808 layer_factory.hpp:136] Creating layer 'out5a/bn' of type 'BatchNorm'
I0925 10:01:47.758967 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.758975 14808 net.cpp:184] Created Layer out5a/bn (38)
I0925 10:01:47.758978 14808 net.cpp:561] out5a/bn <- out5a
I0925 10:01:47.758981 14808 net.cpp:513] out5a/bn -> out5a (in-place)
I0925 10:01:47.759500 14808 net.cpp:245] Setting up out5a/bn
I0925 10:01:47.759507 14808 net.cpp:252] TEST Top shape for layer 38 'out5a/bn' 1 64 64 128 (524288)
I0925 10:01:47.759516 14808 layer_factory.hpp:136] Creating layer 'out5a/relu' of type 'ReLU'
I0925 10:01:47.759521 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.759526 14808 net.cpp:184] Created Layer out5a/relu (39)
I0925 10:01:47.759529 14808 net.cpp:561] out5a/relu <- out5a
I0925 10:01:47.759534 14808 net.cpp:513] out5a/relu -> out5a (in-place)
I0925 10:01:47.759541 14808 net.cpp:245] Setting up out5a/relu
I0925 10:01:47.759546 14808 net.cpp:252] TEST Top shape for layer 39 'out5a/relu' 1 64 64 128 (524288)
I0925 10:01:47.759551 14808 layer_factory.hpp:136] Creating layer 'out5a_up2' of type 'Deconvolution'
I0925 10:01:47.759553 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.759577 14808 net.cpp:184] Created Layer out5a_up2 (40)
I0925 10:01:47.759580 14808 net.cpp:561] out5a_up2 <- out5a
I0925 10:01:47.759583 14808 net.cpp:530] out5a_up2 -> out5a_up2
I0925 10:01:47.759724 14808 net.cpp:245] Setting up out5a_up2
I0925 10:01:47.759730 14808 net.cpp:252] TEST Top shape for layer 40 'out5a_up2' 1 64 128 256 (2097152)
I0925 10:01:47.759735 14808 layer_factory.hpp:136] Creating layer 'out3a' of type 'Convolution'
I0925 10:01:47.759739 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.759748 14808 net.cpp:184] Created Layer out3a (41)
I0925 10:01:47.759752 14808 net.cpp:561] out3a <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0925 10:01:47.759757 14808 net.cpp:530] out3a -> out3a
I0925 10:01:47.760670 14808 net.cpp:245] Setting up out3a
I0925 10:01:47.760679 14808 net.cpp:252] TEST Top shape for layer 41 'out3a' 1 64 128 256 (2097152)
I0925 10:01:47.760685 14808 layer_factory.hpp:136] Creating layer 'out3a/bn' of type 'BatchNorm'
I0925 10:01:47.760689 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.760699 14808 net.cpp:184] Created Layer out3a/bn (42)
I0925 10:01:47.760704 14808 net.cpp:561] out3a/bn <- out3a
I0925 10:01:47.760707 14808 net.cpp:513] out3a/bn -> out3a (in-place)
I0925 10:01:47.761121 14808 net.cpp:245] Setting up out3a/bn
I0925 10:01:47.761128 14808 net.cpp:252] TEST Top shape for layer 42 'out3a/bn' 1 64 128 256 (2097152)
I0925 10:01:47.761137 14808 layer_factory.hpp:136] Creating layer 'out3a/relu' of type 'ReLU'
I0925 10:01:47.761142 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.761145 14808 net.cpp:184] Created Layer out3a/relu (43)
I0925 10:01:47.761149 14808 net.cpp:561] out3a/relu <- out3a
I0925 10:01:47.761154 14808 net.cpp:513] out3a/relu -> out3a (in-place)
I0925 10:01:47.761160 14808 net.cpp:245] Setting up out3a/relu
I0925 10:01:47.761165 14808 net.cpp:252] TEST Top shape for layer 43 'out3a/relu' 1 64 128 256 (2097152)
I0925 10:01:47.761169 14808 layer_factory.hpp:136] Creating layer 'out3_out5_combined' of type 'Eltwise'
I0925 10:01:47.761174 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.761183 14808 net.cpp:184] Created Layer out3_out5_combined (44)
I0925 10:01:47.761186 14808 net.cpp:561] out3_out5_combined <- out5a_up2
I0925 10:01:47.761190 14808 net.cpp:561] out3_out5_combined <- out3a
I0925 10:01:47.761194 14808 net.cpp:530] out3_out5_combined -> out3_out5_combined
I0925 10:01:47.761216 14808 net.cpp:245] Setting up out3_out5_combined
I0925 10:01:47.761222 14808 net.cpp:252] TEST Top shape for layer 44 'out3_out5_combined' 1 64 128 256 (2097152)
I0925 10:01:47.761226 14808 layer_factory.hpp:136] Creating layer 'ctx_conv1' of type 'Convolution'
I0925 10:01:47.761230 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.761242 14808 net.cpp:184] Created Layer ctx_conv1 (45)
I0925 10:01:47.761246 14808 net.cpp:561] ctx_conv1 <- out3_out5_combined
I0925 10:01:47.761250 14808 net.cpp:530] ctx_conv1 -> ctx_conv1
I0925 10:01:47.762152 14808 net.cpp:245] Setting up ctx_conv1
I0925 10:01:47.762161 14808 net.cpp:252] TEST Top shape for layer 45 'ctx_conv1' 1 64 128 256 (2097152)
I0925 10:01:47.762166 14808 layer_factory.hpp:136] Creating layer 'ctx_conv1/bn' of type 'BatchNorm'
I0925 10:01:47.762171 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.762177 14808 net.cpp:184] Created Layer ctx_conv1/bn (46)
I0925 10:01:47.762181 14808 net.cpp:561] ctx_conv1/bn <- ctx_conv1
I0925 10:01:47.762186 14808 net.cpp:513] ctx_conv1/bn -> ctx_conv1 (in-place)
I0925 10:01:47.762589 14808 net.cpp:245] Setting up ctx_conv1/bn
I0925 10:01:47.762598 14808 net.cpp:252] TEST Top shape for layer 46 'ctx_conv1/bn' 1 64 128 256 (2097152)
I0925 10:01:47.762605 14808 layer_factory.hpp:136] Creating layer 'ctx_conv1/relu' of type 'ReLU'
I0925 10:01:47.762614 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.762619 14808 net.cpp:184] Created Layer ctx_conv1/relu (47)
I0925 10:01:47.762624 14808 net.cpp:561] ctx_conv1/relu <- ctx_conv1
I0925 10:01:47.762627 14808 net.cpp:513] ctx_conv1/relu -> ctx_conv1 (in-place)
I0925 10:01:47.762634 14808 net.cpp:245] Setting up ctx_conv1/relu
I0925 10:01:47.762639 14808 net.cpp:252] TEST Top shape for layer 47 'ctx_conv1/relu' 1 64 128 256 (2097152)
I0925 10:01:47.762642 14808 layer_factory.hpp:136] Creating layer 'ctx_conv2' of type 'Convolution'
I0925 10:01:47.762646 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.762660 14808 net.cpp:184] Created Layer ctx_conv2 (48)
I0925 10:01:47.762663 14808 net.cpp:561] ctx_conv2 <- ctx_conv1
I0925 10:01:47.762666 14808 net.cpp:530] ctx_conv2 -> ctx_conv2
I0925 10:01:47.763561 14808 net.cpp:245] Setting up ctx_conv2
I0925 10:01:47.763569 14808 net.cpp:252] TEST Top shape for layer 48 'ctx_conv2' 1 64 128 256 (2097152)
I0925 10:01:47.763576 14808 layer_factory.hpp:136] Creating layer 'ctx_conv2/bn' of type 'BatchNorm'
I0925 10:01:47.763579 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.763586 14808 net.cpp:184] Created Layer ctx_conv2/bn (49)
I0925 10:01:47.763589 14808 net.cpp:561] ctx_conv2/bn <- ctx_conv2
I0925 10:01:47.763593 14808 net.cpp:513] ctx_conv2/bn -> ctx_conv2 (in-place)
I0925 10:01:47.763999 14808 net.cpp:245] Setting up ctx_conv2/bn
I0925 10:01:47.764008 14808 net.cpp:252] TEST Top shape for layer 49 'ctx_conv2/bn' 1 64 128 256 (2097152)
I0925 10:01:47.764015 14808 layer_factory.hpp:136] Creating layer 'ctx_conv2/relu' of type 'ReLU'
I0925 10:01:47.764019 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.764024 14808 net.cpp:184] Created Layer ctx_conv2/relu (50)
I0925 10:01:47.764029 14808 net.cpp:561] ctx_conv2/relu <- ctx_conv2
I0925 10:01:47.764032 14808 net.cpp:513] ctx_conv2/relu -> ctx_conv2 (in-place)
I0925 10:01:47.764037 14808 net.cpp:245] Setting up ctx_conv2/relu
I0925 10:01:47.764042 14808 net.cpp:252] TEST Top shape for layer 50 'ctx_conv2/relu' 1 64 128 256 (2097152)
I0925 10:01:47.764047 14808 layer_factory.hpp:136] Creating layer 'ctx_conv3' of type 'Convolution'
I0925 10:01:47.764050 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.764063 14808 net.cpp:184] Created Layer ctx_conv3 (51)
I0925 10:01:47.764067 14808 net.cpp:561] ctx_conv3 <- ctx_conv2
I0925 10:01:47.764071 14808 net.cpp:530] ctx_conv3 -> ctx_conv3
I0925 10:01:47.764967 14808 net.cpp:245] Setting up ctx_conv3
I0925 10:01:47.764976 14808 net.cpp:252] TEST Top shape for layer 51 'ctx_conv3' 1 64 128 256 (2097152)
I0925 10:01:47.764981 14808 layer_factory.hpp:136] Creating layer 'ctx_conv3/bn' of type 'BatchNorm'
I0925 10:01:47.764986 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.764992 14808 net.cpp:184] Created Layer ctx_conv3/bn (52)
I0925 10:01:47.764997 14808 net.cpp:561] ctx_conv3/bn <- ctx_conv3
I0925 10:01:47.764999 14808 net.cpp:513] ctx_conv3/bn -> ctx_conv3 (in-place)
I0925 10:01:47.765406 14808 net.cpp:245] Setting up ctx_conv3/bn
I0925 10:01:47.765414 14808 net.cpp:252] TEST Top shape for layer 52 'ctx_conv3/bn' 1 64 128 256 (2097152)
I0925 10:01:47.765422 14808 layer_factory.hpp:136] Creating layer 'ctx_conv3/relu' of type 'ReLU'
I0925 10:01:47.765426 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.765430 14808 net.cpp:184] Created Layer ctx_conv3/relu (53)
I0925 10:01:47.765434 14808 net.cpp:561] ctx_conv3/relu <- ctx_conv3
I0925 10:01:47.765439 14808 net.cpp:513] ctx_conv3/relu -> ctx_conv3 (in-place)
I0925 10:01:47.765444 14808 net.cpp:245] Setting up ctx_conv3/relu
I0925 10:01:47.765447 14808 net.cpp:252] TEST Top shape for layer 53 'ctx_conv3/relu' 1 64 128 256 (2097152)
I0925 10:01:47.765457 14808 layer_factory.hpp:136] Creating layer 'ctx_conv4' of type 'Convolution'
I0925 10:01:47.765461 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.765470 14808 net.cpp:184] Created Layer ctx_conv4 (54)
I0925 10:01:47.765472 14808 net.cpp:561] ctx_conv4 <- ctx_conv3
I0925 10:01:47.765476 14808 net.cpp:530] ctx_conv4 -> ctx_conv4
I0925 10:01:47.766371 14808 net.cpp:245] Setting up ctx_conv4
I0925 10:01:47.766379 14808 net.cpp:252] TEST Top shape for layer 54 'ctx_conv4' 1 64 128 256 (2097152)
I0925 10:01:47.766384 14808 layer_factory.hpp:136] Creating layer 'ctx_conv4/bn' of type 'BatchNorm'
I0925 10:01:47.766389 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.766396 14808 net.cpp:184] Created Layer ctx_conv4/bn (55)
I0925 10:01:47.766399 14808 net.cpp:561] ctx_conv4/bn <- ctx_conv4
I0925 10:01:47.766402 14808 net.cpp:513] ctx_conv4/bn -> ctx_conv4 (in-place)
I0925 10:01:47.766827 14808 net.cpp:245] Setting up ctx_conv4/bn
I0925 10:01:47.766836 14808 net.cpp:252] TEST Top shape for layer 55 'ctx_conv4/bn' 1 64 128 256 (2097152)
I0925 10:01:47.766844 14808 layer_factory.hpp:136] Creating layer 'ctx_conv4/relu' of type 'ReLU'
I0925 10:01:47.766849 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.766854 14808 net.cpp:184] Created Layer ctx_conv4/relu (56)
I0925 10:01:47.766858 14808 net.cpp:561] ctx_conv4/relu <- ctx_conv4
I0925 10:01:47.766861 14808 net.cpp:513] ctx_conv4/relu -> ctx_conv4 (in-place)
I0925 10:01:47.766867 14808 net.cpp:245] Setting up ctx_conv4/relu
I0925 10:01:47.766872 14808 net.cpp:252] TEST Top shape for layer 56 'ctx_conv4/relu' 1 64 128 256 (2097152)
I0925 10:01:47.766876 14808 layer_factory.hpp:136] Creating layer 'ctx_final' of type 'Convolution'
I0925 10:01:47.766880 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.766898 14808 net.cpp:184] Created Layer ctx_final (57)
I0925 10:01:47.766902 14808 net.cpp:561] ctx_final <- ctx_conv4
I0925 10:01:47.766906 14808 net.cpp:530] ctx_final -> ctx_final
I0925 10:01:47.767176 14808 net.cpp:245] Setting up ctx_final
I0925 10:01:47.767184 14808 net.cpp:252] TEST Top shape for layer 57 'ctx_final' 1 8 128 256 (262144)
I0925 10:01:47.767191 14808 layer_factory.hpp:136] Creating layer 'ctx_final/relu' of type 'ReLU'
I0925 10:01:47.767195 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.767200 14808 net.cpp:184] Created Layer ctx_final/relu (58)
I0925 10:01:47.767204 14808 net.cpp:561] ctx_final/relu <- ctx_final
I0925 10:01:47.767207 14808 net.cpp:513] ctx_final/relu -> ctx_final (in-place)
I0925 10:01:47.767213 14808 net.cpp:245] Setting up ctx_final/relu
I0925 10:01:47.767217 14808 net.cpp:252] TEST Top shape for layer 58 'ctx_final/relu' 1 8 128 256 (262144)
I0925 10:01:47.767222 14808 layer_factory.hpp:136] Creating layer 'out_deconv_final_up2' of type 'Deconvolution'
I0925 10:01:47.767226 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.767233 14808 net.cpp:184] Created Layer out_deconv_final_up2 (59)
I0925 10:01:47.767237 14808 net.cpp:561] out_deconv_final_up2 <- ctx_final
I0925 10:01:47.767241 14808 net.cpp:530] out_deconv_final_up2 -> out_deconv_final_up2
I0925 10:01:47.767361 14808 net.cpp:245] Setting up out_deconv_final_up2
I0925 10:01:47.767367 14808 net.cpp:252] TEST Top shape for layer 59 'out_deconv_final_up2' 1 8 256 512 (1048576)
I0925 10:01:47.767372 14808 layer_factory.hpp:136] Creating layer 'out_deconv_final_up4' of type 'Deconvolution'
I0925 10:01:47.767376 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.767382 14808 net.cpp:184] Created Layer out_deconv_final_up4 (60)
I0925 10:01:47.767386 14808 net.cpp:561] out_deconv_final_up4 <- out_deconv_final_up2
I0925 10:01:47.767396 14808 net.cpp:530] out_deconv_final_up4 -> out_deconv_final_up4
I0925 10:01:47.767518 14808 net.cpp:245] Setting up out_deconv_final_up4
I0925 10:01:47.767524 14808 net.cpp:252] TEST Top shape for layer 60 'out_deconv_final_up4' 1 8 512 1024 (4194304)
I0925 10:01:47.767529 14808 layer_factory.hpp:136] Creating layer 'out_deconv_final_up8' of type 'Deconvolution'
I0925 10:01:47.767532 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.767539 14808 net.cpp:184] Created Layer out_deconv_final_up8 (61)
I0925 10:01:47.767544 14808 net.cpp:561] out_deconv_final_up8 <- out_deconv_final_up4
I0925 10:01:47.767546 14808 net.cpp:530] out_deconv_final_up8 -> out_deconv_final_up8
I0925 10:01:47.767668 14808 net.cpp:245] Setting up out_deconv_final_up8
I0925 10:01:47.767673 14808 net.cpp:252] TEST Top shape for layer 61 'out_deconv_final_up8' 1 8 1024 2048 (16777216)
I0925 10:01:47.767678 14808 layer_factory.hpp:136] Creating layer 'argMaxOut' of type 'ArgMax'
I0925 10:01:47.767683 14808 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:01:47.767696 14808 net.cpp:184] Created Layer argMaxOut (62)
I0925 10:01:47.767700 14808 net.cpp:561] argMaxOut <- out_deconv_final_up8
I0925 10:01:47.767704 14808 net.cpp:530] argMaxOut -> argMaxOut
I0925 10:01:47.767720 14808 net.cpp:245] Setting up argMaxOut
I0925 10:01:47.767725 14808 net.cpp:252] TEST Top shape for layer 62 'argMaxOut' 1 1 1024 2048 (2097152)
I0925 10:01:47.767729 14808 net.cpp:325] argMaxOut does not need backward computation.
I0925 10:01:47.767734 14808 net.cpp:325] out_deconv_final_up8 does not need backward computation.
I0925 10:01:47.767736 14808 net.cpp:325] out_deconv_final_up4 does not need backward computation.
I0925 10:01:47.767740 14808 net.cpp:325] out_deconv_final_up2 does not need backward computation.
I0925 10:01:47.767743 14808 net.cpp:325] ctx_final/relu does not need backward computation.
I0925 10:01:47.767746 14808 net.cpp:325] ctx_final does not need backward computation.
I0925 10:01:47.767755 14808 net.cpp:325] ctx_conv4/relu does not need backward computation.
I0925 10:01:47.767758 14808 net.cpp:325] ctx_conv4/bn does not need backward computation.
I0925 10:01:47.767761 14808 net.cpp:325] ctx_conv4 does not need backward computation.
I0925 10:01:47.767765 14808 net.cpp:325] ctx_conv3/relu does not need backward computation.
I0925 10:01:47.767767 14808 net.cpp:325] ctx_conv3/bn does not need backward computation.
I0925 10:01:47.767771 14808 net.cpp:325] ctx_conv3 does not need backward computation.
I0925 10:01:47.767772 14808 net.cpp:325] ctx_conv2/relu does not need backward computation.
I0925 10:01:47.767776 14808 net.cpp:325] ctx_conv2/bn does not need backward computation.
I0925 10:01:47.767778 14808 net.cpp:325] ctx_conv2 does not need backward computation.
I0925 10:01:47.767781 14808 net.cpp:325] ctx_conv1/relu does not need backward computation.
I0925 10:01:47.767784 14808 net.cpp:325] ctx_conv1/bn does not need backward computation.
I0925 10:01:47.767787 14808 net.cpp:325] ctx_conv1 does not need backward computation.
I0925 10:01:47.767791 14808 net.cpp:325] out3_out5_combined does not need backward computation.
I0925 10:01:47.767794 14808 net.cpp:325] out3a/relu does not need backward computation.
I0925 10:01:47.767798 14808 net.cpp:325] out3a/bn does not need backward computation.
I0925 10:01:47.767802 14808 net.cpp:325] out3a does not need backward computation.
I0925 10:01:47.767805 14808 net.cpp:325] out5a_up2 does not need backward computation.
I0925 10:01:47.767808 14808 net.cpp:325] out5a/relu does not need backward computation.
I0925 10:01:47.767812 14808 net.cpp:325] out5a/bn does not need backward computation.
I0925 10:01:47.767814 14808 net.cpp:325] out5a does not need backward computation.
I0925 10:01:47.767818 14808 net.cpp:325] res5a_branch2b/relu does not need backward computation.
I0925 10:01:47.767822 14808 net.cpp:325] res5a_branch2b/bn does not need backward computation.
I0925 10:01:47.767829 14808 net.cpp:325] res5a_branch2b does not need backward computation.
I0925 10:01:47.767832 14808 net.cpp:325] res5a_branch2a/relu does not need backward computation.
I0925 10:01:47.767835 14808 net.cpp:325] res5a_branch2a/bn does not need backward computation.
I0925 10:01:47.767839 14808 net.cpp:325] res5a_branch2a does not need backward computation.
I0925 10:01:47.767843 14808 net.cpp:325] pool4 does not need backward computation.
I0925 10:01:47.767846 14808 net.cpp:325] res4a_branch2b/relu does not need backward computation.
I0925 10:01:47.767849 14808 net.cpp:325] res4a_branch2b/bn does not need backward computation.
I0925 10:01:47.767853 14808 net.cpp:325] res4a_branch2b does not need backward computation.
I0925 10:01:47.767855 14808 net.cpp:325] res4a_branch2a/relu does not need backward computation.
I0925 10:01:47.767858 14808 net.cpp:325] res4a_branch2a/bn does not need backward computation.
I0925 10:01:47.767863 14808 net.cpp:325] res4a_branch2a does not need backward computation.
I0925 10:01:47.767865 14808 net.cpp:325] pool3 does not need backward computation.
I0925 10:01:47.767869 14808 net.cpp:325] res3a_branch2b_res3a_branch2b/relu_0_split does not need backward computation.
I0925 10:01:47.767874 14808 net.cpp:325] res3a_branch2b/relu does not need backward computation.
I0925 10:01:47.767876 14808 net.cpp:325] res3a_branch2b/bn does not need backward computation.
I0925 10:01:47.767879 14808 net.cpp:325] res3a_branch2b does not need backward computation.
I0925 10:01:47.767884 14808 net.cpp:325] res3a_branch2a/relu does not need backward computation.
I0925 10:01:47.767886 14808 net.cpp:325] res3a_branch2a/bn does not need backward computation.
I0925 10:01:47.767889 14808 net.cpp:325] res3a_branch2a does not need backward computation.
I0925 10:01:47.767892 14808 net.cpp:325] pool2 does not need backward computation.
I0925 10:01:47.767897 14808 net.cpp:325] res2a_branch2b/relu does not need backward computation.
I0925 10:01:47.767900 14808 net.cpp:325] res2a_branch2b/bn does not need backward computation.
I0925 10:01:47.767904 14808 net.cpp:325] res2a_branch2b does not need backward computation.
I0925 10:01:47.767907 14808 net.cpp:325] res2a_branch2a/relu does not need backward computation.
I0925 10:01:47.767910 14808 net.cpp:325] res2a_branch2a/bn does not need backward computation.
I0925 10:01:47.767913 14808 net.cpp:325] res2a_branch2a does not need backward computation.
I0925 10:01:47.767916 14808 net.cpp:325] pool1 does not need backward computation.
I0925 10:01:47.767920 14808 net.cpp:325] conv1b/relu does not need backward computation.
I0925 10:01:47.767923 14808 net.cpp:325] conv1b/bn does not need backward computation.
I0925 10:01:47.767926 14808 net.cpp:325] conv1b does not need backward computation.
I0925 10:01:47.767930 14808 net.cpp:325] conv1a/relu does not need backward computation.
I0925 10:01:47.767933 14808 net.cpp:325] conv1a/bn does not need backward computation.
I0925 10:01:47.767936 14808 net.cpp:325] conv1a does not need backward computation.
I0925 10:01:47.767940 14808 net.cpp:325] data/bias does not need backward computation.
I0925 10:01:47.767943 14808 net.cpp:325] input does not need backward computation.
I0925 10:01:47.767946 14808 net.cpp:367] This network produces output argMaxOut
I0925 10:01:47.767987 14808 net.cpp:389] Top memory (TEST) required for data: 1224736768 diff: 1224736768
I0925 10:01:47.767992 14808 net.cpp:392] Bottom memory (TEST) required for data: 1216348160 diff: 1216348160
I0925 10:01:47.767994 14808 net.cpp:395] Shared (in-place) memory (TEST) by data: 659554304 diff: 659554304
I0925 10:01:47.767997 14808 net.cpp:398] Parameters memory (TEST) required for data: 10817840 diff: 10817840
I0925 10:01:47.768002 14808 net.cpp:401] Parameters shared memory (TEST) by data: 0 diff: 0
I0925 10:01:47.768004 14808 net.cpp:407] Network initialization done.
I0925 10:01:47.773021 14808 net.cpp:1078] Ignoring source layer data
I0925 10:01:47.773041 14808 net.cpp:1094] Copying source layer data/bias Type:Bias #blobs=1
I0925 10:01:47.773072 14808 net.cpp:1094] Copying source layer conv1a Type:Convolution #blobs=2
I0925 10:01:47.773098 14808 net.cpp:1094] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0925 10:01:47.773248 14808 net.cpp:1094] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0925 10:01:47.773254 14808 net.cpp:1094] Copying source layer conv1b Type:Convolution #blobs=2
I0925 10:01:47.773267 14808 net.cpp:1094] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0925 10:01:47.773360 14808 net.cpp:1094] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0925 10:01:47.773365 14808 net.cpp:1094] Copying source layer pool1 Type:Pooling #blobs=0
I0925 10:01:47.773368 14808 net.cpp:1094] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0925 10:01:47.773386 14808 net.cpp:1094] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0925 10:01:47.773480 14808 net.cpp:1094] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0925 10:01:47.773485 14808 net.cpp:1094] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0925 10:01:47.773499 14808 net.cpp:1094] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0925 10:01:47.773587 14808 net.cpp:1094] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0925 10:01:47.773592 14808 net.cpp:1094] Copying source layer pool2 Type:Pooling #blobs=0
I0925 10:01:47.773597 14808 net.cpp:1094] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0925 10:01:47.773634 14808 net.cpp:1094] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0925 10:01:47.773721 14808 net.cpp:1094] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0925 10:01:47.773726 14808 net.cpp:1094] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0925 10:01:47.773751 14808 net.cpp:1094] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0925 10:01:47.773830 14808 net.cpp:1094] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0925 10:01:47.773835 14808 net.cpp:1094] Copying source layer res3a_branch2b_res3a_branch2b/relu_0_split Type:Split #blobs=0
I0925 10:01:47.773838 14808 net.cpp:1094] Copying source layer pool3 Type:Pooling #blobs=0
I0925 10:01:47.773841 14808 net.cpp:1094] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0925 10:01:47.773955 14808 net.cpp:1094] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0925 10:01:47.774039 14808 net.cpp:1094] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0925 10:01:47.774044 14808 net.cpp:1094] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0925 10:01:47.774102 14808 net.cpp:1094] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0925 10:01:47.774183 14808 net.cpp:1094] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0925 10:01:47.774188 14808 net.cpp:1094] Copying source layer pool4 Type:Pooling #blobs=0
I0925 10:01:47.774190 14808 net.cpp:1094] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0925 10:01:47.774529 14808 net.cpp:1094] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0925 10:01:47.774615 14808 net.cpp:1094] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0925 10:01:47.774619 14808 net.cpp:1094] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0925 10:01:47.774790 14808 net.cpp:1094] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0925 10:01:47.774868 14808 net.cpp:1094] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0925 10:01:47.774873 14808 net.cpp:1094] Copying source layer out5a Type:Convolution #blobs=2
I0925 10:01:47.774926 14808 net.cpp:1094] Copying source layer out5a/bn Type:BatchNorm #blobs=5
I0925 10:01:47.775019 14808 net.cpp:1094] Copying source layer out5a/relu Type:ReLU #blobs=0
I0925 10:01:47.775024 14808 net.cpp:1094] Copying source layer out5a_up2 Type:Deconvolution #blobs=1
I0925 10:01:47.775032 14808 net.cpp:1094] Copying source layer out3a Type:Convolution #blobs=2
I0925 10:01:47.775053 14808 net.cpp:1094] Copying source layer out3a/bn Type:BatchNorm #blobs=5
I0925 10:01:47.775149 14808 net.cpp:1094] Copying source layer out3a/relu Type:ReLU #blobs=0
I0925 10:01:47.775154 14808 net.cpp:1094] Copying source layer out3_out5_combined Type:Eltwise #blobs=0
I0925 10:01:47.775157 14808 net.cpp:1094] Copying source layer ctx_conv1 Type:Convolution #blobs=2
I0925 10:01:47.775179 14808 net.cpp:1094] Copying source layer ctx_conv1/bn Type:BatchNorm #blobs=5
I0925 10:01:47.775266 14808 net.cpp:1094] Copying source layer ctx_conv1/relu Type:ReLU #blobs=0
I0925 10:01:47.775271 14808 net.cpp:1094] Copying source layer ctx_conv2 Type:Convolution #blobs=2
I0925 10:01:47.775293 14808 net.cpp:1094] Copying source layer ctx_conv2/bn Type:BatchNorm #blobs=5
I0925 10:01:47.775380 14808 net.cpp:1094] Copying source layer ctx_conv2/relu Type:ReLU #blobs=0
I0925 10:01:47.775385 14808 net.cpp:1094] Copying source layer ctx_conv3 Type:Convolution #blobs=2
I0925 10:01:47.775408 14808 net.cpp:1094] Copying source layer ctx_conv3/bn Type:BatchNorm #blobs=5
I0925 10:01:47.775499 14808 net.cpp:1094] Copying source layer ctx_conv3/relu Type:ReLU #blobs=0
I0925 10:01:47.775504 14808 net.cpp:1094] Copying source layer ctx_conv4 Type:Convolution #blobs=2
I0925 10:01:47.775523 14808 net.cpp:1094] Copying source layer ctx_conv4/bn Type:BatchNorm #blobs=5
I0925 10:01:47.775610 14808 net.cpp:1094] Copying source layer ctx_conv4/relu Type:ReLU #blobs=0
I0925 10:01:47.775615 14808 net.cpp:1094] Copying source layer ctx_final Type:Convolution #blobs=2
I0925 10:01:47.775627 14808 net.cpp:1094] Copying source layer ctx_final/relu Type:ReLU #blobs=0
I0925 10:01:47.775630 14808 net.cpp:1094] Copying source layer out_deconv_final_up2 Type:Deconvolution #blobs=1
I0925 10:01:47.775638 14808 net.cpp:1094] Copying source layer out_deconv_final_up4 Type:Deconvolution #blobs=1
I0925 10:01:47.775646 14808 net.cpp:1094] Copying source layer out_deconv_final_up8 Type:Deconvolution #blobs=1
I0925 10:01:47.775655 14808 net.cpp:1078] Ignoring source layer loss
Namespace(batch_size=1, blend=False, class_dict='', crop=['0'], input='./data/val-image-list.txt', label='./data/val-label-list.txt', label_dict='', model='../trained/image_segmentation/cityscapes5_jsegnet21v2/sparse/deploy.prototxt', num_classes=5, num_images=500, output=None, palette='', resize=['0'], resize_back=True, search='*.png', weights='../trained/image_segmentation/cityscapes5_jsegnet21v2/sparse/cityscapes5_jsegnet21v2_iter_60000.caffemodel')
Infering list
Getting list of images...running inference for  500  images...
('frankfurt_000000_000294_leftImg8bit.png', 'frankfurt_000000_000294_gtFine_labelIds.png', 0)
('frankfurt_000000_000576_leftImg8bit.png', 'frankfurt_000000_000576_gtFine_labelIds.png', 0)
('frankfurt_000000_001016_leftImg8bit.png', 'frankfurt_000000_001016_gtFine_labelIds.png', 0)
I0925 10:01:48.585053 14808 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1a' with space 0.01G 3/1 1 	(avail 5.89G, req 0.01G)	t: 0
I0925 10:01:48.714310 14808 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1b' with space 0.01G 32/4 6 	(avail 5.89G, req 0.01G)	t: 0
I0925 10:01:48.731748 14808 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2a' with space 0.01G 32/1 6 	(avail 5.89G, req 0.01G)	t: 0
I0925 10:01:48.769992 14808 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2b' with space 0.01G 64/4 6 	(avail 5.89G, req 0.01G)	t: 0
I0925 10:01:48.780865 14808 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2a' with space 0.01G 64/1 6 	(avail 5.89G, req 0.01G)	t: 0
I0925 10:01:48.785037 14808 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2b' with space 0.01G 128/4 6 	(avail 5.89G, req 0.01G)	t: 0
I0925 10:01:48.794605 14808 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2a' with space 0.01G 128/1 6 	(avail 5.89G, req 0.01G)	t: 0
I0925 10:01:48.798171 14808 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2b' with space 0.01G 256/4 6 	(avail 5.89G, req 0.01G)	t: 0
I0925 10:01:48.812430 14808 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'out3a' with space 0.01G 128/2 6 	(avail 5.89G, req 0.01G)	t: 0
I0925 10:01:48.819243 14808 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_conv1' with space 0.01G 64/1 6 	(avail 5.89G, req 0.01G)	t: 0
I0925 10:01:48.844647 14808 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_final' with space 0.01G 64/1 6 	(avail 5.89G, req 0.01G)	t: 0
('frankfurt_000000_001236_leftImg8bit.png', 'frankfurt_000000_001236_gtFine_labelIds.png', 0)
('frankfurt_000000_001751_leftImg8bit.png', 'frankfurt_000000_001751_gtFine_labelIds.png', 0)
('frankfurt_000000_002196_leftImg8bit.png', 'frankfurt_000000_002196_gtFine_labelIds.png', 1)
('frankfurt_000000_002963_leftImg8bit.png', 'frankfurt_000000_002963_gtFine_labelIds.png', 1)
('frankfurt_000000_003025_leftImg8bit.png', 'frankfurt_000000_003025_gtFine_labelIds.png', 1)
('frankfurt_000000_003357_leftImg8bit.png', 'frankfurt_000000_003357_gtFine_labelIds.png', 1)
('frankfurt_000000_003920_leftImg8bit.png', 'frankfurt_000000_003920_gtFine_labelIds.png', 1)
('frankfurt_000000_004617_leftImg8bit.png', 'frankfurt_000000_004617_gtFine_labelIds.png', 2)
('frankfurt_000000_005543_leftImg8bit.png', 'frankfurt_000000_005543_gtFine_labelIds.png', 2)
('frankfurt_000000_005898_leftImg8bit.png', 'frankfurt_000000_005898_gtFine_labelIds.png', 2)
('frankfurt_000000_006589_leftImg8bit.png', 'frankfurt_000000_006589_gtFine_labelIds.png', 2)
('frankfurt_000000_007365_leftImg8bit.png', 'frankfurt_000000_007365_gtFine_labelIds.png', 2)
('frankfurt_000000_008206_leftImg8bit.png', 'frankfurt_000000_008206_gtFine_labelIds.png', 3)
('frankfurt_000000_008451_leftImg8bit.png', 'frankfurt_000000_008451_gtFine_labelIds.png', 3)
('frankfurt_000000_009291_leftImg8bit.png', 'frankfurt_000000_009291_gtFine_labelIds.png', 3)
('frankfurt_000000_009561_leftImg8bit.png', 'frankfurt_000000_009561_gtFine_labelIds.png', 3)
('frankfurt_000000_009688_leftImg8bit.png', 'frankfurt_000000_009688_gtFine_labelIds.png', 3)
('frankfurt_000000_009969_leftImg8bit.png', 'frankfurt_000000_009969_gtFine_labelIds.png', 4)
('frankfurt_000000_010351_leftImg8bit.png', 'frankfurt_000000_010351_gtFine_labelIds.png', 4)
('frankfurt_000000_010763_leftImg8bit.png', 'frankfurt_000000_010763_gtFine_labelIds.png', 4)
('frankfurt_000000_011007_leftImg8bit.png', 'frankfurt_000000_011007_gtFine_labelIds.png', 4)
('frankfurt_000000_011074_leftImg8bit.png', 'frankfurt_000000_011074_gtFine_labelIds.png', 4)
pixel_accuracy=0.974619713189, mean_iou=0.827874724031, iou=[ 0.9573228   0.9616617   0.76134142  0.56018358  0.89886413]
('frankfurt_000000_011461_leftImg8bit.png', 'frankfurt_000000_011461_gtFine_labelIds.png', 5)
('frankfurt_000000_011810_leftImg8bit.png', 'frankfurt_000000_011810_gtFine_labelIds.png', 5)
('frankfurt_000000_012009_leftImg8bit.png', 'frankfurt_000000_012009_gtFine_labelIds.png', 5)
('frankfurt_000000_012121_leftImg8bit.png', 'frankfurt_000000_012121_gtFine_labelIds.png', 5)
('frankfurt_000000_012868_leftImg8bit.png', 'frankfurt_000000_012868_gtFine_labelIds.png', 5)
('frankfurt_000000_013067_leftImg8bit.png', 'frankfurt_000000_013067_gtFine_labelIds.png', 6)
('frankfurt_000000_013240_leftImg8bit.png', 'frankfurt_000000_013240_gtFine_labelIds.png', 6)
('frankfurt_000000_013382_leftImg8bit.png', 'frankfurt_000000_013382_gtFine_labelIds.png', 6)
('frankfurt_000000_013942_leftImg8bit.png', 'frankfurt_000000_013942_gtFine_labelIds.png', 6)
('frankfurt_000000_014480_leftImg8bit.png', 'frankfurt_000000_014480_gtFine_labelIds.png', 6)
('frankfurt_000000_015389_leftImg8bit.png', 'frankfurt_000000_015389_gtFine_labelIds.png', 7)
('frankfurt_000000_015676_leftImg8bit.png', 'frankfurt_000000_015676_gtFine_labelIds.png', 7)
('frankfurt_000000_016005_leftImg8bit.png', 'frankfurt_000000_016005_gtFine_labelIds.png', 7)
('frankfurt_000000_016286_leftImg8bit.png', 'frankfurt_000000_016286_gtFine_labelIds.png', 7)
('frankfurt_000000_017228_leftImg8bit.png', 'frankfurt_000000_017228_gtFine_labelIds.png', 7)
('frankfurt_000000_017476_leftImg8bit.png', 'frankfurt_000000_017476_gtFine_labelIds.png', 8)
('frankfurt_000000_018797_leftImg8bit.png', 'frankfurt_000000_018797_gtFine_labelIds.png', 8)
('frankfurt_000000_019607_leftImg8bit.png', 'frankfurt_000000_019607_gtFine_labelIds.png', 8)
('frankfurt_000000_020215_leftImg8bit.png', 'frankfurt_000000_020215_gtFine_labelIds.png', 8)
('frankfurt_000000_020321_leftImg8bit.png', 'frankfurt_000000_020321_gtFine_labelIds.png', 8)
('frankfurt_000000_020880_leftImg8bit.png', 'frankfurt_000000_020880_gtFine_labelIds.png', 9)
('frankfurt_000000_021667_leftImg8bit.png', 'frankfurt_000000_021667_gtFine_labelIds.png', 9)
('frankfurt_000000_021879_leftImg8bit.png', 'frankfurt_000000_021879_gtFine_labelIds.png', 9)
('frankfurt_000000_022254_leftImg8bit.png', 'frankfurt_000000_022254_gtFine_labelIds.png', 9)
('frankfurt_000000_022797_leftImg8bit.png', 'frankfurt_000000_022797_gtFine_labelIds.png', 9)
pixel_accuracy=0.973945572536, mean_iou=0.835565715962, iou=[ 0.9565774   0.96451372  0.77160591  0.59158097  0.89355058]
('frankfurt_000001_000538_leftImg8bit.png', 'frankfurt_000001_000538_gtFine_labelIds.png', 10)
('frankfurt_000001_001464_leftImg8bit.png', 'frankfurt_000001_001464_gtFine_labelIds.png', 10)
('frankfurt_000001_002512_leftImg8bit.png', 'frankfurt_000001_002512_gtFine_labelIds.png', 10)
('frankfurt_000001_002646_leftImg8bit.png', 'frankfurt_000001_002646_gtFine_labelIds.png', 10)
('frankfurt_000001_002759_leftImg8bit.png', 'frankfurt_000001_002759_gtFine_labelIds.png', 10)
('frankfurt_000001_003056_leftImg8bit.png', 'frankfurt_000001_003056_gtFine_labelIds.png', 11)
('frankfurt_000001_003588_leftImg8bit.png', 'frankfurt_000001_003588_gtFine_labelIds.png', 11)
('frankfurt_000001_004327_leftImg8bit.png', 'frankfurt_000001_004327_gtFine_labelIds.png', 11)
('frankfurt_000001_004736_leftImg8bit.png', 'frankfurt_000001_004736_gtFine_labelIds.png', 11)
('frankfurt_000001_004859_leftImg8bit.png', 'frankfurt_000001_004859_gtFine_labelIds.png', 11)
('frankfurt_000001_005184_leftImg8bit.png', 'frankfurt_000001_005184_gtFine_labelIds.png', 12)
('frankfurt_000001_005410_leftImg8bit.png', 'frankfurt_000001_005410_gtFine_labelIds.png', 12)
('frankfurt_000001_005703_leftImg8bit.png', 'frankfurt_000001_005703_gtFine_labelIds.png', 12)
('frankfurt_000001_005898_leftImg8bit.png', 'frankfurt_000001_005898_gtFine_labelIds.png', 12)
('frankfurt_000001_007285_leftImg8bit.png', 'frankfurt_000001_007285_gtFine_labelIds.png', 12)
('frankfurt_000001_007407_leftImg8bit.png', 'frankfurt_000001_007407_gtFine_labelIds.png', 13)
('frankfurt_000001_007622_leftImg8bit.png', 'frankfurt_000001_007622_gtFine_labelIds.png', 13)
('frankfurt_000001_007857_leftImg8bit.png', 'frankfurt_000001_007857_gtFine_labelIds.png', 13)
('frankfurt_000001_007973_leftImg8bit.png', 'frankfurt_000001_007973_gtFine_labelIds.png', 13)
('frankfurt_000001_008200_leftImg8bit.png', 'frankfurt_000001_008200_gtFine_labelIds.png', 13)
('frankfurt_000001_008688_leftImg8bit.png', 'frankfurt_000001_008688_gtFine_labelIds.png', 14)
('frankfurt_000001_009058_leftImg8bit.png', 'frankfurt_000001_009058_gtFine_labelIds.png', 14)
('frankfurt_000001_009504_leftImg8bit.png', 'frankfurt_000001_009504_gtFine_labelIds.png', 14)
('frankfurt_000001_009854_leftImg8bit.png', 'frankfurt_000001_009854_gtFine_labelIds.png', 14)
('frankfurt_000001_010156_leftImg8bit.png', 'frankfurt_000001_010156_gtFine_labelIds.png', 14)
pixel_accuracy=0.972450572545, mean_iou=0.832375127666, iou=[ 0.95408647  0.96271765  0.75665995  0.59873425  0.88967731]
('frankfurt_000001_010444_leftImg8bit.png', 'frankfurt_000001_010444_gtFine_labelIds.png', 15)
('frankfurt_000001_010600_leftImg8bit.png', 'frankfurt_000001_010600_gtFine_labelIds.png', 15)
('frankfurt_000001_010830_leftImg8bit.png', 'frankfurt_000001_010830_gtFine_labelIds.png', 15)
('frankfurt_000001_011162_leftImg8bit.png', 'frankfurt_000001_011162_gtFine_labelIds.png', 15)
('frankfurt_000001_011715_leftImg8bit.png', 'frankfurt_000001_011715_gtFine_labelIds.png', 15)
('frankfurt_000001_011835_leftImg8bit.png', 'frankfurt_000001_011835_gtFine_labelIds.png', 16)
('frankfurt_000001_012038_leftImg8bit.png', 'frankfurt_000001_012038_gtFine_labelIds.png', 16)
('frankfurt_000001_012519_leftImg8bit.png', 'frankfurt_000001_012519_gtFine_labelIds.png', 16)
('frankfurt_000001_012699_leftImg8bit.png', 'frankfurt_000001_012699_gtFine_labelIds.png', 16)
('frankfurt_000001_012738_leftImg8bit.png', 'frankfurt_000001_012738_gtFine_labelIds.png', 16)
('frankfurt_000001_012870_leftImg8bit.png', 'frankfurt_000001_012870_gtFine_labelIds.png', 17)
('frankfurt_000001_013016_leftImg8bit.png', 'frankfurt_000001_013016_gtFine_labelIds.png', 17)
('frankfurt_000001_013496_leftImg8bit.png', 'frankfurt_000001_013496_gtFine_labelIds.png', 17)
('frankfurt_000001_013710_leftImg8bit.png', 'frankfurt_000001_013710_gtFine_labelIds.png', 17)
('frankfurt_000001_014221_leftImg8bit.png', 'frankfurt_000001_014221_gtFine_labelIds.png', 17)
('frankfurt_000001_014406_leftImg8bit.png', 'frankfurt_000001_014406_gtFine_labelIds.png', 18)
('frankfurt_000001_014565_leftImg8bit.png', 'frankfurt_000001_014565_gtFine_labelIds.png', 18)
('frankfurt_000001_014741_leftImg8bit.png', 'frankfurt_000001_014741_gtFine_labelIds.png', 18)
('frankfurt_000001_015091_leftImg8bit.png', 'frankfurt_000001_015091_gtFine_labelIds.png', 18)
('frankfurt_000001_015328_leftImg8bit.png', 'frankfurt_000001_015328_gtFine_labelIds.png', 18)
('frankfurt_000001_015768_leftImg8bit.png', 'frankfurt_000001_015768_gtFine_labelIds.png', 19)
('frankfurt_000001_016029_leftImg8bit.png', 'frankfurt_000001_016029_gtFine_labelIds.png', 19)
('frankfurt_000001_016273_leftImg8bit.png', 'frankfurt_000001_016273_gtFine_labelIds.png', 19)
('frankfurt_000001_016462_leftImg8bit.png', 'frankfurt_000001_016462_gtFine_labelIds.png', 19)
('frankfurt_000001_017101_leftImg8bit.png', 'frankfurt_000001_017101_gtFine_labelIds.png', 19)
pixel_accuracy=0.96907724439, mean_iou=0.83793888788, iou=[ 0.94919874  0.95705236  0.77951894  0.61489863  0.88902576]
('frankfurt_000001_017459_leftImg8bit.png', 'frankfurt_000001_017459_gtFine_labelIds.png', 20)
('frankfurt_000001_017842_leftImg8bit.png', 'frankfurt_000001_017842_gtFine_labelIds.png', 20)
('frankfurt_000001_018113_leftImg8bit.png', 'frankfurt_000001_018113_gtFine_labelIds.png', 20)
('frankfurt_000001_019698_leftImg8bit.png', 'frankfurt_000001_019698_gtFine_labelIds.png', 20)
('frankfurt_000001_019854_leftImg8bit.png', 'frankfurt_000001_019854_gtFine_labelIds.png', 20)
('frankfurt_000001_019969_leftImg8bit.png', 'frankfurt_000001_019969_gtFine_labelIds.png', 21)
('frankfurt_000001_020046_leftImg8bit.png', 'frankfurt_000001_020046_gtFine_labelIds.png', 21)
('frankfurt_000001_020287_leftImg8bit.png', 'frankfurt_000001_020287_gtFine_labelIds.png', 21)
('frankfurt_000001_020693_leftImg8bit.png', 'frankfurt_000001_020693_gtFine_labelIds.png', 21)
('frankfurt_000001_021406_leftImg8bit.png', 'frankfurt_000001_021406_gtFine_labelIds.png', 21)
('frankfurt_000001_021825_leftImg8bit.png', 'frankfurt_000001_021825_gtFine_labelIds.png', 22)
('frankfurt_000001_023235_leftImg8bit.png', 'frankfurt_000001_023235_gtFine_labelIds.png', 22)
('frankfurt_000001_023369_leftImg8bit.png', 'frankfurt_000001_023369_gtFine_labelIds.png', 22)
('frankfurt_000001_023769_leftImg8bit.png', 'frankfurt_000001_023769_gtFine_labelIds.png', 22)
('frankfurt_000001_024927_leftImg8bit.png', 'frankfurt_000001_024927_gtFine_labelIds.png', 22)
('frankfurt_000001_025512_leftImg8bit.png', 'frankfurt_000001_025512_gtFine_labelIds.png', 23)
('frankfurt_000001_025713_leftImg8bit.png', 'frankfurt_000001_025713_gtFine_labelIds.png', 23)
('frankfurt_000001_025921_leftImg8bit.png', 'frankfurt_000001_025921_gtFine_labelIds.png', 23)
('frankfurt_000001_027325_leftImg8bit.png', 'frankfurt_000001_027325_gtFine_labelIds.png', 23)
('frankfurt_000001_028232_leftImg8bit.png', 'frankfurt_000001_028232_gtFine_labelIds.png', 23)
('frankfurt_000001_028335_leftImg8bit.png', 'frankfurt_000001_028335_gtFine_labelIds.png', 24)
('frankfurt_000001_028590_leftImg8bit.png', 'frankfurt_000001_028590_gtFine_labelIds.png', 24)
('frankfurt_000001_028854_leftImg8bit.png', 'frankfurt_000001_028854_gtFine_labelIds.png', 24)
('frankfurt_000001_029086_leftImg8bit.png', 'frankfurt_000001_029086_gtFine_labelIds.png', 24)
('frankfurt_000001_029236_leftImg8bit.png', 'frankfurt_000001_029236_gtFine_labelIds.png', 24)
pixel_accuracy=0.969113530871, mean_iou=0.835815589208, iou=[ 0.94954938  0.95649333  0.77618565  0.61087635  0.88597324]
('frankfurt_000001_029600_leftImg8bit.png', 'frankfurt_000001_029600_gtFine_labelIds.png', 25)
('frankfurt_000001_030067_leftImg8bit.png', 'frankfurt_000001_030067_gtFine_labelIds.png', 25)
('frankfurt_000001_030310_leftImg8bit.png', 'frankfurt_000001_030310_gtFine_labelIds.png', 25)
('frankfurt_000001_030669_leftImg8bit.png', 'frankfurt_000001_030669_gtFine_labelIds.png', 25)
('frankfurt_000001_031266_leftImg8bit.png', 'frankfurt_000001_031266_gtFine_labelIds.png', 25)
('frankfurt_000001_031416_leftImg8bit.png', 'frankfurt_000001_031416_gtFine_labelIds.png', 26)
('frankfurt_000001_032018_leftImg8bit.png', 'frankfurt_000001_032018_gtFine_labelIds.png', 26)
('frankfurt_000001_032556_leftImg8bit.png', 'frankfurt_000001_032556_gtFine_labelIds.png', 26)
('frankfurt_000001_032711_leftImg8bit.png', 'frankfurt_000001_032711_gtFine_labelIds.png', 26)
('frankfurt_000001_032942_leftImg8bit.png', 'frankfurt_000001_032942_gtFine_labelIds.png', 26)
('frankfurt_000001_033655_leftImg8bit.png', 'frankfurt_000001_033655_gtFine_labelIds.png', 27)
('frankfurt_000001_034047_leftImg8bit.png', 'frankfurt_000001_034047_gtFine_labelIds.png', 27)
('frankfurt_000001_034816_leftImg8bit.png', 'frankfurt_000001_034816_gtFine_labelIds.png', 27)
('frankfurt_000001_035144_leftImg8bit.png', 'frankfurt_000001_035144_gtFine_labelIds.png', 27)
('frankfurt_000001_035864_leftImg8bit.png', 'frankfurt_000001_035864_gtFine_labelIds.png', 27)
('frankfurt_000001_037705_leftImg8bit.png', 'frankfurt_000001_037705_gtFine_labelIds.png', 28)
('frankfurt_000001_038245_leftImg8bit.png', 'frankfurt_000001_038245_gtFine_labelIds.png', 28)
('frankfurt_000001_038418_leftImg8bit.png', 'frankfurt_000001_038418_gtFine_labelIds.png', 28)
('frankfurt_000001_038645_leftImg8bit.png', 'frankfurt_000001_038645_gtFine_labelIds.png', 28)
('frankfurt_000001_038844_leftImg8bit.png', 'frankfurt_000001_038844_gtFine_labelIds.png', 28)
('frankfurt_000001_039895_leftImg8bit.png', 'frankfurt_000001_039895_gtFine_labelIds.png', 29)
('frankfurt_000001_040575_leftImg8bit.png', 'frankfurt_000001_040575_gtFine_labelIds.png', 29)
('frankfurt_000001_040732_leftImg8bit.png', 'frankfurt_000001_040732_gtFine_labelIds.png', 29)
('frankfurt_000001_041074_leftImg8bit.png', 'frankfurt_000001_041074_gtFine_labelIds.png', 29)
('frankfurt_000001_041354_leftImg8bit.png', 'frankfurt_000001_041354_gtFine_labelIds.png', 29)
pixel_accuracy=0.969410761982, mean_iou=0.832399702162, iou=[ 0.94983473  0.95788855  0.7621769   0.59781972  0.8942786 ]
('frankfurt_000001_041517_leftImg8bit.png', 'frankfurt_000001_041517_gtFine_labelIds.png', 30)
('frankfurt_000001_041664_leftImg8bit.png', 'frankfurt_000001_041664_gtFine_labelIds.png', 30)
('frankfurt_000001_042098_leftImg8bit.png', 'frankfurt_000001_042098_gtFine_labelIds.png', 30)
('frankfurt_000001_042384_leftImg8bit.png', 'frankfurt_000001_042384_gtFine_labelIds.png', 30)
('frankfurt_000001_042733_leftImg8bit.png', 'frankfurt_000001_042733_gtFine_labelIds.png', 30)
('frankfurt_000001_043395_leftImg8bit.png', 'frankfurt_000001_043395_gtFine_labelIds.png', 31)
('frankfurt_000001_043564_leftImg8bit.png', 'frankfurt_000001_043564_gtFine_labelIds.png', 31)
('frankfurt_000001_044227_leftImg8bit.png', 'frankfurt_000001_044227_gtFine_labelIds.png', 31)
('frankfurt_000001_044413_leftImg8bit.png', 'frankfurt_000001_044413_gtFine_labelIds.png', 31)
('frankfurt_000001_044525_leftImg8bit.png', 'frankfurt_000001_044525_gtFine_labelIds.png', 31)
('frankfurt_000001_044658_leftImg8bit.png', 'frankfurt_000001_044658_gtFine_labelIds.png', 32)
('frankfurt_000001_044787_leftImg8bit.png', 'frankfurt_000001_044787_gtFine_labelIds.png', 32)
('frankfurt_000001_046126_leftImg8bit.png', 'frankfurt_000001_046126_gtFine_labelIds.png', 32)
('frankfurt_000001_046272_leftImg8bit.png', 'frankfurt_000001_046272_gtFine_labelIds.png', 32)
('frankfurt_000001_046504_leftImg8bit.png', 'frankfurt_000001_046504_gtFine_labelIds.png', 32)
('frankfurt_000001_046779_leftImg8bit.png', 'frankfurt_000001_046779_gtFine_labelIds.png', 33)
('frankfurt_000001_047178_leftImg8bit.png', 'frankfurt_000001_047178_gtFine_labelIds.png', 33)
('frankfurt_000001_047552_leftImg8bit.png', 'frankfurt_000001_047552_gtFine_labelIds.png', 33)
('frankfurt_000001_048196_leftImg8bit.png', 'frankfurt_000001_048196_gtFine_labelIds.png', 33)
('frankfurt_000001_048355_leftImg8bit.png', 'frankfurt_000001_048355_gtFine_labelIds.png', 33)
('frankfurt_000001_048654_leftImg8bit.png', 'frankfurt_000001_048654_gtFine_labelIds.png', 34)
('frankfurt_000001_049078_leftImg8bit.png', 'frankfurt_000001_049078_gtFine_labelIds.png', 34)
('frankfurt_000001_049209_leftImg8bit.png', 'frankfurt_000001_049209_gtFine_labelIds.png', 34)
('frankfurt_000001_049298_leftImg8bit.png', 'frankfurt_000001_049298_gtFine_labelIds.png', 34)
('frankfurt_000001_049698_leftImg8bit.png', 'frankfurt_000001_049698_gtFine_labelIds.png', 34)
pixel_accuracy=0.97097453975, mean_iou=0.834510460502, iou=[ 0.95258275  0.95999429  0.76226576  0.59545877  0.90225073]
('frankfurt_000001_049770_leftImg8bit.png', 'frankfurt_000001_049770_gtFine_labelIds.png', 35)
('frankfurt_000001_050149_leftImg8bit.png', 'frankfurt_000001_050149_gtFine_labelIds.png', 35)
('frankfurt_000001_050686_leftImg8bit.png', 'frankfurt_000001_050686_gtFine_labelIds.png', 35)
('frankfurt_000001_051516_leftImg8bit.png', 'frankfurt_000001_051516_gtFine_labelIds.png', 35)
('frankfurt_000001_051737_leftImg8bit.png', 'frankfurt_000001_051737_gtFine_labelIds.png', 35)
('frankfurt_000001_051807_leftImg8bit.png', 'frankfurt_000001_051807_gtFine_labelIds.png', 36)
('frankfurt_000001_052120_leftImg8bit.png', 'frankfurt_000001_052120_gtFine_labelIds.png', 36)
('frankfurt_000001_052594_leftImg8bit.png', 'frankfurt_000001_052594_gtFine_labelIds.png', 36)
('frankfurt_000001_053102_leftImg8bit.png', 'frankfurt_000001_053102_gtFine_labelIds.png', 36)
('frankfurt_000001_054077_leftImg8bit.png', 'frankfurt_000001_054077_gtFine_labelIds.png', 36)
('frankfurt_000001_054219_leftImg8bit.png', 'frankfurt_000001_054219_gtFine_labelIds.png', 37)
('frankfurt_000001_054415_leftImg8bit.png', 'frankfurt_000001_054415_gtFine_labelIds.png', 37)
('frankfurt_000001_054640_leftImg8bit.png', 'frankfurt_000001_054640_gtFine_labelIds.png', 37)
('frankfurt_000001_054884_leftImg8bit.png', 'frankfurt_000001_054884_gtFine_labelIds.png', 37)
('frankfurt_000001_055062_leftImg8bit.png', 'frankfurt_000001_055062_gtFine_labelIds.png', 37)
('frankfurt_000001_055172_leftImg8bit.png', 'frankfurt_000001_055172_gtFine_labelIds.png', 38)
('frankfurt_000001_055306_leftImg8bit.png', 'frankfurt_000001_055306_gtFine_labelIds.png', 38)
('frankfurt_000001_055387_leftImg8bit.png', 'frankfurt_000001_055387_gtFine_labelIds.png', 38)
('frankfurt_000001_055538_leftImg8bit.png', 'frankfurt_000001_055538_gtFine_labelIds.png', 38)
('frankfurt_000001_055603_leftImg8bit.png', 'frankfurt_000001_055603_gtFine_labelIds.png', 38)
('frankfurt_000001_055709_leftImg8bit.png', 'frankfurt_000001_055709_gtFine_labelIds.png', 39)
('frankfurt_000001_056580_leftImg8bit.png', 'frankfurt_000001_056580_gtFine_labelIds.png', 39)
('frankfurt_000001_057181_leftImg8bit.png', 'frankfurt_000001_057181_gtFine_labelIds.png', 39)
('frankfurt_000001_057478_leftImg8bit.png', 'frankfurt_000001_057478_gtFine_labelIds.png', 39)
('frankfurt_000001_057954_leftImg8bit.png', 'frankfurt_000001_057954_gtFine_labelIds.png', 39)
pixel_accuracy=0.970297117112, mean_iou=0.836444835284, iou=[ 0.95147052  0.96006225  0.77087663  0.59926849  0.9005463 ]
('frankfurt_000001_058057_leftImg8bit.png', 'frankfurt_000001_058057_gtFine_labelIds.png', 40)
('frankfurt_000001_058176_leftImg8bit.png', 'frankfurt_000001_058176_gtFine_labelIds.png', 40)
('frankfurt_000001_058504_leftImg8bit.png', 'frankfurt_000001_058504_gtFine_labelIds.png', 40)
('frankfurt_000001_058914_leftImg8bit.png', 'frankfurt_000001_058914_gtFine_labelIds.png', 40)
('frankfurt_000001_059119_leftImg8bit.png', 'frankfurt_000001_059119_gtFine_labelIds.png', 40)
('frankfurt_000001_059642_leftImg8bit.png', 'frankfurt_000001_059642_gtFine_labelIds.png', 41)
('frankfurt_000001_059789_leftImg8bit.png', 'frankfurt_000001_059789_gtFine_labelIds.png', 41)
('frankfurt_000001_060135_leftImg8bit.png', 'frankfurt_000001_060135_gtFine_labelIds.png', 41)
('frankfurt_000001_060422_leftImg8bit.png', 'frankfurt_000001_060422_gtFine_labelIds.png', 41)
('frankfurt_000001_060545_leftImg8bit.png', 'frankfurt_000001_060545_gtFine_labelIds.png', 41)
('frankfurt_000001_060906_leftImg8bit.png', 'frankfurt_000001_060906_gtFine_labelIds.png', 42)
('frankfurt_000001_061682_leftImg8bit.png', 'frankfurt_000001_061682_gtFine_labelIds.png', 42)
('frankfurt_000001_061763_leftImg8bit.png', 'frankfurt_000001_061763_gtFine_labelIds.png', 42)
('frankfurt_000001_062016_leftImg8bit.png', 'frankfurt_000001_062016_gtFine_labelIds.png', 42)
('frankfurt_000001_062250_leftImg8bit.png', 'frankfurt_000001_062250_gtFine_labelIds.png', 42)
('frankfurt_000001_062396_leftImg8bit.png', 'frankfurt_000001_062396_gtFine_labelIds.png', 43)
('frankfurt_000001_062509_leftImg8bit.png', 'frankfurt_000001_062509_gtFine_labelIds.png', 43)
('frankfurt_000001_062653_leftImg8bit.png', 'frankfurt_000001_062653_gtFine_labelIds.png', 43)
('frankfurt_000001_062793_leftImg8bit.png', 'frankfurt_000001_062793_gtFine_labelIds.png', 43)
('frankfurt_000001_063045_leftImg8bit.png', 'frankfurt_000001_063045_gtFine_labelIds.png', 43)
('frankfurt_000001_064130_leftImg8bit.png', 'frankfurt_000001_064130_gtFine_labelIds.png', 44)
('frankfurt_000001_064305_leftImg8bit.png', 'frankfurt_000001_064305_gtFine_labelIds.png', 44)
('frankfurt_000001_064651_leftImg8bit.png', 'frankfurt_000001_064651_gtFine_labelIds.png', 44)
('frankfurt_000001_064798_leftImg8bit.png', 'frankfurt_000001_064798_gtFine_labelIds.png', 44)
('frankfurt_000001_064925_leftImg8bit.png', 'frankfurt_000001_064925_gtFine_labelIds.png', 44)
pixel_accuracy=0.970971494058, mean_iou=0.836497249083, iou=[ 0.9525559   0.96161937  0.76837761  0.5971926   0.90274077]
('frankfurt_000001_065160_leftImg8bit.png', 'frankfurt_000001_065160_gtFine_labelIds.png', 45)
('frankfurt_000001_065617_leftImg8bit.png', 'frankfurt_000001_065617_gtFine_labelIds.png', 45)
('frankfurt_000001_065850_leftImg8bit.png', 'frankfurt_000001_065850_gtFine_labelIds.png', 45)
('frankfurt_000001_066092_leftImg8bit.png', 'frankfurt_000001_066092_gtFine_labelIds.png', 45)
('frankfurt_000001_066438_leftImg8bit.png', 'frankfurt_000001_066438_gtFine_labelIds.png', 45)
('frankfurt_000001_066574_leftImg8bit.png', 'frankfurt_000001_066574_gtFine_labelIds.png', 46)
('frankfurt_000001_066832_leftImg8bit.png', 'frankfurt_000001_066832_gtFine_labelIds.png', 46)
('frankfurt_000001_067092_leftImg8bit.png', 'frankfurt_000001_067092_gtFine_labelIds.png', 46)
('frankfurt_000001_067178_leftImg8bit.png', 'frankfurt_000001_067178_gtFine_labelIds.png', 46)
('frankfurt_000001_067295_leftImg8bit.png', 'frankfurt_000001_067295_gtFine_labelIds.png', 46)
('frankfurt_000001_067474_leftImg8bit.png', 'frankfurt_000001_067474_gtFine_labelIds.png', 47)
('frankfurt_000001_067735_leftImg8bit.png', 'frankfurt_000001_067735_gtFine_labelIds.png', 47)
('frankfurt_000001_068063_leftImg8bit.png', 'frankfurt_000001_068063_gtFine_labelIds.png', 47)
('frankfurt_000001_068208_leftImg8bit.png', 'frankfurt_000001_068208_gtFine_labelIds.png', 47)
('frankfurt_000001_068682_leftImg8bit.png', 'frankfurt_000001_068682_gtFine_labelIds.png', 47)
('frankfurt_000001_068772_leftImg8bit.png', 'frankfurt_000001_068772_gtFine_labelIds.png', 48)
('frankfurt_000001_069633_leftImg8bit.png', 'frankfurt_000001_069633_gtFine_labelIds.png', 48)
('frankfurt_000001_070099_leftImg8bit.png', 'frankfurt_000001_070099_gtFine_labelIds.png', 48)
('frankfurt_000001_071288_leftImg8bit.png', 'frankfurt_000001_071288_gtFine_labelIds.png', 48)
('frankfurt_000001_071781_leftImg8bit.png', 'frankfurt_000001_071781_gtFine_labelIds.png', 48)
('frankfurt_000001_072155_leftImg8bit.png', 'frankfurt_000001_072155_gtFine_labelIds.png', 49)
('frankfurt_000001_072295_leftImg8bit.png', 'frankfurt_000001_072295_gtFine_labelIds.png', 49)
('frankfurt_000001_073088_leftImg8bit.png', 'frankfurt_000001_073088_gtFine_labelIds.png', 49)
('frankfurt_000001_073243_leftImg8bit.png', 'frankfurt_000001_073243_gtFine_labelIds.png', 49)
('frankfurt_000001_073464_leftImg8bit.png', 'frankfurt_000001_073464_gtFine_labelIds.png', 49)
pixel_accuracy=0.970255315059, mean_iou=0.834261110886, iou=[ 0.95128318  0.95962947  0.76605999  0.59042142  0.9039115 ]
('frankfurt_000001_073911_leftImg8bit.png', 'frankfurt_000001_073911_gtFine_labelIds.png', 50)
('frankfurt_000001_075296_leftImg8bit.png', 'frankfurt_000001_075296_gtFine_labelIds.png', 50)
('frankfurt_000001_075984_leftImg8bit.png', 'frankfurt_000001_075984_gtFine_labelIds.png', 50)
('frankfurt_000001_076502_leftImg8bit.png', 'frankfurt_000001_076502_gtFine_labelIds.png', 50)
('frankfurt_000001_077092_leftImg8bit.png', 'frankfurt_000001_077092_gtFine_labelIds.png', 50)
('frankfurt_000001_077233_leftImg8bit.png', 'frankfurt_000001_077233_gtFine_labelIds.png', 51)
('frankfurt_000001_077434_leftImg8bit.png', 'frankfurt_000001_077434_gtFine_labelIds.png', 51)
('frankfurt_000001_078803_leftImg8bit.png', 'frankfurt_000001_078803_gtFine_labelIds.png', 51)
('frankfurt_000001_079206_leftImg8bit.png', 'frankfurt_000001_079206_gtFine_labelIds.png', 51)
('frankfurt_000001_080091_leftImg8bit.png', 'frankfurt_000001_080091_gtFine_labelIds.png', 51)
('frankfurt_000001_080391_leftImg8bit.png', 'frankfurt_000001_080391_gtFine_labelIds.png', 52)
('frankfurt_000001_080830_leftImg8bit.png', 'frankfurt_000001_080830_gtFine_labelIds.png', 52)
('frankfurt_000001_082087_leftImg8bit.png', 'frankfurt_000001_082087_gtFine_labelIds.png', 52)
('frankfurt_000001_082466_leftImg8bit.png', 'frankfurt_000001_082466_gtFine_labelIds.png', 52)
('frankfurt_000001_083029_leftImg8bit.png', 'frankfurt_000001_083029_gtFine_labelIds.png', 52)
('frankfurt_000001_083199_leftImg8bit.png', 'frankfurt_000001_083199_gtFine_labelIds.png', 53)
('frankfurt_000001_083852_leftImg8bit.png', 'frankfurt_000001_083852_gtFine_labelIds.png', 53)
('lindau_000000_000019_leftImg8bit.png', 'lindau_000000_000019_gtFine_labelIds.png', 53)
('lindau_000001_000019_leftImg8bit.png', 'lindau_000001_000019_gtFine_labelIds.png', 53)
('lindau_000002_000019_leftImg8bit.png', 'lindau_000002_000019_gtFine_labelIds.png', 53)
('lindau_000003_000019_leftImg8bit.png', 'lindau_000003_000019_gtFine_labelIds.png', 54)
('lindau_000004_000019_leftImg8bit.png', 'lindau_000004_000019_gtFine_labelIds.png', 54)
('lindau_000005_000019_leftImg8bit.png', 'lindau_000005_000019_gtFine_labelIds.png', 54)
('lindau_000006_000019_leftImg8bit.png', 'lindau_000006_000019_gtFine_labelIds.png', 54)
('lindau_000007_000019_leftImg8bit.png', 'lindau_000007_000019_gtFine_labelIds.png', 54)
pixel_accuracy=0.970692933594, mean_iou=0.83326091453, iou=[ 0.95199677  0.9605722   0.76157516  0.58877231  0.90338814]
('lindau_000008_000019_leftImg8bit.png', 'lindau_000008_000019_gtFine_labelIds.png', 55)
('lindau_000009_000019_leftImg8bit.png', 'lindau_000009_000019_gtFine_labelIds.png', 55)
('lindau_000010_000019_leftImg8bit.png', 'lindau_000010_000019_gtFine_labelIds.png', 55)
('lindau_000011_000019_leftImg8bit.png', 'lindau_000011_000019_gtFine_labelIds.png', 55)
('lindau_000012_000019_leftImg8bit.png', 'lindau_000012_000019_gtFine_labelIds.png', 55)
('lindau_000013_000019_leftImg8bit.png', 'lindau_000013_000019_gtFine_labelIds.png', 56)
('lindau_000014_000019_leftImg8bit.png', 'lindau_000014_000019_gtFine_labelIds.png', 56)
('lindau_000015_000019_leftImg8bit.png', 'lindau_000015_000019_gtFine_labelIds.png', 56)
('lindau_000016_000019_leftImg8bit.png', 'lindau_000016_000019_gtFine_labelIds.png', 56)
('lindau_000017_000019_leftImg8bit.png', 'lindau_000017_000019_gtFine_labelIds.png', 56)
('lindau_000018_000019_leftImg8bit.png', 'lindau_000018_000019_gtFine_labelIds.png', 57)
('lindau_000019_000019_leftImg8bit.png', 'lindau_000019_000019_gtFine_labelIds.png', 57)
('lindau_000020_000019_leftImg8bit.png', 'lindau_000020_000019_gtFine_labelIds.png', 57)
('lindau_000021_000019_leftImg8bit.png', 'lindau_000021_000019_gtFine_labelIds.png', 57)
('lindau_000022_000019_leftImg8bit.png', 'lindau_000022_000019_gtFine_labelIds.png', 57)
('lindau_000023_000019_leftImg8bit.png', 'lindau_000023_000019_gtFine_labelIds.png', 58)
('lindau_000024_000019_leftImg8bit.png', 'lindau_000024_000019_gtFine_labelIds.png', 58)
('lindau_000025_000019_leftImg8bit.png', 'lindau_000025_000019_gtFine_labelIds.png', 58)
('lindau_000026_000019_leftImg8bit.png', 'lindau_000026_000019_gtFine_labelIds.png', 58)
('lindau_000027_000019_leftImg8bit.png', 'lindau_000027_000019_gtFine_labelIds.png', 58)
('lindau_000028_000019_leftImg8bit.png', 'lindau_000028_000019_gtFine_labelIds.png', 59)
('lindau_000029_000019_leftImg8bit.png', 'lindau_000029_000019_gtFine_labelIds.png', 59)
('lindau_000030_000019_leftImg8bit.png', 'lindau_000030_000019_gtFine_labelIds.png', 59)
('lindau_000031_000019_leftImg8bit.png', 'lindau_000031_000019_gtFine_labelIds.png', 59)
('lindau_000032_000019_leftImg8bit.png', 'lindau_000032_000019_gtFine_labelIds.png', 59)
pixel_accuracy=0.966086989378, mean_iou=0.828416332907, iou=[ 0.94492811  0.94635362  0.75719254  0.59396377  0.89964362]
('lindau_000033_000019_leftImg8bit.png', 'lindau_000033_000019_gtFine_labelIds.png', 60)
('lindau_000034_000019_leftImg8bit.png', 'lindau_000034_000019_gtFine_labelIds.png', 60)
('lindau_000035_000019_leftImg8bit.png', 'lindau_000035_000019_gtFine_labelIds.png', 60)
('lindau_000036_000019_leftImg8bit.png', 'lindau_000036_000019_gtFine_labelIds.png', 60)
('lindau_000037_000019_leftImg8bit.png', 'lindau_000037_000019_gtFine_labelIds.png', 60)
('lindau_000038_000019_leftImg8bit.png', 'lindau_000038_000019_gtFine_labelIds.png', 61)
('lindau_000039_000019_leftImg8bit.png', 'lindau_000039_000019_gtFine_labelIds.png', 61)
('lindau_000040_000019_leftImg8bit.png', 'lindau_000040_000019_gtFine_labelIds.png', 61)
('lindau_000041_000019_leftImg8bit.png', 'lindau_000041_000019_gtFine_labelIds.png', 61)
('lindau_000042_000019_leftImg8bit.png', 'lindau_000042_000019_gtFine_labelIds.png', 61)
('lindau_000043_000019_leftImg8bit.png', 'lindau_000043_000019_gtFine_labelIds.png', 62)
('lindau_000044_000019_leftImg8bit.png', 'lindau_000044_000019_gtFine_labelIds.png', 62)
('lindau_000045_000019_leftImg8bit.png', 'lindau_000045_000019_gtFine_labelIds.png', 62)
('lindau_000046_000019_leftImg8bit.png', 'lindau_000046_000019_gtFine_labelIds.png', 62)
('lindau_000047_000019_leftImg8bit.png', 'lindau_000047_000019_gtFine_labelIds.png', 62)
('lindau_000048_000019_leftImg8bit.png', 'lindau_000048_000019_gtFine_labelIds.png', 63)
('lindau_000049_000019_leftImg8bit.png', 'lindau_000049_000019_gtFine_labelIds.png', 63)
('lindau_000050_000019_leftImg8bit.png', 'lindau_000050_000019_gtFine_labelIds.png', 63)
('lindau_000051_000019_leftImg8bit.png', 'lindau_000051_000019_gtFine_labelIds.png', 63)
('lindau_000052_000019_leftImg8bit.png', 'lindau_000052_000019_gtFine_labelIds.png', 63)
('lindau_000053_000019_leftImg8bit.png', 'lindau_000053_000019_gtFine_labelIds.png', 64)
('lindau_000054_000019_leftImg8bit.png', 'lindau_000054_000019_gtFine_labelIds.png', 64)
('lindau_000055_000019_leftImg8bit.png', 'lindau_000055_000019_gtFine_labelIds.png', 64)
('lindau_000056_000019_leftImg8bit.png', 'lindau_000056_000019_gtFine_labelIds.png', 64)
('lindau_000057_000019_leftImg8bit.png', 'lindau_000057_000019_gtFine_labelIds.png', 64)
pixel_accuracy=0.957510095522, mean_iou=0.819473499635, iou=[ 0.93170223  0.91988381  0.75219295  0.59258364  0.90100486]
('lindau_000058_000019_leftImg8bit.png', 'lindau_000058_000019_gtFine_labelIds.png', 65)
('munster_000000_000019_leftImg8bit.png', 'munster_000000_000019_gtFine_labelIds.png', 65)
('munster_000001_000019_leftImg8bit.png', 'munster_000001_000019_gtFine_labelIds.png', 65)
('munster_000002_000019_leftImg8bit.png', 'munster_000002_000019_gtFine_labelIds.png', 65)
('munster_000003_000019_leftImg8bit.png', 'munster_000003_000019_gtFine_labelIds.png', 65)
('munster_000004_000019_leftImg8bit.png', 'munster_000004_000019_gtFine_labelIds.png', 66)
('munster_000005_000019_leftImg8bit.png', 'munster_000005_000019_gtFine_labelIds.png', 66)
('munster_000006_000019_leftImg8bit.png', 'munster_000006_000019_gtFine_labelIds.png', 66)
('munster_000007_000019_leftImg8bit.png', 'munster_000007_000019_gtFine_labelIds.png', 66)
('munster_000008_000019_leftImg8bit.png', 'munster_000008_000019_gtFine_labelIds.png', 66)
('munster_000009_000019_leftImg8bit.png', 'munster_000009_000019_gtFine_labelIds.png', 67)
('munster_000010_000019_leftImg8bit.png', 'munster_000010_000019_gtFine_labelIds.png', 67)
('munster_000011_000019_leftImg8bit.png', 'munster_000011_000019_gtFine_labelIds.png', 67)
('munster_000012_000019_leftImg8bit.png', 'munster_000012_000019_gtFine_labelIds.png', 67)
('munster_000013_000019_leftImg8bit.png', 'munster_000013_000019_gtFine_labelIds.png', 67)
('munster_000014_000019_leftImg8bit.png', 'munster_000014_000019_gtFine_labelIds.png', 68)
('munster_000015_000019_leftImg8bit.png', 'munster_000015_000019_gtFine_labelIds.png', 68)
('munster_000016_000019_leftImg8bit.png', 'munster_000016_000019_gtFine_labelIds.png', 68)
('munster_000017_000019_leftImg8bit.png', 'munster_000017_000019_gtFine_labelIds.png', 68)
('munster_000018_000019_leftImg8bit.png', 'munster_000018_000019_gtFine_labelIds.png', 68)
('munster_000019_000019_leftImg8bit.png', 'munster_000019_000019_gtFine_labelIds.png', 69)
('munster_000020_000019_leftImg8bit.png', 'munster_000020_000019_gtFine_labelIds.png', 69)
('munster_000021_000019_leftImg8bit.png', 'munster_000021_000019_gtFine_labelIds.png', 69)
('munster_000022_000019_leftImg8bit.png', 'munster_000022_000019_gtFine_labelIds.png', 69)
('munster_000023_000019_leftImg8bit.png', 'munster_000023_000019_gtFine_labelIds.png', 69)
pixel_accuracy=0.959183851364, mean_iou=0.822573184497, iou=[ 0.93427421  0.92376336  0.75227792  0.59920504  0.90334539]
('munster_000024_000019_leftImg8bit.png', 'munster_000024_000019_gtFine_labelIds.png', 70)
('munster_000025_000019_leftImg8bit.png', 'munster_000025_000019_gtFine_labelIds.png', 70)
('munster_000026_000019_leftImg8bit.png', 'munster_000026_000019_gtFine_labelIds.png', 70)
('munster_000027_000019_leftImg8bit.png', 'munster_000027_000019_gtFine_labelIds.png', 70)
('munster_000028_000019_leftImg8bit.png', 'munster_000028_000019_gtFine_labelIds.png', 70)
('munster_000029_000019_leftImg8bit.png', 'munster_000029_000019_gtFine_labelIds.png', 71)
('munster_000030_000019_leftImg8bit.png', 'munster_000030_000019_gtFine_labelIds.png', 71)
('munster_000031_000019_leftImg8bit.png', 'munster_000031_000019_gtFine_labelIds.png', 71)
('munster_000032_000019_leftImg8bit.png', 'munster_000032_000019_gtFine_labelIds.png', 71)
('munster_000033_000019_leftImg8bit.png', 'munster_000033_000019_gtFine_labelIds.png', 71)
('munster_000034_000019_leftImg8bit.png', 'munster_000034_000019_gtFine_labelIds.png', 72)
('munster_000035_000019_leftImg8bit.png', 'munster_000035_000019_gtFine_labelIds.png', 72)
('munster_000036_000019_leftImg8bit.png', 'munster_000036_000019_gtFine_labelIds.png', 72)
('munster_000037_000019_leftImg8bit.png', 'munster_000037_000019_gtFine_labelIds.png', 72)
('munster_000038_000019_leftImg8bit.png', 'munster_000038_000019_gtFine_labelIds.png', 72)
('munster_000039_000019_leftImg8bit.png', 'munster_000039_000019_gtFine_labelIds.png', 73)
('munster_000040_000019_leftImg8bit.png', 'munster_000040_000019_gtFine_labelIds.png', 73)
('munster_000041_000019_leftImg8bit.png', 'munster_000041_000019_gtFine_labelIds.png', 73)
('munster_000042_000019_leftImg8bit.png', 'munster_000042_000019_gtFine_labelIds.png', 73)
('munster_000043_000019_leftImg8bit.png', 'munster_000043_000019_gtFine_labelIds.png', 73)
('munster_000044_000019_leftImg8bit.png', 'munster_000044_000019_gtFine_labelIds.png', 74)
('munster_000045_000019_leftImg8bit.png', 'munster_000045_000019_gtFine_labelIds.png', 74)
('munster_000046_000019_leftImg8bit.png', 'munster_000046_000019_gtFine_labelIds.png', 74)
('munster_000047_000019_leftImg8bit.png', 'munster_000047_000019_gtFine_labelIds.png', 74)
('munster_000048_000019_leftImg8bit.png', 'munster_000048_000019_gtFine_labelIds.png', 74)
pixel_accuracy=0.960260117411, mean_iou=0.825946120639, iou=[ 0.93604152  0.92659556  0.76149897  0.60338871  0.90220585]
('munster_000049_000019_leftImg8bit.png', 'munster_000049_000019_gtFine_labelIds.png', 75)
('munster_000050_000019_leftImg8bit.png', 'munster_000050_000019_gtFine_labelIds.png', 75)
('munster_000051_000019_leftImg8bit.png', 'munster_000051_000019_gtFine_labelIds.png', 75)
('munster_000052_000019_leftImg8bit.png', 'munster_000052_000019_gtFine_labelIds.png', 75)
('munster_000053_000019_leftImg8bit.png', 'munster_000053_000019_gtFine_labelIds.png', 75)
('munster_000054_000019_leftImg8bit.png', 'munster_000054_000019_gtFine_labelIds.png', 76)
('munster_000055_000019_leftImg8bit.png', 'munster_000055_000019_gtFine_labelIds.png', 76)
('munster_000056_000019_leftImg8bit.png', 'munster_000056_000019_gtFine_labelIds.png', 76)
('munster_000057_000019_leftImg8bit.png', 'munster_000057_000019_gtFine_labelIds.png', 76)
('munster_000058_000019_leftImg8bit.png', 'munster_000058_000019_gtFine_labelIds.png', 76)
('munster_000059_000019_leftImg8bit.png', 'munster_000059_000019_gtFine_labelIds.png', 77)
('munster_000060_000019_leftImg8bit.png', 'munster_000060_000019_gtFine_labelIds.png', 77)
('munster_000061_000019_leftImg8bit.png', 'munster_000061_000019_gtFine_labelIds.png', 77)
('munster_000062_000019_leftImg8bit.png', 'munster_000062_000019_gtFine_labelIds.png', 77)
('munster_000063_000019_leftImg8bit.png', 'munster_000063_000019_gtFine_labelIds.png', 77)
('munster_000064_000019_leftImg8bit.png', 'munster_000064_000019_gtFine_labelIds.png', 78)
('munster_000065_000019_leftImg8bit.png', 'munster_000065_000019_gtFine_labelIds.png', 78)
('munster_000066_000019_leftImg8bit.png', 'munster_000066_000019_gtFine_labelIds.png', 78)
('munster_000067_000019_leftImg8bit.png', 'munster_000067_000019_gtFine_labelIds.png', 78)
('munster_000068_000019_leftImg8bit.png', 'munster_000068_000019_gtFine_labelIds.png', 78)
('munster_000069_000019_leftImg8bit.png', 'munster_000069_000019_gtFine_labelIds.png', 79)
('munster_000070_000019_leftImg8bit.png', 'munster_000070_000019_gtFine_labelIds.png', 79)
('munster_000071_000019_leftImg8bit.png', 'munster_000071_000019_gtFine_labelIds.png', 79)
('munster_000072_000019_leftImg8bit.png', 'munster_000072_000019_gtFine_labelIds.png', 79)
('munster_000073_000019_leftImg8bit.png', 'munster_000073_000019_gtFine_labelIds.png', 79)
pixel_accuracy=0.961337719833, mean_iou=0.828198002536, iou=[ 0.93769834  0.92955162  0.76192041  0.60761587  0.90420378]
('munster_000074_000019_leftImg8bit.png', 'munster_000074_000019_gtFine_labelIds.png', 80)
('munster_000075_000019_leftImg8bit.png', 'munster_000075_000019_gtFine_labelIds.png', 80)
('munster_000076_000019_leftImg8bit.png', 'munster_000076_000019_gtFine_labelIds.png', 80)
('munster_000077_000019_leftImg8bit.png', 'munster_000077_000019_gtFine_labelIds.png', 80)
('munster_000078_000019_leftImg8bit.png', 'munster_000078_000019_gtFine_labelIds.png', 80)
('munster_000079_000019_leftImg8bit.png', 'munster_000079_000019_gtFine_labelIds.png', 81)
('munster_000080_000019_leftImg8bit.png', 'munster_000080_000019_gtFine_labelIds.png', 81)
('munster_000081_000019_leftImg8bit.png', 'munster_000081_000019_gtFine_labelIds.png', 81)
('munster_000082_000019_leftImg8bit.png', 'munster_000082_000019_gtFine_labelIds.png', 81)
('munster_000083_000019_leftImg8bit.png', 'munster_000083_000019_gtFine_labelIds.png', 81)
('munster_000084_000019_leftImg8bit.png', 'munster_000084_000019_gtFine_labelIds.png', 82)
('munster_000085_000019_leftImg8bit.png', 'munster_000085_000019_gtFine_labelIds.png', 82)
('munster_000086_000019_leftImg8bit.png', 'munster_000086_000019_gtFine_labelIds.png', 82)
('munster_000087_000019_leftImg8bit.png', 'munster_000087_000019_gtFine_labelIds.png', 82)
('munster_000088_000019_leftImg8bit.png', 'munster_000088_000019_gtFine_labelIds.png', 82)
('munster_000089_000019_leftImg8bit.png', 'munster_000089_000019_gtFine_labelIds.png', 83)
('munster_000090_000019_leftImg8bit.png', 'munster_000090_000019_gtFine_labelIds.png', 83)
('munster_000091_000019_leftImg8bit.png', 'munster_000091_000019_gtFine_labelIds.png', 83)
('munster_000092_000019_leftImg8bit.png', 'munster_000092_000019_gtFine_labelIds.png', 83)
('munster_000093_000019_leftImg8bit.png', 'munster_000093_000019_gtFine_labelIds.png', 83)
('munster_000094_000019_leftImg8bit.png', 'munster_000094_000019_gtFine_labelIds.png', 84)
('munster_000095_000019_leftImg8bit.png', 'munster_000095_000019_gtFine_labelIds.png', 84)
('munster_000096_000019_leftImg8bit.png', 'munster_000096_000019_gtFine_labelIds.png', 84)
('munster_000097_000019_leftImg8bit.png', 'munster_000097_000019_gtFine_labelIds.png', 84)
('munster_000098_000019_leftImg8bit.png', 'munster_000098_000019_gtFine_labelIds.png', 84)
pixel_accuracy=0.962625880367, mean_iou=0.830655784927, iou=[ 0.93963755  0.93230431  0.7621097   0.6102921   0.90893526]
('munster_000099_000019_leftImg8bit.png', 'munster_000099_000019_gtFine_labelIds.png', 85)
('munster_000100_000019_leftImg8bit.png', 'munster_000100_000019_gtFine_labelIds.png', 85)
('munster_000101_000019_leftImg8bit.png', 'munster_000101_000019_gtFine_labelIds.png', 85)
('munster_000102_000019_leftImg8bit.png', 'munster_000102_000019_gtFine_labelIds.png', 85)
('munster_000103_000019_leftImg8bit.png', 'munster_000103_000019_gtFine_labelIds.png', 85)
('munster_000104_000019_leftImg8bit.png', 'munster_000104_000019_gtFine_labelIds.png', 86)
('munster_000105_000019_leftImg8bit.png', 'munster_000105_000019_gtFine_labelIds.png', 86)
('munster_000106_000019_leftImg8bit.png', 'munster_000106_000019_gtFine_labelIds.png', 86)
('munster_000107_000019_leftImg8bit.png', 'munster_000107_000019_gtFine_labelIds.png', 86)
('munster_000108_000019_leftImg8bit.png', 'munster_000108_000019_gtFine_labelIds.png', 86)
('munster_000109_000019_leftImg8bit.png', 'munster_000109_000019_gtFine_labelIds.png', 87)
('munster_000110_000019_leftImg8bit.png', 'munster_000110_000019_gtFine_labelIds.png', 87)
('munster_000111_000019_leftImg8bit.png', 'munster_000111_000019_gtFine_labelIds.png', 87)
('munster_000112_000019_leftImg8bit.png', 'munster_000112_000019_gtFine_labelIds.png', 87)
('munster_000113_000019_leftImg8bit.png', 'munster_000113_000019_gtFine_labelIds.png', 87)
('munster_000114_000019_leftImg8bit.png', 'munster_000114_000019_gtFine_labelIds.png', 88)
('munster_000115_000019_leftImg8bit.png', 'munster_000115_000019_gtFine_labelIds.png', 88)
('munster_000116_000019_leftImg8bit.png', 'munster_000116_000019_gtFine_labelIds.png', 88)
('munster_000117_000019_leftImg8bit.png', 'munster_000117_000019_gtFine_labelIds.png', 88)
('munster_000118_000019_leftImg8bit.png', 'munster_000118_000019_gtFine_labelIds.png', 88)
('munster_000119_000019_leftImg8bit.png', 'munster_000119_000019_gtFine_labelIds.png', 89)
('munster_000120_000019_leftImg8bit.png', 'munster_000120_000019_gtFine_labelIds.png', 89)
('munster_000121_000019_leftImg8bit.png', 'munster_000121_000019_gtFine_labelIds.png', 89)
('munster_000122_000019_leftImg8bit.png', 'munster_000122_000019_gtFine_labelIds.png', 89)
('munster_000123_000019_leftImg8bit.png', 'munster_000123_000019_gtFine_labelIds.png', 89)
pixel_accuracy=0.963931597543, mean_iou=0.831847117084, iou=[ 0.94168328  0.93514561  0.76160193  0.60998417  0.9108206 ]
('munster_000124_000019_leftImg8bit.png', 'munster_000124_000019_gtFine_labelIds.png', 90)
('munster_000125_000019_leftImg8bit.png', 'munster_000125_000019_gtFine_labelIds.png', 90)
('munster_000126_000019_leftImg8bit.png', 'munster_000126_000019_gtFine_labelIds.png', 90)
('munster_000127_000019_leftImg8bit.png', 'munster_000127_000019_gtFine_labelIds.png', 90)
('munster_000128_000019_leftImg8bit.png', 'munster_000128_000019_gtFine_labelIds.png', 90)
('munster_000129_000019_leftImg8bit.png', 'munster_000129_000019_gtFine_labelIds.png', 91)
('munster_000130_000019_leftImg8bit.png', 'munster_000130_000019_gtFine_labelIds.png', 91)
('munster_000131_000019_leftImg8bit.png', 'munster_000131_000019_gtFine_labelIds.png', 91)
('munster_000132_000019_leftImg8bit.png', 'munster_000132_000019_gtFine_labelIds.png', 91)
('munster_000133_000019_leftImg8bit.png', 'munster_000133_000019_gtFine_labelIds.png', 91)
('munster_000134_000019_leftImg8bit.png', 'munster_000134_000019_gtFine_labelIds.png', 92)
('munster_000135_000019_leftImg8bit.png', 'munster_000135_000019_gtFine_labelIds.png', 92)
('munster_000136_000019_leftImg8bit.png', 'munster_000136_000019_gtFine_labelIds.png', 92)
('munster_000137_000019_leftImg8bit.png', 'munster_000137_000019_gtFine_labelIds.png', 92)
('munster_000138_000019_leftImg8bit.png', 'munster_000138_000019_gtFine_labelIds.png', 92)
('munster_000139_000019_leftImg8bit.png', 'munster_000139_000019_gtFine_labelIds.png', 93)
('munster_000140_000019_leftImg8bit.png', 'munster_000140_000019_gtFine_labelIds.png', 93)
('munster_000141_000019_leftImg8bit.png', 'munster_000141_000019_gtFine_labelIds.png', 93)
('munster_000142_000019_leftImg8bit.png', 'munster_000142_000019_gtFine_labelIds.png', 93)
('munster_000143_000019_leftImg8bit.png', 'munster_000143_000019_gtFine_labelIds.png', 93)
('munster_000144_000019_leftImg8bit.png', 'munster_000144_000019_gtFine_labelIds.png', 94)
('munster_000145_000019_leftImg8bit.png', 'munster_000145_000019_gtFine_labelIds.png', 94)
('munster_000146_000019_leftImg8bit.png', 'munster_000146_000019_gtFine_labelIds.png', 94)
('munster_000147_000019_leftImg8bit.png', 'munster_000147_000019_gtFine_labelIds.png', 94)
('munster_000148_000019_leftImg8bit.png', 'munster_000148_000019_gtFine_labelIds.png', 94)
pixel_accuracy=0.96095848628, mean_iou=0.830325513861, iou=[ 0.93683082  0.92666145  0.76653729  0.61029743  0.91130059]
('munster_000149_000019_leftImg8bit.png', 'munster_000149_000019_gtFine_labelIds.png', 95)
('munster_000150_000019_leftImg8bit.png', 'munster_000150_000019_gtFine_labelIds.png', 95)
('munster_000151_000019_leftImg8bit.png', 'munster_000151_000019_gtFine_labelIds.png', 95)
('munster_000152_000019_leftImg8bit.png', 'munster_000152_000019_gtFine_labelIds.png', 95)
('munster_000153_000019_leftImg8bit.png', 'munster_000153_000019_gtFine_labelIds.png', 95)
('munster_000154_000019_leftImg8bit.png', 'munster_000154_000019_gtFine_labelIds.png', 96)
('munster_000155_000019_leftImg8bit.png', 'munster_000155_000019_gtFine_labelIds.png', 96)
('munster_000156_000019_leftImg8bit.png', 'munster_000156_000019_gtFine_labelIds.png', 96)
('munster_000157_000019_leftImg8bit.png', 'munster_000157_000019_gtFine_labelIds.png', 96)
('munster_000158_000019_leftImg8bit.png', 'munster_000158_000019_gtFine_labelIds.png', 96)
('munster_000159_000019_leftImg8bit.png', 'munster_000159_000019_gtFine_labelIds.png', 97)
('munster_000160_000019_leftImg8bit.png', 'munster_000160_000019_gtFine_labelIds.png', 97)
('munster_000161_000019_leftImg8bit.png', 'munster_000161_000019_gtFine_labelIds.png', 97)
('munster_000162_000019_leftImg8bit.png', 'munster_000162_000019_gtFine_labelIds.png', 97)
('munster_000163_000019_leftImg8bit.png', 'munster_000163_000019_gtFine_labelIds.png', 97)
('munster_000164_000019_leftImg8bit.png', 'munster_000164_000019_gtFine_labelIds.png', 98)
('munster_000165_000019_leftImg8bit.png', 'munster_000165_000019_gtFine_labelIds.png', 98)
('munster_000166_000019_leftImg8bit.png', 'munster_000166_000019_gtFine_labelIds.png', 98)
('munster_000167_000019_leftImg8bit.png', 'munster_000167_000019_gtFine_labelIds.png', 98)
('munster_000168_000019_leftImg8bit.png', 'munster_000168_000019_gtFine_labelIds.png', 98)
('munster_000169_000019_leftImg8bit.png', 'munster_000169_000019_gtFine_labelIds.png', 99)
('munster_000170_000019_leftImg8bit.png', 'munster_000170_000019_gtFine_labelIds.png', 99)
('munster_000171_000019_leftImg8bit.png', 'munster_000171_000019_gtFine_labelIds.png', 99)
('munster_000172_000019_leftImg8bit.png', 'munster_000172_000019_gtFine_labelIds.png', 99)
('munster_000173_000019_leftImg8bit.png', 'munster_000173_000019_gtFine_labelIds.png', 99)
pixel_accuracy=0.961544277874, mean_iou=0.832013453427, iou=[ 0.93782942  0.92792907  0.76681501  0.61566917  0.9118246 ]
-------------------------------------------------------------
Final: pixel_accuracy=0.961544277874, mean_iou=0.832013453427, iou=[ 0.93782942  0.92792907  0.76681501  0.61566917  0.9118246 ]
-------------------------------------------------------------
sparse eval.
I0925 10:04:23.664772 18129 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0925 10:04:23.667052 18129 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8278441984, dev_info[0]: total=8506769408 free=8278441984
I0925 10:04:23.667625 18129 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0925 10:04:23.668196 18129 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8278441984, dev_info[0]: total=8506769408 free=8278441984
I0925 10:04:23.669766 18129 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: ../trained/image_segmentation/cityscapes5_jsegnet21v2/test_quantize/deploy.prototxt
I0925 10:04:23.669780 18129 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0925 10:04:23.669783 18129 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0925 10:04:23.670058 18129 net.cpp:72] Initializing net from parameters: 
name: "jsegnet21v2_deploy"
state {
  phase: TEST
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 1024
      dim: 2048
    }
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "out5a"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "out5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "out5a/bn"
  type: "BatchNorm"
  bottom: "out5a"
  top: "out5a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out5a/relu"
  type: "ReLU"
  bottom: "out5a"
  top: "out5a"
}
layer {
  name: "out5a_up2"
  type: "Deconvolution"
  bottom: "out5a"
  top: "out5a_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 64
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out3a"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "out3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "out3a/bn"
  type: "BatchNorm"
  bottom: "out3a"
  top: "out3a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out3a/relu"
  type: "ReLU"
  bottom: "out3a"
  top: "out3a"
}
layer {
  name: "out3_out5_combined"
  type: "Eltwise"
  bottom: "out5a_up2"
  bottom: "out3a"
  top: "out3_out5_combined"
}
layer {
  name: "ctx_conv1"
  type: "Convolution"
  bottom: "out3_out5_combined"
  top: "ctx_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_conv1/bn"
  type: "BatchNorm"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv1/relu"
  type: "ReLU"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
}
layer {
  name: "ctx_conv2"
  type: "Convolution"
  bottom: "ctx_conv1"
  top: "ctx_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv2/bn"
  type: "BatchNorm"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv2/relu"
  type: "ReLU"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
}
layer {
  name: "ctx_conv3"
  type: "Convolution"
  bottom: "ctx_conv2"
  top: "ctx_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv3/bn"
  type: "BatchNorm"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv3/relu"
  type: "ReLU"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
}
layer {
  name: "ctx_conv4"
  type: "Convolution"
  bottom: "ctx_conv3"
  top: "ctx_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv4/bn"
  type: "BatchNorm"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv4/relu"
  type: "ReLU"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
}
layer {
  name: "ctx_final"
  type: "Convolution"
  bottom: "ctx_conv4"
  top: "ctx_final"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_final/relu"
  type: "ReLU"
  bottom: "ctx_final"
  top: "ctx_final"
}
layer {
  name: "out_deconv_final_up2"
  type: "Deconvolution"
  bottom: "ctx_final"
  top: "out_deconv_final_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up4"
  type: "Deconvolution"
  bottom: "out_deconv_final_up2"
  top: "out_deconv_final_up4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up8"
  type: "Deconvolution"
  bottom: "out_deconv_final_up4"
  top: "out_deconv_final_up8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "argMaxOut"
  type: "ArgMax"
  bottom: "out_deconv_final_up8"
  top: "argMaxOut"
  argmax_param {
    axis: 1
  }
}
quantize: true
I0925 10:04:23.670186 18129 net.cpp:104] Using FLOAT as default forward math type
I0925 10:04:23.670192 18129 net.cpp:110] Using FLOAT as default backward math type
I0925 10:04:23.670194 18129 layer_factory.hpp:136] Creating layer 'input' of type 'Input'
I0925 10:04:23.670198 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:23.670207 18129 net.cpp:184] Created Layer input (0)
I0925 10:04:23.670212 18129 net.cpp:530] input -> data
I0925 10:04:23.670864 18129 net.cpp:245] Setting up input
I0925 10:04:23.670876 18129 net.cpp:252] TEST Top shape for layer 0 'input' 1 3 1024 2048 (6291456)
I0925 10:04:23.670884 18129 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0925 10:04:23.670888 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:23.670897 18129 net.cpp:184] Created Layer data/bias (1)
I0925 10:04:23.670899 18129 net.cpp:561] data/bias <- data
I0925 10:04:23.670902 18129 net.cpp:530] data/bias -> data/bias
I0925 10:04:23.675211 18129 net.cpp:245] Setting up data/bias
I0925 10:04:23.675230 18129 net.cpp:252] TEST Top shape for layer 1 'data/bias' 1 3 1024 2048 (6291456)
I0925 10:04:23.675237 18129 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0925 10:04:23.675241 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:23.675258 18129 net.cpp:184] Created Layer conv1a (2)
I0925 10:04:23.675262 18129 net.cpp:561] conv1a <- data/bias
I0925 10:04:23.675266 18129 net.cpp:530] conv1a -> conv1a
I0925 10:04:24.044494 18129 net.cpp:245] Setting up conv1a
I0925 10:04:24.044517 18129 net.cpp:252] TEST Top shape for layer 2 'conv1a' 1 32 512 1024 (16777216)
I0925 10:04:24.044528 18129 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0925 10:04:24.044533 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.044541 18129 net.cpp:184] Created Layer conv1a/bn (3)
I0925 10:04:24.044544 18129 net.cpp:561] conv1a/bn <- conv1a
I0925 10:04:24.044548 18129 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0925 10:04:24.045380 18129 net.cpp:245] Setting up conv1a/bn
I0925 10:04:24.045389 18129 net.cpp:252] TEST Top shape for layer 3 'conv1a/bn' 1 32 512 1024 (16777216)
I0925 10:04:24.045397 18129 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0925 10:04:24.045399 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.045403 18129 net.cpp:184] Created Layer conv1a/relu (4)
I0925 10:04:24.045405 18129 net.cpp:561] conv1a/relu <- conv1a
I0925 10:04:24.045408 18129 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0925 10:04:24.045418 18129 net.cpp:245] Setting up conv1a/relu
I0925 10:04:24.045420 18129 net.cpp:252] TEST Top shape for layer 4 'conv1a/relu' 1 32 512 1024 (16777216)
I0925 10:04:24.045423 18129 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0925 10:04:24.045425 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.045437 18129 net.cpp:184] Created Layer conv1b (5)
I0925 10:04:24.045440 18129 net.cpp:561] conv1b <- conv1a
I0925 10:04:24.045442 18129 net.cpp:530] conv1b -> conv1b
I0925 10:04:24.046933 18129 net.cpp:245] Setting up conv1b
I0925 10:04:24.046942 18129 net.cpp:252] TEST Top shape for layer 5 'conv1b' 1 32 512 1024 (16777216)
I0925 10:04:24.046947 18129 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0925 10:04:24.046950 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.046959 18129 net.cpp:184] Created Layer conv1b/bn (6)
I0925 10:04:24.046962 18129 net.cpp:561] conv1b/bn <- conv1b
I0925 10:04:24.046964 18129 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0925 10:04:24.047734 18129 net.cpp:245] Setting up conv1b/bn
I0925 10:04:24.047744 18129 net.cpp:252] TEST Top shape for layer 6 'conv1b/bn' 1 32 512 1024 (16777216)
I0925 10:04:24.047749 18129 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0925 10:04:24.047751 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.047755 18129 net.cpp:184] Created Layer conv1b/relu (7)
I0925 10:04:24.047757 18129 net.cpp:561] conv1b/relu <- conv1b
I0925 10:04:24.047760 18129 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0925 10:04:24.047762 18129 net.cpp:245] Setting up conv1b/relu
I0925 10:04:24.047765 18129 net.cpp:252] TEST Top shape for layer 7 'conv1b/relu' 1 32 512 1024 (16777216)
I0925 10:04:24.047767 18129 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0925 10:04:24.047780 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.047785 18129 net.cpp:184] Created Layer pool1 (8)
I0925 10:04:24.047786 18129 net.cpp:561] pool1 <- conv1b
I0925 10:04:24.047790 18129 net.cpp:530] pool1 -> pool1
I0925 10:04:24.047823 18129 net.cpp:245] Setting up pool1
I0925 10:04:24.047828 18129 net.cpp:252] TEST Top shape for layer 8 'pool1' 1 32 256 512 (4194304)
I0925 10:04:24.047830 18129 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0925 10:04:24.047833 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.047838 18129 net.cpp:184] Created Layer res2a_branch2a (9)
I0925 10:04:24.047840 18129 net.cpp:561] res2a_branch2a <- pool1
I0925 10:04:24.047842 18129 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0925 10:04:24.048965 18129 net.cpp:245] Setting up res2a_branch2a
I0925 10:04:24.048974 18129 net.cpp:252] TEST Top shape for layer 9 'res2a_branch2a' 1 64 256 512 (8388608)
I0925 10:04:24.048980 18129 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0925 10:04:24.048982 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.048987 18129 net.cpp:184] Created Layer res2a_branch2a/bn (10)
I0925 10:04:24.048990 18129 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0925 10:04:24.048992 18129 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0925 10:04:24.049396 18129 net.cpp:245] Setting up res2a_branch2a/bn
I0925 10:04:24.049402 18129 net.cpp:252] TEST Top shape for layer 10 'res2a_branch2a/bn' 1 64 256 512 (8388608)
I0925 10:04:24.049408 18129 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0925 10:04:24.049410 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.049413 18129 net.cpp:184] Created Layer res2a_branch2a/relu (11)
I0925 10:04:24.049415 18129 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0925 10:04:24.049417 18129 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0925 10:04:24.049420 18129 net.cpp:245] Setting up res2a_branch2a/relu
I0925 10:04:24.049423 18129 net.cpp:252] TEST Top shape for layer 11 'res2a_branch2a/relu' 1 64 256 512 (8388608)
I0925 10:04:24.049425 18129 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0925 10:04:24.049427 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.049435 18129 net.cpp:184] Created Layer res2a_branch2b (12)
I0925 10:04:24.049437 18129 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0925 10:04:24.049439 18129 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0925 10:04:24.050359 18129 net.cpp:245] Setting up res2a_branch2b
I0925 10:04:24.050367 18129 net.cpp:252] TEST Top shape for layer 12 'res2a_branch2b' 1 64 256 512 (8388608)
I0925 10:04:24.050372 18129 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0925 10:04:24.050374 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.050381 18129 net.cpp:184] Created Layer res2a_branch2b/bn (13)
I0925 10:04:24.050384 18129 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0925 10:04:24.050385 18129 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0925 10:04:24.051148 18129 net.cpp:245] Setting up res2a_branch2b/bn
I0925 10:04:24.051156 18129 net.cpp:252] TEST Top shape for layer 13 'res2a_branch2b/bn' 1 64 256 512 (8388608)
I0925 10:04:24.051162 18129 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0925 10:04:24.051164 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.051168 18129 net.cpp:184] Created Layer res2a_branch2b/relu (14)
I0925 10:04:24.051170 18129 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0925 10:04:24.051173 18129 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0925 10:04:24.051184 18129 net.cpp:245] Setting up res2a_branch2b/relu
I0925 10:04:24.051187 18129 net.cpp:252] TEST Top shape for layer 14 'res2a_branch2b/relu' 1 64 256 512 (8388608)
I0925 10:04:24.051189 18129 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0925 10:04:24.051192 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.051194 18129 net.cpp:184] Created Layer pool2 (15)
I0925 10:04:24.051198 18129 net.cpp:561] pool2 <- res2a_branch2b
I0925 10:04:24.051201 18129 net.cpp:530] pool2 -> pool2
I0925 10:04:24.051234 18129 net.cpp:245] Setting up pool2
I0925 10:04:24.051239 18129 net.cpp:252] TEST Top shape for layer 15 'pool2' 1 64 128 256 (2097152)
I0925 10:04:24.051240 18129 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0925 10:04:24.051242 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.051249 18129 net.cpp:184] Created Layer res3a_branch2a (16)
I0925 10:04:24.051251 18129 net.cpp:561] res3a_branch2a <- pool2
I0925 10:04:24.051254 18129 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0925 10:04:24.053763 18129 net.cpp:245] Setting up res3a_branch2a
I0925 10:04:24.053772 18129 net.cpp:252] TEST Top shape for layer 16 'res3a_branch2a' 1 128 128 256 (4194304)
I0925 10:04:24.053777 18129 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0925 10:04:24.053779 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.053784 18129 net.cpp:184] Created Layer res3a_branch2a/bn (17)
I0925 10:04:24.053786 18129 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0925 10:04:24.053788 18129 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0925 10:04:24.054178 18129 net.cpp:245] Setting up res3a_branch2a/bn
I0925 10:04:24.054185 18129 net.cpp:252] TEST Top shape for layer 17 'res3a_branch2a/bn' 1 128 128 256 (4194304)
I0925 10:04:24.054193 18129 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0925 10:04:24.054195 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.054198 18129 net.cpp:184] Created Layer res3a_branch2a/relu (18)
I0925 10:04:24.054200 18129 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0925 10:04:24.054203 18129 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0925 10:04:24.054205 18129 net.cpp:245] Setting up res3a_branch2a/relu
I0925 10:04:24.054208 18129 net.cpp:252] TEST Top shape for layer 18 'res3a_branch2a/relu' 1 128 128 256 (4194304)
I0925 10:04:24.054210 18129 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0925 10:04:24.054213 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.054217 18129 net.cpp:184] Created Layer res3a_branch2b (19)
I0925 10:04:24.054219 18129 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0925 10:04:24.054221 18129 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0925 10:04:24.055111 18129 net.cpp:245] Setting up res3a_branch2b
I0925 10:04:24.055119 18129 net.cpp:252] TEST Top shape for layer 19 'res3a_branch2b' 1 128 128 256 (4194304)
I0925 10:04:24.055122 18129 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0925 10:04:24.055124 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.055128 18129 net.cpp:184] Created Layer res3a_branch2b/bn (20)
I0925 10:04:24.055130 18129 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0925 10:04:24.055133 18129 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0925 10:04:24.055591 18129 net.cpp:245] Setting up res3a_branch2b/bn
I0925 10:04:24.055601 18129 net.cpp:252] TEST Top shape for layer 20 'res3a_branch2b/bn' 1 128 128 256 (4194304)
I0925 10:04:24.055610 18129 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0925 10:04:24.055613 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.055626 18129 net.cpp:184] Created Layer res3a_branch2b/relu (21)
I0925 10:04:24.055629 18129 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0925 10:04:24.055634 18129 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0925 10:04:24.055639 18129 net.cpp:245] Setting up res3a_branch2b/relu
I0925 10:04:24.055644 18129 net.cpp:252] TEST Top shape for layer 21 'res3a_branch2b/relu' 1 128 128 256 (4194304)
I0925 10:04:24.055647 18129 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0925 10:04:24.055650 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.055660 18129 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (22)
I0925 10:04:24.055663 18129 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0925 10:04:24.055667 18129 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0925 10:04:24.055671 18129 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0925 10:04:24.055701 18129 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0925 10:04:24.055706 18129 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b_res3a_branch2b/relu_0_split' 1 128 128 256 (4194304)
I0925 10:04:24.055711 18129 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b_res3a_branch2b/relu_0_split' 1 128 128 256 (4194304)
I0925 10:04:24.055716 18129 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0925 10:04:24.055718 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.055723 18129 net.cpp:184] Created Layer pool3 (23)
I0925 10:04:24.055727 18129 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0925 10:04:24.055732 18129 net.cpp:530] pool3 -> pool3
I0925 10:04:24.055768 18129 net.cpp:245] Setting up pool3
I0925 10:04:24.055774 18129 net.cpp:252] TEST Top shape for layer 23 'pool3' 1 128 64 128 (1048576)
I0925 10:04:24.055779 18129 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0925 10:04:24.055783 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.055791 18129 net.cpp:184] Created Layer res4a_branch2a (24)
I0925 10:04:24.055796 18129 net.cpp:561] res4a_branch2a <- pool3
I0925 10:04:24.055799 18129 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0925 10:04:24.061920 18129 net.cpp:245] Setting up res4a_branch2a
I0925 10:04:24.061930 18129 net.cpp:252] TEST Top shape for layer 24 'res4a_branch2a' 1 256 64 128 (2097152)
I0925 10:04:24.061935 18129 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0925 10:04:24.061939 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.061944 18129 net.cpp:184] Created Layer res4a_branch2a/bn (25)
I0925 10:04:24.061945 18129 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0925 10:04:24.061949 18129 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0925 10:04:24.062342 18129 net.cpp:245] Setting up res4a_branch2a/bn
I0925 10:04:24.062348 18129 net.cpp:252] TEST Top shape for layer 25 'res4a_branch2a/bn' 1 256 64 128 (2097152)
I0925 10:04:24.062353 18129 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0925 10:04:24.062356 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.062361 18129 net.cpp:184] Created Layer res4a_branch2a/relu (26)
I0925 10:04:24.062362 18129 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0925 10:04:24.062364 18129 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0925 10:04:24.062367 18129 net.cpp:245] Setting up res4a_branch2a/relu
I0925 10:04:24.062371 18129 net.cpp:252] TEST Top shape for layer 26 'res4a_branch2a/relu' 1 256 64 128 (2097152)
I0925 10:04:24.062381 18129 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0925 10:04:24.062382 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.062391 18129 net.cpp:184] Created Layer res4a_branch2b (27)
I0925 10:04:24.062392 18129 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0925 10:04:24.062396 18129 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0925 10:04:24.065513 18129 net.cpp:245] Setting up res4a_branch2b
I0925 10:04:24.065521 18129 net.cpp:252] TEST Top shape for layer 27 'res4a_branch2b' 1 256 64 128 (2097152)
I0925 10:04:24.065526 18129 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0925 10:04:24.065528 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.065533 18129 net.cpp:184] Created Layer res4a_branch2b/bn (28)
I0925 10:04:24.065536 18129 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0925 10:04:24.065538 18129 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0925 10:04:24.065990 18129 net.cpp:245] Setting up res4a_branch2b/bn
I0925 10:04:24.065999 18129 net.cpp:252] TEST Top shape for layer 28 'res4a_branch2b/bn' 1 256 64 128 (2097152)
I0925 10:04:24.066004 18129 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0925 10:04:24.066006 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.066010 18129 net.cpp:184] Created Layer res4a_branch2b/relu (29)
I0925 10:04:24.066012 18129 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0925 10:04:24.066015 18129 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0925 10:04:24.066017 18129 net.cpp:245] Setting up res4a_branch2b/relu
I0925 10:04:24.066020 18129 net.cpp:252] TEST Top shape for layer 29 'res4a_branch2b/relu' 1 256 64 128 (2097152)
I0925 10:04:24.066022 18129 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0925 10:04:24.066025 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.066027 18129 net.cpp:184] Created Layer pool4 (30)
I0925 10:04:24.066030 18129 net.cpp:561] pool4 <- res4a_branch2b
I0925 10:04:24.066031 18129 net.cpp:530] pool4 -> pool4
I0925 10:04:24.066062 18129 net.cpp:245] Setting up pool4
I0925 10:04:24.066069 18129 net.cpp:252] TEST Top shape for layer 30 'pool4' 1 256 64 128 (2097152)
I0925 10:04:24.066074 18129 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0925 10:04:24.066077 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.066087 18129 net.cpp:184] Created Layer res5a_branch2a (31)
I0925 10:04:24.066090 18129 net.cpp:561] res5a_branch2a <- pool4
I0925 10:04:24.066094 18129 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0925 10:04:24.091887 18129 net.cpp:245] Setting up res5a_branch2a
I0925 10:04:24.091908 18129 net.cpp:252] TEST Top shape for layer 31 'res5a_branch2a' 1 512 64 128 (4194304)
I0925 10:04:24.091915 18129 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0925 10:04:24.091919 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.091928 18129 net.cpp:184] Created Layer res5a_branch2a/bn (32)
I0925 10:04:24.091931 18129 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0925 10:04:24.091934 18129 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0925 10:04:24.092418 18129 net.cpp:245] Setting up res5a_branch2a/bn
I0925 10:04:24.092428 18129 net.cpp:252] TEST Top shape for layer 32 'res5a_branch2a/bn' 1 512 64 128 (4194304)
I0925 10:04:24.092434 18129 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0925 10:04:24.092437 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.092440 18129 net.cpp:184] Created Layer res5a_branch2a/relu (33)
I0925 10:04:24.092442 18129 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0925 10:04:24.092456 18129 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0925 10:04:24.092460 18129 net.cpp:245] Setting up res5a_branch2a/relu
I0925 10:04:24.092463 18129 net.cpp:252] TEST Top shape for layer 33 'res5a_branch2a/relu' 1 512 64 128 (4194304)
I0925 10:04:24.092465 18129 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0925 10:04:24.092468 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.092478 18129 net.cpp:184] Created Layer res5a_branch2b (34)
I0925 10:04:24.092481 18129 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0925 10:04:24.092483 18129 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0925 10:04:24.104964 18129 net.cpp:245] Setting up res5a_branch2b
I0925 10:04:24.104974 18129 net.cpp:252] TEST Top shape for layer 34 'res5a_branch2b' 1 512 64 128 (4194304)
I0925 10:04:24.104984 18129 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0925 10:04:24.104987 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.104993 18129 net.cpp:184] Created Layer res5a_branch2b/bn (35)
I0925 10:04:24.104995 18129 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0925 10:04:24.104998 18129 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0925 10:04:24.105453 18129 net.cpp:245] Setting up res5a_branch2b/bn
I0925 10:04:24.105461 18129 net.cpp:252] TEST Top shape for layer 35 'res5a_branch2b/bn' 1 512 64 128 (4194304)
I0925 10:04:24.105468 18129 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0925 10:04:24.105469 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.105473 18129 net.cpp:184] Created Layer res5a_branch2b/relu (36)
I0925 10:04:24.105475 18129 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0925 10:04:24.105478 18129 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0925 10:04:24.105480 18129 net.cpp:245] Setting up res5a_branch2b/relu
I0925 10:04:24.105484 18129 net.cpp:252] TEST Top shape for layer 36 'res5a_branch2b/relu' 1 512 64 128 (4194304)
I0925 10:04:24.105485 18129 layer_factory.hpp:136] Creating layer 'out5a' of type 'Convolution'
I0925 10:04:24.105487 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.105494 18129 net.cpp:184] Created Layer out5a (37)
I0925 10:04:24.105496 18129 net.cpp:561] out5a <- res5a_branch2b
I0925 10:04:24.105499 18129 net.cpp:530] out5a -> out5a
I0925 10:04:24.109274 18129 net.cpp:245] Setting up out5a
I0925 10:04:24.109284 18129 net.cpp:252] TEST Top shape for layer 37 'out5a' 1 64 64 128 (524288)
I0925 10:04:24.109288 18129 layer_factory.hpp:136] Creating layer 'out5a/bn' of type 'BatchNorm'
I0925 10:04:24.109292 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.109297 18129 net.cpp:184] Created Layer out5a/bn (38)
I0925 10:04:24.109298 18129 net.cpp:561] out5a/bn <- out5a
I0925 10:04:24.109302 18129 net.cpp:513] out5a/bn -> out5a (in-place)
I0925 10:04:24.109781 18129 net.cpp:245] Setting up out5a/bn
I0925 10:04:24.109789 18129 net.cpp:252] TEST Top shape for layer 38 'out5a/bn' 1 64 64 128 (524288)
I0925 10:04:24.109796 18129 layer_factory.hpp:136] Creating layer 'out5a/relu' of type 'ReLU'
I0925 10:04:24.109797 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.109800 18129 net.cpp:184] Created Layer out5a/relu (39)
I0925 10:04:24.109802 18129 net.cpp:561] out5a/relu <- out5a
I0925 10:04:24.109805 18129 net.cpp:513] out5a/relu -> out5a (in-place)
I0925 10:04:24.109808 18129 net.cpp:245] Setting up out5a/relu
I0925 10:04:24.109812 18129 net.cpp:252] TEST Top shape for layer 39 'out5a/relu' 1 64 64 128 (524288)
I0925 10:04:24.109813 18129 layer_factory.hpp:136] Creating layer 'out5a_up2' of type 'Deconvolution'
I0925 10:04:24.109815 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.109833 18129 net.cpp:184] Created Layer out5a_up2 (40)
I0925 10:04:24.109838 18129 net.cpp:561] out5a_up2 <- out5a
I0925 10:04:24.109839 18129 net.cpp:530] out5a_up2 -> out5a_up2
I0925 10:04:24.110040 18129 net.cpp:245] Setting up out5a_up2
I0925 10:04:24.110049 18129 net.cpp:252] TEST Top shape for layer 40 'out5a_up2' 1 64 128 256 (2097152)
I0925 10:04:24.110054 18129 layer_factory.hpp:136] Creating layer 'out3a' of type 'Convolution'
I0925 10:04:24.110057 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.110066 18129 net.cpp:184] Created Layer out3a (41)
I0925 10:04:24.110069 18129 net.cpp:561] out3a <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0925 10:04:24.110074 18129 net.cpp:530] out3a -> out3a
I0925 10:04:24.111169 18129 net.cpp:245] Setting up out3a
I0925 10:04:24.111181 18129 net.cpp:252] TEST Top shape for layer 41 'out3a' 1 64 128 256 (2097152)
I0925 10:04:24.111186 18129 layer_factory.hpp:136] Creating layer 'out3a/bn' of type 'BatchNorm'
I0925 10:04:24.111191 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.111197 18129 net.cpp:184] Created Layer out3a/bn (42)
I0925 10:04:24.111201 18129 net.cpp:561] out3a/bn <- out3a
I0925 10:04:24.111204 18129 net.cpp:513] out3a/bn -> out3a (in-place)
I0925 10:04:24.111670 18129 net.cpp:245] Setting up out3a/bn
I0925 10:04:24.111677 18129 net.cpp:252] TEST Top shape for layer 42 'out3a/bn' 1 64 128 256 (2097152)
I0925 10:04:24.111682 18129 layer_factory.hpp:136] Creating layer 'out3a/relu' of type 'ReLU'
I0925 10:04:24.111685 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.111688 18129 net.cpp:184] Created Layer out3a/relu (43)
I0925 10:04:24.111690 18129 net.cpp:561] out3a/relu <- out3a
I0925 10:04:24.111693 18129 net.cpp:513] out3a/relu -> out3a (in-place)
I0925 10:04:24.111696 18129 net.cpp:245] Setting up out3a/relu
I0925 10:04:24.111699 18129 net.cpp:252] TEST Top shape for layer 43 'out3a/relu' 1 64 128 256 (2097152)
I0925 10:04:24.111702 18129 layer_factory.hpp:136] Creating layer 'out3_out5_combined' of type 'Eltwise'
I0925 10:04:24.111704 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.111711 18129 net.cpp:184] Created Layer out3_out5_combined (44)
I0925 10:04:24.111716 18129 net.cpp:561] out3_out5_combined <- out5a_up2
I0925 10:04:24.111721 18129 net.cpp:561] out3_out5_combined <- out3a
I0925 10:04:24.111724 18129 net.cpp:530] out3_out5_combined -> out3_out5_combined
I0925 10:04:24.111747 18129 net.cpp:245] Setting up out3_out5_combined
I0925 10:04:24.111753 18129 net.cpp:252] TEST Top shape for layer 44 'out3_out5_combined' 1 64 128 256 (2097152)
I0925 10:04:24.111757 18129 layer_factory.hpp:136] Creating layer 'ctx_conv1' of type 'Convolution'
I0925 10:04:24.111760 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.111769 18129 net.cpp:184] Created Layer ctx_conv1 (45)
I0925 10:04:24.111773 18129 net.cpp:561] ctx_conv1 <- out3_out5_combined
I0925 10:04:24.111778 18129 net.cpp:530] ctx_conv1 -> ctx_conv1
I0925 10:04:24.112731 18129 net.cpp:245] Setting up ctx_conv1
I0925 10:04:24.112740 18129 net.cpp:252] TEST Top shape for layer 45 'ctx_conv1' 1 64 128 256 (2097152)
I0925 10:04:24.112745 18129 layer_factory.hpp:136] Creating layer 'ctx_conv1/bn' of type 'BatchNorm'
I0925 10:04:24.112746 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.112751 18129 net.cpp:184] Created Layer ctx_conv1/bn (46)
I0925 10:04:24.112754 18129 net.cpp:561] ctx_conv1/bn <- ctx_conv1
I0925 10:04:24.112756 18129 net.cpp:513] ctx_conv1/bn -> ctx_conv1 (in-place)
I0925 10:04:24.113199 18129 net.cpp:245] Setting up ctx_conv1/bn
I0925 10:04:24.113206 18129 net.cpp:252] TEST Top shape for layer 46 'ctx_conv1/bn' 1 64 128 256 (2097152)
I0925 10:04:24.113212 18129 layer_factory.hpp:136] Creating layer 'ctx_conv1/relu' of type 'ReLU'
I0925 10:04:24.113222 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.113225 18129 net.cpp:184] Created Layer ctx_conv1/relu (47)
I0925 10:04:24.113229 18129 net.cpp:561] ctx_conv1/relu <- ctx_conv1
I0925 10:04:24.113230 18129 net.cpp:513] ctx_conv1/relu -> ctx_conv1 (in-place)
I0925 10:04:24.113234 18129 net.cpp:245] Setting up ctx_conv1/relu
I0925 10:04:24.113236 18129 net.cpp:252] TEST Top shape for layer 47 'ctx_conv1/relu' 1 64 128 256 (2097152)
I0925 10:04:24.113240 18129 layer_factory.hpp:136] Creating layer 'ctx_conv2' of type 'Convolution'
I0925 10:04:24.113242 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.113252 18129 net.cpp:184] Created Layer ctx_conv2 (48)
I0925 10:04:24.113257 18129 net.cpp:561] ctx_conv2 <- ctx_conv1
I0925 10:04:24.113260 18129 net.cpp:530] ctx_conv2 -> ctx_conv2
I0925 10:04:24.114190 18129 net.cpp:245] Setting up ctx_conv2
I0925 10:04:24.114198 18129 net.cpp:252] TEST Top shape for layer 48 'ctx_conv2' 1 64 128 256 (2097152)
I0925 10:04:24.114202 18129 layer_factory.hpp:136] Creating layer 'ctx_conv2/bn' of type 'BatchNorm'
I0925 10:04:24.114204 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.114208 18129 net.cpp:184] Created Layer ctx_conv2/bn (49)
I0925 10:04:24.114210 18129 net.cpp:561] ctx_conv2/bn <- ctx_conv2
I0925 10:04:24.114212 18129 net.cpp:513] ctx_conv2/bn -> ctx_conv2 (in-place)
I0925 10:04:24.114732 18129 net.cpp:245] Setting up ctx_conv2/bn
I0925 10:04:24.114739 18129 net.cpp:252] TEST Top shape for layer 49 'ctx_conv2/bn' 1 64 128 256 (2097152)
I0925 10:04:24.114745 18129 layer_factory.hpp:136] Creating layer 'ctx_conv2/relu' of type 'ReLU'
I0925 10:04:24.114748 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.114750 18129 net.cpp:184] Created Layer ctx_conv2/relu (50)
I0925 10:04:24.114753 18129 net.cpp:561] ctx_conv2/relu <- ctx_conv2
I0925 10:04:24.114755 18129 net.cpp:513] ctx_conv2/relu -> ctx_conv2 (in-place)
I0925 10:04:24.114758 18129 net.cpp:245] Setting up ctx_conv2/relu
I0925 10:04:24.114760 18129 net.cpp:252] TEST Top shape for layer 50 'ctx_conv2/relu' 1 64 128 256 (2097152)
I0925 10:04:24.114763 18129 layer_factory.hpp:136] Creating layer 'ctx_conv3' of type 'Convolution'
I0925 10:04:24.114764 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.114774 18129 net.cpp:184] Created Layer ctx_conv3 (51)
I0925 10:04:24.114779 18129 net.cpp:561] ctx_conv3 <- ctx_conv2
I0925 10:04:24.114784 18129 net.cpp:530] ctx_conv3 -> ctx_conv3
I0925 10:04:24.115779 18129 net.cpp:245] Setting up ctx_conv3
I0925 10:04:24.115787 18129 net.cpp:252] TEST Top shape for layer 51 'ctx_conv3' 1 64 128 256 (2097152)
I0925 10:04:24.115790 18129 layer_factory.hpp:136] Creating layer 'ctx_conv3/bn' of type 'BatchNorm'
I0925 10:04:24.115793 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.115797 18129 net.cpp:184] Created Layer ctx_conv3/bn (52)
I0925 10:04:24.115799 18129 net.cpp:561] ctx_conv3/bn <- ctx_conv3
I0925 10:04:24.115803 18129 net.cpp:513] ctx_conv3/bn -> ctx_conv3 (in-place)
I0925 10:04:24.116269 18129 net.cpp:245] Setting up ctx_conv3/bn
I0925 10:04:24.116276 18129 net.cpp:252] TEST Top shape for layer 52 'ctx_conv3/bn' 1 64 128 256 (2097152)
I0925 10:04:24.116282 18129 layer_factory.hpp:136] Creating layer 'ctx_conv3/relu' of type 'ReLU'
I0925 10:04:24.116284 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.116287 18129 net.cpp:184] Created Layer ctx_conv3/relu (53)
I0925 10:04:24.116291 18129 net.cpp:561] ctx_conv3/relu <- ctx_conv3
I0925 10:04:24.116292 18129 net.cpp:513] ctx_conv3/relu -> ctx_conv3 (in-place)
I0925 10:04:24.116295 18129 net.cpp:245] Setting up ctx_conv3/relu
I0925 10:04:24.116304 18129 net.cpp:252] TEST Top shape for layer 53 'ctx_conv3/relu' 1 64 128 256 (2097152)
I0925 10:04:24.116307 18129 layer_factory.hpp:136] Creating layer 'ctx_conv4' of type 'Convolution'
I0925 10:04:24.116309 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.116317 18129 net.cpp:184] Created Layer ctx_conv4 (54)
I0925 10:04:24.116322 18129 net.cpp:561] ctx_conv4 <- ctx_conv3
I0925 10:04:24.116327 18129 net.cpp:530] ctx_conv4 -> ctx_conv4
I0925 10:04:24.117331 18129 net.cpp:245] Setting up ctx_conv4
I0925 10:04:24.117339 18129 net.cpp:252] TEST Top shape for layer 54 'ctx_conv4' 1 64 128 256 (2097152)
I0925 10:04:24.117343 18129 layer_factory.hpp:136] Creating layer 'ctx_conv4/bn' of type 'BatchNorm'
I0925 10:04:24.117347 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.117350 18129 net.cpp:184] Created Layer ctx_conv4/bn (55)
I0925 10:04:24.117352 18129 net.cpp:561] ctx_conv4/bn <- ctx_conv4
I0925 10:04:24.117355 18129 net.cpp:513] ctx_conv4/bn -> ctx_conv4 (in-place)
I0925 10:04:24.117820 18129 net.cpp:245] Setting up ctx_conv4/bn
I0925 10:04:24.117826 18129 net.cpp:252] TEST Top shape for layer 55 'ctx_conv4/bn' 1 64 128 256 (2097152)
I0925 10:04:24.117832 18129 layer_factory.hpp:136] Creating layer 'ctx_conv4/relu' of type 'ReLU'
I0925 10:04:24.117835 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.117837 18129 net.cpp:184] Created Layer ctx_conv4/relu (56)
I0925 10:04:24.117841 18129 net.cpp:561] ctx_conv4/relu <- ctx_conv4
I0925 10:04:24.117842 18129 net.cpp:513] ctx_conv4/relu -> ctx_conv4 (in-place)
I0925 10:04:24.117846 18129 net.cpp:245] Setting up ctx_conv4/relu
I0925 10:04:24.117847 18129 net.cpp:252] TEST Top shape for layer 56 'ctx_conv4/relu' 1 64 128 256 (2097152)
I0925 10:04:24.117849 18129 layer_factory.hpp:136] Creating layer 'ctx_final' of type 'Convolution'
I0925 10:04:24.117851 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.117859 18129 net.cpp:184] Created Layer ctx_final (57)
I0925 10:04:24.117863 18129 net.cpp:561] ctx_final <- ctx_conv4
I0925 10:04:24.117866 18129 net.cpp:530] ctx_final -> ctx_final
I0925 10:04:24.118234 18129 net.cpp:245] Setting up ctx_final
I0925 10:04:24.118243 18129 net.cpp:252] TEST Top shape for layer 57 'ctx_final' 1 8 128 256 (262144)
I0925 10:04:24.118250 18129 layer_factory.hpp:136] Creating layer 'ctx_final/relu' of type 'ReLU'
I0925 10:04:24.118253 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.118257 18129 net.cpp:184] Created Layer ctx_final/relu (58)
I0925 10:04:24.118259 18129 net.cpp:561] ctx_final/relu <- ctx_final
I0925 10:04:24.118261 18129 net.cpp:513] ctx_final/relu -> ctx_final (in-place)
I0925 10:04:24.118264 18129 net.cpp:245] Setting up ctx_final/relu
I0925 10:04:24.118268 18129 net.cpp:252] TEST Top shape for layer 58 'ctx_final/relu' 1 8 128 256 (262144)
I0925 10:04:24.118269 18129 layer_factory.hpp:136] Creating layer 'out_deconv_final_up2' of type 'Deconvolution'
I0925 10:04:24.118271 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.118278 18129 net.cpp:184] Created Layer out_deconv_final_up2 (59)
I0925 10:04:24.118280 18129 net.cpp:561] out_deconv_final_up2 <- ctx_final
I0925 10:04:24.118284 18129 net.cpp:530] out_deconv_final_up2 -> out_deconv_final_up2
I0925 10:04:24.118438 18129 net.cpp:245] Setting up out_deconv_final_up2
I0925 10:04:24.118445 18129 net.cpp:252] TEST Top shape for layer 59 'out_deconv_final_up2' 1 8 256 512 (1048576)
I0925 10:04:24.118450 18129 layer_factory.hpp:136] Creating layer 'out_deconv_final_up4' of type 'Deconvolution'
I0925 10:04:24.118453 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.118459 18129 net.cpp:184] Created Layer out_deconv_final_up4 (60)
I0925 10:04:24.118463 18129 net.cpp:561] out_deconv_final_up4 <- out_deconv_final_up2
I0925 10:04:24.118472 18129 net.cpp:530] out_deconv_final_up4 -> out_deconv_final_up4
I0925 10:04:24.118628 18129 net.cpp:245] Setting up out_deconv_final_up4
I0925 10:04:24.118635 18129 net.cpp:252] TEST Top shape for layer 60 'out_deconv_final_up4' 1 8 512 1024 (4194304)
I0925 10:04:24.118640 18129 layer_factory.hpp:136] Creating layer 'out_deconv_final_up8' of type 'Deconvolution'
I0925 10:04:24.118644 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.118650 18129 net.cpp:184] Created Layer out_deconv_final_up8 (61)
I0925 10:04:24.118654 18129 net.cpp:561] out_deconv_final_up8 <- out_deconv_final_up4
I0925 10:04:24.118657 18129 net.cpp:530] out_deconv_final_up8 -> out_deconv_final_up8
I0925 10:04:24.118818 18129 net.cpp:245] Setting up out_deconv_final_up8
I0925 10:04:24.118826 18129 net.cpp:252] TEST Top shape for layer 61 'out_deconv_final_up8' 1 8 1024 2048 (16777216)
I0925 10:04:24.118831 18129 layer_factory.hpp:136] Creating layer 'argMaxOut' of type 'ArgMax'
I0925 10:04:24.118834 18129 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0925 10:04:24.118844 18129 net.cpp:184] Created Layer argMaxOut (62)
I0925 10:04:24.118847 18129 net.cpp:561] argMaxOut <- out_deconv_final_up8
I0925 10:04:24.118850 18129 net.cpp:530] argMaxOut -> argMaxOut
I0925 10:04:24.118870 18129 net.cpp:245] Setting up argMaxOut
I0925 10:04:24.118875 18129 net.cpp:252] TEST Top shape for layer 62 'argMaxOut' 1 1 1024 2048 (2097152)
I0925 10:04:24.118878 18129 net.cpp:325] argMaxOut does not need backward computation.
I0925 10:04:24.118881 18129 net.cpp:325] out_deconv_final_up8 does not need backward computation.
I0925 10:04:24.118885 18129 net.cpp:325] out_deconv_final_up4 does not need backward computation.
I0925 10:04:24.118888 18129 net.cpp:325] out_deconv_final_up2 does not need backward computation.
I0925 10:04:24.118891 18129 net.cpp:325] ctx_final/relu does not need backward computation.
I0925 10:04:24.118894 18129 net.cpp:325] ctx_final does not need backward computation.
I0925 10:04:24.118899 18129 net.cpp:325] ctx_conv4/relu does not need backward computation.
I0925 10:04:24.118902 18129 net.cpp:325] ctx_conv4/bn does not need backward computation.
I0925 10:04:24.118906 18129 net.cpp:325] ctx_conv4 does not need backward computation.
I0925 10:04:24.118908 18129 net.cpp:325] ctx_conv3/relu does not need backward computation.
I0925 10:04:24.118912 18129 net.cpp:325] ctx_conv3/bn does not need backward computation.
I0925 10:04:24.118916 18129 net.cpp:325] ctx_conv3 does not need backward computation.
I0925 10:04:24.118918 18129 net.cpp:325] ctx_conv2/relu does not need backward computation.
I0925 10:04:24.118922 18129 net.cpp:325] ctx_conv2/bn does not need backward computation.
I0925 10:04:24.118926 18129 net.cpp:325] ctx_conv2 does not need backward computation.
I0925 10:04:24.118928 18129 net.cpp:325] ctx_conv1/relu does not need backward computation.
I0925 10:04:24.118932 18129 net.cpp:325] ctx_conv1/bn does not need backward computation.
I0925 10:04:24.118934 18129 net.cpp:325] ctx_conv1 does not need backward computation.
I0925 10:04:24.118939 18129 net.cpp:325] out3_out5_combined does not need backward computation.
I0925 10:04:24.118942 18129 net.cpp:325] out3a/relu does not need backward computation.
I0925 10:04:24.118947 18129 net.cpp:325] out3a/bn does not need backward computation.
I0925 10:04:24.118949 18129 net.cpp:325] out3a does not need backward computation.
I0925 10:04:24.118953 18129 net.cpp:325] out5a_up2 does not need backward computation.
I0925 10:04:24.118957 18129 net.cpp:325] out5a/relu does not need backward computation.
I0925 10:04:24.118960 18129 net.cpp:325] out5a/bn does not need backward computation.
I0925 10:04:24.118963 18129 net.cpp:325] out5a does not need backward computation.
I0925 10:04:24.118968 18129 net.cpp:325] res5a_branch2b/relu does not need backward computation.
I0925 10:04:24.118973 18129 net.cpp:325] res5a_branch2b/bn does not need backward computation.
I0925 10:04:24.118981 18129 net.cpp:325] res5a_branch2b does not need backward computation.
I0925 10:04:24.118986 18129 net.cpp:325] res5a_branch2a/relu does not need backward computation.
I0925 10:04:24.118990 18129 net.cpp:325] res5a_branch2a/bn does not need backward computation.
I0925 10:04:24.118994 18129 net.cpp:325] res5a_branch2a does not need backward computation.
I0925 10:04:24.118999 18129 net.cpp:325] pool4 does not need backward computation.
I0925 10:04:24.119004 18129 net.cpp:325] res4a_branch2b/relu does not need backward computation.
I0925 10:04:24.119007 18129 net.cpp:325] res4a_branch2b/bn does not need backward computation.
I0925 10:04:24.119011 18129 net.cpp:325] res4a_branch2b does not need backward computation.
I0925 10:04:24.119015 18129 net.cpp:325] res4a_branch2a/relu does not need backward computation.
I0925 10:04:24.119019 18129 net.cpp:325] res4a_branch2a/bn does not need backward computation.
I0925 10:04:24.119024 18129 net.cpp:325] res4a_branch2a does not need backward computation.
I0925 10:04:24.119027 18129 net.cpp:325] pool3 does not need backward computation.
I0925 10:04:24.119032 18129 net.cpp:325] res3a_branch2b_res3a_branch2b/relu_0_split does not need backward computation.
I0925 10:04:24.119036 18129 net.cpp:325] res3a_branch2b/relu does not need backward computation.
I0925 10:04:24.119040 18129 net.cpp:325] res3a_branch2b/bn does not need backward computation.
I0925 10:04:24.119045 18129 net.cpp:325] res3a_branch2b does not need backward computation.
I0925 10:04:24.119048 18129 net.cpp:325] res3a_branch2a/relu does not need backward computation.
I0925 10:04:24.119052 18129 net.cpp:325] res3a_branch2a/bn does not need backward computation.
I0925 10:04:24.119056 18129 net.cpp:325] res3a_branch2a does not need backward computation.
I0925 10:04:24.119060 18129 net.cpp:325] pool2 does not need backward computation.
I0925 10:04:24.119065 18129 net.cpp:325] res2a_branch2b/relu does not need backward computation.
I0925 10:04:24.119068 18129 net.cpp:325] res2a_branch2b/bn does not need backward computation.
I0925 10:04:24.119073 18129 net.cpp:325] res2a_branch2b does not need backward computation.
I0925 10:04:24.119077 18129 net.cpp:325] res2a_branch2a/relu does not need backward computation.
I0925 10:04:24.119081 18129 net.cpp:325] res2a_branch2a/bn does not need backward computation.
I0925 10:04:24.119086 18129 net.cpp:325] res2a_branch2a does not need backward computation.
I0925 10:04:24.119089 18129 net.cpp:325] pool1 does not need backward computation.
I0925 10:04:24.119093 18129 net.cpp:325] conv1b/relu does not need backward computation.
I0925 10:04:24.119097 18129 net.cpp:325] conv1b/bn does not need backward computation.
I0925 10:04:24.119102 18129 net.cpp:325] conv1b does not need backward computation.
I0925 10:04:24.119105 18129 net.cpp:325] conv1a/relu does not need backward computation.
I0925 10:04:24.119109 18129 net.cpp:325] conv1a/bn does not need backward computation.
I0925 10:04:24.119114 18129 net.cpp:325] conv1a does not need backward computation.
I0925 10:04:24.119118 18129 net.cpp:325] data/bias does not need backward computation.
I0925 10:04:24.119122 18129 net.cpp:325] input does not need backward computation.
I0925 10:04:24.119127 18129 net.cpp:367] This network produces output argMaxOut
I0925 10:04:24.119189 18129 net.cpp:389] Top memory (TEST) required for data: 1224736768 diff: 1224736768
I0925 10:04:24.119194 18129 net.cpp:392] Bottom memory (TEST) required for data: 1216348160 diff: 1216348160
I0925 10:04:24.119197 18129 net.cpp:395] Shared (in-place) memory (TEST) by data: 659554304 diff: 659554304
I0925 10:04:24.119201 18129 net.cpp:398] Parameters memory (TEST) required for data: 10817840 diff: 10817840
I0925 10:04:24.119205 18129 net.cpp:401] Parameters shared memory (TEST) by data: 0 diff: 0
I0925 10:04:24.119208 18129 net.cpp:407] Network initialization done.
I0925 10:04:24.124652 18129 net.cpp:1078] Ignoring source layer data
I0925 10:04:24.124671 18129 net.cpp:1094] Copying source layer data/bias Type:Bias #blobs=1
I0925 10:04:24.124698 18129 net.cpp:1094] Copying source layer conv1a Type:Convolution #blobs=2
I0925 10:04:24.124722 18129 net.cpp:1094] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0925 10:04:24.124898 18129 net.cpp:1094] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0925 10:04:24.124904 18129 net.cpp:1094] Copying source layer conv1b Type:Convolution #blobs=2
I0925 10:04:24.124912 18129 net.cpp:1094] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0925 10:04:24.125013 18129 net.cpp:1094] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0925 10:04:24.125020 18129 net.cpp:1094] Copying source layer pool1 Type:Pooling #blobs=0
I0925 10:04:24.125023 18129 net.cpp:1094] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0925 10:04:24.125041 18129 net.cpp:1094] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0925 10:04:24.125160 18129 net.cpp:1094] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0925 10:04:24.125166 18129 net.cpp:1094] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0925 10:04:24.125181 18129 net.cpp:1094] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0925 10:04:24.125288 18129 net.cpp:1094] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0925 10:04:24.125295 18129 net.cpp:1094] Copying source layer pool2 Type:Pooling #blobs=0
I0925 10:04:24.125299 18129 net.cpp:1094] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0925 10:04:24.125339 18129 net.cpp:1094] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0925 10:04:24.125445 18129 net.cpp:1094] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0925 10:04:24.125452 18129 net.cpp:1094] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0925 10:04:24.125478 18129 net.cpp:1094] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0925 10:04:24.125579 18129 net.cpp:1094] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0925 10:04:24.125586 18129 net.cpp:1094] Copying source layer res3a_branch2b_res3a_branch2b/relu_0_split Type:Split #blobs=0
I0925 10:04:24.125589 18129 net.cpp:1094] Copying source layer pool3 Type:Pooling #blobs=0
I0925 10:04:24.125593 18129 net.cpp:1094] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0925 10:04:24.125710 18129 net.cpp:1094] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0925 10:04:24.125803 18129 net.cpp:1094] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0925 10:04:24.125808 18129 net.cpp:1094] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0925 10:04:24.125869 18129 net.cpp:1094] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0925 10:04:24.125960 18129 net.cpp:1094] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0925 10:04:24.125965 18129 net.cpp:1094] Copying source layer pool4 Type:Pooling #blobs=0
I0925 10:04:24.125967 18129 net.cpp:1094] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0925 10:04:24.126307 18129 net.cpp:1094] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0925 10:04:24.126399 18129 net.cpp:1094] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0925 10:04:24.126405 18129 net.cpp:1094] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0925 10:04:24.126588 18129 net.cpp:1094] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0925 10:04:24.126679 18129 net.cpp:1094] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0925 10:04:24.126684 18129 net.cpp:1094] Copying source layer out5a Type:Convolution #blobs=2
I0925 10:04:24.126739 18129 net.cpp:1094] Copying source layer out5a/bn Type:BatchNorm #blobs=5
I0925 10:04:24.126843 18129 net.cpp:1094] Copying source layer out5a/relu Type:ReLU #blobs=0
I0925 10:04:24.126848 18129 net.cpp:1094] Copying source layer out5a_up2 Type:Deconvolution #blobs=1
I0925 10:04:24.126855 18129 net.cpp:1094] Copying source layer out3a Type:Convolution #blobs=2
I0925 10:04:24.126878 18129 net.cpp:1094] Copying source layer out3a/bn Type:BatchNorm #blobs=5
I0925 10:04:24.127003 18129 net.cpp:1094] Copying source layer out3a/relu Type:ReLU #blobs=0
I0925 10:04:24.127008 18129 net.cpp:1094] Copying source layer out3_out5_combined Type:Eltwise #blobs=0
I0925 10:04:24.127012 18129 net.cpp:1094] Copying source layer ctx_conv1 Type:Convolution #blobs=2
I0925 10:04:24.127034 18129 net.cpp:1094] Copying source layer ctx_conv1/bn Type:BatchNorm #blobs=5
I0925 10:04:24.127148 18129 net.cpp:1094] Copying source layer ctx_conv1/relu Type:ReLU #blobs=0
I0925 10:04:24.127153 18129 net.cpp:1094] Copying source layer ctx_conv2 Type:Convolution #blobs=2
I0925 10:04:24.127176 18129 net.cpp:1094] Copying source layer ctx_conv2/bn Type:BatchNorm #blobs=5
I0925 10:04:24.127285 18129 net.cpp:1094] Copying source layer ctx_conv2/relu Type:ReLU #blobs=0
I0925 10:04:24.127290 18129 net.cpp:1094] Copying source layer ctx_conv3 Type:Convolution #blobs=2
I0925 10:04:24.127307 18129 net.cpp:1094] Copying source layer ctx_conv3/bn Type:BatchNorm #blobs=5
I0925 10:04:24.127418 18129 net.cpp:1094] Copying source layer ctx_conv3/relu Type:ReLU #blobs=0
I0925 10:04:24.127424 18129 net.cpp:1094] Copying source layer ctx_conv4 Type:Convolution #blobs=2
I0925 10:04:24.127444 18129 net.cpp:1094] Copying source layer ctx_conv4/bn Type:BatchNorm #blobs=5
I0925 10:04:24.127557 18129 net.cpp:1094] Copying source layer ctx_conv4/relu Type:ReLU #blobs=0
I0925 10:04:24.127562 18129 net.cpp:1094] Copying source layer ctx_final Type:Convolution #blobs=2
I0925 10:04:24.127574 18129 net.cpp:1094] Copying source layer ctx_final/relu Type:ReLU #blobs=0
I0925 10:04:24.127579 18129 net.cpp:1094] Copying source layer out_deconv_final_up2 Type:Deconvolution #blobs=1
I0925 10:04:24.127586 18129 net.cpp:1094] Copying source layer out_deconv_final_up4 Type:Deconvolution #blobs=1
I0925 10:04:24.127593 18129 net.cpp:1094] Copying source layer out_deconv_final_up8 Type:Deconvolution #blobs=1
I0925 10:04:24.127600 18129 net.cpp:1078] Ignoring source layer loss
Namespace(batch_size=1, blend=False, class_dict='', crop=['0'], input='./data/val-image-list.txt', label='./data/val-label-list.txt', label_dict='', model='../trained/image_segmentation/cityscapes5_jsegnet21v2/test_quantize/deploy.prototxt', num_classes=5, num_images=500, output=None, palette='', resize=['0'], resize_back=True, search='*.png', weights='../trained/image_segmentation/cityscapes5_jsegnet21v2/sparse/cityscapes5_jsegnet21v2_iter_60000.caffemodel')
Infering list
Getting list of images...running inference for  500  images...
('frankfurt_000000_000294_leftImg8bit.png', 'frankfurt_000000_000294_gtFine_labelIds.png', 0)
('frankfurt_000000_000576_leftImg8bit.png', 'frankfurt_000000_000576_gtFine_labelIds.png', 0)
I0925 10:04:24.681903 18129 net.cpp:1597] Adding quantization params at infer/iter index: 1
('frankfurt_000000_001016_leftImg8bit.png', 'frankfurt_000000_001016_gtFine_labelIds.png', 0)
I0925 10:04:25.052191 18129 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1a' with space 0.01G 3/1 1 	(avail 5.87G, req 0.01G)	t: 0
I0925 10:04:25.181991 18129 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1b' with space 0.01G 32/4 6 	(avail 5.87G, req 0.01G)	t: 0
I0925 10:04:25.200109 18129 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2a' with space 0.01G 32/1 6 	(avail 5.87G, req 0.01G)	t: 0
I0925 10:04:25.241655 18129 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2b' with space 0.01G 64/4 6 	(avail 5.87G, req 0.01G)	t: 0
I0925 10:04:25.253406 18129 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2a' with space 0.01G 64/1 6 	(avail 5.87G, req 0.01G)	t: 0
I0925 10:04:25.257779 18129 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2b' with space 0.01G 128/4 6 	(avail 5.87G, req 0.01G)	t: 0
I0925 10:04:25.269006 18129 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2a' with space 0.01G 128/1 6 	(avail 5.87G, req 0.01G)	t: 0
I0925 10:04:25.273913 18129 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2b' with space 0.01G 256/4 6 	(avail 5.87G, req 0.01G)	t: 0
I0925 10:04:25.288610 18129 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'out3a' with space 0.01G 128/2 6 	(avail 5.87G, req 0.01G)	t: 0
I0925 10:04:25.295416 18129 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_conv1' with space 0.01G 64/1 6 	(avail 5.87G, req 0.01G)	t: 0
I0925 10:04:25.321297 18129 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_final' with space 0.01G 64/1 6 	(avail 5.87G, req 0.01G)	t: 0
('frankfurt_000000_001236_leftImg8bit.png', 'frankfurt_000000_001236_gtFine_labelIds.png', 0)
('frankfurt_000000_001751_leftImg8bit.png', 'frankfurt_000000_001751_gtFine_labelIds.png', 0)
('frankfurt_000000_002196_leftImg8bit.png', 'frankfurt_000000_002196_gtFine_labelIds.png', 1)
('frankfurt_000000_002963_leftImg8bit.png', 'frankfurt_000000_002963_gtFine_labelIds.png', 1)
('frankfurt_000000_003025_leftImg8bit.png', 'frankfurt_000000_003025_gtFine_labelIds.png', 1)
('frankfurt_000000_003357_leftImg8bit.png', 'frankfurt_000000_003357_gtFine_labelIds.png', 1)
('frankfurt_000000_003920_leftImg8bit.png', 'frankfurt_000000_003920_gtFine_labelIds.png', 1)
('frankfurt_000000_004617_leftImg8bit.png', 'frankfurt_000000_004617_gtFine_labelIds.png', 2)
('frankfurt_000000_005543_leftImg8bit.png', 'frankfurt_000000_005543_gtFine_labelIds.png', 2)
('frankfurt_000000_005898_leftImg8bit.png', 'frankfurt_000000_005898_gtFine_labelIds.png', 2)
('frankfurt_000000_006589_leftImg8bit.png', 'frankfurt_000000_006589_gtFine_labelIds.png', 2)
('frankfurt_000000_007365_leftImg8bit.png', 'frankfurt_000000_007365_gtFine_labelIds.png', 2)
('frankfurt_000000_008206_leftImg8bit.png', 'frankfurt_000000_008206_gtFine_labelIds.png', 3)
('frankfurt_000000_008451_leftImg8bit.png', 'frankfurt_000000_008451_gtFine_labelIds.png', 3)
('frankfurt_000000_009291_leftImg8bit.png', 'frankfurt_000000_009291_gtFine_labelIds.png', 3)
('frankfurt_000000_009561_leftImg8bit.png', 'frankfurt_000000_009561_gtFine_labelIds.png', 3)
('frankfurt_000000_009688_leftImg8bit.png', 'frankfurt_000000_009688_gtFine_labelIds.png', 3)
('frankfurt_000000_009969_leftImg8bit.png', 'frankfurt_000000_009969_gtFine_labelIds.png', 4)
('frankfurt_000000_010351_leftImg8bit.png', 'frankfurt_000000_010351_gtFine_labelIds.png', 4)
('frankfurt_000000_010763_leftImg8bit.png', 'frankfurt_000000_010763_gtFine_labelIds.png', 4)
('frankfurt_000000_011007_leftImg8bit.png', 'frankfurt_000000_011007_gtFine_labelIds.png', 4)
('frankfurt_000000_011074_leftImg8bit.png', 'frankfurt_000000_011074_gtFine_labelIds.png', 4)
pixel_accuracy=0.97380823112, mean_iou=0.825089946514, iou=[ 0.95593807  0.95998665  0.75883264  0.55376342  0.89692895]
('frankfurt_000000_011461_leftImg8bit.png', 'frankfurt_000000_011461_gtFine_labelIds.png', 5)
('frankfurt_000000_011810_leftImg8bit.png', 'frankfurt_000000_011810_gtFine_labelIds.png', 5)
('frankfurt_000000_012009_leftImg8bit.png', 'frankfurt_000000_012009_gtFine_labelIds.png', 5)
('frankfurt_000000_012121_leftImg8bit.png', 'frankfurt_000000_012121_gtFine_labelIds.png', 5)
('frankfurt_000000_012868_leftImg8bit.png', 'frankfurt_000000_012868_gtFine_labelIds.png', 5)
('frankfurt_000000_013067_leftImg8bit.png', 'frankfurt_000000_013067_gtFine_labelIds.png', 6)
('frankfurt_000000_013240_leftImg8bit.png', 'frankfurt_000000_013240_gtFine_labelIds.png', 6)
('frankfurt_000000_013382_leftImg8bit.png', 'frankfurt_000000_013382_gtFine_labelIds.png', 6)
('frankfurt_000000_013942_leftImg8bit.png', 'frankfurt_000000_013942_gtFine_labelIds.png', 6)
('frankfurt_000000_014480_leftImg8bit.png', 'frankfurt_000000_014480_gtFine_labelIds.png', 6)
('frankfurt_000000_015389_leftImg8bit.png', 'frankfurt_000000_015389_gtFine_labelIds.png', 7)
('frankfurt_000000_015676_leftImg8bit.png', 'frankfurt_000000_015676_gtFine_labelIds.png', 7)
('frankfurt_000000_016005_leftImg8bit.png', 'frankfurt_000000_016005_gtFine_labelIds.png', 7)
('frankfurt_000000_016286_leftImg8bit.png', 'frankfurt_000000_016286_gtFine_labelIds.png', 7)
('frankfurt_000000_017228_leftImg8bit.png', 'frankfurt_000000_017228_gtFine_labelIds.png', 7)
('frankfurt_000000_017476_leftImg8bit.png', 'frankfurt_000000_017476_gtFine_labelIds.png', 8)
('frankfurt_000000_018797_leftImg8bit.png', 'frankfurt_000000_018797_gtFine_labelIds.png', 8)
('frankfurt_000000_019607_leftImg8bit.png', 'frankfurt_000000_019607_gtFine_labelIds.png', 8)
('frankfurt_000000_020215_leftImg8bit.png', 'frankfurt_000000_020215_gtFine_labelIds.png', 8)
('frankfurt_000000_020321_leftImg8bit.png', 'frankfurt_000000_020321_gtFine_labelIds.png', 8)
('frankfurt_000000_020880_leftImg8bit.png', 'frankfurt_000000_020880_gtFine_labelIds.png', 9)
('frankfurt_000000_021667_leftImg8bit.png', 'frankfurt_000000_021667_gtFine_labelIds.png', 9)
('frankfurt_000000_021879_leftImg8bit.png', 'frankfurt_000000_021879_gtFine_labelIds.png', 9)
('frankfurt_000000_022254_leftImg8bit.png', 'frankfurt_000000_022254_gtFine_labelIds.png', 9)
('frankfurt_000000_022797_leftImg8bit.png', 'frankfurt_000000_022797_gtFine_labelIds.png', 9)
pixel_accuracy=0.973363022862, mean_iou=0.833781388413, iou=[ 0.95559862  0.96315916  0.76966493  0.58786191  0.89262232]
('frankfurt_000001_000538_leftImg8bit.png', 'frankfurt_000001_000538_gtFine_labelIds.png', 10)
('frankfurt_000001_001464_leftImg8bit.png', 'frankfurt_000001_001464_gtFine_labelIds.png', 10)
('frankfurt_000001_002512_leftImg8bit.png', 'frankfurt_000001_002512_gtFine_labelIds.png', 10)
('frankfurt_000001_002646_leftImg8bit.png', 'frankfurt_000001_002646_gtFine_labelIds.png', 10)
('frankfurt_000001_002759_leftImg8bit.png', 'frankfurt_000001_002759_gtFine_labelIds.png', 10)
('frankfurt_000001_003056_leftImg8bit.png', 'frankfurt_000001_003056_gtFine_labelIds.png', 11)
('frankfurt_000001_003588_leftImg8bit.png', 'frankfurt_000001_003588_gtFine_labelIds.png', 11)
('frankfurt_000001_004327_leftImg8bit.png', 'frankfurt_000001_004327_gtFine_labelIds.png', 11)
('frankfurt_000001_004736_leftImg8bit.png', 'frankfurt_000001_004736_gtFine_labelIds.png', 11)
('frankfurt_000001_004859_leftImg8bit.png', 'frankfurt_000001_004859_gtFine_labelIds.png', 11)
('frankfurt_000001_005184_leftImg8bit.png', 'frankfurt_000001_005184_gtFine_labelIds.png', 12)
('frankfurt_000001_005410_leftImg8bit.png', 'frankfurt_000001_005410_gtFine_labelIds.png', 12)
('frankfurt_000001_005703_leftImg8bit.png', 'frankfurt_000001_005703_gtFine_labelIds.png', 12)
('frankfurt_000001_005898_leftImg8bit.png', 'frankfurt_000001_005898_gtFine_labelIds.png', 12)
('frankfurt_000001_007285_leftImg8bit.png', 'frankfurt_000001_007285_gtFine_labelIds.png', 12)
('frankfurt_000001_007407_leftImg8bit.png', 'frankfurt_000001_007407_gtFine_labelIds.png', 13)
('frankfurt_000001_007622_leftImg8bit.png', 'frankfurt_000001_007622_gtFine_labelIds.png', 13)
('frankfurt_000001_007857_leftImg8bit.png', 'frankfurt_000001_007857_gtFine_labelIds.png', 13)
('frankfurt_000001_007973_leftImg8bit.png', 'frankfurt_000001_007973_gtFine_labelIds.png', 13)
('frankfurt_000001_008200_leftImg8bit.png', 'frankfurt_000001_008200_gtFine_labelIds.png', 13)
('frankfurt_000001_008688_leftImg8bit.png', 'frankfurt_000001_008688_gtFine_labelIds.png', 14)
('frankfurt_000001_009058_leftImg8bit.png', 'frankfurt_000001_009058_gtFine_labelIds.png', 14)
('frankfurt_000001_009504_leftImg8bit.png', 'frankfurt_000001_009504_gtFine_labelIds.png', 14)
('frankfurt_000001_009854_leftImg8bit.png', 'frankfurt_000001_009854_gtFine_labelIds.png', 14)
('frankfurt_000001_010156_leftImg8bit.png', 'frankfurt_000001_010156_gtFine_labelIds.png', 14)
pixel_accuracy=0.971926581339, mean_iou=0.830872696403, iou=[ 0.95320835  0.96148677  0.75477866  0.59609259  0.88879712]
('frankfurt_000001_010444_leftImg8bit.png', 'frankfurt_000001_010444_gtFine_labelIds.png', 15)
('frankfurt_000001_010600_leftImg8bit.png', 'frankfurt_000001_010600_gtFine_labelIds.png', 15)
('frankfurt_000001_010830_leftImg8bit.png', 'frankfurt_000001_010830_gtFine_labelIds.png', 15)
('frankfurt_000001_011162_leftImg8bit.png', 'frankfurt_000001_011162_gtFine_labelIds.png', 15)
('frankfurt_000001_011715_leftImg8bit.png', 'frankfurt_000001_011715_gtFine_labelIds.png', 15)
('frankfurt_000001_011835_leftImg8bit.png', 'frankfurt_000001_011835_gtFine_labelIds.png', 16)
('frankfurt_000001_012038_leftImg8bit.png', 'frankfurt_000001_012038_gtFine_labelIds.png', 16)
('frankfurt_000001_012519_leftImg8bit.png', 'frankfurt_000001_012519_gtFine_labelIds.png', 16)
('frankfurt_000001_012699_leftImg8bit.png', 'frankfurt_000001_012699_gtFine_labelIds.png', 16)
('frankfurt_000001_012738_leftImg8bit.png', 'frankfurt_000001_012738_gtFine_labelIds.png', 16)
('frankfurt_000001_012870_leftImg8bit.png', 'frankfurt_000001_012870_gtFine_labelIds.png', 17)
('frankfurt_000001_013016_leftImg8bit.png', 'frankfurt_000001_013016_gtFine_labelIds.png', 17)
('frankfurt_000001_013496_leftImg8bit.png', 'frankfurt_000001_013496_gtFine_labelIds.png', 17)
('frankfurt_000001_013710_leftImg8bit.png', 'frankfurt_000001_013710_gtFine_labelIds.png', 17)
('frankfurt_000001_014221_leftImg8bit.png', 'frankfurt_000001_014221_gtFine_labelIds.png', 17)
('frankfurt_000001_014406_leftImg8bit.png', 'frankfurt_000001_014406_gtFine_labelIds.png', 18)
('frankfurt_000001_014565_leftImg8bit.png', 'frankfurt_000001_014565_gtFine_labelIds.png', 18)
('frankfurt_000001_014741_leftImg8bit.png', 'frankfurt_000001_014741_gtFine_labelIds.png', 18)
('frankfurt_000001_015091_leftImg8bit.png', 'frankfurt_000001_015091_gtFine_labelIds.png', 18)
('frankfurt_000001_015328_leftImg8bit.png', 'frankfurt_000001_015328_gtFine_labelIds.png', 18)
('frankfurt_000001_015768_leftImg8bit.png', 'frankfurt_000001_015768_gtFine_labelIds.png', 19)
('frankfurt_000001_016029_leftImg8bit.png', 'frankfurt_000001_016029_gtFine_labelIds.png', 19)
('frankfurt_000001_016273_leftImg8bit.png', 'frankfurt_000001_016273_gtFine_labelIds.png', 19)
('frankfurt_000001_016462_leftImg8bit.png', 'frankfurt_000001_016462_gtFine_labelIds.png', 19)
('frankfurt_000001_017101_leftImg8bit.png', 'frankfurt_000001_017101_gtFine_labelIds.png', 19)
pixel_accuracy=0.968777545172, mean_iou=0.836729138045, iou=[ 0.9487307   0.95634676  0.77768511  0.61240351  0.88847961]
('frankfurt_000001_017459_leftImg8bit.png', 'frankfurt_000001_017459_gtFine_labelIds.png', 20)
('frankfurt_000001_017842_leftImg8bit.png', 'frankfurt_000001_017842_gtFine_labelIds.png', 20)
('frankfurt_000001_018113_leftImg8bit.png', 'frankfurt_000001_018113_gtFine_labelIds.png', 20)
('frankfurt_000001_019698_leftImg8bit.png', 'frankfurt_000001_019698_gtFine_labelIds.png', 20)
('frankfurt_000001_019854_leftImg8bit.png', 'frankfurt_000001_019854_gtFine_labelIds.png', 20)
('frankfurt_000001_019969_leftImg8bit.png', 'frankfurt_000001_019969_gtFine_labelIds.png', 21)
('frankfurt_000001_020046_leftImg8bit.png', 'frankfurt_000001_020046_gtFine_labelIds.png', 21)
('frankfurt_000001_020287_leftImg8bit.png', 'frankfurt_000001_020287_gtFine_labelIds.png', 21)
('frankfurt_000001_020693_leftImg8bit.png', 'frankfurt_000001_020693_gtFine_labelIds.png', 21)
('frankfurt_000001_021406_leftImg8bit.png', 'frankfurt_000001_021406_gtFine_labelIds.png', 21)
('frankfurt_000001_021825_leftImg8bit.png', 'frankfurt_000001_021825_gtFine_labelIds.png', 22)
('frankfurt_000001_023235_leftImg8bit.png', 'frankfurt_000001_023235_gtFine_labelIds.png', 22)
('frankfurt_000001_023369_leftImg8bit.png', 'frankfurt_000001_023369_gtFine_labelIds.png', 22)
('frankfurt_000001_023769_leftImg8bit.png', 'frankfurt_000001_023769_gtFine_labelIds.png', 22)
('frankfurt_000001_024927_leftImg8bit.png', 'frankfurt_000001_024927_gtFine_labelIds.png', 22)
('frankfurt_000001_025512_leftImg8bit.png', 'frankfurt_000001_025512_gtFine_labelIds.png', 23)
('frankfurt_000001_025713_leftImg8bit.png', 'frankfurt_000001_025713_gtFine_labelIds.png', 23)
('frankfurt_000001_025921_leftImg8bit.png', 'frankfurt_000001_025921_gtFine_labelIds.png', 23)
('frankfurt_000001_027325_leftImg8bit.png', 'frankfurt_000001_027325_gtFine_labelIds.png', 23)
('frankfurt_000001_028232_leftImg8bit.png', 'frankfurt_000001_028232_gtFine_labelIds.png', 23)
('frankfurt_000001_028335_leftImg8bit.png', 'frankfurt_000001_028335_gtFine_labelIds.png', 24)
('frankfurt_000001_028590_leftImg8bit.png', 'frankfurt_000001_028590_gtFine_labelIds.png', 24)
('frankfurt_000001_028854_leftImg8bit.png', 'frankfurt_000001_028854_gtFine_labelIds.png', 24)
('frankfurt_000001_029086_leftImg8bit.png', 'frankfurt_000001_029086_gtFine_labelIds.png', 24)
('frankfurt_000001_029236_leftImg8bit.png', 'frankfurt_000001_029236_gtFine_labelIds.png', 24)
pixel_accuracy=0.968838865219, mean_iou=0.83455035005, iou=[ 0.94914486  0.95592949  0.77407885  0.60879557  0.88480298]
('frankfurt_000001_029600_leftImg8bit.png', 'frankfurt_000001_029600_gtFine_labelIds.png', 25)
('frankfurt_000001_030067_leftImg8bit.png', 'frankfurt_000001_030067_gtFine_labelIds.png', 25)
('frankfurt_000001_030310_leftImg8bit.png', 'frankfurt_000001_030310_gtFine_labelIds.png', 25)
('frankfurt_000001_030669_leftImg8bit.png', 'frankfurt_000001_030669_gtFine_labelIds.png', 25)
('frankfurt_000001_031266_leftImg8bit.png', 'frankfurt_000001_031266_gtFine_labelIds.png', 25)
('frankfurt_000001_031416_leftImg8bit.png', 'frankfurt_000001_031416_gtFine_labelIds.png', 26)
('frankfurt_000001_032018_leftImg8bit.png', 'frankfurt_000001_032018_gtFine_labelIds.png', 26)
('frankfurt_000001_032556_leftImg8bit.png', 'frankfurt_000001_032556_gtFine_labelIds.png', 26)
('frankfurt_000001_032711_leftImg8bit.png', 'frankfurt_000001_032711_gtFine_labelIds.png', 26)
('frankfurt_000001_032942_leftImg8bit.png', 'frankfurt_000001_032942_gtFine_labelIds.png', 26)
('frankfurt_000001_033655_leftImg8bit.png', 'frankfurt_000001_033655_gtFine_labelIds.png', 27)
('frankfurt_000001_034047_leftImg8bit.png', 'frankfurt_000001_034047_gtFine_labelIds.png', 27)
('frankfurt_000001_034816_leftImg8bit.png', 'frankfurt_000001_034816_gtFine_labelIds.png', 27)
('frankfurt_000001_035144_leftImg8bit.png', 'frankfurt_000001_035144_gtFine_labelIds.png', 27)
('frankfurt_000001_035864_leftImg8bit.png', 'frankfurt_000001_035864_gtFine_labelIds.png', 27)
('frankfurt_000001_037705_leftImg8bit.png', 'frankfurt_000001_037705_gtFine_labelIds.png', 28)
('frankfurt_000001_038245_leftImg8bit.png', 'frankfurt_000001_038245_gtFine_labelIds.png', 28)
('frankfurt_000001_038418_leftImg8bit.png', 'frankfurt_000001_038418_gtFine_labelIds.png', 28)
('frankfurt_000001_038645_leftImg8bit.png', 'frankfurt_000001_038645_gtFine_labelIds.png', 28)
('frankfurt_000001_038844_leftImg8bit.png', 'frankfurt_000001_038844_gtFine_labelIds.png', 28)
('frankfurt_000001_039895_leftImg8bit.png', 'frankfurt_000001_039895_gtFine_labelIds.png', 29)
('frankfurt_000001_040575_leftImg8bit.png', 'frankfurt_000001_040575_gtFine_labelIds.png', 29)
('frankfurt_000001_040732_leftImg8bit.png', 'frankfurt_000001_040732_gtFine_labelIds.png', 29)
('frankfurt_000001_041074_leftImg8bit.png', 'frankfurt_000001_041074_gtFine_labelIds.png', 29)
('frankfurt_000001_041354_leftImg8bit.png', 'frankfurt_000001_041354_gtFine_labelIds.png', 29)
pixel_accuracy=0.96905878053, mean_iou=0.831011319632, iou=[ 0.94929802  0.95715504  0.76049821  0.59535123  0.8927541 ]
('frankfurt_000001_041517_leftImg8bit.png', 'frankfurt_000001_041517_gtFine_labelIds.png', 30)
('frankfurt_000001_041664_leftImg8bit.png', 'frankfurt_000001_041664_gtFine_labelIds.png', 30)
('frankfurt_000001_042098_leftImg8bit.png', 'frankfurt_000001_042098_gtFine_labelIds.png', 30)
('frankfurt_000001_042384_leftImg8bit.png', 'frankfurt_000001_042384_gtFine_labelIds.png', 30)
('frankfurt_000001_042733_leftImg8bit.png', 'frankfurt_000001_042733_gtFine_labelIds.png', 30)
('frankfurt_000001_043395_leftImg8bit.png', 'frankfurt_000001_043395_gtFine_labelIds.png', 31)
('frankfurt_000001_043564_leftImg8bit.png', 'frankfurt_000001_043564_gtFine_labelIds.png', 31)
('frankfurt_000001_044227_leftImg8bit.png', 'frankfurt_000001_044227_gtFine_labelIds.png', 31)
('frankfurt_000001_044413_leftImg8bit.png', 'frankfurt_000001_044413_gtFine_labelIds.png', 31)
('frankfurt_000001_044525_leftImg8bit.png', 'frankfurt_000001_044525_gtFine_labelIds.png', 31)
('frankfurt_000001_044658_leftImg8bit.png', 'frankfurt_000001_044658_gtFine_labelIds.png', 32)
('frankfurt_000001_044787_leftImg8bit.png', 'frankfurt_000001_044787_gtFine_labelIds.png', 32)
('frankfurt_000001_046126_leftImg8bit.png', 'frankfurt_000001_046126_gtFine_labelIds.png', 32)
('frankfurt_000001_046272_leftImg8bit.png', 'frankfurt_000001_046272_gtFine_labelIds.png', 32)
('frankfurt_000001_046504_leftImg8bit.png', 'frankfurt_000001_046504_gtFine_labelIds.png', 32)
('frankfurt_000001_046779_leftImg8bit.png', 'frankfurt_000001_046779_gtFine_labelIds.png', 33)
('frankfurt_000001_047178_leftImg8bit.png', 'frankfurt_000001_047178_gtFine_labelIds.png', 33)
('frankfurt_000001_047552_leftImg8bit.png', 'frankfurt_000001_047552_gtFine_labelIds.png', 33)
('frankfurt_000001_048196_leftImg8bit.png', 'frankfurt_000001_048196_gtFine_labelIds.png', 33)
('frankfurt_000001_048355_leftImg8bit.png', 'frankfurt_000001_048355_gtFine_labelIds.png', 33)
('frankfurt_000001_048654_leftImg8bit.png', 'frankfurt_000001_048654_gtFine_labelIds.png', 34)
('frankfurt_000001_049078_leftImg8bit.png', 'frankfurt_000001_049078_gtFine_labelIds.png', 34)
('frankfurt_000001_049209_leftImg8bit.png', 'frankfurt_000001_049209_gtFine_labelIds.png', 34)
('frankfurt_000001_049298_leftImg8bit.png', 'frankfurt_000001_049298_gtFine_labelIds.png', 34)
('frankfurt_000001_049698_leftImg8bit.png', 'frankfurt_000001_049698_gtFine_labelIds.png', 34)
pixel_accuracy=0.970647704051, mean_iou=0.83309457919, iou=[ 0.95208879  0.95928845  0.76076087  0.59238484  0.90094994]
('frankfurt_000001_049770_leftImg8bit.png', 'frankfurt_000001_049770_gtFine_labelIds.png', 35)
('frankfurt_000001_050149_leftImg8bit.png', 'frankfurt_000001_050149_gtFine_labelIds.png', 35)
('frankfurt_000001_050686_leftImg8bit.png', 'frankfurt_000001_050686_gtFine_labelIds.png', 35)
('frankfurt_000001_051516_leftImg8bit.png', 'frankfurt_000001_051516_gtFine_labelIds.png', 35)
('frankfurt_000001_051737_leftImg8bit.png', 'frankfurt_000001_051737_gtFine_labelIds.png', 35)
('frankfurt_000001_051807_leftImg8bit.png', 'frankfurt_000001_051807_gtFine_labelIds.png', 36)
('frankfurt_000001_052120_leftImg8bit.png', 'frankfurt_000001_052120_gtFine_labelIds.png', 36)
('frankfurt_000001_052594_leftImg8bit.png', 'frankfurt_000001_052594_gtFine_labelIds.png', 36)
('frankfurt_000001_053102_leftImg8bit.png', 'frankfurt_000001_053102_gtFine_labelIds.png', 36)
('frankfurt_000001_054077_leftImg8bit.png', 'frankfurt_000001_054077_gtFine_labelIds.png', 36)
('frankfurt_000001_054219_leftImg8bit.png', 'frankfurt_000001_054219_gtFine_labelIds.png', 37)
('frankfurt_000001_054415_leftImg8bit.png', 'frankfurt_000001_054415_gtFine_labelIds.png', 37)
('frankfurt_000001_054640_leftImg8bit.png', 'frankfurt_000001_054640_gtFine_labelIds.png', 37)
('frankfurt_000001_054884_leftImg8bit.png', 'frankfurt_000001_054884_gtFine_labelIds.png', 37)
('frankfurt_000001_055062_leftImg8bit.png', 'frankfurt_000001_055062_gtFine_labelIds.png', 37)
('frankfurt_000001_055172_leftImg8bit.png', 'frankfurt_000001_055172_gtFine_labelIds.png', 38)
('frankfurt_000001_055306_leftImg8bit.png', 'frankfurt_000001_055306_gtFine_labelIds.png', 38)
('frankfurt_000001_055387_leftImg8bit.png', 'frankfurt_000001_055387_gtFine_labelIds.png', 38)
('frankfurt_000001_055538_leftImg8bit.png', 'frankfurt_000001_055538_gtFine_labelIds.png', 38)
('frankfurt_000001_055603_leftImg8bit.png', 'frankfurt_000001_055603_gtFine_labelIds.png', 38)
('frankfurt_000001_055709_leftImg8bit.png', 'frankfurt_000001_055709_gtFine_labelIds.png', 39)
('frankfurt_000001_056580_leftImg8bit.png', 'frankfurt_000001_056580_gtFine_labelIds.png', 39)
('frankfurt_000001_057181_leftImg8bit.png', 'frankfurt_000001_057181_gtFine_labelIds.png', 39)
('frankfurt_000001_057478_leftImg8bit.png', 'frankfurt_000001_057478_gtFine_labelIds.png', 39)
('frankfurt_000001_057954_leftImg8bit.png', 'frankfurt_000001_057954_gtFine_labelIds.png', 39)
pixel_accuracy=0.969999413328, mean_iou=0.834963784561, iou=[ 0.95101855  0.95950418  0.76934403  0.5959948   0.89895735]
('frankfurt_000001_058057_leftImg8bit.png', 'frankfurt_000001_058057_gtFine_labelIds.png', 40)
('frankfurt_000001_058176_leftImg8bit.png', 'frankfurt_000001_058176_gtFine_labelIds.png', 40)
('frankfurt_000001_058504_leftImg8bit.png', 'frankfurt_000001_058504_gtFine_labelIds.png', 40)
('frankfurt_000001_058914_leftImg8bit.png', 'frankfurt_000001_058914_gtFine_labelIds.png', 40)
('frankfurt_000001_059119_leftImg8bit.png', 'frankfurt_000001_059119_gtFine_labelIds.png', 40)
('frankfurt_000001_059642_leftImg8bit.png', 'frankfurt_000001_059642_gtFine_labelIds.png', 41)
('frankfurt_000001_059789_leftImg8bit.png', 'frankfurt_000001_059789_gtFine_labelIds.png', 41)
('frankfurt_000001_060135_leftImg8bit.png', 'frankfurt_000001_060135_gtFine_labelIds.png', 41)
('frankfurt_000001_060422_leftImg8bit.png', 'frankfurt_000001_060422_gtFine_labelIds.png', 41)
('frankfurt_000001_060545_leftImg8bit.png', 'frankfurt_000001_060545_gtFine_labelIds.png', 41)
('frankfurt_000001_060906_leftImg8bit.png', 'frankfurt_000001_060906_gtFine_labelIds.png', 42)
('frankfurt_000001_061682_leftImg8bit.png', 'frankfurt_000001_061682_gtFine_labelIds.png', 42)
('frankfurt_000001_061763_leftImg8bit.png', 'frankfurt_000001_061763_gtFine_labelIds.png', 42)
('frankfurt_000001_062016_leftImg8bit.png', 'frankfurt_000001_062016_gtFine_labelIds.png', 42)
('frankfurt_000001_062250_leftImg8bit.png', 'frankfurt_000001_062250_gtFine_labelIds.png', 42)
('frankfurt_000001_062396_leftImg8bit.png', 'frankfurt_000001_062396_gtFine_labelIds.png', 43)
('frankfurt_000001_062509_leftImg8bit.png', 'frankfurt_000001_062509_gtFine_labelIds.png', 43)
('frankfurt_000001_062653_leftImg8bit.png', 'frankfurt_000001_062653_gtFine_labelIds.png', 43)
('frankfurt_000001_062793_leftImg8bit.png', 'frankfurt_000001_062793_gtFine_labelIds.png', 43)
('frankfurt_000001_063045_leftImg8bit.png', 'frankfurt_000001_063045_gtFine_labelIds.png', 43)
('frankfurt_000001_064130_leftImg8bit.png', 'frankfurt_000001_064130_gtFine_labelIds.png', 44)
('frankfurt_000001_064305_leftImg8bit.png', 'frankfurt_000001_064305_gtFine_labelIds.png', 44)
('frankfurt_000001_064651_leftImg8bit.png', 'frankfurt_000001_064651_gtFine_labelIds.png', 44)
('frankfurt_000001_064798_leftImg8bit.png', 'frankfurt_000001_064798_gtFine_labelIds.png', 44)
('frankfurt_000001_064925_leftImg8bit.png', 'frankfurt_000001_064925_gtFine_labelIds.png', 44)
pixel_accuracy=0.970688027976, mean_iou=0.834976964202, iou=[ 0.95212156  0.96108342  0.76669725  0.5935226   0.90145999]
('frankfurt_000001_065160_leftImg8bit.png', 'frankfurt_000001_065160_gtFine_labelIds.png', 45)
('frankfurt_000001_065617_leftImg8bit.png', 'frankfurt_000001_065617_gtFine_labelIds.png', 45)
('frankfurt_000001_065850_leftImg8bit.png', 'frankfurt_000001_065850_gtFine_labelIds.png', 45)
('frankfurt_000001_066092_leftImg8bit.png', 'frankfurt_000001_066092_gtFine_labelIds.png', 45)
('frankfurt_000001_066438_leftImg8bit.png', 'frankfurt_000001_066438_gtFine_labelIds.png', 45)
('frankfurt_000001_066574_leftImg8bit.png', 'frankfurt_000001_066574_gtFine_labelIds.png', 46)
('frankfurt_000001_066832_leftImg8bit.png', 'frankfurt_000001_066832_gtFine_labelIds.png', 46)
('frankfurt_000001_067092_leftImg8bit.png', 'frankfurt_000001_067092_gtFine_labelIds.png', 46)
('frankfurt_000001_067178_leftImg8bit.png', 'frankfurt_000001_067178_gtFine_labelIds.png', 46)
('frankfurt_000001_067295_leftImg8bit.png', 'frankfurt_000001_067295_gtFine_labelIds.png', 46)
('frankfurt_000001_067474_leftImg8bit.png', 'frankfurt_000001_067474_gtFine_labelIds.png', 47)
('frankfurt_000001_067735_leftImg8bit.png', 'frankfurt_000001_067735_gtFine_labelIds.png', 47)
('frankfurt_000001_068063_leftImg8bit.png', 'frankfurt_000001_068063_gtFine_labelIds.png', 47)
('frankfurt_000001_068208_leftImg8bit.png', 'frankfurt_000001_068208_gtFine_labelIds.png', 47)
('frankfurt_000001_068682_leftImg8bit.png', 'frankfurt_000001_068682_gtFine_labelIds.png', 47)
('frankfurt_000001_068772_leftImg8bit.png', 'frankfurt_000001_068772_gtFine_labelIds.png', 48)
('frankfurt_000001_069633_leftImg8bit.png', 'frankfurt_000001_069633_gtFine_labelIds.png', 48)
('frankfurt_000001_070099_leftImg8bit.png', 'frankfurt_000001_070099_gtFine_labelIds.png', 48)
('frankfurt_000001_071288_leftImg8bit.png', 'frankfurt_000001_071288_gtFine_labelIds.png', 48)
('frankfurt_000001_071781_leftImg8bit.png', 'frankfurt_000001_071781_gtFine_labelIds.png', 48)
('frankfurt_000001_072155_leftImg8bit.png', 'frankfurt_000001_072155_gtFine_labelIds.png', 49)
('frankfurt_000001_072295_leftImg8bit.png', 'frankfurt_000001_072295_gtFine_labelIds.png', 49)
('frankfurt_000001_073088_leftImg8bit.png', 'frankfurt_000001_073088_gtFine_labelIds.png', 49)
('frankfurt_000001_073243_leftImg8bit.png', 'frankfurt_000001_073243_gtFine_labelIds.png', 49)
('frankfurt_000001_073464_leftImg8bit.png', 'frankfurt_000001_073464_gtFine_labelIds.png', 49)
pixel_accuracy=0.970003896556, mean_iou=0.832695941606, iou=[ 0.95089813  0.95915394  0.76418542  0.58628114  0.90296108]
('frankfurt_000001_073911_leftImg8bit.png', 'frankfurt_000001_073911_gtFine_labelIds.png', 50)
('frankfurt_000001_075296_leftImg8bit.png', 'frankfurt_000001_075296_gtFine_labelIds.png', 50)
('frankfurt_000001_075984_leftImg8bit.png', 'frankfurt_000001_075984_gtFine_labelIds.png', 50)
('frankfurt_000001_076502_leftImg8bit.png', 'frankfurt_000001_076502_gtFine_labelIds.png', 50)
('frankfurt_000001_077092_leftImg8bit.png', 'frankfurt_000001_077092_gtFine_labelIds.png', 50)
('frankfurt_000001_077233_leftImg8bit.png', 'frankfurt_000001_077233_gtFine_labelIds.png', 51)
('frankfurt_000001_077434_leftImg8bit.png', 'frankfurt_000001_077434_gtFine_labelIds.png', 51)
('frankfurt_000001_078803_leftImg8bit.png', 'frankfurt_000001_078803_gtFine_labelIds.png', 51)
('frankfurt_000001_079206_leftImg8bit.png', 'frankfurt_000001_079206_gtFine_labelIds.png', 51)
('frankfurt_000001_080091_leftImg8bit.png', 'frankfurt_000001_080091_gtFine_labelIds.png', 51)
('frankfurt_000001_080391_leftImg8bit.png', 'frankfurt_000001_080391_gtFine_labelIds.png', 52)
('frankfurt_000001_080830_leftImg8bit.png', 'frankfurt_000001_080830_gtFine_labelIds.png', 52)
('frankfurt_000001_082087_leftImg8bit.png', 'frankfurt_000001_082087_gtFine_labelIds.png', 52)
('frankfurt_000001_082466_leftImg8bit.png', 'frankfurt_000001_082466_gtFine_labelIds.png', 52)
('frankfurt_000001_083029_leftImg8bit.png', 'frankfurt_000001_083029_gtFine_labelIds.png', 52)
('frankfurt_000001_083199_leftImg8bit.png', 'frankfurt_000001_083199_gtFine_labelIds.png', 53)
('frankfurt_000001_083852_leftImg8bit.png', 'frankfurt_000001_083852_gtFine_labelIds.png', 53)
('lindau_000000_000019_leftImg8bit.png', 'lindau_000000_000019_gtFine_labelIds.png', 53)
('lindau_000001_000019_leftImg8bit.png', 'lindau_000001_000019_gtFine_labelIds.png', 53)
('lindau_000002_000019_leftImg8bit.png', 'lindau_000002_000019_gtFine_labelIds.png', 53)
('lindau_000003_000019_leftImg8bit.png', 'lindau_000003_000019_gtFine_labelIds.png', 54)
('lindau_000004_000019_leftImg8bit.png', 'lindau_000004_000019_gtFine_labelIds.png', 54)
('lindau_000005_000019_leftImg8bit.png', 'lindau_000005_000019_gtFine_labelIds.png', 54)
('lindau_000006_000019_leftImg8bit.png', 'lindau_000006_000019_gtFine_labelIds.png', 54)
('lindau_000007_000019_leftImg8bit.png', 'lindau_000007_000019_gtFine_labelIds.png', 54)
pixel_accuracy=0.970440330527, mean_iou=0.83172495059, iou=[ 0.9516196   0.9600871   0.75959894  0.58496211  0.902357  ]
('lindau_000008_000019_leftImg8bit.png', 'lindau_000008_000019_gtFine_labelIds.png', 55)
('lindau_000009_000019_leftImg8bit.png', 'lindau_000009_000019_gtFine_labelIds.png', 55)
('lindau_000010_000019_leftImg8bit.png', 'lindau_000010_000019_gtFine_labelIds.png', 55)
('lindau_000011_000019_leftImg8bit.png', 'lindau_000011_000019_gtFine_labelIds.png', 55)
('lindau_000012_000019_leftImg8bit.png', 'lindau_000012_000019_gtFine_labelIds.png', 55)
('lindau_000013_000019_leftImg8bit.png', 'lindau_000013_000019_gtFine_labelIds.png', 56)
('lindau_000014_000019_leftImg8bit.png', 'lindau_000014_000019_gtFine_labelIds.png', 56)
('lindau_000015_000019_leftImg8bit.png', 'lindau_000015_000019_gtFine_labelIds.png', 56)
('lindau_000016_000019_leftImg8bit.png', 'lindau_000016_000019_gtFine_labelIds.png', 56)
('lindau_000017_000019_leftImg8bit.png', 'lindau_000017_000019_gtFine_labelIds.png', 56)
('lindau_000018_000019_leftImg8bit.png', 'lindau_000018_000019_gtFine_labelIds.png', 57)
('lindau_000019_000019_leftImg8bit.png', 'lindau_000019_000019_gtFine_labelIds.png', 57)
('lindau_000020_000019_leftImg8bit.png', 'lindau_000020_000019_gtFine_labelIds.png', 57)
('lindau_000021_000019_leftImg8bit.png', 'lindau_000021_000019_gtFine_labelIds.png', 57)
('lindau_000022_000019_leftImg8bit.png', 'lindau_000022_000019_gtFine_labelIds.png', 57)
('lindau_000023_000019_leftImg8bit.png', 'lindau_000023_000019_gtFine_labelIds.png', 58)
('lindau_000024_000019_leftImg8bit.png', 'lindau_000024_000019_gtFine_labelIds.png', 58)
('lindau_000025_000019_leftImg8bit.png', 'lindau_000025_000019_gtFine_labelIds.png', 58)
('lindau_000026_000019_leftImg8bit.png', 'lindau_000026_000019_gtFine_labelIds.png', 58)
('lindau_000027_000019_leftImg8bit.png', 'lindau_000027_000019_gtFine_labelIds.png', 58)
('lindau_000028_000019_leftImg8bit.png', 'lindau_000028_000019_gtFine_labelIds.png', 59)
('lindau_000029_000019_leftImg8bit.png', 'lindau_000029_000019_gtFine_labelIds.png', 59)
('lindau_000030_000019_leftImg8bit.png', 'lindau_000030_000019_gtFine_labelIds.png', 59)
('lindau_000031_000019_leftImg8bit.png', 'lindau_000031_000019_gtFine_labelIds.png', 59)
('lindau_000032_000019_leftImg8bit.png', 'lindau_000032_000019_gtFine_labelIds.png', 59)
pixel_accuracy=0.965740405738, mean_iou=0.826917110839, iou=[ 0.94440652  0.94556066  0.75533796  0.59063083  0.89864958]
('lindau_000033_000019_leftImg8bit.png', 'lindau_000033_000019_gtFine_labelIds.png', 60)
('lindau_000034_000019_leftImg8bit.png', 'lindau_000034_000019_gtFine_labelIds.png', 60)
('lindau_000035_000019_leftImg8bit.png', 'lindau_000035_000019_gtFine_labelIds.png', 60)
('lindau_000036_000019_leftImg8bit.png', 'lindau_000036_000019_gtFine_labelIds.png', 60)
('lindau_000037_000019_leftImg8bit.png', 'lindau_000037_000019_gtFine_labelIds.png', 60)
('lindau_000038_000019_leftImg8bit.png', 'lindau_000038_000019_gtFine_labelIds.png', 61)
('lindau_000039_000019_leftImg8bit.png', 'lindau_000039_000019_gtFine_labelIds.png', 61)
('lindau_000040_000019_leftImg8bit.png', 'lindau_000040_000019_gtFine_labelIds.png', 61)
('lindau_000041_000019_leftImg8bit.png', 'lindau_000041_000019_gtFine_labelIds.png', 61)
('lindau_000042_000019_leftImg8bit.png', 'lindau_000042_000019_gtFine_labelIds.png', 61)
('lindau_000043_000019_leftImg8bit.png', 'lindau_000043_000019_gtFine_labelIds.png', 62)
('lindau_000044_000019_leftImg8bit.png', 'lindau_000044_000019_gtFine_labelIds.png', 62)
('lindau_000045_000019_leftImg8bit.png', 'lindau_000045_000019_gtFine_labelIds.png', 62)
('lindau_000046_000019_leftImg8bit.png', 'lindau_000046_000019_gtFine_labelIds.png', 62)
('lindau_000047_000019_leftImg8bit.png', 'lindau_000047_000019_gtFine_labelIds.png', 62)
('lindau_000048_000019_leftImg8bit.png', 'lindau_000048_000019_gtFine_labelIds.png', 63)
('lindau_000049_000019_leftImg8bit.png', 'lindau_000049_000019_gtFine_labelIds.png', 63)
('lindau_000050_000019_leftImg8bit.png', 'lindau_000050_000019_gtFine_labelIds.png', 63)
('lindau_000051_000019_leftImg8bit.png', 'lindau_000051_000019_gtFine_labelIds.png', 63)
('lindau_000052_000019_leftImg8bit.png', 'lindau_000052_000019_gtFine_labelIds.png', 63)
('lindau_000053_000019_leftImg8bit.png', 'lindau_000053_000019_gtFine_labelIds.png', 64)
('lindau_000054_000019_leftImg8bit.png', 'lindau_000054_000019_gtFine_labelIds.png', 64)
('lindau_000055_000019_leftImg8bit.png', 'lindau_000055_000019_gtFine_labelIds.png', 64)
('lindau_000056_000019_leftImg8bit.png', 'lindau_000056_000019_gtFine_labelIds.png', 64)
('lindau_000057_000019_leftImg8bit.png', 'lindau_000057_000019_gtFine_labelIds.png', 64)
pixel_accuracy=0.95712039997, mean_iou=0.817963072275, iou=[ 0.93113378  0.91893559  0.75031167  0.58924937  0.90018496]
('lindau_000058_000019_leftImg8bit.png', 'lindau_000058_000019_gtFine_labelIds.png', 65)
('munster_000000_000019_leftImg8bit.png', 'munster_000000_000019_gtFine_labelIds.png', 65)
('munster_000001_000019_leftImg8bit.png', 'munster_000001_000019_gtFine_labelIds.png', 65)
('munster_000002_000019_leftImg8bit.png', 'munster_000002_000019_gtFine_labelIds.png', 65)
('munster_000003_000019_leftImg8bit.png', 'munster_000003_000019_gtFine_labelIds.png', 65)
('munster_000004_000019_leftImg8bit.png', 'munster_000004_000019_gtFine_labelIds.png', 66)
('munster_000005_000019_leftImg8bit.png', 'munster_000005_000019_gtFine_labelIds.png', 66)
('munster_000006_000019_leftImg8bit.png', 'munster_000006_000019_gtFine_labelIds.png', 66)
('munster_000007_000019_leftImg8bit.png', 'munster_000007_000019_gtFine_labelIds.png', 66)
('munster_000008_000019_leftImg8bit.png', 'munster_000008_000019_gtFine_labelIds.png', 66)
('munster_000009_000019_leftImg8bit.png', 'munster_000009_000019_gtFine_labelIds.png', 67)
('munster_000010_000019_leftImg8bit.png', 'munster_000010_000019_gtFine_labelIds.png', 67)
('munster_000011_000019_leftImg8bit.png', 'munster_000011_000019_gtFine_labelIds.png', 67)
('munster_000012_000019_leftImg8bit.png', 'munster_000012_000019_gtFine_labelIds.png', 67)
('munster_000013_000019_leftImg8bit.png', 'munster_000013_000019_gtFine_labelIds.png', 67)
('munster_000014_000019_leftImg8bit.png', 'munster_000014_000019_gtFine_labelIds.png', 68)
('munster_000015_000019_leftImg8bit.png', 'munster_000015_000019_gtFine_labelIds.png', 68)
('munster_000016_000019_leftImg8bit.png', 'munster_000016_000019_gtFine_labelIds.png', 68)
('munster_000017_000019_leftImg8bit.png', 'munster_000017_000019_gtFine_labelIds.png', 68)
('munster_000018_000019_leftImg8bit.png', 'munster_000018_000019_gtFine_labelIds.png', 68)
('munster_000019_000019_leftImg8bit.png', 'munster_000019_000019_gtFine_labelIds.png', 69)
('munster_000020_000019_leftImg8bit.png', 'munster_000020_000019_gtFine_labelIds.png', 69)
('munster_000021_000019_leftImg8bit.png', 'munster_000021_000019_gtFine_labelIds.png', 69)
('munster_000022_000019_leftImg8bit.png', 'munster_000022_000019_gtFine_labelIds.png', 69)
('munster_000023_000019_leftImg8bit.png', 'munster_000023_000019_gtFine_labelIds.png', 69)
pixel_accuracy=0.958792741076, mean_iou=0.821045703282, iou=[ 0.93369933  0.92282975  0.75041086  0.5958472   0.90244137]
('munster_000024_000019_leftImg8bit.png', 'munster_000024_000019_gtFine_labelIds.png', 70)
('munster_000025_000019_leftImg8bit.png', 'munster_000025_000019_gtFine_labelIds.png', 70)
('munster_000026_000019_leftImg8bit.png', 'munster_000026_000019_gtFine_labelIds.png', 70)
('munster_000027_000019_leftImg8bit.png', 'munster_000027_000019_gtFine_labelIds.png', 70)
('munster_000028_000019_leftImg8bit.png', 'munster_000028_000019_gtFine_labelIds.png', 70)
('munster_000029_000019_leftImg8bit.png', 'munster_000029_000019_gtFine_labelIds.png', 71)
('munster_000030_000019_leftImg8bit.png', 'munster_000030_000019_gtFine_labelIds.png', 71)
('munster_000031_000019_leftImg8bit.png', 'munster_000031_000019_gtFine_labelIds.png', 71)
('munster_000032_000019_leftImg8bit.png', 'munster_000032_000019_gtFine_labelIds.png', 71)
('munster_000033_000019_leftImg8bit.png', 'munster_000033_000019_gtFine_labelIds.png', 71)
('munster_000034_000019_leftImg8bit.png', 'munster_000034_000019_gtFine_labelIds.png', 72)
('munster_000035_000019_leftImg8bit.png', 'munster_000035_000019_gtFine_labelIds.png', 72)
('munster_000036_000019_leftImg8bit.png', 'munster_000036_000019_gtFine_labelIds.png', 72)
('munster_000037_000019_leftImg8bit.png', 'munster_000037_000019_gtFine_labelIds.png', 72)
('munster_000038_000019_leftImg8bit.png', 'munster_000038_000019_gtFine_labelIds.png', 72)
('munster_000039_000019_leftImg8bit.png', 'munster_000039_000019_gtFine_labelIds.png', 73)
('munster_000040_000019_leftImg8bit.png', 'munster_000040_000019_gtFine_labelIds.png', 73)
('munster_000041_000019_leftImg8bit.png', 'munster_000041_000019_gtFine_labelIds.png', 73)
('munster_000042_000019_leftImg8bit.png', 'munster_000042_000019_gtFine_labelIds.png', 73)
('munster_000043_000019_leftImg8bit.png', 'munster_000043_000019_gtFine_labelIds.png', 73)
('munster_000044_000019_leftImg8bit.png', 'munster_000044_000019_gtFine_labelIds.png', 74)
('munster_000045_000019_leftImg8bit.png', 'munster_000045_000019_gtFine_labelIds.png', 74)
('munster_000046_000019_leftImg8bit.png', 'munster_000046_000019_gtFine_labelIds.png', 74)
('munster_000047_000019_leftImg8bit.png', 'munster_000047_000019_gtFine_labelIds.png', 74)
('munster_000048_000019_leftImg8bit.png', 'munster_000048_000019_gtFine_labelIds.png', 74)
pixel_accuracy=0.959896002176, mean_iou=0.824501334647, iou=[ 0.93550524  0.92572624  0.75975957  0.60016047  0.90135516]
('munster_000049_000019_leftImg8bit.png', 'munster_000049_000019_gtFine_labelIds.png', 75)
('munster_000050_000019_leftImg8bit.png', 'munster_000050_000019_gtFine_labelIds.png', 75)
('munster_000051_000019_leftImg8bit.png', 'munster_000051_000019_gtFine_labelIds.png', 75)
('munster_000052_000019_leftImg8bit.png', 'munster_000052_000019_gtFine_labelIds.png', 75)
('munster_000053_000019_leftImg8bit.png', 'munster_000053_000019_gtFine_labelIds.png', 75)
('munster_000054_000019_leftImg8bit.png', 'munster_000054_000019_gtFine_labelIds.png', 76)
('munster_000055_000019_leftImg8bit.png', 'munster_000055_000019_gtFine_labelIds.png', 76)
('munster_000056_000019_leftImg8bit.png', 'munster_000056_000019_gtFine_labelIds.png', 76)
('munster_000057_000019_leftImg8bit.png', 'munster_000057_000019_gtFine_labelIds.png', 76)
('munster_000058_000019_leftImg8bit.png', 'munster_000058_000019_gtFine_labelIds.png', 76)
('munster_000059_000019_leftImg8bit.png', 'munster_000059_000019_gtFine_labelIds.png', 77)
('munster_000060_000019_leftImg8bit.png', 'munster_000060_000019_gtFine_labelIds.png', 77)
('munster_000061_000019_leftImg8bit.png', 'munster_000061_000019_gtFine_labelIds.png', 77)
('munster_000062_000019_leftImg8bit.png', 'munster_000062_000019_gtFine_labelIds.png', 77)
('munster_000063_000019_leftImg8bit.png', 'munster_000063_000019_gtFine_labelIds.png', 77)
('munster_000064_000019_leftImg8bit.png', 'munster_000064_000019_gtFine_labelIds.png', 78)
('munster_000065_000019_leftImg8bit.png', 'munster_000065_000019_gtFine_labelIds.png', 78)
('munster_000066_000019_leftImg8bit.png', 'munster_000066_000019_gtFine_labelIds.png', 78)
('munster_000067_000019_leftImg8bit.png', 'munster_000067_000019_gtFine_labelIds.png', 78)
('munster_000068_000019_leftImg8bit.png', 'munster_000068_000019_gtFine_labelIds.png', 78)
('munster_000069_000019_leftImg8bit.png', 'munster_000069_000019_gtFine_labelIds.png', 79)
('munster_000070_000019_leftImg8bit.png', 'munster_000070_000019_gtFine_labelIds.png', 79)
('munster_000071_000019_leftImg8bit.png', 'munster_000071_000019_gtFine_labelIds.png', 79)
('munster_000072_000019_leftImg8bit.png', 'munster_000072_000019_gtFine_labelIds.png', 79)
('munster_000073_000019_leftImg8bit.png', 'munster_000073_000019_gtFine_labelIds.png', 79)
pixel_accuracy=0.960996849719, mean_iou=0.826798523264, iou=[ 0.93719747  0.92874884  0.76021238  0.60448903  0.90334489]
('munster_000074_000019_leftImg8bit.png', 'munster_000074_000019_gtFine_labelIds.png', 80)
('munster_000075_000019_leftImg8bit.png', 'munster_000075_000019_gtFine_labelIds.png', 80)
('munster_000076_000019_leftImg8bit.png', 'munster_000076_000019_gtFine_labelIds.png', 80)
('munster_000077_000019_leftImg8bit.png', 'munster_000077_000019_gtFine_labelIds.png', 80)
('munster_000078_000019_leftImg8bit.png', 'munster_000078_000019_gtFine_labelIds.png', 80)
('munster_000079_000019_leftImg8bit.png', 'munster_000079_000019_gtFine_labelIds.png', 81)
('munster_000080_000019_leftImg8bit.png', 'munster_000080_000019_gtFine_labelIds.png', 81)
('munster_000081_000019_leftImg8bit.png', 'munster_000081_000019_gtFine_labelIds.png', 81)
('munster_000082_000019_leftImg8bit.png', 'munster_000082_000019_gtFine_labelIds.png', 81)
('munster_000083_000019_leftImg8bit.png', 'munster_000083_000019_gtFine_labelIds.png', 81)
('munster_000084_000019_leftImg8bit.png', 'munster_000084_000019_gtFine_labelIds.png', 82)
('munster_000085_000019_leftImg8bit.png', 'munster_000085_000019_gtFine_labelIds.png', 82)
('munster_000086_000019_leftImg8bit.png', 'munster_000086_000019_gtFine_labelIds.png', 82)
('munster_000087_000019_leftImg8bit.png', 'munster_000087_000019_gtFine_labelIds.png', 82)
('munster_000088_000019_leftImg8bit.png', 'munster_000088_000019_gtFine_labelIds.png', 82)
('munster_000089_000019_leftImg8bit.png', 'munster_000089_000019_gtFine_labelIds.png', 83)
('munster_000090_000019_leftImg8bit.png', 'munster_000090_000019_gtFine_labelIds.png', 83)
('munster_000091_000019_leftImg8bit.png', 'munster_000091_000019_gtFine_labelIds.png', 83)
('munster_000092_000019_leftImg8bit.png', 'munster_000092_000019_gtFine_labelIds.png', 83)
('munster_000093_000019_leftImg8bit.png', 'munster_000093_000019_gtFine_labelIds.png', 83)
('munster_000094_000019_leftImg8bit.png', 'munster_000094_000019_gtFine_labelIds.png', 84)
('munster_000095_000019_leftImg8bit.png', 'munster_000095_000019_gtFine_labelIds.png', 84)
('munster_000096_000019_leftImg8bit.png', 'munster_000096_000019_gtFine_labelIds.png', 84)
('munster_000097_000019_leftImg8bit.png', 'munster_000097_000019_gtFine_labelIds.png', 84)
('munster_000098_000019_leftImg8bit.png', 'munster_000098_000019_gtFine_labelIds.png', 84)
pixel_accuracy=0.962301384919, mean_iou=0.829303174746, iou=[ 0.93915718  0.9315307   0.76041041  0.60720558  0.90821201]
('munster_000099_000019_leftImg8bit.png', 'munster_000099_000019_gtFine_labelIds.png', 85)
('munster_000100_000019_leftImg8bit.png', 'munster_000100_000019_gtFine_labelIds.png', 85)
('munster_000101_000019_leftImg8bit.png', 'munster_000101_000019_gtFine_labelIds.png', 85)
('munster_000102_000019_leftImg8bit.png', 'munster_000102_000019_gtFine_labelIds.png', 85)
('munster_000103_000019_leftImg8bit.png', 'munster_000103_000019_gtFine_labelIds.png', 85)
('munster_000104_000019_leftImg8bit.png', 'munster_000104_000019_gtFine_labelIds.png', 86)
('munster_000105_000019_leftImg8bit.png', 'munster_000105_000019_gtFine_labelIds.png', 86)
('munster_000106_000019_leftImg8bit.png', 'munster_000106_000019_gtFine_labelIds.png', 86)
('munster_000107_000019_leftImg8bit.png', 'munster_000107_000019_gtFine_labelIds.png', 86)
('munster_000108_000019_leftImg8bit.png', 'munster_000108_000019_gtFine_labelIds.png', 86)
('munster_000109_000019_leftImg8bit.png', 'munster_000109_000019_gtFine_labelIds.png', 87)
('munster_000110_000019_leftImg8bit.png', 'munster_000110_000019_gtFine_labelIds.png', 87)
('munster_000111_000019_leftImg8bit.png', 'munster_000111_000019_gtFine_labelIds.png', 87)
('munster_000112_000019_leftImg8bit.png', 'munster_000112_000019_gtFine_labelIds.png', 87)
('munster_000113_000019_leftImg8bit.png', 'munster_000113_000019_gtFine_labelIds.png', 87)
('munster_000114_000019_leftImg8bit.png', 'munster_000114_000019_gtFine_labelIds.png', 88)
('munster_000115_000019_leftImg8bit.png', 'munster_000115_000019_gtFine_labelIds.png', 88)
('munster_000116_000019_leftImg8bit.png', 'munster_000116_000019_gtFine_labelIds.png', 88)
('munster_000117_000019_leftImg8bit.png', 'munster_000117_000019_gtFine_labelIds.png', 88)
('munster_000118_000019_leftImg8bit.png', 'munster_000118_000019_gtFine_labelIds.png', 88)
('munster_000119_000019_leftImg8bit.png', 'munster_000119_000019_gtFine_labelIds.png', 89)
('munster_000120_000019_leftImg8bit.png', 'munster_000120_000019_gtFine_labelIds.png', 89)
('munster_000121_000019_leftImg8bit.png', 'munster_000121_000019_gtFine_labelIds.png', 89)
('munster_000122_000019_leftImg8bit.png', 'munster_000122_000019_gtFine_labelIds.png', 89)
('munster_000123_000019_leftImg8bit.png', 'munster_000123_000019_gtFine_labelIds.png', 89)
pixel_accuracy=0.963610478217, mean_iou=0.830526695821, iou=[ 0.94120039  0.93437815  0.75985736  0.6070481   0.91014948]
('munster_000124_000019_leftImg8bit.png', 'munster_000124_000019_gtFine_labelIds.png', 90)
('munster_000125_000019_leftImg8bit.png', 'munster_000125_000019_gtFine_labelIds.png', 90)
('munster_000126_000019_leftImg8bit.png', 'munster_000126_000019_gtFine_labelIds.png', 90)
('munster_000127_000019_leftImg8bit.png', 'munster_000127_000019_gtFine_labelIds.png', 90)
('munster_000128_000019_leftImg8bit.png', 'munster_000128_000019_gtFine_labelIds.png', 90)
('munster_000129_000019_leftImg8bit.png', 'munster_000129_000019_gtFine_labelIds.png', 91)
('munster_000130_000019_leftImg8bit.png', 'munster_000130_000019_gtFine_labelIds.png', 91)
('munster_000131_000019_leftImg8bit.png', 'munster_000131_000019_gtFine_labelIds.png', 91)
('munster_000132_000019_leftImg8bit.png', 'munster_000132_000019_gtFine_labelIds.png', 91)
('munster_000133_000019_leftImg8bit.png', 'munster_000133_000019_gtFine_labelIds.png', 91)
('munster_000134_000019_leftImg8bit.png', 'munster_000134_000019_gtFine_labelIds.png', 92)
('munster_000135_000019_leftImg8bit.png', 'munster_000135_000019_gtFine_labelIds.png', 92)
('munster_000136_000019_leftImg8bit.png', 'munster_000136_000019_gtFine_labelIds.png', 92)
('munster_000137_000019_leftImg8bit.png', 'munster_000137_000019_gtFine_labelIds.png', 92)
('munster_000138_000019_leftImg8bit.png', 'munster_000138_000019_gtFine_labelIds.png', 92)
('munster_000139_000019_leftImg8bit.png', 'munster_000139_000019_gtFine_labelIds.png', 93)
('munster_000140_000019_leftImg8bit.png', 'munster_000140_000019_gtFine_labelIds.png', 93)
('munster_000141_000019_leftImg8bit.png', 'munster_000141_000019_gtFine_labelIds.png', 93)
('munster_000142_000019_leftImg8bit.png', 'munster_000142_000019_gtFine_labelIds.png', 93)
('munster_000143_000019_leftImg8bit.png', 'munster_000143_000019_gtFine_labelIds.png', 93)
('munster_000144_000019_leftImg8bit.png', 'munster_000144_000019_gtFine_labelIds.png', 94)
('munster_000145_000019_leftImg8bit.png', 'munster_000145_000019_gtFine_labelIds.png', 94)
('munster_000146_000019_leftImg8bit.png', 'munster_000146_000019_gtFine_labelIds.png', 94)
('munster_000147_000019_leftImg8bit.png', 'munster_000147_000019_gtFine_labelIds.png', 94)
('munster_000148_000019_leftImg8bit.png', 'munster_000148_000019_gtFine_labelIds.png', 94)
pixel_accuracy=0.96058716742, mean_iou=0.828967101012, iou=[ 0.93627499  0.92575327  0.76481384  0.60734732  0.91064609]
('munster_000149_000019_leftImg8bit.png', 'munster_000149_000019_gtFine_labelIds.png', 95)
('munster_000150_000019_leftImg8bit.png', 'munster_000150_000019_gtFine_labelIds.png', 95)
('munster_000151_000019_leftImg8bit.png', 'munster_000151_000019_gtFine_labelIds.png', 95)
('munster_000152_000019_leftImg8bit.png', 'munster_000152_000019_gtFine_labelIds.png', 95)
('munster_000153_000019_leftImg8bit.png', 'munster_000153_000019_gtFine_labelIds.png', 95)
('munster_000154_000019_leftImg8bit.png', 'munster_000154_000019_gtFine_labelIds.png', 96)
('munster_000155_000019_leftImg8bit.png', 'munster_000155_000019_gtFine_labelIds.png', 96)
('munster_000156_000019_leftImg8bit.png', 'munster_000156_000019_gtFine_labelIds.png', 96)
('munster_000157_000019_leftImg8bit.png', 'munster_000157_000019_gtFine_labelIds.png', 96)
('munster_000158_000019_leftImg8bit.png', 'munster_000158_000019_gtFine_labelIds.png', 96)
('munster_000159_000019_leftImg8bit.png', 'munster_000159_000019_gtFine_labelIds.png', 97)
('munster_000160_000019_leftImg8bit.png', 'munster_000160_000019_gtFine_labelIds.png', 97)
('munster_000161_000019_leftImg8bit.png', 'munster_000161_000019_gtFine_labelIds.png', 97)
('munster_000162_000019_leftImg8bit.png', 'munster_000162_000019_gtFine_labelIds.png', 97)
('munster_000163_000019_leftImg8bit.png', 'munster_000163_000019_gtFine_labelIds.png', 97)
('munster_000164_000019_leftImg8bit.png', 'munster_000164_000019_gtFine_labelIds.png', 98)
('munster_000165_000019_leftImg8bit.png', 'munster_000165_000019_gtFine_labelIds.png', 98)
('munster_000166_000019_leftImg8bit.png', 'munster_000166_000019_gtFine_labelIds.png', 98)
('munster_000167_000019_leftImg8bit.png', 'munster_000167_000019_gtFine_labelIds.png', 98)
('munster_000168_000019_leftImg8bit.png', 'munster_000168_000019_gtFine_labelIds.png', 98)
('munster_000169_000019_leftImg8bit.png', 'munster_000169_000019_gtFine_labelIds.png', 99)
('munster_000170_000019_leftImg8bit.png', 'munster_000170_000019_gtFine_labelIds.png', 99)
('munster_000171_000019_leftImg8bit.png', 'munster_000171_000019_gtFine_labelIds.png', 99)
('munster_000172_000019_leftImg8bit.png', 'munster_000172_000019_gtFine_labelIds.png', 99)
('munster_000173_000019_leftImg8bit.png', 'munster_000173_000019_gtFine_labelIds.png', 99)
pixel_accuracy=0.961141580451, mean_iou=0.830623414181, iou=[ 0.93721945  0.92693614  0.76513723  0.61265578  0.91116848]
-------------------------------------------------------------
Final: pixel_accuracy=0.961141580451, mean_iou=0.830623414181, iou=[ 0.93721945  0.92693614  0.76513723  0.61265578  0.91116848]
-------------------------------------------------------------
sparse eval.
