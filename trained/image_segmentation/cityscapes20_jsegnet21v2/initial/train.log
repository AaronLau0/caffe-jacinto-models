I0630 19:26:26.753027  5429 caffe.cpp:209] Using GPUs 0, 1, 2
I0630 19:26:26.753481  5429 caffe.cpp:214] GPU 0: GeForce GTX 1080
I0630 19:26:26.753815  5429 caffe.cpp:214] GPU 1: GeForce GTX 1080
I0630 19:26:26.754145  5429 caffe.cpp:214] GPU 2: GeForce GTX 1080
I0630 19:26:27.687506  5429 solver.cpp:48] Initializing solver from parameters: 
train_net: "training/cityscapes20_jsegnet21v2_2017-06-30_19-26-17/initial/train.prototxt"
test_net: "training/cityscapes20_jsegnet21v2_2017-06-30_19-26-17/initial/test.prototxt"
test_iter: 125
test_interval: 2000
base_lr: 0.0001
display: 100
max_iter: 32000
lr_policy: "multistep"
gamma: 0.1
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 10000
snapshot_prefix: "training/cityscapes20_jsegnet21v2_2017-06-30_19-26-17/initial/cityscapes20_jsegnet21v2"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
snapshot_after_train: true
test_initialization: false
stepvalue: 24000
iter_size: 1
type: "Adam"
I0630 19:26:27.693665  5429 solver.cpp:82] Creating training net from train_net file: training/cityscapes20_jsegnet21v2_2017-06-30_19-26-17/initial/train.prototxt
I0630 19:26:27.698935  5429 net.cpp:327] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top1
I0630 19:26:27.698979  5429 net.cpp:327] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top5
I0630 19:26:27.700279  5429 net.cpp:56] Initializing net from parameters: 
name: "jsegnet21v2_train"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageLabelData"
  top: "data"
  top: "label"
  transform_param {
    mirror: true
    crop_size: 640
    mean_value: 0
  }
  image_label_data_param {
    image_list_path: "data/train-image-lmdb"
    label_list_path: "data/train-label-lmdb"
    batch_size: 5
    threads: 4
    backend: LMDB
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a/bn"
  top: "conv1a/bn"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a/bn"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b/bn"
  top: "conv1b/bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b/bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2a/bn"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b/bn"
  top: "res2a_branch2b/bn"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b/bn"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2a/bn"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b/bn"
  top: "res3a_branch2b/bn"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b/bn"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2a/bn"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b/bn"
  top: "res4a_branch2b/bn"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b/bn"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2a/bn"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b/bn"
  top: "res5a_branch2b/bn"
}
layer {
  name: "out5a"
  type: "Convolution"
  bottom: "res5a_branch2b/bn"
  top: "out5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "out5a/bn"
  type: "BatchNorm"
  bottom: "out5a"
  top: "out5a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "out5a/relu"
  type: "ReLU"
  bottom: "out5a/bn"
  top: "out5a/bn"
}
layer {
  name: "out5a_up2"
  type: "Deconvolution"
  bottom: "out5a/bn"
  top: "out5a_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 64
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out3a"
  type: "Convolution"
  bottom: "res3a_branch2b/bn"
  top: "out3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "out3a/bn"
  type: "BatchNorm"
  bottom: "out3a"
  top: "out3a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "out3a/relu"
  type: "ReLU"
  bottom: "out3a/bn"
  top: "out3a/bn"
}
layer {
  name: "out3_out5_combined"
  type: "Eltwise"
  bottom: "out5a_up2"
  bottom: "out3a/bn"
  top: "out3_out5_combined"
}
layer {
  name: "ctx_conv1"
  type: "Convolution"
  bottom: "out3_out5_combined"
  top: "ctx_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_conv1/bn"
  type: "BatchNorm"
  bottom: "ctx_conv1"
  top: "ctx_conv1/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ctx_conv1/relu"
  type: "ReLU"
  bottom: "ctx_conv1/bn"
  top: "ctx_conv1/bn"
}
layer {
  name: "ctx_conv2"
  type: "Convolution"
  bottom: "ctx_conv1/bn"
  top: "ctx_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv2/bn"
  type: "BatchNorm"
  bottom: "ctx_conv2"
  top: "ctx_conv2/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ctx_conv2/relu"
  type: "ReLU"
  bottom: "ctx_conv2/bn"
  top: "ctx_conv2/bn"
}
layer {
  name: "ctx_conv3"
  type: "Convolution"
  bottom: "ctx_conv2/bn"
  top: "ctx_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv3/bn"
  type: "BatchNorm"
  bottom: "ctx_conv3"
  top: "ctx_conv3/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ctx_conv3/relu"
  type: "ReLU"
  bottom: "ctx_conv3/bn"
  top: "ctx_conv3/bn"
}
layer {
  name: "ctx_conv4"
  type: "Convolution"
  bottom: "ctx_conv3/bn"
  top: "ctx_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv4/bn"
  type: "BatchNorm"
  bottom: "ctx_conv4"
  top: "ctx_conv4/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ctx_conv4/relu"
  type: "ReLU"
  bottom: "ctx_conv4/bn"
  top: "ctx_conv4/bn"
}
layer {
  name: "ctx_final"
  type: "Convolution"
  bottom: "ctx_conv4/bn"
  top: "ctx_final"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    bias_term: true
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_final/relu"
  type: "ReLU"
  bottom: "ctx_final"
  top: "ctx_final"
}
layer {
  name: "out_deconv_final_up2"
  type: "Deconvolution"
  bottom: "ctx_final"
  top: "out_deconv_final_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 20
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up4"
  type: "Deconvolution"
  bottom: "out_deconv_final_up2"
  top: "out_deconv_final_up4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 20
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up8"
  type: "Deconvolution"
  bottom: "out_deconv_final_up4"
  top: "out_deconv_final_up8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 20
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: 255
    normalization: VALID
  }
}
I0630 19:26:27.701280  5429 layer_factory.hpp:77] Creating layer data
I0630 19:26:27.701793  5429 net.cpp:98] Creating Layer data
I0630 19:26:27.701830  5429 net.cpp:413] data -> data
I0630 19:26:27.701905  5429 net.cpp:413] data -> label
I0630 19:26:27.756829  5505 db_lmdb.cpp:35] Opened lmdb data/train-image-lmdb
I0630 19:26:27.775555  5510 db_lmdb.cpp:35] Opened lmdb data/train-label-lmdb
I0630 19:26:28.232306  5429 data_layer.cpp:78] ReshapePrefetch 5, 3, 640, 640
I0630 19:26:28.232374  5429 data_layer.cpp:83] output data size: 5,3,640,640
I0630 19:26:28.257689  5429 data_layer.cpp:78] ReshapePrefetch 5, 1, 640, 640
I0630 19:26:28.257755  5429 data_layer.cpp:83] output data size: 5,1,640,640
I0630 19:26:28.264848  5518 blocking_queue.cpp:50] Waiting for data
I0630 19:26:28.270660  5429 net.cpp:148] Setting up data
I0630 19:26:28.270680  5429 net.cpp:155] Top shape: 5 3 640 640 (6144000)
I0630 19:26:28.270684  5429 net.cpp:155] Top shape: 5 1 640 640 (2048000)
I0630 19:26:28.270686  5429 net.cpp:163] Memory required for data: 32768000
I0630 19:26:28.270692  5429 layer_factory.hpp:77] Creating layer data/bias
I0630 19:26:28.270704  5429 net.cpp:98] Creating Layer data/bias
I0630 19:26:28.270707  5429 net.cpp:439] data/bias <- data
I0630 19:26:28.270717  5429 net.cpp:413] data/bias -> data/bias
I0630 19:26:28.271883  5429 net.cpp:148] Setting up data/bias
I0630 19:26:28.271893  5429 net.cpp:155] Top shape: 5 3 640 640 (6144000)
I0630 19:26:28.271894  5429 net.cpp:163] Memory required for data: 57344000
I0630 19:26:28.271905  5429 layer_factory.hpp:77] Creating layer conv1a
I0630 19:26:28.271915  5429 net.cpp:98] Creating Layer conv1a
I0630 19:26:28.271917  5429 net.cpp:439] conv1a <- data/bias
I0630 19:26:28.271920  5429 net.cpp:413] conv1a -> conv1a
I0630 19:26:28.274107  5429 net.cpp:148] Setting up conv1a
I0630 19:26:28.274121  5429 net.cpp:155] Top shape: 5 32 320 320 (16384000)
I0630 19:26:28.274122  5429 net.cpp:163] Memory required for data: 122880000
I0630 19:26:28.274128  5429 layer_factory.hpp:77] Creating layer conv1a/bn
I0630 19:26:28.274137  5429 net.cpp:98] Creating Layer conv1a/bn
I0630 19:26:28.274139  5429 net.cpp:439] conv1a/bn <- conv1a
I0630 19:26:28.274143  5429 net.cpp:413] conv1a/bn -> conv1a/bn
I0630 19:26:28.275977  5429 net.cpp:148] Setting up conv1a/bn
I0630 19:26:28.275987  5429 net.cpp:155] Top shape: 5 32 320 320 (16384000)
I0630 19:26:28.275990  5429 net.cpp:163] Memory required for data: 188416000
I0630 19:26:28.275995  5429 layer_factory.hpp:77] Creating layer conv1a/relu
I0630 19:26:28.276000  5429 net.cpp:98] Creating Layer conv1a/relu
I0630 19:26:28.276002  5429 net.cpp:439] conv1a/relu <- conv1a/bn
I0630 19:26:28.276005  5429 net.cpp:400] conv1a/relu -> conv1a/bn (in-place)
I0630 19:26:28.276012  5429 net.cpp:148] Setting up conv1a/relu
I0630 19:26:28.276015  5429 net.cpp:155] Top shape: 5 32 320 320 (16384000)
I0630 19:26:28.276017  5429 net.cpp:163] Memory required for data: 253952000
I0630 19:26:28.276018  5429 layer_factory.hpp:77] Creating layer conv1b
I0630 19:26:28.276023  5429 net.cpp:98] Creating Layer conv1b
I0630 19:26:28.276026  5429 net.cpp:439] conv1b <- conv1a/bn
I0630 19:26:28.276029  5429 net.cpp:413] conv1b -> conv1b
I0630 19:26:28.276399  5429 net.cpp:148] Setting up conv1b
I0630 19:26:28.276406  5429 net.cpp:155] Top shape: 5 32 320 320 (16384000)
I0630 19:26:28.276407  5429 net.cpp:163] Memory required for data: 319488000
I0630 19:26:28.276412  5429 layer_factory.hpp:77] Creating layer conv1b/bn
I0630 19:26:28.276415  5429 net.cpp:98] Creating Layer conv1b/bn
I0630 19:26:28.276417  5429 net.cpp:439] conv1b/bn <- conv1b
I0630 19:26:28.276422  5429 net.cpp:413] conv1b/bn -> conv1b/bn
I0630 19:26:28.277117  5429 net.cpp:148] Setting up conv1b/bn
I0630 19:26:28.277123  5429 net.cpp:155] Top shape: 5 32 320 320 (16384000)
I0630 19:26:28.277125  5429 net.cpp:163] Memory required for data: 385024000
I0630 19:26:28.277130  5429 layer_factory.hpp:77] Creating layer conv1b/relu
I0630 19:26:28.277133  5429 net.cpp:98] Creating Layer conv1b/relu
I0630 19:26:28.277135  5429 net.cpp:439] conv1b/relu <- conv1b/bn
I0630 19:26:28.277137  5429 net.cpp:400] conv1b/relu -> conv1b/bn (in-place)
I0630 19:26:28.277140  5429 net.cpp:148] Setting up conv1b/relu
I0630 19:26:28.277143  5429 net.cpp:155] Top shape: 5 32 320 320 (16384000)
I0630 19:26:28.277144  5429 net.cpp:163] Memory required for data: 450560000
I0630 19:26:28.277146  5429 layer_factory.hpp:77] Creating layer pool1
I0630 19:26:28.277153  5429 net.cpp:98] Creating Layer pool1
I0630 19:26:28.277155  5429 net.cpp:439] pool1 <- conv1b/bn
I0630 19:26:28.277159  5429 net.cpp:413] pool1 -> pool1
I0630 19:26:28.277590  5429 net.cpp:148] Setting up pool1
I0630 19:26:28.277596  5429 net.cpp:155] Top shape: 5 32 160 160 (4096000)
I0630 19:26:28.277598  5429 net.cpp:163] Memory required for data: 466944000
I0630 19:26:28.277601  5429 layer_factory.hpp:77] Creating layer res2a_branch2a
I0630 19:26:28.277606  5429 net.cpp:98] Creating Layer res2a_branch2a
I0630 19:26:28.277607  5429 net.cpp:439] res2a_branch2a <- pool1
I0630 19:26:28.277611  5429 net.cpp:413] res2a_branch2a -> res2a_branch2a
I0630 19:26:28.279110  5429 net.cpp:148] Setting up res2a_branch2a
I0630 19:26:28.279119  5429 net.cpp:155] Top shape: 5 64 160 160 (8192000)
I0630 19:26:28.279121  5429 net.cpp:163] Memory required for data: 499712000
I0630 19:26:28.279126  5429 layer_factory.hpp:77] Creating layer res2a_branch2a/bn
I0630 19:26:28.279130  5429 net.cpp:98] Creating Layer res2a_branch2a/bn
I0630 19:26:28.279132  5429 net.cpp:439] res2a_branch2a/bn <- res2a_branch2a
I0630 19:26:28.279135  5429 net.cpp:413] res2a_branch2a/bn -> res2a_branch2a/bn
I0630 19:26:28.279806  5429 net.cpp:148] Setting up res2a_branch2a/bn
I0630 19:26:28.279813  5429 net.cpp:155] Top shape: 5 64 160 160 (8192000)
I0630 19:26:28.279814  5429 net.cpp:163] Memory required for data: 532480000
I0630 19:26:28.279819  5429 layer_factory.hpp:77] Creating layer res2a_branch2a/relu
I0630 19:26:28.279822  5429 net.cpp:98] Creating Layer res2a_branch2a/relu
I0630 19:26:28.279824  5429 net.cpp:439] res2a_branch2a/relu <- res2a_branch2a/bn
I0630 19:26:28.279826  5429 net.cpp:400] res2a_branch2a/relu -> res2a_branch2a/bn (in-place)
I0630 19:26:28.279830  5429 net.cpp:148] Setting up res2a_branch2a/relu
I0630 19:26:28.279832  5429 net.cpp:155] Top shape: 5 64 160 160 (8192000)
I0630 19:26:28.279834  5429 net.cpp:163] Memory required for data: 565248000
I0630 19:26:28.279835  5429 layer_factory.hpp:77] Creating layer res2a_branch2b
I0630 19:26:28.279839  5429 net.cpp:98] Creating Layer res2a_branch2b
I0630 19:26:28.279841  5429 net.cpp:439] res2a_branch2b <- res2a_branch2a/bn
I0630 19:26:28.279844  5429 net.cpp:413] res2a_branch2b -> res2a_branch2b
I0630 19:26:28.281138  5429 net.cpp:148] Setting up res2a_branch2b
I0630 19:26:28.281147  5429 net.cpp:155] Top shape: 5 64 160 160 (8192000)
I0630 19:26:28.281148  5429 net.cpp:163] Memory required for data: 598016000
I0630 19:26:28.281152  5429 layer_factory.hpp:77] Creating layer res2a_branch2b/bn
I0630 19:26:28.281157  5429 net.cpp:98] Creating Layer res2a_branch2b/bn
I0630 19:26:28.281158  5429 net.cpp:439] res2a_branch2b/bn <- res2a_branch2b
I0630 19:26:28.281162  5429 net.cpp:413] res2a_branch2b/bn -> res2a_branch2b/bn
I0630 19:26:28.281860  5429 net.cpp:148] Setting up res2a_branch2b/bn
I0630 19:26:28.281867  5429 net.cpp:155] Top shape: 5 64 160 160 (8192000)
I0630 19:26:28.281868  5429 net.cpp:163] Memory required for data: 630784000
I0630 19:26:28.281873  5429 layer_factory.hpp:77] Creating layer res2a_branch2b/relu
I0630 19:26:28.281877  5429 net.cpp:98] Creating Layer res2a_branch2b/relu
I0630 19:26:28.281878  5429 net.cpp:439] res2a_branch2b/relu <- res2a_branch2b/bn
I0630 19:26:28.281880  5429 net.cpp:400] res2a_branch2b/relu -> res2a_branch2b/bn (in-place)
I0630 19:26:28.281884  5429 net.cpp:148] Setting up res2a_branch2b/relu
I0630 19:26:28.281886  5429 net.cpp:155] Top shape: 5 64 160 160 (8192000)
I0630 19:26:28.281888  5429 net.cpp:163] Memory required for data: 663552000
I0630 19:26:28.281890  5429 layer_factory.hpp:77] Creating layer pool2
I0630 19:26:28.281893  5429 net.cpp:98] Creating Layer pool2
I0630 19:26:28.281895  5429 net.cpp:439] pool2 <- res2a_branch2b/bn
I0630 19:26:28.281898  5429 net.cpp:413] pool2 -> pool2
I0630 19:26:28.281932  5429 net.cpp:148] Setting up pool2
I0630 19:26:28.281936  5429 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0630 19:26:28.281939  5429 net.cpp:163] Memory required for data: 671744000
I0630 19:26:28.281940  5429 layer_factory.hpp:77] Creating layer res3a_branch2a
I0630 19:26:28.281944  5429 net.cpp:98] Creating Layer res3a_branch2a
I0630 19:26:28.281946  5429 net.cpp:439] res3a_branch2a <- pool2
I0630 19:26:28.281949  5429 net.cpp:413] res3a_branch2a -> res3a_branch2a
I0630 19:26:28.283677  5429 net.cpp:148] Setting up res3a_branch2a
I0630 19:26:28.283684  5429 net.cpp:155] Top shape: 5 128 80 80 (4096000)
I0630 19:26:28.283686  5429 net.cpp:163] Memory required for data: 688128000
I0630 19:26:28.283689  5429 layer_factory.hpp:77] Creating layer res3a_branch2a/bn
I0630 19:26:28.283694  5429 net.cpp:98] Creating Layer res3a_branch2a/bn
I0630 19:26:28.283695  5429 net.cpp:439] res3a_branch2a/bn <- res3a_branch2a
I0630 19:26:28.283699  5429 net.cpp:413] res3a_branch2a/bn -> res3a_branch2a/bn
I0630 19:26:28.284312  5429 net.cpp:148] Setting up res3a_branch2a/bn
I0630 19:26:28.284317  5429 net.cpp:155] Top shape: 5 128 80 80 (4096000)
I0630 19:26:28.284319  5429 net.cpp:163] Memory required for data: 704512000
I0630 19:26:28.284325  5429 layer_factory.hpp:77] Creating layer res3a_branch2a/relu
I0630 19:26:28.284328  5429 net.cpp:98] Creating Layer res3a_branch2a/relu
I0630 19:26:28.284330  5429 net.cpp:439] res3a_branch2a/relu <- res3a_branch2a/bn
I0630 19:26:28.284332  5429 net.cpp:400] res3a_branch2a/relu -> res3a_branch2a/bn (in-place)
I0630 19:26:28.284335  5429 net.cpp:148] Setting up res3a_branch2a/relu
I0630 19:26:28.284337  5429 net.cpp:155] Top shape: 5 128 80 80 (4096000)
I0630 19:26:28.284339  5429 net.cpp:163] Memory required for data: 720896000
I0630 19:26:28.284342  5429 layer_factory.hpp:77] Creating layer res3a_branch2b
I0630 19:26:28.284345  5429 net.cpp:98] Creating Layer res3a_branch2b
I0630 19:26:28.284348  5429 net.cpp:439] res3a_branch2b <- res3a_branch2a/bn
I0630 19:26:28.284350  5429 net.cpp:413] res3a_branch2b -> res3a_branch2b
I0630 19:26:28.285348  5429 net.cpp:148] Setting up res3a_branch2b
I0630 19:26:28.285354  5429 net.cpp:155] Top shape: 5 128 80 80 (4096000)
I0630 19:26:28.285356  5429 net.cpp:163] Memory required for data: 737280000
I0630 19:26:28.285359  5429 layer_factory.hpp:77] Creating layer res3a_branch2b/bn
I0630 19:26:28.285363  5429 net.cpp:98] Creating Layer res3a_branch2b/bn
I0630 19:26:28.285365  5429 net.cpp:439] res3a_branch2b/bn <- res3a_branch2b
I0630 19:26:28.285367  5429 net.cpp:413] res3a_branch2b/bn -> res3a_branch2b/bn
I0630 19:26:28.285984  5429 net.cpp:148] Setting up res3a_branch2b/bn
I0630 19:26:28.285990  5429 net.cpp:155] Top shape: 5 128 80 80 (4096000)
I0630 19:26:28.285992  5429 net.cpp:163] Memory required for data: 753664000
I0630 19:26:28.285996  5429 layer_factory.hpp:77] Creating layer res3a_branch2b/relu
I0630 19:26:28.286000  5429 net.cpp:98] Creating Layer res3a_branch2b/relu
I0630 19:26:28.286001  5429 net.cpp:439] res3a_branch2b/relu <- res3a_branch2b/bn
I0630 19:26:28.286010  5429 net.cpp:400] res3a_branch2b/relu -> res3a_branch2b/bn (in-place)
I0630 19:26:28.286013  5429 net.cpp:148] Setting up res3a_branch2b/relu
I0630 19:26:28.286015  5429 net.cpp:155] Top shape: 5 128 80 80 (4096000)
I0630 19:26:28.286017  5429 net.cpp:163] Memory required for data: 770048000
I0630 19:26:28.286020  5429 layer_factory.hpp:77] Creating layer res3a_branch2b/bn_res3a_branch2b/relu_0_split
I0630 19:26:28.286022  5429 net.cpp:98] Creating Layer res3a_branch2b/bn_res3a_branch2b/relu_0_split
I0630 19:26:28.286023  5429 net.cpp:439] res3a_branch2b/bn_res3a_branch2b/relu_0_split <- res3a_branch2b/bn
I0630 19:26:28.286026  5429 net.cpp:413] res3a_branch2b/bn_res3a_branch2b/relu_0_split -> res3a_branch2b/bn_res3a_branch2b/relu_0_split_0
I0630 19:26:28.286031  5429 net.cpp:413] res3a_branch2b/bn_res3a_branch2b/relu_0_split -> res3a_branch2b/bn_res3a_branch2b/relu_0_split_1
I0630 19:26:28.286064  5429 net.cpp:148] Setting up res3a_branch2b/bn_res3a_branch2b/relu_0_split
I0630 19:26:28.286069  5429 net.cpp:155] Top shape: 5 128 80 80 (4096000)
I0630 19:26:28.286072  5429 net.cpp:155] Top shape: 5 128 80 80 (4096000)
I0630 19:26:28.286073  5429 net.cpp:163] Memory required for data: 802816000
I0630 19:26:28.286074  5429 layer_factory.hpp:77] Creating layer pool3
I0630 19:26:28.286077  5429 net.cpp:98] Creating Layer pool3
I0630 19:26:28.286079  5429 net.cpp:439] pool3 <- res3a_branch2b/bn_res3a_branch2b/relu_0_split_0
I0630 19:26:28.286082  5429 net.cpp:413] pool3 -> pool3
I0630 19:26:28.286118  5429 net.cpp:148] Setting up pool3
I0630 19:26:28.286121  5429 net.cpp:155] Top shape: 5 128 40 40 (1024000)
I0630 19:26:28.286123  5429 net.cpp:163] Memory required for data: 806912000
I0630 19:26:28.286125  5429 layer_factory.hpp:77] Creating layer res4a_branch2a
I0630 19:26:28.286129  5429 net.cpp:98] Creating Layer res4a_branch2a
I0630 19:26:28.286131  5429 net.cpp:439] res4a_branch2a <- pool3
I0630 19:26:28.286134  5429 net.cpp:413] res4a_branch2a -> res4a_branch2a
I0630 19:26:28.293206  5429 net.cpp:148] Setting up res4a_branch2a
I0630 19:26:28.293226  5429 net.cpp:155] Top shape: 5 256 40 40 (2048000)
I0630 19:26:28.293228  5429 net.cpp:163] Memory required for data: 815104000
I0630 19:26:28.293234  5429 layer_factory.hpp:77] Creating layer res4a_branch2a/bn
I0630 19:26:28.293243  5429 net.cpp:98] Creating Layer res4a_branch2a/bn
I0630 19:26:28.293246  5429 net.cpp:439] res4a_branch2a/bn <- res4a_branch2a
I0630 19:26:28.293251  5429 net.cpp:413] res4a_branch2a/bn -> res4a_branch2a/bn
I0630 19:26:28.293905  5429 net.cpp:148] Setting up res4a_branch2a/bn
I0630 19:26:28.293910  5429 net.cpp:155] Top shape: 5 256 40 40 (2048000)
I0630 19:26:28.293913  5429 net.cpp:163] Memory required for data: 823296000
I0630 19:26:28.293918  5429 layer_factory.hpp:77] Creating layer res4a_branch2a/relu
I0630 19:26:28.293921  5429 net.cpp:98] Creating Layer res4a_branch2a/relu
I0630 19:26:28.293923  5429 net.cpp:439] res4a_branch2a/relu <- res4a_branch2a/bn
I0630 19:26:28.293926  5429 net.cpp:400] res4a_branch2a/relu -> res4a_branch2a/bn (in-place)
I0630 19:26:28.293929  5429 net.cpp:148] Setting up res4a_branch2a/relu
I0630 19:26:28.293932  5429 net.cpp:155] Top shape: 5 256 40 40 (2048000)
I0630 19:26:28.293933  5429 net.cpp:163] Memory required for data: 831488000
I0630 19:26:28.293936  5429 layer_factory.hpp:77] Creating layer res4a_branch2b
I0630 19:26:28.293941  5429 net.cpp:98] Creating Layer res4a_branch2b
I0630 19:26:28.293942  5429 net.cpp:439] res4a_branch2b <- res4a_branch2a/bn
I0630 19:26:28.293946  5429 net.cpp:413] res4a_branch2b -> res4a_branch2b
I0630 19:26:28.297144  5429 net.cpp:148] Setting up res4a_branch2b
I0630 19:26:28.297150  5429 net.cpp:155] Top shape: 5 256 40 40 (2048000)
I0630 19:26:28.297152  5429 net.cpp:163] Memory required for data: 839680000
I0630 19:26:28.297155  5429 layer_factory.hpp:77] Creating layer res4a_branch2b/bn
I0630 19:26:28.297159  5429 net.cpp:98] Creating Layer res4a_branch2b/bn
I0630 19:26:28.297161  5429 net.cpp:439] res4a_branch2b/bn <- res4a_branch2b
I0630 19:26:28.297175  5429 net.cpp:413] res4a_branch2b/bn -> res4a_branch2b/bn
I0630 19:26:28.297802  5429 net.cpp:148] Setting up res4a_branch2b/bn
I0630 19:26:28.297808  5429 net.cpp:155] Top shape: 5 256 40 40 (2048000)
I0630 19:26:28.297811  5429 net.cpp:163] Memory required for data: 847872000
I0630 19:26:28.297814  5429 layer_factory.hpp:77] Creating layer res4a_branch2b/relu
I0630 19:26:28.297817  5429 net.cpp:98] Creating Layer res4a_branch2b/relu
I0630 19:26:28.297819  5429 net.cpp:439] res4a_branch2b/relu <- res4a_branch2b/bn
I0630 19:26:28.297821  5429 net.cpp:400] res4a_branch2b/relu -> res4a_branch2b/bn (in-place)
I0630 19:26:28.297825  5429 net.cpp:148] Setting up res4a_branch2b/relu
I0630 19:26:28.297827  5429 net.cpp:155] Top shape: 5 256 40 40 (2048000)
I0630 19:26:28.297828  5429 net.cpp:163] Memory required for data: 856064000
I0630 19:26:28.297830  5429 layer_factory.hpp:77] Creating layer pool4
I0630 19:26:28.297834  5429 net.cpp:98] Creating Layer pool4
I0630 19:26:28.297837  5429 net.cpp:439] pool4 <- res4a_branch2b/bn
I0630 19:26:28.297839  5429 net.cpp:413] pool4 -> pool4
I0630 19:26:28.297875  5429 net.cpp:148] Setting up pool4
I0630 19:26:28.297879  5429 net.cpp:155] Top shape: 5 256 40 40 (2048000)
I0630 19:26:28.297881  5429 net.cpp:163] Memory required for data: 864256000
I0630 19:26:28.297883  5429 layer_factory.hpp:77] Creating layer res5a_branch2a
I0630 19:26:28.297888  5429 net.cpp:98] Creating Layer res5a_branch2a
I0630 19:26:28.297889  5429 net.cpp:439] res5a_branch2a <- pool4
I0630 19:26:28.297893  5429 net.cpp:413] res5a_branch2a -> res5a_branch2a
I0630 19:26:28.323674  5429 net.cpp:148] Setting up res5a_branch2a
I0630 19:26:28.323693  5429 net.cpp:155] Top shape: 5 512 40 40 (4096000)
I0630 19:26:28.323695  5429 net.cpp:163] Memory required for data: 880640000
I0630 19:26:28.323701  5429 layer_factory.hpp:77] Creating layer res5a_branch2a/bn
I0630 19:26:28.323712  5429 net.cpp:98] Creating Layer res5a_branch2a/bn
I0630 19:26:28.323715  5429 net.cpp:439] res5a_branch2a/bn <- res5a_branch2a
I0630 19:26:28.323719  5429 net.cpp:413] res5a_branch2a/bn -> res5a_branch2a/bn
I0630 19:26:28.324373  5429 net.cpp:148] Setting up res5a_branch2a/bn
I0630 19:26:28.324379  5429 net.cpp:155] Top shape: 5 512 40 40 (4096000)
I0630 19:26:28.324381  5429 net.cpp:163] Memory required for data: 897024000
I0630 19:26:28.324386  5429 layer_factory.hpp:77] Creating layer res5a_branch2a/relu
I0630 19:26:28.324390  5429 net.cpp:98] Creating Layer res5a_branch2a/relu
I0630 19:26:28.324393  5429 net.cpp:439] res5a_branch2a/relu <- res5a_branch2a/bn
I0630 19:26:28.324394  5429 net.cpp:400] res5a_branch2a/relu -> res5a_branch2a/bn (in-place)
I0630 19:26:28.324398  5429 net.cpp:148] Setting up res5a_branch2a/relu
I0630 19:26:28.324401  5429 net.cpp:155] Top shape: 5 512 40 40 (4096000)
I0630 19:26:28.324403  5429 net.cpp:163] Memory required for data: 913408000
I0630 19:26:28.324404  5429 layer_factory.hpp:77] Creating layer res5a_branch2b
I0630 19:26:28.324409  5429 net.cpp:98] Creating Layer res5a_branch2b
I0630 19:26:28.324411  5429 net.cpp:439] res5a_branch2b <- res5a_branch2a/bn
I0630 19:26:28.324414  5429 net.cpp:413] res5a_branch2b -> res5a_branch2b
I0630 19:26:28.337128  5429 net.cpp:148] Setting up res5a_branch2b
I0630 19:26:28.337139  5429 net.cpp:155] Top shape: 5 512 40 40 (4096000)
I0630 19:26:28.337141  5429 net.cpp:163] Memory required for data: 929792000
I0630 19:26:28.337147  5429 layer_factory.hpp:77] Creating layer res5a_branch2b/bn
I0630 19:26:28.337152  5429 net.cpp:98] Creating Layer res5a_branch2b/bn
I0630 19:26:28.337154  5429 net.cpp:439] res5a_branch2b/bn <- res5a_branch2b
I0630 19:26:28.337157  5429 net.cpp:413] res5a_branch2b/bn -> res5a_branch2b/bn
I0630 19:26:28.337800  5429 net.cpp:148] Setting up res5a_branch2b/bn
I0630 19:26:28.337805  5429 net.cpp:155] Top shape: 5 512 40 40 (4096000)
I0630 19:26:28.337806  5429 net.cpp:163] Memory required for data: 946176000
I0630 19:26:28.337811  5429 layer_factory.hpp:77] Creating layer res5a_branch2b/relu
I0630 19:26:28.337815  5429 net.cpp:98] Creating Layer res5a_branch2b/relu
I0630 19:26:28.337824  5429 net.cpp:439] res5a_branch2b/relu <- res5a_branch2b/bn
I0630 19:26:28.337827  5429 net.cpp:400] res5a_branch2b/relu -> res5a_branch2b/bn (in-place)
I0630 19:26:28.337831  5429 net.cpp:148] Setting up res5a_branch2b/relu
I0630 19:26:28.337833  5429 net.cpp:155] Top shape: 5 512 40 40 (4096000)
I0630 19:26:28.337836  5429 net.cpp:163] Memory required for data: 962560000
I0630 19:26:28.337837  5429 layer_factory.hpp:77] Creating layer out5a
I0630 19:26:28.337841  5429 net.cpp:98] Creating Layer out5a
I0630 19:26:28.337843  5429 net.cpp:439] out5a <- res5a_branch2b/bn
I0630 19:26:28.337848  5429 net.cpp:413] out5a -> out5a
I0630 19:26:28.341904  5429 net.cpp:148] Setting up out5a
I0630 19:26:28.341913  5429 net.cpp:155] Top shape: 5 64 40 40 (512000)
I0630 19:26:28.341915  5429 net.cpp:163] Memory required for data: 964608000
I0630 19:26:28.341919  5429 layer_factory.hpp:77] Creating layer out5a/bn
I0630 19:26:28.341923  5429 net.cpp:98] Creating Layer out5a/bn
I0630 19:26:28.341925  5429 net.cpp:439] out5a/bn <- out5a
I0630 19:26:28.341928  5429 net.cpp:413] out5a/bn -> out5a/bn
I0630 19:26:28.342639  5429 net.cpp:148] Setting up out5a/bn
I0630 19:26:28.342645  5429 net.cpp:155] Top shape: 5 64 40 40 (512000)
I0630 19:26:28.342648  5429 net.cpp:163] Memory required for data: 966656000
I0630 19:26:28.342653  5429 layer_factory.hpp:77] Creating layer out5a/relu
I0630 19:26:28.342655  5429 net.cpp:98] Creating Layer out5a/relu
I0630 19:26:28.342658  5429 net.cpp:439] out5a/relu <- out5a/bn
I0630 19:26:28.342659  5429 net.cpp:400] out5a/relu -> out5a/bn (in-place)
I0630 19:26:28.342663  5429 net.cpp:148] Setting up out5a/relu
I0630 19:26:28.342665  5429 net.cpp:155] Top shape: 5 64 40 40 (512000)
I0630 19:26:28.342666  5429 net.cpp:163] Memory required for data: 968704000
I0630 19:26:28.342669  5429 layer_factory.hpp:77] Creating layer out5a_up2
I0630 19:26:28.342672  5429 net.cpp:98] Creating Layer out5a_up2
I0630 19:26:28.342674  5429 net.cpp:439] out5a_up2 <- out5a/bn
I0630 19:26:28.342676  5429 net.cpp:413] out5a_up2 -> out5a_up2
I0630 19:26:28.342924  5429 net.cpp:148] Setting up out5a_up2
I0630 19:26:28.342929  5429 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0630 19:26:28.342931  5429 net.cpp:163] Memory required for data: 976896000
I0630 19:26:28.342934  5429 layer_factory.hpp:77] Creating layer out3a
I0630 19:26:28.342938  5429 net.cpp:98] Creating Layer out3a
I0630 19:26:28.342941  5429 net.cpp:439] out3a <- res3a_branch2b/bn_res3a_branch2b/relu_0_split_1
I0630 19:26:28.342943  5429 net.cpp:413] out3a -> out3a
I0630 19:26:28.343966  5429 net.cpp:148] Setting up out3a
I0630 19:26:28.343971  5429 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0630 19:26:28.343973  5429 net.cpp:163] Memory required for data: 985088000
I0630 19:26:28.343976  5429 layer_factory.hpp:77] Creating layer out3a/bn
I0630 19:26:28.343981  5429 net.cpp:98] Creating Layer out3a/bn
I0630 19:26:28.343983  5429 net.cpp:439] out3a/bn <- out3a
I0630 19:26:28.343986  5429 net.cpp:413] out3a/bn -> out3a/bn
I0630 19:26:28.344696  5429 net.cpp:148] Setting up out3a/bn
I0630 19:26:28.344702  5429 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0630 19:26:28.344703  5429 net.cpp:163] Memory required for data: 993280000
I0630 19:26:28.344707  5429 layer_factory.hpp:77] Creating layer out3a/relu
I0630 19:26:28.344710  5429 net.cpp:98] Creating Layer out3a/relu
I0630 19:26:28.344712  5429 net.cpp:439] out3a/relu <- out3a/bn
I0630 19:26:28.344714  5429 net.cpp:400] out3a/relu -> out3a/bn (in-place)
I0630 19:26:28.344718  5429 net.cpp:148] Setting up out3a/relu
I0630 19:26:28.344720  5429 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0630 19:26:28.344722  5429 net.cpp:163] Memory required for data: 1001472000
I0630 19:26:28.344723  5429 layer_factory.hpp:77] Creating layer out3_out5_combined
I0630 19:26:28.344729  5429 net.cpp:98] Creating Layer out3_out5_combined
I0630 19:26:28.344732  5429 net.cpp:439] out3_out5_combined <- out5a_up2
I0630 19:26:28.344733  5429 net.cpp:439] out3_out5_combined <- out3a/bn
I0630 19:26:28.344743  5429 net.cpp:413] out3_out5_combined -> out3_out5_combined
I0630 19:26:28.344765  5429 net.cpp:148] Setting up out3_out5_combined
I0630 19:26:28.344769  5429 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0630 19:26:28.344770  5429 net.cpp:163] Memory required for data: 1009664000
I0630 19:26:28.344772  5429 layer_factory.hpp:77] Creating layer ctx_conv1
I0630 19:26:28.344776  5429 net.cpp:98] Creating Layer ctx_conv1
I0630 19:26:28.344779  5429 net.cpp:439] ctx_conv1 <- out3_out5_combined
I0630 19:26:28.344780  5429 net.cpp:413] ctx_conv1 -> ctx_conv1
I0630 19:26:28.345795  5429 net.cpp:148] Setting up ctx_conv1
I0630 19:26:28.345800  5429 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0630 19:26:28.345803  5429 net.cpp:163] Memory required for data: 1017856000
I0630 19:26:28.345805  5429 layer_factory.hpp:77] Creating layer ctx_conv1/bn
I0630 19:26:28.345808  5429 net.cpp:98] Creating Layer ctx_conv1/bn
I0630 19:26:28.345810  5429 net.cpp:439] ctx_conv1/bn <- ctx_conv1
I0630 19:26:28.345813  5429 net.cpp:413] ctx_conv1/bn -> ctx_conv1/bn
I0630 19:26:28.346529  5429 net.cpp:148] Setting up ctx_conv1/bn
I0630 19:26:28.346535  5429 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0630 19:26:28.346537  5429 net.cpp:163] Memory required for data: 1026048000
I0630 19:26:28.346541  5429 layer_factory.hpp:77] Creating layer ctx_conv1/relu
I0630 19:26:28.346544  5429 net.cpp:98] Creating Layer ctx_conv1/relu
I0630 19:26:28.346546  5429 net.cpp:439] ctx_conv1/relu <- ctx_conv1/bn
I0630 19:26:28.346549  5429 net.cpp:400] ctx_conv1/relu -> ctx_conv1/bn (in-place)
I0630 19:26:28.346551  5429 net.cpp:148] Setting up ctx_conv1/relu
I0630 19:26:28.346554  5429 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0630 19:26:28.346555  5429 net.cpp:163] Memory required for data: 1034240000
I0630 19:26:28.346557  5429 layer_factory.hpp:77] Creating layer ctx_conv2
I0630 19:26:28.346561  5429 net.cpp:98] Creating Layer ctx_conv2
I0630 19:26:28.346563  5429 net.cpp:439] ctx_conv2 <- ctx_conv1/bn
I0630 19:26:28.346566  5429 net.cpp:413] ctx_conv2 -> ctx_conv2
I0630 19:26:28.347579  5429 net.cpp:148] Setting up ctx_conv2
I0630 19:26:28.347584  5429 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0630 19:26:28.347585  5429 net.cpp:163] Memory required for data: 1042432000
I0630 19:26:28.347589  5429 layer_factory.hpp:77] Creating layer ctx_conv2/bn
I0630 19:26:28.347591  5429 net.cpp:98] Creating Layer ctx_conv2/bn
I0630 19:26:28.347594  5429 net.cpp:439] ctx_conv2/bn <- ctx_conv2
I0630 19:26:28.347595  5429 net.cpp:413] ctx_conv2/bn -> ctx_conv2/bn
I0630 19:26:28.348312  5429 net.cpp:148] Setting up ctx_conv2/bn
I0630 19:26:28.348317  5429 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0630 19:26:28.348320  5429 net.cpp:163] Memory required for data: 1050624000
I0630 19:26:28.348325  5429 layer_factory.hpp:77] Creating layer ctx_conv2/relu
I0630 19:26:28.348327  5429 net.cpp:98] Creating Layer ctx_conv2/relu
I0630 19:26:28.348330  5429 net.cpp:439] ctx_conv2/relu <- ctx_conv2/bn
I0630 19:26:28.348331  5429 net.cpp:400] ctx_conv2/relu -> ctx_conv2/bn (in-place)
I0630 19:26:28.348335  5429 net.cpp:148] Setting up ctx_conv2/relu
I0630 19:26:28.348337  5429 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0630 19:26:28.348338  5429 net.cpp:163] Memory required for data: 1058816000
I0630 19:26:28.348340  5429 layer_factory.hpp:77] Creating layer ctx_conv3
I0630 19:26:28.348345  5429 net.cpp:98] Creating Layer ctx_conv3
I0630 19:26:28.348346  5429 net.cpp:439] ctx_conv3 <- ctx_conv2/bn
I0630 19:26:28.348348  5429 net.cpp:413] ctx_conv3 -> ctx_conv3
I0630 19:26:28.349366  5429 net.cpp:148] Setting up ctx_conv3
I0630 19:26:28.349371  5429 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0630 19:26:28.349373  5429 net.cpp:163] Memory required for data: 1067008000
I0630 19:26:28.349376  5429 layer_factory.hpp:77] Creating layer ctx_conv3/bn
I0630 19:26:28.349380  5429 net.cpp:98] Creating Layer ctx_conv3/bn
I0630 19:26:28.349381  5429 net.cpp:439] ctx_conv3/bn <- ctx_conv3
I0630 19:26:28.349383  5429 net.cpp:413] ctx_conv3/bn -> ctx_conv3/bn
I0630 19:26:28.350175  5429 net.cpp:148] Setting up ctx_conv3/bn
I0630 19:26:28.350186  5429 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0630 19:26:28.350190  5429 net.cpp:163] Memory required for data: 1075200000
I0630 19:26:28.350198  5429 layer_factory.hpp:77] Creating layer ctx_conv3/relu
I0630 19:26:28.350206  5429 net.cpp:98] Creating Layer ctx_conv3/relu
I0630 19:26:28.350211  5429 net.cpp:439] ctx_conv3/relu <- ctx_conv3/bn
I0630 19:26:28.350219  5429 net.cpp:400] ctx_conv3/relu -> ctx_conv3/bn (in-place)
I0630 19:26:28.350226  5429 net.cpp:148] Setting up ctx_conv3/relu
I0630 19:26:28.350232  5429 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0630 19:26:28.350235  5429 net.cpp:163] Memory required for data: 1083392000
I0630 19:26:28.350240  5429 layer_factory.hpp:77] Creating layer ctx_conv4
I0630 19:26:28.350247  5429 net.cpp:98] Creating Layer ctx_conv4
I0630 19:26:28.350250  5429 net.cpp:439] ctx_conv4 <- ctx_conv3/bn
I0630 19:26:28.350253  5429 net.cpp:413] ctx_conv4 -> ctx_conv4
I0630 19:26:28.351349  5429 net.cpp:148] Setting up ctx_conv4
I0630 19:26:28.351359  5429 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0630 19:26:28.351361  5429 net.cpp:163] Memory required for data: 1091584000
I0630 19:26:28.351364  5429 layer_factory.hpp:77] Creating layer ctx_conv4/bn
I0630 19:26:28.351369  5429 net.cpp:98] Creating Layer ctx_conv4/bn
I0630 19:26:28.351372  5429 net.cpp:439] ctx_conv4/bn <- ctx_conv4
I0630 19:26:28.351375  5429 net.cpp:413] ctx_conv4/bn -> ctx_conv4/bn
I0630 19:26:28.352110  5429 net.cpp:148] Setting up ctx_conv4/bn
I0630 19:26:28.352116  5429 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0630 19:26:28.352118  5429 net.cpp:163] Memory required for data: 1099776000
I0630 19:26:28.352123  5429 layer_factory.hpp:77] Creating layer ctx_conv4/relu
I0630 19:26:28.352128  5429 net.cpp:98] Creating Layer ctx_conv4/relu
I0630 19:26:28.352130  5429 net.cpp:439] ctx_conv4/relu <- ctx_conv4/bn
I0630 19:26:28.352133  5429 net.cpp:400] ctx_conv4/relu -> ctx_conv4/bn (in-place)
I0630 19:26:28.352136  5429 net.cpp:148] Setting up ctx_conv4/relu
I0630 19:26:28.352139  5429 net.cpp:155] Top shape: 5 64 80 80 (2048000)
I0630 19:26:28.352141  5429 net.cpp:163] Memory required for data: 1107968000
I0630 19:26:28.352144  5429 layer_factory.hpp:77] Creating layer ctx_final
I0630 19:26:28.352149  5429 net.cpp:98] Creating Layer ctx_final
I0630 19:26:28.352150  5429 net.cpp:439] ctx_final <- ctx_conv4/bn
I0630 19:26:28.352154  5429 net.cpp:413] ctx_final -> ctx_final
I0630 19:26:28.352687  5429 net.cpp:148] Setting up ctx_final
I0630 19:26:28.352692  5429 net.cpp:155] Top shape: 5 20 80 80 (640000)
I0630 19:26:28.352695  5429 net.cpp:163] Memory required for data: 1110528000
I0630 19:26:28.352699  5429 layer_factory.hpp:77] Creating layer ctx_final/relu
I0630 19:26:28.352701  5429 net.cpp:98] Creating Layer ctx_final/relu
I0630 19:26:28.352705  5429 net.cpp:439] ctx_final/relu <- ctx_final
I0630 19:26:28.352707  5429 net.cpp:400] ctx_final/relu -> ctx_final (in-place)
I0630 19:26:28.352711  5429 net.cpp:148] Setting up ctx_final/relu
I0630 19:26:28.352713  5429 net.cpp:155] Top shape: 5 20 80 80 (640000)
I0630 19:26:28.352716  5429 net.cpp:163] Memory required for data: 1113088000
I0630 19:26:28.352718  5429 layer_factory.hpp:77] Creating layer out_deconv_final_up2
I0630 19:26:28.352721  5429 net.cpp:98] Creating Layer out_deconv_final_up2
I0630 19:26:28.352725  5429 net.cpp:439] out_deconv_final_up2 <- ctx_final
I0630 19:26:28.352728  5429 net.cpp:413] out_deconv_final_up2 -> out_deconv_final_up2
I0630 19:26:28.352967  5429 net.cpp:148] Setting up out_deconv_final_up2
I0630 19:26:28.352972  5429 net.cpp:155] Top shape: 5 20 160 160 (2560000)
I0630 19:26:28.352973  5429 net.cpp:163] Memory required for data: 1123328000
I0630 19:26:28.352977  5429 layer_factory.hpp:77] Creating layer out_deconv_final_up4
I0630 19:26:28.352979  5429 net.cpp:98] Creating Layer out_deconv_final_up4
I0630 19:26:28.352982  5429 net.cpp:439] out_deconv_final_up4 <- out_deconv_final_up2
I0630 19:26:28.352985  5429 net.cpp:413] out_deconv_final_up4 -> out_deconv_final_up4
I0630 19:26:28.353235  5429 net.cpp:148] Setting up out_deconv_final_up4
I0630 19:26:28.353240  5429 net.cpp:155] Top shape: 5 20 320 320 (10240000)
I0630 19:26:28.353243  5429 net.cpp:163] Memory required for data: 1164288000
I0630 19:26:28.353245  5429 layer_factory.hpp:77] Creating layer out_deconv_final_up8
I0630 19:26:28.353250  5429 net.cpp:98] Creating Layer out_deconv_final_up8
I0630 19:26:28.353251  5429 net.cpp:439] out_deconv_final_up8 <- out_deconv_final_up4
I0630 19:26:28.353255  5429 net.cpp:413] out_deconv_final_up8 -> out_deconv_final_up8
I0630 19:26:28.353488  5429 net.cpp:148] Setting up out_deconv_final_up8
I0630 19:26:28.353493  5429 net.cpp:155] Top shape: 5 20 640 640 (40960000)
I0630 19:26:28.353495  5429 net.cpp:163] Memory required for data: 1328128000
I0630 19:26:28.353498  5429 layer_factory.hpp:77] Creating layer loss
I0630 19:26:28.353798  5429 net.cpp:98] Creating Layer loss
I0630 19:26:28.353803  5429 net.cpp:439] loss <- out_deconv_final_up8
I0630 19:26:28.353806  5429 net.cpp:439] loss <- label
I0630 19:26:28.353811  5429 net.cpp:413] loss -> loss
I0630 19:26:28.353819  5429 layer_factory.hpp:77] Creating layer loss
I0630 19:26:28.404989  5429 net.cpp:148] Setting up loss
I0630 19:26:28.405009  5429 net.cpp:155] Top shape: (1)
I0630 19:26:28.405012  5429 net.cpp:158]     with loss weight 1
I0630 19:26:28.405025  5429 net.cpp:163] Memory required for data: 1328128004
I0630 19:26:28.405028  5429 net.cpp:224] loss needs backward computation.
I0630 19:26:28.405031  5429 net.cpp:224] out_deconv_final_up8 needs backward computation.
I0630 19:26:28.405033  5429 net.cpp:224] out_deconv_final_up4 needs backward computation.
I0630 19:26:28.405035  5429 net.cpp:224] out_deconv_final_up2 needs backward computation.
I0630 19:26:28.405037  5429 net.cpp:224] ctx_final/relu needs backward computation.
I0630 19:26:28.405040  5429 net.cpp:224] ctx_final needs backward computation.
I0630 19:26:28.405041  5429 net.cpp:224] ctx_conv4/relu needs backward computation.
I0630 19:26:28.405043  5429 net.cpp:224] ctx_conv4/bn needs backward computation.
I0630 19:26:28.405045  5429 net.cpp:224] ctx_conv4 needs backward computation.
I0630 19:26:28.405047  5429 net.cpp:224] ctx_conv3/relu needs backward computation.
I0630 19:26:28.405050  5429 net.cpp:224] ctx_conv3/bn needs backward computation.
I0630 19:26:28.405051  5429 net.cpp:224] ctx_conv3 needs backward computation.
I0630 19:26:28.405053  5429 net.cpp:224] ctx_conv2/relu needs backward computation.
I0630 19:26:28.405056  5429 net.cpp:224] ctx_conv2/bn needs backward computation.
I0630 19:26:28.405058  5429 net.cpp:224] ctx_conv2 needs backward computation.
I0630 19:26:28.405061  5429 net.cpp:224] ctx_conv1/relu needs backward computation.
I0630 19:26:28.405062  5429 net.cpp:224] ctx_conv1/bn needs backward computation.
I0630 19:26:28.405064  5429 net.cpp:224] ctx_conv1 needs backward computation.
I0630 19:26:28.405067  5429 net.cpp:224] out3_out5_combined needs backward computation.
I0630 19:26:28.405069  5429 net.cpp:224] out3a/relu needs backward computation.
I0630 19:26:28.405071  5429 net.cpp:224] out3a/bn needs backward computation.
I0630 19:26:28.405074  5429 net.cpp:224] out3a needs backward computation.
I0630 19:26:28.405076  5429 net.cpp:224] out5a_up2 needs backward computation.
I0630 19:26:28.405078  5429 net.cpp:224] out5a/relu needs backward computation.
I0630 19:26:28.405081  5429 net.cpp:224] out5a/bn needs backward computation.
I0630 19:26:28.405083  5429 net.cpp:224] out5a needs backward computation.
I0630 19:26:28.405086  5429 net.cpp:224] res5a_branch2b/relu needs backward computation.
I0630 19:26:28.405087  5429 net.cpp:224] res5a_branch2b/bn needs backward computation.
I0630 19:26:28.405091  5429 net.cpp:224] res5a_branch2b needs backward computation.
I0630 19:26:28.405092  5429 net.cpp:224] res5a_branch2a/relu needs backward computation.
I0630 19:26:28.405094  5429 net.cpp:224] res5a_branch2a/bn needs backward computation.
I0630 19:26:28.405097  5429 net.cpp:224] res5a_branch2a needs backward computation.
I0630 19:26:28.405109  5429 net.cpp:224] pool4 needs backward computation.
I0630 19:26:28.405112  5429 net.cpp:224] res4a_branch2b/relu needs backward computation.
I0630 19:26:28.405113  5429 net.cpp:224] res4a_branch2b/bn needs backward computation.
I0630 19:26:28.405115  5429 net.cpp:224] res4a_branch2b needs backward computation.
I0630 19:26:28.405117  5429 net.cpp:224] res4a_branch2a/relu needs backward computation.
I0630 19:26:28.405119  5429 net.cpp:224] res4a_branch2a/bn needs backward computation.
I0630 19:26:28.405122  5429 net.cpp:224] res4a_branch2a needs backward computation.
I0630 19:26:28.405123  5429 net.cpp:224] pool3 needs backward computation.
I0630 19:26:28.405125  5429 net.cpp:224] res3a_branch2b/bn_res3a_branch2b/relu_0_split needs backward computation.
I0630 19:26:28.405128  5429 net.cpp:224] res3a_branch2b/relu needs backward computation.
I0630 19:26:28.405129  5429 net.cpp:224] res3a_branch2b/bn needs backward computation.
I0630 19:26:28.405131  5429 net.cpp:224] res3a_branch2b needs backward computation.
I0630 19:26:28.405133  5429 net.cpp:224] res3a_branch2a/relu needs backward computation.
I0630 19:26:28.405135  5429 net.cpp:224] res3a_branch2a/bn needs backward computation.
I0630 19:26:28.405138  5429 net.cpp:224] res3a_branch2a needs backward computation.
I0630 19:26:28.405139  5429 net.cpp:224] pool2 needs backward computation.
I0630 19:26:28.405141  5429 net.cpp:224] res2a_branch2b/relu needs backward computation.
I0630 19:26:28.405143  5429 net.cpp:224] res2a_branch2b/bn needs backward computation.
I0630 19:26:28.405145  5429 net.cpp:224] res2a_branch2b needs backward computation.
I0630 19:26:28.405148  5429 net.cpp:224] res2a_branch2a/relu needs backward computation.
I0630 19:26:28.405149  5429 net.cpp:224] res2a_branch2a/bn needs backward computation.
I0630 19:26:28.405151  5429 net.cpp:224] res2a_branch2a needs backward computation.
I0630 19:26:28.405153  5429 net.cpp:224] pool1 needs backward computation.
I0630 19:26:28.405155  5429 net.cpp:224] conv1b/relu needs backward computation.
I0630 19:26:28.405158  5429 net.cpp:224] conv1b/bn needs backward computation.
I0630 19:26:28.405160  5429 net.cpp:224] conv1b needs backward computation.
I0630 19:26:28.405163  5429 net.cpp:224] conv1a/relu needs backward computation.
I0630 19:26:28.405165  5429 net.cpp:224] conv1a/bn needs backward computation.
I0630 19:26:28.405167  5429 net.cpp:224] conv1a needs backward computation.
I0630 19:26:28.405170  5429 net.cpp:226] data/bias does not need backward computation.
I0630 19:26:28.405172  5429 net.cpp:226] data does not need backward computation.
I0630 19:26:28.405174  5429 net.cpp:268] This network produces output loss
I0630 19:26:28.405206  5429 net.cpp:288] Network initialization done.
I0630 19:26:28.405920  5429 solver.cpp:182] Creating test net (#0) specified by test_net file: training/cityscapes20_jsegnet21v2_2017-06-30_19-26-17/initial/test.prototxt
I0630 19:26:28.406195  5429 net.cpp:56] Initializing net from parameters: 
name: "jsegnet21v2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageLabelData"
  top: "data"
  top: "label"
  transform_param {
    mirror: false
    crop_size: 640
    mean_value: 0
  }
  image_label_data_param {
    image_list_path: "data/val-image-lmdb"
    label_list_path: "data/val-label-lmdb"
    batch_size: 4
    threads: 4
    backend: LMDB
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a/bn"
  top: "conv1a/bn"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a/bn"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b/bn"
  top: "conv1b/bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b/bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2a/bn"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b/bn"
  top: "res2a_branch2b/bn"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b/bn"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2a/bn"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b/bn"
  top: "res3a_branch2b/bn"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b/bn"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2a/bn"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b/bn"
  top: "res4a_branch2b/bn"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b/bn"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2a/bn"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b/bn"
  top: "res5a_branch2b/bn"
}
layer {
  name: "out5a"
  type: "Convolution"
  bottom: "res5a_branch2b/bn"
  top: "out5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "out5a/bn"
  type: "BatchNorm"
  bottom: "out5a"
  top: "out5a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "out5a/relu"
  type: "ReLU"
  bottom: "out5a/bn"
  top: "out5a/bn"
}
layer {
  name: "out5a_up2"
  type: "Deconvolution"
  bottom: "out5a/bn"
  top: "out5a_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 64
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out3a"
  type: "Convolution"
  bottom: "res3a_branch2b/bn"
  top: "out3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "out3a/bn"
  type: "BatchNorm"
  bottom: "out3a"
  top: "out3a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "out3a/relu"
  type: "ReLU"
  bottom: "out3a/bn"
  top: "out3a/bn"
}
layer {
  name: "out3_out5_combined"
  type: "Eltwise"
  bottom: "out5a_up2"
  bottom: "out3a/bn"
  top: "out3_out5_combined"
}
layer {
  name: "ctx_conv1"
  type: "Convolution"
  bottom: "out3_out5_combined"
  top: "ctx_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_conv1/bn"
  type: "BatchNorm"
  bottom: "ctx_conv1"
  top: "ctx_conv1/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ctx_conv1/relu"
  type: "ReLU"
  bottom: "ctx_conv1/bn"
  top: "ctx_conv1/bn"
}
layer {
  name: "ctx_conv2"
  type: "Convolution"
  bottom: "ctx_conv1/bn"
  top: "ctx_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv2/bn"
  type: "BatchNorm"
  bottom: "ctx_conv2"
  top: "ctx_conv2/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ctx_conv2/relu"
  type: "ReLU"
  bottom: "ctx_conv2/bn"
  top: "ctx_conv2/bn"
}
layer {
  name: "ctx_conv3"
  type: "Convolution"
  bottom: "ctx_conv2/bn"
  top: "ctx_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv3/bn"
  type: "BatchNorm"
  bottom: "ctx_conv3"
  top: "ctx_conv3/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ctx_conv3/relu"
  type: "ReLU"
  bottom: "ctx_conv3/bn"
  top: "ctx_conv3/bn"
}
layer {
  name: "ctx_conv4"
  type: "Convolution"
  bottom: "ctx_conv3/bn"
  top: "ctx_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv4/bn"
  type: "BatchNorm"
  bottom: "ctx_conv4"
  top: "ctx_conv4/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ctx_conv4/relu"
  type: "ReLU"
  bottom: "ctx_conv4/bn"
  top: "ctx_conv4/bn"
}
layer {
  name: "ctx_final"
  type: "Convolution"
  bottom: "ctx_conv4/bn"
  top: "ctx_final"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    bias_term: true
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_final/relu"
  type: "ReLU"
  bottom: "ctx_final"
  top: "ctx_final"
}
layer {
  name: "out_deconv_final_up2"
  type: "Deconvolution"
  bottom: "ctx_final"
  top: "out_deconv_final_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 20
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up4"
  type: "Deconvolution"
  bottom: "out_deconv_final_up2"
  top: "out_deconv_final_up4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 20
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up8"
  type: "Deconvolution"
  bottom: "out_deconv_final_up4"
  top: "out_deconv_final_up8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 20
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: 255
    normalization: VALID
  }
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "accuracy/top1"
  include {
    phase: TEST
  }
  accuracy_param {
    ignore_label: 255
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "accuracy/top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
    ignore_label: 255
  }
}
I0630 19:26:28.406316  5429 layer_factory.hpp:77] Creating layer data
I0630 19:26:28.406322  5429 net.cpp:98] Creating Layer data
I0630 19:26:28.406325  5429 net.cpp:413] data -> data
I0630 19:26:28.406330  5429 net.cpp:413] data -> label
I0630 19:26:28.421135  5520 db_lmdb.cpp:35] Opened lmdb data/val-image-lmdb
I0630 19:26:28.439621  5525 db_lmdb.cpp:35] Opened lmdb data/val-label-lmdb
I0630 19:26:28.687757  5429 data_layer.cpp:78] ReshapePrefetch 4, 3, 640, 640
I0630 19:26:28.687839  5429 data_layer.cpp:83] output data size: 4,3,640,640
I0630 19:26:28.711022  5429 data_layer.cpp:78] ReshapePrefetch 4, 1, 640, 640
I0630 19:26:28.711097  5429 data_layer.cpp:83] output data size: 4,1,640,640
I0630 19:26:28.721737  5429 net.cpp:148] Setting up data
I0630 19:26:28.721755  5429 net.cpp:155] Top shape: 4 3 640 640 (4915200)
I0630 19:26:28.721758  5429 net.cpp:155] Top shape: 4 1 640 640 (1638400)
I0630 19:26:28.721760  5429 net.cpp:163] Memory required for data: 26214400
I0630 19:26:28.721765  5429 layer_factory.hpp:77] Creating layer label_data_1_split
I0630 19:26:28.721771  5429 net.cpp:98] Creating Layer label_data_1_split
I0630 19:26:28.721774  5429 net.cpp:439] label_data_1_split <- label
I0630 19:26:28.721792  5429 net.cpp:413] label_data_1_split -> label_data_1_split_0
I0630 19:26:28.721797  5429 net.cpp:413] label_data_1_split -> label_data_1_split_1
I0630 19:26:28.721801  5429 net.cpp:413] label_data_1_split -> label_data_1_split_2
I0630 19:26:28.721948  5429 net.cpp:148] Setting up label_data_1_split
I0630 19:26:28.721959  5429 net.cpp:155] Top shape: 4 1 640 640 (1638400)
I0630 19:26:28.721962  5429 net.cpp:155] Top shape: 4 1 640 640 (1638400)
I0630 19:26:28.721964  5429 net.cpp:155] Top shape: 4 1 640 640 (1638400)
I0630 19:26:28.721966  5429 net.cpp:163] Memory required for data: 45875200
I0630 19:26:28.721971  5429 layer_factory.hpp:77] Creating layer data/bias
I0630 19:26:28.721976  5429 net.cpp:98] Creating Layer data/bias
I0630 19:26:28.721978  5429 net.cpp:439] data/bias <- data
I0630 19:26:28.721982  5429 net.cpp:413] data/bias -> data/bias
I0630 19:26:28.723155  5429 net.cpp:148] Setting up data/bias
I0630 19:26:28.723163  5429 net.cpp:155] Top shape: 4 3 640 640 (4915200)
I0630 19:26:28.723165  5429 net.cpp:163] Memory required for data: 65536000
I0630 19:26:28.723171  5429 layer_factory.hpp:77] Creating layer conv1a
I0630 19:26:28.723181  5429 net.cpp:98] Creating Layer conv1a
I0630 19:26:28.723182  5429 net.cpp:439] conv1a <- data/bias
I0630 19:26:28.723186  5429 net.cpp:413] conv1a -> conv1a
I0630 19:26:28.724521  5429 net.cpp:148] Setting up conv1a
I0630 19:26:28.724540  5429 net.cpp:155] Top shape: 4 32 320 320 (13107200)
I0630 19:26:28.724545  5429 net.cpp:163] Memory required for data: 117964800
I0630 19:26:28.724556  5429 layer_factory.hpp:77] Creating layer conv1a/bn
I0630 19:26:28.724572  5429 net.cpp:98] Creating Layer conv1a/bn
I0630 19:26:28.724578  5429 net.cpp:439] conv1a/bn <- conv1a
I0630 19:26:28.724587  5429 net.cpp:413] conv1a/bn -> conv1a/bn
I0630 19:26:28.725872  5429 net.cpp:148] Setting up conv1a/bn
I0630 19:26:28.725881  5429 net.cpp:155] Top shape: 4 32 320 320 (13107200)
I0630 19:26:28.725884  5429 net.cpp:163] Memory required for data: 170393600
I0630 19:26:28.725893  5429 layer_factory.hpp:77] Creating layer conv1a/relu
I0630 19:26:28.725899  5429 net.cpp:98] Creating Layer conv1a/relu
I0630 19:26:28.725903  5429 net.cpp:439] conv1a/relu <- conv1a/bn
I0630 19:26:28.725905  5429 net.cpp:400] conv1a/relu -> conv1a/bn (in-place)
I0630 19:26:28.725911  5429 net.cpp:148] Setting up conv1a/relu
I0630 19:26:28.725914  5429 net.cpp:155] Top shape: 4 32 320 320 (13107200)
I0630 19:26:28.725927  5429 net.cpp:163] Memory required for data: 222822400
I0630 19:26:28.725931  5429 layer_factory.hpp:77] Creating layer conv1b
I0630 19:26:28.725939  5429 net.cpp:98] Creating Layer conv1b
I0630 19:26:28.725942  5429 net.cpp:439] conv1b <- conv1a/bn
I0630 19:26:28.725946  5429 net.cpp:413] conv1b -> conv1b
I0630 19:26:28.726514  5429 net.cpp:148] Setting up conv1b
I0630 19:26:28.726521  5429 net.cpp:155] Top shape: 4 32 320 320 (13107200)
I0630 19:26:28.726523  5429 net.cpp:163] Memory required for data: 275251200
I0630 19:26:28.726527  5429 layer_factory.hpp:77] Creating layer conv1b/bn
I0630 19:26:28.726531  5429 net.cpp:98] Creating Layer conv1b/bn
I0630 19:26:28.726533  5429 net.cpp:439] conv1b/bn <- conv1b
I0630 19:26:28.726537  5429 net.cpp:413] conv1b/bn -> conv1b/bn
I0630 19:26:28.727335  5429 net.cpp:148] Setting up conv1b/bn
I0630 19:26:28.727341  5429 net.cpp:155] Top shape: 4 32 320 320 (13107200)
I0630 19:26:28.727344  5429 net.cpp:163] Memory required for data: 327680000
I0630 19:26:28.727349  5429 layer_factory.hpp:77] Creating layer conv1b/relu
I0630 19:26:28.727351  5429 net.cpp:98] Creating Layer conv1b/relu
I0630 19:26:28.727354  5429 net.cpp:439] conv1b/relu <- conv1b/bn
I0630 19:26:28.727355  5429 net.cpp:400] conv1b/relu -> conv1b/bn (in-place)
I0630 19:26:28.727358  5429 net.cpp:148] Setting up conv1b/relu
I0630 19:26:28.727361  5429 net.cpp:155] Top shape: 4 32 320 320 (13107200)
I0630 19:26:28.727362  5429 net.cpp:163] Memory required for data: 380108800
I0630 19:26:28.727365  5429 layer_factory.hpp:77] Creating layer pool1
I0630 19:26:28.727378  5429 net.cpp:98] Creating Layer pool1
I0630 19:26:28.727381  5429 net.cpp:439] pool1 <- conv1b/bn
I0630 19:26:28.727383  5429 net.cpp:413] pool1 -> pool1
I0630 19:26:28.727422  5429 net.cpp:148] Setting up pool1
I0630 19:26:28.727427  5429 net.cpp:155] Top shape: 4 32 160 160 (3276800)
I0630 19:26:28.727428  5429 net.cpp:163] Memory required for data: 393216000
I0630 19:26:28.727430  5429 layer_factory.hpp:77] Creating layer res2a_branch2a
I0630 19:26:28.727433  5429 net.cpp:98] Creating Layer res2a_branch2a
I0630 19:26:28.727435  5429 net.cpp:439] res2a_branch2a <- pool1
I0630 19:26:28.727438  5429 net.cpp:413] res2a_branch2a -> res2a_branch2a
I0630 19:26:28.728130  5429 net.cpp:148] Setting up res2a_branch2a
I0630 19:26:28.728135  5429 net.cpp:155] Top shape: 4 64 160 160 (6553600)
I0630 19:26:28.728137  5429 net.cpp:163] Memory required for data: 419430400
I0630 19:26:28.728142  5429 layer_factory.hpp:77] Creating layer res2a_branch2a/bn
I0630 19:26:28.728145  5429 net.cpp:98] Creating Layer res2a_branch2a/bn
I0630 19:26:28.728147  5429 net.cpp:439] res2a_branch2a/bn <- res2a_branch2a
I0630 19:26:28.728149  5429 net.cpp:413] res2a_branch2a/bn -> res2a_branch2a/bn
I0630 19:26:28.728896  5429 net.cpp:148] Setting up res2a_branch2a/bn
I0630 19:26:28.728901  5429 net.cpp:155] Top shape: 4 64 160 160 (6553600)
I0630 19:26:28.728904  5429 net.cpp:163] Memory required for data: 445644800
I0630 19:26:28.728909  5429 layer_factory.hpp:77] Creating layer res2a_branch2a/relu
I0630 19:26:28.728911  5429 net.cpp:98] Creating Layer res2a_branch2a/relu
I0630 19:26:28.728914  5429 net.cpp:439] res2a_branch2a/relu <- res2a_branch2a/bn
I0630 19:26:28.728915  5429 net.cpp:400] res2a_branch2a/relu -> res2a_branch2a/bn (in-place)
I0630 19:26:28.728919  5429 net.cpp:148] Setting up res2a_branch2a/relu
I0630 19:26:28.728920  5429 net.cpp:155] Top shape: 4 64 160 160 (6553600)
I0630 19:26:28.728922  5429 net.cpp:163] Memory required for data: 471859200
I0630 19:26:28.728924  5429 layer_factory.hpp:77] Creating layer res2a_branch2b
I0630 19:26:28.728927  5429 net.cpp:98] Creating Layer res2a_branch2b
I0630 19:26:28.728929  5429 net.cpp:439] res2a_branch2b <- res2a_branch2a/bn
I0630 19:26:28.728932  5429 net.cpp:413] res2a_branch2b -> res2a_branch2b
I0630 19:26:28.729435  5429 net.cpp:148] Setting up res2a_branch2b
I0630 19:26:28.729440  5429 net.cpp:155] Top shape: 4 64 160 160 (6553600)
I0630 19:26:28.729442  5429 net.cpp:163] Memory required for data: 498073600
I0630 19:26:28.729445  5429 layer_factory.hpp:77] Creating layer res2a_branch2b/bn
I0630 19:26:28.729449  5429 net.cpp:98] Creating Layer res2a_branch2b/bn
I0630 19:26:28.729451  5429 net.cpp:439] res2a_branch2b/bn <- res2a_branch2b
I0630 19:26:28.729454  5429 net.cpp:413] res2a_branch2b/bn -> res2a_branch2b/bn
I0630 19:26:28.730197  5429 net.cpp:148] Setting up res2a_branch2b/bn
I0630 19:26:28.730202  5429 net.cpp:155] Top shape: 4 64 160 160 (6553600)
I0630 19:26:28.730204  5429 net.cpp:163] Memory required for data: 524288000
I0630 19:26:28.730209  5429 layer_factory.hpp:77] Creating layer res2a_branch2b/relu
I0630 19:26:28.730212  5429 net.cpp:98] Creating Layer res2a_branch2b/relu
I0630 19:26:28.730214  5429 net.cpp:439] res2a_branch2b/relu <- res2a_branch2b/bn
I0630 19:26:28.730216  5429 net.cpp:400] res2a_branch2b/relu -> res2a_branch2b/bn (in-place)
I0630 19:26:28.730219  5429 net.cpp:148] Setting up res2a_branch2b/relu
I0630 19:26:28.730222  5429 net.cpp:155] Top shape: 4 64 160 160 (6553600)
I0630 19:26:28.730223  5429 net.cpp:163] Memory required for data: 550502400
I0630 19:26:28.730226  5429 layer_factory.hpp:77] Creating layer pool2
I0630 19:26:28.730229  5429 net.cpp:98] Creating Layer pool2
I0630 19:26:28.730231  5429 net.cpp:439] pool2 <- res2a_branch2b/bn
I0630 19:26:28.730233  5429 net.cpp:413] pool2 -> pool2
I0630 19:26:28.730273  5429 net.cpp:148] Setting up pool2
I0630 19:26:28.730276  5429 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0630 19:26:28.730278  5429 net.cpp:163] Memory required for data: 557056000
I0630 19:26:28.730280  5429 layer_factory.hpp:77] Creating layer res3a_branch2a
I0630 19:26:28.730290  5429 net.cpp:98] Creating Layer res3a_branch2a
I0630 19:26:28.730293  5429 net.cpp:439] res3a_branch2a <- pool2
I0630 19:26:28.730296  5429 net.cpp:413] res3a_branch2a -> res3a_branch2a
I0630 19:26:28.732085  5429 net.cpp:148] Setting up res3a_branch2a
I0630 19:26:28.732095  5429 net.cpp:155] Top shape: 4 128 80 80 (3276800)
I0630 19:26:28.732096  5429 net.cpp:163] Memory required for data: 570163200
I0630 19:26:28.732100  5429 layer_factory.hpp:77] Creating layer res3a_branch2a/bn
I0630 19:26:28.732103  5429 net.cpp:98] Creating Layer res3a_branch2a/bn
I0630 19:26:28.732107  5429 net.cpp:439] res3a_branch2a/bn <- res3a_branch2a
I0630 19:26:28.732111  5429 net.cpp:413] res3a_branch2a/bn -> res3a_branch2a/bn
I0630 19:26:28.732796  5429 net.cpp:148] Setting up res3a_branch2a/bn
I0630 19:26:28.732801  5429 net.cpp:155] Top shape: 4 128 80 80 (3276800)
I0630 19:26:28.732803  5429 net.cpp:163] Memory required for data: 583270400
I0630 19:26:28.732810  5429 layer_factory.hpp:77] Creating layer res3a_branch2a/relu
I0630 19:26:28.732813  5429 net.cpp:98] Creating Layer res3a_branch2a/relu
I0630 19:26:28.732815  5429 net.cpp:439] res3a_branch2a/relu <- res3a_branch2a/bn
I0630 19:26:28.732818  5429 net.cpp:400] res3a_branch2a/relu -> res3a_branch2a/bn (in-place)
I0630 19:26:28.732822  5429 net.cpp:148] Setting up res3a_branch2a/relu
I0630 19:26:28.732825  5429 net.cpp:155] Top shape: 4 128 80 80 (3276800)
I0630 19:26:28.732826  5429 net.cpp:163] Memory required for data: 596377600
I0630 19:26:28.732828  5429 layer_factory.hpp:77] Creating layer res3a_branch2b
I0630 19:26:28.732832  5429 net.cpp:98] Creating Layer res3a_branch2b
I0630 19:26:28.732836  5429 net.cpp:439] res3a_branch2b <- res3a_branch2a/bn
I0630 19:26:28.732838  5429 net.cpp:413] res3a_branch2b -> res3a_branch2b
I0630 19:26:28.733870  5429 net.cpp:148] Setting up res3a_branch2b
I0630 19:26:28.733875  5429 net.cpp:155] Top shape: 4 128 80 80 (3276800)
I0630 19:26:28.733876  5429 net.cpp:163] Memory required for data: 609484800
I0630 19:26:28.733880  5429 layer_factory.hpp:77] Creating layer res3a_branch2b/bn
I0630 19:26:28.733882  5429 net.cpp:98] Creating Layer res3a_branch2b/bn
I0630 19:26:28.733886  5429 net.cpp:439] res3a_branch2b/bn <- res3a_branch2b
I0630 19:26:28.733888  5429 net.cpp:413] res3a_branch2b/bn -> res3a_branch2b/bn
I0630 19:26:28.734571  5429 net.cpp:148] Setting up res3a_branch2b/bn
I0630 19:26:28.734577  5429 net.cpp:155] Top shape: 4 128 80 80 (3276800)
I0630 19:26:28.734580  5429 net.cpp:163] Memory required for data: 622592000
I0630 19:26:28.734585  5429 layer_factory.hpp:77] Creating layer res3a_branch2b/relu
I0630 19:26:28.734587  5429 net.cpp:98] Creating Layer res3a_branch2b/relu
I0630 19:26:28.734589  5429 net.cpp:439] res3a_branch2b/relu <- res3a_branch2b/bn
I0630 19:26:28.734591  5429 net.cpp:400] res3a_branch2b/relu -> res3a_branch2b/bn (in-place)
I0630 19:26:28.734594  5429 net.cpp:148] Setting up res3a_branch2b/relu
I0630 19:26:28.734596  5429 net.cpp:155] Top shape: 4 128 80 80 (3276800)
I0630 19:26:28.734598  5429 net.cpp:163] Memory required for data: 635699200
I0630 19:26:28.734601  5429 layer_factory.hpp:77] Creating layer res3a_branch2b/bn_res3a_branch2b/relu_0_split
I0630 19:26:28.734603  5429 net.cpp:98] Creating Layer res3a_branch2b/bn_res3a_branch2b/relu_0_split
I0630 19:26:28.734606  5429 net.cpp:439] res3a_branch2b/bn_res3a_branch2b/relu_0_split <- res3a_branch2b/bn
I0630 19:26:28.734607  5429 net.cpp:413] res3a_branch2b/bn_res3a_branch2b/relu_0_split -> res3a_branch2b/bn_res3a_branch2b/relu_0_split_0
I0630 19:26:28.734611  5429 net.cpp:413] res3a_branch2b/bn_res3a_branch2b/relu_0_split -> res3a_branch2b/bn_res3a_branch2b/relu_0_split_1
I0630 19:26:28.734647  5429 net.cpp:148] Setting up res3a_branch2b/bn_res3a_branch2b/relu_0_split
I0630 19:26:28.734652  5429 net.cpp:155] Top shape: 4 128 80 80 (3276800)
I0630 19:26:28.734653  5429 net.cpp:155] Top shape: 4 128 80 80 (3276800)
I0630 19:26:28.734655  5429 net.cpp:163] Memory required for data: 661913600
I0630 19:26:28.734664  5429 layer_factory.hpp:77] Creating layer pool3
I0630 19:26:28.734668  5429 net.cpp:98] Creating Layer pool3
I0630 19:26:28.734669  5429 net.cpp:439] pool3 <- res3a_branch2b/bn_res3a_branch2b/relu_0_split_0
I0630 19:26:28.734673  5429 net.cpp:413] pool3 -> pool3
I0630 19:26:28.734714  5429 net.cpp:148] Setting up pool3
I0630 19:26:28.734719  5429 net.cpp:155] Top shape: 4 128 40 40 (819200)
I0630 19:26:28.734720  5429 net.cpp:163] Memory required for data: 665190400
I0630 19:26:28.734722  5429 layer_factory.hpp:77] Creating layer res4a_branch2a
I0630 19:26:28.734726  5429 net.cpp:98] Creating Layer res4a_branch2a
I0630 19:26:28.734728  5429 net.cpp:439] res4a_branch2a <- pool3
I0630 19:26:28.734731  5429 net.cpp:413] res4a_branch2a -> res4a_branch2a
I0630 19:26:28.741770  5429 net.cpp:148] Setting up res4a_branch2a
I0630 19:26:28.741781  5429 net.cpp:155] Top shape: 4 256 40 40 (1638400)
I0630 19:26:28.741783  5429 net.cpp:163] Memory required for data: 671744000
I0630 19:26:28.741787  5429 layer_factory.hpp:77] Creating layer res4a_branch2a/bn
I0630 19:26:28.741791  5429 net.cpp:98] Creating Layer res4a_branch2a/bn
I0630 19:26:28.741793  5429 net.cpp:439] res4a_branch2a/bn <- res4a_branch2a
I0630 19:26:28.741799  5429 net.cpp:413] res4a_branch2a/bn -> res4a_branch2a/bn
I0630 19:26:28.742507  5429 net.cpp:148] Setting up res4a_branch2a/bn
I0630 19:26:28.742513  5429 net.cpp:155] Top shape: 4 256 40 40 (1638400)
I0630 19:26:28.742516  5429 net.cpp:163] Memory required for data: 678297600
I0630 19:26:28.742521  5429 layer_factory.hpp:77] Creating layer res4a_branch2a/relu
I0630 19:26:28.742523  5429 net.cpp:98] Creating Layer res4a_branch2a/relu
I0630 19:26:28.742525  5429 net.cpp:439] res4a_branch2a/relu <- res4a_branch2a/bn
I0630 19:26:28.742527  5429 net.cpp:400] res4a_branch2a/relu -> res4a_branch2a/bn (in-place)
I0630 19:26:28.742530  5429 net.cpp:148] Setting up res4a_branch2a/relu
I0630 19:26:28.742533  5429 net.cpp:155] Top shape: 4 256 40 40 (1638400)
I0630 19:26:28.742535  5429 net.cpp:163] Memory required for data: 684851200
I0630 19:26:28.742537  5429 layer_factory.hpp:77] Creating layer res4a_branch2b
I0630 19:26:28.742540  5429 net.cpp:98] Creating Layer res4a_branch2b
I0630 19:26:28.742542  5429 net.cpp:439] res4a_branch2b <- res4a_branch2a/bn
I0630 19:26:28.742545  5429 net.cpp:413] res4a_branch2b -> res4a_branch2b
I0630 19:26:28.745743  5429 net.cpp:148] Setting up res4a_branch2b
I0630 19:26:28.745748  5429 net.cpp:155] Top shape: 4 256 40 40 (1638400)
I0630 19:26:28.745749  5429 net.cpp:163] Memory required for data: 691404800
I0630 19:26:28.745753  5429 layer_factory.hpp:77] Creating layer res4a_branch2b/bn
I0630 19:26:28.745756  5429 net.cpp:98] Creating Layer res4a_branch2b/bn
I0630 19:26:28.745759  5429 net.cpp:439] res4a_branch2b/bn <- res4a_branch2b
I0630 19:26:28.745760  5429 net.cpp:413] res4a_branch2b/bn -> res4a_branch2b/bn
I0630 19:26:28.746451  5429 net.cpp:148] Setting up res4a_branch2b/bn
I0630 19:26:28.746457  5429 net.cpp:155] Top shape: 4 256 40 40 (1638400)
I0630 19:26:28.746459  5429 net.cpp:163] Memory required for data: 697958400
I0630 19:26:28.746464  5429 layer_factory.hpp:77] Creating layer res4a_branch2b/relu
I0630 19:26:28.746466  5429 net.cpp:98] Creating Layer res4a_branch2b/relu
I0630 19:26:28.746469  5429 net.cpp:439] res4a_branch2b/relu <- res4a_branch2b/bn
I0630 19:26:28.746470  5429 net.cpp:400] res4a_branch2b/relu -> res4a_branch2b/bn (in-place)
I0630 19:26:28.746474  5429 net.cpp:148] Setting up res4a_branch2b/relu
I0630 19:26:28.746476  5429 net.cpp:155] Top shape: 4 256 40 40 (1638400)
I0630 19:26:28.746479  5429 net.cpp:163] Memory required for data: 704512000
I0630 19:26:28.746479  5429 layer_factory.hpp:77] Creating layer pool4
I0630 19:26:28.746482  5429 net.cpp:98] Creating Layer pool4
I0630 19:26:28.746484  5429 net.cpp:439] pool4 <- res4a_branch2b/bn
I0630 19:26:28.746486  5429 net.cpp:413] pool4 -> pool4
I0630 19:26:28.746525  5429 net.cpp:148] Setting up pool4
I0630 19:26:28.746528  5429 net.cpp:155] Top shape: 4 256 40 40 (1638400)
I0630 19:26:28.746537  5429 net.cpp:163] Memory required for data: 711065600
I0630 19:26:28.746539  5429 layer_factory.hpp:77] Creating layer res5a_branch2a
I0630 19:26:28.746544  5429 net.cpp:98] Creating Layer res5a_branch2a
I0630 19:26:28.746546  5429 net.cpp:439] res5a_branch2a <- pool4
I0630 19:26:28.746549  5429 net.cpp:413] res5a_branch2a -> res5a_branch2a
I0630 19:26:28.771392  5429 net.cpp:148] Setting up res5a_branch2a
I0630 19:26:28.771411  5429 net.cpp:155] Top shape: 4 512 40 40 (3276800)
I0630 19:26:28.771414  5429 net.cpp:163] Memory required for data: 724172800
I0630 19:26:28.771420  5429 layer_factory.hpp:77] Creating layer res5a_branch2a/bn
I0630 19:26:28.771426  5429 net.cpp:98] Creating Layer res5a_branch2a/bn
I0630 19:26:28.771430  5429 net.cpp:439] res5a_branch2a/bn <- res5a_branch2a
I0630 19:26:28.771435  5429 net.cpp:413] res5a_branch2a/bn -> res5a_branch2a/bn
I0630 19:26:28.772148  5429 net.cpp:148] Setting up res5a_branch2a/bn
I0630 19:26:28.772155  5429 net.cpp:155] Top shape: 4 512 40 40 (3276800)
I0630 19:26:28.772156  5429 net.cpp:163] Memory required for data: 737280000
I0630 19:26:28.772162  5429 layer_factory.hpp:77] Creating layer res5a_branch2a/relu
I0630 19:26:28.772166  5429 net.cpp:98] Creating Layer res5a_branch2a/relu
I0630 19:26:28.772167  5429 net.cpp:439] res5a_branch2a/relu <- res5a_branch2a/bn
I0630 19:26:28.772171  5429 net.cpp:400] res5a_branch2a/relu -> res5a_branch2a/bn (in-place)
I0630 19:26:28.772173  5429 net.cpp:148] Setting up res5a_branch2a/relu
I0630 19:26:28.772176  5429 net.cpp:155] Top shape: 4 512 40 40 (3276800)
I0630 19:26:28.772177  5429 net.cpp:163] Memory required for data: 750387200
I0630 19:26:28.772179  5429 layer_factory.hpp:77] Creating layer res5a_branch2b
I0630 19:26:28.772184  5429 net.cpp:98] Creating Layer res5a_branch2b
I0630 19:26:28.772186  5429 net.cpp:439] res5a_branch2b <- res5a_branch2a/bn
I0630 19:26:28.772188  5429 net.cpp:413] res5a_branch2b -> res5a_branch2b
I0630 19:26:28.785019  5429 net.cpp:148] Setting up res5a_branch2b
I0630 19:26:28.785028  5429 net.cpp:155] Top shape: 4 512 40 40 (3276800)
I0630 19:26:28.785030  5429 net.cpp:163] Memory required for data: 763494400
I0630 19:26:28.785037  5429 layer_factory.hpp:77] Creating layer res5a_branch2b/bn
I0630 19:26:28.785042  5429 net.cpp:98] Creating Layer res5a_branch2b/bn
I0630 19:26:28.785043  5429 net.cpp:439] res5a_branch2b/bn <- res5a_branch2b
I0630 19:26:28.785046  5429 net.cpp:413] res5a_branch2b/bn -> res5a_branch2b/bn
I0630 19:26:28.785739  5429 net.cpp:148] Setting up res5a_branch2b/bn
I0630 19:26:28.785744  5429 net.cpp:155] Top shape: 4 512 40 40 (3276800)
I0630 19:26:28.785747  5429 net.cpp:163] Memory required for data: 776601600
I0630 19:26:28.785751  5429 layer_factory.hpp:77] Creating layer res5a_branch2b/relu
I0630 19:26:28.785754  5429 net.cpp:98] Creating Layer res5a_branch2b/relu
I0630 19:26:28.785756  5429 net.cpp:439] res5a_branch2b/relu <- res5a_branch2b/bn
I0630 19:26:28.785759  5429 net.cpp:400] res5a_branch2b/relu -> res5a_branch2b/bn (in-place)
I0630 19:26:28.785763  5429 net.cpp:148] Setting up res5a_branch2b/relu
I0630 19:26:28.785764  5429 net.cpp:155] Top shape: 4 512 40 40 (3276800)
I0630 19:26:28.785766  5429 net.cpp:163] Memory required for data: 789708800
I0630 19:26:28.785768  5429 layer_factory.hpp:77] Creating layer out5a
I0630 19:26:28.785771  5429 net.cpp:98] Creating Layer out5a
I0630 19:26:28.785773  5429 net.cpp:439] out5a <- res5a_branch2b/bn
I0630 19:26:28.785776  5429 net.cpp:413] out5a -> out5a
I0630 19:26:28.789860  5429 net.cpp:148] Setting up out5a
I0630 19:26:28.789870  5429 net.cpp:155] Top shape: 4 64 40 40 (409600)
I0630 19:26:28.789872  5429 net.cpp:163] Memory required for data: 791347200
I0630 19:26:28.789876  5429 layer_factory.hpp:77] Creating layer out5a/bn
I0630 19:26:28.789882  5429 net.cpp:98] Creating Layer out5a/bn
I0630 19:26:28.789885  5429 net.cpp:439] out5a/bn <- out5a
I0630 19:26:28.789887  5429 net.cpp:413] out5a/bn -> out5a/bn
I0630 19:26:28.790657  5429 net.cpp:148] Setting up out5a/bn
I0630 19:26:28.790663  5429 net.cpp:155] Top shape: 4 64 40 40 (409600)
I0630 19:26:28.790673  5429 net.cpp:163] Memory required for data: 792985600
I0630 19:26:28.790679  5429 layer_factory.hpp:77] Creating layer out5a/relu
I0630 19:26:28.790683  5429 net.cpp:98] Creating Layer out5a/relu
I0630 19:26:28.790684  5429 net.cpp:439] out5a/relu <- out5a/bn
I0630 19:26:28.790686  5429 net.cpp:400] out5a/relu -> out5a/bn (in-place)
I0630 19:26:28.790690  5429 net.cpp:148] Setting up out5a/relu
I0630 19:26:28.790693  5429 net.cpp:155] Top shape: 4 64 40 40 (409600)
I0630 19:26:28.790694  5429 net.cpp:163] Memory required for data: 794624000
I0630 19:26:28.790696  5429 layer_factory.hpp:77] Creating layer out5a_up2
I0630 19:26:28.790700  5429 net.cpp:98] Creating Layer out5a_up2
I0630 19:26:28.790701  5429 net.cpp:439] out5a_up2 <- out5a/bn
I0630 19:26:28.790705  5429 net.cpp:413] out5a_up2 -> out5a_up2
I0630 19:26:28.790971  5429 net.cpp:148] Setting up out5a_up2
I0630 19:26:28.790977  5429 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0630 19:26:28.790978  5429 net.cpp:163] Memory required for data: 801177600
I0630 19:26:28.790980  5429 layer_factory.hpp:77] Creating layer out3a
I0630 19:26:28.790984  5429 net.cpp:98] Creating Layer out3a
I0630 19:26:28.790987  5429 net.cpp:439] out3a <- res3a_branch2b/bn_res3a_branch2b/relu_0_split_1
I0630 19:26:28.790990  5429 net.cpp:413] out3a -> out3a
I0630 19:26:28.793148  5429 net.cpp:148] Setting up out3a
I0630 19:26:28.793165  5429 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0630 19:26:28.793167  5429 net.cpp:163] Memory required for data: 807731200
I0630 19:26:28.793174  5429 layer_factory.hpp:77] Creating layer out3a/bn
I0630 19:26:28.793180  5429 net.cpp:98] Creating Layer out3a/bn
I0630 19:26:28.793185  5429 net.cpp:439] out3a/bn <- out3a
I0630 19:26:28.793190  5429 net.cpp:413] out3a/bn -> out3a/bn
I0630 19:26:28.793987  5429 net.cpp:148] Setting up out3a/bn
I0630 19:26:28.793992  5429 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0630 19:26:28.793994  5429 net.cpp:163] Memory required for data: 814284800
I0630 19:26:28.793999  5429 layer_factory.hpp:77] Creating layer out3a/relu
I0630 19:26:28.794003  5429 net.cpp:98] Creating Layer out3a/relu
I0630 19:26:28.794005  5429 net.cpp:439] out3a/relu <- out3a/bn
I0630 19:26:28.794008  5429 net.cpp:400] out3a/relu -> out3a/bn (in-place)
I0630 19:26:28.794010  5429 net.cpp:148] Setting up out3a/relu
I0630 19:26:28.794013  5429 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0630 19:26:28.794014  5429 net.cpp:163] Memory required for data: 820838400
I0630 19:26:28.794016  5429 layer_factory.hpp:77] Creating layer out3_out5_combined
I0630 19:26:28.794019  5429 net.cpp:98] Creating Layer out3_out5_combined
I0630 19:26:28.794021  5429 net.cpp:439] out3_out5_combined <- out5a_up2
I0630 19:26:28.794023  5429 net.cpp:439] out3_out5_combined <- out3a/bn
I0630 19:26:28.794026  5429 net.cpp:413] out3_out5_combined -> out3_out5_combined
I0630 19:26:28.794049  5429 net.cpp:148] Setting up out3_out5_combined
I0630 19:26:28.794052  5429 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0630 19:26:28.794054  5429 net.cpp:163] Memory required for data: 827392000
I0630 19:26:28.794056  5429 layer_factory.hpp:77] Creating layer ctx_conv1
I0630 19:26:28.794061  5429 net.cpp:98] Creating Layer ctx_conv1
I0630 19:26:28.794064  5429 net.cpp:439] ctx_conv1 <- out3_out5_combined
I0630 19:26:28.794066  5429 net.cpp:413] ctx_conv1 -> ctx_conv1
I0630 19:26:28.795126  5429 net.cpp:148] Setting up ctx_conv1
I0630 19:26:28.795132  5429 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0630 19:26:28.795135  5429 net.cpp:163] Memory required for data: 833945600
I0630 19:26:28.795137  5429 layer_factory.hpp:77] Creating layer ctx_conv1/bn
I0630 19:26:28.795140  5429 net.cpp:98] Creating Layer ctx_conv1/bn
I0630 19:26:28.795142  5429 net.cpp:439] ctx_conv1/bn <- ctx_conv1
I0630 19:26:28.795145  5429 net.cpp:413] ctx_conv1/bn -> ctx_conv1/bn
I0630 19:26:28.795907  5429 net.cpp:148] Setting up ctx_conv1/bn
I0630 19:26:28.795912  5429 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0630 19:26:28.795914  5429 net.cpp:163] Memory required for data: 840499200
I0630 19:26:28.795928  5429 layer_factory.hpp:77] Creating layer ctx_conv1/relu
I0630 19:26:28.795930  5429 net.cpp:98] Creating Layer ctx_conv1/relu
I0630 19:26:28.795933  5429 net.cpp:439] ctx_conv1/relu <- ctx_conv1/bn
I0630 19:26:28.795934  5429 net.cpp:400] ctx_conv1/relu -> ctx_conv1/bn (in-place)
I0630 19:26:28.795938  5429 net.cpp:148] Setting up ctx_conv1/relu
I0630 19:26:28.795940  5429 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0630 19:26:28.795941  5429 net.cpp:163] Memory required for data: 847052800
I0630 19:26:28.795943  5429 layer_factory.hpp:77] Creating layer ctx_conv2
I0630 19:26:28.795951  5429 net.cpp:98] Creating Layer ctx_conv2
I0630 19:26:28.795954  5429 net.cpp:439] ctx_conv2 <- ctx_conv1/bn
I0630 19:26:28.795958  5429 net.cpp:413] ctx_conv2 -> ctx_conv2
I0630 19:26:28.797004  5429 net.cpp:148] Setting up ctx_conv2
I0630 19:26:28.797009  5429 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0630 19:26:28.797010  5429 net.cpp:163] Memory required for data: 853606400
I0630 19:26:28.797014  5429 layer_factory.hpp:77] Creating layer ctx_conv2/bn
I0630 19:26:28.797018  5429 net.cpp:98] Creating Layer ctx_conv2/bn
I0630 19:26:28.797019  5429 net.cpp:439] ctx_conv2/bn <- ctx_conv2
I0630 19:26:28.797022  5429 net.cpp:413] ctx_conv2/bn -> ctx_conv2/bn
I0630 19:26:28.797790  5429 net.cpp:148] Setting up ctx_conv2/bn
I0630 19:26:28.797794  5429 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0630 19:26:28.797796  5429 net.cpp:163] Memory required for data: 860160000
I0630 19:26:28.797801  5429 layer_factory.hpp:77] Creating layer ctx_conv2/relu
I0630 19:26:28.797803  5429 net.cpp:98] Creating Layer ctx_conv2/relu
I0630 19:26:28.797806  5429 net.cpp:439] ctx_conv2/relu <- ctx_conv2/bn
I0630 19:26:28.797808  5429 net.cpp:400] ctx_conv2/relu -> ctx_conv2/bn (in-place)
I0630 19:26:28.797811  5429 net.cpp:148] Setting up ctx_conv2/relu
I0630 19:26:28.797813  5429 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0630 19:26:28.797816  5429 net.cpp:163] Memory required for data: 866713600
I0630 19:26:28.797816  5429 layer_factory.hpp:77] Creating layer ctx_conv3
I0630 19:26:28.797821  5429 net.cpp:98] Creating Layer ctx_conv3
I0630 19:26:28.797823  5429 net.cpp:439] ctx_conv3 <- ctx_conv2/bn
I0630 19:26:28.797825  5429 net.cpp:413] ctx_conv3 -> ctx_conv3
I0630 19:26:28.798889  5429 net.cpp:148] Setting up ctx_conv3
I0630 19:26:28.798895  5429 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0630 19:26:28.798897  5429 net.cpp:163] Memory required for data: 873267200
I0630 19:26:28.798900  5429 layer_factory.hpp:77] Creating layer ctx_conv3/bn
I0630 19:26:28.798903  5429 net.cpp:98] Creating Layer ctx_conv3/bn
I0630 19:26:28.798905  5429 net.cpp:439] ctx_conv3/bn <- ctx_conv3
I0630 19:26:28.798908  5429 net.cpp:413] ctx_conv3/bn -> ctx_conv3/bn
I0630 19:26:28.799682  5429 net.cpp:148] Setting up ctx_conv3/bn
I0630 19:26:28.799687  5429 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0630 19:26:28.799690  5429 net.cpp:163] Memory required for data: 879820800
I0630 19:26:28.799695  5429 layer_factory.hpp:77] Creating layer ctx_conv3/relu
I0630 19:26:28.799698  5429 net.cpp:98] Creating Layer ctx_conv3/relu
I0630 19:26:28.799700  5429 net.cpp:439] ctx_conv3/relu <- ctx_conv3/bn
I0630 19:26:28.799703  5429 net.cpp:400] ctx_conv3/relu -> ctx_conv3/bn (in-place)
I0630 19:26:28.799706  5429 net.cpp:148] Setting up ctx_conv3/relu
I0630 19:26:28.799708  5429 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0630 19:26:28.799710  5429 net.cpp:163] Memory required for data: 886374400
I0630 19:26:28.799712  5429 layer_factory.hpp:77] Creating layer ctx_conv4
I0630 19:26:28.799715  5429 net.cpp:98] Creating Layer ctx_conv4
I0630 19:26:28.799717  5429 net.cpp:439] ctx_conv4 <- ctx_conv3/bn
I0630 19:26:28.799721  5429 net.cpp:413] ctx_conv4 -> ctx_conv4
I0630 19:26:28.800766  5429 net.cpp:148] Setting up ctx_conv4
I0630 19:26:28.800771  5429 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0630 19:26:28.800773  5429 net.cpp:163] Memory required for data: 892928000
I0630 19:26:28.800776  5429 layer_factory.hpp:77] Creating layer ctx_conv4/bn
I0630 19:26:28.800786  5429 net.cpp:98] Creating Layer ctx_conv4/bn
I0630 19:26:28.800788  5429 net.cpp:439] ctx_conv4/bn <- ctx_conv4
I0630 19:26:28.800791  5429 net.cpp:413] ctx_conv4/bn -> ctx_conv4/bn
I0630 19:26:28.801555  5429 net.cpp:148] Setting up ctx_conv4/bn
I0630 19:26:28.801560  5429 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0630 19:26:28.801563  5429 net.cpp:163] Memory required for data: 899481600
I0630 19:26:28.801568  5429 layer_factory.hpp:77] Creating layer ctx_conv4/relu
I0630 19:26:28.801569  5429 net.cpp:98] Creating Layer ctx_conv4/relu
I0630 19:26:28.801571  5429 net.cpp:439] ctx_conv4/relu <- ctx_conv4/bn
I0630 19:26:28.801574  5429 net.cpp:400] ctx_conv4/relu -> ctx_conv4/bn (in-place)
I0630 19:26:28.801578  5429 net.cpp:148] Setting up ctx_conv4/relu
I0630 19:26:28.801579  5429 net.cpp:155] Top shape: 4 64 80 80 (1638400)
I0630 19:26:28.801581  5429 net.cpp:163] Memory required for data: 906035200
I0630 19:26:28.801582  5429 layer_factory.hpp:77] Creating layer ctx_final
I0630 19:26:28.801586  5429 net.cpp:98] Creating Layer ctx_final
I0630 19:26:28.801589  5429 net.cpp:439] ctx_final <- ctx_conv4/bn
I0630 19:26:28.801590  5429 net.cpp:413] ctx_final -> ctx_final
I0630 19:26:28.802148  5429 net.cpp:148] Setting up ctx_final
I0630 19:26:28.802153  5429 net.cpp:155] Top shape: 4 20 80 80 (512000)
I0630 19:26:28.802155  5429 net.cpp:163] Memory required for data: 908083200
I0630 19:26:28.802158  5429 layer_factory.hpp:77] Creating layer ctx_final/relu
I0630 19:26:28.802161  5429 net.cpp:98] Creating Layer ctx_final/relu
I0630 19:26:28.802163  5429 net.cpp:439] ctx_final/relu <- ctx_final
I0630 19:26:28.802165  5429 net.cpp:400] ctx_final/relu -> ctx_final (in-place)
I0630 19:26:28.802168  5429 net.cpp:148] Setting up ctx_final/relu
I0630 19:26:28.802170  5429 net.cpp:155] Top shape: 4 20 80 80 (512000)
I0630 19:26:28.802172  5429 net.cpp:163] Memory required for data: 910131200
I0630 19:26:28.802173  5429 layer_factory.hpp:77] Creating layer out_deconv_final_up2
I0630 19:26:28.802177  5429 net.cpp:98] Creating Layer out_deconv_final_up2
I0630 19:26:28.802178  5429 net.cpp:439] out_deconv_final_up2 <- ctx_final
I0630 19:26:28.802181  5429 net.cpp:413] out_deconv_final_up2 -> out_deconv_final_up2
I0630 19:26:28.802443  5429 net.cpp:148] Setting up out_deconv_final_up2
I0630 19:26:28.802448  5429 net.cpp:155] Top shape: 4 20 160 160 (2048000)
I0630 19:26:28.802449  5429 net.cpp:163] Memory required for data: 918323200
I0630 19:26:28.802451  5429 layer_factory.hpp:77] Creating layer out_deconv_final_up4
I0630 19:26:28.802455  5429 net.cpp:98] Creating Layer out_deconv_final_up4
I0630 19:26:28.802458  5429 net.cpp:439] out_deconv_final_up4 <- out_deconv_final_up2
I0630 19:26:28.802459  5429 net.cpp:413] out_deconv_final_up4 -> out_deconv_final_up4
I0630 19:26:28.802714  5429 net.cpp:148] Setting up out_deconv_final_up4
I0630 19:26:28.802718  5429 net.cpp:155] Top shape: 4 20 320 320 (8192000)
I0630 19:26:28.802721  5429 net.cpp:163] Memory required for data: 951091200
I0630 19:26:28.802723  5429 layer_factory.hpp:77] Creating layer out_deconv_final_up8
I0630 19:26:28.802728  5429 net.cpp:98] Creating Layer out_deconv_final_up8
I0630 19:26:28.802731  5429 net.cpp:439] out_deconv_final_up8 <- out_deconv_final_up4
I0630 19:26:28.802733  5429 net.cpp:413] out_deconv_final_up8 -> out_deconv_final_up8
I0630 19:26:28.802985  5429 net.cpp:148] Setting up out_deconv_final_up8
I0630 19:26:28.802989  5429 net.cpp:155] Top shape: 4 20 640 640 (32768000)
I0630 19:26:28.802991  5429 net.cpp:163] Memory required for data: 1082163200
I0630 19:26:28.802994  5429 layer_factory.hpp:77] Creating layer out_deconv_final_up8_out_deconv_final_up8_0_split
I0630 19:26:28.802997  5429 net.cpp:98] Creating Layer out_deconv_final_up8_out_deconv_final_up8_0_split
I0630 19:26:28.802999  5429 net.cpp:439] out_deconv_final_up8_out_deconv_final_up8_0_split <- out_deconv_final_up8
I0630 19:26:28.803001  5429 net.cpp:413] out_deconv_final_up8_out_deconv_final_up8_0_split -> out_deconv_final_up8_out_deconv_final_up8_0_split_0
I0630 19:26:28.803010  5429 net.cpp:413] out_deconv_final_up8_out_deconv_final_up8_0_split -> out_deconv_final_up8_out_deconv_final_up8_0_split_1
I0630 19:26:28.803014  5429 net.cpp:413] out_deconv_final_up8_out_deconv_final_up8_0_split -> out_deconv_final_up8_out_deconv_final_up8_0_split_2
I0630 19:26:28.803068  5429 net.cpp:148] Setting up out_deconv_final_up8_out_deconv_final_up8_0_split
I0630 19:26:28.803072  5429 net.cpp:155] Top shape: 4 20 640 640 (32768000)
I0630 19:26:28.803074  5429 net.cpp:155] Top shape: 4 20 640 640 (32768000)
I0630 19:26:28.803077  5429 net.cpp:155] Top shape: 4 20 640 640 (32768000)
I0630 19:26:28.803078  5429 net.cpp:163] Memory required for data: 1475379200
I0630 19:26:28.803081  5429 layer_factory.hpp:77] Creating layer loss
I0630 19:26:28.803086  5429 net.cpp:98] Creating Layer loss
I0630 19:26:28.803087  5429 net.cpp:439] loss <- out_deconv_final_up8_out_deconv_final_up8_0_split_0
I0630 19:26:28.803089  5429 net.cpp:439] loss <- label_data_1_split_0
I0630 19:26:28.803092  5429 net.cpp:413] loss -> loss
I0630 19:26:28.803097  5429 layer_factory.hpp:77] Creating layer loss
I0630 19:26:28.843915  5429 net.cpp:148] Setting up loss
I0630 19:26:28.843938  5429 net.cpp:155] Top shape: (1)
I0630 19:26:28.843940  5429 net.cpp:158]     with loss weight 1
I0630 19:26:28.843947  5429 net.cpp:163] Memory required for data: 1475379204
I0630 19:26:28.843951  5429 layer_factory.hpp:77] Creating layer accuracy/top1
I0630 19:26:28.843963  5429 net.cpp:98] Creating Layer accuracy/top1
I0630 19:26:28.843967  5429 net.cpp:439] accuracy/top1 <- out_deconv_final_up8_out_deconv_final_up8_0_split_1
I0630 19:26:28.843971  5429 net.cpp:439] accuracy/top1 <- label_data_1_split_1
I0630 19:26:28.843974  5429 net.cpp:413] accuracy/top1 -> accuracy/top1
I0630 19:26:28.843982  5429 net.cpp:148] Setting up accuracy/top1
I0630 19:26:28.843986  5429 net.cpp:155] Top shape: (1)
I0630 19:26:28.843987  5429 net.cpp:163] Memory required for data: 1475379208
I0630 19:26:28.843989  5429 layer_factory.hpp:77] Creating layer accuracy/top5
I0630 19:26:28.843993  5429 net.cpp:98] Creating Layer accuracy/top5
I0630 19:26:28.843996  5429 net.cpp:439] accuracy/top5 <- out_deconv_final_up8_out_deconv_final_up8_0_split_2
I0630 19:26:28.843997  5429 net.cpp:439] accuracy/top5 <- label_data_1_split_2
I0630 19:26:28.844000  5429 net.cpp:413] accuracy/top5 -> accuracy/top5
I0630 19:26:28.844003  5429 net.cpp:148] Setting up accuracy/top5
I0630 19:26:28.844007  5429 net.cpp:155] Top shape: (1)
I0630 19:26:28.844008  5429 net.cpp:163] Memory required for data: 1475379212
I0630 19:26:28.844010  5429 net.cpp:226] accuracy/top5 does not need backward computation.
I0630 19:26:28.844013  5429 net.cpp:226] accuracy/top1 does not need backward computation.
I0630 19:26:28.844015  5429 net.cpp:224] loss needs backward computation.
I0630 19:26:28.844017  5429 net.cpp:224] out_deconv_final_up8_out_deconv_final_up8_0_split needs backward computation.
I0630 19:26:28.844020  5429 net.cpp:224] out_deconv_final_up8 needs backward computation.
I0630 19:26:28.844022  5429 net.cpp:224] out_deconv_final_up4 needs backward computation.
I0630 19:26:28.844025  5429 net.cpp:224] out_deconv_final_up2 needs backward computation.
I0630 19:26:28.844027  5429 net.cpp:224] ctx_final/relu needs backward computation.
I0630 19:26:28.844030  5429 net.cpp:224] ctx_final needs backward computation.
I0630 19:26:28.844033  5429 net.cpp:224] ctx_conv4/relu needs backward computation.
I0630 19:26:28.844034  5429 net.cpp:224] ctx_conv4/bn needs backward computation.
I0630 19:26:28.844036  5429 net.cpp:224] ctx_conv4 needs backward computation.
I0630 19:26:28.844039  5429 net.cpp:224] ctx_conv3/relu needs backward computation.
I0630 19:26:28.844043  5429 net.cpp:224] ctx_conv3/bn needs backward computation.
I0630 19:26:28.844044  5429 net.cpp:224] ctx_conv3 needs backward computation.
I0630 19:26:28.844046  5429 net.cpp:224] ctx_conv2/relu needs backward computation.
I0630 19:26:28.844048  5429 net.cpp:224] ctx_conv2/bn needs backward computation.
I0630 19:26:28.844059  5429 net.cpp:224] ctx_conv2 needs backward computation.
I0630 19:26:28.844063  5429 net.cpp:224] ctx_conv1/relu needs backward computation.
I0630 19:26:28.844063  5429 net.cpp:224] ctx_conv1/bn needs backward computation.
I0630 19:26:28.844066  5429 net.cpp:224] ctx_conv1 needs backward computation.
I0630 19:26:28.844069  5429 net.cpp:224] out3_out5_combined needs backward computation.
I0630 19:26:28.844072  5429 net.cpp:224] out3a/relu needs backward computation.
I0630 19:26:28.844074  5429 net.cpp:224] out3a/bn needs backward computation.
I0630 19:26:28.844076  5429 net.cpp:224] out3a needs backward computation.
I0630 19:26:28.844079  5429 net.cpp:224] out5a_up2 needs backward computation.
I0630 19:26:28.844082  5429 net.cpp:224] out5a/relu needs backward computation.
I0630 19:26:28.844084  5429 net.cpp:224] out5a/bn needs backward computation.
I0630 19:26:28.844087  5429 net.cpp:224] out5a needs backward computation.
I0630 19:26:28.844090  5429 net.cpp:224] res5a_branch2b/relu needs backward computation.
I0630 19:26:28.844092  5429 net.cpp:224] res5a_branch2b/bn needs backward computation.
I0630 19:26:28.844094  5429 net.cpp:224] res5a_branch2b needs backward computation.
I0630 19:26:28.844097  5429 net.cpp:224] res5a_branch2a/relu needs backward computation.
I0630 19:26:28.844100  5429 net.cpp:224] res5a_branch2a/bn needs backward computation.
I0630 19:26:28.844102  5429 net.cpp:224] res5a_branch2a needs backward computation.
I0630 19:26:28.844105  5429 net.cpp:224] pool4 needs backward computation.
I0630 19:26:28.844107  5429 net.cpp:224] res4a_branch2b/relu needs backward computation.
I0630 19:26:28.844110  5429 net.cpp:224] res4a_branch2b/bn needs backward computation.
I0630 19:26:28.844111  5429 net.cpp:224] res4a_branch2b needs backward computation.
I0630 19:26:28.844115  5429 net.cpp:224] res4a_branch2a/relu needs backward computation.
I0630 19:26:28.844116  5429 net.cpp:224] res4a_branch2a/bn needs backward computation.
I0630 19:26:28.844120  5429 net.cpp:224] res4a_branch2a needs backward computation.
I0630 19:26:28.844121  5429 net.cpp:224] pool3 needs backward computation.
I0630 19:26:28.844125  5429 net.cpp:224] res3a_branch2b/bn_res3a_branch2b/relu_0_split needs backward computation.
I0630 19:26:28.844127  5429 net.cpp:224] res3a_branch2b/relu needs backward computation.
I0630 19:26:28.844130  5429 net.cpp:224] res3a_branch2b/bn needs backward computation.
I0630 19:26:28.844131  5429 net.cpp:224] res3a_branch2b needs backward computation.
I0630 19:26:28.844135  5429 net.cpp:224] res3a_branch2a/relu needs backward computation.
I0630 19:26:28.844136  5429 net.cpp:224] res3a_branch2a/bn needs backward computation.
I0630 19:26:28.844139  5429 net.cpp:224] res3a_branch2a needs backward computation.
I0630 19:26:28.844141  5429 net.cpp:224] pool2 needs backward computation.
I0630 19:26:28.844144  5429 net.cpp:224] res2a_branch2b/relu needs backward computation.
I0630 19:26:28.844147  5429 net.cpp:224] res2a_branch2b/bn needs backward computation.
I0630 19:26:28.844149  5429 net.cpp:224] res2a_branch2b needs backward computation.
I0630 19:26:28.844152  5429 net.cpp:224] res2a_branch2a/relu needs backward computation.
I0630 19:26:28.844156  5429 net.cpp:224] res2a_branch2a/bn needs backward computation.
I0630 19:26:28.844157  5429 net.cpp:224] res2a_branch2a needs backward computation.
I0630 19:26:28.844159  5429 net.cpp:224] pool1 needs backward computation.
I0630 19:26:28.844162  5429 net.cpp:224] conv1b/relu needs backward computation.
I0630 19:26:28.844166  5429 net.cpp:224] conv1b/bn needs backward computation.
I0630 19:26:28.844167  5429 net.cpp:224] conv1b needs backward computation.
I0630 19:26:28.844171  5429 net.cpp:224] conv1a/relu needs backward computation.
I0630 19:26:28.844172  5429 net.cpp:224] conv1a/bn needs backward computation.
I0630 19:26:28.844175  5429 net.cpp:224] conv1a needs backward computation.
I0630 19:26:28.844177  5429 net.cpp:226] data/bias does not need backward computation.
I0630 19:26:28.844180  5429 net.cpp:226] label_data_1_split does not need backward computation.
I0630 19:26:28.844187  5429 net.cpp:226] data does not need backward computation.
I0630 19:26:28.844188  5429 net.cpp:268] This network produces output accuracy/top1
I0630 19:26:28.844190  5429 net.cpp:268] This network produces output accuracy/top5
I0630 19:26:28.844193  5429 net.cpp:268] This network produces output loss
I0630 19:26:28.844224  5429 net.cpp:288] Network initialization done.
I0630 19:26:28.844316  5429 solver.cpp:60] Solver scaffolding done.
I0630 19:26:28.852279  5429 caffe.cpp:145] Finetuning from training/imagenet_jacintonet11_v2_bn_iter_160000.caffemodel
I0630 19:26:33.119323  5429 net.cpp:804] Ignoring source layer input
I0630 19:26:33.123808  5429 net.cpp:804] Ignoring source layer pool5
I0630 19:26:33.123836  5429 net.cpp:804] Ignoring source layer fc1000
I0630 19:26:33.123847  5429 net.cpp:804] Ignoring source layer fc1000_fc1000_0_split
I0630 19:26:33.123868  5429 net.cpp:804] Ignoring source layer prob
I0630 19:26:33.123870  5429 net.cpp:804] Ignoring source layer argMaxOut
I0630 19:26:33.132794  5429 net.cpp:804] Ignoring source layer input
I0630 19:26:33.133968  5429 net.cpp:804] Ignoring source layer pool5
I0630 19:26:33.133975  5429 net.cpp:804] Ignoring source layer fc1000
I0630 19:26:33.133976  5429 net.cpp:804] Ignoring source layer fc1000_fc1000_0_split
I0630 19:26:33.133978  5429 net.cpp:804] Ignoring source layer prob
I0630 19:26:33.133980  5429 net.cpp:804] Ignoring source layer argMaxOut
I0630 19:26:33.830165  5429 data_layer.cpp:78] ReshapePrefetch 5, 3, 640, 640
I0630 19:26:33.830231  5429 data_layer.cpp:83] output data size: 5,3,640,640
I0630 19:26:33.868137  5429 data_layer.cpp:78] ReshapePrefetch 5, 1, 640, 640
I0630 19:26:33.870117  5429 data_layer.cpp:83] output data size: 5,1,640,640
I0630 19:26:35.364768  5429 data_layer.cpp:78] ReshapePrefetch 5, 3, 640, 640
I0630 19:26:35.364843  5429 data_layer.cpp:83] output data size: 5,3,640,640
I0630 19:26:35.402186  5429 data_layer.cpp:78] ReshapePrefetch 5, 1, 640, 640
I0630 19:26:35.410117  5429 data_layer.cpp:83] output data size: 5,1,640,640
I0630 19:26:35.960364  5429 parallel.cpp:334] Starting Optimization
I0630 19:26:35.960417  5429 solver.cpp:413] Solving jsegnet21v2_train
I0630 19:26:35.960423  5429 solver.cpp:414] Learning Rate Policy: multistep
I0630 19:26:36.010901  5713 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 19:26:41.192584  5429 solver.cpp:290] Iteration 0 (0 iter/s, 5.22933s/100 iter), loss = 2.74647
I0630 19:26:41.192607  5429 solver.cpp:309]     Train net output #0: loss = 2.74647 (* 1 = 2.74647 loss)
I0630 19:26:41.192616  5429 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
I0630 19:31:25.981591  5660 blocking_queue.cpp:50] Waiting for data
I0630 19:32:45.899688  5429 solver.cpp:290] Iteration 100 (0.274206 iter/s, 364.689s/100 iter), loss = 0.687969
I0630 19:32:45.906404  5429 solver.cpp:309]     Train net output #0: loss = 0.687969 (* 1 = 0.687969 loss)
I0630 19:32:45.906415  5429 sgd_solver.cpp:106] Iteration 100, lr = 0.0001
I0630 19:35:09.554340  5694 blocking_queue.cpp:50] Waiting for data
I0630 19:36:18.150493  5429 solver.cpp:290] Iteration 200 (0.471144 iter/s, 212.249s/100 iter), loss = 0.855586
I0630 19:36:18.150537  5429 solver.cpp:309]     Train net output #0: loss = 0.855586 (* 1 = 0.855586 loss)
I0630 19:36:18.150545  5429 sgd_solver.cpp:106] Iteration 200, lr = 0.0001
I0630 19:36:36.818286  5429 solver.cpp:290] Iteration 300 (5.35681 iter/s, 18.6678s/100 iter), loss = 0.443862
I0630 19:36:36.818310  5429 solver.cpp:309]     Train net output #0: loss = 0.443862 (* 1 = 0.443862 loss)
I0630 19:36:36.818317  5429 sgd_solver.cpp:106] Iteration 300, lr = 0.0001
I0630 19:36:56.207587  5429 solver.cpp:290] Iteration 400 (5.15748 iter/s, 19.3893s/100 iter), loss = 0.355478
I0630 19:36:56.207641  5429 solver.cpp:309]     Train net output #0: loss = 0.355478 (* 1 = 0.355478 loss)
I0630 19:36:56.207651  5429 sgd_solver.cpp:106] Iteration 400, lr = 0.0001
I0630 19:37:15.715085  5429 solver.cpp:290] Iteration 500 (5.12625 iter/s, 19.5075s/100 iter), loss = 0.337974
I0630 19:37:15.715107  5429 solver.cpp:309]     Train net output #0: loss = 0.337974 (* 1 = 0.337974 loss)
I0630 19:37:15.715114  5429 sgd_solver.cpp:106] Iteration 500, lr = 0.0001
I0630 19:37:35.235857  5429 solver.cpp:290] Iteration 600 (5.12276 iter/s, 19.5207s/100 iter), loss = 0.153137
I0630 19:37:35.235939  5429 solver.cpp:309]     Train net output #0: loss = 0.153138 (* 1 = 0.153138 loss)
I0630 19:37:35.235949  5429 sgd_solver.cpp:106] Iteration 600, lr = 0.0001
I0630 19:37:54.481595  5429 solver.cpp:290] Iteration 700 (5.19599 iter/s, 19.2456s/100 iter), loss = 0.25378
I0630 19:37:54.481619  5429 solver.cpp:309]     Train net output #0: loss = 0.25378 (* 1 = 0.25378 loss)
I0630 19:37:54.481626  5429 sgd_solver.cpp:106] Iteration 700, lr = 0.0001
I0630 19:38:13.949225  5429 solver.cpp:290] Iteration 800 (5.13679 iter/s, 19.4674s/100 iter), loss = 0.713979
I0630 19:38:13.949306  5429 solver.cpp:309]     Train net output #0: loss = 0.713979 (* 1 = 0.713979 loss)
I0630 19:38:13.949313  5429 sgd_solver.cpp:106] Iteration 800, lr = 0.0001
I0630 19:38:33.364128  5429 solver.cpp:290] Iteration 900 (5.15083 iter/s, 19.4143s/100 iter), loss = 0.194988
I0630 19:38:33.364151  5429 solver.cpp:309]     Train net output #0: loss = 0.194988 (* 1 = 0.194988 loss)
I0630 19:38:33.364158  5429 sgd_solver.cpp:106] Iteration 900, lr = 0.0001
I0630 19:38:52.966876  5429 solver.cpp:290] Iteration 1000 (5.10146 iter/s, 19.6022s/100 iter), loss = 0.457464
I0630 19:38:52.968431  5429 solver.cpp:309]     Train net output #0: loss = 0.457464 (* 1 = 0.457464 loss)
I0630 19:38:52.968444  5429 sgd_solver.cpp:106] Iteration 1000, lr = 0.0001
I0630 19:39:12.345299  5429 solver.cpp:290] Iteration 1100 (5.16092 iter/s, 19.3764s/100 iter), loss = 0.325143
I0630 19:39:12.345329  5429 solver.cpp:309]     Train net output #0: loss = 0.325143 (* 1 = 0.325143 loss)
I0630 19:39:12.345337  5429 sgd_solver.cpp:106] Iteration 1100, lr = 0.0001
I0630 19:39:31.896270  5429 solver.cpp:290] Iteration 1200 (5.11497 iter/s, 19.5505s/100 iter), loss = 0.174273
I0630 19:39:31.896314  5429 solver.cpp:309]     Train net output #0: loss = 0.174273 (* 1 = 0.174273 loss)
I0630 19:39:31.896325  5429 sgd_solver.cpp:106] Iteration 1200, lr = 0.0001
I0630 19:39:51.467409  5429 solver.cpp:290] Iteration 1300 (5.1097 iter/s, 19.5706s/100 iter), loss = 0.209306
I0630 19:39:51.467437  5429 solver.cpp:309]     Train net output #0: loss = 0.209306 (* 1 = 0.209306 loss)
I0630 19:39:51.467447  5429 sgd_solver.cpp:106] Iteration 1300, lr = 0.0001
I0630 19:40:11.054872  5429 solver.cpp:290] Iteration 1400 (5.10544 iter/s, 19.587s/100 iter), loss = 0.700326
I0630 19:40:11.054940  5429 solver.cpp:309]     Train net output #0: loss = 0.700326 (* 1 = 0.700326 loss)
I0630 19:40:11.054947  5429 sgd_solver.cpp:106] Iteration 1400, lr = 0.0001
I0630 19:40:30.430704  5429 solver.cpp:290] Iteration 1500 (5.16121 iter/s, 19.3753s/100 iter), loss = 0.117938
I0630 19:40:30.430727  5429 solver.cpp:309]     Train net output #0: loss = 0.117938 (* 1 = 0.117938 loss)
I0630 19:40:30.430734  5429 sgd_solver.cpp:106] Iteration 1500, lr = 0.0001
I0630 19:40:49.827844  5429 solver.cpp:290] Iteration 1600 (5.15553 iter/s, 19.3966s/100 iter), loss = 0.236955
I0630 19:40:49.827898  5429 solver.cpp:309]     Train net output #0: loss = 0.236955 (* 1 = 0.236955 loss)
I0630 19:40:49.827913  5429 sgd_solver.cpp:106] Iteration 1600, lr = 0.0001
I0630 19:41:09.424984  5429 solver.cpp:290] Iteration 1700 (5.10292 iter/s, 19.5966s/100 iter), loss = 0.262355
I0630 19:41:09.425009  5429 solver.cpp:309]     Train net output #0: loss = 0.262355 (* 1 = 0.262355 loss)
I0630 19:41:09.425017  5429 sgd_solver.cpp:106] Iteration 1700, lr = 0.0001
I0630 19:41:28.597721  5429 solver.cpp:290] Iteration 1800 (5.21587 iter/s, 19.1723s/100 iter), loss = 0.250876
I0630 19:41:28.597822  5429 solver.cpp:309]     Train net output #0: loss = 0.250877 (* 1 = 0.250877 loss)
I0630 19:41:28.597832  5429 sgd_solver.cpp:106] Iteration 1800, lr = 0.0001
I0630 19:41:48.002044  5429 solver.cpp:290] Iteration 1900 (5.15364 iter/s, 19.4038s/100 iter), loss = 0.561186
I0630 19:41:48.002066  5429 solver.cpp:309]     Train net output #0: loss = 0.561186 (* 1 = 0.561186 loss)
I0630 19:41:48.002074  5429 sgd_solver.cpp:106] Iteration 1900, lr = 0.0001
I0630 19:42:07.350342  5429 solver.cpp:471] Iteration 2000, Testing net (#0)
I0630 19:43:43.168138  5429 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.901507
I0630 19:43:43.169898  5429 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.980604
I0630 19:43:43.169909  5429 solver.cpp:544]     Test net output #2: loss = 0.221404 (* 1 = 0.221404 loss)
I0630 19:43:43.394817  5429 solver.cpp:290] Iteration 2000 (0.866626 iter/s, 115.39s/100 iter), loss = 0.246151
I0630 19:43:43.394840  5429 solver.cpp:309]     Train net output #0: loss = 0.246151 (* 1 = 0.246151 loss)
I0630 19:43:43.394847  5429 sgd_solver.cpp:106] Iteration 2000, lr = 0.0001
I0630 19:44:01.495885  5429 solver.cpp:290] Iteration 2100 (5.52468 iter/s, 18.1006s/100 iter), loss = 0.120977
I0630 19:44:01.495913  5429 solver.cpp:309]     Train net output #0: loss = 0.120977 (* 1 = 0.120977 loss)
I0630 19:44:01.495921  5429 sgd_solver.cpp:106] Iteration 2100, lr = 0.0001
I0630 19:45:31.828320  5429 solver.cpp:290] Iteration 2200 (1.10705 iter/s, 90.3303s/100 iter), loss = 0.73541
I0630 19:45:31.828374  5429 solver.cpp:309]     Train net output #0: loss = 0.735411 (* 1 = 0.735411 loss)
I0630 19:45:31.828382  5429 sgd_solver.cpp:106] Iteration 2200, lr = 0.0001
I0630 19:45:54.022749  5429 solver.cpp:290] Iteration 2300 (4.50576 iter/s, 22.1938s/100 iter), loss = 0.16164
I0630 19:45:54.022773  5429 solver.cpp:309]     Train net output #0: loss = 0.16164 (* 1 = 0.16164 loss)
I0630 19:45:54.022781  5429 sgd_solver.cpp:106] Iteration 2300, lr = 0.0001
I0630 19:46:13.034775  5429 solver.cpp:290] Iteration 2400 (5.26001 iter/s, 19.0114s/100 iter), loss = 0.130325
I0630 19:46:13.034821  5429 solver.cpp:309]     Train net output #0: loss = 0.130325 (* 1 = 0.130325 loss)
I0630 19:46:13.034828  5429 sgd_solver.cpp:106] Iteration 2400, lr = 0.0001
I0630 19:46:32.064512  5429 solver.cpp:290] Iteration 2500 (5.25512 iter/s, 19.0291s/100 iter), loss = 0.175133
I0630 19:46:32.064535  5429 solver.cpp:309]     Train net output #0: loss = 0.175133 (* 1 = 0.175133 loss)
I0630 19:46:32.064543  5429 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0630 19:46:51.241194  5429 solver.cpp:290] Iteration 2600 (5.21484 iter/s, 19.176s/100 iter), loss = 0.224398
I0630 19:46:51.241230  5429 solver.cpp:309]     Train net output #0: loss = 0.224398 (* 1 = 0.224398 loss)
I0630 19:46:51.241238  5429 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0630 19:47:10.608156  5429 solver.cpp:290] Iteration 2700 (5.16361 iter/s, 19.3663s/100 iter), loss = 0.132893
I0630 19:47:10.608181  5429 solver.cpp:309]     Train net output #0: loss = 0.132893 (* 1 = 0.132893 loss)
I0630 19:47:10.608187  5429 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0630 19:47:29.957798  5429 solver.cpp:290] Iteration 2800 (5.16825 iter/s, 19.3489s/100 iter), loss = 0.226913
I0630 19:47:29.957876  5429 solver.cpp:309]     Train net output #0: loss = 0.226914 (* 1 = 0.226914 loss)
I0630 19:47:29.957886  5429 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0630 19:47:49.000182  5429 solver.cpp:290] Iteration 2900 (5.25165 iter/s, 19.0416s/100 iter), loss = 0.10714
I0630 19:47:49.000205  5429 solver.cpp:309]     Train net output #0: loss = 0.10714 (* 1 = 0.10714 loss)
I0630 19:47:49.000212  5429 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0630 19:48:07.972378  5429 solver.cpp:290] Iteration 3000 (5.27106 iter/s, 18.9715s/100 iter), loss = 0.16946
I0630 19:48:07.972424  5429 solver.cpp:309]     Train net output #0: loss = 0.16946 (* 1 = 0.16946 loss)
I0630 19:48:07.972432  5429 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0630 19:48:27.210813  5429 solver.cpp:290] Iteration 3100 (5.19812 iter/s, 19.2377s/100 iter), loss = 0.186968
I0630 19:48:27.210835  5429 solver.cpp:309]     Train net output #0: loss = 0.186968 (* 1 = 0.186968 loss)
I0630 19:48:27.210842  5429 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0630 19:48:46.441362  5429 solver.cpp:290] Iteration 3200 (5.20024 iter/s, 19.2299s/100 iter), loss = 0.127278
I0630 19:48:46.441453  5429 solver.cpp:309]     Train net output #0: loss = 0.127278 (* 1 = 0.127278 loss)
I0630 19:48:46.441462  5429 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0630 19:49:05.798693  5429 solver.cpp:290] Iteration 3300 (5.1662 iter/s, 19.3566s/100 iter), loss = 0.100765
I0630 19:49:05.798719  5429 solver.cpp:309]     Train net output #0: loss = 0.100765 (* 1 = 0.100765 loss)
I0630 19:49:05.798728  5429 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0630 19:49:24.896965  5429 solver.cpp:290] Iteration 3400 (5.23626 iter/s, 19.0976s/100 iter), loss = 0.35129
I0630 19:49:24.897014  5429 solver.cpp:309]     Train net output #0: loss = 0.35129 (* 1 = 0.35129 loss)
I0630 19:49:24.897022  5429 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0630 19:49:44.055533  5429 solver.cpp:290] Iteration 3500 (5.21978 iter/s, 19.1579s/100 iter), loss = 0.192884
I0630 19:49:44.055558  5429 solver.cpp:309]     Train net output #0: loss = 0.192884 (* 1 = 0.192884 loss)
I0630 19:49:44.055567  5429 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0630 19:50:03.324772  5429 solver.cpp:290] Iteration 3600 (5.18979 iter/s, 19.2686s/100 iter), loss = 0.0916764
I0630 19:50:03.324816  5429 solver.cpp:309]     Train net output #0: loss = 0.0916765 (* 1 = 0.0916765 loss)
I0630 19:50:03.324825  5429 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0630 19:50:22.476022  5429 solver.cpp:290] Iteration 3700 (5.22177 iter/s, 19.1506s/100 iter), loss = 0.324966
I0630 19:50:22.476078  5429 solver.cpp:309]     Train net output #0: loss = 0.324967 (* 1 = 0.324967 loss)
I0630 19:50:22.476089  5429 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0630 19:50:41.555795  5429 solver.cpp:290] Iteration 3800 (5.24133 iter/s, 19.0791s/100 iter), loss = 0.235144
I0630 19:50:41.555840  5429 solver.cpp:309]     Train net output #0: loss = 0.235145 (* 1 = 0.235145 loss)
I0630 19:50:41.555848  5429 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0630 19:51:00.810511  5429 solver.cpp:290] Iteration 3900 (5.19371 iter/s, 19.2541s/100 iter), loss = 0.11207
I0630 19:51:00.810534  5429 solver.cpp:309]     Train net output #0: loss = 0.11207 (* 1 = 0.11207 loss)
I0630 19:51:00.810541  5429 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0630 19:51:19.866116  5429 solver.cpp:471] Iteration 4000, Testing net (#0)
I0630 19:52:54.264072  5429 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.91504
I0630 19:52:54.264169  5429 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.99196
I0630 19:52:54.264176  5429 solver.cpp:544]     Test net output #2: loss = 0.173459 (* 1 = 0.173459 loss)
I0630 19:52:54.471616  5429 solver.cpp:290] Iteration 4000 (0.879835 iter/s, 113.658s/100 iter), loss = 0.11938
I0630 19:52:54.471642  5429 solver.cpp:309]     Train net output #0: loss = 0.11938 (* 1 = 0.11938 loss)
I0630 19:52:54.471649  5429 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0630 19:53:38.248164  5429 solver.cpp:290] Iteration 4100 (2.2844 iter/s, 43.7751s/100 iter), loss = 0.159242
I0630 19:53:38.248214  5429 solver.cpp:309]     Train net output #0: loss = 0.159242 (* 1 = 0.159242 loss)
I0630 19:53:38.248221  5429 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0630 19:54:09.020256  5694 blocking_queue.cpp:50] Waiting for data
I0630 19:55:08.621134  5429 solver.cpp:290] Iteration 4200 (1.10656 iter/s, 90.3699s/100 iter), loss = 0.118977
I0630 19:55:08.621212  5429 solver.cpp:309]     Train net output #0: loss = 0.118978 (* 1 = 0.118978 loss)
I0630 19:55:08.621220  5429 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0630 19:55:27.445088  5429 solver.cpp:290] Iteration 4300 (5.31257 iter/s, 18.8233s/100 iter), loss = 0.295999
I0630 19:55:27.445112  5429 solver.cpp:309]     Train net output #0: loss = 0.295999 (* 1 = 0.295999 loss)
I0630 19:55:27.445119  5429 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0630 19:55:46.599792  5429 solver.cpp:290] Iteration 4400 (5.22082 iter/s, 19.1541s/100 iter), loss = 0.105363
I0630 19:55:46.599895  5429 solver.cpp:309]     Train net output #0: loss = 0.105363 (* 1 = 0.105363 loss)
I0630 19:55:46.599903  5429 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0630 19:56:05.720142  5429 solver.cpp:290] Iteration 4500 (5.23022 iter/s, 19.1196s/100 iter), loss = 0.134886
I0630 19:56:05.720166  5429 solver.cpp:309]     Train net output #0: loss = 0.134886 (* 1 = 0.134886 loss)
I0630 19:56:05.720173  5429 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0630 19:56:24.755962  5429 solver.cpp:290] Iteration 4600 (5.25343 iter/s, 19.0352s/100 iter), loss = 0.169664
I0630 19:56:24.756059  5429 solver.cpp:309]     Train net output #0: loss = 0.169664 (* 1 = 0.169664 loss)
I0630 19:56:24.756070  5429 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0630 19:56:43.847908  5429 solver.cpp:290] Iteration 4700 (5.238 iter/s, 19.0913s/100 iter), loss = 0.140418
I0630 19:56:43.847935  5429 solver.cpp:309]     Train net output #0: loss = 0.140418 (* 1 = 0.140418 loss)
I0630 19:56:43.847944  5429 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0630 19:57:02.952869  5429 solver.cpp:290] Iteration 4800 (5.23441 iter/s, 19.1043s/100 iter), loss = 0.121721
I0630 19:57:02.952950  5429 solver.cpp:309]     Train net output #0: loss = 0.121721 (* 1 = 0.121721 loss)
I0630 19:57:02.952965  5429 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0630 19:57:22.069211  5429 solver.cpp:290] Iteration 4900 (5.23131 iter/s, 19.1157s/100 iter), loss = 0.165884
I0630 19:57:22.069233  5429 solver.cpp:309]     Train net output #0: loss = 0.165884 (* 1 = 0.165884 loss)
I0630 19:57:22.069241  5429 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0630 19:57:41.283125  5429 solver.cpp:290] Iteration 5000 (5.20473 iter/s, 19.2133s/100 iter), loss = 0.101935
I0630 19:57:41.283202  5429 solver.cpp:309]     Train net output #0: loss = 0.101935 (* 1 = 0.101935 loss)
I0630 19:57:41.283213  5429 sgd_solver.cpp:106] Iteration 5000, lr = 0.0001
I0630 19:58:00.537964  5429 solver.cpp:290] Iteration 5100 (5.19368 iter/s, 19.2542s/100 iter), loss = 0.0650554
I0630 19:58:00.537987  5429 solver.cpp:309]     Train net output #0: loss = 0.0650555 (* 1 = 0.0650555 loss)
I0630 19:58:00.537993  5429 sgd_solver.cpp:106] Iteration 5100, lr = 0.0001
I0630 19:58:19.603713  5429 solver.cpp:290] Iteration 5200 (5.24517 iter/s, 19.0652s/100 iter), loss = 0.0917206
I0630 19:58:19.603785  5429 solver.cpp:309]     Train net output #0: loss = 0.0917208 (* 1 = 0.0917208 loss)
I0630 19:58:19.603794  5429 sgd_solver.cpp:106] Iteration 5200, lr = 0.0001
I0630 19:58:38.669136  5429 solver.cpp:290] Iteration 5300 (5.24527 iter/s, 19.0648s/100 iter), loss = 0.128555
I0630 19:58:38.669162  5429 solver.cpp:309]     Train net output #0: loss = 0.128556 (* 1 = 0.128556 loss)
I0630 19:58:38.669172  5429 sgd_solver.cpp:106] Iteration 5300, lr = 0.0001
I0630 19:58:57.780012  5429 solver.cpp:290] Iteration 5400 (5.23278 iter/s, 19.1103s/100 iter), loss = 0.116487
I0630 19:58:57.780093  5429 solver.cpp:309]     Train net output #0: loss = 0.116487 (* 1 = 0.116487 loss)
I0630 19:58:57.780103  5429 sgd_solver.cpp:106] Iteration 5400, lr = 0.0001
I0630 19:59:16.932225  5429 solver.cpp:290] Iteration 5500 (5.2215 iter/s, 19.1516s/100 iter), loss = 0.106772
I0630 19:59:16.932250  5429 solver.cpp:309]     Train net output #0: loss = 0.106772 (* 1 = 0.106772 loss)
I0630 19:59:16.932257  5429 sgd_solver.cpp:106] Iteration 5500, lr = 0.0001
I0630 19:59:36.160895  5429 solver.cpp:290] Iteration 5600 (5.20073 iter/s, 19.2281s/100 iter), loss = 0.120108
I0630 19:59:36.166146  5429 solver.cpp:309]     Train net output #0: loss = 0.120108 (* 1 = 0.120108 loss)
I0630 19:59:36.166193  5429 sgd_solver.cpp:106] Iteration 5600, lr = 0.0001
I0630 19:59:55.279652  5429 solver.cpp:290] Iteration 5700 (5.23205 iter/s, 19.113s/100 iter), loss = 0.132335
I0630 19:59:55.279675  5429 solver.cpp:309]     Train net output #0: loss = 0.132335 (* 1 = 0.132335 loss)
I0630 19:59:55.279682  5429 sgd_solver.cpp:106] Iteration 5700, lr = 0.0001
I0630 20:00:14.371248  5429 solver.cpp:290] Iteration 5800 (5.23807 iter/s, 19.091s/100 iter), loss = 0.214675
I0630 20:00:14.371318  5429 solver.cpp:309]     Train net output #0: loss = 0.214675 (* 1 = 0.214675 loss)
I0630 20:00:14.371326  5429 sgd_solver.cpp:106] Iteration 5800, lr = 0.0001
I0630 20:00:33.592474  5429 solver.cpp:290] Iteration 5900 (5.20275 iter/s, 19.2206s/100 iter), loss = 0.239315
I0630 20:00:33.592499  5429 solver.cpp:309]     Train net output #0: loss = 0.239315 (* 1 = 0.239315 loss)
I0630 20:00:33.592507  5429 sgd_solver.cpp:106] Iteration 5900, lr = 0.0001
I0630 20:00:52.384157  5429 solver.cpp:471] Iteration 6000, Testing net (#0)
I0630 20:02:27.948573  5429 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.92355
I0630 20:02:27.948674  5429 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.993404
I0630 20:02:27.948683  5429 solver.cpp:544]     Test net output #2: loss = 0.152629 (* 1 = 0.152629 loss)
I0630 20:02:28.162382  5429 solver.cpp:290] Iteration 6000 (0.872854 iter/s, 114.567s/100 iter), loss = 0.12572
I0630 20:02:28.162411  5429 solver.cpp:309]     Train net output #0: loss = 0.12572 (* 1 = 0.12572 loss)
I0630 20:02:28.162418  5429 sgd_solver.cpp:106] Iteration 6000, lr = 0.0001
I0630 20:04:16.850893  5429 solver.cpp:290] Iteration 6100 (0.920086 iter/s, 108.686s/100 iter), loss = 0.172857
I0630 20:04:16.850946  5429 solver.cpp:309]     Train net output #0: loss = 0.172857 (* 1 = 0.172857 loss)
I0630 20:04:16.850955  5429 sgd_solver.cpp:106] Iteration 6100, lr = 0.0001
I0630 20:04:52.937256  5660 blocking_queue.cpp:50] Waiting for data
I0630 20:05:31.799526  5713 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 20:08:45.353124  5429 solver.cpp:290] Iteration 6200 (0.372446 iter/s, 268.495s/100 iter), loss = 0.151617
I0630 20:08:45.353197  5429 solver.cpp:309]     Train net output #0: loss = 0.151617 (* 1 = 0.151617 loss)
I0630 20:08:45.353205  5429 sgd_solver.cpp:106] Iteration 6200, lr = 0.0001
I0630 20:08:48.563202  5694 blocking_queue.cpp:50] Waiting for data
I0630 20:11:31.809408  5429 solver.cpp:290] Iteration 6300 (0.600774 iter/s, 166.452s/100 iter), loss = 0.124393
I0630 20:11:31.809509  5429 solver.cpp:309]     Train net output #0: loss = 0.124393 (* 1 = 0.124393 loss)
I0630 20:11:31.809516  5429 sgd_solver.cpp:106] Iteration 6300, lr = 0.0001
I0630 20:11:50.913897  5429 solver.cpp:290] Iteration 6400 (5.23453 iter/s, 19.1039s/100 iter), loss = 0.150577
I0630 20:11:50.913921  5429 solver.cpp:309]     Train net output #0: loss = 0.150577 (* 1 = 0.150577 loss)
I0630 20:11:50.913928  5429 sgd_solver.cpp:106] Iteration 6400, lr = 0.0001
I0630 20:12:09.800011  5429 solver.cpp:290] Iteration 6500 (5.29504 iter/s, 18.8856s/100 iter), loss = 0.218773
I0630 20:12:09.800081  5429 solver.cpp:309]     Train net output #0: loss = 0.218773 (* 1 = 0.218773 loss)
I0630 20:12:09.800091  5429 sgd_solver.cpp:106] Iteration 6500, lr = 0.0001
I0630 20:12:28.852404  5429 solver.cpp:290] Iteration 6600 (5.24884 iter/s, 19.0518s/100 iter), loss = 0.129673
I0630 20:12:28.852427  5429 solver.cpp:309]     Train net output #0: loss = 0.129673 (* 1 = 0.129673 loss)
I0630 20:12:28.852434  5429 sgd_solver.cpp:106] Iteration 6600, lr = 0.0001
I0630 20:12:47.901103  5429 solver.cpp:290] Iteration 6700 (5.24984 iter/s, 19.0482s/100 iter), loss = 0.0755845
I0630 20:12:47.901206  5429 solver.cpp:309]     Train net output #0: loss = 0.0755844 (* 1 = 0.0755844 loss)
I0630 20:12:47.901216  5429 sgd_solver.cpp:106] Iteration 6700, lr = 0.0001
I0630 20:13:07.012439  5429 solver.cpp:290] Iteration 6800 (5.23267 iter/s, 19.1107s/100 iter), loss = 0.130629
I0630 20:13:07.012460  5429 solver.cpp:309]     Train net output #0: loss = 0.130629 (* 1 = 0.130629 loss)
I0630 20:13:07.012467  5429 sgd_solver.cpp:106] Iteration 6800, lr = 0.0001
I0630 20:13:26.521286  5429 solver.cpp:290] Iteration 6900 (5.12604 iter/s, 19.5082s/100 iter), loss = 0.0725434
I0630 20:13:26.521332  5429 solver.cpp:309]     Train net output #0: loss = 0.0725432 (* 1 = 0.0725432 loss)
I0630 20:13:26.521339  5429 sgd_solver.cpp:106] Iteration 6900, lr = 0.0001
I0630 20:13:45.387913  5429 solver.cpp:290] Iteration 7000 (5.30054 iter/s, 18.866s/100 iter), loss = 0.115313
I0630 20:13:45.387936  5429 solver.cpp:309]     Train net output #0: loss = 0.115313 (* 1 = 0.115313 loss)
I0630 20:13:45.387944  5429 sgd_solver.cpp:106] Iteration 7000, lr = 0.0001
I0630 20:14:04.546496  5429 solver.cpp:290] Iteration 7100 (5.21974 iter/s, 19.158s/100 iter), loss = 0.122775
I0630 20:14:04.546572  5429 solver.cpp:309]     Train net output #0: loss = 0.122775 (* 1 = 0.122775 loss)
I0630 20:14:04.546581  5429 sgd_solver.cpp:106] Iteration 7100, lr = 0.0001
I0630 20:14:23.509938  5429 solver.cpp:290] Iteration 7200 (5.27347 iter/s, 18.9628s/100 iter), loss = 0.160498
I0630 20:14:23.509963  5429 solver.cpp:309]     Train net output #0: loss = 0.160498 (* 1 = 0.160498 loss)
I0630 20:14:23.509970  5429 sgd_solver.cpp:106] Iteration 7200, lr = 0.0001
I0630 20:14:42.599973  5429 solver.cpp:290] Iteration 7300 (5.23849 iter/s, 19.0895s/100 iter), loss = 0.126562
I0630 20:14:42.600028  5429 solver.cpp:309]     Train net output #0: loss = 0.126562 (* 1 = 0.126562 loss)
I0630 20:14:42.600036  5429 sgd_solver.cpp:106] Iteration 7300, lr = 0.0001
I0630 20:15:01.669277  5429 solver.cpp:290] Iteration 7400 (5.24419 iter/s, 19.0687s/100 iter), loss = 0.196361
I0630 20:15:01.669299  5429 solver.cpp:309]     Train net output #0: loss = 0.196361 (* 1 = 0.196361 loss)
I0630 20:15:01.669306  5429 sgd_solver.cpp:106] Iteration 7400, lr = 0.0001
I0630 20:15:20.713816  5429 solver.cpp:290] Iteration 7500 (5.251 iter/s, 19.044s/100 iter), loss = 0.15232
I0630 20:15:20.713856  5429 solver.cpp:309]     Train net output #0: loss = 0.15232 (* 1 = 0.15232 loss)
I0630 20:15:20.713865  5429 sgd_solver.cpp:106] Iteration 7500, lr = 0.0001
I0630 20:15:39.804003  5429 solver.cpp:290] Iteration 7600 (5.23845 iter/s, 19.0896s/100 iter), loss = 0.100301
I0630 20:15:39.804028  5429 solver.cpp:309]     Train net output #0: loss = 0.100301 (* 1 = 0.100301 loss)
I0630 20:15:39.804034  5429 sgd_solver.cpp:106] Iteration 7600, lr = 0.0001
I0630 20:15:58.828616  5429 solver.cpp:290] Iteration 7700 (5.2565 iter/s, 19.0241s/100 iter), loss = 0.0969102
I0630 20:15:58.828670  5429 solver.cpp:309]     Train net output #0: loss = 0.09691 (* 1 = 0.09691 loss)
I0630 20:15:58.828681  5429 sgd_solver.cpp:106] Iteration 7700, lr = 0.0001
I0630 20:16:18.065829  5429 solver.cpp:290] Iteration 7800 (5.19842 iter/s, 19.2366s/100 iter), loss = 0.128974
I0630 20:16:18.065851  5429 solver.cpp:309]     Train net output #0: loss = 0.128974 (* 1 = 0.128974 loss)
I0630 20:16:18.065858  5429 sgd_solver.cpp:106] Iteration 7800, lr = 0.0001
I0630 20:16:37.170838  5429 solver.cpp:290] Iteration 7900 (5.23438 iter/s, 19.1045s/100 iter), loss = 0.119556
I0630 20:16:37.170910  5429 solver.cpp:309]     Train net output #0: loss = 0.119555 (* 1 = 0.119555 loss)
I0630 20:16:37.170918  5429 sgd_solver.cpp:106] Iteration 7900, lr = 0.0001
I0630 20:16:56.079802  5429 solver.cpp:471] Iteration 8000, Testing net (#0)
I0630 20:18:30.923048  5429 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.926498
I0630 20:18:30.923143  5429 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.994144
I0630 20:18:30.923151  5429 solver.cpp:544]     Test net output #2: loss = 0.142364 (* 1 = 0.142364 loss)
I0630 20:18:31.140166  5429 solver.cpp:290] Iteration 8000 (0.877451 iter/s, 113.966s/100 iter), loss = 0.108447
I0630 20:18:31.140189  5429 solver.cpp:309]     Train net output #0: loss = 0.108447 (* 1 = 0.108447 loss)
I0630 20:18:31.140197  5429 sgd_solver.cpp:106] Iteration 8000, lr = 0.0001
I0630 20:18:49.472411  5429 solver.cpp:290] Iteration 8100 (5.45501 iter/s, 18.3318s/100 iter), loss = 0.152832
I0630 20:18:49.472434  5429 solver.cpp:309]     Train net output #0: loss = 0.152832 (* 1 = 0.152832 loss)
I0630 20:18:49.472441  5429 sgd_solver.cpp:106] Iteration 8100, lr = 0.0001
I0630 20:20:47.969199  5660 blocking_queue.cpp:50] Waiting for data
I0630 20:21:56.343435  5429 solver.cpp:290] Iteration 8200 (0.535142 iter/s, 186.866s/100 iter), loss = 0.1286
I0630 20:21:56.343538  5429 solver.cpp:309]     Train net output #0: loss = 0.1286 (* 1 = 0.1286 loss)
I0630 20:21:56.343547  5429 sgd_solver.cpp:106] Iteration 8200, lr = 0.0001
I0630 20:22:17.855624  5429 solver.cpp:290] Iteration 8300 (4.64867 iter/s, 21.5115s/100 iter), loss = 0.0948518
I0630 20:22:17.855653  5429 solver.cpp:309]     Train net output #0: loss = 0.0948516 (* 1 = 0.0948516 loss)
I0630 20:22:17.855662  5429 sgd_solver.cpp:106] Iteration 8300, lr = 0.0001
I0630 20:22:37.157785  5429 solver.cpp:290] Iteration 8400 (5.1809 iter/s, 19.3016s/100 iter), loss = 0.0844778
I0630 20:22:37.157869  5429 solver.cpp:309]     Train net output #0: loss = 0.0844776 (* 1 = 0.0844776 loss)
I0630 20:22:37.157879  5429 sgd_solver.cpp:106] Iteration 8400, lr = 0.0001
I0630 20:22:56.151300  5429 solver.cpp:290] Iteration 8500 (5.26511 iter/s, 18.993s/100 iter), loss = 0.177681
I0630 20:22:56.151325  5429 solver.cpp:309]     Train net output #0: loss = 0.177681 (* 1 = 0.177681 loss)
I0630 20:22:56.151332  5429 sgd_solver.cpp:106] Iteration 8500, lr = 0.0001
I0630 20:23:14.970640  5429 solver.cpp:290] Iteration 8600 (5.31382 iter/s, 18.8188s/100 iter), loss = 0.120142
I0630 20:23:14.970690  5429 solver.cpp:309]     Train net output #0: loss = 0.120142 (* 1 = 0.120142 loss)
I0630 20:23:14.970696  5429 sgd_solver.cpp:106] Iteration 8600, lr = 0.0001
I0630 20:23:33.931332  5429 solver.cpp:290] Iteration 8700 (5.27421 iter/s, 18.9602s/100 iter), loss = 0.165305
I0630 20:23:33.931357  5429 solver.cpp:309]     Train net output #0: loss = 0.165305 (* 1 = 0.165305 loss)
I0630 20:23:33.931365  5429 sgd_solver.cpp:106] Iteration 8700, lr = 0.0001
I0630 20:23:53.176887  5429 solver.cpp:290] Iteration 8800 (5.19614 iter/s, 19.245s/100 iter), loss = 0.106414
I0630 20:23:53.176975  5429 solver.cpp:309]     Train net output #0: loss = 0.106413 (* 1 = 0.106413 loss)
I0630 20:23:53.176986  5429 sgd_solver.cpp:106] Iteration 8800, lr = 0.0001
I0630 20:24:12.155138  5429 solver.cpp:290] Iteration 8900 (5.26935 iter/s, 18.9777s/100 iter), loss = 0.112602
I0630 20:24:12.155159  5429 solver.cpp:309]     Train net output #0: loss = 0.112602 (* 1 = 0.112602 loss)
I0630 20:24:12.155166  5429 sgd_solver.cpp:106] Iteration 8900, lr = 0.0001
I0630 20:24:31.106016  5429 solver.cpp:290] Iteration 9000 (5.27694 iter/s, 18.9504s/100 iter), loss = 0.104817
I0630 20:24:31.106096  5429 solver.cpp:309]     Train net output #0: loss = 0.104816 (* 1 = 0.104816 loss)
I0630 20:24:31.106106  5429 sgd_solver.cpp:106] Iteration 9000, lr = 0.0001
I0630 20:24:50.151245  5429 solver.cpp:290] Iteration 9100 (5.25081 iter/s, 19.0447s/100 iter), loss = 0.213925
I0630 20:24:50.151266  5429 solver.cpp:309]     Train net output #0: loss = 0.213925 (* 1 = 0.213925 loss)
I0630 20:24:50.151274  5429 sgd_solver.cpp:106] Iteration 9100, lr = 0.0001
I0630 20:25:09.061745  5429 solver.cpp:290] Iteration 9200 (5.28821 iter/s, 18.91s/100 iter), loss = 0.103541
I0630 20:25:09.061811  5429 solver.cpp:309]     Train net output #0: loss = 0.10354 (* 1 = 0.10354 loss)
I0630 20:25:09.061820  5429 sgd_solver.cpp:106] Iteration 9200, lr = 0.0001
I0630 20:25:28.333459  5429 solver.cpp:290] Iteration 9300 (5.1891 iter/s, 19.2712s/100 iter), loss = 0.196834
I0630 20:25:28.333482  5429 solver.cpp:309]     Train net output #0: loss = 0.196834 (* 1 = 0.196834 loss)
I0630 20:25:28.333489  5429 sgd_solver.cpp:106] Iteration 9300, lr = 0.0001
I0630 20:25:47.385866  5429 solver.cpp:290] Iteration 9400 (5.24882 iter/s, 19.0519s/100 iter), loss = 0.228286
I0630 20:25:47.385962  5429 solver.cpp:309]     Train net output #0: loss = 0.228286 (* 1 = 0.228286 loss)
I0630 20:25:47.385973  5429 sgd_solver.cpp:106] Iteration 9400, lr = 0.0001
I0630 20:26:06.563931  5429 solver.cpp:290] Iteration 9500 (5.21445 iter/s, 19.1775s/100 iter), loss = 0.123546
I0630 20:26:06.563958  5429 solver.cpp:309]     Train net output #0: loss = 0.123546 (* 1 = 0.123546 loss)
I0630 20:26:06.563967  5429 sgd_solver.cpp:106] Iteration 9500, lr = 0.0001
I0630 20:26:25.786288  5429 solver.cpp:290] Iteration 9600 (5.20241 iter/s, 19.2218s/100 iter), loss = 0.105034
I0630 20:26:25.786418  5429 solver.cpp:309]     Train net output #0: loss = 0.105033 (* 1 = 0.105033 loss)
I0630 20:26:25.786429  5429 sgd_solver.cpp:106] Iteration 9600, lr = 0.0001
I0630 20:26:44.746600  5429 solver.cpp:290] Iteration 9700 (5.27434 iter/s, 18.9597s/100 iter), loss = 0.108437
I0630 20:26:44.746624  5429 solver.cpp:309]     Train net output #0: loss = 0.108437 (* 1 = 0.108437 loss)
I0630 20:26:44.746631  5429 sgd_solver.cpp:106] Iteration 9700, lr = 0.0001
I0630 20:27:03.814149  5429 solver.cpp:290] Iteration 9800 (5.24465 iter/s, 19.0671s/100 iter), loss = 0.0694628
I0630 20:27:03.814230  5429 solver.cpp:309]     Train net output #0: loss = 0.0694625 (* 1 = 0.0694625 loss)
I0630 20:27:03.814241  5429 sgd_solver.cpp:106] Iteration 9800, lr = 0.0001
I0630 20:27:22.975335  5429 solver.cpp:290] Iteration 9900 (5.21904 iter/s, 19.1606s/100 iter), loss = 0.207476
I0630 20:27:22.975361  5429 solver.cpp:309]     Train net output #0: loss = 0.207476 (* 1 = 0.207476 loss)
I0630 20:27:22.975369  5429 sgd_solver.cpp:106] Iteration 9900, lr = 0.0001
I0630 20:27:41.927918  5429 solver.cpp:598] Snapshotting to binary proto file training/cityscapes20_jsegnet21v2_2017-06-30_19-26-17/initial/cityscapes20_jsegnet21v2_iter_10000.caffemodel
I0630 20:27:42.034955  5429 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/cityscapes20_jsegnet21v2_2017-06-30_19-26-17/initial/cityscapes20_jsegnet21v2_iter_10000.solverstate
I0630 20:27:42.085322  5429 solver.cpp:471] Iteration 10000, Testing net (#0)
I0630 20:29:15.119088  5429 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.92671
I0630 20:29:15.119163  5429 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.994139
I0630 20:29:15.119173  5429 solver.cpp:544]     Test net output #2: loss = 0.143588 (* 1 = 0.143588 loss)
I0630 20:29:15.334506  5429 solver.cpp:290] Iteration 10000 (0.890025 iter/s, 112.356s/100 iter), loss = 0.0817711
I0630 20:29:15.334533  5429 solver.cpp:309]     Train net output #0: loss = 0.0817707 (* 1 = 0.0817707 loss)
I0630 20:29:15.334542  5429 sgd_solver.cpp:106] Iteration 10000, lr = 0.0001
I0630 20:30:09.410066  5518 blocking_queue.cpp:50] Waiting for data
I0630 20:30:40.497797  5429 solver.cpp:290] Iteration 10100 (1.17424 iter/s, 85.1612s/100 iter), loss = 0.130447
I0630 20:30:40.497843  5429 solver.cpp:309]     Train net output #0: loss = 0.130447 (* 1 = 0.130447 loss)
I0630 20:30:40.497854  5429 sgd_solver.cpp:106] Iteration 10100, lr = 0.0001
I0630 20:33:45.526274  5695 blocking_queue.cpp:50] Waiting for data
I0630 20:33:49.623913  5429 solver.cpp:290] Iteration 10200 (0.528761 iter/s, 189.121s/100 iter), loss = 0.104663
I0630 20:33:49.623935  5429 solver.cpp:309]     Train net output #0: loss = 0.104662 (* 1 = 0.104662 loss)
I0630 20:33:49.623942  5429 sgd_solver.cpp:106] Iteration 10200, lr = 0.0001
I0630 20:34:12.797773  5429 solver.cpp:290] Iteration 10300 (4.31532 iter/s, 23.1733s/100 iter), loss = 0.150428
I0630 20:34:12.797796  5429 solver.cpp:309]     Train net output #0: loss = 0.150427 (* 1 = 0.150427 loss)
I0630 20:34:12.797802  5429 sgd_solver.cpp:106] Iteration 10300, lr = 0.0001
I0630 20:34:31.853058  5429 solver.cpp:290] Iteration 10400 (5.24803 iter/s, 19.0548s/100 iter), loss = 0.121831
I0630 20:34:31.853123  5429 solver.cpp:309]     Train net output #0: loss = 0.121831 (* 1 = 0.121831 loss)
I0630 20:34:31.853133  5429 sgd_solver.cpp:106] Iteration 10400, lr = 0.0001
I0630 20:34:51.055763  5429 solver.cpp:290] Iteration 10500 (5.20775 iter/s, 19.2022s/100 iter), loss = 0.0907077
I0630 20:34:51.055789  5429 solver.cpp:309]     Train net output #0: loss = 0.0907074 (* 1 = 0.0907074 loss)
I0630 20:34:51.055799  5429 sgd_solver.cpp:106] Iteration 10500, lr = 0.0001
I0630 20:35:10.151765  5429 solver.cpp:290] Iteration 10600 (5.23684 iter/s, 19.0955s/100 iter), loss = 0.0915265
I0630 20:35:10.151818  5429 solver.cpp:309]     Train net output #0: loss = 0.0915262 (* 1 = 0.0915262 loss)
I0630 20:35:10.151829  5429 sgd_solver.cpp:106] Iteration 10600, lr = 0.0001
I0630 20:35:29.367455  5429 solver.cpp:290] Iteration 10700 (5.20422 iter/s, 19.2152s/100 iter), loss = 0.163533
I0630 20:35:29.367480  5429 solver.cpp:309]     Train net output #0: loss = 0.163532 (* 1 = 0.163532 loss)
I0630 20:35:29.367486  5429 sgd_solver.cpp:106] Iteration 10700, lr = 0.0001
I0630 20:35:48.569056  5429 solver.cpp:290] Iteration 10800 (5.20804 iter/s, 19.2011s/100 iter), loss = 0.0563943
I0630 20:35:48.569186  5429 solver.cpp:309]     Train net output #0: loss = 0.0563939 (* 1 = 0.0563939 loss)
I0630 20:35:48.569195  5429 sgd_solver.cpp:106] Iteration 10800, lr = 0.0001
I0630 20:36:07.903909  5429 solver.cpp:290] Iteration 10900 (5.17217 iter/s, 19.3342s/100 iter), loss = 0.137538
I0630 20:36:07.903934  5429 solver.cpp:309]     Train net output #0: loss = 0.137538 (* 1 = 0.137538 loss)
I0630 20:36:07.903944  5429 sgd_solver.cpp:106] Iteration 10900, lr = 0.0001
I0630 20:36:27.142815  5429 solver.cpp:290] Iteration 11000 (5.19794 iter/s, 19.2384s/100 iter), loss = 0.103417
I0630 20:36:27.142874  5429 solver.cpp:309]     Train net output #0: loss = 0.103417 (* 1 = 0.103417 loss)
I0630 20:36:27.142881  5429 sgd_solver.cpp:106] Iteration 11000, lr = 0.0001
I0630 20:36:46.333997  5429 solver.cpp:290] Iteration 11100 (5.21087 iter/s, 19.1906s/100 iter), loss = 0.120189
I0630 20:36:46.334022  5429 solver.cpp:309]     Train net output #0: loss = 0.120188 (* 1 = 0.120188 loss)
I0630 20:36:46.334029  5429 sgd_solver.cpp:106] Iteration 11100, lr = 0.0001
I0630 20:37:05.494940  5429 solver.cpp:290] Iteration 11200 (5.21909 iter/s, 19.1604s/100 iter), loss = 0.0960929
I0630 20:37:05.494992  5429 solver.cpp:309]     Train net output #0: loss = 0.0960925 (* 1 = 0.0960925 loss)
I0630 20:37:05.495005  5429 sgd_solver.cpp:106] Iteration 11200, lr = 0.0001
I0630 20:37:24.635135  5429 solver.cpp:290] Iteration 11300 (5.22475 iter/s, 19.1397s/100 iter), loss = 0.0716244
I0630 20:37:24.635157  5429 solver.cpp:309]     Train net output #0: loss = 0.071624 (* 1 = 0.071624 loss)
I0630 20:37:24.635164  5429 sgd_solver.cpp:106] Iteration 11300, lr = 0.0001
I0630 20:37:43.648597  5429 solver.cpp:290] Iteration 11400 (5.25957 iter/s, 19.013s/100 iter), loss = 0.0828364
I0630 20:37:43.648641  5429 solver.cpp:309]     Train net output #0: loss = 0.082836 (* 1 = 0.082836 loss)
I0630 20:37:43.648651  5429 sgd_solver.cpp:106] Iteration 11400, lr = 0.0001
I0630 20:38:02.804214  5429 solver.cpp:290] Iteration 11500 (5.22054 iter/s, 19.1551s/100 iter), loss = 0.077565
I0630 20:38:02.804239  5429 solver.cpp:309]     Train net output #0: loss = 0.0775646 (* 1 = 0.0775646 loss)
I0630 20:38:02.804245  5429 sgd_solver.cpp:106] Iteration 11500, lr = 0.0001
I0630 20:38:22.098858  5429 solver.cpp:290] Iteration 11600 (5.18292 iter/s, 19.2941s/100 iter), loss = 0.0622331
I0630 20:38:22.098938  5429 solver.cpp:309]     Train net output #0: loss = 0.0622327 (* 1 = 0.0622327 loss)
I0630 20:38:22.098951  5429 sgd_solver.cpp:106] Iteration 11600, lr = 0.0001
I0630 20:38:41.193608  5429 solver.cpp:290] Iteration 11700 (5.23719 iter/s, 19.0942s/100 iter), loss = 0.140836
I0630 20:38:41.193630  5429 solver.cpp:309]     Train net output #0: loss = 0.140835 (* 1 = 0.140835 loss)
I0630 20:38:41.193639  5429 sgd_solver.cpp:106] Iteration 11700, lr = 0.0001
I0630 20:39:00.499003  5429 solver.cpp:290] Iteration 11800 (5.18003 iter/s, 19.3049s/100 iter), loss = 0.08539
I0630 20:39:00.499104  5429 solver.cpp:309]     Train net output #0: loss = 0.0853896 (* 1 = 0.0853896 loss)
I0630 20:39:00.499115  5429 sgd_solver.cpp:106] Iteration 11800, lr = 0.0001
I0630 20:39:19.411805  5429 solver.cpp:290] Iteration 11900 (5.28758 iter/s, 18.9122s/100 iter), loss = 0.136616
I0630 20:39:19.411829  5429 solver.cpp:309]     Train net output #0: loss = 0.136615 (* 1 = 0.136615 loss)
I0630 20:39:19.411836  5429 sgd_solver.cpp:106] Iteration 11900, lr = 0.0001
I0630 20:39:38.245220  5429 solver.cpp:471] Iteration 12000, Testing net (#0)
I0630 20:41:14.245569  5429 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.928017
I0630 20:41:14.245683  5429 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.993707
I0630 20:41:14.245692  5429 solver.cpp:544]     Test net output #2: loss = 0.147323 (* 1 = 0.147323 loss)
I0630 20:41:14.472506  5429 solver.cpp:290] Iteration 12000 (0.869128 iter/s, 115.058s/100 iter), loss = 0.0837495
I0630 20:41:14.472528  5429 solver.cpp:309]     Train net output #0: loss = 0.0837492 (* 1 = 0.0837492 loss)
I0630 20:41:14.472537  5429 sgd_solver.cpp:106] Iteration 12000, lr = 0.0001
I0630 20:42:15.729230  5713 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 20:42:38.739426  5429 solver.cpp:290] Iteration 12100 (1.18673 iter/s, 84.2648s/100 iter), loss = 0.0901462
I0630 20:42:38.739451  5429 solver.cpp:309]     Train net output #0: loss = 0.0901458 (* 1 = 0.0901458 loss)
I0630 20:42:38.739459  5429 sgd_solver.cpp:106] Iteration 12100, lr = 0.0001
I0630 20:42:44.696269  5518 blocking_queue.cpp:50] Waiting for data
I0630 20:43:44.759868  5429 solver.cpp:290] Iteration 12200 (1.51472 iter/s, 66.0188s/100 iter), loss = 0.0899194
I0630 20:43:44.759917  5429 solver.cpp:309]     Train net output #0: loss = 0.089919 (* 1 = 0.089919 loss)
I0630 20:43:44.759924  5429 sgd_solver.cpp:106] Iteration 12200, lr = 0.0001
I0630 20:43:45.033756  5695 blocking_queue.cpp:50] Waiting for data
I0630 20:44:03.931874  5429 solver.cpp:290] Iteration 12300 (5.21608 iter/s, 19.1715s/100 iter), loss = 0.0900487
I0630 20:44:03.931895  5429 solver.cpp:309]     Train net output #0: loss = 0.0900484 (* 1 = 0.0900484 loss)
I0630 20:44:03.931903  5429 sgd_solver.cpp:106] Iteration 12300, lr = 0.0001
I0630 20:44:23.014855  5429 solver.cpp:290] Iteration 12400 (5.24041 iter/s, 19.0825s/100 iter), loss = 0.0795638
I0630 20:44:23.014925  5429 solver.cpp:309]     Train net output #0: loss = 0.0795635 (* 1 = 0.0795635 loss)
I0630 20:44:23.014932  5429 sgd_solver.cpp:106] Iteration 12400, lr = 0.0001
I0630 20:44:42.166259  5429 solver.cpp:290] Iteration 12500 (5.2217 iter/s, 19.1509s/100 iter), loss = 0.075455
I0630 20:44:42.166281  5429 solver.cpp:309]     Train net output #0: loss = 0.0754546 (* 1 = 0.0754546 loss)
I0630 20:44:42.166288  5429 sgd_solver.cpp:106] Iteration 12500, lr = 0.0001
I0630 20:45:01.236198  5429 solver.cpp:290] Iteration 12600 (5.24399 iter/s, 19.0694s/100 iter), loss = 0.0879664
I0630 20:45:01.236275  5429 solver.cpp:309]     Train net output #0: loss = 0.087966 (* 1 = 0.087966 loss)
I0630 20:45:01.236284  5429 sgd_solver.cpp:106] Iteration 12600, lr = 0.0001
I0630 20:45:20.340623  5429 solver.cpp:290] Iteration 12700 (5.23454 iter/s, 19.1039s/100 iter), loss = 0.100452
I0630 20:45:20.340649  5429 solver.cpp:309]     Train net output #0: loss = 0.100452 (* 1 = 0.100452 loss)
I0630 20:45:20.340658  5429 sgd_solver.cpp:106] Iteration 12700, lr = 0.0001
I0630 20:45:39.450958  5429 solver.cpp:290] Iteration 12800 (5.23291 iter/s, 19.1098s/100 iter), loss = 0.0786972
I0630 20:45:39.451040  5429 solver.cpp:309]     Train net output #0: loss = 0.0786969 (* 1 = 0.0786969 loss)
I0630 20:45:39.451050  5429 sgd_solver.cpp:106] Iteration 12800, lr = 0.0001
I0630 20:45:58.474997  5429 solver.cpp:290] Iteration 12900 (5.25666 iter/s, 19.0235s/100 iter), loss = 0.0620362
I0630 20:45:58.475019  5429 solver.cpp:309]     Train net output #0: loss = 0.0620358 (* 1 = 0.0620358 loss)
I0630 20:45:58.475026  5429 sgd_solver.cpp:106] Iteration 12900, lr = 0.0001
I0630 20:46:17.674113  5429 solver.cpp:290] Iteration 13000 (5.20871 iter/s, 19.1986s/100 iter), loss = 0.0829186
I0630 20:46:17.674186  5429 solver.cpp:309]     Train net output #0: loss = 0.0829183 (* 1 = 0.0829183 loss)
I0630 20:46:17.674195  5429 sgd_solver.cpp:106] Iteration 13000, lr = 0.0001
I0630 20:46:36.858489  5429 solver.cpp:290] Iteration 13100 (5.21272 iter/s, 19.1838s/100 iter), loss = 0.105977
I0630 20:46:36.858515  5429 solver.cpp:309]     Train net output #0: loss = 0.105977 (* 1 = 0.105977 loss)
I0630 20:46:36.858522  5429 sgd_solver.cpp:106] Iteration 13100, lr = 0.0001
I0630 20:46:56.089915  5429 solver.cpp:290] Iteration 13200 (5.19996 iter/s, 19.2309s/100 iter), loss = 0.0800845
I0630 20:46:56.089984  5429 solver.cpp:309]     Train net output #0: loss = 0.0800842 (* 1 = 0.0800842 loss)
I0630 20:46:56.089993  5429 sgd_solver.cpp:106] Iteration 13200, lr = 0.0001
I0630 20:47:15.072578  5429 solver.cpp:290] Iteration 13300 (5.26811 iter/s, 18.9821s/100 iter), loss = 0.0749383
I0630 20:47:15.072607  5429 solver.cpp:309]     Train net output #0: loss = 0.074938 (* 1 = 0.074938 loss)
I0630 20:47:15.072616  5429 sgd_solver.cpp:106] Iteration 13300, lr = 0.0001
I0630 20:47:34.029614  5429 solver.cpp:290] Iteration 13400 (5.27523 iter/s, 18.9565s/100 iter), loss = 0.0610113
I0630 20:47:34.029703  5429 solver.cpp:309]     Train net output #0: loss = 0.061011 (* 1 = 0.061011 loss)
I0630 20:47:34.029713  5429 sgd_solver.cpp:106] Iteration 13400, lr = 0.0001
I0630 20:47:53.073302  5429 solver.cpp:290] Iteration 13500 (5.25126 iter/s, 19.043s/100 iter), loss = 0.128607
I0630 20:47:53.073324  5429 solver.cpp:309]     Train net output #0: loss = 0.128607 (* 1 = 0.128607 loss)
I0630 20:47:53.073331  5429 sgd_solver.cpp:106] Iteration 13500, lr = 0.0001
I0630 20:48:12.078768  5429 solver.cpp:290] Iteration 13600 (5.2618 iter/s, 19.0049s/100 iter), loss = 0.0888473
I0630 20:48:12.078855  5429 solver.cpp:309]     Train net output #0: loss = 0.088847 (* 1 = 0.088847 loss)
I0630 20:48:12.078866  5429 sgd_solver.cpp:106] Iteration 13600, lr = 0.0001
I0630 20:48:31.069595  5429 solver.cpp:290] Iteration 13700 (5.26588 iter/s, 18.9902s/100 iter), loss = 0.0791066
I0630 20:48:31.069617  5429 solver.cpp:309]     Train net output #0: loss = 0.0791063 (* 1 = 0.0791063 loss)
I0630 20:48:31.069624  5429 sgd_solver.cpp:106] Iteration 13700, lr = 0.0001
I0630 20:48:50.340338  5429 solver.cpp:290] Iteration 13800 (5.18937 iter/s, 19.2702s/100 iter), loss = 0.115439
I0630 20:48:50.340387  5429 solver.cpp:309]     Train net output #0: loss = 0.115438 (* 1 = 0.115438 loss)
I0630 20:48:50.340395  5429 sgd_solver.cpp:106] Iteration 13800, lr = 0.0001
I0630 20:49:09.529795  5429 solver.cpp:290] Iteration 13900 (5.21136 iter/s, 19.1889s/100 iter), loss = 0.0785274
I0630 20:49:09.529819  5429 solver.cpp:309]     Train net output #0: loss = 0.0785272 (* 1 = 0.0785272 loss)
I0630 20:49:09.529824  5429 sgd_solver.cpp:106] Iteration 13900, lr = 0.0001
I0630 20:49:28.434123  5429 solver.cpp:471] Iteration 14000, Testing net (#0)
I0630 20:51:02.683445  5429 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.925848
I0630 20:51:02.683535  5429 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.993884
I0630 20:51:02.683542  5429 solver.cpp:544]     Test net output #2: loss = 0.142218 (* 1 = 0.142218 loss)
I0630 20:51:02.897466  5429 solver.cpp:290] Iteration 14000 (0.882111 iter/s, 113.364s/100 iter), loss = 0.0795643
I0630 20:51:02.897490  5429 solver.cpp:309]     Train net output #0: loss = 0.0795641 (* 1 = 0.0795641 loss)
I0630 20:51:02.897496  5429 sgd_solver.cpp:106] Iteration 14000, lr = 0.0001
I0630 20:51:21.053231  5429 solver.cpp:290] Iteration 14100 (5.50806 iter/s, 18.1552s/100 iter), loss = 0.187062
I0630 20:51:21.053254  5429 solver.cpp:309]     Train net output #0: loss = 0.187061 (* 1 = 0.187061 loss)
I0630 20:51:21.053261  5429 sgd_solver.cpp:106] Iteration 14100, lr = 0.0001
I0630 20:51:40.207504  5429 solver.cpp:290] Iteration 14200 (5.22092 iter/s, 19.1537s/100 iter), loss = 0.0575425
I0630 20:51:40.207574  5429 solver.cpp:309]     Train net output #0: loss = 0.0575423 (* 1 = 0.0575423 loss)
I0630 20:51:40.207586  5429 sgd_solver.cpp:106] Iteration 14200, lr = 0.0001
I0630 20:51:59.225464  5429 solver.cpp:290] Iteration 14300 (5.25836 iter/s, 19.0173s/100 iter), loss = 0.076787
I0630 20:51:59.225491  5429 solver.cpp:309]     Train net output #0: loss = 0.0767867 (* 1 = 0.0767867 loss)
I0630 20:51:59.225498  5429 sgd_solver.cpp:106] Iteration 14300, lr = 0.0001
I0630 20:52:18.398134  5429 solver.cpp:290] Iteration 14400 (5.21591 iter/s, 19.1721s/100 iter), loss = 0.0840433
I0630 20:52:18.398172  5429 solver.cpp:309]     Train net output #0: loss = 0.084043 (* 1 = 0.084043 loss)
I0630 20:52:18.398180  5429 sgd_solver.cpp:106] Iteration 14400, lr = 0.0001
I0630 20:52:37.572451  5429 solver.cpp:290] Iteration 14500 (5.21547 iter/s, 19.1737s/100 iter), loss = 0.152902
I0630 20:52:37.572474  5429 solver.cpp:309]     Train net output #0: loss = 0.152902 (* 1 = 0.152902 loss)
I0630 20:52:37.572480  5429 sgd_solver.cpp:106] Iteration 14500, lr = 0.0001
I0630 20:52:56.826803  5429 solver.cpp:290] Iteration 14600 (5.19378 iter/s, 19.2538s/100 iter), loss = 0.0803616
I0630 20:52:56.826870  5429 solver.cpp:309]     Train net output #0: loss = 0.0803613 (* 1 = 0.0803613 loss)
I0630 20:52:56.826879  5429 sgd_solver.cpp:106] Iteration 14600, lr = 0.0001
I0630 20:53:15.985292  5429 solver.cpp:290] Iteration 14700 (5.21978 iter/s, 19.1579s/100 iter), loss = 0.121181
I0630 20:53:15.985319  5429 solver.cpp:309]     Train net output #0: loss = 0.12118 (* 1 = 0.12118 loss)
I0630 20:53:15.985328  5429 sgd_solver.cpp:106] Iteration 14700, lr = 0.0001
I0630 20:53:34.983680  5429 solver.cpp:290] Iteration 14800 (5.26376 iter/s, 18.9978s/100 iter), loss = 0.0718724
I0630 20:53:34.983757  5429 solver.cpp:309]     Train net output #0: loss = 0.0718721 (* 1 = 0.0718721 loss)
I0630 20:53:34.983765  5429 sgd_solver.cpp:106] Iteration 14800, lr = 0.0001
I0630 20:53:54.089440  5429 solver.cpp:290] Iteration 14900 (5.23419 iter/s, 19.1051s/100 iter), loss = 0.23514
I0630 20:53:54.089462  5429 solver.cpp:309]     Train net output #0: loss = 0.23514 (* 1 = 0.23514 loss)
I0630 20:53:54.089469  5429 sgd_solver.cpp:106] Iteration 14900, lr = 0.0001
I0630 20:54:13.060606  5429 solver.cpp:290] Iteration 15000 (5.27131 iter/s, 18.9706s/100 iter), loss = 0.118394
I0630 20:54:13.060678  5429 solver.cpp:309]     Train net output #0: loss = 0.118394 (* 1 = 0.118394 loss)
I0630 20:54:13.060684  5429 sgd_solver.cpp:106] Iteration 15000, lr = 0.0001
I0630 20:54:32.271957  5429 solver.cpp:290] Iteration 15100 (5.20542 iter/s, 19.2107s/100 iter), loss = 0.139644
I0630 20:54:32.271982  5429 solver.cpp:309]     Train net output #0: loss = 0.139643 (* 1 = 0.139643 loss)
I0630 20:54:32.271991  5429 sgd_solver.cpp:106] Iteration 15100, lr = 0.0001
I0630 20:54:51.467821  5429 solver.cpp:290] Iteration 15200 (5.20961 iter/s, 19.1953s/100 iter), loss = 0.0825212
I0630 20:54:51.467895  5429 solver.cpp:309]     Train net output #0: loss = 0.0825208 (* 1 = 0.0825208 loss)
I0630 20:54:51.467902  5429 sgd_solver.cpp:106] Iteration 15200, lr = 0.0001
I0630 20:55:10.351411  5429 solver.cpp:290] Iteration 15300 (5.29577 iter/s, 18.883s/100 iter), loss = 0.0775852
I0630 20:55:10.351433  5429 solver.cpp:309]     Train net output #0: loss = 0.0775849 (* 1 = 0.0775849 loss)
I0630 20:55:10.351440  5429 sgd_solver.cpp:106] Iteration 15300, lr = 0.0001
I0630 20:55:29.521488  5429 solver.cpp:290] Iteration 15400 (5.21661 iter/s, 19.1695s/100 iter), loss = 0.0655288
I0630 20:55:29.521561  5429 solver.cpp:309]     Train net output #0: loss = 0.0655284 (* 1 = 0.0655284 loss)
I0630 20:55:29.521569  5429 sgd_solver.cpp:106] Iteration 15400, lr = 0.0001
I0630 20:55:48.514051  5429 solver.cpp:290] Iteration 15500 (5.26539 iter/s, 18.992s/100 iter), loss = 0.0769465
I0630 20:55:48.514073  5429 solver.cpp:309]     Train net output #0: loss = 0.0769461 (* 1 = 0.0769461 loss)
I0630 20:55:48.514081  5429 sgd_solver.cpp:106] Iteration 15500, lr = 0.0001
I0630 20:56:07.773617  5429 solver.cpp:290] Iteration 15600 (5.19238 iter/s, 19.259s/100 iter), loss = 0.077483
I0630 20:56:07.773694  5429 solver.cpp:309]     Train net output #0: loss = 0.0774827 (* 1 = 0.0774827 loss)
I0630 20:56:07.773705  5429 sgd_solver.cpp:106] Iteration 15600, lr = 0.0001
I0630 20:56:26.952617  5429 solver.cpp:290] Iteration 15700 (5.2142 iter/s, 19.1784s/100 iter), loss = 0.115442
I0630 20:56:26.952641  5429 solver.cpp:309]     Train net output #0: loss = 0.115441 (* 1 = 0.115441 loss)
I0630 20:56:26.952651  5429 sgd_solver.cpp:106] Iteration 15700, lr = 0.0001
I0630 20:56:46.195767  5429 solver.cpp:290] Iteration 15800 (5.1968 iter/s, 19.2426s/100 iter), loss = 0.0870652
I0630 20:56:46.195828  5429 solver.cpp:309]     Train net output #0: loss = 0.0870648 (* 1 = 0.0870648 loss)
I0630 20:56:46.195837  5429 sgd_solver.cpp:106] Iteration 15800, lr = 0.0001
I0630 20:57:05.261376  5429 solver.cpp:290] Iteration 15900 (5.24521 iter/s, 19.065s/100 iter), loss = 0.11519
I0630 20:57:05.261399  5429 solver.cpp:309]     Train net output #0: loss = 0.115189 (* 1 = 0.115189 loss)
I0630 20:57:05.261406  5429 sgd_solver.cpp:106] Iteration 15900, lr = 0.0001
I0630 20:57:24.333019  5429 solver.cpp:471] Iteration 16000, Testing net (#0)
I0630 20:58:58.069967  5429 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.930884
I0630 20:58:58.070143  5429 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.994987
I0630 20:58:58.070153  5429 solver.cpp:544]     Test net output #2: loss = 0.140637 (* 1 = 0.140637 loss)
I0630 20:58:58.296066  5429 solver.cpp:290] Iteration 16000 (0.884708 iter/s, 113.032s/100 iter), loss = 0.0831568
I0630 20:58:58.296089  5429 solver.cpp:309]     Train net output #0: loss = 0.0831564 (* 1 = 0.0831564 loss)
I0630 20:58:58.296097  5429 sgd_solver.cpp:106] Iteration 16000, lr = 0.0001
I0630 20:59:16.499593  5429 solver.cpp:290] Iteration 16100 (5.4936 iter/s, 18.203s/100 iter), loss = 0.0666988
I0630 20:59:16.499620  5429 solver.cpp:309]     Train net output #0: loss = 0.0666984 (* 1 = 0.0666984 loss)
I0630 20:59:16.499629  5429 sgd_solver.cpp:106] Iteration 16100, lr = 0.0001
I0630 20:59:35.614058  5429 solver.cpp:290] Iteration 16200 (5.23179 iter/s, 19.1139s/100 iter), loss = 0.0957872
I0630 20:59:35.614146  5429 solver.cpp:309]     Train net output #0: loss = 0.0957868 (* 1 = 0.0957868 loss)
I0630 20:59:35.614157  5429 sgd_solver.cpp:106] Iteration 16200, lr = 0.0001
I0630 20:59:54.612365  5429 solver.cpp:290] Iteration 16300 (5.2638 iter/s, 18.9977s/100 iter), loss = 0.0568139
I0630 20:59:54.612388  5429 solver.cpp:309]     Train net output #0: loss = 0.0568135 (* 1 = 0.0568135 loss)
I0630 20:59:54.612396  5429 sgd_solver.cpp:106] Iteration 16300, lr = 0.0001
I0630 21:00:13.884780  5429 solver.cpp:290] Iteration 16400 (5.18891 iter/s, 19.2719s/100 iter), loss = 0.0974117
I0630 21:00:13.884824  5429 solver.cpp:309]     Train net output #0: loss = 0.0974113 (* 1 = 0.0974113 loss)
I0630 21:00:13.884831  5429 sgd_solver.cpp:106] Iteration 16400, lr = 0.0001
I0630 21:00:33.085340  5429 solver.cpp:290] Iteration 16500 (5.20834 iter/s, 19.2s/100 iter), loss = 0.062476
I0630 21:00:33.085367  5429 solver.cpp:309]     Train net output #0: loss = 0.0624756 (* 1 = 0.0624756 loss)
I0630 21:00:33.085381  5429 sgd_solver.cpp:106] Iteration 16500, lr = 0.0001
I0630 21:00:52.149189  5429 solver.cpp:290] Iteration 16600 (5.24568 iter/s, 19.0633s/100 iter), loss = 0.0704622
I0630 21:00:52.149245  5429 solver.cpp:309]     Train net output #0: loss = 0.0704618 (* 1 = 0.0704618 loss)
I0630 21:00:52.149256  5429 sgd_solver.cpp:106] Iteration 16600, lr = 0.0001
I0630 21:01:11.479930  5429 solver.cpp:290] Iteration 16700 (5.17327 iter/s, 19.3301s/100 iter), loss = 0.0618501
I0630 21:01:11.479954  5429 solver.cpp:309]     Train net output #0: loss = 0.0618497 (* 1 = 0.0618497 loss)
I0630 21:01:11.479960  5429 sgd_solver.cpp:106] Iteration 16700, lr = 0.0001
I0630 21:01:30.542083  5429 solver.cpp:290] Iteration 16800 (5.24615 iter/s, 19.0616s/100 iter), loss = 0.129682
I0630 21:01:30.542193  5429 solver.cpp:309]     Train net output #0: loss = 0.129681 (* 1 = 0.129681 loss)
I0630 21:01:30.542203  5429 sgd_solver.cpp:106] Iteration 16800, lr = 0.0001
I0630 21:01:49.660769  5429 solver.cpp:290] Iteration 16900 (5.23066 iter/s, 19.118s/100 iter), loss = 0.0983927
I0630 21:01:49.660794  5429 solver.cpp:309]     Train net output #0: loss = 0.0983923 (* 1 = 0.0983923 loss)
I0630 21:01:49.660804  5429 sgd_solver.cpp:106] Iteration 16900, lr = 0.0001
I0630 21:02:09.013010  5429 solver.cpp:290] Iteration 17000 (5.16751 iter/s, 19.3517s/100 iter), loss = 0.0746811
I0630 21:02:09.013058  5429 solver.cpp:309]     Train net output #0: loss = 0.0746806 (* 1 = 0.0746806 loss)
I0630 21:02:09.013067  5429 sgd_solver.cpp:106] Iteration 17000, lr = 0.0001
I0630 21:02:28.166365  5429 solver.cpp:290] Iteration 17100 (5.22118 iter/s, 19.1528s/100 iter), loss = 0.0867968
I0630 21:02:28.166393  5429 solver.cpp:309]     Train net output #0: loss = 0.0867964 (* 1 = 0.0867964 loss)
I0630 21:02:28.166401  5429 sgd_solver.cpp:106] Iteration 17100, lr = 0.0001
I0630 21:02:47.265058  5429 solver.cpp:290] Iteration 17200 (5.23612 iter/s, 19.0981s/100 iter), loss = 0.0828645
I0630 21:02:47.265178  5429 solver.cpp:309]     Train net output #0: loss = 0.0828641 (* 1 = 0.0828641 loss)
I0630 21:02:47.265188  5429 sgd_solver.cpp:106] Iteration 17200, lr = 0.0001
I0630 21:03:06.266162  5429 solver.cpp:290] Iteration 17300 (5.26303 iter/s, 19.0005s/100 iter), loss = 0.0727931
I0630 21:03:06.266186  5429 solver.cpp:309]     Train net output #0: loss = 0.0727927 (* 1 = 0.0727927 loss)
I0630 21:03:06.266192  5429 sgd_solver.cpp:106] Iteration 17300, lr = 0.0001
I0630 21:03:25.307121  5429 solver.cpp:290] Iteration 17400 (5.25199 iter/s, 19.0404s/100 iter), loss = 0.0825397
I0630 21:03:25.307173  5429 solver.cpp:309]     Train net output #0: loss = 0.0825393 (* 1 = 0.0825393 loss)
I0630 21:03:25.307179  5429 sgd_solver.cpp:106] Iteration 17400, lr = 0.0001
I0630 21:03:44.537261  5429 solver.cpp:290] Iteration 17500 (5.20033 iter/s, 19.2295s/100 iter), loss = 0.0647001
I0630 21:03:44.537286  5429 solver.cpp:309]     Train net output #0: loss = 0.0646997 (* 1 = 0.0646997 loss)
I0630 21:03:44.537295  5429 sgd_solver.cpp:106] Iteration 17500, lr = 0.0001
I0630 21:04:03.771637  5429 solver.cpp:290] Iteration 17600 (5.19918 iter/s, 19.2338s/100 iter), loss = 0.0904891
I0630 21:04:03.772135  5429 solver.cpp:309]     Train net output #0: loss = 0.0904887 (* 1 = 0.0904887 loss)
I0630 21:04:03.772145  5429 sgd_solver.cpp:106] Iteration 17600, lr = 0.0001
I0630 21:04:22.804414  5429 solver.cpp:290] Iteration 17700 (5.25438 iter/s, 19.0317s/100 iter), loss = 0.138211
I0630 21:04:22.804438  5429 solver.cpp:309]     Train net output #0: loss = 0.138211 (* 1 = 0.138211 loss)
I0630 21:04:22.804447  5429 sgd_solver.cpp:106] Iteration 17700, lr = 0.0001
I0630 21:04:41.811810  5429 solver.cpp:290] Iteration 17800 (5.26126 iter/s, 19.0068s/100 iter), loss = 0.0687797
I0630 21:04:41.811863  5429 solver.cpp:309]     Train net output #0: loss = 0.0687793 (* 1 = 0.0687793 loss)
I0630 21:04:41.811870  5429 sgd_solver.cpp:106] Iteration 17800, lr = 0.0001
I0630 21:05:00.857939  5429 solver.cpp:290] Iteration 17900 (5.25057 iter/s, 19.0455s/100 iter), loss = 0.117813
I0630 21:05:00.857964  5429 solver.cpp:309]     Train net output #0: loss = 0.117813 (* 1 = 0.117813 loss)
I0630 21:05:00.857971  5429 sgd_solver.cpp:106] Iteration 17900, lr = 0.0001
I0630 21:05:19.872777  5429 solver.cpp:471] Iteration 18000, Testing net (#0)
I0630 21:06:53.585321  5429 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.93318
I0630 21:06:53.585400  5429 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.994845
I0630 21:06:53.585407  5429 solver.cpp:544]     Test net output #2: loss = 0.14004 (* 1 = 0.14004 loss)
I0630 21:06:53.802940  5429 solver.cpp:290] Iteration 18000 (0.885411 iter/s, 112.942s/100 iter), loss = 0.0896128
I0630 21:06:53.802964  5429 solver.cpp:309]     Train net output #0: loss = 0.0896124 (* 1 = 0.0896124 loss)
I0630 21:06:53.802970  5429 sgd_solver.cpp:106] Iteration 18000, lr = 0.0001
I0630 21:07:12.217141  5429 solver.cpp:290] Iteration 18100 (5.43075 iter/s, 18.4137s/100 iter), loss = 0.102937
I0630 21:07:12.217164  5429 solver.cpp:309]     Train net output #0: loss = 0.102936 (* 1 = 0.102936 loss)
I0630 21:07:12.217170  5429 sgd_solver.cpp:106] Iteration 18100, lr = 0.0001
I0630 21:07:31.352336  5429 solver.cpp:290] Iteration 18200 (5.22612 iter/s, 19.1346s/100 iter), loss = 0.069806
I0630 21:07:31.352445  5429 solver.cpp:309]     Train net output #0: loss = 0.0698056 (* 1 = 0.0698056 loss)
I0630 21:07:31.352455  5429 sgd_solver.cpp:106] Iteration 18200, lr = 0.0001
I0630 21:07:50.477869  5429 solver.cpp:290] Iteration 18300 (5.22879 iter/s, 19.1249s/100 iter), loss = 0.120183
I0630 21:07:50.477895  5429 solver.cpp:309]     Train net output #0: loss = 0.120183 (* 1 = 0.120183 loss)
I0630 21:07:50.477903  5429 sgd_solver.cpp:106] Iteration 18300, lr = 0.0001
I0630 21:08:09.492986  5429 solver.cpp:290] Iteration 18400 (5.25913 iter/s, 19.0146s/100 iter), loss = 0.157442
I0630 21:08:09.493082  5429 solver.cpp:309]     Train net output #0: loss = 0.157442 (* 1 = 0.157442 loss)
I0630 21:08:09.493090  5429 sgd_solver.cpp:106] Iteration 18400, lr = 0.0001
I0630 21:08:28.493546  5429 solver.cpp:290] Iteration 18500 (5.26318 iter/s, 18.9999s/100 iter), loss = 0.113923
I0630 21:08:28.493571  5429 solver.cpp:309]     Train net output #0: loss = 0.113922 (* 1 = 0.113922 loss)
I0630 21:08:28.493577  5429 sgd_solver.cpp:106] Iteration 18500, lr = 0.0001
I0630 21:08:47.395836  5429 solver.cpp:290] Iteration 18600 (5.29052 iter/s, 18.9017s/100 iter), loss = 0.0639297
I0630 21:08:47.395884  5429 solver.cpp:309]     Train net output #0: loss = 0.0639293 (* 1 = 0.0639293 loss)
I0630 21:08:47.395890  5429 sgd_solver.cpp:106] Iteration 18600, lr = 0.0001
I0630 21:09:06.519739  5429 solver.cpp:290] Iteration 18700 (5.22922 iter/s, 19.1233s/100 iter), loss = 0.109442
I0630 21:09:06.519762  5429 solver.cpp:309]     Train net output #0: loss = 0.109441 (* 1 = 0.109441 loss)
I0630 21:09:06.519768  5429 sgd_solver.cpp:106] Iteration 18700, lr = 0.0001
I0630 21:09:25.594880  5429 solver.cpp:290] Iteration 18800 (5.24258 iter/s, 19.0746s/100 iter), loss = 0.0801012
I0630 21:09:25.594936  5429 solver.cpp:309]     Train net output #0: loss = 0.0801008 (* 1 = 0.0801008 loss)
I0630 21:09:25.594944  5429 sgd_solver.cpp:106] Iteration 18800, lr = 0.0001
I0630 21:09:44.899235  5429 solver.cpp:290] Iteration 18900 (5.18034 iter/s, 19.3038s/100 iter), loss = 0.0820159
I0630 21:09:44.899260  5429 solver.cpp:309]     Train net output #0: loss = 0.0820155 (* 1 = 0.0820155 loss)
I0630 21:09:44.899267  5429 sgd_solver.cpp:106] Iteration 18900, lr = 0.0001
I0630 21:10:04.061269  5429 solver.cpp:290] Iteration 19000 (5.2188 iter/s, 19.1615s/100 iter), loss = 0.0876166
I0630 21:10:04.061321  5429 solver.cpp:309]     Train net output #0: loss = 0.0876162 (* 1 = 0.0876162 loss)
I0630 21:10:04.061328  5429 sgd_solver.cpp:106] Iteration 19000, lr = 0.0001
I0630 21:10:23.184610  5429 solver.cpp:290] Iteration 19100 (5.22937 iter/s, 19.1228s/100 iter), loss = 0.150419
I0630 21:10:23.184638  5429 solver.cpp:309]     Train net output #0: loss = 0.150418 (* 1 = 0.150418 loss)
I0630 21:10:23.184646  5429 sgd_solver.cpp:106] Iteration 19100, lr = 0.0001
I0630 21:10:42.244637  5429 solver.cpp:290] Iteration 19200 (5.24673 iter/s, 19.0595s/100 iter), loss = 0.0602512
I0630 21:10:42.244711  5429 solver.cpp:309]     Train net output #0: loss = 0.0602508 (* 1 = 0.0602508 loss)
I0630 21:10:42.244721  5429 sgd_solver.cpp:106] Iteration 19200, lr = 0.0001
I0630 21:11:01.597455  5429 solver.cpp:290] Iteration 19300 (5.16737 iter/s, 19.3522s/100 iter), loss = 0.126578
I0630 21:11:01.597479  5429 solver.cpp:309]     Train net output #0: loss = 0.126578 (* 1 = 0.126578 loss)
I0630 21:11:01.597486  5429 sgd_solver.cpp:106] Iteration 19300, lr = 0.0001
I0630 21:11:20.657999  5429 solver.cpp:290] Iteration 19400 (5.24659 iter/s, 19.06s/100 iter), loss = 0.102573
I0630 21:11:20.658046  5429 solver.cpp:309]     Train net output #0: loss = 0.102573 (* 1 = 0.102573 loss)
I0630 21:11:20.658053  5429 sgd_solver.cpp:106] Iteration 19400, lr = 0.0001
I0630 21:11:39.646646  5429 solver.cpp:290] Iteration 19500 (5.26646 iter/s, 18.9881s/100 iter), loss = 0.0783299
I0630 21:11:39.646672  5429 solver.cpp:309]     Train net output #0: loss = 0.0783295 (* 1 = 0.0783295 loss)
I0630 21:11:39.646682  5429 sgd_solver.cpp:106] Iteration 19500, lr = 0.0001
I0630 21:11:58.867343  5429 solver.cpp:290] Iteration 19600 (5.20288 iter/s, 19.2201s/100 iter), loss = 0.0756822
I0630 21:11:58.867403  5429 solver.cpp:309]     Train net output #0: loss = 0.0756818 (* 1 = 0.0756818 loss)
I0630 21:11:58.867413  5429 sgd_solver.cpp:106] Iteration 19600, lr = 0.0001
I0630 21:12:18.058748  5429 solver.cpp:290] Iteration 19700 (5.21082 iter/s, 19.1908s/100 iter), loss = 0.0587753
I0630 21:12:18.058769  5429 solver.cpp:309]     Train net output #0: loss = 0.0587749 (* 1 = 0.0587749 loss)
I0630 21:12:18.058776  5429 sgd_solver.cpp:106] Iteration 19700, lr = 0.0001
I0630 21:12:37.201058  5429 solver.cpp:290] Iteration 19800 (5.22418 iter/s, 19.1418s/100 iter), loss = 0.0797299
I0630 21:12:37.201129  5429 solver.cpp:309]     Train net output #0: loss = 0.0797296 (* 1 = 0.0797296 loss)
I0630 21:12:37.201138  5429 sgd_solver.cpp:106] Iteration 19800, lr = 0.0001
I0630 21:12:56.321316  5429 solver.cpp:290] Iteration 19900 (5.23022 iter/s, 19.1197s/100 iter), loss = 0.0787919
I0630 21:12:56.321342  5429 solver.cpp:309]     Train net output #0: loss = 0.0787915 (* 1 = 0.0787915 loss)
I0630 21:12:56.321349  5429 sgd_solver.cpp:106] Iteration 19900, lr = 0.0001
I0630 21:13:15.275111  5429 solver.cpp:598] Snapshotting to binary proto file training/cityscapes20_jsegnet21v2_2017-06-30_19-26-17/initial/cityscapes20_jsegnet21v2_iter_20000.caffemodel
I0630 21:13:15.348865  5429 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/cityscapes20_jsegnet21v2_2017-06-30_19-26-17/initial/cityscapes20_jsegnet21v2_iter_20000.solverstate
I0630 21:13:15.369601  5429 solver.cpp:471] Iteration 20000, Testing net (#0)
I0630 21:14:48.981520  5429 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.932703
I0630 21:14:48.981600  5429 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.994701
I0630 21:14:48.981607  5429 solver.cpp:544]     Test net output #2: loss = 0.149304 (* 1 = 0.149304 loss)
I0630 21:14:49.193789  5429 solver.cpp:290] Iteration 20000 (0.88598 iter/s, 112.869s/100 iter), loss = 0.0781226
I0630 21:14:49.193815  5429 solver.cpp:309]     Train net output #0: loss = 0.0781222 (* 1 = 0.0781222 loss)
I0630 21:14:49.193825  5429 sgd_solver.cpp:106] Iteration 20000, lr = 0.0001
I0630 21:15:07.475752  5429 solver.cpp:290] Iteration 20100 (5.47003 iter/s, 18.2814s/100 iter), loss = 0.0698583
I0630 21:15:07.475778  5429 solver.cpp:309]     Train net output #0: loss = 0.0698579 (* 1 = 0.0698579 loss)
I0630 21:15:07.475785  5429 sgd_solver.cpp:106] Iteration 20100, lr = 0.0001
I0630 21:15:26.398960  5429 solver.cpp:290] Iteration 20200 (5.28467 iter/s, 18.9227s/100 iter), loss = 0.179333
I0630 21:15:26.399065  5429 solver.cpp:309]     Train net output #0: loss = 0.179333 (* 1 = 0.179333 loss)
I0630 21:15:26.399075  5429 sgd_solver.cpp:106] Iteration 20200, lr = 0.0001
I0630 21:15:45.440526  5429 solver.cpp:290] Iteration 20300 (5.25184 iter/s, 19.0409s/100 iter), loss = 0.0599853
I0630 21:15:45.440551  5429 solver.cpp:309]     Train net output #0: loss = 0.0599849 (* 1 = 0.0599849 loss)
I0630 21:15:45.440558  5429 sgd_solver.cpp:106] Iteration 20300, lr = 0.0001
I0630 21:16:04.718083  5429 solver.cpp:290] Iteration 20400 (5.18753 iter/s, 19.277s/100 iter), loss = 0.097101
I0630 21:16:04.718178  5429 solver.cpp:309]     Train net output #0: loss = 0.0971006 (* 1 = 0.0971006 loss)
I0630 21:16:04.718189  5429 sgd_solver.cpp:106] Iteration 20400, lr = 0.0001
I0630 21:16:23.705878  5429 solver.cpp:290] Iteration 20500 (5.26671 iter/s, 18.9872s/100 iter), loss = 0.0565909
I0630 21:16:23.705900  5429 solver.cpp:309]     Train net output #0: loss = 0.0565905 (* 1 = 0.0565905 loss)
I0630 21:16:23.705906  5429 sgd_solver.cpp:106] Iteration 20500, lr = 0.0001
I0630 21:16:43.021759  5429 solver.cpp:290] Iteration 20600 (5.17724 iter/s, 19.3153s/100 iter), loss = 0.101787
I0630 21:16:43.021811  5429 solver.cpp:309]     Train net output #0: loss = 0.101786 (* 1 = 0.101786 loss)
I0630 21:16:43.021821  5429 sgd_solver.cpp:106] Iteration 20600, lr = 0.0001
I0630 21:17:02.294733  5429 solver.cpp:290] Iteration 20700 (5.18877 iter/s, 19.2724s/100 iter), loss = 0.0896704
I0630 21:17:02.294759  5429 solver.cpp:309]     Train net output #0: loss = 0.08967 (* 1 = 0.08967 loss)
I0630 21:17:02.294767  5429 sgd_solver.cpp:106] Iteration 20700, lr = 0.0001
I0630 21:17:21.297395  5429 solver.cpp:290] Iteration 20800 (5.26257 iter/s, 19.0021s/100 iter), loss = 0.0852597
I0630 21:17:21.297459  5429 solver.cpp:309]     Train net output #0: loss = 0.0852593 (* 1 = 0.0852593 loss)
I0630 21:17:21.297467  5429 sgd_solver.cpp:106] Iteration 20800, lr = 0.0001
I0630 21:17:40.347623  5429 solver.cpp:290] Iteration 20900 (5.24944 iter/s, 19.0496s/100 iter), loss = 0.094642
I0630 21:17:40.347654  5429 solver.cpp:309]     Train net output #0: loss = 0.0946415 (* 1 = 0.0946415 loss)
I0630 21:17:40.347662  5429 sgd_solver.cpp:106] Iteration 20900, lr = 0.0001
I0630 21:17:59.483633  5429 solver.cpp:290] Iteration 21000 (5.2259 iter/s, 19.1355s/100 iter), loss = 0.132687
I0630 21:17:59.483687  5429 solver.cpp:309]     Train net output #0: loss = 0.132687 (* 1 = 0.132687 loss)
I0630 21:17:59.483695  5429 sgd_solver.cpp:106] Iteration 21000, lr = 0.0001
I0630 21:18:18.596251  5429 solver.cpp:290] Iteration 21100 (5.2323 iter/s, 19.112s/100 iter), loss = 0.118779
I0630 21:18:18.596274  5429 solver.cpp:309]     Train net output #0: loss = 0.118779 (* 1 = 0.118779 loss)
I0630 21:18:18.596283  5429 sgd_solver.cpp:106] Iteration 21100, lr = 0.0001
I0630 21:18:37.696333  5429 solver.cpp:290] Iteration 21200 (5.23573 iter/s, 19.0995s/100 iter), loss = 0.0883315
I0630 21:18:37.696441  5429 solver.cpp:309]     Train net output #0: loss = 0.088331 (* 1 = 0.088331 loss)
I0630 21:18:37.696451  5429 sgd_solver.cpp:106] Iteration 21200, lr = 0.0001
I0630 21:18:56.822224  5429 solver.cpp:290] Iteration 21300 (5.22869 iter/s, 19.1253s/100 iter), loss = 0.147963
I0630 21:18:56.822248  5429 solver.cpp:309]     Train net output #0: loss = 0.147963 (* 1 = 0.147963 loss)
I0630 21:18:56.822255  5429 sgd_solver.cpp:106] Iteration 21300, lr = 0.0001
I0630 21:19:16.109280  5429 solver.cpp:290] Iteration 21400 (5.18497 iter/s, 19.2865s/100 iter), loss = 0.107209
I0630 21:19:16.109354  5429 solver.cpp:309]     Train net output #0: loss = 0.107208 (* 1 = 0.107208 loss)
I0630 21:19:16.109362  5429 sgd_solver.cpp:106] Iteration 21400, lr = 0.0001
I0630 21:19:35.346940  5429 solver.cpp:290] Iteration 21500 (5.1983 iter/s, 19.2371s/100 iter), loss = 0.0778426
I0630 21:19:35.346963  5429 solver.cpp:309]     Train net output #0: loss = 0.0778422 (* 1 = 0.0778422 loss)
I0630 21:19:35.346971  5429 sgd_solver.cpp:106] Iteration 21500, lr = 0.0001
I0630 21:19:54.730202  5429 solver.cpp:290] Iteration 21600 (5.15924 iter/s, 19.3827s/100 iter), loss = 0.198641
I0630 21:19:54.730239  5429 solver.cpp:309]     Train net output #0: loss = 0.198641 (* 1 = 0.198641 loss)
I0630 21:19:54.730247  5429 sgd_solver.cpp:106] Iteration 21600, lr = 0.0001
I0630 21:20:13.804250  5429 solver.cpp:290] Iteration 21700 (5.24288 iter/s, 19.0735s/100 iter), loss = 0.0623842
I0630 21:20:13.804273  5429 solver.cpp:309]     Train net output #0: loss = 0.0623837 (* 1 = 0.0623837 loss)
I0630 21:20:13.804280  5429 sgd_solver.cpp:106] Iteration 21700, lr = 0.0001
I0630 21:20:32.937218  5429 solver.cpp:290] Iteration 21800 (5.22673 iter/s, 19.1324s/100 iter), loss = 0.0758716
I0630 21:20:32.937263  5429 solver.cpp:309]     Train net output #0: loss = 0.0758711 (* 1 = 0.0758711 loss)
I0630 21:20:32.937269  5429 sgd_solver.cpp:106] Iteration 21800, lr = 0.0001
I0630 21:20:52.078413  5429 solver.cpp:290] Iteration 21900 (5.22449 iter/s, 19.1406s/100 iter), loss = 0.031482
I0630 21:20:52.078480  5429 solver.cpp:309]     Train net output #0: loss = 0.0314815 (* 1 = 0.0314815 loss)
I0630 21:20:52.078505  5429 sgd_solver.cpp:106] Iteration 21900, lr = 0.0001
I0630 21:21:11.211187  5429 solver.cpp:471] Iteration 22000, Testing net (#0)
I0630 21:22:43.969454  5429 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.934486
I0630 21:22:43.969540  5429 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.994916
I0630 21:22:43.969549  5429 solver.cpp:544]     Test net output #2: loss = 0.14391 (* 1 = 0.14391 loss)
I0630 21:22:44.198990  5429 solver.cpp:290] Iteration 22000 (0.891921 iter/s, 112.118s/100 iter), loss = 0.0850116
I0630 21:22:44.199014  5429 solver.cpp:309]     Train net output #0: loss = 0.0850111 (* 1 = 0.0850111 loss)
I0630 21:22:44.199021  5429 sgd_solver.cpp:106] Iteration 22000, lr = 0.0001
I0630 21:23:02.602097  5429 solver.cpp:290] Iteration 22100 (5.43402 iter/s, 18.4026s/100 iter), loss = 0.088284
I0630 21:23:02.602123  5429 solver.cpp:309]     Train net output #0: loss = 0.0882835 (* 1 = 0.0882835 loss)
I0630 21:23:02.602131  5429 sgd_solver.cpp:106] Iteration 22100, lr = 0.0001
I0630 21:23:21.764163  5429 solver.cpp:290] Iteration 22200 (5.21879 iter/s, 19.1615s/100 iter), loss = 0.0859445
I0630 21:23:21.764225  5429 solver.cpp:309]     Train net output #0: loss = 0.085944 (* 1 = 0.085944 loss)
I0630 21:23:21.764233  5429 sgd_solver.cpp:106] Iteration 22200, lr = 0.0001
I0630 21:23:40.897013  5429 solver.cpp:290] Iteration 22300 (5.22677 iter/s, 19.1323s/100 iter), loss = 0.0884386
I0630 21:23:40.897035  5429 solver.cpp:309]     Train net output #0: loss = 0.0884381 (* 1 = 0.0884381 loss)
I0630 21:23:40.897042  5429 sgd_solver.cpp:106] Iteration 22300, lr = 0.0001
I0630 21:24:00.162318  5429 solver.cpp:290] Iteration 22400 (5.19082 iter/s, 19.2648s/100 iter), loss = 0.0822707
I0630 21:24:00.162410  5429 solver.cpp:309]     Train net output #0: loss = 0.0822702 (* 1 = 0.0822702 loss)
I0630 21:24:00.162420  5429 sgd_solver.cpp:106] Iteration 22400, lr = 0.0001
I0630 21:24:19.301054  5429 solver.cpp:290] Iteration 22500 (5.22517 iter/s, 19.1381s/100 iter), loss = 0.0628854
I0630 21:24:19.301076  5429 solver.cpp:309]     Train net output #0: loss = 0.0628849 (* 1 = 0.0628849 loss)
I0630 21:24:19.301084  5429 sgd_solver.cpp:106] Iteration 22500, lr = 0.0001
I0630 21:24:38.417419  5429 solver.cpp:290] Iteration 22600 (5.23127 iter/s, 19.1158s/100 iter), loss = 0.156419
I0630 21:24:38.417487  5429 solver.cpp:309]     Train net output #0: loss = 0.156418 (* 1 = 0.156418 loss)
I0630 21:24:38.417500  5429 sgd_solver.cpp:106] Iteration 22600, lr = 0.0001
I0630 21:24:57.727635  5429 solver.cpp:290] Iteration 22700 (5.17876 iter/s, 19.3096s/100 iter), loss = 0.070628
I0630 21:24:57.727658  5429 solver.cpp:309]     Train net output #0: loss = 0.0706275 (* 1 = 0.0706275 loss)
I0630 21:24:57.727665  5429 sgd_solver.cpp:106] Iteration 22700, lr = 0.0001
I0630 21:25:16.667598  5429 solver.cpp:290] Iteration 22800 (5.27999 iter/s, 18.9394s/100 iter), loss = 0.12594
I0630 21:25:16.667686  5429 solver.cpp:309]     Train net output #0: loss = 0.125939 (* 1 = 0.125939 loss)
I0630 21:25:16.667696  5429 sgd_solver.cpp:106] Iteration 22800, lr = 0.0001
I0630 21:25:35.820523  5429 solver.cpp:290] Iteration 22900 (5.2213 iter/s, 19.1523s/100 iter), loss = 0.0793839
I0630 21:25:35.820545  5429 solver.cpp:309]     Train net output #0: loss = 0.0793835 (* 1 = 0.0793835 loss)
I0630 21:25:35.820551  5429 sgd_solver.cpp:106] Iteration 22900, lr = 0.0001
I0630 21:25:54.925784  5429 solver.cpp:290] Iteration 23000 (5.23431 iter/s, 19.1047s/100 iter), loss = 0.0924845
I0630 21:25:54.925899  5429 solver.cpp:309]     Train net output #0: loss = 0.092484 (* 1 = 0.092484 loss)
I0630 21:25:54.925905  5429 sgd_solver.cpp:106] Iteration 23000, lr = 0.0001
I0630 21:26:14.111289  5429 solver.cpp:290] Iteration 23100 (5.21244 iter/s, 19.1849s/100 iter), loss = 0.0797142
I0630 21:26:14.111315  5429 solver.cpp:309]     Train net output #0: loss = 0.0797138 (* 1 = 0.0797138 loss)
I0630 21:26:14.111321  5429 sgd_solver.cpp:106] Iteration 23100, lr = 0.0001
I0630 21:26:33.278023  5429 solver.cpp:290] Iteration 23200 (5.21752 iter/s, 19.1662s/100 iter), loss = 0.0927219
I0630 21:26:33.278074  5429 solver.cpp:309]     Train net output #0: loss = 0.0927215 (* 1 = 0.0927215 loss)
I0630 21:26:33.278082  5429 sgd_solver.cpp:106] Iteration 23200, lr = 0.0001
I0630 21:26:52.478584  5429 solver.cpp:290] Iteration 23300 (5.20833 iter/s, 19.2s/100 iter), loss = 0.0898942
I0630 21:26:52.478607  5429 solver.cpp:309]     Train net output #0: loss = 0.0898937 (* 1 = 0.0898937 loss)
I0630 21:26:52.478615  5429 sgd_solver.cpp:106] Iteration 23300, lr = 0.0001
I0630 21:27:11.724040  5429 solver.cpp:290] Iteration 23400 (5.19618 iter/s, 19.2449s/100 iter), loss = 0.0598528
I0630 21:27:11.724124  5429 solver.cpp:309]     Train net output #0: loss = 0.0598523 (* 1 = 0.0598523 loss)
I0630 21:27:11.724135  5429 sgd_solver.cpp:106] Iteration 23400, lr = 0.0001
I0630 21:27:30.721218  5429 solver.cpp:290] Iteration 23500 (5.2641 iter/s, 18.9966s/100 iter), loss = 0.105229
I0630 21:27:30.721240  5429 solver.cpp:309]     Train net output #0: loss = 0.105228 (* 1 = 0.105228 loss)
I0630 21:27:30.721247  5429 sgd_solver.cpp:106] Iteration 23500, lr = 0.0001
I0630 21:27:49.690990  5429 solver.cpp:290] Iteration 23600 (5.27169 iter/s, 18.9692s/100 iter), loss = 0.127416
I0630 21:27:49.691036  5429 solver.cpp:309]     Train net output #0: loss = 0.127415 (* 1 = 0.127415 loss)
I0630 21:27:49.691045  5429 sgd_solver.cpp:106] Iteration 23600, lr = 0.0001
I0630 21:28:08.877295  5429 solver.cpp:290] Iteration 23700 (5.2122 iter/s, 19.1857s/100 iter), loss = 0.0560074
I0630 21:28:08.877318  5429 solver.cpp:309]     Train net output #0: loss = 0.0560069 (* 1 = 0.0560069 loss)
I0630 21:28:08.877326  5429 sgd_solver.cpp:106] Iteration 23700, lr = 0.0001
I0630 21:28:27.906369  5429 solver.cpp:290] Iteration 23800 (5.25526 iter/s, 19.0285s/100 iter), loss = 0.0920871
I0630 21:28:27.906443  5429 solver.cpp:309]     Train net output #0: loss = 0.0920866 (* 1 = 0.0920866 loss)
I0630 21:28:27.906451  5429 sgd_solver.cpp:106] Iteration 23800, lr = 0.0001
I0630 21:28:46.934528  5429 solver.cpp:290] Iteration 23900 (5.25553 iter/s, 19.0276s/100 iter), loss = 0.0790047
I0630 21:28:46.934556  5429 solver.cpp:309]     Train net output #0: loss = 0.0790042 (* 1 = 0.0790042 loss)
I0630 21:28:46.934564  5429 sgd_solver.cpp:106] Iteration 23900, lr = 0.0001
I0630 21:29:05.779527  5429 solver.cpp:471] Iteration 24000, Testing net (#0)
I0630 21:30:38.783382  5429 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.934933
I0630 21:30:38.783486  5429 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.995818
I0630 21:30:38.783493  5429 solver.cpp:544]     Test net output #2: loss = 0.12954 (* 1 = 0.12954 loss)
I0630 21:30:38.988459  5429 solver.cpp:290] Iteration 24000 (0.892451 iter/s, 112.051s/100 iter), loss = 0.059087
I0630 21:30:38.988483  5429 solver.cpp:309]     Train net output #0: loss = 0.0590865 (* 1 = 0.0590865 loss)
I0630 21:30:38.988490  5713 sgd_solver.cpp:46] MultiStep Status: Iteration 24000, step = 1
I0630 21:30:38.988494  5712 sgd_solver.cpp:46] MultiStep Status: Iteration 24000, step = 1
I0630 21:30:38.988490  5429 sgd_solver.cpp:46] MultiStep Status: Iteration 24000, step = 1
I0630 21:30:38.988507  5429 sgd_solver.cpp:106] Iteration 24000, lr = 1e-05
I0630 21:30:57.418548  5429 solver.cpp:290] Iteration 24100 (5.42606 iter/s, 18.4296s/100 iter), loss = 0.0799452
I0630 21:30:57.418570  5429 solver.cpp:309]     Train net output #0: loss = 0.0799447 (* 1 = 0.0799447 loss)
I0630 21:30:57.418577  5429 sgd_solver.cpp:106] Iteration 24100, lr = 1e-05
I0630 21:31:16.388422  5429 solver.cpp:290] Iteration 24200 (5.27166 iter/s, 18.9693s/100 iter), loss = 0.0971637
I0630 21:31:16.388496  5429 solver.cpp:309]     Train net output #0: loss = 0.0971632 (* 1 = 0.0971632 loss)
I0630 21:31:16.388505  5429 sgd_solver.cpp:106] Iteration 24200, lr = 1e-05
I0630 21:31:35.417790  5429 solver.cpp:290] Iteration 24300 (5.2552 iter/s, 19.0288s/100 iter), loss = 0.0529078
I0630 21:31:35.417814  5429 solver.cpp:309]     Train net output #0: loss = 0.0529073 (* 1 = 0.0529073 loss)
I0630 21:31:35.417820  5429 sgd_solver.cpp:106] Iteration 24300, lr = 1e-05
I0630 21:31:54.598496  5429 solver.cpp:290] Iteration 24400 (5.21372 iter/s, 19.1802s/100 iter), loss = 0.0726764
I0630 21:31:54.598552  5429 solver.cpp:309]     Train net output #0: loss = 0.0726759 (* 1 = 0.0726759 loss)
I0630 21:31:54.598561  5429 sgd_solver.cpp:106] Iteration 24400, lr = 1e-05
I0630 21:32:13.784790  5429 solver.cpp:290] Iteration 24500 (5.21221 iter/s, 19.1857s/100 iter), loss = 0.0760292
I0630 21:32:13.784812  5429 solver.cpp:309]     Train net output #0: loss = 0.0760287 (* 1 = 0.0760287 loss)
I0630 21:32:13.784819  5429 sgd_solver.cpp:106] Iteration 24500, lr = 1e-05
I0630 21:32:32.828572  5429 solver.cpp:290] Iteration 24600 (5.2512 iter/s, 19.0433s/100 iter), loss = 0.064486
I0630 21:32:32.828639  5429 solver.cpp:309]     Train net output #0: loss = 0.0644855 (* 1 = 0.0644855 loss)
I0630 21:32:32.828646  5429 sgd_solver.cpp:106] Iteration 24600, lr = 1e-05
I0630 21:32:51.693374  5429 solver.cpp:290] Iteration 24700 (5.30104 iter/s, 18.8642s/100 iter), loss = 0.111931
I0630 21:32:51.693397  5429 solver.cpp:309]     Train net output #0: loss = 0.111931 (* 1 = 0.111931 loss)
I0630 21:32:51.693404  5429 sgd_solver.cpp:106] Iteration 24700, lr = 1e-05
I0630 21:33:10.616140  5429 solver.cpp:290] Iteration 24800 (5.28479 iter/s, 18.9222s/100 iter), loss = 0.0375395
I0630 21:33:10.616183  5429 solver.cpp:309]     Train net output #0: loss = 0.037539 (* 1 = 0.037539 loss)
I0630 21:33:10.616189  5429 sgd_solver.cpp:106] Iteration 24800, lr = 1e-05
I0630 21:33:29.892663  5429 solver.cpp:290] Iteration 24900 (5.18781 iter/s, 19.276s/100 iter), loss = 0.0635059
I0630 21:33:29.892688  5429 solver.cpp:309]     Train net output #0: loss = 0.0635054 (* 1 = 0.0635054 loss)
I0630 21:33:29.892695  5429 sgd_solver.cpp:106] Iteration 24900, lr = 1e-05
I0630 21:33:49.280347  5429 solver.cpp:290] Iteration 25000 (5.15806 iter/s, 19.3871s/100 iter), loss = 0.107219
I0630 21:33:49.280412  5429 solver.cpp:309]     Train net output #0: loss = 0.107219 (* 1 = 0.107219 loss)
I0630 21:33:49.280423  5429 sgd_solver.cpp:106] Iteration 25000, lr = 1e-05
I0630 21:34:08.479781  5429 solver.cpp:290] Iteration 25100 (5.20864 iter/s, 19.1989s/100 iter), loss = 0.0658536
I0630 21:34:08.479807  5429 solver.cpp:309]     Train net output #0: loss = 0.0658531 (* 1 = 0.0658531 loss)
I0630 21:34:08.479816  5429 sgd_solver.cpp:106] Iteration 25100, lr = 1e-05
I0630 21:34:27.466636  5429 solver.cpp:290] Iteration 25200 (5.26695 iter/s, 18.9863s/100 iter), loss = 0.0849872
I0630 21:34:27.466694  5429 solver.cpp:309]     Train net output #0: loss = 0.0849866 (* 1 = 0.0849866 loss)
I0630 21:34:27.466702  5429 sgd_solver.cpp:106] Iteration 25200, lr = 1e-05
I0630 21:34:46.510463  5429 solver.cpp:290] Iteration 25300 (5.2512 iter/s, 19.0433s/100 iter), loss = 0.0630214
I0630 21:34:46.510486  5429 solver.cpp:309]     Train net output #0: loss = 0.0630208 (* 1 = 0.0630208 loss)
I0630 21:34:46.510494  5429 sgd_solver.cpp:106] Iteration 25300, lr = 1e-05
I0630 21:35:05.352573  5429 solver.cpp:290] Iteration 25400 (5.30741 iter/s, 18.8416s/100 iter), loss = 0.112971
I0630 21:35:05.352624  5429 solver.cpp:309]     Train net output #0: loss = 0.112971 (* 1 = 0.112971 loss)
I0630 21:35:05.352632  5429 sgd_solver.cpp:106] Iteration 25400, lr = 1e-05
I0630 21:35:24.536056  5429 solver.cpp:290] Iteration 25500 (5.21297 iter/s, 19.1829s/100 iter), loss = 0.100422
I0630 21:35:24.536080  5429 solver.cpp:309]     Train net output #0: loss = 0.100421 (* 1 = 0.100421 loss)
I0630 21:35:24.536087  5429 sgd_solver.cpp:106] Iteration 25500, lr = 1e-05
I0630 21:35:43.528214  5429 solver.cpp:290] Iteration 25600 (5.26548 iter/s, 18.9916s/100 iter), loss = 0.121658
I0630 21:35:43.528259  5429 solver.cpp:309]     Train net output #0: loss = 0.121657 (* 1 = 0.121657 loss)
I0630 21:35:43.528267  5429 sgd_solver.cpp:106] Iteration 25600, lr = 1e-05
I0630 21:36:02.634124  5429 solver.cpp:290] Iteration 25700 (5.23413 iter/s, 19.1054s/100 iter), loss = 0.0723484
I0630 21:36:02.634150  5429 solver.cpp:309]     Train net output #0: loss = 0.0723479 (* 1 = 0.0723479 loss)
I0630 21:36:02.634157  5429 sgd_solver.cpp:106] Iteration 25700, lr = 1e-05
I0630 21:36:21.767534  5429 solver.cpp:290] Iteration 25800 (5.2266 iter/s, 19.1329s/100 iter), loss = 0.0656031
I0630 21:36:21.767576  5429 solver.cpp:309]     Train net output #0: loss = 0.0656026 (* 1 = 0.0656026 loss)
I0630 21:36:21.767585  5429 sgd_solver.cpp:106] Iteration 25800, lr = 1e-05
I0630 21:36:40.761397  5429 solver.cpp:290] Iteration 25900 (5.26502 iter/s, 18.9933s/100 iter), loss = 0.0544191
I0630 21:36:40.761421  5429 solver.cpp:309]     Train net output #0: loss = 0.0544186 (* 1 = 0.0544186 loss)
I0630 21:36:40.761427  5429 sgd_solver.cpp:106] Iteration 25900, lr = 1e-05
I0630 21:36:59.733942  5429 solver.cpp:471] Iteration 26000, Testing net (#0)
I0630 21:38:32.759531  5429 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.93871
I0630 21:38:32.759609  5429 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.995902
I0630 21:38:32.759616  5429 solver.cpp:544]     Test net output #2: loss = 0.127114 (* 1 = 0.127114 loss)
I0630 21:38:32.972810  5429 solver.cpp:290] Iteration 26000 (0.8912 iter/s, 112.208s/100 iter), loss = 0.0745138
I0630 21:38:32.972833  5429 solver.cpp:309]     Train net output #0: loss = 0.0745133 (* 1 = 0.0745133 loss)
I0630 21:38:32.972841  5429 sgd_solver.cpp:106] Iteration 26000, lr = 1e-05
I0630 21:38:51.246098  5429 solver.cpp:290] Iteration 26100 (5.47263 iter/s, 18.2727s/100 iter), loss = 0.0783837
I0630 21:38:51.246124  5429 solver.cpp:309]     Train net output #0: loss = 0.0783832 (* 1 = 0.0783832 loss)
I0630 21:38:51.246132  5429 sgd_solver.cpp:106] Iteration 26100, lr = 1e-05
I0630 21:39:10.389374  5429 solver.cpp:290] Iteration 26200 (5.22392 iter/s, 19.1427s/100 iter), loss = 0.0408745
I0630 21:39:10.389461  5429 solver.cpp:309]     Train net output #0: loss = 0.040874 (* 1 = 0.040874 loss)
I0630 21:39:10.389472  5429 sgd_solver.cpp:106] Iteration 26200, lr = 1e-05
I0630 21:39:29.312986  5429 solver.cpp:290] Iteration 26300 (5.28458 iter/s, 18.923s/100 iter), loss = 0.0651741
I0630 21:39:29.313010  5429 solver.cpp:309]     Train net output #0: loss = 0.0651735 (* 1 = 0.0651735 loss)
I0630 21:39:29.313017  5429 sgd_solver.cpp:106] Iteration 26300, lr = 1e-05
I0630 21:39:48.400732  5429 solver.cpp:290] Iteration 26400 (5.23912 iter/s, 19.0872s/100 iter), loss = 0.0987975
I0630 21:39:48.400810  5429 solver.cpp:309]     Train net output #0: loss = 0.098797 (* 1 = 0.098797 loss)
I0630 21:39:48.400817  5429 sgd_solver.cpp:106] Iteration 26400, lr = 1e-05
I0630 21:40:07.409464  5429 solver.cpp:290] Iteration 26500 (5.26091 iter/s, 19.0081s/100 iter), loss = 0.0632124
I0630 21:40:07.409488  5429 solver.cpp:309]     Train net output #0: loss = 0.0632119 (* 1 = 0.0632119 loss)
I0630 21:40:07.409495  5429 sgd_solver.cpp:106] Iteration 26500, lr = 1e-05
I0630 21:40:26.774796  5429 solver.cpp:290] Iteration 26600 (5.16402 iter/s, 19.3648s/100 iter), loss = 0.120369
I0630 21:40:26.774842  5429 solver.cpp:309]     Train net output #0: loss = 0.120368 (* 1 = 0.120368 loss)
I0630 21:40:26.774849  5429 sgd_solver.cpp:106] Iteration 26600, lr = 1e-05
I0630 21:40:45.859048  5429 solver.cpp:290] Iteration 26700 (5.24008 iter/s, 19.0837s/100 iter), loss = 0.0711406
I0630 21:40:45.859072  5429 solver.cpp:309]     Train net output #0: loss = 0.0711401 (* 1 = 0.0711401 loss)
I0630 21:40:45.859079  5429 sgd_solver.cpp:106] Iteration 26700, lr = 1e-05
I0630 21:41:05.186846  5429 solver.cpp:290] Iteration 26800 (5.17405 iter/s, 19.3272s/100 iter), loss = 0.0877709
I0630 21:41:05.186928  5429 solver.cpp:309]     Train net output #0: loss = 0.0877704 (* 1 = 0.0877704 loss)
I0630 21:41:05.186939  5429 sgd_solver.cpp:106] Iteration 26800, lr = 1e-05
I0630 21:41:24.365043  5429 solver.cpp:290] Iteration 26900 (5.21442 iter/s, 19.1776s/100 iter), loss = 0.0935941
I0630 21:41:24.365067  5429 solver.cpp:309]     Train net output #0: loss = 0.0935936 (* 1 = 0.0935936 loss)
I0630 21:41:24.365073  5429 sgd_solver.cpp:106] Iteration 26900, lr = 1e-05
I0630 21:41:43.375725  5429 solver.cpp:290] Iteration 27000 (5.26036 iter/s, 19.0101s/100 iter), loss = 0.0762573
I0630 21:41:43.375854  5429 solver.cpp:309]     Train net output #0: loss = 0.0762568 (* 1 = 0.0762568 loss)
I0630 21:41:43.375864  5429 sgd_solver.cpp:106] Iteration 27000, lr = 1e-05
I0630 21:42:02.650494  5429 solver.cpp:290] Iteration 27100 (5.18831 iter/s, 19.2741s/100 iter), loss = 0.0445008
I0630 21:42:02.650516  5429 solver.cpp:309]     Train net output #0: loss = 0.0445003 (* 1 = 0.0445003 loss)
I0630 21:42:02.650523  5429 sgd_solver.cpp:106] Iteration 27100, lr = 1e-05
I0630 21:42:21.857062  5429 solver.cpp:290] Iteration 27200 (5.20671 iter/s, 19.206s/100 iter), loss = 0.0838681
I0630 21:42:21.857151  5429 solver.cpp:309]     Train net output #0: loss = 0.0838676 (* 1 = 0.0838676 loss)
I0630 21:42:21.857161  5429 sgd_solver.cpp:106] Iteration 27200, lr = 1e-05
I0630 21:42:40.804252  5429 solver.cpp:290] Iteration 27300 (5.278 iter/s, 18.9466s/100 iter), loss = 0.0828029
I0630 21:42:40.804275  5429 solver.cpp:309]     Train net output #0: loss = 0.0828024 (* 1 = 0.0828024 loss)
I0630 21:42:40.804282  5429 sgd_solver.cpp:106] Iteration 27300, lr = 1e-05
I0630 21:42:59.988241  5429 solver.cpp:290] Iteration 27400 (5.21283 iter/s, 19.1834s/100 iter), loss = 0.0435778
I0630 21:42:59.988286  5429 solver.cpp:309]     Train net output #0: loss = 0.0435773 (* 1 = 0.0435773 loss)
I0630 21:42:59.988294  5429 sgd_solver.cpp:106] Iteration 27400, lr = 1e-05
I0630 21:43:19.181269  5429 solver.cpp:290] Iteration 27500 (5.21038 iter/s, 19.1924s/100 iter), loss = 0.0604317
I0630 21:43:19.181294  5429 solver.cpp:309]     Train net output #0: loss = 0.0604312 (* 1 = 0.0604312 loss)
I0630 21:43:19.181300  5429 sgd_solver.cpp:106] Iteration 27500, lr = 1e-05
I0630 21:43:38.234700  5429 solver.cpp:290] Iteration 27600 (5.24855 iter/s, 19.0529s/100 iter), loss = 0.0519092
I0630 21:43:38.234750  5429 solver.cpp:309]     Train net output #0: loss = 0.0519087 (* 1 = 0.0519087 loss)
I0630 21:43:38.234757  5429 sgd_solver.cpp:106] Iteration 27600, lr = 1e-05
I0630 21:43:57.269340  5429 solver.cpp:290] Iteration 27700 (5.25374 iter/s, 19.0341s/100 iter), loss = 0.0753686
I0630 21:43:57.269366  5429 solver.cpp:309]     Train net output #0: loss = 0.0753681 (* 1 = 0.0753681 loss)
I0630 21:43:57.269376  5429 sgd_solver.cpp:106] Iteration 27700, lr = 1e-05
I0630 21:44:16.048914  5429 solver.cpp:290] Iteration 27800 (5.32509 iter/s, 18.779s/100 iter), loss = 0.0570071
I0630 21:44:16.048965  5429 solver.cpp:309]     Train net output #0: loss = 0.0570066 (* 1 = 0.0570066 loss)
I0630 21:44:16.048974  5429 sgd_solver.cpp:106] Iteration 27800, lr = 1e-05
I0630 21:44:35.230754  5429 solver.cpp:290] Iteration 27900 (5.21342 iter/s, 19.1812s/100 iter), loss = 0.0790409
I0630 21:44:35.230777  5429 solver.cpp:309]     Train net output #0: loss = 0.0790404 (* 1 = 0.0790404 loss)
I0630 21:44:35.230784  5429 sgd_solver.cpp:106] Iteration 27900, lr = 1e-05
I0630 21:44:54.082053  5429 solver.cpp:471] Iteration 28000, Testing net (#0)
I0630 21:46:27.078949  5429 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.93921
I0630 21:46:27.078989  5429 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.995771
I0630 21:46:27.078994  5429 solver.cpp:544]     Test net output #2: loss = 0.127924 (* 1 = 0.127924 loss)
I0630 21:46:27.298524  5429 solver.cpp:290] Iteration 28000 (0.892342 iter/s, 112.065s/100 iter), loss = 0.0631419
I0630 21:46:27.298547  5429 solver.cpp:309]     Train net output #0: loss = 0.0631414 (* 1 = 0.0631414 loss)
I0630 21:46:27.298553  5429 sgd_solver.cpp:106] Iteration 28000, lr = 1e-05
I0630 21:46:46.495591  5429 solver.cpp:290] Iteration 28100 (5.20928 iter/s, 19.1965s/100 iter), loss = 0.0701565
I0630 21:46:46.495615  5429 solver.cpp:309]     Train net output #0: loss = 0.070156 (* 1 = 0.070156 loss)
I0630 21:46:46.495621  5429 sgd_solver.cpp:106] Iteration 28100, lr = 1e-05
I0630 21:47:05.706905  5429 solver.cpp:290] Iteration 28200 (5.20542 iter/s, 19.2107s/100 iter), loss = 0.080405
I0630 21:47:05.706950  5429 solver.cpp:309]     Train net output #0: loss = 0.0804045 (* 1 = 0.0804045 loss)
I0630 21:47:05.706959  5429 sgd_solver.cpp:106] Iteration 28200, lr = 1e-05
I0630 21:47:24.771267  5429 solver.cpp:290] Iteration 28300 (5.24555 iter/s, 19.0638s/100 iter), loss = 0.0940452
I0630 21:47:24.771291  5429 solver.cpp:309]     Train net output #0: loss = 0.0940447 (* 1 = 0.0940447 loss)
I0630 21:47:24.771297  5429 sgd_solver.cpp:106] Iteration 28300, lr = 1e-05
I0630 21:47:43.864105  5429 solver.cpp:290] Iteration 28400 (5.23772 iter/s, 19.0923s/100 iter), loss = 0.0909215
I0630 21:47:43.864188  5429 solver.cpp:309]     Train net output #0: loss = 0.090921 (* 1 = 0.090921 loss)
I0630 21:47:43.864200  5429 sgd_solver.cpp:106] Iteration 28400, lr = 1e-05
I0630 21:48:02.923054  5429 solver.cpp:290] Iteration 28500 (5.24705 iter/s, 19.0583s/100 iter), loss = 0.0528347
I0630 21:48:02.923079  5429 solver.cpp:309]     Train net output #0: loss = 0.0528342 (* 1 = 0.0528342 loss)
I0630 21:48:02.923085  5429 sgd_solver.cpp:106] Iteration 28500, lr = 1e-05
I0630 21:48:22.033093  5429 solver.cpp:290] Iteration 28600 (5.23301 iter/s, 19.1095s/100 iter), loss = 0.0914814
I0630 21:48:22.033150  5429 solver.cpp:309]     Train net output #0: loss = 0.0914809 (* 1 = 0.0914809 loss)
I0630 21:48:22.033159  5429 sgd_solver.cpp:106] Iteration 28600, lr = 1e-05
I0630 21:48:41.161713  5429 solver.cpp:290] Iteration 28700 (5.22793 iter/s, 19.128s/100 iter), loss = 0.0458436
I0630 21:48:41.161742  5429 solver.cpp:309]     Train net output #0: loss = 0.0458431 (* 1 = 0.0458431 loss)
I0630 21:48:41.161752  5429 sgd_solver.cpp:106] Iteration 28700, lr = 1e-05
I0630 21:49:00.460749  5429 solver.cpp:290] Iteration 28800 (5.18176 iter/s, 19.2985s/100 iter), loss = 0.0860932
I0630 21:49:00.460795  5429 solver.cpp:309]     Train net output #0: loss = 0.0860927 (* 1 = 0.0860927 loss)
I0630 21:49:00.460804  5429 sgd_solver.cpp:106] Iteration 28800, lr = 1e-05
I0630 21:49:19.471457  5429 solver.cpp:290] Iteration 28900 (5.26036 iter/s, 19.0101s/100 iter), loss = 0.125325
I0630 21:49:19.471482  5429 solver.cpp:309]     Train net output #0: loss = 0.125325 (* 1 = 0.125325 loss)
I0630 21:49:19.471491  5429 sgd_solver.cpp:106] Iteration 28900, lr = 1e-05
I0630 21:49:38.457309  5429 solver.cpp:290] Iteration 29000 (5.26724 iter/s, 18.9853s/100 iter), loss = 0.0818155
I0630 21:49:38.457363  5429 solver.cpp:309]     Train net output #0: loss = 0.081815 (* 1 = 0.081815 loss)
I0630 21:49:38.457371  5429 sgd_solver.cpp:106] Iteration 29000, lr = 1e-05
I0630 21:49:57.596325  5429 solver.cpp:290] Iteration 29100 (5.22509 iter/s, 19.1384s/100 iter), loss = 0.0562806
I0630 21:49:57.596350  5429 solver.cpp:309]     Train net output #0: loss = 0.0562802 (* 1 = 0.0562802 loss)
I0630 21:49:57.596359  5429 sgd_solver.cpp:106] Iteration 29100, lr = 1e-05
I0630 21:50:16.839902  5429 solver.cpp:290] Iteration 29200 (5.19669 iter/s, 19.243s/100 iter), loss = 0.065218
I0630 21:50:16.840020  5429 solver.cpp:309]     Train net output #0: loss = 0.0652176 (* 1 = 0.0652176 loss)
I0630 21:50:16.840030  5429 sgd_solver.cpp:106] Iteration 29200, lr = 1e-05
I0630 21:50:35.895654  5429 solver.cpp:290] Iteration 29300 (5.24794 iter/s, 19.0551s/100 iter), loss = 0.0410787
I0630 21:50:35.895678  5429 solver.cpp:309]     Train net output #0: loss = 0.0410783 (* 1 = 0.0410783 loss)
I0630 21:50:35.895684  5429 sgd_solver.cpp:106] Iteration 29300, lr = 1e-05
I0630 21:50:54.870517  5429 solver.cpp:290] Iteration 29400 (5.27029 iter/s, 18.9743s/100 iter), loss = 0.058831
I0630 21:50:54.870626  5429 solver.cpp:309]     Train net output #0: loss = 0.0588305 (* 1 = 0.0588305 loss)
I0630 21:50:54.870636  5429 sgd_solver.cpp:106] Iteration 29400, lr = 1e-05
I0630 21:51:13.869984  5429 solver.cpp:290] Iteration 29500 (5.26348 iter/s, 18.9988s/100 iter), loss = 0.0466017
I0630 21:51:13.870009  5429 solver.cpp:309]     Train net output #0: loss = 0.0466012 (* 1 = 0.0466012 loss)
I0630 21:51:13.870016  5429 sgd_solver.cpp:106] Iteration 29500, lr = 1e-05
I0630 21:51:33.023686  5429 solver.cpp:290] Iteration 29600 (5.22108 iter/s, 19.1531s/100 iter), loss = 0.120055
I0630 21:51:33.023777  5429 solver.cpp:309]     Train net output #0: loss = 0.120054 (* 1 = 0.120054 loss)
I0630 21:51:33.023792  5429 sgd_solver.cpp:106] Iteration 29600, lr = 1e-05
I0630 21:51:52.064779  5429 solver.cpp:290] Iteration 29700 (5.25197 iter/s, 19.0405s/100 iter), loss = 0.110836
I0630 21:51:52.064800  5429 solver.cpp:309]     Train net output #0: loss = 0.110836 (* 1 = 0.110836 loss)
I0630 21:51:52.064808  5429 sgd_solver.cpp:106] Iteration 29700, lr = 1e-05
I0630 21:52:11.335633  5429 solver.cpp:290] Iteration 29800 (5.18934 iter/s, 19.2703s/100 iter), loss = 0.0871948
I0630 21:52:11.335690  5429 solver.cpp:309]     Train net output #0: loss = 0.0871944 (* 1 = 0.0871944 loss)
I0630 21:52:11.335700  5429 sgd_solver.cpp:106] Iteration 29800, lr = 1e-05
I0630 21:52:30.449986  5429 solver.cpp:290] Iteration 29900 (5.23183 iter/s, 19.1138s/100 iter), loss = 0.0763954
I0630 21:52:30.450014  5429 solver.cpp:309]     Train net output #0: loss = 0.076395 (* 1 = 0.076395 loss)
I0630 21:52:30.450021  5429 sgd_solver.cpp:106] Iteration 29900, lr = 1e-05
I0630 21:52:49.249289  5429 solver.cpp:598] Snapshotting to binary proto file training/cityscapes20_jsegnet21v2_2017-06-30_19-26-17/initial/cityscapes20_jsegnet21v2_iter_30000.caffemodel
I0630 21:52:49.274492  5429 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/cityscapes20_jsegnet21v2_2017-06-30_19-26-17/initial/cityscapes20_jsegnet21v2_iter_30000.solverstate
I0630 21:52:49.295944  5429 solver.cpp:471] Iteration 30000, Testing net (#0)
I0630 21:54:22.752815  5429 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.939235
I0630 21:54:22.752889  5429 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.996004
I0630 21:54:22.752897  5429 solver.cpp:544]     Test net output #2: loss = 0.128261 (* 1 = 0.128261 loss)
I0630 21:54:22.994814  5429 solver.cpp:290] Iteration 30000 (0.88856 iter/s, 112.542s/100 iter), loss = 0.0817671
I0630 21:54:22.994839  5429 solver.cpp:309]     Train net output #0: loss = 0.0817667 (* 1 = 0.0817667 loss)
I0630 21:54:22.994848  5429 sgd_solver.cpp:106] Iteration 30000, lr = 1e-05
I0630 21:54:42.111484  5429 solver.cpp:290] Iteration 30100 (5.23119 iter/s, 19.1161s/100 iter), loss = 0.0534849
I0630 21:54:42.111505  5429 solver.cpp:309]     Train net output #0: loss = 0.0534845 (* 1 = 0.0534845 loss)
I0630 21:54:42.111512  5429 sgd_solver.cpp:106] Iteration 30100, lr = 1e-05
I0630 21:55:01.199739  5429 solver.cpp:290] Iteration 30200 (5.23898 iter/s, 19.0877s/100 iter), loss = 0.067205
I0630 21:55:01.199780  5429 solver.cpp:309]     Train net output #0: loss = 0.0672046 (* 1 = 0.0672046 loss)
I0630 21:55:01.199789  5429 sgd_solver.cpp:106] Iteration 30200, lr = 1e-05
I0630 21:55:20.340976  5429 solver.cpp:290] Iteration 30300 (5.22448 iter/s, 19.1407s/100 iter), loss = 0.0900274
I0630 21:55:20.341002  5429 solver.cpp:309]     Train net output #0: loss = 0.090027 (* 1 = 0.090027 loss)
I0630 21:55:20.341012  5429 sgd_solver.cpp:106] Iteration 30300, lr = 1e-05
I0630 21:55:39.439327  5429 solver.cpp:290] Iteration 30400 (5.23621 iter/s, 19.0978s/100 iter), loss = 0.0659831
I0630 21:55:39.439370  5429 solver.cpp:309]     Train net output #0: loss = 0.0659827 (* 1 = 0.0659827 loss)
I0630 21:55:39.439378  5429 sgd_solver.cpp:106] Iteration 30400, lr = 1e-05
I0630 21:55:58.598587  5429 solver.cpp:290] Iteration 30500 (5.21956 iter/s, 19.1587s/100 iter), loss = 0.0868088
I0630 21:55:58.598611  5429 solver.cpp:309]     Train net output #0: loss = 0.0868084 (* 1 = 0.0868084 loss)
I0630 21:55:58.598618  5429 sgd_solver.cpp:106] Iteration 30500, lr = 1e-05
I0630 21:56:17.640051  5429 solver.cpp:290] Iteration 30600 (5.25185 iter/s, 19.0409s/100 iter), loss = 0.058014
I0630 21:56:17.640089  5429 solver.cpp:309]     Train net output #0: loss = 0.0580136 (* 1 = 0.0580136 loss)
I0630 21:56:17.640096  5429 sgd_solver.cpp:106] Iteration 30600, lr = 1e-05
I0630 21:56:36.691301  5429 solver.cpp:290] Iteration 30700 (5.24915 iter/s, 19.0507s/100 iter), loss = 0.0655588
I0630 21:56:36.691324  5429 solver.cpp:309]     Train net output #0: loss = 0.0655584 (* 1 = 0.0655584 loss)
I0630 21:56:36.691331  5429 sgd_solver.cpp:106] Iteration 30700, lr = 1e-05
I0630 21:56:55.884627  5429 solver.cpp:290] Iteration 30800 (5.21029 iter/s, 19.1928s/100 iter), loss = 0.0790909
I0630 21:56:55.884675  5429 solver.cpp:309]     Train net output #0: loss = 0.0790905 (* 1 = 0.0790905 loss)
I0630 21:56:55.884683  5429 sgd_solver.cpp:106] Iteration 30800, lr = 1e-05
I0630 21:57:15.098325  5429 solver.cpp:290] Iteration 30900 (5.20477 iter/s, 19.2131s/100 iter), loss = 0.0604149
I0630 21:57:15.098346  5429 solver.cpp:309]     Train net output #0: loss = 0.0604145 (* 1 = 0.0604145 loss)
I0630 21:57:15.098353  5429 sgd_solver.cpp:106] Iteration 30900, lr = 1e-05
I0630 21:57:34.038301  5429 solver.cpp:290] Iteration 31000 (5.27999 iter/s, 18.9394s/100 iter), loss = 0.0658335
I0630 21:57:34.038368  5429 solver.cpp:309]     Train net output #0: loss = 0.0658331 (* 1 = 0.0658331 loss)
I0630 21:57:34.038377  5429 sgd_solver.cpp:106] Iteration 31000, lr = 1e-05
I0630 21:57:53.100184  5429 solver.cpp:290] Iteration 31100 (5.24623 iter/s, 19.0613s/100 iter), loss = 0.0545499
I0630 21:57:53.100210  5429 solver.cpp:309]     Train net output #0: loss = 0.0545495 (* 1 = 0.0545495 loss)
I0630 21:57:53.100219  5429 sgd_solver.cpp:106] Iteration 31100, lr = 1e-05
I0630 21:58:12.190367  5429 solver.cpp:290] Iteration 31200 (5.23844 iter/s, 19.0896s/100 iter), loss = 0.087293
I0630 21:58:12.190450  5429 solver.cpp:309]     Train net output #0: loss = 0.0872926 (* 1 = 0.0872926 loss)
I0630 21:58:12.190459  5429 sgd_solver.cpp:106] Iteration 31200, lr = 1e-05
I0630 21:58:31.088762  5429 solver.cpp:290] Iteration 31300 (5.29162 iter/s, 18.8978s/100 iter), loss = 0.0838009
I0630 21:58:31.088784  5429 solver.cpp:309]     Train net output #0: loss = 0.0838004 (* 1 = 0.0838004 loss)
I0630 21:58:31.088791  5429 sgd_solver.cpp:106] Iteration 31300, lr = 1e-05
I0630 21:58:50.242689  5429 solver.cpp:290] Iteration 31400 (5.22101 iter/s, 19.1534s/100 iter), loss = 0.0646171
I0630 21:58:50.242763  5429 solver.cpp:309]     Train net output #0: loss = 0.0646167 (* 1 = 0.0646167 loss)
I0630 21:58:50.242771  5429 sgd_solver.cpp:106] Iteration 31400, lr = 1e-05
I0630 21:59:09.394811  5429 solver.cpp:290] Iteration 31500 (5.22152 iter/s, 19.1515s/100 iter), loss = 0.0574569
I0630 21:59:09.394836  5429 solver.cpp:309]     Train net output #0: loss = 0.0574565 (* 1 = 0.0574565 loss)
I0630 21:59:09.394843  5429 sgd_solver.cpp:106] Iteration 31500, lr = 1e-05
I0630 21:59:28.293089  5429 solver.cpp:290] Iteration 31600 (5.29164 iter/s, 18.8977s/100 iter), loss = 0.0536601
I0630 21:59:28.293200  5429 solver.cpp:309]     Train net output #0: loss = 0.0536597 (* 1 = 0.0536597 loss)
I0630 21:59:28.293210  5429 sgd_solver.cpp:106] Iteration 31600, lr = 1e-05
I0630 21:59:47.308977  5429 solver.cpp:290] Iteration 31700 (5.25893 iter/s, 19.0153s/100 iter), loss = 0.0782927
I0630 21:59:47.309003  5429 solver.cpp:309]     Train net output #0: loss = 0.0782923 (* 1 = 0.0782923 loss)
I0630 21:59:47.309010  5429 sgd_solver.cpp:106] Iteration 31700, lr = 1e-05
I0630 22:00:06.367347  5429 solver.cpp:290] Iteration 31800 (5.24719 iter/s, 19.0578s/100 iter), loss = 0.0440781
I0630 22:00:06.367398  5429 solver.cpp:309]     Train net output #0: loss = 0.0440777 (* 1 = 0.0440777 loss)
I0630 22:00:06.367406  5429 sgd_solver.cpp:106] Iteration 31800, lr = 1e-05
I0630 22:00:25.501071  5429 solver.cpp:290] Iteration 31900 (5.22653 iter/s, 19.1332s/100 iter), loss = 0.060034
I0630 22:00:25.501098  5429 solver.cpp:309]     Train net output #0: loss = 0.0600336 (* 1 = 0.0600336 loss)
I0630 22:00:25.501106  5429 sgd_solver.cpp:106] Iteration 31900, lr = 1e-05
I0630 22:00:44.471187  5429 solver.cpp:598] Snapshotting to binary proto file training/cityscapes20_jsegnet21v2_2017-06-30_19-26-17/initial/cityscapes20_jsegnet21v2_iter_32000.caffemodel
I0630 22:00:44.497059  5429 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/cityscapes20_jsegnet21v2_2017-06-30_19-26-17/initial/cityscapes20_jsegnet21v2_iter_32000.solverstate
I0630 22:00:44.570858  5429 solver.cpp:451] Iteration 32000, loss = 0.0610758
I0630 22:00:44.570879  5429 solver.cpp:471] Iteration 32000, Testing net (#0)
I0630 22:02:18.846148  5429 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.93853
I0630 22:02:18.846230  5429 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.995939
I0630 22:02:18.846237  5429 solver.cpp:544]     Test net output #2: loss = 0.130387 (* 1 = 0.130387 loss)
I0630 22:02:18.846240  5429 solver.cpp:456] Optimization Done.
I0630 22:02:19.092031  5429 caffe.cpp:246] Optimization Done.
