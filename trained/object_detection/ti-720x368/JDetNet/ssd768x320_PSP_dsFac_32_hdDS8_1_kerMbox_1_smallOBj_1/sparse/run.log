I0324 23:37:50.785481 29022 caffe.cpp:807] This is NVCaffe 0.16.4 started at Sat Mar 24 23:37:49 2018
I0324 23:37:50.785677 29022 caffe.cpp:810] CuDNN version: 6021
I0324 23:37:50.785686 29022 caffe.cpp:811] CuBLAS version: 8000
I0324 23:37:50.785691 29022 caffe.cpp:812] CUDA version: 8000
I0324 23:37:50.785707 29022 caffe.cpp:813] CUDA driver version: 8000
I0324 23:37:50.935798 29022 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0324 23:37:50.936504 29022 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8287879168, dev_info[0]: total=8506769408 free=8287879168
I0324 23:37:50.936522 29022 caffe.cpp:214] Using GPUs 0
I0324 23:37:50.936908 29022 caffe.cpp:219] GPU 0: GeForce GTX 1080
I0324 23:37:50.936966 29022 solver.cpp:43] Solver data type: FLOAT
I0324 23:37:50.937083 29022 solver.cpp:46] Initializing solver from parameters: 
train_net: "training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/train.prototxt"
test_net: "training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/test.prototxt"
test_iter: 452
test_interval: 2000
base_lr: 0.001
display: 100
max_iter: 60000
lr_policy: "poly"
gamma: 0.1
power: 4
momentum: 0.9
weight_decay: 1e-05
snapshot: 2000
snapshot_prefix: "training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
snapshot_after_train: true
regularization_type: "L1"
test_initialization: true
average_loss: 10
stepvalue: 30000
stepvalue: 45000
stepvalue: 300000
iter_size: 4
type: "SGD"
display_sparsity: 2000
sparse_mode: SPARSE_UPDATE
sparsity_target: 0.7
sparsity_step_factor: 0.05
sparsity_step_iter: 2000
sparsity_start_iter: 0
sparsity_start_factor: 0.5
sparsity_threshold_maxratio: 0.2
sparsity_itr_increment_bfr_applying: true
sparsity_threshold_value_max: 0.2
eval_type: "detection"
ap_version: "11point"
show_per_class_result: true
I0324 23:37:50.983922 29022 solver.cpp:78] Creating training net from train_net file: training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/train.prototxt
I0324 23:37:50.998271 29022 net.cpp:72] Initializing net from parameters: 
name: "ssdJacintoNetV2"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 0
    mean_value: 0
    mean_value: 0
    force_color: false
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 320
      width: 768
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: NEAREST
      interp_mode: CUBIC
      interp_mode: LANCZOS4
    }
    emit_constraint {
      emit_type: CENTER
    }
    crop_h: 320
    crop_w: 768
    distort_param {
      brightness_prob: 0.5
      brightness_delta: 32
      contrast_prob: 0.5
      contrast_lower: 0.5
      contrast_upper: 1.5
      hue_prob: 0.5
      hue_delta: 18
      saturation_prob: 0.5
      saturation_lower: 0.5
      saturation_upper: 1.5
      random_order_prob: 0
    }
    expand_param {
      prob: 0.5
      max_expand_ratio: 4
    }
  }
  data_param {
    source: "/user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb"
    batch_size: 8
    backend: LMDB
    threads: 4
    parser_threads: 4
  }
  annotated_data_param {
    batch_sampler {
      max_sample: 1
      max_trials: 1
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.1
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.3
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.5
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.7
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.9
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        max_jaccard_overlap: 1
      }
      max_sample: 1
      max_trials: 50
    }
    label_map_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/labelmap.prototxt"
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "pool6"
  top: "pool7"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool8"
  type: "Pooling"
  bottom: "pool7"
  top: "pool8"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool9"
  type: "Pooling"
  bottom: "pool8"
  top: "pool9"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "ctx_output1"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "ctx_output1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu"
  type: "ReLU"
  bottom: "ctx_output1"
  top: "ctx_output1"
}
layer {
  name: "ctx_output2"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "ctx_output2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu"
  type: "ReLU"
  bottom: "ctx_output2"
  top: "ctx_output2"
}
layer {
  name: "ctx_output3"
  type: "Convolution"
  bottom: "pool6"
  top: "ctx_output3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu"
  type: "ReLU"
  bottom: "ctx_output3"
  top: "ctx_output3"
}
layer {
  name: "ctx_output4"
  type: "Convolution"
  bottom: "pool7"
  top: "ctx_output4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu"
  type: "ReLU"
  bottom: "ctx_output4"
  top: "ctx_output4"
}
layer {
  name: "ctx_output5"
  type: "Convolution"
  bottom: "pool8"
  top: "ctx_output5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu"
  type: "ReLU"
  bottom: "ctx_output5"
  top: "ctx_output5"
}
layer {
  name: "ctx_output6"
  type: "Convolution"
  bottom: "pool9"
  top: "ctx_output6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu"
  type: "ReLU"
  bottom: "ctx_output6"
  top: "ctx_output6"
}
layer {
  name: "ctx_output1/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_loc"
  top: "ctx_output1/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_loc_perm"
  top: "ctx_output1/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_conf"
  top: "ctx_output1/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_conf_perm"
  top: "ctx_output1/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output1"
  bottom: "data"
  top: "ctx_output1/relu_mbox_priorbox"
  prior_box_param {
    min_size: 12.8
    max_size: 32
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_loc"
  top: "ctx_output2/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_loc_perm"
  top: "ctx_output2/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_conf"
  top: "ctx_output2/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_conf_perm"
  top: "ctx_output2/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output2"
  bottom: "data"
  top: "ctx_output2/relu_mbox_priorbox"
  prior_box_param {
    min_size: 32
    max_size: 96
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_loc"
  top: "ctx_output3/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_loc_perm"
  top: "ctx_output3/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_conf"
  top: "ctx_output3/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_conf_perm"
  top: "ctx_output3/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output3"
  bottom: "data"
  top: "ctx_output3/relu_mbox_priorbox"
  prior_box_param {
    min_size: 96
    max_size: 160
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_loc"
  top: "ctx_output4/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_loc_perm"
  top: "ctx_output4/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_conf"
  top: "ctx_output4/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_conf_perm"
  top: "ctx_output4/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output4"
  bottom: "data"
  top: "ctx_output4/relu_mbox_priorbox"
  prior_box_param {
    min_size: 160
    max_size: 224
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_loc"
  top: "ctx_output5/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_loc_perm"
  top: "ctx_output5/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_conf"
  top: "ctx_output5/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_conf_perm"
  top: "ctx_output5/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output5"
  bottom: "data"
  top: "ctx_output5/relu_mbox_priorbox"
  prior_box_param {
    min_size: 224
    max_size: 288
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_loc"
  top: "ctx_output6/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_loc_perm"
  top: "ctx_output6/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_conf"
  top: "ctx_output6/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_conf_perm"
  top: "ctx_output6/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output6"
  bottom: "data"
  top: "ctx_output6/relu_mbox_priorbox"
  prior_box_param {
    min_size: 288
    max_size: 352
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_loc_flat"
  bottom: "ctx_output2/relu_mbox_loc_flat"
  bottom: "ctx_output3/relu_mbox_loc_flat"
  bottom: "ctx_output4/relu_mbox_loc_flat"
  bottom: "ctx_output5/relu_mbox_loc_flat"
  bottom: "ctx_output6/relu_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_conf_flat"
  bottom: "ctx_output2/relu_mbox_conf_flat"
  bottom: "ctx_output3/relu_mbox_conf_flat"
  bottom: "ctx_output4/relu_mbox_conf_flat"
  bottom: "ctx_output5/relu_mbox_conf_flat"
  bottom: "ctx_output6/relu_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_priorbox"
  bottom: "ctx_output2/relu_mbox_priorbox"
  bottom: "ctx_output3/relu_mbox_priorbox"
  bottom: "ctx_output4/relu_mbox_priorbox"
  bottom: "ctx_output5/relu_mbox_priorbox"
  bottom: "ctx_output6/relu_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_loss"
  type: "MultiBoxLoss"
  bottom: "mbox_loc"
  bottom: "mbox_conf"
  bottom: "mbox_priorbox"
  bottom: "label"
  top: "mbox_loss"
  include {
    phase: TRAIN
  }
  propagate_down: true
  propagate_down: true
  propagate_down: false
  propagate_down: false
  loss_param {
    normalization: VALID
  }
  multibox_loss_param {
    loc_loss_type: SMOOTH_L1
    conf_loss_type: SOFTMAX
    loc_weight: 1
    num_classes: 4
    share_location: true
    match_type: PER_PREDICTION
    overlap_threshold: 0.5
    use_prior_for_matching: true
    background_label_id: 0
    use_difficult_gt: false
    neg_pos_ratio: 3
    neg_overlap: 0.5
    code_type: CENTER_SIZE
    ignore_cross_boundary_bbox: false
    mining_type: MAX_NEGATIVE
    ignore_difficult_gt: false
  }
}
I0324 23:37:50.999128 29022 net.cpp:104] Using FLOAT as default forward math type
I0324 23:37:50.999141 29022 net.cpp:110] Using FLOAT as default backward math type
I0324 23:37:50.999189 29022 layer_factory.hpp:136] Creating layer 'data' of type 'AnnotatedData'
I0324 23:37:50.999208 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:50.999374 29022 net.cpp:184] Created Layer data (0)
I0324 23:37:50.999398 29022 net.cpp:530] data -> data
I0324 23:37:50.999428 29022 net.cpp:530] data -> label
I0324 23:37:51.000178 29022 data_reader.cpp:58] Data Reader threads: 4, out queues: 16, depth: 8
I0324 23:37:51.000290 29022 internal_thread.cpp:19] Starting 4 internal thread(s) on device 0
I0324 23:37:51.002084 29044 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0324 23:37:51.002377 29043 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0324 23:37:51.003159 29042 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0324 23:37:51.004241 29045 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0324 23:37:51.015302 29022 annotated_data_layer.cpp:219] output data size: 8,3,320,768
I0324 23:37:51.015502 29022 annotated_data_layer.cpp:265] [0] Output data size: 8, 3, 320, 768
I0324 23:37:51.015544 29022 internal_thread.cpp:19] Starting 4 internal thread(s) on device 0
I0324 23:37:51.015645 29022 net.cpp:245] Setting up data
I0324 23:37:51.015671 29022 net.cpp:252] TRAIN Top shape for layer 0 'data' 8 3 320 768 (5898240)
I0324 23:37:51.015689 29022 net.cpp:252] TRAIN Top shape for layer 0 'data' 1 1 10 8 (80)
I0324 23:37:51.015702 29022 layer_factory.hpp:136] Creating layer 'data_data_0_split' of type 'Split'
I0324 23:37:51.015709 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:51.015723 29022 net.cpp:184] Created Layer data_data_0_split (1)
I0324 23:37:51.015730 29022 net.cpp:561] data_data_0_split <- data
I0324 23:37:51.015743 29022 net.cpp:530] data_data_0_split -> data_data_0_split_0
I0324 23:37:51.015753 29022 net.cpp:530] data_data_0_split -> data_data_0_split_1
I0324 23:37:51.015761 29022 net.cpp:530] data_data_0_split -> data_data_0_split_2
I0324 23:37:51.015769 29022 net.cpp:530] data_data_0_split -> data_data_0_split_3
I0324 23:37:51.015774 29022 net.cpp:530] data_data_0_split -> data_data_0_split_4
I0324 23:37:51.015780 29022 net.cpp:530] data_data_0_split -> data_data_0_split_5
I0324 23:37:51.015785 29022 net.cpp:530] data_data_0_split -> data_data_0_split_6
I0324 23:37:51.015872 29022 net.cpp:245] Setting up data_data_0_split
I0324 23:37:51.015885 29022 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0324 23:37:51.015892 29022 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0324 23:37:51.015898 29022 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0324 23:37:51.015904 29022 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0324 23:37:51.015910 29022 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0324 23:37:51.015916 29022 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0324 23:37:51.015923 29022 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0324 23:37:51.015928 29022 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0324 23:37:51.015935 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:51.015952 29022 net.cpp:184] Created Layer data/bias (2)
I0324 23:37:51.015959 29022 net.cpp:561] data/bias <- data_data_0_split_0
I0324 23:37:51.015965 29022 net.cpp:530] data/bias -> data/bias
I0324 23:37:51.024118 29022 net.cpp:245] Setting up data/bias
I0324 23:37:51.024205 29022 net.cpp:252] TRAIN Top shape for layer 2 'data/bias' 8 3 320 768 (5898240)
I0324 23:37:51.024236 29022 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0324 23:37:51.024245 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:51.024303 29022 net.cpp:184] Created Layer conv1a (3)
I0324 23:37:51.024315 29022 net.cpp:561] conv1a <- data/bias
I0324 23:37:51.024322 29022 net.cpp:530] conv1a -> conv1a
I0324 23:37:52.252699 29022 net.cpp:245] Setting up conv1a
I0324 23:37:52.252738 29022 net.cpp:252] TRAIN Top shape for layer 3 'conv1a' 8 32 160 384 (15728640)
I0324 23:37:52.252758 29022 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0324 23:37:52.252766 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.252815 29022 net.cpp:184] Created Layer conv1a/bn (4)
I0324 23:37:52.252826 29022 net.cpp:561] conv1a/bn <- conv1a
I0324 23:37:52.252835 29022 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0324 23:37:52.254287 29022 net.cpp:245] Setting up conv1a/bn
I0324 23:37:52.254307 29022 net.cpp:252] TRAIN Top shape for layer 4 'conv1a/bn' 8 32 160 384 (15728640)
I0324 23:37:52.254323 29022 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0324 23:37:52.254329 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.254338 29022 net.cpp:184] Created Layer conv1a/relu (5)
I0324 23:37:52.254344 29022 net.cpp:561] conv1a/relu <- conv1a
I0324 23:37:52.254351 29022 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0324 23:37:52.254369 29022 net.cpp:245] Setting up conv1a/relu
I0324 23:37:52.254379 29022 net.cpp:252] TRAIN Top shape for layer 5 'conv1a/relu' 8 32 160 384 (15728640)
I0324 23:37:52.254384 29022 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0324 23:37:52.254390 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.254407 29022 net.cpp:184] Created Layer conv1b (6)
I0324 23:37:52.254412 29022 net.cpp:561] conv1b <- conv1a
I0324 23:37:52.254420 29022 net.cpp:530] conv1b -> conv1b
I0324 23:37:52.255929 29022 net.cpp:245] Setting up conv1b
I0324 23:37:52.255945 29022 net.cpp:252] TRAIN Top shape for layer 6 'conv1b' 8 32 160 384 (15728640)
I0324 23:37:52.255960 29022 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0324 23:37:52.255967 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.255978 29022 net.cpp:184] Created Layer conv1b/bn (7)
I0324 23:37:52.255985 29022 net.cpp:561] conv1b/bn <- conv1b
I0324 23:37:52.255990 29022 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0324 23:37:52.256686 29022 net.cpp:245] Setting up conv1b/bn
I0324 23:37:52.256701 29022 net.cpp:252] TRAIN Top shape for layer 7 'conv1b/bn' 8 32 160 384 (15728640)
I0324 23:37:52.256717 29022 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0324 23:37:52.256724 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.256732 29022 net.cpp:184] Created Layer conv1b/relu (8)
I0324 23:37:52.256737 29022 net.cpp:561] conv1b/relu <- conv1b
I0324 23:37:52.256743 29022 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0324 23:37:52.256752 29022 net.cpp:245] Setting up conv1b/relu
I0324 23:37:52.256758 29022 net.cpp:252] TRAIN Top shape for layer 8 'conv1b/relu' 8 32 160 384 (15728640)
I0324 23:37:52.256764 29022 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0324 23:37:52.256769 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.256781 29022 net.cpp:184] Created Layer pool1 (9)
I0324 23:37:52.256790 29022 net.cpp:561] pool1 <- conv1b
I0324 23:37:52.256796 29022 net.cpp:530] pool1 -> pool1
I0324 23:37:52.265350 29022 net.cpp:245] Setting up pool1
I0324 23:37:52.265367 29022 net.cpp:252] TRAIN Top shape for layer 9 'pool1' 8 32 80 192 (3932160)
I0324 23:37:52.265373 29022 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0324 23:37:52.265380 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.265393 29022 net.cpp:184] Created Layer res2a_branch2a (10)
I0324 23:37:52.265399 29022 net.cpp:561] res2a_branch2a <- pool1
I0324 23:37:52.265406 29022 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0324 23:37:52.267349 29022 net.cpp:245] Setting up res2a_branch2a
I0324 23:37:52.267370 29022 net.cpp:252] TRAIN Top shape for layer 10 'res2a_branch2a' 8 64 80 192 (7864320)
I0324 23:37:52.267387 29022 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0324 23:37:52.267395 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.267421 29022 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0324 23:37:52.267429 29022 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0324 23:37:52.267436 29022 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0324 23:37:52.268610 29022 net.cpp:245] Setting up res2a_branch2a/bn
I0324 23:37:52.268625 29022 net.cpp:252] TRAIN Top shape for layer 11 'res2a_branch2a/bn' 8 64 80 192 (7864320)
I0324 23:37:52.268641 29022 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0324 23:37:52.268648 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.268656 29022 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0324 23:37:52.268662 29022 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0324 23:37:52.268668 29022 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0324 23:37:52.268676 29022 net.cpp:245] Setting up res2a_branch2a/relu
I0324 23:37:52.268687 29022 net.cpp:252] TRAIN Top shape for layer 12 'res2a_branch2a/relu' 8 64 80 192 (7864320)
I0324 23:37:52.268692 29022 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0324 23:37:52.268697 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.268712 29022 net.cpp:184] Created Layer res2a_branch2b (13)
I0324 23:37:52.268718 29022 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0324 23:37:52.268723 29022 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0324 23:37:52.270144 29022 net.cpp:245] Setting up res2a_branch2b
I0324 23:37:52.270162 29022 net.cpp:252] TRAIN Top shape for layer 13 'res2a_branch2b' 8 64 80 192 (7864320)
I0324 23:37:52.270176 29022 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0324 23:37:52.270184 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.270193 29022 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0324 23:37:52.270200 29022 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0324 23:37:52.270206 29022 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0324 23:37:52.270910 29022 net.cpp:245] Setting up res2a_branch2b/bn
I0324 23:37:52.270925 29022 net.cpp:252] TRAIN Top shape for layer 14 'res2a_branch2b/bn' 8 64 80 192 (7864320)
I0324 23:37:52.270941 29022 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0324 23:37:52.270947 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.270956 29022 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0324 23:37:52.270961 29022 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0324 23:37:52.270967 29022 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0324 23:37:52.270975 29022 net.cpp:245] Setting up res2a_branch2b/relu
I0324 23:37:52.270982 29022 net.cpp:252] TRAIN Top shape for layer 15 'res2a_branch2b/relu' 8 64 80 192 (7864320)
I0324 23:37:52.270987 29022 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0324 23:37:52.270993 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.271008 29022 net.cpp:184] Created Layer pool2 (16)
I0324 23:37:52.271013 29022 net.cpp:561] pool2 <- res2a_branch2b
I0324 23:37:52.271019 29022 net.cpp:530] pool2 -> pool2
I0324 23:37:52.271082 29022 net.cpp:245] Setting up pool2
I0324 23:37:52.271095 29022 net.cpp:252] TRAIN Top shape for layer 16 'pool2' 8 64 40 96 (1966080)
I0324 23:37:52.271101 29022 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0324 23:37:52.271107 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.271121 29022 net.cpp:184] Created Layer res3a_branch2a (17)
I0324 23:37:52.271128 29022 net.cpp:561] res3a_branch2a <- pool2
I0324 23:37:52.271134 29022 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0324 23:37:52.274257 29022 net.cpp:245] Setting up res3a_branch2a
I0324 23:37:52.274283 29022 net.cpp:252] TRAIN Top shape for layer 17 'res3a_branch2a' 8 128 40 96 (3932160)
I0324 23:37:52.274297 29022 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0324 23:37:52.274304 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.274314 29022 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0324 23:37:52.274320 29022 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0324 23:37:52.274327 29022 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0324 23:37:52.275004 29022 net.cpp:245] Setting up res3a_branch2a/bn
I0324 23:37:52.275019 29022 net.cpp:252] TRAIN Top shape for layer 18 'res3a_branch2a/bn' 8 128 40 96 (3932160)
I0324 23:37:52.275038 29022 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0324 23:37:52.275045 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.275053 29022 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0324 23:37:52.275058 29022 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0324 23:37:52.275064 29022 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0324 23:37:52.275072 29022 net.cpp:245] Setting up res3a_branch2a/relu
I0324 23:37:52.275079 29022 net.cpp:252] TRAIN Top shape for layer 19 'res3a_branch2a/relu' 8 128 40 96 (3932160)
I0324 23:37:52.275089 29022 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0324 23:37:52.275094 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.275107 29022 net.cpp:184] Created Layer res3a_branch2b (20)
I0324 23:37:52.275113 29022 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0324 23:37:52.275120 29022 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0324 23:37:52.276541 29022 net.cpp:245] Setting up res3a_branch2b
I0324 23:37:52.276557 29022 net.cpp:252] TRAIN Top shape for layer 20 'res3a_branch2b' 8 128 40 96 (3932160)
I0324 23:37:52.276569 29022 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0324 23:37:52.276576 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.276602 29022 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0324 23:37:52.276608 29022 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0324 23:37:52.276614 29022 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0324 23:37:52.277276 29022 net.cpp:245] Setting up res3a_branch2b/bn
I0324 23:37:52.277290 29022 net.cpp:252] TRAIN Top shape for layer 21 'res3a_branch2b/bn' 8 128 40 96 (3932160)
I0324 23:37:52.277307 29022 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0324 23:37:52.277313 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.277320 29022 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0324 23:37:52.277326 29022 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0324 23:37:52.277333 29022 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0324 23:37:52.277340 29022 net.cpp:245] Setting up res3a_branch2b/relu
I0324 23:37:52.277348 29022 net.cpp:252] TRAIN Top shape for layer 22 'res3a_branch2b/relu' 8 128 40 96 (3932160)
I0324 23:37:52.277353 29022 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0324 23:37:52.277359 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.277365 29022 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (23)
I0324 23:37:52.277370 29022 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0324 23:37:52.277376 29022 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0324 23:37:52.277385 29022 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0324 23:37:52.277432 29022 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0324 23:37:52.277452 29022 net.cpp:252] TRAIN Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 8 128 40 96 (3932160)
I0324 23:37:52.277460 29022 net.cpp:252] TRAIN Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 8 128 40 96 (3932160)
I0324 23:37:52.277465 29022 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0324 23:37:52.277472 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.277480 29022 net.cpp:184] Created Layer pool3 (24)
I0324 23:37:52.277487 29022 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0324 23:37:52.277493 29022 net.cpp:530] pool3 -> pool3
I0324 23:37:52.277556 29022 net.cpp:245] Setting up pool3
I0324 23:37:52.277568 29022 net.cpp:252] TRAIN Top shape for layer 24 'pool3' 8 128 20 48 (983040)
I0324 23:37:52.277575 29022 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0324 23:37:52.277580 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.277596 29022 net.cpp:184] Created Layer res4a_branch2a (25)
I0324 23:37:52.277603 29022 net.cpp:561] res4a_branch2a <- pool3
I0324 23:37:52.277609 29022 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0324 23:37:52.288202 29022 net.cpp:245] Setting up res4a_branch2a
I0324 23:37:52.288234 29022 net.cpp:252] TRAIN Top shape for layer 25 'res4a_branch2a' 8 256 20 48 (1966080)
I0324 23:37:52.288249 29022 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0324 23:37:52.288256 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.288271 29022 net.cpp:184] Created Layer res4a_branch2a/bn (26)
I0324 23:37:52.288280 29022 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0324 23:37:52.288287 29022 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0324 23:37:52.288974 29022 net.cpp:245] Setting up res4a_branch2a/bn
I0324 23:37:52.288990 29022 net.cpp:252] TRAIN Top shape for layer 26 'res4a_branch2a/bn' 8 256 20 48 (1966080)
I0324 23:37:52.289002 29022 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0324 23:37:52.289010 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.289017 29022 net.cpp:184] Created Layer res4a_branch2a/relu (27)
I0324 23:37:52.289026 29022 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0324 23:37:52.289033 29022 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0324 23:37:52.289042 29022 net.cpp:245] Setting up res4a_branch2a/relu
I0324 23:37:52.289048 29022 net.cpp:252] TRAIN Top shape for layer 27 'res4a_branch2a/relu' 8 256 20 48 (1966080)
I0324 23:37:52.289054 29022 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0324 23:37:52.289060 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.289075 29022 net.cpp:184] Created Layer res4a_branch2b (28)
I0324 23:37:52.289082 29022 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0324 23:37:52.289088 29022 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0324 23:37:52.294188 29022 net.cpp:245] Setting up res4a_branch2b
I0324 23:37:52.294219 29022 net.cpp:252] TRAIN Top shape for layer 28 'res4a_branch2b' 8 256 20 48 (1966080)
I0324 23:37:52.294234 29022 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0324 23:37:52.294242 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.294256 29022 net.cpp:184] Created Layer res4a_branch2b/bn (29)
I0324 23:37:52.294263 29022 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0324 23:37:52.294271 29022 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0324 23:37:52.294962 29022 net.cpp:245] Setting up res4a_branch2b/bn
I0324 23:37:52.294977 29022 net.cpp:252] TRAIN Top shape for layer 29 'res4a_branch2b/bn' 8 256 20 48 (1966080)
I0324 23:37:52.294991 29022 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0324 23:37:52.295017 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.295025 29022 net.cpp:184] Created Layer res4a_branch2b/relu (30)
I0324 23:37:52.295033 29022 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0324 23:37:52.295040 29022 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0324 23:37:52.295049 29022 net.cpp:245] Setting up res4a_branch2b/relu
I0324 23:37:52.295056 29022 net.cpp:252] TRAIN Top shape for layer 30 'res4a_branch2b/relu' 8 256 20 48 (1966080)
I0324 23:37:52.295063 29022 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0324 23:37:52.295068 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.295078 29022 net.cpp:184] Created Layer pool4 (31)
I0324 23:37:52.295083 29022 net.cpp:561] pool4 <- res4a_branch2b
I0324 23:37:52.295089 29022 net.cpp:530] pool4 -> pool4
I0324 23:37:52.295155 29022 net.cpp:245] Setting up pool4
I0324 23:37:52.295167 29022 net.cpp:252] TRAIN Top shape for layer 31 'pool4' 8 256 10 24 (491520)
I0324 23:37:52.295173 29022 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0324 23:37:52.295179 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.295197 29022 net.cpp:184] Created Layer res5a_branch2a (32)
I0324 23:37:52.295202 29022 net.cpp:561] res5a_branch2a <- pool4
I0324 23:37:52.295208 29022 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0324 23:37:52.334529 29022 net.cpp:245] Setting up res5a_branch2a
I0324 23:37:52.334563 29022 net.cpp:252] TRAIN Top shape for layer 32 'res5a_branch2a' 8 512 10 24 (983040)
I0324 23:37:52.334578 29022 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0324 23:37:52.334586 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.334600 29022 net.cpp:184] Created Layer res5a_branch2a/bn (33)
I0324 23:37:52.334609 29022 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0324 23:37:52.334616 29022 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0324 23:37:52.335295 29022 net.cpp:245] Setting up res5a_branch2a/bn
I0324 23:37:52.335310 29022 net.cpp:252] TRAIN Top shape for layer 33 'res5a_branch2a/bn' 8 512 10 24 (983040)
I0324 23:37:52.335326 29022 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0324 23:37:52.335333 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.335341 29022 net.cpp:184] Created Layer res5a_branch2a/relu (34)
I0324 23:37:52.335347 29022 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0324 23:37:52.335355 29022 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0324 23:37:52.335363 29022 net.cpp:245] Setting up res5a_branch2a/relu
I0324 23:37:52.335373 29022 net.cpp:252] TRAIN Top shape for layer 34 'res5a_branch2a/relu' 8 512 10 24 (983040)
I0324 23:37:52.335379 29022 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0324 23:37:52.335386 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.335400 29022 net.cpp:184] Created Layer res5a_branch2b (35)
I0324 23:37:52.335407 29022 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0324 23:37:52.335412 29022 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0324 23:37:52.355118 29022 net.cpp:245] Setting up res5a_branch2b
I0324 23:37:52.355165 29022 net.cpp:252] TRAIN Top shape for layer 35 'res5a_branch2b' 8 512 10 24 (983040)
I0324 23:37:52.355188 29022 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0324 23:37:52.355197 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.355213 29022 net.cpp:184] Created Layer res5a_branch2b/bn (36)
I0324 23:37:52.355226 29022 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0324 23:37:52.355257 29022 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0324 23:37:52.355996 29022 net.cpp:245] Setting up res5a_branch2b/bn
I0324 23:37:52.356017 29022 net.cpp:252] TRAIN Top shape for layer 36 'res5a_branch2b/bn' 8 512 10 24 (983040)
I0324 23:37:52.356032 29022 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0324 23:37:52.356040 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.356050 29022 net.cpp:184] Created Layer res5a_branch2b/relu (37)
I0324 23:37:52.356055 29022 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0324 23:37:52.356062 29022 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0324 23:37:52.356071 29022 net.cpp:245] Setting up res5a_branch2b/relu
I0324 23:37:52.356083 29022 net.cpp:252] TRAIN Top shape for layer 37 'res5a_branch2b/relu' 8 512 10 24 (983040)
I0324 23:37:52.356094 29022 layer_factory.hpp:136] Creating layer 'res5a_branch2b_res5a_branch2b/relu_0_split' of type 'Split'
I0324 23:37:52.356106 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.356142 29022 net.cpp:184] Created Layer res5a_branch2b_res5a_branch2b/relu_0_split (38)
I0324 23:37:52.356153 29022 net.cpp:561] res5a_branch2b_res5a_branch2b/relu_0_split <- res5a_branch2b
I0324 23:37:52.356160 29022 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_0
I0324 23:37:52.356168 29022 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_1
I0324 23:37:52.356218 29022 net.cpp:245] Setting up res5a_branch2b_res5a_branch2b/relu_0_split
I0324 23:37:52.356231 29022 net.cpp:252] TRAIN Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 8 512 10 24 (983040)
I0324 23:37:52.356238 29022 net.cpp:252] TRAIN Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 8 512 10 24 (983040)
I0324 23:37:52.356245 29022 layer_factory.hpp:136] Creating layer 'pool6' of type 'Pooling'
I0324 23:37:52.356251 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.356263 29022 net.cpp:184] Created Layer pool6 (39)
I0324 23:37:52.356269 29022 net.cpp:561] pool6 <- res5a_branch2b_res5a_branch2b/relu_0_split_0
I0324 23:37:52.356276 29022 net.cpp:530] pool6 -> pool6
I0324 23:37:52.356338 29022 net.cpp:245] Setting up pool6
I0324 23:37:52.356350 29022 net.cpp:252] TRAIN Top shape for layer 39 'pool6' 8 512 5 12 (245760)
I0324 23:37:52.356357 29022 layer_factory.hpp:136] Creating layer 'pool6_pool6_0_split' of type 'Split'
I0324 23:37:52.356364 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.356370 29022 net.cpp:184] Created Layer pool6_pool6_0_split (40)
I0324 23:37:52.356375 29022 net.cpp:561] pool6_pool6_0_split <- pool6
I0324 23:37:52.356381 29022 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_0
I0324 23:37:52.356389 29022 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_1
I0324 23:37:52.356431 29022 net.cpp:245] Setting up pool6_pool6_0_split
I0324 23:37:52.356442 29022 net.cpp:252] TRAIN Top shape for layer 40 'pool6_pool6_0_split' 8 512 5 12 (245760)
I0324 23:37:52.356449 29022 net.cpp:252] TRAIN Top shape for layer 40 'pool6_pool6_0_split' 8 512 5 12 (245760)
I0324 23:37:52.356456 29022 layer_factory.hpp:136] Creating layer 'pool7' of type 'Pooling'
I0324 23:37:52.356462 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.356469 29022 net.cpp:184] Created Layer pool7 (41)
I0324 23:37:52.356475 29022 net.cpp:561] pool7 <- pool6_pool6_0_split_0
I0324 23:37:52.356482 29022 net.cpp:530] pool7 -> pool7
I0324 23:37:52.356540 29022 net.cpp:245] Setting up pool7
I0324 23:37:52.356552 29022 net.cpp:252] TRAIN Top shape for layer 41 'pool7' 8 512 3 6 (73728)
I0324 23:37:52.356559 29022 layer_factory.hpp:136] Creating layer 'pool7_pool7_0_split' of type 'Split'
I0324 23:37:52.356575 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.356583 29022 net.cpp:184] Created Layer pool7_pool7_0_split (42)
I0324 23:37:52.356590 29022 net.cpp:561] pool7_pool7_0_split <- pool7
I0324 23:37:52.356595 29022 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_0
I0324 23:37:52.356603 29022 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_1
I0324 23:37:52.356648 29022 net.cpp:245] Setting up pool7_pool7_0_split
I0324 23:37:52.356660 29022 net.cpp:252] TRAIN Top shape for layer 42 'pool7_pool7_0_split' 8 512 3 6 (73728)
I0324 23:37:52.356667 29022 net.cpp:252] TRAIN Top shape for layer 42 'pool7_pool7_0_split' 8 512 3 6 (73728)
I0324 23:37:52.356673 29022 layer_factory.hpp:136] Creating layer 'pool8' of type 'Pooling'
I0324 23:37:52.356679 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.356688 29022 net.cpp:184] Created Layer pool8 (43)
I0324 23:37:52.356694 29022 net.cpp:561] pool8 <- pool7_pool7_0_split_0
I0324 23:37:52.356700 29022 net.cpp:530] pool8 -> pool8
I0324 23:37:52.356758 29022 net.cpp:245] Setting up pool8
I0324 23:37:52.356771 29022 net.cpp:252] TRAIN Top shape for layer 43 'pool8' 8 512 2 3 (24576)
I0324 23:37:52.356777 29022 layer_factory.hpp:136] Creating layer 'pool8_pool8_0_split' of type 'Split'
I0324 23:37:52.356783 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.356789 29022 net.cpp:184] Created Layer pool8_pool8_0_split (44)
I0324 23:37:52.356796 29022 net.cpp:561] pool8_pool8_0_split <- pool8
I0324 23:37:52.356801 29022 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_0
I0324 23:37:52.356807 29022 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_1
I0324 23:37:52.356850 29022 net.cpp:245] Setting up pool8_pool8_0_split
I0324 23:37:52.356861 29022 net.cpp:252] TRAIN Top shape for layer 44 'pool8_pool8_0_split' 8 512 2 3 (24576)
I0324 23:37:52.356868 29022 net.cpp:252] TRAIN Top shape for layer 44 'pool8_pool8_0_split' 8 512 2 3 (24576)
I0324 23:37:52.356874 29022 layer_factory.hpp:136] Creating layer 'pool9' of type 'Pooling'
I0324 23:37:52.356880 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.356889 29022 net.cpp:184] Created Layer pool9 (45)
I0324 23:37:52.356894 29022 net.cpp:561] pool9 <- pool8_pool8_0_split_0
I0324 23:37:52.356900 29022 net.cpp:530] pool9 -> pool9
I0324 23:37:52.356959 29022 net.cpp:245] Setting up pool9
I0324 23:37:52.356971 29022 net.cpp:252] TRAIN Top shape for layer 45 'pool9' 8 512 1 2 (8192)
I0324 23:37:52.356979 29022 layer_factory.hpp:136] Creating layer 'ctx_output1' of type 'Convolution'
I0324 23:37:52.356986 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.357002 29022 net.cpp:184] Created Layer ctx_output1 (46)
I0324 23:37:52.357008 29022 net.cpp:561] ctx_output1 <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0324 23:37:52.357015 29022 net.cpp:530] ctx_output1 -> ctx_output1
I0324 23:37:52.358364 29022 net.cpp:245] Setting up ctx_output1
I0324 23:37:52.358381 29022 net.cpp:252] TRAIN Top shape for layer 46 'ctx_output1' 8 256 40 96 (7864320)
I0324 23:37:52.358393 29022 layer_factory.hpp:136] Creating layer 'ctx_output1/relu' of type 'ReLU'
I0324 23:37:52.358400 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.358407 29022 net.cpp:184] Created Layer ctx_output1/relu (47)
I0324 23:37:52.358413 29022 net.cpp:561] ctx_output1/relu <- ctx_output1
I0324 23:37:52.358419 29022 net.cpp:513] ctx_output1/relu -> ctx_output1 (in-place)
I0324 23:37:52.358428 29022 net.cpp:245] Setting up ctx_output1/relu
I0324 23:37:52.358434 29022 net.cpp:252] TRAIN Top shape for layer 47 'ctx_output1/relu' 8 256 40 96 (7864320)
I0324 23:37:52.358439 29022 layer_factory.hpp:136] Creating layer 'ctx_output1_ctx_output1/relu_0_split' of type 'Split'
I0324 23:37:52.358445 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.358463 29022 net.cpp:184] Created Layer ctx_output1_ctx_output1/relu_0_split (48)
I0324 23:37:52.358469 29022 net.cpp:561] ctx_output1_ctx_output1/relu_0_split <- ctx_output1
I0324 23:37:52.358474 29022 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_0
I0324 23:37:52.358481 29022 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_1
I0324 23:37:52.358491 29022 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_2
I0324 23:37:52.358552 29022 net.cpp:245] Setting up ctx_output1_ctx_output1/relu_0_split
I0324 23:37:52.358564 29022 net.cpp:252] TRAIN Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 8 256 40 96 (7864320)
I0324 23:37:52.358572 29022 net.cpp:252] TRAIN Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 8 256 40 96 (7864320)
I0324 23:37:52.358578 29022 net.cpp:252] TRAIN Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 8 256 40 96 (7864320)
I0324 23:37:52.358584 29022 layer_factory.hpp:136] Creating layer 'ctx_output2' of type 'Convolution'
I0324 23:37:52.358589 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.358603 29022 net.cpp:184] Created Layer ctx_output2 (49)
I0324 23:37:52.358611 29022 net.cpp:561] ctx_output2 <- res5a_branch2b_res5a_branch2b/relu_0_split_1
I0324 23:37:52.358618 29022 net.cpp:530] ctx_output2 -> ctx_output2
I0324 23:37:52.363021 29022 net.cpp:245] Setting up ctx_output2
I0324 23:37:52.363037 29022 net.cpp:252] TRAIN Top shape for layer 49 'ctx_output2' 8 256 10 24 (491520)
I0324 23:37:52.363050 29022 layer_factory.hpp:136] Creating layer 'ctx_output2/relu' of type 'ReLU'
I0324 23:37:52.363057 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.363065 29022 net.cpp:184] Created Layer ctx_output2/relu (50)
I0324 23:37:52.363070 29022 net.cpp:561] ctx_output2/relu <- ctx_output2
I0324 23:37:52.363076 29022 net.cpp:513] ctx_output2/relu -> ctx_output2 (in-place)
I0324 23:37:52.363085 29022 net.cpp:245] Setting up ctx_output2/relu
I0324 23:37:52.363091 29022 net.cpp:252] TRAIN Top shape for layer 50 'ctx_output2/relu' 8 256 10 24 (491520)
I0324 23:37:52.363097 29022 layer_factory.hpp:136] Creating layer 'ctx_output2_ctx_output2/relu_0_split' of type 'Split'
I0324 23:37:52.363102 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.363108 29022 net.cpp:184] Created Layer ctx_output2_ctx_output2/relu_0_split (51)
I0324 23:37:52.363114 29022 net.cpp:561] ctx_output2_ctx_output2/relu_0_split <- ctx_output2
I0324 23:37:52.363121 29022 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_0
I0324 23:37:52.363126 29022 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_1
I0324 23:37:52.363135 29022 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_2
I0324 23:37:52.363198 29022 net.cpp:245] Setting up ctx_output2_ctx_output2/relu_0_split
I0324 23:37:52.363209 29022 net.cpp:252] TRAIN Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 8 256 10 24 (491520)
I0324 23:37:52.363216 29022 net.cpp:252] TRAIN Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 8 256 10 24 (491520)
I0324 23:37:52.363222 29022 net.cpp:252] TRAIN Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 8 256 10 24 (491520)
I0324 23:37:52.363230 29022 layer_factory.hpp:136] Creating layer 'ctx_output3' of type 'Convolution'
I0324 23:37:52.363236 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.363250 29022 net.cpp:184] Created Layer ctx_output3 (52)
I0324 23:37:52.363256 29022 net.cpp:561] ctx_output3 <- pool6_pool6_0_split_1
I0324 23:37:52.363262 29022 net.cpp:530] ctx_output3 -> ctx_output3
I0324 23:37:52.368592 29022 net.cpp:245] Setting up ctx_output3
I0324 23:37:52.368623 29022 net.cpp:252] TRAIN Top shape for layer 52 'ctx_output3' 8 256 5 12 (122880)
I0324 23:37:52.368638 29022 layer_factory.hpp:136] Creating layer 'ctx_output3/relu' of type 'ReLU'
I0324 23:37:52.368644 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.368652 29022 net.cpp:184] Created Layer ctx_output3/relu (53)
I0324 23:37:52.368659 29022 net.cpp:561] ctx_output3/relu <- ctx_output3
I0324 23:37:52.368665 29022 net.cpp:513] ctx_output3/relu -> ctx_output3 (in-place)
I0324 23:37:52.368674 29022 net.cpp:245] Setting up ctx_output3/relu
I0324 23:37:52.368680 29022 net.cpp:252] TRAIN Top shape for layer 53 'ctx_output3/relu' 8 256 5 12 (122880)
I0324 23:37:52.368686 29022 layer_factory.hpp:136] Creating layer 'ctx_output3_ctx_output3/relu_0_split' of type 'Split'
I0324 23:37:52.368692 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.368702 29022 net.cpp:184] Created Layer ctx_output3_ctx_output3/relu_0_split (54)
I0324 23:37:52.368708 29022 net.cpp:561] ctx_output3_ctx_output3/relu_0_split <- ctx_output3
I0324 23:37:52.368715 29022 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_0
I0324 23:37:52.368721 29022 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_1
I0324 23:37:52.368727 29022 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_2
I0324 23:37:52.368790 29022 net.cpp:245] Setting up ctx_output3_ctx_output3/relu_0_split
I0324 23:37:52.368803 29022 net.cpp:252] TRAIN Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 8 256 5 12 (122880)
I0324 23:37:52.368810 29022 net.cpp:252] TRAIN Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 8 256 5 12 (122880)
I0324 23:37:52.368816 29022 net.cpp:252] TRAIN Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 8 256 5 12 (122880)
I0324 23:37:52.368822 29022 layer_factory.hpp:136] Creating layer 'ctx_output4' of type 'Convolution'
I0324 23:37:52.368830 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.368844 29022 net.cpp:184] Created Layer ctx_output4 (55)
I0324 23:37:52.368851 29022 net.cpp:561] ctx_output4 <- pool7_pool7_0_split_1
I0324 23:37:52.368858 29022 net.cpp:530] ctx_output4 -> ctx_output4
I0324 23:37:52.373229 29022 net.cpp:245] Setting up ctx_output4
I0324 23:37:52.373245 29022 net.cpp:252] TRAIN Top shape for layer 55 'ctx_output4' 8 256 3 6 (36864)
I0324 23:37:52.373255 29022 layer_factory.hpp:136] Creating layer 'ctx_output4/relu' of type 'ReLU'
I0324 23:37:52.373263 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.373271 29022 net.cpp:184] Created Layer ctx_output4/relu (56)
I0324 23:37:52.373277 29022 net.cpp:561] ctx_output4/relu <- ctx_output4
I0324 23:37:52.373283 29022 net.cpp:513] ctx_output4/relu -> ctx_output4 (in-place)
I0324 23:37:52.373291 29022 net.cpp:245] Setting up ctx_output4/relu
I0324 23:37:52.373298 29022 net.cpp:252] TRAIN Top shape for layer 56 'ctx_output4/relu' 8 256 3 6 (36864)
I0324 23:37:52.373304 29022 layer_factory.hpp:136] Creating layer 'ctx_output4_ctx_output4/relu_0_split' of type 'Split'
I0324 23:37:52.373309 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.373317 29022 net.cpp:184] Created Layer ctx_output4_ctx_output4/relu_0_split (57)
I0324 23:37:52.373322 29022 net.cpp:561] ctx_output4_ctx_output4/relu_0_split <- ctx_output4
I0324 23:37:52.373327 29022 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_0
I0324 23:37:52.373334 29022 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_1
I0324 23:37:52.373340 29022 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_2
I0324 23:37:52.373406 29022 net.cpp:245] Setting up ctx_output4_ctx_output4/relu_0_split
I0324 23:37:52.373428 29022 net.cpp:252] TRAIN Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 8 256 3 6 (36864)
I0324 23:37:52.373436 29022 net.cpp:252] TRAIN Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 8 256 3 6 (36864)
I0324 23:37:52.373442 29022 net.cpp:252] TRAIN Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 8 256 3 6 (36864)
I0324 23:37:52.373447 29022 layer_factory.hpp:136] Creating layer 'ctx_output5' of type 'Convolution'
I0324 23:37:52.373453 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.373467 29022 net.cpp:184] Created Layer ctx_output5 (58)
I0324 23:37:52.373474 29022 net.cpp:561] ctx_output5 <- pool8_pool8_0_split_1
I0324 23:37:52.373481 29022 net.cpp:530] ctx_output5 -> ctx_output5
I0324 23:37:52.378058 29022 net.cpp:245] Setting up ctx_output5
I0324 23:37:52.378087 29022 net.cpp:252] TRAIN Top shape for layer 58 'ctx_output5' 8 256 2 3 (12288)
I0324 23:37:52.378101 29022 layer_factory.hpp:136] Creating layer 'ctx_output5/relu' of type 'ReLU'
I0324 23:37:52.378109 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.378119 29022 net.cpp:184] Created Layer ctx_output5/relu (59)
I0324 23:37:52.378130 29022 net.cpp:561] ctx_output5/relu <- ctx_output5
I0324 23:37:52.378139 29022 net.cpp:513] ctx_output5/relu -> ctx_output5 (in-place)
I0324 23:37:52.378149 29022 net.cpp:245] Setting up ctx_output5/relu
I0324 23:37:52.378155 29022 net.cpp:252] TRAIN Top shape for layer 59 'ctx_output5/relu' 8 256 2 3 (12288)
I0324 23:37:52.378160 29022 layer_factory.hpp:136] Creating layer 'ctx_output5_ctx_output5/relu_0_split' of type 'Split'
I0324 23:37:52.378166 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.378173 29022 net.cpp:184] Created Layer ctx_output5_ctx_output5/relu_0_split (60)
I0324 23:37:52.378178 29022 net.cpp:561] ctx_output5_ctx_output5/relu_0_split <- ctx_output5
I0324 23:37:52.378185 29022 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_0
I0324 23:37:52.378192 29022 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_1
I0324 23:37:52.378198 29022 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_2
I0324 23:37:52.378278 29022 net.cpp:245] Setting up ctx_output5_ctx_output5/relu_0_split
I0324 23:37:52.378295 29022 net.cpp:252] TRAIN Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 8 256 2 3 (12288)
I0324 23:37:52.378309 29022 net.cpp:252] TRAIN Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 8 256 2 3 (12288)
I0324 23:37:52.378326 29022 net.cpp:252] TRAIN Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 8 256 2 3 (12288)
I0324 23:37:52.378342 29022 layer_factory.hpp:136] Creating layer 'ctx_output6' of type 'Convolution'
I0324 23:37:52.378351 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.378366 29022 net.cpp:184] Created Layer ctx_output6 (61)
I0324 23:37:52.378373 29022 net.cpp:561] ctx_output6 <- pool9
I0324 23:37:52.378381 29022 net.cpp:530] ctx_output6 -> ctx_output6
I0324 23:37:52.382769 29022 net.cpp:245] Setting up ctx_output6
I0324 23:37:52.382786 29022 net.cpp:252] TRAIN Top shape for layer 61 'ctx_output6' 8 256 1 2 (4096)
I0324 23:37:52.382797 29022 layer_factory.hpp:136] Creating layer 'ctx_output6/relu' of type 'ReLU'
I0324 23:37:52.382802 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.382810 29022 net.cpp:184] Created Layer ctx_output6/relu (62)
I0324 23:37:52.382817 29022 net.cpp:561] ctx_output6/relu <- ctx_output6
I0324 23:37:52.382823 29022 net.cpp:513] ctx_output6/relu -> ctx_output6 (in-place)
I0324 23:37:52.382832 29022 net.cpp:245] Setting up ctx_output6/relu
I0324 23:37:52.382838 29022 net.cpp:252] TRAIN Top shape for layer 62 'ctx_output6/relu' 8 256 1 2 (4096)
I0324 23:37:52.382861 29022 layer_factory.hpp:136] Creating layer 'ctx_output6_ctx_output6/relu_0_split' of type 'Split'
I0324 23:37:52.382874 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.382890 29022 net.cpp:184] Created Layer ctx_output6_ctx_output6/relu_0_split (63)
I0324 23:37:52.382903 29022 net.cpp:561] ctx_output6_ctx_output6/relu_0_split <- ctx_output6
I0324 23:37:52.382915 29022 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_0
I0324 23:37:52.382931 29022 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_1
I0324 23:37:52.382949 29022 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_2
I0324 23:37:52.383028 29022 net.cpp:245] Setting up ctx_output6_ctx_output6/relu_0_split
I0324 23:37:52.383044 29022 net.cpp:252] TRAIN Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 8 256 1 2 (4096)
I0324 23:37:52.383062 29022 net.cpp:252] TRAIN Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 8 256 1 2 (4096)
I0324 23:37:52.383071 29022 net.cpp:252] TRAIN Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 8 256 1 2 (4096)
I0324 23:37:52.383078 29022 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc' of type 'Convolution'
I0324 23:37:52.383085 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.383100 29022 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc (64)
I0324 23:37:52.383107 29022 net.cpp:561] ctx_output1/relu_mbox_loc <- ctx_output1_ctx_output1/relu_0_split_0
I0324 23:37:52.383114 29022 net.cpp:530] ctx_output1/relu_mbox_loc -> ctx_output1/relu_mbox_loc
I0324 23:37:52.383558 29022 net.cpp:245] Setting up ctx_output1/relu_mbox_loc
I0324 23:37:52.383574 29022 net.cpp:252] TRAIN Top shape for layer 64 'ctx_output1/relu_mbox_loc' 8 16 40 96 (491520)
I0324 23:37:52.383584 29022 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_perm' of type 'Permute'
I0324 23:37:52.383590 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.383612 29022 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_perm (65)
I0324 23:37:52.383620 29022 net.cpp:561] ctx_output1/relu_mbox_loc_perm <- ctx_output1/relu_mbox_loc
I0324 23:37:52.383627 29022 net.cpp:530] ctx_output1/relu_mbox_loc_perm -> ctx_output1/relu_mbox_loc_perm
I0324 23:37:52.383746 29022 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_perm
I0324 23:37:52.383759 29022 net.cpp:252] TRAIN Top shape for layer 65 'ctx_output1/relu_mbox_loc_perm' 8 40 96 16 (491520)
I0324 23:37:52.383766 29022 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_flat' of type 'Flatten'
I0324 23:37:52.383772 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.383785 29022 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_flat (66)
I0324 23:37:52.383791 29022 net.cpp:561] ctx_output1/relu_mbox_loc_flat <- ctx_output1/relu_mbox_loc_perm
I0324 23:37:52.383798 29022 net.cpp:530] ctx_output1/relu_mbox_loc_flat -> ctx_output1/relu_mbox_loc_flat
I0324 23:37:52.383832 29022 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_flat
I0324 23:37:52.383844 29022 net.cpp:252] TRAIN Top shape for layer 66 'ctx_output1/relu_mbox_loc_flat' 8 61440 (491520)
I0324 23:37:52.383852 29022 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf' of type 'Convolution'
I0324 23:37:52.383857 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.383878 29022 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf (67)
I0324 23:37:52.383893 29022 net.cpp:561] ctx_output1/relu_mbox_conf <- ctx_output1_ctx_output1/relu_0_split_1
I0324 23:37:52.383909 29022 net.cpp:530] ctx_output1/relu_mbox_conf -> ctx_output1/relu_mbox_conf
I0324 23:37:52.384369 29022 net.cpp:245] Setting up ctx_output1/relu_mbox_conf
I0324 23:37:52.384397 29022 net.cpp:252] TRAIN Top shape for layer 67 'ctx_output1/relu_mbox_conf' 8 16 40 96 (491520)
I0324 23:37:52.384418 29022 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_perm' of type 'Permute'
I0324 23:37:52.384428 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.384438 29022 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_perm (68)
I0324 23:37:52.384443 29022 net.cpp:561] ctx_output1/relu_mbox_conf_perm <- ctx_output1/relu_mbox_conf
I0324 23:37:52.384450 29022 net.cpp:530] ctx_output1/relu_mbox_conf_perm -> ctx_output1/relu_mbox_conf_perm
I0324 23:37:52.384567 29022 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_perm
I0324 23:37:52.384580 29022 net.cpp:252] TRAIN Top shape for layer 68 'ctx_output1/relu_mbox_conf_perm' 8 40 96 16 (491520)
I0324 23:37:52.384587 29022 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_flat' of type 'Flatten'
I0324 23:37:52.384593 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.384600 29022 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_flat (69)
I0324 23:37:52.384605 29022 net.cpp:561] ctx_output1/relu_mbox_conf_flat <- ctx_output1/relu_mbox_conf_perm
I0324 23:37:52.384613 29022 net.cpp:530] ctx_output1/relu_mbox_conf_flat -> ctx_output1/relu_mbox_conf_flat
I0324 23:37:52.384644 29022 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_flat
I0324 23:37:52.384654 29022 net.cpp:252] TRAIN Top shape for layer 69 'ctx_output1/relu_mbox_conf_flat' 8 61440 (491520)
I0324 23:37:52.384661 29022 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_priorbox' of type 'PriorBox'
I0324 23:37:52.384667 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.384682 29022 net.cpp:184] Created Layer ctx_output1/relu_mbox_priorbox (70)
I0324 23:37:52.384690 29022 net.cpp:561] ctx_output1/relu_mbox_priorbox <- ctx_output1_ctx_output1/relu_0_split_2
I0324 23:37:52.384696 29022 net.cpp:561] ctx_output1/relu_mbox_priorbox <- data_data_0_split_1
I0324 23:37:52.384703 29022 net.cpp:530] ctx_output1/relu_mbox_priorbox -> ctx_output1/relu_mbox_priorbox
I0324 23:37:52.384737 29022 net.cpp:245] Setting up ctx_output1/relu_mbox_priorbox
I0324 23:37:52.384749 29022 net.cpp:252] TRAIN Top shape for layer 70 'ctx_output1/relu_mbox_priorbox' 1 2 61440 (122880)
I0324 23:37:52.384755 29022 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc' of type 'Convolution'
I0324 23:37:52.384762 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.384774 29022 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc (71)
I0324 23:37:52.384781 29022 net.cpp:561] ctx_output2/relu_mbox_loc <- ctx_output2_ctx_output2/relu_0_split_0
I0324 23:37:52.384788 29022 net.cpp:530] ctx_output2/relu_mbox_loc -> ctx_output2/relu_mbox_loc
I0324 23:37:52.385298 29022 net.cpp:245] Setting up ctx_output2/relu_mbox_loc
I0324 23:37:52.385313 29022 net.cpp:252] TRAIN Top shape for layer 71 'ctx_output2/relu_mbox_loc' 8 24 10 24 (46080)
I0324 23:37:52.385324 29022 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_perm' of type 'Permute'
I0324 23:37:52.385329 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.385339 29022 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_perm (72)
I0324 23:37:52.385345 29022 net.cpp:561] ctx_output2/relu_mbox_loc_perm <- ctx_output2/relu_mbox_loc
I0324 23:37:52.385352 29022 net.cpp:530] ctx_output2/relu_mbox_loc_perm -> ctx_output2/relu_mbox_loc_perm
I0324 23:37:52.385473 29022 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_perm
I0324 23:37:52.385486 29022 net.cpp:252] TRAIN Top shape for layer 72 'ctx_output2/relu_mbox_loc_perm' 8 10 24 24 (46080)
I0324 23:37:52.385493 29022 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_flat' of type 'Flatten'
I0324 23:37:52.385499 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.385515 29022 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_flat (73)
I0324 23:37:52.385522 29022 net.cpp:561] ctx_output2/relu_mbox_loc_flat <- ctx_output2/relu_mbox_loc_perm
I0324 23:37:52.385529 29022 net.cpp:530] ctx_output2/relu_mbox_loc_flat -> ctx_output2/relu_mbox_loc_flat
I0324 23:37:52.385562 29022 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_flat
I0324 23:37:52.385576 29022 net.cpp:252] TRAIN Top shape for layer 73 'ctx_output2/relu_mbox_loc_flat' 8 5760 (46080)
I0324 23:37:52.385582 29022 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf' of type 'Convolution'
I0324 23:37:52.385588 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.385604 29022 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf (74)
I0324 23:37:52.385612 29022 net.cpp:561] ctx_output2/relu_mbox_conf <- ctx_output2_ctx_output2/relu_0_split_1
I0324 23:37:52.385618 29022 net.cpp:530] ctx_output2/relu_mbox_conf -> ctx_output2/relu_mbox_conf
I0324 23:37:52.386196 29022 net.cpp:245] Setting up ctx_output2/relu_mbox_conf
I0324 23:37:52.386224 29022 net.cpp:252] TRAIN Top shape for layer 74 'ctx_output2/relu_mbox_conf' 8 24 10 24 (46080)
I0324 23:37:52.386236 29022 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_perm' of type 'Permute'
I0324 23:37:52.386243 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.386255 29022 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_perm (75)
I0324 23:37:52.386262 29022 net.cpp:561] ctx_output2/relu_mbox_conf_perm <- ctx_output2/relu_mbox_conf
I0324 23:37:52.386270 29022 net.cpp:530] ctx_output2/relu_mbox_conf_perm -> ctx_output2/relu_mbox_conf_perm
I0324 23:37:52.386395 29022 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_perm
I0324 23:37:52.386409 29022 net.cpp:252] TRAIN Top shape for layer 75 'ctx_output2/relu_mbox_conf_perm' 8 10 24 24 (46080)
I0324 23:37:52.386415 29022 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_flat' of type 'Flatten'
I0324 23:37:52.386421 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.386430 29022 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_flat (76)
I0324 23:37:52.386435 29022 net.cpp:561] ctx_output2/relu_mbox_conf_flat <- ctx_output2/relu_mbox_conf_perm
I0324 23:37:52.386441 29022 net.cpp:530] ctx_output2/relu_mbox_conf_flat -> ctx_output2/relu_mbox_conf_flat
I0324 23:37:52.386472 29022 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_flat
I0324 23:37:52.386485 29022 net.cpp:252] TRAIN Top shape for layer 76 'ctx_output2/relu_mbox_conf_flat' 8 5760 (46080)
I0324 23:37:52.386492 29022 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_priorbox' of type 'PriorBox'
I0324 23:37:52.386498 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.386507 29022 net.cpp:184] Created Layer ctx_output2/relu_mbox_priorbox (77)
I0324 23:37:52.386513 29022 net.cpp:561] ctx_output2/relu_mbox_priorbox <- ctx_output2_ctx_output2/relu_0_split_2
I0324 23:37:52.386520 29022 net.cpp:561] ctx_output2/relu_mbox_priorbox <- data_data_0_split_2
I0324 23:37:52.386528 29022 net.cpp:530] ctx_output2/relu_mbox_priorbox -> ctx_output2/relu_mbox_priorbox
I0324 23:37:52.386562 29022 net.cpp:245] Setting up ctx_output2/relu_mbox_priorbox
I0324 23:37:52.386575 29022 net.cpp:252] TRAIN Top shape for layer 77 'ctx_output2/relu_mbox_priorbox' 1 2 5760 (11520)
I0324 23:37:52.386582 29022 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc' of type 'Convolution'
I0324 23:37:52.386589 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.386602 29022 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc (78)
I0324 23:37:52.386608 29022 net.cpp:561] ctx_output3/relu_mbox_loc <- ctx_output3_ctx_output3/relu_0_split_0
I0324 23:37:52.386615 29022 net.cpp:530] ctx_output3/relu_mbox_loc -> ctx_output3/relu_mbox_loc
I0324 23:37:52.387148 29022 net.cpp:245] Setting up ctx_output3/relu_mbox_loc
I0324 23:37:52.387163 29022 net.cpp:252] TRAIN Top shape for layer 78 'ctx_output3/relu_mbox_loc' 8 24 5 12 (11520)
I0324 23:37:52.387173 29022 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_perm' of type 'Permute'
I0324 23:37:52.387182 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.387192 29022 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_perm (79)
I0324 23:37:52.387198 29022 net.cpp:561] ctx_output3/relu_mbox_loc_perm <- ctx_output3/relu_mbox_loc
I0324 23:37:52.387204 29022 net.cpp:530] ctx_output3/relu_mbox_loc_perm -> ctx_output3/relu_mbox_loc_perm
I0324 23:37:52.387325 29022 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_perm
I0324 23:37:52.387337 29022 net.cpp:252] TRAIN Top shape for layer 79 'ctx_output3/relu_mbox_loc_perm' 8 5 12 24 (11520)
I0324 23:37:52.387343 29022 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_flat' of type 'Flatten'
I0324 23:37:52.387352 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.387359 29022 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_flat (80)
I0324 23:37:52.387365 29022 net.cpp:561] ctx_output3/relu_mbox_loc_flat <- ctx_output3/relu_mbox_loc_perm
I0324 23:37:52.387372 29022 net.cpp:530] ctx_output3/relu_mbox_loc_flat -> ctx_output3/relu_mbox_loc_flat
I0324 23:37:52.387403 29022 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_flat
I0324 23:37:52.387415 29022 net.cpp:252] TRAIN Top shape for layer 80 'ctx_output3/relu_mbox_loc_flat' 8 1440 (11520)
I0324 23:37:52.387421 29022 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf' of type 'Convolution'
I0324 23:37:52.387428 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.387440 29022 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf (81)
I0324 23:37:52.387447 29022 net.cpp:561] ctx_output3/relu_mbox_conf <- ctx_output3_ctx_output3/relu_0_split_1
I0324 23:37:52.387455 29022 net.cpp:530] ctx_output3/relu_mbox_conf -> ctx_output3/relu_mbox_conf
I0324 23:37:52.387960 29022 net.cpp:245] Setting up ctx_output3/relu_mbox_conf
I0324 23:37:52.387975 29022 net.cpp:252] TRAIN Top shape for layer 81 'ctx_output3/relu_mbox_conf' 8 24 5 12 (11520)
I0324 23:37:52.387987 29022 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_perm' of type 'Permute'
I0324 23:37:52.387995 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.388003 29022 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_perm (82)
I0324 23:37:52.388010 29022 net.cpp:561] ctx_output3/relu_mbox_conf_perm <- ctx_output3/relu_mbox_conf
I0324 23:37:52.388016 29022 net.cpp:530] ctx_output3/relu_mbox_conf_perm -> ctx_output3/relu_mbox_conf_perm
I0324 23:37:52.388134 29022 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_perm
I0324 23:37:52.388149 29022 net.cpp:252] TRAIN Top shape for layer 82 'ctx_output3/relu_mbox_conf_perm' 8 5 12 24 (11520)
I0324 23:37:52.388154 29022 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_flat' of type 'Flatten'
I0324 23:37:52.388160 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.388167 29022 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_flat (83)
I0324 23:37:52.388173 29022 net.cpp:561] ctx_output3/relu_mbox_conf_flat <- ctx_output3/relu_mbox_conf_perm
I0324 23:37:52.388180 29022 net.cpp:530] ctx_output3/relu_mbox_conf_flat -> ctx_output3/relu_mbox_conf_flat
I0324 23:37:52.388214 29022 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_flat
I0324 23:37:52.388224 29022 net.cpp:252] TRAIN Top shape for layer 83 'ctx_output3/relu_mbox_conf_flat' 8 1440 (11520)
I0324 23:37:52.388231 29022 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_priorbox' of type 'PriorBox'
I0324 23:37:52.388236 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.388257 29022 net.cpp:184] Created Layer ctx_output3/relu_mbox_priorbox (84)
I0324 23:37:52.388263 29022 net.cpp:561] ctx_output3/relu_mbox_priorbox <- ctx_output3_ctx_output3/relu_0_split_2
I0324 23:37:52.388270 29022 net.cpp:561] ctx_output3/relu_mbox_priorbox <- data_data_0_split_3
I0324 23:37:52.388279 29022 net.cpp:530] ctx_output3/relu_mbox_priorbox -> ctx_output3/relu_mbox_priorbox
I0324 23:37:52.388314 29022 net.cpp:245] Setting up ctx_output3/relu_mbox_priorbox
I0324 23:37:52.388324 29022 net.cpp:252] TRAIN Top shape for layer 84 'ctx_output3/relu_mbox_priorbox' 1 2 1440 (2880)
I0324 23:37:52.388332 29022 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc' of type 'Convolution'
I0324 23:37:52.388339 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.388351 29022 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc (85)
I0324 23:37:52.388360 29022 net.cpp:561] ctx_output4/relu_mbox_loc <- ctx_output4_ctx_output4/relu_0_split_0
I0324 23:37:52.388366 29022 net.cpp:530] ctx_output4/relu_mbox_loc -> ctx_output4/relu_mbox_loc
I0324 23:37:52.388957 29022 net.cpp:245] Setting up ctx_output4/relu_mbox_loc
I0324 23:37:52.388972 29022 net.cpp:252] TRAIN Top shape for layer 85 'ctx_output4/relu_mbox_loc' 8 24 3 6 (3456)
I0324 23:37:52.388983 29022 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_perm' of type 'Permute'
I0324 23:37:52.388988 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.388998 29022 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_perm (86)
I0324 23:37:52.389004 29022 net.cpp:561] ctx_output4/relu_mbox_loc_perm <- ctx_output4/relu_mbox_loc
I0324 23:37:52.389010 29022 net.cpp:530] ctx_output4/relu_mbox_loc_perm -> ctx_output4/relu_mbox_loc_perm
I0324 23:37:52.389137 29022 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_perm
I0324 23:37:52.389147 29022 net.cpp:252] TRAIN Top shape for layer 86 'ctx_output4/relu_mbox_loc_perm' 8 3 6 24 (3456)
I0324 23:37:52.389154 29022 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_flat' of type 'Flatten'
I0324 23:37:52.389160 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.389168 29022 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_flat (87)
I0324 23:37:52.389173 29022 net.cpp:561] ctx_output4/relu_mbox_loc_flat <- ctx_output4/relu_mbox_loc_perm
I0324 23:37:52.389183 29022 net.cpp:530] ctx_output4/relu_mbox_loc_flat -> ctx_output4/relu_mbox_loc_flat
I0324 23:37:52.389212 29022 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_flat
I0324 23:37:52.389222 29022 net.cpp:252] TRAIN Top shape for layer 87 'ctx_output4/relu_mbox_loc_flat' 8 432 (3456)
I0324 23:37:52.389228 29022 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf' of type 'Convolution'
I0324 23:37:52.389233 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.389246 29022 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf (88)
I0324 23:37:52.389252 29022 net.cpp:561] ctx_output4/relu_mbox_conf <- ctx_output4_ctx_output4/relu_0_split_1
I0324 23:37:52.389258 29022 net.cpp:530] ctx_output4/relu_mbox_conf -> ctx_output4/relu_mbox_conf
I0324 23:37:52.389775 29022 net.cpp:245] Setting up ctx_output4/relu_mbox_conf
I0324 23:37:52.389788 29022 net.cpp:252] TRAIN Top shape for layer 88 'ctx_output4/relu_mbox_conf' 8 24 3 6 (3456)
I0324 23:37:52.389798 29022 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_perm' of type 'Permute'
I0324 23:37:52.389804 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.389813 29022 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_perm (89)
I0324 23:37:52.389819 29022 net.cpp:561] ctx_output4/relu_mbox_conf_perm <- ctx_output4/relu_mbox_conf
I0324 23:37:52.389827 29022 net.cpp:530] ctx_output4/relu_mbox_conf_perm -> ctx_output4/relu_mbox_conf_perm
I0324 23:37:52.389956 29022 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_perm
I0324 23:37:52.389968 29022 net.cpp:252] TRAIN Top shape for layer 89 'ctx_output4/relu_mbox_conf_perm' 8 3 6 24 (3456)
I0324 23:37:52.389974 29022 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_flat' of type 'Flatten'
I0324 23:37:52.389981 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.389987 29022 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_flat (90)
I0324 23:37:52.389993 29022 net.cpp:561] ctx_output4/relu_mbox_conf_flat <- ctx_output4/relu_mbox_conf_perm
I0324 23:37:52.389999 29022 net.cpp:530] ctx_output4/relu_mbox_conf_flat -> ctx_output4/relu_mbox_conf_flat
I0324 23:37:52.390029 29022 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_flat
I0324 23:37:52.390038 29022 net.cpp:252] TRAIN Top shape for layer 90 'ctx_output4/relu_mbox_conf_flat' 8 432 (3456)
I0324 23:37:52.390044 29022 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_priorbox' of type 'PriorBox'
I0324 23:37:52.390050 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.390058 29022 net.cpp:184] Created Layer ctx_output4/relu_mbox_priorbox (91)
I0324 23:37:52.390064 29022 net.cpp:561] ctx_output4/relu_mbox_priorbox <- ctx_output4_ctx_output4/relu_0_split_2
I0324 23:37:52.390069 29022 net.cpp:561] ctx_output4/relu_mbox_priorbox <- data_data_0_split_4
I0324 23:37:52.390075 29022 net.cpp:530] ctx_output4/relu_mbox_priorbox -> ctx_output4/relu_mbox_priorbox
I0324 23:37:52.390105 29022 net.cpp:245] Setting up ctx_output4/relu_mbox_priorbox
I0324 23:37:52.390115 29022 net.cpp:252] TRAIN Top shape for layer 91 'ctx_output4/relu_mbox_priorbox' 1 2 432 (864)
I0324 23:37:52.390125 29022 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc' of type 'Convolution'
I0324 23:37:52.390131 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.390144 29022 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc (92)
I0324 23:37:52.390151 29022 net.cpp:561] ctx_output5/relu_mbox_loc <- ctx_output5_ctx_output5/relu_0_split_0
I0324 23:37:52.390157 29022 net.cpp:530] ctx_output5/relu_mbox_loc -> ctx_output5/relu_mbox_loc
I0324 23:37:52.390614 29022 net.cpp:245] Setting up ctx_output5/relu_mbox_loc
I0324 23:37:52.390626 29022 net.cpp:252] TRAIN Top shape for layer 92 'ctx_output5/relu_mbox_loc' 8 16 2 3 (768)
I0324 23:37:52.390635 29022 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_perm' of type 'Permute'
I0324 23:37:52.390641 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.390650 29022 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_perm (93)
I0324 23:37:52.390656 29022 net.cpp:561] ctx_output5/relu_mbox_loc_perm <- ctx_output5/relu_mbox_loc
I0324 23:37:52.390662 29022 net.cpp:530] ctx_output5/relu_mbox_loc_perm -> ctx_output5/relu_mbox_loc_perm
I0324 23:37:52.390779 29022 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_perm
I0324 23:37:52.390789 29022 net.cpp:252] TRAIN Top shape for layer 93 'ctx_output5/relu_mbox_loc_perm' 8 2 3 16 (768)
I0324 23:37:52.390794 29022 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_flat' of type 'Flatten'
I0324 23:37:52.390800 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.390807 29022 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_flat (94)
I0324 23:37:52.390812 29022 net.cpp:561] ctx_output5/relu_mbox_loc_flat <- ctx_output5/relu_mbox_loc_perm
I0324 23:37:52.390820 29022 net.cpp:530] ctx_output5/relu_mbox_loc_flat -> ctx_output5/relu_mbox_loc_flat
I0324 23:37:52.390848 29022 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_flat
I0324 23:37:52.390858 29022 net.cpp:252] TRAIN Top shape for layer 94 'ctx_output5/relu_mbox_loc_flat' 8 96 (768)
I0324 23:37:52.390863 29022 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf' of type 'Convolution'
I0324 23:37:52.390882 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.390897 29022 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf (95)
I0324 23:37:52.390902 29022 net.cpp:561] ctx_output5/relu_mbox_conf <- ctx_output5_ctx_output5/relu_0_split_1
I0324 23:37:52.390909 29022 net.cpp:530] ctx_output5/relu_mbox_conf -> ctx_output5/relu_mbox_conf
I0324 23:37:52.391360 29022 net.cpp:245] Setting up ctx_output5/relu_mbox_conf
I0324 23:37:52.391372 29022 net.cpp:252] TRAIN Top shape for layer 95 'ctx_output5/relu_mbox_conf' 8 16 2 3 (768)
I0324 23:37:52.391382 29022 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_perm' of type 'Permute'
I0324 23:37:52.391387 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.391397 29022 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_perm (96)
I0324 23:37:52.391403 29022 net.cpp:561] ctx_output5/relu_mbox_conf_perm <- ctx_output5/relu_mbox_conf
I0324 23:37:52.391409 29022 net.cpp:530] ctx_output5/relu_mbox_conf_perm -> ctx_output5/relu_mbox_conf_perm
I0324 23:37:52.391532 29022 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_perm
I0324 23:37:52.391543 29022 net.cpp:252] TRAIN Top shape for layer 96 'ctx_output5/relu_mbox_conf_perm' 8 2 3 16 (768)
I0324 23:37:52.391551 29022 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_flat' of type 'Flatten'
I0324 23:37:52.391556 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.391563 29022 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_flat (97)
I0324 23:37:52.391568 29022 net.cpp:561] ctx_output5/relu_mbox_conf_flat <- ctx_output5/relu_mbox_conf_perm
I0324 23:37:52.391578 29022 net.cpp:530] ctx_output5/relu_mbox_conf_flat -> ctx_output5/relu_mbox_conf_flat
I0324 23:37:52.391609 29022 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_flat
I0324 23:37:52.391619 29022 net.cpp:252] TRAIN Top shape for layer 97 'ctx_output5/relu_mbox_conf_flat' 8 96 (768)
I0324 23:37:52.391625 29022 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_priorbox' of type 'PriorBox'
I0324 23:37:52.391633 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.391643 29022 net.cpp:184] Created Layer ctx_output5/relu_mbox_priorbox (98)
I0324 23:37:52.391649 29022 net.cpp:561] ctx_output5/relu_mbox_priorbox <- ctx_output5_ctx_output5/relu_0_split_2
I0324 23:37:52.391654 29022 net.cpp:561] ctx_output5/relu_mbox_priorbox <- data_data_0_split_5
I0324 23:37:52.391661 29022 net.cpp:530] ctx_output5/relu_mbox_priorbox -> ctx_output5/relu_mbox_priorbox
I0324 23:37:52.391692 29022 net.cpp:245] Setting up ctx_output5/relu_mbox_priorbox
I0324 23:37:52.391705 29022 net.cpp:252] TRAIN Top shape for layer 98 'ctx_output5/relu_mbox_priorbox' 1 2 96 (192)
I0324 23:37:52.391711 29022 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc' of type 'Convolution'
I0324 23:37:52.391716 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.391729 29022 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc (99)
I0324 23:37:52.391736 29022 net.cpp:561] ctx_output6/relu_mbox_loc <- ctx_output6_ctx_output6/relu_0_split_0
I0324 23:37:52.391742 29022 net.cpp:530] ctx_output6/relu_mbox_loc -> ctx_output6/relu_mbox_loc
I0324 23:37:52.392180 29022 net.cpp:245] Setting up ctx_output6/relu_mbox_loc
I0324 23:37:52.392197 29022 net.cpp:252] TRAIN Top shape for layer 99 'ctx_output6/relu_mbox_loc' 8 16 1 2 (256)
I0324 23:37:52.392206 29022 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_perm' of type 'Permute'
I0324 23:37:52.392212 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.392221 29022 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_perm (100)
I0324 23:37:52.392227 29022 net.cpp:561] ctx_output6/relu_mbox_loc_perm <- ctx_output6/relu_mbox_loc
I0324 23:37:52.392243 29022 net.cpp:530] ctx_output6/relu_mbox_loc_perm -> ctx_output6/relu_mbox_loc_perm
I0324 23:37:52.392369 29022 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_perm
I0324 23:37:52.392379 29022 net.cpp:252] TRAIN Top shape for layer 100 'ctx_output6/relu_mbox_loc_perm' 8 1 2 16 (256)
I0324 23:37:52.392385 29022 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_flat' of type 'Flatten'
I0324 23:37:52.392391 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.392398 29022 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_flat (101)
I0324 23:37:52.392403 29022 net.cpp:561] ctx_output6/relu_mbox_loc_flat <- ctx_output6/relu_mbox_loc_perm
I0324 23:37:52.392410 29022 net.cpp:530] ctx_output6/relu_mbox_loc_flat -> ctx_output6/relu_mbox_loc_flat
I0324 23:37:52.392439 29022 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_flat
I0324 23:37:52.392449 29022 net.cpp:252] TRAIN Top shape for layer 101 'ctx_output6/relu_mbox_loc_flat' 8 32 (256)
I0324 23:37:52.392455 29022 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf' of type 'Convolution'
I0324 23:37:52.392460 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.392472 29022 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf (102)
I0324 23:37:52.392478 29022 net.cpp:561] ctx_output6/relu_mbox_conf <- ctx_output6_ctx_output6/relu_0_split_1
I0324 23:37:52.392485 29022 net.cpp:530] ctx_output6/relu_mbox_conf -> ctx_output6/relu_mbox_conf
I0324 23:37:52.392913 29022 net.cpp:245] Setting up ctx_output6/relu_mbox_conf
I0324 23:37:52.392926 29022 net.cpp:252] TRAIN Top shape for layer 102 'ctx_output6/relu_mbox_conf' 8 16 1 2 (256)
I0324 23:37:52.392935 29022 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_perm' of type 'Permute'
I0324 23:37:52.393004 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.393023 29022 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_perm (103)
I0324 23:37:52.393034 29022 net.cpp:561] ctx_output6/relu_mbox_conf_perm <- ctx_output6/relu_mbox_conf
I0324 23:37:52.393041 29022 net.cpp:530] ctx_output6/relu_mbox_conf_perm -> ctx_output6/relu_mbox_conf_perm
I0324 23:37:52.393159 29022 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_perm
I0324 23:37:52.393170 29022 net.cpp:252] TRAIN Top shape for layer 103 'ctx_output6/relu_mbox_conf_perm' 8 1 2 16 (256)
I0324 23:37:52.393177 29022 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_flat' of type 'Flatten'
I0324 23:37:52.393182 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.393189 29022 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_flat (104)
I0324 23:37:52.393198 29022 net.cpp:561] ctx_output6/relu_mbox_conf_flat <- ctx_output6/relu_mbox_conf_perm
I0324 23:37:52.393205 29022 net.cpp:530] ctx_output6/relu_mbox_conf_flat -> ctx_output6/relu_mbox_conf_flat
I0324 23:37:52.393235 29022 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_flat
I0324 23:37:52.393244 29022 net.cpp:252] TRAIN Top shape for layer 104 'ctx_output6/relu_mbox_conf_flat' 8 32 (256)
I0324 23:37:52.393250 29022 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_priorbox' of type 'PriorBox'
I0324 23:37:52.393255 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.393263 29022 net.cpp:184] Created Layer ctx_output6/relu_mbox_priorbox (105)
I0324 23:37:52.393270 29022 net.cpp:561] ctx_output6/relu_mbox_priorbox <- ctx_output6_ctx_output6/relu_0_split_2
I0324 23:37:52.393275 29022 net.cpp:561] ctx_output6/relu_mbox_priorbox <- data_data_0_split_6
I0324 23:37:52.393281 29022 net.cpp:530] ctx_output6/relu_mbox_priorbox -> ctx_output6/relu_mbox_priorbox
I0324 23:37:52.393311 29022 net.cpp:245] Setting up ctx_output6/relu_mbox_priorbox
I0324 23:37:52.393321 29022 net.cpp:252] TRAIN Top shape for layer 105 'ctx_output6/relu_mbox_priorbox' 1 2 32 (64)
I0324 23:37:52.393337 29022 layer_factory.hpp:136] Creating layer 'mbox_loc' of type 'Concat'
I0324 23:37:52.393343 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.393354 29022 net.cpp:184] Created Layer mbox_loc (106)
I0324 23:37:52.393360 29022 net.cpp:561] mbox_loc <- ctx_output1/relu_mbox_loc_flat
I0324 23:37:52.393366 29022 net.cpp:561] mbox_loc <- ctx_output2/relu_mbox_loc_flat
I0324 23:37:52.393373 29022 net.cpp:561] mbox_loc <- ctx_output3/relu_mbox_loc_flat
I0324 23:37:52.393378 29022 net.cpp:561] mbox_loc <- ctx_output4/relu_mbox_loc_flat
I0324 23:37:52.393384 29022 net.cpp:561] mbox_loc <- ctx_output5/relu_mbox_loc_flat
I0324 23:37:52.393390 29022 net.cpp:561] mbox_loc <- ctx_output6/relu_mbox_loc_flat
I0324 23:37:52.393395 29022 net.cpp:530] mbox_loc -> mbox_loc
I0324 23:37:52.393429 29022 net.cpp:245] Setting up mbox_loc
I0324 23:37:52.393438 29022 net.cpp:252] TRAIN Top shape for layer 106 'mbox_loc' 8 69200 (553600)
I0324 23:37:52.393443 29022 layer_factory.hpp:136] Creating layer 'mbox_conf' of type 'Concat'
I0324 23:37:52.393450 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.393456 29022 net.cpp:184] Created Layer mbox_conf (107)
I0324 23:37:52.393462 29022 net.cpp:561] mbox_conf <- ctx_output1/relu_mbox_conf_flat
I0324 23:37:52.393470 29022 net.cpp:561] mbox_conf <- ctx_output2/relu_mbox_conf_flat
I0324 23:37:52.393476 29022 net.cpp:561] mbox_conf <- ctx_output3/relu_mbox_conf_flat
I0324 23:37:52.393481 29022 net.cpp:561] mbox_conf <- ctx_output4/relu_mbox_conf_flat
I0324 23:37:52.393486 29022 net.cpp:561] mbox_conf <- ctx_output5/relu_mbox_conf_flat
I0324 23:37:52.393491 29022 net.cpp:561] mbox_conf <- ctx_output6/relu_mbox_conf_flat
I0324 23:37:52.393498 29022 net.cpp:530] mbox_conf -> mbox_conf
I0324 23:37:52.393528 29022 net.cpp:245] Setting up mbox_conf
I0324 23:37:52.393537 29022 net.cpp:252] TRAIN Top shape for layer 107 'mbox_conf' 8 69200 (553600)
I0324 23:37:52.393543 29022 layer_factory.hpp:136] Creating layer 'mbox_priorbox' of type 'Concat'
I0324 23:37:52.393549 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.393556 29022 net.cpp:184] Created Layer mbox_priorbox (108)
I0324 23:37:52.393561 29022 net.cpp:561] mbox_priorbox <- ctx_output1/relu_mbox_priorbox
I0324 23:37:52.393568 29022 net.cpp:561] mbox_priorbox <- ctx_output2/relu_mbox_priorbox
I0324 23:37:52.393573 29022 net.cpp:561] mbox_priorbox <- ctx_output3/relu_mbox_priorbox
I0324 23:37:52.393579 29022 net.cpp:561] mbox_priorbox <- ctx_output4/relu_mbox_priorbox
I0324 23:37:52.393584 29022 net.cpp:561] mbox_priorbox <- ctx_output5/relu_mbox_priorbox
I0324 23:37:52.393590 29022 net.cpp:561] mbox_priorbox <- ctx_output6/relu_mbox_priorbox
I0324 23:37:52.393595 29022 net.cpp:530] mbox_priorbox -> mbox_priorbox
I0324 23:37:52.393625 29022 net.cpp:245] Setting up mbox_priorbox
I0324 23:37:52.393633 29022 net.cpp:252] TRAIN Top shape for layer 108 'mbox_priorbox' 1 2 69200 (138400)
I0324 23:37:52.393640 29022 layer_factory.hpp:136] Creating layer 'mbox_loss' of type 'MultiBoxLoss'
I0324 23:37:52.393645 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.393658 29022 net.cpp:184] Created Layer mbox_loss (109)
I0324 23:37:52.393664 29022 net.cpp:561] mbox_loss <- mbox_loc
I0324 23:37:52.393671 29022 net.cpp:561] mbox_loss <- mbox_conf
I0324 23:37:52.393676 29022 net.cpp:561] mbox_loss <- mbox_priorbox
I0324 23:37:52.393682 29022 net.cpp:561] mbox_loss <- label
I0324 23:37:52.393687 29022 net.cpp:530] mbox_loss -> mbox_loss
I0324 23:37:52.393849 29022 layer_factory.hpp:136] Creating layer 'mbox_loss_smooth_L1_loc' of type 'SmoothL1Loss'
I0324 23:37:52.393860 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.394414 29022 layer_factory.hpp:136] Creating layer 'mbox_loss_softmax_conf' of type 'SoftmaxWithLoss'
I0324 23:37:52.394426 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.394659 29022 net.cpp:245] Setting up mbox_loss
I0324 23:37:52.394672 29022 net.cpp:252] TRAIN Top shape for layer 109 'mbox_loss' (1)
I0324 23:37:52.394678 29022 net.cpp:256]     with loss weight 1
I0324 23:37:52.394692 29022 net.cpp:323] mbox_loss needs backward computation.
I0324 23:37:52.394699 29022 net.cpp:325] mbox_priorbox does not need backward computation.
I0324 23:37:52.394706 29022 net.cpp:323] mbox_conf needs backward computation.
I0324 23:37:52.394711 29022 net.cpp:323] mbox_loc needs backward computation.
I0324 23:37:52.394717 29022 net.cpp:325] ctx_output6/relu_mbox_priorbox does not need backward computation.
I0324 23:37:52.394722 29022 net.cpp:323] ctx_output6/relu_mbox_conf_flat needs backward computation.
I0324 23:37:52.394727 29022 net.cpp:323] ctx_output6/relu_mbox_conf_perm needs backward computation.
I0324 23:37:52.394732 29022 net.cpp:323] ctx_output6/relu_mbox_conf needs backward computation.
I0324 23:37:52.394737 29022 net.cpp:323] ctx_output6/relu_mbox_loc_flat needs backward computation.
I0324 23:37:52.394742 29022 net.cpp:323] ctx_output6/relu_mbox_loc_perm needs backward computation.
I0324 23:37:52.394747 29022 net.cpp:323] ctx_output6/relu_mbox_loc needs backward computation.
I0324 23:37:52.394752 29022 net.cpp:325] ctx_output5/relu_mbox_priorbox does not need backward computation.
I0324 23:37:52.394757 29022 net.cpp:323] ctx_output5/relu_mbox_conf_flat needs backward computation.
I0324 23:37:52.394762 29022 net.cpp:323] ctx_output5/relu_mbox_conf_perm needs backward computation.
I0324 23:37:52.394767 29022 net.cpp:323] ctx_output5/relu_mbox_conf needs backward computation.
I0324 23:37:52.394773 29022 net.cpp:323] ctx_output5/relu_mbox_loc_flat needs backward computation.
I0324 23:37:52.394776 29022 net.cpp:323] ctx_output5/relu_mbox_loc_perm needs backward computation.
I0324 23:37:52.394781 29022 net.cpp:323] ctx_output5/relu_mbox_loc needs backward computation.
I0324 23:37:52.394786 29022 net.cpp:325] ctx_output4/relu_mbox_priorbox does not need backward computation.
I0324 23:37:52.394791 29022 net.cpp:323] ctx_output4/relu_mbox_conf_flat needs backward computation.
I0324 23:37:52.394796 29022 net.cpp:323] ctx_output4/relu_mbox_conf_perm needs backward computation.
I0324 23:37:52.394801 29022 net.cpp:323] ctx_output4/relu_mbox_conf needs backward computation.
I0324 23:37:52.394806 29022 net.cpp:323] ctx_output4/relu_mbox_loc_flat needs backward computation.
I0324 23:37:52.394810 29022 net.cpp:323] ctx_output4/relu_mbox_loc_perm needs backward computation.
I0324 23:37:52.394815 29022 net.cpp:323] ctx_output4/relu_mbox_loc needs backward computation.
I0324 23:37:52.394820 29022 net.cpp:325] ctx_output3/relu_mbox_priorbox does not need backward computation.
I0324 23:37:52.394825 29022 net.cpp:323] ctx_output3/relu_mbox_conf_flat needs backward computation.
I0324 23:37:52.394830 29022 net.cpp:323] ctx_output3/relu_mbox_conf_perm needs backward computation.
I0324 23:37:52.394834 29022 net.cpp:323] ctx_output3/relu_mbox_conf needs backward computation.
I0324 23:37:52.394840 29022 net.cpp:323] ctx_output3/relu_mbox_loc_flat needs backward computation.
I0324 23:37:52.394845 29022 net.cpp:323] ctx_output3/relu_mbox_loc_perm needs backward computation.
I0324 23:37:52.394848 29022 net.cpp:323] ctx_output3/relu_mbox_loc needs backward computation.
I0324 23:37:52.394853 29022 net.cpp:325] ctx_output2/relu_mbox_priorbox does not need backward computation.
I0324 23:37:52.394858 29022 net.cpp:323] ctx_output2/relu_mbox_conf_flat needs backward computation.
I0324 23:37:52.394863 29022 net.cpp:323] ctx_output2/relu_mbox_conf_perm needs backward computation.
I0324 23:37:52.394868 29022 net.cpp:323] ctx_output2/relu_mbox_conf needs backward computation.
I0324 23:37:52.394873 29022 net.cpp:323] ctx_output2/relu_mbox_loc_flat needs backward computation.
I0324 23:37:52.394877 29022 net.cpp:323] ctx_output2/relu_mbox_loc_perm needs backward computation.
I0324 23:37:52.394882 29022 net.cpp:323] ctx_output2/relu_mbox_loc needs backward computation.
I0324 23:37:52.394896 29022 net.cpp:325] ctx_output1/relu_mbox_priorbox does not need backward computation.
I0324 23:37:52.394903 29022 net.cpp:323] ctx_output1/relu_mbox_conf_flat needs backward computation.
I0324 23:37:52.394908 29022 net.cpp:323] ctx_output1/relu_mbox_conf_perm needs backward computation.
I0324 23:37:52.394913 29022 net.cpp:323] ctx_output1/relu_mbox_conf needs backward computation.
I0324 23:37:52.394918 29022 net.cpp:323] ctx_output1/relu_mbox_loc_flat needs backward computation.
I0324 23:37:52.394922 29022 net.cpp:323] ctx_output1/relu_mbox_loc_perm needs backward computation.
I0324 23:37:52.394927 29022 net.cpp:323] ctx_output1/relu_mbox_loc needs backward computation.
I0324 23:37:52.394932 29022 net.cpp:323] ctx_output6_ctx_output6/relu_0_split needs backward computation.
I0324 23:37:52.394937 29022 net.cpp:323] ctx_output6/relu needs backward computation.
I0324 23:37:52.394942 29022 net.cpp:323] ctx_output6 needs backward computation.
I0324 23:37:52.394948 29022 net.cpp:323] ctx_output5_ctx_output5/relu_0_split needs backward computation.
I0324 23:37:52.394953 29022 net.cpp:323] ctx_output5/relu needs backward computation.
I0324 23:37:52.394958 29022 net.cpp:323] ctx_output5 needs backward computation.
I0324 23:37:52.394963 29022 net.cpp:323] ctx_output4_ctx_output4/relu_0_split needs backward computation.
I0324 23:37:52.394968 29022 net.cpp:323] ctx_output4/relu needs backward computation.
I0324 23:37:52.394973 29022 net.cpp:323] ctx_output4 needs backward computation.
I0324 23:37:52.394978 29022 net.cpp:323] ctx_output3_ctx_output3/relu_0_split needs backward computation.
I0324 23:37:52.394982 29022 net.cpp:323] ctx_output3/relu needs backward computation.
I0324 23:37:52.394987 29022 net.cpp:323] ctx_output3 needs backward computation.
I0324 23:37:52.394992 29022 net.cpp:323] ctx_output2_ctx_output2/relu_0_split needs backward computation.
I0324 23:37:52.394997 29022 net.cpp:323] ctx_output2/relu needs backward computation.
I0324 23:37:52.395001 29022 net.cpp:323] ctx_output2 needs backward computation.
I0324 23:37:52.395006 29022 net.cpp:323] ctx_output1_ctx_output1/relu_0_split needs backward computation.
I0324 23:37:52.395011 29022 net.cpp:323] ctx_output1/relu needs backward computation.
I0324 23:37:52.395016 29022 net.cpp:323] ctx_output1 needs backward computation.
I0324 23:37:52.395021 29022 net.cpp:323] pool9 needs backward computation.
I0324 23:37:52.395026 29022 net.cpp:323] pool8_pool8_0_split needs backward computation.
I0324 23:37:52.395031 29022 net.cpp:323] pool8 needs backward computation.
I0324 23:37:52.395036 29022 net.cpp:323] pool7_pool7_0_split needs backward computation.
I0324 23:37:52.395041 29022 net.cpp:323] pool7 needs backward computation.
I0324 23:37:52.395046 29022 net.cpp:323] pool6_pool6_0_split needs backward computation.
I0324 23:37:52.395051 29022 net.cpp:323] pool6 needs backward computation.
I0324 23:37:52.395056 29022 net.cpp:323] res5a_branch2b_res5a_branch2b/relu_0_split needs backward computation.
I0324 23:37:52.395061 29022 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0324 23:37:52.395066 29022 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0324 23:37:52.395071 29022 net.cpp:323] res5a_branch2b needs backward computation.
I0324 23:37:52.395076 29022 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0324 23:37:52.395081 29022 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0324 23:37:52.395086 29022 net.cpp:323] res5a_branch2a needs backward computation.
I0324 23:37:52.395089 29022 net.cpp:323] pool4 needs backward computation.
I0324 23:37:52.395094 29022 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0324 23:37:52.395099 29022 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0324 23:37:52.395104 29022 net.cpp:323] res4a_branch2b needs backward computation.
I0324 23:37:52.395109 29022 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0324 23:37:52.395114 29022 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0324 23:37:52.395118 29022 net.cpp:323] res4a_branch2a needs backward computation.
I0324 23:37:52.395130 29022 net.cpp:323] pool3 needs backward computation.
I0324 23:37:52.395136 29022 net.cpp:323] res3a_branch2b_res3a_branch2b/relu_0_split needs backward computation.
I0324 23:37:52.395141 29022 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0324 23:37:52.395146 29022 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0324 23:37:52.395150 29022 net.cpp:323] res3a_branch2b needs backward computation.
I0324 23:37:52.395156 29022 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0324 23:37:52.395160 29022 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0324 23:37:52.395165 29022 net.cpp:323] res3a_branch2a needs backward computation.
I0324 23:37:52.395170 29022 net.cpp:323] pool2 needs backward computation.
I0324 23:37:52.395175 29022 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0324 23:37:52.395180 29022 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0324 23:37:52.395184 29022 net.cpp:323] res2a_branch2b needs backward computation.
I0324 23:37:52.395190 29022 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0324 23:37:52.395195 29022 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0324 23:37:52.395198 29022 net.cpp:323] res2a_branch2a needs backward computation.
I0324 23:37:52.395203 29022 net.cpp:323] pool1 needs backward computation.
I0324 23:37:52.395208 29022 net.cpp:323] conv1b/relu needs backward computation.
I0324 23:37:52.395213 29022 net.cpp:323] conv1b/bn needs backward computation.
I0324 23:37:52.395218 29022 net.cpp:323] conv1b needs backward computation.
I0324 23:37:52.395222 29022 net.cpp:323] conv1a/relu needs backward computation.
I0324 23:37:52.395227 29022 net.cpp:323] conv1a/bn needs backward computation.
I0324 23:37:52.395232 29022 net.cpp:323] conv1a needs backward computation.
I0324 23:37:52.395237 29022 net.cpp:325] data/bias does not need backward computation.
I0324 23:37:52.395244 29022 net.cpp:325] data_data_0_split does not need backward computation.
I0324 23:37:52.395249 29022 net.cpp:325] data does not need backward computation.
I0324 23:37:52.395253 29022 net.cpp:367] This network produces output mbox_loss
I0324 23:37:52.395347 29022 net.cpp:389] Top memory (TRAIN) required for data: 1206154824 diff: 1206154824
I0324 23:37:52.395355 29022 net.cpp:392] Bottom memory (TRAIN) required for data: 1206154816 diff: 1206154816
I0324 23:37:52.395359 29022 net.cpp:395] Shared (in-place) memory (TRAIN) by data: 521715712 diff: 521715712
I0324 23:37:52.395364 29022 net.cpp:398] Parameters memory (TRAIN) required for data: 12464288 diff: 12464288
I0324 23:37:52.395368 29022 net.cpp:401] Parameters shared memory (TRAIN) by data: 0 diff: 0
I0324 23:37:52.395372 29022 net.cpp:407] Network initialization done.
I0324 23:37:52.402299 29022 solver.cpp:177] Creating test net (#0) specified by test_net file: training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/test.prototxt
I0324 23:37:52.403110 29022 net.cpp:72] Initializing net from parameters: 
name: "ssdJacintoNetV2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_value: 0
    mean_value: 0
    mean_value: 0
    force_color: false
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 320
      width: 768
      interp_mode: LINEAR
    }
    crop_h: 320
    crop_w: 768
  }
  data_param {
    source: "/user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_test_lmdb"
    batch_size: 8
    backend: LMDB
    threads: 4
    parser_threads: 4
  }
  annotated_data_param {
    batch_sampler {
    }
    label_map_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/labelmap.prototxt"
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "pool6"
  top: "pool7"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool8"
  type: "Pooling"
  bottom: "pool7"
  top: "pool8"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool9"
  type: "Pooling"
  bottom: "pool8"
  top: "pool9"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "ctx_output1"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "ctx_output1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu"
  type: "ReLU"
  bottom: "ctx_output1"
  top: "ctx_output1"
}
layer {
  name: "ctx_output2"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "ctx_output2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu"
  type: "ReLU"
  bottom: "ctx_output2"
  top: "ctx_output2"
}
layer {
  name: "ctx_output3"
  type: "Convolution"
  bottom: "pool6"
  top: "ctx_output3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu"
  type: "ReLU"
  bottom: "ctx_output3"
  top: "ctx_output3"
}
layer {
  name: "ctx_output4"
  type: "Convolution"
  bottom: "pool7"
  top: "ctx_output4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu"
  type: "ReLU"
  bottom: "ctx_output4"
  top: "ctx_output4"
}
layer {
  name: "ctx_output5"
  type: "Convolution"
  bottom: "pool8"
  top: "ctx_output5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu"
  type: "ReLU"
  bottom: "ctx_output5"
  top: "ctx_output5"
}
layer {
  name: "ctx_output6"
  type: "Convolution"
  bottom: "pool9"
  top: "ctx_output6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu"
  type: "ReLU"
  bottom: "ctx_output6"
  top: "ctx_output6"
}
layer {
  name: "ctx_output1/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_loc"
  top: "ctx_output1/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_loc_perm"
  top: "ctx_output1/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_conf"
  top: "ctx_output1/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_conf_perm"
  top: "ctx_output1/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output1"
  bottom: "data"
  top: "ctx_output1/relu_mbox_priorbox"
  prior_box_param {
    min_size: 12.8
    max_size: 32
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_loc"
  top: "ctx_output2/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_loc_perm"
  top: "ctx_output2/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_conf"
  top: "ctx_output2/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_conf_perm"
  top: "ctx_output2/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output2"
  bottom: "data"
  top: "ctx_output2/relu_mbox_priorbox"
  prior_box_param {
    min_size: 32
    max_size: 96
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_loc"
  top: "ctx_output3/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_loc_perm"
  top: "ctx_output3/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_conf"
  top: "ctx_output3/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_conf_perm"
  top: "ctx_output3/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output3"
  bottom: "data"
  top: "ctx_output3/relu_mbox_priorbox"
  prior_box_param {
    min_size: 96
    max_size: 160
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_loc"
  top: "ctx_output4/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_loc_perm"
  top: "ctx_output4/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_conf"
  top: "ctx_output4/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_conf_perm"
  top: "ctx_output4/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output4"
  bottom: "data"
  top: "ctx_output4/relu_mbox_priorbox"
  prior_box_param {
    min_size: 160
    max_size: 224
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_loc"
  top: "ctx_output5/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_loc_perm"
  top: "ctx_output5/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_conf"
  top: "ctx_output5/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_conf_perm"
  top: "ctx_output5/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output5"
  bottom: "data"
  top: "ctx_output5/relu_mbox_priorbox"
  prior_box_param {
    min_size: 224
    max_size: 288
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_loc"
  top: "ctx_output6/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_loc_perm"
  top: "ctx_output6/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_conf"
  top: "ctx_output6/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_conf_perm"
  top: "ctx_output6/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output6"
  bottom: "data"
  top: "ctx_output6/relu_mbox_priorbox"
  prior_box_param {
    min_size: 288
    max_size: 352
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_loc_flat"
  bottom: "ctx_output2/relu_mbox_loc_flat"
  bottom: "ctx_output3/relu_mbox_loc_flat"
  bottom: "ctx_output4/relu_mbox_loc_flat"
  bottom: "ctx_output5/relu_mbox_loc_flat"
  bottom: "ctx_output6/relu_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_conf_flat"
  bottom: "ctx_output2/relu_mbox_conf_flat"
  bottom: "ctx_output3/relu_mbox_conf_flat"
  bottom: "ctx_output4/relu_mbox_conf_flat"
  bottom: "ctx_output5/relu_mbox_conf_flat"
  bottom: "ctx_output6/relu_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_priorbox"
  bottom: "ctx_output2/relu_mbox_priorbox"
  bottom: "ctx_output3/relu_mbox_priorbox"
  bottom: "ctx_output4/relu_mbox_priorbox"
  bottom: "ctx_output5/relu_mbox_priorbox"
  bottom: "ctx_output6/relu_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_reshape"
  type: "Reshape"
  bottom: "mbox_conf"
  top: "mbox_conf_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: -1
      dim: 4
    }
  }
}
layer {
  name: "mbox_conf_softmax"
  type: "Softmax"
  bottom: "mbox_conf_reshape"
  top: "mbox_conf_softmax"
  softmax_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_flatten"
  type: "Flatten"
  bottom: "mbox_conf_softmax"
  top: "mbox_conf_flatten"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "detection_out"
  type: "DetectionOutput"
  bottom: "mbox_loc"
  bottom: "mbox_conf_flatten"
  bottom: "mbox_priorbox"
  top: "detection_out"
  include {
    phase: TEST
  }
  detection_output_param {
    num_classes: 4
    share_location: true
    background_label_id: 0
    nms_param {
      nms_threshold: 0.45
      top_k: 400
    }
    save_output_param {
      output_directory: ""
      output_name_prefix: "comp4_det_test_"
      output_format: "VOC"
      label_map_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/labelmap.prototxt"
      name_size_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/test_name_size.txt"
      num_test_image: 3609
    }
    code_type: CENTER_SIZE
    keep_top_k: 200
    confidence_threshold: 0.01
  }
}
layer {
  name: "detection_eval"
  type: "DetectionEvaluate"
  bottom: "detection_out"
  bottom: "label"
  top: "detection_eval"
  include {
    phase: TEST
  }
  detection_evaluate_param {
    num_classes: 4
    background_label_id: 0
    overlap_threshold: 0.5
    evaluate_difficult_gt: true
    name_size_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/test_name_size.txt"
  }
}
I0324 23:37:52.403535 29022 net.cpp:104] Using FLOAT as default forward math type
I0324 23:37:52.403545 29022 net.cpp:110] Using FLOAT as default backward math type
I0324 23:37:52.403550 29022 layer_factory.hpp:136] Creating layer 'data' of type 'AnnotatedData'
I0324 23:37:52.403556 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.403578 29022 net.cpp:184] Created Layer data (0)
I0324 23:37:52.403584 29022 net.cpp:530] data -> data
I0324 23:37:52.403591 29022 net.cpp:530] data -> label
I0324 23:37:52.403604 29022 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 8
I0324 23:37:52.403614 29022 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0324 23:37:52.406114 29077 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_test_lmdb
I0324 23:37:52.419539 29022 annotated_data_layer.cpp:219] output data size: 8,3,320,768
I0324 23:37:52.419622 29022 annotated_data_layer.cpp:265] (0) Output data size: 8, 3, 320, 768
I0324 23:37:52.419680 29022 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0324 23:37:52.420657 29022 net.cpp:245] Setting up data
I0324 23:37:52.420707 29022 net.cpp:252] TEST Top shape for layer 0 'data' 8 3 320 768 (5898240)
I0324 23:37:52.420722 29022 net.cpp:252] TEST Top shape for layer 0 'data' 1 1 31 8 (248)
I0324 23:37:52.420733 29022 layer_factory.hpp:136] Creating layer 'data_data_0_split' of type 'Split'
I0324 23:37:52.420743 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.420760 29022 net.cpp:184] Created Layer data_data_0_split (1)
I0324 23:37:52.420769 29022 net.cpp:561] data_data_0_split <- data
I0324 23:37:52.420780 29022 net.cpp:530] data_data_0_split -> data_data_0_split_0
I0324 23:37:52.420794 29022 net.cpp:530] data_data_0_split -> data_data_0_split_1
I0324 23:37:52.420804 29022 net.cpp:530] data_data_0_split -> data_data_0_split_2
I0324 23:37:52.420814 29022 net.cpp:530] data_data_0_split -> data_data_0_split_3
I0324 23:37:52.420823 29022 net.cpp:530] data_data_0_split -> data_data_0_split_4
I0324 23:37:52.420832 29022 net.cpp:530] data_data_0_split -> data_data_0_split_5
I0324 23:37:52.420841 29022 net.cpp:530] data_data_0_split -> data_data_0_split_6
I0324 23:37:52.421052 29022 net.cpp:245] Setting up data_data_0_split
I0324 23:37:52.421068 29022 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0324 23:37:52.421079 29022 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0324 23:37:52.421089 29022 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0324 23:37:52.421098 29022 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0324 23:37:52.421108 29022 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0324 23:37:52.421118 29022 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0324 23:37:52.421128 29022 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0324 23:37:52.421136 29022 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0324 23:37:52.421145 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.421161 29022 net.cpp:184] Created Layer data/bias (2)
I0324 23:37:52.421169 29022 net.cpp:561] data/bias <- data_data_0_split_0
I0324 23:37:52.421180 29022 net.cpp:530] data/bias -> data/bias
I0324 23:37:52.422698 29078 annotated_data_layer.cpp:111] (0) Parser threads: 1
I0324 23:37:52.422713 29078 annotated_data_layer.cpp:113] (0) Transformer threads: 1
I0324 23:37:52.422933 29022 net.cpp:245] Setting up data/bias
I0324 23:37:52.422952 29022 net.cpp:252] TEST Top shape for layer 2 'data/bias' 8 3 320 768 (5898240)
I0324 23:37:52.422971 29022 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0324 23:37:52.422979 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.423002 29022 net.cpp:184] Created Layer conv1a (3)
I0324 23:37:52.423012 29022 net.cpp:561] conv1a <- data/bias
I0324 23:37:52.423022 29022 net.cpp:530] conv1a -> conv1a
I0324 23:37:52.423645 29022 net.cpp:245] Setting up conv1a
I0324 23:37:52.423663 29022 net.cpp:252] TEST Top shape for layer 3 'conv1a' 8 32 160 384 (15728640)
I0324 23:37:52.423682 29022 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0324 23:37:52.423692 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.423709 29022 net.cpp:184] Created Layer conv1a/bn (4)
I0324 23:37:52.423717 29022 net.cpp:561] conv1a/bn <- conv1a
I0324 23:37:52.423727 29022 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0324 23:37:52.425021 29022 net.cpp:245] Setting up conv1a/bn
I0324 23:37:52.425055 29022 net.cpp:252] TEST Top shape for layer 4 'conv1a/bn' 8 32 160 384 (15728640)
I0324 23:37:52.425084 29022 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0324 23:37:52.425097 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.425112 29022 net.cpp:184] Created Layer conv1a/relu (5)
I0324 23:37:52.425149 29022 net.cpp:561] conv1a/relu <- conv1a
I0324 23:37:52.425163 29022 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0324 23:37:52.425179 29022 net.cpp:245] Setting up conv1a/relu
I0324 23:37:52.425191 29022 net.cpp:252] TEST Top shape for layer 5 'conv1a/relu' 8 32 160 384 (15728640)
I0324 23:37:52.425201 29022 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0324 23:37:52.425211 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.425235 29022 net.cpp:184] Created Layer conv1b (6)
I0324 23:37:52.425246 29022 net.cpp:561] conv1b <- conv1a
I0324 23:37:52.425256 29022 net.cpp:530] conv1b -> conv1b
I0324 23:37:52.425822 29022 net.cpp:245] Setting up conv1b
I0324 23:37:52.425837 29022 net.cpp:252] TEST Top shape for layer 6 'conv1b' 8 32 160 384 (15728640)
I0324 23:37:52.425848 29022 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0324 23:37:52.425855 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.425868 29022 net.cpp:184] Created Layer conv1b/bn (7)
I0324 23:37:52.425873 29022 net.cpp:561] conv1b/bn <- conv1b
I0324 23:37:52.425879 29022 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0324 23:37:52.426618 29022 net.cpp:245] Setting up conv1b/bn
I0324 23:37:52.426632 29022 net.cpp:252] TEST Top shape for layer 7 'conv1b/bn' 8 32 160 384 (15728640)
I0324 23:37:52.426645 29022 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0324 23:37:52.426651 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.426661 29022 net.cpp:184] Created Layer conv1b/relu (8)
I0324 23:37:52.426666 29022 net.cpp:561] conv1b/relu <- conv1b
I0324 23:37:52.426671 29022 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0324 23:37:52.426679 29022 net.cpp:245] Setting up conv1b/relu
I0324 23:37:52.426687 29022 net.cpp:252] TEST Top shape for layer 8 'conv1b/relu' 8 32 160 384 (15728640)
I0324 23:37:52.426692 29022 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0324 23:37:52.426697 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.426707 29022 net.cpp:184] Created Layer pool1 (9)
I0324 23:37:52.426712 29022 net.cpp:561] pool1 <- conv1b
I0324 23:37:52.426718 29022 net.cpp:530] pool1 -> pool1
I0324 23:37:52.426785 29022 net.cpp:245] Setting up pool1
I0324 23:37:52.426796 29022 net.cpp:252] TEST Top shape for layer 9 'pool1' 8 32 80 192 (3932160)
I0324 23:37:52.426802 29022 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0324 23:37:52.426808 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.426821 29022 net.cpp:184] Created Layer res2a_branch2a (10)
I0324 23:37:52.426827 29022 net.cpp:561] res2a_branch2a <- pool1
I0324 23:37:52.426833 29022 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0324 23:37:52.427723 29022 net.cpp:245] Setting up res2a_branch2a
I0324 23:37:52.427736 29022 net.cpp:252] TEST Top shape for layer 10 'res2a_branch2a' 8 64 80 192 (7864320)
I0324 23:37:52.427748 29022 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0324 23:37:52.427754 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.427764 29022 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0324 23:37:52.427770 29022 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0324 23:37:52.427776 29022 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0324 23:37:52.428501 29022 net.cpp:245] Setting up res2a_branch2a/bn
I0324 23:37:52.428514 29022 net.cpp:252] TEST Top shape for layer 11 'res2a_branch2a/bn' 8 64 80 192 (7864320)
I0324 23:37:52.428527 29022 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0324 23:37:52.428534 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.428551 29022 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0324 23:37:52.428558 29022 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0324 23:37:52.428565 29022 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0324 23:37:52.428572 29022 net.cpp:245] Setting up res2a_branch2a/relu
I0324 23:37:52.428580 29022 net.cpp:252] TEST Top shape for layer 12 'res2a_branch2a/relu' 8 64 80 192 (7864320)
I0324 23:37:52.428584 29022 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0324 23:37:52.428591 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.428602 29022 net.cpp:184] Created Layer res2a_branch2b (13)
I0324 23:37:52.428608 29022 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0324 23:37:52.428614 29022 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0324 23:37:52.429215 29022 net.cpp:245] Setting up res2a_branch2b
I0324 23:37:52.429229 29022 net.cpp:252] TEST Top shape for layer 13 'res2a_branch2b' 8 64 80 192 (7864320)
I0324 23:37:52.429239 29022 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0324 23:37:52.429244 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.429255 29022 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0324 23:37:52.429260 29022 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0324 23:37:52.429265 29022 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0324 23:37:52.430021 29022 net.cpp:245] Setting up res2a_branch2b/bn
I0324 23:37:52.430034 29022 net.cpp:252] TEST Top shape for layer 14 'res2a_branch2b/bn' 8 64 80 192 (7864320)
I0324 23:37:52.430047 29022 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0324 23:37:52.430053 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.430060 29022 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0324 23:37:52.430066 29022 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0324 23:37:52.430071 29022 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0324 23:37:52.430079 29022 net.cpp:245] Setting up res2a_branch2b/relu
I0324 23:37:52.430086 29022 net.cpp:252] TEST Top shape for layer 15 'res2a_branch2b/relu' 8 64 80 192 (7864320)
I0324 23:37:52.430091 29022 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0324 23:37:52.430096 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.430105 29022 net.cpp:184] Created Layer pool2 (16)
I0324 23:37:52.430111 29022 net.cpp:561] pool2 <- res2a_branch2b
I0324 23:37:52.430116 29022 net.cpp:530] pool2 -> pool2
I0324 23:37:52.430181 29022 net.cpp:245] Setting up pool2
I0324 23:37:52.430191 29022 net.cpp:252] TEST Top shape for layer 16 'pool2' 8 64 40 96 (1966080)
I0324 23:37:52.430197 29022 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0324 23:37:52.430204 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.430217 29022 net.cpp:184] Created Layer res3a_branch2a (17)
I0324 23:37:52.430223 29022 net.cpp:561] res3a_branch2a <- pool2
I0324 23:37:52.430229 29022 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0324 23:37:52.432813 29022 net.cpp:245] Setting up res3a_branch2a
I0324 23:37:52.432827 29022 net.cpp:252] TEST Top shape for layer 17 'res3a_branch2a' 8 128 40 96 (3932160)
I0324 23:37:52.432837 29022 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0324 23:37:52.432843 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.432852 29022 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0324 23:37:52.432858 29022 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0324 23:37:52.432864 29022 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0324 23:37:52.433573 29022 net.cpp:245] Setting up res3a_branch2a/bn
I0324 23:37:52.433585 29022 net.cpp:252] TEST Top shape for layer 18 'res3a_branch2a/bn' 8 128 40 96 (3932160)
I0324 23:37:52.433610 29022 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0324 23:37:52.433619 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.433625 29022 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0324 23:37:52.433631 29022 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0324 23:37:52.433637 29022 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0324 23:37:52.433645 29022 net.cpp:245] Setting up res3a_branch2a/relu
I0324 23:37:52.433652 29022 net.cpp:252] TEST Top shape for layer 19 'res3a_branch2a/relu' 8 128 40 96 (3932160)
I0324 23:37:52.433657 29022 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0324 23:37:52.433662 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.433676 29022 net.cpp:184] Created Layer res3a_branch2b (20)
I0324 23:37:52.433681 29022 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0324 23:37:52.433687 29022 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0324 23:37:52.435140 29022 net.cpp:245] Setting up res3a_branch2b
I0324 23:37:52.435154 29022 net.cpp:252] TEST Top shape for layer 20 'res3a_branch2b' 8 128 40 96 (3932160)
I0324 23:37:52.435164 29022 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0324 23:37:52.435170 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.435180 29022 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0324 23:37:52.435185 29022 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0324 23:37:52.435191 29022 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0324 23:37:52.435995 29022 net.cpp:245] Setting up res3a_branch2b/bn
I0324 23:37:52.436010 29022 net.cpp:252] TEST Top shape for layer 21 'res3a_branch2b/bn' 8 128 40 96 (3932160)
I0324 23:37:52.436023 29022 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0324 23:37:52.436029 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.436038 29022 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0324 23:37:52.436043 29022 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0324 23:37:52.436049 29022 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0324 23:37:52.436058 29022 net.cpp:245] Setting up res3a_branch2b/relu
I0324 23:37:52.436064 29022 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b/relu' 8 128 40 96 (3932160)
I0324 23:37:52.436069 29022 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0324 23:37:52.436075 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.436082 29022 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (23)
I0324 23:37:52.436089 29022 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0324 23:37:52.436094 29022 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0324 23:37:52.436100 29022 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0324 23:37:52.436149 29022 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0324 23:37:52.436161 29022 net.cpp:252] TEST Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 8 128 40 96 (3932160)
I0324 23:37:52.436167 29022 net.cpp:252] TEST Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 8 128 40 96 (3932160)
I0324 23:37:52.436172 29022 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0324 23:37:52.436178 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.436187 29022 net.cpp:184] Created Layer pool3 (24)
I0324 23:37:52.436193 29022 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0324 23:37:52.436211 29022 net.cpp:530] pool3 -> pool3
I0324 23:37:52.436275 29022 net.cpp:245] Setting up pool3
I0324 23:37:52.436285 29022 net.cpp:252] TEST Top shape for layer 24 'pool3' 8 128 20 48 (983040)
I0324 23:37:52.436292 29022 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0324 23:37:52.436297 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.436311 29022 net.cpp:184] Created Layer res4a_branch2a (25)
I0324 23:37:52.436316 29022 net.cpp:561] res4a_branch2a <- pool3
I0324 23:37:52.436323 29022 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0324 23:37:52.450866 29022 net.cpp:245] Setting up res4a_branch2a
I0324 23:37:52.450917 29022 net.cpp:252] TEST Top shape for layer 25 'res4a_branch2a' 8 256 20 48 (1966080)
I0324 23:37:52.450937 29022 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0324 23:37:52.450949 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.450971 29022 net.cpp:184] Created Layer res4a_branch2a/bn (26)
I0324 23:37:52.450981 29022 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0324 23:37:52.450994 29022 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0324 23:37:52.452155 29022 net.cpp:245] Setting up res4a_branch2a/bn
I0324 23:37:52.452201 29022 net.cpp:252] TEST Top shape for layer 26 'res4a_branch2a/bn' 8 256 20 48 (1966080)
I0324 23:37:52.452229 29022 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0324 23:37:52.452241 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.452257 29022 net.cpp:184] Created Layer res4a_branch2a/relu (27)
I0324 23:37:52.452268 29022 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0324 23:37:52.452280 29022 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0324 23:37:52.452293 29022 net.cpp:245] Setting up res4a_branch2a/relu
I0324 23:37:52.452303 29022 net.cpp:252] TEST Top shape for layer 27 'res4a_branch2a/relu' 8 256 20 48 (1966080)
I0324 23:37:52.452312 29022 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0324 23:37:52.452322 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.452345 29022 net.cpp:184] Created Layer res4a_branch2b (28)
I0324 23:37:52.452353 29022 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0324 23:37:52.452363 29022 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0324 23:37:52.458134 29022 net.cpp:245] Setting up res4a_branch2b
I0324 23:37:52.458163 29022 net.cpp:252] TEST Top shape for layer 28 'res4a_branch2b' 8 256 20 48 (1966080)
I0324 23:37:52.458176 29022 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0324 23:37:52.458184 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.458197 29022 net.cpp:184] Created Layer res4a_branch2b/bn (29)
I0324 23:37:52.458205 29022 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0324 23:37:52.458214 29022 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0324 23:37:52.458936 29022 net.cpp:245] Setting up res4a_branch2b/bn
I0324 23:37:52.458951 29022 net.cpp:252] TEST Top shape for layer 29 'res4a_branch2b/bn' 8 256 20 48 (1966080)
I0324 23:37:52.458964 29022 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0324 23:37:52.458971 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.458979 29022 net.cpp:184] Created Layer res4a_branch2b/relu (30)
I0324 23:37:52.458984 29022 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0324 23:37:52.458990 29022 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0324 23:37:52.458999 29022 net.cpp:245] Setting up res4a_branch2b/relu
I0324 23:37:52.459007 29022 net.cpp:252] TEST Top shape for layer 30 'res4a_branch2b/relu' 8 256 20 48 (1966080)
I0324 23:37:52.459012 29022 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0324 23:37:52.459039 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.459049 29022 net.cpp:184] Created Layer pool4 (31)
I0324 23:37:52.459055 29022 net.cpp:561] pool4 <- res4a_branch2b
I0324 23:37:52.459061 29022 net.cpp:530] pool4 -> pool4
I0324 23:37:52.459130 29022 net.cpp:245] Setting up pool4
I0324 23:37:52.459141 29022 net.cpp:252] TEST Top shape for layer 31 'pool4' 8 256 10 24 (491520)
I0324 23:37:52.459146 29022 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0324 23:37:52.459153 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.459169 29022 net.cpp:184] Created Layer res5a_branch2a (32)
I0324 23:37:52.459175 29022 net.cpp:561] res5a_branch2a <- pool4
I0324 23:37:52.459182 29022 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0324 23:37:52.505049 29022 net.cpp:245] Setting up res5a_branch2a
I0324 23:37:52.505084 29022 net.cpp:252] TEST Top shape for layer 32 'res5a_branch2a' 8 512 10 24 (983040)
I0324 23:37:52.505102 29022 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0324 23:37:52.505113 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.505131 29022 net.cpp:184] Created Layer res5a_branch2a/bn (33)
I0324 23:37:52.505141 29022 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0324 23:37:52.505152 29022 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0324 23:37:52.506181 29022 net.cpp:245] Setting up res5a_branch2a/bn
I0324 23:37:52.506198 29022 net.cpp:252] TEST Top shape for layer 33 'res5a_branch2a/bn' 8 512 10 24 (983040)
I0324 23:37:52.506220 29022 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0324 23:37:52.506232 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.506243 29022 net.cpp:184] Created Layer res5a_branch2a/relu (34)
I0324 23:37:52.506253 29022 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0324 23:37:52.506261 29022 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0324 23:37:52.506274 29022 net.cpp:245] Setting up res5a_branch2a/relu
I0324 23:37:52.506284 29022 net.cpp:252] TEST Top shape for layer 34 'res5a_branch2a/relu' 8 512 10 24 (983040)
I0324 23:37:52.506294 29022 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0324 23:37:52.506301 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.506320 29022 net.cpp:184] Created Layer res5a_branch2b (35)
I0324 23:37:52.506330 29022 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0324 23:37:52.506340 29022 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0324 23:37:52.529603 29022 net.cpp:245] Setting up res5a_branch2b
I0324 23:37:52.529637 29022 net.cpp:252] TEST Top shape for layer 35 'res5a_branch2b' 8 512 10 24 (983040)
I0324 23:37:52.529666 29022 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0324 23:37:52.529680 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.529707 29022 net.cpp:184] Created Layer res5a_branch2b/bn (36)
I0324 23:37:52.529721 29022 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0324 23:37:52.529734 29022 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0324 23:37:52.530817 29022 net.cpp:245] Setting up res5a_branch2b/bn
I0324 23:37:52.530839 29022 net.cpp:252] TEST Top shape for layer 36 'res5a_branch2b/bn' 8 512 10 24 (983040)
I0324 23:37:52.530864 29022 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0324 23:37:52.530875 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.530887 29022 net.cpp:184] Created Layer res5a_branch2b/relu (37)
I0324 23:37:52.530899 29022 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0324 23:37:52.530908 29022 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0324 23:37:52.530949 29022 net.cpp:245] Setting up res5a_branch2b/relu
I0324 23:37:52.530963 29022 net.cpp:252] TEST Top shape for layer 37 'res5a_branch2b/relu' 8 512 10 24 (983040)
I0324 23:37:52.530973 29022 layer_factory.hpp:136] Creating layer 'res5a_branch2b_res5a_branch2b/relu_0_split' of type 'Split'
I0324 23:37:52.530983 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.530994 29022 net.cpp:184] Created Layer res5a_branch2b_res5a_branch2b/relu_0_split (38)
I0324 23:37:52.531003 29022 net.cpp:561] res5a_branch2b_res5a_branch2b/relu_0_split <- res5a_branch2b
I0324 23:37:52.531013 29022 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_0
I0324 23:37:52.531025 29022 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_1
I0324 23:37:52.531095 29022 net.cpp:245] Setting up res5a_branch2b_res5a_branch2b/relu_0_split
I0324 23:37:52.531111 29022 net.cpp:252] TEST Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 8 512 10 24 (983040)
I0324 23:37:52.531122 29022 net.cpp:252] TEST Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 8 512 10 24 (983040)
I0324 23:37:52.531131 29022 layer_factory.hpp:136] Creating layer 'pool6' of type 'Pooling'
I0324 23:37:52.531141 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.531154 29022 net.cpp:184] Created Layer pool6 (39)
I0324 23:37:52.531162 29022 net.cpp:561] pool6 <- res5a_branch2b_res5a_branch2b/relu_0_split_0
I0324 23:37:52.531172 29022 net.cpp:530] pool6 -> pool6
I0324 23:37:52.531265 29022 net.cpp:245] Setting up pool6
I0324 23:37:52.531280 29022 net.cpp:252] TEST Top shape for layer 39 'pool6' 8 512 5 12 (245760)
I0324 23:37:52.531289 29022 layer_factory.hpp:136] Creating layer 'pool6_pool6_0_split' of type 'Split'
I0324 23:37:52.531298 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.531314 29022 net.cpp:184] Created Layer pool6_pool6_0_split (40)
I0324 23:37:52.531324 29022 net.cpp:561] pool6_pool6_0_split <- pool6
I0324 23:37:52.531333 29022 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_0
I0324 23:37:52.531344 29022 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_1
I0324 23:37:52.531414 29022 net.cpp:245] Setting up pool6_pool6_0_split
I0324 23:37:52.531428 29022 net.cpp:252] TEST Top shape for layer 40 'pool6_pool6_0_split' 8 512 5 12 (245760)
I0324 23:37:52.531438 29022 net.cpp:252] TEST Top shape for layer 40 'pool6_pool6_0_split' 8 512 5 12 (245760)
I0324 23:37:52.531447 29022 layer_factory.hpp:136] Creating layer 'pool7' of type 'Pooling'
I0324 23:37:52.531455 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.531467 29022 net.cpp:184] Created Layer pool7 (41)
I0324 23:37:52.531476 29022 net.cpp:561] pool7 <- pool6_pool6_0_split_0
I0324 23:37:52.531484 29022 net.cpp:530] pool7 -> pool7
I0324 23:37:52.531571 29022 net.cpp:245] Setting up pool7
I0324 23:37:52.531585 29022 net.cpp:252] TEST Top shape for layer 41 'pool7' 8 512 3 6 (73728)
I0324 23:37:52.531594 29022 layer_factory.hpp:136] Creating layer 'pool7_pool7_0_split' of type 'Split'
I0324 23:37:52.531603 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.531613 29022 net.cpp:184] Created Layer pool7_pool7_0_split (42)
I0324 23:37:52.531621 29022 net.cpp:561] pool7_pool7_0_split <- pool7
I0324 23:37:52.531630 29022 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_0
I0324 23:37:52.531641 29022 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_1
I0324 23:37:52.531705 29022 net.cpp:245] Setting up pool7_pool7_0_split
I0324 23:37:52.531719 29022 net.cpp:252] TEST Top shape for layer 42 'pool7_pool7_0_split' 8 512 3 6 (73728)
I0324 23:37:52.531729 29022 net.cpp:252] TEST Top shape for layer 42 'pool7_pool7_0_split' 8 512 3 6 (73728)
I0324 23:37:52.531749 29022 layer_factory.hpp:136] Creating layer 'pool8' of type 'Pooling'
I0324 23:37:52.531764 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.531782 29022 net.cpp:184] Created Layer pool8 (43)
I0324 23:37:52.531792 29022 net.cpp:561] pool8 <- pool7_pool7_0_split_0
I0324 23:37:52.531802 29022 net.cpp:530] pool8 -> pool8
I0324 23:37:52.531898 29022 net.cpp:245] Setting up pool8
I0324 23:37:52.531913 29022 net.cpp:252] TEST Top shape for layer 43 'pool8' 8 512 2 3 (24576)
I0324 23:37:52.531922 29022 layer_factory.hpp:136] Creating layer 'pool8_pool8_0_split' of type 'Split'
I0324 23:37:52.531930 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.531940 29022 net.cpp:184] Created Layer pool8_pool8_0_split (44)
I0324 23:37:52.531947 29022 net.cpp:561] pool8_pool8_0_split <- pool8
I0324 23:37:52.531956 29022 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_0
I0324 23:37:52.531966 29022 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_1
I0324 23:37:52.532030 29022 net.cpp:245] Setting up pool8_pool8_0_split
I0324 23:37:52.532043 29022 net.cpp:252] TEST Top shape for layer 44 'pool8_pool8_0_split' 8 512 2 3 (24576)
I0324 23:37:52.532053 29022 net.cpp:252] TEST Top shape for layer 44 'pool8_pool8_0_split' 8 512 2 3 (24576)
I0324 23:37:52.532063 29022 layer_factory.hpp:136] Creating layer 'pool9' of type 'Pooling'
I0324 23:37:52.532070 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.532083 29022 net.cpp:184] Created Layer pool9 (45)
I0324 23:37:52.532090 29022 net.cpp:561] pool9 <- pool8_pool8_0_split_0
I0324 23:37:52.532100 29022 net.cpp:530] pool9 -> pool9
I0324 23:37:52.532186 29022 net.cpp:245] Setting up pool9
I0324 23:37:52.532200 29022 net.cpp:252] TEST Top shape for layer 45 'pool9' 8 512 1 2 (8192)
I0324 23:37:52.532209 29022 layer_factory.hpp:136] Creating layer 'ctx_output1' of type 'Convolution'
I0324 23:37:52.532218 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.532238 29022 net.cpp:184] Created Layer ctx_output1 (46)
I0324 23:37:52.532248 29022 net.cpp:561] ctx_output1 <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0324 23:37:52.532258 29022 net.cpp:530] ctx_output1 -> ctx_output1
I0324 23:37:52.534162 29022 net.cpp:245] Setting up ctx_output1
I0324 23:37:52.534184 29022 net.cpp:252] TEST Top shape for layer 46 'ctx_output1' 8 256 40 96 (7864320)
I0324 23:37:52.534200 29022 layer_factory.hpp:136] Creating layer 'ctx_output1/relu' of type 'ReLU'
I0324 23:37:52.534211 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.534224 29022 net.cpp:184] Created Layer ctx_output1/relu (47)
I0324 23:37:52.534234 29022 net.cpp:561] ctx_output1/relu <- ctx_output1
I0324 23:37:52.534243 29022 net.cpp:513] ctx_output1/relu -> ctx_output1 (in-place)
I0324 23:37:52.534255 29022 net.cpp:245] Setting up ctx_output1/relu
I0324 23:37:52.534266 29022 net.cpp:252] TEST Top shape for layer 47 'ctx_output1/relu' 8 256 40 96 (7864320)
I0324 23:37:52.534276 29022 layer_factory.hpp:136] Creating layer 'ctx_output1_ctx_output1/relu_0_split' of type 'Split'
I0324 23:37:52.534283 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.534292 29022 net.cpp:184] Created Layer ctx_output1_ctx_output1/relu_0_split (48)
I0324 23:37:52.534301 29022 net.cpp:561] ctx_output1_ctx_output1/relu_0_split <- ctx_output1
I0324 23:37:52.534309 29022 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_0
I0324 23:37:52.534319 29022 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_1
I0324 23:37:52.534328 29022 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_2
I0324 23:37:52.534416 29022 net.cpp:245] Setting up ctx_output1_ctx_output1/relu_0_split
I0324 23:37:52.534443 29022 net.cpp:252] TEST Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 8 256 40 96 (7864320)
I0324 23:37:52.534456 29022 net.cpp:252] TEST Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 8 256 40 96 (7864320)
I0324 23:37:52.534464 29022 net.cpp:252] TEST Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 8 256 40 96 (7864320)
I0324 23:37:52.534473 29022 layer_factory.hpp:136] Creating layer 'ctx_output2' of type 'Convolution'
I0324 23:37:52.534482 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.534499 29022 net.cpp:184] Created Layer ctx_output2 (49)
I0324 23:37:52.534509 29022 net.cpp:561] ctx_output2 <- res5a_branch2b_res5a_branch2b/relu_0_split_1
I0324 23:37:52.534518 29022 net.cpp:530] ctx_output2 -> ctx_output2
I0324 23:37:52.540709 29022 net.cpp:245] Setting up ctx_output2
I0324 23:37:52.540741 29022 net.cpp:252] TEST Top shape for layer 49 'ctx_output2' 8 256 10 24 (491520)
I0324 23:37:52.540758 29022 layer_factory.hpp:136] Creating layer 'ctx_output2/relu' of type 'ReLU'
I0324 23:37:52.540768 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.540781 29022 net.cpp:184] Created Layer ctx_output2/relu (50)
I0324 23:37:52.540791 29022 net.cpp:561] ctx_output2/relu <- ctx_output2
I0324 23:37:52.540801 29022 net.cpp:513] ctx_output2/relu -> ctx_output2 (in-place)
I0324 23:37:52.540813 29022 net.cpp:245] Setting up ctx_output2/relu
I0324 23:37:52.540823 29022 net.cpp:252] TEST Top shape for layer 50 'ctx_output2/relu' 8 256 10 24 (491520)
I0324 23:37:52.540832 29022 layer_factory.hpp:136] Creating layer 'ctx_output2_ctx_output2/relu_0_split' of type 'Split'
I0324 23:37:52.540839 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.540849 29022 net.cpp:184] Created Layer ctx_output2_ctx_output2/relu_0_split (51)
I0324 23:37:52.540858 29022 net.cpp:561] ctx_output2_ctx_output2/relu_0_split <- ctx_output2
I0324 23:37:52.540866 29022 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_0
I0324 23:37:52.540876 29022 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_1
I0324 23:37:52.540886 29022 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_2
I0324 23:37:52.540985 29022 net.cpp:245] Setting up ctx_output2_ctx_output2/relu_0_split
I0324 23:37:52.541002 29022 net.cpp:252] TEST Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 8 256 10 24 (491520)
I0324 23:37:52.541014 29022 net.cpp:252] TEST Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 8 256 10 24 (491520)
I0324 23:37:52.541026 29022 net.cpp:252] TEST Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 8 256 10 24 (491520)
I0324 23:37:52.541035 29022 layer_factory.hpp:136] Creating layer 'ctx_output3' of type 'Convolution'
I0324 23:37:52.541045 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.541065 29022 net.cpp:184] Created Layer ctx_output3 (52)
I0324 23:37:52.541075 29022 net.cpp:561] ctx_output3 <- pool6_pool6_0_split_1
I0324 23:37:52.541085 29022 net.cpp:530] ctx_output3 -> ctx_output3
I0324 23:37:52.548501 29022 net.cpp:245] Setting up ctx_output3
I0324 23:37:52.548532 29022 net.cpp:252] TEST Top shape for layer 52 'ctx_output3' 8 256 5 12 (122880)
I0324 23:37:52.548544 29022 layer_factory.hpp:136] Creating layer 'ctx_output3/relu' of type 'ReLU'
I0324 23:37:52.548552 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.548563 29022 net.cpp:184] Created Layer ctx_output3/relu (53)
I0324 23:37:52.548570 29022 net.cpp:561] ctx_output3/relu <- ctx_output3
I0324 23:37:52.548578 29022 net.cpp:513] ctx_output3/relu -> ctx_output3 (in-place)
I0324 23:37:52.548588 29022 net.cpp:245] Setting up ctx_output3/relu
I0324 23:37:52.548594 29022 net.cpp:252] TEST Top shape for layer 53 'ctx_output3/relu' 8 256 5 12 (122880)
I0324 23:37:52.548621 29022 layer_factory.hpp:136] Creating layer 'ctx_output3_ctx_output3/relu_0_split' of type 'Split'
I0324 23:37:52.548629 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.548635 29022 net.cpp:184] Created Layer ctx_output3_ctx_output3/relu_0_split (54)
I0324 23:37:52.548640 29022 net.cpp:561] ctx_output3_ctx_output3/relu_0_split <- ctx_output3
I0324 23:37:52.548646 29022 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_0
I0324 23:37:52.548655 29022 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_1
I0324 23:37:52.548660 29022 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_2
I0324 23:37:52.548727 29022 net.cpp:245] Setting up ctx_output3_ctx_output3/relu_0_split
I0324 23:37:52.548737 29022 net.cpp:252] TEST Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 8 256 5 12 (122880)
I0324 23:37:52.548743 29022 net.cpp:252] TEST Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 8 256 5 12 (122880)
I0324 23:37:52.548749 29022 net.cpp:252] TEST Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 8 256 5 12 (122880)
I0324 23:37:52.548755 29022 layer_factory.hpp:136] Creating layer 'ctx_output4' of type 'Convolution'
I0324 23:37:52.548761 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.548777 29022 net.cpp:184] Created Layer ctx_output4 (55)
I0324 23:37:52.548784 29022 net.cpp:561] ctx_output4 <- pool7_pool7_0_split_1
I0324 23:37:52.548790 29022 net.cpp:530] ctx_output4 -> ctx_output4
I0324 23:37:52.553175 29022 net.cpp:245] Setting up ctx_output4
I0324 23:37:52.553190 29022 net.cpp:252] TEST Top shape for layer 55 'ctx_output4' 8 256 3 6 (36864)
I0324 23:37:52.553200 29022 layer_factory.hpp:136] Creating layer 'ctx_output4/relu' of type 'ReLU'
I0324 23:37:52.553206 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.553215 29022 net.cpp:184] Created Layer ctx_output4/relu (56)
I0324 23:37:52.553221 29022 net.cpp:561] ctx_output4/relu <- ctx_output4
I0324 23:37:52.553227 29022 net.cpp:513] ctx_output4/relu -> ctx_output4 (in-place)
I0324 23:37:52.553236 29022 net.cpp:245] Setting up ctx_output4/relu
I0324 23:37:52.553242 29022 net.cpp:252] TEST Top shape for layer 56 'ctx_output4/relu' 8 256 3 6 (36864)
I0324 23:37:52.553248 29022 layer_factory.hpp:136] Creating layer 'ctx_output4_ctx_output4/relu_0_split' of type 'Split'
I0324 23:37:52.553253 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.553261 29022 net.cpp:184] Created Layer ctx_output4_ctx_output4/relu_0_split (57)
I0324 23:37:52.553266 29022 net.cpp:561] ctx_output4_ctx_output4/relu_0_split <- ctx_output4
I0324 23:37:52.553272 29022 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_0
I0324 23:37:52.553277 29022 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_1
I0324 23:37:52.553285 29022 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_2
I0324 23:37:52.553354 29022 net.cpp:245] Setting up ctx_output4_ctx_output4/relu_0_split
I0324 23:37:52.553365 29022 net.cpp:252] TEST Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 8 256 3 6 (36864)
I0324 23:37:52.553372 29022 net.cpp:252] TEST Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 8 256 3 6 (36864)
I0324 23:37:52.553380 29022 net.cpp:252] TEST Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 8 256 3 6 (36864)
I0324 23:37:52.553386 29022 layer_factory.hpp:136] Creating layer 'ctx_output5' of type 'Convolution'
I0324 23:37:52.553392 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.553409 29022 net.cpp:184] Created Layer ctx_output5 (58)
I0324 23:37:52.553418 29022 net.cpp:561] ctx_output5 <- pool8_pool8_0_split_1
I0324 23:37:52.553436 29022 net.cpp:530] ctx_output5 -> ctx_output5
I0324 23:37:52.557832 29022 net.cpp:245] Setting up ctx_output5
I0324 23:37:52.557847 29022 net.cpp:252] TEST Top shape for layer 58 'ctx_output5' 8 256 2 3 (12288)
I0324 23:37:52.557857 29022 layer_factory.hpp:136] Creating layer 'ctx_output5/relu' of type 'ReLU'
I0324 23:37:52.557863 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.557871 29022 net.cpp:184] Created Layer ctx_output5/relu (59)
I0324 23:37:52.557878 29022 net.cpp:561] ctx_output5/relu <- ctx_output5
I0324 23:37:52.557883 29022 net.cpp:513] ctx_output5/relu -> ctx_output5 (in-place)
I0324 23:37:52.557893 29022 net.cpp:245] Setting up ctx_output5/relu
I0324 23:37:52.557900 29022 net.cpp:252] TEST Top shape for layer 59 'ctx_output5/relu' 8 256 2 3 (12288)
I0324 23:37:52.557905 29022 layer_factory.hpp:136] Creating layer 'ctx_output5_ctx_output5/relu_0_split' of type 'Split'
I0324 23:37:52.557910 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.557917 29022 net.cpp:184] Created Layer ctx_output5_ctx_output5/relu_0_split (60)
I0324 23:37:52.557922 29022 net.cpp:561] ctx_output5_ctx_output5/relu_0_split <- ctx_output5
I0324 23:37:52.557929 29022 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_0
I0324 23:37:52.557936 29022 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_1
I0324 23:37:52.557942 29022 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_2
I0324 23:37:52.558010 29022 net.cpp:245] Setting up ctx_output5_ctx_output5/relu_0_split
I0324 23:37:52.558020 29022 net.cpp:252] TEST Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 8 256 2 3 (12288)
I0324 23:37:52.558027 29022 net.cpp:252] TEST Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 8 256 2 3 (12288)
I0324 23:37:52.558033 29022 net.cpp:252] TEST Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 8 256 2 3 (12288)
I0324 23:37:52.558039 29022 layer_factory.hpp:136] Creating layer 'ctx_output6' of type 'Convolution'
I0324 23:37:52.558044 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.558063 29022 net.cpp:184] Created Layer ctx_output6 (61)
I0324 23:37:52.558068 29022 net.cpp:561] ctx_output6 <- pool9
I0324 23:37:52.558075 29022 net.cpp:530] ctx_output6 -> ctx_output6
I0324 23:37:52.563745 29022 net.cpp:245] Setting up ctx_output6
I0324 23:37:52.563777 29022 net.cpp:252] TEST Top shape for layer 61 'ctx_output6' 8 256 1 2 (4096)
I0324 23:37:52.563796 29022 layer_factory.hpp:136] Creating layer 'ctx_output6/relu' of type 'ReLU'
I0324 23:37:52.563807 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.563824 29022 net.cpp:184] Created Layer ctx_output6/relu (62)
I0324 23:37:52.563835 29022 net.cpp:561] ctx_output6/relu <- ctx_output6
I0324 23:37:52.563846 29022 net.cpp:513] ctx_output6/relu -> ctx_output6 (in-place)
I0324 23:37:52.563859 29022 net.cpp:245] Setting up ctx_output6/relu
I0324 23:37:52.563869 29022 net.cpp:252] TEST Top shape for layer 62 'ctx_output6/relu' 8 256 1 2 (4096)
I0324 23:37:52.563879 29022 layer_factory.hpp:136] Creating layer 'ctx_output6_ctx_output6/relu_0_split' of type 'Split'
I0324 23:37:52.563886 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.563896 29022 net.cpp:184] Created Layer ctx_output6_ctx_output6/relu_0_split (63)
I0324 23:37:52.563904 29022 net.cpp:561] ctx_output6_ctx_output6/relu_0_split <- ctx_output6
I0324 23:37:52.563912 29022 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_0
I0324 23:37:52.563927 29022 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_1
I0324 23:37:52.563946 29022 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_2
I0324 23:37:52.564080 29022 net.cpp:245] Setting up ctx_output6_ctx_output6/relu_0_split
I0324 23:37:52.564096 29022 net.cpp:252] TEST Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 8 256 1 2 (4096)
I0324 23:37:52.564107 29022 net.cpp:252] TEST Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 8 256 1 2 (4096)
I0324 23:37:52.564117 29022 net.cpp:252] TEST Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 8 256 1 2 (4096)
I0324 23:37:52.564126 29022 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc' of type 'Convolution'
I0324 23:37:52.564134 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.564164 29022 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc (64)
I0324 23:37:52.564174 29022 net.cpp:561] ctx_output1/relu_mbox_loc <- ctx_output1_ctx_output1/relu_0_split_0
I0324 23:37:52.564185 29022 net.cpp:530] ctx_output1/relu_mbox_loc -> ctx_output1/relu_mbox_loc
I0324 23:37:52.564867 29022 net.cpp:245] Setting up ctx_output1/relu_mbox_loc
I0324 23:37:52.564883 29022 net.cpp:252] TEST Top shape for layer 64 'ctx_output1/relu_mbox_loc' 8 16 40 96 (491520)
I0324 23:37:52.564900 29022 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_perm' of type 'Permute'
I0324 23:37:52.564910 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.564929 29022 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_perm (65)
I0324 23:37:52.564939 29022 net.cpp:561] ctx_output1/relu_mbox_loc_perm <- ctx_output1/relu_mbox_loc
I0324 23:37:52.564949 29022 net.cpp:530] ctx_output1/relu_mbox_loc_perm -> ctx_output1/relu_mbox_loc_perm
I0324 23:37:52.565132 29022 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_perm
I0324 23:37:52.565147 29022 net.cpp:252] TEST Top shape for layer 65 'ctx_output1/relu_mbox_loc_perm' 8 40 96 16 (491520)
I0324 23:37:52.565156 29022 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_flat' of type 'Flatten'
I0324 23:37:52.565165 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.565178 29022 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_flat (66)
I0324 23:37:52.565187 29022 net.cpp:561] ctx_output1/relu_mbox_loc_flat <- ctx_output1/relu_mbox_loc_perm
I0324 23:37:52.565197 29022 net.cpp:530] ctx_output1/relu_mbox_loc_flat -> ctx_output1/relu_mbox_loc_flat
I0324 23:37:52.565248 29022 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_flat
I0324 23:37:52.565263 29022 net.cpp:252] TEST Top shape for layer 66 'ctx_output1/relu_mbox_loc_flat' 8 61440 (491520)
I0324 23:37:52.565271 29022 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf' of type 'Convolution'
I0324 23:37:52.565279 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.565307 29022 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf (67)
I0324 23:37:52.565320 29022 net.cpp:561] ctx_output1/relu_mbox_conf <- ctx_output1_ctx_output1/relu_0_split_1
I0324 23:37:52.565330 29022 net.cpp:530] ctx_output1/relu_mbox_conf -> ctx_output1/relu_mbox_conf
I0324 23:37:52.566009 29022 net.cpp:245] Setting up ctx_output1/relu_mbox_conf
I0324 23:37:52.566025 29022 net.cpp:252] TEST Top shape for layer 67 'ctx_output1/relu_mbox_conf' 8 16 40 96 (491520)
I0324 23:37:52.566038 29022 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_perm' of type 'Permute'
I0324 23:37:52.566047 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.566064 29022 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_perm (68)
I0324 23:37:52.566074 29022 net.cpp:561] ctx_output1/relu_mbox_conf_perm <- ctx_output1/relu_mbox_conf
I0324 23:37:52.566084 29022 net.cpp:530] ctx_output1/relu_mbox_conf_perm -> ctx_output1/relu_mbox_conf_perm
I0324 23:37:52.566279 29022 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_perm
I0324 23:37:52.566296 29022 net.cpp:252] TEST Top shape for layer 68 'ctx_output1/relu_mbox_conf_perm' 8 40 96 16 (491520)
I0324 23:37:52.566319 29022 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_flat' of type 'Flatten'
I0324 23:37:52.566329 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.566342 29022 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_flat (69)
I0324 23:37:52.566350 29022 net.cpp:561] ctx_output1/relu_mbox_conf_flat <- ctx_output1/relu_mbox_conf_perm
I0324 23:37:52.566360 29022 net.cpp:530] ctx_output1/relu_mbox_conf_flat -> ctx_output1/relu_mbox_conf_flat
I0324 23:37:52.566406 29022 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_flat
I0324 23:37:52.566421 29022 net.cpp:252] TEST Top shape for layer 69 'ctx_output1/relu_mbox_conf_flat' 8 61440 (491520)
I0324 23:37:52.566428 29022 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_priorbox' of type 'PriorBox'
I0324 23:37:52.566437 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.566452 29022 net.cpp:184] Created Layer ctx_output1/relu_mbox_priorbox (70)
I0324 23:37:52.566460 29022 net.cpp:561] ctx_output1/relu_mbox_priorbox <- ctx_output1_ctx_output1/relu_0_split_2
I0324 23:37:52.566470 29022 net.cpp:561] ctx_output1/relu_mbox_priorbox <- data_data_0_split_1
I0324 23:37:52.566480 29022 net.cpp:530] ctx_output1/relu_mbox_priorbox -> ctx_output1/relu_mbox_priorbox
I0324 23:37:52.566527 29022 net.cpp:245] Setting up ctx_output1/relu_mbox_priorbox
I0324 23:37:52.566541 29022 net.cpp:252] TEST Top shape for layer 70 'ctx_output1/relu_mbox_priorbox' 1 2 61440 (122880)
I0324 23:37:52.566550 29022 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc' of type 'Convolution'
I0324 23:37:52.566558 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.566581 29022 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc (71)
I0324 23:37:52.566591 29022 net.cpp:561] ctx_output2/relu_mbox_loc <- ctx_output2_ctx_output2/relu_0_split_0
I0324 23:37:52.566601 29022 net.cpp:530] ctx_output2/relu_mbox_loc -> ctx_output2/relu_mbox_loc
I0324 23:37:52.567378 29022 net.cpp:245] Setting up ctx_output2/relu_mbox_loc
I0324 23:37:52.567394 29022 net.cpp:252] TEST Top shape for layer 71 'ctx_output2/relu_mbox_loc' 8 24 10 24 (46080)
I0324 23:37:52.567407 29022 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_perm' of type 'Permute'
I0324 23:37:52.567416 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.567432 29022 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_perm (72)
I0324 23:37:52.567441 29022 net.cpp:561] ctx_output2/relu_mbox_loc_perm <- ctx_output2/relu_mbox_loc
I0324 23:37:52.567451 29022 net.cpp:530] ctx_output2/relu_mbox_loc_perm -> ctx_output2/relu_mbox_loc_perm
I0324 23:37:52.567653 29022 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_perm
I0324 23:37:52.567669 29022 net.cpp:252] TEST Top shape for layer 72 'ctx_output2/relu_mbox_loc_perm' 8 10 24 24 (46080)
I0324 23:37:52.567679 29022 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_flat' of type 'Flatten'
I0324 23:37:52.567687 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.567698 29022 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_flat (73)
I0324 23:37:52.567705 29022 net.cpp:561] ctx_output2/relu_mbox_loc_flat <- ctx_output2/relu_mbox_loc_perm
I0324 23:37:52.567715 29022 net.cpp:530] ctx_output2/relu_mbox_loc_flat -> ctx_output2/relu_mbox_loc_flat
I0324 23:37:52.567762 29022 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_flat
I0324 23:37:52.567776 29022 net.cpp:252] TEST Top shape for layer 73 'ctx_output2/relu_mbox_loc_flat' 8 5760 (46080)
I0324 23:37:52.567785 29022 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf' of type 'Convolution'
I0324 23:37:52.567793 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.567826 29022 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf (74)
I0324 23:37:52.567837 29022 net.cpp:561] ctx_output2/relu_mbox_conf <- ctx_output2_ctx_output2/relu_0_split_1
I0324 23:37:52.567847 29022 net.cpp:530] ctx_output2/relu_mbox_conf -> ctx_output2/relu_mbox_conf
I0324 23:37:52.568612 29022 net.cpp:245] Setting up ctx_output2/relu_mbox_conf
I0324 23:37:52.568629 29022 net.cpp:252] TEST Top shape for layer 74 'ctx_output2/relu_mbox_conf' 8 24 10 24 (46080)
I0324 23:37:52.568642 29022 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_perm' of type 'Permute'
I0324 23:37:52.568651 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.568670 29022 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_perm (75)
I0324 23:37:52.568680 29022 net.cpp:561] ctx_output2/relu_mbox_conf_perm <- ctx_output2/relu_mbox_conf
I0324 23:37:52.568688 29022 net.cpp:530] ctx_output2/relu_mbox_conf_perm -> ctx_output2/relu_mbox_conf_perm
I0324 23:37:52.568869 29022 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_perm
I0324 23:37:52.568883 29022 net.cpp:252] TEST Top shape for layer 75 'ctx_output2/relu_mbox_conf_perm' 8 10 24 24 (46080)
I0324 23:37:52.568893 29022 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_flat' of type 'Flatten'
I0324 23:37:52.568907 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.568920 29022 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_flat (76)
I0324 23:37:52.568930 29022 net.cpp:561] ctx_output2/relu_mbox_conf_flat <- ctx_output2/relu_mbox_conf_perm
I0324 23:37:52.568941 29022 net.cpp:530] ctx_output2/relu_mbox_conf_flat -> ctx_output2/relu_mbox_conf_flat
I0324 23:37:52.568992 29022 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_flat
I0324 23:37:52.569007 29022 net.cpp:252] TEST Top shape for layer 76 'ctx_output2/relu_mbox_conf_flat' 8 5760 (46080)
I0324 23:37:52.569016 29022 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_priorbox' of type 'PriorBox'
I0324 23:37:52.569025 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.569037 29022 net.cpp:184] Created Layer ctx_output2/relu_mbox_priorbox (77)
I0324 23:37:52.569046 29022 net.cpp:561] ctx_output2/relu_mbox_priorbox <- ctx_output2_ctx_output2/relu_0_split_2
I0324 23:37:52.569057 29022 net.cpp:561] ctx_output2/relu_mbox_priorbox <- data_data_0_split_2
I0324 23:37:52.569067 29022 net.cpp:530] ctx_output2/relu_mbox_priorbox -> ctx_output2/relu_mbox_priorbox
I0324 23:37:52.569113 29022 net.cpp:245] Setting up ctx_output2/relu_mbox_priorbox
I0324 23:37:52.569126 29022 net.cpp:252] TEST Top shape for layer 77 'ctx_output2/relu_mbox_priorbox' 1 2 5760 (11520)
I0324 23:37:52.569135 29022 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc' of type 'Convolution'
I0324 23:37:52.569144 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.569166 29022 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc (78)
I0324 23:37:52.569176 29022 net.cpp:561] ctx_output3/relu_mbox_loc <- ctx_output3_ctx_output3/relu_0_split_0
I0324 23:37:52.569186 29022 net.cpp:530] ctx_output3/relu_mbox_loc -> ctx_output3/relu_mbox_loc
I0324 23:37:52.569967 29022 net.cpp:245] Setting up ctx_output3/relu_mbox_loc
I0324 23:37:52.569983 29022 net.cpp:252] TEST Top shape for layer 78 'ctx_output3/relu_mbox_loc' 8 24 5 12 (11520)
I0324 23:37:52.569998 29022 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_perm' of type 'Permute'
I0324 23:37:52.570005 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.570020 29022 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_perm (79)
I0324 23:37:52.570029 29022 net.cpp:561] ctx_output3/relu_mbox_loc_perm <- ctx_output3/relu_mbox_loc
I0324 23:37:52.570039 29022 net.cpp:530] ctx_output3/relu_mbox_loc_perm -> ctx_output3/relu_mbox_loc_perm
I0324 23:37:52.570238 29022 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_perm
I0324 23:37:52.570256 29022 net.cpp:252] TEST Top shape for layer 79 'ctx_output3/relu_mbox_loc_perm' 8 5 12 24 (11520)
I0324 23:37:52.570266 29022 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_flat' of type 'Flatten'
I0324 23:37:52.570276 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.570287 29022 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_flat (80)
I0324 23:37:52.570297 29022 net.cpp:561] ctx_output3/relu_mbox_loc_flat <- ctx_output3/relu_mbox_loc_perm
I0324 23:37:52.570307 29022 net.cpp:530] ctx_output3/relu_mbox_loc_flat -> ctx_output3/relu_mbox_loc_flat
I0324 23:37:52.570354 29022 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_flat
I0324 23:37:52.570371 29022 net.cpp:252] TEST Top shape for layer 80 'ctx_output3/relu_mbox_loc_flat' 8 1440 (11520)
I0324 23:37:52.570380 29022 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf' of type 'Convolution'
I0324 23:37:52.570389 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.570410 29022 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf (81)
I0324 23:37:52.570420 29022 net.cpp:561] ctx_output3/relu_mbox_conf <- ctx_output3_ctx_output3/relu_0_split_1
I0324 23:37:52.570430 29022 net.cpp:530] ctx_output3/relu_mbox_conf -> ctx_output3/relu_mbox_conf
I0324 23:37:52.571182 29022 net.cpp:245] Setting up ctx_output3/relu_mbox_conf
I0324 23:37:52.571202 29022 net.cpp:252] TEST Top shape for layer 81 'ctx_output3/relu_mbox_conf' 8 24 5 12 (11520)
I0324 23:37:52.571216 29022 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_perm' of type 'Permute'
I0324 23:37:52.571226 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.571244 29022 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_perm (82)
I0324 23:37:52.571254 29022 net.cpp:561] ctx_output3/relu_mbox_conf_perm <- ctx_output3/relu_mbox_conf
I0324 23:37:52.571264 29022 net.cpp:530] ctx_output3/relu_mbox_conf_perm -> ctx_output3/relu_mbox_conf_perm
I0324 23:37:52.571450 29022 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_perm
I0324 23:37:52.571466 29022 net.cpp:252] TEST Top shape for layer 82 'ctx_output3/relu_mbox_conf_perm' 8 5 12 24 (11520)
I0324 23:37:52.571475 29022 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_flat' of type 'Flatten'
I0324 23:37:52.571485 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.571494 29022 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_flat (83)
I0324 23:37:52.571503 29022 net.cpp:561] ctx_output3/relu_mbox_conf_flat <- ctx_output3/relu_mbox_conf_perm
I0324 23:37:52.571513 29022 net.cpp:530] ctx_output3/relu_mbox_conf_flat -> ctx_output3/relu_mbox_conf_flat
I0324 23:37:52.571559 29022 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_flat
I0324 23:37:52.571573 29022 net.cpp:252] TEST Top shape for layer 83 'ctx_output3/relu_mbox_conf_flat' 8 1440 (11520)
I0324 23:37:52.571581 29022 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_priorbox' of type 'PriorBox'
I0324 23:37:52.571590 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.571605 29022 net.cpp:184] Created Layer ctx_output3/relu_mbox_priorbox (84)
I0324 23:37:52.571614 29022 net.cpp:561] ctx_output3/relu_mbox_priorbox <- ctx_output3_ctx_output3/relu_0_split_2
I0324 23:37:52.571625 29022 net.cpp:561] ctx_output3/relu_mbox_priorbox <- data_data_0_split_3
I0324 23:37:52.571638 29022 net.cpp:530] ctx_output3/relu_mbox_priorbox -> ctx_output3/relu_mbox_priorbox
I0324 23:37:52.571692 29022 net.cpp:245] Setting up ctx_output3/relu_mbox_priorbox
I0324 23:37:52.571708 29022 net.cpp:252] TEST Top shape for layer 84 'ctx_output3/relu_mbox_priorbox' 1 2 1440 (2880)
I0324 23:37:52.571718 29022 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc' of type 'Convolution'
I0324 23:37:52.571743 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.571765 29022 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc (85)
I0324 23:37:52.571775 29022 net.cpp:561] ctx_output4/relu_mbox_loc <- ctx_output4_ctx_output4/relu_0_split_0
I0324 23:37:52.571786 29022 net.cpp:530] ctx_output4/relu_mbox_loc -> ctx_output4/relu_mbox_loc
I0324 23:37:52.572557 29022 net.cpp:245] Setting up ctx_output4/relu_mbox_loc
I0324 23:37:52.572576 29022 net.cpp:252] TEST Top shape for layer 85 'ctx_output4/relu_mbox_loc' 8 24 3 6 (3456)
I0324 23:37:52.572590 29022 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_perm' of type 'Permute'
I0324 23:37:52.572599 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.572614 29022 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_perm (86)
I0324 23:37:52.572623 29022 net.cpp:561] ctx_output4/relu_mbox_loc_perm <- ctx_output4/relu_mbox_loc
I0324 23:37:52.572633 29022 net.cpp:530] ctx_output4/relu_mbox_loc_perm -> ctx_output4/relu_mbox_loc_perm
I0324 23:37:52.572818 29022 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_perm
I0324 23:37:52.572834 29022 net.cpp:252] TEST Top shape for layer 86 'ctx_output4/relu_mbox_loc_perm' 8 3 6 24 (3456)
I0324 23:37:52.572842 29022 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_flat' of type 'Flatten'
I0324 23:37:52.572850 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.572863 29022 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_flat (87)
I0324 23:37:52.572872 29022 net.cpp:561] ctx_output4/relu_mbox_loc_flat <- ctx_output4/relu_mbox_loc_perm
I0324 23:37:52.572881 29022 net.cpp:530] ctx_output4/relu_mbox_loc_flat -> ctx_output4/relu_mbox_loc_flat
I0324 23:37:52.572928 29022 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_flat
I0324 23:37:52.572947 29022 net.cpp:252] TEST Top shape for layer 87 'ctx_output4/relu_mbox_loc_flat' 8 432 (3456)
I0324 23:37:52.572957 29022 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf' of type 'Convolution'
I0324 23:37:52.572966 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.572990 29022 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf (88)
I0324 23:37:52.573000 29022 net.cpp:561] ctx_output4/relu_mbox_conf <- ctx_output4_ctx_output4/relu_0_split_1
I0324 23:37:52.573011 29022 net.cpp:530] ctx_output4/relu_mbox_conf -> ctx_output4/relu_mbox_conf
I0324 23:37:52.573786 29022 net.cpp:245] Setting up ctx_output4/relu_mbox_conf
I0324 23:37:52.573803 29022 net.cpp:252] TEST Top shape for layer 88 'ctx_output4/relu_mbox_conf' 8 24 3 6 (3456)
I0324 23:37:52.573817 29022 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_perm' of type 'Permute'
I0324 23:37:52.573827 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.573846 29022 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_perm (89)
I0324 23:37:52.573858 29022 net.cpp:561] ctx_output4/relu_mbox_conf_perm <- ctx_output4/relu_mbox_conf
I0324 23:37:52.573873 29022 net.cpp:530] ctx_output4/relu_mbox_conf_perm -> ctx_output4/relu_mbox_conf_perm
I0324 23:37:52.574074 29022 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_perm
I0324 23:37:52.574090 29022 net.cpp:252] TEST Top shape for layer 89 'ctx_output4/relu_mbox_conf_perm' 8 3 6 24 (3456)
I0324 23:37:52.574098 29022 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_flat' of type 'Flatten'
I0324 23:37:52.574106 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.574120 29022 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_flat (90)
I0324 23:37:52.574129 29022 net.cpp:561] ctx_output4/relu_mbox_conf_flat <- ctx_output4/relu_mbox_conf_perm
I0324 23:37:52.574139 29022 net.cpp:530] ctx_output4/relu_mbox_conf_flat -> ctx_output4/relu_mbox_conf_flat
I0324 23:37:52.574198 29022 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_flat
I0324 23:37:52.574213 29022 net.cpp:252] TEST Top shape for layer 90 'ctx_output4/relu_mbox_conf_flat' 8 432 (3456)
I0324 23:37:52.574223 29022 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_priorbox' of type 'PriorBox'
I0324 23:37:52.574230 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.574244 29022 net.cpp:184] Created Layer ctx_output4/relu_mbox_priorbox (91)
I0324 23:37:52.574254 29022 net.cpp:561] ctx_output4/relu_mbox_priorbox <- ctx_output4_ctx_output4/relu_0_split_2
I0324 23:37:52.574268 29022 net.cpp:561] ctx_output4/relu_mbox_priorbox <- data_data_0_split_4
I0324 23:37:52.574280 29022 net.cpp:530] ctx_output4/relu_mbox_priorbox -> ctx_output4/relu_mbox_priorbox
I0324 23:37:52.574331 29022 net.cpp:245] Setting up ctx_output4/relu_mbox_priorbox
I0324 23:37:52.574347 29022 net.cpp:252] TEST Top shape for layer 91 'ctx_output4/relu_mbox_priorbox' 1 2 432 (864)
I0324 23:37:52.574357 29022 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc' of type 'Convolution'
I0324 23:37:52.574364 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.574388 29022 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc (92)
I0324 23:37:52.574398 29022 net.cpp:561] ctx_output5/relu_mbox_loc <- ctx_output5_ctx_output5/relu_0_split_0
I0324 23:37:52.574407 29022 net.cpp:530] ctx_output5/relu_mbox_loc -> ctx_output5/relu_mbox_loc
I0324 23:37:52.575076 29022 net.cpp:245] Setting up ctx_output5/relu_mbox_loc
I0324 23:37:52.575093 29022 net.cpp:252] TEST Top shape for layer 92 'ctx_output5/relu_mbox_loc' 8 16 2 3 (768)
I0324 23:37:52.575107 29022 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_perm' of type 'Permute'
I0324 23:37:52.575117 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.575143 29022 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_perm (93)
I0324 23:37:52.575156 29022 net.cpp:561] ctx_output5/relu_mbox_loc_perm <- ctx_output5/relu_mbox_loc
I0324 23:37:52.575167 29022 net.cpp:530] ctx_output5/relu_mbox_loc_perm -> ctx_output5/relu_mbox_loc_perm
I0324 23:37:52.590670 29022 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_perm
I0324 23:37:52.590699 29022 net.cpp:252] TEST Top shape for layer 93 'ctx_output5/relu_mbox_loc_perm' 8 2 3 16 (768)
I0324 23:37:52.590713 29022 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_flat' of type 'Flatten'
I0324 23:37:52.590724 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.590740 29022 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_flat (94)
I0324 23:37:52.590750 29022 net.cpp:561] ctx_output5/relu_mbox_loc_flat <- ctx_output5/relu_mbox_loc_perm
I0324 23:37:52.590764 29022 net.cpp:530] ctx_output5/relu_mbox_loc_flat -> ctx_output5/relu_mbox_loc_flat
I0324 23:37:52.590816 29022 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_flat
I0324 23:37:52.590831 29022 net.cpp:252] TEST Top shape for layer 94 'ctx_output5/relu_mbox_loc_flat' 8 96 (768)
I0324 23:37:52.590840 29022 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf' of type 'Convolution'
I0324 23:37:52.590850 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.590878 29022 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf (95)
I0324 23:37:52.590889 29022 net.cpp:561] ctx_output5/relu_mbox_conf <- ctx_output5_ctx_output5/relu_0_split_1
I0324 23:37:52.590903 29022 net.cpp:530] ctx_output5/relu_mbox_conf -> ctx_output5/relu_mbox_conf
I0324 23:37:52.591694 29022 net.cpp:245] Setting up ctx_output5/relu_mbox_conf
I0324 23:37:52.591712 29022 net.cpp:252] TEST Top shape for layer 95 'ctx_output5/relu_mbox_conf' 8 16 2 3 (768)
I0324 23:37:52.591729 29022 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_perm' of type 'Permute'
I0324 23:37:52.591740 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.591778 29022 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_perm (96)
I0324 23:37:52.591790 29022 net.cpp:561] ctx_output5/relu_mbox_conf_perm <- ctx_output5/relu_mbox_conf
I0324 23:37:52.591801 29022 net.cpp:530] ctx_output5/relu_mbox_conf_perm -> ctx_output5/relu_mbox_conf_perm
I0324 23:37:52.592005 29022 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_perm
I0324 23:37:52.592020 29022 net.cpp:252] TEST Top shape for layer 96 'ctx_output5/relu_mbox_conf_perm' 8 2 3 16 (768)
I0324 23:37:52.592030 29022 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_flat' of type 'Flatten'
I0324 23:37:52.592038 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.592054 29022 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_flat (97)
I0324 23:37:52.592067 29022 net.cpp:561] ctx_output5/relu_mbox_conf_flat <- ctx_output5/relu_mbox_conf_perm
I0324 23:37:52.592077 29022 net.cpp:530] ctx_output5/relu_mbox_conf_flat -> ctx_output5/relu_mbox_conf_flat
I0324 23:37:52.592128 29022 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_flat
I0324 23:37:52.592144 29022 net.cpp:252] TEST Top shape for layer 97 'ctx_output5/relu_mbox_conf_flat' 8 96 (768)
I0324 23:37:52.592154 29022 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_priorbox' of type 'PriorBox'
I0324 23:37:52.592164 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.592180 29022 net.cpp:184] Created Layer ctx_output5/relu_mbox_priorbox (98)
I0324 23:37:52.592190 29022 net.cpp:561] ctx_output5/relu_mbox_priorbox <- ctx_output5_ctx_output5/relu_0_split_2
I0324 23:37:52.592201 29022 net.cpp:561] ctx_output5/relu_mbox_priorbox <- data_data_0_split_5
I0324 23:37:52.592217 29022 net.cpp:530] ctx_output5/relu_mbox_priorbox -> ctx_output5/relu_mbox_priorbox
I0324 23:37:52.592274 29022 net.cpp:245] Setting up ctx_output5/relu_mbox_priorbox
I0324 23:37:52.592290 29022 net.cpp:252] TEST Top shape for layer 98 'ctx_output5/relu_mbox_priorbox' 1 2 96 (192)
I0324 23:37:52.592300 29022 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc' of type 'Convolution'
I0324 23:37:52.592311 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.592334 29022 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc (99)
I0324 23:37:52.592344 29022 net.cpp:561] ctx_output6/relu_mbox_loc <- ctx_output6_ctx_output6/relu_0_split_0
I0324 23:37:52.592355 29022 net.cpp:530] ctx_output6/relu_mbox_loc -> ctx_output6/relu_mbox_loc
I0324 23:37:52.593040 29022 net.cpp:245] Setting up ctx_output6/relu_mbox_loc
I0324 23:37:52.593057 29022 net.cpp:252] TEST Top shape for layer 99 'ctx_output6/relu_mbox_loc' 8 16 1 2 (256)
I0324 23:37:52.593070 29022 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_perm' of type 'Permute'
I0324 23:37:52.593078 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.593093 29022 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_perm (100)
I0324 23:37:52.593102 29022 net.cpp:561] ctx_output6/relu_mbox_loc_perm <- ctx_output6/relu_mbox_loc
I0324 23:37:52.593111 29022 net.cpp:530] ctx_output6/relu_mbox_loc_perm -> ctx_output6/relu_mbox_loc_perm
I0324 23:37:52.593322 29022 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_perm
I0324 23:37:52.593338 29022 net.cpp:252] TEST Top shape for layer 100 'ctx_output6/relu_mbox_loc_perm' 8 1 2 16 (256)
I0324 23:37:52.593346 29022 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_flat' of type 'Flatten'
I0324 23:37:52.593354 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.593364 29022 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_flat (101)
I0324 23:37:52.593372 29022 net.cpp:561] ctx_output6/relu_mbox_loc_flat <- ctx_output6/relu_mbox_loc_perm
I0324 23:37:52.593381 29022 net.cpp:530] ctx_output6/relu_mbox_loc_flat -> ctx_output6/relu_mbox_loc_flat
I0324 23:37:52.593442 29022 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_flat
I0324 23:37:52.593457 29022 net.cpp:252] TEST Top shape for layer 101 'ctx_output6/relu_mbox_loc_flat' 8 32 (256)
I0324 23:37:52.593466 29022 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf' of type 'Convolution'
I0324 23:37:52.593474 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.593497 29022 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf (102)
I0324 23:37:52.593505 29022 net.cpp:561] ctx_output6/relu_mbox_conf <- ctx_output6_ctx_output6/relu_0_split_1
I0324 23:37:52.593515 29022 net.cpp:530] ctx_output6/relu_mbox_conf -> ctx_output6/relu_mbox_conf
I0324 23:37:52.594224 29022 net.cpp:245] Setting up ctx_output6/relu_mbox_conf
I0324 23:37:52.594245 29022 net.cpp:252] TEST Top shape for layer 102 'ctx_output6/relu_mbox_conf' 8 16 1 2 (256)
I0324 23:37:52.594260 29022 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_perm' of type 'Permute'
I0324 23:37:52.594270 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.594286 29022 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_perm (103)
I0324 23:37:52.594296 29022 net.cpp:561] ctx_output6/relu_mbox_conf_perm <- ctx_output6/relu_mbox_conf
I0324 23:37:52.594306 29022 net.cpp:530] ctx_output6/relu_mbox_conf_perm -> ctx_output6/relu_mbox_conf_perm
I0324 23:37:52.594516 29022 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_perm
I0324 23:37:52.594538 29022 net.cpp:252] TEST Top shape for layer 103 'ctx_output6/relu_mbox_conf_perm' 8 1 2 16 (256)
I0324 23:37:52.594555 29022 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_flat' of type 'Flatten'
I0324 23:37:52.594569 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.594590 29022 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_flat (104)
I0324 23:37:52.594607 29022 net.cpp:561] ctx_output6/relu_mbox_conf_flat <- ctx_output6/relu_mbox_conf_perm
I0324 23:37:52.594624 29022 net.cpp:530] ctx_output6/relu_mbox_conf_flat -> ctx_output6/relu_mbox_conf_flat
I0324 23:37:52.618624 29022 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_flat
I0324 23:37:52.618647 29022 net.cpp:252] TEST Top shape for layer 104 'ctx_output6/relu_mbox_conf_flat' 8 32 (256)
I0324 23:37:52.618656 29022 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_priorbox' of type 'PriorBox'
I0324 23:37:52.618664 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.618677 29022 net.cpp:184] Created Layer ctx_output6/relu_mbox_priorbox (105)
I0324 23:37:52.618685 29022 net.cpp:561] ctx_output6/relu_mbox_priorbox <- ctx_output6_ctx_output6/relu_0_split_2
I0324 23:37:52.618692 29022 net.cpp:561] ctx_output6/relu_mbox_priorbox <- data_data_0_split_6
I0324 23:37:52.618700 29022 net.cpp:530] ctx_output6/relu_mbox_priorbox -> ctx_output6/relu_mbox_priorbox
I0324 23:37:52.618741 29022 net.cpp:245] Setting up ctx_output6/relu_mbox_priorbox
I0324 23:37:52.618753 29022 net.cpp:252] TEST Top shape for layer 105 'ctx_output6/relu_mbox_priorbox' 1 2 32 (64)
I0324 23:37:52.618760 29022 layer_factory.hpp:136] Creating layer 'mbox_loc' of type 'Concat'
I0324 23:37:52.618765 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.618774 29022 net.cpp:184] Created Layer mbox_loc (106)
I0324 23:37:52.618782 29022 net.cpp:561] mbox_loc <- ctx_output1/relu_mbox_loc_flat
I0324 23:37:52.618788 29022 net.cpp:561] mbox_loc <- ctx_output2/relu_mbox_loc_flat
I0324 23:37:52.618795 29022 net.cpp:561] mbox_loc <- ctx_output3/relu_mbox_loc_flat
I0324 23:37:52.618803 29022 net.cpp:561] mbox_loc <- ctx_output4/relu_mbox_loc_flat
I0324 23:37:52.618808 29022 net.cpp:561] mbox_loc <- ctx_output5/relu_mbox_loc_flat
I0324 23:37:52.618814 29022 net.cpp:561] mbox_loc <- ctx_output6/relu_mbox_loc_flat
I0324 23:37:52.618820 29022 net.cpp:530] mbox_loc -> mbox_loc
I0324 23:37:52.618876 29022 net.cpp:245] Setting up mbox_loc
I0324 23:37:52.618887 29022 net.cpp:252] TEST Top shape for layer 106 'mbox_loc' 8 69200 (553600)
I0324 23:37:52.618893 29022 layer_factory.hpp:136] Creating layer 'mbox_conf' of type 'Concat'
I0324 23:37:52.618898 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.618906 29022 net.cpp:184] Created Layer mbox_conf (107)
I0324 23:37:52.618912 29022 net.cpp:561] mbox_conf <- ctx_output1/relu_mbox_conf_flat
I0324 23:37:52.618919 29022 net.cpp:561] mbox_conf <- ctx_output2/relu_mbox_conf_flat
I0324 23:37:52.618926 29022 net.cpp:561] mbox_conf <- ctx_output3/relu_mbox_conf_flat
I0324 23:37:52.618932 29022 net.cpp:561] mbox_conf <- ctx_output4/relu_mbox_conf_flat
I0324 23:37:52.618937 29022 net.cpp:561] mbox_conf <- ctx_output5/relu_mbox_conf_flat
I0324 23:37:52.618943 29022 net.cpp:561] mbox_conf <- ctx_output6/relu_mbox_conf_flat
I0324 23:37:52.618948 29022 net.cpp:530] mbox_conf -> mbox_conf
I0324 23:37:52.618983 29022 net.cpp:245] Setting up mbox_conf
I0324 23:37:52.618993 29022 net.cpp:252] TEST Top shape for layer 107 'mbox_conf' 8 69200 (553600)
I0324 23:37:52.618999 29022 layer_factory.hpp:136] Creating layer 'mbox_priorbox' of type 'Concat'
I0324 23:37:52.619004 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.619012 29022 net.cpp:184] Created Layer mbox_priorbox (108)
I0324 23:37:52.619019 29022 net.cpp:561] mbox_priorbox <- ctx_output1/relu_mbox_priorbox
I0324 23:37:52.619024 29022 net.cpp:561] mbox_priorbox <- ctx_output2/relu_mbox_priorbox
I0324 23:37:52.619030 29022 net.cpp:561] mbox_priorbox <- ctx_output3/relu_mbox_priorbox
I0324 23:37:52.619036 29022 net.cpp:561] mbox_priorbox <- ctx_output4/relu_mbox_priorbox
I0324 23:37:52.619041 29022 net.cpp:561] mbox_priorbox <- ctx_output5/relu_mbox_priorbox
I0324 23:37:52.619047 29022 net.cpp:561] mbox_priorbox <- ctx_output6/relu_mbox_priorbox
I0324 23:37:52.619053 29022 net.cpp:530] mbox_priorbox -> mbox_priorbox
I0324 23:37:52.619086 29022 net.cpp:245] Setting up mbox_priorbox
I0324 23:37:52.619098 29022 net.cpp:252] TEST Top shape for layer 108 'mbox_priorbox' 1 2 69200 (138400)
I0324 23:37:52.619104 29022 layer_factory.hpp:136] Creating layer 'mbox_conf_reshape' of type 'Reshape'
I0324 23:37:52.619110 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.619122 29022 net.cpp:184] Created Layer mbox_conf_reshape (109)
I0324 23:37:52.619127 29022 net.cpp:561] mbox_conf_reshape <- mbox_conf
I0324 23:37:52.619133 29022 net.cpp:530] mbox_conf_reshape -> mbox_conf_reshape
I0324 23:37:52.619171 29022 net.cpp:245] Setting up mbox_conf_reshape
I0324 23:37:52.619182 29022 net.cpp:252] TEST Top shape for layer 109 'mbox_conf_reshape' 8 17300 4 (553600)
I0324 23:37:52.619189 29022 layer_factory.hpp:136] Creating layer 'mbox_conf_softmax' of type 'Softmax'
I0324 23:37:52.619194 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.619210 29022 net.cpp:184] Created Layer mbox_conf_softmax (110)
I0324 23:37:52.619216 29022 net.cpp:561] mbox_conf_softmax <- mbox_conf_reshape
I0324 23:37:52.619223 29022 net.cpp:530] mbox_conf_softmax -> mbox_conf_softmax
I0324 23:37:52.619307 29022 net.cpp:245] Setting up mbox_conf_softmax
I0324 23:37:52.619318 29022 net.cpp:252] TEST Top shape for layer 110 'mbox_conf_softmax' 8 17300 4 (553600)
I0324 23:37:52.619325 29022 layer_factory.hpp:136] Creating layer 'mbox_conf_flatten' of type 'Flatten'
I0324 23:37:52.619331 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.619340 29022 net.cpp:184] Created Layer mbox_conf_flatten (111)
I0324 23:37:52.619346 29022 net.cpp:561] mbox_conf_flatten <- mbox_conf_softmax
I0324 23:37:52.619351 29022 net.cpp:530] mbox_conf_flatten -> mbox_conf_flatten
I0324 23:37:52.619383 29022 net.cpp:245] Setting up mbox_conf_flatten
I0324 23:37:52.619402 29022 net.cpp:252] TEST Top shape for layer 111 'mbox_conf_flatten' 8 69200 (553600)
I0324 23:37:52.619410 29022 layer_factory.hpp:136] Creating layer 'detection_out' of type 'DetectionOutput'
I0324 23:37:52.619415 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.619436 29022 net.cpp:184] Created Layer detection_out (112)
I0324 23:37:52.619443 29022 net.cpp:561] detection_out <- mbox_loc
I0324 23:37:52.619449 29022 net.cpp:561] detection_out <- mbox_conf_flatten
I0324 23:37:52.619455 29022 net.cpp:561] detection_out <- mbox_priorbox
I0324 23:37:52.619462 29022 net.cpp:530] detection_out -> detection_out
I0324 23:37:52.648674 29022 net.cpp:245] Setting up detection_out
I0324 23:37:52.648700 29022 net.cpp:252] TEST Top shape for layer 112 'detection_out' 1 1 1 7 (7)
I0324 23:37:52.648710 29022 layer_factory.hpp:136] Creating layer 'detection_eval' of type 'DetectionEvaluate'
I0324 23:37:52.648717 29022 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 23:37:52.648732 29022 net.cpp:184] Created Layer detection_eval (113)
I0324 23:37:52.648739 29022 net.cpp:561] detection_eval <- detection_out
I0324 23:37:52.648747 29022 net.cpp:561] detection_eval <- label
I0324 23:37:52.648754 29022 net.cpp:530] detection_eval -> detection_eval
I0324 23:37:52.650524 29022 net.cpp:245] Setting up detection_eval
I0324 23:37:52.650542 29022 net.cpp:252] TEST Top shape for layer 113 'detection_eval' 1 1 4 5 (20)
I0324 23:37:52.650552 29022 net.cpp:325] detection_eval does not need backward computation.
I0324 23:37:52.650562 29022 net.cpp:325] detection_out does not need backward computation.
I0324 23:37:52.650571 29022 net.cpp:325] mbox_conf_flatten does not need backward computation.
I0324 23:37:52.650579 29022 net.cpp:325] mbox_conf_softmax does not need backward computation.
I0324 23:37:52.650588 29022 net.cpp:325] mbox_conf_reshape does not need backward computation.
I0324 23:37:52.650596 29022 net.cpp:325] mbox_priorbox does not need backward computation.
I0324 23:37:52.650607 29022 net.cpp:325] mbox_conf does not need backward computation.
I0324 23:37:52.650619 29022 net.cpp:325] mbox_loc does not need backward computation.
I0324 23:37:52.650629 29022 net.cpp:325] ctx_output6/relu_mbox_priorbox does not need backward computation.
I0324 23:37:52.650637 29022 net.cpp:325] ctx_output6/relu_mbox_conf_flat does not need backward computation.
I0324 23:37:52.650646 29022 net.cpp:325] ctx_output6/relu_mbox_conf_perm does not need backward computation.
I0324 23:37:52.650655 29022 net.cpp:325] ctx_output6/relu_mbox_conf does not need backward computation.
I0324 23:37:52.650665 29022 net.cpp:325] ctx_output6/relu_mbox_loc_flat does not need backward computation.
I0324 23:37:52.650672 29022 net.cpp:325] ctx_output6/relu_mbox_loc_perm does not need backward computation.
I0324 23:37:52.650681 29022 net.cpp:325] ctx_output6/relu_mbox_loc does not need backward computation.
I0324 23:37:52.650691 29022 net.cpp:325] ctx_output5/relu_mbox_priorbox does not need backward computation.
I0324 23:37:52.650699 29022 net.cpp:325] ctx_output5/relu_mbox_conf_flat does not need backward computation.
I0324 23:37:52.650707 29022 net.cpp:325] ctx_output5/relu_mbox_conf_perm does not need backward computation.
I0324 23:37:52.650717 29022 net.cpp:325] ctx_output5/relu_mbox_conf does not need backward computation.
I0324 23:37:52.650724 29022 net.cpp:325] ctx_output5/relu_mbox_loc_flat does not need backward computation.
I0324 23:37:52.650733 29022 net.cpp:325] ctx_output5/relu_mbox_loc_perm does not need backward computation.
I0324 23:37:52.650741 29022 net.cpp:325] ctx_output5/relu_mbox_loc does not need backward computation.
I0324 23:37:52.650750 29022 net.cpp:325] ctx_output4/relu_mbox_priorbox does not need backward computation.
I0324 23:37:52.650760 29022 net.cpp:325] ctx_output4/relu_mbox_conf_flat does not need backward computation.
I0324 23:37:52.650768 29022 net.cpp:325] ctx_output4/relu_mbox_conf_perm does not need backward computation.
I0324 23:37:52.650796 29022 net.cpp:325] ctx_output4/relu_mbox_conf does not need backward computation.
I0324 23:37:52.650806 29022 net.cpp:325] ctx_output4/relu_mbox_loc_flat does not need backward computation.
I0324 23:37:52.650815 29022 net.cpp:325] ctx_output4/relu_mbox_loc_perm does not need backward computation.
I0324 23:37:52.650823 29022 net.cpp:325] ctx_output4/relu_mbox_loc does not need backward computation.
I0324 23:37:52.650832 29022 net.cpp:325] ctx_output3/relu_mbox_priorbox does not need backward computation.
I0324 23:37:52.650841 29022 net.cpp:325] ctx_output3/relu_mbox_conf_flat does not need backward computation.
I0324 23:37:52.650851 29022 net.cpp:325] ctx_output3/relu_mbox_conf_perm does not need backward computation.
I0324 23:37:52.650858 29022 net.cpp:325] ctx_output3/relu_mbox_conf does not need backward computation.
I0324 23:37:52.650867 29022 net.cpp:325] ctx_output3/relu_mbox_loc_flat does not need backward computation.
I0324 23:37:52.650876 29022 net.cpp:325] ctx_output3/relu_mbox_loc_perm does not need backward computation.
I0324 23:37:52.650884 29022 net.cpp:325] ctx_output3/relu_mbox_loc does not need backward computation.
I0324 23:37:52.650892 29022 net.cpp:325] ctx_output2/relu_mbox_priorbox does not need backward computation.
I0324 23:37:52.650902 29022 net.cpp:325] ctx_output2/relu_mbox_conf_flat does not need backward computation.
I0324 23:37:52.650910 29022 net.cpp:325] ctx_output2/relu_mbox_conf_perm does not need backward computation.
I0324 23:37:52.650919 29022 net.cpp:325] ctx_output2/relu_mbox_conf does not need backward computation.
I0324 23:37:52.650928 29022 net.cpp:325] ctx_output2/relu_mbox_loc_flat does not need backward computation.
I0324 23:37:52.650935 29022 net.cpp:325] ctx_output2/relu_mbox_loc_perm does not need backward computation.
I0324 23:37:52.650944 29022 net.cpp:325] ctx_output2/relu_mbox_loc does not need backward computation.
I0324 23:37:52.650952 29022 net.cpp:325] ctx_output1/relu_mbox_priorbox does not need backward computation.
I0324 23:37:52.650961 29022 net.cpp:325] ctx_output1/relu_mbox_conf_flat does not need backward computation.
I0324 23:37:52.650971 29022 net.cpp:325] ctx_output1/relu_mbox_conf_perm does not need backward computation.
I0324 23:37:52.650980 29022 net.cpp:325] ctx_output1/relu_mbox_conf does not need backward computation.
I0324 23:37:52.650988 29022 net.cpp:325] ctx_output1/relu_mbox_loc_flat does not need backward computation.
I0324 23:37:52.650997 29022 net.cpp:325] ctx_output1/relu_mbox_loc_perm does not need backward computation.
I0324 23:37:52.651005 29022 net.cpp:325] ctx_output1/relu_mbox_loc does not need backward computation.
I0324 23:37:52.651015 29022 net.cpp:325] ctx_output6_ctx_output6/relu_0_split does not need backward computation.
I0324 23:37:52.651023 29022 net.cpp:325] ctx_output6/relu does not need backward computation.
I0324 23:37:52.651031 29022 net.cpp:325] ctx_output6 does not need backward computation.
I0324 23:37:52.651041 29022 net.cpp:325] ctx_output5_ctx_output5/relu_0_split does not need backward computation.
I0324 23:37:52.651049 29022 net.cpp:325] ctx_output5/relu does not need backward computation.
I0324 23:37:52.651057 29022 net.cpp:325] ctx_output5 does not need backward computation.
I0324 23:37:52.651065 29022 net.cpp:325] ctx_output4_ctx_output4/relu_0_split does not need backward computation.
I0324 23:37:52.651074 29022 net.cpp:325] ctx_output4/relu does not need backward computation.
I0324 23:37:52.651082 29022 net.cpp:325] ctx_output4 does not need backward computation.
I0324 23:37:52.651090 29022 net.cpp:325] ctx_output3_ctx_output3/relu_0_split does not need backward computation.
I0324 23:37:52.651098 29022 net.cpp:325] ctx_output3/relu does not need backward computation.
I0324 23:37:52.651105 29022 net.cpp:325] ctx_output3 does not need backward computation.
I0324 23:37:52.651113 29022 net.cpp:325] ctx_output2_ctx_output2/relu_0_split does not need backward computation.
I0324 23:37:52.651121 29022 net.cpp:325] ctx_output2/relu does not need backward computation.
I0324 23:37:52.651129 29022 net.cpp:325] ctx_output2 does not need backward computation.
I0324 23:37:52.651150 29022 net.cpp:325] ctx_output1_ctx_output1/relu_0_split does not need backward computation.
I0324 23:37:52.651161 29022 net.cpp:325] ctx_output1/relu does not need backward computation.
I0324 23:37:52.651170 29022 net.cpp:325] ctx_output1 does not need backward computation.
I0324 23:37:52.651178 29022 net.cpp:325] pool9 does not need backward computation.
I0324 23:37:52.651188 29022 net.cpp:325] pool8_pool8_0_split does not need backward computation.
I0324 23:37:52.651196 29022 net.cpp:325] pool8 does not need backward computation.
I0324 23:37:52.651206 29022 net.cpp:325] pool7_pool7_0_split does not need backward computation.
I0324 23:37:52.651216 29022 net.cpp:325] pool7 does not need backward computation.
I0324 23:37:52.651224 29022 net.cpp:325] pool6_pool6_0_split does not need backward computation.
I0324 23:37:52.651232 29022 net.cpp:325] pool6 does not need backward computation.
I0324 23:37:52.651240 29022 net.cpp:325] res5a_branch2b_res5a_branch2b/relu_0_split does not need backward computation.
I0324 23:37:52.651249 29022 net.cpp:325] res5a_branch2b/relu does not need backward computation.
I0324 23:37:52.651257 29022 net.cpp:325] res5a_branch2b/bn does not need backward computation.
I0324 23:37:52.651266 29022 net.cpp:325] res5a_branch2b does not need backward computation.
I0324 23:37:52.651275 29022 net.cpp:325] res5a_branch2a/relu does not need backward computation.
I0324 23:37:52.651283 29022 net.cpp:325] res5a_branch2a/bn does not need backward computation.
I0324 23:37:52.651291 29022 net.cpp:325] res5a_branch2a does not need backward computation.
I0324 23:37:52.651300 29022 net.cpp:325] pool4 does not need backward computation.
I0324 23:37:52.651309 29022 net.cpp:325] res4a_branch2b/relu does not need backward computation.
I0324 23:37:52.651317 29022 net.cpp:325] res4a_branch2b/bn does not need backward computation.
I0324 23:37:52.651325 29022 net.cpp:325] res4a_branch2b does not need backward computation.
I0324 23:37:52.679595 29022 net.cpp:325] res4a_branch2a/relu does not need backward computation.
I0324 23:37:52.679616 29022 net.cpp:325] res4a_branch2a/bn does not need backward computation.
I0324 23:37:52.679626 29022 net.cpp:325] res4a_branch2a does not need backward computation.
I0324 23:37:52.679633 29022 net.cpp:325] pool3 does not need backward computation.
I0324 23:37:52.679639 29022 net.cpp:325] res3a_branch2b_res3a_branch2b/relu_0_split does not need backward computation.
I0324 23:37:52.679644 29022 net.cpp:325] res3a_branch2b/relu does not need backward computation.
I0324 23:37:52.679649 29022 net.cpp:325] res3a_branch2b/bn does not need backward computation.
I0324 23:37:52.679654 29022 net.cpp:325] res3a_branch2b does not need backward computation.
I0324 23:37:52.679659 29022 net.cpp:325] res3a_branch2a/relu does not need backward computation.
I0324 23:37:52.679664 29022 net.cpp:325] res3a_branch2a/bn does not need backward computation.
I0324 23:37:52.679669 29022 net.cpp:325] res3a_branch2a does not need backward computation.
I0324 23:37:52.679674 29022 net.cpp:325] pool2 does not need backward computation.
I0324 23:37:52.679679 29022 net.cpp:325] res2a_branch2b/relu does not need backward computation.
I0324 23:37:52.679684 29022 net.cpp:325] res2a_branch2b/bn does not need backward computation.
I0324 23:37:52.679689 29022 net.cpp:325] res2a_branch2b does not need backward computation.
I0324 23:37:52.679694 29022 net.cpp:325] res2a_branch2a/relu does not need backward computation.
I0324 23:37:52.679699 29022 net.cpp:325] res2a_branch2a/bn does not need backward computation.
I0324 23:37:52.679704 29022 net.cpp:325] res2a_branch2a does not need backward computation.
I0324 23:37:52.679709 29022 net.cpp:325] pool1 does not need backward computation.
I0324 23:37:52.679714 29022 net.cpp:325] conv1b/relu does not need backward computation.
I0324 23:37:52.679719 29022 net.cpp:325] conv1b/bn does not need backward computation.
I0324 23:37:52.679724 29022 net.cpp:325] conv1b does not need backward computation.
I0324 23:37:52.679744 29022 net.cpp:325] conv1a/relu does not need backward computation.
I0324 23:37:52.679749 29022 net.cpp:325] conv1a/bn does not need backward computation.
I0324 23:37:52.679754 29022 net.cpp:325] conv1a does not need backward computation.
I0324 23:37:52.679760 29022 net.cpp:325] data/bias does not need backward computation.
I0324 23:37:52.679766 29022 net.cpp:325] data_data_0_split does not need backward computation.
I0324 23:37:52.679772 29022 net.cpp:325] data does not need backward computation.
I0324 23:37:52.679776 29022 net.cpp:367] This network produces output detection_eval
I0324 23:37:52.679950 29022 net.cpp:389] Top memory (TEST) required for data: 1212798800 diff: 1212798800
I0324 23:37:52.679965 29022 net.cpp:392] Bottom memory (TEST) required for data: 1212798720 diff: 1212798720
I0324 23:37:52.679975 29022 net.cpp:395] Shared (in-place) memory (TEST) by data: 521715712 diff: 521715712
I0324 23:37:52.679983 29022 net.cpp:398] Parameters memory (TEST) required for data: 12464288 diff: 12464288
I0324 23:37:52.679992 29022 net.cpp:401] Parameters shared memory (TEST) by data: 0 diff: 0
I0324 23:37:52.680001 29022 net.cpp:407] Network initialization done.
I0324 23:37:52.680552 29022 solver.cpp:57] Solver scaffolding done.
I0324 23:37:52.692004 29022 caffe.cpp:143] Finetuning from training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/l1reg_51.09/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_40000_51.09.caffemodel
I0324 23:37:52.771119 29022 net.cpp:1094] Copying source layer data Type:AnnotatedData #blobs=0
I0324 23:37:52.771159 29022 net.cpp:1094] Copying source layer data_data_0_split Type:Split #blobs=0
I0324 23:37:52.771168 29022 net.cpp:1094] Copying source layer data/bias Type:Bias #blobs=1
I0324 23:37:52.771219 29022 net.cpp:1094] Copying source layer conv1a Type:Convolution #blobs=2
I0324 23:37:52.771248 29022 net.cpp:1094] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0324 23:37:52.771561 29022 net.cpp:1094] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0324 23:37:52.771575 29022 net.cpp:1094] Copying source layer conv1b Type:Convolution #blobs=2
I0324 23:37:52.771602 29022 net.cpp:1094] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0324 23:37:52.771845 29022 net.cpp:1094] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0324 23:37:52.771858 29022 net.cpp:1094] Copying source layer pool1 Type:Pooling #blobs=0
I0324 23:37:52.771865 29022 net.cpp:1094] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0324 23:37:52.771905 29022 net.cpp:1094] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0324 23:37:52.772152 29022 net.cpp:1094] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0324 23:37:52.772166 29022 net.cpp:1094] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0324 23:37:52.772200 29022 net.cpp:1094] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0324 23:37:52.772440 29022 net.cpp:1094] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0324 23:37:52.772454 29022 net.cpp:1094] Copying source layer pool2 Type:Pooling #blobs=0
I0324 23:37:52.772461 29022 net.cpp:1094] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0324 23:37:52.772536 29022 net.cpp:1094] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0324 23:37:52.772758 29022 net.cpp:1094] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0324 23:37:52.772773 29022 net.cpp:1094] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0324 23:37:52.772831 29022 net.cpp:1094] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0324 23:37:52.773075 29022 net.cpp:1094] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0324 23:37:52.773088 29022 net.cpp:1094] Copying source layer res3a_branch2b_res3a_branch2b/relu_0_split Type:Split #blobs=0
I0324 23:37:52.773097 29022 net.cpp:1094] Copying source layer pool3 Type:Pooling #blobs=0
I0324 23:37:52.773104 29022 net.cpp:1094] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0324 23:37:52.773351 29022 net.cpp:1094] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0324 23:37:52.773543 29022 net.cpp:1094] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0324 23:37:52.773555 29022 net.cpp:1094] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0324 23:37:52.773680 29022 net.cpp:1094] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0324 23:37:52.773931 29022 net.cpp:1094] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0324 23:37:52.773946 29022 net.cpp:1094] Copying source layer pool4 Type:Pooling #blobs=0
I0324 23:37:52.773954 29022 net.cpp:1094] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0324 23:37:52.774705 29022 net.cpp:1094] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0324 23:37:52.774888 29022 net.cpp:1094] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0324 23:37:52.774899 29022 net.cpp:1094] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0324 23:37:52.775318 29022 net.cpp:1094] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0324 23:37:52.775485 29022 net.cpp:1094] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0324 23:37:52.775496 29022 net.cpp:1094] Copying source layer res5a_branch2b_res5a_branch2b/relu_0_split Type:Split #blobs=0
I0324 23:37:52.775501 29022 net.cpp:1094] Copying source layer pool6 Type:Pooling #blobs=0
I0324 23:37:52.775506 29022 net.cpp:1094] Copying source layer pool6_pool6_0_split Type:Split #blobs=0
I0324 23:37:52.775511 29022 net.cpp:1094] Copying source layer pool7 Type:Pooling #blobs=0
I0324 23:37:52.775516 29022 net.cpp:1094] Copying source layer pool7_pool7_0_split Type:Split #blobs=0
I0324 23:37:52.775519 29022 net.cpp:1094] Copying source layer pool8 Type:Pooling #blobs=0
I0324 23:37:52.775524 29022 net.cpp:1094] Copying source layer pool8_pool8_0_split Type:Split #blobs=0
I0324 23:37:52.775529 29022 net.cpp:1094] Copying source layer pool9 Type:Pooling #blobs=0
I0324 23:37:52.775534 29022 net.cpp:1094] Copying source layer ctx_output1 Type:Convolution #blobs=2
I0324 23:37:52.775574 29022 net.cpp:1094] Copying source layer ctx_output1/relu Type:ReLU #blobs=0
I0324 23:37:52.775583 29022 net.cpp:1094] Copying source layer ctx_output1_ctx_output1/relu_0_split Type:Split #blobs=0
I0324 23:37:52.775588 29022 net.cpp:1094] Copying source layer ctx_output2 Type:Convolution #blobs=2
I0324 23:37:52.775686 29022 net.cpp:1094] Copying source layer ctx_output2/relu Type:ReLU #blobs=0
I0324 23:37:52.775694 29022 net.cpp:1094] Copying source layer ctx_output2_ctx_output2/relu_0_split Type:Split #blobs=0
I0324 23:37:52.775699 29022 net.cpp:1094] Copying source layer ctx_output3 Type:Convolution #blobs=2
I0324 23:37:52.775797 29022 net.cpp:1094] Copying source layer ctx_output3/relu Type:ReLU #blobs=0
I0324 23:37:52.775806 29022 net.cpp:1094] Copying source layer ctx_output3_ctx_output3/relu_0_split Type:Split #blobs=0
I0324 23:37:52.775811 29022 net.cpp:1094] Copying source layer ctx_output4 Type:Convolution #blobs=2
I0324 23:37:52.775909 29022 net.cpp:1094] Copying source layer ctx_output4/relu Type:ReLU #blobs=0
I0324 23:37:52.775919 29022 net.cpp:1094] Copying source layer ctx_output4_ctx_output4/relu_0_split Type:Split #blobs=0
I0324 23:37:52.775924 29022 net.cpp:1094] Copying source layer ctx_output5 Type:Convolution #blobs=2
I0324 23:37:52.776021 29022 net.cpp:1094] Copying source layer ctx_output5/relu Type:ReLU #blobs=0
I0324 23:37:52.776031 29022 net.cpp:1094] Copying source layer ctx_output5_ctx_output5/relu_0_split Type:Split #blobs=0
I0324 23:37:52.776036 29022 net.cpp:1094] Copying source layer ctx_output6 Type:Convolution #blobs=2
I0324 23:37:52.776136 29022 net.cpp:1094] Copying source layer ctx_output6/relu Type:ReLU #blobs=0
I0324 23:37:52.776145 29022 net.cpp:1094] Copying source layer ctx_output6_ctx_output6/relu_0_split Type:Split #blobs=0
I0324 23:37:52.776150 29022 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc Type:Convolution #blobs=2
I0324 23:37:52.776170 29022 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc_perm Type:Permute #blobs=0
I0324 23:37:52.776201 29022 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc_flat Type:Flatten #blobs=0
I0324 23:37:52.776207 29022 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf Type:Convolution #blobs=2
I0324 23:37:52.776227 29022 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf_perm Type:Permute #blobs=0
I0324 23:37:52.776234 29022 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf_flat Type:Flatten #blobs=0
I0324 23:37:52.776239 29022 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_priorbox Type:PriorBox #blobs=0
I0324 23:37:52.776244 29022 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc Type:Convolution #blobs=2
I0324 23:37:52.776265 29022 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc_perm Type:Permute #blobs=0
I0324 23:37:52.776273 29022 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc_flat Type:Flatten #blobs=0
I0324 23:37:52.776278 29022 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf Type:Convolution #blobs=2
I0324 23:37:52.776298 29022 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf_perm Type:Permute #blobs=0
I0324 23:37:52.776304 29022 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf_flat Type:Flatten #blobs=0
I0324 23:37:52.776309 29022 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_priorbox Type:PriorBox #blobs=0
I0324 23:37:52.776314 29022 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc Type:Convolution #blobs=2
I0324 23:37:52.776335 29022 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc_perm Type:Permute #blobs=0
I0324 23:37:52.776341 29022 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc_flat Type:Flatten #blobs=0
I0324 23:37:52.776346 29022 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf Type:Convolution #blobs=2
I0324 23:37:52.776368 29022 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf_perm Type:Permute #blobs=0
I0324 23:37:52.776376 29022 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf_flat Type:Flatten #blobs=0
I0324 23:37:52.776381 29022 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_priorbox Type:PriorBox #blobs=0
I0324 23:37:52.776386 29022 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc Type:Convolution #blobs=2
I0324 23:37:52.776407 29022 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc_perm Type:Permute #blobs=0
I0324 23:37:52.776413 29022 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc_flat Type:Flatten #blobs=0
I0324 23:37:52.776418 29022 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf Type:Convolution #blobs=2
I0324 23:37:52.776437 29022 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf_perm Type:Permute #blobs=0
I0324 23:37:52.776444 29022 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf_flat Type:Flatten #blobs=0
I0324 23:37:52.776449 29022 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_priorbox Type:PriorBox #blobs=0
I0324 23:37:52.776454 29022 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc Type:Convolution #blobs=2
I0324 23:37:52.776473 29022 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc_perm Type:Permute #blobs=0
I0324 23:37:52.776479 29022 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc_flat Type:Flatten #blobs=0
I0324 23:37:52.776484 29022 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf Type:Convolution #blobs=2
I0324 23:37:52.776504 29022 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf_perm Type:Permute #blobs=0
I0324 23:37:52.776511 29022 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf_flat Type:Flatten #blobs=0
I0324 23:37:52.776516 29022 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_priorbox Type:PriorBox #blobs=0
I0324 23:37:52.776521 29022 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc Type:Convolution #blobs=2
I0324 23:37:52.776540 29022 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc_perm Type:Permute #blobs=0
I0324 23:37:52.776556 29022 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc_flat Type:Flatten #blobs=0
I0324 23:37:52.776562 29022 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf Type:Convolution #blobs=2
I0324 23:37:52.776582 29022 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf_perm Type:Permute #blobs=0
I0324 23:37:52.776589 29022 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf_flat Type:Flatten #blobs=0
I0324 23:37:52.776594 29022 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_priorbox Type:PriorBox #blobs=0
I0324 23:37:52.776599 29022 net.cpp:1094] Copying source layer mbox_loc Type:Concat #blobs=0
I0324 23:37:52.776604 29022 net.cpp:1094] Copying source layer mbox_conf Type:Concat #blobs=0
I0324 23:37:52.776608 29022 net.cpp:1094] Copying source layer mbox_priorbox Type:Concat #blobs=0
I0324 23:37:52.776613 29022 net.cpp:1094] Copying source layer mbox_loss Type:MultiBoxLoss #blobs=0
I0324 23:37:52.782842 29022 net.cpp:1094] Copying source layer data Type:AnnotatedData #blobs=0
I0324 23:37:52.782868 29022 net.cpp:1094] Copying source layer data_data_0_split Type:Split #blobs=0
I0324 23:37:52.782873 29022 net.cpp:1094] Copying source layer data/bias Type:Bias #blobs=1
I0324 23:37:52.782914 29022 net.cpp:1094] Copying source layer conv1a Type:Convolution #blobs=2
I0324 23:37:52.782937 29022 net.cpp:1094] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0324 23:37:52.783167 29022 net.cpp:1094] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0324 23:37:52.783177 29022 net.cpp:1094] Copying source layer conv1b Type:Convolution #blobs=2
I0324 23:37:52.783196 29022 net.cpp:1094] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0324 23:37:52.783368 29022 net.cpp:1094] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0324 23:37:52.783380 29022 net.cpp:1094] Copying source layer pool1 Type:Pooling #blobs=0
I0324 23:37:52.783385 29022 net.cpp:1094] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0324 23:37:52.783416 29022 net.cpp:1094] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0324 23:37:52.783586 29022 net.cpp:1094] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0324 23:37:52.783596 29022 net.cpp:1094] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0324 23:37:52.783623 29022 net.cpp:1094] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0324 23:37:52.783789 29022 net.cpp:1094] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0324 23:37:52.783799 29022 net.cpp:1094] Copying source layer pool2 Type:Pooling #blobs=0
I0324 23:37:52.783804 29022 net.cpp:1094] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0324 23:37:52.783867 29022 net.cpp:1094] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0324 23:37:52.784025 29022 net.cpp:1094] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0324 23:37:52.784036 29022 net.cpp:1094] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0324 23:37:52.784076 29022 net.cpp:1094] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0324 23:37:52.784225 29022 net.cpp:1094] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0324 23:37:52.784235 29022 net.cpp:1094] Copying source layer res3a_branch2b_res3a_branch2b/relu_0_split Type:Split #blobs=0
I0324 23:37:52.784240 29022 net.cpp:1094] Copying source layer pool3 Type:Pooling #blobs=0
I0324 23:37:52.784245 29022 net.cpp:1094] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0324 23:37:52.784430 29022 net.cpp:1094] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0324 23:37:52.784584 29022 net.cpp:1094] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0324 23:37:52.784593 29022 net.cpp:1094] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0324 23:37:52.784696 29022 net.cpp:1094] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0324 23:37:52.784852 29022 net.cpp:1094] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0324 23:37:52.784891 29022 net.cpp:1094] Copying source layer pool4 Type:Pooling #blobs=0
I0324 23:37:52.784898 29022 net.cpp:1094] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0324 23:37:52.785884 29022 net.cpp:1094] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0324 23:37:52.786085 29022 net.cpp:1094] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0324 23:37:52.786097 29022 net.cpp:1094] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0324 23:37:52.786442 29022 net.cpp:1094] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0324 23:37:52.786594 29022 net.cpp:1094] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0324 23:37:52.786604 29022 net.cpp:1094] Copying source layer res5a_branch2b_res5a_branch2b/relu_0_split Type:Split #blobs=0
I0324 23:37:52.786609 29022 net.cpp:1094] Copying source layer pool6 Type:Pooling #blobs=0
I0324 23:37:52.786614 29022 net.cpp:1094] Copying source layer pool6_pool6_0_split Type:Split #blobs=0
I0324 23:37:52.786618 29022 net.cpp:1094] Copying source layer pool7 Type:Pooling #blobs=0
I0324 23:37:52.786623 29022 net.cpp:1094] Copying source layer pool7_pool7_0_split Type:Split #blobs=0
I0324 23:37:52.786628 29022 net.cpp:1094] Copying source layer pool8 Type:Pooling #blobs=0
I0324 23:37:52.786633 29022 net.cpp:1094] Copying source layer pool8_pool8_0_split Type:Split #blobs=0
I0324 23:37:52.786638 29022 net.cpp:1094] Copying source layer pool9 Type:Pooling #blobs=0
I0324 23:37:52.786643 29022 net.cpp:1094] Copying source layer ctx_output1 Type:Convolution #blobs=2
I0324 23:37:52.786679 29022 net.cpp:1094] Copying source layer ctx_output1/relu Type:ReLU #blobs=0
I0324 23:37:52.786686 29022 net.cpp:1094] Copying source layer ctx_output1_ctx_output1/relu_0_split Type:Split #blobs=0
I0324 23:37:52.786691 29022 net.cpp:1094] Copying source layer ctx_output2 Type:Convolution #blobs=2
I0324 23:37:52.786783 29022 net.cpp:1094] Copying source layer ctx_output2/relu Type:ReLU #blobs=0
I0324 23:37:52.786793 29022 net.cpp:1094] Copying source layer ctx_output2_ctx_output2/relu_0_split Type:Split #blobs=0
I0324 23:37:52.786798 29022 net.cpp:1094] Copying source layer ctx_output3 Type:Convolution #blobs=2
I0324 23:37:52.786891 29022 net.cpp:1094] Copying source layer ctx_output3/relu Type:ReLU #blobs=0
I0324 23:37:52.786900 29022 net.cpp:1094] Copying source layer ctx_output3_ctx_output3/relu_0_split Type:Split #blobs=0
I0324 23:37:52.786906 29022 net.cpp:1094] Copying source layer ctx_output4 Type:Convolution #blobs=2
I0324 23:37:52.786998 29022 net.cpp:1094] Copying source layer ctx_output4/relu Type:ReLU #blobs=0
I0324 23:37:52.787009 29022 net.cpp:1094] Copying source layer ctx_output4_ctx_output4/relu_0_split Type:Split #blobs=0
I0324 23:37:52.787016 29022 net.cpp:1094] Copying source layer ctx_output5 Type:Convolution #blobs=2
I0324 23:37:52.787104 29022 net.cpp:1094] Copying source layer ctx_output5/relu Type:ReLU #blobs=0
I0324 23:37:52.787113 29022 net.cpp:1094] Copying source layer ctx_output5_ctx_output5/relu_0_split Type:Split #blobs=0
I0324 23:37:52.787117 29022 net.cpp:1094] Copying source layer ctx_output6 Type:Convolution #blobs=2
I0324 23:37:52.787206 29022 net.cpp:1094] Copying source layer ctx_output6/relu Type:ReLU #blobs=0
I0324 23:37:52.787215 29022 net.cpp:1094] Copying source layer ctx_output6_ctx_output6/relu_0_split Type:Split #blobs=0
I0324 23:37:52.787220 29022 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc Type:Convolution #blobs=2
I0324 23:37:52.787238 29022 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc_perm Type:Permute #blobs=0
I0324 23:37:52.787245 29022 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc_flat Type:Flatten #blobs=0
I0324 23:37:52.787250 29022 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf Type:Convolution #blobs=2
I0324 23:37:52.787268 29022 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf_perm Type:Permute #blobs=0
I0324 23:37:52.787276 29022 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf_flat Type:Flatten #blobs=0
I0324 23:37:52.787300 29022 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_priorbox Type:PriorBox #blobs=0
I0324 23:37:52.787307 29022 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc Type:Convolution #blobs=2
I0324 23:37:52.787328 29022 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc_perm Type:Permute #blobs=0
I0324 23:37:52.787334 29022 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc_flat Type:Flatten #blobs=0
I0324 23:37:52.787339 29022 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf Type:Convolution #blobs=2
I0324 23:37:52.787358 29022 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf_perm Type:Permute #blobs=0
I0324 23:37:52.787365 29022 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf_flat Type:Flatten #blobs=0
I0324 23:37:52.787370 29022 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_priorbox Type:PriorBox #blobs=0
I0324 23:37:52.787374 29022 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc Type:Convolution #blobs=2
I0324 23:37:52.787394 29022 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc_perm Type:Permute #blobs=0
I0324 23:37:52.787400 29022 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc_flat Type:Flatten #blobs=0
I0324 23:37:52.787405 29022 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf Type:Convolution #blobs=2
I0324 23:37:52.787423 29022 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf_perm Type:Permute #blobs=0
I0324 23:37:52.787431 29022 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf_flat Type:Flatten #blobs=0
I0324 23:37:52.787434 29022 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_priorbox Type:PriorBox #blobs=0
I0324 23:37:52.787441 29022 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc Type:Convolution #blobs=2
I0324 23:37:52.787461 29022 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc_perm Type:Permute #blobs=0
I0324 23:37:52.787467 29022 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc_flat Type:Flatten #blobs=0
I0324 23:37:52.787472 29022 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf Type:Convolution #blobs=2
I0324 23:37:52.787492 29022 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf_perm Type:Permute #blobs=0
I0324 23:37:52.787497 29022 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf_flat Type:Flatten #blobs=0
I0324 23:37:52.787503 29022 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_priorbox Type:PriorBox #blobs=0
I0324 23:37:52.787508 29022 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc Type:Convolution #blobs=2
I0324 23:37:52.787524 29022 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc_perm Type:Permute #blobs=0
I0324 23:37:52.787531 29022 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc_flat Type:Flatten #blobs=0
I0324 23:37:52.787536 29022 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf Type:Convolution #blobs=2
I0324 23:37:52.787554 29022 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf_perm Type:Permute #blobs=0
I0324 23:37:52.787560 29022 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf_flat Type:Flatten #blobs=0
I0324 23:37:52.787564 29022 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_priorbox Type:PriorBox #blobs=0
I0324 23:37:52.787569 29022 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc Type:Convolution #blobs=2
I0324 23:37:52.787587 29022 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc_perm Type:Permute #blobs=0
I0324 23:37:52.787595 29022 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc_flat Type:Flatten #blobs=0
I0324 23:37:52.787598 29022 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf Type:Convolution #blobs=2
I0324 23:37:52.787616 29022 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf_perm Type:Permute #blobs=0
I0324 23:37:52.787623 29022 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf_flat Type:Flatten #blobs=0
I0324 23:37:52.787636 29022 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_priorbox Type:PriorBox #blobs=0
I0324 23:37:52.787642 29022 net.cpp:1094] Copying source layer mbox_loc Type:Concat #blobs=0
I0324 23:37:52.787647 29022 net.cpp:1094] Copying source layer mbox_conf Type:Concat #blobs=0
I0324 23:37:52.787652 29022 net.cpp:1094] Copying source layer mbox_priorbox Type:Concat #blobs=0
I0324 23:37:52.787655 29022 net.cpp:1078] Ignoring source layer mbox_loss
I0324 23:37:52.787823 29022 caffe.cpp:242] Starting Optimization
I0324 23:37:52.787837 29022 net.cpp:2169] All zero weights of convolution layers are frozen
I0324 23:37:52.812266 29022 solver.cpp:501] Solving ssdJacintoNetV2
I0324 23:37:52.812290 29022 solver.cpp:502] Learning Rate Policy: poly
I0324 23:37:52.818454 29022 net.cpp:1412] [0] Reserving 12451584 bytes of shared learnable space
I0324 23:37:52.819237 29022 solver.cpp:678] Iteration 0, Testing net (#0)
I0324 23:37:52.821246 29087 device_alternate.hpp:116] NVML initialized on thread 140370704828160
I0324 23:37:52.822294 29022 net.cpp:1012] Ignoring source layer mbox_loss
I0324 23:37:52.869257 29087 common.cpp:585] NVML succeeded to set CPU affinity on device 0
I0324 23:37:52.928525 29022 blocking_queue.cpp:40] Data layer prefetch queue empty
I0324 23:37:53.204555 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1a' with space 0G 3/1 1 	(avail 7.2G, req 0G)	t: 0
I0324 23:37:53.216446 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1b' with space 0G 32/4 6 	(avail 7.2G, req 0G)	t: 0
I0324 23:37:53.233767 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2a' with space 0G 32/1 6 	(avail 7.2G, req 0G)	t: 0
I0324 23:37:53.240962 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2b' with space 0G 64/4 6 	(avail 7.2G, req 0G)	t: 0
I0324 23:37:53.252455 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2a' with space 0G 64/1 6 	(avail 7.2G, req 0G)	t: 0
I0324 23:37:53.257349 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2b' with space 0G 128/4 6 	(avail 7.2G, req 0G)	t: 0
I0324 23:37:53.265908 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2a' with space 0G 128/1 1 	(avail 7.2G, req 0G)	t: 0
I0324 23:37:53.270396 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2b' with space 0G 256/4 6 	(avail 7.2G, req 0G)	t: 0
I0324 23:37:53.279680 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res5a_branch2a' with space 0G 256/1 1 	(avail 7.2G, req 0G)	t: 0
I0324 23:37:53.283210 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res5a_branch2b' with space 0G 512/4 1 	(avail 7.2G, req 0G)	t: 0
I0324 23:37:53.289299 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output1' with space 0G 128/1 1 	(avail 7.2G, req 0G)	t: 0
I0324 23:37:53.292703 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output2' with space 0G 512/1 1 	(avail 7.2G, req 0G)	t: 0
I0324 23:37:53.294625 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output3' with space 0G 512/1 1 	(avail 7.2G, req 0G)	t: 0
I0324 23:37:53.296957 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output4' with space 0G 512/1 0 	(avail 7.2G, req 0G)	t: 0
I0324 23:37:53.299265 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output5' with space 0G 512/1 0 	(avail 7.2G, req 0G)	t: 0
I0324 23:37:53.301362 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output6' with space 0G 512/1 0 	(avail 7.2G, req 0G)	t: 0
I0324 23:37:53.303887 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output1/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.2G, req 0G)	t: 0
I0324 23:37:53.306625 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output1/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.2G, req 0G)	t: 0
I0324 23:37:53.309134 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output2/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.2G, req 0G)	t: 0
I0324 23:37:53.310740 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output2/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.2G, req 0G)	t: 0
I0324 23:37:53.312621 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output3/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.2G, req 0G)	t: 0
I0324 23:37:53.314172 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output3/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.2G, req 0G)	t: 0
I0324 23:37:53.315729 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output4/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.2G, req 0G)	t: 0
I0324 23:37:53.317458 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output4/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.2G, req 0G)	t: 0
I0324 23:37:53.319058 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output5/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.2G, req 0G)	t: 0
I0324 23:37:53.320912 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output5/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.2G, req 0G)	t: 0
I0324 23:37:53.322422 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output6/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.2G, req 0G)	t: 0
I0324 23:37:53.323988 29022 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output6/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.2G, req 0G)	t: 0
I0324 23:39:16.853368 29077 data_reader.cpp:305] Starting prefetch of epoch 1
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.332776
j:  : 4 : max_pr:  : 0.502304
j:  : 3 : max_pr:  : 0.632703
j:  : 2 : max_pr:  : 0.74938
j:  : 1 : max_pr:  : 0.8596
j:  : 0 : max_pr:  : 1
I0324 23:39:17.291055 29022 solver.cpp:786] class AP 1: 0.370615
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.149106
j:  : 7 : max_pr:  : 0.364451
j:  : 6 : max_pr:  : 0.524976
j:  : 5 : max_pr:  : 0.582876
j:  : 4 : max_pr:  : 0.68241
j:  : 3 : max_pr:  : 0.796763
j:  : 2 : max_pr:  : 0.992751
j:  : 1 : max_pr:  : 0.999243
j:  : 0 : max_pr:  : 1
I0324 23:39:17.390125 29022 solver.cpp:786] class AP 2: 0.553871
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.532596
j:  : 6 : max_pr:  : 0.669494
j:  : 5 : max_pr:  : 0.762348
j:  : 4 : max_pr:  : 0.864268
j:  : 3 : max_pr:  : 0.913801
j:  : 2 : max_pr:  : 0.960661
j:  : 1 : max_pr:  : 0.999013
j:  : 0 : max_pr:  : 1
I0324 23:39:17.411453 29022 solver.cpp:786] class AP 3: 0.609289
I0324 23:39:17.411469 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.511258
I0324 23:39:17.411486 29022 solver.cpp:255] Initial Test completed
I0324 23:39:18.339534 29046 annotated_data_layer.cpp:111] [0] Parser threads: 4
I0324 23:39:18.339583 29046 annotated_data_layer.cpp:113] [0] Transformer threads: 4
I0324 23:39:19.451968 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'conv1a' with space 4.24G 3/1 1 0 0 	(avail 1.05G, req 0G)	t: 0 2.58 2.03
I0324 23:39:19.564651 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'conv1b' with space 4.24G 32/4 6 4 3 	(avail 1.05G, req 0G)	t: 0 0.55 1.11
I0324 23:39:19.789376 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 4.24G 32/1 1 4 3 	(avail 1G, req 0G)	t: 0 0.7 1.27
I0324 23:39:19.873622 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 4.24G 64/4 6 4 1 	(avail 1G, req 0G)	t: 0 0.25 0.6
I0324 23:39:20.040053 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 4.24G 64/1 6 4 5 	(avail 0.97G, req 0.05G)	t: 0 0.38 0.73
I0324 23:39:20.089154 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 4.24G 128/4 6 4 5 	(avail 0.97G, req 0.05G)	t: 0 0.12 0.27
I0324 23:39:20.179886 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 4.24G 128/1 6 4 5 	(avail 0.95G, req 0.05G)	t: 0 0.32 0.44
I0324 23:39:20.215528 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 4.24G 256/4 6 4 5 	(avail 0.95G, req 0.05G)	t: 0 0.1 0.17
I0324 23:39:20.320525 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 4.24G 256/1 6 4 5 	(avail 0.95G, req 0.05G)	t: 0 0.47 0.53
I0324 23:39:20.352818 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 4.24G 512/4 6 4 5 	(avail 0.95G, req 0.05G)	t: 0 0.12 0.14
I0324 23:39:20.398767 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output1' with space 4.24G 128/1 1 1 3 	(avail 0.95G, req 0.05G)	t: 0 0.33 0.8
I0324 23:39:20.469970 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output2' with space 4.24G 512/1 1 1 3 	(avail 0.9G, req 0.05G)	t: 0 0.12 0.16
I0324 23:39:20.493959 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output3' with space 4.24G 512/1 1 1 3 	(avail 0.9G, req 0.05G)	t: 0 0.07 0.09
I0324 23:39:20.521857 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output4' with space 4.24G 512/1 0 0 1 	(avail 0.9G, req 0.05G)	t: 0 0.06 0.08
I0324 23:39:20.549468 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output5' with space 4.24G 512/1 0 0 1 	(avail 0.9G, req 0.05G)	t: 0 0.08 0.07
I0324 23:39:20.576619 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output6' with space 4.24G 512/1 0 0 3 	(avail 0.9G, req 0.05G)	t: 0 0.07 0.07
I0324 23:39:20.676534 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_loc' with space 4.24G 256/1 1 1 3 	(avail 0.9G, req 0.05G)	t: 0 0.21 0.65
I0324 23:39:20.777011 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_conf' with space 4.24G 256/1 1 1 3 	(avail 0.9G, req 0.05G)	t: 0 0.21 0.61
I0324 23:39:20.796140 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_loc' with space 4.24G 256/1 1 1 3 	(avail 0.9G, req 0.05G)	t: 0 0.04 0.06
I0324 23:39:20.812783 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_conf' with space 4.24G 256/1 1 1 0 	(avail 0.9G, req 0.05G)	t: 0 0.06 0.08
I0324 23:39:20.828024 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 0.9G, req 0.05G)	t: 0 0.04 0.04
I0324 23:39:20.844929 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_conf' with space 4.24G 256/1 1 0 0 	(avail 0.9G, req 0.05G)	t: 0 0.06 0.05
I0324 23:39:20.864804 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_loc' with space 4.24G 256/1 1 0 0 	(avail 0.9G, req 0.05G)	t: 0 0.06 0.03
I0324 23:39:20.878892 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_conf' with space 4.24G 256/1 0 1 0 	(avail 0.9G, req 0.05G)	t: 0 0.04 0.05
I0324 23:39:20.893699 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 0.9G, req 0.05G)	t: 0 0.03 0.03
I0324 23:39:20.910894 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_conf' with space 4.24G 256/1 0 0 0 	(avail 0.9G, req 0.05G)	t: 0 0.05 0.03
I0324 23:39:20.927106 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output6/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 0.9G, req 0.05G)	t: 0 0.06 0.05
I0324 23:39:20.942003 29022 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output6/relu_mbox_conf' with space 4.24G 256/1 0 0 0 	(avail 0.9G, req 0.05G)	t: 0 0.07 0.06
I0324 23:39:21.044507 29022 cudnn_conv_layer.cpp:474] [0] Layer 'conv1a' reallocating workspace 4.24G to 0.11G
I0324 23:39:21.195034 29022 solver.cpp:319] Iteration 0 (3.77493 s), loss = 2.55726
I0324 23:39:21.195080 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.10016 (* 1 = 3.10016 loss)
I0324 23:39:21.195096 29022 sgd_solver.cpp:136] Iteration 0, lr = 0.001, m = 0.9
I0324 23:39:21.195107 29022 solver.cpp:351] sparsity_itr_increment_bfr_applying is true: old behaviour:
I0324 23:39:21.750995 29022 solver.cpp:319] Iteration 1 (0.55593 s), loss = 2.54657
I0324 23:39:21.751087 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.58639 (* 1 = 2.58639 loss)
I0324 23:39:21.751127 29022 solver.cpp:351] sparsity_itr_increment_bfr_applying is true: old behaviour:
I0324 23:39:22.453987 29022 solver.cpp:319] Iteration 2 (0.702956 s), loss = 2.80994
I0324 23:39:22.454149 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.97965 (* 1 = 2.97965 loss)
I0324 23:40:36.679323 29022 solver.cpp:314] Iteration 100 (1.32035 iter/s, 74.2228s/98 iter), loss = 2.9738
I0324 23:40:36.679440 29022 solver.cpp:336]     Train net output #0: mbox_loss = 1.88296 (* 1 = 1.88296 loss)
I0324 23:40:36.679457 29022 sgd_solver.cpp:136] Iteration 100, lr = 0.00099335, m = 0.9
I0324 23:41:54.063393 29022 solver.cpp:314] Iteration 200 (1.2923 iter/s, 77.3814s/100 iter), loss = 2.94571
I0324 23:41:54.063561 29022 solver.cpp:336]     Train net output #0: mbox_loss = 1.94387 (* 1 = 1.94387 loss)
I0324 23:41:54.063578 29022 sgd_solver.cpp:136] Iteration 200, lr = 0.000986733, m = 0.9
I0324 23:43:10.887130 29022 solver.cpp:314] Iteration 300 (1.30173 iter/s, 76.8211s/100 iter), loss = 3.13206
I0324 23:43:10.887303 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.45951 (* 1 = 3.45951 loss)
I0324 23:43:10.887320 29022 sgd_solver.cpp:136] Iteration 300, lr = 0.00098015, m = 0.9
I0324 23:44:27.893229 29022 solver.cpp:314] Iteration 400 (1.29864 iter/s, 77.0035s/100 iter), loss = 3.12613
I0324 23:44:27.930392 29022 solver.cpp:336]     Train net output #0: mbox_loss = 1.81363 (* 1 = 1.81363 loss)
I0324 23:44:27.930450 29022 sgd_solver.cpp:136] Iteration 400, lr = 0.000973599, m = 0.9
I0324 23:45:45.078130 29022 solver.cpp:314] Iteration 500 (1.29563 iter/s, 77.1823s/100 iter), loss = 2.95254
I0324 23:45:45.078284 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.85779 (* 1 = 2.85779 loss)
I0324 23:45:45.078320 29022 sgd_solver.cpp:136] Iteration 500, lr = 0.000967081, m = 0.9
I0324 23:47:02.304235 29022 solver.cpp:314] Iteration 600 (1.29494 iter/s, 77.2235s/100 iter), loss = 3.00609
I0324 23:47:02.304380 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.04286 (* 1 = 3.04286 loss)
I0324 23:47:02.304414 29022 sgd_solver.cpp:136] Iteration 600, lr = 0.000960596, m = 0.9
I0324 23:48:19.840101 29022 solver.cpp:314] Iteration 700 (1.28977 iter/s, 77.5333s/100 iter), loss = 3.0334
I0324 23:48:19.840262 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.36618 (* 1 = 3.36618 loss)
I0324 23:48:19.840301 29022 sgd_solver.cpp:136] Iteration 700, lr = 0.000954144, m = 0.9
I0324 23:49:36.684991 29022 solver.cpp:314] Iteration 800 (1.30137 iter/s, 76.8423s/100 iter), loss = 3.10711
I0324 23:49:36.685140 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.40011 (* 1 = 3.40011 loss)
I0324 23:49:36.685174 29022 sgd_solver.cpp:136] Iteration 800, lr = 0.000947724, m = 0.9
I0324 23:50:54.722360 29022 solver.cpp:314] Iteration 900 (1.28148 iter/s, 78.0348s/100 iter), loss = 3.14836
I0324 23:50:54.722494 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.2116 (* 1 = 3.2116 loss)
I0324 23:50:54.722530 29022 sgd_solver.cpp:136] Iteration 900, lr = 0.000941337, m = 0.9
I0324 23:52:15.657650 29022 solver.cpp:314] Iteration 1000 (1.2356 iter/s, 80.9326s/100 iter), loss = 3.06945
I0324 23:52:15.657788 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.62794 (* 1 = 2.62794 loss)
I0324 23:52:15.657821 29022 sgd_solver.cpp:136] Iteration 1000, lr = 0.000934982, m = 0.9
I0324 23:53:36.841406 29022 solver.cpp:314] Iteration 1100 (1.23181 iter/s, 81.1811s/100 iter), loss = 3.03313
I0324 23:53:36.841959 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.59321 (* 1 = 2.59321 loss)
I0324 23:53:36.842320 29022 sgd_solver.cpp:136] Iteration 1100, lr = 0.000928659, m = 0.9
I0324 23:54:56.770280 29022 solver.cpp:314] Iteration 1200 (1.25115 iter/s, 79.9263s/100 iter), loss = 3.16443
I0324 23:54:56.770843 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.99713 (* 1 = 2.99713 loss)
I0324 23:54:56.771210 29022 sgd_solver.cpp:136] Iteration 1200, lr = 0.000922368, m = 0.9
I0324 23:56:15.551933 29022 solver.cpp:314] Iteration 1300 (1.26937 iter/s, 78.7791s/100 iter), loss = 3.15525
I0324 23:56:15.552080 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.20372 (* 1 = 3.20372 loss)
I0324 23:56:15.552114 29022 sgd_solver.cpp:136] Iteration 1300, lr = 0.00091611, m = 0.9
I0324 23:57:34.266027 29022 solver.cpp:314] Iteration 1400 (1.27046 iter/s, 78.7115s/100 iter), loss = 2.86147
I0324 23:57:34.266134 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.8364 (* 1 = 2.8364 loss)
I0324 23:57:34.266150 29022 sgd_solver.cpp:136] Iteration 1400, lr = 0.000909883, m = 0.9
I0324 23:58:52.834488 29022 solver.cpp:314] Iteration 1500 (1.27282 iter/s, 78.5659s/100 iter), loss = 3.07589
I0324 23:58:52.834584 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.3209 (* 1 = 3.3209 loss)
I0324 23:58:52.834600 29022 sgd_solver.cpp:136] Iteration 1500, lr = 0.000903688, m = 0.9
I0325 00:00:10.254882 29022 solver.cpp:314] Iteration 1600 (1.29169 iter/s, 77.4179s/100 iter), loss = 2.9773
I0325 00:00:10.254999 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.52666 (* 1 = 3.52666 loss)
I0325 00:00:10.255017 29022 sgd_solver.cpp:136] Iteration 1600, lr = 0.000897525, m = 0.9
I0325 00:01:28.975028 29022 solver.cpp:314] Iteration 1700 (1.27036 iter/s, 78.7176s/100 iter), loss = 2.95414
I0325 00:01:28.975692 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.32715 (* 1 = 3.32715 loss)
I0325 00:01:28.975726 29022 sgd_solver.cpp:136] Iteration 1700, lr = 0.000891393, m = 0.9
I0325 00:02:48.692102 29022 solver.cpp:314] Iteration 1800 (1.25448 iter/s, 79.7145s/100 iter), loss = 3.13704
I0325 00:02:48.692306 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.69398 (* 1 = 3.69398 loss)
I0325 00:02:48.692354 29022 sgd_solver.cpp:136] Iteration 1800, lr = 0.000885293, m = 0.9
I0325 00:04:06.307266 29022 solver.cpp:314] Iteration 1900 (1.28845 iter/s, 77.6126s/100 iter), loss = 3.09835
I0325 00:04:06.307488 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.08003 (* 1 = 3.08003 loss)
I0325 00:04:06.307523 29022 sgd_solver.cpp:136] Iteration 1900, lr = 0.000879224, m = 0.9
I0325 00:05:24.754730 29022 solver.cpp:443] Finding and applying sparsity: sparsity_target=0.7 sparsity_factor=0.5 sparsity_achieved=4.02661e-05 iter=2000
W0325 00:05:24.756603 29022 net.cpp:2074] conv1a ni=3 no=32
I0325 00:05:24.916682 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:24.916728 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:24.916740 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.2382
I0325 00:05:24.916750 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:05:25.117386 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:25.117427 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:25.117439 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.221673
I0325 00:05:25.117449 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:05:25.265679 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:25.265725 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:25.265733 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.235157
I0325 00:05:25.265738 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:05:25.551918 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:25.551951 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:25.551959 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.290419
I0325 00:05:25.551964 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:05:25.729672 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:25.729719 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:25.729727 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.249104
I0325 00:05:25.729733 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:05:25.766355 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:25.766384 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:25.766391 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.27486
I0325 00:05:25.766396 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:05:25.910164 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:25.910193 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:25.910200 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.355604
I0325 00:05:25.910207 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:05:26.065102 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:26.065135 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:26.065141 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.330058
I0325 00:05:26.065147 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:05:26.513777 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:26.513816 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:26.513823 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.248836
I0325 00:05:26.513828 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:05:26.604244 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:26.604274 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:26.604280 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.222876
I0325 00:05:26.604286 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:05:26.652334 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:26.652356 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:26.652362 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.242829
I0325 00:05:26.652371 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:05:26.680922 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:26.680945 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:26.680951 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.223951
I0325 00:05:26.680958 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:05:26.735251 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:26.735283 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:26.735291 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.21922
I0325 00:05:26.735296 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:05:26.804312 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:26.804345 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:26.804352 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.233996
I0325 00:05:26.804379 29022 net.cpp:2104] final threshold_value used0.2
W0325 00:05:26.826035 29022 net.cpp:2135] conv1a ZeroWeightsFraction=0.195
W0325 00:05:26.826076 29022 net.cpp:2074] conv1b ni=32 no=32
I0325 00:05:27.288446 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:27.288472 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:27.288480 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.222308
I0325 00:05:27.288486 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:05:27.455674 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:27.455693 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:27.455700 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.209052
I0325 00:05:27.455706 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:05:27.507035 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:27.507051 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:27.507057 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.21436
I0325 00:05:27.507063 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:05:27.696286 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:27.696305 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:27.696311 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.221083
I0325 00:05:27.696316 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:05:28.059303 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:28.059322 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:28.059329 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.245358
I0325 00:05:28.059337 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:05:28.119594 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:28.119611 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:28.119616 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.253664
I0325 00:05:28.119626 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:05:28.146912 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:28.146929 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:28.146934 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.233853
I0325 00:05:28.146940 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:05:28.288427 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:28.288445 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:28.288452 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.255151
I0325 00:05:28.288457 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:05:28.349603 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:28.349620 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:28.349627 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.222111
I0325 00:05:28.349632 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:05:28.419263 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:28.419279 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:28.419286 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.223502
I0325 00:05:28.419291 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:05:28.503005 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:28.503021 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:28.503027 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.206627
I0325 00:05:28.503032 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:05:28.756021 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:28.756039 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:28.756045 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.239073
I0325 00:05:28.756052 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:05:28.810505 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:28.810521 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:28.810528 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.211571
I0325 00:05:28.810536 29022 net.cpp:2104] final threshold_value used0.2
W0325 00:05:29.014650 29022 net.cpp:2135] conv1b ZeroWeightsFraction=0.496094
W0325 00:05:29.014680 29022 net.cpp:2074] res2a_branch2a ni=32 no=64
I0325 00:05:31.391829 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:31.391855 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:31.391862 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.213774
I0325 00:05:31.391871 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:05:31.947976 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:31.948010 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:31.948016 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.200856
I0325 00:05:31.948022 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:05:32.390856 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:05:32.390882 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:05:32.390889 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.205798
I0325 00:05:32.390895 29022 net.cpp:2104] final threshold_value used0.2
W0325 00:05:33.961606 29022 net.cpp:2135] res2a_branch2a ZeroWeightsFraction=0.499674
W0325 00:05:33.961652 29022 net.cpp:2074] res2a_branch2b ni=64 no=64
W0325 00:05:41.327613 29022 net.cpp:2135] res2a_branch2b ZeroWeightsFraction=0.481879
W0325 00:05:41.327664 29022 net.cpp:2074] res3a_branch2a ni=64 no=128
W0325 00:05:53.149835 29022 net.cpp:2135] res3a_branch2a ZeroWeightsFraction=0.495212
W0325 00:05:53.149884 29022 net.cpp:2074] res3a_branch2b ni=128 no=128
W0325 00:06:05.541188 29022 net.cpp:2135] res3a_branch2b ZeroWeightsFraction=0.495416
W0325 00:06:05.541419 29022 net.cpp:2074] res4a_branch2a ni=128 no=256
W0325 00:06:25.419463 29022 net.cpp:2135] res4a_branch2a ZeroWeightsFraction=0.498047
W0325 00:06:25.419507 29022 net.cpp:2074] res4a_branch2b ni=256 no=256
W0325 00:06:46.838263 29022 net.cpp:2135] res4a_branch2b ZeroWeightsFraction=0.483887
W0325 00:06:46.838451 29022 net.cpp:2074] res5a_branch2a ni=256 no=512
W0325 00:07:24.715047 29022 net.cpp:2135] res5a_branch2a ZeroWeightsFraction=0.408323
W0325 00:07:24.715217 29022 net.cpp:2074] res5a_branch2b ni=512 no=512
W0325 00:07:43.647984 29022 net.cpp:2135] res5a_branch2b ZeroWeightsFraction=0.49998
W0325 00:07:43.648032 29022 net.cpp:2074] ctx_output1 ni=128 no=256
W0325 00:07:43.648047 29022 net.cpp:2074] ctx_output2 ni=512 no=256
W0325 00:07:43.648056 29022 net.cpp:2074] ctx_output3 ni=512 no=256
W0325 00:07:43.648064 29022 net.cpp:2074] ctx_output4 ni=512 no=256
W0325 00:07:43.648072 29022 net.cpp:2074] ctx_output5 ni=512 no=256
W0325 00:07:43.648082 29022 net.cpp:2074] ctx_output6 ni=512 no=256
W0325 00:07:43.648089 29022 net.cpp:2074] ctx_output1/relu_mbox_loc ni=256 no=16
W0325 00:07:43.648098 29022 net.cpp:2074] ctx_output1/relu_mbox_conf ni=256 no=16
W0325 00:07:43.648108 29022 net.cpp:2074] ctx_output2/relu_mbox_loc ni=256 no=24
W0325 00:07:43.648115 29022 net.cpp:2074] ctx_output2/relu_mbox_conf ni=256 no=24
W0325 00:07:43.648124 29022 net.cpp:2074] ctx_output3/relu_mbox_loc ni=256 no=24
W0325 00:07:43.648134 29022 net.cpp:2074] ctx_output3/relu_mbox_conf ni=256 no=24
W0325 00:07:43.648144 29022 net.cpp:2074] ctx_output4/relu_mbox_loc ni=256 no=24
W0325 00:07:43.648152 29022 net.cpp:2074] ctx_output4/relu_mbox_conf ni=256 no=24
W0325 00:07:43.648161 29022 net.cpp:2074] ctx_output5/relu_mbox_loc ni=256 no=16
W0325 00:07:43.648169 29022 net.cpp:2074] ctx_output5/relu_mbox_conf ni=256 no=16
W0325 00:07:43.648178 29022 net.cpp:2074] ctx_output6/relu_mbox_loc ni=256 no=16
W0325 00:07:43.648186 29022 net.cpp:2074] ctx_output6/relu_mbox_conf ni=256 no=16
I0325 00:07:43.648200 29022 net.cpp:2169] All zero weights of convolution layers are frozen
I0325 00:07:43.653498 29022 solver.cpp:360] Sparsity after update:
I0325 00:07:43.655793 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 00:07:43.655807 29022 net.cpp:2200] conv1a_param_0(0.195) 
I0325 00:07:43.655817 29022 net.cpp:2200] conv1b_param_0(0.496) 
I0325 00:07:43.655823 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 00:07:43.655828 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 00:07:43.655833 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 00:07:43.655841 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 00:07:43.655848 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 00:07:43.655853 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 00:07:43.655858 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 00:07:43.655864 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 00:07:43.655869 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 00:07:43.655874 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 00:07:43.655879 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 00:07:43.655884 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 00:07:43.655889 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 00:07:43.655895 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 00:07:43.655900 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 00:07:43.655905 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 00:07:43.655911 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 00:07:43.655916 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 00:07:43.655925 29022 net.cpp:2200] res2a_branch2a_param_0(0.5) 
I0325 00:07:43.655931 29022 net.cpp:2200] res2a_branch2b_param_0(0.482) 
I0325 00:07:43.655936 29022 net.cpp:2200] res3a_branch2a_param_0(0.495) 
I0325 00:07:43.655942 29022 net.cpp:2200] res3a_branch2b_param_0(0.495) 
I0325 00:07:43.655947 29022 net.cpp:2200] res4a_branch2a_param_0(0.498) 
I0325 00:07:43.655953 29022 net.cpp:2200] res4a_branch2b_param_0(0.484) 
I0325 00:07:43.655958 29022 net.cpp:2200] res5a_branch2a_param_0(0.408) 
I0325 00:07:43.655963 29022 net.cpp:2200] res5a_branch2b_param_0(0.5) 
I0325 00:07:43.655969 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.06484e+06/3.10435e+06) 0.343
I0325 00:07:43.655987 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_2000.caffemodel
I0325 00:07:43.682114 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_2000.solverstate
I0325 00:07:43.690554 29022 solver.cpp:678] Iteration 2000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0
j:  : 4 : max_pr:  : 0.25644
j:  : 3 : max_pr:  : 0.462655
j:  : 2 : max_pr:  : 0.631496
j:  : 1 : max_pr:  : 0.777444
j:  : 0 : max_pr:  : 1
I0325 00:09:07.961316 29022 solver.cpp:786] class AP 1: 0.284367
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0542271
j:  : 7 : max_pr:  : 0.158328
j:  : 6 : max_pr:  : 0.425667
j:  : 5 : max_pr:  : 0.598042
j:  : 4 : max_pr:  : 0.670763
j:  : 3 : max_pr:  : 0.811025
j:  : 2 : max_pr:  : 0.980689
j:  : 1 : max_pr:  : 0.99879
j:  : 0 : max_pr:  : 1
I0325 00:09:08.051928 29022 solver.cpp:786] class AP 2: 0.517957
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.160171
j:  : 6 : max_pr:  : 0.494672
j:  : 5 : max_pr:  : 0.61626
j:  : 4 : max_pr:  : 0.767909
j:  : 3 : max_pr:  : 0.867276
j:  : 2 : max_pr:  : 0.954661
j:  : 1 : max_pr:  : 0.994808
j:  : 0 : max_pr:  : 1
I0325 00:09:08.088518 29022 solver.cpp:786] class AP 3: 0.532342
I0325 00:09:08.088542 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.444889
I0325 00:09:08.088598 29022 solver.cpp:265] Tests completed in 84.3953s
I0325 00:09:08.592819 29022 solver.cpp:314] Iteration 2000 (0.330824 iter/s, 302.276s/100 iter), loss = 3.22795
I0325 00:09:08.592914 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.36922 (* 1 = 3.36922 loss)
I0325 00:09:08.592947 29022 sgd_solver.cpp:136] Iteration 2000, lr = 0.000873186, m = 0.9
I0325 00:10:25.816316 29022 solver.cpp:314] Iteration 2100 (1.29499 iter/s, 77.2209s/100 iter), loss = 3.07192
I0325 00:10:25.816468 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.81333 (* 1 = 2.81333 loss)
I0325 00:10:25.816505 29022 sgd_solver.cpp:136] Iteration 2100, lr = 0.00086718, m = 0.9
I0325 00:11:41.972843 29022 solver.cpp:314] Iteration 2200 (1.31313 iter/s, 76.154s/100 iter), loss = 3.15016
I0325 00:11:41.972992 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.9429 (* 1 = 2.9429 loss)
I0325 00:11:41.973026 29022 sgd_solver.cpp:136] Iteration 2200, lr = 0.000861205, m = 0.9
I0325 00:12:58.414108 29022 solver.cpp:314] Iteration 2300 (1.30824 iter/s, 76.4388s/100 iter), loss = 2.98897
I0325 00:12:58.414243 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.13142 (* 1 = 3.13142 loss)
I0325 00:12:58.414278 29022 sgd_solver.cpp:136] Iteration 2300, lr = 0.00085526, m = 0.9
I0325 00:14:15.679853 29022 solver.cpp:314] Iteration 2400 (1.29428 iter/s, 77.2632s/100 iter), loss = 3.10905
I0325 00:14:15.680001 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.6934 (* 1 = 2.6934 loss)
I0325 00:14:15.680035 29022 sgd_solver.cpp:136] Iteration 2400, lr = 0.000849347, m = 0.9
I0325 00:15:33.239737 29022 solver.cpp:314] Iteration 2500 (1.28937 iter/s, 77.5573s/100 iter), loss = 3.01513
I0325 00:15:33.239881 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.51307 (* 1 = 2.51307 loss)
I0325 00:15:33.239915 29022 sgd_solver.cpp:136] Iteration 2500, lr = 0.000843464, m = 0.9
I0325 00:16:50.555847 29022 solver.cpp:314] Iteration 2600 (1.29343 iter/s, 77.3136s/100 iter), loss = 3.28074
I0325 00:16:50.556305 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.55611 (* 1 = 3.55611 loss)
I0325 00:16:50.556679 29022 sgd_solver.cpp:136] Iteration 2600, lr = 0.000837611, m = 0.9
I0325 00:18:08.492581 29022 solver.cpp:314] Iteration 2700 (1.28313 iter/s, 77.9342s/100 iter), loss = 3.1039
I0325 00:18:08.494413 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.14068 (* 1 = 3.14068 loss)
I0325 00:18:08.494779 29022 sgd_solver.cpp:136] Iteration 2700, lr = 0.00083179, m = 0.9
I0325 00:19:25.073611 29022 solver.cpp:314] Iteration 2800 (1.30585 iter/s, 76.5785s/100 iter), loss = 3.20055
I0325 00:19:25.073707 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.87288 (* 1 = 2.87288 loss)
I0325 00:19:25.073925 29022 sgd_solver.cpp:136] Iteration 2800, lr = 0.000825998, m = 0.9
I0325 00:20:42.797004 29022 solver.cpp:314] Iteration 2900 (1.28666 iter/s, 77.7209s/100 iter), loss = 3.14789
I0325 00:20:42.797144 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.30788 (* 1 = 3.30788 loss)
I0325 00:20:42.797179 29022 sgd_solver.cpp:136] Iteration 2900, lr = 0.000820237, m = 0.9
I0325 00:21:59.911057 29022 solver.cpp:314] Iteration 3000 (1.29682 iter/s, 77.1115s/100 iter), loss = 3.14019
I0325 00:21:59.911211 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.83879 (* 1 = 2.83879 loss)
I0325 00:21:59.911247 29022 sgd_solver.cpp:136] Iteration 3000, lr = 0.000814506, m = 0.9
I0325 00:23:16.901319 29022 solver.cpp:314] Iteration 3100 (1.29891 iter/s, 76.9877s/100 iter), loss = 3.20807
I0325 00:23:16.901465 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.51674 (* 1 = 3.51674 loss)
I0325 00:23:16.901504 29022 sgd_solver.cpp:136] Iteration 3100, lr = 0.000808805, m = 0.9
I0325 00:23:34.310631 29042 data_reader.cpp:305] Starting prefetch of epoch 1
I0325 00:24:34.199568 29022 solver.cpp:314] Iteration 3200 (1.29373 iter/s, 77.2957s/100 iter), loss = 2.99476
I0325 00:24:34.199759 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.27297 (* 1 = 3.27297 loss)
I0325 00:24:34.199795 29022 sgd_solver.cpp:136] Iteration 3200, lr = 0.000803135, m = 0.9
I0325 00:25:49.875036 29022 solver.cpp:314] Iteration 3300 (1.32147 iter/s, 75.673s/100 iter), loss = 3.09749
I0325 00:25:49.875166 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.07658 (* 1 = 3.07658 loss)
I0325 00:25:49.875200 29022 sgd_solver.cpp:136] Iteration 3300, lr = 0.000797494, m = 0.9
I0325 00:27:06.590288 29022 solver.cpp:314] Iteration 3400 (1.30356 iter/s, 76.7128s/100 iter), loss = 2.86055
I0325 00:27:06.590425 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.36233 (* 1 = 3.36233 loss)
I0325 00:27:06.590466 29022 sgd_solver.cpp:136] Iteration 3400, lr = 0.000791882, m = 0.9
I0325 00:28:23.793102 29022 solver.cpp:314] Iteration 3500 (1.29533 iter/s, 77.2003s/100 iter), loss = 3.00799
I0325 00:28:23.793242 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.72445 (* 1 = 2.72445 loss)
I0325 00:28:23.793277 29022 sgd_solver.cpp:136] Iteration 3500, lr = 0.000786301, m = 0.9
I0325 00:29:39.879575 29022 solver.cpp:314] Iteration 3600 (1.31434 iter/s, 76.084s/100 iter), loss = 2.95672
I0325 00:29:39.880025 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.71517 (* 1 = 2.71517 loss)
I0325 00:29:39.880342 29022 sgd_solver.cpp:136] Iteration 3600, lr = 0.000780749, m = 0.9
I0325 00:30:57.844786 29022 solver.cpp:314] Iteration 3700 (1.28266 iter/s, 77.9627s/100 iter), loss = 3.14765
I0325 00:30:57.845240 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.15733 (* 1 = 3.15733 loss)
I0325 00:30:57.845546 29022 sgd_solver.cpp:136] Iteration 3700, lr = 0.000775226, m = 0.9
I0325 00:32:14.660130 29022 solver.cpp:314] Iteration 3800 (1.30187 iter/s, 76.8129s/100 iter), loss = 2.91461
I0325 00:32:14.660264 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.55634 (* 1 = 2.55634 loss)
I0325 00:32:14.660280 29022 sgd_solver.cpp:136] Iteration 3800, lr = 0.000769733, m = 0.9
I0325 00:33:31.843569 29022 solver.cpp:314] Iteration 3900 (1.29566 iter/s, 77.1809s/100 iter), loss = 3.092
I0325 00:33:31.843818 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.25857 (* 1 = 3.25857 loss)
I0325 00:33:31.843904 29022 sgd_solver.cpp:136] Iteration 3900, lr = 0.000764269, m = 0.9
I0325 00:34:47.111572 29022 solver.cpp:443] Finding and applying sparsity: sparsity_target=0.7 sparsity_factor=0.55 sparsity_achieved=0.343017 iter=4000
W0325 00:34:47.111898 29022 net.cpp:2074] conv1a ni=3 no=32
I0325 00:34:47.284745 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:47.284787 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:47.284799 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.23883
I0325 00:34:47.284811 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:34:47.403568 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:47.403607 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:47.403620 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.219129
I0325 00:34:47.403630 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:34:47.586664 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:47.586717 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:47.586730 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.234691
I0325 00:34:47.586740 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:34:47.778144 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:47.778187 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:47.778198 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.291576
I0325 00:34:47.778208 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:34:47.933333 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:47.933378 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:47.933384 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.250268
I0325 00:34:47.933390 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:34:47.974067 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:47.974100 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:47.974107 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.276378
I0325 00:34:47.974112 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:34:48.151978 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:48.152024 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:48.152034 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.355634
I0325 00:34:48.152041 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:34:48.185207 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:48.185251 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:48.185258 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.329925
I0325 00:34:48.185264 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:34:48.548071 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:48.548105 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:48.548110 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.250352
I0325 00:34:48.548116 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:34:48.640956 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:48.640995 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:48.641001 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.222526
I0325 00:34:48.641007 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:34:48.700644 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:48.700676 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:48.700682 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.242489
I0325 00:34:48.700688 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:34:48.744952 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:48.744987 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:48.744993 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.224428
I0325 00:34:48.744998 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:34:48.821017 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:48.821048 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:48.821055 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.220531
I0325 00:34:48.821061 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:34:48.906005 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:48.906034 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:48.906041 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.233608
I0325 00:34:48.906069 29022 net.cpp:2104] final threshold_value used0.2
W0325 00:34:48.927877 29022 net.cpp:2135] conv1a ZeroWeightsFraction=0.266667
W0325 00:34:48.927917 29022 net.cpp:2074] conv1b ni=32 no=32
I0325 00:34:49.449502 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:49.449529 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:49.449537 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.221732
I0325 00:34:49.449545 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:34:49.660974 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:49.660989 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:49.660995 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.208546
I0325 00:34:49.661003 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:34:49.735194 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:49.735209 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:49.735215 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.214979
I0325 00:34:49.735224 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:34:49.994339 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:49.994355 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:49.994361 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.220525
I0325 00:34:49.994370 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:34:50.458832 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:50.458847 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:50.458854 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.24567
I0325 00:34:50.458863 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:34:50.532554 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:50.532570 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:50.532577 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.253612
I0325 00:34:50.532585 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:34:50.569180 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:50.569195 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:50.569200 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.233792
I0325 00:34:50.569208 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:34:50.760885 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:50.760900 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:50.760906 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.254685
I0325 00:34:50.760915 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:34:50.838295 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:50.838311 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:50.838317 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.222896
I0325 00:34:50.838325 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:34:50.913926 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:50.913941 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:50.913947 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.224722
I0325 00:34:50.913956 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:34:51.014932 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:51.014948 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:51.014955 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.205289
I0325 00:34:51.014962 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:34:51.300179 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:51.300212 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:51.300220 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.239381
I0325 00:34:51.300225 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:34:51.360154 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:51.360186 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:51.360193 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.211506
I0325 00:34:51.360219 29022 net.cpp:2104] final threshold_value used0.2
W0325 00:34:51.592352 29022 net.cpp:2135] conv1b ZeroWeightsFraction=0.53559
W0325 00:34:51.592401 29022 net.cpp:2074] res2a_branch2a ni=32 no=64
I0325 00:34:54.395040 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:54.395069 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:54.395076 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.212071
I0325 00:34:54.395086 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:34:55.041996 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:55.042012 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:55.042018 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.202416
I0325 00:34:55.042027 29022 net.cpp:2104] final threshold_value used0.2
I0325 00:34:55.572021 29022 net.cpp:2101] threshold_value_max 0.2
I0325 00:34:55.572049 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 00:34:55.572059 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.206119
I0325 00:34:55.572065 29022 net.cpp:2104] final threshold_value used0.2
W0325 00:34:57.484392 29022 net.cpp:2135] res2a_branch2a ZeroWeightsFraction=0.546441
W0325 00:34:57.484439 29022 net.cpp:2074] res2a_branch2b ni=64 no=64
W0325 00:35:05.834477 29022 net.cpp:2135] res2a_branch2b ZeroWeightsFraction=0.514974
W0325 00:35:05.834522 29022 net.cpp:2074] res3a_branch2a ni=64 no=128
W0325 00:35:19.867331 29022 net.cpp:2135] res3a_branch2a ZeroWeightsFraction=0.542331
W0325 00:35:19.867583 29022 net.cpp:2074] res3a_branch2b ni=128 no=128
W0325 00:35:34.444720 29022 net.cpp:2135] res3a_branch2b ZeroWeightsFraction=0.541694
W0325 00:35:34.444764 29022 net.cpp:2074] res4a_branch2a ni=128 no=256
W0325 00:35:58.079111 29022 net.cpp:2135] res4a_branch2a ZeroWeightsFraction=0.54833
W0325 00:35:58.079407 29022 net.cpp:2074] res4a_branch2b ni=256 no=256
W0325 00:36:23.679744 29022 net.cpp:2135] res4a_branch2b ZeroWeightsFraction=0.539191
W0325 00:36:23.679798 29022 net.cpp:2074] res5a_branch2a ni=256 no=512
W0325 00:37:06.641773 29022 net.cpp:2135] res5a_branch2a ZeroWeightsFraction=0.517161
W0325 00:37:06.642002 29022 net.cpp:2074] res5a_branch2b ni=512 no=512
W0325 00:37:30.876689 29022 net.cpp:2135] res5a_branch2b ZeroWeightsFraction=0.549474
W0325 00:37:30.876904 29022 net.cpp:2074] ctx_output1 ni=128 no=256
W0325 00:37:30.876943 29022 net.cpp:2074] ctx_output2 ni=512 no=256
W0325 00:37:30.876968 29022 net.cpp:2074] ctx_output3 ni=512 no=256
W0325 00:37:30.876992 29022 net.cpp:2074] ctx_output4 ni=512 no=256
W0325 00:37:30.877013 29022 net.cpp:2074] ctx_output5 ni=512 no=256
W0325 00:37:30.877033 29022 net.cpp:2074] ctx_output6 ni=512 no=256
W0325 00:37:30.877053 29022 net.cpp:2074] ctx_output1/relu_mbox_loc ni=256 no=16
W0325 00:37:30.877073 29022 net.cpp:2074] ctx_output1/relu_mbox_conf ni=256 no=16
W0325 00:37:30.877094 29022 net.cpp:2074] ctx_output2/relu_mbox_loc ni=256 no=24
W0325 00:37:30.877105 29022 net.cpp:2074] ctx_output2/relu_mbox_conf ni=256 no=24
W0325 00:37:30.877116 29022 net.cpp:2074] ctx_output3/relu_mbox_loc ni=256 no=24
W0325 00:37:30.877126 29022 net.cpp:2074] ctx_output3/relu_mbox_conf ni=256 no=24
W0325 00:37:30.877136 29022 net.cpp:2074] ctx_output4/relu_mbox_loc ni=256 no=24
W0325 00:37:30.877146 29022 net.cpp:2074] ctx_output4/relu_mbox_conf ni=256 no=24
W0325 00:37:30.877157 29022 net.cpp:2074] ctx_output5/relu_mbox_loc ni=256 no=16
W0325 00:37:30.877167 29022 net.cpp:2074] ctx_output5/relu_mbox_conf ni=256 no=16
W0325 00:37:30.877177 29022 net.cpp:2074] ctx_output6/relu_mbox_loc ni=256 no=16
W0325 00:37:30.877188 29022 net.cpp:2074] ctx_output6/relu_mbox_conf ni=256 no=16
I0325 00:37:30.877202 29022 net.cpp:2169] All zero weights of convolution layers are frozen
I0325 00:37:30.882571 29022 solver.cpp:360] Sparsity after update:
I0325 00:37:30.884891 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 00:37:30.884904 29022 net.cpp:2200] conv1a_param_0(0.267) 
I0325 00:37:30.884912 29022 net.cpp:2200] conv1b_param_0(0.536) 
I0325 00:37:30.884920 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 00:37:30.884927 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 00:37:30.884932 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 00:37:30.884937 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 00:37:30.884943 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 00:37:30.884948 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 00:37:30.884953 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 00:37:30.884958 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 00:37:30.884963 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 00:37:30.884968 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 00:37:30.884974 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 00:37:30.884979 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 00:37:30.884984 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 00:37:30.884989 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 00:37:30.884996 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 00:37:30.885002 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 00:37:30.885007 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 00:37:30.885012 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 00:37:30.885018 29022 net.cpp:2200] res2a_branch2a_param_0(0.546) 
I0325 00:37:30.885023 29022 net.cpp:2200] res2a_branch2b_param_0(0.515) 
I0325 00:37:30.885030 29022 net.cpp:2200] res3a_branch2a_param_0(0.542) 
I0325 00:37:30.885035 29022 net.cpp:2200] res3a_branch2b_param_0(0.542) 
I0325 00:37:30.885040 29022 net.cpp:2200] res4a_branch2a_param_0(0.548) 
I0325 00:37:30.885046 29022 net.cpp:2200] res4a_branch2b_param_0(0.539) 
I0325 00:37:30.885051 29022 net.cpp:2200] res5a_branch2a_param_0(0.517) 
I0325 00:37:30.885056 29022 net.cpp:2200] res5a_branch2b_param_0(0.549) 
I0325 00:37:30.885061 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.25202e+06/3.10435e+06) 0.403
I0325 00:37:30.885078 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_4000.caffemodel
I0325 00:37:30.904215 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_4000.solverstate
I0325 00:37:30.912380 29022 solver.cpp:678] Iteration 4000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0.128568
j:  : 5 : max_pr:  : 0.318995
j:  : 4 : max_pr:  : 0.475742
j:  : 3 : max_pr:  : 0.602593
j:  : 2 : max_pr:  : 0.718304
j:  : 1 : max_pr:  : 0.830889
j:  : 0 : max_pr:  : 1
I0325 00:38:53.860383 29022 solver.cpp:786] class AP 1: 0.370463
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.207794
j:  : 6 : max_pr:  : 0.436878
j:  : 5 : max_pr:  : 0.57453
j:  : 4 : max_pr:  : 0.649217
j:  : 3 : max_pr:  : 0.874522
j:  : 2 : max_pr:  : 0.977119
j:  : 1 : max_pr:  : 0.999265
j:  : 0 : max_pr:  : 1
I0325 00:38:53.952358 29022 solver.cpp:786] class AP 2: 0.519939
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.49981
j:  : 6 : max_pr:  : 0.67478
j:  : 5 : max_pr:  : 0.771805
j:  : 4 : max_pr:  : 0.874204
j:  : 3 : max_pr:  : 0.937451
j:  : 2 : max_pr:  : 0.97643
j:  : 1 : max_pr:  : 0.999086
j:  : 0 : max_pr:  : 1
I0325 00:38:53.973273 29022 solver.cpp:786] class AP 3: 0.612142
I0325 00:38:53.973287 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.500848
I0325 00:38:53.973331 29022 solver.cpp:265] Tests completed in 83.0582s
I0325 00:38:54.546727 29022 solver.cpp:314] Iteration 4000 (0.309892 iter/s, 322.693s/100 iter), loss = 2.96051
I0325 00:38:54.546824 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.86451 (* 1 = 2.86451 loss)
I0325 00:38:54.546857 29022 sgd_solver.cpp:136] Iteration 4000, lr = 0.000758835, m = 0.9
I0325 00:40:11.175297 29022 solver.cpp:314] Iteration 4100 (1.30504 iter/s, 76.626s/100 iter), loss = 3.13169
I0325 00:40:11.175446 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.79876 (* 1 = 2.79876 loss)
I0325 00:40:11.175487 29022 sgd_solver.cpp:136] Iteration 4100, lr = 0.000753429, m = 0.9
I0325 00:41:27.489498 29022 solver.cpp:314] Iteration 4200 (1.31042 iter/s, 76.3117s/100 iter), loss = 3.05143
I0325 00:41:27.489647 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.0309 (* 1 = 3.0309 loss)
I0325 00:41:27.489681 29022 sgd_solver.cpp:136] Iteration 4200, lr = 0.000748052, m = 0.9
I0325 00:42:44.057814 29022 solver.cpp:314] Iteration 4300 (1.30607 iter/s, 76.5658s/100 iter), loss = 3.03656
I0325 00:42:44.057947 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.12725 (* 1 = 2.12725 loss)
I0325 00:42:44.057981 29022 sgd_solver.cpp:136] Iteration 4300, lr = 0.000742704, m = 0.9
I0325 00:44:00.114719 29022 solver.cpp:314] Iteration 4400 (1.31485 iter/s, 76.0544s/100 iter), loss = 3.11787
I0325 00:44:00.114852 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.7541 (* 1 = 2.7541 loss)
I0325 00:44:00.114868 29022 sgd_solver.cpp:136] Iteration 4400, lr = 0.000737385, m = 0.9
I0325 00:45:14.967455 29022 solver.cpp:314] Iteration 4500 (1.336 iter/s, 74.8503s/100 iter), loss = 3.134
I0325 00:45:14.967559 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.28701 (* 1 = 3.28701 loss)
I0325 00:45:14.967578 29022 sgd_solver.cpp:136] Iteration 4500, lr = 0.000732094, m = 0.9
I0325 00:46:30.950783 29022 solver.cpp:314] Iteration 4600 (1.31612 iter/s, 75.9809s/100 iter), loss = 3.143
I0325 00:46:30.951146 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.30778 (* 1 = 3.30778 loss)
I0325 00:46:30.951169 29022 sgd_solver.cpp:136] Iteration 4600, lr = 0.000726832, m = 0.9
I0325 00:47:47.830759 29022 solver.cpp:314] Iteration 4700 (1.30077 iter/s, 76.8775s/100 iter), loss = 3.14787
I0325 00:47:47.830902 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.75013 (* 1 = 2.75013 loss)
I0325 00:47:47.830937 29022 sgd_solver.cpp:136] Iteration 4700, lr = 0.000721598, m = 0.9
I0325 00:49:04.641618 29022 solver.cpp:314] Iteration 4800 (1.30194 iter/s, 76.8084s/100 iter), loss = 3.04195
I0325 00:49:04.641752 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.20863 (* 1 = 3.20863 loss)
I0325 00:49:04.641764 29022 sgd_solver.cpp:136] Iteration 4800, lr = 0.000716393, m = 0.9
I0325 00:50:20.923554 29022 solver.cpp:314] Iteration 4900 (1.31097 iter/s, 76.2795s/100 iter), loss = 3.18949
I0325 00:50:20.923696 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.70328 (* 1 = 3.70328 loss)
I0325 00:50:20.923730 29022 sgd_solver.cpp:136] Iteration 4900, lr = 0.000711216, m = 0.9
I0325 00:51:38.361748 29022 solver.cpp:314] Iteration 5000 (1.29139 iter/s, 77.4357s/100 iter), loss = 3.11766
I0325 00:51:38.361897 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.73918 (* 1 = 2.73918 loss)
I0325 00:51:38.361930 29022 sgd_solver.cpp:136] Iteration 5000, lr = 0.000706067, m = 0.9
I0325 00:52:54.446925 29022 solver.cpp:314] Iteration 5100 (1.31436 iter/s, 76.0827s/100 iter), loss = 3.19414
I0325 00:52:54.447059 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.71154 (* 1 = 3.71154 loss)
I0325 00:52:54.447096 29022 sgd_solver.cpp:136] Iteration 5100, lr = 0.000700946, m = 0.9
I0325 00:54:09.895109 29022 solver.cpp:314] Iteration 5200 (1.32546 iter/s, 75.4458s/100 iter), loss = 3.00249
I0325 00:54:09.895218 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.45642 (* 1 = 3.45642 loss)
I0325 00:54:09.895236 29022 sgd_solver.cpp:136] Iteration 5200, lr = 0.000695853, m = 0.9
I0325 00:55:25.677664 29022 solver.cpp:314] Iteration 5300 (1.31961 iter/s, 75.7801s/100 iter), loss = 3.12124
I0325 00:55:25.677820 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.59575 (* 1 = 2.59575 loss)
I0325 00:55:25.677857 29022 sgd_solver.cpp:136] Iteration 5300, lr = 0.000690787, m = 0.9
I0325 00:56:42.548403 29022 solver.cpp:314] Iteration 5400 (1.30093 iter/s, 76.8683s/100 iter), loss = 3.07368
I0325 00:56:42.548544 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.61112 (* 1 = 2.61112 loss)
I0325 00:56:42.548580 29022 sgd_solver.cpp:136] Iteration 5400, lr = 0.00068575, m = 0.9
I0325 00:57:59.075783 29022 solver.cpp:314] Iteration 5500 (1.30676 iter/s, 76.5249s/100 iter), loss = 3.09914
I0325 00:57:59.075974 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.49801 (* 1 = 2.49801 loss)
I0325 00:57:59.075992 29022 sgd_solver.cpp:136] Iteration 5500, lr = 0.00068074, m = 0.9
I0325 00:59:16.094097 29022 solver.cpp:314] Iteration 5600 (1.29843 iter/s, 77.0158s/100 iter), loss = 3.07967
I0325 00:59:16.094234 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.96408 (* 1 = 2.96408 loss)
I0325 00:59:16.094270 29022 sgd_solver.cpp:136] Iteration 5600, lr = 0.000675757, m = 0.9
I0325 01:00:32.999017 29022 solver.cpp:314] Iteration 5700 (1.30035 iter/s, 76.9024s/100 iter), loss = 3.20793
I0325 01:00:32.999162 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.84316 (* 1 = 3.84316 loss)
I0325 01:00:32.999197 29022 sgd_solver.cpp:136] Iteration 5700, lr = 0.000670802, m = 0.9
I0325 01:01:50.421772 29022 solver.cpp:314] Iteration 5800 (1.29165 iter/s, 77.4203s/100 iter), loss = 3.24064
I0325 01:01:50.421918 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.15022 (* 1 = 3.15022 loss)
I0325 01:01:50.422433 29022 sgd_solver.cpp:136] Iteration 5800, lr = 0.000665874, m = 0.9
I0325 01:03:06.889747 29022 solver.cpp:314] Iteration 5900 (1.30778 iter/s, 76.4655s/100 iter), loss = 3.19904
I0325 01:03:06.889894 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.37883 (* 1 = 3.37883 loss)
I0325 01:03:06.889932 29022 sgd_solver.cpp:136] Iteration 5900, lr = 0.000660973, m = 0.9
I0325 01:04:22.307812 29022 solver.cpp:443] Finding and applying sparsity: sparsity_target=0.7 sparsity_factor=0.6 sparsity_achieved=0.403312 iter=6000
W0325 01:04:22.307938 29022 net.cpp:2074] conv1a ni=3 no=32
I0325 01:04:22.509937 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:22.509973 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:22.509984 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.238782
I0325 01:04:22.509994 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:04:22.583385 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:22.583428 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:22.583441 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.219691
I0325 01:04:22.583451 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:04:22.799485 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:22.799523 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:22.799535 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.234377
I0325 01:04:22.799545 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:04:22.999656 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:22.999701 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:22.999712 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.291165
I0325 01:04:22.999722 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:04:23.073595 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:23.073634 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:23.073647 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.249844
I0325 01:04:23.073657 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:04:23.134721 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:23.134755 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:23.134768 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.276189
I0325 01:04:23.134778 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:04:23.334209 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:23.334249 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:23.334256 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.355433
I0325 01:04:23.334262 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:04:23.373811 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:23.373847 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:23.373854 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.32944
I0325 01:04:23.373860 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:04:23.667455 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:23.667492 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:23.667500 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.250824
I0325 01:04:23.667505 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:04:23.771250 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:23.771286 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:23.771292 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.222367
I0325 01:04:23.771298 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:04:23.843914 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:23.843942 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:23.843950 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.242991
I0325 01:04:23.843955 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:04:23.891196 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:23.891227 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:23.891233 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.22483
I0325 01:04:23.891239 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:04:23.972796 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:23.972827 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:23.972834 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.219721
I0325 01:04:23.972841 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:04:24.063163 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:24.063194 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:24.063201 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.233544
I0325 01:04:24.063231 29022 net.cpp:2104] final threshold_value used0.2
W0325 01:04:24.092298 29022 net.cpp:2135] conv1a ZeroWeightsFraction=0.293333
W0325 01:04:24.092519 29022 net.cpp:2074] conv1b ni=32 no=32
I0325 01:04:24.679076 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:24.679105 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:24.679112 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.222437
I0325 01:04:24.679121 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:04:24.922603 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:24.922619 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:24.922626 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.209021
I0325 01:04:24.922634 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:04:25.010035 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:25.010051 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:25.010057 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.215264
I0325 01:04:25.010066 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:04:25.345355 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:25.345382 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:25.345389 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.220017
I0325 01:04:25.345398 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:04:25.898785 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:25.898802 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:25.898808 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.246353
I0325 01:04:25.898818 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:04:26.022181 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:26.022197 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:26.022202 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.252018
I0325 01:04:26.022212 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:04:26.074756 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:26.074772 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:26.074779 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.234391
I0325 01:04:26.074787 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:04:26.341559 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:26.341593 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:26.341599 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.254843
I0325 01:04:26.341604 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:04:26.437335 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:26.437367 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:26.437373 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.225578
I0325 01:04:26.437379 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:04:26.540438 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:26.540470 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:26.540477 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.225186
I0325 01:04:26.540482 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:04:26.669378 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:26.669409 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:26.669420 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.206394
I0325 01:04:26.669425 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:04:26.949396 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:26.949414 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:26.949421 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.239895
I0325 01:04:26.949429 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:04:27.029534 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:27.029549 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:27.029556 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.21145
I0325 01:04:27.029582 29022 net.cpp:2104] final threshold_value used0.2
W0325 01:04:27.268548 29022 net.cpp:2135] conv1b ZeroWeightsFraction=0.584201
W0325 01:04:27.268754 29022 net.cpp:2074] res2a_branch2a ni=32 no=64
I0325 01:04:30.364449 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:30.364477 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:30.364487 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.212111
I0325 01:04:30.364495 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:04:31.068455 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:31.068473 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:31.068480 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.202389
I0325 01:04:31.068486 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:04:31.666532 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:04:31.666561 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:04:31.666568 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.205488
I0325 01:04:31.666577 29022 net.cpp:2104] final threshold_value used0.2
W0325 01:04:33.823563 29022 net.cpp:2135] res2a_branch2a ZeroWeightsFraction=0.591851
W0325 01:04:33.823724 29022 net.cpp:2074] res2a_branch2b ni=64 no=64
W0325 01:04:42.518952 29022 net.cpp:2135] res2a_branch2b ZeroWeightsFraction=0.539605
W0325 01:04:42.519162 29022 net.cpp:2074] res3a_branch2a ni=64 no=128
W0325 01:04:57.683362 29022 net.cpp:2135] res3a_branch2a ZeroWeightsFraction=0.586046
W0325 01:04:57.683676 29022 net.cpp:2074] res3a_branch2b ni=128 no=128
W0325 01:05:13.526250 29022 net.cpp:2135] res3a_branch2b ZeroWeightsFraction=0.578939
W0325 01:05:13.526465 29022 net.cpp:2074] res4a_branch2a ni=128 no=256
W0325 01:05:40.571087 29022 net.cpp:2135] res4a_branch2a ZeroWeightsFraction=0.599026
W0325 01:05:40.571334 29022 net.cpp:2074] res4a_branch2b ni=256 no=256
W0325 01:06:08.963891 29022 net.cpp:2135] res4a_branch2b ZeroWeightsFraction=0.589444
W0325 01:06:08.964097 29022 net.cpp:2074] res5a_branch2a ni=256 no=512
W0325 01:06:49.553308 29022 net.cpp:2135] res5a_branch2a ZeroWeightsFraction=0.594722
W0325 01:06:49.553550 29022 net.cpp:2074] res5a_branch2b ni=512 no=512
W0325 01:07:19.200364 29022 net.cpp:2135] res5a_branch2b ZeroWeightsFraction=0.599803
W0325 01:07:19.200556 29022 net.cpp:2074] ctx_output1 ni=128 no=256
W0325 01:07:19.200592 29022 net.cpp:2074] ctx_output2 ni=512 no=256
W0325 01:07:19.200616 29022 net.cpp:2074] ctx_output3 ni=512 no=256
W0325 01:07:19.200636 29022 net.cpp:2074] ctx_output4 ni=512 no=256
W0325 01:07:19.200660 29022 net.cpp:2074] ctx_output5 ni=512 no=256
W0325 01:07:19.200681 29022 net.cpp:2074] ctx_output6 ni=512 no=256
W0325 01:07:19.200701 29022 net.cpp:2074] ctx_output1/relu_mbox_loc ni=256 no=16
W0325 01:07:19.200722 29022 net.cpp:2074] ctx_output1/relu_mbox_conf ni=256 no=16
W0325 01:07:19.200742 29022 net.cpp:2074] ctx_output2/relu_mbox_loc ni=256 no=24
W0325 01:07:19.200762 29022 net.cpp:2074] ctx_output2/relu_mbox_conf ni=256 no=24
W0325 01:07:19.200804 29022 net.cpp:2074] ctx_output3/relu_mbox_loc ni=256 no=24
W0325 01:07:19.200817 29022 net.cpp:2074] ctx_output3/relu_mbox_conf ni=256 no=24
W0325 01:07:19.200829 29022 net.cpp:2074] ctx_output4/relu_mbox_loc ni=256 no=24
W0325 01:07:19.200839 29022 net.cpp:2074] ctx_output4/relu_mbox_conf ni=256 no=24
W0325 01:07:19.200850 29022 net.cpp:2074] ctx_output5/relu_mbox_loc ni=256 no=16
W0325 01:07:19.200860 29022 net.cpp:2074] ctx_output5/relu_mbox_conf ni=256 no=16
W0325 01:07:19.200873 29022 net.cpp:2074] ctx_output6/relu_mbox_loc ni=256 no=16
W0325 01:07:19.200896 29022 net.cpp:2074] ctx_output6/relu_mbox_conf ni=256 no=16
I0325 01:07:19.200917 29022 net.cpp:2169] All zero weights of convolution layers are frozen
I0325 01:07:19.206179 29022 solver.cpp:360] Sparsity after update:
I0325 01:07:19.208499 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 01:07:19.208513 29022 net.cpp:2200] conv1a_param_0(0.293) 
I0325 01:07:19.208520 29022 net.cpp:2200] conv1b_param_0(0.584) 
I0325 01:07:19.208529 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 01:07:19.208534 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 01:07:19.208540 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 01:07:19.208545 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 01:07:19.208551 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 01:07:19.208556 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 01:07:19.208561 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 01:07:19.208567 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 01:07:19.208572 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 01:07:19.208578 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 01:07:19.208583 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 01:07:19.208588 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 01:07:19.208595 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 01:07:19.208600 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 01:07:19.208604 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 01:07:19.208611 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 01:07:19.208617 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 01:07:19.208622 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 01:07:19.208628 29022 net.cpp:2200] res2a_branch2a_param_0(0.592) 
I0325 01:07:19.208633 29022 net.cpp:2200] res2a_branch2b_param_0(0.54) 
I0325 01:07:19.208639 29022 net.cpp:2200] res3a_branch2a_param_0(0.586) 
I0325 01:07:19.208644 29022 net.cpp:2200] res3a_branch2b_param_0(0.579) 
I0325 01:07:19.208650 29022 net.cpp:2200] res4a_branch2a_param_0(0.599) 
I0325 01:07:19.208655 29022 net.cpp:2200] res4a_branch2b_param_0(0.589) 
I0325 01:07:19.208662 29022 net.cpp:2200] res5a_branch2a_param_0(0.595) 
I0325 01:07:19.208667 29022 net.cpp:2200] res5a_branch2b_param_0(0.6) 
I0325 01:07:19.208673 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.4014e+06/3.10435e+06) 0.451
I0325 01:07:19.208690 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_6000.caffemodel
I0325 01:07:19.227885 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_6000.solverstate
I0325 01:07:19.236153 29022 solver.cpp:678] Iteration 6000, Testing net (#0)
I0325 01:08:41.444799 29077 data_reader.cpp:305] Starting prefetch of epoch 2
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.134196
j:  : 4 : max_pr:  : 0.386036
j:  : 3 : max_pr:  : 0.564885
j:  : 2 : max_pr:  : 0.70374
j:  : 1 : max_pr:  : 0.85
j:  : 0 : max_pr:  : 1
I0325 01:08:42.375671 29022 solver.cpp:786] class AP 1: 0.330805
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0990497
j:  : 7 : max_pr:  : 0.261885
j:  : 6 : max_pr:  : 0.382563
j:  : 5 : max_pr:  : 0.514093
j:  : 4 : max_pr:  : 0.646816
j:  : 3 : max_pr:  : 0.804092
j:  : 2 : max_pr:  : 0.965108
j:  : 1 : max_pr:  : 0.997713
j:  : 0 : max_pr:  : 1
I0325 01:08:42.467821 29022 solver.cpp:786] class AP 2: 0.515575
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.428917
j:  : 6 : max_pr:  : 0.623444
j:  : 5 : max_pr:  : 0.733003
j:  : 4 : max_pr:  : 0.84693
j:  : 3 : max_pr:  : 0.921411
j:  : 2 : max_pr:  : 0.963711
j:  : 1 : max_pr:  : 0.999684
j:  : 0 : max_pr:  : 1
I0325 01:08:42.496830 29022 solver.cpp:786] class AP 3: 0.592464
I0325 01:08:42.496852 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.479614
I0325 01:08:42.496896 29022 solver.cpp:265] Tests completed in 83.258s
I0325 01:08:43.028362 29022 solver.cpp:314] Iteration 6000 (0.297506 iter/s, 336.128s/100 iter), loss = 2.88076
I0325 01:08:43.028460 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.14628 (* 1 = 2.14628 loss)
I0325 01:08:43.028491 29022 sgd_solver.cpp:136] Iteration 6000, lr = 0.0006561, m = 0.9
I0325 01:09:58.193648 29022 solver.cpp:314] Iteration 6100 (1.33045 iter/s, 75.1628s/100 iter), loss = 3.02781
I0325 01:09:58.193967 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.26386 (* 1 = 3.26386 loss)
I0325 01:09:58.193990 29022 sgd_solver.cpp:136] Iteration 6100, lr = 0.000651253, m = 0.9
I0325 01:11:15.169018 29022 solver.cpp:314] Iteration 6200 (1.29916 iter/s, 76.9728s/100 iter), loss = 3.1971
I0325 01:11:15.169158 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.9063 (* 1 = 3.9063 loss)
I0325 01:11:15.169194 29022 sgd_solver.cpp:136] Iteration 6200, lr = 0.000646434, m = 0.9
I0325 01:12:31.240089 29022 solver.cpp:314] Iteration 6300 (1.3146 iter/s, 76.0686s/100 iter), loss = 3.12017
I0325 01:12:31.240193 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.89125 (* 1 = 3.89125 loss)
I0325 01:12:31.240211 29022 sgd_solver.cpp:136] Iteration 6300, lr = 0.000641641, m = 0.9
I0325 01:13:47.418507 29022 solver.cpp:314] Iteration 6400 (1.31275 iter/s, 76.1759s/100 iter), loss = 3.06577
I0325 01:13:47.418812 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.6627 (* 1 = 3.6627 loss)
I0325 01:13:47.418828 29022 sgd_solver.cpp:136] Iteration 6400, lr = 0.000636875, m = 0.9
I0325 01:15:04.130316 29022 solver.cpp:314] Iteration 6500 (1.30362 iter/s, 76.7093s/100 iter), loss = 3.28555
I0325 01:15:04.130445 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.71128 (* 1 = 2.71128 loss)
I0325 01:15:04.130481 29022 sgd_solver.cpp:136] Iteration 6500, lr = 0.000632135, m = 0.9
I0325 01:16:21.845051 29022 solver.cpp:314] Iteration 6600 (1.2868 iter/s, 77.7122s/100 iter), loss = 3.21361
I0325 01:16:21.845206 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.84964 (* 1 = 2.84964 loss)
I0325 01:16:21.845239 29022 sgd_solver.cpp:136] Iteration 6600, lr = 0.000627422, m = 0.9
I0325 01:17:38.192144 29022 solver.cpp:314] Iteration 6700 (1.30985 iter/s, 76.3446s/100 iter), loss = 3.08391
I0325 01:17:38.192282 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.6717 (* 1 = 2.6717 loss)
I0325 01:17:38.192317 29022 sgd_solver.cpp:136] Iteration 6700, lr = 0.000622736, m = 0.9
I0325 01:18:54.687106 29022 solver.cpp:314] Iteration 6800 (1.30732 iter/s, 76.4925s/100 iter), loss = 3.07279
I0325 01:18:54.687230 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.08956 (* 1 = 3.08956 loss)
I0325 01:18:54.687247 29022 sgd_solver.cpp:136] Iteration 6800, lr = 0.000618075, m = 0.9
I0325 01:20:10.242640 29022 solver.cpp:314] Iteration 6900 (1.32357 iter/s, 75.5531s/100 iter), loss = 3.04984
I0325 01:20:10.242774 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.51375 (* 1 = 3.51375 loss)
I0325 01:20:10.242807 29022 sgd_solver.cpp:136] Iteration 6900, lr = 0.000613441, m = 0.9
I0325 01:21:26.965886 29022 solver.cpp:314] Iteration 7000 (1.30343 iter/s, 76.7208s/100 iter), loss = 3.14603
I0325 01:21:26.965994 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.48004 (* 1 = 2.48004 loss)
I0325 01:21:26.966007 29022 sgd_solver.cpp:136] Iteration 7000, lr = 0.000608833, m = 0.9
I0325 01:22:44.259606 29022 solver.cpp:314] Iteration 7100 (1.29381 iter/s, 77.2913s/100 iter), loss = 3.11799
I0325 01:22:44.259694 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.2246 (* 1 = 3.2246 loss)
I0325 01:22:44.259706 29022 sgd_solver.cpp:136] Iteration 7100, lr = 0.000604251, m = 0.9
I0325 01:24:00.892740 29022 solver.cpp:314] Iteration 7200 (1.30496 iter/s, 76.6307s/100 iter), loss = 3.26043
I0325 01:24:00.892909 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.3956 (* 1 = 3.3956 loss)
I0325 01:24:00.892925 29022 sgd_solver.cpp:136] Iteration 7200, lr = 0.000599695, m = 0.9
I0325 01:25:18.524575 29022 solver.cpp:314] Iteration 7300 (1.28817 iter/s, 77.6294s/100 iter), loss = 3.26668
I0325 01:25:18.524716 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.38323 (* 1 = 3.38323 loss)
I0325 01:25:18.524750 29022 sgd_solver.cpp:136] Iteration 7300, lr = 0.000595165, m = 0.9
I0325 01:26:35.358397 29022 solver.cpp:314] Iteration 7400 (1.30155 iter/s, 76.8314s/100 iter), loss = 3.04097
I0325 01:26:35.358539 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.30013 (* 1 = 3.30013 loss)
I0325 01:26:35.358578 29022 sgd_solver.cpp:136] Iteration 7400, lr = 0.000590661, m = 0.9
I0325 01:27:51.591775 29022 solver.cpp:314] Iteration 7500 (1.3118 iter/s, 76.231s/100 iter), loss = 3.09121
I0325 01:27:51.602118 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.42937 (* 1 = 3.42937 loss)
I0325 01:27:51.602432 29022 sgd_solver.cpp:136] Iteration 7500, lr = 0.000586182, m = 0.9
I0325 01:29:07.101462 29022 solver.cpp:314] Iteration 7600 (1.32438 iter/s, 75.5073s/100 iter), loss = 3.16312
I0325 01:29:07.101943 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.04881 (* 1 = 3.04881 loss)
I0325 01:29:07.101960 29022 sgd_solver.cpp:136] Iteration 7600, lr = 0.000581728, m = 0.9
I0325 01:30:25.079180 29022 solver.cpp:314] Iteration 7700 (1.28246 iter/s, 77.9752s/100 iter), loss = 3.16565
I0325 01:30:25.079345 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.61328 (* 1 = 2.61328 loss)
I0325 01:30:25.079381 29022 sgd_solver.cpp:136] Iteration 7700, lr = 0.0005773, m = 0.9
I0325 01:31:41.684288 29022 solver.cpp:314] Iteration 7800 (1.30544 iter/s, 76.6027s/100 iter), loss = 3.15971
I0325 01:31:41.686633 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.54504 (* 1 = 4.54504 loss)
I0325 01:31:41.686673 29022 sgd_solver.cpp:136] Iteration 7800, lr = 0.000572898, m = 0.9
I0325 01:32:58.592023 29022 solver.cpp:314] Iteration 7900 (1.3003 iter/s, 76.9053s/100 iter), loss = 3.25664
I0325 01:32:58.592133 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.32799 (* 1 = 2.32799 loss)
I0325 01:32:58.592150 29022 sgd_solver.cpp:136] Iteration 7900, lr = 0.00056852, m = 0.9
I0325 01:34:13.841140 29022 solver.cpp:443] Finding and applying sparsity: sparsity_target=0.7 sparsity_factor=0.65 sparsity_achieved=0.451431 iter=8000
W0325 01:34:13.841284 29022 net.cpp:2074] conv1a ni=3 no=32
I0325 01:34:14.038686 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:14.038727 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:14.038734 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.239408
I0325 01:34:14.038740 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:34:14.108278 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:14.108319 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:14.108325 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.219664
I0325 01:34:14.108331 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:34:14.333305 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:14.333387 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:14.333415 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.234955
I0325 01:34:14.333441 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:34:14.567196 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:14.567237 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:14.567248 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.290819
I0325 01:34:14.567258 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:34:14.652299 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:14.652350 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:14.652361 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.250067
I0325 01:34:14.652371 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:34:14.717875 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:14.717909 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:14.717921 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.277527
I0325 01:34:14.717931 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:34:14.925575 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:14.925612 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:14.925624 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.3549
I0325 01:34:14.925634 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:34:15.018326 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:15.018365 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:15.018378 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.328954
I0325 01:34:15.018388 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:34:15.439468 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:15.439505 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:15.439512 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.251236
I0325 01:34:15.439517 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:34:15.555063 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:15.555093 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:15.555099 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.222286
I0325 01:34:15.555105 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:34:15.632730 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:15.632767 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:15.632774 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.242864
I0325 01:34:15.632781 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:34:15.683480 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:15.683516 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:15.683523 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.22542
I0325 01:34:15.683529 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:34:15.768079 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:15.768117 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:15.768124 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.220357
I0325 01:34:15.768129 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:34:15.864686 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:15.864723 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:15.864730 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.233695
I0325 01:34:15.864760 29022 net.cpp:2104] final threshold_value used0.2
W0325 01:34:15.901206 29022 net.cpp:2135] conv1a ZeroWeightsFraction=0.32
W0325 01:34:15.901324 29022 net.cpp:2074] conv1b ni=32 no=32
I0325 01:34:16.522730 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:16.522750 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:16.522756 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.22357
I0325 01:34:16.522765 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:34:16.776859 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:16.776875 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:16.776881 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.209117
I0325 01:34:16.776890 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:34:16.871327 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:16.871342 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:16.871348 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.213648
I0325 01:34:16.871354 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:34:17.233003 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:17.233031 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:17.233038 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.220176
I0325 01:34:17.233047 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:34:17.901541 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:17.901576 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:17.901585 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.246548
I0325 01:34:17.901592 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:34:18.036729 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:18.036744 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:18.036751 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.254435
I0325 01:34:18.036759 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:34:18.095643 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:18.095659 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:18.095664 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.233722
I0325 01:34:18.095672 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:34:18.409544 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:18.409559 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:18.409566 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.255432
I0325 01:34:18.409574 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:34:18.515235 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:18.515250 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:18.515256 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.224252
I0325 01:34:18.515265 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:34:18.636682 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:18.636698 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:18.636703 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.225504
I0325 01:34:18.636713 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:34:18.761181 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:18.761198 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:18.761204 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.207478
I0325 01:34:18.761211 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:34:19.036280 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:19.036295 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:19.036303 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.240512
I0325 01:34:19.036310 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:34:19.118743 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:19.118774 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:19.118780 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.209859
I0325 01:34:19.118787 29022 net.cpp:2104] final threshold_value used0.2
W0325 01:34:19.359267 29022 net.cpp:2135] conv1b ZeroWeightsFraction=0.618056
W0325 01:34:19.359396 29022 net.cpp:2074] res2a_branch2a ni=32 no=64
I0325 01:34:22.734076 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:22.734108 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:22.734115 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.211718
I0325 01:34:22.734122 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:34:23.482530 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:23.482559 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:23.482568 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.20196
I0325 01:34:23.482575 29022 net.cpp:2104] final threshold_value used0.2
I0325 01:34:24.144994 29022 net.cpp:2101] threshold_value_max 0.2
I0325 01:34:24.145010 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 01:34:24.145016 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.205407
I0325 01:34:24.145025 29022 net.cpp:2104] final threshold_value used0.2
W0325 01:34:26.473508 29022 net.cpp:2135] res2a_branch2a ZeroWeightsFraction=0.636773
W0325 01:34:26.473636 29022 net.cpp:2074] res2a_branch2b ni=64 no=64
W0325 01:34:35.304383 29022 net.cpp:2135] res2a_branch2b ZeroWeightsFraction=0.555881
W0325 01:34:35.304512 29022 net.cpp:2074] res3a_branch2a ni=64 no=128
W0325 01:34:51.174840 29022 net.cpp:2135] res3a_branch2a ZeroWeightsFraction=0.619765
W0325 01:34:51.174988 29022 net.cpp:2074] res3a_branch2b ni=128 no=128
W0325 01:35:07.737409 29022 net.cpp:2135] res3a_branch2b ZeroWeightsFraction=0.6081
W0325 01:35:07.737630 29022 net.cpp:2074] res4a_branch2a ni=128 no=256
W0325 01:35:37.889147 29022 net.cpp:2135] res4a_branch2a ZeroWeightsFraction=0.647522
W0325 01:35:37.889366 29022 net.cpp:2074] res4a_branch2b ni=256 no=256
W0325 01:36:08.398386 29022 net.cpp:2135] res4a_branch2b ZeroWeightsFraction=0.631714
W0325 01:36:08.398571 29022 net.cpp:2074] res5a_branch2a ni=256 no=512
W0325 01:36:48.962013 29022 net.cpp:2135] res5a_branch2a ZeroWeightsFraction=0.645874
W0325 01:36:48.962142 29022 net.cpp:2074] res5a_branch2b ni=512 no=512
W0325 01:37:24.143554 29022 net.cpp:2135] res5a_branch2b ZeroWeightsFraction=0.649285
W0325 01:37:24.143708 29022 net.cpp:2074] ctx_output1 ni=128 no=256
W0325 01:37:24.143730 29022 net.cpp:2074] ctx_output2 ni=512 no=256
W0325 01:37:24.143748 29022 net.cpp:2074] ctx_output3 ni=512 no=256
W0325 01:37:24.143760 29022 net.cpp:2074] ctx_output4 ni=512 no=256
W0325 01:37:24.143771 29022 net.cpp:2074] ctx_output5 ni=512 no=256
W0325 01:37:24.143784 29022 net.cpp:2074] ctx_output6 ni=512 no=256
W0325 01:37:24.143795 29022 net.cpp:2074] ctx_output1/relu_mbox_loc ni=256 no=16
W0325 01:37:24.143816 29022 net.cpp:2074] ctx_output1/relu_mbox_conf ni=256 no=16
W0325 01:37:24.143831 29022 net.cpp:2074] ctx_output2/relu_mbox_loc ni=256 no=24
W0325 01:37:24.143841 29022 net.cpp:2074] ctx_output2/relu_mbox_conf ni=256 no=24
W0325 01:37:24.143851 29022 net.cpp:2074] ctx_output3/relu_mbox_loc ni=256 no=24
W0325 01:37:24.143863 29022 net.cpp:2074] ctx_output3/relu_mbox_conf ni=256 no=24
W0325 01:37:24.143874 29022 net.cpp:2074] ctx_output4/relu_mbox_loc ni=256 no=24
W0325 01:37:24.143884 29022 net.cpp:2074] ctx_output4/relu_mbox_conf ni=256 no=24
W0325 01:37:24.143895 29022 net.cpp:2074] ctx_output5/relu_mbox_loc ni=256 no=16
W0325 01:37:24.143905 29022 net.cpp:2074] ctx_output5/relu_mbox_conf ni=256 no=16
W0325 01:37:24.143916 29022 net.cpp:2074] ctx_output6/relu_mbox_loc ni=256 no=16
W0325 01:37:24.143926 29022 net.cpp:2074] ctx_output6/relu_mbox_conf ni=256 no=16
I0325 01:37:24.143942 29022 net.cpp:2169] All zero weights of convolution layers are frozen
I0325 01:37:24.149241 29022 solver.cpp:360] Sparsity after update:
I0325 01:37:24.151659 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 01:37:24.151674 29022 net.cpp:2200] conv1a_param_0(0.32) 
I0325 01:37:24.151686 29022 net.cpp:2200] conv1b_param_0(0.618) 
I0325 01:37:24.151698 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 01:37:24.151710 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 01:37:24.151721 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 01:37:24.151731 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 01:37:24.151741 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 01:37:24.151751 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 01:37:24.151767 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 01:37:24.151782 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 01:37:24.151793 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 01:37:24.151806 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 01:37:24.151821 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 01:37:24.151834 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 01:37:24.151846 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 01:37:24.151861 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 01:37:24.151873 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 01:37:24.151885 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 01:37:24.151898 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 01:37:24.151912 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 01:37:24.151926 29022 net.cpp:2200] res2a_branch2a_param_0(0.637) 
I0325 01:37:24.151938 29022 net.cpp:2200] res2a_branch2b_param_0(0.556) 
I0325 01:37:24.151952 29022 net.cpp:2200] res3a_branch2a_param_0(0.62) 
I0325 01:37:24.151964 29022 net.cpp:2200] res3a_branch2b_param_0(0.608) 
I0325 01:37:24.151978 29022 net.cpp:2200] res4a_branch2a_param_0(0.648) 
I0325 01:37:24.151991 29022 net.cpp:2200] res4a_branch2b_param_0(0.632) 
I0325 01:37:24.152003 29022 net.cpp:2200] res5a_branch2a_param_0(0.646) 
I0325 01:37:24.152016 29022 net.cpp:2200] res5a_branch2b_param_0(0.649) 
I0325 01:37:24.152027 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.51614e+06/3.10435e+06) 0.488
I0325 01:37:24.152062 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_8000.caffemodel
I0325 01:37:24.171697 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_8000.solverstate
I0325 01:37:24.180060 29022 solver.cpp:678] Iteration 8000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.16665
j:  : 4 : max_pr:  : 0.397433
j:  : 3 : max_pr:  : 0.571714
j:  : 2 : max_pr:  : 0.698573
j:  : 1 : max_pr:  : 0.819806
j:  : 0 : max_pr:  : 1
I0325 01:38:47.166132 29022 solver.cpp:786] class AP 1: 0.332198
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.179014
j:  : 7 : max_pr:  : 0.356147
j:  : 6 : max_pr:  : 0.470927
j:  : 5 : max_pr:  : 0.680891
j:  : 4 : max_pr:  : 0.80807
j:  : 3 : max_pr:  : 0.846304
j:  : 2 : max_pr:  : 0.972618
j:  : 1 : max_pr:  : 0.999372
j:  : 0 : max_pr:  : 1
I0325 01:38:47.263257 29022 solver.cpp:786] class AP 2: 0.57394
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.473121
j:  : 6 : max_pr:  : 0.619785
j:  : 5 : max_pr:  : 0.733799
j:  : 4 : max_pr:  : 0.844596
j:  : 3 : max_pr:  : 0.918951
j:  : 2 : max_pr:  : 0.972903
j:  : 1 : max_pr:  : 0.99969
j:  : 0 : max_pr:  : 1
I0325 01:38:47.291895 29022 solver.cpp:786] class AP 3: 0.596622
I0325 01:38:47.291915 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.50092
I0325 01:38:47.292822 29022 solver.cpp:265] Tests completed in 83.1101s
I0325 01:38:47.843297 29022 solver.cpp:314] Iteration 8000 (0.286336 iter/s, 349.24s/100 iter), loss = 3.0469
I0325 01:38:47.843385 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.18302 (* 1 = 3.18302 loss)
I0325 01:38:47.843420 29022 sgd_solver.cpp:136] Iteration 8000, lr = 0.000564168, m = 0.9
I0325 01:40:03.783419 29022 solver.cpp:314] Iteration 8100 (1.31687 iter/s, 75.9377s/100 iter), loss = 3.28893
I0325 01:40:03.783605 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.10285 (* 1 = 3.10285 loss)
I0325 01:40:03.783640 29022 sgd_solver.cpp:136] Iteration 8100, lr = 0.000559841, m = 0.9
I0325 01:41:20.426517 29022 solver.cpp:314] Iteration 8200 (1.30479 iter/s, 76.6406s/100 iter), loss = 3.27711
I0325 01:41:20.426724 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.4382 (* 1 = 3.4382 loss)
I0325 01:41:20.426750 29022 sgd_solver.cpp:136] Iteration 8200, lr = 0.000555538, m = 0.9
I0325 01:42:35.948976 29022 solver.cpp:314] Iteration 8300 (1.32415 iter/s, 75.52s/100 iter), loss = 3.19672
I0325 01:42:35.949241 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.26633 (* 1 = 3.26633 loss)
I0325 01:42:35.949306 29022 sgd_solver.cpp:136] Iteration 8300, lr = 0.000551261, m = 0.9
I0325 01:43:52.791327 29022 solver.cpp:314] Iteration 8400 (1.30141 iter/s, 76.8399s/100 iter), loss = 3.08568
I0325 01:43:52.791877 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.32144 (* 1 = 2.32144 loss)
I0325 01:43:52.792245 29022 sgd_solver.cpp:136] Iteration 8400, lr = 0.000547008, m = 0.9
I0325 01:45:09.145920 29022 solver.cpp:314] Iteration 8500 (1.30972 iter/s, 76.3522s/100 iter), loss = 2.93015
I0325 01:45:09.146046 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.77927 (* 1 = 2.77927 loss)
I0325 01:45:09.146081 29022 sgd_solver.cpp:136] Iteration 8500, lr = 0.00054278, m = 0.9
I0325 01:46:26.721782 29022 solver.cpp:314] Iteration 8600 (1.2891 iter/s, 77.5734s/100 iter), loss = 3.13367
I0325 01:46:26.721875 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.89933 (* 1 = 2.89933 loss)
I0325 01:46:26.721889 29022 sgd_solver.cpp:136] Iteration 8600, lr = 0.000538577, m = 0.9
I0325 01:47:44.087612 29022 solver.cpp:314] Iteration 8700 (1.2926 iter/s, 77.3634s/100 iter), loss = 3.13368
I0325 01:47:44.087754 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.82266 (* 1 = 2.82266 loss)
I0325 01:47:44.087786 29022 sgd_solver.cpp:136] Iteration 8700, lr = 0.000534398, m = 0.9
I0325 01:49:01.007848 29022 solver.cpp:314] Iteration 8800 (1.30009 iter/s, 76.9178s/100 iter), loss = 3.21269
I0325 01:49:01.007987 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.78303 (* 1 = 3.78303 loss)
I0325 01:49:01.008020 29022 sgd_solver.cpp:136] Iteration 8800, lr = 0.000530243, m = 0.9
I0325 01:50:18.486757 29022 solver.cpp:314] Iteration 8900 (1.29071 iter/s, 77.4765s/100 iter), loss = 3.16724
I0325 01:50:18.486912 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.76237 (* 1 = 2.76237 loss)
I0325 01:50:18.486950 29022 sgd_solver.cpp:136] Iteration 8900, lr = 0.000526113, m = 0.9
I0325 01:51:34.488554 29022 solver.cpp:314] Iteration 9000 (1.3158 iter/s, 75.9994s/100 iter), loss = 3.04885
I0325 01:51:34.488687 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.26254 (* 1 = 2.26254 loss)
I0325 01:51:34.488703 29022 sgd_solver.cpp:136] Iteration 9000, lr = 0.000522006, m = 0.9
I0325 01:51:58.769989 29042 data_reader.cpp:305] Starting prefetch of epoch 2
I0325 01:52:51.774215 29022 solver.cpp:314] Iteration 9100 (1.29394 iter/s, 77.2832s/100 iter), loss = 3.31586
I0325 01:52:51.774348 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.88059 (* 1 = 2.88059 loss)
I0325 01:52:51.774384 29022 sgd_solver.cpp:136] Iteration 9100, lr = 0.000517924, m = 0.9
I0325 01:54:08.606698 29022 solver.cpp:314] Iteration 9200 (1.30157 iter/s, 76.8301s/100 iter), loss = 3.16592
I0325 01:54:08.606801 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.97806 (* 1 = 2.97806 loss)
I0325 01:54:08.606817 29022 sgd_solver.cpp:136] Iteration 9200, lr = 0.000513866, m = 0.9
I0325 01:55:25.343505 29022 solver.cpp:314] Iteration 9300 (1.3032 iter/s, 76.7344s/100 iter), loss = 3.13595
I0325 01:55:25.343642 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.603 (* 1 = 2.603 loss)
I0325 01:55:25.343677 29022 sgd_solver.cpp:136] Iteration 9300, lr = 0.000509832, m = 0.9
I0325 01:56:41.442965 29022 solver.cpp:314] Iteration 9400 (1.31411 iter/s, 76.0971s/100 iter), loss = 3.07107
I0325 01:56:41.443120 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.00498 (* 1 = 3.00498 loss)
I0325 01:56:41.443153 29022 sgd_solver.cpp:136] Iteration 9400, lr = 0.000505821, m = 0.9
I0325 01:57:56.968629 29022 solver.cpp:314] Iteration 9500 (1.32409 iter/s, 75.5233s/100 iter), loss = 3.19117
I0325 01:57:56.968802 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.57418 (* 1 = 2.57418 loss)
I0325 01:57:56.968837 29022 sgd_solver.cpp:136] Iteration 9500, lr = 0.000501835, m = 0.9
I0325 01:59:13.718065 29022 solver.cpp:314] Iteration 9600 (1.30298 iter/s, 76.747s/100 iter), loss = 3.17699
I0325 01:59:13.718201 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.08055 (* 1 = 4.08055 loss)
I0325 01:59:13.718237 29022 sgd_solver.cpp:136] Iteration 9600, lr = 0.000497871, m = 0.9
I0325 02:00:31.215596 29022 solver.cpp:314] Iteration 9700 (1.2904 iter/s, 77.4951s/100 iter), loss = 3.28297
I0325 02:00:31.215826 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.41949 (* 1 = 3.41949 loss)
I0325 02:00:31.215843 29022 sgd_solver.cpp:136] Iteration 9700, lr = 0.000493932, m = 0.9
I0325 02:01:49.368078 29022 solver.cpp:314] Iteration 9800 (1.27959 iter/s, 78.15s/100 iter), loss = 3.01656
I0325 02:01:49.368222 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.11071 (* 1 = 3.11071 loss)
I0325 02:01:49.368257 29022 sgd_solver.cpp:136] Iteration 9800, lr = 0.000490016, m = 0.9
I0325 02:03:05.583278 29022 solver.cpp:314] Iteration 9900 (1.31212 iter/s, 76.2128s/100 iter), loss = 3.31906
I0325 02:03:05.583498 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.31533 (* 1 = 3.31533 loss)
I0325 02:03:05.583521 29022 sgd_solver.cpp:136] Iteration 9900, lr = 0.000486123, m = 0.9
I0325 02:04:22.481683 29022 solver.cpp:443] Finding and applying sparsity: sparsity_target=0.7 sparsity_factor=0.7 sparsity_achieved=0.488393 iter=10000
W0325 02:04:22.481801 29022 net.cpp:2074] conv1a ni=3 no=32
I0325 02:04:22.772513 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:22.772549 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:22.772560 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.239262
I0325 02:04:22.772568 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:04:22.865142 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:22.865182 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:22.865193 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.218308
I0325 02:04:22.865202 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:04:23.211752 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:23.211791 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:23.211802 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.235549
I0325 02:04:23.211809 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:04:23.513402 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:23.513438 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:23.513453 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.291566
I0325 02:04:23.513461 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:04:23.610532 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:23.610564 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:23.610579 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.250275
I0325 02:04:23.610587 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:04:23.720769 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:23.720818 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:23.720834 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.275296
I0325 02:04:23.720841 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:04:24.035219 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:24.035255 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:24.035269 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.354598
I0325 02:04:24.035279 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:04:24.277868 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:24.277911 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:24.277926 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.328982
I0325 02:04:24.277935 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:04:24.714908 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:24.714944 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:24.714959 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.251195
I0325 02:04:24.714968 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:04:24.878475 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:24.878506 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:24.878516 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.222508
I0325 02:04:24.878522 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:04:24.960546 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:24.960562 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:24.960568 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.240826
I0325 02:04:24.960577 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:04:25.014981 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:25.014995 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:25.015002 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.225332
I0325 02:04:25.015010 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:04:25.102627 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:25.102644 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:25.102651 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.219514
I0325 02:04:25.102656 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:04:25.206831 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:25.206858 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:25.206866 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.233937
I0325 02:04:25.206898 29022 net.cpp:2104] final threshold_value used0.2
W0325 02:04:25.240206 29022 net.cpp:2135] conv1a ZeroWeightsFraction=0.345
W0325 02:04:25.240319 29022 net.cpp:2074] conv1b ni=32 no=32
I0325 02:04:25.947933 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:25.947965 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:25.947973 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.222623
I0325 02:04:25.947981 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:04:26.213922 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:26.213938 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:26.213944 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.209587
I0325 02:04:26.213949 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:04:26.325884 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:26.325901 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:26.325906 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.21307
I0325 02:04:26.325914 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:04:26.731148 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:26.731163 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:26.731169 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.220897
I0325 02:04:26.731178 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:04:27.511600 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:27.511627 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:27.511634 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.246491
I0325 02:04:27.511642 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:04:27.702916 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:27.702950 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:27.702957 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.255618
I0325 02:04:27.702963 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:04:27.773891 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:27.773923 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:27.773931 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.234891
I0325 02:04:27.773936 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:04:28.200109 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:28.200141 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:28.200148 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.262005
I0325 02:04:28.200156 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:04:28.307685 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:28.307700 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:28.307709 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.224152
I0325 02:04:28.307715 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:04:28.432809 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:28.432824 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:28.432831 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.225453
I0325 02:04:28.432839 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:04:28.557503 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:28.557519 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:28.557525 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.207098
I0325 02:04:28.557534 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:04:28.832267 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:28.832284 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:28.832290 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.240552
I0325 02:04:28.832298 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:04:28.921409 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:28.921424 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:28.921430 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.209204
I0325 02:04:28.921455 29022 net.cpp:2104] final threshold_value used0.2
W0325 02:04:29.183531 29022 net.cpp:2135] conv1b ZeroWeightsFraction=0.654514
W0325 02:04:29.183663 29022 net.cpp:2074] res2a_branch2a ni=32 no=64
I0325 02:04:32.886096 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:32.886132 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:32.886138 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.211135
I0325 02:04:32.886144 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:04:33.677558 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:33.677587 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:33.677593 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.201909
I0325 02:04:33.677603 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:04:34.398080 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:04:34.398097 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:04:34.398102 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.205632
I0325 02:04:34.398110 29022 net.cpp:2104] final threshold_value used0.2
W0325 02:04:36.908294 29022 net.cpp:2135] res2a_branch2a ZeroWeightsFraction=0.673557
W0325 02:04:36.908423 29022 net.cpp:2074] res2a_branch2b ni=64 no=64
W0325 02:04:45.866696 29022 net.cpp:2135] res2a_branch2b ZeroWeightsFraction=0.563802
W0325 02:04:45.866871 29022 net.cpp:2074] res3a_branch2a ni=64 no=128
W0325 02:05:02.667419 29022 net.cpp:2135] res3a_branch2a ZeroWeightsFraction=0.644938
W0325 02:05:02.667487 29022 net.cpp:2074] res3a_branch2b ni=128 no=128
W0325 02:05:20.225553 29022 net.cpp:2135] res3a_branch2b ZeroWeightsFraction=0.627658
W0325 02:05:20.225766 29022 net.cpp:2074] res4a_branch2a ni=128 no=256
W0325 02:05:54.089681 29022 net.cpp:2135] res4a_branch2a ZeroWeightsFraction=0.692193
W0325 02:05:54.090009 29022 net.cpp:2074] res4a_branch2b ni=256 no=256
W0325 02:06:27.183023 29022 net.cpp:2135] res4a_branch2b ZeroWeightsFraction=0.66394
W0325 02:06:27.183292 29022 net.cpp:2074] res5a_branch2a ni=256 no=512
W0325 02:07:15.692077 29022 net.cpp:2135] res5a_branch2a ZeroWeightsFraction=0.695604
W0325 02:07:15.692347 29022 net.cpp:2074] res5a_branch2b ni=512 no=512
W0325 02:07:58.304489 29022 net.cpp:2135] res5a_branch2b ZeroWeightsFraction=0.699626
W0325 02:07:58.304730 29022 net.cpp:2074] ctx_output1 ni=128 no=256
W0325 02:07:58.304764 29022 net.cpp:2074] ctx_output2 ni=512 no=256
W0325 02:07:58.304785 29022 net.cpp:2074] ctx_output3 ni=512 no=256
W0325 02:07:58.304812 29022 net.cpp:2074] ctx_output4 ni=512 no=256
W0325 02:07:58.304833 29022 net.cpp:2074] ctx_output5 ni=512 no=256
W0325 02:07:58.304854 29022 net.cpp:2074] ctx_output6 ni=512 no=256
W0325 02:07:58.304874 29022 net.cpp:2074] ctx_output1/relu_mbox_loc ni=256 no=16
W0325 02:07:58.304894 29022 net.cpp:2074] ctx_output1/relu_mbox_conf ni=256 no=16
W0325 02:07:58.304914 29022 net.cpp:2074] ctx_output2/relu_mbox_loc ni=256 no=24
W0325 02:07:58.304926 29022 net.cpp:2074] ctx_output2/relu_mbox_conf ni=256 no=24
W0325 02:07:58.304937 29022 net.cpp:2074] ctx_output3/relu_mbox_loc ni=256 no=24
W0325 02:07:58.304947 29022 net.cpp:2074] ctx_output3/relu_mbox_conf ni=256 no=24
W0325 02:07:58.304957 29022 net.cpp:2074] ctx_output4/relu_mbox_loc ni=256 no=24
W0325 02:07:58.304967 29022 net.cpp:2074] ctx_output4/relu_mbox_conf ni=256 no=24
W0325 02:07:58.304978 29022 net.cpp:2074] ctx_output5/relu_mbox_loc ni=256 no=16
W0325 02:07:58.304988 29022 net.cpp:2074] ctx_output5/relu_mbox_conf ni=256 no=16
W0325 02:07:58.304998 29022 net.cpp:2074] ctx_output6/relu_mbox_loc ni=256 no=16
W0325 02:07:58.305011 29022 net.cpp:2074] ctx_output6/relu_mbox_conf ni=256 no=16
I0325 02:07:58.305027 29022 net.cpp:2169] All zero weights of convolution layers are frozen
I0325 02:07:58.310320 29022 solver.cpp:360] Sparsity after update:
I0325 02:07:58.312649 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 02:07:58.312664 29022 net.cpp:2200] conv1a_param_0(0.345) 
I0325 02:07:58.312675 29022 net.cpp:2200] conv1b_param_0(0.655) 
I0325 02:07:58.312690 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 02:07:58.312701 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 02:07:58.312707 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 02:07:58.312712 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 02:07:58.312718 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 02:07:58.312723 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 02:07:58.312728 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 02:07:58.312734 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 02:07:58.312739 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 02:07:58.312744 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 02:07:58.312749 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 02:07:58.312755 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 02:07:58.312760 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 02:07:58.312765 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 02:07:58.312772 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 02:07:58.312777 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 02:07:58.312783 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 02:07:58.312789 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 02:07:58.312794 29022 net.cpp:2200] res2a_branch2a_param_0(0.674) 
I0325 02:07:58.312799 29022 net.cpp:2200] res2a_branch2b_param_0(0.564) 
I0325 02:07:58.312805 29022 net.cpp:2200] res3a_branch2a_param_0(0.645) 
I0325 02:07:58.312810 29022 net.cpp:2200] res3a_branch2b_param_0(0.628) 
I0325 02:07:58.312816 29022 net.cpp:2200] res4a_branch2a_param_0(0.692) 
I0325 02:07:58.312821 29022 net.cpp:2200] res4a_branch2b_param_0(0.664) 
I0325 02:07:58.312826 29022 net.cpp:2200] res5a_branch2a_param_0(0.696) 
I0325 02:07:58.312831 29022 net.cpp:2200] res5a_branch2b_param_0(0.7) 
I0325 02:07:58.312837 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.6259e+06/3.10435e+06) 0.524
I0325 02:07:58.312855 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_10000.caffemodel
I0325 02:07:58.350828 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_10000.solverstate
I0325 02:07:58.359385 29022 solver.cpp:678] Iteration 10000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0
j:  : 4 : max_pr:  : 0.301296
j:  : 3 : max_pr:  : 0.543028
j:  : 2 : max_pr:  : 0.68355
j:  : 1 : max_pr:  : 0.820014
j:  : 0 : max_pr:  : 1
I0325 02:09:21.226114 29022 solver.cpp:786] class AP 1: 0.304353
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.044212
j:  : 7 : max_pr:  : 0.179756
j:  : 6 : max_pr:  : 0.364854
j:  : 5 : max_pr:  : 0.550967
j:  : 4 : max_pr:  : 0.695366
j:  : 3 : max_pr:  : 0.799057
j:  : 2 : max_pr:  : 0.842157
j:  : 1 : max_pr:  : 0.997116
j:  : 0 : max_pr:  : 1
I0325 02:09:21.332706 29022 solver.cpp:786] class AP 2: 0.497589
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.33861
j:  : 6 : max_pr:  : 0.542423
j:  : 5 : max_pr:  : 0.658369
j:  : 4 : max_pr:  : 0.771752
j:  : 3 : max_pr:  : 0.860828
j:  : 2 : max_pr:  : 0.954638
j:  : 1 : max_pr:  : 0.998705
j:  : 0 : max_pr:  : 1
I0325 02:09:21.354598 29022 solver.cpp:786] class AP 3: 0.556848
I0325 02:09:21.354612 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.45293
I0325 02:09:21.354656 29022 solver.cpp:265] Tests completed in 82.9926s
I0325 02:09:21.929287 29022 solver.cpp:314] Iteration 10000 (0.265721 iter/s, 376.334s/100 iter), loss = 3.09353
I0325 02:09:21.929384 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.72992 (* 1 = 3.72992 loss)
I0325 02:09:21.929416 29022 sgd_solver.cpp:136] Iteration 10000, lr = 0.000482253, m = 0.9
I0325 02:10:38.043579 29022 solver.cpp:314] Iteration 10100 (1.31386 iter/s, 76.1119s/100 iter), loss = 3.31293
I0325 02:10:38.043671 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.0504 (* 1 = 3.0504 loss)
I0325 02:10:38.043682 29022 sgd_solver.cpp:136] Iteration 10100, lr = 0.000478407, m = 0.9
I0325 02:11:55.284735 29022 solver.cpp:314] Iteration 10200 (1.29469 iter/s, 77.2387s/100 iter), loss = 3.17571
I0325 02:11:55.284844 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.47934 (* 1 = 3.47934 loss)
I0325 02:11:55.284862 29022 sgd_solver.cpp:136] Iteration 10200, lr = 0.000474583, m = 0.9
I0325 02:13:11.516649 29022 solver.cpp:314] Iteration 10300 (1.31183 iter/s, 76.2295s/100 iter), loss = 3.0517
I0325 02:13:11.516774 29022 solver.cpp:336]     Train net output #0: mbox_loss = 1.90956 (* 1 = 1.90956 loss)
I0325 02:13:11.516808 29022 sgd_solver.cpp:136] Iteration 10300, lr = 0.000470783, m = 0.9
I0325 02:14:28.448372 29022 solver.cpp:314] Iteration 10400 (1.2999 iter/s, 76.9293s/100 iter), loss = 3.19823
I0325 02:14:28.448494 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.84805 (* 1 = 3.84805 loss)
I0325 02:14:28.448513 29022 sgd_solver.cpp:136] Iteration 10400, lr = 0.000467005, m = 0.9
I0325 02:15:45.482658 29022 solver.cpp:314] Iteration 10500 (1.29816 iter/s, 77.0319s/100 iter), loss = 3.17296
I0325 02:15:45.482798 29022 solver.cpp:336]     Train net output #0: mbox_loss = 1.70744 (* 1 = 1.70744 loss)
I0325 02:15:45.482832 29022 sgd_solver.cpp:136] Iteration 10500, lr = 0.00046325, m = 0.9
I0325 02:17:02.218003 29022 solver.cpp:314] Iteration 10600 (1.30322 iter/s, 76.733s/100 iter), loss = 3.3103
I0325 02:17:02.218160 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.44832 (* 1 = 2.44832 loss)
I0325 02:17:02.218195 29022 sgd_solver.cpp:136] Iteration 10600, lr = 0.000459518, m = 0.9
I0325 02:18:18.782940 29022 solver.cpp:314] Iteration 10700 (1.30612 iter/s, 76.5626s/100 iter), loss = 3.10199
I0325 02:18:18.783037 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.96141 (* 1 = 3.96141 loss)
I0325 02:18:18.783056 29022 sgd_solver.cpp:136] Iteration 10700, lr = 0.000455809, m = 0.9
I0325 02:19:36.714859 29022 solver.cpp:314] Iteration 10800 (1.28321 iter/s, 77.9295s/100 iter), loss = 3.19983
I0325 02:19:36.714993 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.72832 (* 1 = 2.72832 loss)
I0325 02:19:36.715029 29022 sgd_solver.cpp:136] Iteration 10800, lr = 0.000452122, m = 0.9
I0325 02:20:55.106987 29022 solver.cpp:314] Iteration 10900 (1.27568 iter/s, 78.3897s/100 iter), loss = 3.27343
I0325 02:20:55.109815 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.12003 (* 1 = 4.12003 loss)
I0325 02:20:55.109856 29022 sgd_solver.cpp:136] Iteration 10900, lr = 0.000448457, m = 0.9
I0325 02:22:11.754101 29022 solver.cpp:314] Iteration 11000 (1.30472 iter/s, 76.6447s/100 iter), loss = 3.05214
I0325 02:22:11.754298 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.87388 (* 1 = 2.87388 loss)
I0325 02:22:11.754317 29022 sgd_solver.cpp:136] Iteration 11000, lr = 0.000444815, m = 0.9
I0325 02:23:28.766911 29022 solver.cpp:314] Iteration 11100 (1.29853 iter/s, 77.0104s/100 iter), loss = 3.10328
I0325 02:23:28.767068 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.42304 (* 1 = 3.42304 loss)
I0325 02:23:28.767107 29022 sgd_solver.cpp:136] Iteration 11100, lr = 0.000441195, m = 0.9
I0325 02:24:46.104135 29022 solver.cpp:314] Iteration 11200 (1.29308 iter/s, 77.3348s/100 iter), loss = 3.15257
I0325 02:24:46.104578 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.53567 (* 1 = 2.53567 loss)
I0325 02:24:46.104892 29022 sgd_solver.cpp:136] Iteration 11200, lr = 0.000437597, m = 0.9
I0325 02:26:02.672777 29022 solver.cpp:314] Iteration 11300 (1.30606 iter/s, 76.5663s/100 iter), loss = 3.048
I0325 02:26:02.672878 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.09869 (* 1 = 3.09869 loss)
I0325 02:26:02.672895 29022 sgd_solver.cpp:136] Iteration 11300, lr = 0.000434021, m = 0.9
I0325 02:27:20.101833 29022 solver.cpp:314] Iteration 11400 (1.29154 iter/s, 77.4267s/100 iter), loss = 3.19317
I0325 02:27:20.101933 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.30132 (* 1 = 3.30132 loss)
I0325 02:27:20.101949 29022 sgd_solver.cpp:136] Iteration 11400, lr = 0.000430467, m = 0.9
I0325 02:28:36.691543 29022 solver.cpp:314] Iteration 11500 (1.3057 iter/s, 76.5873s/100 iter), loss = 3.01741
I0325 02:28:36.691681 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.39635 (* 1 = 2.39635 loss)
I0325 02:28:36.691717 29022 sgd_solver.cpp:136] Iteration 11500, lr = 0.000426935, m = 0.9
I0325 02:29:52.247159 29022 solver.cpp:314] Iteration 11600 (1.32357 iter/s, 75.5533s/100 iter), loss = 3.13915
I0325 02:29:52.247334 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.64002 (* 1 = 2.64002 loss)
I0325 02:29:52.247370 29022 sgd_solver.cpp:136] Iteration 11600, lr = 0.000423425, m = 0.9
I0325 02:31:08.882699 29022 solver.cpp:314] Iteration 11700 (1.30492 iter/s, 76.6331s/100 iter), loss = 2.98564
I0325 02:31:08.882832 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.97407 (* 1 = 2.97407 loss)
I0325 02:31:08.882867 29022 sgd_solver.cpp:136] Iteration 11700, lr = 0.000419936, m = 0.9
I0325 02:32:26.307036 29022 solver.cpp:314] Iteration 11800 (1.29162 iter/s, 77.4219s/100 iter), loss = 3.05971
I0325 02:32:26.307178 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.38631 (* 1 = 4.38631 loss)
I0325 02:32:26.307211 29022 sgd_solver.cpp:136] Iteration 11800, lr = 0.000416469, m = 0.9
I0325 02:33:43.424571 29022 solver.cpp:314] Iteration 11900 (1.29676 iter/s, 77.1151s/100 iter), loss = 3.12518
I0325 02:33:43.424674 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.05927 (* 1 = 3.05927 loss)
I0325 02:33:43.424690 29022 sgd_solver.cpp:136] Iteration 11900, lr = 0.000413024, m = 0.9
I0325 02:34:58.581095 29022 solver.cpp:443] Finding and applying sparsity: sparsity_target=0.7 sparsity_factor=0.75 sparsity_achieved=0.523748 iter=12000
W0325 02:34:58.581225 29022 net.cpp:2074] conv1a ni=3 no=32
I0325 02:34:58.874709 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:34:58.874794 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:34:58.874826 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.239412
I0325 02:34:58.874857 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:34:58.979718 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:34:58.979859 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:34:58.979873 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.219109
I0325 02:34:58.979882 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:34:59.276739 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:34:59.276773 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:34:59.276780 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.234691
I0325 02:34:59.276787 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:34:59.576473 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:34:59.576519 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:34:59.576529 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.29186
I0325 02:34:59.576537 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:34:59.679113 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:34:59.679152 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:34:59.679163 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.25145
I0325 02:34:59.679172 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:34:59.796003 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:34:59.796041 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:34:59.796051 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.275991
I0325 02:34:59.796059 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:35:00.128424 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:35:00.128479 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:35:00.128490 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.355318
I0325 02:35:00.128499 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:35:00.360143 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:35:00.360179 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:35:00.360193 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.328726
I0325 02:35:00.360203 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:35:00.680230 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:35:00.680258 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:35:00.680269 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.251574
I0325 02:35:00.680274 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:35:00.791883 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:35:00.791899 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:35:00.791905 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.221941
I0325 02:35:00.791914 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:35:00.885310 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:35:00.885326 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:35:00.885332 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.240842
I0325 02:35:00.885341 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:35:00.941071 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:35:00.941085 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:35:00.941094 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.225904
I0325 02:35:00.941100 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:35:01.037768 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:35:01.037784 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:35:01.037791 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.219363
I0325 02:35:01.037799 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:35:01.145957 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:35:01.145985 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:35:01.145992 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.233846
I0325 02:35:01.146023 29022 net.cpp:2104] final threshold_value used0.2
W0325 02:35:01.180018 29022 net.cpp:2135] conv1a ZeroWeightsFraction=0.371667
W0325 02:35:01.180152 29022 net.cpp:2074] conv1b ni=32 no=32
I0325 02:35:01.909802 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:35:01.909837 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:35:01.909844 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.221374
I0325 02:35:01.909850 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:35:02.155985 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:35:02.156002 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:35:02.156008 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.209392
I0325 02:35:02.156016 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:35:02.275969 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:35:02.275985 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:35:02.275991 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.215447
I0325 02:35:02.276000 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:35:02.654943 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:35:02.654958 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:35:02.654965 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.220219
I0325 02:35:02.654973 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:35:03.415788 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:35:03.415817 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:35:03.415823 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.246258
I0325 02:35:03.415832 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:35:03.623898 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:35:03.623914 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:35:03.623920 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.256798
I0325 02:35:03.623929 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:35:03.735906 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:35:03.735952 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:35:03.735960 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.235145
I0325 02:35:03.735965 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:35:04.200172 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:35:04.200201 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:35:04.200208 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.263493
I0325 02:35:04.200213 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:35:04.300590 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:35:04.300622 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:35:04.300628 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.22504
I0325 02:35:04.300637 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:35:04.416041 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:35:04.416057 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:35:04.416064 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.225147
I0325 02:35:04.416072 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:35:04.532166 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:35:04.532188 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:35:04.532196 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.207534
I0325 02:35:04.532202 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:35:04.785825 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:35:04.785841 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:35:04.785847 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.24108
I0325 02:35:04.785856 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:35:04.885277 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:35:04.885293 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:35:04.885298 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.208146
I0325 02:35:04.885323 29022 net.cpp:2104] final threshold_value used0.2
W0325 02:35:05.139344 29022 net.cpp:2135] conv1b ZeroWeightsFraction=0.674045
W0325 02:35:05.139473 29022 net.cpp:2074] res2a_branch2a ni=32 no=64
I0325 02:35:08.850621 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:35:08.850654 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:35:08.850661 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.211174
I0325 02:35:08.850666 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:35:09.640606 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:35:09.640635 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:35:09.640641 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.201819
I0325 02:35:09.640650 29022 net.cpp:2104] final threshold_value used0.2
I0325 02:35:10.368556 29022 net.cpp:2101] threshold_value_max 0.2
I0325 02:35:10.368573 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 02:35:10.368579 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.2056
I0325 02:35:10.368588 29022 net.cpp:2104] final threshold_value used0.2
W0325 02:35:12.814551 29022 net.cpp:2135] res2a_branch2a ZeroWeightsFraction=0.70421
W0325 02:35:12.814685 29022 net.cpp:2074] res2a_branch2b ni=64 no=64
W0325 02:35:21.144939 29022 net.cpp:2135] res2a_branch2b ZeroWeightsFraction=0.567491
W0325 02:35:21.145056 29022 net.cpp:2074] res3a_branch2a ni=64 no=128
W0325 02:35:37.049899 29022 net.cpp:2135] res3a_branch2a ZeroWeightsFraction=0.662218
W0325 02:35:37.050184 29022 net.cpp:2074] res3a_branch2b ni=128 no=128
W0325 02:35:53.378341 29022 net.cpp:2135] res3a_branch2b ZeroWeightsFraction=0.640761
W0325 02:35:53.378576 29022 net.cpp:2074] res4a_branch2a ni=128 no=256
W0325 02:36:27.552160 29022 net.cpp:2135] res4a_branch2a ZeroWeightsFraction=0.728455
W0325 02:36:27.552364 29022 net.cpp:2074] res4a_branch2b ni=256 no=256
W0325 02:36:58.984251 29022 net.cpp:2135] res4a_branch2b ZeroWeightsFraction=0.689182
W0325 02:36:58.984504 29022 net.cpp:2074] res5a_branch2a ni=256 no=512
W0325 02:37:48.932045 29022 net.cpp:2135] res5a_branch2a ZeroWeightsFraction=0.744605
W0325 02:37:48.932293 29022 net.cpp:2074] res5a_branch2b ni=512 no=512
W0325 02:38:35.926160 29022 net.cpp:2135] res5a_branch2b ZeroWeightsFraction=0.749417
W0325 02:38:35.926421 29022 net.cpp:2074] ctx_output1 ni=128 no=256
W0325 02:38:35.926455 29022 net.cpp:2074] ctx_output2 ni=512 no=256
W0325 02:38:35.926476 29022 net.cpp:2074] ctx_output3 ni=512 no=256
W0325 02:38:35.926542 29022 net.cpp:2074] ctx_output4 ni=512 no=256
W0325 02:38:35.926566 29022 net.cpp:2074] ctx_output5 ni=512 no=256
W0325 02:38:35.926589 29022 net.cpp:2074] ctx_output6 ni=512 no=256
W0325 02:38:35.926601 29022 net.cpp:2074] ctx_output1/relu_mbox_loc ni=256 no=16
W0325 02:38:35.926614 29022 net.cpp:2074] ctx_output1/relu_mbox_conf ni=256 no=16
W0325 02:38:35.926626 29022 net.cpp:2074] ctx_output2/relu_mbox_loc ni=256 no=24
W0325 02:38:35.926636 29022 net.cpp:2074] ctx_output2/relu_mbox_conf ni=256 no=24
W0325 02:38:35.926647 29022 net.cpp:2074] ctx_output3/relu_mbox_loc ni=256 no=24
W0325 02:38:35.926657 29022 net.cpp:2074] ctx_output3/relu_mbox_conf ni=256 no=24
W0325 02:38:35.926668 29022 net.cpp:2074] ctx_output4/relu_mbox_loc ni=256 no=24
W0325 02:38:35.926678 29022 net.cpp:2074] ctx_output4/relu_mbox_conf ni=256 no=24
W0325 02:38:35.926688 29022 net.cpp:2074] ctx_output5/relu_mbox_loc ni=256 no=16
W0325 02:38:35.926700 29022 net.cpp:2074] ctx_output5/relu_mbox_conf ni=256 no=16
W0325 02:38:35.926712 29022 net.cpp:2074] ctx_output6/relu_mbox_loc ni=256 no=16
W0325 02:38:35.926723 29022 net.cpp:2074] ctx_output6/relu_mbox_conf ni=256 no=16
I0325 02:38:35.926734 29022 net.cpp:2169] All zero weights of convolution layers are frozen
I0325 02:38:35.931993 29022 solver.cpp:360] Sparsity after update:
I0325 02:38:35.934244 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 02:38:35.934257 29022 net.cpp:2200] conv1a_param_0(0.372) 
I0325 02:38:35.934265 29022 net.cpp:2200] conv1b_param_0(0.674) 
I0325 02:38:35.934274 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 02:38:35.934279 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 02:38:35.934285 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 02:38:35.934290 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 02:38:35.934295 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 02:38:35.934301 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 02:38:35.934306 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 02:38:35.934311 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 02:38:35.934317 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 02:38:35.934322 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 02:38:35.934327 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 02:38:35.934332 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 02:38:35.934337 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 02:38:35.934343 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 02:38:35.934351 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 02:38:35.934356 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 02:38:35.934362 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 02:38:35.934367 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 02:38:35.934372 29022 net.cpp:2200] res2a_branch2a_param_0(0.704) 
I0325 02:38:35.934378 29022 net.cpp:2200] res2a_branch2b_param_0(0.567) 
I0325 02:38:35.934383 29022 net.cpp:2200] res3a_branch2a_param_0(0.662) 
I0325 02:38:35.934389 29022 net.cpp:2200] res3a_branch2b_param_0(0.641) 
I0325 02:38:35.934394 29022 net.cpp:2200] res4a_branch2a_param_0(0.728) 
I0325 02:38:35.934399 29022 net.cpp:2200] res4a_branch2b_param_0(0.689) 
I0325 02:38:35.934406 29022 net.cpp:2200] res5a_branch2a_param_0(0.745) 
I0325 02:38:35.934411 29022 net.cpp:2200] res5a_branch2b_param_0(0.749) 
I0325 02:38:35.934415 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.72995e+06/3.10435e+06) 0.557
I0325 02:38:35.934433 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_12000.caffemodel
I0325 02:38:35.953428 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_12000.solverstate
I0325 02:38:35.961525 29022 solver.cpp:678] Iteration 12000, Testing net (#0)
I0325 02:39:57.540484 29077 data_reader.cpp:305] Starting prefetch of epoch 3
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.258492
j:  : 4 : max_pr:  : 0.423656
j:  : 3 : max_pr:  : 0.55458
j:  : 2 : max_pr:  : 0.660983
j:  : 1 : max_pr:  : 0.798823
j:  : 0 : max_pr:  : 1
I0325 02:39:58.945493 29022 solver.cpp:786] class AP 1: 0.336049
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0763752
j:  : 7 : max_pr:  : 0.282786
j:  : 6 : max_pr:  : 0.490994
j:  : 5 : max_pr:  : 0.641498
j:  : 4 : max_pr:  : 0.745431
j:  : 3 : max_pr:  : 0.830838
j:  : 2 : max_pr:  : 0.968984
j:  : 1 : max_pr:  : 0.998325
j:  : 0 : max_pr:  : 1
I0325 02:39:59.033622 29022 solver.cpp:786] class AP 2: 0.548657
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.389909
j:  : 6 : max_pr:  : 0.646937
j:  : 5 : max_pr:  : 0.718352
j:  : 4 : max_pr:  : 0.820825
j:  : 3 : max_pr:  : 0.919478
j:  : 2 : max_pr:  : 0.976938
j:  : 1 : max_pr:  : 0.998617
j:  : 0 : max_pr:  : 1
I0325 02:39:59.056989 29022 solver.cpp:786] class AP 3: 0.588278
I0325 02:39:59.057009 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.490995
I0325 02:39:59.057060 29022 solver.cpp:265] Tests completed in 83.0928s
I0325 02:39:59.611759 29022 solver.cpp:314] Iteration 12000 (0.265834 iter/s, 376.175s/100 iter), loss = 3.06557
I0325 02:39:59.612180 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.81472 (* 1 = 3.81472 loss)
I0325 02:39:59.612481 29022 sgd_solver.cpp:136] Iteration 12000, lr = 0.0004096, m = 0.9
I0325 02:41:14.581445 29022 solver.cpp:314] Iteration 12100 (1.33392 iter/s, 74.9673s/100 iter), loss = 3.08812
I0325 02:41:14.581563 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.35251 (* 1 = 2.35251 loss)
I0325 02:41:14.581580 29022 sgd_solver.cpp:136] Iteration 12100, lr = 0.000406197, m = 0.9
I0325 02:42:32.129474 29022 solver.cpp:314] Iteration 12200 (1.28956 iter/s, 77.5455s/100 iter), loss = 3.30226
I0325 02:42:32.129638 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.31268 (* 1 = 3.31268 loss)
I0325 02:42:32.129657 29022 sgd_solver.cpp:136] Iteration 12200, lr = 0.000402816, m = 0.9
I0325 02:43:47.356158 29022 solver.cpp:314] Iteration 12300 (1.32936 iter/s, 75.2243s/100 iter), loss = 3.18427
I0325 02:43:47.356289 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.63656 (* 1 = 3.63656 loss)
I0325 02:43:47.356323 29022 sgd_solver.cpp:136] Iteration 12300, lr = 0.000399456, m = 0.9
I0325 02:45:05.725041 29022 solver.cpp:314] Iteration 12400 (1.27606 iter/s, 78.3664s/100 iter), loss = 3.17687
I0325 02:45:05.725178 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.60682 (* 1 = 2.60682 loss)
I0325 02:45:05.725211 29022 sgd_solver.cpp:136] Iteration 12400, lr = 0.000396116, m = 0.9
I0325 02:46:22.428324 29022 solver.cpp:314] Iteration 12500 (1.30377 iter/s, 76.7008s/100 iter), loss = 3.26327
I0325 02:46:22.428782 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.43681 (* 1 = 3.43681 loss)
I0325 02:46:22.429100 29022 sgd_solver.cpp:136] Iteration 12500, lr = 0.000392798, m = 0.9
I0325 02:47:38.050195 29022 solver.cpp:314] Iteration 12600 (1.32241 iter/s, 75.6195s/100 iter), loss = 3.05964
I0325 02:47:38.050377 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.42331 (* 1 = 2.42331 loss)
I0325 02:47:38.050393 29022 sgd_solver.cpp:136] Iteration 12600, lr = 0.000389501, m = 0.9
I0325 02:48:56.094797 29022 solver.cpp:314] Iteration 12700 (1.28136 iter/s, 78.0421s/100 iter), loss = 3.2419
I0325 02:48:56.097075 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.79404 (* 1 = 2.79404 loss)
I0325 02:48:56.097095 29022 sgd_solver.cpp:136] Iteration 12700, lr = 0.000386224, m = 0.9
I0325 02:50:13.037252 29022 solver.cpp:314] Iteration 12800 (1.29971 iter/s, 76.94s/100 iter), loss = 3.18884
I0325 02:50:13.037379 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.92833 (* 1 = 2.92833 loss)
I0325 02:50:13.037606 29022 sgd_solver.cpp:136] Iteration 12800, lr = 0.000382968, m = 0.9
I0325 02:51:30.958719 29022 solver.cpp:314] Iteration 12900 (1.28338 iter/s, 77.919s/100 iter), loss = 3.22236
I0325 02:51:30.958853 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.7532 (* 1 = 2.7532 loss)
I0325 02:51:30.958865 29022 sgd_solver.cpp:136] Iteration 12900, lr = 0.000379733, m = 0.9
I0325 02:52:46.926342 29022 solver.cpp:314] Iteration 13000 (1.31639 iter/s, 75.9652s/100 iter), loss = 3.04002
I0325 02:52:46.926445 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.93471 (* 1 = 3.93471 loss)
I0325 02:52:46.926461 29022 sgd_solver.cpp:136] Iteration 13000, lr = 0.000376519, m = 0.9
I0325 02:54:03.848237 29022 solver.cpp:314] Iteration 13100 (1.30006 iter/s, 76.9195s/100 iter), loss = 3.32323
I0325 02:54:03.848700 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.0069 (* 1 = 4.0069 loss)
I0325 02:54:03.849010 29022 sgd_solver.cpp:136] Iteration 13100, lr = 0.000373324, m = 0.9
I0325 02:55:20.032781 29022 solver.cpp:314] Iteration 13200 (1.31264 iter/s, 76.1821s/100 iter), loss = 3.17803
I0325 02:55:20.032929 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.66152 (* 1 = 2.66152 loss)
I0325 02:55:20.032971 29022 sgd_solver.cpp:136] Iteration 13200, lr = 0.000370151, m = 0.9
I0325 02:56:35.541137 29022 solver.cpp:314] Iteration 13300 (1.3244 iter/s, 75.506s/100 iter), loss = 3.22473
I0325 02:56:35.541291 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.57957 (* 1 = 2.57957 loss)
I0325 02:56:35.541308 29022 sgd_solver.cpp:136] Iteration 13300, lr = 0.000366997, m = 0.9
I0325 02:57:52.678731 29022 solver.cpp:314] Iteration 13400 (1.29643 iter/s, 77.1351s/100 iter), loss = 3.31683
I0325 02:57:52.678879 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.45103 (* 1 = 2.45103 loss)
I0325 02:57:52.678921 29022 sgd_solver.cpp:136] Iteration 13400, lr = 0.000363864, m = 0.9
I0325 02:59:08.639974 29022 solver.cpp:314] Iteration 13500 (1.3165 iter/s, 75.9588s/100 iter), loss = 3.01097
I0325 02:59:08.640127 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.191 (* 1 = 3.191 loss)
I0325 02:59:08.640163 29022 sgd_solver.cpp:136] Iteration 13500, lr = 0.00036075, m = 0.9
I0325 03:00:25.164022 29022 solver.cpp:314] Iteration 13600 (1.30682 iter/s, 76.5216s/100 iter), loss = 3.10657
I0325 03:00:25.164180 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.022 (* 1 = 3.022 loss)
I0325 03:00:25.164196 29022 sgd_solver.cpp:136] Iteration 13600, lr = 0.000357657, m = 0.9
I0325 03:01:40.356840 29022 solver.cpp:314] Iteration 13700 (1.32996 iter/s, 75.1904s/100 iter), loss = 3.2429
I0325 03:01:40.356986 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.63377 (* 1 = 2.63377 loss)
I0325 03:01:40.357020 29022 sgd_solver.cpp:136] Iteration 13700, lr = 0.000354584, m = 0.9
I0325 03:02:56.739580 29022 solver.cpp:314] Iteration 13800 (1.30924 iter/s, 76.3803s/100 iter), loss = 3.4261
I0325 03:02:56.743225 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.61723 (* 1 = 2.61723 loss)
I0325 03:02:56.743260 29022 sgd_solver.cpp:136] Iteration 13800, lr = 0.00035153, m = 0.9
I0325 03:04:13.184471 29022 solver.cpp:314] Iteration 13900 (1.30817 iter/s, 76.4424s/100 iter), loss = 3.31748
I0325 03:04:13.184643 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.20303 (* 1 = 3.20303 loss)
I0325 03:04:13.184676 29022 sgd_solver.cpp:136] Iteration 13900, lr = 0.000348497, m = 0.9
I0325 03:05:28.386956 29022 solver.cpp:443] Finding and applying sparsity: sparsity_target=0.7 sparsity_factor=0.8 sparsity_achieved=0.557266 iter=14000
W0325 03:05:28.387068 29022 net.cpp:2074] conv1a ni=3 no=32
I0325 03:05:28.668390 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:28.668426 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:28.668432 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.239259
I0325 03:05:28.668438 29022 net.cpp:2104] final threshold_value used0.2
I0325 03:05:28.821522 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:28.821563 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:28.821573 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.21825
I0325 03:05:28.821583 29022 net.cpp:2104] final threshold_value used0.2
I0325 03:05:29.112376 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:29.112419 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:29.112432 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.234375
I0325 03:05:29.112442 29022 net.cpp:2104] final threshold_value used0.2
I0325 03:05:29.348500 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:29.348547 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:29.348558 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.292863
I0325 03:05:29.348567 29022 net.cpp:2104] final threshold_value used0.2
I0325 03:05:29.428537 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:29.428576 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:29.428587 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.250731
I0325 03:05:29.428597 29022 net.cpp:2104] final threshold_value used0.2
I0325 03:05:29.526662 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:29.526698 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:29.526710 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.27501
I0325 03:05:29.526721 29022 net.cpp:2104] final threshold_value used0.2
I0325 03:05:29.793570 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:29.793604 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:29.793615 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.35417
I0325 03:05:29.793625 29022 net.cpp:2104] final threshold_value used0.2
I0325 03:05:29.910099 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:29.910140 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:29.910151 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.327998
I0325 03:05:29.910161 29022 net.cpp:2104] final threshold_value used0.2
I0325 03:05:30.219549 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:30.219583 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:30.219594 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.251562
I0325 03:05:30.219604 29022 net.cpp:2104] final threshold_value used0.2
I0325 03:05:30.359833 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:30.359869 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:30.359879 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.222236
I0325 03:05:30.359889 29022 net.cpp:2104] final threshold_value used0.2
I0325 03:05:30.463532 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:30.463567 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:30.463578 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.239716
I0325 03:05:30.463589 29022 net.cpp:2104] final threshold_value used0.2
I0325 03:05:30.532553 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:30.532586 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:30.532598 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.224894
I0325 03:05:30.532608 29022 net.cpp:2104] final threshold_value used0.2
I0325 03:05:30.637106 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:30.637140 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:30.637152 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.22059
I0325 03:05:30.637162 29022 net.cpp:2104] final threshold_value used0.2
I0325 03:05:30.749840 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:30.749876 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:30.749886 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.234235
I0325 03:05:30.749925 29022 net.cpp:2104] final threshold_value used0.2
W0325 03:05:30.789419 29022 net.cpp:2135] conv1a ZeroWeightsFraction=0.397083
W0325 03:05:30.789651 29022 net.cpp:2074] conv1b ni=32 no=32
I0325 03:05:31.437029 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:31.437059 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:31.437067 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.22181
I0325 03:05:31.437072 29022 net.cpp:2104] final threshold_value used0.2
I0325 03:05:31.684572 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:31.684589 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:31.684595 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.209454
I0325 03:05:31.684603 29022 net.cpp:2104] final threshold_value used0.2
I0325 03:05:31.808893 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:31.808909 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:31.808915 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.215529
I0325 03:05:31.808920 29022 net.cpp:2104] final threshold_value used0.2
I0325 03:05:32.189520 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:32.189538 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:32.189544 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.221183
I0325 03:05:32.189553 29022 net.cpp:2104] final threshold_value used0.2
I0325 03:05:32.962371 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:32.962404 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:32.962411 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.246508
I0325 03:05:32.962417 29022 net.cpp:2104] final threshold_value used0.2
I0325 03:05:33.203204 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:33.203239 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:33.203248 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.256893
I0325 03:05:33.203255 29022 net.cpp:2104] final threshold_value used0.2
I0325 03:05:33.284409 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:33.284425 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:33.284430 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.23547
I0325 03:05:33.284440 29022 net.cpp:2104] final threshold_value used0.2
I0325 03:05:33.740049 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:33.740067 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:33.740072 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.263046
I0325 03:05:33.740082 29022 net.cpp:2104] final threshold_value used0.2
I0325 03:05:33.840167 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:33.840183 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:33.840188 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.223669
I0325 03:05:33.840194 29022 net.cpp:2104] final threshold_value used0.2
I0325 03:05:33.956254 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:33.956269 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:33.956275 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.224189
I0325 03:05:33.956284 29022 net.cpp:2104] final threshold_value used0.2
I0325 03:05:34.071900 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:34.071916 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:34.071923 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.207789
I0325 03:05:34.071931 29022 net.cpp:2104] final threshold_value used0.2
I0325 03:05:34.326117 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:34.326133 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:34.326140 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.240907
I0325 03:05:34.326148 29022 net.cpp:2104] final threshold_value used0.2
I0325 03:05:34.434017 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:34.434032 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:34.434038 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.207341
I0325 03:05:34.434062 29022 net.cpp:2104] final threshold_value used0.2
W0325 03:05:34.687650 29022 net.cpp:2135] conv1b ZeroWeightsFraction=0.679688
W0325 03:05:34.687788 29022 net.cpp:2074] res2a_branch2a ni=32 no=64
I0325 03:05:38.591327 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:38.591357 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:38.591364 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.210859
I0325 03:05:38.591373 29022 net.cpp:2104] final threshold_value used0.2
I0325 03:05:39.438180 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:39.438210 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:39.438216 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.201787
I0325 03:05:39.438225 29022 net.cpp:2104] final threshold_value used0.2
I0325 03:05:40.194118 29022 net.cpp:2101] threshold_value_max 0.2
I0325 03:05:40.194152 29022 net.cpp:2102] threshold_value_maxratio 0.2
I0325 03:05:40.194159 29022 net.cpp:2103] max_abs_value*threshold_value_maxratio 0.205716
I0325 03:05:40.194165 29022 net.cpp:2104] final threshold_value used0.2
W0325 03:05:42.720396 29022 net.cpp:2135] res2a_branch2a ZeroWeightsFraction=0.723036
W0325 03:05:42.720568 29022 net.cpp:2074] res2a_branch2b ni=64 no=64
W0325 03:05:51.061362 29022 net.cpp:2135] res2a_branch2b ZeroWeightsFraction=0.570964
W0325 03:05:51.061609 29022 net.cpp:2074] res3a_branch2a ni=64 no=128
W0325 03:06:07.432674 29022 net.cpp:2135] res3a_branch2a ZeroWeightsFraction=0.674764
W0325 03:06:07.432906 29022 net.cpp:2074] res3a_branch2b ni=128 no=128
W0325 03:06:23.823015 29022 net.cpp:2135] res3a_branch2b ZeroWeightsFraction=0.647244
W0325 03:06:23.823230 29022 net.cpp:2074] res4a_branch2a ni=128 no=256
W0325 03:06:59.948539 29022 net.cpp:2135] res4a_branch2a ZeroWeightsFraction=0.753733
W0325 03:06:59.948770 29022 net.cpp:2074] res4a_branch2b ni=256 no=256
W0325 03:07:31.857568 29022 net.cpp:2135] res4a_branch2b ZeroWeightsFraction=0.701362
W0325 03:07:31.857818 29022 net.cpp:2074] res5a_branch2a ni=256 no=512
W0325 03:08:36.679971 29022 net.cpp:2135] res5a_branch2a ZeroWeightsFraction=0.785856
W0325 03:08:36.680204 29022 net.cpp:2074] res5a_branch2b ni=512 no=512
W0325 03:09:32.242591 29022 net.cpp:2135] res5a_branch2b ZeroWeightsFraction=0.795802
W0325 03:09:32.242838 29022 net.cpp:2074] ctx_output1 ni=128 no=256
W0325 03:09:32.242874 29022 net.cpp:2074] ctx_output2 ni=512 no=256
W0325 03:09:32.242895 29022 net.cpp:2074] ctx_output3 ni=512 no=256
W0325 03:09:32.242920 29022 net.cpp:2074] ctx_output4 ni=512 no=256
W0325 03:09:32.242941 29022 net.cpp:2074] ctx_output5 ni=512 no=256
W0325 03:09:32.242962 29022 net.cpp:2074] ctx_output6 ni=512 no=256
W0325 03:09:32.242982 29022 net.cpp:2074] ctx_output1/relu_mbox_loc ni=256 no=16
W0325 03:09:32.243002 29022 net.cpp:2074] ctx_output1/relu_mbox_conf ni=256 no=16
W0325 03:09:32.243023 29022 net.cpp:2074] ctx_output2/relu_mbox_loc ni=256 no=24
W0325 03:09:32.243037 29022 net.cpp:2074] ctx_output2/relu_mbox_conf ni=256 no=24
W0325 03:09:32.243048 29022 net.cpp:2074] ctx_output3/relu_mbox_loc ni=256 no=24
W0325 03:09:32.243058 29022 net.cpp:2074] ctx_output3/relu_mbox_conf ni=256 no=24
W0325 03:09:32.243068 29022 net.cpp:2074] ctx_output4/relu_mbox_loc ni=256 no=24
W0325 03:09:32.243078 29022 net.cpp:2074] ctx_output4/relu_mbox_conf ni=256 no=24
W0325 03:09:32.243089 29022 net.cpp:2074] ctx_output5/relu_mbox_loc ni=256 no=16
W0325 03:09:32.243099 29022 net.cpp:2074] ctx_output5/relu_mbox_conf ni=256 no=16
W0325 03:09:32.243109 29022 net.cpp:2074] ctx_output6/relu_mbox_loc ni=256 no=16
W0325 03:09:32.243122 29022 net.cpp:2074] ctx_output6/relu_mbox_conf ni=256 no=16
I0325 03:09:32.243163 29022 net.cpp:2169] All zero weights of convolution layers are frozen
I0325 03:09:32.248435 29022 solver.cpp:360] Sparsity after update:
I0325 03:09:32.250676 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 03:09:32.250689 29022 net.cpp:2200] conv1a_param_0(0.397) 
I0325 03:09:32.250697 29022 net.cpp:2200] conv1b_param_0(0.68) 
I0325 03:09:32.250706 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 03:09:32.250712 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 03:09:32.250717 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 03:09:32.250722 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 03:09:32.250727 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 03:09:32.250733 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 03:09:32.250738 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 03:09:32.250743 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 03:09:32.250749 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 03:09:32.250754 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 03:09:32.250759 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 03:09:32.250764 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 03:09:32.250771 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 03:09:32.250775 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 03:09:32.250780 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 03:09:32.250787 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 03:09:32.250793 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 03:09:32.250798 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 03:09:32.250804 29022 net.cpp:2200] res2a_branch2a_param_0(0.723) 
I0325 03:09:32.250809 29022 net.cpp:2200] res2a_branch2b_param_0(0.571) 
I0325 03:09:32.250815 29022 net.cpp:2200] res3a_branch2a_param_0(0.675) 
I0325 03:09:32.250820 29022 net.cpp:2200] res3a_branch2b_param_0(0.647) 
I0325 03:09:32.250826 29022 net.cpp:2200] res4a_branch2a_param_0(0.754) 
I0325 03:09:32.250831 29022 net.cpp:2200] res4a_branch2b_param_0(0.701) 
I0325 03:09:32.250838 29022 net.cpp:2200] res5a_branch2a_param_0(0.786) 
I0325 03:09:32.250843 29022 net.cpp:2200] res5a_branch2b_param_0(0.796) 
I0325 03:09:32.250849 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.81684e+06/3.10435e+06) 0.585
I0325 03:09:32.250865 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_14000.caffemodel
I0325 03:09:32.269855 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_14000.solverstate
I0325 03:09:32.277875 29022 solver.cpp:678] Iteration 14000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.181296
j:  : 4 : max_pr:  : 0.402824
j:  : 3 : max_pr:  : 0.558766
j:  : 2 : max_pr:  : 0.683426
j:  : 1 : max_pr:  : 0.819084
j:  : 0 : max_pr:  : 1
I0325 03:10:55.154868 29022 solver.cpp:786] class AP 1: 0.3314
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.040547
j:  : 7 : max_pr:  : 0.25196
j:  : 6 : max_pr:  : 0.488613
j:  : 5 : max_pr:  : 0.590515
j:  : 4 : max_pr:  : 0.719162
j:  : 3 : max_pr:  : 0.818412
j:  : 2 : max_pr:  : 0.977016
j:  : 1 : max_pr:  : 0.999412
j:  : 0 : max_pr:  : 1
I0325 03:10:55.262938 29022 solver.cpp:786] class AP 2: 0.535058
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.343936
j:  : 6 : max_pr:  : 0.621408
j:  : 5 : max_pr:  : 0.741793
j:  : 4 : max_pr:  : 0.827368
j:  : 3 : max_pr:  : 0.907089
j:  : 2 : max_pr:  : 0.960778
j:  : 1 : max_pr:  : 0.990486
j:  : 0 : max_pr:  : 1
I0325 03:10:55.280346 29022 solver.cpp:786] class AP 3: 0.581169
I0325 03:10:55.280359 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.482542
I0325 03:10:55.280400 29022 solver.cpp:265] Tests completed in 82.9998s
I0325 03:10:55.838515 29022 solver.cpp:314] Iteration 14000 (0.24836 iter/s, 402.641s/100 iter), loss = 3.18931
I0325 03:10:55.838606 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.47933 (* 1 = 2.47933 loss)
I0325 03:10:55.838640 29022 sgd_solver.cpp:136] Iteration 14000, lr = 0.000345483, m = 0.9
I0325 03:12:11.535755 29022 solver.cpp:314] Iteration 14100 (1.3211 iter/s, 75.6947s/100 iter), loss = 3.15492
I0325 03:12:11.536206 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.91231 (* 1 = 2.91231 loss)
I0325 03:12:11.536509 29022 sgd_solver.cpp:136] Iteration 14100, lr = 0.000342488, m = 0.9
I0325 03:13:28.590042 29022 solver.cpp:314] Iteration 14200 (1.29783 iter/s, 77.0518s/100 iter), loss = 3.22573
I0325 03:13:28.590173 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.71238 (* 1 = 3.71238 loss)
I0325 03:13:28.590191 29022 sgd_solver.cpp:136] Iteration 14200, lr = 0.000339513, m = 0.9
I0325 03:14:43.908190 29022 solver.cpp:314] Iteration 14300 (1.32774 iter/s, 75.3157s/100 iter), loss = 3.22698
I0325 03:14:43.908403 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.39878 (* 1 = 2.39878 loss)
I0325 03:14:43.908422 29022 sgd_solver.cpp:136] Iteration 14300, lr = 0.000336558, m = 0.9
I0325 03:16:00.619004 29022 solver.cpp:314] Iteration 14400 (1.30364 iter/s, 76.7083s/100 iter), loss = 3.19987
I0325 03:16:00.619151 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.20794 (* 1 = 2.20794 loss)
I0325 03:16:00.619186 29022 sgd_solver.cpp:136] Iteration 14400, lr = 0.000333622, m = 0.9
I0325 03:17:17.629847 29022 solver.cpp:314] Iteration 14500 (1.29856 iter/s, 77.0083s/100 iter), loss = 3.12691
I0325 03:17:17.630471 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.17989 (* 1 = 2.17989 loss)
I0325 03:17:17.630838 29022 sgd_solver.cpp:136] Iteration 14500, lr = 0.000330705, m = 0.9
I0325 03:18:34.147284 29022 solver.cpp:314] Iteration 14600 (1.30693 iter/s, 76.515s/100 iter), loss = 3.23901
I0325 03:18:34.147418 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.79178 (* 1 = 2.79178 loss)
I0325 03:18:34.147450 29022 sgd_solver.cpp:136] Iteration 14600, lr = 0.000327807, m = 0.9
I0325 03:19:50.939164 29022 solver.cpp:314] Iteration 14700 (1.30226 iter/s, 76.7894s/100 iter), loss = 3.32916
I0325 03:19:50.939270 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.49699 (* 1 = 3.49699 loss)
I0325 03:19:50.939286 29022 sgd_solver.cpp:136] Iteration 14700, lr = 0.000324929, m = 0.9
I0325 03:21:08.655704 29022 solver.cpp:314] Iteration 14800 (1.28677 iter/s, 77.714s/100 iter), loss = 3.12186
I0325 03:21:08.655966 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.78367 (* 1 = 2.78367 loss)
I0325 03:21:08.655990 29022 sgd_solver.cpp:136] Iteration 14800, lr = 0.000322069, m = 0.9
I0325 03:22:24.961971 29022 solver.cpp:314] Iteration 14900 (1.31055 iter/s, 76.3038s/100 iter), loss = 3.27778
I0325 03:22:24.962168 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.28052 (* 1 = 3.28052 loss)
I0325 03:22:24.962189 29022 sgd_solver.cpp:136] Iteration 14900, lr = 0.000319228, m = 0.9
I0325 03:22:56.332068 29042 data_reader.cpp:305] Starting prefetch of epoch 3
I0325 03:23:41.917510 29022 solver.cpp:314] Iteration 15000 (1.29949 iter/s, 76.9531s/100 iter), loss = 3.23778
I0325 03:23:41.917650 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.01286 (* 1 = 3.01286 loss)
I0325 03:23:41.917685 29022 sgd_solver.cpp:136] Iteration 15000, lr = 0.000316406, m = 0.9
I0325 03:24:57.980216 29022 solver.cpp:314] Iteration 15100 (1.31475 iter/s, 76.0603s/100 iter), loss = 3.11499
I0325 03:24:57.980330 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.23075 (* 1 = 3.23075 loss)
I0325 03:24:57.980346 29022 sgd_solver.cpp:136] Iteration 15100, lr = 0.000313603, m = 0.9
I0325 03:26:14.095458 29022 solver.cpp:314] Iteration 15200 (1.31384 iter/s, 76.1128s/100 iter), loss = 3.18079
I0325 03:26:14.095621 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.90398 (* 1 = 3.90398 loss)
I0325 03:26:14.095641 29022 sgd_solver.cpp:136] Iteration 15200, lr = 0.000310819, m = 0.9
I0325 03:27:28.936744 29022 solver.cpp:314] Iteration 15300 (1.3362 iter/s, 74.8389s/100 iter), loss = 3.31677
I0325 03:27:28.936874 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.79489 (* 1 = 2.79489 loss)
I0325 03:27:28.936908 29022 sgd_solver.cpp:136] Iteration 15300, lr = 0.000308053, m = 0.9
I0325 03:28:44.971354 29022 solver.cpp:314] Iteration 15400 (1.31523 iter/s, 76.0322s/100 iter), loss = 3.04247
I0325 03:28:44.971561 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.51463 (* 1 = 2.51463 loss)
I0325 03:28:44.971580 29022 sgd_solver.cpp:136] Iteration 15400, lr = 0.000305305, m = 0.9
I0325 03:30:01.923032 29022 solver.cpp:314] Iteration 15500 (1.29956 iter/s, 76.9492s/100 iter), loss = 3.22769
I0325 03:30:01.923334 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.3236 (* 1 = 2.3236 loss)
I0325 03:30:01.923398 29022 sgd_solver.cpp:136] Iteration 15500, lr = 0.000302576, m = 0.9
I0325 03:31:18.873790 29022 solver.cpp:314] Iteration 15600 (1.29957 iter/s, 76.9483s/100 iter), loss = 3.24736
I0325 03:31:18.873960 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.3103 (* 1 = 4.3103 loss)
I0325 03:31:18.874006 29022 sgd_solver.cpp:136] Iteration 15600, lr = 0.000299866, m = 0.9
I0325 03:32:35.409137 29022 solver.cpp:314] Iteration 15700 (1.30663 iter/s, 76.5329s/100 iter), loss = 3.31159
I0325 03:32:35.409242 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.13475 (* 1 = 3.13475 loss)
I0325 03:32:35.409255 29022 sgd_solver.cpp:136] Iteration 15700, lr = 0.000297173, m = 0.9
I0325 03:33:52.098464 29022 solver.cpp:314] Iteration 15800 (1.304 iter/s, 76.6869s/100 iter), loss = 3.01682
I0325 03:33:52.098598 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.17484 (* 1 = 3.17484 loss)
I0325 03:33:52.098644 29022 sgd_solver.cpp:136] Iteration 15800, lr = 0.000294499, m = 0.9
I0325 03:35:09.193521 29022 solver.cpp:314] Iteration 15900 (1.29714 iter/s, 77.0926s/100 iter), loss = 3.20568
I0325 03:35:09.193655 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.40359 (* 1 = 4.40359 loss)
I0325 03:35:09.193687 29022 sgd_solver.cpp:136] Iteration 15900, lr = 0.000291843, m = 0.9
I0325 03:36:22.551272 29022 solver.cpp:360] Sparsity after update:
I0325 03:36:22.553619 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 03:36:22.553642 29022 net.cpp:2200] conv1a_param_0(0.397) 
I0325 03:36:22.553654 29022 net.cpp:2200] conv1b_param_0(0.68) 
I0325 03:36:22.553660 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 03:36:22.553666 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 03:36:22.553671 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 03:36:22.553676 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 03:36:22.553681 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 03:36:22.553688 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 03:36:22.553706 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 03:36:22.553716 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 03:36:22.553726 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 03:36:22.553732 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 03:36:22.553738 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 03:36:22.553743 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 03:36:22.553748 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 03:36:22.553755 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 03:36:22.553759 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 03:36:22.553764 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 03:36:22.553771 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 03:36:22.553776 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 03:36:22.553781 29022 net.cpp:2200] res2a_branch2a_param_0(0.723) 
I0325 03:36:22.553786 29022 net.cpp:2200] res2a_branch2b_param_0(0.571) 
I0325 03:36:22.553791 29022 net.cpp:2200] res3a_branch2a_param_0(0.675) 
I0325 03:36:22.553797 29022 net.cpp:2200] res3a_branch2b_param_0(0.647) 
I0325 03:36:22.553802 29022 net.cpp:2200] res4a_branch2a_param_0(0.754) 
I0325 03:36:22.553807 29022 net.cpp:2200] res4a_branch2b_param_0(0.701) 
I0325 03:36:22.553813 29022 net.cpp:2200] res5a_branch2a_param_0(0.786) 
I0325 03:36:22.553818 29022 net.cpp:2200] res5a_branch2b_param_0(0.796) 
I0325 03:36:22.553823 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.81684e+06/3.10435e+06) 0.585
I0325 03:36:22.553843 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_16000.caffemodel
I0325 03:36:22.579349 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_16000.solverstate
I0325 03:36:22.590581 29022 solver.cpp:678] Iteration 16000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.214675
j:  : 4 : max_pr:  : 0.436807
j:  : 3 : max_pr:  : 0.581142
j:  : 2 : max_pr:  : 0.696935
j:  : 1 : max_pr:  : 0.844475
j:  : 0 : max_pr:  : 1
I0325 03:37:45.769067 29022 solver.cpp:786] class AP 1: 0.343094
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.136183
j:  : 7 : max_pr:  : 0.300384
j:  : 6 : max_pr:  : 0.55084
j:  : 5 : max_pr:  : 0.654375
j:  : 4 : max_pr:  : 0.760235
j:  : 3 : max_pr:  : 0.798563
j:  : 2 : max_pr:  : 0.98146
j:  : 1 : max_pr:  : 0.997315
j:  : 0 : max_pr:  : 1
I0325 03:37:45.866677 29022 solver.cpp:786] class AP 2: 0.56176
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.470068
j:  : 6 : max_pr:  : 0.646419
j:  : 5 : max_pr:  : 0.746803
j:  : 4 : max_pr:  : 0.837774
j:  : 3 : max_pr:  : 0.91683
j:  : 2 : max_pr:  : 0.967376
j:  : 1 : max_pr:  : 0.997572
j:  : 0 : max_pr:  : 1
I0325 03:37:45.890136 29022 solver.cpp:786] class AP 3: 0.59844
I0325 03:37:45.890156 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.501098
I0325 03:37:45.890202 29022 solver.cpp:265] Tests completed in 83.2969s
I0325 03:37:46.579670 29022 solver.cpp:314] Iteration 16000 (0.6354 iter/s, 157.381s/100 iter), loss = 3.06797
I0325 03:37:46.580075 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.88095 (* 1 = 2.88095 loss)
I0325 03:37:46.580394 29022 sgd_solver.cpp:136] Iteration 16000, lr = 0.000289205, m = 0.9
I0325 03:39:03.165843 29022 solver.cpp:314] Iteration 16100 (1.30576 iter/s, 76.5837s/100 iter), loss = 3.33768
I0325 03:39:03.165940 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.15374 (* 1 = 3.15374 loss)
I0325 03:39:03.166162 29022 sgd_solver.cpp:136] Iteration 16100, lr = 0.000286585, m = 0.9
I0325 03:40:19.370108 29022 solver.cpp:314] Iteration 16200 (1.3123 iter/s, 76.2018s/100 iter), loss = 3.32791
I0325 03:40:19.370334 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.7314 (* 1 = 2.7314 loss)
I0325 03:40:19.370355 29022 sgd_solver.cpp:136] Iteration 16200, lr = 0.000283982, m = 0.9
I0325 03:41:35.381976 29022 solver.cpp:314] Iteration 16300 (1.31563 iter/s, 76.0094s/100 iter), loss = 3.19242
I0325 03:41:35.382077 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.77406 (* 1 = 2.77406 loss)
I0325 03:41:35.382095 29022 sgd_solver.cpp:136] Iteration 16300, lr = 0.000281398, m = 0.9
I0325 03:42:52.280496 29022 solver.cpp:314] Iteration 16400 (1.30046 iter/s, 76.896s/100 iter), loss = 3.14565
I0325 03:42:52.280603 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.57364 (* 1 = 2.57364 loss)
I0325 03:42:52.280620 29022 sgd_solver.cpp:136] Iteration 16400, lr = 0.000278831, m = 0.9
I0325 03:44:08.316903 29022 solver.cpp:314] Iteration 16500 (1.3152 iter/s, 76.034s/100 iter), loss = 3.121
I0325 03:44:08.317009 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.1655 (* 1 = 3.1655 loss)
I0325 03:44:08.317028 29022 sgd_solver.cpp:136] Iteration 16500, lr = 0.000276282, m = 0.9
I0325 03:45:25.213353 29022 solver.cpp:314] Iteration 16600 (1.30049 iter/s, 76.894s/100 iter), loss = 3.21011
I0325 03:45:25.213500 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.45803 (* 1 = 2.45803 loss)
I0325 03:45:25.213536 29022 sgd_solver.cpp:136] Iteration 16600, lr = 0.00027375, m = 0.9
I0325 03:46:41.075345 29022 solver.cpp:314] Iteration 16700 (1.31823 iter/s, 75.8596s/100 iter), loss = 3.30865
I0325 03:46:41.075495 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.5709 (* 1 = 4.5709 loss)
I0325 03:46:41.075531 29022 sgd_solver.cpp:136] Iteration 16700, lr = 0.000271236, m = 0.9
I0325 03:47:57.085434 29022 solver.cpp:314] Iteration 16800 (1.31566 iter/s, 76.0076s/100 iter), loss = 3.15649
I0325 03:47:57.085916 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.08795 (* 1 = 3.08795 loss)
I0325 03:47:57.086231 29022 sgd_solver.cpp:136] Iteration 16800, lr = 0.000268739, m = 0.9
I0325 03:49:12.752830 29022 solver.cpp:314] Iteration 16900 (1.32162 iter/s, 75.665s/100 iter), loss = 3.08255
I0325 03:49:12.752943 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.73932 (* 1 = 2.73932 loss)
I0325 03:49:12.753165 29022 sgd_solver.cpp:136] Iteration 16900, lr = 0.000266259, m = 0.9
I0325 03:50:30.070288 29022 solver.cpp:314] Iteration 17000 (1.29341 iter/s, 77.315s/100 iter), loss = 3.23773
I0325 03:50:30.070431 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.42583 (* 1 = 3.42583 loss)
I0325 03:50:30.070466 29022 sgd_solver.cpp:136] Iteration 17000, lr = 0.000263796, m = 0.9
I0325 03:51:46.456687 29022 solver.cpp:314] Iteration 17100 (1.30918 iter/s, 76.3839s/100 iter), loss = 3.10102
I0325 03:51:46.456877 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.71838 (* 1 = 2.71838 loss)
I0325 03:51:46.456926 29022 sgd_solver.cpp:136] Iteration 17100, lr = 0.000261351, m = 0.9
I0325 03:53:04.028880 29022 solver.cpp:314] Iteration 17200 (1.28916 iter/s, 77.5697s/100 iter), loss = 3.26303
I0325 03:53:04.028995 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.30971 (* 1 = 4.30971 loss)
I0325 03:53:04.029011 29022 sgd_solver.cpp:136] Iteration 17200, lr = 0.000258923, m = 0.9
I0325 03:54:20.968016 29022 solver.cpp:314] Iteration 17300 (1.29977 iter/s, 76.9367s/100 iter), loss = 3.11633
I0325 03:54:20.968156 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.87461 (* 1 = 3.87461 loss)
I0325 03:54:20.968192 29022 sgd_solver.cpp:136] Iteration 17300, lr = 0.000256511, m = 0.9
I0325 03:55:36.475487 29022 solver.cpp:314] Iteration 17400 (1.32441 iter/s, 75.5051s/100 iter), loss = 3.37836
I0325 03:55:36.475639 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.48293 (* 1 = 3.48293 loss)
I0325 03:55:36.475656 29022 sgd_solver.cpp:136] Iteration 17400, lr = 0.000254117, m = 0.9
I0325 03:56:53.236928 29022 solver.cpp:314] Iteration 17500 (1.30278 iter/s, 76.759s/100 iter), loss = 3.15611
I0325 03:56:53.237020 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.56201 (* 1 = 2.56201 loss)
I0325 03:56:53.237032 29022 sgd_solver.cpp:136] Iteration 17500, lr = 0.000251739, m = 0.9
I0325 03:58:11.283756 29022 solver.cpp:314] Iteration 17600 (1.28132 iter/s, 78.0443s/100 iter), loss = 3.06905
I0325 03:58:11.283870 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.21829 (* 1 = 3.21829 loss)
I0325 03:58:11.283890 29022 sgd_solver.cpp:136] Iteration 17600, lr = 0.000249378, m = 0.9
I0325 03:59:28.003342 29022 solver.cpp:314] Iteration 17700 (1.30349 iter/s, 76.7171s/100 iter), loss = 3.26362
I0325 03:59:28.003542 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.72013 (* 1 = 2.72013 loss)
I0325 03:59:28.003577 29022 sgd_solver.cpp:136] Iteration 17700, lr = 0.000247034, m = 0.9
I0325 04:00:44.569360 29022 solver.cpp:314] Iteration 17800 (1.3061 iter/s, 76.5636s/100 iter), loss = 3.18324
I0325 04:00:44.569495 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.28956 (* 1 = 2.28956 loss)
I0325 04:00:44.569530 29022 sgd_solver.cpp:136] Iteration 17800, lr = 0.000244706, m = 0.9
I0325 04:02:01.849303 29022 solver.cpp:314] Iteration 17900 (1.29404 iter/s, 77.2775s/100 iter), loss = 3.10253
I0325 04:02:01.849450 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.52624 (* 1 = 2.52624 loss)
I0325 04:02:01.849484 29022 sgd_solver.cpp:136] Iteration 17900, lr = 0.000242395, m = 0.9
I0325 04:03:18.470489 29022 solver.cpp:360] Sparsity after update:
I0325 04:03:18.473677 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 04:03:18.473752 29022 net.cpp:2200] conv1a_param_0(0.397) 
I0325 04:03:18.473788 29022 net.cpp:2200] conv1b_param_0(0.68) 
I0325 04:03:18.473816 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 04:03:18.473846 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 04:03:18.473875 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 04:03:18.473901 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 04:03:18.473928 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 04:03:18.473955 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 04:03:18.473984 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 04:03:18.474010 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 04:03:18.474037 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 04:03:18.474064 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 04:03:18.474092 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 04:03:18.474118 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 04:03:18.474146 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 04:03:18.474174 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 04:03:18.474202 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 04:03:18.474229 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 04:03:18.474267 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 04:03:18.474297 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 04:03:18.474323 29022 net.cpp:2200] res2a_branch2a_param_0(0.723) 
I0325 04:03:18.474351 29022 net.cpp:2200] res2a_branch2b_param_0(0.571) 
I0325 04:03:18.474378 29022 net.cpp:2200] res3a_branch2a_param_0(0.675) 
I0325 04:03:18.474405 29022 net.cpp:2200] res3a_branch2b_param_0(0.647) 
I0325 04:03:18.474432 29022 net.cpp:2200] res4a_branch2a_param_0(0.754) 
I0325 04:03:18.474459 29022 net.cpp:2200] res4a_branch2b_param_0(0.701) 
I0325 04:03:18.474488 29022 net.cpp:2200] res5a_branch2a_param_0(0.786) 
I0325 04:03:18.474514 29022 net.cpp:2200] res5a_branch2b_param_0(0.796) 
I0325 04:03:18.474542 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.81684e+06/3.10435e+06) 0.585
I0325 04:03:18.474588 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_18000.caffemodel
I0325 04:03:18.500862 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_18000.solverstate
I0325 04:03:18.512681 29022 solver.cpp:678] Iteration 18000, Testing net (#0)
I0325 04:04:39.998699 29077 data_reader.cpp:305] Starting prefetch of epoch 4
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.195656
j:  : 4 : max_pr:  : 0.43543
j:  : 3 : max_pr:  : 0.585313
j:  : 2 : max_pr:  : 0.70296
j:  : 1 : max_pr:  : 0.844084
j:  : 0 : max_pr:  : 1
I0325 04:04:41.906378 29022 solver.cpp:786] class AP 1: 0.342131
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.169815
j:  : 7 : max_pr:  : 0.324608
j:  : 6 : max_pr:  : 0.555667
j:  : 5 : max_pr:  : 0.625205
j:  : 4 : max_pr:  : 0.734289
j:  : 3 : max_pr:  : 0.779984
j:  : 2 : max_pr:  : 0.972932
j:  : 1 : max_pr:  : 0.997428
j:  : 0 : max_pr:  : 1
I0325 04:04:41.995391 29022 solver.cpp:786] class AP 2: 0.559994
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.480957
j:  : 6 : max_pr:  : 0.64643
j:  : 5 : max_pr:  : 0.744941
j:  : 4 : max_pr:  : 0.833976
j:  : 3 : max_pr:  : 0.914725
j:  : 2 : max_pr:  : 0.96685
j:  : 1 : max_pr:  : 0.997889
j:  : 0 : max_pr:  : 1
I0325 04:04:42.019057 29022 solver.cpp:786] class AP 3: 0.598706
I0325 04:04:42.019073 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.500277
I0325 04:04:42.019117 29022 solver.cpp:265] Tests completed in 83.5038s
I0325 04:04:42.599542 29022 solver.cpp:314] Iteration 18000 (0.622103 iter/s, 160.745s/100 iter), loss = 3.1327
I0325 04:04:42.599639 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.49675 (* 1 = 3.49675 loss)
I0325 04:04:42.599673 29022 sgd_solver.cpp:136] Iteration 18000, lr = 0.0002401, m = 0.9
I0325 04:05:59.221355 29022 solver.cpp:314] Iteration 18100 (1.30515 iter/s, 76.6193s/100 iter), loss = 3.27445
I0325 04:05:59.221498 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.07158 (* 1 = 4.07158 loss)
I0325 04:05:59.221531 29022 sgd_solver.cpp:136] Iteration 18100, lr = 0.000237821, m = 0.9
I0325 04:07:15.663136 29022 solver.cpp:314] Iteration 18200 (1.30823 iter/s, 76.4393s/100 iter), loss = 3.15981
I0325 04:07:15.663450 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.38173 (* 1 = 3.38173 loss)
I0325 04:07:15.663468 29022 sgd_solver.cpp:136] Iteration 18200, lr = 0.000235559, m = 0.9
I0325 04:08:32.768261 29022 solver.cpp:314] Iteration 18300 (1.29697 iter/s, 77.1026s/100 iter), loss = 3.13156
I0325 04:08:32.768820 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.98243 (* 1 = 2.98243 loss)
I0325 04:08:32.769183 29022 sgd_solver.cpp:136] Iteration 18300, lr = 0.000233313, m = 0.9
I0325 04:09:49.858871 29022 solver.cpp:314] Iteration 18400 (1.29722 iter/s, 77.0881s/100 iter), loss = 3.29268
I0325 04:09:49.859035 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.08191 (* 1 = 4.08191 loss)
I0325 04:09:49.859052 29022 sgd_solver.cpp:136] Iteration 18400, lr = 0.000231083, m = 0.9
I0325 04:11:05.750844 29022 solver.cpp:314] Iteration 18500 (1.3177 iter/s, 75.8895s/100 iter), loss = 3.02009
I0325 04:11:05.750975 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.59917 (* 1 = 3.59917 loss)
I0325 04:11:05.751009 29022 sgd_solver.cpp:136] Iteration 18500, lr = 0.000228869, m = 0.9
I0325 04:12:22.322036 29022 solver.cpp:314] Iteration 18600 (1.30602 iter/s, 76.5687s/100 iter), loss = 3.26205
I0325 04:12:22.322211 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.46275 (* 1 = 3.46275 loss)
I0325 04:12:22.322247 29022 sgd_solver.cpp:136] Iteration 18600, lr = 0.000226671, m = 0.9
I0325 04:13:38.553684 29022 solver.cpp:314] Iteration 18700 (1.31183 iter/s, 76.2292s/100 iter), loss = 3.15672
I0325 04:13:38.553844 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.22043 (* 1 = 3.22043 loss)
I0325 04:13:38.553880 29022 sgd_solver.cpp:136] Iteration 18700, lr = 0.000224489, m = 0.9
I0325 04:14:54.918356 29022 solver.cpp:314] Iteration 18800 (1.30955 iter/s, 76.3622s/100 iter), loss = 3.08769
I0325 04:14:54.918455 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.04844 (* 1 = 4.04844 loss)
I0325 04:14:54.918474 29022 sgd_solver.cpp:136] Iteration 18800, lr = 0.000222323, m = 0.9
I0325 04:16:12.062851 29022 solver.cpp:314] Iteration 18900 (1.29631 iter/s, 77.142s/100 iter), loss = 3.23046
I0325 04:16:12.063032 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.16075 (* 1 = 3.16075 loss)
I0325 04:16:12.063072 29022 sgd_solver.cpp:136] Iteration 18900, lr = 0.000220172, m = 0.9
I0325 04:17:28.659297 29022 solver.cpp:314] Iteration 19000 (1.30559 iter/s, 76.594s/100 iter), loss = 3.00829
I0325 04:17:28.659446 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.89424 (* 1 = 2.89424 loss)
I0325 04:17:28.659482 29022 sgd_solver.cpp:136] Iteration 19000, lr = 0.000218037, m = 0.9
I0325 04:18:43.767808 29022 solver.cpp:314] Iteration 19100 (1.33145 iter/s, 75.1061s/100 iter), loss = 3.22823
I0325 04:18:43.767936 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.65196 (* 1 = 3.65196 loss)
I0325 04:18:43.767972 29022 sgd_solver.cpp:136] Iteration 19100, lr = 0.000215918, m = 0.9
I0325 04:19:59.926939 29022 solver.cpp:314] Iteration 19200 (1.31308 iter/s, 76.1567s/100 iter), loss = 3.09672
I0325 04:19:59.927079 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.54018 (* 1 = 2.54018 loss)
I0325 04:19:59.927114 29022 sgd_solver.cpp:136] Iteration 19200, lr = 0.000213814, m = 0.9
I0325 04:21:17.808687 29022 solver.cpp:314] Iteration 19300 (1.28404 iter/s, 77.8792s/100 iter), loss = 3.18496
I0325 04:21:17.808827 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.89493 (* 1 = 3.89493 loss)
I0325 04:21:17.808863 29022 sgd_solver.cpp:136] Iteration 19300, lr = 0.000211725, m = 0.9
I0325 04:22:34.830404 29022 solver.cpp:314] Iteration 19400 (1.29838 iter/s, 77.0192s/100 iter), loss = 3.20299
I0325 04:22:34.830569 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.00183 (* 1 = 2.00183 loss)
I0325 04:22:34.830606 29022 sgd_solver.cpp:136] Iteration 19400, lr = 0.000209652, m = 0.9
I0325 04:23:52.003706 29022 solver.cpp:314] Iteration 19500 (1.29583 iter/s, 77.1708s/100 iter), loss = 3.23308
I0325 04:23:52.006321 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.31849 (* 1 = 4.31849 loss)
I0325 04:23:52.006338 29022 sgd_solver.cpp:136] Iteration 19500, lr = 0.000207594, m = 0.9
I0325 04:25:07.626478 29022 solver.cpp:314] Iteration 19600 (1.3224 iter/s, 75.6203s/100 iter), loss = 3.20126
I0325 04:25:07.626607 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.79308 (* 1 = 2.79308 loss)
I0325 04:25:07.626641 29022 sgd_solver.cpp:136] Iteration 19600, lr = 0.000205551, m = 0.9
I0325 04:26:24.504859 29022 solver.cpp:314] Iteration 19700 (1.3008 iter/s, 76.8759s/100 iter), loss = 3.10629
I0325 04:26:24.505038 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.35229 (* 1 = 2.35229 loss)
I0325 04:26:24.505074 29022 sgd_solver.cpp:136] Iteration 19700, lr = 0.000203524, m = 0.9
I0325 04:27:39.767460 29022 solver.cpp:314] Iteration 19800 (1.32872 iter/s, 75.2602s/100 iter), loss = 3.04515
I0325 04:27:39.767628 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.97776 (* 1 = 3.97776 loss)
I0325 04:27:39.767642 29022 sgd_solver.cpp:136] Iteration 19800, lr = 0.000201511, m = 0.9
I0325 04:28:56.106997 29022 solver.cpp:314] Iteration 19900 (1.30998 iter/s, 76.3371s/100 iter), loss = 3.07443
I0325 04:28:56.107143 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.41038 (* 1 = 2.41038 loss)
I0325 04:28:56.107180 29022 sgd_solver.cpp:136] Iteration 19900, lr = 0.000199514, m = 0.9
I0325 04:30:11.873922 29022 solver.cpp:360] Sparsity after update:
I0325 04:30:11.877296 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 04:30:11.877338 29022 net.cpp:2200] conv1a_param_0(0.397) 
I0325 04:30:11.877357 29022 net.cpp:2200] conv1b_param_0(0.68) 
I0325 04:30:11.877365 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 04:30:11.877374 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 04:30:11.877383 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 04:30:11.877391 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 04:30:11.877400 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 04:30:11.877408 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 04:30:11.877418 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 04:30:11.877425 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 04:30:11.877434 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 04:30:11.877441 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 04:30:11.877450 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 04:30:11.877459 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 04:30:11.877467 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 04:30:11.877475 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 04:30:11.877483 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 04:30:11.877492 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 04:30:11.877499 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 04:30:11.877508 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 04:30:11.877516 29022 net.cpp:2200] res2a_branch2a_param_0(0.723) 
I0325 04:30:11.877526 29022 net.cpp:2200] res2a_branch2b_param_0(0.571) 
I0325 04:30:11.877534 29022 net.cpp:2200] res3a_branch2a_param_0(0.675) 
I0325 04:30:11.877542 29022 net.cpp:2200] res3a_branch2b_param_0(0.647) 
I0325 04:30:11.877552 29022 net.cpp:2200] res4a_branch2a_param_0(0.754) 
I0325 04:30:11.877559 29022 net.cpp:2200] res4a_branch2b_param_0(0.701) 
I0325 04:30:11.877568 29022 net.cpp:2200] res5a_branch2a_param_0(0.786) 
I0325 04:30:11.877576 29022 net.cpp:2200] res5a_branch2b_param_0(0.796) 
I0325 04:30:11.877585 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.81684e+06/3.10435e+06) 0.585
I0325 04:30:11.877612 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_20000.caffemodel
I0325 04:30:11.905212 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_20000.solverstate
I0325 04:30:11.917737 29022 solver.cpp:678] Iteration 20000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.221645
j:  : 4 : max_pr:  : 0.448543
j:  : 3 : max_pr:  : 0.58863
j:  : 2 : max_pr:  : 0.706708
j:  : 1 : max_pr:  : 0.845652
j:  : 0 : max_pr:  : 1
I0325 04:31:35.476608 29022 solver.cpp:786] class AP 1: 0.346471
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.162653
j:  : 7 : max_pr:  : 0.318405
j:  : 6 : max_pr:  : 0.557866
j:  : 5 : max_pr:  : 0.639621
j:  : 4 : max_pr:  : 0.743193
j:  : 3 : max_pr:  : 0.782696
j:  : 2 : max_pr:  : 0.982935
j:  : 1 : max_pr:  : 0.997495
j:  : 0 : max_pr:  : 1
I0325 04:31:35.577607 29022 solver.cpp:786] class AP 2: 0.56226
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.494727
j:  : 6 : max_pr:  : 0.656622
j:  : 5 : max_pr:  : 0.749241
j:  : 4 : max_pr:  : 0.834012
j:  : 3 : max_pr:  : 0.916531
j:  : 2 : max_pr:  : 0.968712
j:  : 1 : max_pr:  : 0.998245
j:  : 0 : max_pr:  : 1
I0325 04:31:35.602269 29022 solver.cpp:786] class AP 3: 0.601645
I0325 04:31:35.602286 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.503459
I0325 04:31:35.602329 29022 solver.cpp:265] Tests completed in 83.6819s
I0325 04:31:36.171917 29022 solver.cpp:314] Iteration 20000 (0.624767 iter/s, 160.06s/100 iter), loss = 3.23566
I0325 04:31:36.172017 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.04589 (* 1 = 3.04589 loss)
I0325 04:31:36.172049 29022 sgd_solver.cpp:136] Iteration 20000, lr = 0.000197531, m = 0.9
I0325 04:32:52.486027 29022 solver.cpp:314] Iteration 20100 (1.31042 iter/s, 76.3116s/100 iter), loss = 3.16578
I0325 04:32:52.486177 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.57577 (* 1 = 3.57577 loss)
I0325 04:32:52.486212 29022 sgd_solver.cpp:136] Iteration 20100, lr = 0.000195563, m = 0.9
I0325 04:34:07.867414 29022 solver.cpp:314] Iteration 20200 (1.32663 iter/s, 75.379s/100 iter), loss = 3.03342
I0325 04:34:07.869343 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.41526 (* 1 = 2.41526 loss)
I0325 04:34:07.869371 29022 sgd_solver.cpp:136] Iteration 20200, lr = 0.00019361, m = 0.9
I0325 04:35:24.910199 29022 solver.cpp:314] Iteration 20300 (1.29802 iter/s, 77.0403s/100 iter), loss = 3.14065
I0325 04:35:24.910343 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.59111 (* 1 = 2.59111 loss)
I0325 04:35:24.910379 29022 sgd_solver.cpp:136] Iteration 20300, lr = 0.000191671, m = 0.9
I0325 04:36:40.034708 29022 solver.cpp:314] Iteration 20400 (1.33117 iter/s, 75.1221s/100 iter), loss = 3.16245
I0325 04:36:40.034816 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.31165 (* 1 = 3.31165 loss)
I0325 04:36:40.034831 29022 sgd_solver.cpp:136] Iteration 20400, lr = 0.000189747, m = 0.9
I0325 04:37:56.394309 29022 solver.cpp:314] Iteration 20500 (1.30964 iter/s, 76.3571s/100 iter), loss = 3.1977
I0325 04:37:56.394522 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.40673 (* 1 = 2.40673 loss)
I0325 04:37:56.394558 29022 sgd_solver.cpp:136] Iteration 20500, lr = 0.000187838, m = 0.9
I0325 04:39:12.259920 29022 solver.cpp:314] Iteration 20600 (1.31816 iter/s, 75.8632s/100 iter), loss = 3.16225
I0325 04:39:12.260064 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.3429 (* 1 = 2.3429 loss)
I0325 04:39:12.260098 29022 sgd_solver.cpp:136] Iteration 20600, lr = 0.000185943, m = 0.9
I0325 04:40:28.755403 29022 solver.cpp:314] Iteration 20700 (1.30731 iter/s, 76.493s/100 iter), loss = 3.14947
I0325 04:40:28.755542 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.41593 (* 1 = 2.41593 loss)
I0325 04:40:28.755579 29022 sgd_solver.cpp:136] Iteration 20700, lr = 0.000184062, m = 0.9
I0325 04:41:43.859829 29022 solver.cpp:314] Iteration 20800 (1.33152 iter/s, 75.102s/100 iter), loss = 3.38565
I0325 04:41:43.859921 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.31558 (* 1 = 3.31558 loss)
I0325 04:41:43.859939 29022 sgd_solver.cpp:136] Iteration 20800, lr = 0.000182196, m = 0.9
I0325 04:42:22.836815 29042 data_reader.cpp:305] Starting prefetch of epoch 4
I0325 04:42:59.422873 29022 solver.cpp:314] Iteration 20900 (1.32344 iter/s, 75.5606s/100 iter), loss = 3.1935
I0325 04:42:59.423024 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.61907 (* 1 = 3.61907 loss)
I0325 04:42:59.423061 29022 sgd_solver.cpp:136] Iteration 20900, lr = 0.000180344, m = 0.9
I0325 04:44:16.673543 29022 solver.cpp:314] Iteration 21000 (1.29453 iter/s, 77.2482s/100 iter), loss = 3.20789
I0325 04:44:16.673703 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.83436 (* 1 = 2.83436 loss)
I0325 04:44:16.673720 29022 sgd_solver.cpp:136] Iteration 21000, lr = 0.000178506, m = 0.9
I0325 04:44:54.074867 29022 blocking_queue.cpp:40] Data layer prefetch queue empty
I0325 04:45:33.556597 29022 solver.cpp:314] Iteration 21100 (1.30072 iter/s, 76.8806s/100 iter), loss = 3.29713
I0325 04:45:33.556740 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.20948 (* 1 = 3.20948 loss)
I0325 04:45:33.556773 29022 sgd_solver.cpp:136] Iteration 21100, lr = 0.000176682, m = 0.9
I0325 04:46:48.897625 29022 solver.cpp:314] Iteration 21200 (1.32734 iter/s, 75.3386s/100 iter), loss = 3.35579
I0325 04:46:48.897734 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.688 (* 1 = 2.688 loss)
I0325 04:46:48.897753 29022 sgd_solver.cpp:136] Iteration 21200, lr = 0.000174873, m = 0.9
I0325 04:48:04.964445 29022 solver.cpp:314] Iteration 21300 (1.31468 iter/s, 76.0644s/100 iter), loss = 3.28923
I0325 04:48:04.964577 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.25384 (* 1 = 4.25384 loss)
I0325 04:48:04.964609 29022 sgd_solver.cpp:136] Iteration 21300, lr = 0.000173077, m = 0.9
I0325 04:49:21.304602 29022 solver.cpp:314] Iteration 21400 (1.30997 iter/s, 76.3377s/100 iter), loss = 2.96119
I0325 04:49:21.304728 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.73824 (* 1 = 2.73824 loss)
I0325 04:49:21.304745 29022 sgd_solver.cpp:136] Iteration 21400, lr = 0.000171295, m = 0.9
I0325 04:50:36.702458 29022 solver.cpp:314] Iteration 21500 (1.32634 iter/s, 75.3954s/100 iter), loss = 3.15633
I0325 04:50:36.702641 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.69147 (* 1 = 2.69147 loss)
I0325 04:50:36.702677 29022 sgd_solver.cpp:136] Iteration 21500, lr = 0.000169527, m = 0.9
I0325 04:51:52.275560 29022 solver.cpp:314] Iteration 21600 (1.32326 iter/s, 75.5707s/100 iter), loss = 3.23084
I0325 04:51:52.275679 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.18612 (* 1 = 2.18612 loss)
I0325 04:51:52.275698 29022 sgd_solver.cpp:136] Iteration 21600, lr = 0.000167772, m = 0.9
I0325 04:53:08.840134 29022 solver.cpp:314] Iteration 21700 (1.30613 iter/s, 76.5621s/100 iter), loss = 3.11334
I0325 04:53:08.841159 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.39959 (* 1 = 2.39959 loss)
I0325 04:53:08.841470 29022 sgd_solver.cpp:136] Iteration 21700, lr = 0.000166031, m = 0.9
I0325 04:54:25.045033 29022 solver.cpp:314] Iteration 21800 (1.31229 iter/s, 76.2025s/100 iter), loss = 3.33127
I0325 04:54:25.045765 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.093 (* 1 = 3.093 loss)
I0325 04:54:25.045800 29022 sgd_solver.cpp:136] Iteration 21800, lr = 0.000164304, m = 0.9
I0325 04:55:41.566133 29022 solver.cpp:314] Iteration 21900 (1.30687 iter/s, 76.5186s/100 iter), loss = 3.36007
I0325 04:55:41.566277 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.27893 (* 1 = 2.27893 loss)
I0325 04:55:41.566313 29022 sgd_solver.cpp:136] Iteration 21900, lr = 0.00016259, m = 0.9
I0325 04:56:57.798646 29022 solver.cpp:360] Sparsity after update:
I0325 04:56:57.801723 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 04:56:57.801767 29022 net.cpp:2200] conv1a_param_0(0.397) 
I0325 04:56:57.801798 29022 net.cpp:2200] conv1b_param_0(0.68) 
I0325 04:56:57.801825 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 04:56:57.801851 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 04:56:57.801875 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 04:56:57.801901 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 04:56:57.801928 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 04:56:57.801952 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 04:56:57.801977 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 04:56:57.802004 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 04:56:57.802038 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 04:56:57.802065 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 04:56:57.802090 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 04:56:57.802115 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 04:56:57.802139 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 04:56:57.802165 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 04:56:57.802188 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 04:56:57.802212 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 04:56:57.802237 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 04:56:57.802261 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 04:56:57.802286 29022 net.cpp:2200] res2a_branch2a_param_0(0.723) 
I0325 04:56:57.802311 29022 net.cpp:2200] res2a_branch2b_param_0(0.571) 
I0325 04:56:57.802335 29022 net.cpp:2200] res3a_branch2a_param_0(0.675) 
I0325 04:56:57.802361 29022 net.cpp:2200] res3a_branch2b_param_0(0.647) 
I0325 04:56:57.802384 29022 net.cpp:2200] res4a_branch2a_param_0(0.754) 
I0325 04:56:57.802409 29022 net.cpp:2200] res4a_branch2b_param_0(0.701) 
I0325 04:56:57.802433 29022 net.cpp:2200] res5a_branch2a_param_0(0.786) 
I0325 04:56:57.802459 29022 net.cpp:2200] res5a_branch2b_param_0(0.796) 
I0325 04:56:57.802484 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.81684e+06/3.10435e+06) 0.585
I0325 04:56:57.802526 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_22000.caffemodel
I0325 04:56:57.827898 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_22000.solverstate
I0325 04:56:57.837105 29022 solver.cpp:678] Iteration 22000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.236123
j:  : 4 : max_pr:  : 0.45134
j:  : 3 : max_pr:  : 0.588943
j:  : 2 : max_pr:  : 0.704179
j:  : 1 : max_pr:  : 0.844864
j:  : 0 : max_pr:  : 1
I0325 04:58:21.099757 29022 solver.cpp:786] class AP 1: 0.347768
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.169466
j:  : 7 : max_pr:  : 0.336051
j:  : 6 : max_pr:  : 0.554383
j:  : 5 : max_pr:  : 0.622107
j:  : 4 : max_pr:  : 0.727158
j:  : 3 : max_pr:  : 0.783827
j:  : 2 : max_pr:  : 0.984055
j:  : 1 : max_pr:  : 0.997877
j:  : 0 : max_pr:  : 1
I0325 04:58:21.200799 29022 solver.cpp:786] class AP 2: 0.561357
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.489314
j:  : 6 : max_pr:  : 0.648474
j:  : 5 : max_pr:  : 0.747003
j:  : 4 : max_pr:  : 0.835298
j:  : 3 : max_pr:  : 0.915375
j:  : 2 : max_pr:  : 0.966724
j:  : 1 : max_pr:  : 0.99637
j:  : 0 : max_pr:  : 1
I0325 04:58:21.222646 29022 solver.cpp:786] class AP 3: 0.599869
I0325 04:58:21.222667 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.502998
I0325 04:58:21.222723 29022 solver.cpp:265] Tests completed in 83.3829s
I0325 04:58:21.740345 29022 solver.cpp:314] Iteration 22000 (0.62434 iter/s, 160.169s/100 iter), loss = 3.40922
I0325 04:58:21.740430 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.52707 (* 1 = 3.52707 loss)
I0325 04:58:21.740463 29022 sgd_solver.cpp:136] Iteration 22000, lr = 0.00016089, m = 0.9
I0325 04:59:38.687438 29022 solver.cpp:314] Iteration 22100 (1.29964 iter/s, 76.9446s/100 iter), loss = 3.08542
I0325 04:59:38.687592 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.95198 (* 1 = 2.95198 loss)
I0325 04:59:38.687629 29022 sgd_solver.cpp:136] Iteration 22100, lr = 0.000159203, m = 0.9
I0325 05:00:54.609830 29022 solver.cpp:314] Iteration 22200 (1.31718 iter/s, 75.9199s/100 iter), loss = 3.16475
I0325 05:00:54.609972 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.69716 (* 1 = 2.69716 loss)
I0325 05:00:54.610018 29022 sgd_solver.cpp:136] Iteration 22200, lr = 0.00015753, m = 0.9
I0325 05:02:11.983633 29022 solver.cpp:314] Iteration 22300 (1.29247 iter/s, 77.3713s/100 iter), loss = 3.14701
I0325 05:02:11.983759 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.16515 (* 1 = 3.16515 loss)
I0325 05:02:11.983777 29022 sgd_solver.cpp:136] Iteration 22300, lr = 0.000155869, m = 0.9
I0325 05:03:28.916581 29022 solver.cpp:314] Iteration 22400 (1.29988 iter/s, 76.9305s/100 iter), loss = 3.13113
I0325 05:03:28.916738 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.36701 (* 1 = 3.36701 loss)
I0325 05:03:28.916754 29022 sgd_solver.cpp:136] Iteration 22400, lr = 0.000154222, m = 0.9
I0325 05:04:46.180696 29022 solver.cpp:314] Iteration 22500 (1.2943 iter/s, 77.2616s/100 iter), loss = 3.13968
I0325 05:04:46.182061 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.52302 (* 1 = 3.52302 loss)
I0325 05:04:46.182098 29022 sgd_solver.cpp:136] Iteration 22500, lr = 0.000152588, m = 0.9
I0325 05:06:01.970180 29022 solver.cpp:314] Iteration 22600 (1.31949 iter/s, 75.7871s/100 iter), loss = 3.0291
I0325 05:06:01.970322 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.68012 (* 1 = 3.68012 loss)
I0325 05:06:01.970357 29022 sgd_solver.cpp:136] Iteration 22600, lr = 0.000150967, m = 0.9
I0325 05:07:17.633913 29022 solver.cpp:314] Iteration 22700 (1.32168 iter/s, 75.6613s/100 iter), loss = 3.1486
I0325 05:07:17.634025 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.32337 (* 1 = 2.32337 loss)
I0325 05:07:17.634254 29022 sgd_solver.cpp:136] Iteration 22700, lr = 0.000149359, m = 0.9
I0325 05:08:34.293238 29022 solver.cpp:314] Iteration 22800 (1.30451 iter/s, 76.6569s/100 iter), loss = 3.32859
I0325 05:08:34.293332 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.4803 (* 1 = 3.4803 loss)
I0325 05:08:34.293351 29022 sgd_solver.cpp:136] Iteration 22800, lr = 0.000147763, m = 0.9
I0325 05:09:50.989176 29022 solver.cpp:314] Iteration 22900 (1.30389 iter/s, 76.6935s/100 iter), loss = 3.04709
I0325 05:09:50.989336 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.87137 (* 1 = 2.87137 loss)
I0325 05:09:50.989372 29022 sgd_solver.cpp:136] Iteration 22900, lr = 0.000146181, m = 0.9
I0325 05:11:08.022326 29022 solver.cpp:314] Iteration 23000 (1.29818 iter/s, 77.0307s/100 iter), loss = 3.20332
I0325 05:11:08.022475 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.23762 (* 1 = 3.23762 loss)
I0325 05:11:08.022509 29022 sgd_solver.cpp:136] Iteration 23000, lr = 0.000144611, m = 0.9
I0325 05:12:25.004472 29022 solver.cpp:314] Iteration 23100 (1.29904 iter/s, 76.9797s/100 iter), loss = 2.9904
I0325 05:12:25.004590 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.51829 (* 1 = 2.51829 loss)
I0325 05:12:25.004602 29022 sgd_solver.cpp:136] Iteration 23100, lr = 0.000143054, m = 0.9
I0325 05:13:42.195739 29022 solver.cpp:314] Iteration 23200 (1.29552 iter/s, 77.1888s/100 iter), loss = 3.25608
I0325 05:13:42.195896 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.68248 (* 1 = 3.68248 loss)
I0325 05:13:42.195915 29022 sgd_solver.cpp:136] Iteration 23200, lr = 0.00014151, m = 0.9
I0325 05:14:58.457873 29022 solver.cpp:314] Iteration 23300 (1.31131 iter/s, 76.2597s/100 iter), loss = 3.14099
I0325 05:14:58.458006 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.79126 (* 1 = 2.79126 loss)
I0325 05:14:58.458040 29022 sgd_solver.cpp:136] Iteration 23300, lr = 0.000139978, m = 0.9
I0325 05:16:15.495962 29022 solver.cpp:314] Iteration 23400 (1.2981 iter/s, 77.0356s/100 iter), loss = 3.24246
I0325 05:16:15.496081 29022 solver.cpp:336]     Train net output #0: mbox_loss = 1.9183 (* 1 = 1.9183 loss)
I0325 05:16:15.496115 29022 sgd_solver.cpp:136] Iteration 23400, lr = 0.000138458, m = 0.9
I0325 05:17:31.692474 29022 solver.cpp:314] Iteration 23500 (1.31244 iter/s, 76.1941s/100 iter), loss = 3.20474
I0325 05:17:31.692569 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.78532 (* 1 = 2.78532 loss)
I0325 05:17:31.692581 29022 sgd_solver.cpp:136] Iteration 23500, lr = 0.000136951, m = 0.9
I0325 05:18:48.643962 29022 solver.cpp:314] Iteration 23600 (1.29956 iter/s, 76.949s/100 iter), loss = 3.14276
I0325 05:18:48.647348 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.47378 (* 1 = 2.47378 loss)
I0325 05:18:48.647367 29022 sgd_solver.cpp:136] Iteration 23600, lr = 0.000135457, m = 0.9
I0325 05:20:03.780560 29022 solver.cpp:314] Iteration 23700 (1.33095 iter/s, 75.1342s/100 iter), loss = 3.25667
I0325 05:20:03.780665 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.73192 (* 1 = 2.73192 loss)
I0325 05:20:03.780681 29022 sgd_solver.cpp:136] Iteration 23700, lr = 0.000133974, m = 0.9
I0325 05:21:19.320498 29022 solver.cpp:314] Iteration 23800 (1.32385 iter/s, 75.5375s/100 iter), loss = 3.25618
I0325 05:21:19.320600 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.55656 (* 1 = 2.55656 loss)
I0325 05:21:19.320612 29022 sgd_solver.cpp:136] Iteration 23800, lr = 0.000132504, m = 0.9
I0325 05:22:35.439175 29022 solver.cpp:314] Iteration 23900 (1.31378 iter/s, 76.1162s/100 iter), loss = 3.19979
I0325 05:22:35.439365 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.60893 (* 1 = 2.60893 loss)
I0325 05:22:35.439399 29022 sgd_solver.cpp:136] Iteration 23900, lr = 0.000131046, m = 0.9
I0325 05:23:36.130892 29042 data_reader.cpp:305] Starting prefetch of epoch 5
I0325 05:23:50.250793 29022 solver.cpp:360] Sparsity after update:
I0325 05:23:50.253916 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 05:23:50.253937 29022 net.cpp:2200] conv1a_param_0(0.397) 
I0325 05:23:50.253952 29022 net.cpp:2200] conv1b_param_0(0.68) 
I0325 05:23:50.253962 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 05:23:50.253970 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 05:23:50.253979 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 05:23:50.253988 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 05:23:50.253995 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 05:23:50.254004 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 05:23:50.254012 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 05:23:50.254021 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 05:23:50.254029 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 05:23:50.254037 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 05:23:50.254046 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 05:23:50.254055 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 05:23:50.254063 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 05:23:50.254071 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 05:23:50.254079 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 05:23:50.254093 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 05:23:50.254102 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 05:23:50.254112 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 05:23:50.254119 29022 net.cpp:2200] res2a_branch2a_param_0(0.723) 
I0325 05:23:50.254128 29022 net.cpp:2200] res2a_branch2b_param_0(0.571) 
I0325 05:23:50.254140 29022 net.cpp:2200] res3a_branch2a_param_0(0.675) 
I0325 05:23:50.254150 29022 net.cpp:2200] res3a_branch2b_param_0(0.647) 
I0325 05:23:50.254158 29022 net.cpp:2200] res4a_branch2a_param_0(0.754) 
I0325 05:23:50.254168 29022 net.cpp:2200] res4a_branch2b_param_0(0.701) 
I0325 05:23:50.254179 29022 net.cpp:2200] res5a_branch2a_param_0(0.786) 
I0325 05:23:50.254187 29022 net.cpp:2200] res5a_branch2b_param_0(0.796) 
I0325 05:23:50.254196 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.81684e+06/3.10435e+06) 0.585
I0325 05:23:50.254222 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_24000.caffemodel
I0325 05:23:50.280055 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_24000.solverstate
I0325 05:23:50.292722 29022 solver.cpp:678] Iteration 24000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.231935
j:  : 4 : max_pr:  : 0.45175
j:  : 3 : max_pr:  : 0.589441
j:  : 2 : max_pr:  : 0.705401
j:  : 1 : max_pr:  : 0.845097
j:  : 0 : max_pr:  : 1
I0325 05:25:13.307942 29022 solver.cpp:786] class AP 1: 0.347602
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.155524
j:  : 7 : max_pr:  : 0.318827
j:  : 6 : max_pr:  : 0.54151
j:  : 5 : max_pr:  : 0.637436
j:  : 4 : max_pr:  : 0.741488
j:  : 3 : max_pr:  : 0.783947
j:  : 2 : max_pr:  : 0.982224
j:  : 1 : max_pr:  : 0.997878
j:  : 0 : max_pr:  : 1
I0325 05:25:13.408139 29022 solver.cpp:786] class AP 2: 0.559894
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.491444
j:  : 6 : max_pr:  : 0.651669
j:  : 5 : max_pr:  : 0.749321
j:  : 4 : max_pr:  : 0.833704
j:  : 3 : max_pr:  : 0.916884
j:  : 2 : max_pr:  : 0.965033
j:  : 1 : max_pr:  : 0.996609
j:  : 0 : max_pr:  : 1
I0325 05:25:13.430089 29022 solver.cpp:786] class AP 3: 0.600424
I0325 05:25:13.430104 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.50264
I0325 05:25:13.430148 29022 solver.cpp:265] Tests completed in 83.1348s
I0325 05:25:13.991171 29022 solver.cpp:314] Iteration 24000 (0.630728 iter/s, 158.547s/100 iter), loss = 3.18303
I0325 05:25:13.991225 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.49351 (* 1 = 3.49351 loss)
I0325 05:25:13.991237 29022 sgd_solver.cpp:136] Iteration 24000, lr = 0.0001296, m = 0.9
I0325 05:26:30.334846 29022 solver.cpp:314] Iteration 24100 (1.30991 iter/s, 76.3412s/100 iter), loss = 3.24345
I0325 05:26:30.334995 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.87821 (* 1 = 2.87821 loss)
I0325 05:26:30.335027 29022 sgd_solver.cpp:136] Iteration 24100, lr = 0.000128166, m = 0.9
I0325 05:27:47.469173 29022 solver.cpp:314] Iteration 24200 (1.29648 iter/s, 77.1318s/100 iter), loss = 3.10745
I0325 05:27:47.469386 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.57899 (* 1 = 3.57899 loss)
I0325 05:27:47.469422 29022 sgd_solver.cpp:136] Iteration 24200, lr = 0.000126744, m = 0.9
I0325 05:29:03.160712 29022 solver.cpp:314] Iteration 24300 (1.32119 iter/s, 75.6891s/100 iter), loss = 3.09024
I0325 05:29:03.160848 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.63504 (* 1 = 2.63504 loss)
I0325 05:29:03.160881 29022 sgd_solver.cpp:136] Iteration 24300, lr = 0.000125334, m = 0.9
I0325 05:30:20.293745 29022 solver.cpp:314] Iteration 24400 (1.2965 iter/s, 77.1306s/100 iter), loss = 3.04879
I0325 05:30:20.293884 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.55453 (* 1 = 4.55453 loss)
I0325 05:30:20.293920 29022 sgd_solver.cpp:136] Iteration 24400, lr = 0.000123935, m = 0.9
I0325 05:31:37.849566 29022 solver.cpp:314] Iteration 24500 (1.28944 iter/s, 77.5533s/100 iter), loss = 3.21351
I0325 05:31:37.849715 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.28381 (* 1 = 3.28381 loss)
I0325 05:31:37.849752 29022 sgd_solver.cpp:136] Iteration 24500, lr = 0.000122549, m = 0.9
I0325 05:32:54.653880 29022 solver.cpp:314] Iteration 24600 (1.30205 iter/s, 76.8018s/100 iter), loss = 3.22306
I0325 05:32:54.654040 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.58892 (* 1 = 3.58892 loss)
I0325 05:32:54.654057 29022 sgd_solver.cpp:136] Iteration 24600, lr = 0.000121174, m = 0.9
I0325 05:34:10.241286 29022 solver.cpp:314] Iteration 24700 (1.32301 iter/s, 75.585s/100 iter), loss = 3.09539
I0325 05:34:10.241478 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.33962 (* 1 = 3.33962 loss)
I0325 05:34:10.241513 29022 sgd_solver.cpp:136] Iteration 24700, lr = 0.00011981, m = 0.9
I0325 05:35:26.489850 29022 solver.cpp:314] Iteration 24800 (1.31154 iter/s, 76.2461s/100 iter), loss = 3.23228
I0325 05:35:26.490010 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.72963 (* 1 = 3.72963 loss)
I0325 05:35:26.490044 29022 sgd_solver.cpp:136] Iteration 24800, lr = 0.000118458, m = 0.9
I0325 05:36:42.973266 29022 solver.cpp:314] Iteration 24900 (1.30751 iter/s, 76.481s/100 iter), loss = 3.11635
I0325 05:36:42.973361 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.44456 (* 1 = 2.44456 loss)
I0325 05:36:42.973379 29022 sgd_solver.cpp:136] Iteration 24900, lr = 0.000117118, m = 0.9
I0325 05:37:58.902148 29022 solver.cpp:314] Iteration 25000 (1.31706 iter/s, 75.9265s/100 iter), loss = 3.22269
I0325 05:37:58.902604 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.60102 (* 1 = 2.60102 loss)
I0325 05:37:58.902917 29022 sgd_solver.cpp:136] Iteration 25000, lr = 0.000115789, m = 0.9
I0325 05:39:16.389991 29022 solver.cpp:314] Iteration 25100 (1.29057 iter/s, 77.4854s/100 iter), loss = 3.23664
I0325 05:39:16.390264 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.55692 (* 1 = 2.55692 loss)
I0325 05:39:16.390300 29022 sgd_solver.cpp:136] Iteration 25100, lr = 0.000114471, m = 0.9
I0325 05:40:33.551671 29022 solver.cpp:314] Iteration 25200 (1.29602 iter/s, 77.1592s/100 iter), loss = 3.25975
I0325 05:40:33.551821 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.24771 (* 1 = 3.24771 loss)
I0325 05:40:33.551858 29022 sgd_solver.cpp:136] Iteration 25200, lr = 0.000113165, m = 0.9
I0325 05:41:50.307027 29022 solver.cpp:314] Iteration 25300 (1.30288 iter/s, 76.7529s/100 iter), loss = 3.16593
I0325 05:41:50.307163 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.0503 (* 1 = 4.0503 loss)
I0325 05:41:50.307198 29022 sgd_solver.cpp:136] Iteration 25300, lr = 0.00011187, m = 0.9
I0325 05:43:06.489610 29022 solver.cpp:314] Iteration 25400 (1.31268 iter/s, 76.1801s/100 iter), loss = 3.11063
I0325 05:43:06.489766 29022 solver.cpp:336]     Train net output #0: mbox_loss = 5.6339 (* 1 = 5.6339 loss)
I0325 05:43:06.489800 29022 sgd_solver.cpp:136] Iteration 25400, lr = 0.000110586, m = 0.9
I0325 05:44:22.189879 29022 solver.cpp:314] Iteration 25500 (1.32104 iter/s, 75.6978s/100 iter), loss = 3.24075
I0325 05:44:22.190024 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.79705 (* 1 = 2.79705 loss)
I0325 05:44:22.190066 29022 sgd_solver.cpp:136] Iteration 25500, lr = 0.000109313, m = 0.9
I0325 05:45:39.671452 29022 solver.cpp:314] Iteration 25600 (1.29067 iter/s, 77.4791s/100 iter), loss = 3.29344
I0325 05:45:39.674194 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.81472 (* 1 = 2.81472 loss)
I0325 05:45:39.674536 29022 sgd_solver.cpp:136] Iteration 25600, lr = 0.000108051, m = 0.9
I0325 05:46:54.902565 29022 solver.cpp:314] Iteration 25700 (1.32928 iter/s, 75.2287s/100 iter), loss = 3.17518
I0325 05:46:54.902693 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.35034 (* 1 = 3.35034 loss)
I0325 05:46:54.902726 29022 sgd_solver.cpp:136] Iteration 25700, lr = 0.0001068, m = 0.9
I0325 05:48:10.863260 29022 solver.cpp:314] Iteration 25800 (1.31651 iter/s, 75.9583s/100 iter), loss = 3.01945
I0325 05:48:10.863384 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.8021 (* 1 = 2.8021 loss)
I0325 05:48:10.863401 29022 sgd_solver.cpp:136] Iteration 25800, lr = 0.00010556, m = 0.9
I0325 05:49:25.921726 29022 solver.cpp:314] Iteration 25900 (1.33234 iter/s, 75.056s/100 iter), loss = 3.10082
I0325 05:49:25.921898 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.57492 (* 1 = 2.57492 loss)
I0325 05:49:25.921936 29022 sgd_solver.cpp:136] Iteration 25900, lr = 0.000104331, m = 0.9
I0325 05:50:42.750418 29022 solver.cpp:360] Sparsity after update:
I0325 05:50:42.753710 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 05:50:42.753729 29022 net.cpp:2200] conv1a_param_0(0.397) 
I0325 05:50:42.753744 29022 net.cpp:2200] conv1b_param_0(0.68) 
I0325 05:50:42.753754 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 05:50:42.753762 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 05:50:42.753772 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 05:50:42.753779 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 05:50:42.753788 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 05:50:42.753796 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 05:50:42.753804 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 05:50:42.753813 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 05:50:42.753821 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 05:50:42.753829 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 05:50:42.753837 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 05:50:42.753846 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 05:50:42.753854 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 05:50:42.753862 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 05:50:42.753870 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 05:50:42.753878 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 05:50:42.753886 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 05:50:42.753895 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 05:50:42.753903 29022 net.cpp:2200] res2a_branch2a_param_0(0.723) 
I0325 05:50:42.753911 29022 net.cpp:2200] res2a_branch2b_param_0(0.571) 
I0325 05:50:42.753921 29022 net.cpp:2200] res3a_branch2a_param_0(0.675) 
I0325 05:50:42.753935 29022 net.cpp:2200] res3a_branch2b_param_0(0.647) 
I0325 05:50:42.753944 29022 net.cpp:2200] res4a_branch2a_param_0(0.754) 
I0325 05:50:42.753953 29022 net.cpp:2200] res4a_branch2b_param_0(0.701) 
I0325 05:50:42.753962 29022 net.cpp:2200] res5a_branch2a_param_0(0.786) 
I0325 05:50:42.753970 29022 net.cpp:2200] res5a_branch2b_param_0(0.796) 
I0325 05:50:42.753978 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.81684e+06/3.10435e+06) 0.585
I0325 05:50:42.754004 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_26000.caffemodel
I0325 05:50:42.779407 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_26000.solverstate
I0325 05:50:42.791702 29022 solver.cpp:678] Iteration 26000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.242631
j:  : 4 : max_pr:  : 0.45571
j:  : 3 : max_pr:  : 0.593327
j:  : 2 : max_pr:  : 0.705928
j:  : 1 : max_pr:  : 0.844807
j:  : 0 : max_pr:  : 1
I0325 05:52:06.156965 29022 solver.cpp:786] class AP 1: 0.349309
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.145312
j:  : 7 : max_pr:  : 0.329369
j:  : 6 : max_pr:  : 0.551506
j:  : 5 : max_pr:  : 0.620647
j:  : 4 : max_pr:  : 0.730454
j:  : 3 : max_pr:  : 0.783609
j:  : 2 : max_pr:  : 0.983687
j:  : 1 : max_pr:  : 0.997866
j:  : 0 : max_pr:  : 1
I0325 05:52:06.256379 29022 solver.cpp:786] class AP 2: 0.558405
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.499139
j:  : 6 : max_pr:  : 0.653528
j:  : 5 : max_pr:  : 0.749308
j:  : 4 : max_pr:  : 0.832705
j:  : 3 : max_pr:  : 0.918396
j:  : 2 : max_pr:  : 0.965712
j:  : 1 : max_pr:  : 0.996223
j:  : 0 : max_pr:  : 1
I0325 05:52:06.276995 29022 solver.cpp:786] class AP 3: 0.601365
I0325 05:52:06.277009 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.503026
I0325 05:52:06.277084 29022 solver.cpp:265] Tests completed in 83.4827s
I0325 05:52:06.827787 29022 solver.cpp:314] Iteration 26000 (0.621501 iter/s, 160.901s/100 iter), loss = 3.26746
I0325 05:52:06.827898 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.64691 (* 1 = 2.64691 loss)
I0325 05:52:06.827932 29022 sgd_solver.cpp:136] Iteration 26000, lr = 0.000103112, m = 0.9
I0325 05:53:22.613242 29022 solver.cpp:314] Iteration 26100 (1.31956 iter/s, 75.783s/100 iter), loss = 2.9649
I0325 05:53:22.613405 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.63833 (* 1 = 3.63833 loss)
I0325 05:53:22.613423 29022 sgd_solver.cpp:136] Iteration 26100, lr = 0.000101905, m = 0.9
I0325 05:54:38.906136 29022 solver.cpp:314] Iteration 26200 (1.31078 iter/s, 76.2904s/100 iter), loss = 3.11724
I0325 05:54:38.906266 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.84972 (* 1 = 2.84972 loss)
I0325 05:54:38.906283 29022 sgd_solver.cpp:136] Iteration 26200, lr = 0.000100707, m = 0.9
I0325 05:55:55.053844 29022 solver.cpp:314] Iteration 26300 (1.31328 iter/s, 76.1453s/100 iter), loss = 3.16042
I0325 05:55:55.053956 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.19659 (* 1 = 2.19659 loss)
I0325 05:55:55.053972 29022 sgd_solver.cpp:136] Iteration 26300, lr = 9.9521e-05, m = 0.9
I0325 05:57:11.342811 29022 solver.cpp:314] Iteration 26400 (1.31085 iter/s, 76.2865s/100 iter), loss = 3.31442
I0325 05:57:11.345754 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.00673 (* 1 = 3.00673 loss)
I0325 05:57:11.345785 29022 sgd_solver.cpp:136] Iteration 26400, lr = 9.8345e-05, m = 0.9
I0325 05:58:27.071422 29022 solver.cpp:314] Iteration 26500 (1.32055 iter/s, 75.7262s/100 iter), loss = 3.12031
I0325 05:58:27.071537 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.04933 (* 1 = 3.04933 loss)
I0325 05:58:27.071557 29022 sgd_solver.cpp:136] Iteration 26500, lr = 9.71794e-05, m = 0.9
I0325 05:59:44.074523 29022 solver.cpp:314] Iteration 26600 (1.29869 iter/s, 77.0006s/100 iter), loss = 3.16669
I0325 05:59:44.074685 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.56759 (* 1 = 3.56759 loss)
I0325 05:59:44.074703 29022 sgd_solver.cpp:136] Iteration 26600, lr = 9.60242e-05, m = 0.9
I0325 06:00:59.537981 29022 solver.cpp:314] Iteration 26700 (1.32519 iter/s, 75.461s/100 iter), loss = 3.24058
I0325 06:00:59.538136 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.29698 (* 1 = 2.29698 loss)
I0325 06:00:59.538152 29022 sgd_solver.cpp:136] Iteration 26700, lr = 9.48794e-05, m = 0.9
I0325 06:01:47.294885 29042 data_reader.cpp:305] Starting prefetch of epoch 6
I0325 06:02:16.679186 29022 solver.cpp:314] Iteration 26800 (1.29637 iter/s, 77.1387s/100 iter), loss = 3.07583
I0325 06:02:16.679293 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.26514 (* 1 = 2.26514 loss)
I0325 06:02:16.679327 29022 sgd_solver.cpp:136] Iteration 26800, lr = 9.37448e-05, m = 0.9
I0325 06:03:33.951484 29022 solver.cpp:314] Iteration 26900 (1.29417 iter/s, 77.2698s/100 iter), loss = 3.0689
I0325 06:03:33.951973 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.45536 (* 1 = 2.45536 loss)
I0325 06:03:33.952284 29022 sgd_solver.cpp:136] Iteration 26900, lr = 9.26205e-05, m = 0.9
I0325 06:04:50.468708 29022 solver.cpp:314] Iteration 27000 (1.30694 iter/s, 76.5148s/100 iter), loss = 3.17158
I0325 06:04:50.468854 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.04898 (* 1 = 3.04898 loss)
I0325 06:04:50.468888 29022 sgd_solver.cpp:136] Iteration 27000, lr = 9.15063e-05, m = 0.9
I0325 06:06:06.850263 29022 solver.cpp:314] Iteration 27100 (1.30926 iter/s, 76.3791s/100 iter), loss = 3.24594
I0325 06:06:06.850406 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.26093 (* 1 = 3.26093 loss)
I0325 06:06:06.850442 29022 sgd_solver.cpp:136] Iteration 27100, lr = 9.04021e-05, m = 0.9
I0325 06:07:23.609743 29022 solver.cpp:314] Iteration 27200 (1.30281 iter/s, 76.757s/100 iter), loss = 3.07372
I0325 06:07:23.609938 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.80571 (* 1 = 3.80571 loss)
I0325 06:07:23.610011 29022 sgd_solver.cpp:136] Iteration 27200, lr = 8.9308e-05, m = 0.9
I0325 06:08:39.529804 29022 solver.cpp:314] Iteration 27300 (1.31722 iter/s, 75.9176s/100 iter), loss = 3.06862
I0325 06:08:39.529949 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.57798 (* 1 = 2.57798 loss)
I0325 06:08:39.529985 29022 sgd_solver.cpp:136] Iteration 27300, lr = 8.82238e-05, m = 0.9
I0325 06:09:56.237527 29022 solver.cpp:314] Iteration 27400 (1.30369 iter/s, 76.7053s/100 iter), loss = 3.14722
I0325 06:09:56.237628 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.53899 (* 1 = 3.53899 loss)
I0325 06:09:56.237642 29022 sgd_solver.cpp:136] Iteration 27400, lr = 8.71496e-05, m = 0.9
I0325 06:11:12.568815 29022 solver.cpp:314] Iteration 27500 (1.31012 iter/s, 76.3288s/100 iter), loss = 3.10716
I0325 06:11:12.568953 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.92416 (* 1 = 2.92416 loss)
I0325 06:11:12.568969 29022 sgd_solver.cpp:136] Iteration 27500, lr = 8.60852e-05, m = 0.9
I0325 06:12:29.799367 29022 solver.cpp:314] Iteration 27600 (1.29487 iter/s, 77.2281s/100 iter), loss = 3.08066
I0325 06:12:29.799491 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.47625 (* 1 = 3.47625 loss)
I0325 06:12:29.799517 29022 sgd_solver.cpp:136] Iteration 27600, lr = 8.50305e-05, m = 0.9
I0325 06:13:47.063119 29022 solver.cpp:314] Iteration 27700 (1.29431 iter/s, 77.2613s/100 iter), loss = 3.29924
I0325 06:13:47.072209 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.31141 (* 1 = 3.31141 loss)
I0325 06:13:47.072232 29022 sgd_solver.cpp:136] Iteration 27700, lr = 8.39856e-05, m = 0.9
I0325 06:15:04.584610 29022 solver.cpp:314] Iteration 27800 (1.29001 iter/s, 77.519s/100 iter), loss = 3.17942
I0325 06:15:04.584763 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.18797 (* 1 = 3.18797 loss)
I0325 06:15:04.584795 29022 sgd_solver.cpp:136] Iteration 27800, lr = 8.29504e-05, m = 0.9
I0325 06:16:21.516314 29022 solver.cpp:314] Iteration 27900 (1.2999 iter/s, 76.9292s/100 iter), loss = 3.16884
I0325 06:16:21.516414 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.62551 (* 1 = 4.62551 loss)
I0325 06:16:21.516427 29022 sgd_solver.cpp:136] Iteration 27900, lr = 8.19247e-05, m = 0.9
I0325 06:17:37.427718 29022 solver.cpp:360] Sparsity after update:
I0325 06:17:37.431085 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 06:17:37.431154 29022 net.cpp:2200] conv1a_param_0(0.397) 
I0325 06:17:37.431188 29022 net.cpp:2200] conv1b_param_0(0.68) 
I0325 06:17:37.431216 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 06:17:37.431241 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 06:17:37.431267 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 06:17:37.431291 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 06:17:37.431316 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 06:17:37.431341 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 06:17:37.431366 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 06:17:37.431393 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 06:17:37.431418 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 06:17:37.431443 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 06:17:37.431468 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 06:17:37.431493 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 06:17:37.431517 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 06:17:37.431542 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 06:17:37.431567 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 06:17:37.431593 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 06:17:37.431617 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 06:17:37.431643 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 06:17:37.431668 29022 net.cpp:2200] res2a_branch2a_param_0(0.723) 
I0325 06:17:37.431692 29022 net.cpp:2200] res2a_branch2b_param_0(0.571) 
I0325 06:17:37.431717 29022 net.cpp:2200] res3a_branch2a_param_0(0.675) 
I0325 06:17:37.431742 29022 net.cpp:2200] res3a_branch2b_param_0(0.647) 
I0325 06:17:37.431767 29022 net.cpp:2200] res4a_branch2a_param_0(0.754) 
I0325 06:17:37.431792 29022 net.cpp:2200] res4a_branch2b_param_0(0.701) 
I0325 06:17:37.431816 29022 net.cpp:2200] res5a_branch2a_param_0(0.786) 
I0325 06:17:37.431841 29022 net.cpp:2200] res5a_branch2b_param_0(0.796) 
I0325 06:17:37.431876 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.81684e+06/3.10435e+06) 0.585
I0325 06:17:37.431922 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_28000.caffemodel
I0325 06:17:37.458353 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_28000.solverstate
I0325 06:17:37.467689 29022 solver.cpp:678] Iteration 28000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.235267
j:  : 4 : max_pr:  : 0.455926
j:  : 3 : max_pr:  : 0.5945
j:  : 2 : max_pr:  : 0.709087
j:  : 1 : max_pr:  : 0.846369
j:  : 0 : max_pr:  : 1
I0325 06:19:00.698626 29022 solver.cpp:786] class AP 1: 0.349195
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.166124
j:  : 7 : max_pr:  : 0.325851
j:  : 6 : max_pr:  : 0.556327
j:  : 5 : max_pr:  : 0.63034
j:  : 4 : max_pr:  : 0.73306
j:  : 3 : max_pr:  : 0.781425
j:  : 2 : max_pr:  : 0.982582
j:  : 1 : max_pr:  : 0.997843
j:  : 0 : max_pr:  : 1
I0325 06:19:00.797019 29022 solver.cpp:786] class AP 2: 0.561232
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.493227
j:  : 6 : max_pr:  : 0.654635
j:  : 5 : max_pr:  : 0.747384
j:  : 4 : max_pr:  : 0.831058
j:  : 3 : max_pr:  : 0.914546
j:  : 2 : max_pr:  : 0.966518
j:  : 1 : max_pr:  : 0.996831
j:  : 0 : max_pr:  : 1
I0325 06:19:00.819202 29022 solver.cpp:786] class AP 3: 0.600382
I0325 06:19:00.819216 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.503603
I0325 06:19:00.819298 29022 solver.cpp:265] Tests completed in 83.3489s
I0325 06:19:01.389677 29022 solver.cpp:314] Iteration 28000 (0.625515 iter/s, 159.868s/100 iter), loss = 3.15447
I0325 06:19:01.389768 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.02727 (* 1 = 3.02727 loss)
I0325 06:19:01.389801 29022 sgd_solver.cpp:136] Iteration 28000, lr = 8.09086e-05, m = 0.9
I0325 06:20:16.853423 29022 solver.cpp:314] Iteration 28100 (1.32518 iter/s, 75.4613s/100 iter), loss = 3.12157
I0325 06:20:16.853704 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.42668 (* 1 = 2.42668 loss)
I0325 06:20:16.853744 29022 sgd_solver.cpp:136] Iteration 28100, lr = 7.9902e-05, m = 0.9
I0325 06:21:33.197021 29022 solver.cpp:314] Iteration 28200 (1.30991 iter/s, 76.3411s/100 iter), loss = 3.21225
I0325 06:21:33.197166 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.98526 (* 1 = 2.98526 loss)
I0325 06:21:33.197203 29022 sgd_solver.cpp:136] Iteration 28200, lr = 7.89048e-05, m = 0.9
I0325 06:22:49.251870 29022 solver.cpp:314] Iteration 28300 (1.31488 iter/s, 76.0524s/100 iter), loss = 3.0586
I0325 06:22:49.252002 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.63053 (* 1 = 2.63053 loss)
I0325 06:22:49.252037 29022 sgd_solver.cpp:136] Iteration 28300, lr = 7.7917e-05, m = 0.9
I0325 06:24:05.281750 29022 solver.cpp:314] Iteration 28400 (1.31531 iter/s, 76.0274s/100 iter), loss = 3.18121
I0325 06:24:05.284381 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.89535 (* 1 = 3.89535 loss)
I0325 06:24:05.284404 29022 sgd_solver.cpp:136] Iteration 28400, lr = 7.69384e-05, m = 0.9
I0325 06:25:22.110041 29022 solver.cpp:314] Iteration 28500 (1.30165 iter/s, 76.8258s/100 iter), loss = 3.22687
I0325 06:25:22.110180 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.43668 (* 1 = 2.43668 loss)
I0325 06:25:22.110214 29022 sgd_solver.cpp:136] Iteration 28500, lr = 7.59691e-05, m = 0.9
I0325 06:26:39.854498 29022 solver.cpp:314] Iteration 28600 (1.28631 iter/s, 77.742s/100 iter), loss = 3.10253
I0325 06:26:39.854638 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.37495 (* 1 = 3.37495 loss)
I0325 06:26:39.854650 29022 sgd_solver.cpp:136] Iteration 28600, lr = 7.5009e-05, m = 0.9
I0325 06:27:57.250823 29022 solver.cpp:314] Iteration 28700 (1.29209 iter/s, 77.3938s/100 iter), loss = 3.03575
I0325 06:27:57.250929 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.52748 (* 1 = 2.52748 loss)
I0325 06:27:57.250946 29022 sgd_solver.cpp:136] Iteration 28700, lr = 7.40581e-05, m = 0.9
I0325 06:29:13.683166 29022 solver.cpp:314] Iteration 28800 (1.30839 iter/s, 76.4299s/100 iter), loss = 3.17714
I0325 06:29:13.685787 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.80253 (* 1 = 2.80253 loss)
I0325 06:29:13.685827 29022 sgd_solver.cpp:136] Iteration 28800, lr = 7.31162e-05, m = 0.9
I0325 06:30:30.921602 29022 solver.cpp:314] Iteration 28900 (1.29473 iter/s, 77.236s/100 iter), loss = 3.47491
I0325 06:30:30.922211 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.32979 (* 1 = 3.32979 loss)
I0325 06:30:30.922724 29022 sgd_solver.cpp:136] Iteration 28900, lr = 7.21833e-05, m = 0.9
I0325 06:31:46.561887 29022 solver.cpp:314] Iteration 29000 (1.32209 iter/s, 75.6379s/100 iter), loss = 3.20073
I0325 06:31:46.562011 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.29728 (* 1 = 3.29728 loss)
I0325 06:31:46.562023 29022 sgd_solver.cpp:136] Iteration 29000, lr = 7.12593e-05, m = 0.9
I0325 06:33:02.128103 29022 solver.cpp:314] Iteration 29100 (1.32339 iter/s, 75.5638s/100 iter), loss = 3.17638
I0325 06:33:02.128218 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.72067 (* 1 = 2.72067 loss)
I0325 06:33:02.128232 29022 sgd_solver.cpp:136] Iteration 29100, lr = 7.03443e-05, m = 0.9
I0325 06:34:18.134935 29022 solver.cpp:314] Iteration 29200 (1.31571 iter/s, 76.0044s/100 iter), loss = 3.11197
I0325 06:34:18.135146 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.69863 (* 1 = 2.69863 loss)
I0325 06:34:18.135196 29022 sgd_solver.cpp:136] Iteration 29200, lr = 6.94381e-05, m = 0.9
I0325 06:35:34.977547 29022 solver.cpp:314] Iteration 29300 (1.3014 iter/s, 76.8402s/100 iter), loss = 3.28599
I0325 06:35:34.977671 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.52624 (* 1 = 3.52624 loss)
I0325 06:35:34.977699 29022 sgd_solver.cpp:136] Iteration 29300, lr = 6.85407e-05, m = 0.9
I0325 06:36:51.041019 29022 solver.cpp:314] Iteration 29400 (1.31473 iter/s, 76.061s/100 iter), loss = 2.99193
I0325 06:36:51.041159 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.76266 (* 1 = 2.76266 loss)
I0325 06:36:51.041194 29022 sgd_solver.cpp:136] Iteration 29400, lr = 6.7652e-05, m = 0.9
I0325 06:38:07.954509 29022 solver.cpp:314] Iteration 29500 (1.3002 iter/s, 76.911s/100 iter), loss = 3.27601
I0325 06:38:07.954607 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.97123 (* 1 = 3.97123 loss)
I0325 06:38:07.954620 29022 sgd_solver.cpp:136] Iteration 29500, lr = 6.6772e-05, m = 0.9
I0325 06:39:24.198709 29022 solver.cpp:314] Iteration 29600 (1.31162 iter/s, 76.2418s/100 iter), loss = 3.19301
I0325 06:39:24.198850 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.66919 (* 1 = 2.66919 loss)
I0325 06:39:24.198885 29022 sgd_solver.cpp:136] Iteration 29600, lr = 6.59006e-05, m = 0.9
I0325 06:40:40.828701 29022 solver.cpp:314] Iteration 29700 (1.30501 iter/s, 76.6275s/100 iter), loss = 3.2308
I0325 06:40:40.828804 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.46817 (* 1 = 3.46817 loss)
I0325 06:40:40.828819 29022 sgd_solver.cpp:136] Iteration 29700, lr = 6.50377e-05, m = 0.9
I0325 06:41:57.263192 29022 solver.cpp:314] Iteration 29800 (1.30835 iter/s, 76.432s/100 iter), loss = 3.20616
I0325 06:41:57.265728 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.55476 (* 1 = 3.55476 loss)
I0325 06:41:57.265745 29022 sgd_solver.cpp:136] Iteration 29800, lr = 6.41834e-05, m = 0.9
I0325 06:43:06.433972 29042 data_reader.cpp:305] Starting prefetch of epoch 7
I0325 06:43:14.587828 29022 solver.cpp:314] Iteration 29900 (1.29329 iter/s, 77.3222s/100 iter), loss = 3.11862
I0325 06:43:14.587934 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.1351 (* 1 = 2.1351 loss)
I0325 06:43:14.587968 29022 sgd_solver.cpp:136] Iteration 29900, lr = 6.33375e-05, m = 0.9
I0325 06:44:30.219300 29022 solver.cpp:360] Sparsity after update:
I0325 06:44:30.222434 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 06:44:30.222486 29022 net.cpp:2200] conv1a_param_0(0.397) 
I0325 06:44:30.222523 29022 net.cpp:2200] conv1b_param_0(0.68) 
I0325 06:44:30.222551 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 06:44:30.222579 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 06:44:30.222607 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 06:44:30.222635 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 06:44:30.222663 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 06:44:30.222692 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 06:44:30.222719 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 06:44:30.222745 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 06:44:30.222774 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 06:44:30.222800 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 06:44:30.222828 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 06:44:30.222856 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 06:44:30.222883 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 06:44:30.222911 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 06:44:30.222939 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 06:44:30.222965 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 06:44:30.222992 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 06:44:30.223021 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 06:44:30.223047 29022 net.cpp:2200] res2a_branch2a_param_0(0.723) 
I0325 06:44:30.223074 29022 net.cpp:2200] res2a_branch2b_param_0(0.571) 
I0325 06:44:30.223103 29022 net.cpp:2200] res3a_branch2a_param_0(0.675) 
I0325 06:44:30.223129 29022 net.cpp:2200] res3a_branch2b_param_0(0.647) 
I0325 06:44:30.223156 29022 net.cpp:2200] res4a_branch2a_param_0(0.754) 
I0325 06:44:30.223186 29022 net.cpp:2200] res4a_branch2b_param_0(0.701) 
I0325 06:44:30.223213 29022 net.cpp:2200] res5a_branch2a_param_0(0.786) 
I0325 06:44:30.223242 29022 net.cpp:2200] res5a_branch2b_param_0(0.796) 
I0325 06:44:30.223269 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.81684e+06/3.10435e+06) 0.585
I0325 06:44:30.223315 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_30000.caffemodel
I0325 06:44:30.249661 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_30000.solverstate
I0325 06:44:30.262761 29022 solver.cpp:678] Iteration 30000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.250637
j:  : 4 : max_pr:  : 0.460236
j:  : 3 : max_pr:  : 0.596433
j:  : 2 : max_pr:  : 0.709918
j:  : 1 : max_pr:  : 0.846584
j:  : 0 : max_pr:  : 1
I0325 06:45:53.644701 29022 solver.cpp:786] class AP 1: 0.351255
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.164783
j:  : 7 : max_pr:  : 0.323774
j:  : 6 : max_pr:  : 0.554714
j:  : 5 : max_pr:  : 0.630272
j:  : 4 : max_pr:  : 0.733702
j:  : 3 : max_pr:  : 0.783495
j:  : 2 : max_pr:  : 0.984814
j:  : 1 : max_pr:  : 0.998079
j:  : 0 : max_pr:  : 1
I0325 06:45:53.741305 29022 solver.cpp:786] class AP 2: 0.561239
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.4856
j:  : 6 : max_pr:  : 0.652505
j:  : 5 : max_pr:  : 0.747875
j:  : 4 : max_pr:  : 0.832213
j:  : 3 : max_pr:  : 0.913217
j:  : 2 : max_pr:  : 0.965041
j:  : 1 : max_pr:  : 0.996089
j:  : 0 : max_pr:  : 1
I0325 06:45:53.763406 29022 solver.cpp:786] class AP 3: 0.599322
I0325 06:45:53.763422 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.503939
I0325 06:45:53.763463 29022 solver.cpp:265] Tests completed in 83.498s
I0325 06:45:54.313176 29022 solver.cpp:314] Iteration 30000 (0.626095 iter/s, 159.72s/100 iter), loss = 3.3285
I0325 06:45:54.313266 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.36362 (* 1 = 3.36362 loss)
I0325 06:45:54.313302 29022 sgd_solver.cpp:136] Iteration 30000, lr = 6.25e-05, m = 0.9
I0325 06:47:10.026790 29022 solver.cpp:314] Iteration 30100 (1.32081 iter/s, 75.7112s/100 iter), loss = 3.20637
I0325 06:47:10.027256 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.12685 (* 1 = 3.12685 loss)
I0325 06:47:10.027567 29022 sgd_solver.cpp:136] Iteration 30100, lr = 6.16708e-05, m = 0.9
I0325 06:48:25.120352 29022 solver.cpp:314] Iteration 30200 (1.33172 iter/s, 75.0911s/100 iter), loss = 3.1956
I0325 06:48:25.120479 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.18408 (* 1 = 3.18408 loss)
I0325 06:48:25.120512 29022 sgd_solver.cpp:136] Iteration 30200, lr = 6.08499e-05, m = 0.9
I0325 06:49:40.355330 29022 solver.cpp:314] Iteration 30300 (1.32921 iter/s, 75.2326s/100 iter), loss = 3.16334
I0325 06:49:40.355469 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.56632 (* 1 = 3.56632 loss)
I0325 06:49:40.355504 29022 sgd_solver.cpp:136] Iteration 30300, lr = 6.00373e-05, m = 0.9
I0325 06:50:55.675015 29022 solver.cpp:314] Iteration 30400 (1.32772 iter/s, 75.3173s/100 iter), loss = 3.07938
I0325 06:50:55.675143 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.43265 (* 1 = 2.43265 loss)
I0325 06:50:55.675163 29022 sgd_solver.cpp:136] Iteration 30400, lr = 5.92327e-05, m = 0.9
I0325 06:52:12.273622 29022 solver.cpp:314] Iteration 30500 (1.30555 iter/s, 76.5961s/100 iter), loss = 3.19616
I0325 06:52:12.273764 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.34211 (* 1 = 4.34211 loss)
I0325 06:52:12.273782 29022 sgd_solver.cpp:136] Iteration 30500, lr = 5.84364e-05, m = 0.9
I0325 06:53:28.208714 29022 solver.cpp:314] Iteration 30600 (1.31696 iter/s, 75.9326s/100 iter), loss = 3.18869
I0325 06:53:28.208870 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.61496 (* 1 = 2.61496 loss)
I0325 06:53:28.208890 29022 sgd_solver.cpp:136] Iteration 30600, lr = 5.7648e-05, m = 0.9
I0325 06:54:44.834698 29022 solver.cpp:314] Iteration 30700 (1.30508 iter/s, 76.6235s/100 iter), loss = 3.37073
I0325 06:54:44.834851 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.31013 (* 1 = 3.31013 loss)
I0325 06:54:44.834868 29022 sgd_solver.cpp:136] Iteration 30700, lr = 5.68677e-05, m = 0.9
I0325 06:56:00.461882 29022 solver.cpp:314] Iteration 30800 (1.32232 iter/s, 75.6248s/100 iter), loss = 3.08601
I0325 06:56:00.462028 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.2284 (* 1 = 3.2284 loss)
I0325 06:56:00.462062 29022 sgd_solver.cpp:136] Iteration 30800, lr = 5.60953e-05, m = 0.9
I0325 06:57:16.179033 29022 solver.cpp:314] Iteration 30900 (1.32075 iter/s, 75.7147s/100 iter), loss = 3.19204
I0325 06:57:16.179185 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.21761 (* 1 = 3.21761 loss)
I0325 06:57:16.179222 29022 sgd_solver.cpp:136] Iteration 30900, lr = 5.53308e-05, m = 0.9
I0325 06:58:31.113025 29022 solver.cpp:314] Iteration 31000 (1.33455 iter/s, 74.9316s/100 iter), loss = 3.24612
I0325 06:58:31.113163 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.02214 (* 1 = 2.02214 loss)
I0325 06:58:31.113198 29022 sgd_solver.cpp:136] Iteration 31000, lr = 5.45742e-05, m = 0.9
I0325 06:59:46.988845 29022 solver.cpp:314] Iteration 31100 (1.31799 iter/s, 75.8734s/100 iter), loss = 3.25152
I0325 06:59:46.989318 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.7686 (* 1 = 2.7686 loss)
I0325 06:59:46.989622 29022 sgd_solver.cpp:136] Iteration 31100, lr = 5.38253e-05, m = 0.9
I0325 07:01:04.165665 29022 solver.cpp:314] Iteration 31200 (1.29577 iter/s, 77.1743s/100 iter), loss = 3.16095
I0325 07:01:04.165822 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.74678 (* 1 = 2.74678 loss)
I0325 07:01:04.165865 29022 sgd_solver.cpp:136] Iteration 31200, lr = 5.30842e-05, m = 0.9
I0325 07:02:20.264502 29022 solver.cpp:314] Iteration 31300 (1.31412 iter/s, 76.0964s/100 iter), loss = 3.147
I0325 07:02:20.264614 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.97788 (* 1 = 2.97788 loss)
I0325 07:02:20.264633 29022 sgd_solver.cpp:136] Iteration 31300, lr = 5.23507e-05, m = 0.9
I0325 07:03:37.228262 29022 solver.cpp:314] Iteration 31400 (1.29935 iter/s, 76.9613s/100 iter), loss = 3.30884
I0325 07:03:37.228353 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.29369 (* 1 = 3.29369 loss)
I0325 07:03:37.228365 29022 sgd_solver.cpp:136] Iteration 31400, lr = 5.16249e-05, m = 0.9
I0325 07:04:55.573827 29022 solver.cpp:314] Iteration 31500 (1.27644 iter/s, 78.343s/100 iter), loss = 3.13081
I0325 07:04:55.573992 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.08674 (* 1 = 3.08674 loss)
I0325 07:04:55.574012 29022 sgd_solver.cpp:136] Iteration 31500, lr = 5.09067e-05, m = 0.9
I0325 07:06:12.604780 29022 solver.cpp:314] Iteration 31600 (1.29822 iter/s, 77.0285s/100 iter), loss = 3.13915
I0325 07:06:12.604938 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.22597 (* 1 = 3.22597 loss)
I0325 07:06:12.604974 29022 sgd_solver.cpp:136] Iteration 31600, lr = 5.01959e-05, m = 0.9
I0325 07:07:29.775750 29022 solver.cpp:314] Iteration 31700 (1.29587 iter/s, 77.1685s/100 iter), loss = 3.15063
I0325 07:07:29.775894 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.91907 (* 1 = 3.91907 loss)
I0325 07:07:29.775930 29022 sgd_solver.cpp:136] Iteration 31700, lr = 4.94927e-05, m = 0.9
I0325 07:08:46.940937 29022 solver.cpp:314] Iteration 31800 (1.29596 iter/s, 77.1627s/100 iter), loss = 3.17793
I0325 07:08:46.941082 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.16951 (* 1 = 4.16951 loss)
I0325 07:08:46.941103 29022 sgd_solver.cpp:136] Iteration 31800, lr = 4.87968e-05, m = 0.9
I0325 07:10:03.298185 29022 solver.cpp:314] Iteration 31900 (1.30968 iter/s, 76.3548s/100 iter), loss = 3.18315
I0325 07:10:03.298372 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.3824 (* 1 = 2.3824 loss)
I0325 07:10:03.298409 29022 sgd_solver.cpp:136] Iteration 31900, lr = 4.81083e-05, m = 0.9
I0325 07:11:19.752568 29022 solver.cpp:360] Sparsity after update:
I0325 07:11:19.754987 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 07:11:19.755012 29022 net.cpp:2200] conv1a_param_0(0.397) 
I0325 07:11:19.755030 29022 net.cpp:2200] conv1b_param_0(0.68) 
I0325 07:11:19.755043 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 07:11:19.755053 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 07:11:19.755064 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 07:11:19.755074 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 07:11:19.755084 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 07:11:19.755095 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 07:11:19.755105 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 07:11:19.755115 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 07:11:19.755132 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 07:11:19.755144 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 07:11:19.755158 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 07:11:19.755174 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 07:11:19.755189 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 07:11:19.755205 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 07:11:19.755218 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 07:11:19.755230 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 07:11:19.755244 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 07:11:19.755255 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 07:11:19.755268 29022 net.cpp:2200] res2a_branch2a_param_0(0.723) 
I0325 07:11:19.755280 29022 net.cpp:2200] res2a_branch2b_param_0(0.571) 
I0325 07:11:19.755293 29022 net.cpp:2200] res3a_branch2a_param_0(0.675) 
I0325 07:11:19.755304 29022 net.cpp:2200] res3a_branch2b_param_0(0.647) 
I0325 07:11:19.755314 29022 net.cpp:2200] res4a_branch2a_param_0(0.754) 
I0325 07:11:19.755326 29022 net.cpp:2200] res4a_branch2b_param_0(0.701) 
I0325 07:11:19.755336 29022 net.cpp:2200] res5a_branch2a_param_0(0.786) 
I0325 07:11:19.755347 29022 net.cpp:2200] res5a_branch2b_param_0(0.796) 
I0325 07:11:19.755357 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.81684e+06/3.10435e+06) 0.585
I0325 07:11:19.755393 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_32000.caffemodel
I0325 07:11:19.781200 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_32000.solverstate
I0325 07:11:19.793648 29022 solver.cpp:678] Iteration 32000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.236354
j:  : 4 : max_pr:  : 0.453973
j:  : 3 : max_pr:  : 0.590736
j:  : 2 : max_pr:  : 0.703057
j:  : 1 : max_pr:  : 0.84532
j:  : 0 : max_pr:  : 1
I0325 07:12:43.293918 29022 solver.cpp:786] class AP 1: 0.348131
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.162181
j:  : 7 : max_pr:  : 0.324667
j:  : 6 : max_pr:  : 0.548992
j:  : 5 : max_pr:  : 0.624565
j:  : 4 : max_pr:  : 0.726584
j:  : 3 : max_pr:  : 0.78014
j:  : 2 : max_pr:  : 0.983276
j:  : 1 : max_pr:  : 0.99767
j:  : 0 : max_pr:  : 1
I0325 07:12:43.390353 29022 solver.cpp:786] class AP 2: 0.558916
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.488822
j:  : 6 : max_pr:  : 0.650576
j:  : 5 : max_pr:  : 0.747874
j:  : 4 : max_pr:  : 0.833481
j:  : 3 : max_pr:  : 0.914951
j:  : 2 : max_pr:  : 0.965417
j:  : 1 : max_pr:  : 0.996501
j:  : 0 : max_pr:  : 1
I0325 07:12:43.412705 29022 solver.cpp:786] class AP 3: 0.599784
I0325 07:12:43.412724 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.502277
I0325 07:12:43.412768 29022 solver.cpp:265] Tests completed in 83.6164s
I0325 07:12:43.958741 29022 solver.cpp:314] Iteration 32000 (0.62245 iter/s, 160.655s/100 iter), loss = 3.22292
I0325 07:12:43.958789 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.52251 (* 1 = 3.52251 loss)
I0325 07:12:43.958802 29022 sgd_solver.cpp:136] Iteration 32000, lr = 4.74272e-05, m = 0.9
I0325 07:14:00.504212 29022 solver.cpp:314] Iteration 32100 (1.30646 iter/s, 76.543s/100 iter), loss = 3.01851
I0325 07:14:00.504365 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.84943 (* 1 = 2.84943 loss)
I0325 07:14:00.504401 29022 sgd_solver.cpp:136] Iteration 32100, lr = 4.67532e-05, m = 0.9
I0325 07:15:17.343921 29022 solver.cpp:314] Iteration 32200 (1.30145 iter/s, 76.8372s/100 iter), loss = 3.06866
I0325 07:15:17.344101 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.27261 (* 1 = 2.27261 loss)
I0325 07:15:17.344137 29022 sgd_solver.cpp:136] Iteration 32200, lr = 4.60865e-05, m = 0.9
I0325 07:16:34.016010 29022 solver.cpp:314] Iteration 32300 (1.3043 iter/s, 76.6696s/100 iter), loss = 3.33437
I0325 07:16:34.016160 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.40983 (* 1 = 3.40983 loss)
I0325 07:16:34.016196 29022 sgd_solver.cpp:136] Iteration 32300, lr = 4.5427e-05, m = 0.9
I0325 07:17:50.774595 29022 solver.cpp:314] Iteration 32400 (1.30283 iter/s, 76.7561s/100 iter), loss = 3.14739
I0325 07:17:50.774718 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.6801 (* 1 = 2.6801 loss)
I0325 07:17:50.774735 29022 sgd_solver.cpp:136] Iteration 32400, lr = 4.47746e-05, m = 0.9
I0325 07:19:08.435956 29022 solver.cpp:314] Iteration 32500 (1.28768 iter/s, 77.6589s/100 iter), loss = 3.10038
I0325 07:19:08.436398 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.53106 (* 1 = 3.53106 loss)
I0325 07:19:08.436710 29022 sgd_solver.cpp:136] Iteration 32500, lr = 4.41292e-05, m = 0.9
I0325 07:20:24.605129 29022 solver.cpp:314] Iteration 32600 (1.31291 iter/s, 76.1667s/100 iter), loss = 3.03032
I0325 07:20:24.605274 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.52948 (* 1 = 3.52948 loss)
I0325 07:20:24.605309 29022 sgd_solver.cpp:136] Iteration 32600, lr = 4.34908e-05, m = 0.9
I0325 07:21:18.287302 29042 data_reader.cpp:305] Starting prefetch of epoch 8
I0325 07:21:41.029609 29022 solver.cpp:314] Iteration 32700 (1.30852 iter/s, 76.422s/100 iter), loss = 3.10199
I0325 07:21:41.030051 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.76752 (* 1 = 3.76752 loss)
I0325 07:21:41.030350 29022 sgd_solver.cpp:136] Iteration 32700, lr = 4.28593e-05, m = 0.9
I0325 07:22:57.906741 29022 solver.cpp:314] Iteration 32800 (1.30082 iter/s, 76.8747s/100 iter), loss = 3.25718
I0325 07:22:57.906888 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.47639 (* 1 = 3.47639 loss)
I0325 07:22:57.906924 29022 sgd_solver.cpp:136] Iteration 32800, lr = 4.22348e-05, m = 0.9
I0325 07:24:14.314949 29022 solver.cpp:314] Iteration 32900 (1.3088 iter/s, 76.4058s/100 iter), loss = 3.1621
I0325 07:24:14.315434 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.14645 (* 1 = 4.14645 loss)
I0325 07:24:14.315750 29022 sgd_solver.cpp:136] Iteration 32900, lr = 4.16171e-05, m = 0.9
I0325 07:25:30.906940 29022 solver.cpp:314] Iteration 33000 (1.30566 iter/s, 76.5895s/100 iter), loss = 3.15323
I0325 07:25:30.907042 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.76207 (* 1 = 3.76207 loss)
I0325 07:25:30.907059 29022 sgd_solver.cpp:136] Iteration 33000, lr = 4.10062e-05, m = 0.9
I0325 07:26:47.331753 29022 solver.cpp:314] Iteration 33100 (1.30852 iter/s, 76.4224s/100 iter), loss = 3.0924
I0325 07:26:47.331858 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.1002 (* 1 = 3.1002 loss)
I0325 07:26:47.331876 29022 sgd_solver.cpp:136] Iteration 33100, lr = 4.04021e-05, m = 0.9
I0325 07:28:03.062810 29022 solver.cpp:314] Iteration 33200 (1.3205 iter/s, 75.7286s/100 iter), loss = 3.06651
I0325 07:28:03.062954 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.4689 (* 1 = 4.4689 loss)
I0325 07:28:03.062990 29022 sgd_solver.cpp:136] Iteration 33200, lr = 3.98047e-05, m = 0.9
I0325 07:29:18.296135 29022 solver.cpp:314] Iteration 33300 (1.32924 iter/s, 75.2309s/100 iter), loss = 3.2244
I0325 07:29:18.296306 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.44084 (* 1 = 2.44084 loss)
I0325 07:29:18.296325 29022 sgd_solver.cpp:136] Iteration 33300, lr = 3.92139e-05, m = 0.9
I0325 07:30:34.084028 29022 solver.cpp:314] Iteration 33400 (1.31951 iter/s, 75.7855s/100 iter), loss = 3.1312
I0325 07:30:34.084205 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.60349 (* 1 = 2.60349 loss)
I0325 07:30:34.084239 29022 sgd_solver.cpp:136] Iteration 33400, lr = 3.86297e-05, m = 0.9
I0325 07:31:51.748663 29022 solver.cpp:314] Iteration 33500 (1.28763 iter/s, 77.6621s/100 iter), loss = 3.12799
I0325 07:31:51.748798 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.16379 (* 1 = 3.16379 loss)
I0325 07:31:51.748831 29022 sgd_solver.cpp:136] Iteration 33500, lr = 3.80521e-05, m = 0.9
I0325 07:33:08.008154 29022 solver.cpp:314] Iteration 33600 (1.31135 iter/s, 76.257s/100 iter), loss = 3.23555
I0325 07:33:08.008288 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.39201 (* 1 = 3.39201 loss)
I0325 07:33:08.008322 29022 sgd_solver.cpp:136] Iteration 33600, lr = 3.7481e-05, m = 0.9
I0325 07:34:22.861552 29022 solver.cpp:314] Iteration 33700 (1.33599 iter/s, 74.851s/100 iter), loss = 3.13344
I0325 07:34:22.861702 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.70933 (* 1 = 3.70933 loss)
I0325 07:34:22.861742 29022 sgd_solver.cpp:136] Iteration 33700, lr = 3.69163e-05, m = 0.9
I0325 07:35:39.323384 29022 solver.cpp:314] Iteration 33800 (1.30788 iter/s, 76.4594s/100 iter), loss = 3.35057
I0325 07:35:39.323501 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.69214 (* 1 = 3.69214 loss)
I0325 07:35:39.323518 29022 sgd_solver.cpp:136] Iteration 33800, lr = 3.6358e-05, m = 0.9
I0325 07:36:55.103943 29022 solver.cpp:314] Iteration 33900 (1.31964 iter/s, 75.7781s/100 iter), loss = 3.14752
I0325 07:36:55.104084 29022 solver.cpp:336]     Train net output #0: mbox_loss = 5.27459 (* 1 = 5.27459 loss)
I0325 07:36:55.104118 29022 sgd_solver.cpp:136] Iteration 33900, lr = 3.58061e-05, m = 0.9
I0325 07:38:10.683837 29022 solver.cpp:360] Sparsity after update:
I0325 07:38:10.686456 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 07:38:10.686491 29022 net.cpp:2200] conv1a_param_0(0.397) 
I0325 07:38:10.686508 29022 net.cpp:2200] conv1b_param_0(0.68) 
I0325 07:38:10.686519 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 07:38:10.686528 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 07:38:10.686538 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 07:38:10.686548 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 07:38:10.686558 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 07:38:10.686568 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 07:38:10.686578 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 07:38:10.686589 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 07:38:10.686599 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 07:38:10.686609 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 07:38:10.686619 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 07:38:10.686630 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 07:38:10.686647 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 07:38:10.686659 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 07:38:10.686674 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 07:38:10.686686 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 07:38:10.686700 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 07:38:10.686717 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 07:38:10.686731 29022 net.cpp:2200] res2a_branch2a_param_0(0.723) 
I0325 07:38:10.686746 29022 net.cpp:2200] res2a_branch2b_param_0(0.571) 
I0325 07:38:10.686759 29022 net.cpp:2200] res3a_branch2a_param_0(0.675) 
I0325 07:38:10.686771 29022 net.cpp:2200] res3a_branch2b_param_0(0.647) 
I0325 07:38:10.686784 29022 net.cpp:2200] res4a_branch2a_param_0(0.754) 
I0325 07:38:10.686794 29022 net.cpp:2200] res4a_branch2b_param_0(0.701) 
I0325 07:38:10.686807 29022 net.cpp:2200] res5a_branch2a_param_0(0.786) 
I0325 07:38:10.686820 29022 net.cpp:2200] res5a_branch2b_param_0(0.796) 
I0325 07:38:10.686832 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.81684e+06/3.10435e+06) 0.585
I0325 07:38:10.686870 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_34000.caffemodel
I0325 07:38:10.709053 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_34000.solverstate
I0325 07:38:10.718230 29022 solver.cpp:678] Iteration 34000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.230408
j:  : 4 : max_pr:  : 0.450752
j:  : 3 : max_pr:  : 0.588324
j:  : 2 : max_pr:  : 0.703337
j:  : 1 : max_pr:  : 0.844171
j:  : 0 : max_pr:  : 1
I0325 07:39:34.176254 29022 solver.cpp:786] class AP 1: 0.346999
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.173168
j:  : 7 : max_pr:  : 0.323429
j:  : 6 : max_pr:  : 0.547247
j:  : 5 : max_pr:  : 0.62616
j:  : 4 : max_pr:  : 0.734287
j:  : 3 : max_pr:  : 0.781778
j:  : 2 : max_pr:  : 0.982961
j:  : 1 : max_pr:  : 0.997854
j:  : 0 : max_pr:  : 1
I0325 07:39:34.275610 29022 solver.cpp:786] class AP 2: 0.560626
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.485274
j:  : 6 : max_pr:  : 0.652301
j:  : 5 : max_pr:  : 0.749228
j:  : 4 : max_pr:  : 0.833333
j:  : 3 : max_pr:  : 0.915456
j:  : 2 : max_pr:  : 0.965091
j:  : 1 : max_pr:  : 0.996833
j:  : 0 : max_pr:  : 1
I0325 07:39:34.298553 29022 solver.cpp:786] class AP 3: 0.599774
I0325 07:39:34.298574 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.502466
I0325 07:39:34.298625 29022 solver.cpp:265] Tests completed in 83.5752s
I0325 07:39:34.826390 29022 solver.cpp:314] Iteration 34000 (0.626106 iter/s, 159.717s/100 iter), loss = 3.27006
I0325 07:39:34.826484 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.19803 (* 1 = 4.19803 loss)
I0325 07:39:34.826516 29022 sgd_solver.cpp:136] Iteration 34000, lr = 3.52605e-05, m = 0.9
I0325 07:40:51.443197 29022 solver.cpp:314] Iteration 34100 (1.30524 iter/s, 76.6143s/100 iter), loss = 3.1901
I0325 07:40:51.443346 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.66052 (* 1 = 2.66052 loss)
I0325 07:40:51.443364 29022 sgd_solver.cpp:136] Iteration 34100, lr = 3.47211e-05, m = 0.9
I0325 07:42:07.581050 29022 solver.cpp:314] Iteration 34200 (1.31345 iter/s, 76.1354s/100 iter), loss = 3.18775
I0325 07:42:07.581194 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.67495 (* 1 = 2.67495 loss)
I0325 07:42:07.581231 29022 sgd_solver.cpp:136] Iteration 34200, lr = 3.4188e-05, m = 0.9
I0325 07:43:25.014487 29022 solver.cpp:314] Iteration 34300 (1.29147 iter/s, 77.4309s/100 iter), loss = 3.09311
I0325 07:43:25.014638 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.98255 (* 1 = 2.98255 loss)
I0325 07:43:25.014679 29022 sgd_solver.cpp:136] Iteration 34300, lr = 3.3661e-05, m = 0.9
I0325 07:44:41.549726 29022 solver.cpp:314] Iteration 34400 (1.30663 iter/s, 76.5328s/100 iter), loss = 2.98684
I0325 07:44:41.549855 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.73151 (* 1 = 3.73151 loss)
I0325 07:44:41.549890 29022 sgd_solver.cpp:136] Iteration 34400, lr = 3.31402e-05, m = 0.9
I0325 07:45:58.427565 29022 solver.cpp:314] Iteration 34500 (1.30081 iter/s, 76.8754s/100 iter), loss = 3.13487
I0325 07:45:58.427671 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.87514 (* 1 = 2.87514 loss)
I0325 07:45:58.427690 29022 sgd_solver.cpp:136] Iteration 34500, lr = 3.26254e-05, m = 0.9
I0325 07:47:16.049674 29022 solver.cpp:314] Iteration 34600 (1.28833 iter/s, 77.6196s/100 iter), loss = 3.23828
I0325 07:47:16.049818 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.46288 (* 1 = 2.46288 loss)
I0325 07:47:16.049854 29022 sgd_solver.cpp:136] Iteration 34600, lr = 3.21166e-05, m = 0.9
I0325 07:48:34.905431 29022 solver.cpp:314] Iteration 34700 (1.26824 iter/s, 78.8493s/100 iter), loss = 3.23037
I0325 07:48:34.905575 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.95711 (* 1 = 3.95711 loss)
I0325 07:48:34.905612 29022 sgd_solver.cpp:136] Iteration 34700, lr = 3.16138e-05, m = 0.9
I0325 07:49:52.588809 29022 solver.cpp:314] Iteration 34800 (1.28732 iter/s, 77.6809s/100 iter), loss = 3.10201
I0325 07:49:52.588966 29022 solver.cpp:336]     Train net output #0: mbox_loss = 1.64001 (* 1 = 1.64001 loss)
I0325 07:49:52.588984 29022 sgd_solver.cpp:136] Iteration 34800, lr = 3.1117e-05, m = 0.9
I0325 07:51:11.194633 29022 solver.cpp:314] Iteration 34900 (1.27221 iter/s, 78.6033s/100 iter), loss = 3.18983
I0325 07:51:11.194772 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.40641 (* 1 = 4.40641 loss)
I0325 07:51:11.194808 29022 sgd_solver.cpp:136] Iteration 34900, lr = 3.0626e-05, m = 0.9
I0325 07:52:29.175312 29022 solver.cpp:314] Iteration 35000 (1.28241 iter/s, 77.9782s/100 iter), loss = 3.29453
I0325 07:52:29.175477 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.96029 (* 1 = 2.96029 loss)
I0325 07:52:29.175511 29022 sgd_solver.cpp:136] Iteration 35000, lr = 3.01408e-05, m = 0.9
I0325 07:53:47.016544 29022 solver.cpp:314] Iteration 35100 (1.28471 iter/s, 77.8387s/100 iter), loss = 3.24146
I0325 07:53:47.016650 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.0678 (* 1 = 4.0678 loss)
I0325 07:53:47.016928 29022 sgd_solver.cpp:136] Iteration 35100, lr = 2.96615e-05, m = 0.9
I0325 07:55:05.275423 29022 solver.cpp:314] Iteration 35200 (1.27785 iter/s, 78.2564s/100 iter), loss = 3.09469
I0325 07:55:05.275550 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.72141 (* 1 = 2.72141 loss)
I0325 07:55:05.275568 29022 sgd_solver.cpp:136] Iteration 35200, lr = 2.91878e-05, m = 0.9
I0325 07:56:25.752526 29022 solver.cpp:314] Iteration 35300 (1.24263 iter/s, 80.4745s/100 iter), loss = 3.10791
I0325 07:56:25.752688 29022 solver.cpp:336]     Train net output #0: mbox_loss = 1.67786 (* 1 = 1.67786 loss)
I0325 07:56:25.752725 29022 sgd_solver.cpp:136] Iteration 35300, lr = 2.87199e-05, m = 0.9
I0325 07:57:50.424595 29022 solver.cpp:314] Iteration 35400 (1.18106 iter/s, 84.6693s/100 iter), loss = 3.16985
I0325 07:57:50.424691 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.01861 (* 1 = 3.01861 loss)
I0325 07:57:50.424866 29022 sgd_solver.cpp:136] Iteration 35400, lr = 2.82576e-05, m = 0.9
I0325 07:59:08.976037 29022 solver.cpp:314] Iteration 35500 (1.27309 iter/s, 78.5489s/100 iter), loss = 3.34791
I0325 07:59:08.976202 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.9747 (* 1 = 3.9747 loss)
I0325 07:59:08.976239 29022 sgd_solver.cpp:136] Iteration 35500, lr = 2.78009e-05, m = 0.9
I0325 08:00:26.390837 29022 solver.cpp:314] Iteration 35600 (1.29178 iter/s, 77.4123s/100 iter), loss = 3.07842
I0325 08:00:26.390970 29022 solver.cpp:336]     Train net output #0: mbox_loss = 1.76575 (* 1 = 1.76575 loss)
I0325 08:00:26.391002 29022 sgd_solver.cpp:136] Iteration 35600, lr = 2.73498e-05, m = 0.9
I0325 08:01:44.692394 29022 solver.cpp:314] Iteration 35700 (1.27715 iter/s, 78.299s/100 iter), loss = 3.23837
I0325 08:01:44.692538 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.08265 (* 1 = 3.08265 loss)
I0325 08:01:44.692572 29022 sgd_solver.cpp:136] Iteration 35700, lr = 2.69042e-05, m = 0.9
I0325 08:03:02.514344 29042 data_reader.cpp:305] Starting prefetch of epoch 9
I0325 08:03:02.787309 29022 solver.cpp:314] Iteration 35800 (1.28053 iter/s, 78.0924s/100 iter), loss = 3.37301
I0325 08:03:02.787361 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.84389 (* 1 = 3.84389 loss)
I0325 08:03:02.787375 29022 sgd_solver.cpp:136] Iteration 35800, lr = 2.64641e-05, m = 0.9
I0325 08:04:21.419836 29022 solver.cpp:314] Iteration 35900 (1.27178 iter/s, 78.63s/100 iter), loss = 3.19768
I0325 08:04:21.419950 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.04167 (* 1 = 3.04167 loss)
I0325 08:04:21.419968 29022 sgd_solver.cpp:136] Iteration 35900, lr = 2.60293e-05, m = 0.9
I0325 08:05:40.242136 29022 solver.cpp:360] Sparsity after update:
I0325 08:05:40.245364 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 08:05:40.245419 29022 net.cpp:2200] conv1a_param_0(0.397) 
I0325 08:05:40.245455 29022 net.cpp:2200] conv1b_param_0(0.68) 
I0325 08:05:40.245482 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 08:05:40.245508 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 08:05:40.245538 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 08:05:40.245568 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 08:05:40.245596 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 08:05:40.245625 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 08:05:40.245654 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 08:05:40.245683 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 08:05:40.245723 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 08:05:40.245750 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 08:05:40.245779 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 08:05:40.245807 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 08:05:40.245836 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 08:05:40.245877 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 08:05:40.245906 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 08:05:40.245935 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 08:05:40.245964 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 08:05:40.245992 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 08:05:40.246019 29022 net.cpp:2200] res2a_branch2a_param_0(0.723) 
I0325 08:05:40.246047 29022 net.cpp:2200] res2a_branch2b_param_0(0.571) 
I0325 08:05:40.246078 29022 net.cpp:2200] res3a_branch2a_param_0(0.675) 
I0325 08:05:40.246105 29022 net.cpp:2200] res3a_branch2b_param_0(0.647) 
I0325 08:05:40.246134 29022 net.cpp:2200] res4a_branch2a_param_0(0.754) 
I0325 08:05:40.246162 29022 net.cpp:2200] res4a_branch2b_param_0(0.701) 
I0325 08:05:40.246191 29022 net.cpp:2200] res5a_branch2a_param_0(0.786) 
I0325 08:05:40.246218 29022 net.cpp:2200] res5a_branch2b_param_0(0.796) 
I0325 08:05:40.246248 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.81684e+06/3.10435e+06) 0.585
I0325 08:05:40.246294 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_36000.caffemodel
I0325 08:05:40.272918 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_36000.solverstate
I0325 08:05:40.285495 29022 solver.cpp:678] Iteration 36000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.242898
j:  : 4 : max_pr:  : 0.455893
j:  : 3 : max_pr:  : 0.592106
j:  : 2 : max_pr:  : 0.706989
j:  : 1 : max_pr:  : 0.847414
j:  : 0 : max_pr:  : 1
I0325 08:07:03.943765 29022 solver.cpp:786] class AP 1: 0.349573
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.166458
j:  : 7 : max_pr:  : 0.322122
j:  : 6 : max_pr:  : 0.549667
j:  : 5 : max_pr:  : 0.624554
j:  : 4 : max_pr:  : 0.734373
j:  : 3 : max_pr:  : 0.78767
j:  : 2 : max_pr:  : 0.983767
j:  : 1 : max_pr:  : 0.998004
j:  : 0 : max_pr:  : 1
I0325 08:07:04.045931 29022 solver.cpp:786] class AP 2: 0.560601
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.502472
j:  : 6 : max_pr:  : 0.659384
j:  : 5 : max_pr:  : 0.75508
j:  : 4 : max_pr:  : 0.837085
j:  : 3 : max_pr:  : 0.919286
j:  : 2 : max_pr:  : 0.966969
j:  : 1 : max_pr:  : 0.996587
j:  : 0 : max_pr:  : 1
I0325 08:07:04.067930 29022 solver.cpp:786] class AP 3: 0.603351
I0325 08:07:04.067946 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.504508
I0325 08:07:04.069085 29022 solver.cpp:265] Tests completed in 83.7809s
I0325 08:07:04.754957 29022 solver.cpp:314] Iteration 36000 (0.612258 iter/s, 163.33s/100 iter), loss = 3.00345
I0325 08:07:04.755054 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.7313 (* 1 = 4.7313 loss)
I0325 08:07:04.755089 29022 sgd_solver.cpp:136] Iteration 36000, lr = 2.56e-05, m = 0.9
I0325 08:08:23.531215 29022 solver.cpp:314] Iteration 36100 (1.26946 iter/s, 78.7737s/100 iter), loss = 3.23153
I0325 08:08:23.531363 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.84205 (* 1 = 3.84205 loss)
I0325 08:08:23.531399 29022 sgd_solver.cpp:136] Iteration 36100, lr = 2.5176e-05, m = 0.9
I0325 08:09:41.806175 29022 solver.cpp:314] Iteration 36200 (1.27759 iter/s, 78.2724s/100 iter), loss = 3.49513
I0325 08:09:41.806336 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.20273 (* 1 = 2.20273 loss)
I0325 08:09:41.806372 29022 sgd_solver.cpp:136] Iteration 36200, lr = 2.47573e-05, m = 0.9
I0325 08:10:59.738354 29022 solver.cpp:314] Iteration 36300 (1.28321 iter/s, 77.9297s/100 iter), loss = 3.24265
I0325 08:10:59.738498 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.8228 (* 1 = 3.8228 loss)
I0325 08:10:59.738533 29022 sgd_solver.cpp:136] Iteration 36300, lr = 2.43438e-05, m = 0.9
I0325 08:12:18.890444 29022 solver.cpp:314] Iteration 36400 (1.26343 iter/s, 79.1495s/100 iter), loss = 3.25603
I0325 08:12:18.890590 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.30832 (* 1 = 3.30832 loss)
I0325 08:12:18.890632 29022 sgd_solver.cpp:136] Iteration 36400, lr = 2.39355e-05, m = 0.9
I0325 08:13:36.779260 29022 solver.cpp:314] Iteration 36500 (1.28392 iter/s, 77.8863s/100 iter), loss = 3.29562
I0325 08:13:36.779420 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.9492 (* 1 = 3.9492 loss)
I0325 08:13:36.779438 29022 sgd_solver.cpp:136] Iteration 36500, lr = 2.35324e-05, m = 0.9
I0325 08:14:55.790248 29022 solver.cpp:314] Iteration 36600 (1.26569 iter/s, 79.0085s/100 iter), loss = 3.1005
I0325 08:14:55.790415 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.58895 (* 1 = 2.58895 loss)
I0325 08:14:55.790448 29022 sgd_solver.cpp:136] Iteration 36600, lr = 2.31344e-05, m = 0.9
I0325 08:16:14.080507 29022 solver.cpp:314] Iteration 36700 (1.27734 iter/s, 78.2877s/100 iter), loss = 3.11199
I0325 08:16:14.080682 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.88898 (* 1 = 2.88898 loss)
I0325 08:16:14.080723 29022 sgd_solver.cpp:136] Iteration 36700, lr = 2.27415e-05, m = 0.9
I0325 08:17:32.790447 29022 solver.cpp:314] Iteration 36800 (1.27053 iter/s, 78.7074s/100 iter), loss = 3.30378
I0325 08:17:32.790586 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.08056 (* 1 = 3.08056 loss)
I0325 08:17:32.790623 29022 sgd_solver.cpp:136] Iteration 36800, lr = 2.23536e-05, m = 0.9
I0325 08:18:50.511813 29022 solver.cpp:314] Iteration 36900 (1.28669 iter/s, 77.7189s/100 iter), loss = 3.10235
I0325 08:18:50.511958 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.54158 (* 1 = 3.54158 loss)
I0325 08:18:50.511992 29022 sgd_solver.cpp:136] Iteration 36900, lr = 2.19706e-05, m = 0.9
I0325 08:20:07.999672 29022 solver.cpp:314] Iteration 37000 (1.29057 iter/s, 77.4854s/100 iter), loss = 3.05564
I0325 08:20:07.999830 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.78074 (* 1 = 2.78074 loss)
I0325 08:20:07.999848 29022 sgd_solver.cpp:136] Iteration 37000, lr = 2.15927e-05, m = 0.9
I0325 08:21:26.897410 29022 solver.cpp:314] Iteration 37100 (1.2675 iter/s, 78.8952s/100 iter), loss = 3.2121
I0325 08:21:26.897555 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.36743 (* 1 = 2.36743 loss)
I0325 08:21:26.897593 29022 sgd_solver.cpp:136] Iteration 37100, lr = 2.12196e-05, m = 0.9
I0325 08:22:44.734129 29022 solver.cpp:314] Iteration 37200 (1.28478 iter/s, 77.8342s/100 iter), loss = 3.26042
I0325 08:22:44.734266 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.79341 (* 1 = 3.79341 loss)
I0325 08:22:44.734302 29022 sgd_solver.cpp:136] Iteration 37200, lr = 2.08514e-05, m = 0.9
I0325 08:24:02.197031 29022 solver.cpp:314] Iteration 37300 (1.29098 iter/s, 77.4604s/100 iter), loss = 3.10162
I0325 08:24:02.197201 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.44249 (* 1 = 3.44249 loss)
I0325 08:24:02.197221 29022 sgd_solver.cpp:136] Iteration 37300, lr = 2.04879e-05, m = 0.9
I0325 08:25:21.127409 29022 solver.cpp:314] Iteration 37400 (1.26698 iter/s, 78.9278s/100 iter), loss = 3.20925
I0325 08:25:21.127573 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.7176 (* 1 = 4.7176 loss)
I0325 08:25:21.127615 29022 sgd_solver.cpp:136] Iteration 37400, lr = 2.01293e-05, m = 0.9
I0325 08:26:39.638434 29022 solver.cpp:314] Iteration 37500 (1.27375 iter/s, 78.5085s/100 iter), loss = 3.23262
I0325 08:26:39.638599 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.25752 (* 1 = 3.25752 loss)
I0325 08:26:39.638633 29022 sgd_solver.cpp:136] Iteration 37500, lr = 1.97754e-05, m = 0.9
I0325 08:27:56.952630 29022 solver.cpp:314] Iteration 37600 (1.29347 iter/s, 77.3117s/100 iter), loss = 3.08527
I0325 08:27:56.952764 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.56636 (* 1 = 2.56636 loss)
I0325 08:27:56.952800 29022 sgd_solver.cpp:136] Iteration 37600, lr = 1.94262e-05, m = 0.9
I0325 08:29:13.702061 29022 solver.cpp:314] Iteration 37700 (1.30298 iter/s, 76.7469s/100 iter), loss = 3.10684
I0325 08:29:13.702191 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.59858 (* 1 = 3.59858 loss)
I0325 08:29:13.702211 29022 sgd_solver.cpp:136] Iteration 37700, lr = 1.90816e-05, m = 0.9
I0325 08:30:31.887030 29022 solver.cpp:314] Iteration 37800 (1.27906 iter/s, 78.1824s/100 iter), loss = 3.07478
I0325 08:30:31.887356 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.89717 (* 1 = 3.89717 loss)
I0325 08:30:31.887380 29022 sgd_solver.cpp:136] Iteration 37800, lr = 1.87416e-05, m = 0.9
I0325 08:31:49.978381 29022 solver.cpp:314] Iteration 37900 (1.28059 iter/s, 78.0888s/100 iter), loss = 3.17303
I0325 08:31:49.978526 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.34325 (* 1 = 4.34325 loss)
I0325 08:31:49.978757 29022 sgd_solver.cpp:136] Iteration 37900, lr = 1.84062e-05, m = 0.9
I0325 08:33:09.191485 29022 solver.cpp:360] Sparsity after update:
I0325 08:33:09.194677 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 08:33:09.194695 29022 net.cpp:2200] conv1a_param_0(0.397) 
I0325 08:33:09.194711 29022 net.cpp:2200] conv1b_param_0(0.68) 
I0325 08:33:09.194721 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 08:33:09.194730 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 08:33:09.194739 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 08:33:09.194748 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 08:33:09.194756 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 08:33:09.194766 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 08:33:09.194774 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 08:33:09.194783 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 08:33:09.194792 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 08:33:09.194800 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 08:33:09.194809 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 08:33:09.194818 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 08:33:09.194828 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 08:33:09.194835 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 08:33:09.194880 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 08:33:09.194893 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 08:33:09.194902 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 08:33:09.194911 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 08:33:09.194919 29022 net.cpp:2200] res2a_branch2a_param_0(0.723) 
I0325 08:33:09.194929 29022 net.cpp:2200] res2a_branch2b_param_0(0.571) 
I0325 08:33:09.194938 29022 net.cpp:2200] res3a_branch2a_param_0(0.675) 
I0325 08:33:09.194947 29022 net.cpp:2200] res3a_branch2b_param_0(0.647) 
I0325 08:33:09.194957 29022 net.cpp:2200] res4a_branch2a_param_0(0.754) 
I0325 08:33:09.194965 29022 net.cpp:2200] res4a_branch2b_param_0(0.701) 
I0325 08:33:09.195006 29022 net.cpp:2200] res5a_branch2a_param_0(0.786) 
I0325 08:33:09.195017 29022 net.cpp:2200] res5a_branch2b_param_0(0.796) 
I0325 08:33:09.195026 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.81684e+06/3.10435e+06) 0.585
I0325 08:33:09.195053 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_38000.caffemodel
I0325 08:33:09.218466 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_38000.solverstate
I0325 08:33:09.226876 29022 solver.cpp:678] Iteration 38000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.240016
j:  : 4 : max_pr:  : 0.456067
j:  : 3 : max_pr:  : 0.592159
j:  : 2 : max_pr:  : 0.707707
j:  : 1 : max_pr:  : 0.84779
j:  : 0 : max_pr:  : 1
I0325 08:34:32.189924 29022 solver.cpp:786] class AP 1: 0.349431
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.182873
j:  : 7 : max_pr:  : 0.330602
j:  : 6 : max_pr:  : 0.556987
j:  : 5 : max_pr:  : 0.622527
j:  : 4 : max_pr:  : 0.73457
j:  : 3 : max_pr:  : 0.789229
j:  : 2 : max_pr:  : 0.985199
j:  : 1 : max_pr:  : 0.998062
j:  : 0 : max_pr:  : 1
I0325 08:34:32.292111 29022 solver.cpp:786] class AP 2: 0.563641
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.496585
j:  : 6 : max_pr:  : 0.657723
j:  : 5 : max_pr:  : 0.752379
j:  : 4 : max_pr:  : 0.834148
j:  : 3 : max_pr:  : 0.918343
j:  : 2 : max_pr:  : 0.966867
j:  : 1 : max_pr:  : 0.99675
j:  : 0 : max_pr:  : 1
I0325 08:34:32.313374 29022 solver.cpp:786] class AP 3: 0.602072
I0325 08:34:32.313390 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.505048
I0325 08:34:32.313436 29022 solver.cpp:265] Tests completed in 83.0839s
I0325 08:34:32.898875 29022 solver.cpp:314] Iteration 38000 (0.613816 iter/s, 162.915s/100 iter), loss = 3.34614
I0325 08:34:32.898967 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.4265 (* 1 = 3.4265 loss)
I0325 08:34:32.899000 29022 sgd_solver.cpp:136] Iteration 38000, lr = 1.80753e-05, m = 0.9
I0325 08:35:50.775359 29022 solver.cpp:314] Iteration 38100 (1.28413 iter/s, 77.8739s/100 iter), loss = 3.14247
I0325 08:35:50.775527 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.82544 (* 1 = 3.82544 loss)
I0325 08:35:50.775563 29022 sgd_solver.cpp:136] Iteration 38100, lr = 1.77489e-05, m = 0.9
I0325 08:37:09.339869 29022 solver.cpp:314] Iteration 38200 (1.27288 iter/s, 78.562s/100 iter), loss = 3.11098
I0325 08:37:09.340006 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.77549 (* 1 = 2.77549 loss)
I0325 08:37:09.340042 29022 sgd_solver.cpp:136] Iteration 38200, lr = 1.74269e-05, m = 0.9
I0325 08:38:26.737149 29022 solver.cpp:314] Iteration 38300 (1.29208 iter/s, 77.3948s/100 iter), loss = 3.03753
I0325 08:38:26.737718 29022 solver.cpp:336]     Train net output #0: mbox_loss = 1.83452 (* 1 = 1.83452 loss)
I0325 08:38:26.738086 29022 sgd_solver.cpp:136] Iteration 38300, lr = 1.71094e-05, m = 0.9
I0325 08:39:45.067487 29022 solver.cpp:314] Iteration 38400 (1.27669 iter/s, 78.3278s/100 iter), loss = 3.33978
I0325 08:39:45.067623 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.30451 (* 1 = 3.30451 loss)
I0325 08:39:45.067642 29022 sgd_solver.cpp:136] Iteration 38400, lr = 1.67962e-05, m = 0.9
I0325 08:41:03.419132 29022 solver.cpp:314] Iteration 38500 (1.27634 iter/s, 78.3491s/100 iter), loss = 3.11123
I0325 08:41:03.419277 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.29533 (* 1 = 3.29533 loss)
I0325 08:41:03.419313 29022 sgd_solver.cpp:136] Iteration 38500, lr = 1.64873e-05, m = 0.9
I0325 08:42:07.323493 29042 data_reader.cpp:305] Starting prefetch of epoch 10
I0325 08:42:22.863430 29022 solver.cpp:314] Iteration 38600 (1.25878 iter/s, 79.4417s/100 iter), loss = 3.04302
I0325 08:42:22.863533 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.1159 (* 1 = 3.1159 loss)
I0325 08:42:22.863566 29022 sgd_solver.cpp:136] Iteration 38600, lr = 1.61827e-05, m = 0.9
I0325 08:43:42.393373 29022 solver.cpp:314] Iteration 38700 (1.25743 iter/s, 79.5274s/100 iter), loss = 3.26447
I0325 08:43:42.393518 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.04871 (* 1 = 3.04871 loss)
I0325 08:43:42.393553 29022 sgd_solver.cpp:136] Iteration 38700, lr = 1.58823e-05, m = 0.9
I0325 08:45:00.129014 29022 solver.cpp:314] Iteration 38800 (1.28645 iter/s, 77.7331s/100 iter), loss = 2.91616
I0325 08:45:00.129148 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.86348 (* 1 = 2.86348 loss)
I0325 08:45:00.129181 29022 sgd_solver.cpp:136] Iteration 38800, lr = 1.55861e-05, m = 0.9
I0325 08:46:19.193732 29022 solver.cpp:314] Iteration 38900 (1.26483 iter/s, 79.0622s/100 iter), loss = 3.15489
I0325 08:46:19.194205 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.81141 (* 1 = 3.81141 loss)
I0325 08:46:19.194525 29022 sgd_solver.cpp:136] Iteration 38900, lr = 1.52941e-05, m = 0.9
I0325 08:47:37.601353 29022 solver.cpp:314] Iteration 39000 (1.27543 iter/s, 78.4051s/100 iter), loss = 3.06782
I0325 08:47:37.601500 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.09373 (* 1 = 3.09373 loss)
I0325 08:47:37.601534 29022 sgd_solver.cpp:136] Iteration 39000, lr = 1.50063e-05, m = 0.9
I0325 08:48:54.903090 29022 solver.cpp:314] Iteration 39100 (1.29367 iter/s, 77.2992s/100 iter), loss = 3.09128
I0325 08:48:54.903239 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.42836 (* 1 = 3.42836 loss)
I0325 08:48:54.903272 29022 sgd_solver.cpp:136] Iteration 39100, lr = 1.47225e-05, m = 0.9
I0325 08:50:14.494845 29022 solver.cpp:314] Iteration 39200 (1.25645 iter/s, 79.5892s/100 iter), loss = 3.04217
I0325 08:50:14.494997 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.00844 (* 1 = 3.00844 loss)
I0325 08:50:14.495033 29022 sgd_solver.cpp:136] Iteration 39200, lr = 1.44427e-05, m = 0.9
I0325 08:51:32.885479 29022 solver.cpp:314] Iteration 39300 (1.2757 iter/s, 78.3881s/100 iter), loss = 3.15728
I0325 08:51:32.885576 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.18426 (* 1 = 2.18426 loss)
I0325 08:51:32.885593 29022 sgd_solver.cpp:136] Iteration 39300, lr = 1.4167e-05, m = 0.9
I0325 08:52:52.656086 29022 solver.cpp:314] Iteration 39400 (1.25364 iter/s, 79.768s/100 iter), loss = 3.31071
I0325 08:52:52.656277 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.55891 (* 1 = 3.55891 loss)
I0325 08:52:52.656319 29022 sgd_solver.cpp:136] Iteration 39400, lr = 1.38952e-05, m = 0.9
I0325 08:54:13.102346 29022 solver.cpp:314] Iteration 39500 (1.24311 iter/s, 80.4437s/100 iter), loss = 3.24705
I0325 08:54:13.102949 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.46202 (* 1 = 3.46202 loss)
I0325 08:54:13.102965 29022 sgd_solver.cpp:136] Iteration 39500, lr = 1.36273e-05, m = 0.9
I0325 08:55:31.503746 29022 solver.cpp:314] Iteration 39600 (1.27553 iter/s, 78.3989s/100 iter), loss = 3.11595
I0325 08:55:31.503934 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.47979 (* 1 = 2.47979 loss)
I0325 08:55:31.503973 29022 sgd_solver.cpp:136] Iteration 39600, lr = 1.33634e-05, m = 0.9
I0325 08:56:50.274061 29022 solver.cpp:314] Iteration 39700 (1.26955 iter/s, 78.7678s/100 iter), loss = 3.12359
I0325 08:56:50.274204 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.46346 (* 1 = 3.46346 loss)
I0325 08:56:50.274240 29022 sgd_solver.cpp:136] Iteration 39700, lr = 1.31033e-05, m = 0.9
I0325 08:58:08.333034 29022 solver.cpp:314] Iteration 39800 (1.28112 iter/s, 78.0564s/100 iter), loss = 3.08217
I0325 08:58:08.334440 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.97602 (* 1 = 2.97602 loss)
I0325 08:58:08.334457 29022 sgd_solver.cpp:136] Iteration 39800, lr = 1.2847e-05, m = 0.9
I0325 08:59:27.120767 29022 solver.cpp:314] Iteration 39900 (1.26927 iter/s, 78.7852s/100 iter), loss = 3.15997
I0325 08:59:27.120898 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.59347 (* 1 = 2.59347 loss)
I0325 08:59:27.120932 29022 sgd_solver.cpp:136] Iteration 39900, lr = 1.25944e-05, m = 0.9
I0325 09:00:44.851116 29022 solver.cpp:360] Sparsity after update:
I0325 09:00:44.854229 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 09:00:44.854303 29022 net.cpp:2200] conv1a_param_0(0.397) 
I0325 09:00:44.854337 29022 net.cpp:2200] conv1b_param_0(0.68) 
I0325 09:00:44.854363 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 09:00:44.854388 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 09:00:44.854414 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 09:00:44.854439 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 09:00:44.854463 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 09:00:44.854488 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 09:00:44.854513 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 09:00:44.854537 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 09:00:44.854573 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 09:00:44.854598 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 09:00:44.854624 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 09:00:44.854648 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 09:00:44.854672 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 09:00:44.854697 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 09:00:44.854722 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 09:00:44.854745 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 09:00:44.854769 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 09:00:44.854794 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 09:00:44.854817 29022 net.cpp:2200] res2a_branch2a_param_0(0.723) 
I0325 09:00:44.854842 29022 net.cpp:2200] res2a_branch2b_param_0(0.571) 
I0325 09:00:44.854867 29022 net.cpp:2200] res3a_branch2a_param_0(0.675) 
I0325 09:00:44.854892 29022 net.cpp:2200] res3a_branch2b_param_0(0.647) 
I0325 09:00:44.854917 29022 net.cpp:2200] res4a_branch2a_param_0(0.754) 
I0325 09:00:44.854940 29022 net.cpp:2200] res4a_branch2b_param_0(0.701) 
I0325 09:00:44.854965 29022 net.cpp:2200] res5a_branch2a_param_0(0.786) 
I0325 09:00:44.854990 29022 net.cpp:2200] res5a_branch2b_param_0(0.796) 
I0325 09:00:44.855015 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.81684e+06/3.10435e+06) 0.585
I0325 09:00:44.855062 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_40000.caffemodel
I0325 09:00:44.881271 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_40000.solverstate
I0325 09:00:44.893052 29022 solver.cpp:678] Iteration 40000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.235301
j:  : 4 : max_pr:  : 0.454785
j:  : 3 : max_pr:  : 0.591667
j:  : 2 : max_pr:  : 0.704229
j:  : 1 : max_pr:  : 0.846424
j:  : 0 : max_pr:  : 1
I0325 09:02:08.528210 29022 solver.cpp:786] class AP 1: 0.348401
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.181315
j:  : 7 : max_pr:  : 0.328042
j:  : 6 : max_pr:  : 0.556807
j:  : 5 : max_pr:  : 0.62981
j:  : 4 : max_pr:  : 0.738156
j:  : 3 : max_pr:  : 0.786975
j:  : 2 : max_pr:  : 0.984774
j:  : 1 : max_pr:  : 0.997937
j:  : 0 : max_pr:  : 1
I0325 09:02:08.627159 29022 solver.cpp:786] class AP 2: 0.563983
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.493895
j:  : 6 : max_pr:  : 0.659351
j:  : 5 : max_pr:  : 0.753777
j:  : 4 : max_pr:  : 0.83694
j:  : 3 : max_pr:  : 0.918942
j:  : 2 : max_pr:  : 0.966695
j:  : 1 : max_pr:  : 0.996829
j:  : 0 : max_pr:  : 1
I0325 09:02:08.648947 29022 solver.cpp:786] class AP 3: 0.602403
I0325 09:02:08.648964 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.504929
I0325 09:02:08.650141 29022 solver.cpp:265] Tests completed in 83.7544s
I0325 09:02:09.302211 29022 solver.cpp:314] Iteration 40000 (0.616613 iter/s, 162.176s/100 iter), loss = 3.00861
I0325 09:02:09.302299 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.94475 (* 1 = 3.94475 loss)
I0325 09:02:09.302332 29022 sgd_solver.cpp:136] Iteration 40000, lr = 1.23457e-05, m = 0.9
I0325 09:03:27.855298 29022 solver.cpp:314] Iteration 40100 (1.27307 iter/s, 78.5505s/100 iter), loss = 3.2914
I0325 09:03:27.855394 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.84231 (* 1 = 2.84231 loss)
I0325 09:03:27.855412 29022 sgd_solver.cpp:136] Iteration 40100, lr = 1.21006e-05, m = 0.9
I0325 09:04:45.404815 29022 solver.cpp:314] Iteration 40200 (1.28954 iter/s, 77.547s/100 iter), loss = 3.13206
I0325 09:04:45.404965 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.26307 (* 1 = 3.26307 loss)
I0325 09:04:45.405007 29022 sgd_solver.cpp:136] Iteration 40200, lr = 1.18592e-05, m = 0.9
I0325 09:06:03.410250 29022 solver.cpp:314] Iteration 40300 (1.282 iter/s, 78.0029s/100 iter), loss = 3.44483
I0325 09:06:03.410347 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.70229 (* 1 = 2.70229 loss)
I0325 09:06:03.410363 29022 sgd_solver.cpp:136] Iteration 40300, lr = 1.16214e-05, m = 0.9
I0325 09:07:22.671545 29022 solver.cpp:314] Iteration 40400 (1.26169 iter/s, 79.2587s/100 iter), loss = 3.26787
I0325 09:07:22.671697 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.04323 (* 1 = 3.04323 loss)
I0325 09:07:22.671736 29022 sgd_solver.cpp:136] Iteration 40400, lr = 1.13873e-05, m = 0.9
I0325 09:08:40.358639 29022 solver.cpp:314] Iteration 40500 (1.28726 iter/s, 77.6846s/100 iter), loss = 2.99459
I0325 09:08:40.369755 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.39545 (* 1 = 3.39545 loss)
I0325 09:08:40.369781 29022 sgd_solver.cpp:136] Iteration 40500, lr = 1.11566e-05, m = 0.9
I0325 09:09:57.663903 29022 solver.cpp:314] Iteration 40600 (1.29361 iter/s, 77.3028s/100 iter), loss = 3.09734
I0325 09:09:57.664002 29022 solver.cpp:336]     Train net output #0: mbox_loss = 1.75638 (* 1 = 1.75638 loss)
I0325 09:09:57.664176 29022 sgd_solver.cpp:136] Iteration 40600, lr = 1.09295e-05, m = 0.9
I0325 09:11:16.347379 29022 solver.cpp:314] Iteration 40700 (1.27096 iter/s, 78.681s/100 iter), loss = 3.23071
I0325 09:11:16.347520 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.86603 (* 1 = 3.86603 loss)
I0325 09:11:16.347556 29022 sgd_solver.cpp:136] Iteration 40700, lr = 1.07059e-05, m = 0.9
I0325 09:12:35.947878 29022 solver.cpp:314] Iteration 40800 (1.25631 iter/s, 79.5979s/100 iter), loss = 3.11789
I0325 09:12:35.948012 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.30795 (* 1 = 3.30795 loss)
I0325 09:12:35.948045 29022 sgd_solver.cpp:136] Iteration 40800, lr = 1.04858e-05, m = 0.9
I0325 09:13:54.456620 29022 solver.cpp:314] Iteration 40900 (1.27378 iter/s, 78.5062s/100 iter), loss = 3.15978
I0325 09:13:54.456775 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.39737 (* 1 = 2.39737 loss)
I0325 09:13:54.456810 29022 sgd_solver.cpp:136] Iteration 40900, lr = 1.0269e-05, m = 0.9
I0325 09:15:12.646917 29022 solver.cpp:314] Iteration 41000 (1.27897 iter/s, 78.1878s/100 iter), loss = 3.13619
I0325 09:15:12.647402 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.23484 (* 1 = 3.23484 loss)
I0325 09:15:12.647698 29022 sgd_solver.cpp:136] Iteration 41000, lr = 1.00556e-05, m = 0.9
I0325 09:16:31.138515 29022 solver.cpp:314] Iteration 41100 (1.27406 iter/s, 78.4891s/100 iter), loss = 3.06793
I0325 09:16:31.138669 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.85177 (* 1 = 3.85177 loss)
I0325 09:16:31.138705 29022 sgd_solver.cpp:136] Iteration 41100, lr = 9.8456e-06, m = 0.9
I0325 09:17:48.968467 29022 solver.cpp:314] Iteration 41200 (1.28489 iter/s, 77.8275s/100 iter), loss = 3.09919
I0325 09:17:48.968622 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.33154 (* 1 = 3.33154 loss)
I0325 09:17:48.968663 29022 sgd_solver.cpp:136] Iteration 41200, lr = 9.63888e-06, m = 0.9
I0325 09:19:06.846359 29022 solver.cpp:314] Iteration 41300 (1.2841 iter/s, 77.8754s/100 iter), loss = 3.26705
I0325 09:19:06.846819 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.72764 (* 1 = 3.72764 loss)
I0325 09:19:06.847120 29022 sgd_solver.cpp:136] Iteration 41300, lr = 9.43542e-06, m = 0.9
I0325 09:20:25.304401 29022 solver.cpp:314] Iteration 41400 (1.27461 iter/s, 78.4555s/100 iter), loss = 3.26009
I0325 09:20:25.304538 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.89294 (* 1 = 2.89294 loss)
I0325 09:20:25.304570 29022 sgd_solver.cpp:136] Iteration 41400, lr = 9.23521e-06, m = 0.9
I0325 09:21:43.411707 29022 solver.cpp:314] Iteration 41500 (1.28033 iter/s, 78.1048s/100 iter), loss = 3.27046
I0325 09:21:43.411813 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.73955 (* 1 = 3.73955 loss)
I0325 09:21:43.411829 29022 sgd_solver.cpp:136] Iteration 41500, lr = 9.0382e-06, m = 0.9
I0325 09:23:01.540187 29022 solver.cpp:314] Iteration 41600 (1.27998 iter/s, 78.126s/100 iter), loss = 3.24165
I0325 09:23:01.540437 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.29292 (* 1 = 3.29292 loss)
I0325 09:23:01.540458 29022 sgd_solver.cpp:136] Iteration 41600, lr = 8.84436e-06, m = 0.9
I0325 09:24:20.472743 29022 solver.cpp:314] Iteration 41700 (1.26694 iter/s, 78.93s/100 iter), loss = 3.22913
I0325 09:24:20.472903 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.06328 (* 1 = 4.06328 loss)
I0325 09:24:20.472919 29022 sgd_solver.cpp:136] Iteration 41700, lr = 8.65365e-06, m = 0.9
I0325 09:24:27.373878 29042 data_reader.cpp:305] Starting prefetch of epoch 11
I0325 09:25:40.093045 29022 solver.cpp:314] Iteration 41800 (1.256 iter/s, 79.6178s/100 iter), loss = 3.0427
I0325 09:25:40.093180 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.51899 (* 1 = 2.51899 loss)
I0325 09:25:40.093214 29022 sgd_solver.cpp:136] Iteration 41800, lr = 8.46605e-06, m = 0.9
I0325 09:26:58.394500 29022 solver.cpp:314] Iteration 41900 (1.27716 iter/s, 78.299s/100 iter), loss = 3.3827
I0325 09:26:58.394637 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.6258 (* 1 = 2.6258 loss)
I0325 09:26:58.394671 29022 sgd_solver.cpp:136] Iteration 41900, lr = 8.28151e-06, m = 0.9
I0325 09:28:16.678498 29022 solver.cpp:360] Sparsity after update:
I0325 09:28:16.680948 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 09:28:16.680968 29022 net.cpp:2200] conv1a_param_0(0.397) 
I0325 09:28:16.680980 29022 net.cpp:2200] conv1b_param_0(0.68) 
I0325 09:28:16.680986 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 09:28:16.680992 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 09:28:16.680999 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 09:28:16.681004 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 09:28:16.681008 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 09:28:16.681015 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 09:28:16.681020 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 09:28:16.681025 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 09:28:16.681030 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 09:28:16.681036 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 09:28:16.681041 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 09:28:16.681047 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 09:28:16.681052 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 09:28:16.681057 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 09:28:16.681063 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 09:28:16.681068 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 09:28:16.681074 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 09:28:16.681079 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 09:28:16.681084 29022 net.cpp:2200] res2a_branch2a_param_0(0.723) 
I0325 09:28:16.681090 29022 net.cpp:2200] res2a_branch2b_param_0(0.571) 
I0325 09:28:16.681097 29022 net.cpp:2200] res3a_branch2a_param_0(0.675) 
I0325 09:28:16.681102 29022 net.cpp:2200] res3a_branch2b_param_0(0.647) 
I0325 09:28:16.681107 29022 net.cpp:2200] res4a_branch2a_param_0(0.754) 
I0325 09:28:16.681113 29022 net.cpp:2200] res4a_branch2b_param_0(0.701) 
I0325 09:28:16.681118 29022 net.cpp:2200] res5a_branch2a_param_0(0.786) 
I0325 09:28:16.681123 29022 net.cpp:2200] res5a_branch2b_param_0(0.796) 
I0325 09:28:16.681129 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.81684e+06/3.10435e+06) 0.585
I0325 09:28:16.681147 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_42000.caffemodel
I0325 09:28:16.717602 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_42000.solverstate
I0325 09:28:16.729851 29022 solver.cpp:678] Iteration 42000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.230223
j:  : 4 : max_pr:  : 0.45268
j:  : 3 : max_pr:  : 0.590803
j:  : 2 : max_pr:  : 0.704864
j:  : 1 : max_pr:  : 0.845652
j:  : 0 : max_pr:  : 1
I0325 09:29:40.197298 29022 solver.cpp:786] class AP 1: 0.347656
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.169824
j:  : 7 : max_pr:  : 0.326463
j:  : 6 : max_pr:  : 0.552544
j:  : 5 : max_pr:  : 0.627278
j:  : 4 : max_pr:  : 0.7401
j:  : 3 : max_pr:  : 0.786925
j:  : 2 : max_pr:  : 0.984411
j:  : 1 : max_pr:  : 0.997947
j:  : 0 : max_pr:  : 1
I0325 09:29:40.296409 29022 solver.cpp:786] class AP 2: 0.562317
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.493984
j:  : 6 : max_pr:  : 0.65775
j:  : 5 : max_pr:  : 0.753291
j:  : 4 : max_pr:  : 0.834777
j:  : 3 : max_pr:  : 0.918343
j:  : 2 : max_pr:  : 0.965535
j:  : 1 : max_pr:  : 0.996725
j:  : 0 : max_pr:  : 1
I0325 09:29:40.317682 29022 solver.cpp:786] class AP 3: 0.601855
I0325 09:29:40.317700 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.503943
I0325 09:29:40.318712 29022 solver.cpp:265] Tests completed in 83.5862s
I0325 09:29:40.904191 29022 solver.cpp:314] Iteration 42000 (0.615368 iter/s, 162.505s/100 iter), loss = 3.13107
I0325 09:29:40.904290 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.46337 (* 1 = 2.46337 loss)
I0325 09:29:40.904326 29022 sgd_solver.cpp:136] Iteration 42000, lr = 8.1e-06, m = 0.9
I0325 09:30:58.846068 29022 solver.cpp:314] Iteration 42100 (1.28305 iter/s, 77.9394s/100 iter), loss = 3.08222
I0325 09:30:58.846529 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.09775 (* 1 = 3.09775 loss)
I0325 09:30:58.846834 29022 sgd_solver.cpp:136] Iteration 42100, lr = 7.9215e-06, m = 0.9
I0325 09:32:18.156056 29022 solver.cpp:314] Iteration 42200 (1.26092 iter/s, 79.3074s/100 iter), loss = 2.98978
I0325 09:32:18.156211 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.62226 (* 1 = 4.62226 loss)
I0325 09:32:18.156249 29022 sgd_solver.cpp:136] Iteration 42200, lr = 7.74596e-06, m = 0.9
I0325 09:33:38.176249 29022 solver.cpp:314] Iteration 42300 (1.24972 iter/s, 80.0176s/100 iter), loss = 3.29824
I0325 09:33:38.176440 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.1802 (* 1 = 3.1802 loss)
I0325 09:33:38.176458 29022 sgd_solver.cpp:136] Iteration 42300, lr = 7.57335e-06, m = 0.9
I0325 09:34:55.703985 29022 solver.cpp:314] Iteration 42400 (1.2899 iter/s, 77.5253s/100 iter), loss = 3.2227
I0325 09:34:55.704174 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.74508 (* 1 = 2.74508 loss)
I0325 09:34:55.704191 29022 sgd_solver.cpp:136] Iteration 42400, lr = 7.40365e-06, m = 0.9
I0325 09:36:15.209580 29022 solver.cpp:314] Iteration 42500 (1.25781 iter/s, 79.503s/100 iter), loss = 3.12772
I0325 09:36:15.209700 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.83148 (* 1 = 2.83148 loss)
I0325 09:36:15.209720 29022 sgd_solver.cpp:136] Iteration 42500, lr = 7.23681e-06, m = 0.9
I0325 09:37:32.909540 29022 solver.cpp:314] Iteration 42600 (1.28704 iter/s, 77.6975s/100 iter), loss = 3.18719
I0325 09:37:32.909732 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.27801 (* 1 = 4.27801 loss)
I0325 09:37:32.909768 29022 sgd_solver.cpp:136] Iteration 42600, lr = 7.07281e-06, m = 0.9
I0325 09:38:52.359797 29022 solver.cpp:314] Iteration 42700 (1.25869 iter/s, 79.4477s/100 iter), loss = 3.10655
I0325 09:38:52.359925 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.73198 (* 1 = 3.73198 loss)
I0325 09:38:52.359942 29022 sgd_solver.cpp:136] Iteration 42700, lr = 6.91162e-06, m = 0.9
I0325 09:40:10.967994 29022 solver.cpp:314] Iteration 42800 (1.27217 iter/s, 78.6057s/100 iter), loss = 3.26516
I0325 09:40:10.968222 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.5443 (* 1 = 3.5443 loss)
I0325 09:40:10.968258 29022 sgd_solver.cpp:136] Iteration 42800, lr = 6.75319e-06, m = 0.9
I0325 09:41:28.978967 29022 solver.cpp:314] Iteration 42900 (1.28191 iter/s, 78.0085s/100 iter), loss = 3.30757
I0325 09:41:28.979112 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.65706 (* 1 = 2.65706 loss)
I0325 09:41:28.979149 29022 sgd_solver.cpp:136] Iteration 42900, lr = 6.5975e-06, m = 0.9
I0325 09:42:47.093657 29022 solver.cpp:314] Iteration 43000 (1.28021 iter/s, 78.1122s/100 iter), loss = 3.12207
I0325 09:42:47.094116 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.92704 (* 1 = 2.92704 loss)
I0325 09:42:47.094430 29022 sgd_solver.cpp:136] Iteration 43000, lr = 6.44452e-06, m = 0.9
I0325 09:44:04.563767 29022 solver.cpp:314] Iteration 43100 (1.29086 iter/s, 77.4677s/100 iter), loss = 3.25278
I0325 09:44:04.563877 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.00174 (* 1 = 3.00174 loss)
I0325 09:44:04.563894 29022 sgd_solver.cpp:136] Iteration 43100, lr = 6.29422e-06, m = 0.9
I0325 09:45:23.447613 29022 solver.cpp:314] Iteration 43200 (1.26773 iter/s, 78.8813s/100 iter), loss = 3.1911
I0325 09:45:23.447754 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.75608 (* 1 = 3.75608 loss)
I0325 09:45:23.447791 29022 sgd_solver.cpp:136] Iteration 43200, lr = 6.14656e-06, m = 0.9
I0325 09:46:42.852787 29022 solver.cpp:314] Iteration 43300 (1.2594 iter/s, 79.4026s/100 iter), loss = 2.98464
I0325 09:46:42.852984 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.6934 (* 1 = 2.6934 loss)
I0325 09:46:42.853031 29022 sgd_solver.cpp:136] Iteration 43300, lr = 6.00151e-06, m = 0.9
I0325 09:48:01.768731 29022 solver.cpp:314] Iteration 43400 (1.26721 iter/s, 78.9134s/100 iter), loss = 3.32599
I0325 09:48:01.768873 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.69069 (* 1 = 2.69069 loss)
I0325 09:48:01.768909 29022 sgd_solver.cpp:136] Iteration 43400, lr = 5.85905e-06, m = 0.9
I0325 09:49:21.461796 29022 solver.cpp:314] Iteration 43500 (1.25485 iter/s, 79.6905s/100 iter), loss = 3.41105
I0325 09:49:21.461931 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.04638 (* 1 = 3.04638 loss)
I0325 09:49:21.461968 29022 sgd_solver.cpp:136] Iteration 43500, lr = 5.71914e-06, m = 0.9
I0325 09:50:40.388479 29022 solver.cpp:314] Iteration 43600 (1.26704 iter/s, 78.9242s/100 iter), loss = 3.16964
I0325 09:50:40.388629 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.86935 (* 1 = 2.86935 loss)
I0325 09:50:40.388662 29022 sgd_solver.cpp:136] Iteration 43600, lr = 5.58175e-06, m = 0.9
I0325 09:51:59.508268 29022 solver.cpp:314] Iteration 43700 (1.26395 iter/s, 79.1173s/100 iter), loss = 3.25907
I0325 09:51:59.508360 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.75738 (* 1 = 2.75738 loss)
I0325 09:51:59.508528 29022 sgd_solver.cpp:136] Iteration 43700, lr = 5.44685e-06, m = 0.9
I0325 09:53:19.331084 29022 solver.cpp:314] Iteration 43800 (1.25281 iter/s, 79.8203s/100 iter), loss = 3.29759
I0325 09:53:19.331338 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.97452 (* 1 = 2.97452 loss)
I0325 09:53:19.331362 29022 sgd_solver.cpp:136] Iteration 43800, lr = 5.31441e-06, m = 0.9
I0325 09:54:38.009665 29022 solver.cpp:314] Iteration 43900 (1.27103 iter/s, 78.6761s/100 iter), loss = 3.23912
I0325 09:54:38.009853 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.52596 (* 1 = 4.52596 loss)
I0325 09:54:38.009873 29022 sgd_solver.cpp:136] Iteration 43900, lr = 5.1844e-06, m = 0.9
I0325 09:55:55.920838 29022 solver.cpp:360] Sparsity after update:
I0325 09:55:55.924111 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 09:55:55.924181 29022 net.cpp:2200] conv1a_param_0(0.397) 
I0325 09:55:55.924216 29022 net.cpp:2200] conv1b_param_0(0.68) 
I0325 09:55:55.924242 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 09:55:55.924268 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 09:55:55.924302 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 09:55:55.924329 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 09:55:55.924355 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 09:55:55.924378 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 09:55:55.924403 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 09:55:55.924427 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 09:55:55.924453 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 09:55:55.924477 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 09:55:55.924501 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 09:55:55.924525 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 09:55:55.924551 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 09:55:55.924576 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 09:55:55.924599 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 09:55:55.924623 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 09:55:55.924649 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 09:55:55.924672 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 09:55:55.924696 29022 net.cpp:2200] res2a_branch2a_param_0(0.723) 
I0325 09:55:55.924721 29022 net.cpp:2200] res2a_branch2b_param_0(0.571) 
I0325 09:55:55.924746 29022 net.cpp:2200] res3a_branch2a_param_0(0.675) 
I0325 09:55:55.924772 29022 net.cpp:2200] res3a_branch2b_param_0(0.647) 
I0325 09:55:55.924795 29022 net.cpp:2200] res4a_branch2a_param_0(0.754) 
I0325 09:55:55.924820 29022 net.cpp:2200] res4a_branch2b_param_0(0.701) 
I0325 09:55:55.924845 29022 net.cpp:2200] res5a_branch2a_param_0(0.786) 
I0325 09:55:55.924870 29022 net.cpp:2200] res5a_branch2b_param_0(0.796) 
I0325 09:55:55.924893 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.81684e+06/3.10435e+06) 0.585
I0325 09:55:55.924939 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_44000.caffemodel
I0325 09:55:55.950590 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_44000.solverstate
I0325 09:55:55.959496 29022 solver.cpp:678] Iteration 44000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.234712
j:  : 4 : max_pr:  : 0.457799
j:  : 3 : max_pr:  : 0.595511
j:  : 2 : max_pr:  : 0.707655
j:  : 1 : max_pr:  : 0.847196
j:  : 0 : max_pr:  : 1
I0325 09:57:18.985802 29022 solver.cpp:786] class AP 1: 0.349352
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.174285
j:  : 7 : max_pr:  : 0.323802
j:  : 6 : max_pr:  : 0.556191
j:  : 5 : max_pr:  : 0.631025
j:  : 4 : max_pr:  : 0.734486
j:  : 3 : max_pr:  : 0.784792
j:  : 2 : max_pr:  : 0.984067
j:  : 1 : max_pr:  : 0.997837
j:  : 0 : max_pr:  : 1
I0325 09:57:19.087927 29022 solver.cpp:786] class AP 2: 0.562408
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.493167
j:  : 6 : max_pr:  : 0.657876
j:  : 5 : max_pr:  : 0.753063
j:  : 4 : max_pr:  : 0.834903
j:  : 3 : max_pr:  : 0.918134
j:  : 2 : max_pr:  : 0.966918
j:  : 1 : max_pr:  : 0.996708
j:  : 0 : max_pr:  : 1
I0325 09:57:19.110195 29022 solver.cpp:786] class AP 3: 0.601888
I0325 09:57:19.110215 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.504549
I0325 09:57:19.111291 29022 solver.cpp:265] Tests completed in 83.1491s
I0325 09:57:19.759022 29022 solver.cpp:314] Iteration 44000 (0.61826 iter/s, 161.744s/100 iter), loss = 3.07523
I0325 09:57:19.759114 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.44885 (* 1 = 2.44885 loss)
I0325 09:57:19.759146 29022 sgd_solver.cpp:136] Iteration 44000, lr = 5.05679e-06, m = 0.9
I0325 09:58:38.693517 29022 solver.cpp:314] Iteration 44100 (1.26691 iter/s, 78.932s/100 iter), loss = 3.19237
I0325 09:58:38.693709 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.88402 (* 1 = 4.88402 loss)
I0325 09:58:38.693745 29022 sgd_solver.cpp:136] Iteration 44100, lr = 4.93155e-06, m = 0.9
I0325 09:59:58.099081 29022 solver.cpp:314] Iteration 44200 (1.2594 iter/s, 79.403s/100 iter), loss = 3.06015
I0325 09:59:58.099228 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.63712 (* 1 = 2.63712 loss)
I0325 09:59:58.099264 29022 sgd_solver.cpp:136] Iteration 44200, lr = 4.80865e-06, m = 0.9
I0325 10:01:16.768518 29022 solver.cpp:314] Iteration 44300 (1.27118 iter/s, 78.6669s/100 iter), loss = 3.06713
I0325 10:01:16.775630 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.55387 (* 1 = 2.55387 loss)
I0325 10:01:16.775662 29022 sgd_solver.cpp:136] Iteration 44300, lr = 4.68806e-06, m = 0.9
I0325 10:02:35.907584 29022 solver.cpp:314] Iteration 44400 (1.26364 iter/s, 79.1365s/100 iter), loss = 3.03178
I0325 10:02:35.907691 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.57467 (* 1 = 3.57467 loss)
I0325 10:02:35.907704 29022 sgd_solver.cpp:136] Iteration 44400, lr = 4.56976e-06, m = 0.9
I0325 10:03:46.478898 29042 data_reader.cpp:305] Starting prefetch of epoch 12
I0325 10:03:54.944761 29022 solver.cpp:314] Iteration 44500 (1.26527 iter/s, 79.0347s/100 iter), loss = 3.19889
I0325 10:03:54.944875 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.53511 (* 1 = 2.53511 loss)
I0325 10:03:54.944911 29022 sgd_solver.cpp:136] Iteration 44500, lr = 4.45371e-06, m = 0.9
I0325 10:05:14.534333 29022 solver.cpp:314] Iteration 44600 (1.25649 iter/s, 79.587s/100 iter), loss = 3.45043
I0325 10:05:14.534476 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.25809 (* 1 = 3.25809 loss)
I0325 10:05:14.534510 29022 sgd_solver.cpp:136] Iteration 44600, lr = 4.33988e-06, m = 0.9
I0325 10:06:33.176152 29022 solver.cpp:314] Iteration 44700 (1.27163 iter/s, 78.6393s/100 iter), loss = 2.97929
I0325 10:06:33.176272 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.24419 (* 1 = 4.24419 loss)
I0325 10:06:33.176290 29022 sgd_solver.cpp:136] Iteration 44700, lr = 4.22825e-06, m = 0.9
I0325 10:07:52.436517 29022 solver.cpp:314] Iteration 44800 (1.2617 iter/s, 79.2578s/100 iter), loss = 3.23504
I0325 10:07:52.436655 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.27988 (* 1 = 3.27988 loss)
I0325 10:07:52.436689 29022 sgd_solver.cpp:136] Iteration 44800, lr = 4.11879e-06, m = 0.9
I0325 10:09:11.116679 29022 solver.cpp:314] Iteration 44900 (1.27101 iter/s, 78.6777s/100 iter), loss = 3.21131
I0325 10:09:11.116811 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.96532 (* 1 = 2.96532 loss)
I0325 10:09:11.116845 29022 sgd_solver.cpp:136] Iteration 44900, lr = 4.01146e-06, m = 0.9
I0325 10:10:30.332360 29022 solver.cpp:314] Iteration 45000 (1.26242 iter/s, 79.2132s/100 iter), loss = 3.19736
I0325 10:10:30.332454 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.21464 (* 1 = 3.21464 loss)
I0325 10:10:30.332471 29022 sgd_solver.cpp:136] Iteration 45000, lr = 3.90625e-06, m = 0.9
I0325 10:11:49.606941 29022 solver.cpp:314] Iteration 45100 (1.26148 iter/s, 79.2721s/100 iter), loss = 3.21366
I0325 10:11:49.607036 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.53351 (* 1 = 4.53351 loss)
I0325 10:11:49.607053 29022 sgd_solver.cpp:136] Iteration 45100, lr = 3.80312e-06, m = 0.9
I0325 10:13:09.230263 29022 solver.cpp:314] Iteration 45200 (1.25595 iter/s, 79.6208s/100 iter), loss = 3.13281
I0325 10:13:09.230479 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.0108 (* 1 = 3.0108 loss)
I0325 10:13:09.230515 29022 sgd_solver.cpp:136] Iteration 45200, lr = 3.70205e-06, m = 0.9
I0325 10:14:28.213843 29022 solver.cpp:314] Iteration 45300 (1.26613 iter/s, 78.9811s/100 iter), loss = 3.18122
I0325 10:14:28.213933 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.11189 (* 1 = 4.11189 loss)
I0325 10:14:28.213945 29022 sgd_solver.cpp:136] Iteration 45300, lr = 3.603e-06, m = 0.9
I0325 10:15:48.049960 29022 solver.cpp:314] Iteration 45400 (1.25261 iter/s, 79.8336s/100 iter), loss = 3.18022
I0325 10:15:48.056496 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.11251 (* 1 = 2.11251 loss)
I0325 10:15:48.056540 29022 sgd_solver.cpp:136] Iteration 45400, lr = 3.50596e-06, m = 0.9
I0325 10:17:07.115931 29022 solver.cpp:314] Iteration 45500 (1.26481 iter/s, 79.0634s/100 iter), loss = 3.27771
I0325 10:17:07.116052 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.11898 (* 1 = 3.11898 loss)
I0325 10:17:07.116065 29022 sgd_solver.cpp:136] Iteration 45500, lr = 3.41089e-06, m = 0.9
I0325 10:18:26.019938 29022 solver.cpp:314] Iteration 45600 (1.2674 iter/s, 78.9015s/100 iter), loss = 3.01079
I0325 10:18:26.020073 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.09627 (* 1 = 4.09627 loss)
I0325 10:18:26.020107 29022 sgd_solver.cpp:136] Iteration 45600, lr = 3.31776e-06, m = 0.9
I0325 10:19:43.937927 29022 solver.cpp:314] Iteration 45700 (1.28344 iter/s, 77.9155s/100 iter), loss = 3.30488
I0325 10:19:43.938392 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.14265 (* 1 = 3.14265 loss)
I0325 10:19:43.938695 29022 sgd_solver.cpp:136] Iteration 45700, lr = 3.22656e-06, m = 0.9
I0325 10:21:03.872212 29022 solver.cpp:314] Iteration 45800 (1.25107 iter/s, 79.9317s/100 iter), loss = 3.18669
I0325 10:21:03.872372 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.7918 (* 1 = 3.7918 loss)
I0325 10:21:03.872388 29022 sgd_solver.cpp:136] Iteration 45800, lr = 3.13725e-06, m = 0.9
I0325 10:22:23.415593 29022 solver.cpp:314] Iteration 45900 (1.25722 iter/s, 79.5408s/100 iter), loss = 3.25677
I0325 10:22:23.415753 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.20582 (* 1 = 4.20582 loss)
I0325 10:22:23.415772 29022 sgd_solver.cpp:136] Iteration 45900, lr = 3.0498e-06, m = 0.9
I0325 10:23:41.800221 29022 solver.cpp:360] Sparsity after update:
I0325 10:23:41.802603 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 10:23:41.802616 29022 net.cpp:2200] conv1a_param_0(0.397) 
I0325 10:23:41.802629 29022 net.cpp:2200] conv1b_param_0(0.68) 
I0325 10:23:41.802634 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 10:23:41.802640 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 10:23:41.802646 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 10:23:41.802651 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 10:23:41.802656 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 10:23:41.802662 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 10:23:41.802667 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 10:23:41.802672 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 10:23:41.802678 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 10:23:41.802683 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 10:23:41.802688 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 10:23:41.802695 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 10:23:41.802700 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 10:23:41.802705 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 10:23:41.802709 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 10:23:41.802716 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 10:23:41.802721 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 10:23:41.802726 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 10:23:41.802731 29022 net.cpp:2200] res2a_branch2a_param_0(0.723) 
I0325 10:23:41.802736 29022 net.cpp:2200] res2a_branch2b_param_0(0.571) 
I0325 10:23:41.802742 29022 net.cpp:2200] res3a_branch2a_param_0(0.675) 
I0325 10:23:41.802747 29022 net.cpp:2200] res3a_branch2b_param_0(0.647) 
I0325 10:23:41.802753 29022 net.cpp:2200] res4a_branch2a_param_0(0.754) 
I0325 10:23:41.802758 29022 net.cpp:2200] res4a_branch2b_param_0(0.701) 
I0325 10:23:41.802763 29022 net.cpp:2200] res5a_branch2a_param_0(0.786) 
I0325 10:23:41.802769 29022 net.cpp:2200] res5a_branch2b_param_0(0.796) 
I0325 10:23:41.802774 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.81684e+06/3.10435e+06) 0.585
I0325 10:23:41.802793 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_46000.caffemodel
I0325 10:23:41.825116 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_46000.solverstate
I0325 10:23:41.836791 29022 solver.cpp:678] Iteration 46000, Testing net (#0)
I0325 10:24:38.099886 29022 blocking_queue.cpp:40] Data layer prefetch queue empty
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.237906
j:  : 4 : max_pr:  : 0.459676
j:  : 3 : max_pr:  : 0.594972
j:  : 2 : max_pr:  : 0.709034
j:  : 1 : max_pr:  : 0.847053
j:  : 0 : max_pr:  : 1
I0325 10:25:04.899668 29022 solver.cpp:786] class AP 1: 0.349876
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.17655
j:  : 7 : max_pr:  : 0.328498
j:  : 6 : max_pr:  : 0.559626
j:  : 5 : max_pr:  : 0.632825
j:  : 4 : max_pr:  : 0.738622
j:  : 3 : max_pr:  : 0.790234
j:  : 2 : max_pr:  : 0.985546
j:  : 1 : max_pr:  : 0.997977
j:  : 0 : max_pr:  : 1
I0325 10:25:05.007576 29022 solver.cpp:786] class AP 2: 0.564534
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.493142
j:  : 6 : max_pr:  : 0.65596
j:  : 5 : max_pr:  : 0.751508
j:  : 4 : max_pr:  : 0.83468
j:  : 3 : max_pr:  : 0.917354
j:  : 2 : max_pr:  : 0.965234
j:  : 1 : max_pr:  : 0.996582
j:  : 0 : max_pr:  : 1
I0325 10:25:05.028811 29022 solver.cpp:786] class AP 3: 0.601315
I0325 10:25:05.028829 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.505242
I0325 10:25:05.029918 29022 solver.cpp:265] Tests completed in 83.1905s
I0325 10:25:05.658176 29022 solver.cpp:314] Iteration 46000 (0.616381 iter/s, 162.237s/100 iter), loss = 3.25947
I0325 10:25:05.658268 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.11117 (* 1 = 4.11117 loss)
I0325 10:25:05.658301 29022 sgd_solver.cpp:136] Iteration 46000, lr = 2.9642e-06, m = 0.9
I0325 10:26:24.020993 29022 solver.cpp:314] Iteration 46100 (1.27616 iter/s, 78.3603s/100 iter), loss = 3.14295
I0325 10:26:24.021096 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.28275 (* 1 = 3.28275 loss)
I0325 10:26:24.021114 29022 sgd_solver.cpp:136] Iteration 46100, lr = 2.88041e-06, m = 0.9
I0325 10:27:43.282670 29022 solver.cpp:314] Iteration 46200 (1.26168 iter/s, 79.2591s/100 iter), loss = 3.01904
I0325 10:27:43.282799 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.28222 (* 1 = 3.28222 loss)
I0325 10:27:43.282831 29022 sgd_solver.cpp:136] Iteration 46200, lr = 2.79841e-06, m = 0.9
I0325 10:29:04.123492 29022 solver.cpp:314] Iteration 46300 (1.23704 iter/s, 80.8382s/100 iter), loss = 3.19764
I0325 10:29:04.123630 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.84888 (* 1 = 2.84888 loss)
I0325 10:29:04.123664 29022 sgd_solver.cpp:136] Iteration 46300, lr = 2.71818e-06, m = 0.9
I0325 10:30:22.141676 29022 solver.cpp:314] Iteration 46400 (1.28179 iter/s, 78.0157s/100 iter), loss = 3.16791
I0325 10:30:22.141827 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.37677 (* 1 = 2.37677 loss)
I0325 10:30:22.141865 29022 sgd_solver.cpp:136] Iteration 46400, lr = 2.63968e-06, m = 0.9
I0325 10:31:41.247575 29022 solver.cpp:314] Iteration 46500 (1.26417 iter/s, 79.1034s/100 iter), loss = 3.31244
I0325 10:31:41.247668 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.02351 (* 1 = 4.02351 loss)
I0325 10:31:41.247686 29022 sgd_solver.cpp:136] Iteration 46500, lr = 2.56289e-06, m = 0.9
I0325 10:33:00.540963 29022 solver.cpp:314] Iteration 46600 (1.26118 iter/s, 79.2908s/100 iter), loss = 3.28121
I0325 10:33:00.541107 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.31255 (* 1 = 3.31255 loss)
I0325 10:33:00.541149 29022 sgd_solver.cpp:136] Iteration 46600, lr = 2.48779e-06, m = 0.9
I0325 10:34:19.639495 29022 solver.cpp:314] Iteration 46700 (1.26429 iter/s, 79.096s/100 iter), loss = 3.21297
I0325 10:34:19.639634 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.29135 (* 1 = 2.29135 loss)
I0325 10:34:19.639668 29022 sgd_solver.cpp:136] Iteration 46700, lr = 2.41436e-06, m = 0.9
I0325 10:35:39.604537 29022 solver.cpp:314] Iteration 46800 (1.25059 iter/s, 79.9625s/100 iter), loss = 3.24291
I0325 10:35:39.613957 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.79917 (* 1 = 3.79917 loss)
I0325 10:35:39.614145 29022 sgd_solver.cpp:136] Iteration 46800, lr = 2.34256e-06, m = 0.9
I0325 10:36:59.466313 29022 solver.cpp:314] Iteration 46900 (1.2522 iter/s, 79.8592s/100 iter), loss = 3.15007
I0325 10:36:59.466768 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.56544 (* 1 = 2.56544 loss)
I0325 10:36:59.467088 29022 sgd_solver.cpp:136] Iteration 46900, lr = 2.27237e-06, m = 0.9
I0325 10:38:18.785035 29022 solver.cpp:314] Iteration 47000 (1.26078 iter/s, 79.3162s/100 iter), loss = 3.15076
I0325 10:38:18.785199 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.67805 (* 1 = 4.67805 loss)
I0325 10:38:18.785234 29022 sgd_solver.cpp:136] Iteration 47000, lr = 2.20378e-06, m = 0.9
I0325 10:39:37.433280 29022 solver.cpp:314] Iteration 47100 (1.27152 iter/s, 78.6457s/100 iter), loss = 3.23249
I0325 10:39:37.433426 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.27029 (* 1 = 3.27029 loss)
I0325 10:39:37.433464 29022 sgd_solver.cpp:136] Iteration 47100, lr = 2.13675e-06, m = 0.9
I0325 10:40:57.219521 29022 solver.cpp:314] Iteration 47200 (1.25339 iter/s, 79.7837s/100 iter), loss = 3.16051
I0325 10:40:57.219630 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.33574 (* 1 = 3.33574 loss)
I0325 10:40:57.219647 29022 sgd_solver.cpp:136] Iteration 47200, lr = 2.07126e-06, m = 0.9
I0325 10:42:15.619623 29022 solver.cpp:314] Iteration 47300 (1.27555 iter/s, 78.3976s/100 iter), loss = 3.24174
I0325 10:42:15.619767 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.7128 (* 1 = 2.7128 loss)
I0325 10:42:15.619801 29022 sgd_solver.cpp:136] Iteration 47300, lr = 2.00729e-06, m = 0.9
I0325 10:43:35.868443 29022 solver.cpp:314] Iteration 47400 (1.24616 iter/s, 80.2463s/100 iter), loss = 3.32981
I0325 10:43:35.868633 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.29789 (* 1 = 4.29789 loss)
I0325 10:43:35.868669 29022 sgd_solver.cpp:136] Iteration 47400, lr = 1.94481e-06, m = 0.9
I0325 10:44:55.059170 29022 solver.cpp:314] Iteration 47500 (1.26281 iter/s, 79.1882s/100 iter), loss = 3.0408
I0325 10:44:55.059299 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.44222 (* 1 = 3.44222 loss)
I0325 10:44:55.059334 29022 sgd_solver.cpp:136] Iteration 47500, lr = 1.8838e-06, m = 0.9
I0325 10:46:14.276098 29022 solver.cpp:314] Iteration 47600 (1.2624 iter/s, 79.2144s/100 iter), loss = 3.11339
I0325 10:46:14.276563 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.91426 (* 1 = 2.91426 loss)
I0325 10:46:14.276888 29022 sgd_solver.cpp:136] Iteration 47600, lr = 1.82424e-06, m = 0.9
I0325 10:46:28.954852 29042 data_reader.cpp:305] Starting prefetch of epoch 13
I0325 10:47:34.024888 29022 solver.cpp:314] Iteration 47700 (1.25398 iter/s, 79.7462s/100 iter), loss = 3.18439
I0325 10:47:34.031303 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.41815 (* 1 = 3.41815 loss)
I0325 10:47:34.031338 29022 sgd_solver.cpp:136] Iteration 47700, lr = 1.7661e-06, m = 0.9
I0325 10:48:53.111507 29022 solver.cpp:314] Iteration 47800 (1.26448 iter/s, 79.0841s/100 iter), loss = 2.97766
I0325 10:48:53.111601 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.88365 (* 1 = 2.88365 loss)
I0325 10:48:53.111619 29022 sgd_solver.cpp:136] Iteration 47800, lr = 1.70936e-06, m = 0.9
I0325 10:50:12.635671 29022 solver.cpp:314] Iteration 47900 (1.25752 iter/s, 79.5216s/100 iter), loss = 3.09967
I0325 10:50:12.635838 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.64426 (* 1 = 2.64426 loss)
I0325 10:50:12.635881 29022 sgd_solver.cpp:136] Iteration 47900, lr = 1.654e-06, m = 0.9
I0325 10:51:30.407910 29022 solver.cpp:360] Sparsity after update:
I0325 10:51:30.411039 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 10:51:30.411080 29022 net.cpp:2200] conv1a_param_0(0.397) 
I0325 10:51:30.411113 29022 net.cpp:2200] conv1b_param_0(0.68) 
I0325 10:51:30.411141 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 10:51:30.411166 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 10:51:30.411191 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 10:51:30.411216 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 10:51:30.411242 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 10:51:30.411267 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 10:51:30.411291 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 10:51:30.411316 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 10:51:30.411341 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 10:51:30.411366 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 10:51:30.411391 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 10:51:30.411415 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 10:51:30.411440 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 10:51:30.411466 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 10:51:30.411490 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 10:51:30.411516 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 10:51:30.411541 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 10:51:30.411566 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 10:51:30.411592 29022 net.cpp:2200] res2a_branch2a_param_0(0.723) 
I0325 10:51:30.411617 29022 net.cpp:2200] res2a_branch2b_param_0(0.571) 
I0325 10:51:30.411643 29022 net.cpp:2200] res3a_branch2a_param_0(0.675) 
I0325 10:51:30.411667 29022 net.cpp:2200] res3a_branch2b_param_0(0.647) 
I0325 10:51:30.411692 29022 net.cpp:2200] res4a_branch2a_param_0(0.754) 
I0325 10:51:30.411717 29022 net.cpp:2200] res4a_branch2b_param_0(0.701) 
I0325 10:51:30.411742 29022 net.cpp:2200] res5a_branch2a_param_0(0.786) 
I0325 10:51:30.411767 29022 net.cpp:2200] res5a_branch2b_param_0(0.796) 
I0325 10:51:30.411792 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.81684e+06/3.10435e+06) 0.585
I0325 10:51:30.411836 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_48000.caffemodel
I0325 10:51:30.437923 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_48000.solverstate
I0325 10:51:30.450145 29022 solver.cpp:678] Iteration 48000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.238746
j:  : 4 : max_pr:  : 0.457692
j:  : 3 : max_pr:  : 0.593912
j:  : 2 : max_pr:  : 0.706622
j:  : 1 : max_pr:  : 0.849123
j:  : 0 : max_pr:  : 1
I0325 10:52:53.450554 29022 solver.cpp:786] class AP 1: 0.349645
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.177103
j:  : 7 : max_pr:  : 0.32874
j:  : 6 : max_pr:  : 0.555874
j:  : 5 : max_pr:  : 0.627398
j:  : 4 : max_pr:  : 0.734202
j:  : 3 : max_pr:  : 0.786915
j:  : 2 : max_pr:  : 0.985915
j:  : 1 : max_pr:  : 0.997877
j:  : 0 : max_pr:  : 1
I0325 10:52:53.552194 29022 solver.cpp:786] class AP 2: 0.563093
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.494726
j:  : 6 : max_pr:  : 0.655067
j:  : 5 : max_pr:  : 0.750147
j:  : 4 : max_pr:  : 0.834099
j:  : 3 : max_pr:  : 0.91673
j:  : 2 : max_pr:  : 0.965393
j:  : 1 : max_pr:  : 0.996645
j:  : 0 : max_pr:  : 1
I0325 10:52:53.574234 29022 solver.cpp:786] class AP 3: 0.601164
I0325 10:52:53.574255 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.504634
I0325 10:52:53.574303 29022 solver.cpp:265] Tests completed in 83.1215s
I0325 10:52:54.208261 29022 solver.cpp:314] Iteration 48000 (0.618937 iter/s, 161.567s/100 iter), loss = 3.20428
I0325 10:52:54.208353 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.42994 (* 1 = 3.42994 loss)
I0325 10:52:54.208385 29022 sgd_solver.cpp:136] Iteration 48000, lr = 1.6e-06, m = 0.9
I0325 10:54:12.613919 29022 solver.cpp:314] Iteration 48100 (1.27546 iter/s, 78.4031s/100 iter), loss = 3.10175
I0325 10:54:12.614029 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.08575 (* 1 = 3.08575 loss)
I0325 10:54:12.614045 29022 sgd_solver.cpp:136] Iteration 48100, lr = 1.54733e-06, m = 0.9
I0325 10:55:31.070614 29022 solver.cpp:314] Iteration 48200 (1.27463 iter/s, 78.4542s/100 iter), loss = 3.23799
I0325 10:55:31.070762 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.07962 (* 1 = 3.07962 loss)
I0325 10:55:31.070778 29022 sgd_solver.cpp:136] Iteration 48200, lr = 1.49597e-06, m = 0.9
I0325 10:56:51.033064 29022 solver.cpp:314] Iteration 48300 (1.25063 iter/s, 79.9599s/100 iter), loss = 3.18021
I0325 10:56:51.033165 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.18657 (* 1 = 3.18657 loss)
I0325 10:56:51.033181 29022 sgd_solver.cpp:136] Iteration 48300, lr = 1.4459e-06, m = 0.9
I0325 10:58:10.162123 29022 solver.cpp:314] Iteration 48400 (1.2638 iter/s, 79.1265s/100 iter), loss = 3.29193
I0325 10:58:10.162272 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.2407 (* 1 = 4.2407 loss)
I0325 10:58:10.162307 29022 sgd_solver.cpp:136] Iteration 48400, lr = 1.3971e-06, m = 0.9
I0325 10:59:28.537508 29022 solver.cpp:314] Iteration 48500 (1.27595 iter/s, 78.3729s/100 iter), loss = 3.08922
I0325 10:59:28.537674 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.7341 (* 1 = 2.7341 loss)
I0325 10:59:28.537721 29022 sgd_solver.cpp:136] Iteration 48500, lr = 1.34954e-06, m = 0.9
I0325 11:00:48.168762 29022 solver.cpp:314] Iteration 48600 (1.25583 iter/s, 79.6287s/100 iter), loss = 3.11372
I0325 11:00:48.168931 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.09524 (* 1 = 3.09524 loss)
I0325 11:00:48.168965 29022 sgd_solver.cpp:136] Iteration 48600, lr = 1.30321e-06, m = 0.9
I0325 11:02:08.604732 29022 solver.cpp:314] Iteration 48700 (1.24326 iter/s, 80.4334s/100 iter), loss = 3.19686
I0325 11:02:08.604934 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.16662 (* 1 = 3.16662 loss)
I0325 11:02:08.604969 29022 sgd_solver.cpp:136] Iteration 48700, lr = 1.25808e-06, m = 0.9
I0325 11:03:26.653280 29022 solver.cpp:314] Iteration 48800 (1.28129 iter/s, 78.0461s/100 iter), loss = 3.24461
I0325 11:03:26.653431 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.90837 (* 1 = 3.90837 loss)
I0325 11:03:26.653465 29022 sgd_solver.cpp:136] Iteration 48800, lr = 1.21414e-06, m = 0.9
I0325 11:04:44.852402 29022 solver.cpp:314] Iteration 48900 (1.27883 iter/s, 78.1966s/100 iter), loss = 3.10445
I0325 11:04:44.852538 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.51792 (* 1 = 3.51792 loss)
I0325 11:04:44.852572 29022 sgd_solver.cpp:136] Iteration 48900, lr = 1.17135e-06, m = 0.9
I0325 11:06:04.718768 29022 solver.cpp:314] Iteration 49000 (1.25213 iter/s, 79.8638s/100 iter), loss = 3.01697
I0325 11:06:04.718916 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.35221 (* 1 = 2.35221 loss)
I0325 11:06:04.718953 29022 sgd_solver.cpp:136] Iteration 49000, lr = 1.12971e-06, m = 0.9
I0325 11:07:24.220113 29022 solver.cpp:314] Iteration 49100 (1.25788 iter/s, 79.4988s/100 iter), loss = 3.11171
I0325 11:07:24.220269 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.97447 (* 1 = 2.97447 loss)
I0325 11:07:24.220305 29022 sgd_solver.cpp:136] Iteration 49100, lr = 1.08918e-06, m = 0.9
I0325 11:08:44.803884 29022 solver.cpp:314] Iteration 49200 (1.24098 iter/s, 80.5812s/100 iter), loss = 3.16665
I0325 11:08:44.804038 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.73286 (* 1 = 2.73286 loss)
I0325 11:08:44.804075 29022 sgd_solver.cpp:136] Iteration 49200, lr = 1.04976e-06, m = 0.9
I0325 11:10:04.260051 29022 solver.cpp:314] Iteration 49300 (1.2586 iter/s, 79.4536s/100 iter), loss = 3.22926
I0325 11:10:04.260157 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.09518 (* 1 = 3.09518 loss)
I0325 11:10:04.260433 29022 sgd_solver.cpp:136] Iteration 49300, lr = 1.01142e-06, m = 0.9
I0325 11:11:23.856997 29022 solver.cpp:314] Iteration 49400 (1.25637 iter/s, 79.5944s/100 iter), loss = 3.07996
I0325 11:11:23.857146 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.46994 (* 1 = 3.46994 loss)
I0325 11:11:23.857179 29022 sgd_solver.cpp:136] Iteration 49400, lr = 9.74134e-07, m = 0.9
I0325 11:12:43.604987 29022 solver.cpp:314] Iteration 49500 (1.25405 iter/s, 79.7415s/100 iter), loss = 3.20991
I0325 11:12:43.605130 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.86625 (* 1 = 2.86625 loss)
I0325 11:12:43.605165 29022 sgd_solver.cpp:136] Iteration 49500, lr = 9.37891e-07, m = 0.9
I0325 11:14:03.007632 29022 solver.cpp:314] Iteration 49600 (1.25944 iter/s, 79.4001s/100 iter), loss = 3.22078
I0325 11:14:03.007827 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.64535 (* 1 = 2.64535 loss)
I0325 11:14:03.007844 29022 sgd_solver.cpp:136] Iteration 49600, lr = 9.02669e-07, m = 0.9
I0325 11:15:22.154958 29022 solver.cpp:314] Iteration 49700 (1.26351 iter/s, 79.1448s/100 iter), loss = 3.32541
I0325 11:15:22.155205 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.63945 (* 1 = 3.63945 loss)
I0325 11:15:22.155231 29022 sgd_solver.cpp:136] Iteration 49700, lr = 8.68449e-07, m = 0.9
I0325 11:16:41.793011 29022 solver.cpp:314] Iteration 49800 (1.25572 iter/s, 79.6355s/100 iter), loss = 3.21786
I0325 11:16:41.793507 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.05171 (* 1 = 3.05171 loss)
I0325 11:16:41.793831 29022 sgd_solver.cpp:136] Iteration 49800, lr = 8.3521e-07, m = 0.9
I0325 11:18:01.039003 29022 solver.cpp:314] Iteration 49900 (1.26193 iter/s, 79.2435s/100 iter), loss = 3.16968
I0325 11:18:01.039155 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.87662 (* 1 = 3.87662 loss)
I0325 11:18:01.039192 29022 sgd_solver.cpp:136] Iteration 49900, lr = 8.02936e-07, m = 0.9
I0325 11:19:19.076030 29022 solver.cpp:360] Sparsity after update:
I0325 11:19:19.079330 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 11:19:19.079390 29022 net.cpp:2200] conv1a_param_0(0.397) 
I0325 11:19:19.079427 29022 net.cpp:2200] conv1b_param_0(0.68) 
I0325 11:19:19.079457 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 11:19:19.079486 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 11:19:19.079515 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 11:19:19.079545 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 11:19:19.079571 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 11:19:19.079597 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 11:19:19.079624 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 11:19:19.079653 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 11:19:19.079682 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 11:19:19.079712 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 11:19:19.079741 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 11:19:19.079769 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 11:19:19.079797 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 11:19:19.079826 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 11:19:19.079855 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 11:19:19.079881 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 11:19:19.079908 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 11:19:19.079937 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 11:19:19.079967 29022 net.cpp:2200] res2a_branch2a_param_0(0.723) 
I0325 11:19:19.080004 29022 net.cpp:2200] res2a_branch2b_param_0(0.571) 
I0325 11:19:19.080034 29022 net.cpp:2200] res3a_branch2a_param_0(0.675) 
I0325 11:19:19.080065 29022 net.cpp:2200] res3a_branch2b_param_0(0.647) 
I0325 11:19:19.080092 29022 net.cpp:2200] res4a_branch2a_param_0(0.754) 
I0325 11:19:19.080121 29022 net.cpp:2200] res4a_branch2b_param_0(0.701) 
I0325 11:19:19.080149 29022 net.cpp:2200] res5a_branch2a_param_0(0.786) 
I0325 11:19:19.080175 29022 net.cpp:2200] res5a_branch2b_param_0(0.796) 
I0325 11:19:19.080201 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.81684e+06/3.10435e+06) 0.585
I0325 11:19:19.080250 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_50000.caffemodel
I0325 11:19:19.109285 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_50000.solverstate
I0325 11:19:19.122864 29022 solver.cpp:678] Iteration 50000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.233845
j:  : 4 : max_pr:  : 0.456211
j:  : 3 : max_pr:  : 0.592574
j:  : 2 : max_pr:  : 0.708525
j:  : 1 : max_pr:  : 0.847086
j:  : 0 : max_pr:  : 1
I0325 11:20:42.572733 29022 solver.cpp:786] class AP 1: 0.348931
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.170154
j:  : 7 : max_pr:  : 0.323223
j:  : 6 : max_pr:  : 0.55905
j:  : 5 : max_pr:  : 0.629684
j:  : 4 : max_pr:  : 0.739112
j:  : 3 : max_pr:  : 0.787725
j:  : 2 : max_pr:  : 0.984411
j:  : 1 : max_pr:  : 0.997935
j:  : 0 : max_pr:  : 1
I0325 11:20:42.676270 29022 solver.cpp:786] class AP 2: 0.562845
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.490789
j:  : 6 : max_pr:  : 0.65723
j:  : 5 : max_pr:  : 0.751911
j:  : 4 : max_pr:  : 0.834334
j:  : 3 : max_pr:  : 0.916413
j:  : 2 : max_pr:  : 0.964843
j:  : 1 : max_pr:  : 0.996626
j:  : 0 : max_pr:  : 1
I0325 11:20:42.698536 29022 solver.cpp:786] class AP 3: 0.601104
I0325 11:20:42.698563 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.504293
I0325 11:20:42.699661 29022 solver.cpp:265] Tests completed in 83.5741s
I0325 11:20:43.321468 29022 solver.cpp:314] Iteration 50000 (0.616229 iter/s, 162.277s/100 iter), loss = 3.13869
I0325 11:20:43.321557 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.80662 (* 1 = 2.80662 loss)
I0325 11:20:43.321590 29022 sgd_solver.cpp:136] Iteration 50000, lr = 7.71605e-07, m = 0.9
I0325 11:22:01.393373 29022 solver.cpp:314] Iteration 50100 (1.28091 iter/s, 78.0694s/100 iter), loss = 3.1684
I0325 11:22:01.393553 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.11682 (* 1 = 3.11682 loss)
I0325 11:22:01.393587 29022 sgd_solver.cpp:136] Iteration 50100, lr = 7.41201e-07, m = 0.9
I0325 11:23:19.185838 29022 solver.cpp:314] Iteration 50200 (1.28551 iter/s, 77.79s/100 iter), loss = 2.98014
I0325 11:23:19.186283 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.6488 (* 1 = 2.6488 loss)
I0325 11:23:19.186592 29022 sgd_solver.cpp:136] Iteration 50200, lr = 7.11704e-07, m = 0.9
I0325 11:24:37.864501 29022 solver.cpp:314] Iteration 50300 (1.27103 iter/s, 78.6761s/100 iter), loss = 3.47865
I0325 11:24:37.864632 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.28707 (* 1 = 3.28707 loss)
I0325 11:24:37.864666 29022 sgd_solver.cpp:136] Iteration 50300, lr = 6.83097e-07, m = 0.9
I0325 11:25:57.209239 29042 data_reader.cpp:305] Starting prefetch of epoch 14
I0325 11:25:57.272107 29022 solver.cpp:314] Iteration 50400 (1.25937 iter/s, 79.4051s/100 iter), loss = 3.28245
I0325 11:25:57.272202 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.37901 (* 1 = 4.37901 loss)
I0325 11:25:57.272233 29022 sgd_solver.cpp:136] Iteration 50400, lr = 6.5536e-07, m = 0.9
I0325 11:27:16.935170 29022 solver.cpp:314] Iteration 50500 (1.25533 iter/s, 79.6605s/100 iter), loss = 3.2643
I0325 11:27:16.935364 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.06841 (* 1 = 4.06841 loss)
I0325 11:27:16.935382 29022 sgd_solver.cpp:136] Iteration 50500, lr = 6.28477e-07, m = 0.9
I0325 11:28:35.951668 29022 solver.cpp:314] Iteration 50600 (1.2656 iter/s, 79.014s/100 iter), loss = 2.9094
I0325 11:28:35.951794 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.99108 (* 1 = 2.99108 loss)
I0325 11:28:35.951833 29022 sgd_solver.cpp:136] Iteration 50600, lr = 6.0243e-07, m = 0.9
I0325 11:29:55.504475 29022 solver.cpp:314] Iteration 50700 (1.25707 iter/s, 79.5503s/100 iter), loss = 3.27184
I0325 11:29:55.504590 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.13016 (* 1 = 2.13016 loss)
I0325 11:29:55.504602 29022 sgd_solver.cpp:136] Iteration 50700, lr = 5.772e-07, m = 0.9
I0325 11:31:14.945387 29022 solver.cpp:314] Iteration 50800 (1.25884 iter/s, 79.4384s/100 iter), loss = 3.29093
I0325 11:31:14.945518 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.64695 (* 1 = 2.64695 loss)
I0325 11:31:14.945554 29022 sgd_solver.cpp:136] Iteration 50800, lr = 5.52772e-07, m = 0.9
I0325 11:32:33.743468 29022 solver.cpp:314] Iteration 50900 (1.26911 iter/s, 78.7956s/100 iter), loss = 3.19301
I0325 11:32:33.743613 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.98017 (* 1 = 2.98017 loss)
I0325 11:32:33.743645 29022 sgd_solver.cpp:136] Iteration 50900, lr = 5.29127e-07, m = 0.9
I0325 11:33:53.248849 29022 solver.cpp:314] Iteration 51000 (1.25782 iter/s, 79.5029s/100 iter), loss = 3.15067
I0325 11:33:53.248950 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.04209 (* 1 = 3.04209 loss)
I0325 11:33:53.248966 29022 sgd_solver.cpp:136] Iteration 51000, lr = 5.0625e-07, m = 0.9
I0325 11:35:12.267122 29022 solver.cpp:314] Iteration 51100 (1.26557 iter/s, 79.0158s/100 iter), loss = 3.12658
I0325 11:35:12.267232 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.31636 (* 1 = 3.31636 loss)
I0325 11:35:12.267249 29022 sgd_solver.cpp:136] Iteration 51100, lr = 4.84122e-07, m = 0.9
I0325 11:36:31.313851 29022 solver.cpp:314] Iteration 51200 (1.26511 iter/s, 79.0442s/100 iter), loss = 3.28552
I0325 11:36:31.314023 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.31018 (* 1 = 2.31018 loss)
I0325 11:36:31.314040 29022 sgd_solver.cpp:136] Iteration 51200, lr = 4.62728e-07, m = 0.9
I0325 11:37:50.477852 29022 solver.cpp:314] Iteration 51300 (1.26324 iter/s, 79.1615s/100 iter), loss = 2.94746
I0325 11:37:50.478018 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.7799 (* 1 = 2.7799 loss)
I0325 11:37:50.478056 29022 sgd_solver.cpp:136] Iteration 51300, lr = 4.4205e-07, m = 0.9
I0325 11:39:09.511842 29022 solver.cpp:314] Iteration 51400 (1.26532 iter/s, 79.0315s/100 iter), loss = 3.11469
I0325 11:39:09.512039 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.13661 (* 1 = 4.13661 loss)
I0325 11:39:09.512075 29022 sgd_solver.cpp:136] Iteration 51400, lr = 4.22074e-07, m = 0.9
I0325 11:40:28.387219 29022 solver.cpp:314] Iteration 51500 (1.26786 iter/s, 78.8729s/100 iter), loss = 3.11015
I0325 11:40:28.387398 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.47803 (* 1 = 2.47803 loss)
I0325 11:40:28.387435 29022 sgd_solver.cpp:136] Iteration 51500, lr = 4.02782e-07, m = 0.9
I0325 11:41:47.535259 29022 solver.cpp:314] Iteration 51600 (1.2635 iter/s, 79.1455s/100 iter), loss = 2.9745
I0325 11:41:47.535396 29022 solver.cpp:336]     Train net output #0: mbox_loss = 1.67307 (* 1 = 1.67307 loss)
I0325 11:41:47.535432 29022 sgd_solver.cpp:136] Iteration 51600, lr = 3.8416e-07, m = 0.9
I0325 11:43:05.693670 29022 solver.cpp:314] Iteration 51700 (1.27949 iter/s, 78.1559s/100 iter), loss = 3.26324
I0325 11:43:05.693828 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.73963 (* 1 = 3.73963 loss)
I0325 11:43:05.693861 29022 sgd_solver.cpp:136] Iteration 51700, lr = 3.66191e-07, m = 0.9
I0325 11:44:24.774971 29022 solver.cpp:314] Iteration 51800 (1.26456 iter/s, 79.0788s/100 iter), loss = 3.14885
I0325 11:44:24.775060 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.19411 (* 1 = 3.19411 loss)
I0325 11:44:24.775077 29022 sgd_solver.cpp:136] Iteration 51800, lr = 3.48859e-07, m = 0.9
I0325 11:45:43.643280 29022 solver.cpp:314] Iteration 51900 (1.26798 iter/s, 78.8658s/100 iter), loss = 3.19049
I0325 11:45:43.643501 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.86282 (* 1 = 3.86282 loss)
I0325 11:45:43.643535 29022 sgd_solver.cpp:136] Iteration 51900, lr = 3.32151e-07, m = 0.9
I0325 11:47:02.374583 29022 solver.cpp:360] Sparsity after update:
I0325 11:47:02.377032 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 11:47:02.377053 29022 net.cpp:2200] conv1a_param_0(0.397) 
I0325 11:47:02.377069 29022 net.cpp:2200] conv1b_param_0(0.68) 
I0325 11:47:02.377079 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 11:47:02.377089 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 11:47:02.377097 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 11:47:02.377106 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 11:47:02.377115 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 11:47:02.377123 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 11:47:02.377132 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 11:47:02.377143 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 11:47:02.377153 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 11:47:02.377159 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 11:47:02.377166 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 11:47:02.377171 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 11:47:02.377177 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 11:47:02.377182 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 11:47:02.377187 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 11:47:02.377193 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 11:47:02.377198 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 11:47:02.377203 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 11:47:02.377209 29022 net.cpp:2200] res2a_branch2a_param_0(0.723) 
I0325 11:47:02.377215 29022 net.cpp:2200] res2a_branch2b_param_0(0.571) 
I0325 11:47:02.377220 29022 net.cpp:2200] res3a_branch2a_param_0(0.675) 
I0325 11:47:02.377226 29022 net.cpp:2200] res3a_branch2b_param_0(0.647) 
I0325 11:47:02.377233 29022 net.cpp:2200] res4a_branch2a_param_0(0.754) 
I0325 11:47:02.377238 29022 net.cpp:2200] res4a_branch2b_param_0(0.701) 
I0325 11:47:02.377243 29022 net.cpp:2200] res5a_branch2a_param_0(0.786) 
I0325 11:47:02.377249 29022 net.cpp:2200] res5a_branch2b_param_0(0.796) 
I0325 11:47:02.377254 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.81684e+06/3.10435e+06) 0.585
I0325 11:47:02.377272 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_52000.caffemodel
I0325 11:47:02.399010 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_52000.solverstate
I0325 11:47:02.407799 29022 solver.cpp:678] Iteration 52000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.232437
j:  : 4 : max_pr:  : 0.454588
j:  : 3 : max_pr:  : 0.590075
j:  : 2 : max_pr:  : 0.705178
j:  : 1 : max_pr:  : 0.845061
j:  : 0 : max_pr:  : 1
I0325 11:48:25.798343 29022 solver.cpp:786] class AP 1: 0.34794
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.180105
j:  : 7 : max_pr:  : 0.331685
j:  : 6 : max_pr:  : 0.558851
j:  : 5 : max_pr:  : 0.632701
j:  : 4 : max_pr:  : 0.738938
j:  : 3 : max_pr:  : 0.789988
j:  : 2 : max_pr:  : 0.984814
j:  : 1 : max_pr:  : 0.998034
j:  : 0 : max_pr:  : 1
I0325 11:48:25.911252 29022 solver.cpp:786] class AP 2: 0.565011
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.491762
j:  : 6 : max_pr:  : 0.657785
j:  : 5 : max_pr:  : 0.751361
j:  : 4 : max_pr:  : 0.835039
j:  : 3 : max_pr:  : 0.918343
j:  : 2 : max_pr:  : 0.965948
j:  : 1 : max_pr:  : 0.996576
j:  : 0 : max_pr:  : 1
I0325 11:48:25.932816 29022 solver.cpp:786] class AP 3: 0.601529
I0325 11:48:25.932832 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.504826
I0325 11:48:25.932874 29022 solver.cpp:265] Tests completed in 83.5224s
I0325 11:48:26.577311 29022 solver.cpp:314] Iteration 52000 (0.613765 iter/s, 162.929s/100 iter), loss = 3.10216
I0325 11:48:26.577702 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.01946 (* 1 = 3.01946 loss)
I0325 11:48:26.578006 29022 sgd_solver.cpp:136] Iteration 52000, lr = 3.16049e-07, m = 0.9
I0325 11:49:44.899230 29022 solver.cpp:314] Iteration 52100 (1.27682 iter/s, 78.3194s/100 iter), loss = 3.21357
I0325 11:49:44.899360 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.70402 (* 1 = 3.70402 loss)
I0325 11:49:44.899399 29022 sgd_solver.cpp:136] Iteration 52100, lr = 3.00541e-07, m = 0.9
I0325 11:51:03.781427 29022 solver.cpp:314] Iteration 52200 (1.26775 iter/s, 78.8797s/100 iter), loss = 3.21114
I0325 11:51:03.781896 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.56705 (* 1 = 2.56705 loss)
I0325 11:51:03.782209 29022 sgd_solver.cpp:136] Iteration 52200, lr = 2.8561e-07, m = 0.9
I0325 11:52:23.196259 29022 solver.cpp:314] Iteration 52300 (1.25925 iter/s, 79.4123s/100 iter), loss = 3.10433
I0325 11:52:23.196403 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.03126 (* 1 = 4.03126 loss)
I0325 11:52:23.196439 29022 sgd_solver.cpp:136] Iteration 52300, lr = 2.71243e-07, m = 0.9
I0325 11:53:43.335635 29022 solver.cpp:314] Iteration 52400 (1.24787 iter/s, 80.1368s/100 iter), loss = 3.32393
I0325 11:53:43.335783 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.62329 (* 1 = 4.62329 loss)
I0325 11:53:43.335817 29022 sgd_solver.cpp:136] Iteration 52400, lr = 2.57424e-07, m = 0.9
I0325 11:55:02.837839 29022 solver.cpp:314] Iteration 52500 (1.25787 iter/s, 79.4997s/100 iter), loss = 3.05225
I0325 11:55:02.837939 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.9093 (* 1 = 2.9093 loss)
I0325 11:55:02.837956 29022 sgd_solver.cpp:136] Iteration 52500, lr = 2.44141e-07, m = 0.9
I0325 11:56:21.576326 29022 solver.cpp:314] Iteration 52600 (1.27007 iter/s, 78.736s/100 iter), loss = 3.24333
I0325 11:56:21.576473 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.79751 (* 1 = 4.79751 loss)
I0325 11:56:21.576510 29022 sgd_solver.cpp:136] Iteration 52600, lr = 2.31378e-07, m = 0.9
I0325 11:57:40.639089 29022 solver.cpp:314] Iteration 52700 (1.26486 iter/s, 79.0602s/100 iter), loss = 3.14807
I0325 11:57:40.639237 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.89579 (* 1 = 2.89579 loss)
I0325 11:57:40.639253 29022 sgd_solver.cpp:136] Iteration 52700, lr = 2.19122e-07, m = 0.9
I0325 11:59:00.472193 29022 solver.cpp:314] Iteration 52800 (1.25265 iter/s, 79.8306s/100 iter), loss = 3.09419
I0325 11:59:00.472287 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.5458 (* 1 = 2.5458 loss)
I0325 11:59:00.472306 29022 sgd_solver.cpp:136] Iteration 52800, lr = 2.0736e-07, m = 0.9
I0325 12:00:22.040421 29022 solver.cpp:314] Iteration 52900 (1.22601 iter/s, 81.5656s/100 iter), loss = 3.13909
I0325 12:00:22.040554 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.18182 (* 1 = 3.18182 loss)
I0325 12:00:22.040587 29022 sgd_solver.cpp:136] Iteration 52900, lr = 1.96078e-07, m = 0.9
I0325 12:01:42.366065 29022 solver.cpp:314] Iteration 53000 (1.24497 iter/s, 80.3231s/100 iter), loss = 3.13965
I0325 12:01:42.366266 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.72715 (* 1 = 2.72715 loss)
I0325 12:01:42.366299 29022 sgd_solver.cpp:136] Iteration 53000, lr = 1.85262e-07, m = 0.9
I0325 12:03:02.694805 29022 solver.cpp:314] Iteration 53100 (1.24492 iter/s, 80.3262s/100 iter), loss = 3.06211
I0325 12:03:02.694905 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.15469 (* 1 = 4.15469 loss)
I0325 12:03:02.694923 29022 sgd_solver.cpp:136] Iteration 53100, lr = 1.74901e-07, m = 0.9
I0325 12:04:23.379698 29022 solver.cpp:314] Iteration 53200 (1.23943 iter/s, 80.6823s/100 iter), loss = 3.18453
I0325 12:04:23.379850 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.46006 (* 1 = 3.46006 loss)
I0325 12:04:23.379866 29022 sgd_solver.cpp:136] Iteration 53200, lr = 1.6498e-07, m = 0.9
I0325 12:05:41.580217 29022 solver.cpp:314] Iteration 53300 (1.2788 iter/s, 78.198s/100 iter), loss = 3.36518
I0325 12:05:41.580322 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.70394 (* 1 = 3.70394 loss)
I0325 12:05:41.580341 29022 sgd_solver.cpp:136] Iteration 53300, lr = 1.55487e-07, m = 0.9
I0325 12:07:01.164299 29022 solver.cpp:314] Iteration 53400 (1.25657 iter/s, 79.5815s/100 iter), loss = 3.22943
I0325 12:07:01.164409 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.67902 (* 1 = 2.67902 loss)
I0325 12:07:01.164425 29022 sgd_solver.cpp:136] Iteration 53400, lr = 1.4641e-07, m = 0.9
I0325 12:08:19.313587 29022 solver.cpp:314] Iteration 53500 (1.27964 iter/s, 78.1468s/100 iter), loss = 2.8858
I0325 12:08:19.313680 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.60239 (* 1 = 3.60239 loss)
I0325 12:08:19.313704 29022 sgd_solver.cpp:136] Iteration 53500, lr = 1.37736e-07, m = 0.9
I0325 12:08:42.293296 29042 data_reader.cpp:305] Starting prefetch of epoch 15
I0325 12:09:38.658751 29022 solver.cpp:314] Iteration 53600 (1.26036 iter/s, 79.3426s/100 iter), loss = 3.09687
I0325 12:09:38.658890 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.91363 (* 1 = 2.91363 loss)
I0325 12:09:38.658926 29022 sgd_solver.cpp:136] Iteration 53600, lr = 1.29454e-07, m = 0.9
I0325 12:10:57.132133 29022 solver.cpp:314] Iteration 53700 (1.27436 iter/s, 78.4709s/100 iter), loss = 3.19319
I0325 12:10:57.132282 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.53476 (* 1 = 2.53476 loss)
I0325 12:10:57.132316 29022 sgd_solver.cpp:136] Iteration 53700, lr = 1.21551e-07, m = 0.9
I0325 12:12:15.163960 29022 solver.cpp:314] Iteration 53800 (1.28157 iter/s, 78.0293s/100 iter), loss = 3.04626
I0325 12:12:15.164048 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.3055 (* 1 = 2.3055 loss)
I0325 12:12:15.164065 29022 sgd_solver.cpp:136] Iteration 53800, lr = 1.14015e-07, m = 0.9
I0325 12:13:35.322094 29022 solver.cpp:314] Iteration 53900 (1.24757 iter/s, 80.1556s/100 iter), loss = 3.16536
I0325 12:13:35.322245 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.80758 (* 1 = 2.80758 loss)
I0325 12:13:35.322281 29022 sgd_solver.cpp:136] Iteration 53900, lr = 1.06835e-07, m = 0.9
I0325 12:14:53.667387 29022 solver.cpp:360] Sparsity after update:
I0325 12:14:53.670495 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 12:14:53.670536 29022 net.cpp:2200] conv1a_param_0(0.397) 
I0325 12:14:53.670569 29022 net.cpp:2200] conv1b_param_0(0.68) 
I0325 12:14:53.670596 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 12:14:53.670624 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 12:14:53.670650 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 12:14:53.670676 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 12:14:53.670702 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 12:14:53.670727 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 12:14:53.670753 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 12:14:53.670779 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 12:14:53.670805 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 12:14:53.670831 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 12:14:53.670856 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 12:14:53.670882 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 12:14:53.670918 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 12:14:53.670945 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 12:14:53.670970 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 12:14:53.670995 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 12:14:53.671021 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 12:14:53.671047 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 12:14:53.671072 29022 net.cpp:2200] res2a_branch2a_param_0(0.723) 
I0325 12:14:53.671097 29022 net.cpp:2200] res2a_branch2b_param_0(0.571) 
I0325 12:14:53.671123 29022 net.cpp:2200] res3a_branch2a_param_0(0.675) 
I0325 12:14:53.671149 29022 net.cpp:2200] res3a_branch2b_param_0(0.647) 
I0325 12:14:53.671175 29022 net.cpp:2200] res4a_branch2a_param_0(0.754) 
I0325 12:14:53.671200 29022 net.cpp:2200] res4a_branch2b_param_0(0.701) 
I0325 12:14:53.671226 29022 net.cpp:2200] res5a_branch2a_param_0(0.786) 
I0325 12:14:53.671252 29022 net.cpp:2200] res5a_branch2b_param_0(0.796) 
I0325 12:14:53.671277 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.81684e+06/3.10435e+06) 0.585
I0325 12:14:53.671321 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_54000.caffemodel
I0325 12:14:53.705854 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_54000.solverstate
I0325 12:14:53.716233 29022 solver.cpp:678] Iteration 54000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.232652
j:  : 4 : max_pr:  : 0.450165
j:  : 3 : max_pr:  : 0.58954
j:  : 2 : max_pr:  : 0.703905
j:  : 1 : max_pr:  : 0.845563
j:  : 0 : max_pr:  : 1
I0325 12:16:17.192234 29022 solver.cpp:786] class AP 1: 0.347439
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.181006
j:  : 7 : max_pr:  : 0.332283
j:  : 6 : max_pr:  : 0.561718
j:  : 5 : max_pr:  : 0.631759
j:  : 4 : max_pr:  : 0.739969
j:  : 3 : max_pr:  : 0.78735
j:  : 2 : max_pr:  : 0.985937
j:  : 1 : max_pr:  : 0.998083
j:  : 0 : max_pr:  : 1
I0325 12:16:17.293390 29022 solver.cpp:786] class AP 2: 0.565282
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.492031
j:  : 6 : max_pr:  : 0.654607
j:  : 5 : max_pr:  : 0.748816
j:  : 4 : max_pr:  : 0.832643
j:  : 3 : max_pr:  : 0.916748
j:  : 2 : max_pr:  : 0.966192
j:  : 1 : max_pr:  : 0.996801
j:  : 0 : max_pr:  : 1
I0325 12:16:17.315178 29022 solver.cpp:786] class AP 3: 0.600712
I0325 12:16:17.315192 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.504478
I0325 12:16:17.315237 29022 solver.cpp:265] Tests completed in 83.5963s
I0325 12:16:17.948511 29022 solver.cpp:314] Iteration 54000 (0.614926 iter/s, 162.621s/100 iter), loss = 3.27815
I0325 12:16:17.948565 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.08374 (* 1 = 2.08374 loss)
I0325 12:16:17.948925 29022 sgd_solver.cpp:136] Iteration 54000, lr = 1e-07, m = 0.9
I0325 12:17:37.445897 29022 solver.cpp:314] Iteration 54100 (1.25794 iter/s, 79.4948s/100 iter), loss = 3.02956
I0325 12:17:37.447237 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.58808 (* 1 = 2.58808 loss)
I0325 12:17:37.447257 29022 sgd_solver.cpp:136] Iteration 54100, lr = 9.34983e-08, m = 0.9
I0325 12:18:56.660127 29022 solver.cpp:314] Iteration 54200 (1.26244 iter/s, 79.2117s/100 iter), loss = 3.22659
I0325 12:18:56.660238 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.42135 (* 1 = 2.42135 loss)
I0325 12:18:56.660256 29022 sgd_solver.cpp:136] Iteration 54200, lr = 8.73187e-08, m = 0.9
I0325 12:20:16.330727 29022 solver.cpp:314] Iteration 54300 (1.25521 iter/s, 79.668s/100 iter), loss = 3.06652
I0325 12:20:16.330885 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.88699 (* 1 = 2.88699 loss)
I0325 12:20:16.330931 29022 sgd_solver.cpp:136] Iteration 54300, lr = 8.14507e-08, m = 0.9
I0325 12:21:35.333050 29022 solver.cpp:314] Iteration 54400 (1.26583 iter/s, 78.9998s/100 iter), loss = 3.05325
I0325 12:21:35.333794 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.14401 (* 1 = 3.14401 loss)
I0325 12:21:35.333811 29022 sgd_solver.cpp:136] Iteration 54400, lr = 7.58834e-08, m = 0.9
I0325 12:22:54.602483 29022 solver.cpp:314] Iteration 54500 (1.26156 iter/s, 79.2669s/100 iter), loss = 3.05396
I0325 12:22:54.602668 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.08733 (* 1 = 3.08733 loss)
I0325 12:22:54.602705 29022 sgd_solver.cpp:136] Iteration 54500, lr = 7.06066e-08, m = 0.9
I0325 12:24:14.987537 29022 solver.cpp:314] Iteration 54600 (1.24405 iter/s, 80.3825s/100 iter), loss = 3.16774
I0325 12:24:14.987649 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.27372 (* 1 = 3.27372 loss)
I0325 12:24:14.987663 29022 sgd_solver.cpp:136] Iteration 54600, lr = 6.56099e-08, m = 0.9
I0325 12:25:33.542032 29022 solver.cpp:314] Iteration 54700 (1.27304 iter/s, 78.552s/100 iter), loss = 3.25519
I0325 12:25:33.542572 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.02123 (* 1 = 3.02123 loss)
I0325 12:25:33.542932 29022 sgd_solver.cpp:136] Iteration 54700, lr = 6.08833e-08, m = 0.9
I0325 12:26:52.875241 29022 solver.cpp:314] Iteration 54800 (1.26055 iter/s, 79.3307s/100 iter), loss = 3.07499
I0325 12:26:52.875378 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.06432 (* 1 = 3.06432 loss)
I0325 12:26:52.875413 29022 sgd_solver.cpp:136] Iteration 54800, lr = 5.64167e-08, m = 0.9
I0325 12:28:11.653473 29022 solver.cpp:314] Iteration 54900 (1.26943 iter/s, 78.7757s/100 iter), loss = 3.03862
I0325 12:28:11.653615 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.60828 (* 1 = 2.60828 loss)
I0325 12:28:11.653652 29022 sgd_solver.cpp:136] Iteration 54900, lr = 5.22006e-08, m = 0.9
I0325 12:29:31.548328 29022 solver.cpp:314] Iteration 55000 (1.25169 iter/s, 79.8923s/100 iter), loss = 3.22298
I0325 12:29:31.548434 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.04729 (* 1 = 3.04729 loss)
I0325 12:29:31.548449 29022 sgd_solver.cpp:136] Iteration 55000, lr = 4.82253e-08, m = 0.9
I0325 12:30:50.418123 29022 solver.cpp:314] Iteration 55100 (1.26795 iter/s, 78.8673s/100 iter), loss = 2.97203
I0325 12:30:50.418282 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.67275 (* 1 = 2.67275 loss)
I0325 12:30:50.418316 29022 sgd_solver.cpp:136] Iteration 55100, lr = 4.44815e-08, m = 0.9
I0325 12:32:10.212566 29022 solver.cpp:314] Iteration 55200 (1.25326 iter/s, 79.7919s/100 iter), loss = 3.32719
I0325 12:32:10.212750 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.59693 (* 1 = 2.59693 loss)
I0325 12:32:10.212795 29022 sgd_solver.cpp:136] Iteration 55200, lr = 4.096e-08, m = 0.9
I0325 12:33:29.847702 29022 solver.cpp:314] Iteration 55300 (1.25577 iter/s, 79.6326s/100 iter), loss = 3.1535
I0325 12:33:29.847849 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.31883 (* 1 = 3.31883 loss)
I0325 12:33:29.848067 29022 sgd_solver.cpp:136] Iteration 55300, lr = 3.76518e-08, m = 0.9
I0325 12:34:49.137277 29022 solver.cpp:314] Iteration 55400 (1.26124 iter/s, 79.287s/100 iter), loss = 3.21195
I0325 12:34:49.137624 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.3873 (* 1 = 2.3873 loss)
I0325 12:34:49.137662 29022 sgd_solver.cpp:136] Iteration 55400, lr = 3.45483e-08, m = 0.9
I0325 12:36:07.236160 29022 solver.cpp:314] Iteration 55500 (1.28047 iter/s, 78.0964s/100 iter), loss = 3.14586
I0325 12:36:07.244573 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.77189 (* 1 = 3.77189 loss)
I0325 12:36:07.244715 29022 sgd_solver.cpp:136] Iteration 55500, lr = 3.16406e-08, m = 0.9
I0325 12:37:25.415241 29022 solver.cpp:314] Iteration 55600 (1.27916 iter/s, 78.1766s/100 iter), loss = 3.08283
I0325 12:37:25.415691 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.98714 (* 1 = 2.98714 loss)
I0325 12:37:25.416012 29022 sgd_solver.cpp:136] Iteration 55600, lr = 2.89205e-08, m = 0.9
I0325 12:38:44.936046 29022 solver.cpp:314] Iteration 55700 (1.25757 iter/s, 79.5183s/100 iter), loss = 2.94662
I0325 12:38:44.936197 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.12871 (* 1 = 3.12871 loss)
I0325 12:38:44.936234 29022 sgd_solver.cpp:136] Iteration 55700, lr = 2.63796e-08, m = 0.9
I0325 12:40:04.446135 29022 solver.cpp:314] Iteration 55800 (1.25774 iter/s, 79.5076s/100 iter), loss = 3.22557
I0325 12:40:04.446305 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.21493 (* 1 = 3.21493 loss)
I0325 12:40:04.446342 29022 sgd_solver.cpp:136] Iteration 55800, lr = 2.401e-08, m = 0.9
I0325 12:41:23.772308 29022 solver.cpp:314] Iteration 55900 (1.26066 iter/s, 79.3236s/100 iter), loss = 3.11808
I0325 12:41:23.772471 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.93161 (* 1 = 3.93161 loss)
I0325 12:41:23.772505 29022 sgd_solver.cpp:136] Iteration 55900, lr = 2.18037e-08, m = 0.9
I0325 12:42:43.028869 29022 solver.cpp:360] Sparsity after update:
I0325 12:42:43.031955 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 12:42:43.032001 29022 net.cpp:2200] conv1a_param_0(0.397) 
I0325 12:42:43.032039 29022 net.cpp:2200] conv1b_param_0(0.68) 
I0325 12:42:43.032073 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 12:42:43.032102 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 12:42:43.032136 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 12:42:43.032167 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 12:42:43.032199 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 12:42:43.032229 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 12:42:43.032258 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 12:42:43.032289 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 12:42:43.032321 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 12:42:43.032351 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 12:42:43.032382 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 12:42:43.032413 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 12:42:43.032444 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 12:42:43.032474 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 12:42:43.032505 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 12:42:43.032536 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 12:42:43.032565 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 12:42:43.032596 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 12:42:43.032625 29022 net.cpp:2200] res2a_branch2a_param_0(0.723) 
I0325 12:42:43.032657 29022 net.cpp:2200] res2a_branch2b_param_0(0.571) 
I0325 12:42:43.032688 29022 net.cpp:2200] res3a_branch2a_param_0(0.675) 
I0325 12:42:43.032719 29022 net.cpp:2200] res3a_branch2b_param_0(0.647) 
I0325 12:42:43.032749 29022 net.cpp:2200] res4a_branch2a_param_0(0.754) 
I0325 12:42:43.032780 29022 net.cpp:2200] res4a_branch2b_param_0(0.701) 
I0325 12:42:43.032810 29022 net.cpp:2200] res5a_branch2a_param_0(0.786) 
I0325 12:42:43.032842 29022 net.cpp:2200] res5a_branch2b_param_0(0.796) 
I0325 12:42:43.032872 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.81684e+06/3.10435e+06) 0.585
I0325 12:42:43.032924 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_56000.caffemodel
I0325 12:42:43.060534 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_56000.solverstate
I0325 12:42:43.074054 29022 solver.cpp:678] Iteration 56000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.240376
j:  : 4 : max_pr:  : 0.458117
j:  : 3 : max_pr:  : 0.596194
j:  : 2 : max_pr:  : 0.709949
j:  : 1 : max_pr:  : 0.848279
j:  : 0 : max_pr:  : 1
I0325 12:44:06.162237 29022 solver.cpp:786] class AP 1: 0.350265
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.177572
j:  : 7 : max_pr:  : 0.327931
j:  : 6 : max_pr:  : 0.555468
j:  : 5 : max_pr:  : 0.630846
j:  : 4 : max_pr:  : 0.737906
j:  : 3 : max_pr:  : 0.78843
j:  : 2 : max_pr:  : 0.985562
j:  : 1 : max_pr:  : 0.997944
j:  : 0 : max_pr:  : 1
I0325 12:44:06.264374 29022 solver.cpp:786] class AP 2: 0.563787
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.493959
j:  : 6 : max_pr:  : 0.65549
j:  : 5 : max_pr:  : 0.75096
j:  : 4 : max_pr:  : 0.83321
j:  : 3 : max_pr:  : 0.917037
j:  : 2 : max_pr:  : 0.966387
j:  : 1 : max_pr:  : 0.996684
j:  : 0 : max_pr:  : 1
I0325 12:44:06.286713 29022 solver.cpp:786] class AP 3: 0.601248
I0325 12:44:06.286734 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.5051
I0325 12:44:06.286780 29022 solver.cpp:265] Tests completed in 83.2101s
I0325 12:44:06.958004 29022 solver.cpp:314] Iteration 56000 (0.612818 iter/s, 163.18s/100 iter), loss = 3.22195
I0325 12:44:06.958053 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.66426 (* 1 = 2.66426 loss)
I0325 12:44:06.958067 29022 sgd_solver.cpp:136] Iteration 56000, lr = 1.97531e-08, m = 0.9
I0325 12:45:25.084753 29022 solver.cpp:314] Iteration 56100 (1.28001 iter/s, 78.1242s/100 iter), loss = 3.03484
I0325 12:45:25.084883 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.21931 (* 1 = 2.21931 loss)
I0325 12:45:25.084899 29022 sgd_solver.cpp:136] Iteration 56100, lr = 1.78506e-08, m = 0.9
I0325 12:46:43.872205 29022 solver.cpp:314] Iteration 56200 (1.26928 iter/s, 78.7849s/100 iter), loss = 3.28966
I0325 12:46:43.872392 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.70702 (* 1 = 3.70702 loss)
I0325 12:46:43.872429 29022 sgd_solver.cpp:136] Iteration 56200, lr = 1.6089e-08, m = 0.9
I0325 12:48:03.831984 29022 solver.cpp:314] Iteration 56300 (1.25067 iter/s, 79.9572s/100 iter), loss = 3.0308
I0325 12:48:03.832118 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.52344 (* 1 = 3.52344 loss)
I0325 12:48:03.832152 29022 sgd_solver.cpp:136] Iteration 56300, lr = 1.44611e-08, m = 0.9
I0325 12:48:11.380882 29042 data_reader.cpp:305] Starting prefetch of epoch 16
I0325 12:49:23.152947 29022 solver.cpp:314] Iteration 56400 (1.26074 iter/s, 79.3184s/100 iter), loss = 3.04647
I0325 12:49:23.153061 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.15123 (* 1 = 4.15123 loss)
I0325 12:49:23.153079 29022 sgd_solver.cpp:136] Iteration 56400, lr = 1.296e-08, m = 0.9
I0325 12:50:42.700629 29022 solver.cpp:314] Iteration 56500 (1.25715 iter/s, 79.5451s/100 iter), loss = 3.34377
I0325 12:50:42.700742 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.63525 (* 1 = 3.63525 loss)
I0325 12:50:42.700757 29022 sgd_solver.cpp:136] Iteration 56500, lr = 1.15789e-08, m = 0.9
I0325 12:52:02.178190 29022 solver.cpp:314] Iteration 56600 (1.25826 iter/s, 79.475s/100 iter), loss = 3.31897
I0325 12:52:02.178328 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.40838 (* 1 = 2.40838 loss)
I0325 12:52:02.178364 29022 sgd_solver.cpp:136] Iteration 56600, lr = 1.03112e-08, m = 0.9
I0325 12:53:21.743324 29022 solver.cpp:314] Iteration 56700 (1.25687 iter/s, 79.5626s/100 iter), loss = 3.18356
I0325 12:53:21.743428 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.01636 (* 1 = 3.01636 loss)
I0325 12:53:21.743446 29022 sgd_solver.cpp:136] Iteration 56700, lr = 9.15063e-09, m = 0.9
I0325 12:54:40.507194 29022 solver.cpp:314] Iteration 56800 (1.26966 iter/s, 78.7614s/100 iter), loss = 3.09745
I0325 12:54:40.507354 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.169 (* 1 = 3.169 loss)
I0325 12:54:40.507393 29022 sgd_solver.cpp:136] Iteration 56800, lr = 8.09087e-09, m = 0.9
I0325 12:56:00.075759 29022 solver.cpp:314] Iteration 56900 (1.25682 iter/s, 79.566s/100 iter), loss = 3.25723
I0325 12:56:00.075913 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.43806 (* 1 = 3.43806 loss)
I0325 12:56:00.075948 29022 sgd_solver.cpp:136] Iteration 56900, lr = 7.12594e-09, m = 0.9
I0325 12:57:18.735643 29022 solver.cpp:314] Iteration 57000 (1.27134 iter/s, 78.6574s/100 iter), loss = 3.20695
I0325 12:57:18.736120 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.99254 (* 1 = 3.99254 loss)
I0325 12:57:18.736452 29022 sgd_solver.cpp:136] Iteration 57000, lr = 6.25001e-09, m = 0.9
I0325 12:58:37.859820 29022 solver.cpp:314] Iteration 57100 (1.26388 iter/s, 79.1217s/100 iter), loss = 3.01092
I0325 12:58:37.860015 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.81068 (* 1 = 2.81068 loss)
I0325 12:58:37.860033 29022 sgd_solver.cpp:136] Iteration 57100, lr = 5.45742e-09, m = 0.9
I0325 12:59:57.216469 29022 solver.cpp:314] Iteration 57200 (1.26017 iter/s, 79.3541s/100 iter), loss = 3.025
I0325 12:59:57.216621 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.79123 (* 1 = 3.79123 loss)
I0325 12:59:57.216658 29022 sgd_solver.cpp:136] Iteration 57200, lr = 4.74272e-09, m = 0.9
I0325 13:01:16.187042 29022 solver.cpp:314] Iteration 57300 (1.26634 iter/s, 78.968s/100 iter), loss = 3.0921
I0325 13:01:16.187224 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.9555 (* 1 = 2.9555 loss)
I0325 13:01:16.187259 29022 sgd_solver.cpp:136] Iteration 57300, lr = 4.10063e-09, m = 0.9
I0325 13:02:35.296386 29022 solver.cpp:314] Iteration 57400 (1.26411 iter/s, 79.1068s/100 iter), loss = 3.22223
I0325 13:02:35.296563 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.24816 (* 1 = 3.24816 loss)
I0325 13:02:35.296581 29022 sgd_solver.cpp:136] Iteration 57400, lr = 3.52606e-09, m = 0.9
I0325 13:03:53.963064 29022 solver.cpp:314] Iteration 57500 (1.27123 iter/s, 78.6642s/100 iter), loss = 3.14583
I0325 13:03:53.963217 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.17225 (* 1 = 2.17225 loss)
I0325 13:03:53.963255 29022 sgd_solver.cpp:136] Iteration 57500, lr = 3.01409e-09, m = 0.9
I0325 13:05:13.078088 29022 solver.cpp:314] Iteration 57600 (1.26402 iter/s, 79.1125s/100 iter), loss = 3.39738
I0325 13:05:13.078337 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.72697 (* 1 = 2.72697 loss)
I0325 13:05:13.078374 29022 sgd_solver.cpp:136] Iteration 57600, lr = 2.56001e-09, m = 0.9
I0325 13:06:32.159859 29022 solver.cpp:314] Iteration 57700 (1.26455 iter/s, 79.0792s/100 iter), loss = 3.13406
I0325 13:06:32.160019 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.86948 (* 1 = 2.86948 loss)
I0325 13:06:32.160058 29022 sgd_solver.cpp:136] Iteration 57700, lr = 2.15927e-09, m = 0.9
I0325 13:07:49.996743 29022 solver.cpp:314] Iteration 57800 (1.28478 iter/s, 77.8344s/100 iter), loss = 3.13792
I0325 13:07:49.996882 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.86425 (* 1 = 2.86425 loss)
I0325 13:07:49.996918 29022 sgd_solver.cpp:136] Iteration 57800, lr = 1.80754e-09, m = 0.9
I0325 13:09:08.900727 29022 solver.cpp:314] Iteration 57900 (1.2674 iter/s, 78.9015s/100 iter), loss = 3.05866
I0325 13:09:08.900907 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.34509 (* 1 = 3.34509 loss)
I0325 13:09:08.900940 29022 sgd_solver.cpp:136] Iteration 57900, lr = 1.50063e-09, m = 0.9
I0325 13:10:28.462234 29022 solver.cpp:360] Sparsity after update:
I0325 13:10:28.465317 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 13:10:28.465358 29022 net.cpp:2200] conv1a_param_0(0.397) 
I0325 13:10:28.465390 29022 net.cpp:2200] conv1b_param_0(0.68) 
I0325 13:10:28.465420 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 13:10:28.465445 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 13:10:28.465472 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 13:10:28.465498 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 13:10:28.465525 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 13:10:28.465551 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 13:10:28.465586 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 13:10:28.465613 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 13:10:28.465639 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 13:10:28.465664 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 13:10:28.465700 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 13:10:28.465731 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 13:10:28.465759 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 13:10:28.465785 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 13:10:28.465811 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 13:10:28.465836 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 13:10:28.465862 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 13:10:28.465886 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 13:10:28.465912 29022 net.cpp:2200] res2a_branch2a_param_0(0.723) 
I0325 13:10:28.465939 29022 net.cpp:2200] res2a_branch2b_param_0(0.571) 
I0325 13:10:28.465965 29022 net.cpp:2200] res3a_branch2a_param_0(0.675) 
I0325 13:10:28.465991 29022 net.cpp:2200] res3a_branch2b_param_0(0.647) 
I0325 13:10:28.466017 29022 net.cpp:2200] res4a_branch2a_param_0(0.754) 
I0325 13:10:28.466042 29022 net.cpp:2200] res4a_branch2b_param_0(0.701) 
I0325 13:10:28.466068 29022 net.cpp:2200] res5a_branch2a_param_0(0.786) 
I0325 13:10:28.466094 29022 net.cpp:2200] res5a_branch2b_param_0(0.796) 
I0325 13:10:28.466120 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.81684e+06/3.10435e+06) 0.585
I0325 13:10:28.466164 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_58000.caffemodel
I0325 13:10:28.495923 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_58000.solverstate
I0325 13:10:28.505468 29022 solver.cpp:678] Iteration 58000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.234509
j:  : 4 : max_pr:  : 0.45546
j:  : 3 : max_pr:  : 0.592746
j:  : 2 : max_pr:  : 0.706341
j:  : 1 : max_pr:  : 0.84845
j:  : 0 : max_pr:  : 1
I0325 13:11:51.568177 29022 solver.cpp:786] class AP 1: 0.348864
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.172902
j:  : 7 : max_pr:  : 0.325169
j:  : 6 : max_pr:  : 0.5555
j:  : 5 : max_pr:  : 0.631851
j:  : 4 : max_pr:  : 0.740043
j:  : 3 : max_pr:  : 0.786902
j:  : 2 : max_pr:  : 0.98486
j:  : 1 : max_pr:  : 0.997786
j:  : 0 : max_pr:  : 1
I0325 13:11:51.670023 29022 solver.cpp:786] class AP 2: 0.563183
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.493536
j:  : 6 : max_pr:  : 0.657171
j:  : 5 : max_pr:  : 0.751094
j:  : 4 : max_pr:  : 0.834037
j:  : 3 : max_pr:  : 0.91683
j:  : 2 : max_pr:  : 0.966712
j:  : 1 : max_pr:  : 0.99669
j:  : 0 : max_pr:  : 1
I0325 13:11:51.692355 29022 solver.cpp:786] class AP 3: 0.601461
I0325 13:11:51.692370 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.504503
I0325 13:11:51.692450 29022 solver.cpp:265] Tests completed in 83.1843s
I0325 13:11:52.303645 29022 solver.cpp:314] Iteration 58000 (0.612004 iter/s, 163.398s/100 iter), loss = 3.17188
I0325 13:11:52.303701 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.19414 (* 1 = 3.19414 loss)
I0325 13:11:52.303714 29022 sgd_solver.cpp:136] Iteration 58000, lr = 1.23457e-09, m = 0.9
I0325 13:13:11.287415 29022 solver.cpp:314] Iteration 58100 (1.26612 iter/s, 78.9812s/100 iter), loss = 3.312
I0325 13:13:11.287539 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.6063 (* 1 = 3.6063 loss)
I0325 13:13:11.287555 29022 sgd_solver.cpp:136] Iteration 58100, lr = 1.00557e-09, m = 0.9
I0325 13:14:30.171914 29022 solver.cpp:314] Iteration 58200 (1.26772 iter/s, 78.882s/100 iter), loss = 3.35869
I0325 13:14:30.172061 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.27699 (* 1 = 3.27699 loss)
I0325 13:14:30.172099 29022 sgd_solver.cpp:136] Iteration 58200, lr = 8.09997e-10, m = 0.9
I0325 13:15:49.528477 29022 solver.cpp:314] Iteration 58300 (1.26018 iter/s, 79.354s/100 iter), loss = 3.02851
I0325 13:15:49.528666 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.86561 (* 1 = 2.86561 loss)
I0325 13:15:49.528683 29022 sgd_solver.cpp:136] Iteration 58300, lr = 6.4445e-10, m = 0.9
I0325 13:17:08.593559 29022 solver.cpp:314] Iteration 58400 (1.26482 iter/s, 79.0625s/100 iter), loss = 3.09192
I0325 13:17:08.593672 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.24697 (* 1 = 3.24697 loss)
I0325 13:17:08.593684 29022 sgd_solver.cpp:136] Iteration 58400, lr = 5.05677e-10, m = 0.9
I0325 13:18:27.191737 29022 solver.cpp:314] Iteration 58500 (1.27233 iter/s, 78.5957s/100 iter), loss = 3.23598
I0325 13:18:27.191931 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.96214 (* 1 = 3.96214 loss)
I0325 13:18:27.191948 29022 sgd_solver.cpp:136] Iteration 58500, lr = 3.90624e-10, m = 0.9
I0325 13:19:46.130758 29022 solver.cpp:314] Iteration 58600 (1.26684 iter/s, 78.9365s/100 iter), loss = 2.95683
I0325 13:19:46.130947 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.8182 (* 1 = 2.8182 loss)
I0325 13:19:46.130964 29022 sgd_solver.cpp:136] Iteration 58600, lr = 2.96419e-10, m = 0.9
I0325 13:21:05.545536 29022 solver.cpp:314] Iteration 58700 (1.25925 iter/s, 79.4122s/100 iter), loss = 3.25205
I0325 13:21:05.545686 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.45149 (* 1 = 3.45149 loss)
I0325 13:21:05.545740 29022 sgd_solver.cpp:136] Iteration 58700, lr = 2.20377e-10, m = 0.9
I0325 13:22:23.989472 29022 solver.cpp:314] Iteration 58800 (1.27484 iter/s, 78.4414s/100 iter), loss = 3.30212
I0325 13:22:23.989629 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.15861 (* 1 = 2.15861 loss)
I0325 13:22:23.989671 29022 sgd_solver.cpp:136] Iteration 58800, lr = 1.59999e-10, m = 0.9
I0325 13:23:42.285989 29022 solver.cpp:314] Iteration 58900 (1.27724 iter/s, 78.294s/100 iter), loss = 3.05841
I0325 13:23:42.286156 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.19959 (* 1 = 3.19959 loss)
I0325 13:23:42.286191 29022 sgd_solver.cpp:136] Iteration 58900, lr = 1.1297e-10, m = 0.9
I0325 13:25:02.248070 29022 solver.cpp:314] Iteration 59000 (1.25063 iter/s, 79.9595s/100 iter), loss = 3.31628
I0325 13:25:02.248216 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.40675 (* 1 = 3.40675 loss)
I0325 13:25:02.248255 29022 sgd_solver.cpp:136] Iteration 59000, lr = 7.71602e-11, m = 0.9
I0325 13:26:21.286005 29022 solver.cpp:314] Iteration 59100 (1.26526 iter/s, 79.0354s/100 iter), loss = 3.22547
I0325 13:26:21.286123 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.89576 (* 1 = 3.89576 loss)
I0325 13:26:21.286139 29022 sgd_solver.cpp:136] Iteration 59100, lr = 5.06248e-11, m = 0.9
I0325 13:27:39.956336 29022 solver.cpp:314] Iteration 59200 (1.27117 iter/s, 78.6678s/100 iter), loss = 3.16358
I0325 13:27:39.956471 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.90337 (* 1 = 3.90337 loss)
I0325 13:27:39.956506 29022 sgd_solver.cpp:136] Iteration 59200, lr = 3.16048e-11, m = 0.9
I0325 13:28:58.869958 29022 solver.cpp:314] Iteration 59300 (1.26725 iter/s, 78.9111s/100 iter), loss = 3.18817
I0325 13:28:58.870180 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.27781 (* 1 = 2.27781 loss)
I0325 13:28:58.870216 29022 sgd_solver.cpp:136] Iteration 59300, lr = 1.85262e-11, m = 0.9
I0325 13:30:17.763257 29022 solver.cpp:314] Iteration 59400 (1.26758 iter/s, 78.8908s/100 iter), loss = 3.18027
I0325 13:30:17.763394 29022 solver.cpp:336]     Train net output #0: mbox_loss = 4.01922 (* 1 = 4.01922 loss)
I0325 13:30:17.763432 29022 sgd_solver.cpp:136] Iteration 59400, lr = 9.99996e-12, m = 0.9
I0325 13:30:47.690193 29042 data_reader.cpp:305] Starting prefetch of epoch 17
I0325 13:31:37.510234 29022 solver.cpp:314] Iteration 59500 (1.25401 iter/s, 79.7444s/100 iter), loss = 3.15236
I0325 13:31:37.510432 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.02613 (* 1 = 3.02613 loss)
I0325 13:31:37.510469 29022 sgd_solver.cpp:136] Iteration 59500, lr = 4.82251e-12, m = 0.9
I0325 13:32:55.029289 29022 solver.cpp:314] Iteration 59600 (1.29005 iter/s, 77.5166s/100 iter), loss = 3.16237
I0325 13:32:55.029388 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.14624 (* 1 = 3.14624 loss)
I0325 13:32:55.029489 29022 sgd_solver.cpp:136] Iteration 59600, lr = 1.9753e-12, m = 0.9
I0325 13:34:13.348970 29022 solver.cpp:314] Iteration 59700 (1.27686 iter/s, 78.3172s/100 iter), loss = 3.151
I0325 13:34:13.349509 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.15393 (* 1 = 3.15393 loss)
I0325 13:34:13.349834 29022 sgd_solver.cpp:136] Iteration 59700, lr = 6.24998e-13, m = 0.9
I0325 13:35:31.926849 29022 solver.cpp:314] Iteration 59800 (1.27266 iter/s, 78.5754s/100 iter), loss = 3.13751
I0325 13:35:31.927011 29022 solver.cpp:336]     Train net output #0: mbox_loss = 3.94857 (* 1 = 3.94857 loss)
I0325 13:35:31.927045 29022 sgd_solver.cpp:136] Iteration 59800, lr = 1.23456e-13, m = 0.9
I0325 13:36:51.435206 29022 solver.cpp:314] Iteration 59900 (1.25777 iter/s, 79.5058s/100 iter), loss = 3.20109
I0325 13:36:51.435407 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.67648 (* 1 = 2.67648 loss)
I0325 13:36:51.435425 29022 sgd_solver.cpp:136] Iteration 59900, lr = 7.71602e-15, m = 0.9
I0325 13:38:09.379926 29022 solver.cpp:314] Iteration 59999 (1.27017 iter/s, 77.9422s/99 iter), loss = 3.23104
I0325 13:38:09.380102 29022 solver.cpp:336]     Train net output #0: mbox_loss = 2.97194 (* 1 = 2.97194 loss)
I0325 13:38:09.384035 29022 solver.cpp:360] Sparsity after update:
I0325 13:38:09.387251 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 13:38:09.387305 29022 net.cpp:2200] conv1a_param_0(0.397) 
I0325 13:38:09.387341 29022 net.cpp:2200] conv1b_param_0(0.68) 
I0325 13:38:09.387372 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 13:38:09.387403 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 13:38:09.387434 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 13:38:09.387466 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 13:38:09.387497 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 13:38:09.387528 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 13:38:09.387559 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 13:38:09.387589 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 13:38:09.387621 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 13:38:09.387652 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 13:38:09.387683 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 13:38:09.387713 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 13:38:09.387743 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 13:38:09.387774 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 13:38:09.387806 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 13:38:09.387836 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 13:38:09.387868 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 13:38:09.387898 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 13:38:09.387928 29022 net.cpp:2200] res2a_branch2a_param_0(0.723) 
I0325 13:38:09.387959 29022 net.cpp:2200] res2a_branch2b_param_0(0.571) 
I0325 13:38:09.387991 29022 net.cpp:2200] res3a_branch2a_param_0(0.675) 
I0325 13:38:09.388021 29022 net.cpp:2200] res3a_branch2b_param_0(0.647) 
I0325 13:38:09.388052 29022 net.cpp:2200] res4a_branch2a_param_0(0.754) 
I0325 13:38:09.388083 29022 net.cpp:2200] res4a_branch2b_param_0(0.701) 
I0325 13:38:09.388113 29022 net.cpp:2200] res5a_branch2a_param_0(0.786) 
I0325 13:38:09.388144 29022 net.cpp:2200] res5a_branch2b_param_0(0.796) 
I0325 13:38:09.388175 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.81684e+06/3.10435e+06) 0.585
I0325 13:38:09.388239 29022 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_60000.caffemodel
I0325 13:38:09.416671 29022 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_60000.solverstate
I0325 13:38:09.453305 29022 solver.cpp:390] Sparsity after training:
I0325 13:38:09.456874 29022 net.cpp:2189] Num Params(28), Sparsity (zero_weights/count): 
I0325 13:38:09.456990 29022 net.cpp:2200] conv1a_param_0(0.397) 
I0325 13:38:09.457031 29022 net.cpp:2200] conv1b_param_0(0.68) 
I0325 13:38:09.457062 29022 net.cpp:2200] ctx_output1/relu_mbox_conf_param_0(0) 
I0325 13:38:09.457093 29022 net.cpp:2200] ctx_output1/relu_mbox_loc_param_0(0) 
I0325 13:38:09.457123 29022 net.cpp:2200] ctx_output1_param_0(0) 
I0325 13:38:09.457154 29022 net.cpp:2200] ctx_output2/relu_mbox_conf_param_0(0) 
I0325 13:38:09.457183 29022 net.cpp:2200] ctx_output2/relu_mbox_loc_param_0(0) 
I0325 13:38:09.457214 29022 net.cpp:2200] ctx_output2_param_0(0) 
I0325 13:38:09.457245 29022 net.cpp:2200] ctx_output3/relu_mbox_conf_param_0(0) 
I0325 13:38:09.457275 29022 net.cpp:2200] ctx_output3/relu_mbox_loc_param_0(0) 
I0325 13:38:09.457306 29022 net.cpp:2200] ctx_output3_param_0(0) 
I0325 13:38:09.457336 29022 net.cpp:2200] ctx_output4/relu_mbox_conf_param_0(0) 
I0325 13:38:09.457365 29022 net.cpp:2200] ctx_output4/relu_mbox_loc_param_0(0) 
I0325 13:38:09.457394 29022 net.cpp:2200] ctx_output4_param_0(0) 
I0325 13:38:09.457446 29022 net.cpp:2200] ctx_output5/relu_mbox_conf_param_0(0) 
I0325 13:38:09.457478 29022 net.cpp:2200] ctx_output5/relu_mbox_loc_param_0(0) 
I0325 13:38:09.457507 29022 net.cpp:2200] ctx_output5_param_0(0) 
I0325 13:38:09.457537 29022 net.cpp:2200] ctx_output6/relu_mbox_conf_param_0(0) 
I0325 13:38:09.457567 29022 net.cpp:2200] ctx_output6/relu_mbox_loc_param_0(0) 
I0325 13:38:09.457597 29022 net.cpp:2200] ctx_output6_param_0(0) 
I0325 13:38:09.457625 29022 net.cpp:2200] res2a_branch2a_param_0(0.723) 
I0325 13:38:09.457656 29022 net.cpp:2200] res2a_branch2b_param_0(0.571) 
I0325 13:38:09.457686 29022 net.cpp:2200] res3a_branch2a_param_0(0.675) 
I0325 13:38:09.457738 29022 net.cpp:2200] res3a_branch2b_param_0(0.647) 
I0325 13:38:09.457769 29022 net.cpp:2200] res4a_branch2a_param_0(0.754) 
I0325 13:38:09.457799 29022 net.cpp:2200] res4a_branch2b_param_0(0.701) 
I0325 13:38:09.457830 29022 net.cpp:2200] res5a_branch2a_param_0(0.786) 
I0325 13:38:09.457859 29022 net.cpp:2200] res5a_branch2b_param_0(0.796) 
I0325 13:38:09.457888 29022 net.cpp:2204] Total Sparsity (zero_weights/count) =  (1.81684e+06/3.10435e+06) 0.585
I0325 13:38:09.599259 29022 solver.cpp:549] Iteration 60000, loss = 3.21173
I0325 13:38:09.599361 29022 solver.cpp:678] Iteration 60000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.232801
j:  : 4 : max_pr:  : 0.454297
j:  : 3 : max_pr:  : 0.592062
j:  : 2 : max_pr:  : 0.704413
j:  : 1 : max_pr:  : 0.845652
j:  : 0 : max_pr:  : 1
I0325 13:39:32.990612 29022 solver.cpp:786] class AP 1: 0.348111
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.175822
j:  : 7 : max_pr:  : 0.330138
j:  : 6 : max_pr:  : 0.549819
j:  : 5 : max_pr:  : 0.628302
j:  : 4 : max_pr:  : 0.732418
j:  : 3 : max_pr:  : 0.783484
j:  : 2 : max_pr:  : 0.985551
j:  : 1 : max_pr:  : 0.997848
j:  : 0 : max_pr:  : 1
I0325 13:39:33.094563 29022 solver.cpp:786] class AP 2: 0.562126
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.490221
j:  : 6 : max_pr:  : 0.655146
j:  : 5 : max_pr:  : 0.749827
j:  : 4 : max_pr:  : 0.831475
j:  : 3 : max_pr:  : 0.916332
j:  : 2 : max_pr:  : 0.966215
j:  : 1 : max_pr:  : 0.996768
j:  : 0 : max_pr:  : 1
I0325 13:39:33.116879 29022 solver.cpp:786] class AP 3: 0.600544
I0325 13:39:33.116897 29022 solver.cpp:792] Test net output mAP #0: detection_eval = 0.503594
I0325 13:39:33.118041 29022 caffe.cpp:250] Solver performance on device 0: 1.192 * 8 = 9.538 img/sec (60000 itr in 5.033e+04 sec)
I0325 13:39:33.118067 29022 caffe.cpp:253] Optimization Done in 14h 1m 44s
