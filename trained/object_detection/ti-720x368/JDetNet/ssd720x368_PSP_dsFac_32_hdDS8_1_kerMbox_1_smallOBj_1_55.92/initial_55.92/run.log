WARNING: gnome-keyring:: couldn't connect to: /run/user/35652/keyring-xHkzME/pkcs11: Connection refused
p11-kit: skipping module 'gnome-keyring' whose initialization failed: An error occurred on the device
I0211 01:20:36.292768 20090 caffe.cpp:807] This is NVCaffe 0.16.4 started at Sun Feb 11 01:20:35 2018
I0211 01:20:36.292989 20090 caffe.cpp:810] CuDNN version: 6021
I0211 01:20:36.292997 20090 caffe.cpp:811] CuBLAS version: 8000
I0211 01:20:36.293001 20090 caffe.cpp:812] CUDA version: 8000
I0211 01:20:36.293004 20090 caffe.cpp:813] CUDA driver version: 8000
I0211 01:20:36.660941 20090 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0211 01:20:36.661615 20090 gpu_memory.cpp:161] Total memory: 8504279040, Free: 8215199744, dev_info[0]: total=8504279040 free=8215199744
I0211 01:20:36.662220 20090 gpu_memory.cpp:161] Total memory: 8507555840, Free: 8215199744, dev_info[1]: total=8507555840 free=8378646528
I0211 01:20:36.662235 20090 caffe.cpp:214] Using GPUs 0, 1
I0211 01:20:36.662528 20090 caffe.cpp:219] GPU 0: GeForce GTX 1080
I0211 01:20:36.662825 20090 caffe.cpp:219] GPU 1: GeForce GTX 1080
I0211 01:20:36.662880 20090 solver.cpp:43] Solver data type: FLOAT
I0211 01:20:36.662943 20090 solver.cpp:46] Initializing solver from parameters: 
train_net: "training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/train.prototxt"
test_net: "training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/test.prototxt"
test_iter: 452
test_interval: 2000
base_lr: 0.001
display: 100
max_iter: 120000
lr_policy: "poly"
gamma: 0.1
power: 4
momentum: 0.9
weight_decay: 0.0005
snapshot: 2000
snapshot_prefix: "training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
snapshot_after_train: true
test_initialization: true
average_loss: 10
stepvalue: 60000
stepvalue: 90000
stepvalue: 200000
iter_size: 2
type: "SGD"
eval_type: "detection"
ap_version: "11point"
show_per_class_result: true
I0211 01:20:36.674513 20090 solver.cpp:78] Creating training net from train_net file: training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/train.prototxt
I0211 01:20:36.677951 20090 net.cpp:72] Initializing net from parameters: 
name: "ssdJacintoNetV2"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 0
    mean_value: 0
    mean_value: 0
    force_color: false
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 368
      width: 720
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: NEAREST
      interp_mode: CUBIC
      interp_mode: LANCZOS4
    }
    emit_constraint {
      emit_type: CENTER
    }
    crop_h: 368
    crop_w: 720
    distort_param {
      brightness_prob: 0.5
      brightness_delta: 32
      contrast_prob: 0.5
      contrast_lower: 0.5
      contrast_upper: 1.5
      hue_prob: 0.5
      hue_delta: 18
      saturation_prob: 0.5
      saturation_lower: 0.5
      saturation_upper: 1.5
      random_order_prob: 0
    }
    expand_param {
      prob: 0.5
      max_expand_ratio: 4
    }
  }
  data_param {
    source: "/user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb"
    batch_size: 8
    backend: LMDB
    threads: 4
    parser_threads: 4
  }
  annotated_data_param {
    batch_sampler {
      max_sample: 1
      max_trials: 1
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.1
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.3
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.5
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.7
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.9
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        max_jaccard_overlap: 1
      }
      max_sample: 1
      max_trials: 50
    }
    label_map_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/labelmap.prototxt"
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "pool6"
  top: "pool7"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool8"
  type: "Pooling"
  bottom: "pool7"
  top: "pool8"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool9"
  type: "Pooling"
  bottom: "pool8"
  top: "pool9"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "ctx_output1"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "ctx_output1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu"
  type: "ReLU"
  bottom: "ctx_output1"
  top: "ctx_output1"
}
layer {
  name: "ctx_output2"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "ctx_output2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu"
  type: "ReLU"
  bottom: "ctx_output2"
  top: "ctx_output2"
}
layer {
  name: "ctx_output3"
  type: "Convolution"
  bottom: "pool6"
  top: "ctx_output3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu"
  type: "ReLU"
  bottom: "ctx_output3"
  top: "ctx_output3"
}
layer {
  name: "ctx_output4"
  type: "Convolution"
  bottom: "pool7"
  top: "ctx_output4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu"
  type: "ReLU"
  bottom: "ctx_output4"
  top: "ctx_output4"
}
layer {
  name: "ctx_output5"
  type: "Convolution"
  bottom: "pool8"
  top: "ctx_output5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu"
  type: "ReLU"
  bottom: "ctx_output5"
  top: "ctx_output5"
}
layer {
  name: "ctx_output6"
  type: "Convolution"
  bottom: "pool9"
  top: "ctx_output6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu"
  type: "ReLU"
  bottom: "ctx_output6"
  top: "ctx_output6"
}
layer {
  name: "ctx_output1/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_loc"
  top: "ctx_output1/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_loc_perm"
  top: "ctx_output1/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_conf"
  top: "ctx_output1/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_conf_perm"
  top: "ctx_output1/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output1"
  bottom: "data"
  top: "ctx_output1/relu_mbox_priorbox"
  prior_box_param {
    min_size: 14.72
    max_size: 36.8
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_loc"
  top: "ctx_output2/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_loc_perm"
  top: "ctx_output2/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_conf"
  top: "ctx_output2/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_conf_perm"
  top: "ctx_output2/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output2"
  bottom: "data"
  top: "ctx_output2/relu_mbox_priorbox"
  prior_box_param {
    min_size: 36.8
    max_size: 110.4
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_loc"
  top: "ctx_output3/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_loc_perm"
  top: "ctx_output3/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_conf"
  top: "ctx_output3/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_conf_perm"
  top: "ctx_output3/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output3"
  bottom: "data"
  top: "ctx_output3/relu_mbox_priorbox"
  prior_box_param {
    min_size: 110.4
    max_size: 184
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_loc"
  top: "ctx_output4/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_loc_perm"
  top: "ctx_output4/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_conf"
  top: "ctx_output4/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_conf_perm"
  top: "ctx_output4/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output4"
  bottom: "data"
  top: "ctx_output4/relu_mbox_priorbox"
  prior_box_param {
    min_size: 184
    max_size: 257.6
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_loc"
  top: "ctx_output5/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_loc_perm"
  top: "ctx_output5/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_conf"
  top: "ctx_output5/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_conf_perm"
  top: "ctx_output5/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output5"
  bottom: "data"
  top: "ctx_output5/relu_mbox_priorbox"
  prior_box_param {
    min_size: 257.6
    max_size: 331.2
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_loc"
  top: "ctx_output6/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_loc_perm"
  top: "ctx_output6/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_conf"
  top: "ctx_output6/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_conf_perm"
  top: "ctx_output6/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output6"
  bottom: "data"
  top: "ctx_output6/relu_mbox_priorbox"
  prior_box_param {
    min_size: 331.2
    max_size: 404.8
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_loc_flat"
  bottom: "ctx_output2/relu_mbox_loc_flat"
  bottom: "ctx_output3/relu_mbox_loc_flat"
  bottom: "ctx_output4/relu_mbox_loc_flat"
  bottom: "ctx_output5/relu_mbox_loc_flat"
  bottom: "ctx_output6/relu_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_conf_flat"
  bottom: "ctx_output2/relu_mbox_conf_flat"
  bottom: "ctx_output3/relu_mbox_conf_flat"
  bottom: "ctx_output4/relu_mbox_conf_flat"
  bottom: "ctx_output5/relu_mbox_conf_flat"
  bottom: "ctx_output6/relu_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_priorbox"
  bottom: "ctx_output2/relu_mbox_priorbox"
  bottom: "ctx_output3/relu_mbox_priorbox"
  bottom: "ctx_output4/relu_mbox_priorbox"
  bottom: "ctx_output5/relu_mbox_priorbox"
  bottom: "ctx_output6/relu_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_loss"
  type: "MultiBoxLoss"
  bottom: "mbox_loc"
  bottom: "mbox_conf"
  bottom: "mbox_priorbox"
  bottom: "label"
  top: "mbox_loss"
  include {
    phase: TRAIN
  }
  propagate_down: true
  propagate_down: true
  propagate_down: false
  propagate_down: false
  loss_param {
    normalization: VALID
  }
  multibox_loss_param {
    loc_loss_type: SMOOTH_L1
    conf_loss_type: SOFTMAX
    loc_weight: 1
    num_classes: 4
    share_location: true
    match_type: PER_PREDICTION
    overlap_threshold: 0.5
    use_prior_for_matching: true
    background_label_id: 0
    use_difficult_gt: false
    neg_pos_ratio: 3
    neg_overlap: 0.5
    code_type: CENTER_SIZE
    ignore_cross_boundary_bbox: false
    mining_type: MAX_NEGATIVE
  }
}
I0211 01:20:36.678565 20090 net.cpp:104] Using FLOAT as default forward math type
I0211 01:20:36.678577 20090 net.cpp:110] Using FLOAT as default backward math type
I0211 01:20:36.678584 20090 layer_factory.hpp:136] Creating layer 'data' of type 'AnnotatedData'
I0211 01:20:36.678591 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:36.678715 20090 net.cpp:184] Created Layer data (0)
I0211 01:20:36.678726 20090 net.cpp:530] data -> data
I0211 01:20:36.678743 20090 net.cpp:530] data -> label
I0211 01:20:36.678804 20090 data_reader.cpp:58] Data Reader threads: 4, out queues: 16, depth: 8
I0211 01:20:36.678865 20090 internal_thread.cpp:19] Starting 4 internal thread(s) on device 0
I0211 01:20:36.680306 20125 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0211 01:20:36.681543 20126 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0211 01:20:36.683212 20124 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0211 01:20:36.684908 20123 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0211 01:20:36.695536 20090 annotated_data_layer.cpp:219] output data size: 8,3,368,720
I0211 01:20:36.695868 20090 annotated_data_layer.cpp:265] [0] Output data size: 8, 3, 368, 720
I0211 01:20:36.695926 20090 internal_thread.cpp:19] Starting 4 internal thread(s) on device 0
I0211 01:20:36.696043 20090 net.cpp:245] Setting up data
I0211 01:20:36.696068 20090 net.cpp:252] TRAIN Top shape for layer 0 'data' 8 3 368 720 (6359040)
I0211 01:20:36.696079 20090 net.cpp:252] TRAIN Top shape for layer 0 'data' 1 1 10 8 (80)
I0211 01:20:36.696089 20090 layer_factory.hpp:136] Creating layer 'data_data_0_split' of type 'Split'
I0211 01:20:36.696105 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:36.696156 20090 net.cpp:184] Created Layer data_data_0_split (1)
I0211 01:20:36.696172 20090 net.cpp:561] data_data_0_split <- data
I0211 01:20:36.696190 20090 net.cpp:530] data_data_0_split -> data_data_0_split_0
I0211 01:20:36.696208 20090 net.cpp:530] data_data_0_split -> data_data_0_split_1
I0211 01:20:36.696218 20090 net.cpp:530] data_data_0_split -> data_data_0_split_2
I0211 01:20:36.696231 20090 net.cpp:530] data_data_0_split -> data_data_0_split_3
I0211 01:20:36.696244 20090 net.cpp:530] data_data_0_split -> data_data_0_split_4
I0211 01:20:36.696252 20090 net.cpp:530] data_data_0_split -> data_data_0_split_5
I0211 01:20:36.696261 20090 net.cpp:530] data_data_0_split -> data_data_0_split_6
I0211 01:20:36.696475 20090 net.cpp:245] Setting up data_data_0_split
I0211 01:20:36.696521 20090 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 368 720 (6359040)
I0211 01:20:36.696542 20090 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 368 720 (6359040)
I0211 01:20:36.696552 20090 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 368 720 (6359040)
I0211 01:20:36.696563 20090 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 368 720 (6359040)
I0211 01:20:36.696575 20090 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 368 720 (6359040)
I0211 01:20:36.696586 20090 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 368 720 (6359040)
I0211 01:20:36.696597 20090 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 368 720 (6359040)
I0211 01:20:36.696609 20090 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0211 01:20:36.696619 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:36.696645 20090 net.cpp:184] Created Layer data/bias (2)
I0211 01:20:36.696655 20090 net.cpp:561] data/bias <- data_data_0_split_0
I0211 01:20:36.696666 20090 net.cpp:530] data/bias -> data/bias
I0211 01:20:36.699337 20090 net.cpp:245] Setting up data/bias
I0211 01:20:36.699370 20090 net.cpp:252] TRAIN Top shape for layer 2 'data/bias' 8 3 368 720 (6359040)
I0211 01:20:36.699396 20090 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0211 01:20:36.699406 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:36.699447 20090 net.cpp:184] Created Layer conv1a (3)
I0211 01:20:36.699456 20090 net.cpp:561] conv1a <- data/bias
I0211 01:20:36.699465 20090 net.cpp:530] conv1a -> conv1a
I0211 01:20:37.288475 20090 net.cpp:245] Setting up conv1a
I0211 01:20:37.288537 20090 net.cpp:252] TRAIN Top shape for layer 3 'conv1a' 8 32 184 360 (16957440)
I0211 01:20:37.288558 20090 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0211 01:20:37.288566 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.288621 20090 net.cpp:184] Created Layer conv1a/bn (4)
I0211 01:20:37.288632 20090 net.cpp:561] conv1a/bn <- conv1a
I0211 01:20:37.288641 20090 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0211 01:20:37.289597 20090 net.cpp:245] Setting up conv1a/bn
I0211 01:20:37.289615 20090 net.cpp:252] TRAIN Top shape for layer 4 'conv1a/bn' 8 32 184 360 (16957440)
I0211 01:20:37.289631 20090 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0211 01:20:37.289638 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.289656 20090 net.cpp:184] Created Layer conv1a/relu (5)
I0211 01:20:37.289664 20090 net.cpp:561] conv1a/relu <- conv1a
I0211 01:20:37.289669 20090 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0211 01:20:37.289692 20090 net.cpp:245] Setting up conv1a/relu
I0211 01:20:37.289701 20090 net.cpp:252] TRAIN Top shape for layer 5 'conv1a/relu' 8 32 184 360 (16957440)
I0211 01:20:37.289707 20090 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0211 01:20:37.289718 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.289736 20090 net.cpp:184] Created Layer conv1b (6)
I0211 01:20:37.289743 20090 net.cpp:561] conv1b <- conv1a
I0211 01:20:37.289749 20090 net.cpp:530] conv1b -> conv1b
I0211 01:20:37.291298 20090 net.cpp:245] Setting up conv1b
I0211 01:20:37.291318 20090 net.cpp:252] TRAIN Top shape for layer 6 'conv1b' 8 32 184 360 (16957440)
I0211 01:20:37.291332 20090 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0211 01:20:37.291338 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.291349 20090 net.cpp:184] Created Layer conv1b/bn (7)
I0211 01:20:37.291355 20090 net.cpp:561] conv1b/bn <- conv1b
I0211 01:20:37.291363 20090 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0211 01:20:37.292248 20090 net.cpp:245] Setting up conv1b/bn
I0211 01:20:37.292264 20090 net.cpp:252] TRAIN Top shape for layer 7 'conv1b/bn' 8 32 184 360 (16957440)
I0211 01:20:37.292279 20090 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0211 01:20:37.292284 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.292294 20090 net.cpp:184] Created Layer conv1b/relu (8)
I0211 01:20:37.292300 20090 net.cpp:561] conv1b/relu <- conv1b
I0211 01:20:37.292306 20090 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0211 01:20:37.292315 20090 net.cpp:245] Setting up conv1b/relu
I0211 01:20:37.292323 20090 net.cpp:252] TRAIN Top shape for layer 8 'conv1b/relu' 8 32 184 360 (16957440)
I0211 01:20:37.292328 20090 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0211 01:20:37.292336 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.292353 20090 net.cpp:184] Created Layer pool1 (9)
I0211 01:20:37.292361 20090 net.cpp:561] pool1 <- conv1b
I0211 01:20:37.292367 20090 net.cpp:530] pool1 -> pool1
I0211 01:20:37.292503 20090 net.cpp:245] Setting up pool1
I0211 01:20:37.292516 20090 net.cpp:252] TRAIN Top shape for layer 9 'pool1' 8 32 92 180 (4239360)
I0211 01:20:37.292522 20090 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0211 01:20:37.292528 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.292542 20090 net.cpp:184] Created Layer res2a_branch2a (10)
I0211 01:20:37.292551 20090 net.cpp:561] res2a_branch2a <- pool1
I0211 01:20:37.292557 20090 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0211 01:20:37.295032 20090 net.cpp:245] Setting up res2a_branch2a
I0211 01:20:37.295051 20090 net.cpp:252] TRAIN Top shape for layer 10 'res2a_branch2a' 8 64 92 180 (8478720)
I0211 01:20:37.295065 20090 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0211 01:20:37.295071 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.295095 20090 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0211 01:20:37.295102 20090 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0211 01:20:37.295109 20090 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0211 01:20:37.296365 20090 net.cpp:245] Setting up res2a_branch2a/bn
I0211 01:20:37.296385 20090 net.cpp:252] TRAIN Top shape for layer 11 'res2a_branch2a/bn' 8 64 92 180 (8478720)
I0211 01:20:37.296398 20090 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0211 01:20:37.296404 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.296412 20090 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0211 01:20:37.296418 20090 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0211 01:20:37.296424 20090 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0211 01:20:37.296433 20090 net.cpp:245] Setting up res2a_branch2a/relu
I0211 01:20:37.296442 20090 net.cpp:252] TRAIN Top shape for layer 12 'res2a_branch2a/relu' 8 64 92 180 (8478720)
I0211 01:20:37.296447 20090 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0211 01:20:37.296454 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.296469 20090 net.cpp:184] Created Layer res2a_branch2b (13)
I0211 01:20:37.296476 20090 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0211 01:20:37.296483 20090 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0211 01:20:37.298295 20090 net.cpp:245] Setting up res2a_branch2b
I0211 01:20:37.298316 20090 net.cpp:252] TRAIN Top shape for layer 13 'res2a_branch2b' 8 64 92 180 (8478720)
I0211 01:20:37.298326 20090 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0211 01:20:37.298332 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.298343 20090 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0211 01:20:37.298349 20090 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0211 01:20:37.298357 20090 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0211 01:20:37.299244 20090 net.cpp:245] Setting up res2a_branch2b/bn
I0211 01:20:37.299259 20090 net.cpp:252] TRAIN Top shape for layer 14 'res2a_branch2b/bn' 8 64 92 180 (8478720)
I0211 01:20:37.299273 20090 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0211 01:20:37.299279 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.299288 20090 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0211 01:20:37.299293 20090 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0211 01:20:37.299299 20090 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0211 01:20:37.299307 20090 net.cpp:245] Setting up res2a_branch2b/relu
I0211 01:20:37.299315 20090 net.cpp:252] TRAIN Top shape for layer 15 'res2a_branch2b/relu' 8 64 92 180 (8478720)
I0211 01:20:37.299321 20090 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0211 01:20:37.299329 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.299338 20090 net.cpp:184] Created Layer pool2 (16)
I0211 01:20:37.299345 20090 net.cpp:561] pool2 <- res2a_branch2b
I0211 01:20:37.299351 20090 net.cpp:530] pool2 -> pool2
I0211 01:20:37.299443 20090 net.cpp:245] Setting up pool2
I0211 01:20:37.299453 20090 net.cpp:252] TRAIN Top shape for layer 16 'pool2' 8 64 46 90 (2119680)
I0211 01:20:37.299458 20090 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0211 01:20:37.299464 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.299480 20090 net.cpp:184] Created Layer res3a_branch2a (17)
I0211 01:20:37.299486 20090 net.cpp:561] res3a_branch2a <- pool2
I0211 01:20:37.299492 20090 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0211 01:20:37.302583 20090 net.cpp:245] Setting up res3a_branch2a
I0211 01:20:37.302614 20090 net.cpp:252] TRAIN Top shape for layer 17 'res3a_branch2a' 8 128 46 90 (4239360)
I0211 01:20:37.302625 20090 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0211 01:20:37.302634 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.302654 20090 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0211 01:20:37.302661 20090 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0211 01:20:37.302669 20090 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0211 01:20:37.303545 20090 net.cpp:245] Setting up res3a_branch2a/bn
I0211 01:20:37.303561 20090 net.cpp:252] TRAIN Top shape for layer 18 'res3a_branch2a/bn' 8 128 46 90 (4239360)
I0211 01:20:37.303577 20090 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0211 01:20:37.303586 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.303594 20090 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0211 01:20:37.303601 20090 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0211 01:20:37.303608 20090 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0211 01:20:37.303618 20090 net.cpp:245] Setting up res3a_branch2a/relu
I0211 01:20:37.303627 20090 net.cpp:252] TRAIN Top shape for layer 19 'res3a_branch2a/relu' 8 128 46 90 (4239360)
I0211 01:20:37.303632 20090 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0211 01:20:37.303638 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.303654 20090 net.cpp:184] Created Layer res3a_branch2b (20)
I0211 01:20:37.303661 20090 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0211 01:20:37.303668 20090 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0211 01:20:37.305430 20090 net.cpp:245] Setting up res3a_branch2b
I0211 01:20:37.305447 20090 net.cpp:252] TRAIN Top shape for layer 20 'res3a_branch2b' 8 128 46 90 (4239360)
I0211 01:20:37.305457 20090 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0211 01:20:37.305464 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.305474 20090 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0211 01:20:37.305480 20090 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0211 01:20:37.305486 20090 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0211 01:20:37.306344 20090 net.cpp:245] Setting up res3a_branch2b/bn
I0211 01:20:37.306358 20090 net.cpp:252] TRAIN Top shape for layer 21 'res3a_branch2b/bn' 8 128 46 90 (4239360)
I0211 01:20:37.306370 20090 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0211 01:20:37.306376 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.306385 20090 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0211 01:20:37.306391 20090 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0211 01:20:37.306396 20090 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0211 01:20:37.306404 20090 net.cpp:245] Setting up res3a_branch2b/relu
I0211 01:20:37.306411 20090 net.cpp:252] TRAIN Top shape for layer 22 'res3a_branch2b/relu' 8 128 46 90 (4239360)
I0211 01:20:37.306421 20090 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0211 01:20:37.306427 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.306435 20090 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (23)
I0211 01:20:37.306442 20090 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0211 01:20:37.306447 20090 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0211 01:20:37.306454 20090 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0211 01:20:37.306520 20090 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0211 01:20:37.306545 20090 net.cpp:252] TRAIN Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 8 128 46 90 (4239360)
I0211 01:20:37.306552 20090 net.cpp:252] TRAIN Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 8 128 46 90 (4239360)
I0211 01:20:37.306558 20090 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0211 01:20:37.306566 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.306576 20090 net.cpp:184] Created Layer pool3 (24)
I0211 01:20:37.306583 20090 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0211 01:20:37.306589 20090 net.cpp:530] pool3 -> pool3
I0211 01:20:37.306674 20090 net.cpp:245] Setting up pool3
I0211 01:20:37.306684 20090 net.cpp:252] TRAIN Top shape for layer 24 'pool3' 8 128 23 45 (1059840)
I0211 01:20:37.306691 20090 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0211 01:20:37.306697 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.306711 20090 net.cpp:184] Created Layer res4a_branch2a (25)
I0211 01:20:37.306718 20090 net.cpp:561] res4a_branch2a <- pool3
I0211 01:20:37.306725 20090 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0211 01:20:37.319015 20090 net.cpp:245] Setting up res4a_branch2a
I0211 01:20:37.319034 20090 net.cpp:252] TRAIN Top shape for layer 25 'res4a_branch2a' 8 256 23 45 (2119680)
I0211 01:20:37.319046 20090 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0211 01:20:37.319052 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.319063 20090 net.cpp:184] Created Layer res4a_branch2a/bn (26)
I0211 01:20:37.319070 20090 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0211 01:20:37.319082 20090 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0211 01:20:37.319962 20090 net.cpp:245] Setting up res4a_branch2a/bn
I0211 01:20:37.319977 20090 net.cpp:252] TRAIN Top shape for layer 26 'res4a_branch2a/bn' 8 256 23 45 (2119680)
I0211 01:20:37.319990 20090 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0211 01:20:37.319999 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.320008 20090 net.cpp:184] Created Layer res4a_branch2a/relu (27)
I0211 01:20:37.320013 20090 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0211 01:20:37.320019 20090 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0211 01:20:37.320029 20090 net.cpp:245] Setting up res4a_branch2a/relu
I0211 01:20:37.320047 20090 net.cpp:252] TRAIN Top shape for layer 27 'res4a_branch2a/relu' 8 256 23 45 (2119680)
I0211 01:20:37.320052 20090 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0211 01:20:37.320058 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.320073 20090 net.cpp:184] Created Layer res4a_branch2b (28)
I0211 01:20:37.320078 20090 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0211 01:20:37.320086 20090 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0211 01:20:37.325809 20090 net.cpp:245] Setting up res4a_branch2b
I0211 01:20:37.325829 20090 net.cpp:252] TRAIN Top shape for layer 28 'res4a_branch2b' 8 256 23 45 (2119680)
I0211 01:20:37.325839 20090 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0211 01:20:37.325851 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.325863 20090 net.cpp:184] Created Layer res4a_branch2b/bn (29)
I0211 01:20:37.325872 20090 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0211 01:20:37.325879 20090 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0211 01:20:37.326766 20090 net.cpp:245] Setting up res4a_branch2b/bn
I0211 01:20:37.326781 20090 net.cpp:252] TRAIN Top shape for layer 29 'res4a_branch2b/bn' 8 256 23 45 (2119680)
I0211 01:20:37.326812 20090 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0211 01:20:37.326819 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.326828 20090 net.cpp:184] Created Layer res4a_branch2b/relu (30)
I0211 01:20:37.326833 20090 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0211 01:20:37.326840 20090 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0211 01:20:37.326850 20090 net.cpp:245] Setting up res4a_branch2b/relu
I0211 01:20:37.326865 20090 net.cpp:252] TRAIN Top shape for layer 30 'res4a_branch2b/relu' 8 256 23 45 (2119680)
I0211 01:20:37.326870 20090 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0211 01:20:37.326876 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.326887 20090 net.cpp:184] Created Layer pool4 (31)
I0211 01:20:37.326898 20090 net.cpp:561] pool4 <- res4a_branch2b
I0211 01:20:37.326905 20090 net.cpp:530] pool4 -> pool4
I0211 01:20:37.327000 20090 net.cpp:245] Setting up pool4
I0211 01:20:37.327011 20090 net.cpp:252] TRAIN Top shape for layer 31 'pool4' 8 256 12 23 (565248)
I0211 01:20:37.327018 20090 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0211 01:20:37.327023 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.327044 20090 net.cpp:184] Created Layer res5a_branch2a (32)
I0211 01:20:37.327056 20090 net.cpp:561] res5a_branch2a <- pool4
I0211 01:20:37.327064 20090 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0211 01:20:37.372365 20090 net.cpp:245] Setting up res5a_branch2a
I0211 01:20:37.372397 20090 net.cpp:252] TRAIN Top shape for layer 32 'res5a_branch2a' 8 512 12 23 (1130496)
I0211 01:20:37.372411 20090 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0211 01:20:37.372418 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.372442 20090 net.cpp:184] Created Layer res5a_branch2a/bn (33)
I0211 01:20:37.372449 20090 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0211 01:20:37.372459 20090 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0211 01:20:37.373409 20090 net.cpp:245] Setting up res5a_branch2a/bn
I0211 01:20:37.373425 20090 net.cpp:252] TRAIN Top shape for layer 33 'res5a_branch2a/bn' 8 512 12 23 (1130496)
I0211 01:20:37.373438 20090 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0211 01:20:37.373445 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.373456 20090 net.cpp:184] Created Layer res5a_branch2a/relu (34)
I0211 01:20:37.373466 20090 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0211 01:20:37.373472 20090 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0211 01:20:37.373481 20090 net.cpp:245] Setting up res5a_branch2a/relu
I0211 01:20:37.373489 20090 net.cpp:252] TRAIN Top shape for layer 34 'res5a_branch2a/relu' 8 512 12 23 (1130496)
I0211 01:20:37.373503 20090 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0211 01:20:37.373509 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.373528 20090 net.cpp:184] Created Layer res5a_branch2b (35)
I0211 01:20:37.373534 20090 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0211 01:20:37.373541 20090 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0211 01:20:37.396179 20090 net.cpp:245] Setting up res5a_branch2b
I0211 01:20:37.396212 20090 net.cpp:252] TRAIN Top shape for layer 35 'res5a_branch2b' 8 512 12 23 (1130496)
I0211 01:20:37.396245 20090 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0211 01:20:37.396253 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.396270 20090 net.cpp:184] Created Layer res5a_branch2b/bn (36)
I0211 01:20:37.396276 20090 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0211 01:20:37.396301 20090 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0211 01:20:37.397284 20090 net.cpp:245] Setting up res5a_branch2b/bn
I0211 01:20:37.397302 20090 net.cpp:252] TRAIN Top shape for layer 36 'res5a_branch2b/bn' 8 512 12 23 (1130496)
I0211 01:20:37.397323 20090 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0211 01:20:37.397330 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.397337 20090 net.cpp:184] Created Layer res5a_branch2b/relu (37)
I0211 01:20:37.397343 20090 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0211 01:20:37.397351 20090 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0211 01:20:37.397361 20090 net.cpp:245] Setting up res5a_branch2b/relu
I0211 01:20:37.397368 20090 net.cpp:252] TRAIN Top shape for layer 37 'res5a_branch2b/relu' 8 512 12 23 (1130496)
I0211 01:20:37.397373 20090 layer_factory.hpp:136] Creating layer 'res5a_branch2b_res5a_branch2b/relu_0_split' of type 'Split'
I0211 01:20:37.397385 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.397393 20090 net.cpp:184] Created Layer res5a_branch2b_res5a_branch2b/relu_0_split (38)
I0211 01:20:37.397400 20090 net.cpp:561] res5a_branch2b_res5a_branch2b/relu_0_split <- res5a_branch2b
I0211 01:20:37.397406 20090 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_0
I0211 01:20:37.397414 20090 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_1
I0211 01:20:37.397490 20090 net.cpp:245] Setting up res5a_branch2b_res5a_branch2b/relu_0_split
I0211 01:20:37.397508 20090 net.cpp:252] TRAIN Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 8 512 12 23 (1130496)
I0211 01:20:37.397516 20090 net.cpp:252] TRAIN Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 8 512 12 23 (1130496)
I0211 01:20:37.397523 20090 layer_factory.hpp:136] Creating layer 'pool6' of type 'Pooling'
I0211 01:20:37.397529 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.397542 20090 net.cpp:184] Created Layer pool6 (39)
I0211 01:20:37.397549 20090 net.cpp:561] pool6 <- res5a_branch2b_res5a_branch2b/relu_0_split_0
I0211 01:20:37.397557 20090 net.cpp:530] pool6 -> pool6
I0211 01:20:37.397655 20090 net.cpp:245] Setting up pool6
I0211 01:20:37.397666 20090 net.cpp:252] TRAIN Top shape for layer 39 'pool6' 8 512 6 12 (294912)
I0211 01:20:37.397672 20090 layer_factory.hpp:136] Creating layer 'pool6_pool6_0_split' of type 'Split'
I0211 01:20:37.397680 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.397686 20090 net.cpp:184] Created Layer pool6_pool6_0_split (40)
I0211 01:20:37.397693 20090 net.cpp:561] pool6_pool6_0_split <- pool6
I0211 01:20:37.397701 20090 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_0
I0211 01:20:37.397708 20090 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_1
I0211 01:20:37.397770 20090 net.cpp:245] Setting up pool6_pool6_0_split
I0211 01:20:37.397780 20090 net.cpp:252] TRAIN Top shape for layer 40 'pool6_pool6_0_split' 8 512 6 12 (294912)
I0211 01:20:37.397788 20090 net.cpp:252] TRAIN Top shape for layer 40 'pool6_pool6_0_split' 8 512 6 12 (294912)
I0211 01:20:37.397794 20090 layer_factory.hpp:136] Creating layer 'pool7' of type 'Pooling'
I0211 01:20:37.397799 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.397809 20090 net.cpp:184] Created Layer pool7 (41)
I0211 01:20:37.397815 20090 net.cpp:561] pool7 <- pool6_pool6_0_split_0
I0211 01:20:37.397821 20090 net.cpp:530] pool7 -> pool7
I0211 01:20:37.397907 20090 net.cpp:245] Setting up pool7
I0211 01:20:37.397917 20090 net.cpp:252] TRAIN Top shape for layer 41 'pool7' 8 512 3 6 (73728)
I0211 01:20:37.397922 20090 layer_factory.hpp:136] Creating layer 'pool7_pool7_0_split' of type 'Split'
I0211 01:20:37.397940 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.397948 20090 net.cpp:184] Created Layer pool7_pool7_0_split (42)
I0211 01:20:37.397955 20090 net.cpp:561] pool7_pool7_0_split <- pool7
I0211 01:20:37.397963 20090 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_0
I0211 01:20:37.397972 20090 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_1
I0211 01:20:37.398038 20090 net.cpp:245] Setting up pool7_pool7_0_split
I0211 01:20:37.398049 20090 net.cpp:252] TRAIN Top shape for layer 42 'pool7_pool7_0_split' 8 512 3 6 (73728)
I0211 01:20:37.398058 20090 net.cpp:252] TRAIN Top shape for layer 42 'pool7_pool7_0_split' 8 512 3 6 (73728)
I0211 01:20:37.398064 20090 layer_factory.hpp:136] Creating layer 'pool8' of type 'Pooling'
I0211 01:20:37.398070 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.398079 20090 net.cpp:184] Created Layer pool8 (43)
I0211 01:20:37.398087 20090 net.cpp:561] pool8 <- pool7_pool7_0_split_0
I0211 01:20:37.398092 20090 net.cpp:530] pool8 -> pool8
I0211 01:20:37.398180 20090 net.cpp:245] Setting up pool8
I0211 01:20:37.398190 20090 net.cpp:252] TRAIN Top shape for layer 43 'pool8' 8 512 2 3 (24576)
I0211 01:20:37.398196 20090 layer_factory.hpp:136] Creating layer 'pool8_pool8_0_split' of type 'Split'
I0211 01:20:37.398205 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.398212 20090 net.cpp:184] Created Layer pool8_pool8_0_split (44)
I0211 01:20:37.398219 20090 net.cpp:561] pool8_pool8_0_split <- pool8
I0211 01:20:37.398226 20090 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_0
I0211 01:20:37.398233 20090 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_1
I0211 01:20:37.398293 20090 net.cpp:245] Setting up pool8_pool8_0_split
I0211 01:20:37.398303 20090 net.cpp:252] TRAIN Top shape for layer 44 'pool8_pool8_0_split' 8 512 2 3 (24576)
I0211 01:20:37.398309 20090 net.cpp:252] TRAIN Top shape for layer 44 'pool8_pool8_0_split' 8 512 2 3 (24576)
I0211 01:20:37.398317 20090 layer_factory.hpp:136] Creating layer 'pool9' of type 'Pooling'
I0211 01:20:37.398324 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.398335 20090 net.cpp:184] Created Layer pool9 (45)
I0211 01:20:37.398342 20090 net.cpp:561] pool9 <- pool8_pool8_0_split_0
I0211 01:20:37.398350 20090 net.cpp:530] pool9 -> pool9
I0211 01:20:37.398432 20090 net.cpp:245] Setting up pool9
I0211 01:20:37.398442 20090 net.cpp:252] TRAIN Top shape for layer 45 'pool9' 8 512 1 2 (8192)
I0211 01:20:37.398449 20090 layer_factory.hpp:136] Creating layer 'ctx_output1' of type 'Convolution'
I0211 01:20:37.398457 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.398474 20090 net.cpp:184] Created Layer ctx_output1 (46)
I0211 01:20:37.398483 20090 net.cpp:561] ctx_output1 <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0211 01:20:37.398490 20090 net.cpp:530] ctx_output1 -> ctx_output1
I0211 01:20:37.400166 20090 net.cpp:245] Setting up ctx_output1
I0211 01:20:37.400183 20090 net.cpp:252] TRAIN Top shape for layer 46 'ctx_output1' 8 256 46 90 (8478720)
I0211 01:20:37.400193 20090 layer_factory.hpp:136] Creating layer 'ctx_output1/relu' of type 'ReLU'
I0211 01:20:37.400199 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.400207 20090 net.cpp:184] Created Layer ctx_output1/relu (47)
I0211 01:20:37.400213 20090 net.cpp:561] ctx_output1/relu <- ctx_output1
I0211 01:20:37.400219 20090 net.cpp:513] ctx_output1/relu -> ctx_output1 (in-place)
I0211 01:20:37.400228 20090 net.cpp:245] Setting up ctx_output1/relu
I0211 01:20:37.400233 20090 net.cpp:252] TRAIN Top shape for layer 47 'ctx_output1/relu' 8 256 46 90 (8478720)
I0211 01:20:37.400241 20090 layer_factory.hpp:136] Creating layer 'ctx_output1_ctx_output1/relu_0_split' of type 'Split'
I0211 01:20:37.400246 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.400269 20090 net.cpp:184] Created Layer ctx_output1_ctx_output1/relu_0_split (48)
I0211 01:20:37.400276 20090 net.cpp:561] ctx_output1_ctx_output1/relu_0_split <- ctx_output1
I0211 01:20:37.400282 20090 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_0
I0211 01:20:37.400291 20090 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_1
I0211 01:20:37.400300 20090 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_2
I0211 01:20:37.400398 20090 net.cpp:245] Setting up ctx_output1_ctx_output1/relu_0_split
I0211 01:20:37.400408 20090 net.cpp:252] TRAIN Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 8 256 46 90 (8478720)
I0211 01:20:37.400416 20090 net.cpp:252] TRAIN Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 8 256 46 90 (8478720)
I0211 01:20:37.400424 20090 net.cpp:252] TRAIN Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 8 256 46 90 (8478720)
I0211 01:20:37.400429 20090 layer_factory.hpp:136] Creating layer 'ctx_output2' of type 'Convolution'
I0211 01:20:37.400437 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.400456 20090 net.cpp:184] Created Layer ctx_output2 (49)
I0211 01:20:37.400465 20090 net.cpp:561] ctx_output2 <- res5a_branch2b_res5a_branch2b/relu_0_split_1
I0211 01:20:37.400470 20090 net.cpp:530] ctx_output2 -> ctx_output2
I0211 01:20:37.405678 20090 net.cpp:245] Setting up ctx_output2
I0211 01:20:37.405697 20090 net.cpp:252] TRAIN Top shape for layer 49 'ctx_output2' 8 256 12 23 (565248)
I0211 01:20:37.405707 20090 layer_factory.hpp:136] Creating layer 'ctx_output2/relu' of type 'ReLU'
I0211 01:20:37.405714 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.405721 20090 net.cpp:184] Created Layer ctx_output2/relu (50)
I0211 01:20:37.405727 20090 net.cpp:561] ctx_output2/relu <- ctx_output2
I0211 01:20:37.405733 20090 net.cpp:513] ctx_output2/relu -> ctx_output2 (in-place)
I0211 01:20:37.405745 20090 net.cpp:245] Setting up ctx_output2/relu
I0211 01:20:37.405752 20090 net.cpp:252] TRAIN Top shape for layer 50 'ctx_output2/relu' 8 256 12 23 (565248)
I0211 01:20:37.405757 20090 layer_factory.hpp:136] Creating layer 'ctx_output2_ctx_output2/relu_0_split' of type 'Split'
I0211 01:20:37.405766 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.405771 20090 net.cpp:184] Created Layer ctx_output2_ctx_output2/relu_0_split (51)
I0211 01:20:37.405778 20090 net.cpp:561] ctx_output2_ctx_output2/relu_0_split <- ctx_output2
I0211 01:20:37.405784 20090 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_0
I0211 01:20:37.405794 20090 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_1
I0211 01:20:37.405803 20090 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_2
I0211 01:20:37.405901 20090 net.cpp:245] Setting up ctx_output2_ctx_output2/relu_0_split
I0211 01:20:37.405912 20090 net.cpp:252] TRAIN Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 8 256 12 23 (565248)
I0211 01:20:37.405920 20090 net.cpp:252] TRAIN Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 8 256 12 23 (565248)
I0211 01:20:37.405926 20090 net.cpp:252] TRAIN Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 8 256 12 23 (565248)
I0211 01:20:37.405932 20090 layer_factory.hpp:136] Creating layer 'ctx_output3' of type 'Convolution'
I0211 01:20:37.405939 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.405956 20090 net.cpp:184] Created Layer ctx_output3 (52)
I0211 01:20:37.405963 20090 net.cpp:561] ctx_output3 <- pool6_pool6_0_split_1
I0211 01:20:37.405971 20090 net.cpp:530] ctx_output3 -> ctx_output3
I0211 01:20:37.412359 20090 net.cpp:245] Setting up ctx_output3
I0211 01:20:37.412384 20090 net.cpp:252] TRAIN Top shape for layer 52 'ctx_output3' 8 256 6 12 (147456)
I0211 01:20:37.412395 20090 layer_factory.hpp:136] Creating layer 'ctx_output3/relu' of type 'ReLU'
I0211 01:20:37.412406 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.412417 20090 net.cpp:184] Created Layer ctx_output3/relu (53)
I0211 01:20:37.412425 20090 net.cpp:561] ctx_output3/relu <- ctx_output3
I0211 01:20:37.412432 20090 net.cpp:513] ctx_output3/relu -> ctx_output3 (in-place)
I0211 01:20:37.412441 20090 net.cpp:245] Setting up ctx_output3/relu
I0211 01:20:37.412456 20090 net.cpp:252] TRAIN Top shape for layer 53 'ctx_output3/relu' 8 256 6 12 (147456)
I0211 01:20:37.412467 20090 layer_factory.hpp:136] Creating layer 'ctx_output3_ctx_output3/relu_0_split' of type 'Split'
I0211 01:20:37.412472 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.412479 20090 net.cpp:184] Created Layer ctx_output3_ctx_output3/relu_0_split (54)
I0211 01:20:37.412514 20090 net.cpp:561] ctx_output3_ctx_output3/relu_0_split <- ctx_output3
I0211 01:20:37.412521 20090 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_0
I0211 01:20:37.412529 20090 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_1
I0211 01:20:37.412537 20090 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_2
I0211 01:20:37.412643 20090 net.cpp:245] Setting up ctx_output3_ctx_output3/relu_0_split
I0211 01:20:37.412654 20090 net.cpp:252] TRAIN Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 8 256 6 12 (147456)
I0211 01:20:37.412662 20090 net.cpp:252] TRAIN Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 8 256 6 12 (147456)
I0211 01:20:37.412667 20090 net.cpp:252] TRAIN Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 8 256 6 12 (147456)
I0211 01:20:37.412673 20090 layer_factory.hpp:136] Creating layer 'ctx_output4' of type 'Convolution'
I0211 01:20:37.412681 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.412700 20090 net.cpp:184] Created Layer ctx_output4 (55)
I0211 01:20:37.412709 20090 net.cpp:561] ctx_output4 <- pool7_pool7_0_split_1
I0211 01:20:37.412716 20090 net.cpp:530] ctx_output4 -> ctx_output4
I0211 01:20:37.417906 20090 net.cpp:245] Setting up ctx_output4
I0211 01:20:37.417924 20090 net.cpp:252] TRAIN Top shape for layer 55 'ctx_output4' 8 256 3 6 (36864)
I0211 01:20:37.417934 20090 layer_factory.hpp:136] Creating layer 'ctx_output4/relu' of type 'ReLU'
I0211 01:20:37.417940 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.417950 20090 net.cpp:184] Created Layer ctx_output4/relu (56)
I0211 01:20:37.417956 20090 net.cpp:561] ctx_output4/relu <- ctx_output4
I0211 01:20:37.417964 20090 net.cpp:513] ctx_output4/relu -> ctx_output4 (in-place)
I0211 01:20:37.417973 20090 net.cpp:245] Setting up ctx_output4/relu
I0211 01:20:37.417985 20090 net.cpp:252] TRAIN Top shape for layer 56 'ctx_output4/relu' 8 256 3 6 (36864)
I0211 01:20:37.417991 20090 layer_factory.hpp:136] Creating layer 'ctx_output4_ctx_output4/relu_0_split' of type 'Split'
I0211 01:20:37.417996 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.418011 20090 net.cpp:184] Created Layer ctx_output4_ctx_output4/relu_0_split (57)
I0211 01:20:37.418016 20090 net.cpp:561] ctx_output4_ctx_output4/relu_0_split <- ctx_output4
I0211 01:20:37.418027 20090 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_0
I0211 01:20:37.418036 20090 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_1
I0211 01:20:37.418043 20090 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_2
I0211 01:20:37.418146 20090 net.cpp:245] Setting up ctx_output4_ctx_output4/relu_0_split
I0211 01:20:37.418174 20090 net.cpp:252] TRAIN Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 8 256 3 6 (36864)
I0211 01:20:37.418181 20090 net.cpp:252] TRAIN Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 8 256 3 6 (36864)
I0211 01:20:37.418187 20090 net.cpp:252] TRAIN Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 8 256 3 6 (36864)
I0211 01:20:37.418193 20090 layer_factory.hpp:136] Creating layer 'ctx_output5' of type 'Convolution'
I0211 01:20:37.418200 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.418218 20090 net.cpp:184] Created Layer ctx_output5 (58)
I0211 01:20:37.418227 20090 net.cpp:561] ctx_output5 <- pool8_pool8_0_split_1
I0211 01:20:37.418234 20090 net.cpp:530] ctx_output5 -> ctx_output5
I0211 01:20:37.423405 20090 net.cpp:245] Setting up ctx_output5
I0211 01:20:37.423422 20090 net.cpp:252] TRAIN Top shape for layer 58 'ctx_output5' 8 256 2 3 (12288)
I0211 01:20:37.423432 20090 layer_factory.hpp:136] Creating layer 'ctx_output5/relu' of type 'ReLU'
I0211 01:20:37.423439 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.423447 20090 net.cpp:184] Created Layer ctx_output5/relu (59)
I0211 01:20:37.423455 20090 net.cpp:561] ctx_output5/relu <- ctx_output5
I0211 01:20:37.423461 20090 net.cpp:513] ctx_output5/relu -> ctx_output5 (in-place)
I0211 01:20:37.423471 20090 net.cpp:245] Setting up ctx_output5/relu
I0211 01:20:37.423485 20090 net.cpp:252] TRAIN Top shape for layer 59 'ctx_output5/relu' 8 256 2 3 (12288)
I0211 01:20:37.423491 20090 layer_factory.hpp:136] Creating layer 'ctx_output5_ctx_output5/relu_0_split' of type 'Split'
I0211 01:20:37.423496 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.423502 20090 net.cpp:184] Created Layer ctx_output5_ctx_output5/relu_0_split (60)
I0211 01:20:37.423516 20090 net.cpp:561] ctx_output5_ctx_output5/relu_0_split <- ctx_output5
I0211 01:20:37.423522 20090 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_0
I0211 01:20:37.423532 20090 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_1
I0211 01:20:37.423543 20090 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_2
I0211 01:20:37.423643 20090 net.cpp:245] Setting up ctx_output5_ctx_output5/relu_0_split
I0211 01:20:37.423653 20090 net.cpp:252] TRAIN Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 8 256 2 3 (12288)
I0211 01:20:37.423660 20090 net.cpp:252] TRAIN Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 8 256 2 3 (12288)
I0211 01:20:37.423666 20090 net.cpp:252] TRAIN Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 8 256 2 3 (12288)
I0211 01:20:37.423671 20090 layer_factory.hpp:136] Creating layer 'ctx_output6' of type 'Convolution'
I0211 01:20:37.423678 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.423694 20090 net.cpp:184] Created Layer ctx_output6 (61)
I0211 01:20:37.423702 20090 net.cpp:561] ctx_output6 <- pool9
I0211 01:20:37.423708 20090 net.cpp:530] ctx_output6 -> ctx_output6
I0211 01:20:37.428999 20090 net.cpp:245] Setting up ctx_output6
I0211 01:20:37.429028 20090 net.cpp:252] TRAIN Top shape for layer 61 'ctx_output6' 8 256 1 2 (4096)
I0211 01:20:37.429039 20090 layer_factory.hpp:136] Creating layer 'ctx_output6/relu' of type 'ReLU'
I0211 01:20:37.429047 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.429059 20090 net.cpp:184] Created Layer ctx_output6/relu (62)
I0211 01:20:37.429067 20090 net.cpp:561] ctx_output6/relu <- ctx_output6
I0211 01:20:37.429075 20090 net.cpp:513] ctx_output6/relu -> ctx_output6 (in-place)
I0211 01:20:37.429083 20090 net.cpp:245] Setting up ctx_output6/relu
I0211 01:20:37.429093 20090 net.cpp:252] TRAIN Top shape for layer 62 'ctx_output6/relu' 8 256 1 2 (4096)
I0211 01:20:37.429114 20090 layer_factory.hpp:136] Creating layer 'ctx_output6_ctx_output6/relu_0_split' of type 'Split'
I0211 01:20:37.429121 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.429132 20090 net.cpp:184] Created Layer ctx_output6_ctx_output6/relu_0_split (63)
I0211 01:20:37.429141 20090 net.cpp:561] ctx_output6_ctx_output6/relu_0_split <- ctx_output6
I0211 01:20:37.429147 20090 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_0
I0211 01:20:37.429155 20090 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_1
I0211 01:20:37.429163 20090 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_2
I0211 01:20:37.429265 20090 net.cpp:245] Setting up ctx_output6_ctx_output6/relu_0_split
I0211 01:20:37.429276 20090 net.cpp:252] TRAIN Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 8 256 1 2 (4096)
I0211 01:20:37.429285 20090 net.cpp:252] TRAIN Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 8 256 1 2 (4096)
I0211 01:20:37.429292 20090 net.cpp:252] TRAIN Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 8 256 1 2 (4096)
I0211 01:20:37.429298 20090 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc' of type 'Convolution'
I0211 01:20:37.429311 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.429332 20090 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc (64)
I0211 01:20:37.429340 20090 net.cpp:561] ctx_output1/relu_mbox_loc <- ctx_output1_ctx_output1/relu_0_split_0
I0211 01:20:37.429347 20090 net.cpp:530] ctx_output1/relu_mbox_loc -> ctx_output1/relu_mbox_loc
I0211 01:20:37.430012 20090 net.cpp:245] Setting up ctx_output1/relu_mbox_loc
I0211 01:20:37.430028 20090 net.cpp:252] TRAIN Top shape for layer 64 'ctx_output1/relu_mbox_loc' 8 16 46 90 (529920)
I0211 01:20:37.430038 20090 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_perm' of type 'Permute'
I0211 01:20:37.430045 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.430073 20090 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_perm (65)
I0211 01:20:37.430080 20090 net.cpp:561] ctx_output1/relu_mbox_loc_perm <- ctx_output1/relu_mbox_loc
I0211 01:20:37.430088 20090 net.cpp:530] ctx_output1/relu_mbox_loc_perm -> ctx_output1/relu_mbox_loc_perm
I0211 01:20:37.430284 20090 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_perm
I0211 01:20:37.430294 20090 net.cpp:252] TRAIN Top shape for layer 65 'ctx_output1/relu_mbox_loc_perm' 8 46 90 16 (529920)
I0211 01:20:37.430304 20090 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_flat' of type 'Flatten'
I0211 01:20:37.430308 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.430320 20090 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_flat (66)
I0211 01:20:37.430327 20090 net.cpp:561] ctx_output1/relu_mbox_loc_flat <- ctx_output1/relu_mbox_loc_perm
I0211 01:20:37.430335 20090 net.cpp:530] ctx_output1/relu_mbox_loc_flat -> ctx_output1/relu_mbox_loc_flat
I0211 01:20:37.430380 20090 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_flat
I0211 01:20:37.430390 20090 net.cpp:252] TRAIN Top shape for layer 66 'ctx_output1/relu_mbox_loc_flat' 8 66240 (529920)
I0211 01:20:37.430397 20090 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf' of type 'Convolution'
I0211 01:20:37.430403 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.430420 20090 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf (67)
I0211 01:20:37.430428 20090 net.cpp:561] ctx_output1/relu_mbox_conf <- ctx_output1_ctx_output1/relu_0_split_1
I0211 01:20:37.430434 20090 net.cpp:530] ctx_output1/relu_mbox_conf -> ctx_output1/relu_mbox_conf
I0211 01:20:37.431085 20090 net.cpp:245] Setting up ctx_output1/relu_mbox_conf
I0211 01:20:37.431111 20090 net.cpp:252] TRAIN Top shape for layer 67 'ctx_output1/relu_mbox_conf' 8 16 46 90 (529920)
I0211 01:20:37.431121 20090 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_perm' of type 'Permute'
I0211 01:20:37.431130 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.431143 20090 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_perm (68)
I0211 01:20:37.431151 20090 net.cpp:561] ctx_output1/relu_mbox_conf_perm <- ctx_output1/relu_mbox_conf
I0211 01:20:37.431159 20090 net.cpp:530] ctx_output1/relu_mbox_conf_perm -> ctx_output1/relu_mbox_conf_perm
I0211 01:20:37.431350 20090 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_perm
I0211 01:20:37.431362 20090 net.cpp:252] TRAIN Top shape for layer 68 'ctx_output1/relu_mbox_conf_perm' 8 46 90 16 (529920)
I0211 01:20:37.431368 20090 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_flat' of type 'Flatten'
I0211 01:20:37.431375 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.431383 20090 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_flat (69)
I0211 01:20:37.431388 20090 net.cpp:561] ctx_output1/relu_mbox_conf_flat <- ctx_output1/relu_mbox_conf_perm
I0211 01:20:37.431397 20090 net.cpp:530] ctx_output1/relu_mbox_conf_flat -> ctx_output1/relu_mbox_conf_flat
I0211 01:20:37.431438 20090 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_flat
I0211 01:20:37.431448 20090 net.cpp:252] TRAIN Top shape for layer 69 'ctx_output1/relu_mbox_conf_flat' 8 66240 (529920)
I0211 01:20:37.431454 20090 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_priorbox' of type 'PriorBox'
I0211 01:20:37.431459 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.431475 20090 net.cpp:184] Created Layer ctx_output1/relu_mbox_priorbox (70)
I0211 01:20:37.431483 20090 net.cpp:561] ctx_output1/relu_mbox_priorbox <- ctx_output1_ctx_output1/relu_0_split_2
I0211 01:20:37.431490 20090 net.cpp:561] ctx_output1/relu_mbox_priorbox <- data_data_0_split_1
I0211 01:20:37.431496 20090 net.cpp:530] ctx_output1/relu_mbox_priorbox -> ctx_output1/relu_mbox_priorbox
I0211 01:20:37.431545 20090 net.cpp:245] Setting up ctx_output1/relu_mbox_priorbox
I0211 01:20:37.431556 20090 net.cpp:252] TRAIN Top shape for layer 70 'ctx_output1/relu_mbox_priorbox' 1 2 66240 (132480)
I0211 01:20:37.431562 20090 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc' of type 'Convolution'
I0211 01:20:37.431568 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.431584 20090 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc (71)
I0211 01:20:37.431592 20090 net.cpp:561] ctx_output2/relu_mbox_loc <- ctx_output2_ctx_output2/relu_0_split_0
I0211 01:20:37.431599 20090 net.cpp:530] ctx_output2/relu_mbox_loc -> ctx_output2/relu_mbox_loc
I0211 01:20:37.432325 20090 net.cpp:245] Setting up ctx_output2/relu_mbox_loc
I0211 01:20:37.432341 20090 net.cpp:252] TRAIN Top shape for layer 71 'ctx_output2/relu_mbox_loc' 8 24 12 23 (52992)
I0211 01:20:37.432350 20090 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_perm' of type 'Permute'
I0211 01:20:37.432358 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.432370 20090 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_perm (72)
I0211 01:20:37.432379 20090 net.cpp:561] ctx_output2/relu_mbox_loc_perm <- ctx_output2/relu_mbox_loc
I0211 01:20:37.432384 20090 net.cpp:530] ctx_output2/relu_mbox_loc_perm -> ctx_output2/relu_mbox_loc_perm
I0211 01:20:37.432592 20090 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_perm
I0211 01:20:37.432605 20090 net.cpp:252] TRAIN Top shape for layer 72 'ctx_output2/relu_mbox_loc_perm' 8 12 23 24 (52992)
I0211 01:20:37.432610 20090 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_flat' of type 'Flatten'
I0211 01:20:37.432621 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.432639 20090 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_flat (73)
I0211 01:20:37.432646 20090 net.cpp:561] ctx_output2/relu_mbox_loc_flat <- ctx_output2/relu_mbox_loc_perm
I0211 01:20:37.432654 20090 net.cpp:530] ctx_output2/relu_mbox_loc_flat -> ctx_output2/relu_mbox_loc_flat
I0211 01:20:37.432698 20090 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_flat
I0211 01:20:37.432708 20090 net.cpp:252] TRAIN Top shape for layer 73 'ctx_output2/relu_mbox_loc_flat' 8 6624 (52992)
I0211 01:20:37.432713 20090 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf' of type 'Convolution'
I0211 01:20:37.432719 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.432734 20090 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf (74)
I0211 01:20:37.432742 20090 net.cpp:561] ctx_output2/relu_mbox_conf <- ctx_output2_ctx_output2/relu_0_split_1
I0211 01:20:37.432749 20090 net.cpp:530] ctx_output2/relu_mbox_conf -> ctx_output2/relu_mbox_conf
I0211 01:20:37.433465 20090 net.cpp:245] Setting up ctx_output2/relu_mbox_conf
I0211 01:20:37.433482 20090 net.cpp:252] TRAIN Top shape for layer 74 'ctx_output2/relu_mbox_conf' 8 24 12 23 (52992)
I0211 01:20:37.433492 20090 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_perm' of type 'Permute'
I0211 01:20:37.433499 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.433512 20090 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_perm (75)
I0211 01:20:37.433521 20090 net.cpp:561] ctx_output2/relu_mbox_conf_perm <- ctx_output2/relu_mbox_conf
I0211 01:20:37.433527 20090 net.cpp:530] ctx_output2/relu_mbox_conf_perm -> ctx_output2/relu_mbox_conf_perm
I0211 01:20:37.433722 20090 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_perm
I0211 01:20:37.433732 20090 net.cpp:252] TRAIN Top shape for layer 75 'ctx_output2/relu_mbox_conf_perm' 8 12 23 24 (52992)
I0211 01:20:37.433738 20090 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_flat' of type 'Flatten'
I0211 01:20:37.433743 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.433751 20090 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_flat (76)
I0211 01:20:37.433759 20090 net.cpp:561] ctx_output2/relu_mbox_conf_flat <- ctx_output2/relu_mbox_conf_perm
I0211 01:20:37.433766 20090 net.cpp:530] ctx_output2/relu_mbox_conf_flat -> ctx_output2/relu_mbox_conf_flat
I0211 01:20:37.433805 20090 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_flat
I0211 01:20:37.433815 20090 net.cpp:252] TRAIN Top shape for layer 76 'ctx_output2/relu_mbox_conf_flat' 8 6624 (52992)
I0211 01:20:37.433821 20090 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_priorbox' of type 'PriorBox'
I0211 01:20:37.433827 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.433835 20090 net.cpp:184] Created Layer ctx_output2/relu_mbox_priorbox (77)
I0211 01:20:37.433843 20090 net.cpp:561] ctx_output2/relu_mbox_priorbox <- ctx_output2_ctx_output2/relu_0_split_2
I0211 01:20:37.433851 20090 net.cpp:561] ctx_output2/relu_mbox_priorbox <- data_data_0_split_2
I0211 01:20:37.433856 20090 net.cpp:530] ctx_output2/relu_mbox_priorbox -> ctx_output2/relu_mbox_priorbox
I0211 01:20:37.433900 20090 net.cpp:245] Setting up ctx_output2/relu_mbox_priorbox
I0211 01:20:37.433910 20090 net.cpp:252] TRAIN Top shape for layer 77 'ctx_output2/relu_mbox_priorbox' 1 2 6624 (13248)
I0211 01:20:37.433917 20090 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc' of type 'Convolution'
I0211 01:20:37.433923 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.433940 20090 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc (78)
I0211 01:20:37.433948 20090 net.cpp:561] ctx_output3/relu_mbox_loc <- ctx_output3_ctx_output3/relu_0_split_0
I0211 01:20:37.433955 20090 net.cpp:530] ctx_output3/relu_mbox_loc -> ctx_output3/relu_mbox_loc
I0211 01:20:37.434692 20090 net.cpp:245] Setting up ctx_output3/relu_mbox_loc
I0211 01:20:37.434710 20090 net.cpp:252] TRAIN Top shape for layer 78 'ctx_output3/relu_mbox_loc' 8 24 6 12 (13824)
I0211 01:20:37.434726 20090 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_perm' of type 'Permute'
I0211 01:20:37.434738 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.434751 20090 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_perm (79)
I0211 01:20:37.434759 20090 net.cpp:561] ctx_output3/relu_mbox_loc_perm <- ctx_output3/relu_mbox_loc
I0211 01:20:37.434767 20090 net.cpp:530] ctx_output3/relu_mbox_loc_perm -> ctx_output3/relu_mbox_loc_perm
I0211 01:20:37.434960 20090 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_perm
I0211 01:20:37.434972 20090 net.cpp:252] TRAIN Top shape for layer 79 'ctx_output3/relu_mbox_loc_perm' 8 6 12 24 (13824)
I0211 01:20:37.434978 20090 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_flat' of type 'Flatten'
I0211 01:20:37.434983 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.434991 20090 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_flat (80)
I0211 01:20:37.434998 20090 net.cpp:561] ctx_output3/relu_mbox_loc_flat <- ctx_output3/relu_mbox_loc_perm
I0211 01:20:37.435005 20090 net.cpp:530] ctx_output3/relu_mbox_loc_flat -> ctx_output3/relu_mbox_loc_flat
I0211 01:20:37.435046 20090 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_flat
I0211 01:20:37.435056 20090 net.cpp:252] TRAIN Top shape for layer 80 'ctx_output3/relu_mbox_loc_flat' 8 1728 (13824)
I0211 01:20:37.435062 20090 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf' of type 'Convolution'
I0211 01:20:37.435067 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.435086 20090 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf (81)
I0211 01:20:37.435094 20090 net.cpp:561] ctx_output3/relu_mbox_conf <- ctx_output3_ctx_output3/relu_0_split_1
I0211 01:20:37.435101 20090 net.cpp:530] ctx_output3/relu_mbox_conf -> ctx_output3/relu_mbox_conf
I0211 01:20:37.435822 20090 net.cpp:245] Setting up ctx_output3/relu_mbox_conf
I0211 01:20:37.435838 20090 net.cpp:252] TRAIN Top shape for layer 81 'ctx_output3/relu_mbox_conf' 8 24 6 12 (13824)
I0211 01:20:37.435848 20090 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_perm' of type 'Permute'
I0211 01:20:37.435858 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.435868 20090 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_perm (82)
I0211 01:20:37.435878 20090 net.cpp:561] ctx_output3/relu_mbox_conf_perm <- ctx_output3/relu_mbox_conf
I0211 01:20:37.435884 20090 net.cpp:530] ctx_output3/relu_mbox_conf_perm -> ctx_output3/relu_mbox_conf_perm
I0211 01:20:37.436072 20090 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_perm
I0211 01:20:37.436082 20090 net.cpp:252] TRAIN Top shape for layer 82 'ctx_output3/relu_mbox_conf_perm' 8 6 12 24 (13824)
I0211 01:20:37.436089 20090 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_flat' of type 'Flatten'
I0211 01:20:37.436094 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.436101 20090 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_flat (83)
I0211 01:20:37.436110 20090 net.cpp:561] ctx_output3/relu_mbox_conf_flat <- ctx_output3/relu_mbox_conf_perm
I0211 01:20:37.436116 20090 net.cpp:530] ctx_output3/relu_mbox_conf_flat -> ctx_output3/relu_mbox_conf_flat
I0211 01:20:37.436157 20090 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_flat
I0211 01:20:37.436167 20090 net.cpp:252] TRAIN Top shape for layer 83 'ctx_output3/relu_mbox_conf_flat' 8 1728 (13824)
I0211 01:20:37.436173 20090 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_priorbox' of type 'PriorBox'
I0211 01:20:37.436179 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.436202 20090 net.cpp:184] Created Layer ctx_output3/relu_mbox_priorbox (84)
I0211 01:20:37.436209 20090 net.cpp:561] ctx_output3/relu_mbox_priorbox <- ctx_output3_ctx_output3/relu_0_split_2
I0211 01:20:37.436215 20090 net.cpp:561] ctx_output3/relu_mbox_priorbox <- data_data_0_split_3
I0211 01:20:37.436228 20090 net.cpp:530] ctx_output3/relu_mbox_priorbox -> ctx_output3/relu_mbox_priorbox
I0211 01:20:37.436272 20090 net.cpp:245] Setting up ctx_output3/relu_mbox_priorbox
I0211 01:20:37.436283 20090 net.cpp:252] TRAIN Top shape for layer 84 'ctx_output3/relu_mbox_priorbox' 1 2 1728 (3456)
I0211 01:20:37.436290 20090 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc' of type 'Convolution'
I0211 01:20:37.436296 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.436313 20090 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc (85)
I0211 01:20:37.436322 20090 net.cpp:561] ctx_output4/relu_mbox_loc <- ctx_output4_ctx_output4/relu_0_split_0
I0211 01:20:37.436329 20090 net.cpp:530] ctx_output4/relu_mbox_loc -> ctx_output4/relu_mbox_loc
I0211 01:20:37.437067 20090 net.cpp:245] Setting up ctx_output4/relu_mbox_loc
I0211 01:20:37.437084 20090 net.cpp:252] TRAIN Top shape for layer 85 'ctx_output4/relu_mbox_loc' 8 24 3 6 (3456)
I0211 01:20:37.437094 20090 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_perm' of type 'Permute'
I0211 01:20:37.437100 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.437114 20090 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_perm (86)
I0211 01:20:37.437122 20090 net.cpp:561] ctx_output4/relu_mbox_loc_perm <- ctx_output4/relu_mbox_loc
I0211 01:20:37.437129 20090 net.cpp:530] ctx_output4/relu_mbox_loc_perm -> ctx_output4/relu_mbox_loc_perm
I0211 01:20:37.437325 20090 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_perm
I0211 01:20:37.437336 20090 net.cpp:252] TRAIN Top shape for layer 86 'ctx_output4/relu_mbox_loc_perm' 8 3 6 24 (3456)
I0211 01:20:37.437342 20090 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_flat' of type 'Flatten'
I0211 01:20:37.437348 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.437357 20090 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_flat (87)
I0211 01:20:37.437364 20090 net.cpp:561] ctx_output4/relu_mbox_loc_flat <- ctx_output4/relu_mbox_loc_perm
I0211 01:20:37.437371 20090 net.cpp:530] ctx_output4/relu_mbox_loc_flat -> ctx_output4/relu_mbox_loc_flat
I0211 01:20:37.437412 20090 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_flat
I0211 01:20:37.437422 20090 net.cpp:252] TRAIN Top shape for layer 87 'ctx_output4/relu_mbox_loc_flat' 8 432 (3456)
I0211 01:20:37.437428 20090 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf' of type 'Convolution'
I0211 01:20:37.437435 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.437450 20090 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf (88)
I0211 01:20:37.437458 20090 net.cpp:561] ctx_output4/relu_mbox_conf <- ctx_output4_ctx_output4/relu_0_split_1
I0211 01:20:37.437465 20090 net.cpp:530] ctx_output4/relu_mbox_conf -> ctx_output4/relu_mbox_conf
I0211 01:20:37.438192 20090 net.cpp:245] Setting up ctx_output4/relu_mbox_conf
I0211 01:20:37.438208 20090 net.cpp:252] TRAIN Top shape for layer 88 'ctx_output4/relu_mbox_conf' 8 24 3 6 (3456)
I0211 01:20:37.438220 20090 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_perm' of type 'Permute'
I0211 01:20:37.438227 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.438238 20090 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_perm (89)
I0211 01:20:37.438247 20090 net.cpp:561] ctx_output4/relu_mbox_conf_perm <- ctx_output4/relu_mbox_conf
I0211 01:20:37.438256 20090 net.cpp:530] ctx_output4/relu_mbox_conf_perm -> ctx_output4/relu_mbox_conf_perm
I0211 01:20:37.438463 20090 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_perm
I0211 01:20:37.438475 20090 net.cpp:252] TRAIN Top shape for layer 89 'ctx_output4/relu_mbox_conf_perm' 8 3 6 24 (3456)
I0211 01:20:37.438482 20090 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_flat' of type 'Flatten'
I0211 01:20:37.438488 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.438496 20090 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_flat (90)
I0211 01:20:37.438504 20090 net.cpp:561] ctx_output4/relu_mbox_conf_flat <- ctx_output4/relu_mbox_conf_perm
I0211 01:20:37.438510 20090 net.cpp:530] ctx_output4/relu_mbox_conf_flat -> ctx_output4/relu_mbox_conf_flat
I0211 01:20:37.438554 20090 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_flat
I0211 01:20:37.438563 20090 net.cpp:252] TRAIN Top shape for layer 90 'ctx_output4/relu_mbox_conf_flat' 8 432 (3456)
I0211 01:20:37.438570 20090 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_priorbox' of type 'PriorBox'
I0211 01:20:37.438576 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.438585 20090 net.cpp:184] Created Layer ctx_output4/relu_mbox_priorbox (91)
I0211 01:20:37.438591 20090 net.cpp:561] ctx_output4/relu_mbox_priorbox <- ctx_output4_ctx_output4/relu_0_split_2
I0211 01:20:37.438598 20090 net.cpp:561] ctx_output4/relu_mbox_priorbox <- data_data_0_split_4
I0211 01:20:37.438606 20090 net.cpp:530] ctx_output4/relu_mbox_priorbox -> ctx_output4/relu_mbox_priorbox
I0211 01:20:37.438652 20090 net.cpp:245] Setting up ctx_output4/relu_mbox_priorbox
I0211 01:20:37.438663 20090 net.cpp:252] TRAIN Top shape for layer 91 'ctx_output4/relu_mbox_priorbox' 1 2 432 (864)
I0211 01:20:37.438669 20090 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc' of type 'Convolution'
I0211 01:20:37.438675 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.438694 20090 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc (92)
I0211 01:20:37.438702 20090 net.cpp:561] ctx_output5/relu_mbox_loc <- ctx_output5_ctx_output5/relu_0_split_0
I0211 01:20:37.438709 20090 net.cpp:530] ctx_output5/relu_mbox_loc -> ctx_output5/relu_mbox_loc
I0211 01:20:37.439389 20090 net.cpp:245] Setting up ctx_output5/relu_mbox_loc
I0211 01:20:37.439407 20090 net.cpp:252] TRAIN Top shape for layer 92 'ctx_output5/relu_mbox_loc' 8 16 2 3 (768)
I0211 01:20:37.439417 20090 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_perm' of type 'Permute'
I0211 01:20:37.439424 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.439435 20090 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_perm (93)
I0211 01:20:37.439445 20090 net.cpp:561] ctx_output5/relu_mbox_loc_perm <- ctx_output5/relu_mbox_loc
I0211 01:20:37.439451 20090 net.cpp:530] ctx_output5/relu_mbox_loc_perm -> ctx_output5/relu_mbox_loc_perm
I0211 01:20:37.439642 20090 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_perm
I0211 01:20:37.439653 20090 net.cpp:252] TRAIN Top shape for layer 93 'ctx_output5/relu_mbox_loc_perm' 8 2 3 16 (768)
I0211 01:20:37.439661 20090 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_flat' of type 'Flatten'
I0211 01:20:37.439666 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.439676 20090 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_flat (94)
I0211 01:20:37.439683 20090 net.cpp:561] ctx_output5/relu_mbox_loc_flat <- ctx_output5/relu_mbox_loc_perm
I0211 01:20:37.439689 20090 net.cpp:530] ctx_output5/relu_mbox_loc_flat -> ctx_output5/relu_mbox_loc_flat
I0211 01:20:37.439733 20090 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_flat
I0211 01:20:37.439743 20090 net.cpp:252] TRAIN Top shape for layer 94 'ctx_output5/relu_mbox_loc_flat' 8 96 (768)
I0211 01:20:37.439749 20090 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf' of type 'Convolution'
I0211 01:20:37.439764 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.439780 20090 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf (95)
I0211 01:20:37.439788 20090 net.cpp:561] ctx_output5/relu_mbox_conf <- ctx_output5_ctx_output5/relu_0_split_1
I0211 01:20:37.439795 20090 net.cpp:530] ctx_output5/relu_mbox_conf -> ctx_output5/relu_mbox_conf
I0211 01:20:37.440459 20090 net.cpp:245] Setting up ctx_output5/relu_mbox_conf
I0211 01:20:37.440474 20090 net.cpp:252] TRAIN Top shape for layer 95 'ctx_output5/relu_mbox_conf' 8 16 2 3 (768)
I0211 01:20:37.440485 20090 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_perm' of type 'Permute'
I0211 01:20:37.440512 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.440526 20090 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_perm (96)
I0211 01:20:37.440534 20090 net.cpp:561] ctx_output5/relu_mbox_conf_perm <- ctx_output5/relu_mbox_conf
I0211 01:20:37.440541 20090 net.cpp:530] ctx_output5/relu_mbox_conf_perm -> ctx_output5/relu_mbox_conf_perm
I0211 01:20:37.440742 20090 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_perm
I0211 01:20:37.440752 20090 net.cpp:252] TRAIN Top shape for layer 96 'ctx_output5/relu_mbox_conf_perm' 8 2 3 16 (768)
I0211 01:20:37.440759 20090 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_flat' of type 'Flatten'
I0211 01:20:37.440764 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.440778 20090 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_flat (97)
I0211 01:20:37.440785 20090 net.cpp:561] ctx_output5/relu_mbox_conf_flat <- ctx_output5/relu_mbox_conf_perm
I0211 01:20:37.440794 20090 net.cpp:530] ctx_output5/relu_mbox_conf_flat -> ctx_output5/relu_mbox_conf_flat
I0211 01:20:37.440838 20090 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_flat
I0211 01:20:37.440847 20090 net.cpp:252] TRAIN Top shape for layer 97 'ctx_output5/relu_mbox_conf_flat' 8 96 (768)
I0211 01:20:37.440855 20090 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_priorbox' of type 'PriorBox'
I0211 01:20:37.440862 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.440871 20090 net.cpp:184] Created Layer ctx_output5/relu_mbox_priorbox (98)
I0211 01:20:37.440879 20090 net.cpp:561] ctx_output5/relu_mbox_priorbox <- ctx_output5_ctx_output5/relu_0_split_2
I0211 01:20:37.440886 20090 net.cpp:561] ctx_output5/relu_mbox_priorbox <- data_data_0_split_5
I0211 01:20:37.440894 20090 net.cpp:530] ctx_output5/relu_mbox_priorbox -> ctx_output5/relu_mbox_priorbox
I0211 01:20:37.440940 20090 net.cpp:245] Setting up ctx_output5/relu_mbox_priorbox
I0211 01:20:37.440951 20090 net.cpp:252] TRAIN Top shape for layer 98 'ctx_output5/relu_mbox_priorbox' 1 2 96 (192)
I0211 01:20:37.440958 20090 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc' of type 'Convolution'
I0211 01:20:37.440966 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.440984 20090 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc (99)
I0211 01:20:37.440992 20090 net.cpp:561] ctx_output6/relu_mbox_loc <- ctx_output6_ctx_output6/relu_0_split_0
I0211 01:20:37.440999 20090 net.cpp:530] ctx_output6/relu_mbox_loc -> ctx_output6/relu_mbox_loc
I0211 01:20:37.441665 20090 net.cpp:245] Setting up ctx_output6/relu_mbox_loc
I0211 01:20:37.441682 20090 net.cpp:252] TRAIN Top shape for layer 99 'ctx_output6/relu_mbox_loc' 8 16 1 2 (256)
I0211 01:20:37.441694 20090 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_perm' of type 'Permute'
I0211 01:20:37.441700 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.441712 20090 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_perm (100)
I0211 01:20:37.441720 20090 net.cpp:561] ctx_output6/relu_mbox_loc_perm <- ctx_output6/relu_mbox_loc
I0211 01:20:37.441741 20090 net.cpp:530] ctx_output6/relu_mbox_loc_perm -> ctx_output6/relu_mbox_loc_perm
I0211 01:20:37.441937 20090 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_perm
I0211 01:20:37.441949 20090 net.cpp:252] TRAIN Top shape for layer 100 'ctx_output6/relu_mbox_loc_perm' 8 1 2 16 (256)
I0211 01:20:37.441957 20090 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_flat' of type 'Flatten'
I0211 01:20:37.441964 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.441973 20090 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_flat (101)
I0211 01:20:37.441982 20090 net.cpp:561] ctx_output6/relu_mbox_loc_flat <- ctx_output6/relu_mbox_loc_perm
I0211 01:20:37.441987 20090 net.cpp:530] ctx_output6/relu_mbox_loc_flat -> ctx_output6/relu_mbox_loc_flat
I0211 01:20:37.442059 20090 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_flat
I0211 01:20:37.442071 20090 net.cpp:252] TRAIN Top shape for layer 101 'ctx_output6/relu_mbox_loc_flat' 8 32 (256)
I0211 01:20:37.442080 20090 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf' of type 'Convolution'
I0211 01:20:37.442087 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.442108 20090 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf (102)
I0211 01:20:37.442118 20090 net.cpp:561] ctx_output6/relu_mbox_conf <- ctx_output6_ctx_output6/relu_0_split_1
I0211 01:20:37.442126 20090 net.cpp:530] ctx_output6/relu_mbox_conf -> ctx_output6/relu_mbox_conf
I0211 01:20:37.442788 20090 net.cpp:245] Setting up ctx_output6/relu_mbox_conf
I0211 01:20:37.442806 20090 net.cpp:252] TRAIN Top shape for layer 102 'ctx_output6/relu_mbox_conf' 8 16 1 2 (256)
I0211 01:20:37.442816 20090 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_perm' of type 'Permute'
I0211 01:20:37.442823 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.442834 20090 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_perm (103)
I0211 01:20:37.442842 20090 net.cpp:561] ctx_output6/relu_mbox_conf_perm <- ctx_output6/relu_mbox_conf
I0211 01:20:37.442849 20090 net.cpp:530] ctx_output6/relu_mbox_conf_perm -> ctx_output6/relu_mbox_conf_perm
I0211 01:20:37.443048 20090 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_perm
I0211 01:20:37.443058 20090 net.cpp:252] TRAIN Top shape for layer 103 'ctx_output6/relu_mbox_conf_perm' 8 1 2 16 (256)
I0211 01:20:37.443065 20090 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_flat' of type 'Flatten'
I0211 01:20:37.443073 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.443083 20090 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_flat (104)
I0211 01:20:37.443089 20090 net.cpp:561] ctx_output6/relu_mbox_conf_flat <- ctx_output6/relu_mbox_conf_perm
I0211 01:20:37.443096 20090 net.cpp:530] ctx_output6/relu_mbox_conf_flat -> ctx_output6/relu_mbox_conf_flat
I0211 01:20:37.443140 20090 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_flat
I0211 01:20:37.443150 20090 net.cpp:252] TRAIN Top shape for layer 104 'ctx_output6/relu_mbox_conf_flat' 8 32 (256)
I0211 01:20:37.443157 20090 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_priorbox' of type 'PriorBox'
I0211 01:20:37.443164 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.443173 20090 net.cpp:184] Created Layer ctx_output6/relu_mbox_priorbox (105)
I0211 01:20:37.443181 20090 net.cpp:561] ctx_output6/relu_mbox_priorbox <- ctx_output6_ctx_output6/relu_0_split_2
I0211 01:20:37.443189 20090 net.cpp:561] ctx_output6/relu_mbox_priorbox <- data_data_0_split_6
I0211 01:20:37.443198 20090 net.cpp:530] ctx_output6/relu_mbox_priorbox -> ctx_output6/relu_mbox_priorbox
I0211 01:20:37.443243 20090 net.cpp:245] Setting up ctx_output6/relu_mbox_priorbox
I0211 01:20:37.443254 20090 net.cpp:252] TRAIN Top shape for layer 105 'ctx_output6/relu_mbox_priorbox' 1 2 32 (64)
I0211 01:20:37.443271 20090 layer_factory.hpp:136] Creating layer 'mbox_loc' of type 'Concat'
I0211 01:20:37.443277 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.443289 20090 net.cpp:184] Created Layer mbox_loc (106)
I0211 01:20:37.443297 20090 net.cpp:561] mbox_loc <- ctx_output1/relu_mbox_loc_flat
I0211 01:20:37.443305 20090 net.cpp:561] mbox_loc <- ctx_output2/relu_mbox_loc_flat
I0211 01:20:37.443313 20090 net.cpp:561] mbox_loc <- ctx_output3/relu_mbox_loc_flat
I0211 01:20:37.443320 20090 net.cpp:561] mbox_loc <- ctx_output4/relu_mbox_loc_flat
I0211 01:20:37.443327 20090 net.cpp:561] mbox_loc <- ctx_output5/relu_mbox_loc_flat
I0211 01:20:37.443333 20090 net.cpp:561] mbox_loc <- ctx_output6/relu_mbox_loc_flat
I0211 01:20:37.443341 20090 net.cpp:530] mbox_loc -> mbox_loc
I0211 01:20:37.443392 20090 net.cpp:245] Setting up mbox_loc
I0211 01:20:37.443403 20090 net.cpp:252] TRAIN Top shape for layer 106 'mbox_loc' 8 75152 (601216)
I0211 01:20:37.443411 20090 layer_factory.hpp:136] Creating layer 'mbox_conf' of type 'Concat'
I0211 01:20:37.443418 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.443426 20090 net.cpp:184] Created Layer mbox_conf (107)
I0211 01:20:37.443434 20090 net.cpp:561] mbox_conf <- ctx_output1/relu_mbox_conf_flat
I0211 01:20:37.443440 20090 net.cpp:561] mbox_conf <- ctx_output2/relu_mbox_conf_flat
I0211 01:20:37.443449 20090 net.cpp:561] mbox_conf <- ctx_output3/relu_mbox_conf_flat
I0211 01:20:37.443456 20090 net.cpp:561] mbox_conf <- ctx_output4/relu_mbox_conf_flat
I0211 01:20:37.443464 20090 net.cpp:561] mbox_conf <- ctx_output5/relu_mbox_conf_flat
I0211 01:20:37.443471 20090 net.cpp:561] mbox_conf <- ctx_output6/relu_mbox_conf_flat
I0211 01:20:37.443478 20090 net.cpp:530] mbox_conf -> mbox_conf
I0211 01:20:37.443523 20090 net.cpp:245] Setting up mbox_conf
I0211 01:20:37.443533 20090 net.cpp:252] TRAIN Top shape for layer 107 'mbox_conf' 8 75152 (601216)
I0211 01:20:37.443542 20090 layer_factory.hpp:136] Creating layer 'mbox_priorbox' of type 'Concat'
I0211 01:20:37.443548 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.443555 20090 net.cpp:184] Created Layer mbox_priorbox (108)
I0211 01:20:37.443562 20090 net.cpp:561] mbox_priorbox <- ctx_output1/relu_mbox_priorbox
I0211 01:20:37.443568 20090 net.cpp:561] mbox_priorbox <- ctx_output2/relu_mbox_priorbox
I0211 01:20:37.443576 20090 net.cpp:561] mbox_priorbox <- ctx_output3/relu_mbox_priorbox
I0211 01:20:37.443583 20090 net.cpp:561] mbox_priorbox <- ctx_output4/relu_mbox_priorbox
I0211 01:20:37.443589 20090 net.cpp:561] mbox_priorbox <- ctx_output5/relu_mbox_priorbox
I0211 01:20:37.443596 20090 net.cpp:561] mbox_priorbox <- ctx_output6/relu_mbox_priorbox
I0211 01:20:37.443603 20090 net.cpp:530] mbox_priorbox -> mbox_priorbox
I0211 01:20:37.443645 20090 net.cpp:245] Setting up mbox_priorbox
I0211 01:20:37.443655 20090 net.cpp:252] TRAIN Top shape for layer 108 'mbox_priorbox' 1 2 75152 (150304)
I0211 01:20:37.443661 20090 layer_factory.hpp:136] Creating layer 'mbox_loss' of type 'MultiBoxLoss'
I0211 01:20:37.443668 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.443691 20090 net.cpp:184] Created Layer mbox_loss (109)
I0211 01:20:37.443699 20090 net.cpp:561] mbox_loss <- mbox_loc
I0211 01:20:37.443706 20090 net.cpp:561] mbox_loss <- mbox_conf
I0211 01:20:37.443712 20090 net.cpp:561] mbox_loss <- mbox_priorbox
I0211 01:20:37.443719 20090 net.cpp:561] mbox_loss <- label
I0211 01:20:37.443727 20090 net.cpp:530] mbox_loss -> mbox_loss
I0211 01:20:37.443856 20090 layer_factory.hpp:136] Creating layer 'mbox_loss_smooth_L1_loc' of type 'SmoothL1Loss'
I0211 01:20:37.443866 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.444088 20090 layer_factory.hpp:136] Creating layer 'mbox_loss_softmax_conf' of type 'SoftmaxWithLoss'
I0211 01:20:37.444102 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.444394 20090 net.cpp:245] Setting up mbox_loss
I0211 01:20:37.444411 20090 net.cpp:252] TRAIN Top shape for layer 109 'mbox_loss' (1)
I0211 01:20:37.444419 20090 net.cpp:256]     with loss weight 1
I0211 01:20:37.444438 20090 net.cpp:323] mbox_loss needs backward computation.
I0211 01:20:37.444447 20090 net.cpp:325] mbox_priorbox does not need backward computation.
I0211 01:20:37.444455 20090 net.cpp:323] mbox_conf needs backward computation.
I0211 01:20:37.444463 20090 net.cpp:323] mbox_loc needs backward computation.
I0211 01:20:37.444473 20090 net.cpp:325] ctx_output6/relu_mbox_priorbox does not need backward computation.
I0211 01:20:37.444479 20090 net.cpp:323] ctx_output6/relu_mbox_conf_flat needs backward computation.
I0211 01:20:37.444504 20090 net.cpp:323] ctx_output6/relu_mbox_conf_perm needs backward computation.
I0211 01:20:37.444510 20090 net.cpp:323] ctx_output6/relu_mbox_conf needs backward computation.
I0211 01:20:37.444515 20090 net.cpp:323] ctx_output6/relu_mbox_loc_flat needs backward computation.
I0211 01:20:37.444520 20090 net.cpp:323] ctx_output6/relu_mbox_loc_perm needs backward computation.
I0211 01:20:37.444527 20090 net.cpp:323] ctx_output6/relu_mbox_loc needs backward computation.
I0211 01:20:37.444533 20090 net.cpp:325] ctx_output5/relu_mbox_priorbox does not need backward computation.
I0211 01:20:37.444541 20090 net.cpp:323] ctx_output5/relu_mbox_conf_flat needs backward computation.
I0211 01:20:37.444546 20090 net.cpp:323] ctx_output5/relu_mbox_conf_perm needs backward computation.
I0211 01:20:37.444553 20090 net.cpp:323] ctx_output5/relu_mbox_conf needs backward computation.
I0211 01:20:37.444558 20090 net.cpp:323] ctx_output5/relu_mbox_loc_flat needs backward computation.
I0211 01:20:37.444566 20090 net.cpp:323] ctx_output5/relu_mbox_loc_perm needs backward computation.
I0211 01:20:37.444571 20090 net.cpp:323] ctx_output5/relu_mbox_loc needs backward computation.
I0211 01:20:37.444578 20090 net.cpp:325] ctx_output4/relu_mbox_priorbox does not need backward computation.
I0211 01:20:37.444584 20090 net.cpp:323] ctx_output4/relu_mbox_conf_flat needs backward computation.
I0211 01:20:37.444591 20090 net.cpp:323] ctx_output4/relu_mbox_conf_perm needs backward computation.
I0211 01:20:37.444597 20090 net.cpp:323] ctx_output4/relu_mbox_conf needs backward computation.
I0211 01:20:37.444603 20090 net.cpp:323] ctx_output4/relu_mbox_loc_flat needs backward computation.
I0211 01:20:37.444608 20090 net.cpp:323] ctx_output4/relu_mbox_loc_perm needs backward computation.
I0211 01:20:37.444615 20090 net.cpp:323] ctx_output4/relu_mbox_loc needs backward computation.
I0211 01:20:37.444622 20090 net.cpp:325] ctx_output3/relu_mbox_priorbox does not need backward computation.
I0211 01:20:37.444630 20090 net.cpp:323] ctx_output3/relu_mbox_conf_flat needs backward computation.
I0211 01:20:37.444638 20090 net.cpp:323] ctx_output3/relu_mbox_conf_perm needs backward computation.
I0211 01:20:37.444643 20090 net.cpp:323] ctx_output3/relu_mbox_conf needs backward computation.
I0211 01:20:37.444649 20090 net.cpp:323] ctx_output3/relu_mbox_loc_flat needs backward computation.
I0211 01:20:37.444654 20090 net.cpp:323] ctx_output3/relu_mbox_loc_perm needs backward computation.
I0211 01:20:37.444661 20090 net.cpp:323] ctx_output3/relu_mbox_loc needs backward computation.
I0211 01:20:37.444666 20090 net.cpp:325] ctx_output2/relu_mbox_priorbox does not need backward computation.
I0211 01:20:37.444674 20090 net.cpp:323] ctx_output2/relu_mbox_conf_flat needs backward computation.
I0211 01:20:37.444679 20090 net.cpp:323] ctx_output2/relu_mbox_conf_perm needs backward computation.
I0211 01:20:37.444686 20090 net.cpp:323] ctx_output2/relu_mbox_conf needs backward computation.
I0211 01:20:37.444691 20090 net.cpp:323] ctx_output2/relu_mbox_loc_flat needs backward computation.
I0211 01:20:37.444696 20090 net.cpp:323] ctx_output2/relu_mbox_loc_perm needs backward computation.
I0211 01:20:37.444701 20090 net.cpp:323] ctx_output2/relu_mbox_loc needs backward computation.
I0211 01:20:37.444717 20090 net.cpp:325] ctx_output1/relu_mbox_priorbox does not need backward computation.
I0211 01:20:37.444725 20090 net.cpp:323] ctx_output1/relu_mbox_conf_flat needs backward computation.
I0211 01:20:37.444731 20090 net.cpp:323] ctx_output1/relu_mbox_conf_perm needs backward computation.
I0211 01:20:37.444736 20090 net.cpp:323] ctx_output1/relu_mbox_conf needs backward computation.
I0211 01:20:37.444743 20090 net.cpp:323] ctx_output1/relu_mbox_loc_flat needs backward computation.
I0211 01:20:37.444748 20090 net.cpp:323] ctx_output1/relu_mbox_loc_perm needs backward computation.
I0211 01:20:37.444756 20090 net.cpp:323] ctx_output1/relu_mbox_loc needs backward computation.
I0211 01:20:37.444761 20090 net.cpp:323] ctx_output6_ctx_output6/relu_0_split needs backward computation.
I0211 01:20:37.444768 20090 net.cpp:323] ctx_output6/relu needs backward computation.
I0211 01:20:37.444773 20090 net.cpp:323] ctx_output6 needs backward computation.
I0211 01:20:37.444780 20090 net.cpp:323] ctx_output5_ctx_output5/relu_0_split needs backward computation.
I0211 01:20:37.444787 20090 net.cpp:323] ctx_output5/relu needs backward computation.
I0211 01:20:37.444792 20090 net.cpp:323] ctx_output5 needs backward computation.
I0211 01:20:37.444798 20090 net.cpp:323] ctx_output4_ctx_output4/relu_0_split needs backward computation.
I0211 01:20:37.444805 20090 net.cpp:323] ctx_output4/relu needs backward computation.
I0211 01:20:37.444810 20090 net.cpp:323] ctx_output4 needs backward computation.
I0211 01:20:37.444818 20090 net.cpp:323] ctx_output3_ctx_output3/relu_0_split needs backward computation.
I0211 01:20:37.444823 20090 net.cpp:323] ctx_output3/relu needs backward computation.
I0211 01:20:37.444830 20090 net.cpp:323] ctx_output3 needs backward computation.
I0211 01:20:37.444835 20090 net.cpp:323] ctx_output2_ctx_output2/relu_0_split needs backward computation.
I0211 01:20:37.444841 20090 net.cpp:323] ctx_output2/relu needs backward computation.
I0211 01:20:37.444849 20090 net.cpp:323] ctx_output2 needs backward computation.
I0211 01:20:37.444854 20090 net.cpp:323] ctx_output1_ctx_output1/relu_0_split needs backward computation.
I0211 01:20:37.444860 20090 net.cpp:323] ctx_output1/relu needs backward computation.
I0211 01:20:37.444865 20090 net.cpp:323] ctx_output1 needs backward computation.
I0211 01:20:37.444872 20090 net.cpp:323] pool9 needs backward computation.
I0211 01:20:37.444878 20090 net.cpp:323] pool8_pool8_0_split needs backward computation.
I0211 01:20:37.444885 20090 net.cpp:323] pool8 needs backward computation.
I0211 01:20:37.444890 20090 net.cpp:323] pool7_pool7_0_split needs backward computation.
I0211 01:20:37.444898 20090 net.cpp:323] pool7 needs backward computation.
I0211 01:20:37.444903 20090 net.cpp:323] pool6_pool6_0_split needs backward computation.
I0211 01:20:37.444911 20090 net.cpp:323] pool6 needs backward computation.
I0211 01:20:37.444916 20090 net.cpp:323] res5a_branch2b_res5a_branch2b/relu_0_split needs backward computation.
I0211 01:20:37.444926 20090 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0211 01:20:37.444931 20090 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0211 01:20:37.444943 20090 net.cpp:323] res5a_branch2b needs backward computation.
I0211 01:20:37.444953 20090 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0211 01:20:37.444963 20090 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0211 01:20:37.444968 20090 net.cpp:323] res5a_branch2a needs backward computation.
I0211 01:20:37.444975 20090 net.cpp:323] pool4 needs backward computation.
I0211 01:20:37.444980 20090 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0211 01:20:37.444986 20090 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0211 01:20:37.444991 20090 net.cpp:323] res4a_branch2b needs backward computation.
I0211 01:20:37.444996 20090 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0211 01:20:37.445003 20090 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0211 01:20:37.445017 20090 net.cpp:323] res4a_branch2a needs backward computation.
I0211 01:20:37.445022 20090 net.cpp:323] pool3 needs backward computation.
I0211 01:20:37.445029 20090 net.cpp:323] res3a_branch2b_res3a_branch2b/relu_0_split needs backward computation.
I0211 01:20:37.445035 20090 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0211 01:20:37.445041 20090 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0211 01:20:37.445046 20090 net.cpp:323] res3a_branch2b needs backward computation.
I0211 01:20:37.445053 20090 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0211 01:20:37.445058 20090 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0211 01:20:37.445065 20090 net.cpp:323] res3a_branch2a needs backward computation.
I0211 01:20:37.445070 20090 net.cpp:323] pool2 needs backward computation.
I0211 01:20:37.445077 20090 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0211 01:20:37.445085 20090 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0211 01:20:37.445089 20090 net.cpp:323] res2a_branch2b needs backward computation.
I0211 01:20:37.445096 20090 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0211 01:20:37.445101 20090 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0211 01:20:37.445108 20090 net.cpp:323] res2a_branch2a needs backward computation.
I0211 01:20:37.445113 20090 net.cpp:323] pool1 needs backward computation.
I0211 01:20:37.445121 20090 net.cpp:323] conv1b/relu needs backward computation.
I0211 01:20:37.445125 20090 net.cpp:323] conv1b/bn needs backward computation.
I0211 01:20:37.445132 20090 net.cpp:323] conv1b needs backward computation.
I0211 01:20:37.445137 20090 net.cpp:323] conv1a/relu needs backward computation.
I0211 01:20:37.445143 20090 net.cpp:323] conv1a/bn needs backward computation.
I0211 01:20:37.445148 20090 net.cpp:323] conv1a needs backward computation.
I0211 01:20:37.445156 20090 net.cpp:325] data/bias does not need backward computation.
I0211 01:20:37.445165 20090 net.cpp:325] data_data_0_split does not need backward computation.
I0211 01:20:37.445173 20090 net.cpp:325] data does not need backward computation.
I0211 01:20:37.445178 20090 net.cpp:367] This network produces output mbox_loss
I0211 01:20:37.445302 20090 net.cpp:389] Top memory (TRAIN) required for data: 1304123976 diff: 1304123976
I0211 01:20:37.445310 20090 net.cpp:392] Bottom memory (TRAIN) required for data: 1304123968 diff: 1304123968
I0211 01:20:37.445315 20090 net.cpp:395] Shared (in-place) memory (TRAIN) by data: 563789824 diff: 563789824
I0211 01:20:37.445320 20090 net.cpp:398] Parameters memory (TRAIN) required for data: 12464288 diff: 12464288
I0211 01:20:37.445327 20090 net.cpp:401] Parameters shared memory (TRAIN) by data: 0 diff: 0
I0211 01:20:37.445332 20090 net.cpp:407] Network initialization done.
I0211 01:20:37.447917 20090 solver.cpp:177] Creating test net (#0) specified by test_net file: training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/test.prototxt
I0211 01:20:37.448853 20090 net.cpp:72] Initializing net from parameters: 
name: "ssdJacintoNetV2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_value: 0
    mean_value: 0
    mean_value: 0
    force_color: false
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 368
      width: 720
      interp_mode: LINEAR
    }
    crop_h: 368
    crop_w: 720
  }
  data_param {
    source: "/user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_test_lmdb"
    batch_size: 4
    backend: LMDB
    threads: 4
    parser_threads: 4
  }
  annotated_data_param {
    batch_sampler {
    }
    label_map_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/labelmap.prototxt"
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "pool6"
  top: "pool7"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool8"
  type: "Pooling"
  bottom: "pool7"
  top: "pool8"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool9"
  type: "Pooling"
  bottom: "pool8"
  top: "pool9"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "ctx_output1"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "ctx_output1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu"
  type: "ReLU"
  bottom: "ctx_output1"
  top: "ctx_output1"
}
layer {
  name: "ctx_output2"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "ctx_output2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu"
  type: "ReLU"
  bottom: "ctx_output2"
  top: "ctx_output2"
}
layer {
  name: "ctx_output3"
  type: "Convolution"
  bottom: "pool6"
  top: "ctx_output3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu"
  type: "ReLU"
  bottom: "ctx_output3"
  top: "ctx_output3"
}
layer {
  name: "ctx_output4"
  type: "Convolution"
  bottom: "pool7"
  top: "ctx_output4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu"
  type: "ReLU"
  bottom: "ctx_output4"
  top: "ctx_output4"
}
layer {
  name: "ctx_output5"
  type: "Convolution"
  bottom: "pool8"
  top: "ctx_output5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu"
  type: "ReLU"
  bottom: "ctx_output5"
  top: "ctx_output5"
}
layer {
  name: "ctx_output6"
  type: "Convolution"
  bottom: "pool9"
  top: "ctx_output6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu"
  type: "ReLU"
  bottom: "ctx_output6"
  top: "ctx_output6"
}
layer {
  name: "ctx_output1/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_loc"
  top: "ctx_output1/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_loc_perm"
  top: "ctx_output1/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_conf"
  top: "ctx_output1/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_conf_perm"
  top: "ctx_output1/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output1"
  bottom: "data"
  top: "ctx_output1/relu_mbox_priorbox"
  prior_box_param {
    min_size: 14.72
    max_size: 36.8
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_loc"
  top: "ctx_output2/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_loc_perm"
  top: "ctx_output2/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_conf"
  top: "ctx_output2/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_conf_perm"
  top: "ctx_output2/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output2"
  bottom: "data"
  top: "ctx_output2/relu_mbox_priorbox"
  prior_box_param {
    min_size: 36.8
    max_size: 110.4
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_loc"
  top: "ctx_output3/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_loc_perm"
  top: "ctx_output3/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_conf"
  top: "ctx_output3/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_conf_perm"
  top: "ctx_output3/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output3"
  bottom: "data"
  top: "ctx_output3/relu_mbox_priorbox"
  prior_box_param {
    min_size: 110.4
    max_size: 184
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_loc"
  top: "ctx_output4/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_loc_perm"
  top: "ctx_output4/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_conf"
  top: "ctx_output4/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_conf_perm"
  top: "ctx_output4/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output4"
  bottom: "data"
  top: "ctx_output4/relu_mbox_priorbox"
  prior_box_param {
    min_size: 184
    max_size: 257.6
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_loc"
  top: "ctx_output5/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_loc_perm"
  top: "ctx_output5/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_conf"
  top: "ctx_output5/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_conf_perm"
  top: "ctx_output5/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output5"
  bottom: "data"
  top: "ctx_output5/relu_mbox_priorbox"
  prior_box_param {
    min_size: 257.6
    max_size: 331.2
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_loc"
  top: "ctx_output6/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_loc_perm"
  top: "ctx_output6/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_conf"
  top: "ctx_output6/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_conf_perm"
  top: "ctx_output6/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output6"
  bottom: "data"
  top: "ctx_output6/relu_mbox_priorbox"
  prior_box_param {
    min_size: 331.2
    max_size: 404.8
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_loc_flat"
  bottom: "ctx_output2/relu_mbox_loc_flat"
  bottom: "ctx_output3/relu_mbox_loc_flat"
  bottom: "ctx_output4/relu_mbox_loc_flat"
  bottom: "ctx_output5/relu_mbox_loc_flat"
  bottom: "ctx_output6/relu_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_conf_flat"
  bottom: "ctx_output2/relu_mbox_conf_flat"
  bottom: "ctx_output3/relu_mbox_conf_flat"
  bottom: "ctx_output4/relu_mbox_conf_flat"
  bottom: "ctx_output5/relu_mbox_conf_flat"
  bottom: "ctx_output6/relu_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_priorbox"
  bottom: "ctx_output2/relu_mbox_priorbox"
  bottom: "ctx_output3/relu_mbox_priorbox"
  bottom: "ctx_output4/relu_mbox_priorbox"
  bottom: "ctx_output5/relu_mbox_priorbox"
  bottom: "ctx_output6/relu_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_reshape"
  type: "Reshape"
  bottom: "mbox_conf"
  top: "mbox_conf_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: -1
      dim: 4
    }
  }
}
layer {
  name: "mbox_conf_softmax"
  type: "Softmax"
  bottom: "mbox_conf_reshape"
  top: "mbox_conf_softmax"
  softmax_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_flatten"
  type: "Flatten"
  bottom: "mbox_conf_softmax"
  top: "mbox_conf_flatten"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "detection_out"
  type: "DetectionOutput"
  bottom: "mbox_loc"
  bottom: "mbox_conf_flatten"
  bottom: "mbox_priorbox"
  top: "detection_out"
  include {
    phase: TEST
  }
  detection_output_param {
    num_classes: 4
    share_location: true
    background_label_id: 0
    nms_param {
      nms_threshold: 0.45
      top_k: 400
    }
    save_output_param {
      output_directory: ""
      output_name_prefix: "comp4_det_test_"
      output_format: "VOC"
      label_map_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/labelmap.prototxt"
      name_size_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/test_name_size.txt"
      num_test_image: 3609
    }
    code_type: CENTER_SIZE
    keep_top_k: 200
    confidence_threshold: 0.01
  }
}
layer {
  name: "detection_eval"
  type: "DetectionEvaluate"
  bottom: "detection_out"
  bottom: "label"
  top: "detection_eval"
  include {
    phase: TEST
  }
  detection_evaluate_param {
    num_classes: 4
    background_label_id: 0
    overlap_threshold: 0.5
    evaluate_difficult_gt: false
    name_size_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/test_name_size.txt"
  }
}
I0211 01:20:37.449439 20090 net.cpp:104] Using FLOAT as default forward math type
I0211 01:20:37.449451 20090 net.cpp:110] Using FLOAT as default backward math type
I0211 01:20:37.449457 20090 layer_factory.hpp:136] Creating layer 'data' of type 'AnnotatedData'
I0211 01:20:37.449463 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.449487 20090 net.cpp:184] Created Layer data (0)
I0211 01:20:37.449496 20090 net.cpp:530] data -> data
I0211 01:20:37.449503 20090 net.cpp:530] data -> label
I0211 01:20:37.449519 20090 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 4
I0211 01:20:37.449530 20090 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0211 01:20:37.450456 20150 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_test_lmdb
I0211 01:20:37.461843 20090 annotated_data_layer.cpp:219] output data size: 4,3,368,720
I0211 01:20:37.461925 20090 annotated_data_layer.cpp:265] (0) Output data size: 4, 3, 368, 720
I0211 01:20:37.461987 20090 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0211 01:20:37.462038 20090 net.cpp:245] Setting up data
I0211 01:20:37.462050 20090 net.cpp:252] TEST Top shape for layer 0 'data' 4 3 368 720 (3179520)
I0211 01:20:37.462059 20090 net.cpp:252] TEST Top shape for layer 0 'data' 1 1 31 8 (248)
I0211 01:20:37.462070 20090 layer_factory.hpp:136] Creating layer 'data_data_0_split' of type 'Split'
I0211 01:20:37.462077 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.462087 20090 net.cpp:184] Created Layer data_data_0_split (1)
I0211 01:20:37.462095 20090 net.cpp:561] data_data_0_split <- data
I0211 01:20:37.462103 20090 net.cpp:530] data_data_0_split -> data_data_0_split_0
I0211 01:20:37.462115 20090 net.cpp:530] data_data_0_split -> data_data_0_split_1
I0211 01:20:37.462121 20090 net.cpp:530] data_data_0_split -> data_data_0_split_2
I0211 01:20:37.462131 20090 net.cpp:530] data_data_0_split -> data_data_0_split_3
I0211 01:20:37.462137 20090 net.cpp:530] data_data_0_split -> data_data_0_split_4
I0211 01:20:37.462146 20090 net.cpp:530] data_data_0_split -> data_data_0_split_5
I0211 01:20:37.462152 20090 net.cpp:530] data_data_0_split -> data_data_0_split_6
I0211 01:20:37.462347 20090 net.cpp:245] Setting up data_data_0_split
I0211 01:20:37.462357 20090 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 368 720 (3179520)
I0211 01:20:37.462365 20090 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 368 720 (3179520)
I0211 01:20:37.462371 20090 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 368 720 (3179520)
I0211 01:20:37.462379 20090 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 368 720 (3179520)
I0211 01:20:37.462385 20090 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 368 720 (3179520)
I0211 01:20:37.462391 20090 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 368 720 (3179520)
I0211 01:20:37.462399 20090 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 368 720 (3179520)
I0211 01:20:37.462404 20090 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0211 01:20:37.462410 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.462422 20090 net.cpp:184] Created Layer data/bias (2)
I0211 01:20:37.462430 20090 net.cpp:561] data/bias <- data_data_0_split_0
I0211 01:20:37.462436 20090 net.cpp:530] data/bias -> data/bias
I0211 01:20:37.463737 20151 annotated_data_layer.cpp:111] (0) Parser threads: 1
I0211 01:20:37.463762 20151 annotated_data_layer.cpp:113] (0) Transformer threads: 1
I0211 01:20:37.464365 20090 net.cpp:245] Setting up data/bias
I0211 01:20:37.464385 20090 net.cpp:252] TEST Top shape for layer 2 'data/bias' 4 3 368 720 (3179520)
I0211 01:20:37.464399 20090 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0211 01:20:37.464414 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.464433 20090 net.cpp:184] Created Layer conv1a (3)
I0211 01:20:37.464442 20090 net.cpp:561] conv1a <- data/bias
I0211 01:20:37.464449 20090 net.cpp:530] conv1a -> conv1a
I0211 01:20:37.465167 20090 net.cpp:245] Setting up conv1a
I0211 01:20:37.465184 20090 net.cpp:252] TEST Top shape for layer 3 'conv1a' 4 32 184 360 (8478720)
I0211 01:20:37.465204 20090 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0211 01:20:37.465216 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.465232 20090 net.cpp:184] Created Layer conv1a/bn (4)
I0211 01:20:37.465240 20090 net.cpp:561] conv1a/bn <- conv1a
I0211 01:20:37.465246 20090 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0211 01:20:37.466235 20090 net.cpp:245] Setting up conv1a/bn
I0211 01:20:37.466251 20090 net.cpp:252] TEST Top shape for layer 4 'conv1a/bn' 4 32 184 360 (8478720)
I0211 01:20:37.466272 20090 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0211 01:20:37.466281 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.466305 20090 net.cpp:184] Created Layer conv1a/relu (5)
I0211 01:20:37.466312 20090 net.cpp:561] conv1a/relu <- conv1a
I0211 01:20:37.466318 20090 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0211 01:20:37.466329 20090 net.cpp:245] Setting up conv1a/relu
I0211 01:20:37.466338 20090 net.cpp:252] TEST Top shape for layer 5 'conv1a/relu' 4 32 184 360 (8478720)
I0211 01:20:37.466344 20090 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0211 01:20:37.466351 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.466365 20090 net.cpp:184] Created Layer conv1b (6)
I0211 01:20:37.466373 20090 net.cpp:561] conv1b <- conv1a
I0211 01:20:37.466379 20090 net.cpp:530] conv1b -> conv1b
I0211 01:20:37.467381 20090 net.cpp:245] Setting up conv1b
I0211 01:20:37.467398 20090 net.cpp:252] TEST Top shape for layer 6 'conv1b' 4 32 184 360 (8478720)
I0211 01:20:37.467412 20090 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0211 01:20:37.467422 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.467438 20090 net.cpp:184] Created Layer conv1b/bn (7)
I0211 01:20:37.467447 20090 net.cpp:561] conv1b/bn <- conv1b
I0211 01:20:37.467458 20090 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0211 01:20:37.468432 20090 net.cpp:245] Setting up conv1b/bn
I0211 01:20:37.468451 20090 net.cpp:252] TEST Top shape for layer 7 'conv1b/bn' 4 32 184 360 (8478720)
I0211 01:20:37.468473 20090 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0211 01:20:37.468484 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.468518 20090 net.cpp:184] Created Layer conv1b/relu (8)
I0211 01:20:37.468533 20090 net.cpp:561] conv1b/relu <- conv1b
I0211 01:20:37.468542 20090 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0211 01:20:37.468557 20090 net.cpp:245] Setting up conv1b/relu
I0211 01:20:37.468570 20090 net.cpp:252] TEST Top shape for layer 8 'conv1b/relu' 4 32 184 360 (8478720)
I0211 01:20:37.468582 20090 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0211 01:20:37.468592 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.468606 20090 net.cpp:184] Created Layer pool1 (9)
I0211 01:20:37.468616 20090 net.cpp:561] pool1 <- conv1b
I0211 01:20:37.468624 20090 net.cpp:530] pool1 -> pool1
I0211 01:20:37.468734 20090 net.cpp:245] Setting up pool1
I0211 01:20:37.468746 20090 net.cpp:252] TEST Top shape for layer 9 'pool1' 4 32 92 180 (2119680)
I0211 01:20:37.468756 20090 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0211 01:20:37.468766 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.468786 20090 net.cpp:184] Created Layer res2a_branch2a (10)
I0211 01:20:37.468794 20090 net.cpp:561] res2a_branch2a <- pool1
I0211 01:20:37.468803 20090 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0211 01:20:37.469987 20090 net.cpp:245] Setting up res2a_branch2a
I0211 01:20:37.470006 20090 net.cpp:252] TEST Top shape for layer 10 'res2a_branch2a' 4 64 92 180 (4239360)
I0211 01:20:37.470028 20090 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0211 01:20:37.470039 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.470055 20090 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0211 01:20:37.470064 20090 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0211 01:20:37.470074 20090 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0211 01:20:37.471017 20090 net.cpp:245] Setting up res2a_branch2a/bn
I0211 01:20:37.471035 20090 net.cpp:252] TEST Top shape for layer 11 'res2a_branch2a/bn' 4 64 92 180 (4239360)
I0211 01:20:37.471055 20090 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0211 01:20:37.471066 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.471092 20090 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0211 01:20:37.471103 20090 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0211 01:20:37.471113 20090 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0211 01:20:37.471125 20090 net.cpp:245] Setting up res2a_branch2a/relu
I0211 01:20:37.471138 20090 net.cpp:252] TEST Top shape for layer 12 'res2a_branch2a/relu' 4 64 92 180 (4239360)
I0211 01:20:37.471148 20090 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0211 01:20:37.471156 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.471176 20090 net.cpp:184] Created Layer res2a_branch2b (13)
I0211 01:20:37.471184 20090 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0211 01:20:37.471194 20090 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0211 01:20:37.471994 20090 net.cpp:245] Setting up res2a_branch2b
I0211 01:20:37.472012 20090 net.cpp:252] TEST Top shape for layer 13 'res2a_branch2b' 4 64 92 180 (4239360)
I0211 01:20:37.472026 20090 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0211 01:20:37.472038 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.472051 20090 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0211 01:20:37.472060 20090 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0211 01:20:37.472069 20090 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0211 01:20:37.473002 20090 net.cpp:245] Setting up res2a_branch2b/bn
I0211 01:20:37.473021 20090 net.cpp:252] TEST Top shape for layer 14 'res2a_branch2b/bn' 4 64 92 180 (4239360)
I0211 01:20:37.473042 20090 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0211 01:20:37.473050 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.473062 20090 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0211 01:20:37.473071 20090 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0211 01:20:37.473080 20090 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0211 01:20:37.473093 20090 net.cpp:245] Setting up res2a_branch2b/relu
I0211 01:20:37.473104 20090 net.cpp:252] TEST Top shape for layer 15 'res2a_branch2b/relu' 4 64 92 180 (4239360)
I0211 01:20:37.473114 20090 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0211 01:20:37.473122 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.473139 20090 net.cpp:184] Created Layer pool2 (16)
I0211 01:20:37.473146 20090 net.cpp:561] pool2 <- res2a_branch2b
I0211 01:20:37.473155 20090 net.cpp:530] pool2 -> pool2
I0211 01:20:37.473255 20090 net.cpp:245] Setting up pool2
I0211 01:20:37.473268 20090 net.cpp:252] TEST Top shape for layer 16 'pool2' 4 64 46 90 (1059840)
I0211 01:20:37.473278 20090 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0211 01:20:37.473287 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.473309 20090 net.cpp:184] Created Layer res3a_branch2a (17)
I0211 01:20:37.473316 20090 net.cpp:561] res3a_branch2a <- pool2
I0211 01:20:37.473325 20090 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0211 01:20:37.476362 20090 net.cpp:245] Setting up res3a_branch2a
I0211 01:20:37.476382 20090 net.cpp:252] TEST Top shape for layer 17 'res3a_branch2a' 4 128 46 90 (2119680)
I0211 01:20:37.476397 20090 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0211 01:20:37.476406 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.476424 20090 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0211 01:20:37.476434 20090 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0211 01:20:37.476444 20090 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0211 01:20:37.477372 20090 net.cpp:245] Setting up res3a_branch2a/bn
I0211 01:20:37.477401 20090 net.cpp:252] TEST Top shape for layer 18 'res3a_branch2a/bn' 4 128 46 90 (2119680)
I0211 01:20:37.477425 20090 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0211 01:20:37.477434 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.477447 20090 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0211 01:20:37.477455 20090 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0211 01:20:37.477465 20090 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0211 01:20:37.477479 20090 net.cpp:245] Setting up res3a_branch2a/relu
I0211 01:20:37.477490 20090 net.cpp:252] TEST Top shape for layer 19 'res3a_branch2a/relu' 4 128 46 90 (2119680)
I0211 01:20:37.477499 20090 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0211 01:20:37.477509 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.477526 20090 net.cpp:184] Created Layer res3a_branch2b (20)
I0211 01:20:37.477535 20090 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0211 01:20:37.477543 20090 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0211 01:20:37.479287 20090 net.cpp:245] Setting up res3a_branch2b
I0211 01:20:37.479305 20090 net.cpp:252] TEST Top shape for layer 20 'res3a_branch2b' 4 128 46 90 (2119680)
I0211 01:20:37.479321 20090 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0211 01:20:37.479331 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.479346 20090 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0211 01:20:37.479354 20090 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0211 01:20:37.479363 20090 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0211 01:20:37.480250 20090 net.cpp:245] Setting up res3a_branch2b/bn
I0211 01:20:37.480268 20090 net.cpp:252] TEST Top shape for layer 21 'res3a_branch2b/bn' 4 128 46 90 (2119680)
I0211 01:20:37.480286 20090 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0211 01:20:37.480295 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.480307 20090 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0211 01:20:37.480317 20090 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0211 01:20:37.480326 20090 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0211 01:20:37.480340 20090 net.cpp:245] Setting up res3a_branch2b/relu
I0211 01:20:37.480351 20090 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b/relu' 4 128 46 90 (2119680)
I0211 01:20:37.480360 20090 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0211 01:20:37.480370 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.480382 20090 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (23)
I0211 01:20:37.480391 20090 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0211 01:20:37.480401 20090 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0211 01:20:37.480410 20090 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0211 01:20:37.480504 20090 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0211 01:20:37.480518 20090 net.cpp:252] TEST Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 4 128 46 90 (2119680)
I0211 01:20:37.480530 20090 net.cpp:252] TEST Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 4 128 46 90 (2119680)
I0211 01:20:37.480540 20090 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0211 01:20:37.480548 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.480563 20090 net.cpp:184] Created Layer pool3 (24)
I0211 01:20:37.480572 20090 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0211 01:20:37.480594 20090 net.cpp:530] pool3 -> pool3
I0211 01:20:37.480695 20090 net.cpp:245] Setting up pool3
I0211 01:20:37.480708 20090 net.cpp:252] TEST Top shape for layer 24 'pool3' 4 128 23 45 (529920)
I0211 01:20:37.480717 20090 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0211 01:20:37.480727 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.480746 20090 net.cpp:184] Created Layer res4a_branch2a (25)
I0211 01:20:37.480754 20090 net.cpp:561] res4a_branch2a <- pool3
I0211 01:20:37.480763 20090 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0211 01:20:37.492851 20090 net.cpp:245] Setting up res4a_branch2a
I0211 01:20:37.492887 20090 net.cpp:252] TEST Top shape for layer 25 'res4a_branch2a' 4 256 23 45 (1059840)
I0211 01:20:37.492905 20090 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0211 01:20:37.492915 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.492941 20090 net.cpp:184] Created Layer res4a_branch2a/bn (26)
I0211 01:20:37.492952 20090 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0211 01:20:37.492967 20090 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0211 01:20:37.493896 20090 net.cpp:245] Setting up res4a_branch2a/bn
I0211 01:20:37.493914 20090 net.cpp:252] TEST Top shape for layer 26 'res4a_branch2a/bn' 4 256 23 45 (1059840)
I0211 01:20:37.493937 20090 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0211 01:20:37.493948 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.493960 20090 net.cpp:184] Created Layer res4a_branch2a/relu (27)
I0211 01:20:37.493969 20090 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0211 01:20:37.493978 20090 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0211 01:20:37.493991 20090 net.cpp:245] Setting up res4a_branch2a/relu
I0211 01:20:37.494002 20090 net.cpp:252] TEST Top shape for layer 27 'res4a_branch2a/relu' 4 256 23 45 (1059840)
I0211 01:20:37.494011 20090 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0211 01:20:37.494019 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.494045 20090 net.cpp:184] Created Layer res4a_branch2b (28)
I0211 01:20:37.494053 20090 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0211 01:20:37.494062 20090 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0211 01:20:37.499439 20090 net.cpp:245] Setting up res4a_branch2b
I0211 01:20:37.499459 20090 net.cpp:252] TEST Top shape for layer 28 'res4a_branch2b' 4 256 23 45 (1059840)
I0211 01:20:37.499472 20090 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0211 01:20:37.499483 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.499516 20090 net.cpp:184] Created Layer res4a_branch2b/bn (29)
I0211 01:20:37.499524 20090 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0211 01:20:37.499541 20090 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0211 01:20:37.500458 20090 net.cpp:245] Setting up res4a_branch2b/bn
I0211 01:20:37.500476 20090 net.cpp:252] TEST Top shape for layer 29 'res4a_branch2b/bn' 4 256 23 45 (1059840)
I0211 01:20:37.500526 20090 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0211 01:20:37.500540 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.500552 20090 net.cpp:184] Created Layer res4a_branch2b/relu (30)
I0211 01:20:37.500561 20090 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0211 01:20:37.500573 20090 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0211 01:20:37.500586 20090 net.cpp:245] Setting up res4a_branch2b/relu
I0211 01:20:37.500597 20090 net.cpp:252] TEST Top shape for layer 30 'res4a_branch2b/relu' 4 256 23 45 (1059840)
I0211 01:20:37.500623 20090 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0211 01:20:37.500635 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.500660 20090 net.cpp:184] Created Layer pool4 (31)
I0211 01:20:37.500671 20090 net.cpp:561] pool4 <- res4a_branch2b
I0211 01:20:37.500680 20090 net.cpp:530] pool4 -> pool4
I0211 01:20:37.500783 20090 net.cpp:245] Setting up pool4
I0211 01:20:37.500795 20090 net.cpp:252] TEST Top shape for layer 31 'pool4' 4 256 12 23 (282624)
I0211 01:20:37.500800 20090 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0211 01:20:37.500807 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.500823 20090 net.cpp:184] Created Layer res5a_branch2a (32)
I0211 01:20:37.500829 20090 net.cpp:561] res5a_branch2a <- pool4
I0211 01:20:37.500835 20090 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0211 01:20:37.541213 20090 net.cpp:245] Setting up res5a_branch2a
I0211 01:20:37.541245 20090 net.cpp:252] TEST Top shape for layer 32 'res5a_branch2a' 4 512 12 23 (565248)
I0211 01:20:37.541257 20090 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0211 01:20:37.541263 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.541280 20090 net.cpp:184] Created Layer res5a_branch2a/bn (33)
I0211 01:20:37.541293 20090 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0211 01:20:37.541303 20090 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0211 01:20:37.542212 20090 net.cpp:245] Setting up res5a_branch2a/bn
I0211 01:20:37.542228 20090 net.cpp:252] TEST Top shape for layer 33 'res5a_branch2a/bn' 4 512 12 23 (565248)
I0211 01:20:37.542246 20090 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0211 01:20:37.542259 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.542271 20090 net.cpp:184] Created Layer res5a_branch2a/relu (34)
I0211 01:20:37.542285 20090 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0211 01:20:37.542295 20090 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0211 01:20:37.542307 20090 net.cpp:245] Setting up res5a_branch2a/relu
I0211 01:20:37.542320 20090 net.cpp:252] TEST Top shape for layer 34 'res5a_branch2a/relu' 4 512 12 23 (565248)
I0211 01:20:37.542330 20090 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0211 01:20:37.542337 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.542371 20090 net.cpp:184] Created Layer res5a_branch2b (35)
I0211 01:20:37.542382 20090 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0211 01:20:37.542389 20090 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0211 01:20:37.563076 20090 net.cpp:245] Setting up res5a_branch2b
I0211 01:20:37.563118 20090 net.cpp:252] TEST Top shape for layer 35 'res5a_branch2b' 4 512 12 23 (565248)
I0211 01:20:37.563139 20090 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0211 01:20:37.563150 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.563174 20090 net.cpp:184] Created Layer res5a_branch2b/bn (36)
I0211 01:20:37.563189 20090 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0211 01:20:37.563210 20090 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0211 01:20:37.564173 20090 net.cpp:245] Setting up res5a_branch2b/bn
I0211 01:20:37.564201 20090 net.cpp:252] TEST Top shape for layer 36 'res5a_branch2b/bn' 4 512 12 23 (565248)
I0211 01:20:37.564214 20090 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0211 01:20:37.564221 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.564232 20090 net.cpp:184] Created Layer res5a_branch2b/relu (37)
I0211 01:20:37.564241 20090 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0211 01:20:37.564275 20090 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0211 01:20:37.564290 20090 net.cpp:245] Setting up res5a_branch2b/relu
I0211 01:20:37.564307 20090 net.cpp:252] TEST Top shape for layer 37 'res5a_branch2b/relu' 4 512 12 23 (565248)
I0211 01:20:37.564316 20090 layer_factory.hpp:136] Creating layer 'res5a_branch2b_res5a_branch2b/relu_0_split' of type 'Split'
I0211 01:20:37.564327 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.564339 20090 net.cpp:184] Created Layer res5a_branch2b_res5a_branch2b/relu_0_split (38)
I0211 01:20:37.564350 20090 net.cpp:561] res5a_branch2b_res5a_branch2b/relu_0_split <- res5a_branch2b
I0211 01:20:37.564358 20090 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_0
I0211 01:20:37.564373 20090 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_1
I0211 01:20:37.564465 20090 net.cpp:245] Setting up res5a_branch2b_res5a_branch2b/relu_0_split
I0211 01:20:37.564477 20090 net.cpp:252] TEST Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 4 512 12 23 (565248)
I0211 01:20:37.564508 20090 net.cpp:252] TEST Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 4 512 12 23 (565248)
I0211 01:20:37.564517 20090 layer_factory.hpp:136] Creating layer 'pool6' of type 'Pooling'
I0211 01:20:37.564527 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.564544 20090 net.cpp:184] Created Layer pool6 (39)
I0211 01:20:37.564556 20090 net.cpp:561] pool6 <- res5a_branch2b_res5a_branch2b/relu_0_split_0
I0211 01:20:37.564566 20090 net.cpp:530] pool6 -> pool6
I0211 01:20:37.564677 20090 net.cpp:245] Setting up pool6
I0211 01:20:37.564689 20090 net.cpp:252] TEST Top shape for layer 39 'pool6' 4 512 6 12 (147456)
I0211 01:20:37.564695 20090 layer_factory.hpp:136] Creating layer 'pool6_pool6_0_split' of type 'Split'
I0211 01:20:37.564702 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.564715 20090 net.cpp:184] Created Layer pool6_pool6_0_split (40)
I0211 01:20:37.564723 20090 net.cpp:561] pool6_pool6_0_split <- pool6
I0211 01:20:37.564735 20090 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_0
I0211 01:20:37.564749 20090 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_1
I0211 01:20:37.564841 20090 net.cpp:245] Setting up pool6_pool6_0_split
I0211 01:20:37.564851 20090 net.cpp:252] TEST Top shape for layer 40 'pool6_pool6_0_split' 4 512 6 12 (147456)
I0211 01:20:37.564858 20090 net.cpp:252] TEST Top shape for layer 40 'pool6_pool6_0_split' 4 512 6 12 (147456)
I0211 01:20:37.564864 20090 layer_factory.hpp:136] Creating layer 'pool7' of type 'Pooling'
I0211 01:20:37.564872 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.564890 20090 net.cpp:184] Created Layer pool7 (41)
I0211 01:20:37.564901 20090 net.cpp:561] pool7 <- pool6_pool6_0_split_0
I0211 01:20:37.564910 20090 net.cpp:530] pool7 -> pool7
I0211 01:20:37.565011 20090 net.cpp:245] Setting up pool7
I0211 01:20:37.565022 20090 net.cpp:252] TEST Top shape for layer 41 'pool7' 4 512 3 6 (36864)
I0211 01:20:37.565027 20090 layer_factory.hpp:136] Creating layer 'pool7_pool7_0_split' of type 'Split'
I0211 01:20:37.565034 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.565047 20090 net.cpp:184] Created Layer pool7_pool7_0_split (42)
I0211 01:20:37.565054 20090 net.cpp:561] pool7_pool7_0_split <- pool7
I0211 01:20:37.565069 20090 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_0
I0211 01:20:37.565085 20090 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_1
I0211 01:20:37.565165 20090 net.cpp:245] Setting up pool7_pool7_0_split
I0211 01:20:37.565177 20090 net.cpp:252] TEST Top shape for layer 42 'pool7_pool7_0_split' 4 512 3 6 (36864)
I0211 01:20:37.565186 20090 net.cpp:252] TEST Top shape for layer 42 'pool7_pool7_0_split' 4 512 3 6 (36864)
I0211 01:20:37.565209 20090 layer_factory.hpp:136] Creating layer 'pool8' of type 'Pooling'
I0211 01:20:37.565218 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.565239 20090 net.cpp:184] Created Layer pool8 (43)
I0211 01:20:37.565251 20090 net.cpp:561] pool8 <- pool7_pool7_0_split_0
I0211 01:20:37.565259 20090 net.cpp:530] pool8 -> pool8
I0211 01:20:37.565363 20090 net.cpp:245] Setting up pool8
I0211 01:20:37.565376 20090 net.cpp:252] TEST Top shape for layer 43 'pool8' 4 512 2 3 (12288)
I0211 01:20:37.565382 20090 layer_factory.hpp:136] Creating layer 'pool8_pool8_0_split' of type 'Split'
I0211 01:20:37.565388 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.565403 20090 net.cpp:184] Created Layer pool8_pool8_0_split (44)
I0211 01:20:37.565415 20090 net.cpp:561] pool8_pool8_0_split <- pool8
I0211 01:20:37.565424 20090 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_0
I0211 01:20:37.565433 20090 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_1
I0211 01:20:37.565513 20090 net.cpp:245] Setting up pool8_pool8_0_split
I0211 01:20:37.565526 20090 net.cpp:252] TEST Top shape for layer 44 'pool8_pool8_0_split' 4 512 2 3 (12288)
I0211 01:20:37.565532 20090 net.cpp:252] TEST Top shape for layer 44 'pool8_pool8_0_split' 4 512 2 3 (12288)
I0211 01:20:37.565539 20090 layer_factory.hpp:136] Creating layer 'pool9' of type 'Pooling'
I0211 01:20:37.565547 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.565562 20090 net.cpp:184] Created Layer pool9 (45)
I0211 01:20:37.565573 20090 net.cpp:561] pool9 <- pool8_pool8_0_split_0
I0211 01:20:37.565582 20090 net.cpp:530] pool9 -> pool9
I0211 01:20:37.565676 20090 net.cpp:245] Setting up pool9
I0211 01:20:37.565688 20090 net.cpp:252] TEST Top shape for layer 45 'pool9' 4 512 1 2 (4096)
I0211 01:20:37.565695 20090 layer_factory.hpp:136] Creating layer 'ctx_output1' of type 'Convolution'
I0211 01:20:37.565701 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.565726 20090 net.cpp:184] Created Layer ctx_output1 (46)
I0211 01:20:37.565737 20090 net.cpp:561] ctx_output1 <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0211 01:20:37.565747 20090 net.cpp:530] ctx_output1 -> ctx_output1
I0211 01:20:37.567302 20090 net.cpp:245] Setting up ctx_output1
I0211 01:20:37.567318 20090 net.cpp:252] TEST Top shape for layer 46 'ctx_output1' 4 256 46 90 (4239360)
I0211 01:20:37.567329 20090 layer_factory.hpp:136] Creating layer 'ctx_output1/relu' of type 'ReLU'
I0211 01:20:37.567337 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.567347 20090 net.cpp:184] Created Layer ctx_output1/relu (47)
I0211 01:20:37.567358 20090 net.cpp:561] ctx_output1/relu <- ctx_output1
I0211 01:20:37.567368 20090 net.cpp:513] ctx_output1/relu -> ctx_output1 (in-place)
I0211 01:20:37.567386 20090 net.cpp:245] Setting up ctx_output1/relu
I0211 01:20:37.567399 20090 net.cpp:252] TEST Top shape for layer 47 'ctx_output1/relu' 4 256 46 90 (4239360)
I0211 01:20:37.567406 20090 layer_factory.hpp:136] Creating layer 'ctx_output1_ctx_output1/relu_0_split' of type 'Split'
I0211 01:20:37.567414 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.567426 20090 net.cpp:184] Created Layer ctx_output1_ctx_output1/relu_0_split (48)
I0211 01:20:37.567435 20090 net.cpp:561] ctx_output1_ctx_output1/relu_0_split <- ctx_output1
I0211 01:20:37.567446 20090 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_0
I0211 01:20:37.567461 20090 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_1
I0211 01:20:37.567471 20090 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_2
I0211 01:20:37.567577 20090 net.cpp:245] Setting up ctx_output1_ctx_output1/relu_0_split
I0211 01:20:37.567597 20090 net.cpp:252] TEST Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 4 256 46 90 (4239360)
I0211 01:20:37.567605 20090 net.cpp:252] TEST Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 4 256 46 90 (4239360)
I0211 01:20:37.567613 20090 net.cpp:252] TEST Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 4 256 46 90 (4239360)
I0211 01:20:37.567621 20090 layer_factory.hpp:136] Creating layer 'ctx_output2' of type 'Convolution'
I0211 01:20:37.567632 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.567658 20090 net.cpp:184] Created Layer ctx_output2 (49)
I0211 01:20:37.567667 20090 net.cpp:561] ctx_output2 <- res5a_branch2b_res5a_branch2b/relu_0_split_1
I0211 01:20:37.567674 20090 net.cpp:530] ctx_output2 -> ctx_output2
I0211 01:20:37.572430 20090 net.cpp:245] Setting up ctx_output2
I0211 01:20:37.572448 20090 net.cpp:252] TEST Top shape for layer 49 'ctx_output2' 4 256 12 23 (282624)
I0211 01:20:37.572458 20090 layer_factory.hpp:136] Creating layer 'ctx_output2/relu' of type 'ReLU'
I0211 01:20:37.572468 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.572481 20090 net.cpp:184] Created Layer ctx_output2/relu (50)
I0211 01:20:37.572517 20090 net.cpp:561] ctx_output2/relu <- ctx_output2
I0211 01:20:37.572528 20090 net.cpp:513] ctx_output2/relu -> ctx_output2 (in-place)
I0211 01:20:37.572541 20090 net.cpp:245] Setting up ctx_output2/relu
I0211 01:20:37.572554 20090 net.cpp:252] TEST Top shape for layer 50 'ctx_output2/relu' 4 256 12 23 (282624)
I0211 01:20:37.572562 20090 layer_factory.hpp:136] Creating layer 'ctx_output2_ctx_output2/relu_0_split' of type 'Split'
I0211 01:20:37.572571 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.572582 20090 net.cpp:184] Created Layer ctx_output2_ctx_output2/relu_0_split (51)
I0211 01:20:37.572592 20090 net.cpp:561] ctx_output2_ctx_output2/relu_0_split <- ctx_output2
I0211 01:20:37.572603 20090 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_0
I0211 01:20:37.572618 20090 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_1
I0211 01:20:37.572631 20090 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_2
I0211 01:20:37.572746 20090 net.cpp:245] Setting up ctx_output2_ctx_output2/relu_0_split
I0211 01:20:37.572758 20090 net.cpp:252] TEST Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 4 256 12 23 (282624)
I0211 01:20:37.572765 20090 net.cpp:252] TEST Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 4 256 12 23 (282624)
I0211 01:20:37.572773 20090 net.cpp:252] TEST Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 4 256 12 23 (282624)
I0211 01:20:37.572782 20090 layer_factory.hpp:136] Creating layer 'ctx_output3' of type 'Convolution'
I0211 01:20:37.572794 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.572834 20090 net.cpp:184] Created Layer ctx_output3 (52)
I0211 01:20:37.572845 20090 net.cpp:561] ctx_output3 <- pool6_pool6_0_split_1
I0211 01:20:37.572852 20090 net.cpp:530] ctx_output3 -> ctx_output3
I0211 01:20:37.578742 20090 net.cpp:245] Setting up ctx_output3
I0211 01:20:37.578769 20090 net.cpp:252] TEST Top shape for layer 52 'ctx_output3' 4 256 6 12 (73728)
I0211 01:20:37.578783 20090 layer_factory.hpp:136] Creating layer 'ctx_output3/relu' of type 'ReLU'
I0211 01:20:37.578794 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.578814 20090 net.cpp:184] Created Layer ctx_output3/relu (53)
I0211 01:20:37.578824 20090 net.cpp:561] ctx_output3/relu <- ctx_output3
I0211 01:20:37.578835 20090 net.cpp:513] ctx_output3/relu -> ctx_output3 (in-place)
I0211 01:20:37.578852 20090 net.cpp:245] Setting up ctx_output3/relu
I0211 01:20:37.578878 20090 net.cpp:252] TEST Top shape for layer 53 'ctx_output3/relu' 4 256 6 12 (73728)
I0211 01:20:37.578886 20090 layer_factory.hpp:136] Creating layer 'ctx_output3_ctx_output3/relu_0_split' of type 'Split'
I0211 01:20:37.578894 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.578905 20090 net.cpp:184] Created Layer ctx_output3_ctx_output3/relu_0_split (54)
I0211 01:20:37.578917 20090 net.cpp:561] ctx_output3_ctx_output3/relu_0_split <- ctx_output3
I0211 01:20:37.578927 20090 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_0
I0211 01:20:37.578938 20090 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_1
I0211 01:20:37.578958 20090 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_2
I0211 01:20:37.579073 20090 net.cpp:245] Setting up ctx_output3_ctx_output3/relu_0_split
I0211 01:20:37.579085 20090 net.cpp:252] TEST Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 4 256 6 12 (73728)
I0211 01:20:37.579092 20090 net.cpp:252] TEST Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 4 256 6 12 (73728)
I0211 01:20:37.579099 20090 net.cpp:252] TEST Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 4 256 6 12 (73728)
I0211 01:20:37.579107 20090 layer_factory.hpp:136] Creating layer 'ctx_output4' of type 'Convolution'
I0211 01:20:37.579118 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.579144 20090 net.cpp:184] Created Layer ctx_output4 (55)
I0211 01:20:37.579154 20090 net.cpp:561] ctx_output4 <- pool7_pool7_0_split_1
I0211 01:20:37.579162 20090 net.cpp:530] ctx_output4 -> ctx_output4
I0211 01:20:37.583688 20090 net.cpp:245] Setting up ctx_output4
I0211 01:20:37.583703 20090 net.cpp:252] TEST Top shape for layer 55 'ctx_output4' 4 256 3 6 (18432)
I0211 01:20:37.583724 20090 layer_factory.hpp:136] Creating layer 'ctx_output4/relu' of type 'ReLU'
I0211 01:20:37.583730 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.583739 20090 net.cpp:184] Created Layer ctx_output4/relu (56)
I0211 01:20:37.583744 20090 net.cpp:561] ctx_output4/relu <- ctx_output4
I0211 01:20:37.583748 20090 net.cpp:513] ctx_output4/relu -> ctx_output4 (in-place)
I0211 01:20:37.583761 20090 net.cpp:245] Setting up ctx_output4/relu
I0211 01:20:37.583782 20090 net.cpp:252] TEST Top shape for layer 56 'ctx_output4/relu' 4 256 3 6 (18432)
I0211 01:20:37.583791 20090 layer_factory.hpp:136] Creating layer 'ctx_output4_ctx_output4/relu_0_split' of type 'Split'
I0211 01:20:37.583806 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.583817 20090 net.cpp:184] Created Layer ctx_output4_ctx_output4/relu_0_split (57)
I0211 01:20:37.583832 20090 net.cpp:561] ctx_output4_ctx_output4/relu_0_split <- ctx_output4
I0211 01:20:37.583842 20090 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_0
I0211 01:20:37.583854 20090 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_1
I0211 01:20:37.583868 20090 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_2
I0211 01:20:37.583979 20090 net.cpp:245] Setting up ctx_output4_ctx_output4/relu_0_split
I0211 01:20:37.583992 20090 net.cpp:252] TEST Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 4 256 3 6 (18432)
I0211 01:20:37.583999 20090 net.cpp:252] TEST Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 4 256 3 6 (18432)
I0211 01:20:37.584007 20090 net.cpp:252] TEST Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 4 256 3 6 (18432)
I0211 01:20:37.584015 20090 layer_factory.hpp:136] Creating layer 'ctx_output5' of type 'Convolution'
I0211 01:20:37.584024 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.584051 20090 net.cpp:184] Created Layer ctx_output5 (58)
I0211 01:20:37.584070 20090 net.cpp:561] ctx_output5 <- pool8_pool8_0_split_1
I0211 01:20:37.584079 20090 net.cpp:530] ctx_output5 -> ctx_output5
I0211 01:20:37.588762 20090 net.cpp:245] Setting up ctx_output5
I0211 01:20:37.588778 20090 net.cpp:252] TEST Top shape for layer 58 'ctx_output5' 4 256 2 3 (6144)
I0211 01:20:37.588789 20090 layer_factory.hpp:136] Creating layer 'ctx_output5/relu' of type 'ReLU'
I0211 01:20:37.588798 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.588811 20090 net.cpp:184] Created Layer ctx_output5/relu (59)
I0211 01:20:37.588829 20090 net.cpp:561] ctx_output5/relu <- ctx_output5
I0211 01:20:37.588840 20090 net.cpp:513] ctx_output5/relu -> ctx_output5 (in-place)
I0211 01:20:37.588872 20090 net.cpp:245] Setting up ctx_output5/relu
I0211 01:20:37.588899 20090 net.cpp:252] TEST Top shape for layer 59 'ctx_output5/relu' 4 256 2 3 (6144)
I0211 01:20:37.588907 20090 layer_factory.hpp:136] Creating layer 'ctx_output5_ctx_output5/relu_0_split' of type 'Split'
I0211 01:20:37.588917 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.588932 20090 net.cpp:184] Created Layer ctx_output5_ctx_output5/relu_0_split (60)
I0211 01:20:37.588943 20090 net.cpp:561] ctx_output5_ctx_output5/relu_0_split <- ctx_output5
I0211 01:20:37.588950 20090 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_0
I0211 01:20:37.588961 20090 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_1
I0211 01:20:37.588975 20090 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_2
I0211 01:20:37.589088 20090 net.cpp:245] Setting up ctx_output5_ctx_output5/relu_0_split
I0211 01:20:37.589102 20090 net.cpp:252] TEST Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 4 256 2 3 (6144)
I0211 01:20:37.589108 20090 net.cpp:252] TEST Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 4 256 2 3 (6144)
I0211 01:20:37.589118 20090 net.cpp:252] TEST Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 4 256 2 3 (6144)
I0211 01:20:37.589128 20090 layer_factory.hpp:136] Creating layer 'ctx_output6' of type 'Convolution'
I0211 01:20:37.589136 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.589164 20090 net.cpp:184] Created Layer ctx_output6 (61)
I0211 01:20:37.589175 20090 net.cpp:561] ctx_output6 <- pool9
I0211 01:20:37.589184 20090 net.cpp:530] ctx_output6 -> ctx_output6
I0211 01:20:37.594064 20090 net.cpp:245] Setting up ctx_output6
I0211 01:20:37.594087 20090 net.cpp:252] TEST Top shape for layer 61 'ctx_output6' 4 256 1 2 (2048)
I0211 01:20:37.594099 20090 layer_factory.hpp:136] Creating layer 'ctx_output6/relu' of type 'ReLU'
I0211 01:20:37.594107 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.594120 20090 net.cpp:184] Created Layer ctx_output6/relu (62)
I0211 01:20:37.594138 20090 net.cpp:561] ctx_output6/relu <- ctx_output6
I0211 01:20:37.594157 20090 net.cpp:513] ctx_output6/relu -> ctx_output6 (in-place)
I0211 01:20:37.594177 20090 net.cpp:245] Setting up ctx_output6/relu
I0211 01:20:37.594190 20090 net.cpp:252] TEST Top shape for layer 62 'ctx_output6/relu' 4 256 1 2 (2048)
I0211 01:20:37.594202 20090 layer_factory.hpp:136] Creating layer 'ctx_output6_ctx_output6/relu_0_split' of type 'Split'
I0211 01:20:37.594211 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.594221 20090 net.cpp:184] Created Layer ctx_output6_ctx_output6/relu_0_split (63)
I0211 01:20:37.594233 20090 net.cpp:561] ctx_output6_ctx_output6/relu_0_split <- ctx_output6
I0211 01:20:37.594243 20090 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_0
I0211 01:20:37.594254 20090 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_1
I0211 01:20:37.594281 20090 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_2
I0211 01:20:37.594401 20090 net.cpp:245] Setting up ctx_output6_ctx_output6/relu_0_split
I0211 01:20:37.594414 20090 net.cpp:252] TEST Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 4 256 1 2 (2048)
I0211 01:20:37.594424 20090 net.cpp:252] TEST Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 4 256 1 2 (2048)
I0211 01:20:37.594431 20090 net.cpp:252] TEST Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 4 256 1 2 (2048)
I0211 01:20:37.594442 20090 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc' of type 'Convolution'
I0211 01:20:37.594452 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.594485 20090 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc (64)
I0211 01:20:37.594494 20090 net.cpp:561] ctx_output1/relu_mbox_loc <- ctx_output1_ctx_output1/relu_0_split_0
I0211 01:20:37.594502 20090 net.cpp:530] ctx_output1/relu_mbox_loc -> ctx_output1/relu_mbox_loc
I0211 01:20:37.595166 20090 net.cpp:245] Setting up ctx_output1/relu_mbox_loc
I0211 01:20:37.595181 20090 net.cpp:252] TEST Top shape for layer 64 'ctx_output1/relu_mbox_loc' 4 16 46 90 (264960)
I0211 01:20:37.595193 20090 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_perm' of type 'Permute'
I0211 01:20:37.595204 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.595221 20090 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_perm (65)
I0211 01:20:37.595234 20090 net.cpp:561] ctx_output1/relu_mbox_loc_perm <- ctx_output1/relu_mbox_loc
I0211 01:20:37.595243 20090 net.cpp:530] ctx_output1/relu_mbox_loc_perm -> ctx_output1/relu_mbox_loc_perm
I0211 01:20:37.595440 20090 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_perm
I0211 01:20:37.595453 20090 net.cpp:252] TEST Top shape for layer 65 'ctx_output1/relu_mbox_loc_perm' 4 46 90 16 (264960)
I0211 01:20:37.595459 20090 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_flat' of type 'Flatten'
I0211 01:20:37.595468 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.595481 20090 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_flat (66)
I0211 01:20:37.595492 20090 net.cpp:561] ctx_output1/relu_mbox_loc_flat <- ctx_output1/relu_mbox_loc_perm
I0211 01:20:37.595502 20090 net.cpp:530] ctx_output1/relu_mbox_loc_flat -> ctx_output1/relu_mbox_loc_flat
I0211 01:20:37.595559 20090 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_flat
I0211 01:20:37.595571 20090 net.cpp:252] TEST Top shape for layer 66 'ctx_output1/relu_mbox_loc_flat' 4 66240 (264960)
I0211 01:20:37.595577 20090 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf' of type 'Convolution'
I0211 01:20:37.595584 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.595609 20090 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf (67)
I0211 01:20:37.595619 20090 net.cpp:561] ctx_output1/relu_mbox_conf <- ctx_output1_ctx_output1/relu_0_split_1
I0211 01:20:37.595628 20090 net.cpp:530] ctx_output1/relu_mbox_conf -> ctx_output1/relu_mbox_conf
I0211 01:20:37.596248 20090 net.cpp:245] Setting up ctx_output1/relu_mbox_conf
I0211 01:20:37.596264 20090 net.cpp:252] TEST Top shape for layer 67 'ctx_output1/relu_mbox_conf' 4 16 46 90 (264960)
I0211 01:20:37.596276 20090 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_perm' of type 'Permute'
I0211 01:20:37.596287 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.596303 20090 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_perm (68)
I0211 01:20:37.596315 20090 net.cpp:561] ctx_output1/relu_mbox_conf_perm <- ctx_output1/relu_mbox_conf
I0211 01:20:37.596324 20090 net.cpp:530] ctx_output1/relu_mbox_conf_perm -> ctx_output1/relu_mbox_conf_perm
I0211 01:20:37.596554 20090 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_perm
I0211 01:20:37.596576 20090 net.cpp:252] TEST Top shape for layer 68 'ctx_output1/relu_mbox_conf_perm' 4 46 90 16 (264960)
I0211 01:20:37.596583 20090 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_flat' of type 'Flatten'
I0211 01:20:37.596591 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.596606 20090 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_flat (69)
I0211 01:20:37.596616 20090 net.cpp:561] ctx_output1/relu_mbox_conf_flat <- ctx_output1/relu_mbox_conf_perm
I0211 01:20:37.596626 20090 net.cpp:530] ctx_output1/relu_mbox_conf_flat -> ctx_output1/relu_mbox_conf_flat
I0211 01:20:37.596684 20090 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_flat
I0211 01:20:37.596696 20090 net.cpp:252] TEST Top shape for layer 69 'ctx_output1/relu_mbox_conf_flat' 4 66240 (264960)
I0211 01:20:37.596702 20090 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_priorbox' of type 'PriorBox'
I0211 01:20:37.596710 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.596727 20090 net.cpp:184] Created Layer ctx_output1/relu_mbox_priorbox (70)
I0211 01:20:37.596740 20090 net.cpp:561] ctx_output1/relu_mbox_priorbox <- ctx_output1_ctx_output1/relu_0_split_2
I0211 01:20:37.596748 20090 net.cpp:561] ctx_output1/relu_mbox_priorbox <- data_data_0_split_1
I0211 01:20:37.596758 20090 net.cpp:530] ctx_output1/relu_mbox_priorbox -> ctx_output1/relu_mbox_priorbox
I0211 01:20:37.596827 20090 net.cpp:245] Setting up ctx_output1/relu_mbox_priorbox
I0211 01:20:37.596837 20090 net.cpp:252] TEST Top shape for layer 70 'ctx_output1/relu_mbox_priorbox' 1 2 66240 (132480)
I0211 01:20:37.596843 20090 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc' of type 'Convolution'
I0211 01:20:37.596851 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.596879 20090 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc (71)
I0211 01:20:37.596889 20090 net.cpp:561] ctx_output2/relu_mbox_loc <- ctx_output2_ctx_output2/relu_0_split_0
I0211 01:20:37.596896 20090 net.cpp:530] ctx_output2/relu_mbox_loc -> ctx_output2/relu_mbox_loc
I0211 01:20:37.597623 20090 net.cpp:245] Setting up ctx_output2/relu_mbox_loc
I0211 01:20:37.597640 20090 net.cpp:252] TEST Top shape for layer 71 'ctx_output2/relu_mbox_loc' 4 24 12 23 (26496)
I0211 01:20:37.597651 20090 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_perm' of type 'Permute'
I0211 01:20:37.597666 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.597684 20090 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_perm (72)
I0211 01:20:37.597697 20090 net.cpp:561] ctx_output2/relu_mbox_loc_perm <- ctx_output2/relu_mbox_loc
I0211 01:20:37.597707 20090 net.cpp:530] ctx_output2/relu_mbox_loc_perm -> ctx_output2/relu_mbox_loc_perm
I0211 01:20:37.597916 20090 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_perm
I0211 01:20:37.597930 20090 net.cpp:252] TEST Top shape for layer 72 'ctx_output2/relu_mbox_loc_perm' 4 12 23 24 (26496)
I0211 01:20:37.597937 20090 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_flat' of type 'Flatten'
I0211 01:20:37.597946 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.597961 20090 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_flat (73)
I0211 01:20:37.597973 20090 net.cpp:561] ctx_output2/relu_mbox_loc_flat <- ctx_output2/relu_mbox_loc_perm
I0211 01:20:37.597987 20090 net.cpp:530] ctx_output2/relu_mbox_loc_flat -> ctx_output2/relu_mbox_loc_flat
I0211 01:20:37.598045 20090 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_flat
I0211 01:20:37.598058 20090 net.cpp:252] TEST Top shape for layer 73 'ctx_output2/relu_mbox_loc_flat' 4 6624 (26496)
I0211 01:20:37.598065 20090 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf' of type 'Convolution'
I0211 01:20:37.598074 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.598111 20090 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf (74)
I0211 01:20:37.598124 20090 net.cpp:561] ctx_output2/relu_mbox_conf <- ctx_output2_ctx_output2/relu_0_split_1
I0211 01:20:37.598134 20090 net.cpp:530] ctx_output2/relu_mbox_conf -> ctx_output2/relu_mbox_conf
I0211 01:20:37.598841 20090 net.cpp:245] Setting up ctx_output2/relu_mbox_conf
I0211 01:20:37.598858 20090 net.cpp:252] TEST Top shape for layer 74 'ctx_output2/relu_mbox_conf' 4 24 12 23 (26496)
I0211 01:20:37.598871 20090 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_perm' of type 'Permute'
I0211 01:20:37.598883 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.598903 20090 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_perm (75)
I0211 01:20:37.598914 20090 net.cpp:561] ctx_output2/relu_mbox_conf_perm <- ctx_output2/relu_mbox_conf
I0211 01:20:37.598924 20090 net.cpp:530] ctx_output2/relu_mbox_conf_perm -> ctx_output2/relu_mbox_conf_perm
I0211 01:20:37.599136 20090 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_perm
I0211 01:20:37.599149 20090 net.cpp:252] TEST Top shape for layer 75 'ctx_output2/relu_mbox_conf_perm' 4 12 23 24 (26496)
I0211 01:20:37.599156 20090 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_flat' of type 'Flatten'
I0211 01:20:37.599164 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.599174 20090 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_flat (76)
I0211 01:20:37.599185 20090 net.cpp:561] ctx_output2/relu_mbox_conf_flat <- ctx_output2/relu_mbox_conf_perm
I0211 01:20:37.599195 20090 net.cpp:530] ctx_output2/relu_mbox_conf_flat -> ctx_output2/relu_mbox_conf_flat
I0211 01:20:37.599252 20090 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_flat
I0211 01:20:37.599264 20090 net.cpp:252] TEST Top shape for layer 76 'ctx_output2/relu_mbox_conf_flat' 4 6624 (26496)
I0211 01:20:37.599272 20090 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_priorbox' of type 'PriorBox'
I0211 01:20:37.599278 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.599294 20090 net.cpp:184] Created Layer ctx_output2/relu_mbox_priorbox (77)
I0211 01:20:37.599306 20090 net.cpp:561] ctx_output2/relu_mbox_priorbox <- ctx_output2_ctx_output2/relu_0_split_2
I0211 01:20:37.599316 20090 net.cpp:561] ctx_output2/relu_mbox_priorbox <- data_data_0_split_2
I0211 01:20:37.599329 20090 net.cpp:530] ctx_output2/relu_mbox_priorbox -> ctx_output2/relu_mbox_priorbox
I0211 01:20:37.599387 20090 net.cpp:245] Setting up ctx_output2/relu_mbox_priorbox
I0211 01:20:37.599411 20090 net.cpp:252] TEST Top shape for layer 77 'ctx_output2/relu_mbox_priorbox' 1 2 6624 (13248)
I0211 01:20:37.599421 20090 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc' of type 'Convolution'
I0211 01:20:37.599429 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.599458 20090 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc (78)
I0211 01:20:37.599469 20090 net.cpp:561] ctx_output3/relu_mbox_loc <- ctx_output3_ctx_output3/relu_0_split_0
I0211 01:20:37.599476 20090 net.cpp:530] ctx_output3/relu_mbox_loc -> ctx_output3/relu_mbox_loc
I0211 01:20:37.600167 20090 net.cpp:245] Setting up ctx_output3/relu_mbox_loc
I0211 01:20:37.600183 20090 net.cpp:252] TEST Top shape for layer 78 'ctx_output3/relu_mbox_loc' 4 24 6 12 (6912)
I0211 01:20:37.600193 20090 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_perm' of type 'Permute'
I0211 01:20:37.600201 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.600221 20090 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_perm (79)
I0211 01:20:37.600234 20090 net.cpp:561] ctx_output3/relu_mbox_loc_perm <- ctx_output3/relu_mbox_loc
I0211 01:20:37.600244 20090 net.cpp:530] ctx_output3/relu_mbox_loc_perm -> ctx_output3/relu_mbox_loc_perm
I0211 01:20:37.600455 20090 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_perm
I0211 01:20:37.600468 20090 net.cpp:252] TEST Top shape for layer 79 'ctx_output3/relu_mbox_loc_perm' 4 6 12 24 (6912)
I0211 01:20:37.600476 20090 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_flat' of type 'Flatten'
I0211 01:20:37.600482 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.600530 20090 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_flat (80)
I0211 01:20:37.600544 20090 net.cpp:561] ctx_output3/relu_mbox_loc_flat <- ctx_output3/relu_mbox_loc_perm
I0211 01:20:37.600555 20090 net.cpp:530] ctx_output3/relu_mbox_loc_flat -> ctx_output3/relu_mbox_loc_flat
I0211 01:20:37.600615 20090 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_flat
I0211 01:20:37.600626 20090 net.cpp:252] TEST Top shape for layer 80 'ctx_output3/relu_mbox_loc_flat' 4 1728 (6912)
I0211 01:20:37.600633 20090 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf' of type 'Convolution'
I0211 01:20:37.600641 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.600669 20090 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf (81)
I0211 01:20:37.600680 20090 net.cpp:561] ctx_output3/relu_mbox_conf <- ctx_output3_ctx_output3/relu_0_split_1
I0211 01:20:37.600688 20090 net.cpp:530] ctx_output3/relu_mbox_conf -> ctx_output3/relu_mbox_conf
I0211 01:20:37.601387 20090 net.cpp:245] Setting up ctx_output3/relu_mbox_conf
I0211 01:20:37.601402 20090 net.cpp:252] TEST Top shape for layer 81 'ctx_output3/relu_mbox_conf' 4 24 6 12 (6912)
I0211 01:20:37.601413 20090 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_perm' of type 'Permute'
I0211 01:20:37.601420 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.601439 20090 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_perm (82)
I0211 01:20:37.601451 20090 net.cpp:561] ctx_output3/relu_mbox_conf_perm <- ctx_output3/relu_mbox_conf
I0211 01:20:37.601461 20090 net.cpp:530] ctx_output3/relu_mbox_conf_perm -> ctx_output3/relu_mbox_conf_perm
I0211 01:20:37.601655 20090 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_perm
I0211 01:20:37.601667 20090 net.cpp:252] TEST Top shape for layer 82 'ctx_output3/relu_mbox_conf_perm' 4 6 12 24 (6912)
I0211 01:20:37.601675 20090 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_flat' of type 'Flatten'
I0211 01:20:37.601681 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.601696 20090 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_flat (83)
I0211 01:20:37.601707 20090 net.cpp:561] ctx_output3/relu_mbox_conf_flat <- ctx_output3/relu_mbox_conf_perm
I0211 01:20:37.601716 20090 net.cpp:530] ctx_output3/relu_mbox_conf_flat -> ctx_output3/relu_mbox_conf_flat
I0211 01:20:37.601770 20090 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_flat
I0211 01:20:37.601781 20090 net.cpp:252] TEST Top shape for layer 83 'ctx_output3/relu_mbox_conf_flat' 4 1728 (6912)
I0211 01:20:37.601788 20090 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_priorbox' of type 'PriorBox'
I0211 01:20:37.601795 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.601809 20090 net.cpp:184] Created Layer ctx_output3/relu_mbox_priorbox (84)
I0211 01:20:37.601820 20090 net.cpp:561] ctx_output3/relu_mbox_priorbox <- ctx_output3_ctx_output3/relu_0_split_2
I0211 01:20:37.601831 20090 net.cpp:561] ctx_output3/relu_mbox_priorbox <- data_data_0_split_3
I0211 01:20:37.601843 20090 net.cpp:530] ctx_output3/relu_mbox_priorbox -> ctx_output3/relu_mbox_priorbox
I0211 01:20:37.601898 20090 net.cpp:245] Setting up ctx_output3/relu_mbox_priorbox
I0211 01:20:37.601910 20090 net.cpp:252] TEST Top shape for layer 84 'ctx_output3/relu_mbox_priorbox' 1 2 1728 (3456)
I0211 01:20:37.601917 20090 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc' of type 'Convolution'
I0211 01:20:37.601939 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.601963 20090 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc (85)
I0211 01:20:37.601974 20090 net.cpp:561] ctx_output4/relu_mbox_loc <- ctx_output4_ctx_output4/relu_0_split_0
I0211 01:20:37.601981 20090 net.cpp:530] ctx_output4/relu_mbox_loc -> ctx_output4/relu_mbox_loc
I0211 01:20:37.602679 20090 net.cpp:245] Setting up ctx_output4/relu_mbox_loc
I0211 01:20:37.602694 20090 net.cpp:252] TEST Top shape for layer 85 'ctx_output4/relu_mbox_loc' 4 24 3 6 (1728)
I0211 01:20:37.602705 20090 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_perm' of type 'Permute'
I0211 01:20:37.602713 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.602735 20090 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_perm (86)
I0211 01:20:37.602746 20090 net.cpp:561] ctx_output4/relu_mbox_loc_perm <- ctx_output4/relu_mbox_loc
I0211 01:20:37.602756 20090 net.cpp:530] ctx_output4/relu_mbox_loc_perm -> ctx_output4/relu_mbox_loc_perm
I0211 01:20:37.602977 20090 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_perm
I0211 01:20:37.602989 20090 net.cpp:252] TEST Top shape for layer 86 'ctx_output4/relu_mbox_loc_perm' 4 3 6 24 (1728)
I0211 01:20:37.602995 20090 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_flat' of type 'Flatten'
I0211 01:20:37.603003 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.603016 20090 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_flat (87)
I0211 01:20:37.603027 20090 net.cpp:561] ctx_output4/relu_mbox_loc_flat <- ctx_output4/relu_mbox_loc_perm
I0211 01:20:37.603037 20090 net.cpp:530] ctx_output4/relu_mbox_loc_flat -> ctx_output4/relu_mbox_loc_flat
I0211 01:20:37.603148 20090 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_flat
I0211 01:20:37.603160 20090 net.cpp:252] TEST Top shape for layer 87 'ctx_output4/relu_mbox_loc_flat' 4 432 (1728)
I0211 01:20:37.603166 20090 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf' of type 'Convolution'
I0211 01:20:37.603174 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.603199 20090 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf (88)
I0211 01:20:37.603211 20090 net.cpp:561] ctx_output4/relu_mbox_conf <- ctx_output4_ctx_output4/relu_0_split_1
I0211 01:20:37.603219 20090 net.cpp:530] ctx_output4/relu_mbox_conf -> ctx_output4/relu_mbox_conf
I0211 01:20:37.604619 20090 net.cpp:245] Setting up ctx_output4/relu_mbox_conf
I0211 01:20:37.604643 20090 net.cpp:252] TEST Top shape for layer 88 'ctx_output4/relu_mbox_conf' 4 24 3 6 (1728)
I0211 01:20:37.604656 20090 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_perm' of type 'Permute'
I0211 01:20:37.604666 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.604686 20090 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_perm (89)
I0211 01:20:37.604701 20090 net.cpp:561] ctx_output4/relu_mbox_conf_perm <- ctx_output4/relu_mbox_conf
I0211 01:20:37.604712 20090 net.cpp:530] ctx_output4/relu_mbox_conf_perm -> ctx_output4/relu_mbox_conf_perm
I0211 01:20:37.604934 20090 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_perm
I0211 01:20:37.604948 20090 net.cpp:252] TEST Top shape for layer 89 'ctx_output4/relu_mbox_conf_perm' 4 3 6 24 (1728)
I0211 01:20:37.604955 20090 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_flat' of type 'Flatten'
I0211 01:20:37.604962 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.604975 20090 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_flat (90)
I0211 01:20:37.604987 20090 net.cpp:561] ctx_output4/relu_mbox_conf_flat <- ctx_output4/relu_mbox_conf_perm
I0211 01:20:37.604997 20090 net.cpp:530] ctx_output4/relu_mbox_conf_flat -> ctx_output4/relu_mbox_conf_flat
I0211 01:20:37.605067 20090 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_flat
I0211 01:20:37.605083 20090 net.cpp:252] TEST Top shape for layer 90 'ctx_output4/relu_mbox_conf_flat' 4 432 (1728)
I0211 01:20:37.605093 20090 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_priorbox' of type 'PriorBox'
I0211 01:20:37.605099 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.605110 20090 net.cpp:184] Created Layer ctx_output4/relu_mbox_priorbox (91)
I0211 01:20:37.605115 20090 net.cpp:561] ctx_output4/relu_mbox_priorbox <- ctx_output4_ctx_output4/relu_0_split_2
I0211 01:20:37.605123 20090 net.cpp:561] ctx_output4/relu_mbox_priorbox <- data_data_0_split_4
I0211 01:20:37.605130 20090 net.cpp:530] ctx_output4/relu_mbox_priorbox -> ctx_output4/relu_mbox_priorbox
I0211 01:20:37.605177 20090 net.cpp:245] Setting up ctx_output4/relu_mbox_priorbox
I0211 01:20:37.605190 20090 net.cpp:252] TEST Top shape for layer 91 'ctx_output4/relu_mbox_priorbox' 1 2 432 (864)
I0211 01:20:37.605195 20090 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc' of type 'Convolution'
I0211 01:20:37.605201 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.605221 20090 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc (92)
I0211 01:20:37.605228 20090 net.cpp:561] ctx_output5/relu_mbox_loc <- ctx_output5_ctx_output5/relu_0_split_0
I0211 01:20:37.605234 20090 net.cpp:530] ctx_output5/relu_mbox_loc -> ctx_output5/relu_mbox_loc
I0211 01:20:37.605881 20090 net.cpp:245] Setting up ctx_output5/relu_mbox_loc
I0211 01:20:37.605896 20090 net.cpp:252] TEST Top shape for layer 92 'ctx_output5/relu_mbox_loc' 4 16 2 3 (384)
I0211 01:20:37.605906 20090 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_perm' of type 'Permute'
I0211 01:20:37.605911 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.605921 20090 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_perm (93)
I0211 01:20:37.605927 20090 net.cpp:561] ctx_output5/relu_mbox_loc_perm <- ctx_output5/relu_mbox_loc
I0211 01:20:37.605934 20090 net.cpp:530] ctx_output5/relu_mbox_loc_perm -> ctx_output5/relu_mbox_loc_perm
I0211 01:20:37.606112 20090 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_perm
I0211 01:20:37.606122 20090 net.cpp:252] TEST Top shape for layer 93 'ctx_output5/relu_mbox_loc_perm' 4 2 3 16 (384)
I0211 01:20:37.606127 20090 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_flat' of type 'Flatten'
I0211 01:20:37.606132 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.606138 20090 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_flat (94)
I0211 01:20:37.606144 20090 net.cpp:561] ctx_output5/relu_mbox_loc_flat <- ctx_output5/relu_mbox_loc_perm
I0211 01:20:37.606150 20090 net.cpp:530] ctx_output5/relu_mbox_loc_flat -> ctx_output5/relu_mbox_loc_flat
I0211 01:20:37.606189 20090 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_flat
I0211 01:20:37.606199 20090 net.cpp:252] TEST Top shape for layer 94 'ctx_output5/relu_mbox_loc_flat' 4 96 (384)
I0211 01:20:37.606204 20090 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf' of type 'Convolution'
I0211 01:20:37.606209 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.606223 20090 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf (95)
I0211 01:20:37.606230 20090 net.cpp:561] ctx_output5/relu_mbox_conf <- ctx_output5_ctx_output5/relu_0_split_1
I0211 01:20:37.606237 20090 net.cpp:530] ctx_output5/relu_mbox_conf -> ctx_output5/relu_mbox_conf
I0211 01:20:37.606827 20090 net.cpp:245] Setting up ctx_output5/relu_mbox_conf
I0211 01:20:37.606842 20090 net.cpp:252] TEST Top shape for layer 95 'ctx_output5/relu_mbox_conf' 4 16 2 3 (384)
I0211 01:20:37.606850 20090 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_perm' of type 'Permute'
I0211 01:20:37.606866 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.606878 20090 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_perm (96)
I0211 01:20:37.606884 20090 net.cpp:561] ctx_output5/relu_mbox_conf_perm <- ctx_output5/relu_mbox_conf
I0211 01:20:37.606891 20090 net.cpp:530] ctx_output5/relu_mbox_conf_perm -> ctx_output5/relu_mbox_conf_perm
I0211 01:20:37.607069 20090 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_perm
I0211 01:20:37.607079 20090 net.cpp:252] TEST Top shape for layer 96 'ctx_output5/relu_mbox_conf_perm' 4 2 3 16 (384)
I0211 01:20:37.607084 20090 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_flat' of type 'Flatten'
I0211 01:20:37.607089 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.607095 20090 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_flat (97)
I0211 01:20:37.607100 20090 net.cpp:561] ctx_output5/relu_mbox_conf_flat <- ctx_output5/relu_mbox_conf_perm
I0211 01:20:37.607110 20090 net.cpp:530] ctx_output5/relu_mbox_conf_flat -> ctx_output5/relu_mbox_conf_flat
I0211 01:20:37.607148 20090 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_flat
I0211 01:20:37.607157 20090 net.cpp:252] TEST Top shape for layer 97 'ctx_output5/relu_mbox_conf_flat' 4 96 (384)
I0211 01:20:37.607163 20090 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_priorbox' of type 'PriorBox'
I0211 01:20:37.607168 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.607177 20090 net.cpp:184] Created Layer ctx_output5/relu_mbox_priorbox (98)
I0211 01:20:37.607182 20090 net.cpp:561] ctx_output5/relu_mbox_priorbox <- ctx_output5_ctx_output5/relu_0_split_2
I0211 01:20:37.607188 20090 net.cpp:561] ctx_output5/relu_mbox_priorbox <- data_data_0_split_5
I0211 01:20:37.607197 20090 net.cpp:530] ctx_output5/relu_mbox_priorbox -> ctx_output5/relu_mbox_priorbox
I0211 01:20:37.607236 20090 net.cpp:245] Setting up ctx_output5/relu_mbox_priorbox
I0211 01:20:37.607245 20090 net.cpp:252] TEST Top shape for layer 98 'ctx_output5/relu_mbox_priorbox' 1 2 96 (192)
I0211 01:20:37.607251 20090 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc' of type 'Convolution'
I0211 01:20:37.607256 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.607272 20090 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc (99)
I0211 01:20:37.607280 20090 net.cpp:561] ctx_output6/relu_mbox_loc <- ctx_output6_ctx_output6/relu_0_split_0
I0211 01:20:37.607286 20090 net.cpp:530] ctx_output6/relu_mbox_loc -> ctx_output6/relu_mbox_loc
I0211 01:20:37.607880 20090 net.cpp:245] Setting up ctx_output6/relu_mbox_loc
I0211 01:20:37.607895 20090 net.cpp:252] TEST Top shape for layer 99 'ctx_output6/relu_mbox_loc' 4 16 1 2 (128)
I0211 01:20:37.607904 20090 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_perm' of type 'Permute'
I0211 01:20:37.607910 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.607923 20090 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_perm (100)
I0211 01:20:37.607930 20090 net.cpp:561] ctx_output6/relu_mbox_loc_perm <- ctx_output6/relu_mbox_loc
I0211 01:20:37.607937 20090 net.cpp:530] ctx_output6/relu_mbox_loc_perm -> ctx_output6/relu_mbox_loc_perm
I0211 01:20:37.608114 20090 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_perm
I0211 01:20:37.608124 20090 net.cpp:252] TEST Top shape for layer 100 'ctx_output6/relu_mbox_loc_perm' 4 1 2 16 (128)
I0211 01:20:37.608129 20090 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_flat' of type 'Flatten'
I0211 01:20:37.608134 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.608141 20090 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_flat (101)
I0211 01:20:37.608147 20090 net.cpp:561] ctx_output6/relu_mbox_loc_flat <- ctx_output6/relu_mbox_loc_perm
I0211 01:20:37.608163 20090 net.cpp:530] ctx_output6/relu_mbox_loc_flat -> ctx_output6/relu_mbox_loc_flat
I0211 01:20:37.608204 20090 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_flat
I0211 01:20:37.608214 20090 net.cpp:252] TEST Top shape for layer 101 'ctx_output6/relu_mbox_loc_flat' 4 32 (128)
I0211 01:20:37.608219 20090 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf' of type 'Convolution'
I0211 01:20:37.608225 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.608242 20090 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf (102)
I0211 01:20:37.608248 20090 net.cpp:561] ctx_output6/relu_mbox_conf <- ctx_output6_ctx_output6/relu_0_split_1
I0211 01:20:37.608255 20090 net.cpp:530] ctx_output6/relu_mbox_conf -> ctx_output6/relu_mbox_conf
I0211 01:20:37.608883 20090 net.cpp:245] Setting up ctx_output6/relu_mbox_conf
I0211 01:20:37.608898 20090 net.cpp:252] TEST Top shape for layer 102 'ctx_output6/relu_mbox_conf' 4 16 1 2 (128)
I0211 01:20:37.608907 20090 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_perm' of type 'Permute'
I0211 01:20:37.608913 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.608923 20090 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_perm (103)
I0211 01:20:37.608932 20090 net.cpp:561] ctx_output6/relu_mbox_conf_perm <- ctx_output6/relu_mbox_conf
I0211 01:20:37.608937 20090 net.cpp:530] ctx_output6/relu_mbox_conf_perm -> ctx_output6/relu_mbox_conf_perm
I0211 01:20:37.609117 20090 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_perm
I0211 01:20:37.609127 20090 net.cpp:252] TEST Top shape for layer 103 'ctx_output6/relu_mbox_conf_perm' 4 1 2 16 (128)
I0211 01:20:37.609131 20090 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_flat' of type 'Flatten'
I0211 01:20:37.609136 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.609144 20090 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_flat (104)
I0211 01:20:37.609151 20090 net.cpp:561] ctx_output6/relu_mbox_conf_flat <- ctx_output6/relu_mbox_conf_perm
I0211 01:20:37.609158 20090 net.cpp:530] ctx_output6/relu_mbox_conf_flat -> ctx_output6/relu_mbox_conf_flat
I0211 01:20:37.609197 20090 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_flat
I0211 01:20:37.609206 20090 net.cpp:252] TEST Top shape for layer 104 'ctx_output6/relu_mbox_conf_flat' 4 32 (128)
I0211 01:20:37.609212 20090 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_priorbox' of type 'PriorBox'
I0211 01:20:37.609217 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.609225 20090 net.cpp:184] Created Layer ctx_output6/relu_mbox_priorbox (105)
I0211 01:20:37.609231 20090 net.cpp:561] ctx_output6/relu_mbox_priorbox <- ctx_output6_ctx_output6/relu_0_split_2
I0211 01:20:37.609237 20090 net.cpp:561] ctx_output6/relu_mbox_priorbox <- data_data_0_split_6
I0211 01:20:37.609243 20090 net.cpp:530] ctx_output6/relu_mbox_priorbox -> ctx_output6/relu_mbox_priorbox
I0211 01:20:37.609284 20090 net.cpp:245] Setting up ctx_output6/relu_mbox_priorbox
I0211 01:20:37.609293 20090 net.cpp:252] TEST Top shape for layer 105 'ctx_output6/relu_mbox_priorbox' 1 2 32 (64)
I0211 01:20:37.609298 20090 layer_factory.hpp:136] Creating layer 'mbox_loc' of type 'Concat'
I0211 01:20:37.609303 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.609311 20090 net.cpp:184] Created Layer mbox_loc (106)
I0211 01:20:37.609319 20090 net.cpp:561] mbox_loc <- ctx_output1/relu_mbox_loc_flat
I0211 01:20:37.609326 20090 net.cpp:561] mbox_loc <- ctx_output2/relu_mbox_loc_flat
I0211 01:20:37.609333 20090 net.cpp:561] mbox_loc <- ctx_output3/relu_mbox_loc_flat
I0211 01:20:37.609338 20090 net.cpp:561] mbox_loc <- ctx_output4/relu_mbox_loc_flat
I0211 01:20:37.609344 20090 net.cpp:561] mbox_loc <- ctx_output5/relu_mbox_loc_flat
I0211 01:20:37.609349 20090 net.cpp:561] mbox_loc <- ctx_output6/relu_mbox_loc_flat
I0211 01:20:37.609365 20090 net.cpp:530] mbox_loc -> mbox_loc
I0211 01:20:37.609411 20090 net.cpp:245] Setting up mbox_loc
I0211 01:20:37.609419 20090 net.cpp:252] TEST Top shape for layer 106 'mbox_loc' 4 75152 (300608)
I0211 01:20:37.609424 20090 layer_factory.hpp:136] Creating layer 'mbox_conf' of type 'Concat'
I0211 01:20:37.609429 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.609437 20090 net.cpp:184] Created Layer mbox_conf (107)
I0211 01:20:37.609444 20090 net.cpp:561] mbox_conf <- ctx_output1/relu_mbox_conf_flat
I0211 01:20:37.609450 20090 net.cpp:561] mbox_conf <- ctx_output2/relu_mbox_conf_flat
I0211 01:20:37.609457 20090 net.cpp:561] mbox_conf <- ctx_output3/relu_mbox_conf_flat
I0211 01:20:37.609464 20090 net.cpp:561] mbox_conf <- ctx_output4/relu_mbox_conf_flat
I0211 01:20:37.609469 20090 net.cpp:561] mbox_conf <- ctx_output5/relu_mbox_conf_flat
I0211 01:20:37.609474 20090 net.cpp:561] mbox_conf <- ctx_output6/relu_mbox_conf_flat
I0211 01:20:37.609479 20090 net.cpp:530] mbox_conf -> mbox_conf
I0211 01:20:37.609519 20090 net.cpp:245] Setting up mbox_conf
I0211 01:20:37.609529 20090 net.cpp:252] TEST Top shape for layer 107 'mbox_conf' 4 75152 (300608)
I0211 01:20:37.609534 20090 layer_factory.hpp:136] Creating layer 'mbox_priorbox' of type 'Concat'
I0211 01:20:37.609539 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.609547 20090 net.cpp:184] Created Layer mbox_priorbox (108)
I0211 01:20:37.609555 20090 net.cpp:561] mbox_priorbox <- ctx_output1/relu_mbox_priorbox
I0211 01:20:37.609560 20090 net.cpp:561] mbox_priorbox <- ctx_output2/relu_mbox_priorbox
I0211 01:20:37.609566 20090 net.cpp:561] mbox_priorbox <- ctx_output3/relu_mbox_priorbox
I0211 01:20:37.609571 20090 net.cpp:561] mbox_priorbox <- ctx_output4/relu_mbox_priorbox
I0211 01:20:37.609578 20090 net.cpp:561] mbox_priorbox <- ctx_output5/relu_mbox_priorbox
I0211 01:20:37.609583 20090 net.cpp:561] mbox_priorbox <- ctx_output6/relu_mbox_priorbox
I0211 01:20:37.609588 20090 net.cpp:530] mbox_priorbox -> mbox_priorbox
I0211 01:20:37.609627 20090 net.cpp:245] Setting up mbox_priorbox
I0211 01:20:37.609635 20090 net.cpp:252] TEST Top shape for layer 108 'mbox_priorbox' 1 2 75152 (150304)
I0211 01:20:37.609640 20090 layer_factory.hpp:136] Creating layer 'mbox_conf_reshape' of type 'Reshape'
I0211 01:20:37.609647 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.609655 20090 net.cpp:184] Created Layer mbox_conf_reshape (109)
I0211 01:20:37.609663 20090 net.cpp:561] mbox_conf_reshape <- mbox_conf
I0211 01:20:37.609669 20090 net.cpp:530] mbox_conf_reshape -> mbox_conf_reshape
I0211 01:20:37.609719 20090 net.cpp:245] Setting up mbox_conf_reshape
I0211 01:20:37.609730 20090 net.cpp:252] TEST Top shape for layer 109 'mbox_conf_reshape' 4 18788 4 (300608)
I0211 01:20:37.609735 20090 layer_factory.hpp:136] Creating layer 'mbox_conf_softmax' of type 'Softmax'
I0211 01:20:37.609741 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.609755 20090 net.cpp:184] Created Layer mbox_conf_softmax (110)
I0211 01:20:37.609762 20090 net.cpp:561] mbox_conf_softmax <- mbox_conf_reshape
I0211 01:20:37.609767 20090 net.cpp:530] mbox_conf_softmax -> mbox_conf_softmax
I0211 01:20:37.609874 20090 net.cpp:245] Setting up mbox_conf_softmax
I0211 01:20:37.609884 20090 net.cpp:252] TEST Top shape for layer 110 'mbox_conf_softmax' 4 18788 4 (300608)
I0211 01:20:37.609889 20090 layer_factory.hpp:136] Creating layer 'mbox_conf_flatten' of type 'Flatten'
I0211 01:20:37.609894 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.609900 20090 net.cpp:184] Created Layer mbox_conf_flatten (111)
I0211 01:20:37.609905 20090 net.cpp:561] mbox_conf_flatten <- mbox_conf_softmax
I0211 01:20:37.609910 20090 net.cpp:530] mbox_conf_flatten -> mbox_conf_flatten
I0211 01:20:37.609963 20090 net.cpp:245] Setting up mbox_conf_flatten
I0211 01:20:37.609973 20090 net.cpp:252] TEST Top shape for layer 111 'mbox_conf_flatten' 4 75152 (300608)
I0211 01:20:37.609978 20090 layer_factory.hpp:136] Creating layer 'detection_out' of type 'DetectionOutput'
I0211 01:20:37.609983 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.610005 20090 net.cpp:184] Created Layer detection_out (112)
I0211 01:20:37.610013 20090 net.cpp:561] detection_out <- mbox_loc
I0211 01:20:37.610018 20090 net.cpp:561] detection_out <- mbox_conf_flatten
I0211 01:20:37.610023 20090 net.cpp:561] detection_out <- mbox_priorbox
I0211 01:20:37.610028 20090 net.cpp:530] detection_out -> detection_out
I0211 01:20:37.611822 20090 net.cpp:245] Setting up detection_out
I0211 01:20:37.611836 20090 net.cpp:252] TEST Top shape for layer 112 'detection_out' 1 1 1 7 (7)
I0211 01:20:37.611842 20090 layer_factory.hpp:136] Creating layer 'detection_eval' of type 'DetectionEvaluate'
I0211 01:20:37.611847 20090 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0211 01:20:37.611858 20090 net.cpp:184] Created Layer detection_eval (113)
I0211 01:20:37.611866 20090 net.cpp:561] detection_eval <- detection_out
I0211 01:20:37.611872 20090 net.cpp:561] detection_eval <- label
I0211 01:20:37.611879 20090 net.cpp:530] detection_eval -> detection_eval
I0211 01:20:37.612958 20090 net.cpp:245] Setting up detection_eval
I0211 01:20:37.612972 20090 net.cpp:252] TEST Top shape for layer 113 'detection_eval' 1 1 4 5 (20)
I0211 01:20:37.612978 20090 net.cpp:325] detection_eval does not need backward computation.
I0211 01:20:37.612984 20090 net.cpp:325] detection_out does not need backward computation.
I0211 01:20:37.612989 20090 net.cpp:325] mbox_conf_flatten does not need backward computation.
I0211 01:20:37.612993 20090 net.cpp:325] mbox_conf_softmax does not need backward computation.
I0211 01:20:37.612998 20090 net.cpp:325] mbox_conf_reshape does not need backward computation.
I0211 01:20:37.613003 20090 net.cpp:325] mbox_priorbox does not need backward computation.
I0211 01:20:37.613008 20090 net.cpp:325] mbox_conf does not need backward computation.
I0211 01:20:37.613018 20090 net.cpp:325] mbox_loc does not need backward computation.
I0211 01:20:37.613023 20090 net.cpp:325] ctx_output6/relu_mbox_priorbox does not need backward computation.
I0211 01:20:37.613029 20090 net.cpp:325] ctx_output6/relu_mbox_conf_flat does not need backward computation.
I0211 01:20:37.613034 20090 net.cpp:325] ctx_output6/relu_mbox_conf_perm does not need backward computation.
I0211 01:20:37.613039 20090 net.cpp:325] ctx_output6/relu_mbox_conf does not need backward computation.
I0211 01:20:37.613044 20090 net.cpp:325] ctx_output6/relu_mbox_loc_flat does not need backward computation.
I0211 01:20:37.613047 20090 net.cpp:325] ctx_output6/relu_mbox_loc_perm does not need backward computation.
I0211 01:20:37.613052 20090 net.cpp:325] ctx_output6/relu_mbox_loc does not need backward computation.
I0211 01:20:37.613057 20090 net.cpp:325] ctx_output5/relu_mbox_priorbox does not need backward computation.
I0211 01:20:37.613062 20090 net.cpp:325] ctx_output5/relu_mbox_conf_flat does not need backward computation.
I0211 01:20:37.613066 20090 net.cpp:325] ctx_output5/relu_mbox_conf_perm does not need backward computation.
I0211 01:20:37.613071 20090 net.cpp:325] ctx_output5/relu_mbox_conf does not need backward computation.
I0211 01:20:37.613076 20090 net.cpp:325] ctx_output5/relu_mbox_loc_flat does not need backward computation.
I0211 01:20:37.613080 20090 net.cpp:325] ctx_output5/relu_mbox_loc_perm does not need backward computation.
I0211 01:20:37.613085 20090 net.cpp:325] ctx_output5/relu_mbox_loc does not need backward computation.
I0211 01:20:37.613090 20090 net.cpp:325] ctx_output4/relu_mbox_priorbox does not need backward computation.
I0211 01:20:37.613095 20090 net.cpp:325] ctx_output4/relu_mbox_conf_flat does not need backward computation.
I0211 01:20:37.613098 20090 net.cpp:325] ctx_output4/relu_mbox_conf_perm does not need backward computation.
I0211 01:20:37.613114 20090 net.cpp:325] ctx_output4/relu_mbox_conf does not need backward computation.
I0211 01:20:37.613121 20090 net.cpp:325] ctx_output4/relu_mbox_loc_flat does not need backward computation.
I0211 01:20:37.613126 20090 net.cpp:325] ctx_output4/relu_mbox_loc_perm does not need backward computation.
I0211 01:20:37.613131 20090 net.cpp:325] ctx_output4/relu_mbox_loc does not need backward computation.
I0211 01:20:37.613134 20090 net.cpp:325] ctx_output3/relu_mbox_priorbox does not need backward computation.
I0211 01:20:37.613139 20090 net.cpp:325] ctx_output3/relu_mbox_conf_flat does not need backward computation.
I0211 01:20:37.613144 20090 net.cpp:325] ctx_output3/relu_mbox_conf_perm does not need backward computation.
I0211 01:20:37.613152 20090 net.cpp:325] ctx_output3/relu_mbox_conf does not need backward computation.
I0211 01:20:37.613157 20090 net.cpp:325] ctx_output3/relu_mbox_loc_flat does not need backward computation.
I0211 01:20:37.613162 20090 net.cpp:325] ctx_output3/relu_mbox_loc_perm does not need backward computation.
I0211 01:20:37.613168 20090 net.cpp:325] ctx_output3/relu_mbox_loc does not need backward computation.
I0211 01:20:37.613173 20090 net.cpp:325] ctx_output2/relu_mbox_priorbox does not need backward computation.
I0211 01:20:37.613178 20090 net.cpp:325] ctx_output2/relu_mbox_conf_flat does not need backward computation.
I0211 01:20:37.613183 20090 net.cpp:325] ctx_output2/relu_mbox_conf_perm does not need backward computation.
I0211 01:20:37.613188 20090 net.cpp:325] ctx_output2/relu_mbox_conf does not need backward computation.
I0211 01:20:37.613194 20090 net.cpp:325] ctx_output2/relu_mbox_loc_flat does not need backward computation.
I0211 01:20:37.613200 20090 net.cpp:325] ctx_output2/relu_mbox_loc_perm does not need backward computation.
I0211 01:20:37.613204 20090 net.cpp:325] ctx_output2/relu_mbox_loc does not need backward computation.
I0211 01:20:37.613209 20090 net.cpp:325] ctx_output1/relu_mbox_priorbox does not need backward computation.
I0211 01:20:37.613215 20090 net.cpp:325] ctx_output1/relu_mbox_conf_flat does not need backward computation.
I0211 01:20:37.613219 20090 net.cpp:325] ctx_output1/relu_mbox_conf_perm does not need backward computation.
I0211 01:20:37.613224 20090 net.cpp:325] ctx_output1/relu_mbox_conf does not need backward computation.
I0211 01:20:37.613229 20090 net.cpp:325] ctx_output1/relu_mbox_loc_flat does not need backward computation.
I0211 01:20:37.613234 20090 net.cpp:325] ctx_output1/relu_mbox_loc_perm does not need backward computation.
I0211 01:20:37.613240 20090 net.cpp:325] ctx_output1/relu_mbox_loc does not need backward computation.
I0211 01:20:37.613245 20090 net.cpp:325] ctx_output6_ctx_output6/relu_0_split does not need backward computation.
I0211 01:20:37.613250 20090 net.cpp:325] ctx_output6/relu does not need backward computation.
I0211 01:20:37.613255 20090 net.cpp:325] ctx_output6 does not need backward computation.
I0211 01:20:37.613260 20090 net.cpp:325] ctx_output5_ctx_output5/relu_0_split does not need backward computation.
I0211 01:20:37.613265 20090 net.cpp:325] ctx_output5/relu does not need backward computation.
I0211 01:20:37.613270 20090 net.cpp:325] ctx_output5 does not need backward computation.
I0211 01:20:37.613278 20090 net.cpp:325] ctx_output4_ctx_output4/relu_0_split does not need backward computation.
I0211 01:20:37.613283 20090 net.cpp:325] ctx_output4/relu does not need backward computation.
I0211 01:20:37.613288 20090 net.cpp:325] ctx_output4 does not need backward computation.
I0211 01:20:37.613294 20090 net.cpp:325] ctx_output3_ctx_output3/relu_0_split does not need backward computation.
I0211 01:20:37.613299 20090 net.cpp:325] ctx_output3/relu does not need backward computation.
I0211 01:20:37.613303 20090 net.cpp:325] ctx_output3 does not need backward computation.
I0211 01:20:37.613309 20090 net.cpp:325] ctx_output2_ctx_output2/relu_0_split does not need backward computation.
I0211 01:20:37.613314 20090 net.cpp:325] ctx_output2/relu does not need backward computation.
I0211 01:20:37.613325 20090 net.cpp:325] ctx_output2 does not need backward computation.
I0211 01:20:37.613332 20090 net.cpp:325] ctx_output1_ctx_output1/relu_0_split does not need backward computation.
I0211 01:20:37.613337 20090 net.cpp:325] ctx_output1/relu does not need backward computation.
I0211 01:20:37.613344 20090 net.cpp:325] ctx_output1 does not need backward computation.
I0211 01:20:37.613349 20090 net.cpp:325] pool9 does not need backward computation.
I0211 01:20:37.613354 20090 net.cpp:325] pool8_pool8_0_split does not need backward computation.
I0211 01:20:37.613359 20090 net.cpp:325] pool8 does not need backward computation.
I0211 01:20:37.613364 20090 net.cpp:325] pool7_pool7_0_split does not need backward computation.
I0211 01:20:37.613373 20090 net.cpp:325] pool7 does not need backward computation.
I0211 01:20:37.613378 20090 net.cpp:325] pool6_pool6_0_split does not need backward computation.
I0211 01:20:37.613382 20090 net.cpp:325] pool6 does not need backward computation.
I0211 01:20:37.613387 20090 net.cpp:325] res5a_branch2b_res5a_branch2b/relu_0_split does not need backward computation.
I0211 01:20:37.613392 20090 net.cpp:325] res5a_branch2b/relu does not need backward computation.
I0211 01:20:37.613399 20090 net.cpp:325] res5a_branch2b/bn does not need backward computation.
I0211 01:20:37.613404 20090 net.cpp:325] res5a_branch2b does not need backward computation.
I0211 01:20:37.613409 20090 net.cpp:325] res5a_branch2a/relu does not need backward computation.
I0211 01:20:37.613414 20090 net.cpp:325] res5a_branch2a/bn does not need backward computation.
I0211 01:20:37.613418 20090 net.cpp:325] res5a_branch2a does not need backward computation.
I0211 01:20:37.613423 20090 net.cpp:325] pool4 does not need backward computation.
I0211 01:20:37.613428 20090 net.cpp:325] res4a_branch2b/relu does not need backward computation.
I0211 01:20:37.613433 20090 net.cpp:325] res4a_branch2b/bn does not need backward computation.
I0211 01:20:37.613437 20090 net.cpp:325] res4a_branch2b does not need backward computation.
I0211 01:20:37.613442 20090 net.cpp:325] res4a_branch2a/relu does not need backward computation.
I0211 01:20:37.613447 20090 net.cpp:325] res4a_branch2a/bn does not need backward computation.
I0211 01:20:37.613451 20090 net.cpp:325] res4a_branch2a does not need backward computation.
I0211 01:20:37.613456 20090 net.cpp:325] pool3 does not need backward computation.
I0211 01:20:37.613461 20090 net.cpp:325] res3a_branch2b_res3a_branch2b/relu_0_split does not need backward computation.
I0211 01:20:37.613466 20090 net.cpp:325] res3a_branch2b/relu does not need backward computation.
I0211 01:20:37.613471 20090 net.cpp:325] res3a_branch2b/bn does not need backward computation.
I0211 01:20:37.613476 20090 net.cpp:325] res3a_branch2b does not need backward computation.
I0211 01:20:37.613481 20090 net.cpp:325] res3a_branch2a/relu does not need backward computation.
I0211 01:20:37.613485 20090 net.cpp:325] res3a_branch2a/bn does not need backward computation.
I0211 01:20:37.613489 20090 net.cpp:325] res3a_branch2a does not need backward computation.
I0211 01:20:37.613494 20090 net.cpp:325] pool2 does not need backward computation.
I0211 01:20:37.613499 20090 net.cpp:325] res2a_branch2b/relu does not need backward computation.
I0211 01:20:37.613504 20090 net.cpp:325] res2a_branch2b/bn does not need backward computation.
I0211 01:20:37.613509 20090 net.cpp:325] res2a_branch2b does not need backward computation.
I0211 01:20:37.613513 20090 net.cpp:325] res2a_branch2a/relu does not need backward computation.
I0211 01:20:37.613518 20090 net.cpp:325] res2a_branch2a/bn does not need backward computation.
I0211 01:20:37.613523 20090 net.cpp:325] res2a_branch2a does not need backward computation.
I0211 01:20:37.613528 20090 net.cpp:325] pool1 does not need backward computation.
I0211 01:20:37.613533 20090 net.cpp:325] conv1b/relu does not need backward computation.
I0211 01:20:37.613538 20090 net.cpp:325] conv1b/bn does not need backward computation.
I0211 01:20:37.613541 20090 net.cpp:325] conv1b does not need backward computation.
I0211 01:20:37.613554 20090 net.cpp:325] conv1a/relu does not need backward computation.
I0211 01:20:37.613559 20090 net.cpp:325] conv1a/bn does not need backward computation.
I0211 01:20:37.613564 20090 net.cpp:325] conv1a does not need backward computation.
I0211 01:20:37.613569 20090 net.cpp:325] data/bias does not need backward computation.
I0211 01:20:37.613574 20090 net.cpp:325] data_data_0_split does not need backward computation.
I0211 01:20:37.613580 20090 net.cpp:325] data does not need backward computation.
I0211 01:20:37.613584 20090 net.cpp:367] This network produces output detection_eval
I0211 01:20:37.613690 20090 net.cpp:389] Top memory (TEST) required for data: 656271440 diff: 656271440
I0211 01:20:37.613698 20090 net.cpp:392] Bottom memory (TEST) required for data: 656271360 diff: 656271360
I0211 01:20:37.613703 20090 net.cpp:395] Shared (in-place) memory (TEST) by data: 281894912 diff: 281894912
I0211 01:20:37.613708 20090 net.cpp:398] Parameters memory (TEST) required for data: 12464288 diff: 12464288
I0211 01:20:37.613711 20090 net.cpp:401] Parameters shared memory (TEST) by data: 0 diff: 0
I0211 01:20:37.613716 20090 net.cpp:407] Network initialization done.
I0211 01:20:37.614055 20090 solver.cpp:57] Solver scaffolding done.
I0211 01:20:37.621143 20090 caffe.cpp:143] Finetuning from /user/a0875091/files/work/bitbucket_TI/caffe-jacinto-models/scripts/training/ti201712-720x368/JDetNet/20180208_22-53_ds_PSP_dsFac_32_fc_0_hdDS8_1_cnctHD_0_baseNW3hd_0_kerMbox_1_1stHdSameOpCh_1/initial/ti201712-720x368_ssdJacintoNetV2_iter_120000_53.11.caffemodel
I0211 01:20:37.739790 20090 net.cpp:1094] Copying source layer data Type:AnnotatedData #blobs=0
I0211 01:20:37.739823 20090 net.cpp:1094] Copying source layer data_data_0_split Type:Split #blobs=0
I0211 01:20:37.739835 20090 net.cpp:1094] Copying source layer data/bias Type:Bias #blobs=1
I0211 01:20:37.739894 20090 net.cpp:1094] Copying source layer conv1a Type:Convolution #blobs=2
I0211 01:20:37.739931 20090 net.cpp:1094] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0211 01:20:37.740350 20090 net.cpp:1094] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0211 01:20:37.740366 20090 net.cpp:1094] Copying source layer conv1b Type:Convolution #blobs=2
I0211 01:20:37.740401 20090 net.cpp:1094] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0211 01:20:37.740717 20090 net.cpp:1094] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0211 01:20:37.740734 20090 net.cpp:1094] Copying source layer pool1 Type:Pooling #blobs=0
I0211 01:20:37.740746 20090 net.cpp:1094] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0211 01:20:37.740787 20090 net.cpp:1094] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0211 01:20:37.741089 20090 net.cpp:1094] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0211 01:20:37.741106 20090 net.cpp:1094] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0211 01:20:37.741139 20090 net.cpp:1094] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0211 01:20:37.741420 20090 net.cpp:1094] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0211 01:20:37.741436 20090 net.cpp:1094] Copying source layer pool2 Type:Pooling #blobs=0
I0211 01:20:37.741446 20090 net.cpp:1094] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0211 01:20:37.741515 20090 net.cpp:1094] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0211 01:20:37.741761 20090 net.cpp:1094] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0211 01:20:37.741776 20090 net.cpp:1094] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0211 01:20:37.741829 20090 net.cpp:1094] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0211 01:20:37.742065 20090 net.cpp:1094] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0211 01:20:37.742081 20090 net.cpp:1094] Copying source layer res3a_branch2b_res3a_branch2b/relu_0_split Type:Split #blobs=0
I0211 01:20:37.742091 20090 net.cpp:1094] Copying source layer pool3 Type:Pooling #blobs=0
I0211 01:20:37.742123 20090 net.cpp:1094] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0211 01:20:37.742308 20090 net.cpp:1094] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0211 01:20:37.742549 20090 net.cpp:1094] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0211 01:20:37.742565 20090 net.cpp:1094] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0211 01:20:37.742671 20090 net.cpp:1094] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0211 01:20:37.742899 20090 net.cpp:1094] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0211 01:20:37.742914 20090 net.cpp:1094] Copying source layer pool4 Type:Pooling #blobs=0
I0211 01:20:37.742924 20090 net.cpp:1094] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0211 01:20:37.743660 20090 net.cpp:1094] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0211 01:20:37.744066 20090 net.cpp:1094] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0211 01:20:37.744087 20090 net.cpp:1094] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0211 01:20:37.744423 20090 net.cpp:1094] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0211 01:20:37.744673 20090 net.cpp:1094] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0211 01:20:37.744688 20090 net.cpp:1094] Copying source layer res5a_branch2b_res5a_branch2b/relu_0_split Type:Split #blobs=0
I0211 01:20:37.744694 20090 net.cpp:1094] Copying source layer pool6 Type:Pooling #blobs=0
I0211 01:20:37.744702 20090 net.cpp:1094] Copying source layer pool6_pool6_0_split Type:Split #blobs=0
I0211 01:20:37.744710 20090 net.cpp:1094] Copying source layer pool7 Type:Pooling #blobs=0
I0211 01:20:37.744719 20090 net.cpp:1094] Copying source layer pool7_pool7_0_split Type:Split #blobs=0
I0211 01:20:37.744724 20090 net.cpp:1094] Copying source layer pool8 Type:Pooling #blobs=0
I0211 01:20:37.744732 20090 net.cpp:1094] Copying source layer pool8_pool8_0_split Type:Split #blobs=0
I0211 01:20:37.744738 20090 net.cpp:1094] Copying source layer pool9 Type:Pooling #blobs=0
I0211 01:20:37.744746 20090 net.cpp:1094] Copying source layer ctx_output1 Type:Convolution #blobs=2
I0211 01:20:37.744789 20090 net.cpp:1094] Copying source layer ctx_output1/relu Type:ReLU #blobs=0
I0211 01:20:37.744799 20090 net.cpp:1094] Copying source layer ctx_output1_ctx_output1/relu_0_split Type:Split #blobs=0
I0211 01:20:37.744807 20090 net.cpp:1094] Copying source layer ctx_output2 Type:Convolution #blobs=2
I0211 01:20:37.744897 20090 net.cpp:1094] Copying source layer ctx_output2/relu Type:ReLU #blobs=0
I0211 01:20:37.744907 20090 net.cpp:1094] Copying source layer ctx_output2_ctx_output2/relu_0_split Type:Split #blobs=0
I0211 01:20:37.744913 20090 net.cpp:1094] Copying source layer ctx_output3 Type:Convolution #blobs=2
I0211 01:20:37.745002 20090 net.cpp:1094] Copying source layer ctx_output3/relu Type:ReLU #blobs=0
I0211 01:20:37.745012 20090 net.cpp:1094] Copying source layer ctx_output3_ctx_output3/relu_0_split Type:Split #blobs=0
I0211 01:20:37.745018 20090 net.cpp:1094] Copying source layer ctx_output4 Type:Convolution #blobs=2
I0211 01:20:37.745106 20090 net.cpp:1094] Copying source layer ctx_output4/relu Type:ReLU #blobs=0
I0211 01:20:37.745116 20090 net.cpp:1094] Copying source layer ctx_output4_ctx_output4/relu_0_split Type:Split #blobs=0
I0211 01:20:37.745124 20090 net.cpp:1094] Copying source layer ctx_output5 Type:Convolution #blobs=2
I0211 01:20:37.745213 20090 net.cpp:1094] Copying source layer ctx_output5/relu Type:ReLU #blobs=0
I0211 01:20:37.745223 20090 net.cpp:1094] Copying source layer ctx_output5_ctx_output5/relu_0_split Type:Split #blobs=0
I0211 01:20:37.745229 20090 net.cpp:1094] Copying source layer ctx_output6 Type:Convolution #blobs=2
I0211 01:20:37.745318 20090 net.cpp:1094] Copying source layer ctx_output6/relu Type:ReLU #blobs=0
I0211 01:20:37.745328 20090 net.cpp:1094] Copying source layer ctx_output6_ctx_output6/relu_0_split Type:Split #blobs=0
I0211 01:20:37.745353 20090 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc Type:Convolution #blobs=2
I0211 01:20:37.745379 20090 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc_perm Type:Permute #blobs=0
I0211 01:20:37.745388 20090 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc_flat Type:Flatten #blobs=0
I0211 01:20:37.745394 20090 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf Type:Convolution #blobs=2
I0211 01:20:37.745416 20090 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf_perm Type:Permute #blobs=0
I0211 01:20:37.745424 20090 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf_flat Type:Flatten #blobs=0
I0211 01:20:37.745431 20090 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_priorbox Type:PriorBox #blobs=0
I0211 01:20:37.745438 20090 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc Type:Convolution #blobs=2
I0211 01:20:37.745460 20090 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc_perm Type:Permute #blobs=0
I0211 01:20:37.745468 20090 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc_flat Type:Flatten #blobs=0
I0211 01:20:37.745476 20090 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf Type:Convolution #blobs=2
I0211 01:20:37.745497 20090 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf_perm Type:Permute #blobs=0
I0211 01:20:37.745507 20090 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf_flat Type:Flatten #blobs=0
I0211 01:20:37.745514 20090 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_priorbox Type:PriorBox #blobs=0
I0211 01:20:37.745522 20090 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc Type:Convolution #blobs=2
I0211 01:20:37.745545 20090 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc_perm Type:Permute #blobs=0
I0211 01:20:37.745553 20090 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc_flat Type:Flatten #blobs=0
I0211 01:20:37.745560 20090 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf Type:Convolution #blobs=2
I0211 01:20:37.745582 20090 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf_perm Type:Permute #blobs=0
I0211 01:20:37.745591 20090 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf_flat Type:Flatten #blobs=0
I0211 01:20:37.745599 20090 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_priorbox Type:PriorBox #blobs=0
I0211 01:20:37.745605 20090 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc Type:Convolution #blobs=2
I0211 01:20:37.745627 20090 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc_perm Type:Permute #blobs=0
I0211 01:20:37.745635 20090 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc_flat Type:Flatten #blobs=0
I0211 01:20:37.745642 20090 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf Type:Convolution #blobs=2
I0211 01:20:37.745664 20090 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf_perm Type:Permute #blobs=0
I0211 01:20:37.745672 20090 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf_flat Type:Flatten #blobs=0
I0211 01:20:37.745679 20090 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_priorbox Type:PriorBox #blobs=0
I0211 01:20:37.745687 20090 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc Type:Convolution #blobs=2
I0211 01:20:37.745707 20090 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc_perm Type:Permute #blobs=0
I0211 01:20:37.745715 20090 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc_flat Type:Flatten #blobs=0
I0211 01:20:37.745721 20090 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf Type:Convolution #blobs=2
I0211 01:20:37.745743 20090 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf_perm Type:Permute #blobs=0
I0211 01:20:37.745751 20090 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf_flat Type:Flatten #blobs=0
I0211 01:20:37.745759 20090 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_priorbox Type:PriorBox #blobs=0
I0211 01:20:37.745764 20090 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc Type:Convolution #blobs=2
I0211 01:20:37.745795 20090 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc_perm Type:Permute #blobs=0
I0211 01:20:37.745805 20090 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc_flat Type:Flatten #blobs=0
I0211 01:20:37.745811 20090 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf Type:Convolution #blobs=2
I0211 01:20:37.745832 20090 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf_perm Type:Permute #blobs=0
I0211 01:20:37.745841 20090 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf_flat Type:Flatten #blobs=0
I0211 01:20:37.745847 20090 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_priorbox Type:PriorBox #blobs=0
I0211 01:20:37.745856 20090 net.cpp:1094] Copying source layer mbox_loc Type:Concat #blobs=0
I0211 01:20:37.745862 20090 net.cpp:1094] Copying source layer mbox_conf Type:Concat #blobs=0
I0211 01:20:37.745869 20090 net.cpp:1094] Copying source layer mbox_priorbox Type:Concat #blobs=0
I0211 01:20:37.745878 20090 net.cpp:1094] Copying source layer mbox_loss Type:MultiBoxLoss #blobs=0
I0211 01:20:37.753304 20090 net.cpp:1094] Copying source layer data Type:AnnotatedData #blobs=0
I0211 01:20:37.753332 20090 net.cpp:1094] Copying source layer data_data_0_split Type:Split #blobs=0
I0211 01:20:37.753340 20090 net.cpp:1094] Copying source layer data/bias Type:Bias #blobs=1
I0211 01:20:37.753391 20090 net.cpp:1094] Copying source layer conv1a Type:Convolution #blobs=2
I0211 01:20:37.753414 20090 net.cpp:1094] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0211 01:20:37.753798 20090 net.cpp:1094] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0211 01:20:37.753811 20090 net.cpp:1094] Copying source layer conv1b Type:Convolution #blobs=2
I0211 01:20:37.753834 20090 net.cpp:1094] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0211 01:20:37.754096 20090 net.cpp:1094] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0211 01:20:37.754109 20090 net.cpp:1094] Copying source layer pool1 Type:Pooling #blobs=0
I0211 01:20:37.754115 20090 net.cpp:1094] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0211 01:20:37.754148 20090 net.cpp:1094] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0211 01:20:37.754413 20090 net.cpp:1094] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0211 01:20:37.754426 20090 net.cpp:1094] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0211 01:20:37.754451 20090 net.cpp:1094] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0211 01:20:37.754712 20090 net.cpp:1094] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0211 01:20:37.754725 20090 net.cpp:1094] Copying source layer pool2 Type:Pooling #blobs=0
I0211 01:20:37.754731 20090 net.cpp:1094] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0211 01:20:37.754792 20090 net.cpp:1094] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0211 01:20:37.755017 20090 net.cpp:1094] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0211 01:20:37.755029 20090 net.cpp:1094] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0211 01:20:37.755069 20090 net.cpp:1094] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0211 01:20:37.755271 20090 net.cpp:1094] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0211 01:20:37.755285 20090 net.cpp:1094] Copying source layer res3a_branch2b_res3a_branch2b/relu_0_split Type:Split #blobs=0
I0211 01:20:37.755290 20090 net.cpp:1094] Copying source layer pool3 Type:Pooling #blobs=0
I0211 01:20:37.755296 20090 net.cpp:1094] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0211 01:20:37.755470 20090 net.cpp:1094] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0211 01:20:37.755683 20090 net.cpp:1094] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0211 01:20:37.755697 20090 net.cpp:1094] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0211 01:20:37.755812 20090 net.cpp:1094] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0211 01:20:37.756022 20090 net.cpp:1094] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0211 01:20:37.756034 20090 net.cpp:1094] Copying source layer pool4 Type:Pooling #blobs=0
I0211 01:20:37.756042 20090 net.cpp:1094] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0211 01:20:37.756685 20090 net.cpp:1094] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0211 01:20:37.756911 20090 net.cpp:1094] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0211 01:20:37.756923 20090 net.cpp:1094] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0211 01:20:37.757294 20090 net.cpp:1094] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0211 01:20:37.757526 20090 net.cpp:1094] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0211 01:20:37.757539 20090 net.cpp:1094] Copying source layer res5a_branch2b_res5a_branch2b/relu_0_split Type:Split #blobs=0
I0211 01:20:37.757545 20090 net.cpp:1094] Copying source layer pool6 Type:Pooling #blobs=0
I0211 01:20:37.757551 20090 net.cpp:1094] Copying source layer pool6_pool6_0_split Type:Split #blobs=0
I0211 01:20:37.757557 20090 net.cpp:1094] Copying source layer pool7 Type:Pooling #blobs=0
I0211 01:20:37.757566 20090 net.cpp:1094] Copying source layer pool7_pool7_0_split Type:Split #blobs=0
I0211 01:20:37.757572 20090 net.cpp:1094] Copying source layer pool8 Type:Pooling #blobs=0
I0211 01:20:37.757580 20090 net.cpp:1094] Copying source layer pool8_pool8_0_split Type:Split #blobs=0
I0211 01:20:37.757586 20090 net.cpp:1094] Copying source layer pool9 Type:Pooling #blobs=0
I0211 01:20:37.757594 20090 net.cpp:1094] Copying source layer ctx_output1 Type:Convolution #blobs=2
I0211 01:20:37.757635 20090 net.cpp:1094] Copying source layer ctx_output1/relu Type:ReLU #blobs=0
I0211 01:20:37.757644 20090 net.cpp:1094] Copying source layer ctx_output1_ctx_output1/relu_0_split Type:Split #blobs=0
I0211 01:20:37.757652 20090 net.cpp:1094] Copying source layer ctx_output2 Type:Convolution #blobs=2
I0211 01:20:37.757746 20090 net.cpp:1094] Copying source layer ctx_output2/relu Type:ReLU #blobs=0
I0211 01:20:37.757757 20090 net.cpp:1094] Copying source layer ctx_output2_ctx_output2/relu_0_split Type:Split #blobs=0
I0211 01:20:37.757763 20090 net.cpp:1094] Copying source layer ctx_output3 Type:Convolution #blobs=2
I0211 01:20:37.757848 20090 net.cpp:1094] Copying source layer ctx_output3/relu Type:ReLU #blobs=0
I0211 01:20:37.757856 20090 net.cpp:1094] Copying source layer ctx_output3_ctx_output3/relu_0_split Type:Split #blobs=0
I0211 01:20:37.757863 20090 net.cpp:1094] Copying source layer ctx_output4 Type:Convolution #blobs=2
I0211 01:20:37.757949 20090 net.cpp:1094] Copying source layer ctx_output4/relu Type:ReLU #blobs=0
I0211 01:20:37.757958 20090 net.cpp:1094] Copying source layer ctx_output4_ctx_output4/relu_0_split Type:Split #blobs=0
I0211 01:20:37.757966 20090 net.cpp:1094] Copying source layer ctx_output5 Type:Convolution #blobs=2
I0211 01:20:37.758049 20090 net.cpp:1094] Copying source layer ctx_output5/relu Type:ReLU #blobs=0
I0211 01:20:37.758059 20090 net.cpp:1094] Copying source layer ctx_output5_ctx_output5/relu_0_split Type:Split #blobs=0
I0211 01:20:37.758064 20090 net.cpp:1094] Copying source layer ctx_output6 Type:Convolution #blobs=2
I0211 01:20:37.758152 20090 net.cpp:1094] Copying source layer ctx_output6/relu Type:ReLU #blobs=0
I0211 01:20:37.758160 20090 net.cpp:1094] Copying source layer ctx_output6_ctx_output6/relu_0_split Type:Split #blobs=0
I0211 01:20:37.758167 20090 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc Type:Convolution #blobs=2
I0211 01:20:37.758188 20090 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc_perm Type:Permute #blobs=0
I0211 01:20:37.758196 20090 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc_flat Type:Flatten #blobs=0
I0211 01:20:37.758203 20090 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf Type:Convolution #blobs=2
I0211 01:20:37.758239 20090 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf_perm Type:Permute #blobs=0
I0211 01:20:37.758249 20090 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf_flat Type:Flatten #blobs=0
I0211 01:20:37.758255 20090 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_priorbox Type:PriorBox #blobs=0
I0211 01:20:37.758261 20090 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc Type:Convolution #blobs=2
I0211 01:20:37.758281 20090 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc_perm Type:Permute #blobs=0
I0211 01:20:37.758291 20090 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc_flat Type:Flatten #blobs=0
I0211 01:20:37.758296 20090 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf Type:Convolution #blobs=2
I0211 01:20:37.758317 20090 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf_perm Type:Permute #blobs=0
I0211 01:20:37.758325 20090 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf_flat Type:Flatten #blobs=0
I0211 01:20:37.758332 20090 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_priorbox Type:PriorBox #blobs=0
I0211 01:20:37.758338 20090 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc Type:Convolution #blobs=2
I0211 01:20:37.758360 20090 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc_perm Type:Permute #blobs=0
I0211 01:20:37.758368 20090 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc_flat Type:Flatten #blobs=0
I0211 01:20:37.758375 20090 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf Type:Convolution #blobs=2
I0211 01:20:37.758395 20090 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf_perm Type:Permute #blobs=0
I0211 01:20:37.758404 20090 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf_flat Type:Flatten #blobs=0
I0211 01:20:37.758410 20090 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_priorbox Type:PriorBox #blobs=0
I0211 01:20:37.758417 20090 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc Type:Convolution #blobs=2
I0211 01:20:37.758440 20090 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc_perm Type:Permute #blobs=0
I0211 01:20:37.758448 20090 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc_flat Type:Flatten #blobs=0
I0211 01:20:37.758455 20090 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf Type:Convolution #blobs=2
I0211 01:20:37.758476 20090 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf_perm Type:Permute #blobs=0
I0211 01:20:37.758484 20090 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf_flat Type:Flatten #blobs=0
I0211 01:20:37.758491 20090 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_priorbox Type:PriorBox #blobs=0
I0211 01:20:37.758496 20090 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc Type:Convolution #blobs=2
I0211 01:20:37.758517 20090 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc_perm Type:Permute #blobs=0
I0211 01:20:37.758524 20090 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc_flat Type:Flatten #blobs=0
I0211 01:20:37.758532 20090 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf Type:Convolution #blobs=2
I0211 01:20:37.758550 20090 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf_perm Type:Permute #blobs=0
I0211 01:20:37.758559 20090 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf_flat Type:Flatten #blobs=0
I0211 01:20:37.758566 20090 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_priorbox Type:PriorBox #blobs=0
I0211 01:20:37.758572 20090 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc Type:Convolution #blobs=2
I0211 01:20:37.758594 20090 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc_perm Type:Permute #blobs=0
I0211 01:20:37.758602 20090 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc_flat Type:Flatten #blobs=0
I0211 01:20:37.758608 20090 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf Type:Convolution #blobs=2
I0211 01:20:37.758626 20090 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf_perm Type:Permute #blobs=0
I0211 01:20:37.758643 20090 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf_flat Type:Flatten #blobs=0
I0211 01:20:37.758651 20090 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_priorbox Type:PriorBox #blobs=0
I0211 01:20:37.758656 20090 net.cpp:1094] Copying source layer mbox_loc Type:Concat #blobs=0
I0211 01:20:37.758663 20090 net.cpp:1094] Copying source layer mbox_conf Type:Concat #blobs=0
I0211 01:20:37.758672 20090 net.cpp:1094] Copying source layer mbox_priorbox Type:Concat #blobs=0
I0211 01:20:37.758678 20090 net.cpp:1078] Ignoring source layer mbox_loss
I0211 01:20:37.758975 20090 parallel.cpp:106] [0 - 0] P2pSync adding callback
I0211 01:20:37.758987 20090 parallel.cpp:106] [1 - 1] P2pSync adding callback
I0211 01:20:37.758993 20090 parallel.cpp:59] Starting Optimization
I0211 01:20:37.759001 20090 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0211 01:20:37.759053 20090 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0211 01:20:37.785192 20163 device_alternate.hpp:116] NVML initialized on thread 140356066694912
I0211 01:20:37.877673 20163 common.cpp:585] NVML succeeded to set CPU affinity on device 0
I0211 01:20:37.877753 20164 device_alternate.hpp:116] NVML initialized on thread 140356058302208
I0211 01:20:37.878847 20164 common.cpp:585] NVML succeeded to set CPU affinity on device 1
I0211 01:20:37.893012 20164 solver.cpp:43] Solver data type: FLOAT
I0211 01:20:37.899204 20164 net.cpp:104] Using FLOAT as default forward math type
I0211 01:20:37.899230 20164 net.cpp:110] Using FLOAT as default backward math type
I0211 01:20:37.899430 20164 data_reader.cpp:58] Data Reader threads: 4, out queues: 16, depth: 8
I0211 01:20:37.899528 20164 internal_thread.cpp:19] Starting 4 internal thread(s) on device 1
I0211 01:20:37.903031 20177 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0211 01:20:37.904316 20178 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0211 01:20:37.905495 20176 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0211 01:20:37.906611 20175 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0211 01:20:37.924353 20164 annotated_data_layer.cpp:219] output data size: 8,3,368,720
I0211 01:20:37.924932 20164 annotated_data_layer.cpp:265] [1] Output data size: 8, 3, 368, 720
I0211 01:20:37.925012 20164 internal_thread.cpp:19] Starting 4 internal thread(s) on device 1
I0211 01:20:38.676057 20164 solver.cpp:177] Creating test net (#0) specified by test_net file: training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/test.prototxt
I0211 01:20:38.676910 20164 net.cpp:104] Using FLOAT as default forward math type
I0211 01:20:38.676923 20164 net.cpp:110] Using FLOAT as default backward math type
I0211 01:20:38.676966 20164 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 4
I0211 01:20:38.676977 20164 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0211 01:20:38.678303 20185 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_test_lmdb
I0211 01:20:38.687325 20164 annotated_data_layer.cpp:219] output data size: 4,3,368,720
I0211 01:20:38.687414 20164 annotated_data_layer.cpp:265] (1) Output data size: 4, 3, 368, 720
I0211 01:20:38.687474 20164 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0211 01:20:38.689391 20186 annotated_data_layer.cpp:111] (1) Parser threads: 1
I0211 01:20:38.689448 20186 annotated_data_layer.cpp:113] (1) Transformer threads: 1
I0211 01:20:38.821251 20164 solver.cpp:57] Solver scaffolding done.
I0211 01:20:38.860390 20163 parallel.cpp:161] [0 - 0] P2pSync adding callback
I0211 01:20:38.860390 20164 parallel.cpp:161] [1 - 1] P2pSync adding callback
I0211 01:20:39.078500 20164 solver.cpp:489] Solving ssdJacintoNetV2
I0211 01:20:39.078526 20164 solver.cpp:490] Learning Rate Policy: poly
I0211 01:20:39.078546 20163 solver.cpp:489] Solving ssdJacintoNetV2
I0211 01:20:39.078577 20163 solver.cpp:490] Learning Rate Policy: poly
I0211 01:20:39.088877 20164 net.cpp:1412] [1] Reserving 12451584 bytes of shared learnable space
I0211 01:20:39.091454 20163 net.cpp:1412] [0] Reserving 12451584 bytes of shared learnable space
I0211 01:20:39.095206 20164 solver.cpp:228] Starting Optimization on GPU 1
I0211 01:20:39.095211 20163 solver.cpp:228] Starting Optimization on GPU 0
I0211 01:20:39.095300 20163 solver.cpp:666] Iteration 0, Testing net (#0)
I0211 01:20:39.095343 20207 device_alternate.hpp:116] NVML initialized on thread 140355680847616
I0211 01:20:39.095419 20207 common.cpp:585] NVML succeeded to set CPU affinity on device 1
I0211 01:20:39.095448 20208 device_alternate.hpp:116] NVML initialized on thread 140355672454912
I0211 01:20:39.095571 20208 common.cpp:585] NVML succeeded to set CPU affinity on device 0
I0211 01:20:39.103854 20164 net.cpp:1012] Ignoring source layer mbox_loss
I0211 01:20:39.119439 20163 net.cpp:1012] Ignoring source layer mbox_loss
I0211 01:20:39.213364 20164 blocking_queue.cpp:40] Data layer prefetch queue empty
I0211 01:20:39.399013 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1a' with space 0G 3/1 1 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.404924 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'conv1a' with space 0G 3/1 1 	(avail 7.61G, req 0G)	t: 0
I0211 01:20:39.406137 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1b' with space 0G 32/4 6 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.412653 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'conv1b' with space 0G 32/4 6 	(avail 7.61G, req 0G)	t: 0
I0211 01:20:39.417513 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2a' with space 0G 32/1 1 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.421823 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2b' with space 0G 64/4 6 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.424180 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res2a_branch2a' with space 0G 32/1 1 	(avail 7.61G, req 0G)	t: 0
I0211 01:20:39.429198 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res2a_branch2b' with space 0G 64/4 6 	(avail 7.61G, req 0G)	t: 0
I0211 01:20:39.430306 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2a' with space 0G 64/1 6 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.433419 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2b' with space 0G 128/4 6 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.438282 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res3a_branch2a' with space 0G 64/1 6 	(avail 7.61G, req 0G)	t: 0
I0211 01:20:39.439553 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2a' with space 0G 128/1 1 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.442044 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res3a_branch2b' with space 0G 128/4 6 	(avail 7.61G, req 0G)	t: 0
I0211 01:20:39.442880 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2b' with space 0G 256/4 6 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.448772 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res4a_branch2a' with space 0G 128/1 1 	(avail 7.61G, req 0G)	t: 0
I0211 01:20:39.449199 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res5a_branch2a' with space 0G 256/1 1 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.452657 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res5a_branch2b' with space 0G 512/4 1 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.453106 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res4a_branch2b' with space 0G 256/4 6 	(avail 7.61G, req 0G)	t: 0
I0211 01:20:39.457326 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output1' with space 0G 128/1 1 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.458936 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res5a_branch2a' with space 0G 256/1 1 	(avail 7.61G, req 0G)	t: 0
I0211 01:20:39.460278 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output2' with space 0G 512/1 1 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.462157 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res5a_branch2b' with space 0G 512/4 1 	(avail 7.61G, req 0G)	t: 0
I0211 01:20:39.464299 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output3' with space 0G 512/1 0 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.466331 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output4' with space 0G 512/1 0 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.467438 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output1' with space 0G 128/1 1 	(avail 7.61G, req 0G)	t: 0
I0211 01:20:39.468751 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output5' with space 0G 512/1 0 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.470628 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output2' with space 0G 512/1 1 	(avail 7.61G, req 0G)	t: 0
I0211 01:20:39.471279 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output6' with space 0G 512/1 0 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.475152 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output3' with space 0G 512/1 1 	(avail 7.61G, req 0G)	t: 0
I0211 01:20:39.475492 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output1/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.478076 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output1/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.478695 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output4' with space 0G 512/1 0 	(avail 7.61G, req 0G)	t: 0
I0211 01:20:39.480682 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output2/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.481429 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output5' with space 0G 512/1 0 	(avail 7.61G, req 0G)	t: 0
I0211 01:20:39.482640 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output2/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.484066 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output6' with space 0G 512/1 0 	(avail 7.61G, req 0G)	t: 0
I0211 01:20:39.484946 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output3/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.487289 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output1/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.61G, req 0G)	t: 0
I0211 01:20:39.487690 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output3/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.489881 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output4/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.490777 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output1/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.61G, req 0G)	t: 0
I0211 01:20:39.492163 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output4/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.494269 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output2/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.61G, req 0G)	t: 0
I0211 01:20:39.494746 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output5/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.496603 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output2/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.61G, req 0G)	t: 0
I0211 01:20:39.497177 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output5/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.499177 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output3/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.61G, req 0G)	t: 0
I0211 01:20:39.499785 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output6/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.502005 20163 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output6/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.47G, req 0G)	t: 0
I0211 01:20:39.502840 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output3/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.61G, req 0G)	t: 0
I0211 01:20:39.504966 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output4/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.61G, req 0G)	t: 0
I0211 01:20:39.506887 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output4/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.61G, req 0G)	t: 0
I0211 01:20:39.508842 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output5/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.61G, req 0G)	t: 0
I0211 01:20:39.510797 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output5/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.61G, req 0G)	t: 0
I0211 01:20:39.513550 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output6/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.61G, req 0G)	t: 0
I0211 01:20:39.515925 20164 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output6/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.61G, req 0G)	t: 0
I0211 01:21:30.851186 20150 data_reader.cpp:305] Starting prefetch of epoch 1
I0211 01:21:31.088441 20163 solver.cpp:774] class AP 1: 0.347521
I0211 01:21:31.128643 20164 solver.cpp:774] class AP 1: 0.348168
I0211 01:21:31.153569 20163 solver.cpp:774] class AP 2: 0.60426
I0211 01:21:31.169951 20163 solver.cpp:774] class AP 3: 0.640928
I0211 01:21:31.169978 20163 solver.cpp:780] Test net output mAP #0: detection_eval = 0.530903
I0211 01:21:31.200529 20164 solver.cpp:774] class AP 2: 0.61156
I0211 01:21:31.216653 20164 solver.cpp:774] class AP 3: 0.643656
I0211 01:21:31.216670 20164 solver.cpp:780] Test net output mAP #0: detection_eval = 0.534461
I0211 01:21:31.217192 20163 solver.cpp:255] [MultiGPU] Initial Test completed
I0211 01:21:32.368567 20129 annotated_data_layer.cpp:111] [0] Parser threads: 4
I0211 01:21:32.368599 20129 annotated_data_layer.cpp:113] [0] Transformer threads: 4
I0211 01:21:32.681555 20181 annotated_data_layer.cpp:111] [1] Parser threads: 4
I0211 01:21:32.681583 20181 annotated_data_layer.cpp:113] [1] Transformer threads: 4
I0211 01:21:33.884395 20163 solver.cpp:319] Iteration 0 (2.66706 s), loss = 3.2143
I0211 01:21:33.884451 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.08868 (* 1 = 3.08868 loss)
I0211 01:21:33.884464 20163 sgd_solver.cpp:136] Iteration 0, lr = 0.001, m = 0.9
I0211 01:21:34.021641 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'conv1a' with space 4.24G 3/1 1 0 3 	(avail 1.05G, req 0G)	t: 0 2.77 2.18
I0211 01:21:34.144470 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'conv1b' with space 4.24G 32/4 6 4 3 	(avail 1G, req 0G)	t: 0 0.58 1.06
I0211 01:21:34.280655 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'conv1a' with space 4.24G 3/1 1 0 3 	(avail 1.23G, req 0G)	t: 0 2.76 2.19
I0211 01:21:34.382578 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 4.24G 32/1 1 4 3 	(avail 1G, req 0G)	t: 0 0.86 1.44
I0211 01:21:34.454952 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 4.24G 64/4 1 1 3 	(avail 1G, req 0G)	t: 0 0.28 0.55
I0211 01:21:34.569280 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'conv1b' with space 4.24G 32/4 6 4 3 	(avail 1.18G, req 0G)	t: 0 0.59 1.1
I0211 01:21:34.722091 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 4.24G 64/1 6 4 1 	(avail 0.97G, req 0G)	t: 0 0.48 0.82
I0211 01:21:34.795500 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 4.24G 128/4 6 4 0 	(avail 0.97G, req 0G)	t: 0 0.18 0.31
I0211 01:21:34.834646 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 4.24G 32/1 1 4 3 	(avail 1.15G, req 0G)	t: 0 0.82 1.48
I0211 01:21:34.901715 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 4.24G 128/1 6 4 5 	(avail 0.97G, req 0.04G)	t: 0 0.41 0.52
I0211 01:21:34.909626 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 4.24G 64/4 1 1 3 	(avail 1.15G, req 0G)	t: 0 0.28 0.53
I0211 01:21:34.997558 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 4.24G 256/4 6 4 3 	(avail 0.97G, req 0.04G)	t: 0 0.15 0.21
I0211 01:21:35.119773 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 4.24G 256/1 6 4 5 	(avail 0.97G, req 0.04G)	t: 0 0.57 0.52
I0211 01:21:35.157585 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 4.24G 512/4 6 4 5 	(avail 0.97G, req 0.04G)	t: 0 0.14 0.16
I0211 01:21:35.159461 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 4.24G 64/1 6 4 3 	(avail 1.15G, req 0G)	t: 0 0.48 0.82
I0211 01:21:35.225452 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output1' with space 4.24G 128/1 1 1 1 	(avail 0.94G, req 0.04G)	t: 0 0.4 0.78
I0211 01:21:35.254551 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 4.24G 128/4 6 4 0 	(avail 1.15G, req 0G)	t: 0 0.19 0.27
I0211 01:21:35.310432 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output2' with space 4.24G 512/1 1 1 1 	(avail 0.94G, req 0.04G)	t: 0 0.14 0.19
I0211 01:21:35.349011 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output3' with space 4.24G 512/1 1 1 3 	(avail 0.89G, req 0.04G)	t: 0 0.06 0.09
I0211 01:21:35.362481 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 4.24G 128/1 6 4 5 	(avail 1.15G, req 0.04G)	t: 0 0.41 0.51
I0211 01:21:35.381868 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output4' with space 4.24G 512/1 0 0 1 	(avail 0.89G, req 0.04G)	t: 0 0.06 0.06
I0211 01:21:35.392107 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 4.24G 256/4 6 4 3 	(avail 1.15G, req 0.04G)	t: 0 0.11 0.18
I0211 01:21:35.435457 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output5' with space 4.24G 512/1 0 0 3 	(avail 0.89G, req 0.04G)	t: 0 0.06 0.06
I0211 01:21:35.466935 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output6' with space 4.24G 512/1 0 0 3 	(avail 0.89G, req 0.04G)	t: 0 0.07 0.05
I0211 01:21:35.522840 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 4.24G 256/1 6 4 5 	(avail 1.12G, req 0.04G)	t: 0 0.54 0.5
I0211 01:21:35.551738 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 4.24G 512/4 6 4 5 	(avail 1.12G, req 0.04G)	t: 0 0.1 0.12
I0211 01:21:35.578948 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_loc' with space 4.24G 256/1 1 1 3 	(avail 0.89G, req 0.04G)	t: 0 0.23 0.78
I0211 01:21:35.603124 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output1' with space 4.24G 128/1 1 1 3 	(avail 1.12G, req 0.04G)	t: 0 0.45 0.73
I0211 01:21:35.678007 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output2' with space 4.24G 512/1 1 1 1 	(avail 1.07G, req 0.04G)	t: 0 0.16 0.19
I0211 01:21:35.686681 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_conf' with space 4.24G 256/1 1 1 3 	(avail 0.89G, req 0.04G)	t: 0 0.23 0.8
I0211 01:21:35.731019 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output3' with space 4.24G 512/1 1 1 3 	(avail 1.04G, req 0.04G)	t: 0 0.06 0.08
I0211 01:21:35.748646 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_loc' with space 4.24G 256/1 1 1 3 	(avail 0.89G, req 0.04G)	t: 0 0.06 0.11
I0211 01:21:35.765213 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_conf' with space 4.24G 256/1 1 1 3 	(avail 0.89G, req 0.04G)	t: 0 0.05 0.08
I0211 01:21:35.779227 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output4' with space 4.24G 512/1 0 0 1 	(avail 1.04G, req 0.04G)	t: 0 0.05 0.06
I0211 01:21:35.800956 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_loc' with space 4.24G 256/1 1 0 0 	(avail 0.89G, req 0.04G)	t: 0 0.04 0.04
I0211 01:21:35.818084 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_conf' with space 4.24G 256/1 1 0 0 	(avail 0.89G, req 0.04G)	t: 0 0.04 0.04
I0211 01:21:35.826452 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output5' with space 4.24G 512/1 0 0 3 	(avail 1.04G, req 0.04G)	t: 0 0.06 0.07
I0211 01:21:35.843478 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 0.89G, req 0.04G)	t: 0 0.04 0.04
I0211 01:21:35.855808 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_conf' with space 4.24G 256/1 0 0 0 	(avail 0.89G, req 0.04G)	t: 0 0.04 0.04
I0211 01:21:35.864986 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output6' with space 4.24G 512/1 0 0 3 	(avail 1.04G, req 0.04G)	t: 0 0.05 0.05
I0211 01:21:35.882545 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 0.89G, req 0.04G)	t: 0 0.04 0.03
I0211 01:21:35.904007 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_conf' with space 4.24G 256/1 1 0 0 	(avail 0.89G, req 0.04G)	t: 0 0.04 0.03
I0211 01:21:35.927373 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output6/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 0.89G, req 0.04G)	t: 0 0.04 0.03
I0211 01:21:35.944267 20163 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output6/relu_mbox_conf' with space 4.24G 256/1 0 0 0 	(avail 0.89G, req 0.04G)	t: 0 0.04 0.03
I0211 01:21:35.985059 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_loc' with space 4.24G 256/1 1 1 3 	(avail 1.04G, req 0.04G)	t: 0 0.25 0.81
I0211 01:21:36.127048 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_conf' with space 4.24G 256/1 1 1 3 	(avail 1.04G, req 0.04G)	t: 0 0.22 0.79
I0211 01:21:36.169057 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_loc' with space 4.24G 256/1 1 1 3 	(avail 1.04G, req 0.04G)	t: 0 0.04 0.07
I0211 01:21:36.229465 20163 cudnn_conv_layer.cpp:474] [0] Layer 'conv1a' reallocating workspace 4.24G to 0.07G
I0211 01:21:36.238426 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_conf' with space 4.24G 256/1 1 1 3 	(avail 1.04G, req 0.04G)	t: 0 0.05 0.07
I0211 01:21:36.263303 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_loc' with space 4.24G 256/1 1 1 0 	(avail 1.04G, req 0.04G)	t: 0 0.05 0.06
I0211 01:21:36.286633 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_conf' with space 4.24G 256/1 1 1 0 	(avail 1.04G, req 0.04G)	t: 0 0.05 0.05
I0211 01:21:36.310056 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_loc' with space 4.24G 256/1 1 0 0 	(avail 1.04G, req 0.04G)	t: 0 0.05 0.05
I0211 01:21:36.333024 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_conf' with space 4.24G 256/1 1 0 0 	(avail 1.04G, req 0.04G)	t: 0 0.05 0.06
I0211 01:21:36.355880 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_loc' with space 4.24G 256/1 1 0 0 	(avail 1.04G, req 0.04G)	t: 0 0.05 0.04
I0211 01:21:36.378805 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_conf' with space 4.24G 256/1 1 0 0 	(avail 1.04G, req 0.04G)	t: 0 0.04 0.02
I0211 01:21:36.461026 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output6/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 1.04G, req 0.04G)	t: 0 0.06 0.05
I0211 01:21:36.500759 20164 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output6/relu_mbox_conf' with space 4.24G 256/1 0 0 0 	(avail 1.04G, req 0.04G)	t: 0 0.07 0.06
I0211 01:21:36.665813 20164 cudnn_conv_layer.cpp:474] [1] Layer 'conv1a' reallocating workspace 4.24G to 0.07G
I0211 01:21:36.887379 20163 solver.cpp:319] Iteration 1 (3.00287 s), loss = 3.46596
I0211 01:21:36.887425 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.48511 (* 1 = 3.48511 loss)
I0211 01:21:37.500771 20163 solver.cpp:319] Iteration 2 (0.613356 s), loss = 3.4061
I0211 01:21:37.500823 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.84887 (* 1 = 2.84887 loss)
I0211 01:22:38.416817 20163 solver.cpp:314] Iteration 100 (1.60883 iter/s, 60.9139s/98 iter), loss = 3.51584
I0211 01:22:38.416980 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.38122 (* 1 = 3.38122 loss)
I0211 01:22:38.416996 20163 sgd_solver.cpp:136] Iteration 100, lr = 0.000996671, m = 0.9
I0211 01:23:40.208745 20163 solver.cpp:314] Iteration 200 (1.61839 iter/s, 61.7897s/100 iter), loss = 3.24033
I0211 01:23:40.208881 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.30009 (* 1 = 3.30009 loss)
I0211 01:23:40.208902 20163 sgd_solver.cpp:136] Iteration 200, lr = 0.00099335, m = 0.9
I0211 01:24:41.412552 20163 solver.cpp:314] Iteration 300 (1.63394 iter/s, 61.2016s/100 iter), loss = 3.42535
I0211 01:24:41.416556 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.09207 (* 1 = 3.09207 loss)
I0211 01:24:41.416586 20163 sgd_solver.cpp:136] Iteration 300, lr = 0.000990037, m = 0.9
I0211 01:25:42.176348 20163 solver.cpp:314] Iteration 400 (1.64578 iter/s, 60.7616s/100 iter), loss = 3.36736
I0211 01:25:42.176453 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.50231 (* 1 = 3.50231 loss)
I0211 01:25:42.176470 20163 sgd_solver.cpp:136] Iteration 400, lr = 0.000986733, m = 0.9
I0211 01:26:45.205066 20163 solver.cpp:314] Iteration 500 (1.58664 iter/s, 63.0264s/100 iter), loss = 3.41475
I0211 01:26:45.205229 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.98477 (* 1 = 2.98477 loss)
I0211 01:26:45.205271 20163 sgd_solver.cpp:136] Iteration 500, lr = 0.000983437, m = 0.9
I0211 01:27:47.162135 20163 solver.cpp:314] Iteration 600 (1.61408 iter/s, 61.9548s/100 iter), loss = 3.31594
I0211 01:27:47.172134 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.80086 (* 1 = 3.80086 loss)
I0211 01:27:47.172166 20163 sgd_solver.cpp:136] Iteration 600, lr = 0.00098015, m = 0.9
I0211 01:28:48.024101 20163 solver.cpp:314] Iteration 700 (1.64312 iter/s, 60.8597s/100 iter), loss = 3.35289
I0211 01:28:48.024224 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.52771 (* 1 = 2.52771 loss)
I0211 01:28:48.024238 20163 sgd_solver.cpp:136] Iteration 700, lr = 0.00097687, m = 0.9
I0211 01:29:49.260174 20163 solver.cpp:314] Iteration 800 (1.63308 iter/s, 61.2338s/100 iter), loss = 3.22904
I0211 01:29:49.260298 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.75542 (* 1 = 3.75542 loss)
I0211 01:29:49.260313 20163 sgd_solver.cpp:136] Iteration 800, lr = 0.000973599, m = 0.9
I0211 01:30:51.158011 20163 solver.cpp:314] Iteration 900 (1.61562 iter/s, 61.8956s/100 iter), loss = 3.20985
I0211 01:30:51.158123 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.93564 (* 1 = 2.93564 loss)
I0211 01:30:51.158138 20163 sgd_solver.cpp:136] Iteration 900, lr = 0.000970336, m = 0.9
I0211 01:31:51.722514 20163 solver.cpp:314] Iteration 1000 (1.65119 iter/s, 60.5623s/100 iter), loss = 3.51081
I0211 01:31:51.722646 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.73709 (* 1 = 3.73709 loss)
I0211 01:31:51.722667 20163 sgd_solver.cpp:136] Iteration 1000, lr = 0.000967081, m = 0.9
I0211 01:32:52.602974 20163 solver.cpp:314] Iteration 1100 (1.64262 iter/s, 60.8782s/100 iter), loss = 3.15098
I0211 01:32:52.603112 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.68287 (* 1 = 3.68287 loss)
I0211 01:32:52.603129 20163 sgd_solver.cpp:136] Iteration 1100, lr = 0.000963835, m = 0.9
I0211 01:33:53.941208 20163 solver.cpp:314] Iteration 1200 (1.63036 iter/s, 61.336s/100 iter), loss = 3.27759
I0211 01:33:53.941372 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.20549 (* 1 = 3.20549 loss)
I0211 01:33:53.941390 20163 sgd_solver.cpp:136] Iteration 1200, lr = 0.000960596, m = 0.9
I0211 01:34:54.247701 20163 solver.cpp:314] Iteration 1300 (1.65826 iter/s, 60.3043s/100 iter), loss = 3.15551
I0211 01:34:54.247826 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.55835 (* 1 = 3.55835 loss)
I0211 01:34:54.247843 20163 sgd_solver.cpp:136] Iteration 1300, lr = 0.000957366, m = 0.9
I0211 01:35:57.028564 20163 solver.cpp:314] Iteration 1400 (1.5929 iter/s, 62.7786s/100 iter), loss = 3.30107
I0211 01:35:57.028693 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.47426 (* 1 = 2.47426 loss)
I0211 01:35:57.028709 20163 sgd_solver.cpp:136] Iteration 1400, lr = 0.000954144, m = 0.9
I0211 01:36:57.415594 20163 solver.cpp:314] Iteration 1500 (1.65605 iter/s, 60.3848s/100 iter), loss = 3.40721
I0211 01:36:57.415733 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.80943 (* 1 = 2.80943 loss)
I0211 01:36:57.415784 20163 sgd_solver.cpp:136] Iteration 1500, lr = 0.00095093, m = 0.9
I0211 01:37:58.418216 20163 solver.cpp:314] Iteration 1600 (1.63933 iter/s, 61.0004s/100 iter), loss = 3.53313
I0211 01:37:58.418341 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.83091 (* 1 = 2.83091 loss)
I0211 01:37:58.418365 20163 sgd_solver.cpp:136] Iteration 1600, lr = 0.000947724, m = 0.9
I0211 01:38:59.601936 20163 solver.cpp:314] Iteration 1700 (1.63448 iter/s, 61.1815s/100 iter), loss = 3.1779
I0211 01:38:59.602053 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.68893 (* 1 = 3.68893 loss)
I0211 01:38:59.602069 20163 sgd_solver.cpp:136] Iteration 1700, lr = 0.000944526, m = 0.9
I0211 01:40:01.049327 20163 solver.cpp:314] Iteration 1800 (1.62747 iter/s, 61.4451s/100 iter), loss = 3.25971
I0211 01:40:01.049458 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.81706 (* 1 = 2.81706 loss)
I0211 01:40:01.049476 20163 sgd_solver.cpp:136] Iteration 1800, lr = 0.000941337, m = 0.9
I0211 01:41:02.056865 20163 solver.cpp:314] Iteration 1900 (1.6392 iter/s, 61.0053s/100 iter), loss = 3.07055
I0211 01:41:02.056995 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.80388 (* 1 = 2.80388 loss)
I0211 01:41:02.057011 20163 sgd_solver.cpp:136] Iteration 1900, lr = 0.000938155, m = 0.9
I0211 01:42:02.751114 20163 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_2000.caffemodel
I0211 01:42:02.820214 20163 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_2000.solverstate
I0211 01:42:02.832413 20163 solver.cpp:666] Iteration 2000, Testing net (#0)
I0211 01:42:54.029103 20164 solver.cpp:774] class AP 1: 0.383377
I0211 01:42:54.078260 20164 solver.cpp:774] class AP 2: 0.629383
I0211 01:42:54.095650 20164 solver.cpp:774] class AP 3: 0.60958
I0211 01:42:54.095691 20164 solver.cpp:780] Test net output mAP #0: detection_eval = 0.54078
I0211 01:42:54.308744 20163 solver.cpp:774] class AP 1: 0.379915
I0211 01:42:54.365767 20163 solver.cpp:774] class AP 2: 0.630201
I0211 01:42:54.382840 20163 solver.cpp:774] class AP 3: 0.602039
I0211 01:42:54.382856 20163 solver.cpp:780] Test net output mAP #0: detection_eval = 0.537385
I0211 01:42:54.382912 20163 solver.cpp:265] [MultiGPU] Tests completed in 51.5486s
I0211 01:42:54.809037 20163 solver.cpp:314] Iteration 2000 (0.886933 iter/s, 112.748s/100 iter), loss = 3.27405
I0211 01:42:54.809154 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.50371 (* 1 = 3.50371 loss)
I0211 01:42:54.809202 20163 sgd_solver.cpp:136] Iteration 2000, lr = 0.000934982, m = 0.9
I0211 01:43:55.701131 20163 solver.cpp:314] Iteration 2100 (1.64231 iter/s, 60.8899s/100 iter), loss = 3.45951
I0211 01:43:55.701290 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.45346 (* 1 = 2.45346 loss)
I0211 01:43:55.701306 20163 sgd_solver.cpp:136] Iteration 2100, lr = 0.000931816, m = 0.9
I0211 01:44:56.762518 20163 solver.cpp:314] Iteration 2200 (1.63776 iter/s, 61.0592s/100 iter), loss = 3.42881
I0211 01:44:56.762656 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.93465 (* 1 = 2.93465 loss)
I0211 01:44:56.762675 20163 sgd_solver.cpp:136] Iteration 2200, lr = 0.000928659, m = 0.9
I0211 01:45:59.136018 20163 solver.cpp:314] Iteration 2300 (1.6033 iter/s, 62.3712s/100 iter), loss = 3.29387
I0211 01:45:59.136131 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.63308 (* 1 = 2.63308 loss)
I0211 01:45:59.136145 20163 sgd_solver.cpp:136] Iteration 2300, lr = 0.00092551, m = 0.9
I0211 01:47:00.038779 20163 solver.cpp:314] Iteration 2400 (1.64202 iter/s, 60.9005s/100 iter), loss = 2.95241
I0211 01:47:00.038964 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.72723 (* 1 = 2.72723 loss)
I0211 01:47:00.039008 20163 sgd_solver.cpp:136] Iteration 2400, lr = 0.000922368, m = 0.9
I0211 01:48:00.580549 20163 solver.cpp:314] Iteration 2500 (1.65181 iter/s, 60.5396s/100 iter), loss = 3.12354
I0211 01:48:00.580665 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.94458 (* 1 = 2.94458 loss)
I0211 01:48:00.580684 20163 sgd_solver.cpp:136] Iteration 2500, lr = 0.000919235, m = 0.9
I0211 01:49:01.754128 20163 solver.cpp:314] Iteration 2600 (1.63475 iter/s, 61.1714s/100 iter), loss = 3.4006
I0211 01:49:01.754232 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.67458 (* 1 = 3.67458 loss)
I0211 01:49:01.754251 20163 sgd_solver.cpp:136] Iteration 2600, lr = 0.00091611, m = 0.9
I0211 01:50:02.588552 20163 solver.cpp:314] Iteration 2700 (1.64387 iter/s, 60.8322s/100 iter), loss = 2.99629
I0211 01:50:02.596565 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.05895 (* 1 = 3.05895 loss)
I0211 01:50:02.596588 20163 sgd_solver.cpp:136] Iteration 2700, lr = 0.000912992, m = 0.9
I0211 01:51:04.058616 20163 solver.cpp:314] Iteration 2800 (1.62687 iter/s, 61.4678s/100 iter), loss = 3.24328
I0211 01:51:04.058750 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.16387 (* 1 = 3.16387 loss)
I0211 01:51:04.058766 20163 sgd_solver.cpp:136] Iteration 2800, lr = 0.000909883, m = 0.9
I0211 01:52:04.545016 20163 solver.cpp:314] Iteration 2900 (1.65332 iter/s, 60.4842s/100 iter), loss = 3.493
I0211 01:52:04.545135 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.70432 (* 1 = 2.70432 loss)
I0211 01:52:04.545156 20163 sgd_solver.cpp:136] Iteration 2900, lr = 0.000906782, m = 0.9
I0211 01:53:05.362838 20163 solver.cpp:314] Iteration 3000 (1.64431 iter/s, 60.8156s/100 iter), loss = 3.18637
I0211 01:53:05.362977 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.55282 (* 1 = 3.55282 loss)
I0211 01:53:05.363005 20163 sgd_solver.cpp:136] Iteration 3000, lr = 0.000903688, m = 0.9
I0211 01:54:05.822481 20163 solver.cpp:314] Iteration 3100 (1.65406 iter/s, 60.4574s/100 iter), loss = 3.08937
I0211 01:54:05.822618 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.27793 (* 1 = 3.27793 loss)
I0211 01:54:05.822633 20163 sgd_solver.cpp:136] Iteration 3100, lr = 0.000900602, m = 0.9
I0211 01:54:15.797935 20123 data_reader.cpp:305] Starting prefetch of epoch 1
I0211 01:55:06.284554 20163 solver.cpp:314] Iteration 3200 (1.65399 iter/s, 60.4599s/100 iter), loss = 3.10342
I0211 01:55:06.284677 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.66325 (* 1 = 2.66325 loss)
I0211 01:55:06.284693 20163 sgd_solver.cpp:136] Iteration 3200, lr = 0.000897525, m = 0.9
I0211 01:56:06.201573 20163 solver.cpp:314] Iteration 3300 (1.66904 iter/s, 59.9148s/100 iter), loss = 3.05674
I0211 01:56:06.201668 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.70154 (* 1 = 2.70154 loss)
I0211 01:56:06.201683 20163 sgd_solver.cpp:136] Iteration 3300, lr = 0.000894455, m = 0.9
I0211 01:57:07.985229 20163 solver.cpp:314] Iteration 3400 (1.61861 iter/s, 61.7814s/100 iter), loss = 3.2723
I0211 01:57:07.985458 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.79008 (* 1 = 3.79008 loss)
I0211 01:57:07.985502 20163 sgd_solver.cpp:136] Iteration 3400, lr = 0.000891393, m = 0.9
I0211 01:58:10.141216 20163 solver.cpp:314] Iteration 3500 (1.60891 iter/s, 62.1537s/100 iter), loss = 3.08223
I0211 01:58:10.141345 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.23617 (* 1 = 2.23617 loss)
I0211 01:58:10.141362 20163 sgd_solver.cpp:136] Iteration 3500, lr = 0.000888339, m = 0.9
I0211 01:59:10.322917 20163 solver.cpp:314] Iteration 3600 (1.6617 iter/s, 60.1795s/100 iter), loss = 3.26166
I0211 01:59:10.323053 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.3841 (* 1 = 2.3841 loss)
I0211 01:59:10.323068 20163 sgd_solver.cpp:136] Iteration 3600, lr = 0.000885293, m = 0.9
I0211 02:00:11.470742 20163 solver.cpp:314] Iteration 3700 (1.63544 iter/s, 61.1456s/100 iter), loss = 3.03163
I0211 02:00:11.470877 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.64751 (* 1 = 3.64751 loss)
I0211 02:00:11.470892 20163 sgd_solver.cpp:136] Iteration 3700, lr = 0.000882254, m = 0.9
I0211 02:01:11.813951 20163 solver.cpp:314] Iteration 3800 (1.65725 iter/s, 60.341s/100 iter), loss = 3.36053
I0211 02:01:11.814054 20163 solver.cpp:336]     Train net output #0: mbox_loss = 4.51739 (* 1 = 4.51739 loss)
I0211 02:01:11.814069 20163 sgd_solver.cpp:136] Iteration 3800, lr = 0.000879224, m = 0.9
I0211 02:02:11.783499 20163 solver.cpp:314] Iteration 3900 (1.66757 iter/s, 59.9674s/100 iter), loss = 3.14113
I0211 02:02:11.783612 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.45033 (* 1 = 2.45033 loss)
I0211 02:02:11.783627 20163 sgd_solver.cpp:136] Iteration 3900, lr = 0.000876201, m = 0.9
I0211 02:03:11.470223 20163 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_4000.caffemodel
I0211 02:03:11.520792 20163 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_4000.solverstate
I0211 02:03:11.533386 20163 solver.cpp:666] Iteration 4000, Testing net (#0)
I0211 02:04:03.917632 20163 solver.cpp:774] class AP 1: 0.369397
I0211 02:04:03.981075 20163 solver.cpp:774] class AP 2: 0.615211
I0211 02:04:03.993860 20163 solver.cpp:774] class AP 3: 0.628088
I0211 02:04:03.993881 20163 solver.cpp:780] Test net output mAP #0: detection_eval = 0.537565
I0211 02:04:04.634675 20164 solver.cpp:774] class AP 1: 0.379217
I0211 02:04:04.707402 20164 solver.cpp:774] class AP 2: 0.614414
I0211 02:04:04.720955 20164 solver.cpp:774] class AP 3: 0.626341
I0211 02:04:04.720980 20164 solver.cpp:780] Test net output mAP #0: detection_eval = 0.539991
I0211 02:04:04.721091 20163 solver.cpp:265] [MultiGPU] Tests completed in 53.1858s
I0211 02:04:05.185247 20163 solver.cpp:314] Iteration 4000 (0.881853 iter/s, 113.398s/100 iter), loss = 3.16499
I0211 02:04:05.185377 20163 solver.cpp:336]     Train net output #0: mbox_loss = 4.27355 (* 1 = 4.27355 loss)
I0211 02:04:05.185420 20163 sgd_solver.cpp:136] Iteration 4000, lr = 0.000873186, m = 0.9
I0211 02:05:06.072688 20163 solver.cpp:314] Iteration 4100 (1.64243 iter/s, 60.8852s/100 iter), loss = 3.10783
I0211 02:05:06.072803 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.8476 (* 1 = 2.8476 loss)
I0211 02:05:06.072819 20163 sgd_solver.cpp:136] Iteration 4100, lr = 0.000870179, m = 0.9
I0211 02:06:06.413002 20163 solver.cpp:314] Iteration 4200 (1.65733 iter/s, 60.3381s/100 iter), loss = 3.14298
I0211 02:06:06.413123 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.8027 (* 1 = 2.8027 loss)
I0211 02:06:06.413139 20163 sgd_solver.cpp:136] Iteration 4200, lr = 0.00086718, m = 0.9
I0211 02:07:06.849845 20163 solver.cpp:314] Iteration 4300 (1.65468 iter/s, 60.4346s/100 iter), loss = 3.22972
I0211 02:07:06.849985 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.18532 (* 1 = 3.18532 loss)
I0211 02:07:06.850003 20163 sgd_solver.cpp:136] Iteration 4300, lr = 0.000864188, m = 0.9
I0211 02:08:06.888219 20163 solver.cpp:314] Iteration 4400 (1.66566 iter/s, 60.0362s/100 iter), loss = 3.15938
I0211 02:08:06.888345 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.67842 (* 1 = 3.67842 loss)
I0211 02:08:06.888362 20163 sgd_solver.cpp:136] Iteration 4400, lr = 0.000861205, m = 0.9
I0211 02:09:06.668561 20163 solver.cpp:314] Iteration 4500 (1.67285 iter/s, 59.7782s/100 iter), loss = 2.94434
I0211 02:09:06.668963 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.48058 (* 1 = 2.48058 loss)
I0211 02:09:06.668987 20163 sgd_solver.cpp:136] Iteration 4500, lr = 0.000858228, m = 0.9
I0211 02:10:06.857867 20163 solver.cpp:314] Iteration 4600 (1.66149 iter/s, 60.1871s/100 iter), loss = 3.14757
I0211 02:10:06.858069 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.20789 (* 1 = 3.20789 loss)
I0211 02:10:06.858119 20163 sgd_solver.cpp:136] Iteration 4600, lr = 0.00085526, m = 0.9
I0211 02:11:07.380779 20163 solver.cpp:314] Iteration 4700 (1.65233 iter/s, 60.5207s/100 iter), loss = 3.04593
I0211 02:11:07.380880 20163 solver.cpp:336]     Train net output #0: mbox_loss = 4.4819 (* 1 = 4.4819 loss)
I0211 02:11:07.380899 20163 sgd_solver.cpp:136] Iteration 4700, lr = 0.0008523, m = 0.9
I0211 02:12:08.341886 20163 solver.cpp:314] Iteration 4800 (1.64045 iter/s, 60.9589s/100 iter), loss = 3.32119
I0211 02:12:08.342016 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.7741 (* 1 = 2.7741 loss)
I0211 02:12:08.342036 20163 sgd_solver.cpp:136] Iteration 4800, lr = 0.000849347, m = 0.9
I0211 02:13:09.550508 20163 solver.cpp:314] Iteration 4900 (1.63382 iter/s, 61.2064s/100 iter), loss = 3.44548
I0211 02:13:09.551465 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.03575 (* 1 = 3.03575 loss)
I0211 02:13:09.551483 20163 sgd_solver.cpp:136] Iteration 4900, lr = 0.000846401, m = 0.9
I0211 02:14:09.829756 20163 solver.cpp:314] Iteration 5000 (1.65901 iter/s, 60.2771s/100 iter), loss = 3.1037
I0211 02:14:09.829872 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.68295 (* 1 = 2.68295 loss)
I0211 02:14:09.829888 20163 sgd_solver.cpp:136] Iteration 5000, lr = 0.000843464, m = 0.9
I0211 02:15:10.729866 20163 solver.cpp:314] Iteration 5100 (1.64209 iter/s, 60.8979s/100 iter), loss = 3.1844
I0211 02:15:10.729987 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.82235 (* 1 = 2.82235 loss)
I0211 02:15:10.730003 20163 sgd_solver.cpp:136] Iteration 5100, lr = 0.000840534, m = 0.9
I0211 02:16:12.624569 20163 solver.cpp:314] Iteration 5200 (1.61571 iter/s, 61.8924s/100 iter), loss = 3.2839
I0211 02:16:12.625074 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.82362 (* 1 = 2.82362 loss)
I0211 02:16:12.625355 20163 sgd_solver.cpp:136] Iteration 5200, lr = 0.000837611, m = 0.9
I0211 02:17:13.194741 20163 solver.cpp:314] Iteration 5300 (1.65104 iter/s, 60.568s/100 iter), loss = 3.04198
I0211 02:17:13.194856 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.69563 (* 1 = 2.69563 loss)
I0211 02:17:13.194867 20163 sgd_solver.cpp:136] Iteration 5300, lr = 0.000834697, m = 0.9
I0211 02:18:13.154737 20163 solver.cpp:314] Iteration 5400 (1.66784 iter/s, 59.9578s/100 iter), loss = 3.20629
I0211 02:18:13.154852 20163 solver.cpp:336]     Train net output #0: mbox_loss = 1.93135 (* 1 = 1.93135 loss)
I0211 02:18:13.154867 20163 sgd_solver.cpp:136] Iteration 5400, lr = 0.00083179, m = 0.9
I0211 02:19:12.133898 20163 solver.cpp:314] Iteration 5500 (1.69558 iter/s, 58.977s/100 iter), loss = 3.1858
I0211 02:19:12.134023 20163 solver.cpp:336]     Train net output #0: mbox_loss = 4.23886 (* 1 = 4.23886 loss)
I0211 02:19:12.134042 20163 sgd_solver.cpp:136] Iteration 5500, lr = 0.00082889, m = 0.9
I0211 02:20:13.177049 20163 solver.cpp:314] Iteration 5600 (1.63824 iter/s, 61.0409s/100 iter), loss = 3.21217
I0211 02:20:13.177276 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.097 (* 1 = 2.097 loss)
I0211 02:20:13.177320 20163 sgd_solver.cpp:136] Iteration 5600, lr = 0.000825998, m = 0.9
I0211 02:21:13.503475 20163 solver.cpp:314] Iteration 5700 (1.65771 iter/s, 60.3242s/100 iter), loss = 3.16737
I0211 02:21:13.503620 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.66558 (* 1 = 3.66558 loss)
I0211 02:21:13.503640 20163 sgd_solver.cpp:136] Iteration 5700, lr = 0.000823114, m = 0.9
I0211 02:22:13.190822 20163 solver.cpp:314] Iteration 5800 (1.67546 iter/s, 59.6852s/100 iter), loss = 3.37049
I0211 02:22:13.190943 20163 solver.cpp:336]     Train net output #0: mbox_loss = 4.48902 (* 1 = 4.48902 loss)
I0211 02:22:13.190958 20163 sgd_solver.cpp:136] Iteration 5800, lr = 0.000820237, m = 0.9
I0211 02:23:13.791766 20163 solver.cpp:314] Iteration 5900 (1.6502 iter/s, 60.5987s/100 iter), loss = 3.13241
I0211 02:23:13.791877 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.06113 (* 1 = 3.06113 loss)
I0211 02:23:13.791893 20163 sgd_solver.cpp:136] Iteration 5900, lr = 0.000817368, m = 0.9
I0211 02:24:13.271814 20163 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_6000.caffemodel
I0211 02:24:13.294637 20163 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_6000.solverstate
I0211 02:24:13.306617 20163 solver.cpp:666] Iteration 6000, Testing net (#0)
I0211 02:25:06.394779 20150 data_reader.cpp:305] Starting prefetch of epoch 2
I0211 02:25:06.919876 20163 solver.cpp:774] class AP 1: 0.363445
I0211 02:25:06.997642 20163 solver.cpp:774] class AP 2: 0.63317
I0211 02:25:07.010398 20163 solver.cpp:774] class AP 3: 0.621859
I0211 02:25:07.010417 20163 solver.cpp:780] Test net output mAP #0: detection_eval = 0.539491
I0211 02:25:07.461515 20164 solver.cpp:774] class AP 1: 0.363849
I0211 02:25:07.537192 20164 solver.cpp:774] class AP 2: 0.622085
I0211 02:25:07.549628 20164 solver.cpp:774] class AP 3: 0.622048
I0211 02:25:07.549639 20164 solver.cpp:780] Test net output mAP #0: detection_eval = 0.535994
I0211 02:25:07.549770 20163 solver.cpp:265] [MultiGPU] Tests completed in 54.2412s
I0211 02:25:08.078848 20163 solver.cpp:314] Iteration 6000 (0.875021 iter/s, 114.283s/100 iter), loss = 3.27616
I0211 02:25:08.078899 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.11989 (* 1 = 3.11989 loss)
I0211 02:25:08.078912 20163 sgd_solver.cpp:136] Iteration 6000, lr = 0.000814506, m = 0.9
I0211 02:26:08.915388 20163 solver.cpp:314] Iteration 6100 (1.64381 iter/s, 60.8343s/100 iter), loss = 3.33607
I0211 02:26:08.915503 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.75129 (* 1 = 2.75129 loss)
I0211 02:26:08.915514 20163 sgd_solver.cpp:136] Iteration 6100, lr = 0.000811652, m = 0.9
I0211 02:27:09.368845 20163 solver.cpp:314] Iteration 6200 (1.65423 iter/s, 60.4513s/100 iter), loss = 3.15445
I0211 02:27:09.368968 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.34816 (* 1 = 2.34816 loss)
I0211 02:27:09.368983 20163 sgd_solver.cpp:136] Iteration 6200, lr = 0.000808805, m = 0.9
I0211 02:28:09.354737 20163 solver.cpp:314] Iteration 6300 (1.66712 iter/s, 59.9837s/100 iter), loss = 3.1362
I0211 02:28:09.354925 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.90466 (* 1 = 2.90466 loss)
I0211 02:28:09.354965 20163 sgd_solver.cpp:136] Iteration 6300, lr = 0.000805966, m = 0.9
I0211 02:29:10.366667 20163 solver.cpp:314] Iteration 6400 (1.63908 iter/s, 61.0097s/100 iter), loss = 3.02222
I0211 02:29:10.366803 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.09808 (* 1 = 2.09808 loss)
I0211 02:29:10.366824 20163 sgd_solver.cpp:136] Iteration 6400, lr = 0.000803135, m = 0.9
I0211 02:30:12.133385 20163 solver.cpp:314] Iteration 6500 (1.61905 iter/s, 61.7645s/100 iter), loss = 3.10151
I0211 02:30:12.133513 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.38691 (* 1 = 2.38691 loss)
I0211 02:30:12.133530 20163 sgd_solver.cpp:136] Iteration 6500, lr = 0.00080031, m = 0.9
I0211 02:31:12.402257 20163 solver.cpp:314] Iteration 6600 (1.65929 iter/s, 60.2667s/100 iter), loss = 3.63613
I0211 02:31:12.402493 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.48369 (* 1 = 3.48369 loss)
I0211 02:31:12.402546 20163 sgd_solver.cpp:136] Iteration 6600, lr = 0.000797494, m = 0.9
I0211 02:32:12.803710 20163 solver.cpp:314] Iteration 6700 (1.65565 iter/s, 60.3993s/100 iter), loss = 3.1644
I0211 02:32:12.803863 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.99218 (* 1 = 2.99218 loss)
I0211 02:32:12.803889 20163 sgd_solver.cpp:136] Iteration 6700, lr = 0.000794684, m = 0.9
I0211 02:33:12.465282 20163 solver.cpp:314] Iteration 6800 (1.67618 iter/s, 59.6594s/100 iter), loss = 3.01789
I0211 02:33:12.465456 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.18869 (* 1 = 3.18869 loss)
I0211 02:33:12.465494 20163 sgd_solver.cpp:136] Iteration 6800, lr = 0.000791882, m = 0.9
I0211 02:34:13.329422 20163 solver.cpp:314] Iteration 6900 (1.64306 iter/s, 60.8619s/100 iter), loss = 3.23152
I0211 02:34:13.329522 20163 solver.cpp:336]     Train net output #0: mbox_loss = 5.02387 (* 1 = 5.02387 loss)
I0211 02:34:13.329537 20163 sgd_solver.cpp:136] Iteration 6900, lr = 0.000789088, m = 0.9
I0211 02:35:14.037827 20163 solver.cpp:314] Iteration 7000 (1.64728 iter/s, 60.7062s/100 iter), loss = 3.06127
I0211 02:35:14.037955 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.3105 (* 1 = 3.3105 loss)
I0211 02:35:14.037971 20163 sgd_solver.cpp:136] Iteration 7000, lr = 0.000786301, m = 0.9
I0211 02:36:14.456820 20163 solver.cpp:314] Iteration 7100 (1.65517 iter/s, 60.4168s/100 iter), loss = 2.98987
I0211 02:36:14.457005 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.44406 (* 1 = 3.44406 loss)
I0211 02:36:14.457046 20163 sgd_solver.cpp:136] Iteration 7100, lr = 0.000783521, m = 0.9
I0211 02:37:14.712204 20163 solver.cpp:314] Iteration 7200 (1.65966 iter/s, 60.2532s/100 iter), loss = 3.24458
I0211 02:37:14.712318 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.17467 (* 1 = 3.17467 loss)
I0211 02:37:14.712332 20163 sgd_solver.cpp:136] Iteration 7200, lr = 0.000780749, m = 0.9
I0211 02:38:15.349707 20163 solver.cpp:314] Iteration 7300 (1.6492 iter/s, 60.6353s/100 iter), loss = 3.0794
I0211 02:38:15.349884 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.15506 (* 1 = 3.15506 loss)
I0211 02:38:15.349925 20163 sgd_solver.cpp:136] Iteration 7300, lr = 0.000777984, m = 0.9
I0211 02:39:16.024771 20163 solver.cpp:314] Iteration 7400 (1.64818 iter/s, 60.6729s/100 iter), loss = 3.11781
I0211 02:39:16.026032 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.61024 (* 1 = 3.61024 loss)
I0211 02:39:16.026051 20163 sgd_solver.cpp:136] Iteration 7400, lr = 0.000775226, m = 0.9
I0211 02:40:16.771061 20163 solver.cpp:314] Iteration 7500 (1.64625 iter/s, 60.7441s/100 iter), loss = 2.92842
I0211 02:40:16.772557 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.40733 (* 1 = 3.40733 loss)
I0211 02:40:16.772579 20163 sgd_solver.cpp:136] Iteration 7500, lr = 0.000772476, m = 0.9
I0211 02:41:17.494684 20163 solver.cpp:314] Iteration 7600 (1.64687 iter/s, 60.7214s/100 iter), loss = 3.18626
I0211 02:41:17.494819 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.6314 (* 1 = 3.6314 loss)
I0211 02:41:17.494837 20163 sgd_solver.cpp:136] Iteration 7600, lr = 0.000769733, m = 0.9
I0211 02:42:18.310957 20163 solver.cpp:314] Iteration 7700 (1.64436 iter/s, 60.8141s/100 iter), loss = 3.08722
I0211 02:42:18.320571 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.90777 (* 1 = 2.90777 loss)
I0211 02:42:18.320595 20163 sgd_solver.cpp:136] Iteration 7700, lr = 0.000766998, m = 0.9
I0211 02:43:20.933851 20163 solver.cpp:314] Iteration 7800 (1.59692 iter/s, 62.6206s/100 iter), loss = 3.12847
I0211 02:43:20.934015 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.67382 (* 1 = 3.67382 loss)
I0211 02:43:20.934029 20163 sgd_solver.cpp:136] Iteration 7800, lr = 0.000764269, m = 0.9
I0211 02:44:21.893406 20163 solver.cpp:314] Iteration 7900 (1.64049 iter/s, 60.9573s/100 iter), loss = 3.26702
I0211 02:44:21.893548 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.46955 (* 1 = 2.46955 loss)
I0211 02:44:21.893563 20163 sgd_solver.cpp:136] Iteration 7900, lr = 0.000761548, m = 0.9
I0211 02:45:22.909919 20163 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_8000.caffemodel
I0211 02:45:22.932813 20163 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_8000.solverstate
I0211 02:45:22.945009 20163 solver.cpp:666] Iteration 8000, Testing net (#0)
I0211 02:46:15.417701 20164 solver.cpp:774] class AP 1: 0.407649
I0211 02:46:15.497604 20164 solver.cpp:774] class AP 2: 0.612833
I0211 02:46:15.506640 20164 solver.cpp:774] class AP 3: 0.626054
I0211 02:46:15.506667 20164 solver.cpp:780] Test net output mAP #0: detection_eval = 0.548845
I0211 02:46:15.843299 20163 solver.cpp:774] class AP 1: 0.409018
I0211 02:46:15.914877 20163 solver.cpp:774] class AP 2: 0.611949
I0211 02:46:15.922623 20163 solver.cpp:774] class AP 3: 0.633139
I0211 02:46:15.922636 20163 solver.cpp:780] Test net output mAP #0: detection_eval = 0.551369
I0211 02:46:15.922807 20163 solver.cpp:265] [MultiGPU] Tests completed in 52.9759s
I0211 02:46:16.387717 20163 solver.cpp:314] Iteration 8000 (0.873438 iter/s, 114.49s/100 iter), loss = 3.08198
I0211 02:46:16.387768 20163 solver.cpp:336]     Train net output #0: mbox_loss = 1.75623 (* 1 = 1.75623 loss)
I0211 02:46:16.387781 20163 sgd_solver.cpp:136] Iteration 8000, lr = 0.000758835, m = 0.9
I0211 02:47:16.119279 20163 solver.cpp:314] Iteration 8100 (1.67422 iter/s, 59.7294s/100 iter), loss = 3.1482
I0211 02:47:16.119467 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.94603 (* 1 = 2.94603 loss)
I0211 02:47:16.119510 20163 sgd_solver.cpp:136] Iteration 8100, lr = 0.000756128, m = 0.9
I0211 02:48:16.432561 20163 solver.cpp:314] Iteration 8200 (1.65807 iter/s, 60.3111s/100 iter), loss = 3.1267
I0211 02:48:16.432749 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.2085 (* 1 = 3.2085 loss)
I0211 02:48:16.432791 20163 sgd_solver.cpp:136] Iteration 8200, lr = 0.000753429, m = 0.9
I0211 02:49:16.801277 20163 solver.cpp:314] Iteration 8300 (1.65655 iter/s, 60.3665s/100 iter), loss = 3.084
I0211 02:49:16.801386 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.22639 (* 1 = 2.22639 loss)
I0211 02:49:16.801398 20163 sgd_solver.cpp:136] Iteration 8300, lr = 0.000750737, m = 0.9
I0211 02:50:17.078660 20163 solver.cpp:314] Iteration 8400 (1.65906 iter/s, 60.2752s/100 iter), loss = 2.94334
I0211 02:50:17.078758 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.13793 (* 1 = 3.13793 loss)
I0211 02:50:17.078768 20163 sgd_solver.cpp:136] Iteration 8400, lr = 0.000748052, m = 0.9
I0211 02:51:17.553448 20163 solver.cpp:314] Iteration 8500 (1.65364 iter/s, 60.4726s/100 iter), loss = 3.27491
I0211 02:51:17.553582 20163 solver.cpp:336]     Train net output #0: mbox_loss = 4.5247 (* 1 = 4.5247 loss)
I0211 02:51:17.553601 20163 sgd_solver.cpp:136] Iteration 8500, lr = 0.000745374, m = 0.9
I0211 02:52:17.948779 20163 solver.cpp:314] Iteration 8600 (1.65582 iter/s, 60.3931s/100 iter), loss = 3.13724
I0211 02:52:17.948892 20163 solver.cpp:336]     Train net output #0: mbox_loss = 4.26428 (* 1 = 4.26428 loss)
I0211 02:52:17.948907 20163 sgd_solver.cpp:136] Iteration 8600, lr = 0.000742704, m = 0.9
I0211 02:53:18.532990 20163 solver.cpp:314] Iteration 8700 (1.65066 iter/s, 60.582s/100 iter), loss = 3.08703
I0211 02:53:18.533685 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.77492 (* 1 = 2.77492 loss)
I0211 02:53:18.534005 20163 sgd_solver.cpp:136] Iteration 8700, lr = 0.000740041, m = 0.9
I0211 02:54:19.091367 20163 solver.cpp:314] Iteration 8800 (1.65136 iter/s, 60.5562s/100 iter), loss = 3.23298
I0211 02:54:19.091507 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.28013 (* 1 = 3.28013 loss)
I0211 02:54:19.091523 20163 sgd_solver.cpp:136] Iteration 8800, lr = 0.000737385, m = 0.9
I0211 02:55:21.217698 20163 solver.cpp:314] Iteration 8900 (1.60968 iter/s, 62.1241s/100 iter), loss = 3.05934
I0211 02:55:21.217838 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.78862 (* 1 = 2.78862 loss)
I0211 02:55:21.217851 20163 sgd_solver.cpp:136] Iteration 8900, lr = 0.000734736, m = 0.9
I0211 02:56:22.177263 20163 solver.cpp:314] Iteration 9000 (1.64049 iter/s, 60.9573s/100 iter), loss = 3.09437
I0211 02:56:22.183147 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.23645 (* 1 = 2.23645 loss)
I0211 02:56:22.183197 20163 sgd_solver.cpp:136] Iteration 9000, lr = 0.000732094, m = 0.9
I0211 02:56:38.652195 20123 data_reader.cpp:305] Starting prefetch of epoch 2
I0211 02:57:22.857242 20163 solver.cpp:314] Iteration 9100 (1.64805 iter/s, 60.6778s/100 iter), loss = 3.08691
I0211 02:57:22.857364 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.31011 (* 1 = 2.31011 loss)
I0211 02:57:22.857383 20163 sgd_solver.cpp:136] Iteration 9100, lr = 0.00072946, m = 0.9
I0211 02:58:23.267444 20163 solver.cpp:314] Iteration 9200 (1.65541 iter/s, 60.408s/100 iter), loss = 3.11628
I0211 02:58:23.267561 20163 solver.cpp:336]     Train net output #0: mbox_loss = 1.94608 (* 1 = 1.94608 loss)
I0211 02:58:23.267575 20163 sgd_solver.cpp:136] Iteration 9200, lr = 0.000726832, m = 0.9
I0211 02:59:24.210970 20163 solver.cpp:314] Iteration 9300 (1.64092 iter/s, 60.9413s/100 iter), loss = 3.19152
I0211 02:59:24.211079 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.88403 (* 1 = 2.88403 loss)
I0211 02:59:24.211094 20163 sgd_solver.cpp:136] Iteration 9300, lr = 0.000724212, m = 0.9
I0211 03:00:24.469712 20163 solver.cpp:314] Iteration 9400 (1.65957 iter/s, 60.2565s/100 iter), loss = 3.11615
I0211 03:00:24.469878 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.23567 (* 1 = 3.23567 loss)
I0211 03:00:24.469918 20163 sgd_solver.cpp:136] Iteration 9400, lr = 0.000721598, m = 0.9
I0211 03:01:25.435140 20163 solver.cpp:314] Iteration 9500 (1.64033 iter/s, 60.9632s/100 iter), loss = 3.23982
I0211 03:01:25.435261 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.8085 (* 1 = 2.8085 loss)
I0211 03:01:25.435276 20163 sgd_solver.cpp:136] Iteration 9500, lr = 0.000718992, m = 0.9
I0211 03:02:25.985311 20163 solver.cpp:314] Iteration 9600 (1.65158 iter/s, 60.548s/100 iter), loss = 2.98282
I0211 03:02:25.985440 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.35643 (* 1 = 2.35643 loss)
I0211 03:02:25.985461 20163 sgd_solver.cpp:136] Iteration 9600, lr = 0.000716393, m = 0.9
I0211 03:03:26.477788 20163 solver.cpp:314] Iteration 9700 (1.65316 iter/s, 60.4903s/100 iter), loss = 3.25399
I0211 03:03:26.477918 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.27621 (* 1 = 3.27621 loss)
I0211 03:03:26.477934 20163 sgd_solver.cpp:136] Iteration 9700, lr = 0.000713801, m = 0.9
I0211 03:04:26.532567 20163 solver.cpp:314] Iteration 9800 (1.66521 iter/s, 60.0526s/100 iter), loss = 3.03869
I0211 03:04:26.532757 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.4667 (* 1 = 2.4667 loss)
I0211 03:04:26.532806 20163 sgd_solver.cpp:136] Iteration 9800, lr = 0.000711216, m = 0.9
I0211 03:05:27.076259 20163 solver.cpp:314] Iteration 9900 (1.65176 iter/s, 60.5415s/100 iter), loss = 3.31364
I0211 03:05:27.076385 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.05328 (* 1 = 3.05328 loss)
I0211 03:05:27.076400 20163 sgd_solver.cpp:136] Iteration 9900, lr = 0.000708638, m = 0.9
I0211 03:06:28.701290 20163 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_10000.caffemodel
I0211 03:06:28.723832 20163 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_10000.solverstate
I0211 03:06:28.737381 20163 solver.cpp:666] Iteration 10000, Testing net (#0)
I0211 03:07:20.756619 20163 solver.cpp:774] class AP 1: 0.408746
I0211 03:07:20.811830 20163 solver.cpp:774] class AP 2: 0.640409
I0211 03:07:20.823380 20163 solver.cpp:774] class AP 3: 0.635468
I0211 03:07:20.823403 20163 solver.cpp:780] Test net output mAP #0: detection_eval = 0.561541
I0211 03:07:20.868988 20164 solver.cpp:774] class AP 1: 0.403062
I0211 03:07:20.933459 20164 solver.cpp:774] class AP 2: 0.636815
I0211 03:07:20.944700 20164 solver.cpp:774] class AP 3: 0.631028
I0211 03:07:20.944716 20164 solver.cpp:780] Test net output mAP #0: detection_eval = 0.556968
I0211 03:07:20.944795 20163 solver.cpp:265] [MultiGPU] Tests completed in 52.2055s
I0211 03:07:21.363144 20163 solver.cpp:314] Iteration 10000 (0.875023 iter/s, 114.283s/100 iter), loss = 3.1121
I0211 03:07:21.363273 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.31716 (* 1 = 3.31716 loss)
I0211 03:07:21.363314 20163 sgd_solver.cpp:136] Iteration 10000, lr = 0.000706067, m = 0.9
I0211 03:08:21.261235 20163 solver.cpp:314] Iteration 10100 (1.66956 iter/s, 59.8959s/100 iter), loss = 3.14072
I0211 03:08:21.261418 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.25584 (* 1 = 2.25584 loss)
I0211 03:08:21.261459 20163 sgd_solver.cpp:136] Iteration 10100, lr = 0.000703503, m = 0.9
I0211 03:09:21.782449 20163 solver.cpp:314] Iteration 10200 (1.65237 iter/s, 60.519s/100 iter), loss = 3.1265
I0211 03:09:21.782562 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.34836 (* 1 = 2.34836 loss)
I0211 03:09:21.782577 20163 sgd_solver.cpp:136] Iteration 10200, lr = 0.000700946, m = 0.9
I0211 03:10:22.640519 20163 solver.cpp:314] Iteration 10300 (1.64323 iter/s, 60.8558s/100 iter), loss = 2.91228
I0211 03:10:22.640631 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.33151 (* 1 = 3.33151 loss)
I0211 03:10:22.640646 20163 sgd_solver.cpp:136] Iteration 10300, lr = 0.000698396, m = 0.9
I0211 03:11:23.324074 20163 solver.cpp:314] Iteration 10400 (1.64795 iter/s, 60.6814s/100 iter), loss = 3.18807
I0211 03:11:23.324250 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.88471 (* 1 = 2.88471 loss)
I0211 03:11:23.324292 20163 sgd_solver.cpp:136] Iteration 10400, lr = 0.000695853, m = 0.9
I0211 03:12:23.906581 20163 solver.cpp:314] Iteration 10500 (1.6507 iter/s, 60.5803s/100 iter), loss = 3.24518
I0211 03:12:23.906703 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.57485 (* 1 = 3.57485 loss)
I0211 03:12:23.906721 20163 sgd_solver.cpp:136] Iteration 10500, lr = 0.000693317, m = 0.9
I0211 03:13:24.002069 20163 solver.cpp:314] Iteration 10600 (1.66408 iter/s, 60.0933s/100 iter), loss = 2.99191
I0211 03:13:24.002185 20163 solver.cpp:336]     Train net output #0: mbox_loss = 4.05836 (* 1 = 4.05836 loss)
I0211 03:13:24.002202 20163 sgd_solver.cpp:136] Iteration 10600, lr = 0.000690787, m = 0.9
I0211 03:14:24.807158 20163 solver.cpp:314] Iteration 10700 (1.64466 iter/s, 60.8029s/100 iter), loss = 2.98143
I0211 03:14:24.807325 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.72369 (* 1 = 3.72369 loss)
I0211 03:14:24.807374 20163 sgd_solver.cpp:136] Iteration 10700, lr = 0.000688265, m = 0.9
I0211 03:15:26.863368 20163 solver.cpp:314] Iteration 10800 (1.6115 iter/s, 62.054s/100 iter), loss = 3.1113
I0211 03:15:26.863545 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.05746 (* 1 = 3.05746 loss)
I0211 03:15:26.863601 20163 sgd_solver.cpp:136] Iteration 10800, lr = 0.00068575, m = 0.9
I0211 03:16:27.981005 20163 solver.cpp:314] Iteration 10900 (1.63625 iter/s, 61.1154s/100 iter), loss = 3.11388
I0211 03:16:27.981174 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.46348 (* 1 = 3.46348 loss)
I0211 03:16:27.981191 20163 sgd_solver.cpp:136] Iteration 10900, lr = 0.000683241, m = 0.9
I0211 03:17:29.070840 20163 solver.cpp:314] Iteration 11000 (1.63699 iter/s, 61.0876s/100 iter), loss = 3.13259
I0211 03:17:29.070976 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.42388 (* 1 = 3.42388 loss)
I0211 03:17:29.070997 20163 sgd_solver.cpp:136] Iteration 11000, lr = 0.00068074, m = 0.9
I0211 03:18:30.264915 20163 solver.cpp:314] Iteration 11100 (1.6342 iter/s, 61.1919s/100 iter), loss = 3.07473
I0211 03:18:30.265046 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.84434 (* 1 = 2.84434 loss)
I0211 03:18:30.265064 20163 sgd_solver.cpp:136] Iteration 11100, lr = 0.000678245, m = 0.9
I0211 03:19:31.279242 20163 solver.cpp:314] Iteration 11200 (1.63902 iter/s, 61.0121s/100 iter), loss = 2.9852
I0211 03:19:31.279366 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.37555 (* 1 = 2.37555 loss)
I0211 03:19:31.279382 20163 sgd_solver.cpp:136] Iteration 11200, lr = 0.000675757, m = 0.9
I0211 03:20:31.944342 20163 solver.cpp:314] Iteration 11300 (1.64845 iter/s, 60.6629s/100 iter), loss = 2.84717
I0211 03:20:31.944460 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.96943 (* 1 = 2.96943 loss)
I0211 03:20:31.944475 20163 sgd_solver.cpp:136] Iteration 11300, lr = 0.000673276, m = 0.9
I0211 03:21:32.120645 20163 solver.cpp:314] Iteration 11400 (1.66184 iter/s, 60.1741s/100 iter), loss = 3.02562
I0211 03:21:32.120759 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.68984 (* 1 = 2.68984 loss)
I0211 03:21:32.120774 20163 sgd_solver.cpp:136] Iteration 11400, lr = 0.000670802, m = 0.9
I0211 03:22:32.858948 20163 solver.cpp:314] Iteration 11500 (1.64647 iter/s, 60.7361s/100 iter), loss = 3.20515
I0211 03:22:32.859061 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.35466 (* 1 = 2.35466 loss)
I0211 03:22:32.859076 20163 sgd_solver.cpp:136] Iteration 11500, lr = 0.000668335, m = 0.9
I0211 03:23:33.208920 20163 solver.cpp:314] Iteration 11600 (1.65706 iter/s, 60.3478s/100 iter), loss = 2.95498
I0211 03:23:33.209029 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.97073 (* 1 = 2.97073 loss)
I0211 03:23:33.209044 20163 sgd_solver.cpp:136] Iteration 11600, lr = 0.000665874, m = 0.9
I0211 03:24:34.096573 20163 solver.cpp:314] Iteration 11700 (1.64243 iter/s, 60.8854s/100 iter), loss = 3.02589
I0211 03:24:34.096698 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.69748 (* 1 = 3.69748 loss)
I0211 03:24:34.096736 20163 sgd_solver.cpp:136] Iteration 11700, lr = 0.000663421, m = 0.9
I0211 03:25:35.521718 20163 solver.cpp:314] Iteration 11800 (1.62806 iter/s, 61.4229s/100 iter), loss = 2.88773
I0211 03:25:35.521852 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.95896 (* 1 = 3.95896 loss)
I0211 03:25:35.521869 20163 sgd_solver.cpp:136] Iteration 11800, lr = 0.000660973, m = 0.9
I0211 03:26:35.339489 20163 solver.cpp:314] Iteration 11900 (1.6718 iter/s, 59.8156s/100 iter), loss = 3.03046
I0211 03:26:35.339598 20163 solver.cpp:336]     Train net output #0: mbox_loss = 4.40111 (* 1 = 4.40111 loss)
I0211 03:26:35.339609 20163 sgd_solver.cpp:136] Iteration 11900, lr = 0.000658533, m = 0.9
I0211 03:27:35.749166 20163 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_12000.caffemodel
I0211 03:27:35.771440 20163 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_12000.solverstate
I0211 03:27:35.800659 20163 solver.cpp:666] Iteration 12000, Testing net (#0)
I0211 03:28:30.447319 20164 solver.cpp:774] class AP 1: 0.385372
I0211 03:28:30.505658 20164 solver.cpp:774] class AP 2: 0.583961
I0211 03:28:30.517388 20164 solver.cpp:774] class AP 3: 0.615011
I0211 03:28:30.517412 20164 solver.cpp:780] Test net output mAP #0: detection_eval = 0.528115
I0211 03:28:30.669468 20150 data_reader.cpp:305] Starting prefetch of epoch 3
I0211 03:28:31.492672 20163 solver.cpp:774] class AP 1: 0.38669
I0211 03:28:31.550546 20163 solver.cpp:774] class AP 2: 0.58561
I0211 03:28:31.562131 20163 solver.cpp:774] class AP 3: 0.615628
I0211 03:28:31.562144 20163 solver.cpp:780] Test net output mAP #0: detection_eval = 0.529309
I0211 03:28:31.562206 20163 solver.cpp:265] [MultiGPU] Tests completed in 55.7595s
I0211 03:28:32.056821 20163 solver.cpp:314] Iteration 12000 (0.856802 iter/s, 116.713s/100 iter), loss = 3.04172
I0211 03:28:32.056864 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.7578 (* 1 = 3.7578 loss)
I0211 03:28:32.056874 20163 sgd_solver.cpp:136] Iteration 12000, lr = 0.0006561, m = 0.9
I0211 03:29:32.625869 20163 solver.cpp:314] Iteration 12100 (1.65107 iter/s, 60.5669s/100 iter), loss = 3.11862
I0211 03:29:32.625991 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.44788 (* 1 = 3.44788 loss)
I0211 03:29:32.626008 20163 sgd_solver.cpp:136] Iteration 12100, lr = 0.000653673, m = 0.9
I0211 03:30:33.941704 20163 solver.cpp:314] Iteration 12200 (1.63096 iter/s, 61.3136s/100 iter), loss = 3.1316
I0211 03:30:33.941824 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.5204 (* 1 = 2.5204 loss)
I0211 03:30:33.941840 20163 sgd_solver.cpp:136] Iteration 12200, lr = 0.000651253, m = 0.9
I0211 03:31:32.650638 20163 solver.cpp:314] Iteration 12300 (1.70338 iter/s, 58.7068s/100 iter), loss = 3.07727
I0211 03:31:32.650777 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.62287 (* 1 = 3.62287 loss)
I0211 03:31:32.650796 20163 sgd_solver.cpp:136] Iteration 12300, lr = 0.00064884, m = 0.9
I0211 03:32:33.371773 20163 solver.cpp:314] Iteration 12400 (1.64693 iter/s, 60.7189s/100 iter), loss = 2.93281
I0211 03:32:33.371906 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.24652 (* 1 = 3.24652 loss)
I0211 03:32:33.371922 20163 sgd_solver.cpp:136] Iteration 12400, lr = 0.000646434, m = 0.9
I0211 03:33:34.282690 20163 solver.cpp:314] Iteration 12500 (1.6418 iter/s, 60.9087s/100 iter), loss = 3.2598
I0211 03:33:34.282802 20163 solver.cpp:336]     Train net output #0: mbox_loss = 5.77039 (* 1 = 5.77039 loss)
I0211 03:33:34.282819 20163 sgd_solver.cpp:136] Iteration 12500, lr = 0.000644034, m = 0.9
I0211 03:34:34.627884 20163 solver.cpp:314] Iteration 12600 (1.65719 iter/s, 60.343s/100 iter), loss = 2.90978
I0211 03:34:34.628011 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.77031 (* 1 = 2.77031 loss)
I0211 03:34:34.628027 20163 sgd_solver.cpp:136] Iteration 12600, lr = 0.000641641, m = 0.9
I0211 03:35:35.079748 20163 solver.cpp:314] Iteration 12700 (1.65427 iter/s, 60.4497s/100 iter), loss = 2.81195
I0211 03:35:35.079893 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.25493 (* 1 = 2.25493 loss)
I0211 03:35:35.079911 20163 sgd_solver.cpp:136] Iteration 12700, lr = 0.000639255, m = 0.9
I0211 03:36:35.340459 20163 solver.cpp:314] Iteration 12800 (1.65952 iter/s, 60.2585s/100 iter), loss = 2.82149
I0211 03:36:35.340607 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.05503 (* 1 = 3.05503 loss)
I0211 03:36:35.340623 20163 sgd_solver.cpp:136] Iteration 12800, lr = 0.000636875, m = 0.9
I0211 03:37:35.777981 20163 solver.cpp:314] Iteration 12900 (1.65466 iter/s, 60.4353s/100 iter), loss = 3.05916
I0211 03:37:35.778111 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.25121 (* 1 = 3.25121 loss)
I0211 03:37:35.778128 20163 sgd_solver.cpp:136] Iteration 12900, lr = 0.000634502, m = 0.9
I0211 03:38:36.478449 20163 solver.cpp:314] Iteration 13000 (1.64749 iter/s, 60.6983s/100 iter), loss = 3.19696
I0211 03:38:36.478576 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.27825 (* 1 = 3.27825 loss)
I0211 03:38:36.478593 20163 sgd_solver.cpp:136] Iteration 13000, lr = 0.000632135, m = 0.9
I0211 03:39:36.359298 20163 solver.cpp:314] Iteration 13100 (1.67004 iter/s, 59.8787s/100 iter), loss = 3.18867
I0211 03:39:36.359458 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.87414 (* 1 = 3.87414 loss)
I0211 03:39:36.359473 20163 sgd_solver.cpp:136] Iteration 13100, lr = 0.000629776, m = 0.9
I0211 03:40:37.168700 20163 solver.cpp:314] Iteration 13200 (1.64454 iter/s, 60.8072s/100 iter), loss = 2.82598
I0211 03:40:37.168825 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.28747 (* 1 = 3.28747 loss)
I0211 03:40:37.168845 20163 sgd_solver.cpp:136] Iteration 13200, lr = 0.000627422, m = 0.9
I0211 03:41:38.252763 20163 solver.cpp:314] Iteration 13300 (1.63715 iter/s, 61.0818s/100 iter), loss = 3.01406
I0211 03:41:38.252887 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.29797 (* 1 = 3.29797 loss)
I0211 03:41:38.252902 20163 sgd_solver.cpp:136] Iteration 13300, lr = 0.000625076, m = 0.9
I0211 03:42:38.338325 20163 solver.cpp:314] Iteration 13400 (1.66435 iter/s, 60.0834s/100 iter), loss = 3.18516
I0211 03:42:38.338474 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.6104 (* 1 = 2.6104 loss)
I0211 03:42:38.338491 20163 sgd_solver.cpp:136] Iteration 13400, lr = 0.000622736, m = 0.9
I0211 03:43:40.644613 20163 solver.cpp:314] Iteration 13500 (1.60503 iter/s, 62.304s/100 iter), loss = 3.02805
I0211 03:43:40.644757 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.24215 (* 1 = 3.24215 loss)
I0211 03:43:40.644780 20163 sgd_solver.cpp:136] Iteration 13500, lr = 0.000620402, m = 0.9
I0211 03:44:41.140472 20163 solver.cpp:314] Iteration 13600 (1.65307 iter/s, 60.4937s/100 iter), loss = 3.16356
I0211 03:44:41.141399 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.70804 (* 1 = 2.70804 loss)
I0211 03:44:41.141422 20163 sgd_solver.cpp:136] Iteration 13600, lr = 0.000618075, m = 0.9
I0211 03:45:41.356348 20163 solver.cpp:314] Iteration 13700 (1.66075 iter/s, 60.2137s/100 iter), loss = 3.36174
I0211 03:45:41.356477 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.89518 (* 1 = 2.89518 loss)
I0211 03:45:41.356530 20163 sgd_solver.cpp:136] Iteration 13700, lr = 0.000615755, m = 0.9
I0211 03:46:42.938895 20163 solver.cpp:314] Iteration 13800 (1.6239 iter/s, 61.5803s/100 iter), loss = 3.41821
I0211 03:46:42.939087 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.36031 (* 1 = 3.36031 loss)
I0211 03:46:42.939128 20163 sgd_solver.cpp:136] Iteration 13800, lr = 0.000613441, m = 0.9
I0211 03:47:43.296795 20163 solver.cpp:314] Iteration 13900 (1.65684 iter/s, 60.3557s/100 iter), loss = 3.01429
I0211 03:47:43.296900 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.88577 (* 1 = 2.88577 loss)
I0211 03:47:43.296914 20163 sgd_solver.cpp:136] Iteration 13900, lr = 0.000611134, m = 0.9
I0211 03:48:42.301272 20163 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_14000.caffemodel
I0211 03:48:42.323526 20163 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_14000.solverstate
I0211 03:48:42.333604 20163 solver.cpp:666] Iteration 14000, Testing net (#0)
I0211 03:49:33.512738 20163 solver.cpp:774] class AP 1: 0.37683
I0211 03:49:33.583914 20163 solver.cpp:774] class AP 2: 0.606857
I0211 03:49:33.594593 20163 solver.cpp:774] class AP 3: 0.629221
I0211 03:49:33.594611 20163 solver.cpp:780] Test net output mAP #0: detection_eval = 0.537636
I0211 03:49:36.205952 20164 solver.cpp:774] class AP 1: 0.381075
I0211 03:49:36.271975 20164 solver.cpp:774] class AP 2: 0.617926
I0211 03:49:36.282316 20164 solver.cpp:774] class AP 3: 0.630362
I0211 03:49:36.282330 20164 solver.cpp:780] Test net output mAP #0: detection_eval = 0.543121
I0211 03:49:36.282428 20163 solver.cpp:265] [MultiGPU] Tests completed in 53.9469s
I0211 03:49:36.717396 20163 solver.cpp:314] Iteration 14000 (0.881706 iter/s, 113.416s/100 iter), loss = 2.9299
I0211 03:49:36.717456 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.64141 (* 1 = 2.64141 loss)
I0211 03:49:36.717473 20163 sgd_solver.cpp:136] Iteration 14000, lr = 0.000608833, m = 0.9
I0211 03:50:37.277156 20163 solver.cpp:314] Iteration 14100 (1.65132 iter/s, 60.5576s/100 iter), loss = 2.99059
I0211 03:50:37.277530 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.45864 (* 1 = 2.45864 loss)
I0211 03:50:37.277603 20163 sgd_solver.cpp:136] Iteration 14100, lr = 0.000606539, m = 0.9
I0211 03:51:38.081503 20163 solver.cpp:314] Iteration 14200 (1.64468 iter/s, 60.8021s/100 iter), loss = 2.92337
I0211 03:51:38.081645 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.91438 (* 1 = 2.91438 loss)
I0211 03:51:38.081658 20163 sgd_solver.cpp:136] Iteration 14200, lr = 0.000604251, m = 0.9
I0211 03:52:37.979526 20163 solver.cpp:314] Iteration 14300 (1.66956 iter/s, 59.8959s/100 iter), loss = 3.2206
I0211 03:52:37.979712 20163 solver.cpp:336]     Train net output #0: mbox_loss = 4.63107 (* 1 = 4.63107 loss)
I0211 03:52:37.979753 20163 sgd_solver.cpp:136] Iteration 14300, lr = 0.00060197, m = 0.9
I0211 03:53:38.964308 20163 solver.cpp:314] Iteration 14400 (1.63981 iter/s, 60.9826s/100 iter), loss = 2.94303
I0211 03:53:38.964437 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.78695 (* 1 = 2.78695 loss)
I0211 03:53:38.964452 20163 sgd_solver.cpp:136] Iteration 14400, lr = 0.000599695, m = 0.9
I0211 03:54:39.174043 20163 solver.cpp:314] Iteration 14500 (1.66092 iter/s, 60.2076s/100 iter), loss = 3.14007
I0211 03:54:39.174192 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.12467 (* 1 = 3.12467 loss)
I0211 03:54:39.174207 20163 sgd_solver.cpp:136] Iteration 14500, lr = 0.000597427, m = 0.9
I0211 03:55:38.672940 20163 solver.cpp:314] Iteration 14600 (1.68076 iter/s, 59.4967s/100 iter), loss = 3.08931
I0211 03:55:38.673051 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.12396 (* 1 = 2.12396 loss)
I0211 03:55:38.673066 20163 sgd_solver.cpp:136] Iteration 14600, lr = 0.000595165, m = 0.9
I0211 03:56:38.268887 20163 solver.cpp:314] Iteration 14700 (1.67803 iter/s, 59.5938s/100 iter), loss = 3.26548
I0211 03:56:38.269001 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.54221 (* 1 = 2.54221 loss)
I0211 03:56:38.269016 20163 sgd_solver.cpp:136] Iteration 14700, lr = 0.00059291, m = 0.9
I0211 03:57:39.548565 20163 solver.cpp:314] Iteration 14800 (1.63192 iter/s, 61.2775s/100 iter), loss = 2.90823
I0211 03:57:39.548751 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.90162 (* 1 = 2.90162 loss)
I0211 03:57:39.548794 20163 sgd_solver.cpp:136] Iteration 14800, lr = 0.000590661, m = 0.9
I0211 03:58:41.332612 20163 solver.cpp:314] Iteration 14900 (1.6186 iter/s, 61.7818s/100 iter), loss = 3.27203
I0211 03:58:41.332738 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.79862 (* 1 = 2.79862 loss)
I0211 03:58:41.332763 20163 sgd_solver.cpp:136] Iteration 14900, lr = 0.000588418, m = 0.9
I0211 03:59:02.512944 20123 data_reader.cpp:305] Starting prefetch of epoch 3
I0211 03:59:42.344010 20163 solver.cpp:314] Iteration 15000 (1.6391 iter/s, 61.0092s/100 iter), loss = 2.98492
I0211 03:59:42.344177 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.20621 (* 1 = 3.20621 loss)
I0211 03:59:42.344218 20163 sgd_solver.cpp:136] Iteration 15000, lr = 0.000586182, m = 0.9
I0211 04:00:42.574744 20163 solver.cpp:314] Iteration 15100 (1.66034 iter/s, 60.2285s/100 iter), loss = 2.75925
I0211 04:00:42.575278 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.60741 (* 1 = 2.60741 loss)
I0211 04:00:42.575577 20163 sgd_solver.cpp:136] Iteration 15100, lr = 0.000583952, m = 0.9
I0211 04:01:43.849694 20163 solver.cpp:314] Iteration 15200 (1.63205 iter/s, 61.2727s/100 iter), loss = 3.03558
I0211 04:01:43.849874 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.81745 (* 1 = 2.81745 loss)
I0211 04:01:43.849915 20163 sgd_solver.cpp:136] Iteration 15200, lr = 0.000581728, m = 0.9
I0211 04:02:44.926818 20163 solver.cpp:314] Iteration 15300 (1.63733 iter/s, 61.0749s/100 iter), loss = 3.27779
I0211 04:02:44.926998 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.4307 (* 1 = 3.4307 loss)
I0211 04:02:44.927018 20163 sgd_solver.cpp:136] Iteration 15300, lr = 0.000579511, m = 0.9
I0211 04:03:45.312806 20163 solver.cpp:314] Iteration 15400 (1.65607 iter/s, 60.3838s/100 iter), loss = 3.1698
I0211 04:03:45.312994 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.31866 (* 1 = 3.31866 loss)
I0211 04:03:45.313035 20163 sgd_solver.cpp:136] Iteration 15400, lr = 0.0005773, m = 0.9
I0211 04:04:44.925519 20163 solver.cpp:314] Iteration 15500 (1.67756 iter/s, 59.6105s/100 iter), loss = 3.00853
I0211 04:04:44.925652 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.89272 (* 1 = 2.89272 loss)
I0211 04:04:44.925670 20163 sgd_solver.cpp:136] Iteration 15500, lr = 0.000575096, m = 0.9
I0211 04:05:45.603875 20163 solver.cpp:314] Iteration 15600 (1.64809 iter/s, 60.6762s/100 iter), loss = 3.23144
I0211 04:05:45.604071 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.19077 (* 1 = 3.19077 loss)
I0211 04:05:45.604113 20163 sgd_solver.cpp:136] Iteration 15600, lr = 0.000572898, m = 0.9
I0211 04:06:45.026518 20163 solver.cpp:314] Iteration 15700 (1.68292 iter/s, 59.4205s/100 iter), loss = 3.18994
I0211 04:06:45.026643 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.88552 (* 1 = 2.88552 loss)
I0211 04:06:45.026659 20163 sgd_solver.cpp:136] Iteration 15700, lr = 0.000570706, m = 0.9
I0211 04:07:45.123075 20163 solver.cpp:314] Iteration 15800 (1.66405 iter/s, 60.0944s/100 iter), loss = 3.08223
I0211 04:07:45.123193 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.31271 (* 1 = 2.31271 loss)
I0211 04:07:45.123212 20163 sgd_solver.cpp:136] Iteration 15800, lr = 0.00056852, m = 0.9
I0211 04:08:45.644745 20163 solver.cpp:314] Iteration 15900 (1.65236 iter/s, 60.5195s/100 iter), loss = 3.14527
I0211 04:08:45.644873 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.55488 (* 1 = 3.55488 loss)
I0211 04:08:45.644889 20163 sgd_solver.cpp:136] Iteration 15900, lr = 0.000566341, m = 0.9
I0211 04:09:45.715241 20163 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_16000.caffemodel
I0211 04:09:45.736760 20163 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_16000.solverstate
I0211 04:09:45.753309 20163 solver.cpp:666] Iteration 16000, Testing net (#0)
I0211 04:10:37.467799 20163 solver.cpp:774] class AP 1: 0.34111
I0211 04:10:37.526279 20163 solver.cpp:774] class AP 2: 0.623731
I0211 04:10:37.534533 20163 solver.cpp:774] class AP 3: 0.623751
I0211 04:10:37.534543 20163 solver.cpp:780] Test net output mAP #0: detection_eval = 0.529531
I0211 04:10:38.545835 20164 solver.cpp:774] class AP 1: 0.345013
I0211 04:10:38.613566 20164 solver.cpp:774] class AP 2: 0.620921
I0211 04:10:38.623312 20164 solver.cpp:774] class AP 3: 0.628336
I0211 04:10:38.623330 20164 solver.cpp:780] Test net output mAP #0: detection_eval = 0.531423
I0211 04:10:38.623404 20163 solver.cpp:265] [MultiGPU] Tests completed in 52.8682s
I0211 04:10:39.132306 20163 solver.cpp:314] Iteration 16000 (0.881186 iter/s, 113.483s/100 iter), loss = 3.02202
I0211 04:10:39.132354 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.38236 (* 1 = 2.38236 loss)
I0211 04:10:39.132364 20163 sgd_solver.cpp:136] Iteration 16000, lr = 0.000564168, m = 0.9
I0211 04:11:39.913545 20163 solver.cpp:314] Iteration 16100 (1.6453 iter/s, 60.779s/100 iter), loss = 3.35296
I0211 04:11:39.913671 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.27358 (* 1 = 3.27358 loss)
I0211 04:11:39.913686 20163 sgd_solver.cpp:136] Iteration 16100, lr = 0.000562001, m = 0.9
I0211 04:12:39.863353 20163 solver.cpp:314] Iteration 16200 (1.66812 iter/s, 59.9476s/100 iter), loss = 3.00756
I0211 04:12:39.863515 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.86135 (* 1 = 3.86135 loss)
I0211 04:12:39.863531 20163 sgd_solver.cpp:136] Iteration 16200, lr = 0.000559841, m = 0.9
I0211 04:13:41.675528 20163 solver.cpp:314] Iteration 16300 (1.61786 iter/s, 61.8099s/100 iter), loss = 2.91733
I0211 04:13:41.675649 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.71965 (* 1 = 2.71965 loss)
I0211 04:13:41.675663 20163 sgd_solver.cpp:136] Iteration 16300, lr = 0.000557686, m = 0.9
I0211 04:14:41.864559 20163 solver.cpp:314] Iteration 16400 (1.66149 iter/s, 60.1868s/100 iter), loss = 2.89052
I0211 04:14:41.864686 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.4563 (* 1 = 3.4563 loss)
I0211 04:14:41.864704 20163 sgd_solver.cpp:136] Iteration 16400, lr = 0.000555538, m = 0.9
I0211 04:15:42.921116 20163 solver.cpp:314] Iteration 16500 (1.63789 iter/s, 61.0543s/100 iter), loss = 3.01547
I0211 04:15:42.921237 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.77871 (* 1 = 2.77871 loss)
I0211 04:15:42.921252 20163 sgd_solver.cpp:136] Iteration 16500, lr = 0.000553397, m = 0.9
I0211 04:16:43.887429 20163 solver.cpp:314] Iteration 16600 (1.64031 iter/s, 60.9641s/100 iter), loss = 2.94729
I0211 04:16:43.887558 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.87405 (* 1 = 3.87405 loss)
I0211 04:16:43.887573 20163 sgd_solver.cpp:136] Iteration 16600, lr = 0.000551261, m = 0.9
I0211 04:17:44.273583 20163 solver.cpp:314] Iteration 16700 (1.65607 iter/s, 60.384s/100 iter), loss = 3.17022
I0211 04:17:44.273706 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.59122 (* 1 = 2.59122 loss)
I0211 04:17:44.273722 20163 sgd_solver.cpp:136] Iteration 16700, lr = 0.000549131, m = 0.9
I0211 04:18:45.054697 20163 solver.cpp:314] Iteration 16800 (1.64531 iter/s, 60.7789s/100 iter), loss = 3.09916
I0211 04:18:45.054878 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.40871 (* 1 = 3.40871 loss)
I0211 04:18:45.054920 20163 sgd_solver.cpp:136] Iteration 16800, lr = 0.000547008, m = 0.9
I0211 04:19:45.088582 20163 solver.cpp:314] Iteration 16900 (1.66579 iter/s, 60.0317s/100 iter), loss = 3.00968
I0211 04:19:45.088721 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.12919 (* 1 = 3.12919 loss)
I0211 04:19:45.088744 20163 sgd_solver.cpp:136] Iteration 16900, lr = 0.000544891, m = 0.9
I0211 04:20:44.936573 20163 solver.cpp:314] Iteration 17000 (1.67096 iter/s, 59.8458s/100 iter), loss = 3.20877
I0211 04:20:44.936708 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.80119 (* 1 = 3.80119 loss)
I0211 04:20:44.936729 20163 sgd_solver.cpp:136] Iteration 17000, lr = 0.00054278, m = 0.9
I0211 04:21:46.274585 20163 solver.cpp:314] Iteration 17100 (1.63037 iter/s, 61.3358s/100 iter), loss = 3.08008
I0211 04:21:46.274718 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.2019 (* 1 = 3.2019 loss)
I0211 04:21:46.274735 20163 sgd_solver.cpp:136] Iteration 17100, lr = 0.000540675, m = 0.9
I0211 04:22:46.841998 20163 solver.cpp:314] Iteration 17200 (1.65111 iter/s, 60.5652s/100 iter), loss = 3.18388
I0211 04:22:46.842128 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.6696 (* 1 = 2.6696 loss)
I0211 04:22:46.842144 20163 sgd_solver.cpp:136] Iteration 17200, lr = 0.000538577, m = 0.9
I0211 04:23:47.121201 20163 solver.cpp:314] Iteration 17300 (1.65901 iter/s, 60.277s/100 iter), loss = 3.13566
I0211 04:23:47.121299 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.84162 (* 1 = 3.84162 loss)
I0211 04:23:47.121309 20163 sgd_solver.cpp:136] Iteration 17300, lr = 0.000536484, m = 0.9
I0211 04:24:47.896920 20163 solver.cpp:314] Iteration 17400 (1.64545 iter/s, 60.7735s/100 iter), loss = 3.2893
I0211 04:24:47.897050 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.79933 (* 1 = 2.79933 loss)
I0211 04:24:47.897069 20163 sgd_solver.cpp:136] Iteration 17400, lr = 0.000534398, m = 0.9
I0211 04:25:48.567209 20163 solver.cpp:314] Iteration 17500 (1.64831 iter/s, 60.6681s/100 iter), loss = 2.95788
I0211 04:25:48.567353 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.4682 (* 1 = 2.4682 loss)
I0211 04:25:48.567371 20163 sgd_solver.cpp:136] Iteration 17500, lr = 0.000532317, m = 0.9
I0211 04:26:49.752822 20163 solver.cpp:314] Iteration 17600 (1.63443 iter/s, 61.1834s/100 iter), loss = 2.99538
I0211 04:26:49.752965 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.07467 (* 1 = 3.07467 loss)
I0211 04:26:49.752979 20163 sgd_solver.cpp:136] Iteration 17600, lr = 0.000530243, m = 0.9
I0211 04:27:50.915565 20163 solver.cpp:314] Iteration 17700 (1.63504 iter/s, 61.1605s/100 iter), loss = 2.96716
I0211 04:27:50.915684 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.82196 (* 1 = 2.82196 loss)
I0211 04:27:50.915702 20163 sgd_solver.cpp:136] Iteration 17700, lr = 0.000528175, m = 0.9
I0211 04:28:50.820564 20163 solver.cpp:314] Iteration 17800 (1.66937 iter/s, 59.9028s/100 iter), loss = 3.03853
I0211 04:28:50.820742 20163 solver.cpp:336]     Train net output #0: mbox_loss = 4.80121 (* 1 = 4.80121 loss)
I0211 04:28:50.820785 20163 sgd_solver.cpp:136] Iteration 17800, lr = 0.000526113, m = 0.9
I0211 04:29:51.199604 20163 solver.cpp:314] Iteration 17900 (1.65626 iter/s, 60.3768s/100 iter), loss = 2.93272
I0211 04:29:51.199723 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.02524 (* 1 = 3.02524 loss)
I0211 04:29:51.199738 20163 sgd_solver.cpp:136] Iteration 17900, lr = 0.000524056, m = 0.9
I0211 04:30:50.612967 20163 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_18000.caffemodel
I0211 04:30:50.635085 20163 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_18000.solverstate
I0211 04:30:50.647428 20163 solver.cpp:666] Iteration 18000, Testing net (#0)
I0211 04:31:41.937348 20150 data_reader.cpp:305] Starting prefetch of epoch 4
I0211 04:31:43.062656 20163 solver.cpp:774] class AP 1: 0.389416
I0211 04:31:43.126122 20163 solver.cpp:774] class AP 2: 0.605464
I0211 04:31:43.141255 20163 solver.cpp:774] class AP 3: 0.626549
I0211 04:31:43.141270 20163 solver.cpp:780] Test net output mAP #0: detection_eval = 0.540476
I0211 04:31:43.913214 20164 solver.cpp:774] class AP 1: 0.37299
I0211 04:31:43.974392 20164 solver.cpp:774] class AP 2: 0.605666
I0211 04:31:43.989771 20164 solver.cpp:774] class AP 3: 0.629374
I0211 04:31:43.989784 20164 solver.cpp:780] Test net output mAP #0: detection_eval = 0.53601
I0211 04:31:43.989902 20163 solver.cpp:265] [MultiGPU] Tests completed in 53.3405s
I0211 04:31:44.324466 20163 solver.cpp:314] Iteration 18000 (0.884011 iter/s, 113.121s/100 iter), loss = 2.98596
I0211 04:31:44.324635 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.78395 (* 1 = 2.78395 loss)
I0211 04:31:44.324677 20163 sgd_solver.cpp:136] Iteration 18000, lr = 0.000522006, m = 0.9
I0211 04:32:44.270139 20163 solver.cpp:314] Iteration 18100 (1.66824 iter/s, 59.9435s/100 iter), loss = 3.16079
I0211 04:32:44.270269 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.529 (* 1 = 3.529 loss)
I0211 04:32:44.270288 20163 sgd_solver.cpp:136] Iteration 18100, lr = 0.000519962, m = 0.9
I0211 04:33:45.029958 20163 solver.cpp:314] Iteration 18200 (1.64588 iter/s, 60.7576s/100 iter), loss = 3.16238
I0211 04:33:45.030094 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.98116 (* 1 = 2.98116 loss)
I0211 04:33:45.030114 20163 sgd_solver.cpp:136] Iteration 18200, lr = 0.000517924, m = 0.9
I0211 04:34:44.741509 20163 solver.cpp:314] Iteration 18300 (1.67478 iter/s, 59.7094s/100 iter), loss = 2.90845
I0211 04:34:44.741638 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.51948 (* 1 = 2.51948 loss)
I0211 04:34:44.741654 20163 sgd_solver.cpp:136] Iteration 18300, lr = 0.000515892, m = 0.9
I0211 04:35:45.354982 20163 solver.cpp:314] Iteration 18400 (1.64986 iter/s, 60.6113s/100 iter), loss = 3.19691
I0211 04:35:45.355345 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.51031 (* 1 = 2.51031 loss)
I0211 04:35:45.355415 20163 sgd_solver.cpp:136] Iteration 18400, lr = 0.000513866, m = 0.9
I0211 04:36:46.129719 20163 solver.cpp:314] Iteration 18500 (1.64548 iter/s, 60.7725s/100 iter), loss = 3.34724
I0211 04:36:46.129848 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.07808 (* 1 = 3.07808 loss)
I0211 04:36:46.129861 20163 sgd_solver.cpp:136] Iteration 18500, lr = 0.000511846, m = 0.9
I0211 04:37:46.804563 20163 solver.cpp:314] Iteration 18600 (1.64819 iter/s, 60.6726s/100 iter), loss = 3.07662
I0211 04:37:46.804821 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.6448 (* 1 = 2.6448 loss)
I0211 04:37:46.804842 20163 sgd_solver.cpp:136] Iteration 18600, lr = 0.000509832, m = 0.9
I0211 04:38:46.608597 20163 solver.cpp:314] Iteration 18700 (1.67219 iter/s, 59.8019s/100 iter), loss = 2.87541
I0211 04:38:46.608726 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.01401 (* 1 = 2.01401 loss)
I0211 04:38:46.608747 20163 sgd_solver.cpp:136] Iteration 18700, lr = 0.000507823, m = 0.9
I0211 04:39:46.769183 20163 solver.cpp:314] Iteration 18800 (1.66228 iter/s, 60.1584s/100 iter), loss = 2.95444
I0211 04:39:46.769281 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.07254 (* 1 = 3.07254 loss)
I0211 04:39:46.769297 20163 sgd_solver.cpp:136] Iteration 18800, lr = 0.000505821, m = 0.9
I0211 04:40:47.505226 20163 solver.cpp:314] Iteration 18900 (1.64653 iter/s, 60.7338s/100 iter), loss = 3.18552
I0211 04:40:47.505342 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.39239 (* 1 = 3.39239 loss)
I0211 04:40:47.505355 20163 sgd_solver.cpp:136] Iteration 18900, lr = 0.000503825, m = 0.9
I0211 04:41:47.997584 20163 solver.cpp:314] Iteration 19000 (1.65316 iter/s, 60.4902s/100 iter), loss = 3.03851
I0211 04:41:47.997710 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.67998 (* 1 = 3.67998 loss)
I0211 04:41:47.997725 20163 sgd_solver.cpp:136] Iteration 19000, lr = 0.000501835, m = 0.9
I0211 04:42:48.181597 20163 solver.cpp:314] Iteration 19100 (1.66163 iter/s, 60.1818s/100 iter), loss = 3.10369
I0211 04:42:48.181731 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.93909 (* 1 = 2.93909 loss)
I0211 04:42:48.181748 20163 sgd_solver.cpp:136] Iteration 19100, lr = 0.00049985, m = 0.9
I0211 04:43:50.882697 20163 solver.cpp:314] Iteration 19200 (1.59493 iter/s, 62.6988s/100 iter), loss = 2.93829
I0211 04:43:50.882879 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.96504 (* 1 = 3.96504 loss)
I0211 04:43:50.882895 20163 sgd_solver.cpp:136] Iteration 19200, lr = 0.000497871, m = 0.9
I0211 04:44:52.272574 20163 solver.cpp:314] Iteration 19300 (1.62899 iter/s, 61.3876s/100 iter), loss = 2.97091
I0211 04:44:52.276623 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.38964 (* 1 = 3.38964 loss)
I0211 04:44:52.276667 20163 sgd_solver.cpp:136] Iteration 19300, lr = 0.000495899, m = 0.9
I0211 04:45:53.751521 20163 solver.cpp:314] Iteration 19400 (1.62663 iter/s, 61.4767s/100 iter), loss = 3.06116
I0211 04:45:53.751643 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.90813 (* 1 = 2.90813 loss)
I0211 04:45:53.751659 20163 sgd_solver.cpp:136] Iteration 19400, lr = 0.000493932, m = 0.9
I0211 04:46:55.205557 20163 solver.cpp:314] Iteration 19500 (1.62729 iter/s, 61.4518s/100 iter), loss = 3.27495
I0211 04:46:55.205679 20163 solver.cpp:336]     Train net output #0: mbox_loss = 2.99868 (* 1 = 2.99868 loss)
I0211 04:46:55.205695 20163 sgd_solver.cpp:136] Iteration 19500, lr = 0.000491971, m = 0.9
I0211 04:47:54.572712 20163 solver.cpp:314] Iteration 19600 (1.68449 iter/s, 59.365s/100 iter), loss = 3.05064
I0211 04:47:54.572916 20163 solver.cpp:336]     Train net output #0: mbox_loss = 3.20995 (* 1 = 3.20995 loss)
I0211 04:47:54.572957 20163 sgd_solver.cpp:136] Iteration 19600, lr = 0.000490016, m = 0.9
I0212 09:45:42.074906 12230 caffe.cpp:807] This is NVCaffe 0.16.4 started at Mon Feb 12 09:45:41 2018
I0212 09:45:42.075137 12230 caffe.cpp:810] CuDNN version: 6021
I0212 09:45:42.075147 12230 caffe.cpp:811] CuBLAS version: 8000
I0212 09:45:42.075152 12230 caffe.cpp:812] CUDA version: 8000
I0212 09:45:42.075156 12230 caffe.cpp:813] CUDA driver version: 8000
I0212 09:45:42.630770 12230 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0212 09:45:42.631448 12230 gpu_memory.cpp:161] Total memory: 8504279040, Free: 8298037248, dev_info[0]: total=8504279040 free=8298037248
I0212 09:45:42.632038 12230 gpu_memory.cpp:161] Total memory: 8507555840, Free: 8298037248, dev_info[1]: total=8507555840 free=8378646528
I0212 09:45:42.632056 12230 caffe.cpp:214] Using GPUs 0, 1
I0212 09:45:42.632344 12230 caffe.cpp:219] GPU 0: GeForce GTX 1080
I0212 09:45:42.632627 12230 caffe.cpp:219] GPU 1: GeForce GTX 1080
I0212 09:45:42.642336 12230 solver.cpp:43] Solver data type: FLOAT
I0212 09:45:42.642436 12230 solver.cpp:46] Initializing solver from parameters: 
train_net: "training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/train.prototxt"
test_net: "training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/test.prototxt"
test_iter: 452
test_interval: 2000
base_lr: 0.001
display: 100
max_iter: 120000
lr_policy: "poly"
gamma: 0.1
power: 4
momentum: 0.9
weight_decay: 0.0005
snapshot: 2000
snapshot_prefix: "training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
snapshot_after_train: true
test_initialization: true
average_loss: 10
stepvalue: 60000
stepvalue: 90000
stepvalue: 200000
iter_size: 2
type: "SGD"
eval_type: "detection"
ap_version: "11point"
show_per_class_result: true
I0212 09:45:42.751600 12230 solver.cpp:78] Creating training net from train_net file: training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/train.prototxt
I0212 09:45:42.775455 12230 net.cpp:72] Initializing net from parameters: 
name: "ssdJacintoNetV2"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 0
    mean_value: 0
    mean_value: 0
    force_color: false
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 368
      width: 720
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: NEAREST
      interp_mode: CUBIC
      interp_mode: LANCZOS4
    }
    emit_constraint {
      emit_type: CENTER
    }
    crop_h: 368
    crop_w: 720
    distort_param {
      brightness_prob: 0.5
      brightness_delta: 32
      contrast_prob: 0.5
      contrast_lower: 0.5
      contrast_upper: 1.5
      hue_prob: 0.5
      hue_delta: 18
      saturation_prob: 0.5
      saturation_lower: 0.5
      saturation_upper: 1.5
      random_order_prob: 0
    }
    expand_param {
      prob: 0.5
      max_expand_ratio: 4
    }
  }
  data_param {
    source: "/user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb"
    batch_size: 8
    backend: LMDB
    threads: 4
    parser_threads: 4
  }
  annotated_data_param {
    batch_sampler {
      max_sample: 1
      max_trials: 1
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.1
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.3
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.5
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.7
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.9
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        max_jaccard_overlap: 1
      }
      max_sample: 1
      max_trials: 50
    }
    label_map_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/labelmap.prototxt"
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "pool6"
  top: "pool7"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool8"
  type: "Pooling"
  bottom: "pool7"
  top: "pool8"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool9"
  type: "Pooling"
  bottom: "pool8"
  top: "pool9"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "ctx_output1"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "ctx_output1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu"
  type: "ReLU"
  bottom: "ctx_output1"
  top: "ctx_output1"
}
layer {
  name: "ctx_output2"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "ctx_output2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu"
  type: "ReLU"
  bottom: "ctx_output2"
  top: "ctx_output2"
}
layer {
  name: "ctx_output3"
  type: "Convolution"
  bottom: "pool6"
  top: "ctx_output3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu"
  type: "ReLU"
  bottom: "ctx_output3"
  top: "ctx_output3"
}
layer {
  name: "ctx_output4"
  type: "Convolution"
  bottom: "pool7"
  top: "ctx_output4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu"
  type: "ReLU"
  bottom: "ctx_output4"
  top: "ctx_output4"
}
layer {
  name: "ctx_output5"
  type: "Convolution"
  bottom: "pool8"
  top: "ctx_output5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu"
  type: "ReLU"
  bottom: "ctx_output5"
  top: "ctx_output5"
}
layer {
  name: "ctx_output6"
  type: "Convolution"
  bottom: "pool9"
  top: "ctx_output6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu"
  type: "ReLU"
  bottom: "ctx_output6"
  top: "ctx_output6"
}
layer {
  name: "ctx_output1/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_loc"
  top: "ctx_output1/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_loc_perm"
  top: "ctx_output1/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_conf"
  top: "ctx_output1/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_conf_perm"
  top: "ctx_output1/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output1"
  bottom: "data"
  top: "ctx_output1/relu_mbox_priorbox"
  prior_box_param {
    min_size: 14.72
    max_size: 36.8
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_loc"
  top: "ctx_output2/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_loc_perm"
  top: "ctx_output2/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_conf"
  top: "ctx_output2/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_conf_perm"
  top: "ctx_output2/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output2"
  bottom: "data"
  top: "ctx_output2/relu_mbox_priorbox"
  prior_box_param {
    min_size: 36.8
    max_size: 110.4
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_loc"
  top: "ctx_output3/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_loc_perm"
  top: "ctx_output3/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_conf"
  top: "ctx_output3/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_conf_perm"
  top: "ctx_output3/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output3"
  bottom: "data"
  top: "ctx_output3/relu_mbox_priorbox"
  prior_box_param {
    min_size: 110.4
    max_size: 184
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_loc"
  top: "ctx_output4/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_loc_perm"
  top: "ctx_output4/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_conf"
  top: "ctx_output4/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_conf_perm"
  top: "ctx_output4/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output4"
  bottom: "data"
  top: "ctx_output4/relu_mbox_priorbox"
  prior_box_param {
    min_size: 184
    max_size: 257.6
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_loc"
  top: "ctx_output5/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_loc_perm"
  top: "ctx_output5/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_conf"
  top: "ctx_output5/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_conf_perm"
  top: "ctx_output5/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output5"
  bottom: "data"
  top: "ctx_output5/relu_mbox_priorbox"
  prior_box_param {
    min_size: 257.6
    max_size: 331.2
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_loc"
  top: "ctx_output6/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_loc_perm"
  top: "ctx_output6/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_conf"
  top: "ctx_output6/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_conf_perm"
  top: "ctx_output6/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output6"
  bottom: "data"
  top: "ctx_output6/relu_mbox_priorbox"
  prior_box_param {
    min_size: 331.2
    max_size: 404.8
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_loc_flat"
  bottom: "ctx_output2/relu_mbox_loc_flat"
  bottom: "ctx_output3/relu_mbox_loc_flat"
  bottom: "ctx_output4/relu_mbox_loc_flat"
  bottom: "ctx_output5/relu_mbox_loc_flat"
  bottom: "ctx_output6/relu_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_conf_flat"
  bottom: "ctx_output2/relu_mbox_conf_flat"
  bottom: "ctx_output3/relu_mbox_conf_flat"
  bottom: "ctx_output4/relu_mbox_conf_flat"
  bottom: "ctx_output5/relu_mbox_conf_flat"
  bottom: "ctx_output6/relu_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_priorbox"
  bottom: "ctx_output2/relu_mbox_priorbox"
  bottom: "ctx_output3/relu_mbox_priorbox"
  bottom: "ctx_output4/relu_mbox_priorbox"
  bottom: "ctx_output5/relu_mbox_priorbox"
  bottom: "ctx_output6/relu_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_loss"
  type: "MultiBoxLoss"
  bottom: "mbox_loc"
  bottom: "mbox_conf"
  bottom: "mbox_priorbox"
  bottom: "label"
  top: "mbox_loss"
  include {
    phase: TRAIN
  }
  propagate_down: true
  propagate_down: true
  propagate_down: false
  propagate_down: false
  loss_param {
    normalization: VALID
  }
  multibox_loss_param {
    loc_loss_type: SMOOTH_L1
    conf_loss_type: SOFTMAX
    loc_weight: 1
    num_classes: 4
    share_location: true
    match_type: PER_PREDICTION
    overlap_threshold: 0.5
    use_prior_for_matching: true
    background_label_id: 0
    use_difficult_gt: false
    neg_pos_ratio: 3
    neg_overlap: 0.5
    code_type: CENTER_SIZE
    ignore_cross_boundary_bbox: false
    mining_type: MAX_NEGATIVE
  }
}
I0212 09:45:42.777536 12230 net.cpp:104] Using FLOAT as default forward math type
I0212 09:45:42.777562 12230 net.cpp:110] Using FLOAT as default backward math type
I0212 09:45:42.777572 12230 layer_factory.hpp:136] Creating layer 'data' of type 'AnnotatedData'
I0212 09:45:42.777587 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:42.790622 12230 net.cpp:184] Created Layer data (0)
I0212 09:45:42.790660 12230 net.cpp:530] data -> data
I0212 09:45:42.790691 12230 net.cpp:530] data -> label
I0212 09:45:42.790798 12230 data_reader.cpp:58] Data Reader threads: 4, out queues: 16, depth: 8
I0212 09:45:42.790910 12230 internal_thread.cpp:19] Starting 4 internal thread(s) on device 0
I0212 09:45:42.835440 12276 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0212 09:45:42.835441 12274 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0212 09:45:42.835503 12277 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0212 09:45:42.835464 12275 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0212 09:45:43.157524 12230 annotated_data_layer.cpp:219] output data size: 8,3,368,720
I0212 09:45:43.158138 12230 annotated_data_layer.cpp:265] [0] Output data size: 8, 3, 368, 720
I0212 09:45:43.158239 12230 internal_thread.cpp:19] Starting 4 internal thread(s) on device 0
I0212 09:45:43.159171 12230 net.cpp:245] Setting up data
I0212 09:45:43.159216 12230 net.cpp:252] TRAIN Top shape for layer 0 'data' 8 3 368 720 (6359040)
I0212 09:45:43.159235 12230 net.cpp:252] TRAIN Top shape for layer 0 'data' 1 1 10 8 (80)
I0212 09:45:43.159250 12230 layer_factory.hpp:136] Creating layer 'data_data_0_split' of type 'Split'
I0212 09:45:43.159262 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:43.182400 12230 net.cpp:184] Created Layer data_data_0_split (1)
I0212 09:45:43.182440 12230 net.cpp:561] data_data_0_split <- data
I0212 09:45:43.182464 12230 net.cpp:530] data_data_0_split -> data_data_0_split_0
I0212 09:45:43.182482 12230 net.cpp:530] data_data_0_split -> data_data_0_split_1
I0212 09:45:43.182495 12230 net.cpp:530] data_data_0_split -> data_data_0_split_2
I0212 09:45:43.182508 12230 net.cpp:530] data_data_0_split -> data_data_0_split_3
I0212 09:45:43.182519 12230 net.cpp:530] data_data_0_split -> data_data_0_split_4
I0212 09:45:43.182530 12230 net.cpp:530] data_data_0_split -> data_data_0_split_5
I0212 09:45:43.182541 12230 net.cpp:530] data_data_0_split -> data_data_0_split_6
I0212 09:45:43.182863 12230 net.cpp:245] Setting up data_data_0_split
I0212 09:45:43.182885 12230 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 368 720 (6359040)
I0212 09:45:43.182898 12230 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 368 720 (6359040)
I0212 09:45:43.182906 12230 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 368 720 (6359040)
I0212 09:45:43.182915 12230 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 368 720 (6359040)
I0212 09:45:43.182924 12230 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 368 720 (6359040)
I0212 09:45:43.182934 12230 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 368 720 (6359040)
I0212 09:45:43.182941 12230 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 368 720 (6359040)
I0212 09:45:43.182950 12230 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0212 09:45:43.182960 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:43.183545 12230 net.cpp:184] Created Layer data/bias (2)
I0212 09:45:43.183578 12230 net.cpp:561] data/bias <- data_data_0_split_0
I0212 09:45:43.183593 12230 net.cpp:530] data/bias -> data/bias
I0212 09:45:43.188783 12230 net.cpp:245] Setting up data/bias
I0212 09:45:43.188828 12230 net.cpp:252] TRAIN Top shape for layer 2 'data/bias' 8 3 368 720 (6359040)
I0212 09:45:43.188858 12230 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0212 09:45:43.188871 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:43.189462 12230 net.cpp:184] Created Layer conv1a (3)
I0212 09:45:43.189498 12230 net.cpp:561] conv1a <- data/bias
I0212 09:45:43.189514 12230 net.cpp:530] conv1a -> conv1a
I0212 09:45:45.664588 12230 net.cpp:245] Setting up conv1a
I0212 09:45:45.664651 12230 net.cpp:252] TRAIN Top shape for layer 3 'conv1a' 8 32 184 360 (16957440)
I0212 09:45:45.664687 12230 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0212 09:45:45.664702 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.676620 12230 net.cpp:184] Created Layer conv1a/bn (4)
I0212 09:45:45.676661 12230 net.cpp:561] conv1a/bn <- conv1a
I0212 09:45:45.676677 12230 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0212 09:45:45.680019 12230 net.cpp:245] Setting up conv1a/bn
I0212 09:45:45.680063 12230 net.cpp:252] TRAIN Top shape for layer 4 'conv1a/bn' 8 32 184 360 (16957440)
I0212 09:45:45.680099 12230 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0212 09:45:45.680112 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.680130 12230 net.cpp:184] Created Layer conv1a/relu (5)
I0212 09:45:45.680146 12230 net.cpp:561] conv1a/relu <- conv1a
I0212 09:45:45.680160 12230 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0212 09:45:45.680193 12230 net.cpp:245] Setting up conv1a/relu
I0212 09:45:45.680207 12230 net.cpp:252] TRAIN Top shape for layer 5 'conv1a/relu' 8 32 184 360 (16957440)
I0212 09:45:45.680217 12230 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0212 09:45:45.680228 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.680260 12230 net.cpp:184] Created Layer conv1b (6)
I0212 09:45:45.680280 12230 net.cpp:561] conv1b <- conv1a
I0212 09:45:45.680292 12230 net.cpp:530] conv1b -> conv1b
I0212 09:45:45.683184 12230 net.cpp:245] Setting up conv1b
I0212 09:45:45.683223 12230 net.cpp:252] TRAIN Top shape for layer 6 'conv1b' 8 32 184 360 (16957440)
I0212 09:45:45.683249 12230 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0212 09:45:45.683261 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.683284 12230 net.cpp:184] Created Layer conv1b/bn (7)
I0212 09:45:45.683295 12230 net.cpp:561] conv1b/bn <- conv1b
I0212 09:45:45.683307 12230 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0212 09:45:45.684922 12230 net.cpp:245] Setting up conv1b/bn
I0212 09:45:45.684952 12230 net.cpp:252] TRAIN Top shape for layer 7 'conv1b/bn' 8 32 184 360 (16957440)
I0212 09:45:45.684976 12230 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0212 09:45:45.684988 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.685003 12230 net.cpp:184] Created Layer conv1b/relu (8)
I0212 09:45:45.685014 12230 net.cpp:561] conv1b/relu <- conv1b
I0212 09:45:45.685024 12230 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0212 09:45:45.685039 12230 net.cpp:245] Setting up conv1b/relu
I0212 09:45:45.685050 12230 net.cpp:252] TRAIN Top shape for layer 8 'conv1b/relu' 8 32 184 360 (16957440)
I0212 09:45:45.685060 12230 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0212 09:45:45.685070 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.688344 12230 net.cpp:184] Created Layer pool1 (9)
I0212 09:45:45.688380 12230 net.cpp:561] pool1 <- conv1b
I0212 09:45:45.688396 12230 net.cpp:530] pool1 -> pool1
I0212 09:45:45.694411 12230 net.cpp:245] Setting up pool1
I0212 09:45:45.694450 12230 net.cpp:252] TRAIN Top shape for layer 9 'pool1' 8 32 92 180 (4239360)
I0212 09:45:45.694465 12230 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0212 09:45:45.694478 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.694506 12230 net.cpp:184] Created Layer res2a_branch2a (10)
I0212 09:45:45.694516 12230 net.cpp:561] res2a_branch2a <- pool1
I0212 09:45:45.694528 12230 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0212 09:45:45.699193 12230 net.cpp:245] Setting up res2a_branch2a
I0212 09:45:45.699231 12230 net.cpp:252] TRAIN Top shape for layer 10 'res2a_branch2a' 8 64 92 180 (8478720)
I0212 09:45:45.699256 12230 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0212 09:45:45.699268 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.699312 12230 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0212 09:45:45.699326 12230 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0212 09:45:45.699337 12230 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0212 09:45:45.701640 12230 net.cpp:245] Setting up res2a_branch2a/bn
I0212 09:45:45.701675 12230 net.cpp:252] TRAIN Top shape for layer 11 'res2a_branch2a/bn' 8 64 92 180 (8478720)
I0212 09:45:45.701702 12230 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0212 09:45:45.701714 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.701728 12230 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0212 09:45:45.701738 12230 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0212 09:45:45.701750 12230 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0212 09:45:45.701766 12230 net.cpp:245] Setting up res2a_branch2a/relu
I0212 09:45:45.701776 12230 net.cpp:252] TRAIN Top shape for layer 12 'res2a_branch2a/relu' 8 64 92 180 (8478720)
I0212 09:45:45.701786 12230 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0212 09:45:45.701795 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.701820 12230 net.cpp:184] Created Layer res2a_branch2b (13)
I0212 09:45:45.701838 12230 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0212 09:45:45.701848 12230 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0212 09:45:45.705178 12230 net.cpp:245] Setting up res2a_branch2b
I0212 09:45:45.705214 12230 net.cpp:252] TRAIN Top shape for layer 13 'res2a_branch2b' 8 64 92 180 (8478720)
I0212 09:45:45.705233 12230 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0212 09:45:45.705245 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.705265 12230 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0212 09:45:45.705274 12230 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0212 09:45:45.705286 12230 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0212 09:45:45.706921 12230 net.cpp:245] Setting up res2a_branch2b/bn
I0212 09:45:45.706951 12230 net.cpp:252] TRAIN Top shape for layer 14 'res2a_branch2b/bn' 8 64 92 180 (8478720)
I0212 09:45:45.706975 12230 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0212 09:45:45.706986 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.707000 12230 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0212 09:45:45.707010 12230 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0212 09:45:45.707020 12230 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0212 09:45:45.707036 12230 net.cpp:245] Setting up res2a_branch2b/relu
I0212 09:45:45.707046 12230 net.cpp:252] TRAIN Top shape for layer 15 'res2a_branch2b/relu' 8 64 92 180 (8478720)
I0212 09:45:45.707056 12230 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0212 09:45:45.707064 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.707082 12230 net.cpp:184] Created Layer pool2 (16)
I0212 09:45:45.707092 12230 net.cpp:561] pool2 <- res2a_branch2b
I0212 09:45:45.707103 12230 net.cpp:530] pool2 -> pool2
I0212 09:45:45.707273 12230 net.cpp:245] Setting up pool2
I0212 09:45:45.707293 12230 net.cpp:252] TRAIN Top shape for layer 16 'pool2' 8 64 46 90 (2119680)
I0212 09:45:45.707304 12230 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0212 09:45:45.707314 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.707340 12230 net.cpp:184] Created Layer res3a_branch2a (17)
I0212 09:45:45.707350 12230 net.cpp:561] res3a_branch2a <- pool2
I0212 09:45:45.707360 12230 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0212 09:45:45.713333 12230 net.cpp:245] Setting up res3a_branch2a
I0212 09:45:45.713393 12230 net.cpp:252] TRAIN Top shape for layer 17 'res3a_branch2a' 8 128 46 90 (4239360)
I0212 09:45:45.713414 12230 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0212 09:45:45.713425 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.713444 12230 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0212 09:45:45.713454 12230 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0212 09:45:45.713465 12230 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0212 09:45:45.715042 12230 net.cpp:245] Setting up res3a_branch2a/bn
I0212 09:45:45.715071 12230 net.cpp:252] TRAIN Top shape for layer 18 'res3a_branch2a/bn' 8 128 46 90 (4239360)
I0212 09:45:45.715101 12230 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0212 09:45:45.715111 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.715124 12230 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0212 09:45:45.715133 12230 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0212 09:45:45.715143 12230 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0212 09:45:45.715157 12230 net.cpp:245] Setting up res3a_branch2a/relu
I0212 09:45:45.715168 12230 net.cpp:252] TRAIN Top shape for layer 19 'res3a_branch2a/relu' 8 128 46 90 (4239360)
I0212 09:45:45.715176 12230 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0212 09:45:45.715184 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.715209 12230 net.cpp:184] Created Layer res3a_branch2b (20)
I0212 09:45:45.715227 12230 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0212 09:45:45.715237 12230 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0212 09:45:45.718413 12230 net.cpp:245] Setting up res3a_branch2b
I0212 09:45:45.718442 12230 net.cpp:252] TRAIN Top shape for layer 20 'res3a_branch2b' 8 128 46 90 (4239360)
I0212 09:45:45.718459 12230 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0212 09:45:45.718469 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.718487 12230 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0212 09:45:45.718497 12230 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0212 09:45:45.718508 12230 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0212 09:45:45.719971 12230 net.cpp:245] Setting up res3a_branch2b/bn
I0212 09:45:45.719998 12230 net.cpp:252] TRAIN Top shape for layer 21 'res3a_branch2b/bn' 8 128 46 90 (4239360)
I0212 09:45:45.720019 12230 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0212 09:45:45.720031 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.720042 12230 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0212 09:45:45.720052 12230 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0212 09:45:45.720060 12230 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0212 09:45:45.720073 12230 net.cpp:245] Setting up res3a_branch2b/relu
I0212 09:45:45.720084 12230 net.cpp:252] TRAIN Top shape for layer 22 'res3a_branch2b/relu' 8 128 46 90 (4239360)
I0212 09:45:45.720093 12230 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0212 09:45:45.720100 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.720111 12230 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (23)
I0212 09:45:45.720120 12230 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0212 09:45:45.720129 12230 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0212 09:45:45.720141 12230 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0212 09:45:45.720260 12230 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0212 09:45:45.720306 12230 net.cpp:252] TRAIN Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 8 128 46 90 (4239360)
I0212 09:45:45.720319 12230 net.cpp:252] TRAIN Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 8 128 46 90 (4239360)
I0212 09:45:45.720327 12230 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0212 09:45:45.720337 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.720353 12230 net.cpp:184] Created Layer pool3 (24)
I0212 09:45:45.720367 12230 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0212 09:45:45.720377 12230 net.cpp:530] pool3 -> pool3
I0212 09:45:45.720528 12230 net.cpp:245] Setting up pool3
I0212 09:45:45.720547 12230 net.cpp:252] TRAIN Top shape for layer 24 'pool3' 8 128 23 45 (1059840)
I0212 09:45:45.720557 12230 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0212 09:45:45.720566 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.720589 12230 net.cpp:184] Created Layer res4a_branch2a (25)
I0212 09:45:45.720602 12230 net.cpp:561] res4a_branch2a <- pool3
I0212 09:45:45.720612 12230 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0212 09:45:45.741418 12230 net.cpp:245] Setting up res4a_branch2a
I0212 09:45:45.741451 12230 net.cpp:252] TRAIN Top shape for layer 25 'res4a_branch2a' 8 256 23 45 (2119680)
I0212 09:45:45.741467 12230 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0212 09:45:45.741477 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.741494 12230 net.cpp:184] Created Layer res4a_branch2a/bn (26)
I0212 09:45:45.741503 12230 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0212 09:45:45.741513 12230 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0212 09:45:45.742854 12230 net.cpp:245] Setting up res4a_branch2a/bn
I0212 09:45:45.742879 12230 net.cpp:252] TRAIN Top shape for layer 26 'res4a_branch2a/bn' 8 256 23 45 (2119680)
I0212 09:45:45.742900 12230 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0212 09:45:45.742909 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.742920 12230 net.cpp:184] Created Layer res4a_branch2a/relu (27)
I0212 09:45:45.742929 12230 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0212 09:45:45.742938 12230 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0212 09:45:45.742950 12230 net.cpp:245] Setting up res4a_branch2a/relu
I0212 09:45:45.742959 12230 net.cpp:252] TRAIN Top shape for layer 27 'res4a_branch2a/relu' 8 256 23 45 (2119680)
I0212 09:45:45.742967 12230 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0212 09:45:45.742974 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.742995 12230 net.cpp:184] Created Layer res4a_branch2b (28)
I0212 09:45:45.743003 12230 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0212 09:45:45.743011 12230 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0212 09:45:45.751979 12230 net.cpp:245] Setting up res4a_branch2b
I0212 09:45:45.752010 12230 net.cpp:252] TRAIN Top shape for layer 28 'res4a_branch2b' 8 256 23 45 (2119680)
I0212 09:45:45.752024 12230 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0212 09:45:45.752033 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.752049 12230 net.cpp:184] Created Layer res4a_branch2b/bn (29)
I0212 09:45:45.752058 12230 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0212 09:45:45.752066 12230 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0212 09:45:45.753293 12230 net.cpp:245] Setting up res4a_branch2b/bn
I0212 09:45:45.753314 12230 net.cpp:252] TRAIN Top shape for layer 29 'res4a_branch2b/bn' 8 256 23 45 (2119680)
I0212 09:45:45.753351 12230 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0212 09:45:45.753362 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.753373 12230 net.cpp:184] Created Layer res4a_branch2b/relu (30)
I0212 09:45:45.753381 12230 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0212 09:45:45.753389 12230 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0212 09:45:45.753401 12230 net.cpp:245] Setting up res4a_branch2b/relu
I0212 09:45:45.753410 12230 net.cpp:252] TRAIN Top shape for layer 30 'res4a_branch2b/relu' 8 256 23 45 (2119680)
I0212 09:45:45.753417 12230 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0212 09:45:45.753424 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.753437 12230 net.cpp:184] Created Layer pool4 (31)
I0212 09:45:45.753444 12230 net.cpp:561] pool4 <- res4a_branch2b
I0212 09:45:45.753453 12230 net.cpp:530] pool4 -> pool4
I0212 09:45:45.753587 12230 net.cpp:245] Setting up pool4
I0212 09:45:45.753603 12230 net.cpp:252] TRAIN Top shape for layer 31 'pool4' 8 256 12 23 (565248)
I0212 09:45:45.753612 12230 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0212 09:45:45.753618 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.753645 12230 net.cpp:184] Created Layer res5a_branch2a (32)
I0212 09:45:45.753659 12230 net.cpp:561] res5a_branch2a <- pool4
I0212 09:45:45.753669 12230 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0212 09:45:45.812896 12230 net.cpp:245] Setting up res5a_branch2a
I0212 09:45:45.812933 12230 net.cpp:252] TRAIN Top shape for layer 32 'res5a_branch2a' 8 512 12 23 (1130496)
I0212 09:45:45.812948 12230 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0212 09:45:45.812959 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.812976 12230 net.cpp:184] Created Layer res5a_branch2a/bn (33)
I0212 09:45:45.812984 12230 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0212 09:45:45.812994 12230 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0212 09:45:45.813980 12230 net.cpp:245] Setting up res5a_branch2a/bn
I0212 09:45:45.813998 12230 net.cpp:252] TRAIN Top shape for layer 33 'res5a_branch2a/bn' 8 512 12 23 (1130496)
I0212 09:45:45.814013 12230 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0212 09:45:45.814021 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.814029 12230 net.cpp:184] Created Layer res5a_branch2a/relu (34)
I0212 09:45:45.814036 12230 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0212 09:45:45.814043 12230 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0212 09:45:45.814054 12230 net.cpp:245] Setting up res5a_branch2a/relu
I0212 09:45:45.814060 12230 net.cpp:252] TRAIN Top shape for layer 34 'res5a_branch2a/relu' 8 512 12 23 (1130496)
I0212 09:45:45.814065 12230 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0212 09:45:45.814072 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.814101 12230 net.cpp:184] Created Layer res5a_branch2b (35)
I0212 09:45:45.814108 12230 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0212 09:45:45.814116 12230 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0212 09:45:45.839006 12230 net.cpp:245] Setting up res5a_branch2b
I0212 09:45:45.839035 12230 net.cpp:252] TRAIN Top shape for layer 35 'res5a_branch2b' 8 512 12 23 (1130496)
I0212 09:45:45.839054 12230 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0212 09:45:45.839062 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.839076 12230 net.cpp:184] Created Layer res5a_branch2b/bn (36)
I0212 09:45:45.839082 12230 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0212 09:45:45.839109 12230 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0212 09:45:45.840015 12230 net.cpp:245] Setting up res5a_branch2b/bn
I0212 09:45:45.840031 12230 net.cpp:252] TRAIN Top shape for layer 36 'res5a_branch2b/bn' 8 512 12 23 (1130496)
I0212 09:45:45.840045 12230 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0212 09:45:45.840052 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.840060 12230 net.cpp:184] Created Layer res5a_branch2b/relu (37)
I0212 09:45:45.840066 12230 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0212 09:45:45.840073 12230 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0212 09:45:45.840082 12230 net.cpp:245] Setting up res5a_branch2b/relu
I0212 09:45:45.840088 12230 net.cpp:252] TRAIN Top shape for layer 37 'res5a_branch2b/relu' 8 512 12 23 (1130496)
I0212 09:45:45.840093 12230 layer_factory.hpp:136] Creating layer 'res5a_branch2b_res5a_branch2b/relu_0_split' of type 'Split'
I0212 09:45:45.840101 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.840107 12230 net.cpp:184] Created Layer res5a_branch2b_res5a_branch2b/relu_0_split (38)
I0212 09:45:45.840112 12230 net.cpp:561] res5a_branch2b_res5a_branch2b/relu_0_split <- res5a_branch2b
I0212 09:45:45.840118 12230 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_0
I0212 09:45:45.840126 12230 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_1
I0212 09:45:45.840198 12230 net.cpp:245] Setting up res5a_branch2b_res5a_branch2b/relu_0_split
I0212 09:45:45.840209 12230 net.cpp:252] TRAIN Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 8 512 12 23 (1130496)
I0212 09:45:45.840216 12230 net.cpp:252] TRAIN Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 8 512 12 23 (1130496)
I0212 09:45:45.840222 12230 layer_factory.hpp:136] Creating layer 'pool6' of type 'Pooling'
I0212 09:45:45.840227 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.840239 12230 net.cpp:184] Created Layer pool6 (39)
I0212 09:45:45.840245 12230 net.cpp:561] pool6 <- res5a_branch2b_res5a_branch2b/relu_0_split_0
I0212 09:45:45.840251 12230 net.cpp:530] pool6 -> pool6
I0212 09:45:45.840340 12230 net.cpp:245] Setting up pool6
I0212 09:45:45.840351 12230 net.cpp:252] TRAIN Top shape for layer 39 'pool6' 8 512 6 12 (294912)
I0212 09:45:45.840358 12230 layer_factory.hpp:136] Creating layer 'pool6_pool6_0_split' of type 'Split'
I0212 09:45:45.840363 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.840370 12230 net.cpp:184] Created Layer pool6_pool6_0_split (40)
I0212 09:45:45.840375 12230 net.cpp:561] pool6_pool6_0_split <- pool6
I0212 09:45:45.840381 12230 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_0
I0212 09:45:45.840389 12230 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_1
I0212 09:45:45.840448 12230 net.cpp:245] Setting up pool6_pool6_0_split
I0212 09:45:45.840458 12230 net.cpp:252] TRAIN Top shape for layer 40 'pool6_pool6_0_split' 8 512 6 12 (294912)
I0212 09:45:45.840464 12230 net.cpp:252] TRAIN Top shape for layer 40 'pool6_pool6_0_split' 8 512 6 12 (294912)
I0212 09:45:45.840471 12230 layer_factory.hpp:136] Creating layer 'pool7' of type 'Pooling'
I0212 09:45:45.840476 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.840484 12230 net.cpp:184] Created Layer pool7 (41)
I0212 09:45:45.840490 12230 net.cpp:561] pool7 <- pool6_pool6_0_split_0
I0212 09:45:45.840497 12230 net.cpp:530] pool7 -> pool7
I0212 09:45:45.840579 12230 net.cpp:245] Setting up pool7
I0212 09:45:45.840590 12230 net.cpp:252] TRAIN Top shape for layer 41 'pool7' 8 512 3 6 (73728)
I0212 09:45:45.840595 12230 layer_factory.hpp:136] Creating layer 'pool7_pool7_0_split' of type 'Split'
I0212 09:45:45.840612 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.840620 12230 net.cpp:184] Created Layer pool7_pool7_0_split (42)
I0212 09:45:45.840626 12230 net.cpp:561] pool7_pool7_0_split <- pool7
I0212 09:45:45.840632 12230 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_0
I0212 09:45:45.840641 12230 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_1
I0212 09:45:45.840705 12230 net.cpp:245] Setting up pool7_pool7_0_split
I0212 09:45:45.840716 12230 net.cpp:252] TRAIN Top shape for layer 42 'pool7_pool7_0_split' 8 512 3 6 (73728)
I0212 09:45:45.840723 12230 net.cpp:252] TRAIN Top shape for layer 42 'pool7_pool7_0_split' 8 512 3 6 (73728)
I0212 09:45:45.840729 12230 layer_factory.hpp:136] Creating layer 'pool8' of type 'Pooling'
I0212 09:45:45.840734 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.840744 12230 net.cpp:184] Created Layer pool8 (43)
I0212 09:45:45.840749 12230 net.cpp:561] pool8 <- pool7_pool7_0_split_0
I0212 09:45:45.840755 12230 net.cpp:530] pool8 -> pool8
I0212 09:45:45.840837 12230 net.cpp:245] Setting up pool8
I0212 09:45:45.840848 12230 net.cpp:252] TRAIN Top shape for layer 43 'pool8' 8 512 2 3 (24576)
I0212 09:45:45.840854 12230 layer_factory.hpp:136] Creating layer 'pool8_pool8_0_split' of type 'Split'
I0212 09:45:45.840860 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.840867 12230 net.cpp:184] Created Layer pool8_pool8_0_split (44)
I0212 09:45:45.840872 12230 net.cpp:561] pool8_pool8_0_split <- pool8
I0212 09:45:45.840878 12230 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_0
I0212 09:45:45.840884 12230 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_1
I0212 09:45:45.840942 12230 net.cpp:245] Setting up pool8_pool8_0_split
I0212 09:45:45.840952 12230 net.cpp:252] TRAIN Top shape for layer 44 'pool8_pool8_0_split' 8 512 2 3 (24576)
I0212 09:45:45.840960 12230 net.cpp:252] TRAIN Top shape for layer 44 'pool8_pool8_0_split' 8 512 2 3 (24576)
I0212 09:45:45.840965 12230 layer_factory.hpp:136] Creating layer 'pool9' of type 'Pooling'
I0212 09:45:45.840970 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.840978 12230 net.cpp:184] Created Layer pool9 (45)
I0212 09:45:45.840984 12230 net.cpp:561] pool9 <- pool8_pool8_0_split_0
I0212 09:45:45.840991 12230 net.cpp:530] pool9 -> pool9
I0212 09:45:45.841071 12230 net.cpp:245] Setting up pool9
I0212 09:45:45.841081 12230 net.cpp:252] TRAIN Top shape for layer 45 'pool9' 8 512 1 2 (8192)
I0212 09:45:45.841087 12230 layer_factory.hpp:136] Creating layer 'ctx_output1' of type 'Convolution'
I0212 09:45:45.841094 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.841109 12230 net.cpp:184] Created Layer ctx_output1 (46)
I0212 09:45:45.841115 12230 net.cpp:561] ctx_output1 <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0212 09:45:45.841122 12230 net.cpp:530] ctx_output1 -> ctx_output1
I0212 09:45:45.842847 12230 net.cpp:245] Setting up ctx_output1
I0212 09:45:45.842866 12230 net.cpp:252] TRAIN Top shape for layer 46 'ctx_output1' 8 256 46 90 (8478720)
I0212 09:45:45.842877 12230 layer_factory.hpp:136] Creating layer 'ctx_output1/relu' of type 'ReLU'
I0212 09:45:45.842883 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.842891 12230 net.cpp:184] Created Layer ctx_output1/relu (47)
I0212 09:45:45.842897 12230 net.cpp:561] ctx_output1/relu <- ctx_output1
I0212 09:45:45.842905 12230 net.cpp:513] ctx_output1/relu -> ctx_output1 (in-place)
I0212 09:45:45.842913 12230 net.cpp:245] Setting up ctx_output1/relu
I0212 09:45:45.842919 12230 net.cpp:252] TRAIN Top shape for layer 47 'ctx_output1/relu' 8 256 46 90 (8478720)
I0212 09:45:45.842926 12230 layer_factory.hpp:136] Creating layer 'ctx_output1_ctx_output1/relu_0_split' of type 'Split'
I0212 09:45:45.842931 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.842950 12230 net.cpp:184] Created Layer ctx_output1_ctx_output1/relu_0_split (48)
I0212 09:45:45.842957 12230 net.cpp:561] ctx_output1_ctx_output1/relu_0_split <- ctx_output1
I0212 09:45:45.842962 12230 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_0
I0212 09:45:45.842970 12230 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_1
I0212 09:45:45.842978 12230 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_2
I0212 09:45:45.843075 12230 net.cpp:245] Setting up ctx_output1_ctx_output1/relu_0_split
I0212 09:45:45.843086 12230 net.cpp:252] TRAIN Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 8 256 46 90 (8478720)
I0212 09:45:45.843093 12230 net.cpp:252] TRAIN Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 8 256 46 90 (8478720)
I0212 09:45:45.843098 12230 net.cpp:252] TRAIN Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 8 256 46 90 (8478720)
I0212 09:45:45.843104 12230 layer_factory.hpp:136] Creating layer 'ctx_output2' of type 'Convolution'
I0212 09:45:45.843111 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.843125 12230 net.cpp:184] Created Layer ctx_output2 (49)
I0212 09:45:45.843132 12230 net.cpp:561] ctx_output2 <- res5a_branch2b_res5a_branch2b/relu_0_split_1
I0212 09:45:45.843138 12230 net.cpp:530] ctx_output2 -> ctx_output2
I0212 09:45:45.848544 12230 net.cpp:245] Setting up ctx_output2
I0212 09:45:45.848563 12230 net.cpp:252] TRAIN Top shape for layer 49 'ctx_output2' 8 256 12 23 (565248)
I0212 09:45:45.848573 12230 layer_factory.hpp:136] Creating layer 'ctx_output2/relu' of type 'ReLU'
I0212 09:45:45.848580 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.848588 12230 net.cpp:184] Created Layer ctx_output2/relu (50)
I0212 09:45:45.848594 12230 net.cpp:561] ctx_output2/relu <- ctx_output2
I0212 09:45:45.848601 12230 net.cpp:513] ctx_output2/relu -> ctx_output2 (in-place)
I0212 09:45:45.848611 12230 net.cpp:245] Setting up ctx_output2/relu
I0212 09:45:45.848618 12230 net.cpp:252] TRAIN Top shape for layer 50 'ctx_output2/relu' 8 256 12 23 (565248)
I0212 09:45:45.848623 12230 layer_factory.hpp:136] Creating layer 'ctx_output2_ctx_output2/relu_0_split' of type 'Split'
I0212 09:45:45.848628 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.848635 12230 net.cpp:184] Created Layer ctx_output2_ctx_output2/relu_0_split (51)
I0212 09:45:45.848640 12230 net.cpp:561] ctx_output2_ctx_output2/relu_0_split <- ctx_output2
I0212 09:45:45.848646 12230 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_0
I0212 09:45:45.848654 12230 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_1
I0212 09:45:45.848660 12230 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_2
I0212 09:45:45.848754 12230 net.cpp:245] Setting up ctx_output2_ctx_output2/relu_0_split
I0212 09:45:45.848765 12230 net.cpp:252] TRAIN Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 8 256 12 23 (565248)
I0212 09:45:45.848773 12230 net.cpp:252] TRAIN Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 8 256 12 23 (565248)
I0212 09:45:45.848778 12230 net.cpp:252] TRAIN Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 8 256 12 23 (565248)
I0212 09:45:45.848784 12230 layer_factory.hpp:136] Creating layer 'ctx_output3' of type 'Convolution'
I0212 09:45:45.848790 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.848804 12230 net.cpp:184] Created Layer ctx_output3 (52)
I0212 09:45:45.848811 12230 net.cpp:561] ctx_output3 <- pool6_pool6_0_split_1
I0212 09:45:45.848817 12230 net.cpp:530] ctx_output3 -> ctx_output3
I0212 09:45:45.855378 12230 net.cpp:245] Setting up ctx_output3
I0212 09:45:45.855401 12230 net.cpp:252] TRAIN Top shape for layer 52 'ctx_output3' 8 256 6 12 (147456)
I0212 09:45:45.855412 12230 layer_factory.hpp:136] Creating layer 'ctx_output3/relu' of type 'ReLU'
I0212 09:45:45.855417 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.855427 12230 net.cpp:184] Created Layer ctx_output3/relu (53)
I0212 09:45:45.855432 12230 net.cpp:561] ctx_output3/relu <- ctx_output3
I0212 09:45:45.855439 12230 net.cpp:513] ctx_output3/relu -> ctx_output3 (in-place)
I0212 09:45:45.855448 12230 net.cpp:245] Setting up ctx_output3/relu
I0212 09:45:45.855454 12230 net.cpp:252] TRAIN Top shape for layer 53 'ctx_output3/relu' 8 256 6 12 (147456)
I0212 09:45:45.855460 12230 layer_factory.hpp:136] Creating layer 'ctx_output3_ctx_output3/relu_0_split' of type 'Split'
I0212 09:45:45.855465 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.855473 12230 net.cpp:184] Created Layer ctx_output3_ctx_output3/relu_0_split (54)
I0212 09:45:45.855478 12230 net.cpp:561] ctx_output3_ctx_output3/relu_0_split <- ctx_output3
I0212 09:45:45.855484 12230 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_0
I0212 09:45:45.855490 12230 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_1
I0212 09:45:45.855497 12230 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_2
I0212 09:45:45.855599 12230 net.cpp:245] Setting up ctx_output3_ctx_output3/relu_0_split
I0212 09:45:45.855612 12230 net.cpp:252] TRAIN Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 8 256 6 12 (147456)
I0212 09:45:45.855618 12230 net.cpp:252] TRAIN Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 8 256 6 12 (147456)
I0212 09:45:45.855624 12230 net.cpp:252] TRAIN Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 8 256 6 12 (147456)
I0212 09:45:45.855630 12230 layer_factory.hpp:136] Creating layer 'ctx_output4' of type 'Convolution'
I0212 09:45:45.855636 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.855656 12230 net.cpp:184] Created Layer ctx_output4 (55)
I0212 09:45:45.855662 12230 net.cpp:561] ctx_output4 <- pool7_pool7_0_split_1
I0212 09:45:45.855669 12230 net.cpp:530] ctx_output4 -> ctx_output4
I0212 09:45:45.861063 12230 net.cpp:245] Setting up ctx_output4
I0212 09:45:45.861081 12230 net.cpp:252] TRAIN Top shape for layer 55 'ctx_output4' 8 256 3 6 (36864)
I0212 09:45:45.861091 12230 layer_factory.hpp:136] Creating layer 'ctx_output4/relu' of type 'ReLU'
I0212 09:45:45.861097 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.861105 12230 net.cpp:184] Created Layer ctx_output4/relu (56)
I0212 09:45:45.861111 12230 net.cpp:561] ctx_output4/relu <- ctx_output4
I0212 09:45:45.861117 12230 net.cpp:513] ctx_output4/relu -> ctx_output4 (in-place)
I0212 09:45:45.861129 12230 net.cpp:245] Setting up ctx_output4/relu
I0212 09:45:45.861135 12230 net.cpp:252] TRAIN Top shape for layer 56 'ctx_output4/relu' 8 256 3 6 (36864)
I0212 09:45:45.861140 12230 layer_factory.hpp:136] Creating layer 'ctx_output4_ctx_output4/relu_0_split' of type 'Split'
I0212 09:45:45.861146 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.861152 12230 net.cpp:184] Created Layer ctx_output4_ctx_output4/relu_0_split (57)
I0212 09:45:45.861157 12230 net.cpp:561] ctx_output4_ctx_output4/relu_0_split <- ctx_output4
I0212 09:45:45.861163 12230 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_0
I0212 09:45:45.861171 12230 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_1
I0212 09:45:45.861178 12230 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_2
I0212 09:45:45.861281 12230 net.cpp:245] Setting up ctx_output4_ctx_output4/relu_0_split
I0212 09:45:45.861304 12230 net.cpp:252] TRAIN Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 8 256 3 6 (36864)
I0212 09:45:45.861312 12230 net.cpp:252] TRAIN Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 8 256 3 6 (36864)
I0212 09:45:45.861318 12230 net.cpp:252] TRAIN Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 8 256 3 6 (36864)
I0212 09:45:45.861325 12230 layer_factory.hpp:136] Creating layer 'ctx_output5' of type 'Convolution'
I0212 09:45:45.861330 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.861347 12230 net.cpp:184] Created Layer ctx_output5 (58)
I0212 09:45:45.861354 12230 net.cpp:561] ctx_output5 <- pool8_pool8_0_split_1
I0212 09:45:45.861361 12230 net.cpp:530] ctx_output5 -> ctx_output5
I0212 09:45:45.866772 12230 net.cpp:245] Setting up ctx_output5
I0212 09:45:45.866794 12230 net.cpp:252] TRAIN Top shape for layer 58 'ctx_output5' 8 256 2 3 (12288)
I0212 09:45:45.866804 12230 layer_factory.hpp:136] Creating layer 'ctx_output5/relu' of type 'ReLU'
I0212 09:45:45.866811 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.866820 12230 net.cpp:184] Created Layer ctx_output5/relu (59)
I0212 09:45:45.866827 12230 net.cpp:561] ctx_output5/relu <- ctx_output5
I0212 09:45:45.866837 12230 net.cpp:513] ctx_output5/relu -> ctx_output5 (in-place)
I0212 09:45:45.866847 12230 net.cpp:245] Setting up ctx_output5/relu
I0212 09:45:45.866853 12230 net.cpp:252] TRAIN Top shape for layer 59 'ctx_output5/relu' 8 256 2 3 (12288)
I0212 09:45:45.866859 12230 layer_factory.hpp:136] Creating layer 'ctx_output5_ctx_output5/relu_0_split' of type 'Split'
I0212 09:45:45.866864 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.866873 12230 net.cpp:184] Created Layer ctx_output5_ctx_output5/relu_0_split (60)
I0212 09:45:45.866878 12230 net.cpp:561] ctx_output5_ctx_output5/relu_0_split <- ctx_output5
I0212 09:45:45.866883 12230 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_0
I0212 09:45:45.866891 12230 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_1
I0212 09:45:45.866899 12230 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_2
I0212 09:45:45.867002 12230 net.cpp:245] Setting up ctx_output5_ctx_output5/relu_0_split
I0212 09:45:45.867013 12230 net.cpp:252] TRAIN Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 8 256 2 3 (12288)
I0212 09:45:45.867019 12230 net.cpp:252] TRAIN Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 8 256 2 3 (12288)
I0212 09:45:45.867025 12230 net.cpp:252] TRAIN Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 8 256 2 3 (12288)
I0212 09:45:45.867031 12230 layer_factory.hpp:136] Creating layer 'ctx_output6' of type 'Convolution'
I0212 09:45:45.867036 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.867061 12230 net.cpp:184] Created Layer ctx_output6 (61)
I0212 09:45:45.867069 12230 net.cpp:561] ctx_output6 <- pool9
I0212 09:45:45.867075 12230 net.cpp:530] ctx_output6 -> ctx_output6
I0212 09:45:45.872493 12230 net.cpp:245] Setting up ctx_output6
I0212 09:45:45.872512 12230 net.cpp:252] TRAIN Top shape for layer 61 'ctx_output6' 8 256 1 2 (4096)
I0212 09:45:45.872522 12230 layer_factory.hpp:136] Creating layer 'ctx_output6/relu' of type 'ReLU'
I0212 09:45:45.872529 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.872536 12230 net.cpp:184] Created Layer ctx_output6/relu (62)
I0212 09:45:45.872542 12230 net.cpp:561] ctx_output6/relu <- ctx_output6
I0212 09:45:45.872548 12230 net.cpp:513] ctx_output6/relu -> ctx_output6 (in-place)
I0212 09:45:45.872557 12230 net.cpp:245] Setting up ctx_output6/relu
I0212 09:45:45.872563 12230 net.cpp:252] TRAIN Top shape for layer 62 'ctx_output6/relu' 8 256 1 2 (4096)
I0212 09:45:45.872581 12230 layer_factory.hpp:136] Creating layer 'ctx_output6_ctx_output6/relu_0_split' of type 'Split'
I0212 09:45:45.872587 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.872596 12230 net.cpp:184] Created Layer ctx_output6_ctx_output6/relu_0_split (63)
I0212 09:45:45.872601 12230 net.cpp:561] ctx_output6_ctx_output6/relu_0_split <- ctx_output6
I0212 09:45:45.872607 12230 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_0
I0212 09:45:45.872614 12230 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_1
I0212 09:45:45.872622 12230 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_2
I0212 09:45:45.872725 12230 net.cpp:245] Setting up ctx_output6_ctx_output6/relu_0_split
I0212 09:45:45.872736 12230 net.cpp:252] TRAIN Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 8 256 1 2 (4096)
I0212 09:45:45.872743 12230 net.cpp:252] TRAIN Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 8 256 1 2 (4096)
I0212 09:45:45.872750 12230 net.cpp:252] TRAIN Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 8 256 1 2 (4096)
I0212 09:45:45.872756 12230 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc' of type 'Convolution'
I0212 09:45:45.872761 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.872783 12230 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc (64)
I0212 09:45:45.872789 12230 net.cpp:561] ctx_output1/relu_mbox_loc <- ctx_output1_ctx_output1/relu_0_split_0
I0212 09:45:45.872797 12230 net.cpp:530] ctx_output1/relu_mbox_loc -> ctx_output1/relu_mbox_loc
I0212 09:45:45.873468 12230 net.cpp:245] Setting up ctx_output1/relu_mbox_loc
I0212 09:45:45.873486 12230 net.cpp:252] TRAIN Top shape for layer 64 'ctx_output1/relu_mbox_loc' 8 16 46 90 (529920)
I0212 09:45:45.873495 12230 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_perm' of type 'Permute'
I0212 09:45:45.873502 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.873982 12230 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_perm (65)
I0212 09:45:45.874001 12230 net.cpp:561] ctx_output1/relu_mbox_loc_perm <- ctx_output1/relu_mbox_loc
I0212 09:45:45.874011 12230 net.cpp:530] ctx_output1/relu_mbox_loc_perm -> ctx_output1/relu_mbox_loc_perm
I0212 09:45:45.874248 12230 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_perm
I0212 09:45:45.874264 12230 net.cpp:252] TRAIN Top shape for layer 65 'ctx_output1/relu_mbox_loc_perm' 8 46 90 16 (529920)
I0212 09:45:45.874270 12230 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_flat' of type 'Flatten'
I0212 09:45:45.874276 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.874285 12230 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_flat (66)
I0212 09:45:45.874291 12230 net.cpp:561] ctx_output1/relu_mbox_loc_flat <- ctx_output1/relu_mbox_loc_perm
I0212 09:45:45.874300 12230 net.cpp:530] ctx_output1/relu_mbox_loc_flat -> ctx_output1/relu_mbox_loc_flat
I0212 09:45:45.874349 12230 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_flat
I0212 09:45:45.874361 12230 net.cpp:252] TRAIN Top shape for layer 66 'ctx_output1/relu_mbox_loc_flat' 8 66240 (529920)
I0212 09:45:45.874367 12230 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf' of type 'Convolution'
I0212 09:45:45.874373 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.874392 12230 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf (67)
I0212 09:45:45.874398 12230 net.cpp:561] ctx_output1/relu_mbox_conf <- ctx_output1_ctx_output1/relu_0_split_1
I0212 09:45:45.874405 12230 net.cpp:530] ctx_output1/relu_mbox_conf -> ctx_output1/relu_mbox_conf
I0212 09:45:45.875085 12230 net.cpp:245] Setting up ctx_output1/relu_mbox_conf
I0212 09:45:45.875116 12230 net.cpp:252] TRAIN Top shape for layer 67 'ctx_output1/relu_mbox_conf' 8 16 46 90 (529920)
I0212 09:45:45.875128 12230 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_perm' of type 'Permute'
I0212 09:45:45.875134 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.875149 12230 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_perm (68)
I0212 09:45:45.875155 12230 net.cpp:561] ctx_output1/relu_mbox_conf_perm <- ctx_output1/relu_mbox_conf
I0212 09:45:45.875162 12230 net.cpp:530] ctx_output1/relu_mbox_conf_perm -> ctx_output1/relu_mbox_conf_perm
I0212 09:45:45.875358 12230 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_perm
I0212 09:45:45.875370 12230 net.cpp:252] TRAIN Top shape for layer 68 'ctx_output1/relu_mbox_conf_perm' 8 46 90 16 (529920)
I0212 09:45:45.875376 12230 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_flat' of type 'Flatten'
I0212 09:45:45.875382 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.875392 12230 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_flat (69)
I0212 09:45:45.875398 12230 net.cpp:561] ctx_output1/relu_mbox_conf_flat <- ctx_output1/relu_mbox_conf_perm
I0212 09:45:45.875404 12230 net.cpp:530] ctx_output1/relu_mbox_conf_flat -> ctx_output1/relu_mbox_conf_flat
I0212 09:45:45.875447 12230 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_flat
I0212 09:45:45.875459 12230 net.cpp:252] TRAIN Top shape for layer 69 'ctx_output1/relu_mbox_conf_flat' 8 66240 (529920)
I0212 09:45:45.875464 12230 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_priorbox' of type 'PriorBox'
I0212 09:45:45.875470 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.875905 12230 net.cpp:184] Created Layer ctx_output1/relu_mbox_priorbox (70)
I0212 09:45:45.875938 12230 net.cpp:561] ctx_output1/relu_mbox_priorbox <- ctx_output1_ctx_output1/relu_0_split_2
I0212 09:45:45.875953 12230 net.cpp:561] ctx_output1/relu_mbox_priorbox <- data_data_0_split_1
I0212 09:45:45.875967 12230 net.cpp:530] ctx_output1/relu_mbox_priorbox -> ctx_output1/relu_mbox_priorbox
I0212 09:45:45.876132 12230 net.cpp:245] Setting up ctx_output1/relu_mbox_priorbox
I0212 09:45:45.876160 12230 net.cpp:252] TRAIN Top shape for layer 70 'ctx_output1/relu_mbox_priorbox' 1 2 66240 (132480)
I0212 09:45:45.876173 12230 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc' of type 'Convolution'
I0212 09:45:45.876183 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.876217 12230 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc (71)
I0212 09:45:45.876231 12230 net.cpp:561] ctx_output2/relu_mbox_loc <- ctx_output2_ctx_output2/relu_0_split_0
I0212 09:45:45.876245 12230 net.cpp:530] ctx_output2/relu_mbox_loc -> ctx_output2/relu_mbox_loc
I0212 09:45:45.877073 12230 net.cpp:245] Setting up ctx_output2/relu_mbox_loc
I0212 09:45:45.877090 12230 net.cpp:252] TRAIN Top shape for layer 71 'ctx_output2/relu_mbox_loc' 8 24 12 23 (52992)
I0212 09:45:45.877101 12230 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_perm' of type 'Permute'
I0212 09:45:45.877107 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.877120 12230 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_perm (72)
I0212 09:45:45.877126 12230 net.cpp:561] ctx_output2/relu_mbox_loc_perm <- ctx_output2/relu_mbox_loc
I0212 09:45:45.877133 12230 net.cpp:530] ctx_output2/relu_mbox_loc_perm -> ctx_output2/relu_mbox_loc_perm
I0212 09:45:45.877331 12230 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_perm
I0212 09:45:45.877342 12230 net.cpp:252] TRAIN Top shape for layer 72 'ctx_output2/relu_mbox_loc_perm' 8 12 23 24 (52992)
I0212 09:45:45.877348 12230 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_flat' of type 'Flatten'
I0212 09:45:45.877353 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.877373 12230 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_flat (73)
I0212 09:45:45.877380 12230 net.cpp:561] ctx_output2/relu_mbox_loc_flat <- ctx_output2/relu_mbox_loc_perm
I0212 09:45:45.877388 12230 net.cpp:530] ctx_output2/relu_mbox_loc_flat -> ctx_output2/relu_mbox_loc_flat
I0212 09:45:45.877435 12230 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_flat
I0212 09:45:45.877447 12230 net.cpp:252] TRAIN Top shape for layer 73 'ctx_output2/relu_mbox_loc_flat' 8 6624 (52992)
I0212 09:45:45.877454 12230 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf' of type 'Convolution'
I0212 09:45:45.877459 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.877475 12230 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf (74)
I0212 09:45:45.877481 12230 net.cpp:561] ctx_output2/relu_mbox_conf <- ctx_output2_ctx_output2/relu_0_split_1
I0212 09:45:45.877488 12230 net.cpp:530] ctx_output2/relu_mbox_conf -> ctx_output2/relu_mbox_conf
I0212 09:45:45.878243 12230 net.cpp:245] Setting up ctx_output2/relu_mbox_conf
I0212 09:45:45.878262 12230 net.cpp:252] TRAIN Top shape for layer 74 'ctx_output2/relu_mbox_conf' 8 24 12 23 (52992)
I0212 09:45:45.878271 12230 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_perm' of type 'Permute'
I0212 09:45:45.878278 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.878290 12230 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_perm (75)
I0212 09:45:45.878298 12230 net.cpp:561] ctx_output2/relu_mbox_conf_perm <- ctx_output2/relu_mbox_conf
I0212 09:45:45.878304 12230 net.cpp:530] ctx_output2/relu_mbox_conf_perm -> ctx_output2/relu_mbox_conf_perm
I0212 09:45:45.878500 12230 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_perm
I0212 09:45:45.878513 12230 net.cpp:252] TRAIN Top shape for layer 75 'ctx_output2/relu_mbox_conf_perm' 8 12 23 24 (52992)
I0212 09:45:45.878520 12230 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_flat' of type 'Flatten'
I0212 09:45:45.878525 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.878533 12230 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_flat (76)
I0212 09:45:45.878540 12230 net.cpp:561] ctx_output2/relu_mbox_conf_flat <- ctx_output2/relu_mbox_conf_perm
I0212 09:45:45.878545 12230 net.cpp:530] ctx_output2/relu_mbox_conf_flat -> ctx_output2/relu_mbox_conf_flat
I0212 09:45:45.878588 12230 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_flat
I0212 09:45:45.878599 12230 net.cpp:252] TRAIN Top shape for layer 76 'ctx_output2/relu_mbox_conf_flat' 8 6624 (52992)
I0212 09:45:45.878605 12230 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_priorbox' of type 'PriorBox'
I0212 09:45:45.878612 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.878619 12230 net.cpp:184] Created Layer ctx_output2/relu_mbox_priorbox (77)
I0212 09:45:45.878624 12230 net.cpp:561] ctx_output2/relu_mbox_priorbox <- ctx_output2_ctx_output2/relu_0_split_2
I0212 09:45:45.878631 12230 net.cpp:561] ctx_output2/relu_mbox_priorbox <- data_data_0_split_2
I0212 09:45:45.878638 12230 net.cpp:530] ctx_output2/relu_mbox_priorbox -> ctx_output2/relu_mbox_priorbox
I0212 09:45:45.878687 12230 net.cpp:245] Setting up ctx_output2/relu_mbox_priorbox
I0212 09:45:45.878698 12230 net.cpp:252] TRAIN Top shape for layer 77 'ctx_output2/relu_mbox_priorbox' 1 2 6624 (13248)
I0212 09:45:45.878705 12230 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc' of type 'Convolution'
I0212 09:45:45.878710 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.878731 12230 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc (78)
I0212 09:45:45.878737 12230 net.cpp:561] ctx_output3/relu_mbox_loc <- ctx_output3_ctx_output3/relu_0_split_0
I0212 09:45:45.878744 12230 net.cpp:530] ctx_output3/relu_mbox_loc -> ctx_output3/relu_mbox_loc
I0212 09:45:45.879509 12230 net.cpp:245] Setting up ctx_output3/relu_mbox_loc
I0212 09:45:45.879526 12230 net.cpp:252] TRAIN Top shape for layer 78 'ctx_output3/relu_mbox_loc' 8 24 6 12 (13824)
I0212 09:45:45.879536 12230 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_perm' of type 'Permute'
I0212 09:45:45.879542 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.879554 12230 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_perm (79)
I0212 09:45:45.879559 12230 net.cpp:561] ctx_output3/relu_mbox_loc_perm <- ctx_output3/relu_mbox_loc
I0212 09:45:45.879567 12230 net.cpp:530] ctx_output3/relu_mbox_loc_perm -> ctx_output3/relu_mbox_loc_perm
I0212 09:45:45.879765 12230 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_perm
I0212 09:45:45.879778 12230 net.cpp:252] TRAIN Top shape for layer 79 'ctx_output3/relu_mbox_loc_perm' 8 6 12 24 (13824)
I0212 09:45:45.879784 12230 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_flat' of type 'Flatten'
I0212 09:45:45.879789 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.879797 12230 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_flat (80)
I0212 09:45:45.879802 12230 net.cpp:561] ctx_output3/relu_mbox_loc_flat <- ctx_output3/relu_mbox_loc_perm
I0212 09:45:45.879809 12230 net.cpp:530] ctx_output3/relu_mbox_loc_flat -> ctx_output3/relu_mbox_loc_flat
I0212 09:45:45.879853 12230 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_flat
I0212 09:45:45.879863 12230 net.cpp:252] TRAIN Top shape for layer 80 'ctx_output3/relu_mbox_loc_flat' 8 1728 (13824)
I0212 09:45:45.879868 12230 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf' of type 'Convolution'
I0212 09:45:45.879873 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.879889 12230 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf (81)
I0212 09:45:45.879895 12230 net.cpp:561] ctx_output3/relu_mbox_conf <- ctx_output3_ctx_output3/relu_0_split_1
I0212 09:45:45.879904 12230 net.cpp:530] ctx_output3/relu_mbox_conf -> ctx_output3/relu_mbox_conf
I0212 09:45:45.880645 12230 net.cpp:245] Setting up ctx_output3/relu_mbox_conf
I0212 09:45:45.880662 12230 net.cpp:252] TRAIN Top shape for layer 81 'ctx_output3/relu_mbox_conf' 8 24 6 12 (13824)
I0212 09:45:45.880672 12230 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_perm' of type 'Permute'
I0212 09:45:45.880678 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.880689 12230 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_perm (82)
I0212 09:45:45.880697 12230 net.cpp:561] ctx_output3/relu_mbox_conf_perm <- ctx_output3/relu_mbox_conf
I0212 09:45:45.880703 12230 net.cpp:530] ctx_output3/relu_mbox_conf_perm -> ctx_output3/relu_mbox_conf_perm
I0212 09:45:45.880895 12230 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_perm
I0212 09:45:45.880908 12230 net.cpp:252] TRAIN Top shape for layer 82 'ctx_output3/relu_mbox_conf_perm' 8 6 12 24 (13824)
I0212 09:45:45.880913 12230 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_flat' of type 'Flatten'
I0212 09:45:45.880919 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.880926 12230 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_flat (83)
I0212 09:45:45.880933 12230 net.cpp:561] ctx_output3/relu_mbox_conf_flat <- ctx_output3/relu_mbox_conf_perm
I0212 09:45:45.880939 12230 net.cpp:530] ctx_output3/relu_mbox_conf_flat -> ctx_output3/relu_mbox_conf_flat
I0212 09:45:45.880982 12230 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_flat
I0212 09:45:45.880993 12230 net.cpp:252] TRAIN Top shape for layer 83 'ctx_output3/relu_mbox_conf_flat' 8 1728 (13824)
I0212 09:45:45.881000 12230 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_priorbox' of type 'PriorBox'
I0212 09:45:45.881006 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.881023 12230 net.cpp:184] Created Layer ctx_output3/relu_mbox_priorbox (84)
I0212 09:45:45.881031 12230 net.cpp:561] ctx_output3/relu_mbox_priorbox <- ctx_output3_ctx_output3/relu_0_split_2
I0212 09:45:45.881037 12230 net.cpp:561] ctx_output3/relu_mbox_priorbox <- data_data_0_split_3
I0212 09:45:45.881044 12230 net.cpp:530] ctx_output3/relu_mbox_priorbox -> ctx_output3/relu_mbox_priorbox
I0212 09:45:45.881095 12230 net.cpp:245] Setting up ctx_output3/relu_mbox_priorbox
I0212 09:45:45.881106 12230 net.cpp:252] TRAIN Top shape for layer 84 'ctx_output3/relu_mbox_priorbox' 1 2 1728 (3456)
I0212 09:45:45.881112 12230 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc' of type 'Convolution'
I0212 09:45:45.881119 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.881135 12230 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc (85)
I0212 09:45:45.881142 12230 net.cpp:561] ctx_output4/relu_mbox_loc <- ctx_output4_ctx_output4/relu_0_split_0
I0212 09:45:45.881150 12230 net.cpp:530] ctx_output4/relu_mbox_loc -> ctx_output4/relu_mbox_loc
I0212 09:45:45.881891 12230 net.cpp:245] Setting up ctx_output4/relu_mbox_loc
I0212 09:45:45.881908 12230 net.cpp:252] TRAIN Top shape for layer 85 'ctx_output4/relu_mbox_loc' 8 24 3 6 (3456)
I0212 09:45:45.881918 12230 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_perm' of type 'Permute'
I0212 09:45:45.881924 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.881937 12230 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_perm (86)
I0212 09:45:45.881942 12230 net.cpp:561] ctx_output4/relu_mbox_loc_perm <- ctx_output4/relu_mbox_loc
I0212 09:45:45.881949 12230 net.cpp:530] ctx_output4/relu_mbox_loc_perm -> ctx_output4/relu_mbox_loc_perm
I0212 09:45:45.882160 12230 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_perm
I0212 09:45:45.882174 12230 net.cpp:252] TRAIN Top shape for layer 86 'ctx_output4/relu_mbox_loc_perm' 8 3 6 24 (3456)
I0212 09:45:45.882179 12230 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_flat' of type 'Flatten'
I0212 09:45:45.882185 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.882194 12230 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_flat (87)
I0212 09:45:45.882200 12230 net.cpp:561] ctx_output4/relu_mbox_loc_flat <- ctx_output4/relu_mbox_loc_perm
I0212 09:45:45.882205 12230 net.cpp:530] ctx_output4/relu_mbox_loc_flat -> ctx_output4/relu_mbox_loc_flat
I0212 09:45:45.882251 12230 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_flat
I0212 09:45:45.882261 12230 net.cpp:252] TRAIN Top shape for layer 87 'ctx_output4/relu_mbox_loc_flat' 8 432 (3456)
I0212 09:45:45.882267 12230 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf' of type 'Convolution'
I0212 09:45:45.882273 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.882293 12230 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf (88)
I0212 09:45:45.882299 12230 net.cpp:561] ctx_output4/relu_mbox_conf <- ctx_output4_ctx_output4/relu_0_split_1
I0212 09:45:45.882308 12230 net.cpp:530] ctx_output4/relu_mbox_conf -> ctx_output4/relu_mbox_conf
I0212 09:45:45.883050 12230 net.cpp:245] Setting up ctx_output4/relu_mbox_conf
I0212 09:45:45.883067 12230 net.cpp:252] TRAIN Top shape for layer 88 'ctx_output4/relu_mbox_conf' 8 24 3 6 (3456)
I0212 09:45:45.883077 12230 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_perm' of type 'Permute'
I0212 09:45:45.883085 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.883095 12230 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_perm (89)
I0212 09:45:45.883101 12230 net.cpp:561] ctx_output4/relu_mbox_conf_perm <- ctx_output4/relu_mbox_conf
I0212 09:45:45.883108 12230 net.cpp:530] ctx_output4/relu_mbox_conf_perm -> ctx_output4/relu_mbox_conf_perm
I0212 09:45:45.883318 12230 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_perm
I0212 09:45:45.883333 12230 net.cpp:252] TRAIN Top shape for layer 89 'ctx_output4/relu_mbox_conf_perm' 8 3 6 24 (3456)
I0212 09:45:45.883339 12230 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_flat' of type 'Flatten'
I0212 09:45:45.883345 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.883352 12230 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_flat (90)
I0212 09:45:45.883358 12230 net.cpp:561] ctx_output4/relu_mbox_conf_flat <- ctx_output4/relu_mbox_conf_perm
I0212 09:45:45.883366 12230 net.cpp:530] ctx_output4/relu_mbox_conf_flat -> ctx_output4/relu_mbox_conf_flat
I0212 09:45:45.883410 12230 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_flat
I0212 09:45:45.883421 12230 net.cpp:252] TRAIN Top shape for layer 90 'ctx_output4/relu_mbox_conf_flat' 8 432 (3456)
I0212 09:45:45.883427 12230 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_priorbox' of type 'PriorBox'
I0212 09:45:45.883433 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.883442 12230 net.cpp:184] Created Layer ctx_output4/relu_mbox_priorbox (91)
I0212 09:45:45.883448 12230 net.cpp:561] ctx_output4/relu_mbox_priorbox <- ctx_output4_ctx_output4/relu_0_split_2
I0212 09:45:45.883455 12230 net.cpp:561] ctx_output4/relu_mbox_priorbox <- data_data_0_split_4
I0212 09:45:45.883461 12230 net.cpp:530] ctx_output4/relu_mbox_priorbox -> ctx_output4/relu_mbox_priorbox
I0212 09:45:45.883508 12230 net.cpp:245] Setting up ctx_output4/relu_mbox_priorbox
I0212 09:45:45.883519 12230 net.cpp:252] TRAIN Top shape for layer 91 'ctx_output4/relu_mbox_priorbox' 1 2 432 (864)
I0212 09:45:45.883525 12230 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc' of type 'Convolution'
I0212 09:45:45.883530 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.883548 12230 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc (92)
I0212 09:45:45.883554 12230 net.cpp:561] ctx_output5/relu_mbox_loc <- ctx_output5_ctx_output5/relu_0_split_0
I0212 09:45:45.883561 12230 net.cpp:530] ctx_output5/relu_mbox_loc -> ctx_output5/relu_mbox_loc
I0212 09:45:45.884234 12230 net.cpp:245] Setting up ctx_output5/relu_mbox_loc
I0212 09:45:45.884251 12230 net.cpp:252] TRAIN Top shape for layer 92 'ctx_output5/relu_mbox_loc' 8 16 2 3 (768)
I0212 09:45:45.884261 12230 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_perm' of type 'Permute'
I0212 09:45:45.884268 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.884279 12230 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_perm (93)
I0212 09:45:45.884285 12230 net.cpp:561] ctx_output5/relu_mbox_loc_perm <- ctx_output5/relu_mbox_loc
I0212 09:45:45.884292 12230 net.cpp:530] ctx_output5/relu_mbox_loc_perm -> ctx_output5/relu_mbox_loc_perm
I0212 09:45:45.884487 12230 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_perm
I0212 09:45:45.884500 12230 net.cpp:252] TRAIN Top shape for layer 93 'ctx_output5/relu_mbox_loc_perm' 8 2 3 16 (768)
I0212 09:45:45.884506 12230 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_flat' of type 'Flatten'
I0212 09:45:45.884511 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.884519 12230 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_flat (94)
I0212 09:45:45.884526 12230 net.cpp:561] ctx_output5/relu_mbox_loc_flat <- ctx_output5/relu_mbox_loc_perm
I0212 09:45:45.884532 12230 net.cpp:530] ctx_output5/relu_mbox_loc_flat -> ctx_output5/relu_mbox_loc_flat
I0212 09:45:45.884574 12230 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_flat
I0212 09:45:45.884585 12230 net.cpp:252] TRAIN Top shape for layer 94 'ctx_output5/relu_mbox_loc_flat' 8 96 (768)
I0212 09:45:45.884591 12230 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf' of type 'Convolution'
I0212 09:45:45.884608 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.884625 12230 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf (95)
I0212 09:45:45.884631 12230 net.cpp:561] ctx_output5/relu_mbox_conf <- ctx_output5_ctx_output5/relu_0_split_1
I0212 09:45:45.884639 12230 net.cpp:530] ctx_output5/relu_mbox_conf -> ctx_output5/relu_mbox_conf
I0212 09:45:45.885306 12230 net.cpp:245] Setting up ctx_output5/relu_mbox_conf
I0212 09:45:45.885324 12230 net.cpp:252] TRAIN Top shape for layer 95 'ctx_output5/relu_mbox_conf' 8 16 2 3 (768)
I0212 09:45:45.885334 12230 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_perm' of type 'Permute'
I0212 09:45:45.885340 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.885351 12230 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_perm (96)
I0212 09:45:45.885357 12230 net.cpp:561] ctx_output5/relu_mbox_conf_perm <- ctx_output5/relu_mbox_conf
I0212 09:45:45.885365 12230 net.cpp:530] ctx_output5/relu_mbox_conf_perm -> ctx_output5/relu_mbox_conf_perm
I0212 09:45:45.885560 12230 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_perm
I0212 09:45:45.885571 12230 net.cpp:252] TRAIN Top shape for layer 96 'ctx_output5/relu_mbox_conf_perm' 8 2 3 16 (768)
I0212 09:45:45.885577 12230 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_flat' of type 'Flatten'
I0212 09:45:45.885583 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.885591 12230 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_flat (97)
I0212 09:45:45.885596 12230 net.cpp:561] ctx_output5/relu_mbox_conf_flat <- ctx_output5/relu_mbox_conf_perm
I0212 09:45:45.885603 12230 net.cpp:530] ctx_output5/relu_mbox_conf_flat -> ctx_output5/relu_mbox_conf_flat
I0212 09:45:45.885645 12230 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_flat
I0212 09:45:45.885656 12230 net.cpp:252] TRAIN Top shape for layer 97 'ctx_output5/relu_mbox_conf_flat' 8 96 (768)
I0212 09:45:45.885663 12230 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_priorbox' of type 'PriorBox'
I0212 09:45:45.885668 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.885677 12230 net.cpp:184] Created Layer ctx_output5/relu_mbox_priorbox (98)
I0212 09:45:45.885684 12230 net.cpp:561] ctx_output5/relu_mbox_priorbox <- ctx_output5_ctx_output5/relu_0_split_2
I0212 09:45:45.885690 12230 net.cpp:561] ctx_output5/relu_mbox_priorbox <- data_data_0_split_5
I0212 09:45:45.885696 12230 net.cpp:530] ctx_output5/relu_mbox_priorbox -> ctx_output5/relu_mbox_priorbox
I0212 09:45:45.885741 12230 net.cpp:245] Setting up ctx_output5/relu_mbox_priorbox
I0212 09:45:45.885752 12230 net.cpp:252] TRAIN Top shape for layer 98 'ctx_output5/relu_mbox_priorbox' 1 2 96 (192)
I0212 09:45:45.885759 12230 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc' of type 'Convolution'
I0212 09:45:45.885764 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.885783 12230 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc (99)
I0212 09:45:45.885790 12230 net.cpp:561] ctx_output6/relu_mbox_loc <- ctx_output6_ctx_output6/relu_0_split_0
I0212 09:45:45.885798 12230 net.cpp:530] ctx_output6/relu_mbox_loc -> ctx_output6/relu_mbox_loc
I0212 09:45:45.886479 12230 net.cpp:245] Setting up ctx_output6/relu_mbox_loc
I0212 09:45:45.886497 12230 net.cpp:252] TRAIN Top shape for layer 99 'ctx_output6/relu_mbox_loc' 8 16 1 2 (256)
I0212 09:45:45.886507 12230 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_perm' of type 'Permute'
I0212 09:45:45.886513 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.886526 12230 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_perm (100)
I0212 09:45:45.886533 12230 net.cpp:561] ctx_output6/relu_mbox_loc_perm <- ctx_output6/relu_mbox_loc
I0212 09:45:45.886551 12230 net.cpp:530] ctx_output6/relu_mbox_loc_perm -> ctx_output6/relu_mbox_loc_perm
I0212 09:45:45.886747 12230 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_perm
I0212 09:45:45.886760 12230 net.cpp:252] TRAIN Top shape for layer 100 'ctx_output6/relu_mbox_loc_perm' 8 1 2 16 (256)
I0212 09:45:45.886766 12230 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_flat' of type 'Flatten'
I0212 09:45:45.886772 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.886781 12230 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_flat (101)
I0212 09:45:45.886787 12230 net.cpp:561] ctx_output6/relu_mbox_loc_flat <- ctx_output6/relu_mbox_loc_perm
I0212 09:45:45.886793 12230 net.cpp:530] ctx_output6/relu_mbox_loc_flat -> ctx_output6/relu_mbox_loc_flat
I0212 09:45:45.886837 12230 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_flat
I0212 09:45:45.886847 12230 net.cpp:252] TRAIN Top shape for layer 101 'ctx_output6/relu_mbox_loc_flat' 8 32 (256)
I0212 09:45:45.886853 12230 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf' of type 'Convolution'
I0212 09:45:45.886859 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.886876 12230 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf (102)
I0212 09:45:45.886883 12230 net.cpp:561] ctx_output6/relu_mbox_conf <- ctx_output6_ctx_output6/relu_0_split_1
I0212 09:45:45.886890 12230 net.cpp:530] ctx_output6/relu_mbox_conf -> ctx_output6/relu_mbox_conf
I0212 09:45:45.887555 12230 net.cpp:245] Setting up ctx_output6/relu_mbox_conf
I0212 09:45:45.887573 12230 net.cpp:252] TRAIN Top shape for layer 102 'ctx_output6/relu_mbox_conf' 8 16 1 2 (256)
I0212 09:45:45.887583 12230 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_perm' of type 'Permute'
I0212 09:45:45.887588 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.887603 12230 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_perm (103)
I0212 09:45:45.887609 12230 net.cpp:561] ctx_output6/relu_mbox_conf_perm <- ctx_output6/relu_mbox_conf
I0212 09:45:45.887616 12230 net.cpp:530] ctx_output6/relu_mbox_conf_perm -> ctx_output6/relu_mbox_conf_perm
I0212 09:45:45.887814 12230 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_perm
I0212 09:45:45.887825 12230 net.cpp:252] TRAIN Top shape for layer 103 'ctx_output6/relu_mbox_conf_perm' 8 1 2 16 (256)
I0212 09:45:45.887831 12230 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_flat' of type 'Flatten'
I0212 09:45:45.887837 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.887845 12230 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_flat (104)
I0212 09:45:45.887851 12230 net.cpp:561] ctx_output6/relu_mbox_conf_flat <- ctx_output6/relu_mbox_conf_perm
I0212 09:45:45.887858 12230 net.cpp:530] ctx_output6/relu_mbox_conf_flat -> ctx_output6/relu_mbox_conf_flat
I0212 09:45:45.887902 12230 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_flat
I0212 09:45:45.887912 12230 net.cpp:252] TRAIN Top shape for layer 104 'ctx_output6/relu_mbox_conf_flat' 8 32 (256)
I0212 09:45:45.887918 12230 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_priorbox' of type 'PriorBox'
I0212 09:45:45.887923 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.887933 12230 net.cpp:184] Created Layer ctx_output6/relu_mbox_priorbox (105)
I0212 09:45:45.887938 12230 net.cpp:561] ctx_output6/relu_mbox_priorbox <- ctx_output6_ctx_output6/relu_0_split_2
I0212 09:45:45.887944 12230 net.cpp:561] ctx_output6/relu_mbox_priorbox <- data_data_0_split_6
I0212 09:45:45.887951 12230 net.cpp:530] ctx_output6/relu_mbox_priorbox -> ctx_output6/relu_mbox_priorbox
I0212 09:45:45.887997 12230 net.cpp:245] Setting up ctx_output6/relu_mbox_priorbox
I0212 09:45:45.888008 12230 net.cpp:252] TRAIN Top shape for layer 105 'ctx_output6/relu_mbox_priorbox' 1 2 32 (64)
I0212 09:45:45.888025 12230 layer_factory.hpp:136] Creating layer 'mbox_loc' of type 'Concat'
I0212 09:45:45.888031 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.888042 12230 net.cpp:184] Created Layer mbox_loc (106)
I0212 09:45:45.888048 12230 net.cpp:561] mbox_loc <- ctx_output1/relu_mbox_loc_flat
I0212 09:45:45.888056 12230 net.cpp:561] mbox_loc <- ctx_output2/relu_mbox_loc_flat
I0212 09:45:45.888062 12230 net.cpp:561] mbox_loc <- ctx_output3/relu_mbox_loc_flat
I0212 09:45:45.888068 12230 net.cpp:561] mbox_loc <- ctx_output4/relu_mbox_loc_flat
I0212 09:45:45.888073 12230 net.cpp:561] mbox_loc <- ctx_output5/relu_mbox_loc_flat
I0212 09:45:45.888079 12230 net.cpp:561] mbox_loc <- ctx_output6/relu_mbox_loc_flat
I0212 09:45:45.888085 12230 net.cpp:530] mbox_loc -> mbox_loc
I0212 09:45:45.888135 12230 net.cpp:245] Setting up mbox_loc
I0212 09:45:45.888146 12230 net.cpp:252] TRAIN Top shape for layer 106 'mbox_loc' 8 75152 (601216)
I0212 09:45:45.888152 12230 layer_factory.hpp:136] Creating layer 'mbox_conf' of type 'Concat'
I0212 09:45:45.888159 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.888169 12230 net.cpp:184] Created Layer mbox_conf (107)
I0212 09:45:45.888175 12230 net.cpp:561] mbox_conf <- ctx_output1/relu_mbox_conf_flat
I0212 09:45:45.888180 12230 net.cpp:561] mbox_conf <- ctx_output2/relu_mbox_conf_flat
I0212 09:45:45.888186 12230 net.cpp:561] mbox_conf <- ctx_output3/relu_mbox_conf_flat
I0212 09:45:45.888192 12230 net.cpp:561] mbox_conf <- ctx_output4/relu_mbox_conf_flat
I0212 09:45:45.888198 12230 net.cpp:561] mbox_conf <- ctx_output5/relu_mbox_conf_flat
I0212 09:45:45.888203 12230 net.cpp:561] mbox_conf <- ctx_output6/relu_mbox_conf_flat
I0212 09:45:45.888209 12230 net.cpp:530] mbox_conf -> mbox_conf
I0212 09:45:45.888253 12230 net.cpp:245] Setting up mbox_conf
I0212 09:45:45.888264 12230 net.cpp:252] TRAIN Top shape for layer 107 'mbox_conf' 8 75152 (601216)
I0212 09:45:45.888270 12230 layer_factory.hpp:136] Creating layer 'mbox_priorbox' of type 'Concat'
I0212 09:45:45.888275 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.888284 12230 net.cpp:184] Created Layer mbox_priorbox (108)
I0212 09:45:45.888289 12230 net.cpp:561] mbox_priorbox <- ctx_output1/relu_mbox_priorbox
I0212 09:45:45.888296 12230 net.cpp:561] mbox_priorbox <- ctx_output2/relu_mbox_priorbox
I0212 09:45:45.888303 12230 net.cpp:561] mbox_priorbox <- ctx_output3/relu_mbox_priorbox
I0212 09:45:45.888308 12230 net.cpp:561] mbox_priorbox <- ctx_output4/relu_mbox_priorbox
I0212 09:45:45.888314 12230 net.cpp:561] mbox_priorbox <- ctx_output5/relu_mbox_priorbox
I0212 09:45:45.888319 12230 net.cpp:561] mbox_priorbox <- ctx_output6/relu_mbox_priorbox
I0212 09:45:45.888324 12230 net.cpp:530] mbox_priorbox -> mbox_priorbox
I0212 09:45:45.888366 12230 net.cpp:245] Setting up mbox_priorbox
I0212 09:45:45.888377 12230 net.cpp:252] TRAIN Top shape for layer 108 'mbox_priorbox' 1 2 75152 (150304)
I0212 09:45:45.888382 12230 layer_factory.hpp:136] Creating layer 'mbox_loss' of type 'MultiBoxLoss'
I0212 09:45:45.888388 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.888741 12230 net.cpp:184] Created Layer mbox_loss (109)
I0212 09:45:45.888761 12230 net.cpp:561] mbox_loss <- mbox_loc
I0212 09:45:45.888768 12230 net.cpp:561] mbox_loss <- mbox_conf
I0212 09:45:45.888775 12230 net.cpp:561] mbox_loss <- mbox_priorbox
I0212 09:45:45.888782 12230 net.cpp:561] mbox_loss <- label
I0212 09:45:45.888789 12230 net.cpp:530] mbox_loss -> mbox_loss
I0212 09:45:45.888924 12230 layer_factory.hpp:136] Creating layer 'mbox_loss_smooth_L1_loc' of type 'SmoothL1Loss'
I0212 09:45:45.888936 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.889163 12230 layer_factory.hpp:136] Creating layer 'mbox_loss_softmax_conf' of type 'SoftmaxWithLoss'
I0212 09:45:45.889178 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.889763 12230 net.cpp:245] Setting up mbox_loss
I0212 09:45:45.889781 12230 net.cpp:252] TRAIN Top shape for layer 109 'mbox_loss' (1)
I0212 09:45:45.889787 12230 net.cpp:256]     with loss weight 1
I0212 09:45:45.889806 12230 net.cpp:323] mbox_loss needs backward computation.
I0212 09:45:45.889813 12230 net.cpp:325] mbox_priorbox does not need backward computation.
I0212 09:45:45.889823 12230 net.cpp:323] mbox_conf needs backward computation.
I0212 09:45:45.889830 12230 net.cpp:323] mbox_loc needs backward computation.
I0212 09:45:45.889837 12230 net.cpp:325] ctx_output6/relu_mbox_priorbox does not need backward computation.
I0212 09:45:45.889842 12230 net.cpp:323] ctx_output6/relu_mbox_conf_flat needs backward computation.
I0212 09:45:45.889847 12230 net.cpp:323] ctx_output6/relu_mbox_conf_perm needs backward computation.
I0212 09:45:45.889853 12230 net.cpp:323] ctx_output6/relu_mbox_conf needs backward computation.
I0212 09:45:45.889858 12230 net.cpp:323] ctx_output6/relu_mbox_loc_flat needs backward computation.
I0212 09:45:45.889863 12230 net.cpp:323] ctx_output6/relu_mbox_loc_perm needs backward computation.
I0212 09:45:45.889868 12230 net.cpp:323] ctx_output6/relu_mbox_loc needs backward computation.
I0212 09:45:45.889874 12230 net.cpp:325] ctx_output5/relu_mbox_priorbox does not need backward computation.
I0212 09:45:45.889880 12230 net.cpp:323] ctx_output5/relu_mbox_conf_flat needs backward computation.
I0212 09:45:45.889885 12230 net.cpp:323] ctx_output5/relu_mbox_conf_perm needs backward computation.
I0212 09:45:45.889890 12230 net.cpp:323] ctx_output5/relu_mbox_conf needs backward computation.
I0212 09:45:45.889897 12230 net.cpp:323] ctx_output5/relu_mbox_loc_flat needs backward computation.
I0212 09:45:45.889902 12230 net.cpp:323] ctx_output5/relu_mbox_loc_perm needs backward computation.
I0212 09:45:45.889907 12230 net.cpp:323] ctx_output5/relu_mbox_loc needs backward computation.
I0212 09:45:45.889912 12230 net.cpp:325] ctx_output4/relu_mbox_priorbox does not need backward computation.
I0212 09:45:45.889919 12230 net.cpp:323] ctx_output4/relu_mbox_conf_flat needs backward computation.
I0212 09:45:45.889924 12230 net.cpp:323] ctx_output4/relu_mbox_conf_perm needs backward computation.
I0212 09:45:45.889928 12230 net.cpp:323] ctx_output4/relu_mbox_conf needs backward computation.
I0212 09:45:45.889933 12230 net.cpp:323] ctx_output4/relu_mbox_loc_flat needs backward computation.
I0212 09:45:45.889938 12230 net.cpp:323] ctx_output4/relu_mbox_loc_perm needs backward computation.
I0212 09:45:45.889943 12230 net.cpp:323] ctx_output4/relu_mbox_loc needs backward computation.
I0212 09:45:45.889948 12230 net.cpp:325] ctx_output3/relu_mbox_priorbox does not need backward computation.
I0212 09:45:45.889955 12230 net.cpp:323] ctx_output3/relu_mbox_conf_flat needs backward computation.
I0212 09:45:45.889959 12230 net.cpp:323] ctx_output3/relu_mbox_conf_perm needs backward computation.
I0212 09:45:45.889964 12230 net.cpp:323] ctx_output3/relu_mbox_conf needs backward computation.
I0212 09:45:45.889969 12230 net.cpp:323] ctx_output3/relu_mbox_loc_flat needs backward computation.
I0212 09:45:45.889974 12230 net.cpp:323] ctx_output3/relu_mbox_loc_perm needs backward computation.
I0212 09:45:45.889979 12230 net.cpp:323] ctx_output3/relu_mbox_loc needs backward computation.
I0212 09:45:45.889984 12230 net.cpp:325] ctx_output2/relu_mbox_priorbox does not need backward computation.
I0212 09:45:45.889989 12230 net.cpp:323] ctx_output2/relu_mbox_conf_flat needs backward computation.
I0212 09:45:45.889994 12230 net.cpp:323] ctx_output2/relu_mbox_conf_perm needs backward computation.
I0212 09:45:45.889999 12230 net.cpp:323] ctx_output2/relu_mbox_conf needs backward computation.
I0212 09:45:45.890004 12230 net.cpp:323] ctx_output2/relu_mbox_loc_flat needs backward computation.
I0212 09:45:45.890009 12230 net.cpp:323] ctx_output2/relu_mbox_loc_perm needs backward computation.
I0212 09:45:45.890014 12230 net.cpp:323] ctx_output2/relu_mbox_loc needs backward computation.
I0212 09:45:45.890029 12230 net.cpp:325] ctx_output1/relu_mbox_priorbox does not need backward computation.
I0212 09:45:45.890035 12230 net.cpp:323] ctx_output1/relu_mbox_conf_flat needs backward computation.
I0212 09:45:45.890040 12230 net.cpp:323] ctx_output1/relu_mbox_conf_perm needs backward computation.
I0212 09:45:45.890046 12230 net.cpp:323] ctx_output1/relu_mbox_conf needs backward computation.
I0212 09:45:45.890050 12230 net.cpp:323] ctx_output1/relu_mbox_loc_flat needs backward computation.
I0212 09:45:45.890055 12230 net.cpp:323] ctx_output1/relu_mbox_loc_perm needs backward computation.
I0212 09:45:45.890060 12230 net.cpp:323] ctx_output1/relu_mbox_loc needs backward computation.
I0212 09:45:45.890065 12230 net.cpp:323] ctx_output6_ctx_output6/relu_0_split needs backward computation.
I0212 09:45:45.890071 12230 net.cpp:323] ctx_output6/relu needs backward computation.
I0212 09:45:45.890075 12230 net.cpp:323] ctx_output6 needs backward computation.
I0212 09:45:45.890081 12230 net.cpp:323] ctx_output5_ctx_output5/relu_0_split needs backward computation.
I0212 09:45:45.890086 12230 net.cpp:323] ctx_output5/relu needs backward computation.
I0212 09:45:45.890103 12230 net.cpp:323] ctx_output5 needs backward computation.
I0212 09:45:45.890110 12230 net.cpp:323] ctx_output4_ctx_output4/relu_0_split needs backward computation.
I0212 09:45:45.890115 12230 net.cpp:323] ctx_output4/relu needs backward computation.
I0212 09:45:45.890120 12230 net.cpp:323] ctx_output4 needs backward computation.
I0212 09:45:45.890125 12230 net.cpp:323] ctx_output3_ctx_output3/relu_0_split needs backward computation.
I0212 09:45:45.890130 12230 net.cpp:323] ctx_output3/relu needs backward computation.
I0212 09:45:45.890135 12230 net.cpp:323] ctx_output3 needs backward computation.
I0212 09:45:45.890141 12230 net.cpp:323] ctx_output2_ctx_output2/relu_0_split needs backward computation.
I0212 09:45:45.890147 12230 net.cpp:323] ctx_output2/relu needs backward computation.
I0212 09:45:45.890151 12230 net.cpp:323] ctx_output2 needs backward computation.
I0212 09:45:45.890157 12230 net.cpp:323] ctx_output1_ctx_output1/relu_0_split needs backward computation.
I0212 09:45:45.890163 12230 net.cpp:323] ctx_output1/relu needs backward computation.
I0212 09:45:45.890167 12230 net.cpp:323] ctx_output1 needs backward computation.
I0212 09:45:45.890173 12230 net.cpp:323] pool9 needs backward computation.
I0212 09:45:45.890178 12230 net.cpp:323] pool8_pool8_0_split needs backward computation.
I0212 09:45:45.890183 12230 net.cpp:323] pool8 needs backward computation.
I0212 09:45:45.890189 12230 net.cpp:323] pool7_pool7_0_split needs backward computation.
I0212 09:45:45.890194 12230 net.cpp:323] pool7 needs backward computation.
I0212 09:45:45.890199 12230 net.cpp:323] pool6_pool6_0_split needs backward computation.
I0212 09:45:45.890204 12230 net.cpp:323] pool6 needs backward computation.
I0212 09:45:45.890209 12230 net.cpp:323] res5a_branch2b_res5a_branch2b/relu_0_split needs backward computation.
I0212 09:45:45.890215 12230 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0212 09:45:45.890220 12230 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0212 09:45:45.890225 12230 net.cpp:323] res5a_branch2b needs backward computation.
I0212 09:45:45.890231 12230 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0212 09:45:45.890236 12230 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0212 09:45:45.890241 12230 net.cpp:323] res5a_branch2a needs backward computation.
I0212 09:45:45.890246 12230 net.cpp:323] pool4 needs backward computation.
I0212 09:45:45.890251 12230 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0212 09:45:45.890256 12230 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0212 09:45:45.890260 12230 net.cpp:323] res4a_branch2b needs backward computation.
I0212 09:45:45.890266 12230 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0212 09:45:45.890270 12230 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0212 09:45:45.890282 12230 net.cpp:323] res4a_branch2a needs backward computation.
I0212 09:45:45.890288 12230 net.cpp:323] pool3 needs backward computation.
I0212 09:45:45.890293 12230 net.cpp:323] res3a_branch2b_res3a_branch2b/relu_0_split needs backward computation.
I0212 09:45:45.890300 12230 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0212 09:45:45.890305 12230 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0212 09:45:45.890308 12230 net.cpp:323] res3a_branch2b needs backward computation.
I0212 09:45:45.890314 12230 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0212 09:45:45.890319 12230 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0212 09:45:45.890323 12230 net.cpp:323] res3a_branch2a needs backward computation.
I0212 09:45:45.890329 12230 net.cpp:323] pool2 needs backward computation.
I0212 09:45:45.890334 12230 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0212 09:45:45.890338 12230 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0212 09:45:45.890343 12230 net.cpp:323] res2a_branch2b needs backward computation.
I0212 09:45:45.890348 12230 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0212 09:45:45.890353 12230 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0212 09:45:45.890358 12230 net.cpp:323] res2a_branch2a needs backward computation.
I0212 09:45:45.890363 12230 net.cpp:323] pool1 needs backward computation.
I0212 09:45:45.890368 12230 net.cpp:323] conv1b/relu needs backward computation.
I0212 09:45:45.890373 12230 net.cpp:323] conv1b/bn needs backward computation.
I0212 09:45:45.890378 12230 net.cpp:323] conv1b needs backward computation.
I0212 09:45:45.890383 12230 net.cpp:323] conv1a/relu needs backward computation.
I0212 09:45:45.890388 12230 net.cpp:323] conv1a/bn needs backward computation.
I0212 09:45:45.890393 12230 net.cpp:323] conv1a needs backward computation.
I0212 09:45:45.890399 12230 net.cpp:325] data/bias does not need backward computation.
I0212 09:45:45.890406 12230 net.cpp:325] data_data_0_split does not need backward computation.
I0212 09:45:45.890413 12230 net.cpp:325] data does not need backward computation.
I0212 09:45:45.890416 12230 net.cpp:367] This network produces output mbox_loss
I0212 09:45:45.890542 12230 net.cpp:389] Top memory (TRAIN) required for data: 1304123976 diff: 1304123976
I0212 09:45:45.890552 12230 net.cpp:392] Bottom memory (TRAIN) required for data: 1304123968 diff: 1304123968
I0212 09:45:45.890558 12230 net.cpp:395] Shared (in-place) memory (TRAIN) by data: 563789824 diff: 563789824
I0212 09:45:45.890563 12230 net.cpp:398] Parameters memory (TRAIN) required for data: 12464288 diff: 12464288
I0212 09:45:45.890568 12230 net.cpp:401] Parameters shared memory (TRAIN) by data: 0 diff: 0
I0212 09:45:45.890571 12230 net.cpp:407] Network initialization done.
I0212 09:45:45.901590 12230 solver.cpp:177] Creating test net (#0) specified by test_net file: training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/test.prototxt
I0212 09:45:45.902523 12230 net.cpp:72] Initializing net from parameters: 
name: "ssdJacintoNetV2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_value: 0
    mean_value: 0
    mean_value: 0
    force_color: false
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 368
      width: 720
      interp_mode: LINEAR
    }
    crop_h: 368
    crop_w: 720
  }
  data_param {
    source: "/user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_test_lmdb"
    batch_size: 4
    backend: LMDB
    threads: 4
    parser_threads: 4
  }
  annotated_data_param {
    batch_sampler {
    }
    label_map_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/labelmap.prototxt"
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "pool6"
  top: "pool7"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool8"
  type: "Pooling"
  bottom: "pool7"
  top: "pool8"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool9"
  type: "Pooling"
  bottom: "pool8"
  top: "pool9"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "ctx_output1"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "ctx_output1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu"
  type: "ReLU"
  bottom: "ctx_output1"
  top: "ctx_output1"
}
layer {
  name: "ctx_output2"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "ctx_output2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu"
  type: "ReLU"
  bottom: "ctx_output2"
  top: "ctx_output2"
}
layer {
  name: "ctx_output3"
  type: "Convolution"
  bottom: "pool6"
  top: "ctx_output3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu"
  type: "ReLU"
  bottom: "ctx_output3"
  top: "ctx_output3"
}
layer {
  name: "ctx_output4"
  type: "Convolution"
  bottom: "pool7"
  top: "ctx_output4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu"
  type: "ReLU"
  bottom: "ctx_output4"
  top: "ctx_output4"
}
layer {
  name: "ctx_output5"
  type: "Convolution"
  bottom: "pool8"
  top: "ctx_output5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu"
  type: "ReLU"
  bottom: "ctx_output5"
  top: "ctx_output5"
}
layer {
  name: "ctx_output6"
  type: "Convolution"
  bottom: "pool9"
  top: "ctx_output6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu"
  type: "ReLU"
  bottom: "ctx_output6"
  top: "ctx_output6"
}
layer {
  name: "ctx_output1/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_loc"
  top: "ctx_output1/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_loc_perm"
  top: "ctx_output1/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_conf"
  top: "ctx_output1/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_conf_perm"
  top: "ctx_output1/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output1"
  bottom: "data"
  top: "ctx_output1/relu_mbox_priorbox"
  prior_box_param {
    min_size: 14.72
    max_size: 36.8
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_loc"
  top: "ctx_output2/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_loc_perm"
  top: "ctx_output2/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_conf"
  top: "ctx_output2/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_conf_perm"
  top: "ctx_output2/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output2"
  bottom: "data"
  top: "ctx_output2/relu_mbox_priorbox"
  prior_box_param {
    min_size: 36.8
    max_size: 110.4
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_loc"
  top: "ctx_output3/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_loc_perm"
  top: "ctx_output3/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_conf"
  top: "ctx_output3/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_conf_perm"
  top: "ctx_output3/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output3"
  bottom: "data"
  top: "ctx_output3/relu_mbox_priorbox"
  prior_box_param {
    min_size: 110.4
    max_size: 184
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_loc"
  top: "ctx_output4/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_loc_perm"
  top: "ctx_output4/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_conf"
  top: "ctx_output4/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_conf_perm"
  top: "ctx_output4/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output4"
  bottom: "data"
  top: "ctx_output4/relu_mbox_priorbox"
  prior_box_param {
    min_size: 184
    max_size: 257.6
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_loc"
  top: "ctx_output5/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_loc_perm"
  top: "ctx_output5/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_conf"
  top: "ctx_output5/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_conf_perm"
  top: "ctx_output5/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output5"
  bottom: "data"
  top: "ctx_output5/relu_mbox_priorbox"
  prior_box_param {
    min_size: 257.6
    max_size: 331.2
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_loc"
  top: "ctx_output6/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_loc_perm"
  top: "ctx_output6/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_conf"
  top: "ctx_output6/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_conf_perm"
  top: "ctx_output6/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output6"
  bottom: "data"
  top: "ctx_output6/relu_mbox_priorbox"
  prior_box_param {
    min_size: 331.2
    max_size: 404.8
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_loc_flat"
  bottom: "ctx_output2/relu_mbox_loc_flat"
  bottom: "ctx_output3/relu_mbox_loc_flat"
  bottom: "ctx_output4/relu_mbox_loc_flat"
  bottom: "ctx_output5/relu_mbox_loc_flat"
  bottom: "ctx_output6/relu_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_conf_flat"
  bottom: "ctx_output2/relu_mbox_conf_flat"
  bottom: "ctx_output3/relu_mbox_conf_flat"
  bottom: "ctx_output4/relu_mbox_conf_flat"
  bottom: "ctx_output5/relu_mbox_conf_flat"
  bottom: "ctx_output6/relu_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_priorbox"
  bottom: "ctx_output2/relu_mbox_priorbox"
  bottom: "ctx_output3/relu_mbox_priorbox"
  bottom: "ctx_output4/relu_mbox_priorbox"
  bottom: "ctx_output5/relu_mbox_priorbox"
  bottom: "ctx_output6/relu_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_reshape"
  type: "Reshape"
  bottom: "mbox_conf"
  top: "mbox_conf_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: -1
      dim: 4
    }
  }
}
layer {
  name: "mbox_conf_softmax"
  type: "Softmax"
  bottom: "mbox_conf_reshape"
  top: "mbox_conf_softmax"
  softmax_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_flatten"
  type: "Flatten"
  bottom: "mbox_conf_softmax"
  top: "mbox_conf_flatten"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "detection_out"
  type: "DetectionOutput"
  bottom: "mbox_loc"
  bottom: "mbox_conf_flatten"
  bottom: "mbox_priorbox"
  top: "detection_out"
  include {
    phase: TEST
  }
  detection_output_param {
    num_classes: 4
    share_location: true
    background_label_id: 0
    nms_param {
      nms_threshold: 0.45
      top_k: 400
    }
    save_output_param {
      output_directory: ""
      output_name_prefix: "comp4_det_test_"
      output_format: "VOC"
      label_map_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/labelmap.prototxt"
      name_size_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/test_name_size.txt"
      num_test_image: 3609
    }
    code_type: CENTER_SIZE
    keep_top_k: 200
    confidence_threshold: 0.01
  }
}
layer {
  name: "detection_eval"
  type: "DetectionEvaluate"
  bottom: "detection_out"
  bottom: "label"
  top: "detection_eval"
  include {
    phase: TEST
  }
  detection_evaluate_param {
    num_classes: 4
    background_label_id: 0
    overlap_threshold: 0.5
    evaluate_difficult_gt: false
    name_size_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/test_name_size.txt"
  }
}
I0212 09:45:45.903146 12230 net.cpp:104] Using FLOAT as default forward math type
I0212 09:45:45.903158 12230 net.cpp:110] Using FLOAT as default backward math type
I0212 09:45:45.903164 12230 layer_factory.hpp:136] Creating layer 'data' of type 'AnnotatedData'
I0212 09:45:45.903170 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.903194 12230 net.cpp:184] Created Layer data (0)
I0212 09:45:45.903200 12230 net.cpp:530] data -> data
I0212 09:45:45.903208 12230 net.cpp:530] data -> label
I0212 09:45:45.903223 12230 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 4
I0212 09:45:45.903234 12230 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0212 09:45:45.950978 12330 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_test_lmdb
I0212 09:45:45.977452 12230 annotated_data_layer.cpp:219] output data size: 4,3,368,720
I0212 09:45:45.977552 12230 annotated_data_layer.cpp:265] (0) Output data size: 4, 3, 368, 720
I0212 09:45:45.977649 12230 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0212 09:45:45.977740 12230 net.cpp:245] Setting up data
I0212 09:45:45.977766 12230 net.cpp:252] TEST Top shape for layer 0 'data' 4 3 368 720 (3179520)
I0212 09:45:45.977783 12230 net.cpp:252] TEST Top shape for layer 0 'data' 1 1 31 8 (248)
I0212 09:45:45.977799 12230 layer_factory.hpp:136] Creating layer 'data_data_0_split' of type 'Split'
I0212 09:45:45.977814 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.977838 12230 net.cpp:184] Created Layer data_data_0_split (1)
I0212 09:45:45.977849 12230 net.cpp:561] data_data_0_split <- data
I0212 09:45:45.977865 12230 net.cpp:530] data_data_0_split -> data_data_0_split_0
I0212 09:45:45.977881 12230 net.cpp:530] data_data_0_split -> data_data_0_split_1
I0212 09:45:45.977895 12230 net.cpp:530] data_data_0_split -> data_data_0_split_2
I0212 09:45:45.977907 12230 net.cpp:530] data_data_0_split -> data_data_0_split_3
I0212 09:45:45.977923 12230 net.cpp:530] data_data_0_split -> data_data_0_split_4
I0212 09:45:45.977936 12230 net.cpp:530] data_data_0_split -> data_data_0_split_5
I0212 09:45:45.977949 12230 net.cpp:530] data_data_0_split -> data_data_0_split_6
I0212 09:45:45.978312 12230 net.cpp:245] Setting up data_data_0_split
I0212 09:45:45.978338 12230 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 368 720 (3179520)
I0212 09:45:45.978351 12230 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 368 720 (3179520)
I0212 09:45:45.978364 12230 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 368 720 (3179520)
I0212 09:45:45.978375 12230 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 368 720 (3179520)
I0212 09:45:45.978385 12230 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 368 720 (3179520)
I0212 09:45:45.978411 12230 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 368 720 (3179520)
I0212 09:45:45.978422 12230 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 368 720 (3179520)
I0212 09:45:45.978432 12230 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0212 09:45:45.978442 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.978461 12230 net.cpp:184] Created Layer data/bias (2)
I0212 09:45:45.978471 12230 net.cpp:561] data/bias <- data_data_0_split_0
I0212 09:45:45.978482 12230 net.cpp:530] data/bias -> data/bias
I0212 09:45:45.980386 12332 annotated_data_layer.cpp:111] (0) Parser threads: 1
I0212 09:45:45.980420 12332 annotated_data_layer.cpp:113] (0) Transformer threads: 1
I0212 09:45:45.981091 12230 net.cpp:245] Setting up data/bias
I0212 09:45:45.981113 12230 net.cpp:252] TEST Top shape for layer 2 'data/bias' 4 3 368 720 (3179520)
I0212 09:45:45.981127 12230 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0212 09:45:45.981135 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.981155 12230 net.cpp:184] Created Layer conv1a (3)
I0212 09:45:45.981163 12230 net.cpp:561] conv1a <- data/bias
I0212 09:45:45.981169 12230 net.cpp:530] conv1a -> conv1a
I0212 09:45:45.982051 12230 net.cpp:245] Setting up conv1a
I0212 09:45:45.982074 12230 net.cpp:252] TEST Top shape for layer 3 'conv1a' 4 32 184 360 (8478720)
I0212 09:45:45.982089 12230 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0212 09:45:45.982112 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.982128 12230 net.cpp:184] Created Layer conv1a/bn (4)
I0212 09:45:45.982136 12230 net.cpp:561] conv1a/bn <- conv1a
I0212 09:45:45.982142 12230 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0212 09:45:45.983382 12230 net.cpp:245] Setting up conv1a/bn
I0212 09:45:45.983404 12230 net.cpp:252] TEST Top shape for layer 4 'conv1a/bn' 4 32 184 360 (8478720)
I0212 09:45:45.983422 12230 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0212 09:45:45.983429 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.983453 12230 net.cpp:184] Created Layer conv1a/relu (5)
I0212 09:45:45.983459 12230 net.cpp:561] conv1a/relu <- conv1a
I0212 09:45:45.983466 12230 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0212 09:45:45.983477 12230 net.cpp:245] Setting up conv1a/relu
I0212 09:45:45.983489 12230 net.cpp:252] TEST Top shape for layer 5 'conv1a/relu' 4 32 184 360 (8478720)
I0212 09:45:45.983497 12230 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0212 09:45:45.983507 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.983531 12230 net.cpp:184] Created Layer conv1b (6)
I0212 09:45:45.983541 12230 net.cpp:561] conv1b <- conv1a
I0212 09:45:45.983551 12230 net.cpp:530] conv1b -> conv1b
I0212 09:45:45.984916 12230 net.cpp:245] Setting up conv1b
I0212 09:45:45.984939 12230 net.cpp:252] TEST Top shape for layer 6 'conv1b' 4 32 184 360 (8478720)
I0212 09:45:45.984954 12230 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0212 09:45:45.984961 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.984974 12230 net.cpp:184] Created Layer conv1b/bn (7)
I0212 09:45:45.984980 12230 net.cpp:561] conv1b/bn <- conv1b
I0212 09:45:45.984987 12230 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0212 09:45:45.986243 12230 net.cpp:245] Setting up conv1b/bn
I0212 09:45:45.986263 12230 net.cpp:252] TEST Top shape for layer 7 'conv1b/bn' 4 32 184 360 (8478720)
I0212 09:45:45.986279 12230 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0212 09:45:45.986286 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.986296 12230 net.cpp:184] Created Layer conv1b/relu (8)
I0212 09:45:45.986304 12230 net.cpp:561] conv1b/relu <- conv1b
I0212 09:45:45.986310 12230 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0212 09:45:45.986325 12230 net.cpp:245] Setting up conv1b/relu
I0212 09:45:45.986336 12230 net.cpp:252] TEST Top shape for layer 8 'conv1b/relu' 4 32 184 360 (8478720)
I0212 09:45:45.986346 12230 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0212 09:45:45.986356 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.986378 12230 net.cpp:184] Created Layer pool1 (9)
I0212 09:45:45.986392 12230 net.cpp:561] pool1 <- conv1b
I0212 09:45:45.986402 12230 net.cpp:530] pool1 -> pool1
I0212 09:45:45.986560 12230 net.cpp:245] Setting up pool1
I0212 09:45:45.986579 12230 net.cpp:252] TEST Top shape for layer 9 'pool1' 4 32 92 180 (2119680)
I0212 09:45:45.986594 12230 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0212 09:45:45.986603 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.986627 12230 net.cpp:184] Created Layer res2a_branch2a (10)
I0212 09:45:45.986640 12230 net.cpp:561] res2a_branch2a <- pool1
I0212 09:45:45.986650 12230 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0212 09:45:45.988255 12230 net.cpp:245] Setting up res2a_branch2a
I0212 09:45:45.988276 12230 net.cpp:252] TEST Top shape for layer 10 'res2a_branch2a' 4 64 92 180 (4239360)
I0212 09:45:45.988291 12230 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0212 09:45:45.988297 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.988309 12230 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0212 09:45:45.988315 12230 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0212 09:45:45.988324 12230 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0212 09:45:45.989606 12230 net.cpp:245] Setting up res2a_branch2a/bn
I0212 09:45:45.989627 12230 net.cpp:252] TEST Top shape for layer 11 'res2a_branch2a/bn' 4 64 92 180 (4239360)
I0212 09:45:45.989643 12230 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0212 09:45:45.989651 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.989675 12230 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0212 09:45:45.989686 12230 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0212 09:45:45.989696 12230 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0212 09:45:45.989711 12230 net.cpp:245] Setting up res2a_branch2a/relu
I0212 09:45:45.989722 12230 net.cpp:252] TEST Top shape for layer 12 'res2a_branch2a/relu' 4 64 92 180 (4239360)
I0212 09:45:45.989732 12230 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0212 09:45:45.989742 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.989766 12230 net.cpp:184] Created Layer res2a_branch2b (13)
I0212 09:45:45.989784 12230 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0212 09:45:45.989794 12230 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0212 09:45:45.990993 12230 net.cpp:245] Setting up res2a_branch2b
I0212 09:45:45.991014 12230 net.cpp:252] TEST Top shape for layer 13 'res2a_branch2b' 4 64 92 180 (4239360)
I0212 09:45:45.991024 12230 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0212 09:45:45.991029 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.991041 12230 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0212 09:45:45.991047 12230 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0212 09:45:45.991053 12230 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0212 09:45:45.992213 12230 net.cpp:245] Setting up res2a_branch2b/bn
I0212 09:45:45.992233 12230 net.cpp:252] TEST Top shape for layer 14 'res2a_branch2b/bn' 4 64 92 180 (4239360)
I0212 09:45:45.992246 12230 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0212 09:45:45.992252 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.992261 12230 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0212 09:45:45.992267 12230 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0212 09:45:45.992274 12230 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0212 09:45:45.992286 12230 net.cpp:245] Setting up res2a_branch2b/relu
I0212 09:45:45.992296 12230 net.cpp:252] TEST Top shape for layer 15 'res2a_branch2b/relu' 4 64 92 180 (4239360)
I0212 09:45:45.992306 12230 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0212 09:45:45.992316 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.992331 12230 net.cpp:184] Created Layer pool2 (16)
I0212 09:45:45.992339 12230 net.cpp:561] pool2 <- res2a_branch2b
I0212 09:45:45.992348 12230 net.cpp:530] pool2 -> pool2
I0212 09:45:45.992496 12230 net.cpp:245] Setting up pool2
I0212 09:45:45.992516 12230 net.cpp:252] TEST Top shape for layer 16 'pool2' 4 64 46 90 (1059840)
I0212 09:45:45.992527 12230 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0212 09:45:45.992535 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.992558 12230 net.cpp:184] Created Layer res3a_branch2a (17)
I0212 09:45:45.992570 12230 net.cpp:561] res3a_branch2a <- pool2
I0212 09:45:45.992579 12230 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0212 09:45:45.996074 12230 net.cpp:245] Setting up res3a_branch2a
I0212 09:45:45.996094 12230 net.cpp:252] TEST Top shape for layer 17 'res3a_branch2a' 4 128 46 90 (2119680)
I0212 09:45:45.996105 12230 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0212 09:45:45.996112 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.996124 12230 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0212 09:45:45.996129 12230 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0212 09:45:45.996136 12230 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0212 09:45:45.997268 12230 net.cpp:245] Setting up res3a_branch2a/bn
I0212 09:45:45.997299 12230 net.cpp:252] TEST Top shape for layer 18 'res3a_branch2a/bn' 4 128 46 90 (2119680)
I0212 09:45:45.997318 12230 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0212 09:45:45.997326 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.997335 12230 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0212 09:45:45.997341 12230 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0212 09:45:45.997350 12230 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0212 09:45:45.997364 12230 net.cpp:245] Setting up res3a_branch2a/relu
I0212 09:45:45.997376 12230 net.cpp:252] TEST Top shape for layer 19 'res3a_branch2a/relu' 4 128 46 90 (2119680)
I0212 09:45:45.997385 12230 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0212 09:45:45.997393 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.997416 12230 net.cpp:184] Created Layer res3a_branch2b (20)
I0212 09:45:45.997426 12230 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0212 09:45:45.997436 12230 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0212 09:45:45.999545 12230 net.cpp:245] Setting up res3a_branch2b
I0212 09:45:45.999565 12230 net.cpp:252] TEST Top shape for layer 20 'res3a_branch2b' 4 128 46 90 (2119680)
I0212 09:45:45.999575 12230 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0212 09:45:45.999583 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:45.999593 12230 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0212 09:45:45.999599 12230 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0212 09:45:45.999606 12230 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0212 09:45:46.000789 12230 net.cpp:245] Setting up res3a_branch2b/bn
I0212 09:45:46.000808 12230 net.cpp:252] TEST Top shape for layer 21 'res3a_branch2b/bn' 4 128 46 90 (2119680)
I0212 09:45:46.000823 12230 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0212 09:45:46.000829 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.000839 12230 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0212 09:45:46.000845 12230 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0212 09:45:46.000852 12230 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0212 09:45:46.000864 12230 net.cpp:245] Setting up res3a_branch2b/relu
I0212 09:45:46.000875 12230 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b/relu' 4 128 46 90 (2119680)
I0212 09:45:46.000885 12230 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0212 09:45:46.000895 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.000905 12230 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (23)
I0212 09:45:46.000913 12230 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0212 09:45:46.000923 12230 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0212 09:45:46.000934 12230 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0212 09:45:46.001044 12230 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0212 09:45:46.001063 12230 net.cpp:252] TEST Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 4 128 46 90 (2119680)
I0212 09:45:46.001075 12230 net.cpp:252] TEST Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 4 128 46 90 (2119680)
I0212 09:45:46.001085 12230 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0212 09:45:46.001094 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.001109 12230 net.cpp:184] Created Layer pool3 (24)
I0212 09:45:46.001118 12230 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0212 09:45:46.001147 12230 net.cpp:530] pool3 -> pool3
I0212 09:45:46.001287 12230 net.cpp:245] Setting up pool3
I0212 09:45:46.001304 12230 net.cpp:252] TEST Top shape for layer 24 'pool3' 4 128 23 45 (529920)
I0212 09:45:46.001314 12230 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0212 09:45:46.001323 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.001350 12230 net.cpp:184] Created Layer res4a_branch2a (25)
I0212 09:45:46.001359 12230 net.cpp:561] res4a_branch2a <- pool3
I0212 09:45:46.001370 12230 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0212 09:45:46.014175 12230 net.cpp:245] Setting up res4a_branch2a
I0212 09:45:46.014209 12230 net.cpp:252] TEST Top shape for layer 25 'res4a_branch2a' 4 256 23 45 (1059840)
I0212 09:45:46.014221 12230 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0212 09:45:46.014230 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.014247 12230 net.cpp:184] Created Layer res4a_branch2a/bn (26)
I0212 09:45:46.014257 12230 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0212 09:45:46.014268 12230 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0212 09:45:46.015427 12230 net.cpp:245] Setting up res4a_branch2a/bn
I0212 09:45:46.015446 12230 net.cpp:252] TEST Top shape for layer 26 'res4a_branch2a/bn' 4 256 23 45 (1059840)
I0212 09:45:46.015461 12230 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0212 09:45:46.015468 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.015476 12230 net.cpp:184] Created Layer res4a_branch2a/relu (27)
I0212 09:45:46.015482 12230 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0212 09:45:46.015491 12230 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0212 09:45:46.015506 12230 net.cpp:245] Setting up res4a_branch2a/relu
I0212 09:45:46.015517 12230 net.cpp:252] TEST Top shape for layer 27 'res4a_branch2a/relu' 4 256 23 45 (1059840)
I0212 09:45:46.015527 12230 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0212 09:45:46.015535 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.015561 12230 net.cpp:184] Created Layer res4a_branch2b (28)
I0212 09:45:46.015571 12230 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0212 09:45:46.015580 12230 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0212 09:45:46.026401 12230 net.cpp:245] Setting up res4a_branch2b
I0212 09:45:46.026443 12230 net.cpp:252] TEST Top shape for layer 28 'res4a_branch2b' 4 256 23 45 (1059840)
I0212 09:45:46.026456 12230 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0212 09:45:46.026463 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.026480 12230 net.cpp:184] Created Layer res4a_branch2b/bn (29)
I0212 09:45:46.026490 12230 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0212 09:45:46.026500 12230 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0212 09:45:46.027737 12230 net.cpp:245] Setting up res4a_branch2b/bn
I0212 09:45:46.027757 12230 net.cpp:252] TEST Top shape for layer 29 'res4a_branch2b/bn' 4 256 23 45 (1059840)
I0212 09:45:46.027772 12230 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0212 09:45:46.027779 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.027791 12230 net.cpp:184] Created Layer res4a_branch2b/relu (30)
I0212 09:45:46.027797 12230 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0212 09:45:46.027807 12230 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0212 09:45:46.027822 12230 net.cpp:245] Setting up res4a_branch2b/relu
I0212 09:45:46.027833 12230 net.cpp:252] TEST Top shape for layer 30 'res4a_branch2b/relu' 4 256 23 45 (1059840)
I0212 09:45:46.027864 12230 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0212 09:45:46.027874 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.027892 12230 net.cpp:184] Created Layer pool4 (31)
I0212 09:45:46.027910 12230 net.cpp:561] pool4 <- res4a_branch2b
I0212 09:45:46.027921 12230 net.cpp:530] pool4 -> pool4
I0212 09:45:46.028084 12230 net.cpp:245] Setting up pool4
I0212 09:45:46.028105 12230 net.cpp:252] TEST Top shape for layer 31 'pool4' 4 256 12 23 (282624)
I0212 09:45:46.028115 12230 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0212 09:45:46.028125 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.028158 12230 net.cpp:184] Created Layer res5a_branch2a (32)
I0212 09:45:46.028170 12230 net.cpp:561] res5a_branch2a <- pool4
I0212 09:45:46.028180 12230 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0212 09:45:46.074021 12230 net.cpp:245] Setting up res5a_branch2a
I0212 09:45:46.074056 12230 net.cpp:252] TEST Top shape for layer 32 'res5a_branch2a' 4 512 12 23 (565248)
I0212 09:45:46.074070 12230 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0212 09:45:46.074079 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.074111 12230 net.cpp:184] Created Layer res5a_branch2a/bn (33)
I0212 09:45:46.074120 12230 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0212 09:45:46.074128 12230 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0212 09:45:46.075330 12230 net.cpp:245] Setting up res5a_branch2a/bn
I0212 09:45:46.075350 12230 net.cpp:252] TEST Top shape for layer 33 'res5a_branch2a/bn' 4 512 12 23 (565248)
I0212 09:45:46.075364 12230 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0212 09:45:46.075371 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.075382 12230 net.cpp:184] Created Layer res5a_branch2a/relu (34)
I0212 09:45:46.075388 12230 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0212 09:45:46.075395 12230 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0212 09:45:46.075404 12230 net.cpp:245] Setting up res5a_branch2a/relu
I0212 09:45:46.075417 12230 net.cpp:252] TEST Top shape for layer 34 'res5a_branch2a/relu' 4 512 12 23 (565248)
I0212 09:45:46.075425 12230 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0212 09:45:46.075434 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.075462 12230 net.cpp:184] Created Layer res5a_branch2b (35)
I0212 09:45:46.075475 12230 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0212 09:45:46.075485 12230 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0212 09:45:46.098861 12230 net.cpp:245] Setting up res5a_branch2b
I0212 09:45:46.098897 12230 net.cpp:252] TEST Top shape for layer 35 'res5a_branch2b' 4 512 12 23 (565248)
I0212 09:45:46.098923 12230 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0212 09:45:46.098937 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.098960 12230 net.cpp:184] Created Layer res5a_branch2b/bn (36)
I0212 09:45:46.098975 12230 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0212 09:45:46.098986 12230 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0212 09:45:46.100180 12230 net.cpp:245] Setting up res5a_branch2b/bn
I0212 09:45:46.100199 12230 net.cpp:252] TEST Top shape for layer 36 'res5a_branch2b/bn' 4 512 12 23 (565248)
I0212 09:45:46.100219 12230 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0212 09:45:46.100234 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.100250 12230 net.cpp:184] Created Layer res5a_branch2b/relu (37)
I0212 09:45:46.100260 12230 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0212 09:45:46.100291 12230 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0212 09:45:46.100309 12230 net.cpp:245] Setting up res5a_branch2b/relu
I0212 09:45:46.100322 12230 net.cpp:252] TEST Top shape for layer 37 'res5a_branch2b/relu' 4 512 12 23 (565248)
I0212 09:45:46.100332 12230 layer_factory.hpp:136] Creating layer 'res5a_branch2b_res5a_branch2b/relu_0_split' of type 'Split'
I0212 09:45:46.100342 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.100354 12230 net.cpp:184] Created Layer res5a_branch2b_res5a_branch2b/relu_0_split (38)
I0212 09:45:46.100365 12230 net.cpp:561] res5a_branch2b_res5a_branch2b/relu_0_split <- res5a_branch2b
I0212 09:45:46.100375 12230 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_0
I0212 09:45:46.100391 12230 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_1
I0212 09:45:46.100514 12230 net.cpp:245] Setting up res5a_branch2b_res5a_branch2b/relu_0_split
I0212 09:45:46.100533 12230 net.cpp:252] TEST Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 4 512 12 23 (565248)
I0212 09:45:46.100546 12230 net.cpp:252] TEST Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 4 512 12 23 (565248)
I0212 09:45:46.100555 12230 layer_factory.hpp:136] Creating layer 'pool6' of type 'Pooling'
I0212 09:45:46.100566 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.100584 12230 net.cpp:184] Created Layer pool6 (39)
I0212 09:45:46.100596 12230 net.cpp:561] pool6 <- res5a_branch2b_res5a_branch2b/relu_0_split_0
I0212 09:45:46.100606 12230 net.cpp:530] pool6 -> pool6
I0212 09:45:46.100760 12230 net.cpp:245] Setting up pool6
I0212 09:45:46.100778 12230 net.cpp:252] TEST Top shape for layer 39 'pool6' 4 512 6 12 (147456)
I0212 09:45:46.100790 12230 layer_factory.hpp:136] Creating layer 'pool6_pool6_0_split' of type 'Split'
I0212 09:45:46.100798 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.100811 12230 net.cpp:184] Created Layer pool6_pool6_0_split (40)
I0212 09:45:46.100821 12230 net.cpp:561] pool6_pool6_0_split <- pool6
I0212 09:45:46.100831 12230 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_0
I0212 09:45:46.100841 12230 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_1
I0212 09:45:46.100941 12230 net.cpp:245] Setting up pool6_pool6_0_split
I0212 09:45:46.100957 12230 net.cpp:252] TEST Top shape for layer 40 'pool6_pool6_0_split' 4 512 6 12 (147456)
I0212 09:45:46.100970 12230 net.cpp:252] TEST Top shape for layer 40 'pool6_pool6_0_split' 4 512 6 12 (147456)
I0212 09:45:46.100980 12230 layer_factory.hpp:136] Creating layer 'pool7' of type 'Pooling'
I0212 09:45:46.100992 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.101011 12230 net.cpp:184] Created Layer pool7 (41)
I0212 09:45:46.101022 12230 net.cpp:561] pool7 <- pool6_pool6_0_split_0
I0212 09:45:46.101032 12230 net.cpp:530] pool7 -> pool7
I0212 09:45:46.101173 12230 net.cpp:245] Setting up pool7
I0212 09:45:46.101193 12230 net.cpp:252] TEST Top shape for layer 41 'pool7' 4 512 3 6 (36864)
I0212 09:45:46.101207 12230 layer_factory.hpp:136] Creating layer 'pool7_pool7_0_split' of type 'Split'
I0212 09:45:46.101217 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.101230 12230 net.cpp:184] Created Layer pool7_pool7_0_split (42)
I0212 09:45:46.101241 12230 net.cpp:561] pool7_pool7_0_split <- pool7
I0212 09:45:46.101251 12230 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_0
I0212 09:45:46.101266 12230 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_1
I0212 09:45:46.101374 12230 net.cpp:245] Setting up pool7_pool7_0_split
I0212 09:45:46.101392 12230 net.cpp:252] TEST Top shape for layer 42 'pool7_pool7_0_split' 4 512 3 6 (36864)
I0212 09:45:46.101404 12230 net.cpp:252] TEST Top shape for layer 42 'pool7_pool7_0_split' 4 512 3 6 (36864)
I0212 09:45:46.101428 12230 layer_factory.hpp:136] Creating layer 'pool8' of type 'Pooling'
I0212 09:45:46.101438 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.101454 12230 net.cpp:184] Created Layer pool8 (43)
I0212 09:45:46.101465 12230 net.cpp:561] pool8 <- pool7_pool7_0_split_0
I0212 09:45:46.101475 12230 net.cpp:530] pool8 -> pool8
I0212 09:45:46.101619 12230 net.cpp:245] Setting up pool8
I0212 09:45:46.101637 12230 net.cpp:252] TEST Top shape for layer 43 'pool8' 4 512 2 3 (12288)
I0212 09:45:46.101649 12230 layer_factory.hpp:136] Creating layer 'pool8_pool8_0_split' of type 'Split'
I0212 09:45:46.101657 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.101668 12230 net.cpp:184] Created Layer pool8_pool8_0_split (44)
I0212 09:45:46.101678 12230 net.cpp:561] pool8_pool8_0_split <- pool8
I0212 09:45:46.101688 12230 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_0
I0212 09:45:46.101701 12230 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_1
I0212 09:45:46.101800 12230 net.cpp:245] Setting up pool8_pool8_0_split
I0212 09:45:46.101816 12230 net.cpp:252] TEST Top shape for layer 44 'pool8_pool8_0_split' 4 512 2 3 (12288)
I0212 09:45:46.101830 12230 net.cpp:252] TEST Top shape for layer 44 'pool8_pool8_0_split' 4 512 2 3 (12288)
I0212 09:45:46.101838 12230 layer_factory.hpp:136] Creating layer 'pool9' of type 'Pooling'
I0212 09:45:46.101848 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.101864 12230 net.cpp:184] Created Layer pool9 (45)
I0212 09:45:46.101876 12230 net.cpp:561] pool9 <- pool8_pool8_0_split_0
I0212 09:45:46.101886 12230 net.cpp:530] pool9 -> pool9
I0212 09:45:46.102025 12230 net.cpp:245] Setting up pool9
I0212 09:45:46.102042 12230 net.cpp:252] TEST Top shape for layer 45 'pool9' 4 512 1 2 (4096)
I0212 09:45:46.102053 12230 layer_factory.hpp:136] Creating layer 'ctx_output1' of type 'Convolution'
I0212 09:45:46.102062 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.102113 12230 net.cpp:184] Created Layer ctx_output1 (46)
I0212 09:45:46.102128 12230 net.cpp:561] ctx_output1 <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0212 09:45:46.102140 12230 net.cpp:530] ctx_output1 -> ctx_output1
I0212 09:45:46.104622 12230 net.cpp:245] Setting up ctx_output1
I0212 09:45:46.104647 12230 net.cpp:252] TEST Top shape for layer 46 'ctx_output1' 4 256 46 90 (4239360)
I0212 09:45:46.104666 12230 layer_factory.hpp:136] Creating layer 'ctx_output1/relu' of type 'ReLU'
I0212 09:45:46.104678 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.104693 12230 net.cpp:184] Created Layer ctx_output1/relu (47)
I0212 09:45:46.104704 12230 net.cpp:561] ctx_output1/relu <- ctx_output1
I0212 09:45:46.104714 12230 net.cpp:513] ctx_output1/relu -> ctx_output1 (in-place)
I0212 09:45:46.104728 12230 net.cpp:245] Setting up ctx_output1/relu
I0212 09:45:46.104742 12230 net.cpp:252] TEST Top shape for layer 47 'ctx_output1/relu' 4 256 46 90 (4239360)
I0212 09:45:46.104750 12230 layer_factory.hpp:136] Creating layer 'ctx_output1_ctx_output1/relu_0_split' of type 'Split'
I0212 09:45:46.104759 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.104773 12230 net.cpp:184] Created Layer ctx_output1_ctx_output1/relu_0_split (48)
I0212 09:45:46.104780 12230 net.cpp:561] ctx_output1_ctx_output1/relu_0_split <- ctx_output1
I0212 09:45:46.104790 12230 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_0
I0212 09:45:46.104805 12230 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_1
I0212 09:45:46.104817 12230 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_2
I0212 09:45:46.104974 12230 net.cpp:245] Setting up ctx_output1_ctx_output1/relu_0_split
I0212 09:45:46.105006 12230 net.cpp:252] TEST Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 4 256 46 90 (4239360)
I0212 09:45:46.105020 12230 net.cpp:252] TEST Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 4 256 46 90 (4239360)
I0212 09:45:46.105029 12230 net.cpp:252] TEST Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 4 256 46 90 (4239360)
I0212 09:45:46.105041 12230 layer_factory.hpp:136] Creating layer 'ctx_output2' of type 'Convolution'
I0212 09:45:46.105051 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.105077 12230 net.cpp:184] Created Layer ctx_output2 (49)
I0212 09:45:46.105090 12230 net.cpp:561] ctx_output2 <- res5a_branch2b_res5a_branch2b/relu_0_split_1
I0212 09:45:46.105101 12230 net.cpp:530] ctx_output2 -> ctx_output2
I0212 09:45:46.110949 12230 net.cpp:245] Setting up ctx_output2
I0212 09:45:46.110975 12230 net.cpp:252] TEST Top shape for layer 49 'ctx_output2' 4 256 12 23 (282624)
I0212 09:45:46.110987 12230 layer_factory.hpp:136] Creating layer 'ctx_output2/relu' of type 'ReLU'
I0212 09:45:46.110998 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.111013 12230 net.cpp:184] Created Layer ctx_output2/relu (50)
I0212 09:45:46.111027 12230 net.cpp:561] ctx_output2/relu <- ctx_output2
I0212 09:45:46.111037 12230 net.cpp:513] ctx_output2/relu -> ctx_output2 (in-place)
I0212 09:45:46.111054 12230 net.cpp:245] Setting up ctx_output2/relu
I0212 09:45:46.111068 12230 net.cpp:252] TEST Top shape for layer 50 'ctx_output2/relu' 4 256 12 23 (282624)
I0212 09:45:46.111083 12230 layer_factory.hpp:136] Creating layer 'ctx_output2_ctx_output2/relu_0_split' of type 'Split'
I0212 09:45:46.111090 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.111104 12230 net.cpp:184] Created Layer ctx_output2_ctx_output2/relu_0_split (51)
I0212 09:45:46.111115 12230 net.cpp:561] ctx_output2_ctx_output2/relu_0_split <- ctx_output2
I0212 09:45:46.111124 12230 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_0
I0212 09:45:46.111135 12230 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_1
I0212 09:45:46.111150 12230 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_2
I0212 09:45:46.111312 12230 net.cpp:245] Setting up ctx_output2_ctx_output2/relu_0_split
I0212 09:45:46.111333 12230 net.cpp:252] TEST Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 4 256 12 23 (282624)
I0212 09:45:46.111346 12230 net.cpp:252] TEST Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 4 256 12 23 (282624)
I0212 09:45:46.111357 12230 net.cpp:252] TEST Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 4 256 12 23 (282624)
I0212 09:45:46.111367 12230 layer_factory.hpp:136] Creating layer 'ctx_output3' of type 'Convolution'
I0212 09:45:46.111377 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.111403 12230 net.cpp:184] Created Layer ctx_output3 (52)
I0212 09:45:46.111415 12230 net.cpp:561] ctx_output3 <- pool6_pool6_0_split_1
I0212 09:45:46.111426 12230 net.cpp:530] ctx_output3 -> ctx_output3
I0212 09:45:46.118438 12230 net.cpp:245] Setting up ctx_output3
I0212 09:45:46.118459 12230 net.cpp:252] TEST Top shape for layer 52 'ctx_output3' 4 256 6 12 (73728)
I0212 09:45:46.118472 12230 layer_factory.hpp:136] Creating layer 'ctx_output3/relu' of type 'ReLU'
I0212 09:45:46.118487 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.118500 12230 net.cpp:184] Created Layer ctx_output3/relu (53)
I0212 09:45:46.118510 12230 net.cpp:561] ctx_output3/relu <- ctx_output3
I0212 09:45:46.118520 12230 net.cpp:513] ctx_output3/relu -> ctx_output3 (in-place)
I0212 09:45:46.118538 12230 net.cpp:245] Setting up ctx_output3/relu
I0212 09:45:46.118569 12230 net.cpp:252] TEST Top shape for layer 53 'ctx_output3/relu' 4 256 6 12 (73728)
I0212 09:45:46.118583 12230 layer_factory.hpp:136] Creating layer 'ctx_output3_ctx_output3/relu_0_split' of type 'Split'
I0212 09:45:46.118592 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.118603 12230 net.cpp:184] Created Layer ctx_output3_ctx_output3/relu_0_split (54)
I0212 09:45:46.118616 12230 net.cpp:561] ctx_output3_ctx_output3/relu_0_split <- ctx_output3
I0212 09:45:46.118626 12230 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_0
I0212 09:45:46.118639 12230 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_1
I0212 09:45:46.118654 12230 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_2
I0212 09:45:46.118822 12230 net.cpp:245] Setting up ctx_output3_ctx_output3/relu_0_split
I0212 09:45:46.118840 12230 net.cpp:252] TEST Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 4 256 6 12 (73728)
I0212 09:45:46.118854 12230 net.cpp:252] TEST Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 4 256 6 12 (73728)
I0212 09:45:46.118863 12230 net.cpp:252] TEST Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 4 256 6 12 (73728)
I0212 09:45:46.118875 12230 layer_factory.hpp:136] Creating layer 'ctx_output4' of type 'Convolution'
I0212 09:45:46.118885 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.118912 12230 net.cpp:184] Created Layer ctx_output4 (55)
I0212 09:45:46.118924 12230 net.cpp:561] ctx_output4 <- pool7_pool7_0_split_1
I0212 09:45:46.118935 12230 net.cpp:530] ctx_output4 -> ctx_output4
I0212 09:45:46.124547 12230 net.cpp:245] Setting up ctx_output4
I0212 09:45:46.124567 12230 net.cpp:252] TEST Top shape for layer 55 'ctx_output4' 4 256 3 6 (18432)
I0212 09:45:46.124579 12230 layer_factory.hpp:136] Creating layer 'ctx_output4/relu' of type 'ReLU'
I0212 09:45:46.124588 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.124603 12230 net.cpp:184] Created Layer ctx_output4/relu (56)
I0212 09:45:46.124614 12230 net.cpp:561] ctx_output4/relu <- ctx_output4
I0212 09:45:46.124624 12230 net.cpp:513] ctx_output4/relu -> ctx_output4 (in-place)
I0212 09:45:46.124640 12230 net.cpp:245] Setting up ctx_output4/relu
I0212 09:45:46.124652 12230 net.cpp:252] TEST Top shape for layer 56 'ctx_output4/relu' 4 256 3 6 (18432)
I0212 09:45:46.124665 12230 layer_factory.hpp:136] Creating layer 'ctx_output4_ctx_output4/relu_0_split' of type 'Split'
I0212 09:45:46.124675 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.124686 12230 net.cpp:184] Created Layer ctx_output4_ctx_output4/relu_0_split (57)
I0212 09:45:46.124697 12230 net.cpp:561] ctx_output4_ctx_output4/relu_0_split <- ctx_output4
I0212 09:45:46.124711 12230 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_0
I0212 09:45:46.124724 12230 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_1
I0212 09:45:46.124737 12230 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_2
I0212 09:45:46.124897 12230 net.cpp:245] Setting up ctx_output4_ctx_output4/relu_0_split
I0212 09:45:46.124913 12230 net.cpp:252] TEST Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 4 256 3 6 (18432)
I0212 09:45:46.124927 12230 net.cpp:252] TEST Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 4 256 3 6 (18432)
I0212 09:45:46.124936 12230 net.cpp:252] TEST Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 4 256 3 6 (18432)
I0212 09:45:46.124948 12230 layer_factory.hpp:136] Creating layer 'ctx_output5' of type 'Convolution'
I0212 09:45:46.124958 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.124985 12230 net.cpp:184] Created Layer ctx_output5 (58)
I0212 09:45:46.125013 12230 net.cpp:561] ctx_output5 <- pool8_pool8_0_split_1
I0212 09:45:46.125025 12230 net.cpp:530] ctx_output5 -> ctx_output5
I0212 09:45:46.130704 12230 net.cpp:245] Setting up ctx_output5
I0212 09:45:46.130723 12230 net.cpp:252] TEST Top shape for layer 58 'ctx_output5' 4 256 2 3 (6144)
I0212 09:45:46.130738 12230 layer_factory.hpp:136] Creating layer 'ctx_output5/relu' of type 'ReLU'
I0212 09:45:46.130753 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.130769 12230 net.cpp:184] Created Layer ctx_output5/relu (59)
I0212 09:45:46.130782 12230 net.cpp:561] ctx_output5/relu <- ctx_output5
I0212 09:45:46.130792 12230 net.cpp:513] ctx_output5/relu -> ctx_output5 (in-place)
I0212 09:45:46.130805 12230 net.cpp:245] Setting up ctx_output5/relu
I0212 09:45:46.130820 12230 net.cpp:252] TEST Top shape for layer 59 'ctx_output5/relu' 4 256 2 3 (6144)
I0212 09:45:46.130833 12230 layer_factory.hpp:136] Creating layer 'ctx_output5_ctx_output5/relu_0_split' of type 'Split'
I0212 09:45:46.130842 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.130853 12230 net.cpp:184] Created Layer ctx_output5_ctx_output5/relu_0_split (60)
I0212 09:45:46.130864 12230 net.cpp:561] ctx_output5_ctx_output5/relu_0_split <- ctx_output5
I0212 09:45:46.130874 12230 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_0
I0212 09:45:46.130887 12230 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_1
I0212 09:45:46.130904 12230 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_2
I0212 09:45:46.131063 12230 net.cpp:245] Setting up ctx_output5_ctx_output5/relu_0_split
I0212 09:45:46.131081 12230 net.cpp:252] TEST Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 4 256 2 3 (6144)
I0212 09:45:46.131094 12230 net.cpp:252] TEST Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 4 256 2 3 (6144)
I0212 09:45:46.131105 12230 net.cpp:252] TEST Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 4 256 2 3 (6144)
I0212 09:45:46.131117 12230 layer_factory.hpp:136] Creating layer 'ctx_output6' of type 'Convolution'
I0212 09:45:46.131126 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.131153 12230 net.cpp:184] Created Layer ctx_output6 (61)
I0212 09:45:46.131165 12230 net.cpp:561] ctx_output6 <- pool9
I0212 09:45:46.131176 12230 net.cpp:530] ctx_output6 -> ctx_output6
I0212 09:45:46.136811 12230 net.cpp:245] Setting up ctx_output6
I0212 09:45:46.136831 12230 net.cpp:252] TEST Top shape for layer 61 'ctx_output6' 4 256 1 2 (2048)
I0212 09:45:46.136843 12230 layer_factory.hpp:136] Creating layer 'ctx_output6/relu' of type 'ReLU'
I0212 09:45:46.136852 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.136864 12230 net.cpp:184] Created Layer ctx_output6/relu (62)
I0212 09:45:46.136874 12230 net.cpp:561] ctx_output6/relu <- ctx_output6
I0212 09:45:46.136884 12230 net.cpp:513] ctx_output6/relu -> ctx_output6 (in-place)
I0212 09:45:46.136901 12230 net.cpp:245] Setting up ctx_output6/relu
I0212 09:45:46.136915 12230 net.cpp:252] TEST Top shape for layer 62 'ctx_output6/relu' 4 256 1 2 (2048)
I0212 09:45:46.136925 12230 layer_factory.hpp:136] Creating layer 'ctx_output6_ctx_output6/relu_0_split' of type 'Split'
I0212 09:45:46.136937 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.136950 12230 net.cpp:184] Created Layer ctx_output6_ctx_output6/relu_0_split (63)
I0212 09:45:46.136961 12230 net.cpp:561] ctx_output6_ctx_output6/relu_0_split <- ctx_output6
I0212 09:45:46.136971 12230 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_0
I0212 09:45:46.136984 12230 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_1
I0212 09:45:46.137017 12230 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_2
I0212 09:45:46.137182 12230 net.cpp:245] Setting up ctx_output6_ctx_output6/relu_0_split
I0212 09:45:46.137202 12230 net.cpp:252] TEST Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 4 256 1 2 (2048)
I0212 09:45:46.137217 12230 net.cpp:252] TEST Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 4 256 1 2 (2048)
I0212 09:45:46.137226 12230 net.cpp:252] TEST Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 4 256 1 2 (2048)
I0212 09:45:46.137238 12230 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc' of type 'Convolution'
I0212 09:45:46.137248 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.137279 12230 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc (64)
I0212 09:45:46.137292 12230 net.cpp:561] ctx_output1/relu_mbox_loc <- ctx_output1_ctx_output1/relu_0_split_0
I0212 09:45:46.137303 12230 net.cpp:530] ctx_output1/relu_mbox_loc -> ctx_output1/relu_mbox_loc
I0212 09:45:46.138361 12230 net.cpp:245] Setting up ctx_output1/relu_mbox_loc
I0212 09:45:46.138387 12230 net.cpp:252] TEST Top shape for layer 64 'ctx_output1/relu_mbox_loc' 4 16 46 90 (264960)
I0212 09:45:46.138403 12230 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_perm' of type 'Permute'
I0212 09:45:46.138413 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.138433 12230 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_perm (65)
I0212 09:45:46.138447 12230 net.cpp:561] ctx_output1/relu_mbox_loc_perm <- ctx_output1/relu_mbox_loc
I0212 09:45:46.138456 12230 net.cpp:530] ctx_output1/relu_mbox_loc_perm -> ctx_output1/relu_mbox_loc_perm
I0212 09:45:46.138780 12230 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_perm
I0212 09:45:46.138800 12230 net.cpp:252] TEST Top shape for layer 65 'ctx_output1/relu_mbox_loc_perm' 4 46 90 16 (264960)
I0212 09:45:46.138810 12230 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_flat' of type 'Flatten'
I0212 09:45:46.138819 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.138834 12230 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_flat (66)
I0212 09:45:46.138844 12230 net.cpp:561] ctx_output1/relu_mbox_loc_flat <- ctx_output1/relu_mbox_loc_perm
I0212 09:45:46.138854 12230 net.cpp:530] ctx_output1/relu_mbox_loc_flat -> ctx_output1/relu_mbox_loc_flat
I0212 09:45:46.138924 12230 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_flat
I0212 09:45:46.138942 12230 net.cpp:252] TEST Top shape for layer 66 'ctx_output1/relu_mbox_loc_flat' 4 66240 (264960)
I0212 09:45:46.138952 12230 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf' of type 'Convolution'
I0212 09:45:46.138960 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.138986 12230 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf (67)
I0212 09:45:46.138998 12230 net.cpp:561] ctx_output1/relu_mbox_conf <- ctx_output1_ctx_output1/relu_0_split_1
I0212 09:45:46.139008 12230 net.cpp:530] ctx_output1/relu_mbox_conf -> ctx_output1/relu_mbox_conf
I0212 09:45:46.140058 12230 net.cpp:245] Setting up ctx_output1/relu_mbox_conf
I0212 09:45:46.140084 12230 net.cpp:252] TEST Top shape for layer 67 'ctx_output1/relu_mbox_conf' 4 16 46 90 (264960)
I0212 09:45:46.140100 12230 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_perm' of type 'Permute'
I0212 09:45:46.140110 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.140127 12230 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_perm (68)
I0212 09:45:46.140139 12230 net.cpp:561] ctx_output1/relu_mbox_conf_perm <- ctx_output1/relu_mbox_conf
I0212 09:45:46.140151 12230 net.cpp:530] ctx_output1/relu_mbox_conf_perm -> ctx_output1/relu_mbox_conf_perm
I0212 09:45:46.140478 12230 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_perm
I0212 09:45:46.140516 12230 net.cpp:252] TEST Top shape for layer 68 'ctx_output1/relu_mbox_conf_perm' 4 46 90 16 (264960)
I0212 09:45:46.140527 12230 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_flat' of type 'Flatten'
I0212 09:45:46.140535 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.140548 12230 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_flat (69)
I0212 09:45:46.140558 12230 net.cpp:561] ctx_output1/relu_mbox_conf_flat <- ctx_output1/relu_mbox_conf_perm
I0212 09:45:46.140568 12230 net.cpp:530] ctx_output1/relu_mbox_conf_flat -> ctx_output1/relu_mbox_conf_flat
I0212 09:45:46.140636 12230 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_flat
I0212 09:45:46.140653 12230 net.cpp:252] TEST Top shape for layer 69 'ctx_output1/relu_mbox_conf_flat' 4 66240 (264960)
I0212 09:45:46.140663 12230 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_priorbox' of type 'PriorBox'
I0212 09:45:46.140672 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.140686 12230 net.cpp:184] Created Layer ctx_output1/relu_mbox_priorbox (70)
I0212 09:45:46.140694 12230 net.cpp:561] ctx_output1/relu_mbox_priorbox <- ctx_output1_ctx_output1/relu_0_split_2
I0212 09:45:46.140705 12230 net.cpp:561] ctx_output1/relu_mbox_priorbox <- data_data_0_split_1
I0212 09:45:46.140717 12230 net.cpp:530] ctx_output1/relu_mbox_priorbox -> ctx_output1/relu_mbox_priorbox
I0212 09:45:46.140791 12230 net.cpp:245] Setting up ctx_output1/relu_mbox_priorbox
I0212 09:45:46.140808 12230 net.cpp:252] TEST Top shape for layer 70 'ctx_output1/relu_mbox_priorbox' 1 2 66240 (132480)
I0212 09:45:46.140817 12230 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc' of type 'Convolution'
I0212 09:45:46.140826 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.140857 12230 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc (71)
I0212 09:45:46.140869 12230 net.cpp:561] ctx_output2/relu_mbox_loc <- ctx_output2_ctx_output2/relu_0_split_0
I0212 09:45:46.140880 12230 net.cpp:530] ctx_output2/relu_mbox_loc -> ctx_output2/relu_mbox_loc
I0212 09:45:46.141875 12230 net.cpp:245] Setting up ctx_output2/relu_mbox_loc
I0212 09:45:46.141894 12230 net.cpp:252] TEST Top shape for layer 71 'ctx_output2/relu_mbox_loc' 4 24 12 23 (26496)
I0212 09:45:46.141906 12230 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_perm' of type 'Permute'
I0212 09:45:46.141911 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.141927 12230 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_perm (72)
I0212 09:45:46.141937 12230 net.cpp:561] ctx_output2/relu_mbox_loc_perm <- ctx_output2/relu_mbox_loc
I0212 09:45:46.141947 12230 net.cpp:530] ctx_output2/relu_mbox_loc_perm -> ctx_output2/relu_mbox_loc_perm
I0212 09:45:46.142277 12230 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_perm
I0212 09:45:46.142294 12230 net.cpp:252] TEST Top shape for layer 72 'ctx_output2/relu_mbox_loc_perm' 4 12 23 24 (26496)
I0212 09:45:46.142302 12230 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_flat' of type 'Flatten'
I0212 09:45:46.142307 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.142316 12230 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_flat (73)
I0212 09:45:46.142326 12230 net.cpp:561] ctx_output2/relu_mbox_loc_flat <- ctx_output2/relu_mbox_loc_perm
I0212 09:45:46.142336 12230 net.cpp:530] ctx_output2/relu_mbox_loc_flat -> ctx_output2/relu_mbox_loc_flat
I0212 09:45:46.142405 12230 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_flat
I0212 09:45:46.142422 12230 net.cpp:252] TEST Top shape for layer 73 'ctx_output2/relu_mbox_loc_flat' 4 6624 (26496)
I0212 09:45:46.142431 12230 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf' of type 'Convolution'
I0212 09:45:46.142441 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.142488 12230 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf (74)
I0212 09:45:46.142501 12230 net.cpp:561] ctx_output2/relu_mbox_conf <- ctx_output2_ctx_output2/relu_0_split_1
I0212 09:45:46.142513 12230 net.cpp:530] ctx_output2/relu_mbox_conf -> ctx_output2/relu_mbox_conf
I0212 09:45:46.143625 12230 net.cpp:245] Setting up ctx_output2/relu_mbox_conf
I0212 09:45:46.143651 12230 net.cpp:252] TEST Top shape for layer 74 'ctx_output2/relu_mbox_conf' 4 24 12 23 (26496)
I0212 09:45:46.143666 12230 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_perm' of type 'Permute'
I0212 09:45:46.143678 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.143698 12230 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_perm (75)
I0212 09:45:46.143710 12230 net.cpp:561] ctx_output2/relu_mbox_conf_perm <- ctx_output2/relu_mbox_conf
I0212 09:45:46.143721 12230 net.cpp:530] ctx_output2/relu_mbox_conf_perm -> ctx_output2/relu_mbox_conf_perm
I0212 09:45:46.144035 12230 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_perm
I0212 09:45:46.144055 12230 net.cpp:252] TEST Top shape for layer 75 'ctx_output2/relu_mbox_conf_perm' 4 12 23 24 (26496)
I0212 09:45:46.144064 12230 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_flat' of type 'Flatten'
I0212 09:45:46.144073 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.144085 12230 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_flat (76)
I0212 09:45:46.144095 12230 net.cpp:561] ctx_output2/relu_mbox_conf_flat <- ctx_output2/relu_mbox_conf_perm
I0212 09:45:46.144105 12230 net.cpp:530] ctx_output2/relu_mbox_conf_flat -> ctx_output2/relu_mbox_conf_flat
I0212 09:45:46.144170 12230 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_flat
I0212 09:45:46.144187 12230 net.cpp:252] TEST Top shape for layer 76 'ctx_output2/relu_mbox_conf_flat' 4 6624 (26496)
I0212 09:45:46.144197 12230 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_priorbox' of type 'PriorBox'
I0212 09:45:46.144207 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.144220 12230 net.cpp:184] Created Layer ctx_output2/relu_mbox_priorbox (77)
I0212 09:45:46.144232 12230 net.cpp:561] ctx_output2/relu_mbox_priorbox <- ctx_output2_ctx_output2/relu_0_split_2
I0212 09:45:46.144243 12230 net.cpp:561] ctx_output2/relu_mbox_priorbox <- data_data_0_split_2
I0212 09:45:46.144253 12230 net.cpp:530] ctx_output2/relu_mbox_priorbox -> ctx_output2/relu_mbox_priorbox
I0212 09:45:46.144327 12230 net.cpp:245] Setting up ctx_output2/relu_mbox_priorbox
I0212 09:45:46.144346 12230 net.cpp:252] TEST Top shape for layer 77 'ctx_output2/relu_mbox_priorbox' 1 2 6624 (13248)
I0212 09:45:46.144359 12230 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc' of type 'Convolution'
I0212 09:45:46.144369 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.144398 12230 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc (78)
I0212 09:45:46.144410 12230 net.cpp:561] ctx_output3/relu_mbox_loc <- ctx_output3_ctx_output3/relu_0_split_0
I0212 09:45:46.144421 12230 net.cpp:530] ctx_output3/relu_mbox_loc -> ctx_output3/relu_mbox_loc
I0212 09:45:46.145548 12230 net.cpp:245] Setting up ctx_output3/relu_mbox_loc
I0212 09:45:46.145573 12230 net.cpp:252] TEST Top shape for layer 78 'ctx_output3/relu_mbox_loc' 4 24 6 12 (6912)
I0212 09:45:46.145588 12230 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_perm' of type 'Permute'
I0212 09:45:46.145598 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.145615 12230 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_perm (79)
I0212 09:45:46.145625 12230 net.cpp:561] ctx_output3/relu_mbox_loc_perm <- ctx_output3/relu_mbox_loc
I0212 09:45:46.145635 12230 net.cpp:530] ctx_output3/relu_mbox_loc_perm -> ctx_output3/relu_mbox_loc_perm
I0212 09:45:46.145965 12230 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_perm
I0212 09:45:46.145984 12230 net.cpp:252] TEST Top shape for layer 79 'ctx_output3/relu_mbox_loc_perm' 4 6 12 24 (6912)
I0212 09:45:46.145994 12230 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_flat' of type 'Flatten'
I0212 09:45:46.146003 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.146015 12230 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_flat (80)
I0212 09:45:46.146024 12230 net.cpp:561] ctx_output3/relu_mbox_loc_flat <- ctx_output3/relu_mbox_loc_perm
I0212 09:45:46.146034 12230 net.cpp:530] ctx_output3/relu_mbox_loc_flat -> ctx_output3/relu_mbox_loc_flat
I0212 09:45:46.146118 12230 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_flat
I0212 09:45:46.146137 12230 net.cpp:252] TEST Top shape for layer 80 'ctx_output3/relu_mbox_loc_flat' 4 1728 (6912)
I0212 09:45:46.146147 12230 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf' of type 'Convolution'
I0212 09:45:46.146157 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.146185 12230 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf (81)
I0212 09:45:46.146198 12230 net.cpp:561] ctx_output3/relu_mbox_conf <- ctx_output3_ctx_output3/relu_0_split_1
I0212 09:45:46.146209 12230 net.cpp:530] ctx_output3/relu_mbox_conf -> ctx_output3/relu_mbox_conf
I0212 09:45:46.147336 12230 net.cpp:245] Setting up ctx_output3/relu_mbox_conf
I0212 09:45:46.147359 12230 net.cpp:252] TEST Top shape for layer 81 'ctx_output3/relu_mbox_conf' 4 24 6 12 (6912)
I0212 09:45:46.147375 12230 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_perm' of type 'Permute'
I0212 09:45:46.147384 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.147403 12230 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_perm (82)
I0212 09:45:46.147414 12230 net.cpp:561] ctx_output3/relu_mbox_conf_perm <- ctx_output3/relu_mbox_conf
I0212 09:45:46.147425 12230 net.cpp:530] ctx_output3/relu_mbox_conf_perm -> ctx_output3/relu_mbox_conf_perm
I0212 09:45:46.147745 12230 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_perm
I0212 09:45:46.147768 12230 net.cpp:252] TEST Top shape for layer 82 'ctx_output3/relu_mbox_conf_perm' 4 6 12 24 (6912)
I0212 09:45:46.147778 12230 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_flat' of type 'Flatten'
I0212 09:45:46.147786 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.147799 12230 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_flat (83)
I0212 09:45:46.147807 12230 net.cpp:561] ctx_output3/relu_mbox_conf_flat <- ctx_output3/relu_mbox_conf_perm
I0212 09:45:46.147821 12230 net.cpp:530] ctx_output3/relu_mbox_conf_flat -> ctx_output3/relu_mbox_conf_flat
I0212 09:45:46.147887 12230 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_flat
I0212 09:45:46.147904 12230 net.cpp:252] TEST Top shape for layer 83 'ctx_output3/relu_mbox_conf_flat' 4 1728 (6912)
I0212 09:45:46.147913 12230 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_priorbox' of type 'PriorBox'
I0212 09:45:46.147922 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.147938 12230 net.cpp:184] Created Layer ctx_output3/relu_mbox_priorbox (84)
I0212 09:45:46.147948 12230 net.cpp:561] ctx_output3/relu_mbox_priorbox <- ctx_output3_ctx_output3/relu_0_split_2
I0212 09:45:46.147958 12230 net.cpp:561] ctx_output3/relu_mbox_priorbox <- data_data_0_split_3
I0212 09:45:46.147969 12230 net.cpp:530] ctx_output3/relu_mbox_priorbox -> ctx_output3/relu_mbox_priorbox
I0212 09:45:46.148039 12230 net.cpp:245] Setting up ctx_output3/relu_mbox_priorbox
I0212 09:45:46.148056 12230 net.cpp:252] TEST Top shape for layer 84 'ctx_output3/relu_mbox_priorbox' 1 2 1728 (3456)
I0212 09:45:46.148066 12230 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc' of type 'Convolution'
I0212 09:45:46.148092 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.148118 12230 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc (85)
I0212 09:45:46.148131 12230 net.cpp:561] ctx_output4/relu_mbox_loc <- ctx_output4_ctx_output4/relu_0_split_0
I0212 09:45:46.148144 12230 net.cpp:530] ctx_output4/relu_mbox_loc -> ctx_output4/relu_mbox_loc
I0212 09:45:46.149260 12230 net.cpp:245] Setting up ctx_output4/relu_mbox_loc
I0212 09:45:46.149283 12230 net.cpp:252] TEST Top shape for layer 85 'ctx_output4/relu_mbox_loc' 4 24 3 6 (1728)
I0212 09:45:46.149298 12230 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_perm' of type 'Permute'
I0212 09:45:46.149312 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.149328 12230 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_perm (86)
I0212 09:45:46.149338 12230 net.cpp:561] ctx_output4/relu_mbox_loc_perm <- ctx_output4/relu_mbox_loc
I0212 09:45:46.149349 12230 net.cpp:530] ctx_output4/relu_mbox_loc_perm -> ctx_output4/relu_mbox_loc_perm
I0212 09:45:46.149662 12230 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_perm
I0212 09:45:46.149682 12230 net.cpp:252] TEST Top shape for layer 86 'ctx_output4/relu_mbox_loc_perm' 4 3 6 24 (1728)
I0212 09:45:46.149691 12230 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_flat' of type 'Flatten'
I0212 09:45:46.149700 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.149713 12230 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_flat (87)
I0212 09:45:46.149721 12230 net.cpp:561] ctx_output4/relu_mbox_loc_flat <- ctx_output4/relu_mbox_loc_perm
I0212 09:45:46.149732 12230 net.cpp:530] ctx_output4/relu_mbox_loc_flat -> ctx_output4/relu_mbox_loc_flat
I0212 09:45:46.149801 12230 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_flat
I0212 09:45:46.149817 12230 net.cpp:252] TEST Top shape for layer 87 'ctx_output4/relu_mbox_loc_flat' 4 432 (1728)
I0212 09:45:46.149827 12230 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf' of type 'Convolution'
I0212 09:45:46.149835 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.149859 12230 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf (88)
I0212 09:45:46.149871 12230 net.cpp:561] ctx_output4/relu_mbox_conf <- ctx_output4_ctx_output4/relu_0_split_1
I0212 09:45:46.149883 12230 net.cpp:530] ctx_output4/relu_mbox_conf -> ctx_output4/relu_mbox_conf
I0212 09:45:46.151021 12230 net.cpp:245] Setting up ctx_output4/relu_mbox_conf
I0212 09:45:46.151049 12230 net.cpp:252] TEST Top shape for layer 88 'ctx_output4/relu_mbox_conf' 4 24 3 6 (1728)
I0212 09:45:46.151065 12230 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_perm' of type 'Permute'
I0212 09:45:46.151077 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.151094 12230 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_perm (89)
I0212 09:45:46.151108 12230 net.cpp:561] ctx_output4/relu_mbox_conf_perm <- ctx_output4/relu_mbox_conf
I0212 09:45:46.151118 12230 net.cpp:530] ctx_output4/relu_mbox_conf_perm -> ctx_output4/relu_mbox_conf_perm
I0212 09:45:46.151445 12230 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_perm
I0212 09:45:46.151466 12230 net.cpp:252] TEST Top shape for layer 89 'ctx_output4/relu_mbox_conf_perm' 4 3 6 24 (1728)
I0212 09:45:46.151476 12230 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_flat' of type 'Flatten'
I0212 09:45:46.151485 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.151497 12230 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_flat (90)
I0212 09:45:46.151506 12230 net.cpp:561] ctx_output4/relu_mbox_conf_flat <- ctx_output4/relu_mbox_conf_perm
I0212 09:45:46.151517 12230 net.cpp:530] ctx_output4/relu_mbox_conf_flat -> ctx_output4/relu_mbox_conf_flat
I0212 09:45:46.151603 12230 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_flat
I0212 09:45:46.151623 12230 net.cpp:252] TEST Top shape for layer 90 'ctx_output4/relu_mbox_conf_flat' 4 432 (1728)
I0212 09:45:46.151631 12230 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_priorbox' of type 'PriorBox'
I0212 09:45:46.151640 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.151655 12230 net.cpp:184] Created Layer ctx_output4/relu_mbox_priorbox (91)
I0212 09:45:46.151665 12230 net.cpp:561] ctx_output4/relu_mbox_priorbox <- ctx_output4_ctx_output4/relu_0_split_2
I0212 09:45:46.151676 12230 net.cpp:561] ctx_output4/relu_mbox_priorbox <- data_data_0_split_4
I0212 09:45:46.151686 12230 net.cpp:530] ctx_output4/relu_mbox_priorbox -> ctx_output4/relu_mbox_priorbox
I0212 09:45:46.151756 12230 net.cpp:245] Setting up ctx_output4/relu_mbox_priorbox
I0212 09:45:46.151772 12230 net.cpp:252] TEST Top shape for layer 91 'ctx_output4/relu_mbox_priorbox' 1 2 432 (864)
I0212 09:45:46.151782 12230 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc' of type 'Convolution'
I0212 09:45:46.151792 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.151820 12230 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc (92)
I0212 09:45:46.151832 12230 net.cpp:561] ctx_output5/relu_mbox_loc <- ctx_output5_ctx_output5/relu_0_split_0
I0212 09:45:46.151844 12230 net.cpp:530] ctx_output5/relu_mbox_loc -> ctx_output5/relu_mbox_loc
I0212 09:45:46.152879 12230 net.cpp:245] Setting up ctx_output5/relu_mbox_loc
I0212 09:45:46.152904 12230 net.cpp:252] TEST Top shape for layer 92 'ctx_output5/relu_mbox_loc' 4 16 2 3 (384)
I0212 09:45:46.152920 12230 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_perm' of type 'Permute'
I0212 09:45:46.152928 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.152947 12230 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_perm (93)
I0212 09:45:46.152956 12230 net.cpp:561] ctx_output5/relu_mbox_loc_perm <- ctx_output5/relu_mbox_loc
I0212 09:45:46.152967 12230 net.cpp:530] ctx_output5/relu_mbox_loc_perm -> ctx_output5/relu_mbox_loc_perm
I0212 09:45:46.153287 12230 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_perm
I0212 09:45:46.153307 12230 net.cpp:252] TEST Top shape for layer 93 'ctx_output5/relu_mbox_loc_perm' 4 2 3 16 (384)
I0212 09:45:46.153316 12230 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_flat' of type 'Flatten'
I0212 09:45:46.153326 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.153337 12230 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_flat (94)
I0212 09:45:46.153344 12230 net.cpp:561] ctx_output5/relu_mbox_loc_flat <- ctx_output5/relu_mbox_loc_perm
I0212 09:45:46.153362 12230 net.cpp:530] ctx_output5/relu_mbox_loc_flat -> ctx_output5/relu_mbox_loc_flat
I0212 09:45:46.153432 12230 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_flat
I0212 09:45:46.153451 12230 net.cpp:252] TEST Top shape for layer 94 'ctx_output5/relu_mbox_loc_flat' 4 96 (384)
I0212 09:45:46.153460 12230 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf' of type 'Convolution'
I0212 09:45:46.153470 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.153496 12230 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf (95)
I0212 09:45:46.153508 12230 net.cpp:561] ctx_output5/relu_mbox_conf <- ctx_output5_ctx_output5/relu_0_split_1
I0212 09:45:46.153519 12230 net.cpp:530] ctx_output5/relu_mbox_conf -> ctx_output5/relu_mbox_conf
I0212 09:45:46.154367 12230 net.cpp:245] Setting up ctx_output5/relu_mbox_conf
I0212 09:45:46.154386 12230 net.cpp:252] TEST Top shape for layer 95 'ctx_output5/relu_mbox_conf' 4 16 2 3 (384)
I0212 09:45:46.154397 12230 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_perm' of type 'Permute'
I0212 09:45:46.154419 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.154433 12230 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_perm (96)
I0212 09:45:46.154440 12230 net.cpp:561] ctx_output5/relu_mbox_conf_perm <- ctx_output5/relu_mbox_conf
I0212 09:45:46.154448 12230 net.cpp:530] ctx_output5/relu_mbox_conf_perm -> ctx_output5/relu_mbox_conf_perm
I0212 09:45:46.154767 12230 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_perm
I0212 09:45:46.154788 12230 net.cpp:252] TEST Top shape for layer 96 'ctx_output5/relu_mbox_conf_perm' 4 2 3 16 (384)
I0212 09:45:46.154796 12230 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_flat' of type 'Flatten'
I0212 09:45:46.154805 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.154819 12230 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_flat (97)
I0212 09:45:46.154829 12230 net.cpp:561] ctx_output5/relu_mbox_conf_flat <- ctx_output5/relu_mbox_conf_perm
I0212 09:45:46.154839 12230 net.cpp:530] ctx_output5/relu_mbox_conf_flat -> ctx_output5/relu_mbox_conf_flat
I0212 09:45:46.154949 12230 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_flat
I0212 09:45:46.154968 12230 net.cpp:252] TEST Top shape for layer 97 'ctx_output5/relu_mbox_conf_flat' 4 96 (384)
I0212 09:45:46.154978 12230 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_priorbox' of type 'PriorBox'
I0212 09:45:46.154988 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.155000 12230 net.cpp:184] Created Layer ctx_output5/relu_mbox_priorbox (98)
I0212 09:45:46.155009 12230 net.cpp:561] ctx_output5/relu_mbox_priorbox <- ctx_output5_ctx_output5/relu_0_split_2
I0212 09:45:46.155019 12230 net.cpp:561] ctx_output5/relu_mbox_priorbox <- data_data_0_split_5
I0212 09:45:46.155030 12230 net.cpp:530] ctx_output5/relu_mbox_priorbox -> ctx_output5/relu_mbox_priorbox
I0212 09:45:46.155097 12230 net.cpp:245] Setting up ctx_output5/relu_mbox_priorbox
I0212 09:45:46.155113 12230 net.cpp:252] TEST Top shape for layer 98 'ctx_output5/relu_mbox_priorbox' 1 2 96 (192)
I0212 09:45:46.155122 12230 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc' of type 'Convolution'
I0212 09:45:46.155131 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.155158 12230 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc (99)
I0212 09:45:46.155174 12230 net.cpp:561] ctx_output6/relu_mbox_loc <- ctx_output6_ctx_output6/relu_0_split_0
I0212 09:45:46.155184 12230 net.cpp:530] ctx_output6/relu_mbox_loc -> ctx_output6/relu_mbox_loc
I0212 09:45:46.156203 12230 net.cpp:245] Setting up ctx_output6/relu_mbox_loc
I0212 09:45:46.156226 12230 net.cpp:252] TEST Top shape for layer 99 'ctx_output6/relu_mbox_loc' 4 16 1 2 (128)
I0212 09:45:46.156242 12230 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_perm' of type 'Permute'
I0212 09:45:46.156256 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.156273 12230 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_perm (100)
I0212 09:45:46.156283 12230 net.cpp:561] ctx_output6/relu_mbox_loc_perm <- ctx_output6/relu_mbox_loc
I0212 09:45:46.156293 12230 net.cpp:530] ctx_output6/relu_mbox_loc_perm -> ctx_output6/relu_mbox_loc_perm
I0212 09:45:46.156605 12230 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_perm
I0212 09:45:46.156623 12230 net.cpp:252] TEST Top shape for layer 100 'ctx_output6/relu_mbox_loc_perm' 4 1 2 16 (128)
I0212 09:45:46.156632 12230 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_flat' of type 'Flatten'
I0212 09:45:46.156641 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.156652 12230 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_flat (101)
I0212 09:45:46.156661 12230 net.cpp:561] ctx_output6/relu_mbox_loc_flat <- ctx_output6/relu_mbox_loc_perm
I0212 09:45:46.156685 12230 net.cpp:530] ctx_output6/relu_mbox_loc_flat -> ctx_output6/relu_mbox_loc_flat
I0212 09:45:46.156754 12230 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_flat
I0212 09:45:46.156771 12230 net.cpp:252] TEST Top shape for layer 101 'ctx_output6/relu_mbox_loc_flat' 4 32 (128)
I0212 09:45:46.156781 12230 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf' of type 'Convolution'
I0212 09:45:46.156792 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.156824 12230 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf (102)
I0212 09:45:46.156837 12230 net.cpp:561] ctx_output6/relu_mbox_conf <- ctx_output6_ctx_output6/relu_0_split_1
I0212 09:45:46.156848 12230 net.cpp:530] ctx_output6/relu_mbox_conf -> ctx_output6/relu_mbox_conf
I0212 09:45:46.157891 12230 net.cpp:245] Setting up ctx_output6/relu_mbox_conf
I0212 09:45:46.157914 12230 net.cpp:252] TEST Top shape for layer 102 'ctx_output6/relu_mbox_conf' 4 16 1 2 (128)
I0212 09:45:46.157930 12230 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_perm' of type 'Permute'
I0212 09:45:46.157940 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.157959 12230 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_perm (103)
I0212 09:45:46.157969 12230 net.cpp:561] ctx_output6/relu_mbox_conf_perm <- ctx_output6/relu_mbox_conf
I0212 09:45:46.157981 12230 net.cpp:530] ctx_output6/relu_mbox_conf_perm -> ctx_output6/relu_mbox_conf_perm
I0212 09:45:46.158323 12230 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_perm
I0212 09:45:46.158344 12230 net.cpp:252] TEST Top shape for layer 103 'ctx_output6/relu_mbox_conf_perm' 4 1 2 16 (128)
I0212 09:45:46.158354 12230 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_flat' of type 'Flatten'
I0212 09:45:46.158362 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.158375 12230 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_flat (104)
I0212 09:45:46.158385 12230 net.cpp:561] ctx_output6/relu_mbox_conf_flat <- ctx_output6/relu_mbox_conf_perm
I0212 09:45:46.158394 12230 net.cpp:530] ctx_output6/relu_mbox_conf_flat -> ctx_output6/relu_mbox_conf_flat
I0212 09:45:46.158462 12230 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_flat
I0212 09:45:46.158478 12230 net.cpp:252] TEST Top shape for layer 104 'ctx_output6/relu_mbox_conf_flat' 4 32 (128)
I0212 09:45:46.158488 12230 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_priorbox' of type 'PriorBox'
I0212 09:45:46.158499 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.158511 12230 net.cpp:184] Created Layer ctx_output6/relu_mbox_priorbox (105)
I0212 09:45:46.158522 12230 net.cpp:561] ctx_output6/relu_mbox_priorbox <- ctx_output6_ctx_output6/relu_0_split_2
I0212 09:45:46.158532 12230 net.cpp:561] ctx_output6/relu_mbox_priorbox <- data_data_0_split_6
I0212 09:45:46.158545 12230 net.cpp:530] ctx_output6/relu_mbox_priorbox -> ctx_output6/relu_mbox_priorbox
I0212 09:45:46.158617 12230 net.cpp:245] Setting up ctx_output6/relu_mbox_priorbox
I0212 09:45:46.158637 12230 net.cpp:252] TEST Top shape for layer 105 'ctx_output6/relu_mbox_priorbox' 1 2 32 (64)
I0212 09:45:46.158648 12230 layer_factory.hpp:136] Creating layer 'mbox_loc' of type 'Concat'
I0212 09:45:46.158656 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.158676 12230 net.cpp:184] Created Layer mbox_loc (106)
I0212 09:45:46.158689 12230 net.cpp:561] mbox_loc <- ctx_output1/relu_mbox_loc_flat
I0212 09:45:46.158699 12230 net.cpp:561] mbox_loc <- ctx_output2/relu_mbox_loc_flat
I0212 09:45:46.158711 12230 net.cpp:561] mbox_loc <- ctx_output3/relu_mbox_loc_flat
I0212 09:45:46.158721 12230 net.cpp:561] mbox_loc <- ctx_output4/relu_mbox_loc_flat
I0212 09:45:46.158731 12230 net.cpp:561] mbox_loc <- ctx_output5/relu_mbox_loc_flat
I0212 09:45:46.158740 12230 net.cpp:561] mbox_loc <- ctx_output6/relu_mbox_loc_flat
I0212 09:45:46.158766 12230 net.cpp:530] mbox_loc -> mbox_loc
I0212 09:45:46.158843 12230 net.cpp:245] Setting up mbox_loc
I0212 09:45:46.158859 12230 net.cpp:252] TEST Top shape for layer 106 'mbox_loc' 4 75152 (300608)
I0212 09:45:46.158869 12230 layer_factory.hpp:136] Creating layer 'mbox_conf' of type 'Concat'
I0212 09:45:46.158879 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.158892 12230 net.cpp:184] Created Layer mbox_conf (107)
I0212 09:45:46.158905 12230 net.cpp:561] mbox_conf <- ctx_output1/relu_mbox_conf_flat
I0212 09:45:46.158916 12230 net.cpp:561] mbox_conf <- ctx_output2/relu_mbox_conf_flat
I0212 09:45:46.158926 12230 net.cpp:561] mbox_conf <- ctx_output3/relu_mbox_conf_flat
I0212 09:45:46.158937 12230 net.cpp:561] mbox_conf <- ctx_output4/relu_mbox_conf_flat
I0212 09:45:46.158946 12230 net.cpp:561] mbox_conf <- ctx_output5/relu_mbox_conf_flat
I0212 09:45:46.158955 12230 net.cpp:561] mbox_conf <- ctx_output6/relu_mbox_conf_flat
I0212 09:45:46.158965 12230 net.cpp:530] mbox_conf -> mbox_conf
I0212 09:45:46.159034 12230 net.cpp:245] Setting up mbox_conf
I0212 09:45:46.159052 12230 net.cpp:252] TEST Top shape for layer 107 'mbox_conf' 4 75152 (300608)
I0212 09:45:46.159065 12230 layer_factory.hpp:136] Creating layer 'mbox_priorbox' of type 'Concat'
I0212 09:45:46.159073 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.159086 12230 net.cpp:184] Created Layer mbox_priorbox (108)
I0212 09:45:46.159097 12230 net.cpp:561] mbox_priorbox <- ctx_output1/relu_mbox_priorbox
I0212 09:45:46.159107 12230 net.cpp:561] mbox_priorbox <- ctx_output2/relu_mbox_priorbox
I0212 09:45:46.159117 12230 net.cpp:561] mbox_priorbox <- ctx_output3/relu_mbox_priorbox
I0212 09:45:46.159126 12230 net.cpp:561] mbox_priorbox <- ctx_output4/relu_mbox_priorbox
I0212 09:45:46.159137 12230 net.cpp:561] mbox_priorbox <- ctx_output5/relu_mbox_priorbox
I0212 09:45:46.159147 12230 net.cpp:561] mbox_priorbox <- ctx_output6/relu_mbox_priorbox
I0212 09:45:46.159154 12230 net.cpp:530] mbox_priorbox -> mbox_priorbox
I0212 09:45:46.159224 12230 net.cpp:245] Setting up mbox_priorbox
I0212 09:45:46.159240 12230 net.cpp:252] TEST Top shape for layer 108 'mbox_priorbox' 1 2 75152 (150304)
I0212 09:45:46.159248 12230 layer_factory.hpp:136] Creating layer 'mbox_conf_reshape' of type 'Reshape'
I0212 09:45:46.159260 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.159278 12230 net.cpp:184] Created Layer mbox_conf_reshape (109)
I0212 09:45:46.159289 12230 net.cpp:561] mbox_conf_reshape <- mbox_conf
I0212 09:45:46.159298 12230 net.cpp:530] mbox_conf_reshape -> mbox_conf_reshape
I0212 09:45:46.159369 12230 net.cpp:245] Setting up mbox_conf_reshape
I0212 09:45:46.159385 12230 net.cpp:252] TEST Top shape for layer 109 'mbox_conf_reshape' 4 18788 4 (300608)
I0212 09:45:46.159395 12230 layer_factory.hpp:136] Creating layer 'mbox_conf_softmax' of type 'Softmax'
I0212 09:45:46.159406 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.159430 12230 net.cpp:184] Created Layer mbox_conf_softmax (110)
I0212 09:45:46.159441 12230 net.cpp:561] mbox_conf_softmax <- mbox_conf_reshape
I0212 09:45:46.159452 12230 net.cpp:530] mbox_conf_softmax -> mbox_conf_softmax
I0212 09:45:46.159636 12230 net.cpp:245] Setting up mbox_conf_softmax
I0212 09:45:46.159653 12230 net.cpp:252] TEST Top shape for layer 110 'mbox_conf_softmax' 4 18788 4 (300608)
I0212 09:45:46.159663 12230 layer_factory.hpp:136] Creating layer 'mbox_conf_flatten' of type 'Flatten'
I0212 09:45:46.159673 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.159687 12230 net.cpp:184] Created Layer mbox_conf_flatten (111)
I0212 09:45:46.159695 12230 net.cpp:561] mbox_conf_flatten <- mbox_conf_softmax
I0212 09:45:46.159705 12230 net.cpp:530] mbox_conf_flatten -> mbox_conf_flatten
I0212 09:45:46.159790 12230 net.cpp:245] Setting up mbox_conf_flatten
I0212 09:45:46.159807 12230 net.cpp:252] TEST Top shape for layer 111 'mbox_conf_flatten' 4 75152 (300608)
I0212 09:45:46.159816 12230 layer_factory.hpp:136] Creating layer 'detection_out' of type 'DetectionOutput'
I0212 09:45:46.159827 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.159860 12230 net.cpp:184] Created Layer detection_out (112)
I0212 09:45:46.159871 12230 net.cpp:561] detection_out <- mbox_loc
I0212 09:45:46.159883 12230 net.cpp:561] detection_out <- mbox_conf_flatten
I0212 09:45:46.159891 12230 net.cpp:561] detection_out <- mbox_priorbox
I0212 09:45:46.159904 12230 net.cpp:530] detection_out -> detection_out
I0212 09:45:46.224742 12230 net.cpp:245] Setting up detection_out
I0212 09:45:46.224787 12230 net.cpp:252] TEST Top shape for layer 112 'detection_out' 1 1 1 7 (7)
I0212 09:45:46.224802 12230 layer_factory.hpp:136] Creating layer 'detection_eval' of type 'DetectionEvaluate'
I0212 09:45:46.224815 12230 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 09:45:46.224838 12230 net.cpp:184] Created Layer detection_eval (113)
I0212 09:45:46.224850 12230 net.cpp:561] detection_eval <- detection_out
I0212 09:45:46.224864 12230 net.cpp:561] detection_eval <- label
I0212 09:45:46.224875 12230 net.cpp:530] detection_eval -> detection_eval
I0212 09:45:46.227341 12230 net.cpp:245] Setting up detection_eval
I0212 09:45:46.227370 12230 net.cpp:252] TEST Top shape for layer 113 'detection_eval' 1 1 4 5 (20)
I0212 09:45:46.227383 12230 net.cpp:325] detection_eval does not need backward computation.
I0212 09:45:46.227394 12230 net.cpp:325] detection_out does not need backward computation.
I0212 09:45:46.227404 12230 net.cpp:325] mbox_conf_flatten does not need backward computation.
I0212 09:45:46.227414 12230 net.cpp:325] mbox_conf_softmax does not need backward computation.
I0212 09:45:46.227423 12230 net.cpp:325] mbox_conf_reshape does not need backward computation.
I0212 09:45:46.227433 12230 net.cpp:325] mbox_priorbox does not need backward computation.
I0212 09:45:46.227447 12230 net.cpp:325] mbox_conf does not need backward computation.
I0212 09:45:46.227459 12230 net.cpp:325] mbox_loc does not need backward computation.
I0212 09:45:46.227480 12230 net.cpp:325] ctx_output6/relu_mbox_priorbox does not need backward computation.
I0212 09:45:46.227497 12230 net.cpp:325] ctx_output6/relu_mbox_conf_flat does not need backward computation.
I0212 09:45:46.227506 12230 net.cpp:325] ctx_output6/relu_mbox_conf_perm does not need backward computation.
I0212 09:45:46.227533 12230 net.cpp:325] ctx_output6/relu_mbox_conf does not need backward computation.
I0212 09:45:46.227543 12230 net.cpp:325] ctx_output6/relu_mbox_loc_flat does not need backward computation.
I0212 09:45:46.227553 12230 net.cpp:325] ctx_output6/relu_mbox_loc_perm does not need backward computation.
I0212 09:45:46.227567 12230 net.cpp:325] ctx_output6/relu_mbox_loc does not need backward computation.
I0212 09:45:46.227577 12230 net.cpp:325] ctx_output5/relu_mbox_priorbox does not need backward computation.
I0212 09:45:46.227587 12230 net.cpp:325] ctx_output5/relu_mbox_conf_flat does not need backward computation.
I0212 09:45:46.227600 12230 net.cpp:325] ctx_output5/relu_mbox_conf_perm does not need backward computation.
I0212 09:45:46.227610 12230 net.cpp:325] ctx_output5/relu_mbox_conf does not need backward computation.
I0212 09:45:46.227620 12230 net.cpp:325] ctx_output5/relu_mbox_loc_flat does not need backward computation.
I0212 09:45:46.227634 12230 net.cpp:325] ctx_output5/relu_mbox_loc_perm does not need backward computation.
I0212 09:45:46.227644 12230 net.cpp:325] ctx_output5/relu_mbox_loc does not need backward computation.
I0212 09:45:46.227653 12230 net.cpp:325] ctx_output4/relu_mbox_priorbox does not need backward computation.
I0212 09:45:46.227663 12230 net.cpp:325] ctx_output4/relu_mbox_conf_flat does not need backward computation.
I0212 09:45:46.227674 12230 net.cpp:325] ctx_output4/relu_mbox_conf_perm does not need backward computation.
I0212 09:45:46.227710 12230 net.cpp:325] ctx_output4/relu_mbox_conf does not need backward computation.
I0212 09:45:46.227720 12230 net.cpp:325] ctx_output4/relu_mbox_loc_flat does not need backward computation.
I0212 09:45:46.227730 12230 net.cpp:325] ctx_output4/relu_mbox_loc_perm does not need backward computation.
I0212 09:45:46.227742 12230 net.cpp:325] ctx_output4/relu_mbox_loc does not need backward computation.
I0212 09:45:46.227751 12230 net.cpp:325] ctx_output3/relu_mbox_priorbox does not need backward computation.
I0212 09:45:46.227761 12230 net.cpp:325] ctx_output3/relu_mbox_conf_flat does not need backward computation.
I0212 09:45:46.227773 12230 net.cpp:325] ctx_output3/relu_mbox_conf_perm does not need backward computation.
I0212 09:45:46.227782 12230 net.cpp:325] ctx_output3/relu_mbox_conf does not need backward computation.
I0212 09:45:46.227792 12230 net.cpp:325] ctx_output3/relu_mbox_loc_flat does not need backward computation.
I0212 09:45:46.227802 12230 net.cpp:325] ctx_output3/relu_mbox_loc_perm does not need backward computation.
I0212 09:45:46.227813 12230 net.cpp:325] ctx_output3/relu_mbox_loc does not need backward computation.
I0212 09:45:46.227823 12230 net.cpp:325] ctx_output2/relu_mbox_priorbox does not need backward computation.
I0212 09:45:46.227833 12230 net.cpp:325] ctx_output2/relu_mbox_conf_flat does not need backward computation.
I0212 09:45:46.227844 12230 net.cpp:325] ctx_output2/relu_mbox_conf_perm does not need backward computation.
I0212 09:45:46.227854 12230 net.cpp:325] ctx_output2/relu_mbox_conf does not need backward computation.
I0212 09:45:46.227864 12230 net.cpp:325] ctx_output2/relu_mbox_loc_flat does not need backward computation.
I0212 09:45:46.227874 12230 net.cpp:325] ctx_output2/relu_mbox_loc_perm does not need backward computation.
I0212 09:45:46.227885 12230 net.cpp:325] ctx_output2/relu_mbox_loc does not need backward computation.
I0212 09:45:46.227895 12230 net.cpp:325] ctx_output1/relu_mbox_priorbox does not need backward computation.
I0212 09:45:46.227905 12230 net.cpp:325] ctx_output1/relu_mbox_conf_flat does not need backward computation.
I0212 09:45:46.227916 12230 net.cpp:325] ctx_output1/relu_mbox_conf_perm does not need backward computation.
I0212 09:45:46.227926 12230 net.cpp:325] ctx_output1/relu_mbox_conf does not need backward computation.
I0212 09:45:46.227934 12230 net.cpp:325] ctx_output1/relu_mbox_loc_flat does not need backward computation.
I0212 09:45:46.227943 12230 net.cpp:325] ctx_output1/relu_mbox_loc_perm does not need backward computation.
I0212 09:45:46.227955 12230 net.cpp:325] ctx_output1/relu_mbox_loc does not need backward computation.
I0212 09:45:46.227965 12230 net.cpp:325] ctx_output6_ctx_output6/relu_0_split does not need backward computation.
I0212 09:45:46.227977 12230 net.cpp:325] ctx_output6/relu does not need backward computation.
I0212 09:45:46.227988 12230 net.cpp:325] ctx_output6 does not need backward computation.
I0212 09:45:46.227998 12230 net.cpp:325] ctx_output5_ctx_output5/relu_0_split does not need backward computation.
I0212 09:45:46.228008 12230 net.cpp:325] ctx_output5/relu does not need backward computation.
I0212 09:45:46.228016 12230 net.cpp:325] ctx_output5 does not need backward computation.
I0212 09:45:46.228026 12230 net.cpp:325] ctx_output4_ctx_output4/relu_0_split does not need backward computation.
I0212 09:45:46.228039 12230 net.cpp:325] ctx_output4/relu does not need backward computation.
I0212 09:45:46.228047 12230 net.cpp:325] ctx_output4 does not need backward computation.
I0212 09:45:46.228058 12230 net.cpp:325] ctx_output3_ctx_output3/relu_0_split does not need backward computation.
I0212 09:45:46.228067 12230 net.cpp:325] ctx_output3/relu does not need backward computation.
I0212 09:45:46.228078 12230 net.cpp:325] ctx_output3 does not need backward computation.
I0212 09:45:46.228088 12230 net.cpp:325] ctx_output2_ctx_output2/relu_0_split does not need backward computation.
I0212 09:45:46.228098 12230 net.cpp:325] ctx_output2/relu does not need backward computation.
I0212 09:45:46.228121 12230 net.cpp:325] ctx_output2 does not need backward computation.
I0212 09:45:46.228132 12230 net.cpp:325] ctx_output1_ctx_output1/relu_0_split does not need backward computation.
I0212 09:45:46.228143 12230 net.cpp:325] ctx_output1/relu does not need backward computation.
I0212 09:45:46.228154 12230 net.cpp:325] ctx_output1 does not need backward computation.
I0212 09:45:46.228168 12230 net.cpp:325] pool9 does not need backward computation.
I0212 09:45:46.228178 12230 net.cpp:325] pool8_pool8_0_split does not need backward computation.
I0212 09:45:46.228188 12230 net.cpp:325] pool8 does not need backward computation.
I0212 09:45:46.228199 12230 net.cpp:325] pool7_pool7_0_split does not need backward computation.
I0212 09:45:46.228209 12230 net.cpp:325] pool7 does not need backward computation.
I0212 09:45:46.228220 12230 net.cpp:325] pool6_pool6_0_split does not need backward computation.
I0212 09:45:46.228232 12230 net.cpp:325] pool6 does not need backward computation.
I0212 09:45:46.228242 12230 net.cpp:325] res5a_branch2b_res5a_branch2b/relu_0_split does not need backward computation.
I0212 09:45:46.228252 12230 net.cpp:325] res5a_branch2b/relu does not need backward computation.
I0212 09:45:46.228263 12230 net.cpp:325] res5a_branch2b/bn does not need backward computation.
I0212 09:45:46.228272 12230 net.cpp:325] res5a_branch2b does not need backward computation.
I0212 09:45:46.228282 12230 net.cpp:325] res5a_branch2a/relu does not need backward computation.
I0212 09:45:46.228291 12230 net.cpp:325] res5a_branch2a/bn does not need backward computation.
I0212 09:45:46.228301 12230 net.cpp:325] res5a_branch2a does not need backward computation.
I0212 09:45:46.228312 12230 net.cpp:325] pool4 does not need backward computation.
I0212 09:45:46.228322 12230 net.cpp:325] res4a_branch2b/relu does not need backward computation.
I0212 09:45:46.228330 12230 net.cpp:325] res4a_branch2b/bn does not need backward computation.
I0212 09:45:46.228341 12230 net.cpp:325] res4a_branch2b does not need backward computation.
I0212 09:45:46.228351 12230 net.cpp:325] res4a_branch2a/relu does not need backward computation.
I0212 09:45:46.228360 12230 net.cpp:325] res4a_branch2a/bn does not need backward computation.
I0212 09:45:46.228368 12230 net.cpp:325] res4a_branch2a does not need backward computation.
I0212 09:45:46.228379 12230 net.cpp:325] pool3 does not need backward computation.
I0212 09:45:46.228390 12230 net.cpp:325] res3a_branch2b_res3a_branch2b/relu_0_split does not need backward computation.
I0212 09:45:46.228400 12230 net.cpp:325] res3a_branch2b/relu does not need backward computation.
I0212 09:45:46.228408 12230 net.cpp:325] res3a_branch2b/bn does not need backward computation.
I0212 09:45:46.228418 12230 net.cpp:325] res3a_branch2b does not need backward computation.
I0212 09:45:46.228430 12230 net.cpp:325] res3a_branch2a/relu does not need backward computation.
I0212 09:45:46.228438 12230 net.cpp:325] res3a_branch2a/bn does not need backward computation.
I0212 09:45:46.228447 12230 net.cpp:325] res3a_branch2a does not need backward computation.
I0212 09:45:46.228457 12230 net.cpp:325] pool2 does not need backward computation.
I0212 09:45:46.228468 12230 net.cpp:325] res2a_branch2b/relu does not need backward computation.
I0212 09:45:46.228477 12230 net.cpp:325] res2a_branch2b/bn does not need backward computation.
I0212 09:45:46.228487 12230 net.cpp:325] res2a_branch2b does not need backward computation.
I0212 09:45:46.228498 12230 net.cpp:325] res2a_branch2a/relu does not need backward computation.
I0212 09:45:46.228507 12230 net.cpp:325] res2a_branch2a/bn does not need backward computation.
I0212 09:45:46.228515 12230 net.cpp:325] res2a_branch2a does not need backward computation.
I0212 09:45:46.228525 12230 net.cpp:325] pool1 does not need backward computation.
I0212 09:45:46.228534 12230 net.cpp:325] conv1b/relu does not need backward computation.
I0212 09:45:46.228543 12230 net.cpp:325] conv1b/bn does not need backward computation.
I0212 09:45:46.228552 12230 net.cpp:325] conv1b does not need backward computation.
I0212 09:45:46.228574 12230 net.cpp:325] conv1a/relu does not need backward computation.
I0212 09:45:46.228583 12230 net.cpp:325] conv1a/bn does not need backward computation.
I0212 09:45:46.228591 12230 net.cpp:325] conv1a does not need backward computation.
I0212 09:45:46.228601 12230 net.cpp:325] data/bias does not need backward computation.
I0212 09:45:46.228615 12230 net.cpp:325] data_data_0_split does not need backward computation.
I0212 09:45:46.228626 12230 net.cpp:325] data does not need backward computation.
I0212 09:45:46.228637 12230 net.cpp:367] This network produces output detection_eval
I0212 09:45:46.228863 12230 net.cpp:389] Top memory (TEST) required for data: 656271440 diff: 656271440
I0212 09:45:46.228879 12230 net.cpp:392] Bottom memory (TEST) required for data: 656271360 diff: 656271360
I0212 09:45:46.228888 12230 net.cpp:395] Shared (in-place) memory (TEST) by data: 281894912 diff: 281894912
I0212 09:45:46.228896 12230 net.cpp:398] Parameters memory (TEST) required for data: 12464288 diff: 12464288
I0212 09:45:46.228904 12230 net.cpp:401] Parameters shared memory (TEST) by data: 0 diff: 0
I0212 09:45:46.228914 12230 net.cpp:407] Network initialization done.
I0212 09:45:46.229612 12230 solver.cpp:57] Solver scaffolding done.
I0212 09:45:46.244933 12230 caffe.cpp:232] Resuming from /user/a0875091/files/work/bitbucket_TI/caffe-jacinto-models/scripts/training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_18000.solverstate
I0212 09:45:46.407871 12230 net.cpp:1094] Copying source layer data Type:AnnotatedData #blobs=0
I0212 09:45:46.407920 12230 net.cpp:1094] Copying source layer data_data_0_split Type:Split #blobs=0
I0212 09:45:46.407932 12230 net.cpp:1094] Copying source layer data/bias Type:Bias #blobs=1
I0212 09:45:46.408004 12230 net.cpp:1094] Copying source layer conv1a Type:Convolution #blobs=2
I0212 09:45:46.408046 12230 net.cpp:1094] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0212 09:45:46.408645 12230 net.cpp:1094] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0212 09:45:46.408668 12230 net.cpp:1094] Copying source layer conv1b Type:Convolution #blobs=2
I0212 09:45:46.408699 12230 net.cpp:1094] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0212 09:45:46.409103 12230 net.cpp:1094] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0212 09:45:46.409122 12230 net.cpp:1094] Copying source layer pool1 Type:Pooling #blobs=0
I0212 09:45:46.409132 12230 net.cpp:1094] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0212 09:45:46.409176 12230 net.cpp:1094] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0212 09:45:46.409584 12230 net.cpp:1094] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0212 09:45:46.409602 12230 net.cpp:1094] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0212 09:45:46.409641 12230 net.cpp:1094] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0212 09:45:46.410030 12230 net.cpp:1094] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0212 09:45:46.410048 12230 net.cpp:1094] Copying source layer pool2 Type:Pooling #blobs=0
I0212 09:45:46.410058 12230 net.cpp:1094] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0212 09:45:46.410217 12230 net.cpp:1094] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0212 09:45:46.410611 12230 net.cpp:1094] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0212 09:45:46.410631 12230 net.cpp:1094] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0212 09:45:46.410691 12230 net.cpp:1094] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0212 09:45:46.410990 12230 net.cpp:1094] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0212 09:45:46.411008 12230 net.cpp:1094] Copying source layer res3a_branch2b_res3a_branch2b/relu_0_split Type:Split #blobs=0
I0212 09:45:46.411017 12230 net.cpp:1094] Copying source layer pool3 Type:Pooling #blobs=0
I0212 09:45:46.411051 12230 net.cpp:1094] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0212 09:45:46.411309 12230 net.cpp:1094] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0212 09:45:46.411628 12230 net.cpp:1094] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0212 09:45:46.411646 12230 net.cpp:1094] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0212 09:45:46.411789 12230 net.cpp:1094] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0212 09:45:46.412099 12230 net.cpp:1094] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0212 09:45:46.412117 12230 net.cpp:1094] Copying source layer pool4 Type:Pooling #blobs=0
I0212 09:45:46.412125 12230 net.cpp:1094] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0212 09:45:46.413035 12230 net.cpp:1094] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0212 09:45:46.413394 12230 net.cpp:1094] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0212 09:45:46.413414 12230 net.cpp:1094] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0212 09:45:46.413869 12230 net.cpp:1094] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0212 09:45:46.414219 12230 net.cpp:1094] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0212 09:45:46.414238 12230 net.cpp:1094] Copying source layer res5a_branch2b_res5a_branch2b/relu_0_split Type:Split #blobs=0
I0212 09:45:46.414247 12230 net.cpp:1094] Copying source layer pool6 Type:Pooling #blobs=0
I0212 09:45:46.414255 12230 net.cpp:1094] Copying source layer pool6_pool6_0_split Type:Split #blobs=0
I0212 09:45:46.414263 12230 net.cpp:1094] Copying source layer pool7 Type:Pooling #blobs=0
I0212 09:45:46.414271 12230 net.cpp:1094] Copying source layer pool7_pool7_0_split Type:Split #blobs=0
I0212 09:45:46.414279 12230 net.cpp:1094] Copying source layer pool8 Type:Pooling #blobs=0
I0212 09:45:46.414288 12230 net.cpp:1094] Copying source layer pool8_pool8_0_split Type:Split #blobs=0
I0212 09:45:46.414295 12230 net.cpp:1094] Copying source layer pool9 Type:Pooling #blobs=0
I0212 09:45:46.414304 12230 net.cpp:1094] Copying source layer ctx_output1 Type:Convolution #blobs=2
I0212 09:45:46.414351 12230 net.cpp:1094] Copying source layer ctx_output1/relu Type:ReLU #blobs=0
I0212 09:45:46.414366 12230 net.cpp:1094] Copying source layer ctx_output1_ctx_output1/relu_0_split Type:Split #blobs=0
I0212 09:45:46.414374 12230 net.cpp:1094] Copying source layer ctx_output2 Type:Convolution #blobs=2
I0212 09:45:46.414489 12230 net.cpp:1094] Copying source layer ctx_output2/relu Type:ReLU #blobs=0
I0212 09:45:46.414503 12230 net.cpp:1094] Copying source layer ctx_output2_ctx_output2/relu_0_split Type:Split #blobs=0
I0212 09:45:46.414512 12230 net.cpp:1094] Copying source layer ctx_output3 Type:Convolution #blobs=2
I0212 09:45:46.414628 12230 net.cpp:1094] Copying source layer ctx_output3/relu Type:ReLU #blobs=0
I0212 09:45:46.414643 12230 net.cpp:1094] Copying source layer ctx_output3_ctx_output3/relu_0_split Type:Split #blobs=0
I0212 09:45:46.414650 12230 net.cpp:1094] Copying source layer ctx_output4 Type:Convolution #blobs=2
I0212 09:45:46.414767 12230 net.cpp:1094] Copying source layer ctx_output4/relu Type:ReLU #blobs=0
I0212 09:45:46.414780 12230 net.cpp:1094] Copying source layer ctx_output4_ctx_output4/relu_0_split Type:Split #blobs=0
I0212 09:45:46.414788 12230 net.cpp:1094] Copying source layer ctx_output5 Type:Convolution #blobs=2
I0212 09:45:46.414904 12230 net.cpp:1094] Copying source layer ctx_output5/relu Type:ReLU #blobs=0
I0212 09:45:46.414918 12230 net.cpp:1094] Copying source layer ctx_output5_ctx_output5/relu_0_split Type:Split #blobs=0
I0212 09:45:46.414927 12230 net.cpp:1094] Copying source layer ctx_output6 Type:Convolution #blobs=2
I0212 09:45:46.415045 12230 net.cpp:1094] Copying source layer ctx_output6/relu Type:ReLU #blobs=0
I0212 09:45:46.415058 12230 net.cpp:1094] Copying source layer ctx_output6_ctx_output6/relu_0_split Type:Split #blobs=0
I0212 09:45:46.415087 12230 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc Type:Convolution #blobs=2
I0212 09:45:46.415118 12230 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc_perm Type:Permute #blobs=0
I0212 09:45:46.415132 12230 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc_flat Type:Flatten #blobs=0
I0212 09:45:46.415140 12230 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf Type:Convolution #blobs=2
I0212 09:45:46.415169 12230 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf_perm Type:Permute #blobs=0
I0212 09:45:46.415181 12230 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf_flat Type:Flatten #blobs=0
I0212 09:45:46.415190 12230 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_priorbox Type:PriorBox #blobs=0
I0212 09:45:46.415199 12230 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc Type:Convolution #blobs=2
I0212 09:45:46.415231 12230 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc_perm Type:Permute #blobs=0
I0212 09:45:46.415243 12230 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc_flat Type:Flatten #blobs=0
I0212 09:45:46.415252 12230 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf Type:Convolution #blobs=2
I0212 09:45:46.415282 12230 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf_perm Type:Permute #blobs=0
I0212 09:45:46.415294 12230 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf_flat Type:Flatten #blobs=0
I0212 09:45:46.415303 12230 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_priorbox Type:PriorBox #blobs=0
I0212 09:45:46.415313 12230 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc Type:Convolution #blobs=2
I0212 09:45:46.415341 12230 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc_perm Type:Permute #blobs=0
I0212 09:45:46.415354 12230 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc_flat Type:Flatten #blobs=0
I0212 09:45:46.415364 12230 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf Type:Convolution #blobs=2
I0212 09:45:46.415393 12230 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf_perm Type:Permute #blobs=0
I0212 09:45:46.415406 12230 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf_flat Type:Flatten #blobs=0
I0212 09:45:46.415416 12230 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_priorbox Type:PriorBox #blobs=0
I0212 09:45:46.415423 12230 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc Type:Convolution #blobs=2
I0212 09:45:46.415452 12230 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc_perm Type:Permute #blobs=0
I0212 09:45:46.415464 12230 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc_flat Type:Flatten #blobs=0
I0212 09:45:46.415473 12230 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf Type:Convolution #blobs=2
I0212 09:45:46.415503 12230 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf_perm Type:Permute #blobs=0
I0212 09:45:46.415516 12230 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf_flat Type:Flatten #blobs=0
I0212 09:45:46.415526 12230 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_priorbox Type:PriorBox #blobs=0
I0212 09:45:46.415535 12230 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc Type:Convolution #blobs=2
I0212 09:45:46.415562 12230 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc_perm Type:Permute #blobs=0
I0212 09:45:46.415575 12230 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc_flat Type:Flatten #blobs=0
I0212 09:45:46.415585 12230 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf Type:Convolution #blobs=2
I0212 09:45:46.415612 12230 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf_perm Type:Permute #blobs=0
I0212 09:45:46.415626 12230 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf_flat Type:Flatten #blobs=0
I0212 09:45:46.415634 12230 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_priorbox Type:PriorBox #blobs=0
I0212 09:45:46.415643 12230 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc Type:Convolution #blobs=2
I0212 09:45:46.415690 12230 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc_perm Type:Permute #blobs=0
I0212 09:45:46.415705 12230 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc_flat Type:Flatten #blobs=0
I0212 09:45:46.415714 12230 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf Type:Convolution #blobs=2
I0212 09:45:46.415743 12230 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf_perm Type:Permute #blobs=0
I0212 09:45:46.415755 12230 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf_flat Type:Flatten #blobs=0
I0212 09:45:46.415766 12230 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_priorbox Type:PriorBox #blobs=0
I0212 09:45:46.415773 12230 net.cpp:1094] Copying source layer mbox_loc Type:Concat #blobs=0
I0212 09:45:46.415783 12230 net.cpp:1094] Copying source layer mbox_conf Type:Concat #blobs=0
I0212 09:45:46.415791 12230 net.cpp:1094] Copying source layer mbox_priorbox Type:Concat #blobs=0
I0212 09:45:46.415801 12230 net.cpp:1094] Copying source layer mbox_loss Type:MultiBoxLoss #blobs=0
I0212 09:45:46.416128 12230 sgd_solver.cpp:382] SGDSolver: restoring history
I0212 09:45:46.435734 12230 parallel.cpp:106] [0 - 0] P2pSync adding callback
I0212 09:45:46.435770 12230 parallel.cpp:106] [1 - 1] P2pSync adding callback
I0212 09:45:46.435780 12230 parallel.cpp:59] Starting Optimization
I0212 09:45:46.435787 12230 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0212 09:45:46.435845 12230 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0212 09:45:46.445091 12354 device_alternate.hpp:116] NVML initialized on thread 139997046867712
I0212 09:45:46.505676 12354 common.cpp:585] NVML succeeded to set CPU affinity on device 0
I0212 09:45:46.505770 12355 device_alternate.hpp:116] NVML initialized on thread 139997038475008
I0212 09:45:46.506610 12355 common.cpp:585] NVML succeeded to set CPU affinity on device 1
I0212 09:45:46.518918 12355 solver.cpp:43] Solver data type: FLOAT
I0212 09:45:46.523773 12355 net.cpp:104] Using FLOAT as default forward math type
I0212 09:45:46.523798 12355 net.cpp:110] Using FLOAT as default backward math type
I0212 09:45:46.523978 12355 data_reader.cpp:58] Data Reader threads: 4, out queues: 16, depth: 8
I0212 09:45:46.524062 12355 internal_thread.cpp:19] Starting 4 internal thread(s) on device 1
I0212 09:45:46.525897 12358 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0212 09:45:46.527180 12356 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0212 09:45:46.528213 12357 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0212 09:45:46.529410 12359 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0212 09:45:46.544580 12355 annotated_data_layer.cpp:219] output data size: 8,3,368,720
I0212 09:45:46.545104 12355 annotated_data_layer.cpp:265] [1] Output data size: 8, 3, 368, 720
I0212 09:45:46.545186 12355 internal_thread.cpp:19] Starting 4 internal thread(s) on device 1
I0212 09:45:47.262874 12355 solver.cpp:177] Creating test net (#0) specified by test_net file: training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/test.prototxt
I0212 09:45:47.263749 12355 net.cpp:104] Using FLOAT as default forward math type
I0212 09:45:47.263766 12355 net.cpp:110] Using FLOAT as default backward math type
I0212 09:45:47.263803 12355 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 4
I0212 09:45:47.263814 12355 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0212 09:45:47.265177 12385 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_test_lmdb
I0212 09:45:47.276690 12355 annotated_data_layer.cpp:219] output data size: 4,3,368,720
I0212 09:45:47.276778 12355 annotated_data_layer.cpp:265] (1) Output data size: 4, 3, 368, 720
I0212 09:45:47.276842 12355 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0212 09:45:47.278542 12386 annotated_data_layer.cpp:111] (1) Parser threads: 1
I0212 09:45:47.278566 12386 annotated_data_layer.cpp:113] (1) Transformer threads: 1
I0212 09:45:47.432673 12355 solver.cpp:57] Solver scaffolding done.
I0212 09:45:47.451490 12355 parallel.cpp:161] [1 - 1] P2pSync adding callback
I0212 09:45:47.451494 12354 parallel.cpp:161] [0 - 0] P2pSync adding callback
I0212 09:45:47.597916 12355 solver.cpp:489] Solving ssdJacintoNetV2
I0212 09:45:47.597954 12355 solver.cpp:490] Learning Rate Policy: poly
I0212 09:45:47.597964 12354 solver.cpp:489] Solving ssdJacintoNetV2
I0212 09:45:47.597987 12354 solver.cpp:490] Learning Rate Policy: poly
I0212 09:45:47.605403 12355 net.cpp:1412] [1] Reserving 12451584 bytes of shared learnable space
I0212 09:45:47.608568 12354 net.cpp:1412] [0] Reserving 12451584 bytes of shared learnable space
I0212 09:45:47.612391 12355 solver.cpp:228] Starting Optimization on GPU 1
I0212 09:45:47.612396 12354 solver.cpp:228] Starting Optimization on GPU 0
I0212 09:45:47.612645 12387 device_alternate.hpp:116] NVML initialized on thread 139975525918464
I0212 09:45:47.612884 12387 common.cpp:585] NVML succeeded to set CPU affinity on device 1
I0212 09:45:47.612921 12388 device_alternate.hpp:116] NVML initialized on thread 139975517525760
I0212 09:45:47.613028 12388 common.cpp:585] NVML succeeded to set CPU affinity on device 0
I0212 09:45:47.632966 12354 blocking_queue.cpp:40] Data layer prefetch queue empty
I0212 09:45:48.929275 12360 annotated_data_layer.cpp:111] [1] Parser threads: 4
I0212 09:45:48.929311 12360 annotated_data_layer.cpp:113] [1] Transformer threads: 4
I0212 09:45:48.930044 12292 annotated_data_layer.cpp:111] [0] Parser threads: 4
I0212 09:45:48.930063 12292 annotated_data_layer.cpp:113] [0] Transformer threads: 4
I0212 09:45:49.935907 12354 solver.cpp:319] Iteration 18000 (2.3233 s), loss = 2.61215
I0212 09:45:49.935955 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.51455 (* 1 = 2.51455 loss)
I0212 09:45:49.935967 12354 sgd_solver.cpp:136] Iteration 18000, lr = 0.000522006, m = 0.9
I0212 09:45:50.153957 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'conv1a' with space 4.24G 3/1 1 0 3 	(avail 1.7G, req 0G)	t: 0 2.75 2.17
I0212 09:45:50.289316 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'conv1a' with space 4.24G 3/1 1 0 3 	(avail 1.78G, req 0G)	t: 0 2.76 2.15
I0212 09:45:50.385625 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'conv1b' with space 4.24G 32/4 6 4 3 	(avail 1.7G, req 0G)	t: 0 0.57 1.07
I0212 09:45:50.409309 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'conv1b' with space 4.24G 32/4 6 4 3 	(avail 1.78G, req 0G)	t: 0 0.61 1.05
I0212 09:45:50.655208 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 4.24G 32/1 1 4 3 	(avail 1.65G, req 0G)	t: 0 0.86 1.45
I0212 09:45:50.668989 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 4.24G 32/1 1 4 3 	(avail 1.72G, req 0G)	t: 0 0.82 1.43
I0212 09:45:50.751341 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 4.24G 64/4 1 1 3 	(avail 1.65G, req 0G)	t: 0 0.3 0.54
I0212 09:45:50.789213 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 4.24G 64/4 1 1 3 	(avail 1.72G, req 0G)	t: 0 0.32 0.55
I0212 09:45:51.006372 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 4.24G 64/1 6 4 1 	(avail 1.6G, req 0G)	t: 0 0.45 0.79
I0212 09:45:51.020346 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 4.24G 64/1 6 4 1 	(avail 1.7G, req 0G)	t: 0 0.48 0.83
I0212 09:45:51.080480 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 4.24G 128/4 6 4 0 	(avail 1.6G, req 0G)	t: 0 0.17 0.31
I0212 09:45:51.090209 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 4.24G 128/4 6 4 0 	(avail 1.7G, req 0G)	t: 0 0.18 0.3
I0212 09:45:51.179970 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 4.24G 128/1 6 4 5 	(avail 1.6G, req 0.04G)	t: 0 0.44 0.54
I0212 09:45:51.220798 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 4.24G 128/1 6 4 5 	(avail 1.67G, req 0.04G)	t: 0 0.43 0.51
I0212 09:45:51.246839 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 4.24G 256/4 6 4 5 	(avail 1.57G, req 0.04G)	t: 0 0.09 0.19
I0212 09:45:51.273924 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 4.24G 256/4 6 4 5 	(avail 1.67G, req 0.04G)	t: 0 0.11 0.19
I0212 09:45:51.364662 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 4.24G 256/1 6 4 5 	(avail 1.54G, req 0.04G)	t: 0 0.52 0.5
I0212 09:45:51.384757 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 4.24G 256/1 6 4 5 	(avail 1.61G, req 0.04G)	t: 0 0.54 0.49
I0212 09:45:51.397395 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 4.24G 512/4 6 4 5 	(avail 1.54G, req 0.04G)	t: 0 0.1 0.12
I0212 09:45:51.421393 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 4.24G 512/4 6 4 5 	(avail 1.61G, req 0.04G)	t: 0 0.1 0.12
I0212 09:45:51.439131 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output1' with space 4.24G 128/1 1 1 3 	(avail 1.54G, req 0.04G)	t: 0 0.39 0.75
I0212 09:45:51.475733 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output1' with space 4.24G 128/1 1 1 3 	(avail 1.61G, req 0.04G)	t: 0 0.38 0.73
I0212 09:45:51.500102 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output2' with space 4.24G 512/1 1 1 1 	(avail 1.54G, req 0.04G)	t: 0 0.13 0.2
I0212 09:45:51.526337 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output2' with space 4.24G 512/1 1 1 1 	(avail 1.61G, req 0.04G)	t: 0 0.16 0.21
I0212 09:45:51.528893 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output3' with space 4.24G 512/1 1 1 1 	(avail 1.54G, req 0.04G)	t: 0 0.1 0.09
I0212 09:45:51.550760 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output3' with space 4.24G 512/1 1 1 3 	(avail 1.61G, req 0.04G)	t: 0 0.07 0.1
I0212 09:45:51.564683 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output4' with space 4.24G 512/1 0 0 1 	(avail 1.54G, req 0.04G)	t: 0 0.05 0.06
I0212 09:45:51.585094 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output4' with space 4.24G 512/1 0 0 3 	(avail 1.61G, req 0.04G)	t: 0 0.06 0.07
I0212 09:45:51.596643 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output5' with space 4.24G 512/1 0 0 3 	(avail 1.54G, req 0.04G)	t: 0 0.05 0.06
I0212 09:45:51.612767 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output5' with space 4.24G 512/1 0 0 3 	(avail 1.61G, req 0.04G)	t: 0 0.06 0.05
I0212 09:45:51.636620 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output6' with space 4.24G 512/1 0 0 3 	(avail 1.54G, req 0.04G)	t: 0 0.07 0.06
I0212 09:45:51.642073 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output6' with space 4.24G 512/1 0 0 3 	(avail 1.61G, req 0.04G)	t: 0 0.07 0.05
I0212 09:45:51.745115 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_loc' with space 4.24G 256/1 1 1 3 	(avail 1.61G, req 0.04G)	t: 0 0.26 0.8
I0212 09:45:51.759129 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_loc' with space 4.24G 256/1 1 1 3 	(avail 1.54G, req 0.04G)	t: 0 0.25 0.87
I0212 09:45:51.859489 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_conf' with space 4.24G 256/1 1 1 3 	(avail 1.61G, req 0.04G)	t: 0 0.25 0.8
I0212 09:45:51.868677 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_conf' with space 4.24G 256/1 1 1 3 	(avail 1.51G, req 0.04G)	t: 0 0.24 0.8
I0212 09:45:51.894789 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_loc' with space 4.24G 256/1 1 1 3 	(avail 1.51G, req 0.04G)	t: 0 0.05 0.07
I0212 09:45:51.894873 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_loc' with space 4.24G 256/1 0 1 3 	(avail 1.56G, req 0.04G)	t: 0 0.06 0.07
I0212 09:45:51.911998 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_conf' with space 4.24G 256/1 1 1 3 	(avail 1.56G, req 0.04G)	t: 0 0.04 0.06
I0212 09:45:51.912166 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_conf' with space 4.24G 256/1 1 1 3 	(avail 1.51G, req 0.04G)	t: 0 0.04 0.06
I0212 09:45:51.924815 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 1.51G, req 0.04G)	t: 0 0.03 0.03
I0212 09:45:51.930308 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 1.56G, req 0.04G)	t: 0 0.03 0.03
I0212 09:45:51.937633 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_conf' with space 4.24G 256/1 1 0 0 	(avail 1.51G, req 0.04G)	t: 0 0.03 0.03
I0212 09:45:51.943244 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_conf' with space 4.24G 256/1 1 0 0 	(avail 1.56G, req 0.04G)	t: 0 0.03 0.04
I0212 09:45:51.950382 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_loc' with space 4.24G 256/1 1 0 0 	(avail 1.51G, req 0.04G)	t: 0 0.03 0.03
I0212 09:45:51.956557 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_loc' with space 4.24G 256/1 1 0 0 	(avail 1.56G, req 0.04G)	t: 0 0.03 0.03
I0212 09:45:51.967422 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_conf' with space 4.24G 256/1 1 0 0 	(avail 1.51G, req 0.04G)	t: 0 0.03 0.04
I0212 09:45:51.973062 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_conf' with space 4.24G 256/1 1 0 0 	(avail 1.56G, req 0.04G)	t: 0 0.03 0.03
I0212 09:45:51.980993 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_loc' with space 4.24G 256/1 1 0 0 	(avail 1.51G, req 0.04G)	t: 0 0.03 0.02
I0212 09:45:51.986009 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_loc' with space 4.24G 256/1 1 0 0 	(avail 1.56G, req 0.04G)	t: 0 0.04 0.03
I0212 09:45:51.995088 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_conf' with space 4.24G 256/1 1 0 0 	(avail 1.51G, req 0.04G)	t: 0 0.03 0.02
I0212 09:45:52.000182 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_conf' with space 4.24G 256/1 1 0 1 	(avail 1.56G, req 0.04G)	t: 0 0.05 0.04
I0212 09:45:52.007980 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output6/relu_mbox_loc' with space 4.24G 256/1 1 0 0 	(avail 1.51G, req 0.04G)	t: 0 0.03 0.02
I0212 09:45:52.014292 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output6/relu_mbox_loc' with space 4.24G 256/1 1 0 0 	(avail 1.56G, req 0.04G)	t: 0 0.04 0.02
I0212 09:45:52.020977 12354 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output6/relu_mbox_conf' with space 4.24G 256/1 1 0 0 	(avail 1.51G, req 0.04G)	t: 0 0.03 0.03
I0212 09:45:52.025318 12355 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output6/relu_mbox_conf' with space 4.24G 256/1 1 0 0 	(avail 1.56G, req 0.04G)	t: 0 0.04 0.03
I0212 09:45:52.134202 12354 cudnn_conv_layer.cpp:474] [0] Layer 'conv1a' reallocating workspace 4.24G to 0.07G
I0212 09:45:52.245172 12355 cudnn_conv_layer.cpp:474] [1] Layer 'conv1a' reallocating workspace 4.24G to 0.07G
I0212 09:45:52.466305 12354 solver.cpp:319] Iteration 18001 (2.5303 s), loss = 2.77253
I0212 09:45:52.466404 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.99864 (* 1 = 2.99864 loss)
I0212 09:45:52.845683 12354 solver.cpp:319] Iteration 18002 (0.379356 s), loss = 2.79517
I0212 09:45:52.845788 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.58913 (* 1 = 2.58913 loss)
I0212 09:46:46.766238 12354 solver.cpp:314] Iteration 18100 (1.81755 iter/s, 53.9188s/98 iter), loss = 3.04678
I0212 09:46:46.766398 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.24101 (* 1 = 3.24101 loss)
I0212 09:46:46.766413 12354 sgd_solver.cpp:136] Iteration 18100, lr = 0.000519962, m = 0.9
I0212 09:47:42.514818 12354 solver.cpp:314] Iteration 18200 (1.79383 iter/s, 55.7467s/100 iter), loss = 2.80228
I0212 09:47:42.514947 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.74897 (* 1 = 2.74897 loss)
I0212 09:47:42.514961 12354 sgd_solver.cpp:136] Iteration 18200, lr = 0.000517924, m = 0.9
I0212 09:48:37.402812 12354 solver.cpp:314] Iteration 18300 (1.82195 iter/s, 54.8862s/100 iter), loss = 3.04282
I0212 09:48:37.402926 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.73801 (* 1 = 2.73801 loss)
I0212 09:48:37.402943 12354 sgd_solver.cpp:136] Iteration 18300, lr = 0.000515892, m = 0.9
I0212 09:48:56.954783 12274 data_reader.cpp:305] Starting prefetch of epoch 1
I0212 09:49:32.736366 12354 solver.cpp:314] Iteration 18400 (1.80728 iter/s, 55.3317s/100 iter), loss = 3.03033
I0212 09:49:32.736500 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.1093 (* 1 = 3.1093 loss)
I0212 09:49:32.736662 12354 sgd_solver.cpp:136] Iteration 18400, lr = 0.000513866, m = 0.9
I0212 09:50:28.551105 12354 solver.cpp:314] Iteration 18500 (1.7917 iter/s, 55.8128s/100 iter), loss = 3.05092
I0212 09:50:28.551229 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.8625 (* 1 = 2.8625 loss)
I0212 09:50:28.551244 12354 sgd_solver.cpp:136] Iteration 18500, lr = 0.000511846, m = 0.9
I0212 09:51:24.125092 12354 solver.cpp:314] Iteration 18600 (1.79946 iter/s, 55.5721s/100 iter), loss = 2.99665
I0212 09:51:24.125219 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.45921 (* 1 = 3.45921 loss)
I0212 09:51:24.125236 12354 sgd_solver.cpp:136] Iteration 18600, lr = 0.000509832, m = 0.9
I0212 09:52:19.443615 12354 solver.cpp:314] Iteration 18700 (1.80777 iter/s, 55.3166s/100 iter), loss = 2.96088
I0212 09:52:19.443719 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.40007 (* 1 = 2.40007 loss)
I0212 09:52:19.443733 12354 sgd_solver.cpp:136] Iteration 18700, lr = 0.000507823, m = 0.9
I0212 09:53:14.402570 12354 solver.cpp:314] Iteration 18800 (1.8196 iter/s, 54.9571s/100 iter), loss = 2.86585
I0212 09:53:14.402745 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.30761 (* 1 = 3.30761 loss)
I0212 09:53:14.402779 12354 sgd_solver.cpp:136] Iteration 18800, lr = 0.000505821, m = 0.9
I0212 09:54:10.309356 12354 solver.cpp:314] Iteration 18900 (1.78875 iter/s, 55.9049s/100 iter), loss = 2.91243
I0212 09:54:10.309476 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.26487 (* 1 = 2.26487 loss)
I0212 09:54:10.309491 12354 sgd_solver.cpp:136] Iteration 18900, lr = 0.000503825, m = 0.9
I0212 09:55:06.306486 12354 solver.cpp:314] Iteration 19000 (1.78587 iter/s, 55.9952s/100 iter), loss = 3.13875
I0212 09:55:06.306613 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.39175 (* 1 = 3.39175 loss)
I0212 09:55:06.306633 12354 sgd_solver.cpp:136] Iteration 19000, lr = 0.000501835, m = 0.9
I0212 09:56:02.637312 12354 solver.cpp:314] Iteration 19100 (1.77529 iter/s, 56.3289s/100 iter), loss = 2.86279
I0212 09:56:02.637421 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.35682 (* 1 = 3.35682 loss)
I0212 09:56:02.637436 12354 sgd_solver.cpp:136] Iteration 19100, lr = 0.00049985, m = 0.9
I0212 09:56:58.670553 12354 solver.cpp:314] Iteration 19200 (1.78472 iter/s, 56.0313s/100 iter), loss = 2.98618
I0212 09:56:58.670694 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.97244 (* 1 = 2.97244 loss)
I0212 09:56:58.670712 12354 sgd_solver.cpp:136] Iteration 19200, lr = 0.000497871, m = 0.9
I0212 09:57:54.762934 12354 solver.cpp:314] Iteration 19300 (1.78283 iter/s, 56.0905s/100 iter), loss = 2.92718
I0212 09:57:54.763159 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.41188 (* 1 = 3.41188 loss)
I0212 09:57:54.763175 12354 sgd_solver.cpp:136] Iteration 19300, lr = 0.000495899, m = 0.9
I0212 09:58:52.261871 12354 solver.cpp:314] Iteration 19400 (1.73922 iter/s, 57.497s/100 iter), loss = 3.03176
I0212 09:58:52.261977 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.32944 (* 1 = 2.32944 loss)
I0212 09:58:52.261996 12354 sgd_solver.cpp:136] Iteration 19400, lr = 0.000493932, m = 0.9
I0212 09:59:49.901762 12354 solver.cpp:314] Iteration 19500 (1.73497 iter/s, 57.6379s/100 iter), loss = 3.11816
I0212 09:59:49.901906 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.43743 (* 1 = 2.43743 loss)
I0212 09:59:49.902041 12354 sgd_solver.cpp:136] Iteration 19500, lr = 0.000491971, m = 0.9
I0212 10:00:48.061195 12354 solver.cpp:314] Iteration 19600 (1.71947 iter/s, 58.1574s/100 iter), loss = 3.21698
I0212 10:00:48.061316 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.26869 (* 1 = 2.26869 loss)
I0212 10:00:48.061331 12354 sgd_solver.cpp:136] Iteration 19600, lr = 0.000490016, m = 0.9
I0212 10:01:46.694156 12354 solver.cpp:314] Iteration 19700 (1.70558 iter/s, 58.6309s/100 iter), loss = 2.90226
I0212 10:01:46.694298 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.24458 (* 1 = 3.24458 loss)
I0212 10:01:46.694315 12354 sgd_solver.cpp:136] Iteration 19700, lr = 0.000488066, m = 0.9
I0212 10:02:45.623167 12354 solver.cpp:314] Iteration 19800 (1.69702 iter/s, 58.927s/100 iter), loss = 3.02918
I0212 10:02:45.623266 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.63481 (* 1 = 2.63481 loss)
I0212 10:02:45.623277 12354 sgd_solver.cpp:136] Iteration 19800, lr = 0.000486123, m = 0.9
I0212 10:03:43.980667 12354 solver.cpp:314] Iteration 19900 (1.71364 iter/s, 58.3554s/100 iter), loss = 2.85205
I0212 10:03:43.980983 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.64967 (* 1 = 2.64967 loss)
I0212 10:03:43.981048 12354 sgd_solver.cpp:136] Iteration 19900, lr = 0.000484185, m = 0.9
I0212 10:04:42.516927 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_20000.caffemodel
I0212 10:04:42.521108 12355 net.cpp:1012] Ignoring source layer mbox_loss
I0212 10:04:42.544579 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_20000.solverstate
I0212 10:04:42.556437 12354 solver.cpp:666] Iteration 20000, Testing net (#0)
I0212 10:04:42.569972 12354 net.cpp:1012] Ignoring source layer mbox_loss
I0212 10:04:42.827142 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'conv1a' with space 0.07G 3/1 1 	(avail 5.15G, req 0G)	t: 0
I0212 10:04:42.847100 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'conv1b' with space 0.07G 32/4 6 	(avail 5.15G, req 0G)	t: 0
I0212 10:04:42.862046 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res2a_branch2a' with space 0.07G 32/1 1 	(avail 5.15G, req 0G)	t: 0
I0212 10:04:42.870923 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res2a_branch2b' with space 0.07G 64/4 6 	(avail 5.15G, req 0G)	t: 0
I0212 10:04:42.883615 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res3a_branch2a' with space 0.07G 64/1 6 	(avail 5.15G, req 0G)	t: 0
I0212 10:04:42.888449 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res3a_branch2b' with space 0.07G 128/4 6 	(avail 5.15G, req 0G)	t: 0
I0212 10:04:42.901048 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res4a_branch2a' with space 0.07G 128/1 6 	(avail 5.15G, req 0G)	t: 0
I0212 10:04:42.905545 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res4a_branch2b' with space 0.07G 256/4 6 	(avail 5.15G, req 0G)	t: 0
I0212 10:04:42.914618 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res5a_branch2a' with space 0.07G 256/1 6 	(avail 5.15G, req 0.01G)	t: 0
I0212 10:04:42.918586 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res5a_branch2b' with space 0.07G 512/4 6 	(avail 5.15G, req 0.01G)	t: 0
I0212 10:04:42.921280 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1a' with space 0.07G 3/1 1 	(avail 5.1G, req 0G)	t: 0
I0212 10:04:42.927319 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output1' with space 0.07G 128/1 1 	(avail 5.15G, req 0.01G)	t: 0
I0212 10:04:42.930938 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output2' with space 0.07G 512/1 1 	(avail 5.15G, req 0.01G)	t: 0
I0212 10:04:42.933514 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output3' with space 0.07G 512/1 1 	(avail 5.15G, req 0.01G)	t: 0
I0212 10:04:42.936899 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output4' with space 0.07G 512/1 0 	(avail 5.15G, req 0.01G)	t: 0
I0212 10:04:42.939633 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output5' with space 0.07G 512/1 0 	(avail 5.15G, req 0.01G)	t: 0
I0212 10:04:42.941375 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1b' with space 0.07G 32/4 6 	(avail 5.1G, req 0G)	t: 0
I0212 10:04:42.942126 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output6' with space 0.07G 512/1 0 	(avail 5.15G, req 0.01G)	t: 0
I0212 10:04:42.946388 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output1/relu_mbox_loc' with space 0.07G 256/1 1 	(avail 5.15G, req 0.01G)	t: 0
I0212 10:04:42.949980 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output1/relu_mbox_conf' with space 0.07G 256/1 1 	(avail 5.15G, req 0.01G)	t: 0
I0212 10:04:42.954433 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output2/relu_mbox_loc' with space 0.07G 256/1 1 	(avail 5.15G, req 0.01G)	t: 0
I0212 10:04:42.956580 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2a' with space 0.07G 32/1 1 	(avail 5.1G, req 0G)	t: 0
I0212 10:04:42.958626 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output2/relu_mbox_conf' with space 0.07G 256/1 1 	(avail 5.15G, req 0.01G)	t: 0
I0212 10:04:42.961374 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output3/relu_mbox_loc' with space 0.07G 256/1 1 	(avail 5.15G, req 0.01G)	t: 0
I0212 10:04:42.969503 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output3/relu_mbox_conf' with space 0.07G 256/1 0 	(avail 5.15G, req 0.01G)	t: 0
I0212 10:04:42.971597 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2b' with space 0.07G 64/4 6 	(avail 5.1G, req 0G)	t: 0
I0212 10:04:42.974057 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output4/relu_mbox_loc' with space 0.07G 256/1 1 	(avail 5.15G, req 0.01G)	t: 0
I0212 10:04:42.976184 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output4/relu_mbox_conf' with space 0.07G 256/1 1 	(avail 5.15G, req 0.01G)	t: 0
I0212 10:04:42.978173 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output5/relu_mbox_loc' with space 0.07G 256/1 1 	(avail 5.15G, req 0.01G)	t: 0
I0212 10:04:42.982122 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output5/relu_mbox_conf' with space 0.07G 256/1 0 	(avail 5.15G, req 0.01G)	t: 0
I0212 10:04:42.986961 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2a' with space 0.07G 64/1 6 	(avail 5.1G, req 0G)	t: 0
I0212 10:04:42.988545 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output6/relu_mbox_loc' with space 0.07G 256/1 0 	(avail 5.15G, req 0.01G)	t: 0
I0212 10:04:42.990787 12355 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output6/relu_mbox_conf' with space 0.07G 256/1 0 	(avail 5.15G, req 0.01G)	t: 0
I0212 10:04:42.992308 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2b' with space 0.07G 128/4 6 	(avail 5.1G, req 0G)	t: 0
I0212 10:04:43.007724 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2a' with space 0.07G 128/1 6 	(avail 5.1G, req 0G)	t: 0
I0212 10:04:43.015086 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2b' with space 0.07G 256/4 6 	(avail 5.1G, req 0G)	t: 0
I0212 10:04:43.024338 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res5a_branch2a' with space 0.07G 256/1 6 	(avail 5.1G, req 0.01G)	t: 0
I0212 10:04:43.027778 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res5a_branch2b' with space 0.07G 512/4 6 	(avail 5.1G, req 0.01G)	t: 0
I0212 10:04:43.035038 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output1' with space 0.07G 128/1 1 	(avail 5.1G, req 0.01G)	t: 0
I0212 10:04:43.038812 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output2' with space 0.07G 512/1 1 	(avail 5.1G, req 0.01G)	t: 0
I0212 10:04:43.041823 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output3' with space 0.07G 512/1 1 	(avail 5.1G, req 0.01G)	t: 0
I0212 10:04:43.046569 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output4' with space 0.07G 512/1 0 	(avail 5.1G, req 0.01G)	t: 0
I0212 10:04:43.049166 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output5' with space 0.07G 512/1 0 	(avail 5.1G, req 0.01G)	t: 0
I0212 10:04:43.051647 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output6' with space 0.07G 512/1 0 	(avail 5.1G, req 0.01G)	t: 0
I0212 10:04:43.055047 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output1/relu_mbox_loc' with space 0.07G 256/1 1 	(avail 5.1G, req 0.01G)	t: 0
I0212 10:04:43.058840 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output1/relu_mbox_conf' with space 0.07G 256/1 1 	(avail 5.1G, req 0.01G)	t: 0
I0212 10:04:43.070715 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output2/relu_mbox_loc' with space 0.07G 256/1 1 	(avail 5.1G, req 0.01G)	t: 0
I0212 10:04:43.075003 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output2/relu_mbox_conf' with space 0.07G 256/1 1 	(avail 5.1G, req 0.01G)	t: 0
I0212 10:04:43.077756 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output3/relu_mbox_loc' with space 0.07G 256/1 1 	(avail 5.1G, req 0.01G)	t: 0
I0212 10:04:43.082574 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output3/relu_mbox_conf' with space 0.07G 256/1 1 	(avail 5.1G, req 0.01G)	t: 0
I0212 10:04:43.084897 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output4/relu_mbox_loc' with space 0.07G 256/1 1 	(avail 5.1G, req 0.01G)	t: 0
I0212 10:04:43.087204 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output4/relu_mbox_conf' with space 0.07G 256/1 1 	(avail 5.1G, req 0.01G)	t: 0
I0212 10:04:43.089416 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output5/relu_mbox_loc' with space 0.07G 256/1 1 	(avail 5.1G, req 0.01G)	t: 0
I0212 10:04:43.092589 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output5/relu_mbox_conf' with space 0.07G 256/1 0 	(avail 5.1G, req 0.01G)	t: 0
I0212 10:04:43.094893 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output6/relu_mbox_loc' with space 0.07G 256/1 1 	(avail 5.1G, req 0.01G)	t: 0
I0212 10:04:43.097808 12354 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output6/relu_mbox_conf' with space 0.07G 256/1 0 	(avail 5.1G, req 0.01G)	t: 0
I0212 10:04:59.425693 12386 blocking_queue.cpp:40] Waiting for data
I0212 10:05:36.522343 12355 solver.cpp:774] class AP 1: 0.402311
I0212 10:05:36.576164 12355 solver.cpp:774] class AP 2: 0.613358
I0212 10:05:36.589232 12355 solver.cpp:774] class AP 3: 0.639066
I0212 10:05:36.589290 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.551578
I0212 10:05:37.109756 12354 solver.cpp:774] class AP 1: 0.391719
I0212 10:05:37.169558 12354 solver.cpp:774] class AP 2: 0.600712
I0212 10:05:37.182662 12354 solver.cpp:774] class AP 3: 0.625084
I0212 10:05:37.182673 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.539172
I0212 10:05:37.182708 12354 solver.cpp:265] [MultiGPU] Tests completed in 54.6243s
I0212 10:05:37.569154 12354 solver.cpp:314] Iteration 20000 (0.880402 iter/s, 113.584s/100 iter), loss = 2.94436
I0212 10:05:37.569205 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.09416 (* 1 = 3.09416 loss)
I0212 10:05:37.569222 12354 sgd_solver.cpp:136] Iteration 20000, lr = 0.000482253, m = 0.9
I0212 10:06:32.694594 12354 solver.cpp:314] Iteration 20100 (1.81411 iter/s, 55.1235s/100 iter), loss = 3.18166
I0212 10:06:32.694757 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.22693 (* 1 = 2.22693 loss)
I0212 10:06:32.694772 12354 sgd_solver.cpp:136] Iteration 20100, lr = 0.000480327, m = 0.9
I0212 10:07:27.072353 12354 solver.cpp:314] Iteration 20200 (1.83905 iter/s, 54.3759s/100 iter), loss = 3.15995
I0212 10:07:27.072515 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.69779 (* 1 = 2.69779 loss)
I0212 10:07:27.072547 12354 sgd_solver.cpp:136] Iteration 20200, lr = 0.000478407, m = 0.9
I0212 10:08:22.260227 12354 solver.cpp:314] Iteration 20300 (1.81206 iter/s, 55.1859s/100 iter), loss = 3.03866
I0212 10:08:22.260366 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.16909 (* 1 = 2.16909 loss)
I0212 10:08:22.260381 12354 sgd_solver.cpp:136] Iteration 20300, lr = 0.000476492, m = 0.9
I0212 10:09:16.317908 12354 solver.cpp:314] Iteration 20400 (1.84994 iter/s, 54.0558s/100 iter), loss = 2.73516
I0212 10:09:16.318059 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.55815 (* 1 = 2.55815 loss)
I0212 10:09:16.318126 12354 sgd_solver.cpp:136] Iteration 20400, lr = 0.000474583, m = 0.9
I0212 10:10:11.213790 12354 solver.cpp:314] Iteration 20500 (1.82169 iter/s, 54.8939s/100 iter), loss = 2.90107
I0212 10:10:11.213902 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.69297 (* 1 = 2.69297 loss)
I0212 10:10:11.213917 12354 sgd_solver.cpp:136] Iteration 20500, lr = 0.00047268, m = 0.9
I0212 10:11:06.407718 12354 solver.cpp:314] Iteration 20600 (1.81186 iter/s, 55.1918s/100 iter), loss = 3.11977
I0212 10:11:06.407841 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.57703 (* 1 = 3.57703 loss)
I0212 10:11:06.407857 12354 sgd_solver.cpp:136] Iteration 20600, lr = 0.000470783, m = 0.9
I0212 10:12:01.643172 12354 solver.cpp:314] Iteration 20700 (1.8105 iter/s, 55.2334s/100 iter), loss = 2.78349
I0212 10:12:01.643412 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.94384 (* 1 = 2.94384 loss)
I0212 10:12:01.643450 12354 sgd_solver.cpp:136] Iteration 20700, lr = 0.000468891, m = 0.9
I0212 10:12:56.918956 12354 solver.cpp:314] Iteration 20800 (1.80918 iter/s, 55.2737s/100 iter), loss = 3.04192
I0212 10:12:56.919057 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.04469 (* 1 = 3.04469 loss)
I0212 10:12:56.919212 12354 sgd_solver.cpp:136] Iteration 20800, lr = 0.000467005, m = 0.9
I0212 10:13:51.436679 12354 solver.cpp:314] Iteration 20900 (1.83434 iter/s, 54.5157s/100 iter), loss = 3.24714
I0212 10:13:51.436784 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.41216 (* 1 = 2.41216 loss)
I0212 10:13:51.438818 12354 sgd_solver.cpp:136] Iteration 20900, lr = 0.000465125, m = 0.9
I0212 10:14:46.456192 12354 solver.cpp:314] Iteration 21000 (1.81761 iter/s, 55.0174s/100 iter), loss = 2.9535
I0212 10:14:46.456271 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.30375 (* 1 = 3.30375 loss)
I0212 10:14:46.456284 12354 sgd_solver.cpp:136] Iteration 21000, lr = 0.00046325, m = 0.9
I0212 10:15:41.208176 12354 solver.cpp:314] Iteration 21100 (1.82649 iter/s, 54.7499s/100 iter), loss = 2.8373
I0212 10:15:41.208401 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.73906 (* 1 = 2.73906 loss)
I0212 10:15:41.208719 12354 sgd_solver.cpp:136] Iteration 21100, lr = 0.000461382, m = 0.9
I0212 10:16:36.517848 12354 solver.cpp:314] Iteration 21200 (1.80807 iter/s, 55.3076s/100 iter), loss = 2.87649
I0212 10:16:36.517948 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.52388 (* 1 = 2.52388 loss)
I0212 10:16:36.517963 12354 sgd_solver.cpp:136] Iteration 21200, lr = 0.000459518, m = 0.9
I0212 10:17:31.400972 12354 solver.cpp:314] Iteration 21300 (1.82212 iter/s, 54.8811s/100 iter), loss = 2.83068
I0212 10:17:31.401171 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.40033 (* 1 = 2.40033 loss)
I0212 10:17:31.401206 12354 sgd_solver.cpp:136] Iteration 21300, lr = 0.000457661, m = 0.9
I0212 10:18:26.425151 12354 solver.cpp:314] Iteration 21400 (1.81745 iter/s, 55.0222s/100 iter), loss = 3.05689
I0212 10:18:26.425261 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.62325 (* 1 = 3.62325 loss)
I0212 10:18:26.425276 12354 sgd_solver.cpp:136] Iteration 21400, lr = 0.000455809, m = 0.9
I0212 10:19:02.530274 12274 data_reader.cpp:305] Starting prefetch of epoch 2
I0212 10:19:22.033308 12354 solver.cpp:314] Iteration 21500 (1.79836 iter/s, 55.6061s/100 iter), loss = 2.87304
I0212 10:19:22.033350 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.04119 (* 1 = 2.04119 loss)
I0212 10:19:22.033363 12354 sgd_solver.cpp:136] Iteration 21500, lr = 0.000453962, m = 0.9
I0212 10:20:16.938442 12354 solver.cpp:314] Iteration 21600 (1.82139 iter/s, 54.9032s/100 iter), loss = 3.06532
I0212 10:20:16.938562 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.10336 (* 1 = 2.10336 loss)
I0212 10:20:16.938576 12354 sgd_solver.cpp:136] Iteration 21600, lr = 0.000452122, m = 0.9
I0212 10:21:12.532269 12354 solver.cpp:314] Iteration 21700 (1.79883 iter/s, 55.5918s/100 iter), loss = 2.80498
I0212 10:21:12.532490 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.58034 (* 1 = 3.58034 loss)
I0212 10:21:12.532521 12354 sgd_solver.cpp:136] Iteration 21700, lr = 0.000450287, m = 0.9
I0212 10:22:07.715452 12354 solver.cpp:314] Iteration 21800 (1.81221 iter/s, 55.1812s/100 iter), loss = 3.1646
I0212 10:22:07.715570 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.36356 (* 1 = 4.36356 loss)
I0212 10:22:07.715586 12354 sgd_solver.cpp:136] Iteration 21800, lr = 0.000448457, m = 0.9
I0212 10:23:03.607003 12354 solver.cpp:314] Iteration 21900 (1.78924 iter/s, 55.8896s/100 iter), loss = 2.98666
I0212 10:23:03.607121 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.35827 (* 1 = 2.35827 loss)
I0212 10:23:03.607136 12354 sgd_solver.cpp:136] Iteration 21900, lr = 0.000446633, m = 0.9
I0212 10:23:58.658140 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_22000.caffemodel
I0212 10:23:58.681893 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_22000.solverstate
I0212 10:23:58.695291 12354 solver.cpp:666] Iteration 22000, Testing net (#0)
I0212 10:24:48.123608 12355 solver.cpp:774] class AP 1: 0.393093
I0212 10:24:48.184268 12355 solver.cpp:774] class AP 2: 0.654086
I0212 10:24:48.197525 12355 solver.cpp:774] class AP 3: 0.63621
I0212 10:24:48.197593 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.56113
I0212 10:24:49.266613 12354 solver.cpp:774] class AP 1: 0.363807
I0212 10:24:49.332202 12354 solver.cpp:774] class AP 2: 0.637013
I0212 10:24:49.345425 12354 solver.cpp:774] class AP 3: 0.624705
I0212 10:24:49.345443 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.541842
I0212 10:24:49.345481 12354 solver.cpp:265] [MultiGPU] Tests completed in 50.6484s
I0212 10:24:49.698324 12354 solver.cpp:314] Iteration 22000 (0.942617 iter/s, 106.088s/100 iter), loss = 2.96079
I0212 10:24:49.698379 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.12501 (* 1 = 4.12501 loss)
I0212 10:24:49.698391 12354 sgd_solver.cpp:136] Iteration 22000, lr = 0.000444815, m = 0.9
I0212 10:25:44.826694 12354 solver.cpp:314] Iteration 22100 (1.81401 iter/s, 55.1264s/100 iter), loss = 2.90137
I0212 10:25:44.826822 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.63733 (* 1 = 2.63733 loss)
I0212 10:25:44.826841 12354 sgd_solver.cpp:136] Iteration 22100, lr = 0.000443002, m = 0.9
I0212 10:26:39.187445 12354 solver.cpp:314] Iteration 22200 (1.83963 iter/s, 54.3588s/100 iter), loss = 2.94621
I0212 10:26:39.187665 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.62324 (* 1 = 2.62324 loss)
I0212 10:26:39.187705 12354 sgd_solver.cpp:136] Iteration 22200, lr = 0.000441195, m = 0.9
I0212 10:27:33.381888 12354 solver.cpp:314] Iteration 22300 (1.84527 iter/s, 54.1925s/100 iter), loss = 3.00223
I0212 10:27:33.382001 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.93966 (* 1 = 2.93966 loss)
I0212 10:27:33.382017 12354 sgd_solver.cpp:136] Iteration 22300, lr = 0.000439393, m = 0.9
I0212 10:28:28.906321 12354 solver.cpp:314] Iteration 22400 (1.80108 iter/s, 55.5223s/100 iter), loss = 2.96939
I0212 10:28:28.906427 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.63931 (* 1 = 3.63931 loss)
I0212 10:28:28.906441 12354 sgd_solver.cpp:136] Iteration 22400, lr = 0.000437597, m = 0.9
I0212 10:29:24.461293 12354 solver.cpp:314] Iteration 22500 (1.80009 iter/s, 55.5528s/100 iter), loss = 2.74186
I0212 10:29:24.461410 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.21438 (* 1 = 2.21438 loss)
I0212 10:29:24.461424 12354 sgd_solver.cpp:136] Iteration 22500, lr = 0.000435806, m = 0.9
I0212 10:30:19.804333 12354 solver.cpp:314] Iteration 22600 (1.80698 iter/s, 55.341s/100 iter), loss = 2.97457
I0212 10:30:19.804456 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.99938 (* 1 = 2.99938 loss)
I0212 10:30:19.804472 12354 sgd_solver.cpp:136] Iteration 22600, lr = 0.000434021, m = 0.9
I0212 10:31:14.665108 12354 solver.cpp:314] Iteration 22700 (1.82286 iter/s, 54.8588s/100 iter), loss = 2.82598
I0212 10:31:14.665225 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.32013 (* 1 = 4.32013 loss)
I0212 10:31:14.665240 12354 sgd_solver.cpp:136] Iteration 22700, lr = 0.000432241, m = 0.9
I0212 10:32:10.287119 12354 solver.cpp:314] Iteration 22800 (1.79792 iter/s, 55.62s/100 iter), loss = 3.139
I0212 10:32:10.287214 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.69627 (* 1 = 2.69627 loss)
I0212 10:32:10.287225 12354 sgd_solver.cpp:136] Iteration 22800, lr = 0.000430467, m = 0.9
I0212 10:33:05.837003 12354 solver.cpp:314] Iteration 22900 (1.80025 iter/s, 55.5478s/100 iter), loss = 3.25585
I0212 10:33:05.837139 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.85843 (* 1 = 2.85843 loss)
I0212 10:33:05.837154 12354 sgd_solver.cpp:136] Iteration 22900, lr = 0.000428698, m = 0.9
I0212 10:34:02.499466 12354 solver.cpp:314] Iteration 23000 (1.7649 iter/s, 56.6604s/100 iter), loss = 2.91065
I0212 10:34:02.506196 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.5516 (* 1 = 2.5516 loss)
I0212 10:34:02.506232 12354 sgd_solver.cpp:136] Iteration 23000, lr = 0.000426935, m = 0.9
I0212 10:34:58.571849 12354 solver.cpp:314] Iteration 23100 (1.78347 iter/s, 56.0703s/100 iter), loss = 2.96553
I0212 10:34:58.572067 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.60322 (* 1 = 2.60322 loss)
I0212 10:34:58.572100 12354 sgd_solver.cpp:136] Iteration 23100, lr = 0.000425177, m = 0.9
I0212 10:35:56.456650 12354 solver.cpp:314] Iteration 23200 (1.72763 iter/s, 57.8827s/100 iter), loss = 3.07386
I0212 10:35:56.456763 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.68438 (* 1 = 2.68438 loss)
I0212 10:35:56.456782 12354 sgd_solver.cpp:136] Iteration 23200, lr = 0.000423425, m = 0.9
I0212 10:36:55.910012 12354 solver.cpp:314] Iteration 23300 (1.68205 iter/s, 59.4512s/100 iter), loss = 2.84425
I0212 10:36:55.915026 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.59103 (* 1 = 2.59103 loss)
I0212 10:36:55.915045 12354 sgd_solver.cpp:136] Iteration 23300, lr = 0.000421678, m = 0.9
I0212 10:37:50.690186 12354 solver.cpp:314] Iteration 23400 (1.82554 iter/s, 54.7782s/100 iter), loss = 3.03511
I0212 10:37:50.690536 12354 solver.cpp:336]     Train net output #0: mbox_loss = 1.7949 (* 1 = 1.7949 loss)
I0212 10:37:50.690613 12354 sgd_solver.cpp:136] Iteration 23400, lr = 0.000419936, m = 0.9
I0212 10:38:45.596388 12354 solver.cpp:314] Iteration 23500 (1.82135 iter/s, 54.9042s/100 iter), loss = 2.96404
I0212 10:38:45.596561 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.89738 (* 1 = 3.89738 loss)
I0212 10:38:45.596578 12354 sgd_solver.cpp:136] Iteration 23500, lr = 0.0004182, m = 0.9
I0212 10:39:40.275488 12354 solver.cpp:314] Iteration 23600 (1.82892 iter/s, 54.6771s/100 iter), loss = 3.0369
I0212 10:39:40.275645 12354 solver.cpp:336]     Train net output #0: mbox_loss = 1.88233 (* 1 = 1.88233 loss)
I0212 10:39:40.275661 12354 sgd_solver.cpp:136] Iteration 23600, lr = 0.000416469, m = 0.9
I0212 10:40:34.998606 12354 solver.cpp:314] Iteration 23700 (1.82745 iter/s, 54.7212s/100 iter), loss = 3.00486
I0212 10:40:34.998723 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.32058 (* 1 = 3.32058 loss)
I0212 10:40:34.998738 12354 sgd_solver.cpp:136] Iteration 23700, lr = 0.000414744, m = 0.9
I0212 10:41:30.713177 12354 solver.cpp:314] Iteration 23800 (1.79493 iter/s, 55.7126s/100 iter), loss = 3.17036
I0212 10:41:30.713294 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.8841 (* 1 = 3.8841 loss)
I0212 10:41:30.713310 12354 sgd_solver.cpp:136] Iteration 23800, lr = 0.000413024, m = 0.9
I0212 10:42:27.102161 12354 solver.cpp:314] Iteration 23900 (1.77346 iter/s, 56.387s/100 iter), loss = 2.91652
I0212 10:42:27.104804 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.85383 (* 1 = 2.85383 loss)
I0212 10:42:27.104851 12354 sgd_solver.cpp:136] Iteration 23900, lr = 0.000411309, m = 0.9
I0212 10:43:35.432241 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_24000.caffemodel
I0212 10:43:35.484169 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_24000.solverstate
I0212 10:43:35.496809 12354 solver.cpp:666] Iteration 24000, Testing net (#0)
I0212 10:44:48.552562 12355 solver.cpp:774] class AP 1: 0.401817
I0212 10:44:48.639925 12355 solver.cpp:774] class AP 2: 0.634242
I0212 10:44:48.660212 12355 solver.cpp:774] class AP 3: 0.645872
I0212 10:44:48.660399 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.560643
I0212 10:44:48.814172 12354 solver.cpp:774] class AP 1: 0.372468
I0212 10:44:48.893975 12354 solver.cpp:774] class AP 2: 0.612845
I0212 10:44:48.909533 12354 solver.cpp:774] class AP 3: 0.619167
I0212 10:44:48.909569 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.534826
I0212 10:44:48.909627 12354 solver.cpp:265] [MultiGPU] Tests completed in 73.4101s
I0212 10:44:49.662595 12354 solver.cpp:314] Iteration 24000 (0.701483 iter/s, 142.555s/100 iter), loss = 3.08746
I0212 10:44:49.662647 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.77352 (* 1 = 2.77352 loss)
I0212 10:44:49.662658 12354 sgd_solver.cpp:136] Iteration 24000, lr = 0.0004096, m = 0.9
I0212 10:46:31.416044 12354 solver.cpp:314] Iteration 24100 (0.982803 iter/s, 101.75s/100 iter), loss = 3.12168
I0212 10:46:31.416154 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.5035 (* 1 = 2.5035 loss)
I0212 10:46:31.416169 12354 sgd_solver.cpp:136] Iteration 24100, lr = 0.000407896, m = 0.9
I0212 10:48:12.731796 12354 solver.cpp:314] Iteration 24200 (0.987049 iter/s, 101.312s/100 iter), loss = 2.97854
I0212 10:48:12.731948 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.14412 (* 1 = 2.14412 loss)
I0212 10:48:12.731963 12354 sgd_solver.cpp:136] Iteration 24200, lr = 0.000406197, m = 0.9
I0212 10:48:58.878517 12274 data_reader.cpp:305] Starting prefetch of epoch 3
I0212 10:49:54.666916 12354 solver.cpp:314] Iteration 24300 (0.981052 iter/s, 101.931s/100 iter), loss = 2.97109
I0212 10:49:54.667028 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.93846 (* 1 = 2.93846 loss)
I0212 10:49:54.667043 12354 sgd_solver.cpp:136] Iteration 24300, lr = 0.000404504, m = 0.9
I0212 10:50:59.438458 12354 solver.cpp:314] Iteration 24400 (1.54394 iter/s, 64.7692s/100 iter), loss = 2.80654
I0212 10:50:59.438691 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.02821 (* 1 = 2.02821 loss)
I0212 10:50:59.438726 12354 sgd_solver.cpp:136] Iteration 24400, lr = 0.000402816, m = 0.9
I0212 10:51:54.156899 12354 solver.cpp:314] Iteration 24500 (1.8276 iter/s, 54.7164s/100 iter), loss = 2.93589
I0212 10:51:54.157021 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.19486 (* 1 = 2.19486 loss)
I0212 10:51:54.157150 12354 sgd_solver.cpp:136] Iteration 24500, lr = 0.000401133, m = 0.9
I0212 10:52:49.129707 12354 solver.cpp:314] Iteration 24600 (1.81915 iter/s, 54.9708s/100 iter), loss = 3.44522
I0212 10:52:49.129806 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.20797 (* 1 = 3.20797 loss)
I0212 10:52:49.129817 12354 sgd_solver.cpp:136] Iteration 24600, lr = 0.000399456, m = 0.9
I0212 10:53:43.405752 12354 solver.cpp:314] Iteration 24700 (1.8425 iter/s, 54.274s/100 iter), loss = 2.99797
I0212 10:53:43.405880 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.82078 (* 1 = 2.82078 loss)
I0212 10:53:43.405895 12354 sgd_solver.cpp:136] Iteration 24700, lr = 0.000397783, m = 0.9
I0212 10:54:38.124155 12354 solver.cpp:314] Iteration 24800 (1.82761 iter/s, 54.7164s/100 iter), loss = 2.81271
I0212 10:54:38.124269 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.9189 (* 1 = 2.9189 loss)
I0212 10:54:38.124284 12354 sgd_solver.cpp:136] Iteration 24800, lr = 0.000396116, m = 0.9
I0212 10:55:33.938467 12354 solver.cpp:314] Iteration 24900 (1.79172 iter/s, 55.8123s/100 iter), loss = 3.03976
I0212 10:55:33.938625 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.71345 (* 1 = 4.71345 loss)
I0212 10:55:33.938660 12354 sgd_solver.cpp:136] Iteration 24900, lr = 0.000394455, m = 0.9
I0212 10:56:29.616039 12354 solver.cpp:314] Iteration 25000 (1.79612 iter/s, 55.6755s/100 iter), loss = 2.86402
I0212 10:56:29.616487 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.01406 (* 1 = 3.01406 loss)
I0212 10:56:29.616505 12354 sgd_solver.cpp:136] Iteration 25000, lr = 0.000392798, m = 0.9
I0212 10:57:24.104465 12354 solver.cpp:314] Iteration 25100 (1.83532 iter/s, 54.4864s/100 iter), loss = 2.83788
I0212 10:57:24.104584 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.32598 (* 1 = 3.32598 loss)
I0212 10:57:24.104598 12354 sgd_solver.cpp:136] Iteration 25100, lr = 0.000391147, m = 0.9
I0212 10:58:18.977327 12354 solver.cpp:314] Iteration 25200 (1.82246 iter/s, 54.8709s/100 iter), loss = 3.09937
I0212 10:58:18.977461 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.0539 (* 1 = 3.0539 loss)
I0212 10:58:18.977478 12354 sgd_solver.cpp:136] Iteration 25200, lr = 0.000389501, m = 0.9
I0212 10:59:14.475834 12354 solver.cpp:314] Iteration 25300 (1.80192 iter/s, 55.4965s/100 iter), loss = 2.9138
I0212 10:59:14.475963 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.97587 (* 1 = 2.97587 loss)
I0212 10:59:14.475982 12354 sgd_solver.cpp:136] Iteration 25300, lr = 0.00038786, m = 0.9
I0212 11:00:09.418872 12354 solver.cpp:314] Iteration 25400 (1.82013 iter/s, 54.941s/100 iter), loss = 2.99394
I0212 11:00:09.418983 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.46071 (* 1 = 3.46071 loss)
I0212 11:00:09.418998 12354 sgd_solver.cpp:136] Iteration 25400, lr = 0.000386224, m = 0.9
I0212 11:01:04.146438 12354 solver.cpp:314] Iteration 25500 (1.8273 iter/s, 54.7256s/100 iter), loss = 2.7905
I0212 11:01:04.146569 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.32 (* 1 = 3.32 loss)
I0212 11:01:04.146584 12354 sgd_solver.cpp:136] Iteration 25500, lr = 0.000384594, m = 0.9
I0212 11:01:58.869529 12354 solver.cpp:314] Iteration 25600 (1.82745 iter/s, 54.7211s/100 iter), loss = 3.04193
I0212 11:01:58.869650 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.52101 (* 1 = 3.52101 loss)
I0212 11:01:58.869666 12354 sgd_solver.cpp:136] Iteration 25600, lr = 0.000382968, m = 0.9
I0212 11:02:53.358168 12354 solver.cpp:314] Iteration 25700 (1.83531 iter/s, 54.4867s/100 iter), loss = 2.92417
I0212 11:02:53.358347 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.76898 (* 1 = 2.76898 loss)
I0212 11:02:53.358367 12354 sgd_solver.cpp:136] Iteration 25700, lr = 0.000381348, m = 0.9
I0212 11:03:47.626057 12354 solver.cpp:314] Iteration 25800 (1.84278 iter/s, 54.2659s/100 iter), loss = 2.95693
I0212 11:03:47.626188 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.46792 (* 1 = 3.46792 loss)
I0212 11:03:47.626204 12354 sgd_solver.cpp:136] Iteration 25800, lr = 0.000379733, m = 0.9
I0212 11:04:43.402412 12354 solver.cpp:314] Iteration 25900 (1.79294 iter/s, 55.7743s/100 iter), loss = 3.08658
I0212 11:04:43.402519 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.17641 (* 1 = 2.17641 loss)
I0212 11:04:43.402539 12354 sgd_solver.cpp:136] Iteration 25900, lr = 0.000378123, m = 0.9
I0212 11:05:37.510510 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_26000.caffemodel
I0212 11:05:37.533291 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_26000.solverstate
I0212 11:05:37.545879 12354 solver.cpp:666] Iteration 26000, Testing net (#0)
I0212 11:06:27.395988 12355 solver.cpp:774] class AP 1: 0.402991
I0212 11:06:27.458607 12355 solver.cpp:774] class AP 2: 0.621291
I0212 11:06:27.468966 12355 solver.cpp:774] class AP 3: 0.639437
I0212 11:06:27.468984 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.554573
I0212 11:06:27.884107 12354 solver.cpp:774] class AP 1: 0.401105
I0212 11:06:27.957466 12354 solver.cpp:774] class AP 2: 0.594848
I0212 11:06:27.967083 12354 solver.cpp:774] class AP 3: 0.632741
I0212 11:06:27.967094 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.542898
I0212 11:06:27.967129 12354 solver.cpp:265] [MultiGPU] Tests completed in 50.4194s
I0212 11:06:28.457806 12354 solver.cpp:314] Iteration 26000 (0.951913 iter/s, 105.052s/100 iter), loss = 2.94187
I0212 11:06:28.457839 12354 solver.cpp:336]     Train net output #0: mbox_loss = 1.56286 (* 1 = 1.56286 loss)
I0212 11:06:28.457847 12354 sgd_solver.cpp:136] Iteration 26000, lr = 0.000376519, m = 0.9
I0212 11:07:23.062162 12354 solver.cpp:314] Iteration 26100 (1.83142 iter/s, 54.6024s/100 iter), loss = 3.01041
I0212 11:07:23.062276 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.82755 (* 1 = 2.82755 loss)
I0212 11:07:23.062291 12354 sgd_solver.cpp:136] Iteration 26100, lr = 0.000374919, m = 0.9
I0212 11:08:18.042284 12354 solver.cpp:314] Iteration 26200 (1.8189 iter/s, 54.9781s/100 iter), loss = 2.99323
I0212 11:08:18.042404 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.17044 (* 1 = 3.17044 loss)
I0212 11:08:18.042419 12354 sgd_solver.cpp:136] Iteration 26200, lr = 0.000373324, m = 0.9
I0212 11:09:13.742905 12354 solver.cpp:314] Iteration 26300 (1.79538 iter/s, 55.6986s/100 iter), loss = 2.89904
I0212 11:09:13.743017 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.0948 (* 1 = 2.0948 loss)
I0212 11:09:13.743033 12354 sgd_solver.cpp:136] Iteration 26300, lr = 0.000371735, m = 0.9
I0212 11:10:07.947849 12354 solver.cpp:314] Iteration 26400 (1.84492 iter/s, 54.203s/100 iter), loss = 2.77106
I0212 11:10:07.947968 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.03959 (* 1 = 3.03959 loss)
I0212 11:10:07.947984 12354 sgd_solver.cpp:136] Iteration 26400, lr = 0.000370151, m = 0.9
I0212 11:11:03.014235 12354 solver.cpp:314] Iteration 26500 (1.81605 iter/s, 55.0644s/100 iter), loss = 3.13705
I0212 11:11:03.014371 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.36823 (* 1 = 4.36823 loss)
I0212 11:11:03.014390 12354 sgd_solver.cpp:136] Iteration 26500, lr = 0.000368571, m = 0.9
I0212 11:11:57.485383 12354 solver.cpp:314] Iteration 26600 (1.8359 iter/s, 54.4692s/100 iter), loss = 3.02819
I0212 11:11:57.485534 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.23747 (* 1 = 4.23747 loss)
I0212 11:11:57.485553 12354 sgd_solver.cpp:136] Iteration 26600, lr = 0.000366997, m = 0.9
I0212 11:12:52.337888 12354 solver.cpp:314] Iteration 26700 (1.82314 iter/s, 54.8505s/100 iter), loss = 2.93341
I0212 11:12:52.338013 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.65643 (* 1 = 2.65643 loss)
I0212 11:12:52.338029 12354 sgd_solver.cpp:136] Iteration 26700, lr = 0.000365428, m = 0.9
I0212 11:13:47.549877 12354 solver.cpp:314] Iteration 26800 (1.81127 iter/s, 55.21s/100 iter), loss = 3.04746
I0212 11:13:47.550009 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.05723 (* 1 = 3.05723 loss)
I0212 11:13:47.550194 12354 sgd_solver.cpp:136] Iteration 26800, lr = 0.000363864, m = 0.9
I0212 11:14:43.692958 12354 solver.cpp:314] Iteration 26900 (1.78123 iter/s, 56.1411s/100 iter), loss = 2.893
I0212 11:14:43.693086 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.54721 (* 1 = 2.54721 loss)
I0212 11:14:43.693104 12354 sgd_solver.cpp:136] Iteration 26900, lr = 0.000362305, m = 0.9
I0212 11:15:39.059970 12354 solver.cpp:314] Iteration 27000 (1.80619 iter/s, 55.365s/100 iter), loss = 2.92557
I0212 11:15:39.060164 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.10348 (* 1 = 2.10348 loss)
I0212 11:15:39.060199 12354 sgd_solver.cpp:136] Iteration 27000, lr = 0.00036075, m = 0.9
I0212 11:16:34.295202 12354 solver.cpp:314] Iteration 27100 (1.8105 iter/s, 55.2333s/100 iter), loss = 2.9111
I0212 11:16:34.295300 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.08183 (* 1 = 2.08183 loss)
I0212 11:16:34.295310 12354 sgd_solver.cpp:136] Iteration 27100, lr = 0.000359201, m = 0.9
I0212 11:17:29.237474 12354 solver.cpp:314] Iteration 27200 (1.82016 iter/s, 54.9403s/100 iter), loss = 2.96907
I0212 11:17:29.237599 12354 solver.cpp:336]     Train net output #0: mbox_loss = 1.9027 (* 1 = 1.9027 loss)
I0212 11:17:29.237614 12354 sgd_solver.cpp:136] Iteration 27200, lr = 0.000357657, m = 0.9
I0212 11:18:24.288765 12354 solver.cpp:314] Iteration 27300 (1.81655 iter/s, 55.0493s/100 iter), loss = 3.05291
I0212 11:18:24.288905 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.74979 (* 1 = 2.74979 loss)
I0212 11:18:24.288924 12354 sgd_solver.cpp:136] Iteration 27300, lr = 0.000356118, m = 0.9
I0212 11:19:04.266618 12274 data_reader.cpp:305] Starting prefetch of epoch 4
I0212 11:19:18.810799 12354 solver.cpp:314] Iteration 27400 (1.83419 iter/s, 54.5201s/100 iter), loss = 2.95889
I0212 11:19:18.810842 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.00973 (* 1 = 3.00973 loss)
I0212 11:19:18.810854 12354 sgd_solver.cpp:136] Iteration 27400, lr = 0.000354584, m = 0.9
I0212 11:20:14.372689 12354 solver.cpp:314] Iteration 27500 (1.79986 iter/s, 55.5599s/100 iter), loss = 3.06493
I0212 11:20:14.372818 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.69056 (* 1 = 2.69056 loss)
I0212 11:20:14.372838 12354 sgd_solver.cpp:136] Iteration 27500, lr = 0.000353055, m = 0.9
I0212 11:21:10.058768 12354 solver.cpp:314] Iteration 27600 (1.79584 iter/s, 55.6841s/100 iter), loss = 2.84212
I0212 11:21:10.058884 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.21543 (* 1 = 2.21543 loss)
I0212 11:21:10.058899 12354 sgd_solver.cpp:136] Iteration 27600, lr = 0.00035153, m = 0.9
I0212 11:22:05.438405 12354 solver.cpp:314] Iteration 27700 (1.80578 iter/s, 55.3777s/100 iter), loss = 3.09324
I0212 11:22:05.438534 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.12314 (* 1 = 3.12314 loss)
I0212 11:22:05.438554 12354 sgd_solver.cpp:136] Iteration 27700, lr = 0.000350011, m = 0.9
I0212 11:23:00.514873 12354 solver.cpp:314] Iteration 27800 (1.81572 iter/s, 55.0745s/100 iter), loss = 2.90612
I0212 11:23:00.514981 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.35681 (* 1 = 2.35681 loss)
I0212 11:23:00.514995 12354 sgd_solver.cpp:136] Iteration 27800, lr = 0.000348497, m = 0.9
I0212 11:23:55.841089 12354 solver.cpp:314] Iteration 27900 (1.80753 iter/s, 55.3243s/100 iter), loss = 3.12995
I0212 11:23:55.841243 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.95842 (* 1 = 2.95842 loss)
I0212 11:23:55.841260 12354 sgd_solver.cpp:136] Iteration 27900, lr = 0.000346987, m = 0.9
I0212 11:25:30.139461 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_28000.caffemodel
I0212 11:25:30.195550 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_28000.solverstate
I0212 11:25:30.207309 12354 solver.cpp:666] Iteration 28000, Testing net (#0)
I0212 11:26:43.193529 12355 solver.cpp:774] class AP 1: 0.404889
I0212 11:26:43.281203 12355 solver.cpp:774] class AP 2: 0.632074
I0212 11:26:43.295779 12355 solver.cpp:774] class AP 3: 0.637438
I0212 11:26:43.295816 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.558134
I0212 11:26:43.583236 12354 solver.cpp:774] class AP 1: 0.402912
I0212 11:26:43.657059 12354 solver.cpp:774] class AP 2: 0.618613
I0212 11:26:43.673717 12354 solver.cpp:774] class AP 3: 0.639319
I0212 11:26:43.673748 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.553615
I0212 11:26:43.673790 12354 solver.cpp:265] [MultiGPU] Tests completed in 73.4639s
I0212 11:26:44.334178 12354 solver.cpp:314] Iteration 28000 (0.593517 iter/s, 168.487s/100 iter), loss = 2.94958
I0212 11:26:44.334236 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.27513 (* 1 = 3.27513 loss)
I0212 11:26:44.334252 12354 sgd_solver.cpp:136] Iteration 28000, lr = 0.000345483, m = 0.9
I0212 11:28:24.643059 12354 solver.cpp:314] Iteration 28100 (0.996957 iter/s, 100.305s/100 iter), loss = 2.97577
I0212 11:28:24.643187 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.07569 (* 1 = 2.07569 loss)
I0212 11:28:24.643203 12354 sgd_solver.cpp:136] Iteration 28100, lr = 0.000343983, m = 0.9
I0212 11:30:04.994307 12354 solver.cpp:314] Iteration 28200 (0.996536 iter/s, 100.348s/100 iter), loss = 2.96515
I0212 11:30:05.001888 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.19563 (* 1 = 2.19563 loss)
I0212 11:30:05.001914 12354 sgd_solver.cpp:136] Iteration 28200, lr = 0.000342488, m = 0.9
I0212 11:31:24.638455 12354 solver.cpp:314] Iteration 28300 (1.25563 iter/s, 79.6413s/100 iter), loss = 2.77692
I0212 11:31:24.638561 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.21123 (* 1 = 3.21123 loss)
I0212 11:31:24.638576 12354 sgd_solver.cpp:136] Iteration 28300, lr = 0.000340998, m = 0.9
I0212 11:32:20.078711 12354 solver.cpp:314] Iteration 28400 (1.80381 iter/s, 55.4382s/100 iter), loss = 3.05486
I0212 11:32:20.078871 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.53535 (* 1 = 2.53535 loss)
I0212 11:32:20.078903 12354 sgd_solver.cpp:136] Iteration 28400, lr = 0.000339513, m = 0.9
I0212 11:33:15.199098 12354 solver.cpp:314] Iteration 28500 (1.81428 iter/s, 55.1184s/100 iter), loss = 3.12449
I0212 11:33:15.199199 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.43231 (* 1 = 3.43231 loss)
I0212 11:33:15.199223 12354 sgd_solver.cpp:136] Iteration 28500, lr = 0.000338033, m = 0.9
I0212 11:34:10.331709 12354 solver.cpp:314] Iteration 28600 (1.81387 iter/s, 55.1306s/100 iter), loss = 2.87986
I0212 11:34:10.331817 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.81397 (* 1 = 3.81397 loss)
I0212 11:34:10.331832 12354 sgd_solver.cpp:136] Iteration 28600, lr = 0.000336558, m = 0.9
I0212 11:35:05.467916 12354 solver.cpp:314] Iteration 28700 (1.81376 iter/s, 55.1342s/100 iter), loss = 2.81634
I0212 11:35:05.468020 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.39291 (* 1 = 3.39291 loss)
I0212 11:35:05.468031 12354 sgd_solver.cpp:136] Iteration 28700, lr = 0.000335087, m = 0.9
I0212 11:36:01.348837 12354 solver.cpp:314] Iteration 28800 (1.78958 iter/s, 55.8789s/100 iter), loss = 2.98315
I0212 11:36:01.349000 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.89126 (* 1 = 2.89126 loss)
I0212 11:36:01.349017 12354 sgd_solver.cpp:136] Iteration 28800, lr = 0.000333622, m = 0.9
I0212 11:36:56.135681 12354 solver.cpp:314] Iteration 28900 (1.82533 iter/s, 54.7848s/100 iter), loss = 2.98976
I0212 11:36:56.135820 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.29029 (* 1 = 3.29029 loss)
I0212 11:36:56.135836 12354 sgd_solver.cpp:136] Iteration 28900, lr = 0.000332161, m = 0.9
I0212 11:37:50.896148 12354 solver.cpp:314] Iteration 29000 (1.8262 iter/s, 54.7584s/100 iter), loss = 3.00793
I0212 11:37:50.896277 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.28179 (* 1 = 3.28179 loss)
I0212 11:37:50.896292 12354 sgd_solver.cpp:136] Iteration 29000, lr = 0.000330705, m = 0.9
I0212 11:38:47.167065 12354 solver.cpp:314] Iteration 29100 (1.77718 iter/s, 56.2688s/100 iter), loss = 2.92366
I0212 11:38:47.167207 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.65759 (* 1 = 2.65759 loss)
I0212 11:38:47.167227 12354 sgd_solver.cpp:136] Iteration 29100, lr = 0.000329254, m = 0.9
I0212 11:39:43.051291 12354 solver.cpp:314] Iteration 29200 (1.78948 iter/s, 55.8821s/100 iter), loss = 2.85652
I0212 11:39:43.051390 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.27976 (* 1 = 2.27976 loss)
I0212 11:39:43.051404 12354 sgd_solver.cpp:136] Iteration 29200, lr = 0.000327807, m = 0.9
I0212 11:40:38.662750 12354 solver.cpp:314] Iteration 29300 (1.79826 iter/s, 55.6094s/100 iter), loss = 2.72326
I0212 11:40:38.662910 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.93184 (* 1 = 2.93184 loss)
I0212 11:40:38.662942 12354 sgd_solver.cpp:136] Iteration 29300, lr = 0.000326365, m = 0.9
I0212 11:41:35.238893 12354 solver.cpp:314] Iteration 29400 (1.7676 iter/s, 56.574s/100 iter), loss = 2.88634
I0212 11:41:35.239020 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.48269 (* 1 = 2.48269 loss)
I0212 11:41:35.239037 12354 sgd_solver.cpp:136] Iteration 29400, lr = 0.000324929, m = 0.9
I0212 11:42:30.396280 12354 solver.cpp:314] Iteration 29500 (1.81306 iter/s, 55.1553s/100 iter), loss = 3.07856
I0212 11:42:30.396405 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.34333 (* 1 = 2.34333 loss)
I0212 11:42:30.396425 12354 sgd_solver.cpp:136] Iteration 29500, lr = 0.000323496, m = 0.9
I0212 11:43:26.175365 12354 solver.cpp:314] Iteration 29600 (1.79285 iter/s, 55.777s/100 iter), loss = 2.80212
I0212 11:43:26.175498 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.84051 (* 1 = 2.84051 loss)
I0212 11:43:26.175515 12354 sgd_solver.cpp:136] Iteration 29600, lr = 0.000322069, m = 0.9
I0212 11:44:21.909982 12354 solver.cpp:314] Iteration 29700 (1.79428 iter/s, 55.7326s/100 iter), loss = 2.88661
I0212 11:44:21.910133 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.46195 (* 1 = 3.46195 loss)
I0212 11:44:21.910151 12354 sgd_solver.cpp:136] Iteration 29700, lr = 0.000320646, m = 0.9
I0212 11:45:18.362192 12354 solver.cpp:314] Iteration 29800 (1.77148 iter/s, 56.4501s/100 iter), loss = 2.72702
I0212 11:45:18.362293 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.68446 (* 1 = 3.68446 loss)
I0212 11:45:18.362313 12354 sgd_solver.cpp:136] Iteration 29800, lr = 0.000319228, m = 0.9
I0212 11:46:13.578680 12354 solver.cpp:314] Iteration 29900 (1.81112 iter/s, 55.2145s/100 iter), loss = 2.90913
I0212 11:46:13.578992 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.33257 (* 1 = 4.33257 loss)
I0212 11:46:13.579114 12354 sgd_solver.cpp:136] Iteration 29900, lr = 0.000317815, m = 0.9
I0212 11:47:08.419594 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_30000.caffemodel
I0212 11:47:08.455396 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_30000.solverstate
I0212 11:47:08.476824 12354 solver.cpp:666] Iteration 30000, Testing net (#0)
I0212 11:47:58.438040 12354 solver.cpp:774] class AP 1: 0.366579
I0212 11:47:58.503852 12354 solver.cpp:774] class AP 2: 0.593145
I0212 11:47:58.518236 12354 solver.cpp:774] class AP 3: 0.636541
I0212 11:47:58.518250 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.532088
I0212 11:47:59.686334 12355 solver.cpp:774] class AP 1: 0.369513
I0212 11:47:59.753000 12355 solver.cpp:774] class AP 2: 0.610588
I0212 11:47:59.766773 12355 solver.cpp:774] class AP 3: 0.639974
I0212 11:47:59.766793 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.540025
I0212 11:47:59.766901 12354 solver.cpp:265] [MultiGPU] Tests completed in 51.2882s
I0212 11:48:00.143983 12354 solver.cpp:314] Iteration 30000 (0.938426 iter/s, 106.561s/100 iter), loss = 2.91183
I0212 11:48:00.144079 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.76184 (* 1 = 3.76184 loss)
I0212 11:48:00.144112 12354 sgd_solver.cpp:136] Iteration 30000, lr = 0.000316406, m = 0.9
I0212 11:48:55.487545 12354 solver.cpp:314] Iteration 30100 (1.80696 iter/s, 55.3415s/100 iter), loss = 3.00763
I0212 11:48:55.487669 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.32211 (* 1 = 3.32211 loss)
I0212 11:48:55.487793 12354 sgd_solver.cpp:136] Iteration 30100, lr = 0.000315002, m = 0.9
I0212 11:49:26.971860 12274 data_reader.cpp:305] Starting prefetch of epoch 5
I0212 11:49:51.799639 12354 solver.cpp:314] Iteration 30200 (1.77588 iter/s, 56.31s/100 iter), loss = 2.98985
I0212 11:49:51.799685 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.42358 (* 1 = 2.42358 loss)
I0212 11:49:51.799697 12354 sgd_solver.cpp:136] Iteration 30200, lr = 0.000313603, m = 0.9
I0212 11:50:47.817373 12354 solver.cpp:314] Iteration 30300 (1.78521 iter/s, 56.0157s/100 iter), loss = 2.93088
I0212 11:50:47.817589 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.59032 (* 1 = 3.59032 loss)
I0212 11:50:47.817626 12354 sgd_solver.cpp:136] Iteration 30300, lr = 0.000312209, m = 0.9
I0212 11:51:46.157061 12354 solver.cpp:314] Iteration 30400 (1.71416 iter/s, 58.3376s/100 iter), loss = 2.79225
I0212 11:51:46.157243 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.20704 (* 1 = 3.20704 loss)
I0212 11:51:46.157280 12354 sgd_solver.cpp:136] Iteration 30400, lr = 0.000310819, m = 0.9
I0212 11:52:53.252472 12354 solver.cpp:314] Iteration 30500 (1.49047 iter/s, 67.093s/100 iter), loss = 3.11898
I0212 11:52:53.252601 12354 solver.cpp:336]     Train net output #0: mbox_loss = 5.61681 (* 1 = 5.61681 loss)
I0212 11:52:53.252616 12354 sgd_solver.cpp:136] Iteration 30500, lr = 0.000309433, m = 0.9
I0212 11:53:59.810417 12354 solver.cpp:314] Iteration 30600 (1.5025 iter/s, 66.5555s/100 iter), loss = 2.77121
I0212 11:53:59.810539 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.61396 (* 1 = 2.61396 loss)
I0212 11:53:59.810557 12354 sgd_solver.cpp:136] Iteration 30600, lr = 0.000308053, m = 0.9
I0212 11:55:07.835983 12354 solver.cpp:314] Iteration 30700 (1.47009 iter/s, 68.0231s/100 iter), loss = 2.69586
I0212 11:55:07.838263 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.23281 (* 1 = 2.23281 loss)
I0212 11:55:07.838279 12354 sgd_solver.cpp:136] Iteration 30700, lr = 0.000306677, m = 0.9
I0212 11:56:17.205013 12354 solver.cpp:314] Iteration 30800 (1.44162 iter/s, 69.3665s/100 iter), loss = 2.69086
I0212 11:56:17.205127 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.83481 (* 1 = 2.83481 loss)
I0212 11:56:17.205143 12354 sgd_solver.cpp:136] Iteration 30800, lr = 0.000305305, m = 0.9
I0212 11:57:24.935091 12354 solver.cpp:314] Iteration 30900 (1.4765 iter/s, 67.7276s/100 iter), loss = 2.92409
I0212 11:57:24.935217 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.08791 (* 1 = 3.08791 loss)
I0212 11:57:24.935240 12354 sgd_solver.cpp:136] Iteration 30900, lr = 0.000303939, m = 0.9
I0212 11:58:33.522287 12354 solver.cpp:314] Iteration 31000 (1.45805 iter/s, 68.5847s/100 iter), loss = 3.07632
I0212 11:58:33.522451 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.29826 (* 1 = 3.29826 loss)
I0212 11:58:33.522470 12354 sgd_solver.cpp:136] Iteration 31000, lr = 0.000302576, m = 0.9
I0212 11:59:36.383601 12354 solver.cpp:314] Iteration 31100 (1.59086 iter/s, 62.8591s/100 iter), loss = 3.08011
I0212 11:59:36.383741 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.87346 (* 1 = 3.87346 loss)
I0212 11:59:36.383755 12354 sgd_solver.cpp:136] Iteration 31100, lr = 0.000301219, m = 0.9
I0212 12:00:31.718192 12354 solver.cpp:314] Iteration 31200 (1.80725 iter/s, 55.3326s/100 iter), loss = 2.70462
I0212 12:00:31.718314 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.18862 (* 1 = 3.18862 loss)
I0212 12:00:31.718497 12354 sgd_solver.cpp:136] Iteration 31200, lr = 0.000299866, m = 0.9
I0212 12:01:27.460614 12354 solver.cpp:314] Iteration 31300 (1.79403 iter/s, 55.7404s/100 iter), loss = 2.89092
I0212 12:01:27.460737 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.07386 (* 1 = 3.07386 loss)
I0212 12:01:27.460758 12354 sgd_solver.cpp:136] Iteration 31300, lr = 0.000298517, m = 0.9
I0212 12:02:23.203542 12354 solver.cpp:314] Iteration 31400 (1.79401 iter/s, 55.7409s/100 iter), loss = 3.07719
I0212 12:02:23.203636 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.49116 (* 1 = 2.49116 loss)
I0212 12:02:23.203649 12354 sgd_solver.cpp:136] Iteration 31400, lr = 0.000297173, m = 0.9
I0212 12:03:18.145941 12354 solver.cpp:314] Iteration 31500 (1.82015 iter/s, 54.9404s/100 iter), loss = 2.91231
I0212 12:03:18.146060 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.01141 (* 1 = 3.01141 loss)
I0212 12:03:18.146077 12354 sgd_solver.cpp:136] Iteration 31500, lr = 0.000295834, m = 0.9
I0212 12:04:13.310129 12354 solver.cpp:314] Iteration 31600 (1.81284 iter/s, 55.1622s/100 iter), loss = 3.04641
I0212 12:04:13.310242 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.65239 (* 1 = 2.65239 loss)
I0212 12:04:13.310257 12354 sgd_solver.cpp:136] Iteration 31600, lr = 0.000294499, m = 0.9
I0212 12:05:08.831197 12354 solver.cpp:314] Iteration 31700 (1.80118 iter/s, 55.5191s/100 iter), loss = 3.24161
I0212 12:05:08.831320 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.72887 (* 1 = 2.72887 loss)
I0212 12:05:08.831333 12354 sgd_solver.cpp:136] Iteration 31700, lr = 0.000293169, m = 0.9
I0212 12:06:04.186350 12354 solver.cpp:314] Iteration 31800 (1.80658 iter/s, 55.3532s/100 iter), loss = 3.302
I0212 12:06:04.186468 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.33315 (* 1 = 3.33315 loss)
I0212 12:06:04.186484 12354 sgd_solver.cpp:136] Iteration 31800, lr = 0.000291843, m = 0.9
I0212 12:06:58.934640 12354 solver.cpp:314] Iteration 31900 (1.82661 iter/s, 54.7463s/100 iter), loss = 2.88012
I0212 12:06:58.934772 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.8016 (* 1 = 2.8016 loss)
I0212 12:06:58.934789 12354 sgd_solver.cpp:136] Iteration 31900, lr = 0.000290522, m = 0.9
I0212 12:07:53.370565 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_32000.caffemodel
I0212 12:07:53.388793 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_32000.solverstate
I0212 12:07:53.398036 12354 solver.cpp:666] Iteration 32000, Testing net (#0)
I0212 12:08:43.675472 12355 solver.cpp:774] class AP 1: 0.374174
I0212 12:08:43.738364 12355 solver.cpp:774] class AP 2: 0.617475
I0212 12:08:43.750396 12355 solver.cpp:774] class AP 3: 0.651984
I0212 12:08:43.750422 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.547878
I0212 12:08:43.833410 12354 solver.cpp:774] class AP 1: 0.37169
I0212 12:08:43.903373 12354 solver.cpp:774] class AP 2: 0.606506
I0212 12:08:43.916031 12354 solver.cpp:774] class AP 3: 0.625388
I0212 12:08:43.916043 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.534528
I0212 12:08:43.916079 12354 solver.cpp:265] [MultiGPU] Tests completed in 50.5163s
I0212 12:08:44.387950 12354 solver.cpp:314] Iteration 32000 (0.948321 iter/s, 105.45s/100 iter), loss = 2.8102
I0212 12:08:44.388000 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.6278 (* 1 = 2.6278 loss)
I0212 12:08:44.388008 12354 sgd_solver.cpp:136] Iteration 32000, lr = 0.000289205, m = 0.9
I0212 12:09:39.459496 12354 solver.cpp:314] Iteration 32100 (1.81588 iter/s, 55.0696s/100 iter), loss = 2.84288
I0212 12:09:39.459647 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.30761 (* 1 = 2.30761 loss)
I0212 12:09:39.459663 12354 sgd_solver.cpp:136] Iteration 32100, lr = 0.000287893, m = 0.9
I0212 12:10:34.728583 12354 solver.cpp:314] Iteration 32200 (1.80939 iter/s, 55.2671s/100 iter), loss = 2.79293
I0212 12:10:34.728709 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.84124 (* 1 = 2.84124 loss)
I0212 12:10:34.728729 12354 sgd_solver.cpp:136] Iteration 32200, lr = 0.000286585, m = 0.9
I0212 12:11:30.570441 12354 solver.cpp:314] Iteration 32300 (1.79084 iter/s, 55.8397s/100 iter), loss = 3.10618
I0212 12:11:30.570549 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.31062 (* 1 = 4.31062 loss)
I0212 12:11:30.570564 12354 sgd_solver.cpp:136] Iteration 32300, lr = 0.000285281, m = 0.9
I0212 12:12:26.155318 12354 solver.cpp:314] Iteration 32400 (1.79912 iter/s, 55.5827s/100 iter), loss = 2.81583
I0212 12:12:26.155464 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.73722 (* 1 = 2.73722 loss)
I0212 12:12:26.155481 12354 sgd_solver.cpp:136] Iteration 32400, lr = 0.000283982, m = 0.9
I0212 12:13:21.646888 12354 solver.cpp:314] Iteration 32500 (1.80214 iter/s, 55.4894s/100 iter), loss = 3.02953
I0212 12:13:21.646982 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.02334 (* 1 = 3.02334 loss)
I0212 12:13:21.646992 12354 sgd_solver.cpp:136] Iteration 32500, lr = 0.000282688, m = 0.9
I0212 12:14:16.319977 12354 solver.cpp:314] Iteration 32600 (1.82912 iter/s, 54.671s/100 iter), loss = 2.95372
I0212 12:14:16.320076 12354 solver.cpp:336]     Train net output #0: mbox_loss = 1.98624 (* 1 = 1.98624 loss)
I0212 12:14:16.320089 12354 sgd_solver.cpp:136] Iteration 32600, lr = 0.000281398, m = 0.9
I0212 12:15:12.381707 12354 solver.cpp:314] Iteration 32700 (1.78382 iter/s, 56.0596s/100 iter), loss = 3.10848
I0212 12:15:12.381845 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.30639 (* 1 = 2.30639 loss)
I0212 12:15:12.381860 12354 sgd_solver.cpp:136] Iteration 32700, lr = 0.000280112, m = 0.9
I0212 12:16:07.611042 12354 solver.cpp:314] Iteration 32800 (1.8107 iter/s, 55.2272s/100 iter), loss = 2.7705
I0212 12:16:07.611166 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.79824 (* 1 = 2.79824 loss)
I0212 12:16:07.611182 12354 sgd_solver.cpp:136] Iteration 32800, lr = 0.000278831, m = 0.9
I0212 12:17:02.647305 12354 solver.cpp:314] Iteration 32900 (1.81705 iter/s, 55.0342s/100 iter), loss = 3.1389
I0212 12:17:02.647598 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.7722 (* 1 = 2.7722 loss)
I0212 12:17:02.647660 12354 sgd_solver.cpp:136] Iteration 32900, lr = 0.000277554, m = 0.9
I0212 12:17:58.083418 12354 solver.cpp:314] Iteration 33000 (1.80395 iter/s, 55.434s/100 iter), loss = 2.87122
I0212 12:17:58.083542 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.06642 (* 1 = 3.06642 loss)
I0212 12:17:58.083557 12354 sgd_solver.cpp:136] Iteration 33000, lr = 0.000276282, m = 0.9
I0212 12:18:53.217741 12354 solver.cpp:314] Iteration 33100 (1.81382 iter/s, 55.1322s/100 iter), loss = 2.63987
I0212 12:18:53.217864 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.51634 (* 1 = 2.51634 loss)
I0212 12:18:53.217881 12354 sgd_solver.cpp:136] Iteration 33100, lr = 0.000275014, m = 0.9
I0212 12:19:48.215705 12354 solver.cpp:314] Iteration 33200 (1.81832 iter/s, 54.9957s/100 iter), loss = 2.86694
I0212 12:19:48.215847 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.65863 (* 1 = 2.65863 loss)
I0212 12:19:48.215863 12354 sgd_solver.cpp:136] Iteration 33200, lr = 0.00027375, m = 0.9
I0212 12:20:33.783212 12274 data_reader.cpp:305] Starting prefetch of epoch 6
I0212 12:20:43.191117 12354 solver.cpp:314] Iteration 33300 (1.81907 iter/s, 54.9732s/100 iter), loss = 3.13451
I0212 12:20:43.191159 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.42019 (* 1 = 3.42019 loss)
I0212 12:20:43.191170 12354 sgd_solver.cpp:136] Iteration 33300, lr = 0.00027249, m = 0.9
I0212 12:21:38.699079 12354 solver.cpp:314] Iteration 33400 (1.80162 iter/s, 55.5057s/100 iter), loss = 3.06798
I0212 12:21:38.699203 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.26296 (* 1 = 3.26296 loss)
I0212 12:21:38.699220 12354 sgd_solver.cpp:136] Iteration 33400, lr = 0.000271236, m = 0.9
I0212 12:22:33.594310 12354 solver.cpp:314] Iteration 33500 (1.82172 iter/s, 54.8931s/100 iter), loss = 2.89441
I0212 12:22:33.594460 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.87291 (* 1 = 2.87291 loss)
I0212 12:22:33.594475 12354 sgd_solver.cpp:136] Iteration 33500, lr = 0.000269985, m = 0.9
I0212 12:23:28.377337 12354 solver.cpp:314] Iteration 33600 (1.82545 iter/s, 54.7809s/100 iter), loss = 3.09659
I0212 12:23:28.377465 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.01825 (* 1 = 3.01825 loss)
I0212 12:23:28.377483 12354 sgd_solver.cpp:136] Iteration 33600, lr = 0.000268739, m = 0.9
I0212 12:24:23.574357 12354 solver.cpp:314] Iteration 33700 (1.81176 iter/s, 55.1949s/100 iter), loss = 3.08098
I0212 12:24:23.574456 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.7192 (* 1 = 2.7192 loss)
I0212 12:24:23.574471 12354 sgd_solver.cpp:136] Iteration 33700, lr = 0.000267497, m = 0.9
I0212 12:25:19.311533 12354 solver.cpp:314] Iteration 33800 (1.7942 iter/s, 55.735s/100 iter), loss = 2.92939
I0212 12:25:19.311630 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.074 (* 1 = 2.074 loss)
I0212 12:25:19.311640 12354 sgd_solver.cpp:136] Iteration 33800, lr = 0.000266259, m = 0.9
I0212 12:26:14.050079 12354 solver.cpp:314] Iteration 33900 (1.82694 iter/s, 54.7365s/100 iter), loss = 3.02837
I0212 12:26:14.050227 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.40009 (* 1 = 3.40009 loss)
I0212 12:26:14.050246 12354 sgd_solver.cpp:136] Iteration 33900, lr = 0.000265025, m = 0.9
I0212 12:27:08.314146 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_34000.caffemodel
I0212 12:27:08.337860 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_34000.solverstate
I0212 12:27:08.351189 12354 solver.cpp:666] Iteration 34000, Testing net (#0)
I0212 12:27:57.519582 12354 solver.cpp:774] class AP 1: 0.353531
I0212 12:27:57.598925 12354 solver.cpp:774] class AP 2: 0.613068
I0212 12:27:57.611002 12354 solver.cpp:774] class AP 3: 0.627943
I0212 12:27:57.611032 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.531514
I0212 12:27:59.179438 12355 solver.cpp:774] class AP 1: 0.376194
I0212 12:27:59.253159 12355 solver.cpp:774] class AP 2: 0.631086
I0212 12:27:59.261732 12355 solver.cpp:774] class AP 3: 0.632031
I0212 12:27:59.261751 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.546437
I0212 12:27:59.261875 12354 solver.cpp:265] [MultiGPU] Tests completed in 50.9088s
I0212 12:27:59.743119 12354 solver.cpp:314] Iteration 34000 (0.946172 iter/s, 105.689s/100 iter), loss = 2.9114
I0212 12:27:59.743163 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.30426 (* 1 = 2.30426 loss)
I0212 12:27:59.743172 12354 sgd_solver.cpp:136] Iteration 34000, lr = 0.000263796, m = 0.9
I0212 12:28:54.295248 12354 solver.cpp:314] Iteration 34100 (1.83318 iter/s, 54.5501s/100 iter), loss = 3.25653
I0212 12:28:54.295409 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.17696 (* 1 = 3.17696 loss)
I0212 12:28:54.295423 12354 sgd_solver.cpp:136] Iteration 34100, lr = 0.000262572, m = 0.9
I0212 12:29:48.510468 12354 solver.cpp:314] Iteration 34200 (1.84457 iter/s, 54.213s/100 iter), loss = 2.90363
I0212 12:29:48.510587 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.71354 (* 1 = 3.71354 loss)
I0212 12:29:48.510601 12354 sgd_solver.cpp:136] Iteration 34200, lr = 0.000261351, m = 0.9
I0212 12:30:44.326344 12354 solver.cpp:314] Iteration 34300 (1.79168 iter/s, 55.8137s/100 iter), loss = 2.8205
I0212 12:30:44.326463 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.71922 (* 1 = 2.71922 loss)
I0212 12:30:44.326483 12354 sgd_solver.cpp:136] Iteration 34300, lr = 0.000260135, m = 0.9
I0212 12:31:39.438292 12354 solver.cpp:314] Iteration 34400 (1.81456 iter/s, 55.1098s/100 iter), loss = 2.75528
I0212 12:31:39.438381 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.21324 (* 1 = 3.21324 loss)
I0212 12:31:39.438395 12354 sgd_solver.cpp:136] Iteration 34400, lr = 0.000258923, m = 0.9
I0212 12:32:34.439673 12354 solver.cpp:314] Iteration 34500 (1.81821 iter/s, 54.9993s/100 iter), loss = 2.89978
I0212 12:32:34.439770 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.60702 (* 1 = 2.60702 loss)
I0212 12:32:34.439780 12354 sgd_solver.cpp:136] Iteration 34500, lr = 0.000257715, m = 0.9
I0212 12:33:29.265578 12354 solver.cpp:314] Iteration 34600 (1.82402 iter/s, 54.8239s/100 iter), loss = 2.83261
I0212 12:33:29.265703 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.71026 (* 1 = 3.71026 loss)
I0212 12:33:29.265719 12354 sgd_solver.cpp:136] Iteration 34600, lr = 0.000256511, m = 0.9
I0212 12:34:24.182821 12354 solver.cpp:314] Iteration 34700 (1.82099 iter/s, 54.9152s/100 iter), loss = 3.06596
I0212 12:34:24.184257 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.51948 (* 1 = 2.51948 loss)
I0212 12:34:24.184278 12354 sgd_solver.cpp:136] Iteration 34700, lr = 0.000255312, m = 0.9
I0212 12:35:19.492777 12354 solver.cpp:314] Iteration 34800 (1.80806 iter/s, 55.308s/100 iter), loss = 3.0024
I0212 12:35:19.492938 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.28245 (* 1 = 3.28245 loss)
I0212 12:35:19.492956 12354 sgd_solver.cpp:136] Iteration 34800, lr = 0.000254117, m = 0.9
I0212 12:36:14.002774 12354 solver.cpp:314] Iteration 34900 (1.83459 iter/s, 54.508s/100 iter), loss = 2.8987
I0212 12:36:14.002883 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.02294 (* 1 = 3.02294 loss)
I0212 12:36:14.002897 12354 sgd_solver.cpp:136] Iteration 34900, lr = 0.000252926, m = 0.9
I0212 12:37:09.675001 12354 solver.cpp:314] Iteration 35000 (1.79629 iter/s, 55.6702s/100 iter), loss = 3.11353
I0212 12:37:09.675120 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.76727 (* 1 = 3.76727 loss)
I0212 12:37:09.675137 12354 sgd_solver.cpp:136] Iteration 35000, lr = 0.000251739, m = 0.9
I0212 12:38:05.325876 12354 solver.cpp:314] Iteration 35100 (1.79698 iter/s, 55.6488s/100 iter), loss = 2.99695
I0212 12:38:05.326002 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.04396 (* 1 = 3.04396 loss)
I0212 12:38:05.326017 12354 sgd_solver.cpp:136] Iteration 35100, lr = 0.000250557, m = 0.9
I0212 12:39:00.527256 12354 solver.cpp:314] Iteration 35200 (1.81161 iter/s, 55.1994s/100 iter), loss = 3.05297
I0212 12:39:00.527361 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.53525 (* 1 = 2.53525 loss)
I0212 12:39:00.527374 12354 sgd_solver.cpp:136] Iteration 35200, lr = 0.000249378, m = 0.9
I0212 12:39:54.928484 12354 solver.cpp:314] Iteration 35300 (1.83826 iter/s, 54.3993s/100 iter), loss = 3.04577
I0212 12:39:54.928623 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.61545 (* 1 = 3.61545 loss)
I0212 12:39:54.928640 12354 sgd_solver.cpp:136] Iteration 35300, lr = 0.000248204, m = 0.9
I0212 12:40:50.641849 12354 solver.cpp:314] Iteration 35400 (1.79497 iter/s, 55.7113s/100 iter), loss = 3.16701
I0212 12:40:50.641991 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.67073 (* 1 = 2.67073 loss)
I0212 12:40:50.642009 12354 sgd_solver.cpp:136] Iteration 35400, lr = 0.000247034, m = 0.9
I0212 12:41:45.663620 12354 solver.cpp:314] Iteration 35500 (1.81753 iter/s, 55.0198s/100 iter), loss = 2.85303
I0212 12:41:45.663738 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.32279 (* 1 = 2.32279 loss)
I0212 12:41:45.663750 12354 sgd_solver.cpp:136] Iteration 35500, lr = 0.000245868, m = 0.9
I0212 12:42:40.331300 12354 solver.cpp:314] Iteration 35600 (1.8293 iter/s, 54.6657s/100 iter), loss = 2.90374
I0212 12:42:40.331512 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.01009 (* 1 = 3.01009 loss)
I0212 12:42:40.331550 12354 sgd_solver.cpp:136] Iteration 35600, lr = 0.000244706, m = 0.9
I0212 12:43:35.742527 12354 solver.cpp:314] Iteration 35700 (1.80475 iter/s, 55.4092s/100 iter), loss = 2.85632
I0212 12:43:35.742646 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.66175 (* 1 = 2.66175 loss)
I0212 12:43:35.742661 12354 sgd_solver.cpp:136] Iteration 35700, lr = 0.000243548, m = 0.9
I0212 12:44:30.923610 12354 solver.cpp:314] Iteration 35800 (1.81228 iter/s, 55.1791s/100 iter), loss = 2.91249
I0212 12:44:30.923735 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.68641 (* 1 = 4.68641 loss)
I0212 12:44:30.923874 12354 sgd_solver.cpp:136] Iteration 35800, lr = 0.000242395, m = 0.9
I0212 12:45:26.310732 12354 solver.cpp:314] Iteration 35900 (1.80554 iter/s, 55.3851s/100 iter), loss = 2.83582
I0212 12:45:26.310842 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.97583 (* 1 = 2.97583 loss)
I0212 12:45:26.310854 12354 sgd_solver.cpp:136] Iteration 35900, lr = 0.000241245, m = 0.9
I0212 12:46:21.594420 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_36000.caffemodel
I0212 12:46:21.616559 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_36000.solverstate
I0212 12:46:21.629967 12354 solver.cpp:666] Iteration 36000, Testing net (#0)
I0212 12:47:11.572517 12354 solver.cpp:774] class AP 1: 0.376137
I0212 12:47:11.637017 12354 solver.cpp:774] class AP 2: 0.63112
I0212 12:47:11.650665 12354 solver.cpp:774] class AP 3: 0.629137
I0212 12:47:11.650679 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.545465
I0212 12:47:13.084067 12355 solver.cpp:774] class AP 1: 0.391766
I0212 12:47:13.152040 12355 solver.cpp:774] class AP 2: 0.640665
I0212 12:47:13.165119 12355 solver.cpp:774] class AP 3: 0.661468
I0212 12:47:13.165135 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.564633
I0212 12:47:13.165252 12354 solver.cpp:265] [MultiGPU] Tests completed in 51.5334s
I0212 12:47:13.529481 12354 solver.cpp:314] Iteration 36000 (0.932707 iter/s, 107.215s/100 iter), loss = 2.83496
I0212 12:47:13.529538 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.77344 (* 1 = 2.77344 loss)
I0212 12:47:13.529551 12354 sgd_solver.cpp:136] Iteration 36000, lr = 0.0002401, m = 0.9
I0212 12:47:49.077381 12274 data_reader.cpp:305] Starting prefetch of epoch 7
I0212 12:48:08.769291 12354 solver.cpp:314] Iteration 36100 (1.81035 iter/s, 55.2378s/100 iter), loss = 3.09814
I0212 12:48:08.769332 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.42373 (* 1 = 3.42373 loss)
I0212 12:48:08.769345 12354 sgd_solver.cpp:136] Iteration 36100, lr = 0.000238959, m = 0.9
I0212 12:49:02.990465 12354 solver.cpp:314] Iteration 36200 (1.84437 iter/s, 54.2192s/100 iter), loss = 3.10742
I0212 12:49:02.990623 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.86242 (* 1 = 2.86242 loss)
I0212 12:49:02.990641 12354 sgd_solver.cpp:136] Iteration 36200, lr = 0.000237821, m = 0.9
I0212 12:49:58.052547 12354 solver.cpp:314] Iteration 36300 (1.8162 iter/s, 55.0601s/100 iter), loss = 2.82236
I0212 12:49:58.052669 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.37669 (* 1 = 2.37669 loss)
I0212 12:49:58.052683 12354 sgd_solver.cpp:136] Iteration 36300, lr = 0.000236688, m = 0.9
I0212 12:50:53.608229 12354 solver.cpp:314] Iteration 36400 (1.80006 iter/s, 55.5537s/100 iter), loss = 3.12684
I0212 12:50:53.608357 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.52657 (* 1 = 2.52657 loss)
I0212 12:50:53.608373 12354 sgd_solver.cpp:136] Iteration 36400, lr = 0.000235559, m = 0.9
I0212 12:51:48.631693 12354 solver.cpp:314] Iteration 36500 (1.81747 iter/s, 55.0215s/100 iter), loss = 3.28989
I0212 12:51:48.631822 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.13223 (* 1 = 3.13223 loss)
I0212 12:51:48.631837 12354 sgd_solver.cpp:136] Iteration 36500, lr = 0.000234434, m = 0.9
I0212 12:52:43.870625 12354 solver.cpp:314] Iteration 36600 (1.81038 iter/s, 55.2369s/100 iter), loss = 3.0407
I0212 12:52:43.874260 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.61424 (* 1 = 2.61424 loss)
I0212 12:52:43.874308 12354 sgd_solver.cpp:136] Iteration 36600, lr = 0.000233313, m = 0.9
I0212 12:53:39.403108 12354 solver.cpp:314] Iteration 36700 (1.80081 iter/s, 55.5305s/100 iter), loss = 2.80542
I0212 12:53:39.403236 12354 solver.cpp:336]     Train net output #0: mbox_loss = 1.98488 (* 1 = 1.98488 loss)
I0212 12:53:39.403254 12354 sgd_solver.cpp:136] Iteration 36700, lr = 0.000232196, m = 0.9
I0212 12:54:34.901844 12354 solver.cpp:314] Iteration 36800 (1.80191 iter/s, 55.4967s/100 iter), loss = 2.89795
I0212 12:54:34.901984 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.02003 (* 1 = 3.02003 loss)
I0212 12:54:34.902202 12354 sgd_solver.cpp:136] Iteration 36800, lr = 0.000231083, m = 0.9
I0212 12:55:29.981509 12354 solver.cpp:314] Iteration 36900 (1.81562 iter/s, 55.0777s/100 iter), loss = 3.11165
I0212 12:55:29.981626 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.22918 (* 1 = 3.22918 loss)
I0212 12:55:29.981642 12354 sgd_solver.cpp:136] Iteration 36900, lr = 0.000229974, m = 0.9
I0212 12:56:24.268810 12354 solver.cpp:314] Iteration 37000 (1.84212 iter/s, 54.2853s/100 iter), loss = 2.97739
I0212 12:56:24.268914 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.54951 (* 1 = 3.54951 loss)
I0212 12:56:24.268929 12354 sgd_solver.cpp:136] Iteration 37000, lr = 0.000228869, m = 0.9
I0212 12:57:19.182869 12354 solver.cpp:314] Iteration 37100 (1.82109 iter/s, 54.9121s/100 iter), loss = 3.03623
I0212 12:57:19.182986 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.80402 (* 1 = 2.80402 loss)
I0212 12:57:19.183001 12354 sgd_solver.cpp:136] Iteration 37100, lr = 0.000227768, m = 0.9
I0212 12:58:14.265519 12354 solver.cpp:314] Iteration 37200 (1.81552 iter/s, 55.0807s/100 iter), loss = 2.87533
I0212 12:58:14.265828 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.92549 (* 1 = 3.92549 loss)
I0212 12:58:14.265955 12354 sgd_solver.cpp:136] Iteration 37200, lr = 0.000226671, m = 0.9
I0212 12:59:09.669145 12354 solver.cpp:314] Iteration 37300 (1.805 iter/s, 55.4016s/100 iter), loss = 2.92404
I0212 12:59:09.669457 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.32343 (* 1 = 3.32343 loss)
I0212 12:59:09.669531 12354 sgd_solver.cpp:136] Iteration 37300, lr = 0.000225578, m = 0.9
I0212 13:00:05.286768 12354 solver.cpp:314] Iteration 37400 (1.79806 iter/s, 55.6156s/100 iter), loss = 3.01567
I0212 13:00:05.286882 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.85364 (* 1 = 2.85364 loss)
I0212 13:00:05.286898 12354 sgd_solver.cpp:136] Iteration 37400, lr = 0.000224489, m = 0.9
I0212 13:00:59.954437 12354 solver.cpp:314] Iteration 37500 (1.8293 iter/s, 54.6657s/100 iter), loss = 3.22685
I0212 13:00:59.954576 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.95264 (* 1 = 2.95264 loss)
I0212 13:00:59.954592 12354 sgd_solver.cpp:136] Iteration 37500, lr = 0.000223404, m = 0.9
I0212 13:01:55.216974 12354 solver.cpp:314] Iteration 37600 (1.80961 iter/s, 55.2605s/100 iter), loss = 2.99155
I0212 13:01:55.217133 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.16275 (* 1 = 3.16275 loss)
I0212 13:01:55.217170 12354 sgd_solver.cpp:136] Iteration 37600, lr = 0.000222323, m = 0.9
I0212 13:02:50.777556 12354 solver.cpp:314] Iteration 37700 (1.7999 iter/s, 55.5586s/100 iter), loss = 2.94347
I0212 13:02:50.777681 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.27998 (* 1 = 3.27998 loss)
I0212 13:02:50.777696 12354 sgd_solver.cpp:136] Iteration 37700, lr = 0.000221245, m = 0.9
I0212 13:03:45.920123 12354 solver.cpp:314] Iteration 37800 (1.81355 iter/s, 55.1406s/100 iter), loss = 3.03686
I0212 13:03:45.920238 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.62186 (* 1 = 4.62186 loss)
I0212 13:03:45.920254 12354 sgd_solver.cpp:136] Iteration 37800, lr = 0.000220172, m = 0.9
I0212 13:04:41.269517 12354 solver.cpp:314] Iteration 37900 (1.80677 iter/s, 55.3474s/100 iter), loss = 2.9103
I0212 13:04:41.269665 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.75368 (* 1 = 2.75368 loss)
I0212 13:04:41.269680 12354 sgd_solver.cpp:136] Iteration 37900, lr = 0.000219103, m = 0.9
I0212 13:05:36.356830 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_38000.caffemodel
I0212 13:05:36.380957 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_38000.solverstate
I0212 13:05:36.404767 12354 solver.cpp:666] Iteration 38000, Testing net (#0)
I0212 13:06:25.902468 12355 solver.cpp:774] class AP 1: 0.39445
I0212 13:06:25.974731 12355 solver.cpp:774] class AP 2: 0.641769
I0212 13:06:25.985738 12355 solver.cpp:774] class AP 3: 0.638409
I0212 13:06:25.985761 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.558209
I0212 13:06:26.529803 12354 solver.cpp:774] class AP 1: 0.372891
I0212 13:06:26.608582 12354 solver.cpp:774] class AP 2: 0.624291
I0212 13:06:26.619714 12354 solver.cpp:774] class AP 3: 0.62798
I0212 13:06:26.619741 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.54172
I0212 13:06:26.619933 12354 solver.cpp:265] [MultiGPU] Tests completed in 50.2134s
I0212 13:06:27.034157 12354 solver.cpp:314] Iteration 38000 (0.94553 iter/s, 105.761s/100 iter), loss = 3.06592
I0212 13:06:27.034219 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.65479 (* 1 = 2.65479 loss)
I0212 13:06:27.034234 12354 sgd_solver.cpp:136] Iteration 38000, lr = 0.000218037, m = 0.9
I0212 13:07:21.197989 12354 solver.cpp:314] Iteration 38100 (1.84632 iter/s, 54.1619s/100 iter), loss = 2.99914
I0212 13:07:21.198156 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.25348 (* 1 = 2.25348 loss)
I0212 13:07:21.198173 12354 sgd_solver.cpp:136] Iteration 38100, lr = 0.000216975, m = 0.9
I0212 13:08:16.125625 12354 solver.cpp:314] Iteration 38200 (1.82064 iter/s, 54.9256s/100 iter), loss = 2.79023
I0212 13:08:16.125772 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.03732 (* 1 = 3.03732 loss)
I0212 13:08:16.125790 12354 sgd_solver.cpp:136] Iteration 38200, lr = 0.000215918, m = 0.9
I0212 13:09:11.049535 12354 solver.cpp:314] Iteration 38300 (1.82077 iter/s, 54.9219s/100 iter), loss = 2.98239
I0212 13:09:11.049635 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.85337 (* 1 = 2.85337 loss)
I0212 13:09:11.049654 12354 sgd_solver.cpp:136] Iteration 38300, lr = 0.000214864, m = 0.9
I0212 13:10:06.754053 12354 solver.cpp:314] Iteration 38400 (1.79525 iter/s, 55.7025s/100 iter), loss = 3.0725
I0212 13:10:06.754214 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.13286 (* 1 = 3.13286 loss)
I0212 13:10:06.754230 12354 sgd_solver.cpp:136] Iteration 38400, lr = 0.000213814, m = 0.9
I0212 13:11:02.078327 12354 solver.cpp:314] Iteration 38500 (1.80759 iter/s, 55.3223s/100 iter), loss = 3.08089
I0212 13:11:02.078457 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.05342 (* 1 = 3.05342 loss)
I0212 13:11:02.078474 12354 sgd_solver.cpp:136] Iteration 38500, lr = 0.000212768, m = 0.9
I0212 13:11:57.444140 12354 solver.cpp:314] Iteration 38600 (1.80623 iter/s, 55.3638s/100 iter), loss = 2.92066
I0212 13:11:57.444241 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.08372 (* 1 = 3.08372 loss)
I0212 13:11:57.444257 12354 sgd_solver.cpp:136] Iteration 38600, lr = 0.000211725, m = 0.9
I0212 13:12:53.491787 12354 solver.cpp:314] Iteration 38700 (1.78426 iter/s, 56.0456s/100 iter), loss = 3.19159
I0212 13:12:53.492060 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.3991 (* 1 = 3.3991 loss)
I0212 13:12:53.492131 12354 sgd_solver.cpp:136] Iteration 38700, lr = 0.000210687, m = 0.9
I0212 13:13:47.872004 12354 solver.cpp:314] Iteration 38800 (1.83897 iter/s, 54.3782s/100 iter), loss = 2.91712
I0212 13:13:47.872129 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.52697 (* 1 = 2.52697 loss)
I0212 13:13:47.872143 12354 sgd_solver.cpp:136] Iteration 38800, lr = 0.000209652, m = 0.9
I0212 13:14:43.109369 12354 solver.cpp:314] Iteration 38900 (1.81043 iter/s, 55.2353s/100 iter), loss = 2.88405
I0212 13:14:43.109483 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.69378 (* 1 = 2.69378 loss)
I0212 13:14:43.109616 12354 sgd_solver.cpp:136] Iteration 38900, lr = 0.000208621, m = 0.9
I0212 13:15:36.889956 12354 solver.cpp:314] Iteration 39000 (1.85947 iter/s, 53.7786s/100 iter), loss = 2.89449
I0212 13:15:36.890084 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.36045 (* 1 = 2.36045 loss)
I0212 13:15:36.890130 12354 sgd_solver.cpp:136] Iteration 39000, lr = 0.000207594, m = 0.9
I0212 13:16:32.736027 12354 solver.cpp:314] Iteration 39100 (1.7907 iter/s, 55.844s/100 iter), loss = 3.24487
I0212 13:16:32.736147 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.89731 (* 1 = 2.89731 loss)
I0212 13:16:32.736161 12354 sgd_solver.cpp:136] Iteration 39100, lr = 0.000206571, m = 0.9
I0212 13:17:24.484413 12274 data_reader.cpp:305] Starting prefetch of epoch 8
I0212 13:17:28.237565 12354 solver.cpp:314] Iteration 39200 (1.80182 iter/s, 55.4995s/100 iter), loss = 2.98599
I0212 13:17:28.237610 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.58867 (* 1 = 2.58867 loss)
I0212 13:17:28.237622 12354 sgd_solver.cpp:136] Iteration 39200, lr = 0.000205551, m = 0.9
I0212 13:18:23.182416 12354 solver.cpp:314] Iteration 39300 (1.82007 iter/s, 54.9429s/100 iter), loss = 3.15105
I0212 13:18:23.182541 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.41235 (* 1 = 2.41235 loss)
I0212 13:18:23.182560 12354 sgd_solver.cpp:136] Iteration 39300, lr = 0.000204536, m = 0.9
I0212 13:19:19.265354 12354 solver.cpp:314] Iteration 39400 (1.78314 iter/s, 56.0809s/100 iter), loss = 2.8725
I0212 13:19:19.265468 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.85695 (* 1 = 2.85695 loss)
I0212 13:19:19.265485 12354 sgd_solver.cpp:136] Iteration 39400, lr = 0.000203524, m = 0.9
I0212 13:20:14.251364 12354 solver.cpp:314] Iteration 39500 (1.81871 iter/s, 54.984s/100 iter), loss = 2.94314
I0212 13:20:14.251480 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.01788 (* 1 = 2.01788 loss)
I0212 13:20:14.251495 12354 sgd_solver.cpp:136] Iteration 39500, lr = 0.000202516, m = 0.9
I0212 13:21:09.229866 12354 solver.cpp:314] Iteration 39600 (1.81896 iter/s, 54.9765s/100 iter), loss = 2.99485
I0212 13:21:09.230036 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.38146 (* 1 = 3.38146 loss)
I0212 13:21:09.230077 12354 sgd_solver.cpp:136] Iteration 39600, lr = 0.000201511, m = 0.9
I0212 13:22:04.085063 12354 solver.cpp:314] Iteration 39700 (1.82305 iter/s, 54.8532s/100 iter), loss = 2.9848
I0212 13:22:04.085191 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.48994 (* 1 = 2.48994 loss)
I0212 13:22:04.085207 12354 sgd_solver.cpp:136] Iteration 39700, lr = 0.000200511, m = 0.9
I0212 13:22:58.372539 12354 solver.cpp:314] Iteration 39800 (1.84211 iter/s, 54.2855s/100 iter), loss = 2.94365
I0212 13:22:58.372679 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.71209 (* 1 = 2.71209 loss)
I0212 13:22:58.372911 12354 sgd_solver.cpp:136] Iteration 39800, lr = 0.000199514, m = 0.9
I0212 13:23:53.559541 12354 solver.cpp:314] Iteration 39900 (1.81209 iter/s, 55.185s/100 iter), loss = 2.97002
I0212 13:23:53.559728 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.27277 (* 1 = 2.27277 loss)
I0212 13:23:53.559764 12354 sgd_solver.cpp:136] Iteration 39900, lr = 0.00019852, m = 0.9
I0212 13:24:47.710757 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_40000.caffemodel
I0212 13:24:47.733747 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_40000.solverstate
I0212 13:24:47.747352 12354 solver.cpp:666] Iteration 40000, Testing net (#0)
I0212 13:25:29.725049 12354 blocking_queue.cpp:40] Data layer prefetch queue empty
I0212 13:25:37.854115 12354 solver.cpp:774] class AP 1: 0.36889
I0212 13:25:37.943616 12354 solver.cpp:774] class AP 2: 0.617448
I0212 13:25:37.959331 12354 solver.cpp:774] class AP 3: 0.625994
I0212 13:25:37.959358 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.537444
I0212 13:25:38.360529 12355 solver.cpp:774] class AP 1: 0.393339
I0212 13:25:38.428977 12355 solver.cpp:774] class AP 2: 0.629005
I0212 13:25:38.440927 12355 solver.cpp:774] class AP 3: 0.655003
I0212 13:25:38.440942 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.559116
I0212 13:25:38.441017 12354 solver.cpp:265] [MultiGPU] Tests completed in 50.6918s
I0212 13:25:38.839833 12354 solver.cpp:314] Iteration 40000 (0.94988 iter/s, 105.276s/100 iter), loss = 2.94029
I0212 13:25:38.839877 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.87752 (* 1 = 2.87752 loss)
I0212 13:25:38.839890 12354 sgd_solver.cpp:136] Iteration 40000, lr = 0.000197531, m = 0.9
I0212 13:26:34.324906 12354 solver.cpp:314] Iteration 40100 (1.80235 iter/s, 55.4831s/100 iter), loss = 2.8908
I0212 13:26:34.325084 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.43027 (* 1 = 3.43027 loss)
I0212 13:26:34.325124 12354 sgd_solver.cpp:136] Iteration 40100, lr = 0.000196545, m = 0.9
I0212 13:27:28.962992 12354 solver.cpp:314] Iteration 40200 (1.83029 iter/s, 54.6361s/100 iter), loss = 2.87456
I0212 13:27:28.963101 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.69577 (* 1 = 3.69577 loss)
I0212 13:27:28.963116 12354 sgd_solver.cpp:136] Iteration 40200, lr = 0.000195563, m = 0.9
I0212 13:28:24.354885 12354 solver.cpp:314] Iteration 40300 (1.80538 iter/s, 55.3899s/100 iter), loss = 2.88652
I0212 13:28:24.354995 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.01699 (* 1 = 3.01699 loss)
I0212 13:28:24.355005 12354 sgd_solver.cpp:136] Iteration 40300, lr = 0.000194585, m = 0.9
I0212 13:29:19.696053 12354 solver.cpp:314] Iteration 40400 (1.80704 iter/s, 55.3391s/100 iter), loss = 3.15476
I0212 13:29:19.696169 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.64546 (* 1 = 2.64546 loss)
I0212 13:29:19.696185 12354 sgd_solver.cpp:136] Iteration 40400, lr = 0.00019361, m = 0.9
I0212 13:30:15.179406 12354 solver.cpp:314] Iteration 40500 (1.80241 iter/s, 55.4813s/100 iter), loss = 2.87141
I0212 13:30:15.179584 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.32239 (* 1 = 4.32239 loss)
I0212 13:30:15.179632 12354 sgd_solver.cpp:136] Iteration 40500, lr = 0.000192639, m = 0.9
I0212 13:31:10.426751 12354 solver.cpp:314] Iteration 40600 (1.81011 iter/s, 55.2453s/100 iter), loss = 2.90767
I0212 13:31:10.426877 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.37998 (* 1 = 3.37998 loss)
I0212 13:31:10.426889 12354 sgd_solver.cpp:136] Iteration 40600, lr = 0.000191671, m = 0.9
I0212 13:32:05.754187 12354 solver.cpp:314] Iteration 40700 (1.80749 iter/s, 55.3254s/100 iter), loss = 2.79311
I0212 13:32:05.754395 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.2321 (* 1 = 3.2321 loss)
I0212 13:32:05.754436 12354 sgd_solver.cpp:136] Iteration 40700, lr = 0.000190708, m = 0.9
I0212 13:33:02.178258 12354 solver.cpp:314] Iteration 40800 (1.77236 iter/s, 56.422s/100 iter), loss = 2.93187
I0212 13:33:02.178375 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.9676 (* 1 = 2.9676 loss)
I0212 13:33:02.178391 12354 sgd_solver.cpp:136] Iteration 40800, lr = 0.000189747, m = 0.9
I0212 13:33:57.143187 12354 solver.cpp:314] Iteration 40900 (1.81941 iter/s, 54.9629s/100 iter), loss = 3.01136
I0212 13:33:57.143287 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.83832 (* 1 = 2.83832 loss)
I0212 13:33:57.143298 12354 sgd_solver.cpp:136] Iteration 40900, lr = 0.000188791, m = 0.9
I0212 13:34:52.818054 12354 solver.cpp:314] Iteration 41000 (1.79621 iter/s, 55.6728s/100 iter), loss = 2.88052
I0212 13:34:52.818203 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.90076 (* 1 = 2.90076 loss)
I0212 13:34:52.818218 12354 sgd_solver.cpp:136] Iteration 41000, lr = 0.000187838, m = 0.9
I0212 13:35:48.474931 12354 solver.cpp:314] Iteration 41100 (1.79679 iter/s, 55.6548s/100 iter), loss = 2.89492
I0212 13:35:48.485888 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.09298 (* 1 = 3.09298 loss)
I0212 13:35:48.485920 12354 sgd_solver.cpp:136] Iteration 41100, lr = 0.000186889, m = 0.9
I0212 13:36:43.327046 12354 solver.cpp:314] Iteration 41200 (1.82315 iter/s, 54.8501s/100 iter), loss = 2.79156
I0212 13:36:43.327227 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.47145 (* 1 = 3.47145 loss)
I0212 13:36:43.327262 12354 sgd_solver.cpp:136] Iteration 41200, lr = 0.000185943, m = 0.9
I0212 13:37:37.447926 12354 solver.cpp:314] Iteration 41300 (1.84778 iter/s, 54.1189s/100 iter), loss = 2.92609
I0212 13:37:37.462184 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.02746 (* 1 = 3.02746 loss)
I0212 13:37:37.462220 12354 sgd_solver.cpp:136] Iteration 41300, lr = 0.000185001, m = 0.9
I0212 13:38:32.305596 12354 solver.cpp:314] Iteration 41400 (1.82297 iter/s, 54.8557s/100 iter), loss = 3.16302
I0212 13:38:32.305718 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.27428 (* 1 = 3.27428 loss)
I0212 13:38:32.305733 12354 sgd_solver.cpp:136] Iteration 41400, lr = 0.000184062, m = 0.9
I0212 13:39:28.418182 12354 solver.cpp:314] Iteration 41500 (1.7822 iter/s, 56.1105s/100 iter), loss = 2.95803
I0212 13:39:28.418301 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.37064 (* 1 = 2.37064 loss)
I0212 13:39:28.418318 12354 sgd_solver.cpp:136] Iteration 41500, lr = 0.000183128, m = 0.9
I0212 13:40:24.085597 12354 solver.cpp:314] Iteration 41600 (1.79645 iter/s, 55.6654s/100 iter), loss = 2.9074
I0212 13:40:24.085711 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.30492 (* 1 = 2.30492 loss)
I0212 13:40:24.085728 12354 sgd_solver.cpp:136] Iteration 41600, lr = 0.000182196, m = 0.9
I0212 13:41:19.286612 12354 solver.cpp:314] Iteration 41700 (1.81163 iter/s, 55.199s/100 iter), loss = 2.84328
I0212 13:41:19.286727 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.73946 (* 1 = 2.73946 loss)
I0212 13:41:19.286741 12354 sgd_solver.cpp:136] Iteration 41700, lr = 0.000181268, m = 0.9
I0212 13:42:14.536296 12354 solver.cpp:314] Iteration 41800 (1.81003 iter/s, 55.2477s/100 iter), loss = 3.04789
I0212 13:42:14.536408 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.28697 (* 1 = 3.28697 loss)
I0212 13:42:14.536423 12354 sgd_solver.cpp:136] Iteration 41800, lr = 0.000180344, m = 0.9
I0212 13:43:09.451745 12354 solver.cpp:314] Iteration 41900 (1.82105 iter/s, 54.9134s/100 iter), loss = 2.81355
I0212 13:43:09.451876 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.28495 (* 1 = 3.28495 loss)
I0212 13:43:09.451894 12354 sgd_solver.cpp:136] Iteration 41900, lr = 0.000179423, m = 0.9
I0212 13:44:04.730690 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_42000.caffemodel
I0212 13:44:04.783816 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_42000.solverstate
I0212 13:44:04.796821 12354 solver.cpp:666] Iteration 42000, Testing net (#0)
I0212 13:44:53.210383 12330 data_reader.cpp:305] Starting prefetch of epoch 1
I0212 13:44:54.475340 12354 solver.cpp:774] class AP 1: 0.376769
I0212 13:44:54.547626 12354 solver.cpp:774] class AP 2: 0.643211
I0212 13:44:54.558504 12354 solver.cpp:774] class AP 3: 0.630774
I0212 13:44:54.558521 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.550251
I0212 13:44:55.629218 12355 solver.cpp:774] class AP 1: 0.399515
I0212 13:44:55.700567 12355 solver.cpp:774] class AP 2: 0.650723
I0212 13:44:55.710335 12355 solver.cpp:774] class AP 3: 0.63621
I0212 13:44:55.710355 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.562149
I0212 13:44:55.710428 12354 solver.cpp:265] [MultiGPU] Tests completed in 50.9118s
I0212 13:44:56.118685 12354 solver.cpp:314] Iteration 42000 (0.937532 iter/s, 106.663s/100 iter), loss = 3.04871
I0212 13:44:56.118724 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.88448 (* 1 = 2.88448 loss)
I0212 13:44:56.118733 12354 sgd_solver.cpp:136] Iteration 42000, lr = 0.000178506, m = 0.9
I0212 13:45:50.649972 12354 solver.cpp:314] Iteration 42100 (1.83388 iter/s, 54.5293s/100 iter), loss = 2.90232
I0212 13:45:50.650123 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.24204 (* 1 = 3.24204 loss)
I0212 13:45:50.650367 12354 sgd_solver.cpp:136] Iteration 42100, lr = 0.000177593, m = 0.9
I0212 13:46:47.289798 12354 solver.cpp:314] Iteration 42200 (1.76561 iter/s, 56.6378s/100 iter), loss = 2.92954
I0212 13:46:47.289919 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.45692 (* 1 = 2.45692 loss)
I0212 13:46:47.289933 12354 sgd_solver.cpp:136] Iteration 42200, lr = 0.000176682, m = 0.9
I0212 13:47:42.076742 12354 solver.cpp:314] Iteration 42300 (1.82532 iter/s, 54.785s/100 iter), loss = 3.05352
I0212 13:47:42.076875 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.32648 (* 1 = 3.32648 loss)
I0212 13:47:42.076891 12354 sgd_solver.cpp:136] Iteration 42300, lr = 0.000175776, m = 0.9
I0212 13:48:38.183934 12354 solver.cpp:314] Iteration 42400 (1.78237 iter/s, 56.1051s/100 iter), loss = 2.97916
I0212 13:48:38.184096 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.45969 (* 1 = 3.45969 loss)
I0212 13:48:38.184134 12354 sgd_solver.cpp:136] Iteration 42400, lr = 0.000174873, m = 0.9
I0212 13:49:33.691519 12354 solver.cpp:314] Iteration 42500 (1.80162 iter/s, 55.5056s/100 iter), loss = 2.7921
I0212 13:49:33.691627 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.82876 (* 1 = 2.82876 loss)
I0212 13:49:33.691645 12354 sgd_solver.cpp:136] Iteration 42500, lr = 0.000173973, m = 0.9
I0212 13:50:28.692699 12354 solver.cpp:314] Iteration 42600 (1.81821 iter/s, 54.9992s/100 iter), loss = 2.79838
I0212 13:50:28.692840 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.84659 (* 1 = 2.84659 loss)
I0212 13:50:28.692854 12354 sgd_solver.cpp:136] Iteration 42600, lr = 0.000173077, m = 0.9
I0212 13:51:24.337424 12354 solver.cpp:314] Iteration 42700 (1.79718 iter/s, 55.6427s/100 iter), loss = 2.9104
I0212 13:51:24.337566 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.38933 (* 1 = 3.38933 loss)
I0212 13:51:24.337585 12354 sgd_solver.cpp:136] Iteration 42700, lr = 0.000172184, m = 0.9
I0212 13:52:18.912672 12354 solver.cpp:314] Iteration 42800 (1.8324 iter/s, 54.5733s/100 iter), loss = 3.18463
I0212 13:52:18.912885 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.22201 (* 1 = 2.22201 loss)
I0212 13:52:18.912923 12354 sgd_solver.cpp:136] Iteration 42800, lr = 0.000171295, m = 0.9
I0212 13:53:13.682461 12354 solver.cpp:314] Iteration 42900 (1.82589 iter/s, 54.7678s/100 iter), loss = 2.83552
I0212 13:53:13.682629 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.77191 (* 1 = 2.77191 loss)
I0212 13:53:13.682669 12354 sgd_solver.cpp:136] Iteration 42900, lr = 0.000170409, m = 0.9
I0212 13:54:09.470464 12354 solver.cpp:314] Iteration 43000 (1.79257 iter/s, 55.786s/100 iter), loss = 2.88194
I0212 13:54:09.470608 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.11201 (* 1 = 2.11201 loss)
I0212 13:54:09.470644 12354 sgd_solver.cpp:136] Iteration 43000, lr = 0.000169527, m = 0.9
I0212 13:55:04.516149 12354 solver.cpp:314] Iteration 43100 (1.81674 iter/s, 55.0437s/100 iter), loss = 2.5725
I0212 13:55:04.517148 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.12591 (* 1 = 3.12591 loss)
I0212 13:55:04.517180 12354 sgd_solver.cpp:136] Iteration 43100, lr = 0.000168648, m = 0.9
I0212 13:55:59.520113 12354 solver.cpp:314] Iteration 43200 (1.81812 iter/s, 55.002s/100 iter), loss = 3.1262
I0212 13:55:59.520239 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.95964 (* 1 = 3.95964 loss)
I0212 13:55:59.520254 12354 sgd_solver.cpp:136] Iteration 43200, lr = 0.000167772, m = 0.9
I0212 13:56:54.809866 12354 solver.cpp:314] Iteration 43300 (1.80872 iter/s, 55.2877s/100 iter), loss = 2.85028
I0212 13:56:54.809983 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.36414 (* 1 = 3.36414 loss)
I0212 13:56:54.810003 12354 sgd_solver.cpp:136] Iteration 43300, lr = 0.0001669, m = 0.9
I0212 13:57:49.902199 12354 solver.cpp:314] Iteration 43400 (1.8152 iter/s, 55.0903s/100 iter), loss = 2.81707
I0212 13:57:49.902335 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.79257 (* 1 = 2.79257 loss)
I0212 13:57:49.902354 12354 sgd_solver.cpp:136] Iteration 43400, lr = 0.000166031, m = 0.9
I0212 13:58:45.584630 12354 solver.cpp:314] Iteration 43500 (1.79596 iter/s, 55.6804s/100 iter), loss = 3.12981
I0212 13:58:45.584727 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.7277 (* 1 = 3.7277 loss)
I0212 13:58:45.584736 12354 sgd_solver.cpp:136] Iteration 43500, lr = 0.000165166, m = 0.9
I0212 13:59:40.655110 12354 solver.cpp:314] Iteration 43600 (1.81592 iter/s, 55.0685s/100 iter), loss = 2.86205
I0212 13:59:40.655238 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.59185 (* 1 = 2.59185 loss)
I0212 13:59:40.655258 12354 sgd_solver.cpp:136] Iteration 43600, lr = 0.000164304, m = 0.9
I0212 14:00:35.396049 12354 solver.cpp:314] Iteration 43700 (1.82685 iter/s, 54.7389s/100 iter), loss = 2.90671
I0212 14:00:35.396164 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.66851 (* 1 = 2.66851 loss)
I0212 14:00:35.396178 12354 sgd_solver.cpp:136] Iteration 43700, lr = 0.000163446, m = 0.9
I0212 14:01:29.983997 12354 solver.cpp:314] Iteration 43800 (1.83197 iter/s, 54.586s/100 iter), loss = 3.18325
I0212 14:01:29.984109 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.63648 (* 1 = 2.63648 loss)
I0212 14:01:29.984124 12354 sgd_solver.cpp:136] Iteration 43800, lr = 0.00016259, m = 0.9
I0212 14:02:25.612520 12354 solver.cpp:314] Iteration 43900 (1.7977 iter/s, 55.6265s/100 iter), loss = 2.76668
I0212 14:02:25.612649 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.21718 (* 1 = 3.21718 loss)
I0212 14:02:25.612663 12354 sgd_solver.cpp:136] Iteration 43900, lr = 0.000161739, m = 0.9
I0212 14:03:20.425788 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_44000.caffemodel
I0212 14:03:20.450587 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_44000.solverstate
I0212 14:03:20.459825 12354 solver.cpp:666] Iteration 44000, Testing net (#0)
I0212 14:04:10.961282 12355 solver.cpp:774] class AP 1: 0.395391
I0212 14:04:11.029104 12355 solver.cpp:774] class AP 2: 0.636016
I0212 14:04:11.040963 12355 solver.cpp:774] class AP 3: 0.627787
I0212 14:04:11.040992 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.553065
I0212 14:04:11.436157 12354 solver.cpp:774] class AP 1: 0.377672
I0212 14:04:11.510046 12354 solver.cpp:774] class AP 2: 0.623664
I0212 14:04:11.522352 12354 solver.cpp:774] class AP 3: 0.630606
I0212 14:04:11.522364 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.543981
I0212 14:04:11.522400 12354 solver.cpp:265] [MultiGPU] Tests completed in 51.0607s
I0212 14:04:11.910277 12354 solver.cpp:314] Iteration 44000 (0.940788 iter/s, 106.294s/100 iter), loss = 2.61763
I0212 14:04:11.910320 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.34184 (* 1 = 2.34184 loss)
I0212 14:04:11.910333 12354 sgd_solver.cpp:136] Iteration 44000, lr = 0.00016089, m = 0.9
I0212 14:05:06.585013 12354 solver.cpp:314] Iteration 44100 (1.82906 iter/s, 54.6728s/100 iter), loss = 2.79606
I0212 14:05:06.585167 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.63613 (* 1 = 2.63613 loss)
I0212 14:05:06.585183 12354 sgd_solver.cpp:136] Iteration 44100, lr = 0.000160045, m = 0.9
I0212 14:06:01.817831 12354 solver.cpp:314] Iteration 44200 (1.81058 iter/s, 55.2308s/100 iter), loss = 2.84837
I0212 14:06:01.818243 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.83773 (* 1 = 2.83773 loss)
I0212 14:06:01.818279 12354 sgd_solver.cpp:136] Iteration 44200, lr = 0.000159203, m = 0.9
I0212 14:06:57.252009 12354 solver.cpp:314] Iteration 44300 (1.80401 iter/s, 55.4322s/100 iter), loss = 3.03462
I0212 14:06:57.252125 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.75952 (* 1 = 2.75952 loss)
I0212 14:06:57.252140 12354 sgd_solver.cpp:136] Iteration 44300, lr = 0.000158365, m = 0.9
I0212 14:07:52.904338 12354 solver.cpp:314] Iteration 44400 (1.79694 iter/s, 55.6503s/100 iter), loss = 2.93385
I0212 14:07:52.910238 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.4285 (* 1 = 2.4285 loss)
I0212 14:07:52.910284 12354 sgd_solver.cpp:136] Iteration 44400, lr = 0.00015753, m = 0.9
I0212 14:08:47.387342 12354 solver.cpp:314] Iteration 44500 (1.8355 iter/s, 54.481s/100 iter), loss = 2.68231
I0212 14:08:47.387465 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.14326 (* 1 = 2.14326 loss)
I0212 14:08:47.387480 12354 sgd_solver.cpp:136] Iteration 44500, lr = 0.000156698, m = 0.9
I0212 14:09:42.306876 12354 solver.cpp:314] Iteration 44600 (1.82091 iter/s, 54.9175s/100 iter), loss = 2.94251
I0212 14:09:42.307049 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.42173 (* 1 = 2.42173 loss)
I0212 14:09:42.307085 12354 sgd_solver.cpp:136] Iteration 44600, lr = 0.000155869, m = 0.9
I0212 14:10:37.758586 12354 solver.cpp:314] Iteration 44700 (1.80344 iter/s, 55.4497s/100 iter), loss = 2.94633
I0212 14:10:37.758687 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.79295 (* 1 = 2.79295 loss)
I0212 14:10:37.758698 12354 sgd_solver.cpp:136] Iteration 44700, lr = 0.000155044, m = 0.9
I0212 14:11:33.466178 12354 solver.cpp:314] Iteration 44800 (1.79515 iter/s, 55.7056s/100 iter), loss = 3.20713
I0212 14:11:33.466305 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.94533 (* 1 = 2.94533 loss)
I0212 14:11:33.466320 12354 sgd_solver.cpp:136] Iteration 44800, lr = 0.000154222, m = 0.9
I0212 14:12:28.775777 12354 solver.cpp:314] Iteration 44900 (1.80807 iter/s, 55.3076s/100 iter), loss = 2.86577
I0212 14:12:28.775939 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.24498 (* 1 = 2.24498 loss)
I0212 14:12:28.775954 12354 sgd_solver.cpp:136] Iteration 44900, lr = 0.000153403, m = 0.9
I0212 14:13:23.976925 12354 solver.cpp:314] Iteration 45000 (1.81162 iter/s, 55.1991s/100 iter), loss = 2.90586
I0212 14:13:23.977053 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.78717 (* 1 = 3.78717 loss)
I0212 14:13:23.977064 12354 sgd_solver.cpp:136] Iteration 45000, lr = 0.000152588, m = 0.9
I0212 14:14:18.976438 12354 solver.cpp:314] Iteration 45100 (1.81826 iter/s, 54.9975s/100 iter), loss = 2.75615
I0212 14:14:18.976547 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.97159 (* 1 = 2.97159 loss)
I0212 14:14:18.976562 12354 sgd_solver.cpp:136] Iteration 45100, lr = 0.000151776, m = 0.9
I0212 14:14:20.678206 12274 data_reader.cpp:305] Starting prefetch of epoch 9
I0212 14:15:13.677340 12354 solver.cpp:314] Iteration 45200 (1.82819 iter/s, 54.6989s/100 iter), loss = 2.99146
I0212 14:15:13.677561 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.76147 (* 1 = 2.76147 loss)
I0212 14:15:13.677577 12354 sgd_solver.cpp:136] Iteration 45200, lr = 0.000150967, m = 0.9
I0212 14:16:07.813411 12354 solver.cpp:314] Iteration 45300 (1.84726 iter/s, 54.1341s/100 iter), loss = 3.09308
I0212 14:16:07.813581 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.18506 (* 1 = 3.18506 loss)
I0212 14:16:07.813616 12354 sgd_solver.cpp:136] Iteration 45300, lr = 0.000150161, m = 0.9
I0212 14:17:02.989030 12354 solver.cpp:314] Iteration 45400 (1.81246 iter/s, 55.1736s/100 iter), loss = 3.06251
I0212 14:17:02.989202 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.04819 (* 1 = 3.04819 loss)
I0212 14:17:02.989233 12354 sgd_solver.cpp:136] Iteration 45400, lr = 0.000149359, m = 0.9
I0212 14:17:57.779217 12354 solver.cpp:314] Iteration 45500 (1.82521 iter/s, 54.7882s/100 iter), loss = 2.9246
I0212 14:17:57.779392 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.32058 (* 1 = 2.32058 loss)
I0212 14:17:57.779430 12354 sgd_solver.cpp:136] Iteration 45500, lr = 0.000148559, m = 0.9
I0212 14:18:52.528949 12354 solver.cpp:314] Iteration 45600 (1.82656 iter/s, 54.7477s/100 iter), loss = 2.79622
I0212 14:18:52.529054 12354 solver.cpp:336]     Train net output #0: mbox_loss = 1.6686 (* 1 = 1.6686 loss)
I0212 14:18:52.529074 12354 sgd_solver.cpp:136] Iteration 45600, lr = 0.000147763, m = 0.9
I0212 14:19:47.966977 12354 solver.cpp:314] Iteration 45700 (1.80388 iter/s, 55.436s/100 iter), loss = 3.02898
I0212 14:19:47.967110 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.13975 (* 1 = 3.13975 loss)
I0212 14:19:47.967126 12354 sgd_solver.cpp:136] Iteration 45700, lr = 0.000146971, m = 0.9
I0212 14:20:42.483502 12354 solver.cpp:314] Iteration 45800 (1.83437 iter/s, 54.5145s/100 iter), loss = 3.03915
I0212 14:20:42.483608 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.61599 (* 1 = 2.61599 loss)
I0212 14:20:42.483620 12354 sgd_solver.cpp:136] Iteration 45800, lr = 0.000146181, m = 0.9
I0212 14:21:37.752077 12354 solver.cpp:314] Iteration 45900 (1.80941 iter/s, 55.2666s/100 iter), loss = 3.05746
I0212 14:21:37.752185 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.81465 (* 1 = 2.81465 loss)
I0212 14:21:37.752202 12354 sgd_solver.cpp:136] Iteration 45900, lr = 0.000145394, m = 0.9
I0212 14:22:32.566725 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_46000.caffemodel
I0212 14:22:32.589239 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_46000.solverstate
I0212 14:22:32.602735 12354 solver.cpp:666] Iteration 46000, Testing net (#0)
I0212 14:23:21.921917 12354 solver.cpp:774] class AP 1: 0.392536
I0212 14:23:21.993636 12354 solver.cpp:774] class AP 2: 0.621393
I0212 14:23:22.006374 12354 solver.cpp:774] class AP 3: 0.632309
I0212 14:23:22.006392 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.548746
I0212 14:23:23.379824 12355 solver.cpp:774] class AP 1: 0.393625
I0212 14:23:23.440680 12355 solver.cpp:774] class AP 2: 0.626944
I0212 14:23:23.452584 12355 solver.cpp:774] class AP 3: 0.632085
I0212 14:23:23.452597 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.550884
I0212 14:23:23.452761 12354 solver.cpp:265] [MultiGPU] Tests completed in 50.8482s
I0212 14:23:24.027875 12354 solver.cpp:314] Iteration 46000 (0.940982 iter/s, 106.272s/100 iter), loss = 3.09808
I0212 14:23:24.027927 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.53311 (* 1 = 3.53311 loss)
I0212 14:23:24.027941 12354 sgd_solver.cpp:136] Iteration 46000, lr = 0.000144611, m = 0.9
I0212 14:24:19.254161 12354 solver.cpp:314] Iteration 46100 (1.8108 iter/s, 55.2243s/100 iter), loss = 2.71681
I0212 14:24:19.254405 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.03076 (* 1 = 3.03076 loss)
I0212 14:24:19.254442 12354 sgd_solver.cpp:136] Iteration 46100, lr = 0.000143831, m = 0.9
I0212 14:25:14.571357 12354 solver.cpp:314] Iteration 46200 (1.80782 iter/s, 55.3152s/100 iter), loss = 2.99816
I0212 14:25:14.572113 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.12156 (* 1 = 3.12156 loss)
I0212 14:25:14.572149 12354 sgd_solver.cpp:136] Iteration 46200, lr = 0.000143054, m = 0.9
I0212 14:26:09.434355 12354 solver.cpp:314] Iteration 46300 (1.82279 iter/s, 54.861s/100 iter), loss = 3.02829
I0212 14:26:09.434510 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.12879 (* 1 = 2.12879 loss)
I0212 14:26:09.434526 12354 sgd_solver.cpp:136] Iteration 46300, lr = 0.00014228, m = 0.9
I0212 14:27:04.853693 12354 solver.cpp:314] Iteration 46400 (1.80449 iter/s, 55.4173s/100 iter), loss = 3.08834
I0212 14:27:04.853806 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.49047 (* 1 = 2.49047 loss)
I0212 14:27:04.853821 12354 sgd_solver.cpp:136] Iteration 46400, lr = 0.00014151, m = 0.9
I0212 14:28:00.517820 12354 solver.cpp:314] Iteration 46500 (1.79655 iter/s, 55.6621s/100 iter), loss = 2.92096
I0212 14:28:00.517992 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.76378 (* 1 = 2.76378 loss)
I0212 14:28:00.518035 12354 sgd_solver.cpp:136] Iteration 46500, lr = 0.000140742, m = 0.9
I0212 14:28:55.903834 12354 solver.cpp:314] Iteration 46600 (1.80558 iter/s, 55.384s/100 iter), loss = 2.90402
I0212 14:28:55.903954 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.8582 (* 1 = 2.8582 loss)
I0212 14:28:55.903973 12354 sgd_solver.cpp:136] Iteration 46600, lr = 0.000139978, m = 0.9
I0212 14:29:51.529866 12354 solver.cpp:314] Iteration 46700 (1.79778 iter/s, 55.624s/100 iter), loss = 3.18249
I0212 14:29:51.529958 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.29563 (* 1 = 3.29563 loss)
I0212 14:29:51.529971 12354 sgd_solver.cpp:136] Iteration 46700, lr = 0.000139217, m = 0.9
I0212 14:30:47.653134 12354 solver.cpp:314] Iteration 46800 (1.78186 iter/s, 56.1212s/100 iter), loss = 3.00516
I0212 14:30:47.653247 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.16842 (* 1 = 2.16842 loss)
I0212 14:30:47.653266 12354 sgd_solver.cpp:136] Iteration 46800, lr = 0.000138458, m = 0.9
I0212 14:31:43.174438 12354 solver.cpp:314] Iteration 46900 (1.80118 iter/s, 55.5193s/100 iter), loss = 3.1128
I0212 14:31:43.174646 12354 solver.cpp:336]     Train net output #0: mbox_loss = 5.00642 (* 1 = 5.00642 loss)
I0212 14:31:43.174661 12354 sgd_solver.cpp:136] Iteration 46900, lr = 0.000137703, m = 0.9
I0212 14:32:38.145146 12354 solver.cpp:314] Iteration 47000 (1.81922 iter/s, 54.9687s/100 iter), loss = 2.9352
I0212 14:32:38.145267 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.07298 (* 1 = 2.07298 loss)
I0212 14:32:38.145283 12354 sgd_solver.cpp:136] Iteration 47000, lr = 0.000136951, m = 0.9
I0212 14:33:33.031221 12354 solver.cpp:314] Iteration 47100 (1.82202 iter/s, 54.8841s/100 iter), loss = 3.04755
I0212 14:33:33.031348 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.19134 (* 1 = 4.19134 loss)
I0212 14:33:33.031366 12354 sgd_solver.cpp:136] Iteration 47100, lr = 0.000136202, m = 0.9
I0212 14:34:27.173306 12354 solver.cpp:314] Iteration 47200 (1.84706 iter/s, 54.1401s/100 iter), loss = 2.73452
I0212 14:34:27.173457 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.23304 (* 1 = 2.23304 loss)
I0212 14:34:27.173475 12354 sgd_solver.cpp:136] Iteration 47200, lr = 0.000135457, m = 0.9
I0212 14:35:21.863620 12354 solver.cpp:314] Iteration 47300 (1.82854 iter/s, 54.6883s/100 iter), loss = 2.94178
I0212 14:35:21.863729 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.69622 (* 1 = 2.69622 loss)
I0212 14:35:21.863745 12354 sgd_solver.cpp:136] Iteration 47300, lr = 0.000134714, m = 0.9
I0212 14:36:17.424386 12354 solver.cpp:314] Iteration 47400 (1.7999 iter/s, 55.5587s/100 iter), loss = 2.84178
I0212 14:36:17.424484 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.3074 (* 1 = 2.3074 loss)
I0212 14:36:17.424494 12354 sgd_solver.cpp:136] Iteration 47400, lr = 0.000133974, m = 0.9
I0212 14:37:13.386589 12354 solver.cpp:314] Iteration 47500 (1.78699 iter/s, 55.9602s/100 iter), loss = 3.13274
I0212 14:37:13.386765 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.56832 (* 1 = 2.56832 loss)
I0212 14:37:13.386799 12354 sgd_solver.cpp:136] Iteration 47500, lr = 0.000133238, m = 0.9
I0212 14:38:08.921156 12354 solver.cpp:314] Iteration 47600 (1.80075 iter/s, 55.5325s/100 iter), loss = 2.94734
I0212 14:38:08.921284 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.24911 (* 1 = 2.24911 loss)
I0212 14:38:08.921494 12354 sgd_solver.cpp:136] Iteration 47600, lr = 0.000132504, m = 0.9
I0212 14:39:04.332320 12354 solver.cpp:314] Iteration 47700 (1.80476 iter/s, 55.4091s/100 iter), loss = 2.99773
I0212 14:39:04.332450 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.53058 (* 1 = 3.53058 loss)
I0212 14:39:04.332466 12354 sgd_solver.cpp:136] Iteration 47700, lr = 0.000131774, m = 0.9
I0212 14:39:59.000131 12354 solver.cpp:314] Iteration 47800 (1.8293 iter/s, 54.6658s/100 iter), loss = 2.93341
I0212 14:39:59.000275 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.45753 (* 1 = 2.45753 loss)
I0212 14:39:59.000294 12354 sgd_solver.cpp:136] Iteration 47800, lr = 0.000131046, m = 0.9
I0212 14:40:54.573796 12354 solver.cpp:314] Iteration 47900 (1.79948 iter/s, 55.5716s/100 iter), loss = 2.85463
I0212 14:40:54.573916 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.8056 (* 1 = 2.8056 loss)
I0212 14:40:54.573930 12354 sgd_solver.cpp:136] Iteration 47900, lr = 0.000130321, m = 0.9
I0212 14:41:48.920353 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_48000.caffemodel
I0212 14:41:48.944561 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_48000.solverstate
I0212 14:41:48.958832 12354 solver.cpp:666] Iteration 48000, Testing net (#0)
I0212 14:42:38.200543 12330 data_reader.cpp:305] Starting prefetch of epoch 2
I0212 14:42:38.769132 12355 solver.cpp:774] class AP 1: 0.388945
I0212 14:42:38.839131 12355 solver.cpp:774] class AP 2: 0.63066
I0212 14:42:38.850693 12355 solver.cpp:774] class AP 3: 0.633972
I0212 14:42:38.850718 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.551192
I0212 14:42:39.715559 12354 solver.cpp:774] class AP 1: 0.37166
I0212 14:42:39.782457 12354 solver.cpp:774] class AP 2: 0.616982
I0212 14:42:39.793288 12354 solver.cpp:774] class AP 3: 0.628984
I0212 14:42:39.793299 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.539208
I0212 14:42:39.793334 12354 solver.cpp:265] [MultiGPU] Tests completed in 50.8327s
I0212 14:42:40.137351 12354 solver.cpp:314] Iteration 48000 (0.947331 iter/s, 105.56s/100 iter), loss = 2.73796
I0212 14:42:40.137461 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.08192 (* 1 = 3.08192 loss)
I0212 14:42:40.137497 12354 sgd_solver.cpp:136] Iteration 48000, lr = 0.0001296, m = 0.9
I0212 14:43:35.138522 12354 solver.cpp:314] Iteration 48100 (1.81821 iter/s, 54.9992s/100 iter), loss = 3.06258
I0212 14:43:35.138695 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.66622 (* 1 = 2.66622 loss)
I0212 14:43:35.138711 12354 sgd_solver.cpp:136] Iteration 48100, lr = 0.000128881, m = 0.9
I0212 14:44:30.955205 12354 solver.cpp:314] Iteration 48200 (1.79164 iter/s, 55.8147s/100 iter), loss = 3.07287
I0212 14:44:30.955332 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.16557 (* 1 = 3.16557 loss)
I0212 14:44:30.955346 12354 sgd_solver.cpp:136] Iteration 48200, lr = 0.000128166, m = 0.9
I0212 14:45:26.555727 12354 solver.cpp:314] Iteration 48300 (1.79861 iter/s, 55.5985s/100 iter), loss = 3.02321
I0212 14:45:26.555825 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.58461 (* 1 = 2.58461 loss)
I0212 14:45:26.555840 12354 sgd_solver.cpp:136] Iteration 48300, lr = 0.000127453, m = 0.9
I0212 14:46:21.854959 12354 solver.cpp:314] Iteration 48400 (1.80841 iter/s, 55.2972s/100 iter), loss = 2.88958
I0212 14:46:21.855285 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.98981 (* 1 = 2.98981 loss)
I0212 14:46:21.855424 12354 sgd_solver.cpp:136] Iteration 48400, lr = 0.000126744, m = 0.9
I0212 14:47:17.327491 12354 solver.cpp:314] Iteration 48500 (1.80276 iter/s, 55.4705s/100 iter), loss = 2.92214
I0212 14:47:17.327775 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.47437 (* 1 = 3.47437 loss)
I0212 14:47:17.327837 12354 sgd_solver.cpp:136] Iteration 48500, lr = 0.000126037, m = 0.9
I0212 14:48:12.380301 12354 solver.cpp:314] Iteration 48600 (1.8165 iter/s, 55.0508s/100 iter), loss = 2.86018
I0212 14:48:12.380405 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.84502 (* 1 = 2.84502 loss)
I0212 14:48:12.380568 12354 sgd_solver.cpp:136] Iteration 48600, lr = 0.000125334, m = 0.9
I0212 14:49:07.240957 12354 solver.cpp:314] Iteration 48700 (1.82287 iter/s, 54.8587s/100 iter), loss = 2.98382
I0212 14:49:07.241092 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.66432 (* 1 = 2.66432 loss)
I0212 14:49:07.241111 12354 sgd_solver.cpp:136] Iteration 48700, lr = 0.000124633, m = 0.9
I0212 14:50:01.974584 12354 solver.cpp:314] Iteration 48800 (1.8271 iter/s, 54.7316s/100 iter), loss = 2.8637
I0212 14:50:01.975435 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.19507 (* 1 = 2.19507 loss)
I0212 14:50:01.975564 12354 sgd_solver.cpp:136] Iteration 48800, lr = 0.000123935, m = 0.9
I0212 14:50:57.836683 12354 solver.cpp:314] Iteration 48900 (1.79019 iter/s, 55.8601s/100 iter), loss = 2.90711
I0212 14:50:57.836793 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.42307 (* 1 = 2.42307 loss)
I0212 14:50:57.836804 12354 sgd_solver.cpp:136] Iteration 48900, lr = 0.00012324, m = 0.9
I0212 14:51:54.265151 12354 solver.cpp:314] Iteration 49000 (1.77222 iter/s, 56.4264s/100 iter), loss = 2.80123
I0212 14:51:54.265278 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.18259 (* 1 = 2.18259 loss)
I0212 14:51:54.265293 12354 sgd_solver.cpp:136] Iteration 49000, lr = 0.000122549, m = 0.9
I0212 14:52:48.968114 12354 solver.cpp:314] Iteration 49100 (1.82812 iter/s, 54.701s/100 iter), loss = 2.96906
I0212 14:52:48.968219 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.91288 (* 1 = 2.91288 loss)
I0212 14:52:48.968237 12354 sgd_solver.cpp:136] Iteration 49100, lr = 0.00012186, m = 0.9
I0212 14:53:45.221115 12354 solver.cpp:314] Iteration 49200 (1.77775 iter/s, 56.251s/100 iter), loss = 2.84966
I0212 14:53:45.221236 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.81792 (* 1 = 2.81792 loss)
I0212 14:53:45.221256 12354 sgd_solver.cpp:136] Iteration 49200, lr = 0.000121174, m = 0.9
I0212 14:54:41.041442 12354 solver.cpp:314] Iteration 49300 (1.79153 iter/s, 55.8183s/100 iter), loss = 2.97054
I0212 14:54:41.041607 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.14808 (* 1 = 4.14808 loss)
I0212 14:54:41.041625 12354 sgd_solver.cpp:136] Iteration 49300, lr = 0.00012049, m = 0.9
I0212 14:55:36.286170 12354 solver.cpp:314] Iteration 49400 (1.81019 iter/s, 55.2427s/100 iter), loss = 3.11574
I0212 14:55:36.294209 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.28465 (* 1 = 3.28465 loss)
I0212 14:55:36.294260 12354 sgd_solver.cpp:136] Iteration 49400, lr = 0.00011981, m = 0.9
I0212 14:56:31.842630 12354 solver.cpp:314] Iteration 49500 (1.80004 iter/s, 55.5544s/100 iter), loss = 2.818
I0212 14:56:31.842749 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.57463 (* 1 = 2.57463 loss)
I0212 14:56:31.842763 12354 sgd_solver.cpp:136] Iteration 49500, lr = 0.000119133, m = 0.9
I0212 14:57:26.742557 12354 solver.cpp:314] Iteration 49600 (1.82156 iter/s, 54.8979s/100 iter), loss = 2.94912
I0212 14:57:26.743691 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.65991 (* 1 = 3.65991 loss)
I0212 14:57:26.743710 12354 sgd_solver.cpp:136] Iteration 49600, lr = 0.000118458, m = 0.9
I0212 14:58:21.941787 12354 solver.cpp:314] Iteration 49700 (1.81169 iter/s, 55.1972s/100 iter), loss = 2.84434
I0212 14:58:21.941918 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.36206 (* 1 = 3.36206 loss)
I0212 14:58:21.941934 12354 sgd_solver.cpp:136] Iteration 49700, lr = 0.000117787, m = 0.9
I0212 14:59:17.571501 12354 solver.cpp:314] Iteration 49800 (1.79767 iter/s, 55.6277s/100 iter), loss = 2.86068
I0212 14:59:17.571635 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.79339 (* 1 = 2.79339 loss)
I0212 14:59:17.571648 12354 sgd_solver.cpp:136] Iteration 49800, lr = 0.000117118, m = 0.9
I0212 15:00:12.725698 12354 solver.cpp:314] Iteration 49900 (1.81316 iter/s, 55.1522s/100 iter), loss = 2.85128
I0212 15:00:12.725836 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.54469 (* 1 = 2.54469 loss)
I0212 15:00:12.725853 12354 sgd_solver.cpp:136] Iteration 49900, lr = 0.000116452, m = 0.9
I0212 15:01:06.997440 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_50000.caffemodel
I0212 15:01:07.032891 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_50000.solverstate
I0212 15:01:07.046648 12354 solver.cpp:666] Iteration 50000, Testing net (#0)
I0212 15:01:56.613998 12355 solver.cpp:774] class AP 1: 0.393864
I0212 15:01:56.669863 12355 solver.cpp:774] class AP 2: 0.644272
I0212 15:01:56.679172 12355 solver.cpp:774] class AP 3: 0.634086
I0212 15:01:56.679213 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.557408
I0212 15:01:57.285477 12354 solver.cpp:774] class AP 1: 0.36984
I0212 15:01:57.358264 12354 solver.cpp:774] class AP 2: 0.61899
I0212 15:01:57.369024 12354 solver.cpp:774] class AP 3: 0.631447
I0212 15:01:57.369040 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.540092
I0212 15:01:57.369086 12354 solver.cpp:265] [MultiGPU] Tests completed in 50.3206s
I0212 15:01:57.770175 12354 solver.cpp:314] Iteration 50000 (0.952012 iter/s, 105.041s/100 iter), loss = 3.16652
I0212 15:01:57.770233 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.40367 (* 1 = 3.40367 loss)
I0212 15:01:57.770249 12354 sgd_solver.cpp:136] Iteration 50000, lr = 0.000115789, m = 0.9
I0212 15:02:52.057116 12354 solver.cpp:314] Iteration 50100 (1.84213 iter/s, 54.285s/100 iter), loss = 3.11232
I0212 15:02:52.057256 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.05185 (* 1 = 4.05185 loss)
I0212 15:02:52.057274 12354 sgd_solver.cpp:136] Iteration 50100, lr = 0.000115129, m = 0.9
I0212 15:03:47.848737 12354 solver.cpp:314] Iteration 50200 (1.79245 iter/s, 55.7896s/100 iter), loss = 2.84589
I0212 15:03:47.848904 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.71805 (* 1 = 2.71805 loss)
I0212 15:03:47.848920 12354 sgd_solver.cpp:136] Iteration 50200, lr = 0.000114471, m = 0.9
I0212 15:04:42.494935 12354 solver.cpp:314] Iteration 50300 (1.83002 iter/s, 54.6442s/100 iter), loss = 3.01309
I0212 15:04:42.495097 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.31952 (* 1 = 2.31952 loss)
I0212 15:04:42.495115 12354 sgd_solver.cpp:136] Iteration 50300, lr = 0.000113817, m = 0.9
I0212 15:05:37.368870 12354 solver.cpp:314] Iteration 50400 (1.82243 iter/s, 54.8719s/100 iter), loss = 2.81798
I0212 15:05:37.368997 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.55238 (* 1 = 3.55238 loss)
I0212 15:05:37.369223 12354 sgd_solver.cpp:136] Iteration 50400, lr = 0.000113165, m = 0.9
I0212 15:06:32.450945 12354 solver.cpp:314] Iteration 50500 (1.81554 iter/s, 55.0801s/100 iter), loss = 3.03217
I0212 15:06:32.451066 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.40243 (* 1 = 2.40243 loss)
I0212 15:06:32.451084 12354 sgd_solver.cpp:136] Iteration 50500, lr = 0.000112516, m = 0.9
I0212 15:07:28.149374 12354 solver.cpp:314] Iteration 50600 (1.79545 iter/s, 55.6964s/100 iter), loss = 3.1715
I0212 15:07:28.149502 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.99719 (* 1 = 2.99719 loss)
I0212 15:07:28.149518 12354 sgd_solver.cpp:136] Iteration 50600, lr = 0.00011187, m = 0.9
I0212 15:08:23.787232 12354 solver.cpp:314] Iteration 50700 (1.7974 iter/s, 55.6358s/100 iter), loss = 3.04701
I0212 15:08:23.787364 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.5381 (* 1 = 2.5381 loss)
I0212 15:08:23.787380 12354 sgd_solver.cpp:136] Iteration 50700, lr = 0.000111226, m = 0.9
I0212 15:09:18.369407 12354 solver.cpp:314] Iteration 50800 (1.83217 iter/s, 54.5802s/100 iter), loss = 2.90545
I0212 15:09:18.369523 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.11892 (* 1 = 4.11892 loss)
I0212 15:09:18.369536 12354 sgd_solver.cpp:136] Iteration 50800, lr = 0.000110586, m = 0.9
I0212 15:10:13.654979 12354 solver.cpp:314] Iteration 50900 (1.80886 iter/s, 55.2836s/100 iter), loss = 2.89429
I0212 15:10:13.655107 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.69222 (* 1 = 2.69222 loss)
I0212 15:10:13.655122 12354 sgd_solver.cpp:136] Iteration 50900, lr = 0.000109948, m = 0.9
I0212 15:11:09.440968 12354 solver.cpp:314] Iteration 51000 (1.79263 iter/s, 55.784s/100 iter), loss = 2.92018
I0212 15:11:09.441102 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.61421 (* 1 = 2.61421 loss)
I0212 15:11:09.441119 12354 sgd_solver.cpp:136] Iteration 51000, lr = 0.000109313, m = 0.9
I0212 15:11:16.415045 12274 data_reader.cpp:305] Starting prefetch of epoch 10
I0212 15:12:04.146556 12354 solver.cpp:314] Iteration 51100 (1.82803 iter/s, 54.7036s/100 iter), loss = 3.01464
I0212 15:12:04.146669 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.06756 (* 1 = 3.06756 loss)
I0212 15:12:04.146688 12354 sgd_solver.cpp:136] Iteration 51100, lr = 0.000108681, m = 0.9
I0212 15:12:59.009546 12354 solver.cpp:314] Iteration 51200 (1.82279 iter/s, 54.861s/100 iter), loss = 2.79732
I0212 15:12:59.009709 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.64635 (* 1 = 2.64635 loss)
I0212 15:12:59.009745 12354 sgd_solver.cpp:136] Iteration 51200, lr = 0.000108051, m = 0.9
I0212 15:13:54.379276 12354 solver.cpp:314] Iteration 51300 (1.80611 iter/s, 55.3677s/100 iter), loss = 2.95443
I0212 15:13:54.379418 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.47988 (* 1 = 2.47988 loss)
I0212 15:13:54.379432 12354 sgd_solver.cpp:136] Iteration 51300, lr = 0.000107424, m = 0.9
I0212 15:14:49.888216 12354 solver.cpp:314] Iteration 51400 (1.80158 iter/s, 55.5069s/100 iter), loss = 2.80009
I0212 15:14:49.888326 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.43701 (* 1 = 2.43701 loss)
I0212 15:14:49.888344 12354 sgd_solver.cpp:136] Iteration 51400, lr = 0.0001068, m = 0.9
I0212 15:15:45.815326 12354 solver.cpp:314] Iteration 51500 (1.78811 iter/s, 55.9251s/100 iter), loss = 2.86028
I0212 15:15:45.815484 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.5575 (* 1 = 2.5575 loss)
I0212 15:15:45.815500 12354 sgd_solver.cpp:136] Iteration 51500, lr = 0.000106179, m = 0.9
I0212 15:16:41.435798 12354 solver.cpp:314] Iteration 51600 (1.79796 iter/s, 55.6184s/100 iter), loss = 2.904
I0212 15:16:41.435935 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.65884 (* 1 = 2.65884 loss)
I0212 15:16:41.435953 12354 sgd_solver.cpp:136] Iteration 51600, lr = 0.00010556, m = 0.9
I0212 15:17:37.405515 12354 solver.cpp:314] Iteration 51700 (1.78675 iter/s, 55.9677s/100 iter), loss = 2.7855
I0212 15:17:37.405633 12354 solver.cpp:336]     Train net output #0: mbox_loss = 1.92597 (* 1 = 1.92597 loss)
I0212 15:17:37.405648 12354 sgd_solver.cpp:136] Iteration 51700, lr = 0.000104944, m = 0.9
I0212 15:18:32.566270 12354 solver.cpp:314] Iteration 51800 (1.81295 iter/s, 55.1587s/100 iter), loss = 2.73785
I0212 15:18:32.566380 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.90511 (* 1 = 3.90511 loss)
I0212 15:18:32.566395 12354 sgd_solver.cpp:136] Iteration 51800, lr = 0.000104331, m = 0.9
I0212 15:19:27.968395 12354 solver.cpp:314] Iteration 51900 (1.80505 iter/s, 55.4001s/100 iter), loss = 3.16662
I0212 15:19:27.968505 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.2094 (* 1 = 3.2094 loss)
I0212 15:19:27.968524 12354 sgd_solver.cpp:136] Iteration 51900, lr = 0.00010372, m = 0.9
I0212 15:20:22.432965 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_52000.caffemodel
I0212 15:20:22.457078 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_52000.solverstate
I0212 15:20:22.470794 12354 solver.cpp:666] Iteration 52000, Testing net (#0)
I0212 15:21:14.205741 12354 solver.cpp:774] class AP 1: 0.370364
I0212 15:21:14.283476 12354 solver.cpp:774] class AP 2: 0.618732
I0212 15:21:14.295209 12354 solver.cpp:774] class AP 3: 0.626683
I0212 15:21:14.295228 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.538593
I0212 15:21:15.046602 12355 solver.cpp:774] class AP 1: 0.375531
I0212 15:21:15.118607 12355 solver.cpp:774] class AP 2: 0.626617
I0212 15:21:15.130112 12355 solver.cpp:774] class AP 3: 0.638902
I0212 15:21:15.130125 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.547017
I0212 15:21:15.130231 12354 solver.cpp:265] [MultiGPU] Tests completed in 52.6575s
I0212 15:21:15.583889 12354 solver.cpp:314] Iteration 52000 (0.929268 iter/s, 107.612s/100 iter), loss = 2.99574
I0212 15:21:15.583936 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.40944 (* 1 = 3.40944 loss)
I0212 15:21:15.583945 12354 sgd_solver.cpp:136] Iteration 52000, lr = 0.000103112, m = 0.9
I0212 15:22:10.283489 12354 solver.cpp:314] Iteration 52100 (1.82823 iter/s, 54.6976s/100 iter), loss = 3.01673
I0212 15:22:10.283617 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.30072 (* 1 = 2.30072 loss)
I0212 15:22:10.283632 12354 sgd_solver.cpp:136] Iteration 52100, lr = 0.000102507, m = 0.9
I0212 15:23:04.300056 12354 solver.cpp:314] Iteration 52200 (1.85135 iter/s, 54.0146s/100 iter), loss = 2.84254
I0212 15:23:04.300180 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.39531 (* 1 = 2.39531 loss)
I0212 15:23:04.300195 12354 sgd_solver.cpp:136] Iteration 52200, lr = 0.000101905, m = 0.9
I0212 15:24:00.177789 12354 solver.cpp:314] Iteration 52300 (1.78969 iter/s, 55.8757s/100 iter), loss = 2.96463
I0212 15:24:00.177912 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.77095 (* 1 = 3.77095 loss)
I0212 15:24:00.177927 12354 sgd_solver.cpp:136] Iteration 52300, lr = 0.000101305, m = 0.9
I0212 15:24:54.390875 12354 solver.cpp:314] Iteration 52400 (1.84464 iter/s, 54.2111s/100 iter), loss = 2.85484
I0212 15:24:54.391032 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.12555 (* 1 = 3.12555 loss)
I0212 15:24:54.391049 12354 sgd_solver.cpp:136] Iteration 52400, lr = 0.000100707, m = 0.9
I0212 15:25:49.620035 12354 solver.cpp:314] Iteration 52500 (1.8107 iter/s, 55.2272s/100 iter), loss = 3.0032
I0212 15:25:49.620169 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.26922 (* 1 = 3.26922 loss)
I0212 15:25:49.620301 12354 sgd_solver.cpp:136] Iteration 52500, lr = 0.000100113, m = 0.9
I0212 15:26:44.767518 12354 solver.cpp:314] Iteration 52600 (1.81339 iter/s, 55.1455s/100 iter), loss = 2.79779
I0212 15:26:44.767627 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.4454 (* 1 = 2.4454 loss)
I0212 15:26:44.767642 12354 sgd_solver.cpp:136] Iteration 52600, lr = 9.9521e-05, m = 0.9
I0212 15:27:39.886411 12354 solver.cpp:314] Iteration 52700 (1.81433 iter/s, 55.1169s/100 iter), loss = 2.89459
I0212 15:27:39.886634 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.05113 (* 1 = 3.05113 loss)
I0212 15:27:39.886672 12354 sgd_solver.cpp:136] Iteration 52700, lr = 9.89317e-05, m = 0.9
I0212 15:28:35.177245 12354 solver.cpp:314] Iteration 52800 (1.80868 iter/s, 55.2888s/100 iter), loss = 2.72844
I0212 15:28:35.177664 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.81983 (* 1 = 2.81983 loss)
I0212 15:28:35.177680 12354 sgd_solver.cpp:136] Iteration 52800, lr = 9.8345e-05, m = 0.9
I0212 15:29:30.686377 12354 solver.cpp:314] Iteration 52900 (1.80157 iter/s, 55.5071s/100 iter), loss = 3.07228
I0212 15:29:30.686508 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.42387 (* 1 = 2.42387 loss)
I0212 15:29:30.686527 12354 sgd_solver.cpp:136] Iteration 52900, lr = 9.77609e-05, m = 0.9
I0212 15:30:26.162868 12354 solver.cpp:314] Iteration 53000 (1.80263 iter/s, 55.4745s/100 iter), loss = 3.06219
I0212 15:30:26.162992 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.06855 (* 1 = 2.06855 loss)
I0212 15:30:26.163009 12354 sgd_solver.cpp:136] Iteration 53000, lr = 9.71794e-05, m = 0.9
I0212 15:31:21.389230 12354 solver.cpp:314] Iteration 53100 (1.8108 iter/s, 55.2244s/100 iter), loss = 2.92236
I0212 15:31:21.389400 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.21081 (* 1 = 2.21081 loss)
I0212 15:31:21.389441 12354 sgd_solver.cpp:136] Iteration 53100, lr = 9.66005e-05, m = 0.9
I0212 15:32:16.904790 12354 solver.cpp:314] Iteration 53200 (1.80136 iter/s, 55.5135s/100 iter), loss = 2.96505
I0212 15:32:16.904914 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.13089 (* 1 = 2.13089 loss)
I0212 15:32:16.904932 12354 sgd_solver.cpp:136] Iteration 53200, lr = 9.60242e-05, m = 0.9
I0212 15:33:12.504307 12354 solver.cpp:314] Iteration 53300 (1.79864 iter/s, 55.5975s/100 iter), loss = 3.09011
I0212 15:33:12.504432 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.69172 (* 1 = 2.69172 loss)
I0212 15:33:12.504447 12354 sgd_solver.cpp:136] Iteration 53300, lr = 9.54505e-05, m = 0.9
I0212 15:34:08.783993 12354 solver.cpp:314] Iteration 53400 (1.7769 iter/s, 56.2776s/100 iter), loss = 3.20982
I0212 15:34:08.784116 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.00723 (* 1 = 3.00723 loss)
I0212 15:34:08.784132 12354 sgd_solver.cpp:136] Iteration 53400, lr = 9.48794e-05, m = 0.9
I0212 15:35:03.933804 12354 solver.cpp:314] Iteration 53500 (1.81331 iter/s, 55.1478s/100 iter), loss = 3.1567
I0212 15:35:03.933923 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.8161 (* 1 = 3.8161 loss)
I0212 15:35:03.933940 12354 sgd_solver.cpp:136] Iteration 53500, lr = 9.43108e-05, m = 0.9
I0212 15:35:59.555338 12354 solver.cpp:314] Iteration 53600 (1.79793 iter/s, 55.6195s/100 iter), loss = 3.10971
I0212 15:35:59.555510 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.8078 (* 1 = 2.8078 loss)
I0212 15:35:59.555542 12354 sgd_solver.cpp:136] Iteration 53600, lr = 9.37448e-05, m = 0.9
I0212 15:36:54.965694 12354 solver.cpp:314] Iteration 53700 (1.80478 iter/s, 55.4083s/100 iter), loss = 3.16755
I0212 15:36:54.966152 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.35738 (* 1 = 2.35738 loss)
I0212 15:36:54.966289 12354 sgd_solver.cpp:136] Iteration 53700, lr = 9.31814e-05, m = 0.9
I0212 15:37:50.255137 12354 solver.cpp:314] Iteration 53800 (1.80873 iter/s, 55.2874s/100 iter), loss = 3.22734
I0212 15:37:50.255247 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.37062 (* 1 = 3.37062 loss)
I0212 15:37:50.255265 12354 sgd_solver.cpp:136] Iteration 53800, lr = 9.26205e-05, m = 0.9
I0212 15:38:45.606019 12354 solver.cpp:314] Iteration 53900 (1.80672 iter/s, 55.3489s/100 iter), loss = 2.90895
I0212 15:38:45.606526 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.83417 (* 1 = 2.83417 loss)
I0212 15:38:45.606685 12354 sgd_solver.cpp:136] Iteration 53900, lr = 9.20621e-05, m = 0.9
I0212 15:39:40.870656 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_54000.caffemodel
I0212 15:39:40.893551 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_54000.solverstate
I0212 15:39:40.906641 12354 solver.cpp:666] Iteration 54000, Testing net (#0)
I0212 15:40:29.519465 12330 data_reader.cpp:305] Starting prefetch of epoch 3
I0212 15:40:30.039775 12355 solver.cpp:774] class AP 1: 0.3956
I0212 15:40:30.101235 12355 solver.cpp:774] class AP 2: 0.641474
I0212 15:40:30.114070 12355 solver.cpp:774] class AP 3: 0.657488
I0212 15:40:30.114105 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.564854
I0212 15:40:31.286625 12354 solver.cpp:774] class AP 1: 0.374204
I0212 15:40:31.361387 12354 solver.cpp:774] class AP 2: 0.620045
I0212 15:40:31.373924 12354 solver.cpp:774] class AP 3: 0.624059
I0212 15:40:31.373955 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.539436
I0212 15:40:31.374007 12354 solver.cpp:265] [MultiGPU] Tests completed in 50.4655s
I0212 15:40:31.862346 12354 solver.cpp:314] Iteration 54000 (0.941155 iter/s, 106.252s/100 iter), loss = 2.83728
I0212 15:40:31.862395 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.80952 (* 1 = 2.80952 loss)
I0212 15:40:31.862409 12354 sgd_solver.cpp:136] Iteration 54000, lr = 9.15063e-05, m = 0.9
I0212 15:41:26.683441 12354 solver.cpp:314] Iteration 54100 (1.82418 iter/s, 54.8191s/100 iter), loss = 2.9475
I0212 15:41:26.683568 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.27599 (* 1 = 3.27599 loss)
I0212 15:41:26.683676 12354 sgd_solver.cpp:136] Iteration 54100, lr = 9.09529e-05, m = 0.9
I0212 15:42:20.953593 12354 solver.cpp:314] Iteration 54200 (1.8427 iter/s, 54.2682s/100 iter), loss = 2.90492
I0212 15:42:20.953723 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.15791 (* 1 = 3.15791 loss)
I0212 15:42:20.953738 12354 sgd_solver.cpp:136] Iteration 54200, lr = 9.04021e-05, m = 0.9
I0212 15:43:16.895071 12354 solver.cpp:314] Iteration 54300 (1.78765 iter/s, 55.9394s/100 iter), loss = 3.11489
I0212 15:43:16.895175 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.13405 (* 1 = 3.13405 loss)
I0212 15:43:16.895191 12354 sgd_solver.cpp:136] Iteration 54300, lr = 8.98538e-05, m = 0.9
I0212 15:44:12.213970 12354 solver.cpp:314] Iteration 54400 (1.80777 iter/s, 55.3169s/100 iter), loss = 2.83746
I0212 15:44:12.214087 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.44682 (* 1 = 2.44682 loss)
I0212 15:44:12.214123 12354 sgd_solver.cpp:136] Iteration 54400, lr = 8.9308e-05, m = 0.9
I0212 15:45:08.614425 12354 solver.cpp:314] Iteration 54500 (1.7731 iter/s, 56.3984s/100 iter), loss = 2.80748
I0212 15:45:08.614550 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.979 (* 1 = 2.979 loss)
I0212 15:45:08.614568 12354 sgd_solver.cpp:136] Iteration 54500, lr = 8.87647e-05, m = 0.9
I0212 15:46:03.418473 12354 solver.cpp:314] Iteration 54600 (1.82475 iter/s, 54.8021s/100 iter), loss = 2.88371
I0212 15:46:03.418630 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.56017 (* 1 = 2.56017 loss)
I0212 15:46:03.418646 12354 sgd_solver.cpp:136] Iteration 54600, lr = 8.82238e-05, m = 0.9
I0212 15:46:58.102773 12354 solver.cpp:314] Iteration 54700 (1.82874 iter/s, 54.6823s/100 iter), loss = 2.88739
I0212 15:46:58.102988 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.00712 (* 1 = 3.00712 loss)
I0212 15:46:58.103024 12354 sgd_solver.cpp:136] Iteration 54700, lr = 8.76855e-05, m = 0.9
I0212 15:47:53.042656 12354 solver.cpp:314] Iteration 54800 (1.82024 iter/s, 54.9379s/100 iter), loss = 2.84362
I0212 15:47:53.042834 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.28689 (* 1 = 3.28689 loss)
I0212 15:47:53.042867 12354 sgd_solver.cpp:136] Iteration 54800, lr = 8.71496e-05, m = 0.9
I0212 15:48:48.790202 12354 solver.cpp:314] Iteration 54900 (1.79387 iter/s, 55.7455s/100 iter), loss = 2.88226
I0212 15:48:48.790527 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.57187 (* 1 = 2.57187 loss)
I0212 15:48:48.790591 12354 sgd_solver.cpp:136] Iteration 54900, lr = 8.66162e-05, m = 0.9
I0212 15:49:44.494269 12354 solver.cpp:314] Iteration 55000 (1.79527 iter/s, 55.702s/100 iter), loss = 2.86368
I0212 15:49:44.494401 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.10203 (* 1 = 2.10203 loss)
I0212 15:49:44.494418 12354 sgd_solver.cpp:136] Iteration 55000, lr = 8.60852e-05, m = 0.9
I0212 15:50:40.059711 12354 solver.cpp:314] Iteration 55100 (1.79974 iter/s, 55.5634s/100 iter), loss = 2.95862
I0212 15:50:40.059839 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.83778 (* 1 = 2.83778 loss)
I0212 15:50:40.059850 12354 sgd_solver.cpp:136] Iteration 55100, lr = 8.55567e-05, m = 0.9
I0212 15:51:35.466418 12354 solver.cpp:314] Iteration 55200 (1.8049 iter/s, 55.4047s/100 iter), loss = 2.95393
I0212 15:51:35.466542 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.11439 (* 1 = 2.11439 loss)
I0212 15:51:35.466557 12354 sgd_solver.cpp:136] Iteration 55200, lr = 8.50305e-05, m = 0.9
I0212 15:52:32.022260 12354 solver.cpp:314] Iteration 55300 (1.76823 iter/s, 56.5538s/100 iter), loss = 2.99761
I0212 15:52:32.022387 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.91021 (* 1 = 2.91021 loss)
I0212 15:52:32.022400 12354 sgd_solver.cpp:136] Iteration 55300, lr = 8.45069e-05, m = 0.9
I0212 15:53:28.106159 12354 solver.cpp:314] Iteration 55400 (1.78311 iter/s, 56.0819s/100 iter), loss = 2.89336
I0212 15:53:28.106294 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.53969 (* 1 = 3.53969 loss)
I0212 15:53:28.106317 12354 sgd_solver.cpp:136] Iteration 55400, lr = 8.39856e-05, m = 0.9
I0212 15:54:23.595562 12354 solver.cpp:314] Iteration 55500 (1.80221 iter/s, 55.4874s/100 iter), loss = 3.02039
I0212 15:54:23.595695 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.55136 (* 1 = 2.55136 loss)
I0212 15:54:23.595710 12354 sgd_solver.cpp:136] Iteration 55500, lr = 8.34668e-05, m = 0.9
I0212 15:55:18.912101 12354 solver.cpp:314] Iteration 55600 (1.80784 iter/s, 55.3145s/100 iter), loss = 2.7969
I0212 15:55:18.912264 12354 solver.cpp:336]     Train net output #0: mbox_loss = 1.89038 (* 1 = 1.89038 loss)
I0212 15:55:18.912302 12354 sgd_solver.cpp:136] Iteration 55600, lr = 8.29504e-05, m = 0.9
I0212 15:56:13.801935 12354 solver.cpp:314] Iteration 55700 (1.8219 iter/s, 54.8878s/100 iter), loss = 2.84566
I0212 15:56:13.802058 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.58987 (* 1 = 2.58987 loss)
I0212 15:56:13.802073 12354 sgd_solver.cpp:136] Iteration 55700, lr = 8.24364e-05, m = 0.9
I0212 15:57:10.403867 12354 solver.cpp:314] Iteration 55800 (1.76679 iter/s, 56.5999s/100 iter), loss = 2.99192
I0212 15:57:10.403978 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.12515 (* 1 = 3.12515 loss)
I0212 15:57:10.403991 12354 sgd_solver.cpp:136] Iteration 55800, lr = 8.19247e-05, m = 0.9
I0212 15:58:06.085902 12354 solver.cpp:314] Iteration 55900 (1.79598 iter/s, 55.68s/100 iter), loss = 2.63346
I0212 15:58:06.086056 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.39582 (* 1 = 2.39582 loss)
I0212 15:58:06.086071 12354 sgd_solver.cpp:136] Iteration 55900, lr = 8.14155e-05, m = 0.9
I0212 15:59:01.207927 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_56000.caffemodel
I0212 15:59:01.231163 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_56000.solverstate
I0212 15:59:01.244267 12354 solver.cpp:666] Iteration 56000, Testing net (#0)
I0212 15:59:50.325851 12354 solver.cpp:774] class AP 1: 0.37676
I0212 15:59:50.397009 12354 solver.cpp:774] class AP 2: 0.625953
I0212 15:59:50.407222 12354 solver.cpp:774] class AP 3: 0.634257
I0212 15:59:50.407254 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.545657
I0212 15:59:53.443296 12355 solver.cpp:774] class AP 1: 0.400915
I0212 15:59:53.509632 12355 solver.cpp:774] class AP 2: 0.641872
I0212 15:59:53.519572 12355 solver.cpp:774] class AP 3: 0.638433
I0212 15:59:53.519587 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.560407
I0212 15:59:53.519713 12354 solver.cpp:265] [MultiGPU] Tests completed in 52.2735s
I0212 15:59:53.927048 12354 solver.cpp:314] Iteration 56000 (0.927324 iter/s, 107.837s/100 iter), loss = 2.9458
I0212 15:59:53.927099 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.00549 (* 1 = 3.00549 loss)
I0212 15:59:53.927112 12354 sgd_solver.cpp:136] Iteration 56000, lr = 8.09086e-05, m = 0.9
I0212 16:00:49.126168 12354 solver.cpp:314] Iteration 56100 (1.81169 iter/s, 55.1971s/100 iter), loss = 2.96098
I0212 16:00:49.126297 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.44439 (* 1 = 2.44439 loss)
I0212 16:00:49.126313 12354 sgd_solver.cpp:136] Iteration 56100, lr = 8.04042e-05, m = 0.9
I0212 16:01:45.498332 12354 solver.cpp:314] Iteration 56200 (1.77399 iter/s, 56.3701s/100 iter), loss = 2.88922
I0212 16:01:45.498466 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.61622 (* 1 = 2.61622 loss)
I0212 16:01:45.498481 12354 sgd_solver.cpp:136] Iteration 56200, lr = 7.9902e-05, m = 0.9
I0212 16:02:41.181658 12354 solver.cpp:314] Iteration 56300 (1.79594 iter/s, 55.6813s/100 iter), loss = 2.65883
I0212 16:02:41.181963 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.24987 (* 1 = 3.24987 loss)
I0212 16:02:41.182000 12354 sgd_solver.cpp:136] Iteration 56300, lr = 7.94023e-05, m = 0.9
I0212 16:03:36.934514 12354 solver.cpp:314] Iteration 56400 (1.7937 iter/s, 55.7508s/100 iter), loss = 2.98882
I0212 16:03:36.934638 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.6017 (* 1 = 3.6017 loss)
I0212 16:03:36.934653 12354 sgd_solver.cpp:136] Iteration 56400, lr = 7.89048e-05, m = 0.9
I0212 16:04:31.836597 12354 solver.cpp:314] Iteration 56500 (1.82149 iter/s, 54.9001s/100 iter), loss = 2.86644
I0212 16:04:31.836719 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.74727 (* 1 = 2.74727 loss)
I0212 16:04:31.836736 12354 sgd_solver.cpp:136] Iteration 56500, lr = 7.84097e-05, m = 0.9
I0212 16:05:28.253388 12354 solver.cpp:314] Iteration 56600 (1.77259 iter/s, 56.4147s/100 iter), loss = 3.00062
I0212 16:05:28.253536 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.0362 (* 1 = 2.0362 loss)
I0212 16:05:28.253556 12354 sgd_solver.cpp:136] Iteration 56600, lr = 7.7917e-05, m = 0.9
I0212 16:06:23.527107 12354 solver.cpp:314] Iteration 56700 (1.80924 iter/s, 55.2717s/100 iter), loss = 3.03758
I0212 16:06:23.527271 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.70984 (* 1 = 3.70984 loss)
I0212 16:06:23.527308 12354 sgd_solver.cpp:136] Iteration 56700, lr = 7.74266e-05, m = 0.9
I0212 16:07:18.374408 12354 solver.cpp:314] Iteration 56800 (1.82331 iter/s, 54.8453s/100 iter), loss = 2.89936
I0212 16:07:18.374557 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.0533 (* 1 = 2.0533 loss)
I0212 16:07:18.374573 12354 sgd_solver.cpp:136] Iteration 56800, lr = 7.69384e-05, m = 0.9
I0212 16:08:13.999188 12354 solver.cpp:314] Iteration 56900 (1.79783 iter/s, 55.6227s/100 iter), loss = 2.89297
I0212 16:08:13.999330 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.25269 (* 1 = 2.25269 loss)
I0212 16:08:13.999344 12354 sgd_solver.cpp:136] Iteration 56900, lr = 7.64527e-05, m = 0.9
I0212 16:08:26.050271 12274 data_reader.cpp:305] Starting prefetch of epoch 11
I0212 16:09:09.772552 12354 solver.cpp:314] Iteration 57000 (1.79304 iter/s, 55.7713s/100 iter), loss = 3.10107
I0212 16:09:09.772681 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.68861 (* 1 = 2.68861 loss)
I0212 16:09:09.772696 12354 sgd_solver.cpp:136] Iteration 57000, lr = 7.59691e-05, m = 0.9
I0212 16:10:04.606986 12354 solver.cpp:314] Iteration 57100 (1.82374 iter/s, 54.8324s/100 iter), loss = 2.72218
I0212 16:10:04.607106 12354 solver.cpp:336]     Train net output #0: mbox_loss = 1.91815 (* 1 = 1.91815 loss)
I0212 16:10:04.607321 12354 sgd_solver.cpp:136] Iteration 57100, lr = 7.5488e-05, m = 0.9
I0212 16:11:00.182643 12354 solver.cpp:314] Iteration 57200 (1.79941 iter/s, 55.5736s/100 iter), loss = 2.85426
I0212 16:11:00.182767 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.62249 (* 1 = 2.62249 loss)
I0212 16:11:00.182783 12354 sgd_solver.cpp:136] Iteration 57200, lr = 7.5009e-05, m = 0.9
I0212 16:11:55.315793 12354 solver.cpp:314] Iteration 57300 (1.81386 iter/s, 55.1311s/100 iter), loss = 3.07598
I0212 16:11:55.315896 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.68504 (* 1 = 2.68504 loss)
I0212 16:11:55.315912 12354 sgd_solver.cpp:136] Iteration 57300, lr = 7.45324e-05, m = 0.9
I0212 16:12:50.836522 12354 solver.cpp:314] Iteration 57400 (1.80119 iter/s, 55.5187s/100 iter), loss = 3.20999
I0212 16:12:50.836642 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.54162 (* 1 = 4.54162 loss)
I0212 16:12:50.836657 12354 sgd_solver.cpp:136] Iteration 57400, lr = 7.40581e-05, m = 0.9
I0212 16:13:46.642141 12354 solver.cpp:314] Iteration 57500 (1.792 iter/s, 55.8036s/100 iter), loss = 3.00352
I0212 16:13:46.642279 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.02629 (* 1 = 3.02629 loss)
I0212 16:13:46.642300 12354 sgd_solver.cpp:136] Iteration 57500, lr = 7.3586e-05, m = 0.9
I0212 16:14:53.359107 12354 solver.cpp:314] Iteration 57600 (1.49892 iter/s, 66.7145s/100 iter), loss = 3.04788
I0212 16:14:53.359256 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.31652 (* 1 = 3.31652 loss)
I0212 16:14:53.359272 12354 sgd_solver.cpp:136] Iteration 57600, lr = 7.31162e-05, m = 0.9
I0212 16:16:00.193444 12354 solver.cpp:314] Iteration 57700 (1.49629 iter/s, 66.8319s/100 iter), loss = 2.74113
I0212 16:16:00.193578 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.22225 (* 1 = 2.22225 loss)
I0212 16:16:00.193598 12354 sgd_solver.cpp:136] Iteration 57700, lr = 7.26486e-05, m = 0.9
I0212 16:17:06.250072 12354 solver.cpp:314] Iteration 57800 (1.51391 iter/s, 66.0542s/100 iter), loss = 2.95027
I0212 16:17:06.250258 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.57414 (* 1 = 2.57414 loss)
I0212 16:17:06.250272 12354 sgd_solver.cpp:136] Iteration 57800, lr = 7.21833e-05, m = 0.9
I0212 16:18:15.989470 12354 solver.cpp:314] Iteration 57900 (1.43396 iter/s, 69.7369s/100 iter), loss = 2.92675
I0212 16:18:15.989595 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.48837 (* 1 = 2.48837 loss)
I0212 16:18:15.989610 12354 sgd_solver.cpp:136] Iteration 57900, lr = 7.17202e-05, m = 0.9
I0212 16:19:23.154150 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_58000.caffemodel
I0212 16:19:23.187474 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_58000.solverstate
I0212 16:19:23.200232 12354 solver.cpp:666] Iteration 58000, Testing net (#0)
I0212 16:20:18.087085 12354 solver.cpp:774] class AP 1: 0.374881
I0212 16:20:18.167726 12354 solver.cpp:774] class AP 2: 0.626237
I0212 16:20:18.182184 12354 solver.cpp:774] class AP 3: 0.631837
I0212 16:20:18.182229 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.544318
I0212 16:20:18.288197 12355 solver.cpp:774] class AP 1: 0.38709
I0212 16:20:18.364670 12355 solver.cpp:774] class AP 2: 0.631883
I0212 16:20:18.375927 12355 solver.cpp:774] class AP 3: 0.634627
I0212 16:20:18.375953 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.5512
I0212 16:20:18.376029 12354 solver.cpp:265] [MultiGPU] Tests completed in 55.1738s
I0212 16:20:18.831779 12354 solver.cpp:314] Iteration 58000 (0.814081 iter/s, 122.838s/100 iter), loss = 2.88546
I0212 16:20:18.831826 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.10831 (* 1 = 3.10831 loss)
I0212 16:20:18.831841 12354 sgd_solver.cpp:136] Iteration 58000, lr = 7.12593e-05, m = 0.9
I0212 16:21:25.303290 12354 solver.cpp:314] Iteration 58100 (1.50446 iter/s, 66.4691s/100 iter), loss = 2.82323
I0212 16:21:25.303412 12354 solver.cpp:336]     Train net output #0: mbox_loss = 1.81808 (* 1 = 1.81808 loss)
I0212 16:21:25.303426 12354 sgd_solver.cpp:136] Iteration 58100, lr = 7.08007e-05, m = 0.9
I0212 16:22:20.075464 12354 solver.cpp:314] Iteration 58200 (1.82581 iter/s, 54.7702s/100 iter), loss = 3.01812
I0212 16:22:20.075604 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.06942 (* 1 = 3.06942 loss)
I0212 16:22:20.075623 12354 sgd_solver.cpp:136] Iteration 58200, lr = 7.03443e-05, m = 0.9
I0212 16:23:16.382932 12354 solver.cpp:314] Iteration 58300 (1.77603 iter/s, 56.3054s/100 iter), loss = 2.98029
I0212 16:23:16.383059 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.57306 (* 1 = 2.57306 loss)
I0212 16:23:16.383077 12354 sgd_solver.cpp:136] Iteration 58300, lr = 6.98901e-05, m = 0.9
I0212 16:24:12.200485 12354 solver.cpp:314] Iteration 58400 (1.79162 iter/s, 55.8155s/100 iter), loss = 3.13859
I0212 16:24:12.200649 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.34747 (* 1 = 3.34747 loss)
I0212 16:24:12.200690 12354 sgd_solver.cpp:136] Iteration 58400, lr = 6.94381e-05, m = 0.9
I0212 16:25:07.978307 12354 solver.cpp:314] Iteration 58500 (1.79289 iter/s, 55.7758s/100 iter), loss = 2.91429
I0212 16:25:07.978435 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.34329 (* 1 = 2.34329 loss)
I0212 16:25:07.978454 12354 sgd_solver.cpp:136] Iteration 58500, lr = 6.89883e-05, m = 0.9
I0212 16:26:03.007859 12354 solver.cpp:314] Iteration 58600 (1.81727 iter/s, 55.0275s/100 iter), loss = 2.99761
I0212 16:26:03.008025 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.72751 (* 1 = 2.72751 loss)
I0212 16:26:03.008064 12354 sgd_solver.cpp:136] Iteration 58600, lr = 6.85407e-05, m = 0.9
I0212 16:26:58.810413 12354 solver.cpp:314] Iteration 58700 (1.7921 iter/s, 55.8005s/100 iter), loss = 3.05592
I0212 16:26:58.810546 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.60451 (* 1 = 2.60451 loss)
I0212 16:26:58.810562 12354 sgd_solver.cpp:136] Iteration 58700, lr = 6.80953e-05, m = 0.9
I0212 16:27:54.208940 12354 solver.cpp:314] Iteration 58800 (1.80517 iter/s, 55.3965s/100 iter), loss = 2.87974
I0212 16:27:54.209060 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.23194 (* 1 = 3.23194 loss)
I0212 16:27:54.209074 12354 sgd_solver.cpp:136] Iteration 58800, lr = 6.7652e-05, m = 0.9
I0212 16:29:30.899296 12354 solver.cpp:314] Iteration 58900 (1.03427 iter/s, 96.6868s/100 iter), loss = 3.02567
I0212 16:29:30.899433 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.84831 (* 1 = 2.84831 loss)
I0212 16:29:30.899468 12354 sgd_solver.cpp:136] Iteration 58900, lr = 6.72109e-05, m = 0.9
I0212 16:31:09.370164 12354 solver.cpp:314] Iteration 59000 (1.01557 iter/s, 98.4673s/100 iter), loss = 3.06231
I0212 16:31:09.370357 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.11973 (* 1 = 3.11973 loss)
I0212 16:31:09.370391 12354 sgd_solver.cpp:136] Iteration 59000, lr = 6.6772e-05, m = 0.9
I0212 16:32:51.402663 12354 solver.cpp:314] Iteration 59100 (0.980116 iter/s, 102.029s/100 iter), loss = 2.67237
I0212 16:32:51.402776 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.88108 (* 1 = 2.88108 loss)
I0212 16:32:51.402794 12354 sgd_solver.cpp:136] Iteration 59100, lr = 6.63352e-05, m = 0.9
I0212 16:34:31.422284 12354 solver.cpp:314] Iteration 59200 (0.99984 iter/s, 100.016s/100 iter), loss = 3.07034
I0212 16:34:31.422391 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.55295 (* 1 = 3.55295 loss)
I0212 16:34:31.422406 12354 sgd_solver.cpp:136] Iteration 59200, lr = 6.59006e-05, m = 0.9
I0212 16:36:12.630291 12354 solver.cpp:314] Iteration 59300 (0.9881 iter/s, 101.204s/100 iter), loss = 2.81608
I0212 16:36:12.630399 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.93733 (* 1 = 2.93733 loss)
I0212 16:36:12.630414 12354 sgd_solver.cpp:136] Iteration 59300, lr = 6.54681e-05, m = 0.9
I0212 16:37:18.781141 12354 solver.cpp:314] Iteration 59400 (1.51175 iter/s, 66.1484s/100 iter), loss = 3.03294
I0212 16:37:18.781250 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.38907 (* 1 = 3.38907 loss)
I0212 16:37:18.781402 12354 sgd_solver.cpp:136] Iteration 59400, lr = 6.50377e-05, m = 0.9
I0212 16:38:13.751338 12354 solver.cpp:314] Iteration 59500 (1.81923 iter/s, 54.9682s/100 iter), loss = 2.83842
I0212 16:38:13.751564 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.02475 (* 1 = 2.02475 loss)
I0212 16:38:13.751606 12354 sgd_solver.cpp:136] Iteration 59500, lr = 6.46095e-05, m = 0.9
I0212 16:39:09.266371 12354 solver.cpp:314] Iteration 59600 (1.80138 iter/s, 55.513s/100 iter), loss = 3.0801
I0212 16:39:09.266520 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.62956 (* 1 = 4.62956 loss)
I0212 16:39:09.266559 12354 sgd_solver.cpp:136] Iteration 59600, lr = 6.41834e-05, m = 0.9
I0212 16:40:04.249317 12354 solver.cpp:314] Iteration 59700 (1.81881 iter/s, 54.9809s/100 iter), loss = 2.59268
I0212 16:40:04.249445 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.16627 (* 1 = 2.16627 loss)
I0212 16:40:04.249465 12354 sgd_solver.cpp:136] Iteration 59700, lr = 6.37594e-05, m = 0.9
I0212 16:40:59.499120 12354 solver.cpp:314] Iteration 59800 (1.81003 iter/s, 55.2478s/100 iter), loss = 2.73063
I0212 16:40:59.499218 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.91654 (* 1 = 2.91654 loss)
I0212 16:40:59.499228 12354 sgd_solver.cpp:136] Iteration 59800, lr = 6.33375e-05, m = 0.9
I0212 16:41:54.919504 12354 solver.cpp:314] Iteration 59900 (1.80446 iter/s, 55.4184s/100 iter), loss = 2.85275
I0212 16:41:54.919627 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.81018 (* 1 = 2.81018 loss)
I0212 16:41:54.919642 12354 sgd_solver.cpp:136] Iteration 59900, lr = 6.29177e-05, m = 0.9
I0212 16:42:49.806633 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_60000.caffemodel
I0212 16:42:49.824331 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_60000.solverstate
I0212 16:42:49.833211 12354 solver.cpp:666] Iteration 60000, Testing net (#0)
I0212 16:43:37.968931 12330 data_reader.cpp:305] Starting prefetch of epoch 4
I0212 16:43:40.124565 12354 solver.cpp:774] class AP 1: 0.376263
I0212 16:43:40.197798 12354 solver.cpp:774] class AP 2: 0.622103
I0212 16:43:40.210083 12354 solver.cpp:774] class AP 3: 0.634986
I0212 16:43:40.210117 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.544451
I0212 16:43:40.256227 12355 solver.cpp:774] class AP 1: 0.395193
I0212 16:43:40.326402 12355 solver.cpp:774] class AP 2: 0.644506
I0212 16:43:40.338950 12355 solver.cpp:774] class AP 3: 0.632115
I0212 16:43:40.338968 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.557271
I0212 16:43:40.339069 12354 solver.cpp:265] [MultiGPU] Tests completed in 50.504s
I0212 16:43:40.752599 12354 solver.cpp:314] Iteration 60000 (0.944919 iter/s, 105.829s/100 iter), loss = 2.75741
I0212 16:43:40.752713 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.91597 (* 1 = 2.91597 loss)
I0212 16:43:40.752746 12354 sgd_solver.cpp:136] Iteration 60000, lr = 6.25e-05, m = 0.9
I0212 16:44:36.056243 12354 solver.cpp:314] Iteration 60100 (1.80826 iter/s, 55.3016s/100 iter), loss = 2.89424
I0212 16:44:36.056408 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.23971 (* 1 = 3.23971 loss)
I0212 16:44:36.056427 12354 sgd_solver.cpp:136] Iteration 60100, lr = 6.20844e-05, m = 0.9
I0212 16:45:30.447556 12354 solver.cpp:314] Iteration 60200 (1.8386 iter/s, 54.3893s/100 iter), loss = 3.01454
I0212 16:45:30.447711 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.6687 (* 1 = 2.6687 loss)
I0212 16:45:30.447731 12354 sgd_solver.cpp:136] Iteration 60200, lr = 6.16708e-05, m = 0.9
I0212 16:46:25.880700 12354 solver.cpp:314] Iteration 60300 (1.80404 iter/s, 55.4311s/100 iter), loss = 2.91841
I0212 16:46:25.880853 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.26325 (* 1 = 3.26325 loss)
I0212 16:46:25.881093 12354 sgd_solver.cpp:136] Iteration 60300, lr = 6.12594e-05, m = 0.9
I0212 16:47:21.742449 12354 solver.cpp:314] Iteration 60400 (1.7902 iter/s, 55.8597s/100 iter), loss = 2.79426
I0212 16:47:21.742569 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.24275 (* 1 = 3.24275 loss)
I0212 16:47:21.742583 12354 sgd_solver.cpp:136] Iteration 60400, lr = 6.08499e-05, m = 0.9
I0212 16:48:16.629415 12354 solver.cpp:314] Iteration 60500 (1.82199 iter/s, 54.885s/100 iter), loss = 3.01997
I0212 16:48:16.629653 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.4326 (* 1 = 2.4326 loss)
I0212 16:48:16.629668 12354 sgd_solver.cpp:136] Iteration 60500, lr = 6.04426e-05, m = 0.9
I0212 16:49:11.650279 12354 solver.cpp:314] Iteration 60600 (1.81756 iter/s, 55.0189s/100 iter), loss = 2.89364
I0212 16:49:11.650372 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.36051 (* 1 = 3.36051 loss)
I0212 16:49:11.650383 12354 sgd_solver.cpp:136] Iteration 60600, lr = 6.00373e-05, m = 0.9
I0212 16:50:07.066375 12354 solver.cpp:314] Iteration 60700 (1.8046 iter/s, 55.4141s/100 iter), loss = 2.87512
I0212 16:50:07.066483 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.89005 (* 1 = 2.89005 loss)
I0212 16:50:07.066501 12354 sgd_solver.cpp:136] Iteration 60700, lr = 5.9634e-05, m = 0.9
I0212 16:51:02.527739 12354 solver.cpp:314] Iteration 60800 (1.80312 iter/s, 55.4593s/100 iter), loss = 2.94012
I0212 16:51:02.527873 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.18148 (* 1 = 2.18148 loss)
I0212 16:51:02.528059 12354 sgd_solver.cpp:136] Iteration 60800, lr = 5.92327e-05, m = 0.9
I0212 16:51:57.023857 12354 solver.cpp:314] Iteration 60900 (1.83506 iter/s, 54.4941s/100 iter), loss = 3.01728
I0212 16:51:57.023990 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.21804 (* 1 = 3.21804 loss)
I0212 16:51:57.024008 12354 sgd_solver.cpp:136] Iteration 60900, lr = 5.88335e-05, m = 0.9
I0212 16:52:51.878885 12354 solver.cpp:314] Iteration 61000 (1.82305 iter/s, 54.853s/100 iter), loss = 2.95619
I0212 16:52:51.878983 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.15815 (* 1 = 2.15815 loss)
I0212 16:52:51.878998 12354 sgd_solver.cpp:136] Iteration 61000, lr = 5.84364e-05, m = 0.9
I0212 16:53:47.238696 12354 solver.cpp:314] Iteration 61100 (1.80643 iter/s, 55.3578s/100 iter), loss = 3.037
I0212 16:53:47.238860 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.63699 (* 1 = 3.63699 loss)
I0212 16:53:47.238910 12354 sgd_solver.cpp:136] Iteration 61100, lr = 5.80412e-05, m = 0.9
I0212 16:54:43.003111 12354 solver.cpp:314] Iteration 61200 (1.79332 iter/s, 55.7624s/100 iter), loss = 3.1304
I0212 16:54:43.003257 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.51871 (* 1 = 2.51871 loss)
I0212 16:54:43.003273 12354 sgd_solver.cpp:136] Iteration 61200, lr = 5.7648e-05, m = 0.9
I0212 16:55:37.806744 12354 solver.cpp:314] Iteration 61300 (1.82476 iter/s, 54.8016s/100 iter), loss = 2.93465
I0212 16:55:37.806864 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.58159 (* 1 = 2.58159 loss)
I0212 16:55:37.806879 12354 sgd_solver.cpp:136] Iteration 61300, lr = 5.72569e-05, m = 0.9
I0212 16:56:32.433939 12354 solver.cpp:314] Iteration 61400 (1.83066 iter/s, 54.6252s/100 iter), loss = 2.9528
I0212 16:56:32.434031 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.3558 (* 1 = 3.3558 loss)
I0212 16:56:32.434046 12354 sgd_solver.cpp:136] Iteration 61400, lr = 5.68677e-05, m = 0.9
I0212 16:57:27.955169 12354 solver.cpp:314] Iteration 61500 (1.80118 iter/s, 55.5192s/100 iter), loss = 3.13145
I0212 16:57:27.955271 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.584 (* 1 = 2.584 loss)
I0212 16:57:27.955282 12354 sgd_solver.cpp:136] Iteration 61500, lr = 5.64805e-05, m = 0.9
I0212 16:58:23.425390 12354 solver.cpp:314] Iteration 61600 (1.80283 iter/s, 55.4682s/100 iter), loss = 3.16472
I0212 16:58:23.425505 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.42003 (* 1 = 3.42003 loss)
I0212 16:58:23.425524 12354 sgd_solver.cpp:136] Iteration 61600, lr = 5.60953e-05, m = 0.9
I0212 16:59:19.127097 12354 solver.cpp:314] Iteration 61700 (1.79534 iter/s, 55.6997s/100 iter), loss = 2.85942
I0212 16:59:19.127218 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.68186 (* 1 = 2.68186 loss)
I0212 16:59:19.127233 12354 sgd_solver.cpp:136] Iteration 61700, lr = 5.57121e-05, m = 0.9
I0212 17:00:14.755851 12354 solver.cpp:314] Iteration 61800 (1.7977 iter/s, 55.6267s/100 iter), loss = 2.97001
I0212 17:00:14.755993 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.15005 (* 1 = 3.15005 loss)
I0212 17:00:14.756022 12354 sgd_solver.cpp:136] Iteration 61800, lr = 5.53308e-05, m = 0.9
I0212 17:01:10.505602 12354 solver.cpp:314] Iteration 61900 (1.7938 iter/s, 55.7477s/100 iter), loss = 2.97777
I0212 17:01:10.505717 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.98856 (* 1 = 2.98856 loss)
I0212 17:01:10.505899 12354 sgd_solver.cpp:136] Iteration 61900, lr = 5.49515e-05, m = 0.9
I0212 17:02:05.672304 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_62000.caffemodel
I0212 17:02:05.695156 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_62000.solverstate
I0212 17:02:05.707653 12354 solver.cpp:666] Iteration 62000, Testing net (#0)
I0212 17:02:39.734998 12354 blocking_queue.cpp:40] Data layer prefetch queue empty
I0212 17:02:55.733517 12355 solver.cpp:774] class AP 1: 0.39392
I0212 17:02:55.798257 12355 solver.cpp:774] class AP 2: 0.640545
I0212 17:02:55.809742 12355 solver.cpp:774] class AP 3: 0.628832
I0212 17:02:55.809757 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.554432
I0212 17:02:55.815384 12354 solver.cpp:774] class AP 1: 0.376475
I0212 17:02:55.881899 12354 solver.cpp:774] class AP 2: 0.627478
I0212 17:02:55.893672 12354 solver.cpp:774] class AP 3: 0.629517
I0212 17:02:55.893687 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.54449
I0212 17:02:55.893721 12354 solver.cpp:265] [MultiGPU] Tests completed in 50.1842s
I0212 17:02:56.467929 12354 solver.cpp:314] Iteration 62000 (0.943766 iter/s, 105.958s/100 iter), loss = 2.80648
I0212 17:02:56.467975 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.67893 (* 1 = 2.67893 loss)
I0212 17:02:56.467984 12354 sgd_solver.cpp:136] Iteration 62000, lr = 5.45742e-05, m = 0.9
I0212 17:03:51.140348 12354 solver.cpp:314] Iteration 62100 (1.82914 iter/s, 54.6704s/100 iter), loss = 2.90366
I0212 17:03:51.140525 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.67418 (* 1 = 2.67418 loss)
I0212 17:03:51.140547 12354 sgd_solver.cpp:136] Iteration 62100, lr = 5.41988e-05, m = 0.9
I0212 17:04:46.663069 12354 solver.cpp:314] Iteration 62200 (1.80113 iter/s, 55.5207s/100 iter), loss = 2.91373
I0212 17:04:46.663377 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.86878 (* 1 = 2.86878 loss)
I0212 17:04:46.663522 12354 sgd_solver.cpp:136] Iteration 62200, lr = 5.38253e-05, m = 0.9
I0212 17:05:41.415879 12354 solver.cpp:314] Iteration 62300 (1.82646 iter/s, 54.7508s/100 iter), loss = 2.94956
I0212 17:05:41.415978 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.74306 (* 1 = 2.74306 loss)
I0212 17:05:41.415989 12354 sgd_solver.cpp:136] Iteration 62300, lr = 5.34538e-05, m = 0.9
I0212 17:06:36.496131 12354 solver.cpp:314] Iteration 62400 (1.8156 iter/s, 55.0782s/100 iter), loss = 3.06014
I0212 17:06:36.496264 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.04687 (* 1 = 2.04687 loss)
I0212 17:06:36.496279 12354 sgd_solver.cpp:136] Iteration 62400, lr = 5.30842e-05, m = 0.9
I0212 17:07:31.288985 12354 solver.cpp:314] Iteration 62500 (1.82512 iter/s, 54.7908s/100 iter), loss = 2.90997
I0212 17:07:31.289106 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.74446 (* 1 = 2.74446 loss)
I0212 17:07:31.289124 12354 sgd_solver.cpp:136] Iteration 62500, lr = 5.27165e-05, m = 0.9
I0212 17:08:25.614212 12354 solver.cpp:314] Iteration 62600 (1.84083 iter/s, 54.3232s/100 iter), loss = 2.8267
I0212 17:08:25.614320 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.14452 (* 1 = 3.14452 loss)
I0212 17:08:25.614338 12354 sgd_solver.cpp:136] Iteration 62600, lr = 5.23507e-05, m = 0.9
I0212 17:09:20.818413 12354 solver.cpp:314] Iteration 62700 (1.81152 iter/s, 55.2022s/100 iter), loss = 2.85609
I0212 17:09:20.818517 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.20685 (* 1 = 3.20685 loss)
I0212 17:09:20.818532 12354 sgd_solver.cpp:136] Iteration 62700, lr = 5.19869e-05, m = 0.9
I0212 17:10:15.751202 12354 solver.cpp:314] Iteration 62800 (1.82047 iter/s, 54.9308s/100 iter), loss = 2.99399
I0212 17:10:15.751381 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.78447 (* 1 = 2.78447 loss)
I0212 17:10:15.751420 12354 sgd_solver.cpp:136] Iteration 62800, lr = 5.16249e-05, m = 0.9
I0212 17:10:33.076236 12274 data_reader.cpp:305] Starting prefetch of epoch 12
I0212 17:11:11.030221 12354 solver.cpp:314] Iteration 62900 (1.80907 iter/s, 55.277s/100 iter), loss = 2.9769
I0212 17:11:11.030323 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.40694 (* 1 = 3.40694 loss)
I0212 17:11:11.030333 12354 sgd_solver.cpp:136] Iteration 62900, lr = 5.12648e-05, m = 0.9
I0212 17:12:06.404675 12354 solver.cpp:314] Iteration 63000 (1.80595 iter/s, 55.3724s/100 iter), loss = 3.00075
I0212 17:12:06.412995 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.75093 (* 1 = 2.75093 loss)
I0212 17:12:06.413024 12354 sgd_solver.cpp:136] Iteration 63000, lr = 5.09067e-05, m = 0.9
I0212 17:13:01.931406 12354 solver.cpp:314] Iteration 63100 (1.801 iter/s, 55.5247s/100 iter), loss = 2.77108
I0212 17:13:01.931515 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.34453 (* 1 = 3.34453 loss)
I0212 17:13:01.931529 12354 sgd_solver.cpp:136] Iteration 63100, lr = 5.05504e-05, m = 0.9
I0212 17:13:57.575217 12354 solver.cpp:314] Iteration 63200 (1.79721 iter/s, 55.6418s/100 iter), loss = 2.83658
I0212 17:13:57.575353 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.30972 (* 1 = 3.30972 loss)
I0212 17:13:57.575369 12354 sgd_solver.cpp:136] Iteration 63200, lr = 5.01959e-05, m = 0.9
I0212 17:14:52.870147 12354 solver.cpp:314] Iteration 63300 (1.80855 iter/s, 55.2929s/100 iter), loss = 2.90381
I0212 17:14:52.870311 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.12509 (* 1 = 3.12509 loss)
I0212 17:14:52.870327 12354 sgd_solver.cpp:136] Iteration 63300, lr = 4.98434e-05, m = 0.9
I0212 17:15:47.890904 12354 solver.cpp:314] Iteration 63400 (1.81756 iter/s, 55.0187s/100 iter), loss = 3.24011
I0212 17:15:47.891044 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.81474 (* 1 = 2.81474 loss)
I0212 17:15:47.891065 12354 sgd_solver.cpp:136] Iteration 63400, lr = 4.94927e-05, m = 0.9
I0212 17:16:43.856503 12354 solver.cpp:314] Iteration 63500 (1.78688 iter/s, 55.9636s/100 iter), loss = 2.97021
I0212 17:16:43.856642 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.99468 (* 1 = 3.99468 loss)
I0212 17:16:43.856658 12354 sgd_solver.cpp:136] Iteration 63500, lr = 4.91438e-05, m = 0.9
I0212 17:17:38.522620 12354 solver.cpp:314] Iteration 63600 (1.82935 iter/s, 54.6641s/100 iter), loss = 2.94973
I0212 17:17:38.522727 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.81064 (* 1 = 2.81064 loss)
I0212 17:17:38.522744 12354 sgd_solver.cpp:136] Iteration 63600, lr = 4.87968e-05, m = 0.9
I0212 17:18:33.531385 12354 solver.cpp:314] Iteration 63700 (1.81796 iter/s, 55.0068s/100 iter), loss = 2.94492
I0212 17:18:33.531486 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.61865 (* 1 = 3.61865 loss)
I0212 17:18:33.531503 12354 sgd_solver.cpp:136] Iteration 63700, lr = 4.84517e-05, m = 0.9
I0212 17:19:28.979527 12354 solver.cpp:314] Iteration 63800 (1.80355 iter/s, 55.4461s/100 iter), loss = 2.7013
I0212 17:19:28.979653 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.55971 (* 1 = 2.55971 loss)
I0212 17:19:28.979665 12354 sgd_solver.cpp:136] Iteration 63800, lr = 4.81083e-05, m = 0.9
I0212 17:20:23.759084 12354 solver.cpp:314] Iteration 63900 (1.82557 iter/s, 54.7775s/100 iter), loss = 2.97885
I0212 17:20:23.759214 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.52148 (* 1 = 3.52148 loss)
I0212 17:20:23.759229 12354 sgd_solver.cpp:136] Iteration 63900, lr = 4.77668e-05, m = 0.9
I0212 17:21:18.602825 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_64000.caffemodel
I0212 17:21:18.625953 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_64000.solverstate
I0212 17:21:18.639017 12354 solver.cpp:666] Iteration 64000, Testing net (#0)
I0212 17:22:08.716272 12355 solver.cpp:774] class AP 1: 0.393894
I0212 17:22:08.781774 12355 solver.cpp:774] class AP 2: 0.639808
I0212 17:22:08.793568 12355 solver.cpp:774] class AP 3: 0.632422
I0212 17:22:08.793592 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.555375
I0212 17:22:09.128743 12354 solver.cpp:774] class AP 1: 0.377026
I0212 17:22:09.202996 12354 solver.cpp:774] class AP 2: 0.621719
I0212 17:22:09.214471 12354 solver.cpp:774] class AP 3: 0.62756
I0212 17:22:09.214488 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.542101
I0212 17:22:09.214535 12354 solver.cpp:265] [MultiGPU] Tests completed in 50.5737s
I0212 17:22:09.615716 12354 solver.cpp:314] Iteration 64000 (0.944708 iter/s, 105.853s/100 iter), loss = 3.048
I0212 17:22:09.615769 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.20964 (* 1 = 3.20964 loss)
I0212 17:22:09.615782 12354 sgd_solver.cpp:136] Iteration 64000, lr = 4.74272e-05, m = 0.9
I0212 17:23:04.697432 12354 solver.cpp:314] Iteration 64100 (1.81555 iter/s, 55.0797s/100 iter), loss = 3.07511
I0212 17:23:04.701881 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.37602 (* 1 = 2.37602 loss)
I0212 17:23:04.701905 12354 sgd_solver.cpp:136] Iteration 64100, lr = 4.70893e-05, m = 0.9
I0212 17:24:00.236471 12354 solver.cpp:314] Iteration 64200 (1.8006 iter/s, 55.537s/100 iter), loss = 2.91671
I0212 17:24:00.236619 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.62107 (* 1 = 2.62107 loss)
I0212 17:24:00.236634 12354 sgd_solver.cpp:136] Iteration 64200, lr = 4.67532e-05, m = 0.9
I0212 17:24:56.265928 12354 solver.cpp:314] Iteration 64300 (1.78484 iter/s, 56.0274s/100 iter), loss = 3.02455
I0212 17:24:56.266062 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.5152 (* 1 = 2.5152 loss)
I0212 17:24:56.266077 12354 sgd_solver.cpp:136] Iteration 64300, lr = 4.6419e-05, m = 0.9
I0212 17:25:51.749590 12354 solver.cpp:314] Iteration 64400 (1.8024 iter/s, 55.4816s/100 iter), loss = 2.87067
I0212 17:25:51.749696 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.56158 (* 1 = 2.56158 loss)
I0212 17:25:51.749711 12354 sgd_solver.cpp:136] Iteration 64400, lr = 4.60865e-05, m = 0.9
I0212 17:26:46.468407 12354 solver.cpp:314] Iteration 64500 (1.82759 iter/s, 54.7168s/100 iter), loss = 2.92871
I0212 17:26:46.468555 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.1507 (* 1 = 4.1507 loss)
I0212 17:26:46.468570 12354 sgd_solver.cpp:136] Iteration 64500, lr = 4.57559e-05, m = 0.9
I0212 17:27:42.291260 12354 solver.cpp:314] Iteration 64600 (1.79145 iter/s, 55.8208s/100 iter), loss = 3.22727
I0212 17:27:42.291353 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.74424 (* 1 = 3.74424 loss)
I0212 17:27:42.291363 12354 sgd_solver.cpp:136] Iteration 64600, lr = 4.5427e-05, m = 0.9
I0212 17:28:37.120069 12354 solver.cpp:314] Iteration 64700 (1.82393 iter/s, 54.8268s/100 iter), loss = 2.79834
I0212 17:28:37.120160 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.62509 (* 1 = 2.62509 loss)
I0212 17:28:37.120170 12354 sgd_solver.cpp:136] Iteration 64700, lr = 4.50999e-05, m = 0.9
I0212 17:29:32.457814 12354 solver.cpp:314] Iteration 64800 (1.80715 iter/s, 55.3357s/100 iter), loss = 2.94263
I0212 17:29:32.457933 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.12953 (* 1 = 2.12953 loss)
I0212 17:29:32.457947 12354 sgd_solver.cpp:136] Iteration 64800, lr = 4.47746e-05, m = 0.9
I0212 17:30:27.283133 12354 solver.cpp:314] Iteration 64900 (1.82404 iter/s, 54.8233s/100 iter), loss = 2.99617
I0212 17:30:27.283351 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.09351 (* 1 = 3.09351 loss)
I0212 17:30:27.283397 12354 sgd_solver.cpp:136] Iteration 64900, lr = 4.4451e-05, m = 0.9
I0212 17:31:22.717669 12354 solver.cpp:314] Iteration 65000 (1.804 iter/s, 55.4325s/100 iter), loss = 2.8798
I0212 17:31:22.717911 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.47658 (* 1 = 3.47658 loss)
I0212 17:31:22.717926 12354 sgd_solver.cpp:136] Iteration 65000, lr = 4.41292e-05, m = 0.9
I0212 17:32:17.400053 12354 solver.cpp:314] Iteration 65100 (1.82881 iter/s, 54.6804s/100 iter), loss = 3.17463
I0212 17:32:17.402233 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.98127 (* 1 = 2.98127 loss)
I0212 17:32:17.402281 12354 sgd_solver.cpp:136] Iteration 65100, lr = 4.38091e-05, m = 0.9
I0212 17:33:12.726073 12354 solver.cpp:314] Iteration 65200 (1.80753 iter/s, 55.324s/100 iter), loss = 2.88118
I0212 17:33:12.729029 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.92344 (* 1 = 2.92344 loss)
I0212 17:33:12.729049 12354 sgd_solver.cpp:136] Iteration 65200, lr = 4.34908e-05, m = 0.9
I0212 17:34:08.024183 12354 solver.cpp:314] Iteration 65300 (1.80845 iter/s, 55.2961s/100 iter), loss = 2.87606
I0212 17:34:08.024283 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.94298 (* 1 = 2.94298 loss)
I0212 17:34:08.024299 12354 sgd_solver.cpp:136] Iteration 65300, lr = 4.31742e-05, m = 0.9
I0212 17:35:02.938912 12354 solver.cpp:314] Iteration 65400 (1.82107 iter/s, 54.9127s/100 iter), loss = 3.03255
I0212 17:35:02.939030 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.04425 (* 1 = 3.04425 loss)
I0212 17:35:02.939045 12354 sgd_solver.cpp:136] Iteration 65400, lr = 4.28593e-05, m = 0.9
I0212 17:35:57.430382 12354 solver.cpp:314] Iteration 65500 (1.83522 iter/s, 54.4895s/100 iter), loss = 3.11355
I0212 17:35:57.430593 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.91678 (* 1 = 2.91678 loss)
I0212 17:35:57.430608 12354 sgd_solver.cpp:136] Iteration 65500, lr = 4.25462e-05, m = 0.9
I0212 17:36:53.460595 12354 solver.cpp:314] Iteration 65600 (1.78482 iter/s, 56.0282s/100 iter), loss = 3.00172
I0212 17:36:53.460801 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.07241 (* 1 = 3.07241 loss)
I0212 17:36:53.460837 12354 sgd_solver.cpp:136] Iteration 65600, lr = 4.22348e-05, m = 0.9
I0212 17:37:48.120659 12354 solver.cpp:314] Iteration 65700 (1.82956 iter/s, 54.6581s/100 iter), loss = 2.78107
I0212 17:37:48.120775 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.07355 (* 1 = 3.07355 loss)
I0212 17:37:48.120793 12354 sgd_solver.cpp:136] Iteration 65700, lr = 4.19251e-05, m = 0.9
I0212 17:38:43.086493 12354 solver.cpp:314] Iteration 65800 (1.81938 iter/s, 54.9638s/100 iter), loss = 2.77232
I0212 17:38:43.086597 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.63085 (* 1 = 2.63085 loss)
I0212 17:38:43.086613 12354 sgd_solver.cpp:136] Iteration 65800, lr = 4.16171e-05, m = 0.9
I0212 17:39:38.592944 12354 solver.cpp:314] Iteration 65900 (1.80166 iter/s, 55.5044s/100 iter), loss = 3.04215
I0212 17:39:38.593075 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.82385 (* 1 = 2.82385 loss)
I0212 17:39:38.593094 12354 sgd_solver.cpp:136] Iteration 65900, lr = 4.13108e-05, m = 0.9
I0212 17:40:12.979694 12274 data_reader.cpp:305] Starting prefetch of epoch 13
I0212 17:40:32.864614 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_66000.caffemodel
I0212 17:40:32.882215 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_66000.solverstate
I0212 17:40:32.891228 12354 solver.cpp:666] Iteration 66000, Testing net (#0)
I0212 17:41:23.932569 12354 solver.cpp:774] class AP 1: 0.374503
I0212 17:41:24.008270 12354 solver.cpp:774] class AP 2: 0.633834
I0212 17:41:24.019773 12354 solver.cpp:774] class AP 3: 0.628657
I0212 17:41:24.019789 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.545665
I0212 17:41:25.106035 12355 solver.cpp:774] class AP 1: 0.395786
I0212 17:41:25.170449 12355 solver.cpp:774] class AP 2: 0.647988
I0212 17:41:25.181236 12355 solver.cpp:774] class AP 3: 0.63495
I0212 17:41:25.181249 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.559575
I0212 17:41:25.181358 12354 solver.cpp:265] [MultiGPU] Tests completed in 52.2882s
I0212 17:41:25.630296 12354 solver.cpp:314] Iteration 66000 (0.934287 iter/s, 107.033s/100 iter), loss = 2.86082
I0212 17:41:25.630348 12354 solver.cpp:336]     Train net output #0: mbox_loss = 5.59899 (* 1 = 5.59899 loss)
I0212 17:41:25.630362 12354 sgd_solver.cpp:136] Iteration 66000, lr = 4.10062e-05, m = 0.9
I0212 17:42:20.494889 12354 solver.cpp:314] Iteration 66100 (1.82274 iter/s, 54.8626s/100 iter), loss = 3.08687
I0212 17:42:20.495012 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.70478 (* 1 = 3.70478 loss)
I0212 17:42:20.495026 12354 sgd_solver.cpp:136] Iteration 66100, lr = 4.07033e-05, m = 0.9
I0212 17:43:15.351680 12354 solver.cpp:314] Iteration 66200 (1.823 iter/s, 54.8548s/100 iter), loss = 2.82277
I0212 17:43:15.351864 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.84449 (* 1 = 2.84449 loss)
I0212 17:43:15.351904 12354 sgd_solver.cpp:136] Iteration 66200, lr = 4.04021e-05, m = 0.9
I0212 17:44:10.301378 12354 solver.cpp:314] Iteration 66300 (1.81991 iter/s, 54.9477s/100 iter), loss = 2.8704
I0212 17:44:10.301542 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.48143 (* 1 = 2.48143 loss)
I0212 17:44:10.301579 12354 sgd_solver.cpp:136] Iteration 66300, lr = 4.01026e-05, m = 0.9
I0212 17:45:05.542588 12354 solver.cpp:314] Iteration 66400 (1.81031 iter/s, 55.2392s/100 iter), loss = 2.8077
I0212 17:45:05.542912 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.46366 (* 1 = 2.46366 loss)
I0212 17:45:05.543040 12354 sgd_solver.cpp:136] Iteration 66400, lr = 3.98047e-05, m = 0.9
I0212 17:45:59.577134 12354 solver.cpp:314] Iteration 66500 (1.85074 iter/s, 54.0326s/100 iter), loss = 3.06919
I0212 17:45:59.577255 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.84474 (* 1 = 3.84474 loss)
I0212 17:45:59.577272 12354 sgd_solver.cpp:136] Iteration 66500, lr = 3.95085e-05, m = 0.9
I0212 17:46:54.860819 12354 solver.cpp:314] Iteration 66600 (1.80892 iter/s, 55.2817s/100 iter), loss = 3.00065
I0212 17:46:54.860998 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.42233 (* 1 = 2.42233 loss)
I0212 17:46:54.861035 12354 sgd_solver.cpp:136] Iteration 66600, lr = 3.92139e-05, m = 0.9
I0212 17:47:49.977726 12354 solver.cpp:314] Iteration 66700 (1.81439 iter/s, 55.1149s/100 iter), loss = 2.89698
I0212 17:47:49.977839 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.41271 (* 1 = 3.41271 loss)
I0212 17:47:49.977852 12354 sgd_solver.cpp:136] Iteration 66700, lr = 3.8921e-05, m = 0.9
I0212 17:48:44.929852 12354 solver.cpp:314] Iteration 66800 (1.81983 iter/s, 54.9501s/100 iter), loss = 2.94181
I0212 17:48:44.930035 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.07558 (* 1 = 3.07558 loss)
I0212 17:48:44.930049 12354 sgd_solver.cpp:136] Iteration 66800, lr = 3.86297e-05, m = 0.9
I0212 17:49:40.822841 12354 solver.cpp:314] Iteration 66900 (1.7892 iter/s, 55.8909s/100 iter), loss = 2.76685
I0212 17:49:40.822960 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.63378 (* 1 = 2.63378 loss)
I0212 17:49:40.822978 12354 sgd_solver.cpp:136] Iteration 66900, lr = 3.83401e-05, m = 0.9
I0212 17:50:36.135397 12354 solver.cpp:314] Iteration 67000 (1.80797 iter/s, 55.3105s/100 iter), loss = 2.8043
I0212 17:50:36.135504 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.10275 (* 1 = 2.10275 loss)
I0212 17:50:36.135519 12354 sgd_solver.cpp:136] Iteration 67000, lr = 3.80521e-05, m = 0.9
I0212 17:51:32.295235 12354 solver.cpp:314] Iteration 67100 (1.7807 iter/s, 56.1578s/100 iter), loss = 2.79571
I0212 17:51:32.295382 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.60529 (* 1 = 2.60529 loss)
I0212 17:51:32.295400 12354 sgd_solver.cpp:136] Iteration 67100, lr = 3.77657e-05, m = 0.9
I0212 17:52:27.512027 12354 solver.cpp:314] Iteration 67200 (1.81111 iter/s, 55.2148s/100 iter), loss = 2.9057
I0212 17:52:27.512142 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.75268 (* 1 = 3.75268 loss)
I0212 17:52:27.512156 12354 sgd_solver.cpp:136] Iteration 67200, lr = 3.7481e-05, m = 0.9
I0212 17:53:23.101272 12354 solver.cpp:314] Iteration 67300 (1.79897 iter/s, 55.5872s/100 iter), loss = 2.80562
I0212 17:53:23.101532 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.17489 (* 1 = 3.17489 loss)
I0212 17:53:23.101575 12354 sgd_solver.cpp:136] Iteration 67300, lr = 3.71978e-05, m = 0.9
I0212 17:54:18.133076 12354 solver.cpp:314] Iteration 67400 (1.8172 iter/s, 55.0298s/100 iter), loss = 3.04403
I0212 17:54:18.133204 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.50352 (* 1 = 2.50352 loss)
I0212 17:54:18.133221 12354 sgd_solver.cpp:136] Iteration 67400, lr = 3.69163e-05, m = 0.9
I0212 17:55:13.665845 12354 solver.cpp:314] Iteration 67500 (1.80081 iter/s, 55.5306s/100 iter), loss = 3.00347
I0212 17:55:13.665966 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.42355 (* 1 = 3.42355 loss)
I0212 17:55:13.665982 12354 sgd_solver.cpp:136] Iteration 67500, lr = 3.66364e-05, m = 0.9
I0212 17:56:08.134155 12354 solver.cpp:314] Iteration 67600 (1.836 iter/s, 54.4663s/100 iter), loss = 2.94247
I0212 17:56:08.140099 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.89999 (* 1 = 2.89999 loss)
I0212 17:56:08.140117 12354 sgd_solver.cpp:136] Iteration 67600, lr = 3.6358e-05, m = 0.9
I0212 17:57:03.320224 12354 solver.cpp:314] Iteration 67700 (1.81212 iter/s, 55.1841s/100 iter), loss = 3.15279
I0212 17:57:03.320392 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.66522 (* 1 = 3.66522 loss)
I0212 17:57:03.320408 12354 sgd_solver.cpp:136] Iteration 67700, lr = 3.60813e-05, m = 0.9
I0212 17:57:58.802831 12354 solver.cpp:314] Iteration 67800 (1.80243 iter/s, 55.4806s/100 iter), loss = 2.9735
I0212 17:57:58.802935 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.93585 (* 1 = 2.93585 loss)
I0212 17:57:58.802945 12354 sgd_solver.cpp:136] Iteration 67800, lr = 3.58061e-05, m = 0.9
I0212 17:58:53.246942 12354 solver.cpp:314] Iteration 67900 (1.83681 iter/s, 54.4421s/100 iter), loss = 2.65792
I0212 17:58:53.247053 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.0285 (* 1 = 3.0285 loss)
I0212 17:58:53.247071 12354 sgd_solver.cpp:136] Iteration 67900, lr = 3.55325e-05, m = 0.9
I0212 17:59:47.263018 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_68000.caffemodel
I0212 17:59:47.300571 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_68000.solverstate
I0212 17:59:47.313380 12354 solver.cpp:666] Iteration 68000, Testing net (#0)
I0212 18:00:38.682961 12354 solver.cpp:774] class AP 1: 0.372552
I0212 18:00:38.753301 12354 solver.cpp:774] class AP 2: 0.630192
I0212 18:00:38.764705 12354 solver.cpp:774] class AP 3: 0.625101
I0212 18:00:38.764721 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.542615
I0212 18:00:39.075233 12355 solver.cpp:774] class AP 1: 0.397513
I0212 18:00:39.141496 12355 solver.cpp:774] class AP 2: 0.640641
I0212 18:00:39.152554 12355 solver.cpp:774] class AP 3: 0.636501
I0212 18:00:39.152572 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.558218
I0212 18:00:39.152709 12354 solver.cpp:265] [MultiGPU] Tests completed in 51.8374s
I0212 18:00:39.595770 12354 solver.cpp:314] Iteration 68000 (0.940336 iter/s, 106.345s/100 iter), loss = 2.93403
I0212 18:00:39.595883 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.93162 (* 1 = 2.93162 loss)
I0212 18:00:39.595919 12354 sgd_solver.cpp:136] Iteration 68000, lr = 3.52605e-05, m = 0.9
I0212 18:01:34.832516 12354 solver.cpp:314] Iteration 68100 (1.81045 iter/s, 55.2347s/100 iter), loss = 3.21156
I0212 18:01:34.832630 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.98093 (* 1 = 3.98093 loss)
I0212 18:01:34.832643 12354 sgd_solver.cpp:136] Iteration 68100, lr = 3.499e-05, m = 0.9
I0212 18:02:29.614392 12354 solver.cpp:314] Iteration 68200 (1.82549 iter/s, 54.7799s/100 iter), loss = 3.05583
I0212 18:02:29.614500 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.76359 (* 1 = 2.76359 loss)
I0212 18:02:29.614514 12354 sgd_solver.cpp:136] Iteration 68200, lr = 3.47211e-05, m = 0.9
I0212 18:03:24.464253 12354 solver.cpp:314] Iteration 68300 (1.82323 iter/s, 54.8479s/100 iter), loss = 3.00831
I0212 18:03:24.464393 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.58377 (* 1 = 2.58377 loss)
I0212 18:03:24.464409 12354 sgd_solver.cpp:136] Iteration 68300, lr = 3.44538e-05, m = 0.9
I0212 18:04:20.196056 12354 solver.cpp:314] Iteration 68400 (1.79437 iter/s, 55.7298s/100 iter), loss = 2.86853
I0212 18:04:20.196259 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.63244 (* 1 = 2.63244 loss)
I0212 18:04:20.196296 12354 sgd_solver.cpp:136] Iteration 68400, lr = 3.4188e-05, m = 0.9
I0212 18:05:15.673928 12354 solver.cpp:314] Iteration 68500 (1.80259 iter/s, 55.4758s/100 iter), loss = 2.95454
I0212 18:05:15.676345 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.10495 (* 1 = 3.10495 loss)
I0212 18:05:15.676412 12354 sgd_solver.cpp:136] Iteration 68500, lr = 3.39238e-05, m = 0.9
I0212 18:06:11.217582 12354 solver.cpp:314] Iteration 68600 (1.80045 iter/s, 55.5416s/100 iter), loss = 2.89198
I0212 18:06:11.217722 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.34214 (* 1 = 2.34214 loss)
I0212 18:06:11.217742 12354 sgd_solver.cpp:136] Iteration 68600, lr = 3.3661e-05, m = 0.9
I0212 18:07:06.680413 12354 solver.cpp:314] Iteration 68700 (1.80308 iter/s, 55.4608s/100 iter), loss = 3.03146
I0212 18:07:06.680547 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.02094 (* 1 = 3.02094 loss)
I0212 18:07:06.680562 12354 sgd_solver.cpp:136] Iteration 68700, lr = 3.33999e-05, m = 0.9
I0212 18:07:30.177152 12274 data_reader.cpp:305] Starting prefetch of epoch 14
I0212 18:08:02.771520 12354 solver.cpp:314] Iteration 68800 (1.78288 iter/s, 56.0891s/100 iter), loss = 2.92897
I0212 18:08:02.771639 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.09717 (* 1 = 3.09717 loss)
I0212 18:08:02.771653 12354 sgd_solver.cpp:136] Iteration 68800, lr = 3.31402e-05, m = 0.9
I0212 18:08:57.639642 12354 solver.cpp:314] Iteration 68900 (1.82262 iter/s, 54.8661s/100 iter), loss = 2.89085
I0212 18:08:57.639775 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.4895 (* 1 = 4.4895 loss)
I0212 18:08:57.639793 12354 sgd_solver.cpp:136] Iteration 68900, lr = 3.2882e-05, m = 0.9
I0212 18:09:53.211043 12354 solver.cpp:314] Iteration 69000 (1.79955 iter/s, 55.5694s/100 iter), loss = 2.87566
I0212 18:09:53.211176 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.55313 (* 1 = 4.55313 loss)
I0212 18:09:53.211190 12354 sgd_solver.cpp:136] Iteration 69000, lr = 3.26254e-05, m = 0.9
I0212 18:10:48.304275 12354 solver.cpp:314] Iteration 69100 (1.81517 iter/s, 55.0912s/100 iter), loss = 2.86332
I0212 18:10:48.304440 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.60919 (* 1 = 3.60919 loss)
I0212 18:10:48.304476 12354 sgd_solver.cpp:136] Iteration 69100, lr = 3.23703e-05, m = 0.9
I0212 18:11:43.051239 12354 solver.cpp:314] Iteration 69200 (1.82665 iter/s, 54.745s/100 iter), loss = 2.82735
I0212 18:11:43.051424 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.488 (* 1 = 3.488 loss)
I0212 18:11:43.051463 12354 sgd_solver.cpp:136] Iteration 69200, lr = 3.21166e-05, m = 0.9
I0212 18:12:39.381350 12354 solver.cpp:314] Iteration 69300 (1.77531 iter/s, 56.3281s/100 iter), loss = 2.72652
I0212 18:12:39.389971 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.59985 (* 1 = 2.59985 loss)
I0212 18:12:39.390003 12354 sgd_solver.cpp:136] Iteration 69300, lr = 3.18645e-05, m = 0.9
I0212 18:13:35.411029 12354 solver.cpp:314] Iteration 69400 (1.78483 iter/s, 56.0276s/100 iter), loss = 2.80562
I0212 18:13:35.411140 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.94644 (* 1 = 2.94644 loss)
I0212 18:13:35.411155 12354 sgd_solver.cpp:136] Iteration 69400, lr = 3.16138e-05, m = 0.9
I0212 18:14:30.828622 12354 solver.cpp:314] Iteration 69500 (1.80455 iter/s, 55.4156s/100 iter), loss = 3.32395
I0212 18:14:30.828740 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.11026 (* 1 = 4.11026 loss)
I0212 18:14:30.828753 12354 sgd_solver.cpp:136] Iteration 69500, lr = 3.13647e-05, m = 0.9
I0212 18:15:58.066153 12354 solver.cpp:314] Iteration 69600 (1.14634 iter/s, 87.2344s/100 iter), loss = 2.89784
I0212 18:15:58.066251 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.18466 (* 1 = 4.18466 loss)
I0212 18:15:58.066268 12354 sgd_solver.cpp:136] Iteration 69600, lr = 3.1117e-05, m = 0.9
I0212 18:17:40.218211 12354 solver.cpp:314] Iteration 69700 (0.978968 iter/s, 102.148s/100 iter), loss = 2.99868
I0212 18:17:40.218339 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.59686 (* 1 = 3.59686 loss)
I0212 18:17:40.218361 12354 sgd_solver.cpp:136] Iteration 69700, lr = 3.08707e-05, m = 0.9
I0212 18:19:21.536526 12354 solver.cpp:314] Iteration 69800 (0.987024 iter/s, 101.315s/100 iter), loss = 2.99474
I0212 18:19:21.536689 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.21789 (* 1 = 3.21789 loss)
I0212 18:19:21.536706 12354 sgd_solver.cpp:136] Iteration 69800, lr = 3.0626e-05, m = 0.9
I0212 18:21:02.074800 12354 solver.cpp:314] Iteration 69900 (0.994682 iter/s, 100.535s/100 iter), loss = 3.01089
I0212 18:21:02.074976 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.18898 (* 1 = 3.18898 loss)
I0212 18:21:02.074993 12354 sgd_solver.cpp:136] Iteration 69900, lr = 3.03827e-05, m = 0.9
I0212 18:22:41.654301 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_70000.caffemodel
I0212 18:22:41.737105 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_70000.solverstate
I0212 18:22:41.762231 12354 solver.cpp:666] Iteration 70000, Testing net (#0)
I0212 18:23:45.344888 12354 solver.cpp:774] class AP 1: 0.372536
I0212 18:23:45.355659 12355 solver.cpp:774] class AP 1: 0.392552
I0212 18:23:45.415408 12354 solver.cpp:774] class AP 2: 0.624172
I0212 18:23:45.420620 12355 solver.cpp:774] class AP 2: 0.646938
I0212 18:23:45.426574 12354 solver.cpp:774] class AP 3: 0.62783
I0212 18:23:45.426586 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.541513
I0212 18:23:45.432130 12355 solver.cpp:774] class AP 3: 0.638185
I0212 18:23:45.432145 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.559225
I0212 18:23:45.432214 12354 solver.cpp:265] [MultiGPU] Tests completed in 63.6677s
I0212 18:23:45.840301 12354 solver.cpp:314] Iteration 70000 (0.610651 iter/s, 163.76s/100 iter), loss = 3.08193
I0212 18:23:45.840354 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.08807 (* 1 = 3.08807 loss)
I0212 18:23:45.840363 12354 sgd_solver.cpp:136] Iteration 70000, lr = 3.01408e-05, m = 0.9
I0212 18:24:40.074156 12354 solver.cpp:314] Iteration 70100 (1.84393 iter/s, 54.2319s/100 iter), loss = 3.0429
I0212 18:24:40.074266 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.465 (* 1 = 3.465 loss)
I0212 18:24:40.074393 12354 sgd_solver.cpp:136] Iteration 70100, lr = 2.99004e-05, m = 0.9
I0212 18:25:35.182754 12354 solver.cpp:314] Iteration 70200 (1.81466 iter/s, 55.1066s/100 iter), loss = 2.87339
I0212 18:25:35.182874 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.28449 (* 1 = 3.28449 loss)
I0212 18:25:35.182889 12354 sgd_solver.cpp:136] Iteration 70200, lr = 2.96615e-05, m = 0.9
I0212 18:26:30.476459 12354 solver.cpp:314] Iteration 70300 (1.80859 iter/s, 55.2917s/100 iter), loss = 2.68175
I0212 18:26:30.476686 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.90904 (* 1 = 2.90904 loss)
I0212 18:26:30.476701 12354 sgd_solver.cpp:136] Iteration 70300, lr = 2.94239e-05, m = 0.9
I0212 18:27:25.807119 12354 solver.cpp:314] Iteration 70400 (1.80738 iter/s, 55.3287s/100 iter), loss = 2.89995
I0212 18:27:25.807216 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.62489 (* 1 = 3.62489 loss)
I0212 18:27:25.807230 12354 sgd_solver.cpp:136] Iteration 70400, lr = 2.91878e-05, m = 0.9
I0212 18:28:20.773878 12354 solver.cpp:314] Iteration 70500 (1.81935 iter/s, 54.9648s/100 iter), loss = 3.04607
I0212 18:28:20.776418 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.74946 (* 1 = 2.74946 loss)
I0212 18:28:20.776439 12354 sgd_solver.cpp:136] Iteration 70500, lr = 2.89532e-05, m = 0.9
I0212 18:29:15.546164 12354 solver.cpp:314] Iteration 70600 (1.82581 iter/s, 54.7703s/100 iter), loss = 2.85282
I0212 18:29:15.546278 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.7052 (* 1 = 2.7052 loss)
I0212 18:29:15.546294 12354 sgd_solver.cpp:136] Iteration 70600, lr = 2.87199e-05, m = 0.9
I0212 18:30:09.974869 12354 solver.cpp:314] Iteration 70700 (1.83733 iter/s, 54.4267s/100 iter), loss = 2.84157
I0212 18:30:09.974993 12354 solver.cpp:336]     Train net output #0: mbox_loss = 1.9997 (* 1 = 1.9997 loss)
I0212 18:30:09.975119 12354 sgd_solver.cpp:136] Iteration 70700, lr = 2.84881e-05, m = 0.9
I0212 18:31:05.663978 12354 solver.cpp:314] Iteration 70800 (1.79575 iter/s, 55.6871s/100 iter), loss = 2.77289
I0212 18:31:05.664134 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.18348 (* 1 = 3.18348 loss)
I0212 18:31:05.664149 12354 sgd_solver.cpp:136] Iteration 70800, lr = 2.82576e-05, m = 0.9
I0212 18:32:00.680853 12354 solver.cpp:314] Iteration 70900 (1.81769 iter/s, 55.0149s/100 iter), loss = 2.80704
I0212 18:32:00.680976 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.85642 (* 1 = 2.85642 loss)
I0212 18:32:00.680992 12354 sgd_solver.cpp:136] Iteration 70900, lr = 2.80286e-05, m = 0.9
I0212 18:32:56.298053 12354 solver.cpp:314] Iteration 71000 (1.79807 iter/s, 55.6152s/100 iter), loss = 2.93279
I0212 18:32:56.298207 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.4447 (* 1 = 3.4447 loss)
I0212 18:32:56.298223 12354 sgd_solver.cpp:136] Iteration 71000, lr = 2.78009e-05, m = 0.9
I0212 18:33:52.085599 12354 solver.cpp:314] Iteration 71100 (1.79258 iter/s, 55.7855s/100 iter), loss = 2.9778
I0212 18:33:52.085768 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.7176 (* 1 = 2.7176 loss)
I0212 18:33:52.085805 12354 sgd_solver.cpp:136] Iteration 71100, lr = 2.75747e-05, m = 0.9
I0212 18:34:47.248087 12354 solver.cpp:314] Iteration 71200 (1.81289 iter/s, 55.1605s/100 iter), loss = 2.86263
I0212 18:34:47.248255 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.08259 (* 1 = 2.08259 loss)
I0212 18:34:47.248275 12354 sgd_solver.cpp:136] Iteration 71200, lr = 2.73498e-05, m = 0.9
I0212 18:35:41.815793 12354 solver.cpp:314] Iteration 71300 (1.83265 iter/s, 54.5657s/100 iter), loss = 3.00719
I0212 18:35:41.815891 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.06701 (* 1 = 3.06701 loss)
I0212 18:35:41.815901 12354 sgd_solver.cpp:136] Iteration 71300, lr = 2.71263e-05, m = 0.9
I0212 18:36:37.296692 12354 solver.cpp:314] Iteration 71400 (1.80249 iter/s, 55.4789s/100 iter), loss = 2.86344
I0212 18:36:37.296818 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.7983 (* 1 = 2.7983 loss)
I0212 18:36:37.296838 12354 sgd_solver.cpp:136] Iteration 71400, lr = 2.69042e-05, m = 0.9
I0212 18:37:32.586338 12354 solver.cpp:314] Iteration 71500 (1.80872 iter/s, 55.2876s/100 iter), loss = 2.90662
I0212 18:37:32.586457 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.61353 (* 1 = 2.61353 loss)
I0212 18:37:32.586472 12354 sgd_solver.cpp:136] Iteration 71500, lr = 2.66834e-05, m = 0.9
I0212 18:38:27.175302 12354 solver.cpp:314] Iteration 71600 (1.83194 iter/s, 54.587s/100 iter), loss = 2.69599
I0212 18:38:27.175410 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.40787 (* 1 = 3.40787 loss)
I0212 18:38:27.175549 12354 sgd_solver.cpp:136] Iteration 71600, lr = 2.64641e-05, m = 0.9
I0212 18:39:22.346323 12354 solver.cpp:314] Iteration 71700 (1.81261 iter/s, 55.169s/100 iter), loss = 2.67251
I0212 18:39:22.346436 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.06974 (* 1 = 3.06974 loss)
I0212 18:39:22.346449 12354 sgd_solver.cpp:136] Iteration 71700, lr = 2.6246e-05, m = 0.9
I0212 18:40:17.499413 12354 solver.cpp:314] Iteration 71800 (1.8132 iter/s, 55.1511s/100 iter), loss = 2.77324
I0212 18:40:17.499555 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.98218 (* 1 = 2.98218 loss)
I0212 18:40:17.499572 12354 sgd_solver.cpp:136] Iteration 71800, lr = 2.60293e-05, m = 0.9
I0212 18:40:55.971160 12274 data_reader.cpp:305] Starting prefetch of epoch 15
I0212 18:41:12.789753 12354 solver.cpp:314] Iteration 71900 (1.8087 iter/s, 55.2883s/100 iter), loss = 3.11823
I0212 18:41:12.789819 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.34642 (* 1 = 3.34642 loss)
I0212 18:41:12.789832 12354 sgd_solver.cpp:136] Iteration 71900, lr = 2.5814e-05, m = 0.9
I0212 18:42:07.607085 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_72000.caffemodel
I0212 18:42:07.629904 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_72000.solverstate
I0212 18:42:07.643251 12354 solver.cpp:666] Iteration 72000, Testing net (#0)
I0212 18:42:57.449661 12355 solver.cpp:774] class AP 1: 0.397409
I0212 18:42:57.523371 12355 solver.cpp:774] class AP 2: 0.639776
I0212 18:42:57.534906 12355 solver.cpp:774] class AP 3: 0.63412
I0212 18:42:57.534922 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.557101
I0212 18:42:57.723371 12354 solver.cpp:774] class AP 1: 0.37407
I0212 18:42:57.789875 12354 solver.cpp:774] class AP 2: 0.623184
I0212 18:42:57.800819 12354 solver.cpp:774] class AP 3: 0.628801
I0212 18:42:57.800834 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.542018
I0212 18:42:57.800870 12354 solver.cpp:265] [MultiGPU] Tests completed in 50.1558s
I0212 18:42:58.296041 12354 solver.cpp:314] Iteration 72000 (0.947845 iter/s, 105.502s/100 iter), loss = 3.02823
I0212 18:42:58.296079 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.01431 (* 1 = 2.01431 loss)
I0212 18:42:58.296088 12354 sgd_solver.cpp:136] Iteration 72000, lr = 2.56e-05, m = 0.9
I0212 18:43:53.273324 12354 solver.cpp:314] Iteration 72100 (1.819 iter/s, 54.9753s/100 iter), loss = 3.08563
I0212 18:43:53.273561 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.85661 (* 1 = 2.85661 loss)
I0212 18:43:53.273576 12354 sgd_solver.cpp:136] Iteration 72100, lr = 2.53873e-05, m = 0.9
I0212 18:44:48.710321 12354 solver.cpp:314] Iteration 72200 (1.80392 iter/s, 55.435s/100 iter), loss = 2.82336
I0212 18:44:48.710620 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.71046 (* 1 = 2.71046 loss)
I0212 18:44:48.710749 12354 sgd_solver.cpp:136] Iteration 72200, lr = 2.5176e-05, m = 0.9
I0212 18:45:44.378706 12354 solver.cpp:314] Iteration 72300 (1.79642 iter/s, 55.6664s/100 iter), loss = 2.91318
I0212 18:45:44.378832 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.94945 (* 1 = 2.94945 loss)
I0212 18:45:44.378849 12354 sgd_solver.cpp:136] Iteration 72300, lr = 2.4966e-05, m = 0.9
I0212 18:46:40.071220 12354 solver.cpp:314] Iteration 72400 (1.79564 iter/s, 55.6905s/100 iter), loss = 3.14454
I0212 18:46:40.071318 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.86784 (* 1 = 2.86784 loss)
I0212 18:46:40.071328 12354 sgd_solver.cpp:136] Iteration 72400, lr = 2.47573e-05, m = 0.9
I0212 18:47:35.158269 12354 solver.cpp:314] Iteration 72500 (1.81537 iter/s, 55.085s/100 iter), loss = 2.67588
I0212 18:47:35.158426 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.18272 (* 1 = 3.18272 loss)
I0212 18:47:35.158459 12354 sgd_solver.cpp:136] Iteration 72500, lr = 2.45499e-05, m = 0.9
I0212 18:48:30.338166 12354 solver.cpp:314] Iteration 72600 (1.81232 iter/s, 55.1779s/100 iter), loss = 3.11813
I0212 18:48:30.350239 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.57655 (* 1 = 3.57655 loss)
I0212 18:48:30.350286 12354 sgd_solver.cpp:136] Iteration 72600, lr = 2.43438e-05, m = 0.9
I0212 18:49:26.291368 12354 solver.cpp:314] Iteration 72700 (1.78727 iter/s, 55.9512s/100 iter), loss = 2.76782
I0212 18:49:26.291488 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.13409 (* 1 = 3.13409 loss)
I0212 18:49:26.291503 12354 sgd_solver.cpp:136] Iteration 72700, lr = 2.4139e-05, m = 0.9
I0212 18:50:20.842150 12354 solver.cpp:314] Iteration 72800 (1.83322 iter/s, 54.5488s/100 iter), loss = 2.99118
I0212 18:50:20.842253 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.75241 (* 1 = 3.75241 loss)
I0212 18:50:20.842272 12354 sgd_solver.cpp:136] Iteration 72800, lr = 2.39355e-05, m = 0.9
I0212 18:51:16.090162 12354 solver.cpp:314] Iteration 72900 (1.81009 iter/s, 55.246s/100 iter), loss = 3.05359
I0212 18:51:16.090273 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.52476 (* 1 = 2.52476 loss)
I0212 18:51:16.090292 12354 sgd_solver.cpp:136] Iteration 72900, lr = 2.37333e-05, m = 0.9
I0212 18:52:10.965761 12354 solver.cpp:314] Iteration 73000 (1.82237 iter/s, 54.8736s/100 iter), loss = 2.84696
I0212 18:52:10.965915 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.84834 (* 1 = 2.84834 loss)
I0212 18:52:10.965931 12354 sgd_solver.cpp:136] Iteration 73000, lr = 2.35324e-05, m = 0.9
I0212 18:53:06.632247 12354 solver.cpp:314] Iteration 73100 (1.79648 iter/s, 55.6645s/100 iter), loss = 2.87883
I0212 18:53:06.632386 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.46679 (* 1 = 3.46679 loss)
I0212 18:53:06.632402 12354 sgd_solver.cpp:136] Iteration 73100, lr = 2.33328e-05, m = 0.9
I0212 18:54:02.054328 12354 solver.cpp:314] Iteration 73200 (1.8044 iter/s, 55.4201s/100 iter), loss = 2.81984
I0212 18:54:02.054847 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.17392 (* 1 = 4.17392 loss)
I0212 18:54:02.054862 12354 sgd_solver.cpp:136] Iteration 73200, lr = 2.31344e-05, m = 0.9
I0212 18:54:57.342442 12354 solver.cpp:314] Iteration 73300 (1.80877 iter/s, 55.2861s/100 iter), loss = 2.8724
I0212 18:54:57.342639 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.65493 (* 1 = 2.65493 loss)
I0212 18:54:57.342679 12354 sgd_solver.cpp:136] Iteration 73300, lr = 2.29373e-05, m = 0.9
I0212 18:55:52.552579 12354 solver.cpp:314] Iteration 73400 (1.81133 iter/s, 55.2081s/100 iter), loss = 2.69997
I0212 18:55:52.552719 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.77989 (* 1 = 2.77989 loss)
I0212 18:55:52.552736 12354 sgd_solver.cpp:136] Iteration 73400, lr = 2.27415e-05, m = 0.9
I0212 18:56:48.300915 12354 solver.cpp:314] Iteration 73500 (1.79384 iter/s, 55.7463s/100 iter), loss = 3.16322
I0212 18:56:48.301074 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.85878 (* 1 = 2.85878 loss)
I0212 18:56:48.301105 12354 sgd_solver.cpp:136] Iteration 73500, lr = 2.25469e-05, m = 0.9
I0212 18:57:43.098316 12354 solver.cpp:314] Iteration 73600 (1.82497 iter/s, 54.7954s/100 iter), loss = 3.00661
I0212 18:57:43.098443 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.57156 (* 1 = 2.57156 loss)
I0212 18:57:43.098456 12354 sgd_solver.cpp:136] Iteration 73600, lr = 2.23536e-05, m = 0.9
I0212 18:58:39.781086 12354 solver.cpp:314] Iteration 73700 (1.76427 iter/s, 56.6807s/100 iter), loss = 2.83516
I0212 18:58:39.781213 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.89141 (* 1 = 2.89141 loss)
I0212 18:58:39.781231 12354 sgd_solver.cpp:136] Iteration 73700, lr = 2.21615e-05, m = 0.9
I0212 18:59:34.617988 12354 solver.cpp:314] Iteration 73800 (1.82366 iter/s, 54.8349s/100 iter), loss = 2.91754
I0212 18:59:34.618130 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.68033 (* 1 = 2.68033 loss)
I0212 18:59:34.618146 12354 sgd_solver.cpp:136] Iteration 73800, lr = 2.19706e-05, m = 0.9
I0212 19:00:29.856539 12354 solver.cpp:314] Iteration 73900 (1.8104 iter/s, 55.2365s/100 iter), loss = 3.06066
I0212 19:00:29.856645 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.54131 (* 1 = 3.54131 loss)
I0212 19:00:29.856662 12354 sgd_solver.cpp:136] Iteration 73900, lr = 2.1781e-05, m = 0.9
I0212 19:01:24.740692 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_74000.caffemodel
I0212 19:01:24.763087 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_74000.solverstate
I0212 19:01:24.776340 12354 solver.cpp:666] Iteration 74000, Testing net (#0)
I0212 19:02:14.720031 12354 solver.cpp:774] class AP 1: 0.379204
I0212 19:02:14.786571 12354 solver.cpp:774] class AP 2: 0.626383
I0212 19:02:14.797474 12354 solver.cpp:774] class AP 3: 0.630667
I0212 19:02:14.797492 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.545418
I0212 19:02:15.011780 12355 solver.cpp:774] class AP 1: 0.397896
I0212 19:02:15.074589 12355 solver.cpp:774] class AP 2: 0.642986
I0212 19:02:15.085364 12355 solver.cpp:774] class AP 3: 0.634163
I0212 19:02:15.085381 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.558348
I0212 19:02:15.085494 12354 solver.cpp:265] [MultiGPU] Tests completed in 50.3073s
I0212 19:02:15.524325 12354 solver.cpp:314] Iteration 74000 (0.946397 iter/s, 105.664s/100 iter), loss = 2.97022
I0212 19:02:15.524380 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.87793 (* 1 = 2.87793 loss)
I0212 19:02:15.524396 12354 sgd_solver.cpp:136] Iteration 74000, lr = 2.15927e-05, m = 0.9
I0212 19:03:10.755264 12354 solver.cpp:314] Iteration 74100 (1.81065 iter/s, 55.2289s/100 iter), loss = 2.99508
I0212 19:03:10.755430 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.49312 (* 1 = 4.49312 loss)
I0212 19:03:10.755445 12354 sgd_solver.cpp:136] Iteration 74100, lr = 2.14055e-05, m = 0.9
I0212 19:04:06.527868 12354 solver.cpp:314] Iteration 74200 (1.79306 iter/s, 55.7706s/100 iter), loss = 2.99756
I0212 19:04:06.527997 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.92345 (* 1 = 2.92345 loss)
I0212 19:04:06.528017 12354 sgd_solver.cpp:136] Iteration 74200, lr = 2.12196e-05, m = 0.9
I0212 19:05:02.154409 12354 solver.cpp:314] Iteration 74300 (1.79777 iter/s, 55.6245s/100 iter), loss = 2.84933
I0212 19:05:02.154521 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.68881 (* 1 = 2.68881 loss)
I0212 19:05:02.154541 12354 sgd_solver.cpp:136] Iteration 74300, lr = 2.10349e-05, m = 0.9
I0212 19:05:57.423251 12354 solver.cpp:314] Iteration 74400 (1.8094 iter/s, 55.2668s/100 iter), loss = 2.62185
I0212 19:05:57.423369 12354 solver.cpp:336]     Train net output #0: mbox_loss = 1.95066 (* 1 = 1.95066 loss)
I0212 19:05:57.423383 12354 sgd_solver.cpp:136] Iteration 74400, lr = 2.08514e-05, m = 0.9
I0212 19:06:53.043017 12354 solver.cpp:314] Iteration 74500 (1.79799 iter/s, 55.6177s/100 iter), loss = 2.92698
I0212 19:06:53.043102 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.94169 (* 1 = 2.94169 loss)
I0212 19:06:53.043112 12354 sgd_solver.cpp:136] Iteration 74500, lr = 2.06691e-05, m = 0.9
I0212 19:07:49.547291 12354 solver.cpp:314] Iteration 74600 (1.76984 iter/s, 56.5022s/100 iter), loss = 2.96053
I0212 19:07:49.547418 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.35611 (* 1 = 2.35611 loss)
I0212 19:07:49.547433 12354 sgd_solver.cpp:136] Iteration 74600, lr = 2.04879e-05, m = 0.9
I0212 19:08:17.249267 12274 data_reader.cpp:305] Starting prefetch of epoch 16
I0212 19:08:45.240774 12354 solver.cpp:314] Iteration 74700 (1.79561 iter/s, 55.6914s/100 iter), loss = 2.80984
I0212 19:08:45.240898 12354 solver.cpp:336]     Train net output #0: mbox_loss = 1.93159 (* 1 = 1.93159 loss)
I0212 19:08:45.240916 12354 sgd_solver.cpp:136] Iteration 74700, lr = 2.0308e-05, m = 0.9
I0212 19:09:40.011137 12354 solver.cpp:314] Iteration 74800 (1.82587 iter/s, 54.7683s/100 iter), loss = 2.82551
I0212 19:09:40.011262 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.35813 (* 1 = 2.35813 loss)
I0212 19:09:40.011279 12354 sgd_solver.cpp:136] Iteration 74800, lr = 2.01293e-05, m = 0.9
I0212 19:10:35.044128 12354 solver.cpp:314] Iteration 74900 (1.81716 iter/s, 55.031s/100 iter), loss = 3.12338
I0212 19:10:35.044235 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.86466 (* 1 = 2.86466 loss)
I0212 19:10:35.044252 12354 sgd_solver.cpp:136] Iteration 74900, lr = 1.99518e-05, m = 0.9
I0212 19:11:30.797824 12354 solver.cpp:314] Iteration 75000 (1.79367 iter/s, 55.7516s/100 iter), loss = 3.06733
I0212 19:11:30.797960 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.75478 (* 1 = 3.75478 loss)
I0212 19:11:30.797974 12354 sgd_solver.cpp:136] Iteration 75000, lr = 1.97754e-05, m = 0.9
I0212 19:12:26.126080 12354 solver.cpp:314] Iteration 75100 (1.80746 iter/s, 55.3262s/100 iter), loss = 3.07452
I0212 19:12:26.126385 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.59495 (* 1 = 2.59495 loss)
I0212 19:12:26.126400 12354 sgd_solver.cpp:136] Iteration 75100, lr = 1.96002e-05, m = 0.9
I0212 19:13:21.139838 12354 solver.cpp:314] Iteration 75200 (1.81779 iter/s, 55.0117s/100 iter), loss = 2.77943
I0212 19:13:21.140005 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.58012 (* 1 = 2.58012 loss)
I0212 19:13:21.140022 12354 sgd_solver.cpp:136] Iteration 75200, lr = 1.94262e-05, m = 0.9
I0212 19:14:16.453847 12354 solver.cpp:314] Iteration 75300 (1.80793 iter/s, 55.312s/100 iter), loss = 2.96226
I0212 19:14:16.453985 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.78212 (* 1 = 2.78212 loss)
I0212 19:14:16.454001 12354 sgd_solver.cpp:136] Iteration 75300, lr = 1.92533e-05, m = 0.9
I0212 19:15:11.185019 12354 solver.cpp:314] Iteration 75400 (1.82718 iter/s, 54.7292s/100 iter), loss = 2.81416
I0212 19:15:11.185142 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.84693 (* 1 = 3.84693 loss)
I0212 19:15:11.185156 12354 sgd_solver.cpp:136] Iteration 75400, lr = 1.90816e-05, m = 0.9
I0212 19:16:05.194819 12354 solver.cpp:314] Iteration 75500 (1.85158 iter/s, 54.0078s/100 iter), loss = 2.96625
I0212 19:16:05.194948 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.92375 (* 1 = 2.92375 loss)
I0212 19:16:05.194964 12354 sgd_solver.cpp:136] Iteration 75500, lr = 1.8911e-05, m = 0.9
I0212 19:17:00.506321 12354 solver.cpp:314] Iteration 75600 (1.80801 iter/s, 55.3095s/100 iter), loss = 2.95214
I0212 19:17:00.506451 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.59837 (* 1 = 2.59837 loss)
I0212 19:17:00.506466 12354 sgd_solver.cpp:136] Iteration 75600, lr = 1.87416e-05, m = 0.9
I0212 19:17:55.698702 12354 solver.cpp:314] Iteration 75700 (1.81191 iter/s, 55.1904s/100 iter), loss = 2.74771
I0212 19:17:55.698840 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.87049 (* 1 = 2.87049 loss)
I0212 19:17:55.698855 12354 sgd_solver.cpp:136] Iteration 75700, lr = 1.85733e-05, m = 0.9
I0212 19:18:51.216492 12354 solver.cpp:314] Iteration 75800 (1.80129 iter/s, 55.5158s/100 iter), loss = 3.15201
I0212 19:18:51.216626 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.46379 (* 1 = 4.46379 loss)
I0212 19:18:51.216642 12354 sgd_solver.cpp:136] Iteration 75800, lr = 1.84062e-05, m = 0.9
I0212 19:19:46.095270 12354 solver.cpp:314] Iteration 75900 (1.82227 iter/s, 54.8768s/100 iter), loss = 2.94638
I0212 19:19:46.097740 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.03473 (* 1 = 3.03473 loss)
I0212 19:19:46.097760 12354 sgd_solver.cpp:136] Iteration 75900, lr = 1.82402e-05, m = 0.9
I0212 19:20:41.050149 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_76000.caffemodel
I0212 19:20:41.103075 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_76000.solverstate
I0212 19:20:41.116498 12354 solver.cpp:666] Iteration 76000, Testing net (#0)
I0212 19:21:31.110478 12354 solver.cpp:774] class AP 1: 0.376245
I0212 19:21:31.184069 12354 solver.cpp:774] class AP 2: 0.622459
I0212 19:21:31.195230 12354 solver.cpp:774] class AP 3: 0.631407
I0212 19:21:31.195250 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.54337
I0212 19:21:31.206763 12355 solver.cpp:774] class AP 1: 0.392852
I0212 19:21:31.274756 12355 solver.cpp:774] class AP 2: 0.643195
I0212 19:21:31.285454 12355 solver.cpp:774] class AP 3: 0.630423
I0212 19:21:31.285465 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.55549
I0212 19:21:31.285574 12354 solver.cpp:265] [MultiGPU] Tests completed in 50.1672s
I0212 19:21:31.629261 12354 solver.cpp:314] Iteration 76000 (0.947597 iter/s, 105.53s/100 iter), loss = 2.91473
I0212 19:21:31.629317 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.22475 (* 1 = 3.22475 loss)
I0212 19:21:31.629331 12354 sgd_solver.cpp:136] Iteration 76000, lr = 1.80753e-05, m = 0.9
I0212 19:22:26.814141 12354 solver.cpp:314] Iteration 76100 (1.81216 iter/s, 55.1829s/100 iter), loss = 3.07582
I0212 19:22:26.814296 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.78625 (* 1 = 2.78625 loss)
I0212 19:22:26.814316 12354 sgd_solver.cpp:136] Iteration 76100, lr = 1.79116e-05, m = 0.9
I0212 19:23:22.588534 12354 solver.cpp:314] Iteration 76200 (1.793 iter/s, 55.7723s/100 iter), loss = 3.10658
I0212 19:23:22.588668 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.43924 (* 1 = 3.43924 loss)
I0212 19:23:22.588683 12354 sgd_solver.cpp:136] Iteration 76200, lr = 1.77489e-05, m = 0.9
I0212 19:24:18.512296 12354 solver.cpp:314] Iteration 76300 (1.78821 iter/s, 55.9217s/100 iter), loss = 2.93557
I0212 19:24:18.512424 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.09998 (* 1 = 4.09998 loss)
I0212 19:24:18.512439 12354 sgd_solver.cpp:136] Iteration 76300, lr = 1.75874e-05, m = 0.9
I0212 19:25:13.048522 12354 solver.cpp:314] Iteration 76400 (1.83371 iter/s, 54.5342s/100 iter), loss = 3.03421
I0212 19:25:13.048665 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.02739 (* 1 = 4.02739 loss)
I0212 19:25:13.048820 12354 sgd_solver.cpp:136] Iteration 76400, lr = 1.74269e-05, m = 0.9
I0212 19:26:08.449643 12354 solver.cpp:314] Iteration 76500 (1.80508 iter/s, 55.3991s/100 iter), loss = 3.03726
I0212 19:26:08.449739 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.03179 (* 1 = 3.03179 loss)
I0212 19:26:08.449749 12354 sgd_solver.cpp:136] Iteration 76500, lr = 1.72676e-05, m = 0.9
I0212 19:27:03.572412 12354 solver.cpp:314] Iteration 76600 (1.8142 iter/s, 55.1207s/100 iter), loss = 2.81314
I0212 19:27:03.572543 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.4298 (* 1 = 2.4298 loss)
I0212 19:27:03.572561 12354 sgd_solver.cpp:136] Iteration 76600, lr = 1.71094e-05, m = 0.9
I0212 19:27:59.179489 12354 solver.cpp:314] Iteration 76700 (1.7984 iter/s, 55.605s/100 iter), loss = 2.77816
I0212 19:27:59.179610 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.60952 (* 1 = 2.60952 loss)
I0212 19:27:59.179623 12354 sgd_solver.cpp:136] Iteration 76700, lr = 1.69522e-05, m = 0.9
I0212 19:28:54.978924 12354 solver.cpp:314] Iteration 76800 (1.7922 iter/s, 55.7974s/100 iter), loss = 2.97574
I0212 19:28:54.979034 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.73975 (* 1 = 2.73975 loss)
I0212 19:28:54.979053 12354 sgd_solver.cpp:136] Iteration 76800, lr = 1.67962e-05, m = 0.9
I0212 19:29:50.606762 12354 solver.cpp:314] Iteration 76900 (1.79773 iter/s, 55.6258s/100 iter), loss = 2.85511
I0212 19:29:50.606891 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.81133 (* 1 = 2.81133 loss)
I0212 19:29:50.607038 12354 sgd_solver.cpp:136] Iteration 76900, lr = 1.66412e-05, m = 0.9
I0212 19:30:45.432440 12354 solver.cpp:314] Iteration 77000 (1.82403 iter/s, 54.8237s/100 iter), loss = 2.87871
I0212 19:30:45.432569 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.09755 (* 1 = 3.09755 loss)
I0212 19:30:45.432585 12354 sgd_solver.cpp:136] Iteration 77000, lr = 1.64873e-05, m = 0.9
I0212 19:31:41.683545 12354 solver.cpp:314] Iteration 77100 (1.77781 iter/s, 56.249s/100 iter), loss = 3.0583
I0212 19:31:41.683677 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.7924 (* 1 = 3.7924 loss)
I0212 19:31:41.683692 12354 sgd_solver.cpp:136] Iteration 77100, lr = 1.63344e-05, m = 0.9
I0212 19:32:36.864858 12354 solver.cpp:314] Iteration 77200 (1.81227 iter/s, 55.1793s/100 iter), loss = 3.03662
I0212 19:32:36.864985 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.71701 (* 1 = 2.71701 loss)
I0212 19:32:36.865000 12354 sgd_solver.cpp:136] Iteration 77200, lr = 1.61827e-05, m = 0.9
I0212 19:33:31.890843 12354 solver.cpp:314] Iteration 77300 (1.81739 iter/s, 55.024s/100 iter), loss = 2.77719
I0212 19:33:31.890946 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.18915 (* 1 = 2.18915 loss)
I0212 19:33:31.890957 12354 sgd_solver.cpp:136] Iteration 77300, lr = 1.6032e-05, m = 0.9
I0212 19:34:27.954638 12354 solver.cpp:314] Iteration 77400 (1.78375 iter/s, 56.0617s/100 iter), loss = 3.07618
I0212 19:34:27.954803 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.85883 (* 1 = 2.85883 loss)
I0212 19:34:27.954818 12354 sgd_solver.cpp:136] Iteration 77400, lr = 1.58823e-05, m = 0.9
I0212 19:35:23.019541 12354 solver.cpp:314] Iteration 77500 (1.81611 iter/s, 55.0629s/100 iter), loss = 2.90101
I0212 19:35:23.019680 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.38749 (* 1 = 3.38749 loss)
I0212 19:35:23.019695 12354 sgd_solver.cpp:136] Iteration 77500, lr = 1.57337e-05, m = 0.9
I0212 19:36:17.450687 12354 solver.cpp:314] Iteration 77600 (1.83725 iter/s, 54.4292s/100 iter), loss = 3.09037
I0212 19:36:17.450806 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.67529 (* 1 = 3.67529 loss)
I0212 19:36:17.450824 12354 sgd_solver.cpp:136] Iteration 77600, lr = 1.55861e-05, m = 0.9
I0212 19:37:12.062613 12354 solver.cpp:314] Iteration 77700 (1.83117 iter/s, 54.6099s/100 iter), loss = 2.929
I0212 19:37:12.062706 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.93943 (* 1 = 2.93943 loss)
I0212 19:37:12.062716 12354 sgd_solver.cpp:136] Iteration 77700, lr = 1.54396e-05, m = 0.9
I0212 19:37:56.072659 12274 data_reader.cpp:305] Starting prefetch of epoch 17
I0212 19:38:07.735694 12354 solver.cpp:314] Iteration 77800 (1.79627 iter/s, 55.671s/100 iter), loss = 2.92462
I0212 19:38:07.735744 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.08943 (* 1 = 2.08943 loss)
I0212 19:38:07.735760 12354 sgd_solver.cpp:136] Iteration 77800, lr = 1.52941e-05, m = 0.9
I0212 19:39:03.454953 12354 solver.cpp:314] Iteration 77900 (1.79478 iter/s, 55.7172s/100 iter), loss = 3.00022
I0212 19:39:03.455049 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.41562 (* 1 = 3.41562 loss)
I0212 19:39:03.455060 12354 sgd_solver.cpp:136] Iteration 77900, lr = 1.51497e-05, m = 0.9
I0212 19:39:58.299108 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_78000.caffemodel
I0212 19:39:58.340415 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_78000.solverstate
I0212 19:39:58.353581 12354 solver.cpp:666] Iteration 78000, Testing net (#0)
I0212 19:40:48.490377 12355 solver.cpp:774] class AP 1: 0.396802
I0212 19:40:48.555047 12355 solver.cpp:774] class AP 2: 0.639281
I0212 19:40:48.565959 12355 solver.cpp:774] class AP 3: 0.631143
I0212 19:40:48.565971 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.555742
I0212 19:40:49.125835 12354 solver.cpp:774] class AP 1: 0.376651
I0212 19:40:49.192533 12354 solver.cpp:774] class AP 2: 0.626031
I0212 19:40:49.203675 12354 solver.cpp:774] class AP 3: 0.631648
I0212 19:40:49.203689 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.544777
I0212 19:40:49.203735 12354 solver.cpp:265] [MultiGPU] Tests completed in 50.8483s
I0212 19:40:49.624197 12354 solver.cpp:314] Iteration 78000 (0.941927 iter/s, 106.165s/100 iter), loss = 2.827
I0212 19:40:49.624246 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.35054 (* 1 = 2.35054 loss)
I0212 19:40:49.624259 12354 sgd_solver.cpp:136] Iteration 78000, lr = 1.50063e-05, m = 0.9
I0212 19:41:44.382164 12354 solver.cpp:314] Iteration 78100 (1.82629 iter/s, 54.756s/100 iter), loss = 3.03975
I0212 19:41:44.382299 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.55554 (* 1 = 2.55554 loss)
I0212 19:41:44.382315 12354 sgd_solver.cpp:136] Iteration 78100, lr = 1.48638e-05, m = 0.9
I0212 19:42:39.621148 12354 solver.cpp:314] Iteration 78200 (1.81038 iter/s, 55.237s/100 iter), loss = 2.84501
I0212 19:42:39.621264 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.4873 (* 1 = 3.4873 loss)
I0212 19:42:39.621284 12354 sgd_solver.cpp:136] Iteration 78200, lr = 1.47225e-05, m = 0.9
I0212 19:43:35.577004 12354 solver.cpp:314] Iteration 78300 (1.78719 iter/s, 55.9538s/100 iter), loss = 3.12194
I0212 19:43:35.577263 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.3378 (* 1 = 3.3378 loss)
I0212 19:43:35.577302 12354 sgd_solver.cpp:136] Iteration 78300, lr = 1.45821e-05, m = 0.9
I0212 19:44:31.023732 12354 solver.cpp:314] Iteration 78400 (1.80367 iter/s, 55.4427s/100 iter), loss = 2.88917
I0212 19:44:31.023833 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.48383 (* 1 = 2.48383 loss)
I0212 19:44:31.023847 12354 sgd_solver.cpp:136] Iteration 78400, lr = 1.44427e-05, m = 0.9
I0212 19:45:26.784128 12354 solver.cpp:314] Iteration 78500 (1.79345 iter/s, 55.7584s/100 iter), loss = 2.66839
I0212 19:45:26.784237 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.19744 (* 1 = 2.19744 loss)
I0212 19:45:26.784255 12354 sgd_solver.cpp:136] Iteration 78500, lr = 1.43043e-05, m = 0.9
I0212 19:46:22.574573 12354 solver.cpp:314] Iteration 78600 (1.79249 iter/s, 55.7884s/100 iter), loss = 2.88579
I0212 19:46:22.574687 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.92509 (* 1 = 2.92509 loss)
I0212 19:46:22.574703 12354 sgd_solver.cpp:136] Iteration 78600, lr = 1.4167e-05, m = 0.9
I0212 19:47:18.265266 12354 solver.cpp:314] Iteration 78700 (1.7957 iter/s, 55.6887s/100 iter), loss = 2.66066
I0212 19:47:18.265364 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.86582 (* 1 = 2.86582 loss)
I0212 19:47:18.265378 12354 sgd_solver.cpp:136] Iteration 78700, lr = 1.40306e-05, m = 0.9
I0212 19:48:14.443589 12354 solver.cpp:314] Iteration 78800 (1.78011 iter/s, 56.1763s/100 iter), loss = 2.89628
I0212 19:48:14.443703 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.52785 (* 1 = 2.52785 loss)
I0212 19:48:14.443717 12354 sgd_solver.cpp:136] Iteration 78800, lr = 1.38952e-05, m = 0.9
I0212 19:49:10.859997 12354 solver.cpp:314] Iteration 78900 (1.7726 iter/s, 56.4143s/100 iter), loss = 2.63431
I0212 19:49:10.860116 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.53977 (* 1 = 3.53977 loss)
I0212 19:49:10.860131 12354 sgd_solver.cpp:136] Iteration 78900, lr = 1.37608e-05, m = 0.9
I0212 19:50:05.630179 12354 solver.cpp:314] Iteration 79000 (1.82588 iter/s, 54.7682s/100 iter), loss = 2.93326
I0212 19:50:05.630328 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.69226 (* 1 = 3.69226 loss)
I0212 19:50:05.630355 12354 sgd_solver.cpp:136] Iteration 79000, lr = 1.36273e-05, m = 0.9
I0212 19:51:01.444707 12354 solver.cpp:314] Iteration 79100 (1.79171 iter/s, 55.8125s/100 iter), loss = 2.83132
I0212 19:51:01.444819 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.95171 (* 1 = 2.95171 loss)
I0212 19:51:01.444834 12354 sgd_solver.cpp:136] Iteration 79100, lr = 1.34949e-05, m = 0.9
I0212 19:51:56.757354 12354 solver.cpp:314] Iteration 79200 (1.80797 iter/s, 55.3106s/100 iter), loss = 3.15608
I0212 19:51:56.757457 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.4771 (* 1 = 2.4771 loss)
I0212 19:51:56.757472 12354 sgd_solver.cpp:136] Iteration 79200, lr = 1.33634e-05, m = 0.9
I0212 19:52:52.106498 12354 solver.cpp:314] Iteration 79300 (1.80678 iter/s, 55.3471s/100 iter), loss = 3.00701
I0212 19:52:52.106616 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.98043 (* 1 = 3.98043 loss)
I0212 19:52:52.106633 12354 sgd_solver.cpp:136] Iteration 79300, lr = 1.32328e-05, m = 0.9
I0212 19:53:47.710888 12354 solver.cpp:314] Iteration 79400 (1.79849 iter/s, 55.6023s/100 iter), loss = 3.00422
I0212 19:53:47.711980 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.32524 (* 1 = 3.32524 loss)
I0212 19:53:47.712000 12354 sgd_solver.cpp:136] Iteration 79400, lr = 1.31033e-05, m = 0.9
I0212 19:54:43.110340 12354 solver.cpp:314] Iteration 79500 (1.80514 iter/s, 55.3974s/100 iter), loss = 2.95877
I0212 19:54:43.110460 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.05259 (* 1 = 3.05259 loss)
I0212 19:54:43.110476 12354 sgd_solver.cpp:136] Iteration 79500, lr = 1.29746e-05, m = 0.9
I0212 19:55:38.650012 12354 solver.cpp:314] Iteration 79600 (1.80058 iter/s, 55.5376s/100 iter), loss = 2.72823
I0212 19:55:38.654172 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.69171 (* 1 = 2.69171 loss)
I0212 19:55:38.654198 12354 sgd_solver.cpp:136] Iteration 79600, lr = 1.2847e-05, m = 0.9
I0212 19:56:34.567826 12354 solver.cpp:314] Iteration 79700 (1.7884 iter/s, 55.9158s/100 iter), loss = 2.95135
I0212 19:56:34.567931 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.62979 (* 1 = 2.62979 loss)
I0212 19:56:34.567942 12354 sgd_solver.cpp:136] Iteration 79700, lr = 1.27202e-05, m = 0.9
I0212 19:57:29.649027 12354 solver.cpp:314] Iteration 79800 (1.81557 iter/s, 55.0792s/100 iter), loss = 2.74482
I0212 19:57:29.649139 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.59386 (* 1 = 2.59386 loss)
I0212 19:57:29.649154 12354 sgd_solver.cpp:136] Iteration 79800, lr = 1.25944e-05, m = 0.9
I0212 19:58:25.113652 12354 solver.cpp:314] Iteration 79900 (1.80302 iter/s, 55.4626s/100 iter), loss = 2.84715
I0212 19:58:25.113795 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.29179 (* 1 = 3.29179 loss)
I0212 19:58:25.113809 12354 sgd_solver.cpp:136] Iteration 79900, lr = 1.24696e-05, m = 0.9
I0212 19:59:19.606328 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_80000.caffemodel
I0212 19:59:19.629330 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_80000.solverstate
I0212 19:59:19.642750 12354 solver.cpp:666] Iteration 80000, Testing net (#0)
I0212 20:00:10.138268 12355 solver.cpp:774] class AP 1: 0.394077
I0212 20:00:10.193614 12355 solver.cpp:774] class AP 2: 0.643842
I0212 20:00:10.203516 12355 solver.cpp:774] class AP 3: 0.63275
I0212 20:00:10.203546 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.55689
I0212 20:00:10.502688 12354 solver.cpp:774] class AP 1: 0.378538
I0212 20:00:10.577489 12354 solver.cpp:774] class AP 2: 0.628106
I0212 20:00:10.588654 12354 solver.cpp:774] class AP 3: 0.628953
I0212 20:00:10.588666 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.545199
I0212 20:00:10.588701 12354 solver.cpp:265] [MultiGPU] Tests completed in 50.9441s
I0212 20:00:10.925357 12354 solver.cpp:314] Iteration 80000 (0.94511 iter/s, 105.808s/100 iter), loss = 3.06694
I0212 20:00:10.925416 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.7284 (* 1 = 3.7284 loss)
I0212 20:00:10.925429 12354 sgd_solver.cpp:136] Iteration 80000, lr = 1.23457e-05, m = 0.9
I0212 20:01:05.599635 12354 solver.cpp:314] Iteration 80100 (1.82908 iter/s, 54.6723s/100 iter), loss = 3.02791
I0212 20:01:05.599756 12354 solver.cpp:336]     Train net output #0: mbox_loss = 5.04355 (* 1 = 5.04355 loss)
I0212 20:01:05.599772 12354 sgd_solver.cpp:136] Iteration 80100, lr = 1.22227e-05, m = 0.9
I0212 20:02:00.853924 12354 solver.cpp:314] Iteration 80200 (1.80988 iter/s, 55.2523s/100 iter), loss = 2.77398
I0212 20:02:00.854058 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.67154 (* 1 = 2.67154 loss)
I0212 20:02:00.854079 12354 sgd_solver.cpp:136] Iteration 80200, lr = 1.21006e-05, m = 0.9
I0212 20:02:55.954155 12354 solver.cpp:314] Iteration 80300 (1.81494 iter/s, 55.0982s/100 iter), loss = 2.79428
I0212 20:02:55.954285 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.10991 (* 1 = 3.10991 loss)
I0212 20:02:55.954305 12354 sgd_solver.cpp:136] Iteration 80300, lr = 1.19795e-05, m = 0.9
I0212 20:03:51.454282 12354 solver.cpp:314] Iteration 80400 (1.80186 iter/s, 55.4981s/100 iter), loss = 2.77795
I0212 20:03:51.454393 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.17618 (* 1 = 2.17618 loss)
I0212 20:03:51.454407 12354 sgd_solver.cpp:136] Iteration 80400, lr = 1.18592e-05, m = 0.9
I0212 20:04:47.068167 12354 solver.cpp:314] Iteration 80500 (1.79818 iter/s, 55.6118s/100 iter), loss = 2.96838
I0212 20:04:47.068383 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.26323 (* 1 = 3.26323 loss)
I0212 20:04:47.068423 12354 sgd_solver.cpp:136] Iteration 80500, lr = 1.17399e-05, m = 0.9
I0212 20:05:21.289333 12274 data_reader.cpp:305] Starting prefetch of epoch 18
I0212 20:05:43.484007 12354 solver.cpp:314] Iteration 80600 (1.77262 iter/s, 56.4138s/100 iter), loss = 2.74005
I0212 20:05:43.484061 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.66113 (* 1 = 2.66113 loss)
I0212 20:05:43.484073 12354 sgd_solver.cpp:136] Iteration 80600, lr = 1.16214e-05, m = 0.9
I0212 20:06:38.898334 12354 solver.cpp:314] Iteration 80700 (1.80465 iter/s, 55.4123s/100 iter), loss = 2.86398
I0212 20:06:38.898546 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.35632 (* 1 = 3.35632 loss)
I0212 20:06:38.898584 12354 sgd_solver.cpp:136] Iteration 80700, lr = 1.15039e-05, m = 0.9
I0212 20:07:33.990996 12354 solver.cpp:314] Iteration 80800 (1.81519 iter/s, 55.0906s/100 iter), loss = 2.92852
I0212 20:07:33.991140 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.03586 (* 1 = 4.03586 loss)
I0212 20:07:33.991155 12354 sgd_solver.cpp:136] Iteration 80800, lr = 1.13873e-05, m = 0.9
I0212 20:08:28.984048 12354 solver.cpp:314] Iteration 80900 (1.81848 iter/s, 54.991s/100 iter), loss = 2.86974
I0212 20:08:28.984160 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.45691 (* 1 = 2.45691 loss)
I0212 20:08:28.984174 12354 sgd_solver.cpp:136] Iteration 80900, lr = 1.12715e-05, m = 0.9
I0212 20:09:24.301481 12354 solver.cpp:314] Iteration 81000 (1.80781 iter/s, 55.3154s/100 iter), loss = 3.03203
I0212 20:09:24.301599 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.80996 (* 1 = 2.80996 loss)
I0212 20:09:24.301615 12354 sgd_solver.cpp:136] Iteration 81000, lr = 1.11566e-05, m = 0.9
I0212 20:10:19.780143 12354 solver.cpp:314] Iteration 81100 (1.80256 iter/s, 55.4766s/100 iter), loss = 2.91543
I0212 20:10:19.780251 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.99418 (* 1 = 2.99418 loss)
I0212 20:10:19.780262 12354 sgd_solver.cpp:136] Iteration 81100, lr = 1.10427e-05, m = 0.9
I0212 20:11:14.927937 12354 solver.cpp:314] Iteration 81200 (1.81338 iter/s, 55.1458s/100 iter), loss = 2.81363
I0212 20:11:14.928068 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.88477 (* 1 = 3.88477 loss)
I0212 20:11:14.928083 12354 sgd_solver.cpp:136] Iteration 81200, lr = 1.09295e-05, m = 0.9
I0212 20:12:09.603996 12354 solver.cpp:314] Iteration 81300 (1.82902 iter/s, 54.6741s/100 iter), loss = 3.17452
I0212 20:12:09.604123 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.58754 (* 1 = 2.58754 loss)
I0212 20:12:09.604137 12354 sgd_solver.cpp:136] Iteration 81300, lr = 1.08173e-05, m = 0.9
I0212 20:13:04.915720 12354 solver.cpp:314] Iteration 81400 (1.808 iter/s, 55.3097s/100 iter), loss = 2.9974
I0212 20:13:04.915853 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.82524 (* 1 = 3.82524 loss)
I0212 20:13:04.915868 12354 sgd_solver.cpp:136] Iteration 81400, lr = 1.07059e-05, m = 0.9
I0212 20:14:00.243182 12354 solver.cpp:314] Iteration 81500 (1.80749 iter/s, 55.3254s/100 iter), loss = 2.6896
I0212 20:14:00.243361 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.82831 (* 1 = 2.82831 loss)
I0212 20:14:00.243396 12354 sgd_solver.cpp:136] Iteration 81500, lr = 1.05954e-05, m = 0.9
I0212 20:14:55.225651 12354 solver.cpp:314] Iteration 81600 (1.81883 iter/s, 54.9804s/100 iter), loss = 2.73185
I0212 20:14:55.225778 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.97991 (* 1 = 2.97991 loss)
I0212 20:14:55.225793 12354 sgd_solver.cpp:136] Iteration 81600, lr = 1.04858e-05, m = 0.9
I0212 20:15:49.903617 12354 solver.cpp:314] Iteration 81700 (1.82896 iter/s, 54.676s/100 iter), loss = 2.93353
I0212 20:15:49.903733 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.80465 (* 1 = 4.80465 loss)
I0212 20:15:49.903748 12354 sgd_solver.cpp:136] Iteration 81700, lr = 1.0377e-05, m = 0.9
I0212 20:16:44.770382 12354 solver.cpp:314] Iteration 81800 (1.82266 iter/s, 54.8648s/100 iter), loss = 2.94605
I0212 20:16:44.770521 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.76922 (* 1 = 2.76922 loss)
I0212 20:16:44.770537 12354 sgd_solver.cpp:136] Iteration 81800, lr = 1.0269e-05, m = 0.9
I0212 20:17:40.334527 12354 solver.cpp:314] Iteration 81900 (1.79979 iter/s, 55.5621s/100 iter), loss = 2.95156
I0212 20:17:40.334770 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.22558 (* 1 = 3.22558 loss)
I0212 20:17:40.334786 12354 sgd_solver.cpp:136] Iteration 81900, lr = 1.01619e-05, m = 0.9
I0212 20:18:34.273561 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_82000.caffemodel
I0212 20:18:34.292901 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_82000.solverstate
I0212 20:18:34.301882 12354 solver.cpp:666] Iteration 82000, Testing net (#0)
I0212 20:19:24.537847 12355 solver.cpp:774] class AP 1: 0.395877
I0212 20:19:24.602730 12355 solver.cpp:774] class AP 2: 0.647639
I0212 20:19:24.613898 12355 solver.cpp:774] class AP 3: 0.633825
I0212 20:19:24.613915 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.559114
I0212 20:19:26.262658 12354 solver.cpp:774] class AP 1: 0.375887
I0212 20:19:26.337124 12354 solver.cpp:774] class AP 2: 0.619855
I0212 20:19:26.348354 12354 solver.cpp:774] class AP 3: 0.627198
I0212 20:19:26.348366 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.54098
I0212 20:19:26.348440 12354 solver.cpp:265] [MultiGPU] Tests completed in 52.0447s
I0212 20:19:26.774940 12354 solver.cpp:314] Iteration 82000 (0.939527 iter/s, 106.437s/100 iter), loss = 2.85074
I0212 20:19:26.774977 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.02249 (* 1 = 3.02249 loss)
I0212 20:19:26.774986 12354 sgd_solver.cpp:136] Iteration 82000, lr = 1.00556e-05, m = 0.9
I0212 20:20:21.883566 12354 solver.cpp:314] Iteration 82100 (1.81466 iter/s, 55.1066s/100 iter), loss = 2.67108
I0212 20:20:21.883678 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.16349 (* 1 = 2.16349 loss)
I0212 20:20:21.883693 12354 sgd_solver.cpp:136] Iteration 82100, lr = 9.9502e-06, m = 0.9
I0212 20:21:17.369835 12354 solver.cpp:314] Iteration 82200 (1.80231 iter/s, 55.4842s/100 iter), loss = 3.02594
I0212 20:21:17.382375 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.87976 (* 1 = 2.87976 loss)
I0212 20:21:17.382521 12354 sgd_solver.cpp:136] Iteration 82200, lr = 9.8456e-06, m = 0.9
I0212 20:22:12.562665 12354 solver.cpp:314] Iteration 82300 (1.8119 iter/s, 55.1908s/100 iter), loss = 2.90748
I0212 20:22:12.562784 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.48976 (* 1 = 3.48976 loss)
I0212 20:22:12.562799 12354 sgd_solver.cpp:136] Iteration 82300, lr = 9.74183e-06, m = 0.9
I0212 20:23:07.479406 12354 solver.cpp:314] Iteration 82400 (1.821 iter/s, 54.9147s/100 iter), loss = 2.59806
I0212 20:23:07.479517 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.65776 (* 1 = 3.65776 loss)
I0212 20:23:07.479532 12354 sgd_solver.cpp:136] Iteration 82400, lr = 9.63888e-06, m = 0.9
I0212 20:24:03.110643 12354 solver.cpp:314] Iteration 82500 (1.79762 iter/s, 55.6292s/100 iter), loss = 3.03284
I0212 20:24:03.110769 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.61232 (* 1 = 2.61232 loss)
I0212 20:24:03.110787 12354 sgd_solver.cpp:136] Iteration 82500, lr = 9.53674e-06, m = 0.9
I0212 20:24:58.329545 12354 solver.cpp:314] Iteration 82600 (1.81104 iter/s, 55.2169s/100 iter), loss = 3.04009
I0212 20:24:58.329646 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.81398 (* 1 = 2.81398 loss)
I0212 20:24:58.329797 12354 sgd_solver.cpp:136] Iteration 82600, lr = 9.43542e-06, m = 0.9
I0212 20:25:53.295920 12354 solver.cpp:314] Iteration 82700 (1.81936 iter/s, 54.9644s/100 iter), loss = 2.77788
I0212 20:25:53.296087 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.19179 (* 1 = 2.19179 loss)
I0212 20:25:53.296103 12354 sgd_solver.cpp:136] Iteration 82700, lr = 9.33492e-06, m = 0.9
I0212 20:26:48.448175 12354 solver.cpp:314] Iteration 82800 (1.81323 iter/s, 55.1502s/100 iter), loss = 2.97386
I0212 20:26:48.448292 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.21575 (* 1 = 3.21575 loss)
I0212 20:26:48.448307 12354 sgd_solver.cpp:136] Iteration 82800, lr = 9.23521e-06, m = 0.9
I0212 20:27:43.256848 12354 solver.cpp:314] Iteration 82900 (1.8246 iter/s, 54.8067s/100 iter), loss = 2.85776
I0212 20:27:43.257011 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.341 (* 1 = 3.341 loss)
I0212 20:27:43.257047 12354 sgd_solver.cpp:136] Iteration 82900, lr = 9.13631e-06, m = 0.9
I0212 20:28:37.810389 12354 solver.cpp:314] Iteration 83000 (1.83313 iter/s, 54.5515s/100 iter), loss = 2.92784
I0212 20:28:37.810508 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.39098 (* 1 = 2.39098 loss)
I0212 20:28:37.810523 12354 sgd_solver.cpp:136] Iteration 83000, lr = 9.0382e-06, m = 0.9
I0212 20:29:33.246218 12354 solver.cpp:314] Iteration 83100 (1.80395 iter/s, 55.4338s/100 iter), loss = 2.73894
I0212 20:29:33.246363 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.2018 (* 1 = 3.2018 loss)
I0212 20:29:33.246381 12354 sgd_solver.cpp:136] Iteration 83100, lr = 8.94088e-06, m = 0.9
I0212 20:30:28.520792 12354 solver.cpp:314] Iteration 83200 (1.80922 iter/s, 55.2726s/100 iter), loss = 2.76209
I0212 20:30:28.520889 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.55546 (* 1 = 2.55546 loss)
I0212 20:30:28.520900 12354 sgd_solver.cpp:136] Iteration 83200, lr = 8.84436e-06, m = 0.9
I0212 20:31:24.418546 12354 solver.cpp:314] Iteration 83300 (1.78905 iter/s, 55.8957s/100 iter), loss = 3.09834
I0212 20:31:24.418666 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.92943 (* 1 = 3.92943 loss)
I0212 20:31:24.418682 12354 sgd_solver.cpp:136] Iteration 83300, lr = 8.74862e-06, m = 0.9
I0212 20:32:19.349362 12354 solver.cpp:314] Iteration 83400 (1.82054 iter/s, 54.9288s/100 iter), loss = 2.99521
I0212 20:32:19.349495 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.64286 (* 1 = 2.64286 loss)
I0212 20:32:19.349511 12354 sgd_solver.cpp:136] Iteration 83400, lr = 8.65365e-06, m = 0.9
I0212 20:33:14.002342 12354 solver.cpp:314] Iteration 83500 (1.82979 iter/s, 54.651s/100 iter), loss = 2.82708
I0212 20:33:14.002481 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.22463 (* 1 = 2.22463 loss)
I0212 20:33:14.002501 12354 sgd_solver.cpp:136] Iteration 83500, lr = 8.55946e-06, m = 0.9
I0212 20:34:09.219663 12354 solver.cpp:314] Iteration 83600 (1.81109 iter/s, 55.2153s/100 iter), loss = 2.82308
I0212 20:34:09.219790 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.46139 (* 1 = 3.46139 loss)
I0212 20:34:09.219805 12354 sgd_solver.cpp:136] Iteration 83600, lr = 8.46605e-06, m = 0.9
I0212 20:34:58.237753 12274 data_reader.cpp:305] Starting prefetch of epoch 19
I0212 20:35:04.577050 12354 solver.cpp:314] Iteration 83700 (1.80651 iter/s, 55.3554s/100 iter), loss = 2.74701
I0212 20:35:04.577111 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.88714 (* 1 = 2.88714 loss)
I0212 20:35:04.577126 12354 sgd_solver.cpp:136] Iteration 83700, lr = 8.37339e-06, m = 0.9
I0212 20:35:59.403990 12354 solver.cpp:314] Iteration 83800 (1.82399 iter/s, 54.8249s/100 iter), loss = 3.00226
I0212 20:35:59.404093 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.08037 (* 1 = 2.08037 loss)
I0212 20:35:59.404103 12354 sgd_solver.cpp:136] Iteration 83800, lr = 8.28151e-06, m = 0.9
I0212 20:36:54.821467 12354 solver.cpp:314] Iteration 83900 (1.80455 iter/s, 55.4154s/100 iter), loss = 2.58048
I0212 20:36:54.821609 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.3603 (* 1 = 2.3603 loss)
I0212 20:36:54.821624 12354 sgd_solver.cpp:136] Iteration 83900, lr = 8.19038e-06, m = 0.9
I0212 20:37:49.091387 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_84000.caffemodel
I0212 20:37:49.115394 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_84000.solverstate
I0212 20:37:49.129160 12354 solver.cpp:666] Iteration 84000, Testing net (#0)
I0212 20:38:17.470432 12355 blocking_queue.cpp:40] Data layer prefetch queue empty
I0212 20:38:41.237452 12354 solver.cpp:774] class AP 1: 0.374599
I0212 20:38:41.309159 12354 solver.cpp:774] class AP 2: 0.622118
I0212 20:38:41.320322 12354 solver.cpp:774] class AP 3: 0.624831
I0212 20:38:41.320336 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.540516
I0212 20:38:41.718226 12355 solver.cpp:774] class AP 1: 0.396523
I0212 20:38:41.786360 12355 solver.cpp:774] class AP 2: 0.641709
I0212 20:38:41.797502 12355 solver.cpp:774] class AP 3: 0.637314
I0212 20:38:41.797516 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.558515
I0212 20:38:41.797613 12354 solver.cpp:265] [MultiGPU] Tests completed in 52.6665s
I0212 20:38:42.250860 12354 solver.cpp:314] Iteration 84000 (0.930878 iter/s, 107.425s/100 iter), loss = 2.98605
I0212 20:38:42.250896 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.3986 (* 1 = 2.3986 loss)
I0212 20:38:42.250906 12354 sgd_solver.cpp:136] Iteration 84000, lr = 8.1e-06, m = 0.9
I0212 20:39:37.139672 12354 solver.cpp:314] Iteration 84100 (1.82193 iter/s, 54.8868s/100 iter), loss = 3.04253
I0212 20:39:37.139801 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.05911 (* 1 = 3.05911 loss)
I0212 20:39:37.139814 12354 sgd_solver.cpp:136] Iteration 84100, lr = 8.01038e-06, m = 0.9
I0212 20:40:32.571784 12354 solver.cpp:314] Iteration 84200 (1.80407 iter/s, 55.4301s/100 iter), loss = 2.94556
I0212 20:40:32.571899 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.94747 (* 1 = 2.94747 loss)
I0212 20:40:32.571914 12354 sgd_solver.cpp:136] Iteration 84200, lr = 7.9215e-06, m = 0.9
I0212 20:41:28.140740 12354 solver.cpp:314] Iteration 84300 (1.79963 iter/s, 55.5669s/100 iter), loss = 2.94842
I0212 20:41:28.141057 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.54939 (* 1 = 2.54939 loss)
I0212 20:41:28.141193 12354 sgd_solver.cpp:136] Iteration 84300, lr = 7.83336e-06, m = 0.9
I0212 20:42:23.806772 12354 solver.cpp:314] Iteration 84400 (1.79649 iter/s, 55.664s/100 iter), loss = 2.89476
I0212 20:42:23.806877 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.64188 (* 1 = 3.64188 loss)
I0212 20:42:23.806890 12354 sgd_solver.cpp:136] Iteration 84400, lr = 7.74596e-06, m = 0.9
I0212 20:43:18.388546 12354 solver.cpp:314] Iteration 84500 (1.83218 iter/s, 54.5798s/100 iter), loss = 3.10288
I0212 20:43:18.388713 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.81771 (* 1 = 2.81771 loss)
I0212 20:43:18.388747 12354 sgd_solver.cpp:136] Iteration 84500, lr = 7.65929e-06, m = 0.9
I0212 20:44:13.499711 12354 solver.cpp:314] Iteration 84600 (1.81458 iter/s, 55.1091s/100 iter), loss = 2.87433
I0212 20:44:13.499845 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.38699 (* 1 = 2.38699 loss)
I0212 20:44:13.499863 12354 sgd_solver.cpp:136] Iteration 84600, lr = 7.57335e-06, m = 0.9
I0212 20:45:09.192487 12354 solver.cpp:314] Iteration 84700 (1.79563 iter/s, 55.6907s/100 iter), loss = 2.71302
I0212 20:45:09.192667 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.00294 (* 1 = 3.00294 loss)
I0212 20:45:09.192703 12354 sgd_solver.cpp:136] Iteration 84700, lr = 7.48814e-06, m = 0.9
I0212 20:46:04.762411 12354 solver.cpp:314] Iteration 84800 (1.7996 iter/s, 55.5679s/100 iter), loss = 2.97015
I0212 20:46:04.762534 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.85258 (* 1 = 2.85258 loss)
I0212 20:46:04.762552 12354 sgd_solver.cpp:136] Iteration 84800, lr = 7.40365e-06, m = 0.9
I0212 20:47:00.979166 12354 solver.cpp:314] Iteration 84900 (1.77889 iter/s, 56.2147s/100 iter), loss = 2.85431
I0212 20:47:00.979305 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.56189 (* 1 = 3.56189 loss)
I0212 20:47:00.979321 12354 sgd_solver.cpp:136] Iteration 84900, lr = 7.31987e-06, m = 0.9
I0212 20:47:55.891419 12354 solver.cpp:314] Iteration 85000 (1.82115 iter/s, 54.9102s/100 iter), loss = 2.98975
I0212 20:47:55.891510 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.45113 (* 1 = 2.45113 loss)
I0212 20:47:55.891520 12354 sgd_solver.cpp:136] Iteration 85000, lr = 7.23681e-06, m = 0.9
I0212 20:48:51.663877 12354 solver.cpp:314] Iteration 85100 (1.79307 iter/s, 55.7704s/100 iter), loss = 2.72906
I0212 20:48:51.663975 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.55601 (* 1 = 3.55601 loss)
I0212 20:48:51.663990 12354 sgd_solver.cpp:136] Iteration 85100, lr = 7.15446e-06, m = 0.9
I0212 20:49:46.931157 12354 solver.cpp:314] Iteration 85200 (1.80946 iter/s, 55.2653s/100 iter), loss = 2.81775
I0212 20:49:46.931453 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.94425 (* 1 = 3.94425 loss)
I0212 20:49:46.931517 12354 sgd_solver.cpp:136] Iteration 85200, lr = 7.07281e-06, m = 0.9
I0212 20:50:42.856823 12354 solver.cpp:314] Iteration 85300 (1.78815 iter/s, 55.9236s/100 iter), loss = 2.96503
I0212 20:50:42.857029 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.26792 (* 1 = 3.26792 loss)
I0212 20:50:42.857069 12354 sgd_solver.cpp:136] Iteration 85300, lr = 6.99187e-06, m = 0.9
I0212 20:51:38.554194 12354 solver.cpp:314] Iteration 85400 (1.79548 iter/s, 55.6953s/100 iter), loss = 2.84503
I0212 20:51:38.554280 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.93229 (* 1 = 2.93229 loss)
I0212 20:51:38.554291 12354 sgd_solver.cpp:136] Iteration 85400, lr = 6.91162e-06, m = 0.9
I0212 20:52:33.819088 12354 solver.cpp:314] Iteration 85500 (1.80953 iter/s, 55.2629s/100 iter), loss = 2.69293
I0212 20:52:33.819253 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.10611 (* 1 = 2.10611 loss)
I0212 20:52:33.819291 12354 sgd_solver.cpp:136] Iteration 85500, lr = 6.83206e-06, m = 0.9
I0212 20:53:29.600061 12354 solver.cpp:314] Iteration 85600 (1.79279 iter/s, 55.7789s/100 iter), loss = 2.85628
I0212 20:53:29.600313 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.58322 (* 1 = 2.58322 loss)
I0212 20:53:29.600342 12354 sgd_solver.cpp:136] Iteration 85600, lr = 6.75319e-06, m = 0.9
I0212 20:54:25.463984 12354 solver.cpp:314] Iteration 85700 (1.79013 iter/s, 55.8619s/100 iter), loss = 2.77619
I0212 20:54:25.464126 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.28067 (* 1 = 2.28067 loss)
I0212 20:54:25.464160 12354 sgd_solver.cpp:136] Iteration 85700, lr = 6.67501e-06, m = 0.9
I0212 20:55:21.219926 12354 solver.cpp:314] Iteration 85800 (1.7936 iter/s, 55.7539s/100 iter), loss = 2.793
I0212 20:55:21.220036 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.39981 (* 1 = 2.39981 loss)
I0212 20:55:21.220052 12354 sgd_solver.cpp:136] Iteration 85800, lr = 6.5975e-06, m = 0.9
I0212 20:56:16.906167 12354 solver.cpp:314] Iteration 85900 (1.79584 iter/s, 55.6842s/100 iter), loss = 2.98142
I0212 20:56:16.906302 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.82339 (* 1 = 2.82339 loss)
I0212 20:56:16.906327 12354 sgd_solver.cpp:136] Iteration 85900, lr = 6.52068e-06, m = 0.9
I0212 20:57:11.703069 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_86000.caffemodel
I0212 20:57:11.720945 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_86000.solverstate
I0212 20:57:11.729928 12354 solver.cpp:666] Iteration 86000, Testing net (#0)
I0212 20:58:01.630448 12354 solver.cpp:774] class AP 1: 0.376029
I0212 20:58:01.709920 12354 solver.cpp:774] class AP 2: 0.62873
I0212 20:58:01.721026 12354 solver.cpp:774] class AP 3: 0.625837
I0212 20:58:01.721041 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.543532
I0212 20:58:02.828104 12355 solver.cpp:774] class AP 1: 0.396374
I0212 20:58:02.892146 12355 solver.cpp:774] class AP 2: 0.647548
I0212 20:58:02.903201 12355 solver.cpp:774] class AP 3: 0.635684
I0212 20:58:02.903215 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.559869
I0212 20:58:02.903264 12354 solver.cpp:265] [MultiGPU] Tests completed in 51.1715s
I0212 20:58:03.311291 12354 solver.cpp:314] Iteration 86000 (0.939839 iter/s, 106.401s/100 iter), loss = 3.0534
I0212 20:58:03.311405 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.06236 (* 1 = 3.06236 loss)
I0212 20:58:03.311445 12354 sgd_solver.cpp:136] Iteration 86000, lr = 6.44452e-06, m = 0.9
I0212 20:58:57.869091 12354 solver.cpp:314] Iteration 86100 (1.83299 iter/s, 54.5558s/100 iter), loss = 3.04783
I0212 20:58:57.869226 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.55226 (* 1 = 2.55226 loss)
I0212 20:58:57.869240 12354 sgd_solver.cpp:136] Iteration 86100, lr = 6.36904e-06, m = 0.9
I0212 20:59:53.976413 12354 solver.cpp:314] Iteration 86200 (1.78236 iter/s, 56.1053s/100 iter), loss = 2.71712
I0212 20:59:53.976519 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.78531 (* 1 = 3.78531 loss)
I0212 20:59:53.976532 12354 sgd_solver.cpp:136] Iteration 86200, lr = 6.29422e-06, m = 0.9
I0212 21:00:49.695427 12354 solver.cpp:314] Iteration 86300 (1.79479 iter/s, 55.717s/100 iter), loss = 2.89144
I0212 21:00:49.695525 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.20473 (* 1 = 3.20473 loss)
I0212 21:00:49.695536 12354 sgd_solver.cpp:136] Iteration 86300, lr = 6.22006e-06, m = 0.9
I0212 21:01:45.578464 12354 solver.cpp:314] Iteration 86400 (1.78952 iter/s, 55.881s/100 iter), loss = 2.8443
I0212 21:01:45.578590 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.60377 (* 1 = 3.60377 loss)
I0212 21:01:45.578604 12354 sgd_solver.cpp:136] Iteration 86400, lr = 6.14656e-06, m = 0.9
I0212 21:02:24.813196 12274 data_reader.cpp:305] Starting prefetch of epoch 20
I0212 21:02:40.771335 12354 solver.cpp:314] Iteration 86500 (1.81189 iter/s, 55.1908s/100 iter), loss = 2.96122
I0212 21:02:40.771390 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.51629 (* 1 = 2.51629 loss)
I0212 21:02:40.771404 12354 sgd_solver.cpp:136] Iteration 86500, lr = 6.07371e-06, m = 0.9
I0212 21:03:36.655103 12354 solver.cpp:314] Iteration 86600 (1.78949 iter/s, 55.8817s/100 iter), loss = 2.83902
I0212 21:03:36.655215 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.83737 (* 1 = 2.83737 loss)
I0212 21:03:36.655230 12354 sgd_solver.cpp:136] Iteration 86600, lr = 6.00151e-06, m = 0.9
I0212 21:04:32.254969 12354 solver.cpp:314] Iteration 86700 (1.79863 iter/s, 55.5978s/100 iter), loss = 3.00903
I0212 21:04:32.255934 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.05868 (* 1 = 3.05868 loss)
I0212 21:04:32.255954 12354 sgd_solver.cpp:136] Iteration 86700, lr = 5.92996e-06, m = 0.9
I0212 21:05:27.297169 12354 solver.cpp:314] Iteration 86800 (1.81685 iter/s, 55.0402s/100 iter), loss = 2.80747
I0212 21:05:27.301115 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.77339 (* 1 = 2.77339 loss)
I0212 21:05:27.301141 12354 sgd_solver.cpp:136] Iteration 86800, lr = 5.85905e-06, m = 0.9
I0212 21:06:22.167788 12354 solver.cpp:314] Iteration 86900 (1.82254 iter/s, 54.8686s/100 iter), loss = 2.99402
I0212 21:06:22.167906 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.13194 (* 1 = 3.13194 loss)
I0212 21:06:22.167925 12354 sgd_solver.cpp:136] Iteration 86900, lr = 5.78878e-06, m = 0.9
I0212 21:07:17.901701 12354 solver.cpp:314] Iteration 87000 (1.79431 iter/s, 55.7319s/100 iter), loss = 2.90838
I0212 21:07:17.901860 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.55445 (* 1 = 3.55445 loss)
I0212 21:07:17.901877 12354 sgd_solver.cpp:136] Iteration 87000, lr = 5.71914e-06, m = 0.9
I0212 21:08:13.153384 12354 solver.cpp:314] Iteration 87100 (1.80997 iter/s, 55.2497s/100 iter), loss = 2.64765
I0212 21:08:13.158702 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.55662 (* 1 = 2.55662 loss)
I0212 21:08:13.158742 12354 sgd_solver.cpp:136] Iteration 87100, lr = 5.65013e-06, m = 0.9
I0212 21:09:08.329490 12354 solver.cpp:314] Iteration 87200 (1.81245 iter/s, 55.1741s/100 iter), loss = 2.88697
I0212 21:09:08.329622 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.0084 (* 1 = 3.0084 loss)
I0212 21:09:08.329639 12354 sgd_solver.cpp:136] Iteration 87200, lr = 5.58175e-06, m = 0.9
I0212 21:10:03.433523 12354 solver.cpp:314] Iteration 87300 (1.81482 iter/s, 55.102s/100 iter), loss = 2.95459
I0212 21:10:03.433657 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.64757 (* 1 = 3.64757 loss)
I0212 21:10:03.433676 12354 sgd_solver.cpp:136] Iteration 87300, lr = 5.51399e-06, m = 0.9
I0212 21:10:57.847548 12354 solver.cpp:314] Iteration 87400 (1.83783 iter/s, 54.412s/100 iter), loss = 2.80098
I0212 21:10:57.847666 12354 solver.cpp:336]     Train net output #0: mbox_loss = 1.68781 (* 1 = 1.68781 loss)
I0212 21:10:57.847679 12354 sgd_solver.cpp:136] Iteration 87400, lr = 5.44685e-06, m = 0.9
I0212 21:11:53.200093 12354 solver.cpp:314] Iteration 87500 (1.80667 iter/s, 55.3505s/100 iter), loss = 2.813
I0212 21:11:53.200249 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.42846 (* 1 = 2.42846 loss)
I0212 21:11:53.200285 12354 sgd_solver.cpp:136] Iteration 87500, lr = 5.38032e-06, m = 0.9
I0212 21:12:47.675799 12354 solver.cpp:314] Iteration 87600 (1.83575 iter/s, 54.4737s/100 iter), loss = 2.73073
I0212 21:12:47.675927 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.18174 (* 1 = 3.18174 loss)
I0212 21:12:47.675942 12354 sgd_solver.cpp:136] Iteration 87600, lr = 5.31441e-06, m = 0.9
I0212 21:13:42.571521 12354 solver.cpp:314] Iteration 87700 (1.8217 iter/s, 54.8937s/100 iter), loss = 2.98363
I0212 21:13:42.571609 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.19764 (* 1 = 2.19764 loss)
I0212 21:13:42.571619 12354 sgd_solver.cpp:136] Iteration 87700, lr = 5.2491e-06, m = 0.9
I0212 21:14:38.154176 12354 solver.cpp:314] Iteration 87800 (1.79919 iter/s, 55.5806s/100 iter), loss = 2.95773
I0212 21:14:38.154289 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.75206 (* 1 = 2.75206 loss)
I0212 21:14:38.154305 12354 sgd_solver.cpp:136] Iteration 87800, lr = 5.1844e-06, m = 0.9
I0212 21:15:34.327165 12354 solver.cpp:314] Iteration 87900 (1.78028 iter/s, 56.1709s/100 iter), loss = 2.75441
I0212 21:15:34.327459 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.85493 (* 1 = 3.85493 loss)
I0212 21:15:34.327528 12354 sgd_solver.cpp:136] Iteration 87900, lr = 5.1203e-06, m = 0.9
I0212 21:16:30.592222 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_88000.caffemodel
I0212 21:16:30.618804 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_88000.solverstate
I0212 21:16:30.632474 12354 solver.cpp:666] Iteration 88000, Testing net (#0)
I0212 21:17:21.366080 12355 solver.cpp:774] class AP 1: 0.394292
I0212 21:17:21.433584 12355 solver.cpp:774] class AP 2: 0.645304
I0212 21:17:21.444766 12355 solver.cpp:774] class AP 3: 0.633061
I0212 21:17:21.444782 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.557553
I0212 21:17:23.005681 12354 solver.cpp:774] class AP 1: 0.374338
I0212 21:17:23.080883 12354 solver.cpp:774] class AP 2: 0.63025
I0212 21:17:23.092052 12354 solver.cpp:774] class AP 3: 0.627284
I0212 21:17:23.092067 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.543957
I0212 21:17:23.092103 12354 solver.cpp:265] [MultiGPU] Tests completed in 52.4577s
I0212 21:17:23.548410 12354 solver.cpp:314] Iteration 88000 (0.915606 iter/s, 109.217s/100 iter), loss = 3.01686
I0212 21:17:23.548454 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.82128 (* 1 = 2.82128 loss)
I0212 21:17:23.548465 12354 sgd_solver.cpp:136] Iteration 88000, lr = 5.05679e-06, m = 0.9
I0212 21:18:19.029330 12354 solver.cpp:314] Iteration 88100 (1.80249 iter/s, 55.4789s/100 iter), loss = 2.82693
I0212 21:18:19.029494 12354 solver.cpp:336]     Train net output #0: mbox_loss = 1.98016 (* 1 = 1.98016 loss)
I0212 21:18:19.029515 12354 sgd_solver.cpp:136] Iteration 88100, lr = 4.99387e-06, m = 0.9
I0212 21:19:13.852459 12354 solver.cpp:314] Iteration 88200 (1.82411 iter/s, 54.8211s/100 iter), loss = 2.90063
I0212 21:19:13.852612 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.06112 (* 1 = 3.06112 loss)
I0212 21:19:13.852629 12354 sgd_solver.cpp:136] Iteration 88200, lr = 4.93155e-06, m = 0.9
I0212 21:20:09.570170 12354 solver.cpp:314] Iteration 88300 (1.79483 iter/s, 55.7157s/100 iter), loss = 3.01919
I0212 21:20:09.570297 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.06962 (* 1 = 3.06962 loss)
I0212 21:20:09.570313 12354 sgd_solver.cpp:136] Iteration 88300, lr = 4.86981e-06, m = 0.9
I0212 21:21:05.405757 12354 solver.cpp:314] Iteration 88400 (1.79104 iter/s, 55.8335s/100 iter), loss = 2.92591
I0212 21:21:05.405870 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.31368 (* 1 = 3.31368 loss)
I0212 21:21:05.405885 12354 sgd_solver.cpp:136] Iteration 88400, lr = 4.80865e-06, m = 0.9
I0212 21:22:00.688774 12354 solver.cpp:314] Iteration 88500 (1.80894 iter/s, 55.281s/100 iter), loss = 2.80635
I0212 21:22:00.688875 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.29559 (* 1 = 2.29559 loss)
I0212 21:22:00.688885 12354 sgd_solver.cpp:136] Iteration 88500, lr = 4.74807e-06, m = 0.9
I0212 21:22:55.911070 12354 solver.cpp:314] Iteration 88600 (1.81093 iter/s, 55.2203s/100 iter), loss = 3.09423
I0212 21:22:55.911214 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.68673 (* 1 = 2.68673 loss)
I0212 21:22:55.911229 12354 sgd_solver.cpp:136] Iteration 88600, lr = 4.68806e-06, m = 0.9
I0212 21:23:51.956231 12354 solver.cpp:314] Iteration 88700 (1.78434 iter/s, 56.0431s/100 iter), loss = 2.89291
I0212 21:23:51.956342 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.54346 (* 1 = 2.54346 loss)
I0212 21:23:51.956358 12354 sgd_solver.cpp:136] Iteration 88700, lr = 4.62863e-06, m = 0.9
I0212 21:24:47.084522 12354 solver.cpp:314] Iteration 88800 (1.81409 iter/s, 55.1241s/100 iter), loss = 3.01987
I0212 21:24:47.086184 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.52498 (* 1 = 4.52498 loss)
I0212 21:24:47.086206 12354 sgd_solver.cpp:136] Iteration 88800, lr = 4.56976e-06, m = 0.9
I0212 21:25:42.855587 12354 solver.cpp:314] Iteration 88900 (1.79311 iter/s, 55.769s/100 iter), loss = 2.79199
I0212 21:25:42.855697 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.28272 (* 1 = 3.28272 loss)
I0212 21:25:42.855711 12354 sgd_solver.cpp:136] Iteration 88900, lr = 4.51145e-06, m = 0.9
I0212 21:26:37.487567 12354 solver.cpp:314] Iteration 89000 (1.8305 iter/s, 54.63s/100 iter), loss = 2.80625
I0212 21:26:37.487684 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.79003 (* 1 = 2.79003 loss)
I0212 21:26:37.487699 12354 sgd_solver.cpp:136] Iteration 89000, lr = 4.45371e-06, m = 0.9
I0212 21:27:32.688413 12354 solver.cpp:314] Iteration 89100 (1.81163 iter/s, 55.1988s/100 iter), loss = 3.10065
I0212 21:27:32.688545 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.53319 (* 1 = 3.53319 loss)
I0212 21:27:32.688561 12354 sgd_solver.cpp:136] Iteration 89100, lr = 4.39652e-06, m = 0.9
I0212 21:28:27.979737 12354 solver.cpp:314] Iteration 89200 (1.80867 iter/s, 55.2893s/100 iter), loss = 2.8
I0212 21:28:27.979871 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.68415 (* 1 = 2.68415 loss)
I0212 21:28:27.979887 12354 sgd_solver.cpp:136] Iteration 89200, lr = 4.33988e-06, m = 0.9
I0212 21:29:23.330694 12354 solver.cpp:314] Iteration 89300 (1.80672 iter/s, 55.3489s/100 iter), loss = 2.83274
I0212 21:29:23.330817 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.21656 (* 1 = 3.21656 loss)
I0212 21:29:23.330832 12354 sgd_solver.cpp:136] Iteration 89300, lr = 4.28379e-06, m = 0.9
I0212 21:30:19.162397 12354 solver.cpp:314] Iteration 89400 (1.79116 iter/s, 55.8297s/100 iter), loss = 2.77885
I0212 21:30:19.162561 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.76605 (* 1 = 2.76605 loss)
I0212 21:30:19.162597 12354 sgd_solver.cpp:136] Iteration 89400, lr = 4.22825e-06, m = 0.9
I0212 21:31:14.261162 12354 solver.cpp:314] Iteration 89500 (1.81499 iter/s, 55.0967s/100 iter), loss = 2.8953
I0212 21:31:14.261289 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.6806 (* 1 = 2.6806 loss)
I0212 21:31:14.261307 12354 sgd_solver.cpp:136] Iteration 89500, lr = 4.17325e-06, m = 0.9
I0212 21:32:09.420331 12274 data_reader.cpp:305] Starting prefetch of epoch 21
I0212 21:32:09.562773 12354 solver.cpp:314] Iteration 89600 (1.80833 iter/s, 55.2996s/100 iter), loss = 2.88422
I0212 21:32:09.562827 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.67983 (* 1 = 2.67983 loss)
I0212 21:32:09.562839 12354 sgd_solver.cpp:136] Iteration 89600, lr = 4.11879e-06, m = 0.9
I0212 21:33:04.775344 12354 solver.cpp:314] Iteration 89700 (1.81125 iter/s, 55.2105s/100 iter), loss = 2.75566
I0212 21:33:04.775461 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.97011 (* 1 = 2.97011 loss)
I0212 21:33:04.775477 12354 sgd_solver.cpp:136] Iteration 89700, lr = 4.06486e-06, m = 0.9
I0212 21:33:59.741714 12354 solver.cpp:314] Iteration 89800 (1.81936 iter/s, 54.9644s/100 iter), loss = 2.74894
I0212 21:33:59.741839 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.49326 (* 1 = 2.49326 loss)
I0212 21:33:59.741855 12354 sgd_solver.cpp:136] Iteration 89800, lr = 4.01146e-06, m = 0.9
I0212 21:34:54.298135 12354 solver.cpp:314] Iteration 89900 (1.83303 iter/s, 54.5544s/100 iter), loss = 2.97569
I0212 21:34:54.298259 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.19376 (* 1 = 2.19376 loss)
I0212 21:34:54.298281 12354 sgd_solver.cpp:136] Iteration 89900, lr = 3.95859e-06, m = 0.9
I0212 21:35:49.589829 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_90000.caffemodel
I0212 21:35:49.607874 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_90000.solverstate
I0212 21:35:49.616782 12354 solver.cpp:666] Iteration 90000, Testing net (#0)
I0212 21:36:39.618518 12354 solver.cpp:774] class AP 1: 0.376264
I0212 21:36:39.690389 12354 solver.cpp:774] class AP 2: 0.632396
I0212 21:36:39.701362 12354 solver.cpp:774] class AP 3: 0.629837
I0212 21:36:39.701375 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.546165
I0212 21:36:40.148324 12355 solver.cpp:774] class AP 1: 0.393438
I0212 21:36:40.219538 12355 solver.cpp:774] class AP 2: 0.643512
I0212 21:36:40.230415 12355 solver.cpp:774] class AP 3: 0.634562
I0212 21:36:40.230428 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.55717
I0212 21:36:40.230525 12354 solver.cpp:265] [MultiGPU] Tests completed in 50.6119s
I0212 21:36:40.657372 12354 solver.cpp:314] Iteration 90000 (0.940244 iter/s, 106.355s/100 iter), loss = 2.76305
I0212 21:36:40.657480 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.3608 (* 1 = 2.3608 loss)
I0212 21:36:40.657523 12354 sgd_solver.cpp:136] Iteration 90000, lr = 3.90625e-06, m = 0.9
I0212 21:37:35.486413 12354 solver.cpp:314] Iteration 90100 (1.82392 iter/s, 54.827s/100 iter), loss = 2.96211
I0212 21:37:35.486568 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.6947 (* 1 = 2.6947 loss)
I0212 21:37:35.486587 12354 sgd_solver.cpp:136] Iteration 90100, lr = 3.85443e-06, m = 0.9
I0212 21:38:31.611205 12354 solver.cpp:314] Iteration 90200 (1.78181 iter/s, 56.1227s/100 iter), loss = 3.18928
I0212 21:38:31.611316 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.28691 (* 1 = 3.28691 loss)
I0212 21:38:31.611332 12354 sgd_solver.cpp:136] Iteration 90200, lr = 3.80312e-06, m = 0.9
I0212 21:39:27.638324 12354 solver.cpp:314] Iteration 90300 (1.78492 iter/s, 56.0251s/100 iter), loss = 2.8747
I0212 21:39:27.638444 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.23055 (* 1 = 3.23055 loss)
I0212 21:39:27.638459 12354 sgd_solver.cpp:136] Iteration 90300, lr = 3.75233e-06, m = 0.9
I0212 21:40:22.706887 12354 solver.cpp:314] Iteration 90400 (1.81598 iter/s, 55.0665s/100 iter), loss = 3.00984
I0212 21:40:22.707058 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.20365 (* 1 = 4.20365 loss)
I0212 21:40:22.707096 12354 sgd_solver.cpp:136] Iteration 90400, lr = 3.70205e-06, m = 0.9
I0212 21:41:17.817883 12354 solver.cpp:314] Iteration 90500 (1.81459 iter/s, 55.109s/100 iter), loss = 2.74377
I0212 21:41:17.817997 12354 solver.cpp:336]     Train net output #0: mbox_loss = 1.5689 (* 1 = 1.5689 loss)
I0212 21:41:17.818012 12354 sgd_solver.cpp:136] Iteration 90500, lr = 3.65227e-06, m = 0.9
I0212 21:42:13.422564 12354 solver.cpp:314] Iteration 90600 (1.79848 iter/s, 55.6026s/100 iter), loss = 2.79981
I0212 21:42:13.422730 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.15771 (* 1 = 2.15771 loss)
I0212 21:42:13.422771 12354 sgd_solver.cpp:136] Iteration 90600, lr = 3.603e-06, m = 0.9
I0212 21:43:09.391269 12354 solver.cpp:314] Iteration 90700 (1.78678 iter/s, 55.9667s/100 iter), loss = 2.96594
I0212 21:43:09.391386 12354 solver.cpp:336]     Train net output #0: mbox_loss = 1.84886 (* 1 = 1.84886 loss)
I0212 21:43:09.391402 12354 sgd_solver.cpp:136] Iteration 90700, lr = 3.55423e-06, m = 0.9
I0212 21:44:05.143971 12354 solver.cpp:314] Iteration 90800 (1.7937 iter/s, 55.7507s/100 iter), loss = 3.18722
I0212 21:44:05.144076 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.95116 (* 1 = 2.95116 loss)
I0212 21:44:05.144091 12354 sgd_solver.cpp:136] Iteration 90800, lr = 3.50596e-06, m = 0.9
I0212 21:45:01.027923 12354 solver.cpp:314] Iteration 90900 (1.78949 iter/s, 55.8819s/100 iter), loss = 2.84423
I0212 21:45:01.028031 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.83234 (* 1 = 2.83234 loss)
I0212 21:45:01.028045 12354 sgd_solver.cpp:136] Iteration 90900, lr = 3.45818e-06, m = 0.9
I0212 21:45:56.598130 12354 solver.cpp:314] Iteration 91000 (1.79959 iter/s, 55.5681s/100 iter), loss = 2.99061
I0212 21:45:56.598239 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.51212 (* 1 = 4.51212 loss)
I0212 21:45:56.598255 12354 sgd_solver.cpp:136] Iteration 91000, lr = 3.41089e-06, m = 0.9
I0212 21:46:52.862679 12354 solver.cpp:314] Iteration 91100 (1.77738 iter/s, 56.2625s/100 iter), loss = 2.9066
I0212 21:46:52.862875 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.11642 (* 1 = 3.11642 loss)
I0212 21:46:52.862913 12354 sgd_solver.cpp:136] Iteration 91100, lr = 3.36408e-06, m = 0.9
I0212 21:47:49.288656 12354 solver.cpp:314] Iteration 91200 (1.7723 iter/s, 56.4239s/100 iter), loss = 2.64838
I0212 21:47:49.288769 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.17191 (* 1 = 3.17191 loss)
I0212 21:47:49.288784 12354 sgd_solver.cpp:136] Iteration 91200, lr = 3.31776e-06, m = 0.9
I0212 21:48:44.897300 12354 solver.cpp:314] Iteration 91300 (1.79835 iter/s, 55.6066s/100 iter), loss = 2.88944
I0212 21:48:44.897485 12354 solver.cpp:336]     Train net output #0: mbox_loss = 1.96641 (* 1 = 1.96641 loss)
I0212 21:48:44.897536 12354 sgd_solver.cpp:136] Iteration 91300, lr = 3.27192e-06, m = 0.9
I0212 21:49:40.822427 12354 solver.cpp:314] Iteration 91400 (1.78817 iter/s, 55.9231s/100 iter), loss = 2.97816
I0212 21:49:40.822577 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.56502 (* 1 = 3.56502 loss)
I0212 21:49:40.822593 12354 sgd_solver.cpp:136] Iteration 91400, lr = 3.22656e-06, m = 0.9
I0212 21:50:36.433202 12354 solver.cpp:314] Iteration 91500 (1.79828 iter/s, 55.6087s/100 iter), loss = 2.93311
I0212 21:50:36.433331 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.3526 (* 1 = 3.3526 loss)
I0212 21:50:36.433346 12354 sgd_solver.cpp:136] Iteration 91500, lr = 3.18167e-06, m = 0.9
I0212 21:51:31.978302 12354 solver.cpp:314] Iteration 91600 (1.8004 iter/s, 55.5431s/100 iter), loss = 2.87871
I0212 21:51:31.978426 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.54485 (* 1 = 2.54485 loss)
I0212 21:51:31.978444 12354 sgd_solver.cpp:136] Iteration 91600, lr = 3.13725e-06, m = 0.9
I0212 21:52:27.281882 12354 solver.cpp:314] Iteration 91700 (1.80827 iter/s, 55.3016s/100 iter), loss = 2.82249
I0212 21:52:27.282033 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.5453 (* 1 = 2.5453 loss)
I0212 21:52:27.282050 12354 sgd_solver.cpp:136] Iteration 91700, lr = 3.09329e-06, m = 0.9
I0212 21:53:22.180833 12354 solver.cpp:314] Iteration 91800 (1.8216 iter/s, 54.8969s/100 iter), loss = 3.238
I0212 21:53:22.180953 12354 solver.cpp:336]     Train net output #0: mbox_loss = 5.05915 (* 1 = 5.05915 loss)
I0212 21:53:22.180970 12354 sgd_solver.cpp:136] Iteration 91800, lr = 3.0498e-06, m = 0.9
I0212 21:54:17.165251 12354 solver.cpp:314] Iteration 91900 (1.81876 iter/s, 54.9824s/100 iter), loss = 2.89466
I0212 21:54:17.165406 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.6482 (* 1 = 3.6482 loss)
I0212 21:54:17.165421 12354 sgd_solver.cpp:136] Iteration 91900, lr = 3.00677e-06, m = 0.9
I0212 21:55:12.115509 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_92000.caffemodel
I0212 21:55:12.139241 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_92000.solverstate
I0212 21:55:12.152428 12354 solver.cpp:666] Iteration 92000, Testing net (#0)
I0212 21:56:03.121495 12355 solver.cpp:774] class AP 1: 0.394874
I0212 21:56:03.193369 12355 solver.cpp:774] class AP 2: 0.646286
I0212 21:56:03.204757 12355 solver.cpp:774] class AP 3: 0.630238
I0212 21:56:03.204774 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.557133
I0212 21:56:03.777660 12354 solver.cpp:774] class AP 1: 0.377076
I0212 21:56:03.850967 12354 solver.cpp:774] class AP 2: 0.627252
I0212 21:56:03.862318 12354 solver.cpp:774] class AP 3: 0.631927
I0212 21:56:03.862334 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.545418
I0212 21:56:03.862381 12354 solver.cpp:265] [MultiGPU] Tests completed in 51.7081s
I0212 21:56:04.230162 12354 solver.cpp:314] Iteration 92000 (0.934047 iter/s, 107.061s/100 iter), loss = 2.9021
I0212 21:56:04.230288 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.55115 (* 1 = 3.55115 loss)
I0212 21:56:04.230326 12354 sgd_solver.cpp:136] Iteration 92000, lr = 2.9642e-06, m = 0.9
I0212 21:56:58.975329 12354 solver.cpp:314] Iteration 92100 (1.82671 iter/s, 54.7432s/100 iter), loss = 2.81626
I0212 21:56:58.975523 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.01946 (* 1 = 3.01946 loss)
I0212 21:56:58.975563 12354 sgd_solver.cpp:136] Iteration 92100, lr = 2.92208e-06, m = 0.9
I0212 21:57:53.883709 12354 solver.cpp:314] Iteration 92200 (1.82128 iter/s, 54.9064s/100 iter), loss = 2.90496
I0212 21:57:53.883833 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.58302 (* 1 = 2.58302 loss)
I0212 21:57:53.883850 12354 sgd_solver.cpp:136] Iteration 92200, lr = 2.88041e-06, m = 0.9
I0212 21:58:49.890389 12354 solver.cpp:314] Iteration 92300 (1.78557 iter/s, 56.0046s/100 iter), loss = 2.96047
I0212 21:58:49.890537 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.32336 (* 1 = 2.32336 loss)
I0212 21:58:49.890552 12354 sgd_solver.cpp:136] Iteration 92300, lr = 2.83919e-06, m = 0.9
I0212 21:59:33.451771 12274 data_reader.cpp:305] Starting prefetch of epoch 22
I0212 21:59:45.001724 12354 solver.cpp:314] Iteration 92400 (1.81458 iter/s, 55.1093s/100 iter), loss = 2.79311
I0212 21:59:45.001772 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.53162 (* 1 = 2.53162 loss)
I0212 21:59:45.001783 12354 sgd_solver.cpp:136] Iteration 92400, lr = 2.79841e-06, m = 0.9
I0212 22:00:39.874871 12354 solver.cpp:314] Iteration 92500 (1.82245 iter/s, 54.8711s/100 iter), loss = 2.98032
I0212 22:00:39.874987 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.74015 (* 1 = 3.74015 loss)
I0212 22:00:39.875002 12354 sgd_solver.cpp:136] Iteration 92500, lr = 2.75807e-06, m = 0.9
I0212 22:01:35.578158 12354 solver.cpp:314] Iteration 92600 (1.79529 iter/s, 55.7012s/100 iter), loss = 3.17601
I0212 22:01:35.590239 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.94513 (* 1 = 2.94513 loss)
I0212 22:01:35.590286 12354 sgd_solver.cpp:136] Iteration 92600, lr = 2.71818e-06, m = 0.9
I0212 22:02:30.612462 12354 solver.cpp:314] Iteration 92700 (1.81712 iter/s, 55.0323s/100 iter), loss = 2.94821
I0212 22:02:30.612593 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.99712 (* 1 = 2.99712 loss)
I0212 22:02:30.612608 12354 sgd_solver.cpp:136] Iteration 92700, lr = 2.67871e-06, m = 0.9
I0212 22:03:25.898419 12354 solver.cpp:314] Iteration 92800 (1.80884 iter/s, 55.2839s/100 iter), loss = 2.97807
I0212 22:03:25.901063 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.52687 (* 1 = 2.52687 loss)
I0212 22:03:25.901084 12354 sgd_solver.cpp:136] Iteration 92800, lr = 2.63968e-06, m = 0.9
I0212 22:04:21.060745 12354 solver.cpp:314] Iteration 92900 (1.8129 iter/s, 55.1603s/100 iter), loss = 3.01792
I0212 22:04:21.060849 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.48861 (* 1 = 2.48861 loss)
I0212 22:04:21.060864 12354 sgd_solver.cpp:136] Iteration 92900, lr = 2.60107e-06, m = 0.9
I0212 22:05:16.804457 12354 solver.cpp:314] Iteration 93000 (1.79399 iter/s, 55.7417s/100 iter), loss = 2.74668
I0212 22:05:16.804584 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.85231 (* 1 = 2.85231 loss)
I0212 22:05:16.804599 12354 sgd_solver.cpp:136] Iteration 93000, lr = 2.56289e-06, m = 0.9
I0212 22:06:11.982178 12354 solver.cpp:314] Iteration 93100 (1.81239 iter/s, 55.1757s/100 iter), loss = 2.96215
I0212 22:06:11.982293 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.03015 (* 1 = 3.03015 loss)
I0212 22:06:11.982311 12354 sgd_solver.cpp:136] Iteration 93100, lr = 2.52513e-06, m = 0.9
I0212 22:07:07.426362 12354 solver.cpp:314] Iteration 93200 (1.80368 iter/s, 55.4422s/100 iter), loss = 3.24745
I0212 22:07:07.426784 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.05628 (* 1 = 3.05628 loss)
I0212 22:07:07.426801 12354 sgd_solver.cpp:136] Iteration 93200, lr = 2.48779e-06, m = 0.9
I0212 22:08:03.000777 12354 solver.cpp:314] Iteration 93300 (1.79945 iter/s, 55.5724s/100 iter), loss = 3.11056
I0212 22:08:03.000900 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.03794 (* 1 = 3.03794 loss)
I0212 22:08:03.000918 12354 sgd_solver.cpp:136] Iteration 93300, lr = 2.45087e-06, m = 0.9
I0212 22:08:58.705230 12354 solver.cpp:314] Iteration 93400 (1.79525 iter/s, 55.7024s/100 iter), loss = 2.8587
I0212 22:08:58.705358 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.09041 (* 1 = 2.09041 loss)
I0212 22:08:58.705373 12354 sgd_solver.cpp:136] Iteration 93400, lr = 2.41436e-06, m = 0.9
I0212 22:09:54.018749 12354 solver.cpp:314] Iteration 93500 (1.80794 iter/s, 55.3115s/100 iter), loss = 2.82888
I0212 22:09:54.018868 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.13175 (* 1 = 3.13175 loss)
I0212 22:09:54.018882 12354 sgd_solver.cpp:136] Iteration 93500, lr = 2.37826e-06, m = 0.9
I0212 22:10:49.429661 12354 solver.cpp:314] Iteration 93600 (1.80476 iter/s, 55.4089s/100 iter), loss = 2.82601
I0212 22:10:49.429816 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.30797 (* 1 = 2.30797 loss)
I0212 22:10:49.429833 12354 sgd_solver.cpp:136] Iteration 93600, lr = 2.34256e-06, m = 0.9
I0212 22:11:45.060221 12354 solver.cpp:314] Iteration 93700 (1.79764 iter/s, 55.6285s/100 iter), loss = 2.89258
I0212 22:11:45.060338 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.6848 (* 1 = 2.6848 loss)
I0212 22:11:45.060353 12354 sgd_solver.cpp:136] Iteration 93700, lr = 2.30727e-06, m = 0.9
I0212 22:12:40.768045 12354 solver.cpp:314] Iteration 93800 (1.79515 iter/s, 55.7058s/100 iter), loss = 3.14242
I0212 22:12:40.768154 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.10354 (* 1 = 2.10354 loss)
I0212 22:12:40.768169 12354 sgd_solver.cpp:136] Iteration 93800, lr = 2.27237e-06, m = 0.9
I0212 22:13:36.624877 12354 solver.cpp:314] Iteration 93900 (1.79036 iter/s, 55.8548s/100 iter), loss = 3.03405
I0212 22:13:36.624999 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.29233 (* 1 = 2.29233 loss)
I0212 22:13:36.625013 12354 sgd_solver.cpp:136] Iteration 93900, lr = 2.23788e-06, m = 0.9
I0212 22:14:31.525650 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_94000.caffemodel
I0212 22:14:31.548964 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_94000.solverstate
I0212 22:14:31.561672 12354 solver.cpp:666] Iteration 94000, Testing net (#0)
I0212 22:15:21.947407 12355 solver.cpp:774] class AP 1: 0.396365
I0212 22:15:22.021262 12355 solver.cpp:774] class AP 2: 0.64204
I0212 22:15:22.032317 12355 solver.cpp:774] class AP 3: 0.630765
I0212 22:15:22.032335 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.55639
I0212 22:15:22.548230 12354 solver.cpp:774] class AP 1: 0.375793
I0212 22:15:22.625519 12354 solver.cpp:774] class AP 2: 0.629904
I0212 22:15:22.636863 12354 solver.cpp:774] class AP 3: 0.63122
I0212 22:15:22.636894 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.545639
I0212 22:15:22.636930 12354 solver.cpp:265] [MultiGPU] Tests completed in 51.0734s
I0212 22:15:23.026943 12354 solver.cpp:314] Iteration 94000 (0.939866 iter/s, 106.398s/100 iter), loss = 2.81547
I0212 22:15:23.027055 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.11024 (* 1 = 3.11024 loss)
I0212 22:15:23.027092 12354 sgd_solver.cpp:136] Iteration 94000, lr = 2.20378e-06, m = 0.9
I0212 22:16:18.683135 12354 solver.cpp:314] Iteration 94100 (1.79681 iter/s, 55.6542s/100 iter), loss = 3.10618
I0212 22:16:18.683259 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.84658 (* 1 = 2.84658 loss)
I0212 22:16:18.683275 12354 sgd_solver.cpp:136] Iteration 94100, lr = 2.17007e-06, m = 0.9
I0212 22:17:13.219924 12354 solver.cpp:314] Iteration 94200 (1.83369 iter/s, 54.5348s/100 iter), loss = 2.68544
I0212 22:17:13.220059 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.38052 (* 1 = 3.38052 loss)
I0212 22:17:13.220074 12354 sgd_solver.cpp:136] Iteration 94200, lr = 2.13675e-06, m = 0.9
I0212 22:18:09.211486 12354 solver.cpp:314] Iteration 94300 (1.78605 iter/s, 55.9895s/100 iter), loss = 3.00463
I0212 22:18:09.211599 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.98874 (* 1 = 2.98874 loss)
I0212 22:18:09.211614 12354 sgd_solver.cpp:136] Iteration 94300, lr = 2.10381e-06, m = 0.9
I0212 22:19:04.533524 12354 solver.cpp:314] Iteration 94400 (1.80766 iter/s, 55.32s/100 iter), loss = 2.81023
I0212 22:19:04.533665 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.01393 (* 1 = 2.01393 loss)
I0212 22:19:04.533684 12354 sgd_solver.cpp:136] Iteration 94400, lr = 2.07126e-06, m = 0.9
I0212 22:20:00.477355 12354 solver.cpp:314] Iteration 94500 (1.78757 iter/s, 55.9418s/100 iter), loss = 2.68597
I0212 22:20:00.477494 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.33179 (* 1 = 3.33179 loss)
I0212 22:20:00.477506 12354 sgd_solver.cpp:136] Iteration 94500, lr = 2.03909e-06, m = 0.9
I0212 22:20:55.698997 12354 solver.cpp:314] Iteration 94600 (1.81095 iter/s, 55.2196s/100 iter), loss = 3.02719
I0212 22:20:55.700917 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.26019 (* 1 = 2.26019 loss)
I0212 22:20:55.700942 12354 sgd_solver.cpp:136] Iteration 94600, lr = 2.00729e-06, m = 0.9
I0212 22:21:50.863381 12354 solver.cpp:314] Iteration 94700 (1.81283 iter/s, 55.1624s/100 iter), loss = 2.81913
I0212 22:21:50.863471 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.75069 (* 1 = 2.75069 loss)
I0212 22:21:50.863481 12354 sgd_solver.cpp:136] Iteration 94700, lr = 1.97586e-06, m = 0.9
I0212 22:22:47.535092 12354 solver.cpp:314] Iteration 94800 (1.76461 iter/s, 56.6696s/100 iter), loss = 2.89807
I0212 22:22:47.535236 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.42832 (* 1 = 2.42832 loss)
I0212 22:22:47.535251 12354 sgd_solver.cpp:136] Iteration 94800, lr = 1.94481e-06, m = 0.9
I0212 22:23:43.427197 12354 solver.cpp:314] Iteration 94900 (1.78923 iter/s, 55.8901s/100 iter), loss = 2.79924
I0212 22:23:43.427325 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.45258 (* 1 = 3.45258 loss)
I0212 22:23:43.427340 12354 sgd_solver.cpp:136] Iteration 94900, lr = 1.91412e-06, m = 0.9
I0212 22:24:37.960245 12354 solver.cpp:314] Iteration 95000 (1.83382 iter/s, 54.5311s/100 iter), loss = 2.75112
I0212 22:24:37.960371 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.53027 (* 1 = 2.53027 loss)
I0212 22:24:37.960386 12354 sgd_solver.cpp:136] Iteration 95000, lr = 1.8838e-06, m = 0.9
I0212 22:25:33.581382 12354 solver.cpp:314] Iteration 95100 (1.79794 iter/s, 55.6191s/100 iter), loss = 2.90904
I0212 22:25:33.581506 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.50197 (* 1 = 3.50197 loss)
I0212 22:25:33.581521 12354 sgd_solver.cpp:136] Iteration 95100, lr = 1.85384e-06, m = 0.9
I0212 22:26:29.552016 12354 solver.cpp:314] Iteration 95200 (1.78672 iter/s, 55.9686s/100 iter), loss = 3.01552
I0212 22:26:29.552124 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.25345 (* 1 = 4.25345 loss)
I0212 22:26:29.552134 12354 sgd_solver.cpp:136] Iteration 95200, lr = 1.82424e-06, m = 0.9
I0212 22:27:24.497316 12354 solver.cpp:314] Iteration 95300 (1.82006 iter/s, 54.9433s/100 iter), loss = 2.81999
I0212 22:27:24.497403 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.15523 (* 1 = 3.15523 loss)
I0212 22:27:24.497413 12354 sgd_solver.cpp:136] Iteration 95300, lr = 1.79499e-06, m = 0.9
I0212 22:28:20.060199 12354 solver.cpp:314] Iteration 95400 (1.79983 iter/s, 55.5609s/100 iter), loss = 2.82156
I0212 22:28:20.060307 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.45395 (* 1 = 2.45395 loss)
I0212 22:28:20.060322 12354 sgd_solver.cpp:136] Iteration 95400, lr = 1.7661e-06, m = 0.9
I0212 22:29:14.758483 12354 solver.cpp:314] Iteration 95500 (1.82828 iter/s, 54.6963s/100 iter), loss = 2.77659
I0212 22:29:14.758604 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.19074 (* 1 = 3.19074 loss)
I0212 22:29:14.758618 12354 sgd_solver.cpp:136] Iteration 95500, lr = 1.73756e-06, m = 0.9
I0212 22:29:19.789836 12274 data_reader.cpp:305] Starting prefetch of epoch 23
I0212 22:30:10.847123 12354 solver.cpp:314] Iteration 95600 (1.78296 iter/s, 56.0866s/100 iter), loss = 3.07274
I0212 22:30:10.847265 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.8814 (* 1 = 2.8814 loss)
I0212 22:30:10.847283 12354 sgd_solver.cpp:136] Iteration 95600, lr = 1.70936e-06, m = 0.9
I0212 22:31:06.306327 12354 solver.cpp:314] Iteration 95700 (1.80319 iter/s, 55.4572s/100 iter), loss = 2.76397
I0212 22:31:06.306469 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.41677 (* 1 = 2.41677 loss)
I0212 22:31:06.306485 12354 sgd_solver.cpp:136] Iteration 95700, lr = 1.68151e-06, m = 0.9
I0212 22:32:01.534190 12354 solver.cpp:314] Iteration 95800 (1.81075 iter/s, 55.2258s/100 iter), loss = 3.00023
I0212 22:32:01.534402 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.36425 (* 1 = 2.36425 loss)
I0212 22:32:01.534441 12354 sgd_solver.cpp:136] Iteration 95800, lr = 1.654e-06, m = 0.9
I0212 22:32:58.183881 12354 solver.cpp:314] Iteration 95900 (1.7653 iter/s, 56.6476s/100 iter), loss = 2.85674
I0212 22:32:58.184005 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.63641 (* 1 = 2.63641 loss)
I0212 22:32:58.184021 12354 sgd_solver.cpp:136] Iteration 95900, lr = 1.62683e-06, m = 0.9
I0212 22:33:52.815186 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_96000.caffemodel
I0212 22:33:52.838979 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_96000.solverstate
I0212 22:33:52.850467 12354 solver.cpp:666] Iteration 96000, Testing net (#0)
I0212 22:34:42.617522 12354 solver.cpp:774] class AP 1: 0.376412
I0212 22:34:42.690541 12354 solver.cpp:774] class AP 2: 0.62524
I0212 22:34:42.701787 12354 solver.cpp:774] class AP 3: 0.630003
I0212 22:34:42.701808 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.543885
I0212 22:34:43.312393 12355 solver.cpp:774] class AP 1: 0.394237
I0212 22:34:43.383464 12355 solver.cpp:774] class AP 2: 0.64848
I0212 22:34:43.394485 12355 solver.cpp:774] class AP 3: 0.631817
I0212 22:34:43.394500 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.558178
I0212 22:34:43.394583 12354 solver.cpp:265] [MultiGPU] Tests completed in 50.5423s
I0212 22:34:43.808174 12354 solver.cpp:314] Iteration 96000 (0.946786 iter/s, 105.62s/100 iter), loss = 2.98974
I0212 22:34:43.808218 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.67036 (* 1 = 3.67036 loss)
I0212 22:34:43.808230 12354 sgd_solver.cpp:136] Iteration 96000, lr = 1.6e-06, m = 0.9
I0212 22:35:39.184573 12354 solver.cpp:314] Iteration 96100 (1.80589 iter/s, 55.3744s/100 iter), loss = 2.66984
I0212 22:35:39.184747 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.74123 (* 1 = 2.74123 loss)
I0212 22:35:39.184785 12354 sgd_solver.cpp:136] Iteration 96100, lr = 1.5735e-06, m = 0.9
I0212 22:36:33.726676 12354 solver.cpp:314] Iteration 96200 (1.83351 iter/s, 54.5401s/100 iter), loss = 2.86297
I0212 22:36:33.726974 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.04252 (* 1 = 3.04252 loss)
I0212 22:36:33.727035 12354 sgd_solver.cpp:136] Iteration 96200, lr = 1.54733e-06, m = 0.9
I0212 22:37:28.806891 12354 solver.cpp:314] Iteration 96300 (1.8156 iter/s, 55.0782s/100 iter), loss = 2.85198
I0212 22:37:28.807018 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.24021 (* 1 = 3.24021 loss)
I0212 22:37:28.807035 12354 sgd_solver.cpp:136] Iteration 96300, lr = 1.52149e-06, m = 0.9
I0212 22:38:24.944519 12354 solver.cpp:314] Iteration 96400 (1.7814 iter/s, 56.1356s/100 iter), loss = 3.05425
I0212 22:38:24.944978 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.58807 (* 1 = 3.58807 loss)
I0212 22:38:24.945250 12354 sgd_solver.cpp:136] Iteration 96400, lr = 1.49597e-06, m = 0.9
I0212 22:39:20.119385 12354 solver.cpp:314] Iteration 96500 (1.81249 iter/s, 55.1728s/100 iter), loss = 3.11606
I0212 22:39:20.119601 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.24251 (* 1 = 2.24251 loss)
I0212 22:39:20.119639 12354 sgd_solver.cpp:136] Iteration 96500, lr = 1.47078e-06, m = 0.9
I0212 22:40:15.305549 12354 solver.cpp:314] Iteration 96600 (1.81211 iter/s, 55.1841s/100 iter), loss = 2.89718
I0212 22:40:15.305675 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.36918 (* 1 = 3.36918 loss)
I0212 22:40:15.305690 12354 sgd_solver.cpp:136] Iteration 96600, lr = 1.4459e-06, m = 0.9
I0212 22:41:11.444986 12354 solver.cpp:314] Iteration 96700 (1.78134 iter/s, 56.1374s/100 iter), loss = 2.64714
I0212 22:41:11.445122 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.66719 (* 1 = 2.66719 loss)
I0212 22:41:11.445138 12354 sgd_solver.cpp:136] Iteration 96700, lr = 1.42134e-06, m = 0.9
I0212 22:42:07.063719 12354 solver.cpp:314] Iteration 96800 (1.79802 iter/s, 55.6167s/100 iter), loss = 2.95549
I0212 22:42:07.063858 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.4114 (* 1 = 3.4114 loss)
I0212 22:42:07.063872 12354 sgd_solver.cpp:136] Iteration 96800, lr = 1.3971e-06, m = 0.9
I0212 22:43:02.525794 12354 solver.cpp:314] Iteration 96900 (1.8031 iter/s, 55.46s/100 iter), loss = 2.80973
I0212 22:43:02.525991 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.5168 (* 1 = 3.5168 loss)
I0212 22:43:02.526033 12354 sgd_solver.cpp:136] Iteration 96900, lr = 1.37317e-06, m = 0.9
I0212 22:43:58.054514 12354 solver.cpp:314] Iteration 97000 (1.80094 iter/s, 55.5267s/100 iter), loss = 2.78537
I0212 22:43:58.054672 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.5267 (* 1 = 3.5267 loss)
I0212 22:43:58.054708 12354 sgd_solver.cpp:136] Iteration 97000, lr = 1.34954e-06, m = 0.9
I0212 22:44:52.991526 12354 solver.cpp:314] Iteration 97100 (1.82033 iter/s, 54.935s/100 iter), loss = 2.93423
I0212 22:44:52.991644 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.88186 (* 1 = 3.88186 loss)
I0212 22:44:52.991658 12354 sgd_solver.cpp:136] Iteration 97100, lr = 1.32622e-06, m = 0.9
I0212 22:45:48.747694 12354 solver.cpp:314] Iteration 97200 (1.79359 iter/s, 55.7541s/100 iter), loss = 2.87595
I0212 22:45:48.747867 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.52601 (* 1 = 2.52601 loss)
I0212 22:45:48.747905 12354 sgd_solver.cpp:136] Iteration 97200, lr = 1.30321e-06, m = 0.9
I0212 22:46:45.334221 12354 solver.cpp:314] Iteration 97300 (1.76727 iter/s, 56.5845s/100 iter), loss = 2.83676
I0212 22:46:45.334370 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.59539 (* 1 = 3.59539 loss)
I0212 22:46:45.334404 12354 sgd_solver.cpp:136] Iteration 97300, lr = 1.2805e-06, m = 0.9
I0212 22:47:41.363106 12354 solver.cpp:314] Iteration 97400 (1.78486 iter/s, 56.0268s/100 iter), loss = 2.88822
I0212 22:47:41.363217 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.30111 (* 1 = 3.30111 loss)
I0212 22:47:41.363232 12354 sgd_solver.cpp:136] Iteration 97400, lr = 1.25808e-06, m = 0.9
I0212 22:48:36.927283 12354 solver.cpp:314] Iteration 97500 (1.79979 iter/s, 55.5621s/100 iter), loss = 2.86896
I0212 22:48:36.927386 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.9792 (* 1 = 2.9792 loss)
I0212 22:48:36.927400 12354 sgd_solver.cpp:136] Iteration 97500, lr = 1.23596e-06, m = 0.9
I0212 22:49:33.981896 12354 solver.cpp:314] Iteration 97600 (1.75277 iter/s, 57.0525s/100 iter), loss = 3.03069
I0212 22:49:33.982074 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.23397 (* 1 = 2.23397 loss)
I0212 22:49:33.982139 12354 sgd_solver.cpp:136] Iteration 97600, lr = 1.21414e-06, m = 0.9
I0212 22:50:29.920326 12354 solver.cpp:314] Iteration 97700 (1.78775 iter/s, 55.9364s/100 iter), loss = 2.86347
I0212 22:50:29.920442 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.03929 (* 1 = 3.03929 loss)
I0212 22:50:29.920456 12354 sgd_solver.cpp:136] Iteration 97700, lr = 1.1926e-06, m = 0.9
I0212 22:51:25.686020 12354 solver.cpp:314] Iteration 97800 (1.79328 iter/s, 55.7637s/100 iter), loss = 2.55752
I0212 22:51:25.686213 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.55129 (* 1 = 2.55129 loss)
I0212 22:51:25.686254 12354 sgd_solver.cpp:136] Iteration 97800, lr = 1.17135e-06, m = 0.9
I0212 22:52:21.368374 12354 solver.cpp:314] Iteration 97900 (1.79597 iter/s, 55.6803s/100 iter), loss = 2.91812
I0212 22:52:21.368502 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.83087 (* 1 = 2.83087 loss)
I0212 22:52:21.368521 12354 sgd_solver.cpp:136] Iteration 97900, lr = 1.15039e-06, m = 0.9
I0212 22:53:16.146168 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_98000.caffemodel
I0212 22:53:16.192219 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_98000.solverstate
I0212 22:53:16.205591 12354 solver.cpp:666] Iteration 98000, Testing net (#0)
I0212 22:54:06.894721 12355 solver.cpp:774] class AP 1: 0.394516
I0212 22:54:06.969287 12355 solver.cpp:774] class AP 2: 0.647264
I0212 22:54:06.981722 12355 solver.cpp:774] class AP 3: 0.633707
I0212 22:54:06.981755 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.558496
I0212 22:54:08.363319 12354 solver.cpp:774] class AP 1: 0.374278
I0212 22:54:08.434708 12354 solver.cpp:774] class AP 2: 0.623239
I0212 22:54:08.445978 12354 solver.cpp:774] class AP 3: 0.628674
I0212 22:54:08.446003 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.542064
I0212 22:54:08.446069 12354 solver.cpp:265] [MultiGPU] Tests completed in 52.2386s
I0212 22:54:08.894598 12354 solver.cpp:314] Iteration 98000 (0.93004 iter/s, 107.522s/100 iter), loss = 3.01276
I0212 22:54:08.894636 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.74666 (* 1 = 2.74666 loss)
I0212 22:54:08.894645 12354 sgd_solver.cpp:136] Iteration 98000, lr = 1.12971e-06, m = 0.9
I0212 22:55:03.973958 12354 solver.cpp:314] Iteration 98100 (1.81563 iter/s, 55.0774s/100 iter), loss = 3.01808
I0212 22:55:03.974069 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.03768 (* 1 = 3.03768 loss)
I0212 22:55:03.974083 12354 sgd_solver.cpp:136] Iteration 98100, lr = 1.10931e-06, m = 0.9
I0212 22:55:59.927740 12354 solver.cpp:314] Iteration 98200 (1.78725 iter/s, 55.9517s/100 iter), loss = 2.96573
I0212 22:55:59.927855 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.71001 (* 1 = 4.71001 loss)
I0212 22:55:59.927875 12354 sgd_solver.cpp:136] Iteration 98200, lr = 1.08918e-06, m = 0.9
I0212 22:56:49.257149 12274 data_reader.cpp:305] Starting prefetch of epoch 24
I0212 22:56:55.333961 12354 solver.cpp:314] Iteration 98300 (1.80492 iter/s, 55.4042s/100 iter), loss = 3.08919
I0212 22:56:55.334017 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.62053 (* 1 = 4.62053 loss)
I0212 22:56:55.334029 12354 sgd_solver.cpp:136] Iteration 98300, lr = 1.06934e-06, m = 0.9
I0212 22:57:50.748746 12354 solver.cpp:314] Iteration 98400 (1.80464 iter/s, 55.4128s/100 iter), loss = 2.86372
I0212 22:57:50.748844 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.31213 (* 1 = 3.31213 loss)
I0212 22:57:50.748854 12354 sgd_solver.cpp:136] Iteration 98400, lr = 1.04976e-06, m = 0.9
I0212 22:58:46.370384 12354 solver.cpp:314] Iteration 98500 (1.79793 iter/s, 55.6196s/100 iter), loss = 2.70403
I0212 22:58:46.370483 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.23689 (* 1 = 3.23689 loss)
I0212 22:58:46.370498 12354 sgd_solver.cpp:136] Iteration 98500, lr = 1.03045e-06, m = 0.9
I0212 22:59:41.178156 12354 solver.cpp:314] Iteration 98600 (1.82463 iter/s, 54.8058s/100 iter), loss = 2.98949
I0212 22:59:41.190579 12354 solver.cpp:336]     Train net output #0: mbox_loss = 1.9951 (* 1 = 1.9951 loss)
I0212 22:59:41.190891 12354 sgd_solver.cpp:136] Iteration 98600, lr = 1.01142e-06, m = 0.9
I0212 23:00:37.080690 12354 solver.cpp:314] Iteration 98700 (1.78889 iter/s, 55.9005s/100 iter), loss = 2.90181
I0212 23:00:37.080788 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.20149 (* 1 = 2.20149 loss)
I0212 23:00:37.080803 12354 sgd_solver.cpp:136] Iteration 98700, lr = 9.92644e-07, m = 0.9
I0212 23:01:32.672410 12354 solver.cpp:314] Iteration 98800 (1.79889 iter/s, 55.5897s/100 iter), loss = 3.02238
I0212 23:01:32.686254 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.39143 (* 1 = 2.39143 loss)
I0212 23:01:32.686307 12354 sgd_solver.cpp:136] Iteration 98800, lr = 9.74134e-07, m = 0.9
I0212 23:02:28.007088 12354 solver.cpp:314] Iteration 98900 (1.80725 iter/s, 55.3327s/100 iter), loss = 2.94027
I0212 23:02:28.007195 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.66502 (* 1 = 2.66502 loss)
I0212 23:02:28.007206 12354 sgd_solver.cpp:136] Iteration 98900, lr = 9.55883e-07, m = 0.9
I0212 23:03:23.127058 12354 solver.cpp:314] Iteration 99000 (1.81429 iter/s, 55.118s/100 iter), loss = 2.86859
I0212 23:03:23.136289 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.01782 (* 1 = 2.01782 loss)
I0212 23:03:23.136338 12354 sgd_solver.cpp:136] Iteration 99000, lr = 9.37891e-07, m = 0.9
I0212 23:04:19.011250 12354 solver.cpp:314] Iteration 99100 (1.78948 iter/s, 55.8821s/100 iter), loss = 3.0828
I0212 23:04:19.011373 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.77896 (* 1 = 4.77896 loss)
I0212 23:04:19.011387 12354 sgd_solver.cpp:136] Iteration 99100, lr = 9.20154e-07, m = 0.9
I0212 23:05:14.345122 12354 solver.cpp:314] Iteration 99200 (1.80728 iter/s, 55.3319s/100 iter), loss = 2.80005
I0212 23:05:14.345252 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.32669 (* 1 = 2.32669 loss)
I0212 23:05:14.345270 12354 sgd_solver.cpp:136] Iteration 99200, lr = 9.02669e-07, m = 0.9
I0212 23:06:09.070533 12354 solver.cpp:314] Iteration 99300 (1.82737 iter/s, 54.7234s/100 iter), loss = 2.95224
I0212 23:06:09.070659 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.18831 (* 1 = 2.18831 loss)
I0212 23:06:09.070675 12354 sgd_solver.cpp:136] Iteration 99300, lr = 8.85435e-07, m = 0.9
I0212 23:07:02.945917 12354 solver.cpp:314] Iteration 99400 (1.8562 iter/s, 53.8734s/100 iter), loss = 2.80262
I0212 23:07:02.946125 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.1021 (* 1 = 2.1021 loss)
I0212 23:07:02.946163 12354 sgd_solver.cpp:136] Iteration 99400, lr = 8.68449e-07, m = 0.9
I0212 23:07:57.860592 12354 solver.cpp:314] Iteration 99500 (1.82107 iter/s, 54.9127s/100 iter), loss = 2.94935
I0212 23:07:57.860707 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.94876 (* 1 = 3.94876 loss)
I0212 23:07:57.860723 12354 sgd_solver.cpp:136] Iteration 99500, lr = 8.51708e-07, m = 0.9
I0212 23:08:52.682932 12354 solver.cpp:314] Iteration 99600 (1.82414 iter/s, 54.8203s/100 iter), loss = 3.08611
I0212 23:08:52.683048 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.15506 (* 1 = 2.15506 loss)
I0212 23:08:52.683063 12354 sgd_solver.cpp:136] Iteration 99600, lr = 8.3521e-07, m = 0.9
I0212 23:09:48.395470 12354 solver.cpp:314] Iteration 99700 (1.79499 iter/s, 55.7105s/100 iter), loss = 2.79449
I0212 23:09:48.395617 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.29456 (* 1 = 2.29456 loss)
I0212 23:09:48.395634 12354 sgd_solver.cpp:136] Iteration 99700, lr = 8.18954e-07, m = 0.9
I0212 23:10:43.118717 12354 solver.cpp:314] Iteration 99800 (1.82744 iter/s, 54.7213s/100 iter), loss = 2.92703
I0212 23:10:43.118832 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.26827 (* 1 = 3.26827 loss)
I0212 23:10:43.118849 12354 sgd_solver.cpp:136] Iteration 99800, lr = 8.02936e-07, m = 0.9
I0212 23:11:39.031445 12354 solver.cpp:314] Iteration 99900 (1.78857 iter/s, 55.9107s/100 iter), loss = 3.06474
I0212 23:11:39.031533 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.06604 (* 1 = 3.06604 loss)
I0212 23:11:39.031543 12354 sgd_solver.cpp:136] Iteration 99900, lr = 7.87154e-07, m = 0.9
I0212 23:12:34.075681 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_100000.caffemodel
I0212 23:12:34.100411 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_100000.solverstate
I0212 23:12:34.124969 12354 solver.cpp:666] Iteration 100000, Testing net (#0)
I0212 23:13:24.591714 12355 solver.cpp:774] class AP 1: 0.395675
I0212 23:13:24.655210 12355 solver.cpp:774] class AP 2: 0.644669
I0212 23:13:24.666353 12355 solver.cpp:774] class AP 3: 0.635555
I0212 23:13:24.666369 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.558633
I0212 23:13:25.171877 12354 solver.cpp:774] class AP 1: 0.373735
I0212 23:13:25.240650 12354 solver.cpp:774] class AP 2: 0.629425
I0212 23:13:25.252933 12354 solver.cpp:774] class AP 3: 0.625086
I0212 23:13:25.252976 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.542749
I0212 23:13:25.253010 12354 solver.cpp:265] [MultiGPU] Tests completed in 51.1262s
I0212 23:13:25.886551 12354 solver.cpp:314] Iteration 100000 (0.935881 iter/s, 106.851s/100 iter), loss = 2.88704
I0212 23:13:25.886592 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.72721 (* 1 = 2.72721 loss)
I0212 23:13:25.886601 12354 sgd_solver.cpp:136] Iteration 100000, lr = 7.71605e-07, m = 0.9
I0212 23:14:20.917742 12354 solver.cpp:314] Iteration 100100 (1.81722 iter/s, 55.0292s/100 iter), loss = 2.84036
I0212 23:14:20.917886 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.24332 (* 1 = 2.24332 loss)
I0212 23:14:20.917903 12354 sgd_solver.cpp:136] Iteration 100100, lr = 7.56289e-07, m = 0.9
I0212 23:15:15.915797 12354 solver.cpp:314] Iteration 100200 (1.81831 iter/s, 54.9961s/100 iter), loss = 2.87602
I0212 23:15:15.917999 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.11464 (* 1 = 2.11464 loss)
I0212 23:15:15.918022 12354 sgd_solver.cpp:136] Iteration 100200, lr = 7.41201e-07, m = 0.9
I0212 23:16:10.398514 12354 solver.cpp:314] Iteration 100300 (1.83551 iter/s, 54.4807s/100 iter), loss = 2.85111
I0212 23:16:10.398607 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.23266 (* 1 = 2.23266 loss)
I0212 23:16:10.398622 12354 sgd_solver.cpp:136] Iteration 100300, lr = 7.2634e-07, m = 0.9
I0212 23:17:06.739521 12354 solver.cpp:314] Iteration 100400 (1.77497 iter/s, 56.339s/100 iter), loss = 3.03967
I0212 23:17:06.739670 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.12652 (* 1 = 4.12652 loss)
I0212 23:17:06.739686 12354 sgd_solver.cpp:136] Iteration 100400, lr = 7.11704e-07, m = 0.9
I0212 23:18:02.509522 12354 solver.cpp:314] Iteration 100500 (1.79314 iter/s, 55.768s/100 iter), loss = 2.83614
I0212 23:18:02.509635 12354 solver.cpp:336]     Train net output #0: mbox_loss = 1.90923 (* 1 = 1.90923 loss)
I0212 23:18:02.509650 12354 sgd_solver.cpp:136] Iteration 100500, lr = 6.9729e-07, m = 0.9
I0212 23:18:57.885720 12354 solver.cpp:314] Iteration 100600 (1.8059 iter/s, 55.3742s/100 iter), loss = 2.86744
I0212 23:18:57.885835 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.27993 (* 1 = 2.27993 loss)
I0212 23:18:57.885850 12354 sgd_solver.cpp:136] Iteration 100600, lr = 6.83097e-07, m = 0.9
I0212 23:19:53.443975 12354 solver.cpp:314] Iteration 100700 (1.79998 iter/s, 55.5562s/100 iter), loss = 2.84228
I0212 23:19:53.444092 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.69607 (* 1 = 2.69607 loss)
I0212 23:19:53.444108 12354 sgd_solver.cpp:136] Iteration 100700, lr = 6.69121e-07, m = 0.9
I0212 23:20:49.487355 12354 solver.cpp:314] Iteration 100800 (1.7844 iter/s, 56.0413s/100 iter), loss = 2.72487
I0212 23:20:49.487499 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.38284 (* 1 = 2.38284 loss)
I0212 23:20:49.487517 12354 sgd_solver.cpp:136] Iteration 100800, lr = 6.5536e-07, m = 0.9
I0212 23:21:44.166190 12354 solver.cpp:314] Iteration 100900 (1.82893 iter/s, 54.6768s/100 iter), loss = 2.67448
I0212 23:21:44.166311 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.08357 (* 1 = 2.08357 loss)
I0212 23:21:44.166329 12354 sgd_solver.cpp:136] Iteration 100900, lr = 6.41813e-07, m = 0.9
I0212 23:22:37.959161 12354 solver.cpp:314] Iteration 101000 (1.85905 iter/s, 53.791s/100 iter), loss = 2.97621
I0212 23:22:37.959308 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.55246 (* 1 = 3.55246 loss)
I0212 23:22:37.959324 12354 sgd_solver.cpp:136] Iteration 101000, lr = 6.28477e-07, m = 0.9
I0212 23:23:33.686169 12354 solver.cpp:314] Iteration 101100 (1.79453 iter/s, 55.725s/100 iter), loss = 2.88968
I0212 23:23:33.686287 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.43574 (* 1 = 2.43574 loss)
I0212 23:23:33.686302 12354 sgd_solver.cpp:136] Iteration 101100, lr = 6.15351e-07, m = 0.9
I0212 23:24:28.697723 12354 solver.cpp:314] Iteration 101200 (1.81787 iter/s, 55.0096s/100 iter), loss = 3.01011
I0212 23:24:28.710208 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.92369 (* 1 = 2.92369 loss)
I0212 23:24:28.710237 12354 sgd_solver.cpp:136] Iteration 101200, lr = 6.0243e-07, m = 0.9
I0212 23:25:25.113224 12354 solver.cpp:314] Iteration 101300 (1.77263 iter/s, 56.4134s/100 iter), loss = 2.78893
I0212 23:25:25.113343 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.23366 (* 1 = 2.23366 loss)
I0212 23:25:25.113360 12354 sgd_solver.cpp:136] Iteration 101300, lr = 5.89714e-07, m = 0.9
I0212 23:26:19.996564 12354 solver.cpp:314] Iteration 101400 (1.82211 iter/s, 54.8813s/100 iter), loss = 2.80747
I0212 23:26:19.996702 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.31014 (* 1 = 3.31014 loss)
I0212 23:26:19.996718 12354 sgd_solver.cpp:136] Iteration 101400, lr = 5.772e-07, m = 0.9
I0212 23:26:29.271005 12274 data_reader.cpp:305] Starting prefetch of epoch 25
I0212 23:27:15.096041 12354 solver.cpp:314] Iteration 101500 (1.81497 iter/s, 55.0975s/100 iter), loss = 2.91747
I0212 23:27:15.096159 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.32826 (* 1 = 3.32826 loss)
I0212 23:27:15.096174 12354 sgd_solver.cpp:136] Iteration 101500, lr = 5.64887e-07, m = 0.9
I0212 23:28:09.987244 12354 solver.cpp:314] Iteration 101600 (1.82185 iter/s, 54.8892s/100 iter), loss = 2.9745
I0212 23:28:09.987413 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.95832 (* 1 = 3.95832 loss)
I0212 23:28:09.987460 12354 sgd_solver.cpp:136] Iteration 101600, lr = 5.52772e-07, m = 0.9
I0212 23:29:05.438208 12354 solver.cpp:314] Iteration 101700 (1.80346 iter/s, 55.4489s/100 iter), loss = 2.83367
I0212 23:29:05.438343 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.21143 (* 1 = 3.21143 loss)
I0212 23:29:05.438359 12354 sgd_solver.cpp:136] Iteration 101700, lr = 5.40853e-07, m = 0.9
I0212 23:30:00.421243 12354 solver.cpp:314] Iteration 101800 (1.81881 iter/s, 54.981s/100 iter), loss = 3.03834
I0212 23:30:00.421363 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.72892 (* 1 = 2.72892 loss)
I0212 23:30:00.421377 12354 sgd_solver.cpp:136] Iteration 101800, lr = 5.29127e-07, m = 0.9
I0212 23:30:55.980171 12354 solver.cpp:314] Iteration 101900 (1.79996 iter/s, 55.5569s/100 iter), loss = 2.78974
I0212 23:30:55.980471 12354 solver.cpp:336]     Train net output #0: mbox_loss = 1.97071 (* 1 = 1.97071 loss)
I0212 23:30:55.980537 12354 sgd_solver.cpp:136] Iteration 101900, lr = 5.17594e-07, m = 0.9
I0212 23:31:49.755579 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_102000.caffemodel
I0212 23:31:49.779346 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_102000.solverstate
I0212 23:31:49.788609 12354 solver.cpp:666] Iteration 102000, Testing net (#0)
I0212 23:32:40.005215 12355 solver.cpp:774] class AP 1: 0.393797
I0212 23:32:40.070338 12355 solver.cpp:774] class AP 2: 0.648842
I0212 23:32:40.081559 12355 solver.cpp:774] class AP 3: 0.6356
I0212 23:32:40.081578 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.559413
I0212 23:32:41.012151 12354 solver.cpp:774] class AP 1: 0.37575
I0212 23:32:41.078445 12354 solver.cpp:774] class AP 2: 0.627876
I0212 23:32:41.089556 12354 solver.cpp:774] class AP 3: 0.626506
I0212 23:32:41.089573 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.543377
I0212 23:32:41.089608 12354 solver.cpp:265] [MultiGPU] Tests completed in 51.2991s
I0212 23:32:41.507585 12354 solver.cpp:314] Iteration 102000 (0.947656 iter/s, 105.524s/100 iter), loss = 2.92969
I0212 23:32:41.507625 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.69944 (* 1 = 2.69944 loss)
I0212 23:32:41.507635 12354 sgd_solver.cpp:136] Iteration 102000, lr = 5.0625e-07, m = 0.9
I0212 23:33:35.970949 12354 solver.cpp:314] Iteration 102100 (1.83616 iter/s, 54.4614s/100 iter), loss = 2.98764
I0212 23:33:35.971246 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.40642 (* 1 = 2.40642 loss)
I0212 23:33:35.971262 12354 sgd_solver.cpp:136] Iteration 102100, lr = 4.95093e-07, m = 0.9
I0212 23:34:31.891504 12354 solver.cpp:314] Iteration 102200 (1.78832 iter/s, 55.9185s/100 iter), loss = 2.70743
I0212 23:34:31.891600 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.28421 (* 1 = 2.28421 loss)
I0212 23:34:31.891615 12354 sgd_solver.cpp:136] Iteration 102200, lr = 4.84122e-07, m = 0.9
I0212 23:35:27.618968 12354 solver.cpp:314] Iteration 102300 (1.79451 iter/s, 55.7254s/100 iter), loss = 3.02437
I0212 23:35:27.619071 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.68255 (* 1 = 2.68255 loss)
I0212 23:35:27.619091 12354 sgd_solver.cpp:136] Iteration 102300, lr = 4.73334e-07, m = 0.9
I0212 23:36:23.494969 12354 solver.cpp:314] Iteration 102400 (1.78974 iter/s, 55.874s/100 iter), loss = 2.73045
I0212 23:36:23.495100 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.1329 (* 1 = 2.1329 loss)
I0212 23:36:23.495115 12354 sgd_solver.cpp:136] Iteration 102400, lr = 4.62728e-07, m = 0.9
I0212 23:37:18.629832 12354 solver.cpp:314] Iteration 102500 (1.8138 iter/s, 55.1329s/100 iter), loss = 2.81868
I0212 23:37:18.629956 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.21873 (* 1 = 3.21873 loss)
I0212 23:37:18.629973 12354 sgd_solver.cpp:136] Iteration 102500, lr = 4.523e-07, m = 0.9
I0212 23:38:14.208240 12354 solver.cpp:314] Iteration 102600 (1.79933 iter/s, 55.5764s/100 iter), loss = 2.81977
I0212 23:38:14.208367 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.66446 (* 1 = 2.66446 loss)
I0212 23:38:14.208384 12354 sgd_solver.cpp:136] Iteration 102600, lr = 4.4205e-07, m = 0.9
I0212 23:39:10.219132 12354 solver.cpp:314] Iteration 102700 (1.78543 iter/s, 56.0089s/100 iter), loss = 2.90265
I0212 23:39:10.219267 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.02528 (* 1 = 3.02528 loss)
I0212 23:39:10.219281 12354 sgd_solver.cpp:136] Iteration 102700, lr = 4.31976e-07, m = 0.9
I0212 23:40:06.293221 12354 solver.cpp:314] Iteration 102800 (1.78342 iter/s, 56.072s/100 iter), loss = 2.7769
I0212 23:40:06.293861 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.79835 (* 1 = 2.79835 loss)
I0212 23:40:06.294251 12354 sgd_solver.cpp:136] Iteration 102800, lr = 4.22074e-07, m = 0.9
I0212 23:41:01.718200 12354 solver.cpp:314] Iteration 102900 (1.80431 iter/s, 55.423s/100 iter), loss = 2.72872
I0212 23:41:01.718330 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.60506 (* 1 = 2.60506 loss)
I0212 23:41:01.718344 12354 sgd_solver.cpp:136] Iteration 102900, lr = 4.12344e-07, m = 0.9
I0212 23:41:57.461726 12354 solver.cpp:314] Iteration 103000 (1.794 iter/s, 55.7415s/100 iter), loss = 2.74586
I0212 23:41:57.461829 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.62512 (* 1 = 2.62512 loss)
I0212 23:41:57.461843 12354 sgd_solver.cpp:136] Iteration 103000, lr = 4.02782e-07, m = 0.9
I0212 23:42:52.571422 12354 solver.cpp:314] Iteration 103100 (1.81463 iter/s, 55.1077s/100 iter), loss = 3.06304
I0212 23:42:52.571928 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.24393 (* 1 = 2.24393 loss)
I0212 23:42:52.571946 12354 sgd_solver.cpp:136] Iteration 103100, lr = 3.93389e-07, m = 0.9
I0212 23:43:47.132158 12354 solver.cpp:314] Iteration 103200 (1.83289 iter/s, 54.5587s/100 iter), loss = 2.86022
I0212 23:43:47.137254 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.79222 (* 1 = 2.79222 loss)
I0212 23:43:47.137279 12354 sgd_solver.cpp:136] Iteration 103200, lr = 3.8416e-07, m = 0.9
I0212 23:44:42.370148 12354 solver.cpp:314] Iteration 103300 (1.81041 iter/s, 55.236s/100 iter), loss = 2.98082
I0212 23:44:42.370277 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.92471 (* 1 = 2.92471 loss)
I0212 23:44:42.370296 12354 sgd_solver.cpp:136] Iteration 103300, lr = 3.75095e-07, m = 0.9
I0212 23:45:37.777235 12354 solver.cpp:314] Iteration 103400 (1.80489 iter/s, 55.4051s/100 iter), loss = 2.87223
I0212 23:45:37.777364 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.20453 (* 1 = 3.20453 loss)
I0212 23:45:37.777380 12354 sgd_solver.cpp:136] Iteration 103400, lr = 3.66191e-07, m = 0.9
I0212 23:46:33.081306 12354 solver.cpp:314] Iteration 103500 (1.80825 iter/s, 55.3021s/100 iter), loss = 2.62619
I0212 23:46:33.081418 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.51674 (* 1 = 2.51674 loss)
I0212 23:46:33.081432 12354 sgd_solver.cpp:136] Iteration 103500, lr = 3.57446e-07, m = 0.9
I0212 23:47:28.082170 12354 solver.cpp:314] Iteration 103600 (1.81822 iter/s, 54.9989s/100 iter), loss = 3.07093
I0212 23:47:28.085856 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.43041 (* 1 = 3.43041 loss)
I0212 23:47:28.085904 12354 sgd_solver.cpp:136] Iteration 103600, lr = 3.48859e-07, m = 0.9
I0212 23:48:23.783128 12354 solver.cpp:314] Iteration 103700 (1.79537 iter/s, 55.6989s/100 iter), loss = 3.04626
I0212 23:48:23.783263 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.16709 (* 1 = 2.16709 loss)
I0212 23:48:23.783282 12354 sgd_solver.cpp:136] Iteration 103700, lr = 3.40428e-07, m = 0.9
I0212 23:49:18.599297 12354 solver.cpp:314] Iteration 103800 (1.82435 iter/s, 54.8142s/100 iter), loss = 3.03119
I0212 23:49:18.599426 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.5419 (* 1 = 2.5419 loss)
I0212 23:49:18.599447 12354 sgd_solver.cpp:136] Iteration 103800, lr = 3.32151e-07, m = 0.9
I0212 23:50:13.824702 12354 solver.cpp:314] Iteration 103900 (1.81083 iter/s, 55.2234s/100 iter), loss = 3.13518
I0212 23:50:13.824827 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.34172 (* 1 = 4.34172 loss)
I0212 23:50:13.824843 12354 sgd_solver.cpp:136] Iteration 103900, lr = 3.24025e-07, m = 0.9
I0212 23:51:08.169963 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_104000.caffemodel
I0212 23:51:08.190966 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_104000.solverstate
I0212 23:51:08.200670 12354 solver.cpp:666] Iteration 104000, Testing net (#0)
I0212 23:51:58.135808 12355 solver.cpp:774] class AP 1: 0.397491
I0212 23:51:58.208201 12355 solver.cpp:774] class AP 2: 0.645256
I0212 23:51:58.219384 12355 solver.cpp:774] class AP 3: 0.633187
I0212 23:51:58.219399 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.558645
I0212 23:51:59.114905 12354 solver.cpp:774] class AP 1: 0.37459
I0212 23:51:59.180510 12354 solver.cpp:774] class AP 2: 0.632041
I0212 23:51:59.190286 12354 solver.cpp:774] class AP 3: 0.628308
I0212 23:51:59.190297 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.54498
I0212 23:51:59.190335 12354 solver.cpp:265] [MultiGPU] Tests completed in 50.9878s
I0212 23:51:59.726938 12354 solver.cpp:314] Iteration 104000 (0.944301 iter/s, 105.898s/100 iter), loss = 2.84893
I0212 23:51:59.726981 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.2483 (* 1 = 4.2483 loss)
I0212 23:51:59.726991 12354 sgd_solver.cpp:136] Iteration 104000, lr = 3.16049e-07, m = 0.9
I0212 23:52:55.685458 12354 solver.cpp:314] Iteration 104100 (1.7871 iter/s, 55.9565s/100 iter), loss = 2.85396
I0212 23:52:55.685715 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.93637 (* 1 = 3.93637 loss)
I0212 23:52:55.685751 12354 sgd_solver.cpp:136] Iteration 104100, lr = 3.08222e-07, m = 0.9
I0212 23:53:51.166326 12274 data_reader.cpp:305] Starting prefetch of epoch 26
I0212 23:53:51.642323 12354 solver.cpp:314] Iteration 104200 (1.78716 iter/s, 55.9548s/100 iter), loss = 2.92568
I0212 23:53:51.642379 12354 solver.cpp:336]     Train net output #0: mbox_loss = 1.98731 (* 1 = 1.98731 loss)
I0212 23:53:51.642392 12354 sgd_solver.cpp:136] Iteration 104200, lr = 3.00541e-07, m = 0.9
I0212 23:54:46.339159 12354 solver.cpp:314] Iteration 104300 (1.82833 iter/s, 54.6948s/100 iter), loss = 2.93527
I0212 23:54:46.339290 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.00926 (* 1 = 4.00926 loss)
I0212 23:54:46.339305 12354 sgd_solver.cpp:136] Iteration 104300, lr = 2.93004e-07, m = 0.9
I0212 23:55:41.723698 12354 solver.cpp:314] Iteration 104400 (1.80562 iter/s, 55.3825s/100 iter), loss = 2.76032
I0212 23:55:41.723799 12354 solver.cpp:336]     Train net output #0: mbox_loss = 1.96128 (* 1 = 1.96128 loss)
I0212 23:55:41.723815 12354 sgd_solver.cpp:136] Iteration 104400, lr = 2.8561e-07, m = 0.9
I0212 23:56:36.498348 12354 solver.cpp:314] Iteration 104500 (1.82573 iter/s, 54.7727s/100 iter), loss = 2.81656
I0212 23:56:36.498477 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.25591 (* 1 = 3.25591 loss)
I0212 23:56:36.498492 12354 sgd_solver.cpp:136] Iteration 104500, lr = 2.78357e-07, m = 0.9
I0212 23:57:32.382447 12354 solver.cpp:314] Iteration 104600 (1.78948 iter/s, 55.8821s/100 iter), loss = 2.94682
I0212 23:57:32.382568 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.55938 (* 1 = 2.55938 loss)
I0212 23:57:32.382583 12354 sgd_solver.cpp:136] Iteration 104600, lr = 2.71243e-07, m = 0.9
I0212 23:58:28.049643 12354 solver.cpp:314] Iteration 104700 (1.79646 iter/s, 55.6652s/100 iter), loss = 3.0648
I0212 23:58:28.049767 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.72015 (* 1 = 3.72015 loss)
I0212 23:58:28.049783 12354 sgd_solver.cpp:136] Iteration 104700, lr = 2.64266e-07, m = 0.9
I0212 23:59:23.514019 12354 solver.cpp:314] Iteration 104800 (1.80302 iter/s, 55.4624s/100 iter), loss = 2.98865
I0212 23:59:23.514170 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.00375 (* 1 = 3.00375 loss)
I0212 23:59:23.514696 12354 sgd_solver.cpp:136] Iteration 104800, lr = 2.57424e-07, m = 0.9
I0213 00:00:18.238164 12354 solver.cpp:314] Iteration 104900 (1.82741 iter/s, 54.7222s/100 iter), loss = 3.04417
I0213 00:00:18.238282 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.43126 (* 1 = 3.43126 loss)
I0213 00:00:18.238301 12354 sgd_solver.cpp:136] Iteration 104900, lr = 2.50716e-07, m = 0.9
I0213 00:01:13.350842 12354 solver.cpp:314] Iteration 105000 (1.81453 iter/s, 55.1107s/100 iter), loss = 2.97192
I0213 00:01:13.351061 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.09039 (* 1 = 3.09039 loss)
I0213 00:01:13.351095 12354 sgd_solver.cpp:136] Iteration 105000, lr = 2.44141e-07, m = 0.9
I0213 00:02:07.622313 12354 solver.cpp:314] Iteration 105100 (1.84266 iter/s, 54.2695s/100 iter), loss = 2.81515
I0213 00:02:07.622484 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.35846 (* 1 = 3.35846 loss)
I0213 00:02:07.622504 12354 sgd_solver.cpp:136] Iteration 105100, lr = 2.37695e-07, m = 0.9
I0213 00:03:02.709079 12354 solver.cpp:314] Iteration 105200 (1.81538 iter/s, 55.0848s/100 iter), loss = 3.01678
I0213 00:03:02.709293 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.28985 (* 1 = 2.28985 loss)
I0213 00:03:02.709331 12354 sgd_solver.cpp:136] Iteration 105200, lr = 2.31378e-07, m = 0.9
I0213 00:03:58.700419 12354 solver.cpp:314] Iteration 105300 (1.78606 iter/s, 55.9893s/100 iter), loss = 2.89063
I0213 00:03:58.700547 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.02249 (* 1 = 3.02249 loss)
I0213 00:03:58.700562 12354 sgd_solver.cpp:136] Iteration 105300, lr = 2.25188e-07, m = 0.9
I0213 00:04:54.348302 12354 solver.cpp:314] Iteration 105400 (1.79708 iter/s, 55.6459s/100 iter), loss = 2.78719
I0213 00:04:54.348456 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.88846 (* 1 = 2.88846 loss)
I0213 00:04:54.348472 12354 sgd_solver.cpp:136] Iteration 105400, lr = 2.19122e-07, m = 0.9
I0213 00:05:49.511684 12354 solver.cpp:314] Iteration 105500 (1.81286 iter/s, 55.1614s/100 iter), loss = 2.82878
I0213 00:05:49.511801 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.64523 (* 1 = 2.64523 loss)
I0213 00:05:49.512131 12354 sgd_solver.cpp:136] Iteration 105500, lr = 2.1318e-07, m = 0.9
I0213 00:06:44.686565 12354 solver.cpp:314] Iteration 105600 (1.81249 iter/s, 55.1729s/100 iter), loss = 2.88686
I0213 00:06:44.686682 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.30813 (* 1 = 2.30813 loss)
I0213 00:06:44.686697 12354 sgd_solver.cpp:136] Iteration 105600, lr = 2.0736e-07, m = 0.9
I0213 00:07:39.902565 12354 solver.cpp:314] Iteration 105700 (1.81114 iter/s, 55.214s/100 iter), loss = 2.99108
I0213 00:07:39.902694 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.55193 (* 1 = 3.55193 loss)
I0213 00:07:39.902710 12354 sgd_solver.cpp:136] Iteration 105700, lr = 2.0166e-07, m = 0.9
I0213 00:08:35.044852 12354 solver.cpp:314] Iteration 105800 (1.81356 iter/s, 55.1403s/100 iter), loss = 2.75309
I0213 00:08:35.044975 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.931 (* 1 = 2.931 loss)
I0213 00:08:35.044994 12354 sgd_solver.cpp:136] Iteration 105800, lr = 1.96078e-07, m = 0.9
I0213 00:09:31.644434 12354 solver.cpp:314] Iteration 105900 (1.76686 iter/s, 56.5975s/100 iter), loss = 2.97466
I0213 00:09:31.644548 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.41762 (* 1 = 3.41762 loss)
I0213 00:09:31.644907 12354 sgd_solver.cpp:136] Iteration 105900, lr = 1.90613e-07, m = 0.9
I0213 00:10:26.591838 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_106000.caffemodel
I0213 00:10:26.609802 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_106000.solverstate
I0213 00:10:26.620018 12354 solver.cpp:666] Iteration 106000, Testing net (#0)
I0213 00:10:45.704596 12354 blocking_queue.cpp:40] Data layer prefetch queue empty
I0213 00:11:16.412549 12354 solver.cpp:774] class AP 1: 0.375905
I0213 00:11:16.482378 12354 solver.cpp:774] class AP 2: 0.631694
I0213 00:11:16.493680 12354 solver.cpp:774] class AP 3: 0.628875
I0213 00:11:16.493693 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.545491
I0213 00:11:17.164106 12355 solver.cpp:774] class AP 1: 0.394133
I0213 00:11:17.234072 12355 solver.cpp:774] class AP 2: 0.643693
I0213 00:11:17.244889 12355 solver.cpp:774] class AP 3: 0.632216
I0213 00:11:17.244902 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.556681
I0213 00:11:17.245030 12354 solver.cpp:265] [MultiGPU] Tests completed in 50.6232s
I0213 00:11:17.621543 12354 solver.cpp:314] Iteration 106000 (0.943634 iter/s, 105.973s/100 iter), loss = 3.15463
I0213 00:11:17.621657 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.27745 (* 1 = 2.27745 loss)
I0213 00:11:17.621692 12354 sgd_solver.cpp:136] Iteration 106000, lr = 1.85262e-07, m = 0.9
I0213 00:12:12.330430 12354 solver.cpp:314] Iteration 106100 (1.82792 iter/s, 54.7069s/100 iter), loss = 2.88305
I0213 00:12:12.330552 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.10734 (* 1 = 2.10734 loss)
I0213 00:12:12.330569 12354 sgd_solver.cpp:136] Iteration 106100, lr = 1.80026e-07, m = 0.9
I0213 00:13:07.441645 12354 solver.cpp:314] Iteration 106200 (1.81458 iter/s, 55.1092s/100 iter), loss = 2.76003
I0213 00:13:07.441807 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.64536 (* 1 = 2.64536 loss)
I0213 00:13:07.441826 12354 sgd_solver.cpp:136] Iteration 106200, lr = 1.74901e-07, m = 0.9
I0213 00:14:02.498720 12354 solver.cpp:314] Iteration 106300 (1.81636 iter/s, 55.0551s/100 iter), loss = 3.1121
I0213 00:14:02.498858 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.23533 (* 1 = 3.23533 loss)
I0213 00:14:02.498878 12354 sgd_solver.cpp:136] Iteration 106300, lr = 1.69886e-07, m = 0.9
I0213 00:14:58.115200 12354 solver.cpp:314] Iteration 106400 (1.79809 iter/s, 55.6144s/100 iter), loss = 2.89324
I0213 00:14:58.115402 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.59407 (* 1 = 2.59407 loss)
I0213 00:14:58.115422 12354 sgd_solver.cpp:136] Iteration 106400, lr = 1.6498e-07, m = 0.9
I0213 00:15:52.887663 12354 solver.cpp:314] Iteration 106500 (1.8258 iter/s, 54.7705s/100 iter), loss = 2.70117
I0213 00:15:52.887760 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.36932 (* 1 = 3.36932 loss)
I0213 00:15:52.887770 12354 sgd_solver.cpp:136] Iteration 106500, lr = 1.60181e-07, m = 0.9
I0213 00:16:47.473604 12354 solver.cpp:314] Iteration 106600 (1.83204 iter/s, 54.584s/100 iter), loss = 2.89839
I0213 00:16:47.473701 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.67122 (* 1 = 2.67122 loss)
I0213 00:16:47.473712 12354 sgd_solver.cpp:136] Iteration 106600, lr = 1.55487e-07, m = 0.9
I0213 00:17:43.350862 12354 solver.cpp:314] Iteration 106700 (1.7897 iter/s, 55.8752s/100 iter), loss = 3.05424
I0213 00:17:43.351346 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.40069 (* 1 = 4.40069 loss)
I0213 00:17:43.351363 12354 sgd_solver.cpp:136] Iteration 106700, lr = 1.50897e-07, m = 0.9
I0213 00:18:39.396899 12354 solver.cpp:314] Iteration 106800 (1.78431 iter/s, 56.044s/100 iter), loss = 2.88402
I0213 00:18:39.397070 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.54054 (* 1 = 2.54054 loss)
I0213 00:18:39.397105 12354 sgd_solver.cpp:136] Iteration 106800, lr = 1.4641e-07, m = 0.9
I0213 00:19:34.309923 12354 solver.cpp:314] Iteration 106900 (1.82113 iter/s, 54.911s/100 iter), loss = 3.00862
I0213 00:19:34.310056 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.37175 (* 1 = 2.37175 loss)
I0213 00:19:34.310070 12354 sgd_solver.cpp:136] Iteration 106900, lr = 1.42024e-07, m = 0.9
I0213 00:20:29.778625 12354 solver.cpp:314] Iteration 107000 (1.80288 iter/s, 55.4667s/100 iter), loss = 2.87829
I0213 00:20:29.778750 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.33694 (* 1 = 3.33694 loss)
I0213 00:20:29.778769 12354 sgd_solver.cpp:136] Iteration 107000, lr = 1.37736e-07, m = 0.9
I0213 00:21:24.917886 12354 solver.cpp:314] Iteration 107100 (1.81366 iter/s, 55.1372s/100 iter), loss = 2.76236
I0213 00:21:24.918185 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.39293 (* 1 = 3.39293 loss)
I0213 00:21:24.918249 12354 sgd_solver.cpp:136] Iteration 107100, lr = 1.33547e-07, m = 0.9
I0213 00:22:20.955906 12354 solver.cpp:314] Iteration 107200 (1.78457 iter/s, 56.036s/100 iter), loss = 2.85375
I0213 00:22:20.956004 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.09775 (* 1 = 2.09775 loss)
I0213 00:22:20.956014 12354 sgd_solver.cpp:136] Iteration 107200, lr = 1.29454e-07, m = 0.9
I0213 00:23:16.658519 12354 solver.cpp:314] Iteration 107300 (1.79531 iter/s, 55.7006s/100 iter), loss = 2.94679
I0213 00:23:16.658629 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.17581 (* 1 = 2.17581 loss)
I0213 00:23:16.658640 12354 sgd_solver.cpp:136] Iteration 107300, lr = 1.25456e-07, m = 0.9
I0213 00:23:31.500267 12274 data_reader.cpp:305] Starting prefetch of epoch 27
I0213 00:24:11.276187 12354 solver.cpp:314] Iteration 107400 (1.83098 iter/s, 54.6157s/100 iter), loss = 2.86137
I0213 00:24:11.276294 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.80887 (* 1 = 2.80887 loss)
I0213 00:24:11.276310 12354 sgd_solver.cpp:136] Iteration 107400, lr = 1.21551e-07, m = 0.9
I0213 00:25:06.320675 12354 solver.cpp:314] Iteration 107500 (1.81678 iter/s, 55.0425s/100 iter), loss = 2.85107
I0213 00:25:06.320837 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.73714 (* 1 = 2.73714 loss)
I0213 00:25:06.320852 12354 sgd_solver.cpp:136] Iteration 107500, lr = 1.17738e-07, m = 0.9
I0213 00:26:01.703709 12354 solver.cpp:314] Iteration 107600 (1.80567 iter/s, 55.381s/100 iter), loss = 2.87702
I0213 00:26:01.703850 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.32908 (* 1 = 2.32908 loss)
I0213 00:26:01.703864 12354 sgd_solver.cpp:136] Iteration 107600, lr = 1.14015e-07, m = 0.9
I0213 00:26:57.647101 12354 solver.cpp:314] Iteration 107700 (1.78759 iter/s, 55.9414s/100 iter), loss = 2.82466
I0213 00:26:57.647214 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.97127 (* 1 = 2.97127 loss)
I0213 00:26:57.647233 12354 sgd_solver.cpp:136] Iteration 107700, lr = 1.10381e-07, m = 0.9
I0213 00:27:52.711782 12354 solver.cpp:314] Iteration 107800 (1.81611 iter/s, 55.0627s/100 iter), loss = 2.86362
I0213 00:27:52.711895 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.47342 (* 1 = 3.47342 loss)
I0213 00:27:52.711910 12354 sgd_solver.cpp:136] Iteration 107800, lr = 1.06835e-07, m = 0.9
I0213 00:28:47.802319 12354 solver.cpp:314] Iteration 107900 (1.81526 iter/s, 55.0885s/100 iter), loss = 2.87957
I0213 00:28:47.802440 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.50893 (* 1 = 2.50893 loss)
I0213 00:28:47.802456 12354 sgd_solver.cpp:136] Iteration 107900, lr = 1.03375e-07, m = 0.9
I0213 00:29:42.602138 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_108000.caffemodel
I0213 00:29:42.627411 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_108000.solverstate
I0213 00:29:42.641904 12354 solver.cpp:666] Iteration 108000, Testing net (#0)
I0213 00:30:33.099495 12355 solver.cpp:774] class AP 1: 0.394394
I0213 00:30:33.168331 12355 solver.cpp:774] class AP 2: 0.644176
I0213 00:30:33.179345 12355 solver.cpp:774] class AP 3: 0.630359
I0213 00:30:33.179359 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.55631
I0213 00:30:33.344359 12354 solver.cpp:774] class AP 1: 0.375828
I0213 00:30:33.418347 12354 solver.cpp:774] class AP 2: 0.625432
I0213 00:30:33.429594 12354 solver.cpp:774] class AP 3: 0.632219
I0213 00:30:33.429611 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.544493
I0213 00:30:33.429649 12354 solver.cpp:265] [MultiGPU] Tests completed in 50.7859s
I0213 00:30:33.898154 12354 solver.cpp:314] Iteration 108000 (0.942578 iter/s, 106.092s/100 iter), loss = 2.70314
I0213 00:30:33.898191 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.22326 (* 1 = 3.22326 loss)
I0213 00:30:33.898200 12354 sgd_solver.cpp:136] Iteration 108000, lr = 1e-07, m = 0.9
I0213 00:31:28.921941 12354 solver.cpp:314] Iteration 108100 (1.81746 iter/s, 55.0218s/100 iter), loss = 2.79549
I0213 00:31:28.922058 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.49675 (* 1 = 2.49675 loss)
I0213 00:31:28.922073 12354 sgd_solver.cpp:136] Iteration 108100, lr = 9.67082e-08, m = 0.9
I0213 00:32:24.542004 12354 solver.cpp:314] Iteration 108200 (1.79798 iter/s, 55.618s/100 iter), loss = 2.87509
I0213 00:32:24.542150 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.78994 (* 1 = 2.78994 loss)
I0213 00:32:24.542165 12354 sgd_solver.cpp:136] Iteration 108200, lr = 9.34983e-08, m = 0.9
I0213 00:33:19.459087 12354 solver.cpp:314] Iteration 108300 (1.82099 iter/s, 54.9151s/100 iter), loss = 2.78115
I0213 00:33:19.462224 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.62339 (* 1 = 2.62339 loss)
I0213 00:33:19.462266 12354 sgd_solver.cpp:136] Iteration 108300, lr = 9.03689e-08, m = 0.9
I0213 00:34:14.358764 12354 solver.cpp:314] Iteration 108400 (1.82157 iter/s, 54.8977s/100 iter), loss = 2.82945
I0213 00:34:14.358925 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.41362 (* 1 = 2.41362 loss)
I0213 00:34:14.358942 12354 sgd_solver.cpp:136] Iteration 108400, lr = 8.73187e-08, m = 0.9
I0213 00:35:09.716444 12354 solver.cpp:314] Iteration 108500 (1.8065 iter/s, 55.3557s/100 iter), loss = 2.90716
I0213 00:35:09.716531 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.5318 (* 1 = 2.5318 loss)
I0213 00:35:09.716543 12354 sgd_solver.cpp:136] Iteration 108500, lr = 8.43465e-08, m = 0.9
I0213 00:36:05.128737 12354 solver.cpp:314] Iteration 108600 (1.80472 iter/s, 55.4103s/100 iter), loss = 2.87973
I0213 00:36:05.128862 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.56525 (* 1 = 2.56525 loss)
I0213 00:36:05.128881 12354 sgd_solver.cpp:136] Iteration 108600, lr = 8.14507e-08, m = 0.9
I0213 00:36:59.977623 12354 solver.cpp:314] Iteration 108700 (1.82326 iter/s, 54.8469s/100 iter), loss = 2.8
I0213 00:36:59.977742 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.08203 (* 1 = 2.08203 loss)
I0213 00:36:59.977757 12354 sgd_solver.cpp:136] Iteration 108700, lr = 7.86302e-08, m = 0.9
I0213 00:37:55.341480 12354 solver.cpp:314] Iteration 108800 (1.8063 iter/s, 55.3618s/100 iter), loss = 2.82848
I0213 00:37:55.341644 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.81023 (* 1 = 2.81023 loss)
I0213 00:37:55.341662 12354 sgd_solver.cpp:136] Iteration 108800, lr = 7.58834e-08, m = 0.9
I0213 00:38:50.960072 12354 solver.cpp:314] Iteration 108900 (1.79803 iter/s, 55.6166s/100 iter), loss = 2.69195
I0213 00:38:50.960180 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.27491 (* 1 = 2.27491 loss)
I0213 00:38:50.960193 12354 sgd_solver.cpp:136] Iteration 108900, lr = 7.32093e-08, m = 0.9
I0213 00:39:47.289705 12354 solver.cpp:314] Iteration 109000 (1.77533 iter/s, 56.3276s/100 iter), loss = 2.91338
I0213 00:39:47.289822 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.747 (* 1 = 2.747 loss)
I0213 00:39:47.289835 12354 sgd_solver.cpp:136] Iteration 109000, lr = 7.06066e-08, m = 0.9
I0213 00:40:42.452240 12354 solver.cpp:314] Iteration 109100 (1.81289 iter/s, 55.1605s/100 iter), loss = 2.97881
I0213 00:40:42.452340 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.1186 (* 1 = 2.1186 loss)
I0213 00:40:42.452353 12354 sgd_solver.cpp:136] Iteration 109100, lr = 6.80739e-08, m = 0.9
I0213 00:41:37.926756 12354 solver.cpp:314] Iteration 109200 (1.8027 iter/s, 55.4725s/100 iter), loss = 2.87873
I0213 00:41:37.926892 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.744 (* 1 = 2.744 loss)
I0213 00:41:37.926908 12354 sgd_solver.cpp:136] Iteration 109200, lr = 6.56099e-08, m = 0.9
I0213 00:42:33.317018 12354 solver.cpp:314] Iteration 109300 (1.80544 iter/s, 55.3882s/100 iter), loss = 3.18633
I0213 00:42:33.322536 12354 solver.cpp:336]     Train net output #0: mbox_loss = 1.86485 (* 1 = 1.86485 loss)
I0213 00:42:33.322563 12354 sgd_solver.cpp:136] Iteration 109300, lr = 6.32135e-08, m = 0.9
I0213 00:43:27.805706 12354 solver.cpp:314] Iteration 109400 (1.83531 iter/s, 54.4867s/100 iter), loss = 2.95853
I0213 00:43:27.806236 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.88607 (* 1 = 2.88607 loss)
I0213 00:43:27.806543 12354 sgd_solver.cpp:136] Iteration 109400, lr = 6.08833e-08, m = 0.9
I0213 00:44:22.446858 12354 solver.cpp:314] Iteration 109500 (1.83019 iter/s, 54.6392s/100 iter), loss = 2.71079
I0213 00:44:22.446959 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.15415 (* 1 = 2.15415 loss)
I0213 00:44:22.446974 12354 sgd_solver.cpp:136] Iteration 109500, lr = 5.86181e-08, m = 0.9
I0213 00:45:18.175529 12354 solver.cpp:314] Iteration 109600 (1.79447 iter/s, 55.7266s/100 iter), loss = 2.72192
I0213 00:45:18.175643 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.74252 (* 1 = 2.74252 loss)
I0213 00:45:18.175658 12354 sgd_solver.cpp:136] Iteration 109600, lr = 5.64167e-08, m = 0.9
I0213 00:46:14.295316 12354 solver.cpp:314] Iteration 109700 (1.78197 iter/s, 56.1177s/100 iter), loss = 3.04486
I0213 00:46:14.295491 12354 solver.cpp:336]     Train net output #0: mbox_loss = 1.84126 (* 1 = 1.84126 loss)
I0213 00:46:14.295508 12354 sgd_solver.cpp:136] Iteration 109700, lr = 5.4278e-08, m = 0.9
I0213 00:47:09.608886 12354 solver.cpp:314] Iteration 109800 (1.80794 iter/s, 55.3116s/100 iter), loss = 3.0119
I0213 00:47:09.609084 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.58373 (* 1 = 3.58373 loss)
I0213 00:47:09.609118 12354 sgd_solver.cpp:136] Iteration 109800, lr = 5.22006e-08, m = 0.9
I0213 00:48:05.202015 12354 solver.cpp:314] Iteration 109900 (1.79885 iter/s, 55.5911s/100 iter), loss = 2.88985
I0213 00:48:05.202163 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.23063 (* 1 = 3.23063 loss)
I0213 00:48:05.202178 12354 sgd_solver.cpp:136] Iteration 109900, lr = 5.01834e-08, m = 0.9
I0213 00:48:59.509413 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_110000.caffemodel
I0213 00:48:59.532701 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_110000.solverstate
I0213 00:48:59.545984 12354 solver.cpp:666] Iteration 110000, Testing net (#0)
I0213 00:49:50.601689 12355 solver.cpp:774] class AP 1: 0.394032
I0213 00:49:50.672729 12355 solver.cpp:774] class AP 2: 0.640999
I0213 00:49:50.684000 12355 solver.cpp:774] class AP 3: 0.631299
I0213 00:49:50.684017 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.555443
I0213 00:49:50.783325 12354 solver.cpp:774] class AP 1: 0.376947
I0213 00:49:50.862839 12354 solver.cpp:774] class AP 2: 0.631976
I0213 00:49:50.874317 12354 solver.cpp:774] class AP 3: 0.631064
I0213 00:49:50.874337 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.546662
I0213 00:49:50.874406 12354 solver.cpp:265] [MultiGPU] Tests completed in 51.3265s
I0213 00:49:51.356046 12354 solver.cpp:314] Iteration 110000 (0.942062 iter/s, 106.15s/100 iter), loss = 3.03841
I0213 00:49:51.356097 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.94151 (* 1 = 2.94151 loss)
I0213 00:49:51.356106 12354 sgd_solver.cpp:136] Iteration 110000, lr = 4.82253e-08, m = 0.9
I0213 00:50:45.712260 12354 solver.cpp:314] Iteration 110100 (1.83978 iter/s, 54.3542s/100 iter), loss = 3.04582
I0213 00:50:45.712375 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.3388 (* 1 = 2.3388 loss)
I0213 00:50:45.712390 12354 sgd_solver.cpp:136] Iteration 110100, lr = 4.6325e-08, m = 0.9
I0213 00:50:50.726044 12274 data_reader.cpp:305] Starting prefetch of epoch 28
I0213 00:51:41.156626 12354 solver.cpp:314] Iteration 110200 (1.80368 iter/s, 55.4423s/100 iter), loss = 2.92658
I0213 00:51:41.156733 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.75511 (* 1 = 2.75511 loss)
I0213 00:51:41.156747 12354 sgd_solver.cpp:136] Iteration 110200, lr = 4.44815e-08, m = 0.9
I0213 00:52:36.057557 12354 solver.cpp:314] Iteration 110300 (1.82153 iter/s, 54.8989s/100 iter), loss = 2.89217
I0213 00:52:36.057672 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.54822 (* 1 = 2.54822 loss)
I0213 00:52:36.057687 12354 sgd_solver.cpp:136] Iteration 110300, lr = 4.26935e-08, m = 0.9
I0213 00:53:31.371884 12354 solver.cpp:314] Iteration 110400 (1.80792 iter/s, 55.3123s/100 iter), loss = 2.97787
I0213 00:53:31.372023 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.32756 (* 1 = 3.32756 loss)
I0213 00:53:31.372043 12354 sgd_solver.cpp:136] Iteration 110400, lr = 4.096e-08, m = 0.9
I0213 00:54:25.691897 12354 solver.cpp:314] Iteration 110500 (1.84101 iter/s, 54.318s/100 iter), loss = 2.83668
I0213 00:54:25.692039 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.10997 (* 1 = 3.10997 loss)
I0213 00:54:25.692054 12354 sgd_solver.cpp:136] Iteration 110500, lr = 3.92798e-08, m = 0.9
I0213 00:55:20.784919 12354 solver.cpp:314] Iteration 110600 (1.81518 iter/s, 55.091s/100 iter), loss = 2.88467
I0213 00:55:20.785054 12354 solver.cpp:336]     Train net output #0: mbox_loss = 1.92696 (* 1 = 1.92696 loss)
I0213 00:55:20.785073 12354 sgd_solver.cpp:136] Iteration 110600, lr = 3.76518e-08, m = 0.9
I0213 00:56:16.174845 12354 solver.cpp:314] Iteration 110700 (1.80545 iter/s, 55.3879s/100 iter), loss = 2.8917
I0213 00:56:16.175026 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.36164 (* 1 = 2.36164 loss)
I0213 00:56:16.175062 12354 sgd_solver.cpp:136] Iteration 110700, lr = 3.6075e-08, m = 0.9
I0213 00:57:11.625283 12354 solver.cpp:314] Iteration 110800 (1.80348 iter/s, 55.4484s/100 iter), loss = 3.03526
I0213 00:57:11.625406 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.83525 (* 1 = 2.83525 loss)
I0213 00:57:11.625422 12354 sgd_solver.cpp:136] Iteration 110800, lr = 3.45483e-08, m = 0.9
I0213 00:58:07.882832 12354 solver.cpp:314] Iteration 110900 (1.7776 iter/s, 56.2555s/100 iter), loss = 2.64247
I0213 00:58:07.882977 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.80582 (* 1 = 2.80582 loss)
I0213 00:58:07.882993 12354 sgd_solver.cpp:136] Iteration 110900, lr = 3.30705e-08, m = 0.9
I0213 00:59:04.019544 12354 solver.cpp:314] Iteration 111000 (1.78143 iter/s, 56.1347s/100 iter), loss = 2.89373
I0213 00:59:04.019644 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.00789 (* 1 = 3.00789 loss)
I0213 00:59:04.019975 12354 sgd_solver.cpp:136] Iteration 111000, lr = 3.16406e-08, m = 0.9
I0213 00:59:59.909817 12354 solver.cpp:314] Iteration 111100 (1.78929 iter/s, 55.8882s/100 iter), loss = 2.88653
I0213 00:59:59.909931 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.38183 (* 1 = 3.38183 loss)
I0213 00:59:59.909946 12354 sgd_solver.cpp:136] Iteration 111100, lr = 3.02576e-08, m = 0.9
I0213 01:00:55.398169 12354 solver.cpp:314] Iteration 111200 (1.80225 iter/s, 55.4863s/100 iter), loss = 3.06758
I0213 01:00:55.398308 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.62812 (* 1 = 3.62812 loss)
I0213 01:00:55.398327 12354 sgd_solver.cpp:136] Iteration 111200, lr = 2.89205e-08, m = 0.9
I0213 01:01:50.358510 12354 solver.cpp:314] Iteration 111300 (1.81956 iter/s, 54.9583s/100 iter), loss = 2.85781
I0213 01:01:50.358666 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.09434 (* 1 = 3.09434 loss)
I0213 01:01:50.358700 12354 sgd_solver.cpp:136] Iteration 111300, lr = 2.76282e-08, m = 0.9
I0213 01:02:46.169347 12354 solver.cpp:314] Iteration 111400 (1.79183 iter/s, 55.8088s/100 iter), loss = 2.93379
I0213 01:02:46.169457 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.87192 (* 1 = 2.87192 loss)
I0213 01:02:46.169472 12354 sgd_solver.cpp:136] Iteration 111400, lr = 2.63796e-08, m = 0.9
I0213 01:03:41.718158 12354 solver.cpp:314] Iteration 111500 (1.80028 iter/s, 55.5468s/100 iter), loss = 2.76652
I0213 01:03:41.718302 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.6335 (* 1 = 2.6335 loss)
I0213 01:03:41.718323 12354 sgd_solver.cpp:136] Iteration 111500, lr = 2.51739e-08, m = 0.9
I0213 01:04:37.101507 12354 solver.cpp:314] Iteration 111600 (1.80566 iter/s, 55.3813s/100 iter), loss = 2.83187
I0213 01:04:37.101617 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.34765 (* 1 = 3.34765 loss)
I0213 01:04:37.101634 12354 sgd_solver.cpp:136] Iteration 111600, lr = 2.401e-08, m = 0.9
I0213 01:05:33.899623 12354 solver.cpp:314] Iteration 111700 (1.76069 iter/s, 56.796s/100 iter), loss = 2.83086
I0213 01:05:33.899740 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.07908 (* 1 = 2.07908 loss)
I0213 01:05:33.899755 12354 sgd_solver.cpp:136] Iteration 111700, lr = 2.28869e-08, m = 0.9
I0213 01:06:29.022076 12354 solver.cpp:314] Iteration 111800 (1.81421 iter/s, 55.1204s/100 iter), loss = 3.03937
I0213 01:06:29.022228 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.66347 (* 1 = 3.66347 loss)
I0213 01:06:29.022243 12354 sgd_solver.cpp:136] Iteration 111800, lr = 2.18037e-08, m = 0.9
I0213 01:07:24.007609 12354 solver.cpp:314] Iteration 111900 (1.81873 iter/s, 54.9835s/100 iter), loss = 2.7916
I0213 01:07:24.016854 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.53795 (* 1 = 2.53795 loss)
I0213 01:07:24.016876 12354 sgd_solver.cpp:136] Iteration 111900, lr = 2.07594e-08, m = 0.9
I0213 01:08:18.675981 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_112000.caffemodel
I0213 01:08:18.693876 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_112000.solverstate
I0213 01:08:18.702828 12354 solver.cpp:666] Iteration 112000, Testing net (#0)
I0213 01:09:09.062080 12354 solver.cpp:774] class AP 1: 0.37706
I0213 01:09:09.128197 12354 solver.cpp:774] class AP 2: 0.625075
I0213 01:09:09.139636 12354 solver.cpp:774] class AP 3: 0.628633
I0213 01:09:09.139654 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.543589
I0213 01:09:09.906253 12355 solver.cpp:774] class AP 1: 0.392049
I0213 01:09:09.976997 12355 solver.cpp:774] class AP 2: 0.646956
I0213 01:09:09.988061 12355 solver.cpp:774] class AP 3: 0.632888
I0213 01:09:09.988087 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.557297
I0213 01:09:09.988164 12354 solver.cpp:265] [MultiGPU] Tests completed in 51.2835s
I0213 01:09:10.339234 12354 solver.cpp:314] Iteration 112000 (0.940488 iter/s, 106.328s/100 iter), loss = 2.97825
I0213 01:09:10.341765 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.99825 (* 1 = 2.99825 loss)
I0213 01:09:10.341815 12354 sgd_solver.cpp:136] Iteration 112000, lr = 1.97531e-08, m = 0.9
I0213 01:10:05.591262 12354 solver.cpp:314] Iteration 112100 (1.80995 iter/s, 55.25s/100 iter), loss = 2.93433
I0213 01:10:05.591382 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.80727 (* 1 = 2.80727 loss)
I0213 01:10:05.591397 12354 sgd_solver.cpp:136] Iteration 112100, lr = 1.87838e-08, m = 0.9
I0213 01:11:00.728523 12354 solver.cpp:314] Iteration 112200 (1.81372 iter/s, 55.1353s/100 iter), loss = 2.94441
I0213 01:11:00.728637 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.32352 (* 1 = 3.32352 loss)
I0213 01:11:00.728652 12354 sgd_solver.cpp:136] Iteration 112200, lr = 1.78506e-08, m = 0.9
I0213 01:11:56.342401 12354 solver.cpp:314] Iteration 112300 (1.79818 iter/s, 55.6119s/100 iter), loss = 2.90841
I0213 01:11:56.342514 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.15375 (* 1 = 3.15375 loss)
I0213 01:11:56.342530 12354 sgd_solver.cpp:136] Iteration 112300, lr = 1.69527e-08, m = 0.9
I0213 01:12:51.891299 12354 solver.cpp:314] Iteration 112400 (1.80028 iter/s, 55.5469s/100 iter), loss = 2.62905
I0213 01:12:51.891672 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.68014 (* 1 = 2.68014 loss)
I0213 01:12:51.891690 12354 sgd_solver.cpp:136] Iteration 112400, lr = 1.6089e-08, m = 0.9
I0213 01:13:46.635340 12354 solver.cpp:314] Iteration 112500 (1.82675 iter/s, 54.7421s/100 iter), loss = 2.98248
I0213 01:13:46.635468 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.36455 (* 1 = 2.36455 loss)
I0213 01:13:46.635486 12354 sgd_solver.cpp:136] Iteration 112500, lr = 1.52588e-08, m = 0.9
I0213 01:14:41.515086 12354 solver.cpp:314] Iteration 112600 (1.82223 iter/s, 54.8778s/100 iter), loss = 3.05014
I0213 01:14:41.515256 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.22721 (* 1 = 3.22721 loss)
I0213 01:14:41.515295 12354 sgd_solver.cpp:136] Iteration 112600, lr = 1.44611e-08, m = 0.9
I0213 01:15:36.068711 12354 solver.cpp:314] Iteration 112700 (1.83313 iter/s, 54.5516s/100 iter), loss = 2.87821
I0213 01:15:36.073622 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.68811 (* 1 = 3.68811 loss)
I0213 01:15:36.073647 12354 sgd_solver.cpp:136] Iteration 112700, lr = 1.36951e-08, m = 0.9
I0213 01:16:31.003037 12354 solver.cpp:314] Iteration 112800 (1.82042 iter/s, 54.9323s/100 iter), loss = 2.98108
I0213 01:16:31.003171 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.65727 (* 1 = 2.65727 loss)
I0213 01:16:31.003187 12354 sgd_solver.cpp:136] Iteration 112800, lr = 1.296e-08, m = 0.9
I0213 01:17:25.706187 12354 solver.cpp:314] Iteration 112900 (1.82811 iter/s, 54.7012s/100 iter), loss = 2.91064
I0213 01:17:25.706310 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.37005 (* 1 = 3.37005 loss)
I0213 01:17:25.706324 12354 sgd_solver.cpp:136] Iteration 112900, lr = 1.22549e-08, m = 0.9
I0213 01:18:21.236688 12354 solver.cpp:314] Iteration 113000 (1.80088 iter/s, 55.5285s/100 iter), loss = 2.86966
I0213 01:18:21.236817 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.34343 (* 1 = 3.34343 loss)
I0213 01:18:21.236835 12354 sgd_solver.cpp:136] Iteration 113000, lr = 1.15789e-08, m = 0.9
I0213 01:19:16.642688 12354 solver.cpp:314] Iteration 113100 (1.80492 iter/s, 55.404s/100 iter), loss = 2.69978
I0213 01:19:16.642797 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.62797 (* 1 = 2.62797 loss)
I0213 01:19:16.642807 12354 sgd_solver.cpp:136] Iteration 113100, lr = 1.09313e-08, m = 0.9
I0213 01:20:11.522627 12354 solver.cpp:314] Iteration 113200 (1.82223 iter/s, 54.8779s/100 iter), loss = 2.89271
I0213 01:20:11.522755 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.66499 (* 1 = 2.66499 loss)
I0213 01:20:11.522771 12354 sgd_solver.cpp:136] Iteration 113200, lr = 1.03112e-08, m = 0.9
I0213 01:20:32.565205 12274 data_reader.cpp:305] Starting prefetch of epoch 29
I0213 01:21:06.926268 12354 solver.cpp:314] Iteration 113300 (1.805 iter/s, 55.4016s/100 iter), loss = 3.06118
I0213 01:21:06.926407 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.27301 (* 1 = 2.27301 loss)
I0213 01:21:06.926429 12354 sgd_solver.cpp:136] Iteration 113300, lr = 9.71795e-09, m = 0.9
I0213 01:22:01.548089 12354 solver.cpp:314] Iteration 113400 (1.83084 iter/s, 54.6198s/100 iter), loss = 2.68905
I0213 01:22:01.548218 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.93405 (* 1 = 2.93405 loss)
I0213 01:22:01.548235 12354 sgd_solver.cpp:136] Iteration 113400, lr = 9.15063e-09, m = 0.9
I0213 01:22:57.535995 12354 solver.cpp:314] Iteration 113500 (1.78617 iter/s, 55.9859s/100 iter), loss = 2.8928
I0213 01:22:57.536090 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.40181 (* 1 = 3.40181 loss)
I0213 01:22:57.536101 12354 sgd_solver.cpp:136] Iteration 113500, lr = 8.60852e-09, m = 0.9
I0213 01:23:52.695214 12354 solver.cpp:314] Iteration 113600 (1.813 iter/s, 55.1572s/100 iter), loss = 2.89726
I0213 01:23:52.695369 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.28251 (* 1 = 3.28251 loss)
I0213 01:23:52.695406 12354 sgd_solver.cpp:136] Iteration 113600, lr = 8.09087e-09, m = 0.9
I0213 01:24:48.059789 12354 solver.cpp:314] Iteration 113700 (1.80627 iter/s, 55.3626s/100 iter), loss = 2.7255
I0213 01:24:48.059887 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.93861 (* 1 = 2.93861 loss)
I0213 01:24:48.059900 12354 sgd_solver.cpp:136] Iteration 113700, lr = 7.59692e-09, m = 0.9
I0213 01:25:42.837713 12354 solver.cpp:314] Iteration 113800 (1.82562 iter/s, 54.7759s/100 iter), loss = 2.91422
I0213 01:25:42.837827 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.43865 (* 1 = 2.43865 loss)
I0213 01:25:42.837842 12354 sgd_solver.cpp:136] Iteration 113800, lr = 7.12594e-09, m = 0.9
I0213 01:26:38.544353 12354 solver.cpp:314] Iteration 113900 (1.79518 iter/s, 55.7046s/100 iter), loss = 2.87989
I0213 01:26:38.544477 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.56785 (* 1 = 2.56785 loss)
I0213 01:26:38.544495 12354 sgd_solver.cpp:136] Iteration 113900, lr = 6.67721e-09, m = 0.9
I0213 01:27:33.342159 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_114000.caffemodel
I0213 01:27:33.367175 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_114000.solverstate
I0213 01:27:33.381453 12354 solver.cpp:666] Iteration 114000, Testing net (#0)
I0213 01:28:23.111109 12355 solver.cpp:774] class AP 1: 0.395917
I0213 01:28:23.188932 12355 solver.cpp:774] class AP 2: 0.648114
I0213 01:28:23.200052 12355 solver.cpp:774] class AP 3: 0.634088
I0213 01:28:23.200068 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.559373
I0213 01:28:24.611575 12354 solver.cpp:774] class AP 1: 0.377076
I0213 01:28:24.686084 12354 solver.cpp:774] class AP 2: 0.621722
I0213 01:28:24.697279 12354 solver.cpp:774] class AP 3: 0.627753
I0213 01:28:24.697293 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.542184
I0213 01:28:24.697348 12354 solver.cpp:265] [MultiGPU] Tests completed in 51.314s
I0213 01:28:25.132356 12354 solver.cpp:314] Iteration 114000 (0.938226 iter/s, 106.584s/100 iter), loss = 2.82267
I0213 01:28:25.132403 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.60553 (* 1 = 2.60553 loss)
I0213 01:28:25.132416 12354 sgd_solver.cpp:136] Iteration 114000, lr = 6.25001e-09, m = 0.9
I0213 01:29:20.108656 12354 solver.cpp:314] Iteration 114100 (1.81903 iter/s, 54.9743s/100 iter), loss = 3.13771
I0213 01:29:20.108767 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.67897 (* 1 = 3.67897 loss)
I0213 01:29:20.108777 12354 sgd_solver.cpp:136] Iteration 114100, lr = 5.84364e-09, m = 0.9
I0213 01:30:15.424072 12354 solver.cpp:314] Iteration 114200 (1.80788 iter/s, 55.3134s/100 iter), loss = 2.9471
I0213 01:30:15.424185 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.23012 (* 1 = 2.23012 loss)
I0213 01:30:15.424201 12354 sgd_solver.cpp:136] Iteration 114200, lr = 5.45742e-09, m = 0.9
I0213 01:31:10.746493 12354 solver.cpp:314] Iteration 114300 (1.80765 iter/s, 55.3204s/100 iter), loss = 2.98518
I0213 01:31:10.746928 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.75364 (* 1 = 3.75364 loss)
I0213 01:31:10.746944 12354 sgd_solver.cpp:136] Iteration 114300, lr = 5.09067e-09, m = 0.9
I0213 01:32:05.947574 12354 solver.cpp:314] Iteration 114400 (1.81162 iter/s, 55.1991s/100 iter), loss = 3.07604
I0213 01:32:05.947698 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.98137 (* 1 = 3.98137 loss)
I0213 01:32:05.947715 12354 sgd_solver.cpp:136] Iteration 114400, lr = 4.74272e-09, m = 0.9
I0213 01:33:00.967862 12354 solver.cpp:314] Iteration 114500 (1.81758 iter/s, 55.0183s/100 iter), loss = 2.81776
I0213 01:33:00.967983 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.05792 (* 1 = 2.05792 loss)
I0213 01:33:00.967998 12354 sgd_solver.cpp:136] Iteration 114500, lr = 4.41292e-09, m = 0.9
I0213 01:33:55.752364 12354 solver.cpp:314] Iteration 114600 (1.8254 iter/s, 54.7825s/100 iter), loss = 2.9179
I0213 01:33:55.752497 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.13188 (* 1 = 2.13188 loss)
I0213 01:33:55.752516 12354 sgd_solver.cpp:136] Iteration 114600, lr = 4.10063e-09, m = 0.9
I0213 01:34:50.710304 12354 solver.cpp:314] Iteration 114700 (1.81964 iter/s, 54.9559s/100 iter), loss = 2.99366
I0213 01:34:50.710439 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.02199 (* 1 = 3.02199 loss)
I0213 01:34:50.710458 12354 sgd_solver.cpp:136] Iteration 114700, lr = 3.80521e-09, m = 0.9
I0213 01:35:46.112033 12354 solver.cpp:314] Iteration 114800 (1.80506 iter/s, 55.3997s/100 iter), loss = 2.90667
I0213 01:35:46.112186 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.79848 (* 1 = 2.79848 loss)
I0213 01:35:46.112201 12354 sgd_solver.cpp:136] Iteration 114800, lr = 3.52606e-09, m = 0.9
I0213 01:36:42.065838 12354 solver.cpp:314] Iteration 114900 (1.78725 iter/s, 55.9518s/100 iter), loss = 2.9359
I0213 01:36:42.065973 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.73473 (* 1 = 2.73473 loss)
I0213 01:36:42.065991 12354 sgd_solver.cpp:136] Iteration 114900, lr = 3.26255e-09, m = 0.9
I0213 01:37:37.945950 12354 solver.cpp:314] Iteration 115000 (1.78961 iter/s, 55.8781s/100 iter), loss = 2.86718
I0213 01:37:37.946133 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.77311 (* 1 = 2.77311 loss)
I0213 01:37:37.946148 12354 sgd_solver.cpp:136] Iteration 115000, lr = 3.01409e-09, m = 0.9
I0213 01:38:33.117835 12354 solver.cpp:314] Iteration 115100 (1.81258 iter/s, 55.1699s/100 iter), loss = 3.09638
I0213 01:38:33.117951 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.99475 (* 1 = 3.99475 loss)
I0213 01:38:33.117966 12354 sgd_solver.cpp:136] Iteration 115100, lr = 2.7801e-09, m = 0.9
I0213 01:39:28.583447 12354 solver.cpp:314] Iteration 115200 (1.80298 iter/s, 55.4636s/100 iter), loss = 2.7875
I0213 01:39:28.583577 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.74623 (* 1 = 2.74623 loss)
I0213 01:39:28.583587 12354 sgd_solver.cpp:136] Iteration 115200, lr = 2.56001e-09, m = 0.9
I0213 01:40:23.247664 12354 solver.cpp:314] Iteration 115300 (1.82942 iter/s, 54.6622s/100 iter), loss = 2.962
I0213 01:40:23.247783 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.62985 (* 1 = 2.62985 loss)
I0213 01:40:23.248100 12354 sgd_solver.cpp:136] Iteration 115300, lr = 2.35325e-09, m = 0.9
I0213 01:41:18.635597 12354 solver.cpp:314] Iteration 115400 (1.80551 iter/s, 55.3859s/100 iter), loss = 2.72169
I0213 01:41:18.636090 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.27297 (* 1 = 3.27297 loss)
I0213 01:41:18.636381 12354 sgd_solver.cpp:136] Iteration 115400, lr = 2.15927e-09, m = 0.9
I0213 01:42:14.002777 12354 solver.cpp:314] Iteration 115500 (1.80619 iter/s, 55.3652s/100 iter), loss = 3.25407
I0213 01:42:14.002900 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.35396 (* 1 = 4.35396 loss)
I0213 01:42:14.002918 12354 sgd_solver.cpp:136] Iteration 115500, lr = 1.97754e-09, m = 0.9
I0213 01:43:09.445149 12354 solver.cpp:314] Iteration 115600 (1.80374 iter/s, 55.4403s/100 iter), loss = 2.92311
I0213 01:43:09.445325 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.85956 (* 1 = 3.85956 loss)
I0213 01:43:09.445364 12354 sgd_solver.cpp:136] Iteration 115600, lr = 1.80754e-09, m = 0.9
I0213 01:44:05.795004 12354 solver.cpp:314] Iteration 115700 (1.77469 iter/s, 56.3478s/100 iter), loss = 2.92342
I0213 01:44:05.795102 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.09524 (* 1 = 3.09524 loss)
I0213 01:44:05.795119 12354 sgd_solver.cpp:136] Iteration 115700, lr = 1.64873e-09, m = 0.9
I0213 01:45:00.530171 12354 solver.cpp:314] Iteration 115800 (1.82705 iter/s, 54.7332s/100 iter), loss = 3.3414
I0213 01:45:00.530297 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.37849 (* 1 = 4.37849 loss)
I0213 01:45:00.530314 12354 sgd_solver.cpp:136] Iteration 115800, lr = 1.50063e-09, m = 0.9
I0213 01:45:56.221081 12354 solver.cpp:314] Iteration 115900 (1.79569 iter/s, 55.6889s/100 iter), loss = 2.56601
I0213 01:45:56.223126 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.88757 (* 1 = 2.88757 loss)
I0213 01:45:56.223165 12354 sgd_solver.cpp:136] Iteration 115900, lr = 1.36274e-09, m = 0.9
I0213 01:46:50.474158 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_116000.caffemodel
I0213 01:46:50.497745 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_116000.solverstate
I0213 01:46:50.510939 12354 solver.cpp:666] Iteration 116000, Testing net (#0)
I0213 01:47:40.338665 12355 solver.cpp:774] class AP 1: 0.395663
I0213 01:47:40.402932 12355 solver.cpp:774] class AP 2: 0.646771
I0213 01:47:40.413995 12355 solver.cpp:774] class AP 3: 0.635489
I0213 01:47:40.414007 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.559308
I0213 01:47:40.684851 12354 solver.cpp:774] class AP 1: 0.375137
I0213 01:47:40.759681 12354 solver.cpp:774] class AP 2: 0.633257
I0213 01:47:40.770824 12354 solver.cpp:774] class AP 3: 0.626577
I0213 01:47:40.770841 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.54499
I0213 01:47:40.770900 12354 solver.cpp:265] [MultiGPU] Tests completed in 50.2581s
I0213 01:47:41.201277 12354 solver.cpp:314] Iteration 116000 (0.952595 iter/s, 104.976s/100 iter), loss = 2.91529
I0213 01:47:41.201323 12354 solver.cpp:336]     Train net output #0: mbox_loss = 4.27581 (* 1 = 4.27581 loss)
I0213 01:47:41.201336 12354 sgd_solver.cpp:136] Iteration 116000, lr = 1.23457e-09, m = 0.9
I0213 01:47:51.337642 12274 data_reader.cpp:305] Starting prefetch of epoch 30
I0213 01:48:36.173558 12354 solver.cpp:314] Iteration 116100 (1.81916 iter/s, 54.9703s/100 iter), loss = 3.00844
I0213 01:48:36.173719 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.30913 (* 1 = 3.30913 loss)
I0213 01:48:36.173734 12354 sgd_solver.cpp:136] Iteration 116100, lr = 1.11567e-09, m = 0.9
I0213 01:49:31.522655 12354 solver.cpp:314] Iteration 116200 (1.80678 iter/s, 55.3471s/100 iter), loss = 2.83188
I0213 01:49:31.522789 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.16903 (* 1 = 3.16903 loss)
I0213 01:49:31.522810 12354 sgd_solver.cpp:136] Iteration 116200, lr = 1.00557e-09, m = 0.9
I0213 01:50:26.543800 12354 solver.cpp:314] Iteration 116300 (1.81755 iter/s, 55.0191s/100 iter), loss = 2.74304
I0213 01:50:26.543928 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.09629 (* 1 = 2.09629 loss)
I0213 01:50:26.543946 12354 sgd_solver.cpp:136] Iteration 116300, lr = 9.03817e-10, m = 0.9
I0213 01:51:22.202467 12354 solver.cpp:314] Iteration 116400 (1.79673 iter/s, 55.6566s/100 iter), loss = 2.70298
I0213 01:51:22.202901 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.77421 (* 1 = 2.77421 loss)
I0213 01:51:22.202919 12354 sgd_solver.cpp:136] Iteration 116400, lr = 8.09997e-10, m = 0.9
I0213 01:52:18.174144 12354 solver.cpp:314] Iteration 116500 (1.78668 iter/s, 55.9696s/100 iter), loss = 3.03563
I0213 01:52:18.174460 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.88853 (* 1 = 2.88853 loss)
I0213 01:52:18.174526 12354 sgd_solver.cpp:136] Iteration 116500, lr = 7.23678e-10, m = 0.9
I0213 01:53:14.660914 12354 solver.cpp:314] Iteration 116600 (1.77039 iter/s, 56.4847s/100 iter), loss = 2.85879
I0213 01:53:14.661015 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.92091 (* 1 = 2.92091 loss)
I0213 01:53:14.661029 12354 sgd_solver.cpp:136] Iteration 116600, lr = 6.4445e-10, m = 0.9
I0213 01:54:10.061305 12354 solver.cpp:314] Iteration 116700 (1.80511 iter/s, 55.3984s/100 iter), loss = 2.98122
I0213 01:54:10.061738 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.45073 (* 1 = 3.45073 loss)
I0213 01:54:10.061754 12354 sgd_solver.cpp:136] Iteration 116700, lr = 5.71912e-10, m = 0.9
I0213 01:55:05.413133 12354 solver.cpp:314] Iteration 116800 (1.80669 iter/s, 55.3498s/100 iter), loss = 2.64208
I0213 01:55:05.413261 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.03464 (* 1 = 2.03464 loss)
I0213 01:55:05.413277 12354 sgd_solver.cpp:136] Iteration 116800, lr = 5.05677e-10, m = 0.9
I0213 01:56:00.116788 12354 solver.cpp:314] Iteration 116900 (1.8281 iter/s, 54.7017s/100 iter), loss = 2.90678
I0213 01:56:00.116911 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.98732 (* 1 = 2.98732 loss)
I0213 01:56:00.116930 12354 sgd_solver.cpp:136] Iteration 116900, lr = 4.45369e-10, m = 0.9
I0213 01:56:56.045528 12354 solver.cpp:314] Iteration 117000 (1.78805 iter/s, 55.9267s/100 iter), loss = 2.72364
I0213 01:56:56.045656 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.39254 (* 1 = 3.39254 loss)
I0213 01:56:56.045671 12354 sgd_solver.cpp:136] Iteration 117000, lr = 3.90624e-10, m = 0.9
I0213 01:57:51.526612 12354 solver.cpp:314] Iteration 117100 (1.80248 iter/s, 55.4791s/100 iter), loss = 3.10679
I0213 01:57:51.526777 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.94072 (* 1 = 2.94072 loss)
I0213 01:57:51.526793 12354 sgd_solver.cpp:136] Iteration 117100, lr = 3.41087e-10, m = 0.9
I0213 01:58:47.009574 12354 solver.cpp:314] Iteration 117200 (1.80242 iter/s, 55.4809s/100 iter), loss = 3.17746
I0213 01:58:47.009691 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.94039 (* 1 = 2.94039 loss)
I0213 01:58:47.009707 12354 sgd_solver.cpp:136] Iteration 117200, lr = 2.96419e-10, m = 0.9
I0213 01:59:42.329135 12354 solver.cpp:314] Iteration 117300 (1.80774 iter/s, 55.3175s/100 iter), loss = 2.9426
I0213 01:59:42.329262 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.75904 (* 1 = 2.75904 loss)
I0213 01:59:42.329277 12354 sgd_solver.cpp:136] Iteration 117300, lr = 2.56288e-10, m = 0.9
I0213 02:00:37.563139 12354 solver.cpp:314] Iteration 117400 (1.81055 iter/s, 55.232s/100 iter), loss = 2.84864
I0213 02:00:37.563271 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.99642 (* 1 = 2.99642 loss)
I0213 02:00:37.563284 12354 sgd_solver.cpp:136] Iteration 117400, lr = 2.20377e-10, m = 0.9
I0213 02:01:32.490147 12354 solver.cpp:314] Iteration 117500 (1.82066 iter/s, 54.925s/100 iter), loss = 2.8239
I0213 02:01:32.490278 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.66868 (* 1 = 2.66868 loss)
I0213 02:01:32.490293 12354 sgd_solver.cpp:136] Iteration 117500, lr = 1.88379e-10, m = 0.9
I0213 02:02:28.703945 12354 solver.cpp:314] Iteration 117600 (1.77899 iter/s, 56.2117s/100 iter), loss = 2.87301
I0213 02:02:28.704054 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.78778 (* 1 = 3.78778 loss)
I0213 02:02:28.704071 12354 sgd_solver.cpp:136] Iteration 117600, lr = 1.59999e-10, m = 0.9
I0213 02:03:24.611989 12354 solver.cpp:314] Iteration 117700 (1.78872 iter/s, 55.906s/100 iter), loss = 2.92261
I0213 02:03:24.612110 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.93041 (* 1 = 2.93041 loss)
I0213 02:03:24.612129 12354 sgd_solver.cpp:136] Iteration 117700, lr = 1.34954e-10, m = 0.9
I0213 02:04:18.971909 12354 solver.cpp:314] Iteration 117800 (1.83966 iter/s, 54.3579s/100 iter), loss = 2.85403
I0213 02:04:18.972029 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.93768 (* 1 = 2.93768 loss)
I0213 02:04:18.972045 12354 sgd_solver.cpp:136] Iteration 117800, lr = 1.1297e-10, m = 0.9
I0213 02:05:14.658769 12354 solver.cpp:314] Iteration 117900 (1.79582 iter/s, 55.6848s/100 iter), loss = 3.11384
I0213 02:05:14.658890 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.8205 (* 1 = 2.8205 loss)
I0213 02:05:14.658908 12354 sgd_solver.cpp:136] Iteration 117900, lr = 9.37887e-11, m = 0.9
I0213 02:06:09.015590 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_118000.caffemodel
I0213 02:06:09.039399 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_118000.solverstate
I0213 02:06:09.052780 12354 solver.cpp:666] Iteration 118000, Testing net (#0)
I0213 02:06:59.000028 12355 solver.cpp:774] class AP 1: 0.393358
I0213 02:06:59.064440 12355 solver.cpp:774] class AP 2: 0.6451
I0213 02:06:59.075798 12355 solver.cpp:774] class AP 3: 0.635151
I0213 02:06:59.075814 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.55787
I0213 02:06:59.213891 12354 solver.cpp:774] class AP 1: 0.375366
I0213 02:06:59.282354 12354 solver.cpp:774] class AP 2: 0.625806
I0213 02:06:59.293732 12354 solver.cpp:774] class AP 3: 0.625778
I0213 02:06:59.293756 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.542317
I0213 02:06:59.293822 12354 solver.cpp:265] [MultiGPU] Tests completed in 50.2392s
I0213 02:06:59.668233 12354 solver.cpp:314] Iteration 118000 (0.95233 iter/s, 105.006s/100 iter), loss = 2.9635
I0213 02:06:59.668282 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.27907 (* 1 = 3.27907 loss)
I0213 02:06:59.668293 12354 sgd_solver.cpp:136] Iteration 118000, lr = 7.71602e-11, m = 0.9
I0213 02:07:53.530375 12354 solver.cpp:314] Iteration 118100 (1.85666 iter/s, 53.8602s/100 iter), loss = 2.71174
I0213 02:07:53.530505 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.89931 (* 1 = 2.89931 loss)
I0213 02:07:53.530517 12354 sgd_solver.cpp:136] Iteration 118100, lr = 6.28475e-11, m = 0.9
I0213 02:08:48.729905 12354 solver.cpp:314] Iteration 118200 (1.81168 iter/s, 55.1975s/100 iter), loss = 2.7809
I0213 02:08:48.732909 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.4616 (* 1 = 2.4616 loss)
I0213 02:08:48.732931 12354 sgd_solver.cpp:136] Iteration 118200, lr = 5.06248e-11, m = 0.9
I0213 02:09:43.416170 12354 solver.cpp:314] Iteration 118300 (1.82868 iter/s, 54.6843s/100 iter), loss = 2.86803
I0213 02:09:43.416311 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.09753 (* 1 = 2.09753 loss)
I0213 02:09:43.416327 12354 sgd_solver.cpp:136] Iteration 118300, lr = 4.02781e-11, m = 0.9
I0213 02:10:38.879062 12354 solver.cpp:314] Iteration 118400 (1.80307 iter/s, 55.4609s/100 iter), loss = 3.09638
I0213 02:10:38.879182 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.12367 (* 1 = 3.12367 loss)
I0213 02:10:38.879201 12354 sgd_solver.cpp:136] Iteration 118400, lr = 3.16048e-11, m = 0.9
I0213 02:11:33.995476 12354 solver.cpp:314] Iteration 118500 (1.81441 iter/s, 55.1144s/100 iter), loss = 2.90693
I0213 02:11:33.995609 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.64601 (* 1 = 2.64601 loss)
I0213 02:11:33.995625 12354 sgd_solver.cpp:136] Iteration 118500, lr = 2.4414e-11, m = 0.9
I0213 02:12:29.609376 12354 solver.cpp:314] Iteration 118600 (1.79818 iter/s, 55.6119s/100 iter), loss = 2.99021
I0213 02:12:29.609498 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.30069 (* 1 = 2.30069 loss)
I0213 02:12:29.609513 12354 sgd_solver.cpp:136] Iteration 118600, lr = 1.85262e-11, m = 0.9
I0213 02:13:24.520323 12354 solver.cpp:314] Iteration 118700 (1.8212 iter/s, 54.9089s/100 iter), loss = 3.0451
I0213 02:13:24.520421 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.18639 (* 1 = 3.18639 loss)
I0213 02:13:24.520434 12354 sgd_solver.cpp:136] Iteration 118700, lr = 1.37736e-11, m = 0.9
I0213 02:14:20.483331 12354 solver.cpp:314] Iteration 118800 (1.78696 iter/s, 55.961s/100 iter), loss = 2.93776
I0213 02:14:20.483423 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.53952 (* 1 = 2.53952 loss)
I0213 02:14:20.483433 12354 sgd_solver.cpp:136] Iteration 118800, lr = 9.99996e-12, m = 0.9
I0213 02:15:15.687475 12354 solver.cpp:314] Iteration 118900 (1.81152 iter/s, 55.2021s/100 iter), loss = 2.85314
I0213 02:15:15.687589 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.17721 (* 1 = 3.17721 loss)
I0213 02:15:15.687608 12354 sgd_solver.cpp:136] Iteration 118900, lr = 7.06064e-12, m = 0.9
I0213 02:16:10.994144 12354 solver.cpp:314] Iteration 119000 (1.80817 iter/s, 55.3046s/100 iter), loss = 3.03899
I0213 02:16:10.994266 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.21063 (* 1 = 3.21063 loss)
I0213 02:16:10.994280 12354 sgd_solver.cpp:136] Iteration 119000, lr = 4.82251e-12, m = 0.9
I0213 02:17:05.779291 12354 solver.cpp:314] Iteration 119100 (1.82538 iter/s, 54.7831s/100 iter), loss = 2.98897
I0213 02:17:05.779404 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.9578 (* 1 = 3.9578 loss)
I0213 02:17:05.779419 12354 sgd_solver.cpp:136] Iteration 119100, lr = 3.16405e-12, m = 0.9
I0213 02:17:32.035895 12274 data_reader.cpp:305] Starting prefetch of epoch 31
I0213 02:18:00.763440 12354 solver.cpp:314] Iteration 119200 (1.81877 iter/s, 54.9821s/100 iter), loss = 2.57589
I0213 02:18:00.763823 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.5357 (* 1 = 3.5357 loss)
I0213 02:18:00.763839 12354 sgd_solver.cpp:136] Iteration 119200, lr = 1.9753e-12, m = 0.9
I0213 02:18:56.326324 12354 solver.cpp:314] Iteration 119300 (1.79983 iter/s, 55.5609s/100 iter), loss = 2.8771
I0213 02:18:56.326530 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.47716 (* 1 = 3.47716 loss)
I0213 02:18:56.326570 12354 sgd_solver.cpp:136] Iteration 119300, lr = 1.15789e-12, m = 0.9
I0213 02:19:51.695017 12354 solver.cpp:314] Iteration 119400 (1.80614 iter/s, 55.3667s/100 iter), loss = 2.92908
I0213 02:19:51.695133 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.00331 (* 1 = 3.00331 loss)
I0213 02:19:51.695148 12354 sgd_solver.cpp:136] Iteration 119400, lr = 6.24998e-13, m = 0.9
I0213 02:20:47.194180 12354 solver.cpp:314] Iteration 119500 (1.8019 iter/s, 55.4971s/100 iter), loss = 3.10393
I0213 02:20:47.195111 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.61324 (* 1 = 2.61324 loss)
I0213 02:20:47.195152 12354 sgd_solver.cpp:136] Iteration 119500, lr = 3.01407e-13, m = 0.9
I0213 02:21:42.126169 12354 solver.cpp:314] Iteration 119600 (1.8205 iter/s, 54.93s/100 iter), loss = 2.88173
I0213 02:21:42.126359 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.2982 (* 1 = 2.2982 loss)
I0213 02:21:42.126405 12354 sgd_solver.cpp:136] Iteration 119600, lr = 1.23456e-13, m = 0.9
I0213 02:22:36.665443 12354 solver.cpp:314] Iteration 119700 (1.83361 iter/s, 54.5373s/100 iter), loss = 2.78884
I0213 02:22:36.665542 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.20875 (* 1 = 2.20875 loss)
I0213 02:22:36.665557 12354 sgd_solver.cpp:136] Iteration 119700, lr = 3.90624e-14, m = 0.9
I0213 02:23:31.783527 12354 solver.cpp:314] Iteration 119800 (1.81435 iter/s, 55.1161s/100 iter), loss = 2.93831
I0213 02:23:31.783654 12354 solver.cpp:336]     Train net output #0: mbox_loss = 2.00119 (* 1 = 2.00119 loss)
I0213 02:23:31.783674 12354 sgd_solver.cpp:136] Iteration 119800, lr = 7.71602e-15, m = 0.9
I0213 02:24:26.922387 12354 solver.cpp:314] Iteration 119900 (1.81367 iter/s, 55.1368s/100 iter), loss = 3.07108
I0213 02:24:26.922519 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.3626 (* 1 = 3.3626 loss)
I0213 02:24:26.922539 12354 sgd_solver.cpp:136] Iteration 119900, lr = 4.82251e-16, m = 0.9
I0213 02:25:21.596603 12354 solver.cpp:314] Iteration 119999 (1.81079 iter/s, 54.6722s/99 iter), loss = 2.82888
I0213 02:25:21.596722 12354 solver.cpp:336]     Train net output #0: mbox_loss = 3.18066 (* 1 = 3.18066 loss)
I0213 02:25:21.596741 12354 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_120000.caffemodel
I0213 02:25:21.627343 12354 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_120000.solverstate
I0213 02:25:21.800154 12354 solver.cpp:537] Iteration 120000, loss = 2.76974
I0213 02:25:21.800279 12354 solver.cpp:666] Iteration 120000, Testing net (#0)
I0213 02:26:11.968497 12355 solver.cpp:774] class AP 1: 0.397061
I0213 02:26:12.023442 12355 solver.cpp:774] class AP 2: 0.643711
I0213 02:26:12.033046 12355 solver.cpp:774] class AP 3: 0.633499
I0213 02:26:12.033059 12355 solver.cpp:780] Test net output mAP #0: detection_eval = 0.55809
I0213 02:26:13.164036 12354 solver.cpp:774] class AP 1: 0.372607
I0213 02:26:13.229636 12354 solver.cpp:774] class AP 2: 0.629178
I0213 02:26:13.240814 12354 solver.cpp:774] class AP 3: 0.62781
I0213 02:26:13.240825 12354 solver.cpp:780] Test net output mAP #0: detection_eval = 0.543198
I0213 02:26:13.242383 12230 parallel.cpp:71] Root Solver performance on device 0: 2.001 * 8 = 16.01 img/sec (120000 itr in 5.997e+04 sec)
I0213 02:26:13.242416 12230 parallel.cpp:76]      Solver performance on device 1: 2.001 * 8 = 16.01 img/sec (120000 itr in 5.997e+04 sec)
I0213 02:26:13.242422 12230 parallel.cpp:79] Overall multi-GPU performance: 32.0173 img/sec
I0213 02:26:14.013538 12230 caffe.cpp:253] Optimization Done in 16h 40m 33s
