I0212 23:00:40.999660  3050 caffe.cpp:807] This is NVCaffe 0.16.4 started at Mon Feb 12 23:00:40 2018
I0212 23:00:40.999845  3050 caffe.cpp:810] CuDNN version: 6021
I0212 23:00:40.999853  3050 caffe.cpp:811] CuBLAS version: 8000
I0212 23:00:40.999857  3050 caffe.cpp:812] CUDA version: 8000
I0212 23:00:40.999861  3050 caffe.cpp:813] CUDA driver version: 8000
I0212 23:00:41.256112  3050 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0212 23:00:41.256744  3050 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8063877120, dev_info[0]: total=8506769408 free=8063877120
I0212 23:00:41.257313  3050 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8063877120, dev_info[1]: total=8508145664 free=8379170816
I0212 23:00:41.257329  3050 caffe.cpp:214] Using GPUs 0, 1
I0212 23:00:41.257670  3050 caffe.cpp:219] GPU 0: GeForce GTX 1080
I0212 23:00:41.257990  3050 caffe.cpp:219] GPU 1: GeForce GTX 1080
I0212 23:00:41.258044  3050 solver.cpp:43] Solver data type: FLOAT
I0212 23:00:41.258100  3050 solver.cpp:46] Initializing solver from parameters: 
train_net: "training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/train.prototxt"
test_net: "training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/test.prototxt"
test_iter: 452
test_interval: 2000
base_lr: 0.001
display: 100
max_iter: 60000
lr_policy: "poly"
gamma: 0.1
power: 2
momentum: 0.9
weight_decay: 1e-05
snapshot: 2000
snapshot_prefix: "training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
snapshot_after_train: true
regularization_type: "L1"
test_initialization: true
average_loss: 10
stepvalue: 30000
stepvalue: 45000
stepvalue: 200000
iter_size: 2
type: "SGD"
eval_type: "detection"
ap_version: "11point"
show_per_class_result: true
I0212 23:00:41.267180  3050 solver.cpp:78] Creating training net from train_net file: training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/train.prototxt
I0212 23:00:41.270155  3050 net.cpp:72] Initializing net from parameters: 
name: "ssdJacintoNetV2"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 0
    mean_value: 0
    mean_value: 0
    force_color: false
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 368
      width: 720
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: NEAREST
      interp_mode: CUBIC
      interp_mode: LANCZOS4
    }
    emit_constraint {
      emit_type: CENTER
    }
    crop_h: 368
    crop_w: 720
    distort_param {
      brightness_prob: 0.5
      brightness_delta: 32
      contrast_prob: 0.5
      contrast_lower: 0.5
      contrast_upper: 1.5
      hue_prob: 0.5
      hue_delta: 18
      saturation_prob: 0.5
      saturation_lower: 0.5
      saturation_upper: 1.5
      random_order_prob: 0
    }
    expand_param {
      prob: 0.5
      max_expand_ratio: 4
    }
  }
  data_param {
    source: "/user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb"
    batch_size: 8
    backend: LMDB
    threads: 4
    parser_threads: 4
  }
  annotated_data_param {
    batch_sampler {
      max_sample: 1
      max_trials: 1
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.1
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.3
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.5
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.7
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.9
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        max_jaccard_overlap: 1
      }
      max_sample: 1
      max_trials: 50
    }
    label_map_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/labelmap.prototxt"
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "pool6"
  top: "pool7"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool8"
  type: "Pooling"
  bottom: "pool7"
  top: "pool8"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool9"
  type: "Pooling"
  bottom: "pool8"
  top: "pool9"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "ctx_output1"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "ctx_output1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu"
  type: "ReLU"
  bottom: "ctx_output1"
  top: "ctx_output1"
}
layer {
  name: "ctx_output2"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "ctx_output2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu"
  type: "ReLU"
  bottom: "ctx_output2"
  top: "ctx_output2"
}
layer {
  name: "ctx_output3"
  type: "Convolution"
  bottom: "pool6"
  top: "ctx_output3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu"
  type: "ReLU"
  bottom: "ctx_output3"
  top: "ctx_output3"
}
layer {
  name: "ctx_output4"
  type: "Convolution"
  bottom: "pool7"
  top: "ctx_output4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu"
  type: "ReLU"
  bottom: "ctx_output4"
  top: "ctx_output4"
}
layer {
  name: "ctx_output5"
  type: "Convolution"
  bottom: "pool8"
  top: "ctx_output5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu"
  type: "ReLU"
  bottom: "ctx_output5"
  top: "ctx_output5"
}
layer {
  name: "ctx_output6"
  type: "Convolution"
  bottom: "pool9"
  top: "ctx_output6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu"
  type: "ReLU"
  bottom: "ctx_output6"
  top: "ctx_output6"
}
layer {
  name: "ctx_output1/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_loc"
  top: "ctx_output1/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_loc_perm"
  top: "ctx_output1/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_conf"
  top: "ctx_output1/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_conf_perm"
  top: "ctx_output1/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output1"
  bottom: "data"
  top: "ctx_output1/relu_mbox_priorbox"
  prior_box_param {
    min_size: 14.72
    max_size: 36.8
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_loc"
  top: "ctx_output2/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_loc_perm"
  top: "ctx_output2/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_conf"
  top: "ctx_output2/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_conf_perm"
  top: "ctx_output2/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output2"
  bottom: "data"
  top: "ctx_output2/relu_mbox_priorbox"
  prior_box_param {
    min_size: 36.8
    max_size: 110.4
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_loc"
  top: "ctx_output3/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_loc_perm"
  top: "ctx_output3/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_conf"
  top: "ctx_output3/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_conf_perm"
  top: "ctx_output3/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output3"
  bottom: "data"
  top: "ctx_output3/relu_mbox_priorbox"
  prior_box_param {
    min_size: 110.4
    max_size: 184
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_loc"
  top: "ctx_output4/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_loc_perm"
  top: "ctx_output4/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_conf"
  top: "ctx_output4/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_conf_perm"
  top: "ctx_output4/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output4"
  bottom: "data"
  top: "ctx_output4/relu_mbox_priorbox"
  prior_box_param {
    min_size: 184
    max_size: 257.6
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_loc"
  top: "ctx_output5/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_loc_perm"
  top: "ctx_output5/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_conf"
  top: "ctx_output5/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_conf_perm"
  top: "ctx_output5/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output5"
  bottom: "data"
  top: "ctx_output5/relu_mbox_priorbox"
  prior_box_param {
    min_size: 257.6
    max_size: 331.2
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_loc"
  top: "ctx_output6/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_loc_perm"
  top: "ctx_output6/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_conf"
  top: "ctx_output6/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_conf_perm"
  top: "ctx_output6/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output6"
  bottom: "data"
  top: "ctx_output6/relu_mbox_priorbox"
  prior_box_param {
    min_size: 331.2
    max_size: 404.8
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_loc_flat"
  bottom: "ctx_output2/relu_mbox_loc_flat"
  bottom: "ctx_output3/relu_mbox_loc_flat"
  bottom: "ctx_output4/relu_mbox_loc_flat"
  bottom: "ctx_output5/relu_mbox_loc_flat"
  bottom: "ctx_output6/relu_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_conf_flat"
  bottom: "ctx_output2/relu_mbox_conf_flat"
  bottom: "ctx_output3/relu_mbox_conf_flat"
  bottom: "ctx_output4/relu_mbox_conf_flat"
  bottom: "ctx_output5/relu_mbox_conf_flat"
  bottom: "ctx_output6/relu_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_priorbox"
  bottom: "ctx_output2/relu_mbox_priorbox"
  bottom: "ctx_output3/relu_mbox_priorbox"
  bottom: "ctx_output4/relu_mbox_priorbox"
  bottom: "ctx_output5/relu_mbox_priorbox"
  bottom: "ctx_output6/relu_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_loss"
  type: "MultiBoxLoss"
  bottom: "mbox_loc"
  bottom: "mbox_conf"
  bottom: "mbox_priorbox"
  bottom: "label"
  top: "mbox_loss"
  include {
    phase: TRAIN
  }
  propagate_down: true
  propagate_down: true
  propagate_down: false
  propagate_down: false
  loss_param {
    normalization: VALID
  }
  multibox_loss_param {
    loc_loss_type: SMOOTH_L1
    conf_loss_type: SOFTMAX
    loc_weight: 1
    num_classes: 4
    share_location: true
    match_type: PER_PREDICTION
    overlap_threshold: 0.5
    use_prior_for_matching: true
    background_label_id: 0
    use_difficult_gt: false
    neg_pos_ratio: 3
    neg_overlap: 0.5
    code_type: CENTER_SIZE
    ignore_cross_boundary_bbox: false
    mining_type: MAX_NEGATIVE
  }
}
I0212 23:00:41.270735  3050 net.cpp:104] Using FLOAT as default forward math type
I0212 23:00:41.270746  3050 net.cpp:110] Using FLOAT as default backward math type
I0212 23:00:41.270756  3050 layer_factory.hpp:136] Creating layer 'data' of type 'AnnotatedData'
I0212 23:00:41.270762  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.270865  3050 net.cpp:184] Created Layer data (0)
I0212 23:00:41.270875  3050 net.cpp:530] data -> data
I0212 23:00:41.270895  3050 net.cpp:530] data -> label
I0212 23:00:41.270958  3050 data_reader.cpp:58] Data Reader threads: 4, out queues: 16, depth: 8
I0212 23:00:41.271009  3050 internal_thread.cpp:19] Starting 4 internal thread(s) on device 0
I0212 23:00:41.273922  3080 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0212 23:00:41.273934  3079 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0212 23:00:41.274336  3081 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0212 23:00:41.275012  3082 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0212 23:00:41.292943  3050 annotated_data_layer.cpp:219] output data size: 8,3,368,720
I0212 23:00:41.293315  3050 annotated_data_layer.cpp:265] [0] Output data size: 8, 3, 368, 720
I0212 23:00:41.293380  3050 internal_thread.cpp:19] Starting 4 internal thread(s) on device 0
I0212 23:00:41.293547  3050 net.cpp:245] Setting up data
I0212 23:00:41.293577  3050 net.cpp:252] TRAIN Top shape for layer 0 'data' 8 3 368 720 (6359040)
I0212 23:00:41.293592  3050 net.cpp:252] TRAIN Top shape for layer 0 'data' 1 1 10 8 (80)
I0212 23:00:41.293604  3050 layer_factory.hpp:136] Creating layer 'data_data_0_split' of type 'Split'
I0212 23:00:41.293613  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.293630  3050 net.cpp:184] Created Layer data_data_0_split (1)
I0212 23:00:41.293643  3050 net.cpp:561] data_data_0_split <- data
I0212 23:00:41.293658  3050 net.cpp:530] data_data_0_split -> data_data_0_split_0
I0212 23:00:41.293668  3050 net.cpp:530] data_data_0_split -> data_data_0_split_1
I0212 23:00:41.293675  3050 net.cpp:530] data_data_0_split -> data_data_0_split_2
I0212 23:00:41.293682  3050 net.cpp:530] data_data_0_split -> data_data_0_split_3
I0212 23:00:41.293689  3050 net.cpp:530] data_data_0_split -> data_data_0_split_4
I0212 23:00:41.293694  3050 net.cpp:530] data_data_0_split -> data_data_0_split_5
I0212 23:00:41.293700  3050 net.cpp:530] data_data_0_split -> data_data_0_split_6
I0212 23:00:41.293843  3050 net.cpp:245] Setting up data_data_0_split
I0212 23:00:41.293856  3050 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 368 720 (6359040)
I0212 23:00:41.293864  3050 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 368 720 (6359040)
I0212 23:00:41.293869  3050 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 368 720 (6359040)
I0212 23:00:41.293876  3050 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 368 720 (6359040)
I0212 23:00:41.293882  3050 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 368 720 (6359040)
I0212 23:00:41.293889  3050 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 368 720 (6359040)
I0212 23:00:41.293895  3050 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 368 720 (6359040)
I0212 23:00:41.293900  3050 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0212 23:00:41.293906  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.293918  3050 net.cpp:184] Created Layer data/bias (2)
I0212 23:00:41.293923  3050 net.cpp:561] data/bias <- data_data_0_split_0
I0212 23:00:41.293931  3050 net.cpp:530] data/bias -> data/bias
I0212 23:00:41.303508  3050 net.cpp:245] Setting up data/bias
I0212 23:00:41.303542  3050 net.cpp:252] TRAIN Top shape for layer 2 'data/bias' 8 3 368 720 (6359040)
I0212 23:00:41.303563  3050 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0212 23:00:41.303571  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.303607  3050 net.cpp:184] Created Layer conv1a (3)
I0212 23:00:41.303616  3050 net.cpp:561] conv1a <- data/bias
I0212 23:00:41.303623  3050 net.cpp:530] conv1a -> conv1a
I0212 23:00:41.878162  3050 net.cpp:245] Setting up conv1a
I0212 23:00:41.878198  3050 net.cpp:252] TRAIN Top shape for layer 3 'conv1a' 8 32 184 360 (16957440)
I0212 23:00:41.878218  3050 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0212 23:00:41.878228  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.878279  3050 net.cpp:184] Created Layer conv1a/bn (4)
I0212 23:00:41.878290  3050 net.cpp:561] conv1a/bn <- conv1a
I0212 23:00:41.878299  3050 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0212 23:00:41.879377  3050 net.cpp:245] Setting up conv1a/bn
I0212 23:00:41.879393  3050 net.cpp:252] TRAIN Top shape for layer 4 'conv1a/bn' 8 32 184 360 (16957440)
I0212 23:00:41.879410  3050 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0212 23:00:41.879420  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.879428  3050 net.cpp:184] Created Layer conv1a/relu (5)
I0212 23:00:41.879436  3050 net.cpp:561] conv1a/relu <- conv1a
I0212 23:00:41.879442  3050 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0212 23:00:41.879461  3050 net.cpp:245] Setting up conv1a/relu
I0212 23:00:41.879469  3050 net.cpp:252] TRAIN Top shape for layer 5 'conv1a/relu' 8 32 184 360 (16957440)
I0212 23:00:41.879477  3050 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0212 23:00:41.879483  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.879500  3050 net.cpp:184] Created Layer conv1b (6)
I0212 23:00:41.879508  3050 net.cpp:561] conv1b <- conv1a
I0212 23:00:41.879514  3050 net.cpp:530] conv1b -> conv1b
I0212 23:00:41.881208  3050 net.cpp:245] Setting up conv1b
I0212 23:00:41.881225  3050 net.cpp:252] TRAIN Top shape for layer 6 'conv1b' 8 32 184 360 (16957440)
I0212 23:00:41.881238  3050 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0212 23:00:41.881245  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.881258  3050 net.cpp:184] Created Layer conv1b/bn (7)
I0212 23:00:41.881265  3050 net.cpp:561] conv1b/bn <- conv1b
I0212 23:00:41.881273  3050 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0212 23:00:41.882216  3050 net.cpp:245] Setting up conv1b/bn
I0212 23:00:41.882232  3050 net.cpp:252] TRAIN Top shape for layer 7 'conv1b/bn' 8 32 184 360 (16957440)
I0212 23:00:41.882247  3050 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0212 23:00:41.882254  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.882275  3050 net.cpp:184] Created Layer conv1b/relu (8)
I0212 23:00:41.882283  3050 net.cpp:561] conv1b/relu <- conv1b
I0212 23:00:41.882290  3050 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0212 23:00:41.882302  3050 net.cpp:245] Setting up conv1b/relu
I0212 23:00:41.882309  3050 net.cpp:252] TRAIN Top shape for layer 8 'conv1b/relu' 8 32 184 360 (16957440)
I0212 23:00:41.882316  3050 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0212 23:00:41.882323  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.882338  3050 net.cpp:184] Created Layer pool1 (9)
I0212 23:00:41.882344  3050 net.cpp:561] pool1 <- conv1b
I0212 23:00:41.882350  3050 net.cpp:530] pool1 -> pool1
I0212 23:00:41.882460  3050 net.cpp:245] Setting up pool1
I0212 23:00:41.882474  3050 net.cpp:252] TRAIN Top shape for layer 9 'pool1' 8 32 92 180 (4239360)
I0212 23:00:41.882481  3050 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0212 23:00:41.882488  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.882504  3050 net.cpp:184] Created Layer res2a_branch2a (10)
I0212 23:00:41.882511  3050 net.cpp:561] res2a_branch2a <- pool1
I0212 23:00:41.882519  3050 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0212 23:00:41.885135  3050 net.cpp:245] Setting up res2a_branch2a
I0212 23:00:41.885154  3050 net.cpp:252] TRAIN Top shape for layer 10 'res2a_branch2a' 8 64 92 180 (8478720)
I0212 23:00:41.885170  3050 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0212 23:00:41.885179  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.885201  3050 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0212 23:00:41.885210  3050 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0212 23:00:41.885217  3050 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0212 23:00:41.886726  3050 net.cpp:245] Setting up res2a_branch2a/bn
I0212 23:00:41.886744  3050 net.cpp:252] TRAIN Top shape for layer 11 'res2a_branch2a/bn' 8 64 92 180 (8478720)
I0212 23:00:41.886756  3050 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0212 23:00:41.886765  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.886771  3050 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0212 23:00:41.886778  3050 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0212 23:00:41.886785  3050 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0212 23:00:41.886795  3050 net.cpp:245] Setting up res2a_branch2a/relu
I0212 23:00:41.886803  3050 net.cpp:252] TRAIN Top shape for layer 12 'res2a_branch2a/relu' 8 64 92 180 (8478720)
I0212 23:00:41.886809  3050 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0212 23:00:41.886816  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.886832  3050 net.cpp:184] Created Layer res2a_branch2b (13)
I0212 23:00:41.886839  3050 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0212 23:00:41.886845  3050 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0212 23:00:41.888622  3050 net.cpp:245] Setting up res2a_branch2b
I0212 23:00:41.888641  3050 net.cpp:252] TRAIN Top shape for layer 13 'res2a_branch2b' 8 64 92 180 (8478720)
I0212 23:00:41.888653  3050 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0212 23:00:41.888661  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.888676  3050 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0212 23:00:41.888684  3050 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0212 23:00:41.888691  3050 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0212 23:00:41.889655  3050 net.cpp:245] Setting up res2a_branch2b/bn
I0212 23:00:41.889670  3050 net.cpp:252] TRAIN Top shape for layer 14 'res2a_branch2b/bn' 8 64 92 180 (8478720)
I0212 23:00:41.889686  3050 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0212 23:00:41.889693  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.889701  3050 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0212 23:00:41.889708  3050 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0212 23:00:41.889714  3050 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0212 23:00:41.889721  3050 net.cpp:245] Setting up res2a_branch2b/relu
I0212 23:00:41.889729  3050 net.cpp:252] TRAIN Top shape for layer 15 'res2a_branch2b/relu' 8 64 92 180 (8478720)
I0212 23:00:41.889734  3050 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0212 23:00:41.889739  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.889752  3050 net.cpp:184] Created Layer pool2 (16)
I0212 23:00:41.889760  3050 net.cpp:561] pool2 <- res2a_branch2b
I0212 23:00:41.889766  3050 net.cpp:530] pool2 -> pool2
I0212 23:00:41.889863  3050 net.cpp:245] Setting up pool2
I0212 23:00:41.889878  3050 net.cpp:252] TRAIN Top shape for layer 16 'pool2' 8 64 46 90 (2119680)
I0212 23:00:41.889885  3050 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0212 23:00:41.889891  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.889910  3050 net.cpp:184] Created Layer res3a_branch2a (17)
I0212 23:00:41.889917  3050 net.cpp:561] res3a_branch2a <- pool2
I0212 23:00:41.889924  3050 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0212 23:00:41.893005  3050 net.cpp:245] Setting up res3a_branch2a
I0212 23:00:41.893036  3050 net.cpp:252] TRAIN Top shape for layer 17 'res3a_branch2a' 8 128 46 90 (4239360)
I0212 23:00:41.893048  3050 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0212 23:00:41.893055  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.893070  3050 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0212 23:00:41.893079  3050 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0212 23:00:41.893085  3050 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0212 23:00:41.894022  3050 net.cpp:245] Setting up res3a_branch2a/bn
I0212 23:00:41.894037  3050 net.cpp:252] TRAIN Top shape for layer 18 'res3a_branch2a/bn' 8 128 46 90 (4239360)
I0212 23:00:41.894057  3050 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0212 23:00:41.894063  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.894071  3050 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0212 23:00:41.894076  3050 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0212 23:00:41.894083  3050 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0212 23:00:41.894093  3050 net.cpp:245] Setting up res3a_branch2a/relu
I0212 23:00:41.894100  3050 net.cpp:252] TRAIN Top shape for layer 19 'res3a_branch2a/relu' 8 128 46 90 (4239360)
I0212 23:00:41.894105  3050 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0212 23:00:41.894111  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.894127  3050 net.cpp:184] Created Layer res3a_branch2b (20)
I0212 23:00:41.894134  3050 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0212 23:00:41.894140  3050 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0212 23:00:41.895759  3050 net.cpp:245] Setting up res3a_branch2b
I0212 23:00:41.895776  3050 net.cpp:252] TRAIN Top shape for layer 20 'res3a_branch2b' 8 128 46 90 (4239360)
I0212 23:00:41.895786  3050 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0212 23:00:41.895792  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.895803  3050 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0212 23:00:41.895809  3050 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0212 23:00:41.895814  3050 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0212 23:00:41.896739  3050 net.cpp:245] Setting up res3a_branch2b/bn
I0212 23:00:41.896754  3050 net.cpp:252] TRAIN Top shape for layer 21 'res3a_branch2b/bn' 8 128 46 90 (4239360)
I0212 23:00:41.896770  3050 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0212 23:00:41.896776  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.896783  3050 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0212 23:00:41.896788  3050 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0212 23:00:41.896795  3050 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0212 23:00:41.896802  3050 net.cpp:245] Setting up res3a_branch2b/relu
I0212 23:00:41.896811  3050 net.cpp:252] TRAIN Top shape for layer 22 'res3a_branch2b/relu' 8 128 46 90 (4239360)
I0212 23:00:41.896817  3050 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0212 23:00:41.896824  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.896832  3050 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (23)
I0212 23:00:41.896839  3050 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0212 23:00:41.896845  3050 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0212 23:00:41.896853  3050 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0212 23:00:41.896925  3050 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0212 23:00:41.896947  3050 net.cpp:252] TRAIN Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 8 128 46 90 (4239360)
I0212 23:00:41.896955  3050 net.cpp:252] TRAIN Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 8 128 46 90 (4239360)
I0212 23:00:41.896961  3050 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0212 23:00:41.896967  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.896977  3050 net.cpp:184] Created Layer pool3 (24)
I0212 23:00:41.896983  3050 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0212 23:00:41.896989  3050 net.cpp:530] pool3 -> pool3
I0212 23:00:41.897081  3050 net.cpp:245] Setting up pool3
I0212 23:00:41.897096  3050 net.cpp:252] TRAIN Top shape for layer 24 'pool3' 8 128 23 45 (1059840)
I0212 23:00:41.897102  3050 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0212 23:00:41.897109  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.897122  3050 net.cpp:184] Created Layer res4a_branch2a (25)
I0212 23:00:41.897128  3050 net.cpp:561] res4a_branch2a <- pool3
I0212 23:00:41.897135  3050 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0212 23:00:41.908874  3050 net.cpp:245] Setting up res4a_branch2a
I0212 23:00:41.908905  3050 net.cpp:252] TRAIN Top shape for layer 25 'res4a_branch2a' 8 256 23 45 (2119680)
I0212 23:00:41.908920  3050 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0212 23:00:41.908927  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.908946  3050 net.cpp:184] Created Layer res4a_branch2a/bn (26)
I0212 23:00:41.908953  3050 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0212 23:00:41.908962  3050 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0212 23:00:41.909912  3050 net.cpp:245] Setting up res4a_branch2a/bn
I0212 23:00:41.909927  3050 net.cpp:252] TRAIN Top shape for layer 26 'res4a_branch2a/bn' 8 256 23 45 (2119680)
I0212 23:00:41.909940  3050 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0212 23:00:41.909947  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.909957  3050 net.cpp:184] Created Layer res4a_branch2a/relu (27)
I0212 23:00:41.909963  3050 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0212 23:00:41.909970  3050 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0212 23:00:41.909978  3050 net.cpp:245] Setting up res4a_branch2a/relu
I0212 23:00:41.909984  3050 net.cpp:252] TRAIN Top shape for layer 27 'res4a_branch2a/relu' 8 256 23 45 (2119680)
I0212 23:00:41.909991  3050 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0212 23:00:41.909996  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.910015  3050 net.cpp:184] Created Layer res4a_branch2b (28)
I0212 23:00:41.910023  3050 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0212 23:00:41.910029  3050 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0212 23:00:41.915205  3050 net.cpp:245] Setting up res4a_branch2b
I0212 23:00:41.915238  3050 net.cpp:252] TRAIN Top shape for layer 28 'res4a_branch2b' 8 256 23 45 (2119680)
I0212 23:00:41.915251  3050 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0212 23:00:41.915258  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.915277  3050 net.cpp:184] Created Layer res4a_branch2b/bn (29)
I0212 23:00:41.915284  3050 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0212 23:00:41.915292  3050 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0212 23:00:41.916244  3050 net.cpp:245] Setting up res4a_branch2b/bn
I0212 23:00:41.916260  3050 net.cpp:252] TRAIN Top shape for layer 29 'res4a_branch2b/bn' 8 256 23 45 (2119680)
I0212 23:00:41.916288  3050 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0212 23:00:41.916297  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.916307  3050 net.cpp:184] Created Layer res4a_branch2b/relu (30)
I0212 23:00:41.916314  3050 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0212 23:00:41.916321  3050 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0212 23:00:41.916330  3050 net.cpp:245] Setting up res4a_branch2b/relu
I0212 23:00:41.916340  3050 net.cpp:252] TRAIN Top shape for layer 30 'res4a_branch2b/relu' 8 256 23 45 (2119680)
I0212 23:00:41.916347  3050 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0212 23:00:41.916353  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.916364  3050 net.cpp:184] Created Layer pool4 (31)
I0212 23:00:41.916371  3050 net.cpp:561] pool4 <- res4a_branch2b
I0212 23:00:41.916378  3050 net.cpp:530] pool4 -> pool4
I0212 23:00:41.916477  3050 net.cpp:245] Setting up pool4
I0212 23:00:41.916491  3050 net.cpp:252] TRAIN Top shape for layer 31 'pool4' 8 256 12 23 (565248)
I0212 23:00:41.916498  3050 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0212 23:00:41.916505  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.916525  3050 net.cpp:184] Created Layer res5a_branch2a (32)
I0212 23:00:41.916532  3050 net.cpp:561] res5a_branch2a <- pool4
I0212 23:00:41.916540  3050 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0212 23:00:41.956465  3050 net.cpp:245] Setting up res5a_branch2a
I0212 23:00:41.956497  3050 net.cpp:252] TRAIN Top shape for layer 32 'res5a_branch2a' 8 512 12 23 (1130496)
I0212 23:00:41.956514  3050 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0212 23:00:41.956523  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.956539  3050 net.cpp:184] Created Layer res5a_branch2a/bn (33)
I0212 23:00:41.956547  3050 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0212 23:00:41.956554  3050 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0212 23:00:41.957481  3050 net.cpp:245] Setting up res5a_branch2a/bn
I0212 23:00:41.957496  3050 net.cpp:252] TRAIN Top shape for layer 33 'res5a_branch2a/bn' 8 512 12 23 (1130496)
I0212 23:00:41.957514  3050 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0212 23:00:41.957520  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.957530  3050 net.cpp:184] Created Layer res5a_branch2a/relu (34)
I0212 23:00:41.957536  3050 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0212 23:00:41.957542  3050 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0212 23:00:41.957551  3050 net.cpp:245] Setting up res5a_branch2a/relu
I0212 23:00:41.957558  3050 net.cpp:252] TRAIN Top shape for layer 34 'res5a_branch2a/relu' 8 512 12 23 (1130496)
I0212 23:00:41.957564  3050 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0212 23:00:41.957569  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.957586  3050 net.cpp:184] Created Layer res5a_branch2b (35)
I0212 23:00:41.957594  3050 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0212 23:00:41.957600  3050 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0212 23:00:41.977845  3050 net.cpp:245] Setting up res5a_branch2b
I0212 23:00:41.977886  3050 net.cpp:252] TRAIN Top shape for layer 35 'res5a_branch2b' 8 512 12 23 (1130496)
I0212 23:00:41.977910  3050 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0212 23:00:41.977917  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.977934  3050 net.cpp:184] Created Layer res5a_branch2b/bn (36)
I0212 23:00:41.977942  3050 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0212 23:00:41.977973  3050 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0212 23:00:41.978937  3050 net.cpp:245] Setting up res5a_branch2b/bn
I0212 23:00:41.978953  3050 net.cpp:252] TRAIN Top shape for layer 36 'res5a_branch2b/bn' 8 512 12 23 (1130496)
I0212 23:00:41.978969  3050 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0212 23:00:41.978977  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.978986  3050 net.cpp:184] Created Layer res5a_branch2b/relu (37)
I0212 23:00:41.978992  3050 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0212 23:00:41.978998  3050 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0212 23:00:41.979007  3050 net.cpp:245] Setting up res5a_branch2b/relu
I0212 23:00:41.979013  3050 net.cpp:252] TRAIN Top shape for layer 37 'res5a_branch2b/relu' 8 512 12 23 (1130496)
I0212 23:00:41.979020  3050 layer_factory.hpp:136] Creating layer 'res5a_branch2b_res5a_branch2b/relu_0_split' of type 'Split'
I0212 23:00:41.979025  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.979032  3050 net.cpp:184] Created Layer res5a_branch2b_res5a_branch2b/relu_0_split (38)
I0212 23:00:41.979038  3050 net.cpp:561] res5a_branch2b_res5a_branch2b/relu_0_split <- res5a_branch2b
I0212 23:00:41.979043  3050 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_0
I0212 23:00:41.979051  3050 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_1
I0212 23:00:41.979127  3050 net.cpp:245] Setting up res5a_branch2b_res5a_branch2b/relu_0_split
I0212 23:00:41.979140  3050 net.cpp:252] TRAIN Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 8 512 12 23 (1130496)
I0212 23:00:41.979147  3050 net.cpp:252] TRAIN Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 8 512 12 23 (1130496)
I0212 23:00:41.979153  3050 layer_factory.hpp:136] Creating layer 'pool6' of type 'Pooling'
I0212 23:00:41.979159  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.979173  3050 net.cpp:184] Created Layer pool6 (39)
I0212 23:00:41.979179  3050 net.cpp:561] pool6 <- res5a_branch2b_res5a_branch2b/relu_0_split_0
I0212 23:00:41.979187  3050 net.cpp:530] pool6 -> pool6
I0212 23:00:41.979285  3050 net.cpp:245] Setting up pool6
I0212 23:00:41.979298  3050 net.cpp:252] TRAIN Top shape for layer 39 'pool6' 8 512 6 12 (294912)
I0212 23:00:41.979305  3050 layer_factory.hpp:136] Creating layer 'pool6_pool6_0_split' of type 'Split'
I0212 23:00:41.979310  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.979316  3050 net.cpp:184] Created Layer pool6_pool6_0_split (40)
I0212 23:00:41.979321  3050 net.cpp:561] pool6_pool6_0_split <- pool6
I0212 23:00:41.979327  3050 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_0
I0212 23:00:41.979334  3050 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_1
I0212 23:00:41.979399  3050 net.cpp:245] Setting up pool6_pool6_0_split
I0212 23:00:41.979413  3050 net.cpp:252] TRAIN Top shape for layer 40 'pool6_pool6_0_split' 8 512 6 12 (294912)
I0212 23:00:41.979418  3050 net.cpp:252] TRAIN Top shape for layer 40 'pool6_pool6_0_split' 8 512 6 12 (294912)
I0212 23:00:41.979424  3050 layer_factory.hpp:136] Creating layer 'pool7' of type 'Pooling'
I0212 23:00:41.979430  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.979439  3050 net.cpp:184] Created Layer pool7 (41)
I0212 23:00:41.979444  3050 net.cpp:561] pool7 <- pool6_pool6_0_split_0
I0212 23:00:41.979449  3050 net.cpp:530] pool7 -> pool7
I0212 23:00:41.979539  3050 net.cpp:245] Setting up pool7
I0212 23:00:41.979552  3050 net.cpp:252] TRAIN Top shape for layer 41 'pool7' 8 512 3 6 (73728)
I0212 23:00:41.979559  3050 layer_factory.hpp:136] Creating layer 'pool7_pool7_0_split' of type 'Split'
I0212 23:00:41.979576  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.979584  3050 net.cpp:184] Created Layer pool7_pool7_0_split (42)
I0212 23:00:41.979589  3050 net.cpp:561] pool7_pool7_0_split <- pool7
I0212 23:00:41.979598  3050 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_0
I0212 23:00:41.979609  3050 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_1
I0212 23:00:41.979677  3050 net.cpp:245] Setting up pool7_pool7_0_split
I0212 23:00:41.979691  3050 net.cpp:252] TRAIN Top shape for layer 42 'pool7_pool7_0_split' 8 512 3 6 (73728)
I0212 23:00:41.979698  3050 net.cpp:252] TRAIN Top shape for layer 42 'pool7_pool7_0_split' 8 512 3 6 (73728)
I0212 23:00:41.979704  3050 layer_factory.hpp:136] Creating layer 'pool8' of type 'Pooling'
I0212 23:00:41.979709  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.979719  3050 net.cpp:184] Created Layer pool8 (43)
I0212 23:00:41.979725  3050 net.cpp:561] pool8 <- pool7_pool7_0_split_0
I0212 23:00:41.979732  3050 net.cpp:530] pool8 -> pool8
I0212 23:00:41.979826  3050 net.cpp:245] Setting up pool8
I0212 23:00:41.979840  3050 net.cpp:252] TRAIN Top shape for layer 43 'pool8' 8 512 2 3 (24576)
I0212 23:00:41.979846  3050 layer_factory.hpp:136] Creating layer 'pool8_pool8_0_split' of type 'Split'
I0212 23:00:41.979851  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.979858  3050 net.cpp:184] Created Layer pool8_pool8_0_split (44)
I0212 23:00:41.979863  3050 net.cpp:561] pool8_pool8_0_split <- pool8
I0212 23:00:41.979869  3050 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_0
I0212 23:00:41.979876  3050 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_1
I0212 23:00:41.979940  3050 net.cpp:245] Setting up pool8_pool8_0_split
I0212 23:00:41.979954  3050 net.cpp:252] TRAIN Top shape for layer 44 'pool8_pool8_0_split' 8 512 2 3 (24576)
I0212 23:00:41.979960  3050 net.cpp:252] TRAIN Top shape for layer 44 'pool8_pool8_0_split' 8 512 2 3 (24576)
I0212 23:00:41.979966  3050 layer_factory.hpp:136] Creating layer 'pool9' of type 'Pooling'
I0212 23:00:41.979971  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.979981  3050 net.cpp:184] Created Layer pool9 (45)
I0212 23:00:41.979987  3050 net.cpp:561] pool9 <- pool8_pool8_0_split_0
I0212 23:00:41.979993  3050 net.cpp:530] pool9 -> pool9
I0212 23:00:41.980087  3050 net.cpp:245] Setting up pool9
I0212 23:00:41.980100  3050 net.cpp:252] TRAIN Top shape for layer 45 'pool9' 8 512 1 2 (8192)
I0212 23:00:41.980106  3050 layer_factory.hpp:136] Creating layer 'ctx_output1' of type 'Convolution'
I0212 23:00:41.980113  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.980129  3050 net.cpp:184] Created Layer ctx_output1 (46)
I0212 23:00:41.980136  3050 net.cpp:561] ctx_output1 <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0212 23:00:41.980144  3050 net.cpp:530] ctx_output1 -> ctx_output1
I0212 23:00:41.981603  3050 net.cpp:245] Setting up ctx_output1
I0212 23:00:41.981618  3050 net.cpp:252] TRAIN Top shape for layer 46 'ctx_output1' 8 256 46 90 (8478720)
I0212 23:00:41.981631  3050 layer_factory.hpp:136] Creating layer 'ctx_output1/relu' of type 'ReLU'
I0212 23:00:41.981637  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.981647  3050 net.cpp:184] Created Layer ctx_output1/relu (47)
I0212 23:00:41.981652  3050 net.cpp:561] ctx_output1/relu <- ctx_output1
I0212 23:00:41.981658  3050 net.cpp:513] ctx_output1/relu -> ctx_output1 (in-place)
I0212 23:00:41.981667  3050 net.cpp:245] Setting up ctx_output1/relu
I0212 23:00:41.981673  3050 net.cpp:252] TRAIN Top shape for layer 47 'ctx_output1/relu' 8 256 46 90 (8478720)
I0212 23:00:41.981678  3050 layer_factory.hpp:136] Creating layer 'ctx_output1_ctx_output1/relu_0_split' of type 'Split'
I0212 23:00:41.981694  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.981701  3050 net.cpp:184] Created Layer ctx_output1_ctx_output1/relu_0_split (48)
I0212 23:00:41.981708  3050 net.cpp:561] ctx_output1_ctx_output1/relu_0_split <- ctx_output1
I0212 23:00:41.981714  3050 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_0
I0212 23:00:41.981721  3050 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_1
I0212 23:00:41.981730  3050 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_2
I0212 23:00:41.981827  3050 net.cpp:245] Setting up ctx_output1_ctx_output1/relu_0_split
I0212 23:00:41.981839  3050 net.cpp:252] TRAIN Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 8 256 46 90 (8478720)
I0212 23:00:41.981847  3050 net.cpp:252] TRAIN Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 8 256 46 90 (8478720)
I0212 23:00:41.981853  3050 net.cpp:252] TRAIN Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 8 256 46 90 (8478720)
I0212 23:00:41.981858  3050 layer_factory.hpp:136] Creating layer 'ctx_output2' of type 'Convolution'
I0212 23:00:41.981864  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.981880  3050 net.cpp:184] Created Layer ctx_output2 (49)
I0212 23:00:41.981889  3050 net.cpp:561] ctx_output2 <- res5a_branch2b_res5a_branch2b/relu_0_split_1
I0212 23:00:41.981895  3050 net.cpp:530] ctx_output2 -> ctx_output2
I0212 23:00:41.986281  3050 net.cpp:245] Setting up ctx_output2
I0212 23:00:41.986296  3050 net.cpp:252] TRAIN Top shape for layer 49 'ctx_output2' 8 256 12 23 (565248)
I0212 23:00:41.986308  3050 layer_factory.hpp:136] Creating layer 'ctx_output2/relu' of type 'ReLU'
I0212 23:00:41.986315  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.986323  3050 net.cpp:184] Created Layer ctx_output2/relu (50)
I0212 23:00:41.986330  3050 net.cpp:561] ctx_output2/relu <- ctx_output2
I0212 23:00:41.986335  3050 net.cpp:513] ctx_output2/relu -> ctx_output2 (in-place)
I0212 23:00:41.986343  3050 net.cpp:245] Setting up ctx_output2/relu
I0212 23:00:41.986351  3050 net.cpp:252] TRAIN Top shape for layer 50 'ctx_output2/relu' 8 256 12 23 (565248)
I0212 23:00:41.986356  3050 layer_factory.hpp:136] Creating layer 'ctx_output2_ctx_output2/relu_0_split' of type 'Split'
I0212 23:00:41.986361  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.986368  3050 net.cpp:184] Created Layer ctx_output2_ctx_output2/relu_0_split (51)
I0212 23:00:41.986377  3050 net.cpp:561] ctx_output2_ctx_output2/relu_0_split <- ctx_output2
I0212 23:00:41.986382  3050 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_0
I0212 23:00:41.986389  3050 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_1
I0212 23:00:41.986395  3050 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_2
I0212 23:00:41.986495  3050 net.cpp:245] Setting up ctx_output2_ctx_output2/relu_0_split
I0212 23:00:41.986507  3050 net.cpp:252] TRAIN Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 8 256 12 23 (565248)
I0212 23:00:41.986515  3050 net.cpp:252] TRAIN Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 8 256 12 23 (565248)
I0212 23:00:41.986521  3050 net.cpp:252] TRAIN Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 8 256 12 23 (565248)
I0212 23:00:41.986526  3050 layer_factory.hpp:136] Creating layer 'ctx_output3' of type 'Convolution'
I0212 23:00:41.986531  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.986548  3050 net.cpp:184] Created Layer ctx_output3 (52)
I0212 23:00:41.986555  3050 net.cpp:561] ctx_output3 <- pool6_pool6_0_split_1
I0212 23:00:41.986562  3050 net.cpp:530] ctx_output3 -> ctx_output3
I0212 23:00:41.992096  3050 net.cpp:245] Setting up ctx_output3
I0212 23:00:41.992115  3050 net.cpp:252] TRAIN Top shape for layer 52 'ctx_output3' 8 256 6 12 (147456)
I0212 23:00:41.992130  3050 layer_factory.hpp:136] Creating layer 'ctx_output3/relu' of type 'ReLU'
I0212 23:00:41.992136  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.992143  3050 net.cpp:184] Created Layer ctx_output3/relu (53)
I0212 23:00:41.992149  3050 net.cpp:561] ctx_output3/relu <- ctx_output3
I0212 23:00:41.992156  3050 net.cpp:513] ctx_output3/relu -> ctx_output3 (in-place)
I0212 23:00:41.992166  3050 net.cpp:245] Setting up ctx_output3/relu
I0212 23:00:41.992172  3050 net.cpp:252] TRAIN Top shape for layer 53 'ctx_output3/relu' 8 256 6 12 (147456)
I0212 23:00:41.992178  3050 layer_factory.hpp:136] Creating layer 'ctx_output3_ctx_output3/relu_0_split' of type 'Split'
I0212 23:00:41.992183  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.992192  3050 net.cpp:184] Created Layer ctx_output3_ctx_output3/relu_0_split (54)
I0212 23:00:41.992198  3050 net.cpp:561] ctx_output3_ctx_output3/relu_0_split <- ctx_output3
I0212 23:00:41.992204  3050 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_0
I0212 23:00:41.992213  3050 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_1
I0212 23:00:41.992219  3050 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_2
I0212 23:00:41.992321  3050 net.cpp:245] Setting up ctx_output3_ctx_output3/relu_0_split
I0212 23:00:41.992334  3050 net.cpp:252] TRAIN Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 8 256 6 12 (147456)
I0212 23:00:41.992341  3050 net.cpp:252] TRAIN Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 8 256 6 12 (147456)
I0212 23:00:41.992347  3050 net.cpp:252] TRAIN Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 8 256 6 12 (147456)
I0212 23:00:41.992355  3050 layer_factory.hpp:136] Creating layer 'ctx_output4' of type 'Convolution'
I0212 23:00:41.992362  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.992378  3050 net.cpp:184] Created Layer ctx_output4 (55)
I0212 23:00:41.992384  3050 net.cpp:561] ctx_output4 <- pool7_pool7_0_split_1
I0212 23:00:41.992391  3050 net.cpp:530] ctx_output4 -> ctx_output4
I0212 23:00:41.996764  3050 net.cpp:245] Setting up ctx_output4
I0212 23:00:41.996779  3050 net.cpp:252] TRAIN Top shape for layer 55 'ctx_output4' 8 256 3 6 (36864)
I0212 23:00:41.996793  3050 layer_factory.hpp:136] Creating layer 'ctx_output4/relu' of type 'ReLU'
I0212 23:00:41.996798  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.996807  3050 net.cpp:184] Created Layer ctx_output4/relu (56)
I0212 23:00:41.996814  3050 net.cpp:561] ctx_output4/relu <- ctx_output4
I0212 23:00:41.996819  3050 net.cpp:513] ctx_output4/relu -> ctx_output4 (in-place)
I0212 23:00:41.996829  3050 net.cpp:245] Setting up ctx_output4/relu
I0212 23:00:41.996835  3050 net.cpp:252] TRAIN Top shape for layer 56 'ctx_output4/relu' 8 256 3 6 (36864)
I0212 23:00:41.996841  3050 layer_factory.hpp:136] Creating layer 'ctx_output4_ctx_output4/relu_0_split' of type 'Split'
I0212 23:00:41.996846  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.996852  3050 net.cpp:184] Created Layer ctx_output4_ctx_output4/relu_0_split (57)
I0212 23:00:41.996860  3050 net.cpp:561] ctx_output4_ctx_output4/relu_0_split <- ctx_output4
I0212 23:00:41.996866  3050 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_0
I0212 23:00:41.996876  3050 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_1
I0212 23:00:41.996882  3050 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_2
I0212 23:00:41.996991  3050 net.cpp:245] Setting up ctx_output4_ctx_output4/relu_0_split
I0212 23:00:41.997005  3050 net.cpp:252] TRAIN Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 8 256 3 6 (36864)
I0212 23:00:41.997011  3050 net.cpp:252] TRAIN Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 8 256 3 6 (36864)
I0212 23:00:41.997021  3050 net.cpp:252] TRAIN Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 8 256 3 6 (36864)
I0212 23:00:41.997027  3050 layer_factory.hpp:136] Creating layer 'ctx_output5' of type 'Convolution'
I0212 23:00:41.997032  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:41.997050  3050 net.cpp:184] Created Layer ctx_output5 (58)
I0212 23:00:41.997056  3050 net.cpp:561] ctx_output5 <- pool8_pool8_0_split_1
I0212 23:00:41.997062  3050 net.cpp:530] ctx_output5 -> ctx_output5
I0212 23:00:42.002015  3050 net.cpp:245] Setting up ctx_output5
I0212 23:00:42.002049  3050 net.cpp:252] TRAIN Top shape for layer 58 'ctx_output5' 8 256 2 3 (12288)
I0212 23:00:42.002061  3050 layer_factory.hpp:136] Creating layer 'ctx_output5/relu' of type 'ReLU'
I0212 23:00:42.002069  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.002081  3050 net.cpp:184] Created Layer ctx_output5/relu (59)
I0212 23:00:42.002089  3050 net.cpp:561] ctx_output5/relu <- ctx_output5
I0212 23:00:42.002096  3050 net.cpp:513] ctx_output5/relu -> ctx_output5 (in-place)
I0212 23:00:42.002106  3050 net.cpp:245] Setting up ctx_output5/relu
I0212 23:00:42.002115  3050 net.cpp:252] TRAIN Top shape for layer 59 'ctx_output5/relu' 8 256 2 3 (12288)
I0212 23:00:42.002125  3050 layer_factory.hpp:136] Creating layer 'ctx_output5_ctx_output5/relu_0_split' of type 'Split'
I0212 23:00:42.002130  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.002136  3050 net.cpp:184] Created Layer ctx_output5_ctx_output5/relu_0_split (60)
I0212 23:00:42.002142  3050 net.cpp:561] ctx_output5_ctx_output5/relu_0_split <- ctx_output5
I0212 23:00:42.002148  3050 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_0
I0212 23:00:42.002156  3050 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_1
I0212 23:00:42.002163  3050 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_2
I0212 23:00:42.002277  3050 net.cpp:245] Setting up ctx_output5_ctx_output5/relu_0_split
I0212 23:00:42.002292  3050 net.cpp:252] TRAIN Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 8 256 2 3 (12288)
I0212 23:00:42.002300  3050 net.cpp:252] TRAIN Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 8 256 2 3 (12288)
I0212 23:00:42.002305  3050 net.cpp:252] TRAIN Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 8 256 2 3 (12288)
I0212 23:00:42.002311  3050 layer_factory.hpp:136] Creating layer 'ctx_output6' of type 'Convolution'
I0212 23:00:42.002318  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.002341  3050 net.cpp:184] Created Layer ctx_output6 (61)
I0212 23:00:42.002349  3050 net.cpp:561] ctx_output6 <- pool9
I0212 23:00:42.002357  3050 net.cpp:530] ctx_output6 -> ctx_output6
I0212 23:00:42.007046  3050 net.cpp:245] Setting up ctx_output6
I0212 23:00:42.007081  3050 net.cpp:252] TRAIN Top shape for layer 61 'ctx_output6' 8 256 1 2 (4096)
I0212 23:00:42.007095  3050 layer_factory.hpp:136] Creating layer 'ctx_output6/relu' of type 'ReLU'
I0212 23:00:42.007102  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.007112  3050 net.cpp:184] Created Layer ctx_output6/relu (62)
I0212 23:00:42.007120  3050 net.cpp:561] ctx_output6/relu <- ctx_output6
I0212 23:00:42.007128  3050 net.cpp:513] ctx_output6/relu -> ctx_output6 (in-place)
I0212 23:00:42.007138  3050 net.cpp:245] Setting up ctx_output6/relu
I0212 23:00:42.007144  3050 net.cpp:252] TRAIN Top shape for layer 62 'ctx_output6/relu' 8 256 1 2 (4096)
I0212 23:00:42.007166  3050 layer_factory.hpp:136] Creating layer 'ctx_output6_ctx_output6/relu_0_split' of type 'Split'
I0212 23:00:42.007174  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.007182  3050 net.cpp:184] Created Layer ctx_output6_ctx_output6/relu_0_split (63)
I0212 23:00:42.007189  3050 net.cpp:561] ctx_output6_ctx_output6/relu_0_split <- ctx_output6
I0212 23:00:42.007194  3050 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_0
I0212 23:00:42.007205  3050 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_1
I0212 23:00:42.007211  3050 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_2
I0212 23:00:42.007313  3050 net.cpp:245] Setting up ctx_output6_ctx_output6/relu_0_split
I0212 23:00:42.007325  3050 net.cpp:252] TRAIN Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 8 256 1 2 (4096)
I0212 23:00:42.007335  3050 net.cpp:252] TRAIN Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 8 256 1 2 (4096)
I0212 23:00:42.007342  3050 net.cpp:252] TRAIN Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 8 256 1 2 (4096)
I0212 23:00:42.007349  3050 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc' of type 'Convolution'
I0212 23:00:42.007354  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.007375  3050 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc (64)
I0212 23:00:42.007382  3050 net.cpp:561] ctx_output1/relu_mbox_loc <- ctx_output1_ctx_output1/relu_0_split_0
I0212 23:00:42.007390  3050 net.cpp:530] ctx_output1/relu_mbox_loc -> ctx_output1/relu_mbox_loc
I0212 23:00:42.008021  3050 net.cpp:245] Setting up ctx_output1/relu_mbox_loc
I0212 23:00:42.008036  3050 net.cpp:252] TRAIN Top shape for layer 64 'ctx_output1/relu_mbox_loc' 8 16 46 90 (529920)
I0212 23:00:42.008046  3050 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_perm' of type 'Permute'
I0212 23:00:42.008054  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.008074  3050 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_perm (65)
I0212 23:00:42.008081  3050 net.cpp:561] ctx_output1/relu_mbox_loc_perm <- ctx_output1/relu_mbox_loc
I0212 23:00:42.008088  3050 net.cpp:530] ctx_output1/relu_mbox_loc_perm -> ctx_output1/relu_mbox_loc_perm
I0212 23:00:42.008282  3050 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_perm
I0212 23:00:42.008296  3050 net.cpp:252] TRAIN Top shape for layer 65 'ctx_output1/relu_mbox_loc_perm' 8 46 90 16 (529920)
I0212 23:00:42.008301  3050 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_flat' of type 'Flatten'
I0212 23:00:42.008311  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.008324  3050 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_flat (66)
I0212 23:00:42.008330  3050 net.cpp:561] ctx_output1/relu_mbox_loc_flat <- ctx_output1/relu_mbox_loc_perm
I0212 23:00:42.008337  3050 net.cpp:530] ctx_output1/relu_mbox_loc_flat -> ctx_output1/relu_mbox_loc_flat
I0212 23:00:42.008384  3050 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_flat
I0212 23:00:42.008397  3050 net.cpp:252] TRAIN Top shape for layer 66 'ctx_output1/relu_mbox_loc_flat' 8 66240 (529920)
I0212 23:00:42.008404  3050 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf' of type 'Convolution'
I0212 23:00:42.008409  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.008424  3050 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf (67)
I0212 23:00:42.008432  3050 net.cpp:561] ctx_output1/relu_mbox_conf <- ctx_output1_ctx_output1/relu_0_split_1
I0212 23:00:42.008440  3050 net.cpp:530] ctx_output1/relu_mbox_conf -> ctx_output1/relu_mbox_conf
I0212 23:00:42.009043  3050 net.cpp:245] Setting up ctx_output1/relu_mbox_conf
I0212 23:00:42.009066  3050 net.cpp:252] TRAIN Top shape for layer 67 'ctx_output1/relu_mbox_conf' 8 16 46 90 (529920)
I0212 23:00:42.009080  3050 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_perm' of type 'Permute'
I0212 23:00:42.009086  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.009099  3050 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_perm (68)
I0212 23:00:42.009104  3050 net.cpp:561] ctx_output1/relu_mbox_conf_perm <- ctx_output1/relu_mbox_conf
I0212 23:00:42.009111  3050 net.cpp:530] ctx_output1/relu_mbox_conf_perm -> ctx_output1/relu_mbox_conf_perm
I0212 23:00:42.009307  3050 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_perm
I0212 23:00:42.009320  3050 net.cpp:252] TRAIN Top shape for layer 68 'ctx_output1/relu_mbox_conf_perm' 8 46 90 16 (529920)
I0212 23:00:42.009326  3050 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_flat' of type 'Flatten'
I0212 23:00:42.009335  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.009343  3050 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_flat (69)
I0212 23:00:42.009348  3050 net.cpp:561] ctx_output1/relu_mbox_conf_flat <- ctx_output1/relu_mbox_conf_perm
I0212 23:00:42.009354  3050 net.cpp:530] ctx_output1/relu_mbox_conf_flat -> ctx_output1/relu_mbox_conf_flat
I0212 23:00:42.009399  3050 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_flat
I0212 23:00:42.009413  3050 net.cpp:252] TRAIN Top shape for layer 69 'ctx_output1/relu_mbox_conf_flat' 8 66240 (529920)
I0212 23:00:42.009418  3050 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_priorbox' of type 'PriorBox'
I0212 23:00:42.009424  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.009434  3050 net.cpp:184] Created Layer ctx_output1/relu_mbox_priorbox (70)
I0212 23:00:42.009440  3050 net.cpp:561] ctx_output1/relu_mbox_priorbox <- ctx_output1_ctx_output1/relu_0_split_2
I0212 23:00:42.009446  3050 net.cpp:561] ctx_output1/relu_mbox_priorbox <- data_data_0_split_1
I0212 23:00:42.009456  3050 net.cpp:530] ctx_output1/relu_mbox_priorbox -> ctx_output1/relu_mbox_priorbox
I0212 23:00:42.009505  3050 net.cpp:245] Setting up ctx_output1/relu_mbox_priorbox
I0212 23:00:42.009516  3050 net.cpp:252] TRAIN Top shape for layer 70 'ctx_output1/relu_mbox_priorbox' 1 2 66240 (132480)
I0212 23:00:42.009522  3050 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc' of type 'Convolution'
I0212 23:00:42.009528  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.009546  3050 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc (71)
I0212 23:00:42.009555  3050 net.cpp:561] ctx_output2/relu_mbox_loc <- ctx_output2_ctx_output2/relu_0_split_0
I0212 23:00:42.009563  3050 net.cpp:530] ctx_output2/relu_mbox_loc -> ctx_output2/relu_mbox_loc
I0212 23:00:42.010233  3050 net.cpp:245] Setting up ctx_output2/relu_mbox_loc
I0212 23:00:42.010248  3050 net.cpp:252] TRAIN Top shape for layer 71 'ctx_output2/relu_mbox_loc' 8 24 12 23 (52992)
I0212 23:00:42.010257  3050 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_perm' of type 'Permute'
I0212 23:00:42.010267  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.010277  3050 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_perm (72)
I0212 23:00:42.010284  3050 net.cpp:561] ctx_output2/relu_mbox_loc_perm <- ctx_output2/relu_mbox_loc
I0212 23:00:42.010290  3050 net.cpp:530] ctx_output2/relu_mbox_loc_perm -> ctx_output2/relu_mbox_loc_perm
I0212 23:00:42.010491  3050 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_perm
I0212 23:00:42.010505  3050 net.cpp:252] TRAIN Top shape for layer 72 'ctx_output2/relu_mbox_loc_perm' 8 12 23 24 (52992)
I0212 23:00:42.010511  3050 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_flat' of type 'Flatten'
I0212 23:00:42.010516  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.010540  3050 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_flat (73)
I0212 23:00:42.010546  3050 net.cpp:561] ctx_output2/relu_mbox_loc_flat <- ctx_output2/relu_mbox_loc_perm
I0212 23:00:42.010552  3050 net.cpp:530] ctx_output2/relu_mbox_loc_flat -> ctx_output2/relu_mbox_loc_flat
I0212 23:00:42.010598  3050 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_flat
I0212 23:00:42.010612  3050 net.cpp:252] TRAIN Top shape for layer 73 'ctx_output2/relu_mbox_loc_flat' 8 6624 (52992)
I0212 23:00:42.010618  3050 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf' of type 'Convolution'
I0212 23:00:42.010623  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.010639  3050 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf (74)
I0212 23:00:42.010646  3050 net.cpp:561] ctx_output2/relu_mbox_conf <- ctx_output2_ctx_output2/relu_0_split_1
I0212 23:00:42.010653  3050 net.cpp:530] ctx_output2/relu_mbox_conf -> ctx_output2/relu_mbox_conf
I0212 23:00:42.011318  3050 net.cpp:245] Setting up ctx_output2/relu_mbox_conf
I0212 23:00:42.011333  3050 net.cpp:252] TRAIN Top shape for layer 74 'ctx_output2/relu_mbox_conf' 8 24 12 23 (52992)
I0212 23:00:42.011343  3050 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_perm' of type 'Permute'
I0212 23:00:42.011353  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.011363  3050 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_perm (75)
I0212 23:00:42.011369  3050 net.cpp:561] ctx_output2/relu_mbox_conf_perm <- ctx_output2/relu_mbox_conf
I0212 23:00:42.011376  3050 net.cpp:530] ctx_output2/relu_mbox_conf_perm -> ctx_output2/relu_mbox_conf_perm
I0212 23:00:42.011574  3050 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_perm
I0212 23:00:42.011587  3050 net.cpp:252] TRAIN Top shape for layer 75 'ctx_output2/relu_mbox_conf_perm' 8 12 23 24 (52992)
I0212 23:00:42.011593  3050 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_flat' of type 'Flatten'
I0212 23:00:42.011601  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.011610  3050 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_flat (76)
I0212 23:00:42.011615  3050 net.cpp:561] ctx_output2/relu_mbox_conf_flat <- ctx_output2/relu_mbox_conf_perm
I0212 23:00:42.011621  3050 net.cpp:530] ctx_output2/relu_mbox_conf_flat -> ctx_output2/relu_mbox_conf_flat
I0212 23:00:42.011665  3050 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_flat
I0212 23:00:42.011679  3050 net.cpp:252] TRAIN Top shape for layer 76 'ctx_output2/relu_mbox_conf_flat' 8 6624 (52992)
I0212 23:00:42.011685  3050 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_priorbox' of type 'PriorBox'
I0212 23:00:42.011692  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.011698  3050 net.cpp:184] Created Layer ctx_output2/relu_mbox_priorbox (77)
I0212 23:00:42.011704  3050 net.cpp:561] ctx_output2/relu_mbox_priorbox <- ctx_output2_ctx_output2/relu_0_split_2
I0212 23:00:42.011711  3050 net.cpp:561] ctx_output2/relu_mbox_priorbox <- data_data_0_split_2
I0212 23:00:42.011718  3050 net.cpp:530] ctx_output2/relu_mbox_priorbox -> ctx_output2/relu_mbox_priorbox
I0212 23:00:42.011765  3050 net.cpp:245] Setting up ctx_output2/relu_mbox_priorbox
I0212 23:00:42.011777  3050 net.cpp:252] TRAIN Top shape for layer 77 'ctx_output2/relu_mbox_priorbox' 1 2 6624 (13248)
I0212 23:00:42.011783  3050 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc' of type 'Convolution'
I0212 23:00:42.011790  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.011806  3050 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc (78)
I0212 23:00:42.011812  3050 net.cpp:561] ctx_output3/relu_mbox_loc <- ctx_output3_ctx_output3/relu_0_split_0
I0212 23:00:42.011827  3050 net.cpp:530] ctx_output3/relu_mbox_loc -> ctx_output3/relu_mbox_loc
I0212 23:00:42.012498  3050 net.cpp:245] Setting up ctx_output3/relu_mbox_loc
I0212 23:00:42.012516  3050 net.cpp:252] TRAIN Top shape for layer 78 'ctx_output3/relu_mbox_loc' 8 24 6 12 (13824)
I0212 23:00:42.012526  3050 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_perm' of type 'Permute'
I0212 23:00:42.012531  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.012542  3050 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_perm (79)
I0212 23:00:42.012550  3050 net.cpp:561] ctx_output3/relu_mbox_loc_perm <- ctx_output3/relu_mbox_loc
I0212 23:00:42.012557  3050 net.cpp:530] ctx_output3/relu_mbox_loc_perm -> ctx_output3/relu_mbox_loc_perm
I0212 23:00:42.012755  3050 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_perm
I0212 23:00:42.012768  3050 net.cpp:252] TRAIN Top shape for layer 79 'ctx_output3/relu_mbox_loc_perm' 8 6 12 24 (13824)
I0212 23:00:42.012774  3050 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_flat' of type 'Flatten'
I0212 23:00:42.012784  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.012790  3050 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_flat (80)
I0212 23:00:42.012796  3050 net.cpp:561] ctx_output3/relu_mbox_loc_flat <- ctx_output3/relu_mbox_loc_perm
I0212 23:00:42.012802  3050 net.cpp:530] ctx_output3/relu_mbox_loc_flat -> ctx_output3/relu_mbox_loc_flat
I0212 23:00:42.012848  3050 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_flat
I0212 23:00:42.012861  3050 net.cpp:252] TRAIN Top shape for layer 80 'ctx_output3/relu_mbox_loc_flat' 8 1728 (13824)
I0212 23:00:42.012867  3050 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf' of type 'Convolution'
I0212 23:00:42.012873  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.012892  3050 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf (81)
I0212 23:00:42.012899  3050 net.cpp:561] ctx_output3/relu_mbox_conf <- ctx_output3_ctx_output3/relu_0_split_1
I0212 23:00:42.012907  3050 net.cpp:530] ctx_output3/relu_mbox_conf -> ctx_output3/relu_mbox_conf
I0212 23:00:42.013572  3050 net.cpp:245] Setting up ctx_output3/relu_mbox_conf
I0212 23:00:42.013587  3050 net.cpp:252] TRAIN Top shape for layer 81 'ctx_output3/relu_mbox_conf' 8 24 6 12 (13824)
I0212 23:00:42.013597  3050 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_perm' of type 'Permute'
I0212 23:00:42.013607  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.013617  3050 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_perm (82)
I0212 23:00:42.013623  3050 net.cpp:561] ctx_output3/relu_mbox_conf_perm <- ctx_output3/relu_mbox_conf
I0212 23:00:42.013629  3050 net.cpp:530] ctx_output3/relu_mbox_conf_perm -> ctx_output3/relu_mbox_conf_perm
I0212 23:00:42.013824  3050 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_perm
I0212 23:00:42.013837  3050 net.cpp:252] TRAIN Top shape for layer 82 'ctx_output3/relu_mbox_conf_perm' 8 6 12 24 (13824)
I0212 23:00:42.013846  3050 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_flat' of type 'Flatten'
I0212 23:00:42.013852  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.013861  3050 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_flat (83)
I0212 23:00:42.013867  3050 net.cpp:561] ctx_output3/relu_mbox_conf_flat <- ctx_output3/relu_mbox_conf_perm
I0212 23:00:42.013873  3050 net.cpp:530] ctx_output3/relu_mbox_conf_flat -> ctx_output3/relu_mbox_conf_flat
I0212 23:00:42.013918  3050 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_flat
I0212 23:00:42.013928  3050 net.cpp:252] TRAIN Top shape for layer 83 'ctx_output3/relu_mbox_conf_flat' 8 1728 (13824)
I0212 23:00:42.013936  3050 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_priorbox' of type 'PriorBox'
I0212 23:00:42.013952  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.013962  3050 net.cpp:184] Created Layer ctx_output3/relu_mbox_priorbox (84)
I0212 23:00:42.013967  3050 net.cpp:561] ctx_output3/relu_mbox_priorbox <- ctx_output3_ctx_output3/relu_0_split_2
I0212 23:00:42.013975  3050 net.cpp:561] ctx_output3/relu_mbox_priorbox <- data_data_0_split_3
I0212 23:00:42.013983  3050 net.cpp:530] ctx_output3/relu_mbox_priorbox -> ctx_output3/relu_mbox_priorbox
I0212 23:00:42.014029  3050 net.cpp:245] Setting up ctx_output3/relu_mbox_priorbox
I0212 23:00:42.014039  3050 net.cpp:252] TRAIN Top shape for layer 84 'ctx_output3/relu_mbox_priorbox' 1 2 1728 (3456)
I0212 23:00:42.014045  3050 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc' of type 'Convolution'
I0212 23:00:42.014051  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.014066  3050 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc (85)
I0212 23:00:42.014072  3050 net.cpp:561] ctx_output4/relu_mbox_loc <- ctx_output4_ctx_output4/relu_0_split_0
I0212 23:00:42.014080  3050 net.cpp:530] ctx_output4/relu_mbox_loc -> ctx_output4/relu_mbox_loc
I0212 23:00:42.014760  3050 net.cpp:245] Setting up ctx_output4/relu_mbox_loc
I0212 23:00:42.014772  3050 net.cpp:252] TRAIN Top shape for layer 85 'ctx_output4/relu_mbox_loc' 8 24 3 6 (3456)
I0212 23:00:42.014781  3050 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_perm' of type 'Permute'
I0212 23:00:42.014787  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.014797  3050 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_perm (86)
I0212 23:00:42.014803  3050 net.cpp:561] ctx_output4/relu_mbox_loc_perm <- ctx_output4/relu_mbox_loc
I0212 23:00:42.014809  3050 net.cpp:530] ctx_output4/relu_mbox_loc_perm -> ctx_output4/relu_mbox_loc_perm
I0212 23:00:42.014997  3050 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_perm
I0212 23:00:42.015009  3050 net.cpp:252] TRAIN Top shape for layer 86 'ctx_output4/relu_mbox_loc_perm' 8 3 6 24 (3456)
I0212 23:00:42.015014  3050 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_flat' of type 'Flatten'
I0212 23:00:42.015020  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.015027  3050 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_flat (87)
I0212 23:00:42.015033  3050 net.cpp:561] ctx_output4/relu_mbox_loc_flat <- ctx_output4/relu_mbox_loc_perm
I0212 23:00:42.015038  3050 net.cpp:530] ctx_output4/relu_mbox_loc_flat -> ctx_output4/relu_mbox_loc_flat
I0212 23:00:42.015080  3050 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_flat
I0212 23:00:42.015091  3050 net.cpp:252] TRAIN Top shape for layer 87 'ctx_output4/relu_mbox_loc_flat' 8 432 (3456)
I0212 23:00:42.015097  3050 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf' of type 'Convolution'
I0212 23:00:42.015102  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.015117  3050 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf (88)
I0212 23:00:42.015123  3050 net.cpp:561] ctx_output4/relu_mbox_conf <- ctx_output4_ctx_output4/relu_0_split_1
I0212 23:00:42.015130  3050 net.cpp:530] ctx_output4/relu_mbox_conf -> ctx_output4/relu_mbox_conf
I0212 23:00:42.015795  3050 net.cpp:245] Setting up ctx_output4/relu_mbox_conf
I0212 23:00:42.015811  3050 net.cpp:252] TRAIN Top shape for layer 88 'ctx_output4/relu_mbox_conf' 8 24 3 6 (3456)
I0212 23:00:42.015821  3050 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_perm' of type 'Permute'
I0212 23:00:42.015827  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.015837  3050 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_perm (89)
I0212 23:00:42.015843  3050 net.cpp:561] ctx_output4/relu_mbox_conf_perm <- ctx_output4/relu_mbox_conf
I0212 23:00:42.015849  3050 net.cpp:530] ctx_output4/relu_mbox_conf_perm -> ctx_output4/relu_mbox_conf_perm
I0212 23:00:42.016047  3050 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_perm
I0212 23:00:42.016059  3050 net.cpp:252] TRAIN Top shape for layer 89 'ctx_output4/relu_mbox_conf_perm' 8 3 6 24 (3456)
I0212 23:00:42.016065  3050 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_flat' of type 'Flatten'
I0212 23:00:42.016070  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.016077  3050 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_flat (90)
I0212 23:00:42.016083  3050 net.cpp:561] ctx_output4/relu_mbox_conf_flat <- ctx_output4/relu_mbox_conf_perm
I0212 23:00:42.016088  3050 net.cpp:530] ctx_output4/relu_mbox_conf_flat -> ctx_output4/relu_mbox_conf_flat
I0212 23:00:42.016131  3050 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_flat
I0212 23:00:42.016141  3050 net.cpp:252] TRAIN Top shape for layer 90 'ctx_output4/relu_mbox_conf_flat' 8 432 (3456)
I0212 23:00:42.016147  3050 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_priorbox' of type 'PriorBox'
I0212 23:00:42.016153  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.016162  3050 net.cpp:184] Created Layer ctx_output4/relu_mbox_priorbox (91)
I0212 23:00:42.016167  3050 net.cpp:561] ctx_output4/relu_mbox_priorbox <- ctx_output4_ctx_output4/relu_0_split_2
I0212 23:00:42.016175  3050 net.cpp:561] ctx_output4/relu_mbox_priorbox <- data_data_0_split_4
I0212 23:00:42.016180  3050 net.cpp:530] ctx_output4/relu_mbox_priorbox -> ctx_output4/relu_mbox_priorbox
I0212 23:00:42.016224  3050 net.cpp:245] Setting up ctx_output4/relu_mbox_priorbox
I0212 23:00:42.016234  3050 net.cpp:252] TRAIN Top shape for layer 91 'ctx_output4/relu_mbox_priorbox' 1 2 432 (864)
I0212 23:00:42.016240  3050 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc' of type 'Convolution'
I0212 23:00:42.016247  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.016263  3050 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc (92)
I0212 23:00:42.016270  3050 net.cpp:561] ctx_output5/relu_mbox_loc <- ctx_output5_ctx_output5/relu_0_split_0
I0212 23:00:42.016276  3050 net.cpp:530] ctx_output5/relu_mbox_loc -> ctx_output5/relu_mbox_loc
I0212 23:00:42.016877  3050 net.cpp:245] Setting up ctx_output5/relu_mbox_loc
I0212 23:00:42.016891  3050 net.cpp:252] TRAIN Top shape for layer 92 'ctx_output5/relu_mbox_loc' 8 16 2 3 (768)
I0212 23:00:42.016901  3050 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_perm' of type 'Permute'
I0212 23:00:42.016906  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.016917  3050 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_perm (93)
I0212 23:00:42.016923  3050 net.cpp:561] ctx_output5/relu_mbox_loc_perm <- ctx_output5/relu_mbox_loc
I0212 23:00:42.016929  3050 net.cpp:530] ctx_output5/relu_mbox_loc_perm -> ctx_output5/relu_mbox_loc_perm
I0212 23:00:42.017117  3050 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_perm
I0212 23:00:42.017129  3050 net.cpp:252] TRAIN Top shape for layer 93 'ctx_output5/relu_mbox_loc_perm' 8 2 3 16 (768)
I0212 23:00:42.017135  3050 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_flat' of type 'Flatten'
I0212 23:00:42.017140  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.017148  3050 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_flat (94)
I0212 23:00:42.017155  3050 net.cpp:561] ctx_output5/relu_mbox_loc_flat <- ctx_output5/relu_mbox_loc_perm
I0212 23:00:42.017161  3050 net.cpp:530] ctx_output5/relu_mbox_loc_flat -> ctx_output5/relu_mbox_loc_flat
I0212 23:00:42.017204  3050 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_flat
I0212 23:00:42.017215  3050 net.cpp:252] TRAIN Top shape for layer 94 'ctx_output5/relu_mbox_loc_flat' 8 96 (768)
I0212 23:00:42.017220  3050 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf' of type 'Convolution'
I0212 23:00:42.017233  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.017249  3050 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf (95)
I0212 23:00:42.017256  3050 net.cpp:561] ctx_output5/relu_mbox_conf <- ctx_output5_ctx_output5/relu_0_split_1
I0212 23:00:42.017262  3050 net.cpp:530] ctx_output5/relu_mbox_conf -> ctx_output5/relu_mbox_conf
I0212 23:00:42.017868  3050 net.cpp:245] Setting up ctx_output5/relu_mbox_conf
I0212 23:00:42.017881  3050 net.cpp:252] TRAIN Top shape for layer 95 'ctx_output5/relu_mbox_conf' 8 16 2 3 (768)
I0212 23:00:42.017890  3050 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_perm' of type 'Permute'
I0212 23:00:42.017896  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.017906  3050 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_perm (96)
I0212 23:00:42.017913  3050 net.cpp:561] ctx_output5/relu_mbox_conf_perm <- ctx_output5/relu_mbox_conf
I0212 23:00:42.017920  3050 net.cpp:530] ctx_output5/relu_mbox_conf_perm -> ctx_output5/relu_mbox_conf_perm
I0212 23:00:42.018108  3050 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_perm
I0212 23:00:42.018121  3050 net.cpp:252] TRAIN Top shape for layer 96 'ctx_output5/relu_mbox_conf_perm' 8 2 3 16 (768)
I0212 23:00:42.018126  3050 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_flat' of type 'Flatten'
I0212 23:00:42.018131  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.018139  3050 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_flat (97)
I0212 23:00:42.018146  3050 net.cpp:561] ctx_output5/relu_mbox_conf_flat <- ctx_output5/relu_mbox_conf_perm
I0212 23:00:42.018151  3050 net.cpp:530] ctx_output5/relu_mbox_conf_flat -> ctx_output5/relu_mbox_conf_flat
I0212 23:00:42.018198  3050 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_flat
I0212 23:00:42.018208  3050 net.cpp:252] TRAIN Top shape for layer 97 'ctx_output5/relu_mbox_conf_flat' 8 96 (768)
I0212 23:00:42.018213  3050 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_priorbox' of type 'PriorBox'
I0212 23:00:42.018219  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.018226  3050 net.cpp:184] Created Layer ctx_output5/relu_mbox_priorbox (98)
I0212 23:00:42.018231  3050 net.cpp:561] ctx_output5/relu_mbox_priorbox <- ctx_output5_ctx_output5/relu_0_split_2
I0212 23:00:42.018237  3050 net.cpp:561] ctx_output5/relu_mbox_priorbox <- data_data_0_split_5
I0212 23:00:42.018244  3050 net.cpp:530] ctx_output5/relu_mbox_priorbox -> ctx_output5/relu_mbox_priorbox
I0212 23:00:42.018295  3050 net.cpp:245] Setting up ctx_output5/relu_mbox_priorbox
I0212 23:00:42.018306  3050 net.cpp:252] TRAIN Top shape for layer 98 'ctx_output5/relu_mbox_priorbox' 1 2 96 (192)
I0212 23:00:42.018312  3050 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc' of type 'Convolution'
I0212 23:00:42.018317  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.018332  3050 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc (99)
I0212 23:00:42.018338  3050 net.cpp:561] ctx_output6/relu_mbox_loc <- ctx_output6_ctx_output6/relu_0_split_0
I0212 23:00:42.018344  3050 net.cpp:530] ctx_output6/relu_mbox_loc -> ctx_output6/relu_mbox_loc
I0212 23:00:42.018949  3050 net.cpp:245] Setting up ctx_output6/relu_mbox_loc
I0212 23:00:42.018963  3050 net.cpp:252] TRAIN Top shape for layer 99 'ctx_output6/relu_mbox_loc' 8 16 1 2 (256)
I0212 23:00:42.018972  3050 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_perm' of type 'Permute'
I0212 23:00:42.018978  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.018990  3050 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_perm (100)
I0212 23:00:42.018996  3050 net.cpp:561] ctx_output6/relu_mbox_loc_perm <- ctx_output6/relu_mbox_loc
I0212 23:00:42.019011  3050 net.cpp:530] ctx_output6/relu_mbox_loc_perm -> ctx_output6/relu_mbox_loc_perm
I0212 23:00:42.019201  3050 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_perm
I0212 23:00:42.019212  3050 net.cpp:252] TRAIN Top shape for layer 100 'ctx_output6/relu_mbox_loc_perm' 8 1 2 16 (256)
I0212 23:00:42.019218  3050 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_flat' of type 'Flatten'
I0212 23:00:42.019223  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.019230  3050 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_flat (101)
I0212 23:00:42.019235  3050 net.cpp:561] ctx_output6/relu_mbox_loc_flat <- ctx_output6/relu_mbox_loc_perm
I0212 23:00:42.019242  3050 net.cpp:530] ctx_output6/relu_mbox_loc_flat -> ctx_output6/relu_mbox_loc_flat
I0212 23:00:42.019284  3050 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_flat
I0212 23:00:42.019294  3050 net.cpp:252] TRAIN Top shape for layer 101 'ctx_output6/relu_mbox_loc_flat' 8 32 (256)
I0212 23:00:42.019300  3050 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf' of type 'Convolution'
I0212 23:00:42.019306  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.019322  3050 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf (102)
I0212 23:00:42.019330  3050 net.cpp:561] ctx_output6/relu_mbox_conf <- ctx_output6_ctx_output6/relu_0_split_1
I0212 23:00:42.019335  3050 net.cpp:530] ctx_output6/relu_mbox_conf -> ctx_output6/relu_mbox_conf
I0212 23:00:42.019942  3050 net.cpp:245] Setting up ctx_output6/relu_mbox_conf
I0212 23:00:42.019955  3050 net.cpp:252] TRAIN Top shape for layer 102 'ctx_output6/relu_mbox_conf' 8 16 1 2 (256)
I0212 23:00:42.019964  3050 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_perm' of type 'Permute'
I0212 23:00:42.019969  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.019981  3050 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_perm (103)
I0212 23:00:42.019987  3050 net.cpp:561] ctx_output6/relu_mbox_conf_perm <- ctx_output6/relu_mbox_conf
I0212 23:00:42.019994  3050 net.cpp:530] ctx_output6/relu_mbox_conf_perm -> ctx_output6/relu_mbox_conf_perm
I0212 23:00:42.020181  3050 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_perm
I0212 23:00:42.020192  3050 net.cpp:252] TRAIN Top shape for layer 103 'ctx_output6/relu_mbox_conf_perm' 8 1 2 16 (256)
I0212 23:00:42.020198  3050 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_flat' of type 'Flatten'
I0212 23:00:42.020205  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.020210  3050 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_flat (104)
I0212 23:00:42.020216  3050 net.cpp:561] ctx_output6/relu_mbox_conf_flat <- ctx_output6/relu_mbox_conf_perm
I0212 23:00:42.020222  3050 net.cpp:530] ctx_output6/relu_mbox_conf_flat -> ctx_output6/relu_mbox_conf_flat
I0212 23:00:42.020264  3050 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_flat
I0212 23:00:42.020275  3050 net.cpp:252] TRAIN Top shape for layer 104 'ctx_output6/relu_mbox_conf_flat' 8 32 (256)
I0212 23:00:42.020282  3050 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_priorbox' of type 'PriorBox'
I0212 23:00:42.020287  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.020294  3050 net.cpp:184] Created Layer ctx_output6/relu_mbox_priorbox (105)
I0212 23:00:42.020299  3050 net.cpp:561] ctx_output6/relu_mbox_priorbox <- ctx_output6_ctx_output6/relu_0_split_2
I0212 23:00:42.020305  3050 net.cpp:561] ctx_output6/relu_mbox_priorbox <- data_data_0_split_6
I0212 23:00:42.020311  3050 net.cpp:530] ctx_output6/relu_mbox_priorbox -> ctx_output6/relu_mbox_priorbox
I0212 23:00:42.020356  3050 net.cpp:245] Setting up ctx_output6/relu_mbox_priorbox
I0212 23:00:42.020367  3050 net.cpp:252] TRAIN Top shape for layer 105 'ctx_output6/relu_mbox_priorbox' 1 2 32 (64)
I0212 23:00:42.020381  3050 layer_factory.hpp:136] Creating layer 'mbox_loc' of type 'Concat'
I0212 23:00:42.020388  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.020400  3050 net.cpp:184] Created Layer mbox_loc (106)
I0212 23:00:42.020406  3050 net.cpp:561] mbox_loc <- ctx_output1/relu_mbox_loc_flat
I0212 23:00:42.020411  3050 net.cpp:561] mbox_loc <- ctx_output2/relu_mbox_loc_flat
I0212 23:00:42.020417  3050 net.cpp:561] mbox_loc <- ctx_output3/relu_mbox_loc_flat
I0212 23:00:42.020423  3050 net.cpp:561] mbox_loc <- ctx_output4/relu_mbox_loc_flat
I0212 23:00:42.020428  3050 net.cpp:561] mbox_loc <- ctx_output5/relu_mbox_loc_flat
I0212 23:00:42.020433  3050 net.cpp:561] mbox_loc <- ctx_output6/relu_mbox_loc_flat
I0212 23:00:42.020439  3050 net.cpp:530] mbox_loc -> mbox_loc
I0212 23:00:42.020485  3050 net.cpp:245] Setting up mbox_loc
I0212 23:00:42.020496  3050 net.cpp:252] TRAIN Top shape for layer 106 'mbox_loc' 8 75152 (601216)
I0212 23:00:42.020503  3050 layer_factory.hpp:136] Creating layer 'mbox_conf' of type 'Concat'
I0212 23:00:42.020507  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.020515  3050 net.cpp:184] Created Layer mbox_conf (107)
I0212 23:00:42.020520  3050 net.cpp:561] mbox_conf <- ctx_output1/relu_mbox_conf_flat
I0212 23:00:42.020526  3050 net.cpp:561] mbox_conf <- ctx_output2/relu_mbox_conf_flat
I0212 23:00:42.020532  3050 net.cpp:561] mbox_conf <- ctx_output3/relu_mbox_conf_flat
I0212 23:00:42.020537  3050 net.cpp:561] mbox_conf <- ctx_output4/relu_mbox_conf_flat
I0212 23:00:42.020542  3050 net.cpp:561] mbox_conf <- ctx_output5/relu_mbox_conf_flat
I0212 23:00:42.020548  3050 net.cpp:561] mbox_conf <- ctx_output6/relu_mbox_conf_flat
I0212 23:00:42.020555  3050 net.cpp:530] mbox_conf -> mbox_conf
I0212 23:00:42.020598  3050 net.cpp:245] Setting up mbox_conf
I0212 23:00:42.020611  3050 net.cpp:252] TRAIN Top shape for layer 107 'mbox_conf' 8 75152 (601216)
I0212 23:00:42.020617  3050 layer_factory.hpp:136] Creating layer 'mbox_priorbox' of type 'Concat'
I0212 23:00:42.020622  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.020629  3050 net.cpp:184] Created Layer mbox_priorbox (108)
I0212 23:00:42.020634  3050 net.cpp:561] mbox_priorbox <- ctx_output1/relu_mbox_priorbox
I0212 23:00:42.020640  3050 net.cpp:561] mbox_priorbox <- ctx_output2/relu_mbox_priorbox
I0212 23:00:42.020647  3050 net.cpp:561] mbox_priorbox <- ctx_output3/relu_mbox_priorbox
I0212 23:00:42.020651  3050 net.cpp:561] mbox_priorbox <- ctx_output4/relu_mbox_priorbox
I0212 23:00:42.020656  3050 net.cpp:561] mbox_priorbox <- ctx_output5/relu_mbox_priorbox
I0212 23:00:42.020661  3050 net.cpp:561] mbox_priorbox <- ctx_output6/relu_mbox_priorbox
I0212 23:00:42.020666  3050 net.cpp:530] mbox_priorbox -> mbox_priorbox
I0212 23:00:42.020709  3050 net.cpp:245] Setting up mbox_priorbox
I0212 23:00:42.020720  3050 net.cpp:252] TRAIN Top shape for layer 108 'mbox_priorbox' 1 2 75152 (150304)
I0212 23:00:42.020725  3050 layer_factory.hpp:136] Creating layer 'mbox_loss' of type 'MultiBoxLoss'
I0212 23:00:42.020731  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.020750  3050 net.cpp:184] Created Layer mbox_loss (109)
I0212 23:00:42.020756  3050 net.cpp:561] mbox_loss <- mbox_loc
I0212 23:00:42.020762  3050 net.cpp:561] mbox_loss <- mbox_conf
I0212 23:00:42.020768  3050 net.cpp:561] mbox_loss <- mbox_priorbox
I0212 23:00:42.020773  3050 net.cpp:561] mbox_loss <- label
I0212 23:00:42.020779  3050 net.cpp:530] mbox_loss -> mbox_loss
I0212 23:00:42.020879  3050 layer_factory.hpp:136] Creating layer 'mbox_loss_smooth_L1_loc' of type 'SmoothL1Loss'
I0212 23:00:42.020889  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.021095  3050 layer_factory.hpp:136] Creating layer 'mbox_loss_softmax_conf' of type 'SoftmaxWithLoss'
I0212 23:00:42.021113  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.021385  3050 net.cpp:245] Setting up mbox_loss
I0212 23:00:42.021399  3050 net.cpp:252] TRAIN Top shape for layer 109 'mbox_loss' (1)
I0212 23:00:42.021404  3050 net.cpp:256]     with loss weight 1
I0212 23:00:42.021420  3050 net.cpp:323] mbox_loss needs backward computation.
I0212 23:00:42.021425  3050 net.cpp:325] mbox_priorbox does not need backward computation.
I0212 23:00:42.021432  3050 net.cpp:323] mbox_conf needs backward computation.
I0212 23:00:42.021437  3050 net.cpp:323] mbox_loc needs backward computation.
I0212 23:00:42.021443  3050 net.cpp:325] ctx_output6/relu_mbox_priorbox does not need backward computation.
I0212 23:00:42.021448  3050 net.cpp:323] ctx_output6/relu_mbox_conf_flat needs backward computation.
I0212 23:00:42.021453  3050 net.cpp:323] ctx_output6/relu_mbox_conf_perm needs backward computation.
I0212 23:00:42.021459  3050 net.cpp:323] ctx_output6/relu_mbox_conf needs backward computation.
I0212 23:00:42.021464  3050 net.cpp:323] ctx_output6/relu_mbox_loc_flat needs backward computation.
I0212 23:00:42.021469  3050 net.cpp:323] ctx_output6/relu_mbox_loc_perm needs backward computation.
I0212 23:00:42.021474  3050 net.cpp:323] ctx_output6/relu_mbox_loc needs backward computation.
I0212 23:00:42.021478  3050 net.cpp:325] ctx_output5/relu_mbox_priorbox does not need backward computation.
I0212 23:00:42.021483  3050 net.cpp:323] ctx_output5/relu_mbox_conf_flat needs backward computation.
I0212 23:00:42.021488  3050 net.cpp:323] ctx_output5/relu_mbox_conf_perm needs backward computation.
I0212 23:00:42.021493  3050 net.cpp:323] ctx_output5/relu_mbox_conf needs backward computation.
I0212 23:00:42.021498  3050 net.cpp:323] ctx_output5/relu_mbox_loc_flat needs backward computation.
I0212 23:00:42.021502  3050 net.cpp:323] ctx_output5/relu_mbox_loc_perm needs backward computation.
I0212 23:00:42.021507  3050 net.cpp:323] ctx_output5/relu_mbox_loc needs backward computation.
I0212 23:00:42.021512  3050 net.cpp:325] ctx_output4/relu_mbox_priorbox does not need backward computation.
I0212 23:00:42.021517  3050 net.cpp:323] ctx_output4/relu_mbox_conf_flat needs backward computation.
I0212 23:00:42.021522  3050 net.cpp:323] ctx_output4/relu_mbox_conf_perm needs backward computation.
I0212 23:00:42.021526  3050 net.cpp:323] ctx_output4/relu_mbox_conf needs backward computation.
I0212 23:00:42.021531  3050 net.cpp:323] ctx_output4/relu_mbox_loc_flat needs backward computation.
I0212 23:00:42.021536  3050 net.cpp:323] ctx_output4/relu_mbox_loc_perm needs backward computation.
I0212 23:00:42.021540  3050 net.cpp:323] ctx_output4/relu_mbox_loc needs backward computation.
I0212 23:00:42.021545  3050 net.cpp:325] ctx_output3/relu_mbox_priorbox does not need backward computation.
I0212 23:00:42.021550  3050 net.cpp:323] ctx_output3/relu_mbox_conf_flat needs backward computation.
I0212 23:00:42.021555  3050 net.cpp:323] ctx_output3/relu_mbox_conf_perm needs backward computation.
I0212 23:00:42.021559  3050 net.cpp:323] ctx_output3/relu_mbox_conf needs backward computation.
I0212 23:00:42.021564  3050 net.cpp:323] ctx_output3/relu_mbox_loc_flat needs backward computation.
I0212 23:00:42.021569  3050 net.cpp:323] ctx_output3/relu_mbox_loc_perm needs backward computation.
I0212 23:00:42.021574  3050 net.cpp:323] ctx_output3/relu_mbox_loc needs backward computation.
I0212 23:00:42.021579  3050 net.cpp:325] ctx_output2/relu_mbox_priorbox does not need backward computation.
I0212 23:00:42.021584  3050 net.cpp:323] ctx_output2/relu_mbox_conf_flat needs backward computation.
I0212 23:00:42.021589  3050 net.cpp:323] ctx_output2/relu_mbox_conf_perm needs backward computation.
I0212 23:00:42.021594  3050 net.cpp:323] ctx_output2/relu_mbox_conf needs backward computation.
I0212 23:00:42.021597  3050 net.cpp:323] ctx_output2/relu_mbox_loc_flat needs backward computation.
I0212 23:00:42.021601  3050 net.cpp:323] ctx_output2/relu_mbox_loc_perm needs backward computation.
I0212 23:00:42.021606  3050 net.cpp:323] ctx_output2/relu_mbox_loc needs backward computation.
I0212 23:00:42.021620  3050 net.cpp:325] ctx_output1/relu_mbox_priorbox does not need backward computation.
I0212 23:00:42.021626  3050 net.cpp:323] ctx_output1/relu_mbox_conf_flat needs backward computation.
I0212 23:00:42.021631  3050 net.cpp:323] ctx_output1/relu_mbox_conf_perm needs backward computation.
I0212 23:00:42.021636  3050 net.cpp:323] ctx_output1/relu_mbox_conf needs backward computation.
I0212 23:00:42.021641  3050 net.cpp:323] ctx_output1/relu_mbox_loc_flat needs backward computation.
I0212 23:00:42.021646  3050 net.cpp:323] ctx_output1/relu_mbox_loc_perm needs backward computation.
I0212 23:00:42.021651  3050 net.cpp:323] ctx_output1/relu_mbox_loc needs backward computation.
I0212 23:00:42.021656  3050 net.cpp:323] ctx_output6_ctx_output6/relu_0_split needs backward computation.
I0212 23:00:42.021661  3050 net.cpp:323] ctx_output6/relu needs backward computation.
I0212 23:00:42.021666  3050 net.cpp:323] ctx_output6 needs backward computation.
I0212 23:00:42.021670  3050 net.cpp:323] ctx_output5_ctx_output5/relu_0_split needs backward computation.
I0212 23:00:42.021674  3050 net.cpp:323] ctx_output5/relu needs backward computation.
I0212 23:00:42.021679  3050 net.cpp:323] ctx_output5 needs backward computation.
I0212 23:00:42.021684  3050 net.cpp:323] ctx_output4_ctx_output4/relu_0_split needs backward computation.
I0212 23:00:42.021688  3050 net.cpp:323] ctx_output4/relu needs backward computation.
I0212 23:00:42.021693  3050 net.cpp:323] ctx_output4 needs backward computation.
I0212 23:00:42.021698  3050 net.cpp:323] ctx_output3_ctx_output3/relu_0_split needs backward computation.
I0212 23:00:42.021703  3050 net.cpp:323] ctx_output3/relu needs backward computation.
I0212 23:00:42.021708  3050 net.cpp:323] ctx_output3 needs backward computation.
I0212 23:00:42.021713  3050 net.cpp:323] ctx_output2_ctx_output2/relu_0_split needs backward computation.
I0212 23:00:42.021718  3050 net.cpp:323] ctx_output2/relu needs backward computation.
I0212 23:00:42.021721  3050 net.cpp:323] ctx_output2 needs backward computation.
I0212 23:00:42.021726  3050 net.cpp:323] ctx_output1_ctx_output1/relu_0_split needs backward computation.
I0212 23:00:42.021731  3050 net.cpp:323] ctx_output1/relu needs backward computation.
I0212 23:00:42.021735  3050 net.cpp:323] ctx_output1 needs backward computation.
I0212 23:00:42.021740  3050 net.cpp:323] pool9 needs backward computation.
I0212 23:00:42.021745  3050 net.cpp:323] pool8_pool8_0_split needs backward computation.
I0212 23:00:42.021750  3050 net.cpp:323] pool8 needs backward computation.
I0212 23:00:42.021755  3050 net.cpp:323] pool7_pool7_0_split needs backward computation.
I0212 23:00:42.021759  3050 net.cpp:323] pool7 needs backward computation.
I0212 23:00:42.021764  3050 net.cpp:323] pool6_pool6_0_split needs backward computation.
I0212 23:00:42.021770  3050 net.cpp:323] pool6 needs backward computation.
I0212 23:00:42.021775  3050 net.cpp:323] res5a_branch2b_res5a_branch2b/relu_0_split needs backward computation.
I0212 23:00:42.021780  3050 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0212 23:00:42.021783  3050 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0212 23:00:42.021788  3050 net.cpp:323] res5a_branch2b needs backward computation.
I0212 23:00:42.021793  3050 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0212 23:00:42.021798  3050 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0212 23:00:42.021802  3050 net.cpp:323] res5a_branch2a needs backward computation.
I0212 23:00:42.021807  3050 net.cpp:323] pool4 needs backward computation.
I0212 23:00:42.021811  3050 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0212 23:00:42.021816  3050 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0212 23:00:42.021821  3050 net.cpp:323] res4a_branch2b needs backward computation.
I0212 23:00:42.021826  3050 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0212 23:00:42.021831  3050 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0212 23:00:42.021842  3050 net.cpp:323] res4a_branch2a needs backward computation.
I0212 23:00:42.021847  3050 net.cpp:323] pool3 needs backward computation.
I0212 23:00:42.021852  3050 net.cpp:323] res3a_branch2b_res3a_branch2b/relu_0_split needs backward computation.
I0212 23:00:42.021857  3050 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0212 23:00:42.021862  3050 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0212 23:00:42.021865  3050 net.cpp:323] res3a_branch2b needs backward computation.
I0212 23:00:42.021870  3050 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0212 23:00:42.021875  3050 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0212 23:00:42.021879  3050 net.cpp:323] res3a_branch2a needs backward computation.
I0212 23:00:42.021884  3050 net.cpp:323] pool2 needs backward computation.
I0212 23:00:42.021889  3050 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0212 23:00:42.021893  3050 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0212 23:00:42.021898  3050 net.cpp:323] res2a_branch2b needs backward computation.
I0212 23:00:42.021903  3050 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0212 23:00:42.021908  3050 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0212 23:00:42.021911  3050 net.cpp:323] res2a_branch2a needs backward computation.
I0212 23:00:42.021916  3050 net.cpp:323] pool1 needs backward computation.
I0212 23:00:42.021921  3050 net.cpp:323] conv1b/relu needs backward computation.
I0212 23:00:42.021925  3050 net.cpp:323] conv1b/bn needs backward computation.
I0212 23:00:42.021930  3050 net.cpp:323] conv1b needs backward computation.
I0212 23:00:42.021934  3050 net.cpp:323] conv1a/relu needs backward computation.
I0212 23:00:42.021939  3050 net.cpp:323] conv1a/bn needs backward computation.
I0212 23:00:42.021944  3050 net.cpp:323] conv1a needs backward computation.
I0212 23:00:42.021948  3050 net.cpp:325] data/bias does not need backward computation.
I0212 23:00:42.021955  3050 net.cpp:325] data_data_0_split does not need backward computation.
I0212 23:00:42.021960  3050 net.cpp:325] data does not need backward computation.
I0212 23:00:42.021963  3050 net.cpp:367] This network produces output mbox_loss
I0212 23:00:42.022060  3050 net.cpp:389] Top memory (TRAIN) required for data: 1304123976 diff: 1304123976
I0212 23:00:42.022068  3050 net.cpp:392] Bottom memory (TRAIN) required for data: 1304123968 diff: 1304123968
I0212 23:00:42.022073  3050 net.cpp:395] Shared (in-place) memory (TRAIN) by data: 563789824 diff: 563789824
I0212 23:00:42.022076  3050 net.cpp:398] Parameters memory (TRAIN) required for data: 12464288 diff: 12464288
I0212 23:00:42.022080  3050 net.cpp:401] Parameters shared memory (TRAIN) by data: 0 diff: 0
I0212 23:00:42.022084  3050 net.cpp:407] Network initialization done.
I0212 23:00:42.037526  3050 solver.cpp:177] Creating test net (#0) specified by test_net file: training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/test.prototxt
I0212 23:00:42.038458  3050 net.cpp:72] Initializing net from parameters: 
name: "ssdJacintoNetV2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_value: 0
    mean_value: 0
    mean_value: 0
    force_color: false
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 368
      width: 720
      interp_mode: LINEAR
    }
    crop_h: 368
    crop_w: 720
  }
  data_param {
    source: "/user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_test_lmdb"
    batch_size: 4
    backend: LMDB
    threads: 4
    parser_threads: 4
  }
  annotated_data_param {
    batch_sampler {
    }
    label_map_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/labelmap.prototxt"
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "pool6"
  top: "pool7"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool8"
  type: "Pooling"
  bottom: "pool7"
  top: "pool8"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool9"
  type: "Pooling"
  bottom: "pool8"
  top: "pool9"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "ctx_output1"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "ctx_output1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu"
  type: "ReLU"
  bottom: "ctx_output1"
  top: "ctx_output1"
}
layer {
  name: "ctx_output2"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "ctx_output2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu"
  type: "ReLU"
  bottom: "ctx_output2"
  top: "ctx_output2"
}
layer {
  name: "ctx_output3"
  type: "Convolution"
  bottom: "pool6"
  top: "ctx_output3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu"
  type: "ReLU"
  bottom: "ctx_output3"
  top: "ctx_output3"
}
layer {
  name: "ctx_output4"
  type: "Convolution"
  bottom: "pool7"
  top: "ctx_output4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu"
  type: "ReLU"
  bottom: "ctx_output4"
  top: "ctx_output4"
}
layer {
  name: "ctx_output5"
  type: "Convolution"
  bottom: "pool8"
  top: "ctx_output5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu"
  type: "ReLU"
  bottom: "ctx_output5"
  top: "ctx_output5"
}
layer {
  name: "ctx_output6"
  type: "Convolution"
  bottom: "pool9"
  top: "ctx_output6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu"
  type: "ReLU"
  bottom: "ctx_output6"
  top: "ctx_output6"
}
layer {
  name: "ctx_output1/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_loc"
  top: "ctx_output1/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_loc_perm"
  top: "ctx_output1/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_conf"
  top: "ctx_output1/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_conf_perm"
  top: "ctx_output1/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output1"
  bottom: "data"
  top: "ctx_output1/relu_mbox_priorbox"
  prior_box_param {
    min_size: 14.72
    max_size: 36.8
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_loc"
  top: "ctx_output2/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_loc_perm"
  top: "ctx_output2/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_conf"
  top: "ctx_output2/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_conf_perm"
  top: "ctx_output2/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output2"
  bottom: "data"
  top: "ctx_output2/relu_mbox_priorbox"
  prior_box_param {
    min_size: 36.8
    max_size: 110.4
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_loc"
  top: "ctx_output3/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_loc_perm"
  top: "ctx_output3/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_conf"
  top: "ctx_output3/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_conf_perm"
  top: "ctx_output3/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output3"
  bottom: "data"
  top: "ctx_output3/relu_mbox_priorbox"
  prior_box_param {
    min_size: 110.4
    max_size: 184
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_loc"
  top: "ctx_output4/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_loc_perm"
  top: "ctx_output4/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_conf"
  top: "ctx_output4/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_conf_perm"
  top: "ctx_output4/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output4"
  bottom: "data"
  top: "ctx_output4/relu_mbox_priorbox"
  prior_box_param {
    min_size: 184
    max_size: 257.6
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_loc"
  top: "ctx_output5/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_loc_perm"
  top: "ctx_output5/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_conf"
  top: "ctx_output5/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_conf_perm"
  top: "ctx_output5/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output5"
  bottom: "data"
  top: "ctx_output5/relu_mbox_priorbox"
  prior_box_param {
    min_size: 257.6
    max_size: 331.2
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_loc"
  top: "ctx_output6/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_loc_perm"
  top: "ctx_output6/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_conf"
  top: "ctx_output6/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_conf_perm"
  top: "ctx_output6/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output6"
  bottom: "data"
  top: "ctx_output6/relu_mbox_priorbox"
  prior_box_param {
    min_size: 331.2
    max_size: 404.8
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_loc_flat"
  bottom: "ctx_output2/relu_mbox_loc_flat"
  bottom: "ctx_output3/relu_mbox_loc_flat"
  bottom: "ctx_output4/relu_mbox_loc_flat"
  bottom: "ctx_output5/relu_mbox_loc_flat"
  bottom: "ctx_output6/relu_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_conf_flat"
  bottom: "ctx_output2/relu_mbox_conf_flat"
  bottom: "ctx_output3/relu_mbox_conf_flat"
  bottom: "ctx_output4/relu_mbox_conf_flat"
  bottom: "ctx_output5/relu_mbox_conf_flat"
  bottom: "ctx_output6/relu_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_priorbox"
  bottom: "ctx_output2/relu_mbox_priorbox"
  bottom: "ctx_output3/relu_mbox_priorbox"
  bottom: "ctx_output4/relu_mbox_priorbox"
  bottom: "ctx_output5/relu_mbox_priorbox"
  bottom: "ctx_output6/relu_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_reshape"
  type: "Reshape"
  bottom: "mbox_conf"
  top: "mbox_conf_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: -1
      dim: 4
    }
  }
}
layer {
  name: "mbox_conf_softmax"
  type: "Softmax"
  bottom: "mbox_conf_reshape"
  top: "mbox_conf_softmax"
  softmax_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_flatten"
  type: "Flatten"
  bottom: "mbox_conf_softmax"
  top: "mbox_conf_flatten"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "detection_out"
  type: "DetectionOutput"
  bottom: "mbox_loc"
  bottom: "mbox_conf_flatten"
  bottom: "mbox_priorbox"
  top: "detection_out"
  include {
    phase: TEST
  }
  detection_output_param {
    num_classes: 4
    share_location: true
    background_label_id: 0
    nms_param {
      nms_threshold: 0.45
      top_k: 400
    }
    save_output_param {
      output_directory: ""
      output_name_prefix: "comp4_det_test_"
      output_format: "VOC"
      label_map_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/labelmap.prototxt"
      name_size_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/test_name_size.txt"
      num_test_image: 3609
    }
    code_type: CENTER_SIZE
    keep_top_k: 200
    confidence_threshold: 0.01
  }
}
layer {
  name: "detection_eval"
  type: "DetectionEvaluate"
  bottom: "detection_out"
  bottom: "label"
  top: "detection_eval"
  include {
    phase: TEST
  }
  detection_evaluate_param {
    num_classes: 4
    background_label_id: 0
    overlap_threshold: 0.5
    evaluate_difficult_gt: false
    name_size_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/test_name_size.txt"
  }
}
I0212 23:00:42.039036  3050 net.cpp:104] Using FLOAT as default forward math type
I0212 23:00:42.039048  3050 net.cpp:110] Using FLOAT as default backward math type
I0212 23:00:42.039054  3050 layer_factory.hpp:136] Creating layer 'data' of type 'AnnotatedData'
I0212 23:00:42.039062  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.039091  3050 net.cpp:184] Created Layer data (0)
I0212 23:00:42.039098  3050 net.cpp:530] data -> data
I0212 23:00:42.039108  3050 net.cpp:530] data -> label
I0212 23:00:42.039124  3050 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 4
I0212 23:00:42.039134  3050 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0212 23:00:42.040369  3113 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_test_lmdb
I0212 23:00:42.050715  3050 annotated_data_layer.cpp:219] output data size: 4,3,368,720
I0212 23:00:42.050797  3050 annotated_data_layer.cpp:265] (0) Output data size: 4, 3, 368, 720
I0212 23:00:42.050858  3050 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0212 23:00:42.052184  3050 net.cpp:245] Setting up data
I0212 23:00:42.052201  3050 net.cpp:252] TEST Top shape for layer 0 'data' 4 3 368 720 (3179520)
I0212 23:00:42.052208  3050 net.cpp:252] TEST Top shape for layer 0 'data' 1 1 31 8 (248)
I0212 23:00:42.052217  3050 layer_factory.hpp:136] Creating layer 'data_data_0_split' of type 'Split'
I0212 23:00:42.052224  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.052237  3050 net.cpp:184] Created Layer data_data_0_split (1)
I0212 23:00:42.052243  3050 net.cpp:561] data_data_0_split <- data
I0212 23:00:42.052251  3050 net.cpp:530] data_data_0_split -> data_data_0_split_0
I0212 23:00:42.052260  3050 net.cpp:530] data_data_0_split -> data_data_0_split_1
I0212 23:00:42.052266  3050 net.cpp:530] data_data_0_split -> data_data_0_split_2
I0212 23:00:42.052273  3050 net.cpp:530] data_data_0_split -> data_data_0_split_3
I0212 23:00:42.052279  3050 net.cpp:530] data_data_0_split -> data_data_0_split_4
I0212 23:00:42.052286  3050 net.cpp:530] data_data_0_split -> data_data_0_split_5
I0212 23:00:42.052292  3050 net.cpp:530] data_data_0_split -> data_data_0_split_6
I0212 23:00:42.052477  3050 net.cpp:245] Setting up data_data_0_split
I0212 23:00:42.052489  3050 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 368 720 (3179520)
I0212 23:00:42.052496  3050 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 368 720 (3179520)
I0212 23:00:42.052502  3050 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 368 720 (3179520)
I0212 23:00:42.052510  3050 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 368 720 (3179520)
I0212 23:00:42.052515  3050 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 368 720 (3179520)
I0212 23:00:42.052521  3050 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 368 720 (3179520)
I0212 23:00:42.052527  3050 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 368 720 (3179520)
I0212 23:00:42.052533  3050 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0212 23:00:42.052539  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.052551  3050 net.cpp:184] Created Layer data/bias (2)
I0212 23:00:42.052556  3050 net.cpp:561] data/bias <- data_data_0_split_0
I0212 23:00:42.052561  3050 net.cpp:530] data/bias -> data/bias
I0212 23:00:42.053723  3114 annotated_data_layer.cpp:111] (0) Parser threads: 1
I0212 23:00:42.053738  3114 annotated_data_layer.cpp:113] (0) Transformer threads: 1
I0212 23:00:42.054718  3050 net.cpp:245] Setting up data/bias
I0212 23:00:42.054733  3050 net.cpp:252] TEST Top shape for layer 2 'data/bias' 4 3 368 720 (3179520)
I0212 23:00:42.054745  3050 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0212 23:00:42.054752  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.054769  3050 net.cpp:184] Created Layer conv1a (3)
I0212 23:00:42.054774  3050 net.cpp:561] conv1a <- data/bias
I0212 23:00:42.054782  3050 net.cpp:530] conv1a -> conv1a
I0212 23:00:42.055389  3050 net.cpp:245] Setting up conv1a
I0212 23:00:42.055403  3050 net.cpp:252] TEST Top shape for layer 3 'conv1a' 4 32 184 360 (8478720)
I0212 23:00:42.055414  3050 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0212 23:00:42.055421  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.055433  3050 net.cpp:184] Created Layer conv1a/bn (4)
I0212 23:00:42.055439  3050 net.cpp:561] conv1a/bn <- conv1a
I0212 23:00:42.055445  3050 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0212 23:00:42.056417  3050 net.cpp:245] Setting up conv1a/bn
I0212 23:00:42.056430  3050 net.cpp:252] TEST Top shape for layer 4 'conv1a/bn' 4 32 184 360 (8478720)
I0212 23:00:42.056445  3050 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0212 23:00:42.056452  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.056473  3050 net.cpp:184] Created Layer conv1a/relu (5)
I0212 23:00:42.056480  3050 net.cpp:561] conv1a/relu <- conv1a
I0212 23:00:42.056486  3050 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0212 23:00:42.056494  3050 net.cpp:245] Setting up conv1a/relu
I0212 23:00:42.056501  3050 net.cpp:252] TEST Top shape for layer 5 'conv1a/relu' 4 32 184 360 (8478720)
I0212 23:00:42.056507  3050 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0212 23:00:42.056512  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.056525  3050 net.cpp:184] Created Layer conv1b (6)
I0212 23:00:42.056530  3050 net.cpp:561] conv1b <- conv1a
I0212 23:00:42.056536  3050 net.cpp:530] conv1b -> conv1b
I0212 23:00:42.057658  3050 net.cpp:245] Setting up conv1b
I0212 23:00:42.057673  3050 net.cpp:252] TEST Top shape for layer 6 'conv1b' 4 32 184 360 (8478720)
I0212 23:00:42.057684  3050 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0212 23:00:42.057690  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.057700  3050 net.cpp:184] Created Layer conv1b/bn (7)
I0212 23:00:42.057706  3050 net.cpp:561] conv1b/bn <- conv1b
I0212 23:00:42.057713  3050 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0212 23:00:42.058725  3050 net.cpp:245] Setting up conv1b/bn
I0212 23:00:42.058740  3050 net.cpp:252] TEST Top shape for layer 7 'conv1b/bn' 4 32 184 360 (8478720)
I0212 23:00:42.058755  3050 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0212 23:00:42.058763  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.058771  3050 net.cpp:184] Created Layer conv1b/relu (8)
I0212 23:00:42.058779  3050 net.cpp:561] conv1b/relu <- conv1b
I0212 23:00:42.058784  3050 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0212 23:00:42.058794  3050 net.cpp:245] Setting up conv1b/relu
I0212 23:00:42.058800  3050 net.cpp:252] TEST Top shape for layer 8 'conv1b/relu' 4 32 184 360 (8478720)
I0212 23:00:42.058807  3050 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0212 23:00:42.058814  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.058823  3050 net.cpp:184] Created Layer pool1 (9)
I0212 23:00:42.058830  3050 net.cpp:561] pool1 <- conv1b
I0212 23:00:42.058835  3050 net.cpp:530] pool1 -> pool1
I0212 23:00:42.058943  3050 net.cpp:245] Setting up pool1
I0212 23:00:42.058955  3050 net.cpp:252] TEST Top shape for layer 9 'pool1' 4 32 92 180 (2119680)
I0212 23:00:42.058962  3050 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0212 23:00:42.058969  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.058984  3050 net.cpp:184] Created Layer res2a_branch2a (10)
I0212 23:00:42.058990  3050 net.cpp:561] res2a_branch2a <- pool1
I0212 23:00:42.058997  3050 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0212 23:00:42.060281  3050 net.cpp:245] Setting up res2a_branch2a
I0212 23:00:42.060297  3050 net.cpp:252] TEST Top shape for layer 10 'res2a_branch2a' 4 64 92 180 (4239360)
I0212 23:00:42.060314  3050 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0212 23:00:42.060323  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.060338  3050 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0212 23:00:42.060345  3050 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0212 23:00:42.060353  3050 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0212 23:00:42.061763  3050 net.cpp:245] Setting up res2a_branch2a/bn
I0212 23:00:42.061789  3050 net.cpp:252] TEST Top shape for layer 11 'res2a_branch2a/bn' 4 64 92 180 (4239360)
I0212 23:00:42.061806  3050 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0212 23:00:42.061813  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.061843  3050 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0212 23:00:42.061851  3050 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0212 23:00:42.061857  3050 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0212 23:00:42.061866  3050 net.cpp:245] Setting up res2a_branch2a/relu
I0212 23:00:42.061873  3050 net.cpp:252] TEST Top shape for layer 12 'res2a_branch2a/relu' 4 64 92 180 (4239360)
I0212 23:00:42.061879  3050 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0212 23:00:42.061884  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.061900  3050 net.cpp:184] Created Layer res2a_branch2b (13)
I0212 23:00:42.061906  3050 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0212 23:00:42.061911  3050 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0212 23:00:42.062755  3050 net.cpp:245] Setting up res2a_branch2b
I0212 23:00:42.062769  3050 net.cpp:252] TEST Top shape for layer 13 'res2a_branch2b' 4 64 92 180 (4239360)
I0212 23:00:42.062779  3050 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0212 23:00:42.062785  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.062795  3050 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0212 23:00:42.062801  3050 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0212 23:00:42.062808  3050 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0212 23:00:42.063772  3050 net.cpp:245] Setting up res2a_branch2b/bn
I0212 23:00:42.063786  3050 net.cpp:252] TEST Top shape for layer 14 'res2a_branch2b/bn' 4 64 92 180 (4239360)
I0212 23:00:42.063798  3050 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0212 23:00:42.063804  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.063812  3050 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0212 23:00:42.063817  3050 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0212 23:00:42.063823  3050 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0212 23:00:42.063832  3050 net.cpp:245] Setting up res2a_branch2b/relu
I0212 23:00:42.063838  3050 net.cpp:252] TEST Top shape for layer 15 'res2a_branch2b/relu' 4 64 92 180 (4239360)
I0212 23:00:42.063843  3050 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0212 23:00:42.063848  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.063859  3050 net.cpp:184] Created Layer pool2 (16)
I0212 23:00:42.063864  3050 net.cpp:561] pool2 <- res2a_branch2b
I0212 23:00:42.063869  3050 net.cpp:530] pool2 -> pool2
I0212 23:00:42.063966  3050 net.cpp:245] Setting up pool2
I0212 23:00:42.063977  3050 net.cpp:252] TEST Top shape for layer 16 'pool2' 4 64 46 90 (1059840)
I0212 23:00:42.063983  3050 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0212 23:00:42.063992  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.064005  3050 net.cpp:184] Created Layer res3a_branch2a (17)
I0212 23:00:42.064011  3050 net.cpp:561] res3a_branch2a <- pool2
I0212 23:00:42.064018  3050 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0212 23:00:42.067073  3050 net.cpp:245] Setting up res3a_branch2a
I0212 23:00:42.067090  3050 net.cpp:252] TEST Top shape for layer 17 'res3a_branch2a' 4 128 46 90 (2119680)
I0212 23:00:42.067100  3050 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0212 23:00:42.067106  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.067116  3050 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0212 23:00:42.067121  3050 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0212 23:00:42.067127  3050 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0212 23:00:42.068099  3050 net.cpp:245] Setting up res3a_branch2a/bn
I0212 23:00:42.068148  3050 net.cpp:252] TEST Top shape for layer 18 'res3a_branch2a/bn' 4 128 46 90 (2119680)
I0212 23:00:42.068171  3050 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0212 23:00:42.068177  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.068187  3050 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0212 23:00:42.068194  3050 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0212 23:00:42.068202  3050 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0212 23:00:42.068210  3050 net.cpp:245] Setting up res3a_branch2a/relu
I0212 23:00:42.068217  3050 net.cpp:252] TEST Top shape for layer 19 'res3a_branch2a/relu' 4 128 46 90 (2119680)
I0212 23:00:42.068222  3050 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0212 23:00:42.068228  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.068244  3050 net.cpp:184] Created Layer res3a_branch2b (20)
I0212 23:00:42.068249  3050 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0212 23:00:42.068255  3050 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0212 23:00:42.070044  3050 net.cpp:245] Setting up res3a_branch2b
I0212 23:00:42.070057  3050 net.cpp:252] TEST Top shape for layer 20 'res3a_branch2b' 4 128 46 90 (2119680)
I0212 23:00:42.070067  3050 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0212 23:00:42.070073  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.070085  3050 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0212 23:00:42.070091  3050 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0212 23:00:42.070096  3050 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0212 23:00:42.071087  3050 net.cpp:245] Setting up res3a_branch2b/bn
I0212 23:00:42.071100  3050 net.cpp:252] TEST Top shape for layer 21 'res3a_branch2b/bn' 4 128 46 90 (2119680)
I0212 23:00:42.071115  3050 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0212 23:00:42.071120  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.071127  3050 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0212 23:00:42.071132  3050 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0212 23:00:42.071138  3050 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0212 23:00:42.071146  3050 net.cpp:245] Setting up res3a_branch2b/relu
I0212 23:00:42.071152  3050 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b/relu' 4 128 46 90 (2119680)
I0212 23:00:42.071158  3050 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0212 23:00:42.071163  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.071171  3050 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (23)
I0212 23:00:42.071177  3050 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0212 23:00:42.071182  3050 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0212 23:00:42.071188  3050 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0212 23:00:42.071259  3050 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0212 23:00:42.071269  3050 net.cpp:252] TEST Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 4 128 46 90 (2119680)
I0212 23:00:42.071276  3050 net.cpp:252] TEST Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 4 128 46 90 (2119680)
I0212 23:00:42.071282  3050 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0212 23:00:42.071288  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.071297  3050 net.cpp:184] Created Layer pool3 (24)
I0212 23:00:42.071303  3050 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0212 23:00:42.071319  3050 net.cpp:530] pool3 -> pool3
I0212 23:00:42.071416  3050 net.cpp:245] Setting up pool3
I0212 23:00:42.071427  3050 net.cpp:252] TEST Top shape for layer 24 'pool3' 4 128 23 45 (529920)
I0212 23:00:42.071434  3050 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0212 23:00:42.071439  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.071451  3050 net.cpp:184] Created Layer res4a_branch2a (25)
I0212 23:00:42.071457  3050 net.cpp:561] res4a_branch2a <- pool3
I0212 23:00:42.071463  3050 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0212 23:00:42.083434  3050 net.cpp:245] Setting up res4a_branch2a
I0212 23:00:42.083465  3050 net.cpp:252] TEST Top shape for layer 25 'res4a_branch2a' 4 256 23 45 (1059840)
I0212 23:00:42.083477  3050 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0212 23:00:42.083485  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.083499  3050 net.cpp:184] Created Layer res4a_branch2a/bn (26)
I0212 23:00:42.083506  3050 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0212 23:00:42.083514  3050 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0212 23:00:42.084516  3050 net.cpp:245] Setting up res4a_branch2a/bn
I0212 23:00:42.084528  3050 net.cpp:252] TEST Top shape for layer 26 'res4a_branch2a/bn' 4 256 23 45 (1059840)
I0212 23:00:42.084543  3050 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0212 23:00:42.084550  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.084558  3050 net.cpp:184] Created Layer res4a_branch2a/relu (27)
I0212 23:00:42.084563  3050 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0212 23:00:42.084569  3050 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0212 23:00:42.084579  3050 net.cpp:245] Setting up res4a_branch2a/relu
I0212 23:00:42.084586  3050 net.cpp:252] TEST Top shape for layer 27 'res4a_branch2a/relu' 4 256 23 45 (1059840)
I0212 23:00:42.084591  3050 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0212 23:00:42.084597  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.084614  3050 net.cpp:184] Created Layer res4a_branch2b (28)
I0212 23:00:42.084619  3050 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0212 23:00:42.084625  3050 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0212 23:00:42.090281  3050 net.cpp:245] Setting up res4a_branch2b
I0212 23:00:42.090297  3050 net.cpp:252] TEST Top shape for layer 28 'res4a_branch2b' 4 256 23 45 (1059840)
I0212 23:00:42.090307  3050 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0212 23:00:42.090314  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.090327  3050 net.cpp:184] Created Layer res4a_branch2b/bn (29)
I0212 23:00:42.090333  3050 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0212 23:00:42.090340  3050 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0212 23:00:42.091516  3050 net.cpp:245] Setting up res4a_branch2b/bn
I0212 23:00:42.091542  3050 net.cpp:252] TEST Top shape for layer 29 'res4a_branch2b/bn' 4 256 23 45 (1059840)
I0212 23:00:42.091564  3050 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0212 23:00:42.091574  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.091590  3050 net.cpp:184] Created Layer res4a_branch2b/relu (30)
I0212 23:00:42.091599  3050 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0212 23:00:42.091609  3050 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0212 23:00:42.091622  3050 net.cpp:245] Setting up res4a_branch2b/relu
I0212 23:00:42.091632  3050 net.cpp:252] TEST Top shape for layer 30 'res4a_branch2b/relu' 4 256 23 45 (1059840)
I0212 23:00:42.091667  3050 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0212 23:00:42.091677  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.091694  3050 net.cpp:184] Created Layer pool4 (31)
I0212 23:00:42.091701  3050 net.cpp:561] pool4 <- res4a_branch2b
I0212 23:00:42.091711  3050 net.cpp:530] pool4 -> pool4
I0212 23:00:42.091881  3050 net.cpp:245] Setting up pool4
I0212 23:00:42.091897  3050 net.cpp:252] TEST Top shape for layer 31 'pool4' 4 256 12 23 (282624)
I0212 23:00:42.091907  3050 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0212 23:00:42.091917  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.091948  3050 net.cpp:184] Created Layer res5a_branch2a (32)
I0212 23:00:42.091956  3050 net.cpp:561] res5a_branch2a <- pool4
I0212 23:00:42.091966  3050 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0212 23:00:42.136296  3050 net.cpp:245] Setting up res5a_branch2a
I0212 23:00:42.136329  3050 net.cpp:252] TEST Top shape for layer 32 'res5a_branch2a' 4 512 12 23 (565248)
I0212 23:00:42.136343  3050 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0212 23:00:42.136350  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.136366  3050 net.cpp:184] Created Layer res5a_branch2a/bn (33)
I0212 23:00:42.136374  3050 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0212 23:00:42.136382  3050 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0212 23:00:42.137388  3050 net.cpp:245] Setting up res5a_branch2a/bn
I0212 23:00:42.137403  3050 net.cpp:252] TEST Top shape for layer 33 'res5a_branch2a/bn' 4 512 12 23 (565248)
I0212 23:00:42.137415  3050 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0212 23:00:42.137423  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.137432  3050 net.cpp:184] Created Layer res5a_branch2a/relu (34)
I0212 23:00:42.137437  3050 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0212 23:00:42.137444  3050 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0212 23:00:42.137452  3050 net.cpp:245] Setting up res5a_branch2a/relu
I0212 23:00:42.137460  3050 net.cpp:252] TEST Top shape for layer 34 'res5a_branch2a/relu' 4 512 12 23 (565248)
I0212 23:00:42.137466  3050 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0212 23:00:42.137471  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.137488  3050 net.cpp:184] Created Layer res5a_branch2b (35)
I0212 23:00:42.137495  3050 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0212 23:00:42.137500  3050 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0212 23:00:42.160006  3050 net.cpp:245] Setting up res5a_branch2b
I0212 23:00:42.160039  3050 net.cpp:252] TEST Top shape for layer 35 'res5a_branch2b' 4 512 12 23 (565248)
I0212 23:00:42.160061  3050 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0212 23:00:42.160069  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.160086  3050 net.cpp:184] Created Layer res5a_branch2b/bn (36)
I0212 23:00:42.160094  3050 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0212 23:00:42.160101  3050 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0212 23:00:42.161159  3050 net.cpp:245] Setting up res5a_branch2b/bn
I0212 23:00:42.161191  3050 net.cpp:252] TEST Top shape for layer 36 'res5a_branch2b/bn' 4 512 12 23 (565248)
I0212 23:00:42.161209  3050 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0212 23:00:42.161218  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.161231  3050 net.cpp:184] Created Layer res5a_branch2b/relu (37)
I0212 23:00:42.161238  3050 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0212 23:00:42.161274  3050 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0212 23:00:42.161285  3050 net.cpp:245] Setting up res5a_branch2b/relu
I0212 23:00:42.161291  3050 net.cpp:252] TEST Top shape for layer 37 'res5a_branch2b/relu' 4 512 12 23 (565248)
I0212 23:00:42.161298  3050 layer_factory.hpp:136] Creating layer 'res5a_branch2b_res5a_branch2b/relu_0_split' of type 'Split'
I0212 23:00:42.161303  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.161310  3050 net.cpp:184] Created Layer res5a_branch2b_res5a_branch2b/relu_0_split (38)
I0212 23:00:42.161315  3050 net.cpp:561] res5a_branch2b_res5a_branch2b/relu_0_split <- res5a_branch2b
I0212 23:00:42.161321  3050 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_0
I0212 23:00:42.161330  3050 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_1
I0212 23:00:42.161418  3050 net.cpp:245] Setting up res5a_branch2b_res5a_branch2b/relu_0_split
I0212 23:00:42.161430  3050 net.cpp:252] TEST Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 4 512 12 23 (565248)
I0212 23:00:42.161437  3050 net.cpp:252] TEST Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 4 512 12 23 (565248)
I0212 23:00:42.161442  3050 layer_factory.hpp:136] Creating layer 'pool6' of type 'Pooling'
I0212 23:00:42.161448  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.161459  3050 net.cpp:184] Created Layer pool6 (39)
I0212 23:00:42.161468  3050 net.cpp:561] pool6 <- res5a_branch2b_res5a_branch2b/relu_0_split_0
I0212 23:00:42.161473  3050 net.cpp:530] pool6 -> pool6
I0212 23:00:42.161579  3050 net.cpp:245] Setting up pool6
I0212 23:00:42.161592  3050 net.cpp:252] TEST Top shape for layer 39 'pool6' 4 512 6 12 (147456)
I0212 23:00:42.161597  3050 layer_factory.hpp:136] Creating layer 'pool6_pool6_0_split' of type 'Split'
I0212 23:00:42.161602  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.161610  3050 net.cpp:184] Created Layer pool6_pool6_0_split (40)
I0212 23:00:42.161617  3050 net.cpp:561] pool6_pool6_0_split <- pool6
I0212 23:00:42.161623  3050 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_0
I0212 23:00:42.161629  3050 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_1
I0212 23:00:42.161698  3050 net.cpp:245] Setting up pool6_pool6_0_split
I0212 23:00:42.161710  3050 net.cpp:252] TEST Top shape for layer 40 'pool6_pool6_0_split' 4 512 6 12 (147456)
I0212 23:00:42.161716  3050 net.cpp:252] TEST Top shape for layer 40 'pool6_pool6_0_split' 4 512 6 12 (147456)
I0212 23:00:42.161722  3050 layer_factory.hpp:136] Creating layer 'pool7' of type 'Pooling'
I0212 23:00:42.161728  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.161736  3050 net.cpp:184] Created Layer pool7 (41)
I0212 23:00:42.161741  3050 net.cpp:561] pool7 <- pool6_pool6_0_split_0
I0212 23:00:42.161748  3050 net.cpp:530] pool7 -> pool7
I0212 23:00:42.161844  3050 net.cpp:245] Setting up pool7
I0212 23:00:42.161856  3050 net.cpp:252] TEST Top shape for layer 41 'pool7' 4 512 3 6 (36864)
I0212 23:00:42.161862  3050 layer_factory.hpp:136] Creating layer 'pool7_pool7_0_split' of type 'Split'
I0212 23:00:42.161867  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.161875  3050 net.cpp:184] Created Layer pool7_pool7_0_split (42)
I0212 23:00:42.161881  3050 net.cpp:561] pool7_pool7_0_split <- pool7
I0212 23:00:42.161887  3050 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_0
I0212 23:00:42.161896  3050 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_1
I0212 23:00:42.161972  3050 net.cpp:245] Setting up pool7_pool7_0_split
I0212 23:00:42.161984  3050 net.cpp:252] TEST Top shape for layer 42 'pool7_pool7_0_split' 4 512 3 6 (36864)
I0212 23:00:42.161999  3050 net.cpp:252] TEST Top shape for layer 42 'pool7_pool7_0_split' 4 512 3 6 (36864)
I0212 23:00:42.162006  3050 layer_factory.hpp:136] Creating layer 'pool8' of type 'Pooling'
I0212 23:00:42.162011  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.162022  3050 net.cpp:184] Created Layer pool8 (43)
I0212 23:00:42.162029  3050 net.cpp:561] pool8 <- pool7_pool7_0_split_0
I0212 23:00:42.162034  3050 net.cpp:530] pool8 -> pool8
I0212 23:00:42.162137  3050 net.cpp:245] Setting up pool8
I0212 23:00:42.162149  3050 net.cpp:252] TEST Top shape for layer 43 'pool8' 4 512 2 3 (12288)
I0212 23:00:42.162155  3050 layer_factory.hpp:136] Creating layer 'pool8_pool8_0_split' of type 'Split'
I0212 23:00:42.162160  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.162168  3050 net.cpp:184] Created Layer pool8_pool8_0_split (44)
I0212 23:00:42.162173  3050 net.cpp:561] pool8_pool8_0_split <- pool8
I0212 23:00:42.162178  3050 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_0
I0212 23:00:42.162186  3050 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_1
I0212 23:00:42.162256  3050 net.cpp:245] Setting up pool8_pool8_0_split
I0212 23:00:42.162276  3050 net.cpp:252] TEST Top shape for layer 44 'pool8_pool8_0_split' 4 512 2 3 (12288)
I0212 23:00:42.162284  3050 net.cpp:252] TEST Top shape for layer 44 'pool8_pool8_0_split' 4 512 2 3 (12288)
I0212 23:00:42.162291  3050 layer_factory.hpp:136] Creating layer 'pool9' of type 'Pooling'
I0212 23:00:42.162295  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.162305  3050 net.cpp:184] Created Layer pool9 (45)
I0212 23:00:42.162312  3050 net.cpp:561] pool9 <- pool8_pool8_0_split_0
I0212 23:00:42.162317  3050 net.cpp:530] pool9 -> pool9
I0212 23:00:42.162417  3050 net.cpp:245] Setting up pool9
I0212 23:00:42.162428  3050 net.cpp:252] TEST Top shape for layer 45 'pool9' 4 512 1 2 (4096)
I0212 23:00:42.162434  3050 layer_factory.hpp:136] Creating layer 'ctx_output1' of type 'Convolution'
I0212 23:00:42.162441  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.162458  3050 net.cpp:184] Created Layer ctx_output1 (46)
I0212 23:00:42.162466  3050 net.cpp:561] ctx_output1 <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0212 23:00:42.162472  3050 net.cpp:530] ctx_output1 -> ctx_output1
I0212 23:00:42.164162  3050 net.cpp:245] Setting up ctx_output1
I0212 23:00:42.164176  3050 net.cpp:252] TEST Top shape for layer 46 'ctx_output1' 4 256 46 90 (4239360)
I0212 23:00:42.164186  3050 layer_factory.hpp:136] Creating layer 'ctx_output1/relu' of type 'ReLU'
I0212 23:00:42.164191  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.164201  3050 net.cpp:184] Created Layer ctx_output1/relu (47)
I0212 23:00:42.164206  3050 net.cpp:561] ctx_output1/relu <- ctx_output1
I0212 23:00:42.164212  3050 net.cpp:513] ctx_output1/relu -> ctx_output1 (in-place)
I0212 23:00:42.164221  3050 net.cpp:245] Setting up ctx_output1/relu
I0212 23:00:42.164227  3050 net.cpp:252] TEST Top shape for layer 47 'ctx_output1/relu' 4 256 46 90 (4239360)
I0212 23:00:42.164232  3050 layer_factory.hpp:136] Creating layer 'ctx_output1_ctx_output1/relu_0_split' of type 'Split'
I0212 23:00:42.164237  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.164243  3050 net.cpp:184] Created Layer ctx_output1_ctx_output1/relu_0_split (48)
I0212 23:00:42.164248  3050 net.cpp:561] ctx_output1_ctx_output1/relu_0_split <- ctx_output1
I0212 23:00:42.164255  3050 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_0
I0212 23:00:42.164263  3050 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_1
I0212 23:00:42.164269  3050 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_2
I0212 23:00:42.164381  3050 net.cpp:245] Setting up ctx_output1_ctx_output1/relu_0_split
I0212 23:00:42.164393  3050 net.cpp:252] TEST Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 4 256 46 90 (4239360)
I0212 23:00:42.164399  3050 net.cpp:252] TEST Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 4 256 46 90 (4239360)
I0212 23:00:42.164407  3050 net.cpp:252] TEST Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 4 256 46 90 (4239360)
I0212 23:00:42.164412  3050 layer_factory.hpp:136] Creating layer 'ctx_output2' of type 'Convolution'
I0212 23:00:42.164417  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.164433  3050 net.cpp:184] Created Layer ctx_output2 (49)
I0212 23:00:42.164440  3050 net.cpp:561] ctx_output2 <- res5a_branch2b_res5a_branch2b/relu_0_split_1
I0212 23:00:42.164446  3050 net.cpp:530] ctx_output2 -> ctx_output2
I0212 23:00:42.171993  3050 net.cpp:245] Setting up ctx_output2
I0212 23:00:42.172015  3050 net.cpp:252] TEST Top shape for layer 49 'ctx_output2' 4 256 12 23 (282624)
I0212 23:00:42.172027  3050 layer_factory.hpp:136] Creating layer 'ctx_output2/relu' of type 'ReLU'
I0212 23:00:42.172034  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.172045  3050 net.cpp:184] Created Layer ctx_output2/relu (50)
I0212 23:00:42.172052  3050 net.cpp:561] ctx_output2/relu <- ctx_output2
I0212 23:00:42.172060  3050 net.cpp:513] ctx_output2/relu -> ctx_output2 (in-place)
I0212 23:00:42.172068  3050 net.cpp:245] Setting up ctx_output2/relu
I0212 23:00:42.172075  3050 net.cpp:252] TEST Top shape for layer 50 'ctx_output2/relu' 4 256 12 23 (282624)
I0212 23:00:42.172080  3050 layer_factory.hpp:136] Creating layer 'ctx_output2_ctx_output2/relu_0_split' of type 'Split'
I0212 23:00:42.172086  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.172092  3050 net.cpp:184] Created Layer ctx_output2_ctx_output2/relu_0_split (51)
I0212 23:00:42.172097  3050 net.cpp:561] ctx_output2_ctx_output2/relu_0_split <- ctx_output2
I0212 23:00:42.172103  3050 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_0
I0212 23:00:42.172112  3050 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_1
I0212 23:00:42.172119  3050 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_2
I0212 23:00:42.172224  3050 net.cpp:245] Setting up ctx_output2_ctx_output2/relu_0_split
I0212 23:00:42.172235  3050 net.cpp:252] TEST Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 4 256 12 23 (282624)
I0212 23:00:42.172241  3050 net.cpp:252] TEST Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 4 256 12 23 (282624)
I0212 23:00:42.172248  3050 net.cpp:252] TEST Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 4 256 12 23 (282624)
I0212 23:00:42.172255  3050 layer_factory.hpp:136] Creating layer 'ctx_output3' of type 'Convolution'
I0212 23:00:42.172260  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.172277  3050 net.cpp:184] Created Layer ctx_output3 (52)
I0212 23:00:42.172286  3050 net.cpp:561] ctx_output3 <- pool6_pool6_0_split_1
I0212 23:00:42.172291  3050 net.cpp:530] ctx_output3 -> ctx_output3
I0212 23:00:42.178699  3050 net.cpp:245] Setting up ctx_output3
I0212 23:00:42.178715  3050 net.cpp:252] TEST Top shape for layer 52 'ctx_output3' 4 256 6 12 (73728)
I0212 23:00:42.178726  3050 layer_factory.hpp:136] Creating layer 'ctx_output3/relu' of type 'ReLU'
I0212 23:00:42.178733  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.178741  3050 net.cpp:184] Created Layer ctx_output3/relu (53)
I0212 23:00:42.178747  3050 net.cpp:561] ctx_output3/relu <- ctx_output3
I0212 23:00:42.178755  3050 net.cpp:513] ctx_output3/relu -> ctx_output3 (in-place)
I0212 23:00:42.178764  3050 net.cpp:245] Setting up ctx_output3/relu
I0212 23:00:42.178791  3050 net.cpp:252] TEST Top shape for layer 53 'ctx_output3/relu' 4 256 6 12 (73728)
I0212 23:00:42.178799  3050 layer_factory.hpp:136] Creating layer 'ctx_output3_ctx_output3/relu_0_split' of type 'Split'
I0212 23:00:42.178804  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.178812  3050 net.cpp:184] Created Layer ctx_output3_ctx_output3/relu_0_split (54)
I0212 23:00:42.178817  3050 net.cpp:561] ctx_output3_ctx_output3/relu_0_split <- ctx_output3
I0212 23:00:42.178823  3050 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_0
I0212 23:00:42.178833  3050 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_1
I0212 23:00:42.178840  3050 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_2
I0212 23:00:42.178951  3050 net.cpp:245] Setting up ctx_output3_ctx_output3/relu_0_split
I0212 23:00:42.178963  3050 net.cpp:252] TEST Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 4 256 6 12 (73728)
I0212 23:00:42.178972  3050 net.cpp:252] TEST Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 4 256 6 12 (73728)
I0212 23:00:42.178978  3050 net.cpp:252] TEST Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 4 256 6 12 (73728)
I0212 23:00:42.178984  3050 layer_factory.hpp:136] Creating layer 'ctx_output4' of type 'Convolution'
I0212 23:00:42.178990  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.179010  3050 net.cpp:184] Created Layer ctx_output4 (55)
I0212 23:00:42.179018  3050 net.cpp:561] ctx_output4 <- pool7_pool7_0_split_1
I0212 23:00:42.179025  3050 net.cpp:530] ctx_output4 -> ctx_output4
I0212 23:00:42.184648  3050 net.cpp:245] Setting up ctx_output4
I0212 23:00:42.184677  3050 net.cpp:252] TEST Top shape for layer 55 'ctx_output4' 4 256 3 6 (18432)
I0212 23:00:42.184690  3050 layer_factory.hpp:136] Creating layer 'ctx_output4/relu' of type 'ReLU'
I0212 23:00:42.184697  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.184707  3050 net.cpp:184] Created Layer ctx_output4/relu (56)
I0212 23:00:42.184715  3050 net.cpp:561] ctx_output4/relu <- ctx_output4
I0212 23:00:42.184722  3050 net.cpp:513] ctx_output4/relu -> ctx_output4 (in-place)
I0212 23:00:42.184734  3050 net.cpp:245] Setting up ctx_output4/relu
I0212 23:00:42.184741  3050 net.cpp:252] TEST Top shape for layer 56 'ctx_output4/relu' 4 256 3 6 (18432)
I0212 23:00:42.184747  3050 layer_factory.hpp:136] Creating layer 'ctx_output4_ctx_output4/relu_0_split' of type 'Split'
I0212 23:00:42.184752  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.184759  3050 net.cpp:184] Created Layer ctx_output4_ctx_output4/relu_0_split (57)
I0212 23:00:42.184764  3050 net.cpp:561] ctx_output4_ctx_output4/relu_0_split <- ctx_output4
I0212 23:00:42.184770  3050 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_0
I0212 23:00:42.184779  3050 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_1
I0212 23:00:42.184787  3050 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_2
I0212 23:00:42.184890  3050 net.cpp:245] Setting up ctx_output4_ctx_output4/relu_0_split
I0212 23:00:42.184901  3050 net.cpp:252] TEST Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 4 256 3 6 (18432)
I0212 23:00:42.184907  3050 net.cpp:252] TEST Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 4 256 3 6 (18432)
I0212 23:00:42.184914  3050 net.cpp:252] TEST Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 4 256 3 6 (18432)
I0212 23:00:42.184919  3050 layer_factory.hpp:136] Creating layer 'ctx_output5' of type 'Convolution'
I0212 23:00:42.184926  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.184962  3050 net.cpp:184] Created Layer ctx_output5 (58)
I0212 23:00:42.184969  3050 net.cpp:561] ctx_output5 <- pool8_pool8_0_split_1
I0212 23:00:42.184976  3050 net.cpp:530] ctx_output5 -> ctx_output5
I0212 23:00:42.190167  3050 net.cpp:245] Setting up ctx_output5
I0212 23:00:42.190199  3050 net.cpp:252] TEST Top shape for layer 58 'ctx_output5' 4 256 2 3 (6144)
I0212 23:00:42.190210  3050 layer_factory.hpp:136] Creating layer 'ctx_output5/relu' of type 'ReLU'
I0212 23:00:42.190218  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.190227  3050 net.cpp:184] Created Layer ctx_output5/relu (59)
I0212 23:00:42.190234  3050 net.cpp:561] ctx_output5/relu <- ctx_output5
I0212 23:00:42.190241  3050 net.cpp:513] ctx_output5/relu -> ctx_output5 (in-place)
I0212 23:00:42.190250  3050 net.cpp:245] Setting up ctx_output5/relu
I0212 23:00:42.190258  3050 net.cpp:252] TEST Top shape for layer 59 'ctx_output5/relu' 4 256 2 3 (6144)
I0212 23:00:42.190263  3050 layer_factory.hpp:136] Creating layer 'ctx_output5_ctx_output5/relu_0_split' of type 'Split'
I0212 23:00:42.190268  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.190294  3050 net.cpp:184] Created Layer ctx_output5_ctx_output5/relu_0_split (60)
I0212 23:00:42.190299  3050 net.cpp:561] ctx_output5_ctx_output5/relu_0_split <- ctx_output5
I0212 23:00:42.190305  3050 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_0
I0212 23:00:42.190312  3050 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_1
I0212 23:00:42.190320  3050 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_2
I0212 23:00:42.190420  3050 net.cpp:245] Setting up ctx_output5_ctx_output5/relu_0_split
I0212 23:00:42.190431  3050 net.cpp:252] TEST Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 4 256 2 3 (6144)
I0212 23:00:42.190438  3050 net.cpp:252] TEST Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 4 256 2 3 (6144)
I0212 23:00:42.190444  3050 net.cpp:252] TEST Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 4 256 2 3 (6144)
I0212 23:00:42.190450  3050 layer_factory.hpp:136] Creating layer 'ctx_output6' of type 'Convolution'
I0212 23:00:42.190456  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.190474  3050 net.cpp:184] Created Layer ctx_output6 (61)
I0212 23:00:42.190480  3050 net.cpp:561] ctx_output6 <- pool9
I0212 23:00:42.190487  3050 net.cpp:530] ctx_output6 -> ctx_output6
I0212 23:00:42.195435  3050 net.cpp:245] Setting up ctx_output6
I0212 23:00:42.195448  3050 net.cpp:252] TEST Top shape for layer 61 'ctx_output6' 4 256 1 2 (2048)
I0212 23:00:42.195457  3050 layer_factory.hpp:136] Creating layer 'ctx_output6/relu' of type 'ReLU'
I0212 23:00:42.195463  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.195472  3050 net.cpp:184] Created Layer ctx_output6/relu (62)
I0212 23:00:42.195477  3050 net.cpp:561] ctx_output6/relu <- ctx_output6
I0212 23:00:42.195483  3050 net.cpp:513] ctx_output6/relu -> ctx_output6 (in-place)
I0212 23:00:42.195492  3050 net.cpp:245] Setting up ctx_output6/relu
I0212 23:00:42.195498  3050 net.cpp:252] TEST Top shape for layer 62 'ctx_output6/relu' 4 256 1 2 (2048)
I0212 23:00:42.195504  3050 layer_factory.hpp:136] Creating layer 'ctx_output6_ctx_output6/relu_0_split' of type 'Split'
I0212 23:00:42.195509  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.195515  3050 net.cpp:184] Created Layer ctx_output6_ctx_output6/relu_0_split (63)
I0212 23:00:42.195520  3050 net.cpp:561] ctx_output6_ctx_output6/relu_0_split <- ctx_output6
I0212 23:00:42.195525  3050 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_0
I0212 23:00:42.195533  3050 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_1
I0212 23:00:42.195559  3050 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_2
I0212 23:00:42.195662  3050 net.cpp:245] Setting up ctx_output6_ctx_output6/relu_0_split
I0212 23:00:42.195672  3050 net.cpp:252] TEST Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 4 256 1 2 (2048)
I0212 23:00:42.195678  3050 net.cpp:252] TEST Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 4 256 1 2 (2048)
I0212 23:00:42.195684  3050 net.cpp:252] TEST Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 4 256 1 2 (2048)
I0212 23:00:42.195690  3050 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc' of type 'Convolution'
I0212 23:00:42.195695  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.195714  3050 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc (64)
I0212 23:00:42.195721  3050 net.cpp:561] ctx_output1/relu_mbox_loc <- ctx_output1_ctx_output1/relu_0_split_0
I0212 23:00:42.195729  3050 net.cpp:530] ctx_output1/relu_mbox_loc -> ctx_output1/relu_mbox_loc
I0212 23:00:42.196378  3050 net.cpp:245] Setting up ctx_output1/relu_mbox_loc
I0212 23:00:42.196391  3050 net.cpp:252] TEST Top shape for layer 64 'ctx_output1/relu_mbox_loc' 4 16 46 90 (264960)
I0212 23:00:42.196401  3050 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_perm' of type 'Permute'
I0212 23:00:42.196408  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.196419  3050 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_perm (65)
I0212 23:00:42.196424  3050 net.cpp:561] ctx_output1/relu_mbox_loc_perm <- ctx_output1/relu_mbox_loc
I0212 23:00:42.196430  3050 net.cpp:530] ctx_output1/relu_mbox_loc_perm -> ctx_output1/relu_mbox_loc_perm
I0212 23:00:42.196630  3050 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_perm
I0212 23:00:42.196641  3050 net.cpp:252] TEST Top shape for layer 65 'ctx_output1/relu_mbox_loc_perm' 4 46 90 16 (264960)
I0212 23:00:42.196647  3050 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_flat' of type 'Flatten'
I0212 23:00:42.196652  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.196662  3050 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_flat (66)
I0212 23:00:42.196667  3050 net.cpp:561] ctx_output1/relu_mbox_loc_flat <- ctx_output1/relu_mbox_loc_perm
I0212 23:00:42.196673  3050 net.cpp:530] ctx_output1/relu_mbox_loc_flat -> ctx_output1/relu_mbox_loc_flat
I0212 23:00:42.196720  3050 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_flat
I0212 23:00:42.196733  3050 net.cpp:252] TEST Top shape for layer 66 'ctx_output1/relu_mbox_loc_flat' 4 66240 (264960)
I0212 23:00:42.196739  3050 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf' of type 'Convolution'
I0212 23:00:42.196745  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.196760  3050 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf (67)
I0212 23:00:42.196766  3050 net.cpp:561] ctx_output1/relu_mbox_conf <- ctx_output1_ctx_output1/relu_0_split_1
I0212 23:00:42.196774  3050 net.cpp:530] ctx_output1/relu_mbox_conf -> ctx_output1/relu_mbox_conf
I0212 23:00:42.197408  3050 net.cpp:245] Setting up ctx_output1/relu_mbox_conf
I0212 23:00:42.197422  3050 net.cpp:252] TEST Top shape for layer 67 'ctx_output1/relu_mbox_conf' 4 16 46 90 (264960)
I0212 23:00:42.197432  3050 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_perm' of type 'Permute'
I0212 23:00:42.197438  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.197448  3050 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_perm (68)
I0212 23:00:42.197453  3050 net.cpp:561] ctx_output1/relu_mbox_conf_perm <- ctx_output1/relu_mbox_conf
I0212 23:00:42.197459  3050 net.cpp:530] ctx_output1/relu_mbox_conf_perm -> ctx_output1/relu_mbox_conf_perm
I0212 23:00:42.197655  3050 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_perm
I0212 23:00:42.197676  3050 net.cpp:252] TEST Top shape for layer 68 'ctx_output1/relu_mbox_conf_perm' 4 46 90 16 (264960)
I0212 23:00:42.197682  3050 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_flat' of type 'Flatten'
I0212 23:00:42.197688  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.197695  3050 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_flat (69)
I0212 23:00:42.197700  3050 net.cpp:561] ctx_output1/relu_mbox_conf_flat <- ctx_output1/relu_mbox_conf_perm
I0212 23:00:42.197706  3050 net.cpp:530] ctx_output1/relu_mbox_conf_flat -> ctx_output1/relu_mbox_conf_flat
I0212 23:00:42.197753  3050 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_flat
I0212 23:00:42.197764  3050 net.cpp:252] TEST Top shape for layer 69 'ctx_output1/relu_mbox_conf_flat' 4 66240 (264960)
I0212 23:00:42.197770  3050 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_priorbox' of type 'PriorBox'
I0212 23:00:42.197775  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.197785  3050 net.cpp:184] Created Layer ctx_output1/relu_mbox_priorbox (70)
I0212 23:00:42.197791  3050 net.cpp:561] ctx_output1/relu_mbox_priorbox <- ctx_output1_ctx_output1/relu_0_split_2
I0212 23:00:42.197798  3050 net.cpp:561] ctx_output1/relu_mbox_priorbox <- data_data_0_split_1
I0212 23:00:42.197804  3050 net.cpp:530] ctx_output1/relu_mbox_priorbox -> ctx_output1/relu_mbox_priorbox
I0212 23:00:42.197850  3050 net.cpp:245] Setting up ctx_output1/relu_mbox_priorbox
I0212 23:00:42.197861  3050 net.cpp:252] TEST Top shape for layer 70 'ctx_output1/relu_mbox_priorbox' 1 2 66240 (132480)
I0212 23:00:42.197866  3050 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc' of type 'Convolution'
I0212 23:00:42.197872  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.197890  3050 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc (71)
I0212 23:00:42.197897  3050 net.cpp:561] ctx_output2/relu_mbox_loc <- ctx_output2_ctx_output2/relu_0_split_0
I0212 23:00:42.197904  3050 net.cpp:530] ctx_output2/relu_mbox_loc -> ctx_output2/relu_mbox_loc
I0212 23:00:42.198621  3050 net.cpp:245] Setting up ctx_output2/relu_mbox_loc
I0212 23:00:42.198633  3050 net.cpp:252] TEST Top shape for layer 71 'ctx_output2/relu_mbox_loc' 4 24 12 23 (26496)
I0212 23:00:42.198642  3050 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_perm' of type 'Permute'
I0212 23:00:42.198649  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.198659  3050 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_perm (72)
I0212 23:00:42.198665  3050 net.cpp:561] ctx_output2/relu_mbox_loc_perm <- ctx_output2/relu_mbox_loc
I0212 23:00:42.198671  3050 net.cpp:530] ctx_output2/relu_mbox_loc_perm -> ctx_output2/relu_mbox_loc_perm
I0212 23:00:42.198870  3050 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_perm
I0212 23:00:42.198881  3050 net.cpp:252] TEST Top shape for layer 72 'ctx_output2/relu_mbox_loc_perm' 4 12 23 24 (26496)
I0212 23:00:42.198887  3050 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_flat' of type 'Flatten'
I0212 23:00:42.198892  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.198901  3050 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_flat (73)
I0212 23:00:42.198907  3050 net.cpp:561] ctx_output2/relu_mbox_loc_flat <- ctx_output2/relu_mbox_loc_perm
I0212 23:00:42.198913  3050 net.cpp:530] ctx_output2/relu_mbox_loc_flat -> ctx_output2/relu_mbox_loc_flat
I0212 23:00:42.198957  3050 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_flat
I0212 23:00:42.198967  3050 net.cpp:252] TEST Top shape for layer 73 'ctx_output2/relu_mbox_loc_flat' 4 6624 (26496)
I0212 23:00:42.198973  3050 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf' of type 'Convolution'
I0212 23:00:42.198988  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.199005  3050 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf (74)
I0212 23:00:42.199012  3050 net.cpp:561] ctx_output2/relu_mbox_conf <- ctx_output2_ctx_output2/relu_0_split_1
I0212 23:00:42.199018  3050 net.cpp:530] ctx_output2/relu_mbox_conf -> ctx_output2/relu_mbox_conf
I0212 23:00:42.199724  3050 net.cpp:245] Setting up ctx_output2/relu_mbox_conf
I0212 23:00:42.199738  3050 net.cpp:252] TEST Top shape for layer 74 'ctx_output2/relu_mbox_conf' 4 24 12 23 (26496)
I0212 23:00:42.199746  3050 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_perm' of type 'Permute'
I0212 23:00:42.199753  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.199762  3050 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_perm (75)
I0212 23:00:42.199769  3050 net.cpp:561] ctx_output2/relu_mbox_conf_perm <- ctx_output2/relu_mbox_conf
I0212 23:00:42.199775  3050 net.cpp:530] ctx_output2/relu_mbox_conf_perm -> ctx_output2/relu_mbox_conf_perm
I0212 23:00:42.199975  3050 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_perm
I0212 23:00:42.199987  3050 net.cpp:252] TEST Top shape for layer 75 'ctx_output2/relu_mbox_conf_perm' 4 12 23 24 (26496)
I0212 23:00:42.199993  3050 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_flat' of type 'Flatten'
I0212 23:00:42.199998  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.200006  3050 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_flat (76)
I0212 23:00:42.200011  3050 net.cpp:561] ctx_output2/relu_mbox_conf_flat <- ctx_output2/relu_mbox_conf_perm
I0212 23:00:42.200017  3050 net.cpp:530] ctx_output2/relu_mbox_conf_flat -> ctx_output2/relu_mbox_conf_flat
I0212 23:00:42.200062  3050 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_flat
I0212 23:00:42.200073  3050 net.cpp:252] TEST Top shape for layer 76 'ctx_output2/relu_mbox_conf_flat' 4 6624 (26496)
I0212 23:00:42.200079  3050 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_priorbox' of type 'PriorBox'
I0212 23:00:42.200084  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.200093  3050 net.cpp:184] Created Layer ctx_output2/relu_mbox_priorbox (77)
I0212 23:00:42.200099  3050 net.cpp:561] ctx_output2/relu_mbox_priorbox <- ctx_output2_ctx_output2/relu_0_split_2
I0212 23:00:42.200105  3050 net.cpp:561] ctx_output2/relu_mbox_priorbox <- data_data_0_split_2
I0212 23:00:42.200112  3050 net.cpp:530] ctx_output2/relu_mbox_priorbox -> ctx_output2/relu_mbox_priorbox
I0212 23:00:42.200158  3050 net.cpp:245] Setting up ctx_output2/relu_mbox_priorbox
I0212 23:00:42.200170  3050 net.cpp:252] TEST Top shape for layer 77 'ctx_output2/relu_mbox_priorbox' 1 2 6624 (13248)
I0212 23:00:42.200176  3050 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc' of type 'Convolution'
I0212 23:00:42.200182  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.200197  3050 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc (78)
I0212 23:00:42.200203  3050 net.cpp:561] ctx_output3/relu_mbox_loc <- ctx_output3_ctx_output3/relu_0_split_0
I0212 23:00:42.200209  3050 net.cpp:530] ctx_output3/relu_mbox_loc -> ctx_output3/relu_mbox_loc
I0212 23:00:42.200919  3050 net.cpp:245] Setting up ctx_output3/relu_mbox_loc
I0212 23:00:42.200932  3050 net.cpp:252] TEST Top shape for layer 78 'ctx_output3/relu_mbox_loc' 4 24 6 12 (6912)
I0212 23:00:42.200942  3050 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_perm' of type 'Permute'
I0212 23:00:42.200947  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.200958  3050 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_perm (79)
I0212 23:00:42.200964  3050 net.cpp:561] ctx_output3/relu_mbox_loc_perm <- ctx_output3/relu_mbox_loc
I0212 23:00:42.200970  3050 net.cpp:530] ctx_output3/relu_mbox_loc_perm -> ctx_output3/relu_mbox_loc_perm
I0212 23:00:42.201180  3050 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_perm
I0212 23:00:42.201192  3050 net.cpp:252] TEST Top shape for layer 79 'ctx_output3/relu_mbox_loc_perm' 4 6 12 24 (6912)
I0212 23:00:42.201198  3050 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_flat' of type 'Flatten'
I0212 23:00:42.201203  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.201212  3050 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_flat (80)
I0212 23:00:42.201218  3050 net.cpp:561] ctx_output3/relu_mbox_loc_flat <- ctx_output3/relu_mbox_loc_perm
I0212 23:00:42.201225  3050 net.cpp:530] ctx_output3/relu_mbox_loc_flat -> ctx_output3/relu_mbox_loc_flat
I0212 23:00:42.201269  3050 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_flat
I0212 23:00:42.201279  3050 net.cpp:252] TEST Top shape for layer 80 'ctx_output3/relu_mbox_loc_flat' 4 1728 (6912)
I0212 23:00:42.201285  3050 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf' of type 'Convolution'
I0212 23:00:42.201292  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.201308  3050 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf (81)
I0212 23:00:42.201315  3050 net.cpp:561] ctx_output3/relu_mbox_conf <- ctx_output3_ctx_output3/relu_0_split_1
I0212 23:00:42.201323  3050 net.cpp:530] ctx_output3/relu_mbox_conf -> ctx_output3/relu_mbox_conf
I0212 23:00:42.202025  3050 net.cpp:245] Setting up ctx_output3/relu_mbox_conf
I0212 23:00:42.202039  3050 net.cpp:252] TEST Top shape for layer 81 'ctx_output3/relu_mbox_conf' 4 24 6 12 (6912)
I0212 23:00:42.202047  3050 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_perm' of type 'Permute'
I0212 23:00:42.202054  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.202064  3050 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_perm (82)
I0212 23:00:42.202069  3050 net.cpp:561] ctx_output3/relu_mbox_conf_perm <- ctx_output3/relu_mbox_conf
I0212 23:00:42.202075  3050 net.cpp:530] ctx_output3/relu_mbox_conf_perm -> ctx_output3/relu_mbox_conf_perm
I0212 23:00:42.202286  3050 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_perm
I0212 23:00:42.202297  3050 net.cpp:252] TEST Top shape for layer 82 'ctx_output3/relu_mbox_conf_perm' 4 6 12 24 (6912)
I0212 23:00:42.202303  3050 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_flat' of type 'Flatten'
I0212 23:00:42.202308  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.202316  3050 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_flat (83)
I0212 23:00:42.202322  3050 net.cpp:561] ctx_output3/relu_mbox_conf_flat <- ctx_output3/relu_mbox_conf_perm
I0212 23:00:42.202328  3050 net.cpp:530] ctx_output3/relu_mbox_conf_flat -> ctx_output3/relu_mbox_conf_flat
I0212 23:00:42.202374  3050 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_flat
I0212 23:00:42.202385  3050 net.cpp:252] TEST Top shape for layer 83 'ctx_output3/relu_mbox_conf_flat' 4 1728 (6912)
I0212 23:00:42.202391  3050 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_priorbox' of type 'PriorBox'
I0212 23:00:42.202397  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.202404  3050 net.cpp:184] Created Layer ctx_output3/relu_mbox_priorbox (84)
I0212 23:00:42.202410  3050 net.cpp:561] ctx_output3/relu_mbox_priorbox <- ctx_output3_ctx_output3/relu_0_split_2
I0212 23:00:42.202416  3050 net.cpp:561] ctx_output3/relu_mbox_priorbox <- data_data_0_split_3
I0212 23:00:42.202422  3050 net.cpp:530] ctx_output3/relu_mbox_priorbox -> ctx_output3/relu_mbox_priorbox
I0212 23:00:42.202471  3050 net.cpp:245] Setting up ctx_output3/relu_mbox_priorbox
I0212 23:00:42.202481  3050 net.cpp:252] TEST Top shape for layer 84 'ctx_output3/relu_mbox_priorbox' 1 2 1728 (3456)
I0212 23:00:42.202486  3050 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc' of type 'Convolution'
I0212 23:00:42.202502  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.202517  3050 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc (85)
I0212 23:00:42.202524  3050 net.cpp:561] ctx_output4/relu_mbox_loc <- ctx_output4_ctx_output4/relu_0_split_0
I0212 23:00:42.202531  3050 net.cpp:530] ctx_output4/relu_mbox_loc -> ctx_output4/relu_mbox_loc
I0212 23:00:42.203241  3050 net.cpp:245] Setting up ctx_output4/relu_mbox_loc
I0212 23:00:42.203254  3050 net.cpp:252] TEST Top shape for layer 85 'ctx_output4/relu_mbox_loc' 4 24 3 6 (1728)
I0212 23:00:42.203263  3050 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_perm' of type 'Permute'
I0212 23:00:42.203269  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.203279  3050 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_perm (86)
I0212 23:00:42.203285  3050 net.cpp:561] ctx_output4/relu_mbox_loc_perm <- ctx_output4/relu_mbox_loc
I0212 23:00:42.203292  3050 net.cpp:530] ctx_output4/relu_mbox_loc_perm -> ctx_output4/relu_mbox_loc_perm
I0212 23:00:42.203491  3050 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_perm
I0212 23:00:42.203503  3050 net.cpp:252] TEST Top shape for layer 86 'ctx_output4/relu_mbox_loc_perm' 4 3 6 24 (1728)
I0212 23:00:42.203508  3050 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_flat' of type 'Flatten'
I0212 23:00:42.203514  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.203521  3050 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_flat (87)
I0212 23:00:42.203526  3050 net.cpp:561] ctx_output4/relu_mbox_loc_flat <- ctx_output4/relu_mbox_loc_perm
I0212 23:00:42.203532  3050 net.cpp:530] ctx_output4/relu_mbox_loc_flat -> ctx_output4/relu_mbox_loc_flat
I0212 23:00:42.203577  3050 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_flat
I0212 23:00:42.203588  3050 net.cpp:252] TEST Top shape for layer 87 'ctx_output4/relu_mbox_loc_flat' 4 432 (1728)
I0212 23:00:42.203594  3050 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf' of type 'Convolution'
I0212 23:00:42.203599  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.203616  3050 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf (88)
I0212 23:00:42.203624  3050 net.cpp:561] ctx_output4/relu_mbox_conf <- ctx_output4_ctx_output4/relu_0_split_1
I0212 23:00:42.203629  3050 net.cpp:530] ctx_output4/relu_mbox_conf -> ctx_output4/relu_mbox_conf
I0212 23:00:42.204339  3050 net.cpp:245] Setting up ctx_output4/relu_mbox_conf
I0212 23:00:42.204351  3050 net.cpp:252] TEST Top shape for layer 88 'ctx_output4/relu_mbox_conf' 4 24 3 6 (1728)
I0212 23:00:42.204360  3050 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_perm' of type 'Permute'
I0212 23:00:42.204366  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.204377  3050 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_perm (89)
I0212 23:00:42.204383  3050 net.cpp:561] ctx_output4/relu_mbox_conf_perm <- ctx_output4/relu_mbox_conf
I0212 23:00:42.204390  3050 net.cpp:530] ctx_output4/relu_mbox_conf_perm -> ctx_output4/relu_mbox_conf_perm
I0212 23:00:42.204589  3050 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_perm
I0212 23:00:42.204602  3050 net.cpp:252] TEST Top shape for layer 89 'ctx_output4/relu_mbox_conf_perm' 4 3 6 24 (1728)
I0212 23:00:42.204607  3050 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_flat' of type 'Flatten'
I0212 23:00:42.204612  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.204620  3050 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_flat (90)
I0212 23:00:42.204627  3050 net.cpp:561] ctx_output4/relu_mbox_conf_flat <- ctx_output4/relu_mbox_conf_perm
I0212 23:00:42.204632  3050 net.cpp:530] ctx_output4/relu_mbox_conf_flat -> ctx_output4/relu_mbox_conf_flat
I0212 23:00:42.204687  3050 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_flat
I0212 23:00:42.204699  3050 net.cpp:252] TEST Top shape for layer 90 'ctx_output4/relu_mbox_conf_flat' 4 432 (1728)
I0212 23:00:42.204705  3050 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_priorbox' of type 'PriorBox'
I0212 23:00:42.204710  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.204717  3050 net.cpp:184] Created Layer ctx_output4/relu_mbox_priorbox (91)
I0212 23:00:42.204723  3050 net.cpp:561] ctx_output4/relu_mbox_priorbox <- ctx_output4_ctx_output4/relu_0_split_2
I0212 23:00:42.204730  3050 net.cpp:561] ctx_output4/relu_mbox_priorbox <- data_data_0_split_4
I0212 23:00:42.204735  3050 net.cpp:530] ctx_output4/relu_mbox_priorbox -> ctx_output4/relu_mbox_priorbox
I0212 23:00:42.204783  3050 net.cpp:245] Setting up ctx_output4/relu_mbox_priorbox
I0212 23:00:42.204793  3050 net.cpp:252] TEST Top shape for layer 91 'ctx_output4/relu_mbox_priorbox' 1 2 432 (864)
I0212 23:00:42.204799  3050 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc' of type 'Convolution'
I0212 23:00:42.204805  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.204821  3050 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc (92)
I0212 23:00:42.204829  3050 net.cpp:561] ctx_output5/relu_mbox_loc <- ctx_output5_ctx_output5/relu_0_split_0
I0212 23:00:42.204835  3050 net.cpp:530] ctx_output5/relu_mbox_loc -> ctx_output5/relu_mbox_loc
I0212 23:00:42.205476  3050 net.cpp:245] Setting up ctx_output5/relu_mbox_loc
I0212 23:00:42.205490  3050 net.cpp:252] TEST Top shape for layer 92 'ctx_output5/relu_mbox_loc' 4 16 2 3 (384)
I0212 23:00:42.205498  3050 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_perm' of type 'Permute'
I0212 23:00:42.205504  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.205514  3050 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_perm (93)
I0212 23:00:42.205520  3050 net.cpp:561] ctx_output5/relu_mbox_loc_perm <- ctx_output5/relu_mbox_loc
I0212 23:00:42.205526  3050 net.cpp:530] ctx_output5/relu_mbox_loc_perm -> ctx_output5/relu_mbox_loc_perm
I0212 23:00:42.214947  3050 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_perm
I0212 23:00:42.214977  3050 net.cpp:252] TEST Top shape for layer 93 'ctx_output5/relu_mbox_loc_perm' 4 2 3 16 (384)
I0212 23:00:42.214987  3050 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_flat' of type 'Flatten'
I0212 23:00:42.214998  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.215013  3050 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_flat (94)
I0212 23:00:42.215023  3050 net.cpp:561] ctx_output5/relu_mbox_loc_flat <- ctx_output5/relu_mbox_loc_perm
I0212 23:00:42.215032  3050 net.cpp:530] ctx_output5/relu_mbox_loc_flat -> ctx_output5/relu_mbox_loc_flat
I0212 23:00:42.215093  3050 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_flat
I0212 23:00:42.215108  3050 net.cpp:252] TEST Top shape for layer 94 'ctx_output5/relu_mbox_loc_flat' 4 96 (384)
I0212 23:00:42.215116  3050 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf' of type 'Convolution'
I0212 23:00:42.215126  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.215149  3050 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf (95)
I0212 23:00:42.215159  3050 net.cpp:561] ctx_output5/relu_mbox_conf <- ctx_output5_ctx_output5/relu_0_split_1
I0212 23:00:42.215170  3050 net.cpp:530] ctx_output5/relu_mbox_conf -> ctx_output5/relu_mbox_conf
I0212 23:00:42.215963  3050 net.cpp:245] Setting up ctx_output5/relu_mbox_conf
I0212 23:00:42.215977  3050 net.cpp:252] TEST Top shape for layer 95 'ctx_output5/relu_mbox_conf' 4 16 2 3 (384)
I0212 23:00:42.215987  3050 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_perm' of type 'Permute'
I0212 23:00:42.216009  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.216023  3050 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_perm (96)
I0212 23:00:42.216029  3050 net.cpp:561] ctx_output5/relu_mbox_conf_perm <- ctx_output5/relu_mbox_conf
I0212 23:00:42.216037  3050 net.cpp:530] ctx_output5/relu_mbox_conf_perm -> ctx_output5/relu_mbox_conf_perm
I0212 23:00:42.216246  3050 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_perm
I0212 23:00:42.216259  3050 net.cpp:252] TEST Top shape for layer 96 'ctx_output5/relu_mbox_conf_perm' 4 2 3 16 (384)
I0212 23:00:42.216265  3050 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_flat' of type 'Flatten'
I0212 23:00:42.216270  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.216277  3050 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_flat (97)
I0212 23:00:42.216284  3050 net.cpp:561] ctx_output5/relu_mbox_conf_flat <- ctx_output5/relu_mbox_conf_perm
I0212 23:00:42.216289  3050 net.cpp:530] ctx_output5/relu_mbox_conf_flat -> ctx_output5/relu_mbox_conf_flat
I0212 23:00:42.216336  3050 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_flat
I0212 23:00:42.216347  3050 net.cpp:252] TEST Top shape for layer 97 'ctx_output5/relu_mbox_conf_flat' 4 96 (384)
I0212 23:00:42.216353  3050 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_priorbox' of type 'PriorBox'
I0212 23:00:42.216359  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.216368  3050 net.cpp:184] Created Layer ctx_output5/relu_mbox_priorbox (98)
I0212 23:00:42.216373  3050 net.cpp:561] ctx_output5/relu_mbox_priorbox <- ctx_output5_ctx_output5/relu_0_split_2
I0212 23:00:42.216380  3050 net.cpp:561] ctx_output5/relu_mbox_priorbox <- data_data_0_split_5
I0212 23:00:42.216387  3050 net.cpp:530] ctx_output5/relu_mbox_priorbox -> ctx_output5/relu_mbox_priorbox
I0212 23:00:42.216437  3050 net.cpp:245] Setting up ctx_output5/relu_mbox_priorbox
I0212 23:00:42.216449  3050 net.cpp:252] TEST Top shape for layer 98 'ctx_output5/relu_mbox_priorbox' 1 2 96 (192)
I0212 23:00:42.216454  3050 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc' of type 'Convolution'
I0212 23:00:42.216460  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.216476  3050 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc (99)
I0212 23:00:42.216483  3050 net.cpp:561] ctx_output6/relu_mbox_loc <- ctx_output6_ctx_output6/relu_0_split_0
I0212 23:00:42.216490  3050 net.cpp:530] ctx_output6/relu_mbox_loc -> ctx_output6/relu_mbox_loc
I0212 23:00:42.217162  3050 net.cpp:245] Setting up ctx_output6/relu_mbox_loc
I0212 23:00:42.217176  3050 net.cpp:252] TEST Top shape for layer 99 'ctx_output6/relu_mbox_loc' 4 16 1 2 (128)
I0212 23:00:42.217185  3050 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_perm' of type 'Permute'
I0212 23:00:42.217191  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.217202  3050 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_perm (100)
I0212 23:00:42.217208  3050 net.cpp:561] ctx_output6/relu_mbox_loc_perm <- ctx_output6/relu_mbox_loc
I0212 23:00:42.217214  3050 net.cpp:530] ctx_output6/relu_mbox_loc_perm -> ctx_output6/relu_mbox_loc_perm
I0212 23:00:42.217424  3050 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_perm
I0212 23:00:42.217437  3050 net.cpp:252] TEST Top shape for layer 100 'ctx_output6/relu_mbox_loc_perm' 4 1 2 16 (128)
I0212 23:00:42.217442  3050 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_flat' of type 'Flatten'
I0212 23:00:42.217448  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.217455  3050 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_flat (101)
I0212 23:00:42.217460  3050 net.cpp:561] ctx_output6/relu_mbox_loc_flat <- ctx_output6/relu_mbox_loc_perm
I0212 23:00:42.217476  3050 net.cpp:530] ctx_output6/relu_mbox_loc_flat -> ctx_output6/relu_mbox_loc_flat
I0212 23:00:42.217525  3050 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_flat
I0212 23:00:42.217535  3050 net.cpp:252] TEST Top shape for layer 101 'ctx_output6/relu_mbox_loc_flat' 4 32 (128)
I0212 23:00:42.217542  3050 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf' of type 'Convolution'
I0212 23:00:42.217548  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.217566  3050 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf (102)
I0212 23:00:42.217573  3050 net.cpp:561] ctx_output6/relu_mbox_conf <- ctx_output6_ctx_output6/relu_0_split_1
I0212 23:00:42.217581  3050 net.cpp:530] ctx_output6/relu_mbox_conf -> ctx_output6/relu_mbox_conf
I0212 23:00:42.218253  3050 net.cpp:245] Setting up ctx_output6/relu_mbox_conf
I0212 23:00:42.218282  3050 net.cpp:252] TEST Top shape for layer 102 'ctx_output6/relu_mbox_conf' 4 16 1 2 (128)
I0212 23:00:42.218294  3050 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_perm' of type 'Permute'
I0212 23:00:42.218300  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.218312  3050 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_perm (103)
I0212 23:00:42.218317  3050 net.cpp:561] ctx_output6/relu_mbox_conf_perm <- ctx_output6/relu_mbox_conf
I0212 23:00:42.218323  3050 net.cpp:530] ctx_output6/relu_mbox_conf_perm -> ctx_output6/relu_mbox_conf_perm
I0212 23:00:42.218535  3050 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_perm
I0212 23:00:42.218547  3050 net.cpp:252] TEST Top shape for layer 103 'ctx_output6/relu_mbox_conf_perm' 4 1 2 16 (128)
I0212 23:00:42.218554  3050 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_flat' of type 'Flatten'
I0212 23:00:42.218559  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.218566  3050 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_flat (104)
I0212 23:00:42.218571  3050 net.cpp:561] ctx_output6/relu_mbox_conf_flat <- ctx_output6/relu_mbox_conf_perm
I0212 23:00:42.218578  3050 net.cpp:530] ctx_output6/relu_mbox_conf_flat -> ctx_output6/relu_mbox_conf_flat
I0212 23:00:42.241307  3050 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_flat
I0212 23:00:42.241333  3050 net.cpp:252] TEST Top shape for layer 104 'ctx_output6/relu_mbox_conf_flat' 4 32 (128)
I0212 23:00:42.241343  3050 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_priorbox' of type 'PriorBox'
I0212 23:00:42.241349  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.241364  3050 net.cpp:184] Created Layer ctx_output6/relu_mbox_priorbox (105)
I0212 23:00:42.241369  3050 net.cpp:561] ctx_output6/relu_mbox_priorbox <- ctx_output6_ctx_output6/relu_0_split_2
I0212 23:00:42.241377  3050 net.cpp:561] ctx_output6/relu_mbox_priorbox <- data_data_0_split_6
I0212 23:00:42.241384  3050 net.cpp:530] ctx_output6/relu_mbox_priorbox -> ctx_output6/relu_mbox_priorbox
I0212 23:00:42.241441  3050 net.cpp:245] Setting up ctx_output6/relu_mbox_priorbox
I0212 23:00:42.241452  3050 net.cpp:252] TEST Top shape for layer 105 'ctx_output6/relu_mbox_priorbox' 1 2 32 (64)
I0212 23:00:42.241458  3050 layer_factory.hpp:136] Creating layer 'mbox_loc' of type 'Concat'
I0212 23:00:42.241464  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.241474  3050 net.cpp:184] Created Layer mbox_loc (106)
I0212 23:00:42.241482  3050 net.cpp:561] mbox_loc <- ctx_output1/relu_mbox_loc_flat
I0212 23:00:42.241488  3050 net.cpp:561] mbox_loc <- ctx_output2/relu_mbox_loc_flat
I0212 23:00:42.241495  3050 net.cpp:561] mbox_loc <- ctx_output3/relu_mbox_loc_flat
I0212 23:00:42.241503  3050 net.cpp:561] mbox_loc <- ctx_output4/relu_mbox_loc_flat
I0212 23:00:42.241508  3050 net.cpp:561] mbox_loc <- ctx_output5/relu_mbox_loc_flat
I0212 23:00:42.241515  3050 net.cpp:561] mbox_loc <- ctx_output6/relu_mbox_loc_flat
I0212 23:00:42.241533  3050 net.cpp:530] mbox_loc -> mbox_loc
I0212 23:00:42.241591  3050 net.cpp:245] Setting up mbox_loc
I0212 23:00:42.241603  3050 net.cpp:252] TEST Top shape for layer 106 'mbox_loc' 4 75152 (300608)
I0212 23:00:42.241610  3050 layer_factory.hpp:136] Creating layer 'mbox_conf' of type 'Concat'
I0212 23:00:42.241614  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.241622  3050 net.cpp:184] Created Layer mbox_conf (107)
I0212 23:00:42.241628  3050 net.cpp:561] mbox_conf <- ctx_output1/relu_mbox_conf_flat
I0212 23:00:42.241634  3050 net.cpp:561] mbox_conf <- ctx_output2/relu_mbox_conf_flat
I0212 23:00:42.241641  3050 net.cpp:561] mbox_conf <- ctx_output3/relu_mbox_conf_flat
I0212 23:00:42.241647  3050 net.cpp:561] mbox_conf <- ctx_output4/relu_mbox_conf_flat
I0212 23:00:42.241653  3050 net.cpp:561] mbox_conf <- ctx_output5/relu_mbox_conf_flat
I0212 23:00:42.241658  3050 net.cpp:561] mbox_conf <- ctx_output6/relu_mbox_conf_flat
I0212 23:00:42.241664  3050 net.cpp:530] mbox_conf -> mbox_conf
I0212 23:00:42.241714  3050 net.cpp:245] Setting up mbox_conf
I0212 23:00:42.241724  3050 net.cpp:252] TEST Top shape for layer 107 'mbox_conf' 4 75152 (300608)
I0212 23:00:42.241729  3050 layer_factory.hpp:136] Creating layer 'mbox_priorbox' of type 'Concat'
I0212 23:00:42.241735  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.241745  3050 net.cpp:184] Created Layer mbox_priorbox (108)
I0212 23:00:42.241751  3050 net.cpp:561] mbox_priorbox <- ctx_output1/relu_mbox_priorbox
I0212 23:00:42.241757  3050 net.cpp:561] mbox_priorbox <- ctx_output2/relu_mbox_priorbox
I0212 23:00:42.241763  3050 net.cpp:561] mbox_priorbox <- ctx_output3/relu_mbox_priorbox
I0212 23:00:42.241770  3050 net.cpp:561] mbox_priorbox <- ctx_output4/relu_mbox_priorbox
I0212 23:00:42.241775  3050 net.cpp:561] mbox_priorbox <- ctx_output5/relu_mbox_priorbox
I0212 23:00:42.241781  3050 net.cpp:561] mbox_priorbox <- ctx_output6/relu_mbox_priorbox
I0212 23:00:42.241786  3050 net.cpp:530] mbox_priorbox -> mbox_priorbox
I0212 23:00:42.241834  3050 net.cpp:245] Setting up mbox_priorbox
I0212 23:00:42.241847  3050 net.cpp:252] TEST Top shape for layer 108 'mbox_priorbox' 1 2 75152 (150304)
I0212 23:00:42.241852  3050 layer_factory.hpp:136] Creating layer 'mbox_conf_reshape' of type 'Reshape'
I0212 23:00:42.241858  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.241869  3050 net.cpp:184] Created Layer mbox_conf_reshape (109)
I0212 23:00:42.241874  3050 net.cpp:561] mbox_conf_reshape <- mbox_conf
I0212 23:00:42.241880  3050 net.cpp:530] mbox_conf_reshape -> mbox_conf_reshape
I0212 23:00:42.241931  3050 net.cpp:245] Setting up mbox_conf_reshape
I0212 23:00:42.241943  3050 net.cpp:252] TEST Top shape for layer 109 'mbox_conf_reshape' 4 18788 4 (300608)
I0212 23:00:42.241950  3050 layer_factory.hpp:136] Creating layer 'mbox_conf_softmax' of type 'Softmax'
I0212 23:00:42.241955  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.241971  3050 net.cpp:184] Created Layer mbox_conf_softmax (110)
I0212 23:00:42.241976  3050 net.cpp:561] mbox_conf_softmax <- mbox_conf_reshape
I0212 23:00:42.241982  3050 net.cpp:530] mbox_conf_softmax -> mbox_conf_softmax
I0212 23:00:42.242110  3050 net.cpp:245] Setting up mbox_conf_softmax
I0212 23:00:42.242122  3050 net.cpp:252] TEST Top shape for layer 110 'mbox_conf_softmax' 4 18788 4 (300608)
I0212 23:00:42.242128  3050 layer_factory.hpp:136] Creating layer 'mbox_conf_flatten' of type 'Flatten'
I0212 23:00:42.242133  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.242141  3050 net.cpp:184] Created Layer mbox_conf_flatten (111)
I0212 23:00:42.242147  3050 net.cpp:561] mbox_conf_flatten <- mbox_conf_softmax
I0212 23:00:42.242153  3050 net.cpp:530] mbox_conf_flatten -> mbox_conf_flatten
I0212 23:00:42.242215  3050 net.cpp:245] Setting up mbox_conf_flatten
I0212 23:00:42.242226  3050 net.cpp:252] TEST Top shape for layer 111 'mbox_conf_flatten' 4 75152 (300608)
I0212 23:00:42.242233  3050 layer_factory.hpp:136] Creating layer 'detection_out' of type 'DetectionOutput'
I0212 23:00:42.242238  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.242255  3050 net.cpp:184] Created Layer detection_out (112)
I0212 23:00:42.242262  3050 net.cpp:561] detection_out <- mbox_loc
I0212 23:00:42.242287  3050 net.cpp:561] detection_out <- mbox_conf_flatten
I0212 23:00:42.242305  3050 net.cpp:561] detection_out <- mbox_priorbox
I0212 23:00:42.242316  3050 net.cpp:530] detection_out -> detection_out
I0212 23:00:42.252929  3050 net.cpp:245] Setting up detection_out
I0212 23:00:42.252971  3050 net.cpp:252] TEST Top shape for layer 112 'detection_out' 1 1 1 7 (7)
I0212 23:00:42.252987  3050 layer_factory.hpp:136] Creating layer 'detection_eval' of type 'DetectionEvaluate'
I0212 23:00:42.253000  3050 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0212 23:00:42.253024  3050 net.cpp:184] Created Layer detection_eval (113)
I0212 23:00:42.253037  3050 net.cpp:561] detection_eval <- detection_out
I0212 23:00:42.253051  3050 net.cpp:561] detection_eval <- label
I0212 23:00:42.253063  3050 net.cpp:530] detection_eval -> detection_eval
I0212 23:00:42.254812  3050 net.cpp:245] Setting up detection_eval
I0212 23:00:42.254824  3050 net.cpp:252] TEST Top shape for layer 113 'detection_eval' 1 1 4 5 (20)
I0212 23:00:42.254832  3050 net.cpp:325] detection_eval does not need backward computation.
I0212 23:00:42.254837  3050 net.cpp:325] detection_out does not need backward computation.
I0212 23:00:42.254842  3050 net.cpp:325] mbox_conf_flatten does not need backward computation.
I0212 23:00:42.254848  3050 net.cpp:325] mbox_conf_softmax does not need backward computation.
I0212 23:00:42.254853  3050 net.cpp:325] mbox_conf_reshape does not need backward computation.
I0212 23:00:42.254858  3050 net.cpp:325] mbox_priorbox does not need backward computation.
I0212 23:00:42.254864  3050 net.cpp:325] mbox_conf does not need backward computation.
I0212 23:00:42.254870  3050 net.cpp:325] mbox_loc does not need backward computation.
I0212 23:00:42.254878  3050 net.cpp:325] ctx_output6/relu_mbox_priorbox does not need backward computation.
I0212 23:00:42.254882  3050 net.cpp:325] ctx_output6/relu_mbox_conf_flat does not need backward computation.
I0212 23:00:42.254887  3050 net.cpp:325] ctx_output6/relu_mbox_conf_perm does not need backward computation.
I0212 23:00:42.254894  3050 net.cpp:325] ctx_output6/relu_mbox_conf does not need backward computation.
I0212 23:00:42.254899  3050 net.cpp:325] ctx_output6/relu_mbox_loc_flat does not need backward computation.
I0212 23:00:42.254904  3050 net.cpp:325] ctx_output6/relu_mbox_loc_perm does not need backward computation.
I0212 23:00:42.254909  3050 net.cpp:325] ctx_output6/relu_mbox_loc does not need backward computation.
I0212 23:00:42.254914  3050 net.cpp:325] ctx_output5/relu_mbox_priorbox does not need backward computation.
I0212 23:00:42.254920  3050 net.cpp:325] ctx_output5/relu_mbox_conf_flat does not need backward computation.
I0212 23:00:42.254923  3050 net.cpp:325] ctx_output5/relu_mbox_conf_perm does not need backward computation.
I0212 23:00:42.254928  3050 net.cpp:325] ctx_output5/relu_mbox_conf does not need backward computation.
I0212 23:00:42.254935  3050 net.cpp:325] ctx_output5/relu_mbox_loc_flat does not need backward computation.
I0212 23:00:42.254938  3050 net.cpp:325] ctx_output5/relu_mbox_loc_perm does not need backward computation.
I0212 23:00:42.254943  3050 net.cpp:325] ctx_output5/relu_mbox_loc does not need backward computation.
I0212 23:00:42.254950  3050 net.cpp:325] ctx_output4/relu_mbox_priorbox does not need backward computation.
I0212 23:00:42.254954  3050 net.cpp:325] ctx_output4/relu_mbox_conf_flat does not need backward computation.
I0212 23:00:42.254959  3050 net.cpp:325] ctx_output4/relu_mbox_conf_perm does not need backward computation.
I0212 23:00:42.254979  3050 net.cpp:325] ctx_output4/relu_mbox_conf does not need backward computation.
I0212 23:00:42.254986  3050 net.cpp:325] ctx_output4/relu_mbox_loc_flat does not need backward computation.
I0212 23:00:42.254990  3050 net.cpp:325] ctx_output4/relu_mbox_loc_perm does not need backward computation.
I0212 23:00:42.254995  3050 net.cpp:325] ctx_output4/relu_mbox_loc does not need backward computation.
I0212 23:00:42.255002  3050 net.cpp:325] ctx_output3/relu_mbox_priorbox does not need backward computation.
I0212 23:00:42.255007  3050 net.cpp:325] ctx_output3/relu_mbox_conf_flat does not need backward computation.
I0212 23:00:42.255012  3050 net.cpp:325] ctx_output3/relu_mbox_conf_perm does not need backward computation.
I0212 23:00:42.255017  3050 net.cpp:325] ctx_output3/relu_mbox_conf does not need backward computation.
I0212 23:00:42.255022  3050 net.cpp:325] ctx_output3/relu_mbox_loc_flat does not need backward computation.
I0212 23:00:42.255026  3050 net.cpp:325] ctx_output3/relu_mbox_loc_perm does not need backward computation.
I0212 23:00:42.255034  3050 net.cpp:325] ctx_output3/relu_mbox_loc does not need backward computation.
I0212 23:00:42.255040  3050 net.cpp:325] ctx_output2/relu_mbox_priorbox does not need backward computation.
I0212 23:00:42.255046  3050 net.cpp:325] ctx_output2/relu_mbox_conf_flat does not need backward computation.
I0212 23:00:42.255053  3050 net.cpp:325] ctx_output2/relu_mbox_conf_perm does not need backward computation.
I0212 23:00:42.255058  3050 net.cpp:325] ctx_output2/relu_mbox_conf does not need backward computation.
I0212 23:00:42.255062  3050 net.cpp:325] ctx_output2/relu_mbox_loc_flat does not need backward computation.
I0212 23:00:42.255067  3050 net.cpp:325] ctx_output2/relu_mbox_loc_perm does not need backward computation.
I0212 23:00:42.255074  3050 net.cpp:325] ctx_output2/relu_mbox_loc does not need backward computation.
I0212 23:00:42.255079  3050 net.cpp:325] ctx_output1/relu_mbox_priorbox does not need backward computation.
I0212 23:00:42.255084  3050 net.cpp:325] ctx_output1/relu_mbox_conf_flat does not need backward computation.
I0212 23:00:42.255090  3050 net.cpp:325] ctx_output1/relu_mbox_conf_perm does not need backward computation.
I0212 23:00:42.255095  3050 net.cpp:325] ctx_output1/relu_mbox_conf does not need backward computation.
I0212 23:00:42.255100  3050 net.cpp:325] ctx_output1/relu_mbox_loc_flat does not need backward computation.
I0212 23:00:42.255105  3050 net.cpp:325] ctx_output1/relu_mbox_loc_perm does not need backward computation.
I0212 23:00:42.255110  3050 net.cpp:325] ctx_output1/relu_mbox_loc does not need backward computation.
I0212 23:00:42.255116  3050 net.cpp:325] ctx_output6_ctx_output6/relu_0_split does not need backward computation.
I0212 23:00:42.255121  3050 net.cpp:325] ctx_output6/relu does not need backward computation.
I0212 23:00:42.255127  3050 net.cpp:325] ctx_output6 does not need backward computation.
I0212 23:00:42.255132  3050 net.cpp:325] ctx_output5_ctx_output5/relu_0_split does not need backward computation.
I0212 23:00:42.255137  3050 net.cpp:325] ctx_output5/relu does not need backward computation.
I0212 23:00:42.255142  3050 net.cpp:325] ctx_output5 does not need backward computation.
I0212 23:00:42.255148  3050 net.cpp:325] ctx_output4_ctx_output4/relu_0_split does not need backward computation.
I0212 23:00:42.255153  3050 net.cpp:325] ctx_output4/relu does not need backward computation.
I0212 23:00:42.255158  3050 net.cpp:325] ctx_output4 does not need backward computation.
I0212 23:00:42.255163  3050 net.cpp:325] ctx_output3_ctx_output3/relu_0_split does not need backward computation.
I0212 23:00:42.255168  3050 net.cpp:325] ctx_output3/relu does not need backward computation.
I0212 23:00:42.255173  3050 net.cpp:325] ctx_output3 does not need backward computation.
I0212 23:00:42.255179  3050 net.cpp:325] ctx_output2_ctx_output2/relu_0_split does not need backward computation.
I0212 23:00:42.255184  3050 net.cpp:325] ctx_output2/relu does not need backward computation.
I0212 23:00:42.255195  3050 net.cpp:325] ctx_output2 does not need backward computation.
I0212 23:00:42.255201  3050 net.cpp:325] ctx_output1_ctx_output1/relu_0_split does not need backward computation.
I0212 23:00:42.255208  3050 net.cpp:325] ctx_output1/relu does not need backward computation.
I0212 23:00:42.255213  3050 net.cpp:325] ctx_output1 does not need backward computation.
I0212 23:00:42.255218  3050 net.cpp:325] pool9 does not need backward computation.
I0212 23:00:42.255223  3050 net.cpp:325] pool8_pool8_0_split does not need backward computation.
I0212 23:00:42.255228  3050 net.cpp:325] pool8 does not need backward computation.
I0212 23:00:42.255234  3050 net.cpp:325] pool7_pool7_0_split does not need backward computation.
I0212 23:00:42.255239  3050 net.cpp:325] pool7 does not need backward computation.
I0212 23:00:42.255244  3050 net.cpp:325] pool6_pool6_0_split does not need backward computation.
I0212 23:00:42.255249  3050 net.cpp:325] pool6 does not need backward computation.
I0212 23:00:42.255254  3050 net.cpp:325] res5a_branch2b_res5a_branch2b/relu_0_split does not need backward computation.
I0212 23:00:42.255259  3050 net.cpp:325] res5a_branch2b/relu does not need backward computation.
I0212 23:00:42.255264  3050 net.cpp:325] res5a_branch2b/bn does not need backward computation.
I0212 23:00:42.255270  3050 net.cpp:325] res5a_branch2b does not need backward computation.
I0212 23:00:42.255275  3050 net.cpp:325] res5a_branch2a/relu does not need backward computation.
I0212 23:00:42.255280  3050 net.cpp:325] res5a_branch2a/bn does not need backward computation.
I0212 23:00:42.255285  3050 net.cpp:325] res5a_branch2a does not need backward computation.
I0212 23:00:42.255290  3050 net.cpp:325] pool4 does not need backward computation.
I0212 23:00:42.255297  3050 net.cpp:325] res4a_branch2b/relu does not need backward computation.
I0212 23:00:42.255303  3050 net.cpp:325] res4a_branch2b/bn does not need backward computation.
I0212 23:00:42.255308  3050 net.cpp:325] res4a_branch2b does not need backward computation.
I0212 23:00:42.276087  3050 net.cpp:325] res4a_branch2a/relu does not need backward computation.
I0212 23:00:42.276114  3050 net.cpp:325] res4a_branch2a/bn does not need backward computation.
I0212 23:00:42.276126  3050 net.cpp:325] res4a_branch2a does not need backward computation.
I0212 23:00:42.276141  3050 net.cpp:325] pool3 does not need backward computation.
I0212 23:00:42.276152  3050 net.cpp:325] res3a_branch2b_res3a_branch2b/relu_0_split does not need backward computation.
I0212 23:00:42.276162  3050 net.cpp:325] res3a_branch2b/relu does not need backward computation.
I0212 23:00:42.276172  3050 net.cpp:325] res3a_branch2b/bn does not need backward computation.
I0212 23:00:42.276181  3050 net.cpp:325] res3a_branch2b does not need backward computation.
I0212 23:00:42.276191  3050 net.cpp:325] res3a_branch2a/relu does not need backward computation.
I0212 23:00:42.276201  3050 net.cpp:325] res3a_branch2a/bn does not need backward computation.
I0212 23:00:42.276211  3050 net.cpp:325] res3a_branch2a does not need backward computation.
I0212 23:00:42.276219  3050 net.cpp:325] pool2 does not need backward computation.
I0212 23:00:42.276229  3050 net.cpp:325] res2a_branch2b/relu does not need backward computation.
I0212 23:00:42.276238  3050 net.cpp:325] res2a_branch2b/bn does not need backward computation.
I0212 23:00:42.276247  3050 net.cpp:325] res2a_branch2b does not need backward computation.
I0212 23:00:42.276257  3050 net.cpp:325] res2a_branch2a/relu does not need backward computation.
I0212 23:00:42.276266  3050 net.cpp:325] res2a_branch2a/bn does not need backward computation.
I0212 23:00:42.276275  3050 net.cpp:325] res2a_branch2a does not need backward computation.
I0212 23:00:42.276285  3050 net.cpp:325] pool1 does not need backward computation.
I0212 23:00:42.276295  3050 net.cpp:325] conv1b/relu does not need backward computation.
I0212 23:00:42.276304  3050 net.cpp:325] conv1b/bn does not need backward computation.
I0212 23:00:42.276314  3050 net.cpp:325] conv1b does not need backward computation.
I0212 23:00:42.276341  3050 net.cpp:325] conv1a/relu does not need backward computation.
I0212 23:00:42.276352  3050 net.cpp:325] conv1a/bn does not need backward computation.
I0212 23:00:42.276361  3050 net.cpp:325] conv1a does not need backward computation.
I0212 23:00:42.276372  3050 net.cpp:325] data/bias does not need backward computation.
I0212 23:00:42.276384  3050 net.cpp:325] data_data_0_split does not need backward computation.
I0212 23:00:42.276396  3050 net.cpp:325] data does not need backward computation.
I0212 23:00:42.276403  3050 net.cpp:367] This network produces output detection_eval
I0212 23:00:42.276593  3050 net.cpp:389] Top memory (TEST) required for data: 656271440 diff: 656271440
I0212 23:00:42.276607  3050 net.cpp:392] Bottom memory (TEST) required for data: 656271360 diff: 656271360
I0212 23:00:42.276617  3050 net.cpp:395] Shared (in-place) memory (TEST) by data: 281894912 diff: 281894912
I0212 23:00:42.276624  3050 net.cpp:398] Parameters memory (TEST) required for data: 12464288 diff: 12464288
I0212 23:00:42.276633  3050 net.cpp:401] Parameters shared memory (TEST) by data: 0 diff: 0
I0212 23:00:42.276643  3050 net.cpp:407] Network initialization done.
I0212 23:00:42.277184  3050 solver.cpp:57] Solver scaffolding done.
I0212 23:00:42.291098  3050 caffe.cpp:143] Finetuning from training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_10000_55.92.caffemodel
I0212 23:00:42.365959  3050 net.cpp:1094] Copying source layer data Type:AnnotatedData #blobs=0
I0212 23:00:42.365998  3050 net.cpp:1094] Copying source layer data_data_0_split Type:Split #blobs=0
I0212 23:00:42.366005  3050 net.cpp:1094] Copying source layer data/bias Type:Bias #blobs=1
I0212 23:00:42.366063  3050 net.cpp:1094] Copying source layer conv1a Type:Convolution #blobs=2
I0212 23:00:42.366096  3050 net.cpp:1094] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0212 23:00:42.366539  3050 net.cpp:1094] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0212 23:00:42.366552  3050 net.cpp:1094] Copying source layer conv1b Type:Convolution #blobs=2
I0212 23:00:42.366571  3050 net.cpp:1094] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0212 23:00:42.366849  3050 net.cpp:1094] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0212 23:00:42.366861  3050 net.cpp:1094] Copying source layer pool1 Type:Pooling #blobs=0
I0212 23:00:42.366866  3050 net.cpp:1094] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0212 23:00:42.366896  3050 net.cpp:1094] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0212 23:00:42.367131  3050 net.cpp:1094] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0212 23:00:42.367142  3050 net.cpp:1094] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0212 23:00:42.367166  3050 net.cpp:1094] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0212 23:00:42.367395  3050 net.cpp:1094] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0212 23:00:42.367405  3050 net.cpp:1094] Copying source layer pool2 Type:Pooling #blobs=0
I0212 23:00:42.367410  3050 net.cpp:1094] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0212 23:00:42.367472  3050 net.cpp:1094] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0212 23:00:42.367681  3050 net.cpp:1094] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0212 23:00:42.367692  3050 net.cpp:1094] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0212 23:00:42.367732  3050 net.cpp:1094] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0212 23:00:42.367929  3050 net.cpp:1094] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0212 23:00:42.367939  3050 net.cpp:1094] Copying source layer res3a_branch2b_res3a_branch2b/relu_0_split Type:Split #blobs=0
I0212 23:00:42.367944  3050 net.cpp:1094] Copying source layer pool3 Type:Pooling #blobs=0
I0212 23:00:42.367962  3050 net.cpp:1094] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0212 23:00:42.368150  3050 net.cpp:1094] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0212 23:00:42.368356  3050 net.cpp:1094] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0212 23:00:42.368366  3050 net.cpp:1094] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0212 23:00:42.368472  3050 net.cpp:1094] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0212 23:00:42.368674  3050 net.cpp:1094] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0212 23:00:42.368683  3050 net.cpp:1094] Copying source layer pool4 Type:Pooling #blobs=0
I0212 23:00:42.368688  3050 net.cpp:1094] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0212 23:00:42.369364  3050 net.cpp:1094] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0212 23:00:42.369593  3050 net.cpp:1094] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0212 23:00:42.369604  3050 net.cpp:1094] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0212 23:00:42.369930  3050 net.cpp:1094] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0212 23:00:42.370122  3050 net.cpp:1094] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0212 23:00:42.370133  3050 net.cpp:1094] Copying source layer res5a_branch2b_res5a_branch2b/relu_0_split Type:Split #blobs=0
I0212 23:00:42.370138  3050 net.cpp:1094] Copying source layer pool6 Type:Pooling #blobs=0
I0212 23:00:42.370143  3050 net.cpp:1094] Copying source layer pool6_pool6_0_split Type:Split #blobs=0
I0212 23:00:42.370148  3050 net.cpp:1094] Copying source layer pool7 Type:Pooling #blobs=0
I0212 23:00:42.370153  3050 net.cpp:1094] Copying source layer pool7_pool7_0_split Type:Split #blobs=0
I0212 23:00:42.370157  3050 net.cpp:1094] Copying source layer pool8 Type:Pooling #blobs=0
I0212 23:00:42.370162  3050 net.cpp:1094] Copying source layer pool8_pool8_0_split Type:Split #blobs=0
I0212 23:00:42.370167  3050 net.cpp:1094] Copying source layer pool9 Type:Pooling #blobs=0
I0212 23:00:42.370172  3050 net.cpp:1094] Copying source layer ctx_output1 Type:Convolution #blobs=2
I0212 23:00:42.370210  3050 net.cpp:1094] Copying source layer ctx_output1/relu Type:ReLU #blobs=0
I0212 23:00:42.370219  3050 net.cpp:1094] Copying source layer ctx_output1_ctx_output1/relu_0_split Type:Split #blobs=0
I0212 23:00:42.370224  3050 net.cpp:1094] Copying source layer ctx_output2 Type:Convolution #blobs=2
I0212 23:00:42.370331  3050 net.cpp:1094] Copying source layer ctx_output2/relu Type:ReLU #blobs=0
I0212 23:00:42.370342  3050 net.cpp:1094] Copying source layer ctx_output2_ctx_output2/relu_0_split Type:Split #blobs=0
I0212 23:00:42.370347  3050 net.cpp:1094] Copying source layer ctx_output3 Type:Convolution #blobs=2
I0212 23:00:42.370434  3050 net.cpp:1094] Copying source layer ctx_output3/relu Type:ReLU #blobs=0
I0212 23:00:42.370443  3050 net.cpp:1094] Copying source layer ctx_output3_ctx_output3/relu_0_split Type:Split #blobs=0
I0212 23:00:42.370448  3050 net.cpp:1094] Copying source layer ctx_output4 Type:Convolution #blobs=2
I0212 23:00:42.370538  3050 net.cpp:1094] Copying source layer ctx_output4/relu Type:ReLU #blobs=0
I0212 23:00:42.370548  3050 net.cpp:1094] Copying source layer ctx_output4_ctx_output4/relu_0_split Type:Split #blobs=0
I0212 23:00:42.370553  3050 net.cpp:1094] Copying source layer ctx_output5 Type:Convolution #blobs=2
I0212 23:00:42.370642  3050 net.cpp:1094] Copying source layer ctx_output5/relu Type:ReLU #blobs=0
I0212 23:00:42.370651  3050 net.cpp:1094] Copying source layer ctx_output5_ctx_output5/relu_0_split Type:Split #blobs=0
I0212 23:00:42.370656  3050 net.cpp:1094] Copying source layer ctx_output6 Type:Convolution #blobs=2
I0212 23:00:42.370746  3050 net.cpp:1094] Copying source layer ctx_output6/relu Type:ReLU #blobs=0
I0212 23:00:42.370755  3050 net.cpp:1094] Copying source layer ctx_output6_ctx_output6/relu_0_split Type:Split #blobs=0
I0212 23:00:42.370760  3050 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc Type:Convolution #blobs=2
I0212 23:00:42.370805  3050 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc_perm Type:Permute #blobs=0
I0212 23:00:42.370811  3050 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc_flat Type:Flatten #blobs=0
I0212 23:00:42.370816  3050 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf Type:Convolution #blobs=2
I0212 23:00:42.370836  3050 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf_perm Type:Permute #blobs=0
I0212 23:00:42.370842  3050 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf_flat Type:Flatten #blobs=0
I0212 23:00:42.370847  3050 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_priorbox Type:PriorBox #blobs=0
I0212 23:00:42.370852  3050 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc Type:Convolution #blobs=2
I0212 23:00:42.370872  3050 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc_perm Type:Permute #blobs=0
I0212 23:00:42.370879  3050 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc_flat Type:Flatten #blobs=0
I0212 23:00:42.370884  3050 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf Type:Convolution #blobs=2
I0212 23:00:42.370904  3050 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf_perm Type:Permute #blobs=0
I0212 23:00:42.370913  3050 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf_flat Type:Flatten #blobs=0
I0212 23:00:42.370918  3050 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_priorbox Type:PriorBox #blobs=0
I0212 23:00:42.370921  3050 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc Type:Convolution #blobs=2
I0212 23:00:42.370942  3050 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc_perm Type:Permute #blobs=0
I0212 23:00:42.370949  3050 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc_flat Type:Flatten #blobs=0
I0212 23:00:42.370954  3050 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf Type:Convolution #blobs=2
I0212 23:00:42.370975  3050 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf_perm Type:Permute #blobs=0
I0212 23:00:42.370981  3050 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf_flat Type:Flatten #blobs=0
I0212 23:00:42.370987  3050 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_priorbox Type:PriorBox #blobs=0
I0212 23:00:42.370991  3050 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc Type:Convolution #blobs=2
I0212 23:00:42.371012  3050 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc_perm Type:Permute #blobs=0
I0212 23:00:42.371019  3050 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc_flat Type:Flatten #blobs=0
I0212 23:00:42.371024  3050 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf Type:Convolution #blobs=2
I0212 23:00:42.371043  3050 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf_perm Type:Permute #blobs=0
I0212 23:00:42.371050  3050 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf_flat Type:Flatten #blobs=0
I0212 23:00:42.371055  3050 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_priorbox Type:PriorBox #blobs=0
I0212 23:00:42.371060  3050 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc Type:Convolution #blobs=2
I0212 23:00:42.371079  3050 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc_perm Type:Permute #blobs=0
I0212 23:00:42.371086  3050 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc_flat Type:Flatten #blobs=0
I0212 23:00:42.371090  3050 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf Type:Convolution #blobs=2
I0212 23:00:42.371109  3050 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf_perm Type:Permute #blobs=0
I0212 23:00:42.371116  3050 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf_flat Type:Flatten #blobs=0
I0212 23:00:42.371121  3050 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_priorbox Type:PriorBox #blobs=0
I0212 23:00:42.371126  3050 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc Type:Convolution #blobs=2
I0212 23:00:42.371155  3050 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc_perm Type:Permute #blobs=0
I0212 23:00:42.371163  3050 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc_flat Type:Flatten #blobs=0
I0212 23:00:42.371168  3050 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf Type:Convolution #blobs=2
I0212 23:00:42.371187  3050 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf_perm Type:Permute #blobs=0
I0212 23:00:42.371194  3050 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf_flat Type:Flatten #blobs=0
I0212 23:00:42.371199  3050 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_priorbox Type:PriorBox #blobs=0
I0212 23:00:42.371204  3050 net.cpp:1094] Copying source layer mbox_loc Type:Concat #blobs=0
I0212 23:00:42.371208  3050 net.cpp:1094] Copying source layer mbox_conf Type:Concat #blobs=0
I0212 23:00:42.371213  3050 net.cpp:1094] Copying source layer mbox_priorbox Type:Concat #blobs=0
I0212 23:00:42.371218  3050 net.cpp:1094] Copying source layer mbox_loss Type:MultiBoxLoss #blobs=0
I0212 23:00:42.377552  3050 net.cpp:1094] Copying source layer data Type:AnnotatedData #blobs=0
I0212 23:00:42.377581  3050 net.cpp:1094] Copying source layer data_data_0_split Type:Split #blobs=0
I0212 23:00:42.377586  3050 net.cpp:1094] Copying source layer data/bias Type:Bias #blobs=1
I0212 23:00:42.377629  3050 net.cpp:1094] Copying source layer conv1a Type:Convolution #blobs=2
I0212 23:00:42.377650  3050 net.cpp:1094] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0212 23:00:42.377962  3050 net.cpp:1094] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0212 23:00:42.377974  3050 net.cpp:1094] Copying source layer conv1b Type:Convolution #blobs=2
I0212 23:00:42.377991  3050 net.cpp:1094] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0212 23:00:42.378222  3050 net.cpp:1094] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0212 23:00:42.378233  3050 net.cpp:1094] Copying source layer pool1 Type:Pooling #blobs=0
I0212 23:00:42.378238  3050 net.cpp:1094] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0212 23:00:42.378268  3050 net.cpp:1094] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0212 23:00:42.378520  3050 net.cpp:1094] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0212 23:00:42.378531  3050 net.cpp:1094] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0212 23:00:42.378554  3050 net.cpp:1094] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0212 23:00:42.378777  3050 net.cpp:1094] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0212 23:00:42.378787  3050 net.cpp:1094] Copying source layer pool2 Type:Pooling #blobs=0
I0212 23:00:42.378793  3050 net.cpp:1094] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0212 23:00:42.378852  3050 net.cpp:1094] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0212 23:00:42.379057  3050 net.cpp:1094] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0212 23:00:42.379067  3050 net.cpp:1094] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0212 23:00:42.379106  3050 net.cpp:1094] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0212 23:00:42.379298  3050 net.cpp:1094] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0212 23:00:42.379307  3050 net.cpp:1094] Copying source layer res3a_branch2b_res3a_branch2b/relu_0_split Type:Split #blobs=0
I0212 23:00:42.379312  3050 net.cpp:1094] Copying source layer pool3 Type:Pooling #blobs=0
I0212 23:00:42.379317  3050 net.cpp:1094] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0212 23:00:42.379503  3050 net.cpp:1094] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0212 23:00:42.379699  3050 net.cpp:1094] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0212 23:00:42.379709  3050 net.cpp:1094] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0212 23:00:42.379808  3050 net.cpp:1094] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0212 23:00:42.380026  3050 net.cpp:1094] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0212 23:00:42.380038  3050 net.cpp:1094] Copying source layer pool4 Type:Pooling #blobs=0
I0212 23:00:42.380041  3050 net.cpp:1094] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0212 23:00:42.380669  3050 net.cpp:1094] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0212 23:00:42.380873  3050 net.cpp:1094] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0212 23:00:42.380884  3050 net.cpp:1094] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0212 23:00:42.381192  3050 net.cpp:1094] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0212 23:00:42.381382  3050 net.cpp:1094] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0212 23:00:42.381392  3050 net.cpp:1094] Copying source layer res5a_branch2b_res5a_branch2b/relu_0_split Type:Split #blobs=0
I0212 23:00:42.381397  3050 net.cpp:1094] Copying source layer pool6 Type:Pooling #blobs=0
I0212 23:00:42.381402  3050 net.cpp:1094] Copying source layer pool6_pool6_0_split Type:Split #blobs=0
I0212 23:00:42.381407  3050 net.cpp:1094] Copying source layer pool7 Type:Pooling #blobs=0
I0212 23:00:42.381412  3050 net.cpp:1094] Copying source layer pool7_pool7_0_split Type:Split #blobs=0
I0212 23:00:42.381417  3050 net.cpp:1094] Copying source layer pool8 Type:Pooling #blobs=0
I0212 23:00:42.381420  3050 net.cpp:1094] Copying source layer pool8_pool8_0_split Type:Split #blobs=0
I0212 23:00:42.381425  3050 net.cpp:1094] Copying source layer pool9 Type:Pooling #blobs=0
I0212 23:00:42.381429  3050 net.cpp:1094] Copying source layer ctx_output1 Type:Convolution #blobs=2
I0212 23:00:42.381465  3050 net.cpp:1094] Copying source layer ctx_output1/relu Type:ReLU #blobs=0
I0212 23:00:42.381474  3050 net.cpp:1094] Copying source layer ctx_output1_ctx_output1/relu_0_split Type:Split #blobs=0
I0212 23:00:42.381480  3050 net.cpp:1094] Copying source layer ctx_output2 Type:Convolution #blobs=2
I0212 23:00:42.381567  3050 net.cpp:1094] Copying source layer ctx_output2/relu Type:ReLU #blobs=0
I0212 23:00:42.381577  3050 net.cpp:1094] Copying source layer ctx_output2_ctx_output2/relu_0_split Type:Split #blobs=0
I0212 23:00:42.381582  3050 net.cpp:1094] Copying source layer ctx_output3 Type:Convolution #blobs=2
I0212 23:00:42.381666  3050 net.cpp:1094] Copying source layer ctx_output3/relu Type:ReLU #blobs=0
I0212 23:00:42.381676  3050 net.cpp:1094] Copying source layer ctx_output3_ctx_output3/relu_0_split Type:Split #blobs=0
I0212 23:00:42.381680  3050 net.cpp:1094] Copying source layer ctx_output4 Type:Convolution #blobs=2
I0212 23:00:42.381764  3050 net.cpp:1094] Copying source layer ctx_output4/relu Type:ReLU #blobs=0
I0212 23:00:42.381773  3050 net.cpp:1094] Copying source layer ctx_output4_ctx_output4/relu_0_split Type:Split #blobs=0
I0212 23:00:42.381778  3050 net.cpp:1094] Copying source layer ctx_output5 Type:Convolution #blobs=2
I0212 23:00:42.381862  3050 net.cpp:1094] Copying source layer ctx_output5/relu Type:ReLU #blobs=0
I0212 23:00:42.381871  3050 net.cpp:1094] Copying source layer ctx_output5_ctx_output5/relu_0_split Type:Split #blobs=0
I0212 23:00:42.381876  3050 net.cpp:1094] Copying source layer ctx_output6 Type:Convolution #blobs=2
I0212 23:00:42.381959  3050 net.cpp:1094] Copying source layer ctx_output6/relu Type:ReLU #blobs=0
I0212 23:00:42.381969  3050 net.cpp:1094] Copying source layer ctx_output6_ctx_output6/relu_0_split Type:Split #blobs=0
I0212 23:00:42.381974  3050 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc Type:Convolution #blobs=2
I0212 23:00:42.381994  3050 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc_perm Type:Permute #blobs=0
I0212 23:00:42.382000  3050 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc_flat Type:Flatten #blobs=0
I0212 23:00:42.382005  3050 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf Type:Convolution #blobs=2
I0212 23:00:42.382024  3050 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf_perm Type:Permute #blobs=0
I0212 23:00:42.382048  3050 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf_flat Type:Flatten #blobs=0
I0212 23:00:42.382055  3050 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_priorbox Type:PriorBox #blobs=0
I0212 23:00:42.382059  3050 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc Type:Convolution #blobs=2
I0212 23:00:42.382081  3050 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc_perm Type:Permute #blobs=0
I0212 23:00:42.382088  3050 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc_flat Type:Flatten #blobs=0
I0212 23:00:42.382092  3050 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf Type:Convolution #blobs=2
I0212 23:00:42.382112  3050 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf_perm Type:Permute #blobs=0
I0212 23:00:42.382119  3050 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf_flat Type:Flatten #blobs=0
I0212 23:00:42.382123  3050 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_priorbox Type:PriorBox #blobs=0
I0212 23:00:42.382128  3050 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc Type:Convolution #blobs=2
I0212 23:00:42.382148  3050 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc_perm Type:Permute #blobs=0
I0212 23:00:42.382154  3050 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc_flat Type:Flatten #blobs=0
I0212 23:00:42.382159  3050 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf Type:Convolution #blobs=2
I0212 23:00:42.382179  3050 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf_perm Type:Permute #blobs=0
I0212 23:00:42.382185  3050 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf_flat Type:Flatten #blobs=0
I0212 23:00:42.382190  3050 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_priorbox Type:PriorBox #blobs=0
I0212 23:00:42.382195  3050 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc Type:Convolution #blobs=2
I0212 23:00:42.382216  3050 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc_perm Type:Permute #blobs=0
I0212 23:00:42.382223  3050 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc_flat Type:Flatten #blobs=0
I0212 23:00:42.382227  3050 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf Type:Convolution #blobs=2
I0212 23:00:42.382247  3050 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf_perm Type:Permute #blobs=0
I0212 23:00:42.382254  3050 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf_flat Type:Flatten #blobs=0
I0212 23:00:42.382258  3050 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_priorbox Type:PriorBox #blobs=0
I0212 23:00:42.382263  3050 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc Type:Convolution #blobs=2
I0212 23:00:42.382305  3050 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc_perm Type:Permute #blobs=0
I0212 23:00:42.382314  3050 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc_flat Type:Flatten #blobs=0
I0212 23:00:42.382319  3050 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf Type:Convolution #blobs=2
I0212 23:00:42.382339  3050 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf_perm Type:Permute #blobs=0
I0212 23:00:42.382346  3050 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf_flat Type:Flatten #blobs=0
I0212 23:00:42.382351  3050 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_priorbox Type:PriorBox #blobs=0
I0212 23:00:42.382356  3050 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc Type:Convolution #blobs=2
I0212 23:00:42.382375  3050 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc_perm Type:Permute #blobs=0
I0212 23:00:42.382382  3050 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc_flat Type:Flatten #blobs=0
I0212 23:00:42.382387  3050 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf Type:Convolution #blobs=2
I0212 23:00:42.382405  3050 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf_perm Type:Permute #blobs=0
I0212 23:00:42.382421  3050 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf_flat Type:Flatten #blobs=0
I0212 23:00:42.382427  3050 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_priorbox Type:PriorBox #blobs=0
I0212 23:00:42.382432  3050 net.cpp:1094] Copying source layer mbox_loc Type:Concat #blobs=0
I0212 23:00:42.382437  3050 net.cpp:1094] Copying source layer mbox_conf Type:Concat #blobs=0
I0212 23:00:42.382441  3050 net.cpp:1094] Copying source layer mbox_priorbox Type:Concat #blobs=0
I0212 23:00:42.382447  3050 net.cpp:1078] Ignoring source layer mbox_loss
I0212 23:00:42.382659  3050 parallel.cpp:106] [0 - 0] P2pSync adding callback
I0212 23:00:42.382671  3050 parallel.cpp:106] [1 - 1] P2pSync adding callback
I0212 23:00:42.382675  3050 parallel.cpp:59] Starting Optimization
I0212 23:00:42.382680  3050 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0212 23:00:42.382726  3050 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0212 23:00:42.384363  3135 device_alternate.hpp:116] NVML initialized on thread 140631355655936
I0212 23:00:42.416517  3135 common.cpp:585] NVML succeeded to set CPU affinity on device 0
I0212 23:00:42.416615  3136 device_alternate.hpp:116] NVML initialized on thread 140631347263232
I0212 23:00:42.418180  3136 common.cpp:585] NVML succeeded to set CPU affinity on device 1
I0212 23:00:42.426414  3136 solver.cpp:43] Solver data type: FLOAT
I0212 23:00:42.429435  3136 net.cpp:104] Using FLOAT as default forward math type
I0212 23:00:42.429452  3136 net.cpp:110] Using FLOAT as default backward math type
I0212 23:00:42.429564  3136 data_reader.cpp:58] Data Reader threads: 4, out queues: 16, depth: 8
I0212 23:00:42.429611  3136 internal_thread.cpp:19] Starting 4 internal thread(s) on device 1
I0212 23:00:42.435174  3137 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0212 23:00:42.436120  3138 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0212 23:00:42.436779  3140 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0212 23:00:42.437433  3139 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0212 23:00:42.447888  3136 annotated_data_layer.cpp:219] output data size: 8,3,368,720
I0212 23:00:42.448256  3136 annotated_data_layer.cpp:265] [1] Output data size: 8, 3, 368, 720
I0212 23:00:42.448316  3136 internal_thread.cpp:19] Starting 4 internal thread(s) on device 1
I0212 23:00:43.163552  3136 solver.cpp:177] Creating test net (#0) specified by test_net file: training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/test.prototxt
I0212 23:00:43.164269  3136 net.cpp:104] Using FLOAT as default forward math type
I0212 23:00:43.164283  3136 net.cpp:110] Using FLOAT as default backward math type
I0212 23:00:43.164315  3136 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 4
I0212 23:00:43.164328  3136 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0212 23:00:43.166225  3145 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_test_lmdb
I0212 23:00:43.176929  3136 annotated_data_layer.cpp:219] output data size: 4,3,368,720
I0212 23:00:43.177027  3136 annotated_data_layer.cpp:265] (1) Output data size: 4, 3, 368, 720
I0212 23:00:43.177098  3136 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0212 23:00:43.178802  3146 annotated_data_layer.cpp:111] (1) Parser threads: 1
I0212 23:00:43.178824  3146 annotated_data_layer.cpp:113] (1) Transformer threads: 1
I0212 23:00:43.320041  3136 solver.cpp:57] Solver scaffolding done.
I0212 23:00:43.339762  3136 parallel.cpp:161] [1 - 1] P2pSync adding callback
I0212 23:00:43.339763  3135 parallel.cpp:161] [0 - 0] P2pSync adding callback
I0212 23:00:43.538477  3136 solver.cpp:489] Solving ssdJacintoNetV2
I0212 23:00:43.538485  3135 solver.cpp:489] Solving ssdJacintoNetV2
I0212 23:00:43.538512  3136 solver.cpp:490] Learning Rate Policy: poly
I0212 23:00:43.538518  3135 solver.cpp:490] Learning Rate Policy: poly
I0212 23:00:43.548089  3136 net.cpp:1412] [1] Reserving 12451584 bytes of shared learnable space
I0212 23:00:43.549417  3135 net.cpp:1412] [0] Reserving 12451584 bytes of shared learnable space
I0212 23:00:43.554872  3136 solver.cpp:228] Starting Optimization on GPU 1
I0212 23:00:43.554874  3135 solver.cpp:228] Starting Optimization on GPU 0
I0212 23:00:43.556658  3135 solver.cpp:666] Iteration 0, Testing net (#0)
I0212 23:00:43.556680  3147 device_alternate.hpp:116] NVML initialized on thread 140610031834880
I0212 23:00:43.556725  3147 common.cpp:585] NVML succeeded to set CPU affinity on device 1
I0212 23:00:43.556754  3148 device_alternate.hpp:116] NVML initialized on thread 140610023442176
I0212 23:00:43.556802  3148 common.cpp:585] NVML succeeded to set CPU affinity on device 0
I0212 23:00:43.565042  3136 net.cpp:1012] Ignoring source layer mbox_loss
I0212 23:00:43.569111  3135 net.cpp:1012] Ignoring source layer mbox_loss
I0212 23:00:43.728595  3136 blocking_queue.cpp:40] Data layer prefetch queue empty
I0212 23:00:43.798732  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'conv1a' with space 0G 3/1 1 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.805924  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'conv1b' with space 0G 32/4 6 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.817230  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res2a_branch2a' with space 0G 32/1 1 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.821791  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res2a_branch2b' with space 0G 64/4 6 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.822618  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1a' with space 0G 3/1 1 	(avail 7.32G, req 0G)	t: 0
I0212 23:00:43.829728  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1b' with space 0G 32/4 6 	(avail 7.32G, req 0G)	t: 0
I0212 23:00:43.831485  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res3a_branch2a' with space 0G 64/1 6 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.835047  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res3a_branch2b' with space 0G 128/4 6 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.842093  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2a' with space 0G 32/1 1 	(avail 7.32G, req 0G)	t: 0
I0212 23:00:43.842361  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res4a_branch2a' with space 0G 128/1 1 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.845510  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res4a_branch2b' with space 0G 256/4 6 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.846648  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2b' with space 0G 64/4 6 	(avail 7.32G, req 0G)	t: 0
I0212 23:00:43.851064  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res5a_branch2a' with space 0G 256/1 1 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.854195  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res5a_branch2b' with space 0G 512/4 1 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.854856  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2a' with space 0G 64/1 6 	(avail 7.32G, req 0G)	t: 0
I0212 23:00:43.858237  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2b' with space 0G 128/4 6 	(avail 7.32G, req 0G)	t: 0
I0212 23:00:43.861441  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output1' with space 0G 128/1 1 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.864897  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output2' with space 0G 512/1 1 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.867173  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output3' with space 0G 512/1 0 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.867924  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2a' with space 0G 128/1 1 	(avail 7.32G, req 0G)	t: 0
I0212 23:00:43.869715  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output4' with space 0G 512/1 0 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.871161  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2b' with space 0G 256/4 6 	(avail 7.32G, req 0G)	t: 0
I0212 23:00:43.871990  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output5' with space 0G 512/1 0 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.874119  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output6' with space 0G 512/1 0 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.876667  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output1/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.877064  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res5a_branch2a' with space 0G 256/1 1 	(avail 7.32G, req 0G)	t: 0
I0212 23:00:43.879441  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output1/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.880249  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res5a_branch2b' with space 0G 512/4 1 	(avail 7.32G, req 0G)	t: 0
I0212 23:00:43.881898  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output2/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.884394  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output2/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.886128  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output1' with space 0G 128/1 1 	(avail 7.32G, req 0G)	t: 0
I0212 23:00:43.888499  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output3/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.889427  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output2' with space 0G 512/1 1 	(avail 7.32G, req 0G)	t: 0
I0212 23:00:43.890915  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output3/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.894196  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output3' with space 0G 512/1 0 	(avail 7.32G, req 0G)	t: 0
I0212 23:00:43.896154  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output4/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.897109  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output4' with space 0G 512/1 0 	(avail 7.32G, req 0G)	t: 0
I0212 23:00:43.898530  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output4/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.900132  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output5' with space 0G 512/1 0 	(avail 7.32G, req 0G)	t: 0
I0212 23:00:43.900985  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output5/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.903317  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output6' with space 0G 512/1 0 	(avail 7.32G, req 0G)	t: 0
I0212 23:00:43.903812  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output5/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.906054  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output1/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.32G, req 0G)	t: 0
I0212 23:00:43.906632  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output6/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.909073  3136 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output6/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.61G, req 0G)	t: 0
I0212 23:00:43.909636  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output1/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.32G, req 0G)	t: 0
I0212 23:00:43.913959  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output2/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.32G, req 0G)	t: 0
I0212 23:00:43.915540  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output2/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.32G, req 0G)	t: 0
I0212 23:00:43.917647  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output3/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.32G, req 0G)	t: 0
I0212 23:00:43.919258  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output3/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.32G, req 0G)	t: 0
I0212 23:00:43.920840  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output4/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.32G, req 0G)	t: 0
I0212 23:00:43.922837  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output4/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.32G, req 0G)	t: 0
I0212 23:00:43.924697  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output5/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.32G, req 0G)	t: 0
I0212 23:00:43.926332  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output5/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.32G, req 0G)	t: 0
I0212 23:00:43.928181  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output6/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.32G, req 0G)	t: 0
I0212 23:00:43.930016  3135 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output6/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.32G, req 0G)	t: 0
I0212 23:01:34.681681  3113 data_reader.cpp:305] Starting prefetch of epoch 1
I0212 23:01:34.940024  3135 solver.cpp:774] class AP 1: 0.403147
I0212 23:01:34.983891  3135 solver.cpp:774] class AP 2: 0.637417
I0212 23:01:34.993360  3135 solver.cpp:774] class AP 3: 0.62838
I0212 23:01:34.993389  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.556315
I0212 23:01:35.125128  3136 solver.cpp:774] class AP 1: 0.40834
I0212 23:01:35.168372  3136 solver.cpp:774] class AP 2: 0.639416
I0212 23:01:35.177732  3136 solver.cpp:774] class AP 3: 0.636762
I0212 23:01:35.177759  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.561506
I0212 23:01:35.178141  3135 solver.cpp:255] [MultiGPU] Initial Test completed
I0212 23:01:37.096410  3084 annotated_data_layer.cpp:111] [0] Parser threads: 4
I0212 23:01:37.096452  3084 annotated_data_layer.cpp:113] [0] Transformer threads: 4
I0212 23:01:37.196804  3141 annotated_data_layer.cpp:111] [1] Parser threads: 4
I0212 23:01:37.196835  3141 annotated_data_layer.cpp:113] [1] Transformer threads: 4
I0212 23:01:38.686900  3135 solver.cpp:319] Iteration 0 (3.50857 s), loss = 2.62694
I0212 23:01:38.686955  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.54516 (* 1 = 2.54516 loss)
I0212 23:01:38.686970  3135 sgd_solver.cpp:136] Iteration 0, lr = 0.001, m = 0.9
I0212 23:01:38.804857  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'conv1a' with space 4.24G 3/1 1 0 3 	(avail 0.9G, req 0G)	t: 0 2.65 2.16
I0212 23:01:38.937701  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'conv1b' with space 4.24G 32/4 6 4 3 	(avail 0.87G, req 0G)	t: 0 0.6 1.14
I0212 23:01:39.085417  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'conv1a' with space 4.24G 3/1 1 0 3 	(avail 1.2G, req 0G)	t: 0 2.76 2.16
I0212 23:01:39.175353  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 4.24G 32/1 1 4 3 	(avail 0.84G, req 0G)	t: 0 0.89 1.44
I0212 23:01:39.205912  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'conv1b' with space 4.24G 32/4 6 4 3 	(avail 1.2G, req 0G)	t: 0 0.61 1.12
I0212 23:01:39.267293  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 4.24G 64/4 1 1 3 	(avail 0.84G, req 0G)	t: 0 0.3 0.6
I0212 23:01:39.473302  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 4.24G 64/1 6 4 1 	(avail 0.84G, req 0G)	t: 0 0.49 0.8
I0212 23:01:39.531781  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 4.24G 128/4 6 4 0 	(avail 0.84G, req 0G)	t: 0 0.15 0.26
I0212 23:01:39.573268  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 4.24G 32/1 1 4 3 	(avail 1.15G, req 0G)	t: 0 0.81 1.47
I0212 23:01:39.658411  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 4.24G 64/4 1 1 3 	(avail 1.15G, req 0G)	t: 0 0.28 0.54
I0212 23:01:39.659354  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 4.24G 128/1 6 4 5 	(avail 0.82G, req 0.04G)	t: 0 0.43 0.53
I0212 23:01:39.695488  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 4.24G 256/4 6 4 5 	(avail 0.82G, req 0.04G)	t: 0 0.12 0.22
I0212 23:01:39.809885  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 4.24G 256/1 6 4 5 	(avail 0.82G, req 0.04G)	t: 0 0.56 0.52
I0212 23:01:39.844103  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 4.24G 64/1 6 4 3 	(avail 1.15G, req 0G)	t: 0 0.5 0.82
I0212 23:01:39.901566  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 4.24G 512/4 6 4 5 	(avail 0.79G, req 0.04G)	t: 0 0.15 0.14
I0212 23:01:39.927944  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 4.24G 128/4 6 4 0 	(avail 1.15G, req 0G)	t: 0 0.14 0.28
I0212 23:01:39.972618  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output1' with space 4.24G 128/1 1 1 3 	(avail 0.79G, req 0.04G)	t: 0 0.4 0.75
I0212 23:01:40.031828  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output2' with space 4.24G 512/1 1 1 1 	(avail 0.79G, req 0.04G)	t: 0 0.17 0.2
I0212 23:01:40.036509  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 4.24G 128/1 6 4 5 	(avail 1.15G, req 0.04G)	t: 0 0.41 0.51
I0212 23:01:40.065212  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output3' with space 4.24G 512/1 1 1 1 	(avail 0.79G, req 0.04G)	t: 0 0.1 0.13
I0212 23:01:40.074211  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 4.24G 256/4 6 4 5 	(avail 1.15G, req 0.04G)	t: 0 0.1 0.19
I0212 23:01:40.094928  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output4' with space 4.24G 512/1 0 0 1 	(avail 0.79G, req 0.04G)	t: 0 0.1 0.08
I0212 23:01:40.134991  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output5' with space 4.24G 512/1 0 0 1 	(avail 0.79G, req 0.04G)	t: 0 0.11 0.11
I0212 23:01:40.167111  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output6' with space 4.24G 512/1 0 0 1 	(avail 0.76G, req 0.04G)	t: 0 0.08 0.08
I0212 23:01:40.218420  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 4.24G 256/1 6 4 5 	(avail 1.15G, req 0.04G)	t: 0 0.52 0.5
I0212 23:01:40.262024  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 4.24G 512/4 6 4 5 	(avail 1.15G, req 0.04G)	t: 0 0.14 0.15
I0212 23:01:40.276644  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_loc' with space 4.24G 256/1 1 1 3 	(avail 0.76G, req 0.04G)	t: 0 0.24 0.79
I0212 23:01:40.316357  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output1' with space 4.24G 128/1 1 1 3 	(avail 1.15G, req 0.04G)	t: 0 0.42 0.77
I0212 23:01:40.391217  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_conf' with space 4.24G 256/1 1 1 3 	(avail 0.73G, req 0.04G)	t: 0 0.28 0.88
I0212 23:01:40.415336  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output2' with space 4.24G 512/1 1 1 1 	(avail 1.1G, req 0.04G)	t: 0 0.35 0.23
I0212 23:01:40.424949  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_loc' with space 4.24G 256/1 1 1 3 	(avail 0.73G, req 0.04G)	t: 0 0.08 0.11
I0212 23:01:40.465212  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_conf' with space 4.24G 256/1 1 1 3 	(avail 0.73G, req 0.04G)	t: 0 0.07 0.1
I0212 23:01:40.474028  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output3' with space 4.24G 512/1 1 1 1 	(avail 1.1G, req 0.04G)	t: 0 0.07 0.1
I0212 23:01:40.487907  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 0.73G, req 0.04G)	t: 0 0.05 0.05
I0212 23:01:40.502578  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output4' with space 4.24G 512/1 0 0 1 	(avail 1.1G, req 0.04G)	t: 0 0.06 0.07
I0212 23:01:40.506139  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_conf' with space 4.24G 256/1 0 0 0 	(avail 0.73G, req 0.04G)	t: 0 0.06 0.05
I0212 23:01:40.525789  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 0.73G, req 0.04G)	t: 0 0.06 0.04
I0212 23:01:40.534673  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output5' with space 4.24G 512/1 0 0 1 	(avail 1.1G, req 0.04G)	t: 0 0.06 0.06
I0212 23:01:40.575156  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_conf' with space 4.24G 256/1 0 0 0 	(avail 0.73G, req 0.04G)	t: 0 0.06 0.05
I0212 23:01:40.584345  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output6' with space 4.24G 512/1 0 0 1 	(avail 1.04G, req 0.04G)	t: 0 0.07 0.1
I0212 23:01:40.593070  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 0.73G, req 0.04G)	t: 0 0.03 0.03
I0212 23:01:40.603253  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_conf' with space 4.24G 256/1 0 0 0 	(avail 0.73G, req 0.04G)	t: 0 0.03 0.03
I0212 23:01:40.623857  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output6/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 0.73G, req 0.04G)	t: 0 0.05 0.05
I0212 23:01:40.638485  3135 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output6/relu_mbox_conf' with space 4.24G 256/1 0 0 0 	(avail 0.73G, req 0.04G)	t: 0 0.06 0.06
I0212 23:01:40.714735  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_loc' with space 4.24G 256/1 1 1 3 	(avail 1.04G, req 0.04G)	t: 0 0.28 0.83
I0212 23:01:40.821913  3135 cudnn_conv_layer.cpp:474] [0] Layer 'conv1a' reallocating workspace 4.24G to 0.07G
I0212 23:01:40.824957  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_conf' with space 4.24G 256/1 1 1 3 	(avail 1.04G, req 0.04G)	t: 0 0.27 0.84
I0212 23:01:40.846706  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_loc' with space 4.24G 256/1 1 1 3 	(avail 1.04G, req 0.04G)	t: 0 0.08 0.11
I0212 23:01:40.873550  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_conf' with space 4.24G 256/1 0 1 3 	(avail 1.04G, req 0.04G)	t: 0 0.05 0.08
I0212 23:01:40.897073  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_loc' with space 4.24G 256/1 1 0 0 	(avail 1.04G, req 0.04G)	t: 0 0.04 0.04
I0212 23:01:40.922644  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_conf' with space 4.24G 256/1 1 0 0 	(avail 1.04G, req 0.04G)	t: 0 0.04 0.04
I0212 23:01:40.946393  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_loc' with space 4.24G 256/1 1 0 0 	(avail 1.04G, req 0.04G)	t: 0 0.05 0.04
I0212 23:01:40.961027  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_conf' with space 4.24G 256/1 0 0 0 	(avail 1.04G, req 0.04G)	t: 0 0.06 0.05
I0212 23:01:40.983410  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 1.04G, req 0.04G)	t: 0 0.04 0.03
I0212 23:01:41.000278  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_conf' with space 4.24G 256/1 0 0 0 	(avail 1.04G, req 0.04G)	t: 0 0.04 0.03
I0212 23:01:41.013895  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output6/relu_mbox_loc' with space 4.24G 256/1 1 0 0 	(avail 1.04G, req 0.04G)	t: 0 0.05 0.05
I0212 23:01:41.037077  3136 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output6/relu_mbox_conf' with space 4.24G 256/1 0 0 0 	(avail 1.04G, req 0.04G)	t: 0 0.07 0.07
I0212 23:01:41.278349  3136 cudnn_conv_layer.cpp:474] [1] Layer 'conv1a' reallocating workspace 4.24G to 0.07G
I0212 23:01:41.517889  3135 solver.cpp:319] Iteration 1 (2.83089 s), loss = 2.83265
I0212 23:01:41.517940  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.10003 (* 1 = 3.10003 loss)
I0212 23:01:42.089299  3135 solver.cpp:319] Iteration 2 (0.571384 s), loss = 2.86185
I0212 23:01:42.089347  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.70424 (* 1 = 2.70424 loss)
I0212 23:02:47.902842  3135 solver.cpp:314] Iteration 100 (1.4891 iter/s, 65.8115s/98 iter), loss = 3.12835
I0212 23:02:47.902988  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.24022 (* 1 = 3.24022 loss)
I0212 23:02:47.903007  3135 sgd_solver.cpp:136] Iteration 100, lr = 0.00099667, m = 0.9
I0212 23:03:55.533905  3135 solver.cpp:314] Iteration 200 (1.47866 iter/s, 67.629s/100 iter), loss = 2.83851
I0212 23:03:55.534008  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.97572 (* 1 = 2.97572 loss)
I0212 23:03:55.534023  3135 sgd_solver.cpp:136] Iteration 200, lr = 0.000993344, m = 0.9
I0212 23:05:02.242485  3135 solver.cpp:314] Iteration 300 (1.4991 iter/s, 66.7065s/100 iter), loss = 3.12422
I0212 23:05:02.242599  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.92937 (* 1 = 2.92937 loss)
I0212 23:05:02.242617  3135 sgd_solver.cpp:136] Iteration 300, lr = 0.000990025, m = 0.9
I0212 23:06:09.954514  3135 solver.cpp:314] Iteration 400 (1.47689 iter/s, 67.71s/100 iter), loss = 3.09158
I0212 23:06:09.954617  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.09616 (* 1 = 3.09616 loss)
I0212 23:06:09.954633  3135 sgd_solver.cpp:136] Iteration 400, lr = 0.000986711, m = 0.9
I0212 23:07:17.894050  3135 solver.cpp:314] Iteration 500 (1.47194 iter/s, 67.9375s/100 iter), loss = 3.14997
I0212 23:07:17.894168  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.8597 (* 1 = 2.8597 loss)
I0212 23:07:17.894186  3135 sgd_solver.cpp:136] Iteration 500, lr = 0.000983403, m = 0.9
I0212 23:08:25.534145  3135 solver.cpp:314] Iteration 600 (1.47846 iter/s, 67.6381s/100 iter), loss = 3.04377
I0212 23:08:25.535205  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.31395 (* 1 = 3.31395 loss)
I0212 23:08:25.535221  3135 sgd_solver.cpp:136] Iteration 600, lr = 0.0009801, m = 0.9
I0212 23:09:32.521538  3135 solver.cpp:314] Iteration 700 (1.49286 iter/s, 66.9854s/100 iter), loss = 3.01117
I0212 23:09:32.521647  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.52368 (* 1 = 2.52368 loss)
I0212 23:09:32.521662  3135 sgd_solver.cpp:136] Iteration 700, lr = 0.000976803, m = 0.9
I0212 23:10:41.586319  3135 solver.cpp:314] Iteration 800 (1.44796 iter/s, 69.0627s/100 iter), loss = 2.97001
I0212 23:10:41.586413  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.40317 (* 1 = 3.40317 loss)
I0212 23:10:41.586431  3135 sgd_solver.cpp:136] Iteration 800, lr = 0.000973511, m = 0.9
I0212 23:11:50.783094  3135 solver.cpp:314] Iteration 900 (1.4452 iter/s, 69.1947s/100 iter), loss = 2.97935
I0212 23:11:50.783211  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.33072 (* 1 = 2.33072 loss)
I0212 23:11:50.783227  3135 sgd_solver.cpp:136] Iteration 900, lr = 0.000970225, m = 0.9
I0212 23:12:59.486824  3135 solver.cpp:314] Iteration 1000 (1.45557 iter/s, 68.7017s/100 iter), loss = 3.22065
I0212 23:12:59.486965  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.47979 (* 1 = 3.47979 loss)
I0212 23:12:59.487005  3135 sgd_solver.cpp:136] Iteration 1000, lr = 0.000966944, m = 0.9
I0212 23:14:09.446578  3135 solver.cpp:314] Iteration 1100 (1.42944 iter/s, 69.9577s/100 iter), loss = 2.94776
I0212 23:14:09.446672  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.42797 (* 1 = 3.42797 loss)
I0212 23:14:09.446688  3135 sgd_solver.cpp:136] Iteration 1100, lr = 0.00096367, m = 0.9
I0212 23:15:19.136132  3135 solver.cpp:314] Iteration 1200 (1.43498 iter/s, 69.6875s/100 iter), loss = 3.0683
I0212 23:15:19.136277  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.04618 (* 1 = 3.04618 loss)
I0212 23:15:19.136293  3135 sgd_solver.cpp:136] Iteration 1200, lr = 0.0009604, m = 0.9
I0212 23:16:28.645244  3135 solver.cpp:314] Iteration 1300 (1.4387 iter/s, 69.5071s/100 iter), loss = 2.98714
I0212 23:16:28.645355  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.43763 (* 1 = 3.43763 loss)
I0212 23:16:28.645371  3135 sgd_solver.cpp:136] Iteration 1300, lr = 0.000957136, m = 0.9
I0212 23:17:38.498497  3135 solver.cpp:314] Iteration 1400 (1.43161 iter/s, 69.8512s/100 iter), loss = 3.10661
I0212 23:17:38.498603  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.39745 (* 1 = 2.39745 loss)
I0212 23:17:38.498622  3135 sgd_solver.cpp:136] Iteration 1400, lr = 0.000953878, m = 0.9
I0212 23:18:47.641813  3135 solver.cpp:314] Iteration 1500 (1.44631 iter/s, 69.1413s/100 iter), loss = 3.16307
I0212 23:18:47.641928  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.48548 (* 1 = 2.48548 loss)
I0212 23:18:47.641947  3135 sgd_solver.cpp:136] Iteration 1500, lr = 0.000950625, m = 0.9
I0212 23:19:56.999215  3135 solver.cpp:314] Iteration 1600 (1.44185 iter/s, 69.3554s/100 iter), loss = 3.28244
I0212 23:19:56.999322  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.49088 (* 1 = 2.49088 loss)
I0212 23:19:56.999339  3135 sgd_solver.cpp:136] Iteration 1600, lr = 0.000947378, m = 0.9
I0212 23:21:07.749310  3135 solver.cpp:314] Iteration 1700 (1.41347 iter/s, 70.748s/100 iter), loss = 2.96243
I0212 23:21:07.749449  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.31297 (* 1 = 3.31297 loss)
I0212 23:21:07.749485  3135 sgd_solver.cpp:136] Iteration 1700, lr = 0.000944136, m = 0.9
I0212 23:22:17.821800  3135 solver.cpp:314] Iteration 1800 (1.42714 iter/s, 70.0704s/100 iter), loss = 3.09092
I0212 23:22:17.821926  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.63074 (* 1 = 2.63074 loss)
I0212 23:22:17.821943  3135 sgd_solver.cpp:136] Iteration 1800, lr = 0.0009409, m = 0.9
I0212 23:23:27.714392  3135 solver.cpp:314] Iteration 1900 (1.43081 iter/s, 69.8906s/100 iter), loss = 2.91329
I0212 23:23:27.714509  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.65029 (* 1 = 2.65029 loss)
I0212 23:23:27.714529  3135 sgd_solver.cpp:136] Iteration 1900, lr = 0.00093767, m = 0.9
I0212 23:24:37.374547  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_2000.caffemodel
I0212 23:24:37.475541  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_2000.solverstate
I0212 23:24:37.490969  3135 solver.cpp:666] Iteration 2000, Testing net (#0)
I0212 23:25:28.083214  3135 solver.cpp:774] class AP 1: 0.382238
I0212 23:25:28.137787  3135 solver.cpp:774] class AP 2: 0.619063
I0212 23:25:28.148525  3135 solver.cpp:774] class AP 3: 0.619455
I0212 23:25:28.148563  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.540252
I0212 23:25:28.262992  3136 solver.cpp:774] class AP 1: 0.389454
I0212 23:25:28.306203  3136 solver.cpp:774] class AP 2: 0.618468
I0212 23:25:28.316458  3136 solver.cpp:774] class AP 3: 0.62608
I0212 23:25:28.316478  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.544668
I0212 23:25:28.316597  3135 solver.cpp:265] [MultiGPU] Tests completed in 50.8242s
I0212 23:25:28.742781  3135 solver.cpp:314] Iteration 2000 (0.826276 iter/s, 121.025s/100 iter), loss = 3.02162
I0212 23:25:28.742820  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.13305 (* 1 = 3.13305 loss)
I0212 23:25:28.742836  3135 sgd_solver.cpp:136] Iteration 2000, lr = 0.000934444, m = 0.9
I0212 23:26:37.704358  3135 solver.cpp:314] Iteration 2100 (1.45012 iter/s, 68.9596s/100 iter), loss = 3.23559
I0212 23:26:37.704484  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.32745 (* 1 = 2.32745 loss)
I0212 23:26:37.704500  3135 sgd_solver.cpp:136] Iteration 2100, lr = 0.000931225, m = 0.9
I0212 23:27:46.521899  3135 solver.cpp:314] Iteration 2200 (1.45316 iter/s, 68.8155s/100 iter), loss = 3.22944
I0212 23:27:46.522008  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.7804 (* 1 = 2.7804 loss)
I0212 23:27:46.522260  3135 sgd_solver.cpp:136] Iteration 2200, lr = 0.000928011, m = 0.9
I0212 23:28:55.437502  3135 solver.cpp:314] Iteration 2300 (1.45109 iter/s, 68.9136s/100 iter), loss = 3.0862
I0212 23:28:55.437630  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.32194 (* 1 = 2.32194 loss)
I0212 23:28:55.437649  3135 sgd_solver.cpp:136] Iteration 2300, lr = 0.000924803, m = 0.9
I0212 23:30:03.525491  3135 solver.cpp:314] Iteration 2400 (1.46873 iter/s, 68.0859s/100 iter), loss = 2.80732
I0212 23:30:03.525678  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.60883 (* 1 = 2.60883 loss)
I0212 23:30:03.525719  3135 sgd_solver.cpp:136] Iteration 2400, lr = 0.0009216, m = 0.9
I0212 23:31:12.587909  3135 solver.cpp:314] Iteration 2500 (1.44801 iter/s, 69.0604s/100 iter), loss = 2.92228
I0212 23:31:12.588007  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.77612 (* 1 = 2.77612 loss)
I0212 23:31:12.588022  3135 sgd_solver.cpp:136] Iteration 2500, lr = 0.000918403, m = 0.9
I0212 23:32:21.958092  3135 solver.cpp:314] Iteration 2600 (1.44158 iter/s, 69.3681s/100 iter), loss = 3.1674
I0212 23:32:21.958189  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.49169 (* 1 = 3.49169 loss)
I0212 23:32:21.958204  3135 sgd_solver.cpp:136] Iteration 2600, lr = 0.000915211, m = 0.9
I0212 23:33:32.234364  3135 solver.cpp:314] Iteration 2700 (1.423 iter/s, 70.2742s/100 iter), loss = 2.85401
I0212 23:33:32.234467  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.03982 (* 1 = 3.03982 loss)
I0212 23:33:32.234483  3135 sgd_solver.cpp:136] Iteration 2700, lr = 0.000912025, m = 0.9
I0212 23:34:42.412122  3135 solver.cpp:314] Iteration 2800 (1.425 iter/s, 70.1757s/100 iter), loss = 3.11215
I0212 23:34:42.412225  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.08982 (* 1 = 3.08982 loss)
I0212 23:34:42.412245  3135 sgd_solver.cpp:136] Iteration 2800, lr = 0.000908844, m = 0.9
I0212 23:35:51.808080  3135 solver.cpp:314] Iteration 2900 (1.44105 iter/s, 69.3939s/100 iter), loss = 3.3037
I0212 23:35:51.808218  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.45595 (* 1 = 2.45595 loss)
I0212 23:35:51.808254  3135 sgd_solver.cpp:136] Iteration 2900, lr = 0.000905669, m = 0.9
I0212 23:37:01.452659  3135 solver.cpp:314] Iteration 3000 (1.4359 iter/s, 69.6425s/100 iter), loss = 3.01668
I0212 23:37:01.452765  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.42834 (* 1 = 3.42834 loss)
I0212 23:37:01.452782  3135 sgd_solver.cpp:136] Iteration 3000, lr = 0.0009025, m = 0.9
I0212 23:38:10.761126  3135 solver.cpp:314] Iteration 3100 (1.44287 iter/s, 69.3064s/100 iter), loss = 2.92275
I0212 23:38:10.761234  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.98731 (* 1 = 2.98731 loss)
I0212 23:38:10.761251  3135 sgd_solver.cpp:136] Iteration 3100, lr = 0.000899336, m = 0.9
I0212 23:38:22.361166  3079 data_reader.cpp:305] Starting prefetch of epoch 1
I0212 23:39:20.322705  3135 solver.cpp:314] Iteration 3200 (1.43762 iter/s, 69.5595s/100 iter), loss = 2.92364
I0212 23:39:20.322865  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.46703 (* 1 = 2.46703 loss)
I0212 23:39:20.322881  3135 sgd_solver.cpp:136] Iteration 3200, lr = 0.000896178, m = 0.9
I0212 23:40:28.898320  3135 solver.cpp:314] Iteration 3300 (1.45829 iter/s, 68.5736s/100 iter), loss = 2.87123
I0212 23:40:28.910383  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.47777 (* 1 = 2.47777 loss)
I0212 23:40:28.910432  3135 sgd_solver.cpp:136] Iteration 3300, lr = 0.000893025, m = 0.9
I0212 23:41:38.460214  3135 solver.cpp:314] Iteration 3400 (1.43761 iter/s, 69.5598s/100 iter), loss = 3.11532
I0212 23:41:38.460393  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.56791 (* 1 = 3.56791 loss)
I0212 23:41:38.460433  3135 sgd_solver.cpp:136] Iteration 3400, lr = 0.000889878, m = 0.9
I0212 23:42:48.803714  3135 solver.cpp:314] Iteration 3500 (1.42164 iter/s, 70.3414s/100 iter), loss = 2.94721
I0212 23:42:48.803812  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.10511 (* 1 = 2.10511 loss)
I0212 23:42:48.803828  3135 sgd_solver.cpp:136] Iteration 3500, lr = 0.000886736, m = 0.9
I0212 23:43:57.870503  3135 solver.cpp:314] Iteration 3600 (1.44792 iter/s, 69.0647s/100 iter), loss = 3.11962
I0212 23:43:57.870609  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.21745 (* 1 = 2.21745 loss)
I0212 23:43:57.870626  3135 sgd_solver.cpp:136] Iteration 3600, lr = 0.0008836, m = 0.9
I0212 23:45:08.376884  3135 solver.cpp:314] Iteration 3700 (1.41835 iter/s, 70.5043s/100 iter), loss = 2.86731
I0212 23:45:08.376996  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.5931 (* 1 = 3.5931 loss)
I0212 23:45:08.377010  3135 sgd_solver.cpp:136] Iteration 3700, lr = 0.00088047, m = 0.9
I0212 23:46:18.618085  3135 solver.cpp:314] Iteration 3800 (1.42371 iter/s, 70.2391s/100 iter), loss = 3.22539
I0212 23:46:18.618582  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.3549 (* 1 = 4.3549 loss)
I0212 23:46:18.618902  3135 sgd_solver.cpp:136] Iteration 3800, lr = 0.000877345, m = 0.9
I0212 23:47:28.127631  3135 solver.cpp:314] Iteration 3900 (1.43869 iter/s, 69.5075s/100 iter), loss = 3.02186
I0212 23:47:28.127753  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.40433 (* 1 = 2.40433 loss)
I0212 23:47:28.127769  3135 sgd_solver.cpp:136] Iteration 3900, lr = 0.000874225, m = 0.9
I0212 23:48:36.914690  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_4000.caffemodel
I0212 23:48:36.940681  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_4000.solverstate
I0212 23:48:36.950289  3135 solver.cpp:666] Iteration 4000, Testing net (#0)
I0212 23:49:26.359774  3135 solver.cpp:774] class AP 1: 0.368131
I0212 23:49:26.430923  3135 solver.cpp:774] class AP 2: 0.622865
I0212 23:49:26.442747  3135 solver.cpp:774] class AP 3: 0.634952
I0212 23:49:26.442785  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.541982
I0212 23:49:26.554220  3136 solver.cpp:774] class AP 1: 0.375787
I0212 23:49:26.607710  3136 solver.cpp:774] class AP 2: 0.622124
I0212 23:49:26.617121  3136 solver.cpp:774] class AP 3: 0.635268
I0212 23:49:26.617159  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.544393
I0212 23:49:26.617671  3135 solver.cpp:265] [MultiGPU] Tests completed in 49.6659s
I0212 23:49:27.043128  3135 solver.cpp:314] Iteration 4000 (0.840958 iter/s, 118.912s/100 iter), loss = 3.01299
I0212 23:49:27.043193  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.13324 (* 1 = 4.13324 loss)
I0212 23:49:27.043210  3135 sgd_solver.cpp:136] Iteration 4000, lr = 0.000871111, m = 0.9
I0212 23:50:36.353875  3135 solver.cpp:314] Iteration 4100 (1.44282 iter/s, 69.3087s/100 iter), loss = 2.96523
I0212 23:50:36.354063  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.74323 (* 1 = 2.74323 loss)
I0212 23:50:36.354111  3135 sgd_solver.cpp:136] Iteration 4100, lr = 0.000868003, m = 0.9
I0212 23:51:46.862540  3135 solver.cpp:314] Iteration 4200 (1.41831 iter/s, 70.5066s/100 iter), loss = 2.98397
I0212 23:51:46.862655  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.66278 (* 1 = 2.66278 loss)
I0212 23:51:46.862673  3135 sgd_solver.cpp:136] Iteration 4200, lr = 0.0008649, m = 0.9
I0212 23:52:55.628000  3135 solver.cpp:314] Iteration 4300 (1.45426 iter/s, 68.7634s/100 iter), loss = 3.06111
I0212 23:52:55.630352  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.97415 (* 1 = 2.97415 loss)
I0212 23:52:55.630380  3135 sgd_solver.cpp:136] Iteration 4300, lr = 0.000861803, m = 0.9
I0212 23:54:05.741454  3135 solver.cpp:314] Iteration 4400 (1.4263 iter/s, 70.1114s/100 iter), loss = 3.03675
I0212 23:54:05.741562  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.6403 (* 1 = 3.6403 loss)
I0212 23:54:05.741580  3135 sgd_solver.cpp:136] Iteration 4400, lr = 0.000858711, m = 0.9
I0212 23:55:15.554240  3135 solver.cpp:314] Iteration 4500 (1.43245 iter/s, 69.8107s/100 iter), loss = 2.80882
I0212 23:55:15.554410  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.25251 (* 1 = 2.25251 loss)
I0212 23:55:15.554430  3135 sgd_solver.cpp:136] Iteration 4500, lr = 0.000855625, m = 0.9
I0212 23:56:25.771268  3135 solver.cpp:314] Iteration 4600 (1.4242 iter/s, 70.2149s/100 iter), loss = 3.0043
I0212 23:56:25.771373  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.03233 (* 1 = 3.03233 loss)
I0212 23:56:25.771389  3135 sgd_solver.cpp:136] Iteration 4600, lr = 0.000852545, m = 0.9
I0212 23:57:35.412546  3135 solver.cpp:314] Iteration 4700 (1.43597 iter/s, 69.6392s/100 iter), loss = 2.89418
I0212 23:57:35.412655  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.32983 (* 1 = 4.32983 loss)
I0212 23:57:35.412673  3135 sgd_solver.cpp:136] Iteration 4700, lr = 0.00084947, m = 0.9
I0212 23:58:45.646034  3135 solver.cpp:314] Iteration 4800 (1.42386 iter/s, 70.2314s/100 iter), loss = 3.20095
I0212 23:58:45.646157  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.7499 (* 1 = 2.7499 loss)
I0212 23:58:45.646175  3135 sgd_solver.cpp:136] Iteration 4800, lr = 0.0008464, m = 0.9
I0212 23:59:55.542707  3135 solver.cpp:314] Iteration 4900 (1.43073 iter/s, 69.8946s/100 iter), loss = 3.30421
I0212 23:59:55.542812  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.92147 (* 1 = 2.92147 loss)
I0212 23:59:55.542827  3135 sgd_solver.cpp:136] Iteration 4900, lr = 0.000843336, m = 0.9
I0213 00:01:05.730654  3135 solver.cpp:314] Iteration 5000 (1.42479 iter/s, 70.1859s/100 iter), loss = 2.97604
I0213 00:01:05.734336  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.58738 (* 1 = 2.58738 loss)
I0213 00:01:05.734364  3135 sgd_solver.cpp:136] Iteration 5000, lr = 0.000840278, m = 0.9
I0213 00:02:15.973721  3135 solver.cpp:314] Iteration 5100 (1.42367 iter/s, 70.241s/100 iter), loss = 2.99726
I0213 00:02:15.973821  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.70973 (* 1 = 2.70973 loss)
I0213 00:02:15.973836  3135 sgd_solver.cpp:136] Iteration 5100, lr = 0.000837225, m = 0.9
I0213 00:03:25.545402  3135 solver.cpp:314] Iteration 5200 (1.43741 iter/s, 69.5696s/100 iter), loss = 3.16088
I0213 00:03:25.545514  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.72198 (* 1 = 2.72198 loss)
I0213 00:03:25.545529  3135 sgd_solver.cpp:136] Iteration 5200, lr = 0.000834178, m = 0.9
I0213 00:04:34.917536  3135 solver.cpp:314] Iteration 5300 (1.44154 iter/s, 69.3701s/100 iter), loss = 2.91084
I0213 00:04:34.917632  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.59316 (* 1 = 2.59316 loss)
I0213 00:04:34.917644  3135 sgd_solver.cpp:136] Iteration 5300, lr = 0.000831136, m = 0.9
I0213 00:05:43.144604  3135 solver.cpp:314] Iteration 5400 (1.46574 iter/s, 68.225s/100 iter), loss = 3.07364
I0213 00:05:43.144707  3135 solver.cpp:336]     Train net output #0: mbox_loss = 1.83007 (* 1 = 1.83007 loss)
I0213 00:05:43.144723  3135 sgd_solver.cpp:136] Iteration 5400, lr = 0.0008281, m = 0.9
I0213 00:06:52.655179  3135 solver.cpp:314] Iteration 5500 (1.43867 iter/s, 69.5085s/100 iter), loss = 3.0422
I0213 00:06:52.655275  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.97886 (* 1 = 3.97886 loss)
I0213 00:06:52.655292  3135 sgd_solver.cpp:136] Iteration 5500, lr = 0.000825069, m = 0.9
I0213 00:08:01.810856  3135 solver.cpp:314] Iteration 5600 (1.44606 iter/s, 69.1536s/100 iter), loss = 3.08148
I0213 00:08:01.810995  3135 solver.cpp:336]     Train net output #0: mbox_loss = 1.93496 (* 1 = 1.93496 loss)
I0213 00:08:01.811014  3135 sgd_solver.cpp:136] Iteration 5600, lr = 0.000822044, m = 0.9
I0213 00:09:10.129127  3135 solver.cpp:314] Iteration 5700 (1.46378 iter/s, 68.3162s/100 iter), loss = 3.05327
I0213 00:09:10.129233  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.51402 (* 1 = 3.51402 loss)
I0213 00:09:10.129251  3135 sgd_solver.cpp:136] Iteration 5700, lr = 0.000819025, m = 0.9
I0213 00:10:20.559244  3135 solver.cpp:314] Iteration 5800 (1.41989 iter/s, 70.428s/100 iter), loss = 3.21738
I0213 00:10:20.559345  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.00076 (* 1 = 4.00076 loss)
I0213 00:10:20.559360  3135 sgd_solver.cpp:136] Iteration 5800, lr = 0.000816011, m = 0.9
I0213 00:11:31.162485  3135 solver.cpp:314] Iteration 5900 (1.41641 iter/s, 70.6012s/100 iter), loss = 2.98008
I0213 00:11:31.162580  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.9543 (* 1 = 2.9543 loss)
I0213 00:11:31.162595  3135 sgd_solver.cpp:136] Iteration 5900, lr = 0.000813003, m = 0.9
I0213 00:12:40.383289  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_6000.caffemodel
I0213 00:12:40.415972  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_6000.solverstate
I0213 00:12:40.428531  3135 solver.cpp:666] Iteration 6000, Testing net (#0)
I0213 00:13:29.964620  3113 data_reader.cpp:305] Starting prefetch of epoch 2
I0213 00:13:30.616541  3135 solver.cpp:774] class AP 1: 0.367709
I0213 00:13:30.670470  3135 solver.cpp:774] class AP 2: 0.618171
I0213 00:13:30.681110  3135 solver.cpp:774] class AP 3: 0.625551
I0213 00:13:30.681167  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.537144
I0213 00:13:32.180467  3136 solver.cpp:774] class AP 1: 0.365332
I0213 00:13:32.234752  3136 solver.cpp:774] class AP 2: 0.610898
I0213 00:13:32.245031  3136 solver.cpp:774] class AP 3: 0.626395
I0213 00:13:32.245071  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.534208
I0213 00:13:32.245635  3135 solver.cpp:265] [MultiGPU] Tests completed in 51.8156s
I0213 00:13:32.831938  3135 solver.cpp:314] Iteration 6000 (0.821923 iter/s, 121.666s/100 iter), loss = 3.13641
I0213 00:13:32.831977  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.89124 (* 1 = 2.89124 loss)
I0213 00:13:32.831987  3135 sgd_solver.cpp:136] Iteration 6000, lr = 0.00081, m = 0.9
I0213 00:14:43.786823  3135 solver.cpp:314] Iteration 6100 (1.40939 iter/s, 70.9528s/100 iter), loss = 3.17227
I0213 00:14:43.786965  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.52847 (* 1 = 2.52847 loss)
I0213 00:14:43.787000  3135 sgd_solver.cpp:136] Iteration 6100, lr = 0.000807003, m = 0.9
I0213 00:15:54.453889  3135 solver.cpp:314] Iteration 6200 (1.41513 iter/s, 70.665s/100 iter), loss = 3.05234
I0213 00:15:54.453989  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.21579 (* 1 = 2.21579 loss)
I0213 00:15:54.454008  3135 sgd_solver.cpp:136] Iteration 6200, lr = 0.000804011, m = 0.9
I0213 00:17:05.186544  3135 solver.cpp:314] Iteration 6300 (1.41382 iter/s, 70.7305s/100 iter), loss = 3.03457
I0213 00:17:05.186646  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.82596 (* 1 = 2.82596 loss)
I0213 00:17:05.186663  3135 sgd_solver.cpp:136] Iteration 6300, lr = 0.000801025, m = 0.9
I0213 00:18:14.948660  3135 solver.cpp:314] Iteration 6400 (1.43349 iter/s, 69.7598s/100 iter), loss = 2.88986
I0213 00:18:14.948786  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.08017 (* 1 = 2.08017 loss)
I0213 00:18:14.948804  3135 sgd_solver.cpp:136] Iteration 6400, lr = 0.000798044, m = 0.9
I0213 00:19:24.999871  3135 solver.cpp:314] Iteration 6500 (1.42757 iter/s, 70.0489s/100 iter), loss = 2.99908
I0213 00:19:25.000015  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.29651 (* 1 = 2.29651 loss)
I0213 00:19:25.000031  3135 sgd_solver.cpp:136] Iteration 6500, lr = 0.000795069, m = 0.9
I0213 00:20:34.806843  3135 solver.cpp:314] Iteration 6600 (1.43257 iter/s, 69.8047s/100 iter), loss = 3.50901
I0213 00:20:34.806964  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.29552 (* 1 = 3.29552 loss)
I0213 00:20:34.806995  3135 sgd_solver.cpp:136] Iteration 6600, lr = 0.0007921, m = 0.9
I0213 00:21:45.698341  3135 solver.cpp:314] Iteration 6700 (1.41065 iter/s, 70.8892s/100 iter), loss = 3.04809
I0213 00:21:45.698490  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.93416 (* 1 = 2.93416 loss)
I0213 00:21:45.698530  3135 sgd_solver.cpp:136] Iteration 6700, lr = 0.000789136, m = 0.9
I0213 00:22:54.614902  3135 solver.cpp:314] Iteration 6800 (1.45108 iter/s, 68.9143s/100 iter), loss = 2.87554
I0213 00:22:54.615007  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.02693 (* 1 = 3.02693 loss)
I0213 00:22:54.615026  3135 sgd_solver.cpp:136] Iteration 6800, lr = 0.000786178, m = 0.9
I0213 00:24:04.630810  3135 solver.cpp:314] Iteration 6900 (1.42829 iter/s, 70.0137s/100 iter), loss = 3.08546
I0213 00:24:04.630930  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.63131 (* 1 = 4.63131 loss)
I0213 00:24:04.630949  3135 sgd_solver.cpp:136] Iteration 6900, lr = 0.000783225, m = 0.9
I0213 00:25:15.338603  3135 solver.cpp:314] Iteration 7000 (1.41432 iter/s, 70.7055s/100 iter), loss = 2.90567
I0213 00:25:15.339171  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.06265 (* 1 = 3.06265 loss)
I0213 00:25:15.339506  3135 sgd_solver.cpp:136] Iteration 7000, lr = 0.000780278, m = 0.9
I0213 00:26:25.536082  3135 solver.cpp:314] Iteration 7100 (1.4246 iter/s, 70.1952s/100 iter), loss = 2.87091
I0213 00:26:25.536258  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.33063 (* 1 = 3.33063 loss)
I0213 00:26:25.536296  3135 sgd_solver.cpp:136] Iteration 7100, lr = 0.000777336, m = 0.9
I0213 00:27:35.008932  3135 solver.cpp:314] Iteration 7200 (1.43946 iter/s, 69.4706s/100 iter), loss = 3.14485
I0213 00:27:35.009088  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.08221 (* 1 = 3.08221 loss)
I0213 00:27:35.009124  3135 sgd_solver.cpp:136] Iteration 7200, lr = 0.0007744, m = 0.9
I0213 00:28:44.978533  3135 solver.cpp:314] Iteration 7300 (1.42924 iter/s, 69.9674s/100 iter), loss = 2.96876
I0213 00:28:44.978646  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.00458 (* 1 = 3.00458 loss)
I0213 00:28:44.978664  3135 sgd_solver.cpp:136] Iteration 7300, lr = 0.000771469, m = 0.9
I0213 00:29:55.794365  3135 solver.cpp:314] Iteration 7400 (1.41216 iter/s, 70.8136s/100 iter), loss = 3.03348
I0213 00:29:55.794493  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.46393 (* 1 = 3.46393 loss)
I0213 00:29:55.794515  3135 sgd_solver.cpp:136] Iteration 7400, lr = 0.000768545, m = 0.9
I0213 00:31:05.573091  3135 solver.cpp:314] Iteration 7500 (1.43315 iter/s, 69.7765s/100 iter), loss = 2.83517
I0213 00:31:05.573192  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.28019 (* 1 = 3.28019 loss)
I0213 00:31:05.573207  3135 sgd_solver.cpp:136] Iteration 7500, lr = 0.000765625, m = 0.9
I0213 00:32:14.909662  3135 solver.cpp:314] Iteration 7600 (1.44229 iter/s, 69.3344s/100 iter), loss = 3.07577
I0213 00:32:14.909781  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.52249 (* 1 = 3.52249 loss)
I0213 00:32:14.909802  3135 sgd_solver.cpp:136] Iteration 7600, lr = 0.000762711, m = 0.9
I0213 00:33:25.295539  3135 solver.cpp:314] Iteration 7700 (1.42078 iter/s, 70.3836s/100 iter), loss = 2.96196
I0213 00:33:25.295641  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.82006 (* 1 = 2.82006 loss)
I0213 00:33:25.295658  3135 sgd_solver.cpp:136] Iteration 7700, lr = 0.000759803, m = 0.9
I0213 00:34:34.328614  3135 solver.cpp:314] Iteration 7800 (1.44863 iter/s, 69.0309s/100 iter), loss = 3.00712
I0213 00:34:34.328773  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.58151 (* 1 = 3.58151 loss)
I0213 00:34:34.328790  3135 sgd_solver.cpp:136] Iteration 7800, lr = 0.0007569, m = 0.9
I0213 00:35:44.410336  3135 solver.cpp:314] Iteration 7900 (1.42695 iter/s, 70.0795s/100 iter), loss = 3.14724
I0213 00:35:44.410748  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.17463 (* 1 = 2.17463 loss)
I0213 00:35:44.410776  3135 sgd_solver.cpp:136] Iteration 7900, lr = 0.000754003, m = 0.9
I0213 00:36:53.390622  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_8000.caffemodel
I0213 00:36:53.423157  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_8000.solverstate
I0213 00:36:53.436728  3135 solver.cpp:666] Iteration 8000, Testing net (#0)
I0213 00:37:42.401242  3135 solver.cpp:774] class AP 1: 0.401004
I0213 00:37:42.473188  3135 solver.cpp:774] class AP 2: 0.608697
I0213 00:37:42.483003  3135 solver.cpp:774] class AP 3: 0.635026
I0213 00:37:42.483053  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.548242
I0213 00:37:43.035424  3136 solver.cpp:774] class AP 1: 0.391926
I0213 00:37:43.091404  3136 solver.cpp:774] class AP 2: 0.612984
I0213 00:37:43.099791  3136 solver.cpp:774] class AP 3: 0.626278
I0213 00:37:43.099830  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.543729
I0213 00:37:43.100003  3135 solver.cpp:265] [MultiGPU] Tests completed in 49.6617s
I0213 00:37:43.586359  3135 solver.cpp:314] Iteration 8000 (0.839122 iter/s, 119.172s/100 iter), loss = 2.99561
I0213 00:37:43.586403  3135 solver.cpp:336]     Train net output #0: mbox_loss = 1.62583 (* 1 = 1.62583 loss)
I0213 00:37:43.586416  3135 sgd_solver.cpp:136] Iteration 8000, lr = 0.000751111, m = 0.9
I0213 00:38:53.486536  3135 solver.cpp:314] Iteration 8100 (1.43066 iter/s, 69.8979s/100 iter), loss = 3.05924
I0213 00:38:53.486676  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.88933 (* 1 = 2.88933 loss)
I0213 00:38:53.486716  3135 sgd_solver.cpp:136] Iteration 8100, lr = 0.000748225, m = 0.9
I0213 00:40:03.207514  3135 solver.cpp:314] Iteration 8200 (1.43433 iter/s, 69.7188s/100 iter), loss = 3.02234
I0213 00:40:03.207618  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.16555 (* 1 = 3.16555 loss)
I0213 00:40:03.207636  3135 sgd_solver.cpp:136] Iteration 8200, lr = 0.000745344, m = 0.9
I0213 00:41:13.713311  3135 solver.cpp:314] Iteration 8300 (1.41837 iter/s, 70.5036s/100 iter), loss = 2.97523
I0213 00:41:13.713423  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.20244 (* 1 = 2.20244 loss)
I0213 00:41:13.713439  3135 sgd_solver.cpp:136] Iteration 8300, lr = 0.00074247, m = 0.9
I0213 00:42:23.298686  3135 solver.cpp:314] Iteration 8400 (1.43713 iter/s, 69.5832s/100 iter), loss = 2.84071
I0213 00:42:23.298791  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.0572 (* 1 = 3.0572 loss)
I0213 00:42:23.298810  3135 sgd_solver.cpp:136] Iteration 8400, lr = 0.0007396, m = 0.9
I0213 00:43:33.134645  3135 solver.cpp:314] Iteration 8500 (1.43197 iter/s, 69.8337s/100 iter), loss = 3.19079
I0213 00:43:33.134757  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.54093 (* 1 = 4.54093 loss)
I0213 00:43:33.134775  3135 sgd_solver.cpp:136] Iteration 8500, lr = 0.000736736, m = 0.9
I0213 00:44:42.910861  3135 solver.cpp:314] Iteration 8600 (1.4332 iter/s, 69.774s/100 iter), loss = 3.04015
I0213 00:44:42.910995  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.28839 (* 1 = 4.28839 loss)
I0213 00:44:42.911029  3135 sgd_solver.cpp:136] Iteration 8600, lr = 0.000733878, m = 0.9
I0213 00:45:53.738446  3135 solver.cpp:314] Iteration 8700 (1.41192 iter/s, 70.8253s/100 iter), loss = 2.9951
I0213 00:45:53.738579  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.68066 (* 1 = 2.68066 loss)
I0213 00:45:53.738595  3135 sgd_solver.cpp:136] Iteration 8700, lr = 0.000731025, m = 0.9
I0213 00:47:03.410534  3135 solver.cpp:314] Iteration 8800 (1.43534 iter/s, 69.6699s/100 iter), loss = 3.13308
I0213 00:47:03.410670  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.12698 (* 1 = 3.12698 loss)
I0213 00:47:03.410706  3135 sgd_solver.cpp:136] Iteration 8800, lr = 0.000728178, m = 0.9
I0213 00:48:14.737226  3135 solver.cpp:314] Iteration 8900 (1.40204 iter/s, 71.3244s/100 iter), loss = 2.93868
I0213 00:48:14.737331  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.64515 (* 1 = 2.64515 loss)
I0213 00:48:14.737347  3135 sgd_solver.cpp:136] Iteration 8900, lr = 0.000725336, m = 0.9
I0213 00:49:24.749124  3135 solver.cpp:314] Iteration 9000 (1.42837 iter/s, 70.0097s/100 iter), loss = 2.99512
I0213 00:49:24.749606  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.19812 (* 1 = 2.19812 loss)
I0213 00:49:24.749920  3135 sgd_solver.cpp:136] Iteration 9000, lr = 0.0007225, m = 0.9
I0213 00:49:43.495190  3079 data_reader.cpp:305] Starting prefetch of epoch 2
I0213 00:50:34.860566  3135 solver.cpp:314] Iteration 9100 (1.42635 iter/s, 70.1092s/100 iter), loss = 2.97423
I0213 00:50:34.860710  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.22628 (* 1 = 2.22628 loss)
I0213 00:50:34.860744  3135 sgd_solver.cpp:136] Iteration 9100, lr = 0.00071967, m = 0.9
I0213 00:51:44.754585  3135 solver.cpp:314] Iteration 9200 (1.43079 iter/s, 69.8917s/100 iter), loss = 3.00191
I0213 00:51:44.754695  3135 solver.cpp:336]     Train net output #0: mbox_loss = 1.89246 (* 1 = 1.89246 loss)
I0213 00:51:44.754712  3135 sgd_solver.cpp:136] Iteration 9200, lr = 0.000716845, m = 0.9
I0213 00:52:54.858964  3135 solver.cpp:314] Iteration 9300 (1.42649 iter/s, 70.1019s/100 iter), loss = 3.07692
I0213 00:52:54.859086  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.7642 (* 1 = 2.7642 loss)
I0213 00:52:54.859104  3135 sgd_solver.cpp:136] Iteration 9300, lr = 0.000714025, m = 0.9
I0213 00:54:05.218516  3135 solver.cpp:314] Iteration 9400 (1.42132 iter/s, 70.3571s/100 iter), loss = 3.01301
I0213 00:54:05.218624  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.11606 (* 1 = 3.11606 loss)
I0213 00:54:05.218641  3135 sgd_solver.cpp:136] Iteration 9400, lr = 0.000711211, m = 0.9
I0213 00:55:15.697669  3135 solver.cpp:314] Iteration 9500 (1.41891 iter/s, 70.4767s/100 iter), loss = 3.11381
I0213 00:55:15.697798  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.76064 (* 1 = 2.76064 loss)
I0213 00:55:15.698196  3135 sgd_solver.cpp:136] Iteration 9500, lr = 0.000708403, m = 0.9
I0213 00:56:25.874333  3135 solver.cpp:314] Iteration 9600 (1.42502 iter/s, 70.1742s/100 iter), loss = 2.89215
I0213 00:56:25.874475  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.29071 (* 1 = 2.29071 loss)
I0213 00:56:25.874512  3135 sgd_solver.cpp:136] Iteration 9600, lr = 0.0007056, m = 0.9
I0213 00:57:35.534797  3135 solver.cpp:314] Iteration 9700 (1.43558 iter/s, 69.6581s/100 iter), loss = 3.14676
I0213 00:57:35.534963  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.16631 (* 1 = 3.16631 loss)
I0213 00:57:35.535006  3135 sgd_solver.cpp:136] Iteration 9700, lr = 0.000702803, m = 0.9
I0213 00:58:44.874426  3135 solver.cpp:314] Iteration 9800 (1.44223 iter/s, 69.3372s/100 iter), loss = 2.94372
I0213 00:58:44.874586  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.30478 (* 1 = 2.30478 loss)
I0213 00:58:44.874624  3135 sgd_solver.cpp:136] Iteration 9800, lr = 0.000700011, m = 0.9
I0213 00:59:54.681028  3135 solver.cpp:314] Iteration 9900 (1.43258 iter/s, 69.8042s/100 iter), loss = 3.18952
I0213 00:59:54.681133  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.05195 (* 1 = 3.05195 loss)
I0213 00:59:54.681149  3135 sgd_solver.cpp:136] Iteration 9900, lr = 0.000697225, m = 0.9
I0213 01:01:04.248077  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_10000.caffemodel
I0213 01:01:04.280566  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_10000.solverstate
I0213 01:01:04.294526  3135 solver.cpp:666] Iteration 10000, Testing net (#0)
I0213 01:01:56.590447  3136 solver.cpp:774] class AP 1: 0.403174
I0213 01:01:56.646037  3136 solver.cpp:774] class AP 2: 0.608554
I0213 01:01:56.658280  3136 solver.cpp:774] class AP 3: 0.632294
I0213 01:01:56.658324  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.548008
I0213 01:01:57.169683  3135 solver.cpp:774] class AP 1: 0.407949
I0213 01:01:57.212118  3135 solver.cpp:774] class AP 2: 0.612843
I0213 01:01:57.221392  3135 solver.cpp:774] class AP 3: 0.63798
I0213 01:01:57.221410  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.552924
I0213 01:01:57.221848  3135 solver.cpp:265] [MultiGPU] Tests completed in 52.9255s
I0213 01:01:57.755817  3135 solver.cpp:314] Iteration 10000 (0.812542 iter/s, 123.071s/100 iter), loss = 3.04353
I0213 01:01:57.755872  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.42064 (* 1 = 3.42064 loss)
I0213 01:01:57.755887  3135 sgd_solver.cpp:136] Iteration 10000, lr = 0.000694444, m = 0.9
I0213 01:03:06.704665  3135 solver.cpp:314] Iteration 10100 (1.4504 iter/s, 68.9465s/100 iter), loss = 3.07719
I0213 01:03:06.704807  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.22972 (* 1 = 2.22972 loss)
I0213 01:03:06.704843  3135 sgd_solver.cpp:136] Iteration 10100, lr = 0.000691669, m = 0.9
I0213 01:04:16.189669  3135 solver.cpp:314] Iteration 10200 (1.43921 iter/s, 69.4826s/100 iter), loss = 3.0778
I0213 01:04:16.189774  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.24252 (* 1 = 2.24252 loss)
I0213 01:04:16.189787  3135 sgd_solver.cpp:136] Iteration 10200, lr = 0.0006889, m = 0.9
I0213 01:05:26.785286  3135 solver.cpp:314] Iteration 10300 (1.41657 iter/s, 70.5932s/100 iter), loss = 2.87561
I0213 01:05:26.785435  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.18812 (* 1 = 3.18812 loss)
I0213 01:05:26.785473  3135 sgd_solver.cpp:136] Iteration 10300, lr = 0.000686136, m = 0.9
I0213 01:06:37.429355  3135 solver.cpp:314] Iteration 10400 (1.4156 iter/s, 70.6416s/100 iter), loss = 3.16881
I0213 01:06:37.429456  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.71432 (* 1 = 2.71432 loss)
I0213 01:06:37.429472  3135 sgd_solver.cpp:136] Iteration 10400, lr = 0.000683378, m = 0.9
I0213 01:07:46.710430  3135 solver.cpp:314] Iteration 10500 (1.44344 iter/s, 69.2787s/100 iter), loss = 3.22547
I0213 01:07:46.710549  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.52991 (* 1 = 3.52991 loss)
I0213 01:07:46.710566  3135 sgd_solver.cpp:136] Iteration 10500, lr = 0.000680625, m = 0.9
I0213 01:08:55.986490  3135 solver.cpp:314] Iteration 10600 (1.44355 iter/s, 69.2737s/100 iter), loss = 2.96979
I0213 01:08:55.986590  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.99778 (* 1 = 3.99778 loss)
I0213 01:08:55.986606  3135 sgd_solver.cpp:136] Iteration 10600, lr = 0.000677878, m = 0.9
I0213 01:10:06.259219  3135 solver.cpp:314] Iteration 10700 (1.42308 iter/s, 70.2703s/100 iter), loss = 2.90879
I0213 01:10:06.259348  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.62083 (* 1 = 3.62083 loss)
I0213 01:10:06.259382  3135 sgd_solver.cpp:136] Iteration 10700, lr = 0.000675136, m = 0.9
I0213 01:11:17.458227  3135 solver.cpp:314] Iteration 10800 (1.40456 iter/s, 71.1966s/100 iter), loss = 3.0631
I0213 01:11:17.458345  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.97864 (* 1 = 2.97864 loss)
I0213 01:11:17.458361  3135 sgd_solver.cpp:136] Iteration 10800, lr = 0.0006724, m = 0.9
I0213 01:12:27.240109  3135 solver.cpp:314] Iteration 10900 (1.43309 iter/s, 69.7795s/100 iter), loss = 3.0678
I0213 01:12:27.240257  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.36686 (* 1 = 3.36686 loss)
I0213 01:12:27.240275  3135 sgd_solver.cpp:136] Iteration 10900, lr = 0.000669669, m = 0.9
I0213 01:13:36.881031  3135 solver.cpp:314] Iteration 11000 (1.43599 iter/s, 69.6386s/100 iter), loss = 3.09935
I0213 01:13:36.881134  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.27528 (* 1 = 3.27528 loss)
I0213 01:13:36.881148  3135 sgd_solver.cpp:136] Iteration 11000, lr = 0.000666944, m = 0.9
I0213 01:14:48.618861  3135 solver.cpp:314] Iteration 11100 (1.39401 iter/s, 71.7354s/100 iter), loss = 3.02061
I0213 01:14:48.618974  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.78946 (* 1 = 2.78946 loss)
I0213 01:14:48.618993  3135 sgd_solver.cpp:136] Iteration 11100, lr = 0.000664225, m = 0.9
I0213 01:15:59.306337  3135 solver.cpp:314] Iteration 11200 (1.41473 iter/s, 70.6851s/100 iter), loss = 2.92139
I0213 01:15:59.306447  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.31691 (* 1 = 2.31691 loss)
I0213 01:15:59.306464  3135 sgd_solver.cpp:136] Iteration 11200, lr = 0.000661511, m = 0.9
I0213 01:17:08.954311  3135 solver.cpp:314] Iteration 11300 (1.43584 iter/s, 69.6456s/100 iter), loss = 2.8007
I0213 01:17:08.954409  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.91486 (* 1 = 2.91486 loss)
I0213 01:17:08.954426  3135 sgd_solver.cpp:136] Iteration 11300, lr = 0.000658803, m = 0.9
I0213 01:18:19.516645  3135 solver.cpp:314] Iteration 11400 (1.41723 iter/s, 70.56s/100 iter), loss = 2.9876
I0213 01:18:19.516736  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.64954 (* 1 = 2.64954 loss)
I0213 01:18:19.516752  3135 sgd_solver.cpp:136] Iteration 11400, lr = 0.0006561, m = 0.9
I0213 01:19:30.045768  3135 solver.cpp:314] Iteration 11500 (1.4179 iter/s, 70.5267s/100 iter), loss = 3.15931
I0213 01:19:30.045891  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.24198 (* 1 = 2.24198 loss)
I0213 01:19:30.045908  3135 sgd_solver.cpp:136] Iteration 11500, lr = 0.000653403, m = 0.9
I0213 01:20:39.678526  3135 solver.cpp:314] Iteration 11600 (1.43615 iter/s, 69.6304s/100 iter), loss = 2.89015
I0213 01:20:39.678638  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.94864 (* 1 = 2.94864 loss)
I0213 01:20:39.678655  3135 sgd_solver.cpp:136] Iteration 11600, lr = 0.000650711, m = 0.9
I0213 01:21:50.455900  3135 solver.cpp:314] Iteration 11700 (1.41293 iter/s, 70.775s/100 iter), loss = 2.98137
I0213 01:21:50.456030  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.653 (* 1 = 3.653 loss)
I0213 01:21:50.456048  3135 sgd_solver.cpp:136] Iteration 11700, lr = 0.000648025, m = 0.9
I0213 01:23:01.747340  3135 solver.cpp:314] Iteration 11800 (1.40274 iter/s, 71.289s/100 iter), loss = 2.8293
I0213 01:23:01.747443  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.83401 (* 1 = 3.83401 loss)
I0213 01:23:01.747459  3135 sgd_solver.cpp:136] Iteration 11800, lr = 0.000645344, m = 0.9
I0213 01:24:12.238334  3135 solver.cpp:314] Iteration 11900 (1.41867 iter/s, 70.4886s/100 iter), loss = 2.98509
I0213 01:24:12.238462  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.38173 (* 1 = 4.38173 loss)
I0213 01:24:12.238482  3135 sgd_solver.cpp:136] Iteration 11900, lr = 0.00064267, m = 0.9
I0213 01:25:21.021898  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_12000.caffemodel
I0213 01:25:21.056505  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_12000.solverstate
I0213 01:25:21.066133  3135 solver.cpp:666] Iteration 12000, Testing net (#0)
I0213 01:26:10.115439  3113 data_reader.cpp:305] Starting prefetch of epoch 3
I0213 01:26:10.890736  3136 solver.cpp:774] class AP 1: 0.375214
I0213 01:26:10.908637  3135 solver.cpp:774] class AP 1: 0.377881
I0213 01:26:10.938328  3136 solver.cpp:774] class AP 2: 0.589237
I0213 01:26:10.949841  3136 solver.cpp:774] class AP 3: 0.608858
I0213 01:26:10.949898  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.524437
I0213 01:26:10.957623  3135 solver.cpp:774] class AP 2: 0.591233
I0213 01:26:10.968401  3135 solver.cpp:774] class AP 3: 0.608176
I0213 01:26:10.968420  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.525764
I0213 01:26:10.968819  3135 solver.cpp:265] [MultiGPU] Tests completed in 49.901s
I0213 01:26:11.514636  3135 solver.cpp:314] Iteration 12000 (0.838418 iter/s, 119.272s/100 iter), loss = 2.98681
I0213 01:26:11.514683  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.82317 (* 1 = 3.82317 loss)
I0213 01:26:11.514698  3135 sgd_solver.cpp:136] Iteration 12000, lr = 0.00064, m = 0.9
I0213 01:27:21.644438  3135 solver.cpp:314] Iteration 12100 (1.42598 iter/s, 70.1273s/100 iter), loss = 3.08607
I0213 01:27:21.644577  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.39764 (* 1 = 3.39764 loss)
I0213 01:27:21.644593  3135 sgd_solver.cpp:136] Iteration 12100, lr = 0.000637336, m = 0.9
I0213 01:28:32.470402  3135 solver.cpp:314] Iteration 12200 (1.41196 iter/s, 70.8235s/100 iter), loss = 3.07454
I0213 01:28:32.470496  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.48473 (* 1 = 2.48473 loss)
I0213 01:28:32.470512  3135 sgd_solver.cpp:136] Iteration 12200, lr = 0.000634678, m = 0.9
I0213 01:29:41.544356  3135 solver.cpp:314] Iteration 12300 (1.44778 iter/s, 69.0715s/100 iter), loss = 3.03035
I0213 01:29:41.544461  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.66554 (* 1 = 3.66554 loss)
I0213 01:29:41.544473  3135 sgd_solver.cpp:136] Iteration 12300, lr = 0.000632025, m = 0.9
I0213 01:30:52.172188  3135 solver.cpp:314] Iteration 12400 (1.41592 iter/s, 70.6253s/100 iter), loss = 2.8928
I0213 01:30:52.172401  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.20308 (* 1 = 3.20308 loss)
I0213 01:30:52.172441  3135 sgd_solver.cpp:136] Iteration 12400, lr = 0.000629378, m = 0.9
I0213 01:32:02.985867  3135 solver.cpp:314] Iteration 12500 (1.41221 iter/s, 70.8112s/100 iter), loss = 3.23303
I0213 01:32:02.985991  3135 solver.cpp:336]     Train net output #0: mbox_loss = 5.71714 (* 1 = 5.71714 loss)
I0213 01:32:02.986011  3135 sgd_solver.cpp:136] Iteration 12500, lr = 0.000626736, m = 0.9
I0213 01:33:14.018339  3135 solver.cpp:314] Iteration 12600 (1.40786 iter/s, 71.03s/100 iter), loss = 2.84712
I0213 01:33:14.018461  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.69711 (* 1 = 2.69711 loss)
I0213 01:33:14.018481  3135 sgd_solver.cpp:136] Iteration 12600, lr = 0.0006241, m = 0.9
I0213 01:34:25.106709  3135 solver.cpp:314] Iteration 12700 (1.40675 iter/s, 71.0859s/100 iter), loss = 2.74812
I0213 01:34:25.106807  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.23595 (* 1 = 2.23595 loss)
I0213 01:34:25.106822  3135 sgd_solver.cpp:136] Iteration 12700, lr = 0.000621469, m = 0.9
I0213 01:35:35.455945  3135 solver.cpp:314] Iteration 12800 (1.42153 iter/s, 70.3468s/100 iter), loss = 2.79181
I0213 01:35:35.456110  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.03814 (* 1 = 3.03814 loss)
I0213 01:35:35.456151  3135 sgd_solver.cpp:136] Iteration 12800, lr = 0.000618844, m = 0.9
I0213 01:36:45.615106  3135 solver.cpp:314] Iteration 12900 (1.42538 iter/s, 70.1567s/100 iter), loss = 2.99539
I0213 01:36:45.615213  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.16167 (* 1 = 3.16167 loss)
I0213 01:36:45.615231  3135 sgd_solver.cpp:136] Iteration 12900, lr = 0.000616225, m = 0.9
I0213 01:37:56.203227  3135 solver.cpp:314] Iteration 13000 (1.41672 iter/s, 70.5856s/100 iter), loss = 3.16777
I0213 01:37:56.203330  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.37837 (* 1 = 3.37837 loss)
I0213 01:37:56.203347  3135 sgd_solver.cpp:136] Iteration 13000, lr = 0.000613611, m = 0.9
I0213 01:39:06.234541  3135 solver.cpp:314] Iteration 13100 (1.42798 iter/s, 70.0289s/100 iter), loss = 3.15162
I0213 01:39:06.234714  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.90107 (* 1 = 3.90107 loss)
I0213 01:39:06.234732  3135 sgd_solver.cpp:136] Iteration 13100, lr = 0.000611003, m = 0.9
I0213 01:40:16.336179  3135 solver.cpp:314] Iteration 13200 (1.42655 iter/s, 70.0992s/100 iter), loss = 2.77468
I0213 01:40:16.336344  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.32289 (* 1 = 3.32289 loss)
I0213 01:40:16.336381  3135 sgd_solver.cpp:136] Iteration 13200, lr = 0.0006084, m = 0.9
I0213 01:41:27.564959  3135 solver.cpp:314] Iteration 13300 (1.40398 iter/s, 71.2263s/100 iter), loss = 2.97658
I0213 01:41:27.565052  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.08632 (* 1 = 3.08632 loss)
I0213 01:41:27.565066  3135 sgd_solver.cpp:136] Iteration 13300, lr = 0.000605803, m = 0.9
I0213 01:42:38.069567  3135 solver.cpp:314] Iteration 13400 (1.4184 iter/s, 70.5021s/100 iter), loss = 3.14218
I0213 01:42:38.069677  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.57943 (* 1 = 2.57943 loss)
I0213 01:42:38.069694  3135 sgd_solver.cpp:136] Iteration 13400, lr = 0.000603211, m = 0.9
I0213 01:43:47.458492  3135 solver.cpp:314] Iteration 13500 (1.4412 iter/s, 69.3865s/100 iter), loss = 2.98765
I0213 01:43:47.462327  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.17216 (* 1 = 3.17216 loss)
I0213 01:43:47.462358  3135 sgd_solver.cpp:136] Iteration 13500, lr = 0.000600625, m = 0.9
I0213 01:44:58.813827  3135 solver.cpp:314] Iteration 13600 (1.40149 iter/s, 71.3527s/100 iter), loss = 3.1226
I0213 01:44:58.813976  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.64495 (* 1 = 2.64495 loss)
I0213 01:44:58.814010  3135 sgd_solver.cpp:136] Iteration 13600, lr = 0.000598044, m = 0.9
I0213 01:46:08.884656  3135 solver.cpp:314] Iteration 13700 (1.42718 iter/s, 70.0683s/100 iter), loss = 3.31752
I0213 01:46:08.884750  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.76697 (* 1 = 2.76697 loss)
I0213 01:46:08.884768  3135 sgd_solver.cpp:136] Iteration 13700, lr = 0.000595469, m = 0.9
I0213 01:47:20.269919  3135 solver.cpp:314] Iteration 13800 (1.4009 iter/s, 71.3827s/100 iter), loss = 3.38167
I0213 01:47:20.270030  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.45847 (* 1 = 3.45847 loss)
I0213 01:47:20.270047  3135 sgd_solver.cpp:136] Iteration 13800, lr = 0.0005929, m = 0.9
I0213 01:48:30.818339  3135 solver.cpp:314] Iteration 13900 (1.41752 iter/s, 70.5458s/100 iter), loss = 2.9715
I0213 01:48:30.818495  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.90867 (* 1 = 2.90867 loss)
I0213 01:48:30.818524  3135 sgd_solver.cpp:136] Iteration 13900, lr = 0.000590336, m = 0.9
I0213 01:49:40.309259  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_14000.caffemodel
I0213 01:49:40.344347  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_14000.solverstate
I0213 01:49:40.358558  3135 solver.cpp:666] Iteration 14000, Testing net (#0)
I0213 01:50:30.003628  3136 solver.cpp:774] class AP 1: 0.372223
I0213 01:50:30.063686  3136 solver.cpp:774] class AP 2: 0.600186
I0213 01:50:30.072595  3136 solver.cpp:774] class AP 3: 0.625557
I0213 01:50:30.072628  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.532655
I0213 01:50:30.394201  3135 solver.cpp:774] class AP 1: 0.372071
I0213 01:50:30.448143  3135 solver.cpp:774] class AP 2: 0.593476
I0213 01:50:30.457803  3135 solver.cpp:774] class AP 3: 0.626852
I0213 01:50:30.457844  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.5308
I0213 01:50:30.458441  3135 solver.cpp:265] [MultiGPU] Tests completed in 50.0981s
I0213 01:50:30.960292  3135 solver.cpp:314] Iteration 14000 (0.83238 iter/s, 120.137s/100 iter), loss = 2.89063
I0213 01:50:30.960350  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.6489 (* 1 = 2.6489 loss)
I0213 01:50:30.960367  3135 sgd_solver.cpp:136] Iteration 14000, lr = 0.000587778, m = 0.9
I0213 01:51:40.713295  3135 solver.cpp:314] Iteration 14100 (1.43368 iter/s, 69.7505s/100 iter), loss = 2.92675
I0213 01:51:40.713426  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.35224 (* 1 = 2.35224 loss)
I0213 01:51:40.713444  3135 sgd_solver.cpp:136] Iteration 14100, lr = 0.000585225, m = 0.9
I0213 01:52:50.925882  3135 solver.cpp:314] Iteration 14200 (1.4243 iter/s, 70.2101s/100 iter), loss = 2.85952
I0213 01:52:50.926878  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.9054 (* 1 = 2.9054 loss)
I0213 01:52:50.926947  3135 sgd_solver.cpp:136] Iteration 14200, lr = 0.000582678, m = 0.9
I0213 01:54:00.871487  3135 solver.cpp:314] Iteration 14300 (1.42973 iter/s, 69.9431s/100 iter), loss = 3.16635
I0213 01:54:00.871634  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.57636 (* 1 = 4.57636 loss)
I0213 01:54:00.871654  3135 sgd_solver.cpp:136] Iteration 14300, lr = 0.000580136, m = 0.9
I0213 01:55:11.054363  3135 solver.cpp:314] Iteration 14400 (1.4249 iter/s, 70.1804s/100 iter), loss = 2.91462
I0213 01:55:11.054457  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.71822 (* 1 = 2.71822 loss)
I0213 01:55:11.054474  3135 sgd_solver.cpp:136] Iteration 14400, lr = 0.0005776, m = 0.9
I0213 01:56:21.651877  3135 solver.cpp:314] Iteration 14500 (1.41653 iter/s, 70.595s/100 iter), loss = 3.10429
I0213 01:56:21.651978  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.02768 (* 1 = 3.02768 loss)
I0213 01:56:21.651996  3135 sgd_solver.cpp:136] Iteration 14500, lr = 0.000575069, m = 0.9
I0213 01:57:32.615715  3135 solver.cpp:314] Iteration 14600 (1.40922 iter/s, 70.9613s/100 iter), loss = 3.0606
I0213 01:57:32.615869  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.05619 (* 1 = 2.05619 loss)
I0213 01:57:32.615905  3135 sgd_solver.cpp:136] Iteration 14600, lr = 0.000572544, m = 0.9
I0213 01:58:43.048655  3135 solver.cpp:314] Iteration 14700 (1.41984 iter/s, 70.4304s/100 iter), loss = 3.20838
I0213 01:58:43.048759  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.3392 (* 1 = 2.3392 loss)
I0213 01:58:43.048777  3135 sgd_solver.cpp:136] Iteration 14700, lr = 0.000570025, m = 0.9
I0213 01:59:54.532212  3135 solver.cpp:314] Iteration 14800 (1.39897 iter/s, 71.481s/100 iter), loss = 2.87257
I0213 01:59:54.532310  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.91411 (* 1 = 2.91411 loss)
I0213 01:59:54.532326  3135 sgd_solver.cpp:136] Iteration 14800, lr = 0.000567511, m = 0.9
I0213 02:01:06.086457  3135 solver.cpp:314] Iteration 14900 (1.39759 iter/s, 71.5517s/100 iter), loss = 3.2219
I0213 02:01:06.086560  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.74553 (* 1 = 2.74553 loss)
I0213 02:01:06.086575  3135 sgd_solver.cpp:136] Iteration 14900, lr = 0.000565003, m = 0.9
I0213 02:01:30.949056  3079 data_reader.cpp:305] Starting prefetch of epoch 3
I0213 02:02:16.976354  3135 solver.cpp:314] Iteration 15000 (1.41069 iter/s, 70.8874s/100 iter), loss = 2.94633
I0213 02:02:16.976454  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.09276 (* 1 = 3.09276 loss)
I0213 02:02:16.976469  3135 sgd_solver.cpp:136] Iteration 15000, lr = 0.0005625, m = 0.9
I0213 02:03:26.860661  3135 solver.cpp:314] Iteration 15100 (1.43099 iter/s, 69.8818s/100 iter), loss = 2.71946
I0213 02:03:26.860975  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.57627 (* 1 = 2.57627 loss)
I0213 02:03:26.860999  3135 sgd_solver.cpp:136] Iteration 15100, lr = 0.000560003, m = 0.9
I0213 02:04:37.098430  3135 solver.cpp:314] Iteration 15200 (1.42379 iter/s, 70.2353s/100 iter), loss = 2.99346
I0213 02:04:37.098589  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.80862 (* 1 = 2.80862 loss)
I0213 02:04:37.098605  3135 sgd_solver.cpp:136] Iteration 15200, lr = 0.000557511, m = 0.9
I0213 02:05:47.958509  3135 solver.cpp:314] Iteration 15300 (1.41128 iter/s, 70.8576s/100 iter), loss = 3.22454
I0213 02:05:47.959025  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.37095 (* 1 = 3.37095 loss)
I0213 02:05:47.959367  3135 sgd_solver.cpp:136] Iteration 15300, lr = 0.000555025, m = 0.9
I0213 02:06:58.642663  3135 solver.cpp:314] Iteration 15400 (1.41479 iter/s, 70.6816s/100 iter), loss = 3.12841
I0213 02:06:58.642776  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.26345 (* 1 = 3.26345 loss)
I0213 02:06:58.642793  3135 sgd_solver.cpp:136] Iteration 15400, lr = 0.000552544, m = 0.9
I0213 02:08:08.594192  3135 solver.cpp:314] Iteration 15500 (1.42961 iter/s, 69.9491s/100 iter), loss = 2.96684
I0213 02:08:08.594734  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.88513 (* 1 = 2.88513 loss)
I0213 02:08:08.594751  3135 sgd_solver.cpp:136] Iteration 15500, lr = 0.000550069, m = 0.9
I0213 02:09:19.009289  3135 solver.cpp:314] Iteration 15600 (1.4202 iter/s, 70.4126s/100 iter), loss = 3.16953
I0213 02:09:19.009400  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.04926 (* 1 = 3.04926 loss)
I0213 02:09:19.009419  3135 sgd_solver.cpp:136] Iteration 15600, lr = 0.0005476, m = 0.9
I0213 02:10:29.642328  3135 solver.cpp:314] Iteration 15700 (1.41582 iter/s, 70.6306s/100 iter), loss = 3.14099
I0213 02:10:29.654397  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.80801 (* 1 = 2.80801 loss)
I0213 02:10:29.654446  3135 sgd_solver.cpp:136] Iteration 15700, lr = 0.000545136, m = 0.9
I0213 02:11:39.897964  3135 solver.cpp:314] Iteration 15800 (1.42342 iter/s, 70.2532s/100 iter), loss = 3.03662
I0213 02:11:39.898074  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.31485 (* 1 = 2.31485 loss)
I0213 02:11:39.898090  3135 sgd_solver.cpp:136] Iteration 15800, lr = 0.000542678, m = 0.9
I0213 02:12:50.801744  3135 solver.cpp:314] Iteration 15900 (1.41041 iter/s, 70.9013s/100 iter), loss = 3.10145
I0213 02:12:50.801846  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.43197 (* 1 = 3.43197 loss)
I0213 02:12:50.801861  3135 sgd_solver.cpp:136] Iteration 15900, lr = 0.000540225, m = 0.9
I0213 02:14:00.423545  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_16000.caffemodel
I0213 02:14:00.456025  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_16000.solverstate
I0213 02:14:00.468628  3135 solver.cpp:666] Iteration 16000, Testing net (#0)
I0213 02:14:49.606351  3136 solver.cpp:774] class AP 1: 0.335978
I0213 02:14:49.662036  3136 solver.cpp:774] class AP 2: 0.614598
I0213 02:14:49.670197  3136 solver.cpp:774] class AP 3: 0.624123
I0213 02:14:49.670217  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.5249
I0213 02:14:50.046339  3135 solver.cpp:774] class AP 1: 0.332734
I0213 02:14:50.100803  3135 solver.cpp:774] class AP 2: 0.622357
I0213 02:14:50.108783  3135 solver.cpp:774] class AP 3: 0.618217
I0213 02:14:50.108808  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.524436
I0213 02:14:50.109331  3135 solver.cpp:265] [MultiGPU] Tests completed in 49.639s
I0213 02:14:50.586184  3135 solver.cpp:314] Iteration 16000 (0.834862 iter/s, 119.78s/100 iter), loss = 2.98353
I0213 02:14:50.586231  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.32387 (* 1 = 2.32387 loss)
I0213 02:14:50.586241  3135 sgd_solver.cpp:136] Iteration 16000, lr = 0.000537778, m = 0.9
I0213 02:16:00.548012  3135 solver.cpp:314] Iteration 16100 (1.4294 iter/s, 69.9594s/100 iter), loss = 3.31564
I0213 02:16:00.548127  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.2755 (* 1 = 3.2755 loss)
I0213 02:16:00.548147  3135 sgd_solver.cpp:136] Iteration 16100, lr = 0.000535336, m = 0.9
I0213 02:17:10.370313  3135 solver.cpp:314] Iteration 16200 (1.43226 iter/s, 69.8199s/100 iter), loss = 2.99471
I0213 02:17:10.370455  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.81248 (* 1 = 3.81248 loss)
I0213 02:17:10.370474  3135 sgd_solver.cpp:136] Iteration 16200, lr = 0.0005329, m = 0.9
I0213 02:18:22.743803  3135 solver.cpp:314] Iteration 16300 (1.38177 iter/s, 72.371s/100 iter), loss = 2.87845
I0213 02:18:22.743903  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.75135 (* 1 = 2.75135 loss)
I0213 02:18:22.743918  3135 sgd_solver.cpp:136] Iteration 16300, lr = 0.00053047, m = 0.9
I0213 02:19:33.144794  3135 solver.cpp:314] Iteration 16400 (1.42048 iter/s, 70.3986s/100 iter), loss = 2.83569
I0213 02:19:33.144912  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.35622 (* 1 = 3.35622 loss)
I0213 02:19:33.144929  3135 sgd_solver.cpp:136] Iteration 16400, lr = 0.000528044, m = 0.9
I0213 02:20:44.241729  3135 solver.cpp:314] Iteration 16500 (1.40658 iter/s, 71.0945s/100 iter), loss = 2.986
I0213 02:20:44.241842  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.75169 (* 1 = 2.75169 loss)
I0213 02:20:44.241860  3135 sgd_solver.cpp:136] Iteration 16500, lr = 0.000525625, m = 0.9
I0213 02:21:55.155869  3135 solver.cpp:314] Iteration 16600 (1.4102 iter/s, 70.9117s/100 iter), loss = 2.91598
I0213 02:21:55.155977  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.87762 (* 1 = 3.87762 loss)
I0213 02:21:55.155994  3135 sgd_solver.cpp:136] Iteration 16600, lr = 0.000523211, m = 0.9
I0213 02:23:06.569106  3135 solver.cpp:314] Iteration 16700 (1.40035 iter/s, 71.4108s/100 iter), loss = 3.12483
I0213 02:23:06.569245  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.60485 (* 1 = 2.60485 loss)
I0213 02:23:06.569272  3135 sgd_solver.cpp:136] Iteration 16700, lr = 0.000520803, m = 0.9
I0213 02:24:17.858645  3135 solver.cpp:314] Iteration 16800 (1.40278 iter/s, 71.2871s/100 iter), loss = 3.06528
I0213 02:24:17.866364  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.41021 (* 1 = 3.41021 loss)
I0213 02:24:17.866400  3135 sgd_solver.cpp:136] Iteration 16800, lr = 0.0005184, m = 0.9
I0213 02:25:28.890697  3135 solver.cpp:314] Iteration 16900 (1.40786 iter/s, 71.0296s/100 iter), loss = 2.96296
I0213 02:25:28.890794  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.12852 (* 1 = 3.12852 loss)
I0213 02:25:28.890810  3135 sgd_solver.cpp:136] Iteration 16900, lr = 0.000516003, m = 0.9
I0213 02:26:40.280396  3135 solver.cpp:314] Iteration 17000 (1.40081 iter/s, 71.3871s/100 iter), loss = 3.18856
I0213 02:26:40.280524  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.79325 (* 1 = 3.79325 loss)
I0213 02:26:40.280540  3135 sgd_solver.cpp:136] Iteration 17000, lr = 0.000513611, m = 0.9
I0213 02:27:51.564285  3135 solver.cpp:314] Iteration 17100 (1.40289 iter/s, 71.2814s/100 iter), loss = 3.03837
I0213 02:27:51.564378  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.175 (* 1 = 3.175 loss)
I0213 02:27:51.564394  3135 sgd_solver.cpp:136] Iteration 17100, lr = 0.000511225, m = 0.9
I0213 02:29:02.630338  3135 solver.cpp:314] Iteration 17200 (1.40719 iter/s, 71.0637s/100 iter), loss = 3.13279
I0213 02:29:02.630441  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.68451 (* 1 = 2.68451 loss)
I0213 02:29:02.630460  3135 sgd_solver.cpp:136] Iteration 17200, lr = 0.000508845, m = 0.9
I0213 02:30:12.912618  3135 solver.cpp:314] Iteration 17300 (1.42288 iter/s, 70.2799s/100 iter), loss = 3.09618
I0213 02:30:12.912725  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.6584 (* 1 = 3.6584 loss)
I0213 02:30:12.912741  3135 sgd_solver.cpp:136] Iteration 17300, lr = 0.00050647, m = 0.9
I0213 02:31:24.127820  3135 solver.cpp:314] Iteration 17400 (1.40424 iter/s, 71.2128s/100 iter), loss = 3.23056
I0213 02:31:24.127967  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.77198 (* 1 = 2.77198 loss)
I0213 02:31:24.128187  3135 sgd_solver.cpp:136] Iteration 17400, lr = 0.0005041, m = 0.9
I0213 02:32:35.588553  3135 solver.cpp:314] Iteration 17500 (1.39942 iter/s, 71.4583s/100 iter), loss = 2.89962
I0213 02:32:35.588693  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.35731 (* 1 = 2.35731 loss)
I0213 02:32:35.588709  3135 sgd_solver.cpp:136] Iteration 17500, lr = 0.000501736, m = 0.9
I0213 02:33:46.209645  3135 solver.cpp:314] Iteration 17600 (1.41605 iter/s, 70.6187s/100 iter), loss = 2.96142
I0213 02:33:46.209782  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.04789 (* 1 = 3.04789 loss)
I0213 02:33:46.209820  3135 sgd_solver.cpp:136] Iteration 17600, lr = 0.000499378, m = 0.9
I0213 02:34:57.951362  3135 solver.cpp:314] Iteration 17700 (1.39394 iter/s, 71.7393s/100 iter), loss = 2.91811
I0213 02:34:57.951483  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.75612 (* 1 = 2.75612 loss)
I0213 02:34:57.951501  3135 sgd_solver.cpp:136] Iteration 17700, lr = 0.000497025, m = 0.9
I0213 02:36:09.160782  3135 solver.cpp:314] Iteration 17800 (1.40436 iter/s, 71.207s/100 iter), loss = 2.99248
I0213 02:36:09.160893  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.72961 (* 1 = 4.72961 loss)
I0213 02:36:09.160909  3135 sgd_solver.cpp:136] Iteration 17800, lr = 0.000494678, m = 0.9
I0213 02:37:20.282368  3135 solver.cpp:314] Iteration 17900 (1.40609 iter/s, 71.1192s/100 iter), loss = 2.90141
I0213 02:37:20.282470  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.09316 (* 1 = 3.09316 loss)
I0213 02:37:20.282488  3135 sgd_solver.cpp:136] Iteration 17900, lr = 0.000492336, m = 0.9
I0213 02:38:30.567384  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_18000.caffemodel
I0213 02:38:30.716444  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_18000.solverstate
I0213 02:38:30.729439  3135 solver.cpp:666] Iteration 18000, Testing net (#0)
I0213 02:39:22.293993  3113 data_reader.cpp:305] Starting prefetch of epoch 4
I0213 02:39:22.408416  3136 solver.cpp:774] class AP 1: 0.396996
I0213 02:39:22.461871  3136 solver.cpp:774] class AP 2: 0.622167
I0213 02:39:22.476379  3136 solver.cpp:774] class AP 3: 0.650968
I0213 02:39:22.476428  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.55671
I0213 02:39:23.318917  3135 solver.cpp:774] class AP 1: 0.392741
I0213 02:39:23.367151  3135 solver.cpp:774] class AP 2: 0.621235
I0213 02:39:23.378818  3135 solver.cpp:774] class AP 3: 0.626953
I0213 02:39:23.378854  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.546976
I0213 02:39:23.378901  3135 solver.cpp:265] [MultiGPU] Tests completed in 52.6477s
I0213 02:39:23.841673  3135 solver.cpp:314] Iteration 18000 (0.809355 iter/s, 123.555s/100 iter), loss = 2.94546
I0213 02:39:23.841722  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.78471 (* 1 = 2.78471 loss)
I0213 02:39:23.841734  3135 sgd_solver.cpp:136] Iteration 18000, lr = 0.00049, m = 0.9
I0213 02:40:33.648077  3135 solver.cpp:314] Iteration 18100 (1.43258 iter/s, 69.8041s/100 iter), loss = 3.1229
I0213 02:40:33.648172  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.50538 (* 1 = 3.50538 loss)
I0213 02:40:33.648187  3135 sgd_solver.cpp:136] Iteration 18100, lr = 0.000487669, m = 0.9
I0213 02:41:44.025387  3135 solver.cpp:314] Iteration 18200 (1.42096 iter/s, 70.375s/100 iter), loss = 3.1033
I0213 02:41:44.025494  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.91702 (* 1 = 2.91702 loss)
I0213 02:41:44.025511  3135 sgd_solver.cpp:136] Iteration 18200, lr = 0.000485344, m = 0.9
I0213 02:42:53.740097  3135 solver.cpp:314] Iteration 18300 (1.43447 iter/s, 69.7124s/100 iter), loss = 2.85686
I0213 02:42:53.740196  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.41209 (* 1 = 2.41209 loss)
I0213 02:42:53.740213  3135 sgd_solver.cpp:136] Iteration 18300, lr = 0.000483025, m = 0.9
I0213 02:44:04.183482  3135 solver.cpp:314] Iteration 18400 (1.41963 iter/s, 70.441s/100 iter), loss = 3.15296
I0213 02:44:04.183640  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.47494 (* 1 = 2.47494 loss)
I0213 02:44:04.183660  3135 sgd_solver.cpp:136] Iteration 18400, lr = 0.000480711, m = 0.9
I0213 02:45:15.806074  3135 solver.cpp:314] Iteration 18500 (1.39625 iter/s, 71.6202s/100 iter), loss = 3.31594
I0213 02:45:15.806187  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.09364 (* 1 = 3.09364 loss)
I0213 02:45:15.806205  3135 sgd_solver.cpp:136] Iteration 18500, lr = 0.000478403, m = 0.9
I0213 02:46:26.930680  3135 solver.cpp:314] Iteration 18600 (1.40603 iter/s, 71.1222s/100 iter), loss = 3.03114
I0213 02:46:26.930784  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.59196 (* 1 = 2.59196 loss)
I0213 02:46:26.930802  3135 sgd_solver.cpp:136] Iteration 18600, lr = 0.0004761, m = 0.9
I0213 02:47:36.983003  3135 solver.cpp:314] Iteration 18700 (1.42755 iter/s, 70.05s/100 iter), loss = 2.81745
I0213 02:47:36.983114  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.0446 (* 1 = 2.0446 loss)
I0213 02:47:36.983131  3135 sgd_solver.cpp:136] Iteration 18700, lr = 0.000473803, m = 0.9
I0213 02:48:47.978335  3135 solver.cpp:314] Iteration 18800 (1.40859 iter/s, 70.993s/100 iter), loss = 2.88883
I0213 02:48:47.978430  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.04199 (* 1 = 3.04199 loss)
I0213 02:48:47.978448  3135 sgd_solver.cpp:136] Iteration 18800, lr = 0.000471511, m = 0.9
I0213 02:49:58.407340  3135 solver.cpp:314] Iteration 18900 (1.41992 iter/s, 70.4267s/100 iter), loss = 3.14392
I0213 02:49:58.407451  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.32357 (* 1 = 3.32357 loss)
I0213 02:49:58.407469  3135 sgd_solver.cpp:136] Iteration 18900, lr = 0.000469225, m = 0.9
I0213 02:51:09.275830  3135 solver.cpp:314] Iteration 19000 (1.41111 iter/s, 70.8661s/100 iter), loss = 2.98969
I0213 02:51:09.276047  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.61548 (* 1 = 3.61548 loss)
I0213 02:51:09.276082  3135 sgd_solver.cpp:136] Iteration 19000, lr = 0.000466944, m = 0.9
I0213 02:52:19.493504  3135 solver.cpp:314] Iteration 19100 (1.42419 iter/s, 70.2153s/100 iter), loss = 3.04994
I0213 02:52:19.493613  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.82165 (* 1 = 2.82165 loss)
I0213 02:52:19.493629  3135 sgd_solver.cpp:136] Iteration 19100, lr = 0.000464669, m = 0.9
I0213 02:53:30.307893  3135 solver.cpp:314] Iteration 19200 (1.41219 iter/s, 70.812s/100 iter), loss = 2.87944
I0213 02:53:30.307996  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.91852 (* 1 = 3.91852 loss)
I0213 02:53:30.308013  3135 sgd_solver.cpp:136] Iteration 19200, lr = 0.0004624, m = 0.9
I0213 02:54:40.800603  3135 solver.cpp:314] Iteration 19300 (1.41863 iter/s, 70.4904s/100 iter), loss = 2.93204
I0213 02:54:40.802429  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.35729 (* 1 = 3.35729 loss)
I0213 02:54:40.802776  3135 sgd_solver.cpp:136] Iteration 19300, lr = 0.000460136, m = 0.9
I0213 02:55:51.674938  3135 solver.cpp:314] Iteration 19400 (1.41099 iter/s, 70.872s/100 iter), loss = 3.01657
I0213 02:55:51.675037  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.88186 (* 1 = 2.88186 loss)
I0213 02:55:51.675055  3135 sgd_solver.cpp:136] Iteration 19400, lr = 0.000457878, m = 0.9
I0213 02:57:02.323854  3135 solver.cpp:314] Iteration 19500 (1.4155 iter/s, 70.6466s/100 iter), loss = 3.25843
I0213 02:57:02.324156  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.97236 (* 1 = 2.97236 loss)
I0213 02:57:02.324187  3135 sgd_solver.cpp:136] Iteration 19500, lr = 0.000455625, m = 0.9
I0213 02:58:12.480515  3135 solver.cpp:314] Iteration 19600 (1.42543 iter/s, 70.1544s/100 iter), loss = 3.02074
I0213 02:58:12.480670  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.13298 (* 1 = 3.13298 loss)
I0213 02:58:12.480686  3135 sgd_solver.cpp:136] Iteration 19600, lr = 0.000453378, m = 0.9
I0213 02:59:23.508523  3135 solver.cpp:314] Iteration 19700 (1.40794 iter/s, 71.0257s/100 iter), loss = 2.97391
I0213 02:59:23.508700  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.203 (* 1 = 3.203 loss)
I0213 02:59:23.508743  3135 sgd_solver.cpp:136] Iteration 19700, lr = 0.000451136, m = 0.9
I0213 03:00:34.444717  3135 solver.cpp:314] Iteration 19800 (1.40976 iter/s, 70.9339s/100 iter), loss = 3.06172
I0213 03:00:34.444844  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.67887 (* 1 = 4.67887 loss)
I0213 03:00:34.444866  3135 sgd_solver.cpp:136] Iteration 19800, lr = 0.0004489, m = 0.9
I0213 03:01:45.182507  3135 solver.cpp:314] Iteration 19900 (1.41372 iter/s, 70.7355s/100 iter), loss = 2.93006
I0213 03:01:45.201493  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.7919 (* 1 = 2.7919 loss)
I0213 03:01:45.201906  3135 sgd_solver.cpp:136] Iteration 19900, lr = 0.000446669, m = 0.9
I0213 03:02:55.489770  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_20000.caffemodel
I0213 03:02:55.556783  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_20000.solverstate
I0213 03:02:55.578567  3135 solver.cpp:666] Iteration 20000, Testing net (#0)
I0213 03:03:44.867696  3135 solver.cpp:774] class AP 1: 0.386135
I0213 03:03:44.919194  3136 solver.cpp:774] class AP 1: 0.389149
I0213 03:03:44.921139  3135 solver.cpp:774] class AP 2: 0.631355
I0213 03:03:44.928448  3135 solver.cpp:774] class AP 3: 0.627952
I0213 03:03:44.928509  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.548481
I0213 03:03:44.973518  3136 solver.cpp:774] class AP 2: 0.625241
I0213 03:03:44.986189  3136 solver.cpp:774] class AP 3: 0.628809
I0213 03:03:44.986284  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.547733
I0213 03:03:44.987067  3135 solver.cpp:265] [MultiGPU] Tests completed in 49.4069s
I0213 03:03:45.506675  3135 solver.cpp:314] Iteration 20000 (0.831115 iter/s, 120.32s/100 iter), loss = 3.12003
I0213 03:03:45.506727  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.67451 (* 1 = 2.67451 loss)
I0213 03:03:45.506742  3135 sgd_solver.cpp:136] Iteration 20000, lr = 0.000444444, m = 0.9
I0213 03:04:55.606304  3135 solver.cpp:314] Iteration 20100 (1.42659 iter/s, 70.0973s/100 iter), loss = 3.00004
I0213 03:04:55.613445  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.34892 (* 1 = 2.34892 loss)
I0213 03:04:55.613490  3135 sgd_solver.cpp:136] Iteration 20100, lr = 0.000442225, m = 0.9
I0213 03:06:05.623710  3135 solver.cpp:314] Iteration 20200 (1.42826 iter/s, 70.0151s/100 iter), loss = 2.80396
I0213 03:06:05.623805  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.99953 (* 1 = 2.99953 loss)
I0213 03:06:05.623816  3135 sgd_solver.cpp:136] Iteration 20200, lr = 0.000440011, m = 0.9
I0213 03:07:15.965651  3135 solver.cpp:314] Iteration 20300 (1.42167 iter/s, 70.3396s/100 iter), loss = 2.99937
I0213 03:07:15.966338  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.8844 (* 1 = 2.8844 loss)
I0213 03:07:15.966372  3135 sgd_solver.cpp:136] Iteration 20300, lr = 0.000437803, m = 0.9
I0213 03:08:28.054947  3135 solver.cpp:314] Iteration 20400 (1.38721 iter/s, 72.087s/100 iter), loss = 3.08033
I0213 03:08:28.055048  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.14205 (* 1 = 3.14205 loss)
I0213 03:08:28.055064  3135 sgd_solver.cpp:136] Iteration 20400, lr = 0.0004356, m = 0.9
I0213 03:09:39.269618  3135 solver.cpp:314] Iteration 20500 (1.40425 iter/s, 71.2124s/100 iter), loss = 3.1134
I0213 03:09:39.269700  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.03828 (* 1 = 3.03828 loss)
I0213 03:09:39.269711  3135 sgd_solver.cpp:136] Iteration 20500, lr = 0.000433403, m = 0.9
I0213 03:10:49.374724  3135 solver.cpp:314] Iteration 20600 (1.42648 iter/s, 70.1028s/100 iter), loss = 2.94184
I0213 03:10:49.374871  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.05408 (* 1 = 3.05408 loss)
I0213 03:10:49.374887  3135 sgd_solver.cpp:136] Iteration 20600, lr = 0.000431211, m = 0.9
I0213 03:11:59.853273  3135 solver.cpp:314] Iteration 20700 (1.41892 iter/s, 70.4763s/100 iter), loss = 3.1959
I0213 03:11:59.853390  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.34434 (* 1 = 3.34434 loss)
I0213 03:11:59.853406  3135 sgd_solver.cpp:136] Iteration 20700, lr = 0.000429025, m = 0.9
I0213 03:13:10.949612  3135 solver.cpp:314] Iteration 20800 (1.40659 iter/s, 71.094s/100 iter), loss = 2.91616
I0213 03:13:10.949724  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.58054 (* 1 = 2.58054 loss)
I0213 03:13:10.949740  3135 sgd_solver.cpp:136] Iteration 20800, lr = 0.000426844, m = 0.9
I0213 03:13:42.628263  3079 data_reader.cpp:305] Starting prefetch of epoch 4
I0213 03:14:21.393007  3135 solver.cpp:314] Iteration 20900 (1.41963 iter/s, 70.4411s/100 iter), loss = 2.90483
I0213 03:14:21.393106  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.80112 (* 1 = 2.80112 loss)
I0213 03:14:21.393122  3135 sgd_solver.cpp:136] Iteration 20900, lr = 0.000424669, m = 0.9
I0213 03:15:31.772220  3135 solver.cpp:314] Iteration 21000 (1.42092 iter/s, 70.3769s/100 iter), loss = 2.90957
I0213 03:15:31.772369  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.36087 (* 1 = 2.36087 loss)
I0213 03:15:31.772405  3135 sgd_solver.cpp:136] Iteration 21000, lr = 0.0004225, m = 0.9
I0213 03:16:41.910338  3135 solver.cpp:314] Iteration 21100 (1.4258 iter/s, 70.1358s/100 iter), loss = 3.2552
I0213 03:16:41.910486  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.86878 (* 1 = 2.86878 loss)
I0213 03:16:41.910527  3135 sgd_solver.cpp:136] Iteration 21100, lr = 0.000420336, m = 0.9
I0213 03:17:52.036862  3135 solver.cpp:314] Iteration 21200 (1.42604 iter/s, 70.1242s/100 iter), loss = 3.01575
I0213 03:17:52.036957  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.57149 (* 1 = 2.57149 loss)
I0213 03:17:52.036973  3135 sgd_solver.cpp:136] Iteration 21200, lr = 0.000418178, m = 0.9
I0213 03:19:03.045236  3135 solver.cpp:314] Iteration 21300 (1.40833 iter/s, 71.0061s/100 iter), loss = 3.15069
I0213 03:19:03.050343  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.45529 (* 1 = 2.45529 loss)
I0213 03:19:03.050372  3135 sgd_solver.cpp:136] Iteration 21300, lr = 0.000416025, m = 0.9
I0213 03:20:14.174471  3135 solver.cpp:314] Iteration 21400 (1.40594 iter/s, 71.1269s/100 iter), loss = 2.87338
I0213 03:20:14.175621  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.84788 (* 1 = 2.84788 loss)
I0213 03:20:14.175648  3135 sgd_solver.cpp:136] Iteration 21400, lr = 0.000413878, m = 0.9
I0213 03:21:24.175097  3135 solver.cpp:314] Iteration 21500 (1.42861 iter/s, 69.9984s/100 iter), loss = 2.96581
I0213 03:21:24.175246  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.08734 (* 1 = 2.08734 loss)
I0213 03:21:24.175281  3135 sgd_solver.cpp:136] Iteration 21500, lr = 0.000411736, m = 0.9
I0213 03:22:34.330822  3135 solver.cpp:314] Iteration 21600 (1.42545 iter/s, 70.1534s/100 iter), loss = 3.00846
I0213 03:22:34.330929  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.3948 (* 1 = 3.3948 loss)
I0213 03:22:34.330945  3135 sgd_solver.cpp:136] Iteration 21600, lr = 0.0004096, m = 0.9
I0213 03:23:44.130317  3135 solver.cpp:314] Iteration 21700 (1.43272 iter/s, 69.7972s/100 iter), loss = 3.02046
I0213 03:23:44.130463  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.52592 (* 1 = 2.52592 loss)
I0213 03:23:44.130501  3135 sgd_solver.cpp:136] Iteration 21700, lr = 0.000407469, m = 0.9
I0213 03:24:54.334528  3135 solver.cpp:314] Iteration 21800 (1.42446 iter/s, 70.2019s/100 iter), loss = 2.95447
I0213 03:24:54.334636  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.68986 (* 1 = 2.68986 loss)
I0213 03:24:54.334653  3135 sgd_solver.cpp:136] Iteration 21800, lr = 0.000405344, m = 0.9
I0213 03:26:05.054282  3135 solver.cpp:314] Iteration 21900 (1.41408 iter/s, 70.7174s/100 iter), loss = 2.98784
I0213 03:26:05.054417  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.26397 (* 1 = 2.26397 loss)
I0213 03:26:05.054433  3135 sgd_solver.cpp:136] Iteration 21900, lr = 0.000403225, m = 0.9
I0213 03:27:15.019251  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_22000.caffemodel
I0213 03:27:15.052225  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_22000.solverstate
I0213 03:27:15.064846  3135 solver.cpp:666] Iteration 22000, Testing net (#0)
I0213 03:27:19.690599  3136 blocking_queue.cpp:40] Data layer prefetch queue empty
I0213 03:28:05.477006  3136 solver.cpp:774] class AP 1: 0.366283
I0213 03:28:05.548903  3136 solver.cpp:774] class AP 2: 0.58575
I0213 03:28:05.561756  3136 solver.cpp:774] class AP 3: 0.625483
I0213 03:28:05.561794  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.525839
I0213 03:28:06.195097  3135 solver.cpp:774] class AP 1: 0.365777
I0213 03:28:06.247483  3135 solver.cpp:774] class AP 2: 0.600224
I0213 03:28:06.257401  3135 solver.cpp:774] class AP 3: 0.626261
I0213 03:28:06.257438  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.530754
I0213 03:28:06.257827  3135 solver.cpp:265] [MultiGPU] Tests completed in 51.1913s
I0213 03:28:06.797040  3135 solver.cpp:314] Iteration 22000 (0.821431 iter/s, 121.739s/100 iter), loss = 2.9504
I0213 03:28:06.797087  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.85189 (* 1 = 2.85189 loss)
I0213 03:28:06.797101  3135 sgd_solver.cpp:136] Iteration 22000, lr = 0.000401111, m = 0.9
I0213 03:29:16.827829  3135 solver.cpp:314] Iteration 22100 (1.42799 iter/s, 70.0285s/100 iter), loss = 2.90751
I0213 03:29:16.828316  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.44113 (* 1 = 3.44113 loss)
I0213 03:29:16.828636  3135 sgd_solver.cpp:136] Iteration 22100, lr = 0.000399003, m = 0.9
I0213 03:30:26.978214  3135 solver.cpp:314] Iteration 22200 (1.42556 iter/s, 70.1481s/100 iter), loss = 2.88993
I0213 03:30:26.978350  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.73948 (* 1 = 3.73948 loss)
I0213 03:30:26.978369  3135 sgd_solver.cpp:136] Iteration 22200, lr = 0.0003969, m = 0.9
I0213 03:31:37.447425  3135 solver.cpp:314] Iteration 22300 (1.41911 iter/s, 70.4669s/100 iter), loss = 2.89787
I0213 03:31:37.447594  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.13125 (* 1 = 3.13125 loss)
I0213 03:31:37.447613  3135 sgd_solver.cpp:136] Iteration 22300, lr = 0.000394803, m = 0.9
I0213 03:32:48.665626  3135 solver.cpp:314] Iteration 22400 (1.40418 iter/s, 71.2159s/100 iter), loss = 3.17055
I0213 03:32:48.665735  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.70615 (* 1 = 2.70615 loss)
I0213 03:32:48.665956  3135 sgd_solver.cpp:136] Iteration 22400, lr = 0.000392711, m = 0.9
I0213 03:33:59.742818  3135 solver.cpp:314] Iteration 22500 (1.40697 iter/s, 71.0749s/100 iter), loss = 2.88272
I0213 03:33:59.742936  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.37512 (* 1 = 4.37512 loss)
I0213 03:33:59.742955  3135 sgd_solver.cpp:136] Iteration 22500, lr = 0.000390625, m = 0.9
I0213 03:35:10.564023  3135 solver.cpp:314] Iteration 22600 (1.41205 iter/s, 70.8189s/100 iter), loss = 2.91922
I0213 03:35:10.564174  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.4738 (* 1 = 3.4738 loss)
I0213 03:35:10.564215  3135 sgd_solver.cpp:136] Iteration 22600, lr = 0.000388544, m = 0.9
I0213 03:36:21.565156  3135 solver.cpp:314] Iteration 22700 (1.40847 iter/s, 70.9988s/100 iter), loss = 2.80144
I0213 03:36:21.565274  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.27116 (* 1 = 3.27116 loss)
I0213 03:36:21.565579  3135 sgd_solver.cpp:136] Iteration 22700, lr = 0.000386469, m = 0.9
I0213 03:37:32.696269  3135 solver.cpp:314] Iteration 22800 (1.4059 iter/s, 71.1288s/100 iter), loss = 2.94871
I0213 03:37:32.696456  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.01857 (* 1 = 3.01857 loss)
I0213 03:37:32.696493  3135 sgd_solver.cpp:136] Iteration 22800, lr = 0.0003844, m = 0.9
I0213 03:38:42.415830  3135 solver.cpp:314] Iteration 22900 (1.43436 iter/s, 69.7173s/100 iter), loss = 3.03492
I0213 03:38:42.415940  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.80889 (* 1 = 2.80889 loss)
I0213 03:38:42.415956  3135 sgd_solver.cpp:136] Iteration 22900, lr = 0.000382336, m = 0.9
I0213 03:39:54.858491  3135 solver.cpp:314] Iteration 23000 (1.38045 iter/s, 72.4403s/100 iter), loss = 2.88898
I0213 03:39:54.858603  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.00057 (* 1 = 3.00057 loss)
I0213 03:39:54.858619  3135 sgd_solver.cpp:136] Iteration 23000, lr = 0.000380278, m = 0.9
I0213 03:41:05.099375  3135 solver.cpp:314] Iteration 23100 (1.42372 iter/s, 70.2386s/100 iter), loss = 2.9174
I0213 03:41:05.099488  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.06847 (* 1 = 3.06847 loss)
I0213 03:41:05.099505  3135 sgd_solver.cpp:136] Iteration 23100, lr = 0.000378225, m = 0.9
I0213 03:42:16.011417  3135 solver.cpp:314] Iteration 23200 (1.41024 iter/s, 70.9098s/100 iter), loss = 2.79885
I0213 03:42:16.011503  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.44088 (* 1 = 3.44088 loss)
I0213 03:42:16.011520  3135 sgd_solver.cpp:136] Iteration 23200, lr = 0.000376178, m = 0.9
I0213 03:43:26.257808  3135 solver.cpp:314] Iteration 23300 (1.42361 iter/s, 70.2441s/100 iter), loss = 2.93317
I0213 03:43:26.258299  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.04612 (* 1 = 3.04612 loss)
I0213 03:43:26.258620  3135 sgd_solver.cpp:136] Iteration 23300, lr = 0.000374136, m = 0.9
I0213 03:44:36.910279  3135 solver.cpp:314] Iteration 23400 (1.41543 iter/s, 70.6502s/100 iter), loss = 3.16295
I0213 03:44:36.910418  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.26928 (* 1 = 3.26928 loss)
I0213 03:44:36.910454  3135 sgd_solver.cpp:136] Iteration 23400, lr = 0.0003721, m = 0.9
I0213 03:45:48.340838  3135 solver.cpp:314] Iteration 23500 (1.40009 iter/s, 71.4241s/100 iter), loss = 2.96193
I0213 03:45:48.340953  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.36416 (* 1 = 2.36416 loss)
I0213 03:45:48.340970  3135 sgd_solver.cpp:136] Iteration 23500, lr = 0.000370069, m = 0.9
I0213 03:46:59.723436  3135 solver.cpp:314] Iteration 23600 (1.40095 iter/s, 71.3803s/100 iter), loss = 2.9236
I0213 03:46:59.723539  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.30564 (* 1 = 2.30564 loss)
I0213 03:46:59.723554  3135 sgd_solver.cpp:136] Iteration 23600, lr = 0.000368044, m = 0.9
I0213 03:48:10.490540  3135 solver.cpp:314] Iteration 23700 (1.41313 iter/s, 70.7648s/100 iter), loss = 2.86946
I0213 03:48:10.490662  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.87847 (* 1 = 2.87847 loss)
I0213 03:48:10.490680  3135 sgd_solver.cpp:136] Iteration 23700, lr = 0.000366025, m = 0.9
I0213 03:49:21.019594  3135 solver.cpp:314] Iteration 23800 (1.4179 iter/s, 70.5268s/100 iter), loss = 3.07506
I0213 03:49:21.019731  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.33848 (* 1 = 3.33848 loss)
I0213 03:49:21.019767  3135 sgd_solver.cpp:136] Iteration 23800, lr = 0.000364011, m = 0.9
I0213 03:50:31.958315  3135 solver.cpp:314] Iteration 23900 (1.40971 iter/s, 70.9364s/100 iter), loss = 2.82855
I0213 03:50:31.958426  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.30711 (* 1 = 3.30711 loss)
I0213 03:50:31.958446  3135 sgd_solver.cpp:136] Iteration 23900, lr = 0.000362003, m = 0.9
I0213 03:51:25.532099  3079 data_reader.cpp:305] Starting prefetch of epoch 5
I0213 03:51:42.522779  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_24000.caffemodel
I0213 03:51:42.596362  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_24000.solverstate
I0213 03:51:42.610908  3135 solver.cpp:666] Iteration 24000, Testing net (#0)
I0213 03:52:33.864411  3136 solver.cpp:774] class AP 1: 0.378218
I0213 03:52:33.919569  3136 solver.cpp:774] class AP 2: 0.64839
I0213 03:52:33.927640  3136 solver.cpp:774] class AP 3: 0.626196
I0213 03:52:33.927681  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.550934
I0213 03:52:33.945814  3135 solver.cpp:774] class AP 1: 0.379178
I0213 03:52:33.999919  3135 solver.cpp:774] class AP 2: 0.642526
I0213 03:52:34.007874  3135 solver.cpp:774] class AP 3: 0.631381
I0213 03:52:34.007891  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.551028
I0213 03:52:34.008301  3135 solver.cpp:265] [MultiGPU] Tests completed in 51.3957s
I0213 03:52:34.471702  3135 solver.cpp:314] Iteration 24000 (0.816264 iter/s, 122.509s/100 iter), loss = 3.05481
I0213 03:52:34.471750  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.88098 (* 1 = 2.88098 loss)
I0213 03:52:34.471762  3135 sgd_solver.cpp:136] Iteration 24000, lr = 0.00036, m = 0.9
I0213 03:53:44.361704  3135 solver.cpp:314] Iteration 24100 (1.43087 iter/s, 69.8877s/100 iter), loss = 2.9108
I0213 03:53:44.361846  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.20694 (* 1 = 3.20694 loss)
I0213 03:53:44.361882  3135 sgd_solver.cpp:136] Iteration 24100, lr = 0.000358003, m = 0.9
I0213 03:54:56.216516  3135 solver.cpp:314] Iteration 24200 (1.39174 iter/s, 71.8525s/100 iter), loss = 2.93242
I0213 03:54:56.216625  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.47828 (* 1 = 2.47828 loss)
I0213 03:54:56.216644  3135 sgd_solver.cpp:136] Iteration 24200, lr = 0.000356011, m = 0.9
I0213 03:56:06.486207  3135 solver.cpp:314] Iteration 24300 (1.42314 iter/s, 70.2674s/100 iter), loss = 3.07073
I0213 03:56:06.486703  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.28514 (* 1 = 3.28514 loss)
I0213 03:56:06.487035  3135 sgd_solver.cpp:136] Iteration 24300, lr = 0.000354025, m = 0.9
I0213 03:57:17.667105  3135 solver.cpp:314] Iteration 24400 (1.40492 iter/s, 71.1786s/100 iter), loss = 2.98532
I0213 03:57:17.667218  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.50469 (* 1 = 3.50469 loss)
I0213 03:57:17.667234  3135 sgd_solver.cpp:136] Iteration 24400, lr = 0.000352045, m = 0.9
I0213 03:58:28.061761  3135 solver.cpp:314] Iteration 24500 (1.42061 iter/s, 70.3924s/100 iter), loss = 2.78452
I0213 03:58:28.061904  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.82663 (* 1 = 2.82663 loss)
I0213 03:58:28.061928  3135 sgd_solver.cpp:136] Iteration 24500, lr = 0.000350069, m = 0.9
I0213 03:59:37.787343  3135 solver.cpp:314] Iteration 24600 (1.43424 iter/s, 69.7233s/100 iter), loss = 2.79781
I0213 03:59:37.787451  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.85664 (* 1 = 2.85664 loss)
I0213 03:59:37.787467  3135 sgd_solver.cpp:136] Iteration 24600, lr = 0.0003481, m = 0.9
I0213 04:00:48.827034  3135 solver.cpp:314] Iteration 24700 (1.40771 iter/s, 71.0374s/100 iter), loss = 2.90344
I0213 04:00:48.827131  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.3542 (* 1 = 3.3542 loss)
I0213 04:00:48.827149  3135 sgd_solver.cpp:136] Iteration 24700, lr = 0.000346136, m = 0.9
I0213 04:01:59.580601  3135 solver.cpp:314] Iteration 24800 (1.4134 iter/s, 70.7513s/100 iter), loss = 3.18763
I0213 04:01:59.580693  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.15408 (* 1 = 2.15408 loss)
I0213 04:01:59.580709  3135 sgd_solver.cpp:136] Iteration 24800, lr = 0.000344178, m = 0.9
I0213 04:03:10.567034  3135 solver.cpp:314] Iteration 24900 (1.40877 iter/s, 70.9841s/100 iter), loss = 2.83644
I0213 04:03:10.567138  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.76626 (* 1 = 2.76626 loss)
I0213 04:03:10.567155  3135 sgd_solver.cpp:136] Iteration 24900, lr = 0.000342225, m = 0.9
I0213 04:04:21.298522  3135 solver.cpp:314] Iteration 25000 (1.41384 iter/s, 70.7292s/100 iter), loss = 2.89338
I0213 04:04:21.298645  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.17166 (* 1 = 2.17166 loss)
I0213 04:04:21.298660  3135 sgd_solver.cpp:136] Iteration 25000, lr = 0.000340278, m = 0.9
I0213 04:05:32.450534  3135 solver.cpp:314] Iteration 25100 (1.40549 iter/s, 71.1497s/100 iter), loss = 2.5977
I0213 04:05:32.450681  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.1337 (* 1 = 3.1337 loss)
I0213 04:05:32.450717  3135 sgd_solver.cpp:136] Iteration 25100, lr = 0.000338336, m = 0.9
I0213 04:06:43.239794  3135 solver.cpp:314] Iteration 25200 (1.41269 iter/s, 70.787s/100 iter), loss = 3.11911
I0213 04:06:43.239954  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.93141 (* 1 = 3.93141 loss)
I0213 04:06:43.239991  3135 sgd_solver.cpp:136] Iteration 25200, lr = 0.0003364, m = 0.9
I0213 04:07:53.665526  3135 solver.cpp:314] Iteration 25300 (1.41998 iter/s, 70.4235s/100 iter), loss = 2.85428
I0213 04:07:53.665642  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.36491 (* 1 = 3.36491 loss)
I0213 04:07:53.665658  3135 sgd_solver.cpp:136] Iteration 25300, lr = 0.00033447, m = 0.9
I0213 04:09:04.331252  3135 solver.cpp:314] Iteration 25400 (1.41516 iter/s, 70.6634s/100 iter), loss = 2.80669
I0213 04:09:04.331403  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.81627 (* 1 = 2.81627 loss)
I0213 04:09:04.331440  3135 sgd_solver.cpp:136] Iteration 25400, lr = 0.000332544, m = 0.9
I0213 04:10:15.294337  3135 solver.cpp:314] Iteration 25500 (1.40923 iter/s, 70.9608s/100 iter), loss = 3.14441
I0213 04:10:15.294457  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.6964 (* 1 = 3.6964 loss)
I0213 04:10:15.294476  3135 sgd_solver.cpp:136] Iteration 25500, lr = 0.000330625, m = 0.9
I0213 04:11:25.983847  3135 solver.cpp:314] Iteration 25600 (1.41468 iter/s, 70.6872s/100 iter), loss = 2.87523
I0213 04:11:25.983948  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.61103 (* 1 = 2.61103 loss)
I0213 04:11:25.983964  3135 sgd_solver.cpp:136] Iteration 25600, lr = 0.000328711, m = 0.9
I0213 04:12:36.648360  3135 solver.cpp:314] Iteration 25700 (1.41518 iter/s, 70.6622s/100 iter), loss = 2.9096
I0213 04:12:36.648492  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.71657 (* 1 = 2.71657 loss)
I0213 04:12:36.648510  3135 sgd_solver.cpp:136] Iteration 25700, lr = 0.000326803, m = 0.9
I0213 04:13:47.537684  3135 solver.cpp:314] Iteration 25800 (1.4107 iter/s, 70.887s/100 iter), loss = 3.18393
I0213 04:13:47.537786  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.53215 (* 1 = 2.53215 loss)
I0213 04:13:47.537798  3135 sgd_solver.cpp:136] Iteration 25800, lr = 0.0003249, m = 0.9
I0213 04:14:57.903090  3135 solver.cpp:314] Iteration 25900 (1.4212 iter/s, 70.3631s/100 iter), loss = 2.77983
I0213 04:14:57.903199  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.27223 (* 1 = 3.27223 loss)
I0213 04:14:57.903216  3135 sgd_solver.cpp:136] Iteration 25900, lr = 0.000323003, m = 0.9
I0213 04:16:07.444111  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_26000.caffemodel
I0213 04:16:07.483067  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_26000.solverstate
I0213 04:16:07.497598  3135 solver.cpp:666] Iteration 26000, Testing net (#0)
I0213 04:16:57.923538  3135 solver.cpp:774] class AP 1: 0.378519
I0213 04:16:57.977509  3135 solver.cpp:774] class AP 2: 0.630044
I0213 04:16:57.986660  3135 solver.cpp:774] class AP 3: 0.629999
I0213 04:16:57.986696  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.546187
I0213 04:16:58.365600  3136 solver.cpp:774] class AP 1: 0.37622
I0213 04:16:58.540666  3136 solver.cpp:774] class AP 2: 0.621169
I0213 04:16:58.548915  3136 solver.cpp:774] class AP 3: 0.62615
I0213 04:16:58.548933  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.54118
I0213 04:16:58.549413  3135 solver.cpp:265] [MultiGPU] Tests completed in 51.0502s
I0213 04:16:59.146548  3135 solver.cpp:314] Iteration 26000 (0.824814 iter/s, 121.24s/100 iter), loss = 2.61282
I0213 04:16:59.146596  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.35223 (* 1 = 2.35223 loss)
I0213 04:16:59.146610  3135 sgd_solver.cpp:136] Iteration 26000, lr = 0.000321111, m = 0.9
I0213 04:18:09.375370  3135 solver.cpp:314] Iteration 26100 (1.42396 iter/s, 70.2265s/100 iter), loss = 2.79384
I0213 04:18:09.375504  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.62265 (* 1 = 2.62265 loss)
I0213 04:18:09.375742  3135 sgd_solver.cpp:136] Iteration 26100, lr = 0.000319225, m = 0.9
I0213 04:19:20.452293  3135 solver.cpp:314] Iteration 26200 (1.40697 iter/s, 71.0746s/100 iter), loss = 2.85726
I0213 04:19:20.452385  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.89689 (* 1 = 2.89689 loss)
I0213 04:19:20.452399  3135 sgd_solver.cpp:136] Iteration 26200, lr = 0.000317344, m = 0.9
I0213 04:20:31.536465  3135 solver.cpp:314] Iteration 26300 (1.40683 iter/s, 71.0819s/100 iter), loss = 3.02359
I0213 04:20:31.536613  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.77743 (* 1 = 2.77743 loss)
I0213 04:20:31.536649  3135 sgd_solver.cpp:136] Iteration 26300, lr = 0.000315469, m = 0.9
I0213 04:21:43.079619  3135 solver.cpp:314] Iteration 26400 (1.3978 iter/s, 71.5408s/100 iter), loss = 2.96223
I0213 04:21:43.079743  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.48454 (* 1 = 2.48454 loss)
I0213 04:21:43.079762  3135 sgd_solver.cpp:136] Iteration 26400, lr = 0.0003136, m = 0.9
I0213 04:22:53.365171  3135 solver.cpp:314] Iteration 26500 (1.42281 iter/s, 70.2833s/100 iter), loss = 2.67744
I0213 04:22:53.365279  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.1454 (* 1 = 2.1454 loss)
I0213 04:22:53.365296  3135 sgd_solver.cpp:136] Iteration 26500, lr = 0.000311736, m = 0.9
I0213 04:24:04.273882  3135 solver.cpp:314] Iteration 26600 (1.41031 iter/s, 70.9064s/100 iter), loss = 2.93643
I0213 04:24:04.273994  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.42963 (* 1 = 2.42963 loss)
I0213 04:24:04.274011  3135 sgd_solver.cpp:136] Iteration 26600, lr = 0.000309878, m = 0.9
I0213 04:25:15.422159  3135 solver.cpp:314] Iteration 26700 (1.40556 iter/s, 71.146s/100 iter), loss = 2.9436
I0213 04:25:15.422302  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.78117 (* 1 = 2.78117 loss)
I0213 04:25:15.422323  3135 sgd_solver.cpp:136] Iteration 26700, lr = 0.000308025, m = 0.9
I0213 04:25:54.630658  3079 data_reader.cpp:305] Starting prefetch of epoch 6
I0213 04:26:25.570070  3135 solver.cpp:314] Iteration 26800 (1.42561 iter/s, 70.1456s/100 iter), loss = 3.21345
I0213 04:26:25.570169  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.8641 (* 1 = 2.8641 loss)
I0213 04:26:25.570186  3135 sgd_solver.cpp:136] Iteration 26800, lr = 0.000306178, m = 0.9
I0213 04:27:35.645977  3135 solver.cpp:314] Iteration 26900 (1.42707 iter/s, 70.0736s/100 iter), loss = 2.85114
I0213 04:27:35.646098  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.2638 (* 1 = 2.2638 loss)
I0213 04:27:35.646361  3135 sgd_solver.cpp:136] Iteration 26900, lr = 0.000304336, m = 0.9
I0213 04:28:46.911710  3135 solver.cpp:314] Iteration 27000 (1.40324 iter/s, 71.2634s/100 iter), loss = 2.89907
I0213 04:28:46.911819  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.80271 (* 1 = 3.80271 loss)
I0213 04:28:46.911836  3135 sgd_solver.cpp:136] Iteration 27000, lr = 0.0003025, m = 0.9
I0213 04:29:56.776057  3135 solver.cpp:314] Iteration 27100 (1.43139 iter/s, 69.8621s/100 iter), loss = 2.76928
I0213 04:29:56.776211  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.98474 (* 1 = 2.98474 loss)
I0213 04:29:56.776228  3135 sgd_solver.cpp:136] Iteration 27100, lr = 0.000300669, m = 0.9
I0213 04:31:08.249920  3135 solver.cpp:314] Iteration 27200 (1.39916 iter/s, 71.4715s/100 iter), loss = 2.98735
I0213 04:31:08.250023  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.73968 (* 1 = 2.73968 loss)
I0213 04:31:08.250257  3135 sgd_solver.cpp:136] Iteration 27200, lr = 0.000298844, m = 0.9
I0213 04:32:18.622941  3135 solver.cpp:314] Iteration 27300 (1.42105 iter/s, 70.3707s/100 iter), loss = 3.09334
I0213 04:32:18.623039  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.20639 (* 1 = 3.20639 loss)
I0213 04:32:18.623054  3135 sgd_solver.cpp:136] Iteration 27300, lr = 0.000297025, m = 0.9
I0213 04:33:29.358388  3135 solver.cpp:314] Iteration 27400 (1.41376 iter/s, 70.7332s/100 iter), loss = 3.06062
I0213 04:33:29.358544  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.02586 (* 1 = 3.02586 loss)
I0213 04:33:29.358562  3135 sgd_solver.cpp:136] Iteration 27400, lr = 0.000295211, m = 0.9
I0213 04:34:40.332996  3135 solver.cpp:314] Iteration 27500 (1.409 iter/s, 70.9723s/100 iter), loss = 2.92637
I0213 04:34:40.333108  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.3194 (* 1 = 2.3194 loss)
I0213 04:34:40.333292  3135 sgd_solver.cpp:136] Iteration 27500, lr = 0.000293403, m = 0.9
I0213 04:35:51.300940  3135 solver.cpp:314] Iteration 27600 (1.40913 iter/s, 70.9657s/100 iter), loss = 2.79501
I0213 04:35:51.301053  3135 solver.cpp:336]     Train net output #0: mbox_loss = 1.66817 (* 1 = 1.66817 loss)
I0213 04:35:51.301069  3135 sgd_solver.cpp:136] Iteration 27600, lr = 0.0002916, m = 0.9
I0213 04:37:01.738791  3135 solver.cpp:314] Iteration 27700 (1.41974 iter/s, 70.4356s/100 iter), loss = 3.03776
I0213 04:37:01.738927  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.13472 (* 1 = 3.13472 loss)
I0213 04:37:01.738942  3135 sgd_solver.cpp:136] Iteration 27700, lr = 0.000289803, m = 0.9
I0213 04:38:12.670768  3135 solver.cpp:314] Iteration 27800 (1.40985 iter/s, 70.9297s/100 iter), loss = 3.04472
I0213 04:38:12.670866  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.6453 (* 1 = 2.6453 loss)
I0213 04:38:12.670881  3135 sgd_solver.cpp:136] Iteration 27800, lr = 0.000288011, m = 0.9
I0213 04:39:23.471658  3135 solver.cpp:314] Iteration 27900 (1.41246 iter/s, 70.7986s/100 iter), loss = 3.05138
I0213 04:39:23.471768  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.76186 (* 1 = 2.76186 loss)
I0213 04:39:23.471784  3135 sgd_solver.cpp:136] Iteration 27900, lr = 0.000286225, m = 0.9
I0213 04:40:33.947860  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_28000.caffemodel
I0213 04:40:33.988082  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_28000.solverstate
I0213 04:40:34.001399  3135 solver.cpp:666] Iteration 28000, Testing net (#0)
I0213 04:41:24.266901  3135 solver.cpp:774] class AP 1: 0.394744
I0213 04:41:24.297158  3136 solver.cpp:774] class AP 1: 0.389243
I0213 04:41:24.327957  3135 solver.cpp:774] class AP 2: 0.605713
I0213 04:41:24.341958  3135 solver.cpp:774] class AP 3: 0.632921
I0213 04:41:24.342001  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.544459
I0213 04:41:24.354959  3136 solver.cpp:774] class AP 2: 0.609405
I0213 04:41:24.365319  3136 solver.cpp:774] class AP 3: 0.632025
I0213 04:41:24.365353  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.543558
I0213 04:41:24.365628  3135 solver.cpp:265] [MultiGPU] Tests completed in 50.3626s
I0213 04:41:24.915161  3135 solver.cpp:314] Iteration 28000 (0.823455 iter/s, 121.44s/100 iter), loss = 3.08556
I0213 04:41:24.915251  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.5586 (* 1 = 3.5586 loss)
I0213 04:41:24.915284  3135 sgd_solver.cpp:136] Iteration 28000, lr = 0.000284444, m = 0.9
I0213 04:42:35.934430  3135 solver.cpp:314] Iteration 28100 (1.40811 iter/s, 71.017s/100 iter), loss = 2.71068
I0213 04:42:35.934567  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.03179 (* 1 = 3.03179 loss)
I0213 04:42:35.934584  3135 sgd_solver.cpp:136] Iteration 28100, lr = 0.000282669, m = 0.9
I0213 04:43:46.843127  3135 solver.cpp:314] Iteration 28200 (1.41031 iter/s, 70.9064s/100 iter), loss = 3.00578
I0213 04:43:46.846858  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.1223 (* 1 = 3.1223 loss)
I0213 04:43:46.846876  3135 sgd_solver.cpp:136] Iteration 28200, lr = 0.0002809, m = 0.9
I0213 04:44:57.514361  3135 solver.cpp:314] Iteration 28300 (1.41505 iter/s, 70.669s/100 iter), loss = 3.01971
I0213 04:44:57.514468  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.13693 (* 1 = 2.13693 loss)
I0213 04:44:57.514487  3135 sgd_solver.cpp:136] Iteration 28300, lr = 0.000279136, m = 0.9
I0213 04:46:08.110532  3135 solver.cpp:314] Iteration 28400 (1.41655 iter/s, 70.5939s/100 iter), loss = 3.08652
I0213 04:46:08.110630  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.46026 (* 1 = 2.46026 loss)
I0213 04:46:08.110649  3135 sgd_solver.cpp:136] Iteration 28400, lr = 0.000277378, m = 0.9
I0213 04:47:18.229321  3135 solver.cpp:314] Iteration 28500 (1.4262 iter/s, 70.1165s/100 iter), loss = 2.93823
I0213 04:47:18.229430  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.75003 (* 1 = 2.75003 loss)
I0213 04:47:18.229449  3135 sgd_solver.cpp:136] Iteration 28500, lr = 0.000275625, m = 0.9
I0213 04:48:29.005537  3135 solver.cpp:314] Iteration 28600 (1.41295 iter/s, 70.7739s/100 iter), loss = 2.89433
I0213 04:48:29.005658  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.82047 (* 1 = 2.82047 loss)
I0213 04:48:29.005674  3135 sgd_solver.cpp:136] Iteration 28600, lr = 0.000273878, m = 0.9
I0213 04:49:39.873080  3135 solver.cpp:314] Iteration 28700 (1.41113 iter/s, 70.8653s/100 iter), loss = 3.16253
I0213 04:49:39.873216  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.31712 (* 1 = 3.31712 loss)
I0213 04:49:39.873250  3135 sgd_solver.cpp:136] Iteration 28700, lr = 0.000272136, m = 0.9
I0213 04:50:51.147539  3135 solver.cpp:314] Iteration 28800 (1.40307 iter/s, 71.2722s/100 iter), loss = 2.99603
I0213 04:50:51.147653  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.13315 (* 1 = 2.13315 loss)
I0213 04:50:51.147672  3135 sgd_solver.cpp:136] Iteration 28800, lr = 0.0002704, m = 0.9
I0213 04:52:02.178946  3135 solver.cpp:314] Iteration 28900 (1.40787 iter/s, 71.0291s/100 iter), loss = 3.09308
I0213 04:52:02.179122  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.91282 (* 1 = 4.91282 loss)
I0213 04:52:02.179139  3135 sgd_solver.cpp:136] Iteration 28900, lr = 0.000268669, m = 0.9
I0213 04:53:12.615111  3135 solver.cpp:314] Iteration 29000 (1.41977 iter/s, 70.4339s/100 iter), loss = 2.94095
I0213 04:53:12.615219  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.07142 (* 1 = 2.07142 loss)
I0213 04:53:12.615238  3135 sgd_solver.cpp:136] Iteration 29000, lr = 0.000266944, m = 0.9
I0213 04:54:24.322789  3135 solver.cpp:314] Iteration 29100 (1.3946 iter/s, 71.7054s/100 iter), loss = 3.03124
I0213 04:54:24.322895  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.08416 (* 1 = 4.08416 loss)
I0213 04:54:24.322909  3135 sgd_solver.cpp:136] Iteration 29100, lr = 0.000265225, m = 0.9
I0213 04:55:35.242321  3135 solver.cpp:314] Iteration 29200 (1.41009 iter/s, 70.9172s/100 iter), loss = 2.73556
I0213 04:55:35.242422  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.20638 (* 1 = 2.20638 loss)
I0213 04:55:35.242439  3135 sgd_solver.cpp:136] Iteration 29200, lr = 0.000263511, m = 0.9
I0213 04:56:45.552601  3135 solver.cpp:314] Iteration 29300 (1.42231 iter/s, 70.308s/100 iter), loss = 2.92427
I0213 04:56:45.558336  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.69566 (* 1 = 2.69566 loss)
I0213 04:56:45.558365  3135 sgd_solver.cpp:136] Iteration 29300, lr = 0.000261803, m = 0.9
I0213 04:57:56.906519  3135 solver.cpp:314] Iteration 29400 (1.40151 iter/s, 71.3516s/100 iter), loss = 2.84441
I0213 04:57:56.906659  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.2968 (* 1 = 2.2968 loss)
I0213 04:57:56.906678  3135 sgd_solver.cpp:136] Iteration 29400, lr = 0.0002601, m = 0.9
I0213 04:59:08.110944  3135 solver.cpp:314] Iteration 29500 (1.40445 iter/s, 71.2021s/100 iter), loss = 3.13165
I0213 04:59:08.111096  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.57874 (* 1 = 2.57874 loss)
I0213 04:59:08.111136  3135 sgd_solver.cpp:136] Iteration 29500, lr = 0.000258403, m = 0.9
I0213 05:00:19.417256  3135 solver.cpp:314] Iteration 29600 (1.40245 iter/s, 71.304s/100 iter), loss = 2.93577
I0213 05:00:19.417414  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.30743 (* 1 = 2.30743 loss)
I0213 05:00:19.417433  3135 sgd_solver.cpp:136] Iteration 29600, lr = 0.000256711, m = 0.9
I0213 05:01:30.771219  3135 solver.cpp:314] Iteration 29700 (1.40151 iter/s, 71.3517s/100 iter), loss = 2.98068
I0213 05:01:30.771332  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.5842 (* 1 = 3.5842 loss)
I0213 05:01:30.771350  3135 sgd_solver.cpp:136] Iteration 29700, lr = 0.000255025, m = 0.9
I0213 05:02:40.990097  3135 solver.cpp:314] Iteration 29800 (1.42416 iter/s, 70.2166s/100 iter), loss = 2.93348
I0213 05:02:40.990211  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.53699 (* 1 = 2.53699 loss)
I0213 05:02:40.990229  3135 sgd_solver.cpp:136] Iteration 29800, lr = 0.000253344, m = 0.9
I0213 05:03:39.510797  3079 data_reader.cpp:305] Starting prefetch of epoch 7
I0213 05:03:51.440718  3135 solver.cpp:314] Iteration 29900 (1.41948 iter/s, 70.4483s/100 iter), loss = 2.8498
I0213 05:03:51.440775  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.80683 (* 1 = 2.80683 loss)
I0213 05:03:51.440793  3135 sgd_solver.cpp:136] Iteration 29900, lr = 0.000251669, m = 0.9
I0213 05:05:00.629882  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_30000.caffemodel
I0213 05:05:00.664077  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_30000.solverstate
I0213 05:05:00.678439  3135 solver.cpp:666] Iteration 30000, Testing net (#0)
I0213 05:05:52.640934  3135 solver.cpp:774] class AP 1: 0.36462
I0213 05:05:52.694180  3135 solver.cpp:774] class AP 2: 0.604851
I0213 05:05:52.703357  3135 solver.cpp:774] class AP 3: 0.627071
I0213 05:05:52.703398  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.532181
I0213 05:05:53.631225  3136 solver.cpp:774] class AP 1: 0.368552
I0213 05:05:53.683930  3136 solver.cpp:774] class AP 2: 0.611844
I0213 05:05:53.692723  3136 solver.cpp:774] class AP 3: 0.625562
I0213 05:05:53.692757  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.535319
I0213 05:05:53.693310  3135 solver.cpp:265] [MultiGPU] Tests completed in 53.0132s
I0213 05:05:54.141870  3135 solver.cpp:314] Iteration 30000 (0.815014 iter/s, 122.697s/100 iter), loss = 2.74547
I0213 05:05:54.141916  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.08029 (* 1 = 3.08029 loss)
I0213 05:05:54.141929  3135 sgd_solver.cpp:136] Iteration 30000, lr = 0.00025, m = 0.9
I0213 05:07:03.881789  3135 solver.cpp:314] Iteration 30100 (1.43395 iter/s, 69.7377s/100 iter), loss = 3.03201
I0213 05:07:03.882081  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.63015 (* 1 = 2.63015 loss)
I0213 05:07:03.882102  3135 sgd_solver.cpp:136] Iteration 30100, lr = 0.000248336, m = 0.9
I0213 05:08:14.699146  3135 solver.cpp:314] Iteration 30200 (1.41213 iter/s, 70.8151s/100 iter), loss = 3.07093
I0213 05:08:14.699287  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.21837 (* 1 = 3.21837 loss)
I0213 05:08:14.699306  3135 sgd_solver.cpp:136] Iteration 30200, lr = 0.000246678, m = 0.9
I0213 05:09:25.961526  3135 solver.cpp:314] Iteration 30300 (1.40331 iter/s, 71.2601s/100 iter), loss = 3.03062
I0213 05:09:25.961647  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.63385 (* 1 = 2.63385 loss)
I0213 05:09:25.961666  3135 sgd_solver.cpp:136] Iteration 30300, lr = 0.000245025, m = 0.9
I0213 05:10:36.029649  3135 solver.cpp:314] Iteration 30400 (1.42723 iter/s, 70.0659s/100 iter), loss = 2.89509
I0213 05:10:36.029801  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.97071 (* 1 = 2.97071 loss)
I0213 05:10:36.029839  3135 sgd_solver.cpp:136] Iteration 30400, lr = 0.000243378, m = 0.9
I0213 05:11:46.561579  3135 solver.cpp:314] Iteration 30500 (1.41784 iter/s, 70.5296s/100 iter), loss = 2.91733
I0213 05:11:46.561683  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.51529 (* 1 = 3.51529 loss)
I0213 05:11:46.562088  3135 sgd_solver.cpp:136] Iteration 30500, lr = 0.000241736, m = 0.9
I0213 05:12:57.626328  3135 solver.cpp:314] Iteration 30600 (1.40725 iter/s, 71.0605s/100 iter), loss = 2.85468
I0213 05:12:57.626440  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.862 (* 1 = 2.862 loss)
I0213 05:12:57.626456  3135 sgd_solver.cpp:136] Iteration 30600, lr = 0.0002401, m = 0.9
I0213 05:14:08.730496  3135 solver.cpp:314] Iteration 30700 (1.40643 iter/s, 71.1019s/100 iter), loss = 2.97903
I0213 05:14:08.730600  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.6472 (* 1 = 2.6472 loss)
I0213 05:14:08.730619  3135 sgd_solver.cpp:136] Iteration 30700, lr = 0.000238469, m = 0.9
I0213 05:15:20.353787  3135 solver.cpp:314] Iteration 30800 (1.39624 iter/s, 71.621s/100 iter), loss = 2.8645
I0213 05:15:20.353894  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.24408 (* 1 = 2.24408 loss)
I0213 05:15:20.353910  3135 sgd_solver.cpp:136] Iteration 30800, lr = 0.000236844, m = 0.9
I0213 05:16:31.876940  3135 solver.cpp:314] Iteration 30900 (1.39819 iter/s, 71.5208s/100 iter), loss = 2.9111
I0213 05:16:31.877032  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.4143 (* 1 = 2.4143 loss)
I0213 05:16:31.877048  3135 sgd_solver.cpp:136] Iteration 30900, lr = 0.000235225, m = 0.9
I0213 05:17:43.687032  3135 solver.cpp:314] Iteration 31000 (1.39261 iter/s, 71.8078s/100 iter), loss = 2.7843
I0213 05:17:43.687144  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.12928 (* 1 = 2.12928 loss)
I0213 05:17:43.687161  3135 sgd_solver.cpp:136] Iteration 31000, lr = 0.000233611, m = 0.9
I0213 05:18:54.056355  3135 solver.cpp:314] Iteration 31100 (1.42112 iter/s, 70.3671s/100 iter), loss = 2.96168
I0213 05:18:54.056462  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.9449 (* 1 = 2.9449 loss)
I0213 05:18:54.056478  3135 sgd_solver.cpp:136] Iteration 31100, lr = 0.000232003, m = 0.9
I0213 05:20:05.328088  3135 solver.cpp:314] Iteration 31200 (1.40313 iter/s, 71.2694s/100 iter), loss = 2.84685
I0213 05:20:05.328208  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.86981 (* 1 = 2.86981 loss)
I0213 05:20:05.328227  3135 sgd_solver.cpp:136] Iteration 31200, lr = 0.0002304, m = 0.9
I0213 05:21:16.350636  3135 solver.cpp:314] Iteration 31300 (1.40805 iter/s, 71.0202s/100 iter), loss = 2.96919
I0213 05:21:16.350747  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.34652 (* 1 = 4.34652 loss)
I0213 05:21:16.350764  3135 sgd_solver.cpp:136] Iteration 31300, lr = 0.000228803, m = 0.9
I0213 05:22:27.684135  3135 solver.cpp:314] Iteration 31400 (1.40191 iter/s, 71.3312s/100 iter), loss = 3.11502
I0213 05:22:27.684249  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.33926 (* 1 = 3.33926 loss)
I0213 05:22:27.684268  3135 sgd_solver.cpp:136] Iteration 31400, lr = 0.000227211, m = 0.9
I0213 05:23:38.612015  3135 solver.cpp:314] Iteration 31500 (1.40993 iter/s, 70.9256s/100 iter), loss = 2.81535
I0213 05:23:38.612162  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.63259 (* 1 = 2.63259 loss)
I0213 05:23:38.612181  3135 sgd_solver.cpp:136] Iteration 31500, lr = 0.000225625, m = 0.9
I0213 05:24:49.377351  3135 solver.cpp:314] Iteration 31600 (1.41317 iter/s, 70.7631s/100 iter), loss = 2.94051
I0213 05:24:49.377493  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.68707 (* 1 = 3.68707 loss)
I0213 05:24:49.377512  3135 sgd_solver.cpp:136] Iteration 31600, lr = 0.000224044, m = 0.9
I0213 05:26:00.755739  3135 solver.cpp:314] Iteration 31700 (1.40103 iter/s, 71.3761s/100 iter), loss = 2.83356
I0213 05:26:00.758311  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.30999 (* 1 = 3.30999 loss)
I0213 05:26:00.758332  3135 sgd_solver.cpp:136] Iteration 31700, lr = 0.000222469, m = 0.9
I0213 05:27:11.336661  3135 solver.cpp:314] Iteration 31800 (1.41686 iter/s, 70.5786s/100 iter), loss = 2.84542
I0213 05:27:11.336779  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.8087 (* 1 = 2.8087 loss)
I0213 05:27:11.336797  3135 sgd_solver.cpp:136] Iteration 31800, lr = 0.0002209, m = 0.9
I0213 05:28:21.903496  3135 solver.cpp:314] Iteration 31900 (1.41714 iter/s, 70.5645s/100 iter), loss = 2.8536
I0213 05:28:21.903645  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.56987 (* 1 = 2.56987 loss)
I0213 05:28:21.903682  3135 sgd_solver.cpp:136] Iteration 31900, lr = 0.000219336, m = 0.9
I0213 05:29:32.362756  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_32000.caffemodel
I0213 05:29:32.399304  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_32000.solverstate
I0213 05:29:32.413844  3135 solver.cpp:666] Iteration 32000, Testing net (#0)
I0213 05:30:24.121577  3136 solver.cpp:774] class AP 1: 0.374312
I0213 05:30:24.175406  3136 solver.cpp:774] class AP 2: 0.632756
I0213 05:30:24.183311  3136 solver.cpp:774] class AP 3: 0.633517
I0213 05:30:24.183331  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.546861
I0213 05:30:24.863831  3135 solver.cpp:774] class AP 1: 0.369555
I0213 05:30:24.916409  3135 solver.cpp:774] class AP 2: 0.637601
I0213 05:30:24.924192  3135 solver.cpp:774] class AP 3: 0.628345
I0213 05:30:24.924248  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.545167
I0213 05:30:24.924644  3135 solver.cpp:265] [MultiGPU] Tests completed in 52.5091s
I0213 05:30:25.442649  3135 solver.cpp:314] Iteration 32000 (0.809486 iter/s, 123.535s/100 iter), loss = 3.14381
I0213 05:30:25.442700  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.45274 (* 1 = 3.45274 loss)
I0213 05:30:25.442714  3135 sgd_solver.cpp:136] Iteration 32000, lr = 0.000217778, m = 0.9
I0213 05:31:35.755254  3135 solver.cpp:314] Iteration 32100 (1.42227 iter/s, 70.3103s/100 iter), loss = 3.09285
I0213 05:31:35.755378  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.02907 (* 1 = 4.02907 loss)
I0213 05:31:35.755394  3135 sgd_solver.cpp:136] Iteration 32100, lr = 0.000216225, m = 0.9
I0213 05:32:46.582182  3135 solver.cpp:314] Iteration 32200 (1.41194 iter/s, 70.8246s/100 iter), loss = 2.83709
I0213 05:32:46.582299  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.72887 (* 1 = 2.72887 loss)
I0213 05:32:46.582315  3135 sgd_solver.cpp:136] Iteration 32200, lr = 0.000214678, m = 0.9
I0213 05:33:58.198921  3135 solver.cpp:314] Iteration 32300 (1.39637 iter/s, 71.6144s/100 iter), loss = 3.01141
I0213 05:33:58.199028  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.34284 (* 1 = 2.34284 loss)
I0213 05:33:58.199045  3135 sgd_solver.cpp:136] Iteration 32300, lr = 0.000213136, m = 0.9
I0213 05:35:08.846453  3135 solver.cpp:314] Iteration 32400 (1.41552 iter/s, 70.6452s/100 iter), loss = 2.80497
I0213 05:35:08.846583  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.49806 (* 1 = 3.49806 loss)
I0213 05:35:08.846599  3135 sgd_solver.cpp:136] Iteration 32400, lr = 0.0002116, m = 0.9
I0213 05:36:19.579079  3135 solver.cpp:314] Iteration 32500 (1.41382 iter/s, 70.7303s/100 iter), loss = 3.03271
I0213 05:36:19.579237  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.373 (* 1 = 2.373 loss)
I0213 05:36:19.579275  3135 sgd_solver.cpp:136] Iteration 32500, lr = 0.000210069, m = 0.9
I0213 05:37:30.813906  3135 solver.cpp:314] Iteration 32600 (1.40385 iter/s, 71.2325s/100 iter), loss = 3.14941
I0213 05:37:30.814045  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.97179 (* 1 = 2.97179 loss)
I0213 05:37:30.814064  3135 sgd_solver.cpp:136] Iteration 32600, lr = 0.000208544, m = 0.9
I0213 05:38:17.773830  3079 data_reader.cpp:305] Starting prefetch of epoch 8
I0213 05:38:43.254549  3135 solver.cpp:314] Iteration 32700 (1.38049 iter/s, 72.4383s/100 iter), loss = 3.04691
I0213 05:38:43.254602  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.53944 (* 1 = 2.53944 loss)
I0213 05:38:43.254850  3135 sgd_solver.cpp:136] Iteration 32700, lr = 0.000207025, m = 0.9
I0213 05:39:53.584991  3135 solver.cpp:314] Iteration 32800 (1.42191 iter/s, 70.3282s/100 iter), loss = 2.88335
I0213 05:39:53.585108  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.18176 (* 1 = 4.18176 loss)
I0213 05:39:53.585125  3135 sgd_solver.cpp:136] Iteration 32800, lr = 0.000205511, m = 0.9
I0213 05:41:04.713995  3135 solver.cpp:314] Iteration 32900 (1.40594 iter/s, 71.1267s/100 iter), loss = 2.89549
I0213 05:41:04.714095  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.7176 (* 1 = 2.7176 loss)
I0213 05:41:04.714112  3135 sgd_solver.cpp:136] Iteration 32900, lr = 0.000204003, m = 0.9
I0213 05:42:14.794499  3135 solver.cpp:314] Iteration 33000 (1.42698 iter/s, 70.0782s/100 iter), loss = 2.90192
I0213 05:42:14.794627  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.63426 (* 1 = 2.63426 loss)
I0213 05:42:14.794646  3135 sgd_solver.cpp:136] Iteration 33000, lr = 0.0002025, m = 0.9
I0213 05:43:26.102325  3135 solver.cpp:314] Iteration 33100 (1.40242 iter/s, 71.3055s/100 iter), loss = 3.02933
I0213 05:43:26.114326  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.08134 (* 1 = 3.08134 loss)
I0213 05:43:26.114364  3135 sgd_solver.cpp:136] Iteration 33100, lr = 0.000201003, m = 0.9
I0213 05:44:37.686713  3135 solver.cpp:314] Iteration 33200 (1.397 iter/s, 71.5821s/100 iter), loss = 2.80014
I0213 05:44:37.686807  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.67374 (* 1 = 2.67374 loss)
I0213 05:44:37.686826  3135 sgd_solver.cpp:136] Iteration 33200, lr = 0.000199511, m = 0.9
I0213 05:45:48.525353  3135 solver.cpp:314] Iteration 33300 (1.4117 iter/s, 70.8363s/100 iter), loss = 2.93797
I0213 05:45:48.525455  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.42499 (* 1 = 2.42499 loss)
I0213 05:45:48.525472  3135 sgd_solver.cpp:136] Iteration 33300, lr = 0.000198025, m = 0.9
I0213 05:46:59.134057  3135 solver.cpp:314] Iteration 33400 (1.4163 iter/s, 70.6064s/100 iter), loss = 2.78795
I0213 05:46:59.134326  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.39526 (* 1 = 2.39526 loss)
I0213 05:46:59.134341  3135 sgd_solver.cpp:136] Iteration 33400, lr = 0.000196544, m = 0.9
I0213 05:48:08.964718  3135 solver.cpp:314] Iteration 33500 (1.43208 iter/s, 69.8284s/100 iter), loss = 2.84335
I0213 05:48:08.964829  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.55396 (* 1 = 2.55396 loss)
I0213 05:48:08.964848  3135 sgd_solver.cpp:136] Iteration 33500, lr = 0.000195069, m = 0.9
I0213 05:49:20.252337  3135 solver.cpp:314] Iteration 33600 (1.40281 iter/s, 71.2853s/100 iter), loss = 2.91112
I0213 05:49:20.252442  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.63374 (* 1 = 2.63374 loss)
I0213 05:49:20.252460  3135 sgd_solver.cpp:136] Iteration 33600, lr = 0.0001936, m = 0.9
I0213 05:50:31.324688  3135 solver.cpp:314] Iteration 33700 (1.40706 iter/s, 71.07s/100 iter), loss = 2.77222
I0213 05:50:31.324822  3135 solver.cpp:336]     Train net output #0: mbox_loss = 1.85562 (* 1 = 1.85562 loss)
I0213 05:50:31.324841  3135 sgd_solver.cpp:136] Iteration 33700, lr = 0.000192136, m = 0.9
I0213 05:51:42.510578  3135 solver.cpp:314] Iteration 33800 (1.40482 iter/s, 71.1836s/100 iter), loss = 2.72399
I0213 05:51:42.510697  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.7668 (* 1 = 3.7668 loss)
I0213 05:51:42.510716  3135 sgd_solver.cpp:136] Iteration 33800, lr = 0.000190678, m = 0.9
I0213 05:52:53.687598  3135 solver.cpp:314] Iteration 33900 (1.40499 iter/s, 71.1747s/100 iter), loss = 3.14027
I0213 05:52:53.687705  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.17443 (* 1 = 3.17443 loss)
I0213 05:52:53.687722  3135 sgd_solver.cpp:136] Iteration 33900, lr = 0.000189225, m = 0.9
I0213 05:54:03.407232  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_34000.caffemodel
I0213 05:54:03.437750  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_34000.solverstate
I0213 05:54:03.451022  3135 solver.cpp:666] Iteration 34000, Testing net (#0)
I0213 05:54:53.374794  3135 solver.cpp:774] class AP 1: 0.373781
I0213 05:54:53.429347  3135 solver.cpp:774] class AP 2: 0.623999
I0213 05:54:53.439162  3135 solver.cpp:774] class AP 3: 0.627536
I0213 05:54:53.439198  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.541772
I0213 05:54:53.572271  3136 solver.cpp:774] class AP 1: 0.378938
I0213 05:54:53.628836  3136 solver.cpp:774] class AP 2: 0.623991
I0213 05:54:53.639871  3136 solver.cpp:774] class AP 3: 0.633436
I0213 05:54:53.639909  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.545455
I0213 05:54:53.640349  3135 solver.cpp:265] [MultiGPU] Tests completed in 50.1877s
I0213 05:54:54.036849  3135 solver.cpp:314] Iteration 34000 (0.830942 iter/s, 120.345s/100 iter), loss = 2.99046
I0213 05:54:54.036893  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.42978 (* 1 = 3.42978 loss)
I0213 05:54:54.036907  3135 sgd_solver.cpp:136] Iteration 34000, lr = 0.000187778, m = 0.9
I0213 05:56:05.077077  3135 solver.cpp:314] Iteration 34100 (1.4077 iter/s, 71.0379s/100 iter), loss = 3.00599
I0213 05:56:05.077183  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.3086 (* 1 = 2.3086 loss)
I0213 05:56:05.077198  3135 sgd_solver.cpp:136] Iteration 34100, lr = 0.000186336, m = 0.9
I0213 05:57:14.525720  3135 solver.cpp:314] Iteration 34200 (1.43996 iter/s, 69.4464s/100 iter), loss = 2.83746
I0213 05:57:14.525831  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.36116 (* 1 = 2.36116 loss)
I0213 05:57:14.525849  3135 sgd_solver.cpp:136] Iteration 34200, lr = 0.0001849, m = 0.9
I0213 05:58:25.635188  3135 solver.cpp:314] Iteration 34300 (1.40633 iter/s, 71.1071s/100 iter), loss = 2.94702
I0213 05:58:25.635282  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.77233 (* 1 = 3.77233 loss)
I0213 05:58:25.635299  3135 sgd_solver.cpp:136] Iteration 34300, lr = 0.000183469, m = 0.9
I0213 05:59:35.984416  3135 solver.cpp:314] Iteration 34400 (1.42153 iter/s, 70.3469s/100 iter), loss = 2.83621
I0213 05:59:35.984532  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.09026 (* 1 = 3.09026 loss)
I0213 05:59:35.984551  3135 sgd_solver.cpp:136] Iteration 34400, lr = 0.000182044, m = 0.9
I0213 06:00:46.274960  3135 solver.cpp:314] Iteration 34500 (1.42271 iter/s, 70.2883s/100 iter), loss = 2.97986
I0213 06:00:46.275125  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.23078 (* 1 = 3.23078 loss)
I0213 06:00:46.275166  3135 sgd_solver.cpp:136] Iteration 34500, lr = 0.000180625, m = 0.9
I0213 06:01:57.692101  3135 solver.cpp:314] Iteration 34600 (1.40027 iter/s, 71.4148s/100 iter), loss = 2.78223
I0213 06:01:57.692257  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.37852 (* 1 = 2.37852 loss)
I0213 06:01:57.692278  3135 sgd_solver.cpp:136] Iteration 34600, lr = 0.000179211, m = 0.9
I0213 06:03:07.617846  3135 solver.cpp:314] Iteration 34700 (1.43014 iter/s, 69.9235s/100 iter), loss = 2.88892
I0213 06:03:07.618016  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.01066 (* 1 = 3.01066 loss)
I0213 06:03:07.618031  3135 sgd_solver.cpp:136] Iteration 34700, lr = 0.000177803, m = 0.9
I0213 06:04:18.770586  3135 solver.cpp:314] Iteration 34800 (1.40547 iter/s, 71.1504s/100 iter), loss = 2.71389
I0213 06:04:18.770697  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.74847 (* 1 = 2.74847 loss)
I0213 06:04:18.770714  3135 sgd_solver.cpp:136] Iteration 34800, lr = 0.0001764, m = 0.9
I0213 06:05:30.149106  3135 solver.cpp:314] Iteration 34900 (1.40111 iter/s, 71.3721s/100 iter), loss = 3.05054
I0213 06:05:30.149598  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.42847 (* 1 = 2.42847 loss)
I0213 06:05:30.149919  3135 sgd_solver.cpp:136] Iteration 34900, lr = 0.000175003, m = 0.9
I0213 06:06:40.290129  3135 solver.cpp:314] Iteration 35000 (1.42574 iter/s, 70.1388s/100 iter), loss = 3.048
I0213 06:06:40.290238  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.06145 (* 1 = 2.06145 loss)
I0213 06:06:40.290256  3135 sgd_solver.cpp:136] Iteration 35000, lr = 0.000173611, m = 0.9
I0213 06:07:50.948195  3135 solver.cpp:314] Iteration 35100 (1.41531 iter/s, 70.6558s/100 iter), loss = 2.92006
I0213 06:07:50.948355  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.10832 (* 1 = 2.10832 loss)
I0213 06:07:50.948391  3135 sgd_solver.cpp:136] Iteration 35100, lr = 0.000172225, m = 0.9
I0213 06:09:00.935611  3135 solver.cpp:314] Iteration 35200 (1.42887 iter/s, 69.9852s/100 iter), loss = 2.97751
I0213 06:09:00.935735  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.12832 (* 1 = 2.12832 loss)
I0213 06:09:00.935753  3135 sgd_solver.cpp:136] Iteration 35200, lr = 0.000170844, m = 0.9
I0213 06:10:11.594575  3135 solver.cpp:314] Iteration 35300 (1.41529 iter/s, 70.6567s/100 iter), loss = 3.06511
I0213 06:10:11.594722  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.64498 (* 1 = 2.64498 loss)
I0213 06:10:11.594739  3135 sgd_solver.cpp:136] Iteration 35300, lr = 0.000169469, m = 0.9
I0213 06:11:22.862365  3135 solver.cpp:314] Iteration 35400 (1.4032 iter/s, 71.2655s/100 iter), loss = 3.17301
I0213 06:11:22.862479  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.92191 (* 1 = 2.92191 loss)
I0213 06:11:22.862498  3135 sgd_solver.cpp:136] Iteration 35400, lr = 0.0001681, m = 0.9
I0213 06:12:32.870371  3135 solver.cpp:314] Iteration 35500 (1.42845 iter/s, 70.0058s/100 iter), loss = 3.15234
I0213 06:12:32.870477  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.78752 (* 1 = 3.78752 loss)
I0213 06:12:32.870494  3135 sgd_solver.cpp:136] Iteration 35500, lr = 0.000166736, m = 0.9
I0213 06:13:44.961558  3135 solver.cpp:314] Iteration 35600 (1.38718 iter/s, 72.0889s/100 iter), loss = 3.09833
I0213 06:13:44.961717  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.81353 (* 1 = 2.81353 loss)
I0213 06:13:44.961750  3135 sgd_solver.cpp:136] Iteration 35600, lr = 0.000165378, m = 0.9
I0213 06:14:56.794123  3135 solver.cpp:314] Iteration 35700 (1.39217 iter/s, 71.8303s/100 iter), loss = 3.16967
I0213 06:14:56.794225  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.32717 (* 1 = 2.32717 loss)
I0213 06:14:56.794241  3135 sgd_solver.cpp:136] Iteration 35700, lr = 0.000164025, m = 0.9
I0213 06:16:03.446846  3079 data_reader.cpp:305] Starting prefetch of epoch 9
I0213 06:16:08.587252  3135 solver.cpp:314] Iteration 35800 (1.39294 iter/s, 71.7908s/100 iter), loss = 3.23898
I0213 06:16:08.587303  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.34841 (* 1 = 3.34841 loss)
I0213 06:16:08.587318  3135 sgd_solver.cpp:136] Iteration 35800, lr = 0.000162678, m = 0.9
I0213 06:17:19.424435  3135 solver.cpp:314] Iteration 35900 (1.41173 iter/s, 70.8349s/100 iter), loss = 2.91094
I0213 06:17:19.424573  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.85146 (* 1 = 2.85146 loss)
I0213 06:17:19.424592  3135 sgd_solver.cpp:136] Iteration 35900, lr = 0.000161336, m = 0.9
I0213 06:18:30.002307  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_36000.caffemodel
I0213 06:18:30.033198  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_36000.solverstate
I0213 06:18:30.050050  3135 solver.cpp:666] Iteration 36000, Testing net (#0)
I0213 06:19:19.880631  3136 solver.cpp:774] class AP 1: 0.397373
I0213 06:19:19.925866  3135 solver.cpp:774] class AP 1: 0.397622
I0213 06:19:19.933513  3136 solver.cpp:774] class AP 2: 0.627784
I0213 06:19:19.943291  3136 solver.cpp:774] class AP 3: 0.624247
I0213 06:19:19.943336  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.549801
I0213 06:19:19.977885  3135 solver.cpp:774] class AP 2: 0.634862
I0213 06:19:19.987584  3135 solver.cpp:774] class AP 3: 0.619949
I0213 06:19:19.987617  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.550811
I0213 06:19:19.987836  3135 solver.cpp:265] [MultiGPU] Tests completed in 49.9362s
I0213 06:19:20.456202  3135 solver.cpp:314] Iteration 36000 (0.826256 iter/s, 121.028s/100 iter), loss = 2.82456
I0213 06:19:20.456252  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.85976 (* 1 = 2.85976 loss)
I0213 06:19:20.456264  3135 sgd_solver.cpp:136] Iteration 36000, lr = 0.00016, m = 0.9
I0213 06:20:32.477696  3135 solver.cpp:314] Iteration 36100 (1.38852 iter/s, 72.0192s/100 iter), loss = 2.94297
I0213 06:20:32.477828  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.30382 (* 1 = 3.30382 loss)
I0213 06:20:32.477865  3135 sgd_solver.cpp:136] Iteration 36100, lr = 0.000158669, m = 0.9
I0213 06:21:43.674013  3135 solver.cpp:314] Iteration 36200 (1.40461 iter/s, 71.194s/100 iter), loss = 2.88896
I0213 06:21:43.674115  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.11256 (* 1 = 3.11256 loss)
I0213 06:21:43.674131  3135 sgd_solver.cpp:136] Iteration 36200, lr = 0.000157344, m = 0.9
I0213 06:22:55.359701  3135 solver.cpp:314] Iteration 36300 (1.39502 iter/s, 71.6834s/100 iter), loss = 3.07702
I0213 06:22:55.359818  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.05704 (* 1 = 3.05704 loss)
I0213 06:22:55.359834  3135 sgd_solver.cpp:136] Iteration 36300, lr = 0.000156025, m = 0.9
I0213 06:24:05.339454  3135 solver.cpp:314] Iteration 36400 (1.42903 iter/s, 69.9775s/100 iter), loss = 2.83806
I0213 06:24:05.339574  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.38506 (* 1 = 2.38506 loss)
I0213 06:24:05.339592  3135 sgd_solver.cpp:136] Iteration 36400, lr = 0.000154711, m = 0.9
I0213 06:25:17.106914  3135 solver.cpp:314] Iteration 36500 (1.39343 iter/s, 71.7652s/100 iter), loss = 2.81637
I0213 06:25:17.107028  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.97483 (* 1 = 2.97483 loss)
I0213 06:25:17.107045  3135 sgd_solver.cpp:136] Iteration 36500, lr = 0.000153403, m = 0.9
I0213 06:26:27.926331  3135 solver.cpp:314] Iteration 36600 (1.41209 iter/s, 70.8172s/100 iter), loss = 2.87818
I0213 06:26:27.926432  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.51801 (* 1 = 2.51801 loss)
I0213 06:26:27.926450  3135 sgd_solver.cpp:136] Iteration 36600, lr = 0.0001521, m = 0.9
I0213 06:27:38.577162  3135 solver.cpp:314] Iteration 36700 (1.41546 iter/s, 70.6486s/100 iter), loss = 2.88343
I0213 06:27:38.577342  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.95216 (* 1 = 2.95216 loss)
I0213 06:27:38.577364  3135 sgd_solver.cpp:136] Iteration 36700, lr = 0.000150803, m = 0.9
I0213 06:28:49.508636  3135 solver.cpp:314] Iteration 36800 (1.40986 iter/s, 70.9292s/100 iter), loss = 2.83036
I0213 06:28:49.508776  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.22269 (* 1 = 3.22269 loss)
I0213 06:28:49.508795  3135 sgd_solver.cpp:136] Iteration 36800, lr = 0.000149511, m = 0.9
I0213 06:30:00.582648  3135 solver.cpp:314] Iteration 36900 (1.40703 iter/s, 71.0717s/100 iter), loss = 2.85762
I0213 06:30:00.582813  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.50448 (* 1 = 2.50448 loss)
I0213 06:30:00.582878  3135 sgd_solver.cpp:136] Iteration 36900, lr = 0.000148225, m = 0.9
I0213 06:31:11.501482  3135 solver.cpp:314] Iteration 37000 (1.41011 iter/s, 70.9166s/100 iter), loss = 2.84252
I0213 06:31:11.501617  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.08363 (* 1 = 2.08363 loss)
I0213 06:31:11.501633  3135 sgd_solver.cpp:136] Iteration 37000, lr = 0.000146944, m = 0.9
I0213 06:32:22.278626  3135 solver.cpp:314] Iteration 37100 (1.41293 iter/s, 70.7749s/100 iter), loss = 2.95751
I0213 06:32:22.278730  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.83386 (* 1 = 2.83386 loss)
I0213 06:32:22.278748  3135 sgd_solver.cpp:136] Iteration 37100, lr = 0.000145669, m = 0.9
I0213 06:33:34.302623  3135 solver.cpp:314] Iteration 37200 (1.38847 iter/s, 72.0217s/100 iter), loss = 2.95343
I0213 06:33:34.302732  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.09921 (* 1 = 2.09921 loss)
I0213 06:33:34.302989  3135 sgd_solver.cpp:136] Iteration 37200, lr = 0.0001444, m = 0.9
I0213 06:34:45.536073  3135 solver.cpp:314] Iteration 37300 (1.40388 iter/s, 71.2312s/100 iter), loss = 2.97298
I0213 06:34:45.536192  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.85903 (* 1 = 2.85903 loss)
I0213 06:34:45.536208  3135 sgd_solver.cpp:136] Iteration 37300, lr = 0.000143136, m = 0.9
I0213 06:35:56.918315  3135 solver.cpp:314] Iteration 37400 (1.40095 iter/s, 71.38s/100 iter), loss = 2.88791
I0213 06:35:56.918452  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.55583 (* 1 = 3.55583 loss)
I0213 06:35:56.918488  3135 sgd_solver.cpp:136] Iteration 37400, lr = 0.000141878, m = 0.9
I0213 06:37:07.514958  3135 solver.cpp:314] Iteration 37500 (1.41654 iter/s, 70.5944s/100 iter), loss = 2.99774
I0213 06:37:07.515067  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.58964 (* 1 = 2.58964 loss)
I0213 06:37:07.515085  3135 sgd_solver.cpp:136] Iteration 37500, lr = 0.000140625, m = 0.9
I0213 06:38:17.481503  3135 solver.cpp:314] Iteration 37600 (1.4293 iter/s, 69.9643s/100 iter), loss = 2.77044
I0213 06:38:17.481617  3135 solver.cpp:336]     Train net output #0: mbox_loss = 1.84981 (* 1 = 1.84981 loss)
I0213 06:38:17.481633  3135 sgd_solver.cpp:136] Iteration 37600, lr = 0.000139378, m = 0.9
I0213 06:39:29.027444  3135 solver.cpp:314] Iteration 37700 (1.39775 iter/s, 71.5437s/100 iter), loss = 2.83981
I0213 06:39:29.027554  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.62479 (* 1 = 2.62479 loss)
I0213 06:39:29.027570  3135 sgd_solver.cpp:136] Iteration 37700, lr = 0.000138136, m = 0.9
I0213 06:40:40.486713  3135 solver.cpp:314] Iteration 37800 (1.39944 iter/s, 71.457s/100 iter), loss = 2.98918
I0213 06:40:40.486834  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.04347 (* 1 = 3.04347 loss)
I0213 06:40:40.486850  3135 sgd_solver.cpp:136] Iteration 37800, lr = 0.0001369, m = 0.9
I0213 06:41:50.523144  3135 solver.cpp:314] Iteration 37900 (1.42787 iter/s, 70.0342s/100 iter), loss = 2.61654
I0213 06:41:50.523247  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.37581 (* 1 = 2.37581 loss)
I0213 06:41:50.523264  3135 sgd_solver.cpp:136] Iteration 37900, lr = 0.000135669, m = 0.9
I0213 06:43:00.616945  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_38000.caffemodel
I0213 06:43:00.649853  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_38000.solverstate
I0213 06:43:00.662480  3135 solver.cpp:666] Iteration 38000, Testing net (#0)
I0213 06:43:50.158004  3136 solver.cpp:774] class AP 1: 0.395812
I0213 06:43:50.216717  3136 solver.cpp:774] class AP 2: 0.63492
I0213 06:43:50.225271  3136 solver.cpp:774] class AP 3: 0.634066
I0213 06:43:50.225298  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.554933
I0213 06:43:50.386646  3135 solver.cpp:774] class AP 1: 0.399827
I0213 06:43:50.441175  3135 solver.cpp:774] class AP 2: 0.635921
I0213 06:43:50.449626  3135 solver.cpp:774] class AP 3: 0.634219
I0213 06:43:50.449666  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.556656
I0213 06:43:50.450100  3135 solver.cpp:265] [MultiGPU] Tests completed in 49.786s
I0213 06:43:50.870568  3135 solver.cpp:314] Iteration 38000 (0.830954 iter/s, 120.344s/100 iter), loss = 2.92676
I0213 06:43:50.870656  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.01368 (* 1 = 3.01368 loss)
I0213 06:43:50.870692  3135 sgd_solver.cpp:136] Iteration 38000, lr = 0.000134444, m = 0.9
I0213 06:45:02.149809  3135 solver.cpp:314] Iteration 38100 (1.40298 iter/s, 71.277s/100 iter), loss = 2.93392
I0213 06:45:02.149946  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.4791 (* 1 = 2.4791 loss)
I0213 06:45:02.149986  3135 sgd_solver.cpp:136] Iteration 38100, lr = 0.000133225, m = 0.9
I0213 06:46:12.969832  3135 solver.cpp:314] Iteration 38200 (1.41208 iter/s, 70.8177s/100 iter), loss = 2.8637
I0213 06:46:12.969947  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.62522 (* 1 = 2.62522 loss)
I0213 06:46:12.969964  3135 sgd_solver.cpp:136] Iteration 38200, lr = 0.000132011, m = 0.9
I0213 06:47:24.564275  3135 solver.cpp:314] Iteration 38300 (1.3968 iter/s, 71.5921s/100 iter), loss = 2.64359
I0213 06:47:24.564378  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.28651 (* 1 = 3.28651 loss)
I0213 06:47:24.564776  3135 sgd_solver.cpp:136] Iteration 38300, lr = 0.000130803, m = 0.9
I0213 06:48:35.658095  3135 solver.cpp:314] Iteration 38400 (1.40664 iter/s, 71.0915s/100 iter), loss = 2.98898
I0213 06:48:35.658200  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.57903 (* 1 = 3.57903 loss)
I0213 06:48:35.658216  3135 sgd_solver.cpp:136] Iteration 38400, lr = 0.0001296, m = 0.9
I0213 06:49:46.734931  3135 solver.cpp:314] Iteration 38500 (1.40697 iter/s, 71.0746s/100 iter), loss = 2.8348
I0213 06:49:46.735030  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.77387 (* 1 = 2.77387 loss)
I0213 06:49:46.735047  3135 sgd_solver.cpp:136] Iteration 38500, lr = 0.000128403, m = 0.9
I0213 06:50:41.101083  3079 data_reader.cpp:305] Starting prefetch of epoch 10
I0213 06:50:58.274606  3135 solver.cpp:314] Iteration 38600 (1.39787 iter/s, 71.5374s/100 iter), loss = 2.98364
I0213 06:50:58.274669  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.05771 (* 1 = 2.05771 loss)
I0213 06:50:58.274684  3135 sgd_solver.cpp:136] Iteration 38600, lr = 0.000127211, m = 0.9
I0213 06:52:09.523910  3135 solver.cpp:314] Iteration 38700 (1.40357 iter/s, 71.247s/100 iter), loss = 3.02732
I0213 06:52:09.524009  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.72244 (* 1 = 3.72244 loss)
I0213 06:52:09.524026  3135 sgd_solver.cpp:136] Iteration 38700, lr = 0.000126025, m = 0.9
I0213 06:53:20.534390  3135 solver.cpp:314] Iteration 38800 (1.40829 iter/s, 71.0082s/100 iter), loss = 2.87613
I0213 06:53:20.534488  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.01022 (* 1 = 2.01022 loss)
I0213 06:53:20.534504  3135 sgd_solver.cpp:136] Iteration 38800, lr = 0.000124844, m = 0.9
I0213 06:54:31.987751  3135 solver.cpp:314] Iteration 38900 (1.39956 iter/s, 71.4511s/100 iter), loss = 2.88379
I0213 06:54:31.987859  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.22584 (* 1 = 2.22584 loss)
I0213 06:54:31.987879  3135 sgd_solver.cpp:136] Iteration 38900, lr = 0.000123669, m = 0.9
I0213 06:55:42.138515  3135 solver.cpp:314] Iteration 39000 (1.42555 iter/s, 70.1485s/100 iter), loss = 3.09378
I0213 06:55:42.138649  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.69914 (* 1 = 2.69914 loss)
I0213 06:55:42.138664  3135 sgd_solver.cpp:136] Iteration 39000, lr = 0.0001225, m = 0.9
I0213 06:56:53.026517  3135 solver.cpp:314] Iteration 39100 (1.41072 iter/s, 70.8857s/100 iter), loss = 2.70296
I0213 06:56:53.026628  3135 solver.cpp:336]     Train net output #0: mbox_loss = 1.90869 (* 1 = 1.90869 loss)
I0213 06:56:53.026648  3135 sgd_solver.cpp:136] Iteration 39100, lr = 0.000121336, m = 0.9
I0213 06:58:04.316603  3135 solver.cpp:314] Iteration 39200 (1.40276 iter/s, 71.2878s/100 iter), loss = 2.85092
I0213 06:58:04.316736  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.59799 (* 1 = 2.59799 loss)
I0213 06:58:04.316759  3135 sgd_solver.cpp:136] Iteration 39200, lr = 0.000120178, m = 0.9
I0213 06:59:16.030517  3135 solver.cpp:314] Iteration 39300 (1.39447 iter/s, 71.7116s/100 iter), loss = 3.06587
I0213 06:59:16.030623  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.70484 (* 1 = 2.70484 loss)
I0213 06:59:16.030639  3135 sgd_solver.cpp:136] Iteration 39300, lr = 0.000119025, m = 0.9
I0213 07:00:26.418864  3135 solver.cpp:314] Iteration 39400 (1.42073 iter/s, 70.3861s/100 iter), loss = 3.1843
I0213 07:00:26.418993  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.44785 (* 1 = 4.44785 loss)
I0213 07:00:26.419026  3135 sgd_solver.cpp:136] Iteration 39400, lr = 0.000117878, m = 0.9
I0213 07:01:37.547302  3135 solver.cpp:314] Iteration 39500 (1.40595 iter/s, 71.1262s/100 iter), loss = 2.97696
I0213 07:01:37.547921  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.04451 (* 1 = 3.04451 loss)
I0213 07:01:37.548328  3135 sgd_solver.cpp:136] Iteration 39500, lr = 0.000116736, m = 0.9
I0213 07:02:49.102154  3135 solver.cpp:314] Iteration 39600 (1.39757 iter/s, 71.5526s/100 iter), loss = 3.03212
I0213 07:02:49.102246  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.28576 (* 1 = 3.28576 loss)
I0213 07:02:49.102259  3135 sgd_solver.cpp:136] Iteration 39600, lr = 0.0001156, m = 0.9
I0213 07:03:59.592824  3135 solver.cpp:314] Iteration 39700 (1.41867 iter/s, 70.4884s/100 iter), loss = 2.73031
I0213 07:03:59.593031  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.23427 (* 1 = 2.23427 loss)
I0213 07:03:59.593068  3135 sgd_solver.cpp:136] Iteration 39700, lr = 0.000114469, m = 0.9
I0213 07:05:11.508482  3135 solver.cpp:314] Iteration 39800 (1.39056 iter/s, 71.9134s/100 iter), loss = 2.94061
I0213 07:05:11.508611  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.56855 (* 1 = 2.56855 loss)
I0213 07:05:11.508631  3135 sgd_solver.cpp:136] Iteration 39800, lr = 0.000113344, m = 0.9
I0213 07:06:23.305667  3135 solver.cpp:314] Iteration 39900 (1.39286 iter/s, 71.7949s/100 iter), loss = 2.93694
I0213 07:06:23.305783  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.4952 (* 1 = 2.4952 loss)
I0213 07:06:23.305801  3135 sgd_solver.cpp:136] Iteration 39900, lr = 0.000112225, m = 0.9
I0213 07:07:32.782207  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_40000.caffemodel
I0213 07:07:32.822351  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_40000.solverstate
I0213 07:07:32.835858  3135 solver.cpp:666] Iteration 40000, Testing net (#0)
I0213 07:08:22.219646  3135 solver.cpp:774] class AP 1: 0.372287
I0213 07:08:22.275055  3135 solver.cpp:774] class AP 2: 0.624949
I0213 07:08:22.286155  3135 solver.cpp:774] class AP 3: 0.636147
I0213 07:08:22.286206  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.544461
I0213 07:08:22.781798  3136 solver.cpp:774] class AP 1: 0.369016
I0213 07:08:22.833495  3136 solver.cpp:774] class AP 2: 0.622249
I0213 07:08:22.842337  3136 solver.cpp:774] class AP 3: 0.628549
I0213 07:08:22.842375  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.539938
I0213 07:08:22.842780  3135 solver.cpp:265] [MultiGPU] Tests completed in 50.0054s
I0213 07:08:23.262704  3135 solver.cpp:314] Iteration 40000 (0.833658 iter/s, 119.953s/100 iter), loss = 2.86386
I0213 07:08:23.263023  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.11835 (* 1 = 3.11835 loss)
I0213 07:08:23.263058  3135 sgd_solver.cpp:136] Iteration 40000, lr = 0.000111111, m = 0.9
I0213 07:09:33.140874  3135 solver.cpp:314] Iteration 40100 (1.43111 iter/s, 69.8759s/100 iter), loss = 2.80404
I0213 07:09:33.141023  3135 solver.cpp:336]     Train net output #0: mbox_loss = 1.7678 (* 1 = 1.7678 loss)
I0213 07:09:33.141048  3135 sgd_solver.cpp:136] Iteration 40100, lr = 0.000110003, m = 0.9
I0213 07:10:44.021869  3135 solver.cpp:314] Iteration 40200 (1.41086 iter/s, 70.8787s/100 iter), loss = 3.02121
I0213 07:10:44.021975  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.08191 (* 1 = 3.08191 loss)
I0213 07:10:44.021991  3135 sgd_solver.cpp:136] Iteration 40200, lr = 0.0001089, m = 0.9
I0213 07:11:55.186830  3135 solver.cpp:314] Iteration 40300 (1.40523 iter/s, 71.1627s/100 iter), loss = 2.97259
I0213 07:11:55.186928  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.58404 (* 1 = 2.58404 loss)
I0213 07:11:55.186946  3135 sgd_solver.cpp:136] Iteration 40300, lr = 0.000107803, m = 0.9
I0213 07:13:06.366305  3135 solver.cpp:314] Iteration 40400 (1.40494 iter/s, 71.1772s/100 iter), loss = 3.13113
I0213 07:13:06.370332  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.32593 (* 1 = 3.32593 loss)
I0213 07:13:06.370359  3135 sgd_solver.cpp:136] Iteration 40400, lr = 0.000106711, m = 0.9
I0213 07:14:17.720449  3135 solver.cpp:314] Iteration 40500 (1.4015 iter/s, 71.3519s/100 iter), loss = 2.90036
I0213 07:14:17.720568  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.37178 (* 1 = 2.37178 loss)
I0213 07:14:17.720585  3135 sgd_solver.cpp:136] Iteration 40500, lr = 0.000105625, m = 0.9
I0213 07:15:30.276062  3135 solver.cpp:314] Iteration 40600 (1.3783 iter/s, 72.5533s/100 iter), loss = 2.99647
I0213 07:15:30.276193  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.68758 (* 1 = 2.68758 loss)
I0213 07:15:30.276211  3135 sgd_solver.cpp:136] Iteration 40600, lr = 0.000104544, m = 0.9
I0213 07:16:40.566965  3135 solver.cpp:314] Iteration 40700 (1.4227 iter/s, 70.2887s/100 iter), loss = 3.04145
I0213 07:16:40.567075  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.58432 (* 1 = 2.58432 loss)
I0213 07:16:40.567093  3135 sgd_solver.cpp:136] Iteration 40700, lr = 0.000103469, m = 0.9
I0213 07:17:50.910357  3135 solver.cpp:314] Iteration 40800 (1.42164 iter/s, 70.3411s/100 iter), loss = 2.85582
I0213 07:17:50.914418  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.187 (* 1 = 3.187 loss)
I0213 07:17:50.914479  3135 sgd_solver.cpp:136] Iteration 40800, lr = 0.0001024, m = 0.9
I0213 07:19:01.227865  3135 solver.cpp:314] Iteration 40900 (1.42217 iter/s, 70.3153s/100 iter), loss = 3.01517
I0213 07:19:01.228047  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.87335 (* 1 = 2.87335 loss)
I0213 07:19:01.228065  3135 sgd_solver.cpp:136] Iteration 40900, lr = 0.000101336, m = 0.9
I0213 07:20:12.008410  3135 solver.cpp:314] Iteration 41000 (1.41286 iter/s, 70.7783s/100 iter), loss = 3.05359
I0213 07:20:12.008575  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.07631 (* 1 = 3.07631 loss)
I0213 07:20:12.008613  3135 sgd_solver.cpp:136] Iteration 41000, lr = 0.000100278, m = 0.9
I0213 07:21:22.478335  3135 solver.cpp:314] Iteration 41100 (1.41909 iter/s, 70.4677s/100 iter), loss = 2.65465
I0213 07:21:22.478447  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.79912 (* 1 = 2.79912 loss)
I0213 07:21:22.478467  3135 sgd_solver.cpp:136] Iteration 41100, lr = 9.9225e-05, m = 0.9
I0213 07:22:33.091486  3135 solver.cpp:314] Iteration 41200 (1.41621 iter/s, 70.6109s/100 iter), loss = 3.05546
I0213 07:22:33.091629  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.52694 (* 1 = 3.52694 loss)
I0213 07:22:33.091645  3135 sgd_solver.cpp:136] Iteration 41200, lr = 9.81778e-05, m = 0.9
I0213 07:23:43.357831  3135 solver.cpp:314] Iteration 41300 (1.4232 iter/s, 70.2641s/100 iter), loss = 2.79974
I0213 07:23:43.357971  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.88748 (* 1 = 2.88748 loss)
I0213 07:23:43.358007  3135 sgd_solver.cpp:136] Iteration 41300, lr = 9.71361e-05, m = 0.9
I0213 07:24:54.760884  3135 solver.cpp:314] Iteration 41400 (1.40055 iter/s, 71.4008s/100 iter), loss = 3.01856
I0213 07:24:54.760983  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.38188 (* 1 = 3.38188 loss)
I0213 07:24:54.760999  3135 sgd_solver.cpp:136] Iteration 41400, lr = 9.61e-05, m = 0.9
I0213 07:26:05.912843  3135 solver.cpp:314] Iteration 41500 (1.40549 iter/s, 71.1497s/100 iter), loss = 2.82039
I0213 07:26:05.912958  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.03155 (* 1 = 2.03155 loss)
I0213 07:26:05.912973  3135 sgd_solver.cpp:136] Iteration 41500, lr = 9.50695e-05, m = 0.9
I0213 07:27:16.952841  3135 solver.cpp:314] Iteration 41600 (1.4077 iter/s, 71.0377s/100 iter), loss = 3.06854
I0213 07:27:16.952940  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.60491 (* 1 = 4.60491 loss)
I0213 07:27:16.952955  3135 sgd_solver.cpp:136] Iteration 41600, lr = 9.40445e-05, m = 0.9
I0213 07:28:28.018780  3135 solver.cpp:314] Iteration 41700 (1.40719 iter/s, 71.0637s/100 iter), loss = 2.57619
I0213 07:28:28.018889  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.1299 (* 1 = 2.1299 loss)
I0213 07:28:28.018906  3135 sgd_solver.cpp:136] Iteration 41700, lr = 9.3025e-05, m = 0.9
I0213 07:28:30.133538  3079 data_reader.cpp:305] Starting prefetch of epoch 11
I0213 07:29:39.724032  3135 solver.cpp:314] Iteration 41800 (1.39464 iter/s, 71.7029s/100 iter), loss = 2.70514
I0213 07:29:39.724560  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.78058 (* 1 = 2.78058 loss)
I0213 07:29:39.724884  3135 sgd_solver.cpp:136] Iteration 41800, lr = 9.20111e-05, m = 0.9
I0213 07:30:50.418239  3135 solver.cpp:314] Iteration 41900 (1.41459 iter/s, 70.6919s/100 iter), loss = 2.83851
I0213 07:30:50.418354  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.83974 (* 1 = 2.83974 loss)
I0213 07:30:50.418370  3135 sgd_solver.cpp:136] Iteration 41900, lr = 9.10028e-05, m = 0.9
I0213 07:32:00.566324  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_42000.caffemodel
I0213 07:32:00.594411  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_42000.solverstate
I0213 07:32:00.607226  3135 solver.cpp:666] Iteration 42000, Testing net (#0)
I0213 07:32:49.776078  3135 solver.cpp:774] class AP 1: 0.378154
I0213 07:32:49.830812  3135 solver.cpp:774] class AP 2: 0.633507
I0213 07:32:49.841411  3135 solver.cpp:774] class AP 3: 0.632591
I0213 07:32:49.841457  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.548084
I0213 07:32:49.853566  3136 solver.cpp:774] class AP 1: 0.374875
I0213 07:32:49.907447  3136 solver.cpp:774] class AP 2: 0.628386
I0213 07:32:49.916924  3136 solver.cpp:774] class AP 3: 0.629012
I0213 07:32:49.916942  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.544091
I0213 07:32:49.917119  3135 solver.cpp:265] [MultiGPU] Tests completed in 49.3083s
I0213 07:32:50.364051  3135 solver.cpp:314] Iteration 42000 (0.833736 iter/s, 119.942s/100 iter), loss = 2.74129
I0213 07:32:50.364150  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.89758 (* 1 = 2.89758 loss)
I0213 07:32:50.364182  3135 sgd_solver.cpp:136] Iteration 42000, lr = 9e-05, m = 0.9
I0213 07:34:02.102753  3135 solver.cpp:314] Iteration 42100 (1.39399 iter/s, 71.7364s/100 iter), loss = 2.8797
I0213 07:34:02.106052  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.19983 (* 1 = 3.19983 loss)
I0213 07:34:02.106081  3135 sgd_solver.cpp:136] Iteration 42100, lr = 8.90028e-05, m = 0.9
I0213 07:35:12.948612  3135 solver.cpp:314] Iteration 42200 (1.41156 iter/s, 70.8436s/100 iter), loss = 2.9918
I0213 07:35:12.948724  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.66448 (* 1 = 2.66448 loss)
I0213 07:35:12.948740  3135 sgd_solver.cpp:136] Iteration 42200, lr = 8.80111e-05, m = 0.9
I0213 07:36:24.214848  3135 solver.cpp:314] Iteration 42300 (1.40323 iter/s, 71.264s/100 iter), loss = 2.90152
I0213 07:36:24.214962  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.19376 (* 1 = 3.19376 loss)
I0213 07:36:24.214980  3135 sgd_solver.cpp:136] Iteration 42300, lr = 8.7025e-05, m = 0.9
I0213 07:37:34.418548  3135 solver.cpp:314] Iteration 42400 (1.42447 iter/s, 70.2015s/100 iter), loss = 2.77342
I0213 07:37:34.418704  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.18429 (* 1 = 3.18429 loss)
I0213 07:37:34.418742  3135 sgd_solver.cpp:136] Iteration 42400, lr = 8.60445e-05, m = 0.9
I0213 07:38:44.756186  3135 solver.cpp:314] Iteration 42500 (1.42176 iter/s, 70.3354s/100 iter), loss = 2.98993
I0213 07:38:44.756297  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.45536 (* 1 = 2.45536 loss)
I0213 07:38:44.756315  3135 sgd_solver.cpp:136] Iteration 42500, lr = 8.50695e-05, m = 0.9
I0213 07:39:55.086949  3135 solver.cpp:314] Iteration 42600 (1.4219 iter/s, 70.3285s/100 iter), loss = 2.87442
I0213 07:39:55.087057  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.21296 (* 1 = 3.21296 loss)
I0213 07:39:55.087170  3135 sgd_solver.cpp:136] Iteration 42600, lr = 8.41e-05, m = 0.9
I0213 07:41:06.877077  3135 solver.cpp:314] Iteration 42700 (1.39299 iter/s, 71.7878s/100 iter), loss = 2.8613
I0213 07:41:06.877208  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.82198 (* 1 = 2.82198 loss)
I0213 07:41:06.877228  3135 sgd_solver.cpp:136] Iteration 42700, lr = 8.31361e-05, m = 0.9
I0213 07:42:18.466847  3135 solver.cpp:314] Iteration 42800 (1.39689 iter/s, 71.5875s/100 iter), loss = 2.92856
I0213 07:42:18.466955  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.10751 (* 1 = 2.10751 loss)
I0213 07:42:18.466975  3135 sgd_solver.cpp:136] Iteration 42800, lr = 8.21778e-05, m = 0.9
I0213 07:43:28.915786  3135 solver.cpp:314] Iteration 42900 (1.41951 iter/s, 70.4467s/100 iter), loss = 3.01476
I0213 07:43:28.915900  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.27588 (* 1 = 3.27588 loss)
I0213 07:43:28.915916  3135 sgd_solver.cpp:136] Iteration 42900, lr = 8.1225e-05, m = 0.9
I0213 07:44:39.995587  3135 solver.cpp:314] Iteration 43000 (1.40691 iter/s, 71.0775s/100 iter), loss = 2.94337
I0213 07:44:39.995734  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.14971 (* 1 = 2.14971 loss)
I0213 07:44:39.995769  3135 sgd_solver.cpp:136] Iteration 43000, lr = 8.02778e-05, m = 0.9
I0213 07:45:51.190963  3135 solver.cpp:314] Iteration 43100 (1.40463 iter/s, 71.1931s/100 iter), loss = 3.02162
I0213 07:45:51.191118  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.63759 (* 1 = 3.63759 loss)
I0213 07:45:51.191156  3135 sgd_solver.cpp:136] Iteration 43100, lr = 7.93361e-05, m = 0.9
I0213 07:47:02.745936  3135 solver.cpp:314] Iteration 43200 (1.39757 iter/s, 71.5527s/100 iter), loss = 3.13504
I0213 07:47:02.746039  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.49158 (* 1 = 2.49158 loss)
I0213 07:47:02.746055  3135 sgd_solver.cpp:136] Iteration 43200, lr = 7.84e-05, m = 0.9
I0213 07:48:13.251161  3135 solver.cpp:314] Iteration 43300 (1.41838 iter/s, 70.503s/100 iter), loss = 2.91879
I0213 07:48:13.251257  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.53548 (* 1 = 2.53548 loss)
I0213 07:48:13.251276  3135 sgd_solver.cpp:136] Iteration 43300, lr = 7.74694e-05, m = 0.9
I0213 07:49:23.799357  3135 solver.cpp:314] Iteration 43400 (1.41752 iter/s, 70.5459s/100 iter), loss = 2.9322
I0213 07:49:23.799541  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.37656 (* 1 = 3.37656 loss)
I0213 07:49:23.799582  3135 sgd_solver.cpp:136] Iteration 43400, lr = 7.65444e-05, m = 0.9
I0213 07:50:34.975466  3135 solver.cpp:314] Iteration 43500 (1.40501 iter/s, 71.1738s/100 iter), loss = 3.10782
I0213 07:50:34.975622  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.50842 (* 1 = 2.50842 loss)
I0213 07:50:34.975638  3135 sgd_solver.cpp:136] Iteration 43500, lr = 7.5625e-05, m = 0.9
I0213 07:51:45.315140  3135 solver.cpp:314] Iteration 43600 (1.42172 iter/s, 70.3374s/100 iter), loss = 3.14203
I0213 07:51:45.315237  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.41258 (* 1 = 3.41258 loss)
I0213 07:51:45.315254  3135 sgd_solver.cpp:136] Iteration 43600, lr = 7.47111e-05, m = 0.9
I0213 07:52:56.519287  3135 solver.cpp:314] Iteration 43700 (1.40446 iter/s, 71.2019s/100 iter), loss = 2.85336
I0213 07:52:56.519398  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.67861 (* 1 = 2.67861 loss)
I0213 07:52:56.519418  3135 sgd_solver.cpp:136] Iteration 43700, lr = 7.38028e-05, m = 0.9
I0213 07:54:07.398308  3135 solver.cpp:314] Iteration 43800 (1.4109 iter/s, 70.8768s/100 iter), loss = 2.94904
I0213 07:54:07.398452  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.11778 (* 1 = 3.11778 loss)
I0213 07:54:07.398489  3135 sgd_solver.cpp:136] Iteration 43800, lr = 7.29e-05, m = 0.9
I0213 07:55:18.475482  3135 solver.cpp:314] Iteration 43900 (1.40697 iter/s, 71.0749s/100 iter), loss = 2.9573
I0213 07:55:18.475585  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.99816 (* 1 = 2.99816 loss)
I0213 07:55:18.475602  3135 sgd_solver.cpp:136] Iteration 43900, lr = 7.20028e-05, m = 0.9
I0213 07:56:28.661871  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_44000.caffemodel
I0213 07:56:28.724273  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_44000.solverstate
I0213 07:56:28.739667  3135 solver.cpp:666] Iteration 44000, Testing net (#0)
I0213 07:56:37.483178  3135 blocking_queue.cpp:40] Data layer prefetch queue empty
I0213 07:57:18.079937  3136 solver.cpp:774] class AP 1: 0.376758
I0213 07:57:18.136413  3136 solver.cpp:774] class AP 2: 0.637246
I0213 07:57:18.145731  3136 solver.cpp:774] class AP 3: 0.625866
I0213 07:57:18.145773  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.546623
I0213 07:57:18.151654  3135 solver.cpp:774] class AP 1: 0.379846
I0213 07:57:18.207172  3135 solver.cpp:774] class AP 2: 0.635052
I0213 07:57:18.216517  3135 solver.cpp:774] class AP 3: 0.627119
I0213 07:57:18.216536  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.547339
I0213 07:57:18.216976  3135 solver.cpp:265] [MultiGPU] Tests completed in 49.4758s
I0213 07:57:18.702440  3135 solver.cpp:314] Iteration 44000 (0.831787 iter/s, 120.223s/100 iter), loss = 2.78466
I0213 07:57:18.702484  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.69524 (* 1 = 2.69524 loss)
I0213 07:57:18.702497  3135 sgd_solver.cpp:136] Iteration 44000, lr = 7.11111e-05, m = 0.9
I0213 07:58:28.366380  3135 solver.cpp:314] Iteration 44100 (1.43551 iter/s, 69.6617s/100 iter), loss = 2.89144
I0213 07:58:28.366969  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.62334 (* 1 = 2.62334 loss)
I0213 07:58:28.367348  3135 sgd_solver.cpp:136] Iteration 44100, lr = 7.0225e-05, m = 0.9
I0213 07:59:38.853731  3135 solver.cpp:314] Iteration 44200 (1.41874 iter/s, 70.4851s/100 iter), loss = 2.90082
I0213 07:59:38.853827  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.87798 (* 1 = 2.87798 loss)
I0213 07:59:38.853843  3135 sgd_solver.cpp:136] Iteration 44200, lr = 6.93444e-05, m = 0.9
I0213 08:00:54.040894  3135 solver.cpp:314] Iteration 44300 (1.33006 iter/s, 75.1848s/100 iter), loss = 2.93869
I0213 08:00:54.041045  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.78922 (* 1 = 2.78922 loss)
I0213 08:00:54.041062  3135 sgd_solver.cpp:136] Iteration 44300, lr = 6.84694e-05, m = 0.9
I0213 08:02:10.773360  3135 solver.cpp:314] Iteration 44400 (1.30327 iter/s, 76.73s/100 iter), loss = 3.05601
I0213 08:02:10.773469  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.00553 (* 1 = 2.00553 loss)
I0213 08:02:10.773486  3135 sgd_solver.cpp:136] Iteration 44400, lr = 6.76e-05, m = 0.9
I0213 08:03:11.300293  3079 data_reader.cpp:305] Starting prefetch of epoch 12
I0213 08:03:23.032886  3135 solver.cpp:314] Iteration 44500 (1.38394 iter/s, 72.2572s/100 iter), loss = 2.90148
I0213 08:03:23.032938  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.7383 (* 1 = 2.7383 loss)
I0213 08:03:23.032951  3135 sgd_solver.cpp:136] Iteration 44500, lr = 6.67361e-05, m = 0.9
I0213 08:04:34.742689  3135 solver.cpp:314] Iteration 44600 (1.39455 iter/s, 71.7075s/100 iter), loss = 2.81675
I0213 08:04:34.742801  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.10237 (* 1 = 3.10237 loss)
I0213 08:04:34.742817  3135 sgd_solver.cpp:136] Iteration 44600, lr = 6.58778e-05, m = 0.9
I0213 08:05:45.995092  3135 solver.cpp:314] Iteration 44700 (1.40351 iter/s, 71.2501s/100 iter), loss = 2.84328
I0213 08:05:45.995234  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.20508 (* 1 = 3.20508 loss)
I0213 08:05:45.995270  3135 sgd_solver.cpp:136] Iteration 44700, lr = 6.5025e-05, m = 0.9
I0213 08:06:55.822345  3135 solver.cpp:314] Iteration 44800 (1.43215 iter/s, 69.825s/100 iter), loss = 2.99326
I0213 08:06:55.822463  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.88588 (* 1 = 2.88588 loss)
I0213 08:06:55.822485  3135 sgd_solver.cpp:136] Iteration 44800, lr = 6.41778e-05, m = 0.9
I0213 08:08:08.432551  3135 solver.cpp:314] Iteration 44900 (1.37726 iter/s, 72.6079s/100 iter), loss = 2.97081
I0213 08:08:08.432658  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.47029 (* 1 = 3.47029 loss)
I0213 08:08:08.432674  3135 sgd_solver.cpp:136] Iteration 44900, lr = 6.33361e-05, m = 0.9
I0213 08:09:19.726831  3135 solver.cpp:314] Iteration 45000 (1.40268 iter/s, 71.292s/100 iter), loss = 2.98529
I0213 08:09:19.726994  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.67026 (* 1 = 2.67026 loss)
I0213 08:09:19.727032  3135 sgd_solver.cpp:136] Iteration 45000, lr = 6.25e-05, m = 0.9
I0213 08:10:29.757694  3135 solver.cpp:314] Iteration 45100 (1.42799 iter/s, 70.0286s/100 iter), loss = 2.75315
I0213 08:10:29.757804  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.31876 (* 1 = 3.31876 loss)
I0213 08:10:29.758056  3135 sgd_solver.cpp:136] Iteration 45100, lr = 6.16694e-05, m = 0.9
I0213 08:11:41.418895  3135 solver.cpp:314] Iteration 45200 (1.3955 iter/s, 71.6589s/100 iter), loss = 2.80204
I0213 08:11:41.419004  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.29339 (* 1 = 3.29339 loss)
I0213 08:11:41.419020  3135 sgd_solver.cpp:136] Iteration 45200, lr = 6.08444e-05, m = 0.9
I0213 08:12:51.713642  3135 solver.cpp:314] Iteration 45300 (1.42263 iter/s, 70.2925s/100 iter), loss = 2.90018
I0213 08:12:51.713739  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.10135 (* 1 = 3.10135 loss)
I0213 08:12:51.713755  3135 sgd_solver.cpp:136] Iteration 45300, lr = 6.0025e-05, m = 0.9
I0213 08:14:03.012317  3135 solver.cpp:314] Iteration 45400 (1.4026 iter/s, 71.2964s/100 iter), loss = 3.2326
I0213 08:14:03.012421  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.96282 (* 1 = 2.96282 loss)
I0213 08:14:03.012439  3135 sgd_solver.cpp:136] Iteration 45400, lr = 5.92111e-05, m = 0.9
I0213 08:15:14.792335  3135 solver.cpp:314] Iteration 45500 (1.39319 iter/s, 71.7777s/100 iter), loss = 2.94084
I0213 08:15:14.792434  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.95976 (* 1 = 3.95976 loss)
I0213 08:15:14.792450  3135 sgd_solver.cpp:136] Iteration 45500, lr = 5.84028e-05, m = 0.9
I0213 08:16:24.725867  3135 solver.cpp:314] Iteration 45600 (1.42997 iter/s, 69.9313s/100 iter), loss = 2.92983
I0213 08:16:24.726012  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.803 (* 1 = 2.803 loss)
I0213 08:16:24.726028  3135 sgd_solver.cpp:136] Iteration 45600, lr = 5.76e-05, m = 0.9
I0213 08:17:35.395165  3135 solver.cpp:314] Iteration 45700 (1.41509 iter/s, 70.667s/100 iter), loss = 2.9337
I0213 08:17:35.395300  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.65047 (* 1 = 3.65047 loss)
I0213 08:17:35.395321  3135 sgd_solver.cpp:136] Iteration 45700, lr = 5.68028e-05, m = 0.9
I0213 08:18:45.276204  3135 solver.cpp:314] Iteration 45800 (1.43105 iter/s, 69.8788s/100 iter), loss = 2.66569
I0213 08:18:45.276687  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.48941 (* 1 = 2.48941 loss)
I0213 08:18:45.277010  3135 sgd_solver.cpp:136] Iteration 45800, lr = 5.60111e-05, m = 0.9
I0213 08:19:57.080677  3135 solver.cpp:314] Iteration 45900 (1.39272 iter/s, 71.8022s/100 iter), loss = 2.94876
I0213 08:19:57.080838  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.46844 (* 1 = 3.46844 loss)
I0213 08:19:57.080850  3135 sgd_solver.cpp:136] Iteration 45900, lr = 5.5225e-05, m = 0.9
I0213 08:21:07.229594  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_46000.caffemodel
I0213 08:21:07.276603  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_46000.solverstate
I0213 08:21:07.293721  3135 solver.cpp:666] Iteration 46000, Testing net (#0)
I0213 08:21:56.980373  3135 solver.cpp:774] class AP 1: 0.378271
I0213 08:21:57.037870  3135 solver.cpp:774] class AP 2: 0.628203
I0213 08:21:57.049345  3135 solver.cpp:774] class AP 3: 0.629505
I0213 08:21:57.049392  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.545326
I0213 08:21:57.841183  3136 solver.cpp:774] class AP 1: 0.394372
I0213 08:21:57.893146  3136 solver.cpp:774] class AP 2: 0.638395
I0213 08:21:57.901937  3136 solver.cpp:774] class AP 3: 0.629451
I0213 08:21:57.901983  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.554073
I0213 08:21:57.902400  3135 solver.cpp:265] [MultiGPU] Tests completed in 50.6071s
I0213 08:21:58.466289  3135 solver.cpp:314] Iteration 46000 (0.823847 iter/s, 121.382s/100 iter), loss = 3.03998
I0213 08:21:58.466344  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.20279 (* 1 = 3.20279 loss)
I0213 08:21:58.466357  3135 sgd_solver.cpp:136] Iteration 46000, lr = 5.44445e-05, m = 0.9
I0213 08:23:09.464319  3135 solver.cpp:314] Iteration 46100 (1.40853 iter/s, 70.9958s/100 iter), loss = 3.06491
I0213 08:23:09.464421  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.35925 (* 1 = 2.35925 loss)
I0213 08:23:09.464437  3135 sgd_solver.cpp:136] Iteration 46100, lr = 5.36695e-05, m = 0.9
I0213 08:24:21.899582  3135 solver.cpp:314] Iteration 46200 (1.38059 iter/s, 72.4329s/100 iter), loss = 2.8912
I0213 08:24:21.899689  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.62785 (* 1 = 2.62785 loss)
I0213 08:24:21.899704  3135 sgd_solver.cpp:136] Iteration 46200, lr = 5.29e-05, m = 0.9
I0213 08:25:33.626827  3135 solver.cpp:314] Iteration 46300 (1.39422 iter/s, 71.7249s/100 iter), loss = 3.01202
I0213 08:25:33.626927  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.48432 (* 1 = 2.48432 loss)
I0213 08:25:33.626943  3135 sgd_solver.cpp:136] Iteration 46300, lr = 5.21361e-05, m = 0.9
I0213 08:26:44.900878  3135 solver.cpp:314] Iteration 46400 (1.40308 iter/s, 71.2718s/100 iter), loss = 2.83952
I0213 08:26:44.901033  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.5654 (* 1 = 2.5654 loss)
I0213 08:26:44.901051  3135 sgd_solver.cpp:136] Iteration 46400, lr = 5.13778e-05, m = 0.9
I0213 08:27:54.866477  3135 solver.cpp:314] Iteration 46500 (1.42932 iter/s, 69.9633s/100 iter), loss = 2.90532
I0213 08:27:54.866627  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.12158 (* 1 = 4.12158 loss)
I0213 08:27:54.866647  3135 sgd_solver.cpp:136] Iteration 46500, lr = 5.0625e-05, m = 0.9
I0213 08:29:06.754339  3135 solver.cpp:314] Iteration 46600 (1.3911 iter/s, 71.8855s/100 iter), loss = 3.21907
I0213 08:29:06.754482  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.74554 (* 1 = 3.74554 loss)
I0213 08:29:06.754503  3135 sgd_solver.cpp:136] Iteration 46600, lr = 4.98778e-05, m = 0.9
I0213 08:30:17.542919  3135 solver.cpp:314] Iteration 46700 (1.4127 iter/s, 70.7863s/100 iter), loss = 2.77032
I0213 08:30:17.543023  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.5979 (* 1 = 2.5979 loss)
I0213 08:30:17.543040  3135 sgd_solver.cpp:136] Iteration 46700, lr = 4.91361e-05, m = 0.9
I0213 08:31:29.567087  3135 solver.cpp:314] Iteration 46800 (1.38847 iter/s, 72.0218s/100 iter), loss = 2.92719
I0213 08:31:29.567226  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.13532 (* 1 = 2.13532 loss)
I0213 08:31:29.567250  3135 sgd_solver.cpp:136] Iteration 46800, lr = 4.84e-05, m = 0.9
I0213 08:32:39.868507  3135 solver.cpp:314] Iteration 46900 (1.42249 iter/s, 70.2992s/100 iter), loss = 2.98502
I0213 08:32:39.868614  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.15226 (* 1 = 3.15226 loss)
I0213 08:32:39.868631  3135 sgd_solver.cpp:136] Iteration 46900, lr = 4.76694e-05, m = 0.9
I0213 08:33:50.653048  3135 solver.cpp:314] Iteration 47000 (1.41278 iter/s, 70.7823s/100 iter), loss = 2.86298
I0213 08:33:50.653152  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.42624 (* 1 = 3.42624 loss)
I0213 08:33:50.653169  3135 sgd_solver.cpp:136] Iteration 47000, lr = 4.69444e-05, m = 0.9
I0213 08:35:00.570694  3135 solver.cpp:314] Iteration 47100 (1.4303 iter/s, 69.9154s/100 iter), loss = 3.15425
I0213 08:35:00.570796  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.99772 (* 1 = 2.99772 loss)
I0213 08:35:00.570811  3135 sgd_solver.cpp:136] Iteration 47100, lr = 4.6225e-05, m = 0.9
I0213 08:36:11.420905  3135 solver.cpp:314] Iteration 47200 (1.41147 iter/s, 70.8479s/100 iter), loss = 2.85569
I0213 08:36:11.421011  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.97028 (* 1 = 2.97028 loss)
I0213 08:36:11.421028  3135 sgd_solver.cpp:136] Iteration 47200, lr = 4.55111e-05, m = 0.9
I0213 08:37:22.151767  3135 solver.cpp:314] Iteration 47300 (1.41386 iter/s, 70.7286s/100 iter), loss = 2.85491
I0213 08:37:22.151875  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.96767 (* 1 = 2.96767 loss)
I0213 08:37:22.151890  3135 sgd_solver.cpp:136] Iteration 47300, lr = 4.48028e-05, m = 0.9
I0213 08:38:33.579095  3135 solver.cpp:314] Iteration 47400 (1.40007 iter/s, 71.425s/100 iter), loss = 3.01739
I0213 08:38:33.579196  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.01433 (* 1 = 3.01433 loss)
I0213 08:38:33.579216  3135 sgd_solver.cpp:136] Iteration 47400, lr = 4.41e-05, m = 0.9
I0213 08:39:45.152591  3135 solver.cpp:314] Iteration 47500 (1.39721 iter/s, 71.5712s/100 iter), loss = 3.0907
I0213 08:39:45.152951  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.92039 (* 1 = 2.92039 loss)
I0213 08:39:45.152976  3135 sgd_solver.cpp:136] Iteration 47500, lr = 4.34028e-05, m = 0.9
I0213 08:40:55.660887  3135 solver.cpp:314] Iteration 47600 (1.41832 iter/s, 70.506s/100 iter), loss = 2.98116
I0213 08:40:55.661221  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.08465 (* 1 = 3.08465 loss)
I0213 08:40:55.661245  3135 sgd_solver.cpp:136] Iteration 47600, lr = 4.27111e-05, m = 0.9
I0213 08:41:05.053412  3079 data_reader.cpp:305] Starting prefetch of epoch 13
I0213 08:42:06.419729  3135 solver.cpp:314] Iteration 47700 (1.4133 iter/s, 70.7565s/100 iter), loss = 2.76751
I0213 08:42:06.419857  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.07174 (* 1 = 3.07174 loss)
I0213 08:42:06.419890  3135 sgd_solver.cpp:136] Iteration 47700, lr = 4.2025e-05, m = 0.9
I0213 08:43:17.170128  3135 solver.cpp:314] Iteration 47800 (1.41347 iter/s, 70.7481s/100 iter), loss = 2.75705
I0213 08:43:17.170317  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.59275 (* 1 = 2.59275 loss)
I0213 08:43:17.170358  3135 sgd_solver.cpp:136] Iteration 47800, lr = 4.13444e-05, m = 0.9
I0213 08:44:28.358327  3135 solver.cpp:314] Iteration 47900 (1.40477 iter/s, 71.1859s/100 iter), loss = 3.01242
I0213 08:44:28.358474  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.79576 (* 1 = 2.79576 loss)
I0213 08:44:28.358510  3135 sgd_solver.cpp:136] Iteration 47900, lr = 4.06694e-05, m = 0.9
I0213 08:45:38.890630  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_48000.caffemodel
I0213 08:45:38.926817  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_48000.solverstate
I0213 08:45:38.945391  3135 solver.cpp:666] Iteration 48000, Testing net (#0)
I0213 08:46:29.462420  3136 solver.cpp:774] class AP 1: 0.380446
I0213 08:46:29.523818  3135 solver.cpp:774] class AP 1: 0.376273
I0213 08:46:29.525686  3136 solver.cpp:774] class AP 2: 0.641221
I0213 08:46:29.534929  3136 solver.cpp:774] class AP 3: 0.633824
I0213 08:46:29.534962  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.55183
I0213 08:46:29.578514  3135 solver.cpp:774] class AP 2: 0.645332
I0213 08:46:29.587923  3135 solver.cpp:774] class AP 3: 0.62763
I0213 08:46:29.587960  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.549745
I0213 08:46:29.588372  3135 solver.cpp:265] [MultiGPU] Tests completed in 50.6414s
I0213 08:46:30.081993  3135 solver.cpp:314] Iteration 48000 (0.821559 iter/s, 121.72s/100 iter), loss = 2.83106
I0213 08:46:30.082051  3135 solver.cpp:336]     Train net output #0: mbox_loss = 5.29533 (* 1 = 5.29533 loss)
I0213 08:46:30.082067  3135 sgd_solver.cpp:136] Iteration 48000, lr = 4e-05, m = 0.9
I0213 08:47:40.759194  3135 solver.cpp:314] Iteration 48100 (1.41493 iter/s, 70.6749s/100 iter), loss = 3.07537
I0213 08:47:40.759346  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.65737 (* 1 = 3.65737 loss)
I0213 08:47:40.759382  3135 sgd_solver.cpp:136] Iteration 48100, lr = 3.93361e-05, m = 0.9
I0213 08:48:52.730715  3135 solver.cpp:314] Iteration 48200 (1.38948 iter/s, 71.9692s/100 iter), loss = 2.80666
I0213 08:48:52.730821  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.82798 (* 1 = 2.82798 loss)
I0213 08:48:52.730840  3135 sgd_solver.cpp:136] Iteration 48200, lr = 3.86778e-05, m = 0.9
I0213 08:50:04.508536  3135 solver.cpp:314] Iteration 48300 (1.39323 iter/s, 71.7755s/100 iter), loss = 2.85655
I0213 08:50:04.508679  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.4706 (* 1 = 2.4706 loss)
I0213 08:50:04.508714  3135 sgd_solver.cpp:136] Iteration 48300, lr = 3.8025e-05, m = 0.9
I0213 08:51:16.814077  3135 solver.cpp:314] Iteration 48400 (1.38306 iter/s, 72.3032s/100 iter), loss = 2.78604
I0213 08:51:16.814219  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.50939 (* 1 = 2.50939 loss)
I0213 08:51:16.814256  3135 sgd_solver.cpp:136] Iteration 48400, lr = 3.73778e-05, m = 0.9
I0213 08:52:30.228302  3135 solver.cpp:314] Iteration 48500 (1.36218 iter/s, 73.4118s/100 iter), loss = 3.04134
I0213 08:52:30.228447  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.88916 (* 1 = 3.88916 loss)
I0213 08:52:30.228464  3135 sgd_solver.cpp:136] Iteration 48500, lr = 3.67361e-05, m = 0.9
I0213 08:53:41.794330  3135 solver.cpp:314] Iteration 48600 (1.39736 iter/s, 71.5637s/100 iter), loss = 2.97481
I0213 08:53:41.794486  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.4191 (* 1 = 2.4191 loss)
I0213 08:53:41.794503  3135 sgd_solver.cpp:136] Iteration 48600, lr = 3.61e-05, m = 0.9
I0213 08:54:52.126127  3135 solver.cpp:314] Iteration 48700 (1.42188 iter/s, 70.3295s/100 iter), loss = 2.86321
I0213 08:54:52.126260  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.37705 (* 1 = 3.37705 loss)
I0213 08:54:52.126286  3135 sgd_solver.cpp:136] Iteration 48700, lr = 3.54694e-05, m = 0.9
I0213 08:56:03.338527  3135 solver.cpp:314] Iteration 48800 (1.4043 iter/s, 71.2101s/100 iter), loss = 2.93285
I0213 08:56:03.338634  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.01708 (* 1 = 3.01708 loss)
I0213 08:56:03.338651  3135 sgd_solver.cpp:136] Iteration 48800, lr = 3.48444e-05, m = 0.9
I0213 08:57:14.807288  3135 solver.cpp:314] Iteration 48900 (1.39926 iter/s, 71.4664s/100 iter), loss = 2.74271
I0213 08:57:14.807394  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.6312 (* 1 = 2.6312 loss)
I0213 08:57:14.807411  3135 sgd_solver.cpp:136] Iteration 48900, lr = 3.4225e-05, m = 0.9
I0213 08:58:26.261075  3135 solver.cpp:314] Iteration 49000 (1.39955 iter/s, 71.4515s/100 iter), loss = 2.77872
I0213 08:58:26.261193  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.05422 (* 1 = 2.05422 loss)
I0213 08:58:26.261215  3135 sgd_solver.cpp:136] Iteration 49000, lr = 3.36111e-05, m = 0.9
I0213 08:59:38.259727  3135 solver.cpp:314] Iteration 49100 (1.38896 iter/s, 71.9963s/100 iter), loss = 2.76519
I0213 08:59:38.259826  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.53384 (* 1 = 2.53384 loss)
I0213 08:59:38.259841  3135 sgd_solver.cpp:136] Iteration 49100, lr = 3.30028e-05, m = 0.9
I0213 09:00:49.815496  3135 solver.cpp:314] Iteration 49200 (1.39756 iter/s, 71.5535s/100 iter), loss = 2.8841
I0213 09:00:49.815596  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.78042 (* 1 = 3.78042 loss)
I0213 09:00:49.815613  3135 sgd_solver.cpp:136] Iteration 49200, lr = 3.24e-05, m = 0.9
I0213 09:02:01.802945  3135 solver.cpp:314] Iteration 49300 (1.38918 iter/s, 71.9851s/100 iter), loss = 2.78832
I0213 09:02:01.803041  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.11896 (* 1 = 3.11896 loss)
I0213 09:02:01.804128  3135 sgd_solver.cpp:136] Iteration 49300, lr = 3.18028e-05, m = 0.9
I0213 09:03:12.206499  3135 solver.cpp:314] Iteration 49400 (1.42043 iter/s, 70.4013s/100 iter), loss = 3.01614
I0213 09:03:12.206647  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.47648 (* 1 = 2.47648 loss)
I0213 09:03:12.206684  3135 sgd_solver.cpp:136] Iteration 49400, lr = 3.12111e-05, m = 0.9
I0213 09:04:24.186758  3135 solver.cpp:314] Iteration 49500 (1.38931 iter/s, 71.9779s/100 iter), loss = 2.98899
I0213 09:04:24.186915  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.36779 (* 1 = 3.36779 loss)
I0213 09:04:24.186956  3135 sgd_solver.cpp:136] Iteration 49500, lr = 3.0625e-05, m = 0.9
I0213 09:05:36.245688  3135 solver.cpp:314] Iteration 49600 (1.3878 iter/s, 72.0566s/100 iter), loss = 2.92262
I0213 09:05:36.245820  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.90105 (* 1 = 2.90105 loss)
I0213 09:05:36.245839  3135 sgd_solver.cpp:136] Iteration 49600, lr = 3.00444e-05, m = 0.9
I0213 09:06:48.127887  3135 solver.cpp:314] Iteration 49700 (1.39121 iter/s, 71.8799s/100 iter), loss = 3.15198
I0213 09:06:48.128054  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.62552 (* 1 = 3.62552 loss)
I0213 09:06:48.128072  3135 sgd_solver.cpp:136] Iteration 49700, lr = 2.94695e-05, m = 0.9
I0213 09:07:59.241291  3135 solver.cpp:314] Iteration 49800 (1.40625 iter/s, 71.1111s/100 iter), loss = 2.95139
I0213 09:07:59.241410  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.91646 (* 1 = 2.91646 loss)
I0213 09:07:59.241426  3135 sgd_solver.cpp:136] Iteration 49800, lr = 2.89e-05, m = 0.9
I0213 09:09:09.895311  3135 solver.cpp:314] Iteration 49900 (1.41539 iter/s, 70.6517s/100 iter), loss = 2.63516
I0213 09:09:09.895422  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.95608 (* 1 = 2.95608 loss)
I0213 09:09:09.895440  3135 sgd_solver.cpp:136] Iteration 49900, lr = 2.83361e-05, m = 0.9
I0213 09:10:19.311214  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_50000.caffemodel
I0213 09:10:19.342679  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_50000.solverstate
I0213 09:10:19.357779  3135 solver.cpp:666] Iteration 50000, Testing net (#0)
I0213 09:11:08.722232  3136 solver.cpp:774] class AP 1: 0.396682
I0213 09:11:08.778709  3136 solver.cpp:774] class AP 2: 0.640605
I0213 09:11:08.788571  3136 solver.cpp:774] class AP 3: 0.632177
I0213 09:11:08.788612  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.556488
I0213 09:11:08.976835  3135 solver.cpp:774] class AP 1: 0.391421
I0213 09:11:09.029163  3135 solver.cpp:774] class AP 2: 0.634535
I0213 09:11:09.038111  3135 solver.cpp:774] class AP 3: 0.628315
I0213 09:11:09.038148  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.551424
I0213 09:11:09.038197  3135 solver.cpp:265] [MultiGPU] Tests completed in 49.6788s
I0213 09:11:09.604140  3135 solver.cpp:314] Iteration 50000 (0.835387 iter/s, 119.705s/100 iter), loss = 2.9085
I0213 09:11:09.604189  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.86974 (* 1 = 2.86974 loss)
I0213 09:11:09.604202  3135 sgd_solver.cpp:136] Iteration 50000, lr = 2.77778e-05, m = 0.9
I0213 09:12:21.308863  3135 solver.cpp:314] Iteration 50100 (1.39465 iter/s, 71.7024s/100 iter), loss = 3.18173
I0213 09:12:21.308975  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.97795 (* 1 = 3.97795 loss)
I0213 09:12:21.308989  3135 sgd_solver.cpp:136] Iteration 50100, lr = 2.7225e-05, m = 0.9
I0213 09:13:32.694476  3135 solver.cpp:314] Iteration 50200 (1.40089 iter/s, 71.3833s/100 iter), loss = 3.04362
I0213 09:13:32.694640  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.72565 (* 1 = 2.72565 loss)
I0213 09:13:32.694679  3135 sgd_solver.cpp:136] Iteration 50200, lr = 2.66778e-05, m = 0.9
I0213 09:14:42.500320  3135 solver.cpp:314] Iteration 50300 (1.43259 iter/s, 69.8036s/100 iter), loss = 2.99984
I0213 09:14:42.500479  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.53744 (* 1 = 2.53744 loss)
I0213 09:14:42.500497  3135 sgd_solver.cpp:136] Iteration 50300, lr = 2.61361e-05, m = 0.9
I0213 09:15:48.447866  3079 data_reader.cpp:305] Starting prefetch of epoch 14
I0213 09:15:53.386760  3135 solver.cpp:314] Iteration 50400 (1.41075 iter/s, 70.8841s/100 iter), loss = 2.87649
I0213 09:15:53.386809  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.61741 (* 1 = 2.61741 loss)
I0213 09:15:53.386826  3135 sgd_solver.cpp:136] Iteration 50400, lr = 2.56e-05, m = 0.9
I0213 09:17:05.063050  3135 solver.cpp:314] Iteration 50500 (1.39521 iter/s, 71.674s/100 iter), loss = 2.92177
I0213 09:17:05.063154  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.02914 (* 1 = 3.02914 loss)
I0213 09:17:05.063170  3135 sgd_solver.cpp:136] Iteration 50500, lr = 2.50695e-05, m = 0.9
I0213 09:18:16.884960  3135 solver.cpp:314] Iteration 50600 (1.39238 iter/s, 71.8196s/100 iter), loss = 2.86351
I0213 09:18:16.885062  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.32409 (* 1 = 2.32409 loss)
I0213 09:18:16.885080  3135 sgd_solver.cpp:136] Iteration 50600, lr = 2.45445e-05, m = 0.9
I0213 09:19:27.502043  3135 solver.cpp:314] Iteration 50700 (1.41613 iter/s, 70.6148s/100 iter), loss = 3.0019
I0213 09:19:27.502154  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.9463 (* 1 = 2.9463 loss)
I0213 09:19:27.502415  3135 sgd_solver.cpp:136] Iteration 50700, lr = 2.4025e-05, m = 0.9
I0213 09:20:39.102363  3135 solver.cpp:314] Iteration 50800 (1.39669 iter/s, 71.598s/100 iter), loss = 2.90093
I0213 09:20:39.110337  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.07206 (* 1 = 3.07206 loss)
I0213 09:20:39.110369  3135 sgd_solver.cpp:136] Iteration 50800, lr = 2.35111e-05, m = 0.9
I0213 09:21:48.853830  3135 solver.cpp:314] Iteration 50900 (1.43371 iter/s, 69.7492s/100 iter), loss = 2.86371
I0213 09:21:48.854002  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.4476 (* 1 = 4.4476 loss)
I0213 09:21:48.854019  3135 sgd_solver.cpp:136] Iteration 50900, lr = 2.30028e-05, m = 0.9
I0213 09:22:59.510622  3135 solver.cpp:314] Iteration 51000 (1.41534 iter/s, 70.6545s/100 iter), loss = 2.83874
I0213 09:22:59.513401  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.53683 (* 1 = 4.53683 loss)
I0213 09:22:59.513427  3135 sgd_solver.cpp:136] Iteration 51000, lr = 2.25e-05, m = 0.9
I0213 09:24:09.709614  3135 solver.cpp:314] Iteration 51100 (1.42457 iter/s, 70.1967s/100 iter), loss = 2.8414
I0213 09:24:09.709717  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.63354 (* 1 = 3.63354 loss)
I0213 09:24:09.709733  3135 sgd_solver.cpp:136] Iteration 51100, lr = 2.20028e-05, m = 0.9
I0213 09:25:20.561511  3135 solver.cpp:314] Iteration 51200 (1.41145 iter/s, 70.8489s/100 iter), loss = 2.79996
I0213 09:25:20.561625  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.52754 (* 1 = 3.52754 loss)
I0213 09:25:20.561643  3135 sgd_solver.cpp:136] Iteration 51200, lr = 2.15111e-05, m = 0.9
I0213 09:26:32.245462  3135 solver.cpp:314] Iteration 51300 (1.39504 iter/s, 71.6823s/100 iter), loss = 2.69812
I0213 09:26:32.245627  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.56851 (* 1 = 2.56851 loss)
I0213 09:26:32.245667  3135 sgd_solver.cpp:136] Iteration 51300, lr = 2.1025e-05, m = 0.9
I0213 09:27:43.618566  3135 solver.cpp:314] Iteration 51400 (1.40113 iter/s, 71.3708s/100 iter), loss = 2.79165
I0213 09:27:43.618769  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.9564 (* 1 = 2.9564 loss)
I0213 09:27:43.618811  3135 sgd_solver.cpp:136] Iteration 51400, lr = 2.05444e-05, m = 0.9
I0213 09:28:55.546707  3135 solver.cpp:314] Iteration 51500 (1.39032 iter/s, 71.9258s/100 iter), loss = 3.31424
I0213 09:28:55.546813  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.02106 (* 1 = 4.02106 loss)
I0213 09:28:55.546828  3135 sgd_solver.cpp:136] Iteration 51500, lr = 2.00694e-05, m = 0.9
I0213 09:30:06.038530  3135 solver.cpp:314] Iteration 51600 (1.41865 iter/s, 70.4895s/100 iter), loss = 2.8694
I0213 09:30:06.038628  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.18252 (* 1 = 4.18252 loss)
I0213 09:30:06.038643  3135 sgd_solver.cpp:136] Iteration 51600, lr = 1.96e-05, m = 0.9
I0213 09:31:17.567828  3135 solver.cpp:314] Iteration 51700 (1.39807 iter/s, 71.527s/100 iter), loss = 2.9775
I0213 09:31:17.568393  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.56995 (* 1 = 3.56995 loss)
I0213 09:31:17.568765  3135 sgd_solver.cpp:136] Iteration 51700, lr = 1.91361e-05, m = 0.9
I0213 09:32:28.730655  3135 solver.cpp:314] Iteration 51800 (1.40527 iter/s, 71.1605s/100 iter), loss = 2.98217
I0213 09:32:28.730758  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.18751 (* 1 = 3.18751 loss)
I0213 09:32:28.731001  3135 sgd_solver.cpp:136] Iteration 51800, lr = 1.86778e-05, m = 0.9
I0213 09:33:39.719933  3135 solver.cpp:314] Iteration 51900 (1.40871 iter/s, 70.987s/100 iter), loss = 2.99176
I0213 09:33:39.720049  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.11233 (* 1 = 3.11233 loss)
I0213 09:33:39.720065  3135 sgd_solver.cpp:136] Iteration 51900, lr = 1.8225e-05, m = 0.9
I0213 09:34:50.684147  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_52000.caffemodel
I0213 09:34:50.749158  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_52000.solverstate
I0213 09:34:50.770186  3135 solver.cpp:666] Iteration 52000, Testing net (#0)
I0213 09:35:40.446185  3136 solver.cpp:774] class AP 1: 0.37992
I0213 09:35:40.503468  3136 solver.cpp:774] class AP 2: 0.636561
I0213 09:35:40.512408  3136 solver.cpp:774] class AP 3: 0.632055
I0213 09:35:40.512439  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.549512
I0213 09:35:41.001997  3135 solver.cpp:774] class AP 1: 0.375941
I0213 09:35:41.055510  3135 solver.cpp:774] class AP 2: 0.640646
I0213 09:35:41.064258  3135 solver.cpp:774] class AP 3: 0.630161
I0213 09:35:41.064293  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.548916
I0213 09:35:41.064695  3135 solver.cpp:265] [MultiGPU] Tests completed in 50.2929s
I0213 09:35:41.546314  3135 solver.cpp:314] Iteration 52000 (0.820867 iter/s, 121.822s/100 iter), loss = 3.06061
I0213 09:35:41.546453  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.03625 (* 1 = 3.03625 loss)
I0213 09:35:41.546470  3135 sgd_solver.cpp:136] Iteration 52000, lr = 1.77778e-05, m = 0.9
I0213 09:36:52.381247  3135 solver.cpp:314] Iteration 52100 (1.41178 iter/s, 70.8326s/100 iter), loss = 3.02963
I0213 09:36:52.381363  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.44387 (* 1 = 3.44387 loss)
I0213 09:36:52.381381  3135 sgd_solver.cpp:136] Iteration 52100, lr = 1.73361e-05, m = 0.9
I0213 09:38:02.784186  3135 solver.cpp:314] Iteration 52200 (1.42044 iter/s, 70.4007s/100 iter), loss = 2.85342
I0213 09:38:02.784286  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.27277 (* 1 = 3.27277 loss)
I0213 09:38:02.784301  3135 sgd_solver.cpp:136] Iteration 52200, lr = 1.69e-05, m = 0.9
I0213 09:39:13.759138  3135 solver.cpp:314] Iteration 52300 (1.40899 iter/s, 70.9726s/100 iter), loss = 2.6494
I0213 09:39:13.759285  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.8693 (* 1 = 2.8693 loss)
I0213 09:39:13.759322  3135 sgd_solver.cpp:136] Iteration 52300, lr = 1.64694e-05, m = 0.9
I0213 09:40:24.519165  3135 solver.cpp:314] Iteration 52400 (1.41327 iter/s, 70.7577s/100 iter), loss = 2.88188
I0213 09:40:24.519255  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.72067 (* 1 = 3.72067 loss)
I0213 09:40:24.519271  3135 sgd_solver.cpp:136] Iteration 52400, lr = 1.60444e-05, m = 0.9
I0213 09:41:35.287184  3135 solver.cpp:314] Iteration 52500 (1.41311 iter/s, 70.7657s/100 iter), loss = 3.02838
I0213 09:41:35.287276  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.72778 (* 1 = 2.72778 loss)
I0213 09:41:35.287288  3135 sgd_solver.cpp:136] Iteration 52500, lr = 1.5625e-05, m = 0.9
I0213 09:42:45.555331  3135 solver.cpp:314] Iteration 52600 (1.42317 iter/s, 70.2659s/100 iter), loss = 2.83791
I0213 09:42:45.555487  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.63593 (* 1 = 2.63593 loss)
I0213 09:42:45.555505  3135 sgd_solver.cpp:136] Iteration 52600, lr = 1.52111e-05, m = 0.9
I0213 09:43:56.309628  3135 solver.cpp:314] Iteration 52700 (1.41339 iter/s, 70.752s/100 iter), loss = 2.82675
I0213 09:43:56.311391  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.02846 (* 1 = 2.02846 loss)
I0213 09:43:56.311699  3135 sgd_solver.cpp:136] Iteration 52700, lr = 1.48028e-05, m = 0.9
I0213 09:45:07.772632  3135 solver.cpp:314] Iteration 52800 (1.39937 iter/s, 71.4607s/100 iter), loss = 2.74968
I0213 09:45:07.772739  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.25432 (* 1 = 3.25432 loss)
I0213 09:45:07.773469  3135 sgd_solver.cpp:136] Iteration 52800, lr = 1.44e-05, m = 0.9
I0213 09:46:18.196449  3135 solver.cpp:314] Iteration 52900 (1.42002 iter/s, 70.4215s/100 iter), loss = 2.77752
I0213 09:46:18.196543  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.84387 (* 1 = 2.84387 loss)
I0213 09:46:18.196560  3135 sgd_solver.cpp:136] Iteration 52900, lr = 1.40028e-05, m = 0.9
I0213 09:47:30.421535  3135 solver.cpp:314] Iteration 53000 (1.38461 iter/s, 72.2227s/100 iter), loss = 2.91952
I0213 09:47:30.421624  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.45921 (* 1 = 3.45921 loss)
I0213 09:47:30.421639  3135 sgd_solver.cpp:136] Iteration 53000, lr = 1.36111e-05, m = 0.9
I0213 09:48:42.351066  3135 solver.cpp:314] Iteration 53100 (1.3903 iter/s, 71.9271s/100 iter), loss = 2.95639
I0213 09:48:42.351213  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.70655 (* 1 = 2.70655 loss)
I0213 09:48:42.351858  3135 sgd_solver.cpp:136] Iteration 53100, lr = 1.3225e-05, m = 0.9
I0213 09:49:53.399519  3135 solver.cpp:314] Iteration 53200 (1.40754 iter/s, 71.0462s/100 iter), loss = 2.83187
I0213 09:49:53.399617  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.04606 (* 1 = 2.04606 loss)
I0213 09:49:53.399632  3135 sgd_solver.cpp:136] Iteration 53200, lr = 1.28444e-05, m = 0.9
I0213 09:51:04.511037  3135 solver.cpp:314] Iteration 53300 (1.40629 iter/s, 71.1092s/100 iter), loss = 2.98207
I0213 09:51:04.511129  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.00849 (* 1 = 3.00849 loss)
I0213 09:51:04.511145  3135 sgd_solver.cpp:136] Iteration 53300, lr = 1.24694e-05, m = 0.9
I0213 09:52:15.010781  3135 solver.cpp:314] Iteration 53400 (1.41849 iter/s, 70.4975s/100 iter), loss = 2.83518
I0213 09:52:15.014307  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.74591 (* 1 = 2.74591 loss)
I0213 09:52:15.014324  3135 sgd_solver.cpp:136] Iteration 53400, lr = 1.21e-05, m = 0.9
I0213 09:53:25.370242  3135 solver.cpp:314] Iteration 53500 (1.42133 iter/s, 70.3565s/100 iter), loss = 2.89178
I0213 09:53:25.370357  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.60879 (* 1 = 2.60879 loss)
I0213 09:53:25.370375  3135 sgd_solver.cpp:136] Iteration 53500, lr = 1.17361e-05, m = 0.9
I0213 09:53:41.673979  3079 data_reader.cpp:305] Starting prefetch of epoch 15
I0213 09:54:35.354904  3135 solver.cpp:314] Iteration 53600 (1.42892 iter/s, 69.9831s/100 iter), loss = 2.67436
I0213 09:54:35.355005  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.34932 (* 1 = 3.34932 loss)
I0213 09:54:35.355021  3135 sgd_solver.cpp:136] Iteration 53600, lr = 1.13778e-05, m = 0.9
I0213 09:55:52.254866  3135 solver.cpp:314] Iteration 53700 (1.30043 iter/s, 76.8975s/100 iter), loss = 2.63308
I0213 09:55:52.254967  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.009 (* 1 = 3.009 loss)
I0213 09:55:52.254987  3135 sgd_solver.cpp:136] Iteration 53700, lr = 1.1025e-05, m = 0.9
I0213 09:57:09.954589  3135 solver.cpp:314] Iteration 53800 (1.28705 iter/s, 77.6972s/100 iter), loss = 2.77283
I0213 09:57:09.954694  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.91934 (* 1 = 2.91934 loss)
I0213 09:57:09.954710  3135 sgd_solver.cpp:136] Iteration 53800, lr = 1.06778e-05, m = 0.9
I0213 09:58:26.044289  3135 solver.cpp:314] Iteration 53900 (1.31428 iter/s, 76.0872s/100 iter), loss = 3.1132
I0213 09:58:26.044389  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.27236 (* 1 = 3.27236 loss)
I0213 09:58:26.044407  3135 sgd_solver.cpp:136] Iteration 53900, lr = 1.03361e-05, m = 0.9
I0213 09:59:41.501636  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_54000.caffemodel
I0213 09:59:41.986703  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_54000.solverstate
I0213 09:59:42.003424  3135 solver.cpp:666] Iteration 54000, Testing net (#0)
I0213 10:00:33.154584  3136 solver.cpp:774] class AP 1: 0.377928
I0213 10:00:33.164230  3135 solver.cpp:774] class AP 1: 0.380537
I0213 10:00:33.227876  3136 solver.cpp:774] class AP 2: 0.627408
I0213 10:00:33.236245  3135 solver.cpp:774] class AP 2: 0.636622
I0213 10:00:33.239594  3136 solver.cpp:774] class AP 3: 0.630159
I0213 10:00:33.239624  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.545165
I0213 10:00:33.246212  3135 solver.cpp:774] class AP 3: 0.630565
I0213 10:00:33.246232  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.549241
I0213 10:00:33.246431  3135 solver.cpp:265] [MultiGPU] Tests completed in 51.2414s
I0213 10:00:33.789314  3135 solver.cpp:314] Iteration 54000 (0.782835 iter/s, 127.741s/100 iter), loss = 2.99679
I0213 10:00:33.789368  3135 solver.cpp:336]     Train net output #0: mbox_loss = 1.9208 (* 1 = 1.9208 loss)
I0213 10:00:33.789386  3135 sgd_solver.cpp:136] Iteration 54000, lr = 1e-05, m = 0.9
I0213 10:01:52.322322  3135 solver.cpp:314] Iteration 54100 (1.27339 iter/s, 78.5305s/100 iter), loss = 3.06635
I0213 10:01:52.330567  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.88079 (* 1 = 2.88079 loss)
I0213 10:01:52.330755  3135 sgd_solver.cpp:136] Iteration 54100, lr = 9.66945e-06, m = 0.9
I0213 10:03:08.858537  3135 solver.cpp:314] Iteration 54200 (1.30661 iter/s, 76.5337s/100 iter), loss = 2.80565
I0213 10:03:08.858671  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.6996 (* 1 = 2.6996 loss)
I0213 10:03:08.858687  3135 sgd_solver.cpp:136] Iteration 54200, lr = 9.34445e-06, m = 0.9
I0213 10:04:24.156105  3135 solver.cpp:314] Iteration 54300 (1.32811 iter/s, 75.2951s/100 iter), loss = 2.881
I0213 10:04:24.156206  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.92479 (* 1 = 2.92479 loss)
I0213 10:04:24.156224  3135 sgd_solver.cpp:136] Iteration 54300, lr = 9.02501e-06, m = 0.9
I0213 10:05:40.494632  3135 solver.cpp:314] Iteration 54400 (1.31 iter/s, 76.336s/100 iter), loss = 3.12072
I0213 10:05:40.494731  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.83865 (* 1 = 2.83865 loss)
I0213 10:05:40.494747  3135 sgd_solver.cpp:136] Iteration 54400, lr = 8.71111e-06, m = 0.9
I0213 10:06:56.905748  3135 solver.cpp:314] Iteration 54500 (1.30875 iter/s, 76.4086s/100 iter), loss = 2.66082
I0213 10:06:56.905901  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.11908 (* 1 = 3.11908 loss)
I0213 10:06:56.906651  3135 sgd_solver.cpp:136] Iteration 54500, lr = 8.40277e-06, m = 0.9
I0213 10:08:11.798352  3135 solver.cpp:314] Iteration 54600 (1.33529 iter/s, 74.8902s/100 iter), loss = 3.09387
I0213 10:08:11.798460  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.47537 (* 1 = 3.47537 loss)
I0213 10:08:11.798480  3135 sgd_solver.cpp:136] Iteration 54600, lr = 8.1e-06, m = 0.9
I0213 10:09:28.150516  3135 solver.cpp:314] Iteration 54700 (1.30976 iter/s, 76.3497s/100 iter), loss = 2.74752
I0213 10:09:28.154327  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.0809 (* 1 = 3.0809 loss)
I0213 10:09:28.154359  3135 sgd_solver.cpp:136] Iteration 54700, lr = 7.80277e-06, m = 0.9
I0213 10:10:43.424757  3135 solver.cpp:314] Iteration 54800 (1.32852 iter/s, 75.2718s/100 iter), loss = 2.97091
I0213 10:10:43.425576  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.69074 (* 1 = 3.69074 loss)
I0213 10:10:43.425603  3135 sgd_solver.cpp:136] Iteration 54800, lr = 7.51111e-06, m = 0.9
I0213 10:11:58.752452  3135 solver.cpp:314] Iteration 54900 (1.32758 iter/s, 75.3252s/100 iter), loss = 3.03485
I0213 10:11:58.752557  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.4677 (* 1 = 2.4677 loss)
I0213 10:11:58.752574  3135 sgd_solver.cpp:136] Iteration 54900, lr = 7.225e-06, m = 0.9
I0213 10:13:14.096155  3135 solver.cpp:314] Iteration 55000 (1.32729 iter/s, 75.3413s/100 iter), loss = 2.80418
I0213 10:13:14.096289  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.81887 (* 1 = 2.81887 loss)
I0213 10:13:14.096309  3135 sgd_solver.cpp:136] Iteration 55000, lr = 6.94444e-06, m = 0.9
I0213 10:14:29.243952  3135 solver.cpp:314] Iteration 55100 (1.33075 iter/s, 75.1454s/100 iter), loss = 2.85625
I0213 10:14:29.254357  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.39324 (* 1 = 3.39324 loss)
I0213 10:14:29.254389  3135 sgd_solver.cpp:136] Iteration 55100, lr = 6.66944e-06, m = 0.9
I0213 10:15:45.259349  3135 solver.cpp:314] Iteration 55200 (1.31557 iter/s, 76.0129s/100 iter), loss = 2.8021
I0213 10:15:45.259454  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.13837 (* 1 = 4.13837 loss)
I0213 10:15:45.259471  3135 sgd_solver.cpp:136] Iteration 55200, lr = 6.4e-06, m = 0.9
I0213 10:17:01.262030  3135 solver.cpp:314] Iteration 55300 (1.31579 iter/s, 76.0002s/100 iter), loss = 2.83964
I0213 10:17:01.262166  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.60979 (* 1 = 2.60979 loss)
I0213 10:17:01.262183  3135 sgd_solver.cpp:136] Iteration 55300, lr = 6.13611e-06, m = 0.9
I0213 10:18:16.271873  3135 solver.cpp:314] Iteration 55400 (1.3332 iter/s, 75.0074s/100 iter), loss = 2.68051
I0213 10:18:16.272035  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.78089 (* 1 = 2.78089 loss)
I0213 10:18:16.272052  3135 sgd_solver.cpp:136] Iteration 55400, lr = 5.87778e-06, m = 0.9
I0213 10:19:31.250578  3135 solver.cpp:314] Iteration 55500 (1.33376 iter/s, 74.9763s/100 iter), loss = 3.12752
I0213 10:19:31.251416  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.85145 (* 1 = 2.85145 loss)
I0213 10:19:31.251459  3135 sgd_solver.cpp:136] Iteration 55500, lr = 5.625e-06, m = 0.9
I0213 10:20:47.687047  3135 solver.cpp:314] Iteration 55600 (1.30832 iter/s, 76.434s/100 iter), loss = 2.99
I0213 10:20:47.687206  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.54973 (* 1 = 2.54973 loss)
I0213 10:20:47.687222  3135 sgd_solver.cpp:136] Iteration 55600, lr = 5.37778e-06, m = 0.9
I0213 10:22:04.316673  3135 solver.cpp:314] Iteration 55700 (1.30502 iter/s, 76.6272s/100 iter), loss = 2.81715
I0213 10:22:04.316768  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.8857 (* 1 = 2.8857 loss)
I0213 10:22:04.316785  3135 sgd_solver.cpp:136] Iteration 55700, lr = 5.13611e-06, m = 0.9
I0213 10:23:20.073576  3135 solver.cpp:314] Iteration 55800 (1.32005 iter/s, 75.7545s/100 iter), loss = 2.90937
I0213 10:23:20.073679  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.6448 (* 1 = 2.6448 loss)
I0213 10:23:20.073695  3135 sgd_solver.cpp:136] Iteration 55800, lr = 4.9e-06, m = 0.9
I0213 10:24:34.465656  3135 solver.cpp:314] Iteration 55900 (1.34427 iter/s, 74.3897s/100 iter), loss = 3.04357
I0213 10:24:34.465760  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.52408 (* 1 = 3.52408 loss)
I0213 10:24:34.465778  3135 sgd_solver.cpp:136] Iteration 55900, lr = 4.66944e-06, m = 0.9
I0213 10:25:49.745618  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_56000.caffemodel
I0213 10:25:49.797744  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_56000.solverstate
I0213 10:25:49.811476  3135 solver.cpp:666] Iteration 56000, Testing net (#0)
I0213 10:26:40.958592  3136 solver.cpp:774] class AP 1: 0.378466
I0213 10:26:41.030966  3136 solver.cpp:774] class AP 2: 0.638036
I0213 10:26:41.042232  3136 solver.cpp:774] class AP 3: 0.626868
I0213 10:26:41.042281  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.54779
I0213 10:26:42.490145  3135 solver.cpp:774] class AP 1: 0.397106
I0213 10:26:42.580723  3135 solver.cpp:774] class AP 2: 0.634792
I0213 10:26:42.589686  3135 solver.cpp:774] class AP 3: 0.633317
I0213 10:26:42.589709  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.555071
I0213 10:26:42.590128  3135 solver.cpp:265] [MultiGPU] Tests completed in 52.777s
I0213 10:26:43.015303  3135 solver.cpp:314] Iteration 56000 (0.777935 iter/s, 128.545s/100 iter), loss = 2.94343
I0213 10:26:43.015353  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.84882 (* 1 = 2.84882 loss)
I0213 10:26:43.015370  3135 sgd_solver.cpp:136] Iteration 56000, lr = 4.44444e-06, m = 0.9
I0213 10:27:59.097453  3135 solver.cpp:314] Iteration 56100 (1.31441 iter/s, 76.0797s/100 iter), loss = 2.98543
I0213 10:27:59.097554  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.40641 (* 1 = 4.40641 loss)
I0213 10:27:59.098289  3135 sgd_solver.cpp:136] Iteration 56100, lr = 4.225e-06, m = 0.9
I0213 10:29:17.777247  3135 solver.cpp:314] Iteration 56200 (1.27102 iter/s, 78.6772s/100 iter), loss = 2.97413
I0213 10:29:17.777420  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.89615 (* 1 = 2.89615 loss)
I0213 10:29:17.777438  3135 sgd_solver.cpp:136] Iteration 56200, lr = 4.01111e-06, m = 0.9
I0213 10:30:36.065060  3135 solver.cpp:314] Iteration 56300 (1.27738 iter/s, 78.2853s/100 iter), loss = 2.81496
I0213 10:30:36.065937  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.67142 (* 1 = 2.67142 loss)
I0213 10:30:36.066006  3135 sgd_solver.cpp:136] Iteration 56300, lr = 3.80278e-06, m = 0.9
I0213 10:30:38.832695  3079 data_reader.cpp:305] Starting prefetch of epoch 16
I0213 10:31:53.866725  3135 solver.cpp:314] Iteration 56400 (1.28536 iter/s, 77.7991s/100 iter), loss = 2.59889
I0213 10:31:53.866875  3135 solver.cpp:336]     Train net output #0: mbox_loss = 1.92568 (* 1 = 1.92568 loss)
I0213 10:31:53.866910  3135 sgd_solver.cpp:136] Iteration 56400, lr = 3.6e-06, m = 0.9
I0213 10:33:07.971698  3135 solver.cpp:314] Iteration 56500 (1.34948 iter/s, 74.1026s/100 iter), loss = 2.90569
I0213 10:33:07.971798  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.96646 (* 1 = 2.96646 loss)
I0213 10:33:07.971815  3135 sgd_solver.cpp:136] Iteration 56500, lr = 3.40278e-06, m = 0.9
I0213 10:34:23.150557  3135 solver.cpp:314] Iteration 56600 (1.3302 iter/s, 75.1764s/100 iter), loss = 2.95075
I0213 10:34:23.154350  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.40341 (* 1 = 2.40341 loss)
I0213 10:34:23.154378  3135 sgd_solver.cpp:136] Iteration 56600, lr = 3.21111e-06, m = 0.9
I0213 10:35:39.748939  3135 solver.cpp:314] Iteration 56700 (1.30555 iter/s, 76.5959s/100 iter), loss = 2.77768
I0213 10:35:39.749040  3135 solver.cpp:336]     Train net output #0: mbox_loss = 1.89105 (* 1 = 1.89105 loss)
I0213 10:35:39.749056  3135 sgd_solver.cpp:136] Iteration 56700, lr = 3.025e-06, m = 0.9
I0213 10:36:55.060926  3135 solver.cpp:314] Iteration 56800 (1.32785 iter/s, 75.3096s/100 iter), loss = 2.79846
I0213 10:36:55.061018  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.35003 (* 1 = 2.35003 loss)
I0213 10:36:55.061036  3135 sgd_solver.cpp:136] Iteration 56800, lr = 2.84445e-06, m = 0.9
I0213 10:38:10.224834  3135 solver.cpp:314] Iteration 56900 (1.33047 iter/s, 75.1615s/100 iter), loss = 3.09533
I0213 10:38:10.224937  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.8679 (* 1 = 2.8679 loss)
I0213 10:38:10.224956  3135 sgd_solver.cpp:136] Iteration 56900, lr = 2.66945e-06, m = 0.9
I0213 10:39:26.942317  3135 solver.cpp:314] Iteration 57000 (1.30353 iter/s, 76.715s/100 iter), loss = 3.05058
I0213 10:39:26.942423  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.7841 (* 1 = 3.7841 loss)
I0213 10:39:26.942442  3135 sgd_solver.cpp:136] Iteration 57000, lr = 2.5e-06, m = 0.9
I0213 10:40:42.698356  3135 solver.cpp:314] Iteration 57100 (1.32007 iter/s, 75.7535s/100 iter), loss = 3.05674
I0213 10:40:42.698454  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.52753 (* 1 = 2.52753 loss)
I0213 10:40:42.698472  3135 sgd_solver.cpp:136] Iteration 57100, lr = 2.33611e-06, m = 0.9
I0213 10:41:59.026485  3135 solver.cpp:314] Iteration 57200 (1.31018 iter/s, 76.3257s/100 iter), loss = 2.75411
I0213 10:41:59.026589  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.55599 (* 1 = 2.55599 loss)
I0213 10:41:59.026607  3135 sgd_solver.cpp:136] Iteration 57200, lr = 2.17778e-06, m = 0.9
I0213 10:43:13.594329  3135 solver.cpp:314] Iteration 57300 (1.3411 iter/s, 74.5654s/100 iter), loss = 2.9446
I0213 10:43:13.594482  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.82434 (* 1 = 2.82434 loss)
I0213 10:43:13.594522  3135 sgd_solver.cpp:136] Iteration 57300, lr = 2.025e-06, m = 0.9
I0213 10:44:28.766249  3135 solver.cpp:314] Iteration 57400 (1.33033 iter/s, 75.1695s/100 iter), loss = 2.80246
I0213 10:44:28.766371  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.8387 (* 1 = 3.8387 loss)
I0213 10:44:28.766389  3135 sgd_solver.cpp:136] Iteration 57400, lr = 1.87778e-06, m = 0.9
I0213 10:45:44.048758  3135 solver.cpp:314] Iteration 57500 (1.32837 iter/s, 75.2801s/100 iter), loss = 2.94524
I0213 10:45:44.048962  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.86814 (* 1 = 2.86814 loss)
I0213 10:45:44.049000  3135 sgd_solver.cpp:136] Iteration 57500, lr = 1.73611e-06, m = 0.9
I0213 10:46:59.225371  3135 solver.cpp:314] Iteration 57600 (1.33024 iter/s, 75.1742s/100 iter), loss = 2.91993
I0213 10:46:59.225649  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.55371 (* 1 = 2.55371 loss)
I0213 10:46:59.225729  3135 sgd_solver.cpp:136] Iteration 57600, lr = 1.6e-06, m = 0.9
I0213 10:48:15.112722  3135 solver.cpp:314] Iteration 57700 (1.31779 iter/s, 75.8849s/100 iter), loss = 2.74325
I0213 10:48:15.112881  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.79845 (* 1 = 2.79845 loss)
I0213 10:48:15.112898  3135 sgd_solver.cpp:136] Iteration 57700, lr = 1.46945e-06, m = 0.9
I0213 10:49:31.022300  3135 solver.cpp:314] Iteration 57800 (1.31748 iter/s, 75.9025s/100 iter), loss = 3.11626
I0213 10:49:31.022403  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.41871 (* 1 = 4.41871 loss)
I0213 10:49:31.022423  3135 sgd_solver.cpp:136] Iteration 57800, lr = 1.34445e-06, m = 0.9
I0213 10:50:45.418684  3135 solver.cpp:314] Iteration 57900 (1.34411 iter/s, 74.3986s/100 iter), loss = 2.92255
I0213 10:50:45.418803  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.02765 (* 1 = 3.02765 loss)
I0213 10:50:45.418822  3135 sgd_solver.cpp:136] Iteration 57900, lr = 1.225e-06, m = 0.9
I0213 10:51:59.125095  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_58000.caffemodel
I0213 10:51:59.170811  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_58000.solverstate
I0213 10:51:59.184589  3135 solver.cpp:666] Iteration 58000, Testing net (#0)
I0213 10:52:51.056257  3136 solver.cpp:774] class AP 1: 0.378863
I0213 10:52:51.122455  3136 solver.cpp:774] class AP 2: 0.631352
I0213 10:52:51.131238  3136 solver.cpp:774] class AP 3: 0.628021
I0213 10:52:51.131265  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.546079
I0213 10:52:52.352550  3135 solver.cpp:774] class AP 1: 0.380641
I0213 10:52:52.405649  3135 solver.cpp:774] class AP 2: 0.637012
I0213 10:52:52.414646  3135 solver.cpp:774] class AP 3: 0.632634
I0213 10:52:52.414698  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.550096
I0213 10:52:52.415119  3135 solver.cpp:265] [MultiGPU] Tests completed in 53.2288s
I0213 10:52:52.873803  3135 solver.cpp:314] Iteration 58000 (0.784615 iter/s, 127.451s/100 iter), loss = 2.89837
I0213 10:52:52.873889  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.15831 (* 1 = 3.15831 loss)
I0213 10:52:52.873924  3135 sgd_solver.cpp:136] Iteration 58000, lr = 1.11111e-06, m = 0.9
I0213 10:54:06.926314  3135 solver.cpp:314] Iteration 58100 (1.35044 iter/s, 74.0501s/100 iter), loss = 3.06937
I0213 10:54:06.926465  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.86326 (* 1 = 2.86326 loss)
I0213 10:54:06.926482  3135 sgd_solver.cpp:136] Iteration 58100, lr = 1.00278e-06, m = 0.9
I0213 10:55:23.042558  3135 solver.cpp:314] Iteration 58200 (1.31382 iter/s, 76.1138s/100 iter), loss = 3.09697
I0213 10:55:23.042732  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.418 (* 1 = 3.418 loss)
I0213 10:55:23.042770  3135 sgd_solver.cpp:136] Iteration 58200, lr = 8.99998e-07, m = 0.9
I0213 10:56:39.545104  3135 solver.cpp:314] Iteration 58300 (1.30719 iter/s, 76.5001s/100 iter), loss = 2.90929
I0213 10:56:39.545203  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.11444 (* 1 = 4.11444 loss)
I0213 10:56:39.545223  3135 sgd_solver.cpp:136] Iteration 58300, lr = 8.02776e-07, m = 0.9
I0213 10:57:56.570518  3135 solver.cpp:314] Iteration 58400 (1.29832 iter/s, 77.0229s/100 iter), loss = 3.00405
I0213 10:57:56.570642  3135 solver.cpp:336]     Train net output #0: mbox_loss = 4.04111 (* 1 = 4.04111 loss)
I0213 10:57:56.570658  3135 sgd_solver.cpp:136] Iteration 58400, lr = 7.1111e-07, m = 0.9
I0213 10:59:14.870466  3135 solver.cpp:314] Iteration 58500 (1.27718 iter/s, 78.2974s/100 iter), loss = 3.01323
I0213 10:59:14.870563  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.98762 (* 1 = 2.98762 loss)
I0213 10:59:14.870579  3135 sgd_solver.cpp:136] Iteration 58500, lr = 6.24999e-07, m = 0.9
I0213 11:00:33.768000  3135 solver.cpp:314] Iteration 58600 (1.26751 iter/s, 78.895s/100 iter), loss = 2.7948
I0213 11:00:33.768129  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.44577 (* 1 = 2.44577 loss)
I0213 11:00:33.768158  3135 sgd_solver.cpp:136] Iteration 58600, lr = 5.44443e-07, m = 0.9
I0213 11:01:50.067014  3135 solver.cpp:314] Iteration 58700 (1.31068 iter/s, 76.2965s/100 iter), loss = 2.75426
I0213 11:01:50.067190  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.5306 (* 1 = 2.5306 loss)
I0213 11:01:50.067229  3135 sgd_solver.cpp:136] Iteration 58700, lr = 4.69444e-07, m = 0.9
I0213 11:03:04.913375  3135 solver.cpp:314] Iteration 58800 (1.33611 iter/s, 74.844s/100 iter), loss = 2.94472
I0213 11:03:04.913470  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.67334 (* 1 = 2.67334 loss)
I0213 11:03:04.913488  3135 sgd_solver.cpp:136] Iteration 58800, lr = 3.99999e-07, m = 0.9
I0213 11:04:20.374176  3135 solver.cpp:314] Iteration 58900 (1.32523 iter/s, 75.4584s/100 iter), loss = 2.84301
I0213 11:04:20.374655  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.77097 (* 1 = 2.77097 loss)
I0213 11:04:20.374969  3135 sgd_solver.cpp:136] Iteration 58900, lr = 3.3611e-07, m = 0.9
I0213 11:05:37.089877  3135 solver.cpp:314] Iteration 59000 (1.30356 iter/s, 76.7132s/100 iter), loss = 2.85042
I0213 11:05:37.090801  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.99746 (* 1 = 2.99746 loss)
I0213 11:05:37.090823  3135 sgd_solver.cpp:136] Iteration 59000, lr = 2.77777e-07, m = 0.9
I0213 11:06:52.541754  3135 solver.cpp:314] Iteration 59100 (1.32539 iter/s, 75.4494s/100 iter), loss = 3.03451
I0213 11:06:52.541852  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.85062 (* 1 = 3.85062 loss)
I0213 11:06:52.541868  3135 sgd_solver.cpp:136] Iteration 59100, lr = 2.25e-07, m = 0.9
I0213 11:08:11.012991  3135 solver.cpp:314] Iteration 59200 (1.27439 iter/s, 78.4687s/100 iter), loss = 3.01027
I0213 11:08:11.013101  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.67955 (* 1 = 2.67955 loss)
I0213 11:08:11.013119  3135 sgd_solver.cpp:136] Iteration 59200, lr = 1.77777e-07, m = 0.9
I0213 11:09:30.636476  3135 solver.cpp:314] Iteration 59300 (1.25595 iter/s, 79.6209s/100 iter), loss = 2.76162
I0213 11:09:30.636651  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.11498 (* 1 = 2.11498 loss)
I0213 11:09:30.636692  3135 sgd_solver.cpp:136] Iteration 59300, lr = 1.36111e-07, m = 0.9
I0213 11:10:48.852422  3135 solver.cpp:314] Iteration 59400 (1.27855 iter/s, 78.2134s/100 iter), loss = 3.06477
I0213 11:10:48.858745  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.82955 (* 1 = 2.82955 loss)
I0213 11:10:48.858781  3135 sgd_solver.cpp:136] Iteration 59400, lr = 9.99998e-08, m = 0.9
I0213 11:11:12.770401  3079 data_reader.cpp:305] Starting prefetch of epoch 17
I0213 11:12:13.051779  3135 solver.cpp:314] Iteration 59500 (1.1877 iter/s, 84.1966s/100 iter), loss = 2.86907
I0213 11:12:13.051936  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.36005 (* 1 = 3.36005 loss)
I0213 11:12:13.051978  3135 sgd_solver.cpp:136] Iteration 59500, lr = 6.94443e-08, m = 0.9
I0213 11:13:41.190548  3135 solver.cpp:314] Iteration 59600 (1.13461 iter/s, 88.1359s/100 iter), loss = 3.07323
I0213 11:13:41.190691  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.62328 (* 1 = 3.62328 loss)
I0213 11:13:41.190708  3135 sgd_solver.cpp:136] Iteration 59600, lr = 4.44444e-08, m = 0.9
I0213 11:15:11.435860  3135 solver.cpp:314] Iteration 59700 (1.10813 iter/s, 90.2424s/100 iter), loss = 2.90965
I0213 11:15:11.435981  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.84552 (* 1 = 2.84552 loss)
I0213 11:15:11.435998  3135 sgd_solver.cpp:136] Iteration 59700, lr = 2.5e-08, m = 0.9
I0213 11:16:37.851167  3135 solver.cpp:314] Iteration 59800 (1.15724 iter/s, 86.4125s/100 iter), loss = 2.89905
I0213 11:16:37.851282  3135 solver.cpp:336]     Train net output #0: mbox_loss = 2.06557 (* 1 = 2.06557 loss)
I0213 11:16:37.851300  3135 sgd_solver.cpp:136] Iteration 59800, lr = 1.11111e-08, m = 0.9
I0213 11:17:51.743839  3135 solver.cpp:314] Iteration 59900 (1.35336 iter/s, 73.8903s/100 iter), loss = 2.97799
I0213 11:17:51.743952  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.4122 (* 1 = 3.4122 loss)
I0213 11:17:51.743969  3135 sgd_solver.cpp:136] Iteration 59900, lr = 2.77777e-09, m = 0.9
I0213 11:19:05.597482  3135 solver.cpp:314] Iteration 59999 (1.34053 iter/s, 73.8513s/99 iter), loss = 2.84965
I0213 11:19:05.597579  3135 solver.cpp:336]     Train net output #0: mbox_loss = 3.19106 (* 1 = 3.19106 loss)
I0213 11:19:05.597611  3135 solver.cpp:824] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_60000.caffemodel
I0213 11:19:05.702428  3135 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/ssd768x320_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1_51.41/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_60000.solverstate
I0213 11:19:05.944330  3135 solver.cpp:537] Iteration 60000, loss = 2.85348
I0213 11:19:05.944444  3135 solver.cpp:666] Iteration 60000, Testing net (#0)
I0213 11:19:56.669901  3136 solver.cpp:774] class AP 1: 0.377567
I0213 11:19:56.724107  3136 solver.cpp:774] class AP 2: 0.637081
I0213 11:19:56.733139  3136 solver.cpp:774] class AP 3: 0.630207
I0213 11:19:56.733229  3136 solver.cpp:780] Test net output mAP #0: detection_eval = 0.548285
I0213 11:19:56.902014  3135 solver.cpp:774] class AP 1: 0.380996
I0213 11:19:56.954430  3135 solver.cpp:774] class AP 2: 0.634422
I0213 11:19:56.962986  3135 solver.cpp:774] class AP 3: 0.631366
I0213 11:19:56.963002  3135 solver.cpp:780] Test net output mAP #0: detection_eval = 0.548928
I0213 11:19:57.000203  3050 parallel.cpp:71] Root Solver performance on device 0: 1.356 * 8 = 10.85 img/sec (60000 itr in 4.424e+04 sec)
I0213 11:19:57.000258  3050 parallel.cpp:76]      Solver performance on device 1: 1.356 * 8 = 10.85 img/sec (60000 itr in 4.424e+04 sec)
I0213 11:19:57.000272  3050 parallel.cpp:79] Overall multi-GPU performance: 21.6981 img/sec
I0213 11:19:57.813261  3050 caffe.cpp:253] Optimization Done in 12h 19m 17s
