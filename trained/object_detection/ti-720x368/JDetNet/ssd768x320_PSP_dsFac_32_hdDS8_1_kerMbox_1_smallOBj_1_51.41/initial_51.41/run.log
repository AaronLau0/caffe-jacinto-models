I0323 22:48:36.225579  1439 caffe.cpp:807] This is NVCaffe 0.16.4 started at Fri Mar 23 22:48:35 2018
I0323 22:48:36.225777  1439 caffe.cpp:810] CuDNN version: 6021
I0323 22:48:36.225785  1439 caffe.cpp:811] CuBLAS version: 8000
I0323 22:48:36.225790  1439 caffe.cpp:812] CUDA version: 8000
I0323 22:48:36.225795  1439 caffe.cpp:813] CUDA driver version: 8000
I0323 22:48:36.472690  1439 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0323 22:48:36.473331  1439 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8287879168, dev_info[0]: total=8506769408 free=8287879168
I0323 22:48:36.473907  1439 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8287879168, dev_info[1]: total=8508145664 free=8379236352
I0323 22:48:36.473925  1439 caffe.cpp:214] Using GPUs 0, 1
I0323 22:48:36.474248  1439 caffe.cpp:219] GPU 0: GeForce GTX 1080
I0323 22:48:36.474567  1439 caffe.cpp:219] GPU 1: GeForce GTX 1080
I0323 22:48:36.474620  1439 solver.cpp:43] Solver data type: FLOAT
I0323 22:48:36.474674  1439 solver.cpp:46] Initializing solver from parameters: 
train_net: "training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/train.prototxt"
test_net: "training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/test.prototxt"
test_iter: 452
test_interval: 2000
base_lr: 0.01
display: 100
max_iter: 50000
lr_policy: "multistep"
gamma: 0.1
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 2000
snapshot_prefix: "training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
snapshot_after_train: true
test_initialization: true
average_loss: 10
stepvalue: 30000
stepvalue: 40000
stepvalue: 300000
iter_size: 2
type: "SGD"
eval_type: "detection"
ap_version: "11point"
show_per_class_result: true
I0323 22:48:36.483230  1439 solver.cpp:78] Creating training net from train_net file: training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/train.prototxt
I0323 22:48:36.486196  1439 net.cpp:72] Initializing net from parameters: 
name: "ssdJacintoNetV2"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 0
    mean_value: 0
    mean_value: 0
    force_color: false
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 320
      width: 768
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: NEAREST
      interp_mode: CUBIC
      interp_mode: LANCZOS4
    }
    emit_constraint {
      emit_type: CENTER
    }
    crop_h: 320
    crop_w: 768
    distort_param {
      brightness_prob: 0.5
      brightness_delta: 32
      contrast_prob: 0.5
      contrast_lower: 0.5
      contrast_upper: 1.5
      hue_prob: 0.5
      hue_delta: 18
      saturation_prob: 0.5
      saturation_lower: 0.5
      saturation_upper: 1.5
      random_order_prob: 0
    }
    expand_param {
      prob: 0.5
      max_expand_ratio: 4
    }
  }
  data_param {
    source: "/user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb"
    batch_size: 8
    backend: LMDB
    threads: 4
    parser_threads: 4
  }
  annotated_data_param {
    batch_sampler {
      max_sample: 1
      max_trials: 1
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.1
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.3
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.5
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.7
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.9
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        max_jaccard_overlap: 1
      }
      max_sample: 1
      max_trials: 50
    }
    label_map_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/labelmap.prototxt"
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "pool6"
  top: "pool7"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool8"
  type: "Pooling"
  bottom: "pool7"
  top: "pool8"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool9"
  type: "Pooling"
  bottom: "pool8"
  top: "pool9"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "ctx_output1"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "ctx_output1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu"
  type: "ReLU"
  bottom: "ctx_output1"
  top: "ctx_output1"
}
layer {
  name: "ctx_output2"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "ctx_output2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu"
  type: "ReLU"
  bottom: "ctx_output2"
  top: "ctx_output2"
}
layer {
  name: "ctx_output3"
  type: "Convolution"
  bottom: "pool6"
  top: "ctx_output3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu"
  type: "ReLU"
  bottom: "ctx_output3"
  top: "ctx_output3"
}
layer {
  name: "ctx_output4"
  type: "Convolution"
  bottom: "pool7"
  top: "ctx_output4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu"
  type: "ReLU"
  bottom: "ctx_output4"
  top: "ctx_output4"
}
layer {
  name: "ctx_output5"
  type: "Convolution"
  bottom: "pool8"
  top: "ctx_output5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu"
  type: "ReLU"
  bottom: "ctx_output5"
  top: "ctx_output5"
}
layer {
  name: "ctx_output6"
  type: "Convolution"
  bottom: "pool9"
  top: "ctx_output6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu"
  type: "ReLU"
  bottom: "ctx_output6"
  top: "ctx_output6"
}
layer {
  name: "ctx_output1/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_loc"
  top: "ctx_output1/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_loc_perm"
  top: "ctx_output1/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_conf"
  top: "ctx_output1/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_conf_perm"
  top: "ctx_output1/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output1"
  bottom: "data"
  top: "ctx_output1/relu_mbox_priorbox"
  prior_box_param {
    min_size: 12.8
    max_size: 32
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_loc"
  top: "ctx_output2/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_loc_perm"
  top: "ctx_output2/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_conf"
  top: "ctx_output2/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_conf_perm"
  top: "ctx_output2/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output2"
  bottom: "data"
  top: "ctx_output2/relu_mbox_priorbox"
  prior_box_param {
    min_size: 32
    max_size: 96
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_loc"
  top: "ctx_output3/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_loc_perm"
  top: "ctx_output3/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_conf"
  top: "ctx_output3/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_conf_perm"
  top: "ctx_output3/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output3"
  bottom: "data"
  top: "ctx_output3/relu_mbox_priorbox"
  prior_box_param {
    min_size: 96
    max_size: 160
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_loc"
  top: "ctx_output4/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_loc_perm"
  top: "ctx_output4/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_conf"
  top: "ctx_output4/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_conf_perm"
  top: "ctx_output4/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output4"
  bottom: "data"
  top: "ctx_output4/relu_mbox_priorbox"
  prior_box_param {
    min_size: 160
    max_size: 224
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_loc"
  top: "ctx_output5/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_loc_perm"
  top: "ctx_output5/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_conf"
  top: "ctx_output5/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_conf_perm"
  top: "ctx_output5/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output5"
  bottom: "data"
  top: "ctx_output5/relu_mbox_priorbox"
  prior_box_param {
    min_size: 224
    max_size: 288
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_loc"
  top: "ctx_output6/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_loc_perm"
  top: "ctx_output6/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_conf"
  top: "ctx_output6/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_conf_perm"
  top: "ctx_output6/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output6"
  bottom: "data"
  top: "ctx_output6/relu_mbox_priorbox"
  prior_box_param {
    min_size: 288
    max_size: 352
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_loc_flat"
  bottom: "ctx_output2/relu_mbox_loc_flat"
  bottom: "ctx_output3/relu_mbox_loc_flat"
  bottom: "ctx_output4/relu_mbox_loc_flat"
  bottom: "ctx_output5/relu_mbox_loc_flat"
  bottom: "ctx_output6/relu_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_conf_flat"
  bottom: "ctx_output2/relu_mbox_conf_flat"
  bottom: "ctx_output3/relu_mbox_conf_flat"
  bottom: "ctx_output4/relu_mbox_conf_flat"
  bottom: "ctx_output5/relu_mbox_conf_flat"
  bottom: "ctx_output6/relu_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_priorbox"
  bottom: "ctx_output2/relu_mbox_priorbox"
  bottom: "ctx_output3/relu_mbox_priorbox"
  bottom: "ctx_output4/relu_mbox_priorbox"
  bottom: "ctx_output5/relu_mbox_priorbox"
  bottom: "ctx_output6/relu_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_loss"
  type: "MultiBoxLoss"
  bottom: "mbox_loc"
  bottom: "mbox_conf"
  bottom: "mbox_priorbox"
  bottom: "label"
  top: "mbox_loss"
  include {
    phase: TRAIN
  }
  propagate_down: true
  propagate_down: true
  propagate_down: false
  propagate_down: false
  loss_param {
    normalization: VALID
  }
  multibox_loss_param {
    loc_loss_type: SMOOTH_L1
    conf_loss_type: SOFTMAX
    loc_weight: 1
    num_classes: 4
    share_location: true
    match_type: PER_PREDICTION
    overlap_threshold: 0.5
    use_prior_for_matching: true
    background_label_id: 0
    use_difficult_gt: false
    neg_pos_ratio: 3
    neg_overlap: 0.5
    code_type: CENTER_SIZE
    ignore_cross_boundary_bbox: false
    mining_type: MAX_NEGATIVE
    ignore_difficult_gt: false
  }
}
I0323 22:48:36.486711  1439 net.cpp:104] Using FLOAT as default forward math type
I0323 22:48:36.486723  1439 net.cpp:110] Using FLOAT as default backward math type
I0323 22:48:36.486733  1439 layer_factory.hpp:136] Creating layer 'data' of type 'AnnotatedData'
I0323 22:48:36.486740  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.486843  1439 net.cpp:184] Created Layer data (0)
I0323 22:48:36.486855  1439 net.cpp:530] data -> data
I0323 22:48:36.486881  1439 net.cpp:530] data -> label
I0323 22:48:36.486940  1439 data_reader.cpp:58] Data Reader threads: 4, out queues: 16, depth: 8
I0323 22:48:36.486995  1439 internal_thread.cpp:19] Starting 4 internal thread(s) on device 0
I0323 22:48:36.488067  1464 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0323 22:48:36.488637  1462 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0323 22:48:36.489271  1463 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0323 22:48:36.490625  1465 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0323 22:48:36.501452  1439 annotated_data_layer.cpp:219] output data size: 8,3,320,768
I0323 22:48:36.501797  1439 annotated_data_layer.cpp:265] [0] Output data size: 8, 3, 320, 768
I0323 22:48:36.501883  1439 internal_thread.cpp:19] Starting 4 internal thread(s) on device 0
I0323 22:48:36.502395  1439 net.cpp:245] Setting up data
I0323 22:48:36.502440  1439 net.cpp:252] TRAIN Top shape for layer 0 'data' 8 3 320 768 (5898240)
I0323 22:48:36.502470  1439 net.cpp:252] TRAIN Top shape for layer 0 'data' 1 1 10 8 (80)
I0323 22:48:36.502492  1439 layer_factory.hpp:136] Creating layer 'data_data_0_split' of type 'Split'
I0323 22:48:36.502512  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.502542  1439 net.cpp:184] Created Layer data_data_0_split (1)
I0323 22:48:36.502558  1439 net.cpp:561] data_data_0_split <- data
I0323 22:48:36.502584  1439 net.cpp:530] data_data_0_split -> data_data_0_split_0
I0323 22:48:36.502607  1439 net.cpp:530] data_data_0_split -> data_data_0_split_1
I0323 22:48:36.502627  1439 net.cpp:530] data_data_0_split -> data_data_0_split_2
I0323 22:48:36.502645  1439 net.cpp:530] data_data_0_split -> data_data_0_split_3
I0323 22:48:36.502661  1439 net.cpp:530] data_data_0_split -> data_data_0_split_4
I0323 22:48:36.502679  1439 net.cpp:530] data_data_0_split -> data_data_0_split_5
I0323 22:48:36.502694  1439 net.cpp:530] data_data_0_split -> data_data_0_split_6
I0323 22:48:36.502969  1439 net.cpp:245] Setting up data_data_0_split
I0323 22:48:36.502990  1439 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0323 22:48:36.503001  1439 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0323 22:48:36.503013  1439 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0323 22:48:36.503024  1439 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0323 22:48:36.503036  1439 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0323 22:48:36.503047  1439 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0323 22:48:36.503058  1439 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0323 22:48:36.503068  1439 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0323 22:48:36.503078  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.503103  1439 net.cpp:184] Created Layer data/bias (2)
I0323 22:48:36.503114  1439 net.cpp:561] data/bias <- data_data_0_split_0
I0323 22:48:36.503125  1439 net.cpp:530] data/bias -> data/bias
I0323 22:48:36.506296  1439 net.cpp:245] Setting up data/bias
I0323 22:48:36.506335  1439 net.cpp:252] TRAIN Top shape for layer 2 'data/bias' 8 3 320 768 (5898240)
I0323 22:48:36.506371  1439 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0323 22:48:36.506386  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.506428  1439 net.cpp:184] Created Layer conv1a (3)
I0323 22:48:36.506439  1439 net.cpp:561] conv1a <- data/bias
I0323 22:48:36.506451  1439 net.cpp:530] conv1a -> conv1a
I0323 22:48:36.969373  1439 net.cpp:245] Setting up conv1a
I0323 22:48:36.969411  1439 net.cpp:252] TRAIN Top shape for layer 3 'conv1a' 8 32 160 384 (15728640)
I0323 22:48:36.969432  1439 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0323 22:48:36.969440  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.969465  1439 net.cpp:184] Created Layer conv1a/bn (4)
I0323 22:48:36.969493  1439 net.cpp:561] conv1a/bn <- conv1a
I0323 22:48:36.969509  1439 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0323 22:48:36.970440  1439 net.cpp:245] Setting up conv1a/bn
I0323 22:48:36.970456  1439 net.cpp:252] TRAIN Top shape for layer 4 'conv1a/bn' 8 32 160 384 (15728640)
I0323 22:48:36.970475  1439 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0323 22:48:36.970484  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.970492  1439 net.cpp:184] Created Layer conv1a/relu (5)
I0323 22:48:36.970499  1439 net.cpp:561] conv1a/relu <- conv1a
I0323 22:48:36.970505  1439 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0323 22:48:36.970521  1439 net.cpp:245] Setting up conv1a/relu
I0323 22:48:36.970531  1439 net.cpp:252] TRAIN Top shape for layer 5 'conv1a/relu' 8 32 160 384 (15728640)
I0323 22:48:36.970538  1439 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0323 22:48:36.970544  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.970561  1439 net.cpp:184] Created Layer conv1b (6)
I0323 22:48:36.970568  1439 net.cpp:561] conv1b <- conv1a
I0323 22:48:36.970574  1439 net.cpp:530] conv1b -> conv1b
I0323 22:48:36.972215  1439 net.cpp:245] Setting up conv1b
I0323 22:48:36.972231  1439 net.cpp:252] TRAIN Top shape for layer 6 'conv1b' 8 32 160 384 (15728640)
I0323 22:48:36.972247  1439 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0323 22:48:36.972254  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.972265  1439 net.cpp:184] Created Layer conv1b/bn (7)
I0323 22:48:36.972270  1439 net.cpp:561] conv1b/bn <- conv1b
I0323 22:48:36.972277  1439 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0323 22:48:36.973145  1439 net.cpp:245] Setting up conv1b/bn
I0323 22:48:36.973160  1439 net.cpp:252] TRAIN Top shape for layer 7 'conv1b/bn' 8 32 160 384 (15728640)
I0323 22:48:36.973176  1439 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0323 22:48:36.973183  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.973191  1439 net.cpp:184] Created Layer conv1b/relu (8)
I0323 22:48:36.973197  1439 net.cpp:561] conv1b/relu <- conv1b
I0323 22:48:36.973203  1439 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0323 22:48:36.973212  1439 net.cpp:245] Setting up conv1b/relu
I0323 22:48:36.973218  1439 net.cpp:252] TRAIN Top shape for layer 8 'conv1b/relu' 8 32 160 384 (15728640)
I0323 22:48:36.973224  1439 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0323 22:48:36.973230  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.973242  1439 net.cpp:184] Created Layer pool1 (9)
I0323 22:48:36.973251  1439 net.cpp:561] pool1 <- conv1b
I0323 22:48:36.973258  1439 net.cpp:530] pool1 -> pool1
I0323 22:48:36.973362  1439 net.cpp:245] Setting up pool1
I0323 22:48:36.973376  1439 net.cpp:252] TRAIN Top shape for layer 9 'pool1' 8 32 80 192 (3932160)
I0323 22:48:36.973383  1439 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0323 22:48:36.973389  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.973402  1439 net.cpp:184] Created Layer res2a_branch2a (10)
I0323 22:48:36.973408  1439 net.cpp:561] res2a_branch2a <- pool1
I0323 22:48:36.973414  1439 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0323 22:48:36.975458  1439 net.cpp:245] Setting up res2a_branch2a
I0323 22:48:36.975477  1439 net.cpp:252] TRAIN Top shape for layer 10 'res2a_branch2a' 8 64 80 192 (7864320)
I0323 22:48:36.975493  1439 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0323 22:48:36.975500  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.975512  1439 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0323 22:48:36.975528  1439 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0323 22:48:36.975535  1439 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0323 22:48:36.977026  1439 net.cpp:245] Setting up res2a_branch2a/bn
I0323 22:48:36.977042  1439 net.cpp:252] TRAIN Top shape for layer 11 'res2a_branch2a/bn' 8 64 80 192 (7864320)
I0323 22:48:36.977061  1439 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0323 22:48:36.977069  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.977077  1439 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0323 22:48:36.977082  1439 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0323 22:48:36.977088  1439 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0323 22:48:36.977097  1439 net.cpp:245] Setting up res2a_branch2a/relu
I0323 22:48:36.977110  1439 net.cpp:252] TRAIN Top shape for layer 12 'res2a_branch2a/relu' 8 64 80 192 (7864320)
I0323 22:48:36.977116  1439 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0323 22:48:36.977121  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.977138  1439 net.cpp:184] Created Layer res2a_branch2b (13)
I0323 22:48:36.977145  1439 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0323 22:48:36.977152  1439 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0323 22:48:36.978955  1439 net.cpp:245] Setting up res2a_branch2b
I0323 22:48:36.978974  1439 net.cpp:252] TRAIN Top shape for layer 13 'res2a_branch2b' 8 64 80 192 (7864320)
I0323 22:48:36.978989  1439 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0323 22:48:36.978996  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.979007  1439 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0323 22:48:36.979014  1439 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0323 22:48:36.979022  1439 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0323 22:48:36.979959  1439 net.cpp:245] Setting up res2a_branch2b/bn
I0323 22:48:36.979974  1439 net.cpp:252] TRAIN Top shape for layer 14 'res2a_branch2b/bn' 8 64 80 192 (7864320)
I0323 22:48:36.979990  1439 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0323 22:48:36.979997  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.980005  1439 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0323 22:48:36.980010  1439 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0323 22:48:36.980016  1439 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0323 22:48:36.980024  1439 net.cpp:245] Setting up res2a_branch2b/relu
I0323 22:48:36.980036  1439 net.cpp:252] TRAIN Top shape for layer 15 'res2a_branch2b/relu' 8 64 80 192 (7864320)
I0323 22:48:36.980041  1439 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0323 22:48:36.980047  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.980062  1439 net.cpp:184] Created Layer pool2 (16)
I0323 22:48:36.980069  1439 net.cpp:561] pool2 <- res2a_branch2b
I0323 22:48:36.980075  1439 net.cpp:530] pool2 -> pool2
I0323 22:48:36.980172  1439 net.cpp:245] Setting up pool2
I0323 22:48:36.980186  1439 net.cpp:252] TRAIN Top shape for layer 16 'pool2' 8 64 40 96 (1966080)
I0323 22:48:36.980192  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0323 22:48:36.980198  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.980214  1439 net.cpp:184] Created Layer res3a_branch2a (17)
I0323 22:48:36.980221  1439 net.cpp:561] res3a_branch2a <- pool2
I0323 22:48:36.980227  1439 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0323 22:48:36.983559  1439 net.cpp:245] Setting up res3a_branch2a
I0323 22:48:36.983580  1439 net.cpp:252] TRAIN Top shape for layer 17 'res3a_branch2a' 8 128 40 96 (3932160)
I0323 22:48:36.983606  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0323 22:48:36.983613  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.983626  1439 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0323 22:48:36.983633  1439 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0323 22:48:36.983639  1439 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0323 22:48:36.984562  1439 net.cpp:245] Setting up res3a_branch2a/bn
I0323 22:48:36.984577  1439 net.cpp:252] TRAIN Top shape for layer 18 'res3a_branch2a/bn' 8 128 40 96 (3932160)
I0323 22:48:36.984599  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0323 22:48:36.984607  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.984616  1439 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0323 22:48:36.984621  1439 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0323 22:48:36.984627  1439 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0323 22:48:36.984637  1439 net.cpp:245] Setting up res3a_branch2a/relu
I0323 22:48:36.984645  1439 net.cpp:252] TRAIN Top shape for layer 19 'res3a_branch2a/relu' 8 128 40 96 (3932160)
I0323 22:48:36.984650  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0323 22:48:36.984658  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.984675  1439 net.cpp:184] Created Layer res3a_branch2b (20)
I0323 22:48:36.984683  1439 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0323 22:48:36.984689  1439 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0323 22:48:36.986270  1439 net.cpp:245] Setting up res3a_branch2b
I0323 22:48:36.986285  1439 net.cpp:252] TRAIN Top shape for layer 20 'res3a_branch2b' 8 128 40 96 (3932160)
I0323 22:48:36.986299  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0323 22:48:36.986305  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.986318  1439 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0323 22:48:36.986325  1439 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0323 22:48:36.986331  1439 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0323 22:48:36.987254  1439 net.cpp:245] Setting up res3a_branch2b/bn
I0323 22:48:36.987270  1439 net.cpp:252] TRAIN Top shape for layer 21 'res3a_branch2b/bn' 8 128 40 96 (3932160)
I0323 22:48:36.987287  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0323 22:48:36.987293  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.987300  1439 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0323 22:48:36.987306  1439 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0323 22:48:36.987314  1439 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0323 22:48:36.987323  1439 net.cpp:245] Setting up res3a_branch2b/relu
I0323 22:48:36.987329  1439 net.cpp:252] TRAIN Top shape for layer 22 'res3a_branch2b/relu' 8 128 40 96 (3932160)
I0323 22:48:36.987335  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0323 22:48:36.987341  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.987352  1439 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (23)
I0323 22:48:36.987360  1439 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0323 22:48:36.987365  1439 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0323 22:48:36.987375  1439 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0323 22:48:36.987448  1439 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0323 22:48:36.987463  1439 net.cpp:252] TRAIN Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 8 128 40 96 (3932160)
I0323 22:48:36.987480  1439 net.cpp:252] TRAIN Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 8 128 40 96 (3932160)
I0323 22:48:36.987488  1439 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0323 22:48:36.987493  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.987502  1439 net.cpp:184] Created Layer pool3 (24)
I0323 22:48:36.987509  1439 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0323 22:48:36.987514  1439 net.cpp:530] pool3 -> pool3
I0323 22:48:36.987612  1439 net.cpp:245] Setting up pool3
I0323 22:48:36.987625  1439 net.cpp:252] TRAIN Top shape for layer 24 'pool3' 8 128 20 48 (983040)
I0323 22:48:36.987632  1439 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0323 22:48:36.987637  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.987653  1439 net.cpp:184] Created Layer res4a_branch2a (25)
I0323 22:48:36.987659  1439 net.cpp:561] res4a_branch2a <- pool3
I0323 22:48:36.987665  1439 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0323 22:48:36.997952  1439 net.cpp:245] Setting up res4a_branch2a
I0323 22:48:36.997972  1439 net.cpp:252] TRAIN Top shape for layer 25 'res4a_branch2a' 8 256 20 48 (1966080)
I0323 22:48:36.997983  1439 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0323 22:48:36.997989  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.998004  1439 net.cpp:184] Created Layer res4a_branch2a/bn (26)
I0323 22:48:36.998013  1439 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0323 22:48:36.998019  1439 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0323 22:48:36.998970  1439 net.cpp:245] Setting up res4a_branch2a/bn
I0323 22:48:36.998986  1439 net.cpp:252] TRAIN Top shape for layer 26 'res4a_branch2a/bn' 8 256 20 48 (1966080)
I0323 22:48:36.999001  1439 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0323 22:48:36.999007  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.999017  1439 net.cpp:184] Created Layer res4a_branch2a/relu (27)
I0323 22:48:36.999022  1439 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0323 22:48:36.999028  1439 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0323 22:48:36.999037  1439 net.cpp:245] Setting up res4a_branch2a/relu
I0323 22:48:36.999045  1439 net.cpp:252] TRAIN Top shape for layer 27 'res4a_branch2a/relu' 8 256 20 48 (1966080)
I0323 22:48:36.999052  1439 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0323 22:48:36.999058  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.999078  1439 net.cpp:184] Created Layer res4a_branch2b (28)
I0323 22:48:36.999085  1439 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0323 22:48:36.999091  1439 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0323 22:48:37.004145  1439 net.cpp:245] Setting up res4a_branch2b
I0323 22:48:37.004170  1439 net.cpp:252] TRAIN Top shape for layer 28 'res4a_branch2b' 8 256 20 48 (1966080)
I0323 22:48:37.004182  1439 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0323 22:48:37.004189  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.004204  1439 net.cpp:184] Created Layer res4a_branch2b/bn (29)
I0323 22:48:37.004211  1439 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0323 22:48:37.004218  1439 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0323 22:48:37.005167  1439 net.cpp:245] Setting up res4a_branch2b/bn
I0323 22:48:37.005182  1439 net.cpp:252] TRAIN Top shape for layer 29 'res4a_branch2b/bn' 8 256 20 48 (1966080)
I0323 22:48:37.005195  1439 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0323 22:48:37.005218  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.005226  1439 net.cpp:184] Created Layer res4a_branch2b/relu (30)
I0323 22:48:37.005233  1439 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0323 22:48:37.005240  1439 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0323 22:48:37.005249  1439 net.cpp:245] Setting up res4a_branch2b/relu
I0323 22:48:37.005259  1439 net.cpp:252] TRAIN Top shape for layer 30 'res4a_branch2b/relu' 8 256 20 48 (1966080)
I0323 22:48:37.005265  1439 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0323 22:48:37.005272  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.005285  1439 net.cpp:184] Created Layer pool4 (31)
I0323 22:48:37.005291  1439 net.cpp:561] pool4 <- res4a_branch2b
I0323 22:48:37.005298  1439 net.cpp:530] pool4 -> pool4
I0323 22:48:37.005398  1439 net.cpp:245] Setting up pool4
I0323 22:48:37.005411  1439 net.cpp:252] TRAIN Top shape for layer 31 'pool4' 8 256 10 24 (491520)
I0323 22:48:37.005419  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0323 22:48:37.005424  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.005445  1439 net.cpp:184] Created Layer res5a_branch2a (32)
I0323 22:48:37.005452  1439 net.cpp:561] res5a_branch2a <- pool4
I0323 22:48:37.005460  1439 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0323 22:48:37.044706  1439 net.cpp:245] Setting up res5a_branch2a
I0323 22:48:37.044737  1439 net.cpp:252] TRAIN Top shape for layer 32 'res5a_branch2a' 8 512 10 24 (983040)
I0323 22:48:37.044755  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0323 22:48:37.044764  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.044780  1439 net.cpp:184] Created Layer res5a_branch2a/bn (33)
I0323 22:48:37.044788  1439 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0323 22:48:37.044796  1439 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0323 22:48:37.045740  1439 net.cpp:245] Setting up res5a_branch2a/bn
I0323 22:48:37.045756  1439 net.cpp:252] TRAIN Top shape for layer 33 'res5a_branch2a/bn' 8 512 10 24 (983040)
I0323 22:48:37.045770  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0323 22:48:37.045778  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.045788  1439 net.cpp:184] Created Layer res5a_branch2a/relu (34)
I0323 22:48:37.045794  1439 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0323 22:48:37.045799  1439 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0323 22:48:37.045809  1439 net.cpp:245] Setting up res5a_branch2a/relu
I0323 22:48:37.045815  1439 net.cpp:252] TRAIN Top shape for layer 34 'res5a_branch2a/relu' 8 512 10 24 (983040)
I0323 22:48:37.045821  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0323 22:48:37.045835  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.045857  1439 net.cpp:184] Created Layer res5a_branch2b (35)
I0323 22:48:37.045866  1439 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0323 22:48:37.045872  1439 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0323 22:48:37.065218  1439 net.cpp:245] Setting up res5a_branch2b
I0323 22:48:37.065250  1439 net.cpp:252] TRAIN Top shape for layer 35 'res5a_branch2b' 8 512 10 24 (983040)
I0323 22:48:37.065273  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0323 22:48:37.065282  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.065301  1439 net.cpp:184] Created Layer res5a_branch2b/bn (36)
I0323 22:48:37.065310  1439 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0323 22:48:37.065318  1439 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0323 22:48:37.066318  1439 net.cpp:245] Setting up res5a_branch2b/bn
I0323 22:48:37.066334  1439 net.cpp:252] TRAIN Top shape for layer 36 'res5a_branch2b/bn' 8 512 10 24 (983040)
I0323 22:48:37.066347  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0323 22:48:37.066354  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.066365  1439 net.cpp:184] Created Layer res5a_branch2b/relu (37)
I0323 22:48:37.066370  1439 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0323 22:48:37.066380  1439 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0323 22:48:37.066390  1439 net.cpp:245] Setting up res5a_branch2b/relu
I0323 22:48:37.066401  1439 net.cpp:252] TRAIN Top shape for layer 37 'res5a_branch2b/relu' 8 512 10 24 (983040)
I0323 22:48:37.066412  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2b_res5a_branch2b/relu_0_split' of type 'Split'
I0323 22:48:37.066418  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.066424  1439 net.cpp:184] Created Layer res5a_branch2b_res5a_branch2b/relu_0_split (38)
I0323 22:48:37.066431  1439 net.cpp:561] res5a_branch2b_res5a_branch2b/relu_0_split <- res5a_branch2b
I0323 22:48:37.066437  1439 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_0
I0323 22:48:37.066445  1439 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_1
I0323 22:48:37.066520  1439 net.cpp:245] Setting up res5a_branch2b_res5a_branch2b/relu_0_split
I0323 22:48:37.066534  1439 net.cpp:252] TRAIN Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 8 512 10 24 (983040)
I0323 22:48:37.066541  1439 net.cpp:252] TRAIN Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 8 512 10 24 (983040)
I0323 22:48:37.066548  1439 layer_factory.hpp:136] Creating layer 'pool6' of type 'Pooling'
I0323 22:48:37.066555  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.066567  1439 net.cpp:184] Created Layer pool6 (39)
I0323 22:48:37.066576  1439 net.cpp:561] pool6 <- res5a_branch2b_res5a_branch2b/relu_0_split_0
I0323 22:48:37.066582  1439 net.cpp:530] pool6 -> pool6
I0323 22:48:37.066684  1439 net.cpp:245] Setting up pool6
I0323 22:48:37.066697  1439 net.cpp:252] TRAIN Top shape for layer 39 'pool6' 8 512 5 12 (245760)
I0323 22:48:37.066706  1439 layer_factory.hpp:136] Creating layer 'pool6_pool6_0_split' of type 'Split'
I0323 22:48:37.066712  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.066721  1439 net.cpp:184] Created Layer pool6_pool6_0_split (40)
I0323 22:48:37.066728  1439 net.cpp:561] pool6_pool6_0_split <- pool6
I0323 22:48:37.066735  1439 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_0
I0323 22:48:37.066743  1439 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_1
I0323 22:48:37.066808  1439 net.cpp:245] Setting up pool6_pool6_0_split
I0323 22:48:37.066821  1439 net.cpp:252] TRAIN Top shape for layer 40 'pool6_pool6_0_split' 8 512 5 12 (245760)
I0323 22:48:37.066830  1439 net.cpp:252] TRAIN Top shape for layer 40 'pool6_pool6_0_split' 8 512 5 12 (245760)
I0323 22:48:37.066838  1439 layer_factory.hpp:136] Creating layer 'pool7' of type 'Pooling'
I0323 22:48:37.066844  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.066855  1439 net.cpp:184] Created Layer pool7 (41)
I0323 22:48:37.066864  1439 net.cpp:561] pool7 <- pool6_pool6_0_split_0
I0323 22:48:37.066870  1439 net.cpp:530] pool7 -> pool7
I0323 22:48:37.066962  1439 net.cpp:245] Setting up pool7
I0323 22:48:37.066975  1439 net.cpp:252] TRAIN Top shape for layer 41 'pool7' 8 512 3 6 (73728)
I0323 22:48:37.066982  1439 layer_factory.hpp:136] Creating layer 'pool7_pool7_0_split' of type 'Split'
I0323 22:48:37.066988  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.067006  1439 net.cpp:184] Created Layer pool7_pool7_0_split (42)
I0323 22:48:37.067014  1439 net.cpp:561] pool7_pool7_0_split <- pool7
I0323 22:48:37.067023  1439 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_0
I0323 22:48:37.067034  1439 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_1
I0323 22:48:37.067101  1439 net.cpp:245] Setting up pool7_pool7_0_split
I0323 22:48:37.067114  1439 net.cpp:252] TRAIN Top shape for layer 42 'pool7_pool7_0_split' 8 512 3 6 (73728)
I0323 22:48:37.067122  1439 net.cpp:252] TRAIN Top shape for layer 42 'pool7_pool7_0_split' 8 512 3 6 (73728)
I0323 22:48:37.067129  1439 layer_factory.hpp:136] Creating layer 'pool8' of type 'Pooling'
I0323 22:48:37.067137  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.067149  1439 net.cpp:184] Created Layer pool8 (43)
I0323 22:48:37.067157  1439 net.cpp:561] pool8 <- pool7_pool7_0_split_0
I0323 22:48:37.067165  1439 net.cpp:530] pool8 -> pool8
I0323 22:48:37.067260  1439 net.cpp:245] Setting up pool8
I0323 22:48:37.067272  1439 net.cpp:252] TRAIN Top shape for layer 43 'pool8' 8 512 2 3 (24576)
I0323 22:48:37.067279  1439 layer_factory.hpp:136] Creating layer 'pool8_pool8_0_split' of type 'Split'
I0323 22:48:37.067286  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.067299  1439 net.cpp:184] Created Layer pool8_pool8_0_split (44)
I0323 22:48:37.067306  1439 net.cpp:561] pool8_pool8_0_split <- pool8
I0323 22:48:37.067314  1439 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_0
I0323 22:48:37.067322  1439 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_1
I0323 22:48:37.067389  1439 net.cpp:245] Setting up pool8_pool8_0_split
I0323 22:48:37.067401  1439 net.cpp:252] TRAIN Top shape for layer 44 'pool8_pool8_0_split' 8 512 2 3 (24576)
I0323 22:48:37.067409  1439 net.cpp:252] TRAIN Top shape for layer 44 'pool8_pool8_0_split' 8 512 2 3 (24576)
I0323 22:48:37.067415  1439 layer_factory.hpp:136] Creating layer 'pool9' of type 'Pooling'
I0323 22:48:37.067422  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.067432  1439 net.cpp:184] Created Layer pool9 (45)
I0323 22:48:37.067440  1439 net.cpp:561] pool9 <- pool8_pool8_0_split_0
I0323 22:48:37.067448  1439 net.cpp:530] pool9 -> pool9
I0323 22:48:37.067541  1439 net.cpp:245] Setting up pool9
I0323 22:48:37.067554  1439 net.cpp:252] TRAIN Top shape for layer 45 'pool9' 8 512 1 2 (8192)
I0323 22:48:37.067561  1439 layer_factory.hpp:136] Creating layer 'ctx_output1' of type 'Convolution'
I0323 22:48:37.067569  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.067589  1439 net.cpp:184] Created Layer ctx_output1 (46)
I0323 22:48:37.067598  1439 net.cpp:561] ctx_output1 <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0323 22:48:37.067606  1439 net.cpp:530] ctx_output1 -> ctx_output1
I0323 22:48:37.069097  1439 net.cpp:245] Setting up ctx_output1
I0323 22:48:37.069113  1439 net.cpp:252] TRAIN Top shape for layer 46 'ctx_output1' 8 256 40 96 (7864320)
I0323 22:48:37.069123  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu' of type 'ReLU'
I0323 22:48:37.069129  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.069139  1439 net.cpp:184] Created Layer ctx_output1/relu (47)
I0323 22:48:37.069145  1439 net.cpp:561] ctx_output1/relu <- ctx_output1
I0323 22:48:37.069151  1439 net.cpp:513] ctx_output1/relu -> ctx_output1 (in-place)
I0323 22:48:37.069161  1439 net.cpp:245] Setting up ctx_output1/relu
I0323 22:48:37.069172  1439 net.cpp:252] TRAIN Top shape for layer 47 'ctx_output1/relu' 8 256 40 96 (7864320)
I0323 22:48:37.069178  1439 layer_factory.hpp:136] Creating layer 'ctx_output1_ctx_output1/relu_0_split' of type 'Split'
I0323 22:48:37.069183  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.069190  1439 net.cpp:184] Created Layer ctx_output1_ctx_output1/relu_0_split (48)
I0323 22:48:37.069206  1439 net.cpp:561] ctx_output1_ctx_output1/relu_0_split <- ctx_output1
I0323 22:48:37.069213  1439 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_0
I0323 22:48:37.069221  1439 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_1
I0323 22:48:37.069231  1439 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_2
I0323 22:48:37.069329  1439 net.cpp:245] Setting up ctx_output1_ctx_output1/relu_0_split
I0323 22:48:37.069341  1439 net.cpp:252] TRAIN Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 8 256 40 96 (7864320)
I0323 22:48:37.069348  1439 net.cpp:252] TRAIN Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 8 256 40 96 (7864320)
I0323 22:48:37.069356  1439 net.cpp:252] TRAIN Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 8 256 40 96 (7864320)
I0323 22:48:37.069363  1439 layer_factory.hpp:136] Creating layer 'ctx_output2' of type 'Convolution'
I0323 22:48:37.069371  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.069389  1439 net.cpp:184] Created Layer ctx_output2 (49)
I0323 22:48:37.069398  1439 net.cpp:561] ctx_output2 <- res5a_branch2b_res5a_branch2b/relu_0_split_1
I0323 22:48:37.069406  1439 net.cpp:530] ctx_output2 -> ctx_output2
I0323 22:48:37.074061  1439 net.cpp:245] Setting up ctx_output2
I0323 22:48:37.074090  1439 net.cpp:252] TRAIN Top shape for layer 49 'ctx_output2' 8 256 10 24 (491520)
I0323 22:48:37.074107  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu' of type 'ReLU'
I0323 22:48:37.074115  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.074126  1439 net.cpp:184] Created Layer ctx_output2/relu (50)
I0323 22:48:37.074133  1439 net.cpp:561] ctx_output2/relu <- ctx_output2
I0323 22:48:37.074141  1439 net.cpp:513] ctx_output2/relu -> ctx_output2 (in-place)
I0323 22:48:37.074151  1439 net.cpp:245] Setting up ctx_output2/relu
I0323 22:48:37.074159  1439 net.cpp:252] TRAIN Top shape for layer 50 'ctx_output2/relu' 8 256 10 24 (491520)
I0323 22:48:37.074167  1439 layer_factory.hpp:136] Creating layer 'ctx_output2_ctx_output2/relu_0_split' of type 'Split'
I0323 22:48:37.074173  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.074188  1439 net.cpp:184] Created Layer ctx_output2_ctx_output2/relu_0_split (51)
I0323 22:48:37.074196  1439 net.cpp:561] ctx_output2_ctx_output2/relu_0_split <- ctx_output2
I0323 22:48:37.074203  1439 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_0
I0323 22:48:37.074211  1439 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_1
I0323 22:48:37.074219  1439 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_2
I0323 22:48:37.074318  1439 net.cpp:245] Setting up ctx_output2_ctx_output2/relu_0_split
I0323 22:48:37.074334  1439 net.cpp:252] TRAIN Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 8 256 10 24 (491520)
I0323 22:48:37.074342  1439 net.cpp:252] TRAIN Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 8 256 10 24 (491520)
I0323 22:48:37.074348  1439 net.cpp:252] TRAIN Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 8 256 10 24 (491520)
I0323 22:48:37.074354  1439 layer_factory.hpp:136] Creating layer 'ctx_output3' of type 'Convolution'
I0323 22:48:37.074362  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.074383  1439 net.cpp:184] Created Layer ctx_output3 (52)
I0323 22:48:37.074391  1439 net.cpp:561] ctx_output3 <- pool6_pool6_0_split_1
I0323 22:48:37.074399  1439 net.cpp:530] ctx_output3 -> ctx_output3
I0323 22:48:37.080008  1439 net.cpp:245] Setting up ctx_output3
I0323 22:48:37.080026  1439 net.cpp:252] TRAIN Top shape for layer 52 'ctx_output3' 8 256 5 12 (122880)
I0323 22:48:37.080055  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu' of type 'ReLU'
I0323 22:48:37.080062  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.080070  1439 net.cpp:184] Created Layer ctx_output3/relu (53)
I0323 22:48:37.080076  1439 net.cpp:561] ctx_output3/relu <- ctx_output3
I0323 22:48:37.080082  1439 net.cpp:513] ctx_output3/relu -> ctx_output3 (in-place)
I0323 22:48:37.080090  1439 net.cpp:245] Setting up ctx_output3/relu
I0323 22:48:37.080101  1439 net.cpp:252] TRAIN Top shape for layer 53 'ctx_output3/relu' 8 256 5 12 (122880)
I0323 22:48:37.080106  1439 layer_factory.hpp:136] Creating layer 'ctx_output3_ctx_output3/relu_0_split' of type 'Split'
I0323 22:48:37.080111  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.080119  1439 net.cpp:184] Created Layer ctx_output3_ctx_output3/relu_0_split (54)
I0323 22:48:37.080128  1439 net.cpp:561] ctx_output3_ctx_output3/relu_0_split <- ctx_output3
I0323 22:48:37.080134  1439 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_0
I0323 22:48:37.080142  1439 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_1
I0323 22:48:37.080152  1439 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_2
I0323 22:48:37.080250  1439 net.cpp:245] Setting up ctx_output3_ctx_output3/relu_0_split
I0323 22:48:37.080265  1439 net.cpp:252] TRAIN Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 8 256 5 12 (122880)
I0323 22:48:37.080271  1439 net.cpp:252] TRAIN Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 8 256 5 12 (122880)
I0323 22:48:37.080279  1439 net.cpp:252] TRAIN Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 8 256 5 12 (122880)
I0323 22:48:37.080286  1439 layer_factory.hpp:136] Creating layer 'ctx_output4' of type 'Convolution'
I0323 22:48:37.080293  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.080310  1439 net.cpp:184] Created Layer ctx_output4 (55)
I0323 22:48:37.080319  1439 net.cpp:561] ctx_output4 <- pool7_pool7_0_split_1
I0323 22:48:37.080327  1439 net.cpp:530] ctx_output4 -> ctx_output4
I0323 22:48:37.084702  1439 net.cpp:245] Setting up ctx_output4
I0323 22:48:37.084717  1439 net.cpp:252] TRAIN Top shape for layer 55 'ctx_output4' 8 256 3 6 (36864)
I0323 22:48:37.084729  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu' of type 'ReLU'
I0323 22:48:37.084736  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.084743  1439 net.cpp:184] Created Layer ctx_output4/relu (56)
I0323 22:48:37.084749  1439 net.cpp:561] ctx_output4/relu <- ctx_output4
I0323 22:48:37.084755  1439 net.cpp:513] ctx_output4/relu -> ctx_output4 (in-place)
I0323 22:48:37.084765  1439 net.cpp:245] Setting up ctx_output4/relu
I0323 22:48:37.084774  1439 net.cpp:252] TRAIN Top shape for layer 56 'ctx_output4/relu' 8 256 3 6 (36864)
I0323 22:48:37.084782  1439 layer_factory.hpp:136] Creating layer 'ctx_output4_ctx_output4/relu_0_split' of type 'Split'
I0323 22:48:37.084789  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.084795  1439 net.cpp:184] Created Layer ctx_output4_ctx_output4/relu_0_split (57)
I0323 22:48:37.084802  1439 net.cpp:561] ctx_output4_ctx_output4/relu_0_split <- ctx_output4
I0323 22:48:37.084808  1439 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_0
I0323 22:48:37.084815  1439 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_1
I0323 22:48:37.084825  1439 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_2
I0323 22:48:37.084928  1439 net.cpp:245] Setting up ctx_output4_ctx_output4/relu_0_split
I0323 22:48:37.084941  1439 net.cpp:252] TRAIN Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 8 256 3 6 (36864)
I0323 22:48:37.084962  1439 net.cpp:252] TRAIN Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 8 256 3 6 (36864)
I0323 22:48:37.084969  1439 net.cpp:252] TRAIN Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 8 256 3 6 (36864)
I0323 22:48:37.084975  1439 layer_factory.hpp:136] Creating layer 'ctx_output5' of type 'Convolution'
I0323 22:48:37.084981  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.084997  1439 net.cpp:184] Created Layer ctx_output5 (58)
I0323 22:48:37.085006  1439 net.cpp:561] ctx_output5 <- pool8_pool8_0_split_1
I0323 22:48:37.085014  1439 net.cpp:530] ctx_output5 -> ctx_output5
I0323 22:48:37.089378  1439 net.cpp:245] Setting up ctx_output5
I0323 22:48:37.089393  1439 net.cpp:252] TRAIN Top shape for layer 58 'ctx_output5' 8 256 2 3 (12288)
I0323 22:48:37.089403  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu' of type 'ReLU'
I0323 22:48:37.089412  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.089421  1439 net.cpp:184] Created Layer ctx_output5/relu (59)
I0323 22:48:37.089426  1439 net.cpp:561] ctx_output5/relu <- ctx_output5
I0323 22:48:37.089432  1439 net.cpp:513] ctx_output5/relu -> ctx_output5 (in-place)
I0323 22:48:37.089442  1439 net.cpp:245] Setting up ctx_output5/relu
I0323 22:48:37.089450  1439 net.cpp:252] TRAIN Top shape for layer 59 'ctx_output5/relu' 8 256 2 3 (12288)
I0323 22:48:37.089458  1439 layer_factory.hpp:136] Creating layer 'ctx_output5_ctx_output5/relu_0_split' of type 'Split'
I0323 22:48:37.089464  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.089473  1439 net.cpp:184] Created Layer ctx_output5_ctx_output5/relu_0_split (60)
I0323 22:48:37.089478  1439 net.cpp:561] ctx_output5_ctx_output5/relu_0_split <- ctx_output5
I0323 22:48:37.089485  1439 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_0
I0323 22:48:37.089493  1439 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_1
I0323 22:48:37.089501  1439 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_2
I0323 22:48:37.089604  1439 net.cpp:245] Setting up ctx_output5_ctx_output5/relu_0_split
I0323 22:48:37.089617  1439 net.cpp:252] TRAIN Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 8 256 2 3 (12288)
I0323 22:48:37.089624  1439 net.cpp:252] TRAIN Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 8 256 2 3 (12288)
I0323 22:48:37.089633  1439 net.cpp:252] TRAIN Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 8 256 2 3 (12288)
I0323 22:48:37.089639  1439 layer_factory.hpp:136] Creating layer 'ctx_output6' of type 'Convolution'
I0323 22:48:37.089645  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.089661  1439 net.cpp:184] Created Layer ctx_output6 (61)
I0323 22:48:37.089668  1439 net.cpp:561] ctx_output6 <- pool9
I0323 22:48:37.089675  1439 net.cpp:530] ctx_output6 -> ctx_output6
I0323 22:48:37.094300  1439 net.cpp:245] Setting up ctx_output6
I0323 22:48:37.094328  1439 net.cpp:252] TRAIN Top shape for layer 61 'ctx_output6' 8 256 1 2 (4096)
I0323 22:48:37.094341  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu' of type 'ReLU'
I0323 22:48:37.094348  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.094359  1439 net.cpp:184] Created Layer ctx_output6/relu (62)
I0323 22:48:37.094367  1439 net.cpp:561] ctx_output6/relu <- ctx_output6
I0323 22:48:37.094374  1439 net.cpp:513] ctx_output6/relu -> ctx_output6 (in-place)
I0323 22:48:37.094384  1439 net.cpp:245] Setting up ctx_output6/relu
I0323 22:48:37.094391  1439 net.cpp:252] TRAIN Top shape for layer 62 'ctx_output6/relu' 8 256 1 2 (4096)
I0323 22:48:37.094399  1439 layer_factory.hpp:136] Creating layer 'ctx_output6_ctx_output6/relu_0_split' of type 'Split'
I0323 22:48:37.094419  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.094430  1439 net.cpp:184] Created Layer ctx_output6_ctx_output6/relu_0_split (63)
I0323 22:48:37.094437  1439 net.cpp:561] ctx_output6_ctx_output6/relu_0_split <- ctx_output6
I0323 22:48:37.094444  1439 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_0
I0323 22:48:37.094454  1439 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_1
I0323 22:48:37.094463  1439 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_2
I0323 22:48:37.094563  1439 net.cpp:245] Setting up ctx_output6_ctx_output6/relu_0_split
I0323 22:48:37.094576  1439 net.cpp:252] TRAIN Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 8 256 1 2 (4096)
I0323 22:48:37.094583  1439 net.cpp:252] TRAIN Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 8 256 1 2 (4096)
I0323 22:48:37.094590  1439 net.cpp:252] TRAIN Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 8 256 1 2 (4096)
I0323 22:48:37.094597  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc' of type 'Convolution'
I0323 22:48:37.094605  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.094627  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc (64)
I0323 22:48:37.094636  1439 net.cpp:561] ctx_output1/relu_mbox_loc <- ctx_output1_ctx_output1/relu_0_split_0
I0323 22:48:37.094645  1439 net.cpp:530] ctx_output1/relu_mbox_loc -> ctx_output1/relu_mbox_loc
I0323 22:48:37.095273  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_loc
I0323 22:48:37.095289  1439 net.cpp:252] TRAIN Top shape for layer 64 'ctx_output1/relu_mbox_loc' 8 16 40 96 (491520)
I0323 22:48:37.095300  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_perm' of type 'Permute'
I0323 22:48:37.095309  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.095331  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_perm (65)
I0323 22:48:37.095340  1439 net.cpp:561] ctx_output1/relu_mbox_loc_perm <- ctx_output1/relu_mbox_loc
I0323 22:48:37.095347  1439 net.cpp:530] ctx_output1/relu_mbox_loc_perm -> ctx_output1/relu_mbox_loc_perm
I0323 22:48:37.095549  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_perm
I0323 22:48:37.095563  1439 net.cpp:252] TRAIN Top shape for layer 65 'ctx_output1/relu_mbox_loc_perm' 8 40 96 16 (491520)
I0323 22:48:37.095571  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_flat' of type 'Flatten'
I0323 22:48:37.095577  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.095592  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_flat (66)
I0323 22:48:37.095600  1439 net.cpp:561] ctx_output1/relu_mbox_loc_flat <- ctx_output1/relu_mbox_loc_perm
I0323 22:48:37.095607  1439 net.cpp:530] ctx_output1/relu_mbox_loc_flat -> ctx_output1/relu_mbox_loc_flat
I0323 22:48:37.095654  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_flat
I0323 22:48:37.095667  1439 net.cpp:252] TRAIN Top shape for layer 66 'ctx_output1/relu_mbox_loc_flat' 8 61440 (491520)
I0323 22:48:37.095675  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf' of type 'Convolution'
I0323 22:48:37.095682  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.095700  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf (67)
I0323 22:48:37.095707  1439 net.cpp:561] ctx_output1/relu_mbox_conf <- ctx_output1_ctx_output1/relu_0_split_1
I0323 22:48:37.095716  1439 net.cpp:530] ctx_output1/relu_mbox_conf -> ctx_output1/relu_mbox_conf
I0323 22:48:37.096338  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_conf
I0323 22:48:37.096354  1439 net.cpp:252] TRAIN Top shape for layer 67 'ctx_output1/relu_mbox_conf' 8 16 40 96 (491520)
I0323 22:48:37.096374  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_perm' of type 'Permute'
I0323 22:48:37.096382  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.096396  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_perm (68)
I0323 22:48:37.096405  1439 net.cpp:561] ctx_output1/relu_mbox_conf_perm <- ctx_output1/relu_mbox_conf
I0323 22:48:37.096412  1439 net.cpp:530] ctx_output1/relu_mbox_conf_perm -> ctx_output1/relu_mbox_conf_perm
I0323 22:48:37.096609  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_perm
I0323 22:48:37.096623  1439 net.cpp:252] TRAIN Top shape for layer 68 'ctx_output1/relu_mbox_conf_perm' 8 40 96 16 (491520)
I0323 22:48:37.096631  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_flat' of type 'Flatten'
I0323 22:48:37.096637  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.096647  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_flat (69)
I0323 22:48:37.096654  1439 net.cpp:561] ctx_output1/relu_mbox_conf_flat <- ctx_output1/relu_mbox_conf_perm
I0323 22:48:37.096662  1439 net.cpp:530] ctx_output1/relu_mbox_conf_flat -> ctx_output1/relu_mbox_conf_flat
I0323 22:48:37.096709  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_flat
I0323 22:48:37.096721  1439 net.cpp:252] TRAIN Top shape for layer 69 'ctx_output1/relu_mbox_conf_flat' 8 61440 (491520)
I0323 22:48:37.096729  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_priorbox' of type 'PriorBox'
I0323 22:48:37.096736  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.096752  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_priorbox (70)
I0323 22:48:37.096760  1439 net.cpp:561] ctx_output1/relu_mbox_priorbox <- ctx_output1_ctx_output1/relu_0_split_2
I0323 22:48:37.096767  1439 net.cpp:561] ctx_output1/relu_mbox_priorbox <- data_data_0_split_1
I0323 22:48:37.096776  1439 net.cpp:530] ctx_output1/relu_mbox_priorbox -> ctx_output1/relu_mbox_priorbox
I0323 22:48:37.096829  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_priorbox
I0323 22:48:37.096843  1439 net.cpp:252] TRAIN Top shape for layer 70 'ctx_output1/relu_mbox_priorbox' 1 2 61440 (122880)
I0323 22:48:37.096850  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc' of type 'Convolution'
I0323 22:48:37.096858  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.096873  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc (71)
I0323 22:48:37.096882  1439 net.cpp:561] ctx_output2/relu_mbox_loc <- ctx_output2_ctx_output2/relu_0_split_0
I0323 22:48:37.096890  1439 net.cpp:530] ctx_output2/relu_mbox_loc -> ctx_output2/relu_mbox_loc
I0323 22:48:37.097582  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_loc
I0323 22:48:37.097597  1439 net.cpp:252] TRAIN Top shape for layer 71 'ctx_output2/relu_mbox_loc' 8 24 10 24 (46080)
I0323 22:48:37.097609  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_perm' of type 'Permute'
I0323 22:48:37.097616  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.097628  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_perm (72)
I0323 22:48:37.097636  1439 net.cpp:561] ctx_output2/relu_mbox_loc_perm <- ctx_output2/relu_mbox_loc
I0323 22:48:37.097645  1439 net.cpp:530] ctx_output2/relu_mbox_loc_perm -> ctx_output2/relu_mbox_loc_perm
I0323 22:48:37.097847  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_perm
I0323 22:48:37.097862  1439 net.cpp:252] TRAIN Top shape for layer 72 'ctx_output2/relu_mbox_loc_perm' 8 10 24 24 (46080)
I0323 22:48:37.097869  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_flat' of type 'Flatten'
I0323 22:48:37.097877  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.097887  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_flat (73)
I0323 22:48:37.097903  1439 net.cpp:561] ctx_output2/relu_mbox_loc_flat <- ctx_output2/relu_mbox_loc_perm
I0323 22:48:37.097913  1439 net.cpp:530] ctx_output2/relu_mbox_loc_flat -> ctx_output2/relu_mbox_loc_flat
I0323 22:48:37.097959  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_flat
I0323 22:48:37.097972  1439 net.cpp:252] TRAIN Top shape for layer 73 'ctx_output2/relu_mbox_loc_flat' 8 5760 (46080)
I0323 22:48:37.097980  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf' of type 'Convolution'
I0323 22:48:37.097986  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.098004  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf (74)
I0323 22:48:37.098012  1439 net.cpp:561] ctx_output2/relu_mbox_conf <- ctx_output2_ctx_output2/relu_0_split_1
I0323 22:48:37.098021  1439 net.cpp:530] ctx_output2/relu_mbox_conf -> ctx_output2/relu_mbox_conf
I0323 22:48:37.098708  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_conf
I0323 22:48:37.098724  1439 net.cpp:252] TRAIN Top shape for layer 74 'ctx_output2/relu_mbox_conf' 8 24 10 24 (46080)
I0323 22:48:37.098736  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_perm' of type 'Permute'
I0323 22:48:37.098743  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.098757  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_perm (75)
I0323 22:48:37.098765  1439 net.cpp:561] ctx_output2/relu_mbox_conf_perm <- ctx_output2/relu_mbox_conf
I0323 22:48:37.098773  1439 net.cpp:530] ctx_output2/relu_mbox_conf_perm -> ctx_output2/relu_mbox_conf_perm
I0323 22:48:37.098968  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_perm
I0323 22:48:37.098983  1439 net.cpp:252] TRAIN Top shape for layer 75 'ctx_output2/relu_mbox_conf_perm' 8 10 24 24 (46080)
I0323 22:48:37.098989  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_flat' of type 'Flatten'
I0323 22:48:37.098996  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.099004  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_flat (76)
I0323 22:48:37.099011  1439 net.cpp:561] ctx_output2/relu_mbox_conf_flat <- ctx_output2/relu_mbox_conf_perm
I0323 22:48:37.099018  1439 net.cpp:530] ctx_output2/relu_mbox_conf_flat -> ctx_output2/relu_mbox_conf_flat
I0323 22:48:37.099064  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_flat
I0323 22:48:37.099077  1439 net.cpp:252] TRAIN Top shape for layer 76 'ctx_output2/relu_mbox_conf_flat' 8 5760 (46080)
I0323 22:48:37.099086  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_priorbox' of type 'PriorBox'
I0323 22:48:37.099092  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.099102  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_priorbox (77)
I0323 22:48:37.099108  1439 net.cpp:561] ctx_output2/relu_mbox_priorbox <- ctx_output2_ctx_output2/relu_0_split_2
I0323 22:48:37.099115  1439 net.cpp:561] ctx_output2/relu_mbox_priorbox <- data_data_0_split_2
I0323 22:48:37.099123  1439 net.cpp:530] ctx_output2/relu_mbox_priorbox -> ctx_output2/relu_mbox_priorbox
I0323 22:48:37.099172  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_priorbox
I0323 22:48:37.099185  1439 net.cpp:252] TRAIN Top shape for layer 77 'ctx_output2/relu_mbox_priorbox' 1 2 5760 (11520)
I0323 22:48:37.099192  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc' of type 'Convolution'
I0323 22:48:37.099200  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.099220  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc (78)
I0323 22:48:37.099228  1439 net.cpp:561] ctx_output3/relu_mbox_loc <- ctx_output3_ctx_output3/relu_0_split_0
I0323 22:48:37.099236  1439 net.cpp:530] ctx_output3/relu_mbox_loc -> ctx_output3/relu_mbox_loc
I0323 22:48:37.099925  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_loc
I0323 22:48:37.099951  1439 net.cpp:252] TRAIN Top shape for layer 78 'ctx_output3/relu_mbox_loc' 8 24 5 12 (11520)
I0323 22:48:37.099962  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_perm' of type 'Permute'
I0323 22:48:37.099970  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.099983  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_perm (79)
I0323 22:48:37.099992  1439 net.cpp:561] ctx_output3/relu_mbox_loc_perm <- ctx_output3/relu_mbox_loc
I0323 22:48:37.099998  1439 net.cpp:530] ctx_output3/relu_mbox_loc_perm -> ctx_output3/relu_mbox_loc_perm
I0323 22:48:37.100195  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_perm
I0323 22:48:37.100210  1439 net.cpp:252] TRAIN Top shape for layer 79 'ctx_output3/relu_mbox_loc_perm' 8 5 12 24 (11520)
I0323 22:48:37.100216  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_flat' of type 'Flatten'
I0323 22:48:37.100222  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.100232  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_flat (80)
I0323 22:48:37.100240  1439 net.cpp:561] ctx_output3/relu_mbox_loc_flat <- ctx_output3/relu_mbox_loc_perm
I0323 22:48:37.100247  1439 net.cpp:530] ctx_output3/relu_mbox_loc_flat -> ctx_output3/relu_mbox_loc_flat
I0323 22:48:37.100294  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_flat
I0323 22:48:37.100306  1439 net.cpp:252] TRAIN Top shape for layer 80 'ctx_output3/relu_mbox_loc_flat' 8 1440 (11520)
I0323 22:48:37.100314  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf' of type 'Convolution'
I0323 22:48:37.100322  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.100337  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf (81)
I0323 22:48:37.100345  1439 net.cpp:561] ctx_output3/relu_mbox_conf <- ctx_output3_ctx_output3/relu_0_split_1
I0323 22:48:37.100354  1439 net.cpp:530] ctx_output3/relu_mbox_conf -> ctx_output3/relu_mbox_conf
I0323 22:48:37.101060  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_conf
I0323 22:48:37.101076  1439 net.cpp:252] TRAIN Top shape for layer 81 'ctx_output3/relu_mbox_conf' 8 24 5 12 (11520)
I0323 22:48:37.101086  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_perm' of type 'Permute'
I0323 22:48:37.101094  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.101106  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_perm (82)
I0323 22:48:37.101114  1439 net.cpp:561] ctx_output3/relu_mbox_conf_perm <- ctx_output3/relu_mbox_conf
I0323 22:48:37.101122  1439 net.cpp:530] ctx_output3/relu_mbox_conf_perm -> ctx_output3/relu_mbox_conf_perm
I0323 22:48:37.101320  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_perm
I0323 22:48:37.101335  1439 net.cpp:252] TRAIN Top shape for layer 82 'ctx_output3/relu_mbox_conf_perm' 8 5 12 24 (11520)
I0323 22:48:37.101341  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_flat' of type 'Flatten'
I0323 22:48:37.101347  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.101361  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_flat (83)
I0323 22:48:37.101368  1439 net.cpp:561] ctx_output3/relu_mbox_conf_flat <- ctx_output3/relu_mbox_conf_perm
I0323 22:48:37.101375  1439 net.cpp:530] ctx_output3/relu_mbox_conf_flat -> ctx_output3/relu_mbox_conf_flat
I0323 22:48:37.101421  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_flat
I0323 22:48:37.101434  1439 net.cpp:252] TRAIN Top shape for layer 83 'ctx_output3/relu_mbox_conf_flat' 8 1440 (11520)
I0323 22:48:37.101441  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_priorbox' of type 'PriorBox'
I0323 22:48:37.101449  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.101457  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_priorbox (84)
I0323 22:48:37.101475  1439 net.cpp:561] ctx_output3/relu_mbox_priorbox <- ctx_output3_ctx_output3/relu_0_split_2
I0323 22:48:37.101483  1439 net.cpp:561] ctx_output3/relu_mbox_priorbox <- data_data_0_split_3
I0323 22:48:37.101491  1439 net.cpp:530] ctx_output3/relu_mbox_priorbox -> ctx_output3/relu_mbox_priorbox
I0323 22:48:37.101542  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_priorbox
I0323 22:48:37.101555  1439 net.cpp:252] TRAIN Top shape for layer 84 'ctx_output3/relu_mbox_priorbox' 1 2 1440 (2880)
I0323 22:48:37.101563  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc' of type 'Convolution'
I0323 22:48:37.101570  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.101588  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc (85)
I0323 22:48:37.101596  1439 net.cpp:561] ctx_output4/relu_mbox_loc <- ctx_output4_ctx_output4/relu_0_split_0
I0323 22:48:37.101604  1439 net.cpp:530] ctx_output4/relu_mbox_loc -> ctx_output4/relu_mbox_loc
I0323 22:48:37.102319  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_loc
I0323 22:48:37.102335  1439 net.cpp:252] TRAIN Top shape for layer 85 'ctx_output4/relu_mbox_loc' 8 24 3 6 (3456)
I0323 22:48:37.102346  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_perm' of type 'Permute'
I0323 22:48:37.102352  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.102365  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_perm (86)
I0323 22:48:37.102373  1439 net.cpp:561] ctx_output4/relu_mbox_loc_perm <- ctx_output4/relu_mbox_loc
I0323 22:48:37.102380  1439 net.cpp:530] ctx_output4/relu_mbox_loc_perm -> ctx_output4/relu_mbox_loc_perm
I0323 22:48:37.102578  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_perm
I0323 22:48:37.102593  1439 net.cpp:252] TRAIN Top shape for layer 86 'ctx_output4/relu_mbox_loc_perm' 8 3 6 24 (3456)
I0323 22:48:37.102599  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_flat' of type 'Flatten'
I0323 22:48:37.102607  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.102615  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_flat (87)
I0323 22:48:37.102622  1439 net.cpp:561] ctx_output4/relu_mbox_loc_flat <- ctx_output4/relu_mbox_loc_perm
I0323 22:48:37.102629  1439 net.cpp:530] ctx_output4/relu_mbox_loc_flat -> ctx_output4/relu_mbox_loc_flat
I0323 22:48:37.102674  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_flat
I0323 22:48:37.102686  1439 net.cpp:252] TRAIN Top shape for layer 87 'ctx_output4/relu_mbox_loc_flat' 8 432 (3456)
I0323 22:48:37.102694  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf' of type 'Convolution'
I0323 22:48:37.102699  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.102718  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf (88)
I0323 22:48:37.102726  1439 net.cpp:561] ctx_output4/relu_mbox_conf <- ctx_output4_ctx_output4/relu_0_split_1
I0323 22:48:37.102733  1439 net.cpp:530] ctx_output4/relu_mbox_conf -> ctx_output4/relu_mbox_conf
I0323 22:48:37.103548  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_conf
I0323 22:48:37.103581  1439 net.cpp:252] TRAIN Top shape for layer 88 'ctx_output4/relu_mbox_conf' 8 24 3 6 (3456)
I0323 22:48:37.103595  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_perm' of type 'Permute'
I0323 22:48:37.103602  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.103617  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_perm (89)
I0323 22:48:37.103628  1439 net.cpp:561] ctx_output4/relu_mbox_conf_perm <- ctx_output4/relu_mbox_conf
I0323 22:48:37.103638  1439 net.cpp:530] ctx_output4/relu_mbox_conf_perm -> ctx_output4/relu_mbox_conf_perm
I0323 22:48:37.103843  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_perm
I0323 22:48:37.103870  1439 net.cpp:252] TRAIN Top shape for layer 89 'ctx_output4/relu_mbox_conf_perm' 8 3 6 24 (3456)
I0323 22:48:37.103878  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_flat' of type 'Flatten'
I0323 22:48:37.103884  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.103893  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_flat (90)
I0323 22:48:37.103900  1439 net.cpp:561] ctx_output4/relu_mbox_conf_flat <- ctx_output4/relu_mbox_conf_perm
I0323 22:48:37.103907  1439 net.cpp:530] ctx_output4/relu_mbox_conf_flat -> ctx_output4/relu_mbox_conf_flat
I0323 22:48:37.103955  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_flat
I0323 22:48:37.103968  1439 net.cpp:252] TRAIN Top shape for layer 90 'ctx_output4/relu_mbox_conf_flat' 8 432 (3456)
I0323 22:48:37.103976  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_priorbox' of type 'PriorBox'
I0323 22:48:37.103981  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.103991  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_priorbox (91)
I0323 22:48:37.103997  1439 net.cpp:561] ctx_output4/relu_mbox_priorbox <- ctx_output4_ctx_output4/relu_0_split_2
I0323 22:48:37.104005  1439 net.cpp:561] ctx_output4/relu_mbox_priorbox <- data_data_0_split_4
I0323 22:48:37.104012  1439 net.cpp:530] ctx_output4/relu_mbox_priorbox -> ctx_output4/relu_mbox_priorbox
I0323 22:48:37.104063  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_priorbox
I0323 22:48:37.104077  1439 net.cpp:252] TRAIN Top shape for layer 91 'ctx_output4/relu_mbox_priorbox' 1 2 432 (864)
I0323 22:48:37.104084  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc' of type 'Convolution'
I0323 22:48:37.104090  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.104110  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc (92)
I0323 22:48:37.104117  1439 net.cpp:561] ctx_output5/relu_mbox_loc <- ctx_output5_ctx_output5/relu_0_split_0
I0323 22:48:37.104125  1439 net.cpp:530] ctx_output5/relu_mbox_loc -> ctx_output5/relu_mbox_loc
I0323 22:48:37.104766  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_loc
I0323 22:48:37.104782  1439 net.cpp:252] TRAIN Top shape for layer 92 'ctx_output5/relu_mbox_loc' 8 16 2 3 (768)
I0323 22:48:37.104791  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_perm' of type 'Permute'
I0323 22:48:37.104799  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.104811  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_perm (93)
I0323 22:48:37.104820  1439 net.cpp:561] ctx_output5/relu_mbox_loc_perm <- ctx_output5/relu_mbox_loc
I0323 22:48:37.104826  1439 net.cpp:530] ctx_output5/relu_mbox_loc_perm -> ctx_output5/relu_mbox_loc_perm
I0323 22:48:37.105026  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_perm
I0323 22:48:37.105039  1439 net.cpp:252] TRAIN Top shape for layer 93 'ctx_output5/relu_mbox_loc_perm' 8 2 3 16 (768)
I0323 22:48:37.105046  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_flat' of type 'Flatten'
I0323 22:48:37.105052  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.105062  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_flat (94)
I0323 22:48:37.105067  1439 net.cpp:561] ctx_output5/relu_mbox_loc_flat <- ctx_output5/relu_mbox_loc_perm
I0323 22:48:37.105073  1439 net.cpp:530] ctx_output5/relu_mbox_loc_flat -> ctx_output5/relu_mbox_loc_flat
I0323 22:48:37.105118  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_flat
I0323 22:48:37.105131  1439 net.cpp:252] TRAIN Top shape for layer 94 'ctx_output5/relu_mbox_loc_flat' 8 96 (768)
I0323 22:48:37.105139  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf' of type 'Convolution'
I0323 22:48:37.105146  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.105173  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf (95)
I0323 22:48:37.105182  1439 net.cpp:561] ctx_output5/relu_mbox_conf <- ctx_output5_ctx_output5/relu_0_split_1
I0323 22:48:37.105190  1439 net.cpp:530] ctx_output5/relu_mbox_conf -> ctx_output5/relu_mbox_conf
I0323 22:48:37.105844  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_conf
I0323 22:48:37.105861  1439 net.cpp:252] TRAIN Top shape for layer 95 'ctx_output5/relu_mbox_conf' 8 16 2 3 (768)
I0323 22:48:37.105871  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_perm' of type 'Permute'
I0323 22:48:37.105877  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.105888  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_perm (96)
I0323 22:48:37.105895  1439 net.cpp:561] ctx_output5/relu_mbox_conf_perm <- ctx_output5/relu_mbox_conf
I0323 22:48:37.105902  1439 net.cpp:530] ctx_output5/relu_mbox_conf_perm -> ctx_output5/relu_mbox_conf_perm
I0323 22:48:37.106101  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_perm
I0323 22:48:37.106115  1439 net.cpp:252] TRAIN Top shape for layer 96 'ctx_output5/relu_mbox_conf_perm' 8 2 3 16 (768)
I0323 22:48:37.106122  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_flat' of type 'Flatten'
I0323 22:48:37.106129  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.106139  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_flat (97)
I0323 22:48:37.106146  1439 net.cpp:561] ctx_output5/relu_mbox_conf_flat <- ctx_output5/relu_mbox_conf_perm
I0323 22:48:37.106154  1439 net.cpp:530] ctx_output5/relu_mbox_conf_flat -> ctx_output5/relu_mbox_conf_flat
I0323 22:48:37.106201  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_flat
I0323 22:48:37.106215  1439 net.cpp:252] TRAIN Top shape for layer 97 'ctx_output5/relu_mbox_conf_flat' 8 96 (768)
I0323 22:48:37.106221  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_priorbox' of type 'PriorBox'
I0323 22:48:37.106228  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.106237  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_priorbox (98)
I0323 22:48:37.106245  1439 net.cpp:561] ctx_output5/relu_mbox_priorbox <- ctx_output5_ctx_output5/relu_0_split_2
I0323 22:48:37.106253  1439 net.cpp:561] ctx_output5/relu_mbox_priorbox <- data_data_0_split_5
I0323 22:48:37.106261  1439 net.cpp:530] ctx_output5/relu_mbox_priorbox -> ctx_output5/relu_mbox_priorbox
I0323 22:48:37.106308  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_priorbox
I0323 22:48:37.106323  1439 net.cpp:252] TRAIN Top shape for layer 98 'ctx_output5/relu_mbox_priorbox' 1 2 96 (192)
I0323 22:48:37.106329  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc' of type 'Convolution'
I0323 22:48:37.106336  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.106359  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc (99)
I0323 22:48:37.106367  1439 net.cpp:561] ctx_output6/relu_mbox_loc <- ctx_output6_ctx_output6/relu_0_split_0
I0323 22:48:37.106375  1439 net.cpp:530] ctx_output6/relu_mbox_loc -> ctx_output6/relu_mbox_loc
I0323 22:48:37.107007  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_loc
I0323 22:48:37.107022  1439 net.cpp:252] TRAIN Top shape for layer 99 'ctx_output6/relu_mbox_loc' 8 16 1 2 (256)
I0323 22:48:37.107033  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_perm' of type 'Permute'
I0323 22:48:37.107040  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.107053  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_perm (100)
I0323 22:48:37.107061  1439 net.cpp:561] ctx_output6/relu_mbox_loc_perm <- ctx_output6/relu_mbox_loc
I0323 22:48:37.107069  1439 net.cpp:530] ctx_output6/relu_mbox_loc_perm -> ctx_output6/relu_mbox_loc_perm
I0323 22:48:37.107281  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_perm
I0323 22:48:37.107296  1439 net.cpp:252] TRAIN Top shape for layer 100 'ctx_output6/relu_mbox_loc_perm' 8 1 2 16 (256)
I0323 22:48:37.107302  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_flat' of type 'Flatten'
I0323 22:48:37.107309  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.107317  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_flat (101)
I0323 22:48:37.107326  1439 net.cpp:561] ctx_output6/relu_mbox_loc_flat <- ctx_output6/relu_mbox_loc_perm
I0323 22:48:37.107332  1439 net.cpp:530] ctx_output6/relu_mbox_loc_flat -> ctx_output6/relu_mbox_loc_flat
I0323 22:48:37.107379  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_flat
I0323 22:48:37.107393  1439 net.cpp:252] TRAIN Top shape for layer 101 'ctx_output6/relu_mbox_loc_flat' 8 32 (256)
I0323 22:48:37.107400  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf' of type 'Convolution'
I0323 22:48:37.107408  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.107424  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf (102)
I0323 22:48:37.107432  1439 net.cpp:561] ctx_output6/relu_mbox_conf <- ctx_output6_ctx_output6/relu_0_split_1
I0323 22:48:37.107440  1439 net.cpp:530] ctx_output6/relu_mbox_conf -> ctx_output6/relu_mbox_conf
I0323 22:48:37.108079  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_conf
I0323 22:48:37.108096  1439 net.cpp:252] TRAIN Top shape for layer 102 'ctx_output6/relu_mbox_conf' 8 16 1 2 (256)
I0323 22:48:37.108106  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_perm' of type 'Permute'
I0323 22:48:37.108112  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.108124  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_perm (103)
I0323 22:48:37.108131  1439 net.cpp:561] ctx_output6/relu_mbox_conf_perm <- ctx_output6/relu_mbox_conf
I0323 22:48:37.108139  1439 net.cpp:530] ctx_output6/relu_mbox_conf_perm -> ctx_output6/relu_mbox_conf_perm
I0323 22:48:37.108336  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_perm
I0323 22:48:37.108351  1439 net.cpp:252] TRAIN Top shape for layer 103 'ctx_output6/relu_mbox_conf_perm' 8 1 2 16 (256)
I0323 22:48:37.108357  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_flat' of type 'Flatten'
I0323 22:48:37.108363  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.108371  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_flat (104)
I0323 22:48:37.108376  1439 net.cpp:561] ctx_output6/relu_mbox_conf_flat <- ctx_output6/relu_mbox_conf_perm
I0323 22:48:37.108382  1439 net.cpp:530] ctx_output6/relu_mbox_conf_flat -> ctx_output6/relu_mbox_conf_flat
I0323 22:48:37.108428  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_flat
I0323 22:48:37.108440  1439 net.cpp:252] TRAIN Top shape for layer 104 'ctx_output6/relu_mbox_conf_flat' 8 32 (256)
I0323 22:48:37.108446  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_priorbox' of type 'PriorBox'
I0323 22:48:37.108453  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.108460  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_priorbox (105)
I0323 22:48:37.108466  1439 net.cpp:561] ctx_output6/relu_mbox_priorbox <- ctx_output6_ctx_output6/relu_0_split_2
I0323 22:48:37.108474  1439 net.cpp:561] ctx_output6/relu_mbox_priorbox <- data_data_0_split_6
I0323 22:48:37.108479  1439 net.cpp:530] ctx_output6/relu_mbox_priorbox -> ctx_output6/relu_mbox_priorbox
I0323 22:48:37.108526  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_priorbox
I0323 22:48:37.108539  1439 net.cpp:252] TRAIN Top shape for layer 105 'ctx_output6/relu_mbox_priorbox' 1 2 32 (64)
I0323 22:48:37.108546  1439 layer_factory.hpp:136] Creating layer 'mbox_loc' of type 'Concat'
I0323 22:48:37.108561  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.108574  1439 net.cpp:184] Created Layer mbox_loc (106)
I0323 22:48:37.108582  1439 net.cpp:561] mbox_loc <- ctx_output1/relu_mbox_loc_flat
I0323 22:48:37.108592  1439 net.cpp:561] mbox_loc <- ctx_output2/relu_mbox_loc_flat
I0323 22:48:37.108602  1439 net.cpp:561] mbox_loc <- ctx_output3/relu_mbox_loc_flat
I0323 22:48:37.108608  1439 net.cpp:561] mbox_loc <- ctx_output4/relu_mbox_loc_flat
I0323 22:48:37.108616  1439 net.cpp:561] mbox_loc <- ctx_output5/relu_mbox_loc_flat
I0323 22:48:37.108624  1439 net.cpp:561] mbox_loc <- ctx_output6/relu_mbox_loc_flat
I0323 22:48:37.108631  1439 net.cpp:530] mbox_loc -> mbox_loc
I0323 22:48:37.108680  1439 net.cpp:245] Setting up mbox_loc
I0323 22:48:37.108693  1439 net.cpp:252] TRAIN Top shape for layer 106 'mbox_loc' 8 69200 (553600)
I0323 22:48:37.108700  1439 layer_factory.hpp:136] Creating layer 'mbox_conf' of type 'Concat'
I0323 22:48:37.108705  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.108713  1439 net.cpp:184] Created Layer mbox_conf (107)
I0323 22:48:37.108719  1439 net.cpp:561] mbox_conf <- ctx_output1/relu_mbox_conf_flat
I0323 22:48:37.108726  1439 net.cpp:561] mbox_conf <- ctx_output2/relu_mbox_conf_flat
I0323 22:48:37.108736  1439 net.cpp:561] mbox_conf <- ctx_output3/relu_mbox_conf_flat
I0323 22:48:37.108743  1439 net.cpp:561] mbox_conf <- ctx_output4/relu_mbox_conf_flat
I0323 22:48:37.108749  1439 net.cpp:561] mbox_conf <- ctx_output5/relu_mbox_conf_flat
I0323 22:48:37.108755  1439 net.cpp:561] mbox_conf <- ctx_output6/relu_mbox_conf_flat
I0323 22:48:37.108762  1439 net.cpp:530] mbox_conf -> mbox_conf
I0323 22:48:37.108808  1439 net.cpp:245] Setting up mbox_conf
I0323 22:48:37.108822  1439 net.cpp:252] TRAIN Top shape for layer 107 'mbox_conf' 8 69200 (553600)
I0323 22:48:37.108830  1439 layer_factory.hpp:136] Creating layer 'mbox_priorbox' of type 'Concat'
I0323 22:48:37.108836  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.108845  1439 net.cpp:184] Created Layer mbox_priorbox (108)
I0323 22:48:37.108852  1439 net.cpp:561] mbox_priorbox <- ctx_output1/relu_mbox_priorbox
I0323 22:48:37.108860  1439 net.cpp:561] mbox_priorbox <- ctx_output2/relu_mbox_priorbox
I0323 22:48:37.108868  1439 net.cpp:561] mbox_priorbox <- ctx_output3/relu_mbox_priorbox
I0323 22:48:37.108875  1439 net.cpp:561] mbox_priorbox <- ctx_output4/relu_mbox_priorbox
I0323 22:48:37.108882  1439 net.cpp:561] mbox_priorbox <- ctx_output5/relu_mbox_priorbox
I0323 22:48:37.108889  1439 net.cpp:561] mbox_priorbox <- ctx_output6/relu_mbox_priorbox
I0323 22:48:37.108896  1439 net.cpp:530] mbox_priorbox -> mbox_priorbox
I0323 22:48:37.108942  1439 net.cpp:245] Setting up mbox_priorbox
I0323 22:48:37.108954  1439 net.cpp:252] TRAIN Top shape for layer 108 'mbox_priorbox' 1 2 69200 (138400)
I0323 22:48:37.108963  1439 layer_factory.hpp:136] Creating layer 'mbox_loss' of type 'MultiBoxLoss'
I0323 22:48:37.108969  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.108986  1439 net.cpp:184] Created Layer mbox_loss (109)
I0323 22:48:37.108994  1439 net.cpp:561] mbox_loss <- mbox_loc
I0323 22:48:37.109001  1439 net.cpp:561] mbox_loss <- mbox_conf
I0323 22:48:37.109009  1439 net.cpp:561] mbox_loss <- mbox_priorbox
I0323 22:48:37.109015  1439 net.cpp:561] mbox_loss <- label
I0323 22:48:37.109024  1439 net.cpp:530] mbox_loss -> mbox_loss
I0323 22:48:37.109128  1439 layer_factory.hpp:136] Creating layer 'mbox_loss_smooth_L1_loc' of type 'SmoothL1Loss'
I0323 22:48:37.109140  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.109351  1439 layer_factory.hpp:136] Creating layer 'mbox_loss_softmax_conf' of type 'SoftmaxWithLoss'
I0323 22:48:37.109365  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.109648  1439 net.cpp:245] Setting up mbox_loss
I0323 22:48:37.109673  1439 net.cpp:252] TRAIN Top shape for layer 109 'mbox_loss' (1)
I0323 22:48:37.109680  1439 net.cpp:256]     with loss weight 1
I0323 22:48:37.109702  1439 net.cpp:323] mbox_loss needs backward computation.
I0323 22:48:37.109710  1439 net.cpp:325] mbox_priorbox does not need backward computation.
I0323 22:48:37.109719  1439 net.cpp:323] mbox_conf needs backward computation.
I0323 22:48:37.109726  1439 net.cpp:323] mbox_loc needs backward computation.
I0323 22:48:37.109733  1439 net.cpp:325] ctx_output6/relu_mbox_priorbox does not need backward computation.
I0323 22:48:37.109740  1439 net.cpp:323] ctx_output6/relu_mbox_conf_flat needs backward computation.
I0323 22:48:37.109750  1439 net.cpp:323] ctx_output6/relu_mbox_conf_perm needs backward computation.
I0323 22:48:37.109756  1439 net.cpp:323] ctx_output6/relu_mbox_conf needs backward computation.
I0323 22:48:37.109762  1439 net.cpp:323] ctx_output6/relu_mbox_loc_flat needs backward computation.
I0323 22:48:37.109768  1439 net.cpp:323] ctx_output6/relu_mbox_loc_perm needs backward computation.
I0323 22:48:37.109776  1439 net.cpp:323] ctx_output6/relu_mbox_loc needs backward computation.
I0323 22:48:37.109781  1439 net.cpp:325] ctx_output5/relu_mbox_priorbox does not need backward computation.
I0323 22:48:37.109788  1439 net.cpp:323] ctx_output5/relu_mbox_conf_flat needs backward computation.
I0323 22:48:37.109794  1439 net.cpp:323] ctx_output5/relu_mbox_conf_perm needs backward computation.
I0323 22:48:37.109800  1439 net.cpp:323] ctx_output5/relu_mbox_conf needs backward computation.
I0323 22:48:37.109807  1439 net.cpp:323] ctx_output5/relu_mbox_loc_flat needs backward computation.
I0323 22:48:37.109812  1439 net.cpp:323] ctx_output5/relu_mbox_loc_perm needs backward computation.
I0323 22:48:37.109818  1439 net.cpp:323] ctx_output5/relu_mbox_loc needs backward computation.
I0323 22:48:37.109824  1439 net.cpp:325] ctx_output4/relu_mbox_priorbox does not need backward computation.
I0323 22:48:37.109832  1439 net.cpp:323] ctx_output4/relu_mbox_conf_flat needs backward computation.
I0323 22:48:37.109838  1439 net.cpp:323] ctx_output4/relu_mbox_conf_perm needs backward computation.
I0323 22:48:37.109843  1439 net.cpp:323] ctx_output4/relu_mbox_conf needs backward computation.
I0323 22:48:37.109849  1439 net.cpp:323] ctx_output4/relu_mbox_loc_flat needs backward computation.
I0323 22:48:37.109855  1439 net.cpp:323] ctx_output4/relu_mbox_loc_perm needs backward computation.
I0323 22:48:37.109863  1439 net.cpp:323] ctx_output4/relu_mbox_loc needs backward computation.
I0323 22:48:37.109869  1439 net.cpp:325] ctx_output3/relu_mbox_priorbox does not need backward computation.
I0323 22:48:37.109875  1439 net.cpp:323] ctx_output3/relu_mbox_conf_flat needs backward computation.
I0323 22:48:37.109881  1439 net.cpp:323] ctx_output3/relu_mbox_conf_perm needs backward computation.
I0323 22:48:37.109887  1439 net.cpp:323] ctx_output3/relu_mbox_conf needs backward computation.
I0323 22:48:37.109894  1439 net.cpp:323] ctx_output3/relu_mbox_loc_flat needs backward computation.
I0323 22:48:37.109900  1439 net.cpp:323] ctx_output3/relu_mbox_loc_perm needs backward computation.
I0323 22:48:37.109906  1439 net.cpp:323] ctx_output3/relu_mbox_loc needs backward computation.
I0323 22:48:37.109912  1439 net.cpp:325] ctx_output2/relu_mbox_priorbox does not need backward computation.
I0323 22:48:37.109920  1439 net.cpp:323] ctx_output2/relu_mbox_conf_flat needs backward computation.
I0323 22:48:37.109926  1439 net.cpp:323] ctx_output2/relu_mbox_conf_perm needs backward computation.
I0323 22:48:37.109932  1439 net.cpp:323] ctx_output2/relu_mbox_conf needs backward computation.
I0323 22:48:37.109938  1439 net.cpp:323] ctx_output2/relu_mbox_loc_flat needs backward computation.
I0323 22:48:37.109944  1439 net.cpp:323] ctx_output2/relu_mbox_loc_perm needs backward computation.
I0323 22:48:37.109951  1439 net.cpp:323] ctx_output2/relu_mbox_loc needs backward computation.
I0323 22:48:37.109957  1439 net.cpp:325] ctx_output1/relu_mbox_priorbox does not need backward computation.
I0323 22:48:37.109972  1439 net.cpp:323] ctx_output1/relu_mbox_conf_flat needs backward computation.
I0323 22:48:37.109982  1439 net.cpp:323] ctx_output1/relu_mbox_conf_perm needs backward computation.
I0323 22:48:37.109988  1439 net.cpp:323] ctx_output1/relu_mbox_conf needs backward computation.
I0323 22:48:37.109994  1439 net.cpp:323] ctx_output1/relu_mbox_loc_flat needs backward computation.
I0323 22:48:37.110000  1439 net.cpp:323] ctx_output1/relu_mbox_loc_perm needs backward computation.
I0323 22:48:37.110008  1439 net.cpp:323] ctx_output1/relu_mbox_loc needs backward computation.
I0323 22:48:37.110013  1439 net.cpp:323] ctx_output6_ctx_output6/relu_0_split needs backward computation.
I0323 22:48:37.110020  1439 net.cpp:323] ctx_output6/relu needs backward computation.
I0323 22:48:37.110026  1439 net.cpp:323] ctx_output6 needs backward computation.
I0323 22:48:37.110033  1439 net.cpp:323] ctx_output5_ctx_output5/relu_0_split needs backward computation.
I0323 22:48:37.110038  1439 net.cpp:323] ctx_output5/relu needs backward computation.
I0323 22:48:37.110044  1439 net.cpp:323] ctx_output5 needs backward computation.
I0323 22:48:37.110051  1439 net.cpp:323] ctx_output4_ctx_output4/relu_0_split needs backward computation.
I0323 22:48:37.110057  1439 net.cpp:323] ctx_output4/relu needs backward computation.
I0323 22:48:37.110064  1439 net.cpp:323] ctx_output4 needs backward computation.
I0323 22:48:37.110069  1439 net.cpp:323] ctx_output3_ctx_output3/relu_0_split needs backward computation.
I0323 22:48:37.110076  1439 net.cpp:323] ctx_output3/relu needs backward computation.
I0323 22:48:37.110082  1439 net.cpp:323] ctx_output3 needs backward computation.
I0323 22:48:37.110088  1439 net.cpp:323] ctx_output2_ctx_output2/relu_0_split needs backward computation.
I0323 22:48:37.110095  1439 net.cpp:323] ctx_output2/relu needs backward computation.
I0323 22:48:37.110100  1439 net.cpp:323] ctx_output2 needs backward computation.
I0323 22:48:37.110106  1439 net.cpp:323] ctx_output1_ctx_output1/relu_0_split needs backward computation.
I0323 22:48:37.110112  1439 net.cpp:323] ctx_output1/relu needs backward computation.
I0323 22:48:37.110118  1439 net.cpp:323] ctx_output1 needs backward computation.
I0323 22:48:37.110126  1439 net.cpp:323] pool9 needs backward computation.
I0323 22:48:37.110131  1439 net.cpp:323] pool8_pool8_0_split needs backward computation.
I0323 22:48:37.110137  1439 net.cpp:323] pool8 needs backward computation.
I0323 22:48:37.110144  1439 net.cpp:323] pool7_pool7_0_split needs backward computation.
I0323 22:48:37.110150  1439 net.cpp:323] pool7 needs backward computation.
I0323 22:48:37.110157  1439 net.cpp:323] pool6_pool6_0_split needs backward computation.
I0323 22:48:37.110162  1439 net.cpp:323] pool6 needs backward computation.
I0323 22:48:37.110169  1439 net.cpp:323] res5a_branch2b_res5a_branch2b/relu_0_split needs backward computation.
I0323 22:48:37.110175  1439 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0323 22:48:37.110182  1439 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0323 22:48:37.110188  1439 net.cpp:323] res5a_branch2b needs backward computation.
I0323 22:48:37.110193  1439 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0323 22:48:37.110199  1439 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0323 22:48:37.110205  1439 net.cpp:323] res5a_branch2a needs backward computation.
I0323 22:48:37.110211  1439 net.cpp:323] pool4 needs backward computation.
I0323 22:48:37.110218  1439 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0323 22:48:37.110224  1439 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0323 22:48:37.110229  1439 net.cpp:323] res4a_branch2b needs backward computation.
I0323 22:48:37.110236  1439 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0323 22:48:37.110242  1439 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0323 22:48:37.110249  1439 net.cpp:323] res4a_branch2a needs backward computation.
I0323 22:48:37.110255  1439 net.cpp:323] pool3 needs backward computation.
I0323 22:48:37.110267  1439 net.cpp:323] res3a_branch2b_res3a_branch2b/relu_0_split needs backward computation.
I0323 22:48:37.110275  1439 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0323 22:48:37.110280  1439 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0323 22:48:37.110286  1439 net.cpp:323] res3a_branch2b needs backward computation.
I0323 22:48:37.110292  1439 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0323 22:48:37.110298  1439 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0323 22:48:37.110304  1439 net.cpp:323] res3a_branch2a needs backward computation.
I0323 22:48:37.110311  1439 net.cpp:323] pool2 needs backward computation.
I0323 22:48:37.110316  1439 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0323 22:48:37.110322  1439 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0323 22:48:37.110328  1439 net.cpp:323] res2a_branch2b needs backward computation.
I0323 22:48:37.110334  1439 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0323 22:48:37.110340  1439 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0323 22:48:37.110347  1439 net.cpp:323] res2a_branch2a needs backward computation.
I0323 22:48:37.110352  1439 net.cpp:323] pool1 needs backward computation.
I0323 22:48:37.110358  1439 net.cpp:323] conv1b/relu needs backward computation.
I0323 22:48:37.110364  1439 net.cpp:323] conv1b/bn needs backward computation.
I0323 22:48:37.110370  1439 net.cpp:323] conv1b needs backward computation.
I0323 22:48:37.110376  1439 net.cpp:323] conv1a/relu needs backward computation.
I0323 22:48:37.110383  1439 net.cpp:323] conv1a/bn needs backward computation.
I0323 22:48:37.110388  1439 net.cpp:323] conv1a needs backward computation.
I0323 22:48:37.110394  1439 net.cpp:325] data/bias does not need backward computation.
I0323 22:48:37.110402  1439 net.cpp:325] data_data_0_split does not need backward computation.
I0323 22:48:37.110409  1439 net.cpp:325] data does not need backward computation.
I0323 22:48:37.110414  1439 net.cpp:367] This network produces output mbox_loss
I0323 22:48:37.110522  1439 net.cpp:389] Top memory (TRAIN) required for data: 1206154824 diff: 1206154824
I0323 22:48:37.110532  1439 net.cpp:392] Bottom memory (TRAIN) required for data: 1206154816 diff: 1206154816
I0323 22:48:37.110539  1439 net.cpp:395] Shared (in-place) memory (TRAIN) by data: 521715712 diff: 521715712
I0323 22:48:37.110544  1439 net.cpp:398] Parameters memory (TRAIN) required for data: 12464288 diff: 12464288
I0323 22:48:37.110550  1439 net.cpp:401] Parameters shared memory (TRAIN) by data: 0 diff: 0
I0323 22:48:37.110556  1439 net.cpp:407] Network initialization done.
I0323 22:48:37.112663  1439 solver.cpp:177] Creating test net (#0) specified by test_net file: training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/test.prototxt
I0323 22:48:37.113517  1439 net.cpp:72] Initializing net from parameters: 
name: "ssdJacintoNetV2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_value: 0
    mean_value: 0
    mean_value: 0
    force_color: false
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 320
      width: 768
      interp_mode: LINEAR
    }
    crop_h: 320
    crop_w: 768
  }
  data_param {
    source: "/user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_test_lmdb"
    batch_size: 4
    backend: LMDB
    threads: 4
    parser_threads: 4
  }
  annotated_data_param {
    batch_sampler {
    }
    label_map_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/labelmap.prototxt"
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "pool6"
  top: "pool7"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool8"
  type: "Pooling"
  bottom: "pool7"
  top: "pool8"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool9"
  type: "Pooling"
  bottom: "pool8"
  top: "pool9"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "ctx_output1"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "ctx_output1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu"
  type: "ReLU"
  bottom: "ctx_output1"
  top: "ctx_output1"
}
layer {
  name: "ctx_output2"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "ctx_output2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu"
  type: "ReLU"
  bottom: "ctx_output2"
  top: "ctx_output2"
}
layer {
  name: "ctx_output3"
  type: "Convolution"
  bottom: "pool6"
  top: "ctx_output3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu"
  type: "ReLU"
  bottom: "ctx_output3"
  top: "ctx_output3"
}
layer {
  name: "ctx_output4"
  type: "Convolution"
  bottom: "pool7"
  top: "ctx_output4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu"
  type: "ReLU"
  bottom: "ctx_output4"
  top: "ctx_output4"
}
layer {
  name: "ctx_output5"
  type: "Convolution"
  bottom: "pool8"
  top: "ctx_output5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu"
  type: "ReLU"
  bottom: "ctx_output5"
  top: "ctx_output5"
}
layer {
  name: "ctx_output6"
  type: "Convolution"
  bottom: "pool9"
  top: "ctx_output6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu"
  type: "ReLU"
  bottom: "ctx_output6"
  top: "ctx_output6"
}
layer {
  name: "ctx_output1/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_loc"
  top: "ctx_output1/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_loc_perm"
  top: "ctx_output1/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_conf"
  top: "ctx_output1/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_conf_perm"
  top: "ctx_output1/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output1"
  bottom: "data"
  top: "ctx_output1/relu_mbox_priorbox"
  prior_box_param {
    min_size: 12.8
    max_size: 32
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_loc"
  top: "ctx_output2/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_loc_perm"
  top: "ctx_output2/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_conf"
  top: "ctx_output2/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_conf_perm"
  top: "ctx_output2/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output2"
  bottom: "data"
  top: "ctx_output2/relu_mbox_priorbox"
  prior_box_param {
    min_size: 32
    max_size: 96
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_loc"
  top: "ctx_output3/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_loc_perm"
  top: "ctx_output3/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_conf"
  top: "ctx_output3/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_conf_perm"
  top: "ctx_output3/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output3"
  bottom: "data"
  top: "ctx_output3/relu_mbox_priorbox"
  prior_box_param {
    min_size: 96
    max_size: 160
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_loc"
  top: "ctx_output4/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_loc_perm"
  top: "ctx_output4/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_conf"
  top: "ctx_output4/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_conf_perm"
  top: "ctx_output4/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output4"
  bottom: "data"
  top: "ctx_output4/relu_mbox_priorbox"
  prior_box_param {
    min_size: 160
    max_size: 224
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_loc"
  top: "ctx_output5/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_loc_perm"
  top: "ctx_output5/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_conf"
  top: "ctx_output5/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_conf_perm"
  top: "ctx_output5/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output5"
  bottom: "data"
  top: "ctx_output5/relu_mbox_priorbox"
  prior_box_param {
    min_size: 224
    max_size: 288
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_loc"
  top: "ctx_output6/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_loc_perm"
  top: "ctx_output6/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_conf"
  top: "ctx_output6/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_conf_perm"
  top: "ctx_output6/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output6"
  bottom: "data"
  top: "ctx_output6/relu_mbox_priorbox"
  prior_box_param {
    min_size: 288
    max_size: 352
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_loc_flat"
  bottom: "ctx_output2/relu_mbox_loc_flat"
  bottom: "ctx_output3/relu_mbox_loc_flat"
  bottom: "ctx_output4/relu_mbox_loc_flat"
  bottom: "ctx_output5/relu_mbox_loc_flat"
  bottom: "ctx_output6/relu_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_conf_flat"
  bottom: "ctx_output2/relu_mbox_conf_flat"
  bottom: "ctx_output3/relu_mbox_conf_flat"
  bottom: "ctx_output4/relu_mbox_conf_flat"
  bottom: "ctx_output5/relu_mbox_conf_flat"
  bottom: "ctx_output6/relu_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_priorbox"
  bottom: "ctx_output2/relu_mbox_priorbox"
  bottom: "ctx_output3/relu_mbox_priorbox"
  bottom: "ctx_output4/relu_mbox_priorbox"
  bottom: "ctx_output5/relu_mbox_priorbox"
  bottom: "ctx_output6/relu_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_reshape"
  type: "Reshape"
  bottom: "mbox_conf"
  top: "mbox_conf_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: -1
      dim: 4
    }
  }
}
layer {
  name: "mbox_conf_softmax"
  type: "Softmax"
  bottom: "mbox_conf_reshape"
  top: "mbox_conf_softmax"
  softmax_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_flatten"
  type: "Flatten"
  bottom: "mbox_conf_softmax"
  top: "mbox_conf_flatten"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "detection_out"
  type: "DetectionOutput"
  bottom: "mbox_loc"
  bottom: "mbox_conf_flatten"
  bottom: "mbox_priorbox"
  top: "detection_out"
  include {
    phase: TEST
  }
  detection_output_param {
    num_classes: 4
    share_location: true
    background_label_id: 0
    nms_param {
      nms_threshold: 0.45
      top_k: 400
    }
    save_output_param {
      output_directory: ""
      output_name_prefix: "comp4_det_test_"
      output_format: "VOC"
      label_map_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/labelmap.prototxt"
      name_size_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/test_name_size.txt"
      num_test_image: 3609
    }
    code_type: CENTER_SIZE
    keep_top_k: 200
    confidence_threshold: 0.01
  }
}
layer {
  name: "detection_eval"
  type: "DetectionEvaluate"
  bottom: "detection_out"
  bottom: "label"
  top: "detection_eval"
  include {
    phase: TEST
  }
  detection_evaluate_param {
    num_classes: 4
    background_label_id: 0
    overlap_threshold: 0.5
    evaluate_difficult_gt: true
    name_size_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/test_name_size.txt"
  }
}
I0323 22:48:37.114012  1439 net.cpp:104] Using FLOAT as default forward math type
I0323 22:48:37.114024  1439 net.cpp:110] Using FLOAT as default backward math type
I0323 22:48:37.114029  1439 layer_factory.hpp:136] Creating layer 'data' of type 'AnnotatedData'
I0323 22:48:37.114038  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.114060  1439 net.cpp:184] Created Layer data (0)
I0323 22:48:37.114068  1439 net.cpp:530] data -> data
I0323 22:48:37.114074  1439 net.cpp:530] data -> label
I0323 22:48:37.114090  1439 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 4
I0323 22:48:37.114102  1439 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0323 22:48:37.114799  1484 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_test_lmdb
I0323 22:48:37.125500  1439 annotated_data_layer.cpp:219] output data size: 4,3,320,768
I0323 22:48:37.125593  1439 annotated_data_layer.cpp:265] (0) Output data size: 4, 3, 320, 768
I0323 22:48:37.125661  1439 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0323 22:48:37.125720  1439 net.cpp:245] Setting up data
I0323 22:48:37.125737  1439 net.cpp:252] TEST Top shape for layer 0 'data' 4 3 320 768 (2949120)
I0323 22:48:37.125761  1439 net.cpp:252] TEST Top shape for layer 0 'data' 1 1 31 8 (248)
I0323 22:48:37.125771  1439 layer_factory.hpp:136] Creating layer 'data_data_0_split' of type 'Split'
I0323 22:48:37.125779  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.125794  1439 net.cpp:184] Created Layer data_data_0_split (1)
I0323 22:48:37.125803  1439 net.cpp:561] data_data_0_split <- data
I0323 22:48:37.125813  1439 net.cpp:530] data_data_0_split -> data_data_0_split_0
I0323 22:48:37.125824  1439 net.cpp:530] data_data_0_split -> data_data_0_split_1
I0323 22:48:37.125833  1439 net.cpp:530] data_data_0_split -> data_data_0_split_2
I0323 22:48:37.125841  1439 net.cpp:530] data_data_0_split -> data_data_0_split_3
I0323 22:48:37.125849  1439 net.cpp:530] data_data_0_split -> data_data_0_split_4
I0323 22:48:37.125855  1439 net.cpp:530] data_data_0_split -> data_data_0_split_5
I0323 22:48:37.125862  1439 net.cpp:530] data_data_0_split -> data_data_0_split_6
I0323 22:48:37.126067  1439 net.cpp:245] Setting up data_data_0_split
I0323 22:48:37.126082  1439 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 320 768 (2949120)
I0323 22:48:37.126092  1439 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 320 768 (2949120)
I0323 22:48:37.126101  1439 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 320 768 (2949120)
I0323 22:48:37.126107  1439 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 320 768 (2949120)
I0323 22:48:37.126116  1439 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 320 768 (2949120)
I0323 22:48:37.126123  1439 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 320 768 (2949120)
I0323 22:48:37.126132  1439 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 320 768 (2949120)
I0323 22:48:37.126139  1439 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0323 22:48:37.126147  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.126160  1439 net.cpp:184] Created Layer data/bias (2)
I0323 22:48:37.126168  1439 net.cpp:561] data/bias <- data_data_0_split_0
I0323 22:48:37.126176  1439 net.cpp:530] data/bias -> data/bias
I0323 22:48:37.127470  1485 annotated_data_layer.cpp:111] (0) Parser threads: 1
I0323 22:48:37.127492  1485 annotated_data_layer.cpp:113] (0) Transformer threads: 1
I0323 22:48:37.127879  1439 net.cpp:245] Setting up data/bias
I0323 22:48:37.127900  1439 net.cpp:252] TEST Top shape for layer 2 'data/bias' 4 3 320 768 (2949120)
I0323 22:48:37.127915  1439 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0323 22:48:37.127924  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.127944  1439 net.cpp:184] Created Layer conv1a (3)
I0323 22:48:37.127952  1439 net.cpp:561] conv1a <- data/bias
I0323 22:48:37.127961  1439 net.cpp:530] conv1a -> conv1a
I0323 22:48:37.128628  1439 net.cpp:245] Setting up conv1a
I0323 22:48:37.128644  1439 net.cpp:252] TEST Top shape for layer 3 'conv1a' 4 32 160 384 (7864320)
I0323 22:48:37.128659  1439 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0323 22:48:37.128667  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.128682  1439 net.cpp:184] Created Layer conv1a/bn (4)
I0323 22:48:37.128690  1439 net.cpp:561] conv1a/bn <- conv1a
I0323 22:48:37.128697  1439 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0323 22:48:37.129917  1439 net.cpp:245] Setting up conv1a/bn
I0323 22:48:37.129935  1439 net.cpp:252] TEST Top shape for layer 4 'conv1a/bn' 4 32 160 384 (7864320)
I0323 22:48:37.129952  1439 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0323 22:48:37.129961  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.129971  1439 net.cpp:184] Created Layer conv1a/relu (5)
I0323 22:48:37.129977  1439 net.cpp:561] conv1a/relu <- conv1a
I0323 22:48:37.129998  1439 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0323 22:48:37.130010  1439 net.cpp:245] Setting up conv1a/relu
I0323 22:48:37.130018  1439 net.cpp:252] TEST Top shape for layer 5 'conv1a/relu' 4 32 160 384 (7864320)
I0323 22:48:37.130025  1439 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0323 22:48:37.130033  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.130048  1439 net.cpp:184] Created Layer conv1b (6)
I0323 22:48:37.130054  1439 net.cpp:561] conv1b <- conv1a
I0323 22:48:37.130061  1439 net.cpp:530] conv1b -> conv1b
I0323 22:48:37.130632  1439 net.cpp:245] Setting up conv1b
I0323 22:48:37.130648  1439 net.cpp:252] TEST Top shape for layer 6 'conv1b' 4 32 160 384 (7864320)
I0323 22:48:37.130661  1439 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0323 22:48:37.130668  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.130679  1439 net.cpp:184] Created Layer conv1b/bn (7)
I0323 22:48:37.130686  1439 net.cpp:561] conv1b/bn <- conv1b
I0323 22:48:37.130694  1439 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0323 22:48:37.131654  1439 net.cpp:245] Setting up conv1b/bn
I0323 22:48:37.131670  1439 net.cpp:252] TEST Top shape for layer 7 'conv1b/bn' 4 32 160 384 (7864320)
I0323 22:48:37.131685  1439 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0323 22:48:37.131692  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.131702  1439 net.cpp:184] Created Layer conv1b/relu (8)
I0323 22:48:37.131709  1439 net.cpp:561] conv1b/relu <- conv1b
I0323 22:48:37.131716  1439 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0323 22:48:37.131726  1439 net.cpp:245] Setting up conv1b/relu
I0323 22:48:37.131733  1439 net.cpp:252] TEST Top shape for layer 8 'conv1b/relu' 4 32 160 384 (7864320)
I0323 22:48:37.131741  1439 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0323 22:48:37.131747  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.131757  1439 net.cpp:184] Created Layer pool1 (9)
I0323 22:48:37.131764  1439 net.cpp:561] pool1 <- conv1b
I0323 22:48:37.131772  1439 net.cpp:530] pool1 -> pool1
I0323 22:48:37.131870  1439 net.cpp:245] Setting up pool1
I0323 22:48:37.131884  1439 net.cpp:252] TEST Top shape for layer 9 'pool1' 4 32 80 192 (1966080)
I0323 22:48:37.131891  1439 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0323 22:48:37.131898  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.131913  1439 net.cpp:184] Created Layer res2a_branch2a (10)
I0323 22:48:37.131920  1439 net.cpp:561] res2a_branch2a <- pool1
I0323 22:48:37.131927  1439 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0323 22:48:37.132988  1439 net.cpp:245] Setting up res2a_branch2a
I0323 22:48:37.133004  1439 net.cpp:252] TEST Top shape for layer 10 'res2a_branch2a' 4 64 80 192 (3932160)
I0323 22:48:37.133018  1439 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0323 22:48:37.133025  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.133036  1439 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0323 22:48:37.133044  1439 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0323 22:48:37.133051  1439 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0323 22:48:37.134023  1439 net.cpp:245] Setting up res2a_branch2a/bn
I0323 22:48:37.134039  1439 net.cpp:252] TEST Top shape for layer 11 'res2a_branch2a/bn' 4 64 80 192 (3932160)
I0323 22:48:37.134054  1439 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0323 22:48:37.134063  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.134070  1439 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0323 22:48:37.134076  1439 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0323 22:48:37.134094  1439 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0323 22:48:37.134105  1439 net.cpp:245] Setting up res2a_branch2a/relu
I0323 22:48:37.134114  1439 net.cpp:252] TEST Top shape for layer 12 'res2a_branch2a/relu' 4 64 80 192 (3932160)
I0323 22:48:37.134120  1439 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0323 22:48:37.134127  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.134141  1439 net.cpp:184] Created Layer res2a_branch2b (13)
I0323 22:48:37.134150  1439 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0323 22:48:37.134156  1439 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0323 22:48:37.134959  1439 net.cpp:245] Setting up res2a_branch2b
I0323 22:48:37.134985  1439 net.cpp:252] TEST Top shape for layer 13 'res2a_branch2b' 4 64 80 192 (3932160)
I0323 22:48:37.134997  1439 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0323 22:48:37.135006  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.135021  1439 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0323 22:48:37.135030  1439 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0323 22:48:37.135037  1439 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0323 22:48:37.136027  1439 net.cpp:245] Setting up res2a_branch2b/bn
I0323 22:48:37.136044  1439 net.cpp:252] TEST Top shape for layer 14 'res2a_branch2b/bn' 4 64 80 192 (3932160)
I0323 22:48:37.136059  1439 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0323 22:48:37.136066  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.136075  1439 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0323 22:48:37.136082  1439 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0323 22:48:37.136090  1439 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0323 22:48:37.136101  1439 net.cpp:245] Setting up res2a_branch2b/relu
I0323 22:48:37.136107  1439 net.cpp:252] TEST Top shape for layer 15 'res2a_branch2b/relu' 4 64 80 192 (3932160)
I0323 22:48:37.136114  1439 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0323 22:48:37.136121  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.136133  1439 net.cpp:184] Created Layer pool2 (16)
I0323 22:48:37.136140  1439 net.cpp:561] pool2 <- res2a_branch2b
I0323 22:48:37.136147  1439 net.cpp:530] pool2 -> pool2
I0323 22:48:37.136247  1439 net.cpp:245] Setting up pool2
I0323 22:48:37.136260  1439 net.cpp:252] TEST Top shape for layer 16 'pool2' 4 64 40 96 (983040)
I0323 22:48:37.136267  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0323 22:48:37.136276  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.136291  1439 net.cpp:184] Created Layer res3a_branch2a (17)
I0323 22:48:37.136298  1439 net.cpp:561] res3a_branch2a <- pool2
I0323 22:48:37.136307  1439 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0323 22:48:37.139078  1439 net.cpp:245] Setting up res3a_branch2a
I0323 22:48:37.139096  1439 net.cpp:252] TEST Top shape for layer 17 'res3a_branch2a' 4 128 40 96 (1966080)
I0323 22:48:37.139106  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0323 22:48:37.139112  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.139124  1439 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0323 22:48:37.139132  1439 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0323 22:48:37.139138  1439 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0323 22:48:37.140094  1439 net.cpp:245] Setting up res3a_branch2a/bn
I0323 22:48:37.140110  1439 net.cpp:252] TEST Top shape for layer 18 'res3a_branch2a/bn' 4 128 40 96 (1966080)
I0323 22:48:37.140126  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0323 22:48:37.140149  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.140159  1439 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0323 22:48:37.140166  1439 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0323 22:48:37.140174  1439 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0323 22:48:37.140183  1439 net.cpp:245] Setting up res3a_branch2a/relu
I0323 22:48:37.140192  1439 net.cpp:252] TEST Top shape for layer 19 'res3a_branch2a/relu' 4 128 40 96 (1966080)
I0323 22:48:37.140199  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0323 22:48:37.140205  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.140219  1439 net.cpp:184] Created Layer res3a_branch2b (20)
I0323 22:48:37.140228  1439 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0323 22:48:37.140234  1439 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0323 22:48:37.141865  1439 net.cpp:245] Setting up res3a_branch2b
I0323 22:48:37.141881  1439 net.cpp:252] TEST Top shape for layer 20 'res3a_branch2b' 4 128 40 96 (1966080)
I0323 22:48:37.141893  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0323 22:48:37.141901  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.141912  1439 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0323 22:48:37.141919  1439 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0323 22:48:37.141927  1439 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0323 22:48:37.142868  1439 net.cpp:245] Setting up res3a_branch2b/bn
I0323 22:48:37.142884  1439 net.cpp:252] TEST Top shape for layer 21 'res3a_branch2b/bn' 4 128 40 96 (1966080)
I0323 22:48:37.142897  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0323 22:48:37.142905  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.142913  1439 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0323 22:48:37.142920  1439 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0323 22:48:37.142927  1439 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0323 22:48:37.142937  1439 net.cpp:245] Setting up res3a_branch2b/relu
I0323 22:48:37.142944  1439 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b/relu' 4 128 40 96 (1966080)
I0323 22:48:37.142951  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0323 22:48:37.142958  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.142966  1439 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (23)
I0323 22:48:37.142973  1439 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0323 22:48:37.142980  1439 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0323 22:48:37.142988  1439 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0323 22:48:37.143061  1439 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0323 22:48:37.143074  1439 net.cpp:252] TEST Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 4 128 40 96 (1966080)
I0323 22:48:37.143082  1439 net.cpp:252] TEST Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 4 128 40 96 (1966080)
I0323 22:48:37.143090  1439 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0323 22:48:37.143096  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.143107  1439 net.cpp:184] Created Layer pool3 (24)
I0323 22:48:37.143115  1439 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0323 22:48:37.143121  1439 net.cpp:530] pool3 -> pool3
I0323 22:48:37.143215  1439 net.cpp:245] Setting up pool3
I0323 22:48:37.143239  1439 net.cpp:252] TEST Top shape for layer 24 'pool3' 4 128 20 48 (491520)
I0323 22:48:37.143247  1439 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0323 22:48:37.143254  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.143268  1439 net.cpp:184] Created Layer res4a_branch2a (25)
I0323 22:48:37.143275  1439 net.cpp:561] res4a_branch2a <- pool3
I0323 22:48:37.143283  1439 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0323 22:48:37.154127  1439 net.cpp:245] Setting up res4a_branch2a
I0323 22:48:37.154163  1439 net.cpp:252] TEST Top shape for layer 25 'res4a_branch2a' 4 256 20 48 (983040)
I0323 22:48:37.154184  1439 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0323 22:48:37.154199  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.154224  1439 net.cpp:184] Created Layer res4a_branch2a/bn (26)
I0323 22:48:37.154238  1439 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0323 22:48:37.154256  1439 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0323 22:48:37.155279  1439 net.cpp:245] Setting up res4a_branch2a/bn
I0323 22:48:37.155300  1439 net.cpp:252] TEST Top shape for layer 26 'res4a_branch2a/bn' 4 256 20 48 (983040)
I0323 22:48:37.155331  1439 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0323 22:48:37.155345  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.155364  1439 net.cpp:184] Created Layer res4a_branch2a/relu (27)
I0323 22:48:37.155376  1439 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0323 22:48:37.155390  1439 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0323 22:48:37.155406  1439 net.cpp:245] Setting up res4a_branch2a/relu
I0323 22:48:37.155422  1439 net.cpp:252] TEST Top shape for layer 27 'res4a_branch2a/relu' 4 256 20 48 (983040)
I0323 22:48:37.155434  1439 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0323 22:48:37.155447  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.155472  1439 net.cpp:184] Created Layer res4a_branch2b (28)
I0323 22:48:37.155484  1439 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0323 22:48:37.155498  1439 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0323 22:48:37.160631  1439 net.cpp:245] Setting up res4a_branch2b
I0323 22:48:37.160656  1439 net.cpp:252] TEST Top shape for layer 28 'res4a_branch2b' 4 256 20 48 (983040)
I0323 22:48:37.160673  1439 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0323 22:48:37.160686  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.160708  1439 net.cpp:184] Created Layer res4a_branch2b/bn (29)
I0323 22:48:37.160720  1439 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0323 22:48:37.160734  1439 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0323 22:48:37.161746  1439 net.cpp:245] Setting up res4a_branch2b/bn
I0323 22:48:37.161764  1439 net.cpp:252] TEST Top shape for layer 29 'res4a_branch2b/bn' 4 256 20 48 (983040)
I0323 22:48:37.161792  1439 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0323 22:48:37.161805  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.161820  1439 net.cpp:184] Created Layer res4a_branch2b/relu (30)
I0323 22:48:37.161833  1439 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0323 22:48:37.161845  1439 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0323 22:48:37.161864  1439 net.cpp:245] Setting up res4a_branch2b/relu
I0323 22:48:37.161876  1439 net.cpp:252] TEST Top shape for layer 30 'res4a_branch2b/relu' 4 256 20 48 (983040)
I0323 22:48:37.161888  1439 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0323 22:48:37.161900  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.161933  1439 net.cpp:184] Created Layer pool4 (31)
I0323 22:48:37.161945  1439 net.cpp:561] pool4 <- res4a_branch2b
I0323 22:48:37.161959  1439 net.cpp:530] pool4 -> pool4
I0323 22:48:37.162073  1439 net.cpp:245] Setting up pool4
I0323 22:48:37.162091  1439 net.cpp:252] TEST Top shape for layer 31 'pool4' 4 256 10 24 (245760)
I0323 22:48:37.162104  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0323 22:48:37.162117  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.162144  1439 net.cpp:184] Created Layer res5a_branch2a (32)
I0323 22:48:37.162156  1439 net.cpp:561] res5a_branch2a <- pool4
I0323 22:48:37.162170  1439 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0323 22:48:37.201156  1439 net.cpp:245] Setting up res5a_branch2a
I0323 22:48:37.201194  1439 net.cpp:252] TEST Top shape for layer 32 'res5a_branch2a' 4 512 10 24 (491520)
I0323 22:48:37.201215  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0323 22:48:37.201230  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.201257  1439 net.cpp:184] Created Layer res5a_branch2a/bn (33)
I0323 22:48:37.201272  1439 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0323 22:48:37.201288  1439 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0323 22:48:37.202329  1439 net.cpp:245] Setting up res5a_branch2a/bn
I0323 22:48:37.202347  1439 net.cpp:252] TEST Top shape for layer 33 'res5a_branch2a/bn' 4 512 10 24 (491520)
I0323 22:48:37.202373  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0323 22:48:37.202384  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.202404  1439 net.cpp:184] Created Layer res5a_branch2a/relu (34)
I0323 22:48:37.202414  1439 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0323 22:48:37.202427  1439 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0323 22:48:37.202445  1439 net.cpp:245] Setting up res5a_branch2a/relu
I0323 22:48:37.202459  1439 net.cpp:252] TEST Top shape for layer 34 'res5a_branch2a/relu' 4 512 10 24 (491520)
I0323 22:48:37.202471  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0323 22:48:37.202483  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.202509  1439 net.cpp:184] Created Layer res5a_branch2b (35)
I0323 22:48:37.202520  1439 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0323 22:48:37.202534  1439 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0323 22:48:37.222508  1439 net.cpp:245] Setting up res5a_branch2b
I0323 22:48:37.222544  1439 net.cpp:252] TEST Top shape for layer 35 'res5a_branch2b' 4 512 10 24 (491520)
I0323 22:48:37.222579  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0323 22:48:37.222594  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.222622  1439 net.cpp:184] Created Layer res5a_branch2b/bn (36)
I0323 22:48:37.222637  1439 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0323 22:48:37.222653  1439 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0323 22:48:37.223672  1439 net.cpp:245] Setting up res5a_branch2b/bn
I0323 22:48:37.223690  1439 net.cpp:252] TEST Top shape for layer 36 'res5a_branch2b/bn' 4 512 10 24 (491520)
I0323 22:48:37.223713  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0323 22:48:37.223726  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.223743  1439 net.cpp:184] Created Layer res5a_branch2b/relu (37)
I0323 22:48:37.223754  1439 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0323 22:48:37.223768  1439 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0323 22:48:37.223784  1439 net.cpp:245] Setting up res5a_branch2b/relu
I0323 22:48:37.223811  1439 net.cpp:252] TEST Top shape for layer 37 'res5a_branch2b/relu' 4 512 10 24 (491520)
I0323 22:48:37.223824  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2b_res5a_branch2b/relu_0_split' of type 'Split'
I0323 22:48:37.223836  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.223850  1439 net.cpp:184] Created Layer res5a_branch2b_res5a_branch2b/relu_0_split (38)
I0323 22:48:37.223861  1439 net.cpp:561] res5a_branch2b_res5a_branch2b/relu_0_split <- res5a_branch2b
I0323 22:48:37.223875  1439 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_0
I0323 22:48:37.223892  1439 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_1
I0323 22:48:37.223980  1439 net.cpp:245] Setting up res5a_branch2b_res5a_branch2b/relu_0_split
I0323 22:48:37.223996  1439 net.cpp:252] TEST Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 4 512 10 24 (491520)
I0323 22:48:37.224012  1439 net.cpp:252] TEST Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 4 512 10 24 (491520)
I0323 22:48:37.224023  1439 layer_factory.hpp:136] Creating layer 'pool6' of type 'Pooling'
I0323 22:48:37.224036  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.224056  1439 net.cpp:184] Created Layer pool6 (39)
I0323 22:48:37.224067  1439 net.cpp:561] pool6 <- res5a_branch2b_res5a_branch2b/relu_0_split_0
I0323 22:48:37.224081  1439 net.cpp:530] pool6 -> pool6
I0323 22:48:37.224198  1439 net.cpp:245] Setting up pool6
I0323 22:48:37.224215  1439 net.cpp:252] TEST Top shape for layer 39 'pool6' 4 512 5 12 (122880)
I0323 22:48:37.224228  1439 layer_factory.hpp:136] Creating layer 'pool6_pool6_0_split' of type 'Split'
I0323 22:48:37.224241  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.224256  1439 net.cpp:184] Created Layer pool6_pool6_0_split (40)
I0323 22:48:37.224267  1439 net.cpp:561] pool6_pool6_0_split <- pool6
I0323 22:48:37.224280  1439 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_0
I0323 22:48:37.224294  1439 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_1
I0323 22:48:37.224375  1439 net.cpp:245] Setting up pool6_pool6_0_split
I0323 22:48:37.224392  1439 net.cpp:252] TEST Top shape for layer 40 'pool6_pool6_0_split' 4 512 5 12 (122880)
I0323 22:48:37.224406  1439 net.cpp:252] TEST Top shape for layer 40 'pool6_pool6_0_split' 4 512 5 12 (122880)
I0323 22:48:37.224418  1439 layer_factory.hpp:136] Creating layer 'pool7' of type 'Pooling'
I0323 22:48:37.224431  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.224447  1439 net.cpp:184] Created Layer pool7 (41)
I0323 22:48:37.224457  1439 net.cpp:561] pool7 <- pool6_pool6_0_split_0
I0323 22:48:37.224470  1439 net.cpp:530] pool7 -> pool7
I0323 22:48:37.224578  1439 net.cpp:245] Setting up pool7
I0323 22:48:37.224596  1439 net.cpp:252] TEST Top shape for layer 41 'pool7' 4 512 3 6 (36864)
I0323 22:48:37.224608  1439 layer_factory.hpp:136] Creating layer 'pool7_pool7_0_split' of type 'Split'
I0323 22:48:37.224619  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.224635  1439 net.cpp:184] Created Layer pool7_pool7_0_split (42)
I0323 22:48:37.224647  1439 net.cpp:561] pool7_pool7_0_split <- pool7
I0323 22:48:37.224659  1439 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_0
I0323 22:48:37.224678  1439 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_1
I0323 22:48:37.224761  1439 net.cpp:245] Setting up pool7_pool7_0_split
I0323 22:48:37.224778  1439 net.cpp:252] TEST Top shape for layer 42 'pool7_pool7_0_split' 4 512 3 6 (36864)
I0323 22:48:37.224793  1439 net.cpp:252] TEST Top shape for layer 42 'pool7_pool7_0_split' 4 512 3 6 (36864)
I0323 22:48:37.224805  1439 layer_factory.hpp:136] Creating layer 'pool8' of type 'Pooling'
I0323 22:48:37.224825  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.224845  1439 net.cpp:184] Created Layer pool8 (43)
I0323 22:48:37.224856  1439 net.cpp:561] pool8 <- pool7_pool7_0_split_0
I0323 22:48:37.224870  1439 net.cpp:530] pool8 -> pool8
I0323 22:48:37.224983  1439 net.cpp:245] Setting up pool8
I0323 22:48:37.224999  1439 net.cpp:252] TEST Top shape for layer 43 'pool8' 4 512 2 3 (12288)
I0323 22:48:37.225013  1439 layer_factory.hpp:136] Creating layer 'pool8_pool8_0_split' of type 'Split'
I0323 22:48:37.225024  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.225039  1439 net.cpp:184] Created Layer pool8_pool8_0_split (44)
I0323 22:48:37.225049  1439 net.cpp:561] pool8_pool8_0_split <- pool8
I0323 22:48:37.225062  1439 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_0
I0323 22:48:37.225078  1439 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_1
I0323 22:48:37.225160  1439 net.cpp:245] Setting up pool8_pool8_0_split
I0323 22:48:37.225177  1439 net.cpp:252] TEST Top shape for layer 44 'pool8_pool8_0_split' 4 512 2 3 (12288)
I0323 22:48:37.225191  1439 net.cpp:252] TEST Top shape for layer 44 'pool8_pool8_0_split' 4 512 2 3 (12288)
I0323 22:48:37.225203  1439 layer_factory.hpp:136] Creating layer 'pool9' of type 'Pooling'
I0323 22:48:37.225215  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.225234  1439 net.cpp:184] Created Layer pool9 (45)
I0323 22:48:37.225245  1439 net.cpp:561] pool9 <- pool8_pool8_0_split_0
I0323 22:48:37.225258  1439 net.cpp:530] pool9 -> pool9
I0323 22:48:37.225370  1439 net.cpp:245] Setting up pool9
I0323 22:48:37.225386  1439 net.cpp:252] TEST Top shape for layer 45 'pool9' 4 512 1 2 (4096)
I0323 22:48:37.225399  1439 layer_factory.hpp:136] Creating layer 'ctx_output1' of type 'Convolution'
I0323 22:48:37.225411  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.225437  1439 net.cpp:184] Created Layer ctx_output1 (46)
I0323 22:48:37.225450  1439 net.cpp:561] ctx_output1 <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0323 22:48:37.225464  1439 net.cpp:530] ctx_output1 -> ctx_output1
I0323 22:48:37.227031  1439 net.cpp:245] Setting up ctx_output1
I0323 22:48:37.227051  1439 net.cpp:252] TEST Top shape for layer 46 'ctx_output1' 4 256 40 96 (3932160)
I0323 22:48:37.227069  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu' of type 'ReLU'
I0323 22:48:37.227080  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.227097  1439 net.cpp:184] Created Layer ctx_output1/relu (47)
I0323 22:48:37.227109  1439 net.cpp:561] ctx_output1/relu <- ctx_output1
I0323 22:48:37.227123  1439 net.cpp:513] ctx_output1/relu -> ctx_output1 (in-place)
I0323 22:48:37.227138  1439 net.cpp:245] Setting up ctx_output1/relu
I0323 22:48:37.227150  1439 net.cpp:252] TEST Top shape for layer 47 'ctx_output1/relu' 4 256 40 96 (3932160)
I0323 22:48:37.227162  1439 layer_factory.hpp:136] Creating layer 'ctx_output1_ctx_output1/relu_0_split' of type 'Split'
I0323 22:48:37.227174  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.227187  1439 net.cpp:184] Created Layer ctx_output1_ctx_output1/relu_0_split (48)
I0323 22:48:37.227198  1439 net.cpp:561] ctx_output1_ctx_output1/relu_0_split <- ctx_output1
I0323 22:48:37.227213  1439 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_0
I0323 22:48:37.227227  1439 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_1
I0323 22:48:37.227241  1439 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_2
I0323 22:48:37.227355  1439 net.cpp:245] Setting up ctx_output1_ctx_output1/relu_0_split
I0323 22:48:37.227372  1439 net.cpp:252] TEST Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 4 256 40 96 (3932160)
I0323 22:48:37.227397  1439 net.cpp:252] TEST Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 4 256 40 96 (3932160)
I0323 22:48:37.227412  1439 net.cpp:252] TEST Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 4 256 40 96 (3932160)
I0323 22:48:37.227423  1439 layer_factory.hpp:136] Creating layer 'ctx_output2' of type 'Convolution'
I0323 22:48:37.227435  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.227461  1439 net.cpp:184] Created Layer ctx_output2 (49)
I0323 22:48:37.227473  1439 net.cpp:561] ctx_output2 <- res5a_branch2b_res5a_branch2b/relu_0_split_1
I0323 22:48:37.227488  1439 net.cpp:530] ctx_output2 -> ctx_output2
I0323 22:48:37.232197  1439 net.cpp:245] Setting up ctx_output2
I0323 22:48:37.232230  1439 net.cpp:252] TEST Top shape for layer 49 'ctx_output2' 4 256 10 24 (245760)
I0323 22:48:37.232250  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu' of type 'ReLU'
I0323 22:48:37.232264  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.232283  1439 net.cpp:184] Created Layer ctx_output2/relu (50)
I0323 22:48:37.232296  1439 net.cpp:561] ctx_output2/relu <- ctx_output2
I0323 22:48:37.232311  1439 net.cpp:513] ctx_output2/relu -> ctx_output2 (in-place)
I0323 22:48:37.232328  1439 net.cpp:245] Setting up ctx_output2/relu
I0323 22:48:37.232342  1439 net.cpp:252] TEST Top shape for layer 50 'ctx_output2/relu' 4 256 10 24 (245760)
I0323 22:48:37.232353  1439 layer_factory.hpp:136] Creating layer 'ctx_output2_ctx_output2/relu_0_split' of type 'Split'
I0323 22:48:37.232365  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.232383  1439 net.cpp:184] Created Layer ctx_output2_ctx_output2/relu_0_split (51)
I0323 22:48:37.232393  1439 net.cpp:561] ctx_output2_ctx_output2/relu_0_split <- ctx_output2
I0323 22:48:37.232406  1439 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_0
I0323 22:48:37.232421  1439 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_1
I0323 22:48:37.232434  1439 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_2
I0323 22:48:37.232551  1439 net.cpp:245] Setting up ctx_output2_ctx_output2/relu_0_split
I0323 22:48:37.232571  1439 net.cpp:252] TEST Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 4 256 10 24 (245760)
I0323 22:48:37.232586  1439 net.cpp:252] TEST Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 4 256 10 24 (245760)
I0323 22:48:37.232599  1439 net.cpp:252] TEST Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 4 256 10 24 (245760)
I0323 22:48:37.232611  1439 layer_factory.hpp:136] Creating layer 'ctx_output3' of type 'Convolution'
I0323 22:48:37.232623  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.232650  1439 net.cpp:184] Created Layer ctx_output3 (52)
I0323 22:48:37.232663  1439 net.cpp:561] ctx_output3 <- pool6_pool6_0_split_1
I0323 22:48:37.232677  1439 net.cpp:530] ctx_output3 -> ctx_output3
I0323 22:48:37.238481  1439 net.cpp:245] Setting up ctx_output3
I0323 22:48:37.238507  1439 net.cpp:252] TEST Top shape for layer 52 'ctx_output3' 4 256 5 12 (61440)
I0323 22:48:37.238526  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu' of type 'ReLU'
I0323 22:48:37.238539  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.238554  1439 net.cpp:184] Created Layer ctx_output3/relu (53)
I0323 22:48:37.238566  1439 net.cpp:561] ctx_output3/relu <- ctx_output3
I0323 22:48:37.238579  1439 net.cpp:513] ctx_output3/relu -> ctx_output3 (in-place)
I0323 22:48:37.238598  1439 net.cpp:245] Setting up ctx_output3/relu
I0323 22:48:37.238611  1439 net.cpp:252] TEST Top shape for layer 53 'ctx_output3/relu' 4 256 5 12 (61440)
I0323 22:48:37.238623  1439 layer_factory.hpp:136] Creating layer 'ctx_output3_ctx_output3/relu_0_split' of type 'Split'
I0323 22:48:37.238648  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.238663  1439 net.cpp:184] Created Layer ctx_output3_ctx_output3/relu_0_split (54)
I0323 22:48:37.238674  1439 net.cpp:561] ctx_output3_ctx_output3/relu_0_split <- ctx_output3
I0323 22:48:37.238688  1439 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_0
I0323 22:48:37.238704  1439 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_1
I0323 22:48:37.238718  1439 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_2
I0323 22:48:37.238833  1439 net.cpp:245] Setting up ctx_output3_ctx_output3/relu_0_split
I0323 22:48:37.238850  1439 net.cpp:252] TEST Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 4 256 5 12 (61440)
I0323 22:48:37.238865  1439 net.cpp:252] TEST Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 4 256 5 12 (61440)
I0323 22:48:37.238879  1439 net.cpp:252] TEST Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 4 256 5 12 (61440)
I0323 22:48:37.238891  1439 layer_factory.hpp:136] Creating layer 'ctx_output4' of type 'Convolution'
I0323 22:48:37.238903  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.238929  1439 net.cpp:184] Created Layer ctx_output4 (55)
I0323 22:48:37.238941  1439 net.cpp:561] ctx_output4 <- pool7_pool7_0_split_1
I0323 22:48:37.238956  1439 net.cpp:530] ctx_output4 -> ctx_output4
I0323 22:48:37.243552  1439 net.cpp:245] Setting up ctx_output4
I0323 22:48:37.243582  1439 net.cpp:252] TEST Top shape for layer 55 'ctx_output4' 4 256 3 6 (18432)
I0323 22:48:37.243600  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu' of type 'ReLU'
I0323 22:48:37.243613  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.243631  1439 net.cpp:184] Created Layer ctx_output4/relu (56)
I0323 22:48:37.243647  1439 net.cpp:561] ctx_output4/relu <- ctx_output4
I0323 22:48:37.243660  1439 net.cpp:513] ctx_output4/relu -> ctx_output4 (in-place)
I0323 22:48:37.243679  1439 net.cpp:245] Setting up ctx_output4/relu
I0323 22:48:37.243692  1439 net.cpp:252] TEST Top shape for layer 56 'ctx_output4/relu' 4 256 3 6 (18432)
I0323 22:48:37.243705  1439 layer_factory.hpp:136] Creating layer 'ctx_output4_ctx_output4/relu_0_split' of type 'Split'
I0323 22:48:37.243716  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.243731  1439 net.cpp:184] Created Layer ctx_output4_ctx_output4/relu_0_split (57)
I0323 22:48:37.243742  1439 net.cpp:561] ctx_output4_ctx_output4/relu_0_split <- ctx_output4
I0323 22:48:37.243755  1439 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_0
I0323 22:48:37.243770  1439 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_1
I0323 22:48:37.243787  1439 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_2
I0323 22:48:37.244882  1439 net.cpp:245] Setting up ctx_output4_ctx_output4/relu_0_split
I0323 22:48:37.244899  1439 net.cpp:252] TEST Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 4 256 3 6 (18432)
I0323 22:48:37.244915  1439 net.cpp:252] TEST Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 4 256 3 6 (18432)
I0323 22:48:37.244927  1439 net.cpp:252] TEST Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 4 256 3 6 (18432)
I0323 22:48:37.244940  1439 layer_factory.hpp:136] Creating layer 'ctx_output5' of type 'Convolution'
I0323 22:48:37.244951  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.244979  1439 net.cpp:184] Created Layer ctx_output5 (58)
I0323 22:48:37.244992  1439 net.cpp:561] ctx_output5 <- pool8_pool8_0_split_1
I0323 22:48:37.245007  1439 net.cpp:530] ctx_output5 -> ctx_output5
I0323 22:48:37.249682  1439 net.cpp:245] Setting up ctx_output5
I0323 22:48:37.249727  1439 net.cpp:252] TEST Top shape for layer 58 'ctx_output5' 4 256 2 3 (6144)
I0323 22:48:37.249753  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu' of type 'ReLU'
I0323 22:48:37.249766  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.249783  1439 net.cpp:184] Created Layer ctx_output5/relu (59)
I0323 22:48:37.249796  1439 net.cpp:561] ctx_output5/relu <- ctx_output5
I0323 22:48:37.249810  1439 net.cpp:513] ctx_output5/relu -> ctx_output5 (in-place)
I0323 22:48:37.249827  1439 net.cpp:245] Setting up ctx_output5/relu
I0323 22:48:37.249840  1439 net.cpp:252] TEST Top shape for layer 59 'ctx_output5/relu' 4 256 2 3 (6144)
I0323 22:48:37.249852  1439 layer_factory.hpp:136] Creating layer 'ctx_output5_ctx_output5/relu_0_split' of type 'Split'
I0323 22:48:37.249864  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.249881  1439 net.cpp:184] Created Layer ctx_output5_ctx_output5/relu_0_split (60)
I0323 22:48:37.249891  1439 net.cpp:561] ctx_output5_ctx_output5/relu_0_split <- ctx_output5
I0323 22:48:37.249904  1439 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_0
I0323 22:48:37.249918  1439 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_1
I0323 22:48:37.249938  1439 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_2
I0323 22:48:37.250051  1439 net.cpp:245] Setting up ctx_output5_ctx_output5/relu_0_split
I0323 22:48:37.250068  1439 net.cpp:252] TEST Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 4 256 2 3 (6144)
I0323 22:48:37.250083  1439 net.cpp:252] TEST Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 4 256 2 3 (6144)
I0323 22:48:37.250097  1439 net.cpp:252] TEST Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 4 256 2 3 (6144)
I0323 22:48:37.250108  1439 layer_factory.hpp:136] Creating layer 'ctx_output6' of type 'Convolution'
I0323 22:48:37.250120  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.250150  1439 net.cpp:184] Created Layer ctx_output6 (61)
I0323 22:48:37.250164  1439 net.cpp:561] ctx_output6 <- pool9
I0323 22:48:37.250178  1439 net.cpp:530] ctx_output6 -> ctx_output6
I0323 22:48:37.254750  1439 net.cpp:245] Setting up ctx_output6
I0323 22:48:37.254768  1439 net.cpp:252] TEST Top shape for layer 61 'ctx_output6' 4 256 1 2 (2048)
I0323 22:48:37.254791  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu' of type 'ReLU'
I0323 22:48:37.254802  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.254819  1439 net.cpp:184] Created Layer ctx_output6/relu (62)
I0323 22:48:37.254832  1439 net.cpp:561] ctx_output6/relu <- ctx_output6
I0323 22:48:37.254844  1439 net.cpp:513] ctx_output6/relu -> ctx_output6 (in-place)
I0323 22:48:37.254860  1439 net.cpp:245] Setting up ctx_output6/relu
I0323 22:48:37.254873  1439 net.cpp:252] TEST Top shape for layer 62 'ctx_output6/relu' 4 256 1 2 (2048)
I0323 22:48:37.254885  1439 layer_factory.hpp:136] Creating layer 'ctx_output6_ctx_output6/relu_0_split' of type 'Split'
I0323 22:48:37.254896  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.254914  1439 net.cpp:184] Created Layer ctx_output6_ctx_output6/relu_0_split (63)
I0323 22:48:37.254925  1439 net.cpp:561] ctx_output6_ctx_output6/relu_0_split <- ctx_output6
I0323 22:48:37.254938  1439 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_0
I0323 22:48:37.254952  1439 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_1
I0323 22:48:37.254968  1439 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_2
I0323 22:48:37.255084  1439 net.cpp:245] Setting up ctx_output6_ctx_output6/relu_0_split
I0323 22:48:37.255115  1439 net.cpp:252] TEST Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 4 256 1 2 (2048)
I0323 22:48:37.255131  1439 net.cpp:252] TEST Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 4 256 1 2 (2048)
I0323 22:48:37.255143  1439 net.cpp:252] TEST Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 4 256 1 2 (2048)
I0323 22:48:37.255156  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc' of type 'Convolution'
I0323 22:48:37.255167  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.255197  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc (64)
I0323 22:48:37.255208  1439 net.cpp:561] ctx_output1/relu_mbox_loc <- ctx_output1_ctx_output1/relu_0_split_0
I0323 22:48:37.255223  1439 net.cpp:530] ctx_output1/relu_mbox_loc -> ctx_output1/relu_mbox_loc
I0323 22:48:37.255892  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_loc
I0323 22:48:37.255909  1439 net.cpp:252] TEST Top shape for layer 64 'ctx_output1/relu_mbox_loc' 4 16 40 96 (245760)
I0323 22:48:37.255929  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_perm' of type 'Permute'
I0323 22:48:37.255940  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.255960  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_perm (65)
I0323 22:48:37.255971  1439 net.cpp:561] ctx_output1/relu_mbox_loc_perm <- ctx_output1/relu_mbox_loc
I0323 22:48:37.255985  1439 net.cpp:530] ctx_output1/relu_mbox_loc_perm -> ctx_output1/relu_mbox_loc_perm
I0323 22:48:37.256201  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_perm
I0323 22:48:37.256217  1439 net.cpp:252] TEST Top shape for layer 65 'ctx_output1/relu_mbox_loc_perm' 4 40 96 16 (245760)
I0323 22:48:37.256230  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_flat' of type 'Flatten'
I0323 22:48:37.256242  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.256258  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_flat (66)
I0323 22:48:37.256268  1439 net.cpp:561] ctx_output1/relu_mbox_loc_flat <- ctx_output1/relu_mbox_loc_perm
I0323 22:48:37.256283  1439 net.cpp:530] ctx_output1/relu_mbox_loc_flat -> ctx_output1/relu_mbox_loc_flat
I0323 22:48:37.256341  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_flat
I0323 22:48:37.256358  1439 net.cpp:252] TEST Top shape for layer 66 'ctx_output1/relu_mbox_loc_flat' 4 61440 (245760)
I0323 22:48:37.256372  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf' of type 'Convolution'
I0323 22:48:37.256384  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.256409  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf (67)
I0323 22:48:37.256422  1439 net.cpp:561] ctx_output1/relu_mbox_conf <- ctx_output1_ctx_output1/relu_0_split_1
I0323 22:48:37.256436  1439 net.cpp:530] ctx_output1/relu_mbox_conf -> ctx_output1/relu_mbox_conf
I0323 22:48:37.257087  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_conf
I0323 22:48:37.257105  1439 net.cpp:252] TEST Top shape for layer 67 'ctx_output1/relu_mbox_conf' 4 16 40 96 (245760)
I0323 22:48:37.257124  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_perm' of type 'Permute'
I0323 22:48:37.257135  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.257155  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_perm (68)
I0323 22:48:37.257166  1439 net.cpp:561] ctx_output1/relu_mbox_conf_perm <- ctx_output1/relu_mbox_conf
I0323 22:48:37.257180  1439 net.cpp:530] ctx_output1/relu_mbox_conf_perm -> ctx_output1/relu_mbox_conf_perm
I0323 22:48:37.257397  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_perm
I0323 22:48:37.257414  1439 net.cpp:252] TEST Top shape for layer 68 'ctx_output1/relu_mbox_conf_perm' 4 40 96 16 (245760)
I0323 22:48:37.257436  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_flat' of type 'Flatten'
I0323 22:48:37.257449  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.257463  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_flat (69)
I0323 22:48:37.257475  1439 net.cpp:561] ctx_output1/relu_mbox_conf_flat <- ctx_output1/relu_mbox_conf_perm
I0323 22:48:37.257489  1439 net.cpp:530] ctx_output1/relu_mbox_conf_flat -> ctx_output1/relu_mbox_conf_flat
I0323 22:48:37.257546  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_flat
I0323 22:48:37.257563  1439 net.cpp:252] TEST Top shape for layer 69 'ctx_output1/relu_mbox_conf_flat' 4 61440 (245760)
I0323 22:48:37.257576  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_priorbox' of type 'PriorBox'
I0323 22:48:37.257588  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.257607  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_priorbox (70)
I0323 22:48:37.257618  1439 net.cpp:561] ctx_output1/relu_mbox_priorbox <- ctx_output1_ctx_output1/relu_0_split_2
I0323 22:48:37.257632  1439 net.cpp:561] ctx_output1/relu_mbox_priorbox <- data_data_0_split_1
I0323 22:48:37.257647  1439 net.cpp:530] ctx_output1/relu_mbox_priorbox -> ctx_output1/relu_mbox_priorbox
I0323 22:48:37.257711  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_priorbox
I0323 22:48:37.257728  1439 net.cpp:252] TEST Top shape for layer 70 'ctx_output1/relu_mbox_priorbox' 1 2 61440 (122880)
I0323 22:48:37.257742  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc' of type 'Convolution'
I0323 22:48:37.257753  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.257779  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc (71)
I0323 22:48:37.257791  1439 net.cpp:561] ctx_output2/relu_mbox_loc <- ctx_output2_ctx_output2/relu_0_split_0
I0323 22:48:37.257805  1439 net.cpp:530] ctx_output2/relu_mbox_loc -> ctx_output2/relu_mbox_loc
I0323 22:48:37.258532  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_loc
I0323 22:48:37.258549  1439 net.cpp:252] TEST Top shape for layer 71 'ctx_output2/relu_mbox_loc' 4 24 10 24 (23040)
I0323 22:48:37.258569  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_perm' of type 'Permute'
I0323 22:48:37.258579  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.258599  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_perm (72)
I0323 22:48:37.258611  1439 net.cpp:561] ctx_output2/relu_mbox_loc_perm <- ctx_output2/relu_mbox_loc
I0323 22:48:37.258625  1439 net.cpp:530] ctx_output2/relu_mbox_loc_perm -> ctx_output2/relu_mbox_loc_perm
I0323 22:48:37.258839  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_perm
I0323 22:48:37.258857  1439 net.cpp:252] TEST Top shape for layer 72 'ctx_output2/relu_mbox_loc_perm' 4 10 24 24 (23040)
I0323 22:48:37.258869  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_flat' of type 'Flatten'
I0323 22:48:37.258882  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.258898  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_flat (73)
I0323 22:48:37.258910  1439 net.cpp:561] ctx_output2/relu_mbox_loc_flat <- ctx_output2/relu_mbox_loc_perm
I0323 22:48:37.258924  1439 net.cpp:530] ctx_output2/relu_mbox_loc_flat -> ctx_output2/relu_mbox_loc_flat
I0323 22:48:37.258980  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_flat
I0323 22:48:37.258996  1439 net.cpp:252] TEST Top shape for layer 73 'ctx_output2/relu_mbox_loc_flat' 4 5760 (23040)
I0323 22:48:37.259009  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf' of type 'Convolution'
I0323 22:48:37.259021  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.259047  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf (74)
I0323 22:48:37.259068  1439 net.cpp:561] ctx_output2/relu_mbox_conf <- ctx_output2_ctx_output2/relu_0_split_1
I0323 22:48:37.259084  1439 net.cpp:530] ctx_output2/relu_mbox_conf -> ctx_output2/relu_mbox_conf
I0323 22:48:37.259871  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_conf
I0323 22:48:37.259908  1439 net.cpp:252] TEST Top shape for layer 74 'ctx_output2/relu_mbox_conf' 4 24 10 24 (23040)
I0323 22:48:37.259928  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_perm' of type 'Permute'
I0323 22:48:37.259943  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.259964  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_perm (75)
I0323 22:48:37.259979  1439 net.cpp:561] ctx_output2/relu_mbox_conf_perm <- ctx_output2/relu_mbox_conf
I0323 22:48:37.259994  1439 net.cpp:530] ctx_output2/relu_mbox_conf_perm -> ctx_output2/relu_mbox_conf_perm
I0323 22:48:37.260212  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_perm
I0323 22:48:37.260231  1439 net.cpp:252] TEST Top shape for layer 75 'ctx_output2/relu_mbox_conf_perm' 4 10 24 24 (23040)
I0323 22:48:37.260243  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_flat' of type 'Flatten'
I0323 22:48:37.260255  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.260270  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_flat (76)
I0323 22:48:37.260282  1439 net.cpp:561] ctx_output2/relu_mbox_conf_flat <- ctx_output2/relu_mbox_conf_perm
I0323 22:48:37.260296  1439 net.cpp:530] ctx_output2/relu_mbox_conf_flat -> ctx_output2/relu_mbox_conf_flat
I0323 22:48:37.260354  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_flat
I0323 22:48:37.260370  1439 net.cpp:252] TEST Top shape for layer 76 'ctx_output2/relu_mbox_conf_flat' 4 5760 (23040)
I0323 22:48:37.260383  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_priorbox' of type 'PriorBox'
I0323 22:48:37.260396  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.260413  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_priorbox (77)
I0323 22:48:37.260426  1439 net.cpp:561] ctx_output2/relu_mbox_priorbox <- ctx_output2_ctx_output2/relu_0_split_2
I0323 22:48:37.260437  1439 net.cpp:561] ctx_output2/relu_mbox_priorbox <- data_data_0_split_2
I0323 22:48:37.260444  1439 net.cpp:530] ctx_output2/relu_mbox_priorbox -> ctx_output2/relu_mbox_priorbox
I0323 22:48:37.260499  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_priorbox
I0323 22:48:37.260509  1439 net.cpp:252] TEST Top shape for layer 77 'ctx_output2/relu_mbox_priorbox' 1 2 5760 (11520)
I0323 22:48:37.260517  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc' of type 'Convolution'
I0323 22:48:37.260524  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.260540  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc (78)
I0323 22:48:37.260548  1439 net.cpp:561] ctx_output3/relu_mbox_loc <- ctx_output3_ctx_output3/relu_0_split_0
I0323 22:48:37.260556  1439 net.cpp:530] ctx_output3/relu_mbox_loc -> ctx_output3/relu_mbox_loc
I0323 22:48:37.261277  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_loc
I0323 22:48:37.261291  1439 net.cpp:252] TEST Top shape for layer 78 'ctx_output3/relu_mbox_loc' 4 24 5 12 (5760)
I0323 22:48:37.261301  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_perm' of type 'Permute'
I0323 22:48:37.261307  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.261318  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_perm (79)
I0323 22:48:37.261325  1439 net.cpp:561] ctx_output3/relu_mbox_loc_perm <- ctx_output3/relu_mbox_loc
I0323 22:48:37.261332  1439 net.cpp:530] ctx_output3/relu_mbox_loc_perm -> ctx_output3/relu_mbox_loc_perm
I0323 22:48:37.261540  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_perm
I0323 22:48:37.261553  1439 net.cpp:252] TEST Top shape for layer 79 'ctx_output3/relu_mbox_loc_perm' 4 5 12 24 (5760)
I0323 22:48:37.261572  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_flat' of type 'Flatten'
I0323 22:48:37.261579  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.261589  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_flat (80)
I0323 22:48:37.261595  1439 net.cpp:561] ctx_output3/relu_mbox_loc_flat <- ctx_output3/relu_mbox_loc_perm
I0323 22:48:37.261600  1439 net.cpp:530] ctx_output3/relu_mbox_loc_flat -> ctx_output3/relu_mbox_loc_flat
I0323 22:48:37.261648  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_flat
I0323 22:48:37.261659  1439 net.cpp:252] TEST Top shape for layer 80 'ctx_output3/relu_mbox_loc_flat' 4 1440 (5760)
I0323 22:48:37.261667  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf' of type 'Convolution'
I0323 22:48:37.261672  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.261688  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf (81)
I0323 22:48:37.261718  1439 net.cpp:561] ctx_output3/relu_mbox_conf <- ctx_output3_ctx_output3/relu_0_split_1
I0323 22:48:37.261726  1439 net.cpp:530] ctx_output3/relu_mbox_conf -> ctx_output3/relu_mbox_conf
I0323 22:48:37.262441  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_conf
I0323 22:48:37.262454  1439 net.cpp:252] TEST Top shape for layer 81 'ctx_output3/relu_mbox_conf' 4 24 5 12 (5760)
I0323 22:48:37.262465  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_perm' of type 'Permute'
I0323 22:48:37.262470  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.262481  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_perm (82)
I0323 22:48:37.262490  1439 net.cpp:561] ctx_output3/relu_mbox_conf_perm <- ctx_output3/relu_mbox_conf
I0323 22:48:37.262495  1439 net.cpp:530] ctx_output3/relu_mbox_conf_perm -> ctx_output3/relu_mbox_conf_perm
I0323 22:48:37.262706  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_perm
I0323 22:48:37.262718  1439 net.cpp:252] TEST Top shape for layer 82 'ctx_output3/relu_mbox_conf_perm' 4 5 12 24 (5760)
I0323 22:48:37.262725  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_flat' of type 'Flatten'
I0323 22:48:37.262730  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.262739  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_flat (83)
I0323 22:48:37.262745  1439 net.cpp:561] ctx_output3/relu_mbox_conf_flat <- ctx_output3/relu_mbox_conf_perm
I0323 22:48:37.262753  1439 net.cpp:530] ctx_output3/relu_mbox_conf_flat -> ctx_output3/relu_mbox_conf_flat
I0323 22:48:37.262799  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_flat
I0323 22:48:37.262810  1439 net.cpp:252] TEST Top shape for layer 83 'ctx_output3/relu_mbox_conf_flat' 4 1440 (5760)
I0323 22:48:37.262816  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_priorbox' of type 'PriorBox'
I0323 22:48:37.262822  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.262830  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_priorbox (84)
I0323 22:48:37.262835  1439 net.cpp:561] ctx_output3/relu_mbox_priorbox <- ctx_output3_ctx_output3/relu_0_split_2
I0323 22:48:37.262842  1439 net.cpp:561] ctx_output3/relu_mbox_priorbox <- data_data_0_split_3
I0323 22:48:37.262850  1439 net.cpp:530] ctx_output3/relu_mbox_priorbox -> ctx_output3/relu_mbox_priorbox
I0323 22:48:37.262898  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_priorbox
I0323 22:48:37.262909  1439 net.cpp:252] TEST Top shape for layer 84 'ctx_output3/relu_mbox_priorbox' 1 2 1440 (2880)
I0323 22:48:37.262917  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc' of type 'Convolution'
I0323 22:48:37.262922  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.262946  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc (85)
I0323 22:48:37.262954  1439 net.cpp:561] ctx_output4/relu_mbox_loc <- ctx_output4_ctx_output4/relu_0_split_0
I0323 22:48:37.262961  1439 net.cpp:530] ctx_output4/relu_mbox_loc -> ctx_output4/relu_mbox_loc
I0323 22:48:37.263681  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_loc
I0323 22:48:37.263695  1439 net.cpp:252] TEST Top shape for layer 85 'ctx_output4/relu_mbox_loc' 4 24 3 6 (1728)
I0323 22:48:37.263705  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_perm' of type 'Permute'
I0323 22:48:37.263710  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.263721  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_perm (86)
I0323 22:48:37.263728  1439 net.cpp:561] ctx_output4/relu_mbox_loc_perm <- ctx_output4/relu_mbox_loc
I0323 22:48:37.263734  1439 net.cpp:530] ctx_output4/relu_mbox_loc_perm -> ctx_output4/relu_mbox_loc_perm
I0323 22:48:37.263942  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_perm
I0323 22:48:37.263954  1439 net.cpp:252] TEST Top shape for layer 86 'ctx_output4/relu_mbox_loc_perm' 4 3 6 24 (1728)
I0323 22:48:37.263960  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_flat' of type 'Flatten'
I0323 22:48:37.263967  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.263973  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_flat (87)
I0323 22:48:37.263979  1439 net.cpp:561] ctx_output4/relu_mbox_loc_flat <- ctx_output4/relu_mbox_loc_perm
I0323 22:48:37.263985  1439 net.cpp:530] ctx_output4/relu_mbox_loc_flat -> ctx_output4/relu_mbox_loc_flat
I0323 22:48:37.264032  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_flat
I0323 22:48:37.264044  1439 net.cpp:252] TEST Top shape for layer 87 'ctx_output4/relu_mbox_loc_flat' 4 432 (1728)
I0323 22:48:37.264050  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf' of type 'Convolution'
I0323 22:48:37.264055  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.264073  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf (88)
I0323 22:48:37.264081  1439 net.cpp:561] ctx_output4/relu_mbox_conf <- ctx_output4_ctx_output4/relu_0_split_1
I0323 22:48:37.264087  1439 net.cpp:530] ctx_output4/relu_mbox_conf -> ctx_output4/relu_mbox_conf
I0323 22:48:37.264806  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_conf
I0323 22:48:37.264818  1439 net.cpp:252] TEST Top shape for layer 88 'ctx_output4/relu_mbox_conf' 4 24 3 6 (1728)
I0323 22:48:37.264827  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_perm' of type 'Permute'
I0323 22:48:37.264833  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.264845  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_perm (89)
I0323 22:48:37.264853  1439 net.cpp:561] ctx_output4/relu_mbox_conf_perm <- ctx_output4/relu_mbox_conf
I0323 22:48:37.264859  1439 net.cpp:530] ctx_output4/relu_mbox_conf_perm -> ctx_output4/relu_mbox_conf_perm
I0323 22:48:37.265069  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_perm
I0323 22:48:37.265081  1439 net.cpp:252] TEST Top shape for layer 89 'ctx_output4/relu_mbox_conf_perm' 4 3 6 24 (1728)
I0323 22:48:37.265087  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_flat' of type 'Flatten'
I0323 22:48:37.265092  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.265100  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_flat (90)
I0323 22:48:37.265105  1439 net.cpp:561] ctx_output4/relu_mbox_conf_flat <- ctx_output4/relu_mbox_conf_perm
I0323 22:48:37.265112  1439 net.cpp:530] ctx_output4/relu_mbox_conf_flat -> ctx_output4/relu_mbox_conf_flat
I0323 22:48:37.265159  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_flat
I0323 22:48:37.265170  1439 net.cpp:252] TEST Top shape for layer 90 'ctx_output4/relu_mbox_conf_flat' 4 432 (1728)
I0323 22:48:37.265185  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_priorbox' of type 'PriorBox'
I0323 22:48:37.265192  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.265199  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_priorbox (91)
I0323 22:48:37.265205  1439 net.cpp:561] ctx_output4/relu_mbox_priorbox <- ctx_output4_ctx_output4/relu_0_split_2
I0323 22:48:37.265213  1439 net.cpp:561] ctx_output4/relu_mbox_priorbox <- data_data_0_split_4
I0323 22:48:37.265219  1439 net.cpp:530] ctx_output4/relu_mbox_priorbox -> ctx_output4/relu_mbox_priorbox
I0323 22:48:37.265269  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_priorbox
I0323 22:48:37.265280  1439 net.cpp:252] TEST Top shape for layer 91 'ctx_output4/relu_mbox_priorbox' 1 2 432 (864)
I0323 22:48:37.265286  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc' of type 'Convolution'
I0323 22:48:37.265292  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.265311  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc (92)
I0323 22:48:37.265318  1439 net.cpp:561] ctx_output5/relu_mbox_loc <- ctx_output5_ctx_output5/relu_0_split_0
I0323 22:48:37.265326  1439 net.cpp:530] ctx_output5/relu_mbox_loc -> ctx_output5/relu_mbox_loc
I0323 22:48:37.265995  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_loc
I0323 22:48:37.266008  1439 net.cpp:252] TEST Top shape for layer 92 'ctx_output5/relu_mbox_loc' 4 16 2 3 (384)
I0323 22:48:37.266017  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_perm' of type 'Permute'
I0323 22:48:37.266023  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.266036  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_perm (93)
I0323 22:48:37.266041  1439 net.cpp:561] ctx_output5/relu_mbox_loc_perm <- ctx_output5/relu_mbox_loc
I0323 22:48:37.266048  1439 net.cpp:530] ctx_output5/relu_mbox_loc_perm -> ctx_output5/relu_mbox_loc_perm
I0323 22:48:37.266257  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_perm
I0323 22:48:37.266269  1439 net.cpp:252] TEST Top shape for layer 93 'ctx_output5/relu_mbox_loc_perm' 4 2 3 16 (384)
I0323 22:48:37.266276  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_flat' of type 'Flatten'
I0323 22:48:37.266281  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.266289  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_flat (94)
I0323 22:48:37.266294  1439 net.cpp:561] ctx_output5/relu_mbox_loc_flat <- ctx_output5/relu_mbox_loc_perm
I0323 22:48:37.266301  1439 net.cpp:530] ctx_output5/relu_mbox_loc_flat -> ctx_output5/relu_mbox_loc_flat
I0323 22:48:37.266347  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_flat
I0323 22:48:37.266358  1439 net.cpp:252] TEST Top shape for layer 94 'ctx_output5/relu_mbox_loc_flat' 4 96 (384)
I0323 22:48:37.266366  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf' of type 'Convolution'
I0323 22:48:37.266371  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.266386  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf (95)
I0323 22:48:37.266393  1439 net.cpp:561] ctx_output5/relu_mbox_conf <- ctx_output5_ctx_output5/relu_0_split_1
I0323 22:48:37.266400  1439 net.cpp:530] ctx_output5/relu_mbox_conf -> ctx_output5/relu_mbox_conf
I0323 22:48:37.267055  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_conf
I0323 22:48:37.267067  1439 net.cpp:252] TEST Top shape for layer 95 'ctx_output5/relu_mbox_conf' 4 16 2 3 (384)
I0323 22:48:37.267077  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_perm' of type 'Permute'
I0323 22:48:37.267083  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.267096  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_perm (96)
I0323 22:48:37.267112  1439 net.cpp:561] ctx_output5/relu_mbox_conf_perm <- ctx_output5/relu_mbox_conf
I0323 22:48:37.267119  1439 net.cpp:530] ctx_output5/relu_mbox_conf_perm -> ctx_output5/relu_mbox_conf_perm
I0323 22:48:37.267328  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_perm
I0323 22:48:37.267339  1439 net.cpp:252] TEST Top shape for layer 96 'ctx_output5/relu_mbox_conf_perm' 4 2 3 16 (384)
I0323 22:48:37.267345  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_flat' of type 'Flatten'
I0323 22:48:37.267351  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.267359  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_flat (97)
I0323 22:48:37.267366  1439 net.cpp:561] ctx_output5/relu_mbox_conf_flat <- ctx_output5/relu_mbox_conf_perm
I0323 22:48:37.267372  1439 net.cpp:530] ctx_output5/relu_mbox_conf_flat -> ctx_output5/relu_mbox_conf_flat
I0323 22:48:37.267419  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_flat
I0323 22:48:37.267431  1439 net.cpp:252] TEST Top shape for layer 97 'ctx_output5/relu_mbox_conf_flat' 4 96 (384)
I0323 22:48:37.267436  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_priorbox' of type 'PriorBox'
I0323 22:48:37.267442  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.267449  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_priorbox (98)
I0323 22:48:37.267455  1439 net.cpp:561] ctx_output5/relu_mbox_priorbox <- ctx_output5_ctx_output5/relu_0_split_2
I0323 22:48:37.267463  1439 net.cpp:561] ctx_output5/relu_mbox_priorbox <- data_data_0_split_5
I0323 22:48:37.267470  1439 net.cpp:530] ctx_output5/relu_mbox_priorbox -> ctx_output5/relu_mbox_priorbox
I0323 22:48:37.267520  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_priorbox
I0323 22:48:37.267531  1439 net.cpp:252] TEST Top shape for layer 98 'ctx_output5/relu_mbox_priorbox' 1 2 96 (192)
I0323 22:48:37.267537  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc' of type 'Convolution'
I0323 22:48:37.267544  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.267560  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc (99)
I0323 22:48:37.267567  1439 net.cpp:561] ctx_output6/relu_mbox_loc <- ctx_output6_ctx_output6/relu_0_split_0
I0323 22:48:37.267573  1439 net.cpp:530] ctx_output6/relu_mbox_loc -> ctx_output6/relu_mbox_loc
I0323 22:48:37.268223  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_loc
I0323 22:48:37.268235  1439 net.cpp:252] TEST Top shape for layer 99 'ctx_output6/relu_mbox_loc' 4 16 1 2 (128)
I0323 22:48:37.268244  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_perm' of type 'Permute'
I0323 22:48:37.268251  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.268262  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_perm (100)
I0323 22:48:37.268270  1439 net.cpp:561] ctx_output6/relu_mbox_loc_perm <- ctx_output6/relu_mbox_loc
I0323 22:48:37.268276  1439 net.cpp:530] ctx_output6/relu_mbox_loc_perm -> ctx_output6/relu_mbox_loc_perm
I0323 22:48:37.268486  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_perm
I0323 22:48:37.268497  1439 net.cpp:252] TEST Top shape for layer 100 'ctx_output6/relu_mbox_loc_perm' 4 1 2 16 (128)
I0323 22:48:37.268503  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_flat' of type 'Flatten'
I0323 22:48:37.268509  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.268517  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_flat (101)
I0323 22:48:37.268522  1439 net.cpp:561] ctx_output6/relu_mbox_loc_flat <- ctx_output6/relu_mbox_loc_perm
I0323 22:48:37.268528  1439 net.cpp:530] ctx_output6/relu_mbox_loc_flat -> ctx_output6/relu_mbox_loc_flat
I0323 22:48:37.268574  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_flat
I0323 22:48:37.268594  1439 net.cpp:252] TEST Top shape for layer 101 'ctx_output6/relu_mbox_loc_flat' 4 32 (128)
I0323 22:48:37.268601  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf' of type 'Convolution'
I0323 22:48:37.268607  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.268625  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf (102)
I0323 22:48:37.268632  1439 net.cpp:561] ctx_output6/relu_mbox_conf <- ctx_output6_ctx_output6/relu_0_split_1
I0323 22:48:37.268640  1439 net.cpp:530] ctx_output6/relu_mbox_conf -> ctx_output6/relu_mbox_conf
I0323 22:48:37.269294  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_conf
I0323 22:48:37.269307  1439 net.cpp:252] TEST Top shape for layer 102 'ctx_output6/relu_mbox_conf' 4 16 1 2 (128)
I0323 22:48:37.269316  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_perm' of type 'Permute'
I0323 22:48:37.269322  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.269333  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_perm (103)
I0323 22:48:37.269340  1439 net.cpp:561] ctx_output6/relu_mbox_conf_perm <- ctx_output6/relu_mbox_conf
I0323 22:48:37.269347  1439 net.cpp:530] ctx_output6/relu_mbox_conf_perm -> ctx_output6/relu_mbox_conf_perm
I0323 22:48:37.269556  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_perm
I0323 22:48:37.269568  1439 net.cpp:252] TEST Top shape for layer 103 'ctx_output6/relu_mbox_conf_perm' 4 1 2 16 (128)
I0323 22:48:37.269574  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_flat' of type 'Flatten'
I0323 22:48:37.269579  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.269587  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_flat (104)
I0323 22:48:37.269593  1439 net.cpp:561] ctx_output6/relu_mbox_conf_flat <- ctx_output6/relu_mbox_conf_perm
I0323 22:48:37.269599  1439 net.cpp:530] ctx_output6/relu_mbox_conf_flat -> ctx_output6/relu_mbox_conf_flat
I0323 22:48:37.269646  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_flat
I0323 22:48:37.269657  1439 net.cpp:252] TEST Top shape for layer 104 'ctx_output6/relu_mbox_conf_flat' 4 32 (128)
I0323 22:48:37.269664  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_priorbox' of type 'PriorBox'
I0323 22:48:37.269670  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.269678  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_priorbox (105)
I0323 22:48:37.269685  1439 net.cpp:561] ctx_output6/relu_mbox_priorbox <- ctx_output6_ctx_output6/relu_0_split_2
I0323 22:48:37.269698  1439 net.cpp:561] ctx_output6/relu_mbox_priorbox <- data_data_0_split_6
I0323 22:48:37.269706  1439 net.cpp:530] ctx_output6/relu_mbox_priorbox -> ctx_output6/relu_mbox_priorbox
I0323 22:48:37.269754  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_priorbox
I0323 22:48:37.269767  1439 net.cpp:252] TEST Top shape for layer 105 'ctx_output6/relu_mbox_priorbox' 1 2 32 (64)
I0323 22:48:37.269773  1439 layer_factory.hpp:136] Creating layer 'mbox_loc' of type 'Concat'
I0323 22:48:37.269778  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.269788  1439 net.cpp:184] Created Layer mbox_loc (106)
I0323 22:48:37.269794  1439 net.cpp:561] mbox_loc <- ctx_output1/relu_mbox_loc_flat
I0323 22:48:37.269801  1439 net.cpp:561] mbox_loc <- ctx_output2/relu_mbox_loc_flat
I0323 22:48:37.269807  1439 net.cpp:561] mbox_loc <- ctx_output3/relu_mbox_loc_flat
I0323 22:48:37.269814  1439 net.cpp:561] mbox_loc <- ctx_output4/relu_mbox_loc_flat
I0323 22:48:37.269820  1439 net.cpp:561] mbox_loc <- ctx_output5/relu_mbox_loc_flat
I0323 22:48:37.269825  1439 net.cpp:561] mbox_loc <- ctx_output6/relu_mbox_loc_flat
I0323 22:48:37.269831  1439 net.cpp:530] mbox_loc -> mbox_loc
I0323 22:48:37.269883  1439 net.cpp:245] Setting up mbox_loc
I0323 22:48:37.269903  1439 net.cpp:252] TEST Top shape for layer 106 'mbox_loc' 4 69200 (276800)
I0323 22:48:37.269910  1439 layer_factory.hpp:136] Creating layer 'mbox_conf' of type 'Concat'
I0323 22:48:37.269915  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.269923  1439 net.cpp:184] Created Layer mbox_conf (107)
I0323 22:48:37.269929  1439 net.cpp:561] mbox_conf <- ctx_output1/relu_mbox_conf_flat
I0323 22:48:37.269937  1439 net.cpp:561] mbox_conf <- ctx_output2/relu_mbox_conf_flat
I0323 22:48:37.269942  1439 net.cpp:561] mbox_conf <- ctx_output3/relu_mbox_conf_flat
I0323 22:48:37.269948  1439 net.cpp:561] mbox_conf <- ctx_output4/relu_mbox_conf_flat
I0323 22:48:37.269953  1439 net.cpp:561] mbox_conf <- ctx_output5/relu_mbox_conf_flat
I0323 22:48:37.269959  1439 net.cpp:561] mbox_conf <- ctx_output6/relu_mbox_conf_flat
I0323 22:48:37.269964  1439 net.cpp:530] mbox_conf -> mbox_conf
I0323 22:48:37.270015  1439 net.cpp:245] Setting up mbox_conf
I0323 22:48:37.270025  1439 net.cpp:252] TEST Top shape for layer 107 'mbox_conf' 4 69200 (276800)
I0323 22:48:37.270031  1439 layer_factory.hpp:136] Creating layer 'mbox_priorbox' of type 'Concat'
I0323 22:48:37.270037  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.270046  1439 net.cpp:184] Created Layer mbox_priorbox (108)
I0323 22:48:37.270052  1439 net.cpp:561] mbox_priorbox <- ctx_output1/relu_mbox_priorbox
I0323 22:48:37.270059  1439 net.cpp:561] mbox_priorbox <- ctx_output2/relu_mbox_priorbox
I0323 22:48:37.270066  1439 net.cpp:561] mbox_priorbox <- ctx_output3/relu_mbox_priorbox
I0323 22:48:37.270071  1439 net.cpp:561] mbox_priorbox <- ctx_output4/relu_mbox_priorbox
I0323 22:48:37.270076  1439 net.cpp:561] mbox_priorbox <- ctx_output5/relu_mbox_priorbox
I0323 22:48:37.270082  1439 net.cpp:561] mbox_priorbox <- ctx_output6/relu_mbox_priorbox
I0323 22:48:37.270087  1439 net.cpp:530] mbox_priorbox -> mbox_priorbox
I0323 22:48:37.270135  1439 net.cpp:245] Setting up mbox_priorbox
I0323 22:48:37.270148  1439 net.cpp:252] TEST Top shape for layer 108 'mbox_priorbox' 1 2 69200 (138400)
I0323 22:48:37.270153  1439 layer_factory.hpp:136] Creating layer 'mbox_conf_reshape' of type 'Reshape'
I0323 22:48:37.270159  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.270170  1439 net.cpp:184] Created Layer mbox_conf_reshape (109)
I0323 22:48:37.270176  1439 net.cpp:561] mbox_conf_reshape <- mbox_conf
I0323 22:48:37.270182  1439 net.cpp:530] mbox_conf_reshape -> mbox_conf_reshape
I0323 22:48:37.270232  1439 net.cpp:245] Setting up mbox_conf_reshape
I0323 22:48:37.270244  1439 net.cpp:252] TEST Top shape for layer 109 'mbox_conf_reshape' 4 17300 4 (276800)
I0323 22:48:37.270251  1439 layer_factory.hpp:136] Creating layer 'mbox_conf_softmax' of type 'Softmax'
I0323 22:48:37.270256  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.270272  1439 net.cpp:184] Created Layer mbox_conf_softmax (110)
I0323 22:48:37.270279  1439 net.cpp:561] mbox_conf_softmax <- mbox_conf_reshape
I0323 22:48:37.270285  1439 net.cpp:530] mbox_conf_softmax -> mbox_conf_softmax
I0323 22:48:37.270407  1439 net.cpp:245] Setting up mbox_conf_softmax
I0323 22:48:37.270418  1439 net.cpp:252] TEST Top shape for layer 110 'mbox_conf_softmax' 4 17300 4 (276800)
I0323 22:48:37.270424  1439 layer_factory.hpp:136] Creating layer 'mbox_conf_flatten' of type 'Flatten'
I0323 22:48:37.270431  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.270437  1439 net.cpp:184] Created Layer mbox_conf_flatten (111)
I0323 22:48:37.270442  1439 net.cpp:561] mbox_conf_flatten <- mbox_conf_softmax
I0323 22:48:37.270449  1439 net.cpp:530] mbox_conf_flatten -> mbox_conf_flatten
I0323 22:48:37.270498  1439 net.cpp:245] Setting up mbox_conf_flatten
I0323 22:48:37.270509  1439 net.cpp:252] TEST Top shape for layer 111 'mbox_conf_flatten' 4 69200 (276800)
I0323 22:48:37.270524  1439 layer_factory.hpp:136] Creating layer 'detection_out' of type 'DetectionOutput'
I0323 22:48:37.270530  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.270551  1439 net.cpp:184] Created Layer detection_out (112)
I0323 22:48:37.270558  1439 net.cpp:561] detection_out <- mbox_loc
I0323 22:48:37.270565  1439 net.cpp:561] detection_out <- mbox_conf_flatten
I0323 22:48:37.270571  1439 net.cpp:561] detection_out <- mbox_priorbox
I0323 22:48:37.270577  1439 net.cpp:530] detection_out -> detection_out
I0323 22:48:37.272238  1439 net.cpp:245] Setting up detection_out
I0323 22:48:37.272251  1439 net.cpp:252] TEST Top shape for layer 112 'detection_out' 1 1 1 7 (7)
I0323 22:48:37.272258  1439 layer_factory.hpp:136] Creating layer 'detection_eval' of type 'DetectionEvaluate'
I0323 22:48:37.272264  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.272274  1439 net.cpp:184] Created Layer detection_eval (113)
I0323 22:48:37.272280  1439 net.cpp:561] detection_eval <- detection_out
I0323 22:48:37.272286  1439 net.cpp:561] detection_eval <- label
I0323 22:48:37.272294  1439 net.cpp:530] detection_eval -> detection_eval
I0323 22:48:37.273342  1439 net.cpp:245] Setting up detection_eval
I0323 22:48:37.273355  1439 net.cpp:252] TEST Top shape for layer 113 'detection_eval' 1 1 4 5 (20)
I0323 22:48:37.273362  1439 net.cpp:325] detection_eval does not need backward computation.
I0323 22:48:37.273367  1439 net.cpp:325] detection_out does not need backward computation.
I0323 22:48:37.273373  1439 net.cpp:325] mbox_conf_flatten does not need backward computation.
I0323 22:48:37.273377  1439 net.cpp:325] mbox_conf_softmax does not need backward computation.
I0323 22:48:37.273382  1439 net.cpp:325] mbox_conf_reshape does not need backward computation.
I0323 22:48:37.273387  1439 net.cpp:325] mbox_priorbox does not need backward computation.
I0323 22:48:37.273393  1439 net.cpp:325] mbox_conf does not need backward computation.
I0323 22:48:37.273401  1439 net.cpp:325] mbox_loc does not need backward computation.
I0323 22:48:37.273406  1439 net.cpp:325] ctx_output6/relu_mbox_priorbox does not need backward computation.
I0323 22:48:37.273412  1439 net.cpp:325] ctx_output6/relu_mbox_conf_flat does not need backward computation.
I0323 22:48:37.273417  1439 net.cpp:325] ctx_output6/relu_mbox_conf_perm does not need backward computation.
I0323 22:48:37.273422  1439 net.cpp:325] ctx_output6/relu_mbox_conf does not need backward computation.
I0323 22:48:37.273427  1439 net.cpp:325] ctx_output6/relu_mbox_loc_flat does not need backward computation.
I0323 22:48:37.273432  1439 net.cpp:325] ctx_output6/relu_mbox_loc_perm does not need backward computation.
I0323 22:48:37.273437  1439 net.cpp:325] ctx_output6/relu_mbox_loc does not need backward computation.
I0323 22:48:37.273442  1439 net.cpp:325] ctx_output5/relu_mbox_priorbox does not need backward computation.
I0323 22:48:37.273447  1439 net.cpp:325] ctx_output5/relu_mbox_conf_flat does not need backward computation.
I0323 22:48:37.273452  1439 net.cpp:325] ctx_output5/relu_mbox_conf_perm does not need backward computation.
I0323 22:48:37.273457  1439 net.cpp:325] ctx_output5/relu_mbox_conf does not need backward computation.
I0323 22:48:37.273461  1439 net.cpp:325] ctx_output5/relu_mbox_loc_flat does not need backward computation.
I0323 22:48:37.273466  1439 net.cpp:325] ctx_output5/relu_mbox_loc_perm does not need backward computation.
I0323 22:48:37.273471  1439 net.cpp:325] ctx_output5/relu_mbox_loc does not need backward computation.
I0323 22:48:37.273476  1439 net.cpp:325] ctx_output4/relu_mbox_priorbox does not need backward computation.
I0323 22:48:37.273481  1439 net.cpp:325] ctx_output4/relu_mbox_conf_flat does not need backward computation.
I0323 22:48:37.273486  1439 net.cpp:325] ctx_output4/relu_mbox_conf_perm does not need backward computation.
I0323 22:48:37.273491  1439 net.cpp:325] ctx_output4/relu_mbox_conf does not need backward computation.
I0323 22:48:37.273495  1439 net.cpp:325] ctx_output4/relu_mbox_loc_flat does not need backward computation.
I0323 22:48:37.273509  1439 net.cpp:325] ctx_output4/relu_mbox_loc_perm does not need backward computation.
I0323 22:48:37.273515  1439 net.cpp:325] ctx_output4/relu_mbox_loc does not need backward computation.
I0323 22:48:37.273520  1439 net.cpp:325] ctx_output3/relu_mbox_priorbox does not need backward computation.
I0323 22:48:37.273525  1439 net.cpp:325] ctx_output3/relu_mbox_conf_flat does not need backward computation.
I0323 22:48:37.273530  1439 net.cpp:325] ctx_output3/relu_mbox_conf_perm does not need backward computation.
I0323 22:48:37.273535  1439 net.cpp:325] ctx_output3/relu_mbox_conf does not need backward computation.
I0323 22:48:37.273540  1439 net.cpp:325] ctx_output3/relu_mbox_loc_flat does not need backward computation.
I0323 22:48:37.273545  1439 net.cpp:325] ctx_output3/relu_mbox_loc_perm does not need backward computation.
I0323 22:48:37.273550  1439 net.cpp:325] ctx_output3/relu_mbox_loc does not need backward computation.
I0323 22:48:37.273555  1439 net.cpp:325] ctx_output2/relu_mbox_priorbox does not need backward computation.
I0323 22:48:37.273561  1439 net.cpp:325] ctx_output2/relu_mbox_conf_flat does not need backward computation.
I0323 22:48:37.273566  1439 net.cpp:325] ctx_output2/relu_mbox_conf_perm does not need backward computation.
I0323 22:48:37.273571  1439 net.cpp:325] ctx_output2/relu_mbox_conf does not need backward computation.
I0323 22:48:37.273576  1439 net.cpp:325] ctx_output2/relu_mbox_loc_flat does not need backward computation.
I0323 22:48:37.273581  1439 net.cpp:325] ctx_output2/relu_mbox_loc_perm does not need backward computation.
I0323 22:48:37.273586  1439 net.cpp:325] ctx_output2/relu_mbox_loc does not need backward computation.
I0323 22:48:37.273591  1439 net.cpp:325] ctx_output1/relu_mbox_priorbox does not need backward computation.
I0323 22:48:37.273597  1439 net.cpp:325] ctx_output1/relu_mbox_conf_flat does not need backward computation.
I0323 22:48:37.273602  1439 net.cpp:325] ctx_output1/relu_mbox_conf_perm does not need backward computation.
I0323 22:48:37.273607  1439 net.cpp:325] ctx_output1/relu_mbox_conf does not need backward computation.
I0323 22:48:37.273612  1439 net.cpp:325] ctx_output1/relu_mbox_loc_flat does not need backward computation.
I0323 22:48:37.273617  1439 net.cpp:325] ctx_output1/relu_mbox_loc_perm does not need backward computation.
I0323 22:48:37.273622  1439 net.cpp:325] ctx_output1/relu_mbox_loc does not need backward computation.
I0323 22:48:37.273627  1439 net.cpp:325] ctx_output6_ctx_output6/relu_0_split does not need backward computation.
I0323 22:48:37.273633  1439 net.cpp:325] ctx_output6/relu does not need backward computation.
I0323 22:48:37.273638  1439 net.cpp:325] ctx_output6 does not need backward computation.
I0323 22:48:37.273643  1439 net.cpp:325] ctx_output5_ctx_output5/relu_0_split does not need backward computation.
I0323 22:48:37.273648  1439 net.cpp:325] ctx_output5/relu does not need backward computation.
I0323 22:48:37.273653  1439 net.cpp:325] ctx_output5 does not need backward computation.
I0323 22:48:37.273658  1439 net.cpp:325] ctx_output4_ctx_output4/relu_0_split does not need backward computation.
I0323 22:48:37.273663  1439 net.cpp:325] ctx_output4/relu does not need backward computation.
I0323 22:48:37.273669  1439 net.cpp:325] ctx_output4 does not need backward computation.
I0323 22:48:37.273674  1439 net.cpp:325] ctx_output3_ctx_output3/relu_0_split does not need backward computation.
I0323 22:48:37.273679  1439 net.cpp:325] ctx_output3/relu does not need backward computation.
I0323 22:48:37.273684  1439 net.cpp:325] ctx_output3 does not need backward computation.
I0323 22:48:37.273699  1439 net.cpp:325] ctx_output2_ctx_output2/relu_0_split does not need backward computation.
I0323 22:48:37.273707  1439 net.cpp:325] ctx_output2/relu does not need backward computation.
I0323 22:48:37.273712  1439 net.cpp:325] ctx_output2 does not need backward computation.
I0323 22:48:37.273718  1439 net.cpp:325] ctx_output1_ctx_output1/relu_0_split does not need backward computation.
I0323 22:48:37.273732  1439 net.cpp:325] ctx_output1/relu does not need backward computation.
I0323 22:48:37.273738  1439 net.cpp:325] ctx_output1 does not need backward computation.
I0323 22:48:37.273744  1439 net.cpp:325] pool9 does not need backward computation.
I0323 22:48:37.273749  1439 net.cpp:325] pool8_pool8_0_split does not need backward computation.
I0323 22:48:37.273756  1439 net.cpp:325] pool8 does not need backward computation.
I0323 22:48:37.273761  1439 net.cpp:325] pool7_pool7_0_split does not need backward computation.
I0323 22:48:37.273766  1439 net.cpp:325] pool7 does not need backward computation.
I0323 22:48:37.273772  1439 net.cpp:325] pool6_pool6_0_split does not need backward computation.
I0323 22:48:37.273777  1439 net.cpp:325] pool6 does not need backward computation.
I0323 22:48:37.273782  1439 net.cpp:325] res5a_branch2b_res5a_branch2b/relu_0_split does not need backward computation.
I0323 22:48:37.273787  1439 net.cpp:325] res5a_branch2b/relu does not need backward computation.
I0323 22:48:37.273792  1439 net.cpp:325] res5a_branch2b/bn does not need backward computation.
I0323 22:48:37.273797  1439 net.cpp:325] res5a_branch2b does not need backward computation.
I0323 22:48:37.273802  1439 net.cpp:325] res5a_branch2a/relu does not need backward computation.
I0323 22:48:37.273807  1439 net.cpp:325] res5a_branch2a/bn does not need backward computation.
I0323 22:48:37.273811  1439 net.cpp:325] res5a_branch2a does not need backward computation.
I0323 22:48:37.273816  1439 net.cpp:325] pool4 does not need backward computation.
I0323 22:48:37.273821  1439 net.cpp:325] res4a_branch2b/relu does not need backward computation.
I0323 22:48:37.273826  1439 net.cpp:325] res4a_branch2b/bn does not need backward computation.
I0323 22:48:37.273830  1439 net.cpp:325] res4a_branch2b does not need backward computation.
I0323 22:48:37.273836  1439 net.cpp:325] res4a_branch2a/relu does not need backward computation.
I0323 22:48:37.273841  1439 net.cpp:325] res4a_branch2a/bn does not need backward computation.
I0323 22:48:37.273846  1439 net.cpp:325] res4a_branch2a does not need backward computation.
I0323 22:48:37.273851  1439 net.cpp:325] pool3 does not need backward computation.
I0323 22:48:37.273856  1439 net.cpp:325] res3a_branch2b_res3a_branch2b/relu_0_split does not need backward computation.
I0323 22:48:37.273862  1439 net.cpp:325] res3a_branch2b/relu does not need backward computation.
I0323 22:48:37.273867  1439 net.cpp:325] res3a_branch2b/bn does not need backward computation.
I0323 22:48:37.273871  1439 net.cpp:325] res3a_branch2b does not need backward computation.
I0323 22:48:37.273877  1439 net.cpp:325] res3a_branch2a/relu does not need backward computation.
I0323 22:48:37.273882  1439 net.cpp:325] res3a_branch2a/bn does not need backward computation.
I0323 22:48:37.273887  1439 net.cpp:325] res3a_branch2a does not need backward computation.
I0323 22:48:37.273892  1439 net.cpp:325] pool2 does not need backward computation.
I0323 22:48:37.273897  1439 net.cpp:325] res2a_branch2b/relu does not need backward computation.
I0323 22:48:37.273902  1439 net.cpp:325] res2a_branch2b/bn does not need backward computation.
I0323 22:48:37.273907  1439 net.cpp:325] res2a_branch2b does not need backward computation.
I0323 22:48:37.273912  1439 net.cpp:325] res2a_branch2a/relu does not need backward computation.
I0323 22:48:37.273916  1439 net.cpp:325] res2a_branch2a/bn does not need backward computation.
I0323 22:48:37.273921  1439 net.cpp:325] res2a_branch2a does not need backward computation.
I0323 22:48:37.273926  1439 net.cpp:325] pool1 does not need backward computation.
I0323 22:48:37.273931  1439 net.cpp:325] conv1b/relu does not need backward computation.
I0323 22:48:37.273936  1439 net.cpp:325] conv1b/bn does not need backward computation.
I0323 22:48:37.273941  1439 net.cpp:325] conv1b does not need backward computation.
I0323 22:48:37.273947  1439 net.cpp:325] conv1a/relu does not need backward computation.
I0323 22:48:37.273952  1439 net.cpp:325] conv1a/bn does not need backward computation.
I0323 22:48:37.273962  1439 net.cpp:325] conv1a does not need backward computation.
I0323 22:48:37.273968  1439 net.cpp:325] data/bias does not need backward computation.
I0323 22:48:37.273974  1439 net.cpp:325] data_data_0_split does not need backward computation.
I0323 22:48:37.273979  1439 net.cpp:325] data does not need backward computation.
I0323 22:48:37.273984  1439 net.cpp:367] This network produces output detection_eval
I0323 22:48:37.274085  1439 net.cpp:389] Top memory (TEST) required for data: 606953552 diff: 606953552
I0323 22:48:37.274093  1439 net.cpp:392] Bottom memory (TEST) required for data: 606953472 diff: 606953472
I0323 22:48:37.274097  1439 net.cpp:395] Shared (in-place) memory (TEST) by data: 260857856 diff: 260857856
I0323 22:48:37.274102  1439 net.cpp:398] Parameters memory (TEST) required for data: 12464288 diff: 12464288
I0323 22:48:37.274107  1439 net.cpp:401] Parameters shared memory (TEST) by data: 0 diff: 0
I0323 22:48:37.274111  1439 net.cpp:407] Network initialization done.
I0323 22:48:37.274442  1439 solver.cpp:57] Solver scaffolding done.
I0323 22:48:37.282564  1439 caffe.cpp:143] Finetuning from /user/a0875091/files/work/bitbucket_TI/caffe-jacinto-models/scripts/training/ti-vgg-720x368-v2/JDetNet/20180211_01-20_ds_PSP_dsFac_32_fc_0_hdDS8_1_cnctHD_0_baseNW3hd_0_kerMbox_1_1stHdSameOpCh_1/sparse_fac0.5_0.8_53.26/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_38000_53.26.caffemodel
I0323 22:48:37.291489  1439 net.cpp:1094] Copying source layer data Type:AnnotatedData #blobs=0
I0323 22:48:37.291517  1439 net.cpp:1094] Copying source layer data_data_0_split Type:Split #blobs=0
I0323 22:48:37.291522  1439 net.cpp:1094] Copying source layer data/bias Type:Bias #blobs=1
I0323 22:48:37.291564  1439 net.cpp:1094] Copying source layer conv1a Type:Convolution #blobs=2
I0323 22:48:37.291586  1439 net.cpp:1094] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0323 22:48:37.291908  1439 net.cpp:1094] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0323 22:48:37.291919  1439 net.cpp:1094] Copying source layer conv1b Type:Convolution #blobs=2
I0323 22:48:37.291937  1439 net.cpp:1094] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0323 22:48:37.292167  1439 net.cpp:1094] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0323 22:48:37.292177  1439 net.cpp:1094] Copying source layer pool1 Type:Pooling #blobs=0
I0323 22:48:37.292182  1439 net.cpp:1094] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0323 22:48:37.292210  1439 net.cpp:1094] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0323 22:48:37.292443  1439 net.cpp:1094] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0323 22:48:37.292452  1439 net.cpp:1094] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0323 22:48:37.292474  1439 net.cpp:1094] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0323 22:48:37.292697  1439 net.cpp:1094] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0323 22:48:37.292707  1439 net.cpp:1094] Copying source layer pool2 Type:Pooling #blobs=0
I0323 22:48:37.292712  1439 net.cpp:1094] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0323 22:48:37.292771  1439 net.cpp:1094] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0323 22:48:37.292984  1439 net.cpp:1094] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0323 22:48:37.292994  1439 net.cpp:1094] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0323 22:48:37.293036  1439 net.cpp:1094] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0323 22:48:37.293243  1439 net.cpp:1094] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0323 22:48:37.293254  1439 net.cpp:1094] Copying source layer res3a_branch2b_res3a_branch2b/relu_0_split Type:Split #blobs=0
I0323 22:48:37.293259  1439 net.cpp:1094] Copying source layer pool3 Type:Pooling #blobs=0
I0323 22:48:37.293264  1439 net.cpp:1094] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0323 22:48:37.293478  1439 net.cpp:1094] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0323 22:48:37.293678  1439 net.cpp:1094] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0323 22:48:37.293687  1439 net.cpp:1094] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0323 22:48:37.293807  1439 net.cpp:1094] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0323 22:48:37.294010  1439 net.cpp:1094] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0323 22:48:37.294020  1439 net.cpp:1094] Copying source layer pool4 Type:Pooling #blobs=0
I0323 22:48:37.294025  1439 net.cpp:1094] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0323 22:48:37.294644  1439 net.cpp:1094] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0323 22:48:37.294864  1439 net.cpp:1094] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0323 22:48:37.294874  1439 net.cpp:1094] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0323 22:48:37.295181  1439 net.cpp:1094] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0323 22:48:37.295367  1439 net.cpp:1094] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0323 22:48:37.295377  1439 net.cpp:1094] Copying source layer res5a_branch2b_res5a_branch2b/relu_0_split Type:Split #blobs=0
I0323 22:48:37.295382  1439 net.cpp:1094] Copying source layer pool6 Type:Pooling #blobs=0
I0323 22:48:37.295387  1439 net.cpp:1094] Copying source layer pool6_pool6_0_split Type:Split #blobs=0
I0323 22:48:37.295390  1439 net.cpp:1094] Copying source layer pool7 Type:Pooling #blobs=0
I0323 22:48:37.295395  1439 net.cpp:1094] Copying source layer pool7_pool7_0_split Type:Split #blobs=0
I0323 22:48:37.295399  1439 net.cpp:1094] Copying source layer pool8 Type:Pooling #blobs=0
I0323 22:48:37.295406  1439 net.cpp:1094] Copying source layer pool8_pool8_0_split Type:Split #blobs=0
I0323 22:48:37.295411  1439 net.cpp:1094] Copying source layer pool9 Type:Pooling #blobs=0
I0323 22:48:37.295415  1439 net.cpp:1094] Copying source layer ctx_output1 Type:Convolution #blobs=2
I0323 22:48:37.295451  1439 net.cpp:1094] Copying source layer ctx_output1/relu Type:ReLU #blobs=0
I0323 22:48:37.295460  1439 net.cpp:1094] Copying source layer ctx_output1_ctx_output1/relu_0_split Type:Split #blobs=0
I0323 22:48:37.295465  1439 net.cpp:1094] Copying source layer ctx_output2 Type:Convolution #blobs=2
I0323 22:48:37.295548  1439 net.cpp:1094] Copying source layer ctx_output2/relu Type:ReLU #blobs=0
I0323 22:48:37.295557  1439 net.cpp:1094] Copying source layer ctx_output2_ctx_output2/relu_0_split Type:Split #blobs=0
I0323 22:48:37.295562  1439 net.cpp:1094] Copying source layer ctx_output3 Type:Convolution #blobs=2
I0323 22:48:37.295646  1439 net.cpp:1094] Copying source layer ctx_output3/relu Type:ReLU #blobs=0
I0323 22:48:37.295655  1439 net.cpp:1094] Copying source layer ctx_output3_ctx_output3/relu_0_split Type:Split #blobs=0
I0323 22:48:37.295660  1439 net.cpp:1094] Copying source layer ctx_output4 Type:Convolution #blobs=2
I0323 22:48:37.295742  1439 net.cpp:1094] Copying source layer ctx_output4/relu Type:ReLU #blobs=0
I0323 22:48:37.295752  1439 net.cpp:1094] Copying source layer ctx_output4_ctx_output4/relu_0_split Type:Split #blobs=0
I0323 22:48:37.295756  1439 net.cpp:1094] Copying source layer ctx_output5 Type:Convolution #blobs=2
I0323 22:48:37.295836  1439 net.cpp:1094] Copying source layer ctx_output5/relu Type:ReLU #blobs=0
I0323 22:48:37.295846  1439 net.cpp:1094] Copying source layer ctx_output5_ctx_output5/relu_0_split Type:Split #blobs=0
I0323 22:48:37.295850  1439 net.cpp:1094] Copying source layer ctx_output6 Type:Convolution #blobs=2
I0323 22:48:37.295934  1439 net.cpp:1094] Copying source layer ctx_output6/relu Type:ReLU #blobs=0
I0323 22:48:37.295944  1439 net.cpp:1094] Copying source layer ctx_output6_ctx_output6/relu_0_split Type:Split #blobs=0
I0323 22:48:37.295949  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc Type:Convolution #blobs=2
I0323 22:48:37.295967  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc_perm Type:Permute #blobs=0
I0323 22:48:37.295995  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc_flat Type:Flatten #blobs=0
I0323 22:48:37.296000  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf Type:Convolution #blobs=2
I0323 22:48:37.296020  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf_perm Type:Permute #blobs=0
I0323 22:48:37.296027  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf_flat Type:Flatten #blobs=0
I0323 22:48:37.296031  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_priorbox Type:PriorBox #blobs=0
I0323 22:48:37.296036  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc Type:Convolution #blobs=2
I0323 22:48:37.296056  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc_perm Type:Permute #blobs=0
I0323 22:48:37.296062  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc_flat Type:Flatten #blobs=0
I0323 22:48:37.296066  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf Type:Convolution #blobs=2
I0323 22:48:37.296085  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf_perm Type:Permute #blobs=0
I0323 22:48:37.296092  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf_flat Type:Flatten #blobs=0
I0323 22:48:37.296097  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_priorbox Type:PriorBox #blobs=0
I0323 22:48:37.296103  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc Type:Convolution #blobs=2
I0323 22:48:37.296120  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc_perm Type:Permute #blobs=0
I0323 22:48:37.296128  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc_flat Type:Flatten #blobs=0
I0323 22:48:37.296133  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf Type:Convolution #blobs=2
I0323 22:48:37.296152  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf_perm Type:Permute #blobs=0
I0323 22:48:37.296159  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf_flat Type:Flatten #blobs=0
I0323 22:48:37.296164  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_priorbox Type:PriorBox #blobs=0
I0323 22:48:37.296169  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc Type:Convolution #blobs=2
I0323 22:48:37.296187  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc_perm Type:Permute #blobs=0
I0323 22:48:37.296195  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc_flat Type:Flatten #blobs=0
I0323 22:48:37.296200  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf Type:Convolution #blobs=2
I0323 22:48:37.296217  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf_perm Type:Permute #blobs=0
I0323 22:48:37.296224  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf_flat Type:Flatten #blobs=0
I0323 22:48:37.296228  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_priorbox Type:PriorBox #blobs=0
I0323 22:48:37.296233  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc Type:Convolution #blobs=2
I0323 22:48:37.296252  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc_perm Type:Permute #blobs=0
I0323 22:48:37.296258  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc_flat Type:Flatten #blobs=0
I0323 22:48:37.296263  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf Type:Convolution #blobs=2
I0323 22:48:37.296280  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf_perm Type:Permute #blobs=0
I0323 22:48:37.296288  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf_flat Type:Flatten #blobs=0
I0323 22:48:37.296293  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_priorbox Type:PriorBox #blobs=0
I0323 22:48:37.296298  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc Type:Convolution #blobs=2
I0323 22:48:37.296315  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc_perm Type:Permute #blobs=0
I0323 22:48:37.296329  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc_flat Type:Flatten #blobs=0
I0323 22:48:37.296335  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf Type:Convolution #blobs=2
I0323 22:48:37.296355  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf_perm Type:Permute #blobs=0
I0323 22:48:37.296362  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf_flat Type:Flatten #blobs=0
I0323 22:48:37.296367  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_priorbox Type:PriorBox #blobs=0
I0323 22:48:37.296371  1439 net.cpp:1094] Copying source layer mbox_loc Type:Concat #blobs=0
I0323 22:48:37.296376  1439 net.cpp:1094] Copying source layer mbox_conf Type:Concat #blobs=0
I0323 22:48:37.296380  1439 net.cpp:1094] Copying source layer mbox_priorbox Type:Concat #blobs=0
I0323 22:48:37.296386  1439 net.cpp:1094] Copying source layer mbox_loss Type:MultiBoxLoss #blobs=0
I0323 22:48:37.302093  1439 net.cpp:1094] Copying source layer data Type:AnnotatedData #blobs=0
I0323 22:48:37.302119  1439 net.cpp:1094] Copying source layer data_data_0_split Type:Split #blobs=0
I0323 22:48:37.302124  1439 net.cpp:1094] Copying source layer data/bias Type:Bias #blobs=1
I0323 22:48:37.302165  1439 net.cpp:1094] Copying source layer conv1a Type:Convolution #blobs=2
I0323 22:48:37.302186  1439 net.cpp:1094] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0323 22:48:37.302500  1439 net.cpp:1094] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0323 22:48:37.302510  1439 net.cpp:1094] Copying source layer conv1b Type:Convolution #blobs=2
I0323 22:48:37.302528  1439 net.cpp:1094] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0323 22:48:37.302763  1439 net.cpp:1094] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0323 22:48:37.302773  1439 net.cpp:1094] Copying source layer pool1 Type:Pooling #blobs=0
I0323 22:48:37.302778  1439 net.cpp:1094] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0323 22:48:37.302809  1439 net.cpp:1094] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0323 22:48:37.303040  1439 net.cpp:1094] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0323 22:48:37.303051  1439 net.cpp:1094] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0323 22:48:37.303074  1439 net.cpp:1094] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0323 22:48:37.303298  1439 net.cpp:1094] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0323 22:48:37.303309  1439 net.cpp:1094] Copying source layer pool2 Type:Pooling #blobs=0
I0323 22:48:37.303314  1439 net.cpp:1094] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0323 22:48:37.303372  1439 net.cpp:1094] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0323 22:48:37.303581  1439 net.cpp:1094] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0323 22:48:37.303591  1439 net.cpp:1094] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0323 22:48:37.303629  1439 net.cpp:1094] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0323 22:48:37.303825  1439 net.cpp:1094] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0323 22:48:37.303835  1439 net.cpp:1094] Copying source layer res3a_branch2b_res3a_branch2b/relu_0_split Type:Split #blobs=0
I0323 22:48:37.303840  1439 net.cpp:1094] Copying source layer pool3 Type:Pooling #blobs=0
I0323 22:48:37.303845  1439 net.cpp:1094] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0323 22:48:37.304018  1439 net.cpp:1094] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0323 22:48:37.304216  1439 net.cpp:1094] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0323 22:48:37.304226  1439 net.cpp:1094] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0323 22:48:37.304325  1439 net.cpp:1094] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0323 22:48:37.304522  1439 net.cpp:1094] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0323 22:48:37.304556  1439 net.cpp:1094] Copying source layer pool4 Type:Pooling #blobs=0
I0323 22:48:37.304563  1439 net.cpp:1094] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0323 22:48:37.305229  1439 net.cpp:1094] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0323 22:48:37.305444  1439 net.cpp:1094] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0323 22:48:37.305454  1439 net.cpp:1094] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0323 22:48:37.305786  1439 net.cpp:1094] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0323 22:48:37.305979  1439 net.cpp:1094] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0323 22:48:37.305989  1439 net.cpp:1094] Copying source layer res5a_branch2b_res5a_branch2b/relu_0_split Type:Split #blobs=0
I0323 22:48:37.305995  1439 net.cpp:1094] Copying source layer pool6 Type:Pooling #blobs=0
I0323 22:48:37.306000  1439 net.cpp:1094] Copying source layer pool6_pool6_0_split Type:Split #blobs=0
I0323 22:48:37.306005  1439 net.cpp:1094] Copying source layer pool7 Type:Pooling #blobs=0
I0323 22:48:37.306010  1439 net.cpp:1094] Copying source layer pool7_pool7_0_split Type:Split #blobs=0
I0323 22:48:37.306015  1439 net.cpp:1094] Copying source layer pool8 Type:Pooling #blobs=0
I0323 22:48:37.306018  1439 net.cpp:1094] Copying source layer pool8_pool8_0_split Type:Split #blobs=0
I0323 22:48:37.306023  1439 net.cpp:1094] Copying source layer pool9 Type:Pooling #blobs=0
I0323 22:48:37.306028  1439 net.cpp:1094] Copying source layer ctx_output1 Type:Convolution #blobs=2
I0323 22:48:37.306064  1439 net.cpp:1094] Copying source layer ctx_output1/relu Type:ReLU #blobs=0
I0323 22:48:37.306074  1439 net.cpp:1094] Copying source layer ctx_output1_ctx_output1/relu_0_split Type:Split #blobs=0
I0323 22:48:37.306079  1439 net.cpp:1094] Copying source layer ctx_output2 Type:Convolution #blobs=2
I0323 22:48:37.306172  1439 net.cpp:1094] Copying source layer ctx_output2/relu Type:ReLU #blobs=0
I0323 22:48:37.306181  1439 net.cpp:1094] Copying source layer ctx_output2_ctx_output2/relu_0_split Type:Split #blobs=0
I0323 22:48:37.306186  1439 net.cpp:1094] Copying source layer ctx_output3 Type:Convolution #blobs=2
I0323 22:48:37.306290  1439 net.cpp:1094] Copying source layer ctx_output3/relu Type:ReLU #blobs=0
I0323 22:48:37.306300  1439 net.cpp:1094] Copying source layer ctx_output3_ctx_output3/relu_0_split Type:Split #blobs=0
I0323 22:48:37.306305  1439 net.cpp:1094] Copying source layer ctx_output4 Type:Convolution #blobs=2
I0323 22:48:37.306398  1439 net.cpp:1094] Copying source layer ctx_output4/relu Type:ReLU #blobs=0
I0323 22:48:37.306408  1439 net.cpp:1094] Copying source layer ctx_output4_ctx_output4/relu_0_split Type:Split #blobs=0
I0323 22:48:37.306413  1439 net.cpp:1094] Copying source layer ctx_output5 Type:Convolution #blobs=2
I0323 22:48:37.306507  1439 net.cpp:1094] Copying source layer ctx_output5/relu Type:ReLU #blobs=0
I0323 22:48:37.306516  1439 net.cpp:1094] Copying source layer ctx_output5_ctx_output5/relu_0_split Type:Split #blobs=0
I0323 22:48:37.306521  1439 net.cpp:1094] Copying source layer ctx_output6 Type:Convolution #blobs=2
I0323 22:48:37.306615  1439 net.cpp:1094] Copying source layer ctx_output6/relu Type:ReLU #blobs=0
I0323 22:48:37.306624  1439 net.cpp:1094] Copying source layer ctx_output6_ctx_output6/relu_0_split Type:Split #blobs=0
I0323 22:48:37.306629  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc Type:Convolution #blobs=2
I0323 22:48:37.306648  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc_perm Type:Permute #blobs=0
I0323 22:48:37.306655  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc_flat Type:Flatten #blobs=0
I0323 22:48:37.306660  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf Type:Convolution #blobs=2
I0323 22:48:37.306679  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf_perm Type:Permute #blobs=0
I0323 22:48:37.306686  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf_flat Type:Flatten #blobs=0
I0323 22:48:37.306713  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_priorbox Type:PriorBox #blobs=0
I0323 22:48:37.306718  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc Type:Convolution #blobs=2
I0323 22:48:37.306741  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc_perm Type:Permute #blobs=0
I0323 22:48:37.306748  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc_flat Type:Flatten #blobs=0
I0323 22:48:37.306753  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf Type:Convolution #blobs=2
I0323 22:48:37.306773  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf_perm Type:Permute #blobs=0
I0323 22:48:37.306780  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf_flat Type:Flatten #blobs=0
I0323 22:48:37.306785  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_priorbox Type:PriorBox #blobs=0
I0323 22:48:37.306790  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc Type:Convolution #blobs=2
I0323 22:48:37.306812  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc_perm Type:Permute #blobs=0
I0323 22:48:37.306818  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc_flat Type:Flatten #blobs=0
I0323 22:48:37.306823  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf Type:Convolution #blobs=2
I0323 22:48:37.306843  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf_perm Type:Permute #blobs=0
I0323 22:48:37.306849  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf_flat Type:Flatten #blobs=0
I0323 22:48:37.306855  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_priorbox Type:PriorBox #blobs=0
I0323 22:48:37.306860  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc Type:Convolution #blobs=2
I0323 22:48:37.306880  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc_perm Type:Permute #blobs=0
I0323 22:48:37.306887  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc_flat Type:Flatten #blobs=0
I0323 22:48:37.306892  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf Type:Convolution #blobs=2
I0323 22:48:37.306912  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf_perm Type:Permute #blobs=0
I0323 22:48:37.306919  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf_flat Type:Flatten #blobs=0
I0323 22:48:37.306924  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_priorbox Type:PriorBox #blobs=0
I0323 22:48:37.306929  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc Type:Convolution #blobs=2
I0323 22:48:37.306948  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc_perm Type:Permute #blobs=0
I0323 22:48:37.306955  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc_flat Type:Flatten #blobs=0
I0323 22:48:37.306960  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf Type:Convolution #blobs=2
I0323 22:48:37.306978  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf_perm Type:Permute #blobs=0
I0323 22:48:37.306985  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf_flat Type:Flatten #blobs=0
I0323 22:48:37.306990  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_priorbox Type:PriorBox #blobs=0
I0323 22:48:37.306995  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc Type:Convolution #blobs=2
I0323 22:48:37.307014  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc_perm Type:Permute #blobs=0
I0323 22:48:37.307021  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc_flat Type:Flatten #blobs=0
I0323 22:48:37.307026  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf Type:Convolution #blobs=2
I0323 22:48:37.307044  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf_perm Type:Permute #blobs=0
I0323 22:48:37.307050  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf_flat Type:Flatten #blobs=0
I0323 22:48:37.307065  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_priorbox Type:PriorBox #blobs=0
I0323 22:48:37.307070  1439 net.cpp:1094] Copying source layer mbox_loc Type:Concat #blobs=0
I0323 22:48:37.307075  1439 net.cpp:1094] Copying source layer mbox_conf Type:Concat #blobs=0
I0323 22:48:37.307080  1439 net.cpp:1094] Copying source layer mbox_priorbox Type:Concat #blobs=0
I0323 22:48:37.307085  1439 net.cpp:1078] Ignoring source layer mbox_loss
I0323 22:48:37.307307  1439 parallel.cpp:106] [0 - 0] P2pSync adding callback
I0323 22:48:37.307319  1439 parallel.cpp:106] [1 - 1] P2pSync adding callback
I0323 22:48:37.307324  1439 parallel.cpp:59] Starting Optimization
I0323 22:48:37.307329  1439 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0323 22:48:37.307685  1439 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0323 22:48:37.308764  1494 device_alternate.hpp:116] NVML initialized on thread 140336974259968
I0323 22:48:37.338196  1494 common.cpp:585] NVML succeeded to set CPU affinity on device 1
I0323 22:48:37.338301  1493 device_alternate.hpp:116] NVML initialized on thread 140336982652672
I0323 22:48:37.339195  1493 common.cpp:585] NVML succeeded to set CPU affinity on device 0
I0323 22:48:37.347589  1494 solver.cpp:43] Solver data type: FLOAT
I0323 22:48:37.350347  1494 net.cpp:104] Using FLOAT as default forward math type
I0323 22:48:37.350358  1494 net.cpp:110] Using FLOAT as default backward math type
I0323 22:48:37.350466  1494 data_reader.cpp:58] Data Reader threads: 4, out queues: 16, depth: 8
I0323 22:48:37.350510  1494 internal_thread.cpp:19] Starting 4 internal thread(s) on device 1
I0323 22:48:37.351308  1495 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0323 22:48:37.351958  1498 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0323 22:48:37.352596  1496 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0323 22:48:37.353497  1497 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0323 22:48:37.364022  1494 annotated_data_layer.cpp:219] output data size: 8,3,320,768
I0323 22:48:37.364425  1494 annotated_data_layer.cpp:265] [1] Output data size: 8, 3, 320, 768
I0323 22:48:37.364488  1494 internal_thread.cpp:19] Starting 4 internal thread(s) on device 1
I0323 22:48:37.995002  1494 solver.cpp:177] Creating test net (#0) specified by test_net file: training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/test.prototxt
I0323 22:48:37.995725  1494 net.cpp:104] Using FLOAT as default forward math type
I0323 22:48:37.995738  1494 net.cpp:110] Using FLOAT as default backward math type
I0323 22:48:37.995775  1494 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 4
I0323 22:48:37.995787  1494 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0323 22:48:37.996495  1503 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_test_lmdb
I0323 22:48:38.006635  1494 annotated_data_layer.cpp:219] output data size: 4,3,320,768
I0323 22:48:38.006729  1494 annotated_data_layer.cpp:265] (1) Output data size: 4, 3, 320, 768
I0323 22:48:38.006799  1494 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0323 22:48:38.008486  1504 annotated_data_layer.cpp:111] (1) Parser threads: 1
I0323 22:48:38.008514  1504 annotated_data_layer.cpp:113] (1) Transformer threads: 1
I0323 22:48:38.149907  1494 solver.cpp:57] Solver scaffolding done.
I0323 22:48:38.168328  1493 parallel.cpp:161] [0 - 0] P2pSync adding callback
I0323 22:48:38.168329  1494 parallel.cpp:161] [1 - 1] P2pSync adding callback
I0323 22:48:38.333955  1494 solver.cpp:501] Solving ssdJacintoNetV2
I0323 22:48:38.333982  1494 solver.cpp:502] Learning Rate Policy: multistep
I0323 22:48:38.334008  1493 solver.cpp:501] Solving ssdJacintoNetV2
I0323 22:48:38.334023  1493 solver.cpp:502] Learning Rate Policy: multistep
I0323 22:48:38.344741  1494 net.cpp:1412] [1] Reserving 12451584 bytes of shared learnable space
I0323 22:48:38.347131  1493 net.cpp:1412] [0] Reserving 12451584 bytes of shared learnable space
I0323 22:48:38.352551  1494 solver.cpp:228] Starting Optimization on GPU 1
I0323 22:48:38.352555  1493 solver.cpp:228] Starting Optimization on GPU 0
I0323 22:48:38.352813  1493 solver.cpp:678] Iteration 0, Testing net (#0)
I0323 22:48:38.352880  1513 device_alternate.hpp:116] NVML initialized on thread 140336663860992
I0323 22:48:38.352912  1513 common.cpp:585] NVML succeeded to set CPU affinity on device 0
I0323 22:48:38.352934  1514 device_alternate.hpp:116] NVML initialized on thread 140336672253696
I0323 22:48:38.352960  1514 common.cpp:585] NVML succeeded to set CPU affinity on device 1
I0323 22:48:38.359366  1494 net.cpp:1012] Ignoring source layer mbox_loss
I0323 22:48:38.376183  1493 net.cpp:1012] Ignoring source layer mbox_loss
I0323 22:48:38.474556  1494 blocking_queue.cpp:40] Data layer prefetch queue empty
I0323 22:48:38.660125  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'conv1a' with space 0G 3/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.666992  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'conv1b' with space 0G 32/4 6 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.670248  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1a' with space 0G 3/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.678160  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1b' with space 0G 32/4 6 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.678447  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res2a_branch2a' with space 0G 32/1 6 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.683032  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res2a_branch2b' with space 0G 64/4 6 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.688418  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2a' with space 0G 32/1 6 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.689842  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res3a_branch2a' with space 0G 64/1 6 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.692903  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res3a_branch2b' with space 0G 128/4 6 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.693415  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2b' with space 0G 64/4 6 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.698366  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res4a_branch2a' with space 0G 128/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.700047  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2a' with space 0G 64/1 6 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.701572  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res4a_branch2b' with space 0G 256/4 6 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.703281  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2b' with space 0G 128/4 6 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.706374  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res5a_branch2a' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.709956  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2a' with space 0G 128/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.710350  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res5a_branch2b' with space 0G 512/4 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.713250  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2b' with space 0G 256/4 6 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.714952  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output1' with space 0G 128/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.717547  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output2' with space 0G 512/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.718616  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res5a_branch2a' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.722424  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res5a_branch2b' with space 0G 512/4 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.723744  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output3' with space 0G 512/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.725983  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output4' with space 0G 512/1 0 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.727907  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output5' with space 0G 512/1 0 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.730051  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output6' with space 0G 512/1 0 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.730603  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output1' with space 0G 128/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.732157  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output1/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.734339  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output1/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.736270  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output2' with space 0G 512/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.736860  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output2/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.738873  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output2/relu_mbox_conf' with space 0G 256/1 0 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.739390  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output3' with space 0G 512/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.741276  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output3/relu_mbox_loc' with space 0G 256/1 0 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.741865  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output4' with space 0G 512/1 0 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.744217  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output5' with space 0G 512/1 0 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.744465  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output3/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.746644  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output6' with space 0G 512/1 0 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.747625  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output4/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.749306  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output1/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.750080  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output4/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.752954  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output5/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.753414  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output1/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.755259  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output5/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.757040  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output2/relu_mbox_loc' with space 0G 256/1 0 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.757730  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output6/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.758860  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output2/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.760174  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output6/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.761310  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output3/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.762965  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output3/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.764596  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output4/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.766147  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output4/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.767784  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output5/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.769353  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output5/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.771673  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output6/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.773937  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output6/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0
j:  : 4 : max_pr:  : 0
j:  : 3 : max_pr:  : 0.29729
j:  : 2 : max_pr:  : 0.415784
j:  : 1 : max_pr:  : 0.494114
j:  : 0 : max_pr:  : 0.666667
I0323 22:49:31.237844  1494 solver.cpp:786] class AP 1: 0.17035
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.042008
j:  : 6 : max_pr:  : 0.2404
j:  : 5 : max_pr:  : 0.535524
j:  : 4 : max_pr:  : 0.650923
j:  : 3 : max_pr:  : 0.846908
j:  : 2 : max_pr:  : 0.95279
j:  : 1 : max_pr:  : 0.993046
j:  : 0 : max_pr:  : 1
I0323 22:49:31.296622  1494 solver.cpp:786] class AP 2: 0.478327
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0.337287
j:  : 5 : max_pr:  : 0.426856
j:  : 4 : max_pr:  : 0.486442
j:  : 3 : max_pr:  : 0.516665
j:  : 2 : max_pr:  : 0.572415
j:  : 1 : max_pr:  : 0.651184
j:  : 0 : max_pr:  : 0.855319
I0323 22:49:31.311218  1494 solver.cpp:786] class AP 3: 0.349652
I0323 22:49:31.311242  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.332776
I0323 22:49:31.413830  1484 data_reader.cpp:305] Starting prefetch of epoch 1
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0
j:  : 4 : max_pr:  : 0
j:  : 3 : max_pr:  : 0.304722
j:  : 2 : max_pr:  : 0.415248
j:  : 1 : max_pr:  : 0.51502
j:  : 0 : max_pr:  : 1
I0323 22:49:31.627115  1493 solver.cpp:786] class AP 1: 0.203181
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.0324629
j:  : 6 : max_pr:  : 0.225933
j:  : 5 : max_pr:  : 0.524698
j:  : 4 : max_pr:  : 0.6381
j:  : 3 : max_pr:  : 0.822615
j:  : 2 : max_pr:  : 0.949165
j:  : 1 : max_pr:  : 0.989362
j:  : 0 : max_pr:  : 0.990672
I0323 22:49:31.678009  1493 solver.cpp:786] class AP 2: 0.470273
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0.331866
j:  : 5 : max_pr:  : 0.422604
j:  : 4 : max_pr:  : 0.486772
j:  : 3 : max_pr:  : 0.522185
j:  : 2 : max_pr:  : 0.581631
j:  : 1 : max_pr:  : 0.660413
j:  : 0 : max_pr:  : 1
I0323 22:49:31.688917  1493 solver.cpp:786] class AP 3: 0.364134
I0323 22:49:31.688944  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.345863
I0323 22:49:31.689474  1493 solver.cpp:255] [MultiGPU] Initial Test completed
I0323 22:49:33.514550  1466 annotated_data_layer.cpp:111] [0] Parser threads: 4
I0323 22:49:33.514581  1466 annotated_data_layer.cpp:113] [0] Transformer threads: 4
I0323 22:49:33.791932  1499 annotated_data_layer.cpp:111] [1] Parser threads: 4
I0323 22:49:33.791985  1499 annotated_data_layer.cpp:113] [1] Transformer threads: 4
I0323 22:49:35.065896  1494 solver.cpp:351] sparsity_itr_increment_bfr_applying is true: old behaviour:
I0323 22:49:35.065876  1493 solver.cpp:319] Iteration 0 (3.3761 s), loss = 3.7739
I0323 22:49:35.065955  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.74846 (* 1 = 3.74846 loss)
I0323 22:49:35.065978  1493 sgd_solver.cpp:136] Iteration 0, lr = 0.01, m = 0.9
I0323 22:49:35.065997  1493 solver.cpp:351] sparsity_itr_increment_bfr_applying is true: old behaviour:
I0323 22:49:35.183605  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'conv1a' with space 4.24G 3/1 1 0 0 	(avail 1.52G, req 0G)	t: 0 2.58 2.05
I0323 22:49:35.276432  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'conv1b' with space 4.24G 32/4 6 4 3 	(avail 1.52G, req 0G)	t: 0 0.53 1.09
I0323 22:49:35.410187  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'conv1a' with space 4.24G 3/1 1 0 0 	(avail 1.63G, req 0G)	t: 0 2.31 2.04
I0323 22:49:35.514749  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 4.24G 32/1 6 4 3 	(avail 1.47G, req 0G)	t: 0 0.75 1.25
I0323 22:49:35.520167  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'conv1b' with space 4.24G 32/4 6 4 3 	(avail 1.6G, req 0G)	t: 0 0.51 1.1
I0323 22:49:35.629465  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 4.24G 64/4 1 4 3 	(avail 1.47G, req 0G)	t: 0 0.28 0.59
I0323 22:49:35.771760  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 4.24G 32/1 1 4 3 	(avail 1.58G, req 0G)	t: 0 0.66 1.22
I0323 22:49:35.810722  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 4.24G 64/1 6 4 5 	(avail 1.47G, req 0.05G)	t: 0 0.42 0.77
I0323 22:49:35.857448  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 4.24G 64/4 6 4 3 	(avail 1.58G, req 0G)	t: 0 0.27 0.59
I0323 22:49:35.860350  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 4.24G 128/4 6 4 5 	(avail 1.47G, req 0.05G)	t: 0 0.15 0.26
I0323 22:49:35.953533  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 4.24G 128/1 6 4 5 	(avail 1.47G, req 0.05G)	t: 0 0.36 0.47
I0323 22:49:36.022078  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 4.24G 256/4 6 4 5 	(avail 1.47G, req 0.05G)	t: 0 0.08 0.17
I0323 22:49:36.045765  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 4.24G 64/1 6 4 5 	(avail 1.55G, req 0.05G)	t: 0 0.42 0.73
I0323 22:49:36.131213  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 4.24G 128/4 6 4 5 	(avail 1.55G, req 0.05G)	t: 0 0.12 0.26
I0323 22:49:36.182531  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 4.24G 256/1 6 4 5 	(avail 1.44G, req 0.05G)	t: 0 0.47 0.5
I0323 22:49:36.241499  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 4.24G 512/4 6 4 5 	(avail 1.44G, req 0.05G)	t: 0 0.12 0.14
I0323 22:49:36.270212  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 4.24G 128/1 6 4 5 	(avail 1.55G, req 0.05G)	t: 0 0.32 0.44
I0323 22:49:36.305871  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 4.24G 256/4 6 4 5 	(avail 1.55G, req 0.05G)	t: 0 0.11 0.19
I0323 22:49:36.319852  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output1' with space 4.24G 128/1 1 1 3 	(avail 1.42G, req 0.05G)	t: 0 0.34 0.8
I0323 22:49:36.392588  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output2' with space 4.24G 512/1 1 1 1 	(avail 1.42G, req 0.05G)	t: 0 0.17 0.19
I0323 22:49:36.411859  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 4.24G 256/1 6 4 5 	(avail 1.55G, req 0.05G)	t: 0 0.46 0.5
I0323 22:49:36.427016  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output3' with space 4.24G 512/1 0 1 1 	(avail 1.42G, req 0.05G)	t: 0 0.07 0.09
I0323 22:49:36.446193  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 4.24G 512/4 6 4 5 	(avail 1.55G, req 0.05G)	t: 0 0.08 0.13
I0323 22:49:36.458101  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output4' with space 4.24G 512/1 0 0 1 	(avail 1.42G, req 0.05G)	t: 0 0.1 0.11
I0323 22:49:36.487696  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output5' with space 4.24G 512/1 0 0 1 	(avail 1.42G, req 0.05G)	t: 0 0.09 0.09
I0323 22:49:36.509845  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output1' with space 4.24G 128/1 1 1 3 	(avail 1.53G, req 0.05G)	t: 0 0.35 0.8
I0323 22:49:36.547974  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output6' with space 4.24G 512/1 0 0 1 	(avail 1.39G, req 0.05G)	t: 0 0.06 0.07
I0323 22:49:36.592002  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output2' with space 4.24G 512/1 0 1 1 	(avail 1.53G, req 0.05G)	t: 0 0.16 0.18
I0323 22:49:36.623448  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output3' with space 4.24G 512/1 0 1 1 	(avail 1.53G, req 0.05G)	t: 0 0.1 0.12
I0323 22:49:36.656561  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output4' with space 4.24G 512/1 0 0 1 	(avail 1.53G, req 0.05G)	t: 0 0.08 0.09
I0323 22:49:36.669945  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_loc' with space 4.24G 256/1 1 1 3 	(avail 1.39G, req 0.05G)	t: 0 0.22 0.62
I0323 22:49:36.714236  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output5' with space 4.24G 512/1 0 0 1 	(avail 1.53G, req 0.05G)	t: 0 0.06 0.06
I0323 22:49:36.774420  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output6' with space 4.24G 512/1 0 0 3 	(avail 1.53G, req 0.05G)	t: 0 0.06 0.06
I0323 22:49:36.853092  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_conf' with space 4.24G 256/1 1 1 3 	(avail 1.37G, req 0.05G)	t: 0 0.29 0.62
I0323 22:49:36.884588  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_loc' with space 4.24G 256/1 1 1 0 	(avail 1.37G, req 0.05G)	t: 0 0.06 0.07
I0323 22:49:36.903250  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_loc' with space 4.24G 256/1 1 1 3 	(avail 1.53G, req 0.05G)	t: 0 0.21 0.63
I0323 22:49:36.911309  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_conf' with space 4.24G 256/1 0 1 3 	(avail 1.37G, req 0.05G)	t: 0 0.04 0.06
I0323 22:49:36.929129  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 1.37G, req 0.05G)	t: 0 0.06 0.06
I0323 22:49:36.960880  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_conf' with space 4.24G 256/1 0 0 0 	(avail 1.37G, req 0.05G)	t: 0 0.06 0.05
I0323 22:49:36.985903  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_loc' with space 4.24G 256/1 1 0 0 	(avail 1.37G, req 0.05G)	t: 0 0.06 0.06
I0323 22:49:37.014472  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_conf' with space 4.24G 256/1 1 0 0 	(avail 1.37G, req 0.05G)	t: 0 0.05 0.04
I0323 22:49:37.036401  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 1.37G, req 0.05G)	t: 0 0.03 0.03
I0323 22:49:37.063347  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_conf' with space 4.24G 256/1 1 0 0 	(avail 1.37G, req 0.05G)	t: 0 0.03 0.03
I0323 22:49:37.070669  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_conf' with space 4.24G 256/1 1 1 3 	(avail 1.45G, req 0.05G)	t: 0 0.25 0.63
I0323 22:49:37.089983  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output6/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 1.37G, req 0.05G)	t: 0 0.03 0.03
I0323 22:49:37.106283  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output6/relu_mbox_conf' with space 4.24G 256/1 0 0 0 	(avail 1.37G, req 0.05G)	t: 0 0.04 0.03
I0323 22:49:37.109550  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_loc' with space 4.24G 256/1 1 1 0 	(avail 1.45G, req 0.05G)	t: 0 0.07 0.07
I0323 22:49:37.138844  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_conf' with space 4.24G 256/1 1 1 3 	(avail 1.45G, req 0.05G)	t: 0 0.08 0.1
I0323 22:49:37.156304  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_loc' with space 4.24G 256/1 0 0 3 	(avail 1.45G, req 0.05G)	t: 0 0.08 0.06
I0323 22:49:37.169209  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_conf' with space 4.24G 256/1 1 0 0 	(avail 1.45G, req 0.05G)	t: 0 0.06 0.05
I0323 22:49:37.182801  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 1.45G, req 0.05G)	t: 0 0.05 0.05
I0323 22:49:37.246248  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_conf' with space 4.24G 256/1 0 0 0 	(avail 1.45G, req 0.05G)	t: 0 0.15 0.14
I0323 22:49:37.298352  1493 cudnn_conv_layer.cpp:474] [0] Layer 'conv1a' reallocating workspace 4.24G to 0.11G
I0323 22:49:37.303014  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 1.45G, req 0.05G)	t: 0 0.06 0.05
I0323 22:49:37.316648  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_conf' with space 4.24G 256/1 0 0 0 	(avail 1.45G, req 0.05G)	t: 0 0.07 0.05
I0323 22:49:37.332348  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output6/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 1.45G, req 0.05G)	t: 0 0.06 0.07
I0323 22:49:37.354843  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output6/relu_mbox_conf' with space 4.24G 256/1 0 0 0 	(avail 1.45G, req 0.05G)	t: 0 0.05 0.05
I0323 22:49:37.617507  1494 cudnn_conv_layer.cpp:474] [1] Layer 'conv1a' reallocating workspace 4.24G to 0.11G
I0323 22:49:37.836638  1493 solver.cpp:319] Iteration 1 (2.77067 s), loss = 3.90344
I0323 22:49:37.836683  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.93222 (* 1 = 3.93222 loss)
I0323 22:49:37.836694  1493 solver.cpp:351] sparsity_itr_increment_bfr_applying is true: old behaviour:
I0323 22:49:37.836654  1494 solver.cpp:351] sparsity_itr_increment_bfr_applying is true: old behaviour:
I0323 22:49:38.389751  1493 solver.cpp:319] Iteration 2 (0.553087 s), loss = 4.08933
I0323 22:49:38.389796  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.94315 (* 1 = 3.94315 loss)
I0323 22:50:41.782698  1493 solver.cpp:314] Iteration 100 (1.54596 iter/s, 63.3911s/98 iter), loss = 4.53405
I0323 22:50:41.782853  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.26661 (* 1 = 4.26661 loss)
I0323 22:50:41.782874  1493 sgd_solver.cpp:136] Iteration 100, lr = 0.01, m = 0.9
I0323 22:51:48.734098  1493 solver.cpp:314] Iteration 200 (1.49366 iter/s, 66.9494s/100 iter), loss = 4.29166
I0323 22:51:48.734192  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.14717 (* 1 = 4.14717 loss)
I0323 22:51:48.734205  1493 sgd_solver.cpp:136] Iteration 200, lr = 0.01, m = 0.9
I0323 22:52:53.841429  1493 solver.cpp:314] Iteration 300 (1.53597 iter/s, 65.1054s/100 iter), loss = 4.05096
I0323 22:52:53.841604  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.06028 (* 1 = 4.06028 loss)
I0323 22:52:53.841652  1493 sgd_solver.cpp:136] Iteration 300, lr = 0.01, m = 0.9
I0323 22:53:59.821766  1493 solver.cpp:314] Iteration 400 (1.51565 iter/s, 65.9784s/100 iter), loss = 4.26812
I0323 22:53:59.823148  1493 solver.cpp:336]     Train net output #0: mbox_loss = 5.10703 (* 1 = 5.10703 loss)
I0323 22:53:59.823170  1493 sgd_solver.cpp:136] Iteration 400, lr = 0.01, m = 0.9
I0323 22:55:06.601943  1493 solver.cpp:314] Iteration 500 (1.49749 iter/s, 66.7782s/100 iter), loss = 4.01307
I0323 22:55:06.602041  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.12499 (* 1 = 4.12499 loss)
I0323 22:55:06.602058  1493 sgd_solver.cpp:136] Iteration 500, lr = 0.01, m = 0.9
I0323 22:56:12.717741  1493 solver.cpp:314] Iteration 600 (1.51254 iter/s, 66.1139s/100 iter), loss = 4.03872
I0323 22:56:12.717905  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.72107 (* 1 = 3.72107 loss)
I0323 22:56:12.717922  1493 sgd_solver.cpp:136] Iteration 600, lr = 0.01, m = 0.9
I0323 22:57:18.432302  1493 solver.cpp:314] Iteration 700 (1.52178 iter/s, 65.7127s/100 iter), loss = 4.0706
I0323 22:57:18.432431  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.13445 (* 1 = 3.13445 loss)
I0323 22:57:18.432499  1493 sgd_solver.cpp:136] Iteration 700, lr = 0.01, m = 0.9
I0323 22:58:24.029772  1493 solver.cpp:314] Iteration 800 (1.52449 iter/s, 65.5956s/100 iter), loss = 3.83964
I0323 22:58:24.031848  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.13615 (* 1 = 4.13615 loss)
I0323 22:58:24.031878  1493 sgd_solver.cpp:136] Iteration 800, lr = 0.01, m = 0.9
I0323 22:59:30.654832  1493 solver.cpp:314] Iteration 900 (1.50098 iter/s, 66.6232s/100 iter), loss = 3.79302
I0323 22:59:30.654929  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.24517 (* 1 = 3.24517 loss)
I0323 22:59:30.654945  1493 sgd_solver.cpp:136] Iteration 900, lr = 0.01, m = 0.9
I0323 23:00:35.984648  1493 solver.cpp:314] Iteration 1000 (1.53074 iter/s, 65.3279s/100 iter), loss = 4.11693
I0323 23:00:35.984827  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.98215 (* 1 = 4.98215 loss)
I0323 23:00:35.984843  1493 sgd_solver.cpp:136] Iteration 1000, lr = 0.01, m = 0.9
I0323 23:01:41.806044  1493 solver.cpp:314] Iteration 1100 (1.51931 iter/s, 65.8195s/100 iter), loss = 3.8272
I0323 23:01:41.806192  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.44516 (* 1 = 3.44516 loss)
I0323 23:01:41.806210  1493 sgd_solver.cpp:136] Iteration 1100, lr = 0.01, m = 0.9
I0323 23:02:47.790160  1493 solver.cpp:314] Iteration 1200 (1.51556 iter/s, 65.9822s/100 iter), loss = 3.88279
I0323 23:02:47.790256  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.2625 (* 1 = 3.2625 loss)
I0323 23:02:47.790271  1493 sgd_solver.cpp:136] Iteration 1200, lr = 0.01, m = 0.9
I0323 23:03:54.517460  1493 solver.cpp:314] Iteration 1300 (1.49868 iter/s, 66.7254s/100 iter), loss = 3.90681
I0323 23:03:54.517565  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.19064 (* 1 = 4.19064 loss)
I0323 23:03:54.517582  1493 sgd_solver.cpp:136] Iteration 1300, lr = 0.01, m = 0.9
I0323 23:05:01.549114  1493 solver.cpp:314] Iteration 1400 (1.49188 iter/s, 67.0297s/100 iter), loss = 3.82962
I0323 23:05:01.549216  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.12871 (* 1 = 3.12871 loss)
I0323 23:05:01.549232  1493 sgd_solver.cpp:136] Iteration 1400, lr = 0.01, m = 0.9
I0323 23:06:07.945736  1493 solver.cpp:314] Iteration 1500 (1.50614 iter/s, 66.3947s/100 iter), loss = 3.98527
I0323 23:06:07.949784  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.51266 (* 1 = 3.51266 loss)
I0323 23:06:07.950186  1493 sgd_solver.cpp:136] Iteration 1500, lr = 0.01, m = 0.9
I0323 23:07:14.704038  1493 solver.cpp:314] Iteration 1600 (1.49798 iter/s, 66.7564s/100 iter), loss = 4.05769
I0323 23:07:14.704138  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.48868 (* 1 = 3.48868 loss)
I0323 23:07:14.704154  1493 sgd_solver.cpp:136] Iteration 1600, lr = 0.01, m = 0.9
I0323 23:08:20.619010  1493 solver.cpp:314] Iteration 1700 (1.51715 iter/s, 65.9131s/100 iter), loss = 3.66393
I0323 23:08:20.619122  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.30512 (* 1 = 3.30512 loss)
I0323 23:08:20.619138  1493 sgd_solver.cpp:136] Iteration 1700, lr = 0.01, m = 0.9
I0323 23:09:26.906046  1493 solver.cpp:314] Iteration 1800 (1.50863 iter/s, 66.2851s/100 iter), loss = 3.94065
I0323 23:09:26.906152  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.12901 (* 1 = 3.12901 loss)
I0323 23:09:26.906169  1493 sgd_solver.cpp:136] Iteration 1800, lr = 0.01, m = 0.9
I0323 23:10:32.813359  1493 solver.cpp:314] Iteration 1900 (1.51733 iter/s, 65.9054s/100 iter), loss = 3.62983
I0323 23:10:32.813457  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.22451 (* 1 = 3.22451 loss)
I0323 23:10:32.813472  1493 sgd_solver.cpp:136] Iteration 1900, lr = 0.01, m = 0.9
I0323 23:11:38.201161  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_2000.caffemodel
I0323 23:11:38.264041  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_2000.solverstate
I0323 23:11:38.285671  1493 solver.cpp:678] Iteration 2000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0
j:  : 4 : max_pr:  : 0
j:  : 3 : max_pr:  : 0.257837
j:  : 2 : max_pr:  : 0.483572
j:  : 1 : max_pr:  : 0.738134
j:  : 0 : max_pr:  : 1
I0323 23:12:27.068806  1493 solver.cpp:786] class AP 1: 0.225413
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.0272546
j:  : 6 : max_pr:  : 0.122667
j:  : 5 : max_pr:  : 0.24801
j:  : 4 : max_pr:  : 0.304307
j:  : 3 : max_pr:  : 0.365978
j:  : 2 : max_pr:  : 0.647029
j:  : 1 : max_pr:  : 0.889197
j:  : 0 : max_pr:  : 1
I0323 23:12:27.130771  1493 solver.cpp:786] class AP 2: 0.327677
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0.305954
j:  : 5 : max_pr:  : 0.514786
j:  : 4 : max_pr:  : 0.661602
j:  : 3 : max_pr:  : 0.728096
j:  : 2 : max_pr:  : 0.862496
j:  : 1 : max_pr:  : 0.989429
j:  : 0 : max_pr:  : 1
I0323 23:12:27.140970  1493 solver.cpp:786] class AP 3: 0.460215
I0323 23:12:27.140992  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.337768
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0
j:  : 4 : max_pr:  : 0
j:  : 3 : max_pr:  : 0.264869
j:  : 2 : max_pr:  : 0.47644
j:  : 1 : max_pr:  : 0.7251
j:  : 0 : max_pr:  : 1
I0323 23:12:27.175611  1494 solver.cpp:786] class AP 1: 0.224219
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.0301652
j:  : 6 : max_pr:  : 0.130019
j:  : 5 : max_pr:  : 0.256378
j:  : 4 : max_pr:  : 0.326788
j:  : 3 : max_pr:  : 0.398011
j:  : 2 : max_pr:  : 0.687007
j:  : 1 : max_pr:  : 0.908206
j:  : 0 : max_pr:  : 1
I0323 23:12:27.235172  1494 solver.cpp:786] class AP 2: 0.339689
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0.312224
j:  : 5 : max_pr:  : 0.536312
j:  : 4 : max_pr:  : 0.684362
j:  : 3 : max_pr:  : 0.757178
j:  : 2 : max_pr:  : 0.86758
j:  : 1 : max_pr:  : 0.991059
j:  : 0 : max_pr:  : 1
I0323 23:12:27.245080  1494 solver.cpp:786] class AP 3: 0.468065
I0323 23:12:27.245092  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.343991
I0323 23:12:27.245458  1493 solver.cpp:265] [MultiGPU] Tests completed in 48.9584s
I0323 23:12:27.637941  1493 solver.cpp:314] Iteration 2000 (0.870919 iter/s, 114.821s/100 iter), loss = 3.93422
I0323 23:12:27.637984  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.70852 (* 1 = 3.70852 loss)
I0323 23:12:27.638000  1493 sgd_solver.cpp:136] Iteration 2000, lr = 0.01, m = 0.9
I0323 23:13:32.956596  1493 solver.cpp:314] Iteration 2100 (1.531 iter/s, 65.3168s/100 iter), loss = 3.92707
I0323 23:13:32.956732  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.07801 (* 1 = 3.07801 loss)
I0323 23:13:32.956748  1493 sgd_solver.cpp:136] Iteration 2100, lr = 0.01, m = 0.9
I0323 23:14:38.408421  1493 solver.cpp:314] Iteration 2200 (1.52789 iter/s, 65.4499s/100 iter), loss = 4.08358
I0323 23:14:38.408526  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.63275 (* 1 = 3.63275 loss)
I0323 23:14:38.408542  1493 sgd_solver.cpp:136] Iteration 2200, lr = 0.01, m = 0.9
I0323 23:15:43.043073  1493 solver.cpp:314] Iteration 2300 (1.5472 iter/s, 64.6328s/100 iter), loss = 3.73523
I0323 23:15:43.043195  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.18382 (* 1 = 3.18382 loss)
I0323 23:15:43.043215  1493 sgd_solver.cpp:136] Iteration 2300, lr = 0.01, m = 0.9
I0323 23:16:47.923194  1493 solver.cpp:314] Iteration 2400 (1.54135 iter/s, 64.8783s/100 iter), loss = 3.48827
I0323 23:16:47.923300  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.31882 (* 1 = 3.31882 loss)
I0323 23:16:47.923317  1493 sgd_solver.cpp:136] Iteration 2400, lr = 0.01, m = 0.9
I0323 23:17:53.522997  1493 solver.cpp:314] Iteration 2500 (1.52444 iter/s, 65.5979s/100 iter), loss = 3.64736
I0323 23:17:53.523195  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.34811 (* 1 = 4.34811 loss)
I0323 23:17:53.523238  1493 sgd_solver.cpp:136] Iteration 2500, lr = 0.01, m = 0.9
I0323 23:18:59.832096  1493 solver.cpp:314] Iteration 2600 (1.50813 iter/s, 66.3072s/100 iter), loss = 3.97786
I0323 23:18:59.832244  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.67067 (* 1 = 4.67067 loss)
I0323 23:18:59.832275  1493 sgd_solver.cpp:136] Iteration 2600, lr = 0.01, m = 0.9
I0323 23:20:06.328936  1493 solver.cpp:314] Iteration 2700 (1.50387 iter/s, 66.4949s/100 iter), loss = 3.58704
I0323 23:20:06.329077  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.36411 (* 1 = 3.36411 loss)
I0323 23:20:06.329108  1493 sgd_solver.cpp:136] Iteration 2700, lr = 0.01, m = 0.9
I0323 23:21:12.268213  1493 solver.cpp:314] Iteration 2800 (1.51659 iter/s, 65.9374s/100 iter), loss = 3.78468
I0323 23:21:12.268323  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.83231 (* 1 = 3.83231 loss)
I0323 23:21:12.268340  1493 sgd_solver.cpp:136] Iteration 2800, lr = 0.01, m = 0.9
I0323 23:22:17.448163  1493 solver.cpp:314] Iteration 2900 (1.53426 iter/s, 65.1781s/100 iter), loss = 3.86018
I0323 23:22:17.449739  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.50774 (* 1 = 3.50774 loss)
I0323 23:22:17.449765  1493 sgd_solver.cpp:136] Iteration 2900, lr = 0.01, m = 0.9
I0323 23:23:23.012611  1493 solver.cpp:314] Iteration 3000 (1.52526 iter/s, 65.5626s/100 iter), loss = 3.71755
I0323 23:23:23.012836  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.74866 (* 1 = 3.74866 loss)
I0323 23:23:23.012867  1493 sgd_solver.cpp:136] Iteration 3000, lr = 0.01, m = 0.9
I0323 23:24:29.062083  1493 solver.cpp:314] Iteration 3100 (1.51406 iter/s, 66.0476s/100 iter), loss = 3.5891
I0323 23:24:29.062177  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.23949 (* 1 = 3.23949 loss)
I0323 23:24:29.062192  1493 sgd_solver.cpp:136] Iteration 3100, lr = 0.01, m = 0.9
I0323 23:24:40.043028  1462 data_reader.cpp:305] Starting prefetch of epoch 1
I0323 23:25:35.049856  1493 solver.cpp:314] Iteration 3200 (1.51548 iter/s, 65.9859s/100 iter), loss = 3.6305
I0323 23:25:35.049950  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.17921 (* 1 = 3.17921 loss)
I0323 23:25:35.049966  1493 sgd_solver.cpp:136] Iteration 3200, lr = 0.01, m = 0.9
I0323 23:26:39.866283  1493 solver.cpp:314] Iteration 3300 (1.54286 iter/s, 64.8146s/100 iter), loss = 3.58764
I0323 23:26:39.866370  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.94418 (* 1 = 2.94418 loss)
I0323 23:26:39.866385  1493 sgd_solver.cpp:136] Iteration 3300, lr = 0.01, m = 0.9
I0323 23:27:45.787070  1493 solver.cpp:314] Iteration 3400 (1.51702 iter/s, 65.9189s/100 iter), loss = 3.7022
I0323 23:27:45.787238  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.91076 (* 1 = 3.91076 loss)
I0323 23:27:45.787255  1493 sgd_solver.cpp:136] Iteration 3400, lr = 0.01, m = 0.9
I0323 23:28:51.658072  1493 solver.cpp:314] Iteration 3500 (1.51816 iter/s, 65.869s/100 iter), loss = 3.67867
I0323 23:28:51.658227  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.99867 (* 1 = 2.99867 loss)
I0323 23:28:51.658252  1493 sgd_solver.cpp:136] Iteration 3500, lr = 0.01, m = 0.9
I0323 23:29:57.168680  1493 solver.cpp:314] Iteration 3600 (1.52652 iter/s, 65.5087s/100 iter), loss = 3.54569
I0323 23:29:57.168771  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.69876 (* 1 = 2.69876 loss)
I0323 23:29:57.168787  1493 sgd_solver.cpp:136] Iteration 3600, lr = 0.01, m = 0.9
I0323 23:31:02.713940  1493 solver.cpp:314] Iteration 3700 (1.52571 iter/s, 65.5433s/100 iter), loss = 3.59419
I0323 23:31:02.715456  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.13385 (* 1 = 4.13385 loss)
I0323 23:31:02.715499  1493 sgd_solver.cpp:136] Iteration 3700, lr = 0.01, m = 0.9
I0323 23:32:08.956547  1493 solver.cpp:314] Iteration 3800 (1.50965 iter/s, 66.2406s/100 iter), loss = 3.87835
I0323 23:32:08.956714  1493 solver.cpp:336]     Train net output #0: mbox_loss = 5.27415 (* 1 = 5.27415 loss)
I0323 23:32:08.956730  1493 sgd_solver.cpp:136] Iteration 3800, lr = 0.01, m = 0.9
I0323 23:33:14.536777  1493 solver.cpp:314] Iteration 3900 (1.5249 iter/s, 65.5783s/100 iter), loss = 3.54694
I0323 23:33:14.545765  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.12785 (* 1 = 3.12785 loss)
I0323 23:33:14.545796  1493 sgd_solver.cpp:136] Iteration 3900, lr = 0.01, m = 0.9
I0323 23:34:20.705313  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_4000.caffemodel
I0323 23:34:20.733619  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_4000.solverstate
I0323 23:34:20.746870  1493 solver.cpp:678] Iteration 4000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.249333
j:  : 4 : max_pr:  : 0.390546
j:  : 3 : max_pr:  : 0.549348
j:  : 2 : max_pr:  : 0.711037
j:  : 1 : max_pr:  : 0.835869
j:  : 0 : max_pr:  : 1
I0323 23:35:11.179517  1494 solver.cpp:786] class AP 1: 0.339649
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0960451
j:  : 7 : max_pr:  : 0.287844
j:  : 6 : max_pr:  : 0.496092
j:  : 5 : max_pr:  : 0.650736
j:  : 4 : max_pr:  : 0.724747
j:  : 3 : max_pr:  : 0.830261
j:  : 2 : max_pr:  : 0.968586
j:  : 1 : max_pr:  : 0.99171
j:  : 0 : max_pr:  : 1
I0323 23:35:11.235651  1494 solver.cpp:786] class AP 2: 0.549638
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0.494088
j:  : 5 : max_pr:  : 0.695418
j:  : 4 : max_pr:  : 0.797502
j:  : 3 : max_pr:  : 0.880107
j:  : 2 : max_pr:  : 0.939524
j:  : 1 : max_pr:  : 0.995321
j:  : 0 : max_pr:  : 1
I0323 23:35:11.242960  1494 solver.cpp:786] class AP 3: 0.527451
I0323 23:35:11.242979  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.472246
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.250076
j:  : 4 : max_pr:  : 0.387178
j:  : 3 : max_pr:  : 0.533955
j:  : 2 : max_pr:  : 0.706031
j:  : 1 : max_pr:  : 0.829768
j:  : 0 : max_pr:  : 1
I0323 23:35:11.694854  1493 solver.cpp:786] class AP 1: 0.337001
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0990823
j:  : 7 : max_pr:  : 0.295945
j:  : 6 : max_pr:  : 0.512333
j:  : 5 : max_pr:  : 0.652906
j:  : 4 : max_pr:  : 0.733785
j:  : 3 : max_pr:  : 0.845521
j:  : 2 : max_pr:  : 0.978374
j:  : 1 : max_pr:  : 0.994547
j:  : 0 : max_pr:  : 1
I0323 23:35:11.748678  1493 solver.cpp:786] class AP 2: 0.555681
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0.492401
j:  : 5 : max_pr:  : 0.684252
j:  : 4 : max_pr:  : 0.793294
j:  : 3 : max_pr:  : 0.891045
j:  : 2 : max_pr:  : 0.950592
j:  : 1 : max_pr:  : 0.995717
j:  : 0 : max_pr:  : 1
I0323 23:35:11.755487  1493 solver.cpp:786] class AP 3: 0.527937
I0323 23:35:11.755501  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.473539
I0323 23:35:11.755556  1493 solver.cpp:265] [MultiGPU] Tests completed in 51.0072s
I0323 23:35:12.212098  1493 solver.cpp:314] Iteration 4000 (0.849821 iter/s, 117.672s/100 iter), loss = 3.64583
I0323 23:35:12.212146  1493 solver.cpp:336]     Train net output #0: mbox_loss = 5.45991 (* 1 = 5.45991 loss)
I0323 23:35:12.212159  1493 sgd_solver.cpp:136] Iteration 4000, lr = 0.01, m = 0.9
I0323 23:36:17.810649  1493 solver.cpp:314] Iteration 4100 (1.52447 iter/s, 65.5966s/100 iter), loss = 3.56298
I0323 23:36:17.813741  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.78696 (* 1 = 3.78696 loss)
I0323 23:36:17.813763  1493 sgd_solver.cpp:136] Iteration 4100, lr = 0.01, m = 0.9
I0323 23:37:23.327805  1493 solver.cpp:314] Iteration 4200 (1.52636 iter/s, 65.5152s/100 iter), loss = 3.57056
I0323 23:37:23.327966  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.63471 (* 1 = 3.63471 loss)
I0323 23:37:23.328009  1493 sgd_solver.cpp:136] Iteration 4200, lr = 0.01, m = 0.9
I0323 23:38:28.764933  1493 solver.cpp:314] Iteration 4300 (1.52823 iter/s, 65.4352s/100 iter), loss = 3.71638
I0323 23:38:28.765061  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.64287 (* 1 = 3.64287 loss)
I0323 23:38:28.765077  1493 sgd_solver.cpp:136] Iteration 4300, lr = 0.01, m = 0.9
I0323 23:39:34.565781  1493 solver.cpp:314] Iteration 4400 (1.51978 iter/s, 65.7989s/100 iter), loss = 3.50247
I0323 23:39:34.566073  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.18056 (* 1 = 4.18056 loss)
I0323 23:39:34.566092  1493 sgd_solver.cpp:136] Iteration 4400, lr = 0.01, m = 0.9
I0323 23:40:40.217588  1493 solver.cpp:314] Iteration 4500 (1.52323 iter/s, 65.6499s/100 iter), loss = 3.48663
I0323 23:40:40.217679  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.41477 (* 1 = 3.41477 loss)
I0323 23:40:40.217700  1493 sgd_solver.cpp:136] Iteration 4500, lr = 0.01, m = 0.9
I0323 23:41:45.158931  1493 solver.cpp:314] Iteration 4600 (1.5399 iter/s, 64.9393s/100 iter), loss = 3.60284
I0323 23:41:45.159026  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.3186 (* 1 = 3.3186 loss)
I0323 23:41:45.159049  1493 sgd_solver.cpp:136] Iteration 4600, lr = 0.01, m = 0.9
I0323 23:42:50.860043  1493 solver.cpp:314] Iteration 4700 (1.52209 iter/s, 65.6992s/100 iter), loss = 3.42156
I0323 23:42:50.860149  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.9847 (* 1 = 4.9847 loss)
I0323 23:42:50.860168  1493 sgd_solver.cpp:136] Iteration 4700, lr = 0.01, m = 0.9
I0323 23:43:57.800213  1493 solver.cpp:314] Iteration 4800 (1.49392 iter/s, 66.9382s/100 iter), loss = 3.73948
I0323 23:43:57.800319  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.7261 (* 1 = 3.7261 loss)
I0323 23:43:57.800338  1493 sgd_solver.cpp:136] Iteration 4800, lr = 0.01, m = 0.9
I0323 23:45:04.579332  1493 solver.cpp:314] Iteration 4900 (1.49752 iter/s, 66.7771s/100 iter), loss = 3.85184
I0323 23:45:04.579429  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.97434 (* 1 = 2.97434 loss)
I0323 23:45:04.579447  1493 sgd_solver.cpp:136] Iteration 4900, lr = 0.01, m = 0.9
I0323 23:46:10.649952  1493 solver.cpp:314] Iteration 5000 (1.51358 iter/s, 66.0686s/100 iter), loss = 3.6092
I0323 23:46:10.650065  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.73208 (* 1 = 3.73208 loss)
I0323 23:46:10.650084  1493 sgd_solver.cpp:136] Iteration 5000, lr = 0.01, m = 0.9
I0323 23:47:17.673758  1493 solver.cpp:314] Iteration 5100 (1.49205 iter/s, 67.0217s/100 iter), loss = 3.76322
I0323 23:47:17.673857  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.03634 (* 1 = 3.03634 loss)
I0323 23:47:17.673877  1493 sgd_solver.cpp:136] Iteration 5100, lr = 0.01, m = 0.9
I0323 23:48:23.590859  1493 solver.cpp:314] Iteration 5200 (1.5171 iter/s, 65.915s/100 iter), loss = 3.65575
I0323 23:48:23.590967  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.89876 (* 1 = 3.89876 loss)
I0323 23:48:23.590983  1493 sgd_solver.cpp:136] Iteration 5200, lr = 0.01, m = 0.9
I0323 23:49:29.921963  1493 solver.cpp:314] Iteration 5300 (1.50764 iter/s, 66.329s/100 iter), loss = 3.35529
I0323 23:49:29.922060  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.20429 (* 1 = 3.20429 loss)
I0323 23:49:29.922076  1493 sgd_solver.cpp:136] Iteration 5300, lr = 0.01, m = 0.9
I0323 23:50:34.964031  1493 solver.cpp:314] Iteration 5400 (1.53751 iter/s, 65.04s/100 iter), loss = 3.73991
I0323 23:50:34.964133  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.32458 (* 1 = 2.32458 loss)
I0323 23:50:34.964150  1493 sgd_solver.cpp:136] Iteration 5400, lr = 0.01, m = 0.9
I0323 23:51:40.491174  1493 solver.cpp:314] Iteration 5500 (1.52613 iter/s, 65.5251s/100 iter), loss = 3.75828
I0323 23:51:40.491259  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.53949 (* 1 = 4.53949 loss)
I0323 23:51:40.491276  1493 sgd_solver.cpp:136] Iteration 5500, lr = 0.01, m = 0.9
I0323 23:52:46.236522  1493 solver.cpp:314] Iteration 5600 (1.52107 iter/s, 65.7433s/100 iter), loss = 3.86445
I0323 23:52:46.237745  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.68713 (* 1 = 2.68713 loss)
I0323 23:52:46.237764  1493 sgd_solver.cpp:136] Iteration 5600, lr = 0.01, m = 0.9
I0323 23:53:50.701752  1493 solver.cpp:314] Iteration 5700 (1.55127 iter/s, 64.4632s/100 iter), loss = 3.74217
I0323 23:53:50.701915  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.76621 (* 1 = 4.76621 loss)
I0323 23:53:50.701934  1493 sgd_solver.cpp:136] Iteration 5700, lr = 0.01, m = 0.9
I0323 23:54:56.607148  1493 solver.cpp:314] Iteration 5800 (1.51737 iter/s, 65.9034s/100 iter), loss = 3.68885
I0323 23:54:56.607332  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.17297 (* 1 = 4.17297 loss)
I0323 23:54:56.607349  1493 sgd_solver.cpp:136] Iteration 5800, lr = 0.01, m = 0.9
I0323 23:56:02.107303  1493 solver.cpp:314] Iteration 5900 (1.52676 iter/s, 65.4981s/100 iter), loss = 3.6931
I0323 23:56:02.107419  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.28701 (* 1 = 3.28701 loss)
I0323 23:56:02.107435  1493 sgd_solver.cpp:136] Iteration 5900, lr = 0.01, m = 0.9
I0323 23:57:07.927500  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_6000.caffemodel
I0323 23:57:07.957630  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_6000.solverstate
I0323 23:57:07.971668  1493 solver.cpp:678] Iteration 6000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0
j:  : 4 : max_pr:  : 0.264802
j:  : 3 : max_pr:  : 0.408934
j:  : 2 : max_pr:  : 0.573539
j:  : 1 : max_pr:  : 0.718662
j:  : 0 : max_pr:  : 1
I0323 23:57:56.551786  1494 solver.cpp:786] class AP 1: 0.269631
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.170201
j:  : 6 : max_pr:  : 0.315961
j:  : 5 : max_pr:  : 0.38364
j:  : 4 : max_pr:  : 0.517681
j:  : 3 : max_pr:  : 0.666902
j:  : 2 : max_pr:  : 0.846671
j:  : 1 : max_pr:  : 0.973412
j:  : 0 : max_pr:  : 1
I0323 23:57:56.608112  1494 solver.cpp:786] class AP 2: 0.443134
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.238212
j:  : 6 : max_pr:  : 0.53317
j:  : 5 : max_pr:  : 0.692232
j:  : 4 : max_pr:  : 0.827159
j:  : 3 : max_pr:  : 0.909344
j:  : 2 : max_pr:  : 0.968836
j:  : 1 : max_pr:  : 0.992345
j:  : 0 : max_pr:  : 1
I0323 23:57:56.618846  1494 solver.cpp:786] class AP 3: 0.560118
I0323 23:57:56.618872  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.424294
I0323 23:57:57.662381  1484 data_reader.cpp:305] Starting prefetch of epoch 2
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0
j:  : 4 : max_pr:  : 0.279093
j:  : 3 : max_pr:  : 0.411936
j:  : 2 : max_pr:  : 0.594411
j:  : 1 : max_pr:  : 0.722571
j:  : 0 : max_pr:  : 1
I0323 23:57:58.112660  1493 solver.cpp:786] class AP 1: 0.273456
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.182652
j:  : 6 : max_pr:  : 0.333779
j:  : 5 : max_pr:  : 0.404421
j:  : 4 : max_pr:  : 0.538851
j:  : 3 : max_pr:  : 0.685891
j:  : 2 : max_pr:  : 0.86
j:  : 1 : max_pr:  : 0.978378
j:  : 0 : max_pr:  : 1
I0323 23:57:58.167145  1493 solver.cpp:786] class AP 2: 0.453088
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.216061
j:  : 6 : max_pr:  : 0.524859
j:  : 5 : max_pr:  : 0.696322
j:  : 4 : max_pr:  : 0.824334
j:  : 3 : max_pr:  : 0.903288
j:  : 2 : max_pr:  : 0.965553
j:  : 1 : max_pr:  : 0.986769
j:  : 0 : max_pr:  : 1
I0323 23:57:58.177659  1493 solver.cpp:786] class AP 3: 0.556108
I0323 23:57:58.177680  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.427551
I0323 23:57:58.177742  1493 solver.cpp:265] [MultiGPU] Tests completed in 50.2045s
I0323 23:57:58.538506  1493 solver.cpp:314] Iteration 6000 (0.858903 iter/s, 116.428s/100 iter), loss = 3.64532
I0323 23:57:58.538555  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.89105 (* 1 = 2.89105 loss)
I0323 23:57:58.538569  1493 sgd_solver.cpp:136] Iteration 6000, lr = 0.01, m = 0.9
I0323 23:59:04.232373  1493 solver.cpp:314] Iteration 6100 (1.52226 iter/s, 65.6918s/100 iter), loss = 3.72147
I0323 23:59:04.232480  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.03591 (* 1 = 3.03591 loss)
I0323 23:59:04.232498  1493 sgd_solver.cpp:136] Iteration 6100, lr = 0.01, m = 0.9
I0324 00:00:10.231567  1493 solver.cpp:314] Iteration 6200 (1.51522 iter/s, 65.9971s/100 iter), loss = 3.39948
I0324 00:00:10.231691  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.60755 (* 1 = 2.60755 loss)
I0324 00:00:10.231709  1493 sgd_solver.cpp:136] Iteration 6200, lr = 0.01, m = 0.9
I0324 00:01:15.706171  1493 solver.cpp:314] Iteration 6300 (1.52736 iter/s, 65.4725s/100 iter), loss = 3.49766
I0324 00:01:15.706274  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.26824 (* 1 = 3.26824 loss)
I0324 00:01:15.706290  1493 sgd_solver.cpp:136] Iteration 6300, lr = 0.01, m = 0.9
I0324 00:02:20.990417  1493 solver.cpp:314] Iteration 6400 (1.53181 iter/s, 65.2822s/100 iter), loss = 3.39909
I0324 00:02:20.990517  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.53965 (* 1 = 2.53965 loss)
I0324 00:02:20.990533  1493 sgd_solver.cpp:136] Iteration 6400, lr = 0.01, m = 0.9
I0324 00:03:26.161092  1493 solver.cpp:314] Iteration 6500 (1.53448 iter/s, 65.1686s/100 iter), loss = 3.6938
I0324 00:03:26.161185  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.53954 (* 1 = 2.53954 loss)
I0324 00:03:26.161201  1493 sgd_solver.cpp:136] Iteration 6500, lr = 0.01, m = 0.9
I0324 00:04:31.741350  1493 solver.cpp:314] Iteration 6600 (1.5249 iter/s, 65.5782s/100 iter), loss = 3.97862
I0324 00:04:31.741487  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.57129 (* 1 = 3.57129 loss)
I0324 00:04:31.741503  1493 sgd_solver.cpp:136] Iteration 6600, lr = 0.01, m = 0.9
I0324 00:05:37.314642  1493 solver.cpp:314] Iteration 6700 (1.52506 iter/s, 65.5712s/100 iter), loss = 3.57041
I0324 00:05:37.314831  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.81369 (* 1 = 3.81369 loss)
I0324 00:05:37.314877  1493 sgd_solver.cpp:136] Iteration 6700, lr = 0.01, m = 0.9
I0324 00:06:41.639374  1493 solver.cpp:314] Iteration 6800 (1.55466 iter/s, 64.3227s/100 iter), loss = 3.5264
I0324 00:06:41.639467  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.78112 (* 1 = 3.78112 loss)
I0324 00:06:41.639483  1493 sgd_solver.cpp:136] Iteration 6800, lr = 0.01, m = 0.9
I0324 00:07:47.377039  1493 solver.cpp:314] Iteration 6900 (1.52125 iter/s, 65.7356s/100 iter), loss = 3.51282
I0324 00:07:47.377140  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.55444 (* 1 = 4.55444 loss)
I0324 00:07:47.377157  1493 sgd_solver.cpp:136] Iteration 6900, lr = 0.01, m = 0.9
I0324 00:08:54.100044  1493 solver.cpp:314] Iteration 7000 (1.49878 iter/s, 66.7209s/100 iter), loss = 3.37651
I0324 00:08:54.100154  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.0988 (* 1 = 4.0988 loss)
I0324 00:08:54.100170  1493 sgd_solver.cpp:136] Iteration 7000, lr = 0.01, m = 0.9
I0324 00:09:59.150048  1493 solver.cpp:314] Iteration 7100 (1.53733 iter/s, 65.048s/100 iter), loss = 3.39871
I0324 00:09:59.161775  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.87484 (* 1 = 3.87484 loss)
I0324 00:09:59.161813  1493 sgd_solver.cpp:136] Iteration 7100, lr = 0.01, m = 0.9
I0324 00:11:04.106070  1493 solver.cpp:314] Iteration 7200 (1.53955 iter/s, 64.954s/100 iter), loss = 3.56878
I0324 00:11:04.106170  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.91254 (* 1 = 2.91254 loss)
I0324 00:11:04.106186  1493 sgd_solver.cpp:136] Iteration 7200, lr = 0.01, m = 0.9
I0324 00:12:10.077451  1493 solver.cpp:314] Iteration 7300 (1.51586 iter/s, 65.9693s/100 iter), loss = 3.38421
I0324 00:12:10.077558  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.33571 (* 1 = 3.33571 loss)
I0324 00:12:10.077574  1493 sgd_solver.cpp:136] Iteration 7300, lr = 0.01, m = 0.9
I0324 00:13:16.223156  1493 solver.cpp:314] Iteration 7400 (1.51186 iter/s, 66.1436s/100 iter), loss = 3.39565
I0324 00:13:16.223249  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.12179 (* 1 = 3.12179 loss)
I0324 00:13:16.223265  1493 sgd_solver.cpp:136] Iteration 7400, lr = 0.01, m = 0.9
I0324 00:14:21.378032  1493 solver.cpp:314] Iteration 7500 (1.53485 iter/s, 65.1528s/100 iter), loss = 3.29695
I0324 00:14:21.378144  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.07874 (* 1 = 4.07874 loss)
I0324 00:14:21.378160  1493 sgd_solver.cpp:136] Iteration 7500, lr = 0.01, m = 0.9
I0324 00:15:26.844632  1493 solver.cpp:314] Iteration 7600 (1.52754 iter/s, 65.4646s/100 iter), loss = 3.57633
I0324 00:15:26.844722  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.51862 (* 1 = 4.51862 loss)
I0324 00:15:26.844738  1493 sgd_solver.cpp:136] Iteration 7600, lr = 0.01, m = 0.9
I0324 00:16:32.970170  1493 solver.cpp:314] Iteration 7700 (1.51232 iter/s, 66.1235s/100 iter), loss = 3.51353
I0324 00:16:32.970261  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.10791 (* 1 = 3.10791 loss)
I0324 00:16:32.970278  1493 sgd_solver.cpp:136] Iteration 7700, lr = 0.01, m = 0.9
I0324 00:17:38.005755  1493 solver.cpp:314] Iteration 7800 (1.53767 iter/s, 65.0336s/100 iter), loss = 3.59255
I0324 00:17:38.005854  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.40926 (* 1 = 3.40926 loss)
I0324 00:17:38.005872  1493 sgd_solver.cpp:136] Iteration 7800, lr = 0.01, m = 0.9
I0324 00:18:44.916975  1493 solver.cpp:314] Iteration 7900 (1.49456 iter/s, 66.9091s/100 iter), loss = 3.68403
I0324 00:18:44.917068  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.7763 (* 1 = 2.7763 loss)
I0324 00:18:44.917083  1493 sgd_solver.cpp:136] Iteration 7900, lr = 0.01, m = 0.9
I0324 00:19:50.453608  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_8000.caffemodel
I0324 00:19:50.483727  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_8000.solverstate
I0324 00:19:50.512354  1493 solver.cpp:678] Iteration 8000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.092346
j:  : 4 : max_pr:  : 0.213431
j:  : 3 : max_pr:  : 0.375501
j:  : 2 : max_pr:  : 0.588912
j:  : 1 : max_pr:  : 0.758143
j:  : 0 : max_pr:  : 1
I0324 00:20:39.216615  1493 solver.cpp:786] class AP 1: 0.275303
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0719037
j:  : 7 : max_pr:  : 0.20478
j:  : 6 : max_pr:  : 0.354954
j:  : 5 : max_pr:  : 0.521657
j:  : 4 : max_pr:  : 0.643117
j:  : 3 : max_pr:  : 0.751513
j:  : 2 : max_pr:  : 0.850641
j:  : 1 : max_pr:  : 0.973723
j:  : 0 : max_pr:  : 1
I0324 00:20:39.252051  1493 solver.cpp:786] class AP 2: 0.48839
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.244548
j:  : 6 : max_pr:  : 0.481944
j:  : 5 : max_pr:  : 0.640816
j:  : 4 : max_pr:  : 0.791737
j:  : 3 : max_pr:  : 0.905313
j:  : 2 : max_pr:  : 0.975829
j:  : 1 : max_pr:  : 0.996547
j:  : 0 : max_pr:  : 1
I0324 00:20:39.268198  1493 solver.cpp:786] class AP 3: 0.548794
I0324 00:20:39.268215  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.437496
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.0800874
j:  : 4 : max_pr:  : 0.18886
j:  : 3 : max_pr:  : 0.34786
j:  : 2 : max_pr:  : 0.560818
j:  : 1 : max_pr:  : 0.754334
j:  : 0 : max_pr:  : 1
I0324 00:20:40.112000  1494 solver.cpp:786] class AP 1: 0.266542
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0622612
j:  : 7 : max_pr:  : 0.193643
j:  : 6 : max_pr:  : 0.348679
j:  : 5 : max_pr:  : 0.51807
j:  : 4 : max_pr:  : 0.625216
j:  : 3 : max_pr:  : 0.733977
j:  : 2 : max_pr:  : 0.822309
j:  : 1 : max_pr:  : 0.974203
j:  : 0 : max_pr:  : 1
I0324 00:20:40.149173  1494 solver.cpp:786] class AP 2: 0.479851
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.240872
j:  : 6 : max_pr:  : 0.481904
j:  : 5 : max_pr:  : 0.61906
j:  : 4 : max_pr:  : 0.780258
j:  : 3 : max_pr:  : 0.907002
j:  : 2 : max_pr:  : 0.971448
j:  : 1 : max_pr:  : 0.997216
j:  : 0 : max_pr:  : 1
I0324 00:20:40.165241  1494 solver.cpp:786] class AP 3: 0.545251
I0324 00:20:40.165258  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.430548
I0324 00:20:40.165453  1493 solver.cpp:265] [MultiGPU] Tests completed in 49.6516s
I0324 00:20:40.645059  1493 solver.cpp:314] Iteration 8000 (0.864121 iter/s, 115.725s/100 iter), loss = 3.43207
I0324 00:20:40.645100  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.71073 (* 1 = 2.71073 loss)
I0324 00:20:40.645110  1493 sgd_solver.cpp:136] Iteration 8000, lr = 0.01, m = 0.9
I0324 00:21:45.682251  1493 solver.cpp:314] Iteration 8100 (1.53763 iter/s, 65.0352s/100 iter), loss = 3.52282
I0324 00:21:45.682437  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.28748 (* 1 = 3.28748 loss)
I0324 00:21:45.682477  1493 sgd_solver.cpp:136] Iteration 8100, lr = 0.01, m = 0.9
I0324 00:22:51.604496  1493 solver.cpp:314] Iteration 8200 (1.51699 iter/s, 65.9202s/100 iter), loss = 3.45494
I0324 00:22:51.604954  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.49514 (* 1 = 3.49514 loss)
I0324 00:22:51.605249  1493 sgd_solver.cpp:136] Iteration 8200, lr = 0.01, m = 0.9
I0324 00:23:57.259727  1493 solver.cpp:314] Iteration 8300 (1.52315 iter/s, 65.6532s/100 iter), loss = 3.48424
I0324 00:23:57.259883  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.86053 (* 1 = 2.86053 loss)
I0324 00:23:57.259923  1493 sgd_solver.cpp:136] Iteration 8300, lr = 0.01, m = 0.9
I0324 00:25:02.766027  1493 solver.cpp:314] Iteration 8400 (1.52662 iter/s, 65.5043s/100 iter), loss = 3.20079
I0324 00:25:02.766129  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.87111 (* 1 = 3.87111 loss)
I0324 00:25:02.766145  1493 sgd_solver.cpp:136] Iteration 8400, lr = 0.01, m = 0.9
I0324 00:26:08.209748  1493 solver.cpp:314] Iteration 8500 (1.52808 iter/s, 65.4417s/100 iter), loss = 3.68466
I0324 00:26:08.214956  1493 solver.cpp:336]     Train net output #0: mbox_loss = 5.14123 (* 1 = 5.14123 loss)
I0324 00:26:08.215009  1493 sgd_solver.cpp:136] Iteration 8500, lr = 0.01, m = 0.9
I0324 00:27:13.486155  1493 solver.cpp:314] Iteration 8600 (1.53199 iter/s, 65.2744s/100 iter), loss = 3.50389
I0324 00:27:13.486246  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.07484 (* 1 = 4.07484 loss)
I0324 00:27:13.486263  1493 sgd_solver.cpp:136] Iteration 8600, lr = 0.01, m = 0.9
I0324 00:28:18.958425  1493 solver.cpp:314] Iteration 8700 (1.52741 iter/s, 65.4703s/100 iter), loss = 3.47908
I0324 00:28:18.958520  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.26346 (* 1 = 3.26346 loss)
I0324 00:28:18.958536  1493 sgd_solver.cpp:136] Iteration 8700, lr = 0.01, m = 0.9
I0324 00:29:24.352366  1493 solver.cpp:314] Iteration 8800 (1.52924 iter/s, 65.3919s/100 iter), loss = 3.79761
I0324 00:29:24.352463  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.68835 (* 1 = 4.68835 loss)
I0324 00:29:24.352479  1493 sgd_solver.cpp:136] Iteration 8800, lr = 0.01, m = 0.9
I0324 00:30:31.694037  1493 solver.cpp:314] Iteration 8900 (1.48501 iter/s, 67.3396s/100 iter), loss = 3.53406
I0324 00:30:31.694169  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.56952 (* 1 = 3.56952 loss)
I0324 00:30:31.694185  1493 sgd_solver.cpp:136] Iteration 8900, lr = 0.01, m = 0.9
I0324 00:31:37.121475  1493 solver.cpp:314] Iteration 9000 (1.52846 iter/s, 65.4254s/100 iter), loss = 3.58133
I0324 00:31:37.121662  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.81429 (* 1 = 2.81429 loss)
I0324 00:31:37.121726  1493 sgd_solver.cpp:136] Iteration 9000, lr = 0.01, m = 0.9
I0324 00:31:54.971845  1462 data_reader.cpp:305] Starting prefetch of epoch 2
I0324 00:32:43.386075  1493 solver.cpp:314] Iteration 9100 (1.50915 iter/s, 66.2625s/100 iter), loss = 3.60358
I0324 00:32:43.386176  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.04168 (* 1 = 3.04168 loss)
I0324 00:32:43.386193  1493 sgd_solver.cpp:136] Iteration 9100, lr = 0.01, m = 0.9
I0324 00:33:48.909031  1493 solver.cpp:314] Iteration 9200 (1.52623 iter/s, 65.5209s/100 iter), loss = 3.43796
I0324 00:33:48.909135  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.18362 (* 1 = 2.18362 loss)
I0324 00:33:48.909153  1493 sgd_solver.cpp:136] Iteration 9200, lr = 0.01, m = 0.9
I0324 00:34:54.677342  1493 solver.cpp:314] Iteration 9300 (1.52054 iter/s, 65.7662s/100 iter), loss = 3.58827
I0324 00:34:54.677464  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.16888 (* 1 = 3.16888 loss)
I0324 00:34:54.677481  1493 sgd_solver.cpp:136] Iteration 9300, lr = 0.01, m = 0.9
I0324 00:36:00.543059  1493 solver.cpp:314] Iteration 9400 (1.51829 iter/s, 65.8636s/100 iter), loss = 3.54996
I0324 00:36:00.543151  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.80996 (* 1 = 3.80996 loss)
I0324 00:36:00.543167  1493 sgd_solver.cpp:136] Iteration 9400, lr = 0.01, m = 0.9
I0324 00:37:07.125758  1493 solver.cpp:314] Iteration 9500 (1.50194 iter/s, 66.5806s/100 iter), loss = 3.73318
I0324 00:37:07.128546  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.14847 (* 1 = 3.14847 loss)
I0324 00:37:07.128578  1493 sgd_solver.cpp:136] Iteration 9500, lr = 0.01, m = 0.9
I0324 00:38:13.182322  1493 solver.cpp:314] Iteration 9600 (1.5139 iter/s, 66.0545s/100 iter), loss = 3.34628
I0324 00:38:13.189757  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.1029 (* 1 = 3.1029 loss)
I0324 00:38:13.189786  1493 sgd_solver.cpp:136] Iteration 9600, lr = 0.01, m = 0.9
I0324 00:39:18.289948  1493 solver.cpp:314] Iteration 9700 (1.53597 iter/s, 65.1056s/100 iter), loss = 3.59371
I0324 00:39:18.290057  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.73427 (* 1 = 3.73427 loss)
I0324 00:39:18.290076  1493 sgd_solver.cpp:136] Iteration 9700, lr = 0.01, m = 0.9
I0324 00:40:23.290082  1493 solver.cpp:314] Iteration 9800 (1.53851 iter/s, 64.9981s/100 iter), loss = 3.3753
I0324 00:40:23.290187  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.01297 (* 1 = 3.01297 loss)
I0324 00:40:23.290202  1493 sgd_solver.cpp:136] Iteration 9800, lr = 0.01, m = 0.9
I0324 00:41:28.307837  1493 solver.cpp:314] Iteration 9900 (1.53809 iter/s, 65.0157s/100 iter), loss = 3.72817
I0324 00:41:28.307951  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.82434 (* 1 = 3.82434 loss)
I0324 00:41:28.307968  1493 sgd_solver.cpp:136] Iteration 9900, lr = 0.01, m = 0.9
I0324 00:42:32.880717  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_10000.caffemodel
I0324 00:42:32.914347  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_10000.solverstate
I0324 00:42:32.927933  1493 solver.cpp:678] Iteration 10000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.0883842
j:  : 4 : max_pr:  : 0.210196
j:  : 3 : max_pr:  : 0.382536
j:  : 2 : max_pr:  : 0.606086
j:  : 1 : max_pr:  : 0.763236
j:  : 0 : max_pr:  : 1
I0324 00:43:23.928879  1494 solver.cpp:786] class AP 1: 0.277313
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0.173365
j:  : 5 : max_pr:  : 0.296098
j:  : 4 : max_pr:  : 0.37654
j:  : 3 : max_pr:  : 0.466344
j:  : 2 : max_pr:  : 0.682019
j:  : 1 : max_pr:  : 0.995392
j:  : 0 : max_pr:  : 1
I0324 00:43:23.953594  1494 solver.cpp:786] class AP 2: 0.362705
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.139919
j:  : 6 : max_pr:  : 0.378528
j:  : 5 : max_pr:  : 0.604776
j:  : 4 : max_pr:  : 0.750606
j:  : 3 : max_pr:  : 0.904917
j:  : 2 : max_pr:  : 0.96203
j:  : 1 : max_pr:  : 0.997467
j:  : 0 : max_pr:  : 1
I0324 00:43:23.974536  1494 solver.cpp:786] class AP 3: 0.521658
I0324 00:43:23.974566  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.387225
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.0986902
j:  : 4 : max_pr:  : 0.219218
j:  : 3 : max_pr:  : 0.387883
j:  : 2 : max_pr:  : 0.609197
j:  : 1 : max_pr:  : 0.788062
j:  : 0 : max_pr:  : 1
I0324 00:43:24.445469  1493 solver.cpp:786] class AP 1: 0.282096
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0.181738
j:  : 5 : max_pr:  : 0.312734
j:  : 4 : max_pr:  : 0.395303
j:  : 3 : max_pr:  : 0.508448
j:  : 2 : max_pr:  : 0.703167
j:  : 1 : max_pr:  : 0.987934
j:  : 0 : max_pr:  : 1
I0324 00:43:24.464617  1493 solver.cpp:786] class AP 2: 0.371757
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.136155
j:  : 6 : max_pr:  : 0.402046
j:  : 5 : max_pr:  : 0.607677
j:  : 4 : max_pr:  : 0.764279
j:  : 3 : max_pr:  : 0.910002
j:  : 2 : max_pr:  : 0.96697
j:  : 1 : max_pr:  : 0.997945
j:  : 0 : max_pr:  : 1
I0324 00:43:24.481138  1493 solver.cpp:786] class AP 3: 0.525916
I0324 00:43:24.481165  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.393256
I0324 00:43:24.481240  1493 solver.cpp:265] [MultiGPU] Tests completed in 51.5517s
I0324 00:43:24.806480  1493 solver.cpp:314] Iteration 10000 (0.858406 iter/s, 116.495s/100 iter), loss = 3.56671
I0324 00:43:24.806599  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.35555 (* 1 = 3.35555 loss)
I0324 00:43:24.806639  1493 sgd_solver.cpp:136] Iteration 10000, lr = 0.01, m = 0.9
I0324 00:44:29.202270  1493 solver.cpp:314] Iteration 10100 (1.55295 iter/s, 64.3937s/100 iter), loss = 3.37112
I0324 00:44:29.202379  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.52113 (* 1 = 2.52113 loss)
I0324 00:44:29.202397  1493 sgd_solver.cpp:136] Iteration 10100, lr = 0.01, m = 0.9
I0324 00:45:34.875838  1493 solver.cpp:314] Iteration 10200 (1.52273 iter/s, 65.6715s/100 iter), loss = 3.46496
I0324 00:45:34.875946  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.62065 (* 1 = 2.62065 loss)
I0324 00:45:34.875963  1493 sgd_solver.cpp:136] Iteration 10200, lr = 0.01, m = 0.9
I0324 00:46:42.261962  1493 solver.cpp:314] Iteration 10300 (1.48403 iter/s, 67.384s/100 iter), loss = 3.2301
I0324 00:46:42.262140  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.39753 (* 1 = 4.39753 loss)
I0324 00:46:42.262195  1493 sgd_solver.cpp:136] Iteration 10300, lr = 0.01, m = 0.9
I0324 00:47:48.443289  1493 solver.cpp:314] Iteration 10400 (1.51105 iter/s, 66.1792s/100 iter), loss = 3.40286
I0324 00:47:48.443404  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.20781 (* 1 = 3.20781 loss)
I0324 00:47:48.443423  1493 sgd_solver.cpp:136] Iteration 10400, lr = 0.01, m = 0.9
I0324 00:48:53.699035  1493 solver.cpp:314] Iteration 10500 (1.53248 iter/s, 65.2537s/100 iter), loss = 3.59113
I0324 00:48:53.699147  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.34281 (* 1 = 4.34281 loss)
I0324 00:48:53.699164  1493 sgd_solver.cpp:136] Iteration 10500, lr = 0.01, m = 0.9
I0324 00:49:59.703778  1493 solver.cpp:314] Iteration 10600 (1.51509 iter/s, 66.0027s/100 iter), loss = 3.29992
I0324 00:49:59.703894  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.0981 (* 1 = 4.0981 loss)
I0324 00:49:59.703910  1493 sgd_solver.cpp:136] Iteration 10600, lr = 0.01, m = 0.9
I0324 00:51:05.309868  1493 solver.cpp:314] Iteration 10700 (1.5243 iter/s, 65.604s/100 iter), loss = 3.32804
I0324 00:51:05.309975  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.08175 (* 1 = 4.08175 loss)
I0324 00:51:05.309994  1493 sgd_solver.cpp:136] Iteration 10700, lr = 0.01, m = 0.9
I0324 00:52:12.448505  1493 solver.cpp:314] Iteration 10800 (1.4895 iter/s, 67.1365s/100 iter), loss = 3.40371
I0324 00:52:12.448608  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.73724 (* 1 = 3.73724 loss)
I0324 00:52:12.448626  1493 sgd_solver.cpp:136] Iteration 10800, lr = 0.01, m = 0.9
I0324 00:53:18.743923  1493 solver.cpp:314] Iteration 10900 (1.50845 iter/s, 66.2933s/100 iter), loss = 3.47074
I0324 00:53:18.744033  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.52648 (* 1 = 3.52648 loss)
I0324 00:53:18.744048  1493 sgd_solver.cpp:136] Iteration 10900, lr = 0.01, m = 0.9
I0324 00:54:25.006358  1493 solver.cpp:314] Iteration 11000 (1.5092 iter/s, 66.2602s/100 iter), loss = 3.59654
I0324 00:54:25.006561  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.91716 (* 1 = 3.91716 loss)
I0324 00:54:25.006579  1493 sgd_solver.cpp:136] Iteration 11000, lr = 0.01, m = 0.9
I0324 00:55:31.823015  1493 solver.cpp:314] Iteration 11100 (1.49668 iter/s, 66.8145s/100 iter), loss = 3.40073
I0324 00:55:31.823153  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.05204 (* 1 = 3.05204 loss)
I0324 00:55:31.823184  1493 sgd_solver.cpp:136] Iteration 11100, lr = 0.01, m = 0.9
I0324 00:56:39.242735  1493 solver.cpp:314] Iteration 11200 (1.48329 iter/s, 67.4175s/100 iter), loss = 3.35049
I0324 00:56:39.246502  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.85504 (* 1 = 2.85504 loss)
I0324 00:56:39.246537  1493 sgd_solver.cpp:136] Iteration 11200, lr = 0.01, m = 0.9
I0324 00:57:45.520761  1493 solver.cpp:314] Iteration 11300 (1.50885 iter/s, 66.2758s/100 iter), loss = 3.18078
I0324 00:57:45.520859  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.7724 (* 1 = 3.7724 loss)
I0324 00:57:45.520875  1493 sgd_solver.cpp:136] Iteration 11300, lr = 0.01, m = 0.9
I0324 00:58:52.693975  1493 solver.cpp:314] Iteration 11400 (1.48874 iter/s, 67.171s/100 iter), loss = 3.44213
I0324 00:58:52.694073  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.813 (* 1 = 2.813 loss)
I0324 00:58:52.694090  1493 sgd_solver.cpp:136] Iteration 11400, lr = 0.01, m = 0.9
I0324 00:59:59.712666  1493 solver.cpp:314] Iteration 11500 (1.49217 iter/s, 67.0165s/100 iter), loss = 3.50918
I0324 00:59:59.712762  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.7648 (* 1 = 2.7648 loss)
I0324 00:59:59.712777  1493 sgd_solver.cpp:136] Iteration 11500, lr = 0.01, m = 0.9
I0324 01:01:05.725922  1493 solver.cpp:314] Iteration 11600 (1.5149 iter/s, 66.0111s/100 iter), loss = 3.35634
I0324 01:01:05.726014  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.81372 (* 1 = 3.81372 loss)
I0324 01:01:05.726029  1493 sgd_solver.cpp:136] Iteration 11600, lr = 0.01, m = 0.9
I0324 01:02:13.388463  1493 solver.cpp:314] Iteration 11700 (1.47797 iter/s, 67.6603s/100 iter), loss = 3.38503
I0324 01:02:13.388573  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.92131 (* 1 = 3.92131 loss)
I0324 01:02:13.388590  1493 sgd_solver.cpp:136] Iteration 11700, lr = 0.01, m = 0.9
I0324 01:03:21.765744  1493 solver.cpp:314] Iteration 11800 (1.46252 iter/s, 68.3751s/100 iter), loss = 3.26905
I0324 01:03:21.765934  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.69845 (* 1 = 4.69845 loss)
I0324 01:03:21.765952  1493 sgd_solver.cpp:136] Iteration 11800, lr = 0.01, m = 0.9
I0324 01:04:29.253662  1493 solver.cpp:314] Iteration 11900 (1.48179 iter/s, 67.4857s/100 iter), loss = 3.44823
I0324 01:04:29.253777  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.10163 (* 1 = 4.10163 loss)
I0324 01:04:29.253832  1493 sgd_solver.cpp:136] Iteration 11900, lr = 0.01, m = 0.9
I0324 01:05:35.044499  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_12000.caffemodel
I0324 01:05:35.074874  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_12000.solverstate
I0324 01:05:35.088021  1493 solver.cpp:678] Iteration 12000, Testing net (#0)
I0324 01:06:25.431396  1484 data_reader.cpp:305] Starting prefetch of epoch 3
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.127876
j:  : 4 : max_pr:  : 0.28951
j:  : 3 : max_pr:  : 0.493061
j:  : 2 : max_pr:  : 0.660776
j:  : 1 : max_pr:  : 0.813529
j:  : 0 : max_pr:  : 1
I0324 01:06:26.228066  1493 solver.cpp:786] class AP 1: 0.307705
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.0430357
j:  : 6 : max_pr:  : 0.29075
j:  : 5 : max_pr:  : 0.393084
j:  : 4 : max_pr:  : 0.611717
j:  : 3 : max_pr:  : 0.656686
j:  : 2 : max_pr:  : 0.804497
j:  : 1 : max_pr:  : 0.967456
j:  : 0 : max_pr:  : 1
I0324 01:06:26.273908  1493 solver.cpp:786] class AP 2: 0.433384
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.310813
j:  : 6 : max_pr:  : 0.6223
j:  : 5 : max_pr:  : 0.707463
j:  : 4 : max_pr:  : 0.839286
j:  : 3 : max_pr:  : 0.918442
j:  : 2 : max_pr:  : 0.971663
j:  : 1 : max_pr:  : 0.993127
j:  : 0 : max_pr:  : 1
I0324 01:06:26.300473  1493 solver.cpp:786] class AP 3: 0.578463
I0324 01:06:26.300499  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.439851
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.137418
j:  : 4 : max_pr:  : 0.294831
j:  : 3 : max_pr:  : 0.498303
j:  : 2 : max_pr:  : 0.664343
j:  : 1 : max_pr:  : 0.81264
j:  : 0 : max_pr:  : 1
I0324 01:06:27.018479  1494 solver.cpp:786] class AP 1: 0.309776
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.0670853
j:  : 6 : max_pr:  : 0.314141
j:  : 5 : max_pr:  : 0.411594
j:  : 4 : max_pr:  : 0.616021
j:  : 3 : max_pr:  : 0.654193
j:  : 2 : max_pr:  : 0.800121
j:  : 1 : max_pr:  : 0.98051
j:  : 0 : max_pr:  : 1
I0324 01:06:27.053040  1494 solver.cpp:786] class AP 2: 0.440333
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.316018
j:  : 6 : max_pr:  : 0.625187
j:  : 5 : max_pr:  : 0.702768
j:  : 4 : max_pr:  : 0.831273
j:  : 3 : max_pr:  : 0.932902
j:  : 2 : max_pr:  : 0.977693
j:  : 1 : max_pr:  : 0.996556
j:  : 0 : max_pr:  : 1
I0324 01:06:27.073181  1494 solver.cpp:786] class AP 3: 0.580218
I0324 01:06:27.073199  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.443442
I0324 01:06:27.073773  1493 solver.cpp:265] [MultiGPU] Tests completed in 51.9841s
I0324 01:06:27.463096  1493 solver.cpp:314] Iteration 12000 (0.845983 iter/s, 118.206s/100 iter), loss = 3.27902
I0324 01:06:27.463147  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.22057 (* 1 = 4.22057 loss)
I0324 01:06:27.463157  1493 sgd_solver.cpp:136] Iteration 12000, lr = 0.01, m = 0.9
I0324 01:07:33.652843  1493 solver.cpp:314] Iteration 12100 (1.51086 iter/s, 66.1876s/100 iter), loss = 3.35193
I0324 01:07:33.652976  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.28957 (* 1 = 3.28957 loss)
I0324 01:07:33.652992  1493 sgd_solver.cpp:136] Iteration 12100, lr = 0.01, m = 0.9
I0324 01:08:41.037922  1493 solver.cpp:314] Iteration 12200 (1.48406 iter/s, 67.3828s/100 iter), loss = 3.64089
I0324 01:08:41.038036  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.45423 (* 1 = 3.45423 loss)
I0324 01:08:41.038053  1493 sgd_solver.cpp:136] Iteration 12200, lr = 0.01, m = 0.9
I0324 01:09:46.954119  1493 solver.cpp:314] Iteration 12300 (1.51713 iter/s, 65.914s/100 iter), loss = 3.38768
I0324 01:09:46.954223  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.10304 (* 1 = 4.10304 loss)
I0324 01:09:46.954238  1493 sgd_solver.cpp:136] Iteration 12300, lr = 0.01, m = 0.9
I0324 01:10:55.405983  1493 solver.cpp:314] Iteration 12400 (1.46093 iter/s, 68.4496s/100 iter), loss = 3.25215
I0324 01:10:55.406078  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.16809 (* 1 = 3.16809 loss)
I0324 01:10:55.406129  1493 sgd_solver.cpp:136] Iteration 12400, lr = 0.01, m = 0.9
I0324 01:12:03.290380  1493 solver.cpp:314] Iteration 12500 (1.47314 iter/s, 67.8822s/100 iter), loss = 3.60075
I0324 01:12:03.290477  1493 solver.cpp:336]     Train net output #0: mbox_loss = 5.87083 (* 1 = 5.87083 loss)
I0324 01:12:03.290491  1493 sgd_solver.cpp:136] Iteration 12500, lr = 0.01, m = 0.9
I0324 01:13:10.693929  1493 solver.cpp:314] Iteration 12600 (1.48365 iter/s, 67.4013s/100 iter), loss = 3.10517
I0324 01:13:10.694031  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.68245 (* 1 = 2.68245 loss)
I0324 01:13:10.694047  1493 sgd_solver.cpp:136] Iteration 12600, lr = 0.01, m = 0.9
I0324 01:14:18.174289  1493 solver.cpp:314] Iteration 12700 (1.48196 iter/s, 67.4781s/100 iter), loss = 3.19785
I0324 01:14:18.174453  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.82778 (* 1 = 2.82778 loss)
I0324 01:14:18.174485  1493 sgd_solver.cpp:136] Iteration 12700, lr = 0.01, m = 0.9
I0324 01:15:24.862468  1493 solver.cpp:314] Iteration 12800 (1.49957 iter/s, 66.686s/100 iter), loss = 3.24914
I0324 01:15:24.862571  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.96787 (* 1 = 2.96787 loss)
I0324 01:15:24.862589  1493 sgd_solver.cpp:136] Iteration 12800, lr = 0.01, m = 0.9
I0324 01:16:32.100735  1493 solver.cpp:314] Iteration 12900 (1.4873 iter/s, 67.236s/100 iter), loss = 3.50869
I0324 01:16:32.100921  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.99681 (* 1 = 3.99681 loss)
I0324 01:16:32.100965  1493 sgd_solver.cpp:136] Iteration 12900, lr = 0.01, m = 0.9
I0324 01:17:40.478075  1493 solver.cpp:314] Iteration 13000 (1.46252 iter/s, 68.3751s/100 iter), loss = 3.68001
I0324 01:17:40.478171  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.8691 (* 1 = 3.8691 loss)
I0324 01:17:40.478188  1493 sgd_solver.cpp:136] Iteration 13000, lr = 0.01, m = 0.9
I0324 01:18:47.891790  1493 solver.cpp:314] Iteration 13100 (1.48343 iter/s, 67.4115s/100 iter), loss = 3.59265
I0324 01:18:47.891897  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.57936 (* 1 = 3.57936 loss)
I0324 01:18:47.891914  1493 sgd_solver.cpp:136] Iteration 13100, lr = 0.01, m = 0.9
I0324 01:19:54.686573  1493 solver.cpp:314] Iteration 13200 (1.49717 iter/s, 66.7926s/100 iter), loss = 3.30138
I0324 01:19:54.686673  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.20258 (* 1 = 4.20258 loss)
I0324 01:19:54.686689  1493 sgd_solver.cpp:136] Iteration 13200, lr = 0.01, m = 0.9
I0324 01:21:02.797778  1493 solver.cpp:314] Iteration 13300 (1.46824 iter/s, 68.109s/100 iter), loss = 3.26095
I0324 01:21:02.797889  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.90228 (* 1 = 2.90228 loss)
I0324 01:21:02.797910  1493 sgd_solver.cpp:136] Iteration 13300, lr = 0.01, m = 0.9
I0324 01:22:10.458333  1493 solver.cpp:314] Iteration 13400 (1.47801 iter/s, 67.6583s/100 iter), loss = 3.54356
I0324 01:22:10.458467  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.07579 (* 1 = 3.07579 loss)
I0324 01:22:10.458482  1493 sgd_solver.cpp:136] Iteration 13400, lr = 0.01, m = 0.9
I0324 01:23:16.814280  1493 solver.cpp:314] Iteration 13500 (1.50708 iter/s, 66.3535s/100 iter), loss = 3.35192
I0324 01:23:16.814378  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.5404 (* 1 = 3.5404 loss)
I0324 01:23:16.814394  1493 sgd_solver.cpp:136] Iteration 13500, lr = 0.01, m = 0.9
I0324 01:24:25.011915  1493 solver.cpp:314] Iteration 13600 (1.46638 iter/s, 68.1951s/100 iter), loss = 3.50063
I0324 01:24:25.012024  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.7827 (* 1 = 2.7827 loss)
I0324 01:24:25.012048  1493 sgd_solver.cpp:136] Iteration 13600, lr = 0.01, m = 0.9
I0324 01:25:32.315466  1493 solver.cpp:314] Iteration 13700 (1.48586 iter/s, 67.301s/100 iter), loss = 3.77392
I0324 01:25:32.315582  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.25484 (* 1 = 3.25484 loss)
I0324 01:25:32.315600  1493 sgd_solver.cpp:136] Iteration 13700, lr = 0.01, m = 0.9
I0324 01:26:40.636320  1493 solver.cpp:314] Iteration 13800 (1.46374 iter/s, 68.3183s/100 iter), loss = 3.71731
I0324 01:26:40.636418  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.48557 (* 1 = 3.48557 loss)
I0324 01:26:40.636432  1493 sgd_solver.cpp:136] Iteration 13800, lr = 0.01, m = 0.9
I0324 01:27:46.901612  1493 solver.cpp:314] Iteration 13900 (1.50914 iter/s, 66.2628s/100 iter), loss = 3.32985
I0324 01:27:46.901718  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.73953 (* 1 = 3.73953 loss)
I0324 01:27:46.901734  1493 sgd_solver.cpp:136] Iteration 13900, lr = 0.01, m = 0.9
I0324 01:28:53.282320  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_14000.caffemodel
I0324 01:28:53.336619  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_14000.solverstate
I0324 01:28:53.351231  1493 solver.cpp:678] Iteration 14000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0
j:  : 4 : max_pr:  : 0.227073
j:  : 3 : max_pr:  : 0.463404
j:  : 2 : max_pr:  : 0.672385
j:  : 1 : max_pr:  : 0.79947
j:  : 0 : max_pr:  : 1
I0324 01:29:42.248080  1493 solver.cpp:786] class AP 1: 0.287485
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.141378
j:  : 6 : max_pr:  : 0.333069
j:  : 5 : max_pr:  : 0.416479
j:  : 4 : max_pr:  : 0.582929
j:  : 3 : max_pr:  : 0.685145
j:  : 2 : max_pr:  : 0.962035
j:  : 1 : max_pr:  : 0.993912
j:  : 0 : max_pr:  : 1
I0324 01:29:42.299069  1493 solver.cpp:786] class AP 2: 0.464995
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.407772
j:  : 6 : max_pr:  : 0.590134
j:  : 5 : max_pr:  : 0.695768
j:  : 4 : max_pr:  : 0.822665
j:  : 3 : max_pr:  : 0.901765
j:  : 2 : max_pr:  : 0.950267
j:  : 1 : max_pr:  : 0.998693
j:  : 0 : max_pr:  : 1
I0324 01:29:42.315351  1493 solver.cpp:786] class AP 3: 0.578824
I0324 01:29:42.315390  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.443768
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0
j:  : 4 : max_pr:  : 0.263239
j:  : 3 : max_pr:  : 0.498149
j:  : 2 : max_pr:  : 0.69049
j:  : 1 : max_pr:  : 0.814978
j:  : 0 : max_pr:  : 1
I0324 01:29:43.539805  1494 solver.cpp:786] class AP 1: 0.296987
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.154981
j:  : 6 : max_pr:  : 0.348476
j:  : 5 : max_pr:  : 0.435568
j:  : 4 : max_pr:  : 0.595926
j:  : 3 : max_pr:  : 0.705196
j:  : 2 : max_pr:  : 0.972933
j:  : 1 : max_pr:  : 0.997337
j:  : 0 : max_pr:  : 1
I0324 01:29:43.589936  1494 solver.cpp:786] class AP 2: 0.473674
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.393673
j:  : 6 : max_pr:  : 0.579096
j:  : 5 : max_pr:  : 0.686226
j:  : 4 : max_pr:  : 0.813333
j:  : 3 : max_pr:  : 0.901261
j:  : 2 : max_pr:  : 0.954762
j:  : 1 : max_pr:  : 0.999295
j:  : 0 : max_pr:  : 1
I0324 01:29:43.605798  1494 solver.cpp:786] class AP 3: 0.575241
I0324 01:29:43.605829  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.448634
I0324 01:29:43.606343  1493 solver.cpp:265] [MultiGPU] Tests completed in 50.2533s
I0324 01:29:44.034678  1493 solver.cpp:314] Iteration 14000 (0.853761 iter/s, 117.129s/100 iter), loss = 3.44722
I0324 01:29:44.034723  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.93244 (* 1 = 2.93244 loss)
I0324 01:29:44.034736  1493 sgd_solver.cpp:136] Iteration 14000, lr = 0.01, m = 0.9
I0324 01:30:50.603837  1493 solver.cpp:314] Iteration 14100 (1.50225 iter/s, 66.5667s/100 iter), loss = 3.33066
I0324 01:30:50.603941  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.91316 (* 1 = 2.91316 loss)
I0324 01:30:50.603956  1493 sgd_solver.cpp:136] Iteration 14100, lr = 0.01, m = 0.9
I0324 01:31:58.909924  1493 solver.cpp:314] Iteration 14200 (1.46405 iter/s, 68.3036s/100 iter), loss = 3.34804
I0324 01:31:58.910025  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.70849 (* 1 = 2.70849 loss)
I0324 01:31:58.910043  1493 sgd_solver.cpp:136] Iteration 14200, lr = 0.01, m = 0.9
I0324 01:33:05.977946  1493 solver.cpp:314] Iteration 14300 (1.49108 iter/s, 67.0655s/100 iter), loss = 3.60798
I0324 01:33:05.978139  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.2952 (* 1 = 4.2952 loss)
I0324 01:33:05.978183  1493 sgd_solver.cpp:136] Iteration 14300, lr = 0.01, m = 0.9
I0324 01:34:14.171448  1493 solver.cpp:314] Iteration 14400 (1.46647 iter/s, 68.191s/100 iter), loss = 3.31727
I0324 01:34:14.171581  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.3488 (* 1 = 3.3488 loss)
I0324 01:34:14.171602  1493 sgd_solver.cpp:136] Iteration 14400, lr = 0.01, m = 0.9
I0324 01:35:21.633782  1493 solver.cpp:314] Iteration 14500 (1.48236 iter/s, 67.4599s/100 iter), loss = 3.48788
I0324 01:35:21.633913  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.22493 (* 1 = 3.22493 loss)
I0324 01:35:21.633929  1493 sgd_solver.cpp:136] Iteration 14500, lr = 0.01, m = 0.9
I0324 01:36:29.464287  1493 solver.cpp:314] Iteration 14600 (1.47432 iter/s, 67.828s/100 iter), loss = 3.47816
I0324 01:36:29.464449  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.53951 (* 1 = 2.53951 loss)
I0324 01:36:29.464494  1493 sgd_solver.cpp:136] Iteration 14600, lr = 0.01, m = 0.9
I0324 01:37:36.945614  1493 solver.cpp:314] Iteration 14700 (1.48195 iter/s, 67.4789s/100 iter), loss = 3.74746
I0324 01:37:36.945734  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.5235 (* 1 = 2.5235 loss)
I0324 01:37:36.945752  1493 sgd_solver.cpp:136] Iteration 14700, lr = 0.01, m = 0.9
I0324 01:38:45.589309  1493 solver.cpp:314] Iteration 14800 (1.45685 iter/s, 68.6412s/100 iter), loss = 3.25079
I0324 01:38:45.589817  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.36086 (* 1 = 3.36086 loss)
I0324 01:38:45.589860  1493 sgd_solver.cpp:136] Iteration 14800, lr = 0.01, m = 0.9
I0324 01:39:53.036111  1493 solver.cpp:314] Iteration 14900 (1.4827 iter/s, 67.4444s/100 iter), loss = 3.45229
I0324 01:39:53.036213  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.75269 (* 1 = 2.75269 loss)
I0324 01:39:53.036228  1493 sgd_solver.cpp:136] Iteration 14900, lr = 0.01, m = 0.9
I0324 01:40:16.971506  1462 data_reader.cpp:305] Starting prefetch of epoch 3
I0324 01:41:00.541577  1493 solver.cpp:314] Iteration 15000 (1.48142 iter/s, 67.5029s/100 iter), loss = 3.31357
I0324 01:41:00.541710  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.92953 (* 1 = 2.92953 loss)
I0324 01:41:00.541731  1493 sgd_solver.cpp:136] Iteration 15000, lr = 0.01, m = 0.9
I0324 01:42:07.445760  1493 solver.cpp:314] Iteration 15100 (1.49474 iter/s, 66.9014s/100 iter), loss = 3.19273
I0324 01:42:07.453832  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.50422 (* 1 = 2.50422 loss)
I0324 01:42:07.453891  1493 sgd_solver.cpp:136] Iteration 15100, lr = 0.01, m = 0.9
I0324 01:43:14.975728  1493 solver.cpp:314] Iteration 15200 (1.48088 iter/s, 67.5272s/100 iter), loss = 3.41622
I0324 01:43:14.975824  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.44342 (* 1 = 3.44342 loss)
I0324 01:43:14.975841  1493 sgd_solver.cpp:136] Iteration 15200, lr = 0.01, m = 0.9
I0324 01:44:23.045131  1493 solver.cpp:314] Iteration 15300 (1.46915 iter/s, 68.0667s/100 iter), loss = 3.53393
I0324 01:44:23.045235  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.06966 (* 1 = 4.06966 loss)
I0324 01:44:23.045251  1493 sgd_solver.cpp:136] Iteration 15300, lr = 0.01, m = 0.9
I0324 01:45:31.008242  1493 solver.cpp:314] Iteration 15400 (1.47145 iter/s, 67.9604s/100 iter), loss = 3.57076
I0324 01:45:31.008404  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.99108 (* 1 = 2.99108 loss)
I0324 01:45:31.008450  1493 sgd_solver.cpp:136] Iteration 15400, lr = 0.01, m = 0.9
I0324 01:46:37.874505  1493 solver.cpp:314] Iteration 15500 (1.49558 iter/s, 66.8636s/100 iter), loss = 3.39432
I0324 01:46:37.874614  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.38494 (* 1 = 3.38494 loss)
I0324 01:46:37.874630  1493 sgd_solver.cpp:136] Iteration 15500, lr = 0.01, m = 0.9
I0324 01:47:45.048866  1493 solver.cpp:314] Iteration 15600 (1.48873 iter/s, 67.1712s/100 iter), loss = 3.52126
I0324 01:47:45.049412  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.32736 (* 1 = 3.32736 loss)
I0324 01:47:45.049787  1493 sgd_solver.cpp:136] Iteration 15600, lr = 0.01, m = 0.9
I0324 01:48:52.035972  1493 solver.cpp:314] Iteration 15700 (1.4929 iter/s, 66.9839s/100 iter), loss = 3.54131
I0324 01:48:52.036159  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.78782 (* 1 = 2.78782 loss)
I0324 01:48:52.036206  1493 sgd_solver.cpp:136] Iteration 15700, lr = 0.01, m = 0.9
I0324 01:49:59.173761  1493 solver.cpp:314] Iteration 15800 (1.48954 iter/s, 67.1347s/100 iter), loss = 3.56904
I0324 01:49:59.173985  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.97626 (* 1 = 2.97626 loss)
I0324 01:49:59.174034  1493 sgd_solver.cpp:136] Iteration 15800, lr = 0.01, m = 0.9
I0324 01:51:07.305764  1493 solver.cpp:314] Iteration 15900 (1.4678 iter/s, 68.129s/100 iter), loss = 3.55732
I0324 01:51:07.308660  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.78103 (* 1 = 3.78103 loss)
I0324 01:51:07.308678  1493 sgd_solver.cpp:136] Iteration 15900, lr = 0.01, m = 0.9
I0324 01:52:14.819656  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_16000.caffemodel
I0324 01:52:14.887532  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_16000.solverstate
I0324 01:52:14.908982  1493 solver.cpp:678] Iteration 16000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.109635
j:  : 4 : max_pr:  : 0.322591
j:  : 3 : max_pr:  : 0.475017
j:  : 2 : max_pr:  : 0.635158
j:  : 1 : max_pr:  : 0.745161
j:  : 0 : max_pr:  : 1
I0324 01:53:04.640537  1494 solver.cpp:786] class AP 1: 0.298869
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.066295
j:  : 7 : max_pr:  : 0.266153
j:  : 6 : max_pr:  : 0.411978
j:  : 5 : max_pr:  : 0.487112
j:  : 4 : max_pr:  : 0.527911
j:  : 3 : max_pr:  : 0.638996
j:  : 2 : max_pr:  : 0.984387
j:  : 1 : max_pr:  : 1
j:  : 0 : max_pr:  : 1
I0324 01:53:04.684640  1494 solver.cpp:786] class AP 2: 0.489348
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.318648
j:  : 6 : max_pr:  : 0.560553
j:  : 5 : max_pr:  : 0.664116
j:  : 4 : max_pr:  : 0.787705
j:  : 3 : max_pr:  : 0.892223
j:  : 2 : max_pr:  : 0.954101
j:  : 1 : max_pr:  : 0.992403
j:  : 0 : max_pr:  : 1
I0324 01:53:04.693123  1494 solver.cpp:786] class AP 3: 0.560886
I0324 01:53:04.693145  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.449701
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.0902004
j:  : 4 : max_pr:  : 0.310423
j:  : 3 : max_pr:  : 0.474536
j:  : 2 : max_pr:  : 0.643012
j:  : 1 : max_pr:  : 0.75021
j:  : 0 : max_pr:  : 1
I0324 01:53:05.740387  1493 solver.cpp:786] class AP 1: 0.297126
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0521254
j:  : 7 : max_pr:  : 0.275483
j:  : 6 : max_pr:  : 0.418198
j:  : 5 : max_pr:  : 0.482932
j:  : 4 : max_pr:  : 0.52297
j:  : 3 : max_pr:  : 0.620476
j:  : 2 : max_pr:  : 0.982184
j:  : 1 : max_pr:  : 0.995579
j:  : 0 : max_pr:  : 1
I0324 01:53:05.785544  1493 solver.cpp:786] class AP 2: 0.486359
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.308168
j:  : 6 : max_pr:  : 0.556764
j:  : 5 : max_pr:  : 0.659951
j:  : 4 : max_pr:  : 0.791485
j:  : 3 : max_pr:  : 0.896522
j:  : 2 : max_pr:  : 0.954592
j:  : 1 : max_pr:  : 0.987386
j:  : 0 : max_pr:  : 1
I0324 01:53:05.793956  1493 solver.cpp:786] class AP 3: 0.559533
I0324 01:53:05.793975  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.447673
I0324 01:53:05.794397  1493 solver.cpp:265] [MultiGPU] Tests completed in 50.8833s
I0324 01:53:06.245031  1493 solver.cpp:314] Iteration 16000 (0.840801 iter/s, 118.934s/100 iter), loss = 3.58185
I0324 01:53:06.245081  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.74418 (* 1 = 2.74418 loss)
I0324 01:53:06.245097  1493 sgd_solver.cpp:136] Iteration 16000, lr = 0.01, m = 0.9
I0324 01:54:12.892140  1493 solver.cpp:314] Iteration 16100 (1.5005 iter/s, 66.6444s/100 iter), loss = 3.63365
I0324 01:54:12.892246  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.56879 (* 1 = 3.56879 loss)
I0324 01:54:12.892263  1493 sgd_solver.cpp:136] Iteration 16100, lr = 0.01, m = 0.9
I0324 01:55:19.026055  1493 solver.cpp:314] Iteration 16200 (1.51214 iter/s, 66.1313s/100 iter), loss = 3.46666
I0324 01:55:19.026180  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.75814 (* 1 = 3.75814 loss)
I0324 01:55:19.026242  1493 sgd_solver.cpp:136] Iteration 16200, lr = 0.01, m = 0.9
I0324 01:56:27.937949  1493 solver.cpp:314] Iteration 16300 (1.45118 iter/s, 68.9093s/100 iter), loss = 3.22139
I0324 01:56:27.938050  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.22216 (* 1 = 3.22216 loss)
I0324 01:56:27.938064  1493 sgd_solver.cpp:136] Iteration 16300, lr = 0.01, m = 0.9
I0324 01:57:35.737799  1493 solver.cpp:314] Iteration 16400 (1.47498 iter/s, 67.7973s/100 iter), loss = 3.14434
I0324 01:57:35.737901  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.78541 (* 1 = 3.78541 loss)
I0324 01:57:35.737920  1493 sgd_solver.cpp:136] Iteration 16400, lr = 0.01, m = 0.9
I0324 01:58:43.141762  1493 solver.cpp:314] Iteration 16500 (1.48365 iter/s, 67.4015s/100 iter), loss = 3.38133
I0324 01:58:43.146232  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.607 (* 1 = 2.607 loss)
I0324 01:58:43.146291  1493 sgd_solver.cpp:136] Iteration 16500, lr = 0.01, m = 0.9
I0324 01:59:51.229951  1493 solver.cpp:314] Iteration 16600 (1.46874 iter/s, 68.0858s/100 iter), loss = 3.25371
I0324 01:59:51.230096  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.62042 (* 1 = 3.62042 loss)
I0324 01:59:51.230113  1493 sgd_solver.cpp:136] Iteration 16600, lr = 0.01, m = 0.9
I0324 02:00:59.460319  1493 solver.cpp:314] Iteration 16700 (1.46567 iter/s, 68.228s/100 iter), loss = 3.45712
I0324 02:00:59.460424  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.31103 (* 1 = 3.31103 loss)
I0324 02:00:59.460441  1493 sgd_solver.cpp:136] Iteration 16700, lr = 0.01, m = 0.9
I0324 02:02:08.015976  1493 solver.cpp:314] Iteration 16800 (1.45872 iter/s, 68.5533s/100 iter), loss = 3.39995
I0324 02:02:08.016101  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.04167 (* 1 = 3.04167 loss)
I0324 02:02:08.016119  1493 sgd_solver.cpp:136] Iteration 16800, lr = 0.01, m = 0.9
I0324 02:03:15.892104  1493 solver.cpp:314] Iteration 16900 (1.47332 iter/s, 67.8738s/100 iter), loss = 3.29085
I0324 02:03:15.892205  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.87195 (* 1 = 3.87195 loss)
I0324 02:03:15.892223  1493 sgd_solver.cpp:136] Iteration 16900, lr = 0.01, m = 0.9
I0324 02:04:25.185519  1493 solver.cpp:314] Iteration 17000 (1.44319 iter/s, 69.2911s/100 iter), loss = 3.58247
I0324 02:04:25.185657  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.97455 (* 1 = 3.97455 loss)
I0324 02:04:25.185688  1493 sgd_solver.cpp:136] Iteration 17000, lr = 0.01, m = 0.9
I0324 02:05:33.378283  1493 solver.cpp:314] Iteration 17100 (1.46648 iter/s, 68.1905s/100 iter), loss = 3.45222
I0324 02:05:33.378381  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.14737 (* 1 = 3.14737 loss)
I0324 02:05:33.378396  1493 sgd_solver.cpp:136] Iteration 17100, lr = 0.01, m = 0.9
I0324 02:06:42.526181  1493 solver.cpp:314] Iteration 17200 (1.44623 iter/s, 69.1453s/100 iter), loss = 3.57033
I0324 02:06:42.526288  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.05204 (* 1 = 3.05204 loss)
I0324 02:06:42.526304  1493 sgd_solver.cpp:136] Iteration 17200, lr = 0.01, m = 0.9
I0324 02:07:50.909178  1493 solver.cpp:314] Iteration 17300 (1.4624 iter/s, 68.3805s/100 iter), loss = 3.55865
I0324 02:07:50.909296  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.06042 (* 1 = 4.06042 loss)
I0324 02:07:50.909313  1493 sgd_solver.cpp:136] Iteration 17300, lr = 0.01, m = 0.9
I0324 02:08:59.750669  1493 solver.cpp:314] Iteration 17400 (1.45266 iter/s, 68.8392s/100 iter), loss = 3.6522
I0324 02:08:59.750783  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.31433 (* 1 = 3.31433 loss)
I0324 02:08:59.750795  1493 sgd_solver.cpp:136] Iteration 17400, lr = 0.01, m = 0.9
I0324 02:10:08.501528  1493 solver.cpp:314] Iteration 17500 (1.45458 iter/s, 68.7486s/100 iter), loss = 3.4229
I0324 02:10:08.501631  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.28968 (* 1 = 3.28968 loss)
I0324 02:10:08.501647  1493 sgd_solver.cpp:136] Iteration 17500, lr = 0.01, m = 0.9
I0324 02:11:16.819927  1493 solver.cpp:314] Iteration 17600 (1.46378 iter/s, 68.3161s/100 iter), loss = 3.37231
I0324 02:11:16.820039  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.0814 (* 1 = 3.0814 loss)
I0324 02:11:16.820055  1493 sgd_solver.cpp:136] Iteration 17600, lr = 0.01, m = 0.9
I0324 02:12:26.428428  1493 solver.cpp:314] Iteration 17700 (1.43665 iter/s, 69.6062s/100 iter), loss = 3.38358
I0324 02:12:26.428604  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.01492 (* 1 = 3.01492 loss)
I0324 02:12:26.428619  1493 sgd_solver.cpp:136] Iteration 17700, lr = 0.01, m = 0.9
I0324 02:13:34.453768  1493 solver.cpp:314] Iteration 17800 (1.47009 iter/s, 68.0231s/100 iter), loss = 3.32271
I0324 02:13:34.454229  1493 solver.cpp:336]     Train net output #0: mbox_loss = 5.23133 (* 1 = 5.23133 loss)
I0324 02:13:34.454533  1493 sgd_solver.cpp:136] Iteration 17800, lr = 0.01, m = 0.9
I0324 02:14:42.799410  1493 solver.cpp:314] Iteration 17900 (1.4632 iter/s, 68.3434s/100 iter), loss = 3.28651
I0324 02:14:42.799546  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.74021 (* 1 = 3.74021 loss)
I0324 02:14:42.799561  1493 sgd_solver.cpp:136] Iteration 17900, lr = 0.01, m = 0.9
I0324 02:15:50.065956  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_18000.caffemodel
I0324 02:15:50.112823  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_18000.solverstate
I0324 02:15:50.137229  1493 solver.cpp:678] Iteration 18000, Testing net (#0)
I0324 02:16:38.597935  1484 data_reader.cpp:305] Starting prefetch of epoch 4
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.0742609
j:  : 4 : max_pr:  : 0.291916
j:  : 3 : max_pr:  : 0.473343
j:  : 2 : max_pr:  : 0.62963
j:  : 1 : max_pr:  : 0.796288
j:  : 0 : max_pr:  : 1
I0324 02:16:39.687934  1493 solver.cpp:786] class AP 1: 0.296858
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.132686
j:  : 6 : max_pr:  : 0.269225
j:  : 5 : max_pr:  : 0.332712
j:  : 4 : max_pr:  : 0.445369
j:  : 3 : max_pr:  : 0.705236
j:  : 2 : max_pr:  : 0.880658
j:  : 1 : max_pr:  : 0.987059
j:  : 0 : max_pr:  : 1
I0324 02:16:39.713994  1493 solver.cpp:786] class AP 2: 0.432086
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.296645
j:  : 6 : max_pr:  : 0.503406
j:  : 5 : max_pr:  : 0.61267
j:  : 4 : max_pr:  : 0.718025
j:  : 3 : max_pr:  : 0.816573
j:  : 2 : max_pr:  : 0.920357
j:  : 1 : max_pr:  : 0.98983
j:  : 0 : max_pr:  : 1
I0324 02:16:39.736860  1493 solver.cpp:786] class AP 3: 0.532501
I0324 02:16:39.736891  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.420482
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0
j:  : 4 : max_pr:  : 0.285636
j:  : 3 : max_pr:  : 0.480458
j:  : 2 : max_pr:  : 0.637889
j:  : 1 : max_pr:  : 0.808237
j:  : 0 : max_pr:  : 1
I0324 02:16:39.902225  1494 solver.cpp:786] class AP 1: 0.29202
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.130745
j:  : 6 : max_pr:  : 0.262525
j:  : 5 : max_pr:  : 0.339611
j:  : 4 : max_pr:  : 0.445318
j:  : 3 : max_pr:  : 0.703997
j:  : 2 : max_pr:  : 0.920848
j:  : 1 : max_pr:  : 0.987897
j:  : 0 : max_pr:  : 1
I0324 02:16:39.927487  1494 solver.cpp:786] class AP 2: 0.43554
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.299536
j:  : 6 : max_pr:  : 0.4972
j:  : 5 : max_pr:  : 0.618646
j:  : 4 : max_pr:  : 0.72249
j:  : 3 : max_pr:  : 0.825969
j:  : 2 : max_pr:  : 0.922503
j:  : 1 : max_pr:  : 0.987646
j:  : 0 : max_pr:  : 1
I0324 02:16:39.949774  1494 solver.cpp:786] class AP 3: 0.533999
I0324 02:16:39.949791  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.42052
I0324 02:16:39.949913  1493 solver.cpp:265] [MultiGPU] Tests completed in 49.8111s
I0324 02:16:40.377734  1493 solver.cpp:314] Iteration 18000 (0.850524 iter/s, 117.575s/100 iter), loss = 3.36994
I0324 02:16:40.377787  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.13416 (* 1 = 3.13416 loss)
I0324 02:16:40.377802  1493 sgd_solver.cpp:136] Iteration 18000, lr = 0.01, m = 0.9
I0324 02:17:48.081506  1493 solver.cpp:314] Iteration 18100 (1.47707 iter/s, 67.7016s/100 iter), loss = 3.56786
I0324 02:17:48.081605  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.25438 (* 1 = 4.25438 loss)
I0324 02:17:48.081622  1493 sgd_solver.cpp:136] Iteration 18100, lr = 0.01, m = 0.9
I0324 02:18:56.080590  1493 solver.cpp:314] Iteration 18200 (1.47066 iter/s, 67.9969s/100 iter), loss = 3.34761
I0324 02:18:56.080708  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.11411 (* 1 = 3.11411 loss)
I0324 02:18:56.080725  1493 sgd_solver.cpp:136] Iteration 18200, lr = 0.01, m = 0.9
I0324 02:20:04.348018  1493 solver.cpp:314] Iteration 18300 (1.46487 iter/s, 68.2653s/100 iter), loss = 3.32588
I0324 02:20:04.348121  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.78083 (* 1 = 2.78083 loss)
I0324 02:20:04.348381  1493 sgd_solver.cpp:136] Iteration 18300, lr = 0.01, m = 0.9
I0324 02:21:12.465056  1493 solver.cpp:314] Iteration 18400 (1.46811 iter/s, 68.1149s/100 iter), loss = 3.51341
I0324 02:21:12.465147  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.91503 (* 1 = 2.91503 loss)
I0324 02:21:12.465160  1493 sgd_solver.cpp:136] Iteration 18400, lr = 0.01, m = 0.9
I0324 02:22:20.847021  1493 solver.cpp:314] Iteration 18500 (1.46242 iter/s, 68.3798s/100 iter), loss = 3.79226
I0324 02:22:20.847137  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.76967 (* 1 = 3.76967 loss)
I0324 02:22:20.847152  1493 sgd_solver.cpp:136] Iteration 18500, lr = 0.01, m = 0.9
I0324 02:23:28.808383  1493 solver.cpp:314] Iteration 18600 (1.47147 iter/s, 67.9592s/100 iter), loss = 3.45277
I0324 02:23:28.808490  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.89668 (* 1 = 2.89668 loss)
I0324 02:23:28.808506  1493 sgd_solver.cpp:136] Iteration 18600, lr = 0.01, m = 0.9
I0324 02:24:36.493877  1493 solver.cpp:314] Iteration 18700 (1.47747 iter/s, 67.6833s/100 iter), loss = 3.31322
I0324 02:24:36.493986  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.67828 (* 1 = 2.67828 loss)
I0324 02:24:36.494004  1493 sgd_solver.cpp:136] Iteration 18700, lr = 0.01, m = 0.9
I0324 02:25:45.061903  1493 solver.cpp:314] Iteration 18800 (1.45845 iter/s, 68.5659s/100 iter), loss = 3.20218
I0324 02:25:45.062011  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.29221 (* 1 = 3.29221 loss)
I0324 02:25:45.062028  1493 sgd_solver.cpp:136] Iteration 18800, lr = 0.01, m = 0.9
I0324 02:26:52.443099  1493 solver.cpp:314] Iteration 18900 (1.48414 iter/s, 67.3791s/100 iter), loss = 3.5696
I0324 02:26:52.446130  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.48884 (* 1 = 3.48884 loss)
I0324 02:26:52.446187  1493 sgd_solver.cpp:136] Iteration 18900, lr = 0.01, m = 0.9
I0324 02:28:00.241564  1493 solver.cpp:314] Iteration 19000 (1.47501 iter/s, 67.7963s/100 iter), loss = 3.30365
I0324 02:28:00.241674  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.04448 (* 1 = 4.04448 loss)
I0324 02:28:00.242308  1493 sgd_solver.cpp:136] Iteration 19000, lr = 0.01, m = 0.9
I0324 02:29:08.852954  1493 solver.cpp:314] Iteration 19100 (1.45753 iter/s, 68.6092s/100 iter), loss = 3.30343
I0324 02:29:08.853056  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.70191 (* 1 = 2.70191 loss)
I0324 02:29:08.853068  1493 sgd_solver.cpp:136] Iteration 19100, lr = 0.01, m = 0.9
I0324 02:30:16.756850  1493 solver.cpp:314] Iteration 19200 (1.47272 iter/s, 67.9018s/100 iter), loss = 3.28787
I0324 02:30:16.756942  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.59542 (* 1 = 4.59542 loss)
I0324 02:30:16.756990  1493 sgd_solver.cpp:136] Iteration 19200, lr = 0.01, m = 0.9
I0324 02:31:26.090167  1493 solver.cpp:314] Iteration 19300 (1.44235 iter/s, 69.3311s/100 iter), loss = 3.25885
I0324 02:31:26.090260  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.92242 (* 1 = 3.92242 loss)
I0324 02:31:26.090276  1493 sgd_solver.cpp:136] Iteration 19300, lr = 0.01, m = 0.9
I0324 02:32:34.603922  1493 solver.cpp:314] Iteration 19400 (1.45961 iter/s, 68.5116s/100 iter), loss = 3.32482
I0324 02:32:34.604045  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.46624 (* 1 = 3.46624 loss)
I0324 02:32:34.604063  1493 sgd_solver.cpp:136] Iteration 19400, lr = 0.01, m = 0.9
I0324 02:33:42.745759  1493 solver.cpp:314] Iteration 19500 (1.46757 iter/s, 68.1397s/100 iter), loss = 3.57517
I0324 02:33:42.745954  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.06664 (* 1 = 3.06664 loss)
I0324 02:33:42.746001  1493 sgd_solver.cpp:136] Iteration 19500, lr = 0.01, m = 0.9
I0324 02:34:50.006767  1493 solver.cpp:314] Iteration 19600 (1.48679 iter/s, 67.2588s/100 iter), loss = 3.39327
I0324 02:34:50.007279  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.89135 (* 1 = 3.89135 loss)
I0324 02:34:50.007601  1493 sgd_solver.cpp:136] Iteration 19600, lr = 0.01, m = 0.9
I0324 02:35:58.465950  1493 solver.cpp:314] Iteration 19700 (1.46077 iter/s, 68.457s/100 iter), loss = 3.50741
I0324 02:35:58.467294  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.78333 (* 1 = 3.78333 loss)
I0324 02:35:58.467389  1493 sgd_solver.cpp:136] Iteration 19700, lr = 0.01, m = 0.9
I0324 02:37:06.169937  1493 solver.cpp:314] Iteration 19800 (1.47707 iter/s, 67.7018s/100 iter), loss = 3.52263
I0324 02:37:06.170034  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.33142 (* 1 = 4.33142 loss)
I0324 02:37:06.170050  1493 sgd_solver.cpp:136] Iteration 19800, lr = 0.01, m = 0.9
I0324 02:38:14.249579  1493 solver.cpp:314] Iteration 19900 (1.46891 iter/s, 68.0775s/100 iter), loss = 3.21958
I0324 02:38:14.249680  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.26034 (* 1 = 3.26034 loss)
I0324 02:38:14.249706  1493 sgd_solver.cpp:136] Iteration 19900, lr = 0.01, m = 0.9
I0324 02:39:21.894328  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_20000.caffemodel
I0324 02:39:21.929373  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_20000.solverstate
I0324 02:39:21.941836  1493 solver.cpp:678] Iteration 20000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.176665
j:  : 4 : max_pr:  : 0.333088
j:  : 3 : max_pr:  : 0.543798
j:  : 2 : max_pr:  : 0.731181
j:  : 1 : max_pr:  : 0.840371
j:  : 0 : max_pr:  : 1
I0324 02:40:13.711907  1494 solver.cpp:786] class AP 1: 0.329555
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0494382
j:  : 7 : max_pr:  : 0.152309
j:  : 6 : max_pr:  : 0.249033
j:  : 5 : max_pr:  : 0.532077
j:  : 4 : max_pr:  : 0.724051
j:  : 3 : max_pr:  : 0.817874
j:  : 2 : max_pr:  : 0.981763
j:  : 1 : max_pr:  : 0.995522
j:  : 0 : max_pr:  : 1
I0324 02:40:13.751165  1494 solver.cpp:786] class AP 2: 0.500188
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.305371
j:  : 6 : max_pr:  : 0.553946
j:  : 5 : max_pr:  : 0.66792
j:  : 4 : max_pr:  : 0.807184
j:  : 3 : max_pr:  : 0.910832
j:  : 2 : max_pr:  : 0.95769
j:  : 1 : max_pr:  : 0.985161
j:  : 0 : max_pr:  : 1
I0324 02:40:13.772433  1494 solver.cpp:786] class AP 3: 0.562555
I0324 02:40:13.772462  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.464099
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.181645
j:  : 4 : max_pr:  : 0.33078
j:  : 3 : max_pr:  : 0.53421
j:  : 2 : max_pr:  : 0.720898
j:  : 1 : max_pr:  : 0.836406
j:  : 0 : max_pr:  : 1
I0324 02:40:13.854182  1493 solver.cpp:786] class AP 1: 0.327631
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0547233
j:  : 7 : max_pr:  : 0.147537
j:  : 6 : max_pr:  : 0.252727
j:  : 5 : max_pr:  : 0.559136
j:  : 4 : max_pr:  : 0.726767
j:  : 3 : max_pr:  : 0.81803
j:  : 2 : max_pr:  : 0.990166
j:  : 1 : max_pr:  : 1
j:  : 0 : max_pr:  : 1
I0324 02:40:13.893112  1493 solver.cpp:786] class AP 2: 0.504462
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.292602
j:  : 6 : max_pr:  : 0.548017
j:  : 5 : max_pr:  : 0.659067
j:  : 4 : max_pr:  : 0.797624
j:  : 3 : max_pr:  : 0.917853
j:  : 2 : max_pr:  : 0.960878
j:  : 1 : max_pr:  : 0.991864
j:  : 0 : max_pr:  : 1
I0324 02:40:13.913898  1493 solver.cpp:786] class AP 3: 0.560719
I0324 02:40:13.913936  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.464271
I0324 02:40:13.914335  1493 solver.cpp:265] [MultiGPU] Tests completed in 51.9708s
I0324 02:40:14.381657  1493 solver.cpp:314] Iteration 20000 (0.832444 iter/s, 120.128s/100 iter), loss = 3.72166
I0324 02:40:14.381719  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.8209 (* 1 = 2.8209 loss)
I0324 02:40:14.381737  1493 sgd_solver.cpp:136] Iteration 20000, lr = 0.01, m = 0.9
I0324 02:41:21.255056  1493 solver.cpp:314] Iteration 20100 (1.49541 iter/s, 66.8712s/100 iter), loss = 3.25393
I0324 02:41:21.255216  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.09607 (* 1 = 2.09607 loss)
I0324 02:41:21.255234  1493 sgd_solver.cpp:136] Iteration 20100, lr = 0.01, m = 0.9
I0324 02:42:29.588402  1493 solver.cpp:314] Iteration 20200 (1.46346 iter/s, 68.3311s/100 iter), loss = 3.25936
I0324 02:42:29.588515  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.35636 (* 1 = 3.35636 loss)
I0324 02:42:29.588531  1493 sgd_solver.cpp:136] Iteration 20200, lr = 0.01, m = 0.9
I0324 02:43:38.415886  1493 solver.cpp:314] Iteration 20300 (1.45296 iter/s, 68.8252s/100 iter), loss = 3.51516
I0324 02:43:38.416072  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.20549 (* 1 = 3.20549 loss)
I0324 02:43:38.416088  1493 sgd_solver.cpp:136] Iteration 20300, lr = 0.01, m = 0.9
I0324 02:44:46.994220  1493 solver.cpp:314] Iteration 20400 (1.45823 iter/s, 68.5761s/100 iter), loss = 3.34034
I0324 02:44:46.994323  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.88782 (* 1 = 2.88782 loss)
I0324 02:44:46.994336  1493 sgd_solver.cpp:136] Iteration 20400, lr = 0.01, m = 0.9
I0324 02:45:54.299638  1493 solver.cpp:314] Iteration 20500 (1.48581 iter/s, 67.3032s/100 iter), loss = 3.3049
I0324 02:45:54.299759  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.95579 (* 1 = 3.95579 loss)
I0324 02:45:54.299774  1493 sgd_solver.cpp:136] Iteration 20500, lr = 0.01, m = 0.9
I0324 02:47:02.026600  1493 solver.cpp:314] Iteration 20600 (1.47657 iter/s, 67.7247s/100 iter), loss = 3.32191
I0324 02:47:02.026744  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.37043 (* 1 = 3.37043 loss)
I0324 02:47:02.026763  1493 sgd_solver.cpp:136] Iteration 20600, lr = 0.01, m = 0.9
I0324 02:48:11.015346  1493 solver.cpp:314] Iteration 20700 (1.44956 iter/s, 68.9865s/100 iter), loss = 3.4972
I0324 02:48:11.015523  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.31054 (* 1 = 3.31054 loss)
I0324 02:48:11.015563  1493 sgd_solver.cpp:136] Iteration 20700, lr = 0.01, m = 0.9
I0324 02:49:18.649745  1493 solver.cpp:314] Iteration 20800 (1.47859 iter/s, 67.6322s/100 iter), loss = 3.14476
I0324 02:49:18.650768  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.53959 (* 1 = 2.53959 loss)
I0324 02:49:18.650786  1493 sgd_solver.cpp:136] Iteration 20800, lr = 0.01, m = 0.9
I0324 02:49:49.429471  1462 data_reader.cpp:305] Starting prefetch of epoch 4
I0324 02:50:26.268965  1493 solver.cpp:314] Iteration 20900 (1.47892 iter/s, 67.617s/100 iter), loss = 3.32912
I0324 02:50:26.269146  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.76675 (* 1 = 3.76675 loss)
I0324 02:50:26.269194  1493 sgd_solver.cpp:136] Iteration 20900, lr = 0.01, m = 0.9
I0324 02:51:33.714769  1493 solver.cpp:314] Iteration 21000 (1.48272 iter/s, 67.4436s/100 iter), loss = 3.36654
I0324 02:51:33.714879  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.68781 (* 1 = 2.68781 loss)
I0324 02:51:33.714895  1493 sgd_solver.cpp:136] Iteration 21000, lr = 0.01, m = 0.9
I0324 02:52:41.929245  1493 solver.cpp:314] Iteration 21100 (1.46601 iter/s, 68.2123s/100 iter), loss = 3.52332
I0324 02:52:41.929400  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.19348 (* 1 = 3.19348 loss)
I0324 02:52:41.929417  1493 sgd_solver.cpp:136] Iteration 21100, lr = 0.01, m = 0.9
I0324 02:53:49.580140  1493 solver.cpp:314] Iteration 21200 (1.47823 iter/s, 67.6487s/100 iter), loss = 3.43547
I0324 02:53:49.580241  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.2509 (* 1 = 3.2509 loss)
I0324 02:53:49.580257  1493 sgd_solver.cpp:136] Iteration 21200, lr = 0.01, m = 0.9
I0324 02:54:58.335450  1493 solver.cpp:314] Iteration 21300 (1.45448 iter/s, 68.7531s/100 iter), loss = 3.52543
I0324 02:54:58.335551  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.97907 (* 1 = 2.97907 loss)
I0324 02:54:58.335567  1493 sgd_solver.cpp:136] Iteration 21300, lr = 0.01, m = 0.9
I0324 02:56:06.445991  1493 solver.cpp:314] Iteration 21400 (1.46825 iter/s, 68.1084s/100 iter), loss = 3.18732
I0324 02:56:06.446099  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.93023 (* 1 = 2.93023 loss)
I0324 02:56:06.446118  1493 sgd_solver.cpp:136] Iteration 21400, lr = 0.01, m = 0.9
I0324 02:57:14.519945  1493 solver.cpp:314] Iteration 21500 (1.46904 iter/s, 68.0718s/100 iter), loss = 3.2296
I0324 02:57:14.520040  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.17727 (* 1 = 2.17727 loss)
I0324 02:57:14.520056  1493 sgd_solver.cpp:136] Iteration 21500, lr = 0.01, m = 0.9
I0324 02:58:22.479888  1493 solver.cpp:314] Iteration 21600 (1.4715 iter/s, 67.9577s/100 iter), loss = 3.32777
I0324 02:58:22.480026  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.58279 (* 1 = 3.58279 loss)
I0324 02:58:22.480048  1493 sgd_solver.cpp:136] Iteration 21600, lr = 0.01, m = 0.9
I0324 02:59:28.993958  1493 solver.cpp:314] Iteration 21700 (1.50349 iter/s, 66.5119s/100 iter), loss = 3.39898
I0324 02:59:28.994060  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.73504 (* 1 = 2.73504 loss)
I0324 02:59:28.994076  1493 sgd_solver.cpp:136] Iteration 21700, lr = 0.01, m = 0.9
I0324 03:00:37.518712  1493 solver.cpp:314] Iteration 21800 (1.45937 iter/s, 68.5225s/100 iter), loss = 3.2361
I0324 03:00:37.518821  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.43218 (* 1 = 2.43218 loss)
I0324 03:00:37.518841  1493 sgd_solver.cpp:136] Iteration 21800, lr = 0.01, m = 0.9
I0324 03:01:45.914625  1493 solver.cpp:314] Iteration 21900 (1.46212 iter/s, 68.3937s/100 iter), loss = 3.35305
I0324 03:01:45.915123  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.04785 (* 1 = 3.04785 loss)
I0324 03:01:45.915446  1493 sgd_solver.cpp:136] Iteration 21900, lr = 0.01, m = 0.9
I0324 03:02:53.726816  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_22000.caffemodel
I0324 03:02:53.772471  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_22000.solverstate
I0324 03:02:53.807066  1493 solver.cpp:678] Iteration 22000, Testing net (#0)
I0324 03:02:57.749728  1494 blocking_queue.cpp:40] Data layer prefetch queue empty
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.214566
j:  : 4 : max_pr:  : 0.352058
j:  : 3 : max_pr:  : 0.492398
j:  : 2 : max_pr:  : 0.661838
j:  : 1 : max_pr:  : 0.817642
j:  : 0 : max_pr:  : 1
I0324 03:03:43.102856  1494 solver.cpp:786] class AP 1: 0.321682
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.223828
j:  : 6 : max_pr:  : 0.358517
j:  : 5 : max_pr:  : 0.451576
j:  : 4 : max_pr:  : 0.560089
j:  : 3 : max_pr:  : 0.64851
j:  : 2 : max_pr:  : 0.835535
j:  : 1 : max_pr:  : 0.998843
j:  : 0 : max_pr:  : 1
I0324 03:03:43.156816  1494 solver.cpp:786] class AP 2: 0.461536
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.319547
j:  : 6 : max_pr:  : 0.590697
j:  : 5 : max_pr:  : 0.700851
j:  : 4 : max_pr:  : 0.812886
j:  : 3 : max_pr:  : 0.879959
j:  : 2 : max_pr:  : 0.943816
j:  : 1 : max_pr:  : 0.995315
j:  : 0 : max_pr:  : 1
I0324 03:03:43.167377  1494 solver.cpp:786] class AP 3: 0.567552
I0324 03:03:43.167400  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.450257
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.231233
j:  : 4 : max_pr:  : 0.365882
j:  : 3 : max_pr:  : 0.515491
j:  : 2 : max_pr:  : 0.675968
j:  : 1 : max_pr:  : 0.833107
j:  : 0 : max_pr:  : 1
I0324 03:03:43.865933  1493 solver.cpp:786] class AP 1: 0.329244
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0293718
j:  : 7 : max_pr:  : 0.267344
j:  : 6 : max_pr:  : 0.39353
j:  : 5 : max_pr:  : 0.481192
j:  : 4 : max_pr:  : 0.590375
j:  : 3 : max_pr:  : 0.670007
j:  : 2 : max_pr:  : 0.899256
j:  : 1 : max_pr:  : 0.9989
j:  : 0 : max_pr:  : 1
I0324 03:03:43.918349  1493 solver.cpp:786] class AP 2: 0.484543
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.305277
j:  : 6 : max_pr:  : 0.567942
j:  : 5 : max_pr:  : 0.688976
j:  : 4 : max_pr:  : 0.805053
j:  : 3 : max_pr:  : 0.873111
j:  : 2 : max_pr:  : 0.944855
j:  : 1 : max_pr:  : 0.995254
j:  : 0 : max_pr:  : 1
I0324 03:03:43.928908  1493 solver.cpp:786] class AP 3: 0.561861
I0324 03:03:43.928923  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.458549
I0324 03:03:43.929320  1493 solver.cpp:265] [MultiGPU] Tests completed in 50.1206s
I0324 03:03:44.335175  1493 solver.cpp:314] Iteration 22000 (0.844475 iter/s, 118.417s/100 iter), loss = 3.27956
I0324 03:03:44.335224  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.73915 (* 1 = 2.73915 loss)
I0324 03:03:44.335238  1493 sgd_solver.cpp:136] Iteration 22000, lr = 0.01, m = 0.9
I0324 03:04:52.153982  1493 solver.cpp:314] Iteration 22100 (1.47457 iter/s, 67.8166s/100 iter), loss = 3.20011
I0324 03:04:52.154176  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.7268 (* 1 = 3.7268 loss)
I0324 03:04:52.154217  1493 sgd_solver.cpp:136] Iteration 22100, lr = 0.01, m = 0.9
I0324 03:06:00.027003  1493 solver.cpp:314] Iteration 22200 (1.47339 iter/s, 67.8708s/100 iter), loss = 3.23635
I0324 03:06:00.027107  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.01643 (* 1 = 4.01643 loss)
I0324 03:06:00.027124  1493 sgd_solver.cpp:136] Iteration 22200, lr = 0.01, m = 0.9
I0324 03:07:08.302386  1493 solver.cpp:314] Iteration 22300 (1.4647 iter/s, 68.2732s/100 iter), loss = 3.3497
I0324 03:07:08.302484  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.10656 (* 1 = 3.10656 loss)
I0324 03:07:08.302500  1493 sgd_solver.cpp:136] Iteration 22300, lr = 0.01, m = 0.9
I0324 03:08:17.222054  1493 solver.cpp:314] Iteration 22400 (1.45101 iter/s, 68.9174s/100 iter), loss = 3.33389
I0324 03:08:17.222255  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.41235 (* 1 = 2.41235 loss)
I0324 03:08:17.222272  1493 sgd_solver.cpp:136] Iteration 22400, lr = 0.01, m = 0.9
I0324 03:09:25.037597  1493 solver.cpp:314] Iteration 22500 (1.47464 iter/s, 67.8134s/100 iter), loss = 3.27002
I0324 03:09:25.037719  1493 solver.cpp:336]     Train net output #0: mbox_loss = 5.07316 (* 1 = 5.07316 loss)
I0324 03:09:25.037734  1493 sgd_solver.cpp:136] Iteration 22500, lr = 0.01, m = 0.9
I0324 03:10:34.162050  1493 solver.cpp:314] Iteration 22600 (1.44671 iter/s, 69.1222s/100 iter), loss = 3.42982
I0324 03:10:34.162158  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.68374 (* 1 = 3.68374 loss)
I0324 03:10:34.162174  1493 sgd_solver.cpp:136] Iteration 22600, lr = 0.01, m = 0.9
I0324 03:11:42.729990  1493 solver.cpp:314] Iteration 22700 (1.45845 iter/s, 68.5657s/100 iter), loss = 3.22971
I0324 03:11:42.730099  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.51295 (* 1 = 3.51295 loss)
I0324 03:11:42.730114  1493 sgd_solver.cpp:136] Iteration 22700, lr = 0.01, m = 0.9
I0324 03:12:50.525934  1493 solver.cpp:314] Iteration 22800 (1.47506 iter/s, 67.7938s/100 iter), loss = 3.29671
I0324 03:12:50.545877  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.1362 (* 1 = 3.1362 loss)
I0324 03:12:50.545910  1493 sgd_solver.cpp:136] Iteration 22800, lr = 0.01, m = 0.9
I0324 03:13:58.034446  1493 solver.cpp:314] Iteration 22900 (1.48134 iter/s, 67.5063s/100 iter), loss = 3.34538
I0324 03:13:58.034551  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.82425 (* 1 = 2.82425 loss)
I0324 03:13:58.034569  1493 sgd_solver.cpp:136] Iteration 22900, lr = 0.01, m = 0.9
I0324 03:15:07.076831  1493 solver.cpp:314] Iteration 23000 (1.44843 iter/s, 69.0402s/100 iter), loss = 3.27965
I0324 03:15:07.076936  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.75501 (* 1 = 2.75501 loss)
I0324 03:15:07.076954  1493 sgd_solver.cpp:136] Iteration 23000, lr = 0.01, m = 0.9
I0324 03:16:15.591579  1493 solver.cpp:314] Iteration 23100 (1.45959 iter/s, 68.5126s/100 iter), loss = 3.34976
I0324 03:16:15.591676  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.5104 (* 1 = 4.5104 loss)
I0324 03:16:15.591693  1493 sgd_solver.cpp:136] Iteration 23100, lr = 0.01, m = 0.9
I0324 03:17:23.735728  1493 solver.cpp:314] Iteration 23200 (1.46752 iter/s, 68.142s/100 iter), loss = 3.11091
I0324 03:17:23.735898  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.61029 (* 1 = 3.61029 loss)
I0324 03:17:23.735951  1493 sgd_solver.cpp:136] Iteration 23200, lr = 0.01, m = 0.9
I0324 03:18:30.940017  1493 solver.cpp:314] Iteration 23300 (1.48805 iter/s, 67.2021s/100 iter), loss = 3.3608
I0324 03:18:30.944656  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.55852 (* 1 = 3.55852 loss)
I0324 03:18:30.944687  1493 sgd_solver.cpp:136] Iteration 23300, lr = 0.01, m = 0.9
I0324 03:19:39.009754  1493 solver.cpp:314] Iteration 23400 (1.46913 iter/s, 68.0676s/100 iter), loss = 3.67897
I0324 03:19:39.013766  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.66934 (* 1 = 3.66934 loss)
I0324 03:19:39.013795  1493 sgd_solver.cpp:136] Iteration 23400, lr = 0.01, m = 0.9
I0324 03:20:48.370496  1493 solver.cpp:314] Iteration 23500 (1.44178 iter/s, 69.3585s/100 iter), loss = 3.29584
I0324 03:20:48.370609  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.30967 (* 1 = 3.30967 loss)
I0324 03:20:48.370626  1493 sgd_solver.cpp:136] Iteration 23500, lr = 0.01, m = 0.9
I0324 03:21:57.380429  1493 solver.cpp:314] Iteration 23600 (1.44911 iter/s, 69.0077s/100 iter), loss = 3.29315
I0324 03:21:57.385754  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.46097 (* 1 = 2.46097 loss)
I0324 03:21:57.385781  1493 sgd_solver.cpp:136] Iteration 23600, lr = 0.01, m = 0.9
I0324 03:23:05.439491  1493 solver.cpp:314] Iteration 23700 (1.46936 iter/s, 68.0569s/100 iter), loss = 3.19056
I0324 03:23:05.439579  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.0267 (* 1 = 3.0267 loss)
I0324 03:23:05.439595  1493 sgd_solver.cpp:136] Iteration 23700, lr = 0.01, m = 0.9
I0324 03:24:13.667991  1493 solver.cpp:314] Iteration 23800 (1.46571 iter/s, 68.2263s/100 iter), loss = 3.48804
I0324 03:24:13.668095  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.52121 (* 1 = 3.52121 loss)
I0324 03:24:13.668110  1493 sgd_solver.cpp:136] Iteration 23800, lr = 0.01, m = 0.9
I0324 03:25:22.160535  1493 solver.cpp:314] Iteration 23900 (1.46006 iter/s, 68.4904s/100 iter), loss = 3.31552
I0324 03:25:22.160645  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.47637 (* 1 = 3.47637 loss)
I0324 03:25:22.160660  1493 sgd_solver.cpp:136] Iteration 23900, lr = 0.01, m = 0.9
I0324 03:26:13.679545  1462 data_reader.cpp:305] Starting prefetch of epoch 5
I0324 03:26:30.398116  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_24000.caffemodel
I0324 03:26:30.438395  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_24000.solverstate
I0324 03:26:30.455543  1493 solver.cpp:678] Iteration 24000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.197889
j:  : 4 : max_pr:  : 0.377845
j:  : 3 : max_pr:  : 0.557948
j:  : 2 : max_pr:  : 0.688452
j:  : 1 : max_pr:  : 0.822365
j:  : 0 : max_pr:  : 1
I0324 03:27:20.163981  1494 solver.cpp:786] class AP 1: 0.331318
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.193523
j:  : 6 : max_pr:  : 0.495456
j:  : 5 : max_pr:  : 0.625
j:  : 4 : max_pr:  : 0.671591
j:  : 3 : max_pr:  : 0.704839
j:  : 2 : max_pr:  : 0.912482
j:  : 1 : max_pr:  : 0.996918
j:  : 0 : max_pr:  : 1
I0324 03:27:20.201545  1494 solver.cpp:786] class AP 2: 0.509074
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.374188
j:  : 6 : max_pr:  : 0.62892
j:  : 5 : max_pr:  : 0.736214
j:  : 4 : max_pr:  : 0.838196
j:  : 3 : max_pr:  : 0.907276
j:  : 2 : max_pr:  : 0.966404
j:  : 1 : max_pr:  : 0.995254
j:  : 0 : max_pr:  : 1
I0324 03:27:20.207870  1494 solver.cpp:786] class AP 3: 0.586041
I0324 03:27:20.207883  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.475478
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.21404
j:  : 4 : max_pr:  : 0.389651
j:  : 3 : max_pr:  : 0.568032
j:  : 2 : max_pr:  : 0.685869
j:  : 1 : max_pr:  : 0.802964
j:  : 0 : max_pr:  : 1
I0324 03:27:20.601045  1493 solver.cpp:786] class AP 1: 0.332778
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.193665
j:  : 6 : max_pr:  : 0.494566
j:  : 5 : max_pr:  : 0.631358
j:  : 4 : max_pr:  : 0.684552
j:  : 3 : max_pr:  : 0.722141
j:  : 2 : max_pr:  : 0.949677
j:  : 1 : max_pr:  : 0.995169
j:  : 0 : max_pr:  : 1
I0324 03:27:20.637691  1493 solver.cpp:786] class AP 2: 0.515557
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.403538
j:  : 6 : max_pr:  : 0.637482
j:  : 5 : max_pr:  : 0.748087
j:  : 4 : max_pr:  : 0.846131
j:  : 3 : max_pr:  : 0.9079
j:  : 2 : max_pr:  : 0.966165
j:  : 1 : max_pr:  : 0.996533
j:  : 0 : max_pr:  : 1
I0324 03:27:20.643834  1493 solver.cpp:786] class AP 3: 0.59144
I0324 03:27:20.643846  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.479925
I0324 03:27:20.644266  1493 solver.cpp:265] [MultiGPU] Tests completed in 50.1871s
I0324 03:27:21.029166  1493 solver.cpp:314] Iteration 24000 (0.841292 iter/s, 118.865s/100 iter), loss = 3.35702
I0324 03:27:21.029211  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.30069 (* 1 = 3.30069 loss)
I0324 03:27:21.029223  1493 sgd_solver.cpp:136] Iteration 24000, lr = 0.01, m = 0.9
I0324 03:28:28.333950  1493 solver.cpp:314] Iteration 24100 (1.48583 iter/s, 67.3026s/100 iter), loss = 3.25341
I0324 03:28:28.334065  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.97696 (* 1 = 3.97696 loss)
I0324 03:28:28.334082  1493 sgd_solver.cpp:136] Iteration 24100, lr = 0.01, m = 0.9
I0324 03:29:38.457409  1493 solver.cpp:314] Iteration 24200 (1.4261 iter/s, 70.1212s/100 iter), loss = 3.40958
I0324 03:29:38.457514  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.08884 (* 1 = 3.08884 loss)
I0324 03:29:38.457530  1493 sgd_solver.cpp:136] Iteration 24200, lr = 0.01, m = 0.9
I0324 03:30:46.117868  1493 solver.cpp:314] Iteration 24300 (1.47802 iter/s, 67.6582s/100 iter), loss = 3.44554
I0324 03:30:46.118000  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.56992 (* 1 = 3.56992 loss)
I0324 03:30:46.118017  1493 sgd_solver.cpp:136] Iteration 24300, lr = 0.01, m = 0.9
I0324 03:31:55.008327  1493 solver.cpp:314] Iteration 24400 (1.45163 iter/s, 68.8882s/100 iter), loss = 3.34375
I0324 03:31:55.008442  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.8685 (* 1 = 3.8685 loss)
I0324 03:31:55.008458  1493 sgd_solver.cpp:136] Iteration 24400, lr = 0.01, m = 0.9
I0324 03:33:02.927687  1493 solver.cpp:314] Iteration 24500 (1.47238 iter/s, 67.9171s/100 iter), loss = 3.11755
I0324 03:33:02.927798  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.65164 (* 1 = 2.65164 loss)
I0324 03:33:02.927814  1493 sgd_solver.cpp:136] Iteration 24500, lr = 0.01, m = 0.9
I0324 03:34:10.598026  1493 solver.cpp:314] Iteration 24600 (1.4778 iter/s, 67.6681s/100 iter), loss = 3.14617
I0324 03:34:10.598124  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.05121 (* 1 = 3.05121 loss)
I0324 03:34:10.598140  1493 sgd_solver.cpp:136] Iteration 24600, lr = 0.01, m = 0.9
I0324 03:35:19.284149  1493 solver.cpp:314] Iteration 24700 (1.45595 iter/s, 68.6839s/100 iter), loss = 3.33678
I0324 03:35:19.284247  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.4067 (* 1 = 3.4067 loss)
I0324 03:35:19.284262  1493 sgd_solver.cpp:136] Iteration 24700, lr = 0.01, m = 0.9
I0324 03:36:27.823156  1493 solver.cpp:314] Iteration 24800 (1.45907 iter/s, 68.5368s/100 iter), loss = 3.55168
I0324 03:36:27.823352  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.50938 (* 1 = 2.50938 loss)
I0324 03:36:27.823369  1493 sgd_solver.cpp:136] Iteration 24800, lr = 0.01, m = 0.9
I0324 03:37:37.314131  1493 solver.cpp:314] Iteration 24900 (1.43908 iter/s, 69.4887s/100 iter), loss = 3.16249
I0324 03:37:37.314234  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.19893 (* 1 = 3.19893 loss)
I0324 03:37:37.314252  1493 sgd_solver.cpp:136] Iteration 24900, lr = 0.01, m = 0.9
I0324 03:38:45.422544  1493 solver.cpp:314] Iteration 25000 (1.4683 iter/s, 68.1062s/100 iter), loss = 3.22951
I0324 03:38:45.425740  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.3228 (* 1 = 2.3228 loss)
I0324 03:38:45.425762  1493 sgd_solver.cpp:136] Iteration 25000, lr = 0.01, m = 0.9
I0324 03:39:54.706387  1493 solver.cpp:314] Iteration 25100 (1.44339 iter/s, 69.2816s/100 iter), loss = 3.0647
I0324 03:39:54.706492  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.36209 (* 1 = 3.36209 loss)
I0324 03:39:54.706511  1493 sgd_solver.cpp:136] Iteration 25100, lr = 0.01, m = 0.9
I0324 03:41:02.139382  1493 solver.cpp:314] Iteration 25200 (1.483 iter/s, 67.4308s/100 iter), loss = 3.40195
I0324 03:41:02.139493  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.60671 (* 1 = 3.60671 loss)
I0324 03:41:02.139510  1493 sgd_solver.cpp:136] Iteration 25200, lr = 0.01, m = 0.9
I0324 03:42:10.086516  1493 solver.cpp:314] Iteration 25300 (1.47178 iter/s, 67.9449s/100 iter), loss = 3.16989
I0324 03:42:10.086686  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.02361 (* 1 = 3.02361 loss)
I0324 03:42:10.086736  1493 sgd_solver.cpp:136] Iteration 25300, lr = 0.01, m = 0.9
I0324 03:43:18.122854  1493 solver.cpp:314] Iteration 25400 (1.46985 iter/s, 68.0341s/100 iter), loss = 3.29807
I0324 03:43:18.125746  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.25639 (* 1 = 3.25639 loss)
I0324 03:43:18.125771  1493 sgd_solver.cpp:136] Iteration 25400, lr = 0.01, m = 0.9
I0324 03:44:27.157753  1493 solver.cpp:314] Iteration 25500 (1.44859 iter/s, 69.0327s/100 iter), loss = 3.58363
I0324 03:44:27.157860  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.31903 (* 1 = 4.31903 loss)
I0324 03:44:27.157878  1493 sgd_solver.cpp:136] Iteration 25500, lr = 0.01, m = 0.9
I0324 03:45:35.705179  1493 solver.cpp:314] Iteration 25600 (1.45889 iter/s, 68.5452s/100 iter), loss = 3.26778
I0324 03:45:35.705329  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.43835 (* 1 = 3.43835 loss)
I0324 03:45:35.705344  1493 sgd_solver.cpp:136] Iteration 25600, lr = 0.01, m = 0.9
I0324 03:46:44.479405  1493 solver.cpp:314] Iteration 25700 (1.45408 iter/s, 68.772s/100 iter), loss = 3.23389
I0324 03:46:44.479550  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.20696 (* 1 = 3.20696 loss)
I0324 03:46:44.479570  1493 sgd_solver.cpp:136] Iteration 25700, lr = 0.01, m = 0.9
I0324 03:47:52.256301  1493 solver.cpp:314] Iteration 25800 (1.47548 iter/s, 67.7747s/100 iter), loss = 3.40371
I0324 03:47:52.256485  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.64878 (* 1 = 2.64878 loss)
I0324 03:47:52.256526  1493 sgd_solver.cpp:136] Iteration 25800, lr = 0.01, m = 0.9
I0324 03:49:01.000243  1493 solver.cpp:314] Iteration 25900 (1.45472 iter/s, 68.7417s/100 iter), loss = 3.10372
I0324 03:49:01.000417  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.03274 (* 1 = 3.03274 loss)
I0324 03:49:01.000463  1493 sgd_solver.cpp:136] Iteration 25900, lr = 0.01, m = 0.9
I0324 03:50:08.561566  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_26000.caffemodel
I0324 03:50:08.594918  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_26000.solverstate
I0324 03:50:08.610136  1493 solver.cpp:678] Iteration 26000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.195129
j:  : 4 : max_pr:  : 0.344646
j:  : 3 : max_pr:  : 0.546061
j:  : 2 : max_pr:  : 0.714088
j:  : 1 : max_pr:  : 0.789842
j:  : 0 : max_pr:  : 1
I0324 03:51:00.880100  1494 solver.cpp:786] class AP 1: 0.326342
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.028003
j:  : 7 : max_pr:  : 0.183
j:  : 6 : max_pr:  : 0.344615
j:  : 5 : max_pr:  : 0.398015
j:  : 4 : max_pr:  : 0.465361
j:  : 3 : max_pr:  : 0.640319
j:  : 2 : max_pr:  : 0.755408
j:  : 1 : max_pr:  : 0.977169
j:  : 0 : max_pr:  : 1
I0324 03:51:00.936053  1494 solver.cpp:786] class AP 2: 0.435626
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.416581
j:  : 6 : max_pr:  : 0.601078
j:  : 5 : max_pr:  : 0.712417
j:  : 4 : max_pr:  : 0.813893
j:  : 3 : max_pr:  : 0.879756
j:  : 2 : max_pr:  : 0.957761
j:  : 1 : max_pr:  : 0.995053
j:  : 0 : max_pr:  : 1
I0324 03:51:00.946501  1494 solver.cpp:786] class AP 3: 0.579685
I0324 03:51:00.946518  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.447218
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.200286
j:  : 4 : max_pr:  : 0.344353
j:  : 3 : max_pr:  : 0.56205
j:  : 2 : max_pr:  : 0.722343
j:  : 1 : max_pr:  : 0.815193
j:  : 0 : max_pr:  : 1
I0324 03:51:01.642367  1493 solver.cpp:786] class AP 1: 0.331293
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0372254
j:  : 7 : max_pr:  : 0.185023
j:  : 6 : max_pr:  : 0.366754
j:  : 5 : max_pr:  : 0.414358
j:  : 4 : max_pr:  : 0.473331
j:  : 3 : max_pr:  : 0.652565
j:  : 2 : max_pr:  : 0.78256
j:  : 1 : max_pr:  : 0.985141
j:  : 0 : max_pr:  : 1
I0324 03:51:01.696255  1493 solver.cpp:786] class AP 2: 0.445178
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.403364
j:  : 6 : max_pr:  : 0.592513
j:  : 5 : max_pr:  : 0.715767
j:  : 4 : max_pr:  : 0.825261
j:  : 3 : max_pr:  : 0.882754
j:  : 2 : max_pr:  : 0.958683
j:  : 1 : max_pr:  : 0.995807
j:  : 0 : max_pr:  : 1
I0324 03:51:01.706776  1493 solver.cpp:786] class AP 3: 0.579468
I0324 03:51:01.706789  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.45198
I0324 03:51:01.707031  1493 solver.cpp:265] [MultiGPU] Tests completed in 53.0952s
I0324 03:51:02.108139  1493 solver.cpp:314] Iteration 26000 (0.825737 iter/s, 121.104s/100 iter), loss = 3.12124
I0324 03:51:02.108245  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.31223 (* 1 = 3.31223 loss)
I0324 03:51:02.108286  1493 sgd_solver.cpp:136] Iteration 26000, lr = 0.01, m = 0.9
I0324 03:52:08.941757  1493 solver.cpp:314] Iteration 26100 (1.4963 iter/s, 66.8315s/100 iter), loss = 3.12777
I0324 03:52:08.941938  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.53384 (* 1 = 3.53384 loss)
I0324 03:52:08.941987  1493 sgd_solver.cpp:136] Iteration 26100, lr = 0.01, m = 0.9
I0324 03:53:16.797056  1493 solver.cpp:314] Iteration 26200 (1.47377 iter/s, 67.8531s/100 iter), loss = 3.45139
I0324 03:53:16.797222  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.09279 (* 1 = 4.09279 loss)
I0324 03:53:16.797266  1493 sgd_solver.cpp:136] Iteration 26200, lr = 0.01, m = 0.9
I0324 03:54:24.368139  1493 solver.cpp:314] Iteration 26300 (1.47997 iter/s, 67.5689s/100 iter), loss = 3.45854
I0324 03:54:24.368360  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.14581 (* 1 = 3.14581 loss)
I0324 03:54:24.368407  1493 sgd_solver.cpp:136] Iteration 26300, lr = 0.01, m = 0.9
I0324 03:55:33.651650  1493 solver.cpp:314] Iteration 26400 (1.44339 iter/s, 69.2813s/100 iter), loss = 3.16581
I0324 03:55:33.653755  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.7025 (* 1 = 2.7025 loss)
I0324 03:55:33.653781  1493 sgd_solver.cpp:136] Iteration 26400, lr = 0.01, m = 0.9
I0324 03:56:41.227520  1493 solver.cpp:314] Iteration 26500 (1.47987 iter/s, 67.5737s/100 iter), loss = 3.17522
I0324 03:56:41.227645  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.33598 (* 1 = 2.33598 loss)
I0324 03:56:41.227663  1493 sgd_solver.cpp:136] Iteration 26500, lr = 0.01, m = 0.9
I0324 03:57:49.742219  1493 solver.cpp:314] Iteration 26600 (1.45959 iter/s, 68.5125s/100 iter), loss = 3.31247
I0324 03:57:49.742377  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.59812 (* 1 = 2.59812 loss)
I0324 03:57:49.742395  1493 sgd_solver.cpp:136] Iteration 26600, lr = 0.01, m = 0.9
I0324 03:58:58.518157  1493 solver.cpp:314] Iteration 26700 (1.45405 iter/s, 68.7736s/100 iter), loss = 3.3972
I0324 03:58:58.518317  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.85944 (* 1 = 2.85944 loss)
I0324 03:58:58.518352  1493 sgd_solver.cpp:136] Iteration 26700, lr = 0.01, m = 0.9
I0324 03:59:37.058415  1462 data_reader.cpp:305] Starting prefetch of epoch 6
I0324 04:00:07.633262  1493 solver.cpp:314] Iteration 26800 (1.44691 iter/s, 69.1128s/100 iter), loss = 3.66739
I0324 04:00:07.633396  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.44553 (* 1 = 3.44553 loss)
I0324 04:00:07.633417  1493 sgd_solver.cpp:136] Iteration 26800, lr = 0.01, m = 0.9
I0324 04:01:15.221968  1493 solver.cpp:314] Iteration 26900 (1.47959 iter/s, 67.5864s/100 iter), loss = 3.21614
I0324 04:01:15.222062  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.16124 (* 1 = 3.16124 loss)
I0324 04:01:15.222079  1493 sgd_solver.cpp:136] Iteration 26900, lr = 0.01, m = 0.9
I0324 04:02:24.141134  1493 solver.cpp:314] Iteration 27000 (1.45102 iter/s, 68.9169s/100 iter), loss = 3.08931
I0324 04:02:24.141732  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.59049 (* 1 = 3.59049 loss)
I0324 04:02:24.141750  1493 sgd_solver.cpp:136] Iteration 27000, lr = 0.01, m = 0.9
I0324 04:03:31.896029  1493 solver.cpp:314] Iteration 27100 (1.47596 iter/s, 67.7527s/100 iter), loss = 3.20901
I0324 04:03:31.896142  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.88092 (* 1 = 2.88092 loss)
I0324 04:03:31.896158  1493 sgd_solver.cpp:136] Iteration 27100, lr = 0.01, m = 0.9
I0324 04:04:40.558153  1493 solver.cpp:314] Iteration 27200 (1.45645 iter/s, 68.6599s/100 iter), loss = 3.43271
I0324 04:04:40.558331  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.76375 (* 1 = 2.76375 loss)
I0324 04:04:40.558346  1493 sgd_solver.cpp:136] Iteration 27200, lr = 0.01, m = 0.9
I0324 04:05:49.320977  1493 solver.cpp:314] Iteration 27300 (1.45432 iter/s, 68.7606s/100 iter), loss = 3.48419
I0324 04:05:49.321079  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.79428 (* 1 = 3.79428 loss)
I0324 04:05:49.321095  1493 sgd_solver.cpp:136] Iteration 27300, lr = 0.01, m = 0.9
I0324 04:06:58.176414  1493 solver.cpp:314] Iteration 27400 (1.45237 iter/s, 68.8532s/100 iter), loss = 3.32597
I0324 04:06:58.176522  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.08838 (* 1 = 3.08838 loss)
I0324 04:06:58.176537  1493 sgd_solver.cpp:136] Iteration 27400, lr = 0.01, m = 0.9
I0324 04:08:06.773888  1493 solver.cpp:314] Iteration 27500 (1.45783 iter/s, 68.5952s/100 iter), loss = 3.26818
I0324 04:08:06.773977  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.95038 (* 1 = 2.95038 loss)
I0324 04:08:06.773988  1493 sgd_solver.cpp:136] Iteration 27500, lr = 0.01, m = 0.9
I0324 04:09:14.350052  1493 solver.cpp:314] Iteration 27600 (1.47986 iter/s, 67.5739s/100 iter), loss = 3.27808
I0324 04:09:14.350160  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.09459 (* 1 = 2.09459 loss)
I0324 04:09:14.350175  1493 sgd_solver.cpp:136] Iteration 27600, lr = 0.01, m = 0.9
I0324 04:10:22.621615  1493 solver.cpp:314] Iteration 27700 (1.46479 iter/s, 68.2693s/100 iter), loss = 3.43963
I0324 04:10:22.621752  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.69716 (* 1 = 3.69716 loss)
I0324 04:10:22.621770  1493 sgd_solver.cpp:136] Iteration 27700, lr = 0.01, m = 0.9
I0324 04:11:30.583108  1493 solver.cpp:314] Iteration 27800 (1.47147 iter/s, 67.9593s/100 iter), loss = 3.3316
I0324 04:11:30.583215  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.86687 (* 1 = 2.86687 loss)
I0324 04:11:30.583231  1493 sgd_solver.cpp:136] Iteration 27800, lr = 0.01, m = 0.9
I0324 04:12:40.168104  1493 solver.cpp:314] Iteration 27900 (1.43714 iter/s, 69.5827s/100 iter), loss = 3.59672
I0324 04:12:40.168233  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.88894 (* 1 = 2.88894 loss)
I0324 04:12:40.168249  1493 sgd_solver.cpp:136] Iteration 27900, lr = 0.01, m = 0.9
I0324 04:13:48.120735  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_28000.caffemodel
I0324 04:13:48.171733  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_28000.solverstate
I0324 04:13:48.186265  1493 solver.cpp:678] Iteration 28000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.200932
j:  : 4 : max_pr:  : 0.385672
j:  : 3 : max_pr:  : 0.568767
j:  : 2 : max_pr:  : 0.731087
j:  : 1 : max_pr:  : 0.863268
j:  : 0 : max_pr:  : 1
I0324 04:14:36.552481  1493 solver.cpp:786] class AP 1: 0.340884
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.104182
j:  : 6 : max_pr:  : 0.247249
j:  : 5 : max_pr:  : 0.429773
j:  : 4 : max_pr:  : 0.570416
j:  : 3 : max_pr:  : 0.61745
j:  : 2 : max_pr:  : 0.90647
j:  : 1 : max_pr:  : 0.980993
j:  : 0 : max_pr:  : 1
I0324 04:14:36.607247  1493 solver.cpp:786] class AP 2: 0.441503
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.406672
j:  : 6 : max_pr:  : 0.609873
j:  : 5 : max_pr:  : 0.726215
j:  : 4 : max_pr:  : 0.839157
j:  : 3 : max_pr:  : 0.922064
j:  : 2 : max_pr:  : 0.966925
j:  : 1 : max_pr:  : 0.995927
j:  : 0 : max_pr:  : 1
I0324 04:14:36.618633  1493 solver.cpp:786] class AP 3: 0.587894
I0324 04:14:36.618651  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.45676
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.187523
j:  : 4 : max_pr:  : 0.372847
j:  : 3 : max_pr:  : 0.558694
j:  : 2 : max_pr:  : 0.729192
j:  : 1 : max_pr:  : 0.859716
j:  : 0 : max_pr:  : 1
I0324 04:14:37.537777  1494 solver.cpp:786] class AP 1: 0.337088
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.119537
j:  : 6 : max_pr:  : 0.257845
j:  : 5 : max_pr:  : 0.429155
j:  : 4 : max_pr:  : 0.577468
j:  : 3 : max_pr:  : 0.616572
j:  : 2 : max_pr:  : 0.922859
j:  : 1 : max_pr:  : 0.992548
j:  : 0 : max_pr:  : 1
I0324 04:14:37.591341  1494 solver.cpp:786] class AP 2: 0.446908
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.408222
j:  : 6 : max_pr:  : 0.6
j:  : 5 : max_pr:  : 0.708138
j:  : 4 : max_pr:  : 0.826481
j:  : 3 : max_pr:  : 0.923587
j:  : 2 : max_pr:  : 0.971546
j:  : 1 : max_pr:  : 0.997247
j:  : 0 : max_pr:  : 1
I0324 04:14:37.602242  1494 solver.cpp:786] class AP 3: 0.58502
I0324 04:14:37.602260  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.456339
I0324 04:14:37.602757  1493 solver.cpp:265] [MultiGPU] Tests completed in 49.4149s
I0324 04:14:38.228183  1493 solver.cpp:314] Iteration 28000 (0.847054 iter/s, 118.056s/100 iter), loss = 3.45101
I0324 04:14:38.228232  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.78249 (* 1 = 3.78249 loss)
I0324 04:14:38.228248  1493 sgd_solver.cpp:136] Iteration 28000, lr = 0.01, m = 0.9
I0324 04:15:47.401950  1493 solver.cpp:314] Iteration 28100 (1.44568 iter/s, 69.1715s/100 iter), loss = 3.19378
I0324 04:15:47.402060  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.68084 (* 1 = 3.68084 loss)
I0324 04:15:47.402078  1493 sgd_solver.cpp:136] Iteration 28100, lr = 0.01, m = 0.9
I0324 04:16:55.672598  1493 solver.cpp:314] Iteration 28200 (1.46481 iter/s, 68.2684s/100 iter), loss = 3.45862
I0324 04:16:55.672705  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.88581 (* 1 = 3.88581 loss)
I0324 04:16:55.672722  1493 sgd_solver.cpp:136] Iteration 28200, lr = 0.01, m = 0.9
I0324 04:18:03.710263  1493 solver.cpp:314] Iteration 28300 (1.46982 iter/s, 68.0354s/100 iter), loss = 3.50482
I0324 04:18:03.710446  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.3886 (* 1 = 2.3886 loss)
I0324 04:18:03.710494  1493 sgd_solver.cpp:136] Iteration 28300, lr = 0.01, m = 0.9
I0324 04:19:11.808413  1493 solver.cpp:314] Iteration 28400 (1.46852 iter/s, 68.0959s/100 iter), loss = 3.43326
I0324 04:19:11.808526  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.58028 (* 1 = 2.58028 loss)
I0324 04:19:11.808543  1493 sgd_solver.cpp:136] Iteration 28400, lr = 0.01, m = 0.9
I0324 04:20:19.741763  1493 solver.cpp:314] Iteration 28500 (1.47208 iter/s, 67.9311s/100 iter), loss = 3.3659
I0324 04:20:19.741876  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.14903 (* 1 = 3.14903 loss)
I0324 04:20:19.741894  1493 sgd_solver.cpp:136] Iteration 28500, lr = 0.01, m = 0.9
I0324 04:21:27.349468  1493 solver.cpp:314] Iteration 28600 (1.47917 iter/s, 67.6055s/100 iter), loss = 3.19423
I0324 04:21:27.349570  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.22662 (* 1 = 3.22662 loss)
I0324 04:21:27.349586  1493 sgd_solver.cpp:136] Iteration 28600, lr = 0.01, m = 0.9
I0324 04:22:35.550379  1493 solver.cpp:314] Iteration 28700 (1.4663 iter/s, 68.1987s/100 iter), loss = 3.53234
I0324 04:22:35.557752  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.95898 (* 1 = 2.95898 loss)
I0324 04:22:35.557782  1493 sgd_solver.cpp:136] Iteration 28700, lr = 0.01, m = 0.9
I0324 04:23:44.102680  1493 solver.cpp:314] Iteration 28800 (1.45879 iter/s, 68.5501s/100 iter), loss = 3.33448
I0324 04:23:44.105546  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.90432 (* 1 = 2.90432 loss)
I0324 04:23:44.105571  1493 sgd_solver.cpp:136] Iteration 28800, lr = 0.01, m = 0.9
I0324 04:24:53.147745  1493 solver.cpp:314] Iteration 28900 (1.44838 iter/s, 69.0428s/100 iter), loss = 3.5653
I0324 04:24:53.147938  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.82266 (* 1 = 4.82266 loss)
I0324 04:24:53.147981  1493 sgd_solver.cpp:136] Iteration 28900, lr = 0.01, m = 0.9
I0324 04:26:01.118953  1493 solver.cpp:314] Iteration 29000 (1.47126 iter/s, 67.969s/100 iter), loss = 3.34675
I0324 04:26:01.121815  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.46074 (* 1 = 2.46074 loss)
I0324 04:26:01.121863  1493 sgd_solver.cpp:136] Iteration 29000, lr = 0.01, m = 0.9
I0324 04:27:10.343139  1493 solver.cpp:314] Iteration 29100 (1.44463 iter/s, 69.2219s/100 iter), loss = 3.56498
I0324 04:27:10.343267  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.34765 (* 1 = 4.34765 loss)
I0324 04:27:10.343287  1493 sgd_solver.cpp:136] Iteration 29100, lr = 0.01, m = 0.9
I0324 04:28:18.312539  1493 solver.cpp:314] Iteration 29200 (1.4713 iter/s, 67.9672s/100 iter), loss = 2.9908
I0324 04:28:18.312642  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.55168 (* 1 = 2.55168 loss)
I0324 04:28:18.312659  1493 sgd_solver.cpp:136] Iteration 29200, lr = 0.01, m = 0.9
I0324 04:29:25.882611  1493 solver.cpp:314] Iteration 29300 (1.47999 iter/s, 67.5679s/100 iter), loss = 3.24084
I0324 04:29:25.882717  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.70365 (* 1 = 2.70365 loss)
I0324 04:29:25.882732  1493 sgd_solver.cpp:136] Iteration 29300, lr = 0.01, m = 0.9
I0324 04:30:34.765738  1493 solver.cpp:314] Iteration 29400 (1.45178 iter/s, 68.8809s/100 iter), loss = 3.20227
I0324 04:30:34.769731  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.05094 (* 1 = 3.05094 loss)
I0324 04:30:34.769752  1493 sgd_solver.cpp:136] Iteration 29400, lr = 0.01, m = 0.9
I0324 04:31:44.038076  1493 solver.cpp:314] Iteration 29500 (1.44362 iter/s, 69.2701s/100 iter), loss = 3.5688
I0324 04:31:44.038198  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.68706 (* 1 = 2.68706 loss)
I0324 04:31:44.038434  1493 sgd_solver.cpp:136] Iteration 29500, lr = 0.01, m = 0.9
I0324 04:32:53.519412  1493 solver.cpp:314] Iteration 29600 (1.43928 iter/s, 69.4791s/100 iter), loss = 3.30433
I0324 04:32:53.519568  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.00735 (* 1 = 3.00735 loss)
I0324 04:32:53.519620  1493 sgd_solver.cpp:136] Iteration 29600, lr = 0.01, m = 0.9
I0324 04:34:03.394122  1493 solver.cpp:314] Iteration 29700 (1.43118 iter/s, 69.8724s/100 iter), loss = 3.42956
I0324 04:34:03.397778  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.81404 (* 1 = 3.81404 loss)
I0324 04:34:03.397812  1493 sgd_solver.cpp:136] Iteration 29700, lr = 0.01, m = 0.9
I0324 04:35:11.597964  1493 solver.cpp:314] Iteration 29800 (1.46624 iter/s, 68.2016s/100 iter), loss = 3.29442
I0324 04:35:11.598085  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.75627 (* 1 = 2.75627 loss)
I0324 04:35:11.598104  1493 sgd_solver.cpp:136] Iteration 29800, lr = 0.01, m = 0.9
I0324 04:36:08.816516  1462 data_reader.cpp:305] Starting prefetch of epoch 7
I0324 04:36:20.441967  1493 solver.cpp:314] Iteration 29900 (1.45261 iter/s, 68.8418s/100 iter), loss = 3.2418
I0324 04:36:20.442023  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.38336 (* 1 = 3.38336 loss)
I0324 04:36:20.442037  1493 sgd_solver.cpp:136] Iteration 29900, lr = 0.01, m = 0.9
I0324 04:37:27.998044  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_30000.caffemodel
I0324 04:37:28.032227  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_30000.solverstate
I0324 04:37:28.047492  1493 solver.cpp:678] Iteration 30000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0
j:  : 4 : max_pr:  : 0.293892
j:  : 3 : max_pr:  : 0.470443
j:  : 2 : max_pr:  : 0.615903
j:  : 1 : max_pr:  : 0.781619
j:  : 0 : max_pr:  : 1
I0324 04:38:17.476258  1493 solver.cpp:786] class AP 1: 0.287442
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.0979697
j:  : 6 : max_pr:  : 0.280676
j:  : 5 : max_pr:  : 0.412056
j:  : 4 : max_pr:  : 0.687262
j:  : 3 : max_pr:  : 0.837158
j:  : 2 : max_pr:  : 0.968702
j:  : 1 : max_pr:  : 0.994326
j:  : 0 : max_pr:  : 1
I0324 04:38:17.538826  1493 solver.cpp:786] class AP 2: 0.479832
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.366832
j:  : 6 : max_pr:  : 0.588178
j:  : 5 : max_pr:  : 0.734163
j:  : 4 : max_pr:  : 0.841503
j:  : 3 : max_pr:  : 0.903274
j:  : 2 : max_pr:  : 0.94721
j:  : 1 : max_pr:  : 0.98817
j:  : 0 : max_pr:  : 1
I0324 04:38:17.546349  1493 solver.cpp:786] class AP 3: 0.57903
I0324 04:38:17.546373  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.448768
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0
j:  : 4 : max_pr:  : 0.296201
j:  : 3 : max_pr:  : 0.471911
j:  : 2 : max_pr:  : 0.631434
j:  : 1 : max_pr:  : 0.777027
j:  : 0 : max_pr:  : 1
I0324 04:38:18.430460  1494 solver.cpp:786] class AP 1: 0.288779
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0345139
j:  : 7 : max_pr:  : 0.116971
j:  : 6 : max_pr:  : 0.339681
j:  : 5 : max_pr:  : 0.45256
j:  : 4 : max_pr:  : 0.702703
j:  : 3 : max_pr:  : 0.849701
j:  : 2 : max_pr:  : 0.975789
j:  : 1 : max_pr:  : 0.997264
j:  : 0 : max_pr:  : 1
I0324 04:38:18.480906  1494 solver.cpp:786] class AP 2: 0.497198
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.354619
j:  : 6 : max_pr:  : 0.591005
j:  : 5 : max_pr:  : 0.731292
j:  : 4 : max_pr:  : 0.834824
j:  : 3 : max_pr:  : 0.898247
j:  : 2 : max_pr:  : 0.953029
j:  : 1 : max_pr:  : 0.988981
j:  : 0 : max_pr:  : 1
I0324 04:38:18.487922  1494 solver.cpp:786] class AP 3: 0.577454
I0324 04:38:18.487934  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.454477
I0324 04:38:18.488270  1493 solver.cpp:265] [MultiGPU] Tests completed in 50.4391s
I0324 04:38:18.843747  1514 sgd_solver.cpp:48] MultiStep Status: Iteration 30000, step = 1
I0324 04:38:18.843780  1513 sgd_solver.cpp:48] MultiStep Status: Iteration 30000, step = 1
I0324 04:38:18.892415  1493 solver.cpp:314] Iteration 30000 (0.844262 iter/s, 118.447s/100 iter), loss = 3.05387
I0324 04:38:18.892460  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.8282 (* 1 = 3.8282 loss)
I0324 04:38:18.892473  1493 sgd_solver.cpp:136] Iteration 30000, lr = 0.001, m = 0.9
I0324 04:39:27.134181  1493 solver.cpp:314] Iteration 30100 (1.46543 iter/s, 68.2395s/100 iter), loss = 3.32898
I0324 04:39:27.134275  1493 solver.cpp:336]     Train net output #0: mbox_loss = 1.9905 (* 1 = 1.9905 loss)
I0324 04:39:27.134291  1493 sgd_solver.cpp:136] Iteration 30100, lr = 0.001, m = 0.9
I0324 04:40:36.470481  1493 solver.cpp:314] Iteration 30200 (1.44229 iter/s, 69.334s/100 iter), loss = 3.36419
I0324 04:40:36.470580  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.95438 (* 1 = 2.95438 loss)
I0324 04:40:36.470595  1493 sgd_solver.cpp:136] Iteration 30200, lr = 0.001, m = 0.9
I0324 04:41:44.985738  1493 solver.cpp:314] Iteration 30300 (1.45958 iter/s, 68.513s/100 iter), loss = 3.33215
I0324 04:41:44.985838  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.9634 (* 1 = 2.9634 loss)
I0324 04:41:44.985854  1493 sgd_solver.cpp:136] Iteration 30300, lr = 0.001, m = 0.9
I0324 04:42:53.090034  1493 solver.cpp:314] Iteration 30400 (1.46838 iter/s, 68.1021s/100 iter), loss = 3.08935
I0324 04:42:53.090137  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.76763 (* 1 = 3.76763 loss)
I0324 04:42:53.090154  1493 sgd_solver.cpp:136] Iteration 30400, lr = 0.001, m = 0.9
I0324 04:44:01.568042  1493 solver.cpp:314] Iteration 30500 (1.46037 iter/s, 68.4758s/100 iter), loss = 3.25807
I0324 04:44:01.568159  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.86797 (* 1 = 3.86797 loss)
I0324 04:44:01.568176  1493 sgd_solver.cpp:136] Iteration 30500, lr = 0.001, m = 0.9
I0324 04:45:10.125234  1493 solver.cpp:314] Iteration 30600 (1.45868 iter/s, 68.5549s/100 iter), loss = 3.12427
I0324 04:45:10.125334  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.75404 (* 1 = 3.75404 loss)
I0324 04:45:10.125350  1493 sgd_solver.cpp:136] Iteration 30600, lr = 0.001, m = 0.9
I0324 04:46:18.044426  1493 solver.cpp:314] Iteration 30700 (1.47239 iter/s, 67.917s/100 iter), loss = 3.25787
I0324 04:46:18.044523  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.62772 (* 1 = 2.62772 loss)
I0324 04:46:18.044538  1493 sgd_solver.cpp:136] Iteration 30700, lr = 0.001, m = 0.9
I0324 04:47:26.229001  1493 solver.cpp:314] Iteration 30800 (1.46666 iter/s, 68.1823s/100 iter), loss = 3.23526
I0324 04:47:26.229125  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.46939 (* 1 = 2.46939 loss)
I0324 04:47:26.229142  1493 sgd_solver.cpp:136] Iteration 30800, lr = 0.001, m = 0.9
I0324 04:48:35.028506  1493 solver.cpp:314] Iteration 30900 (1.45355 iter/s, 68.7973s/100 iter), loss = 3.20354
I0324 04:48:35.028606  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.89058 (* 1 = 2.89058 loss)
I0324 04:48:35.028622  1493 sgd_solver.cpp:136] Iteration 30900, lr = 0.001, m = 0.9
I0324 04:49:43.541235  1493 solver.cpp:314] Iteration 31000 (1.45963 iter/s, 68.5105s/100 iter), loss = 3.07137
I0324 04:49:43.541369  1493 solver.cpp:336]     Train net output #0: mbox_loss = 1.99802 (* 1 = 1.99802 loss)
I0324 04:49:43.541385  1493 sgd_solver.cpp:136] Iteration 31000, lr = 0.001, m = 0.9
I0324 04:50:52.033763  1493 solver.cpp:314] Iteration 31100 (1.46006 iter/s, 68.4903s/100 iter), loss = 3.34557
I0324 04:50:52.033941  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.14735 (* 1 = 4.14735 loss)
I0324 04:50:52.033991  1493 sgd_solver.cpp:136] Iteration 31100, lr = 0.001, m = 0.9
I0324 04:52:00.871625  1493 solver.cpp:314] Iteration 31200 (1.45274 iter/s, 68.8356s/100 iter), loss = 3.10128
I0324 04:52:00.871724  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.54138 (* 1 = 3.54138 loss)
I0324 04:52:00.871737  1493 sgd_solver.cpp:136] Iteration 31200, lr = 0.001, m = 0.9
I0324 04:53:09.100801  1493 solver.cpp:314] Iteration 31300 (1.4657 iter/s, 68.2269s/100 iter), loss = 3.09036
I0324 04:53:09.100915  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.92382 (* 1 = 3.92382 loss)
I0324 04:53:09.100931  1493 sgd_solver.cpp:136] Iteration 31300, lr = 0.001, m = 0.9
I0324 04:54:17.601903  1493 solver.cpp:314] Iteration 31400 (1.45988 iter/s, 68.4988s/100 iter), loss = 3.23065
I0324 04:54:17.602071  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.04487 (* 1 = 3.04487 loss)
I0324 04:54:17.602085  1493 sgd_solver.cpp:136] Iteration 31400, lr = 0.001, m = 0.9
I0324 04:55:26.195432  1493 solver.cpp:314] Iteration 31500 (1.45791 iter/s, 68.5913s/100 iter), loss = 3.08858
I0324 04:55:26.195540  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.04291 (* 1 = 3.04291 loss)
I0324 04:55:26.195557  1493 sgd_solver.cpp:136] Iteration 31500, lr = 0.001, m = 0.9
I0324 04:56:34.266700  1493 solver.cpp:314] Iteration 31600 (1.4691 iter/s, 68.0691s/100 iter), loss = 3.12815
I0324 04:56:34.266813  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.21098 (* 1 = 4.21098 loss)
I0324 04:56:34.266829  1493 sgd_solver.cpp:136] Iteration 31600, lr = 0.001, m = 0.9
I0324 04:57:43.163002  1493 solver.cpp:314] Iteration 31700 (1.4515 iter/s, 68.8941s/100 iter), loss = 3.09732
I0324 04:57:43.164546  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.057 (* 1 = 4.057 loss)
I0324 04:57:43.164913  1493 sgd_solver.cpp:136] Iteration 31700, lr = 0.001, m = 0.9
I0324 04:58:51.781131  1493 solver.cpp:314] Iteration 31800 (1.45739 iter/s, 68.6159s/100 iter), loss = 3.11282
I0324 04:58:51.781225  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.8298 (* 1 = 2.8298 loss)
I0324 04:58:51.781240  1493 sgd_solver.cpp:136] Iteration 31800, lr = 0.001, m = 0.9
I0324 04:59:59.910989  1493 solver.cpp:314] Iteration 31900 (1.46783 iter/s, 68.1276s/100 iter), loss = 3.15105
I0324 04:59:59.911121  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.70382 (* 1 = 2.70382 loss)
I0324 04:59:59.911145  1493 sgd_solver.cpp:136] Iteration 31900, lr = 0.001, m = 0.9
I0324 05:01:07.585994  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_32000.caffemodel
I0324 05:01:07.610126  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_32000.solverstate
I0324 05:01:07.620652  1493 solver.cpp:678] Iteration 32000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.287099
j:  : 4 : max_pr:  : 0.459724
j:  : 3 : max_pr:  : 0.604633
j:  : 2 : max_pr:  : 0.737864
j:  : 1 : max_pr:  : 0.84517
j:  : 0 : max_pr:  : 1
I0324 05:01:57.238963  1493 solver.cpp:786] class AP 1: 0.357681
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.22495
j:  : 7 : max_pr:  : 0.477737
j:  : 6 : max_pr:  : 0.557394
j:  : 5 : max_pr:  : 0.646831
j:  : 4 : max_pr:  : 0.695628
j:  : 3 : max_pr:  : 0.793664
j:  : 2 : max_pr:  : 0.985283
j:  : 1 : max_pr:  : 0.997972
j:  : 0 : max_pr:  : 1
I0324 05:01:57.290829  1493 solver.cpp:786] class AP 2: 0.579951
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.488847
j:  : 6 : max_pr:  : 0.640763
j:  : 5 : max_pr:  : 0.760195
j:  : 4 : max_pr:  : 0.859917
j:  : 3 : max_pr:  : 0.916938
j:  : 2 : max_pr:  : 0.962697
j:  : 1 : max_pr:  : 0.998602
j:  : 0 : max_pr:  : 1
I0324 05:01:57.299624  1493 solver.cpp:786] class AP 3: 0.602542
I0324 05:01:57.299649  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.513391
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.293051
j:  : 4 : max_pr:  : 0.476419
j:  : 3 : max_pr:  : 0.610785
j:  : 2 : max_pr:  : 0.731596
j:  : 1 : max_pr:  : 0.852467
j:  : 0 : max_pr:  : 1
I0324 05:01:57.496753  1494 solver.cpp:786] class AP 1: 0.360392
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.20925
j:  : 7 : max_pr:  : 0.462271
j:  : 6 : max_pr:  : 0.537677
j:  : 5 : max_pr:  : 0.630189
j:  : 4 : max_pr:  : 0.682902
j:  : 3 : max_pr:  : 0.787022
j:  : 2 : max_pr:  : 0.988772
j:  : 1 : max_pr:  : 0.994162
j:  : 0 : max_pr:  : 1
I0324 05:01:57.547935  1494 solver.cpp:786] class AP 2: 0.572022
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.502446
j:  : 6 : max_pr:  : 0.653903
j:  : 5 : max_pr:  : 0.770257
j:  : 4 : max_pr:  : 0.862676
j:  : 3 : max_pr:  : 0.917173
j:  : 2 : max_pr:  : 0.970062
j:  : 1 : max_pr:  : 0.99798
j:  : 0 : max_pr:  : 1
I0324 05:01:57.556828  1494 solver.cpp:786] class AP 3: 0.606772
I0324 05:01:57.556855  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.513062
I0324 05:01:57.557181  1493 solver.cpp:265] [MultiGPU] Tests completed in 49.9349s
I0324 05:01:57.990131  1493 solver.cpp:314] Iteration 32000 (0.846917 iter/s, 118.075s/100 iter), loss = 3.38297
I0324 05:01:57.990178  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.54239 (* 1 = 3.54239 loss)
I0324 05:01:57.990195  1493 sgd_solver.cpp:136] Iteration 32000, lr = 0.001, m = 0.9
I0324 05:03:06.210880  1493 solver.cpp:314] Iteration 32100 (1.46588 iter/s, 68.2185s/100 iter), loss = 3.29019
I0324 05:03:06.211024  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.65425 (* 1 = 3.65425 loss)
I0324 05:03:06.211042  1493 sgd_solver.cpp:136] Iteration 32100, lr = 0.001, m = 0.9
I0324 05:04:15.189118  1493 solver.cpp:314] Iteration 32200 (1.44978 iter/s, 68.976s/100 iter), loss = 3.01319
I0324 05:04:15.189227  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.2521 (* 1 = 3.2521 loss)
I0324 05:04:15.189244  1493 sgd_solver.cpp:136] Iteration 32200, lr = 0.001, m = 0.9
I0324 05:05:24.245437  1493 solver.cpp:314] Iteration 32300 (1.44814 iter/s, 69.0541s/100 iter), loss = 3.10525
I0324 05:05:24.245542  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.35539 (* 1 = 2.35539 loss)
I0324 05:05:24.245592  1493 sgd_solver.cpp:136] Iteration 32300, lr = 0.001, m = 0.9
I0324 05:06:33.073758  1493 solver.cpp:314] Iteration 32400 (1.45294 iter/s, 68.8261s/100 iter), loss = 3.03749
I0324 05:06:33.073854  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.42143 (* 1 = 4.42143 loss)
I0324 05:06:33.073873  1493 sgd_solver.cpp:136] Iteration 32400, lr = 0.001, m = 0.9
I0324 05:07:42.340334  1493 solver.cpp:314] Iteration 32500 (1.44374 iter/s, 69.2643s/100 iter), loss = 3.42609
I0324 05:07:42.340451  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.13776 (* 1 = 3.13776 loss)
I0324 05:07:42.340467  1493 sgd_solver.cpp:136] Iteration 32500, lr = 0.001, m = 0.9
I0324 05:08:50.743110  1493 solver.cpp:314] Iteration 32600 (1.46198 iter/s, 68.4006s/100 iter), loss = 3.29134
I0324 05:08:50.743204  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.52749 (* 1 = 3.52749 loss)
I0324 05:08:50.743219  1493 sgd_solver.cpp:136] Iteration 32600, lr = 0.001, m = 0.9
I0324 05:09:36.537892  1462 data_reader.cpp:305] Starting prefetch of epoch 8
I0324 05:10:00.517961  1493 solver.cpp:314] Iteration 32700 (1.43323 iter/s, 69.7726s/100 iter), loss = 3.23018
I0324 05:10:00.518018  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.51003 (* 1 = 2.51003 loss)
I0324 05:10:00.518034  1493 sgd_solver.cpp:136] Iteration 32700, lr = 0.001, m = 0.9
I0324 05:11:08.614143  1493 solver.cpp:314] Iteration 32800 (1.46856 iter/s, 68.094s/100 iter), loss = 3.14439
I0324 05:11:08.614255  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.58671 (* 1 = 4.58671 loss)
I0324 05:11:08.614274  1493 sgd_solver.cpp:136] Iteration 32800, lr = 0.001, m = 0.9
I0324 05:12:17.648457  1493 solver.cpp:314] Iteration 32900 (1.44861 iter/s, 69.0317s/100 iter), loss = 3.03609
I0324 05:12:17.648741  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.74252 (* 1 = 2.74252 loss)
I0324 05:12:17.648788  1493 sgd_solver.cpp:136] Iteration 32900, lr = 0.001, m = 0.9
I0324 05:13:26.030236  1493 solver.cpp:314] Iteration 33000 (1.46242 iter/s, 68.3799s/100 iter), loss = 3.14619
I0324 05:13:26.034071  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.79386 (* 1 = 2.79386 loss)
I0324 05:13:26.034101  1493 sgd_solver.cpp:136] Iteration 33000, lr = 0.001, m = 0.9
I0324 05:14:35.221992  1493 solver.cpp:314] Iteration 33100 (1.44531 iter/s, 69.1895s/100 iter), loss = 3.22596
I0324 05:14:35.222084  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.95066 (* 1 = 2.95066 loss)
I0324 05:14:35.222100  1493 sgd_solver.cpp:136] Iteration 33100, lr = 0.001, m = 0.9
I0324 05:15:44.254739  1493 solver.cpp:314] Iteration 33200 (1.44863 iter/s, 69.0305s/100 iter), loss = 2.9646
I0324 05:15:44.254884  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.96016 (* 1 = 2.96016 loss)
I0324 05:15:44.254900  1493 sgd_solver.cpp:136] Iteration 33200, lr = 0.001, m = 0.9
I0324 05:16:52.206069  1493 solver.cpp:314] Iteration 33300 (1.47169 iter/s, 67.9491s/100 iter), loss = 3.09558
I0324 05:16:52.206184  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.45728 (* 1 = 2.45728 loss)
I0324 05:16:52.206205  1493 sgd_solver.cpp:136] Iteration 33300, lr = 0.001, m = 0.9
I0324 05:18:00.317981  1493 solver.cpp:314] Iteration 33400 (1.46822 iter/s, 68.1097s/100 iter), loss = 2.93924
I0324 05:18:00.318094  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.64619 (* 1 = 2.64619 loss)
I0324 05:18:00.318110  1493 sgd_solver.cpp:136] Iteration 33400, lr = 0.001, m = 0.9
I0324 05:19:07.897786  1493 solver.cpp:314] Iteration 33500 (1.47978 iter/s, 67.5776s/100 iter), loss = 3.0175
I0324 05:19:07.897928  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.53345 (* 1 = 2.53345 loss)
I0324 05:19:07.897950  1493 sgd_solver.cpp:136] Iteration 33500, lr = 0.001, m = 0.9
I0324 05:20:16.454084  1493 solver.cpp:314] Iteration 33600 (1.4587 iter/s, 68.5541s/100 iter), loss = 3.00862
I0324 05:20:16.454174  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.8877 (* 1 = 2.8877 loss)
I0324 05:20:16.454187  1493 sgd_solver.cpp:136] Iteration 33600, lr = 0.001, m = 0.9
I0324 05:21:25.063731  1493 solver.cpp:314] Iteration 33700 (1.45757 iter/s, 68.6074s/100 iter), loss = 3.04978
I0324 05:21:25.063834  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.37687 (* 1 = 2.37687 loss)
I0324 05:21:25.063849  1493 sgd_solver.cpp:136] Iteration 33700, lr = 0.001, m = 0.9
I0324 05:22:33.457923  1493 solver.cpp:314] Iteration 33800 (1.46216 iter/s, 68.392s/100 iter), loss = 2.91296
I0324 05:22:33.458025  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.77329 (* 1 = 3.77329 loss)
I0324 05:22:33.458042  1493 sgd_solver.cpp:136] Iteration 33800, lr = 0.001, m = 0.9
I0324 05:23:42.159627  1493 solver.cpp:314] Iteration 33900 (1.45562 iter/s, 68.6995s/100 iter), loss = 3.39291
I0324 05:23:42.159713  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.11504 (* 1 = 3.11504 loss)
I0324 05:23:42.159729  1493 sgd_solver.cpp:136] Iteration 33900, lr = 0.001, m = 0.9
I0324 05:24:49.557456  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_34000.caffemodel
I0324 05:24:49.706102  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_34000.solverstate
I0324 05:24:49.719933  1493 solver.cpp:678] Iteration 34000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.334459
j:  : 4 : max_pr:  : 0.505058
j:  : 3 : max_pr:  : 0.647602
j:  : 2 : max_pr:  : 0.769069
j:  : 1 : max_pr:  : 0.873563
j:  : 0 : max_pr:  : 1
I0324 05:25:39.281067  1494 solver.cpp:786] class AP 1: 0.375432
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.143264
j:  : 7 : max_pr:  : 0.398034
j:  : 6 : max_pr:  : 0.505086
j:  : 5 : max_pr:  : 0.586633
j:  : 4 : max_pr:  : 0.673349
j:  : 3 : max_pr:  : 0.785342
j:  : 2 : max_pr:  : 0.9858
j:  : 1 : max_pr:  : 0.994398
j:  : 0 : max_pr:  : 1
I0324 05:25:39.331179  1494 solver.cpp:786] class AP 2: 0.551991
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.506404
j:  : 6 : max_pr:  : 0.669751
j:  : 5 : max_pr:  : 0.766258
j:  : 4 : max_pr:  : 0.856649
j:  : 3 : max_pr:  : 0.928758
j:  : 2 : max_pr:  : 0.969728
j:  : 1 : max_pr:  : 0.997999
j:  : 0 : max_pr:  : 1
I0324 05:25:39.344349  1494 solver.cpp:786] class AP 3: 0.608686
I0324 05:25:39.344368  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.512036
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.335006
j:  : 4 : max_pr:  : 0.497963
j:  : 3 : max_pr:  : 0.641351
j:  : 2 : max_pr:  : 0.769182
j:  : 1 : max_pr:  : 0.866827
j:  : 0 : max_pr:  : 1
I0324 05:25:39.766078  1493 solver.cpp:786] class AP 1: 0.373666
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.150067
j:  : 7 : max_pr:  : 0.406275
j:  : 6 : max_pr:  : 0.499611
j:  : 5 : max_pr:  : 0.593929
j:  : 4 : max_pr:  : 0.689396
j:  : 3 : max_pr:  : 0.797516
j:  : 2 : max_pr:  : 0.987758
j:  : 1 : max_pr:  : 0.99799
j:  : 0 : max_pr:  : 1
I0324 05:25:39.812012  1493 solver.cpp:786] class AP 2: 0.556595
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.503358
j:  : 6 : max_pr:  : 0.668187
j:  : 5 : max_pr:  : 0.754253
j:  : 4 : max_pr:  : 0.846563
j:  : 3 : max_pr:  : 0.924045
j:  : 2 : max_pr:  : 0.972087
j:  : 1 : max_pr:  : 0.9987
j:  : 0 : max_pr:  : 1
I0324 05:25:39.824985  1493 solver.cpp:786] class AP 3: 0.606109
I0324 05:25:39.825002  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.512123
I0324 05:25:39.825176  1493 solver.cpp:265] [MultiGPU] Tests completed in 50.1036s
I0324 05:25:40.229918  1493 solver.cpp:314] Iteration 34000 (0.846981 iter/s, 118.066s/100 iter), loss = 3.1846
I0324 05:25:40.229967  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.38742 (* 1 = 3.38742 loss)
I0324 05:25:40.229984  1493 sgd_solver.cpp:136] Iteration 34000, lr = 0.001, m = 0.9
I0324 05:26:49.193742  1493 solver.cpp:314] Iteration 34100 (1.45008 iter/s, 68.9616s/100 iter), loss = 3.13106
I0324 05:26:49.193835  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.18312 (* 1 = 2.18312 loss)
I0324 05:26:49.193852  1493 sgd_solver.cpp:136] Iteration 34100, lr = 0.001, m = 0.9
I0324 05:27:56.430981  1493 solver.cpp:314] Iteration 34200 (1.48732 iter/s, 67.235s/100 iter), loss = 3.05109
I0324 05:27:56.431138  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.6334 (* 1 = 2.6334 loss)
I0324 05:27:56.431200  1493 sgd_solver.cpp:136] Iteration 34200, lr = 0.001, m = 0.9
I0324 05:29:05.209769  1493 solver.cpp:314] Iteration 34300 (1.45398 iter/s, 68.7766s/100 iter), loss = 3.00419
I0324 05:29:05.209862  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.78304 (* 1 = 3.78304 loss)
I0324 05:29:05.209880  1493 sgd_solver.cpp:136] Iteration 34300, lr = 0.001, m = 0.9
I0324 05:30:13.859606  1493 solver.cpp:314] Iteration 34400 (1.45671 iter/s, 68.6476s/100 iter), loss = 3.10409
I0324 05:30:13.859717  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.9314 (* 1 = 2.9314 loss)
I0324 05:30:13.859735  1493 sgd_solver.cpp:136] Iteration 34400, lr = 0.001, m = 0.9
I0324 05:31:22.117724  1493 solver.cpp:314] Iteration 34500 (1.46511 iter/s, 68.2545s/100 iter), loss = 3.29385
I0324 05:31:22.117895  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.47133 (* 1 = 3.47133 loss)
I0324 05:31:22.117938  1493 sgd_solver.cpp:136] Iteration 34500, lr = 0.001, m = 0.9
I0324 05:32:30.933543  1493 solver.cpp:314] Iteration 34600 (1.4532 iter/s, 68.8136s/100 iter), loss = 3.00425
I0324 05:32:30.933651  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.61391 (* 1 = 2.61391 loss)
I0324 05:32:30.933667  1493 sgd_solver.cpp:136] Iteration 34600, lr = 0.001, m = 0.9
I0324 05:33:38.689227  1493 solver.cpp:314] Iteration 34700 (1.47594 iter/s, 67.7535s/100 iter), loss = 3.16158
I0324 05:33:38.689342  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.6788 (* 1 = 3.6788 loss)
I0324 05:33:38.689360  1493 sgd_solver.cpp:136] Iteration 34700, lr = 0.001, m = 0.9
I0324 05:34:47.669968  1493 solver.cpp:314] Iteration 34800 (1.44973 iter/s, 68.9785s/100 iter), loss = 2.9654
I0324 05:34:47.670091  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.02196 (* 1 = 3.02196 loss)
I0324 05:34:47.670109  1493 sgd_solver.cpp:136] Iteration 34800, lr = 0.001, m = 0.9
I0324 05:35:55.802497  1493 solver.cpp:314] Iteration 34900 (1.46778 iter/s, 68.1303s/100 iter), loss = 3.13765
I0324 05:35:55.802690  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.20823 (* 1 = 3.20823 loss)
I0324 05:35:55.802708  1493 sgd_solver.cpp:136] Iteration 34900, lr = 0.001, m = 0.9
I0324 05:37:03.573736  1493 solver.cpp:314] Iteration 35000 (1.4756 iter/s, 67.769s/100 iter), loss = 3.07385
I0324 05:37:03.573827  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.15509 (* 1 = 2.15509 loss)
I0324 05:37:03.573842  1493 sgd_solver.cpp:136] Iteration 35000, lr = 0.001, m = 0.9
I0324 05:38:11.757516  1493 solver.cpp:314] Iteration 35100 (1.46667 iter/s, 68.1815s/100 iter), loss = 2.95175
I0324 05:38:11.757634  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.1259 (* 1 = 2.1259 loss)
I0324 05:38:11.757653  1493 sgd_solver.cpp:136] Iteration 35100, lr = 0.001, m = 0.9
I0324 05:39:19.719951  1493 solver.cpp:314] Iteration 35200 (1.47145 iter/s, 67.9602s/100 iter), loss = 3.07648
I0324 05:39:19.720069  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.83685 (* 1 = 2.83685 loss)
I0324 05:39:19.720086  1493 sgd_solver.cpp:136] Iteration 35200, lr = 0.001, m = 0.9
I0324 05:40:27.666568  1493 solver.cpp:314] Iteration 35300 (1.47179 iter/s, 67.9444s/100 iter), loss = 3.13368
I0324 05:40:27.666746  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.9148 (* 1 = 2.9148 loss)
I0324 05:40:27.666797  1493 sgd_solver.cpp:136] Iteration 35300, lr = 0.001, m = 0.9
I0324 05:41:36.700660  1493 solver.cpp:314] Iteration 35400 (1.44861 iter/s, 69.0319s/100 iter), loss = 3.38468
I0324 05:41:36.700765  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.94705 (* 1 = 2.94705 loss)
I0324 05:41:36.700781  1493 sgd_solver.cpp:136] Iteration 35400, lr = 0.001, m = 0.9
I0324 05:42:45.207931  1493 solver.cpp:314] Iteration 35500 (1.45975 iter/s, 68.5051s/100 iter), loss = 3.40995
I0324 05:42:45.208118  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.60356 (* 1 = 4.60356 loss)
I0324 05:42:45.208164  1493 sgd_solver.cpp:136] Iteration 35500, lr = 0.001, m = 0.9
I0324 05:43:54.469554  1493 solver.cpp:314] Iteration 35600 (1.44385 iter/s, 69.2594s/100 iter), loss = 3.11336
I0324 05:43:54.469667  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.59693 (* 1 = 2.59693 loss)
I0324 05:43:54.469684  1493 sgd_solver.cpp:136] Iteration 35600, lr = 0.001, m = 0.9
I0324 05:45:03.744671  1493 solver.cpp:314] Iteration 35700 (1.44357 iter/s, 69.2729s/100 iter), loss = 3.26466
I0324 05:45:03.744837  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.53225 (* 1 = 2.53225 loss)
I0324 05:45:03.744889  1493 sgd_solver.cpp:136] Iteration 35700, lr = 0.001, m = 0.9
I0324 05:46:08.600015  1462 data_reader.cpp:305] Starting prefetch of epoch 9
I0324 05:46:13.138972  1493 solver.cpp:314] Iteration 35800 (1.44109 iter/s, 69.392s/100 iter), loss = 3.32576
I0324 05:46:13.139034  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.17723 (* 1 = 3.17723 loss)
I0324 05:46:13.139050  1493 sgd_solver.cpp:136] Iteration 35800, lr = 0.001, m = 0.9
I0324 05:47:21.720034  1493 solver.cpp:314] Iteration 35900 (1.45818 iter/s, 68.5788s/100 iter), loss = 3.08525
I0324 05:47:21.720144  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.01859 (* 1 = 3.01859 loss)
I0324 05:47:21.720160  1493 sgd_solver.cpp:136] Iteration 35900, lr = 0.001, m = 0.9
I0324 05:48:29.143674  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_36000.caffemodel
I0324 05:48:29.212237  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_36000.solverstate
I0324 05:48:29.228641  1493 solver.cpp:678] Iteration 36000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.277873
j:  : 4 : max_pr:  : 0.46802
j:  : 3 : max_pr:  : 0.636278
j:  : 2 : max_pr:  : 0.761347
j:  : 1 : max_pr:  : 0.859848
j:  : 0 : max_pr:  : 1
I0324 05:49:21.849993  1494 solver.cpp:786] class AP 1: 0.363943
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0931766
j:  : 7 : max_pr:  : 0.336171
j:  : 6 : max_pr:  : 0.422412
j:  : 5 : max_pr:  : 0.56835
j:  : 4 : max_pr:  : 0.677912
j:  : 3 : max_pr:  : 0.823655
j:  : 2 : max_pr:  : 0.985441
j:  : 1 : max_pr:  : 0.993958
j:  : 0 : max_pr:  : 1
I0324 05:49:21.910722  1494 solver.cpp:786] class AP 2: 0.536461
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.512695
j:  : 6 : max_pr:  : 0.664823
j:  : 5 : max_pr:  : 0.765117
j:  : 4 : max_pr:  : 0.854076
j:  : 3 : max_pr:  : 0.906599
j:  : 2 : max_pr:  : 0.959987
j:  : 1 : max_pr:  : 0.999316
j:  : 0 : max_pr:  : 1
I0324 05:49:21.925061  1494 solver.cpp:786] class AP 3: 0.605692
I0324 05:49:21.925084  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.502032
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.297832
j:  : 4 : max_pr:  : 0.481777
j:  : 3 : max_pr:  : 0.633882
j:  : 2 : max_pr:  : 0.761185
j:  : 1 : max_pr:  : 0.854274
j:  : 0 : max_pr:  : 1
I0324 05:49:22.129170  1493 solver.cpp:786] class AP 1: 0.366268
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.120043
j:  : 7 : max_pr:  : 0.349509
j:  : 6 : max_pr:  : 0.43211
j:  : 5 : max_pr:  : 0.583617
j:  : 4 : max_pr:  : 0.705198
j:  : 3 : max_pr:  : 0.840636
j:  : 2 : max_pr:  : 0.988688
j:  : 1 : max_pr:  : 0.997487
j:  : 0 : max_pr:  : 1
I0324 05:49:22.174985  1493 solver.cpp:786] class AP 2: 0.547026
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.51719
j:  : 6 : max_pr:  : 0.659781
j:  : 5 : max_pr:  : 0.746734
j:  : 4 : max_pr:  : 0.839369
j:  : 3 : max_pr:  : 0.905987
j:  : 2 : max_pr:  : 0.964175
j:  : 1 : max_pr:  : 0.998619
j:  : 0 : max_pr:  : 1
I0324 05:49:22.185590  1493 solver.cpp:786] class AP 3: 0.602896
I0324 05:49:22.185611  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.505397
I0324 05:49:22.186076  1493 solver.cpp:265] [MultiGPU] Tests completed in 52.9557s
I0324 05:49:22.597928  1493 solver.cpp:314] Iteration 36000 (0.827308 iter/s, 120.874s/100 iter), loss = 3.01297
I0324 05:49:22.597985  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.27799 (* 1 = 3.27799 loss)
I0324 05:49:22.597998  1493 sgd_solver.cpp:136] Iteration 36000, lr = 0.001, m = 0.9
I0324 05:50:31.762331  1493 solver.cpp:314] Iteration 36100 (1.44588 iter/s, 69.1622s/100 iter), loss = 3.20378
I0324 05:50:31.762426  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.63261 (* 1 = 3.63261 loss)
I0324 05:50:31.762441  1493 sgd_solver.cpp:136] Iteration 36100, lr = 0.001, m = 0.9
I0324 05:51:39.909493  1493 solver.cpp:314] Iteration 36200 (1.46746 iter/s, 68.145s/100 iter), loss = 3.06866
I0324 05:51:39.910847  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.65989 (* 1 = 2.65989 loss)
I0324 05:51:39.910864  1493 sgd_solver.cpp:136] Iteration 36200, lr = 0.001, m = 0.9
I0324 05:52:49.057768  1493 solver.cpp:314] Iteration 36300 (1.44621 iter/s, 69.146s/100 iter), loss = 3.25532
I0324 05:52:49.057878  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.16506 (* 1 = 3.16506 loss)
I0324 05:52:49.057895  1493 sgd_solver.cpp:136] Iteration 36300, lr = 0.001, m = 0.9
I0324 05:53:56.790212  1493 solver.cpp:314] Iteration 36400 (1.47645 iter/s, 67.7302s/100 iter), loss = 2.98655
I0324 05:53:56.790431  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.06229 (* 1 = 2.06229 loss)
I0324 05:53:56.790475  1493 sgd_solver.cpp:136] Iteration 36400, lr = 0.001, m = 0.9
I0324 05:55:05.948130  1493 solver.cpp:314] Iteration 36500 (1.44601 iter/s, 69.1557s/100 iter), loss = 3.03433
I0324 05:55:05.948236  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.05719 (* 1 = 3.05719 loss)
I0324 05:55:05.948288  1493 sgd_solver.cpp:136] Iteration 36500, lr = 0.001, m = 0.9
I0324 05:56:13.762109  1493 solver.cpp:314] Iteration 36600 (1.47467 iter/s, 67.8118s/100 iter), loss = 3.03109
I0324 05:56:13.762208  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.6267 (* 1 = 2.6267 loss)
I0324 05:56:13.762223  1493 sgd_solver.cpp:136] Iteration 36600, lr = 0.001, m = 0.9
I0324 05:57:22.993758  1493 solver.cpp:314] Iteration 36700 (1.44447 iter/s, 69.2294s/100 iter), loss = 3.0632
I0324 05:57:22.993926  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.34975 (* 1 = 3.34975 loss)
I0324 05:57:22.993974  1493 sgd_solver.cpp:136] Iteration 36700, lr = 0.001, m = 0.9
I0324 05:58:30.784646  1493 solver.cpp:314] Iteration 36800 (1.47517 iter/s, 67.7887s/100 iter), loss = 3.08144
I0324 05:58:30.785848  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.99949 (* 1 = 2.99949 loss)
I0324 05:58:30.785912  1493 sgd_solver.cpp:136] Iteration 36800, lr = 0.001, m = 0.9
I0324 05:59:40.022205  1493 solver.cpp:314] Iteration 36900 (1.44435 iter/s, 69.2353s/100 iter), loss = 2.98647
I0324 05:59:40.022358  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.85841 (* 1 = 2.85841 loss)
I0324 05:59:40.022403  1493 sgd_solver.cpp:136] Iteration 36900, lr = 0.001, m = 0.9
I0324 06:00:49.034061  1493 solver.cpp:314] Iteration 37000 (1.44907 iter/s, 69.0096s/100 iter), loss = 3.03436
I0324 06:00:49.034159  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.40249 (* 1 = 2.40249 loss)
I0324 06:00:49.034175  1493 sgd_solver.cpp:136] Iteration 37000, lr = 0.001, m = 0.9
I0324 06:01:57.793774  1493 solver.cpp:314] Iteration 37100 (1.45439 iter/s, 68.7575s/100 iter), loss = 3.20596
I0324 06:01:57.793925  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.78822 (* 1 = 2.78822 loss)
I0324 06:01:57.793951  1493 sgd_solver.cpp:136] Iteration 37100, lr = 0.001, m = 0.9
I0324 06:03:06.574765  1493 solver.cpp:314] Iteration 37200 (1.45394 iter/s, 68.7788s/100 iter), loss = 3.08501
I0324 06:03:06.574869  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.53701 (* 1 = 2.53701 loss)
I0324 06:03:06.574887  1493 sgd_solver.cpp:136] Iteration 37200, lr = 0.001, m = 0.9
I0324 06:04:14.987294  1493 solver.cpp:314] Iteration 37300 (1.46177 iter/s, 68.4103s/100 iter), loss = 3.1111
I0324 06:04:14.987402  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.27009 (* 1 = 3.27009 loss)
I0324 06:04:14.987418  1493 sgd_solver.cpp:136] Iteration 37300, lr = 0.001, m = 0.9
I0324 06:05:23.926103  1493 solver.cpp:314] Iteration 37400 (1.45061 iter/s, 68.9366s/100 iter), loss = 3.12703
I0324 06:05:23.926214  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.07052 (* 1 = 4.07052 loss)
I0324 06:05:23.926231  1493 sgd_solver.cpp:136] Iteration 37400, lr = 0.001, m = 0.9
I0324 06:06:32.738171  1493 solver.cpp:314] Iteration 37500 (1.45328 iter/s, 68.8098s/100 iter), loss = 3.10383
I0324 06:06:32.738262  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.71144 (* 1 = 2.71144 loss)
I0324 06:06:32.738278  1493 sgd_solver.cpp:136] Iteration 37500, lr = 0.001, m = 0.9
I0324 06:07:40.559028  1493 solver.cpp:314] Iteration 37600 (1.47452 iter/s, 67.8187s/100 iter), loss = 3.07532
I0324 06:07:40.559136  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.29325 (* 1 = 2.29325 loss)
I0324 06:07:40.559154  1493 sgd_solver.cpp:136] Iteration 37600, lr = 0.001, m = 0.9
I0324 06:08:48.281908  1493 solver.cpp:314] Iteration 37700 (1.47665 iter/s, 67.7206s/100 iter), loss = 2.9932
I0324 06:08:48.282080  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.68044 (* 1 = 2.68044 loss)
I0324 06:08:48.282129  1493 sgd_solver.cpp:136] Iteration 37700, lr = 0.001, m = 0.9
I0324 06:09:57.541754  1493 solver.cpp:314] Iteration 37800 (1.44389 iter/s, 69.2576s/100 iter), loss = 3.17548
I0324 06:09:57.541887  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.46325 (* 1 = 3.46325 loss)
I0324 06:09:57.541906  1493 sgd_solver.cpp:136] Iteration 37800, lr = 0.001, m = 0.9
I0324 06:11:05.114650  1493 solver.cpp:314] Iteration 37900 (1.47993 iter/s, 67.5707s/100 iter), loss = 2.93584
I0324 06:11:05.114776  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.99593 (* 1 = 2.99593 loss)
I0324 06:11:05.114826  1493 sgd_solver.cpp:136] Iteration 37900, lr = 0.001, m = 0.9
I0324 06:12:11.682731  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_38000.caffemodel
I0324 06:12:11.731462  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_38000.solverstate
I0324 06:12:11.749845  1493 solver.cpp:678] Iteration 38000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.282705
j:  : 4 : max_pr:  : 0.46875
j:  : 3 : max_pr:  : 0.60372
j:  : 2 : max_pr:  : 0.726551
j:  : 1 : max_pr:  : 0.829963
j:  : 0 : max_pr:  : 1
I0324 06:13:08.292428  1494 solver.cpp:786] class AP 1: 0.355608
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0993178
j:  : 7 : max_pr:  : 0.435933
j:  : 6 : max_pr:  : 0.528732
j:  : 5 : max_pr:  : 0.618462
j:  : 4 : max_pr:  : 0.67367
j:  : 3 : max_pr:  : 0.797065
j:  : 2 : max_pr:  : 0.987702
j:  : 1 : max_pr:  : 0.996279
j:  : 0 : max_pr:  : 1
I0324 06:13:08.346942  1494 solver.cpp:786] class AP 2: 0.557924
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.519979
j:  : 6 : max_pr:  : 0.66536
j:  : 5 : max_pr:  : 0.766223
j:  : 4 : max_pr:  : 0.868365
j:  : 3 : max_pr:  : 0.91852
j:  : 2 : max_pr:  : 0.961811
j:  : 1 : max_pr:  : 0.998672
j:  : 0 : max_pr:  : 1
I0324 06:13:08.357007  1494 solver.cpp:786] class AP 3: 0.608994
I0324 06:13:08.357026  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.507509
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.299261
j:  : 4 : max_pr:  : 0.491679
j:  : 3 : max_pr:  : 0.620112
j:  : 2 : max_pr:  : 0.735506
j:  : 1 : max_pr:  : 0.843621
j:  : 0 : max_pr:  : 1
I0324 06:13:08.739434  1493 solver.cpp:786] class AP 1: 0.362744
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.145593
j:  : 7 : max_pr:  : 0.436877
j:  : 6 : max_pr:  : 0.524029
j:  : 5 : max_pr:  : 0.620999
j:  : 4 : max_pr:  : 0.68508
j:  : 3 : max_pr:  : 0.797915
j:  : 2 : max_pr:  : 0.991809
j:  : 1 : max_pr:  : 1
j:  : 0 : max_pr:  : 1
I0324 06:13:08.792268  1493 solver.cpp:786] class AP 2: 0.563846
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.500792
j:  : 6 : max_pr:  : 0.650391
j:  : 5 : max_pr:  : 0.746773
j:  : 4 : max_pr:  : 0.854876
j:  : 3 : max_pr:  : 0.91209
j:  : 2 : max_pr:  : 0.962212
j:  : 1 : max_pr:  : 0.999361
j:  : 0 : max_pr:  : 1
I0324 06:13:08.801992  1493 solver.cpp:786] class AP 3: 0.602409
I0324 06:13:08.802006  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.509666
I0324 06:13:08.802376  1493 solver.cpp:265] [MultiGPU] Tests completed in 57.0508s
I0324 06:13:09.280328  1493 solver.cpp:314] Iteration 38000 (0.805402 iter/s, 124.162s/100 iter), loss = 3.14978
I0324 06:13:09.280375  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.25916 (* 1 = 4.25916 loss)
I0324 06:13:09.280386  1493 sgd_solver.cpp:136] Iteration 38000, lr = 0.001, m = 0.9
I0324 06:14:17.389927  1493 solver.cpp:314] Iteration 38100 (1.46827 iter/s, 68.1074s/100 iter), loss = 3.19815
I0324 06:14:17.390029  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.53201 (* 1 = 2.53201 loss)
I0324 06:14:17.390048  1493 sgd_solver.cpp:136] Iteration 38100, lr = 0.001, m = 0.9
I0324 06:15:25.657567  1493 solver.cpp:314] Iteration 38200 (1.46487 iter/s, 68.2654s/100 iter), loss = 3.11119
I0324 06:15:25.657670  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.18423 (* 1 = 3.18423 loss)
I0324 06:15:25.657685  1493 sgd_solver.cpp:136] Iteration 38200, lr = 0.001, m = 0.9
I0324 06:16:34.368717  1493 solver.cpp:314] Iteration 38300 (1.45542 iter/s, 68.7089s/100 iter), loss = 2.83169
I0324 06:16:34.368892  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.20701 (* 1 = 3.20701 loss)
I0324 06:16:34.368938  1493 sgd_solver.cpp:136] Iteration 38300, lr = 0.001, m = 0.9
I0324 06:17:42.805747  1493 solver.cpp:314] Iteration 38400 (1.46124 iter/s, 68.4348s/100 iter), loss = 3.35598
I0324 06:17:42.810947  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.96208 (* 1 = 3.96208 loss)
I0324 06:17:42.810973  1493 sgd_solver.cpp:136] Iteration 38400, lr = 0.001, m = 0.9
I0324 06:18:50.791467  1493 solver.cpp:314] Iteration 38500 (1.47094 iter/s, 67.9835s/100 iter), loss = 3.17166
I0324 06:18:50.791641  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.80233 (* 1 = 2.80233 loss)
I0324 06:18:50.791687  1493 sgd_solver.cpp:136] Iteration 38500, lr = 0.001, m = 0.9
I0324 06:19:43.405539  1462 data_reader.cpp:305] Starting prefetch of epoch 10
I0324 06:19:59.953063  1493 solver.cpp:314] Iteration 38600 (1.44594 iter/s, 69.1593s/100 iter), loss = 3.08497
I0324 06:19:59.953125  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.43066 (* 1 = 2.43066 loss)
I0324 06:19:59.953140  1493 sgd_solver.cpp:136] Iteration 38600, lr = 0.001, m = 0.9
I0324 06:21:08.539633  1493 solver.cpp:314] Iteration 38700 (1.45806 iter/s, 68.5844s/100 iter), loss = 3.28512
I0324 06:21:08.539822  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.13924 (* 1 = 4.13924 loss)
I0324 06:21:08.539865  1493 sgd_solver.cpp:136] Iteration 38700, lr = 0.001, m = 0.9
I0324 06:22:17.390202  1493 solver.cpp:314] Iteration 38800 (1.45247 iter/s, 68.8483s/100 iter), loss = 2.99097
I0324 06:22:17.391670  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.25015 (* 1 = 2.25015 loss)
I0324 06:22:17.391698  1493 sgd_solver.cpp:136] Iteration 38800, lr = 0.001, m = 0.9
I0324 06:23:26.585938  1493 solver.cpp:314] Iteration 38900 (1.44522 iter/s, 69.1935s/100 iter), loss = 3.04095
I0324 06:23:26.586050  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.27443 (* 1 = 2.27443 loss)
I0324 06:23:26.586068  1493 sgd_solver.cpp:136] Iteration 38900, lr = 0.001, m = 0.9
I0324 06:24:34.712321  1493 solver.cpp:314] Iteration 39000 (1.46791 iter/s, 68.1242s/100 iter), loss = 3.19843
I0324 06:24:34.712429  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.03752 (* 1 = 3.03752 loss)
I0324 06:24:34.712446  1493 sgd_solver.cpp:136] Iteration 39000, lr = 0.001, m = 0.9
I0324 06:25:42.690222  1493 solver.cpp:314] Iteration 39100 (1.47111 iter/s, 67.9757s/100 iter), loss = 2.93493
I0324 06:25:42.690318  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.35527 (* 1 = 2.35527 loss)
I0324 06:25:42.690335  1493 sgd_solver.cpp:136] Iteration 39100, lr = 0.001, m = 0.9
I0324 06:26:51.954618  1493 solver.cpp:314] Iteration 39200 (1.44379 iter/s, 69.2622s/100 iter), loss = 2.98839
I0324 06:26:51.954733  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.53746 (* 1 = 2.53746 loss)
I0324 06:26:51.954749  1493 sgd_solver.cpp:136] Iteration 39200, lr = 0.001, m = 0.9
I0324 06:28:01.005865  1493 solver.cpp:314] Iteration 39300 (1.44825 iter/s, 69.049s/100 iter), loss = 3.27341
I0324 06:28:01.005995  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.92711 (* 1 = 2.92711 loss)
I0324 06:28:01.006016  1493 sgd_solver.cpp:136] Iteration 39300, lr = 0.001, m = 0.9
I0324 06:29:08.705284  1493 solver.cpp:314] Iteration 39400 (1.47716 iter/s, 67.6973s/100 iter), loss = 3.17794
I0324 06:29:08.705417  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.3065 (* 1 = 4.3065 loss)
I0324 06:29:08.705476  1493 sgd_solver.cpp:136] Iteration 39400, lr = 0.001, m = 0.9
I0324 06:30:16.873984  1493 solver.cpp:314] Iteration 39500 (1.467 iter/s, 68.1665s/100 iter), loss = 3.06495
I0324 06:30:16.874104  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.3942 (* 1 = 3.3942 loss)
I0324 06:30:16.874517  1493 sgd_solver.cpp:136] Iteration 39500, lr = 0.001, m = 0.9
I0324 06:31:27.358816  1493 solver.cpp:314] Iteration 39600 (1.41879 iter/s, 70.4826s/100 iter), loss = 3.47505
I0324 06:31:27.358917  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.19611 (* 1 = 4.19611 loss)
I0324 06:31:27.358935  1493 sgd_solver.cpp:136] Iteration 39600, lr = 0.001, m = 0.9
I0324 06:32:35.501832  1493 solver.cpp:314] Iteration 39700 (1.46755 iter/s, 68.1408s/100 iter), loss = 3.10486
I0324 06:32:35.502022  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.33085 (* 1 = 2.33085 loss)
I0324 06:32:35.502073  1493 sgd_solver.cpp:136] Iteration 39700, lr = 0.001, m = 0.9
I0324 06:33:44.404040  1493 solver.cpp:314] Iteration 39800 (1.45138 iter/s, 68.8999s/100 iter), loss = 3.10937
I0324 06:33:44.404193  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.72066 (* 1 = 2.72066 loss)
I0324 06:33:44.404233  1493 sgd_solver.cpp:136] Iteration 39800, lr = 0.001, m = 0.9
I0324 06:34:53.161674  1493 solver.cpp:314] Iteration 39900 (1.45443 iter/s, 68.7554s/100 iter), loss = 3.10082
I0324 06:34:53.162077  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.5804 (* 1 = 2.5804 loss)
I0324 06:34:53.162096  1493 sgd_solver.cpp:136] Iteration 39900, lr = 0.001, m = 0.9
I0324 06:36:00.112795  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_40000.caffemodel
I0324 06:36:00.149907  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_40000.solverstate
I0324 06:36:00.164129  1493 solver.cpp:678] Iteration 40000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.295553
j:  : 4 : max_pr:  : 0.501398
j:  : 3 : max_pr:  : 0.649253
j:  : 2 : max_pr:  : 0.771506
j:  : 1 : max_pr:  : 0.870336
j:  : 0 : max_pr:  : 1
I0324 06:36:48.985051  1493 solver.cpp:786] class AP 1: 0.371641
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.187926
j:  : 7 : max_pr:  : 0.381788
j:  : 6 : max_pr:  : 0.56477
j:  : 5 : max_pr:  : 0.627597
j:  : 4 : max_pr:  : 0.681571
j:  : 3 : max_pr:  : 0.788423
j:  : 2 : max_pr:  : 0.98449
j:  : 1 : max_pr:  : 0.995294
j:  : 0 : max_pr:  : 1
I0324 06:36:49.052119  1493 solver.cpp:786] class AP 2: 0.564714
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.524227
j:  : 6 : max_pr:  : 0.666562
j:  : 5 : max_pr:  : 0.759595
j:  : 4 : max_pr:  : 0.865724
j:  : 3 : max_pr:  : 0.918398
j:  : 2 : max_pr:  : 0.967191
j:  : 1 : max_pr:  : 0.998046
j:  : 0 : max_pr:  : 1
I0324 06:36:49.067087  1493 solver.cpp:786] class AP 3: 0.609068
I0324 06:36:49.067109  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.515141
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.282791
j:  : 4 : max_pr:  : 0.478205
j:  : 3 : max_pr:  : 0.631759
j:  : 2 : max_pr:  : 0.762556
j:  : 1 : max_pr:  : 0.861486
j:  : 0 : max_pr:  : 1
I0324 06:36:50.314074  1494 solver.cpp:786] class AP 1: 0.365163
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.204041
j:  : 7 : max_pr:  : 0.39525
j:  : 6 : max_pr:  : 0.571664
j:  : 5 : max_pr:  : 0.633327
j:  : 4 : max_pr:  : 0.682245
j:  : 3 : max_pr:  : 0.790785
j:  : 2 : max_pr:  : 0.988345
j:  : 1 : max_pr:  : 0.998033
j:  : 0 : max_pr:  : 1
I0324 06:36:50.363394  1494 solver.cpp:786] class AP 2: 0.569426
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.514667
j:  : 6 : max_pr:  : 0.658447
j:  : 5 : max_pr:  : 0.750053
j:  : 4 : max_pr:  : 0.860639
j:  : 3 : max_pr:  : 0.915618
j:  : 2 : max_pr:  : 0.957225
j:  : 1 : max_pr:  : 0.997874
j:  : 0 : max_pr:  : 1
I0324 06:36:50.374399  1494 solver.cpp:786] class AP 3: 0.604957
I0324 06:36:50.374415  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.513182
I0324 06:36:50.374971  1493 solver.cpp:265] [MultiGPU] Tests completed in 50.2092s
I0324 06:36:50.797813  1514 sgd_solver.cpp:48] MultiStep Status: Iteration 40000, step = 2
I0324 06:36:50.797951  1513 sgd_solver.cpp:48] MultiStep Status: Iteration 40000, step = 2
I0324 06:36:50.877429  1493 solver.cpp:314] Iteration 40000 (0.849532 iter/s, 117.712s/100 iter), loss = 3.08852
I0324 06:36:50.877476  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.28139 (* 1 = 3.28139 loss)
I0324 06:36:50.877492  1493 sgd_solver.cpp:136] Iteration 40000, lr = 0.0001, m = 0.9
I0324 06:37:58.216634  1493 solver.cpp:314] Iteration 40100 (1.48507 iter/s, 67.337s/100 iter), loss = 3.03868
I0324 06:37:58.216742  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.43267 (* 1 = 2.43267 loss)
I0324 06:37:58.216759  1493 sgd_solver.cpp:136] Iteration 40100, lr = 0.0001, m = 0.9
I0324 06:39:07.549751  1493 solver.cpp:314] Iteration 40200 (1.44236 iter/s, 69.3308s/100 iter), loss = 3.21853
I0324 06:39:07.549849  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.84291 (* 1 = 3.84291 loss)
I0324 06:39:07.549867  1493 sgd_solver.cpp:136] Iteration 40200, lr = 0.0001, m = 0.9
I0324 06:40:15.846252  1493 solver.cpp:314] Iteration 40300 (1.46425 iter/s, 68.2943s/100 iter), loss = 3.04632
I0324 06:40:15.846424  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.36273 (* 1 = 2.36273 loss)
I0324 06:40:15.846468  1493 sgd_solver.cpp:136] Iteration 40300, lr = 0.0001, m = 0.9
I0324 06:41:23.929738  1493 solver.cpp:314] Iteration 40400 (1.46883 iter/s, 68.0813s/100 iter), loss = 3.36412
I0324 06:41:23.929889  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.45681 (* 1 = 3.45681 loss)
I0324 06:41:23.929934  1493 sgd_solver.cpp:136] Iteration 40400, lr = 0.0001, m = 0.9
I0324 06:42:32.415668  1493 solver.cpp:314] Iteration 40500 (1.4602 iter/s, 68.4837s/100 iter), loss = 3.02066
I0324 06:42:32.415837  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.53995 (* 1 = 2.53995 loss)
I0324 06:42:32.415882  1493 sgd_solver.cpp:136] Iteration 40500, lr = 0.0001, m = 0.9
I0324 06:43:41.269759  1493 solver.cpp:314] Iteration 40600 (1.45239 iter/s, 68.8518s/100 iter), loss = 3.13494
I0324 06:43:41.269866  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.68003 (* 1 = 2.68003 loss)
I0324 06:43:41.269884  1493 sgd_solver.cpp:136] Iteration 40600, lr = 0.0001, m = 0.9
I0324 06:44:49.405748  1493 solver.cpp:314] Iteration 40700 (1.4677 iter/s, 68.1338s/100 iter), loss = 3.23995
I0324 06:44:49.405851  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.08359 (* 1 = 3.08359 loss)
I0324 06:44:49.405870  1493 sgd_solver.cpp:136] Iteration 40700, lr = 0.0001, m = 0.9
I0324 06:45:57.259088  1493 solver.cpp:314] Iteration 40800 (1.47382 iter/s, 67.8511s/100 iter), loss = 3.02396
I0324 06:45:57.259333  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.92997 (* 1 = 3.92997 loss)
I0324 06:45:57.259390  1493 sgd_solver.cpp:136] Iteration 40800, lr = 0.0001, m = 0.9
I0324 06:47:05.876575  1493 solver.cpp:314] Iteration 40900 (1.4574 iter/s, 68.6152s/100 iter), loss = 3.08889
I0324 06:47:05.876715  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.78777 (* 1 = 2.78777 loss)
I0324 06:47:05.876732  1493 sgd_solver.cpp:136] Iteration 40900, lr = 0.0001, m = 0.9
I0324 06:48:13.945984  1493 solver.cpp:314] Iteration 41000 (1.46914 iter/s, 68.0672s/100 iter), loss = 3.07945
I0324 06:48:13.946074  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.28953 (* 1 = 3.28953 loss)
I0324 06:48:13.946089  1493 sgd_solver.cpp:136] Iteration 41000, lr = 0.0001, m = 0.9
I0324 06:49:22.611306  1493 solver.cpp:314] Iteration 41100 (1.45639 iter/s, 68.6631s/100 iter), loss = 2.77328
I0324 06:49:22.619182  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.06424 (* 1 = 2.06424 loss)
I0324 06:49:22.619220  1493 sgd_solver.cpp:136] Iteration 41100, lr = 0.0001, m = 0.9
I0324 06:50:31.034060  1493 solver.cpp:314] Iteration 41200 (1.46155 iter/s, 68.4205s/100 iter), loss = 3.15337
I0324 06:50:31.034165  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.11522 (* 1 = 3.11522 loss)
I0324 06:50:31.034181  1493 sgd_solver.cpp:136] Iteration 41200, lr = 0.0001, m = 0.9
I0324 06:51:38.494746  1493 solver.cpp:314] Iteration 41300 (1.48239 iter/s, 67.4585s/100 iter), loss = 2.98827
I0324 06:51:38.494854  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.14123 (* 1 = 3.14123 loss)
I0324 06:51:38.494871  1493 sgd_solver.cpp:136] Iteration 41300, lr = 0.0001, m = 0.9
I0324 06:52:47.247902  1493 solver.cpp:314] Iteration 41400 (1.45453 iter/s, 68.7509s/100 iter), loss = 3.13453
I0324 06:52:47.248010  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.36733 (* 1 = 3.36733 loss)
I0324 06:52:47.248026  1493 sgd_solver.cpp:136] Iteration 41400, lr = 0.0001, m = 0.9
I0324 06:53:56.805222  1493 solver.cpp:314] Iteration 41500 (1.43771 iter/s, 69.555s/100 iter), loss = 3.04435
I0324 06:53:56.805393  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.30626 (* 1 = 2.30626 loss)
I0324 06:53:56.805436  1493 sgd_solver.cpp:136] Iteration 41500, lr = 0.0001, m = 0.9
I0324 06:55:04.460912  1493 solver.cpp:314] Iteration 41600 (1.47812 iter/s, 67.6535s/100 iter), loss = 3.12917
I0324 06:55:04.461483  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.52901 (* 1 = 4.52901 loss)
I0324 06:55:04.461885  1493 sgd_solver.cpp:136] Iteration 41600, lr = 0.0001, m = 0.9
I0324 06:56:12.606453  1493 solver.cpp:314] Iteration 41700 (1.4675 iter/s, 68.1433s/100 iter), loss = 2.7812
I0324 06:56:12.606642  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.13501 (* 1 = 2.13501 loss)
I0324 06:56:12.606657  1493 sgd_solver.cpp:136] Iteration 41700, lr = 0.0001, m = 0.9
I0324 06:56:14.873960  1462 data_reader.cpp:305] Starting prefetch of epoch 11
I0324 06:57:21.558989  1493 solver.cpp:314] Iteration 41800 (1.45032 iter/s, 68.9503s/100 iter), loss = 2.78542
I0324 06:57:21.559094  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.32422 (* 1 = 2.32422 loss)
I0324 06:57:21.559111  1493 sgd_solver.cpp:136] Iteration 41800, lr = 0.0001, m = 0.9
I0324 06:58:30.013484  1493 solver.cpp:314] Iteration 41900 (1.46087 iter/s, 68.4523s/100 iter), loss = 3.07801
I0324 06:58:30.013669  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.08809 (* 1 = 3.08809 loss)
I0324 06:58:30.013684  1493 sgd_solver.cpp:136] Iteration 41900, lr = 0.0001, m = 0.9
I0324 06:59:37.968294  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_42000.caffemodel
I0324 06:59:38.002785  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_42000.solverstate
I0324 06:59:38.016464  1493 solver.cpp:678] Iteration 42000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.312643
j:  : 4 : max_pr:  : 0.500104
j:  : 3 : max_pr:  : 0.636085
j:  : 2 : max_pr:  : 0.768165
j:  : 1 : max_pr:  : 0.854364
j:  : 0 : max_pr:  : 1
I0324 07:00:27.290899  1494 solver.cpp:786] class AP 1: 0.370124
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.161471
j:  : 7 : max_pr:  : 0.396291
j:  : 6 : max_pr:  : 0.533352
j:  : 5 : max_pr:  : 0.607773
j:  : 4 : max_pr:  : 0.683497
j:  : 3 : max_pr:  : 0.788848
j:  : 2 : max_pr:  : 0.989198
j:  : 1 : max_pr:  : 0.998217
j:  : 0 : max_pr:  : 1
I0324 07:00:27.341408  1494 solver.cpp:786] class AP 2: 0.559877
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.526765
j:  : 6 : max_pr:  : 0.650962
j:  : 5 : max_pr:  : 0.744788
j:  : 4 : max_pr:  : 0.855324
j:  : 3 : max_pr:  : 0.911714
j:  : 2 : max_pr:  : 0.960399
j:  : 1 : max_pr:  : 0.998641
j:  : 0 : max_pr:  : 1
I0324 07:00:27.352352  1494 solver.cpp:786] class AP 3: 0.604418
I0324 07:00:27.352372  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.511473
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.301721
j:  : 4 : max_pr:  : 0.500103
j:  : 3 : max_pr:  : 0.639113
j:  : 2 : max_pr:  : 0.75762
j:  : 1 : max_pr:  : 0.869234
j:  : 0 : max_pr:  : 1
I0324 07:00:28.224586  1493 solver.cpp:786] class AP 1: 0.369799
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.129792
j:  : 7 : max_pr:  : 0.385017
j:  : 6 : max_pr:  : 0.532157
j:  : 5 : max_pr:  : 0.602879
j:  : 4 : max_pr:  : 0.672325
j:  : 3 : max_pr:  : 0.782123
j:  : 2 : max_pr:  : 0.988688
j:  : 1 : max_pr:  : 0.996475
j:  : 0 : max_pr:  : 1
I0324 07:00:28.273643  1493 solver.cpp:786] class AP 2: 0.553587
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.501511
j:  : 6 : max_pr:  : 0.645022
j:  : 5 : max_pr:  : 0.751983
j:  : 4 : max_pr:  : 0.864964
j:  : 3 : max_pr:  : 0.912022
j:  : 2 : max_pr:  : 0.960526
j:  : 1 : max_pr:  : 0.997921
j:  : 0 : max_pr:  : 1
I0324 07:00:28.283913  1493 solver.cpp:786] class AP 3: 0.603086
I0324 07:00:28.283926  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.508824
I0324 07:00:28.284315  1493 solver.cpp:265] [MultiGPU] Tests completed in 50.2662s
I0324 07:00:28.674978  1493 solver.cpp:314] Iteration 42000 (0.842761 iter/s, 118.658s/100 iter), loss = 3.03242
I0324 07:00:28.675034  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.54725 (* 1 = 3.54725 loss)
I0324 07:00:28.675048  1493 sgd_solver.cpp:136] Iteration 42000, lr = 0.0001, m = 0.9
I0324 07:01:37.345760  1493 solver.cpp:314] Iteration 42100 (1.45627 iter/s, 68.6685s/100 iter), loss = 3.04733
I0324 07:01:37.357802  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.17982 (* 1 = 3.17982 loss)
I0324 07:01:37.358191  1493 sgd_solver.cpp:136] Iteration 42100, lr = 0.0001, m = 0.9
I0324 07:02:44.809765  1493 solver.cpp:314] Iteration 42200 (1.48232 iter/s, 67.4618s/100 iter), loss = 3.19144
I0324 07:02:44.809875  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.85471 (* 1 = 2.85471 loss)
I0324 07:02:44.809895  1493 sgd_solver.cpp:136] Iteration 42200, lr = 0.0001, m = 0.9
I0324 07:03:53.429183  1493 solver.cpp:314] Iteration 42300 (1.45736 iter/s, 68.6172s/100 iter), loss = 3.14307
I0324 07:03:53.429285  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.1819 (* 1 = 3.1819 loss)
I0324 07:03:53.429301  1493 sgd_solver.cpp:136] Iteration 42300, lr = 0.0001, m = 0.9
I0324 07:05:02.114215  1493 solver.cpp:314] Iteration 42400 (1.45597 iter/s, 68.6828s/100 iter), loss = 3.04257
I0324 07:05:02.114322  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.55872 (* 1 = 3.55872 loss)
I0324 07:05:02.114339  1493 sgd_solver.cpp:136] Iteration 42400, lr = 0.0001, m = 0.9
I0324 07:06:10.153756  1493 solver.cpp:314] Iteration 42500 (1.46978 iter/s, 68.0373s/100 iter), loss = 3.14747
I0324 07:06:10.153864  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.19636 (* 1 = 3.19636 loss)
I0324 07:06:10.153883  1493 sgd_solver.cpp:136] Iteration 42500, lr = 0.0001, m = 0.9
I0324 07:07:18.160948  1493 solver.cpp:314] Iteration 42600 (1.47048 iter/s, 68.005s/100 iter), loss = 3.07537
I0324 07:07:18.161048  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.89271 (* 1 = 3.89271 loss)
I0324 07:07:18.161067  1493 sgd_solver.cpp:136] Iteration 42600, lr = 0.0001, m = 0.9
I0324 07:08:27.325760  1493 solver.cpp:314] Iteration 42700 (1.44587 iter/s, 69.1625s/100 iter), loss = 3.03557
I0324 07:08:27.325883  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.08161 (* 1 = 3.08161 loss)
I0324 07:08:27.325911  1493 sgd_solver.cpp:136] Iteration 42700, lr = 0.0001, m = 0.9
I0324 07:09:36.198614  1493 solver.cpp:314] Iteration 42800 (1.452 iter/s, 68.8706s/100 iter), loss = 3.12652
I0324 07:09:36.198715  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.58332 (* 1 = 2.58332 loss)
I0324 07:09:36.198731  1493 sgd_solver.cpp:136] Iteration 42800, lr = 0.0001, m = 0.9
I0324 07:10:43.046583  1493 solver.cpp:314] Iteration 42900 (1.49598 iter/s, 66.8458s/100 iter), loss = 3.15927
I0324 07:10:43.046686  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.56872 (* 1 = 3.56872 loss)
I0324 07:10:43.046705  1493 sgd_solver.cpp:136] Iteration 42900, lr = 0.0001, m = 0.9
I0324 07:11:51.254344  1493 solver.cpp:314] Iteration 43000 (1.46616 iter/s, 68.2055s/100 iter), loss = 3.17444
I0324 07:11:51.254451  1493 solver.cpp:336]     Train net output #0: mbox_loss = 1.9194 (* 1 = 1.9194 loss)
I0324 07:11:51.254501  1493 sgd_solver.cpp:136] Iteration 43000, lr = 0.0001, m = 0.9
I0324 07:12:59.041858  1493 solver.cpp:314] Iteration 43100 (1.47525 iter/s, 67.7853s/100 iter), loss = 3.14547
I0324 07:12:59.042013  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.13829 (* 1 = 4.13829 loss)
I0324 07:12:59.042033  1493 sgd_solver.cpp:136] Iteration 43100, lr = 0.0001, m = 0.9
I0324 07:14:08.468654  1493 solver.cpp:314] Iteration 43200 (1.44041 iter/s, 69.4245s/100 iter), loss = 3.21238
I0324 07:14:08.469185  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.62066 (* 1 = 2.62066 loss)
I0324 07:14:08.471381  1493 sgd_solver.cpp:136] Iteration 43200, lr = 0.0001, m = 0.9
I0324 07:15:17.422499  1493 solver.cpp:314] Iteration 43300 (1.45029 iter/s, 68.9516s/100 iter), loss = 3.04188
I0324 07:15:17.422703  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.27608 (* 1 = 2.27608 loss)
I0324 07:15:17.422746  1493 sgd_solver.cpp:136] Iteration 43300, lr = 0.0001, m = 0.9
I0324 07:16:25.646433  1493 solver.cpp:314] Iteration 43400 (1.46581 iter/s, 68.2217s/100 iter), loss = 3.07938
I0324 07:16:25.646719  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.18998 (* 1 = 3.18998 loss)
I0324 07:16:25.646764  1493 sgd_solver.cpp:136] Iteration 43400, lr = 0.0001, m = 0.9
I0324 07:17:34.599541  1493 solver.cpp:314] Iteration 43500 (1.45031 iter/s, 68.9509s/100 iter), loss = 3.36825
I0324 07:17:34.599635  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.15881 (* 1 = 3.15881 loss)
I0324 07:17:34.599651  1493 sgd_solver.cpp:136] Iteration 43500, lr = 0.0001, m = 0.9
I0324 07:18:42.184196  1493 solver.cpp:314] Iteration 43600 (1.47967 iter/s, 67.5824s/100 iter), loss = 3.33264
I0324 07:18:42.184298  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.606 (* 1 = 3.606 loss)
I0324 07:18:42.184310  1493 sgd_solver.cpp:136] Iteration 43600, lr = 0.0001, m = 0.9
I0324 07:19:50.697921  1493 solver.cpp:314] Iteration 43700 (1.45961 iter/s, 68.5115s/100 iter), loss = 3.13021
I0324 07:19:50.698088  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.03949 (* 1 = 3.03949 loss)
I0324 07:19:50.698134  1493 sgd_solver.cpp:136] Iteration 43700, lr = 0.0001, m = 0.9
I0324 07:21:00.272279  1493 solver.cpp:314] Iteration 43800 (1.43736 iter/s, 69.5721s/100 iter), loss = 3.29125
I0324 07:21:00.272380  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.13415 (* 1 = 3.13415 loss)
I0324 07:21:00.272397  1493 sgd_solver.cpp:136] Iteration 43800, lr = 0.0001, m = 0.9
I0324 07:22:08.697846  1493 solver.cpp:314] Iteration 43900 (1.46149 iter/s, 68.4233s/100 iter), loss = 3.1668
I0324 07:22:08.697959  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.67469 (* 1 = 3.67469 loss)
I0324 07:22:08.697978  1493 sgd_solver.cpp:136] Iteration 43900, lr = 0.0001, m = 0.9
I0324 07:23:16.902506  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_44000.caffemodel
I0324 07:23:16.973913  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_44000.solverstate
I0324 07:23:16.993432  1493 solver.cpp:678] Iteration 44000, Testing net (#0)
I0324 07:23:25.021747  1494 blocking_queue.cpp:40] Data layer prefetch queue empty
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.323504
j:  : 4 : max_pr:  : 0.507162
j:  : 3 : max_pr:  : 0.635208
j:  : 2 : max_pr:  : 0.765338
j:  : 1 : max_pr:  : 0.858696
j:  : 0 : max_pr:  : 1
I0324 07:24:06.091373  1494 solver.cpp:786] class AP 1: 0.37181
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.309723
j:  : 4 : max_pr:  : 0.495249
j:  : 3 : max_pr:  : 0.642849
j:  : 2 : max_pr:  : 0.761294
j:  : 1 : max_pr:  : 0.863333
j:  : 0 : max_pr:  : 1
I0324 07:24:06.116075  1493 solver.cpp:786] class AP 1: 0.370223
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.180469
j:  : 7 : max_pr:  : 0.405578
j:  : 6 : max_pr:  : 0.516895
j:  : 5 : max_pr:  : 0.592122
j:  : 4 : max_pr:  : 0.688538
j:  : 3 : max_pr:  : 0.797881
j:  : 2 : max_pr:  : 0.992424
j:  : 1 : max_pr:  : 1
j:  : 0 : max_pr:  : 1
I0324 07:24:06.142516  1494 solver.cpp:786] class AP 2: 0.561264
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.529029
j:  : 6 : max_pr:  : 0.656903
j:  : 5 : max_pr:  : 0.7474
j:  : 4 : max_pr:  : 0.857472
j:  : 3 : max_pr:  : 0.915317
j:  : 2 : max_pr:  : 0.965076
j:  : 1 : max_pr:  : 0.998076
j:  : 0 : max_pr:  : 1
I0324 07:24:06.153496  1494 solver.cpp:786] class AP 3: 0.606298
I0324 07:24:06.153522  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.513124
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.13076
j:  : 7 : max_pr:  : 0.385656
j:  : 6 : max_pr:  : 0.500908
j:  : 5 : max_pr:  : 0.585987
j:  : 4 : max_pr:  : 0.675577
j:  : 3 : max_pr:  : 0.784497
j:  : 2 : max_pr:  : 0.980989
j:  : 1 : max_pr:  : 0.994481
j:  : 0 : max_pr:  : 1
I0324 07:24:06.167196  1493 solver.cpp:786] class AP 2: 0.548987
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.507787
j:  : 6 : max_pr:  : 0.65539
j:  : 5 : max_pr:  : 0.7609
j:  : 4 : max_pr:  : 0.865935
j:  : 3 : max_pr:  : 0.915844
j:  : 2 : max_pr:  : 0.959838
j:  : 1 : max_pr:  : 0.998615
j:  : 0 : max_pr:  : 1
I0324 07:24:06.177507  1493 solver.cpp:786] class AP 3: 0.605846
I0324 07:24:06.177525  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.508352
I0324 07:24:06.177912  1493 solver.cpp:265] [MultiGPU] Tests completed in 49.1829s
I0324 07:24:06.637744  1493 solver.cpp:314] Iteration 44000 (0.847917 iter/s, 117.936s/100 iter), loss = 2.87876
I0324 07:24:06.637792  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.97773 (* 1 = 2.97773 loss)
I0324 07:24:06.637807  1493 sgd_solver.cpp:136] Iteration 44000, lr = 0.0001, m = 0.9
I0324 07:25:13.721985  1493 solver.cpp:314] Iteration 44100 (1.49071 iter/s, 67.082s/100 iter), loss = 3.03519
I0324 07:25:13.722128  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.91357 (* 1 = 2.91357 loss)
I0324 07:25:13.722146  1493 sgd_solver.cpp:136] Iteration 44100, lr = 0.0001, m = 0.9
I0324 07:26:21.807013  1493 solver.cpp:314] Iteration 44200 (1.4688 iter/s, 68.0828s/100 iter), loss = 3.04453
I0324 07:26:21.807114  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.72558 (* 1 = 2.72558 loss)
I0324 07:26:21.807130  1493 sgd_solver.cpp:136] Iteration 44200, lr = 0.0001, m = 0.9
I0324 07:27:29.474364  1493 solver.cpp:314] Iteration 44300 (1.47787 iter/s, 67.6651s/100 iter), loss = 3.03962
I0324 07:27:29.474539  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.16806 (* 1 = 3.16806 loss)
I0324 07:27:29.474557  1493 sgd_solver.cpp:136] Iteration 44300, lr = 0.0001, m = 0.9
I0324 07:28:37.776736  1493 solver.cpp:314] Iteration 44400 (1.46413 iter/s, 68.3001s/100 iter), loss = 3.2947
I0324 07:28:37.776933  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.47371 (* 1 = 2.47371 loss)
I0324 07:28:37.776976  1493 sgd_solver.cpp:136] Iteration 44400, lr = 0.0001, m = 0.9
I0324 07:29:35.134449  1462 data_reader.cpp:305] Starting prefetch of epoch 12
I0324 07:29:46.429221  1493 solver.cpp:314] Iteration 44500 (1.45666 iter/s, 68.6502s/100 iter), loss = 3.04056
I0324 07:29:46.429276  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.28047 (* 1 = 3.28047 loss)
I0324 07:29:46.429294  1493 sgd_solver.cpp:136] Iteration 44500, lr = 0.0001, m = 0.9
I0324 07:30:54.252179  1493 solver.cpp:314] Iteration 44600 (1.47448 iter/s, 67.8207s/100 iter), loss = 3.0794
I0324 07:30:54.252295  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.87731 (* 1 = 3.87731 loss)
I0324 07:30:54.252313  1493 sgd_solver.cpp:136] Iteration 44600, lr = 0.0001, m = 0.9
I0324 07:32:02.570093  1493 solver.cpp:314] Iteration 44700 (1.46379 iter/s, 68.3157s/100 iter), loss = 2.94132
I0324 07:32:02.570273  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.50639 (* 1 = 3.50639 loss)
I0324 07:32:02.570291  1493 sgd_solver.cpp:136] Iteration 44700, lr = 0.0001, m = 0.9
I0324 07:33:09.631613  1493 solver.cpp:314] Iteration 44800 (1.49122 iter/s, 67.0593s/100 iter), loss = 3.23547
I0324 07:33:09.631713  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.78171 (* 1 = 2.78171 loss)
I0324 07:33:09.631731  1493 sgd_solver.cpp:136] Iteration 44800, lr = 0.0001, m = 0.9
I0324 07:34:18.292480  1493 solver.cpp:314] Iteration 44900 (1.45648 iter/s, 68.6586s/100 iter), loss = 3.20796
I0324 07:34:18.292631  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.34022 (* 1 = 3.34022 loss)
I0324 07:34:18.292672  1493 sgd_solver.cpp:136] Iteration 44900, lr = 0.0001, m = 0.9
I0324 07:35:27.213379  1493 solver.cpp:314] Iteration 45000 (1.45099 iter/s, 68.9186s/100 iter), loss = 3.04834
I0324 07:35:27.213486  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.07171 (* 1 = 3.07171 loss)
I0324 07:35:27.213505  1493 sgd_solver.cpp:136] Iteration 45000, lr = 0.0001, m = 0.9
I0324 07:36:34.401302  1493 solver.cpp:314] Iteration 45100 (1.48841 iter/s, 67.1857s/100 iter), loss = 3.10929
I0324 07:36:34.401409  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.10011 (* 1 = 4.10011 loss)
I0324 07:36:34.401425  1493 sgd_solver.cpp:136] Iteration 45100, lr = 0.0001, m = 0.9
I0324 07:37:42.392565  1493 solver.cpp:314] Iteration 45200 (1.47083 iter/s, 67.989s/100 iter), loss = 2.9916
I0324 07:37:42.393033  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.09249 (* 1 = 3.09249 loss)
I0324 07:37:42.393354  1493 sgd_solver.cpp:136] Iteration 45200, lr = 0.0001, m = 0.9
I0324 07:38:50.156069  1493 solver.cpp:314] Iteration 45300 (1.47577 iter/s, 67.7613s/100 iter), loss = 3.05863
I0324 07:38:50.156204  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.19671 (* 1 = 3.19671 loss)
I0324 07:38:50.156220  1493 sgd_solver.cpp:136] Iteration 45300, lr = 0.0001, m = 0.9
I0324 07:39:58.985978  1493 solver.cpp:314] Iteration 45400 (1.4529 iter/s, 68.8277s/100 iter), loss = 3.29304
I0324 07:39:58.986135  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.98825 (* 1 = 2.98825 loss)
I0324 07:39:58.986153  1493 sgd_solver.cpp:136] Iteration 45400, lr = 0.0001, m = 0.9
I0324 07:41:07.751751  1493 solver.cpp:314] Iteration 45500 (1.45426 iter/s, 68.7635s/100 iter), loss = 3.13522
I0324 07:41:07.751860  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.35104 (* 1 = 4.35104 loss)
I0324 07:41:07.751878  1493 sgd_solver.cpp:136] Iteration 45500, lr = 0.0001, m = 0.9
I0324 07:42:15.678202  1493 solver.cpp:314] Iteration 45600 (1.47223 iter/s, 67.9242s/100 iter), loss = 3.0868
I0324 07:42:15.678292  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.47244 (* 1 = 3.47244 loss)
I0324 07:42:15.678309  1493 sgd_solver.cpp:136] Iteration 45600, lr = 0.0001, m = 0.9
I0324 07:43:24.641938  1493 solver.cpp:314] Iteration 45700 (1.45008 iter/s, 68.9615s/100 iter), loss = 3.13317
I0324 07:43:24.642052  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.62148 (* 1 = 3.62148 loss)
I0324 07:43:24.642069  1493 sgd_solver.cpp:136] Iteration 45700, lr = 0.0001, m = 0.9
I0324 07:44:33.018784  1493 solver.cpp:314] Iteration 45800 (1.46253 iter/s, 68.3746s/100 iter), loss = 2.87154
I0324 07:44:33.018872  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.90256 (* 1 = 2.90256 loss)
I0324 07:44:33.018885  1493 sgd_solver.cpp:136] Iteration 45800, lr = 0.0001, m = 0.9
I0324 07:45:42.010219  1493 solver.cpp:314] Iteration 45900 (1.4495 iter/s, 68.9892s/100 iter), loss = 3.13208
I0324 07:45:42.010313  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.5656 (* 1 = 3.5656 loss)
I0324 07:45:42.010330  1493 sgd_solver.cpp:136] Iteration 45900, lr = 0.0001, m = 0.9
I0324 07:46:49.378049  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_46000.caffemodel
I0324 07:46:49.427376  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_46000.solverstate
I0324 07:46:49.439302  1493 solver.cpp:678] Iteration 46000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.318496
j:  : 4 : max_pr:  : 0.510603
j:  : 3 : max_pr:  : 0.640019
j:  : 2 : max_pr:  : 0.765478
j:  : 1 : max_pr:  : 0.865629
j:  : 0 : max_pr:  : 1
I0324 07:47:40.523267  1494 solver.cpp:786] class AP 1: 0.372748
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.158434
j:  : 7 : max_pr:  : 0.399983
j:  : 6 : max_pr:  : 0.533002
j:  : 5 : max_pr:  : 0.608096
j:  : 4 : max_pr:  : 0.693701
j:  : 3 : max_pr:  : 0.79067
j:  : 2 : max_pr:  : 0.991058
j:  : 1 : max_pr:  : 0.998817
j:  : 0 : max_pr:  : 1
I0324 07:47:40.573727  1494 solver.cpp:786] class AP 2: 0.561251
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.511185
j:  : 6 : max_pr:  : 0.646059
j:  : 5 : max_pr:  : 0.746721
j:  : 4 : max_pr:  : 0.85699
j:  : 3 : max_pr:  : 0.909955
j:  : 2 : max_pr:  : 0.961631
j:  : 1 : max_pr:  : 0.999351
j:  : 0 : max_pr:  : 1
I0324 07:47:40.583670  1494 solver.cpp:786] class AP 3: 0.602899
I0324 07:47:40.583688  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.512299
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.299651
j:  : 4 : max_pr:  : 0.48777
j:  : 3 : max_pr:  : 0.632885
j:  : 2 : max_pr:  : 0.75789
j:  : 1 : max_pr:  : 0.857829
j:  : 0 : max_pr:  : 1
I0324 07:47:41.355732  1493 solver.cpp:786] class AP 1: 0.366911
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.102269
j:  : 7 : max_pr:  : 0.376892
j:  : 6 : max_pr:  : 0.51983
j:  : 5 : max_pr:  : 0.588519
j:  : 4 : max_pr:  : 0.667541
j:  : 3 : max_pr:  : 0.783505
j:  : 2 : max_pr:  : 0.979969
j:  : 1 : max_pr:  : 0.996223
j:  : 0 : max_pr:  : 1
I0324 07:47:41.405869  1493 solver.cpp:786] class AP 2: 0.546795
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.52116
j:  : 6 : max_pr:  : 0.654558
j:  : 5 : max_pr:  : 0.760921
j:  : 4 : max_pr:  : 0.867832
j:  : 3 : max_pr:  : 0.913359
j:  : 2 : max_pr:  : 0.95683
j:  : 1 : max_pr:  : 0.998029
j:  : 0 : max_pr:  : 1
I0324 07:47:41.415472  1493 solver.cpp:786] class AP 3: 0.606608
I0324 07:47:41.415488  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.506772
I0324 07:47:41.415808  1493 solver.cpp:265] [MultiGPU] Tests completed in 51.9748s
I0324 07:47:41.818620  1493 solver.cpp:314] Iteration 46000 (0.834693 iter/s, 119.804s/100 iter), loss = 3.18002
I0324 07:47:41.818672  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.473 (* 1 = 3.473 loss)
I0324 07:47:41.818688  1493 sgd_solver.cpp:136] Iteration 46000, lr = 0.0001, m = 0.9
I0324 07:48:50.328485  1493 solver.cpp:314] Iteration 46100 (1.45969 iter/s, 68.5076s/100 iter), loss = 3.36331
I0324 07:48:50.328640  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.37204 (* 1 = 2.37204 loss)
I0324 07:48:50.328663  1493 sgd_solver.cpp:136] Iteration 46100, lr = 0.0001, m = 0.9
I0324 07:50:00.038676  1493 solver.cpp:314] Iteration 46200 (1.43456 iter/s, 69.7079s/100 iter), loss = 3.17479
I0324 07:50:00.038774  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.17881 (* 1 = 3.17881 loss)
I0324 07:50:00.038790  1493 sgd_solver.cpp:136] Iteration 46200, lr = 0.0001, m = 0.9
I0324 07:51:08.659468  1493 solver.cpp:314] Iteration 46300 (1.45733 iter/s, 68.6185s/100 iter), loss = 3.12083
I0324 07:51:08.659602  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.88121 (* 1 = 2.88121 loss)
I0324 07:51:08.659621  1493 sgd_solver.cpp:136] Iteration 46300, lr = 0.0001, m = 0.9
I0324 07:52:17.232301  1493 solver.cpp:314] Iteration 46400 (1.45835 iter/s, 68.5706s/100 iter), loss = 2.9281
I0324 07:52:17.232379  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.83569 (* 1 = 2.83569 loss)
I0324 07:52:17.232396  1493 sgd_solver.cpp:136] Iteration 46400, lr = 0.0001, m = 0.9
I0324 07:53:24.369060  1493 solver.cpp:314] Iteration 46500 (1.48955 iter/s, 67.1346s/100 iter), loss = 3.04655
I0324 07:53:24.369159  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.12292 (* 1 = 4.12292 loss)
I0324 07:53:24.369175  1493 sgd_solver.cpp:136] Iteration 46500, lr = 0.0001, m = 0.9
I0324 07:54:33.791268  1493 solver.cpp:314] Iteration 46600 (1.44051 iter/s, 69.4199s/100 iter), loss = 3.48185
I0324 07:54:33.791363  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.89147 (* 1 = 3.89147 loss)
I0324 07:54:33.791378  1493 sgd_solver.cpp:136] Iteration 46600, lr = 0.0001, m = 0.9
I0324 07:55:42.009618  1493 solver.cpp:314] Iteration 46700 (1.46593 iter/s, 68.2161s/100 iter), loss = 2.95552
I0324 07:55:42.009727  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.30125 (* 1 = 3.30125 loss)
I0324 07:55:42.009743  1493 sgd_solver.cpp:136] Iteration 46700, lr = 0.0001, m = 0.9
I0324 07:56:50.739230  1493 solver.cpp:314] Iteration 46800 (1.45502 iter/s, 68.7274s/100 iter), loss = 3.06636
I0324 07:56:50.739329  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.78629 (* 1 = 2.78629 loss)
I0324 07:56:50.739346  1493 sgd_solver.cpp:136] Iteration 46800, lr = 0.0001, m = 0.9
I0324 07:57:58.850126  1493 solver.cpp:314] Iteration 46900 (1.46824 iter/s, 68.1087s/100 iter), loss = 3.17339
I0324 07:57:58.861762  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.81028 (* 1 = 2.81028 loss)
I0324 07:57:58.861793  1493 sgd_solver.cpp:136] Iteration 46900, lr = 0.0001, m = 0.9
I0324 07:59:06.926781  1493 solver.cpp:314] Iteration 47000 (1.46898 iter/s, 68.0744s/100 iter), loss = 3.07419
I0324 07:59:06.926870  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.60293 (* 1 = 3.60293 loss)
I0324 07:59:06.926887  1493 sgd_solver.cpp:136] Iteration 47000, lr = 0.0001, m = 0.9
I0324 08:00:15.171891  1493 solver.cpp:314] Iteration 47100 (1.46535 iter/s, 68.2429s/100 iter), loss = 3.25982
I0324 08:00:15.171980  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.13503 (* 1 = 3.13503 loss)
I0324 08:00:15.171998  1493 sgd_solver.cpp:136] Iteration 47100, lr = 0.0001, m = 0.9
I0324 08:01:23.476588  1493 solver.cpp:314] Iteration 47200 (1.46408 iter/s, 68.3025s/100 iter), loss = 2.98622
I0324 08:01:23.477038  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.79857 (* 1 = 2.79857 loss)
I0324 08:01:23.477337  1493 sgd_solver.cpp:136] Iteration 47200, lr = 0.0001, m = 0.9
I0324 08:02:32.167660  1493 solver.cpp:314] Iteration 47300 (1.45584 iter/s, 68.6888s/100 iter), loss = 3.03302
I0324 08:02:32.167763  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.97592 (* 1 = 2.97592 loss)
I0324 08:02:32.167780  1493 sgd_solver.cpp:136] Iteration 47300, lr = 0.0001, m = 0.9
I0324 08:03:40.843776  1493 solver.cpp:314] Iteration 47400 (1.45616 iter/s, 68.6739s/100 iter), loss = 3.20969
I0324 08:03:40.843880  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.0404 (* 1 = 3.0404 loss)
I0324 08:03:40.843895  1493 sgd_solver.cpp:136] Iteration 47400, lr = 0.0001, m = 0.9
I0324 08:04:49.813959  1493 solver.cpp:314] Iteration 47500 (1.44995 iter/s, 68.9679s/100 iter), loss = 3.19008
I0324 08:04:49.814065  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.83467 (* 1 = 3.83467 loss)
I0324 08:04:49.814085  1493 sgd_solver.cpp:136] Iteration 47500, lr = 0.0001, m = 0.9
I0324 08:06:07.845269  1493 solver.cpp:314] Iteration 47600 (1.28158 iter/s, 78.0288s/100 iter), loss = 3.1701
I0324 08:06:07.845417  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.43291 (* 1 = 3.43291 loss)
I0324 08:06:07.845437  1493 sgd_solver.cpp:136] Iteration 47600, lr = 0.0001, m = 0.9
I0324 08:06:18.440486  1462 data_reader.cpp:305] Starting prefetch of epoch 13
I0324 08:07:19.009405  1493 solver.cpp:314] Iteration 47700 (1.40525 iter/s, 71.1618s/100 iter), loss = 2.96089
I0324 08:07:19.009599  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.96258 (* 1 = 2.96258 loss)
I0324 08:07:19.009616  1493 sgd_solver.cpp:136] Iteration 47700, lr = 0.0001, m = 0.9
I0324 08:08:28.652622  1493 solver.cpp:314] Iteration 47800 (1.43594 iter/s, 69.641s/100 iter), loss = 3.00437
I0324 08:08:28.652722  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.82456 (* 1 = 2.82456 loss)
I0324 08:08:28.652740  1493 sgd_solver.cpp:136] Iteration 47800, lr = 0.0001, m = 0.9
I0324 08:09:37.009982  1493 solver.cpp:314] Iteration 47900 (1.46295 iter/s, 68.3551s/100 iter), loss = 3.08069
I0324 08:09:37.010143  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.44851 (* 1 = 3.44851 loss)
I0324 08:09:37.010175  1493 sgd_solver.cpp:136] Iteration 47900, lr = 0.0001, m = 0.9
I0324 08:10:45.285873  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_48000.caffemodel
I0324 08:10:45.337837  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_48000.solverstate
I0324 08:10:45.353183  1493 solver.cpp:678] Iteration 48000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.319582
j:  : 4 : max_pr:  : 0.508569
j:  : 3 : max_pr:  : 0.639059
j:  : 2 : max_pr:  : 0.75887
j:  : 1 : max_pr:  : 0.865917
j:  : 0 : max_pr:  : 1
I0324 08:11:36.528122  1494 solver.cpp:786] class AP 1: 0.372
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.147016
j:  : 7 : max_pr:  : 0.390298
j:  : 6 : max_pr:  : 0.506851
j:  : 5 : max_pr:  : 0.584337
j:  : 4 : max_pr:  : 0.671672
j:  : 3 : max_pr:  : 0.789705
j:  : 2 : max_pr:  : 0.988798
j:  : 1 : max_pr:  : 0.996725
j:  : 0 : max_pr:  : 1
I0324 08:11:36.601222  1494 solver.cpp:786] class AP 2: 0.552309
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.518559
j:  : 6 : max_pr:  : 0.652951
j:  : 5 : max_pr:  : 0.755558
j:  : 4 : max_pr:  : 0.861473
j:  : 3 : max_pr:  : 0.913532
j:  : 2 : max_pr:  : 0.963847
j:  : 1 : max_pr:  : 0.998648
j:  : 0 : max_pr:  : 1
I0324 08:11:36.614987  1494 solver.cpp:786] class AP 3: 0.60587
I0324 08:11:36.615008  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.51006
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.303622
j:  : 4 : max_pr:  : 0.47742
j:  : 3 : max_pr:  : 0.627168
j:  : 2 : max_pr:  : 0.755767
j:  : 1 : max_pr:  : 0.848715
j:  : 0 : max_pr:  : 1
I0324 08:11:36.767804  1493 solver.cpp:786] class AP 1: 0.36479
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.141884
j:  : 7 : max_pr:  : 0.399067
j:  : 6 : max_pr:  : 0.518634
j:  : 5 : max_pr:  : 0.607109
j:  : 4 : max_pr:  : 0.681587
j:  : 3 : max_pr:  : 0.798492
j:  : 2 : max_pr:  : 0.989875
j:  : 1 : max_pr:  : 0.998152
j:  : 0 : max_pr:  : 1
I0324 08:11:36.815198  1493 solver.cpp:786] class AP 2: 0.557709
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.520393
j:  : 6 : max_pr:  : 0.655156
j:  : 5 : max_pr:  : 0.749734
j:  : 4 : max_pr:  : 0.858775
j:  : 3 : max_pr:  : 0.913053
j:  : 2 : max_pr:  : 0.955917
j:  : 1 : max_pr:  : 0.998
j:  : 0 : max_pr:  : 1
I0324 08:11:36.825574  1493 solver.cpp:786] class AP 3: 0.604639
I0324 08:11:36.825588  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.509046
I0324 08:11:36.826038  1493 solver.cpp:265] [MultiGPU] Tests completed in 51.4712s
I0324 08:11:37.303663  1493 solver.cpp:314] Iteration 48000 (0.831326 iter/s, 120.29s/100 iter), loss = 3.05037
I0324 08:11:37.303714  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.61017 (* 1 = 4.61017 loss)
I0324 08:11:37.303728  1493 sgd_solver.cpp:136] Iteration 48000, lr = 0.0001, m = 0.9
I0324 08:12:45.937726  1493 solver.cpp:314] Iteration 48100 (1.45705 iter/s, 68.6318s/100 iter), loss = 3.2158
I0324 08:12:45.937826  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.42711 (* 1 = 4.42711 loss)
I0324 08:12:45.937844  1493 sgd_solver.cpp:136] Iteration 48100, lr = 0.0001, m = 0.9
I0324 08:13:55.932718  1493 solver.cpp:314] Iteration 48200 (1.42872 iter/s, 69.9927s/100 iter), loss = 3.1085
I0324 08:13:55.932832  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.90847 (* 1 = 2.90847 loss)
I0324 08:13:55.932849  1493 sgd_solver.cpp:136] Iteration 48200, lr = 0.0001, m = 0.9
I0324 08:15:05.714157  1493 solver.cpp:314] Iteration 48300 (1.43309 iter/s, 69.7792s/100 iter), loss = 2.96223
I0324 08:15:05.714648  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.47242 (* 1 = 2.47242 loss)
I0324 08:15:05.714965  1493 sgd_solver.cpp:136] Iteration 48300, lr = 0.0001, m = 0.9
I0324 08:16:15.229903  1493 solver.cpp:314] Iteration 48400 (1.43857 iter/s, 69.5135s/100 iter), loss = 3.02779
I0324 08:16:15.230000  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.88536 (* 1 = 2.88536 loss)
I0324 08:16:15.230015  1493 sgd_solver.cpp:136] Iteration 48400, lr = 0.0001, m = 0.9
I0324 08:17:24.878267  1493 solver.cpp:314] Iteration 48500 (1.43583 iter/s, 69.6461s/100 iter), loss = 3.04692
I0324 08:17:24.878449  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.6819 (* 1 = 3.6819 loss)
I0324 08:17:24.878468  1493 sgd_solver.cpp:136] Iteration 48500, lr = 0.0001, m = 0.9
I0324 08:18:33.962224  1493 solver.cpp:314] Iteration 48600 (1.44756 iter/s, 69.0817s/100 iter), loss = 3.19699
I0324 08:18:33.962337  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.55413 (* 1 = 2.55413 loss)
I0324 08:18:33.962352  1493 sgd_solver.cpp:136] Iteration 48600, lr = 0.0001, m = 0.9
I0324 08:19:42.437485  1493 solver.cpp:314] Iteration 48700 (1.46043 iter/s, 68.473s/100 iter), loss = 3.03198
I0324 08:19:42.439985  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.3487 (* 1 = 3.3487 loss)
I0324 08:19:42.440022  1493 sgd_solver.cpp:136] Iteration 48700, lr = 0.0001, m = 0.9
I0324 08:20:51.397435  1493 solver.cpp:314] Iteration 48800 (1.45016 iter/s, 68.9577s/100 iter), loss = 3.16773
I0324 08:20:51.397606  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.93014 (* 1 = 2.93014 loss)
I0324 08:20:51.397650  1493 sgd_solver.cpp:136] Iteration 48800, lr = 0.0001, m = 0.9
I0324 08:22:00.320960  1493 solver.cpp:314] Iteration 48900 (1.45093 iter/s, 68.9213s/100 iter), loss = 2.95943
I0324 08:22:00.321063  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.15924 (* 1 = 3.15924 loss)
I0324 08:22:00.321113  1493 sgd_solver.cpp:136] Iteration 48900, lr = 0.0001, m = 0.9
I0324 08:23:09.153996  1493 solver.cpp:314] Iteration 49000 (1.45284 iter/s, 68.8308s/100 iter), loss = 3.01083
I0324 08:23:09.154206  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.00913 (* 1 = 3.00913 loss)
I0324 08:23:09.154250  1493 sgd_solver.cpp:136] Iteration 49000, lr = 0.0001, m = 0.9
I0324 08:24:18.587268  1493 solver.cpp:314] Iteration 49100 (1.44028 iter/s, 69.431s/100 iter), loss = 2.92082
I0324 08:24:18.587440  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.49399 (* 1 = 2.49399 loss)
I0324 08:24:18.587458  1493 sgd_solver.cpp:136] Iteration 49100, lr = 0.0001, m = 0.9
I0324 08:25:27.421752  1493 solver.cpp:314] Iteration 49200 (1.45281 iter/s, 68.8322s/100 iter), loss = 2.91
I0324 08:25:27.421857  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.91904 (* 1 = 2.91904 loss)
I0324 08:25:27.421875  1493 sgd_solver.cpp:136] Iteration 49200, lr = 0.0001, m = 0.9
I0324 08:26:37.659121  1493 solver.cpp:314] Iteration 49300 (1.42379 iter/s, 70.2351s/100 iter), loss = 2.94176
I0324 08:26:37.659212  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.14731 (* 1 = 3.14731 loss)
I0324 08:26:37.659229  1493 sgd_solver.cpp:136] Iteration 49300, lr = 0.0001, m = 0.9
I0324 08:27:45.442374  1493 solver.cpp:314] Iteration 49400 (1.47534 iter/s, 67.781s/100 iter), loss = 3.1537
I0324 08:27:45.444113  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.56675 (* 1 = 2.56675 loss)
I0324 08:27:45.444145  1493 sgd_solver.cpp:136] Iteration 49400, lr = 0.0001, m = 0.9
I0324 08:28:53.792826  1493 solver.cpp:314] Iteration 49500 (1.4631 iter/s, 68.3482s/100 iter), loss = 3.19355
I0324 08:28:53.793004  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.55939 (* 1 = 3.55939 loss)
I0324 08:28:53.793020  1493 sgd_solver.cpp:136] Iteration 49500, lr = 0.0001, m = 0.9
I0324 08:30:02.876988  1493 solver.cpp:314] Iteration 49600 (1.44756 iter/s, 69.0819s/100 iter), loss = 3.12519
I0324 08:30:02.877101  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.39449 (* 1 = 3.39449 loss)
I0324 08:30:02.877120  1493 sgd_solver.cpp:136] Iteration 49600, lr = 0.0001, m = 0.9
I0324 08:31:12.009752  1493 solver.cpp:314] Iteration 49700 (1.44654 iter/s, 69.1305s/100 iter), loss = 3.39141
I0324 08:31:12.009920  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.81698 (* 1 = 4.81698 loss)
I0324 08:31:12.009966  1493 sgd_solver.cpp:136] Iteration 49700, lr = 0.0001, m = 0.9
I0324 08:32:21.401818  1493 solver.cpp:314] Iteration 49800 (1.44113 iter/s, 69.3898s/100 iter), loss = 3.09816
I0324 08:32:21.409768  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.29372 (* 1 = 3.29372 loss)
I0324 08:32:21.409796  1493 sgd_solver.cpp:136] Iteration 49800, lr = 0.0001, m = 0.9
I0324 08:33:29.666260  1493 solver.cpp:314] Iteration 49900 (1.46494 iter/s, 68.2622s/100 iter), loss = 2.93668
I0324 08:33:29.666352  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.3391 (* 1 = 3.3391 loss)
I0324 08:33:29.666368  1493 sgd_solver.cpp:136] Iteration 49900, lr = 0.0001, m = 0.9
I0324 08:34:37.389823  1493 solver.cpp:314] Iteration 49999 (1.46187 iter/s, 67.7213s/99 iter), loss = 3.0404
I0324 08:34:37.389987  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.23989 (* 1 = 3.23989 loss)
I0324 08:34:37.390035  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_50000.caffemodel
I0324 08:34:37.438530  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_50000.solverstate
I0324 08:34:37.773929  1493 solver.cpp:549] Iteration 50000, loss = 3.02993
I0324 08:34:37.785235  1493 solver.cpp:678] Iteration 50000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.309383
j:  : 4 : max_pr:  : 0.498191
j:  : 3 : max_pr:  : 0.638325
j:  : 2 : max_pr:  : 0.757312
j:  : 1 : max_pr:  : 0.867882
j:  : 0 : max_pr:  : 1
I0324 08:35:26.327373  1494 solver.cpp:786] class AP 1: 0.370099
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.101165
j:  : 7 : max_pr:  : 0.357718
j:  : 6 : max_pr:  : 0.499299
j:  : 5 : max_pr:  : 0.579162
j:  : 4 : max_pr:  : 0.655536
j:  : 3 : max_pr:  : 0.779148
j:  : 2 : max_pr:  : 0.984985
j:  : 1 : max_pr:  : 0.99645
j:  : 0 : max_pr:  : 1
I0324 08:35:26.376336  1494 solver.cpp:786] class AP 2: 0.541224
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.500856
j:  : 6 : max_pr:  : 0.649505
j:  : 5 : max_pr:  : 0.759966
j:  : 4 : max_pr:  : 0.86626
j:  : 3 : max_pr:  : 0.9174
j:  : 2 : max_pr:  : 0.962475
j:  : 1 : max_pr:  : 0.998629
j:  : 0 : max_pr:  : 1
I0324 08:35:26.387223  1494 solver.cpp:786] class AP 3: 0.605008
I0324 08:35:26.387264  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.505444
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.311504
j:  : 4 : max_pr:  : 0.493892
j:  : 3 : max_pr:  : 0.632183
j:  : 2 : max_pr:  : 0.760355
j:  : 1 : max_pr:  : 0.847928
j:  : 0 : max_pr:  : 1
I0324 08:35:27.543148  1493 solver.cpp:786] class AP 1: 0.367806
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.120761
j:  : 7 : max_pr:  : 0.373173
j:  : 6 : max_pr:  : 0.505518
j:  : 5 : max_pr:  : 0.589305
j:  : 4 : max_pr:  : 0.672946
j:  : 3 : max_pr:  : 0.787556
j:  : 2 : max_pr:  : 0.982429
j:  : 1 : max_pr:  : 0.998133
j:  : 0 : max_pr:  : 1
I0324 08:35:27.590461  1493 solver.cpp:786] class AP 2: 0.548166
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.530129
j:  : 6 : max_pr:  : 0.65901
j:  : 5 : max_pr:  : 0.755811
j:  : 4 : max_pr:  : 0.860656
j:  : 3 : max_pr:  : 0.914786
j:  : 2 : max_pr:  : 0.959427
j:  : 1 : max_pr:  : 0.998663
j:  : 0 : max_pr:  : 1
I0324 08:35:27.600972  1493 solver.cpp:786] class AP 3: 0.607135
I0324 08:35:27.600997  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.507702
I0324 08:35:27.626009  1439 parallel.cpp:71] Root Solver performance on device 0: 1.425 * 8 = 11.4 img/sec (50000 itr in 3.51e+04 sec)
I0324 08:35:27.626051  1439 parallel.cpp:76]      Solver performance on device 1: 1.425 * 8 = 11.4 img/sec (50000 itr in 3.51e+04 sec)
I0324 08:35:27.626061  1439 parallel.cpp:79] Overall multi-GPU performance: 22.7925 img/sec
I0324 08:35:28.166178  1439 caffe.cpp:253] Optimization Done in 9h 46m 53s
