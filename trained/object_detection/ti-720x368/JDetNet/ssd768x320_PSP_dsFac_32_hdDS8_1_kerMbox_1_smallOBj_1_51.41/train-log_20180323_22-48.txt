Logging output to training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/train-log_20180323_22-48.txt
training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial
{'type':'SGD','base_lr':1e-2,'max_iter':50000,'lr_policy':'multistep','power':1.0,'stepvalue':[30000,40000,300000],'weight_decay':0.0001}
{'config_name':'training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial','model_name':'ssdJacintoNetV2','dataset':'ti-vgg-720x368-v2','gpus':'0,1','train_data':'/user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb','test_data':'/user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_test_lmdb','name_size_file':'/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/test_name_size.txt','label_map_file':'/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/labelmap.prototxt','num_test_image':3609,'num_classes':4,'min_ratio':10,'max_ratio':90,
'log_space_steps':2,'use_difficult_gt':0,'ignore_difficult_gt':0,'evaluate_difficult_gt':1,'pretrain_model':'/user/a0875091/files/work/bitbucket_TI/caffe-jacinto-models/scripts/training/ti-vgg-720x368-v2/JDetNet/20180211_01-20_ds_PSP_dsFac_32_fc_0_hdDS8_1_cnctHD_0_baseNW3hd_0_kerMbox_1_1stHdSameOpCh_1/sparse_fac0.5_0.8_53.26/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_38000_53.26.caffemodel','use_image_list':0,'shuffle':0,'num_output':8,'resize_width':768,'resize_height':320,'crop_width':768,'crop_height':320,'batch_size':16,'aspect_ratios_type':1,'ssd_size':'512x512','small_objs':1,'min_dim':320,'concat_reg_head':0,'fully_conv_at_end':0,'first_hd_same_op_ch':1,'ker_mbox_loc_conf':1,'base_nw_3_head':0,'reg_head_at_ds8':1,'ds_fac':32,'ds_type':'PSP','rhead_name_non_linear':0,'force_color':0,'num_intermediate':512,'use_batchnorm_mbox':0}
caffe_root = :  /user/a0875091/files/work/bitbucket_TI/caffe-jacinto//build/tools/caffe.bin
config_param.ds_fac : 32
config_param.stride_list : [2, 2, 2, 2, 2]
min_dim = 320
ratio_step_size: 20
minsizes = [12.8, 32.0, 96.0, 160.0, 224.0, 288.0]
maxsizes = [32.0, 96.0, 160.0, 224.0, 288.0, 352.0]
ARs: [[2], [2, 3], [2, 3], [2, 3], [2], [2]]
training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/train.prototxt
training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/l1reg
{'type':'SGD','base_lr':1e-3,'max_iter':60000,'lr_policy':'multistep','power':1.0,'stepvalue':[30000,45000,300000],'regularization_type':'L1','weight_decay':1e-5}
{'config_name':'training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/l1reg','model_name':'ssdJacintoNetV2','dataset':'ti-vgg-720x368-v2','gpus':'0,1','train_data':'/user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb','test_data':'/user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_test_lmdb','name_size_file':'/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/test_name_size.txt','label_map_file':'/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/labelmap.prototxt','num_test_image':3609,'num_classes':4,'min_ratio':10,'max_ratio':90,
'log_space_steps':2,'use_difficult_gt':0,'ignore_difficult_gt':0,'evaluate_difficult_gt':1,'pretrain_model':'training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_50000.caffemodel','use_image_list':0,'shuffle':0,'num_output':8,'resize_width':768,'resize_height':320,'crop_width':768,'crop_height':320,'batch_size':16,'aspect_ratios_type':1,'ssd_size':'512x512','small_objs':1,'min_dim':320,'concat_reg_head':0,
'fully_conv_at_end':0,'first_hd_same_op_ch':1,'ker_mbox_loc_conf':1,'base_nw_3_head':0,'reg_head_at_ds8':1,'ds_fac':32,'ds_type':'PSP','rhead_name_non_linear':0,'force_color':0,'num_intermediate':512,'use_batchnorm_mbox':0}
caffe_root = :  /user/a0875091/files/work/bitbucket_TI/caffe-jacinto//build/tools/caffe.bin
config_param.ds_fac : 32
config_param.stride_list : [2, 2, 2, 2, 2]
min_dim = 320
ratio_step_size: 20
minsizes = [12.8, 32.0, 96.0, 160.0, 224.0, 288.0]
maxsizes = [32.0, 96.0, 160.0, 224.0, 288.0, 352.0]
ARs: [[2], [2, 3], [2, 3], [2, 3], [2], [2]]
training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/l1reg/train.prototxt
training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse
{'type':'SGD','base_lr':1e-2,'max_iter':60000,'lr_policy':'multistep','power':1.0,'stepvalue':[30000,45000,300000],'regularization_type':'L1','weight_decay':1e-5,'sparse_mode':1,'display_sparsity':2000,'sparsity_target':0.65,'sparsity_start_iter':0,'sparsity_start_factor':0.5,'sparsity_step_iter':2000,'sparsity_step_factor':0.05,'sparsity_itr_increment_bfr_applying':1,'sparsity_threshold_maxratio':0.2,'sparsity_threshold_value_max':0.2}
{'config_name':'training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse','model_name':'ssdJacintoNetV2','dataset':'ti-vgg-720x368-v2','gpus':'0','train_data':'/user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb','test_data':'/user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_test_lmdb','name_size_file':'/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/test_name_size.txt','label_map_file':'/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/labelmap.prototxt','num_test_image':3609,'num_classes':4,'min_ratio':10,'max_ratio':90,
'log_space_steps':2,'use_difficult_gt':0,'ignore_difficult_gt':0,'evaluate_difficult_gt':1,'pretrain_model':'training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_60000.caffemodel','use_image_list':0,'shuffle':0,'num_output':8,'resize_width':768,'resize_height':320,'crop_width':768,'crop_height':320,'batch_size':8,'aspect_ratios_type':1,'ssd_size':'512x512','small_objs':1,'min_dim':320,'concat_reg_head':0,
'fully_conv_at_end':0,'first_hd_same_op_ch':1,'ker_mbox_loc_conf':1,'base_nw_3_head':0,'reg_head_at_ds8':1,'ds_fac':32,'ds_type':'PSP','rhead_name_non_linear':0,'force_color':0,'num_intermediate':512,'use_batchnorm_mbox':0}
caffe_root = :  /user/a0875091/files/work/bitbucket_TI/caffe-jacinto//build/tools/caffe.bin
config_param.ds_fac : 32
config_param.stride_list : [2, 2, 2, 2, 2]
min_dim = 320
ratio_step_size: 20
minsizes = [12.8, 32.0, 96.0, 160.0, 224.0, 288.0]
maxsizes = [32.0, 96.0, 160.0, 224.0, 288.0, 352.0]
ARs: [[2], [2, 3], [2, 3], [2, 3], [2], [2]]
training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/train.prototxt
training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/test
{'type':'SGD','base_lr':1e-2,'max_iter':60000,'lr_policy':'multistep','power':1.0,'stepvalue':[30000,45000,300000],'regularization_type':'L1','weight_decay':1e-5,'sparse_mode':1,'display_sparsity':1000}
{'config_name':'training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/test','model_name':'ssdJacintoNetV2','dataset':'ti-vgg-720x368-v2','gpus':'0','train_data':'/user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb','test_data':'/user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_test_lmdb','name_size_file':'/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/test_name_size.txt','label_map_file':'/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/labelmap.prototxt','num_test_image':3609,'num_classes':4,'min_ratio':10,'max_ratio':90,
'log_space_steps':2,'use_difficult_gt':0,'ignore_difficult_gt':0,'evaluate_difficult_gt':1,'pretrain_model':'training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_60000.caffemodel','use_image_list':0,'shuffle':0,'num_output':8,'resize_width':768,'resize_height':320,'crop_width':768,'crop_height':320,'batch_size':8,'test_batch_size':10,'caffe_cmd':'test_detection','display_sparsity':1,'aspect_ratios_type':1,'ssd_size':'512x512','small_objs':1,'min_dim':320,'concat_reg_head':0,
'fully_conv_at_end':0,'first_hd_same_op_ch':1,'ker_mbox_loc_conf':1,'base_nw_3_head':0,'reg_head_at_ds8':1,'ds_fac':32,'ds_type':'PSP','rhead_name_non_linear':0,'force_color':0,'num_intermediate':512,'use_batchnorm_mbox':0}
caffe_root = :  /user/a0875091/files/work/bitbucket_TI/caffe-jacinto//build/tools/caffe.bin
config_param.ds_fac : 32
config_param.stride_list : [2, 2, 2, 2, 2]
min_dim = 320
ratio_step_size: 20
minsizes = [12.8, 32.0, 96.0, 160.0, 224.0, 288.0]
maxsizes = [32.0, 96.0, 160.0, 224.0, 288.0, 352.0]
ARs: [[2], [2, 3], [2, 3], [2, 3], [2], [2]]
training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/test/train.prototxt
training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/test_quantize
{'type':'SGD','base_lr':1e-2,'max_iter':60000,'lr_policy':'multistep','power':1.0,'stepvalue':[30000,45000,300000],'regularization_type':'L1','weight_decay':1e-5,'sparse_mode':1,'display_sparsity':1000}
{'config_name':'training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/test_quantize','model_name':'ssdJacintoNetV2','dataset':'ti-vgg-720x368-v2','gpus':'0','train_data':'/user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb','test_data':'/user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_test_lmdb','name_size_file':'/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/test_name_size.txt','label_map_file':'/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/labelmap.prototxt','num_test_image':3609,'num_classes':4,'min_ratio':10,'max_ratio':90,
'log_space_steps':2,'use_difficult_gt':0,'ignore_difficult_gt':0,'evaluate_difficult_gt':1,'pretrain_model':'training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/sparse/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_60000.caffemodel','use_image_list':0,'shuffle':0,'num_output':8,'resize_width':768,'resize_height':320,'crop_width':768,'crop_height':320,'batch_size':8,'test_batch_size':10,'caffe_cmd':'test_detection','aspect_ratios_type':1,'ssd_size':'512x512','small_objs':1,'min_dim':320,'concat_reg_head':0,
'fully_conv_at_end':0,'first_hd_same_op_ch':1,'ker_mbox_loc_conf':1,'base_nw_3_head':0,'reg_head_at_ds8':1,'ds_fac':32,'ds_type':'PSP','rhead_name_non_linear':0,'force_color':0,'num_intermediate':512,'use_batchnorm_mbox':0}
caffe_root = :  /user/a0875091/files/work/bitbucket_TI/caffe-jacinto//build/tools/caffe.bin
config_param.ds_fac : 32
config_param.stride_list : [2, 2, 2, 2, 2]
min_dim = 320
ratio_step_size: 20
minsizes = [12.8, 32.0, 96.0, 160.0, 224.0, 288.0]
maxsizes = [32.0, 96.0, 160.0, 224.0, 288.0, 352.0]
ARs: [[2], [2, 3], [2, 3], [2, 3], [2], [2]]
training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/test_quantize/train.prototxt
I0323 22:48:36.225579  1439 caffe.cpp:807] This is NVCaffe 0.16.4 started at Fri Mar 23 22:48:35 2018
I0323 22:48:36.225777  1439 caffe.cpp:810] CuDNN version: 6021
I0323 22:48:36.225785  1439 caffe.cpp:811] CuBLAS version: 8000
I0323 22:48:36.225790  1439 caffe.cpp:812] CUDA version: 8000
I0323 22:48:36.225795  1439 caffe.cpp:813] CUDA driver version: 8000
I0323 22:48:36.472690  1439 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0323 22:48:36.473331  1439 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8287879168, dev_info[0]: total=8506769408 free=8287879168
I0323 22:48:36.473907  1439 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8287879168, dev_info[1]: total=8508145664 free=8379236352
I0323 22:48:36.473925  1439 caffe.cpp:214] Using GPUs 0, 1
I0323 22:48:36.474248  1439 caffe.cpp:219] GPU 0: GeForce GTX 1080
I0323 22:48:36.474567  1439 caffe.cpp:219] GPU 1: GeForce GTX 1080
I0323 22:48:36.474620  1439 solver.cpp:43] Solver data type: FLOAT
I0323 22:48:36.474674  1439 solver.cpp:46] Initializing solver from parameters: 
train_net: "training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/train.prototxt"
test_net: "training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/test.prototxt"
test_iter: 452
test_interval: 2000
base_lr: 0.01
display: 100
max_iter: 50000
lr_policy: "multistep"
gamma: 0.1
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 2000
snapshot_prefix: "training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
snapshot_after_train: true
test_initialization: true
average_loss: 10
stepvalue: 30000
stepvalue: 40000
stepvalue: 300000
iter_size: 2
type: "SGD"
eval_type: "detection"
ap_version: "11point"
show_per_class_result: true
I0323 22:48:36.483230  1439 solver.cpp:78] Creating training net from train_net file: training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/train.prototxt
I0323 22:48:36.486196  1439 net.cpp:72] Initializing net from parameters: 
name: "ssdJacintoNetV2"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 0
    mean_value: 0
    mean_value: 0
    force_color: false
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 320
      width: 768
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: NEAREST
      interp_mode: CUBIC
      interp_mode: LANCZOS4
    }
    emit_constraint {
      emit_type: CENTER
    }
    crop_h: 320
    crop_w: 768
    distort_param {
      brightness_prob: 0.5
      brightness_delta: 32
      contrast_prob: 0.5
      contrast_lower: 0.5
      contrast_upper: 1.5
      hue_prob: 0.5
      hue_delta: 18
      saturation_prob: 0.5
      saturation_lower: 0.5
      saturation_upper: 1.5
      random_order_prob: 0
    }
    expand_param {
      prob: 0.5
      max_expand_ratio: 4
    }
  }
  data_param {
    source: "/user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb"
    batch_size: 8
    backend: LMDB
    threads: 4
    parser_threads: 4
  }
  annotated_data_param {
    batch_sampler {
      max_sample: 1
      max_trials: 1
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.1
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.3
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.5
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.7
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.9
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        max_jaccard_overlap: 1
      }
      max_sample: 1
      max_trials: 50
    }
    label_map_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/labelmap.prototxt"
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "pool6"
  top: "pool7"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool8"
  type: "Pooling"
  bottom: "pool7"
  top: "pool8"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool9"
  type: "Pooling"
  bottom: "pool8"
  top: "pool9"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "ctx_output1"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "ctx_output1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu"
  type: "ReLU"
  bottom: "ctx_output1"
  top: "ctx_output1"
}
layer {
  name: "ctx_output2"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "ctx_output2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu"
  type: "ReLU"
  bottom: "ctx_output2"
  top: "ctx_output2"
}
layer {
  name: "ctx_output3"
  type: "Convolution"
  bottom: "pool6"
  top: "ctx_output3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu"
  type: "ReLU"
  bottom: "ctx_output3"
  top: "ctx_output3"
}
layer {
  name: "ctx_output4"
  type: "Convolution"
  bottom: "pool7"
  top: "ctx_output4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu"
  type: "ReLU"
  bottom: "ctx_output4"
  top: "ctx_output4"
}
layer {
  name: "ctx_output5"
  type: "Convolution"
  bottom: "pool8"
  top: "ctx_output5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu"
  type: "ReLU"
  bottom: "ctx_output5"
  top: "ctx_output5"
}
layer {
  name: "ctx_output6"
  type: "Convolution"
  bottom: "pool9"
  top: "ctx_output6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu"
  type: "ReLU"
  bottom: "ctx_output6"
  top: "ctx_output6"
}
layer {
  name: "ctx_output1/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_loc"
  top: "ctx_output1/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_loc_perm"
  top: "ctx_output1/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_conf"
  top: "ctx_output1/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_conf_perm"
  top: "ctx_output1/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output1"
  bottom: "data"
  top: "ctx_output1/relu_mbox_priorbox"
  prior_box_param {
    min_size: 12.8
    max_size: 32
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_loc"
  top: "ctx_output2/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_loc_perm"
  top: "ctx_output2/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_conf"
  top: "ctx_output2/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_conf_perm"
  top: "ctx_output2/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output2"
  bottom: "data"
  top: "ctx_output2/relu_mbox_priorbox"
  prior_box_param {
    min_size: 32
    max_size: 96
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_loc"
  top: "ctx_output3/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_loc_perm"
  top: "ctx_output3/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_conf"
  top: "ctx_output3/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_conf_perm"
  top: "ctx_output3/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output3"
  bottom: "data"
  top: "ctx_output3/relu_mbox_priorbox"
  prior_box_param {
    min_size: 96
    max_size: 160
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_loc"
  top: "ctx_output4/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_loc_perm"
  top: "ctx_output4/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_conf"
  top: "ctx_output4/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_conf_perm"
  top: "ctx_output4/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output4"
  bottom: "data"
  top: "ctx_output4/relu_mbox_priorbox"
  prior_box_param {
    min_size: 160
    max_size: 224
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_loc"
  top: "ctx_output5/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_loc_perm"
  top: "ctx_output5/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_conf"
  top: "ctx_output5/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_conf_perm"
  top: "ctx_output5/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output5"
  bottom: "data"
  top: "ctx_output5/relu_mbox_priorbox"
  prior_box_param {
    min_size: 224
    max_size: 288
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_loc"
  top: "ctx_output6/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_loc_perm"
  top: "ctx_output6/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_conf"
  top: "ctx_output6/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_conf_perm"
  top: "ctx_output6/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output6"
  bottom: "data"
  top: "ctx_output6/relu_mbox_priorbox"
  prior_box_param {
    min_size: 288
    max_size: 352
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_loc_flat"
  bottom: "ctx_output2/relu_mbox_loc_flat"
  bottom: "ctx_output3/relu_mbox_loc_flat"
  bottom: "ctx_output4/relu_mbox_loc_flat"
  bottom: "ctx_output5/relu_mbox_loc_flat"
  bottom: "ctx_output6/relu_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_conf_flat"
  bottom: "ctx_output2/relu_mbox_conf_flat"
  bottom: "ctx_output3/relu_mbox_conf_flat"
  bottom: "ctx_output4/relu_mbox_conf_flat"
  bottom: "ctx_output5/relu_mbox_conf_flat"
  bottom: "ctx_output6/relu_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_priorbox"
  bottom: "ctx_output2/relu_mbox_priorbox"
  bottom: "ctx_output3/relu_mbox_priorbox"
  bottom: "ctx_output4/relu_mbox_priorbox"
  bottom: "ctx_output5/relu_mbox_priorbox"
  bottom: "ctx_output6/relu_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_loss"
  type: "MultiBoxLoss"
  bottom: "mbox_loc"
  bottom: "mbox_conf"
  bottom: "mbox_priorbox"
  bottom: "label"
  top: "mbox_loss"
  include {
    phase: TRAIN
  }
  propagate_down: true
  propagate_down: true
  propagate_down: false
  propagate_down: false
  loss_param {
    normalization: VALID
  }
  multibox_loss_param {
    loc_loss_type: SMOOTH_L1
    conf_loss_type: SOFTMAX
    loc_weight: 1
    num_classes: 4
    share_location: true
    match_type: PER_PREDICTION
    overlap_threshold: 0.5
    use_prior_for_matching: true
    background_label_id: 0
    use_difficult_gt: false
    neg_pos_ratio: 3
    neg_overlap: 0.5
    code_type: CENTER_SIZE
    ignore_cross_boundary_bbox: false
    mining_type: MAX_NEGATIVE
    ignore_difficult_gt: false
  }
}
I0323 22:48:36.486711  1439 net.cpp:104] Using FLOAT as default forward math type
I0323 22:48:36.486723  1439 net.cpp:110] Using FLOAT as default backward math type
I0323 22:48:36.486733  1439 layer_factory.hpp:136] Creating layer 'data' of type 'AnnotatedData'
I0323 22:48:36.486740  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.486843  1439 net.cpp:184] Created Layer data (0)
I0323 22:48:36.486855  1439 net.cpp:530] data -> data
I0323 22:48:36.486881  1439 net.cpp:530] data -> label
I0323 22:48:36.486940  1439 data_reader.cpp:58] Data Reader threads: 4, out queues: 16, depth: 8
I0323 22:48:36.486995  1439 internal_thread.cpp:19] Starting 4 internal thread(s) on device 0
I0323 22:48:36.488067  1464 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0323 22:48:36.488637  1462 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0323 22:48:36.489271  1463 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0323 22:48:36.490625  1465 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0323 22:48:36.501452  1439 annotated_data_layer.cpp:219] output data size: 8,3,320,768
I0323 22:48:36.501797  1439 annotated_data_layer.cpp:265] [0] Output data size: 8, 3, 320, 768
I0323 22:48:36.501883  1439 internal_thread.cpp:19] Starting 4 internal thread(s) on device 0
I0323 22:48:36.502395  1439 net.cpp:245] Setting up data
I0323 22:48:36.502440  1439 net.cpp:252] TRAIN Top shape for layer 0 'data' 8 3 320 768 (5898240)
I0323 22:48:36.502470  1439 net.cpp:252] TRAIN Top shape for layer 0 'data' 1 1 10 8 (80)
I0323 22:48:36.502492  1439 layer_factory.hpp:136] Creating layer 'data_data_0_split' of type 'Split'
I0323 22:48:36.502512  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.502542  1439 net.cpp:184] Created Layer data_data_0_split (1)
I0323 22:48:36.502558  1439 net.cpp:561] data_data_0_split <- data
I0323 22:48:36.502584  1439 net.cpp:530] data_data_0_split -> data_data_0_split_0
I0323 22:48:36.502607  1439 net.cpp:530] data_data_0_split -> data_data_0_split_1
I0323 22:48:36.502627  1439 net.cpp:530] data_data_0_split -> data_data_0_split_2
I0323 22:48:36.502645  1439 net.cpp:530] data_data_0_split -> data_data_0_split_3
I0323 22:48:36.502661  1439 net.cpp:530] data_data_0_split -> data_data_0_split_4
I0323 22:48:36.502679  1439 net.cpp:530] data_data_0_split -> data_data_0_split_5
I0323 22:48:36.502694  1439 net.cpp:530] data_data_0_split -> data_data_0_split_6
I0323 22:48:36.502969  1439 net.cpp:245] Setting up data_data_0_split
I0323 22:48:36.502990  1439 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0323 22:48:36.503001  1439 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0323 22:48:36.503013  1439 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0323 22:48:36.503024  1439 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0323 22:48:36.503036  1439 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0323 22:48:36.503047  1439 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0323 22:48:36.503058  1439 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0323 22:48:36.503068  1439 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0323 22:48:36.503078  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.503103  1439 net.cpp:184] Created Layer data/bias (2)
I0323 22:48:36.503114  1439 net.cpp:561] data/bias <- data_data_0_split_0
I0323 22:48:36.503125  1439 net.cpp:530] data/bias -> data/bias
I0323 22:48:36.506296  1439 net.cpp:245] Setting up data/bias
I0323 22:48:36.506335  1439 net.cpp:252] TRAIN Top shape for layer 2 'data/bias' 8 3 320 768 (5898240)
I0323 22:48:36.506371  1439 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0323 22:48:36.506386  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.506428  1439 net.cpp:184] Created Layer conv1a (3)
I0323 22:48:36.506439  1439 net.cpp:561] conv1a <- data/bias
I0323 22:48:36.506451  1439 net.cpp:530] conv1a -> conv1a
I0323 22:48:36.969373  1439 net.cpp:245] Setting up conv1a
I0323 22:48:36.969411  1439 net.cpp:252] TRAIN Top shape for layer 3 'conv1a' 8 32 160 384 (15728640)
I0323 22:48:36.969432  1439 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0323 22:48:36.969440  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.969465  1439 net.cpp:184] Created Layer conv1a/bn (4)
I0323 22:48:36.969493  1439 net.cpp:561] conv1a/bn <- conv1a
I0323 22:48:36.969509  1439 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0323 22:48:36.970440  1439 net.cpp:245] Setting up conv1a/bn
I0323 22:48:36.970456  1439 net.cpp:252] TRAIN Top shape for layer 4 'conv1a/bn' 8 32 160 384 (15728640)
I0323 22:48:36.970475  1439 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0323 22:48:36.970484  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.970492  1439 net.cpp:184] Created Layer conv1a/relu (5)
I0323 22:48:36.970499  1439 net.cpp:561] conv1a/relu <- conv1a
I0323 22:48:36.970505  1439 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0323 22:48:36.970521  1439 net.cpp:245] Setting up conv1a/relu
I0323 22:48:36.970531  1439 net.cpp:252] TRAIN Top shape for layer 5 'conv1a/relu' 8 32 160 384 (15728640)
I0323 22:48:36.970538  1439 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0323 22:48:36.970544  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.970561  1439 net.cpp:184] Created Layer conv1b (6)
I0323 22:48:36.970568  1439 net.cpp:561] conv1b <- conv1a
I0323 22:48:36.970574  1439 net.cpp:530] conv1b -> conv1b
I0323 22:48:36.972215  1439 net.cpp:245] Setting up conv1b
I0323 22:48:36.972231  1439 net.cpp:252] TRAIN Top shape for layer 6 'conv1b' 8 32 160 384 (15728640)
I0323 22:48:36.972247  1439 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0323 22:48:36.972254  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.972265  1439 net.cpp:184] Created Layer conv1b/bn (7)
I0323 22:48:36.972270  1439 net.cpp:561] conv1b/bn <- conv1b
I0323 22:48:36.972277  1439 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0323 22:48:36.973145  1439 net.cpp:245] Setting up conv1b/bn
I0323 22:48:36.973160  1439 net.cpp:252] TRAIN Top shape for layer 7 'conv1b/bn' 8 32 160 384 (15728640)
I0323 22:48:36.973176  1439 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0323 22:48:36.973183  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.973191  1439 net.cpp:184] Created Layer conv1b/relu (8)
I0323 22:48:36.973197  1439 net.cpp:561] conv1b/relu <- conv1b
I0323 22:48:36.973203  1439 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0323 22:48:36.973212  1439 net.cpp:245] Setting up conv1b/relu
I0323 22:48:36.973218  1439 net.cpp:252] TRAIN Top shape for layer 8 'conv1b/relu' 8 32 160 384 (15728640)
I0323 22:48:36.973224  1439 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0323 22:48:36.973230  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.973242  1439 net.cpp:184] Created Layer pool1 (9)
I0323 22:48:36.973251  1439 net.cpp:561] pool1 <- conv1b
I0323 22:48:36.973258  1439 net.cpp:530] pool1 -> pool1
I0323 22:48:36.973362  1439 net.cpp:245] Setting up pool1
I0323 22:48:36.973376  1439 net.cpp:252] TRAIN Top shape for layer 9 'pool1' 8 32 80 192 (3932160)
I0323 22:48:36.973383  1439 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0323 22:48:36.973389  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.973402  1439 net.cpp:184] Created Layer res2a_branch2a (10)
I0323 22:48:36.973408  1439 net.cpp:561] res2a_branch2a <- pool1
I0323 22:48:36.973414  1439 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0323 22:48:36.975458  1439 net.cpp:245] Setting up res2a_branch2a
I0323 22:48:36.975477  1439 net.cpp:252] TRAIN Top shape for layer 10 'res2a_branch2a' 8 64 80 192 (7864320)
I0323 22:48:36.975493  1439 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0323 22:48:36.975500  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.975512  1439 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0323 22:48:36.975528  1439 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0323 22:48:36.975535  1439 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0323 22:48:36.977026  1439 net.cpp:245] Setting up res2a_branch2a/bn
I0323 22:48:36.977042  1439 net.cpp:252] TRAIN Top shape for layer 11 'res2a_branch2a/bn' 8 64 80 192 (7864320)
I0323 22:48:36.977061  1439 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0323 22:48:36.977069  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.977077  1439 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0323 22:48:36.977082  1439 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0323 22:48:36.977088  1439 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0323 22:48:36.977097  1439 net.cpp:245] Setting up res2a_branch2a/relu
I0323 22:48:36.977110  1439 net.cpp:252] TRAIN Top shape for layer 12 'res2a_branch2a/relu' 8 64 80 192 (7864320)
I0323 22:48:36.977116  1439 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0323 22:48:36.977121  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.977138  1439 net.cpp:184] Created Layer res2a_branch2b (13)
I0323 22:48:36.977145  1439 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0323 22:48:36.977152  1439 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0323 22:48:36.978955  1439 net.cpp:245] Setting up res2a_branch2b
I0323 22:48:36.978974  1439 net.cpp:252] TRAIN Top shape for layer 13 'res2a_branch2b' 8 64 80 192 (7864320)
I0323 22:48:36.978989  1439 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0323 22:48:36.978996  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.979007  1439 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0323 22:48:36.979014  1439 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0323 22:48:36.979022  1439 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0323 22:48:36.979959  1439 net.cpp:245] Setting up res2a_branch2b/bn
I0323 22:48:36.979974  1439 net.cpp:252] TRAIN Top shape for layer 14 'res2a_branch2b/bn' 8 64 80 192 (7864320)
I0323 22:48:36.979990  1439 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0323 22:48:36.979997  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.980005  1439 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0323 22:48:36.980010  1439 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0323 22:48:36.980016  1439 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0323 22:48:36.980024  1439 net.cpp:245] Setting up res2a_branch2b/relu
I0323 22:48:36.980036  1439 net.cpp:252] TRAIN Top shape for layer 15 'res2a_branch2b/relu' 8 64 80 192 (7864320)
I0323 22:48:36.980041  1439 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0323 22:48:36.980047  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.980062  1439 net.cpp:184] Created Layer pool2 (16)
I0323 22:48:36.980069  1439 net.cpp:561] pool2 <- res2a_branch2b
I0323 22:48:36.980075  1439 net.cpp:530] pool2 -> pool2
I0323 22:48:36.980172  1439 net.cpp:245] Setting up pool2
I0323 22:48:36.980186  1439 net.cpp:252] TRAIN Top shape for layer 16 'pool2' 8 64 40 96 (1966080)
I0323 22:48:36.980192  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0323 22:48:36.980198  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.980214  1439 net.cpp:184] Created Layer res3a_branch2a (17)
I0323 22:48:36.980221  1439 net.cpp:561] res3a_branch2a <- pool2
I0323 22:48:36.980227  1439 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0323 22:48:36.983559  1439 net.cpp:245] Setting up res3a_branch2a
I0323 22:48:36.983580  1439 net.cpp:252] TRAIN Top shape for layer 17 'res3a_branch2a' 8 128 40 96 (3932160)
I0323 22:48:36.983606  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0323 22:48:36.983613  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.983626  1439 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0323 22:48:36.983633  1439 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0323 22:48:36.983639  1439 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0323 22:48:36.984562  1439 net.cpp:245] Setting up res3a_branch2a/bn
I0323 22:48:36.984577  1439 net.cpp:252] TRAIN Top shape for layer 18 'res3a_branch2a/bn' 8 128 40 96 (3932160)
I0323 22:48:36.984599  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0323 22:48:36.984607  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.984616  1439 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0323 22:48:36.984621  1439 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0323 22:48:36.984627  1439 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0323 22:48:36.984637  1439 net.cpp:245] Setting up res3a_branch2a/relu
I0323 22:48:36.984645  1439 net.cpp:252] TRAIN Top shape for layer 19 'res3a_branch2a/relu' 8 128 40 96 (3932160)
I0323 22:48:36.984650  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0323 22:48:36.984658  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.984675  1439 net.cpp:184] Created Layer res3a_branch2b (20)
I0323 22:48:36.984683  1439 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0323 22:48:36.984689  1439 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0323 22:48:36.986270  1439 net.cpp:245] Setting up res3a_branch2b
I0323 22:48:36.986285  1439 net.cpp:252] TRAIN Top shape for layer 20 'res3a_branch2b' 8 128 40 96 (3932160)
I0323 22:48:36.986299  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0323 22:48:36.986305  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.986318  1439 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0323 22:48:36.986325  1439 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0323 22:48:36.986331  1439 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0323 22:48:36.987254  1439 net.cpp:245] Setting up res3a_branch2b/bn
I0323 22:48:36.987270  1439 net.cpp:252] TRAIN Top shape for layer 21 'res3a_branch2b/bn' 8 128 40 96 (3932160)
I0323 22:48:36.987287  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0323 22:48:36.987293  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.987300  1439 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0323 22:48:36.987306  1439 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0323 22:48:36.987314  1439 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0323 22:48:36.987323  1439 net.cpp:245] Setting up res3a_branch2b/relu
I0323 22:48:36.987329  1439 net.cpp:252] TRAIN Top shape for layer 22 'res3a_branch2b/relu' 8 128 40 96 (3932160)
I0323 22:48:36.987335  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0323 22:48:36.987341  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.987352  1439 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (23)
I0323 22:48:36.987360  1439 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0323 22:48:36.987365  1439 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0323 22:48:36.987375  1439 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0323 22:48:36.987448  1439 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0323 22:48:36.987463  1439 net.cpp:252] TRAIN Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 8 128 40 96 (3932160)
I0323 22:48:36.987480  1439 net.cpp:252] TRAIN Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 8 128 40 96 (3932160)
I0323 22:48:36.987488  1439 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0323 22:48:36.987493  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.987502  1439 net.cpp:184] Created Layer pool3 (24)
I0323 22:48:36.987509  1439 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0323 22:48:36.987514  1439 net.cpp:530] pool3 -> pool3
I0323 22:48:36.987612  1439 net.cpp:245] Setting up pool3
I0323 22:48:36.987625  1439 net.cpp:252] TRAIN Top shape for layer 24 'pool3' 8 128 20 48 (983040)
I0323 22:48:36.987632  1439 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0323 22:48:36.987637  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.987653  1439 net.cpp:184] Created Layer res4a_branch2a (25)
I0323 22:48:36.987659  1439 net.cpp:561] res4a_branch2a <- pool3
I0323 22:48:36.987665  1439 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0323 22:48:36.997952  1439 net.cpp:245] Setting up res4a_branch2a
I0323 22:48:36.997972  1439 net.cpp:252] TRAIN Top shape for layer 25 'res4a_branch2a' 8 256 20 48 (1966080)
I0323 22:48:36.997983  1439 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0323 22:48:36.997989  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.998004  1439 net.cpp:184] Created Layer res4a_branch2a/bn (26)
I0323 22:48:36.998013  1439 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0323 22:48:36.998019  1439 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0323 22:48:36.998970  1439 net.cpp:245] Setting up res4a_branch2a/bn
I0323 22:48:36.998986  1439 net.cpp:252] TRAIN Top shape for layer 26 'res4a_branch2a/bn' 8 256 20 48 (1966080)
I0323 22:48:36.999001  1439 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0323 22:48:36.999007  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.999017  1439 net.cpp:184] Created Layer res4a_branch2a/relu (27)
I0323 22:48:36.999022  1439 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0323 22:48:36.999028  1439 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0323 22:48:36.999037  1439 net.cpp:245] Setting up res4a_branch2a/relu
I0323 22:48:36.999045  1439 net.cpp:252] TRAIN Top shape for layer 27 'res4a_branch2a/relu' 8 256 20 48 (1966080)
I0323 22:48:36.999052  1439 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0323 22:48:36.999058  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:36.999078  1439 net.cpp:184] Created Layer res4a_branch2b (28)
I0323 22:48:36.999085  1439 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0323 22:48:36.999091  1439 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0323 22:48:37.004145  1439 net.cpp:245] Setting up res4a_branch2b
I0323 22:48:37.004170  1439 net.cpp:252] TRAIN Top shape for layer 28 'res4a_branch2b' 8 256 20 48 (1966080)
I0323 22:48:37.004182  1439 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0323 22:48:37.004189  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.004204  1439 net.cpp:184] Created Layer res4a_branch2b/bn (29)
I0323 22:48:37.004211  1439 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0323 22:48:37.004218  1439 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0323 22:48:37.005167  1439 net.cpp:245] Setting up res4a_branch2b/bn
I0323 22:48:37.005182  1439 net.cpp:252] TRAIN Top shape for layer 29 'res4a_branch2b/bn' 8 256 20 48 (1966080)
I0323 22:48:37.005195  1439 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0323 22:48:37.005218  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.005226  1439 net.cpp:184] Created Layer res4a_branch2b/relu (30)
I0323 22:48:37.005233  1439 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0323 22:48:37.005240  1439 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0323 22:48:37.005249  1439 net.cpp:245] Setting up res4a_branch2b/relu
I0323 22:48:37.005259  1439 net.cpp:252] TRAIN Top shape for layer 30 'res4a_branch2b/relu' 8 256 20 48 (1966080)
I0323 22:48:37.005265  1439 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0323 22:48:37.005272  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.005285  1439 net.cpp:184] Created Layer pool4 (31)
I0323 22:48:37.005291  1439 net.cpp:561] pool4 <- res4a_branch2b
I0323 22:48:37.005298  1439 net.cpp:530] pool4 -> pool4
I0323 22:48:37.005398  1439 net.cpp:245] Setting up pool4
I0323 22:48:37.005411  1439 net.cpp:252] TRAIN Top shape for layer 31 'pool4' 8 256 10 24 (491520)
I0323 22:48:37.005419  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0323 22:48:37.005424  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.005445  1439 net.cpp:184] Created Layer res5a_branch2a (32)
I0323 22:48:37.005452  1439 net.cpp:561] res5a_branch2a <- pool4
I0323 22:48:37.005460  1439 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0323 22:48:37.044706  1439 net.cpp:245] Setting up res5a_branch2a
I0323 22:48:37.044737  1439 net.cpp:252] TRAIN Top shape for layer 32 'res5a_branch2a' 8 512 10 24 (983040)
I0323 22:48:37.044755  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0323 22:48:37.044764  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.044780  1439 net.cpp:184] Created Layer res5a_branch2a/bn (33)
I0323 22:48:37.044788  1439 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0323 22:48:37.044796  1439 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0323 22:48:37.045740  1439 net.cpp:245] Setting up res5a_branch2a/bn
I0323 22:48:37.045756  1439 net.cpp:252] TRAIN Top shape for layer 33 'res5a_branch2a/bn' 8 512 10 24 (983040)
I0323 22:48:37.045770  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0323 22:48:37.045778  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.045788  1439 net.cpp:184] Created Layer res5a_branch2a/relu (34)
I0323 22:48:37.045794  1439 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0323 22:48:37.045799  1439 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0323 22:48:37.045809  1439 net.cpp:245] Setting up res5a_branch2a/relu
I0323 22:48:37.045815  1439 net.cpp:252] TRAIN Top shape for layer 34 'res5a_branch2a/relu' 8 512 10 24 (983040)
I0323 22:48:37.045821  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0323 22:48:37.045835  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.045857  1439 net.cpp:184] Created Layer res5a_branch2b (35)
I0323 22:48:37.045866  1439 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0323 22:48:37.045872  1439 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0323 22:48:37.065218  1439 net.cpp:245] Setting up res5a_branch2b
I0323 22:48:37.065250  1439 net.cpp:252] TRAIN Top shape for layer 35 'res5a_branch2b' 8 512 10 24 (983040)
I0323 22:48:37.065273  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0323 22:48:37.065282  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.065301  1439 net.cpp:184] Created Layer res5a_branch2b/bn (36)
I0323 22:48:37.065310  1439 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0323 22:48:37.065318  1439 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0323 22:48:37.066318  1439 net.cpp:245] Setting up res5a_branch2b/bn
I0323 22:48:37.066334  1439 net.cpp:252] TRAIN Top shape for layer 36 'res5a_branch2b/bn' 8 512 10 24 (983040)
I0323 22:48:37.066347  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0323 22:48:37.066354  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.066365  1439 net.cpp:184] Created Layer res5a_branch2b/relu (37)
I0323 22:48:37.066370  1439 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0323 22:48:37.066380  1439 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0323 22:48:37.066390  1439 net.cpp:245] Setting up res5a_branch2b/relu
I0323 22:48:37.066401  1439 net.cpp:252] TRAIN Top shape for layer 37 'res5a_branch2b/relu' 8 512 10 24 (983040)
I0323 22:48:37.066412  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2b_res5a_branch2b/relu_0_split' of type 'Split'
I0323 22:48:37.066418  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.066424  1439 net.cpp:184] Created Layer res5a_branch2b_res5a_branch2b/relu_0_split (38)
I0323 22:48:37.066431  1439 net.cpp:561] res5a_branch2b_res5a_branch2b/relu_0_split <- res5a_branch2b
I0323 22:48:37.066437  1439 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_0
I0323 22:48:37.066445  1439 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_1
I0323 22:48:37.066520  1439 net.cpp:245] Setting up res5a_branch2b_res5a_branch2b/relu_0_split
I0323 22:48:37.066534  1439 net.cpp:252] TRAIN Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 8 512 10 24 (983040)
I0323 22:48:37.066541  1439 net.cpp:252] TRAIN Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 8 512 10 24 (983040)
I0323 22:48:37.066548  1439 layer_factory.hpp:136] Creating layer 'pool6' of type 'Pooling'
I0323 22:48:37.066555  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.066567  1439 net.cpp:184] Created Layer pool6 (39)
I0323 22:48:37.066576  1439 net.cpp:561] pool6 <- res5a_branch2b_res5a_branch2b/relu_0_split_0
I0323 22:48:37.066582  1439 net.cpp:530] pool6 -> pool6
I0323 22:48:37.066684  1439 net.cpp:245] Setting up pool6
I0323 22:48:37.066697  1439 net.cpp:252] TRAIN Top shape for layer 39 'pool6' 8 512 5 12 (245760)
I0323 22:48:37.066706  1439 layer_factory.hpp:136] Creating layer 'pool6_pool6_0_split' of type 'Split'
I0323 22:48:37.066712  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.066721  1439 net.cpp:184] Created Layer pool6_pool6_0_split (40)
I0323 22:48:37.066728  1439 net.cpp:561] pool6_pool6_0_split <- pool6
I0323 22:48:37.066735  1439 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_0
I0323 22:48:37.066743  1439 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_1
I0323 22:48:37.066808  1439 net.cpp:245] Setting up pool6_pool6_0_split
I0323 22:48:37.066821  1439 net.cpp:252] TRAIN Top shape for layer 40 'pool6_pool6_0_split' 8 512 5 12 (245760)
I0323 22:48:37.066830  1439 net.cpp:252] TRAIN Top shape for layer 40 'pool6_pool6_0_split' 8 512 5 12 (245760)
I0323 22:48:37.066838  1439 layer_factory.hpp:136] Creating layer 'pool7' of type 'Pooling'
I0323 22:48:37.066844  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.066855  1439 net.cpp:184] Created Layer pool7 (41)
I0323 22:48:37.066864  1439 net.cpp:561] pool7 <- pool6_pool6_0_split_0
I0323 22:48:37.066870  1439 net.cpp:530] pool7 -> pool7
I0323 22:48:37.066962  1439 net.cpp:245] Setting up pool7
I0323 22:48:37.066975  1439 net.cpp:252] TRAIN Top shape for layer 41 'pool7' 8 512 3 6 (73728)
I0323 22:48:37.066982  1439 layer_factory.hpp:136] Creating layer 'pool7_pool7_0_split' of type 'Split'
I0323 22:48:37.066988  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.067006  1439 net.cpp:184] Created Layer pool7_pool7_0_split (42)
I0323 22:48:37.067014  1439 net.cpp:561] pool7_pool7_0_split <- pool7
I0323 22:48:37.067023  1439 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_0
I0323 22:48:37.067034  1439 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_1
I0323 22:48:37.067101  1439 net.cpp:245] Setting up pool7_pool7_0_split
I0323 22:48:37.067114  1439 net.cpp:252] TRAIN Top shape for layer 42 'pool7_pool7_0_split' 8 512 3 6 (73728)
I0323 22:48:37.067122  1439 net.cpp:252] TRAIN Top shape for layer 42 'pool7_pool7_0_split' 8 512 3 6 (73728)
I0323 22:48:37.067129  1439 layer_factory.hpp:136] Creating layer 'pool8' of type 'Pooling'
I0323 22:48:37.067137  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.067149  1439 net.cpp:184] Created Layer pool8 (43)
I0323 22:48:37.067157  1439 net.cpp:561] pool8 <- pool7_pool7_0_split_0
I0323 22:48:37.067165  1439 net.cpp:530] pool8 -> pool8
I0323 22:48:37.067260  1439 net.cpp:245] Setting up pool8
I0323 22:48:37.067272  1439 net.cpp:252] TRAIN Top shape for layer 43 'pool8' 8 512 2 3 (24576)
I0323 22:48:37.067279  1439 layer_factory.hpp:136] Creating layer 'pool8_pool8_0_split' of type 'Split'
I0323 22:48:37.067286  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.067299  1439 net.cpp:184] Created Layer pool8_pool8_0_split (44)
I0323 22:48:37.067306  1439 net.cpp:561] pool8_pool8_0_split <- pool8
I0323 22:48:37.067314  1439 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_0
I0323 22:48:37.067322  1439 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_1
I0323 22:48:37.067389  1439 net.cpp:245] Setting up pool8_pool8_0_split
I0323 22:48:37.067401  1439 net.cpp:252] TRAIN Top shape for layer 44 'pool8_pool8_0_split' 8 512 2 3 (24576)
I0323 22:48:37.067409  1439 net.cpp:252] TRAIN Top shape for layer 44 'pool8_pool8_0_split' 8 512 2 3 (24576)
I0323 22:48:37.067415  1439 layer_factory.hpp:136] Creating layer 'pool9' of type 'Pooling'
I0323 22:48:37.067422  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.067432  1439 net.cpp:184] Created Layer pool9 (45)
I0323 22:48:37.067440  1439 net.cpp:561] pool9 <- pool8_pool8_0_split_0
I0323 22:48:37.067448  1439 net.cpp:530] pool9 -> pool9
I0323 22:48:37.067541  1439 net.cpp:245] Setting up pool9
I0323 22:48:37.067554  1439 net.cpp:252] TRAIN Top shape for layer 45 'pool9' 8 512 1 2 (8192)
I0323 22:48:37.067561  1439 layer_factory.hpp:136] Creating layer 'ctx_output1' of type 'Convolution'
I0323 22:48:37.067569  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.067589  1439 net.cpp:184] Created Layer ctx_output1 (46)
I0323 22:48:37.067598  1439 net.cpp:561] ctx_output1 <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0323 22:48:37.067606  1439 net.cpp:530] ctx_output1 -> ctx_output1
I0323 22:48:37.069097  1439 net.cpp:245] Setting up ctx_output1
I0323 22:48:37.069113  1439 net.cpp:252] TRAIN Top shape for layer 46 'ctx_output1' 8 256 40 96 (7864320)
I0323 22:48:37.069123  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu' of type 'ReLU'
I0323 22:48:37.069129  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.069139  1439 net.cpp:184] Created Layer ctx_output1/relu (47)
I0323 22:48:37.069145  1439 net.cpp:561] ctx_output1/relu <- ctx_output1
I0323 22:48:37.069151  1439 net.cpp:513] ctx_output1/relu -> ctx_output1 (in-place)
I0323 22:48:37.069161  1439 net.cpp:245] Setting up ctx_output1/relu
I0323 22:48:37.069172  1439 net.cpp:252] TRAIN Top shape for layer 47 'ctx_output1/relu' 8 256 40 96 (7864320)
I0323 22:48:37.069178  1439 layer_factory.hpp:136] Creating layer 'ctx_output1_ctx_output1/relu_0_split' of type 'Split'
I0323 22:48:37.069183  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.069190  1439 net.cpp:184] Created Layer ctx_output1_ctx_output1/relu_0_split (48)
I0323 22:48:37.069206  1439 net.cpp:561] ctx_output1_ctx_output1/relu_0_split <- ctx_output1
I0323 22:48:37.069213  1439 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_0
I0323 22:48:37.069221  1439 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_1
I0323 22:48:37.069231  1439 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_2
I0323 22:48:37.069329  1439 net.cpp:245] Setting up ctx_output1_ctx_output1/relu_0_split
I0323 22:48:37.069341  1439 net.cpp:252] TRAIN Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 8 256 40 96 (7864320)
I0323 22:48:37.069348  1439 net.cpp:252] TRAIN Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 8 256 40 96 (7864320)
I0323 22:48:37.069356  1439 net.cpp:252] TRAIN Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 8 256 40 96 (7864320)
I0323 22:48:37.069363  1439 layer_factory.hpp:136] Creating layer 'ctx_output2' of type 'Convolution'
I0323 22:48:37.069371  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.069389  1439 net.cpp:184] Created Layer ctx_output2 (49)
I0323 22:48:37.069398  1439 net.cpp:561] ctx_output2 <- res5a_branch2b_res5a_branch2b/relu_0_split_1
I0323 22:48:37.069406  1439 net.cpp:530] ctx_output2 -> ctx_output2
I0323 22:48:37.074061  1439 net.cpp:245] Setting up ctx_output2
I0323 22:48:37.074090  1439 net.cpp:252] TRAIN Top shape for layer 49 'ctx_output2' 8 256 10 24 (491520)
I0323 22:48:37.074107  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu' of type 'ReLU'
I0323 22:48:37.074115  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.074126  1439 net.cpp:184] Created Layer ctx_output2/relu (50)
I0323 22:48:37.074133  1439 net.cpp:561] ctx_output2/relu <- ctx_output2
I0323 22:48:37.074141  1439 net.cpp:513] ctx_output2/relu -> ctx_output2 (in-place)
I0323 22:48:37.074151  1439 net.cpp:245] Setting up ctx_output2/relu
I0323 22:48:37.074159  1439 net.cpp:252] TRAIN Top shape for layer 50 'ctx_output2/relu' 8 256 10 24 (491520)
I0323 22:48:37.074167  1439 layer_factory.hpp:136] Creating layer 'ctx_output2_ctx_output2/relu_0_split' of type 'Split'
I0323 22:48:37.074173  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.074188  1439 net.cpp:184] Created Layer ctx_output2_ctx_output2/relu_0_split (51)
I0323 22:48:37.074196  1439 net.cpp:561] ctx_output2_ctx_output2/relu_0_split <- ctx_output2
I0323 22:48:37.074203  1439 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_0
I0323 22:48:37.074211  1439 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_1
I0323 22:48:37.074219  1439 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_2
I0323 22:48:37.074318  1439 net.cpp:245] Setting up ctx_output2_ctx_output2/relu_0_split
I0323 22:48:37.074334  1439 net.cpp:252] TRAIN Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 8 256 10 24 (491520)
I0323 22:48:37.074342  1439 net.cpp:252] TRAIN Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 8 256 10 24 (491520)
I0323 22:48:37.074348  1439 net.cpp:252] TRAIN Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 8 256 10 24 (491520)
I0323 22:48:37.074354  1439 layer_factory.hpp:136] Creating layer 'ctx_output3' of type 'Convolution'
I0323 22:48:37.074362  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.074383  1439 net.cpp:184] Created Layer ctx_output3 (52)
I0323 22:48:37.074391  1439 net.cpp:561] ctx_output3 <- pool6_pool6_0_split_1
I0323 22:48:37.074399  1439 net.cpp:530] ctx_output3 -> ctx_output3
I0323 22:48:37.080008  1439 net.cpp:245] Setting up ctx_output3
I0323 22:48:37.080026  1439 net.cpp:252] TRAIN Top shape for layer 52 'ctx_output3' 8 256 5 12 (122880)
I0323 22:48:37.080055  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu' of type 'ReLU'
I0323 22:48:37.080062  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.080070  1439 net.cpp:184] Created Layer ctx_output3/relu (53)
I0323 22:48:37.080076  1439 net.cpp:561] ctx_output3/relu <- ctx_output3
I0323 22:48:37.080082  1439 net.cpp:513] ctx_output3/relu -> ctx_output3 (in-place)
I0323 22:48:37.080090  1439 net.cpp:245] Setting up ctx_output3/relu
I0323 22:48:37.080101  1439 net.cpp:252] TRAIN Top shape for layer 53 'ctx_output3/relu' 8 256 5 12 (122880)
I0323 22:48:37.080106  1439 layer_factory.hpp:136] Creating layer 'ctx_output3_ctx_output3/relu_0_split' of type 'Split'
I0323 22:48:37.080111  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.080119  1439 net.cpp:184] Created Layer ctx_output3_ctx_output3/relu_0_split (54)
I0323 22:48:37.080128  1439 net.cpp:561] ctx_output3_ctx_output3/relu_0_split <- ctx_output3
I0323 22:48:37.080134  1439 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_0
I0323 22:48:37.080142  1439 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_1
I0323 22:48:37.080152  1439 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_2
I0323 22:48:37.080250  1439 net.cpp:245] Setting up ctx_output3_ctx_output3/relu_0_split
I0323 22:48:37.080265  1439 net.cpp:252] TRAIN Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 8 256 5 12 (122880)
I0323 22:48:37.080271  1439 net.cpp:252] TRAIN Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 8 256 5 12 (122880)
I0323 22:48:37.080279  1439 net.cpp:252] TRAIN Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 8 256 5 12 (122880)
I0323 22:48:37.080286  1439 layer_factory.hpp:136] Creating layer 'ctx_output4' of type 'Convolution'
I0323 22:48:37.080293  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.080310  1439 net.cpp:184] Created Layer ctx_output4 (55)
I0323 22:48:37.080319  1439 net.cpp:561] ctx_output4 <- pool7_pool7_0_split_1
I0323 22:48:37.080327  1439 net.cpp:530] ctx_output4 -> ctx_output4
I0323 22:48:37.084702  1439 net.cpp:245] Setting up ctx_output4
I0323 22:48:37.084717  1439 net.cpp:252] TRAIN Top shape for layer 55 'ctx_output4' 8 256 3 6 (36864)
I0323 22:48:37.084729  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu' of type 'ReLU'
I0323 22:48:37.084736  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.084743  1439 net.cpp:184] Created Layer ctx_output4/relu (56)
I0323 22:48:37.084749  1439 net.cpp:561] ctx_output4/relu <- ctx_output4
I0323 22:48:37.084755  1439 net.cpp:513] ctx_output4/relu -> ctx_output4 (in-place)
I0323 22:48:37.084765  1439 net.cpp:245] Setting up ctx_output4/relu
I0323 22:48:37.084774  1439 net.cpp:252] TRAIN Top shape for layer 56 'ctx_output4/relu' 8 256 3 6 (36864)
I0323 22:48:37.084782  1439 layer_factory.hpp:136] Creating layer 'ctx_output4_ctx_output4/relu_0_split' of type 'Split'
I0323 22:48:37.084789  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.084795  1439 net.cpp:184] Created Layer ctx_output4_ctx_output4/relu_0_split (57)
I0323 22:48:37.084802  1439 net.cpp:561] ctx_output4_ctx_output4/relu_0_split <- ctx_output4
I0323 22:48:37.084808  1439 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_0
I0323 22:48:37.084815  1439 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_1
I0323 22:48:37.084825  1439 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_2
I0323 22:48:37.084928  1439 net.cpp:245] Setting up ctx_output4_ctx_output4/relu_0_split
I0323 22:48:37.084941  1439 net.cpp:252] TRAIN Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 8 256 3 6 (36864)
I0323 22:48:37.084962  1439 net.cpp:252] TRAIN Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 8 256 3 6 (36864)
I0323 22:48:37.084969  1439 net.cpp:252] TRAIN Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 8 256 3 6 (36864)
I0323 22:48:37.084975  1439 layer_factory.hpp:136] Creating layer 'ctx_output5' of type 'Convolution'
I0323 22:48:37.084981  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.084997  1439 net.cpp:184] Created Layer ctx_output5 (58)
I0323 22:48:37.085006  1439 net.cpp:561] ctx_output5 <- pool8_pool8_0_split_1
I0323 22:48:37.085014  1439 net.cpp:530] ctx_output5 -> ctx_output5
I0323 22:48:37.089378  1439 net.cpp:245] Setting up ctx_output5
I0323 22:48:37.089393  1439 net.cpp:252] TRAIN Top shape for layer 58 'ctx_output5' 8 256 2 3 (12288)
I0323 22:48:37.089403  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu' of type 'ReLU'
I0323 22:48:37.089412  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.089421  1439 net.cpp:184] Created Layer ctx_output5/relu (59)
I0323 22:48:37.089426  1439 net.cpp:561] ctx_output5/relu <- ctx_output5
I0323 22:48:37.089432  1439 net.cpp:513] ctx_output5/relu -> ctx_output5 (in-place)
I0323 22:48:37.089442  1439 net.cpp:245] Setting up ctx_output5/relu
I0323 22:48:37.089450  1439 net.cpp:252] TRAIN Top shape for layer 59 'ctx_output5/relu' 8 256 2 3 (12288)
I0323 22:48:37.089458  1439 layer_factory.hpp:136] Creating layer 'ctx_output5_ctx_output5/relu_0_split' of type 'Split'
I0323 22:48:37.089464  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.089473  1439 net.cpp:184] Created Layer ctx_output5_ctx_output5/relu_0_split (60)
I0323 22:48:37.089478  1439 net.cpp:561] ctx_output5_ctx_output5/relu_0_split <- ctx_output5
I0323 22:48:37.089485  1439 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_0
I0323 22:48:37.089493  1439 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_1
I0323 22:48:37.089501  1439 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_2
I0323 22:48:37.089604  1439 net.cpp:245] Setting up ctx_output5_ctx_output5/relu_0_split
I0323 22:48:37.089617  1439 net.cpp:252] TRAIN Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 8 256 2 3 (12288)
I0323 22:48:37.089624  1439 net.cpp:252] TRAIN Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 8 256 2 3 (12288)
I0323 22:48:37.089633  1439 net.cpp:252] TRAIN Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 8 256 2 3 (12288)
I0323 22:48:37.089639  1439 layer_factory.hpp:136] Creating layer 'ctx_output6' of type 'Convolution'
I0323 22:48:37.089645  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.089661  1439 net.cpp:184] Created Layer ctx_output6 (61)
I0323 22:48:37.089668  1439 net.cpp:561] ctx_output6 <- pool9
I0323 22:48:37.089675  1439 net.cpp:530] ctx_output6 -> ctx_output6
I0323 22:48:37.094300  1439 net.cpp:245] Setting up ctx_output6
I0323 22:48:37.094328  1439 net.cpp:252] TRAIN Top shape for layer 61 'ctx_output6' 8 256 1 2 (4096)
I0323 22:48:37.094341  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu' of type 'ReLU'
I0323 22:48:37.094348  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.094359  1439 net.cpp:184] Created Layer ctx_output6/relu (62)
I0323 22:48:37.094367  1439 net.cpp:561] ctx_output6/relu <- ctx_output6
I0323 22:48:37.094374  1439 net.cpp:513] ctx_output6/relu -> ctx_output6 (in-place)
I0323 22:48:37.094384  1439 net.cpp:245] Setting up ctx_output6/relu
I0323 22:48:37.094391  1439 net.cpp:252] TRAIN Top shape for layer 62 'ctx_output6/relu' 8 256 1 2 (4096)
I0323 22:48:37.094399  1439 layer_factory.hpp:136] Creating layer 'ctx_output6_ctx_output6/relu_0_split' of type 'Split'
I0323 22:48:37.094419  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.094430  1439 net.cpp:184] Created Layer ctx_output6_ctx_output6/relu_0_split (63)
I0323 22:48:37.094437  1439 net.cpp:561] ctx_output6_ctx_output6/relu_0_split <- ctx_output6
I0323 22:48:37.094444  1439 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_0
I0323 22:48:37.094454  1439 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_1
I0323 22:48:37.094463  1439 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_2
I0323 22:48:37.094563  1439 net.cpp:245] Setting up ctx_output6_ctx_output6/relu_0_split
I0323 22:48:37.094576  1439 net.cpp:252] TRAIN Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 8 256 1 2 (4096)
I0323 22:48:37.094583  1439 net.cpp:252] TRAIN Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 8 256 1 2 (4096)
I0323 22:48:37.094590  1439 net.cpp:252] TRAIN Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 8 256 1 2 (4096)
I0323 22:48:37.094597  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc' of type 'Convolution'
I0323 22:48:37.094605  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.094627  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc (64)
I0323 22:48:37.094636  1439 net.cpp:561] ctx_output1/relu_mbox_loc <- ctx_output1_ctx_output1/relu_0_split_0
I0323 22:48:37.094645  1439 net.cpp:530] ctx_output1/relu_mbox_loc -> ctx_output1/relu_mbox_loc
I0323 22:48:37.095273  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_loc
I0323 22:48:37.095289  1439 net.cpp:252] TRAIN Top shape for layer 64 'ctx_output1/relu_mbox_loc' 8 16 40 96 (491520)
I0323 22:48:37.095300  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_perm' of type 'Permute'
I0323 22:48:37.095309  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.095331  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_perm (65)
I0323 22:48:37.095340  1439 net.cpp:561] ctx_output1/relu_mbox_loc_perm <- ctx_output1/relu_mbox_loc
I0323 22:48:37.095347  1439 net.cpp:530] ctx_output1/relu_mbox_loc_perm -> ctx_output1/relu_mbox_loc_perm
I0323 22:48:37.095549  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_perm
I0323 22:48:37.095563  1439 net.cpp:252] TRAIN Top shape for layer 65 'ctx_output1/relu_mbox_loc_perm' 8 40 96 16 (491520)
I0323 22:48:37.095571  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_flat' of type 'Flatten'
I0323 22:48:37.095577  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.095592  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_flat (66)
I0323 22:48:37.095600  1439 net.cpp:561] ctx_output1/relu_mbox_loc_flat <- ctx_output1/relu_mbox_loc_perm
I0323 22:48:37.095607  1439 net.cpp:530] ctx_output1/relu_mbox_loc_flat -> ctx_output1/relu_mbox_loc_flat
I0323 22:48:37.095654  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_flat
I0323 22:48:37.095667  1439 net.cpp:252] TRAIN Top shape for layer 66 'ctx_output1/relu_mbox_loc_flat' 8 61440 (491520)
I0323 22:48:37.095675  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf' of type 'Convolution'
I0323 22:48:37.095682  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.095700  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf (67)
I0323 22:48:37.095707  1439 net.cpp:561] ctx_output1/relu_mbox_conf <- ctx_output1_ctx_output1/relu_0_split_1
I0323 22:48:37.095716  1439 net.cpp:530] ctx_output1/relu_mbox_conf -> ctx_output1/relu_mbox_conf
I0323 22:48:37.096338  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_conf
I0323 22:48:37.096354  1439 net.cpp:252] TRAIN Top shape for layer 67 'ctx_output1/relu_mbox_conf' 8 16 40 96 (491520)
I0323 22:48:37.096374  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_perm' of type 'Permute'
I0323 22:48:37.096382  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.096396  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_perm (68)
I0323 22:48:37.096405  1439 net.cpp:561] ctx_output1/relu_mbox_conf_perm <- ctx_output1/relu_mbox_conf
I0323 22:48:37.096412  1439 net.cpp:530] ctx_output1/relu_mbox_conf_perm -> ctx_output1/relu_mbox_conf_perm
I0323 22:48:37.096609  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_perm
I0323 22:48:37.096623  1439 net.cpp:252] TRAIN Top shape for layer 68 'ctx_output1/relu_mbox_conf_perm' 8 40 96 16 (491520)
I0323 22:48:37.096631  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_flat' of type 'Flatten'
I0323 22:48:37.096637  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.096647  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_flat (69)
I0323 22:48:37.096654  1439 net.cpp:561] ctx_output1/relu_mbox_conf_flat <- ctx_output1/relu_mbox_conf_perm
I0323 22:48:37.096662  1439 net.cpp:530] ctx_output1/relu_mbox_conf_flat -> ctx_output1/relu_mbox_conf_flat
I0323 22:48:37.096709  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_flat
I0323 22:48:37.096721  1439 net.cpp:252] TRAIN Top shape for layer 69 'ctx_output1/relu_mbox_conf_flat' 8 61440 (491520)
I0323 22:48:37.096729  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_priorbox' of type 'PriorBox'
I0323 22:48:37.096736  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.096752  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_priorbox (70)
I0323 22:48:37.096760  1439 net.cpp:561] ctx_output1/relu_mbox_priorbox <- ctx_output1_ctx_output1/relu_0_split_2
I0323 22:48:37.096767  1439 net.cpp:561] ctx_output1/relu_mbox_priorbox <- data_data_0_split_1
I0323 22:48:37.096776  1439 net.cpp:530] ctx_output1/relu_mbox_priorbox -> ctx_output1/relu_mbox_priorbox
I0323 22:48:37.096829  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_priorbox
I0323 22:48:37.096843  1439 net.cpp:252] TRAIN Top shape for layer 70 'ctx_output1/relu_mbox_priorbox' 1 2 61440 (122880)
I0323 22:48:37.096850  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc' of type 'Convolution'
I0323 22:48:37.096858  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.096873  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc (71)
I0323 22:48:37.096882  1439 net.cpp:561] ctx_output2/relu_mbox_loc <- ctx_output2_ctx_output2/relu_0_split_0
I0323 22:48:37.096890  1439 net.cpp:530] ctx_output2/relu_mbox_loc -> ctx_output2/relu_mbox_loc
I0323 22:48:37.097582  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_loc
I0323 22:48:37.097597  1439 net.cpp:252] TRAIN Top shape for layer 71 'ctx_output2/relu_mbox_loc' 8 24 10 24 (46080)
I0323 22:48:37.097609  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_perm' of type 'Permute'
I0323 22:48:37.097616  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.097628  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_perm (72)
I0323 22:48:37.097636  1439 net.cpp:561] ctx_output2/relu_mbox_loc_perm <- ctx_output2/relu_mbox_loc
I0323 22:48:37.097645  1439 net.cpp:530] ctx_output2/relu_mbox_loc_perm -> ctx_output2/relu_mbox_loc_perm
I0323 22:48:37.097847  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_perm
I0323 22:48:37.097862  1439 net.cpp:252] TRAIN Top shape for layer 72 'ctx_output2/relu_mbox_loc_perm' 8 10 24 24 (46080)
I0323 22:48:37.097869  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_flat' of type 'Flatten'
I0323 22:48:37.097877  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.097887  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_flat (73)
I0323 22:48:37.097903  1439 net.cpp:561] ctx_output2/relu_mbox_loc_flat <- ctx_output2/relu_mbox_loc_perm
I0323 22:48:37.097913  1439 net.cpp:530] ctx_output2/relu_mbox_loc_flat -> ctx_output2/relu_mbox_loc_flat
I0323 22:48:37.097959  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_flat
I0323 22:48:37.097972  1439 net.cpp:252] TRAIN Top shape for layer 73 'ctx_output2/relu_mbox_loc_flat' 8 5760 (46080)
I0323 22:48:37.097980  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf' of type 'Convolution'
I0323 22:48:37.097986  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.098004  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf (74)
I0323 22:48:37.098012  1439 net.cpp:561] ctx_output2/relu_mbox_conf <- ctx_output2_ctx_output2/relu_0_split_1
I0323 22:48:37.098021  1439 net.cpp:530] ctx_output2/relu_mbox_conf -> ctx_output2/relu_mbox_conf
I0323 22:48:37.098708  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_conf
I0323 22:48:37.098724  1439 net.cpp:252] TRAIN Top shape for layer 74 'ctx_output2/relu_mbox_conf' 8 24 10 24 (46080)
I0323 22:48:37.098736  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_perm' of type 'Permute'
I0323 22:48:37.098743  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.098757  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_perm (75)
I0323 22:48:37.098765  1439 net.cpp:561] ctx_output2/relu_mbox_conf_perm <- ctx_output2/relu_mbox_conf
I0323 22:48:37.098773  1439 net.cpp:530] ctx_output2/relu_mbox_conf_perm -> ctx_output2/relu_mbox_conf_perm
I0323 22:48:37.098968  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_perm
I0323 22:48:37.098983  1439 net.cpp:252] TRAIN Top shape for layer 75 'ctx_output2/relu_mbox_conf_perm' 8 10 24 24 (46080)
I0323 22:48:37.098989  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_flat' of type 'Flatten'
I0323 22:48:37.098996  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.099004  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_flat (76)
I0323 22:48:37.099011  1439 net.cpp:561] ctx_output2/relu_mbox_conf_flat <- ctx_output2/relu_mbox_conf_perm
I0323 22:48:37.099018  1439 net.cpp:530] ctx_output2/relu_mbox_conf_flat -> ctx_output2/relu_mbox_conf_flat
I0323 22:48:37.099064  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_flat
I0323 22:48:37.099077  1439 net.cpp:252] TRAIN Top shape for layer 76 'ctx_output2/relu_mbox_conf_flat' 8 5760 (46080)
I0323 22:48:37.099086  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_priorbox' of type 'PriorBox'
I0323 22:48:37.099092  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.099102  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_priorbox (77)
I0323 22:48:37.099108  1439 net.cpp:561] ctx_output2/relu_mbox_priorbox <- ctx_output2_ctx_output2/relu_0_split_2
I0323 22:48:37.099115  1439 net.cpp:561] ctx_output2/relu_mbox_priorbox <- data_data_0_split_2
I0323 22:48:37.099123  1439 net.cpp:530] ctx_output2/relu_mbox_priorbox -> ctx_output2/relu_mbox_priorbox
I0323 22:48:37.099172  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_priorbox
I0323 22:48:37.099185  1439 net.cpp:252] TRAIN Top shape for layer 77 'ctx_output2/relu_mbox_priorbox' 1 2 5760 (11520)
I0323 22:48:37.099192  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc' of type 'Convolution'
I0323 22:48:37.099200  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.099220  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc (78)
I0323 22:48:37.099228  1439 net.cpp:561] ctx_output3/relu_mbox_loc <- ctx_output3_ctx_output3/relu_0_split_0
I0323 22:48:37.099236  1439 net.cpp:530] ctx_output3/relu_mbox_loc -> ctx_output3/relu_mbox_loc
I0323 22:48:37.099925  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_loc
I0323 22:48:37.099951  1439 net.cpp:252] TRAIN Top shape for layer 78 'ctx_output3/relu_mbox_loc' 8 24 5 12 (11520)
I0323 22:48:37.099962  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_perm' of type 'Permute'
I0323 22:48:37.099970  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.099983  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_perm (79)
I0323 22:48:37.099992  1439 net.cpp:561] ctx_output3/relu_mbox_loc_perm <- ctx_output3/relu_mbox_loc
I0323 22:48:37.099998  1439 net.cpp:530] ctx_output3/relu_mbox_loc_perm -> ctx_output3/relu_mbox_loc_perm
I0323 22:48:37.100195  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_perm
I0323 22:48:37.100210  1439 net.cpp:252] TRAIN Top shape for layer 79 'ctx_output3/relu_mbox_loc_perm' 8 5 12 24 (11520)
I0323 22:48:37.100216  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_flat' of type 'Flatten'
I0323 22:48:37.100222  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.100232  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_flat (80)
I0323 22:48:37.100240  1439 net.cpp:561] ctx_output3/relu_mbox_loc_flat <- ctx_output3/relu_mbox_loc_perm
I0323 22:48:37.100247  1439 net.cpp:530] ctx_output3/relu_mbox_loc_flat -> ctx_output3/relu_mbox_loc_flat
I0323 22:48:37.100294  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_flat
I0323 22:48:37.100306  1439 net.cpp:252] TRAIN Top shape for layer 80 'ctx_output3/relu_mbox_loc_flat' 8 1440 (11520)
I0323 22:48:37.100314  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf' of type 'Convolution'
I0323 22:48:37.100322  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.100337  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf (81)
I0323 22:48:37.100345  1439 net.cpp:561] ctx_output3/relu_mbox_conf <- ctx_output3_ctx_output3/relu_0_split_1
I0323 22:48:37.100354  1439 net.cpp:530] ctx_output3/relu_mbox_conf -> ctx_output3/relu_mbox_conf
I0323 22:48:37.101060  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_conf
I0323 22:48:37.101076  1439 net.cpp:252] TRAIN Top shape for layer 81 'ctx_output3/relu_mbox_conf' 8 24 5 12 (11520)
I0323 22:48:37.101086  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_perm' of type 'Permute'
I0323 22:48:37.101094  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.101106  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_perm (82)
I0323 22:48:37.101114  1439 net.cpp:561] ctx_output3/relu_mbox_conf_perm <- ctx_output3/relu_mbox_conf
I0323 22:48:37.101122  1439 net.cpp:530] ctx_output3/relu_mbox_conf_perm -> ctx_output3/relu_mbox_conf_perm
I0323 22:48:37.101320  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_perm
I0323 22:48:37.101335  1439 net.cpp:252] TRAIN Top shape for layer 82 'ctx_output3/relu_mbox_conf_perm' 8 5 12 24 (11520)
I0323 22:48:37.101341  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_flat' of type 'Flatten'
I0323 22:48:37.101347  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.101361  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_flat (83)
I0323 22:48:37.101368  1439 net.cpp:561] ctx_output3/relu_mbox_conf_flat <- ctx_output3/relu_mbox_conf_perm
I0323 22:48:37.101375  1439 net.cpp:530] ctx_output3/relu_mbox_conf_flat -> ctx_output3/relu_mbox_conf_flat
I0323 22:48:37.101421  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_flat
I0323 22:48:37.101434  1439 net.cpp:252] TRAIN Top shape for layer 83 'ctx_output3/relu_mbox_conf_flat' 8 1440 (11520)
I0323 22:48:37.101441  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_priorbox' of type 'PriorBox'
I0323 22:48:37.101449  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.101457  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_priorbox (84)
I0323 22:48:37.101475  1439 net.cpp:561] ctx_output3/relu_mbox_priorbox <- ctx_output3_ctx_output3/relu_0_split_2
I0323 22:48:37.101483  1439 net.cpp:561] ctx_output3/relu_mbox_priorbox <- data_data_0_split_3
I0323 22:48:37.101491  1439 net.cpp:530] ctx_output3/relu_mbox_priorbox -> ctx_output3/relu_mbox_priorbox
I0323 22:48:37.101542  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_priorbox
I0323 22:48:37.101555  1439 net.cpp:252] TRAIN Top shape for layer 84 'ctx_output3/relu_mbox_priorbox' 1 2 1440 (2880)
I0323 22:48:37.101563  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc' of type 'Convolution'
I0323 22:48:37.101570  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.101588  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc (85)
I0323 22:48:37.101596  1439 net.cpp:561] ctx_output4/relu_mbox_loc <- ctx_output4_ctx_output4/relu_0_split_0
I0323 22:48:37.101604  1439 net.cpp:530] ctx_output4/relu_mbox_loc -> ctx_output4/relu_mbox_loc
I0323 22:48:37.102319  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_loc
I0323 22:48:37.102335  1439 net.cpp:252] TRAIN Top shape for layer 85 'ctx_output4/relu_mbox_loc' 8 24 3 6 (3456)
I0323 22:48:37.102346  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_perm' of type 'Permute'
I0323 22:48:37.102352  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.102365  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_perm (86)
I0323 22:48:37.102373  1439 net.cpp:561] ctx_output4/relu_mbox_loc_perm <- ctx_output4/relu_mbox_loc
I0323 22:48:37.102380  1439 net.cpp:530] ctx_output4/relu_mbox_loc_perm -> ctx_output4/relu_mbox_loc_perm
I0323 22:48:37.102578  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_perm
I0323 22:48:37.102593  1439 net.cpp:252] TRAIN Top shape for layer 86 'ctx_output4/relu_mbox_loc_perm' 8 3 6 24 (3456)
I0323 22:48:37.102599  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_flat' of type 'Flatten'
I0323 22:48:37.102607  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.102615  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_flat (87)
I0323 22:48:37.102622  1439 net.cpp:561] ctx_output4/relu_mbox_loc_flat <- ctx_output4/relu_mbox_loc_perm
I0323 22:48:37.102629  1439 net.cpp:530] ctx_output4/relu_mbox_loc_flat -> ctx_output4/relu_mbox_loc_flat
I0323 22:48:37.102674  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_flat
I0323 22:48:37.102686  1439 net.cpp:252] TRAIN Top shape for layer 87 'ctx_output4/relu_mbox_loc_flat' 8 432 (3456)
I0323 22:48:37.102694  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf' of type 'Convolution'
I0323 22:48:37.102699  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.102718  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf (88)
I0323 22:48:37.102726  1439 net.cpp:561] ctx_output4/relu_mbox_conf <- ctx_output4_ctx_output4/relu_0_split_1
I0323 22:48:37.102733  1439 net.cpp:530] ctx_output4/relu_mbox_conf -> ctx_output4/relu_mbox_conf
I0323 22:48:37.103548  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_conf
I0323 22:48:37.103581  1439 net.cpp:252] TRAIN Top shape for layer 88 'ctx_output4/relu_mbox_conf' 8 24 3 6 (3456)
I0323 22:48:37.103595  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_perm' of type 'Permute'
I0323 22:48:37.103602  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.103617  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_perm (89)
I0323 22:48:37.103628  1439 net.cpp:561] ctx_output4/relu_mbox_conf_perm <- ctx_output4/relu_mbox_conf
I0323 22:48:37.103638  1439 net.cpp:530] ctx_output4/relu_mbox_conf_perm -> ctx_output4/relu_mbox_conf_perm
I0323 22:48:37.103843  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_perm
I0323 22:48:37.103870  1439 net.cpp:252] TRAIN Top shape for layer 89 'ctx_output4/relu_mbox_conf_perm' 8 3 6 24 (3456)
I0323 22:48:37.103878  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_flat' of type 'Flatten'
I0323 22:48:37.103884  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.103893  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_flat (90)
I0323 22:48:37.103900  1439 net.cpp:561] ctx_output4/relu_mbox_conf_flat <- ctx_output4/relu_mbox_conf_perm
I0323 22:48:37.103907  1439 net.cpp:530] ctx_output4/relu_mbox_conf_flat -> ctx_output4/relu_mbox_conf_flat
I0323 22:48:37.103955  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_flat
I0323 22:48:37.103968  1439 net.cpp:252] TRAIN Top shape for layer 90 'ctx_output4/relu_mbox_conf_flat' 8 432 (3456)
I0323 22:48:37.103976  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_priorbox' of type 'PriorBox'
I0323 22:48:37.103981  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.103991  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_priorbox (91)
I0323 22:48:37.103997  1439 net.cpp:561] ctx_output4/relu_mbox_priorbox <- ctx_output4_ctx_output4/relu_0_split_2
I0323 22:48:37.104005  1439 net.cpp:561] ctx_output4/relu_mbox_priorbox <- data_data_0_split_4
I0323 22:48:37.104012  1439 net.cpp:530] ctx_output4/relu_mbox_priorbox -> ctx_output4/relu_mbox_priorbox
I0323 22:48:37.104063  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_priorbox
I0323 22:48:37.104077  1439 net.cpp:252] TRAIN Top shape for layer 91 'ctx_output4/relu_mbox_priorbox' 1 2 432 (864)
I0323 22:48:37.104084  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc' of type 'Convolution'
I0323 22:48:37.104090  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.104110  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc (92)
I0323 22:48:37.104117  1439 net.cpp:561] ctx_output5/relu_mbox_loc <- ctx_output5_ctx_output5/relu_0_split_0
I0323 22:48:37.104125  1439 net.cpp:530] ctx_output5/relu_mbox_loc -> ctx_output5/relu_mbox_loc
I0323 22:48:37.104766  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_loc
I0323 22:48:37.104782  1439 net.cpp:252] TRAIN Top shape for layer 92 'ctx_output5/relu_mbox_loc' 8 16 2 3 (768)
I0323 22:48:37.104791  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_perm' of type 'Permute'
I0323 22:48:37.104799  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.104811  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_perm (93)
I0323 22:48:37.104820  1439 net.cpp:561] ctx_output5/relu_mbox_loc_perm <- ctx_output5/relu_mbox_loc
I0323 22:48:37.104826  1439 net.cpp:530] ctx_output5/relu_mbox_loc_perm -> ctx_output5/relu_mbox_loc_perm
I0323 22:48:37.105026  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_perm
I0323 22:48:37.105039  1439 net.cpp:252] TRAIN Top shape for layer 93 'ctx_output5/relu_mbox_loc_perm' 8 2 3 16 (768)
I0323 22:48:37.105046  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_flat' of type 'Flatten'
I0323 22:48:37.105052  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.105062  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_flat (94)
I0323 22:48:37.105067  1439 net.cpp:561] ctx_output5/relu_mbox_loc_flat <- ctx_output5/relu_mbox_loc_perm
I0323 22:48:37.105073  1439 net.cpp:530] ctx_output5/relu_mbox_loc_flat -> ctx_output5/relu_mbox_loc_flat
I0323 22:48:37.105118  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_flat
I0323 22:48:37.105131  1439 net.cpp:252] TRAIN Top shape for layer 94 'ctx_output5/relu_mbox_loc_flat' 8 96 (768)
I0323 22:48:37.105139  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf' of type 'Convolution'
I0323 22:48:37.105146  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.105173  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf (95)
I0323 22:48:37.105182  1439 net.cpp:561] ctx_output5/relu_mbox_conf <- ctx_output5_ctx_output5/relu_0_split_1
I0323 22:48:37.105190  1439 net.cpp:530] ctx_output5/relu_mbox_conf -> ctx_output5/relu_mbox_conf
I0323 22:48:37.105844  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_conf
I0323 22:48:37.105861  1439 net.cpp:252] TRAIN Top shape for layer 95 'ctx_output5/relu_mbox_conf' 8 16 2 3 (768)
I0323 22:48:37.105871  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_perm' of type 'Permute'
I0323 22:48:37.105877  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.105888  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_perm (96)
I0323 22:48:37.105895  1439 net.cpp:561] ctx_output5/relu_mbox_conf_perm <- ctx_output5/relu_mbox_conf
I0323 22:48:37.105902  1439 net.cpp:530] ctx_output5/relu_mbox_conf_perm -> ctx_output5/relu_mbox_conf_perm
I0323 22:48:37.106101  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_perm
I0323 22:48:37.106115  1439 net.cpp:252] TRAIN Top shape for layer 96 'ctx_output5/relu_mbox_conf_perm' 8 2 3 16 (768)
I0323 22:48:37.106122  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_flat' of type 'Flatten'
I0323 22:48:37.106129  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.106139  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_flat (97)
I0323 22:48:37.106146  1439 net.cpp:561] ctx_output5/relu_mbox_conf_flat <- ctx_output5/relu_mbox_conf_perm
I0323 22:48:37.106154  1439 net.cpp:530] ctx_output5/relu_mbox_conf_flat -> ctx_output5/relu_mbox_conf_flat
I0323 22:48:37.106201  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_flat
I0323 22:48:37.106215  1439 net.cpp:252] TRAIN Top shape for layer 97 'ctx_output5/relu_mbox_conf_flat' 8 96 (768)
I0323 22:48:37.106221  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_priorbox' of type 'PriorBox'
I0323 22:48:37.106228  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.106237  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_priorbox (98)
I0323 22:48:37.106245  1439 net.cpp:561] ctx_output5/relu_mbox_priorbox <- ctx_output5_ctx_output5/relu_0_split_2
I0323 22:48:37.106253  1439 net.cpp:561] ctx_output5/relu_mbox_priorbox <- data_data_0_split_5
I0323 22:48:37.106261  1439 net.cpp:530] ctx_output5/relu_mbox_priorbox -> ctx_output5/relu_mbox_priorbox
I0323 22:48:37.106308  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_priorbox
I0323 22:48:37.106323  1439 net.cpp:252] TRAIN Top shape for layer 98 'ctx_output5/relu_mbox_priorbox' 1 2 96 (192)
I0323 22:48:37.106329  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc' of type 'Convolution'
I0323 22:48:37.106336  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.106359  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc (99)
I0323 22:48:37.106367  1439 net.cpp:561] ctx_output6/relu_mbox_loc <- ctx_output6_ctx_output6/relu_0_split_0
I0323 22:48:37.106375  1439 net.cpp:530] ctx_output6/relu_mbox_loc -> ctx_output6/relu_mbox_loc
I0323 22:48:37.107007  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_loc
I0323 22:48:37.107022  1439 net.cpp:252] TRAIN Top shape for layer 99 'ctx_output6/relu_mbox_loc' 8 16 1 2 (256)
I0323 22:48:37.107033  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_perm' of type 'Permute'
I0323 22:48:37.107040  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.107053  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_perm (100)
I0323 22:48:37.107061  1439 net.cpp:561] ctx_output6/relu_mbox_loc_perm <- ctx_output6/relu_mbox_loc
I0323 22:48:37.107069  1439 net.cpp:530] ctx_output6/relu_mbox_loc_perm -> ctx_output6/relu_mbox_loc_perm
I0323 22:48:37.107281  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_perm
I0323 22:48:37.107296  1439 net.cpp:252] TRAIN Top shape for layer 100 'ctx_output6/relu_mbox_loc_perm' 8 1 2 16 (256)
I0323 22:48:37.107302  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_flat' of type 'Flatten'
I0323 22:48:37.107309  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.107317  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_flat (101)
I0323 22:48:37.107326  1439 net.cpp:561] ctx_output6/relu_mbox_loc_flat <- ctx_output6/relu_mbox_loc_perm
I0323 22:48:37.107332  1439 net.cpp:530] ctx_output6/relu_mbox_loc_flat -> ctx_output6/relu_mbox_loc_flat
I0323 22:48:37.107379  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_flat
I0323 22:48:37.107393  1439 net.cpp:252] TRAIN Top shape for layer 101 'ctx_output6/relu_mbox_loc_flat' 8 32 (256)
I0323 22:48:37.107400  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf' of type 'Convolution'
I0323 22:48:37.107408  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.107424  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf (102)
I0323 22:48:37.107432  1439 net.cpp:561] ctx_output6/relu_mbox_conf <- ctx_output6_ctx_output6/relu_0_split_1
I0323 22:48:37.107440  1439 net.cpp:530] ctx_output6/relu_mbox_conf -> ctx_output6/relu_mbox_conf
I0323 22:48:37.108079  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_conf
I0323 22:48:37.108096  1439 net.cpp:252] TRAIN Top shape for layer 102 'ctx_output6/relu_mbox_conf' 8 16 1 2 (256)
I0323 22:48:37.108106  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_perm' of type 'Permute'
I0323 22:48:37.108112  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.108124  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_perm (103)
I0323 22:48:37.108131  1439 net.cpp:561] ctx_output6/relu_mbox_conf_perm <- ctx_output6/relu_mbox_conf
I0323 22:48:37.108139  1439 net.cpp:530] ctx_output6/relu_mbox_conf_perm -> ctx_output6/relu_mbox_conf_perm
I0323 22:48:37.108336  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_perm
I0323 22:48:37.108351  1439 net.cpp:252] TRAIN Top shape for layer 103 'ctx_output6/relu_mbox_conf_perm' 8 1 2 16 (256)
I0323 22:48:37.108357  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_flat' of type 'Flatten'
I0323 22:48:37.108363  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.108371  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_flat (104)
I0323 22:48:37.108376  1439 net.cpp:561] ctx_output6/relu_mbox_conf_flat <- ctx_output6/relu_mbox_conf_perm
I0323 22:48:37.108382  1439 net.cpp:530] ctx_output6/relu_mbox_conf_flat -> ctx_output6/relu_mbox_conf_flat
I0323 22:48:37.108428  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_flat
I0323 22:48:37.108440  1439 net.cpp:252] TRAIN Top shape for layer 104 'ctx_output6/relu_mbox_conf_flat' 8 32 (256)
I0323 22:48:37.108446  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_priorbox' of type 'PriorBox'
I0323 22:48:37.108453  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.108460  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_priorbox (105)
I0323 22:48:37.108466  1439 net.cpp:561] ctx_output6/relu_mbox_priorbox <- ctx_output6_ctx_output6/relu_0_split_2
I0323 22:48:37.108474  1439 net.cpp:561] ctx_output6/relu_mbox_priorbox <- data_data_0_split_6
I0323 22:48:37.108479  1439 net.cpp:530] ctx_output6/relu_mbox_priorbox -> ctx_output6/relu_mbox_priorbox
I0323 22:48:37.108526  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_priorbox
I0323 22:48:37.108539  1439 net.cpp:252] TRAIN Top shape for layer 105 'ctx_output6/relu_mbox_priorbox' 1 2 32 (64)
I0323 22:48:37.108546  1439 layer_factory.hpp:136] Creating layer 'mbox_loc' of type 'Concat'
I0323 22:48:37.108561  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.108574  1439 net.cpp:184] Created Layer mbox_loc (106)
I0323 22:48:37.108582  1439 net.cpp:561] mbox_loc <- ctx_output1/relu_mbox_loc_flat
I0323 22:48:37.108592  1439 net.cpp:561] mbox_loc <- ctx_output2/relu_mbox_loc_flat
I0323 22:48:37.108602  1439 net.cpp:561] mbox_loc <- ctx_output3/relu_mbox_loc_flat
I0323 22:48:37.108608  1439 net.cpp:561] mbox_loc <- ctx_output4/relu_mbox_loc_flat
I0323 22:48:37.108616  1439 net.cpp:561] mbox_loc <- ctx_output5/relu_mbox_loc_flat
I0323 22:48:37.108624  1439 net.cpp:561] mbox_loc <- ctx_output6/relu_mbox_loc_flat
I0323 22:48:37.108631  1439 net.cpp:530] mbox_loc -> mbox_loc
I0323 22:48:37.108680  1439 net.cpp:245] Setting up mbox_loc
I0323 22:48:37.108693  1439 net.cpp:252] TRAIN Top shape for layer 106 'mbox_loc' 8 69200 (553600)
I0323 22:48:37.108700  1439 layer_factory.hpp:136] Creating layer 'mbox_conf' of type 'Concat'
I0323 22:48:37.108705  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.108713  1439 net.cpp:184] Created Layer mbox_conf (107)
I0323 22:48:37.108719  1439 net.cpp:561] mbox_conf <- ctx_output1/relu_mbox_conf_flat
I0323 22:48:37.108726  1439 net.cpp:561] mbox_conf <- ctx_output2/relu_mbox_conf_flat
I0323 22:48:37.108736  1439 net.cpp:561] mbox_conf <- ctx_output3/relu_mbox_conf_flat
I0323 22:48:37.108743  1439 net.cpp:561] mbox_conf <- ctx_output4/relu_mbox_conf_flat
I0323 22:48:37.108749  1439 net.cpp:561] mbox_conf <- ctx_output5/relu_mbox_conf_flat
I0323 22:48:37.108755  1439 net.cpp:561] mbox_conf <- ctx_output6/relu_mbox_conf_flat
I0323 22:48:37.108762  1439 net.cpp:530] mbox_conf -> mbox_conf
I0323 22:48:37.108808  1439 net.cpp:245] Setting up mbox_conf
I0323 22:48:37.108822  1439 net.cpp:252] TRAIN Top shape for layer 107 'mbox_conf' 8 69200 (553600)
I0323 22:48:37.108830  1439 layer_factory.hpp:136] Creating layer 'mbox_priorbox' of type 'Concat'
I0323 22:48:37.108836  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.108845  1439 net.cpp:184] Created Layer mbox_priorbox (108)
I0323 22:48:37.108852  1439 net.cpp:561] mbox_priorbox <- ctx_output1/relu_mbox_priorbox
I0323 22:48:37.108860  1439 net.cpp:561] mbox_priorbox <- ctx_output2/relu_mbox_priorbox
I0323 22:48:37.108868  1439 net.cpp:561] mbox_priorbox <- ctx_output3/relu_mbox_priorbox
I0323 22:48:37.108875  1439 net.cpp:561] mbox_priorbox <- ctx_output4/relu_mbox_priorbox
I0323 22:48:37.108882  1439 net.cpp:561] mbox_priorbox <- ctx_output5/relu_mbox_priorbox
I0323 22:48:37.108889  1439 net.cpp:561] mbox_priorbox <- ctx_output6/relu_mbox_priorbox
I0323 22:48:37.108896  1439 net.cpp:530] mbox_priorbox -> mbox_priorbox
I0323 22:48:37.108942  1439 net.cpp:245] Setting up mbox_priorbox
I0323 22:48:37.108954  1439 net.cpp:252] TRAIN Top shape for layer 108 'mbox_priorbox' 1 2 69200 (138400)
I0323 22:48:37.108963  1439 layer_factory.hpp:136] Creating layer 'mbox_loss' of type 'MultiBoxLoss'
I0323 22:48:37.108969  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.108986  1439 net.cpp:184] Created Layer mbox_loss (109)
I0323 22:48:37.108994  1439 net.cpp:561] mbox_loss <- mbox_loc
I0323 22:48:37.109001  1439 net.cpp:561] mbox_loss <- mbox_conf
I0323 22:48:37.109009  1439 net.cpp:561] mbox_loss <- mbox_priorbox
I0323 22:48:37.109015  1439 net.cpp:561] mbox_loss <- label
I0323 22:48:37.109024  1439 net.cpp:530] mbox_loss -> mbox_loss
I0323 22:48:37.109128  1439 layer_factory.hpp:136] Creating layer 'mbox_loss_smooth_L1_loc' of type 'SmoothL1Loss'
I0323 22:48:37.109140  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.109351  1439 layer_factory.hpp:136] Creating layer 'mbox_loss_softmax_conf' of type 'SoftmaxWithLoss'
I0323 22:48:37.109365  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.109648  1439 net.cpp:245] Setting up mbox_loss
I0323 22:48:37.109673  1439 net.cpp:252] TRAIN Top shape for layer 109 'mbox_loss' (1)
I0323 22:48:37.109680  1439 net.cpp:256]     with loss weight 1
I0323 22:48:37.109702  1439 net.cpp:323] mbox_loss needs backward computation.
I0323 22:48:37.109710  1439 net.cpp:325] mbox_priorbox does not need backward computation.
I0323 22:48:37.109719  1439 net.cpp:323] mbox_conf needs backward computation.
I0323 22:48:37.109726  1439 net.cpp:323] mbox_loc needs backward computation.
I0323 22:48:37.109733  1439 net.cpp:325] ctx_output6/relu_mbox_priorbox does not need backward computation.
I0323 22:48:37.109740  1439 net.cpp:323] ctx_output6/relu_mbox_conf_flat needs backward computation.
I0323 22:48:37.109750  1439 net.cpp:323] ctx_output6/relu_mbox_conf_perm needs backward computation.
I0323 22:48:37.109756  1439 net.cpp:323] ctx_output6/relu_mbox_conf needs backward computation.
I0323 22:48:37.109762  1439 net.cpp:323] ctx_output6/relu_mbox_loc_flat needs backward computation.
I0323 22:48:37.109768  1439 net.cpp:323] ctx_output6/relu_mbox_loc_perm needs backward computation.
I0323 22:48:37.109776  1439 net.cpp:323] ctx_output6/relu_mbox_loc needs backward computation.
I0323 22:48:37.109781  1439 net.cpp:325] ctx_output5/relu_mbox_priorbox does not need backward computation.
I0323 22:48:37.109788  1439 net.cpp:323] ctx_output5/relu_mbox_conf_flat needs backward computation.
I0323 22:48:37.109794  1439 net.cpp:323] ctx_output5/relu_mbox_conf_perm needs backward computation.
I0323 22:48:37.109800  1439 net.cpp:323] ctx_output5/relu_mbox_conf needs backward computation.
I0323 22:48:37.109807  1439 net.cpp:323] ctx_output5/relu_mbox_loc_flat needs backward computation.
I0323 22:48:37.109812  1439 net.cpp:323] ctx_output5/relu_mbox_loc_perm needs backward computation.
I0323 22:48:37.109818  1439 net.cpp:323] ctx_output5/relu_mbox_loc needs backward computation.
I0323 22:48:37.109824  1439 net.cpp:325] ctx_output4/relu_mbox_priorbox does not need backward computation.
I0323 22:48:37.109832  1439 net.cpp:323] ctx_output4/relu_mbox_conf_flat needs backward computation.
I0323 22:48:37.109838  1439 net.cpp:323] ctx_output4/relu_mbox_conf_perm needs backward computation.
I0323 22:48:37.109843  1439 net.cpp:323] ctx_output4/relu_mbox_conf needs backward computation.
I0323 22:48:37.109849  1439 net.cpp:323] ctx_output4/relu_mbox_loc_flat needs backward computation.
I0323 22:48:37.109855  1439 net.cpp:323] ctx_output4/relu_mbox_loc_perm needs backward computation.
I0323 22:48:37.109863  1439 net.cpp:323] ctx_output4/relu_mbox_loc needs backward computation.
I0323 22:48:37.109869  1439 net.cpp:325] ctx_output3/relu_mbox_priorbox does not need backward computation.
I0323 22:48:37.109875  1439 net.cpp:323] ctx_output3/relu_mbox_conf_flat needs backward computation.
I0323 22:48:37.109881  1439 net.cpp:323] ctx_output3/relu_mbox_conf_perm needs backward computation.
I0323 22:48:37.109887  1439 net.cpp:323] ctx_output3/relu_mbox_conf needs backward computation.
I0323 22:48:37.109894  1439 net.cpp:323] ctx_output3/relu_mbox_loc_flat needs backward computation.
I0323 22:48:37.109900  1439 net.cpp:323] ctx_output3/relu_mbox_loc_perm needs backward computation.
I0323 22:48:37.109906  1439 net.cpp:323] ctx_output3/relu_mbox_loc needs backward computation.
I0323 22:48:37.109912  1439 net.cpp:325] ctx_output2/relu_mbox_priorbox does not need backward computation.
I0323 22:48:37.109920  1439 net.cpp:323] ctx_output2/relu_mbox_conf_flat needs backward computation.
I0323 22:48:37.109926  1439 net.cpp:323] ctx_output2/relu_mbox_conf_perm needs backward computation.
I0323 22:48:37.109932  1439 net.cpp:323] ctx_output2/relu_mbox_conf needs backward computation.
I0323 22:48:37.109938  1439 net.cpp:323] ctx_output2/relu_mbox_loc_flat needs backward computation.
I0323 22:48:37.109944  1439 net.cpp:323] ctx_output2/relu_mbox_loc_perm needs backward computation.
I0323 22:48:37.109951  1439 net.cpp:323] ctx_output2/relu_mbox_loc needs backward computation.
I0323 22:48:37.109957  1439 net.cpp:325] ctx_output1/relu_mbox_priorbox does not need backward computation.
I0323 22:48:37.109972  1439 net.cpp:323] ctx_output1/relu_mbox_conf_flat needs backward computation.
I0323 22:48:37.109982  1439 net.cpp:323] ctx_output1/relu_mbox_conf_perm needs backward computation.
I0323 22:48:37.109988  1439 net.cpp:323] ctx_output1/relu_mbox_conf needs backward computation.
I0323 22:48:37.109994  1439 net.cpp:323] ctx_output1/relu_mbox_loc_flat needs backward computation.
I0323 22:48:37.110000  1439 net.cpp:323] ctx_output1/relu_mbox_loc_perm needs backward computation.
I0323 22:48:37.110008  1439 net.cpp:323] ctx_output1/relu_mbox_loc needs backward computation.
I0323 22:48:37.110013  1439 net.cpp:323] ctx_output6_ctx_output6/relu_0_split needs backward computation.
I0323 22:48:37.110020  1439 net.cpp:323] ctx_output6/relu needs backward computation.
I0323 22:48:37.110026  1439 net.cpp:323] ctx_output6 needs backward computation.
I0323 22:48:37.110033  1439 net.cpp:323] ctx_output5_ctx_output5/relu_0_split needs backward computation.
I0323 22:48:37.110038  1439 net.cpp:323] ctx_output5/relu needs backward computation.
I0323 22:48:37.110044  1439 net.cpp:323] ctx_output5 needs backward computation.
I0323 22:48:37.110051  1439 net.cpp:323] ctx_output4_ctx_output4/relu_0_split needs backward computation.
I0323 22:48:37.110057  1439 net.cpp:323] ctx_output4/relu needs backward computation.
I0323 22:48:37.110064  1439 net.cpp:323] ctx_output4 needs backward computation.
I0323 22:48:37.110069  1439 net.cpp:323] ctx_output3_ctx_output3/relu_0_split needs backward computation.
I0323 22:48:37.110076  1439 net.cpp:323] ctx_output3/relu needs backward computation.
I0323 22:48:37.110082  1439 net.cpp:323] ctx_output3 needs backward computation.
I0323 22:48:37.110088  1439 net.cpp:323] ctx_output2_ctx_output2/relu_0_split needs backward computation.
I0323 22:48:37.110095  1439 net.cpp:323] ctx_output2/relu needs backward computation.
I0323 22:48:37.110100  1439 net.cpp:323] ctx_output2 needs backward computation.
I0323 22:48:37.110106  1439 net.cpp:323] ctx_output1_ctx_output1/relu_0_split needs backward computation.
I0323 22:48:37.110112  1439 net.cpp:323] ctx_output1/relu needs backward computation.
I0323 22:48:37.110118  1439 net.cpp:323] ctx_output1 needs backward computation.
I0323 22:48:37.110126  1439 net.cpp:323] pool9 needs backward computation.
I0323 22:48:37.110131  1439 net.cpp:323] pool8_pool8_0_split needs backward computation.
I0323 22:48:37.110137  1439 net.cpp:323] pool8 needs backward computation.
I0323 22:48:37.110144  1439 net.cpp:323] pool7_pool7_0_split needs backward computation.
I0323 22:48:37.110150  1439 net.cpp:323] pool7 needs backward computation.
I0323 22:48:37.110157  1439 net.cpp:323] pool6_pool6_0_split needs backward computation.
I0323 22:48:37.110162  1439 net.cpp:323] pool6 needs backward computation.
I0323 22:48:37.110169  1439 net.cpp:323] res5a_branch2b_res5a_branch2b/relu_0_split needs backward computation.
I0323 22:48:37.110175  1439 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0323 22:48:37.110182  1439 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0323 22:48:37.110188  1439 net.cpp:323] res5a_branch2b needs backward computation.
I0323 22:48:37.110193  1439 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0323 22:48:37.110199  1439 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0323 22:48:37.110205  1439 net.cpp:323] res5a_branch2a needs backward computation.
I0323 22:48:37.110211  1439 net.cpp:323] pool4 needs backward computation.
I0323 22:48:37.110218  1439 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0323 22:48:37.110224  1439 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0323 22:48:37.110229  1439 net.cpp:323] res4a_branch2b needs backward computation.
I0323 22:48:37.110236  1439 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0323 22:48:37.110242  1439 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0323 22:48:37.110249  1439 net.cpp:323] res4a_branch2a needs backward computation.
I0323 22:48:37.110255  1439 net.cpp:323] pool3 needs backward computation.
I0323 22:48:37.110267  1439 net.cpp:323] res3a_branch2b_res3a_branch2b/relu_0_split needs backward computation.
I0323 22:48:37.110275  1439 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0323 22:48:37.110280  1439 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0323 22:48:37.110286  1439 net.cpp:323] res3a_branch2b needs backward computation.
I0323 22:48:37.110292  1439 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0323 22:48:37.110298  1439 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0323 22:48:37.110304  1439 net.cpp:323] res3a_branch2a needs backward computation.
I0323 22:48:37.110311  1439 net.cpp:323] pool2 needs backward computation.
I0323 22:48:37.110316  1439 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0323 22:48:37.110322  1439 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0323 22:48:37.110328  1439 net.cpp:323] res2a_branch2b needs backward computation.
I0323 22:48:37.110334  1439 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0323 22:48:37.110340  1439 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0323 22:48:37.110347  1439 net.cpp:323] res2a_branch2a needs backward computation.
I0323 22:48:37.110352  1439 net.cpp:323] pool1 needs backward computation.
I0323 22:48:37.110358  1439 net.cpp:323] conv1b/relu needs backward computation.
I0323 22:48:37.110364  1439 net.cpp:323] conv1b/bn needs backward computation.
I0323 22:48:37.110370  1439 net.cpp:323] conv1b needs backward computation.
I0323 22:48:37.110376  1439 net.cpp:323] conv1a/relu needs backward computation.
I0323 22:48:37.110383  1439 net.cpp:323] conv1a/bn needs backward computation.
I0323 22:48:37.110388  1439 net.cpp:323] conv1a needs backward computation.
I0323 22:48:37.110394  1439 net.cpp:325] data/bias does not need backward computation.
I0323 22:48:37.110402  1439 net.cpp:325] data_data_0_split does not need backward computation.
I0323 22:48:37.110409  1439 net.cpp:325] data does not need backward computation.
I0323 22:48:37.110414  1439 net.cpp:367] This network produces output mbox_loss
I0323 22:48:37.110522  1439 net.cpp:389] Top memory (TRAIN) required for data: 1206154824 diff: 1206154824
I0323 22:48:37.110532  1439 net.cpp:392] Bottom memory (TRAIN) required for data: 1206154816 diff: 1206154816
I0323 22:48:37.110539  1439 net.cpp:395] Shared (in-place) memory (TRAIN) by data: 521715712 diff: 521715712
I0323 22:48:37.110544  1439 net.cpp:398] Parameters memory (TRAIN) required for data: 12464288 diff: 12464288
I0323 22:48:37.110550  1439 net.cpp:401] Parameters shared memory (TRAIN) by data: 0 diff: 0
I0323 22:48:37.110556  1439 net.cpp:407] Network initialization done.
I0323 22:48:37.112663  1439 solver.cpp:177] Creating test net (#0) specified by test_net file: training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/test.prototxt
I0323 22:48:37.113517  1439 net.cpp:72] Initializing net from parameters: 
name: "ssdJacintoNetV2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_value: 0
    mean_value: 0
    mean_value: 0
    force_color: false
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 320
      width: 768
      interp_mode: LINEAR
    }
    crop_h: 320
    crop_w: 768
  }
  data_param {
    source: "/user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_test_lmdb"
    batch_size: 4
    backend: LMDB
    threads: 4
    parser_threads: 4
  }
  annotated_data_param {
    batch_sampler {
    }
    label_map_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/labelmap.prototxt"
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "pool6"
  top: "pool7"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool8"
  type: "Pooling"
  bottom: "pool7"
  top: "pool8"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool9"
  type: "Pooling"
  bottom: "pool8"
  top: "pool9"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "ctx_output1"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "ctx_output1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu"
  type: "ReLU"
  bottom: "ctx_output1"
  top: "ctx_output1"
}
layer {
  name: "ctx_output2"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "ctx_output2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu"
  type: "ReLU"
  bottom: "ctx_output2"
  top: "ctx_output2"
}
layer {
  name: "ctx_output3"
  type: "Convolution"
  bottom: "pool6"
  top: "ctx_output3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu"
  type: "ReLU"
  bottom: "ctx_output3"
  top: "ctx_output3"
}
layer {
  name: "ctx_output4"
  type: "Convolution"
  bottom: "pool7"
  top: "ctx_output4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu"
  type: "ReLU"
  bottom: "ctx_output4"
  top: "ctx_output4"
}
layer {
  name: "ctx_output5"
  type: "Convolution"
  bottom: "pool8"
  top: "ctx_output5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu"
  type: "ReLU"
  bottom: "ctx_output5"
  top: "ctx_output5"
}
layer {
  name: "ctx_output6"
  type: "Convolution"
  bottom: "pool9"
  top: "ctx_output6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu"
  type: "ReLU"
  bottom: "ctx_output6"
  top: "ctx_output6"
}
layer {
  name: "ctx_output1/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_loc"
  top: "ctx_output1/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_loc_perm"
  top: "ctx_output1/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_conf"
  top: "ctx_output1/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_conf_perm"
  top: "ctx_output1/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output1"
  bottom: "data"
  top: "ctx_output1/relu_mbox_priorbox"
  prior_box_param {
    min_size: 12.8
    max_size: 32
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_loc"
  top: "ctx_output2/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_loc_perm"
  top: "ctx_output2/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_conf"
  top: "ctx_output2/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_conf_perm"
  top: "ctx_output2/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output2"
  bottom: "data"
  top: "ctx_output2/relu_mbox_priorbox"
  prior_box_param {
    min_size: 32
    max_size: 96
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_loc"
  top: "ctx_output3/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_loc_perm"
  top: "ctx_output3/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_conf"
  top: "ctx_output3/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_conf_perm"
  top: "ctx_output3/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output3"
  bottom: "data"
  top: "ctx_output3/relu_mbox_priorbox"
  prior_box_param {
    min_size: 96
    max_size: 160
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_loc"
  top: "ctx_output4/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_loc_perm"
  top: "ctx_output4/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_conf"
  top: "ctx_output4/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_conf_perm"
  top: "ctx_output4/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output4"
  bottom: "data"
  top: "ctx_output4/relu_mbox_priorbox"
  prior_box_param {
    min_size: 160
    max_size: 224
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_loc"
  top: "ctx_output5/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_loc_perm"
  top: "ctx_output5/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_conf"
  top: "ctx_output5/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_conf_perm"
  top: "ctx_output5/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output5"
  bottom: "data"
  top: "ctx_output5/relu_mbox_priorbox"
  prior_box_param {
    min_size: 224
    max_size: 288
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_loc"
  top: "ctx_output6/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_loc_perm"
  top: "ctx_output6/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_conf"
  top: "ctx_output6/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_conf_perm"
  top: "ctx_output6/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output6"
  bottom: "data"
  top: "ctx_output6/relu_mbox_priorbox"
  prior_box_param {
    min_size: 288
    max_size: 352
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_loc_flat"
  bottom: "ctx_output2/relu_mbox_loc_flat"
  bottom: "ctx_output3/relu_mbox_loc_flat"
  bottom: "ctx_output4/relu_mbox_loc_flat"
  bottom: "ctx_output5/relu_mbox_loc_flat"
  bottom: "ctx_output6/relu_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_conf_flat"
  bottom: "ctx_output2/relu_mbox_conf_flat"
  bottom: "ctx_output3/relu_mbox_conf_flat"
  bottom: "ctx_output4/relu_mbox_conf_flat"
  bottom: "ctx_output5/relu_mbox_conf_flat"
  bottom: "ctx_output6/relu_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_priorbox"
  bottom: "ctx_output2/relu_mbox_priorbox"
  bottom: "ctx_output3/relu_mbox_priorbox"
  bottom: "ctx_output4/relu_mbox_priorbox"
  bottom: "ctx_output5/relu_mbox_priorbox"
  bottom: "ctx_output6/relu_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_reshape"
  type: "Reshape"
  bottom: "mbox_conf"
  top: "mbox_conf_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: -1
      dim: 4
    }
  }
}
layer {
  name: "mbox_conf_softmax"
  type: "Softmax"
  bottom: "mbox_conf_reshape"
  top: "mbox_conf_softmax"
  softmax_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_flatten"
  type: "Flatten"
  bottom: "mbox_conf_softmax"
  top: "mbox_conf_flatten"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "detection_out"
  type: "DetectionOutput"
  bottom: "mbox_loc"
  bottom: "mbox_conf_flatten"
  bottom: "mbox_priorbox"
  top: "detection_out"
  include {
    phase: TEST
  }
  detection_output_param {
    num_classes: 4
    share_location: true
    background_label_id: 0
    nms_param {
      nms_threshold: 0.45
      top_k: 400
    }
    save_output_param {
      output_directory: ""
      output_name_prefix: "comp4_det_test_"
      output_format: "VOC"
      label_map_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/labelmap.prototxt"
      name_size_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/test_name_size.txt"
      num_test_image: 3609
    }
    code_type: CENTER_SIZE
    keep_top_k: 200
    confidence_threshold: 0.01
  }
}
layer {
  name: "detection_eval"
  type: "DetectionEvaluate"
  bottom: "detection_out"
  bottom: "label"
  top: "detection_eval"
  include {
    phase: TEST
  }
  detection_evaluate_param {
    num_classes: 4
    background_label_id: 0
    overlap_threshold: 0.5
    evaluate_difficult_gt: true
    name_size_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/test_name_size.txt"
  }
}
I0323 22:48:37.114012  1439 net.cpp:104] Using FLOAT as default forward math type
I0323 22:48:37.114024  1439 net.cpp:110] Using FLOAT as default backward math type
I0323 22:48:37.114029  1439 layer_factory.hpp:136] Creating layer 'data' of type 'AnnotatedData'
I0323 22:48:37.114038  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.114060  1439 net.cpp:184] Created Layer data (0)
I0323 22:48:37.114068  1439 net.cpp:530] data -> data
I0323 22:48:37.114074  1439 net.cpp:530] data -> label
I0323 22:48:37.114090  1439 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 4
I0323 22:48:37.114102  1439 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0323 22:48:37.114799  1484 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_test_lmdb
I0323 22:48:37.125500  1439 annotated_data_layer.cpp:219] output data size: 4,3,320,768
I0323 22:48:37.125593  1439 annotated_data_layer.cpp:265] (0) Output data size: 4, 3, 320, 768
I0323 22:48:37.125661  1439 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0323 22:48:37.125720  1439 net.cpp:245] Setting up data
I0323 22:48:37.125737  1439 net.cpp:252] TEST Top shape for layer 0 'data' 4 3 320 768 (2949120)
I0323 22:48:37.125761  1439 net.cpp:252] TEST Top shape for layer 0 'data' 1 1 31 8 (248)
I0323 22:48:37.125771  1439 layer_factory.hpp:136] Creating layer 'data_data_0_split' of type 'Split'
I0323 22:48:37.125779  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.125794  1439 net.cpp:184] Created Layer data_data_0_split (1)
I0323 22:48:37.125803  1439 net.cpp:561] data_data_0_split <- data
I0323 22:48:37.125813  1439 net.cpp:530] data_data_0_split -> data_data_0_split_0
I0323 22:48:37.125824  1439 net.cpp:530] data_data_0_split -> data_data_0_split_1
I0323 22:48:37.125833  1439 net.cpp:530] data_data_0_split -> data_data_0_split_2
I0323 22:48:37.125841  1439 net.cpp:530] data_data_0_split -> data_data_0_split_3
I0323 22:48:37.125849  1439 net.cpp:530] data_data_0_split -> data_data_0_split_4
I0323 22:48:37.125855  1439 net.cpp:530] data_data_0_split -> data_data_0_split_5
I0323 22:48:37.125862  1439 net.cpp:530] data_data_0_split -> data_data_0_split_6
I0323 22:48:37.126067  1439 net.cpp:245] Setting up data_data_0_split
I0323 22:48:37.126082  1439 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 320 768 (2949120)
I0323 22:48:37.126092  1439 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 320 768 (2949120)
I0323 22:48:37.126101  1439 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 320 768 (2949120)
I0323 22:48:37.126107  1439 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 320 768 (2949120)
I0323 22:48:37.126116  1439 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 320 768 (2949120)
I0323 22:48:37.126123  1439 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 320 768 (2949120)
I0323 22:48:37.126132  1439 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 320 768 (2949120)
I0323 22:48:37.126139  1439 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0323 22:48:37.126147  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.126160  1439 net.cpp:184] Created Layer data/bias (2)
I0323 22:48:37.126168  1439 net.cpp:561] data/bias <- data_data_0_split_0
I0323 22:48:37.126176  1439 net.cpp:530] data/bias -> data/bias
I0323 22:48:37.127470  1485 annotated_data_layer.cpp:111] (0) Parser threads: 1
I0323 22:48:37.127492  1485 annotated_data_layer.cpp:113] (0) Transformer threads: 1
I0323 22:48:37.127879  1439 net.cpp:245] Setting up data/bias
I0323 22:48:37.127900  1439 net.cpp:252] TEST Top shape for layer 2 'data/bias' 4 3 320 768 (2949120)
I0323 22:48:37.127915  1439 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0323 22:48:37.127924  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.127944  1439 net.cpp:184] Created Layer conv1a (3)
I0323 22:48:37.127952  1439 net.cpp:561] conv1a <- data/bias
I0323 22:48:37.127961  1439 net.cpp:530] conv1a -> conv1a
I0323 22:48:37.128628  1439 net.cpp:245] Setting up conv1a
I0323 22:48:37.128644  1439 net.cpp:252] TEST Top shape for layer 3 'conv1a' 4 32 160 384 (7864320)
I0323 22:48:37.128659  1439 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0323 22:48:37.128667  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.128682  1439 net.cpp:184] Created Layer conv1a/bn (4)
I0323 22:48:37.128690  1439 net.cpp:561] conv1a/bn <- conv1a
I0323 22:48:37.128697  1439 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0323 22:48:37.129917  1439 net.cpp:245] Setting up conv1a/bn
I0323 22:48:37.129935  1439 net.cpp:252] TEST Top shape for layer 4 'conv1a/bn' 4 32 160 384 (7864320)
I0323 22:48:37.129952  1439 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0323 22:48:37.129961  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.129971  1439 net.cpp:184] Created Layer conv1a/relu (5)
I0323 22:48:37.129977  1439 net.cpp:561] conv1a/relu <- conv1a
I0323 22:48:37.129998  1439 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0323 22:48:37.130010  1439 net.cpp:245] Setting up conv1a/relu
I0323 22:48:37.130018  1439 net.cpp:252] TEST Top shape for layer 5 'conv1a/relu' 4 32 160 384 (7864320)
I0323 22:48:37.130025  1439 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0323 22:48:37.130033  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.130048  1439 net.cpp:184] Created Layer conv1b (6)
I0323 22:48:37.130054  1439 net.cpp:561] conv1b <- conv1a
I0323 22:48:37.130061  1439 net.cpp:530] conv1b -> conv1b
I0323 22:48:37.130632  1439 net.cpp:245] Setting up conv1b
I0323 22:48:37.130648  1439 net.cpp:252] TEST Top shape for layer 6 'conv1b' 4 32 160 384 (7864320)
I0323 22:48:37.130661  1439 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0323 22:48:37.130668  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.130679  1439 net.cpp:184] Created Layer conv1b/bn (7)
I0323 22:48:37.130686  1439 net.cpp:561] conv1b/bn <- conv1b
I0323 22:48:37.130694  1439 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0323 22:48:37.131654  1439 net.cpp:245] Setting up conv1b/bn
I0323 22:48:37.131670  1439 net.cpp:252] TEST Top shape for layer 7 'conv1b/bn' 4 32 160 384 (7864320)
I0323 22:48:37.131685  1439 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0323 22:48:37.131692  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.131702  1439 net.cpp:184] Created Layer conv1b/relu (8)
I0323 22:48:37.131709  1439 net.cpp:561] conv1b/relu <- conv1b
I0323 22:48:37.131716  1439 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0323 22:48:37.131726  1439 net.cpp:245] Setting up conv1b/relu
I0323 22:48:37.131733  1439 net.cpp:252] TEST Top shape for layer 8 'conv1b/relu' 4 32 160 384 (7864320)
I0323 22:48:37.131741  1439 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0323 22:48:37.131747  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.131757  1439 net.cpp:184] Created Layer pool1 (9)
I0323 22:48:37.131764  1439 net.cpp:561] pool1 <- conv1b
I0323 22:48:37.131772  1439 net.cpp:530] pool1 -> pool1
I0323 22:48:37.131870  1439 net.cpp:245] Setting up pool1
I0323 22:48:37.131884  1439 net.cpp:252] TEST Top shape for layer 9 'pool1' 4 32 80 192 (1966080)
I0323 22:48:37.131891  1439 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0323 22:48:37.131898  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.131913  1439 net.cpp:184] Created Layer res2a_branch2a (10)
I0323 22:48:37.131920  1439 net.cpp:561] res2a_branch2a <- pool1
I0323 22:48:37.131927  1439 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0323 22:48:37.132988  1439 net.cpp:245] Setting up res2a_branch2a
I0323 22:48:37.133004  1439 net.cpp:252] TEST Top shape for layer 10 'res2a_branch2a' 4 64 80 192 (3932160)
I0323 22:48:37.133018  1439 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0323 22:48:37.133025  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.133036  1439 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0323 22:48:37.133044  1439 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0323 22:48:37.133051  1439 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0323 22:48:37.134023  1439 net.cpp:245] Setting up res2a_branch2a/bn
I0323 22:48:37.134039  1439 net.cpp:252] TEST Top shape for layer 11 'res2a_branch2a/bn' 4 64 80 192 (3932160)
I0323 22:48:37.134054  1439 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0323 22:48:37.134063  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.134070  1439 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0323 22:48:37.134076  1439 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0323 22:48:37.134094  1439 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0323 22:48:37.134105  1439 net.cpp:245] Setting up res2a_branch2a/relu
I0323 22:48:37.134114  1439 net.cpp:252] TEST Top shape for layer 12 'res2a_branch2a/relu' 4 64 80 192 (3932160)
I0323 22:48:37.134120  1439 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0323 22:48:37.134127  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.134141  1439 net.cpp:184] Created Layer res2a_branch2b (13)
I0323 22:48:37.134150  1439 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0323 22:48:37.134156  1439 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0323 22:48:37.134959  1439 net.cpp:245] Setting up res2a_branch2b
I0323 22:48:37.134985  1439 net.cpp:252] TEST Top shape for layer 13 'res2a_branch2b' 4 64 80 192 (3932160)
I0323 22:48:37.134997  1439 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0323 22:48:37.135006  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.135021  1439 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0323 22:48:37.135030  1439 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0323 22:48:37.135037  1439 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0323 22:48:37.136027  1439 net.cpp:245] Setting up res2a_branch2b/bn
I0323 22:48:37.136044  1439 net.cpp:252] TEST Top shape for layer 14 'res2a_branch2b/bn' 4 64 80 192 (3932160)
I0323 22:48:37.136059  1439 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0323 22:48:37.136066  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.136075  1439 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0323 22:48:37.136082  1439 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0323 22:48:37.136090  1439 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0323 22:48:37.136101  1439 net.cpp:245] Setting up res2a_branch2b/relu
I0323 22:48:37.136107  1439 net.cpp:252] TEST Top shape for layer 15 'res2a_branch2b/relu' 4 64 80 192 (3932160)
I0323 22:48:37.136114  1439 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0323 22:48:37.136121  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.136133  1439 net.cpp:184] Created Layer pool2 (16)
I0323 22:48:37.136140  1439 net.cpp:561] pool2 <- res2a_branch2b
I0323 22:48:37.136147  1439 net.cpp:530] pool2 -> pool2
I0323 22:48:37.136247  1439 net.cpp:245] Setting up pool2
I0323 22:48:37.136260  1439 net.cpp:252] TEST Top shape for layer 16 'pool2' 4 64 40 96 (983040)
I0323 22:48:37.136267  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0323 22:48:37.136276  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.136291  1439 net.cpp:184] Created Layer res3a_branch2a (17)
I0323 22:48:37.136298  1439 net.cpp:561] res3a_branch2a <- pool2
I0323 22:48:37.136307  1439 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0323 22:48:37.139078  1439 net.cpp:245] Setting up res3a_branch2a
I0323 22:48:37.139096  1439 net.cpp:252] TEST Top shape for layer 17 'res3a_branch2a' 4 128 40 96 (1966080)
I0323 22:48:37.139106  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0323 22:48:37.139112  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.139124  1439 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0323 22:48:37.139132  1439 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0323 22:48:37.139138  1439 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0323 22:48:37.140094  1439 net.cpp:245] Setting up res3a_branch2a/bn
I0323 22:48:37.140110  1439 net.cpp:252] TEST Top shape for layer 18 'res3a_branch2a/bn' 4 128 40 96 (1966080)
I0323 22:48:37.140126  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0323 22:48:37.140149  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.140159  1439 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0323 22:48:37.140166  1439 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0323 22:48:37.140174  1439 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0323 22:48:37.140183  1439 net.cpp:245] Setting up res3a_branch2a/relu
I0323 22:48:37.140192  1439 net.cpp:252] TEST Top shape for layer 19 'res3a_branch2a/relu' 4 128 40 96 (1966080)
I0323 22:48:37.140199  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0323 22:48:37.140205  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.140219  1439 net.cpp:184] Created Layer res3a_branch2b (20)
I0323 22:48:37.140228  1439 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0323 22:48:37.140234  1439 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0323 22:48:37.141865  1439 net.cpp:245] Setting up res3a_branch2b
I0323 22:48:37.141881  1439 net.cpp:252] TEST Top shape for layer 20 'res3a_branch2b' 4 128 40 96 (1966080)
I0323 22:48:37.141893  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0323 22:48:37.141901  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.141912  1439 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0323 22:48:37.141919  1439 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0323 22:48:37.141927  1439 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0323 22:48:37.142868  1439 net.cpp:245] Setting up res3a_branch2b/bn
I0323 22:48:37.142884  1439 net.cpp:252] TEST Top shape for layer 21 'res3a_branch2b/bn' 4 128 40 96 (1966080)
I0323 22:48:37.142897  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0323 22:48:37.142905  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.142913  1439 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0323 22:48:37.142920  1439 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0323 22:48:37.142927  1439 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0323 22:48:37.142937  1439 net.cpp:245] Setting up res3a_branch2b/relu
I0323 22:48:37.142944  1439 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b/relu' 4 128 40 96 (1966080)
I0323 22:48:37.142951  1439 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0323 22:48:37.142958  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.142966  1439 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (23)
I0323 22:48:37.142973  1439 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0323 22:48:37.142980  1439 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0323 22:48:37.142988  1439 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0323 22:48:37.143061  1439 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0323 22:48:37.143074  1439 net.cpp:252] TEST Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 4 128 40 96 (1966080)
I0323 22:48:37.143082  1439 net.cpp:252] TEST Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 4 128 40 96 (1966080)
I0323 22:48:37.143090  1439 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0323 22:48:37.143096  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.143107  1439 net.cpp:184] Created Layer pool3 (24)
I0323 22:48:37.143115  1439 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0323 22:48:37.143121  1439 net.cpp:530] pool3 -> pool3
I0323 22:48:37.143215  1439 net.cpp:245] Setting up pool3
I0323 22:48:37.143239  1439 net.cpp:252] TEST Top shape for layer 24 'pool3' 4 128 20 48 (491520)
I0323 22:48:37.143247  1439 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0323 22:48:37.143254  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.143268  1439 net.cpp:184] Created Layer res4a_branch2a (25)
I0323 22:48:37.143275  1439 net.cpp:561] res4a_branch2a <- pool3
I0323 22:48:37.143283  1439 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0323 22:48:37.154127  1439 net.cpp:245] Setting up res4a_branch2a
I0323 22:48:37.154163  1439 net.cpp:252] TEST Top shape for layer 25 'res4a_branch2a' 4 256 20 48 (983040)
I0323 22:48:37.154184  1439 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0323 22:48:37.154199  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.154224  1439 net.cpp:184] Created Layer res4a_branch2a/bn (26)
I0323 22:48:37.154238  1439 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0323 22:48:37.154256  1439 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0323 22:48:37.155279  1439 net.cpp:245] Setting up res4a_branch2a/bn
I0323 22:48:37.155300  1439 net.cpp:252] TEST Top shape for layer 26 'res4a_branch2a/bn' 4 256 20 48 (983040)
I0323 22:48:37.155331  1439 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0323 22:48:37.155345  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.155364  1439 net.cpp:184] Created Layer res4a_branch2a/relu (27)
I0323 22:48:37.155376  1439 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0323 22:48:37.155390  1439 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0323 22:48:37.155406  1439 net.cpp:245] Setting up res4a_branch2a/relu
I0323 22:48:37.155422  1439 net.cpp:252] TEST Top shape for layer 27 'res4a_branch2a/relu' 4 256 20 48 (983040)
I0323 22:48:37.155434  1439 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0323 22:48:37.155447  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.155472  1439 net.cpp:184] Created Layer res4a_branch2b (28)
I0323 22:48:37.155484  1439 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0323 22:48:37.155498  1439 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0323 22:48:37.160631  1439 net.cpp:245] Setting up res4a_branch2b
I0323 22:48:37.160656  1439 net.cpp:252] TEST Top shape for layer 28 'res4a_branch2b' 4 256 20 48 (983040)
I0323 22:48:37.160673  1439 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0323 22:48:37.160686  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.160708  1439 net.cpp:184] Created Layer res4a_branch2b/bn (29)
I0323 22:48:37.160720  1439 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0323 22:48:37.160734  1439 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0323 22:48:37.161746  1439 net.cpp:245] Setting up res4a_branch2b/bn
I0323 22:48:37.161764  1439 net.cpp:252] TEST Top shape for layer 29 'res4a_branch2b/bn' 4 256 20 48 (983040)
I0323 22:48:37.161792  1439 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0323 22:48:37.161805  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.161820  1439 net.cpp:184] Created Layer res4a_branch2b/relu (30)
I0323 22:48:37.161833  1439 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0323 22:48:37.161845  1439 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0323 22:48:37.161864  1439 net.cpp:245] Setting up res4a_branch2b/relu
I0323 22:48:37.161876  1439 net.cpp:252] TEST Top shape for layer 30 'res4a_branch2b/relu' 4 256 20 48 (983040)
I0323 22:48:37.161888  1439 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0323 22:48:37.161900  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.161933  1439 net.cpp:184] Created Layer pool4 (31)
I0323 22:48:37.161945  1439 net.cpp:561] pool4 <- res4a_branch2b
I0323 22:48:37.161959  1439 net.cpp:530] pool4 -> pool4
I0323 22:48:37.162073  1439 net.cpp:245] Setting up pool4
I0323 22:48:37.162091  1439 net.cpp:252] TEST Top shape for layer 31 'pool4' 4 256 10 24 (245760)
I0323 22:48:37.162104  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0323 22:48:37.162117  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.162144  1439 net.cpp:184] Created Layer res5a_branch2a (32)
I0323 22:48:37.162156  1439 net.cpp:561] res5a_branch2a <- pool4
I0323 22:48:37.162170  1439 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0323 22:48:37.201156  1439 net.cpp:245] Setting up res5a_branch2a
I0323 22:48:37.201194  1439 net.cpp:252] TEST Top shape for layer 32 'res5a_branch2a' 4 512 10 24 (491520)
I0323 22:48:37.201215  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0323 22:48:37.201230  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.201257  1439 net.cpp:184] Created Layer res5a_branch2a/bn (33)
I0323 22:48:37.201272  1439 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0323 22:48:37.201288  1439 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0323 22:48:37.202329  1439 net.cpp:245] Setting up res5a_branch2a/bn
I0323 22:48:37.202347  1439 net.cpp:252] TEST Top shape for layer 33 'res5a_branch2a/bn' 4 512 10 24 (491520)
I0323 22:48:37.202373  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0323 22:48:37.202384  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.202404  1439 net.cpp:184] Created Layer res5a_branch2a/relu (34)
I0323 22:48:37.202414  1439 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0323 22:48:37.202427  1439 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0323 22:48:37.202445  1439 net.cpp:245] Setting up res5a_branch2a/relu
I0323 22:48:37.202459  1439 net.cpp:252] TEST Top shape for layer 34 'res5a_branch2a/relu' 4 512 10 24 (491520)
I0323 22:48:37.202471  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0323 22:48:37.202483  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.202509  1439 net.cpp:184] Created Layer res5a_branch2b (35)
I0323 22:48:37.202520  1439 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0323 22:48:37.202534  1439 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0323 22:48:37.222508  1439 net.cpp:245] Setting up res5a_branch2b
I0323 22:48:37.222544  1439 net.cpp:252] TEST Top shape for layer 35 'res5a_branch2b' 4 512 10 24 (491520)
I0323 22:48:37.222579  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0323 22:48:37.222594  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.222622  1439 net.cpp:184] Created Layer res5a_branch2b/bn (36)
I0323 22:48:37.222637  1439 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0323 22:48:37.222653  1439 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0323 22:48:37.223672  1439 net.cpp:245] Setting up res5a_branch2b/bn
I0323 22:48:37.223690  1439 net.cpp:252] TEST Top shape for layer 36 'res5a_branch2b/bn' 4 512 10 24 (491520)
I0323 22:48:37.223713  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0323 22:48:37.223726  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.223743  1439 net.cpp:184] Created Layer res5a_branch2b/relu (37)
I0323 22:48:37.223754  1439 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0323 22:48:37.223768  1439 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0323 22:48:37.223784  1439 net.cpp:245] Setting up res5a_branch2b/relu
I0323 22:48:37.223811  1439 net.cpp:252] TEST Top shape for layer 37 'res5a_branch2b/relu' 4 512 10 24 (491520)
I0323 22:48:37.223824  1439 layer_factory.hpp:136] Creating layer 'res5a_branch2b_res5a_branch2b/relu_0_split' of type 'Split'
I0323 22:48:37.223836  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.223850  1439 net.cpp:184] Created Layer res5a_branch2b_res5a_branch2b/relu_0_split (38)
I0323 22:48:37.223861  1439 net.cpp:561] res5a_branch2b_res5a_branch2b/relu_0_split <- res5a_branch2b
I0323 22:48:37.223875  1439 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_0
I0323 22:48:37.223892  1439 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_1
I0323 22:48:37.223980  1439 net.cpp:245] Setting up res5a_branch2b_res5a_branch2b/relu_0_split
I0323 22:48:37.223996  1439 net.cpp:252] TEST Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 4 512 10 24 (491520)
I0323 22:48:37.224012  1439 net.cpp:252] TEST Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 4 512 10 24 (491520)
I0323 22:48:37.224023  1439 layer_factory.hpp:136] Creating layer 'pool6' of type 'Pooling'
I0323 22:48:37.224036  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.224056  1439 net.cpp:184] Created Layer pool6 (39)
I0323 22:48:37.224067  1439 net.cpp:561] pool6 <- res5a_branch2b_res5a_branch2b/relu_0_split_0
I0323 22:48:37.224081  1439 net.cpp:530] pool6 -> pool6
I0323 22:48:37.224198  1439 net.cpp:245] Setting up pool6
I0323 22:48:37.224215  1439 net.cpp:252] TEST Top shape for layer 39 'pool6' 4 512 5 12 (122880)
I0323 22:48:37.224228  1439 layer_factory.hpp:136] Creating layer 'pool6_pool6_0_split' of type 'Split'
I0323 22:48:37.224241  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.224256  1439 net.cpp:184] Created Layer pool6_pool6_0_split (40)
I0323 22:48:37.224267  1439 net.cpp:561] pool6_pool6_0_split <- pool6
I0323 22:48:37.224280  1439 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_0
I0323 22:48:37.224294  1439 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_1
I0323 22:48:37.224375  1439 net.cpp:245] Setting up pool6_pool6_0_split
I0323 22:48:37.224392  1439 net.cpp:252] TEST Top shape for layer 40 'pool6_pool6_0_split' 4 512 5 12 (122880)
I0323 22:48:37.224406  1439 net.cpp:252] TEST Top shape for layer 40 'pool6_pool6_0_split' 4 512 5 12 (122880)
I0323 22:48:37.224418  1439 layer_factory.hpp:136] Creating layer 'pool7' of type 'Pooling'
I0323 22:48:37.224431  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.224447  1439 net.cpp:184] Created Layer pool7 (41)
I0323 22:48:37.224457  1439 net.cpp:561] pool7 <- pool6_pool6_0_split_0
I0323 22:48:37.224470  1439 net.cpp:530] pool7 -> pool7
I0323 22:48:37.224578  1439 net.cpp:245] Setting up pool7
I0323 22:48:37.224596  1439 net.cpp:252] TEST Top shape for layer 41 'pool7' 4 512 3 6 (36864)
I0323 22:48:37.224608  1439 layer_factory.hpp:136] Creating layer 'pool7_pool7_0_split' of type 'Split'
I0323 22:48:37.224619  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.224635  1439 net.cpp:184] Created Layer pool7_pool7_0_split (42)
I0323 22:48:37.224647  1439 net.cpp:561] pool7_pool7_0_split <- pool7
I0323 22:48:37.224659  1439 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_0
I0323 22:48:37.224678  1439 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_1
I0323 22:48:37.224761  1439 net.cpp:245] Setting up pool7_pool7_0_split
I0323 22:48:37.224778  1439 net.cpp:252] TEST Top shape for layer 42 'pool7_pool7_0_split' 4 512 3 6 (36864)
I0323 22:48:37.224793  1439 net.cpp:252] TEST Top shape for layer 42 'pool7_pool7_0_split' 4 512 3 6 (36864)
I0323 22:48:37.224805  1439 layer_factory.hpp:136] Creating layer 'pool8' of type 'Pooling'
I0323 22:48:37.224825  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.224845  1439 net.cpp:184] Created Layer pool8 (43)
I0323 22:48:37.224856  1439 net.cpp:561] pool8 <- pool7_pool7_0_split_0
I0323 22:48:37.224870  1439 net.cpp:530] pool8 -> pool8
I0323 22:48:37.224983  1439 net.cpp:245] Setting up pool8
I0323 22:48:37.224999  1439 net.cpp:252] TEST Top shape for layer 43 'pool8' 4 512 2 3 (12288)
I0323 22:48:37.225013  1439 layer_factory.hpp:136] Creating layer 'pool8_pool8_0_split' of type 'Split'
I0323 22:48:37.225024  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.225039  1439 net.cpp:184] Created Layer pool8_pool8_0_split (44)
I0323 22:48:37.225049  1439 net.cpp:561] pool8_pool8_0_split <- pool8
I0323 22:48:37.225062  1439 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_0
I0323 22:48:37.225078  1439 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_1
I0323 22:48:37.225160  1439 net.cpp:245] Setting up pool8_pool8_0_split
I0323 22:48:37.225177  1439 net.cpp:252] TEST Top shape for layer 44 'pool8_pool8_0_split' 4 512 2 3 (12288)
I0323 22:48:37.225191  1439 net.cpp:252] TEST Top shape for layer 44 'pool8_pool8_0_split' 4 512 2 3 (12288)
I0323 22:48:37.225203  1439 layer_factory.hpp:136] Creating layer 'pool9' of type 'Pooling'
I0323 22:48:37.225215  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.225234  1439 net.cpp:184] Created Layer pool9 (45)
I0323 22:48:37.225245  1439 net.cpp:561] pool9 <- pool8_pool8_0_split_0
I0323 22:48:37.225258  1439 net.cpp:530] pool9 -> pool9
I0323 22:48:37.225370  1439 net.cpp:245] Setting up pool9
I0323 22:48:37.225386  1439 net.cpp:252] TEST Top shape for layer 45 'pool9' 4 512 1 2 (4096)
I0323 22:48:37.225399  1439 layer_factory.hpp:136] Creating layer 'ctx_output1' of type 'Convolution'
I0323 22:48:37.225411  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.225437  1439 net.cpp:184] Created Layer ctx_output1 (46)
I0323 22:48:37.225450  1439 net.cpp:561] ctx_output1 <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0323 22:48:37.225464  1439 net.cpp:530] ctx_output1 -> ctx_output1
I0323 22:48:37.227031  1439 net.cpp:245] Setting up ctx_output1
I0323 22:48:37.227051  1439 net.cpp:252] TEST Top shape for layer 46 'ctx_output1' 4 256 40 96 (3932160)
I0323 22:48:37.227069  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu' of type 'ReLU'
I0323 22:48:37.227080  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.227097  1439 net.cpp:184] Created Layer ctx_output1/relu (47)
I0323 22:48:37.227109  1439 net.cpp:561] ctx_output1/relu <- ctx_output1
I0323 22:48:37.227123  1439 net.cpp:513] ctx_output1/relu -> ctx_output1 (in-place)
I0323 22:48:37.227138  1439 net.cpp:245] Setting up ctx_output1/relu
I0323 22:48:37.227150  1439 net.cpp:252] TEST Top shape for layer 47 'ctx_output1/relu' 4 256 40 96 (3932160)
I0323 22:48:37.227162  1439 layer_factory.hpp:136] Creating layer 'ctx_output1_ctx_output1/relu_0_split' of type 'Split'
I0323 22:48:37.227174  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.227187  1439 net.cpp:184] Created Layer ctx_output1_ctx_output1/relu_0_split (48)
I0323 22:48:37.227198  1439 net.cpp:561] ctx_output1_ctx_output1/relu_0_split <- ctx_output1
I0323 22:48:37.227213  1439 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_0
I0323 22:48:37.227227  1439 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_1
I0323 22:48:37.227241  1439 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_2
I0323 22:48:37.227355  1439 net.cpp:245] Setting up ctx_output1_ctx_output1/relu_0_split
I0323 22:48:37.227372  1439 net.cpp:252] TEST Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 4 256 40 96 (3932160)
I0323 22:48:37.227397  1439 net.cpp:252] TEST Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 4 256 40 96 (3932160)
I0323 22:48:37.227412  1439 net.cpp:252] TEST Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 4 256 40 96 (3932160)
I0323 22:48:37.227423  1439 layer_factory.hpp:136] Creating layer 'ctx_output2' of type 'Convolution'
I0323 22:48:37.227435  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.227461  1439 net.cpp:184] Created Layer ctx_output2 (49)
I0323 22:48:37.227473  1439 net.cpp:561] ctx_output2 <- res5a_branch2b_res5a_branch2b/relu_0_split_1
I0323 22:48:37.227488  1439 net.cpp:530] ctx_output2 -> ctx_output2
I0323 22:48:37.232197  1439 net.cpp:245] Setting up ctx_output2
I0323 22:48:37.232230  1439 net.cpp:252] TEST Top shape for layer 49 'ctx_output2' 4 256 10 24 (245760)
I0323 22:48:37.232250  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu' of type 'ReLU'
I0323 22:48:37.232264  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.232283  1439 net.cpp:184] Created Layer ctx_output2/relu (50)
I0323 22:48:37.232296  1439 net.cpp:561] ctx_output2/relu <- ctx_output2
I0323 22:48:37.232311  1439 net.cpp:513] ctx_output2/relu -> ctx_output2 (in-place)
I0323 22:48:37.232328  1439 net.cpp:245] Setting up ctx_output2/relu
I0323 22:48:37.232342  1439 net.cpp:252] TEST Top shape for layer 50 'ctx_output2/relu' 4 256 10 24 (245760)
I0323 22:48:37.232353  1439 layer_factory.hpp:136] Creating layer 'ctx_output2_ctx_output2/relu_0_split' of type 'Split'
I0323 22:48:37.232365  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.232383  1439 net.cpp:184] Created Layer ctx_output2_ctx_output2/relu_0_split (51)
I0323 22:48:37.232393  1439 net.cpp:561] ctx_output2_ctx_output2/relu_0_split <- ctx_output2
I0323 22:48:37.232406  1439 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_0
I0323 22:48:37.232421  1439 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_1
I0323 22:48:37.232434  1439 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_2
I0323 22:48:37.232551  1439 net.cpp:245] Setting up ctx_output2_ctx_output2/relu_0_split
I0323 22:48:37.232571  1439 net.cpp:252] TEST Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 4 256 10 24 (245760)
I0323 22:48:37.232586  1439 net.cpp:252] TEST Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 4 256 10 24 (245760)
I0323 22:48:37.232599  1439 net.cpp:252] TEST Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 4 256 10 24 (245760)
I0323 22:48:37.232611  1439 layer_factory.hpp:136] Creating layer 'ctx_output3' of type 'Convolution'
I0323 22:48:37.232623  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.232650  1439 net.cpp:184] Created Layer ctx_output3 (52)
I0323 22:48:37.232663  1439 net.cpp:561] ctx_output3 <- pool6_pool6_0_split_1
I0323 22:48:37.232677  1439 net.cpp:530] ctx_output3 -> ctx_output3
I0323 22:48:37.238481  1439 net.cpp:245] Setting up ctx_output3
I0323 22:48:37.238507  1439 net.cpp:252] TEST Top shape for layer 52 'ctx_output3' 4 256 5 12 (61440)
I0323 22:48:37.238526  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu' of type 'ReLU'
I0323 22:48:37.238539  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.238554  1439 net.cpp:184] Created Layer ctx_output3/relu (53)
I0323 22:48:37.238566  1439 net.cpp:561] ctx_output3/relu <- ctx_output3
I0323 22:48:37.238579  1439 net.cpp:513] ctx_output3/relu -> ctx_output3 (in-place)
I0323 22:48:37.238598  1439 net.cpp:245] Setting up ctx_output3/relu
I0323 22:48:37.238611  1439 net.cpp:252] TEST Top shape for layer 53 'ctx_output3/relu' 4 256 5 12 (61440)
I0323 22:48:37.238623  1439 layer_factory.hpp:136] Creating layer 'ctx_output3_ctx_output3/relu_0_split' of type 'Split'
I0323 22:48:37.238648  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.238663  1439 net.cpp:184] Created Layer ctx_output3_ctx_output3/relu_0_split (54)
I0323 22:48:37.238674  1439 net.cpp:561] ctx_output3_ctx_output3/relu_0_split <- ctx_output3
I0323 22:48:37.238688  1439 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_0
I0323 22:48:37.238704  1439 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_1
I0323 22:48:37.238718  1439 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_2
I0323 22:48:37.238833  1439 net.cpp:245] Setting up ctx_output3_ctx_output3/relu_0_split
I0323 22:48:37.238850  1439 net.cpp:252] TEST Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 4 256 5 12 (61440)
I0323 22:48:37.238865  1439 net.cpp:252] TEST Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 4 256 5 12 (61440)
I0323 22:48:37.238879  1439 net.cpp:252] TEST Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 4 256 5 12 (61440)
I0323 22:48:37.238891  1439 layer_factory.hpp:136] Creating layer 'ctx_output4' of type 'Convolution'
I0323 22:48:37.238903  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.238929  1439 net.cpp:184] Created Layer ctx_output4 (55)
I0323 22:48:37.238941  1439 net.cpp:561] ctx_output4 <- pool7_pool7_0_split_1
I0323 22:48:37.238956  1439 net.cpp:530] ctx_output4 -> ctx_output4
I0323 22:48:37.243552  1439 net.cpp:245] Setting up ctx_output4
I0323 22:48:37.243582  1439 net.cpp:252] TEST Top shape for layer 55 'ctx_output4' 4 256 3 6 (18432)
I0323 22:48:37.243600  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu' of type 'ReLU'
I0323 22:48:37.243613  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.243631  1439 net.cpp:184] Created Layer ctx_output4/relu (56)
I0323 22:48:37.243647  1439 net.cpp:561] ctx_output4/relu <- ctx_output4
I0323 22:48:37.243660  1439 net.cpp:513] ctx_output4/relu -> ctx_output4 (in-place)
I0323 22:48:37.243679  1439 net.cpp:245] Setting up ctx_output4/relu
I0323 22:48:37.243692  1439 net.cpp:252] TEST Top shape for layer 56 'ctx_output4/relu' 4 256 3 6 (18432)
I0323 22:48:37.243705  1439 layer_factory.hpp:136] Creating layer 'ctx_output4_ctx_output4/relu_0_split' of type 'Split'
I0323 22:48:37.243716  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.243731  1439 net.cpp:184] Created Layer ctx_output4_ctx_output4/relu_0_split (57)
I0323 22:48:37.243742  1439 net.cpp:561] ctx_output4_ctx_output4/relu_0_split <- ctx_output4
I0323 22:48:37.243755  1439 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_0
I0323 22:48:37.243770  1439 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_1
I0323 22:48:37.243787  1439 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_2
I0323 22:48:37.244882  1439 net.cpp:245] Setting up ctx_output4_ctx_output4/relu_0_split
I0323 22:48:37.244899  1439 net.cpp:252] TEST Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 4 256 3 6 (18432)
I0323 22:48:37.244915  1439 net.cpp:252] TEST Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 4 256 3 6 (18432)
I0323 22:48:37.244927  1439 net.cpp:252] TEST Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 4 256 3 6 (18432)
I0323 22:48:37.244940  1439 layer_factory.hpp:136] Creating layer 'ctx_output5' of type 'Convolution'
I0323 22:48:37.244951  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.244979  1439 net.cpp:184] Created Layer ctx_output5 (58)
I0323 22:48:37.244992  1439 net.cpp:561] ctx_output5 <- pool8_pool8_0_split_1
I0323 22:48:37.245007  1439 net.cpp:530] ctx_output5 -> ctx_output5
I0323 22:48:37.249682  1439 net.cpp:245] Setting up ctx_output5
I0323 22:48:37.249727  1439 net.cpp:252] TEST Top shape for layer 58 'ctx_output5' 4 256 2 3 (6144)
I0323 22:48:37.249753  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu' of type 'ReLU'
I0323 22:48:37.249766  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.249783  1439 net.cpp:184] Created Layer ctx_output5/relu (59)
I0323 22:48:37.249796  1439 net.cpp:561] ctx_output5/relu <- ctx_output5
I0323 22:48:37.249810  1439 net.cpp:513] ctx_output5/relu -> ctx_output5 (in-place)
I0323 22:48:37.249827  1439 net.cpp:245] Setting up ctx_output5/relu
I0323 22:48:37.249840  1439 net.cpp:252] TEST Top shape for layer 59 'ctx_output5/relu' 4 256 2 3 (6144)
I0323 22:48:37.249852  1439 layer_factory.hpp:136] Creating layer 'ctx_output5_ctx_output5/relu_0_split' of type 'Split'
I0323 22:48:37.249864  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.249881  1439 net.cpp:184] Created Layer ctx_output5_ctx_output5/relu_0_split (60)
I0323 22:48:37.249891  1439 net.cpp:561] ctx_output5_ctx_output5/relu_0_split <- ctx_output5
I0323 22:48:37.249904  1439 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_0
I0323 22:48:37.249918  1439 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_1
I0323 22:48:37.249938  1439 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_2
I0323 22:48:37.250051  1439 net.cpp:245] Setting up ctx_output5_ctx_output5/relu_0_split
I0323 22:48:37.250068  1439 net.cpp:252] TEST Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 4 256 2 3 (6144)
I0323 22:48:37.250083  1439 net.cpp:252] TEST Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 4 256 2 3 (6144)
I0323 22:48:37.250097  1439 net.cpp:252] TEST Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 4 256 2 3 (6144)
I0323 22:48:37.250108  1439 layer_factory.hpp:136] Creating layer 'ctx_output6' of type 'Convolution'
I0323 22:48:37.250120  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.250150  1439 net.cpp:184] Created Layer ctx_output6 (61)
I0323 22:48:37.250164  1439 net.cpp:561] ctx_output6 <- pool9
I0323 22:48:37.250178  1439 net.cpp:530] ctx_output6 -> ctx_output6
I0323 22:48:37.254750  1439 net.cpp:245] Setting up ctx_output6
I0323 22:48:37.254768  1439 net.cpp:252] TEST Top shape for layer 61 'ctx_output6' 4 256 1 2 (2048)
I0323 22:48:37.254791  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu' of type 'ReLU'
I0323 22:48:37.254802  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.254819  1439 net.cpp:184] Created Layer ctx_output6/relu (62)
I0323 22:48:37.254832  1439 net.cpp:561] ctx_output6/relu <- ctx_output6
I0323 22:48:37.254844  1439 net.cpp:513] ctx_output6/relu -> ctx_output6 (in-place)
I0323 22:48:37.254860  1439 net.cpp:245] Setting up ctx_output6/relu
I0323 22:48:37.254873  1439 net.cpp:252] TEST Top shape for layer 62 'ctx_output6/relu' 4 256 1 2 (2048)
I0323 22:48:37.254885  1439 layer_factory.hpp:136] Creating layer 'ctx_output6_ctx_output6/relu_0_split' of type 'Split'
I0323 22:48:37.254896  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.254914  1439 net.cpp:184] Created Layer ctx_output6_ctx_output6/relu_0_split (63)
I0323 22:48:37.254925  1439 net.cpp:561] ctx_output6_ctx_output6/relu_0_split <- ctx_output6
I0323 22:48:37.254938  1439 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_0
I0323 22:48:37.254952  1439 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_1
I0323 22:48:37.254968  1439 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_2
I0323 22:48:37.255084  1439 net.cpp:245] Setting up ctx_output6_ctx_output6/relu_0_split
I0323 22:48:37.255115  1439 net.cpp:252] TEST Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 4 256 1 2 (2048)
I0323 22:48:37.255131  1439 net.cpp:252] TEST Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 4 256 1 2 (2048)
I0323 22:48:37.255143  1439 net.cpp:252] TEST Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 4 256 1 2 (2048)
I0323 22:48:37.255156  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc' of type 'Convolution'
I0323 22:48:37.255167  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.255197  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc (64)
I0323 22:48:37.255208  1439 net.cpp:561] ctx_output1/relu_mbox_loc <- ctx_output1_ctx_output1/relu_0_split_0
I0323 22:48:37.255223  1439 net.cpp:530] ctx_output1/relu_mbox_loc -> ctx_output1/relu_mbox_loc
I0323 22:48:37.255892  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_loc
I0323 22:48:37.255909  1439 net.cpp:252] TEST Top shape for layer 64 'ctx_output1/relu_mbox_loc' 4 16 40 96 (245760)
I0323 22:48:37.255929  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_perm' of type 'Permute'
I0323 22:48:37.255940  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.255960  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_perm (65)
I0323 22:48:37.255971  1439 net.cpp:561] ctx_output1/relu_mbox_loc_perm <- ctx_output1/relu_mbox_loc
I0323 22:48:37.255985  1439 net.cpp:530] ctx_output1/relu_mbox_loc_perm -> ctx_output1/relu_mbox_loc_perm
I0323 22:48:37.256201  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_perm
I0323 22:48:37.256217  1439 net.cpp:252] TEST Top shape for layer 65 'ctx_output1/relu_mbox_loc_perm' 4 40 96 16 (245760)
I0323 22:48:37.256230  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_flat' of type 'Flatten'
I0323 22:48:37.256242  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.256258  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_flat (66)
I0323 22:48:37.256268  1439 net.cpp:561] ctx_output1/relu_mbox_loc_flat <- ctx_output1/relu_mbox_loc_perm
I0323 22:48:37.256283  1439 net.cpp:530] ctx_output1/relu_mbox_loc_flat -> ctx_output1/relu_mbox_loc_flat
I0323 22:48:37.256341  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_flat
I0323 22:48:37.256358  1439 net.cpp:252] TEST Top shape for layer 66 'ctx_output1/relu_mbox_loc_flat' 4 61440 (245760)
I0323 22:48:37.256372  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf' of type 'Convolution'
I0323 22:48:37.256384  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.256409  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf (67)
I0323 22:48:37.256422  1439 net.cpp:561] ctx_output1/relu_mbox_conf <- ctx_output1_ctx_output1/relu_0_split_1
I0323 22:48:37.256436  1439 net.cpp:530] ctx_output1/relu_mbox_conf -> ctx_output1/relu_mbox_conf
I0323 22:48:37.257087  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_conf
I0323 22:48:37.257105  1439 net.cpp:252] TEST Top shape for layer 67 'ctx_output1/relu_mbox_conf' 4 16 40 96 (245760)
I0323 22:48:37.257124  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_perm' of type 'Permute'
I0323 22:48:37.257135  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.257155  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_perm (68)
I0323 22:48:37.257166  1439 net.cpp:561] ctx_output1/relu_mbox_conf_perm <- ctx_output1/relu_mbox_conf
I0323 22:48:37.257180  1439 net.cpp:530] ctx_output1/relu_mbox_conf_perm -> ctx_output1/relu_mbox_conf_perm
I0323 22:48:37.257397  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_perm
I0323 22:48:37.257414  1439 net.cpp:252] TEST Top shape for layer 68 'ctx_output1/relu_mbox_conf_perm' 4 40 96 16 (245760)
I0323 22:48:37.257436  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_flat' of type 'Flatten'
I0323 22:48:37.257449  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.257463  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_flat (69)
I0323 22:48:37.257475  1439 net.cpp:561] ctx_output1/relu_mbox_conf_flat <- ctx_output1/relu_mbox_conf_perm
I0323 22:48:37.257489  1439 net.cpp:530] ctx_output1/relu_mbox_conf_flat -> ctx_output1/relu_mbox_conf_flat
I0323 22:48:37.257546  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_flat
I0323 22:48:37.257563  1439 net.cpp:252] TEST Top shape for layer 69 'ctx_output1/relu_mbox_conf_flat' 4 61440 (245760)
I0323 22:48:37.257576  1439 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_priorbox' of type 'PriorBox'
I0323 22:48:37.257588  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.257607  1439 net.cpp:184] Created Layer ctx_output1/relu_mbox_priorbox (70)
I0323 22:48:37.257618  1439 net.cpp:561] ctx_output1/relu_mbox_priorbox <- ctx_output1_ctx_output1/relu_0_split_2
I0323 22:48:37.257632  1439 net.cpp:561] ctx_output1/relu_mbox_priorbox <- data_data_0_split_1
I0323 22:48:37.257647  1439 net.cpp:530] ctx_output1/relu_mbox_priorbox -> ctx_output1/relu_mbox_priorbox
I0323 22:48:37.257711  1439 net.cpp:245] Setting up ctx_output1/relu_mbox_priorbox
I0323 22:48:37.257728  1439 net.cpp:252] TEST Top shape for layer 70 'ctx_output1/relu_mbox_priorbox' 1 2 61440 (122880)
I0323 22:48:37.257742  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc' of type 'Convolution'
I0323 22:48:37.257753  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.257779  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc (71)
I0323 22:48:37.257791  1439 net.cpp:561] ctx_output2/relu_mbox_loc <- ctx_output2_ctx_output2/relu_0_split_0
I0323 22:48:37.257805  1439 net.cpp:530] ctx_output2/relu_mbox_loc -> ctx_output2/relu_mbox_loc
I0323 22:48:37.258532  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_loc
I0323 22:48:37.258549  1439 net.cpp:252] TEST Top shape for layer 71 'ctx_output2/relu_mbox_loc' 4 24 10 24 (23040)
I0323 22:48:37.258569  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_perm' of type 'Permute'
I0323 22:48:37.258579  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.258599  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_perm (72)
I0323 22:48:37.258611  1439 net.cpp:561] ctx_output2/relu_mbox_loc_perm <- ctx_output2/relu_mbox_loc
I0323 22:48:37.258625  1439 net.cpp:530] ctx_output2/relu_mbox_loc_perm -> ctx_output2/relu_mbox_loc_perm
I0323 22:48:37.258839  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_perm
I0323 22:48:37.258857  1439 net.cpp:252] TEST Top shape for layer 72 'ctx_output2/relu_mbox_loc_perm' 4 10 24 24 (23040)
I0323 22:48:37.258869  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_flat' of type 'Flatten'
I0323 22:48:37.258882  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.258898  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_flat (73)
I0323 22:48:37.258910  1439 net.cpp:561] ctx_output2/relu_mbox_loc_flat <- ctx_output2/relu_mbox_loc_perm
I0323 22:48:37.258924  1439 net.cpp:530] ctx_output2/relu_mbox_loc_flat -> ctx_output2/relu_mbox_loc_flat
I0323 22:48:37.258980  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_flat
I0323 22:48:37.258996  1439 net.cpp:252] TEST Top shape for layer 73 'ctx_output2/relu_mbox_loc_flat' 4 5760 (23040)
I0323 22:48:37.259009  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf' of type 'Convolution'
I0323 22:48:37.259021  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.259047  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf (74)
I0323 22:48:37.259068  1439 net.cpp:561] ctx_output2/relu_mbox_conf <- ctx_output2_ctx_output2/relu_0_split_1
I0323 22:48:37.259084  1439 net.cpp:530] ctx_output2/relu_mbox_conf -> ctx_output2/relu_mbox_conf
I0323 22:48:37.259871  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_conf
I0323 22:48:37.259908  1439 net.cpp:252] TEST Top shape for layer 74 'ctx_output2/relu_mbox_conf' 4 24 10 24 (23040)
I0323 22:48:37.259928  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_perm' of type 'Permute'
I0323 22:48:37.259943  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.259964  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_perm (75)
I0323 22:48:37.259979  1439 net.cpp:561] ctx_output2/relu_mbox_conf_perm <- ctx_output2/relu_mbox_conf
I0323 22:48:37.259994  1439 net.cpp:530] ctx_output2/relu_mbox_conf_perm -> ctx_output2/relu_mbox_conf_perm
I0323 22:48:37.260212  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_perm
I0323 22:48:37.260231  1439 net.cpp:252] TEST Top shape for layer 75 'ctx_output2/relu_mbox_conf_perm' 4 10 24 24 (23040)
I0323 22:48:37.260243  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_flat' of type 'Flatten'
I0323 22:48:37.260255  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.260270  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_flat (76)
I0323 22:48:37.260282  1439 net.cpp:561] ctx_output2/relu_mbox_conf_flat <- ctx_output2/relu_mbox_conf_perm
I0323 22:48:37.260296  1439 net.cpp:530] ctx_output2/relu_mbox_conf_flat -> ctx_output2/relu_mbox_conf_flat
I0323 22:48:37.260354  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_flat
I0323 22:48:37.260370  1439 net.cpp:252] TEST Top shape for layer 76 'ctx_output2/relu_mbox_conf_flat' 4 5760 (23040)
I0323 22:48:37.260383  1439 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_priorbox' of type 'PriorBox'
I0323 22:48:37.260396  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.260413  1439 net.cpp:184] Created Layer ctx_output2/relu_mbox_priorbox (77)
I0323 22:48:37.260426  1439 net.cpp:561] ctx_output2/relu_mbox_priorbox <- ctx_output2_ctx_output2/relu_0_split_2
I0323 22:48:37.260437  1439 net.cpp:561] ctx_output2/relu_mbox_priorbox <- data_data_0_split_2
I0323 22:48:37.260444  1439 net.cpp:530] ctx_output2/relu_mbox_priorbox -> ctx_output2/relu_mbox_priorbox
I0323 22:48:37.260499  1439 net.cpp:245] Setting up ctx_output2/relu_mbox_priorbox
I0323 22:48:37.260509  1439 net.cpp:252] TEST Top shape for layer 77 'ctx_output2/relu_mbox_priorbox' 1 2 5760 (11520)
I0323 22:48:37.260517  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc' of type 'Convolution'
I0323 22:48:37.260524  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.260540  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc (78)
I0323 22:48:37.260548  1439 net.cpp:561] ctx_output3/relu_mbox_loc <- ctx_output3_ctx_output3/relu_0_split_0
I0323 22:48:37.260556  1439 net.cpp:530] ctx_output3/relu_mbox_loc -> ctx_output3/relu_mbox_loc
I0323 22:48:37.261277  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_loc
I0323 22:48:37.261291  1439 net.cpp:252] TEST Top shape for layer 78 'ctx_output3/relu_mbox_loc' 4 24 5 12 (5760)
I0323 22:48:37.261301  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_perm' of type 'Permute'
I0323 22:48:37.261307  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.261318  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_perm (79)
I0323 22:48:37.261325  1439 net.cpp:561] ctx_output3/relu_mbox_loc_perm <- ctx_output3/relu_mbox_loc
I0323 22:48:37.261332  1439 net.cpp:530] ctx_output3/relu_mbox_loc_perm -> ctx_output3/relu_mbox_loc_perm
I0323 22:48:37.261540  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_perm
I0323 22:48:37.261553  1439 net.cpp:252] TEST Top shape for layer 79 'ctx_output3/relu_mbox_loc_perm' 4 5 12 24 (5760)
I0323 22:48:37.261572  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_flat' of type 'Flatten'
I0323 22:48:37.261579  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.261589  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_flat (80)
I0323 22:48:37.261595  1439 net.cpp:561] ctx_output3/relu_mbox_loc_flat <- ctx_output3/relu_mbox_loc_perm
I0323 22:48:37.261600  1439 net.cpp:530] ctx_output3/relu_mbox_loc_flat -> ctx_output3/relu_mbox_loc_flat
I0323 22:48:37.261648  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_flat
I0323 22:48:37.261659  1439 net.cpp:252] TEST Top shape for layer 80 'ctx_output3/relu_mbox_loc_flat' 4 1440 (5760)
I0323 22:48:37.261667  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf' of type 'Convolution'
I0323 22:48:37.261672  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.261688  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf (81)
I0323 22:48:37.261718  1439 net.cpp:561] ctx_output3/relu_mbox_conf <- ctx_output3_ctx_output3/relu_0_split_1
I0323 22:48:37.261726  1439 net.cpp:530] ctx_output3/relu_mbox_conf -> ctx_output3/relu_mbox_conf
I0323 22:48:37.262441  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_conf
I0323 22:48:37.262454  1439 net.cpp:252] TEST Top shape for layer 81 'ctx_output3/relu_mbox_conf' 4 24 5 12 (5760)
I0323 22:48:37.262465  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_perm' of type 'Permute'
I0323 22:48:37.262470  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.262481  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_perm (82)
I0323 22:48:37.262490  1439 net.cpp:561] ctx_output3/relu_mbox_conf_perm <- ctx_output3/relu_mbox_conf
I0323 22:48:37.262495  1439 net.cpp:530] ctx_output3/relu_mbox_conf_perm -> ctx_output3/relu_mbox_conf_perm
I0323 22:48:37.262706  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_perm
I0323 22:48:37.262718  1439 net.cpp:252] TEST Top shape for layer 82 'ctx_output3/relu_mbox_conf_perm' 4 5 12 24 (5760)
I0323 22:48:37.262725  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_flat' of type 'Flatten'
I0323 22:48:37.262730  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.262739  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_flat (83)
I0323 22:48:37.262745  1439 net.cpp:561] ctx_output3/relu_mbox_conf_flat <- ctx_output3/relu_mbox_conf_perm
I0323 22:48:37.262753  1439 net.cpp:530] ctx_output3/relu_mbox_conf_flat -> ctx_output3/relu_mbox_conf_flat
I0323 22:48:37.262799  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_flat
I0323 22:48:37.262810  1439 net.cpp:252] TEST Top shape for layer 83 'ctx_output3/relu_mbox_conf_flat' 4 1440 (5760)
I0323 22:48:37.262816  1439 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_priorbox' of type 'PriorBox'
I0323 22:48:37.262822  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.262830  1439 net.cpp:184] Created Layer ctx_output3/relu_mbox_priorbox (84)
I0323 22:48:37.262835  1439 net.cpp:561] ctx_output3/relu_mbox_priorbox <- ctx_output3_ctx_output3/relu_0_split_2
I0323 22:48:37.262842  1439 net.cpp:561] ctx_output3/relu_mbox_priorbox <- data_data_0_split_3
I0323 22:48:37.262850  1439 net.cpp:530] ctx_output3/relu_mbox_priorbox -> ctx_output3/relu_mbox_priorbox
I0323 22:48:37.262898  1439 net.cpp:245] Setting up ctx_output3/relu_mbox_priorbox
I0323 22:48:37.262909  1439 net.cpp:252] TEST Top shape for layer 84 'ctx_output3/relu_mbox_priorbox' 1 2 1440 (2880)
I0323 22:48:37.262917  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc' of type 'Convolution'
I0323 22:48:37.262922  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.262946  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc (85)
I0323 22:48:37.262954  1439 net.cpp:561] ctx_output4/relu_mbox_loc <- ctx_output4_ctx_output4/relu_0_split_0
I0323 22:48:37.262961  1439 net.cpp:530] ctx_output4/relu_mbox_loc -> ctx_output4/relu_mbox_loc
I0323 22:48:37.263681  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_loc
I0323 22:48:37.263695  1439 net.cpp:252] TEST Top shape for layer 85 'ctx_output4/relu_mbox_loc' 4 24 3 6 (1728)
I0323 22:48:37.263705  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_perm' of type 'Permute'
I0323 22:48:37.263710  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.263721  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_perm (86)
I0323 22:48:37.263728  1439 net.cpp:561] ctx_output4/relu_mbox_loc_perm <- ctx_output4/relu_mbox_loc
I0323 22:48:37.263734  1439 net.cpp:530] ctx_output4/relu_mbox_loc_perm -> ctx_output4/relu_mbox_loc_perm
I0323 22:48:37.263942  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_perm
I0323 22:48:37.263954  1439 net.cpp:252] TEST Top shape for layer 86 'ctx_output4/relu_mbox_loc_perm' 4 3 6 24 (1728)
I0323 22:48:37.263960  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_flat' of type 'Flatten'
I0323 22:48:37.263967  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.263973  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_flat (87)
I0323 22:48:37.263979  1439 net.cpp:561] ctx_output4/relu_mbox_loc_flat <- ctx_output4/relu_mbox_loc_perm
I0323 22:48:37.263985  1439 net.cpp:530] ctx_output4/relu_mbox_loc_flat -> ctx_output4/relu_mbox_loc_flat
I0323 22:48:37.264032  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_flat
I0323 22:48:37.264044  1439 net.cpp:252] TEST Top shape for layer 87 'ctx_output4/relu_mbox_loc_flat' 4 432 (1728)
I0323 22:48:37.264050  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf' of type 'Convolution'
I0323 22:48:37.264055  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.264073  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf (88)
I0323 22:48:37.264081  1439 net.cpp:561] ctx_output4/relu_mbox_conf <- ctx_output4_ctx_output4/relu_0_split_1
I0323 22:48:37.264087  1439 net.cpp:530] ctx_output4/relu_mbox_conf -> ctx_output4/relu_mbox_conf
I0323 22:48:37.264806  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_conf
I0323 22:48:37.264818  1439 net.cpp:252] TEST Top shape for layer 88 'ctx_output4/relu_mbox_conf' 4 24 3 6 (1728)
I0323 22:48:37.264827  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_perm' of type 'Permute'
I0323 22:48:37.264833  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.264845  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_perm (89)
I0323 22:48:37.264853  1439 net.cpp:561] ctx_output4/relu_mbox_conf_perm <- ctx_output4/relu_mbox_conf
I0323 22:48:37.264859  1439 net.cpp:530] ctx_output4/relu_mbox_conf_perm -> ctx_output4/relu_mbox_conf_perm
I0323 22:48:37.265069  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_perm
I0323 22:48:37.265081  1439 net.cpp:252] TEST Top shape for layer 89 'ctx_output4/relu_mbox_conf_perm' 4 3 6 24 (1728)
I0323 22:48:37.265087  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_flat' of type 'Flatten'
I0323 22:48:37.265092  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.265100  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_flat (90)
I0323 22:48:37.265105  1439 net.cpp:561] ctx_output4/relu_mbox_conf_flat <- ctx_output4/relu_mbox_conf_perm
I0323 22:48:37.265112  1439 net.cpp:530] ctx_output4/relu_mbox_conf_flat -> ctx_output4/relu_mbox_conf_flat
I0323 22:48:37.265159  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_flat
I0323 22:48:37.265170  1439 net.cpp:252] TEST Top shape for layer 90 'ctx_output4/relu_mbox_conf_flat' 4 432 (1728)
I0323 22:48:37.265185  1439 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_priorbox' of type 'PriorBox'
I0323 22:48:37.265192  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.265199  1439 net.cpp:184] Created Layer ctx_output4/relu_mbox_priorbox (91)
I0323 22:48:37.265205  1439 net.cpp:561] ctx_output4/relu_mbox_priorbox <- ctx_output4_ctx_output4/relu_0_split_2
I0323 22:48:37.265213  1439 net.cpp:561] ctx_output4/relu_mbox_priorbox <- data_data_0_split_4
I0323 22:48:37.265219  1439 net.cpp:530] ctx_output4/relu_mbox_priorbox -> ctx_output4/relu_mbox_priorbox
I0323 22:48:37.265269  1439 net.cpp:245] Setting up ctx_output4/relu_mbox_priorbox
I0323 22:48:37.265280  1439 net.cpp:252] TEST Top shape for layer 91 'ctx_output4/relu_mbox_priorbox' 1 2 432 (864)
I0323 22:48:37.265286  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc' of type 'Convolution'
I0323 22:48:37.265292  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.265311  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc (92)
I0323 22:48:37.265318  1439 net.cpp:561] ctx_output5/relu_mbox_loc <- ctx_output5_ctx_output5/relu_0_split_0
I0323 22:48:37.265326  1439 net.cpp:530] ctx_output5/relu_mbox_loc -> ctx_output5/relu_mbox_loc
I0323 22:48:37.265995  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_loc
I0323 22:48:37.266008  1439 net.cpp:252] TEST Top shape for layer 92 'ctx_output5/relu_mbox_loc' 4 16 2 3 (384)
I0323 22:48:37.266017  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_perm' of type 'Permute'
I0323 22:48:37.266023  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.266036  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_perm (93)
I0323 22:48:37.266041  1439 net.cpp:561] ctx_output5/relu_mbox_loc_perm <- ctx_output5/relu_mbox_loc
I0323 22:48:37.266048  1439 net.cpp:530] ctx_output5/relu_mbox_loc_perm -> ctx_output5/relu_mbox_loc_perm
I0323 22:48:37.266257  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_perm
I0323 22:48:37.266269  1439 net.cpp:252] TEST Top shape for layer 93 'ctx_output5/relu_mbox_loc_perm' 4 2 3 16 (384)
I0323 22:48:37.266276  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_flat' of type 'Flatten'
I0323 22:48:37.266281  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.266289  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_flat (94)
I0323 22:48:37.266294  1439 net.cpp:561] ctx_output5/relu_mbox_loc_flat <- ctx_output5/relu_mbox_loc_perm
I0323 22:48:37.266301  1439 net.cpp:530] ctx_output5/relu_mbox_loc_flat -> ctx_output5/relu_mbox_loc_flat
I0323 22:48:37.266347  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_flat
I0323 22:48:37.266358  1439 net.cpp:252] TEST Top shape for layer 94 'ctx_output5/relu_mbox_loc_flat' 4 96 (384)
I0323 22:48:37.266366  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf' of type 'Convolution'
I0323 22:48:37.266371  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.266386  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf (95)
I0323 22:48:37.266393  1439 net.cpp:561] ctx_output5/relu_mbox_conf <- ctx_output5_ctx_output5/relu_0_split_1
I0323 22:48:37.266400  1439 net.cpp:530] ctx_output5/relu_mbox_conf -> ctx_output5/relu_mbox_conf
I0323 22:48:37.267055  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_conf
I0323 22:48:37.267067  1439 net.cpp:252] TEST Top shape for layer 95 'ctx_output5/relu_mbox_conf' 4 16 2 3 (384)
I0323 22:48:37.267077  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_perm' of type 'Permute'
I0323 22:48:37.267083  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.267096  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_perm (96)
I0323 22:48:37.267112  1439 net.cpp:561] ctx_output5/relu_mbox_conf_perm <- ctx_output5/relu_mbox_conf
I0323 22:48:37.267119  1439 net.cpp:530] ctx_output5/relu_mbox_conf_perm -> ctx_output5/relu_mbox_conf_perm
I0323 22:48:37.267328  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_perm
I0323 22:48:37.267339  1439 net.cpp:252] TEST Top shape for layer 96 'ctx_output5/relu_mbox_conf_perm' 4 2 3 16 (384)
I0323 22:48:37.267345  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_flat' of type 'Flatten'
I0323 22:48:37.267351  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.267359  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_flat (97)
I0323 22:48:37.267366  1439 net.cpp:561] ctx_output5/relu_mbox_conf_flat <- ctx_output5/relu_mbox_conf_perm
I0323 22:48:37.267372  1439 net.cpp:530] ctx_output5/relu_mbox_conf_flat -> ctx_output5/relu_mbox_conf_flat
I0323 22:48:37.267419  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_flat
I0323 22:48:37.267431  1439 net.cpp:252] TEST Top shape for layer 97 'ctx_output5/relu_mbox_conf_flat' 4 96 (384)
I0323 22:48:37.267436  1439 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_priorbox' of type 'PriorBox'
I0323 22:48:37.267442  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.267449  1439 net.cpp:184] Created Layer ctx_output5/relu_mbox_priorbox (98)
I0323 22:48:37.267455  1439 net.cpp:561] ctx_output5/relu_mbox_priorbox <- ctx_output5_ctx_output5/relu_0_split_2
I0323 22:48:37.267463  1439 net.cpp:561] ctx_output5/relu_mbox_priorbox <- data_data_0_split_5
I0323 22:48:37.267470  1439 net.cpp:530] ctx_output5/relu_mbox_priorbox -> ctx_output5/relu_mbox_priorbox
I0323 22:48:37.267520  1439 net.cpp:245] Setting up ctx_output5/relu_mbox_priorbox
I0323 22:48:37.267531  1439 net.cpp:252] TEST Top shape for layer 98 'ctx_output5/relu_mbox_priorbox' 1 2 96 (192)
I0323 22:48:37.267537  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc' of type 'Convolution'
I0323 22:48:37.267544  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.267560  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc (99)
I0323 22:48:37.267567  1439 net.cpp:561] ctx_output6/relu_mbox_loc <- ctx_output6_ctx_output6/relu_0_split_0
I0323 22:48:37.267573  1439 net.cpp:530] ctx_output6/relu_mbox_loc -> ctx_output6/relu_mbox_loc
I0323 22:48:37.268223  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_loc
I0323 22:48:37.268235  1439 net.cpp:252] TEST Top shape for layer 99 'ctx_output6/relu_mbox_loc' 4 16 1 2 (128)
I0323 22:48:37.268244  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_perm' of type 'Permute'
I0323 22:48:37.268251  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.268262  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_perm (100)
I0323 22:48:37.268270  1439 net.cpp:561] ctx_output6/relu_mbox_loc_perm <- ctx_output6/relu_mbox_loc
I0323 22:48:37.268276  1439 net.cpp:530] ctx_output6/relu_mbox_loc_perm -> ctx_output6/relu_mbox_loc_perm
I0323 22:48:37.268486  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_perm
I0323 22:48:37.268497  1439 net.cpp:252] TEST Top shape for layer 100 'ctx_output6/relu_mbox_loc_perm' 4 1 2 16 (128)
I0323 22:48:37.268503  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_flat' of type 'Flatten'
I0323 22:48:37.268509  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.268517  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_flat (101)
I0323 22:48:37.268522  1439 net.cpp:561] ctx_output6/relu_mbox_loc_flat <- ctx_output6/relu_mbox_loc_perm
I0323 22:48:37.268528  1439 net.cpp:530] ctx_output6/relu_mbox_loc_flat -> ctx_output6/relu_mbox_loc_flat
I0323 22:48:37.268574  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_flat
I0323 22:48:37.268594  1439 net.cpp:252] TEST Top shape for layer 101 'ctx_output6/relu_mbox_loc_flat' 4 32 (128)
I0323 22:48:37.268601  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf' of type 'Convolution'
I0323 22:48:37.268607  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.268625  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf (102)
I0323 22:48:37.268632  1439 net.cpp:561] ctx_output6/relu_mbox_conf <- ctx_output6_ctx_output6/relu_0_split_1
I0323 22:48:37.268640  1439 net.cpp:530] ctx_output6/relu_mbox_conf -> ctx_output6/relu_mbox_conf
I0323 22:48:37.269294  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_conf
I0323 22:48:37.269307  1439 net.cpp:252] TEST Top shape for layer 102 'ctx_output6/relu_mbox_conf' 4 16 1 2 (128)
I0323 22:48:37.269316  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_perm' of type 'Permute'
I0323 22:48:37.269322  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.269333  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_perm (103)
I0323 22:48:37.269340  1439 net.cpp:561] ctx_output6/relu_mbox_conf_perm <- ctx_output6/relu_mbox_conf
I0323 22:48:37.269347  1439 net.cpp:530] ctx_output6/relu_mbox_conf_perm -> ctx_output6/relu_mbox_conf_perm
I0323 22:48:37.269556  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_perm
I0323 22:48:37.269568  1439 net.cpp:252] TEST Top shape for layer 103 'ctx_output6/relu_mbox_conf_perm' 4 1 2 16 (128)
I0323 22:48:37.269574  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_flat' of type 'Flatten'
I0323 22:48:37.269579  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.269587  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_flat (104)
I0323 22:48:37.269593  1439 net.cpp:561] ctx_output6/relu_mbox_conf_flat <- ctx_output6/relu_mbox_conf_perm
I0323 22:48:37.269599  1439 net.cpp:530] ctx_output6/relu_mbox_conf_flat -> ctx_output6/relu_mbox_conf_flat
I0323 22:48:37.269646  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_flat
I0323 22:48:37.269657  1439 net.cpp:252] TEST Top shape for layer 104 'ctx_output6/relu_mbox_conf_flat' 4 32 (128)
I0323 22:48:37.269664  1439 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_priorbox' of type 'PriorBox'
I0323 22:48:37.269670  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.269678  1439 net.cpp:184] Created Layer ctx_output6/relu_mbox_priorbox (105)
I0323 22:48:37.269685  1439 net.cpp:561] ctx_output6/relu_mbox_priorbox <- ctx_output6_ctx_output6/relu_0_split_2
I0323 22:48:37.269698  1439 net.cpp:561] ctx_output6/relu_mbox_priorbox <- data_data_0_split_6
I0323 22:48:37.269706  1439 net.cpp:530] ctx_output6/relu_mbox_priorbox -> ctx_output6/relu_mbox_priorbox
I0323 22:48:37.269754  1439 net.cpp:245] Setting up ctx_output6/relu_mbox_priorbox
I0323 22:48:37.269767  1439 net.cpp:252] TEST Top shape for layer 105 'ctx_output6/relu_mbox_priorbox' 1 2 32 (64)
I0323 22:48:37.269773  1439 layer_factory.hpp:136] Creating layer 'mbox_loc' of type 'Concat'
I0323 22:48:37.269778  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.269788  1439 net.cpp:184] Created Layer mbox_loc (106)
I0323 22:48:37.269794  1439 net.cpp:561] mbox_loc <- ctx_output1/relu_mbox_loc_flat
I0323 22:48:37.269801  1439 net.cpp:561] mbox_loc <- ctx_output2/relu_mbox_loc_flat
I0323 22:48:37.269807  1439 net.cpp:561] mbox_loc <- ctx_output3/relu_mbox_loc_flat
I0323 22:48:37.269814  1439 net.cpp:561] mbox_loc <- ctx_output4/relu_mbox_loc_flat
I0323 22:48:37.269820  1439 net.cpp:561] mbox_loc <- ctx_output5/relu_mbox_loc_flat
I0323 22:48:37.269825  1439 net.cpp:561] mbox_loc <- ctx_output6/relu_mbox_loc_flat
I0323 22:48:37.269831  1439 net.cpp:530] mbox_loc -> mbox_loc
I0323 22:48:37.269883  1439 net.cpp:245] Setting up mbox_loc
I0323 22:48:37.269903  1439 net.cpp:252] TEST Top shape for layer 106 'mbox_loc' 4 69200 (276800)
I0323 22:48:37.269910  1439 layer_factory.hpp:136] Creating layer 'mbox_conf' of type 'Concat'
I0323 22:48:37.269915  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.269923  1439 net.cpp:184] Created Layer mbox_conf (107)
I0323 22:48:37.269929  1439 net.cpp:561] mbox_conf <- ctx_output1/relu_mbox_conf_flat
I0323 22:48:37.269937  1439 net.cpp:561] mbox_conf <- ctx_output2/relu_mbox_conf_flat
I0323 22:48:37.269942  1439 net.cpp:561] mbox_conf <- ctx_output3/relu_mbox_conf_flat
I0323 22:48:37.269948  1439 net.cpp:561] mbox_conf <- ctx_output4/relu_mbox_conf_flat
I0323 22:48:37.269953  1439 net.cpp:561] mbox_conf <- ctx_output5/relu_mbox_conf_flat
I0323 22:48:37.269959  1439 net.cpp:561] mbox_conf <- ctx_output6/relu_mbox_conf_flat
I0323 22:48:37.269964  1439 net.cpp:530] mbox_conf -> mbox_conf
I0323 22:48:37.270015  1439 net.cpp:245] Setting up mbox_conf
I0323 22:48:37.270025  1439 net.cpp:252] TEST Top shape for layer 107 'mbox_conf' 4 69200 (276800)
I0323 22:48:37.270031  1439 layer_factory.hpp:136] Creating layer 'mbox_priorbox' of type 'Concat'
I0323 22:48:37.270037  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.270046  1439 net.cpp:184] Created Layer mbox_priorbox (108)
I0323 22:48:37.270052  1439 net.cpp:561] mbox_priorbox <- ctx_output1/relu_mbox_priorbox
I0323 22:48:37.270059  1439 net.cpp:561] mbox_priorbox <- ctx_output2/relu_mbox_priorbox
I0323 22:48:37.270066  1439 net.cpp:561] mbox_priorbox <- ctx_output3/relu_mbox_priorbox
I0323 22:48:37.270071  1439 net.cpp:561] mbox_priorbox <- ctx_output4/relu_mbox_priorbox
I0323 22:48:37.270076  1439 net.cpp:561] mbox_priorbox <- ctx_output5/relu_mbox_priorbox
I0323 22:48:37.270082  1439 net.cpp:561] mbox_priorbox <- ctx_output6/relu_mbox_priorbox
I0323 22:48:37.270087  1439 net.cpp:530] mbox_priorbox -> mbox_priorbox
I0323 22:48:37.270135  1439 net.cpp:245] Setting up mbox_priorbox
I0323 22:48:37.270148  1439 net.cpp:252] TEST Top shape for layer 108 'mbox_priorbox' 1 2 69200 (138400)
I0323 22:48:37.270153  1439 layer_factory.hpp:136] Creating layer 'mbox_conf_reshape' of type 'Reshape'
I0323 22:48:37.270159  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.270170  1439 net.cpp:184] Created Layer mbox_conf_reshape (109)
I0323 22:48:37.270176  1439 net.cpp:561] mbox_conf_reshape <- mbox_conf
I0323 22:48:37.270182  1439 net.cpp:530] mbox_conf_reshape -> mbox_conf_reshape
I0323 22:48:37.270232  1439 net.cpp:245] Setting up mbox_conf_reshape
I0323 22:48:37.270244  1439 net.cpp:252] TEST Top shape for layer 109 'mbox_conf_reshape' 4 17300 4 (276800)
I0323 22:48:37.270251  1439 layer_factory.hpp:136] Creating layer 'mbox_conf_softmax' of type 'Softmax'
I0323 22:48:37.270256  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.270272  1439 net.cpp:184] Created Layer mbox_conf_softmax (110)
I0323 22:48:37.270279  1439 net.cpp:561] mbox_conf_softmax <- mbox_conf_reshape
I0323 22:48:37.270285  1439 net.cpp:530] mbox_conf_softmax -> mbox_conf_softmax
I0323 22:48:37.270407  1439 net.cpp:245] Setting up mbox_conf_softmax
I0323 22:48:37.270418  1439 net.cpp:252] TEST Top shape for layer 110 'mbox_conf_softmax' 4 17300 4 (276800)
I0323 22:48:37.270424  1439 layer_factory.hpp:136] Creating layer 'mbox_conf_flatten' of type 'Flatten'
I0323 22:48:37.270431  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.270437  1439 net.cpp:184] Created Layer mbox_conf_flatten (111)
I0323 22:48:37.270442  1439 net.cpp:561] mbox_conf_flatten <- mbox_conf_softmax
I0323 22:48:37.270449  1439 net.cpp:530] mbox_conf_flatten -> mbox_conf_flatten
I0323 22:48:37.270498  1439 net.cpp:245] Setting up mbox_conf_flatten
I0323 22:48:37.270509  1439 net.cpp:252] TEST Top shape for layer 111 'mbox_conf_flatten' 4 69200 (276800)
I0323 22:48:37.270524  1439 layer_factory.hpp:136] Creating layer 'detection_out' of type 'DetectionOutput'
I0323 22:48:37.270530  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.270551  1439 net.cpp:184] Created Layer detection_out (112)
I0323 22:48:37.270558  1439 net.cpp:561] detection_out <- mbox_loc
I0323 22:48:37.270565  1439 net.cpp:561] detection_out <- mbox_conf_flatten
I0323 22:48:37.270571  1439 net.cpp:561] detection_out <- mbox_priorbox
I0323 22:48:37.270577  1439 net.cpp:530] detection_out -> detection_out
I0323 22:48:37.272238  1439 net.cpp:245] Setting up detection_out
I0323 22:48:37.272251  1439 net.cpp:252] TEST Top shape for layer 112 'detection_out' 1 1 1 7 (7)
I0323 22:48:37.272258  1439 layer_factory.hpp:136] Creating layer 'detection_eval' of type 'DetectionEvaluate'
I0323 22:48:37.272264  1439 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0323 22:48:37.272274  1439 net.cpp:184] Created Layer detection_eval (113)
I0323 22:48:37.272280  1439 net.cpp:561] detection_eval <- detection_out
I0323 22:48:37.272286  1439 net.cpp:561] detection_eval <- label
I0323 22:48:37.272294  1439 net.cpp:530] detection_eval -> detection_eval
I0323 22:48:37.273342  1439 net.cpp:245] Setting up detection_eval
I0323 22:48:37.273355  1439 net.cpp:252] TEST Top shape for layer 113 'detection_eval' 1 1 4 5 (20)
I0323 22:48:37.273362  1439 net.cpp:325] detection_eval does not need backward computation.
I0323 22:48:37.273367  1439 net.cpp:325] detection_out does not need backward computation.
I0323 22:48:37.273373  1439 net.cpp:325] mbox_conf_flatten does not need backward computation.
I0323 22:48:37.273377  1439 net.cpp:325] mbox_conf_softmax does not need backward computation.
I0323 22:48:37.273382  1439 net.cpp:325] mbox_conf_reshape does not need backward computation.
I0323 22:48:37.273387  1439 net.cpp:325] mbox_priorbox does not need backward computation.
I0323 22:48:37.273393  1439 net.cpp:325] mbox_conf does not need backward computation.
I0323 22:48:37.273401  1439 net.cpp:325] mbox_loc does not need backward computation.
I0323 22:48:37.273406  1439 net.cpp:325] ctx_output6/relu_mbox_priorbox does not need backward computation.
I0323 22:48:37.273412  1439 net.cpp:325] ctx_output6/relu_mbox_conf_flat does not need backward computation.
I0323 22:48:37.273417  1439 net.cpp:325] ctx_output6/relu_mbox_conf_perm does not need backward computation.
I0323 22:48:37.273422  1439 net.cpp:325] ctx_output6/relu_mbox_conf does not need backward computation.
I0323 22:48:37.273427  1439 net.cpp:325] ctx_output6/relu_mbox_loc_flat does not need backward computation.
I0323 22:48:37.273432  1439 net.cpp:325] ctx_output6/relu_mbox_loc_perm does not need backward computation.
I0323 22:48:37.273437  1439 net.cpp:325] ctx_output6/relu_mbox_loc does not need backward computation.
I0323 22:48:37.273442  1439 net.cpp:325] ctx_output5/relu_mbox_priorbox does not need backward computation.
I0323 22:48:37.273447  1439 net.cpp:325] ctx_output5/relu_mbox_conf_flat does not need backward computation.
I0323 22:48:37.273452  1439 net.cpp:325] ctx_output5/relu_mbox_conf_perm does not need backward computation.
I0323 22:48:37.273457  1439 net.cpp:325] ctx_output5/relu_mbox_conf does not need backward computation.
I0323 22:48:37.273461  1439 net.cpp:325] ctx_output5/relu_mbox_loc_flat does not need backward computation.
I0323 22:48:37.273466  1439 net.cpp:325] ctx_output5/relu_mbox_loc_perm does not need backward computation.
I0323 22:48:37.273471  1439 net.cpp:325] ctx_output5/relu_mbox_loc does not need backward computation.
I0323 22:48:37.273476  1439 net.cpp:325] ctx_output4/relu_mbox_priorbox does not need backward computation.
I0323 22:48:37.273481  1439 net.cpp:325] ctx_output4/relu_mbox_conf_flat does not need backward computation.
I0323 22:48:37.273486  1439 net.cpp:325] ctx_output4/relu_mbox_conf_perm does not need backward computation.
I0323 22:48:37.273491  1439 net.cpp:325] ctx_output4/relu_mbox_conf does not need backward computation.
I0323 22:48:37.273495  1439 net.cpp:325] ctx_output4/relu_mbox_loc_flat does not need backward computation.
I0323 22:48:37.273509  1439 net.cpp:325] ctx_output4/relu_mbox_loc_perm does not need backward computation.
I0323 22:48:37.273515  1439 net.cpp:325] ctx_output4/relu_mbox_loc does not need backward computation.
I0323 22:48:37.273520  1439 net.cpp:325] ctx_output3/relu_mbox_priorbox does not need backward computation.
I0323 22:48:37.273525  1439 net.cpp:325] ctx_output3/relu_mbox_conf_flat does not need backward computation.
I0323 22:48:37.273530  1439 net.cpp:325] ctx_output3/relu_mbox_conf_perm does not need backward computation.
I0323 22:48:37.273535  1439 net.cpp:325] ctx_output3/relu_mbox_conf does not need backward computation.
I0323 22:48:37.273540  1439 net.cpp:325] ctx_output3/relu_mbox_loc_flat does not need backward computation.
I0323 22:48:37.273545  1439 net.cpp:325] ctx_output3/relu_mbox_loc_perm does not need backward computation.
I0323 22:48:37.273550  1439 net.cpp:325] ctx_output3/relu_mbox_loc does not need backward computation.
I0323 22:48:37.273555  1439 net.cpp:325] ctx_output2/relu_mbox_priorbox does not need backward computation.
I0323 22:48:37.273561  1439 net.cpp:325] ctx_output2/relu_mbox_conf_flat does not need backward computation.
I0323 22:48:37.273566  1439 net.cpp:325] ctx_output2/relu_mbox_conf_perm does not need backward computation.
I0323 22:48:37.273571  1439 net.cpp:325] ctx_output2/relu_mbox_conf does not need backward computation.
I0323 22:48:37.273576  1439 net.cpp:325] ctx_output2/relu_mbox_loc_flat does not need backward computation.
I0323 22:48:37.273581  1439 net.cpp:325] ctx_output2/relu_mbox_loc_perm does not need backward computation.
I0323 22:48:37.273586  1439 net.cpp:325] ctx_output2/relu_mbox_loc does not need backward computation.
I0323 22:48:37.273591  1439 net.cpp:325] ctx_output1/relu_mbox_priorbox does not need backward computation.
I0323 22:48:37.273597  1439 net.cpp:325] ctx_output1/relu_mbox_conf_flat does not need backward computation.
I0323 22:48:37.273602  1439 net.cpp:325] ctx_output1/relu_mbox_conf_perm does not need backward computation.
I0323 22:48:37.273607  1439 net.cpp:325] ctx_output1/relu_mbox_conf does not need backward computation.
I0323 22:48:37.273612  1439 net.cpp:325] ctx_output1/relu_mbox_loc_flat does not need backward computation.
I0323 22:48:37.273617  1439 net.cpp:325] ctx_output1/relu_mbox_loc_perm does not need backward computation.
I0323 22:48:37.273622  1439 net.cpp:325] ctx_output1/relu_mbox_loc does not need backward computation.
I0323 22:48:37.273627  1439 net.cpp:325] ctx_output6_ctx_output6/relu_0_split does not need backward computation.
I0323 22:48:37.273633  1439 net.cpp:325] ctx_output6/relu does not need backward computation.
I0323 22:48:37.273638  1439 net.cpp:325] ctx_output6 does not need backward computation.
I0323 22:48:37.273643  1439 net.cpp:325] ctx_output5_ctx_output5/relu_0_split does not need backward computation.
I0323 22:48:37.273648  1439 net.cpp:325] ctx_output5/relu does not need backward computation.
I0323 22:48:37.273653  1439 net.cpp:325] ctx_output5 does not need backward computation.
I0323 22:48:37.273658  1439 net.cpp:325] ctx_output4_ctx_output4/relu_0_split does not need backward computation.
I0323 22:48:37.273663  1439 net.cpp:325] ctx_output4/relu does not need backward computation.
I0323 22:48:37.273669  1439 net.cpp:325] ctx_output4 does not need backward computation.
I0323 22:48:37.273674  1439 net.cpp:325] ctx_output3_ctx_output3/relu_0_split does not need backward computation.
I0323 22:48:37.273679  1439 net.cpp:325] ctx_output3/relu does not need backward computation.
I0323 22:48:37.273684  1439 net.cpp:325] ctx_output3 does not need backward computation.
I0323 22:48:37.273699  1439 net.cpp:325] ctx_output2_ctx_output2/relu_0_split does not need backward computation.
I0323 22:48:37.273707  1439 net.cpp:325] ctx_output2/relu does not need backward computation.
I0323 22:48:37.273712  1439 net.cpp:325] ctx_output2 does not need backward computation.
I0323 22:48:37.273718  1439 net.cpp:325] ctx_output1_ctx_output1/relu_0_split does not need backward computation.
I0323 22:48:37.273732  1439 net.cpp:325] ctx_output1/relu does not need backward computation.
I0323 22:48:37.273738  1439 net.cpp:325] ctx_output1 does not need backward computation.
I0323 22:48:37.273744  1439 net.cpp:325] pool9 does not need backward computation.
I0323 22:48:37.273749  1439 net.cpp:325] pool8_pool8_0_split does not need backward computation.
I0323 22:48:37.273756  1439 net.cpp:325] pool8 does not need backward computation.
I0323 22:48:37.273761  1439 net.cpp:325] pool7_pool7_0_split does not need backward computation.
I0323 22:48:37.273766  1439 net.cpp:325] pool7 does not need backward computation.
I0323 22:48:37.273772  1439 net.cpp:325] pool6_pool6_0_split does not need backward computation.
I0323 22:48:37.273777  1439 net.cpp:325] pool6 does not need backward computation.
I0323 22:48:37.273782  1439 net.cpp:325] res5a_branch2b_res5a_branch2b/relu_0_split does not need backward computation.
I0323 22:48:37.273787  1439 net.cpp:325] res5a_branch2b/relu does not need backward computation.
I0323 22:48:37.273792  1439 net.cpp:325] res5a_branch2b/bn does not need backward computation.
I0323 22:48:37.273797  1439 net.cpp:325] res5a_branch2b does not need backward computation.
I0323 22:48:37.273802  1439 net.cpp:325] res5a_branch2a/relu does not need backward computation.
I0323 22:48:37.273807  1439 net.cpp:325] res5a_branch2a/bn does not need backward computation.
I0323 22:48:37.273811  1439 net.cpp:325] res5a_branch2a does not need backward computation.
I0323 22:48:37.273816  1439 net.cpp:325] pool4 does not need backward computation.
I0323 22:48:37.273821  1439 net.cpp:325] res4a_branch2b/relu does not need backward computation.
I0323 22:48:37.273826  1439 net.cpp:325] res4a_branch2b/bn does not need backward computation.
I0323 22:48:37.273830  1439 net.cpp:325] res4a_branch2b does not need backward computation.
I0323 22:48:37.273836  1439 net.cpp:325] res4a_branch2a/relu does not need backward computation.
I0323 22:48:37.273841  1439 net.cpp:325] res4a_branch2a/bn does not need backward computation.
I0323 22:48:37.273846  1439 net.cpp:325] res4a_branch2a does not need backward computation.
I0323 22:48:37.273851  1439 net.cpp:325] pool3 does not need backward computation.
I0323 22:48:37.273856  1439 net.cpp:325] res3a_branch2b_res3a_branch2b/relu_0_split does not need backward computation.
I0323 22:48:37.273862  1439 net.cpp:325] res3a_branch2b/relu does not need backward computation.
I0323 22:48:37.273867  1439 net.cpp:325] res3a_branch2b/bn does not need backward computation.
I0323 22:48:37.273871  1439 net.cpp:325] res3a_branch2b does not need backward computation.
I0323 22:48:37.273877  1439 net.cpp:325] res3a_branch2a/relu does not need backward computation.
I0323 22:48:37.273882  1439 net.cpp:325] res3a_branch2a/bn does not need backward computation.
I0323 22:48:37.273887  1439 net.cpp:325] res3a_branch2a does not need backward computation.
I0323 22:48:37.273892  1439 net.cpp:325] pool2 does not need backward computation.
I0323 22:48:37.273897  1439 net.cpp:325] res2a_branch2b/relu does not need backward computation.
I0323 22:48:37.273902  1439 net.cpp:325] res2a_branch2b/bn does not need backward computation.
I0323 22:48:37.273907  1439 net.cpp:325] res2a_branch2b does not need backward computation.
I0323 22:48:37.273912  1439 net.cpp:325] res2a_branch2a/relu does not need backward computation.
I0323 22:48:37.273916  1439 net.cpp:325] res2a_branch2a/bn does not need backward computation.
I0323 22:48:37.273921  1439 net.cpp:325] res2a_branch2a does not need backward computation.
I0323 22:48:37.273926  1439 net.cpp:325] pool1 does not need backward computation.
I0323 22:48:37.273931  1439 net.cpp:325] conv1b/relu does not need backward computation.
I0323 22:48:37.273936  1439 net.cpp:325] conv1b/bn does not need backward computation.
I0323 22:48:37.273941  1439 net.cpp:325] conv1b does not need backward computation.
I0323 22:48:37.273947  1439 net.cpp:325] conv1a/relu does not need backward computation.
I0323 22:48:37.273952  1439 net.cpp:325] conv1a/bn does not need backward computation.
I0323 22:48:37.273962  1439 net.cpp:325] conv1a does not need backward computation.
I0323 22:48:37.273968  1439 net.cpp:325] data/bias does not need backward computation.
I0323 22:48:37.273974  1439 net.cpp:325] data_data_0_split does not need backward computation.
I0323 22:48:37.273979  1439 net.cpp:325] data does not need backward computation.
I0323 22:48:37.273984  1439 net.cpp:367] This network produces output detection_eval
I0323 22:48:37.274085  1439 net.cpp:389] Top memory (TEST) required for data: 606953552 diff: 606953552
I0323 22:48:37.274093  1439 net.cpp:392] Bottom memory (TEST) required for data: 606953472 diff: 606953472
I0323 22:48:37.274097  1439 net.cpp:395] Shared (in-place) memory (TEST) by data: 260857856 diff: 260857856
I0323 22:48:37.274102  1439 net.cpp:398] Parameters memory (TEST) required for data: 12464288 diff: 12464288
I0323 22:48:37.274107  1439 net.cpp:401] Parameters shared memory (TEST) by data: 0 diff: 0
I0323 22:48:37.274111  1439 net.cpp:407] Network initialization done.
I0323 22:48:37.274442  1439 solver.cpp:57] Solver scaffolding done.
I0323 22:48:37.282564  1439 caffe.cpp:143] Finetuning from /user/a0875091/files/work/bitbucket_TI/caffe-jacinto-models/scripts/training/ti-vgg-720x368-v2/JDetNet/20180211_01-20_ds_PSP_dsFac_32_fc_0_hdDS8_1_cnctHD_0_baseNW3hd_0_kerMbox_1_1stHdSameOpCh_1/sparse_fac0.5_0.8_53.26/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_38000_53.26.caffemodel
I0323 22:48:37.291489  1439 net.cpp:1094] Copying source layer data Type:AnnotatedData #blobs=0
I0323 22:48:37.291517  1439 net.cpp:1094] Copying source layer data_data_0_split Type:Split #blobs=0
I0323 22:48:37.291522  1439 net.cpp:1094] Copying source layer data/bias Type:Bias #blobs=1
I0323 22:48:37.291564  1439 net.cpp:1094] Copying source layer conv1a Type:Convolution #blobs=2
I0323 22:48:37.291586  1439 net.cpp:1094] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0323 22:48:37.291908  1439 net.cpp:1094] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0323 22:48:37.291919  1439 net.cpp:1094] Copying source layer conv1b Type:Convolution #blobs=2
I0323 22:48:37.291937  1439 net.cpp:1094] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0323 22:48:37.292167  1439 net.cpp:1094] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0323 22:48:37.292177  1439 net.cpp:1094] Copying source layer pool1 Type:Pooling #blobs=0
I0323 22:48:37.292182  1439 net.cpp:1094] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0323 22:48:37.292210  1439 net.cpp:1094] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0323 22:48:37.292443  1439 net.cpp:1094] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0323 22:48:37.292452  1439 net.cpp:1094] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0323 22:48:37.292474  1439 net.cpp:1094] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0323 22:48:37.292697  1439 net.cpp:1094] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0323 22:48:37.292707  1439 net.cpp:1094] Copying source layer pool2 Type:Pooling #blobs=0
I0323 22:48:37.292712  1439 net.cpp:1094] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0323 22:48:37.292771  1439 net.cpp:1094] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0323 22:48:37.292984  1439 net.cpp:1094] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0323 22:48:37.292994  1439 net.cpp:1094] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0323 22:48:37.293036  1439 net.cpp:1094] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0323 22:48:37.293243  1439 net.cpp:1094] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0323 22:48:37.293254  1439 net.cpp:1094] Copying source layer res3a_branch2b_res3a_branch2b/relu_0_split Type:Split #blobs=0
I0323 22:48:37.293259  1439 net.cpp:1094] Copying source layer pool3 Type:Pooling #blobs=0
I0323 22:48:37.293264  1439 net.cpp:1094] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0323 22:48:37.293478  1439 net.cpp:1094] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0323 22:48:37.293678  1439 net.cpp:1094] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0323 22:48:37.293687  1439 net.cpp:1094] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0323 22:48:37.293807  1439 net.cpp:1094] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0323 22:48:37.294010  1439 net.cpp:1094] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0323 22:48:37.294020  1439 net.cpp:1094] Copying source layer pool4 Type:Pooling #blobs=0
I0323 22:48:37.294025  1439 net.cpp:1094] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0323 22:48:37.294644  1439 net.cpp:1094] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0323 22:48:37.294864  1439 net.cpp:1094] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0323 22:48:37.294874  1439 net.cpp:1094] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0323 22:48:37.295181  1439 net.cpp:1094] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0323 22:48:37.295367  1439 net.cpp:1094] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0323 22:48:37.295377  1439 net.cpp:1094] Copying source layer res5a_branch2b_res5a_branch2b/relu_0_split Type:Split #blobs=0
I0323 22:48:37.295382  1439 net.cpp:1094] Copying source layer pool6 Type:Pooling #blobs=0
I0323 22:48:37.295387  1439 net.cpp:1094] Copying source layer pool6_pool6_0_split Type:Split #blobs=0
I0323 22:48:37.295390  1439 net.cpp:1094] Copying source layer pool7 Type:Pooling #blobs=0
I0323 22:48:37.295395  1439 net.cpp:1094] Copying source layer pool7_pool7_0_split Type:Split #blobs=0
I0323 22:48:37.295399  1439 net.cpp:1094] Copying source layer pool8 Type:Pooling #blobs=0
I0323 22:48:37.295406  1439 net.cpp:1094] Copying source layer pool8_pool8_0_split Type:Split #blobs=0
I0323 22:48:37.295411  1439 net.cpp:1094] Copying source layer pool9 Type:Pooling #blobs=0
I0323 22:48:37.295415  1439 net.cpp:1094] Copying source layer ctx_output1 Type:Convolution #blobs=2
I0323 22:48:37.295451  1439 net.cpp:1094] Copying source layer ctx_output1/relu Type:ReLU #blobs=0
I0323 22:48:37.295460  1439 net.cpp:1094] Copying source layer ctx_output1_ctx_output1/relu_0_split Type:Split #blobs=0
I0323 22:48:37.295465  1439 net.cpp:1094] Copying source layer ctx_output2 Type:Convolution #blobs=2
I0323 22:48:37.295548  1439 net.cpp:1094] Copying source layer ctx_output2/relu Type:ReLU #blobs=0
I0323 22:48:37.295557  1439 net.cpp:1094] Copying source layer ctx_output2_ctx_output2/relu_0_split Type:Split #blobs=0
I0323 22:48:37.295562  1439 net.cpp:1094] Copying source layer ctx_output3 Type:Convolution #blobs=2
I0323 22:48:37.295646  1439 net.cpp:1094] Copying source layer ctx_output3/relu Type:ReLU #blobs=0
I0323 22:48:37.295655  1439 net.cpp:1094] Copying source layer ctx_output3_ctx_output3/relu_0_split Type:Split #blobs=0
I0323 22:48:37.295660  1439 net.cpp:1094] Copying source layer ctx_output4 Type:Convolution #blobs=2
I0323 22:48:37.295742  1439 net.cpp:1094] Copying source layer ctx_output4/relu Type:ReLU #blobs=0
I0323 22:48:37.295752  1439 net.cpp:1094] Copying source layer ctx_output4_ctx_output4/relu_0_split Type:Split #blobs=0
I0323 22:48:37.295756  1439 net.cpp:1094] Copying source layer ctx_output5 Type:Convolution #blobs=2
I0323 22:48:37.295836  1439 net.cpp:1094] Copying source layer ctx_output5/relu Type:ReLU #blobs=0
I0323 22:48:37.295846  1439 net.cpp:1094] Copying source layer ctx_output5_ctx_output5/relu_0_split Type:Split #blobs=0
I0323 22:48:37.295850  1439 net.cpp:1094] Copying source layer ctx_output6 Type:Convolution #blobs=2
I0323 22:48:37.295934  1439 net.cpp:1094] Copying source layer ctx_output6/relu Type:ReLU #blobs=0
I0323 22:48:37.295944  1439 net.cpp:1094] Copying source layer ctx_output6_ctx_output6/relu_0_split Type:Split #blobs=0
I0323 22:48:37.295949  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc Type:Convolution #blobs=2
I0323 22:48:37.295967  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc_perm Type:Permute #blobs=0
I0323 22:48:37.295995  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc_flat Type:Flatten #blobs=0
I0323 22:48:37.296000  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf Type:Convolution #blobs=2
I0323 22:48:37.296020  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf_perm Type:Permute #blobs=0
I0323 22:48:37.296027  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf_flat Type:Flatten #blobs=0
I0323 22:48:37.296031  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_priorbox Type:PriorBox #blobs=0
I0323 22:48:37.296036  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc Type:Convolution #blobs=2
I0323 22:48:37.296056  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc_perm Type:Permute #blobs=0
I0323 22:48:37.296062  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc_flat Type:Flatten #blobs=0
I0323 22:48:37.296066  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf Type:Convolution #blobs=2
I0323 22:48:37.296085  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf_perm Type:Permute #blobs=0
I0323 22:48:37.296092  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf_flat Type:Flatten #blobs=0
I0323 22:48:37.296097  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_priorbox Type:PriorBox #blobs=0
I0323 22:48:37.296103  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc Type:Convolution #blobs=2
I0323 22:48:37.296120  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc_perm Type:Permute #blobs=0
I0323 22:48:37.296128  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc_flat Type:Flatten #blobs=0
I0323 22:48:37.296133  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf Type:Convolution #blobs=2
I0323 22:48:37.296152  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf_perm Type:Permute #blobs=0
I0323 22:48:37.296159  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf_flat Type:Flatten #blobs=0
I0323 22:48:37.296164  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_priorbox Type:PriorBox #blobs=0
I0323 22:48:37.296169  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc Type:Convolution #blobs=2
I0323 22:48:37.296187  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc_perm Type:Permute #blobs=0
I0323 22:48:37.296195  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc_flat Type:Flatten #blobs=0
I0323 22:48:37.296200  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf Type:Convolution #blobs=2
I0323 22:48:37.296217  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf_perm Type:Permute #blobs=0
I0323 22:48:37.296224  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf_flat Type:Flatten #blobs=0
I0323 22:48:37.296228  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_priorbox Type:PriorBox #blobs=0
I0323 22:48:37.296233  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc Type:Convolution #blobs=2
I0323 22:48:37.296252  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc_perm Type:Permute #blobs=0
I0323 22:48:37.296258  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc_flat Type:Flatten #blobs=0
I0323 22:48:37.296263  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf Type:Convolution #blobs=2
I0323 22:48:37.296280  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf_perm Type:Permute #blobs=0
I0323 22:48:37.296288  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf_flat Type:Flatten #blobs=0
I0323 22:48:37.296293  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_priorbox Type:PriorBox #blobs=0
I0323 22:48:37.296298  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc Type:Convolution #blobs=2
I0323 22:48:37.296315  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc_perm Type:Permute #blobs=0
I0323 22:48:37.296329  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc_flat Type:Flatten #blobs=0
I0323 22:48:37.296335  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf Type:Convolution #blobs=2
I0323 22:48:37.296355  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf_perm Type:Permute #blobs=0
I0323 22:48:37.296362  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf_flat Type:Flatten #blobs=0
I0323 22:48:37.296367  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_priorbox Type:PriorBox #blobs=0
I0323 22:48:37.296371  1439 net.cpp:1094] Copying source layer mbox_loc Type:Concat #blobs=0
I0323 22:48:37.296376  1439 net.cpp:1094] Copying source layer mbox_conf Type:Concat #blobs=0
I0323 22:48:37.296380  1439 net.cpp:1094] Copying source layer mbox_priorbox Type:Concat #blobs=0
I0323 22:48:37.296386  1439 net.cpp:1094] Copying source layer mbox_loss Type:MultiBoxLoss #blobs=0
I0323 22:48:37.302093  1439 net.cpp:1094] Copying source layer data Type:AnnotatedData #blobs=0
I0323 22:48:37.302119  1439 net.cpp:1094] Copying source layer data_data_0_split Type:Split #blobs=0
I0323 22:48:37.302124  1439 net.cpp:1094] Copying source layer data/bias Type:Bias #blobs=1
I0323 22:48:37.302165  1439 net.cpp:1094] Copying source layer conv1a Type:Convolution #blobs=2
I0323 22:48:37.302186  1439 net.cpp:1094] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0323 22:48:37.302500  1439 net.cpp:1094] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0323 22:48:37.302510  1439 net.cpp:1094] Copying source layer conv1b Type:Convolution #blobs=2
I0323 22:48:37.302528  1439 net.cpp:1094] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0323 22:48:37.302763  1439 net.cpp:1094] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0323 22:48:37.302773  1439 net.cpp:1094] Copying source layer pool1 Type:Pooling #blobs=0
I0323 22:48:37.302778  1439 net.cpp:1094] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0323 22:48:37.302809  1439 net.cpp:1094] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0323 22:48:37.303040  1439 net.cpp:1094] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0323 22:48:37.303051  1439 net.cpp:1094] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0323 22:48:37.303074  1439 net.cpp:1094] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0323 22:48:37.303298  1439 net.cpp:1094] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0323 22:48:37.303309  1439 net.cpp:1094] Copying source layer pool2 Type:Pooling #blobs=0
I0323 22:48:37.303314  1439 net.cpp:1094] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0323 22:48:37.303372  1439 net.cpp:1094] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0323 22:48:37.303581  1439 net.cpp:1094] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0323 22:48:37.303591  1439 net.cpp:1094] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0323 22:48:37.303629  1439 net.cpp:1094] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0323 22:48:37.303825  1439 net.cpp:1094] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0323 22:48:37.303835  1439 net.cpp:1094] Copying source layer res3a_branch2b_res3a_branch2b/relu_0_split Type:Split #blobs=0
I0323 22:48:37.303840  1439 net.cpp:1094] Copying source layer pool3 Type:Pooling #blobs=0
I0323 22:48:37.303845  1439 net.cpp:1094] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0323 22:48:37.304018  1439 net.cpp:1094] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0323 22:48:37.304216  1439 net.cpp:1094] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0323 22:48:37.304226  1439 net.cpp:1094] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0323 22:48:37.304325  1439 net.cpp:1094] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0323 22:48:37.304522  1439 net.cpp:1094] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0323 22:48:37.304556  1439 net.cpp:1094] Copying source layer pool4 Type:Pooling #blobs=0
I0323 22:48:37.304563  1439 net.cpp:1094] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0323 22:48:37.305229  1439 net.cpp:1094] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0323 22:48:37.305444  1439 net.cpp:1094] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0323 22:48:37.305454  1439 net.cpp:1094] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0323 22:48:37.305786  1439 net.cpp:1094] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0323 22:48:37.305979  1439 net.cpp:1094] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0323 22:48:37.305989  1439 net.cpp:1094] Copying source layer res5a_branch2b_res5a_branch2b/relu_0_split Type:Split #blobs=0
I0323 22:48:37.305995  1439 net.cpp:1094] Copying source layer pool6 Type:Pooling #blobs=0
I0323 22:48:37.306000  1439 net.cpp:1094] Copying source layer pool6_pool6_0_split Type:Split #blobs=0
I0323 22:48:37.306005  1439 net.cpp:1094] Copying source layer pool7 Type:Pooling #blobs=0
I0323 22:48:37.306010  1439 net.cpp:1094] Copying source layer pool7_pool7_0_split Type:Split #blobs=0
I0323 22:48:37.306015  1439 net.cpp:1094] Copying source layer pool8 Type:Pooling #blobs=0
I0323 22:48:37.306018  1439 net.cpp:1094] Copying source layer pool8_pool8_0_split Type:Split #blobs=0
I0323 22:48:37.306023  1439 net.cpp:1094] Copying source layer pool9 Type:Pooling #blobs=0
I0323 22:48:37.306028  1439 net.cpp:1094] Copying source layer ctx_output1 Type:Convolution #blobs=2
I0323 22:48:37.306064  1439 net.cpp:1094] Copying source layer ctx_output1/relu Type:ReLU #blobs=0
I0323 22:48:37.306074  1439 net.cpp:1094] Copying source layer ctx_output1_ctx_output1/relu_0_split Type:Split #blobs=0
I0323 22:48:37.306079  1439 net.cpp:1094] Copying source layer ctx_output2 Type:Convolution #blobs=2
I0323 22:48:37.306172  1439 net.cpp:1094] Copying source layer ctx_output2/relu Type:ReLU #blobs=0
I0323 22:48:37.306181  1439 net.cpp:1094] Copying source layer ctx_output2_ctx_output2/relu_0_split Type:Split #blobs=0
I0323 22:48:37.306186  1439 net.cpp:1094] Copying source layer ctx_output3 Type:Convolution #blobs=2
I0323 22:48:37.306290  1439 net.cpp:1094] Copying source layer ctx_output3/relu Type:ReLU #blobs=0
I0323 22:48:37.306300  1439 net.cpp:1094] Copying source layer ctx_output3_ctx_output3/relu_0_split Type:Split #blobs=0
I0323 22:48:37.306305  1439 net.cpp:1094] Copying source layer ctx_output4 Type:Convolution #blobs=2
I0323 22:48:37.306398  1439 net.cpp:1094] Copying source layer ctx_output4/relu Type:ReLU #blobs=0
I0323 22:48:37.306408  1439 net.cpp:1094] Copying source layer ctx_output4_ctx_output4/relu_0_split Type:Split #blobs=0
I0323 22:48:37.306413  1439 net.cpp:1094] Copying source layer ctx_output5 Type:Convolution #blobs=2
I0323 22:48:37.306507  1439 net.cpp:1094] Copying source layer ctx_output5/relu Type:ReLU #blobs=0
I0323 22:48:37.306516  1439 net.cpp:1094] Copying source layer ctx_output5_ctx_output5/relu_0_split Type:Split #blobs=0
I0323 22:48:37.306521  1439 net.cpp:1094] Copying source layer ctx_output6 Type:Convolution #blobs=2
I0323 22:48:37.306615  1439 net.cpp:1094] Copying source layer ctx_output6/relu Type:ReLU #blobs=0
I0323 22:48:37.306624  1439 net.cpp:1094] Copying source layer ctx_output6_ctx_output6/relu_0_split Type:Split #blobs=0
I0323 22:48:37.306629  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc Type:Convolution #blobs=2
I0323 22:48:37.306648  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc_perm Type:Permute #blobs=0
I0323 22:48:37.306655  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc_flat Type:Flatten #blobs=0
I0323 22:48:37.306660  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf Type:Convolution #blobs=2
I0323 22:48:37.306679  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf_perm Type:Permute #blobs=0
I0323 22:48:37.306686  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf_flat Type:Flatten #blobs=0
I0323 22:48:37.306713  1439 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_priorbox Type:PriorBox #blobs=0
I0323 22:48:37.306718  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc Type:Convolution #blobs=2
I0323 22:48:37.306741  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc_perm Type:Permute #blobs=0
I0323 22:48:37.306748  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc_flat Type:Flatten #blobs=0
I0323 22:48:37.306753  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf Type:Convolution #blobs=2
I0323 22:48:37.306773  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf_perm Type:Permute #blobs=0
I0323 22:48:37.306780  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf_flat Type:Flatten #blobs=0
I0323 22:48:37.306785  1439 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_priorbox Type:PriorBox #blobs=0
I0323 22:48:37.306790  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc Type:Convolution #blobs=2
I0323 22:48:37.306812  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc_perm Type:Permute #blobs=0
I0323 22:48:37.306818  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc_flat Type:Flatten #blobs=0
I0323 22:48:37.306823  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf Type:Convolution #blobs=2
I0323 22:48:37.306843  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf_perm Type:Permute #blobs=0
I0323 22:48:37.306849  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf_flat Type:Flatten #blobs=0
I0323 22:48:37.306855  1439 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_priorbox Type:PriorBox #blobs=0
I0323 22:48:37.306860  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc Type:Convolution #blobs=2
I0323 22:48:37.306880  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc_perm Type:Permute #blobs=0
I0323 22:48:37.306887  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc_flat Type:Flatten #blobs=0
I0323 22:48:37.306892  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf Type:Convolution #blobs=2
I0323 22:48:37.306912  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf_perm Type:Permute #blobs=0
I0323 22:48:37.306919  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf_flat Type:Flatten #blobs=0
I0323 22:48:37.306924  1439 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_priorbox Type:PriorBox #blobs=0
I0323 22:48:37.306929  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc Type:Convolution #blobs=2
I0323 22:48:37.306948  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc_perm Type:Permute #blobs=0
I0323 22:48:37.306955  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc_flat Type:Flatten #blobs=0
I0323 22:48:37.306960  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf Type:Convolution #blobs=2
I0323 22:48:37.306978  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf_perm Type:Permute #blobs=0
I0323 22:48:37.306985  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf_flat Type:Flatten #blobs=0
I0323 22:48:37.306990  1439 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_priorbox Type:PriorBox #blobs=0
I0323 22:48:37.306995  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc Type:Convolution #blobs=2
I0323 22:48:37.307014  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc_perm Type:Permute #blobs=0
I0323 22:48:37.307021  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc_flat Type:Flatten #blobs=0
I0323 22:48:37.307026  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf Type:Convolution #blobs=2
I0323 22:48:37.307044  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf_perm Type:Permute #blobs=0
I0323 22:48:37.307050  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf_flat Type:Flatten #blobs=0
I0323 22:48:37.307065  1439 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_priorbox Type:PriorBox #blobs=0
I0323 22:48:37.307070  1439 net.cpp:1094] Copying source layer mbox_loc Type:Concat #blobs=0
I0323 22:48:37.307075  1439 net.cpp:1094] Copying source layer mbox_conf Type:Concat #blobs=0
I0323 22:48:37.307080  1439 net.cpp:1094] Copying source layer mbox_priorbox Type:Concat #blobs=0
I0323 22:48:37.307085  1439 net.cpp:1078] Ignoring source layer mbox_loss
I0323 22:48:37.307307  1439 parallel.cpp:106] [0 - 0] P2pSync adding callback
I0323 22:48:37.307319  1439 parallel.cpp:106] [1 - 1] P2pSync adding callback
I0323 22:48:37.307324  1439 parallel.cpp:59] Starting Optimization
I0323 22:48:37.307329  1439 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0323 22:48:37.307685  1439 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0323 22:48:37.308764  1494 device_alternate.hpp:116] NVML initialized on thread 140336974259968
I0323 22:48:37.338196  1494 common.cpp:585] NVML succeeded to set CPU affinity on device 1
I0323 22:48:37.338301  1493 device_alternate.hpp:116] NVML initialized on thread 140336982652672
I0323 22:48:37.339195  1493 common.cpp:585] NVML succeeded to set CPU affinity on device 0
I0323 22:48:37.347589  1494 solver.cpp:43] Solver data type: FLOAT
I0323 22:48:37.350347  1494 net.cpp:104] Using FLOAT as default forward math type
I0323 22:48:37.350358  1494 net.cpp:110] Using FLOAT as default backward math type
I0323 22:48:37.350466  1494 data_reader.cpp:58] Data Reader threads: 4, out queues: 16, depth: 8
I0323 22:48:37.350510  1494 internal_thread.cpp:19] Starting 4 internal thread(s) on device 1
I0323 22:48:37.351308  1495 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0323 22:48:37.351958  1498 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0323 22:48:37.352596  1496 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0323 22:48:37.353497  1497 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0323 22:48:37.364022  1494 annotated_data_layer.cpp:219] output data size: 8,3,320,768
I0323 22:48:37.364425  1494 annotated_data_layer.cpp:265] [1] Output data size: 8, 3, 320, 768
I0323 22:48:37.364488  1494 internal_thread.cpp:19] Starting 4 internal thread(s) on device 1
I0323 22:48:37.995002  1494 solver.cpp:177] Creating test net (#0) specified by test_net file: training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/test.prototxt
I0323 22:48:37.995725  1494 net.cpp:104] Using FLOAT as default forward math type
I0323 22:48:37.995738  1494 net.cpp:110] Using FLOAT as default backward math type
I0323 22:48:37.995775  1494 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 4
I0323 22:48:37.995787  1494 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0323 22:48:37.996495  1503 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_test_lmdb
I0323 22:48:38.006635  1494 annotated_data_layer.cpp:219] output data size: 4,3,320,768
I0323 22:48:38.006729  1494 annotated_data_layer.cpp:265] (1) Output data size: 4, 3, 320, 768
I0323 22:48:38.006799  1494 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0323 22:48:38.008486  1504 annotated_data_layer.cpp:111] (1) Parser threads: 1
I0323 22:48:38.008514  1504 annotated_data_layer.cpp:113] (1) Transformer threads: 1
I0323 22:48:38.149907  1494 solver.cpp:57] Solver scaffolding done.
I0323 22:48:38.168328  1493 parallel.cpp:161] [0 - 0] P2pSync adding callback
I0323 22:48:38.168329  1494 parallel.cpp:161] [1 - 1] P2pSync adding callback
I0323 22:48:38.333955  1494 solver.cpp:501] Solving ssdJacintoNetV2
I0323 22:48:38.333982  1494 solver.cpp:502] Learning Rate Policy: multistep
I0323 22:48:38.334008  1493 solver.cpp:501] Solving ssdJacintoNetV2
I0323 22:48:38.334023  1493 solver.cpp:502] Learning Rate Policy: multistep
I0323 22:48:38.344741  1494 net.cpp:1412] [1] Reserving 12451584 bytes of shared learnable space
I0323 22:48:38.347131  1493 net.cpp:1412] [0] Reserving 12451584 bytes of shared learnable space
I0323 22:48:38.352551  1494 solver.cpp:228] Starting Optimization on GPU 1
I0323 22:48:38.352555  1493 solver.cpp:228] Starting Optimization on GPU 0
I0323 22:48:38.352813  1493 solver.cpp:678] Iteration 0, Testing net (#0)
I0323 22:48:38.352880  1513 device_alternate.hpp:116] NVML initialized on thread 140336663860992
I0323 22:48:38.352912  1513 common.cpp:585] NVML succeeded to set CPU affinity on device 0
I0323 22:48:38.352934  1514 device_alternate.hpp:116] NVML initialized on thread 140336672253696
I0323 22:48:38.352960  1514 common.cpp:585] NVML succeeded to set CPU affinity on device 1
I0323 22:48:38.359366  1494 net.cpp:1012] Ignoring source layer mbox_loss
I0323 22:48:38.376183  1493 net.cpp:1012] Ignoring source layer mbox_loss
I0323 22:48:38.474556  1494 blocking_queue.cpp:40] Data layer prefetch queue empty
I0323 22:48:38.660125  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'conv1a' with space 0G 3/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.666992  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'conv1b' with space 0G 32/4 6 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.670248  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1a' with space 0G 3/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.678160  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1b' with space 0G 32/4 6 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.678447  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res2a_branch2a' with space 0G 32/1 6 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.683032  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res2a_branch2b' with space 0G 64/4 6 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.688418  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2a' with space 0G 32/1 6 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.689842  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res3a_branch2a' with space 0G 64/1 6 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.692903  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res3a_branch2b' with space 0G 128/4 6 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.693415  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2b' with space 0G 64/4 6 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.698366  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res4a_branch2a' with space 0G 128/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.700047  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2a' with space 0G 64/1 6 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.701572  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res4a_branch2b' with space 0G 256/4 6 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.703281  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2b' with space 0G 128/4 6 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.706374  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res5a_branch2a' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.709956  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2a' with space 0G 128/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.710350  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res5a_branch2b' with space 0G 512/4 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.713250  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2b' with space 0G 256/4 6 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.714952  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output1' with space 0G 128/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.717547  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output2' with space 0G 512/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.718616  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res5a_branch2a' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.722424  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res5a_branch2b' with space 0G 512/4 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.723744  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output3' with space 0G 512/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.725983  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output4' with space 0G 512/1 0 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.727907  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output5' with space 0G 512/1 0 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.730051  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output6' with space 0G 512/1 0 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.730603  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output1' with space 0G 128/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.732157  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output1/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.734339  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output1/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.736270  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output2' with space 0G 512/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.736860  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output2/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.738873  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output2/relu_mbox_conf' with space 0G 256/1 0 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.739390  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output3' with space 0G 512/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.741276  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output3/relu_mbox_loc' with space 0G 256/1 0 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.741865  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output4' with space 0G 512/1 0 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.744217  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output5' with space 0G 512/1 0 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.744465  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output3/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.746644  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output6' with space 0G 512/1 0 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.747625  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output4/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.749306  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output1/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.750080  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output4/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.752954  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output5/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.753414  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output1/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.755259  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output5/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.757040  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output2/relu_mbox_loc' with space 0G 256/1 0 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.757730  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output6/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.758860  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output2/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.760174  1494 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output6/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0323 22:48:38.761310  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output3/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.762965  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output3/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.764596  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output4/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.766147  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output4/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.767784  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output5/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.769353  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output5/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.771673  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output6/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0323 22:48:38.773937  1493 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output6/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0
j:  : 4 : max_pr:  : 0
j:  : 3 : max_pr:  : 0.29729
j:  : 2 : max_pr:  : 0.415784
j:  : 1 : max_pr:  : 0.494114
j:  : 0 : max_pr:  : 0.666667
I0323 22:49:31.237844  1494 solver.cpp:786] class AP 1: 0.17035
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.042008
j:  : 6 : max_pr:  : 0.2404
j:  : 5 : max_pr:  : 0.535524
j:  : 4 : max_pr:  : 0.650923
j:  : 3 : max_pr:  : 0.846908
j:  : 2 : max_pr:  : 0.95279
j:  : 1 : max_pr:  : 0.993046
j:  : 0 : max_pr:  : 1
I0323 22:49:31.296622  1494 solver.cpp:786] class AP 2: 0.478327
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0.337287
j:  : 5 : max_pr:  : 0.426856
j:  : 4 : max_pr:  : 0.486442
j:  : 3 : max_pr:  : 0.516665
j:  : 2 : max_pr:  : 0.572415
j:  : 1 : max_pr:  : 0.651184
j:  : 0 : max_pr:  : 0.855319
I0323 22:49:31.311218  1494 solver.cpp:786] class AP 3: 0.349652
I0323 22:49:31.311242  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.332776
I0323 22:49:31.413830  1484 data_reader.cpp:305] Starting prefetch of epoch 1
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0
j:  : 4 : max_pr:  : 0
j:  : 3 : max_pr:  : 0.304722
j:  : 2 : max_pr:  : 0.415248
j:  : 1 : max_pr:  : 0.51502
j:  : 0 : max_pr:  : 1
I0323 22:49:31.627115  1493 solver.cpp:786] class AP 1: 0.203181
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.0324629
j:  : 6 : max_pr:  : 0.225933
j:  : 5 : max_pr:  : 0.524698
j:  : 4 : max_pr:  : 0.6381
j:  : 3 : max_pr:  : 0.822615
j:  : 2 : max_pr:  : 0.949165
j:  : 1 : max_pr:  : 0.989362
j:  : 0 : max_pr:  : 0.990672
I0323 22:49:31.678009  1493 solver.cpp:786] class AP 2: 0.470273
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0.331866
j:  : 5 : max_pr:  : 0.422604
j:  : 4 : max_pr:  : 0.486772
j:  : 3 : max_pr:  : 0.522185
j:  : 2 : max_pr:  : 0.581631
j:  : 1 : max_pr:  : 0.660413
j:  : 0 : max_pr:  : 1
I0323 22:49:31.688917  1493 solver.cpp:786] class AP 3: 0.364134
I0323 22:49:31.688944  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.345863
I0323 22:49:31.689474  1493 solver.cpp:255] [MultiGPU] Initial Test completed
I0323 22:49:33.514550  1466 annotated_data_layer.cpp:111] [0] Parser threads: 4
I0323 22:49:33.514581  1466 annotated_data_layer.cpp:113] [0] Transformer threads: 4
I0323 22:49:33.791932  1499 annotated_data_layer.cpp:111] [1] Parser threads: 4
I0323 22:49:33.791985  1499 annotated_data_layer.cpp:113] [1] Transformer threads: 4
I0323 22:49:35.065896  1494 solver.cpp:351] sparsity_itr_increment_bfr_applying is true: old behaviour:
I0323 22:49:35.065876  1493 solver.cpp:319] Iteration 0 (3.3761 s), loss = 3.7739
I0323 22:49:35.065955  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.74846 (* 1 = 3.74846 loss)
I0323 22:49:35.065978  1493 sgd_solver.cpp:136] Iteration 0, lr = 0.01, m = 0.9
I0323 22:49:35.065997  1493 solver.cpp:351] sparsity_itr_increment_bfr_applying is true: old behaviour:
I0323 22:49:35.183605  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'conv1a' with space 4.24G 3/1 1 0 0 	(avail 1.52G, req 0G)	t: 0 2.58 2.05
I0323 22:49:35.276432  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'conv1b' with space 4.24G 32/4 6 4 3 	(avail 1.52G, req 0G)	t: 0 0.53 1.09
I0323 22:49:35.410187  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'conv1a' with space 4.24G 3/1 1 0 0 	(avail 1.63G, req 0G)	t: 0 2.31 2.04
I0323 22:49:35.514749  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 4.24G 32/1 6 4 3 	(avail 1.47G, req 0G)	t: 0 0.75 1.25
I0323 22:49:35.520167  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'conv1b' with space 4.24G 32/4 6 4 3 	(avail 1.6G, req 0G)	t: 0 0.51 1.1
I0323 22:49:35.629465  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 4.24G 64/4 1 4 3 	(avail 1.47G, req 0G)	t: 0 0.28 0.59
I0323 22:49:35.771760  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 4.24G 32/1 1 4 3 	(avail 1.58G, req 0G)	t: 0 0.66 1.22
I0323 22:49:35.810722  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 4.24G 64/1 6 4 5 	(avail 1.47G, req 0.05G)	t: 0 0.42 0.77
I0323 22:49:35.857448  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 4.24G 64/4 6 4 3 	(avail 1.58G, req 0G)	t: 0 0.27 0.59
I0323 22:49:35.860350  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 4.24G 128/4 6 4 5 	(avail 1.47G, req 0.05G)	t: 0 0.15 0.26
I0323 22:49:35.953533  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 4.24G 128/1 6 4 5 	(avail 1.47G, req 0.05G)	t: 0 0.36 0.47
I0323 22:49:36.022078  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 4.24G 256/4 6 4 5 	(avail 1.47G, req 0.05G)	t: 0 0.08 0.17
I0323 22:49:36.045765  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 4.24G 64/1 6 4 5 	(avail 1.55G, req 0.05G)	t: 0 0.42 0.73
I0323 22:49:36.131213  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 4.24G 128/4 6 4 5 	(avail 1.55G, req 0.05G)	t: 0 0.12 0.26
I0323 22:49:36.182531  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 4.24G 256/1 6 4 5 	(avail 1.44G, req 0.05G)	t: 0 0.47 0.5
I0323 22:49:36.241499  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 4.24G 512/4 6 4 5 	(avail 1.44G, req 0.05G)	t: 0 0.12 0.14
I0323 22:49:36.270212  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 4.24G 128/1 6 4 5 	(avail 1.55G, req 0.05G)	t: 0 0.32 0.44
I0323 22:49:36.305871  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 4.24G 256/4 6 4 5 	(avail 1.55G, req 0.05G)	t: 0 0.11 0.19
I0323 22:49:36.319852  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output1' with space 4.24G 128/1 1 1 3 	(avail 1.42G, req 0.05G)	t: 0 0.34 0.8
I0323 22:49:36.392588  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output2' with space 4.24G 512/1 1 1 1 	(avail 1.42G, req 0.05G)	t: 0 0.17 0.19
I0323 22:49:36.411859  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 4.24G 256/1 6 4 5 	(avail 1.55G, req 0.05G)	t: 0 0.46 0.5
I0323 22:49:36.427016  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output3' with space 4.24G 512/1 0 1 1 	(avail 1.42G, req 0.05G)	t: 0 0.07 0.09
I0323 22:49:36.446193  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 4.24G 512/4 6 4 5 	(avail 1.55G, req 0.05G)	t: 0 0.08 0.13
I0323 22:49:36.458101  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output4' with space 4.24G 512/1 0 0 1 	(avail 1.42G, req 0.05G)	t: 0 0.1 0.11
I0323 22:49:36.487696  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output5' with space 4.24G 512/1 0 0 1 	(avail 1.42G, req 0.05G)	t: 0 0.09 0.09
I0323 22:49:36.509845  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output1' with space 4.24G 128/1 1 1 3 	(avail 1.53G, req 0.05G)	t: 0 0.35 0.8
I0323 22:49:36.547974  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output6' with space 4.24G 512/1 0 0 1 	(avail 1.39G, req 0.05G)	t: 0 0.06 0.07
I0323 22:49:36.592002  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output2' with space 4.24G 512/1 0 1 1 	(avail 1.53G, req 0.05G)	t: 0 0.16 0.18
I0323 22:49:36.623448  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output3' with space 4.24G 512/1 0 1 1 	(avail 1.53G, req 0.05G)	t: 0 0.1 0.12
I0323 22:49:36.656561  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output4' with space 4.24G 512/1 0 0 1 	(avail 1.53G, req 0.05G)	t: 0 0.08 0.09
I0323 22:49:36.669945  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_loc' with space 4.24G 256/1 1 1 3 	(avail 1.39G, req 0.05G)	t: 0 0.22 0.62
I0323 22:49:36.714236  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output5' with space 4.24G 512/1 0 0 1 	(avail 1.53G, req 0.05G)	t: 0 0.06 0.06
I0323 22:49:36.774420  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output6' with space 4.24G 512/1 0 0 3 	(avail 1.53G, req 0.05G)	t: 0 0.06 0.06
I0323 22:49:36.853092  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_conf' with space 4.24G 256/1 1 1 3 	(avail 1.37G, req 0.05G)	t: 0 0.29 0.62
I0323 22:49:36.884588  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_loc' with space 4.24G 256/1 1 1 0 	(avail 1.37G, req 0.05G)	t: 0 0.06 0.07
I0323 22:49:36.903250  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_loc' with space 4.24G 256/1 1 1 3 	(avail 1.53G, req 0.05G)	t: 0 0.21 0.63
I0323 22:49:36.911309  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_conf' with space 4.24G 256/1 0 1 3 	(avail 1.37G, req 0.05G)	t: 0 0.04 0.06
I0323 22:49:36.929129  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 1.37G, req 0.05G)	t: 0 0.06 0.06
I0323 22:49:36.960880  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_conf' with space 4.24G 256/1 0 0 0 	(avail 1.37G, req 0.05G)	t: 0 0.06 0.05
I0323 22:49:36.985903  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_loc' with space 4.24G 256/1 1 0 0 	(avail 1.37G, req 0.05G)	t: 0 0.06 0.06
I0323 22:49:37.014472  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_conf' with space 4.24G 256/1 1 0 0 	(avail 1.37G, req 0.05G)	t: 0 0.05 0.04
I0323 22:49:37.036401  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 1.37G, req 0.05G)	t: 0 0.03 0.03
I0323 22:49:37.063347  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_conf' with space 4.24G 256/1 1 0 0 	(avail 1.37G, req 0.05G)	t: 0 0.03 0.03
I0323 22:49:37.070669  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_conf' with space 4.24G 256/1 1 1 3 	(avail 1.45G, req 0.05G)	t: 0 0.25 0.63
I0323 22:49:37.089983  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output6/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 1.37G, req 0.05G)	t: 0 0.03 0.03
I0323 22:49:37.106283  1493 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output6/relu_mbox_conf' with space 4.24G 256/1 0 0 0 	(avail 1.37G, req 0.05G)	t: 0 0.04 0.03
I0323 22:49:37.109550  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_loc' with space 4.24G 256/1 1 1 0 	(avail 1.45G, req 0.05G)	t: 0 0.07 0.07
I0323 22:49:37.138844  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_conf' with space 4.24G 256/1 1 1 3 	(avail 1.45G, req 0.05G)	t: 0 0.08 0.1
I0323 22:49:37.156304  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_loc' with space 4.24G 256/1 0 0 3 	(avail 1.45G, req 0.05G)	t: 0 0.08 0.06
I0323 22:49:37.169209  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_conf' with space 4.24G 256/1 1 0 0 	(avail 1.45G, req 0.05G)	t: 0 0.06 0.05
I0323 22:49:37.182801  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 1.45G, req 0.05G)	t: 0 0.05 0.05
I0323 22:49:37.246248  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_conf' with space 4.24G 256/1 0 0 0 	(avail 1.45G, req 0.05G)	t: 0 0.15 0.14
I0323 22:49:37.298352  1493 cudnn_conv_layer.cpp:474] [0] Layer 'conv1a' reallocating workspace 4.24G to 0.11G
I0323 22:49:37.303014  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 1.45G, req 0.05G)	t: 0 0.06 0.05
I0323 22:49:37.316648  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_conf' with space 4.24G 256/1 0 0 0 	(avail 1.45G, req 0.05G)	t: 0 0.07 0.05
I0323 22:49:37.332348  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output6/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 1.45G, req 0.05G)	t: 0 0.06 0.07
I0323 22:49:37.354843  1494 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output6/relu_mbox_conf' with space 4.24G 256/1 0 0 0 	(avail 1.45G, req 0.05G)	t: 0 0.05 0.05
I0323 22:49:37.617507  1494 cudnn_conv_layer.cpp:474] [1] Layer 'conv1a' reallocating workspace 4.24G to 0.11G
I0323 22:49:37.836638  1493 solver.cpp:319] Iteration 1 (2.77067 s), loss = 3.90344
I0323 22:49:37.836683  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.93222 (* 1 = 3.93222 loss)
I0323 22:49:37.836694  1493 solver.cpp:351] sparsity_itr_increment_bfr_applying is true: old behaviour:
I0323 22:49:37.836654  1494 solver.cpp:351] sparsity_itr_increment_bfr_applying is true: old behaviour:
I0323 22:49:38.389751  1493 solver.cpp:319] Iteration 2 (0.553087 s), loss = 4.08933
I0323 22:49:38.389796  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.94315 (* 1 = 3.94315 loss)
I0323 22:50:41.782698  1493 solver.cpp:314] Iteration 100 (1.54596 iter/s, 63.3911s/98 iter), loss = 4.53405
I0323 22:50:41.782853  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.26661 (* 1 = 4.26661 loss)
I0323 22:50:41.782874  1493 sgd_solver.cpp:136] Iteration 100, lr = 0.01, m = 0.9
I0323 22:51:48.734098  1493 solver.cpp:314] Iteration 200 (1.49366 iter/s, 66.9494s/100 iter), loss = 4.29166
I0323 22:51:48.734192  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.14717 (* 1 = 4.14717 loss)
I0323 22:51:48.734205  1493 sgd_solver.cpp:136] Iteration 200, lr = 0.01, m = 0.9
I0323 22:52:53.841429  1493 solver.cpp:314] Iteration 300 (1.53597 iter/s, 65.1054s/100 iter), loss = 4.05096
I0323 22:52:53.841604  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.06028 (* 1 = 4.06028 loss)
I0323 22:52:53.841652  1493 sgd_solver.cpp:136] Iteration 300, lr = 0.01, m = 0.9
I0323 22:53:59.821766  1493 solver.cpp:314] Iteration 400 (1.51565 iter/s, 65.9784s/100 iter), loss = 4.26812
I0323 22:53:59.823148  1493 solver.cpp:336]     Train net output #0: mbox_loss = 5.10703 (* 1 = 5.10703 loss)
I0323 22:53:59.823170  1493 sgd_solver.cpp:136] Iteration 400, lr = 0.01, m = 0.9
I0323 22:55:06.601943  1493 solver.cpp:314] Iteration 500 (1.49749 iter/s, 66.7782s/100 iter), loss = 4.01307
I0323 22:55:06.602041  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.12499 (* 1 = 4.12499 loss)
I0323 22:55:06.602058  1493 sgd_solver.cpp:136] Iteration 500, lr = 0.01, m = 0.9
I0323 22:56:12.717741  1493 solver.cpp:314] Iteration 600 (1.51254 iter/s, 66.1139s/100 iter), loss = 4.03872
I0323 22:56:12.717905  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.72107 (* 1 = 3.72107 loss)
I0323 22:56:12.717922  1493 sgd_solver.cpp:136] Iteration 600, lr = 0.01, m = 0.9
I0323 22:57:18.432302  1493 solver.cpp:314] Iteration 700 (1.52178 iter/s, 65.7127s/100 iter), loss = 4.0706
I0323 22:57:18.432431  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.13445 (* 1 = 3.13445 loss)
I0323 22:57:18.432499  1493 sgd_solver.cpp:136] Iteration 700, lr = 0.01, m = 0.9
I0323 22:58:24.029772  1493 solver.cpp:314] Iteration 800 (1.52449 iter/s, 65.5956s/100 iter), loss = 3.83964
I0323 22:58:24.031848  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.13615 (* 1 = 4.13615 loss)
I0323 22:58:24.031878  1493 sgd_solver.cpp:136] Iteration 800, lr = 0.01, m = 0.9
I0323 22:59:30.654832  1493 solver.cpp:314] Iteration 900 (1.50098 iter/s, 66.6232s/100 iter), loss = 3.79302
I0323 22:59:30.654929  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.24517 (* 1 = 3.24517 loss)
I0323 22:59:30.654945  1493 sgd_solver.cpp:136] Iteration 900, lr = 0.01, m = 0.9
I0323 23:00:35.984648  1493 solver.cpp:314] Iteration 1000 (1.53074 iter/s, 65.3279s/100 iter), loss = 4.11693
I0323 23:00:35.984827  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.98215 (* 1 = 4.98215 loss)
I0323 23:00:35.984843  1493 sgd_solver.cpp:136] Iteration 1000, lr = 0.01, m = 0.9
I0323 23:01:41.806044  1493 solver.cpp:314] Iteration 1100 (1.51931 iter/s, 65.8195s/100 iter), loss = 3.8272
I0323 23:01:41.806192  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.44516 (* 1 = 3.44516 loss)
I0323 23:01:41.806210  1493 sgd_solver.cpp:136] Iteration 1100, lr = 0.01, m = 0.9
I0323 23:02:47.790160  1493 solver.cpp:314] Iteration 1200 (1.51556 iter/s, 65.9822s/100 iter), loss = 3.88279
I0323 23:02:47.790256  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.2625 (* 1 = 3.2625 loss)
I0323 23:02:47.790271  1493 sgd_solver.cpp:136] Iteration 1200, lr = 0.01, m = 0.9
I0323 23:03:54.517460  1493 solver.cpp:314] Iteration 1300 (1.49868 iter/s, 66.7254s/100 iter), loss = 3.90681
I0323 23:03:54.517565  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.19064 (* 1 = 4.19064 loss)
I0323 23:03:54.517582  1493 sgd_solver.cpp:136] Iteration 1300, lr = 0.01, m = 0.9
I0323 23:05:01.549114  1493 solver.cpp:314] Iteration 1400 (1.49188 iter/s, 67.0297s/100 iter), loss = 3.82962
I0323 23:05:01.549216  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.12871 (* 1 = 3.12871 loss)
I0323 23:05:01.549232  1493 sgd_solver.cpp:136] Iteration 1400, lr = 0.01, m = 0.9
I0323 23:06:07.945736  1493 solver.cpp:314] Iteration 1500 (1.50614 iter/s, 66.3947s/100 iter), loss = 3.98527
I0323 23:06:07.949784  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.51266 (* 1 = 3.51266 loss)
I0323 23:06:07.950186  1493 sgd_solver.cpp:136] Iteration 1500, lr = 0.01, m = 0.9
I0323 23:07:14.704038  1493 solver.cpp:314] Iteration 1600 (1.49798 iter/s, 66.7564s/100 iter), loss = 4.05769
I0323 23:07:14.704138  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.48868 (* 1 = 3.48868 loss)
I0323 23:07:14.704154  1493 sgd_solver.cpp:136] Iteration 1600, lr = 0.01, m = 0.9
I0323 23:08:20.619010  1493 solver.cpp:314] Iteration 1700 (1.51715 iter/s, 65.9131s/100 iter), loss = 3.66393
I0323 23:08:20.619122  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.30512 (* 1 = 3.30512 loss)
I0323 23:08:20.619138  1493 sgd_solver.cpp:136] Iteration 1700, lr = 0.01, m = 0.9
I0323 23:09:26.906046  1493 solver.cpp:314] Iteration 1800 (1.50863 iter/s, 66.2851s/100 iter), loss = 3.94065
I0323 23:09:26.906152  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.12901 (* 1 = 3.12901 loss)
I0323 23:09:26.906169  1493 sgd_solver.cpp:136] Iteration 1800, lr = 0.01, m = 0.9
I0323 23:10:32.813359  1493 solver.cpp:314] Iteration 1900 (1.51733 iter/s, 65.9054s/100 iter), loss = 3.62983
I0323 23:10:32.813457  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.22451 (* 1 = 3.22451 loss)
I0323 23:10:32.813472  1493 sgd_solver.cpp:136] Iteration 1900, lr = 0.01, m = 0.9
I0323 23:11:38.201161  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_2000.caffemodel
I0323 23:11:38.264041  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_2000.solverstate
I0323 23:11:38.285671  1493 solver.cpp:678] Iteration 2000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0
j:  : 4 : max_pr:  : 0
j:  : 3 : max_pr:  : 0.257837
j:  : 2 : max_pr:  : 0.483572
j:  : 1 : max_pr:  : 0.738134
j:  : 0 : max_pr:  : 1
I0323 23:12:27.068806  1493 solver.cpp:786] class AP 1: 0.225413
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.0272546
j:  : 6 : max_pr:  : 0.122667
j:  : 5 : max_pr:  : 0.24801
j:  : 4 : max_pr:  : 0.304307
j:  : 3 : max_pr:  : 0.365978
j:  : 2 : max_pr:  : 0.647029
j:  : 1 : max_pr:  : 0.889197
j:  : 0 : max_pr:  : 1
I0323 23:12:27.130771  1493 solver.cpp:786] class AP 2: 0.327677
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0.305954
j:  : 5 : max_pr:  : 0.514786
j:  : 4 : max_pr:  : 0.661602
j:  : 3 : max_pr:  : 0.728096
j:  : 2 : max_pr:  : 0.862496
j:  : 1 : max_pr:  : 0.989429
j:  : 0 : max_pr:  : 1
I0323 23:12:27.140970  1493 solver.cpp:786] class AP 3: 0.460215
I0323 23:12:27.140992  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.337768
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0
j:  : 4 : max_pr:  : 0
j:  : 3 : max_pr:  : 0.264869
j:  : 2 : max_pr:  : 0.47644
j:  : 1 : max_pr:  : 0.7251
j:  : 0 : max_pr:  : 1
I0323 23:12:27.175611  1494 solver.cpp:786] class AP 1: 0.224219
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.0301652
j:  : 6 : max_pr:  : 0.130019
j:  : 5 : max_pr:  : 0.256378
j:  : 4 : max_pr:  : 0.326788
j:  : 3 : max_pr:  : 0.398011
j:  : 2 : max_pr:  : 0.687007
j:  : 1 : max_pr:  : 0.908206
j:  : 0 : max_pr:  : 1
I0323 23:12:27.235172  1494 solver.cpp:786] class AP 2: 0.339689
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0.312224
j:  : 5 : max_pr:  : 0.536312
j:  : 4 : max_pr:  : 0.684362
j:  : 3 : max_pr:  : 0.757178
j:  : 2 : max_pr:  : 0.86758
j:  : 1 : max_pr:  : 0.991059
j:  : 0 : max_pr:  : 1
I0323 23:12:27.245080  1494 solver.cpp:786] class AP 3: 0.468065
I0323 23:12:27.245092  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.343991
I0323 23:12:27.245458  1493 solver.cpp:265] [MultiGPU] Tests completed in 48.9584s
I0323 23:12:27.637941  1493 solver.cpp:314] Iteration 2000 (0.870919 iter/s, 114.821s/100 iter), loss = 3.93422
I0323 23:12:27.637984  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.70852 (* 1 = 3.70852 loss)
I0323 23:12:27.638000  1493 sgd_solver.cpp:136] Iteration 2000, lr = 0.01, m = 0.9
I0323 23:13:32.956596  1493 solver.cpp:314] Iteration 2100 (1.531 iter/s, 65.3168s/100 iter), loss = 3.92707
I0323 23:13:32.956732  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.07801 (* 1 = 3.07801 loss)
I0323 23:13:32.956748  1493 sgd_solver.cpp:136] Iteration 2100, lr = 0.01, m = 0.9
I0323 23:14:38.408421  1493 solver.cpp:314] Iteration 2200 (1.52789 iter/s, 65.4499s/100 iter), loss = 4.08358
I0323 23:14:38.408526  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.63275 (* 1 = 3.63275 loss)
I0323 23:14:38.408542  1493 sgd_solver.cpp:136] Iteration 2200, lr = 0.01, m = 0.9
I0323 23:15:43.043073  1493 solver.cpp:314] Iteration 2300 (1.5472 iter/s, 64.6328s/100 iter), loss = 3.73523
I0323 23:15:43.043195  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.18382 (* 1 = 3.18382 loss)
I0323 23:15:43.043215  1493 sgd_solver.cpp:136] Iteration 2300, lr = 0.01, m = 0.9
I0323 23:16:47.923194  1493 solver.cpp:314] Iteration 2400 (1.54135 iter/s, 64.8783s/100 iter), loss = 3.48827
I0323 23:16:47.923300  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.31882 (* 1 = 3.31882 loss)
I0323 23:16:47.923317  1493 sgd_solver.cpp:136] Iteration 2400, lr = 0.01, m = 0.9
I0323 23:17:53.522997  1493 solver.cpp:314] Iteration 2500 (1.52444 iter/s, 65.5979s/100 iter), loss = 3.64736
I0323 23:17:53.523195  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.34811 (* 1 = 4.34811 loss)
I0323 23:17:53.523238  1493 sgd_solver.cpp:136] Iteration 2500, lr = 0.01, m = 0.9
I0323 23:18:59.832096  1493 solver.cpp:314] Iteration 2600 (1.50813 iter/s, 66.3072s/100 iter), loss = 3.97786
I0323 23:18:59.832244  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.67067 (* 1 = 4.67067 loss)
I0323 23:18:59.832275  1493 sgd_solver.cpp:136] Iteration 2600, lr = 0.01, m = 0.9
I0323 23:20:06.328936  1493 solver.cpp:314] Iteration 2700 (1.50387 iter/s, 66.4949s/100 iter), loss = 3.58704
I0323 23:20:06.329077  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.36411 (* 1 = 3.36411 loss)
I0323 23:20:06.329108  1493 sgd_solver.cpp:136] Iteration 2700, lr = 0.01, m = 0.9
I0323 23:21:12.268213  1493 solver.cpp:314] Iteration 2800 (1.51659 iter/s, 65.9374s/100 iter), loss = 3.78468
I0323 23:21:12.268323  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.83231 (* 1 = 3.83231 loss)
I0323 23:21:12.268340  1493 sgd_solver.cpp:136] Iteration 2800, lr = 0.01, m = 0.9
I0323 23:22:17.448163  1493 solver.cpp:314] Iteration 2900 (1.53426 iter/s, 65.1781s/100 iter), loss = 3.86018
I0323 23:22:17.449739  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.50774 (* 1 = 3.50774 loss)
I0323 23:22:17.449765  1493 sgd_solver.cpp:136] Iteration 2900, lr = 0.01, m = 0.9
I0323 23:23:23.012611  1493 solver.cpp:314] Iteration 3000 (1.52526 iter/s, 65.5626s/100 iter), loss = 3.71755
I0323 23:23:23.012836  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.74866 (* 1 = 3.74866 loss)
I0323 23:23:23.012867  1493 sgd_solver.cpp:136] Iteration 3000, lr = 0.01, m = 0.9
I0323 23:24:29.062083  1493 solver.cpp:314] Iteration 3100 (1.51406 iter/s, 66.0476s/100 iter), loss = 3.5891
I0323 23:24:29.062177  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.23949 (* 1 = 3.23949 loss)
I0323 23:24:29.062192  1493 sgd_solver.cpp:136] Iteration 3100, lr = 0.01, m = 0.9
I0323 23:24:40.043028  1462 data_reader.cpp:305] Starting prefetch of epoch 1
I0323 23:25:35.049856  1493 solver.cpp:314] Iteration 3200 (1.51548 iter/s, 65.9859s/100 iter), loss = 3.6305
I0323 23:25:35.049950  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.17921 (* 1 = 3.17921 loss)
I0323 23:25:35.049966  1493 sgd_solver.cpp:136] Iteration 3200, lr = 0.01, m = 0.9
I0323 23:26:39.866283  1493 solver.cpp:314] Iteration 3300 (1.54286 iter/s, 64.8146s/100 iter), loss = 3.58764
I0323 23:26:39.866370  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.94418 (* 1 = 2.94418 loss)
I0323 23:26:39.866385  1493 sgd_solver.cpp:136] Iteration 3300, lr = 0.01, m = 0.9
I0323 23:27:45.787070  1493 solver.cpp:314] Iteration 3400 (1.51702 iter/s, 65.9189s/100 iter), loss = 3.7022
I0323 23:27:45.787238  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.91076 (* 1 = 3.91076 loss)
I0323 23:27:45.787255  1493 sgd_solver.cpp:136] Iteration 3400, lr = 0.01, m = 0.9
I0323 23:28:51.658072  1493 solver.cpp:314] Iteration 3500 (1.51816 iter/s, 65.869s/100 iter), loss = 3.67867
I0323 23:28:51.658227  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.99867 (* 1 = 2.99867 loss)
I0323 23:28:51.658252  1493 sgd_solver.cpp:136] Iteration 3500, lr = 0.01, m = 0.9
I0323 23:29:57.168680  1493 solver.cpp:314] Iteration 3600 (1.52652 iter/s, 65.5087s/100 iter), loss = 3.54569
I0323 23:29:57.168771  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.69876 (* 1 = 2.69876 loss)
I0323 23:29:57.168787  1493 sgd_solver.cpp:136] Iteration 3600, lr = 0.01, m = 0.9
I0323 23:31:02.713940  1493 solver.cpp:314] Iteration 3700 (1.52571 iter/s, 65.5433s/100 iter), loss = 3.59419
I0323 23:31:02.715456  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.13385 (* 1 = 4.13385 loss)
I0323 23:31:02.715499  1493 sgd_solver.cpp:136] Iteration 3700, lr = 0.01, m = 0.9
I0323 23:32:08.956547  1493 solver.cpp:314] Iteration 3800 (1.50965 iter/s, 66.2406s/100 iter), loss = 3.87835
I0323 23:32:08.956714  1493 solver.cpp:336]     Train net output #0: mbox_loss = 5.27415 (* 1 = 5.27415 loss)
I0323 23:32:08.956730  1493 sgd_solver.cpp:136] Iteration 3800, lr = 0.01, m = 0.9
I0323 23:33:14.536777  1493 solver.cpp:314] Iteration 3900 (1.5249 iter/s, 65.5783s/100 iter), loss = 3.54694
I0323 23:33:14.545765  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.12785 (* 1 = 3.12785 loss)
I0323 23:33:14.545796  1493 sgd_solver.cpp:136] Iteration 3900, lr = 0.01, m = 0.9
I0323 23:34:20.705313  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_4000.caffemodel
I0323 23:34:20.733619  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_4000.solverstate
I0323 23:34:20.746870  1493 solver.cpp:678] Iteration 4000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.249333
j:  : 4 : max_pr:  : 0.390546
j:  : 3 : max_pr:  : 0.549348
j:  : 2 : max_pr:  : 0.711037
j:  : 1 : max_pr:  : 0.835869
j:  : 0 : max_pr:  : 1
I0323 23:35:11.179517  1494 solver.cpp:786] class AP 1: 0.339649
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0960451
j:  : 7 : max_pr:  : 0.287844
j:  : 6 : max_pr:  : 0.496092
j:  : 5 : max_pr:  : 0.650736
j:  : 4 : max_pr:  : 0.724747
j:  : 3 : max_pr:  : 0.830261
j:  : 2 : max_pr:  : 0.968586
j:  : 1 : max_pr:  : 0.99171
j:  : 0 : max_pr:  : 1
I0323 23:35:11.235651  1494 solver.cpp:786] class AP 2: 0.549638
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0.494088
j:  : 5 : max_pr:  : 0.695418
j:  : 4 : max_pr:  : 0.797502
j:  : 3 : max_pr:  : 0.880107
j:  : 2 : max_pr:  : 0.939524
j:  : 1 : max_pr:  : 0.995321
j:  : 0 : max_pr:  : 1
I0323 23:35:11.242960  1494 solver.cpp:786] class AP 3: 0.527451
I0323 23:35:11.242979  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.472246
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.250076
j:  : 4 : max_pr:  : 0.387178
j:  : 3 : max_pr:  : 0.533955
j:  : 2 : max_pr:  : 0.706031
j:  : 1 : max_pr:  : 0.829768
j:  : 0 : max_pr:  : 1
I0323 23:35:11.694854  1493 solver.cpp:786] class AP 1: 0.337001
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0990823
j:  : 7 : max_pr:  : 0.295945
j:  : 6 : max_pr:  : 0.512333
j:  : 5 : max_pr:  : 0.652906
j:  : 4 : max_pr:  : 0.733785
j:  : 3 : max_pr:  : 0.845521
j:  : 2 : max_pr:  : 0.978374
j:  : 1 : max_pr:  : 0.994547
j:  : 0 : max_pr:  : 1
I0323 23:35:11.748678  1493 solver.cpp:786] class AP 2: 0.555681
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0.492401
j:  : 5 : max_pr:  : 0.684252
j:  : 4 : max_pr:  : 0.793294
j:  : 3 : max_pr:  : 0.891045
j:  : 2 : max_pr:  : 0.950592
j:  : 1 : max_pr:  : 0.995717
j:  : 0 : max_pr:  : 1
I0323 23:35:11.755487  1493 solver.cpp:786] class AP 3: 0.527937
I0323 23:35:11.755501  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.473539
I0323 23:35:11.755556  1493 solver.cpp:265] [MultiGPU] Tests completed in 51.0072s
I0323 23:35:12.212098  1493 solver.cpp:314] Iteration 4000 (0.849821 iter/s, 117.672s/100 iter), loss = 3.64583
I0323 23:35:12.212146  1493 solver.cpp:336]     Train net output #0: mbox_loss = 5.45991 (* 1 = 5.45991 loss)
I0323 23:35:12.212159  1493 sgd_solver.cpp:136] Iteration 4000, lr = 0.01, m = 0.9
I0323 23:36:17.810649  1493 solver.cpp:314] Iteration 4100 (1.52447 iter/s, 65.5966s/100 iter), loss = 3.56298
I0323 23:36:17.813741  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.78696 (* 1 = 3.78696 loss)
I0323 23:36:17.813763  1493 sgd_solver.cpp:136] Iteration 4100, lr = 0.01, m = 0.9
I0323 23:37:23.327805  1493 solver.cpp:314] Iteration 4200 (1.52636 iter/s, 65.5152s/100 iter), loss = 3.57056
I0323 23:37:23.327966  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.63471 (* 1 = 3.63471 loss)
I0323 23:37:23.328009  1493 sgd_solver.cpp:136] Iteration 4200, lr = 0.01, m = 0.9
I0323 23:38:28.764933  1493 solver.cpp:314] Iteration 4300 (1.52823 iter/s, 65.4352s/100 iter), loss = 3.71638
I0323 23:38:28.765061  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.64287 (* 1 = 3.64287 loss)
I0323 23:38:28.765077  1493 sgd_solver.cpp:136] Iteration 4300, lr = 0.01, m = 0.9
I0323 23:39:34.565781  1493 solver.cpp:314] Iteration 4400 (1.51978 iter/s, 65.7989s/100 iter), loss = 3.50247
I0323 23:39:34.566073  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.18056 (* 1 = 4.18056 loss)
I0323 23:39:34.566092  1493 sgd_solver.cpp:136] Iteration 4400, lr = 0.01, m = 0.9
I0323 23:40:40.217588  1493 solver.cpp:314] Iteration 4500 (1.52323 iter/s, 65.6499s/100 iter), loss = 3.48663
I0323 23:40:40.217679  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.41477 (* 1 = 3.41477 loss)
I0323 23:40:40.217700  1493 sgd_solver.cpp:136] Iteration 4500, lr = 0.01, m = 0.9
I0323 23:41:45.158931  1493 solver.cpp:314] Iteration 4600 (1.5399 iter/s, 64.9393s/100 iter), loss = 3.60284
I0323 23:41:45.159026  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.3186 (* 1 = 3.3186 loss)
I0323 23:41:45.159049  1493 sgd_solver.cpp:136] Iteration 4600, lr = 0.01, m = 0.9
I0323 23:42:50.860043  1493 solver.cpp:314] Iteration 4700 (1.52209 iter/s, 65.6992s/100 iter), loss = 3.42156
I0323 23:42:50.860149  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.9847 (* 1 = 4.9847 loss)
I0323 23:42:50.860168  1493 sgd_solver.cpp:136] Iteration 4700, lr = 0.01, m = 0.9
I0323 23:43:57.800213  1493 solver.cpp:314] Iteration 4800 (1.49392 iter/s, 66.9382s/100 iter), loss = 3.73948
I0323 23:43:57.800319  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.7261 (* 1 = 3.7261 loss)
I0323 23:43:57.800338  1493 sgd_solver.cpp:136] Iteration 4800, lr = 0.01, m = 0.9
I0323 23:45:04.579332  1493 solver.cpp:314] Iteration 4900 (1.49752 iter/s, 66.7771s/100 iter), loss = 3.85184
I0323 23:45:04.579429  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.97434 (* 1 = 2.97434 loss)
I0323 23:45:04.579447  1493 sgd_solver.cpp:136] Iteration 4900, lr = 0.01, m = 0.9
I0323 23:46:10.649952  1493 solver.cpp:314] Iteration 5000 (1.51358 iter/s, 66.0686s/100 iter), loss = 3.6092
I0323 23:46:10.650065  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.73208 (* 1 = 3.73208 loss)
I0323 23:46:10.650084  1493 sgd_solver.cpp:136] Iteration 5000, lr = 0.01, m = 0.9
I0323 23:47:17.673758  1493 solver.cpp:314] Iteration 5100 (1.49205 iter/s, 67.0217s/100 iter), loss = 3.76322
I0323 23:47:17.673857  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.03634 (* 1 = 3.03634 loss)
I0323 23:47:17.673877  1493 sgd_solver.cpp:136] Iteration 5100, lr = 0.01, m = 0.9
I0323 23:48:23.590859  1493 solver.cpp:314] Iteration 5200 (1.5171 iter/s, 65.915s/100 iter), loss = 3.65575
I0323 23:48:23.590967  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.89876 (* 1 = 3.89876 loss)
I0323 23:48:23.590983  1493 sgd_solver.cpp:136] Iteration 5200, lr = 0.01, m = 0.9
I0323 23:49:29.921963  1493 solver.cpp:314] Iteration 5300 (1.50764 iter/s, 66.329s/100 iter), loss = 3.35529
I0323 23:49:29.922060  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.20429 (* 1 = 3.20429 loss)
I0323 23:49:29.922076  1493 sgd_solver.cpp:136] Iteration 5300, lr = 0.01, m = 0.9
I0323 23:50:34.964031  1493 solver.cpp:314] Iteration 5400 (1.53751 iter/s, 65.04s/100 iter), loss = 3.73991
I0323 23:50:34.964133  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.32458 (* 1 = 2.32458 loss)
I0323 23:50:34.964150  1493 sgd_solver.cpp:136] Iteration 5400, lr = 0.01, m = 0.9
I0323 23:51:40.491174  1493 solver.cpp:314] Iteration 5500 (1.52613 iter/s, 65.5251s/100 iter), loss = 3.75828
I0323 23:51:40.491259  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.53949 (* 1 = 4.53949 loss)
I0323 23:51:40.491276  1493 sgd_solver.cpp:136] Iteration 5500, lr = 0.01, m = 0.9
I0323 23:52:46.236522  1493 solver.cpp:314] Iteration 5600 (1.52107 iter/s, 65.7433s/100 iter), loss = 3.86445
I0323 23:52:46.237745  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.68713 (* 1 = 2.68713 loss)
I0323 23:52:46.237764  1493 sgd_solver.cpp:136] Iteration 5600, lr = 0.01, m = 0.9
I0323 23:53:50.701752  1493 solver.cpp:314] Iteration 5700 (1.55127 iter/s, 64.4632s/100 iter), loss = 3.74217
I0323 23:53:50.701915  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.76621 (* 1 = 4.76621 loss)
I0323 23:53:50.701934  1493 sgd_solver.cpp:136] Iteration 5700, lr = 0.01, m = 0.9
I0323 23:54:56.607148  1493 solver.cpp:314] Iteration 5800 (1.51737 iter/s, 65.9034s/100 iter), loss = 3.68885
I0323 23:54:56.607332  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.17297 (* 1 = 4.17297 loss)
I0323 23:54:56.607349  1493 sgd_solver.cpp:136] Iteration 5800, lr = 0.01, m = 0.9
I0323 23:56:02.107303  1493 solver.cpp:314] Iteration 5900 (1.52676 iter/s, 65.4981s/100 iter), loss = 3.6931
I0323 23:56:02.107419  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.28701 (* 1 = 3.28701 loss)
I0323 23:56:02.107435  1493 sgd_solver.cpp:136] Iteration 5900, lr = 0.01, m = 0.9
I0323 23:57:07.927500  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_6000.caffemodel
I0323 23:57:07.957630  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_6000.solverstate
I0323 23:57:07.971668  1493 solver.cpp:678] Iteration 6000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0
j:  : 4 : max_pr:  : 0.264802
j:  : 3 : max_pr:  : 0.408934
j:  : 2 : max_pr:  : 0.573539
j:  : 1 : max_pr:  : 0.718662
j:  : 0 : max_pr:  : 1
I0323 23:57:56.551786  1494 solver.cpp:786] class AP 1: 0.269631
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.170201
j:  : 6 : max_pr:  : 0.315961
j:  : 5 : max_pr:  : 0.38364
j:  : 4 : max_pr:  : 0.517681
j:  : 3 : max_pr:  : 0.666902
j:  : 2 : max_pr:  : 0.846671
j:  : 1 : max_pr:  : 0.973412
j:  : 0 : max_pr:  : 1
I0323 23:57:56.608112  1494 solver.cpp:786] class AP 2: 0.443134
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.238212
j:  : 6 : max_pr:  : 0.53317
j:  : 5 : max_pr:  : 0.692232
j:  : 4 : max_pr:  : 0.827159
j:  : 3 : max_pr:  : 0.909344
j:  : 2 : max_pr:  : 0.968836
j:  : 1 : max_pr:  : 0.992345
j:  : 0 : max_pr:  : 1
I0323 23:57:56.618846  1494 solver.cpp:786] class AP 3: 0.560118
I0323 23:57:56.618872  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.424294
I0323 23:57:57.662381  1484 data_reader.cpp:305] Starting prefetch of epoch 2
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0
j:  : 4 : max_pr:  : 0.279093
j:  : 3 : max_pr:  : 0.411936
j:  : 2 : max_pr:  : 0.594411
j:  : 1 : max_pr:  : 0.722571
j:  : 0 : max_pr:  : 1
I0323 23:57:58.112660  1493 solver.cpp:786] class AP 1: 0.273456
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.182652
j:  : 6 : max_pr:  : 0.333779
j:  : 5 : max_pr:  : 0.404421
j:  : 4 : max_pr:  : 0.538851
j:  : 3 : max_pr:  : 0.685891
j:  : 2 : max_pr:  : 0.86
j:  : 1 : max_pr:  : 0.978378
j:  : 0 : max_pr:  : 1
I0323 23:57:58.167145  1493 solver.cpp:786] class AP 2: 0.453088
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.216061
j:  : 6 : max_pr:  : 0.524859
j:  : 5 : max_pr:  : 0.696322
j:  : 4 : max_pr:  : 0.824334
j:  : 3 : max_pr:  : 0.903288
j:  : 2 : max_pr:  : 0.965553
j:  : 1 : max_pr:  : 0.986769
j:  : 0 : max_pr:  : 1
I0323 23:57:58.177659  1493 solver.cpp:786] class AP 3: 0.556108
I0323 23:57:58.177680  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.427551
I0323 23:57:58.177742  1493 solver.cpp:265] [MultiGPU] Tests completed in 50.2045s
I0323 23:57:58.538506  1493 solver.cpp:314] Iteration 6000 (0.858903 iter/s, 116.428s/100 iter), loss = 3.64532
I0323 23:57:58.538555  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.89105 (* 1 = 2.89105 loss)
I0323 23:57:58.538569  1493 sgd_solver.cpp:136] Iteration 6000, lr = 0.01, m = 0.9
I0323 23:59:04.232373  1493 solver.cpp:314] Iteration 6100 (1.52226 iter/s, 65.6918s/100 iter), loss = 3.72147
I0323 23:59:04.232480  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.03591 (* 1 = 3.03591 loss)
I0323 23:59:04.232498  1493 sgd_solver.cpp:136] Iteration 6100, lr = 0.01, m = 0.9
I0324 00:00:10.231567  1493 solver.cpp:314] Iteration 6200 (1.51522 iter/s, 65.9971s/100 iter), loss = 3.39948
I0324 00:00:10.231691  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.60755 (* 1 = 2.60755 loss)
I0324 00:00:10.231709  1493 sgd_solver.cpp:136] Iteration 6200, lr = 0.01, m = 0.9
I0324 00:01:15.706171  1493 solver.cpp:314] Iteration 6300 (1.52736 iter/s, 65.4725s/100 iter), loss = 3.49766
I0324 00:01:15.706274  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.26824 (* 1 = 3.26824 loss)
I0324 00:01:15.706290  1493 sgd_solver.cpp:136] Iteration 6300, lr = 0.01, m = 0.9
I0324 00:02:20.990417  1493 solver.cpp:314] Iteration 6400 (1.53181 iter/s, 65.2822s/100 iter), loss = 3.39909
I0324 00:02:20.990517  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.53965 (* 1 = 2.53965 loss)
I0324 00:02:20.990533  1493 sgd_solver.cpp:136] Iteration 6400, lr = 0.01, m = 0.9
I0324 00:03:26.161092  1493 solver.cpp:314] Iteration 6500 (1.53448 iter/s, 65.1686s/100 iter), loss = 3.6938
I0324 00:03:26.161185  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.53954 (* 1 = 2.53954 loss)
I0324 00:03:26.161201  1493 sgd_solver.cpp:136] Iteration 6500, lr = 0.01, m = 0.9
I0324 00:04:31.741350  1493 solver.cpp:314] Iteration 6600 (1.5249 iter/s, 65.5782s/100 iter), loss = 3.97862
I0324 00:04:31.741487  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.57129 (* 1 = 3.57129 loss)
I0324 00:04:31.741503  1493 sgd_solver.cpp:136] Iteration 6600, lr = 0.01, m = 0.9
I0324 00:05:37.314642  1493 solver.cpp:314] Iteration 6700 (1.52506 iter/s, 65.5712s/100 iter), loss = 3.57041
I0324 00:05:37.314831  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.81369 (* 1 = 3.81369 loss)
I0324 00:05:37.314877  1493 sgd_solver.cpp:136] Iteration 6700, lr = 0.01, m = 0.9
I0324 00:06:41.639374  1493 solver.cpp:314] Iteration 6800 (1.55466 iter/s, 64.3227s/100 iter), loss = 3.5264
I0324 00:06:41.639467  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.78112 (* 1 = 3.78112 loss)
I0324 00:06:41.639483  1493 sgd_solver.cpp:136] Iteration 6800, lr = 0.01, m = 0.9
I0324 00:07:47.377039  1493 solver.cpp:314] Iteration 6900 (1.52125 iter/s, 65.7356s/100 iter), loss = 3.51282
I0324 00:07:47.377140  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.55444 (* 1 = 4.55444 loss)
I0324 00:07:47.377157  1493 sgd_solver.cpp:136] Iteration 6900, lr = 0.01, m = 0.9
I0324 00:08:54.100044  1493 solver.cpp:314] Iteration 7000 (1.49878 iter/s, 66.7209s/100 iter), loss = 3.37651
I0324 00:08:54.100154  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.0988 (* 1 = 4.0988 loss)
I0324 00:08:54.100170  1493 sgd_solver.cpp:136] Iteration 7000, lr = 0.01, m = 0.9
I0324 00:09:59.150048  1493 solver.cpp:314] Iteration 7100 (1.53733 iter/s, 65.048s/100 iter), loss = 3.39871
I0324 00:09:59.161775  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.87484 (* 1 = 3.87484 loss)
I0324 00:09:59.161813  1493 sgd_solver.cpp:136] Iteration 7100, lr = 0.01, m = 0.9
I0324 00:11:04.106070  1493 solver.cpp:314] Iteration 7200 (1.53955 iter/s, 64.954s/100 iter), loss = 3.56878
I0324 00:11:04.106170  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.91254 (* 1 = 2.91254 loss)
I0324 00:11:04.106186  1493 sgd_solver.cpp:136] Iteration 7200, lr = 0.01, m = 0.9
I0324 00:12:10.077451  1493 solver.cpp:314] Iteration 7300 (1.51586 iter/s, 65.9693s/100 iter), loss = 3.38421
I0324 00:12:10.077558  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.33571 (* 1 = 3.33571 loss)
I0324 00:12:10.077574  1493 sgd_solver.cpp:136] Iteration 7300, lr = 0.01, m = 0.9
I0324 00:13:16.223156  1493 solver.cpp:314] Iteration 7400 (1.51186 iter/s, 66.1436s/100 iter), loss = 3.39565
I0324 00:13:16.223249  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.12179 (* 1 = 3.12179 loss)
I0324 00:13:16.223265  1493 sgd_solver.cpp:136] Iteration 7400, lr = 0.01, m = 0.9
I0324 00:14:21.378032  1493 solver.cpp:314] Iteration 7500 (1.53485 iter/s, 65.1528s/100 iter), loss = 3.29695
I0324 00:14:21.378144  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.07874 (* 1 = 4.07874 loss)
I0324 00:14:21.378160  1493 sgd_solver.cpp:136] Iteration 7500, lr = 0.01, m = 0.9
I0324 00:15:26.844632  1493 solver.cpp:314] Iteration 7600 (1.52754 iter/s, 65.4646s/100 iter), loss = 3.57633
I0324 00:15:26.844722  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.51862 (* 1 = 4.51862 loss)
I0324 00:15:26.844738  1493 sgd_solver.cpp:136] Iteration 7600, lr = 0.01, m = 0.9
I0324 00:16:32.970170  1493 solver.cpp:314] Iteration 7700 (1.51232 iter/s, 66.1235s/100 iter), loss = 3.51353
I0324 00:16:32.970261  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.10791 (* 1 = 3.10791 loss)
I0324 00:16:32.970278  1493 sgd_solver.cpp:136] Iteration 7700, lr = 0.01, m = 0.9
I0324 00:17:38.005755  1493 solver.cpp:314] Iteration 7800 (1.53767 iter/s, 65.0336s/100 iter), loss = 3.59255
I0324 00:17:38.005854  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.40926 (* 1 = 3.40926 loss)
I0324 00:17:38.005872  1493 sgd_solver.cpp:136] Iteration 7800, lr = 0.01, m = 0.9
I0324 00:18:44.916975  1493 solver.cpp:314] Iteration 7900 (1.49456 iter/s, 66.9091s/100 iter), loss = 3.68403
I0324 00:18:44.917068  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.7763 (* 1 = 2.7763 loss)
I0324 00:18:44.917083  1493 sgd_solver.cpp:136] Iteration 7900, lr = 0.01, m = 0.9
I0324 00:19:50.453608  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_8000.caffemodel
I0324 00:19:50.483727  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_8000.solverstate
I0324 00:19:50.512354  1493 solver.cpp:678] Iteration 8000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.092346
j:  : 4 : max_pr:  : 0.213431
j:  : 3 : max_pr:  : 0.375501
j:  : 2 : max_pr:  : 0.588912
j:  : 1 : max_pr:  : 0.758143
j:  : 0 : max_pr:  : 1
I0324 00:20:39.216615  1493 solver.cpp:786] class AP 1: 0.275303
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0719037
j:  : 7 : max_pr:  : 0.20478
j:  : 6 : max_pr:  : 0.354954
j:  : 5 : max_pr:  : 0.521657
j:  : 4 : max_pr:  : 0.643117
j:  : 3 : max_pr:  : 0.751513
j:  : 2 : max_pr:  : 0.850641
j:  : 1 : max_pr:  : 0.973723
j:  : 0 : max_pr:  : 1
I0324 00:20:39.252051  1493 solver.cpp:786] class AP 2: 0.48839
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.244548
j:  : 6 : max_pr:  : 0.481944
j:  : 5 : max_pr:  : 0.640816
j:  : 4 : max_pr:  : 0.791737
j:  : 3 : max_pr:  : 0.905313
j:  : 2 : max_pr:  : 0.975829
j:  : 1 : max_pr:  : 0.996547
j:  : 0 : max_pr:  : 1
I0324 00:20:39.268198  1493 solver.cpp:786] class AP 3: 0.548794
I0324 00:20:39.268215  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.437496
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.0800874
j:  : 4 : max_pr:  : 0.18886
j:  : 3 : max_pr:  : 0.34786
j:  : 2 : max_pr:  : 0.560818
j:  : 1 : max_pr:  : 0.754334
j:  : 0 : max_pr:  : 1
I0324 00:20:40.112000  1494 solver.cpp:786] class AP 1: 0.266542
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0622612
j:  : 7 : max_pr:  : 0.193643
j:  : 6 : max_pr:  : 0.348679
j:  : 5 : max_pr:  : 0.51807
j:  : 4 : max_pr:  : 0.625216
j:  : 3 : max_pr:  : 0.733977
j:  : 2 : max_pr:  : 0.822309
j:  : 1 : max_pr:  : 0.974203
j:  : 0 : max_pr:  : 1
I0324 00:20:40.149173  1494 solver.cpp:786] class AP 2: 0.479851
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.240872
j:  : 6 : max_pr:  : 0.481904
j:  : 5 : max_pr:  : 0.61906
j:  : 4 : max_pr:  : 0.780258
j:  : 3 : max_pr:  : 0.907002
j:  : 2 : max_pr:  : 0.971448
j:  : 1 : max_pr:  : 0.997216
j:  : 0 : max_pr:  : 1
I0324 00:20:40.165241  1494 solver.cpp:786] class AP 3: 0.545251
I0324 00:20:40.165258  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.430548
I0324 00:20:40.165453  1493 solver.cpp:265] [MultiGPU] Tests completed in 49.6516s
I0324 00:20:40.645059  1493 solver.cpp:314] Iteration 8000 (0.864121 iter/s, 115.725s/100 iter), loss = 3.43207
I0324 00:20:40.645100  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.71073 (* 1 = 2.71073 loss)
I0324 00:20:40.645110  1493 sgd_solver.cpp:136] Iteration 8000, lr = 0.01, m = 0.9
I0324 00:21:45.682251  1493 solver.cpp:314] Iteration 8100 (1.53763 iter/s, 65.0352s/100 iter), loss = 3.52282
I0324 00:21:45.682437  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.28748 (* 1 = 3.28748 loss)
I0324 00:21:45.682477  1493 sgd_solver.cpp:136] Iteration 8100, lr = 0.01, m = 0.9
I0324 00:22:51.604496  1493 solver.cpp:314] Iteration 8200 (1.51699 iter/s, 65.9202s/100 iter), loss = 3.45494
I0324 00:22:51.604954  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.49514 (* 1 = 3.49514 loss)
I0324 00:22:51.605249  1493 sgd_solver.cpp:136] Iteration 8200, lr = 0.01, m = 0.9
I0324 00:23:57.259727  1493 solver.cpp:314] Iteration 8300 (1.52315 iter/s, 65.6532s/100 iter), loss = 3.48424
I0324 00:23:57.259883  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.86053 (* 1 = 2.86053 loss)
I0324 00:23:57.259923  1493 sgd_solver.cpp:136] Iteration 8300, lr = 0.01, m = 0.9
I0324 00:25:02.766027  1493 solver.cpp:314] Iteration 8400 (1.52662 iter/s, 65.5043s/100 iter), loss = 3.20079
I0324 00:25:02.766129  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.87111 (* 1 = 3.87111 loss)
I0324 00:25:02.766145  1493 sgd_solver.cpp:136] Iteration 8400, lr = 0.01, m = 0.9
I0324 00:26:08.209748  1493 solver.cpp:314] Iteration 8500 (1.52808 iter/s, 65.4417s/100 iter), loss = 3.68466
I0324 00:26:08.214956  1493 solver.cpp:336]     Train net output #0: mbox_loss = 5.14123 (* 1 = 5.14123 loss)
I0324 00:26:08.215009  1493 sgd_solver.cpp:136] Iteration 8500, lr = 0.01, m = 0.9
I0324 00:27:13.486155  1493 solver.cpp:314] Iteration 8600 (1.53199 iter/s, 65.2744s/100 iter), loss = 3.50389
I0324 00:27:13.486246  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.07484 (* 1 = 4.07484 loss)
I0324 00:27:13.486263  1493 sgd_solver.cpp:136] Iteration 8600, lr = 0.01, m = 0.9
I0324 00:28:18.958425  1493 solver.cpp:314] Iteration 8700 (1.52741 iter/s, 65.4703s/100 iter), loss = 3.47908
I0324 00:28:18.958520  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.26346 (* 1 = 3.26346 loss)
I0324 00:28:18.958536  1493 sgd_solver.cpp:136] Iteration 8700, lr = 0.01, m = 0.9
I0324 00:29:24.352366  1493 solver.cpp:314] Iteration 8800 (1.52924 iter/s, 65.3919s/100 iter), loss = 3.79761
I0324 00:29:24.352463  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.68835 (* 1 = 4.68835 loss)
I0324 00:29:24.352479  1493 sgd_solver.cpp:136] Iteration 8800, lr = 0.01, m = 0.9
I0324 00:30:31.694037  1493 solver.cpp:314] Iteration 8900 (1.48501 iter/s, 67.3396s/100 iter), loss = 3.53406
I0324 00:30:31.694169  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.56952 (* 1 = 3.56952 loss)
I0324 00:30:31.694185  1493 sgd_solver.cpp:136] Iteration 8900, lr = 0.01, m = 0.9
I0324 00:31:37.121475  1493 solver.cpp:314] Iteration 9000 (1.52846 iter/s, 65.4254s/100 iter), loss = 3.58133
I0324 00:31:37.121662  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.81429 (* 1 = 2.81429 loss)
I0324 00:31:37.121726  1493 sgd_solver.cpp:136] Iteration 9000, lr = 0.01, m = 0.9
I0324 00:31:54.971845  1462 data_reader.cpp:305] Starting prefetch of epoch 2
I0324 00:32:43.386075  1493 solver.cpp:314] Iteration 9100 (1.50915 iter/s, 66.2625s/100 iter), loss = 3.60358
I0324 00:32:43.386176  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.04168 (* 1 = 3.04168 loss)
I0324 00:32:43.386193  1493 sgd_solver.cpp:136] Iteration 9100, lr = 0.01, m = 0.9
I0324 00:33:48.909031  1493 solver.cpp:314] Iteration 9200 (1.52623 iter/s, 65.5209s/100 iter), loss = 3.43796
I0324 00:33:48.909135  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.18362 (* 1 = 2.18362 loss)
I0324 00:33:48.909153  1493 sgd_solver.cpp:136] Iteration 9200, lr = 0.01, m = 0.9
I0324 00:34:54.677342  1493 solver.cpp:314] Iteration 9300 (1.52054 iter/s, 65.7662s/100 iter), loss = 3.58827
I0324 00:34:54.677464  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.16888 (* 1 = 3.16888 loss)
I0324 00:34:54.677481  1493 sgd_solver.cpp:136] Iteration 9300, lr = 0.01, m = 0.9
I0324 00:36:00.543059  1493 solver.cpp:314] Iteration 9400 (1.51829 iter/s, 65.8636s/100 iter), loss = 3.54996
I0324 00:36:00.543151  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.80996 (* 1 = 3.80996 loss)
I0324 00:36:00.543167  1493 sgd_solver.cpp:136] Iteration 9400, lr = 0.01, m = 0.9
I0324 00:37:07.125758  1493 solver.cpp:314] Iteration 9500 (1.50194 iter/s, 66.5806s/100 iter), loss = 3.73318
I0324 00:37:07.128546  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.14847 (* 1 = 3.14847 loss)
I0324 00:37:07.128578  1493 sgd_solver.cpp:136] Iteration 9500, lr = 0.01, m = 0.9
I0324 00:38:13.182322  1493 solver.cpp:314] Iteration 9600 (1.5139 iter/s, 66.0545s/100 iter), loss = 3.34628
I0324 00:38:13.189757  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.1029 (* 1 = 3.1029 loss)
I0324 00:38:13.189786  1493 sgd_solver.cpp:136] Iteration 9600, lr = 0.01, m = 0.9
I0324 00:39:18.289948  1493 solver.cpp:314] Iteration 9700 (1.53597 iter/s, 65.1056s/100 iter), loss = 3.59371
I0324 00:39:18.290057  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.73427 (* 1 = 3.73427 loss)
I0324 00:39:18.290076  1493 sgd_solver.cpp:136] Iteration 9700, lr = 0.01, m = 0.9
I0324 00:40:23.290082  1493 solver.cpp:314] Iteration 9800 (1.53851 iter/s, 64.9981s/100 iter), loss = 3.3753
I0324 00:40:23.290187  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.01297 (* 1 = 3.01297 loss)
I0324 00:40:23.290202  1493 sgd_solver.cpp:136] Iteration 9800, lr = 0.01, m = 0.9
I0324 00:41:28.307837  1493 solver.cpp:314] Iteration 9900 (1.53809 iter/s, 65.0157s/100 iter), loss = 3.72817
I0324 00:41:28.307951  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.82434 (* 1 = 3.82434 loss)
I0324 00:41:28.307968  1493 sgd_solver.cpp:136] Iteration 9900, lr = 0.01, m = 0.9
I0324 00:42:32.880717  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_10000.caffemodel
I0324 00:42:32.914347  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_10000.solverstate
I0324 00:42:32.927933  1493 solver.cpp:678] Iteration 10000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.0883842
j:  : 4 : max_pr:  : 0.210196
j:  : 3 : max_pr:  : 0.382536
j:  : 2 : max_pr:  : 0.606086
j:  : 1 : max_pr:  : 0.763236
j:  : 0 : max_pr:  : 1
I0324 00:43:23.928879  1494 solver.cpp:786] class AP 1: 0.277313
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0.173365
j:  : 5 : max_pr:  : 0.296098
j:  : 4 : max_pr:  : 0.37654
j:  : 3 : max_pr:  : 0.466344
j:  : 2 : max_pr:  : 0.682019
j:  : 1 : max_pr:  : 0.995392
j:  : 0 : max_pr:  : 1
I0324 00:43:23.953594  1494 solver.cpp:786] class AP 2: 0.362705
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.139919
j:  : 6 : max_pr:  : 0.378528
j:  : 5 : max_pr:  : 0.604776
j:  : 4 : max_pr:  : 0.750606
j:  : 3 : max_pr:  : 0.904917
j:  : 2 : max_pr:  : 0.96203
j:  : 1 : max_pr:  : 0.997467
j:  : 0 : max_pr:  : 1
I0324 00:43:23.974536  1494 solver.cpp:786] class AP 3: 0.521658
I0324 00:43:23.974566  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.387225
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.0986902
j:  : 4 : max_pr:  : 0.219218
j:  : 3 : max_pr:  : 0.387883
j:  : 2 : max_pr:  : 0.609197
j:  : 1 : max_pr:  : 0.788062
j:  : 0 : max_pr:  : 1
I0324 00:43:24.445469  1493 solver.cpp:786] class AP 1: 0.282096
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0.181738
j:  : 5 : max_pr:  : 0.312734
j:  : 4 : max_pr:  : 0.395303
j:  : 3 : max_pr:  : 0.508448
j:  : 2 : max_pr:  : 0.703167
j:  : 1 : max_pr:  : 0.987934
j:  : 0 : max_pr:  : 1
I0324 00:43:24.464617  1493 solver.cpp:786] class AP 2: 0.371757
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.136155
j:  : 6 : max_pr:  : 0.402046
j:  : 5 : max_pr:  : 0.607677
j:  : 4 : max_pr:  : 0.764279
j:  : 3 : max_pr:  : 0.910002
j:  : 2 : max_pr:  : 0.96697
j:  : 1 : max_pr:  : 0.997945
j:  : 0 : max_pr:  : 1
I0324 00:43:24.481138  1493 solver.cpp:786] class AP 3: 0.525916
I0324 00:43:24.481165  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.393256
I0324 00:43:24.481240  1493 solver.cpp:265] [MultiGPU] Tests completed in 51.5517s
I0324 00:43:24.806480  1493 solver.cpp:314] Iteration 10000 (0.858406 iter/s, 116.495s/100 iter), loss = 3.56671
I0324 00:43:24.806599  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.35555 (* 1 = 3.35555 loss)
I0324 00:43:24.806639  1493 sgd_solver.cpp:136] Iteration 10000, lr = 0.01, m = 0.9
I0324 00:44:29.202270  1493 solver.cpp:314] Iteration 10100 (1.55295 iter/s, 64.3937s/100 iter), loss = 3.37112
I0324 00:44:29.202379  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.52113 (* 1 = 2.52113 loss)
I0324 00:44:29.202397  1493 sgd_solver.cpp:136] Iteration 10100, lr = 0.01, m = 0.9
I0324 00:45:34.875838  1493 solver.cpp:314] Iteration 10200 (1.52273 iter/s, 65.6715s/100 iter), loss = 3.46496
I0324 00:45:34.875946  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.62065 (* 1 = 2.62065 loss)
I0324 00:45:34.875963  1493 sgd_solver.cpp:136] Iteration 10200, lr = 0.01, m = 0.9
I0324 00:46:42.261962  1493 solver.cpp:314] Iteration 10300 (1.48403 iter/s, 67.384s/100 iter), loss = 3.2301
I0324 00:46:42.262140  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.39753 (* 1 = 4.39753 loss)
I0324 00:46:42.262195  1493 sgd_solver.cpp:136] Iteration 10300, lr = 0.01, m = 0.9
I0324 00:47:48.443289  1493 solver.cpp:314] Iteration 10400 (1.51105 iter/s, 66.1792s/100 iter), loss = 3.40286
I0324 00:47:48.443404  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.20781 (* 1 = 3.20781 loss)
I0324 00:47:48.443423  1493 sgd_solver.cpp:136] Iteration 10400, lr = 0.01, m = 0.9
I0324 00:48:53.699035  1493 solver.cpp:314] Iteration 10500 (1.53248 iter/s, 65.2537s/100 iter), loss = 3.59113
I0324 00:48:53.699147  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.34281 (* 1 = 4.34281 loss)
I0324 00:48:53.699164  1493 sgd_solver.cpp:136] Iteration 10500, lr = 0.01, m = 0.9
I0324 00:49:59.703778  1493 solver.cpp:314] Iteration 10600 (1.51509 iter/s, 66.0027s/100 iter), loss = 3.29992
I0324 00:49:59.703894  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.0981 (* 1 = 4.0981 loss)
I0324 00:49:59.703910  1493 sgd_solver.cpp:136] Iteration 10600, lr = 0.01, m = 0.9
I0324 00:51:05.309868  1493 solver.cpp:314] Iteration 10700 (1.5243 iter/s, 65.604s/100 iter), loss = 3.32804
I0324 00:51:05.309975  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.08175 (* 1 = 4.08175 loss)
I0324 00:51:05.309994  1493 sgd_solver.cpp:136] Iteration 10700, lr = 0.01, m = 0.9
I0324 00:52:12.448505  1493 solver.cpp:314] Iteration 10800 (1.4895 iter/s, 67.1365s/100 iter), loss = 3.40371
I0324 00:52:12.448608  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.73724 (* 1 = 3.73724 loss)
I0324 00:52:12.448626  1493 sgd_solver.cpp:136] Iteration 10800, lr = 0.01, m = 0.9
I0324 00:53:18.743923  1493 solver.cpp:314] Iteration 10900 (1.50845 iter/s, 66.2933s/100 iter), loss = 3.47074
I0324 00:53:18.744033  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.52648 (* 1 = 3.52648 loss)
I0324 00:53:18.744048  1493 sgd_solver.cpp:136] Iteration 10900, lr = 0.01, m = 0.9
I0324 00:54:25.006358  1493 solver.cpp:314] Iteration 11000 (1.5092 iter/s, 66.2602s/100 iter), loss = 3.59654
I0324 00:54:25.006561  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.91716 (* 1 = 3.91716 loss)
I0324 00:54:25.006579  1493 sgd_solver.cpp:136] Iteration 11000, lr = 0.01, m = 0.9
I0324 00:55:31.823015  1493 solver.cpp:314] Iteration 11100 (1.49668 iter/s, 66.8145s/100 iter), loss = 3.40073
I0324 00:55:31.823153  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.05204 (* 1 = 3.05204 loss)
I0324 00:55:31.823184  1493 sgd_solver.cpp:136] Iteration 11100, lr = 0.01, m = 0.9
I0324 00:56:39.242735  1493 solver.cpp:314] Iteration 11200 (1.48329 iter/s, 67.4175s/100 iter), loss = 3.35049
I0324 00:56:39.246502  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.85504 (* 1 = 2.85504 loss)
I0324 00:56:39.246537  1493 sgd_solver.cpp:136] Iteration 11200, lr = 0.01, m = 0.9
I0324 00:57:45.520761  1493 solver.cpp:314] Iteration 11300 (1.50885 iter/s, 66.2758s/100 iter), loss = 3.18078
I0324 00:57:45.520859  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.7724 (* 1 = 3.7724 loss)
I0324 00:57:45.520875  1493 sgd_solver.cpp:136] Iteration 11300, lr = 0.01, m = 0.9
I0324 00:58:52.693975  1493 solver.cpp:314] Iteration 11400 (1.48874 iter/s, 67.171s/100 iter), loss = 3.44213
I0324 00:58:52.694073  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.813 (* 1 = 2.813 loss)
I0324 00:58:52.694090  1493 sgd_solver.cpp:136] Iteration 11400, lr = 0.01, m = 0.9
I0324 00:59:59.712666  1493 solver.cpp:314] Iteration 11500 (1.49217 iter/s, 67.0165s/100 iter), loss = 3.50918
I0324 00:59:59.712762  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.7648 (* 1 = 2.7648 loss)
I0324 00:59:59.712777  1493 sgd_solver.cpp:136] Iteration 11500, lr = 0.01, m = 0.9
I0324 01:01:05.725922  1493 solver.cpp:314] Iteration 11600 (1.5149 iter/s, 66.0111s/100 iter), loss = 3.35634
I0324 01:01:05.726014  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.81372 (* 1 = 3.81372 loss)
I0324 01:01:05.726029  1493 sgd_solver.cpp:136] Iteration 11600, lr = 0.01, m = 0.9
I0324 01:02:13.388463  1493 solver.cpp:314] Iteration 11700 (1.47797 iter/s, 67.6603s/100 iter), loss = 3.38503
I0324 01:02:13.388573  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.92131 (* 1 = 3.92131 loss)
I0324 01:02:13.388590  1493 sgd_solver.cpp:136] Iteration 11700, lr = 0.01, m = 0.9
I0324 01:03:21.765744  1493 solver.cpp:314] Iteration 11800 (1.46252 iter/s, 68.3751s/100 iter), loss = 3.26905
I0324 01:03:21.765934  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.69845 (* 1 = 4.69845 loss)
I0324 01:03:21.765952  1493 sgd_solver.cpp:136] Iteration 11800, lr = 0.01, m = 0.9
I0324 01:04:29.253662  1493 solver.cpp:314] Iteration 11900 (1.48179 iter/s, 67.4857s/100 iter), loss = 3.44823
I0324 01:04:29.253777  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.10163 (* 1 = 4.10163 loss)
I0324 01:04:29.253832  1493 sgd_solver.cpp:136] Iteration 11900, lr = 0.01, m = 0.9
I0324 01:05:35.044499  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_12000.caffemodel
I0324 01:05:35.074874  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_12000.solverstate
I0324 01:05:35.088021  1493 solver.cpp:678] Iteration 12000, Testing net (#0)
I0324 01:06:25.431396  1484 data_reader.cpp:305] Starting prefetch of epoch 3
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.127876
j:  : 4 : max_pr:  : 0.28951
j:  : 3 : max_pr:  : 0.493061
j:  : 2 : max_pr:  : 0.660776
j:  : 1 : max_pr:  : 0.813529
j:  : 0 : max_pr:  : 1
I0324 01:06:26.228066  1493 solver.cpp:786] class AP 1: 0.307705
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.0430357
j:  : 6 : max_pr:  : 0.29075
j:  : 5 : max_pr:  : 0.393084
j:  : 4 : max_pr:  : 0.611717
j:  : 3 : max_pr:  : 0.656686
j:  : 2 : max_pr:  : 0.804497
j:  : 1 : max_pr:  : 0.967456
j:  : 0 : max_pr:  : 1
I0324 01:06:26.273908  1493 solver.cpp:786] class AP 2: 0.433384
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.310813
j:  : 6 : max_pr:  : 0.6223
j:  : 5 : max_pr:  : 0.707463
j:  : 4 : max_pr:  : 0.839286
j:  : 3 : max_pr:  : 0.918442
j:  : 2 : max_pr:  : 0.971663
j:  : 1 : max_pr:  : 0.993127
j:  : 0 : max_pr:  : 1
I0324 01:06:26.300473  1493 solver.cpp:786] class AP 3: 0.578463
I0324 01:06:26.300499  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.439851
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.137418
j:  : 4 : max_pr:  : 0.294831
j:  : 3 : max_pr:  : 0.498303
j:  : 2 : max_pr:  : 0.664343
j:  : 1 : max_pr:  : 0.81264
j:  : 0 : max_pr:  : 1
I0324 01:06:27.018479  1494 solver.cpp:786] class AP 1: 0.309776
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.0670853
j:  : 6 : max_pr:  : 0.314141
j:  : 5 : max_pr:  : 0.411594
j:  : 4 : max_pr:  : 0.616021
j:  : 3 : max_pr:  : 0.654193
j:  : 2 : max_pr:  : 0.800121
j:  : 1 : max_pr:  : 0.98051
j:  : 0 : max_pr:  : 1
I0324 01:06:27.053040  1494 solver.cpp:786] class AP 2: 0.440333
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.316018
j:  : 6 : max_pr:  : 0.625187
j:  : 5 : max_pr:  : 0.702768
j:  : 4 : max_pr:  : 0.831273
j:  : 3 : max_pr:  : 0.932902
j:  : 2 : max_pr:  : 0.977693
j:  : 1 : max_pr:  : 0.996556
j:  : 0 : max_pr:  : 1
I0324 01:06:27.073181  1494 solver.cpp:786] class AP 3: 0.580218
I0324 01:06:27.073199  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.443442
I0324 01:06:27.073773  1493 solver.cpp:265] [MultiGPU] Tests completed in 51.9841s
I0324 01:06:27.463096  1493 solver.cpp:314] Iteration 12000 (0.845983 iter/s, 118.206s/100 iter), loss = 3.27902
I0324 01:06:27.463147  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.22057 (* 1 = 4.22057 loss)
I0324 01:06:27.463157  1493 sgd_solver.cpp:136] Iteration 12000, lr = 0.01, m = 0.9
I0324 01:07:33.652843  1493 solver.cpp:314] Iteration 12100 (1.51086 iter/s, 66.1876s/100 iter), loss = 3.35193
I0324 01:07:33.652976  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.28957 (* 1 = 3.28957 loss)
I0324 01:07:33.652992  1493 sgd_solver.cpp:136] Iteration 12100, lr = 0.01, m = 0.9
I0324 01:08:41.037922  1493 solver.cpp:314] Iteration 12200 (1.48406 iter/s, 67.3828s/100 iter), loss = 3.64089
I0324 01:08:41.038036  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.45423 (* 1 = 3.45423 loss)
I0324 01:08:41.038053  1493 sgd_solver.cpp:136] Iteration 12200, lr = 0.01, m = 0.9
I0324 01:09:46.954119  1493 solver.cpp:314] Iteration 12300 (1.51713 iter/s, 65.914s/100 iter), loss = 3.38768
I0324 01:09:46.954223  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.10304 (* 1 = 4.10304 loss)
I0324 01:09:46.954238  1493 sgd_solver.cpp:136] Iteration 12300, lr = 0.01, m = 0.9
I0324 01:10:55.405983  1493 solver.cpp:314] Iteration 12400 (1.46093 iter/s, 68.4496s/100 iter), loss = 3.25215
I0324 01:10:55.406078  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.16809 (* 1 = 3.16809 loss)
I0324 01:10:55.406129  1493 sgd_solver.cpp:136] Iteration 12400, lr = 0.01, m = 0.9
I0324 01:12:03.290380  1493 solver.cpp:314] Iteration 12500 (1.47314 iter/s, 67.8822s/100 iter), loss = 3.60075
I0324 01:12:03.290477  1493 solver.cpp:336]     Train net output #0: mbox_loss = 5.87083 (* 1 = 5.87083 loss)
I0324 01:12:03.290491  1493 sgd_solver.cpp:136] Iteration 12500, lr = 0.01, m = 0.9
I0324 01:13:10.693929  1493 solver.cpp:314] Iteration 12600 (1.48365 iter/s, 67.4013s/100 iter), loss = 3.10517
I0324 01:13:10.694031  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.68245 (* 1 = 2.68245 loss)
I0324 01:13:10.694047  1493 sgd_solver.cpp:136] Iteration 12600, lr = 0.01, m = 0.9
I0324 01:14:18.174289  1493 solver.cpp:314] Iteration 12700 (1.48196 iter/s, 67.4781s/100 iter), loss = 3.19785
I0324 01:14:18.174453  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.82778 (* 1 = 2.82778 loss)
I0324 01:14:18.174485  1493 sgd_solver.cpp:136] Iteration 12700, lr = 0.01, m = 0.9
I0324 01:15:24.862468  1493 solver.cpp:314] Iteration 12800 (1.49957 iter/s, 66.686s/100 iter), loss = 3.24914
I0324 01:15:24.862571  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.96787 (* 1 = 2.96787 loss)
I0324 01:15:24.862589  1493 sgd_solver.cpp:136] Iteration 12800, lr = 0.01, m = 0.9
I0324 01:16:32.100735  1493 solver.cpp:314] Iteration 12900 (1.4873 iter/s, 67.236s/100 iter), loss = 3.50869
I0324 01:16:32.100921  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.99681 (* 1 = 3.99681 loss)
I0324 01:16:32.100965  1493 sgd_solver.cpp:136] Iteration 12900, lr = 0.01, m = 0.9
I0324 01:17:40.478075  1493 solver.cpp:314] Iteration 13000 (1.46252 iter/s, 68.3751s/100 iter), loss = 3.68001
I0324 01:17:40.478171  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.8691 (* 1 = 3.8691 loss)
I0324 01:17:40.478188  1493 sgd_solver.cpp:136] Iteration 13000, lr = 0.01, m = 0.9
I0324 01:18:47.891790  1493 solver.cpp:314] Iteration 13100 (1.48343 iter/s, 67.4115s/100 iter), loss = 3.59265
I0324 01:18:47.891897  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.57936 (* 1 = 3.57936 loss)
I0324 01:18:47.891914  1493 sgd_solver.cpp:136] Iteration 13100, lr = 0.01, m = 0.9
I0324 01:19:54.686573  1493 solver.cpp:314] Iteration 13200 (1.49717 iter/s, 66.7926s/100 iter), loss = 3.30138
I0324 01:19:54.686673  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.20258 (* 1 = 4.20258 loss)
I0324 01:19:54.686689  1493 sgd_solver.cpp:136] Iteration 13200, lr = 0.01, m = 0.9
I0324 01:21:02.797778  1493 solver.cpp:314] Iteration 13300 (1.46824 iter/s, 68.109s/100 iter), loss = 3.26095
I0324 01:21:02.797889  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.90228 (* 1 = 2.90228 loss)
I0324 01:21:02.797910  1493 sgd_solver.cpp:136] Iteration 13300, lr = 0.01, m = 0.9
I0324 01:22:10.458333  1493 solver.cpp:314] Iteration 13400 (1.47801 iter/s, 67.6583s/100 iter), loss = 3.54356
I0324 01:22:10.458467  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.07579 (* 1 = 3.07579 loss)
I0324 01:22:10.458482  1493 sgd_solver.cpp:136] Iteration 13400, lr = 0.01, m = 0.9
I0324 01:23:16.814280  1493 solver.cpp:314] Iteration 13500 (1.50708 iter/s, 66.3535s/100 iter), loss = 3.35192
I0324 01:23:16.814378  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.5404 (* 1 = 3.5404 loss)
I0324 01:23:16.814394  1493 sgd_solver.cpp:136] Iteration 13500, lr = 0.01, m = 0.9
I0324 01:24:25.011915  1493 solver.cpp:314] Iteration 13600 (1.46638 iter/s, 68.1951s/100 iter), loss = 3.50063
I0324 01:24:25.012024  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.7827 (* 1 = 2.7827 loss)
I0324 01:24:25.012048  1493 sgd_solver.cpp:136] Iteration 13600, lr = 0.01, m = 0.9
I0324 01:25:32.315466  1493 solver.cpp:314] Iteration 13700 (1.48586 iter/s, 67.301s/100 iter), loss = 3.77392
I0324 01:25:32.315582  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.25484 (* 1 = 3.25484 loss)
I0324 01:25:32.315600  1493 sgd_solver.cpp:136] Iteration 13700, lr = 0.01, m = 0.9
I0324 01:26:40.636320  1493 solver.cpp:314] Iteration 13800 (1.46374 iter/s, 68.3183s/100 iter), loss = 3.71731
I0324 01:26:40.636418  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.48557 (* 1 = 3.48557 loss)
I0324 01:26:40.636432  1493 sgd_solver.cpp:136] Iteration 13800, lr = 0.01, m = 0.9
I0324 01:27:46.901612  1493 solver.cpp:314] Iteration 13900 (1.50914 iter/s, 66.2628s/100 iter), loss = 3.32985
I0324 01:27:46.901718  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.73953 (* 1 = 3.73953 loss)
I0324 01:27:46.901734  1493 sgd_solver.cpp:136] Iteration 13900, lr = 0.01, m = 0.9
I0324 01:28:53.282320  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_14000.caffemodel
I0324 01:28:53.336619  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_14000.solverstate
I0324 01:28:53.351231  1493 solver.cpp:678] Iteration 14000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0
j:  : 4 : max_pr:  : 0.227073
j:  : 3 : max_pr:  : 0.463404
j:  : 2 : max_pr:  : 0.672385
j:  : 1 : max_pr:  : 0.79947
j:  : 0 : max_pr:  : 1
I0324 01:29:42.248080  1493 solver.cpp:786] class AP 1: 0.287485
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.141378
j:  : 6 : max_pr:  : 0.333069
j:  : 5 : max_pr:  : 0.416479
j:  : 4 : max_pr:  : 0.582929
j:  : 3 : max_pr:  : 0.685145
j:  : 2 : max_pr:  : 0.962035
j:  : 1 : max_pr:  : 0.993912
j:  : 0 : max_pr:  : 1
I0324 01:29:42.299069  1493 solver.cpp:786] class AP 2: 0.464995
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.407772
j:  : 6 : max_pr:  : 0.590134
j:  : 5 : max_pr:  : 0.695768
j:  : 4 : max_pr:  : 0.822665
j:  : 3 : max_pr:  : 0.901765
j:  : 2 : max_pr:  : 0.950267
j:  : 1 : max_pr:  : 0.998693
j:  : 0 : max_pr:  : 1
I0324 01:29:42.315351  1493 solver.cpp:786] class AP 3: 0.578824
I0324 01:29:42.315390  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.443768
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0
j:  : 4 : max_pr:  : 0.263239
j:  : 3 : max_pr:  : 0.498149
j:  : 2 : max_pr:  : 0.69049
j:  : 1 : max_pr:  : 0.814978
j:  : 0 : max_pr:  : 1
I0324 01:29:43.539805  1494 solver.cpp:786] class AP 1: 0.296987
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.154981
j:  : 6 : max_pr:  : 0.348476
j:  : 5 : max_pr:  : 0.435568
j:  : 4 : max_pr:  : 0.595926
j:  : 3 : max_pr:  : 0.705196
j:  : 2 : max_pr:  : 0.972933
j:  : 1 : max_pr:  : 0.997337
j:  : 0 : max_pr:  : 1
I0324 01:29:43.589936  1494 solver.cpp:786] class AP 2: 0.473674
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.393673
j:  : 6 : max_pr:  : 0.579096
j:  : 5 : max_pr:  : 0.686226
j:  : 4 : max_pr:  : 0.813333
j:  : 3 : max_pr:  : 0.901261
j:  : 2 : max_pr:  : 0.954762
j:  : 1 : max_pr:  : 0.999295
j:  : 0 : max_pr:  : 1
I0324 01:29:43.605798  1494 solver.cpp:786] class AP 3: 0.575241
I0324 01:29:43.605829  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.448634
I0324 01:29:43.606343  1493 solver.cpp:265] [MultiGPU] Tests completed in 50.2533s
I0324 01:29:44.034678  1493 solver.cpp:314] Iteration 14000 (0.853761 iter/s, 117.129s/100 iter), loss = 3.44722
I0324 01:29:44.034723  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.93244 (* 1 = 2.93244 loss)
I0324 01:29:44.034736  1493 sgd_solver.cpp:136] Iteration 14000, lr = 0.01, m = 0.9
I0324 01:30:50.603837  1493 solver.cpp:314] Iteration 14100 (1.50225 iter/s, 66.5667s/100 iter), loss = 3.33066
I0324 01:30:50.603941  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.91316 (* 1 = 2.91316 loss)
I0324 01:30:50.603956  1493 sgd_solver.cpp:136] Iteration 14100, lr = 0.01, m = 0.9
I0324 01:31:58.909924  1493 solver.cpp:314] Iteration 14200 (1.46405 iter/s, 68.3036s/100 iter), loss = 3.34804
I0324 01:31:58.910025  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.70849 (* 1 = 2.70849 loss)
I0324 01:31:58.910043  1493 sgd_solver.cpp:136] Iteration 14200, lr = 0.01, m = 0.9
I0324 01:33:05.977946  1493 solver.cpp:314] Iteration 14300 (1.49108 iter/s, 67.0655s/100 iter), loss = 3.60798
I0324 01:33:05.978139  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.2952 (* 1 = 4.2952 loss)
I0324 01:33:05.978183  1493 sgd_solver.cpp:136] Iteration 14300, lr = 0.01, m = 0.9
I0324 01:34:14.171448  1493 solver.cpp:314] Iteration 14400 (1.46647 iter/s, 68.191s/100 iter), loss = 3.31727
I0324 01:34:14.171581  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.3488 (* 1 = 3.3488 loss)
I0324 01:34:14.171602  1493 sgd_solver.cpp:136] Iteration 14400, lr = 0.01, m = 0.9
I0324 01:35:21.633782  1493 solver.cpp:314] Iteration 14500 (1.48236 iter/s, 67.4599s/100 iter), loss = 3.48788
I0324 01:35:21.633913  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.22493 (* 1 = 3.22493 loss)
I0324 01:35:21.633929  1493 sgd_solver.cpp:136] Iteration 14500, lr = 0.01, m = 0.9
I0324 01:36:29.464287  1493 solver.cpp:314] Iteration 14600 (1.47432 iter/s, 67.828s/100 iter), loss = 3.47816
I0324 01:36:29.464449  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.53951 (* 1 = 2.53951 loss)
I0324 01:36:29.464494  1493 sgd_solver.cpp:136] Iteration 14600, lr = 0.01, m = 0.9
I0324 01:37:36.945614  1493 solver.cpp:314] Iteration 14700 (1.48195 iter/s, 67.4789s/100 iter), loss = 3.74746
I0324 01:37:36.945734  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.5235 (* 1 = 2.5235 loss)
I0324 01:37:36.945752  1493 sgd_solver.cpp:136] Iteration 14700, lr = 0.01, m = 0.9
I0324 01:38:45.589309  1493 solver.cpp:314] Iteration 14800 (1.45685 iter/s, 68.6412s/100 iter), loss = 3.25079
I0324 01:38:45.589817  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.36086 (* 1 = 3.36086 loss)
I0324 01:38:45.589860  1493 sgd_solver.cpp:136] Iteration 14800, lr = 0.01, m = 0.9
I0324 01:39:53.036111  1493 solver.cpp:314] Iteration 14900 (1.4827 iter/s, 67.4444s/100 iter), loss = 3.45229
I0324 01:39:53.036213  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.75269 (* 1 = 2.75269 loss)
I0324 01:39:53.036228  1493 sgd_solver.cpp:136] Iteration 14900, lr = 0.01, m = 0.9
I0324 01:40:16.971506  1462 data_reader.cpp:305] Starting prefetch of epoch 3
I0324 01:41:00.541577  1493 solver.cpp:314] Iteration 15000 (1.48142 iter/s, 67.5029s/100 iter), loss = 3.31357
I0324 01:41:00.541710  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.92953 (* 1 = 2.92953 loss)
I0324 01:41:00.541731  1493 sgd_solver.cpp:136] Iteration 15000, lr = 0.01, m = 0.9
I0324 01:42:07.445760  1493 solver.cpp:314] Iteration 15100 (1.49474 iter/s, 66.9014s/100 iter), loss = 3.19273
I0324 01:42:07.453832  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.50422 (* 1 = 2.50422 loss)
I0324 01:42:07.453891  1493 sgd_solver.cpp:136] Iteration 15100, lr = 0.01, m = 0.9
I0324 01:43:14.975728  1493 solver.cpp:314] Iteration 15200 (1.48088 iter/s, 67.5272s/100 iter), loss = 3.41622
I0324 01:43:14.975824  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.44342 (* 1 = 3.44342 loss)
I0324 01:43:14.975841  1493 sgd_solver.cpp:136] Iteration 15200, lr = 0.01, m = 0.9
I0324 01:44:23.045131  1493 solver.cpp:314] Iteration 15300 (1.46915 iter/s, 68.0667s/100 iter), loss = 3.53393
I0324 01:44:23.045235  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.06966 (* 1 = 4.06966 loss)
I0324 01:44:23.045251  1493 sgd_solver.cpp:136] Iteration 15300, lr = 0.01, m = 0.9
I0324 01:45:31.008242  1493 solver.cpp:314] Iteration 15400 (1.47145 iter/s, 67.9604s/100 iter), loss = 3.57076
I0324 01:45:31.008404  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.99108 (* 1 = 2.99108 loss)
I0324 01:45:31.008450  1493 sgd_solver.cpp:136] Iteration 15400, lr = 0.01, m = 0.9
I0324 01:46:37.874505  1493 solver.cpp:314] Iteration 15500 (1.49558 iter/s, 66.8636s/100 iter), loss = 3.39432
I0324 01:46:37.874614  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.38494 (* 1 = 3.38494 loss)
I0324 01:46:37.874630  1493 sgd_solver.cpp:136] Iteration 15500, lr = 0.01, m = 0.9
I0324 01:47:45.048866  1493 solver.cpp:314] Iteration 15600 (1.48873 iter/s, 67.1712s/100 iter), loss = 3.52126
I0324 01:47:45.049412  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.32736 (* 1 = 3.32736 loss)
I0324 01:47:45.049787  1493 sgd_solver.cpp:136] Iteration 15600, lr = 0.01, m = 0.9
I0324 01:48:52.035972  1493 solver.cpp:314] Iteration 15700 (1.4929 iter/s, 66.9839s/100 iter), loss = 3.54131
I0324 01:48:52.036159  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.78782 (* 1 = 2.78782 loss)
I0324 01:48:52.036206  1493 sgd_solver.cpp:136] Iteration 15700, lr = 0.01, m = 0.9
I0324 01:49:59.173761  1493 solver.cpp:314] Iteration 15800 (1.48954 iter/s, 67.1347s/100 iter), loss = 3.56904
I0324 01:49:59.173985  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.97626 (* 1 = 2.97626 loss)
I0324 01:49:59.174034  1493 sgd_solver.cpp:136] Iteration 15800, lr = 0.01, m = 0.9
I0324 01:51:07.305764  1493 solver.cpp:314] Iteration 15900 (1.4678 iter/s, 68.129s/100 iter), loss = 3.55732
I0324 01:51:07.308660  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.78103 (* 1 = 3.78103 loss)
I0324 01:51:07.308678  1493 sgd_solver.cpp:136] Iteration 15900, lr = 0.01, m = 0.9
I0324 01:52:14.819656  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_16000.caffemodel
I0324 01:52:14.887532  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_16000.solverstate
I0324 01:52:14.908982  1493 solver.cpp:678] Iteration 16000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.109635
j:  : 4 : max_pr:  : 0.322591
j:  : 3 : max_pr:  : 0.475017
j:  : 2 : max_pr:  : 0.635158
j:  : 1 : max_pr:  : 0.745161
j:  : 0 : max_pr:  : 1
I0324 01:53:04.640537  1494 solver.cpp:786] class AP 1: 0.298869
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.066295
j:  : 7 : max_pr:  : 0.266153
j:  : 6 : max_pr:  : 0.411978
j:  : 5 : max_pr:  : 0.487112
j:  : 4 : max_pr:  : 0.527911
j:  : 3 : max_pr:  : 0.638996
j:  : 2 : max_pr:  : 0.984387
j:  : 1 : max_pr:  : 1
j:  : 0 : max_pr:  : 1
I0324 01:53:04.684640  1494 solver.cpp:786] class AP 2: 0.489348
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.318648
j:  : 6 : max_pr:  : 0.560553
j:  : 5 : max_pr:  : 0.664116
j:  : 4 : max_pr:  : 0.787705
j:  : 3 : max_pr:  : 0.892223
j:  : 2 : max_pr:  : 0.954101
j:  : 1 : max_pr:  : 0.992403
j:  : 0 : max_pr:  : 1
I0324 01:53:04.693123  1494 solver.cpp:786] class AP 3: 0.560886
I0324 01:53:04.693145  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.449701
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.0902004
j:  : 4 : max_pr:  : 0.310423
j:  : 3 : max_pr:  : 0.474536
j:  : 2 : max_pr:  : 0.643012
j:  : 1 : max_pr:  : 0.75021
j:  : 0 : max_pr:  : 1
I0324 01:53:05.740387  1493 solver.cpp:786] class AP 1: 0.297126
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0521254
j:  : 7 : max_pr:  : 0.275483
j:  : 6 : max_pr:  : 0.418198
j:  : 5 : max_pr:  : 0.482932
j:  : 4 : max_pr:  : 0.52297
j:  : 3 : max_pr:  : 0.620476
j:  : 2 : max_pr:  : 0.982184
j:  : 1 : max_pr:  : 0.995579
j:  : 0 : max_pr:  : 1
I0324 01:53:05.785544  1493 solver.cpp:786] class AP 2: 0.486359
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.308168
j:  : 6 : max_pr:  : 0.556764
j:  : 5 : max_pr:  : 0.659951
j:  : 4 : max_pr:  : 0.791485
j:  : 3 : max_pr:  : 0.896522
j:  : 2 : max_pr:  : 0.954592
j:  : 1 : max_pr:  : 0.987386
j:  : 0 : max_pr:  : 1
I0324 01:53:05.793956  1493 solver.cpp:786] class AP 3: 0.559533
I0324 01:53:05.793975  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.447673
I0324 01:53:05.794397  1493 solver.cpp:265] [MultiGPU] Tests completed in 50.8833s
I0324 01:53:06.245031  1493 solver.cpp:314] Iteration 16000 (0.840801 iter/s, 118.934s/100 iter), loss = 3.58185
I0324 01:53:06.245081  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.74418 (* 1 = 2.74418 loss)
I0324 01:53:06.245097  1493 sgd_solver.cpp:136] Iteration 16000, lr = 0.01, m = 0.9
I0324 01:54:12.892140  1493 solver.cpp:314] Iteration 16100 (1.5005 iter/s, 66.6444s/100 iter), loss = 3.63365
I0324 01:54:12.892246  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.56879 (* 1 = 3.56879 loss)
I0324 01:54:12.892263  1493 sgd_solver.cpp:136] Iteration 16100, lr = 0.01, m = 0.9
I0324 01:55:19.026055  1493 solver.cpp:314] Iteration 16200 (1.51214 iter/s, 66.1313s/100 iter), loss = 3.46666
I0324 01:55:19.026180  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.75814 (* 1 = 3.75814 loss)
I0324 01:55:19.026242  1493 sgd_solver.cpp:136] Iteration 16200, lr = 0.01, m = 0.9
I0324 01:56:27.937949  1493 solver.cpp:314] Iteration 16300 (1.45118 iter/s, 68.9093s/100 iter), loss = 3.22139
I0324 01:56:27.938050  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.22216 (* 1 = 3.22216 loss)
I0324 01:56:27.938064  1493 sgd_solver.cpp:136] Iteration 16300, lr = 0.01, m = 0.9
I0324 01:57:35.737799  1493 solver.cpp:314] Iteration 16400 (1.47498 iter/s, 67.7973s/100 iter), loss = 3.14434
I0324 01:57:35.737901  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.78541 (* 1 = 3.78541 loss)
I0324 01:57:35.737920  1493 sgd_solver.cpp:136] Iteration 16400, lr = 0.01, m = 0.9
I0324 01:58:43.141762  1493 solver.cpp:314] Iteration 16500 (1.48365 iter/s, 67.4015s/100 iter), loss = 3.38133
I0324 01:58:43.146232  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.607 (* 1 = 2.607 loss)
I0324 01:58:43.146291  1493 sgd_solver.cpp:136] Iteration 16500, lr = 0.01, m = 0.9
I0324 01:59:51.229951  1493 solver.cpp:314] Iteration 16600 (1.46874 iter/s, 68.0858s/100 iter), loss = 3.25371
I0324 01:59:51.230096  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.62042 (* 1 = 3.62042 loss)
I0324 01:59:51.230113  1493 sgd_solver.cpp:136] Iteration 16600, lr = 0.01, m = 0.9
I0324 02:00:59.460319  1493 solver.cpp:314] Iteration 16700 (1.46567 iter/s, 68.228s/100 iter), loss = 3.45712
I0324 02:00:59.460424  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.31103 (* 1 = 3.31103 loss)
I0324 02:00:59.460441  1493 sgd_solver.cpp:136] Iteration 16700, lr = 0.01, m = 0.9
I0324 02:02:08.015976  1493 solver.cpp:314] Iteration 16800 (1.45872 iter/s, 68.5533s/100 iter), loss = 3.39995
I0324 02:02:08.016101  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.04167 (* 1 = 3.04167 loss)
I0324 02:02:08.016119  1493 sgd_solver.cpp:136] Iteration 16800, lr = 0.01, m = 0.9
I0324 02:03:15.892104  1493 solver.cpp:314] Iteration 16900 (1.47332 iter/s, 67.8738s/100 iter), loss = 3.29085
I0324 02:03:15.892205  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.87195 (* 1 = 3.87195 loss)
I0324 02:03:15.892223  1493 sgd_solver.cpp:136] Iteration 16900, lr = 0.01, m = 0.9
I0324 02:04:25.185519  1493 solver.cpp:314] Iteration 17000 (1.44319 iter/s, 69.2911s/100 iter), loss = 3.58247
I0324 02:04:25.185657  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.97455 (* 1 = 3.97455 loss)
I0324 02:04:25.185688  1493 sgd_solver.cpp:136] Iteration 17000, lr = 0.01, m = 0.9
I0324 02:05:33.378283  1493 solver.cpp:314] Iteration 17100 (1.46648 iter/s, 68.1905s/100 iter), loss = 3.45222
I0324 02:05:33.378381  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.14737 (* 1 = 3.14737 loss)
I0324 02:05:33.378396  1493 sgd_solver.cpp:136] Iteration 17100, lr = 0.01, m = 0.9
I0324 02:06:42.526181  1493 solver.cpp:314] Iteration 17200 (1.44623 iter/s, 69.1453s/100 iter), loss = 3.57033
I0324 02:06:42.526288  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.05204 (* 1 = 3.05204 loss)
I0324 02:06:42.526304  1493 sgd_solver.cpp:136] Iteration 17200, lr = 0.01, m = 0.9
I0324 02:07:50.909178  1493 solver.cpp:314] Iteration 17300 (1.4624 iter/s, 68.3805s/100 iter), loss = 3.55865
I0324 02:07:50.909296  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.06042 (* 1 = 4.06042 loss)
I0324 02:07:50.909313  1493 sgd_solver.cpp:136] Iteration 17300, lr = 0.01, m = 0.9
I0324 02:08:59.750669  1493 solver.cpp:314] Iteration 17400 (1.45266 iter/s, 68.8392s/100 iter), loss = 3.6522
I0324 02:08:59.750783  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.31433 (* 1 = 3.31433 loss)
I0324 02:08:59.750795  1493 sgd_solver.cpp:136] Iteration 17400, lr = 0.01, m = 0.9
I0324 02:10:08.501528  1493 solver.cpp:314] Iteration 17500 (1.45458 iter/s, 68.7486s/100 iter), loss = 3.4229
I0324 02:10:08.501631  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.28968 (* 1 = 3.28968 loss)
I0324 02:10:08.501647  1493 sgd_solver.cpp:136] Iteration 17500, lr = 0.01, m = 0.9
I0324 02:11:16.819927  1493 solver.cpp:314] Iteration 17600 (1.46378 iter/s, 68.3161s/100 iter), loss = 3.37231
I0324 02:11:16.820039  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.0814 (* 1 = 3.0814 loss)
I0324 02:11:16.820055  1493 sgd_solver.cpp:136] Iteration 17600, lr = 0.01, m = 0.9
I0324 02:12:26.428428  1493 solver.cpp:314] Iteration 17700 (1.43665 iter/s, 69.6062s/100 iter), loss = 3.38358
I0324 02:12:26.428604  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.01492 (* 1 = 3.01492 loss)
I0324 02:12:26.428619  1493 sgd_solver.cpp:136] Iteration 17700, lr = 0.01, m = 0.9
I0324 02:13:34.453768  1493 solver.cpp:314] Iteration 17800 (1.47009 iter/s, 68.0231s/100 iter), loss = 3.32271
I0324 02:13:34.454229  1493 solver.cpp:336]     Train net output #0: mbox_loss = 5.23133 (* 1 = 5.23133 loss)
I0324 02:13:34.454533  1493 sgd_solver.cpp:136] Iteration 17800, lr = 0.01, m = 0.9
I0324 02:14:42.799410  1493 solver.cpp:314] Iteration 17900 (1.4632 iter/s, 68.3434s/100 iter), loss = 3.28651
I0324 02:14:42.799546  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.74021 (* 1 = 3.74021 loss)
I0324 02:14:42.799561  1493 sgd_solver.cpp:136] Iteration 17900, lr = 0.01, m = 0.9
I0324 02:15:50.065956  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_18000.caffemodel
I0324 02:15:50.112823  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_18000.solverstate
I0324 02:15:50.137229  1493 solver.cpp:678] Iteration 18000, Testing net (#0)
I0324 02:16:38.597935  1484 data_reader.cpp:305] Starting prefetch of epoch 4
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.0742609
j:  : 4 : max_pr:  : 0.291916
j:  : 3 : max_pr:  : 0.473343
j:  : 2 : max_pr:  : 0.62963
j:  : 1 : max_pr:  : 0.796288
j:  : 0 : max_pr:  : 1
I0324 02:16:39.687934  1493 solver.cpp:786] class AP 1: 0.296858
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.132686
j:  : 6 : max_pr:  : 0.269225
j:  : 5 : max_pr:  : 0.332712
j:  : 4 : max_pr:  : 0.445369
j:  : 3 : max_pr:  : 0.705236
j:  : 2 : max_pr:  : 0.880658
j:  : 1 : max_pr:  : 0.987059
j:  : 0 : max_pr:  : 1
I0324 02:16:39.713994  1493 solver.cpp:786] class AP 2: 0.432086
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.296645
j:  : 6 : max_pr:  : 0.503406
j:  : 5 : max_pr:  : 0.61267
j:  : 4 : max_pr:  : 0.718025
j:  : 3 : max_pr:  : 0.816573
j:  : 2 : max_pr:  : 0.920357
j:  : 1 : max_pr:  : 0.98983
j:  : 0 : max_pr:  : 1
I0324 02:16:39.736860  1493 solver.cpp:786] class AP 3: 0.532501
I0324 02:16:39.736891  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.420482
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0
j:  : 4 : max_pr:  : 0.285636
j:  : 3 : max_pr:  : 0.480458
j:  : 2 : max_pr:  : 0.637889
j:  : 1 : max_pr:  : 0.808237
j:  : 0 : max_pr:  : 1
I0324 02:16:39.902225  1494 solver.cpp:786] class AP 1: 0.29202
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.130745
j:  : 6 : max_pr:  : 0.262525
j:  : 5 : max_pr:  : 0.339611
j:  : 4 : max_pr:  : 0.445318
j:  : 3 : max_pr:  : 0.703997
j:  : 2 : max_pr:  : 0.920848
j:  : 1 : max_pr:  : 0.987897
j:  : 0 : max_pr:  : 1
I0324 02:16:39.927487  1494 solver.cpp:786] class AP 2: 0.43554
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.299536
j:  : 6 : max_pr:  : 0.4972
j:  : 5 : max_pr:  : 0.618646
j:  : 4 : max_pr:  : 0.72249
j:  : 3 : max_pr:  : 0.825969
j:  : 2 : max_pr:  : 0.922503
j:  : 1 : max_pr:  : 0.987646
j:  : 0 : max_pr:  : 1
I0324 02:16:39.949774  1494 solver.cpp:786] class AP 3: 0.533999
I0324 02:16:39.949791  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.42052
I0324 02:16:39.949913  1493 solver.cpp:265] [MultiGPU] Tests completed in 49.8111s
I0324 02:16:40.377734  1493 solver.cpp:314] Iteration 18000 (0.850524 iter/s, 117.575s/100 iter), loss = 3.36994
I0324 02:16:40.377787  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.13416 (* 1 = 3.13416 loss)
I0324 02:16:40.377802  1493 sgd_solver.cpp:136] Iteration 18000, lr = 0.01, m = 0.9
I0324 02:17:48.081506  1493 solver.cpp:314] Iteration 18100 (1.47707 iter/s, 67.7016s/100 iter), loss = 3.56786
I0324 02:17:48.081605  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.25438 (* 1 = 4.25438 loss)
I0324 02:17:48.081622  1493 sgd_solver.cpp:136] Iteration 18100, lr = 0.01, m = 0.9
I0324 02:18:56.080590  1493 solver.cpp:314] Iteration 18200 (1.47066 iter/s, 67.9969s/100 iter), loss = 3.34761
I0324 02:18:56.080708  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.11411 (* 1 = 3.11411 loss)
I0324 02:18:56.080725  1493 sgd_solver.cpp:136] Iteration 18200, lr = 0.01, m = 0.9
I0324 02:20:04.348018  1493 solver.cpp:314] Iteration 18300 (1.46487 iter/s, 68.2653s/100 iter), loss = 3.32588
I0324 02:20:04.348121  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.78083 (* 1 = 2.78083 loss)
I0324 02:20:04.348381  1493 sgd_solver.cpp:136] Iteration 18300, lr = 0.01, m = 0.9
I0324 02:21:12.465056  1493 solver.cpp:314] Iteration 18400 (1.46811 iter/s, 68.1149s/100 iter), loss = 3.51341
I0324 02:21:12.465147  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.91503 (* 1 = 2.91503 loss)
I0324 02:21:12.465160  1493 sgd_solver.cpp:136] Iteration 18400, lr = 0.01, m = 0.9
I0324 02:22:20.847021  1493 solver.cpp:314] Iteration 18500 (1.46242 iter/s, 68.3798s/100 iter), loss = 3.79226
I0324 02:22:20.847137  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.76967 (* 1 = 3.76967 loss)
I0324 02:22:20.847152  1493 sgd_solver.cpp:136] Iteration 18500, lr = 0.01, m = 0.9
I0324 02:23:28.808383  1493 solver.cpp:314] Iteration 18600 (1.47147 iter/s, 67.9592s/100 iter), loss = 3.45277
I0324 02:23:28.808490  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.89668 (* 1 = 2.89668 loss)
I0324 02:23:28.808506  1493 sgd_solver.cpp:136] Iteration 18600, lr = 0.01, m = 0.9
I0324 02:24:36.493877  1493 solver.cpp:314] Iteration 18700 (1.47747 iter/s, 67.6833s/100 iter), loss = 3.31322
I0324 02:24:36.493986  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.67828 (* 1 = 2.67828 loss)
I0324 02:24:36.494004  1493 sgd_solver.cpp:136] Iteration 18700, lr = 0.01, m = 0.9
I0324 02:25:45.061903  1493 solver.cpp:314] Iteration 18800 (1.45845 iter/s, 68.5659s/100 iter), loss = 3.20218
I0324 02:25:45.062011  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.29221 (* 1 = 3.29221 loss)
I0324 02:25:45.062028  1493 sgd_solver.cpp:136] Iteration 18800, lr = 0.01, m = 0.9
I0324 02:26:52.443099  1493 solver.cpp:314] Iteration 18900 (1.48414 iter/s, 67.3791s/100 iter), loss = 3.5696
I0324 02:26:52.446130  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.48884 (* 1 = 3.48884 loss)
I0324 02:26:52.446187  1493 sgd_solver.cpp:136] Iteration 18900, lr = 0.01, m = 0.9
I0324 02:28:00.241564  1493 solver.cpp:314] Iteration 19000 (1.47501 iter/s, 67.7963s/100 iter), loss = 3.30365
I0324 02:28:00.241674  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.04448 (* 1 = 4.04448 loss)
I0324 02:28:00.242308  1493 sgd_solver.cpp:136] Iteration 19000, lr = 0.01, m = 0.9
I0324 02:29:08.852954  1493 solver.cpp:314] Iteration 19100 (1.45753 iter/s, 68.6092s/100 iter), loss = 3.30343
I0324 02:29:08.853056  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.70191 (* 1 = 2.70191 loss)
I0324 02:29:08.853068  1493 sgd_solver.cpp:136] Iteration 19100, lr = 0.01, m = 0.9
I0324 02:30:16.756850  1493 solver.cpp:314] Iteration 19200 (1.47272 iter/s, 67.9018s/100 iter), loss = 3.28787
I0324 02:30:16.756942  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.59542 (* 1 = 4.59542 loss)
I0324 02:30:16.756990  1493 sgd_solver.cpp:136] Iteration 19200, lr = 0.01, m = 0.9
I0324 02:31:26.090167  1493 solver.cpp:314] Iteration 19300 (1.44235 iter/s, 69.3311s/100 iter), loss = 3.25885
I0324 02:31:26.090260  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.92242 (* 1 = 3.92242 loss)
I0324 02:31:26.090276  1493 sgd_solver.cpp:136] Iteration 19300, lr = 0.01, m = 0.9
I0324 02:32:34.603922  1493 solver.cpp:314] Iteration 19400 (1.45961 iter/s, 68.5116s/100 iter), loss = 3.32482
I0324 02:32:34.604045  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.46624 (* 1 = 3.46624 loss)
I0324 02:32:34.604063  1493 sgd_solver.cpp:136] Iteration 19400, lr = 0.01, m = 0.9
I0324 02:33:42.745759  1493 solver.cpp:314] Iteration 19500 (1.46757 iter/s, 68.1397s/100 iter), loss = 3.57517
I0324 02:33:42.745954  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.06664 (* 1 = 3.06664 loss)
I0324 02:33:42.746001  1493 sgd_solver.cpp:136] Iteration 19500, lr = 0.01, m = 0.9
I0324 02:34:50.006767  1493 solver.cpp:314] Iteration 19600 (1.48679 iter/s, 67.2588s/100 iter), loss = 3.39327
I0324 02:34:50.007279  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.89135 (* 1 = 3.89135 loss)
I0324 02:34:50.007601  1493 sgd_solver.cpp:136] Iteration 19600, lr = 0.01, m = 0.9
I0324 02:35:58.465950  1493 solver.cpp:314] Iteration 19700 (1.46077 iter/s, 68.457s/100 iter), loss = 3.50741
I0324 02:35:58.467294  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.78333 (* 1 = 3.78333 loss)
I0324 02:35:58.467389  1493 sgd_solver.cpp:136] Iteration 19700, lr = 0.01, m = 0.9
I0324 02:37:06.169937  1493 solver.cpp:314] Iteration 19800 (1.47707 iter/s, 67.7018s/100 iter), loss = 3.52263
I0324 02:37:06.170034  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.33142 (* 1 = 4.33142 loss)
I0324 02:37:06.170050  1493 sgd_solver.cpp:136] Iteration 19800, lr = 0.01, m = 0.9
I0324 02:38:14.249579  1493 solver.cpp:314] Iteration 19900 (1.46891 iter/s, 68.0775s/100 iter), loss = 3.21958
I0324 02:38:14.249680  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.26034 (* 1 = 3.26034 loss)
I0324 02:38:14.249706  1493 sgd_solver.cpp:136] Iteration 19900, lr = 0.01, m = 0.9
I0324 02:39:21.894328  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_20000.caffemodel
I0324 02:39:21.929373  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_20000.solverstate
I0324 02:39:21.941836  1493 solver.cpp:678] Iteration 20000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.176665
j:  : 4 : max_pr:  : 0.333088
j:  : 3 : max_pr:  : 0.543798
j:  : 2 : max_pr:  : 0.731181
j:  : 1 : max_pr:  : 0.840371
j:  : 0 : max_pr:  : 1
I0324 02:40:13.711907  1494 solver.cpp:786] class AP 1: 0.329555
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0494382
j:  : 7 : max_pr:  : 0.152309
j:  : 6 : max_pr:  : 0.249033
j:  : 5 : max_pr:  : 0.532077
j:  : 4 : max_pr:  : 0.724051
j:  : 3 : max_pr:  : 0.817874
j:  : 2 : max_pr:  : 0.981763
j:  : 1 : max_pr:  : 0.995522
j:  : 0 : max_pr:  : 1
I0324 02:40:13.751165  1494 solver.cpp:786] class AP 2: 0.500188
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.305371
j:  : 6 : max_pr:  : 0.553946
j:  : 5 : max_pr:  : 0.66792
j:  : 4 : max_pr:  : 0.807184
j:  : 3 : max_pr:  : 0.910832
j:  : 2 : max_pr:  : 0.95769
j:  : 1 : max_pr:  : 0.985161
j:  : 0 : max_pr:  : 1
I0324 02:40:13.772433  1494 solver.cpp:786] class AP 3: 0.562555
I0324 02:40:13.772462  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.464099
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.181645
j:  : 4 : max_pr:  : 0.33078
j:  : 3 : max_pr:  : 0.53421
j:  : 2 : max_pr:  : 0.720898
j:  : 1 : max_pr:  : 0.836406
j:  : 0 : max_pr:  : 1
I0324 02:40:13.854182  1493 solver.cpp:786] class AP 1: 0.327631
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0547233
j:  : 7 : max_pr:  : 0.147537
j:  : 6 : max_pr:  : 0.252727
j:  : 5 : max_pr:  : 0.559136
j:  : 4 : max_pr:  : 0.726767
j:  : 3 : max_pr:  : 0.81803
j:  : 2 : max_pr:  : 0.990166
j:  : 1 : max_pr:  : 1
j:  : 0 : max_pr:  : 1
I0324 02:40:13.893112  1493 solver.cpp:786] class AP 2: 0.504462
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.292602
j:  : 6 : max_pr:  : 0.548017
j:  : 5 : max_pr:  : 0.659067
j:  : 4 : max_pr:  : 0.797624
j:  : 3 : max_pr:  : 0.917853
j:  : 2 : max_pr:  : 0.960878
j:  : 1 : max_pr:  : 0.991864
j:  : 0 : max_pr:  : 1
I0324 02:40:13.913898  1493 solver.cpp:786] class AP 3: 0.560719
I0324 02:40:13.913936  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.464271
I0324 02:40:13.914335  1493 solver.cpp:265] [MultiGPU] Tests completed in 51.9708s
I0324 02:40:14.381657  1493 solver.cpp:314] Iteration 20000 (0.832444 iter/s, 120.128s/100 iter), loss = 3.72166
I0324 02:40:14.381719  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.8209 (* 1 = 2.8209 loss)
I0324 02:40:14.381737  1493 sgd_solver.cpp:136] Iteration 20000, lr = 0.01, m = 0.9
I0324 02:41:21.255056  1493 solver.cpp:314] Iteration 20100 (1.49541 iter/s, 66.8712s/100 iter), loss = 3.25393
I0324 02:41:21.255216  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.09607 (* 1 = 2.09607 loss)
I0324 02:41:21.255234  1493 sgd_solver.cpp:136] Iteration 20100, lr = 0.01, m = 0.9
I0324 02:42:29.588402  1493 solver.cpp:314] Iteration 20200 (1.46346 iter/s, 68.3311s/100 iter), loss = 3.25936
I0324 02:42:29.588515  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.35636 (* 1 = 3.35636 loss)
I0324 02:42:29.588531  1493 sgd_solver.cpp:136] Iteration 20200, lr = 0.01, m = 0.9
I0324 02:43:38.415886  1493 solver.cpp:314] Iteration 20300 (1.45296 iter/s, 68.8252s/100 iter), loss = 3.51516
I0324 02:43:38.416072  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.20549 (* 1 = 3.20549 loss)
I0324 02:43:38.416088  1493 sgd_solver.cpp:136] Iteration 20300, lr = 0.01, m = 0.9
I0324 02:44:46.994220  1493 solver.cpp:314] Iteration 20400 (1.45823 iter/s, 68.5761s/100 iter), loss = 3.34034
I0324 02:44:46.994323  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.88782 (* 1 = 2.88782 loss)
I0324 02:44:46.994336  1493 sgd_solver.cpp:136] Iteration 20400, lr = 0.01, m = 0.9
I0324 02:45:54.299638  1493 solver.cpp:314] Iteration 20500 (1.48581 iter/s, 67.3032s/100 iter), loss = 3.3049
I0324 02:45:54.299759  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.95579 (* 1 = 3.95579 loss)
I0324 02:45:54.299774  1493 sgd_solver.cpp:136] Iteration 20500, lr = 0.01, m = 0.9
I0324 02:47:02.026600  1493 solver.cpp:314] Iteration 20600 (1.47657 iter/s, 67.7247s/100 iter), loss = 3.32191
I0324 02:47:02.026744  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.37043 (* 1 = 3.37043 loss)
I0324 02:47:02.026763  1493 sgd_solver.cpp:136] Iteration 20600, lr = 0.01, m = 0.9
I0324 02:48:11.015346  1493 solver.cpp:314] Iteration 20700 (1.44956 iter/s, 68.9865s/100 iter), loss = 3.4972
I0324 02:48:11.015523  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.31054 (* 1 = 3.31054 loss)
I0324 02:48:11.015563  1493 sgd_solver.cpp:136] Iteration 20700, lr = 0.01, m = 0.9
I0324 02:49:18.649745  1493 solver.cpp:314] Iteration 20800 (1.47859 iter/s, 67.6322s/100 iter), loss = 3.14476
I0324 02:49:18.650768  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.53959 (* 1 = 2.53959 loss)
I0324 02:49:18.650786  1493 sgd_solver.cpp:136] Iteration 20800, lr = 0.01, m = 0.9
I0324 02:49:49.429471  1462 data_reader.cpp:305] Starting prefetch of epoch 4
I0324 02:50:26.268965  1493 solver.cpp:314] Iteration 20900 (1.47892 iter/s, 67.617s/100 iter), loss = 3.32912
I0324 02:50:26.269146  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.76675 (* 1 = 3.76675 loss)
I0324 02:50:26.269194  1493 sgd_solver.cpp:136] Iteration 20900, lr = 0.01, m = 0.9
I0324 02:51:33.714769  1493 solver.cpp:314] Iteration 21000 (1.48272 iter/s, 67.4436s/100 iter), loss = 3.36654
I0324 02:51:33.714879  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.68781 (* 1 = 2.68781 loss)
I0324 02:51:33.714895  1493 sgd_solver.cpp:136] Iteration 21000, lr = 0.01, m = 0.9
I0324 02:52:41.929245  1493 solver.cpp:314] Iteration 21100 (1.46601 iter/s, 68.2123s/100 iter), loss = 3.52332
I0324 02:52:41.929400  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.19348 (* 1 = 3.19348 loss)
I0324 02:52:41.929417  1493 sgd_solver.cpp:136] Iteration 21100, lr = 0.01, m = 0.9
I0324 02:53:49.580140  1493 solver.cpp:314] Iteration 21200 (1.47823 iter/s, 67.6487s/100 iter), loss = 3.43547
I0324 02:53:49.580241  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.2509 (* 1 = 3.2509 loss)
I0324 02:53:49.580257  1493 sgd_solver.cpp:136] Iteration 21200, lr = 0.01, m = 0.9
I0324 02:54:58.335450  1493 solver.cpp:314] Iteration 21300 (1.45448 iter/s, 68.7531s/100 iter), loss = 3.52543
I0324 02:54:58.335551  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.97907 (* 1 = 2.97907 loss)
I0324 02:54:58.335567  1493 sgd_solver.cpp:136] Iteration 21300, lr = 0.01, m = 0.9
I0324 02:56:06.445991  1493 solver.cpp:314] Iteration 21400 (1.46825 iter/s, 68.1084s/100 iter), loss = 3.18732
I0324 02:56:06.446099  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.93023 (* 1 = 2.93023 loss)
I0324 02:56:06.446118  1493 sgd_solver.cpp:136] Iteration 21400, lr = 0.01, m = 0.9
I0324 02:57:14.519945  1493 solver.cpp:314] Iteration 21500 (1.46904 iter/s, 68.0718s/100 iter), loss = 3.2296
I0324 02:57:14.520040  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.17727 (* 1 = 2.17727 loss)
I0324 02:57:14.520056  1493 sgd_solver.cpp:136] Iteration 21500, lr = 0.01, m = 0.9
I0324 02:58:22.479888  1493 solver.cpp:314] Iteration 21600 (1.4715 iter/s, 67.9577s/100 iter), loss = 3.32777
I0324 02:58:22.480026  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.58279 (* 1 = 3.58279 loss)
I0324 02:58:22.480048  1493 sgd_solver.cpp:136] Iteration 21600, lr = 0.01, m = 0.9
I0324 02:59:28.993958  1493 solver.cpp:314] Iteration 21700 (1.50349 iter/s, 66.5119s/100 iter), loss = 3.39898
I0324 02:59:28.994060  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.73504 (* 1 = 2.73504 loss)
I0324 02:59:28.994076  1493 sgd_solver.cpp:136] Iteration 21700, lr = 0.01, m = 0.9
I0324 03:00:37.518712  1493 solver.cpp:314] Iteration 21800 (1.45937 iter/s, 68.5225s/100 iter), loss = 3.2361
I0324 03:00:37.518821  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.43218 (* 1 = 2.43218 loss)
I0324 03:00:37.518841  1493 sgd_solver.cpp:136] Iteration 21800, lr = 0.01, m = 0.9
I0324 03:01:45.914625  1493 solver.cpp:314] Iteration 21900 (1.46212 iter/s, 68.3937s/100 iter), loss = 3.35305
I0324 03:01:45.915123  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.04785 (* 1 = 3.04785 loss)
I0324 03:01:45.915446  1493 sgd_solver.cpp:136] Iteration 21900, lr = 0.01, m = 0.9
I0324 03:02:53.726816  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_22000.caffemodel
I0324 03:02:53.772471  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_22000.solverstate
I0324 03:02:53.807066  1493 solver.cpp:678] Iteration 22000, Testing net (#0)
I0324 03:02:57.749728  1494 blocking_queue.cpp:40] Data layer prefetch queue empty
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.214566
j:  : 4 : max_pr:  : 0.352058
j:  : 3 : max_pr:  : 0.492398
j:  : 2 : max_pr:  : 0.661838
j:  : 1 : max_pr:  : 0.817642
j:  : 0 : max_pr:  : 1
I0324 03:03:43.102856  1494 solver.cpp:786] class AP 1: 0.321682
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.223828
j:  : 6 : max_pr:  : 0.358517
j:  : 5 : max_pr:  : 0.451576
j:  : 4 : max_pr:  : 0.560089
j:  : 3 : max_pr:  : 0.64851
j:  : 2 : max_pr:  : 0.835535
j:  : 1 : max_pr:  : 0.998843
j:  : 0 : max_pr:  : 1
I0324 03:03:43.156816  1494 solver.cpp:786] class AP 2: 0.461536
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.319547
j:  : 6 : max_pr:  : 0.590697
j:  : 5 : max_pr:  : 0.700851
j:  : 4 : max_pr:  : 0.812886
j:  : 3 : max_pr:  : 0.879959
j:  : 2 : max_pr:  : 0.943816
j:  : 1 : max_pr:  : 0.995315
j:  : 0 : max_pr:  : 1
I0324 03:03:43.167377  1494 solver.cpp:786] class AP 3: 0.567552
I0324 03:03:43.167400  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.450257
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.231233
j:  : 4 : max_pr:  : 0.365882
j:  : 3 : max_pr:  : 0.515491
j:  : 2 : max_pr:  : 0.675968
j:  : 1 : max_pr:  : 0.833107
j:  : 0 : max_pr:  : 1
I0324 03:03:43.865933  1493 solver.cpp:786] class AP 1: 0.329244
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0293718
j:  : 7 : max_pr:  : 0.267344
j:  : 6 : max_pr:  : 0.39353
j:  : 5 : max_pr:  : 0.481192
j:  : 4 : max_pr:  : 0.590375
j:  : 3 : max_pr:  : 0.670007
j:  : 2 : max_pr:  : 0.899256
j:  : 1 : max_pr:  : 0.9989
j:  : 0 : max_pr:  : 1
I0324 03:03:43.918349  1493 solver.cpp:786] class AP 2: 0.484543
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.305277
j:  : 6 : max_pr:  : 0.567942
j:  : 5 : max_pr:  : 0.688976
j:  : 4 : max_pr:  : 0.805053
j:  : 3 : max_pr:  : 0.873111
j:  : 2 : max_pr:  : 0.944855
j:  : 1 : max_pr:  : 0.995254
j:  : 0 : max_pr:  : 1
I0324 03:03:43.928908  1493 solver.cpp:786] class AP 3: 0.561861
I0324 03:03:43.928923  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.458549
I0324 03:03:43.929320  1493 solver.cpp:265] [MultiGPU] Tests completed in 50.1206s
I0324 03:03:44.335175  1493 solver.cpp:314] Iteration 22000 (0.844475 iter/s, 118.417s/100 iter), loss = 3.27956
I0324 03:03:44.335224  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.73915 (* 1 = 2.73915 loss)
I0324 03:03:44.335238  1493 sgd_solver.cpp:136] Iteration 22000, lr = 0.01, m = 0.9
I0324 03:04:52.153982  1493 solver.cpp:314] Iteration 22100 (1.47457 iter/s, 67.8166s/100 iter), loss = 3.20011
I0324 03:04:52.154176  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.7268 (* 1 = 3.7268 loss)
I0324 03:04:52.154217  1493 sgd_solver.cpp:136] Iteration 22100, lr = 0.01, m = 0.9
I0324 03:06:00.027003  1493 solver.cpp:314] Iteration 22200 (1.47339 iter/s, 67.8708s/100 iter), loss = 3.23635
I0324 03:06:00.027107  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.01643 (* 1 = 4.01643 loss)
I0324 03:06:00.027124  1493 sgd_solver.cpp:136] Iteration 22200, lr = 0.01, m = 0.9
I0324 03:07:08.302386  1493 solver.cpp:314] Iteration 22300 (1.4647 iter/s, 68.2732s/100 iter), loss = 3.3497
I0324 03:07:08.302484  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.10656 (* 1 = 3.10656 loss)
I0324 03:07:08.302500  1493 sgd_solver.cpp:136] Iteration 22300, lr = 0.01, m = 0.9
I0324 03:08:17.222054  1493 solver.cpp:314] Iteration 22400 (1.45101 iter/s, 68.9174s/100 iter), loss = 3.33389
I0324 03:08:17.222255  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.41235 (* 1 = 2.41235 loss)
I0324 03:08:17.222272  1493 sgd_solver.cpp:136] Iteration 22400, lr = 0.01, m = 0.9
I0324 03:09:25.037597  1493 solver.cpp:314] Iteration 22500 (1.47464 iter/s, 67.8134s/100 iter), loss = 3.27002
I0324 03:09:25.037719  1493 solver.cpp:336]     Train net output #0: mbox_loss = 5.07316 (* 1 = 5.07316 loss)
I0324 03:09:25.037734  1493 sgd_solver.cpp:136] Iteration 22500, lr = 0.01, m = 0.9
I0324 03:10:34.162050  1493 solver.cpp:314] Iteration 22600 (1.44671 iter/s, 69.1222s/100 iter), loss = 3.42982
I0324 03:10:34.162158  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.68374 (* 1 = 3.68374 loss)
I0324 03:10:34.162174  1493 sgd_solver.cpp:136] Iteration 22600, lr = 0.01, m = 0.9
I0324 03:11:42.729990  1493 solver.cpp:314] Iteration 22700 (1.45845 iter/s, 68.5657s/100 iter), loss = 3.22971
I0324 03:11:42.730099  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.51295 (* 1 = 3.51295 loss)
I0324 03:11:42.730114  1493 sgd_solver.cpp:136] Iteration 22700, lr = 0.01, m = 0.9
I0324 03:12:50.525934  1493 solver.cpp:314] Iteration 22800 (1.47506 iter/s, 67.7938s/100 iter), loss = 3.29671
I0324 03:12:50.545877  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.1362 (* 1 = 3.1362 loss)
I0324 03:12:50.545910  1493 sgd_solver.cpp:136] Iteration 22800, lr = 0.01, m = 0.9
I0324 03:13:58.034446  1493 solver.cpp:314] Iteration 22900 (1.48134 iter/s, 67.5063s/100 iter), loss = 3.34538
I0324 03:13:58.034551  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.82425 (* 1 = 2.82425 loss)
I0324 03:13:58.034569  1493 sgd_solver.cpp:136] Iteration 22900, lr = 0.01, m = 0.9
I0324 03:15:07.076831  1493 solver.cpp:314] Iteration 23000 (1.44843 iter/s, 69.0402s/100 iter), loss = 3.27965
I0324 03:15:07.076936  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.75501 (* 1 = 2.75501 loss)
I0324 03:15:07.076954  1493 sgd_solver.cpp:136] Iteration 23000, lr = 0.01, m = 0.9
I0324 03:16:15.591579  1493 solver.cpp:314] Iteration 23100 (1.45959 iter/s, 68.5126s/100 iter), loss = 3.34976
I0324 03:16:15.591676  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.5104 (* 1 = 4.5104 loss)
I0324 03:16:15.591693  1493 sgd_solver.cpp:136] Iteration 23100, lr = 0.01, m = 0.9
I0324 03:17:23.735728  1493 solver.cpp:314] Iteration 23200 (1.46752 iter/s, 68.142s/100 iter), loss = 3.11091
I0324 03:17:23.735898  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.61029 (* 1 = 3.61029 loss)
I0324 03:17:23.735951  1493 sgd_solver.cpp:136] Iteration 23200, lr = 0.01, m = 0.9
I0324 03:18:30.940017  1493 solver.cpp:314] Iteration 23300 (1.48805 iter/s, 67.2021s/100 iter), loss = 3.3608
I0324 03:18:30.944656  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.55852 (* 1 = 3.55852 loss)
I0324 03:18:30.944687  1493 sgd_solver.cpp:136] Iteration 23300, lr = 0.01, m = 0.9
I0324 03:19:39.009754  1493 solver.cpp:314] Iteration 23400 (1.46913 iter/s, 68.0676s/100 iter), loss = 3.67897
I0324 03:19:39.013766  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.66934 (* 1 = 3.66934 loss)
I0324 03:19:39.013795  1493 sgd_solver.cpp:136] Iteration 23400, lr = 0.01, m = 0.9
I0324 03:20:48.370496  1493 solver.cpp:314] Iteration 23500 (1.44178 iter/s, 69.3585s/100 iter), loss = 3.29584
I0324 03:20:48.370609  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.30967 (* 1 = 3.30967 loss)
I0324 03:20:48.370626  1493 sgd_solver.cpp:136] Iteration 23500, lr = 0.01, m = 0.9
I0324 03:21:57.380429  1493 solver.cpp:314] Iteration 23600 (1.44911 iter/s, 69.0077s/100 iter), loss = 3.29315
I0324 03:21:57.385754  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.46097 (* 1 = 2.46097 loss)
I0324 03:21:57.385781  1493 sgd_solver.cpp:136] Iteration 23600, lr = 0.01, m = 0.9
I0324 03:23:05.439491  1493 solver.cpp:314] Iteration 23700 (1.46936 iter/s, 68.0569s/100 iter), loss = 3.19056
I0324 03:23:05.439579  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.0267 (* 1 = 3.0267 loss)
I0324 03:23:05.439595  1493 sgd_solver.cpp:136] Iteration 23700, lr = 0.01, m = 0.9
I0324 03:24:13.667991  1493 solver.cpp:314] Iteration 23800 (1.46571 iter/s, 68.2263s/100 iter), loss = 3.48804
I0324 03:24:13.668095  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.52121 (* 1 = 3.52121 loss)
I0324 03:24:13.668110  1493 sgd_solver.cpp:136] Iteration 23800, lr = 0.01, m = 0.9
I0324 03:25:22.160535  1493 solver.cpp:314] Iteration 23900 (1.46006 iter/s, 68.4904s/100 iter), loss = 3.31552
I0324 03:25:22.160645  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.47637 (* 1 = 3.47637 loss)
I0324 03:25:22.160660  1493 sgd_solver.cpp:136] Iteration 23900, lr = 0.01, m = 0.9
I0324 03:26:13.679545  1462 data_reader.cpp:305] Starting prefetch of epoch 5
I0324 03:26:30.398116  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_24000.caffemodel
I0324 03:26:30.438395  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_24000.solverstate
I0324 03:26:30.455543  1493 solver.cpp:678] Iteration 24000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.197889
j:  : 4 : max_pr:  : 0.377845
j:  : 3 : max_pr:  : 0.557948
j:  : 2 : max_pr:  : 0.688452
j:  : 1 : max_pr:  : 0.822365
j:  : 0 : max_pr:  : 1
I0324 03:27:20.163981  1494 solver.cpp:786] class AP 1: 0.331318
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.193523
j:  : 6 : max_pr:  : 0.495456
j:  : 5 : max_pr:  : 0.625
j:  : 4 : max_pr:  : 0.671591
j:  : 3 : max_pr:  : 0.704839
j:  : 2 : max_pr:  : 0.912482
j:  : 1 : max_pr:  : 0.996918
j:  : 0 : max_pr:  : 1
I0324 03:27:20.201545  1494 solver.cpp:786] class AP 2: 0.509074
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.374188
j:  : 6 : max_pr:  : 0.62892
j:  : 5 : max_pr:  : 0.736214
j:  : 4 : max_pr:  : 0.838196
j:  : 3 : max_pr:  : 0.907276
j:  : 2 : max_pr:  : 0.966404
j:  : 1 : max_pr:  : 0.995254
j:  : 0 : max_pr:  : 1
I0324 03:27:20.207870  1494 solver.cpp:786] class AP 3: 0.586041
I0324 03:27:20.207883  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.475478
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.21404
j:  : 4 : max_pr:  : 0.389651
j:  : 3 : max_pr:  : 0.568032
j:  : 2 : max_pr:  : 0.685869
j:  : 1 : max_pr:  : 0.802964
j:  : 0 : max_pr:  : 1
I0324 03:27:20.601045  1493 solver.cpp:786] class AP 1: 0.332778
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.193665
j:  : 6 : max_pr:  : 0.494566
j:  : 5 : max_pr:  : 0.631358
j:  : 4 : max_pr:  : 0.684552
j:  : 3 : max_pr:  : 0.722141
j:  : 2 : max_pr:  : 0.949677
j:  : 1 : max_pr:  : 0.995169
j:  : 0 : max_pr:  : 1
I0324 03:27:20.637691  1493 solver.cpp:786] class AP 2: 0.515557
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.403538
j:  : 6 : max_pr:  : 0.637482
j:  : 5 : max_pr:  : 0.748087
j:  : 4 : max_pr:  : 0.846131
j:  : 3 : max_pr:  : 0.9079
j:  : 2 : max_pr:  : 0.966165
j:  : 1 : max_pr:  : 0.996533
j:  : 0 : max_pr:  : 1
I0324 03:27:20.643834  1493 solver.cpp:786] class AP 3: 0.59144
I0324 03:27:20.643846  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.479925
I0324 03:27:20.644266  1493 solver.cpp:265] [MultiGPU] Tests completed in 50.1871s
I0324 03:27:21.029166  1493 solver.cpp:314] Iteration 24000 (0.841292 iter/s, 118.865s/100 iter), loss = 3.35702
I0324 03:27:21.029211  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.30069 (* 1 = 3.30069 loss)
I0324 03:27:21.029223  1493 sgd_solver.cpp:136] Iteration 24000, lr = 0.01, m = 0.9
I0324 03:28:28.333950  1493 solver.cpp:314] Iteration 24100 (1.48583 iter/s, 67.3026s/100 iter), loss = 3.25341
I0324 03:28:28.334065  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.97696 (* 1 = 3.97696 loss)
I0324 03:28:28.334082  1493 sgd_solver.cpp:136] Iteration 24100, lr = 0.01, m = 0.9
I0324 03:29:38.457409  1493 solver.cpp:314] Iteration 24200 (1.4261 iter/s, 70.1212s/100 iter), loss = 3.40958
I0324 03:29:38.457514  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.08884 (* 1 = 3.08884 loss)
I0324 03:29:38.457530  1493 sgd_solver.cpp:136] Iteration 24200, lr = 0.01, m = 0.9
I0324 03:30:46.117868  1493 solver.cpp:314] Iteration 24300 (1.47802 iter/s, 67.6582s/100 iter), loss = 3.44554
I0324 03:30:46.118000  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.56992 (* 1 = 3.56992 loss)
I0324 03:30:46.118017  1493 sgd_solver.cpp:136] Iteration 24300, lr = 0.01, m = 0.9
I0324 03:31:55.008327  1493 solver.cpp:314] Iteration 24400 (1.45163 iter/s, 68.8882s/100 iter), loss = 3.34375
I0324 03:31:55.008442  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.8685 (* 1 = 3.8685 loss)
I0324 03:31:55.008458  1493 sgd_solver.cpp:136] Iteration 24400, lr = 0.01, m = 0.9
I0324 03:33:02.927687  1493 solver.cpp:314] Iteration 24500 (1.47238 iter/s, 67.9171s/100 iter), loss = 3.11755
I0324 03:33:02.927798  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.65164 (* 1 = 2.65164 loss)
I0324 03:33:02.927814  1493 sgd_solver.cpp:136] Iteration 24500, lr = 0.01, m = 0.9
I0324 03:34:10.598026  1493 solver.cpp:314] Iteration 24600 (1.4778 iter/s, 67.6681s/100 iter), loss = 3.14617
I0324 03:34:10.598124  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.05121 (* 1 = 3.05121 loss)
I0324 03:34:10.598140  1493 sgd_solver.cpp:136] Iteration 24600, lr = 0.01, m = 0.9
I0324 03:35:19.284149  1493 solver.cpp:314] Iteration 24700 (1.45595 iter/s, 68.6839s/100 iter), loss = 3.33678
I0324 03:35:19.284247  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.4067 (* 1 = 3.4067 loss)
I0324 03:35:19.284262  1493 sgd_solver.cpp:136] Iteration 24700, lr = 0.01, m = 0.9
I0324 03:36:27.823156  1493 solver.cpp:314] Iteration 24800 (1.45907 iter/s, 68.5368s/100 iter), loss = 3.55168
I0324 03:36:27.823352  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.50938 (* 1 = 2.50938 loss)
I0324 03:36:27.823369  1493 sgd_solver.cpp:136] Iteration 24800, lr = 0.01, m = 0.9
I0324 03:37:37.314131  1493 solver.cpp:314] Iteration 24900 (1.43908 iter/s, 69.4887s/100 iter), loss = 3.16249
I0324 03:37:37.314234  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.19893 (* 1 = 3.19893 loss)
I0324 03:37:37.314252  1493 sgd_solver.cpp:136] Iteration 24900, lr = 0.01, m = 0.9
I0324 03:38:45.422544  1493 solver.cpp:314] Iteration 25000 (1.4683 iter/s, 68.1062s/100 iter), loss = 3.22951
I0324 03:38:45.425740  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.3228 (* 1 = 2.3228 loss)
I0324 03:38:45.425762  1493 sgd_solver.cpp:136] Iteration 25000, lr = 0.01, m = 0.9
I0324 03:39:54.706387  1493 solver.cpp:314] Iteration 25100 (1.44339 iter/s, 69.2816s/100 iter), loss = 3.0647
I0324 03:39:54.706492  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.36209 (* 1 = 3.36209 loss)
I0324 03:39:54.706511  1493 sgd_solver.cpp:136] Iteration 25100, lr = 0.01, m = 0.9
I0324 03:41:02.139382  1493 solver.cpp:314] Iteration 25200 (1.483 iter/s, 67.4308s/100 iter), loss = 3.40195
I0324 03:41:02.139493  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.60671 (* 1 = 3.60671 loss)
I0324 03:41:02.139510  1493 sgd_solver.cpp:136] Iteration 25200, lr = 0.01, m = 0.9
I0324 03:42:10.086516  1493 solver.cpp:314] Iteration 25300 (1.47178 iter/s, 67.9449s/100 iter), loss = 3.16989
I0324 03:42:10.086686  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.02361 (* 1 = 3.02361 loss)
I0324 03:42:10.086736  1493 sgd_solver.cpp:136] Iteration 25300, lr = 0.01, m = 0.9
I0324 03:43:18.122854  1493 solver.cpp:314] Iteration 25400 (1.46985 iter/s, 68.0341s/100 iter), loss = 3.29807
I0324 03:43:18.125746  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.25639 (* 1 = 3.25639 loss)
I0324 03:43:18.125771  1493 sgd_solver.cpp:136] Iteration 25400, lr = 0.01, m = 0.9
I0324 03:44:27.157753  1493 solver.cpp:314] Iteration 25500 (1.44859 iter/s, 69.0327s/100 iter), loss = 3.58363
I0324 03:44:27.157860  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.31903 (* 1 = 4.31903 loss)
I0324 03:44:27.157878  1493 sgd_solver.cpp:136] Iteration 25500, lr = 0.01, m = 0.9
I0324 03:45:35.705179  1493 solver.cpp:314] Iteration 25600 (1.45889 iter/s, 68.5452s/100 iter), loss = 3.26778
I0324 03:45:35.705329  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.43835 (* 1 = 3.43835 loss)
I0324 03:45:35.705344  1493 sgd_solver.cpp:136] Iteration 25600, lr = 0.01, m = 0.9
I0324 03:46:44.479405  1493 solver.cpp:314] Iteration 25700 (1.45408 iter/s, 68.772s/100 iter), loss = 3.23389
I0324 03:46:44.479550  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.20696 (* 1 = 3.20696 loss)
I0324 03:46:44.479570  1493 sgd_solver.cpp:136] Iteration 25700, lr = 0.01, m = 0.9
I0324 03:47:52.256301  1493 solver.cpp:314] Iteration 25800 (1.47548 iter/s, 67.7747s/100 iter), loss = 3.40371
I0324 03:47:52.256485  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.64878 (* 1 = 2.64878 loss)
I0324 03:47:52.256526  1493 sgd_solver.cpp:136] Iteration 25800, lr = 0.01, m = 0.9
I0324 03:49:01.000243  1493 solver.cpp:314] Iteration 25900 (1.45472 iter/s, 68.7417s/100 iter), loss = 3.10372
I0324 03:49:01.000417  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.03274 (* 1 = 3.03274 loss)
I0324 03:49:01.000463  1493 sgd_solver.cpp:136] Iteration 25900, lr = 0.01, m = 0.9
I0324 03:50:08.561566  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_26000.caffemodel
I0324 03:50:08.594918  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_26000.solverstate
I0324 03:50:08.610136  1493 solver.cpp:678] Iteration 26000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.195129
j:  : 4 : max_pr:  : 0.344646
j:  : 3 : max_pr:  : 0.546061
j:  : 2 : max_pr:  : 0.714088
j:  : 1 : max_pr:  : 0.789842
j:  : 0 : max_pr:  : 1
I0324 03:51:00.880100  1494 solver.cpp:786] class AP 1: 0.326342
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.028003
j:  : 7 : max_pr:  : 0.183
j:  : 6 : max_pr:  : 0.344615
j:  : 5 : max_pr:  : 0.398015
j:  : 4 : max_pr:  : 0.465361
j:  : 3 : max_pr:  : 0.640319
j:  : 2 : max_pr:  : 0.755408
j:  : 1 : max_pr:  : 0.977169
j:  : 0 : max_pr:  : 1
I0324 03:51:00.936053  1494 solver.cpp:786] class AP 2: 0.435626
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.416581
j:  : 6 : max_pr:  : 0.601078
j:  : 5 : max_pr:  : 0.712417
j:  : 4 : max_pr:  : 0.813893
j:  : 3 : max_pr:  : 0.879756
j:  : 2 : max_pr:  : 0.957761
j:  : 1 : max_pr:  : 0.995053
j:  : 0 : max_pr:  : 1
I0324 03:51:00.946501  1494 solver.cpp:786] class AP 3: 0.579685
I0324 03:51:00.946518  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.447218
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.200286
j:  : 4 : max_pr:  : 0.344353
j:  : 3 : max_pr:  : 0.56205
j:  : 2 : max_pr:  : 0.722343
j:  : 1 : max_pr:  : 0.815193
j:  : 0 : max_pr:  : 1
I0324 03:51:01.642367  1493 solver.cpp:786] class AP 1: 0.331293
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0372254
j:  : 7 : max_pr:  : 0.185023
j:  : 6 : max_pr:  : 0.366754
j:  : 5 : max_pr:  : 0.414358
j:  : 4 : max_pr:  : 0.473331
j:  : 3 : max_pr:  : 0.652565
j:  : 2 : max_pr:  : 0.78256
j:  : 1 : max_pr:  : 0.985141
j:  : 0 : max_pr:  : 1
I0324 03:51:01.696255  1493 solver.cpp:786] class AP 2: 0.445178
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.403364
j:  : 6 : max_pr:  : 0.592513
j:  : 5 : max_pr:  : 0.715767
j:  : 4 : max_pr:  : 0.825261
j:  : 3 : max_pr:  : 0.882754
j:  : 2 : max_pr:  : 0.958683
j:  : 1 : max_pr:  : 0.995807
j:  : 0 : max_pr:  : 1
I0324 03:51:01.706776  1493 solver.cpp:786] class AP 3: 0.579468
I0324 03:51:01.706789  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.45198
I0324 03:51:01.707031  1493 solver.cpp:265] [MultiGPU] Tests completed in 53.0952s
I0324 03:51:02.108139  1493 solver.cpp:314] Iteration 26000 (0.825737 iter/s, 121.104s/100 iter), loss = 3.12124
I0324 03:51:02.108245  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.31223 (* 1 = 3.31223 loss)
I0324 03:51:02.108286  1493 sgd_solver.cpp:136] Iteration 26000, lr = 0.01, m = 0.9
I0324 03:52:08.941757  1493 solver.cpp:314] Iteration 26100 (1.4963 iter/s, 66.8315s/100 iter), loss = 3.12777
I0324 03:52:08.941938  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.53384 (* 1 = 3.53384 loss)
I0324 03:52:08.941987  1493 sgd_solver.cpp:136] Iteration 26100, lr = 0.01, m = 0.9
I0324 03:53:16.797056  1493 solver.cpp:314] Iteration 26200 (1.47377 iter/s, 67.8531s/100 iter), loss = 3.45139
I0324 03:53:16.797222  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.09279 (* 1 = 4.09279 loss)
I0324 03:53:16.797266  1493 sgd_solver.cpp:136] Iteration 26200, lr = 0.01, m = 0.9
I0324 03:54:24.368139  1493 solver.cpp:314] Iteration 26300 (1.47997 iter/s, 67.5689s/100 iter), loss = 3.45854
I0324 03:54:24.368360  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.14581 (* 1 = 3.14581 loss)
I0324 03:54:24.368407  1493 sgd_solver.cpp:136] Iteration 26300, lr = 0.01, m = 0.9
I0324 03:55:33.651650  1493 solver.cpp:314] Iteration 26400 (1.44339 iter/s, 69.2813s/100 iter), loss = 3.16581
I0324 03:55:33.653755  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.7025 (* 1 = 2.7025 loss)
I0324 03:55:33.653781  1493 sgd_solver.cpp:136] Iteration 26400, lr = 0.01, m = 0.9
I0324 03:56:41.227520  1493 solver.cpp:314] Iteration 26500 (1.47987 iter/s, 67.5737s/100 iter), loss = 3.17522
I0324 03:56:41.227645  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.33598 (* 1 = 2.33598 loss)
I0324 03:56:41.227663  1493 sgd_solver.cpp:136] Iteration 26500, lr = 0.01, m = 0.9
I0324 03:57:49.742219  1493 solver.cpp:314] Iteration 26600 (1.45959 iter/s, 68.5125s/100 iter), loss = 3.31247
I0324 03:57:49.742377  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.59812 (* 1 = 2.59812 loss)
I0324 03:57:49.742395  1493 sgd_solver.cpp:136] Iteration 26600, lr = 0.01, m = 0.9
I0324 03:58:58.518157  1493 solver.cpp:314] Iteration 26700 (1.45405 iter/s, 68.7736s/100 iter), loss = 3.3972
I0324 03:58:58.518317  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.85944 (* 1 = 2.85944 loss)
I0324 03:58:58.518352  1493 sgd_solver.cpp:136] Iteration 26700, lr = 0.01, m = 0.9
I0324 03:59:37.058415  1462 data_reader.cpp:305] Starting prefetch of epoch 6
I0324 04:00:07.633262  1493 solver.cpp:314] Iteration 26800 (1.44691 iter/s, 69.1128s/100 iter), loss = 3.66739
I0324 04:00:07.633396  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.44553 (* 1 = 3.44553 loss)
I0324 04:00:07.633417  1493 sgd_solver.cpp:136] Iteration 26800, lr = 0.01, m = 0.9
I0324 04:01:15.221968  1493 solver.cpp:314] Iteration 26900 (1.47959 iter/s, 67.5864s/100 iter), loss = 3.21614
I0324 04:01:15.222062  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.16124 (* 1 = 3.16124 loss)
I0324 04:01:15.222079  1493 sgd_solver.cpp:136] Iteration 26900, lr = 0.01, m = 0.9
I0324 04:02:24.141134  1493 solver.cpp:314] Iteration 27000 (1.45102 iter/s, 68.9169s/100 iter), loss = 3.08931
I0324 04:02:24.141732  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.59049 (* 1 = 3.59049 loss)
I0324 04:02:24.141750  1493 sgd_solver.cpp:136] Iteration 27000, lr = 0.01, m = 0.9
I0324 04:03:31.896029  1493 solver.cpp:314] Iteration 27100 (1.47596 iter/s, 67.7527s/100 iter), loss = 3.20901
I0324 04:03:31.896142  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.88092 (* 1 = 2.88092 loss)
I0324 04:03:31.896158  1493 sgd_solver.cpp:136] Iteration 27100, lr = 0.01, m = 0.9
I0324 04:04:40.558153  1493 solver.cpp:314] Iteration 27200 (1.45645 iter/s, 68.6599s/100 iter), loss = 3.43271
I0324 04:04:40.558331  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.76375 (* 1 = 2.76375 loss)
I0324 04:04:40.558346  1493 sgd_solver.cpp:136] Iteration 27200, lr = 0.01, m = 0.9
I0324 04:05:49.320977  1493 solver.cpp:314] Iteration 27300 (1.45432 iter/s, 68.7606s/100 iter), loss = 3.48419
I0324 04:05:49.321079  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.79428 (* 1 = 3.79428 loss)
I0324 04:05:49.321095  1493 sgd_solver.cpp:136] Iteration 27300, lr = 0.01, m = 0.9
I0324 04:06:58.176414  1493 solver.cpp:314] Iteration 27400 (1.45237 iter/s, 68.8532s/100 iter), loss = 3.32597
I0324 04:06:58.176522  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.08838 (* 1 = 3.08838 loss)
I0324 04:06:58.176537  1493 sgd_solver.cpp:136] Iteration 27400, lr = 0.01, m = 0.9
I0324 04:08:06.773888  1493 solver.cpp:314] Iteration 27500 (1.45783 iter/s, 68.5952s/100 iter), loss = 3.26818
I0324 04:08:06.773977  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.95038 (* 1 = 2.95038 loss)
I0324 04:08:06.773988  1493 sgd_solver.cpp:136] Iteration 27500, lr = 0.01, m = 0.9
I0324 04:09:14.350052  1493 solver.cpp:314] Iteration 27600 (1.47986 iter/s, 67.5739s/100 iter), loss = 3.27808
I0324 04:09:14.350160  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.09459 (* 1 = 2.09459 loss)
I0324 04:09:14.350175  1493 sgd_solver.cpp:136] Iteration 27600, lr = 0.01, m = 0.9
I0324 04:10:22.621615  1493 solver.cpp:314] Iteration 27700 (1.46479 iter/s, 68.2693s/100 iter), loss = 3.43963
I0324 04:10:22.621752  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.69716 (* 1 = 3.69716 loss)
I0324 04:10:22.621770  1493 sgd_solver.cpp:136] Iteration 27700, lr = 0.01, m = 0.9
I0324 04:11:30.583108  1493 solver.cpp:314] Iteration 27800 (1.47147 iter/s, 67.9593s/100 iter), loss = 3.3316
I0324 04:11:30.583215  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.86687 (* 1 = 2.86687 loss)
I0324 04:11:30.583231  1493 sgd_solver.cpp:136] Iteration 27800, lr = 0.01, m = 0.9
I0324 04:12:40.168104  1493 solver.cpp:314] Iteration 27900 (1.43714 iter/s, 69.5827s/100 iter), loss = 3.59672
I0324 04:12:40.168233  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.88894 (* 1 = 2.88894 loss)
I0324 04:12:40.168249  1493 sgd_solver.cpp:136] Iteration 27900, lr = 0.01, m = 0.9
I0324 04:13:48.120735  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_28000.caffemodel
I0324 04:13:48.171733  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_28000.solverstate
I0324 04:13:48.186265  1493 solver.cpp:678] Iteration 28000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.200932
j:  : 4 : max_pr:  : 0.385672
j:  : 3 : max_pr:  : 0.568767
j:  : 2 : max_pr:  : 0.731087
j:  : 1 : max_pr:  : 0.863268
j:  : 0 : max_pr:  : 1
I0324 04:14:36.552481  1493 solver.cpp:786] class AP 1: 0.340884
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.104182
j:  : 6 : max_pr:  : 0.247249
j:  : 5 : max_pr:  : 0.429773
j:  : 4 : max_pr:  : 0.570416
j:  : 3 : max_pr:  : 0.61745
j:  : 2 : max_pr:  : 0.90647
j:  : 1 : max_pr:  : 0.980993
j:  : 0 : max_pr:  : 1
I0324 04:14:36.607247  1493 solver.cpp:786] class AP 2: 0.441503
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.406672
j:  : 6 : max_pr:  : 0.609873
j:  : 5 : max_pr:  : 0.726215
j:  : 4 : max_pr:  : 0.839157
j:  : 3 : max_pr:  : 0.922064
j:  : 2 : max_pr:  : 0.966925
j:  : 1 : max_pr:  : 0.995927
j:  : 0 : max_pr:  : 1
I0324 04:14:36.618633  1493 solver.cpp:786] class AP 3: 0.587894
I0324 04:14:36.618651  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.45676
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.187523
j:  : 4 : max_pr:  : 0.372847
j:  : 3 : max_pr:  : 0.558694
j:  : 2 : max_pr:  : 0.729192
j:  : 1 : max_pr:  : 0.859716
j:  : 0 : max_pr:  : 1
I0324 04:14:37.537777  1494 solver.cpp:786] class AP 1: 0.337088
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.119537
j:  : 6 : max_pr:  : 0.257845
j:  : 5 : max_pr:  : 0.429155
j:  : 4 : max_pr:  : 0.577468
j:  : 3 : max_pr:  : 0.616572
j:  : 2 : max_pr:  : 0.922859
j:  : 1 : max_pr:  : 0.992548
j:  : 0 : max_pr:  : 1
I0324 04:14:37.591341  1494 solver.cpp:786] class AP 2: 0.446908
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.408222
j:  : 6 : max_pr:  : 0.6
j:  : 5 : max_pr:  : 0.708138
j:  : 4 : max_pr:  : 0.826481
j:  : 3 : max_pr:  : 0.923587
j:  : 2 : max_pr:  : 0.971546
j:  : 1 : max_pr:  : 0.997247
j:  : 0 : max_pr:  : 1
I0324 04:14:37.602242  1494 solver.cpp:786] class AP 3: 0.58502
I0324 04:14:37.602260  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.456339
I0324 04:14:37.602757  1493 solver.cpp:265] [MultiGPU] Tests completed in 49.4149s
I0324 04:14:38.228183  1493 solver.cpp:314] Iteration 28000 (0.847054 iter/s, 118.056s/100 iter), loss = 3.45101
I0324 04:14:38.228232  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.78249 (* 1 = 3.78249 loss)
I0324 04:14:38.228248  1493 sgd_solver.cpp:136] Iteration 28000, lr = 0.01, m = 0.9
I0324 04:15:47.401950  1493 solver.cpp:314] Iteration 28100 (1.44568 iter/s, 69.1715s/100 iter), loss = 3.19378
I0324 04:15:47.402060  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.68084 (* 1 = 3.68084 loss)
I0324 04:15:47.402078  1493 sgd_solver.cpp:136] Iteration 28100, lr = 0.01, m = 0.9
I0324 04:16:55.672598  1493 solver.cpp:314] Iteration 28200 (1.46481 iter/s, 68.2684s/100 iter), loss = 3.45862
I0324 04:16:55.672705  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.88581 (* 1 = 3.88581 loss)
I0324 04:16:55.672722  1493 sgd_solver.cpp:136] Iteration 28200, lr = 0.01, m = 0.9
I0324 04:18:03.710263  1493 solver.cpp:314] Iteration 28300 (1.46982 iter/s, 68.0354s/100 iter), loss = 3.50482
I0324 04:18:03.710446  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.3886 (* 1 = 2.3886 loss)
I0324 04:18:03.710494  1493 sgd_solver.cpp:136] Iteration 28300, lr = 0.01, m = 0.9
I0324 04:19:11.808413  1493 solver.cpp:314] Iteration 28400 (1.46852 iter/s, 68.0959s/100 iter), loss = 3.43326
I0324 04:19:11.808526  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.58028 (* 1 = 2.58028 loss)
I0324 04:19:11.808543  1493 sgd_solver.cpp:136] Iteration 28400, lr = 0.01, m = 0.9
I0324 04:20:19.741763  1493 solver.cpp:314] Iteration 28500 (1.47208 iter/s, 67.9311s/100 iter), loss = 3.3659
I0324 04:20:19.741876  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.14903 (* 1 = 3.14903 loss)
I0324 04:20:19.741894  1493 sgd_solver.cpp:136] Iteration 28500, lr = 0.01, m = 0.9
I0324 04:21:27.349468  1493 solver.cpp:314] Iteration 28600 (1.47917 iter/s, 67.6055s/100 iter), loss = 3.19423
I0324 04:21:27.349570  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.22662 (* 1 = 3.22662 loss)
I0324 04:21:27.349586  1493 sgd_solver.cpp:136] Iteration 28600, lr = 0.01, m = 0.9
I0324 04:22:35.550379  1493 solver.cpp:314] Iteration 28700 (1.4663 iter/s, 68.1987s/100 iter), loss = 3.53234
I0324 04:22:35.557752  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.95898 (* 1 = 2.95898 loss)
I0324 04:22:35.557782  1493 sgd_solver.cpp:136] Iteration 28700, lr = 0.01, m = 0.9
I0324 04:23:44.102680  1493 solver.cpp:314] Iteration 28800 (1.45879 iter/s, 68.5501s/100 iter), loss = 3.33448
I0324 04:23:44.105546  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.90432 (* 1 = 2.90432 loss)
I0324 04:23:44.105571  1493 sgd_solver.cpp:136] Iteration 28800, lr = 0.01, m = 0.9
I0324 04:24:53.147745  1493 solver.cpp:314] Iteration 28900 (1.44838 iter/s, 69.0428s/100 iter), loss = 3.5653
I0324 04:24:53.147938  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.82266 (* 1 = 4.82266 loss)
I0324 04:24:53.147981  1493 sgd_solver.cpp:136] Iteration 28900, lr = 0.01, m = 0.9
I0324 04:26:01.118953  1493 solver.cpp:314] Iteration 29000 (1.47126 iter/s, 67.969s/100 iter), loss = 3.34675
I0324 04:26:01.121815  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.46074 (* 1 = 2.46074 loss)
I0324 04:26:01.121863  1493 sgd_solver.cpp:136] Iteration 29000, lr = 0.01, m = 0.9
I0324 04:27:10.343139  1493 solver.cpp:314] Iteration 29100 (1.44463 iter/s, 69.2219s/100 iter), loss = 3.56498
I0324 04:27:10.343267  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.34765 (* 1 = 4.34765 loss)
I0324 04:27:10.343287  1493 sgd_solver.cpp:136] Iteration 29100, lr = 0.01, m = 0.9
I0324 04:28:18.312539  1493 solver.cpp:314] Iteration 29200 (1.4713 iter/s, 67.9672s/100 iter), loss = 2.9908
I0324 04:28:18.312642  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.55168 (* 1 = 2.55168 loss)
I0324 04:28:18.312659  1493 sgd_solver.cpp:136] Iteration 29200, lr = 0.01, m = 0.9
I0324 04:29:25.882611  1493 solver.cpp:314] Iteration 29300 (1.47999 iter/s, 67.5679s/100 iter), loss = 3.24084
I0324 04:29:25.882717  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.70365 (* 1 = 2.70365 loss)
I0324 04:29:25.882732  1493 sgd_solver.cpp:136] Iteration 29300, lr = 0.01, m = 0.9
I0324 04:30:34.765738  1493 solver.cpp:314] Iteration 29400 (1.45178 iter/s, 68.8809s/100 iter), loss = 3.20227
I0324 04:30:34.769731  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.05094 (* 1 = 3.05094 loss)
I0324 04:30:34.769752  1493 sgd_solver.cpp:136] Iteration 29400, lr = 0.01, m = 0.9
I0324 04:31:44.038076  1493 solver.cpp:314] Iteration 29500 (1.44362 iter/s, 69.2701s/100 iter), loss = 3.5688
I0324 04:31:44.038198  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.68706 (* 1 = 2.68706 loss)
I0324 04:31:44.038434  1493 sgd_solver.cpp:136] Iteration 29500, lr = 0.01, m = 0.9
I0324 04:32:53.519412  1493 solver.cpp:314] Iteration 29600 (1.43928 iter/s, 69.4791s/100 iter), loss = 3.30433
I0324 04:32:53.519568  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.00735 (* 1 = 3.00735 loss)
I0324 04:32:53.519620  1493 sgd_solver.cpp:136] Iteration 29600, lr = 0.01, m = 0.9
I0324 04:34:03.394122  1493 solver.cpp:314] Iteration 29700 (1.43118 iter/s, 69.8724s/100 iter), loss = 3.42956
I0324 04:34:03.397778  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.81404 (* 1 = 3.81404 loss)
I0324 04:34:03.397812  1493 sgd_solver.cpp:136] Iteration 29700, lr = 0.01, m = 0.9
I0324 04:35:11.597964  1493 solver.cpp:314] Iteration 29800 (1.46624 iter/s, 68.2016s/100 iter), loss = 3.29442
I0324 04:35:11.598085  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.75627 (* 1 = 2.75627 loss)
I0324 04:35:11.598104  1493 sgd_solver.cpp:136] Iteration 29800, lr = 0.01, m = 0.9
I0324 04:36:08.816516  1462 data_reader.cpp:305] Starting prefetch of epoch 7
I0324 04:36:20.441967  1493 solver.cpp:314] Iteration 29900 (1.45261 iter/s, 68.8418s/100 iter), loss = 3.2418
I0324 04:36:20.442023  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.38336 (* 1 = 3.38336 loss)
I0324 04:36:20.442037  1493 sgd_solver.cpp:136] Iteration 29900, lr = 0.01, m = 0.9
I0324 04:37:27.998044  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_30000.caffemodel
I0324 04:37:28.032227  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_30000.solverstate
I0324 04:37:28.047492  1493 solver.cpp:678] Iteration 30000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0
j:  : 4 : max_pr:  : 0.293892
j:  : 3 : max_pr:  : 0.470443
j:  : 2 : max_pr:  : 0.615903
j:  : 1 : max_pr:  : 0.781619
j:  : 0 : max_pr:  : 1
I0324 04:38:17.476258  1493 solver.cpp:786] class AP 1: 0.287442
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.0979697
j:  : 6 : max_pr:  : 0.280676
j:  : 5 : max_pr:  : 0.412056
j:  : 4 : max_pr:  : 0.687262
j:  : 3 : max_pr:  : 0.837158
j:  : 2 : max_pr:  : 0.968702
j:  : 1 : max_pr:  : 0.994326
j:  : 0 : max_pr:  : 1
I0324 04:38:17.538826  1493 solver.cpp:786] class AP 2: 0.479832
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.366832
j:  : 6 : max_pr:  : 0.588178
j:  : 5 : max_pr:  : 0.734163
j:  : 4 : max_pr:  : 0.841503
j:  : 3 : max_pr:  : 0.903274
j:  : 2 : max_pr:  : 0.94721
j:  : 1 : max_pr:  : 0.98817
j:  : 0 : max_pr:  : 1
I0324 04:38:17.546349  1493 solver.cpp:786] class AP 3: 0.57903
I0324 04:38:17.546373  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.448768
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0
j:  : 4 : max_pr:  : 0.296201
j:  : 3 : max_pr:  : 0.471911
j:  : 2 : max_pr:  : 0.631434
j:  : 1 : max_pr:  : 0.777027
j:  : 0 : max_pr:  : 1
I0324 04:38:18.430460  1494 solver.cpp:786] class AP 1: 0.288779
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0345139
j:  : 7 : max_pr:  : 0.116971
j:  : 6 : max_pr:  : 0.339681
j:  : 5 : max_pr:  : 0.45256
j:  : 4 : max_pr:  : 0.702703
j:  : 3 : max_pr:  : 0.849701
j:  : 2 : max_pr:  : 0.975789
j:  : 1 : max_pr:  : 0.997264
j:  : 0 : max_pr:  : 1
I0324 04:38:18.480906  1494 solver.cpp:786] class AP 2: 0.497198
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.354619
j:  : 6 : max_pr:  : 0.591005
j:  : 5 : max_pr:  : 0.731292
j:  : 4 : max_pr:  : 0.834824
j:  : 3 : max_pr:  : 0.898247
j:  : 2 : max_pr:  : 0.953029
j:  : 1 : max_pr:  : 0.988981
j:  : 0 : max_pr:  : 1
I0324 04:38:18.487922  1494 solver.cpp:786] class AP 3: 0.577454
I0324 04:38:18.487934  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.454477
I0324 04:38:18.488270  1493 solver.cpp:265] [MultiGPU] Tests completed in 50.4391s
I0324 04:38:18.843747  1514 sgd_solver.cpp:48] MultiStep Status: Iteration 30000, step = 1
I0324 04:38:18.843780  1513 sgd_solver.cpp:48] MultiStep Status: Iteration 30000, step = 1
I0324 04:38:18.892415  1493 solver.cpp:314] Iteration 30000 (0.844262 iter/s, 118.447s/100 iter), loss = 3.05387
I0324 04:38:18.892460  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.8282 (* 1 = 3.8282 loss)
I0324 04:38:18.892473  1493 sgd_solver.cpp:136] Iteration 30000, lr = 0.001, m = 0.9
I0324 04:39:27.134181  1493 solver.cpp:314] Iteration 30100 (1.46543 iter/s, 68.2395s/100 iter), loss = 3.32898
I0324 04:39:27.134275  1493 solver.cpp:336]     Train net output #0: mbox_loss = 1.9905 (* 1 = 1.9905 loss)
I0324 04:39:27.134291  1493 sgd_solver.cpp:136] Iteration 30100, lr = 0.001, m = 0.9
I0324 04:40:36.470481  1493 solver.cpp:314] Iteration 30200 (1.44229 iter/s, 69.334s/100 iter), loss = 3.36419
I0324 04:40:36.470580  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.95438 (* 1 = 2.95438 loss)
I0324 04:40:36.470595  1493 sgd_solver.cpp:136] Iteration 30200, lr = 0.001, m = 0.9
I0324 04:41:44.985738  1493 solver.cpp:314] Iteration 30300 (1.45958 iter/s, 68.513s/100 iter), loss = 3.33215
I0324 04:41:44.985838  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.9634 (* 1 = 2.9634 loss)
I0324 04:41:44.985854  1493 sgd_solver.cpp:136] Iteration 30300, lr = 0.001, m = 0.9
I0324 04:42:53.090034  1493 solver.cpp:314] Iteration 30400 (1.46838 iter/s, 68.1021s/100 iter), loss = 3.08935
I0324 04:42:53.090137  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.76763 (* 1 = 3.76763 loss)
I0324 04:42:53.090154  1493 sgd_solver.cpp:136] Iteration 30400, lr = 0.001, m = 0.9
I0324 04:44:01.568042  1493 solver.cpp:314] Iteration 30500 (1.46037 iter/s, 68.4758s/100 iter), loss = 3.25807
I0324 04:44:01.568159  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.86797 (* 1 = 3.86797 loss)
I0324 04:44:01.568176  1493 sgd_solver.cpp:136] Iteration 30500, lr = 0.001, m = 0.9
I0324 04:45:10.125234  1493 solver.cpp:314] Iteration 30600 (1.45868 iter/s, 68.5549s/100 iter), loss = 3.12427
I0324 04:45:10.125334  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.75404 (* 1 = 3.75404 loss)
I0324 04:45:10.125350  1493 sgd_solver.cpp:136] Iteration 30600, lr = 0.001, m = 0.9
I0324 04:46:18.044426  1493 solver.cpp:314] Iteration 30700 (1.47239 iter/s, 67.917s/100 iter), loss = 3.25787
I0324 04:46:18.044523  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.62772 (* 1 = 2.62772 loss)
I0324 04:46:18.044538  1493 sgd_solver.cpp:136] Iteration 30700, lr = 0.001, m = 0.9
I0324 04:47:26.229001  1493 solver.cpp:314] Iteration 30800 (1.46666 iter/s, 68.1823s/100 iter), loss = 3.23526
I0324 04:47:26.229125  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.46939 (* 1 = 2.46939 loss)
I0324 04:47:26.229142  1493 sgd_solver.cpp:136] Iteration 30800, lr = 0.001, m = 0.9
I0324 04:48:35.028506  1493 solver.cpp:314] Iteration 30900 (1.45355 iter/s, 68.7973s/100 iter), loss = 3.20354
I0324 04:48:35.028606  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.89058 (* 1 = 2.89058 loss)
I0324 04:48:35.028622  1493 sgd_solver.cpp:136] Iteration 30900, lr = 0.001, m = 0.9
I0324 04:49:43.541235  1493 solver.cpp:314] Iteration 31000 (1.45963 iter/s, 68.5105s/100 iter), loss = 3.07137
I0324 04:49:43.541369  1493 solver.cpp:336]     Train net output #0: mbox_loss = 1.99802 (* 1 = 1.99802 loss)
I0324 04:49:43.541385  1493 sgd_solver.cpp:136] Iteration 31000, lr = 0.001, m = 0.9
I0324 04:50:52.033763  1493 solver.cpp:314] Iteration 31100 (1.46006 iter/s, 68.4903s/100 iter), loss = 3.34557
I0324 04:50:52.033941  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.14735 (* 1 = 4.14735 loss)
I0324 04:50:52.033991  1493 sgd_solver.cpp:136] Iteration 31100, lr = 0.001, m = 0.9
I0324 04:52:00.871625  1493 solver.cpp:314] Iteration 31200 (1.45274 iter/s, 68.8356s/100 iter), loss = 3.10128
I0324 04:52:00.871724  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.54138 (* 1 = 3.54138 loss)
I0324 04:52:00.871737  1493 sgd_solver.cpp:136] Iteration 31200, lr = 0.001, m = 0.9
I0324 04:53:09.100801  1493 solver.cpp:314] Iteration 31300 (1.4657 iter/s, 68.2269s/100 iter), loss = 3.09036
I0324 04:53:09.100915  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.92382 (* 1 = 3.92382 loss)
I0324 04:53:09.100931  1493 sgd_solver.cpp:136] Iteration 31300, lr = 0.001, m = 0.9
I0324 04:54:17.601903  1493 solver.cpp:314] Iteration 31400 (1.45988 iter/s, 68.4988s/100 iter), loss = 3.23065
I0324 04:54:17.602071  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.04487 (* 1 = 3.04487 loss)
I0324 04:54:17.602085  1493 sgd_solver.cpp:136] Iteration 31400, lr = 0.001, m = 0.9
I0324 04:55:26.195432  1493 solver.cpp:314] Iteration 31500 (1.45791 iter/s, 68.5913s/100 iter), loss = 3.08858
I0324 04:55:26.195540  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.04291 (* 1 = 3.04291 loss)
I0324 04:55:26.195557  1493 sgd_solver.cpp:136] Iteration 31500, lr = 0.001, m = 0.9
I0324 04:56:34.266700  1493 solver.cpp:314] Iteration 31600 (1.4691 iter/s, 68.0691s/100 iter), loss = 3.12815
I0324 04:56:34.266813  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.21098 (* 1 = 4.21098 loss)
I0324 04:56:34.266829  1493 sgd_solver.cpp:136] Iteration 31600, lr = 0.001, m = 0.9
I0324 04:57:43.163002  1493 solver.cpp:314] Iteration 31700 (1.4515 iter/s, 68.8941s/100 iter), loss = 3.09732
I0324 04:57:43.164546  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.057 (* 1 = 4.057 loss)
I0324 04:57:43.164913  1493 sgd_solver.cpp:136] Iteration 31700, lr = 0.001, m = 0.9
I0324 04:58:51.781131  1493 solver.cpp:314] Iteration 31800 (1.45739 iter/s, 68.6159s/100 iter), loss = 3.11282
I0324 04:58:51.781225  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.8298 (* 1 = 2.8298 loss)
I0324 04:58:51.781240  1493 sgd_solver.cpp:136] Iteration 31800, lr = 0.001, m = 0.9
I0324 04:59:59.910989  1493 solver.cpp:314] Iteration 31900 (1.46783 iter/s, 68.1276s/100 iter), loss = 3.15105
I0324 04:59:59.911121  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.70382 (* 1 = 2.70382 loss)
I0324 04:59:59.911145  1493 sgd_solver.cpp:136] Iteration 31900, lr = 0.001, m = 0.9
I0324 05:01:07.585994  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_32000.caffemodel
I0324 05:01:07.610126  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_32000.solverstate
I0324 05:01:07.620652  1493 solver.cpp:678] Iteration 32000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.287099
j:  : 4 : max_pr:  : 0.459724
j:  : 3 : max_pr:  : 0.604633
j:  : 2 : max_pr:  : 0.737864
j:  : 1 : max_pr:  : 0.84517
j:  : 0 : max_pr:  : 1
I0324 05:01:57.238963  1493 solver.cpp:786] class AP 1: 0.357681
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.22495
j:  : 7 : max_pr:  : 0.477737
j:  : 6 : max_pr:  : 0.557394
j:  : 5 : max_pr:  : 0.646831
j:  : 4 : max_pr:  : 0.695628
j:  : 3 : max_pr:  : 0.793664
j:  : 2 : max_pr:  : 0.985283
j:  : 1 : max_pr:  : 0.997972
j:  : 0 : max_pr:  : 1
I0324 05:01:57.290829  1493 solver.cpp:786] class AP 2: 0.579951
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.488847
j:  : 6 : max_pr:  : 0.640763
j:  : 5 : max_pr:  : 0.760195
j:  : 4 : max_pr:  : 0.859917
j:  : 3 : max_pr:  : 0.916938
j:  : 2 : max_pr:  : 0.962697
j:  : 1 : max_pr:  : 0.998602
j:  : 0 : max_pr:  : 1
I0324 05:01:57.299624  1493 solver.cpp:786] class AP 3: 0.602542
I0324 05:01:57.299649  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.513391
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.293051
j:  : 4 : max_pr:  : 0.476419
j:  : 3 : max_pr:  : 0.610785
j:  : 2 : max_pr:  : 0.731596
j:  : 1 : max_pr:  : 0.852467
j:  : 0 : max_pr:  : 1
I0324 05:01:57.496753  1494 solver.cpp:786] class AP 1: 0.360392
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.20925
j:  : 7 : max_pr:  : 0.462271
j:  : 6 : max_pr:  : 0.537677
j:  : 5 : max_pr:  : 0.630189
j:  : 4 : max_pr:  : 0.682902
j:  : 3 : max_pr:  : 0.787022
j:  : 2 : max_pr:  : 0.988772
j:  : 1 : max_pr:  : 0.994162
j:  : 0 : max_pr:  : 1
I0324 05:01:57.547935  1494 solver.cpp:786] class AP 2: 0.572022
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.502446
j:  : 6 : max_pr:  : 0.653903
j:  : 5 : max_pr:  : 0.770257
j:  : 4 : max_pr:  : 0.862676
j:  : 3 : max_pr:  : 0.917173
j:  : 2 : max_pr:  : 0.970062
j:  : 1 : max_pr:  : 0.99798
j:  : 0 : max_pr:  : 1
I0324 05:01:57.556828  1494 solver.cpp:786] class AP 3: 0.606772
I0324 05:01:57.556855  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.513062
I0324 05:01:57.557181  1493 solver.cpp:265] [MultiGPU] Tests completed in 49.9349s
I0324 05:01:57.990131  1493 solver.cpp:314] Iteration 32000 (0.846917 iter/s, 118.075s/100 iter), loss = 3.38297
I0324 05:01:57.990178  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.54239 (* 1 = 3.54239 loss)
I0324 05:01:57.990195  1493 sgd_solver.cpp:136] Iteration 32000, lr = 0.001, m = 0.9
I0324 05:03:06.210880  1493 solver.cpp:314] Iteration 32100 (1.46588 iter/s, 68.2185s/100 iter), loss = 3.29019
I0324 05:03:06.211024  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.65425 (* 1 = 3.65425 loss)
I0324 05:03:06.211042  1493 sgd_solver.cpp:136] Iteration 32100, lr = 0.001, m = 0.9
I0324 05:04:15.189118  1493 solver.cpp:314] Iteration 32200 (1.44978 iter/s, 68.976s/100 iter), loss = 3.01319
I0324 05:04:15.189227  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.2521 (* 1 = 3.2521 loss)
I0324 05:04:15.189244  1493 sgd_solver.cpp:136] Iteration 32200, lr = 0.001, m = 0.9
I0324 05:05:24.245437  1493 solver.cpp:314] Iteration 32300 (1.44814 iter/s, 69.0541s/100 iter), loss = 3.10525
I0324 05:05:24.245542  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.35539 (* 1 = 2.35539 loss)
I0324 05:05:24.245592  1493 sgd_solver.cpp:136] Iteration 32300, lr = 0.001, m = 0.9
I0324 05:06:33.073758  1493 solver.cpp:314] Iteration 32400 (1.45294 iter/s, 68.8261s/100 iter), loss = 3.03749
I0324 05:06:33.073854  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.42143 (* 1 = 4.42143 loss)
I0324 05:06:33.073873  1493 sgd_solver.cpp:136] Iteration 32400, lr = 0.001, m = 0.9
I0324 05:07:42.340334  1493 solver.cpp:314] Iteration 32500 (1.44374 iter/s, 69.2643s/100 iter), loss = 3.42609
I0324 05:07:42.340451  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.13776 (* 1 = 3.13776 loss)
I0324 05:07:42.340467  1493 sgd_solver.cpp:136] Iteration 32500, lr = 0.001, m = 0.9
I0324 05:08:50.743110  1493 solver.cpp:314] Iteration 32600 (1.46198 iter/s, 68.4006s/100 iter), loss = 3.29134
I0324 05:08:50.743204  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.52749 (* 1 = 3.52749 loss)
I0324 05:08:50.743219  1493 sgd_solver.cpp:136] Iteration 32600, lr = 0.001, m = 0.9
I0324 05:09:36.537892  1462 data_reader.cpp:305] Starting prefetch of epoch 8
I0324 05:10:00.517961  1493 solver.cpp:314] Iteration 32700 (1.43323 iter/s, 69.7726s/100 iter), loss = 3.23018
I0324 05:10:00.518018  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.51003 (* 1 = 2.51003 loss)
I0324 05:10:00.518034  1493 sgd_solver.cpp:136] Iteration 32700, lr = 0.001, m = 0.9
I0324 05:11:08.614143  1493 solver.cpp:314] Iteration 32800 (1.46856 iter/s, 68.094s/100 iter), loss = 3.14439
I0324 05:11:08.614255  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.58671 (* 1 = 4.58671 loss)
I0324 05:11:08.614274  1493 sgd_solver.cpp:136] Iteration 32800, lr = 0.001, m = 0.9
I0324 05:12:17.648457  1493 solver.cpp:314] Iteration 32900 (1.44861 iter/s, 69.0317s/100 iter), loss = 3.03609
I0324 05:12:17.648741  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.74252 (* 1 = 2.74252 loss)
I0324 05:12:17.648788  1493 sgd_solver.cpp:136] Iteration 32900, lr = 0.001, m = 0.9
I0324 05:13:26.030236  1493 solver.cpp:314] Iteration 33000 (1.46242 iter/s, 68.3799s/100 iter), loss = 3.14619
I0324 05:13:26.034071  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.79386 (* 1 = 2.79386 loss)
I0324 05:13:26.034101  1493 sgd_solver.cpp:136] Iteration 33000, lr = 0.001, m = 0.9
I0324 05:14:35.221992  1493 solver.cpp:314] Iteration 33100 (1.44531 iter/s, 69.1895s/100 iter), loss = 3.22596
I0324 05:14:35.222084  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.95066 (* 1 = 2.95066 loss)
I0324 05:14:35.222100  1493 sgd_solver.cpp:136] Iteration 33100, lr = 0.001, m = 0.9
I0324 05:15:44.254739  1493 solver.cpp:314] Iteration 33200 (1.44863 iter/s, 69.0305s/100 iter), loss = 2.9646
I0324 05:15:44.254884  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.96016 (* 1 = 2.96016 loss)
I0324 05:15:44.254900  1493 sgd_solver.cpp:136] Iteration 33200, lr = 0.001, m = 0.9
I0324 05:16:52.206069  1493 solver.cpp:314] Iteration 33300 (1.47169 iter/s, 67.9491s/100 iter), loss = 3.09558
I0324 05:16:52.206184  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.45728 (* 1 = 2.45728 loss)
I0324 05:16:52.206205  1493 sgd_solver.cpp:136] Iteration 33300, lr = 0.001, m = 0.9
I0324 05:18:00.317981  1493 solver.cpp:314] Iteration 33400 (1.46822 iter/s, 68.1097s/100 iter), loss = 2.93924
I0324 05:18:00.318094  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.64619 (* 1 = 2.64619 loss)
I0324 05:18:00.318110  1493 sgd_solver.cpp:136] Iteration 33400, lr = 0.001, m = 0.9
I0324 05:19:07.897786  1493 solver.cpp:314] Iteration 33500 (1.47978 iter/s, 67.5776s/100 iter), loss = 3.0175
I0324 05:19:07.897928  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.53345 (* 1 = 2.53345 loss)
I0324 05:19:07.897950  1493 sgd_solver.cpp:136] Iteration 33500, lr = 0.001, m = 0.9
I0324 05:20:16.454084  1493 solver.cpp:314] Iteration 33600 (1.4587 iter/s, 68.5541s/100 iter), loss = 3.00862
I0324 05:20:16.454174  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.8877 (* 1 = 2.8877 loss)
I0324 05:20:16.454187  1493 sgd_solver.cpp:136] Iteration 33600, lr = 0.001, m = 0.9
I0324 05:21:25.063731  1493 solver.cpp:314] Iteration 33700 (1.45757 iter/s, 68.6074s/100 iter), loss = 3.04978
I0324 05:21:25.063834  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.37687 (* 1 = 2.37687 loss)
I0324 05:21:25.063849  1493 sgd_solver.cpp:136] Iteration 33700, lr = 0.001, m = 0.9
I0324 05:22:33.457923  1493 solver.cpp:314] Iteration 33800 (1.46216 iter/s, 68.392s/100 iter), loss = 2.91296
I0324 05:22:33.458025  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.77329 (* 1 = 3.77329 loss)
I0324 05:22:33.458042  1493 sgd_solver.cpp:136] Iteration 33800, lr = 0.001, m = 0.9
I0324 05:23:42.159627  1493 solver.cpp:314] Iteration 33900 (1.45562 iter/s, 68.6995s/100 iter), loss = 3.39291
I0324 05:23:42.159713  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.11504 (* 1 = 3.11504 loss)
I0324 05:23:42.159729  1493 sgd_solver.cpp:136] Iteration 33900, lr = 0.001, m = 0.9
I0324 05:24:49.557456  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_34000.caffemodel
I0324 05:24:49.706102  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_34000.solverstate
I0324 05:24:49.719933  1493 solver.cpp:678] Iteration 34000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.334459
j:  : 4 : max_pr:  : 0.505058
j:  : 3 : max_pr:  : 0.647602
j:  : 2 : max_pr:  : 0.769069
j:  : 1 : max_pr:  : 0.873563
j:  : 0 : max_pr:  : 1
I0324 05:25:39.281067  1494 solver.cpp:786] class AP 1: 0.375432
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.143264
j:  : 7 : max_pr:  : 0.398034
j:  : 6 : max_pr:  : 0.505086
j:  : 5 : max_pr:  : 0.586633
j:  : 4 : max_pr:  : 0.673349
j:  : 3 : max_pr:  : 0.785342
j:  : 2 : max_pr:  : 0.9858
j:  : 1 : max_pr:  : 0.994398
j:  : 0 : max_pr:  : 1
I0324 05:25:39.331179  1494 solver.cpp:786] class AP 2: 0.551991
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.506404
j:  : 6 : max_pr:  : 0.669751
j:  : 5 : max_pr:  : 0.766258
j:  : 4 : max_pr:  : 0.856649
j:  : 3 : max_pr:  : 0.928758
j:  : 2 : max_pr:  : 0.969728
j:  : 1 : max_pr:  : 0.997999
j:  : 0 : max_pr:  : 1
I0324 05:25:39.344349  1494 solver.cpp:786] class AP 3: 0.608686
I0324 05:25:39.344368  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.512036
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.335006
j:  : 4 : max_pr:  : 0.497963
j:  : 3 : max_pr:  : 0.641351
j:  : 2 : max_pr:  : 0.769182
j:  : 1 : max_pr:  : 0.866827
j:  : 0 : max_pr:  : 1
I0324 05:25:39.766078  1493 solver.cpp:786] class AP 1: 0.373666
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.150067
j:  : 7 : max_pr:  : 0.406275
j:  : 6 : max_pr:  : 0.499611
j:  : 5 : max_pr:  : 0.593929
j:  : 4 : max_pr:  : 0.689396
j:  : 3 : max_pr:  : 0.797516
j:  : 2 : max_pr:  : 0.987758
j:  : 1 : max_pr:  : 0.99799
j:  : 0 : max_pr:  : 1
I0324 05:25:39.812012  1493 solver.cpp:786] class AP 2: 0.556595
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.503358
j:  : 6 : max_pr:  : 0.668187
j:  : 5 : max_pr:  : 0.754253
j:  : 4 : max_pr:  : 0.846563
j:  : 3 : max_pr:  : 0.924045
j:  : 2 : max_pr:  : 0.972087
j:  : 1 : max_pr:  : 0.9987
j:  : 0 : max_pr:  : 1
I0324 05:25:39.824985  1493 solver.cpp:786] class AP 3: 0.606109
I0324 05:25:39.825002  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.512123
I0324 05:25:39.825176  1493 solver.cpp:265] [MultiGPU] Tests completed in 50.1036s
I0324 05:25:40.229918  1493 solver.cpp:314] Iteration 34000 (0.846981 iter/s, 118.066s/100 iter), loss = 3.1846
I0324 05:25:40.229967  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.38742 (* 1 = 3.38742 loss)
I0324 05:25:40.229984  1493 sgd_solver.cpp:136] Iteration 34000, lr = 0.001, m = 0.9
I0324 05:26:49.193742  1493 solver.cpp:314] Iteration 34100 (1.45008 iter/s, 68.9616s/100 iter), loss = 3.13106
I0324 05:26:49.193835  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.18312 (* 1 = 2.18312 loss)
I0324 05:26:49.193852  1493 sgd_solver.cpp:136] Iteration 34100, lr = 0.001, m = 0.9
I0324 05:27:56.430981  1493 solver.cpp:314] Iteration 34200 (1.48732 iter/s, 67.235s/100 iter), loss = 3.05109
I0324 05:27:56.431138  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.6334 (* 1 = 2.6334 loss)
I0324 05:27:56.431200  1493 sgd_solver.cpp:136] Iteration 34200, lr = 0.001, m = 0.9
I0324 05:29:05.209769  1493 solver.cpp:314] Iteration 34300 (1.45398 iter/s, 68.7766s/100 iter), loss = 3.00419
I0324 05:29:05.209862  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.78304 (* 1 = 3.78304 loss)
I0324 05:29:05.209880  1493 sgd_solver.cpp:136] Iteration 34300, lr = 0.001, m = 0.9
I0324 05:30:13.859606  1493 solver.cpp:314] Iteration 34400 (1.45671 iter/s, 68.6476s/100 iter), loss = 3.10409
I0324 05:30:13.859717  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.9314 (* 1 = 2.9314 loss)
I0324 05:30:13.859735  1493 sgd_solver.cpp:136] Iteration 34400, lr = 0.001, m = 0.9
I0324 05:31:22.117724  1493 solver.cpp:314] Iteration 34500 (1.46511 iter/s, 68.2545s/100 iter), loss = 3.29385
I0324 05:31:22.117895  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.47133 (* 1 = 3.47133 loss)
I0324 05:31:22.117938  1493 sgd_solver.cpp:136] Iteration 34500, lr = 0.001, m = 0.9
I0324 05:32:30.933543  1493 solver.cpp:314] Iteration 34600 (1.4532 iter/s, 68.8136s/100 iter), loss = 3.00425
I0324 05:32:30.933651  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.61391 (* 1 = 2.61391 loss)
I0324 05:32:30.933667  1493 sgd_solver.cpp:136] Iteration 34600, lr = 0.001, m = 0.9
I0324 05:33:38.689227  1493 solver.cpp:314] Iteration 34700 (1.47594 iter/s, 67.7535s/100 iter), loss = 3.16158
I0324 05:33:38.689342  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.6788 (* 1 = 3.6788 loss)
I0324 05:33:38.689360  1493 sgd_solver.cpp:136] Iteration 34700, lr = 0.001, m = 0.9
I0324 05:34:47.669968  1493 solver.cpp:314] Iteration 34800 (1.44973 iter/s, 68.9785s/100 iter), loss = 2.9654
I0324 05:34:47.670091  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.02196 (* 1 = 3.02196 loss)
I0324 05:34:47.670109  1493 sgd_solver.cpp:136] Iteration 34800, lr = 0.001, m = 0.9
I0324 05:35:55.802497  1493 solver.cpp:314] Iteration 34900 (1.46778 iter/s, 68.1303s/100 iter), loss = 3.13765
I0324 05:35:55.802690  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.20823 (* 1 = 3.20823 loss)
I0324 05:35:55.802708  1493 sgd_solver.cpp:136] Iteration 34900, lr = 0.001, m = 0.9
I0324 05:37:03.573736  1493 solver.cpp:314] Iteration 35000 (1.4756 iter/s, 67.769s/100 iter), loss = 3.07385
I0324 05:37:03.573827  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.15509 (* 1 = 2.15509 loss)
I0324 05:37:03.573842  1493 sgd_solver.cpp:136] Iteration 35000, lr = 0.001, m = 0.9
I0324 05:38:11.757516  1493 solver.cpp:314] Iteration 35100 (1.46667 iter/s, 68.1815s/100 iter), loss = 2.95175
I0324 05:38:11.757634  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.1259 (* 1 = 2.1259 loss)
I0324 05:38:11.757653  1493 sgd_solver.cpp:136] Iteration 35100, lr = 0.001, m = 0.9
I0324 05:39:19.719951  1493 solver.cpp:314] Iteration 35200 (1.47145 iter/s, 67.9602s/100 iter), loss = 3.07648
I0324 05:39:19.720069  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.83685 (* 1 = 2.83685 loss)
I0324 05:39:19.720086  1493 sgd_solver.cpp:136] Iteration 35200, lr = 0.001, m = 0.9
I0324 05:40:27.666568  1493 solver.cpp:314] Iteration 35300 (1.47179 iter/s, 67.9444s/100 iter), loss = 3.13368
I0324 05:40:27.666746  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.9148 (* 1 = 2.9148 loss)
I0324 05:40:27.666797  1493 sgd_solver.cpp:136] Iteration 35300, lr = 0.001, m = 0.9
I0324 05:41:36.700660  1493 solver.cpp:314] Iteration 35400 (1.44861 iter/s, 69.0319s/100 iter), loss = 3.38468
I0324 05:41:36.700765  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.94705 (* 1 = 2.94705 loss)
I0324 05:41:36.700781  1493 sgd_solver.cpp:136] Iteration 35400, lr = 0.001, m = 0.9
I0324 05:42:45.207931  1493 solver.cpp:314] Iteration 35500 (1.45975 iter/s, 68.5051s/100 iter), loss = 3.40995
I0324 05:42:45.208118  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.60356 (* 1 = 4.60356 loss)
I0324 05:42:45.208164  1493 sgd_solver.cpp:136] Iteration 35500, lr = 0.001, m = 0.9
I0324 05:43:54.469554  1493 solver.cpp:314] Iteration 35600 (1.44385 iter/s, 69.2594s/100 iter), loss = 3.11336
I0324 05:43:54.469667  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.59693 (* 1 = 2.59693 loss)
I0324 05:43:54.469684  1493 sgd_solver.cpp:136] Iteration 35600, lr = 0.001, m = 0.9
I0324 05:45:03.744671  1493 solver.cpp:314] Iteration 35700 (1.44357 iter/s, 69.2729s/100 iter), loss = 3.26466
I0324 05:45:03.744837  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.53225 (* 1 = 2.53225 loss)
I0324 05:45:03.744889  1493 sgd_solver.cpp:136] Iteration 35700, lr = 0.001, m = 0.9
I0324 05:46:08.600015  1462 data_reader.cpp:305] Starting prefetch of epoch 9
I0324 05:46:13.138972  1493 solver.cpp:314] Iteration 35800 (1.44109 iter/s, 69.392s/100 iter), loss = 3.32576
I0324 05:46:13.139034  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.17723 (* 1 = 3.17723 loss)
I0324 05:46:13.139050  1493 sgd_solver.cpp:136] Iteration 35800, lr = 0.001, m = 0.9
I0324 05:47:21.720034  1493 solver.cpp:314] Iteration 35900 (1.45818 iter/s, 68.5788s/100 iter), loss = 3.08525
I0324 05:47:21.720144  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.01859 (* 1 = 3.01859 loss)
I0324 05:47:21.720160  1493 sgd_solver.cpp:136] Iteration 35900, lr = 0.001, m = 0.9
I0324 05:48:29.143674  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_36000.caffemodel
I0324 05:48:29.212237  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_36000.solverstate
I0324 05:48:29.228641  1493 solver.cpp:678] Iteration 36000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.277873
j:  : 4 : max_pr:  : 0.46802
j:  : 3 : max_pr:  : 0.636278
j:  : 2 : max_pr:  : 0.761347
j:  : 1 : max_pr:  : 0.859848
j:  : 0 : max_pr:  : 1
I0324 05:49:21.849993  1494 solver.cpp:786] class AP 1: 0.363943
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0931766
j:  : 7 : max_pr:  : 0.336171
j:  : 6 : max_pr:  : 0.422412
j:  : 5 : max_pr:  : 0.56835
j:  : 4 : max_pr:  : 0.677912
j:  : 3 : max_pr:  : 0.823655
j:  : 2 : max_pr:  : 0.985441
j:  : 1 : max_pr:  : 0.993958
j:  : 0 : max_pr:  : 1
I0324 05:49:21.910722  1494 solver.cpp:786] class AP 2: 0.536461
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.512695
j:  : 6 : max_pr:  : 0.664823
j:  : 5 : max_pr:  : 0.765117
j:  : 4 : max_pr:  : 0.854076
j:  : 3 : max_pr:  : 0.906599
j:  : 2 : max_pr:  : 0.959987
j:  : 1 : max_pr:  : 0.999316
j:  : 0 : max_pr:  : 1
I0324 05:49:21.925061  1494 solver.cpp:786] class AP 3: 0.605692
I0324 05:49:21.925084  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.502032
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.297832
j:  : 4 : max_pr:  : 0.481777
j:  : 3 : max_pr:  : 0.633882
j:  : 2 : max_pr:  : 0.761185
j:  : 1 : max_pr:  : 0.854274
j:  : 0 : max_pr:  : 1
I0324 05:49:22.129170  1493 solver.cpp:786] class AP 1: 0.366268
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.120043
j:  : 7 : max_pr:  : 0.349509
j:  : 6 : max_pr:  : 0.43211
j:  : 5 : max_pr:  : 0.583617
j:  : 4 : max_pr:  : 0.705198
j:  : 3 : max_pr:  : 0.840636
j:  : 2 : max_pr:  : 0.988688
j:  : 1 : max_pr:  : 0.997487
j:  : 0 : max_pr:  : 1
I0324 05:49:22.174985  1493 solver.cpp:786] class AP 2: 0.547026
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.51719
j:  : 6 : max_pr:  : 0.659781
j:  : 5 : max_pr:  : 0.746734
j:  : 4 : max_pr:  : 0.839369
j:  : 3 : max_pr:  : 0.905987
j:  : 2 : max_pr:  : 0.964175
j:  : 1 : max_pr:  : 0.998619
j:  : 0 : max_pr:  : 1
I0324 05:49:22.185590  1493 solver.cpp:786] class AP 3: 0.602896
I0324 05:49:22.185611  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.505397
I0324 05:49:22.186076  1493 solver.cpp:265] [MultiGPU] Tests completed in 52.9557s
I0324 05:49:22.597928  1493 solver.cpp:314] Iteration 36000 (0.827308 iter/s, 120.874s/100 iter), loss = 3.01297
I0324 05:49:22.597985  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.27799 (* 1 = 3.27799 loss)
I0324 05:49:22.597998  1493 sgd_solver.cpp:136] Iteration 36000, lr = 0.001, m = 0.9
I0324 05:50:31.762331  1493 solver.cpp:314] Iteration 36100 (1.44588 iter/s, 69.1622s/100 iter), loss = 3.20378
I0324 05:50:31.762426  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.63261 (* 1 = 3.63261 loss)
I0324 05:50:31.762441  1493 sgd_solver.cpp:136] Iteration 36100, lr = 0.001, m = 0.9
I0324 05:51:39.909493  1493 solver.cpp:314] Iteration 36200 (1.46746 iter/s, 68.145s/100 iter), loss = 3.06866
I0324 05:51:39.910847  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.65989 (* 1 = 2.65989 loss)
I0324 05:51:39.910864  1493 sgd_solver.cpp:136] Iteration 36200, lr = 0.001, m = 0.9
I0324 05:52:49.057768  1493 solver.cpp:314] Iteration 36300 (1.44621 iter/s, 69.146s/100 iter), loss = 3.25532
I0324 05:52:49.057878  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.16506 (* 1 = 3.16506 loss)
I0324 05:52:49.057895  1493 sgd_solver.cpp:136] Iteration 36300, lr = 0.001, m = 0.9
I0324 05:53:56.790212  1493 solver.cpp:314] Iteration 36400 (1.47645 iter/s, 67.7302s/100 iter), loss = 2.98655
I0324 05:53:56.790431  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.06229 (* 1 = 2.06229 loss)
I0324 05:53:56.790475  1493 sgd_solver.cpp:136] Iteration 36400, lr = 0.001, m = 0.9
I0324 05:55:05.948130  1493 solver.cpp:314] Iteration 36500 (1.44601 iter/s, 69.1557s/100 iter), loss = 3.03433
I0324 05:55:05.948236  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.05719 (* 1 = 3.05719 loss)
I0324 05:55:05.948288  1493 sgd_solver.cpp:136] Iteration 36500, lr = 0.001, m = 0.9
I0324 05:56:13.762109  1493 solver.cpp:314] Iteration 36600 (1.47467 iter/s, 67.8118s/100 iter), loss = 3.03109
I0324 05:56:13.762208  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.6267 (* 1 = 2.6267 loss)
I0324 05:56:13.762223  1493 sgd_solver.cpp:136] Iteration 36600, lr = 0.001, m = 0.9
I0324 05:57:22.993758  1493 solver.cpp:314] Iteration 36700 (1.44447 iter/s, 69.2294s/100 iter), loss = 3.0632
I0324 05:57:22.993926  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.34975 (* 1 = 3.34975 loss)
I0324 05:57:22.993974  1493 sgd_solver.cpp:136] Iteration 36700, lr = 0.001, m = 0.9
I0324 05:58:30.784646  1493 solver.cpp:314] Iteration 36800 (1.47517 iter/s, 67.7887s/100 iter), loss = 3.08144
I0324 05:58:30.785848  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.99949 (* 1 = 2.99949 loss)
I0324 05:58:30.785912  1493 sgd_solver.cpp:136] Iteration 36800, lr = 0.001, m = 0.9
I0324 05:59:40.022205  1493 solver.cpp:314] Iteration 36900 (1.44435 iter/s, 69.2353s/100 iter), loss = 2.98647
I0324 05:59:40.022358  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.85841 (* 1 = 2.85841 loss)
I0324 05:59:40.022403  1493 sgd_solver.cpp:136] Iteration 36900, lr = 0.001, m = 0.9
I0324 06:00:49.034061  1493 solver.cpp:314] Iteration 37000 (1.44907 iter/s, 69.0096s/100 iter), loss = 3.03436
I0324 06:00:49.034159  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.40249 (* 1 = 2.40249 loss)
I0324 06:00:49.034175  1493 sgd_solver.cpp:136] Iteration 37000, lr = 0.001, m = 0.9
I0324 06:01:57.793774  1493 solver.cpp:314] Iteration 37100 (1.45439 iter/s, 68.7575s/100 iter), loss = 3.20596
I0324 06:01:57.793925  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.78822 (* 1 = 2.78822 loss)
I0324 06:01:57.793951  1493 sgd_solver.cpp:136] Iteration 37100, lr = 0.001, m = 0.9
I0324 06:03:06.574765  1493 solver.cpp:314] Iteration 37200 (1.45394 iter/s, 68.7788s/100 iter), loss = 3.08501
I0324 06:03:06.574869  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.53701 (* 1 = 2.53701 loss)
I0324 06:03:06.574887  1493 sgd_solver.cpp:136] Iteration 37200, lr = 0.001, m = 0.9
I0324 06:04:14.987294  1493 solver.cpp:314] Iteration 37300 (1.46177 iter/s, 68.4103s/100 iter), loss = 3.1111
I0324 06:04:14.987402  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.27009 (* 1 = 3.27009 loss)
I0324 06:04:14.987418  1493 sgd_solver.cpp:136] Iteration 37300, lr = 0.001, m = 0.9
I0324 06:05:23.926103  1493 solver.cpp:314] Iteration 37400 (1.45061 iter/s, 68.9366s/100 iter), loss = 3.12703
I0324 06:05:23.926214  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.07052 (* 1 = 4.07052 loss)
I0324 06:05:23.926231  1493 sgd_solver.cpp:136] Iteration 37400, lr = 0.001, m = 0.9
I0324 06:06:32.738171  1493 solver.cpp:314] Iteration 37500 (1.45328 iter/s, 68.8098s/100 iter), loss = 3.10383
I0324 06:06:32.738262  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.71144 (* 1 = 2.71144 loss)
I0324 06:06:32.738278  1493 sgd_solver.cpp:136] Iteration 37500, lr = 0.001, m = 0.9
I0324 06:07:40.559028  1493 solver.cpp:314] Iteration 37600 (1.47452 iter/s, 67.8187s/100 iter), loss = 3.07532
I0324 06:07:40.559136  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.29325 (* 1 = 2.29325 loss)
I0324 06:07:40.559154  1493 sgd_solver.cpp:136] Iteration 37600, lr = 0.001, m = 0.9
I0324 06:08:48.281908  1493 solver.cpp:314] Iteration 37700 (1.47665 iter/s, 67.7206s/100 iter), loss = 2.9932
I0324 06:08:48.282080  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.68044 (* 1 = 2.68044 loss)
I0324 06:08:48.282129  1493 sgd_solver.cpp:136] Iteration 37700, lr = 0.001, m = 0.9
I0324 06:09:57.541754  1493 solver.cpp:314] Iteration 37800 (1.44389 iter/s, 69.2576s/100 iter), loss = 3.17548
I0324 06:09:57.541887  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.46325 (* 1 = 3.46325 loss)
I0324 06:09:57.541906  1493 sgd_solver.cpp:136] Iteration 37800, lr = 0.001, m = 0.9
I0324 06:11:05.114650  1493 solver.cpp:314] Iteration 37900 (1.47993 iter/s, 67.5707s/100 iter), loss = 2.93584
I0324 06:11:05.114776  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.99593 (* 1 = 2.99593 loss)
I0324 06:11:05.114826  1493 sgd_solver.cpp:136] Iteration 37900, lr = 0.001, m = 0.9
I0324 06:12:11.682731  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_38000.caffemodel
I0324 06:12:11.731462  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_38000.solverstate
I0324 06:12:11.749845  1493 solver.cpp:678] Iteration 38000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.282705
j:  : 4 : max_pr:  : 0.46875
j:  : 3 : max_pr:  : 0.60372
j:  : 2 : max_pr:  : 0.726551
j:  : 1 : max_pr:  : 0.829963
j:  : 0 : max_pr:  : 1
I0324 06:13:08.292428  1494 solver.cpp:786] class AP 1: 0.355608
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0993178
j:  : 7 : max_pr:  : 0.435933
j:  : 6 : max_pr:  : 0.528732
j:  : 5 : max_pr:  : 0.618462
j:  : 4 : max_pr:  : 0.67367
j:  : 3 : max_pr:  : 0.797065
j:  : 2 : max_pr:  : 0.987702
j:  : 1 : max_pr:  : 0.996279
j:  : 0 : max_pr:  : 1
I0324 06:13:08.346942  1494 solver.cpp:786] class AP 2: 0.557924
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.519979
j:  : 6 : max_pr:  : 0.66536
j:  : 5 : max_pr:  : 0.766223
j:  : 4 : max_pr:  : 0.868365
j:  : 3 : max_pr:  : 0.91852
j:  : 2 : max_pr:  : 0.961811
j:  : 1 : max_pr:  : 0.998672
j:  : 0 : max_pr:  : 1
I0324 06:13:08.357007  1494 solver.cpp:786] class AP 3: 0.608994
I0324 06:13:08.357026  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.507509
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.299261
j:  : 4 : max_pr:  : 0.491679
j:  : 3 : max_pr:  : 0.620112
j:  : 2 : max_pr:  : 0.735506
j:  : 1 : max_pr:  : 0.843621
j:  : 0 : max_pr:  : 1
I0324 06:13:08.739434  1493 solver.cpp:786] class AP 1: 0.362744
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.145593
j:  : 7 : max_pr:  : 0.436877
j:  : 6 : max_pr:  : 0.524029
j:  : 5 : max_pr:  : 0.620999
j:  : 4 : max_pr:  : 0.68508
j:  : 3 : max_pr:  : 0.797915
j:  : 2 : max_pr:  : 0.991809
j:  : 1 : max_pr:  : 1
j:  : 0 : max_pr:  : 1
I0324 06:13:08.792268  1493 solver.cpp:786] class AP 2: 0.563846
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.500792
j:  : 6 : max_pr:  : 0.650391
j:  : 5 : max_pr:  : 0.746773
j:  : 4 : max_pr:  : 0.854876
j:  : 3 : max_pr:  : 0.91209
j:  : 2 : max_pr:  : 0.962212
j:  : 1 : max_pr:  : 0.999361
j:  : 0 : max_pr:  : 1
I0324 06:13:08.801992  1493 solver.cpp:786] class AP 3: 0.602409
I0324 06:13:08.802006  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.509666
I0324 06:13:08.802376  1493 solver.cpp:265] [MultiGPU] Tests completed in 57.0508s
I0324 06:13:09.280328  1493 solver.cpp:314] Iteration 38000 (0.805402 iter/s, 124.162s/100 iter), loss = 3.14978
I0324 06:13:09.280375  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.25916 (* 1 = 4.25916 loss)
I0324 06:13:09.280386  1493 sgd_solver.cpp:136] Iteration 38000, lr = 0.001, m = 0.9
I0324 06:14:17.389927  1493 solver.cpp:314] Iteration 38100 (1.46827 iter/s, 68.1074s/100 iter), loss = 3.19815
I0324 06:14:17.390029  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.53201 (* 1 = 2.53201 loss)
I0324 06:14:17.390048  1493 sgd_solver.cpp:136] Iteration 38100, lr = 0.001, m = 0.9
I0324 06:15:25.657567  1493 solver.cpp:314] Iteration 38200 (1.46487 iter/s, 68.2654s/100 iter), loss = 3.11119
I0324 06:15:25.657670  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.18423 (* 1 = 3.18423 loss)
I0324 06:15:25.657685  1493 sgd_solver.cpp:136] Iteration 38200, lr = 0.001, m = 0.9
I0324 06:16:34.368717  1493 solver.cpp:314] Iteration 38300 (1.45542 iter/s, 68.7089s/100 iter), loss = 2.83169
I0324 06:16:34.368892  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.20701 (* 1 = 3.20701 loss)
I0324 06:16:34.368938  1493 sgd_solver.cpp:136] Iteration 38300, lr = 0.001, m = 0.9
I0324 06:17:42.805747  1493 solver.cpp:314] Iteration 38400 (1.46124 iter/s, 68.4348s/100 iter), loss = 3.35598
I0324 06:17:42.810947  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.96208 (* 1 = 3.96208 loss)
I0324 06:17:42.810973  1493 sgd_solver.cpp:136] Iteration 38400, lr = 0.001, m = 0.9
I0324 06:18:50.791467  1493 solver.cpp:314] Iteration 38500 (1.47094 iter/s, 67.9835s/100 iter), loss = 3.17166
I0324 06:18:50.791641  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.80233 (* 1 = 2.80233 loss)
I0324 06:18:50.791687  1493 sgd_solver.cpp:136] Iteration 38500, lr = 0.001, m = 0.9
I0324 06:19:43.405539  1462 data_reader.cpp:305] Starting prefetch of epoch 10
I0324 06:19:59.953063  1493 solver.cpp:314] Iteration 38600 (1.44594 iter/s, 69.1593s/100 iter), loss = 3.08497
I0324 06:19:59.953125  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.43066 (* 1 = 2.43066 loss)
I0324 06:19:59.953140  1493 sgd_solver.cpp:136] Iteration 38600, lr = 0.001, m = 0.9
I0324 06:21:08.539633  1493 solver.cpp:314] Iteration 38700 (1.45806 iter/s, 68.5844s/100 iter), loss = 3.28512
I0324 06:21:08.539822  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.13924 (* 1 = 4.13924 loss)
I0324 06:21:08.539865  1493 sgd_solver.cpp:136] Iteration 38700, lr = 0.001, m = 0.9
I0324 06:22:17.390202  1493 solver.cpp:314] Iteration 38800 (1.45247 iter/s, 68.8483s/100 iter), loss = 2.99097
I0324 06:22:17.391670  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.25015 (* 1 = 2.25015 loss)
I0324 06:22:17.391698  1493 sgd_solver.cpp:136] Iteration 38800, lr = 0.001, m = 0.9
I0324 06:23:26.585938  1493 solver.cpp:314] Iteration 38900 (1.44522 iter/s, 69.1935s/100 iter), loss = 3.04095
I0324 06:23:26.586050  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.27443 (* 1 = 2.27443 loss)
I0324 06:23:26.586068  1493 sgd_solver.cpp:136] Iteration 38900, lr = 0.001, m = 0.9
I0324 06:24:34.712321  1493 solver.cpp:314] Iteration 39000 (1.46791 iter/s, 68.1242s/100 iter), loss = 3.19843
I0324 06:24:34.712429  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.03752 (* 1 = 3.03752 loss)
I0324 06:24:34.712446  1493 sgd_solver.cpp:136] Iteration 39000, lr = 0.001, m = 0.9
I0324 06:25:42.690222  1493 solver.cpp:314] Iteration 39100 (1.47111 iter/s, 67.9757s/100 iter), loss = 2.93493
I0324 06:25:42.690318  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.35527 (* 1 = 2.35527 loss)
I0324 06:25:42.690335  1493 sgd_solver.cpp:136] Iteration 39100, lr = 0.001, m = 0.9
I0324 06:26:51.954618  1493 solver.cpp:314] Iteration 39200 (1.44379 iter/s, 69.2622s/100 iter), loss = 2.98839
I0324 06:26:51.954733  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.53746 (* 1 = 2.53746 loss)
I0324 06:26:51.954749  1493 sgd_solver.cpp:136] Iteration 39200, lr = 0.001, m = 0.9
I0324 06:28:01.005865  1493 solver.cpp:314] Iteration 39300 (1.44825 iter/s, 69.049s/100 iter), loss = 3.27341
I0324 06:28:01.005995  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.92711 (* 1 = 2.92711 loss)
I0324 06:28:01.006016  1493 sgd_solver.cpp:136] Iteration 39300, lr = 0.001, m = 0.9
I0324 06:29:08.705284  1493 solver.cpp:314] Iteration 39400 (1.47716 iter/s, 67.6973s/100 iter), loss = 3.17794
I0324 06:29:08.705417  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.3065 (* 1 = 4.3065 loss)
I0324 06:29:08.705476  1493 sgd_solver.cpp:136] Iteration 39400, lr = 0.001, m = 0.9
I0324 06:30:16.873984  1493 solver.cpp:314] Iteration 39500 (1.467 iter/s, 68.1665s/100 iter), loss = 3.06495
I0324 06:30:16.874104  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.3942 (* 1 = 3.3942 loss)
I0324 06:30:16.874517  1493 sgd_solver.cpp:136] Iteration 39500, lr = 0.001, m = 0.9
I0324 06:31:27.358816  1493 solver.cpp:314] Iteration 39600 (1.41879 iter/s, 70.4826s/100 iter), loss = 3.47505
I0324 06:31:27.358917  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.19611 (* 1 = 4.19611 loss)
I0324 06:31:27.358935  1493 sgd_solver.cpp:136] Iteration 39600, lr = 0.001, m = 0.9
I0324 06:32:35.501832  1493 solver.cpp:314] Iteration 39700 (1.46755 iter/s, 68.1408s/100 iter), loss = 3.10486
I0324 06:32:35.502022  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.33085 (* 1 = 2.33085 loss)
I0324 06:32:35.502073  1493 sgd_solver.cpp:136] Iteration 39700, lr = 0.001, m = 0.9
I0324 06:33:44.404040  1493 solver.cpp:314] Iteration 39800 (1.45138 iter/s, 68.8999s/100 iter), loss = 3.10937
I0324 06:33:44.404193  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.72066 (* 1 = 2.72066 loss)
I0324 06:33:44.404233  1493 sgd_solver.cpp:136] Iteration 39800, lr = 0.001, m = 0.9
I0324 06:34:53.161674  1493 solver.cpp:314] Iteration 39900 (1.45443 iter/s, 68.7554s/100 iter), loss = 3.10082
I0324 06:34:53.162077  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.5804 (* 1 = 2.5804 loss)
I0324 06:34:53.162096  1493 sgd_solver.cpp:136] Iteration 39900, lr = 0.001, m = 0.9
I0324 06:36:00.112795  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_40000.caffemodel
I0324 06:36:00.149907  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_40000.solverstate
I0324 06:36:00.164129  1493 solver.cpp:678] Iteration 40000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.295553
j:  : 4 : max_pr:  : 0.501398
j:  : 3 : max_pr:  : 0.649253
j:  : 2 : max_pr:  : 0.771506
j:  : 1 : max_pr:  : 0.870336
j:  : 0 : max_pr:  : 1
I0324 06:36:48.985051  1493 solver.cpp:786] class AP 1: 0.371641
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.187926
j:  : 7 : max_pr:  : 0.381788
j:  : 6 : max_pr:  : 0.56477
j:  : 5 : max_pr:  : 0.627597
j:  : 4 : max_pr:  : 0.681571
j:  : 3 : max_pr:  : 0.788423
j:  : 2 : max_pr:  : 0.98449
j:  : 1 : max_pr:  : 0.995294
j:  : 0 : max_pr:  : 1
I0324 06:36:49.052119  1493 solver.cpp:786] class AP 2: 0.564714
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.524227
j:  : 6 : max_pr:  : 0.666562
j:  : 5 : max_pr:  : 0.759595
j:  : 4 : max_pr:  : 0.865724
j:  : 3 : max_pr:  : 0.918398
j:  : 2 : max_pr:  : 0.967191
j:  : 1 : max_pr:  : 0.998046
j:  : 0 : max_pr:  : 1
I0324 06:36:49.067087  1493 solver.cpp:786] class AP 3: 0.609068
I0324 06:36:49.067109  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.515141
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.282791
j:  : 4 : max_pr:  : 0.478205
j:  : 3 : max_pr:  : 0.631759
j:  : 2 : max_pr:  : 0.762556
j:  : 1 : max_pr:  : 0.861486
j:  : 0 : max_pr:  : 1
I0324 06:36:50.314074  1494 solver.cpp:786] class AP 1: 0.365163
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.204041
j:  : 7 : max_pr:  : 0.39525
j:  : 6 : max_pr:  : 0.571664
j:  : 5 : max_pr:  : 0.633327
j:  : 4 : max_pr:  : 0.682245
j:  : 3 : max_pr:  : 0.790785
j:  : 2 : max_pr:  : 0.988345
j:  : 1 : max_pr:  : 0.998033
j:  : 0 : max_pr:  : 1
I0324 06:36:50.363394  1494 solver.cpp:786] class AP 2: 0.569426
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.514667
j:  : 6 : max_pr:  : 0.658447
j:  : 5 : max_pr:  : 0.750053
j:  : 4 : max_pr:  : 0.860639
j:  : 3 : max_pr:  : 0.915618
j:  : 2 : max_pr:  : 0.957225
j:  : 1 : max_pr:  : 0.997874
j:  : 0 : max_pr:  : 1
I0324 06:36:50.374399  1494 solver.cpp:786] class AP 3: 0.604957
I0324 06:36:50.374415  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.513182
I0324 06:36:50.374971  1493 solver.cpp:265] [MultiGPU] Tests completed in 50.2092s
I0324 06:36:50.797813  1514 sgd_solver.cpp:48] MultiStep Status: Iteration 40000, step = 2
I0324 06:36:50.797951  1513 sgd_solver.cpp:48] MultiStep Status: Iteration 40000, step = 2
I0324 06:36:50.877429  1493 solver.cpp:314] Iteration 40000 (0.849532 iter/s, 117.712s/100 iter), loss = 3.08852
I0324 06:36:50.877476  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.28139 (* 1 = 3.28139 loss)
I0324 06:36:50.877492  1493 sgd_solver.cpp:136] Iteration 40000, lr = 0.0001, m = 0.9
I0324 06:37:58.216634  1493 solver.cpp:314] Iteration 40100 (1.48507 iter/s, 67.337s/100 iter), loss = 3.03868
I0324 06:37:58.216742  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.43267 (* 1 = 2.43267 loss)
I0324 06:37:58.216759  1493 sgd_solver.cpp:136] Iteration 40100, lr = 0.0001, m = 0.9
I0324 06:39:07.549751  1493 solver.cpp:314] Iteration 40200 (1.44236 iter/s, 69.3308s/100 iter), loss = 3.21853
I0324 06:39:07.549849  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.84291 (* 1 = 3.84291 loss)
I0324 06:39:07.549867  1493 sgd_solver.cpp:136] Iteration 40200, lr = 0.0001, m = 0.9
I0324 06:40:15.846252  1493 solver.cpp:314] Iteration 40300 (1.46425 iter/s, 68.2943s/100 iter), loss = 3.04632
I0324 06:40:15.846424  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.36273 (* 1 = 2.36273 loss)
I0324 06:40:15.846468  1493 sgd_solver.cpp:136] Iteration 40300, lr = 0.0001, m = 0.9
I0324 06:41:23.929738  1493 solver.cpp:314] Iteration 40400 (1.46883 iter/s, 68.0813s/100 iter), loss = 3.36412
I0324 06:41:23.929889  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.45681 (* 1 = 3.45681 loss)
I0324 06:41:23.929934  1493 sgd_solver.cpp:136] Iteration 40400, lr = 0.0001, m = 0.9
I0324 06:42:32.415668  1493 solver.cpp:314] Iteration 40500 (1.4602 iter/s, 68.4837s/100 iter), loss = 3.02066
I0324 06:42:32.415837  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.53995 (* 1 = 2.53995 loss)
I0324 06:42:32.415882  1493 sgd_solver.cpp:136] Iteration 40500, lr = 0.0001, m = 0.9
I0324 06:43:41.269759  1493 solver.cpp:314] Iteration 40600 (1.45239 iter/s, 68.8518s/100 iter), loss = 3.13494
I0324 06:43:41.269866  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.68003 (* 1 = 2.68003 loss)
I0324 06:43:41.269884  1493 sgd_solver.cpp:136] Iteration 40600, lr = 0.0001, m = 0.9
I0324 06:44:49.405748  1493 solver.cpp:314] Iteration 40700 (1.4677 iter/s, 68.1338s/100 iter), loss = 3.23995
I0324 06:44:49.405851  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.08359 (* 1 = 3.08359 loss)
I0324 06:44:49.405870  1493 sgd_solver.cpp:136] Iteration 40700, lr = 0.0001, m = 0.9
I0324 06:45:57.259088  1493 solver.cpp:314] Iteration 40800 (1.47382 iter/s, 67.8511s/100 iter), loss = 3.02396
I0324 06:45:57.259333  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.92997 (* 1 = 3.92997 loss)
I0324 06:45:57.259390  1493 sgd_solver.cpp:136] Iteration 40800, lr = 0.0001, m = 0.9
I0324 06:47:05.876575  1493 solver.cpp:314] Iteration 40900 (1.4574 iter/s, 68.6152s/100 iter), loss = 3.08889
I0324 06:47:05.876715  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.78777 (* 1 = 2.78777 loss)
I0324 06:47:05.876732  1493 sgd_solver.cpp:136] Iteration 40900, lr = 0.0001, m = 0.9
I0324 06:48:13.945984  1493 solver.cpp:314] Iteration 41000 (1.46914 iter/s, 68.0672s/100 iter), loss = 3.07945
I0324 06:48:13.946074  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.28953 (* 1 = 3.28953 loss)
I0324 06:48:13.946089  1493 sgd_solver.cpp:136] Iteration 41000, lr = 0.0001, m = 0.9
I0324 06:49:22.611306  1493 solver.cpp:314] Iteration 41100 (1.45639 iter/s, 68.6631s/100 iter), loss = 2.77328
I0324 06:49:22.619182  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.06424 (* 1 = 2.06424 loss)
I0324 06:49:22.619220  1493 sgd_solver.cpp:136] Iteration 41100, lr = 0.0001, m = 0.9
I0324 06:50:31.034060  1493 solver.cpp:314] Iteration 41200 (1.46155 iter/s, 68.4205s/100 iter), loss = 3.15337
I0324 06:50:31.034165  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.11522 (* 1 = 3.11522 loss)
I0324 06:50:31.034181  1493 sgd_solver.cpp:136] Iteration 41200, lr = 0.0001, m = 0.9
I0324 06:51:38.494746  1493 solver.cpp:314] Iteration 41300 (1.48239 iter/s, 67.4585s/100 iter), loss = 2.98827
I0324 06:51:38.494854  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.14123 (* 1 = 3.14123 loss)
I0324 06:51:38.494871  1493 sgd_solver.cpp:136] Iteration 41300, lr = 0.0001, m = 0.9
I0324 06:52:47.247902  1493 solver.cpp:314] Iteration 41400 (1.45453 iter/s, 68.7509s/100 iter), loss = 3.13453
I0324 06:52:47.248010  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.36733 (* 1 = 3.36733 loss)
I0324 06:52:47.248026  1493 sgd_solver.cpp:136] Iteration 41400, lr = 0.0001, m = 0.9
I0324 06:53:56.805222  1493 solver.cpp:314] Iteration 41500 (1.43771 iter/s, 69.555s/100 iter), loss = 3.04435
I0324 06:53:56.805393  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.30626 (* 1 = 2.30626 loss)
I0324 06:53:56.805436  1493 sgd_solver.cpp:136] Iteration 41500, lr = 0.0001, m = 0.9
I0324 06:55:04.460912  1493 solver.cpp:314] Iteration 41600 (1.47812 iter/s, 67.6535s/100 iter), loss = 3.12917
I0324 06:55:04.461483  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.52901 (* 1 = 4.52901 loss)
I0324 06:55:04.461885  1493 sgd_solver.cpp:136] Iteration 41600, lr = 0.0001, m = 0.9
I0324 06:56:12.606453  1493 solver.cpp:314] Iteration 41700 (1.4675 iter/s, 68.1433s/100 iter), loss = 2.7812
I0324 06:56:12.606642  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.13501 (* 1 = 2.13501 loss)
I0324 06:56:12.606657  1493 sgd_solver.cpp:136] Iteration 41700, lr = 0.0001, m = 0.9
I0324 06:56:14.873960  1462 data_reader.cpp:305] Starting prefetch of epoch 11
I0324 06:57:21.558989  1493 solver.cpp:314] Iteration 41800 (1.45032 iter/s, 68.9503s/100 iter), loss = 2.78542
I0324 06:57:21.559094  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.32422 (* 1 = 2.32422 loss)
I0324 06:57:21.559111  1493 sgd_solver.cpp:136] Iteration 41800, lr = 0.0001, m = 0.9
I0324 06:58:30.013484  1493 solver.cpp:314] Iteration 41900 (1.46087 iter/s, 68.4523s/100 iter), loss = 3.07801
I0324 06:58:30.013669  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.08809 (* 1 = 3.08809 loss)
I0324 06:58:30.013684  1493 sgd_solver.cpp:136] Iteration 41900, lr = 0.0001, m = 0.9
I0324 06:59:37.968294  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_42000.caffemodel
I0324 06:59:38.002785  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_42000.solverstate
I0324 06:59:38.016464  1493 solver.cpp:678] Iteration 42000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.312643
j:  : 4 : max_pr:  : 0.500104
j:  : 3 : max_pr:  : 0.636085
j:  : 2 : max_pr:  : 0.768165
j:  : 1 : max_pr:  : 0.854364
j:  : 0 : max_pr:  : 1
I0324 07:00:27.290899  1494 solver.cpp:786] class AP 1: 0.370124
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.161471
j:  : 7 : max_pr:  : 0.396291
j:  : 6 : max_pr:  : 0.533352
j:  : 5 : max_pr:  : 0.607773
j:  : 4 : max_pr:  : 0.683497
j:  : 3 : max_pr:  : 0.788848
j:  : 2 : max_pr:  : 0.989198
j:  : 1 : max_pr:  : 0.998217
j:  : 0 : max_pr:  : 1
I0324 07:00:27.341408  1494 solver.cpp:786] class AP 2: 0.559877
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.526765
j:  : 6 : max_pr:  : 0.650962
j:  : 5 : max_pr:  : 0.744788
j:  : 4 : max_pr:  : 0.855324
j:  : 3 : max_pr:  : 0.911714
j:  : 2 : max_pr:  : 0.960399
j:  : 1 : max_pr:  : 0.998641
j:  : 0 : max_pr:  : 1
I0324 07:00:27.352352  1494 solver.cpp:786] class AP 3: 0.604418
I0324 07:00:27.352372  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.511473
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.301721
j:  : 4 : max_pr:  : 0.500103
j:  : 3 : max_pr:  : 0.639113
j:  : 2 : max_pr:  : 0.75762
j:  : 1 : max_pr:  : 0.869234
j:  : 0 : max_pr:  : 1
I0324 07:00:28.224586  1493 solver.cpp:786] class AP 1: 0.369799
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.129792
j:  : 7 : max_pr:  : 0.385017
j:  : 6 : max_pr:  : 0.532157
j:  : 5 : max_pr:  : 0.602879
j:  : 4 : max_pr:  : 0.672325
j:  : 3 : max_pr:  : 0.782123
j:  : 2 : max_pr:  : 0.988688
j:  : 1 : max_pr:  : 0.996475
j:  : 0 : max_pr:  : 1
I0324 07:00:28.273643  1493 solver.cpp:786] class AP 2: 0.553587
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.501511
j:  : 6 : max_pr:  : 0.645022
j:  : 5 : max_pr:  : 0.751983
j:  : 4 : max_pr:  : 0.864964
j:  : 3 : max_pr:  : 0.912022
j:  : 2 : max_pr:  : 0.960526
j:  : 1 : max_pr:  : 0.997921
j:  : 0 : max_pr:  : 1
I0324 07:00:28.283913  1493 solver.cpp:786] class AP 3: 0.603086
I0324 07:00:28.283926  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.508824
I0324 07:00:28.284315  1493 solver.cpp:265] [MultiGPU] Tests completed in 50.2662s
I0324 07:00:28.674978  1493 solver.cpp:314] Iteration 42000 (0.842761 iter/s, 118.658s/100 iter), loss = 3.03242
I0324 07:00:28.675034  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.54725 (* 1 = 3.54725 loss)
I0324 07:00:28.675048  1493 sgd_solver.cpp:136] Iteration 42000, lr = 0.0001, m = 0.9
I0324 07:01:37.345760  1493 solver.cpp:314] Iteration 42100 (1.45627 iter/s, 68.6685s/100 iter), loss = 3.04733
I0324 07:01:37.357802  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.17982 (* 1 = 3.17982 loss)
I0324 07:01:37.358191  1493 sgd_solver.cpp:136] Iteration 42100, lr = 0.0001, m = 0.9
I0324 07:02:44.809765  1493 solver.cpp:314] Iteration 42200 (1.48232 iter/s, 67.4618s/100 iter), loss = 3.19144
I0324 07:02:44.809875  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.85471 (* 1 = 2.85471 loss)
I0324 07:02:44.809895  1493 sgd_solver.cpp:136] Iteration 42200, lr = 0.0001, m = 0.9
I0324 07:03:53.429183  1493 solver.cpp:314] Iteration 42300 (1.45736 iter/s, 68.6172s/100 iter), loss = 3.14307
I0324 07:03:53.429285  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.1819 (* 1 = 3.1819 loss)
I0324 07:03:53.429301  1493 sgd_solver.cpp:136] Iteration 42300, lr = 0.0001, m = 0.9
I0324 07:05:02.114215  1493 solver.cpp:314] Iteration 42400 (1.45597 iter/s, 68.6828s/100 iter), loss = 3.04257
I0324 07:05:02.114322  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.55872 (* 1 = 3.55872 loss)
I0324 07:05:02.114339  1493 sgd_solver.cpp:136] Iteration 42400, lr = 0.0001, m = 0.9
I0324 07:06:10.153756  1493 solver.cpp:314] Iteration 42500 (1.46978 iter/s, 68.0373s/100 iter), loss = 3.14747
I0324 07:06:10.153864  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.19636 (* 1 = 3.19636 loss)
I0324 07:06:10.153883  1493 sgd_solver.cpp:136] Iteration 42500, lr = 0.0001, m = 0.9
I0324 07:07:18.160948  1493 solver.cpp:314] Iteration 42600 (1.47048 iter/s, 68.005s/100 iter), loss = 3.07537
I0324 07:07:18.161048  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.89271 (* 1 = 3.89271 loss)
I0324 07:07:18.161067  1493 sgd_solver.cpp:136] Iteration 42600, lr = 0.0001, m = 0.9
I0324 07:08:27.325760  1493 solver.cpp:314] Iteration 42700 (1.44587 iter/s, 69.1625s/100 iter), loss = 3.03557
I0324 07:08:27.325883  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.08161 (* 1 = 3.08161 loss)
I0324 07:08:27.325911  1493 sgd_solver.cpp:136] Iteration 42700, lr = 0.0001, m = 0.9
I0324 07:09:36.198614  1493 solver.cpp:314] Iteration 42800 (1.452 iter/s, 68.8706s/100 iter), loss = 3.12652
I0324 07:09:36.198715  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.58332 (* 1 = 2.58332 loss)
I0324 07:09:36.198731  1493 sgd_solver.cpp:136] Iteration 42800, lr = 0.0001, m = 0.9
I0324 07:10:43.046583  1493 solver.cpp:314] Iteration 42900 (1.49598 iter/s, 66.8458s/100 iter), loss = 3.15927
I0324 07:10:43.046686  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.56872 (* 1 = 3.56872 loss)
I0324 07:10:43.046705  1493 sgd_solver.cpp:136] Iteration 42900, lr = 0.0001, m = 0.9
I0324 07:11:51.254344  1493 solver.cpp:314] Iteration 43000 (1.46616 iter/s, 68.2055s/100 iter), loss = 3.17444
I0324 07:11:51.254451  1493 solver.cpp:336]     Train net output #0: mbox_loss = 1.9194 (* 1 = 1.9194 loss)
I0324 07:11:51.254501  1493 sgd_solver.cpp:136] Iteration 43000, lr = 0.0001, m = 0.9
I0324 07:12:59.041858  1493 solver.cpp:314] Iteration 43100 (1.47525 iter/s, 67.7853s/100 iter), loss = 3.14547
I0324 07:12:59.042013  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.13829 (* 1 = 4.13829 loss)
I0324 07:12:59.042033  1493 sgd_solver.cpp:136] Iteration 43100, lr = 0.0001, m = 0.9
I0324 07:14:08.468654  1493 solver.cpp:314] Iteration 43200 (1.44041 iter/s, 69.4245s/100 iter), loss = 3.21238
I0324 07:14:08.469185  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.62066 (* 1 = 2.62066 loss)
I0324 07:14:08.471381  1493 sgd_solver.cpp:136] Iteration 43200, lr = 0.0001, m = 0.9
I0324 07:15:17.422499  1493 solver.cpp:314] Iteration 43300 (1.45029 iter/s, 68.9516s/100 iter), loss = 3.04188
I0324 07:15:17.422703  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.27608 (* 1 = 2.27608 loss)
I0324 07:15:17.422746  1493 sgd_solver.cpp:136] Iteration 43300, lr = 0.0001, m = 0.9
I0324 07:16:25.646433  1493 solver.cpp:314] Iteration 43400 (1.46581 iter/s, 68.2217s/100 iter), loss = 3.07938
I0324 07:16:25.646719  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.18998 (* 1 = 3.18998 loss)
I0324 07:16:25.646764  1493 sgd_solver.cpp:136] Iteration 43400, lr = 0.0001, m = 0.9
I0324 07:17:34.599541  1493 solver.cpp:314] Iteration 43500 (1.45031 iter/s, 68.9509s/100 iter), loss = 3.36825
I0324 07:17:34.599635  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.15881 (* 1 = 3.15881 loss)
I0324 07:17:34.599651  1493 sgd_solver.cpp:136] Iteration 43500, lr = 0.0001, m = 0.9
I0324 07:18:42.184196  1493 solver.cpp:314] Iteration 43600 (1.47967 iter/s, 67.5824s/100 iter), loss = 3.33264
I0324 07:18:42.184298  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.606 (* 1 = 3.606 loss)
I0324 07:18:42.184310  1493 sgd_solver.cpp:136] Iteration 43600, lr = 0.0001, m = 0.9
I0324 07:19:50.697921  1493 solver.cpp:314] Iteration 43700 (1.45961 iter/s, 68.5115s/100 iter), loss = 3.13021
I0324 07:19:50.698088  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.03949 (* 1 = 3.03949 loss)
I0324 07:19:50.698134  1493 sgd_solver.cpp:136] Iteration 43700, lr = 0.0001, m = 0.9
I0324 07:21:00.272279  1493 solver.cpp:314] Iteration 43800 (1.43736 iter/s, 69.5721s/100 iter), loss = 3.29125
I0324 07:21:00.272380  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.13415 (* 1 = 3.13415 loss)
I0324 07:21:00.272397  1493 sgd_solver.cpp:136] Iteration 43800, lr = 0.0001, m = 0.9
I0324 07:22:08.697846  1493 solver.cpp:314] Iteration 43900 (1.46149 iter/s, 68.4233s/100 iter), loss = 3.1668
I0324 07:22:08.697959  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.67469 (* 1 = 3.67469 loss)
I0324 07:22:08.697978  1493 sgd_solver.cpp:136] Iteration 43900, lr = 0.0001, m = 0.9
I0324 07:23:16.902506  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_44000.caffemodel
I0324 07:23:16.973913  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_44000.solverstate
I0324 07:23:16.993432  1493 solver.cpp:678] Iteration 44000, Testing net (#0)
I0324 07:23:25.021747  1494 blocking_queue.cpp:40] Data layer prefetch queue empty
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.323504
j:  : 4 : max_pr:  : 0.507162
j:  : 3 : max_pr:  : 0.635208
j:  : 2 : max_pr:  : 0.765338
j:  : 1 : max_pr:  : 0.858696
j:  : 0 : max_pr:  : 1
I0324 07:24:06.091373  1494 solver.cpp:786] class AP 1: 0.37181
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.309723
j:  : 4 : max_pr:  : 0.495249
j:  : 3 : max_pr:  : 0.642849
j:  : 2 : max_pr:  : 0.761294
j:  : 1 : max_pr:  : 0.863333
j:  : 0 : max_pr:  : 1
I0324 07:24:06.116075  1493 solver.cpp:786] class AP 1: 0.370223
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.180469
j:  : 7 : max_pr:  : 0.405578
j:  : 6 : max_pr:  : 0.516895
j:  : 5 : max_pr:  : 0.592122
j:  : 4 : max_pr:  : 0.688538
j:  : 3 : max_pr:  : 0.797881
j:  : 2 : max_pr:  : 0.992424
j:  : 1 : max_pr:  : 1
j:  : 0 : max_pr:  : 1
I0324 07:24:06.142516  1494 solver.cpp:786] class AP 2: 0.561264
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.529029
j:  : 6 : max_pr:  : 0.656903
j:  : 5 : max_pr:  : 0.7474
j:  : 4 : max_pr:  : 0.857472
j:  : 3 : max_pr:  : 0.915317
j:  : 2 : max_pr:  : 0.965076
j:  : 1 : max_pr:  : 0.998076
j:  : 0 : max_pr:  : 1
I0324 07:24:06.153496  1494 solver.cpp:786] class AP 3: 0.606298
I0324 07:24:06.153522  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.513124
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.13076
j:  : 7 : max_pr:  : 0.385656
j:  : 6 : max_pr:  : 0.500908
j:  : 5 : max_pr:  : 0.585987
j:  : 4 : max_pr:  : 0.675577
j:  : 3 : max_pr:  : 0.784497
j:  : 2 : max_pr:  : 0.980989
j:  : 1 : max_pr:  : 0.994481
j:  : 0 : max_pr:  : 1
I0324 07:24:06.167196  1493 solver.cpp:786] class AP 2: 0.548987
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.507787
j:  : 6 : max_pr:  : 0.65539
j:  : 5 : max_pr:  : 0.7609
j:  : 4 : max_pr:  : 0.865935
j:  : 3 : max_pr:  : 0.915844
j:  : 2 : max_pr:  : 0.959838
j:  : 1 : max_pr:  : 0.998615
j:  : 0 : max_pr:  : 1
I0324 07:24:06.177507  1493 solver.cpp:786] class AP 3: 0.605846
I0324 07:24:06.177525  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.508352
I0324 07:24:06.177912  1493 solver.cpp:265] [MultiGPU] Tests completed in 49.1829s
I0324 07:24:06.637744  1493 solver.cpp:314] Iteration 44000 (0.847917 iter/s, 117.936s/100 iter), loss = 2.87876
I0324 07:24:06.637792  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.97773 (* 1 = 2.97773 loss)
I0324 07:24:06.637807  1493 sgd_solver.cpp:136] Iteration 44000, lr = 0.0001, m = 0.9
I0324 07:25:13.721985  1493 solver.cpp:314] Iteration 44100 (1.49071 iter/s, 67.082s/100 iter), loss = 3.03519
I0324 07:25:13.722128  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.91357 (* 1 = 2.91357 loss)
I0324 07:25:13.722146  1493 sgd_solver.cpp:136] Iteration 44100, lr = 0.0001, m = 0.9
I0324 07:26:21.807013  1493 solver.cpp:314] Iteration 44200 (1.4688 iter/s, 68.0828s/100 iter), loss = 3.04453
I0324 07:26:21.807114  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.72558 (* 1 = 2.72558 loss)
I0324 07:26:21.807130  1493 sgd_solver.cpp:136] Iteration 44200, lr = 0.0001, m = 0.9
I0324 07:27:29.474364  1493 solver.cpp:314] Iteration 44300 (1.47787 iter/s, 67.6651s/100 iter), loss = 3.03962
I0324 07:27:29.474539  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.16806 (* 1 = 3.16806 loss)
I0324 07:27:29.474557  1493 sgd_solver.cpp:136] Iteration 44300, lr = 0.0001, m = 0.9
I0324 07:28:37.776736  1493 solver.cpp:314] Iteration 44400 (1.46413 iter/s, 68.3001s/100 iter), loss = 3.2947
I0324 07:28:37.776933  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.47371 (* 1 = 2.47371 loss)
I0324 07:28:37.776976  1493 sgd_solver.cpp:136] Iteration 44400, lr = 0.0001, m = 0.9
I0324 07:29:35.134449  1462 data_reader.cpp:305] Starting prefetch of epoch 12
I0324 07:29:46.429221  1493 solver.cpp:314] Iteration 44500 (1.45666 iter/s, 68.6502s/100 iter), loss = 3.04056
I0324 07:29:46.429276  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.28047 (* 1 = 3.28047 loss)
I0324 07:29:46.429294  1493 sgd_solver.cpp:136] Iteration 44500, lr = 0.0001, m = 0.9
I0324 07:30:54.252179  1493 solver.cpp:314] Iteration 44600 (1.47448 iter/s, 67.8207s/100 iter), loss = 3.0794
I0324 07:30:54.252295  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.87731 (* 1 = 3.87731 loss)
I0324 07:30:54.252313  1493 sgd_solver.cpp:136] Iteration 44600, lr = 0.0001, m = 0.9
I0324 07:32:02.570093  1493 solver.cpp:314] Iteration 44700 (1.46379 iter/s, 68.3157s/100 iter), loss = 2.94132
I0324 07:32:02.570273  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.50639 (* 1 = 3.50639 loss)
I0324 07:32:02.570291  1493 sgd_solver.cpp:136] Iteration 44700, lr = 0.0001, m = 0.9
I0324 07:33:09.631613  1493 solver.cpp:314] Iteration 44800 (1.49122 iter/s, 67.0593s/100 iter), loss = 3.23547
I0324 07:33:09.631713  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.78171 (* 1 = 2.78171 loss)
I0324 07:33:09.631731  1493 sgd_solver.cpp:136] Iteration 44800, lr = 0.0001, m = 0.9
I0324 07:34:18.292480  1493 solver.cpp:314] Iteration 44900 (1.45648 iter/s, 68.6586s/100 iter), loss = 3.20796
I0324 07:34:18.292631  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.34022 (* 1 = 3.34022 loss)
I0324 07:34:18.292672  1493 sgd_solver.cpp:136] Iteration 44900, lr = 0.0001, m = 0.9
I0324 07:35:27.213379  1493 solver.cpp:314] Iteration 45000 (1.45099 iter/s, 68.9186s/100 iter), loss = 3.04834
I0324 07:35:27.213486  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.07171 (* 1 = 3.07171 loss)
I0324 07:35:27.213505  1493 sgd_solver.cpp:136] Iteration 45000, lr = 0.0001, m = 0.9
I0324 07:36:34.401302  1493 solver.cpp:314] Iteration 45100 (1.48841 iter/s, 67.1857s/100 iter), loss = 3.10929
I0324 07:36:34.401409  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.10011 (* 1 = 4.10011 loss)
I0324 07:36:34.401425  1493 sgd_solver.cpp:136] Iteration 45100, lr = 0.0001, m = 0.9
I0324 07:37:42.392565  1493 solver.cpp:314] Iteration 45200 (1.47083 iter/s, 67.989s/100 iter), loss = 2.9916
I0324 07:37:42.393033  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.09249 (* 1 = 3.09249 loss)
I0324 07:37:42.393354  1493 sgd_solver.cpp:136] Iteration 45200, lr = 0.0001, m = 0.9
I0324 07:38:50.156069  1493 solver.cpp:314] Iteration 45300 (1.47577 iter/s, 67.7613s/100 iter), loss = 3.05863
I0324 07:38:50.156204  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.19671 (* 1 = 3.19671 loss)
I0324 07:38:50.156220  1493 sgd_solver.cpp:136] Iteration 45300, lr = 0.0001, m = 0.9
I0324 07:39:58.985978  1493 solver.cpp:314] Iteration 45400 (1.4529 iter/s, 68.8277s/100 iter), loss = 3.29304
I0324 07:39:58.986135  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.98825 (* 1 = 2.98825 loss)
I0324 07:39:58.986153  1493 sgd_solver.cpp:136] Iteration 45400, lr = 0.0001, m = 0.9
I0324 07:41:07.751751  1493 solver.cpp:314] Iteration 45500 (1.45426 iter/s, 68.7635s/100 iter), loss = 3.13522
I0324 07:41:07.751860  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.35104 (* 1 = 4.35104 loss)
I0324 07:41:07.751878  1493 sgd_solver.cpp:136] Iteration 45500, lr = 0.0001, m = 0.9
I0324 07:42:15.678202  1493 solver.cpp:314] Iteration 45600 (1.47223 iter/s, 67.9242s/100 iter), loss = 3.0868
I0324 07:42:15.678292  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.47244 (* 1 = 3.47244 loss)
I0324 07:42:15.678309  1493 sgd_solver.cpp:136] Iteration 45600, lr = 0.0001, m = 0.9
I0324 07:43:24.641938  1493 solver.cpp:314] Iteration 45700 (1.45008 iter/s, 68.9615s/100 iter), loss = 3.13317
I0324 07:43:24.642052  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.62148 (* 1 = 3.62148 loss)
I0324 07:43:24.642069  1493 sgd_solver.cpp:136] Iteration 45700, lr = 0.0001, m = 0.9
I0324 07:44:33.018784  1493 solver.cpp:314] Iteration 45800 (1.46253 iter/s, 68.3746s/100 iter), loss = 2.87154
I0324 07:44:33.018872  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.90256 (* 1 = 2.90256 loss)
I0324 07:44:33.018885  1493 sgd_solver.cpp:136] Iteration 45800, lr = 0.0001, m = 0.9
I0324 07:45:42.010219  1493 solver.cpp:314] Iteration 45900 (1.4495 iter/s, 68.9892s/100 iter), loss = 3.13208
I0324 07:45:42.010313  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.5656 (* 1 = 3.5656 loss)
I0324 07:45:42.010330  1493 sgd_solver.cpp:136] Iteration 45900, lr = 0.0001, m = 0.9
I0324 07:46:49.378049  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_46000.caffemodel
I0324 07:46:49.427376  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_46000.solverstate
I0324 07:46:49.439302  1493 solver.cpp:678] Iteration 46000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.318496
j:  : 4 : max_pr:  : 0.510603
j:  : 3 : max_pr:  : 0.640019
j:  : 2 : max_pr:  : 0.765478
j:  : 1 : max_pr:  : 0.865629
j:  : 0 : max_pr:  : 1
I0324 07:47:40.523267  1494 solver.cpp:786] class AP 1: 0.372748
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.158434
j:  : 7 : max_pr:  : 0.399983
j:  : 6 : max_pr:  : 0.533002
j:  : 5 : max_pr:  : 0.608096
j:  : 4 : max_pr:  : 0.693701
j:  : 3 : max_pr:  : 0.79067
j:  : 2 : max_pr:  : 0.991058
j:  : 1 : max_pr:  : 0.998817
j:  : 0 : max_pr:  : 1
I0324 07:47:40.573727  1494 solver.cpp:786] class AP 2: 0.561251
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.511185
j:  : 6 : max_pr:  : 0.646059
j:  : 5 : max_pr:  : 0.746721
j:  : 4 : max_pr:  : 0.85699
j:  : 3 : max_pr:  : 0.909955
j:  : 2 : max_pr:  : 0.961631
j:  : 1 : max_pr:  : 0.999351
j:  : 0 : max_pr:  : 1
I0324 07:47:40.583670  1494 solver.cpp:786] class AP 3: 0.602899
I0324 07:47:40.583688  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.512299
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.299651
j:  : 4 : max_pr:  : 0.48777
j:  : 3 : max_pr:  : 0.632885
j:  : 2 : max_pr:  : 0.75789
j:  : 1 : max_pr:  : 0.857829
j:  : 0 : max_pr:  : 1
I0324 07:47:41.355732  1493 solver.cpp:786] class AP 1: 0.366911
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.102269
j:  : 7 : max_pr:  : 0.376892
j:  : 6 : max_pr:  : 0.51983
j:  : 5 : max_pr:  : 0.588519
j:  : 4 : max_pr:  : 0.667541
j:  : 3 : max_pr:  : 0.783505
j:  : 2 : max_pr:  : 0.979969
j:  : 1 : max_pr:  : 0.996223
j:  : 0 : max_pr:  : 1
I0324 07:47:41.405869  1493 solver.cpp:786] class AP 2: 0.546795
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.52116
j:  : 6 : max_pr:  : 0.654558
j:  : 5 : max_pr:  : 0.760921
j:  : 4 : max_pr:  : 0.867832
j:  : 3 : max_pr:  : 0.913359
j:  : 2 : max_pr:  : 0.95683
j:  : 1 : max_pr:  : 0.998029
j:  : 0 : max_pr:  : 1
I0324 07:47:41.415472  1493 solver.cpp:786] class AP 3: 0.606608
I0324 07:47:41.415488  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.506772
I0324 07:47:41.415808  1493 solver.cpp:265] [MultiGPU] Tests completed in 51.9748s
I0324 07:47:41.818620  1493 solver.cpp:314] Iteration 46000 (0.834693 iter/s, 119.804s/100 iter), loss = 3.18002
I0324 07:47:41.818672  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.473 (* 1 = 3.473 loss)
I0324 07:47:41.818688  1493 sgd_solver.cpp:136] Iteration 46000, lr = 0.0001, m = 0.9
I0324 07:48:50.328485  1493 solver.cpp:314] Iteration 46100 (1.45969 iter/s, 68.5076s/100 iter), loss = 3.36331
I0324 07:48:50.328640  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.37204 (* 1 = 2.37204 loss)
I0324 07:48:50.328663  1493 sgd_solver.cpp:136] Iteration 46100, lr = 0.0001, m = 0.9
I0324 07:50:00.038676  1493 solver.cpp:314] Iteration 46200 (1.43456 iter/s, 69.7079s/100 iter), loss = 3.17479
I0324 07:50:00.038774  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.17881 (* 1 = 3.17881 loss)
I0324 07:50:00.038790  1493 sgd_solver.cpp:136] Iteration 46200, lr = 0.0001, m = 0.9
I0324 07:51:08.659468  1493 solver.cpp:314] Iteration 46300 (1.45733 iter/s, 68.6185s/100 iter), loss = 3.12083
I0324 07:51:08.659602  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.88121 (* 1 = 2.88121 loss)
I0324 07:51:08.659621  1493 sgd_solver.cpp:136] Iteration 46300, lr = 0.0001, m = 0.9
I0324 07:52:17.232301  1493 solver.cpp:314] Iteration 46400 (1.45835 iter/s, 68.5706s/100 iter), loss = 2.9281
I0324 07:52:17.232379  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.83569 (* 1 = 2.83569 loss)
I0324 07:52:17.232396  1493 sgd_solver.cpp:136] Iteration 46400, lr = 0.0001, m = 0.9
I0324 07:53:24.369060  1493 solver.cpp:314] Iteration 46500 (1.48955 iter/s, 67.1346s/100 iter), loss = 3.04655
I0324 07:53:24.369159  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.12292 (* 1 = 4.12292 loss)
I0324 07:53:24.369175  1493 sgd_solver.cpp:136] Iteration 46500, lr = 0.0001, m = 0.9
I0324 07:54:33.791268  1493 solver.cpp:314] Iteration 46600 (1.44051 iter/s, 69.4199s/100 iter), loss = 3.48185
I0324 07:54:33.791363  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.89147 (* 1 = 3.89147 loss)
I0324 07:54:33.791378  1493 sgd_solver.cpp:136] Iteration 46600, lr = 0.0001, m = 0.9
I0324 07:55:42.009618  1493 solver.cpp:314] Iteration 46700 (1.46593 iter/s, 68.2161s/100 iter), loss = 2.95552
I0324 07:55:42.009727  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.30125 (* 1 = 3.30125 loss)
I0324 07:55:42.009743  1493 sgd_solver.cpp:136] Iteration 46700, lr = 0.0001, m = 0.9
I0324 07:56:50.739230  1493 solver.cpp:314] Iteration 46800 (1.45502 iter/s, 68.7274s/100 iter), loss = 3.06636
I0324 07:56:50.739329  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.78629 (* 1 = 2.78629 loss)
I0324 07:56:50.739346  1493 sgd_solver.cpp:136] Iteration 46800, lr = 0.0001, m = 0.9
I0324 07:57:58.850126  1493 solver.cpp:314] Iteration 46900 (1.46824 iter/s, 68.1087s/100 iter), loss = 3.17339
I0324 07:57:58.861762  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.81028 (* 1 = 2.81028 loss)
I0324 07:57:58.861793  1493 sgd_solver.cpp:136] Iteration 46900, lr = 0.0001, m = 0.9
I0324 07:59:06.926781  1493 solver.cpp:314] Iteration 47000 (1.46898 iter/s, 68.0744s/100 iter), loss = 3.07419
I0324 07:59:06.926870  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.60293 (* 1 = 3.60293 loss)
I0324 07:59:06.926887  1493 sgd_solver.cpp:136] Iteration 47000, lr = 0.0001, m = 0.9
I0324 08:00:15.171891  1493 solver.cpp:314] Iteration 47100 (1.46535 iter/s, 68.2429s/100 iter), loss = 3.25982
I0324 08:00:15.171980  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.13503 (* 1 = 3.13503 loss)
I0324 08:00:15.171998  1493 sgd_solver.cpp:136] Iteration 47100, lr = 0.0001, m = 0.9
I0324 08:01:23.476588  1493 solver.cpp:314] Iteration 47200 (1.46408 iter/s, 68.3025s/100 iter), loss = 2.98622
I0324 08:01:23.477038  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.79857 (* 1 = 2.79857 loss)
I0324 08:01:23.477337  1493 sgd_solver.cpp:136] Iteration 47200, lr = 0.0001, m = 0.9
I0324 08:02:32.167660  1493 solver.cpp:314] Iteration 47300 (1.45584 iter/s, 68.6888s/100 iter), loss = 3.03302
I0324 08:02:32.167763  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.97592 (* 1 = 2.97592 loss)
I0324 08:02:32.167780  1493 sgd_solver.cpp:136] Iteration 47300, lr = 0.0001, m = 0.9
I0324 08:03:40.843776  1493 solver.cpp:314] Iteration 47400 (1.45616 iter/s, 68.6739s/100 iter), loss = 3.20969
I0324 08:03:40.843880  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.0404 (* 1 = 3.0404 loss)
I0324 08:03:40.843895  1493 sgd_solver.cpp:136] Iteration 47400, lr = 0.0001, m = 0.9
I0324 08:04:49.813959  1493 solver.cpp:314] Iteration 47500 (1.44995 iter/s, 68.9679s/100 iter), loss = 3.19008
I0324 08:04:49.814065  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.83467 (* 1 = 3.83467 loss)
I0324 08:04:49.814085  1493 sgd_solver.cpp:136] Iteration 47500, lr = 0.0001, m = 0.9
I0324 08:06:07.845269  1493 solver.cpp:314] Iteration 47600 (1.28158 iter/s, 78.0288s/100 iter), loss = 3.1701
I0324 08:06:07.845417  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.43291 (* 1 = 3.43291 loss)
I0324 08:06:07.845437  1493 sgd_solver.cpp:136] Iteration 47600, lr = 0.0001, m = 0.9
I0324 08:06:18.440486  1462 data_reader.cpp:305] Starting prefetch of epoch 13
I0324 08:07:19.009405  1493 solver.cpp:314] Iteration 47700 (1.40525 iter/s, 71.1618s/100 iter), loss = 2.96089
I0324 08:07:19.009599  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.96258 (* 1 = 2.96258 loss)
I0324 08:07:19.009616  1493 sgd_solver.cpp:136] Iteration 47700, lr = 0.0001, m = 0.9
I0324 08:08:28.652622  1493 solver.cpp:314] Iteration 47800 (1.43594 iter/s, 69.641s/100 iter), loss = 3.00437
I0324 08:08:28.652722  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.82456 (* 1 = 2.82456 loss)
I0324 08:08:28.652740  1493 sgd_solver.cpp:136] Iteration 47800, lr = 0.0001, m = 0.9
I0324 08:09:37.009982  1493 solver.cpp:314] Iteration 47900 (1.46295 iter/s, 68.3551s/100 iter), loss = 3.08069
I0324 08:09:37.010143  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.44851 (* 1 = 3.44851 loss)
I0324 08:09:37.010175  1493 sgd_solver.cpp:136] Iteration 47900, lr = 0.0001, m = 0.9
I0324 08:10:45.285873  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_48000.caffemodel
I0324 08:10:45.337837  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_48000.solverstate
I0324 08:10:45.353183  1493 solver.cpp:678] Iteration 48000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.319582
j:  : 4 : max_pr:  : 0.508569
j:  : 3 : max_pr:  : 0.639059
j:  : 2 : max_pr:  : 0.75887
j:  : 1 : max_pr:  : 0.865917
j:  : 0 : max_pr:  : 1
I0324 08:11:36.528122  1494 solver.cpp:786] class AP 1: 0.372
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.147016
j:  : 7 : max_pr:  : 0.390298
j:  : 6 : max_pr:  : 0.506851
j:  : 5 : max_pr:  : 0.584337
j:  : 4 : max_pr:  : 0.671672
j:  : 3 : max_pr:  : 0.789705
j:  : 2 : max_pr:  : 0.988798
j:  : 1 : max_pr:  : 0.996725
j:  : 0 : max_pr:  : 1
I0324 08:11:36.601222  1494 solver.cpp:786] class AP 2: 0.552309
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.518559
j:  : 6 : max_pr:  : 0.652951
j:  : 5 : max_pr:  : 0.755558
j:  : 4 : max_pr:  : 0.861473
j:  : 3 : max_pr:  : 0.913532
j:  : 2 : max_pr:  : 0.963847
j:  : 1 : max_pr:  : 0.998648
j:  : 0 : max_pr:  : 1
I0324 08:11:36.614987  1494 solver.cpp:786] class AP 3: 0.60587
I0324 08:11:36.615008  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.51006
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.303622
j:  : 4 : max_pr:  : 0.47742
j:  : 3 : max_pr:  : 0.627168
j:  : 2 : max_pr:  : 0.755767
j:  : 1 : max_pr:  : 0.848715
j:  : 0 : max_pr:  : 1
I0324 08:11:36.767804  1493 solver.cpp:786] class AP 1: 0.36479
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.141884
j:  : 7 : max_pr:  : 0.399067
j:  : 6 : max_pr:  : 0.518634
j:  : 5 : max_pr:  : 0.607109
j:  : 4 : max_pr:  : 0.681587
j:  : 3 : max_pr:  : 0.798492
j:  : 2 : max_pr:  : 0.989875
j:  : 1 : max_pr:  : 0.998152
j:  : 0 : max_pr:  : 1
I0324 08:11:36.815198  1493 solver.cpp:786] class AP 2: 0.557709
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.520393
j:  : 6 : max_pr:  : 0.655156
j:  : 5 : max_pr:  : 0.749734
j:  : 4 : max_pr:  : 0.858775
j:  : 3 : max_pr:  : 0.913053
j:  : 2 : max_pr:  : 0.955917
j:  : 1 : max_pr:  : 0.998
j:  : 0 : max_pr:  : 1
I0324 08:11:36.825574  1493 solver.cpp:786] class AP 3: 0.604639
I0324 08:11:36.825588  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.509046
I0324 08:11:36.826038  1493 solver.cpp:265] [MultiGPU] Tests completed in 51.4712s
I0324 08:11:37.303663  1493 solver.cpp:314] Iteration 48000 (0.831326 iter/s, 120.29s/100 iter), loss = 3.05037
I0324 08:11:37.303714  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.61017 (* 1 = 4.61017 loss)
I0324 08:11:37.303728  1493 sgd_solver.cpp:136] Iteration 48000, lr = 0.0001, m = 0.9
I0324 08:12:45.937726  1493 solver.cpp:314] Iteration 48100 (1.45705 iter/s, 68.6318s/100 iter), loss = 3.2158
I0324 08:12:45.937826  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.42711 (* 1 = 4.42711 loss)
I0324 08:12:45.937844  1493 sgd_solver.cpp:136] Iteration 48100, lr = 0.0001, m = 0.9
I0324 08:13:55.932718  1493 solver.cpp:314] Iteration 48200 (1.42872 iter/s, 69.9927s/100 iter), loss = 3.1085
I0324 08:13:55.932832  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.90847 (* 1 = 2.90847 loss)
I0324 08:13:55.932849  1493 sgd_solver.cpp:136] Iteration 48200, lr = 0.0001, m = 0.9
I0324 08:15:05.714157  1493 solver.cpp:314] Iteration 48300 (1.43309 iter/s, 69.7792s/100 iter), loss = 2.96223
I0324 08:15:05.714648  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.47242 (* 1 = 2.47242 loss)
I0324 08:15:05.714965  1493 sgd_solver.cpp:136] Iteration 48300, lr = 0.0001, m = 0.9
I0324 08:16:15.229903  1493 solver.cpp:314] Iteration 48400 (1.43857 iter/s, 69.5135s/100 iter), loss = 3.02779
I0324 08:16:15.230000  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.88536 (* 1 = 2.88536 loss)
I0324 08:16:15.230015  1493 sgd_solver.cpp:136] Iteration 48400, lr = 0.0001, m = 0.9
I0324 08:17:24.878267  1493 solver.cpp:314] Iteration 48500 (1.43583 iter/s, 69.6461s/100 iter), loss = 3.04692
I0324 08:17:24.878449  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.6819 (* 1 = 3.6819 loss)
I0324 08:17:24.878468  1493 sgd_solver.cpp:136] Iteration 48500, lr = 0.0001, m = 0.9
I0324 08:18:33.962224  1493 solver.cpp:314] Iteration 48600 (1.44756 iter/s, 69.0817s/100 iter), loss = 3.19699
I0324 08:18:33.962337  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.55413 (* 1 = 2.55413 loss)
I0324 08:18:33.962352  1493 sgd_solver.cpp:136] Iteration 48600, lr = 0.0001, m = 0.9
I0324 08:19:42.437485  1493 solver.cpp:314] Iteration 48700 (1.46043 iter/s, 68.473s/100 iter), loss = 3.03198
I0324 08:19:42.439985  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.3487 (* 1 = 3.3487 loss)
I0324 08:19:42.440022  1493 sgd_solver.cpp:136] Iteration 48700, lr = 0.0001, m = 0.9
I0324 08:20:51.397435  1493 solver.cpp:314] Iteration 48800 (1.45016 iter/s, 68.9577s/100 iter), loss = 3.16773
I0324 08:20:51.397606  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.93014 (* 1 = 2.93014 loss)
I0324 08:20:51.397650  1493 sgd_solver.cpp:136] Iteration 48800, lr = 0.0001, m = 0.9
I0324 08:22:00.320960  1493 solver.cpp:314] Iteration 48900 (1.45093 iter/s, 68.9213s/100 iter), loss = 2.95943
I0324 08:22:00.321063  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.15924 (* 1 = 3.15924 loss)
I0324 08:22:00.321113  1493 sgd_solver.cpp:136] Iteration 48900, lr = 0.0001, m = 0.9
I0324 08:23:09.153996  1493 solver.cpp:314] Iteration 49000 (1.45284 iter/s, 68.8308s/100 iter), loss = 3.01083
I0324 08:23:09.154206  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.00913 (* 1 = 3.00913 loss)
I0324 08:23:09.154250  1493 sgd_solver.cpp:136] Iteration 49000, lr = 0.0001, m = 0.9
I0324 08:24:18.587268  1493 solver.cpp:314] Iteration 49100 (1.44028 iter/s, 69.431s/100 iter), loss = 2.92082
I0324 08:24:18.587440  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.49399 (* 1 = 2.49399 loss)
I0324 08:24:18.587458  1493 sgd_solver.cpp:136] Iteration 49100, lr = 0.0001, m = 0.9
I0324 08:25:27.421752  1493 solver.cpp:314] Iteration 49200 (1.45281 iter/s, 68.8322s/100 iter), loss = 2.91
I0324 08:25:27.421857  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.91904 (* 1 = 2.91904 loss)
I0324 08:25:27.421875  1493 sgd_solver.cpp:136] Iteration 49200, lr = 0.0001, m = 0.9
I0324 08:26:37.659121  1493 solver.cpp:314] Iteration 49300 (1.42379 iter/s, 70.2351s/100 iter), loss = 2.94176
I0324 08:26:37.659212  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.14731 (* 1 = 3.14731 loss)
I0324 08:26:37.659229  1493 sgd_solver.cpp:136] Iteration 49300, lr = 0.0001, m = 0.9
I0324 08:27:45.442374  1493 solver.cpp:314] Iteration 49400 (1.47534 iter/s, 67.781s/100 iter), loss = 3.1537
I0324 08:27:45.444113  1493 solver.cpp:336]     Train net output #0: mbox_loss = 2.56675 (* 1 = 2.56675 loss)
I0324 08:27:45.444145  1493 sgd_solver.cpp:136] Iteration 49400, lr = 0.0001, m = 0.9
I0324 08:28:53.792826  1493 solver.cpp:314] Iteration 49500 (1.4631 iter/s, 68.3482s/100 iter), loss = 3.19355
I0324 08:28:53.793004  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.55939 (* 1 = 3.55939 loss)
I0324 08:28:53.793020  1493 sgd_solver.cpp:136] Iteration 49500, lr = 0.0001, m = 0.9
I0324 08:30:02.876988  1493 solver.cpp:314] Iteration 49600 (1.44756 iter/s, 69.0819s/100 iter), loss = 3.12519
I0324 08:30:02.877101  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.39449 (* 1 = 3.39449 loss)
I0324 08:30:02.877120  1493 sgd_solver.cpp:136] Iteration 49600, lr = 0.0001, m = 0.9
I0324 08:31:12.009752  1493 solver.cpp:314] Iteration 49700 (1.44654 iter/s, 69.1305s/100 iter), loss = 3.39141
I0324 08:31:12.009920  1493 solver.cpp:336]     Train net output #0: mbox_loss = 4.81698 (* 1 = 4.81698 loss)
I0324 08:31:12.009966  1493 sgd_solver.cpp:136] Iteration 49700, lr = 0.0001, m = 0.9
I0324 08:32:21.401818  1493 solver.cpp:314] Iteration 49800 (1.44113 iter/s, 69.3898s/100 iter), loss = 3.09816
I0324 08:32:21.409768  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.29372 (* 1 = 3.29372 loss)
I0324 08:32:21.409796  1493 sgd_solver.cpp:136] Iteration 49800, lr = 0.0001, m = 0.9
I0324 08:33:29.666260  1493 solver.cpp:314] Iteration 49900 (1.46494 iter/s, 68.2622s/100 iter), loss = 2.93668
I0324 08:33:29.666352  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.3391 (* 1 = 3.3391 loss)
I0324 08:33:29.666368  1493 sgd_solver.cpp:136] Iteration 49900, lr = 0.0001, m = 0.9
I0324 08:34:37.389823  1493 solver.cpp:314] Iteration 49999 (1.46187 iter/s, 67.7213s/99 iter), loss = 3.0404
I0324 08:34:37.389987  1493 solver.cpp:336]     Train net output #0: mbox_loss = 3.23989 (* 1 = 3.23989 loss)
I0324 08:34:37.390035  1493 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_50000.caffemodel
I0324 08:34:37.438530  1493 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_50000.solverstate
I0324 08:34:37.773929  1493 solver.cpp:549] Iteration 50000, loss = 3.02993
I0324 08:34:37.785235  1493 solver.cpp:678] Iteration 50000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.309383
j:  : 4 : max_pr:  : 0.498191
j:  : 3 : max_pr:  : 0.638325
j:  : 2 : max_pr:  : 0.757312
j:  : 1 : max_pr:  : 0.867882
j:  : 0 : max_pr:  : 1
I0324 08:35:26.327373  1494 solver.cpp:786] class AP 1: 0.370099
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.101165
j:  : 7 : max_pr:  : 0.357718
j:  : 6 : max_pr:  : 0.499299
j:  : 5 : max_pr:  : 0.579162
j:  : 4 : max_pr:  : 0.655536
j:  : 3 : max_pr:  : 0.779148
j:  : 2 : max_pr:  : 0.984985
j:  : 1 : max_pr:  : 0.99645
j:  : 0 : max_pr:  : 1
I0324 08:35:26.376336  1494 solver.cpp:786] class AP 2: 0.541224
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.500856
j:  : 6 : max_pr:  : 0.649505
j:  : 5 : max_pr:  : 0.759966
j:  : 4 : max_pr:  : 0.86626
j:  : 3 : max_pr:  : 0.9174
j:  : 2 : max_pr:  : 0.962475
j:  : 1 : max_pr:  : 0.998629
j:  : 0 : max_pr:  : 1
I0324 08:35:26.387223  1494 solver.cpp:786] class AP 3: 0.605008
I0324 08:35:26.387264  1494 solver.cpp:792] Test net output mAP #0: detection_eval = 0.505444
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.311504
j:  : 4 : max_pr:  : 0.493892
j:  : 3 : max_pr:  : 0.632183
j:  : 2 : max_pr:  : 0.760355
j:  : 1 : max_pr:  : 0.847928
j:  : 0 : max_pr:  : 1
I0324 08:35:27.543148  1493 solver.cpp:786] class AP 1: 0.367806
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.120761
j:  : 7 : max_pr:  : 0.373173
j:  : 6 : max_pr:  : 0.505518
j:  : 5 : max_pr:  : 0.589305
j:  : 4 : max_pr:  : 0.672946
j:  : 3 : max_pr:  : 0.787556
j:  : 2 : max_pr:  : 0.982429
j:  : 1 : max_pr:  : 0.998133
j:  : 0 : max_pr:  : 1
I0324 08:35:27.590461  1493 solver.cpp:786] class AP 2: 0.548166
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.530129
j:  : 6 : max_pr:  : 0.65901
j:  : 5 : max_pr:  : 0.755811
j:  : 4 : max_pr:  : 0.860656
j:  : 3 : max_pr:  : 0.914786
j:  : 2 : max_pr:  : 0.959427
j:  : 1 : max_pr:  : 0.998663
j:  : 0 : max_pr:  : 1
I0324 08:35:27.600972  1493 solver.cpp:786] class AP 3: 0.607135
I0324 08:35:27.600997  1493 solver.cpp:792] Test net output mAP #0: detection_eval = 0.507702
I0324 08:35:27.626009  1439 parallel.cpp:71] Root Solver performance on device 0: 1.425 * 8 = 11.4 img/sec (50000 itr in 3.51e+04 sec)
I0324 08:35:27.626051  1439 parallel.cpp:76]      Solver performance on device 1: 1.425 * 8 = 11.4 img/sec (50000 itr in 3.51e+04 sec)
I0324 08:35:27.626061  1439 parallel.cpp:79] Overall multi-GPU performance: 22.7925 img/sec
I0324 08:35:28.166178  1439 caffe.cpp:253] Optimization Done in 9h 46m 53s
I0324 08:35:32.943548 10003 caffe.cpp:807] This is NVCaffe 0.16.4 started at Sat Mar 24 08:35:31 2018
I0324 08:35:32.944912 10003 caffe.cpp:810] CuDNN version: 6021
I0324 08:35:32.944921 10003 caffe.cpp:811] CuBLAS version: 8000
I0324 08:35:32.944926 10003 caffe.cpp:812] CUDA version: 8000
I0324 08:35:32.944929 10003 caffe.cpp:813] CUDA driver version: 8000
I0324 08:35:33.259367 10003 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0324 08:35:33.260023 10003 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8287879168, dev_info[0]: total=8506769408 free=8287879168
I0324 08:35:33.260593 10003 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8287879168, dev_info[1]: total=8508145664 free=8379236352
I0324 08:35:33.260610 10003 caffe.cpp:214] Using GPUs 0, 1
I0324 08:35:33.260933 10003 caffe.cpp:219] GPU 0: GeForce GTX 1080
I0324 08:35:33.261253 10003 caffe.cpp:219] GPU 1: GeForce GTX 1080
I0324 08:35:33.261304 10003 solver.cpp:43] Solver data type: FLOAT
I0324 08:35:33.261399 10003 solver.cpp:46] Initializing solver from parameters: 
train_net: "training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/l1reg/train.prototxt"
test_net: "training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/l1reg/test.prototxt"
test_iter: 452
test_interval: 2000
base_lr: 0.001
display: 100
max_iter: 60000
lr_policy: "multistep"
gamma: 0.1
power: 1
momentum: 0.9
weight_decay: 1e-05
snapshot: 2000
snapshot_prefix: "training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
snapshot_after_train: true
regularization_type: "L1"
test_initialization: true
average_loss: 10
stepvalue: 30000
stepvalue: 45000
stepvalue: 300000
iter_size: 2
type: "SGD"
eval_type: "detection"
ap_version: "11point"
show_per_class_result: true
I0324 08:35:33.312932 10003 solver.cpp:78] Creating training net from train_net file: training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/l1reg/train.prototxt
I0324 08:35:33.321439 10003 net.cpp:72] Initializing net from parameters: 
name: "ssdJacintoNetV2"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 0
    mean_value: 0
    mean_value: 0
    force_color: false
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 320
      width: 768
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: NEAREST
      interp_mode: CUBIC
      interp_mode: LANCZOS4
    }
    emit_constraint {
      emit_type: CENTER
    }
    crop_h: 320
    crop_w: 768
    distort_param {
      brightness_prob: 0.5
      brightness_delta: 32
      contrast_prob: 0.5
      contrast_lower: 0.5
      contrast_upper: 1.5
      hue_prob: 0.5
      hue_delta: 18
      saturation_prob: 0.5
      saturation_lower: 0.5
      saturation_upper: 1.5
      random_order_prob: 0
    }
    expand_param {
      prob: 0.5
      max_expand_ratio: 4
    }
  }
  data_param {
    source: "/user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb"
    batch_size: 8
    backend: LMDB
    threads: 4
    parser_threads: 4
  }
  annotated_data_param {
    batch_sampler {
      max_sample: 1
      max_trials: 1
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.1
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.3
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.5
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.7
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.9
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        max_jaccard_overlap: 1
      }
      max_sample: 1
      max_trials: 50
    }
    label_map_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/labelmap.prototxt"
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "pool6"
  top: "pool7"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool8"
  type: "Pooling"
  bottom: "pool7"
  top: "pool8"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool9"
  type: "Pooling"
  bottom: "pool8"
  top: "pool9"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "ctx_output1"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "ctx_output1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu"
  type: "ReLU"
  bottom: "ctx_output1"
  top: "ctx_output1"
}
layer {
  name: "ctx_output2"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "ctx_output2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu"
  type: "ReLU"
  bottom: "ctx_output2"
  top: "ctx_output2"
}
layer {
  name: "ctx_output3"
  type: "Convolution"
  bottom: "pool6"
  top: "ctx_output3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu"
  type: "ReLU"
  bottom: "ctx_output3"
  top: "ctx_output3"
}
layer {
  name: "ctx_output4"
  type: "Convolution"
  bottom: "pool7"
  top: "ctx_output4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu"
  type: "ReLU"
  bottom: "ctx_output4"
  top: "ctx_output4"
}
layer {
  name: "ctx_output5"
  type: "Convolution"
  bottom: "pool8"
  top: "ctx_output5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu"
  type: "ReLU"
  bottom: "ctx_output5"
  top: "ctx_output5"
}
layer {
  name: "ctx_output6"
  type: "Convolution"
  bottom: "pool9"
  top: "ctx_output6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu"
  type: "ReLU"
  bottom: "ctx_output6"
  top: "ctx_output6"
}
layer {
  name: "ctx_output1/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_loc"
  top: "ctx_output1/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_loc_perm"
  top: "ctx_output1/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_conf"
  top: "ctx_output1/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_conf_perm"
  top: "ctx_output1/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output1"
  bottom: "data"
  top: "ctx_output1/relu_mbox_priorbox"
  prior_box_param {
    min_size: 12.8
    max_size: 32
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_loc"
  top: "ctx_output2/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_loc_perm"
  top: "ctx_output2/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_conf"
  top: "ctx_output2/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_conf_perm"
  top: "ctx_output2/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output2"
  bottom: "data"
  top: "ctx_output2/relu_mbox_priorbox"
  prior_box_param {
    min_size: 32
    max_size: 96
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_loc"
  top: "ctx_output3/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_loc_perm"
  top: "ctx_output3/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_conf"
  top: "ctx_output3/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_conf_perm"
  top: "ctx_output3/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output3"
  bottom: "data"
  top: "ctx_output3/relu_mbox_priorbox"
  prior_box_param {
    min_size: 96
    max_size: 160
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_loc"
  top: "ctx_output4/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_loc_perm"
  top: "ctx_output4/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_conf"
  top: "ctx_output4/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_conf_perm"
  top: "ctx_output4/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output4"
  bottom: "data"
  top: "ctx_output4/relu_mbox_priorbox"
  prior_box_param {
    min_size: 160
    max_size: 224
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_loc"
  top: "ctx_output5/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_loc_perm"
  top: "ctx_output5/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_conf"
  top: "ctx_output5/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_conf_perm"
  top: "ctx_output5/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output5"
  bottom: "data"
  top: "ctx_output5/relu_mbox_priorbox"
  prior_box_param {
    min_size: 224
    max_size: 288
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_loc"
  top: "ctx_output6/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_loc_perm"
  top: "ctx_output6/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_conf"
  top: "ctx_output6/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_conf_perm"
  top: "ctx_output6/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output6"
  bottom: "data"
  top: "ctx_output6/relu_mbox_priorbox"
  prior_box_param {
    min_size: 288
    max_size: 352
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_loc_flat"
  bottom: "ctx_output2/relu_mbox_loc_flat"
  bottom: "ctx_output3/relu_mbox_loc_flat"
  bottom: "ctx_output4/relu_mbox_loc_flat"
  bottom: "ctx_output5/relu_mbox_loc_flat"
  bottom: "ctx_output6/relu_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_conf_flat"
  bottom: "ctx_output2/relu_mbox_conf_flat"
  bottom: "ctx_output3/relu_mbox_conf_flat"
  bottom: "ctx_output4/relu_mbox_conf_flat"
  bottom: "ctx_output5/relu_mbox_conf_flat"
  bottom: "ctx_output6/relu_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_priorbox"
  bottom: "ctx_output2/relu_mbox_priorbox"
  bottom: "ctx_output3/relu_mbox_priorbox"
  bottom: "ctx_output4/relu_mbox_priorbox"
  bottom: "ctx_output5/relu_mbox_priorbox"
  bottom: "ctx_output6/relu_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_loss"
  type: "MultiBoxLoss"
  bottom: "mbox_loc"
  bottom: "mbox_conf"
  bottom: "mbox_priorbox"
  bottom: "label"
  top: "mbox_loss"
  include {
    phase: TRAIN
  }
  propagate_down: true
  propagate_down: true
  propagate_down: false
  propagate_down: false
  loss_param {
    normalization: VALID
  }
  multibox_loss_param {
    loc_loss_type: SMOOTH_L1
    conf_loss_type: SOFTMAX
    loc_weight: 1
    num_classes: 4
    share_location: true
    match_type: PER_PREDICTION
    overlap_threshold: 0.5
    use_prior_for_matching: true
    background_label_id: 0
    use_difficult_gt: false
    neg_pos_ratio: 3
    neg_overlap: 0.5
    code_type: CENTER_SIZE
    ignore_cross_boundary_bbox: false
    mining_type: MAX_NEGATIVE
    ignore_difficult_gt: false
  }
}
I0324 08:35:33.322008 10003 net.cpp:104] Using FLOAT as default forward math type
I0324 08:35:33.322022 10003 net.cpp:110] Using FLOAT as default backward math type
I0324 08:35:33.322059 10003 layer_factory.hpp:136] Creating layer 'data' of type 'AnnotatedData'
I0324 08:35:33.322073 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:33.328838 10003 net.cpp:184] Created Layer data (0)
I0324 08:35:33.328856 10003 net.cpp:530] data -> data
I0324 08:35:33.328878 10003 net.cpp:530] data -> label
I0324 08:35:33.334724 10003 data_reader.cpp:58] Data Reader threads: 4, out queues: 16, depth: 8
I0324 08:35:33.334825 10003 internal_thread.cpp:19] Starting 4 internal thread(s) on device 0
I0324 08:35:33.351140 10056 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0324 08:35:33.351191 10055 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0324 08:35:33.351245 10054 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0324 08:35:33.351253 10057 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0324 08:35:33.365085 10003 annotated_data_layer.cpp:219] output data size: 8,3,320,768
I0324 08:35:33.365437 10003 annotated_data_layer.cpp:265] [0] Output data size: 8, 3, 320, 768
I0324 08:35:33.365500 10003 internal_thread.cpp:19] Starting 4 internal thread(s) on device 0
I0324 08:35:33.365605 10003 net.cpp:245] Setting up data
I0324 08:35:33.365633 10003 net.cpp:252] TRAIN Top shape for layer 0 'data' 8 3 320 768 (5898240)
I0324 08:35:33.365656 10003 net.cpp:252] TRAIN Top shape for layer 0 'data' 1 1 10 8 (80)
I0324 08:35:33.365679 10003 layer_factory.hpp:136] Creating layer 'data_data_0_split' of type 'Split'
I0324 08:35:33.365706 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:33.365736 10003 net.cpp:184] Created Layer data_data_0_split (1)
I0324 08:35:33.365754 10003 net.cpp:561] data_data_0_split <- data
I0324 08:35:33.365778 10003 net.cpp:530] data_data_0_split -> data_data_0_split_0
I0324 08:35:33.365802 10003 net.cpp:530] data_data_0_split -> data_data_0_split_1
I0324 08:35:33.365819 10003 net.cpp:530] data_data_0_split -> data_data_0_split_2
I0324 08:35:33.365837 10003 net.cpp:530] data_data_0_split -> data_data_0_split_3
I0324 08:35:33.365854 10003 net.cpp:530] data_data_0_split -> data_data_0_split_4
I0324 08:35:33.365870 10003 net.cpp:530] data_data_0_split -> data_data_0_split_5
I0324 08:35:33.365886 10003 net.cpp:530] data_data_0_split -> data_data_0_split_6
I0324 08:35:33.366039 10003 net.cpp:245] Setting up data_data_0_split
I0324 08:35:33.366056 10003 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0324 08:35:33.366071 10003 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0324 08:35:33.366087 10003 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0324 08:35:33.366103 10003 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0324 08:35:33.366118 10003 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0324 08:35:33.366133 10003 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0324 08:35:33.366149 10003 net.cpp:252] TRAIN Top shape for layer 1 'data_data_0_split' 8 3 320 768 (5898240)
I0324 08:35:33.366163 10003 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0324 08:35:33.366176 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:33.366204 10003 net.cpp:184] Created Layer data/bias (2)
I0324 08:35:33.366216 10003 net.cpp:561] data/bias <- data_data_0_split_0
I0324 08:35:33.366230 10003 net.cpp:530] data/bias -> data/bias
I0324 08:35:33.381556 10003 net.cpp:245] Setting up data/bias
I0324 08:35:33.381579 10003 net.cpp:252] TRAIN Top shape for layer 2 'data/bias' 8 3 320 768 (5898240)
I0324 08:35:33.381603 10003 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0324 08:35:33.381610 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:33.381651 10003 net.cpp:184] Created Layer conv1a (3)
I0324 08:35:33.381669 10003 net.cpp:561] conv1a <- data/bias
I0324 08:35:33.381682 10003 net.cpp:530] conv1a -> conv1a
I0324 08:35:34.543619 10003 net.cpp:245] Setting up conv1a
I0324 08:35:34.543654 10003 net.cpp:252] TRAIN Top shape for layer 3 'conv1a' 8 32 160 384 (15728640)
I0324 08:35:34.543674 10003 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0324 08:35:34.543682 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.543709 10003 net.cpp:184] Created Layer conv1a/bn (4)
I0324 08:35:34.543733 10003 net.cpp:561] conv1a/bn <- conv1a
I0324 08:35:34.543743 10003 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0324 08:35:34.550035 10003 net.cpp:245] Setting up conv1a/bn
I0324 08:35:34.550053 10003 net.cpp:252] TRAIN Top shape for layer 4 'conv1a/bn' 8 32 160 384 (15728640)
I0324 08:35:34.550070 10003 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0324 08:35:34.550076 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.550086 10003 net.cpp:184] Created Layer conv1a/relu (5)
I0324 08:35:34.550091 10003 net.cpp:561] conv1a/relu <- conv1a
I0324 08:35:34.550097 10003 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0324 08:35:34.550114 10003 net.cpp:245] Setting up conv1a/relu
I0324 08:35:34.550123 10003 net.cpp:252] TRAIN Top shape for layer 5 'conv1a/relu' 8 32 160 384 (15728640)
I0324 08:35:34.550130 10003 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0324 08:35:34.550137 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.550153 10003 net.cpp:184] Created Layer conv1b (6)
I0324 08:35:34.550160 10003 net.cpp:561] conv1b <- conv1a
I0324 08:35:34.550168 10003 net.cpp:530] conv1b -> conv1b
I0324 08:35:34.551875 10003 net.cpp:245] Setting up conv1b
I0324 08:35:34.551892 10003 net.cpp:252] TRAIN Top shape for layer 6 'conv1b' 8 32 160 384 (15728640)
I0324 08:35:34.551905 10003 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0324 08:35:34.551913 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.551924 10003 net.cpp:184] Created Layer conv1b/bn (7)
I0324 08:35:34.551931 10003 net.cpp:561] conv1b/bn <- conv1b
I0324 08:35:34.551939 10003 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0324 08:35:34.552808 10003 net.cpp:245] Setting up conv1b/bn
I0324 08:35:34.552822 10003 net.cpp:252] TRAIN Top shape for layer 7 'conv1b/bn' 8 32 160 384 (15728640)
I0324 08:35:34.552837 10003 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0324 08:35:34.552845 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.552855 10003 net.cpp:184] Created Layer conv1b/relu (8)
I0324 08:35:34.552861 10003 net.cpp:561] conv1b/relu <- conv1b
I0324 08:35:34.552868 10003 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0324 08:35:34.552877 10003 net.cpp:245] Setting up conv1b/relu
I0324 08:35:34.552886 10003 net.cpp:252] TRAIN Top shape for layer 8 'conv1b/relu' 8 32 160 384 (15728640)
I0324 08:35:34.552892 10003 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0324 08:35:34.552899 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.552911 10003 net.cpp:184] Created Layer pool1 (9)
I0324 08:35:34.552917 10003 net.cpp:561] pool1 <- conv1b
I0324 08:35:34.552922 10003 net.cpp:530] pool1 -> pool1
I0324 08:35:34.553412 10003 net.cpp:245] Setting up pool1
I0324 08:35:34.553427 10003 net.cpp:252] TRAIN Top shape for layer 9 'pool1' 8 32 80 192 (3932160)
I0324 08:35:34.553436 10003 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0324 08:35:34.553443 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.553458 10003 net.cpp:184] Created Layer res2a_branch2a (10)
I0324 08:35:34.553467 10003 net.cpp:561] res2a_branch2a <- pool1
I0324 08:35:34.553474 10003 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0324 08:35:34.555629 10003 net.cpp:245] Setting up res2a_branch2a
I0324 08:35:34.555654 10003 net.cpp:252] TRAIN Top shape for layer 10 'res2a_branch2a' 8 64 80 192 (7864320)
I0324 08:35:34.555668 10003 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0324 08:35:34.555675 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.555687 10003 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0324 08:35:34.555730 10003 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0324 08:35:34.555747 10003 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0324 08:35:34.557271 10003 net.cpp:245] Setting up res2a_branch2a/bn
I0324 08:35:34.557292 10003 net.cpp:252] TRAIN Top shape for layer 11 'res2a_branch2a/bn' 8 64 80 192 (7864320)
I0324 08:35:34.557312 10003 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0324 08:35:34.557322 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.557329 10003 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0324 08:35:34.557335 10003 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0324 08:35:34.557343 10003 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0324 08:35:34.557351 10003 net.cpp:245] Setting up res2a_branch2a/relu
I0324 08:35:34.557360 10003 net.cpp:252] TRAIN Top shape for layer 12 'res2a_branch2a/relu' 8 64 80 192 (7864320)
I0324 08:35:34.557366 10003 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0324 08:35:34.557373 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.557389 10003 net.cpp:184] Created Layer res2a_branch2b (13)
I0324 08:35:34.557396 10003 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0324 08:35:34.557402 10003 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0324 08:35:34.559263 10003 net.cpp:245] Setting up res2a_branch2b
I0324 08:35:34.559283 10003 net.cpp:252] TRAIN Top shape for layer 13 'res2a_branch2b' 8 64 80 192 (7864320)
I0324 08:35:34.559294 10003 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0324 08:35:34.559300 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.559312 10003 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0324 08:35:34.559319 10003 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0324 08:35:34.559325 10003 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0324 08:35:34.560184 10003 net.cpp:245] Setting up res2a_branch2b/bn
I0324 08:35:34.560199 10003 net.cpp:252] TRAIN Top shape for layer 14 'res2a_branch2b/bn' 8 64 80 192 (7864320)
I0324 08:35:34.560212 10003 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0324 08:35:34.560220 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.560226 10003 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0324 08:35:34.560232 10003 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0324 08:35:34.560238 10003 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0324 08:35:34.560246 10003 net.cpp:245] Setting up res2a_branch2b/relu
I0324 08:35:34.560253 10003 net.cpp:252] TRAIN Top shape for layer 15 'res2a_branch2b/relu' 8 64 80 192 (7864320)
I0324 08:35:34.560258 10003 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0324 08:35:34.560264 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.560277 10003 net.cpp:184] Created Layer pool2 (16)
I0324 08:35:34.560284 10003 net.cpp:561] pool2 <- res2a_branch2b
I0324 08:35:34.560290 10003 net.cpp:530] pool2 -> pool2
I0324 08:35:34.560375 10003 net.cpp:245] Setting up pool2
I0324 08:35:34.560389 10003 net.cpp:252] TRAIN Top shape for layer 16 'pool2' 8 64 40 96 (1966080)
I0324 08:35:34.560395 10003 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0324 08:35:34.560400 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.560415 10003 net.cpp:184] Created Layer res3a_branch2a (17)
I0324 08:35:34.560422 10003 net.cpp:561] res3a_branch2a <- pool2
I0324 08:35:34.560428 10003 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0324 08:35:34.563706 10003 net.cpp:245] Setting up res3a_branch2a
I0324 08:35:34.563724 10003 net.cpp:252] TRAIN Top shape for layer 17 'res3a_branch2a' 8 128 40 96 (3932160)
I0324 08:35:34.563748 10003 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0324 08:35:34.563756 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.563766 10003 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0324 08:35:34.563776 10003 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0324 08:35:34.563782 10003 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0324 08:35:34.564610 10003 net.cpp:245] Setting up res3a_branch2a/bn
I0324 08:35:34.564625 10003 net.cpp:252] TRAIN Top shape for layer 18 'res3a_branch2a/bn' 8 128 40 96 (3932160)
I0324 08:35:34.564642 10003 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0324 08:35:34.564648 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.564656 10003 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0324 08:35:34.564662 10003 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0324 08:35:34.564668 10003 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0324 08:35:34.564677 10003 net.cpp:245] Setting up res3a_branch2a/relu
I0324 08:35:34.564683 10003 net.cpp:252] TRAIN Top shape for layer 19 'res3a_branch2a/relu' 8 128 40 96 (3932160)
I0324 08:35:34.564692 10003 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0324 08:35:34.564699 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.564714 10003 net.cpp:184] Created Layer res3a_branch2b (20)
I0324 08:35:34.564721 10003 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0324 08:35:34.564728 10003 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0324 08:35:34.566283 10003 net.cpp:245] Setting up res3a_branch2b
I0324 08:35:34.566299 10003 net.cpp:252] TRAIN Top shape for layer 20 'res3a_branch2b' 8 128 40 96 (3932160)
I0324 08:35:34.566309 10003 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0324 08:35:34.566315 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.566325 10003 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0324 08:35:34.566331 10003 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0324 08:35:34.566337 10003 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0324 08:35:34.567165 10003 net.cpp:245] Setting up res3a_branch2b/bn
I0324 08:35:34.567181 10003 net.cpp:252] TRAIN Top shape for layer 21 'res3a_branch2b/bn' 8 128 40 96 (3932160)
I0324 08:35:34.567194 10003 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0324 08:35:34.567200 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.567207 10003 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0324 08:35:34.567214 10003 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0324 08:35:34.567219 10003 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0324 08:35:34.567227 10003 net.cpp:245] Setting up res3a_branch2b/relu
I0324 08:35:34.567234 10003 net.cpp:252] TRAIN Top shape for layer 22 'res3a_branch2b/relu' 8 128 40 96 (3932160)
I0324 08:35:34.567239 10003 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0324 08:35:34.567247 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.567255 10003 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (23)
I0324 08:35:34.567260 10003 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0324 08:35:34.567266 10003 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0324 08:35:34.567272 10003 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0324 08:35:34.567337 10003 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0324 08:35:34.567349 10003 net.cpp:252] TRAIN Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 8 128 40 96 (3932160)
I0324 08:35:34.567368 10003 net.cpp:252] TRAIN Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 8 128 40 96 (3932160)
I0324 08:35:34.567375 10003 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0324 08:35:34.567381 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.567391 10003 net.cpp:184] Created Layer pool3 (24)
I0324 08:35:34.567399 10003 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0324 08:35:34.567405 10003 net.cpp:530] pool3 -> pool3
I0324 08:35:34.567488 10003 net.cpp:245] Setting up pool3
I0324 08:35:34.567502 10003 net.cpp:252] TRAIN Top shape for layer 24 'pool3' 8 128 20 48 (983040)
I0324 08:35:34.567507 10003 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0324 08:35:34.567514 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.567528 10003 net.cpp:184] Created Layer res4a_branch2a (25)
I0324 08:35:34.567535 10003 net.cpp:561] res4a_branch2a <- pool3
I0324 08:35:34.567543 10003 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0324 08:35:34.578188 10003 net.cpp:245] Setting up res4a_branch2a
I0324 08:35:34.578218 10003 net.cpp:252] TRAIN Top shape for layer 25 'res4a_branch2a' 8 256 20 48 (1966080)
I0324 08:35:34.578232 10003 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0324 08:35:34.578239 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.578253 10003 net.cpp:184] Created Layer res4a_branch2a/bn (26)
I0324 08:35:34.578260 10003 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0324 08:35:34.578269 10003 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0324 08:35:34.579120 10003 net.cpp:245] Setting up res4a_branch2a/bn
I0324 08:35:34.579136 10003 net.cpp:252] TRAIN Top shape for layer 26 'res4a_branch2a/bn' 8 256 20 48 (1966080)
I0324 08:35:34.579149 10003 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0324 08:35:34.579156 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.579164 10003 net.cpp:184] Created Layer res4a_branch2a/relu (27)
I0324 08:35:34.579170 10003 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0324 08:35:34.579175 10003 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0324 08:35:34.579185 10003 net.cpp:245] Setting up res4a_branch2a/relu
I0324 08:35:34.579190 10003 net.cpp:252] TRAIN Top shape for layer 27 'res4a_branch2a/relu' 8 256 20 48 (1966080)
I0324 08:35:34.579196 10003 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0324 08:35:34.579203 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.579221 10003 net.cpp:184] Created Layer res4a_branch2b (28)
I0324 08:35:34.579227 10003 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0324 08:35:34.579233 10003 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0324 08:35:34.584303 10003 net.cpp:245] Setting up res4a_branch2b
I0324 08:35:34.584331 10003 net.cpp:252] TRAIN Top shape for layer 28 'res4a_branch2b' 8 256 20 48 (1966080)
I0324 08:35:34.584343 10003 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0324 08:35:34.584350 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.584364 10003 net.cpp:184] Created Layer res4a_branch2b/bn (29)
I0324 08:35:34.584372 10003 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0324 08:35:34.584378 10003 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0324 08:35:34.585229 10003 net.cpp:245] Setting up res4a_branch2b/bn
I0324 08:35:34.585245 10003 net.cpp:252] TRAIN Top shape for layer 29 'res4a_branch2b/bn' 8 256 20 48 (1966080)
I0324 08:35:34.585258 10003 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0324 08:35:34.585278 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.585286 10003 net.cpp:184] Created Layer res4a_branch2b/relu (30)
I0324 08:35:34.585292 10003 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0324 08:35:34.585299 10003 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0324 08:35:34.585307 10003 net.cpp:245] Setting up res4a_branch2b/relu
I0324 08:35:34.585314 10003 net.cpp:252] TRAIN Top shape for layer 30 'res4a_branch2b/relu' 8 256 20 48 (1966080)
I0324 08:35:34.585326 10003 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0324 08:35:34.585332 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.585341 10003 net.cpp:184] Created Layer pool4 (31)
I0324 08:35:34.585353 10003 net.cpp:561] pool4 <- res4a_branch2b
I0324 08:35:34.585360 10003 net.cpp:530] pool4 -> pool4
I0324 08:35:34.585448 10003 net.cpp:245] Setting up pool4
I0324 08:35:34.585460 10003 net.cpp:252] TRAIN Top shape for layer 31 'pool4' 8 256 10 24 (491520)
I0324 08:35:34.585467 10003 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0324 08:35:34.585474 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.585490 10003 net.cpp:184] Created Layer res5a_branch2a (32)
I0324 08:35:34.585496 10003 net.cpp:561] res5a_branch2a <- pool4
I0324 08:35:34.585502 10003 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0324 08:35:34.625437 10003 net.cpp:245] Setting up res5a_branch2a
I0324 08:35:34.625469 10003 net.cpp:252] TRAIN Top shape for layer 32 'res5a_branch2a' 8 512 10 24 (983040)
I0324 08:35:34.625483 10003 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0324 08:35:34.625491 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.625505 10003 net.cpp:184] Created Layer res5a_branch2a/bn (33)
I0324 08:35:34.625514 10003 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0324 08:35:34.625521 10003 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0324 08:35:34.626412 10003 net.cpp:245] Setting up res5a_branch2a/bn
I0324 08:35:34.626428 10003 net.cpp:252] TRAIN Top shape for layer 33 'res5a_branch2a/bn' 8 512 10 24 (983040)
I0324 08:35:34.626442 10003 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0324 08:35:34.626449 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.626459 10003 net.cpp:184] Created Layer res5a_branch2a/relu (34)
I0324 08:35:34.626466 10003 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0324 08:35:34.626471 10003 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0324 08:35:34.626480 10003 net.cpp:245] Setting up res5a_branch2a/relu
I0324 08:35:34.626487 10003 net.cpp:252] TRAIN Top shape for layer 34 'res5a_branch2a/relu' 8 512 10 24 (983040)
I0324 08:35:34.626492 10003 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0324 08:35:34.626505 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.626524 10003 net.cpp:184] Created Layer res5a_branch2b (35)
I0324 08:35:34.626531 10003 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0324 08:35:34.626538 10003 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0324 08:35:34.646428 10003 net.cpp:245] Setting up res5a_branch2b
I0324 08:35:34.646461 10003 net.cpp:252] TRAIN Top shape for layer 35 'res5a_branch2b' 8 512 10 24 (983040)
I0324 08:35:34.646486 10003 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0324 08:35:34.646493 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.646509 10003 net.cpp:184] Created Layer res5a_branch2b/bn (36)
I0324 08:35:34.646517 10003 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0324 08:35:34.646523 10003 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0324 08:35:34.647442 10003 net.cpp:245] Setting up res5a_branch2b/bn
I0324 08:35:34.647459 10003 net.cpp:252] TRAIN Top shape for layer 36 'res5a_branch2b/bn' 8 512 10 24 (983040)
I0324 08:35:34.647472 10003 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0324 08:35:34.647480 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.647487 10003 net.cpp:184] Created Layer res5a_branch2b/relu (37)
I0324 08:35:34.647493 10003 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0324 08:35:34.647500 10003 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0324 08:35:34.647507 10003 net.cpp:245] Setting up res5a_branch2b/relu
I0324 08:35:34.647514 10003 net.cpp:252] TRAIN Top shape for layer 37 'res5a_branch2b/relu' 8 512 10 24 (983040)
I0324 08:35:34.647521 10003 layer_factory.hpp:136] Creating layer 'res5a_branch2b_res5a_branch2b/relu_0_split' of type 'Split'
I0324 08:35:34.647526 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.647533 10003 net.cpp:184] Created Layer res5a_branch2b_res5a_branch2b/relu_0_split (38)
I0324 08:35:34.647543 10003 net.cpp:561] res5a_branch2b_res5a_branch2b/relu_0_split <- res5a_branch2b
I0324 08:35:34.647549 10003 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_0
I0324 08:35:34.647557 10003 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_1
I0324 08:35:34.647629 10003 net.cpp:245] Setting up res5a_branch2b_res5a_branch2b/relu_0_split
I0324 08:35:34.647641 10003 net.cpp:252] TRAIN Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 8 512 10 24 (983040)
I0324 08:35:34.647649 10003 net.cpp:252] TRAIN Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 8 512 10 24 (983040)
I0324 08:35:34.647655 10003 layer_factory.hpp:136] Creating layer 'pool6' of type 'Pooling'
I0324 08:35:34.647660 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.647671 10003 net.cpp:184] Created Layer pool6 (39)
I0324 08:35:34.647680 10003 net.cpp:561] pool6 <- res5a_branch2b_res5a_branch2b/relu_0_split_0
I0324 08:35:34.647686 10003 net.cpp:530] pool6 -> pool6
I0324 08:35:34.647779 10003 net.cpp:245] Setting up pool6
I0324 08:35:34.647794 10003 net.cpp:252] TRAIN Top shape for layer 39 'pool6' 8 512 5 12 (245760)
I0324 08:35:34.647800 10003 layer_factory.hpp:136] Creating layer 'pool6_pool6_0_split' of type 'Split'
I0324 08:35:34.647806 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.647814 10003 net.cpp:184] Created Layer pool6_pool6_0_split (40)
I0324 08:35:34.647819 10003 net.cpp:561] pool6_pool6_0_split <- pool6
I0324 08:35:34.647825 10003 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_0
I0324 08:35:34.647831 10003 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_1
I0324 08:35:34.647894 10003 net.cpp:245] Setting up pool6_pool6_0_split
I0324 08:35:34.647908 10003 net.cpp:252] TRAIN Top shape for layer 40 'pool6_pool6_0_split' 8 512 5 12 (245760)
I0324 08:35:34.647914 10003 net.cpp:252] TRAIN Top shape for layer 40 'pool6_pool6_0_split' 8 512 5 12 (245760)
I0324 08:35:34.647920 10003 layer_factory.hpp:136] Creating layer 'pool7' of type 'Pooling'
I0324 08:35:34.647927 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.647936 10003 net.cpp:184] Created Layer pool7 (41)
I0324 08:35:34.647943 10003 net.cpp:561] pool7 <- pool6_pool6_0_split_0
I0324 08:35:34.647948 10003 net.cpp:530] pool7 -> pool7
I0324 08:35:34.648036 10003 net.cpp:245] Setting up pool7
I0324 08:35:34.648049 10003 net.cpp:252] TRAIN Top shape for layer 41 'pool7' 8 512 3 6 (73728)
I0324 08:35:34.648056 10003 layer_factory.hpp:136] Creating layer 'pool7_pool7_0_split' of type 'Split'
I0324 08:35:34.648061 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.648078 10003 net.cpp:184] Created Layer pool7_pool7_0_split (42)
I0324 08:35:34.648085 10003 net.cpp:561] pool7_pool7_0_split <- pool7
I0324 08:35:34.648092 10003 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_0
I0324 08:35:34.648103 10003 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_1
I0324 08:35:34.648167 10003 net.cpp:245] Setting up pool7_pool7_0_split
I0324 08:35:34.648181 10003 net.cpp:252] TRAIN Top shape for layer 42 'pool7_pool7_0_split' 8 512 3 6 (73728)
I0324 08:35:34.648190 10003 net.cpp:252] TRAIN Top shape for layer 42 'pool7_pool7_0_split' 8 512 3 6 (73728)
I0324 08:35:34.648195 10003 layer_factory.hpp:136] Creating layer 'pool8' of type 'Pooling'
I0324 08:35:34.648200 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.648208 10003 net.cpp:184] Created Layer pool8 (43)
I0324 08:35:34.648214 10003 net.cpp:561] pool8 <- pool7_pool7_0_split_0
I0324 08:35:34.648223 10003 net.cpp:530] pool8 -> pool8
I0324 08:35:34.648310 10003 net.cpp:245] Setting up pool8
I0324 08:35:34.648324 10003 net.cpp:252] TRAIN Top shape for layer 43 'pool8' 8 512 2 3 (24576)
I0324 08:35:34.648329 10003 layer_factory.hpp:136] Creating layer 'pool8_pool8_0_split' of type 'Split'
I0324 08:35:34.648335 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.648344 10003 net.cpp:184] Created Layer pool8_pool8_0_split (44)
I0324 08:35:34.648350 10003 net.cpp:561] pool8_pool8_0_split <- pool8
I0324 08:35:34.648355 10003 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_0
I0324 08:35:34.648361 10003 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_1
I0324 08:35:34.648424 10003 net.cpp:245] Setting up pool8_pool8_0_split
I0324 08:35:34.648437 10003 net.cpp:252] TRAIN Top shape for layer 44 'pool8_pool8_0_split' 8 512 2 3 (24576)
I0324 08:35:34.648444 10003 net.cpp:252] TRAIN Top shape for layer 44 'pool8_pool8_0_split' 8 512 2 3 (24576)
I0324 08:35:34.648449 10003 layer_factory.hpp:136] Creating layer 'pool9' of type 'Pooling'
I0324 08:35:34.648455 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.648466 10003 net.cpp:184] Created Layer pool9 (45)
I0324 08:35:34.648473 10003 net.cpp:561] pool9 <- pool8_pool8_0_split_0
I0324 08:35:34.648479 10003 net.cpp:530] pool9 -> pool9
I0324 08:35:34.648566 10003 net.cpp:245] Setting up pool9
I0324 08:35:34.648579 10003 net.cpp:252] TRAIN Top shape for layer 45 'pool9' 8 512 1 2 (8192)
I0324 08:35:34.648586 10003 layer_factory.hpp:136] Creating layer 'ctx_output1' of type 'Convolution'
I0324 08:35:34.648592 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.648609 10003 net.cpp:184] Created Layer ctx_output1 (46)
I0324 08:35:34.648617 10003 net.cpp:561] ctx_output1 <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0324 08:35:34.648625 10003 net.cpp:530] ctx_output1 -> ctx_output1
I0324 08:35:34.650108 10003 net.cpp:245] Setting up ctx_output1
I0324 08:35:34.650125 10003 net.cpp:252] TRAIN Top shape for layer 46 'ctx_output1' 8 256 40 96 (7864320)
I0324 08:35:34.650135 10003 layer_factory.hpp:136] Creating layer 'ctx_output1/relu' of type 'ReLU'
I0324 08:35:34.650141 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.650148 10003 net.cpp:184] Created Layer ctx_output1/relu (47)
I0324 08:35:34.650154 10003 net.cpp:561] ctx_output1/relu <- ctx_output1
I0324 08:35:34.650161 10003 net.cpp:513] ctx_output1/relu -> ctx_output1 (in-place)
I0324 08:35:34.650168 10003 net.cpp:245] Setting up ctx_output1/relu
I0324 08:35:34.650177 10003 net.cpp:252] TRAIN Top shape for layer 47 'ctx_output1/relu' 8 256 40 96 (7864320)
I0324 08:35:34.650182 10003 layer_factory.hpp:136] Creating layer 'ctx_output1_ctx_output1/relu_0_split' of type 'Split'
I0324 08:35:34.650187 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.650207 10003 net.cpp:184] Created Layer ctx_output1_ctx_output1/relu_0_split (48)
I0324 08:35:34.650214 10003 net.cpp:561] ctx_output1_ctx_output1/relu_0_split <- ctx_output1
I0324 08:35:34.650220 10003 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_0
I0324 08:35:34.650229 10003 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_1
I0324 08:35:34.650236 10003 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_2
I0324 08:35:34.650331 10003 net.cpp:245] Setting up ctx_output1_ctx_output1/relu_0_split
I0324 08:35:34.650346 10003 net.cpp:252] TRAIN Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 8 256 40 96 (7864320)
I0324 08:35:34.650352 10003 net.cpp:252] TRAIN Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 8 256 40 96 (7864320)
I0324 08:35:34.650358 10003 net.cpp:252] TRAIN Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 8 256 40 96 (7864320)
I0324 08:35:34.650364 10003 layer_factory.hpp:136] Creating layer 'ctx_output2' of type 'Convolution'
I0324 08:35:34.650369 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.650388 10003 net.cpp:184] Created Layer ctx_output2 (49)
I0324 08:35:34.650395 10003 net.cpp:561] ctx_output2 <- res5a_branch2b_res5a_branch2b/relu_0_split_1
I0324 08:35:34.650404 10003 net.cpp:530] ctx_output2 -> ctx_output2
I0324 08:35:34.654976 10003 net.cpp:245] Setting up ctx_output2
I0324 08:35:34.654999 10003 net.cpp:252] TRAIN Top shape for layer 49 'ctx_output2' 8 256 10 24 (491520)
I0324 08:35:34.655011 10003 layer_factory.hpp:136] Creating layer 'ctx_output2/relu' of type 'ReLU'
I0324 08:35:34.655017 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.655026 10003 net.cpp:184] Created Layer ctx_output2/relu (50)
I0324 08:35:34.655032 10003 net.cpp:561] ctx_output2/relu <- ctx_output2
I0324 08:35:34.655040 10003 net.cpp:513] ctx_output2/relu -> ctx_output2 (in-place)
I0324 08:35:34.655050 10003 net.cpp:245] Setting up ctx_output2/relu
I0324 08:35:34.655057 10003 net.cpp:252] TRAIN Top shape for layer 50 'ctx_output2/relu' 8 256 10 24 (491520)
I0324 08:35:34.655062 10003 layer_factory.hpp:136] Creating layer 'ctx_output2_ctx_output2/relu_0_split' of type 'Split'
I0324 08:35:34.655068 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.655081 10003 net.cpp:184] Created Layer ctx_output2_ctx_output2/relu_0_split (51)
I0324 08:35:34.655088 10003 net.cpp:561] ctx_output2_ctx_output2/relu_0_split <- ctx_output2
I0324 08:35:34.655094 10003 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_0
I0324 08:35:34.655104 10003 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_1
I0324 08:35:34.655114 10003 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_2
I0324 08:35:34.655210 10003 net.cpp:245] Setting up ctx_output2_ctx_output2/relu_0_split
I0324 08:35:34.655223 10003 net.cpp:252] TRAIN Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 8 256 10 24 (491520)
I0324 08:35:34.655231 10003 net.cpp:252] TRAIN Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 8 256 10 24 (491520)
I0324 08:35:34.655237 10003 net.cpp:252] TRAIN Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 8 256 10 24 (491520)
I0324 08:35:34.655243 10003 layer_factory.hpp:136] Creating layer 'ctx_output3' of type 'Convolution'
I0324 08:35:34.655249 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.655267 10003 net.cpp:184] Created Layer ctx_output3 (52)
I0324 08:35:34.655274 10003 net.cpp:561] ctx_output3 <- pool6_pool6_0_split_1
I0324 08:35:34.655282 10003 net.cpp:530] ctx_output3 -> ctx_output3
I0324 08:35:34.661036 10003 net.cpp:245] Setting up ctx_output3
I0324 08:35:34.661063 10003 net.cpp:252] TRAIN Top shape for layer 52 'ctx_output3' 8 256 5 12 (122880)
I0324 08:35:34.661092 10003 layer_factory.hpp:136] Creating layer 'ctx_output3/relu' of type 'ReLU'
I0324 08:35:34.661099 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.661111 10003 net.cpp:184] Created Layer ctx_output3/relu (53)
I0324 08:35:34.661120 10003 net.cpp:561] ctx_output3/relu <- ctx_output3
I0324 08:35:34.661128 10003 net.cpp:513] ctx_output3/relu -> ctx_output3 (in-place)
I0324 08:35:34.661139 10003 net.cpp:245] Setting up ctx_output3/relu
I0324 08:35:34.661146 10003 net.cpp:252] TRAIN Top shape for layer 53 'ctx_output3/relu' 8 256 5 12 (122880)
I0324 08:35:34.661152 10003 layer_factory.hpp:136] Creating layer 'ctx_output3_ctx_output3/relu_0_split' of type 'Split'
I0324 08:35:34.661157 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.661166 10003 net.cpp:184] Created Layer ctx_output3_ctx_output3/relu_0_split (54)
I0324 08:35:34.661175 10003 net.cpp:561] ctx_output3_ctx_output3/relu_0_split <- ctx_output3
I0324 08:35:34.661180 10003 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_0
I0324 08:35:34.661187 10003 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_1
I0324 08:35:34.661195 10003 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_2
I0324 08:35:34.661290 10003 net.cpp:245] Setting up ctx_output3_ctx_output3/relu_0_split
I0324 08:35:34.661304 10003 net.cpp:252] TRAIN Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 8 256 5 12 (122880)
I0324 08:35:34.661312 10003 net.cpp:252] TRAIN Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 8 256 5 12 (122880)
I0324 08:35:34.661319 10003 net.cpp:252] TRAIN Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 8 256 5 12 (122880)
I0324 08:35:34.661324 10003 layer_factory.hpp:136] Creating layer 'ctx_output4' of type 'Convolution'
I0324 08:35:34.661330 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.661347 10003 net.cpp:184] Created Layer ctx_output4 (55)
I0324 08:35:34.661355 10003 net.cpp:561] ctx_output4 <- pool7_pool7_0_split_1
I0324 08:35:34.661363 10003 net.cpp:530] ctx_output4 -> ctx_output4
I0324 08:35:34.665891 10003 net.cpp:245] Setting up ctx_output4
I0324 08:35:34.665907 10003 net.cpp:252] TRAIN Top shape for layer 55 'ctx_output4' 8 256 3 6 (36864)
I0324 08:35:34.665917 10003 layer_factory.hpp:136] Creating layer 'ctx_output4/relu' of type 'ReLU'
I0324 08:35:34.665923 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.665930 10003 net.cpp:184] Created Layer ctx_output4/relu (56)
I0324 08:35:34.665936 10003 net.cpp:561] ctx_output4/relu <- ctx_output4
I0324 08:35:34.665942 10003 net.cpp:513] ctx_output4/relu -> ctx_output4 (in-place)
I0324 08:35:34.665951 10003 net.cpp:245] Setting up ctx_output4/relu
I0324 08:35:34.665957 10003 net.cpp:252] TRAIN Top shape for layer 56 'ctx_output4/relu' 8 256 3 6 (36864)
I0324 08:35:34.665962 10003 layer_factory.hpp:136] Creating layer 'ctx_output4_ctx_output4/relu_0_split' of type 'Split'
I0324 08:35:34.665968 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.665978 10003 net.cpp:184] Created Layer ctx_output4_ctx_output4/relu_0_split (57)
I0324 08:35:34.665985 10003 net.cpp:561] ctx_output4_ctx_output4/relu_0_split <- ctx_output4
I0324 08:35:34.665992 10003 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_0
I0324 08:35:34.665999 10003 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_1
I0324 08:35:34.666007 10003 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_2
I0324 08:35:34.666101 10003 net.cpp:245] Setting up ctx_output4_ctx_output4/relu_0_split
I0324 08:35:34.666115 10003 net.cpp:252] TRAIN Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 8 256 3 6 (36864)
I0324 08:35:34.666133 10003 net.cpp:252] TRAIN Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 8 256 3 6 (36864)
I0324 08:35:34.666141 10003 net.cpp:252] TRAIN Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 8 256 3 6 (36864)
I0324 08:35:34.666146 10003 layer_factory.hpp:136] Creating layer 'ctx_output5' of type 'Convolution'
I0324 08:35:34.666152 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.666168 10003 net.cpp:184] Created Layer ctx_output5 (58)
I0324 08:35:34.666175 10003 net.cpp:561] ctx_output5 <- pool8_pool8_0_split_1
I0324 08:35:34.666182 10003 net.cpp:530] ctx_output5 -> ctx_output5
I0324 08:35:34.670717 10003 net.cpp:245] Setting up ctx_output5
I0324 08:35:34.670735 10003 net.cpp:252] TRAIN Top shape for layer 58 'ctx_output5' 8 256 2 3 (12288)
I0324 08:35:34.670747 10003 layer_factory.hpp:136] Creating layer 'ctx_output5/relu' of type 'ReLU'
I0324 08:35:34.670753 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.670761 10003 net.cpp:184] Created Layer ctx_output5/relu (59)
I0324 08:35:34.670768 10003 net.cpp:561] ctx_output5/relu <- ctx_output5
I0324 08:35:34.670774 10003 net.cpp:513] ctx_output5/relu -> ctx_output5 (in-place)
I0324 08:35:34.670783 10003 net.cpp:245] Setting up ctx_output5/relu
I0324 08:35:34.670789 10003 net.cpp:252] TRAIN Top shape for layer 59 'ctx_output5/relu' 8 256 2 3 (12288)
I0324 08:35:34.670795 10003 layer_factory.hpp:136] Creating layer 'ctx_output5_ctx_output5/relu_0_split' of type 'Split'
I0324 08:35:34.670800 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.670809 10003 net.cpp:184] Created Layer ctx_output5_ctx_output5/relu_0_split (60)
I0324 08:35:34.670816 10003 net.cpp:561] ctx_output5_ctx_output5/relu_0_split <- ctx_output5
I0324 08:35:34.670823 10003 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_0
I0324 08:35:34.670835 10003 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_1
I0324 08:35:34.670842 10003 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_2
I0324 08:35:34.670934 10003 net.cpp:245] Setting up ctx_output5_ctx_output5/relu_0_split
I0324 08:35:34.670948 10003 net.cpp:252] TRAIN Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 8 256 2 3 (12288)
I0324 08:35:34.670954 10003 net.cpp:252] TRAIN Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 8 256 2 3 (12288)
I0324 08:35:34.670961 10003 net.cpp:252] TRAIN Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 8 256 2 3 (12288)
I0324 08:35:34.670966 10003 layer_factory.hpp:136] Creating layer 'ctx_output6' of type 'Convolution'
I0324 08:35:34.670972 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.670989 10003 net.cpp:184] Created Layer ctx_output6 (61)
I0324 08:35:34.670995 10003 net.cpp:561] ctx_output6 <- pool9
I0324 08:35:34.671003 10003 net.cpp:530] ctx_output6 -> ctx_output6
I0324 08:35:34.675525 10003 net.cpp:245] Setting up ctx_output6
I0324 08:35:34.675542 10003 net.cpp:252] TRAIN Top shape for layer 61 'ctx_output6' 8 256 1 2 (4096)
I0324 08:35:34.675551 10003 layer_factory.hpp:136] Creating layer 'ctx_output6/relu' of type 'ReLU'
I0324 08:35:34.675559 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.675567 10003 net.cpp:184] Created Layer ctx_output6/relu (62)
I0324 08:35:34.675575 10003 net.cpp:561] ctx_output6/relu <- ctx_output6
I0324 08:35:34.675580 10003 net.cpp:513] ctx_output6/relu -> ctx_output6 (in-place)
I0324 08:35:34.675588 10003 net.cpp:245] Setting up ctx_output6/relu
I0324 08:35:34.675595 10003 net.cpp:252] TRAIN Top shape for layer 62 'ctx_output6/relu' 8 256 1 2 (4096)
I0324 08:35:34.675601 10003 layer_factory.hpp:136] Creating layer 'ctx_output6_ctx_output6/relu_0_split' of type 'Split'
I0324 08:35:34.675618 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.675628 10003 net.cpp:184] Created Layer ctx_output6_ctx_output6/relu_0_split (63)
I0324 08:35:34.675635 10003 net.cpp:561] ctx_output6_ctx_output6/relu_0_split <- ctx_output6
I0324 08:35:34.675642 10003 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_0
I0324 08:35:34.675648 10003 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_1
I0324 08:35:34.675657 10003 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_2
I0324 08:35:34.675748 10003 net.cpp:245] Setting up ctx_output6_ctx_output6/relu_0_split
I0324 08:35:34.675763 10003 net.cpp:252] TRAIN Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 8 256 1 2 (4096)
I0324 08:35:34.675772 10003 net.cpp:252] TRAIN Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 8 256 1 2 (4096)
I0324 08:35:34.675779 10003 net.cpp:252] TRAIN Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 8 256 1 2 (4096)
I0324 08:35:34.675786 10003 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc' of type 'Convolution'
I0324 08:35:34.675792 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.675812 10003 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc (64)
I0324 08:35:34.675820 10003 net.cpp:561] ctx_output1/relu_mbox_loc <- ctx_output1_ctx_output1/relu_0_split_0
I0324 08:35:34.675829 10003 net.cpp:530] ctx_output1/relu_mbox_loc -> ctx_output1/relu_mbox_loc
I0324 08:35:34.676424 10003 net.cpp:245] Setting up ctx_output1/relu_mbox_loc
I0324 08:35:34.676440 10003 net.cpp:252] TRAIN Top shape for layer 64 'ctx_output1/relu_mbox_loc' 8 16 40 96 (491520)
I0324 08:35:34.676450 10003 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_perm' of type 'Permute'
I0324 08:35:34.676457 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.676479 10003 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_perm (65)
I0324 08:35:34.676488 10003 net.cpp:561] ctx_output1/relu_mbox_loc_perm <- ctx_output1/relu_mbox_loc
I0324 08:35:34.676496 10003 net.cpp:530] ctx_output1/relu_mbox_loc_perm -> ctx_output1/relu_mbox_loc_perm
I0324 08:35:34.676682 10003 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_perm
I0324 08:35:34.676697 10003 net.cpp:252] TRAIN Top shape for layer 65 'ctx_output1/relu_mbox_loc_perm' 8 40 96 16 (491520)
I0324 08:35:34.676703 10003 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_flat' of type 'Flatten'
I0324 08:35:34.676710 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.676720 10003 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_flat (66)
I0324 08:35:34.676728 10003 net.cpp:561] ctx_output1/relu_mbox_loc_flat <- ctx_output1/relu_mbox_loc_perm
I0324 08:35:34.676734 10003 net.cpp:530] ctx_output1/relu_mbox_loc_flat -> ctx_output1/relu_mbox_loc_flat
I0324 08:35:34.676780 10003 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_flat
I0324 08:35:34.676793 10003 net.cpp:252] TRAIN Top shape for layer 66 'ctx_output1/relu_mbox_loc_flat' 8 61440 (491520)
I0324 08:35:34.676801 10003 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf' of type 'Convolution'
I0324 08:35:34.676808 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.676826 10003 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf (67)
I0324 08:35:34.676833 10003 net.cpp:561] ctx_output1/relu_mbox_conf <- ctx_output1_ctx_output1/relu_0_split_1
I0324 08:35:34.676841 10003 net.cpp:530] ctx_output1/relu_mbox_conf -> ctx_output1/relu_mbox_conf
I0324 08:35:34.677435 10003 net.cpp:245] Setting up ctx_output1/relu_mbox_conf
I0324 08:35:34.677451 10003 net.cpp:252] TRAIN Top shape for layer 67 'ctx_output1/relu_mbox_conf' 8 16 40 96 (491520)
I0324 08:35:34.677471 10003 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_perm' of type 'Permute'
I0324 08:35:34.677479 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.677491 10003 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_perm (68)
I0324 08:35:34.677498 10003 net.cpp:561] ctx_output1/relu_mbox_conf_perm <- ctx_output1/relu_mbox_conf
I0324 08:35:34.677507 10003 net.cpp:530] ctx_output1/relu_mbox_conf_perm -> ctx_output1/relu_mbox_conf_perm
I0324 08:35:34.677697 10003 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_perm
I0324 08:35:34.677713 10003 net.cpp:252] TRAIN Top shape for layer 68 'ctx_output1/relu_mbox_conf_perm' 8 40 96 16 (491520)
I0324 08:35:34.677721 10003 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_flat' of type 'Flatten'
I0324 08:35:34.677728 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.677737 10003 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_flat (69)
I0324 08:35:34.677744 10003 net.cpp:561] ctx_output1/relu_mbox_conf_flat <- ctx_output1/relu_mbox_conf_perm
I0324 08:35:34.677752 10003 net.cpp:530] ctx_output1/relu_mbox_conf_flat -> ctx_output1/relu_mbox_conf_flat
I0324 08:35:34.677796 10003 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_flat
I0324 08:35:34.677809 10003 net.cpp:252] TRAIN Top shape for layer 69 'ctx_output1/relu_mbox_conf_flat' 8 61440 (491520)
I0324 08:35:34.677815 10003 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_priorbox' of type 'PriorBox'
I0324 08:35:34.677821 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.677839 10003 net.cpp:184] Created Layer ctx_output1/relu_mbox_priorbox (70)
I0324 08:35:34.677845 10003 net.cpp:561] ctx_output1/relu_mbox_priorbox <- ctx_output1_ctx_output1/relu_0_split_2
I0324 08:35:34.677853 10003 net.cpp:561] ctx_output1/relu_mbox_priorbox <- data_data_0_split_1
I0324 08:35:34.677862 10003 net.cpp:530] ctx_output1/relu_mbox_priorbox -> ctx_output1/relu_mbox_priorbox
I0324 08:35:34.677911 10003 net.cpp:245] Setting up ctx_output1/relu_mbox_priorbox
I0324 08:35:34.677923 10003 net.cpp:252] TRAIN Top shape for layer 70 'ctx_output1/relu_mbox_priorbox' 1 2 61440 (122880)
I0324 08:35:34.677932 10003 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc' of type 'Convolution'
I0324 08:35:34.677938 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.677955 10003 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc (71)
I0324 08:35:34.677963 10003 net.cpp:561] ctx_output2/relu_mbox_loc <- ctx_output2_ctx_output2/relu_0_split_0
I0324 08:35:34.677973 10003 net.cpp:530] ctx_output2/relu_mbox_loc -> ctx_output2/relu_mbox_loc
I0324 08:35:34.678643 10003 net.cpp:245] Setting up ctx_output2/relu_mbox_loc
I0324 08:35:34.678659 10003 net.cpp:252] TRAIN Top shape for layer 71 'ctx_output2/relu_mbox_loc' 8 24 10 24 (46080)
I0324 08:35:34.678670 10003 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_perm' of type 'Permute'
I0324 08:35:34.678678 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.678689 10003 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_perm (72)
I0324 08:35:34.678696 10003 net.cpp:561] ctx_output2/relu_mbox_loc_perm <- ctx_output2/relu_mbox_loc
I0324 08:35:34.678704 10003 net.cpp:530] ctx_output2/relu_mbox_loc_perm -> ctx_output2/relu_mbox_loc_perm
I0324 08:35:34.678891 10003 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_perm
I0324 08:35:34.678905 10003 net.cpp:252] TRAIN Top shape for layer 72 'ctx_output2/relu_mbox_loc_perm' 8 10 24 24 (46080)
I0324 08:35:34.678912 10003 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_flat' of type 'Flatten'
I0324 08:35:34.678920 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.678930 10003 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_flat (73)
I0324 08:35:34.678946 10003 net.cpp:561] ctx_output2/relu_mbox_loc_flat <- ctx_output2/relu_mbox_loc_perm
I0324 08:35:34.678954 10003 net.cpp:530] ctx_output2/relu_mbox_loc_flat -> ctx_output2/relu_mbox_loc_flat
I0324 08:35:34.678997 10003 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_flat
I0324 08:35:34.679013 10003 net.cpp:252] TRAIN Top shape for layer 73 'ctx_output2/relu_mbox_loc_flat' 8 5760 (46080)
I0324 08:35:34.679020 10003 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf' of type 'Convolution'
I0324 08:35:34.679028 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.679044 10003 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf (74)
I0324 08:35:34.679054 10003 net.cpp:561] ctx_output2/relu_mbox_conf <- ctx_output2_ctx_output2/relu_0_split_1
I0324 08:35:34.679061 10003 net.cpp:530] ctx_output2/relu_mbox_conf -> ctx_output2/relu_mbox_conf
I0324 08:35:34.679724 10003 net.cpp:245] Setting up ctx_output2/relu_mbox_conf
I0324 08:35:34.679739 10003 net.cpp:252] TRAIN Top shape for layer 74 'ctx_output2/relu_mbox_conf' 8 24 10 24 (46080)
I0324 08:35:34.679750 10003 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_perm' of type 'Permute'
I0324 08:35:34.679757 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.679769 10003 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_perm (75)
I0324 08:35:34.679777 10003 net.cpp:561] ctx_output2/relu_mbox_conf_perm <- ctx_output2/relu_mbox_conf
I0324 08:35:34.679785 10003 net.cpp:530] ctx_output2/relu_mbox_conf_perm -> ctx_output2/relu_mbox_conf_perm
I0324 08:35:34.679975 10003 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_perm
I0324 08:35:34.679988 10003 net.cpp:252] TRAIN Top shape for layer 75 'ctx_output2/relu_mbox_conf_perm' 8 10 24 24 (46080)
I0324 08:35:34.679996 10003 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_flat' of type 'Flatten'
I0324 08:35:34.680002 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.680011 10003 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_flat (76)
I0324 08:35:34.680017 10003 net.cpp:561] ctx_output2/relu_mbox_conf_flat <- ctx_output2/relu_mbox_conf_perm
I0324 08:35:34.680025 10003 net.cpp:530] ctx_output2/relu_mbox_conf_flat -> ctx_output2/relu_mbox_conf_flat
I0324 08:35:34.680069 10003 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_flat
I0324 08:35:34.680083 10003 net.cpp:252] TRAIN Top shape for layer 76 'ctx_output2/relu_mbox_conf_flat' 8 5760 (46080)
I0324 08:35:34.680089 10003 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_priorbox' of type 'PriorBox'
I0324 08:35:34.680096 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.680106 10003 net.cpp:184] Created Layer ctx_output2/relu_mbox_priorbox (77)
I0324 08:35:34.680114 10003 net.cpp:561] ctx_output2/relu_mbox_priorbox <- ctx_output2_ctx_output2/relu_0_split_2
I0324 08:35:34.680122 10003 net.cpp:561] ctx_output2/relu_mbox_priorbox <- data_data_0_split_2
I0324 08:35:34.680130 10003 net.cpp:530] ctx_output2/relu_mbox_priorbox -> ctx_output2/relu_mbox_priorbox
I0324 08:35:34.680174 10003 net.cpp:245] Setting up ctx_output2/relu_mbox_priorbox
I0324 08:35:34.680187 10003 net.cpp:252] TRAIN Top shape for layer 77 'ctx_output2/relu_mbox_priorbox' 1 2 5760 (11520)
I0324 08:35:34.680194 10003 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc' of type 'Convolution'
I0324 08:35:34.680202 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.680219 10003 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc (78)
I0324 08:35:34.680227 10003 net.cpp:561] ctx_output3/relu_mbox_loc <- ctx_output3_ctx_output3/relu_0_split_0
I0324 08:35:34.680235 10003 net.cpp:530] ctx_output3/relu_mbox_loc -> ctx_output3/relu_mbox_loc
I0324 08:35:34.680896 10003 net.cpp:245] Setting up ctx_output3/relu_mbox_loc
I0324 08:35:34.680922 10003 net.cpp:252] TRAIN Top shape for layer 78 'ctx_output3/relu_mbox_loc' 8 24 5 12 (11520)
I0324 08:35:34.680932 10003 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_perm' of type 'Permute'
I0324 08:35:34.680940 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.680953 10003 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_perm (79)
I0324 08:35:34.680961 10003 net.cpp:561] ctx_output3/relu_mbox_loc_perm <- ctx_output3/relu_mbox_loc
I0324 08:35:34.680968 10003 net.cpp:530] ctx_output3/relu_mbox_loc_perm -> ctx_output3/relu_mbox_loc_perm
I0324 08:35:34.681157 10003 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_perm
I0324 08:35:34.681171 10003 net.cpp:252] TRAIN Top shape for layer 79 'ctx_output3/relu_mbox_loc_perm' 8 5 12 24 (11520)
I0324 08:35:34.681179 10003 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_flat' of type 'Flatten'
I0324 08:35:34.681185 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.681195 10003 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_flat (80)
I0324 08:35:34.681202 10003 net.cpp:561] ctx_output3/relu_mbox_loc_flat <- ctx_output3/relu_mbox_loc_perm
I0324 08:35:34.681210 10003 net.cpp:530] ctx_output3/relu_mbox_loc_flat -> ctx_output3/relu_mbox_loc_flat
I0324 08:35:34.681253 10003 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_flat
I0324 08:35:34.681267 10003 net.cpp:252] TRAIN Top shape for layer 80 'ctx_output3/relu_mbox_loc_flat' 8 1440 (11520)
I0324 08:35:34.681273 10003 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf' of type 'Convolution'
I0324 08:35:34.681280 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.681298 10003 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf (81)
I0324 08:35:34.681308 10003 net.cpp:561] ctx_output3/relu_mbox_conf <- ctx_output3_ctx_output3/relu_0_split_1
I0324 08:35:34.681315 10003 net.cpp:530] ctx_output3/relu_mbox_conf -> ctx_output3/relu_mbox_conf
I0324 08:35:34.682015 10003 net.cpp:245] Setting up ctx_output3/relu_mbox_conf
I0324 08:35:34.682031 10003 net.cpp:252] TRAIN Top shape for layer 81 'ctx_output3/relu_mbox_conf' 8 24 5 12 (11520)
I0324 08:35:34.682042 10003 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_perm' of type 'Permute'
I0324 08:35:34.682049 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.682061 10003 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_perm (82)
I0324 08:35:34.682070 10003 net.cpp:561] ctx_output3/relu_mbox_conf_perm <- ctx_output3/relu_mbox_conf
I0324 08:35:34.682077 10003 net.cpp:530] ctx_output3/relu_mbox_conf_perm -> ctx_output3/relu_mbox_conf_perm
I0324 08:35:34.682265 10003 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_perm
I0324 08:35:34.682279 10003 net.cpp:252] TRAIN Top shape for layer 82 'ctx_output3/relu_mbox_conf_perm' 8 5 12 24 (11520)
I0324 08:35:34.682287 10003 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_flat' of type 'Flatten'
I0324 08:35:34.682293 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.682303 10003 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_flat (83)
I0324 08:35:34.682312 10003 net.cpp:561] ctx_output3/relu_mbox_conf_flat <- ctx_output3/relu_mbox_conf_perm
I0324 08:35:34.682318 10003 net.cpp:530] ctx_output3/relu_mbox_conf_flat -> ctx_output3/relu_mbox_conf_flat
I0324 08:35:34.682363 10003 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_flat
I0324 08:35:34.682376 10003 net.cpp:252] TRAIN Top shape for layer 83 'ctx_output3/relu_mbox_conf_flat' 8 1440 (11520)
I0324 08:35:34.682384 10003 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_priorbox' of type 'PriorBox'
I0324 08:35:34.682390 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.682410 10003 net.cpp:184] Created Layer ctx_output3/relu_mbox_priorbox (84)
I0324 08:35:34.682417 10003 net.cpp:561] ctx_output3/relu_mbox_priorbox <- ctx_output3_ctx_output3/relu_0_split_2
I0324 08:35:34.682425 10003 net.cpp:561] ctx_output3/relu_mbox_priorbox <- data_data_0_split_3
I0324 08:35:34.682433 10003 net.cpp:530] ctx_output3/relu_mbox_priorbox -> ctx_output3/relu_mbox_priorbox
I0324 08:35:34.682480 10003 net.cpp:245] Setting up ctx_output3/relu_mbox_priorbox
I0324 08:35:34.682494 10003 net.cpp:252] TRAIN Top shape for layer 84 'ctx_output3/relu_mbox_priorbox' 1 2 1440 (2880)
I0324 08:35:34.682502 10003 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc' of type 'Convolution'
I0324 08:35:34.682508 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.682525 10003 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc (85)
I0324 08:35:34.682533 10003 net.cpp:561] ctx_output4/relu_mbox_loc <- ctx_output4_ctx_output4/relu_0_split_0
I0324 08:35:34.682541 10003 net.cpp:530] ctx_output4/relu_mbox_loc -> ctx_output4/relu_mbox_loc
I0324 08:35:34.683220 10003 net.cpp:245] Setting up ctx_output4/relu_mbox_loc
I0324 08:35:34.683236 10003 net.cpp:252] TRAIN Top shape for layer 85 'ctx_output4/relu_mbox_loc' 8 24 3 6 (3456)
I0324 08:35:34.683248 10003 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_perm' of type 'Permute'
I0324 08:35:34.683254 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.683267 10003 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_perm (86)
I0324 08:35:34.683275 10003 net.cpp:561] ctx_output4/relu_mbox_loc_perm <- ctx_output4/relu_mbox_loc
I0324 08:35:34.683282 10003 net.cpp:530] ctx_output4/relu_mbox_loc_perm -> ctx_output4/relu_mbox_loc_perm
I0324 08:35:34.683475 10003 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_perm
I0324 08:35:34.683487 10003 net.cpp:252] TRAIN Top shape for layer 86 'ctx_output4/relu_mbox_loc_perm' 8 3 6 24 (3456)
I0324 08:35:34.683495 10003 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_flat' of type 'Flatten'
I0324 08:35:34.683501 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.683511 10003 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_flat (87)
I0324 08:35:34.683517 10003 net.cpp:561] ctx_output4/relu_mbox_loc_flat <- ctx_output4/relu_mbox_loc_perm
I0324 08:35:34.683524 10003 net.cpp:530] ctx_output4/relu_mbox_loc_flat -> ctx_output4/relu_mbox_loc_flat
I0324 08:35:34.683569 10003 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_flat
I0324 08:35:34.683581 10003 net.cpp:252] TRAIN Top shape for layer 87 'ctx_output4/relu_mbox_loc_flat' 8 432 (3456)
I0324 08:35:34.683589 10003 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf' of type 'Convolution'
I0324 08:35:34.683596 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.683612 10003 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf (88)
I0324 08:35:34.683622 10003 net.cpp:561] ctx_output4/relu_mbox_conf <- ctx_output4_ctx_output4/relu_0_split_1
I0324 08:35:34.683631 10003 net.cpp:530] ctx_output4/relu_mbox_conf -> ctx_output4/relu_mbox_conf
I0324 08:35:34.684303 10003 net.cpp:245] Setting up ctx_output4/relu_mbox_conf
I0324 08:35:34.684317 10003 net.cpp:252] TRAIN Top shape for layer 88 'ctx_output4/relu_mbox_conf' 8 24 3 6 (3456)
I0324 08:35:34.684329 10003 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_perm' of type 'Permute'
I0324 08:35:34.684335 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.684348 10003 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_perm (89)
I0324 08:35:34.684356 10003 net.cpp:561] ctx_output4/relu_mbox_conf_perm <- ctx_output4/relu_mbox_conf
I0324 08:35:34.684363 10003 net.cpp:530] ctx_output4/relu_mbox_conf_perm -> ctx_output4/relu_mbox_conf_perm
I0324 08:35:34.684556 10003 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_perm
I0324 08:35:34.684578 10003 net.cpp:252] TRAIN Top shape for layer 89 'ctx_output4/relu_mbox_conf_perm' 8 3 6 24 (3456)
I0324 08:35:34.684587 10003 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_flat' of type 'Flatten'
I0324 08:35:34.684593 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.684603 10003 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_flat (90)
I0324 08:35:34.684612 10003 net.cpp:561] ctx_output4/relu_mbox_conf_flat <- ctx_output4/relu_mbox_conf_perm
I0324 08:35:34.684618 10003 net.cpp:530] ctx_output4/relu_mbox_conf_flat -> ctx_output4/relu_mbox_conf_flat
I0324 08:35:34.684664 10003 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_flat
I0324 08:35:34.684677 10003 net.cpp:252] TRAIN Top shape for layer 90 'ctx_output4/relu_mbox_conf_flat' 8 432 (3456)
I0324 08:35:34.684684 10003 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_priorbox' of type 'PriorBox'
I0324 08:35:34.684691 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.684700 10003 net.cpp:184] Created Layer ctx_output4/relu_mbox_priorbox (91)
I0324 08:35:34.684706 10003 net.cpp:561] ctx_output4/relu_mbox_priorbox <- ctx_output4_ctx_output4/relu_0_split_2
I0324 08:35:34.684715 10003 net.cpp:561] ctx_output4/relu_mbox_priorbox <- data_data_0_split_4
I0324 08:35:34.684722 10003 net.cpp:530] ctx_output4/relu_mbox_priorbox -> ctx_output4/relu_mbox_priorbox
I0324 08:35:34.684769 10003 net.cpp:245] Setting up ctx_output4/relu_mbox_priorbox
I0324 08:35:34.684782 10003 net.cpp:252] TRAIN Top shape for layer 91 'ctx_output4/relu_mbox_priorbox' 1 2 432 (864)
I0324 08:35:34.684789 10003 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc' of type 'Convolution'
I0324 08:35:34.684795 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.684815 10003 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc (92)
I0324 08:35:34.684823 10003 net.cpp:561] ctx_output5/relu_mbox_loc <- ctx_output5_ctx_output5/relu_0_split_0
I0324 08:35:34.684831 10003 net.cpp:530] ctx_output5/relu_mbox_loc -> ctx_output5/relu_mbox_loc
I0324 08:35:34.685439 10003 net.cpp:245] Setting up ctx_output5/relu_mbox_loc
I0324 08:35:34.685456 10003 net.cpp:252] TRAIN Top shape for layer 92 'ctx_output5/relu_mbox_loc' 8 16 2 3 (768)
I0324 08:35:34.685467 10003 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_perm' of type 'Permute'
I0324 08:35:34.685473 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.685484 10003 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_perm (93)
I0324 08:35:34.685492 10003 net.cpp:561] ctx_output5/relu_mbox_loc_perm <- ctx_output5/relu_mbox_loc
I0324 08:35:34.685499 10003 net.cpp:530] ctx_output5/relu_mbox_loc_perm -> ctx_output5/relu_mbox_loc_perm
I0324 08:35:34.685688 10003 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_perm
I0324 08:35:34.685706 10003 net.cpp:252] TRAIN Top shape for layer 93 'ctx_output5/relu_mbox_loc_perm' 8 2 3 16 (768)
I0324 08:35:34.685714 10003 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_flat' of type 'Flatten'
I0324 08:35:34.685721 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.685731 10003 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_flat (94)
I0324 08:35:34.685739 10003 net.cpp:561] ctx_output5/relu_mbox_loc_flat <- ctx_output5/relu_mbox_loc_perm
I0324 08:35:34.685746 10003 net.cpp:530] ctx_output5/relu_mbox_loc_flat -> ctx_output5/relu_mbox_loc_flat
I0324 08:35:34.685791 10003 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_flat
I0324 08:35:34.685804 10003 net.cpp:252] TRAIN Top shape for layer 94 'ctx_output5/relu_mbox_loc_flat' 8 96 (768)
I0324 08:35:34.685812 10003 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf' of type 'Convolution'
I0324 08:35:34.685818 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.685847 10003 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf (95)
I0324 08:35:34.685853 10003 net.cpp:561] ctx_output5/relu_mbox_conf <- ctx_output5_ctx_output5/relu_0_split_1
I0324 08:35:34.685863 10003 net.cpp:530] ctx_output5/relu_mbox_conf -> ctx_output5/relu_mbox_conf
I0324 08:35:34.686475 10003 net.cpp:245] Setting up ctx_output5/relu_mbox_conf
I0324 08:35:34.686491 10003 net.cpp:252] TRAIN Top shape for layer 95 'ctx_output5/relu_mbox_conf' 8 16 2 3 (768)
I0324 08:35:34.686501 10003 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_perm' of type 'Permute'
I0324 08:35:34.686506 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.686517 10003 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_perm (96)
I0324 08:35:34.686524 10003 net.cpp:561] ctx_output5/relu_mbox_conf_perm <- ctx_output5/relu_mbox_conf
I0324 08:35:34.686530 10003 net.cpp:530] ctx_output5/relu_mbox_conf_perm -> ctx_output5/relu_mbox_conf_perm
I0324 08:35:34.686717 10003 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_perm
I0324 08:35:34.686731 10003 net.cpp:252] TRAIN Top shape for layer 96 'ctx_output5/relu_mbox_conf_perm' 8 2 3 16 (768)
I0324 08:35:34.686738 10003 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_flat' of type 'Flatten'
I0324 08:35:34.686743 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.686751 10003 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_flat (97)
I0324 08:35:34.686758 10003 net.cpp:561] ctx_output5/relu_mbox_conf_flat <- ctx_output5/relu_mbox_conf_perm
I0324 08:35:34.686764 10003 net.cpp:530] ctx_output5/relu_mbox_conf_flat -> ctx_output5/relu_mbox_conf_flat
I0324 08:35:34.686807 10003 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_flat
I0324 08:35:34.686820 10003 net.cpp:252] TRAIN Top shape for layer 97 'ctx_output5/relu_mbox_conf_flat' 8 96 (768)
I0324 08:35:34.686826 10003 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_priorbox' of type 'PriorBox'
I0324 08:35:34.686832 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.686841 10003 net.cpp:184] Created Layer ctx_output5/relu_mbox_priorbox (98)
I0324 08:35:34.686846 10003 net.cpp:561] ctx_output5/relu_mbox_priorbox <- ctx_output5_ctx_output5/relu_0_split_2
I0324 08:35:34.686852 10003 net.cpp:561] ctx_output5/relu_mbox_priorbox <- data_data_0_split_5
I0324 08:35:34.686859 10003 net.cpp:530] ctx_output5/relu_mbox_priorbox -> ctx_output5/relu_mbox_priorbox
I0324 08:35:34.686908 10003 net.cpp:245] Setting up ctx_output5/relu_mbox_priorbox
I0324 08:35:34.686920 10003 net.cpp:252] TRAIN Top shape for layer 98 'ctx_output5/relu_mbox_priorbox' 1 2 96 (192)
I0324 08:35:34.686926 10003 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc' of type 'Convolution'
I0324 08:35:34.686933 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.686949 10003 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc (99)
I0324 08:35:34.686955 10003 net.cpp:561] ctx_output6/relu_mbox_loc <- ctx_output6_ctx_output6/relu_0_split_0
I0324 08:35:34.686962 10003 net.cpp:530] ctx_output6/relu_mbox_loc -> ctx_output6/relu_mbox_loc
I0324 08:35:34.687577 10003 net.cpp:245] Setting up ctx_output6/relu_mbox_loc
I0324 08:35:34.687592 10003 net.cpp:252] TRAIN Top shape for layer 99 'ctx_output6/relu_mbox_loc' 8 16 1 2 (256)
I0324 08:35:34.687602 10003 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_perm' of type 'Permute'
I0324 08:35:34.687608 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.687618 10003 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_perm (100)
I0324 08:35:34.687624 10003 net.cpp:561] ctx_output6/relu_mbox_loc_perm <- ctx_output6/relu_mbox_loc
I0324 08:35:34.687633 10003 net.cpp:530] ctx_output6/relu_mbox_loc_perm -> ctx_output6/relu_mbox_loc_perm
I0324 08:35:34.687829 10003 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_perm
I0324 08:35:34.687844 10003 net.cpp:252] TRAIN Top shape for layer 100 'ctx_output6/relu_mbox_loc_perm' 8 1 2 16 (256)
I0324 08:35:34.687850 10003 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_flat' of type 'Flatten'
I0324 08:35:34.687855 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.687863 10003 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_flat (101)
I0324 08:35:34.687870 10003 net.cpp:561] ctx_output6/relu_mbox_loc_flat <- ctx_output6/relu_mbox_loc_perm
I0324 08:35:34.687875 10003 net.cpp:530] ctx_output6/relu_mbox_loc_flat -> ctx_output6/relu_mbox_loc_flat
I0324 08:35:34.687921 10003 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_flat
I0324 08:35:34.687933 10003 net.cpp:252] TRAIN Top shape for layer 101 'ctx_output6/relu_mbox_loc_flat' 8 32 (256)
I0324 08:35:34.687940 10003 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf' of type 'Convolution'
I0324 08:35:34.687945 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.687963 10003 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf (102)
I0324 08:35:34.687971 10003 net.cpp:561] ctx_output6/relu_mbox_conf <- ctx_output6_ctx_output6/relu_0_split_1
I0324 08:35:34.687980 10003 net.cpp:530] ctx_output6/relu_mbox_conf -> ctx_output6/relu_mbox_conf
I0324 08:35:34.688592 10003 net.cpp:245] Setting up ctx_output6/relu_mbox_conf
I0324 08:35:34.688609 10003 net.cpp:252] TRAIN Top shape for layer 102 'ctx_output6/relu_mbox_conf' 8 16 1 2 (256)
I0324 08:35:34.688618 10003 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_perm' of type 'Permute'
I0324 08:35:34.688624 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.688635 10003 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_perm (103)
I0324 08:35:34.688642 10003 net.cpp:561] ctx_output6/relu_mbox_conf_perm <- ctx_output6/relu_mbox_conf
I0324 08:35:34.688650 10003 net.cpp:530] ctx_output6/relu_mbox_conf_perm -> ctx_output6/relu_mbox_conf_perm
I0324 08:35:34.688841 10003 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_perm
I0324 08:35:34.688854 10003 net.cpp:252] TRAIN Top shape for layer 103 'ctx_output6/relu_mbox_conf_perm' 8 1 2 16 (256)
I0324 08:35:34.688861 10003 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_flat' of type 'Flatten'
I0324 08:35:34.688866 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.688874 10003 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_flat (104)
I0324 08:35:34.688879 10003 net.cpp:561] ctx_output6/relu_mbox_conf_flat <- ctx_output6/relu_mbox_conf_perm
I0324 08:35:34.688886 10003 net.cpp:530] ctx_output6/relu_mbox_conf_flat -> ctx_output6/relu_mbox_conf_flat
I0324 08:35:34.688930 10003 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_flat
I0324 08:35:34.688942 10003 net.cpp:252] TRAIN Top shape for layer 104 'ctx_output6/relu_mbox_conf_flat' 8 32 (256)
I0324 08:35:34.688948 10003 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_priorbox' of type 'PriorBox'
I0324 08:35:34.688954 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.688963 10003 net.cpp:184] Created Layer ctx_output6/relu_mbox_priorbox (105)
I0324 08:35:34.688969 10003 net.cpp:561] ctx_output6/relu_mbox_priorbox <- ctx_output6_ctx_output6/relu_0_split_2
I0324 08:35:34.688977 10003 net.cpp:561] ctx_output6/relu_mbox_priorbox <- data_data_0_split_6
I0324 08:35:34.688984 10003 net.cpp:530] ctx_output6/relu_mbox_priorbox -> ctx_output6/relu_mbox_priorbox
I0324 08:35:34.689028 10003 net.cpp:245] Setting up ctx_output6/relu_mbox_priorbox
I0324 08:35:34.689040 10003 net.cpp:252] TRAIN Top shape for layer 105 'ctx_output6/relu_mbox_priorbox' 1 2 32 (64)
I0324 08:35:34.689047 10003 layer_factory.hpp:136] Creating layer 'mbox_loc' of type 'Concat'
I0324 08:35:34.689061 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.689074 10003 net.cpp:184] Created Layer mbox_loc (106)
I0324 08:35:34.689080 10003 net.cpp:561] mbox_loc <- ctx_output1/relu_mbox_loc_flat
I0324 08:35:34.689088 10003 net.cpp:561] mbox_loc <- ctx_output2/relu_mbox_loc_flat
I0324 08:35:34.689096 10003 net.cpp:561] mbox_loc <- ctx_output3/relu_mbox_loc_flat
I0324 08:35:34.689105 10003 net.cpp:561] mbox_loc <- ctx_output4/relu_mbox_loc_flat
I0324 08:35:34.689110 10003 net.cpp:561] mbox_loc <- ctx_output5/relu_mbox_loc_flat
I0324 08:35:34.689117 10003 net.cpp:561] mbox_loc <- ctx_output6/relu_mbox_loc_flat
I0324 08:35:34.689124 10003 net.cpp:530] mbox_loc -> mbox_loc
I0324 08:35:34.689172 10003 net.cpp:245] Setting up mbox_loc
I0324 08:35:34.689185 10003 net.cpp:252] TRAIN Top shape for layer 106 'mbox_loc' 8 69200 (553600)
I0324 08:35:34.689193 10003 layer_factory.hpp:136] Creating layer 'mbox_conf' of type 'Concat'
I0324 08:35:34.689198 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.689205 10003 net.cpp:184] Created Layer mbox_conf (107)
I0324 08:35:34.689210 10003 net.cpp:561] mbox_conf <- ctx_output1/relu_mbox_conf_flat
I0324 08:35:34.689218 10003 net.cpp:561] mbox_conf <- ctx_output2/relu_mbox_conf_flat
I0324 08:35:34.689225 10003 net.cpp:561] mbox_conf <- ctx_output3/relu_mbox_conf_flat
I0324 08:35:34.689234 10003 net.cpp:561] mbox_conf <- ctx_output4/relu_mbox_conf_flat
I0324 08:35:34.689239 10003 net.cpp:561] mbox_conf <- ctx_output5/relu_mbox_conf_flat
I0324 08:35:34.689246 10003 net.cpp:561] mbox_conf <- ctx_output6/relu_mbox_conf_flat
I0324 08:35:34.689254 10003 net.cpp:530] mbox_conf -> mbox_conf
I0324 08:35:34.689299 10003 net.cpp:245] Setting up mbox_conf
I0324 08:35:34.689312 10003 net.cpp:252] TRAIN Top shape for layer 107 'mbox_conf' 8 69200 (553600)
I0324 08:35:34.689318 10003 layer_factory.hpp:136] Creating layer 'mbox_priorbox' of type 'Concat'
I0324 08:35:34.689324 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.689334 10003 net.cpp:184] Created Layer mbox_priorbox (108)
I0324 08:35:34.689340 10003 net.cpp:561] mbox_priorbox <- ctx_output1/relu_mbox_priorbox
I0324 08:35:34.689347 10003 net.cpp:561] mbox_priorbox <- ctx_output2/relu_mbox_priorbox
I0324 08:35:34.689353 10003 net.cpp:561] mbox_priorbox <- ctx_output3/relu_mbox_priorbox
I0324 08:35:34.689360 10003 net.cpp:561] mbox_priorbox <- ctx_output4/relu_mbox_priorbox
I0324 08:35:34.689368 10003 net.cpp:561] mbox_priorbox <- ctx_output5/relu_mbox_priorbox
I0324 08:35:34.689374 10003 net.cpp:561] mbox_priorbox <- ctx_output6/relu_mbox_priorbox
I0324 08:35:34.689380 10003 net.cpp:530] mbox_priorbox -> mbox_priorbox
I0324 08:35:34.689425 10003 net.cpp:245] Setting up mbox_priorbox
I0324 08:35:34.689438 10003 net.cpp:252] TRAIN Top shape for layer 108 'mbox_priorbox' 1 2 69200 (138400)
I0324 08:35:34.689445 10003 layer_factory.hpp:136] Creating layer 'mbox_loss' of type 'MultiBoxLoss'
I0324 08:35:34.689450 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.689465 10003 net.cpp:184] Created Layer mbox_loss (109)
I0324 08:35:34.689472 10003 net.cpp:561] mbox_loss <- mbox_loc
I0324 08:35:34.689478 10003 net.cpp:561] mbox_loss <- mbox_conf
I0324 08:35:34.689486 10003 net.cpp:561] mbox_loss <- mbox_priorbox
I0324 08:35:34.689492 10003 net.cpp:561] mbox_loss <- label
I0324 08:35:34.689502 10003 net.cpp:530] mbox_loss -> mbox_loss
I0324 08:35:34.689601 10003 layer_factory.hpp:136] Creating layer 'mbox_loss_smooth_L1_loc' of type 'SmoothL1Loss'
I0324 08:35:34.689613 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.693899 10003 layer_factory.hpp:136] Creating layer 'mbox_loss_softmax_conf' of type 'SoftmaxWithLoss'
I0324 08:35:34.693915 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.694197 10003 net.cpp:245] Setting up mbox_loss
I0324 08:35:34.694213 10003 net.cpp:252] TRAIN Top shape for layer 109 'mbox_loss' (1)
I0324 08:35:34.694219 10003 net.cpp:256]     with loss weight 1
I0324 08:35:34.694234 10003 net.cpp:323] mbox_loss needs backward computation.
I0324 08:35:34.694241 10003 net.cpp:325] mbox_priorbox does not need backward computation.
I0324 08:35:34.694247 10003 net.cpp:323] mbox_conf needs backward computation.
I0324 08:35:34.694255 10003 net.cpp:323] mbox_loc needs backward computation.
I0324 08:35:34.694262 10003 net.cpp:325] ctx_output6/relu_mbox_priorbox does not need backward computation.
I0324 08:35:34.694269 10003 net.cpp:323] ctx_output6/relu_mbox_conf_flat needs backward computation.
I0324 08:35:34.694275 10003 net.cpp:323] ctx_output6/relu_mbox_conf_perm needs backward computation.
I0324 08:35:34.694280 10003 net.cpp:323] ctx_output6/relu_mbox_conf needs backward computation.
I0324 08:35:34.694286 10003 net.cpp:323] ctx_output6/relu_mbox_loc_flat needs backward computation.
I0324 08:35:34.694291 10003 net.cpp:323] ctx_output6/relu_mbox_loc_perm needs backward computation.
I0324 08:35:34.694298 10003 net.cpp:323] ctx_output6/relu_mbox_loc needs backward computation.
I0324 08:35:34.694303 10003 net.cpp:325] ctx_output5/relu_mbox_priorbox does not need backward computation.
I0324 08:35:34.694311 10003 net.cpp:323] ctx_output5/relu_mbox_conf_flat needs backward computation.
I0324 08:35:34.694317 10003 net.cpp:323] ctx_output5/relu_mbox_conf_perm needs backward computation.
I0324 08:35:34.694322 10003 net.cpp:323] ctx_output5/relu_mbox_conf needs backward computation.
I0324 08:35:34.694329 10003 net.cpp:323] ctx_output5/relu_mbox_loc_flat needs backward computation.
I0324 08:35:34.694334 10003 net.cpp:323] ctx_output5/relu_mbox_loc_perm needs backward computation.
I0324 08:35:34.694341 10003 net.cpp:323] ctx_output5/relu_mbox_loc needs backward computation.
I0324 08:35:34.694347 10003 net.cpp:325] ctx_output4/relu_mbox_priorbox does not need backward computation.
I0324 08:35:34.694355 10003 net.cpp:323] ctx_output4/relu_mbox_conf_flat needs backward computation.
I0324 08:35:34.694360 10003 net.cpp:323] ctx_output4/relu_mbox_conf_perm needs backward computation.
I0324 08:35:34.694366 10003 net.cpp:323] ctx_output4/relu_mbox_conf needs backward computation.
I0324 08:35:34.694371 10003 net.cpp:323] ctx_output4/relu_mbox_loc_flat needs backward computation.
I0324 08:35:34.694376 10003 net.cpp:323] ctx_output4/relu_mbox_loc_perm needs backward computation.
I0324 08:35:34.694381 10003 net.cpp:323] ctx_output4/relu_mbox_loc needs backward computation.
I0324 08:35:34.694386 10003 net.cpp:325] ctx_output3/relu_mbox_priorbox does not need backward computation.
I0324 08:35:34.694393 10003 net.cpp:323] ctx_output3/relu_mbox_conf_flat needs backward computation.
I0324 08:35:34.694399 10003 net.cpp:323] ctx_output3/relu_mbox_conf_perm needs backward computation.
I0324 08:35:34.694406 10003 net.cpp:323] ctx_output3/relu_mbox_conf needs backward computation.
I0324 08:35:34.694412 10003 net.cpp:323] ctx_output3/relu_mbox_loc_flat needs backward computation.
I0324 08:35:34.694418 10003 net.cpp:323] ctx_output3/relu_mbox_loc_perm needs backward computation.
I0324 08:35:34.694424 10003 net.cpp:323] ctx_output3/relu_mbox_loc needs backward computation.
I0324 08:35:34.694432 10003 net.cpp:325] ctx_output2/relu_mbox_priorbox does not need backward computation.
I0324 08:35:34.694437 10003 net.cpp:323] ctx_output2/relu_mbox_conf_flat needs backward computation.
I0324 08:35:34.694443 10003 net.cpp:323] ctx_output2/relu_mbox_conf_perm needs backward computation.
I0324 08:35:34.694449 10003 net.cpp:323] ctx_output2/relu_mbox_conf needs backward computation.
I0324 08:35:34.694454 10003 net.cpp:323] ctx_output2/relu_mbox_loc_flat needs backward computation.
I0324 08:35:34.694458 10003 net.cpp:323] ctx_output2/relu_mbox_loc_perm needs backward computation.
I0324 08:35:34.694465 10003 net.cpp:323] ctx_output2/relu_mbox_loc needs backward computation.
I0324 08:35:34.694471 10003 net.cpp:325] ctx_output1/relu_mbox_priorbox does not need backward computation.
I0324 08:35:34.694489 10003 net.cpp:323] ctx_output1/relu_mbox_conf_flat needs backward computation.
I0324 08:35:34.694494 10003 net.cpp:323] ctx_output1/relu_mbox_conf_perm needs backward computation.
I0324 08:35:34.694499 10003 net.cpp:323] ctx_output1/relu_mbox_conf needs backward computation.
I0324 08:35:34.694505 10003 net.cpp:323] ctx_output1/relu_mbox_loc_flat needs backward computation.
I0324 08:35:34.694512 10003 net.cpp:323] ctx_output1/relu_mbox_loc_perm needs backward computation.
I0324 08:35:34.694519 10003 net.cpp:323] ctx_output1/relu_mbox_loc needs backward computation.
I0324 08:35:34.694525 10003 net.cpp:323] ctx_output6_ctx_output6/relu_0_split needs backward computation.
I0324 08:35:34.694533 10003 net.cpp:323] ctx_output6/relu needs backward computation.
I0324 08:35:34.694540 10003 net.cpp:323] ctx_output6 needs backward computation.
I0324 08:35:34.694546 10003 net.cpp:323] ctx_output5_ctx_output5/relu_0_split needs backward computation.
I0324 08:35:34.694552 10003 net.cpp:323] ctx_output5/relu needs backward computation.
I0324 08:35:34.694557 10003 net.cpp:323] ctx_output5 needs backward computation.
I0324 08:35:34.694564 10003 net.cpp:323] ctx_output4_ctx_output4/relu_0_split needs backward computation.
I0324 08:35:34.694571 10003 net.cpp:323] ctx_output4/relu needs backward computation.
I0324 08:35:34.694576 10003 net.cpp:323] ctx_output4 needs backward computation.
I0324 08:35:34.694582 10003 net.cpp:323] ctx_output3_ctx_output3/relu_0_split needs backward computation.
I0324 08:35:34.694588 10003 net.cpp:323] ctx_output3/relu needs backward computation.
I0324 08:35:34.694593 10003 net.cpp:323] ctx_output3 needs backward computation.
I0324 08:35:34.694599 10003 net.cpp:323] ctx_output2_ctx_output2/relu_0_split needs backward computation.
I0324 08:35:34.694605 10003 net.cpp:323] ctx_output2/relu needs backward computation.
I0324 08:35:34.694612 10003 net.cpp:323] ctx_output2 needs backward computation.
I0324 08:35:34.694617 10003 net.cpp:323] ctx_output1_ctx_output1/relu_0_split needs backward computation.
I0324 08:35:34.694623 10003 net.cpp:323] ctx_output1/relu needs backward computation.
I0324 08:35:34.694629 10003 net.cpp:323] ctx_output1 needs backward computation.
I0324 08:35:34.694635 10003 net.cpp:323] pool9 needs backward computation.
I0324 08:35:34.694641 10003 net.cpp:323] pool8_pool8_0_split needs backward computation.
I0324 08:35:34.694648 10003 net.cpp:323] pool8 needs backward computation.
I0324 08:35:34.694653 10003 net.cpp:323] pool7_pool7_0_split needs backward computation.
I0324 08:35:34.694659 10003 net.cpp:323] pool7 needs backward computation.
I0324 08:35:34.694665 10003 net.cpp:323] pool6_pool6_0_split needs backward computation.
I0324 08:35:34.694670 10003 net.cpp:323] pool6 needs backward computation.
I0324 08:35:34.694677 10003 net.cpp:323] res5a_branch2b_res5a_branch2b/relu_0_split needs backward computation.
I0324 08:35:34.694684 10003 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0324 08:35:34.694689 10003 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0324 08:35:34.694694 10003 net.cpp:323] res5a_branch2b needs backward computation.
I0324 08:35:34.694700 10003 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0324 08:35:34.694706 10003 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0324 08:35:34.694711 10003 net.cpp:323] res5a_branch2a needs backward computation.
I0324 08:35:34.694717 10003 net.cpp:323] pool4 needs backward computation.
I0324 08:35:34.694723 10003 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0324 08:35:34.694730 10003 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0324 08:35:34.694736 10003 net.cpp:323] res4a_branch2b needs backward computation.
I0324 08:35:34.694741 10003 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0324 08:35:34.694747 10003 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0324 08:35:34.694752 10003 net.cpp:323] res4a_branch2a needs backward computation.
I0324 08:35:34.694757 10003 net.cpp:323] pool3 needs backward computation.
I0324 08:35:34.694770 10003 net.cpp:323] res3a_branch2b_res3a_branch2b/relu_0_split needs backward computation.
I0324 08:35:34.694777 10003 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0324 08:35:34.694783 10003 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0324 08:35:34.694789 10003 net.cpp:323] res3a_branch2b needs backward computation.
I0324 08:35:34.694795 10003 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0324 08:35:34.694802 10003 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0324 08:35:34.694808 10003 net.cpp:323] res3a_branch2a needs backward computation.
I0324 08:35:34.694813 10003 net.cpp:323] pool2 needs backward computation.
I0324 08:35:34.694819 10003 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0324 08:35:34.694825 10003 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0324 08:35:34.694830 10003 net.cpp:323] res2a_branch2b needs backward computation.
I0324 08:35:34.694836 10003 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0324 08:35:34.694842 10003 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0324 08:35:34.694847 10003 net.cpp:323] res2a_branch2a needs backward computation.
I0324 08:35:34.694854 10003 net.cpp:323] pool1 needs backward computation.
I0324 08:35:34.694859 10003 net.cpp:323] conv1b/relu needs backward computation.
I0324 08:35:34.694865 10003 net.cpp:323] conv1b/bn needs backward computation.
I0324 08:35:34.694870 10003 net.cpp:323] conv1b needs backward computation.
I0324 08:35:34.694876 10003 net.cpp:323] conv1a/relu needs backward computation.
I0324 08:35:34.694882 10003 net.cpp:323] conv1a/bn needs backward computation.
I0324 08:35:34.694887 10003 net.cpp:323] conv1a needs backward computation.
I0324 08:35:34.694895 10003 net.cpp:325] data/bias does not need backward computation.
I0324 08:35:34.694902 10003 net.cpp:325] data_data_0_split does not need backward computation.
I0324 08:35:34.694911 10003 net.cpp:325] data does not need backward computation.
I0324 08:35:34.694916 10003 net.cpp:367] This network produces output mbox_loss
I0324 08:35:34.695022 10003 net.cpp:389] Top memory (TRAIN) required for data: 1206154824 diff: 1206154824
I0324 08:35:34.695032 10003 net.cpp:392] Bottom memory (TRAIN) required for data: 1206154816 diff: 1206154816
I0324 08:35:34.695039 10003 net.cpp:395] Shared (in-place) memory (TRAIN) by data: 521715712 diff: 521715712
I0324 08:35:34.695044 10003 net.cpp:398] Parameters memory (TRAIN) required for data: 12464288 diff: 12464288
I0324 08:35:34.695050 10003 net.cpp:401] Parameters shared memory (TRAIN) by data: 0 diff: 0
I0324 08:35:34.695055 10003 net.cpp:407] Network initialization done.
I0324 08:35:34.709302 10003 solver.cpp:177] Creating test net (#0) specified by test_net file: training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/l1reg/test.prototxt
I0324 08:35:34.710192 10003 net.cpp:72] Initializing net from parameters: 
name: "ssdJacintoNetV2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_value: 0
    mean_value: 0
    mean_value: 0
    force_color: false
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 320
      width: 768
      interp_mode: LINEAR
    }
    crop_h: 320
    crop_w: 768
  }
  data_param {
    source: "/user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_test_lmdb"
    batch_size: 4
    backend: LMDB
    threads: 4
    parser_threads: 4
  }
  annotated_data_param {
    batch_sampler {
    }
    label_map_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/labelmap.prototxt"
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "pool6"
  top: "pool7"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool8"
  type: "Pooling"
  bottom: "pool7"
  top: "pool8"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "pool9"
  type: "Pooling"
  bottom: "pool8"
  top: "pool9"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "ctx_output1"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "ctx_output1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu"
  type: "ReLU"
  bottom: "ctx_output1"
  top: "ctx_output1"
}
layer {
  name: "ctx_output2"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "ctx_output2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu"
  type: "ReLU"
  bottom: "ctx_output2"
  top: "ctx_output2"
}
layer {
  name: "ctx_output3"
  type: "Convolution"
  bottom: "pool6"
  top: "ctx_output3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu"
  type: "ReLU"
  bottom: "ctx_output3"
  top: "ctx_output3"
}
layer {
  name: "ctx_output4"
  type: "Convolution"
  bottom: "pool7"
  top: "ctx_output4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu"
  type: "ReLU"
  bottom: "ctx_output4"
  top: "ctx_output4"
}
layer {
  name: "ctx_output5"
  type: "Convolution"
  bottom: "pool8"
  top: "ctx_output5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu"
  type: "ReLU"
  bottom: "ctx_output5"
  top: "ctx_output5"
}
layer {
  name: "ctx_output6"
  type: "Convolution"
  bottom: "pool9"
  top: "ctx_output6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu"
  type: "ReLU"
  bottom: "ctx_output6"
  top: "ctx_output6"
}
layer {
  name: "ctx_output1/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_loc"
  top: "ctx_output1/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_loc_perm"
  top: "ctx_output1/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_conf"
  top: "ctx_output1/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_conf_perm"
  top: "ctx_output1/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output1"
  bottom: "data"
  top: "ctx_output1/relu_mbox_priorbox"
  prior_box_param {
    min_size: 12.8
    max_size: 32
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_loc"
  top: "ctx_output2/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_loc_perm"
  top: "ctx_output2/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_conf"
  top: "ctx_output2/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_conf_perm"
  top: "ctx_output2/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output2"
  bottom: "data"
  top: "ctx_output2/relu_mbox_priorbox"
  prior_box_param {
    min_size: 32
    max_size: 96
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_loc"
  top: "ctx_output3/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_loc_perm"
  top: "ctx_output3/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output3"
  top: "ctx_output3/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output3/relu_mbox_conf"
  top: "ctx_output3/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output3/relu_mbox_conf_perm"
  top: "ctx_output3/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output3/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output3"
  bottom: "data"
  top: "ctx_output3/relu_mbox_priorbox"
  prior_box_param {
    min_size: 96
    max_size: 160
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_loc"
  top: "ctx_output4/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_loc_perm"
  top: "ctx_output4/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output4"
  top: "ctx_output4/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output4/relu_mbox_conf"
  top: "ctx_output4/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output4/relu_mbox_conf_perm"
  top: "ctx_output4/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output4/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output4"
  bottom: "data"
  top: "ctx_output4/relu_mbox_priorbox"
  prior_box_param {
    min_size: 160
    max_size: 224
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_loc"
  top: "ctx_output5/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_loc_perm"
  top: "ctx_output5/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output5"
  top: "ctx_output5/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output5/relu_mbox_conf"
  top: "ctx_output5/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output5/relu_mbox_conf_perm"
  top: "ctx_output5/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output5/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output5"
  bottom: "data"
  top: "ctx_output5/relu_mbox_priorbox"
  prior_box_param {
    min_size: 224
    max_size: 288
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_loc"
  top: "ctx_output6/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_loc_perm"
  top: "ctx_output6/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output6"
  top: "ctx_output6/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output6/relu_mbox_conf"
  top: "ctx_output6/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output6/relu_mbox_conf_perm"
  top: "ctx_output6/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output6/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output6"
  bottom: "data"
  top: "ctx_output6/relu_mbox_priorbox"
  prior_box_param {
    min_size: 288
    max_size: 352
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_loc_flat"
  bottom: "ctx_output2/relu_mbox_loc_flat"
  bottom: "ctx_output3/relu_mbox_loc_flat"
  bottom: "ctx_output4/relu_mbox_loc_flat"
  bottom: "ctx_output5/relu_mbox_loc_flat"
  bottom: "ctx_output6/relu_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_conf_flat"
  bottom: "ctx_output2/relu_mbox_conf_flat"
  bottom: "ctx_output3/relu_mbox_conf_flat"
  bottom: "ctx_output4/relu_mbox_conf_flat"
  bottom: "ctx_output5/relu_mbox_conf_flat"
  bottom: "ctx_output6/relu_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "ctx_output1/relu_mbox_priorbox"
  bottom: "ctx_output2/relu_mbox_priorbox"
  bottom: "ctx_output3/relu_mbox_priorbox"
  bottom: "ctx_output4/relu_mbox_priorbox"
  bottom: "ctx_output5/relu_mbox_priorbox"
  bottom: "ctx_output6/relu_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_reshape"
  type: "Reshape"
  bottom: "mbox_conf"
  top: "mbox_conf_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: -1
      dim: 4
    }
  }
}
layer {
  name: "mbox_conf_softmax"
  type: "Softmax"
  bottom: "mbox_conf_reshape"
  top: "mbox_conf_softmax"
  softmax_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_flatten"
  type: "Flatten"
  bottom: "mbox_conf_softmax"
  top: "mbox_conf_flatten"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "detection_out"
  type: "DetectionOutput"
  bottom: "mbox_loc"
  bottom: "mbox_conf_flatten"
  bottom: "mbox_priorbox"
  top: "detection_out"
  include {
    phase: TEST
  }
  detection_output_param {
    num_classes: 4
    share_location: true
    background_label_id: 0
    nms_param {
      nms_threshold: 0.45
      top_k: 400
    }
    save_output_param {
      output_directory: ""
      output_name_prefix: "comp4_det_test_"
      output_format: "VOC"
      label_map_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/labelmap.prototxt"
      name_size_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/test_name_size.txt"
      num_test_image: 3609
    }
    code_type: CENTER_SIZE
    keep_top_k: 200
    confidence_threshold: 0.01
  }
}
layer {
  name: "detection_eval"
  type: "DetectionEvaluate"
  bottom: "detection_out"
  bottom: "label"
  top: "detection_eval"
  include {
    phase: TEST
  }
  detection_evaluate_param {
    num_classes: 4
    background_label_id: 0
    overlap_threshold: 0.5
    evaluate_difficult_gt: true
    name_size_file: "/user/a0875091/files/work/github/weiliu89/caffe-ssd/data/TI_VGG16_720x368_V2/test_name_size.txt"
  }
}
I0324 08:35:34.710696 10003 net.cpp:104] Using FLOAT as default forward math type
I0324 08:35:34.710710 10003 net.cpp:110] Using FLOAT as default backward math type
I0324 08:35:34.710716 10003 layer_factory.hpp:136] Creating layer 'data' of type 'AnnotatedData'
I0324 08:35:34.710721 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.710746 10003 net.cpp:184] Created Layer data (0)
I0324 08:35:34.710752 10003 net.cpp:530] data -> data
I0324 08:35:34.710762 10003 net.cpp:530] data -> label
I0324 08:35:34.710777 10003 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 4
I0324 08:35:34.710789 10003 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0324 08:35:34.711581 10070 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_test_lmdb
I0324 08:35:34.721757 10003 annotated_data_layer.cpp:219] output data size: 4,3,320,768
I0324 08:35:34.721844 10003 annotated_data_layer.cpp:265] (0) Output data size: 4, 3, 320, 768
I0324 08:35:34.721905 10003 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0324 08:35:34.721947 10003 net.cpp:245] Setting up data
I0324 08:35:34.721961 10003 net.cpp:252] TEST Top shape for layer 0 'data' 4 3 320 768 (2949120)
I0324 08:35:34.721984 10003 net.cpp:252] TEST Top shape for layer 0 'data' 1 1 31 8 (248)
I0324 08:35:34.721994 10003 layer_factory.hpp:136] Creating layer 'data_data_0_split' of type 'Split'
I0324 08:35:34.722004 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.722018 10003 net.cpp:184] Created Layer data_data_0_split (1)
I0324 08:35:34.722024 10003 net.cpp:561] data_data_0_split <- data
I0324 08:35:34.722034 10003 net.cpp:530] data_data_0_split -> data_data_0_split_0
I0324 08:35:34.722045 10003 net.cpp:530] data_data_0_split -> data_data_0_split_1
I0324 08:35:34.722054 10003 net.cpp:530] data_data_0_split -> data_data_0_split_2
I0324 08:35:34.722061 10003 net.cpp:530] data_data_0_split -> data_data_0_split_3
I0324 08:35:34.722069 10003 net.cpp:530] data_data_0_split -> data_data_0_split_4
I0324 08:35:34.722076 10003 net.cpp:530] data_data_0_split -> data_data_0_split_5
I0324 08:35:34.722084 10003 net.cpp:530] data_data_0_split -> data_data_0_split_6
I0324 08:35:34.722261 10003 net.cpp:245] Setting up data_data_0_split
I0324 08:35:34.722276 10003 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 320 768 (2949120)
I0324 08:35:34.722285 10003 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 320 768 (2949120)
I0324 08:35:34.722291 10003 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 320 768 (2949120)
I0324 08:35:34.722298 10003 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 320 768 (2949120)
I0324 08:35:34.722306 10003 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 320 768 (2949120)
I0324 08:35:34.722313 10003 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 320 768 (2949120)
I0324 08:35:34.722321 10003 net.cpp:252] TEST Top shape for layer 1 'data_data_0_split' 4 3 320 768 (2949120)
I0324 08:35:34.722327 10003 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0324 08:35:34.722334 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.722345 10003 net.cpp:184] Created Layer data/bias (2)
I0324 08:35:34.722352 10003 net.cpp:561] data/bias <- data_data_0_split_0
I0324 08:35:34.722360 10003 net.cpp:530] data/bias -> data/bias
I0324 08:35:34.723712 10071 annotated_data_layer.cpp:111] (0) Parser threads: 1
I0324 08:35:34.723736 10071 annotated_data_layer.cpp:113] (0) Transformer threads: 1
I0324 08:35:34.723943 10003 net.cpp:245] Setting up data/bias
I0324 08:35:34.723961 10003 net.cpp:252] TEST Top shape for layer 2 'data/bias' 4 3 320 768 (2949120)
I0324 08:35:34.723975 10003 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0324 08:35:34.723984 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.724001 10003 net.cpp:184] Created Layer conv1a (3)
I0324 08:35:34.724009 10003 net.cpp:561] conv1a <- data/bias
I0324 08:35:34.724017 10003 net.cpp:530] conv1a -> conv1a
I0324 08:35:34.724617 10003 net.cpp:245] Setting up conv1a
I0324 08:35:34.724633 10003 net.cpp:252] TEST Top shape for layer 3 'conv1a' 4 32 160 384 (7864320)
I0324 08:35:34.724647 10003 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0324 08:35:34.724654 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.724668 10003 net.cpp:184] Created Layer conv1a/bn (4)
I0324 08:35:34.724675 10003 net.cpp:561] conv1a/bn <- conv1a
I0324 08:35:34.724683 10003 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0324 08:35:34.725632 10003 net.cpp:245] Setting up conv1a/bn
I0324 08:35:34.725647 10003 net.cpp:252] TEST Top shape for layer 4 'conv1a/bn' 4 32 160 384 (7864320)
I0324 08:35:34.725663 10003 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0324 08:35:34.725672 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.725680 10003 net.cpp:184] Created Layer conv1a/relu (5)
I0324 08:35:34.725687 10003 net.cpp:561] conv1a/relu <- conv1a
I0324 08:35:34.725715 10003 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0324 08:35:34.725728 10003 net.cpp:245] Setting up conv1a/relu
I0324 08:35:34.725735 10003 net.cpp:252] TEST Top shape for layer 5 'conv1a/relu' 4 32 160 384 (7864320)
I0324 08:35:34.725742 10003 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0324 08:35:34.725749 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.725762 10003 net.cpp:184] Created Layer conv1b (6)
I0324 08:35:34.725769 10003 net.cpp:561] conv1b <- conv1a
I0324 08:35:34.725776 10003 net.cpp:530] conv1b -> conv1b
I0324 08:35:34.726327 10003 net.cpp:245] Setting up conv1b
I0324 08:35:34.726343 10003 net.cpp:252] TEST Top shape for layer 6 'conv1b' 4 32 160 384 (7864320)
I0324 08:35:34.726356 10003 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0324 08:35:34.726363 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.726374 10003 net.cpp:184] Created Layer conv1b/bn (7)
I0324 08:35:34.726382 10003 net.cpp:561] conv1b/bn <- conv1b
I0324 08:35:34.726388 10003 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0324 08:35:34.727387 10003 net.cpp:245] Setting up conv1b/bn
I0324 08:35:34.727406 10003 net.cpp:252] TEST Top shape for layer 7 'conv1b/bn' 4 32 160 384 (7864320)
I0324 08:35:34.727421 10003 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0324 08:35:34.727427 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.727437 10003 net.cpp:184] Created Layer conv1b/relu (8)
I0324 08:35:34.727443 10003 net.cpp:561] conv1b/relu <- conv1b
I0324 08:35:34.727449 10003 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0324 08:35:34.727458 10003 net.cpp:245] Setting up conv1b/relu
I0324 08:35:34.727465 10003 net.cpp:252] TEST Top shape for layer 8 'conv1b/relu' 4 32 160 384 (7864320)
I0324 08:35:34.727475 10003 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0324 08:35:34.727483 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.727494 10003 net.cpp:184] Created Layer pool1 (9)
I0324 08:35:34.727501 10003 net.cpp:561] pool1 <- conv1b
I0324 08:35:34.727509 10003 net.cpp:530] pool1 -> pool1
I0324 08:35:34.727613 10003 net.cpp:245] Setting up pool1
I0324 08:35:34.727628 10003 net.cpp:252] TEST Top shape for layer 9 'pool1' 4 32 80 192 (1966080)
I0324 08:35:34.727635 10003 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0324 08:35:34.727643 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.727656 10003 net.cpp:184] Created Layer res2a_branch2a (10)
I0324 08:35:34.727663 10003 net.cpp:561] res2a_branch2a <- pool1
I0324 08:35:34.727670 10003 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0324 08:35:34.728920 10003 net.cpp:245] Setting up res2a_branch2a
I0324 08:35:34.728935 10003 net.cpp:252] TEST Top shape for layer 10 'res2a_branch2a' 4 64 80 192 (3932160)
I0324 08:35:34.728948 10003 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0324 08:35:34.728955 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.728966 10003 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0324 08:35:34.728972 10003 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0324 08:35:34.728979 10003 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0324 08:35:34.730016 10003 net.cpp:245] Setting up res2a_branch2a/bn
I0324 08:35:34.730031 10003 net.cpp:252] TEST Top shape for layer 11 'res2a_branch2a/bn' 4 64 80 192 (3932160)
I0324 08:35:34.730043 10003 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0324 08:35:34.730051 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.730057 10003 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0324 08:35:34.730073 10003 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0324 08:35:34.730080 10003 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0324 08:35:34.730088 10003 net.cpp:245] Setting up res2a_branch2a/relu
I0324 08:35:34.730095 10003 net.cpp:252] TEST Top shape for layer 12 'res2a_branch2a/relu' 4 64 80 192 (3932160)
I0324 08:35:34.730101 10003 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0324 08:35:34.730106 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.730120 10003 net.cpp:184] Created Layer res2a_branch2b (13)
I0324 08:35:34.730125 10003 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0324 08:35:34.730131 10003 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0324 08:35:34.730913 10003 net.cpp:245] Setting up res2a_branch2b
I0324 08:35:34.730926 10003 net.cpp:252] TEST Top shape for layer 13 'res2a_branch2b' 4 64 80 192 (3932160)
I0324 08:35:34.730937 10003 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0324 08:35:34.730942 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.730952 10003 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0324 08:35:34.730957 10003 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0324 08:35:34.730963 10003 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0324 08:35:34.731889 10003 net.cpp:245] Setting up res2a_branch2b/bn
I0324 08:35:34.731902 10003 net.cpp:252] TEST Top shape for layer 14 'res2a_branch2b/bn' 4 64 80 192 (3932160)
I0324 08:35:34.731915 10003 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0324 08:35:34.731921 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.731928 10003 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0324 08:35:34.731935 10003 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0324 08:35:34.731940 10003 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0324 08:35:34.731947 10003 net.cpp:245] Setting up res2a_branch2b/relu
I0324 08:35:34.731954 10003 net.cpp:252] TEST Top shape for layer 15 'res2a_branch2b/relu' 4 64 80 192 (3932160)
I0324 08:35:34.731959 10003 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0324 08:35:34.731964 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.731973 10003 net.cpp:184] Created Layer pool2 (16)
I0324 08:35:34.731978 10003 net.cpp:561] pool2 <- res2a_branch2b
I0324 08:35:34.731984 10003 net.cpp:530] pool2 -> pool2
I0324 08:35:34.732076 10003 net.cpp:245] Setting up pool2
I0324 08:35:34.732087 10003 net.cpp:252] TEST Top shape for layer 16 'pool2' 4 64 40 96 (983040)
I0324 08:35:34.732094 10003 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0324 08:35:34.732100 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.732113 10003 net.cpp:184] Created Layer res3a_branch2a (17)
I0324 08:35:34.732120 10003 net.cpp:561] res3a_branch2a <- pool2
I0324 08:35:34.732125 10003 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0324 08:35:34.735218 10003 net.cpp:245] Setting up res3a_branch2a
I0324 08:35:34.735244 10003 net.cpp:252] TEST Top shape for layer 17 'res3a_branch2a' 4 128 40 96 (1966080)
I0324 08:35:34.735255 10003 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0324 08:35:34.735262 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.735275 10003 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0324 08:35:34.735282 10003 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0324 08:35:34.735289 10003 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0324 08:35:34.736196 10003 net.cpp:245] Setting up res3a_branch2a/bn
I0324 08:35:34.736209 10003 net.cpp:252] TEST Top shape for layer 18 'res3a_branch2a/bn' 4 128 40 96 (1966080)
I0324 08:35:34.736227 10003 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0324 08:35:34.736245 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.736254 10003 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0324 08:35:34.736260 10003 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0324 08:35:34.736266 10003 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0324 08:35:34.736275 10003 net.cpp:245] Setting up res3a_branch2a/relu
I0324 08:35:34.736281 10003 net.cpp:252] TEST Top shape for layer 19 'res3a_branch2a/relu' 4 128 40 96 (1966080)
I0324 08:35:34.736287 10003 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0324 08:35:34.736294 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.736307 10003 net.cpp:184] Created Layer res3a_branch2b (20)
I0324 08:35:34.736312 10003 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0324 08:35:34.736318 10003 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0324 08:35:34.738155 10003 net.cpp:245] Setting up res3a_branch2b
I0324 08:35:34.738183 10003 net.cpp:252] TEST Top shape for layer 20 'res3a_branch2b' 4 128 40 96 (1966080)
I0324 08:35:34.738195 10003 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0324 08:35:34.738204 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.738215 10003 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0324 08:35:34.738222 10003 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0324 08:35:34.738229 10003 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0324 08:35:34.739143 10003 net.cpp:245] Setting up res3a_branch2b/bn
I0324 08:35:34.739156 10003 net.cpp:252] TEST Top shape for layer 21 'res3a_branch2b/bn' 4 128 40 96 (1966080)
I0324 08:35:34.739169 10003 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0324 08:35:34.739176 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.739183 10003 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0324 08:35:34.739189 10003 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0324 08:35:34.739195 10003 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0324 08:35:34.739203 10003 net.cpp:245] Setting up res3a_branch2b/relu
I0324 08:35:34.739209 10003 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b/relu' 4 128 40 96 (1966080)
I0324 08:35:34.739215 10003 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0324 08:35:34.739220 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.739228 10003 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (23)
I0324 08:35:34.739233 10003 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0324 08:35:34.739238 10003 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0324 08:35:34.739245 10003 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0324 08:35:34.739315 10003 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0324 08:35:34.739326 10003 net.cpp:252] TEST Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 4 128 40 96 (1966080)
I0324 08:35:34.739332 10003 net.cpp:252] TEST Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 4 128 40 96 (1966080)
I0324 08:35:34.739337 10003 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0324 08:35:34.739343 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.739354 10003 net.cpp:184] Created Layer pool3 (24)
I0324 08:35:34.739359 10003 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0324 08:35:34.739367 10003 net.cpp:530] pool3 -> pool3
I0324 08:35:34.739457 10003 net.cpp:245] Setting up pool3
I0324 08:35:34.739485 10003 net.cpp:252] TEST Top shape for layer 24 'pool3' 4 128 20 48 (491520)
I0324 08:35:34.739492 10003 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0324 08:35:34.739498 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.739512 10003 net.cpp:184] Created Layer res4a_branch2a (25)
I0324 08:35:34.739518 10003 net.cpp:561] res4a_branch2a <- pool3
I0324 08:35:34.739526 10003 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0324 08:35:34.751488 10003 net.cpp:245] Setting up res4a_branch2a
I0324 08:35:34.751516 10003 net.cpp:252] TEST Top shape for layer 25 'res4a_branch2a' 4 256 20 48 (983040)
I0324 08:35:34.751530 10003 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0324 08:35:34.751538 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.751551 10003 net.cpp:184] Created Layer res4a_branch2a/bn (26)
I0324 08:35:34.751559 10003 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0324 08:35:34.751567 10003 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0324 08:35:34.752518 10003 net.cpp:245] Setting up res4a_branch2a/bn
I0324 08:35:34.752532 10003 net.cpp:252] TEST Top shape for layer 26 'res4a_branch2a/bn' 4 256 20 48 (983040)
I0324 08:35:34.752547 10003 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0324 08:35:34.752554 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.752562 10003 net.cpp:184] Created Layer res4a_branch2a/relu (27)
I0324 08:35:34.752568 10003 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0324 08:35:34.752573 10003 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0324 08:35:34.752581 10003 net.cpp:245] Setting up res4a_branch2a/relu
I0324 08:35:34.752588 10003 net.cpp:252] TEST Top shape for layer 27 'res4a_branch2a/relu' 4 256 20 48 (983040)
I0324 08:35:34.752594 10003 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0324 08:35:34.752600 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.752617 10003 net.cpp:184] Created Layer res4a_branch2b (28)
I0324 08:35:34.752624 10003 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0324 08:35:34.752630 10003 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0324 08:35:34.758303 10003 net.cpp:245] Setting up res4a_branch2b
I0324 08:35:34.758323 10003 net.cpp:252] TEST Top shape for layer 28 'res4a_branch2b' 4 256 20 48 (983040)
I0324 08:35:34.758334 10003 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0324 08:35:34.758342 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.758355 10003 net.cpp:184] Created Layer res4a_branch2b/bn (29)
I0324 08:35:34.758363 10003 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0324 08:35:34.758370 10003 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0324 08:35:34.759325 10003 net.cpp:245] Setting up res4a_branch2b/bn
I0324 08:35:34.759340 10003 net.cpp:252] TEST Top shape for layer 29 'res4a_branch2b/bn' 4 256 20 48 (983040)
I0324 08:35:34.759351 10003 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0324 08:35:34.759358 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.759366 10003 net.cpp:184] Created Layer res4a_branch2b/relu (30)
I0324 08:35:34.759371 10003 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0324 08:35:34.759377 10003 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0324 08:35:34.759385 10003 net.cpp:245] Setting up res4a_branch2b/relu
I0324 08:35:34.759392 10003 net.cpp:252] TEST Top shape for layer 30 'res4a_branch2b/relu' 4 256 20 48 (983040)
I0324 08:35:34.759397 10003 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0324 08:35:34.759403 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.759438 10003 net.cpp:184] Created Layer pool4 (31)
I0324 08:35:34.759444 10003 net.cpp:561] pool4 <- res4a_branch2b
I0324 08:35:34.759451 10003 net.cpp:530] pool4 -> pool4
I0324 08:35:34.759552 10003 net.cpp:245] Setting up pool4
I0324 08:35:34.759563 10003 net.cpp:252] TEST Top shape for layer 31 'pool4' 4 256 10 24 (245760)
I0324 08:35:34.759570 10003 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0324 08:35:34.759577 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.759593 10003 net.cpp:184] Created Layer res5a_branch2a (32)
I0324 08:35:34.759601 10003 net.cpp:561] res5a_branch2a <- pool4
I0324 08:35:34.759608 10003 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0324 08:35:34.804234 10003 net.cpp:245] Setting up res5a_branch2a
I0324 08:35:34.804265 10003 net.cpp:252] TEST Top shape for layer 32 'res5a_branch2a' 4 512 10 24 (491520)
I0324 08:35:34.804278 10003 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0324 08:35:34.804286 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.804302 10003 net.cpp:184] Created Layer res5a_branch2a/bn (33)
I0324 08:35:34.804311 10003 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0324 08:35:34.804318 10003 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0324 08:35:34.805276 10003 net.cpp:245] Setting up res5a_branch2a/bn
I0324 08:35:34.805290 10003 net.cpp:252] TEST Top shape for layer 33 'res5a_branch2a/bn' 4 512 10 24 (491520)
I0324 08:35:34.805305 10003 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0324 08:35:34.805312 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.805320 10003 net.cpp:184] Created Layer res5a_branch2a/relu (34)
I0324 08:35:34.805326 10003 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0324 08:35:34.805332 10003 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0324 08:35:34.805341 10003 net.cpp:245] Setting up res5a_branch2a/relu
I0324 08:35:34.805347 10003 net.cpp:252] TEST Top shape for layer 34 'res5a_branch2a/relu' 4 512 10 24 (491520)
I0324 08:35:34.805353 10003 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0324 08:35:34.805358 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.805377 10003 net.cpp:184] Created Layer res5a_branch2b (35)
I0324 08:35:34.805382 10003 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0324 08:35:34.805388 10003 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0324 08:35:34.827934 10003 net.cpp:245] Setting up res5a_branch2b
I0324 08:35:34.827965 10003 net.cpp:252] TEST Top shape for layer 35 'res5a_branch2b' 4 512 10 24 (491520)
I0324 08:35:34.827991 10003 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0324 08:35:34.827998 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.828014 10003 net.cpp:184] Created Layer res5a_branch2b/bn (36)
I0324 08:35:34.828022 10003 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0324 08:35:34.828029 10003 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0324 08:35:34.828995 10003 net.cpp:245] Setting up res5a_branch2b/bn
I0324 08:35:34.829008 10003 net.cpp:252] TEST Top shape for layer 36 'res5a_branch2b/bn' 4 512 10 24 (491520)
I0324 08:35:34.829021 10003 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0324 08:35:34.829028 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.829036 10003 net.cpp:184] Created Layer res5a_branch2b/relu (37)
I0324 08:35:34.829042 10003 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0324 08:35:34.829048 10003 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0324 08:35:34.829058 10003 net.cpp:245] Setting up res5a_branch2b/relu
I0324 08:35:34.829087 10003 net.cpp:252] TEST Top shape for layer 37 'res5a_branch2b/relu' 4 512 10 24 (491520)
I0324 08:35:34.829093 10003 layer_factory.hpp:136] Creating layer 'res5a_branch2b_res5a_branch2b/relu_0_split' of type 'Split'
I0324 08:35:34.829099 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.829105 10003 net.cpp:184] Created Layer res5a_branch2b_res5a_branch2b/relu_0_split (38)
I0324 08:35:34.829113 10003 net.cpp:561] res5a_branch2b_res5a_branch2b/relu_0_split <- res5a_branch2b
I0324 08:35:34.829119 10003 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_0
I0324 08:35:34.829126 10003 net.cpp:530] res5a_branch2b_res5a_branch2b/relu_0_split -> res5a_branch2b_res5a_branch2b/relu_0_split_1
I0324 08:35:34.829200 10003 net.cpp:245] Setting up res5a_branch2b_res5a_branch2b/relu_0_split
I0324 08:35:34.829210 10003 net.cpp:252] TEST Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 4 512 10 24 (491520)
I0324 08:35:34.829217 10003 net.cpp:252] TEST Top shape for layer 38 'res5a_branch2b_res5a_branch2b/relu_0_split' 4 512 10 24 (491520)
I0324 08:35:34.829222 10003 layer_factory.hpp:136] Creating layer 'pool6' of type 'Pooling'
I0324 08:35:34.829228 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.829239 10003 net.cpp:184] Created Layer pool6 (39)
I0324 08:35:34.829246 10003 net.cpp:561] pool6 <- res5a_branch2b_res5a_branch2b/relu_0_split_0
I0324 08:35:34.829252 10003 net.cpp:530] pool6 -> pool6
I0324 08:35:34.829356 10003 net.cpp:245] Setting up pool6
I0324 08:35:34.829367 10003 net.cpp:252] TEST Top shape for layer 39 'pool6' 4 512 5 12 (122880)
I0324 08:35:34.829375 10003 layer_factory.hpp:136] Creating layer 'pool6_pool6_0_split' of type 'Split'
I0324 08:35:34.829380 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.829386 10003 net.cpp:184] Created Layer pool6_pool6_0_split (40)
I0324 08:35:34.829392 10003 net.cpp:561] pool6_pool6_0_split <- pool6
I0324 08:35:34.829398 10003 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_0
I0324 08:35:34.829406 10003 net.cpp:530] pool6_pool6_0_split -> pool6_pool6_0_split_1
I0324 08:35:34.829473 10003 net.cpp:245] Setting up pool6_pool6_0_split
I0324 08:35:34.829484 10003 net.cpp:252] TEST Top shape for layer 40 'pool6_pool6_0_split' 4 512 5 12 (122880)
I0324 08:35:34.829490 10003 net.cpp:252] TEST Top shape for layer 40 'pool6_pool6_0_split' 4 512 5 12 (122880)
I0324 08:35:34.829496 10003 layer_factory.hpp:136] Creating layer 'pool7' of type 'Pooling'
I0324 08:35:34.829502 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.829512 10003 net.cpp:184] Created Layer pool7 (41)
I0324 08:35:34.829519 10003 net.cpp:561] pool7 <- pool6_pool6_0_split_0
I0324 08:35:34.829525 10003 net.cpp:530] pool7 -> pool7
I0324 08:35:34.829619 10003 net.cpp:245] Setting up pool7
I0324 08:35:34.829630 10003 net.cpp:252] TEST Top shape for layer 41 'pool7' 4 512 3 6 (36864)
I0324 08:35:34.829636 10003 layer_factory.hpp:136] Creating layer 'pool7_pool7_0_split' of type 'Split'
I0324 08:35:34.829643 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.829651 10003 net.cpp:184] Created Layer pool7_pool7_0_split (42)
I0324 08:35:34.829656 10003 net.cpp:561] pool7_pool7_0_split <- pool7
I0324 08:35:34.829663 10003 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_0
I0324 08:35:34.829670 10003 net.cpp:530] pool7_pool7_0_split -> pool7_pool7_0_split_1
I0324 08:35:34.829746 10003 net.cpp:245] Setting up pool7_pool7_0_split
I0324 08:35:34.829758 10003 net.cpp:252] TEST Top shape for layer 42 'pool7_pool7_0_split' 4 512 3 6 (36864)
I0324 08:35:34.829766 10003 net.cpp:252] TEST Top shape for layer 42 'pool7_pool7_0_split' 4 512 3 6 (36864)
I0324 08:35:34.829771 10003 layer_factory.hpp:136] Creating layer 'pool8' of type 'Pooling'
I0324 08:35:34.829787 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.829800 10003 net.cpp:184] Created Layer pool8 (43)
I0324 08:35:34.829807 10003 net.cpp:561] pool8 <- pool7_pool7_0_split_0
I0324 08:35:34.829813 10003 net.cpp:530] pool8 -> pool8
I0324 08:35:34.829907 10003 net.cpp:245] Setting up pool8
I0324 08:35:34.829919 10003 net.cpp:252] TEST Top shape for layer 43 'pool8' 4 512 2 3 (12288)
I0324 08:35:34.829926 10003 layer_factory.hpp:136] Creating layer 'pool8_pool8_0_split' of type 'Split'
I0324 08:35:34.829931 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.829941 10003 net.cpp:184] Created Layer pool8_pool8_0_split (44)
I0324 08:35:34.829946 10003 net.cpp:561] pool8_pool8_0_split <- pool8
I0324 08:35:34.829952 10003 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_0
I0324 08:35:34.829959 10003 net.cpp:530] pool8_pool8_0_split -> pool8_pool8_0_split_1
I0324 08:35:34.830026 10003 net.cpp:245] Setting up pool8_pool8_0_split
I0324 08:35:34.830037 10003 net.cpp:252] TEST Top shape for layer 44 'pool8_pool8_0_split' 4 512 2 3 (12288)
I0324 08:35:34.830044 10003 net.cpp:252] TEST Top shape for layer 44 'pool8_pool8_0_split' 4 512 2 3 (12288)
I0324 08:35:34.830049 10003 layer_factory.hpp:136] Creating layer 'pool9' of type 'Pooling'
I0324 08:35:34.830055 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.830065 10003 net.cpp:184] Created Layer pool9 (45)
I0324 08:35:34.830071 10003 net.cpp:561] pool9 <- pool8_pool8_0_split_0
I0324 08:35:34.830077 10003 net.cpp:530] pool9 -> pool9
I0324 08:35:34.830171 10003 net.cpp:245] Setting up pool9
I0324 08:35:34.830183 10003 net.cpp:252] TEST Top shape for layer 45 'pool9' 4 512 1 2 (4096)
I0324 08:35:34.830188 10003 layer_factory.hpp:136] Creating layer 'ctx_output1' of type 'Convolution'
I0324 08:35:34.830194 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.830210 10003 net.cpp:184] Created Layer ctx_output1 (46)
I0324 08:35:34.830217 10003 net.cpp:561] ctx_output1 <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0324 08:35:34.830224 10003 net.cpp:530] ctx_output1 -> ctx_output1
I0324 08:35:34.831862 10003 net.cpp:245] Setting up ctx_output1
I0324 08:35:34.831876 10003 net.cpp:252] TEST Top shape for layer 46 'ctx_output1' 4 256 40 96 (3932160)
I0324 08:35:34.831885 10003 layer_factory.hpp:136] Creating layer 'ctx_output1/relu' of type 'ReLU'
I0324 08:35:34.831892 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.831898 10003 net.cpp:184] Created Layer ctx_output1/relu (47)
I0324 08:35:34.831904 10003 net.cpp:561] ctx_output1/relu <- ctx_output1
I0324 08:35:34.831910 10003 net.cpp:513] ctx_output1/relu -> ctx_output1 (in-place)
I0324 08:35:34.831920 10003 net.cpp:245] Setting up ctx_output1/relu
I0324 08:35:34.831928 10003 net.cpp:252] TEST Top shape for layer 47 'ctx_output1/relu' 4 256 40 96 (3932160)
I0324 08:35:34.831933 10003 layer_factory.hpp:136] Creating layer 'ctx_output1_ctx_output1/relu_0_split' of type 'Split'
I0324 08:35:34.831938 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.831945 10003 net.cpp:184] Created Layer ctx_output1_ctx_output1/relu_0_split (48)
I0324 08:35:34.831950 10003 net.cpp:561] ctx_output1_ctx_output1/relu_0_split <- ctx_output1
I0324 08:35:34.831956 10003 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_0
I0324 08:35:34.831962 10003 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_1
I0324 08:35:34.831969 10003 net.cpp:530] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_2
I0324 08:35:34.832067 10003 net.cpp:245] Setting up ctx_output1_ctx_output1/relu_0_split
I0324 08:35:34.832077 10003 net.cpp:252] TEST Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 4 256 40 96 (3932160)
I0324 08:35:34.832093 10003 net.cpp:252] TEST Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 4 256 40 96 (3932160)
I0324 08:35:34.832100 10003 net.cpp:252] TEST Top shape for layer 48 'ctx_output1_ctx_output1/relu_0_split' 4 256 40 96 (3932160)
I0324 08:35:34.832106 10003 layer_factory.hpp:136] Creating layer 'ctx_output2' of type 'Convolution'
I0324 08:35:34.832113 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.832129 10003 net.cpp:184] Created Layer ctx_output2 (49)
I0324 08:35:34.832135 10003 net.cpp:561] ctx_output2 <- res5a_branch2b_res5a_branch2b/relu_0_split_1
I0324 08:35:34.832142 10003 net.cpp:530] ctx_output2 -> ctx_output2
I0324 08:35:34.837450 10003 net.cpp:245] Setting up ctx_output2
I0324 08:35:34.837476 10003 net.cpp:252] TEST Top shape for layer 49 'ctx_output2' 4 256 10 24 (245760)
I0324 08:35:34.837487 10003 layer_factory.hpp:136] Creating layer 'ctx_output2/relu' of type 'ReLU'
I0324 08:35:34.837494 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.837504 10003 net.cpp:184] Created Layer ctx_output2/relu (50)
I0324 08:35:34.837512 10003 net.cpp:561] ctx_output2/relu <- ctx_output2
I0324 08:35:34.837518 10003 net.cpp:513] ctx_output2/relu -> ctx_output2 (in-place)
I0324 08:35:34.837527 10003 net.cpp:245] Setting up ctx_output2/relu
I0324 08:35:34.837534 10003 net.cpp:252] TEST Top shape for layer 50 'ctx_output2/relu' 4 256 10 24 (245760)
I0324 08:35:34.837539 10003 layer_factory.hpp:136] Creating layer 'ctx_output2_ctx_output2/relu_0_split' of type 'Split'
I0324 08:35:34.837544 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.837551 10003 net.cpp:184] Created Layer ctx_output2_ctx_output2/relu_0_split (51)
I0324 08:35:34.837556 10003 net.cpp:561] ctx_output2_ctx_output2/relu_0_split <- ctx_output2
I0324 08:35:34.837563 10003 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_0
I0324 08:35:34.837571 10003 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_1
I0324 08:35:34.837577 10003 net.cpp:530] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_2
I0324 08:35:34.837679 10003 net.cpp:245] Setting up ctx_output2_ctx_output2/relu_0_split
I0324 08:35:34.837705 10003 net.cpp:252] TEST Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 4 256 10 24 (245760)
I0324 08:35:34.837714 10003 net.cpp:252] TEST Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 4 256 10 24 (245760)
I0324 08:35:34.837720 10003 net.cpp:252] TEST Top shape for layer 51 'ctx_output2_ctx_output2/relu_0_split' 4 256 10 24 (245760)
I0324 08:35:34.837726 10003 layer_factory.hpp:136] Creating layer 'ctx_output3' of type 'Convolution'
I0324 08:35:34.837733 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.837752 10003 net.cpp:184] Created Layer ctx_output3 (52)
I0324 08:35:34.837759 10003 net.cpp:561] ctx_output3 <- pool6_pool6_0_split_1
I0324 08:35:34.837766 10003 net.cpp:530] ctx_output3 -> ctx_output3
I0324 08:35:34.844101 10003 net.cpp:245] Setting up ctx_output3
I0324 08:35:34.844125 10003 net.cpp:252] TEST Top shape for layer 52 'ctx_output3' 4 256 5 12 (61440)
I0324 08:35:34.844137 10003 layer_factory.hpp:136] Creating layer 'ctx_output3/relu' of type 'ReLU'
I0324 08:35:34.844146 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.844154 10003 net.cpp:184] Created Layer ctx_output3/relu (53)
I0324 08:35:34.844161 10003 net.cpp:561] ctx_output3/relu <- ctx_output3
I0324 08:35:34.844168 10003 net.cpp:513] ctx_output3/relu -> ctx_output3 (in-place)
I0324 08:35:34.844178 10003 net.cpp:245] Setting up ctx_output3/relu
I0324 08:35:34.844184 10003 net.cpp:252] TEST Top shape for layer 53 'ctx_output3/relu' 4 256 5 12 (61440)
I0324 08:35:34.844190 10003 layer_factory.hpp:136] Creating layer 'ctx_output3_ctx_output3/relu_0_split' of type 'Split'
I0324 08:35:34.844214 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.844224 10003 net.cpp:184] Created Layer ctx_output3_ctx_output3/relu_0_split (54)
I0324 08:35:34.844229 10003 net.cpp:561] ctx_output3_ctx_output3/relu_0_split <- ctx_output3
I0324 08:35:34.844235 10003 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_0
I0324 08:35:34.844244 10003 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_1
I0324 08:35:34.844254 10003 net.cpp:530] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_2
I0324 08:35:34.844353 10003 net.cpp:245] Setting up ctx_output3_ctx_output3/relu_0_split
I0324 08:35:34.844364 10003 net.cpp:252] TEST Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 4 256 5 12 (61440)
I0324 08:35:34.844372 10003 net.cpp:252] TEST Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 4 256 5 12 (61440)
I0324 08:35:34.844377 10003 net.cpp:252] TEST Top shape for layer 54 'ctx_output3_ctx_output3/relu_0_split' 4 256 5 12 (61440)
I0324 08:35:34.844383 10003 layer_factory.hpp:136] Creating layer 'ctx_output4' of type 'Convolution'
I0324 08:35:34.844389 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.844409 10003 net.cpp:184] Created Layer ctx_output4 (55)
I0324 08:35:34.844418 10003 net.cpp:561] ctx_output4 <- pool7_pool7_0_split_1
I0324 08:35:34.844424 10003 net.cpp:530] ctx_output4 -> ctx_output4
I0324 08:35:34.849445 10003 net.cpp:245] Setting up ctx_output4
I0324 08:35:34.849460 10003 net.cpp:252] TEST Top shape for layer 55 'ctx_output4' 4 256 3 6 (18432)
I0324 08:35:34.849469 10003 layer_factory.hpp:136] Creating layer 'ctx_output4/relu' of type 'ReLU'
I0324 08:35:34.849475 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.849483 10003 net.cpp:184] Created Layer ctx_output4/relu (56)
I0324 08:35:34.849488 10003 net.cpp:561] ctx_output4/relu <- ctx_output4
I0324 08:35:34.849494 10003 net.cpp:513] ctx_output4/relu -> ctx_output4 (in-place)
I0324 08:35:34.849504 10003 net.cpp:245] Setting up ctx_output4/relu
I0324 08:35:34.849511 10003 net.cpp:252] TEST Top shape for layer 56 'ctx_output4/relu' 4 256 3 6 (18432)
I0324 08:35:34.849516 10003 layer_factory.hpp:136] Creating layer 'ctx_output4_ctx_output4/relu_0_split' of type 'Split'
I0324 08:35:34.849521 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.849529 10003 net.cpp:184] Created Layer ctx_output4_ctx_output4/relu_0_split (57)
I0324 08:35:34.849534 10003 net.cpp:561] ctx_output4_ctx_output4/relu_0_split <- ctx_output4
I0324 08:35:34.849539 10003 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_0
I0324 08:35:34.849547 10003 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_1
I0324 08:35:34.849555 10003 net.cpp:530] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_2
I0324 08:35:34.849653 10003 net.cpp:245] Setting up ctx_output4_ctx_output4/relu_0_split
I0324 08:35:34.849664 10003 net.cpp:252] TEST Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 4 256 3 6 (18432)
I0324 08:35:34.849671 10003 net.cpp:252] TEST Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 4 256 3 6 (18432)
I0324 08:35:34.849678 10003 net.cpp:252] TEST Top shape for layer 57 'ctx_output4_ctx_output4/relu_0_split' 4 256 3 6 (18432)
I0324 08:35:34.849684 10003 layer_factory.hpp:136] Creating layer 'ctx_output5' of type 'Convolution'
I0324 08:35:34.849689 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.849721 10003 net.cpp:184] Created Layer ctx_output5 (58)
I0324 08:35:34.849728 10003 net.cpp:561] ctx_output5 <- pool8_pool8_0_split_1
I0324 08:35:34.849736 10003 net.cpp:530] ctx_output5 -> ctx_output5
I0324 08:35:34.854785 10003 net.cpp:245] Setting up ctx_output5
I0324 08:35:34.854800 10003 net.cpp:252] TEST Top shape for layer 58 'ctx_output5' 4 256 2 3 (6144)
I0324 08:35:34.854809 10003 layer_factory.hpp:136] Creating layer 'ctx_output5/relu' of type 'ReLU'
I0324 08:35:34.854815 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.854827 10003 net.cpp:184] Created Layer ctx_output5/relu (59)
I0324 08:35:34.854835 10003 net.cpp:561] ctx_output5/relu <- ctx_output5
I0324 08:35:34.854840 10003 net.cpp:513] ctx_output5/relu -> ctx_output5 (in-place)
I0324 08:35:34.854848 10003 net.cpp:245] Setting up ctx_output5/relu
I0324 08:35:34.854856 10003 net.cpp:252] TEST Top shape for layer 59 'ctx_output5/relu' 4 256 2 3 (6144)
I0324 08:35:34.854861 10003 layer_factory.hpp:136] Creating layer 'ctx_output5_ctx_output5/relu_0_split' of type 'Split'
I0324 08:35:34.854866 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.854876 10003 net.cpp:184] Created Layer ctx_output5_ctx_output5/relu_0_split (60)
I0324 08:35:34.854881 10003 net.cpp:561] ctx_output5_ctx_output5/relu_0_split <- ctx_output5
I0324 08:35:34.854887 10003 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_0
I0324 08:35:34.854893 10003 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_1
I0324 08:35:34.854899 10003 net.cpp:530] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_2
I0324 08:35:34.854997 10003 net.cpp:245] Setting up ctx_output5_ctx_output5/relu_0_split
I0324 08:35:34.855012 10003 net.cpp:252] TEST Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 4 256 2 3 (6144)
I0324 08:35:34.855020 10003 net.cpp:252] TEST Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 4 256 2 3 (6144)
I0324 08:35:34.855026 10003 net.cpp:252] TEST Top shape for layer 60 'ctx_output5_ctx_output5/relu_0_split' 4 256 2 3 (6144)
I0324 08:35:34.855031 10003 layer_factory.hpp:136] Creating layer 'ctx_output6' of type 'Convolution'
I0324 08:35:34.855037 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.855052 10003 net.cpp:184] Created Layer ctx_output6 (61)
I0324 08:35:34.855059 10003 net.cpp:561] ctx_output6 <- pool9
I0324 08:35:34.855067 10003 net.cpp:530] ctx_output6 -> ctx_output6
I0324 08:35:34.860113 10003 net.cpp:245] Setting up ctx_output6
I0324 08:35:34.860131 10003 net.cpp:252] TEST Top shape for layer 61 'ctx_output6' 4 256 1 2 (2048)
I0324 08:35:34.860141 10003 layer_factory.hpp:136] Creating layer 'ctx_output6/relu' of type 'ReLU'
I0324 08:35:34.860147 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.860157 10003 net.cpp:184] Created Layer ctx_output6/relu (62)
I0324 08:35:34.860163 10003 net.cpp:561] ctx_output6/relu <- ctx_output6
I0324 08:35:34.860169 10003 net.cpp:513] ctx_output6/relu -> ctx_output6 (in-place)
I0324 08:35:34.860178 10003 net.cpp:245] Setting up ctx_output6/relu
I0324 08:35:34.860184 10003 net.cpp:252] TEST Top shape for layer 62 'ctx_output6/relu' 4 256 1 2 (2048)
I0324 08:35:34.860190 10003 layer_factory.hpp:136] Creating layer 'ctx_output6_ctx_output6/relu_0_split' of type 'Split'
I0324 08:35:34.860195 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.860203 10003 net.cpp:184] Created Layer ctx_output6_ctx_output6/relu_0_split (63)
I0324 08:35:34.860209 10003 net.cpp:561] ctx_output6_ctx_output6/relu_0_split <- ctx_output6
I0324 08:35:34.860214 10003 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_0
I0324 08:35:34.860221 10003 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_1
I0324 08:35:34.860229 10003 net.cpp:530] ctx_output6_ctx_output6/relu_0_split -> ctx_output6_ctx_output6/relu_0_split_2
I0324 08:35:34.860327 10003 net.cpp:245] Setting up ctx_output6_ctx_output6/relu_0_split
I0324 08:35:34.860353 10003 net.cpp:252] TEST Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 4 256 1 2 (2048)
I0324 08:35:34.860361 10003 net.cpp:252] TEST Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 4 256 1 2 (2048)
I0324 08:35:34.860368 10003 net.cpp:252] TEST Top shape for layer 63 'ctx_output6_ctx_output6/relu_0_split' 4 256 1 2 (2048)
I0324 08:35:34.860373 10003 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc' of type 'Convolution'
I0324 08:35:34.860378 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.860399 10003 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc (64)
I0324 08:35:34.860405 10003 net.cpp:561] ctx_output1/relu_mbox_loc <- ctx_output1_ctx_output1/relu_0_split_0
I0324 08:35:34.860412 10003 net.cpp:530] ctx_output1/relu_mbox_loc -> ctx_output1/relu_mbox_loc
I0324 08:35:34.861071 10003 net.cpp:245] Setting up ctx_output1/relu_mbox_loc
I0324 08:35:34.861085 10003 net.cpp:252] TEST Top shape for layer 64 'ctx_output1/relu_mbox_loc' 4 16 40 96 (245760)
I0324 08:35:34.861094 10003 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_perm' of type 'Permute'
I0324 08:35:34.861101 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.861112 10003 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_perm (65)
I0324 08:35:34.861119 10003 net.cpp:561] ctx_output1/relu_mbox_loc_perm <- ctx_output1/relu_mbox_loc
I0324 08:35:34.861125 10003 net.cpp:530] ctx_output1/relu_mbox_loc_perm -> ctx_output1/relu_mbox_loc_perm
I0324 08:35:34.861328 10003 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_perm
I0324 08:35:34.861340 10003 net.cpp:252] TEST Top shape for layer 65 'ctx_output1/relu_mbox_loc_perm' 4 40 96 16 (245760)
I0324 08:35:34.861346 10003 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_loc_flat' of type 'Flatten'
I0324 08:35:34.861352 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.861361 10003 net.cpp:184] Created Layer ctx_output1/relu_mbox_loc_flat (66)
I0324 08:35:34.861366 10003 net.cpp:561] ctx_output1/relu_mbox_loc_flat <- ctx_output1/relu_mbox_loc_perm
I0324 08:35:34.861371 10003 net.cpp:530] ctx_output1/relu_mbox_loc_flat -> ctx_output1/relu_mbox_loc_flat
I0324 08:35:34.861418 10003 net.cpp:245] Setting up ctx_output1/relu_mbox_loc_flat
I0324 08:35:34.861430 10003 net.cpp:252] TEST Top shape for layer 66 'ctx_output1/relu_mbox_loc_flat' 4 61440 (245760)
I0324 08:35:34.861436 10003 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf' of type 'Convolution'
I0324 08:35:34.861443 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.861459 10003 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf (67)
I0324 08:35:34.861466 10003 net.cpp:561] ctx_output1/relu_mbox_conf <- ctx_output1_ctx_output1/relu_0_split_1
I0324 08:35:34.861474 10003 net.cpp:530] ctx_output1/relu_mbox_conf -> ctx_output1/relu_mbox_conf
I0324 08:35:34.862133 10003 net.cpp:245] Setting up ctx_output1/relu_mbox_conf
I0324 08:35:34.862148 10003 net.cpp:252] TEST Top shape for layer 67 'ctx_output1/relu_mbox_conf' 4 16 40 96 (245760)
I0324 08:35:34.862156 10003 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_perm' of type 'Permute'
I0324 08:35:34.862162 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.862174 10003 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_perm (68)
I0324 08:35:34.862181 10003 net.cpp:561] ctx_output1/relu_mbox_conf_perm <- ctx_output1/relu_mbox_conf
I0324 08:35:34.862187 10003 net.cpp:530] ctx_output1/relu_mbox_conf_perm -> ctx_output1/relu_mbox_conf_perm
I0324 08:35:34.862385 10003 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_perm
I0324 08:35:34.862397 10003 net.cpp:252] TEST Top shape for layer 68 'ctx_output1/relu_mbox_conf_perm' 4 40 96 16 (245760)
I0324 08:35:34.862413 10003 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_conf_flat' of type 'Flatten'
I0324 08:35:34.862419 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.862429 10003 net.cpp:184] Created Layer ctx_output1/relu_mbox_conf_flat (69)
I0324 08:35:34.862435 10003 net.cpp:561] ctx_output1/relu_mbox_conf_flat <- ctx_output1/relu_mbox_conf_perm
I0324 08:35:34.862442 10003 net.cpp:530] ctx_output1/relu_mbox_conf_flat -> ctx_output1/relu_mbox_conf_flat
I0324 08:35:34.862488 10003 net.cpp:245] Setting up ctx_output1/relu_mbox_conf_flat
I0324 08:35:34.862499 10003 net.cpp:252] TEST Top shape for layer 69 'ctx_output1/relu_mbox_conf_flat' 4 61440 (245760)
I0324 08:35:34.862505 10003 layer_factory.hpp:136] Creating layer 'ctx_output1/relu_mbox_priorbox' of type 'PriorBox'
I0324 08:35:34.862511 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.862519 10003 net.cpp:184] Created Layer ctx_output1/relu_mbox_priorbox (70)
I0324 08:35:34.862525 10003 net.cpp:561] ctx_output1/relu_mbox_priorbox <- ctx_output1_ctx_output1/relu_0_split_2
I0324 08:35:34.862531 10003 net.cpp:561] ctx_output1/relu_mbox_priorbox <- data_data_0_split_1
I0324 08:35:34.862538 10003 net.cpp:530] ctx_output1/relu_mbox_priorbox -> ctx_output1/relu_mbox_priorbox
I0324 08:35:34.862588 10003 net.cpp:245] Setting up ctx_output1/relu_mbox_priorbox
I0324 08:35:34.862599 10003 net.cpp:252] TEST Top shape for layer 70 'ctx_output1/relu_mbox_priorbox' 1 2 61440 (122880)
I0324 08:35:34.862606 10003 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc' of type 'Convolution'
I0324 08:35:34.862612 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.862628 10003 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc (71)
I0324 08:35:34.862635 10003 net.cpp:561] ctx_output2/relu_mbox_loc <- ctx_output2_ctx_output2/relu_0_split_0
I0324 08:35:34.862643 10003 net.cpp:530] ctx_output2/relu_mbox_loc -> ctx_output2/relu_mbox_loc
I0324 08:35:34.863369 10003 net.cpp:245] Setting up ctx_output2/relu_mbox_loc
I0324 08:35:34.863382 10003 net.cpp:252] TEST Top shape for layer 71 'ctx_output2/relu_mbox_loc' 4 24 10 24 (23040)
I0324 08:35:34.863391 10003 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_perm' of type 'Permute'
I0324 08:35:34.863397 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.863409 10003 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_perm (72)
I0324 08:35:34.863415 10003 net.cpp:561] ctx_output2/relu_mbox_loc_perm <- ctx_output2/relu_mbox_loc
I0324 08:35:34.863421 10003 net.cpp:530] ctx_output2/relu_mbox_loc_perm -> ctx_output2/relu_mbox_loc_perm
I0324 08:35:34.863621 10003 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_perm
I0324 08:35:34.863632 10003 net.cpp:252] TEST Top shape for layer 72 'ctx_output2/relu_mbox_loc_perm' 4 10 24 24 (23040)
I0324 08:35:34.863638 10003 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_loc_flat' of type 'Flatten'
I0324 08:35:34.863644 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.863653 10003 net.cpp:184] Created Layer ctx_output2/relu_mbox_loc_flat (73)
I0324 08:35:34.863659 10003 net.cpp:561] ctx_output2/relu_mbox_loc_flat <- ctx_output2/relu_mbox_loc_perm
I0324 08:35:34.863665 10003 net.cpp:530] ctx_output2/relu_mbox_loc_flat -> ctx_output2/relu_mbox_loc_flat
I0324 08:35:34.863710 10003 net.cpp:245] Setting up ctx_output2/relu_mbox_loc_flat
I0324 08:35:34.863721 10003 net.cpp:252] TEST Top shape for layer 73 'ctx_output2/relu_mbox_loc_flat' 4 5760 (23040)
I0324 08:35:34.863728 10003 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf' of type 'Convolution'
I0324 08:35:34.863734 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.863749 10003 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf (74)
I0324 08:35:34.863764 10003 net.cpp:561] ctx_output2/relu_mbox_conf <- ctx_output2_ctx_output2/relu_0_split_1
I0324 08:35:34.863771 10003 net.cpp:530] ctx_output2/relu_mbox_conf -> ctx_output2/relu_mbox_conf
I0324 08:35:34.864495 10003 net.cpp:245] Setting up ctx_output2/relu_mbox_conf
I0324 08:35:34.864508 10003 net.cpp:252] TEST Top shape for layer 74 'ctx_output2/relu_mbox_conf' 4 24 10 24 (23040)
I0324 08:35:34.864517 10003 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_perm' of type 'Permute'
I0324 08:35:34.864523 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.864536 10003 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_perm (75)
I0324 08:35:34.864542 10003 net.cpp:561] ctx_output2/relu_mbox_conf_perm <- ctx_output2/relu_mbox_conf
I0324 08:35:34.864547 10003 net.cpp:530] ctx_output2/relu_mbox_conf_perm -> ctx_output2/relu_mbox_conf_perm
I0324 08:35:34.864748 10003 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_perm
I0324 08:35:34.864760 10003 net.cpp:252] TEST Top shape for layer 75 'ctx_output2/relu_mbox_conf_perm' 4 10 24 24 (23040)
I0324 08:35:34.864768 10003 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_conf_flat' of type 'Flatten'
I0324 08:35:34.864773 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.864779 10003 net.cpp:184] Created Layer ctx_output2/relu_mbox_conf_flat (76)
I0324 08:35:34.864785 10003 net.cpp:561] ctx_output2/relu_mbox_conf_flat <- ctx_output2/relu_mbox_conf_perm
I0324 08:35:34.864791 10003 net.cpp:530] ctx_output2/relu_mbox_conf_flat -> ctx_output2/relu_mbox_conf_flat
I0324 08:35:34.864836 10003 net.cpp:245] Setting up ctx_output2/relu_mbox_conf_flat
I0324 08:35:34.864848 10003 net.cpp:252] TEST Top shape for layer 76 'ctx_output2/relu_mbox_conf_flat' 4 5760 (23040)
I0324 08:35:34.864854 10003 layer_factory.hpp:136] Creating layer 'ctx_output2/relu_mbox_priorbox' of type 'PriorBox'
I0324 08:35:34.864859 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.864867 10003 net.cpp:184] Created Layer ctx_output2/relu_mbox_priorbox (77)
I0324 08:35:34.864873 10003 net.cpp:561] ctx_output2/relu_mbox_priorbox <- ctx_output2_ctx_output2/relu_0_split_2
I0324 08:35:34.864879 10003 net.cpp:561] ctx_output2/relu_mbox_priorbox <- data_data_0_split_2
I0324 08:35:34.864886 10003 net.cpp:530] ctx_output2/relu_mbox_priorbox -> ctx_output2/relu_mbox_priorbox
I0324 08:35:34.864933 10003 net.cpp:245] Setting up ctx_output2/relu_mbox_priorbox
I0324 08:35:34.864944 10003 net.cpp:252] TEST Top shape for layer 77 'ctx_output2/relu_mbox_priorbox' 1 2 5760 (11520)
I0324 08:35:34.864951 10003 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc' of type 'Convolution'
I0324 08:35:34.864956 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.864972 10003 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc (78)
I0324 08:35:34.864979 10003 net.cpp:561] ctx_output3/relu_mbox_loc <- ctx_output3_ctx_output3/relu_0_split_0
I0324 08:35:34.864986 10003 net.cpp:530] ctx_output3/relu_mbox_loc -> ctx_output3/relu_mbox_loc
I0324 08:35:34.865708 10003 net.cpp:245] Setting up ctx_output3/relu_mbox_loc
I0324 08:35:34.865722 10003 net.cpp:252] TEST Top shape for layer 78 'ctx_output3/relu_mbox_loc' 4 24 5 12 (5760)
I0324 08:35:34.865731 10003 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_perm' of type 'Permute'
I0324 08:35:34.865737 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.865748 10003 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_perm (79)
I0324 08:35:34.865754 10003 net.cpp:561] ctx_output3/relu_mbox_loc_perm <- ctx_output3/relu_mbox_loc
I0324 08:35:34.865761 10003 net.cpp:530] ctx_output3/relu_mbox_loc_perm -> ctx_output3/relu_mbox_loc_perm
I0324 08:35:34.865963 10003 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_perm
I0324 08:35:34.865985 10003 net.cpp:252] TEST Top shape for layer 79 'ctx_output3/relu_mbox_loc_perm' 4 5 12 24 (5760)
I0324 08:35:34.865993 10003 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_loc_flat' of type 'Flatten'
I0324 08:35:34.865998 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.866008 10003 net.cpp:184] Created Layer ctx_output3/relu_mbox_loc_flat (80)
I0324 08:35:34.866014 10003 net.cpp:561] ctx_output3/relu_mbox_loc_flat <- ctx_output3/relu_mbox_loc_perm
I0324 08:35:34.866019 10003 net.cpp:530] ctx_output3/relu_mbox_loc_flat -> ctx_output3/relu_mbox_loc_flat
I0324 08:35:34.866065 10003 net.cpp:245] Setting up ctx_output3/relu_mbox_loc_flat
I0324 08:35:34.866076 10003 net.cpp:252] TEST Top shape for layer 80 'ctx_output3/relu_mbox_loc_flat' 4 1440 (5760)
I0324 08:35:34.866083 10003 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf' of type 'Convolution'
I0324 08:35:34.866088 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.866106 10003 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf (81)
I0324 08:35:34.866113 10003 net.cpp:561] ctx_output3/relu_mbox_conf <- ctx_output3_ctx_output3/relu_0_split_1
I0324 08:35:34.866120 10003 net.cpp:530] ctx_output3/relu_mbox_conf -> ctx_output3/relu_mbox_conf
I0324 08:35:34.866842 10003 net.cpp:245] Setting up ctx_output3/relu_mbox_conf
I0324 08:35:34.866856 10003 net.cpp:252] TEST Top shape for layer 81 'ctx_output3/relu_mbox_conf' 4 24 5 12 (5760)
I0324 08:35:34.866865 10003 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_perm' of type 'Permute'
I0324 08:35:34.866871 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.866883 10003 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_perm (82)
I0324 08:35:34.866888 10003 net.cpp:561] ctx_output3/relu_mbox_conf_perm <- ctx_output3/relu_mbox_conf
I0324 08:35:34.866894 10003 net.cpp:530] ctx_output3/relu_mbox_conf_perm -> ctx_output3/relu_mbox_conf_perm
I0324 08:35:34.867094 10003 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_perm
I0324 08:35:34.867106 10003 net.cpp:252] TEST Top shape for layer 82 'ctx_output3/relu_mbox_conf_perm' 4 5 12 24 (5760)
I0324 08:35:34.867112 10003 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_conf_flat' of type 'Flatten'
I0324 08:35:34.867117 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.867126 10003 net.cpp:184] Created Layer ctx_output3/relu_mbox_conf_flat (83)
I0324 08:35:34.867133 10003 net.cpp:561] ctx_output3/relu_mbox_conf_flat <- ctx_output3/relu_mbox_conf_perm
I0324 08:35:34.867139 10003 net.cpp:530] ctx_output3/relu_mbox_conf_flat -> ctx_output3/relu_mbox_conf_flat
I0324 08:35:34.867187 10003 net.cpp:245] Setting up ctx_output3/relu_mbox_conf_flat
I0324 08:35:34.867198 10003 net.cpp:252] TEST Top shape for layer 83 'ctx_output3/relu_mbox_conf_flat' 4 1440 (5760)
I0324 08:35:34.867204 10003 layer_factory.hpp:136] Creating layer 'ctx_output3/relu_mbox_priorbox' of type 'PriorBox'
I0324 08:35:34.867210 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.867218 10003 net.cpp:184] Created Layer ctx_output3/relu_mbox_priorbox (84)
I0324 08:35:34.867224 10003 net.cpp:561] ctx_output3/relu_mbox_priorbox <- ctx_output3_ctx_output3/relu_0_split_2
I0324 08:35:34.867230 10003 net.cpp:561] ctx_output3/relu_mbox_priorbox <- data_data_0_split_3
I0324 08:35:34.867238 10003 net.cpp:530] ctx_output3/relu_mbox_priorbox -> ctx_output3/relu_mbox_priorbox
I0324 08:35:34.867285 10003 net.cpp:245] Setting up ctx_output3/relu_mbox_priorbox
I0324 08:35:34.867297 10003 net.cpp:252] TEST Top shape for layer 84 'ctx_output3/relu_mbox_priorbox' 1 2 1440 (2880)
I0324 08:35:34.867303 10003 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc' of type 'Convolution'
I0324 08:35:34.867308 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.867334 10003 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc (85)
I0324 08:35:34.867342 10003 net.cpp:561] ctx_output4/relu_mbox_loc <- ctx_output4_ctx_output4/relu_0_split_0
I0324 08:35:34.867349 10003 net.cpp:530] ctx_output4/relu_mbox_loc -> ctx_output4/relu_mbox_loc
I0324 08:35:34.868073 10003 net.cpp:245] Setting up ctx_output4/relu_mbox_loc
I0324 08:35:34.868086 10003 net.cpp:252] TEST Top shape for layer 85 'ctx_output4/relu_mbox_loc' 4 24 3 6 (1728)
I0324 08:35:34.868096 10003 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_perm' of type 'Permute'
I0324 08:35:34.868103 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.868113 10003 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_perm (86)
I0324 08:35:34.868119 10003 net.cpp:561] ctx_output4/relu_mbox_loc_perm <- ctx_output4/relu_mbox_loc
I0324 08:35:34.868125 10003 net.cpp:530] ctx_output4/relu_mbox_loc_perm -> ctx_output4/relu_mbox_loc_perm
I0324 08:35:34.868326 10003 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_perm
I0324 08:35:34.868337 10003 net.cpp:252] TEST Top shape for layer 86 'ctx_output4/relu_mbox_loc_perm' 4 3 6 24 (1728)
I0324 08:35:34.868343 10003 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_loc_flat' of type 'Flatten'
I0324 08:35:34.868350 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.868356 10003 net.cpp:184] Created Layer ctx_output4/relu_mbox_loc_flat (87)
I0324 08:35:34.868362 10003 net.cpp:561] ctx_output4/relu_mbox_loc_flat <- ctx_output4/relu_mbox_loc_perm
I0324 08:35:34.868368 10003 net.cpp:530] ctx_output4/relu_mbox_loc_flat -> ctx_output4/relu_mbox_loc_flat
I0324 08:35:34.868413 10003 net.cpp:245] Setting up ctx_output4/relu_mbox_loc_flat
I0324 08:35:34.868424 10003 net.cpp:252] TEST Top shape for layer 87 'ctx_output4/relu_mbox_loc_flat' 4 432 (1728)
I0324 08:35:34.868430 10003 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf' of type 'Convolution'
I0324 08:35:34.868436 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.868451 10003 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf (88)
I0324 08:35:34.868458 10003 net.cpp:561] ctx_output4/relu_mbox_conf <- ctx_output4_ctx_output4/relu_0_split_1
I0324 08:35:34.868464 10003 net.cpp:530] ctx_output4/relu_mbox_conf -> ctx_output4/relu_mbox_conf
I0324 08:35:34.869191 10003 net.cpp:245] Setting up ctx_output4/relu_mbox_conf
I0324 08:35:34.869206 10003 net.cpp:252] TEST Top shape for layer 88 'ctx_output4/relu_mbox_conf' 4 24 3 6 (1728)
I0324 08:35:34.869216 10003 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_perm' of type 'Permute'
I0324 08:35:34.869222 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.869233 10003 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_perm (89)
I0324 08:35:34.869240 10003 net.cpp:561] ctx_output4/relu_mbox_conf_perm <- ctx_output4/relu_mbox_conf
I0324 08:35:34.869246 10003 net.cpp:530] ctx_output4/relu_mbox_conf_perm -> ctx_output4/relu_mbox_conf_perm
I0324 08:35:34.869447 10003 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_perm
I0324 08:35:34.869459 10003 net.cpp:252] TEST Top shape for layer 89 'ctx_output4/relu_mbox_conf_perm' 4 3 6 24 (1728)
I0324 08:35:34.869465 10003 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_conf_flat' of type 'Flatten'
I0324 08:35:34.869472 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.869478 10003 net.cpp:184] Created Layer ctx_output4/relu_mbox_conf_flat (90)
I0324 08:35:34.869484 10003 net.cpp:561] ctx_output4/relu_mbox_conf_flat <- ctx_output4/relu_mbox_conf_perm
I0324 08:35:34.869490 10003 net.cpp:530] ctx_output4/relu_mbox_conf_flat -> ctx_output4/relu_mbox_conf_flat
I0324 08:35:34.869535 10003 net.cpp:245] Setting up ctx_output4/relu_mbox_conf_flat
I0324 08:35:34.869546 10003 net.cpp:252] TEST Top shape for layer 90 'ctx_output4/relu_mbox_conf_flat' 4 432 (1728)
I0324 08:35:34.869561 10003 layer_factory.hpp:136] Creating layer 'ctx_output4/relu_mbox_priorbox' of type 'PriorBox'
I0324 08:35:34.869568 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.869577 10003 net.cpp:184] Created Layer ctx_output4/relu_mbox_priorbox (91)
I0324 08:35:34.869583 10003 net.cpp:561] ctx_output4/relu_mbox_priorbox <- ctx_output4_ctx_output4/relu_0_split_2
I0324 08:35:34.869590 10003 net.cpp:561] ctx_output4/relu_mbox_priorbox <- data_data_0_split_4
I0324 08:35:34.869596 10003 net.cpp:530] ctx_output4/relu_mbox_priorbox -> ctx_output4/relu_mbox_priorbox
I0324 08:35:34.869644 10003 net.cpp:245] Setting up ctx_output4/relu_mbox_priorbox
I0324 08:35:34.869655 10003 net.cpp:252] TEST Top shape for layer 91 'ctx_output4/relu_mbox_priorbox' 1 2 432 (864)
I0324 08:35:34.869662 10003 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc' of type 'Convolution'
I0324 08:35:34.869668 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.869685 10003 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc (92)
I0324 08:35:34.869699 10003 net.cpp:561] ctx_output5/relu_mbox_loc <- ctx_output5_ctx_output5/relu_0_split_0
I0324 08:35:34.869705 10003 net.cpp:530] ctx_output5/relu_mbox_loc -> ctx_output5/relu_mbox_loc
I0324 08:35:34.870358 10003 net.cpp:245] Setting up ctx_output5/relu_mbox_loc
I0324 08:35:34.870371 10003 net.cpp:252] TEST Top shape for layer 92 'ctx_output5/relu_mbox_loc' 4 16 2 3 (384)
I0324 08:35:34.870380 10003 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_perm' of type 'Permute'
I0324 08:35:34.870386 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.870398 10003 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_perm (93)
I0324 08:35:34.870405 10003 net.cpp:561] ctx_output5/relu_mbox_loc_perm <- ctx_output5/relu_mbox_loc
I0324 08:35:34.870411 10003 net.cpp:530] ctx_output5/relu_mbox_loc_perm -> ctx_output5/relu_mbox_loc_perm
I0324 08:35:34.870611 10003 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_perm
I0324 08:35:34.870623 10003 net.cpp:252] TEST Top shape for layer 93 'ctx_output5/relu_mbox_loc_perm' 4 2 3 16 (384)
I0324 08:35:34.870630 10003 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_loc_flat' of type 'Flatten'
I0324 08:35:34.870635 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.870645 10003 net.cpp:184] Created Layer ctx_output5/relu_mbox_loc_flat (94)
I0324 08:35:34.870651 10003 net.cpp:561] ctx_output5/relu_mbox_loc_flat <- ctx_output5/relu_mbox_loc_perm
I0324 08:35:34.870656 10003 net.cpp:530] ctx_output5/relu_mbox_loc_flat -> ctx_output5/relu_mbox_loc_flat
I0324 08:35:34.870702 10003 net.cpp:245] Setting up ctx_output5/relu_mbox_loc_flat
I0324 08:35:34.870712 10003 net.cpp:252] TEST Top shape for layer 94 'ctx_output5/relu_mbox_loc_flat' 4 96 (384)
I0324 08:35:34.870718 10003 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf' of type 'Convolution'
I0324 08:35:34.870724 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.870739 10003 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf (95)
I0324 08:35:34.870746 10003 net.cpp:561] ctx_output5/relu_mbox_conf <- ctx_output5_ctx_output5/relu_0_split_1
I0324 08:35:34.870754 10003 net.cpp:530] ctx_output5/relu_mbox_conf -> ctx_output5/relu_mbox_conf
I0324 08:35:34.871405 10003 net.cpp:245] Setting up ctx_output5/relu_mbox_conf
I0324 08:35:34.871418 10003 net.cpp:252] TEST Top shape for layer 95 'ctx_output5/relu_mbox_conf' 4 16 2 3 (384)
I0324 08:35:34.871428 10003 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_perm' of type 'Permute'
I0324 08:35:34.871433 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.871444 10003 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_perm (96)
I0324 08:35:34.871460 10003 net.cpp:561] ctx_output5/relu_mbox_conf_perm <- ctx_output5/relu_mbox_conf
I0324 08:35:34.871469 10003 net.cpp:530] ctx_output5/relu_mbox_conf_perm -> ctx_output5/relu_mbox_conf_perm
I0324 08:35:34.871670 10003 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_perm
I0324 08:35:34.871682 10003 net.cpp:252] TEST Top shape for layer 96 'ctx_output5/relu_mbox_conf_perm' 4 2 3 16 (384)
I0324 08:35:34.871688 10003 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_conf_flat' of type 'Flatten'
I0324 08:35:34.871693 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.871702 10003 net.cpp:184] Created Layer ctx_output5/relu_mbox_conf_flat (97)
I0324 08:35:34.871708 10003 net.cpp:561] ctx_output5/relu_mbox_conf_flat <- ctx_output5/relu_mbox_conf_perm
I0324 08:35:34.871716 10003 net.cpp:530] ctx_output5/relu_mbox_conf_flat -> ctx_output5/relu_mbox_conf_flat
I0324 08:35:34.871760 10003 net.cpp:245] Setting up ctx_output5/relu_mbox_conf_flat
I0324 08:35:34.871771 10003 net.cpp:252] TEST Top shape for layer 97 'ctx_output5/relu_mbox_conf_flat' 4 96 (384)
I0324 08:35:34.871778 10003 layer_factory.hpp:136] Creating layer 'ctx_output5/relu_mbox_priorbox' of type 'PriorBox'
I0324 08:35:34.871783 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.871790 10003 net.cpp:184] Created Layer ctx_output5/relu_mbox_priorbox (98)
I0324 08:35:34.871796 10003 net.cpp:561] ctx_output5/relu_mbox_priorbox <- ctx_output5_ctx_output5/relu_0_split_2
I0324 08:35:34.871803 10003 net.cpp:561] ctx_output5/relu_mbox_priorbox <- data_data_0_split_5
I0324 08:35:34.871809 10003 net.cpp:530] ctx_output5/relu_mbox_priorbox -> ctx_output5/relu_mbox_priorbox
I0324 08:35:34.871856 10003 net.cpp:245] Setting up ctx_output5/relu_mbox_priorbox
I0324 08:35:34.871867 10003 net.cpp:252] TEST Top shape for layer 98 'ctx_output5/relu_mbox_priorbox' 1 2 96 (192)
I0324 08:35:34.871873 10003 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc' of type 'Convolution'
I0324 08:35:34.871879 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.871894 10003 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc (99)
I0324 08:35:34.871901 10003 net.cpp:561] ctx_output6/relu_mbox_loc <- ctx_output6_ctx_output6/relu_0_split_0
I0324 08:35:34.871908 10003 net.cpp:530] ctx_output6/relu_mbox_loc -> ctx_output6/relu_mbox_loc
I0324 08:35:34.872553 10003 net.cpp:245] Setting up ctx_output6/relu_mbox_loc
I0324 08:35:34.872566 10003 net.cpp:252] TEST Top shape for layer 99 'ctx_output6/relu_mbox_loc' 4 16 1 2 (128)
I0324 08:35:34.872575 10003 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_perm' of type 'Permute'
I0324 08:35:34.872581 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.872594 10003 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_perm (100)
I0324 08:35:34.872601 10003 net.cpp:561] ctx_output6/relu_mbox_loc_perm <- ctx_output6/relu_mbox_loc
I0324 08:35:34.872607 10003 net.cpp:530] ctx_output6/relu_mbox_loc_perm -> ctx_output6/relu_mbox_loc_perm
I0324 08:35:34.872807 10003 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_perm
I0324 08:35:34.872817 10003 net.cpp:252] TEST Top shape for layer 100 'ctx_output6/relu_mbox_loc_perm' 4 1 2 16 (128)
I0324 08:35:34.872823 10003 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_loc_flat' of type 'Flatten'
I0324 08:35:34.872829 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.872836 10003 net.cpp:184] Created Layer ctx_output6/relu_mbox_loc_flat (101)
I0324 08:35:34.872843 10003 net.cpp:561] ctx_output6/relu_mbox_loc_flat <- ctx_output6/relu_mbox_loc_perm
I0324 08:35:34.872848 10003 net.cpp:530] ctx_output6/relu_mbox_loc_flat -> ctx_output6/relu_mbox_loc_flat
I0324 08:35:34.872894 10003 net.cpp:245] Setting up ctx_output6/relu_mbox_loc_flat
I0324 08:35:34.872912 10003 net.cpp:252] TEST Top shape for layer 101 'ctx_output6/relu_mbox_loc_flat' 4 32 (128)
I0324 08:35:34.872920 10003 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf' of type 'Convolution'
I0324 08:35:34.872925 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.872942 10003 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf (102)
I0324 08:35:34.872951 10003 net.cpp:561] ctx_output6/relu_mbox_conf <- ctx_output6_ctx_output6/relu_0_split_1
I0324 08:35:34.872956 10003 net.cpp:530] ctx_output6/relu_mbox_conf -> ctx_output6/relu_mbox_conf
I0324 08:35:34.873612 10003 net.cpp:245] Setting up ctx_output6/relu_mbox_conf
I0324 08:35:34.873625 10003 net.cpp:252] TEST Top shape for layer 102 'ctx_output6/relu_mbox_conf' 4 16 1 2 (128)
I0324 08:35:34.873636 10003 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_perm' of type 'Permute'
I0324 08:35:34.873641 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.873653 10003 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_perm (103)
I0324 08:35:34.873659 10003 net.cpp:561] ctx_output6/relu_mbox_conf_perm <- ctx_output6/relu_mbox_conf
I0324 08:35:34.873666 10003 net.cpp:530] ctx_output6/relu_mbox_conf_perm -> ctx_output6/relu_mbox_conf_perm
I0324 08:35:34.873883 10003 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_perm
I0324 08:35:34.873895 10003 net.cpp:252] TEST Top shape for layer 103 'ctx_output6/relu_mbox_conf_perm' 4 1 2 16 (128)
I0324 08:35:34.873903 10003 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_conf_flat' of type 'Flatten'
I0324 08:35:34.873908 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.873915 10003 net.cpp:184] Created Layer ctx_output6/relu_mbox_conf_flat (104)
I0324 08:35:34.873920 10003 net.cpp:561] ctx_output6/relu_mbox_conf_flat <- ctx_output6/relu_mbox_conf_perm
I0324 08:35:34.873927 10003 net.cpp:530] ctx_output6/relu_mbox_conf_flat -> ctx_output6/relu_mbox_conf_flat
I0324 08:35:34.873972 10003 net.cpp:245] Setting up ctx_output6/relu_mbox_conf_flat
I0324 08:35:34.873983 10003 net.cpp:252] TEST Top shape for layer 104 'ctx_output6/relu_mbox_conf_flat' 4 32 (128)
I0324 08:35:34.873991 10003 layer_factory.hpp:136] Creating layer 'ctx_output6/relu_mbox_priorbox' of type 'PriorBox'
I0324 08:35:34.873996 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.874004 10003 net.cpp:184] Created Layer ctx_output6/relu_mbox_priorbox (105)
I0324 08:35:34.874009 10003 net.cpp:561] ctx_output6/relu_mbox_priorbox <- ctx_output6_ctx_output6/relu_0_split_2
I0324 08:35:34.874017 10003 net.cpp:561] ctx_output6/relu_mbox_priorbox <- data_data_0_split_6
I0324 08:35:34.874022 10003 net.cpp:530] ctx_output6/relu_mbox_priorbox -> ctx_output6/relu_mbox_priorbox
I0324 08:35:34.874069 10003 net.cpp:245] Setting up ctx_output6/relu_mbox_priorbox
I0324 08:35:34.874080 10003 net.cpp:252] TEST Top shape for layer 105 'ctx_output6/relu_mbox_priorbox' 1 2 32 (64)
I0324 08:35:34.874086 10003 layer_factory.hpp:136] Creating layer 'mbox_loc' of type 'Concat'
I0324 08:35:34.874091 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.874101 10003 net.cpp:184] Created Layer mbox_loc (106)
I0324 08:35:34.874107 10003 net.cpp:561] mbox_loc <- ctx_output1/relu_mbox_loc_flat
I0324 08:35:34.874114 10003 net.cpp:561] mbox_loc <- ctx_output2/relu_mbox_loc_flat
I0324 08:35:34.874120 10003 net.cpp:561] mbox_loc <- ctx_output3/relu_mbox_loc_flat
I0324 08:35:34.874126 10003 net.cpp:561] mbox_loc <- ctx_output4/relu_mbox_loc_flat
I0324 08:35:34.874132 10003 net.cpp:561] mbox_loc <- ctx_output5/relu_mbox_loc_flat
I0324 08:35:34.874137 10003 net.cpp:561] mbox_loc <- ctx_output6/relu_mbox_loc_flat
I0324 08:35:34.874143 10003 net.cpp:530] mbox_loc -> mbox_loc
I0324 08:35:34.874191 10003 net.cpp:245] Setting up mbox_loc
I0324 08:35:34.874210 10003 net.cpp:252] TEST Top shape for layer 106 'mbox_loc' 4 69200 (276800)
I0324 08:35:34.874217 10003 layer_factory.hpp:136] Creating layer 'mbox_conf' of type 'Concat'
I0324 08:35:34.874223 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.874230 10003 net.cpp:184] Created Layer mbox_conf (107)
I0324 08:35:34.874236 10003 net.cpp:561] mbox_conf <- ctx_output1/relu_mbox_conf_flat
I0324 08:35:34.874243 10003 net.cpp:561] mbox_conf <- ctx_output2/relu_mbox_conf_flat
I0324 08:35:34.874250 10003 net.cpp:561] mbox_conf <- ctx_output3/relu_mbox_conf_flat
I0324 08:35:34.874258 10003 net.cpp:561] mbox_conf <- ctx_output4/relu_mbox_conf_flat
I0324 08:35:34.874263 10003 net.cpp:561] mbox_conf <- ctx_output5/relu_mbox_conf_flat
I0324 08:35:34.874269 10003 net.cpp:561] mbox_conf <- ctx_output6/relu_mbox_conf_flat
I0324 08:35:34.874274 10003 net.cpp:530] mbox_conf -> mbox_conf
I0324 08:35:34.874320 10003 net.cpp:245] Setting up mbox_conf
I0324 08:35:34.874333 10003 net.cpp:252] TEST Top shape for layer 107 'mbox_conf' 4 69200 (276800)
I0324 08:35:34.874339 10003 layer_factory.hpp:136] Creating layer 'mbox_priorbox' of type 'Concat'
I0324 08:35:34.874346 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.874352 10003 net.cpp:184] Created Layer mbox_priorbox (108)
I0324 08:35:34.874358 10003 net.cpp:561] mbox_priorbox <- ctx_output1/relu_mbox_priorbox
I0324 08:35:34.874364 10003 net.cpp:561] mbox_priorbox <- ctx_output2/relu_mbox_priorbox
I0324 08:35:34.874370 10003 net.cpp:561] mbox_priorbox <- ctx_output3/relu_mbox_priorbox
I0324 08:35:34.874375 10003 net.cpp:561] mbox_priorbox <- ctx_output4/relu_mbox_priorbox
I0324 08:35:34.874382 10003 net.cpp:561] mbox_priorbox <- ctx_output5/relu_mbox_priorbox
I0324 08:35:34.874387 10003 net.cpp:561] mbox_priorbox <- ctx_output6/relu_mbox_priorbox
I0324 08:35:34.874392 10003 net.cpp:530] mbox_priorbox -> mbox_priorbox
I0324 08:35:34.874436 10003 net.cpp:245] Setting up mbox_priorbox
I0324 08:35:34.874447 10003 net.cpp:252] TEST Top shape for layer 108 'mbox_priorbox' 1 2 69200 (138400)
I0324 08:35:34.874454 10003 layer_factory.hpp:136] Creating layer 'mbox_conf_reshape' of type 'Reshape'
I0324 08:35:34.874459 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.874470 10003 net.cpp:184] Created Layer mbox_conf_reshape (109)
I0324 08:35:34.874476 10003 net.cpp:561] mbox_conf_reshape <- mbox_conf
I0324 08:35:34.874486 10003 net.cpp:530] mbox_conf_reshape -> mbox_conf_reshape
I0324 08:35:34.874533 10003 net.cpp:245] Setting up mbox_conf_reshape
I0324 08:35:34.874544 10003 net.cpp:252] TEST Top shape for layer 109 'mbox_conf_reshape' 4 17300 4 (276800)
I0324 08:35:34.874550 10003 layer_factory.hpp:136] Creating layer 'mbox_conf_softmax' of type 'Softmax'
I0324 08:35:34.874557 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.874577 10003 net.cpp:184] Created Layer mbox_conf_softmax (110)
I0324 08:35:34.874584 10003 net.cpp:561] mbox_conf_softmax <- mbox_conf_reshape
I0324 08:35:34.874590 10003 net.cpp:530] mbox_conf_softmax -> mbox_conf_softmax
I0324 08:35:34.874708 10003 net.cpp:245] Setting up mbox_conf_softmax
I0324 08:35:34.874719 10003 net.cpp:252] TEST Top shape for layer 110 'mbox_conf_softmax' 4 17300 4 (276800)
I0324 08:35:34.874725 10003 layer_factory.hpp:136] Creating layer 'mbox_conf_flatten' of type 'Flatten'
I0324 08:35:34.874732 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.874740 10003 net.cpp:184] Created Layer mbox_conf_flatten (111)
I0324 08:35:34.874745 10003 net.cpp:561] mbox_conf_flatten <- mbox_conf_softmax
I0324 08:35:34.874752 10003 net.cpp:530] mbox_conf_flatten -> mbox_conf_flatten
I0324 08:35:34.874799 10003 net.cpp:245] Setting up mbox_conf_flatten
I0324 08:35:34.874810 10003 net.cpp:252] TEST Top shape for layer 111 'mbox_conf_flatten' 4 69200 (276800)
I0324 08:35:34.874825 10003 layer_factory.hpp:136] Creating layer 'detection_out' of type 'DetectionOutput'
I0324 08:35:34.874831 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.874847 10003 net.cpp:184] Created Layer detection_out (112)
I0324 08:35:34.874855 10003 net.cpp:561] detection_out <- mbox_loc
I0324 08:35:34.874861 10003 net.cpp:561] detection_out <- mbox_conf_flatten
I0324 08:35:34.874866 10003 net.cpp:561] detection_out <- mbox_priorbox
I0324 08:35:34.874872 10003 net.cpp:530] detection_out -> detection_out
I0324 08:35:34.913203 10003 net.cpp:245] Setting up detection_out
I0324 08:35:34.913230 10003 net.cpp:252] TEST Top shape for layer 112 'detection_out' 1 1 1 7 (7)
I0324 08:35:34.913239 10003 layer_factory.hpp:136] Creating layer 'detection_eval' of type 'DetectionEvaluate'
I0324 08:35:34.913246 10003 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0324 08:35:34.913260 10003 net.cpp:184] Created Layer detection_eval (113)
I0324 08:35:34.913267 10003 net.cpp:561] detection_eval <- detection_out
I0324 08:35:34.913275 10003 net.cpp:561] detection_eval <- label
I0324 08:35:34.913281 10003 net.cpp:530] detection_eval -> detection_eval
I0324 08:35:34.914340 10003 net.cpp:245] Setting up detection_eval
I0324 08:35:34.914355 10003 net.cpp:252] TEST Top shape for layer 113 'detection_eval' 1 1 4 5 (20)
I0324 08:35:34.914361 10003 net.cpp:325] detection_eval does not need backward computation.
I0324 08:35:34.914366 10003 net.cpp:325] detection_out does not need backward computation.
I0324 08:35:34.914371 10003 net.cpp:325] mbox_conf_flatten does not need backward computation.
I0324 08:35:34.914377 10003 net.cpp:325] mbox_conf_softmax does not need backward computation.
I0324 08:35:34.914382 10003 net.cpp:325] mbox_conf_reshape does not need backward computation.
I0324 08:35:34.914386 10003 net.cpp:325] mbox_priorbox does not need backward computation.
I0324 08:35:34.914393 10003 net.cpp:325] mbox_conf does not need backward computation.
I0324 08:35:34.914399 10003 net.cpp:325] mbox_loc does not need backward computation.
I0324 08:35:34.914405 10003 net.cpp:325] ctx_output6/relu_mbox_priorbox does not need backward computation.
I0324 08:35:34.914412 10003 net.cpp:325] ctx_output6/relu_mbox_conf_flat does not need backward computation.
I0324 08:35:34.914417 10003 net.cpp:325] ctx_output6/relu_mbox_conf_perm does not need backward computation.
I0324 08:35:34.914422 10003 net.cpp:325] ctx_output6/relu_mbox_conf does not need backward computation.
I0324 08:35:34.914427 10003 net.cpp:325] ctx_output6/relu_mbox_loc_flat does not need backward computation.
I0324 08:35:34.914432 10003 net.cpp:325] ctx_output6/relu_mbox_loc_perm does not need backward computation.
I0324 08:35:34.914438 10003 net.cpp:325] ctx_output6/relu_mbox_loc does not need backward computation.
I0324 08:35:34.914443 10003 net.cpp:325] ctx_output5/relu_mbox_priorbox does not need backward computation.
I0324 08:35:34.914448 10003 net.cpp:325] ctx_output5/relu_mbox_conf_flat does not need backward computation.
I0324 08:35:34.914453 10003 net.cpp:325] ctx_output5/relu_mbox_conf_perm does not need backward computation.
I0324 08:35:34.914458 10003 net.cpp:325] ctx_output5/relu_mbox_conf does not need backward computation.
I0324 08:35:34.914463 10003 net.cpp:325] ctx_output5/relu_mbox_loc_flat does not need backward computation.
I0324 08:35:34.914466 10003 net.cpp:325] ctx_output5/relu_mbox_loc_perm does not need backward computation.
I0324 08:35:34.914471 10003 net.cpp:325] ctx_output5/relu_mbox_loc does not need backward computation.
I0324 08:35:34.914476 10003 net.cpp:325] ctx_output4/relu_mbox_priorbox does not need backward computation.
I0324 08:35:34.914482 10003 net.cpp:325] ctx_output4/relu_mbox_conf_flat does not need backward computation.
I0324 08:35:34.914487 10003 net.cpp:325] ctx_output4/relu_mbox_conf_perm does not need backward computation.
I0324 08:35:34.914492 10003 net.cpp:325] ctx_output4/relu_mbox_conf does not need backward computation.
I0324 08:35:34.914510 10003 net.cpp:325] ctx_output4/relu_mbox_loc_flat does not need backward computation.
I0324 08:35:34.914516 10003 net.cpp:325] ctx_output4/relu_mbox_loc_perm does not need backward computation.
I0324 08:35:34.914521 10003 net.cpp:325] ctx_output4/relu_mbox_loc does not need backward computation.
I0324 08:35:34.914526 10003 net.cpp:325] ctx_output3/relu_mbox_priorbox does not need backward computation.
I0324 08:35:34.914531 10003 net.cpp:325] ctx_output3/relu_mbox_conf_flat does not need backward computation.
I0324 08:35:34.914536 10003 net.cpp:325] ctx_output3/relu_mbox_conf_perm does not need backward computation.
I0324 08:35:34.914541 10003 net.cpp:325] ctx_output3/relu_mbox_conf does not need backward computation.
I0324 08:35:34.914546 10003 net.cpp:325] ctx_output3/relu_mbox_loc_flat does not need backward computation.
I0324 08:35:34.914551 10003 net.cpp:325] ctx_output3/relu_mbox_loc_perm does not need backward computation.
I0324 08:35:34.914556 10003 net.cpp:325] ctx_output3/relu_mbox_loc does not need backward computation.
I0324 08:35:34.914561 10003 net.cpp:325] ctx_output2/relu_mbox_priorbox does not need backward computation.
I0324 08:35:34.914566 10003 net.cpp:325] ctx_output2/relu_mbox_conf_flat does not need backward computation.
I0324 08:35:34.914572 10003 net.cpp:325] ctx_output2/relu_mbox_conf_perm does not need backward computation.
I0324 08:35:34.914577 10003 net.cpp:325] ctx_output2/relu_mbox_conf does not need backward computation.
I0324 08:35:34.914582 10003 net.cpp:325] ctx_output2/relu_mbox_loc_flat does not need backward computation.
I0324 08:35:34.914585 10003 net.cpp:325] ctx_output2/relu_mbox_loc_perm does not need backward computation.
I0324 08:35:34.914590 10003 net.cpp:325] ctx_output2/relu_mbox_loc does not need backward computation.
I0324 08:35:34.914597 10003 net.cpp:325] ctx_output1/relu_mbox_priorbox does not need backward computation.
I0324 08:35:34.914602 10003 net.cpp:325] ctx_output1/relu_mbox_conf_flat does not need backward computation.
I0324 08:35:34.914607 10003 net.cpp:325] ctx_output1/relu_mbox_conf_perm does not need backward computation.
I0324 08:35:34.914611 10003 net.cpp:325] ctx_output1/relu_mbox_conf does not need backward computation.
I0324 08:35:34.914616 10003 net.cpp:325] ctx_output1/relu_mbox_loc_flat does not need backward computation.
I0324 08:35:34.914621 10003 net.cpp:325] ctx_output1/relu_mbox_loc_perm does not need backward computation.
I0324 08:35:34.914626 10003 net.cpp:325] ctx_output1/relu_mbox_loc does not need backward computation.
I0324 08:35:34.914631 10003 net.cpp:325] ctx_output6_ctx_output6/relu_0_split does not need backward computation.
I0324 08:35:34.914636 10003 net.cpp:325] ctx_output6/relu does not need backward computation.
I0324 08:35:34.914641 10003 net.cpp:325] ctx_output6 does not need backward computation.
I0324 08:35:34.914646 10003 net.cpp:325] ctx_output5_ctx_output5/relu_0_split does not need backward computation.
I0324 08:35:34.914651 10003 net.cpp:325] ctx_output5/relu does not need backward computation.
I0324 08:35:34.914656 10003 net.cpp:325] ctx_output5 does not need backward computation.
I0324 08:35:34.914661 10003 net.cpp:325] ctx_output4_ctx_output4/relu_0_split does not need backward computation.
I0324 08:35:34.914666 10003 net.cpp:325] ctx_output4/relu does not need backward computation.
I0324 08:35:34.914671 10003 net.cpp:325] ctx_output4 does not need backward computation.
I0324 08:35:34.914676 10003 net.cpp:325] ctx_output3_ctx_output3/relu_0_split does not need backward computation.
I0324 08:35:34.914681 10003 net.cpp:325] ctx_output3/relu does not need backward computation.
I0324 08:35:34.914686 10003 net.cpp:325] ctx_output3 does not need backward computation.
I0324 08:35:34.914691 10003 net.cpp:325] ctx_output2_ctx_output2/relu_0_split does not need backward computation.
I0324 08:35:34.914695 10003 net.cpp:325] ctx_output2/relu does not need backward computation.
I0324 08:35:34.914700 10003 net.cpp:325] ctx_output2 does not need backward computation.
I0324 08:35:34.914705 10003 net.cpp:325] ctx_output1_ctx_output1/relu_0_split does not need backward computation.
I0324 08:35:34.914716 10003 net.cpp:325] ctx_output1/relu does not need backward computation.
I0324 08:35:34.914722 10003 net.cpp:325] ctx_output1 does not need backward computation.
I0324 08:35:34.914727 10003 net.cpp:325] pool9 does not need backward computation.
I0324 08:35:34.914732 10003 net.cpp:325] pool8_pool8_0_split does not need backward computation.
I0324 08:35:34.914737 10003 net.cpp:325] pool8 does not need backward computation.
I0324 08:35:34.914742 10003 net.cpp:325] pool7_pool7_0_split does not need backward computation.
I0324 08:35:34.914747 10003 net.cpp:325] pool7 does not need backward computation.
I0324 08:35:34.914752 10003 net.cpp:325] pool6_pool6_0_split does not need backward computation.
I0324 08:35:34.914757 10003 net.cpp:325] pool6 does not need backward computation.
I0324 08:35:34.914763 10003 net.cpp:325] res5a_branch2b_res5a_branch2b/relu_0_split does not need backward computation.
I0324 08:35:34.914768 10003 net.cpp:325] res5a_branch2b/relu does not need backward computation.
I0324 08:35:34.914772 10003 net.cpp:325] res5a_branch2b/bn does not need backward computation.
I0324 08:35:34.914777 10003 net.cpp:325] res5a_branch2b does not need backward computation.
I0324 08:35:34.914783 10003 net.cpp:325] res5a_branch2a/relu does not need backward computation.
I0324 08:35:34.914788 10003 net.cpp:325] res5a_branch2a/bn does not need backward computation.
I0324 08:35:34.914793 10003 net.cpp:325] res5a_branch2a does not need backward computation.
I0324 08:35:34.914796 10003 net.cpp:325] pool4 does not need backward computation.
I0324 08:35:34.914803 10003 net.cpp:325] res4a_branch2b/relu does not need backward computation.
I0324 08:35:34.914806 10003 net.cpp:325] res4a_branch2b/bn does not need backward computation.
I0324 08:35:34.914811 10003 net.cpp:325] res4a_branch2b does not need backward computation.
I0324 08:35:34.914816 10003 net.cpp:325] res4a_branch2a/relu does not need backward computation.
I0324 08:35:34.914821 10003 net.cpp:325] res4a_branch2a/bn does not need backward computation.
I0324 08:35:34.914825 10003 net.cpp:325] res4a_branch2a does not need backward computation.
I0324 08:35:34.914830 10003 net.cpp:325] pool3 does not need backward computation.
I0324 08:35:34.914836 10003 net.cpp:325] res3a_branch2b_res3a_branch2b/relu_0_split does not need backward computation.
I0324 08:35:34.914841 10003 net.cpp:325] res3a_branch2b/relu does not need backward computation.
I0324 08:35:34.914846 10003 net.cpp:325] res3a_branch2b/bn does not need backward computation.
I0324 08:35:34.914850 10003 net.cpp:325] res3a_branch2b does not need backward computation.
I0324 08:35:34.914855 10003 net.cpp:325] res3a_branch2a/relu does not need backward computation.
I0324 08:35:34.914860 10003 net.cpp:325] res3a_branch2a/bn does not need backward computation.
I0324 08:35:34.914865 10003 net.cpp:325] res3a_branch2a does not need backward computation.
I0324 08:35:34.914870 10003 net.cpp:325] pool2 does not need backward computation.
I0324 08:35:34.914875 10003 net.cpp:325] res2a_branch2b/relu does not need backward computation.
I0324 08:35:34.914880 10003 net.cpp:325] res2a_branch2b/bn does not need backward computation.
I0324 08:35:34.914885 10003 net.cpp:325] res2a_branch2b does not need backward computation.
I0324 08:35:34.914889 10003 net.cpp:325] res2a_branch2a/relu does not need backward computation.
I0324 08:35:34.914894 10003 net.cpp:325] res2a_branch2a/bn does not need backward computation.
I0324 08:35:34.914898 10003 net.cpp:325] res2a_branch2a does not need backward computation.
I0324 08:35:34.914903 10003 net.cpp:325] pool1 does not need backward computation.
I0324 08:35:34.914908 10003 net.cpp:325] conv1b/relu does not need backward computation.
I0324 08:35:34.914913 10003 net.cpp:325] conv1b/bn does not need backward computation.
I0324 08:35:34.914917 10003 net.cpp:325] conv1b does not need backward computation.
I0324 08:35:34.914922 10003 net.cpp:325] conv1a/relu does not need backward computation.
I0324 08:35:34.914927 10003 net.cpp:325] conv1a/bn does not need backward computation.
I0324 08:35:34.914937 10003 net.cpp:325] conv1a does not need backward computation.
I0324 08:35:34.914943 10003 net.cpp:325] data/bias does not need backward computation.
I0324 08:35:34.914949 10003 net.cpp:325] data_data_0_split does not need backward computation.
I0324 08:35:34.914954 10003 net.cpp:325] data does not need backward computation.
I0324 08:35:34.914959 10003 net.cpp:367] This network produces output detection_eval
I0324 08:35:34.915060 10003 net.cpp:389] Top memory (TEST) required for data: 606953552 diff: 606953552
I0324 08:35:34.915067 10003 net.cpp:392] Bottom memory (TEST) required for data: 606953472 diff: 606953472
I0324 08:35:34.915071 10003 net.cpp:395] Shared (in-place) memory (TEST) by data: 260857856 diff: 260857856
I0324 08:35:34.915076 10003 net.cpp:398] Parameters memory (TEST) required for data: 12464288 diff: 12464288
I0324 08:35:34.915081 10003 net.cpp:401] Parameters shared memory (TEST) by data: 0 diff: 0
I0324 08:35:34.915086 10003 net.cpp:407] Network initialization done.
I0324 08:35:34.915422 10003 solver.cpp:57] Solver scaffolding done.
I0324 08:35:34.922982 10003 caffe.cpp:143] Finetuning from training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/initial/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_50000.caffemodel
I0324 08:35:34.931462 10003 net.cpp:1094] Copying source layer data Type:AnnotatedData #blobs=0
I0324 08:35:34.931489 10003 net.cpp:1094] Copying source layer data_data_0_split Type:Split #blobs=0
I0324 08:35:34.931494 10003 net.cpp:1094] Copying source layer data/bias Type:Bias #blobs=1
I0324 08:35:34.931535 10003 net.cpp:1094] Copying source layer conv1a Type:Convolution #blobs=2
I0324 08:35:34.931555 10003 net.cpp:1094] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0324 08:35:34.931865 10003 net.cpp:1094] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0324 08:35:34.931876 10003 net.cpp:1094] Copying source layer conv1b Type:Convolution #blobs=2
I0324 08:35:34.931895 10003 net.cpp:1094] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0324 08:35:34.932127 10003 net.cpp:1094] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0324 08:35:34.932137 10003 net.cpp:1094] Copying source layer pool1 Type:Pooling #blobs=0
I0324 08:35:34.932143 10003 net.cpp:1094] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0324 08:35:34.932173 10003 net.cpp:1094] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0324 08:35:34.932397 10003 net.cpp:1094] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0324 08:35:34.932409 10003 net.cpp:1094] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0324 08:35:34.932430 10003 net.cpp:1094] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0324 08:35:34.932644 10003 net.cpp:1094] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0324 08:35:34.932654 10003 net.cpp:1094] Copying source layer pool2 Type:Pooling #blobs=0
I0324 08:35:34.932659 10003 net.cpp:1094] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0324 08:35:34.932718 10003 net.cpp:1094] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0324 08:35:34.932914 10003 net.cpp:1094] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0324 08:35:34.932925 10003 net.cpp:1094] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0324 08:35:34.932962 10003 net.cpp:1094] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0324 08:35:34.933151 10003 net.cpp:1094] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0324 08:35:34.933161 10003 net.cpp:1094] Copying source layer res3a_branch2b_res3a_branch2b/relu_0_split Type:Split #blobs=0
I0324 08:35:34.933166 10003 net.cpp:1094] Copying source layer pool3 Type:Pooling #blobs=0
I0324 08:35:34.933169 10003 net.cpp:1094] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0324 08:35:34.933341 10003 net.cpp:1094] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0324 08:35:34.933553 10003 net.cpp:1094] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0324 08:35:34.933564 10003 net.cpp:1094] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0324 08:35:34.933660 10003 net.cpp:1094] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0324 08:35:34.933883 10003 net.cpp:1094] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0324 08:35:34.933894 10003 net.cpp:1094] Copying source layer pool4 Type:Pooling #blobs=0
I0324 08:35:34.933899 10003 net.cpp:1094] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0324 08:35:34.934530 10003 net.cpp:1094] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0324 08:35:34.934741 10003 net.cpp:1094] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0324 08:35:34.934751 10003 net.cpp:1094] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0324 08:35:34.935055 10003 net.cpp:1094] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0324 08:35:34.935236 10003 net.cpp:1094] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0324 08:35:34.935246 10003 net.cpp:1094] Copying source layer res5a_branch2b_res5a_branch2b/relu_0_split Type:Split #blobs=0
I0324 08:35:34.935251 10003 net.cpp:1094] Copying source layer pool6 Type:Pooling #blobs=0
I0324 08:35:34.935256 10003 net.cpp:1094] Copying source layer pool6_pool6_0_split Type:Split #blobs=0
I0324 08:35:34.935261 10003 net.cpp:1094] Copying source layer pool7 Type:Pooling #blobs=0
I0324 08:35:34.935266 10003 net.cpp:1094] Copying source layer pool7_pool7_0_split Type:Split #blobs=0
I0324 08:35:34.935269 10003 net.cpp:1094] Copying source layer pool8 Type:Pooling #blobs=0
I0324 08:35:34.935274 10003 net.cpp:1094] Copying source layer pool8_pool8_0_split Type:Split #blobs=0
I0324 08:35:34.935279 10003 net.cpp:1094] Copying source layer pool9 Type:Pooling #blobs=0
I0324 08:35:34.935283 10003 net.cpp:1094] Copying source layer ctx_output1 Type:Convolution #blobs=2
I0324 08:35:34.935319 10003 net.cpp:1094] Copying source layer ctx_output1/relu Type:ReLU #blobs=0
I0324 08:35:34.935328 10003 net.cpp:1094] Copying source layer ctx_output1_ctx_output1/relu_0_split Type:Split #blobs=0
I0324 08:35:34.935333 10003 net.cpp:1094] Copying source layer ctx_output2 Type:Convolution #blobs=2
I0324 08:35:34.935415 10003 net.cpp:1094] Copying source layer ctx_output2/relu Type:ReLU #blobs=0
I0324 08:35:34.935425 10003 net.cpp:1094] Copying source layer ctx_output2_ctx_output2/relu_0_split Type:Split #blobs=0
I0324 08:35:34.935430 10003 net.cpp:1094] Copying source layer ctx_output3 Type:Convolution #blobs=2
I0324 08:35:34.935511 10003 net.cpp:1094] Copying source layer ctx_output3/relu Type:ReLU #blobs=0
I0324 08:35:34.935520 10003 net.cpp:1094] Copying source layer ctx_output3_ctx_output3/relu_0_split Type:Split #blobs=0
I0324 08:35:34.935525 10003 net.cpp:1094] Copying source layer ctx_output4 Type:Convolution #blobs=2
I0324 08:35:34.935607 10003 net.cpp:1094] Copying source layer ctx_output4/relu Type:ReLU #blobs=0
I0324 08:35:34.935616 10003 net.cpp:1094] Copying source layer ctx_output4_ctx_output4/relu_0_split Type:Split #blobs=0
I0324 08:35:34.935621 10003 net.cpp:1094] Copying source layer ctx_output5 Type:Convolution #blobs=2
I0324 08:35:34.935701 10003 net.cpp:1094] Copying source layer ctx_output5/relu Type:ReLU #blobs=0
I0324 08:35:34.935710 10003 net.cpp:1094] Copying source layer ctx_output5_ctx_output5/relu_0_split Type:Split #blobs=0
I0324 08:35:34.935715 10003 net.cpp:1094] Copying source layer ctx_output6 Type:Convolution #blobs=2
I0324 08:35:34.935796 10003 net.cpp:1094] Copying source layer ctx_output6/relu Type:ReLU #blobs=0
I0324 08:35:34.935806 10003 net.cpp:1094] Copying source layer ctx_output6_ctx_output6/relu_0_split Type:Split #blobs=0
I0324 08:35:34.935811 10003 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc Type:Convolution #blobs=2
I0324 08:35:34.935828 10003 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc_perm Type:Permute #blobs=0
I0324 08:35:34.935834 10003 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc_flat Type:Flatten #blobs=0
I0324 08:35:34.935859 10003 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf Type:Convolution #blobs=2
I0324 08:35:34.935879 10003 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf_perm Type:Permute #blobs=0
I0324 08:35:34.935886 10003 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf_flat Type:Flatten #blobs=0
I0324 08:35:34.935891 10003 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_priorbox Type:PriorBox #blobs=0
I0324 08:35:34.935895 10003 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc Type:Convolution #blobs=2
I0324 08:35:34.935915 10003 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc_perm Type:Permute #blobs=0
I0324 08:35:34.935921 10003 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc_flat Type:Flatten #blobs=0
I0324 08:35:34.935926 10003 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf Type:Convolution #blobs=2
I0324 08:35:34.935945 10003 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf_perm Type:Permute #blobs=0
I0324 08:35:34.935951 10003 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf_flat Type:Flatten #blobs=0
I0324 08:35:34.935956 10003 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_priorbox Type:PriorBox #blobs=0
I0324 08:35:34.935961 10003 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc Type:Convolution #blobs=2
I0324 08:35:34.935978 10003 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc_perm Type:Permute #blobs=0
I0324 08:35:34.935986 10003 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc_flat Type:Flatten #blobs=0
I0324 08:35:34.935989 10003 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf Type:Convolution #blobs=2
I0324 08:35:34.936008 10003 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf_perm Type:Permute #blobs=0
I0324 08:35:34.936014 10003 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf_flat Type:Flatten #blobs=0
I0324 08:35:34.936019 10003 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_priorbox Type:PriorBox #blobs=0
I0324 08:35:34.959079 10003 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc Type:Convolution #blobs=2
I0324 08:35:34.959167 10003 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc_perm Type:Permute #blobs=0
I0324 08:35:34.959194 10003 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc_flat Type:Flatten #blobs=0
I0324 08:35:34.959208 10003 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf Type:Convolution #blobs=2
I0324 08:35:34.959260 10003 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf_perm Type:Permute #blobs=0
I0324 08:35:34.959282 10003 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf_flat Type:Flatten #blobs=0
I0324 08:35:34.959298 10003 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_priorbox Type:PriorBox #blobs=0
I0324 08:35:34.959316 10003 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc Type:Convolution #blobs=2
I0324 08:35:34.959358 10003 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc_perm Type:Permute #blobs=0
I0324 08:35:34.959373 10003 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc_flat Type:Flatten #blobs=0
I0324 08:35:34.959383 10003 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf Type:Convolution #blobs=2
I0324 08:35:34.959416 10003 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf_perm Type:Permute #blobs=0
I0324 08:35:34.959429 10003 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf_flat Type:Flatten #blobs=0
I0324 08:35:34.959440 10003 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_priorbox Type:PriorBox #blobs=0
I0324 08:35:34.959450 10003 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc Type:Convolution #blobs=2
I0324 08:35:34.959482 10003 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc_perm Type:Permute #blobs=0
I0324 08:35:34.959496 10003 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc_flat Type:Flatten #blobs=0
I0324 08:35:34.959527 10003 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf Type:Convolution #blobs=2
I0324 08:35:34.959565 10003 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf_perm Type:Permute #blobs=0
I0324 08:35:34.959579 10003 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf_flat Type:Flatten #blobs=0
I0324 08:35:34.959589 10003 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_priorbox Type:PriorBox #blobs=0
I0324 08:35:34.959599 10003 net.cpp:1094] Copying source layer mbox_loc Type:Concat #blobs=0
I0324 08:35:34.959609 10003 net.cpp:1094] Copying source layer mbox_conf Type:Concat #blobs=0
I0324 08:35:34.959619 10003 net.cpp:1094] Copying source layer mbox_priorbox Type:Concat #blobs=0
I0324 08:35:34.959630 10003 net.cpp:1094] Copying source layer mbox_loss Type:MultiBoxLoss #blobs=0
I0324 08:35:34.968904 10003 net.cpp:1094] Copying source layer data Type:AnnotatedData #blobs=0
I0324 08:35:34.968936 10003 net.cpp:1094] Copying source layer data_data_0_split Type:Split #blobs=0
I0324 08:35:34.968945 10003 net.cpp:1094] Copying source layer data/bias Type:Bias #blobs=1
I0324 08:35:34.968996 10003 net.cpp:1094] Copying source layer conv1a Type:Convolution #blobs=2
I0324 08:35:34.969025 10003 net.cpp:1094] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0324 08:35:34.969470 10003 net.cpp:1094] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0324 08:35:34.969486 10003 net.cpp:1094] Copying source layer conv1b Type:Convolution #blobs=2
I0324 08:35:34.969513 10003 net.cpp:1094] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0324 08:35:34.969941 10003 net.cpp:1094] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0324 08:35:34.969954 10003 net.cpp:1094] Copying source layer pool1 Type:Pooling #blobs=0
I0324 08:35:34.969959 10003 net.cpp:1094] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0324 08:35:34.969988 10003 net.cpp:1094] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0324 08:35:34.970217 10003 net.cpp:1094] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0324 08:35:34.970228 10003 net.cpp:1094] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0324 08:35:34.970250 10003 net.cpp:1094] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0324 08:35:34.970474 10003 net.cpp:1094] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0324 08:35:34.970484 10003 net.cpp:1094] Copying source layer pool2 Type:Pooling #blobs=0
I0324 08:35:34.970490 10003 net.cpp:1094] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0324 08:35:34.970552 10003 net.cpp:1094] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0324 08:35:34.970760 10003 net.cpp:1094] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0324 08:35:34.970772 10003 net.cpp:1094] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0324 08:35:34.970811 10003 net.cpp:1094] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0324 08:35:34.971004 10003 net.cpp:1094] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0324 08:35:34.971015 10003 net.cpp:1094] Copying source layer res3a_branch2b_res3a_branch2b/relu_0_split Type:Split #blobs=0
I0324 08:35:34.971020 10003 net.cpp:1094] Copying source layer pool3 Type:Pooling #blobs=0
I0324 08:35:34.971025 10003 net.cpp:1094] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0324 08:35:34.971210 10003 net.cpp:1094] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0324 08:35:34.971410 10003 net.cpp:1094] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0324 08:35:34.971421 10003 net.cpp:1094] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0324 08:35:34.971524 10003 net.cpp:1094] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0324 08:35:34.971719 10003 net.cpp:1094] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0324 08:35:34.971729 10003 net.cpp:1094] Copying source layer pool4 Type:Pooling #blobs=0
I0324 08:35:34.971746 10003 net.cpp:1094] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0324 08:35:34.972376 10003 net.cpp:1094] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0324 08:35:34.972570 10003 net.cpp:1094] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0324 08:35:34.972580 10003 net.cpp:1094] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0324 08:35:34.972880 10003 net.cpp:1094] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0324 08:35:34.973063 10003 net.cpp:1094] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0324 08:35:34.973073 10003 net.cpp:1094] Copying source layer res5a_branch2b_res5a_branch2b/relu_0_split Type:Split #blobs=0
I0324 08:35:34.973078 10003 net.cpp:1094] Copying source layer pool6 Type:Pooling #blobs=0
I0324 08:35:34.973083 10003 net.cpp:1094] Copying source layer pool6_pool6_0_split Type:Split #blobs=0
I0324 08:35:34.973088 10003 net.cpp:1094] Copying source layer pool7 Type:Pooling #blobs=0
I0324 08:35:34.973093 10003 net.cpp:1094] Copying source layer pool7_pool7_0_split Type:Split #blobs=0
I0324 08:35:34.973098 10003 net.cpp:1094] Copying source layer pool8 Type:Pooling #blobs=0
I0324 08:35:34.973103 10003 net.cpp:1094] Copying source layer pool8_pool8_0_split Type:Split #blobs=0
I0324 08:35:34.973106 10003 net.cpp:1094] Copying source layer pool9 Type:Pooling #blobs=0
I0324 08:35:34.973111 10003 net.cpp:1094] Copying source layer ctx_output1 Type:Convolution #blobs=2
I0324 08:35:34.973146 10003 net.cpp:1094] Copying source layer ctx_output1/relu Type:ReLU #blobs=0
I0324 08:35:34.973155 10003 net.cpp:1094] Copying source layer ctx_output1_ctx_output1/relu_0_split Type:Split #blobs=0
I0324 08:35:34.973160 10003 net.cpp:1094] Copying source layer ctx_output2 Type:Convolution #blobs=2
I0324 08:35:34.973243 10003 net.cpp:1094] Copying source layer ctx_output2/relu Type:ReLU #blobs=0
I0324 08:35:34.973253 10003 net.cpp:1094] Copying source layer ctx_output2_ctx_output2/relu_0_split Type:Split #blobs=0
I0324 08:35:34.973258 10003 net.cpp:1094] Copying source layer ctx_output3 Type:Convolution #blobs=2
I0324 08:35:34.973341 10003 net.cpp:1094] Copying source layer ctx_output3/relu Type:ReLU #blobs=0
I0324 08:35:34.973351 10003 net.cpp:1094] Copying source layer ctx_output3_ctx_output3/relu_0_split Type:Split #blobs=0
I0324 08:35:34.973356 10003 net.cpp:1094] Copying source layer ctx_output4 Type:Convolution #blobs=2
I0324 08:35:34.973438 10003 net.cpp:1094] Copying source layer ctx_output4/relu Type:ReLU #blobs=0
I0324 08:35:34.973446 10003 net.cpp:1094] Copying source layer ctx_output4_ctx_output4/relu_0_split Type:Split #blobs=0
I0324 08:35:34.973450 10003 net.cpp:1094] Copying source layer ctx_output5 Type:Convolution #blobs=2
I0324 08:35:34.973533 10003 net.cpp:1094] Copying source layer ctx_output5/relu Type:ReLU #blobs=0
I0324 08:35:34.973541 10003 net.cpp:1094] Copying source layer ctx_output5_ctx_output5/relu_0_split Type:Split #blobs=0
I0324 08:35:34.973546 10003 net.cpp:1094] Copying source layer ctx_output6 Type:Convolution #blobs=2
I0324 08:35:34.973629 10003 net.cpp:1094] Copying source layer ctx_output6/relu Type:ReLU #blobs=0
I0324 08:35:34.973639 10003 net.cpp:1094] Copying source layer ctx_output6_ctx_output6/relu_0_split Type:Split #blobs=0
I0324 08:35:34.973644 10003 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc Type:Convolution #blobs=2
I0324 08:35:34.973661 10003 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc_perm Type:Permute #blobs=0
I0324 08:35:34.973667 10003 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_loc_flat Type:Flatten #blobs=0
I0324 08:35:34.973672 10003 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf Type:Convolution #blobs=2
I0324 08:35:34.973690 10003 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf_perm Type:Permute #blobs=0
I0324 08:35:34.973801 10003 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_conf_flat Type:Flatten #blobs=0
I0324 08:35:34.973808 10003 net.cpp:1094] Copying source layer ctx_output1/relu_mbox_priorbox Type:PriorBox #blobs=0
I0324 08:35:34.973834 10003 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc Type:Convolution #blobs=2
I0324 08:35:34.973857 10003 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc_perm Type:Permute #blobs=0
I0324 08:35:34.973865 10003 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_loc_flat Type:Flatten #blobs=0
I0324 08:35:34.973873 10003 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf Type:Convolution #blobs=2
I0324 08:35:34.973904 10003 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf_perm Type:Permute #blobs=0
I0324 08:35:34.973918 10003 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_conf_flat Type:Flatten #blobs=0
I0324 08:35:34.973924 10003 net.cpp:1094] Copying source layer ctx_output2/relu_mbox_priorbox Type:PriorBox #blobs=0
I0324 08:35:34.973929 10003 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc Type:Convolution #blobs=2
I0324 08:35:34.973951 10003 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc_perm Type:Permute #blobs=0
I0324 08:35:34.973958 10003 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_loc_flat Type:Flatten #blobs=0
I0324 08:35:34.973963 10003 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf Type:Convolution #blobs=2
I0324 08:35:34.973981 10003 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf_perm Type:Permute #blobs=0
I0324 08:35:34.973989 10003 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_conf_flat Type:Flatten #blobs=0
I0324 08:35:34.973994 10003 net.cpp:1094] Copying source layer ctx_output3/relu_mbox_priorbox Type:PriorBox #blobs=0
I0324 08:35:34.973999 10003 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc Type:Convolution #blobs=2
I0324 08:35:34.974016 10003 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc_perm Type:Permute #blobs=0
I0324 08:35:34.974025 10003 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_loc_flat Type:Flatten #blobs=0
I0324 08:35:34.974030 10003 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf Type:Convolution #blobs=2
I0324 08:35:34.974047 10003 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf_perm Type:Permute #blobs=0
I0324 08:35:34.974054 10003 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_conf_flat Type:Flatten #blobs=0
I0324 08:35:34.974059 10003 net.cpp:1094] Copying source layer ctx_output4/relu_mbox_priorbox Type:PriorBox #blobs=0
I0324 08:35:34.974064 10003 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc Type:Convolution #blobs=2
I0324 08:35:34.974081 10003 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc_perm Type:Permute #blobs=0
I0324 08:35:34.974088 10003 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_loc_flat Type:Flatten #blobs=0
I0324 08:35:34.974093 10003 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf Type:Convolution #blobs=2
I0324 08:35:34.974110 10003 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf_perm Type:Permute #blobs=0
I0324 08:35:34.974117 10003 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_conf_flat Type:Flatten #blobs=0
I0324 08:35:34.974123 10003 net.cpp:1094] Copying source layer ctx_output5/relu_mbox_priorbox Type:PriorBox #blobs=0
I0324 08:35:34.974128 10003 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc Type:Convolution #blobs=2
I0324 08:35:34.974144 10003 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc_perm Type:Permute #blobs=0
I0324 08:35:34.974151 10003 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_loc_flat Type:Flatten #blobs=0
I0324 08:35:34.974156 10003 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf Type:Convolution #blobs=2
I0324 08:35:34.974174 10003 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf_perm Type:Permute #blobs=0
I0324 08:35:34.974180 10003 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_conf_flat Type:Flatten #blobs=0
I0324 08:35:34.974185 10003 net.cpp:1094] Copying source layer ctx_output6/relu_mbox_priorbox Type:PriorBox #blobs=0
I0324 08:35:34.974200 10003 net.cpp:1094] Copying source layer mbox_loc Type:Concat #blobs=0
I0324 08:35:34.974205 10003 net.cpp:1094] Copying source layer mbox_conf Type:Concat #blobs=0
I0324 08:35:34.974210 10003 net.cpp:1094] Copying source layer mbox_priorbox Type:Concat #blobs=0
I0324 08:35:34.974215 10003 net.cpp:1078] Ignoring source layer mbox_loss
I0324 08:35:34.974431 10003 parallel.cpp:106] [0 - 0] P2pSync adding callback
I0324 08:35:34.974443 10003 parallel.cpp:106] [1 - 1] P2pSync adding callback
I0324 08:35:34.974448 10003 parallel.cpp:59] Starting Optimization
I0324 08:35:34.974453 10003 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0324 08:35:34.974498 10003 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0324 08:35:34.976284 10083 device_alternate.hpp:116] NVML initialized on thread 139788606736128
I0324 08:35:35.015540 10083 common.cpp:585] NVML succeeded to set CPU affinity on device 0
I0324 08:35:35.015638 10084 device_alternate.hpp:116] NVML initialized on thread 139788598343424
I0324 08:35:35.017122 10084 common.cpp:585] NVML succeeded to set CPU affinity on device 1
I0324 08:35:35.024613 10084 solver.cpp:43] Solver data type: FLOAT
I0324 08:35:35.027281 10084 net.cpp:104] Using FLOAT as default forward math type
I0324 08:35:35.027292 10084 net.cpp:110] Using FLOAT as default backward math type
I0324 08:35:35.027400 10084 data_reader.cpp:58] Data Reader threads: 4, out queues: 16, depth: 8
I0324 08:35:35.027444 10084 internal_thread.cpp:19] Starting 4 internal thread(s) on device 1
I0324 08:35:35.028740 10085 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0324 08:35:35.029445 10087 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0324 08:35:35.030081 10086 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0324 08:35:35.030714 10088 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_train_lmdb
I0324 08:35:35.041493 10084 annotated_data_layer.cpp:219] output data size: 8,3,320,768
I0324 08:35:35.061655 10084 annotated_data_layer.cpp:265] [1] Output data size: 8, 3, 320, 768
I0324 08:35:35.061746 10084 internal_thread.cpp:19] Starting 4 internal thread(s) on device 1
I0324 08:35:35.676715 10084 solver.cpp:177] Creating test net (#0) specified by test_net file: training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/l1reg/test.prototxt
I0324 08:35:35.677410 10084 net.cpp:104] Using FLOAT as default forward math type
I0324 08:35:35.677423 10084 net.cpp:110] Using FLOAT as default backward math type
I0324 08:35:35.677459 10084 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 4
I0324 08:35:35.677471 10084 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0324 08:35:35.678216 10111 db_lmdb.cpp:24] Opened lmdb /user/a0875091/files/data/datasets/object-detect/ti/detection/xml/TI_VGG16_720x368_V2/lmdb/TI_VGG16_720x368_V2_test_lmdb
I0324 08:35:35.688832 10084 annotated_data_layer.cpp:219] output data size: 4,3,320,768
I0324 08:35:35.688922 10084 annotated_data_layer.cpp:265] (1) Output data size: 4, 3, 320, 768
I0324 08:35:35.688985 10084 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0324 08:35:35.690829 10112 annotated_data_layer.cpp:111] (1) Parser threads: 1
I0324 08:35:35.690855 10112 annotated_data_layer.cpp:113] (1) Transformer threads: 1
I0324 08:35:35.828879 10084 solver.cpp:57] Solver scaffolding done.
I0324 08:35:35.847626 10084 parallel.cpp:161] [1 - 1] P2pSync adding callback
I0324 08:35:35.847626 10083 parallel.cpp:161] [0 - 0] P2pSync adding callback
I0324 08:35:36.008028 10084 solver.cpp:501] Solving ssdJacintoNetV2
I0324 08:35:36.008078 10084 solver.cpp:502] Learning Rate Policy: multistep
I0324 08:35:36.008086 10083 solver.cpp:501] Solving ssdJacintoNetV2
I0324 08:35:36.008105 10083 solver.cpp:502] Learning Rate Policy: multistep
I0324 08:35:36.020649 10084 net.cpp:1412] [1] Reserving 12451584 bytes of shared learnable space
I0324 08:35:36.022732 10083 net.cpp:1412] [0] Reserving 12451584 bytes of shared learnable space
I0324 08:35:36.028239 10083 solver.cpp:228] Starting Optimization on GPU 0
I0324 08:35:36.028240 10084 solver.cpp:228] Starting Optimization on GPU 1
I0324 08:35:36.028553 10083 solver.cpp:678] Iteration 0, Testing net (#0)
I0324 08:35:36.028633 10114 device_alternate.hpp:116] NVML initialized on thread 139787688208128
I0324 08:35:36.028676 10114 common.cpp:585] NVML succeeded to set CPU affinity on device 1
I0324 08:35:36.028744 10113 device_alternate.hpp:116] NVML initialized on thread 139787679815424
I0324 08:35:36.028794 10113 common.cpp:585] NVML succeeded to set CPU affinity on device 0
I0324 08:35:36.036044 10084 net.cpp:1012] Ignoring source layer mbox_loss
I0324 08:35:36.049541 10083 net.cpp:1012] Ignoring source layer mbox_loss
I0324 08:35:36.142127 10084 blocking_queue.cpp:40] Data layer prefetch queue empty
I0324 08:35:36.342499 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'conv1a' with space 0G 3/1 1 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.349083 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'conv1b' with space 0G 32/4 6 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.352447 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1a' with space 0G 3/1 1 	(avail 7.66G, req 0G)	t: 0
I0324 08:35:36.360208 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1b' with space 0G 32/4 6 	(avail 7.66G, req 0G)	t: 0
I0324 08:35:36.360515 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res2a_branch2a' with space 0G 32/1 6 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.364989 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res2a_branch2b' with space 0G 64/4 6 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.370710 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2a' with space 0G 32/1 6 	(avail 7.66G, req 0G)	t: 0
I0324 08:35:36.371879 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res3a_branch2a' with space 0G 64/1 6 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.375943 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2b' with space 0G 64/4 6 	(avail 7.66G, req 0G)	t: 0
I0324 08:35:36.376340 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res3a_branch2b' with space 0G 128/4 6 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.382447 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res4a_branch2a' with space 0G 128/1 1 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.382901 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2a' with space 0G 64/1 6 	(avail 7.66G, req 0G)	t: 0
I0324 08:35:36.386214 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res4a_branch2b' with space 0G 256/4 6 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.386534 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2b' with space 0G 128/4 6 	(avail 7.66G, req 0G)	t: 0
I0324 08:35:36.391687 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res5a_branch2a' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.392333 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2a' with space 0G 128/1 1 	(avail 7.66G, req 0G)	t: 0
I0324 08:35:36.394810 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res5a_branch2b' with space 0G 512/4 1 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.395463 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2b' with space 0G 256/4 6 	(avail 7.66G, req 0G)	t: 0
I0324 08:35:36.399211 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output1' with space 0G 128/1 1 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.400524 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res5a_branch2a' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0324 08:35:36.401939 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output2' with space 0G 512/1 1 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.403427 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res5a_branch2b' with space 0G 512/4 1 	(avail 7.66G, req 0G)	t: 0
I0324 08:35:36.404647 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output3' with space 0G 512/1 1 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.407368 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output4' with space 0G 512/1 0 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.407968 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output1' with space 0G 128/1 1 	(avail 7.66G, req 0G)	t: 0
I0324 08:35:36.409552 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output5' with space 0G 512/1 0 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.410537 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output2' with space 0G 512/1 1 	(avail 7.66G, req 0G)	t: 0
I0324 08:35:36.412530 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output3' with space 0G 512/1 1 	(avail 7.66G, req 0G)	t: 0
I0324 08:35:36.413081 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output6' with space 0G 512/1 0 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.415477 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output4' with space 0G 512/1 0 	(avail 7.66G, req 0G)	t: 0
I0324 08:35:36.416633 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output1/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.418977 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output1/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.419420 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output5' with space 0G 512/1 0 	(avail 7.66G, req 0G)	t: 0
I0324 08:35:36.421402 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output2/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.421813 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output6' with space 0G 512/1 0 	(avail 7.66G, req 0G)	t: 0
I0324 08:35:36.423036 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output2/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.423979 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output1/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0324 08:35:36.425060 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output3/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.426440 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output1/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0324 08:35:36.427124 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output3/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.428917 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output2/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0324 08:35:36.429317 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output4/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.430505 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output2/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0324 08:35:36.431483 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output4/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.432484 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output3/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0324 08:35:36.434209 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output3/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0324 08:35:36.435165 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output5/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.436152 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output4/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0324 08:35:36.438123 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output4/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0324 08:35:36.438356 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output5/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.439903 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output5/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0324 08:35:36.441805 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output5/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0324 08:35:36.442126 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output6/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.443898 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output6/relu_mbox_loc' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0324 08:35:36.444453 10084 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_output6/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.72G, req 0G)	t: 0
I0324 08:35:36.446454 10083 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_output6/relu_mbox_conf' with space 0G 256/1 1 	(avail 7.66G, req 0G)	t: 0
I0324 08:36:24.842363 10070 data_reader.cpp:305] Starting prefetch of epoch 1
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.302963
j:  : 4 : max_pr:  : 0.480864
j:  : 3 : max_pr:  : 0.631113
j:  : 2 : max_pr:  : 0.757067
j:  : 1 : max_pr:  : 0.851338
j:  : 0 : max_pr:  : 1
I0324 08:36:25.077036 10083 solver.cpp:786] class AP 1: 0.365759
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.112159
j:  : 7 : max_pr:  : 0.370828
j:  : 6 : max_pr:  : 0.510792
j:  : 5 : max_pr:  : 0.592275
j:  : 4 : max_pr:  : 0.671595
j:  : 3 : max_pr:  : 0.792359
j:  : 2 : max_pr:  : 0.983771
j:  : 1 : max_pr:  : 0.998115
j:  : 0 : max_pr:  : 1
I0324 08:36:25.140444 10083 solver.cpp:786] class AP 2: 0.548354
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.51619
j:  : 6 : max_pr:  : 0.657018
j:  : 5 : max_pr:  : 0.757155
j:  : 4 : max_pr:  : 0.863762
j:  : 3 : max_pr:  : 0.916161
j:  : 2 : max_pr:  : 0.957138
j:  : 1 : max_pr:  : 0.998614
j:  : 0 : max_pr:  : 1
I0324 08:36:25.154189 10083 solver.cpp:786] class AP 3: 0.606004
I0324 08:36:25.154211 10083 solver.cpp:792] Test net output mAP #0: detection_eval = 0.506705
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.317735
j:  : 4 : max_pr:  : 0.508832
j:  : 3 : max_pr:  : 0.640384
j:  : 2 : max_pr:  : 0.760784
j:  : 1 : max_pr:  : 0.864051
j:  : 0 : max_pr:  : 1
I0324 08:36:25.302822 10084 solver.cpp:786] class AP 1: 0.371981
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.110452
j:  : 7 : max_pr:  : 0.364854
j:  : 6 : max_pr:  : 0.497805
j:  : 5 : max_pr:  : 0.579769
j:  : 4 : max_pr:  : 0.665578
j:  : 3 : max_pr:  : 0.777821
j:  : 2 : max_pr:  : 0.983871
j:  : 1 : max_pr:  : 0.996575
j:  : 0 : max_pr:  : 1
I0324 08:36:25.351040 10084 solver.cpp:786] class AP 2: 0.543339
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.515269
j:  : 6 : max_pr:  : 0.654729
j:  : 5 : max_pr:  : 0.757834
j:  : 4 : max_pr:  : 0.863024
j:  : 3 : max_pr:  : 0.915137
j:  : 2 : max_pr:  : 0.96467
j:  : 1 : max_pr:  : 0.998676
j:  : 0 : max_pr:  : 1
I0324 08:36:25.361692 10084 solver.cpp:786] class AP 3: 0.606304
I0324 08:36:25.361712 10084 solver.cpp:792] Test net output mAP #0: detection_eval = 0.507208
I0324 08:36:25.362234 10083 solver.cpp:255] [MultiGPU] Initial Test completed
I0324 08:36:26.587579 10058 annotated_data_layer.cpp:111] [0] Parser threads: 4
I0324 08:36:26.587610 10058 annotated_data_layer.cpp:113] [0] Transformer threads: 4
I0324 08:36:26.785466 10089 annotated_data_layer.cpp:111] [1] Parser threads: 4
I0324 08:36:26.785507 10089 annotated_data_layer.cpp:113] [1] Transformer threads: 4
I0324 08:36:28.342314 10083 solver.cpp:319] Iteration 0 (2.97176 s), loss = 2.35549
I0324 08:36:28.342368 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.13215 (* 1 = 2.13215 loss)
I0324 08:36:28.342386 10083 sgd_solver.cpp:136] Iteration 0, lr = 0.001, m = 0.9
I0324 08:36:28.342397 10083 solver.cpp:351] sparsity_itr_increment_bfr_applying is true: old behaviour:
I0324 08:36:28.348107 10084 solver.cpp:351] sparsity_itr_increment_bfr_applying is true: old behaviour:
I0324 08:36:28.461549 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'conv1a' with space 4.24G 3/1 1 0 0 	(avail 1.63G, req 0G)	t: 0 2.33 2.06
I0324 08:36:28.465013 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'conv1a' with space 4.24G 3/1 1 0 0 	(avail 1.47G, req 0G)	t: 0 2.59 2.06
I0324 08:36:28.574789 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'conv1b' with space 4.24G 32/4 6 4 3 	(avail 1.47G, req 0G)	t: 0 0.53 1.11
I0324 08:36:28.580133 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'conv1b' with space 4.24G 32/4 6 4 3 	(avail 1.6G, req 0G)	t: 0 0.5 1.08
I0324 08:36:28.808477 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 4.24G 32/1 6 4 3 	(avail 1.47G, req 0G)	t: 0 0.66 1.25
I0324 08:36:28.822674 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 4.24G 32/1 1 4 3 	(avail 1.58G, req 0G)	t: 0 0.66 1.26
I0324 08:36:28.891450 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 4.24G 64/4 6 4 3 	(avail 1.47G, req 0G)	t: 0 0.24 0.56
I0324 08:36:28.916443 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 4.24G 64/4 6 4 3 	(avail 1.58G, req 0G)	t: 0 0.25 0.55
I0324 08:36:29.060506 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 4.24G 64/1 6 4 5 	(avail 1.42G, req 0.05G)	t: 0 0.4 0.74
I0324 08:36:29.094852 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 4.24G 64/1 6 4 5 	(avail 1.55G, req 0.05G)	t: 0 0.37 0.73
I0324 08:36:29.112488 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 4.24G 128/4 6 4 5 	(avail 1.42G, req 0.05G)	t: 0 0.16 0.28
I0324 08:36:29.142943 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 4.24G 128/4 6 4 5 	(avail 1.55G, req 0.05G)	t: 0 0.12 0.28
I0324 08:36:29.205910 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 4.24G 128/1 6 4 5 	(avail 1.42G, req 0.05G)	t: 0 0.35 0.46
I0324 08:36:29.235740 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 4.24G 128/1 6 4 5 	(avail 1.55G, req 0.05G)	t: 0 0.36 0.45
I0324 08:36:29.249790 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 4.24G 256/4 6 4 5 	(avail 1.42G, req 0.05G)	t: 0 0.08 0.17
I0324 08:36:29.277345 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 4.24G 256/4 6 4 5 	(avail 1.55G, req 0.05G)	t: 0 0.12 0.18
I0324 08:36:29.363847 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 4.24G 256/1 6 4 5 	(avail 1.39G, req 0.05G)	t: 0 0.44 0.5
I0324 08:36:29.380286 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 4.24G 256/1 6 4 5 	(avail 1.55G, req 0.05G)	t: 0 0.44 0.54
I0324 08:36:29.402106 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 4.24G 512/4 6 4 5 	(avail 1.39G, req 0.05G)	t: 0 0.13 0.14
I0324 08:36:29.425523 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 4.24G 512/4 6 4 5 	(avail 1.55G, req 0.05G)	t: 0 0.12 0.14
I0324 08:36:29.441742 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output1' with space 4.24G 128/1 1 1 3 	(avail 1.39G, req 0.05G)	t: 0 0.37 0.84
I0324 08:36:29.470067 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output1' with space 4.24G 128/1 1 1 3 	(avail 1.53G, req 0.05G)	t: 0 0.36 0.8
I0324 08:36:29.502902 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output2' with space 4.24G 512/1 1 1 1 	(avail 1.39G, req 0.05G)	t: 0 0.18 0.16
I0324 08:36:29.523831 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output2' with space 4.24G 512/1 1 1 1 	(avail 1.53G, req 0.05G)	t: 0 0.16 0.16
I0324 08:36:29.560976 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output3' with space 4.24G 512/1 0 1 1 	(avail 1.39G, req 0.05G)	t: 0 0.11 0.11
I0324 08:36:29.563984 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output3' with space 4.24G 512/1 1 1 1 	(avail 1.53G, req 0.05G)	t: 0 0.11 0.12
I0324 08:36:29.604976 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output4' with space 4.24G 512/1 0 0 1 	(avail 1.53G, req 0.05G)	t: 0 0.06 0.07
I0324 08:36:29.612335 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output4' with space 4.24G 512/1 0 0 1 	(avail 1.39G, req 0.05G)	t: 0 0.1 0.1
I0324 08:36:29.637671 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output5' with space 4.24G 512/1 0 0 1 	(avail 1.5G, req 0.05G)	t: 0 0.06 0.06
I0324 08:36:29.666836 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output5' with space 4.24G 512/1 0 0 3 	(avail 1.37G, req 0.05G)	t: 0 0.1 0.1
I0324 08:36:29.716055 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output6' with space 4.24G 512/1 0 0 1 	(avail 1.48G, req 0.05G)	t: 0 0.1 0.1
I0324 08:36:29.721319 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output6' with space 4.24G 512/1 0 0 3 	(avail 1.37G, req 0.05G)	t: 0 0.1 0.1
I0324 08:36:29.831218 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_loc' with space 4.24G 256/1 1 1 3 	(avail 1.48G, req 0.05G)	t: 0 0.22 0.64
I0324 08:36:29.840940 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_loc' with space 4.24G 256/1 1 1 3 	(avail 1.37G, req 0.05G)	t: 0 0.27 0.65
I0324 08:36:29.951992 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_conf' with space 4.24G 256/1 1 1 3 	(avail 1.37G, req 0.05G)	t: 0 0.22 0.62
I0324 08:36:29.991230 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_loc' with space 4.24G 256/1 1 1 0 	(avail 1.34G, req 0.05G)	t: 0 0.05 0.07
I0324 08:36:30.008394 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_conf' with space 4.24G 256/1 1 1 0 	(avail 1.34G, req 0.05G)	t: 0 0.06 0.07
I0324 08:36:30.026209 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_conf' with space 4.24G 256/1 1 1 3 	(avail 1.45G, req 0.05G)	t: 0 0.23 0.61
I0324 08:36:30.027895 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_loc' with space 4.24G 256/1 1 0 0 	(avail 1.34G, req 0.05G)	t: 0 0.05 0.04
I0324 08:36:30.058964 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_loc' with space 4.24G 256/1 1 1 0 	(avail 1.45G, req 0.05G)	t: 0 0.05 0.07
I0324 08:36:30.063822 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_conf' with space 4.24G 256/1 1 1 0 	(avail 1.34G, req 0.05G)	t: 0 0.05 0.04
I0324 08:36:30.085503 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_loc' with space 4.24G 256/1 1 0 0 	(avail 1.34G, req 0.05G)	t: 0 0.04 0.04
I0324 08:36:30.089381 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_conf' with space 4.24G 256/1 1 1 0 	(avail 1.45G, req 0.05G)	t: 0 0.06 0.08
I0324 08:36:30.114079 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_conf' with space 4.24G 256/1 1 1 0 	(avail 1.34G, req 0.05G)	t: 0 0.06 0.04
I0324 08:36:30.119760 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 1.45G, req 0.05G)	t: 0 0.06 0.04
I0324 08:36:30.145745 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 1.34G, req 0.05G)	t: 0 0.04 0.07
I0324 08:36:30.152052 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_conf' with space 4.24G 256/1 0 0 0 	(avail 1.45G, req 0.05G)	t: 0 0.05 0.07
I0324 08:36:30.166509 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_conf' with space 4.24G 256/1 1 0 0 	(avail 1.34G, req 0.05G)	t: 0 0.03 0.03
I0324 08:36:30.177685 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_loc' with space 4.24G 256/1 0 1 0 	(avail 1.45G, req 0.05G)	t: 0 0.07 0.07
I0324 08:36:30.177912 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output6/relu_mbox_loc' with space 4.24G 256/1 1 0 0 	(avail 1.34G, req 0.05G)	t: 0 0.04 0.03
I0324 08:36:30.213369 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_conf' with space 4.24G 256/1 1 0 0 	(avail 1.45G, req 0.05G)	t: 0 0.07 0.07
I0324 08:36:30.227165 10083 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_output6/relu_mbox_conf' with space 4.24G 256/1 0 0 0 	(avail 1.34G, req 0.05G)	t: 0 0.04 0.03
I0324 08:36:30.235384 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 1.45G, req 0.05G)	t: 0 0.07 0.06
I0324 08:36:30.260116 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_conf' with space 4.24G 256/1 0 1 0 	(avail 1.45G, req 0.05G)	t: 0 0.07 0.06
I0324 08:36:30.291558 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output6/relu_mbox_loc' with space 4.24G 256/1 0 0 0 	(avail 1.45G, req 0.05G)	t: 0 0.06 0.04
I0324 08:36:30.310395 10084 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_output6/relu_mbox_conf' with space 4.24G 256/1 0 0 0 	(avail 1.45G, req 0.05G)	t: 0 0.05 0.04
I0324 08:36:30.420766 10083 cudnn_conv_layer.cpp:474] [0] Layer 'conv1a' reallocating workspace 4.24G to 0.11G
I0324 08:36:30.543406 10084 cudnn_conv_layer.cpp:474] [1] Layer 'conv1a' reallocating workspace 4.24G to 0.11G
I0324 08:36:30.786813 10083 solver.cpp:319] Iteration 1 (2.44441 s), loss = 2.60506
I0324 08:36:30.786854 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.15044 (* 1 = 3.15044 loss)
I0324 08:36:30.786864 10083 solver.cpp:351] sparsity_itr_increment_bfr_applying is true: old behaviour:
I0324 08:36:30.786953 10084 solver.cpp:351] sparsity_itr_increment_bfr_applying is true: old behaviour:
I0324 08:36:31.264272 10083 solver.cpp:319] Iteration 2 (0.477431 s), loss = 2.92541
I0324 08:36:31.264324 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.82867 (* 1 = 2.82867 loss)
I0324 08:37:33.763490 10083 solver.cpp:314] Iteration 100 (1.56807 iter/s, 62.4972s/98 iter), loss = 3.1481
I0324 08:37:33.763628 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.01859 (* 1 = 3.01859 loss)
I0324 08:37:33.763643 10083 sgd_solver.cpp:136] Iteration 100, lr = 0.001, m = 0.9
I0324 08:38:39.902204 10083 solver.cpp:314] Iteration 200 (1.51202 iter/s, 66.1365s/100 iter), loss = 2.95343
I0324 08:38:39.902326 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.75954 (* 1 = 2.75954 loss)
I0324 08:38:39.902343 10083 sgd_solver.cpp:136] Iteration 200, lr = 0.001, m = 0.9
I0324 08:39:44.535719 10083 solver.cpp:314] Iteration 300 (1.54724 iter/s, 64.6314s/100 iter), loss = 2.99481
I0324 08:39:44.535894 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.3341 (* 1 = 3.3341 loss)
I0324 08:39:44.535938 10083 sgd_solver.cpp:136] Iteration 300, lr = 0.001, m = 0.9
I0324 08:40:50.487582 10083 solver.cpp:314] Iteration 400 (1.51631 iter/s, 65.9497s/100 iter), loss = 3.162
I0324 08:40:50.487679 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.94736 (* 1 = 3.94736 loss)
I0324 08:40:50.487696 10083 sgd_solver.cpp:136] Iteration 400, lr = 0.001, m = 0.9
I0324 08:41:57.079520 10083 solver.cpp:314] Iteration 500 (1.50173 iter/s, 66.5898s/100 iter), loss = 3.09774
I0324 08:41:57.079627 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.33222 (* 1 = 3.33222 loss)
I0324 08:41:57.079643 10083 sgd_solver.cpp:136] Iteration 500, lr = 0.001, m = 0.9
I0324 08:43:02.719404 10083 solver.cpp:314] Iteration 600 (1.52351 iter/s, 65.6377s/100 iter), loss = 2.98968
I0324 08:43:02.719523 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.94343 (* 1 = 2.94343 loss)
I0324 08:43:02.719542 10083 sgd_solver.cpp:136] Iteration 600, lr = 0.001, m = 0.9
I0324 08:44:08.022087 10083 solver.cpp:314] Iteration 700 (1.53138 iter/s, 65.3005s/100 iter), loss = 3.00473
I0324 08:44:08.022251 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.32725 (* 1 = 2.32725 loss)
I0324 08:44:08.022295 10083 sgd_solver.cpp:136] Iteration 700, lr = 0.001, m = 0.9
I0324 08:45:14.418145 10083 solver.cpp:314] Iteration 800 (1.50616 iter/s, 66.3939s/100 iter), loss = 2.84592
I0324 08:45:14.418249 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.09103 (* 1 = 3.09103 loss)
I0324 08:45:14.418270 10083 sgd_solver.cpp:136] Iteration 800, lr = 0.001, m = 0.9
I0324 08:46:20.925789 10083 solver.cpp:314] Iteration 900 (1.50364 iter/s, 66.5055s/100 iter), loss = 3.00783
I0324 08:46:20.925890 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.69931 (* 1 = 2.69931 loss)
I0324 08:46:20.925911 10083 sgd_solver.cpp:136] Iteration 900, lr = 0.001, m = 0.9
I0324 08:47:26.631680 10083 solver.cpp:314] Iteration 1000 (1.52198 iter/s, 65.7037s/100 iter), loss = 3.14298
I0324 08:47:26.631777 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.85834 (* 1 = 3.85834 loss)
I0324 08:47:26.631791 10083 sgd_solver.cpp:136] Iteration 1000, lr = 0.001, m = 0.9
I0324 08:48:32.161964 10083 solver.cpp:314] Iteration 1100 (1.52606 iter/s, 65.5281s/100 iter), loss = 2.91135
I0324 08:48:32.162067 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.8302 (* 1 = 2.8302 loss)
I0324 08:48:32.162083 10083 sgd_solver.cpp:136] Iteration 1100, lr = 0.001, m = 0.9
I0324 08:49:37.974792 10083 solver.cpp:314] Iteration 1200 (1.51951 iter/s, 65.8107s/100 iter), loss = 3.08369
I0324 08:49:37.974964 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.36466 (* 1 = 2.36466 loss)
I0324 08:49:37.974987 10083 sgd_solver.cpp:136] Iteration 1200, lr = 0.001, m = 0.9
I0324 08:50:43.069788 10083 solver.cpp:314] Iteration 1300 (1.53627 iter/s, 65.0929s/100 iter), loss = 3.03445
I0324 08:50:43.069937 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.59577 (* 1 = 3.59577 loss)
I0324 08:50:43.069958 10083 sgd_solver.cpp:136] Iteration 1300, lr = 0.001, m = 0.9
I0324 08:51:49.692001 10083 solver.cpp:314] Iteration 1400 (1.50105 iter/s, 66.62s/100 iter), loss = 3.12079
I0324 08:51:49.692106 10083 solver.cpp:336]     Train net output #0: mbox_loss = 1.89331 (* 1 = 1.89331 loss)
I0324 08:51:49.692129 10083 sgd_solver.cpp:136] Iteration 1400, lr = 0.001, m = 0.9
I0324 08:52:55.762064 10083 solver.cpp:314] Iteration 1500 (1.51359 iter/s, 66.0679s/100 iter), loss = 3.1385
I0324 08:52:55.765758 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.68786 (* 1 = 2.68786 loss)
I0324 08:52:55.765791 10083 sgd_solver.cpp:136] Iteration 1500, lr = 0.001, m = 0.9
I0324 08:54:02.514050 10083 solver.cpp:314] Iteration 1600 (1.49813 iter/s, 66.7498s/100 iter), loss = 3.25556
I0324 08:54:02.514166 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.78462 (* 1 = 2.78462 loss)
I0324 08:54:02.514277 10083 sgd_solver.cpp:136] Iteration 1600, lr = 0.001, m = 0.9
I0324 08:55:08.673763 10083 solver.cpp:314] Iteration 1700 (1.51154 iter/s, 66.1575s/100 iter), loss = 3.00994
I0324 08:55:08.675194 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.4656 (* 1 = 2.4656 loss)
I0324 08:55:08.675215 10083 sgd_solver.cpp:136] Iteration 1700, lr = 0.001, m = 0.9
I0324 08:56:15.619386 10083 solver.cpp:314] Iteration 1800 (1.4938 iter/s, 66.9434s/100 iter), loss = 3.11908
I0324 08:56:15.619477 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.37664 (* 1 = 2.37664 loss)
I0324 08:56:15.619493 10083 sgd_solver.cpp:136] Iteration 1800, lr = 0.001, m = 0.9
I0324 08:57:21.471570 10083 solver.cpp:314] Iteration 1900 (1.5186 iter/s, 65.85s/100 iter), loss = 2.91871
I0324 08:57:21.471673 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.37395 (* 1 = 2.37395 loss)
I0324 08:57:21.471690 10083 sgd_solver.cpp:136] Iteration 1900, lr = 0.001, m = 0.9
I0324 08:58:26.614470 10083 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_2000.caffemodel
I0324 08:58:26.696537 10083 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_2000.solverstate
I0324 08:58:26.717854 10083 solver.cpp:678] Iteration 2000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.281668
j:  : 4 : max_pr:  : 0.499211
j:  : 3 : max_pr:  : 0.638042
j:  : 2 : max_pr:  : 0.756757
j:  : 1 : max_pr:  : 0.86969
j:  : 0 : max_pr:  : 1
I0324 08:59:14.582674 10084 solver.cpp:786] class AP 1: 0.367761
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0767502
j:  : 7 : max_pr:  : 0.317872
j:  : 6 : max_pr:  : 0.494572
j:  : 5 : max_pr:  : 0.565765
j:  : 4 : max_pr:  : 0.653163
j:  : 3 : max_pr:  : 0.789919
j:  : 2 : max_pr:  : 0.982707
j:  : 1 : max_pr:  : 0.994638
j:  : 0 : max_pr:  : 1
I0324 08:59:14.636132 10084 solver.cpp:786] class AP 2: 0.534126
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.493905
j:  : 6 : max_pr:  : 0.660102
j:  : 5 : max_pr:  : 0.759923
j:  : 4 : max_pr:  : 0.869943
j:  : 3 : max_pr:  : 0.9217
j:  : 2 : max_pr:  : 0.963624
j:  : 1 : max_pr:  : 0.997902
j:  : 0 : max_pr:  : 1
I0324 08:59:14.646538 10084 solver.cpp:786] class AP 3: 0.6061
I0324 08:59:14.646555 10084 solver.cpp:792] Test net output mAP #0: detection_eval = 0.502662
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.285194
j:  : 4 : max_pr:  : 0.497033
j:  : 3 : max_pr:  : 0.63506
j:  : 2 : max_pr:  : 0.753901
j:  : 1 : max_pr:  : 0.845903
j:  : 0 : max_pr:  : 1
I0324 08:59:15.347476 10083 solver.cpp:786] class AP 1: 0.36519
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0969283
j:  : 7 : max_pr:  : 0.336253
j:  : 6 : max_pr:  : 0.528693
j:  : 5 : max_pr:  : 0.575193
j:  : 4 : max_pr:  : 0.670936
j:  : 3 : max_pr:  : 0.799834
j:  : 2 : max_pr:  : 0.97953
j:  : 1 : max_pr:  : 0.998092
j:  : 0 : max_pr:  : 1
I0324 08:59:15.391270 10083 solver.cpp:786] class AP 2: 0.544133
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.516013
j:  : 6 : max_pr:  : 0.662674
j:  : 5 : max_pr:  : 0.750971
j:  : 4 : max_pr:  : 0.859568
j:  : 3 : max_pr:  : 0.915937
j:  : 2 : max_pr:  : 0.959064
j:  : 1 : max_pr:  : 0.998656
j:  : 0 : max_pr:  : 1
I0324 08:59:15.401336 10083 solver.cpp:786] class AP 3: 0.605717
I0324 08:59:15.401352 10083 solver.cpp:792] Test net output mAP #0: detection_eval = 0.505013
I0324 08:59:15.401386 10083 solver.cpp:265] [MultiGPU] Tests completed in 48.682s
I0324 08:59:15.813282 10083 solver.cpp:314] Iteration 2000 (0.8746 iter/s, 114.338s/100 iter), loss = 3.06535
I0324 08:59:15.813319 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.88964 (* 1 = 2.88964 loss)
I0324 08:59:15.813333 10083 sgd_solver.cpp:136] Iteration 2000, lr = 0.001, m = 0.9
I0324 09:00:21.443449 10083 solver.cpp:314] Iteration 2100 (1.52374 iter/s, 65.628s/100 iter), loss = 3.19193
I0324 09:00:21.443625 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.41322 (* 1 = 2.41322 loss)
I0324 09:00:21.443645 10083 sgd_solver.cpp:136] Iteration 2100, lr = 0.001, m = 0.9
I0324 09:01:27.074345 10083 solver.cpp:314] Iteration 2200 (1.52372 iter/s, 65.6288s/100 iter), loss = 3.3706
I0324 09:01:27.074446 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.83994 (* 1 = 2.83994 loss)
I0324 09:01:27.074462 10083 sgd_solver.cpp:136] Iteration 2200, lr = 0.001, m = 0.9
I0324 09:02:32.420460 10083 solver.cpp:314] Iteration 2300 (1.53036 iter/s, 65.344s/100 iter), loss = 3.09919
I0324 09:02:32.420634 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.54147 (* 1 = 2.54147 loss)
I0324 09:02:32.420653 10083 sgd_solver.cpp:136] Iteration 2300, lr = 0.001, m = 0.9
I0324 09:03:37.169450 10083 solver.cpp:314] Iteration 2400 (1.54448 iter/s, 64.7469s/100 iter), loss = 2.83966
I0324 09:03:37.169556 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.57847 (* 1 = 2.57847 loss)
I0324 09:03:37.169574 10083 sgd_solver.cpp:136] Iteration 2400, lr = 0.001, m = 0.9
I0324 09:04:43.158571 10083 solver.cpp:314] Iteration 2500 (1.51545 iter/s, 65.987s/100 iter), loss = 2.98871
I0324 09:04:43.158676 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.27986 (* 1 = 3.27986 loss)
I0324 09:04:43.158695 10083 sgd_solver.cpp:136] Iteration 2500, lr = 0.001, m = 0.9
I0324 09:05:49.348317 10083 solver.cpp:314] Iteration 2600 (1.51086 iter/s, 66.1876s/100 iter), loss = 3.22764
I0324 09:05:49.348435 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.47847 (* 1 = 3.47847 loss)
I0324 09:05:49.348457 10083 sgd_solver.cpp:136] Iteration 2600, lr = 0.001, m = 0.9
I0324 09:06:55.681071 10083 solver.cpp:314] Iteration 2700 (1.5076 iter/s, 66.3306s/100 iter), loss = 2.96229
I0324 09:06:55.681569 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.7457 (* 1 = 2.7457 loss)
I0324 09:06:55.681882 10083 sgd_solver.cpp:136] Iteration 2700, lr = 0.001, m = 0.9
I0324 09:08:01.951398 10083 solver.cpp:314] Iteration 2800 (1.50902 iter/s, 66.2682s/100 iter), loss = 3.23058
I0324 09:08:01.951652 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.42605 (* 1 = 3.42605 loss)
I0324 09:08:01.951696 10083 sgd_solver.cpp:136] Iteration 2800, lr = 0.001, m = 0.9
I0324 09:09:08.039882 10083 solver.cpp:314] Iteration 2900 (1.51317 iter/s, 66.0863s/100 iter), loss = 3.2036
I0324 09:09:08.039991 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.91053 (* 1 = 2.91053 loss)
I0324 09:09:08.040009 10083 sgd_solver.cpp:136] Iteration 2900, lr = 0.001, m = 0.9
I0324 09:10:14.023964 10083 solver.cpp:314] Iteration 3000 (1.51557 iter/s, 65.9819s/100 iter), loss = 3.15313
I0324 09:10:14.024068 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.35828 (* 1 = 3.35828 loss)
I0324 09:10:14.024085 10083 sgd_solver.cpp:136] Iteration 3000, lr = 0.001, m = 0.9
I0324 09:11:19.794112 10083 solver.cpp:314] Iteration 3100 (1.5205 iter/s, 65.768s/100 iter), loss = 2.95725
I0324 09:11:19.794292 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.76831 (* 1 = 2.76831 loss)
I0324 09:11:19.794311 10083 sgd_solver.cpp:136] Iteration 3100, lr = 0.001, m = 0.9
I0324 09:11:31.189204 10054 data_reader.cpp:305] Starting prefetch of epoch 1
I0324 09:12:26.075053 10083 solver.cpp:314] Iteration 3200 (1.50878 iter/s, 66.2788s/100 iter), loss = 2.98791
I0324 09:12:26.075156 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.76584 (* 1 = 2.76584 loss)
I0324 09:12:26.075173 10083 sgd_solver.cpp:136] Iteration 3200, lr = 0.001, m = 0.9
I0324 09:13:30.889899 10083 solver.cpp:314] Iteration 3300 (1.54291 iter/s, 64.8127s/100 iter), loss = 2.99169
I0324 09:13:30.890112 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.26327 (* 1 = 2.26327 loss)
I0324 09:13:30.890132 10083 sgd_solver.cpp:136] Iteration 3300, lr = 0.001, m = 0.9
I0324 09:14:36.489217 10083 solver.cpp:314] Iteration 3400 (1.52446 iter/s, 65.5972s/100 iter), loss = 3.10574
I0324 09:14:36.489347 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.30216 (* 1 = 3.30216 loss)
I0324 09:14:36.489363 10083 sgd_solver.cpp:136] Iteration 3400, lr = 0.001, m = 0.9
I0324 09:15:42.338310 10083 solver.cpp:314] Iteration 3500 (1.51867 iter/s, 65.8469s/100 iter), loss = 3.03252
I0324 09:15:42.338498 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.49739 (* 1 = 2.49739 loss)
I0324 09:15:42.338520 10083 sgd_solver.cpp:136] Iteration 3500, lr = 0.001, m = 0.9
I0324 09:16:47.175521 10083 solver.cpp:314] Iteration 3600 (1.54237 iter/s, 64.8351s/100 iter), loss = 2.99447
I0324 09:16:47.175703 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.14501 (* 1 = 2.14501 loss)
I0324 09:16:47.175746 10083 sgd_solver.cpp:136] Iteration 3600, lr = 0.001, m = 0.9
I0324 09:17:53.169904 10083 solver.cpp:314] Iteration 3700 (1.51533 iter/s, 65.9922s/100 iter), loss = 2.95706
I0324 09:17:53.170017 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.86258 (* 1 = 3.86258 loss)
I0324 09:17:53.170032 10083 sgd_solver.cpp:136] Iteration 3700, lr = 0.001, m = 0.9
I0324 09:18:58.643550 10083 solver.cpp:314] Iteration 3800 (1.52738 iter/s, 65.4715s/100 iter), loss = 3.27154
I0324 09:18:58.643659 10083 solver.cpp:336]     Train net output #0: mbox_loss = 4.55452 (* 1 = 4.55452 loss)
I0324 09:18:58.643676 10083 sgd_solver.cpp:136] Iteration 3800, lr = 0.001, m = 0.9
I0324 09:20:03.782543 10083 solver.cpp:314] Iteration 3900 (1.53523 iter/s, 65.1369s/100 iter), loss = 2.98077
I0324 09:20:03.782639 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.66978 (* 1 = 2.66978 loss)
I0324 09:20:03.782655 10083 sgd_solver.cpp:136] Iteration 3900, lr = 0.001, m = 0.9
I0324 09:21:08.882030 10083 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_4000.caffemodel
I0324 09:21:08.909473 10083 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_4000.solverstate
I0324 09:21:08.921689 10083 solver.cpp:678] Iteration 4000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.336901
j:  : 4 : max_pr:  : 0.51796
j:  : 3 : max_pr:  : 0.643347
j:  : 2 : max_pr:  : 0.751035
j:  : 1 : max_pr:  : 0.853296
j:  : 0 : max_pr:  : 1
I0324 09:21:58.925617 10083 solver.cpp:786] class AP 1: 0.372958
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.240614
j:  : 7 : max_pr:  : 0.440159
j:  : 6 : max_pr:  : 0.574224
j:  : 5 : max_pr:  : 0.623277
j:  : 4 : max_pr:  : 0.690919
j:  : 3 : max_pr:  : 0.830638
j:  : 2 : max_pr:  : 0.99398
j:  : 1 : max_pr:  : 1
j:  : 0 : max_pr:  : 1
I0324 09:21:58.967504 10083 solver.cpp:786] class AP 2: 0.581256
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.514534
j:  : 6 : max_pr:  : 0.653479
j:  : 5 : max_pr:  : 0.741071
j:  : 4 : max_pr:  : 0.850862
j:  : 3 : max_pr:  : 0.9159
j:  : 2 : max_pr:  : 0.964026
j:  : 1 : max_pr:  : 0.998604
j:  : 0 : max_pr:  : 1
I0324 09:21:58.981500 10083 solver.cpp:786] class AP 3: 0.603498
I0324 09:21:58.981554 10083 solver.cpp:792] Test net output mAP #0: detection_eval = 0.519237
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.327693
j:  : 4 : max_pr:  : 0.509559
j:  : 3 : max_pr:  : 0.646388
j:  : 2 : max_pr:  : 0.756154
j:  : 1 : max_pr:  : 0.868791
j:  : 0 : max_pr:  : 1
I0324 09:21:59.924648 10084 solver.cpp:786] class AP 1: 0.373508
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.212321
j:  : 7 : max_pr:  : 0.426025
j:  : 6 : max_pr:  : 0.567057
j:  : 5 : max_pr:  : 0.62185
j:  : 4 : max_pr:  : 0.680717
j:  : 3 : max_pr:  : 0.821111
j:  : 2 : max_pr:  : 0.990868
j:  : 1 : max_pr:  : 0.998571
j:  : 0 : max_pr:  : 1
I0324 09:21:59.995380 10084 solver.cpp:786] class AP 2: 0.574411
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.512893
j:  : 6 : max_pr:  : 0.659066
j:  : 5 : max_pr:  : 0.762779
j:  : 4 : max_pr:  : 0.868184
j:  : 3 : max_pr:  : 0.917776
j:  : 2 : max_pr:  : 0.956478
j:  : 1 : max_pr:  : 0.999365
j:  : 0 : max_pr:  : 1
I0324 09:22:00.019726 10084 solver.cpp:786] class AP 3: 0.606958
I0324 09:22:00.019781 10084 solver.cpp:792] Test net output mAP #0: detection_eval = 0.518292
I0324 09:22:00.020586 10083 solver.cpp:265] [MultiGPU] Tests completed in 51.0972s
I0324 09:22:00.413300 10083 solver.cpp:314] Iteration 4000 (0.857435 iter/s, 116.627s/100 iter), loss = 3.1547
I0324 09:22:00.413413 10083 solver.cpp:336]     Train net output #0: mbox_loss = 4.88942 (* 1 = 4.88942 loss)
I0324 09:22:00.413451 10083 sgd_solver.cpp:136] Iteration 4000, lr = 0.001, m = 0.9
I0324 09:23:06.139673 10083 solver.cpp:314] Iteration 4100 (1.52151 iter/s, 65.7242s/100 iter), loss = 3.00668
I0324 09:23:06.139868 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.94694 (* 1 = 2.94694 loss)
I0324 09:23:06.139915 10083 sgd_solver.cpp:136] Iteration 4100, lr = 0.001, m = 0.9
I0324 09:24:12.123165 10083 solver.cpp:314] Iteration 4200 (1.51558 iter/s, 65.9813s/100 iter), loss = 3.01626
I0324 09:24:12.123256 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.1021 (* 1 = 3.1021 loss)
I0324 09:24:12.123272 10083 sgd_solver.cpp:136] Iteration 4200, lr = 0.001, m = 0.9
I0324 09:25:17.144243 10083 solver.cpp:314] Iteration 4300 (1.53801 iter/s, 65.0189s/100 iter), loss = 3.08331
I0324 09:25:17.144402 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.0705 (* 1 = 3.0705 loss)
I0324 09:25:17.144443 10083 sgd_solver.cpp:136] Iteration 4300, lr = 0.001, m = 0.9
I0324 09:26:22.981930 10083 solver.cpp:314] Iteration 4400 (1.51894 iter/s, 65.8355s/100 iter), loss = 2.94746
I0324 09:26:22.982069 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.53557 (* 1 = 3.53557 loss)
I0324 09:26:22.982086 10083 sgd_solver.cpp:136] Iteration 4400, lr = 0.001, m = 0.9
I0324 09:27:28.485041 10083 solver.cpp:314] Iteration 4500 (1.5267 iter/s, 65.501s/100 iter), loss = 2.85039
I0324 09:27:28.485221 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.54648 (* 1 = 2.54648 loss)
I0324 09:27:28.485239 10083 sgd_solver.cpp:136] Iteration 4500, lr = 0.001, m = 0.9
I0324 09:28:33.745914 10083 solver.cpp:314] Iteration 4600 (1.53236 iter/s, 65.2587s/100 iter), loss = 3.031
I0324 09:28:33.746013 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.83502 (* 1 = 2.83502 loss)
I0324 09:28:33.746031 10083 sgd_solver.cpp:136] Iteration 4600, lr = 0.001, m = 0.9
I0324 09:29:38.664458 10083 solver.cpp:314] Iteration 4700 (1.54044 iter/s, 64.9164s/100 iter), loss = 2.89083
I0324 09:29:38.664558 10083 solver.cpp:336]     Train net output #0: mbox_loss = 4.61076 (* 1 = 4.61076 loss)
I0324 09:29:38.664575 10083 sgd_solver.cpp:136] Iteration 4700, lr = 0.001, m = 0.9
I0324 09:30:45.288446 10083 solver.cpp:314] Iteration 4800 (1.50101 iter/s, 66.6218s/100 iter), loss = 3.25106
I0324 09:30:45.288548 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.121 (* 1 = 3.121 loss)
I0324 09:30:45.288563 10083 sgd_solver.cpp:136] Iteration 4800, lr = 0.001, m = 0.9
I0324 09:31:51.302361 10083 solver.cpp:314] Iteration 4900 (1.51488 iter/s, 66.0117s/100 iter), loss = 3.32716
I0324 09:31:51.302479 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.61356 (* 1 = 2.61356 loss)
I0324 09:31:51.302497 10083 sgd_solver.cpp:136] Iteration 4900, lr = 0.001, m = 0.9
I0324 09:32:57.325762 10083 solver.cpp:314] Iteration 5000 (1.51466 iter/s, 66.0212s/100 iter), loss = 2.99949
I0324 09:32:57.337841 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.30246 (* 1 = 3.30246 loss)
I0324 09:32:57.337899 10083 sgd_solver.cpp:136] Iteration 5000, lr = 0.001, m = 0.9
I0324 09:34:03.722185 10083 solver.cpp:314] Iteration 5100 (1.50615 iter/s, 66.3943s/100 iter), loss = 3.18761
I0324 09:34:03.722364 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.36864 (* 1 = 2.36864 loss)
I0324 09:34:03.722384 10083 sgd_solver.cpp:136] Iteration 5100, lr = 0.001, m = 0.9
I0324 09:35:09.700295 10083 solver.cpp:314] Iteration 5200 (1.5157 iter/s, 65.976s/100 iter), loss = 3.105
I0324 09:35:09.700456 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.27118 (* 1 = 3.27118 loss)
I0324 09:35:09.700498 10083 sgd_solver.cpp:136] Iteration 5200, lr = 0.001, m = 0.9
I0324 09:36:15.481951 10083 solver.cpp:314] Iteration 5300 (1.52023 iter/s, 65.7795s/100 iter), loss = 2.7928
I0324 09:36:15.482058 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.92976 (* 1 = 2.92976 loss)
I0324 09:36:15.482076 10083 sgd_solver.cpp:136] Iteration 5300, lr = 0.001, m = 0.9
I0324 09:37:20.669922 10083 solver.cpp:314] Iteration 5400 (1.53408 iter/s, 65.1858s/100 iter), loss = 3.16622
I0324 09:37:20.670034 10083 solver.cpp:336]     Train net output #0: mbox_loss = 1.89939 (* 1 = 1.89939 loss)
I0324 09:37:20.670050 10083 sgd_solver.cpp:136] Iteration 5400, lr = 0.001, m = 0.9
I0324 09:38:25.861963 10083 solver.cpp:314] Iteration 5500 (1.53398 iter/s, 65.1899s/100 iter), loss = 3.17244
I0324 09:38:25.862085 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.99756 (* 1 = 3.99756 loss)
I0324 09:38:25.862102 10083 sgd_solver.cpp:136] Iteration 5500, lr = 0.001, m = 0.9
I0324 09:39:31.507678 10083 solver.cpp:314] Iteration 5600 (1.52338 iter/s, 65.6436s/100 iter), loss = 3.30078
I0324 09:39:31.507791 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.14766 (* 1 = 2.14766 loss)
I0324 09:39:31.507807 10083 sgd_solver.cpp:136] Iteration 5600, lr = 0.001, m = 0.9
I0324 09:40:35.950744 10083 solver.cpp:314] Iteration 5700 (1.55181 iter/s, 64.441s/100 iter), loss = 3.2593
I0324 09:40:35.950875 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.75933 (* 1 = 3.75933 loss)
I0324 09:40:35.950891 10083 sgd_solver.cpp:136] Iteration 5700, lr = 0.001, m = 0.9
I0324 09:41:41.816356 10083 solver.cpp:314] Iteration 5800 (1.51829 iter/s, 65.8635s/100 iter), loss = 3.18935
I0324 09:41:41.816469 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.52823 (* 1 = 3.52823 loss)
I0324 09:41:41.816486 10083 sgd_solver.cpp:136] Iteration 5800, lr = 0.001, m = 0.9
I0324 09:42:47.966742 10083 solver.cpp:314] Iteration 5900 (1.51176 iter/s, 66.1482s/100 iter), loss = 3.1109
I0324 09:42:47.966866 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.57723 (* 1 = 2.57723 loss)
I0324 09:42:47.966891 10083 sgd_solver.cpp:136] Iteration 5900, lr = 0.001, m = 0.9
I0324 09:43:52.932119 10083 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_6000.caffemodel
I0324 09:43:52.964290 10083 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_6000.solverstate
I0324 09:43:52.976701 10083 solver.cpp:678] Iteration 6000, Testing net (#0)
I0324 09:44:40.840751 10070 data_reader.cpp:305] Starting prefetch of epoch 2
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.296825
j:  : 4 : max_pr:  : 0.489945
j:  : 3 : max_pr:  : 0.628373
j:  : 2 : max_pr:  : 0.743688
j:  : 1 : max_pr:  : 0.846826
j:  : 0 : max_pr:  : 1
I0324 09:44:41.314353 10083 solver.cpp:786] class AP 1: 0.364151
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.167022
j:  : 7 : max_pr:  : 0.434499
j:  : 6 : max_pr:  : 0.567149
j:  : 5 : max_pr:  : 0.646031
j:  : 4 : max_pr:  : 0.673407
j:  : 3 : max_pr:  : 0.80532
j:  : 2 : max_pr:  : 0.994807
j:  : 1 : max_pr:  : 1
j:  : 0 : max_pr:  : 1
I0324 09:44:41.352771 10083 solver.cpp:786] class AP 2: 0.571658
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.502563
j:  : 6 : max_pr:  : 0.643645
j:  : 5 : max_pr:  : 0.750992
j:  : 4 : max_pr:  : 0.853989
j:  : 3 : max_pr:  : 0.911771
j:  : 2 : max_pr:  : 0.963014
j:  : 1 : max_pr:  : 0.997374
j:  : 0 : max_pr:  : 1
I0324 09:44:41.366152 10083 solver.cpp:786] class AP 3: 0.602122
I0324 09:44:41.366168 10083 solver.cpp:792] Test net output mAP #0: detection_eval = 0.512644
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.273263
j:  : 4 : max_pr:  : 0.4752
j:  : 3 : max_pr:  : 0.613425
j:  : 2 : max_pr:  : 0.727848
j:  : 1 : max_pr:  : 0.837089
j:  : 0 : max_pr:  : 1
I0324 09:44:41.677351 10084 solver.cpp:786] class AP 1: 0.356984
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.118983
j:  : 7 : max_pr:  : 0.415896
j:  : 6 : max_pr:  : 0.55881
j:  : 5 : max_pr:  : 0.636658
j:  : 4 : max_pr:  : 0.665346
j:  : 3 : max_pr:  : 0.788068
j:  : 2 : max_pr:  : 0.990588
j:  : 1 : max_pr:  : 0.997312
j:  : 0 : max_pr:  : 1
I0324 09:44:41.716392 10084 solver.cpp:786] class AP 2: 0.56106
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.531228
j:  : 6 : max_pr:  : 0.667927
j:  : 5 : max_pr:  : 0.766819
j:  : 4 : max_pr:  : 0.865299
j:  : 3 : max_pr:  : 0.918726
j:  : 2 : max_pr:  : 0.959593
j:  : 1 : max_pr:  : 0.997213
j:  : 0 : max_pr:  : 1
I0324 09:44:41.729506 10084 solver.cpp:786] class AP 3: 0.60971
I0324 09:44:41.729522 10084 solver.cpp:792] Test net output mAP #0: detection_eval = 0.509251
I0324 09:44:41.730053 10083 solver.cpp:265] [MultiGPU] Tests completed in 48.7518s
I0324 09:44:42.097920 10083 solver.cpp:314] Iteration 6000 (0.876213 iter/s, 114.127s/100 iter), loss = 3.12532
I0324 09:44:42.097978 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.17177 (* 1 = 2.17177 loss)
I0324 09:44:42.097995 10083 sgd_solver.cpp:136] Iteration 6000, lr = 0.001, m = 0.9
I0324 09:45:48.669778 10083 solver.cpp:314] Iteration 6100 (1.50219 iter/s, 66.5697s/100 iter), loss = 3.17708
I0324 09:45:48.673766 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.38225 (* 1 = 2.38225 loss)
I0324 09:45:48.673799 10083 sgd_solver.cpp:136] Iteration 6100, lr = 0.001, m = 0.9
I0324 09:46:54.407492 10083 solver.cpp:314] Iteration 6200 (1.52125 iter/s, 65.7356s/100 iter), loss = 2.93577
I0324 09:46:54.407608 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.07717 (* 1 = 2.07717 loss)
I0324 09:46:54.407624 10083 sgd_solver.cpp:136] Iteration 6200, lr = 0.001, m = 0.9
I0324 09:47:59.932293 10083 solver.cpp:314] Iteration 6300 (1.52619 iter/s, 65.5227s/100 iter), loss = 3.02914
I0324 09:47:59.932405 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.94402 (* 1 = 2.94402 loss)
I0324 09:47:59.932422 10083 sgd_solver.cpp:136] Iteration 6300, lr = 0.001, m = 0.9
I0324 09:49:05.550712 10083 solver.cpp:314] Iteration 6400 (1.52401 iter/s, 65.6163s/100 iter), loss = 2.90643
I0324 09:49:05.550829 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.19209 (* 1 = 2.19209 loss)
I0324 09:49:05.550849 10083 sgd_solver.cpp:136] Iteration 6400, lr = 0.001, m = 0.9
I0324 09:50:12.296385 10083 solver.cpp:314] Iteration 6500 (1.49827 iter/s, 66.7435s/100 iter), loss = 3.15788
I0324 09:50:12.296496 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.07027 (* 1 = 2.07027 loss)
I0324 09:50:12.296512 10083 sgd_solver.cpp:136] Iteration 6500, lr = 0.001, m = 0.9
I0324 09:51:18.229938 10083 solver.cpp:314] Iteration 6600 (1.51673 iter/s, 65.9314s/100 iter), loss = 3.48092
I0324 09:51:18.230079 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.41252 (* 1 = 3.41252 loss)
I0324 09:51:18.230099 10083 sgd_solver.cpp:136] Iteration 6600, lr = 0.001, m = 0.9
I0324 09:52:23.838657 10083 solver.cpp:314] Iteration 6700 (1.52424 iter/s, 65.6066s/100 iter), loss = 3.04383
I0324 09:52:23.838842 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.25486 (* 1 = 3.25486 loss)
I0324 09:52:23.838886 10083 sgd_solver.cpp:136] Iteration 6700, lr = 0.001, m = 0.9
I0324 09:53:28.710218 10083 solver.cpp:314] Iteration 6800 (1.54156 iter/s, 64.8694s/100 iter), loss = 3.03596
I0324 09:53:28.710324 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.51556 (* 1 = 3.51556 loss)
I0324 09:53:28.710340 10083 sgd_solver.cpp:136] Iteration 6800, lr = 0.001, m = 0.9
I0324 09:54:34.938459 10083 solver.cpp:314] Iteration 6900 (1.50998 iter/s, 66.2261s/100 iter), loss = 3.06874
I0324 09:54:34.938557 10083 solver.cpp:336]     Train net output #0: mbox_loss = 4.15128 (* 1 = 4.15128 loss)
I0324 09:54:34.938572 10083 sgd_solver.cpp:136] Iteration 6900, lr = 0.001, m = 0.9
I0324 09:55:40.912425 10083 solver.cpp:314] Iteration 7000 (1.5158 iter/s, 65.9718s/100 iter), loss = 2.90014
I0324 09:55:40.912533 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.21378 (* 1 = 3.21378 loss)
I0324 09:55:40.912549 10083 sgd_solver.cpp:136] Iteration 7000, lr = 0.001, m = 0.9
I0324 09:56:46.683998 10083 solver.cpp:314] Iteration 7100 (1.52046 iter/s, 65.7694s/100 iter), loss = 2.88167
I0324 09:56:46.685966 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.56645 (* 1 = 3.56645 loss)
I0324 09:56:46.685992 10083 sgd_solver.cpp:136] Iteration 7100, lr = 0.001, m = 0.9
I0324 09:57:51.819330 10083 solver.cpp:314] Iteration 7200 (1.53532 iter/s, 65.1332s/100 iter), loss = 3.13706
I0324 09:57:51.819475 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.68964 (* 1 = 2.68964 loss)
I0324 09:57:51.819520 10083 sgd_solver.cpp:136] Iteration 7200, lr = 0.001, m = 0.9
I0324 09:58:57.393767 10083 solver.cpp:314] Iteration 7300 (1.52503 iter/s, 65.5723s/100 iter), loss = 2.88594
I0324 09:58:57.393880 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.98235 (* 1 = 2.98235 loss)
I0324 09:58:57.393899 10083 sgd_solver.cpp:136] Iteration 7300, lr = 0.001, m = 0.9
I0324 10:00:03.963029 10083 solver.cpp:314] Iteration 7400 (1.50224 iter/s, 66.5671s/100 iter), loss = 2.95215
I0324 10:00:03.963120 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.52391 (* 1 = 2.52391 loss)
I0324 10:00:03.963135 10083 sgd_solver.cpp:136] Iteration 7400, lr = 0.001, m = 0.9
I0324 10:01:08.742985 10083 solver.cpp:314] Iteration 7500 (1.54374 iter/s, 64.7778s/100 iter), loss = 2.86254
I0324 10:01:08.743089 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.5964 (* 1 = 3.5964 loss)
I0324 10:01:08.743105 10083 sgd_solver.cpp:136] Iteration 7500, lr = 0.001, m = 0.9
I0324 10:02:14.079020 10083 solver.cpp:314] Iteration 7600 (1.5306 iter/s, 65.3339s/100 iter), loss = 3.04271
I0324 10:02:14.079120 10083 solver.cpp:336]     Train net output #0: mbox_loss = 4.12975 (* 1 = 4.12975 loss)
I0324 10:02:14.079138 10083 sgd_solver.cpp:136] Iteration 7600, lr = 0.001, m = 0.9
I0324 10:03:19.717967 10083 solver.cpp:314] Iteration 7700 (1.52354 iter/s, 65.6368s/100 iter), loss = 3.01827
I0324 10:03:19.718210 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.4527 (* 1 = 2.4527 loss)
I0324 10:03:19.718264 10083 sgd_solver.cpp:136] Iteration 7700, lr = 0.001, m = 0.9
I0324 10:04:25.280556 10083 solver.cpp:314] Iteration 7800 (1.52531 iter/s, 65.5605s/100 iter), loss = 3.16773
I0324 10:04:25.280665 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.23068 (* 1 = 3.23068 loss)
I0324 10:04:25.280685 10083 sgd_solver.cpp:136] Iteration 7800, lr = 0.001, m = 0.9
I0324 10:05:31.235244 10083 solver.cpp:314] Iteration 7900 (1.51624 iter/s, 65.9525s/100 iter), loss = 3.24847
I0324 10:05:31.235340 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.06233 (* 1 = 2.06233 loss)
I0324 10:05:31.235611 10083 sgd_solver.cpp:136] Iteration 7900, lr = 0.001, m = 0.9
I0324 10:06:36.123790 10083 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_8000.caffemodel
I0324 10:06:36.150462 10083 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_8000.solverstate
I0324 10:06:36.163172 10083 solver.cpp:678] Iteration 8000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.342483
j:  : 4 : max_pr:  : 0.525839
j:  : 3 : max_pr:  : 0.651379
j:  : 2 : max_pr:  : 0.763392
j:  : 1 : max_pr:  : 0.860794
j:  : 0 : max_pr:  : 1
I0324 10:07:29.788473 10083 solver.cpp:786] class AP 1: 0.376717
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.114808
j:  : 7 : max_pr:  : 0.320628
j:  : 6 : max_pr:  : 0.435487
j:  : 5 : max_pr:  : 0.563766
j:  : 4 : max_pr:  : 0.680616
j:  : 3 : max_pr:  : 0.74953
j:  : 2 : max_pr:  : 0.986607
j:  : 1 : max_pr:  : 0.997573
j:  : 0 : max_pr:  : 1
I0324 10:07:29.831230 10083 solver.cpp:786] class AP 2: 0.531729
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.515668
j:  : 6 : max_pr:  : 0.66504
j:  : 5 : max_pr:  : 0.766326
j:  : 4 : max_pr:  : 0.875446
j:  : 3 : max_pr:  : 0.926845
j:  : 2 : max_pr:  : 0.97072
j:  : 1 : max_pr:  : 0.998843
j:  : 0 : max_pr:  : 1
I0324 10:07:29.842672 10083 solver.cpp:786] class AP 3: 0.610808
I0324 10:07:29.842690 10083 solver.cpp:792] Test net output mAP #0: detection_eval = 0.506418
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.336075
j:  : 4 : max_pr:  : 0.503746
j:  : 3 : max_pr:  : 0.637491
j:  : 2 : max_pr:  : 0.755085
j:  : 1 : max_pr:  : 0.860937
j:  : 0 : max_pr:  : 1
I0324 10:07:31.067977 10084 solver.cpp:786] class AP 1: 0.372121
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.099355
j:  : 7 : max_pr:  : 0.337903
j:  : 6 : max_pr:  : 0.446599
j:  : 5 : max_pr:  : 0.581391
j:  : 4 : max_pr:  : 0.687974
j:  : 3 : max_pr:  : 0.745006
j:  : 2 : max_pr:  : 0.985237
j:  : 1 : max_pr:  : 0.99806
j:  : 0 : max_pr:  : 1
I0324 10:07:31.108721 10084 solver.cpp:786] class AP 2: 0.534684
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.515302
j:  : 6 : max_pr:  : 0.664672
j:  : 5 : max_pr:  : 0.762901
j:  : 4 : max_pr:  : 0.872713
j:  : 3 : max_pr:  : 0.924874
j:  : 2 : max_pr:  : 0.964431
j:  : 1 : max_pr:  : 0.999375
j:  : 0 : max_pr:  : 1
I0324 10:07:31.120077 10084 solver.cpp:786] class AP 3: 0.609479
I0324 10:07:31.120096 10084 solver.cpp:792] Test net output mAP #0: detection_eval = 0.505428
I0324 10:07:31.120609 10083 solver.cpp:265] [MultiGPU] Tests completed in 54.9557s
I0324 10:07:31.490934 10083 solver.cpp:314] Iteration 8000 (0.831589 iter/s, 120.252s/100 iter), loss = 2.92423
I0324 10:07:31.490979 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.5013 (* 1 = 2.5013 loss)
I0324 10:07:31.490993 10083 sgd_solver.cpp:136] Iteration 8000, lr = 0.001, m = 0.9
I0324 10:08:36.613749 10083 solver.cpp:314] Iteration 8100 (1.53561 iter/s, 65.1207s/100 iter), loss = 3.07723
I0324 10:08:36.613847 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.72503 (* 1 = 2.72503 loss)
I0324 10:08:36.613865 10083 sgd_solver.cpp:136] Iteration 8100, lr = 0.001, m = 0.9
I0324 10:09:42.205750 10083 solver.cpp:314] Iteration 8200 (1.52463 iter/s, 65.5899s/100 iter), loss = 2.96729
I0324 10:09:42.205850 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.1228 (* 1 = 3.1228 loss)
I0324 10:09:42.205869 10083 sgd_solver.cpp:136] Iteration 8200, lr = 0.001, m = 0.9
I0324 10:10:47.896883 10083 solver.cpp:314] Iteration 8300 (1.52233 iter/s, 65.689s/100 iter), loss = 2.92598
I0324 10:10:47.896984 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.27498 (* 1 = 2.27498 loss)
I0324 10:10:47.896999 10083 sgd_solver.cpp:136] Iteration 8300, lr = 0.001, m = 0.9
I0324 10:11:52.351347 10083 solver.cpp:314] Iteration 8400 (1.55153 iter/s, 64.4524s/100 iter), loss = 2.81479
I0324 10:11:52.351457 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.52976 (* 1 = 3.52976 loss)
I0324 10:11:52.351474 10083 sgd_solver.cpp:136] Iteration 8400, lr = 0.001, m = 0.9
I0324 10:12:58.090095 10083 solver.cpp:314] Iteration 8500 (1.52122 iter/s, 65.7366s/100 iter), loss = 3.25672
I0324 10:12:58.090207 10083 solver.cpp:336]     Train net output #0: mbox_loss = 4.45862 (* 1 = 4.45862 loss)
I0324 10:12:58.090224 10083 sgd_solver.cpp:136] Iteration 8500, lr = 0.001, m = 0.9
I0324 10:14:04.029927 10083 solver.cpp:314] Iteration 8600 (1.51658 iter/s, 65.9377s/100 iter), loss = 3.11396
I0324 10:14:04.030035 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.79218 (* 1 = 3.79218 loss)
I0324 10:14:04.030053 10083 sgd_solver.cpp:136] Iteration 8600, lr = 0.001, m = 0.9
I0324 10:15:09.972977 10083 solver.cpp:314] Iteration 8700 (1.51651 iter/s, 65.9409s/100 iter), loss = 2.99045
I0324 10:15:09.973078 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.9085 (* 1 = 2.9085 loss)
I0324 10:15:09.973094 10083 sgd_solver.cpp:136] Iteration 8700, lr = 0.001, m = 0.9
I0324 10:16:15.917850 10083 solver.cpp:314] Iteration 8800 (1.51647 iter/s, 65.9427s/100 iter), loss = 3.33457
I0324 10:16:15.917949 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.54094 (* 1 = 3.54094 loss)
I0324 10:16:15.917966 10083 sgd_solver.cpp:136] Iteration 8800, lr = 0.001, m = 0.9
I0324 10:17:22.816375 10083 solver.cpp:314] Iteration 8900 (1.49485 iter/s, 66.8963s/100 iter), loss = 3.05041
I0324 10:17:22.816493 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.30611 (* 1 = 3.30611 loss)
I0324 10:17:22.816509 10083 sgd_solver.cpp:136] Iteration 8900, lr = 0.001, m = 0.9
I0324 10:18:29.215503 10083 solver.cpp:314] Iteration 9000 (1.50609 iter/s, 66.397s/100 iter), loss = 3.12145
I0324 10:18:29.215625 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.40954 (* 1 = 2.40954 loss)
I0324 10:18:29.215641 10083 sgd_solver.cpp:136] Iteration 9000, lr = 0.001, m = 0.9
I0324 10:18:46.520473 10054 data_reader.cpp:305] Starting prefetch of epoch 2
I0324 10:19:35.351722 10083 solver.cpp:314] Iteration 9100 (1.51208 iter/s, 66.1341s/100 iter), loss = 3.08607
I0324 10:19:35.351827 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.59332 (* 1 = 2.59332 loss)
I0324 10:19:35.351845 10083 sgd_solver.cpp:136] Iteration 9100, lr = 0.001, m = 0.9
I0324 10:20:40.922183 10083 solver.cpp:314] Iteration 9200 (1.52513 iter/s, 65.5683s/100 iter), loss = 3.05531
I0324 10:20:40.922341 10083 solver.cpp:336]     Train net output #0: mbox_loss = 1.85453 (* 1 = 1.85453 loss)
I0324 10:20:40.922384 10083 sgd_solver.cpp:136] Iteration 9200, lr = 0.001, m = 0.9
I0324 10:21:47.272367 10083 solver.cpp:314] Iteration 9300 (1.5072 iter/s, 66.348s/100 iter), loss = 3.10135
I0324 10:21:47.272465 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.1451 (* 1 = 2.1451 loss)
I0324 10:21:47.272485 10083 sgd_solver.cpp:136] Iteration 9300, lr = 0.001, m = 0.9
I0324 10:22:53.309769 10083 solver.cpp:314] Iteration 9400 (1.51434 iter/s, 66.0352s/100 iter), loss = 3.15982
I0324 10:22:53.309877 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.30405 (* 1 = 3.30405 loss)
I0324 10:22:53.309898 10083 sgd_solver.cpp:136] Iteration 9400, lr = 0.001, m = 0.9
I0324 10:23:59.653754 10083 solver.cpp:314] Iteration 9500 (1.50734 iter/s, 66.3418s/100 iter), loss = 3.21677
I0324 10:23:59.653857 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.76981 (* 1 = 2.76981 loss)
I0324 10:23:59.653877 10083 sgd_solver.cpp:136] Iteration 9500, lr = 0.001, m = 0.9
I0324 10:25:06.961941 10083 solver.cpp:314] Iteration 9600 (1.48575 iter/s, 67.306s/100 iter), loss = 2.87306
I0324 10:25:06.962049 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.58944 (* 1 = 2.58944 loss)
I0324 10:25:06.962067 10083 sgd_solver.cpp:136] Iteration 9600, lr = 0.001, m = 0.9
I0324 10:26:12.892803 10083 solver.cpp:314] Iteration 9700 (1.51679 iter/s, 65.9287s/100 iter), loss = 3.18552
I0324 10:26:12.893038 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.41537 (* 1 = 3.41537 loss)
I0324 10:26:12.893081 10083 sgd_solver.cpp:136] Iteration 9700, lr = 0.001, m = 0.9
I0324 10:27:18.799564 10083 solver.cpp:314] Iteration 9800 (1.51734 iter/s, 65.9046s/100 iter), loss = 3.01559
I0324 10:27:18.799758 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.4732 (* 1 = 2.4732 loss)
I0324 10:27:18.799774 10083 sgd_solver.cpp:136] Iteration 9800, lr = 0.001, m = 0.9
I0324 10:28:24.416560 10083 solver.cpp:314] Iteration 9900 (1.52404 iter/s, 65.6149s/100 iter), loss = 3.22466
I0324 10:28:24.417973 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.12751 (* 1 = 3.12751 loss)
I0324 10:28:24.417999 10083 sgd_solver.cpp:136] Iteration 9900, lr = 0.001, m = 0.9
I0324 10:29:30.880741 10083 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_10000.caffemodel
I0324 10:29:30.914352 10083 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_10000.solverstate
I0324 10:29:30.928040 10083 solver.cpp:678] Iteration 10000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.324625
j:  : 4 : max_pr:  : 0.489839
j:  : 3 : max_pr:  : 0.630714
j:  : 2 : max_pr:  : 0.740324
j:  : 1 : max_pr:  : 0.847513
j:  : 0 : max_pr:  : 1
I0324 10:30:20.685274 10084 solver.cpp:786] class AP 1: 0.366638
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0686897
j:  : 7 : max_pr:  : 0.236766
j:  : 6 : max_pr:  : 0.43958
j:  : 5 : max_pr:  : 0.557485
j:  : 4 : max_pr:  : 0.69564
j:  : 3 : max_pr:  : 0.797107
j:  : 2 : max_pr:  : 0.980466
j:  : 1 : max_pr:  : 0.997639
j:  : 0 : max_pr:  : 1
I0324 10:30:20.738822 10084 solver.cpp:786] class AP 2: 0.524852
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.54699
j:  : 6 : max_pr:  : 0.663597
j:  : 5 : max_pr:  : 0.758219
j:  : 4 : max_pr:  : 0.865911
j:  : 3 : max_pr:  : 0.918296
j:  : 2 : max_pr:  : 0.965016
j:  : 1 : max_pr:  : 0.998695
j:  : 0 : max_pr:  : 1
I0324 10:30:20.748461 10084 solver.cpp:786] class AP 3: 0.610611
I0324 10:30:20.748499 10084 solver.cpp:792] Test net output mAP #0: detection_eval = 0.5007
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.325735
j:  : 4 : max_pr:  : 0.490009
j:  : 3 : max_pr:  : 0.637275
j:  : 2 : max_pr:  : 0.746412
j:  : 1 : max_pr:  : 0.858182
j:  : 0 : max_pr:  : 1
I0324 10:30:21.353530 10083 solver.cpp:786] class AP 1: 0.368874
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0502728
j:  : 7 : max_pr:  : 0.23424
j:  : 6 : max_pr:  : 0.445634
j:  : 5 : max_pr:  : 0.563828
j:  : 4 : max_pr:  : 0.677579
j:  : 3 : max_pr:  : 0.785514
j:  : 2 : max_pr:  : 0.988679
j:  : 1 : max_pr:  : 0.99562
j:  : 0 : max_pr:  : 1
I0324 10:30:21.399993 10083 solver.cpp:786] class AP 2: 0.521942
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.520967
j:  : 6 : max_pr:  : 0.655758
j:  : 5 : max_pr:  : 0.766336
j:  : 4 : max_pr:  : 0.878011
j:  : 3 : max_pr:  : 0.922977
j:  : 2 : max_pr:  : 0.969016
j:  : 1 : max_pr:  : 0.997995
j:  : 0 : max_pr:  : 1
I0324 10:30:21.409435 10083 solver.cpp:786] class AP 3: 0.610096
I0324 10:30:21.409449 10083 solver.cpp:792] Test net output mAP #0: detection_eval = 0.500304
I0324 10:30:21.410054 10083 solver.cpp:265] [MultiGPU] Tests completed in 50.4804s
I0324 10:30:21.760885 10083 solver.cpp:314] Iteration 10000 (0.852221 iter/s, 117.341s/100 iter), loss = 3.1151
I0324 10:30:21.760995 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.99527 (* 1 = 2.99527 loss)
I0324 10:30:21.761034 10083 sgd_solver.cpp:136] Iteration 10000, lr = 0.001, m = 0.9
I0324 10:31:27.230036 10083 solver.cpp:314] Iteration 10100 (1.52749 iter/s, 65.467s/100 iter), loss = 2.92513
I0324 10:31:27.230222 10083 solver.cpp:336]     Train net output #0: mbox_loss = 1.99041 (* 1 = 1.99041 loss)
I0324 10:31:27.230265 10083 sgd_solver.cpp:136] Iteration 10100, lr = 0.001, m = 0.9
I0324 10:32:32.986987 10083 solver.cpp:314] Iteration 10200 (1.5208 iter/s, 65.7548s/100 iter), loss = 2.97309
I0324 10:32:32.987083 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.11181 (* 1 = 2.11181 loss)
I0324 10:32:32.987099 10083 sgd_solver.cpp:136] Iteration 10200, lr = 0.001, m = 0.9
I0324 10:33:41.126124 10083 solver.cpp:314] Iteration 10300 (1.46763 iter/s, 68.1369s/100 iter), loss = 2.84136
I0324 10:33:41.126281 10083 solver.cpp:336]     Train net output #0: mbox_loss = 4.09822 (* 1 = 4.09822 loss)
I0324 10:33:41.126298 10083 sgd_solver.cpp:136] Iteration 10300, lr = 0.001, m = 0.9
I0324 10:34:48.718690 10083 solver.cpp:314] Iteration 10400 (1.4795 iter/s, 67.5904s/100 iter), loss = 3.01335
I0324 10:34:48.718782 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.80976 (* 1 = 2.80976 loss)
I0324 10:34:48.718799 10083 sgd_solver.cpp:136] Iteration 10400, lr = 0.001, m = 0.9
I0324 10:35:54.573971 10083 solver.cpp:314] Iteration 10500 (1.51853 iter/s, 65.8531s/100 iter), loss = 3.2187
I0324 10:35:54.574206 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.96489 (* 1 = 3.96489 loss)
I0324 10:35:54.574260 10083 sgd_solver.cpp:136] Iteration 10500, lr = 0.001, m = 0.9
I0324 10:37:02.225808 10083 solver.cpp:314] Iteration 10600 (1.4782 iter/s, 67.6496s/100 iter), loss = 2.8055
I0324 10:37:02.225926 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.47172 (* 1 = 3.47172 loss)
I0324 10:37:02.225949 10083 sgd_solver.cpp:136] Iteration 10600, lr = 0.001, m = 0.9
I0324 10:38:09.482158 10083 solver.cpp:314] Iteration 10700 (1.4869 iter/s, 67.2542s/100 iter), loss = 2.85171
I0324 10:38:09.482317 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.27742 (* 1 = 3.27742 loss)
I0324 10:38:09.482360 10083 sgd_solver.cpp:136] Iteration 10700, lr = 0.001, m = 0.9
I0324 10:39:17.870036 10083 solver.cpp:314] Iteration 10800 (1.4623 iter/s, 68.3857s/100 iter), loss = 3.04916
I0324 10:39:17.871783 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.19705 (* 1 = 3.19705 loss)
I0324 10:39:17.871803 10083 sgd_solver.cpp:136] Iteration 10800, lr = 0.001, m = 0.9
I0324 10:40:25.838138 10083 solver.cpp:314] Iteration 10900 (1.47133 iter/s, 67.9659s/100 iter), loss = 3.07635
I0324 10:40:25.838239 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.98027 (* 1 = 2.98027 loss)
I0324 10:40:25.838256 10083 sgd_solver.cpp:136] Iteration 10900, lr = 0.001, m = 0.9
I0324 10:41:32.281754 10083 solver.cpp:314] Iteration 11000 (1.50551 iter/s, 66.4226s/100 iter), loss = 3.10984
I0324 10:41:32.282315 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.67763 (* 1 = 3.67763 loss)
I0324 10:41:32.282639 10083 sgd_solver.cpp:136] Iteration 11000, lr = 0.001, m = 0.9
I0324 10:42:40.442106 10083 solver.cpp:314] Iteration 11100 (1.46718 iter/s, 68.1581s/100 iter), loss = 2.9678
I0324 10:42:40.442260 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.56611 (* 1 = 2.56611 loss)
I0324 10:42:40.442303 10083 sgd_solver.cpp:136] Iteration 11100, lr = 0.001, m = 0.9
I0324 10:43:47.999115 10083 solver.cpp:314] Iteration 11200 (1.48028 iter/s, 67.5548s/100 iter), loss = 2.9479
I0324 10:43:47.999244 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.46354 (* 1 = 2.46354 loss)
I0324 10:43:47.999260 10083 sgd_solver.cpp:136] Iteration 11200, lr = 0.001, m = 0.9
I0324 10:44:54.941747 10083 solver.cpp:314] Iteration 11300 (1.49387 iter/s, 66.9405s/100 iter), loss = 2.80298
I0324 10:44:54.941843 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.47088 (* 1 = 3.47088 loss)
I0324 10:44:54.941859 10083 sgd_solver.cpp:136] Iteration 11300, lr = 0.001, m = 0.9
I0324 10:46:03.649996 10083 solver.cpp:314] Iteration 11400 (1.45548 iter/s, 68.706s/100 iter), loss = 3.01003
I0324 10:46:03.650089 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.43691 (* 1 = 2.43691 loss)
I0324 10:46:03.650104 10083 sgd_solver.cpp:136] Iteration 11400, lr = 0.001, m = 0.9
I0324 10:47:11.365954 10083 solver.cpp:314] Iteration 11500 (1.4768 iter/s, 67.7138s/100 iter), loss = 3.11824
I0324 10:47:11.366046 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.38975 (* 1 = 2.38975 loss)
I0324 10:47:11.366062 10083 sgd_solver.cpp:136] Iteration 11500, lr = 0.001, m = 0.9
I0324 10:48:17.670912 10083 solver.cpp:314] Iteration 11600 (1.50823 iter/s, 66.3028s/100 iter), loss = 2.92027
I0324 10:48:17.671119 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.22984 (* 1 = 3.22984 loss)
I0324 10:48:17.671136 10083 sgd_solver.cpp:136] Iteration 11600, lr = 0.001, m = 0.9
I0324 10:49:27.565131 10083 solver.cpp:314] Iteration 11700 (1.43078 iter/s, 69.8919s/100 iter), loss = 2.91684
I0324 10:49:27.565238 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.39208 (* 1 = 3.39208 loss)
I0324 10:49:27.565259 10083 sgd_solver.cpp:136] Iteration 11700, lr = 0.001, m = 0.9
I0324 10:50:36.010437 10083 solver.cpp:314] Iteration 11800 (1.46107 iter/s, 68.4431s/100 iter), loss = 2.84315
I0324 10:50:36.010577 10083 solver.cpp:336]     Train net output #0: mbox_loss = 4.02965 (* 1 = 4.02965 loss)
I0324 10:50:36.010612 10083 sgd_solver.cpp:136] Iteration 11800, lr = 0.001, m = 0.9
I0324 10:51:44.111374 10083 solver.cpp:314] Iteration 11900 (1.46846 iter/s, 68.0987s/100 iter), loss = 3.02284
I0324 10:51:44.111829 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.45406 (* 1 = 3.45406 loss)
I0324 10:51:44.111845 10083 sgd_solver.cpp:136] Iteration 11900, lr = 0.001, m = 0.9
I0324 10:52:50.600489 10083 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_12000.caffemodel
I0324 10:52:50.641732 10083 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_12000.solverstate
I0324 10:52:50.652000 10083 solver.cpp:678] Iteration 12000, Testing net (#0)
I0324 10:53:42.275508 10070 data_reader.cpp:305] Starting prefetch of epoch 3
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.264077
j:  : 4 : max_pr:  : 0.484745
j:  : 3 : max_pr:  : 0.637569
j:  : 2 : max_pr:  : 0.757506
j:  : 1 : max_pr:  : 0.868361
j:  : 0 : max_pr:  : 1
I0324 10:53:43.159168 10083 solver.cpp:786] class AP 1: 0.364751
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.238267
j:  : 6 : max_pr:  : 0.398906
j:  : 5 : max_pr:  : 0.542862
j:  : 4 : max_pr:  : 0.686499
j:  : 3 : max_pr:  : 0.801993
j:  : 2 : max_pr:  : 0.969127
j:  : 1 : max_pr:  : 0.99442
j:  : 0 : max_pr:  : 1
I0324 10:53:43.231019 10083 solver.cpp:786] class AP 2: 0.512007
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.477218
j:  : 6 : max_pr:  : 0.635659
j:  : 5 : max_pr:  : 0.744188
j:  : 4 : max_pr:  : 0.858005
j:  : 3 : max_pr:  : 0.917329
j:  : 2 : max_pr:  : 0.962888
j:  : 1 : max_pr:  : 0.99806
j:  : 0 : max_pr:  : 1
I0324 10:53:43.242453 10083 solver.cpp:786] class AP 3: 0.599395
I0324 10:53:43.242476 10083 solver.cpp:792] Test net output mAP #0: detection_eval = 0.492051
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.281098
j:  : 4 : max_pr:  : 0.490188
j:  : 3 : max_pr:  : 0.639219
j:  : 2 : max_pr:  : 0.759372
j:  : 1 : max_pr:  : 0.865467
j:  : 0 : max_pr:  : 1
I0324 10:53:43.327648 10084 solver.cpp:786] class AP 1: 0.366849
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.251697
j:  : 6 : max_pr:  : 0.398026
j:  : 5 : max_pr:  : 0.552074
j:  : 4 : max_pr:  : 0.710742
j:  : 3 : max_pr:  : 0.811955
j:  : 2 : max_pr:  : 0.984974
j:  : 1 : max_pr:  : 1
j:  : 0 : max_pr:  : 1
I0324 10:53:43.381050 10084 solver.cpp:786] class AP 2: 0.519042
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.489252
j:  : 6 : max_pr:  : 0.635074
j:  : 5 : max_pr:  : 0.732899
j:  : 4 : max_pr:  : 0.847252
j:  : 3 : max_pr:  : 0.914769
j:  : 2 : max_pr:  : 0.965208
j:  : 1 : max_pr:  : 0.997967
j:  : 0 : max_pr:  : 1
I0324 10:53:43.389904 10084 solver.cpp:786] class AP 3: 0.598402
I0324 10:53:43.389930 10084 solver.cpp:792] Test net output mAP #0: detection_eval = 0.494765
I0324 10:53:43.390389 10083 solver.cpp:265] [MultiGPU] Tests completed in 52.7367s
I0324 10:53:43.930310 10083 solver.cpp:314] Iteration 12000 (0.83462 iter/s, 119.815s/100 iter), loss = 2.89279
I0324 10:53:43.930352 10083 solver.cpp:336]     Train net output #0: mbox_loss = 4.0233 (* 1 = 4.0233 loss)
I0324 10:53:43.930361 10083 sgd_solver.cpp:136] Iteration 12000, lr = 0.001, m = 0.9
I0324 10:54:50.409168 10083 solver.cpp:314] Iteration 12100 (1.50429 iter/s, 66.4767s/100 iter), loss = 2.99483
I0324 10:54:50.409303 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.02588 (* 1 = 3.02588 loss)
I0324 10:54:50.409319 10083 sgd_solver.cpp:136] Iteration 12100, lr = 0.001, m = 0.9
I0324 10:55:57.961875 10083 solver.cpp:314] Iteration 12200 (1.48037 iter/s, 67.5505s/100 iter), loss = 3.1739
I0324 10:55:57.961978 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.65333 (* 1 = 2.65333 loss)
I0324 10:55:57.961994 10083 sgd_solver.cpp:136] Iteration 12200, lr = 0.001, m = 0.9
I0324 10:57:04.145038 10083 solver.cpp:314] Iteration 12300 (1.51101 iter/s, 66.181s/100 iter), loss = 3.00801
I0324 10:57:04.145148 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.9163 (* 1 = 3.9163 loss)
I0324 10:57:04.145166 10083 sgd_solver.cpp:136] Iteration 12300, lr = 0.001, m = 0.9
I0324 10:58:12.514222 10083 solver.cpp:314] Iteration 12400 (1.4627 iter/s, 68.367s/100 iter), loss = 2.85983
I0324 10:58:12.514330 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.57903 (* 1 = 2.57903 loss)
I0324 10:58:12.514346 10083 sgd_solver.cpp:136] Iteration 12400, lr = 0.001, m = 0.9
I0324 10:59:20.544383 10083 solver.cpp:314] Iteration 12500 (1.46998 iter/s, 68.0279s/100 iter), loss = 3.1745
I0324 10:59:20.544505 10083 solver.cpp:336]     Train net output #0: mbox_loss = 4.98734 (* 1 = 4.98734 loss)
I0324 10:59:20.544523 10083 sgd_solver.cpp:136] Iteration 12500, lr = 0.001, m = 0.9
I0324 11:00:28.372761 10083 solver.cpp:314] Iteration 12600 (1.47436 iter/s, 67.8262s/100 iter), loss = 2.70914
I0324 11:00:28.372877 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.43773 (* 1 = 2.43773 loss)
I0324 11:00:28.372895 10083 sgd_solver.cpp:136] Iteration 12600, lr = 0.001, m = 0.9
I0324 11:01:35.677950 10083 solver.cpp:314] Iteration 12700 (1.48582 iter/s, 67.303s/100 iter), loss = 2.77947
I0324 11:01:35.678042 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.32714 (* 1 = 2.32714 loss)
I0324 11:01:35.678058 10083 sgd_solver.cpp:136] Iteration 12700, lr = 0.001, m = 0.9
I0324 11:02:42.613850 10083 solver.cpp:314] Iteration 12800 (1.49402 iter/s, 66.9337s/100 iter), loss = 2.86551
I0324 11:02:42.613950 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.57583 (* 1 = 2.57583 loss)
I0324 11:02:42.613968 10083 sgd_solver.cpp:136] Iteration 12800, lr = 0.001, m = 0.9
I0324 11:03:49.727102 10083 solver.cpp:314] Iteration 12900 (1.49007 iter/s, 67.1111s/100 iter), loss = 3.08087
I0324 11:03:49.727208 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.52616 (* 1 = 3.52616 loss)
I0324 11:03:49.727226 10083 sgd_solver.cpp:136] Iteration 12900, lr = 0.001, m = 0.9
I0324 11:04:57.661759 10083 solver.cpp:314] Iteration 13000 (1.47205 iter/s, 67.9324s/100 iter), loss = 3.2795
I0324 11:04:57.669754 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.86449 (* 1 = 3.86449 loss)
I0324 11:04:57.669783 10083 sgd_solver.cpp:136] Iteration 13000, lr = 0.001, m = 0.9
I0324 11:06:04.617319 10083 solver.cpp:314] Iteration 13100 (1.49358 iter/s, 66.9534s/100 iter), loss = 3.13004
I0324 11:06:04.617527 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.21113 (* 1 = 3.21113 loss)
I0324 11:06:04.617574 10083 sgd_solver.cpp:136] Iteration 13100, lr = 0.001, m = 0.9
I0324 11:07:12.059973 10083 solver.cpp:314] Iteration 13200 (1.48279 iter/s, 67.4405s/100 iter), loss = 2.9444
I0324 11:07:12.060076 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.8102 (* 1 = 3.8102 loss)
I0324 11:07:12.060096 10083 sgd_solver.cpp:136] Iteration 13200, lr = 0.001, m = 0.9
I0324 11:08:19.989796 10083 solver.cpp:314] Iteration 13300 (1.47216 iter/s, 67.9276s/100 iter), loss = 2.87483
I0324 11:08:19.989923 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.46934 (* 1 = 2.46934 loss)
I0324 11:08:19.990036 10083 sgd_solver.cpp:136] Iteration 13300, lr = 0.001, m = 0.9
I0324 11:09:26.832231 10083 solver.cpp:314] Iteration 13400 (1.4961 iter/s, 66.8403s/100 iter), loss = 3.21847
I0324 11:09:26.832355 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.47223 (* 1 = 2.47223 loss)
I0324 11:09:26.832376 10083 sgd_solver.cpp:136] Iteration 13400, lr = 0.001, m = 0.9
I0324 11:10:33.062057 10083 solver.cpp:314] Iteration 13500 (1.50994 iter/s, 66.2277s/100 iter), loss = 2.94962
I0324 11:10:33.062157 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.12474 (* 1 = 3.12474 loss)
I0324 11:10:33.062177 10083 sgd_solver.cpp:136] Iteration 13500, lr = 0.001, m = 0.9
I0324 11:11:41.498064 10083 solver.cpp:314] Iteration 13600 (1.46127 iter/s, 68.4338s/100 iter), loss = 3.07655
I0324 11:11:41.498153 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.58843 (* 1 = 2.58843 loss)
I0324 11:11:41.498174 10083 sgd_solver.cpp:136] Iteration 13600, lr = 0.001, m = 0.9
I0324 11:12:48.420104 10083 solver.cpp:314] Iteration 13700 (1.49432 iter/s, 66.9199s/100 iter), loss = 3.39304
I0324 11:12:48.420215 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.85421 (* 1 = 2.85421 loss)
I0324 11:12:48.420231 10083 sgd_solver.cpp:136] Iteration 13700, lr = 0.001, m = 0.9
I0324 11:13:56.742875 10083 solver.cpp:314] Iteration 13800 (1.46369 iter/s, 68.3205s/100 iter), loss = 3.36378
I0324 11:13:56.742979 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.32276 (* 1 = 3.32276 loss)
I0324 11:13:56.742995 10083 sgd_solver.cpp:136] Iteration 13800, lr = 0.001, m = 0.9
I0324 11:15:03.382908 10083 solver.cpp:314] Iteration 13900 (1.50065 iter/s, 66.6378s/100 iter), loss = 2.89635
I0324 11:15:03.383011 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.41505 (* 1 = 3.41505 loss)
I0324 11:15:03.383028 10083 sgd_solver.cpp:136] Iteration 13900, lr = 0.001, m = 0.9
I0324 11:16:09.688514 10083 solver.cpp:836] Snapshotting to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_14000.caffemodel
I0324 11:16:09.725488 10083 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/ti-vgg-720x368-v2/JDetNet/20180323_22-48_ds_PSP_dsFac_32_hdDS8_1_kerMbox_1_smallOBj_1/l1reg/ti-vgg-720x368-v2_ssdJacintoNetV2_iter_14000.solverstate
I0324 11:16:09.746078 10083 solver.cpp:678] Iteration 14000, Testing net (#0)
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.337517
j:  : 4 : max_pr:  : 0.518793
j:  : 3 : max_pr:  : 0.652605
j:  : 2 : max_pr:  : 0.765803
j:  : 1 : max_pr:  : 0.861956
j:  : 0 : max_pr:  : 1
I0324 11:17:01.003124 10084 solver.cpp:786] class AP 1: 0.376061
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.117292
j:  : 7 : max_pr:  : 0.358751
j:  : 6 : max_pr:  : 0.478527
j:  : 5 : max_pr:  : 0.583772
j:  : 4 : max_pr:  : 0.696756
j:  : 3 : max_pr:  : 0.815359
j:  : 2 : max_pr:  : 0.985947
j:  : 1 : max_pr:  : 1
j:  : 0 : max_pr:  : 1
I0324 11:17:01.057008 10084 solver.cpp:786] class AP 2: 0.548764
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.49628
j:  : 6 : max_pr:  : 0.649737
j:  : 5 : max_pr:  : 0.750214
j:  : 4 : max_pr:  : 0.86286
j:  : 3 : max_pr:  : 0.91896
j:  : 2 : max_pr:  : 0.96654
j:  : 1 : max_pr:  : 0.999318
j:  : 0 : max_pr:  : 1
I0324 11:17:01.066691 10084 solver.cpp:786] class AP 3: 0.603992
I0324 11:17:01.066709 10084 solver.cpp:792] Test net output mAP #0: detection_eval = 0.509606
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0
j:  : 6 : max_pr:  : 0
j:  : 5 : max_pr:  : 0.313902
j:  : 4 : max_pr:  : 0.503032
j:  : 3 : max_pr:  : 0.640531
j:  : 2 : max_pr:  : 0.762017
j:  : 1 : max_pr:  : 0.853289
j:  : 0 : max_pr:  : 1
I0324 11:17:01.630553 10083 solver.cpp:786] class AP 1: 0.370252
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0.0645083
j:  : 7 : max_pr:  : 0.335744
j:  : 6 : max_pr:  : 0.453074
j:  : 5 : max_pr:  : 0.565608
j:  : 4 : max_pr:  : 0.67506
j:  : 3 : max_pr:  : 0.808811
j:  : 2 : max_pr:  : 0.977572
j:  : 1 : max_pr:  : 0.997019
j:  : 0 : max_pr:  : 1
I0324 11:17:01.683969 10083 solver.cpp:786] class AP 2: 0.534309
j:  : 10 : max_pr:  : 0
j:  : 9 : max_pr:  : 0
j:  : 8 : max_pr:  : 0
j:  : 7 : max_pr:  : 0.513678
j:  : 6 : max_pr:  : 0.672615
j:  : 5 : max_pr:  : 0.770001
j:  : 4 : max_pr:  : 0.867219
j:  : 3 : max_pr:  : 0.923998
j:  : 2 : max_pr:  : 0.964698
j:  : 1 : max_pr:  : 0.998697
j:  : 0 : max_pr:  : 1
I0324 11:17:01.693601 10083 solver.cpp:786] class AP 3: 0.610082
I0324 11:17:01.693619 10083 solver.cpp:792] Test net output mAP #0: detection_eval = 0.504881
I0324 11:17:01.694149 10083 solver.cpp:265] [MultiGPU] Tests completed in 51.9464s
I0324 11:17:02.140422 10083 solver.cpp:314] Iteration 14000 (0.842079 iter/s, 118.754s/100 iter), loss = 3.05202
I0324 11:17:02.140460 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.85113 (* 1 = 2.85113 loss)
I0324 11:17:02.140476 10083 sgd_solver.cpp:136] Iteration 14000, lr = 0.001, m = 0.9
I0324 11:18:08.666347 10083 solver.cpp:314] Iteration 14100 (1.50322 iter/s, 66.5238s/100 iter), loss = 2.91416
I0324 11:18:08.666445 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.56191 (* 1 = 2.56191 loss)
I0324 11:18:08.666460 10083 sgd_solver.cpp:136] Iteration 14100, lr = 0.001, m = 0.9
I0324 11:19:15.598296 10083 solver.cpp:314] Iteration 14200 (1.4941 iter/s, 66.9297s/100 iter), loss = 2.86972
I0324 11:19:15.598412 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.39154 (* 1 = 2.39154 loss)
I0324 11:19:15.598428 10083 sgd_solver.cpp:136] Iteration 14200, lr = 0.001, m = 0.9
I0324 11:20:22.819139 10083 solver.cpp:314] Iteration 14300 (1.48768 iter/s, 67.2186s/100 iter), loss = 3.25127
I0324 11:20:22.819259 10083 solver.cpp:336]     Train net output #0: mbox_loss = 4.01539 (* 1 = 4.01539 loss)
I0324 11:20:22.819274 10083 sgd_solver.cpp:136] Iteration 14300, lr = 0.001, m = 0.9
I0324 11:21:30.695046 10083 solver.cpp:314] Iteration 14400 (1.47333 iter/s, 67.8737s/100 iter), loss = 2.92271
I0324 11:21:30.696452 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.09845 (* 1 = 3.09845 loss)
I0324 11:21:30.696497 10083 sgd_solver.cpp:136] Iteration 14400, lr = 0.001, m = 0.9
I0324 11:22:37.968757 10083 solver.cpp:314] Iteration 14500 (1.48651 iter/s, 67.2715s/100 iter), loss = 3.14455
I0324 11:22:37.968883 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.79652 (* 1 = 2.79652 loss)
I0324 11:22:37.968900 10083 sgd_solver.cpp:136] Iteration 14500, lr = 0.001, m = 0.9
I0324 11:23:45.721760 10083 solver.cpp:314] Iteration 14600 (1.476 iter/s, 67.7508s/100 iter), loss = 3.1267
I0324 11:23:45.721933 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.03573 (* 1 = 2.03573 loss)
I0324 11:23:45.721982 10083 sgd_solver.cpp:136] Iteration 14600, lr = 0.001, m = 0.9
I0324 11:24:52.463721 10083 solver.cpp:314] Iteration 14700 (1.49836 iter/s, 66.7398s/100 iter), loss = 3.26347
I0324 11:24:52.463891 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.07422 (* 1 = 2.07422 loss)
I0324 11:24:52.463907 10083 sgd_solver.cpp:136] Iteration 14700, lr = 0.001, m = 0.9
I0324 11:26:00.134198 10083 solver.cpp:314] Iteration 14800 (1.4778 iter/s, 67.6683s/100 iter), loss = 2.88481
I0324 11:26:00.134292 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.85315 (* 1 = 2.85315 loss)
I0324 11:26:00.134313 10083 sgd_solver.cpp:136] Iteration 14800, lr = 0.001, m = 0.9
I0324 11:27:08.499418 10083 solver.cpp:314] Iteration 14900 (1.46278 iter/s, 68.363s/100 iter), loss = 3.09031
I0324 11:27:08.499518 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.58974 (* 1 = 2.58974 loss)
I0324 11:27:08.499541 10083 sgd_solver.cpp:136] Iteration 14900, lr = 0.001, m = 0.9
I0324 11:27:32.832126 10054 data_reader.cpp:305] Starting prefetch of epoch 3
I0324 11:28:16.652003 10083 solver.cpp:314] Iteration 15000 (1.46735 iter/s, 68.1502s/100 iter), loss = 2.95483
I0324 11:28:16.652103 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.7717 (* 1 = 2.7717 loss)
I0324 11:28:16.652118 10083 sgd_solver.cpp:136] Iteration 15000, lr = 0.001, m = 0.9
I0324 11:29:26.425902 10083 solver.cpp:314] Iteration 15100 (1.43325 iter/s, 69.7716s/100 iter), loss = 2.84343
I0324 11:29:26.426002 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.21723 (* 1 = 2.21723 loss)
I0324 11:29:26.426019 10083 sgd_solver.cpp:136] Iteration 15100, lr = 0.001, m = 0.9
I0324 11:30:35.993935 10083 solver.cpp:314] Iteration 15200 (1.43749 iter/s, 69.5658s/100 iter), loss = 3.02774
I0324 11:30:35.994117 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.03153 (* 1 = 3.03153 loss)
I0324 11:30:35.994160 10083 sgd_solver.cpp:136] Iteration 15200, lr = 0.001, m = 0.9
I0324 11:31:44.945051 10083 solver.cpp:314] Iteration 15300 (1.45035 iter/s, 68.9489s/100 iter), loss = 3.08879
I0324 11:31:44.945611 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.33329 (* 1 = 3.33329 loss)
I0324 11:31:44.947317 10083 sgd_solver.cpp:136] Iteration 15300, lr = 0.001, m = 0.9
I0324 11:32:53.534430 10083 solver.cpp:314] Iteration 15400 (1.458 iter/s, 68.5871s/100 iter), loss = 3.18096
I0324 11:32:53.534523 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.953 (* 1 = 2.953 loss)
I0324 11:32:53.534540 10083 sgd_solver.cpp:136] Iteration 15400, lr = 0.001, m = 0.9
I0324 11:34:00.609901 10083 solver.cpp:314] Iteration 15500 (1.49091 iter/s, 67.0733s/100 iter), loss = 3.02346
I0324 11:34:00.609998 10083 solver.cpp:336]     Train net output #0: mbox_loss = 3.05619 (* 1 = 3.05619 loss)
I0324 11:34:00.610015 10083 sgd_solver.cpp:136] Iteration 15500, lr = 0.001, m = 0.9
I0324 11:35:09.303803 10083 solver.cpp:314] Iteration 15600 (1.45578 iter/s, 68.6917s/100 iter), loss = 3.10977
I0324 11:35:09.303910 10083 solver.cpp:336]     Train net output #0: mbox_loss = 2.69169 (* 1 = 2.69169 loss)
I0324 11:35:09.303927 10083 sgd_solver.cpp:136] Iteration 15600, lr = 0.001, m = 0.9
