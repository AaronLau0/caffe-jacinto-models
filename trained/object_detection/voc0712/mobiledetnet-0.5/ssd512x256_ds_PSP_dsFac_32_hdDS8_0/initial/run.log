I0510 14:48:29.573801  5307 caffe.cpp:902] This is NVCaffe 0.17.0 started at Thu May 10 14:48:29 2018
I0510 14:48:29.573921  5307 caffe.cpp:904] CuDNN version: 7003
I0510 14:48:29.573925  5307 caffe.cpp:905] CuBLAS version: 9000
I0510 14:48:29.573927  5307 caffe.cpp:906] CUDA version: 9000
I0510 14:48:29.573930  5307 caffe.cpp:907] CUDA driver version: 9000
I0510 14:48:29.573932  5307 caffe.cpp:908] Arguments: 
[0]: /user/a0393608/files/work/code/vision/ti/bitbucket/algoref/caffe-jacinto/build/tools/caffe.bin
[1]: train
[2]: --solver=training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/solver.prototxt
[3]: --weights=../trained/image_classification/imagenet_mobilenet-0.5/initial/imagenet_mobilenet-0.5_iter_320000.caffemodel
[4]: --gpu
[5]: 0
I0510 14:48:29.596494  5307 gpu_memory.cpp:105] GPUMemory::Manager initialized
I0510 14:48:29.597261  5307 gpu_memory.cpp:107] Total memory: 11713708032, Free: 11223957504, dev_info[0]: total=11713708032 free=11223957504
I0510 14:48:29.597268  5307 caffe.cpp:226] Using GPUs 0
I0510 14:48:29.597745  5307 caffe.cpp:230] GPU 0: GeForce GTX 1080 Ti
I0510 14:48:29.597784  5307 solver.cpp:41] Solver data type: FLOAT
I0510 14:48:29.605398  5307 solver.cpp:44] Initializing solver from parameters: 
train_net: "training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/train.prototxt"
test_net: "training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/test.prototxt"
test_iter: 619
test_interval: 2000
base_lr: 0.01
display: 100
max_iter: 120000
lr_policy: "multistep"
gamma: 0.1
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 2000
snapshot_prefix: "training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
train_state {
  level: 0
  stage: ""
}
snapshot_after_train: true
test_initialization: true
average_loss: 10
stepvalue: 60000
stepvalue: 90000
stepvalue: 300000
iter_size: 2
type: "SGD"
eval_type: "detection"
ap_version: "11point"
show_per_class_result: true
I0510 14:48:29.605489  5307 solver.cpp:76] Creating training net from train_net file: training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/train.prototxt
I0510 14:48:29.607403  5307 net.cpp:80] Initializing net from parameters: 
name: "mobiledetnet-0.5"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 0
    mean_value: 0
    mean_value: 0
    force_color: false
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 256
      width: 512
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: NEAREST
      interp_mode: CUBIC
      interp_mode: LANCZOS4
    }
    emit_constraint {
      emit_type: CENTER
    }
    crop_h: 256
    crop_w: 512
    distort_param {
      brightness_prob: 0.5
      brightness_delta: 32
      contrast_prob: 0.5
      contrast_lower: 0.5
      contrast_upper: 1.5
      hue_prob: 0.5
      hue_delta: 18
      saturation_prob: 0.5
      saturation_lower: 0.5
      saturation_upper: 1.5
      random_order_prob: 0
    }
    expand_param {
      prob: 0.5
      max_expand_ratio: 4
    }
  }
  data_param {
    source: "../../caffe-jacinto/examples/VOC0712/VOC0712_trainval_lmdb"
    batch_size: 16
    backend: LMDB
    threads: 4
    parser_threads: 4
  }
  annotated_data_param {
    batch_sampler {
      max_sample: 1
      max_trials: 1
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.1
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.3
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.5
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.7
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.9
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        max_jaccard_overlap: 1
      }
      max_sample: 1
      max_trials: 50
    }
    label_map_file: "../../caffe-jacinto/data/VOC0712/labelmap_voc.prototxt"
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1/dw"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1/dw"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 16
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
}
layer {
  name: "conv2_1/dw/scale"
  type: "Scale"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1/dw"
  type: "ReLU"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
}
layer {
  name: "conv2_1/sep"
  type: "Convolution"
  bottom: "conv2_1/dw"
  top: "conv2_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
}
layer {
  name: "conv2_1/sep/scale"
  type: "Scale"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1/sep"
  type: "ReLU"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
}
layer {
  name: "conv2_2/dw"
  type: "Convolution"
  bottom: "conv2_1/sep"
  top: "conv2_2/dw"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
}
layer {
  name: "conv2_2/dw/scale"
  type: "Scale"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2/dw"
  type: "ReLU"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
}
layer {
  name: "conv2_2/sep"
  type: "Convolution"
  bottom: "conv2_2/dw"
  top: "conv2_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
}
layer {
  name: "conv2_2/sep/scale"
  type: "Scale"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2/sep"
  type: "ReLU"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
}
layer {
  name: "conv3_1/dw"
  type: "Convolution"
  bottom: "conv2_2/sep"
  top: "conv3_1/dw"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
}
layer {
  name: "conv3_1/dw/scale"
  type: "Scale"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1/dw"
  type: "ReLU"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
}
layer {
  name: "conv3_1/sep"
  type: "Convolution"
  bottom: "conv3_1/dw"
  top: "conv3_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
}
layer {
  name: "conv3_1/sep/scale"
  type: "Scale"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1/sep"
  type: "ReLU"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
}
layer {
  name: "conv3_2/dw"
  type: "Convolution"
  bottom: "conv3_1/sep"
  top: "conv3_2/dw"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
}
layer {
  name: "conv3_2/dw/scale"
  type: "Scale"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2/dw"
  type: "ReLU"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
}
layer {
  name: "conv3_2/sep"
  type: "Convolution"
  bottom: "conv3_2/dw"
  top: "conv3_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
}
layer {
  name: "conv3_2/sep/scale"
  type: "Scale"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2/sep"
  type: "ReLU"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
}
layer {
  name: "conv4_1/dw"
  type: "Convolution"
  bottom: "conv3_2/sep"
  top: "conv4_1/dw"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
}
layer {
  name: "conv4_1/dw/scale"
  type: "Scale"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1/dw"
  type: "ReLU"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
}
layer {
  name: "conv4_1/sep"
  type: "Convolution"
  bottom: "conv4_1/dw"
  top: "conv4_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
}
layer {
  name: "conv4_1/sep/scale"
  type: "Scale"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1/sep"
  type: "ReLU"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
}
layer {
  name: "conv4_2/dw"
  type: "Convolution"
  bottom: "conv4_1/sep"
  top: "conv4_2/dw"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
}
layer {
  name: "conv4_2/dw/scale"
  type: "Scale"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2/dw"
  type: "ReLU"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
}
layer {
  name: "conv4_2/sep"
  type: "Convolution"
  bottom: "conv4_2/dw"
  top: "conv4_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
}
layer {
  name: "conv4_2/sep/scale"
  type: "Scale"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2/sep"
  type: "ReLU"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
}
layer {
  name: "conv5_1/dw"
  type: "Convolution"
  bottom: "conv4_2/sep"
  top: "conv5_1/dw"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
}
layer {
  name: "conv5_1/dw/scale"
  type: "Scale"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1/dw"
  type: "ReLU"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
}
layer {
  name: "conv5_1/sep"
  type: "Convolution"
  bottom: "conv5_1/dw"
  top: "conv5_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
}
layer {
  name: "conv5_1/sep/scale"
  type: "Scale"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1/sep"
  type: "ReLU"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
}
layer {
  name: "conv5_2/dw"
  type: "Convolution"
  bottom: "conv5_1/sep"
  top: "conv5_2/dw"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
}
layer {
  name: "conv5_2/dw/scale"
  type: "Scale"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2/dw"
  type: "ReLU"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
}
layer {
  name: "conv5_2/sep"
  type: "Convolution"
  bottom: "conv5_2/dw"
  top: "conv5_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
}
layer {
  name: "conv5_2/sep/scale"
  type: "Scale"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2/sep"
  type: "ReLU"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
}
layer {
  name: "conv5_3/dw"
  type: "Convolution"
  bottom: "conv5_2/sep"
  top: "conv5_3/dw"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
}
layer {
  name: "conv5_3/dw/scale"
  type: "Scale"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3/dw"
  type: "ReLU"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
}
layer {
  name: "conv5_3/sep"
  type: "Convolution"
  bottom: "conv5_3/dw"
  top: "conv5_3/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
}
layer {
  name: "conv5_3/sep/scale"
  type: "Scale"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3/sep"
  type: "ReLU"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
}
layer {
  name: "conv5_4/dw"
  type: "Convolution"
  bottom: "conv5_3/sep"
  top: "conv5_4/dw"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
}
layer {
  name: "conv5_4/dw/scale"
  type: "Scale"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_4/dw"
  type: "ReLU"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
}
layer {
  name: "conv5_4/sep"
  type: "Convolution"
  bottom: "conv5_4/dw"
  top: "conv5_4/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
}
layer {
  name: "conv5_4/sep/scale"
  type: "Scale"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_4/sep"
  type: "ReLU"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
}
layer {
  name: "conv5_5/dw"
  type: "Convolution"
  bottom: "conv5_4/sep"
  top: "conv5_5/dw"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
}
layer {
  name: "conv5_5/dw/scale"
  type: "Scale"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_5/dw"
  type: "ReLU"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
}
layer {
  name: "conv5_5/sep"
  type: "Convolution"
  bottom: "conv5_5/dw"
  top: "conv5_5/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
}
layer {
  name: "conv5_5/sep/scale"
  type: "Scale"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_5/sep"
  type: "ReLU"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
}
layer {
  name: "conv5_6/dw"
  type: "Convolution"
  bottom: "conv5_5/sep"
  top: "conv5_6/dw"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_6/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
}
layer {
  name: "conv5_6/dw/scale"
  type: "Scale"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_6/dw"
  type: "ReLU"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
}
layer {
  name: "conv5_6/sep"
  type: "Convolution"
  bottom: "conv5_6/dw"
  top: "conv5_6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_6/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
}
layer {
  name: "conv5_6/sep/scale"
  type: "Scale"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_6/sep"
  type: "ReLU"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
}
layer {
  name: "conv6/dw"
  type: "Convolution"
  bottom: "conv5_6/sep"
  top: "conv6/dw"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6/dw"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/sep"
  type: "Convolution"
  bottom: "conv6/dw"
  top: "conv6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/sep/bn"
  type: "BatchNorm"
  bottom: "conv6/sep"
  top: "conv6/sep"
}
layer {
  name: "conv6/sep/scale"
  type: "Scale"
  bottom: "conv6/sep"
  top: "conv6/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6/sep"
  type: "ReLU"
  bottom: "conv6/sep"
  top: "conv6/sep"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv6/sep"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "pool6"
  top: "pool7"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "pool8"
  type: "Pooling"
  bottom: "pool7"
  top: "pool8"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "ctx_output1/1x1"
  type: "Convolution"
  bottom: "conv5_5/sep"
  top: "ctx_output1/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/1x1/bn"
  type: "BatchNorm"
  bottom: "ctx_output1/1x1"
  top: "ctx_output1/1x1"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_output1/1x1/relu"
  type: "ReLU"
  bottom: "ctx_output1/1x1"
  top: "ctx_output1/1x1"
}
layer {
  name: "ctx_output1"
  type: "Convolution"
  bottom: "ctx_output1/1x1"
  top: "ctx_output1"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/bn"
  type: "BatchNorm"
  bottom: "ctx_output1"
  top: "ctx_output1"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_output1/relu"
  type: "ReLU"
  bottom: "ctx_output1"
  top: "ctx_output1"
}
layer {
  name: "ctx_output2/1x1"
  type: "Convolution"
  bottom: "conv6/sep"
  top: "ctx_output2/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/1x1/bn"
  type: "BatchNorm"
  bottom: "ctx_output2/1x1"
  top: "ctx_output2/1x1"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_output2/1x1/relu"
  type: "ReLU"
  bottom: "ctx_output2/1x1"
  top: "ctx_output2/1x1"
}
layer {
  name: "ctx_output2"
  type: "Convolution"
  bottom: "ctx_output2/1x1"
  top: "ctx_output2"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/bn"
  type: "BatchNorm"
  bottom: "ctx_output2"
  top: "ctx_output2"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_output2/relu"
  type: "ReLU"
  bottom: "ctx_output2"
  top: "ctx_output2"
}
layer {
  name: "ctx_output3/1x1"
  type: "Convolution"
  bottom: "pool6"
  top: "ctx_output3/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/1x1/bn"
  type: "BatchNorm"
  bottom: "ctx_output3/1x1"
  top: "ctx_output3/1x1"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_output3/1x1/relu"
  type: "ReLU"
  bottom: "ctx_output3/1x1"
  top: "ctx_output3/1x1"
}
layer {
  name: "ctx_output3"
  type: "Convolution"
  bottom: "ctx_output3/1x1"
  top: "ctx_output3"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/bn"
  type: "BatchNorm"
  bottom: "ctx_output3"
  top: "ctx_output3"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_output3/relu"
  type: "ReLU"
  bottom: "ctx_output3"
  top: "ctx_output3"
}
layer {
  name: "ctx_output4/1x1"
  type: "Convolution"
  bottom: "pool7"
  top: "ctx_output4/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/1x1/bn"
  type: "BatchNorm"
  bottom: "ctx_output4/1x1"
  top: "ctx_output4/1x1"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_output4/1x1/relu"
  type: "ReLU"
  bottom: "ctx_output4/1x1"
  top: "ctx_output4/1x1"
}
layer {
  name: "ctx_output4"
  type: "Convolution"
  bottom: "ctx_output4/1x1"
  top: "ctx_output4"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/bn"
  type: "BatchNorm"
  bottom: "ctx_output4"
  top: "ctx_output4"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_output4/relu"
  type: "ReLU"
  bottom: "ctx_output4"
  top: "ctx_output4"
}
layer {
  name: "ctx_output5/1x1"
  type: "Convolution"
  bottom: "pool8"
  top: "ctx_output5/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/1x1/bn"
  type: "BatchNorm"
  bottom: "ctx_output5/1x1"
  top: "ctx_output5/1x1"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_output5/1x1/relu"
  type: "ReLU"
  bottom: "ctx_output5/1x1"
  top: "ctx_output5/1x1"
}
layer {
  name: "ctx_output5"
  type: "Convolution"
  bottom: "ctx_output5/1x1"
  top: "ctx_output5"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/bn"
  type: "BatchNorm"
  bottom: "ctx_output5"
  top: "ctx_output5"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_output5/relu"
  type: "ReLU"
  bottom: "ctx_output5"
  top: "ctx_output5"
}
layer {
  name: "ctx_output1/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_loc"
  top: "ctx_output1/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_loc_perm"
  top: "ctx_output1/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 84
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_conf"
  top: "ctx_output1/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_flat"
  type: "Flatten"
I0510 14:48:29.607969  5307 net.cpp:110] Using FLOAT as default forward math type
I0510 14:48:29.607976  5307 net.cpp:116] Using FLOAT as default backward math type
I0510 14:48:29.607981  5307 layer_factory.hpp:172] Creating layer 'data' of type 'AnnotatedData'
I0510 14:48:29.607986  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:29.608055  5307 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0510 14:48:29.608973  5322 blocking_queue.cpp:40] Data layer prefetch queue empty
I0510 14:48:29.609016  5307 net.cpp:200] Created Layer data (0)
I0510 14:48:29.609035  5307 net.cpp:542] data -> data
I0510 14:48:29.609045  5307 net.cpp:542] data -> label
I0510 14:48:29.609061  5307 data_reader.cpp:58] Data Reader threads: 4, out queues: 16, depth: 16
I0510 14:48:29.609109  5307 internal_thread.cpp:19] Starting 4 internal thread(s) on device 0
I0510 14:48:29.609990  5323 db_lmdb.cpp:36] Opened lmdb ../../caffe-jacinto/examples/VOC0712/VOC0712_trainval_lmdb
I0510 14:48:29.610841  5324 db_lmdb.cpp:36] Opened lmdb ../../caffe-jacinto/examples/VOC0712/VOC0712_trainval_lmdb
I0510 14:48:29.612040  5307 annotated_data_layer.cpp:105] output data size: 16,3,256,512
I0510 14:48:29.612288  5307 annotated_data_layer.cpp:150] [0] Output data size: 16, 3, 256, 512
I0510 14:48:29.612665  5325 db_lmdb.cpp:36] Opened lmdb ../../caffe-jacinto/examples/VOC0712/VOC0712_trainval_lmdb
I0510 14:48:29.613466  5326 db_lmdb.cpp:36] Opened lmdb ../../caffe-jacinto/examples/VOC0712/VOC0712_trainval_lmdb
I0510 14:48:29.613507  5307 internal_thread.cpp:19] Starting 4 internal thread(s) on device 0
I0510 14:48:29.614493  5328 data_layer.cpp:105] [0] Parser threads: 4
I0510 14:48:29.614506  5328 data_layer.cpp:107] [0] Transformer threads: 4
I0510 14:48:29.615298  5307 net.cpp:260] Setting up data
I0510 14:48:29.624570  5307 net.cpp:267] TRAIN Top shape for layer 0 'data' 16 3 256 512 (6291456)
I0510 14:48:29.624604  5307 net.cpp:267] TRAIN Top shape for layer 0 'data' 1 1 2 8 (16)
I0510 14:48:29.624614  5307 layer_factory.hpp:172] Creating layer 'data_data_0_split' of type 'Split'
I0510 14:48:29.624619  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:29.624629  5307 net.cpp:200] Created Layer data_data_0_split (1)
I0510 14:48:29.624634  5307 net.cpp:572] data_data_0_split <- data
I0510 14:48:29.624646  5307 net.cpp:542] data_data_0_split -> data_data_0_split_0
I0510 14:48:29.624662  5307 net.cpp:542] data_data_0_split -> data_data_0_split_1
I0510 14:48:29.624671  5307 net.cpp:542] data_data_0_split -> data_data_0_split_2
I0510 14:48:29.624678  5307 net.cpp:542] data_data_0_split -> data_data_0_split_3
I0510 14:48:29.624685  5307 net.cpp:542] data_data_0_split -> data_data_0_split_4
I0510 14:48:29.624688  5307 net.cpp:542] data_data_0_split -> data_data_0_split_5
I0510 14:48:29.624884  5307 net.cpp:260] Setting up data_data_0_split
I0510 14:48:29.624892  5307 net.cpp:267] TRAIN Top shape for layer 1 'data_data_0_split' 16 3 256 512 (6291456)
I0510 14:48:29.624897  5307 net.cpp:267] TRAIN Top shape for layer 1 'data_data_0_split' 16 3 256 512 (6291456)
I0510 14:48:29.624902  5307 net.cpp:267] TRAIN Top shape for layer 1 'data_data_0_split' 16 3 256 512 (6291456)
I0510 14:48:29.624907  5307 net.cpp:267] TRAIN Top shape for layer 1 'data_data_0_split' 16 3 256 512 (6291456)
I0510 14:48:29.624910  5307 net.cpp:267] TRAIN Top shape for layer 1 'data_data_0_split' 16 3 256 512 (6291456)
I0510 14:48:29.624915  5307 net.cpp:267] TRAIN Top shape for layer 1 'data_data_0_split' 16 3 256 512 (6291456)
I0510 14:48:29.624933  5307 layer_factory.hpp:172] Creating layer 'data/bias' of type 'Bias'
I0510 14:48:29.624944  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:29.624961  5307 net.cpp:200] Created Layer data/bias (2)
I0510 14:48:29.624971  5307 net.cpp:572] data/bias <- data_data_0_split_0
I0510 14:48:29.624981  5307 net.cpp:542] data/bias -> data/bias
I0510 14:48:29.637835  5307 net.cpp:260] Setting up data/bias
I0510 14:48:29.637859  5307 net.cpp:267] TRAIN Top shape for layer 2 'data/bias' 16 3 256 512 (6291456)
I0510 14:48:29.637876  5307 layer_factory.hpp:172] Creating layer 'conv1' of type 'Convolution'
I0510 14:48:29.637883  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:29.637907  5307 net.cpp:200] Created Layer conv1 (3)
I0510 14:48:29.637912  5307 net.cpp:572] conv1 <- data/bias
I0510 14:48:29.637917  5307 net.cpp:542] conv1 -> conv1
I0510 14:48:30.098809  5307 net.cpp:260] Setting up conv1
I0510 14:48:30.098845  5307 net.cpp:267] TRAIN Top shape for layer 3 'conv1' 16 16 128 256 (8388608)
I0510 14:48:30.098858  5307 layer_factory.hpp:172] Creating layer 'conv1/bn' of type 'BatchNorm'
I0510 14:48:30.098865  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.098881  5307 net.cpp:200] Created Layer conv1/bn (4)
I0510 14:48:30.098886  5307 net.cpp:572] conv1/bn <- conv1
I0510 14:48:30.098891  5307 net.cpp:527] conv1/bn -> conv1 (in-place)
I0510 14:48:30.099910  5307 net.cpp:260] Setting up conv1/bn
I0510 14:48:30.099922  5307 net.cpp:267] TRAIN Top shape for layer 4 'conv1/bn' 16 16 128 256 (8388608)
I0510 14:48:30.099934  5307 layer_factory.hpp:172] Creating layer 'conv1/scale' of type 'Scale'
I0510 14:48:30.099942  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.099951  5307 net.cpp:200] Created Layer conv1/scale (5)
I0510 14:48:30.099956  5307 net.cpp:572] conv1/scale <- conv1
I0510 14:48:30.099961  5307 net.cpp:527] conv1/scale -> conv1 (in-place)
I0510 14:48:30.100003  5307 layer_factory.hpp:172] Creating layer 'conv1/scale' of type 'Bias'
I0510 14:48:30.100008  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.100152  5307 net.cpp:260] Setting up conv1/scale
I0510 14:48:30.100162  5307 net.cpp:267] TRAIN Top shape for layer 5 'conv1/scale' 16 16 128 256 (8388608)
I0510 14:48:30.100169  5307 layer_factory.hpp:172] Creating layer 'relu1' of type 'ReLU'
I0510 14:48:30.100173  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.100180  5307 net.cpp:200] Created Layer relu1 (6)
I0510 14:48:30.100184  5307 net.cpp:572] relu1 <- conv1
I0510 14:48:30.100188  5307 net.cpp:527] relu1 -> conv1 (in-place)
I0510 14:48:30.100204  5307 net.cpp:260] Setting up relu1
I0510 14:48:30.100209  5307 net.cpp:267] TRAIN Top shape for layer 6 'relu1' 16 16 128 256 (8388608)
I0510 14:48:30.100214  5307 layer_factory.hpp:172] Creating layer 'conv2_1/dw' of type 'Convolution'
I0510 14:48:30.100217  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.100227  5307 net.cpp:200] Created Layer conv2_1/dw (7)
I0510 14:48:30.100232  5307 net.cpp:572] conv2_1/dw <- conv1
I0510 14:48:30.100236  5307 net.cpp:542] conv2_1/dw -> conv2_1/dw
I0510 14:48:30.101371  5307 net.cpp:260] Setting up conv2_1/dw
I0510 14:48:30.101382  5307 net.cpp:267] TRAIN Top shape for layer 7 'conv2_1/dw' 16 16 128 256 (8388608)
I0510 14:48:30.101388  5307 layer_factory.hpp:172] Creating layer 'conv2_1/dw/bn' of type 'BatchNorm'
I0510 14:48:30.101394  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.101402  5307 net.cpp:200] Created Layer conv2_1/dw/bn (8)
I0510 14:48:30.101408  5307 net.cpp:572] conv2_1/dw/bn <- conv2_1/dw
I0510 14:48:30.101411  5307 net.cpp:527] conv2_1/dw/bn -> conv2_1/dw (in-place)
I0510 14:48:30.101748  5307 net.cpp:260] Setting up conv2_1/dw/bn
I0510 14:48:30.101757  5307 net.cpp:267] TRAIN Top shape for layer 8 'conv2_1/dw/bn' 16 16 128 256 (8388608)
I0510 14:48:30.101766  5307 layer_factory.hpp:172] Creating layer 'conv2_1/dw/scale' of type 'Scale'
I0510 14:48:30.101773  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.101778  5307 net.cpp:200] Created Layer conv2_1/dw/scale (9)
I0510 14:48:30.101783  5307 net.cpp:572] conv2_1/dw/scale <- conv2_1/dw
I0510 14:48:30.101788  5307 net.cpp:527] conv2_1/dw/scale -> conv2_1/dw (in-place)
I0510 14:48:30.101821  5307 layer_factory.hpp:172] Creating layer 'conv2_1/dw/scale' of type 'Bias'
I0510 14:48:30.101827  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.101965  5307 net.cpp:260] Setting up conv2_1/dw/scale
I0510 14:48:30.101975  5307 net.cpp:267] TRAIN Top shape for layer 9 'conv2_1/dw/scale' 16 16 128 256 (8388608)
I0510 14:48:30.101981  5307 layer_factory.hpp:172] Creating layer 'relu2_1/dw' of type 'ReLU'
I0510 14:48:30.101995  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.102000  5307 net.cpp:200] Created Layer relu2_1/dw (10)
I0510 14:48:30.102005  5307 net.cpp:572] relu2_1/dw <- conv2_1/dw
I0510 14:48:30.102008  5307 net.cpp:527] relu2_1/dw -> conv2_1/dw (in-place)
I0510 14:48:30.102013  5307 net.cpp:260] Setting up relu2_1/dw
I0510 14:48:30.102018  5307 net.cpp:267] TRAIN Top shape for layer 10 'relu2_1/dw' 16 16 128 256 (8388608)
I0510 14:48:30.102022  5307 layer_factory.hpp:172] Creating layer 'conv2_1/sep' of type 'Convolution'
I0510 14:48:30.102026  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.102035  5307 net.cpp:200] Created Layer conv2_1/sep (11)
I0510 14:48:30.102038  5307 net.cpp:572] conv2_1/sep <- conv2_1/dw
I0510 14:48:30.102042  5307 net.cpp:542] conv2_1/sep -> conv2_1/sep
I0510 14:48:30.102200  5307 net.cpp:260] Setting up conv2_1/sep
I0510 14:48:30.102208  5307 net.cpp:267] TRAIN Top shape for layer 11 'conv2_1/sep' 16 32 128 256 (16777216)
I0510 14:48:30.102216  5307 layer_factory.hpp:172] Creating layer 'conv2_1/sep/bn' of type 'BatchNorm'
I0510 14:48:30.102219  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.102226  5307 net.cpp:200] Created Layer conv2_1/sep/bn (12)
I0510 14:48:30.102229  5307 net.cpp:572] conv2_1/sep/bn <- conv2_1/sep
I0510 14:48:30.102234  5307 net.cpp:527] conv2_1/sep/bn -> conv2_1/sep (in-place)
I0510 14:48:30.102529  5307 net.cpp:260] Setting up conv2_1/sep/bn
I0510 14:48:30.102545  5307 net.cpp:267] TRAIN Top shape for layer 12 'conv2_1/sep/bn' 16 32 128 256 (16777216)
I0510 14:48:30.102557  5307 layer_factory.hpp:172] Creating layer 'conv2_1/sep/scale' of type 'Scale'
I0510 14:48:30.102566  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.102576  5307 net.cpp:200] Created Layer conv2_1/sep/scale (13)
I0510 14:48:30.102583  5307 net.cpp:572] conv2_1/sep/scale <- conv2_1/sep
I0510 14:48:30.102591  5307 net.cpp:527] conv2_1/sep/scale -> conv2_1/sep (in-place)
I0510 14:48:30.102627  5307 layer_factory.hpp:172] Creating layer 'conv2_1/sep/scale' of type 'Bias'
I0510 14:48:30.102636  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.102756  5307 net.cpp:260] Setting up conv2_1/sep/scale
I0510 14:48:30.102767  5307 net.cpp:267] TRAIN Top shape for layer 13 'conv2_1/sep/scale' 16 32 128 256 (16777216)
I0510 14:48:30.102778  5307 layer_factory.hpp:172] Creating layer 'relu2_1/sep' of type 'ReLU'
I0510 14:48:30.102787  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.102794  5307 net.cpp:200] Created Layer relu2_1/sep (14)
I0510 14:48:30.102802  5307 net.cpp:572] relu2_1/sep <- conv2_1/sep
I0510 14:48:30.102810  5307 net.cpp:527] relu2_1/sep -> conv2_1/sep (in-place)
I0510 14:48:30.102820  5307 net.cpp:260] Setting up relu2_1/sep
I0510 14:48:30.102829  5307 net.cpp:267] TRAIN Top shape for layer 14 'relu2_1/sep' 16 32 128 256 (16777216)
I0510 14:48:30.102838  5307 layer_factory.hpp:172] Creating layer 'conv2_2/dw' of type 'Convolution'
I0510 14:48:30.102845  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.102857  5307 net.cpp:200] Created Layer conv2_2/dw (15)
I0510 14:48:30.102865  5307 net.cpp:572] conv2_2/dw <- conv2_1/sep
I0510 14:48:30.102874  5307 net.cpp:542] conv2_2/dw -> conv2_2/dw
I0510 14:48:30.103037  5307 net.cpp:260] Setting up conv2_2/dw
I0510 14:48:30.103050  5307 net.cpp:267] TRAIN Top shape for layer 15 'conv2_2/dw' 16 32 64 128 (4194304)
I0510 14:48:30.103060  5307 layer_factory.hpp:172] Creating layer 'conv2_2/dw/bn' of type 'BatchNorm'
I0510 14:48:30.103068  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.103081  5307 net.cpp:200] Created Layer conv2_2/dw/bn (16)
I0510 14:48:30.103094  5307 net.cpp:572] conv2_2/dw/bn <- conv2_2/dw
I0510 14:48:30.103102  5307 net.cpp:527] conv2_2/dw/bn -> conv2_2/dw (in-place)
I0510 14:48:30.104127  5307 net.cpp:260] Setting up conv2_2/dw/bn
I0510 14:48:30.104146  5307 net.cpp:267] TRAIN Top shape for layer 16 'conv2_2/dw/bn' 16 32 64 128 (4194304)
I0510 14:48:30.104158  5307 layer_factory.hpp:172] Creating layer 'conv2_2/dw/scale' of type 'Scale'
I0510 14:48:30.104167  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.104180  5307 net.cpp:200] Created Layer conv2_2/dw/scale (17)
I0510 14:48:30.104188  5307 net.cpp:572] conv2_2/dw/scale <- conv2_2/dw
I0510 14:48:30.104197  5307 net.cpp:527] conv2_2/dw/scale -> conv2_2/dw (in-place)
I0510 14:48:30.104234  5307 layer_factory.hpp:172] Creating layer 'conv2_2/dw/scale' of type 'Bias'
I0510 14:48:30.104244  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.104336  5307 net.cpp:260] Setting up conv2_2/dw/scale
I0510 14:48:30.104347  5307 net.cpp:267] TRAIN Top shape for layer 17 'conv2_2/dw/scale' 16 32 64 128 (4194304)
I0510 14:48:30.104357  5307 layer_factory.hpp:172] Creating layer 'relu2_2/dw' of type 'ReLU'
I0510 14:48:30.104365  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.104374  5307 net.cpp:200] Created Layer relu2_2/dw (18)
I0510 14:48:30.104382  5307 net.cpp:572] relu2_2/dw <- conv2_2/dw
I0510 14:48:30.104390  5307 net.cpp:527] relu2_2/dw -> conv2_2/dw (in-place)
I0510 14:48:30.104400  5307 net.cpp:260] Setting up relu2_2/dw
I0510 14:48:30.104409  5307 net.cpp:267] TRAIN Top shape for layer 18 'relu2_2/dw' 16 32 64 128 (4194304)
I0510 14:48:30.104418  5307 layer_factory.hpp:172] Creating layer 'conv2_2/sep' of type 'Convolution'
I0510 14:48:30.104425  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.104436  5307 net.cpp:200] Created Layer conv2_2/sep (19)
I0510 14:48:30.104445  5307 net.cpp:572] conv2_2/sep <- conv2_2/dw
I0510 14:48:30.104454  5307 net.cpp:542] conv2_2/sep -> conv2_2/sep
I0510 14:48:30.105271  5307 net.cpp:260] Setting up conv2_2/sep
I0510 14:48:30.105281  5307 net.cpp:267] TRAIN Top shape for layer 19 'conv2_2/sep' 16 64 64 128 (8388608)
I0510 14:48:30.105289  5307 layer_factory.hpp:172] Creating layer 'conv2_2/sep/bn' of type 'BatchNorm'
I0510 14:48:30.105294  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.105303  5307 net.cpp:200] Created Layer conv2_2/sep/bn (20)
I0510 14:48:30.105306  5307 net.cpp:572] conv2_2/sep/bn <- conv2_2/sep
I0510 14:48:30.105311  5307 net.cpp:527] conv2_2/sep/bn -> conv2_2/sep (in-place)
I0510 14:48:30.105557  5307 net.cpp:260] Setting up conv2_2/sep/bn
I0510 14:48:30.105564  5307 net.cpp:267] TRAIN Top shape for layer 20 'conv2_2/sep/bn' 16 64 64 128 (8388608)
I0510 14:48:30.105572  5307 layer_factory.hpp:172] Creating layer 'conv2_2/sep/scale' of type 'Scale'
I0510 14:48:30.105576  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.105582  5307 net.cpp:200] Created Layer conv2_2/sep/scale (21)
I0510 14:48:30.105587  5307 net.cpp:572] conv2_2/sep/scale <- conv2_2/sep
I0510 14:48:30.105590  5307 net.cpp:527] conv2_2/sep/scale -> conv2_2/sep (in-place)
I0510 14:48:30.105618  5307 layer_factory.hpp:172] Creating layer 'conv2_2/sep/scale' of type 'Bias'
I0510 14:48:30.105623  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.105701  5307 net.cpp:260] Setting up conv2_2/sep/scale
I0510 14:48:30.105707  5307 net.cpp:267] TRAIN Top shape for layer 21 'conv2_2/sep/scale' 16 64 64 128 (8388608)
I0510 14:48:30.105715  5307 layer_factory.hpp:172] Creating layer 'relu2_2/sep' of type 'ReLU'
I0510 14:48:30.105718  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.105731  5307 net.cpp:200] Created Layer relu2_2/sep (22)
I0510 14:48:30.105736  5307 net.cpp:572] relu2_2/sep <- conv2_2/sep
I0510 14:48:30.105741  5307 net.cpp:527] relu2_2/sep -> conv2_2/sep (in-place)
I0510 14:48:30.105746  5307 net.cpp:260] Setting up relu2_2/sep
I0510 14:48:30.105751  5307 net.cpp:267] TRAIN Top shape for layer 22 'relu2_2/sep' 16 64 64 128 (8388608)
I0510 14:48:30.105756  5307 layer_factory.hpp:172] Creating layer 'conv3_1/dw' of type 'Convolution'
I0510 14:48:30.105760  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.105770  5307 net.cpp:200] Created Layer conv3_1/dw (23)
I0510 14:48:30.105774  5307 net.cpp:572] conv3_1/dw <- conv2_2/sep
I0510 14:48:30.105778  5307 net.cpp:542] conv3_1/dw -> conv3_1/dw
I0510 14:48:30.106595  5307 net.cpp:260] Setting up conv3_1/dw
I0510 14:48:30.106611  5307 net.cpp:267] TRAIN Top shape for layer 23 'conv3_1/dw' 16 64 64 128 (8388608)
I0510 14:48:30.106621  5307 layer_factory.hpp:172] Creating layer 'conv3_1/dw/bn' of type 'BatchNorm'
I0510 14:48:30.106629  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.106639  5307 net.cpp:200] Created Layer conv3_1/dw/bn (24)
I0510 14:48:30.106647  5307 net.cpp:572] conv3_1/dw/bn <- conv3_1/dw
I0510 14:48:30.106657  5307 net.cpp:527] conv3_1/dw/bn -> conv3_1/dw (in-place)
I0510 14:48:30.106976  5307 net.cpp:260] Setting up conv3_1/dw/bn
I0510 14:48:30.106989  5307 net.cpp:267] TRAIN Top shape for layer 24 'conv3_1/dw/bn' 16 64 64 128 (8388608)
I0510 14:48:30.107003  5307 layer_factory.hpp:172] Creating layer 'conv3_1/dw/scale' of type 'Scale'
I0510 14:48:30.107012  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.107023  5307 net.cpp:200] Created Layer conv3_1/dw/scale (25)
I0510 14:48:30.107030  5307 net.cpp:572] conv3_1/dw/scale <- conv3_1/dw
I0510 14:48:30.107039  5307 net.cpp:527] conv3_1/dw/scale -> conv3_1/dw (in-place)
I0510 14:48:30.107076  5307 layer_factory.hpp:172] Creating layer 'conv3_1/dw/scale' of type 'Bias'
I0510 14:48:30.107087  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.107194  5307 net.cpp:260] Setting up conv3_1/dw/scale
I0510 14:48:30.107206  5307 net.cpp:267] TRAIN Top shape for layer 25 'conv3_1/dw/scale' 16 64 64 128 (8388608)
I0510 14:48:30.107218  5307 layer_factory.hpp:172] Creating layer 'relu3_1/dw' of type 'ReLU'
I0510 14:48:30.107226  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.107235  5307 net.cpp:200] Created Layer relu3_1/dw (26)
I0510 14:48:30.107244  5307 net.cpp:572] relu3_1/dw <- conv3_1/dw
I0510 14:48:30.107251  5307 net.cpp:527] relu3_1/dw -> conv3_1/dw (in-place)
I0510 14:48:30.107260  5307 net.cpp:260] Setting up relu3_1/dw
I0510 14:48:30.107270  5307 net.cpp:267] TRAIN Top shape for layer 26 'relu3_1/dw' 16 64 64 128 (8388608)
I0510 14:48:30.107278  5307 layer_factory.hpp:172] Creating layer 'conv3_1/sep' of type 'Convolution'
I0510 14:48:30.107286  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.107298  5307 net.cpp:200] Created Layer conv3_1/sep (27)
I0510 14:48:30.107306  5307 net.cpp:572] conv3_1/sep <- conv3_1/dw
I0510 14:48:30.107314  5307 net.cpp:542] conv3_1/sep -> conv3_1/sep
I0510 14:48:30.107592  5307 net.cpp:260] Setting up conv3_1/sep
I0510 14:48:30.107605  5307 net.cpp:267] TRAIN Top shape for layer 27 'conv3_1/sep' 16 64 64 128 (8388608)
I0510 14:48:30.107615  5307 layer_factory.hpp:172] Creating layer 'conv3_1/sep/bn' of type 'BatchNorm'
I0510 14:48:30.107623  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.107633  5307 net.cpp:200] Created Layer conv3_1/sep/bn (28)
I0510 14:48:30.107637  5307 net.cpp:572] conv3_1/sep/bn <- conv3_1/sep
I0510 14:48:30.107642  5307 net.cpp:527] conv3_1/sep/bn -> conv3_1/sep (in-place)
I0510 14:48:30.107893  5307 net.cpp:260] Setting up conv3_1/sep/bn
I0510 14:48:30.107900  5307 net.cpp:267] TRAIN Top shape for layer 28 'conv3_1/sep/bn' 16 64 64 128 (8388608)
I0510 14:48:30.107908  5307 layer_factory.hpp:172] Creating layer 'conv3_1/sep/scale' of type 'Scale'
I0510 14:48:30.107913  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.107919  5307 net.cpp:200] Created Layer conv3_1/sep/scale (29)
I0510 14:48:30.107923  5307 net.cpp:572] conv3_1/sep/scale <- conv3_1/sep
I0510 14:48:30.107928  5307 net.cpp:527] conv3_1/sep/scale -> conv3_1/sep (in-place)
I0510 14:48:30.107954  5307 layer_factory.hpp:172] Creating layer 'conv3_1/sep/scale' of type 'Bias'
I0510 14:48:30.107959  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.108036  5307 net.cpp:260] Setting up conv3_1/sep/scale
I0510 14:48:30.108042  5307 net.cpp:267] TRAIN Top shape for layer 29 'conv3_1/sep/scale' 16 64 64 128 (8388608)
I0510 14:48:30.108048  5307 layer_factory.hpp:172] Creating layer 'relu3_1/sep' of type 'ReLU'
I0510 14:48:30.108052  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.108057  5307 net.cpp:200] Created Layer relu3_1/sep (30)
I0510 14:48:30.108062  5307 net.cpp:572] relu3_1/sep <- conv3_1/sep
I0510 14:48:30.108065  5307 net.cpp:527] relu3_1/sep -> conv3_1/sep (in-place)
I0510 14:48:30.108072  5307 net.cpp:260] Setting up relu3_1/sep
I0510 14:48:30.108078  5307 net.cpp:267] TRAIN Top shape for layer 30 'relu3_1/sep' 16 64 64 128 (8388608)
I0510 14:48:30.108081  5307 layer_factory.hpp:172] Creating layer 'conv3_2/dw' of type 'Convolution'
I0510 14:48:30.108086  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.108093  5307 net.cpp:200] Created Layer conv3_2/dw (31)
I0510 14:48:30.108098  5307 net.cpp:572] conv3_2/dw <- conv3_1/sep
I0510 14:48:30.108103  5307 net.cpp:542] conv3_2/dw -> conv3_2/dw
I0510 14:48:30.108237  5307 net.cpp:260] Setting up conv3_2/dw
I0510 14:48:30.108245  5307 net.cpp:267] TRAIN Top shape for layer 31 'conv3_2/dw' 16 64 32 64 (2097152)
I0510 14:48:30.108252  5307 layer_factory.hpp:172] Creating layer 'conv3_2/dw/bn' of type 'BatchNorm'
I0510 14:48:30.108255  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.108263  5307 net.cpp:200] Created Layer conv3_2/dw/bn (32)
I0510 14:48:30.108266  5307 net.cpp:572] conv3_2/dw/bn <- conv3_2/dw
I0510 14:48:30.108271  5307 net.cpp:527] conv3_2/dw/bn -> conv3_2/dw (in-place)
I0510 14:48:30.108546  5307 net.cpp:260] Setting up conv3_2/dw/bn
I0510 14:48:30.108561  5307 net.cpp:267] TRAIN Top shape for layer 32 'conv3_2/dw/bn' 16 64 32 64 (2097152)
I0510 14:48:30.108573  5307 layer_factory.hpp:172] Creating layer 'conv3_2/dw/scale' of type 'Scale'
I0510 14:48:30.108582  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.108592  5307 net.cpp:200] Created Layer conv3_2/dw/scale (33)
I0510 14:48:30.108598  5307 net.cpp:572] conv3_2/dw/scale <- conv3_2/dw
I0510 14:48:30.108606  5307 net.cpp:527] conv3_2/dw/scale -> conv3_2/dw (in-place)
I0510 14:48:30.108641  5307 layer_factory.hpp:172] Creating layer 'conv3_2/dw/scale' of type 'Bias'
I0510 14:48:30.108650  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.108736  5307 net.cpp:260] Setting up conv3_2/dw/scale
I0510 14:48:30.108747  5307 net.cpp:267] TRAIN Top shape for layer 33 'conv3_2/dw/scale' 16 64 32 64 (2097152)
I0510 14:48:30.108757  5307 layer_factory.hpp:172] Creating layer 'relu3_2/dw' of type 'ReLU'
I0510 14:48:30.108765  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.108773  5307 net.cpp:200] Created Layer relu3_2/dw (34)
I0510 14:48:30.108781  5307 net.cpp:572] relu3_2/dw <- conv3_2/dw
I0510 14:48:30.108793  5307 net.cpp:527] relu3_2/dw -> conv3_2/dw (in-place)
I0510 14:48:30.108806  5307 net.cpp:260] Setting up relu3_2/dw
I0510 14:48:30.108815  5307 net.cpp:267] TRAIN Top shape for layer 34 'relu3_2/dw' 16 64 32 64 (2097152)
I0510 14:48:30.108824  5307 layer_factory.hpp:172] Creating layer 'conv3_2/sep' of type 'Convolution'
I0510 14:48:30.108830  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.108842  5307 net.cpp:200] Created Layer conv3_2/sep (35)
I0510 14:48:30.108850  5307 net.cpp:572] conv3_2/sep <- conv3_2/dw
I0510 14:48:30.108857  5307 net.cpp:542] conv3_2/sep -> conv3_2/sep
I0510 14:48:30.109174  5307 net.cpp:260] Setting up conv3_2/sep
I0510 14:48:30.109182  5307 net.cpp:267] TRAIN Top shape for layer 35 'conv3_2/sep' 16 128 32 64 (4194304)
I0510 14:48:30.109189  5307 layer_factory.hpp:172] Creating layer 'conv3_2/sep/bn' of type 'BatchNorm'
I0510 14:48:30.109192  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.109200  5307 net.cpp:200] Created Layer conv3_2/sep/bn (36)
I0510 14:48:30.109203  5307 net.cpp:572] conv3_2/sep/bn <- conv3_2/sep
I0510 14:48:30.109207  5307 net.cpp:527] conv3_2/sep/bn -> conv3_2/sep (in-place)
I0510 14:48:30.109417  5307 net.cpp:260] Setting up conv3_2/sep/bn
I0510 14:48:30.109424  5307 net.cpp:267] TRAIN Top shape for layer 36 'conv3_2/sep/bn' 16 128 32 64 (4194304)
I0510 14:48:30.109431  5307 layer_factory.hpp:172] Creating layer 'conv3_2/sep/scale' of type 'Scale'
I0510 14:48:30.109436  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.109441  5307 net.cpp:200] Created Layer conv3_2/sep/scale (37)
I0510 14:48:30.109446  5307 net.cpp:572] conv3_2/sep/scale <- conv3_2/sep
I0510 14:48:30.109449  5307 net.cpp:527] conv3_2/sep/scale -> conv3_2/sep (in-place)
I0510 14:48:30.109475  5307 layer_factory.hpp:172] Creating layer 'conv3_2/sep/scale' of type 'Bias'
I0510 14:48:30.109480  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.109545  5307 net.cpp:260] Setting up conv3_2/sep/scale
I0510 14:48:30.109552  5307 net.cpp:267] TRAIN Top shape for layer 37 'conv3_2/sep/scale' 16 128 32 64 (4194304)
I0510 14:48:30.109558  5307 layer_factory.hpp:172] Creating layer 'relu3_2/sep' of type 'ReLU'
I0510 14:48:30.109563  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.109568  5307 net.cpp:200] Created Layer relu3_2/sep (38)
I0510 14:48:30.109572  5307 net.cpp:572] relu3_2/sep <- conv3_2/sep
I0510 14:48:30.109576  5307 net.cpp:527] relu3_2/sep -> conv3_2/sep (in-place)
I0510 14:48:30.109582  5307 net.cpp:260] Setting up relu3_2/sep
I0510 14:48:30.109586  5307 net.cpp:267] TRAIN Top shape for layer 38 'relu3_2/sep' 16 128 32 64 (4194304)
I0510 14:48:30.109591  5307 layer_factory.hpp:172] Creating layer 'conv4_1/dw' of type 'Convolution'
I0510 14:48:30.109596  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.109604  5307 net.cpp:200] Created Layer conv4_1/dw (39)
I0510 14:48:30.109607  5307 net.cpp:572] conv4_1/dw <- conv3_2/sep
I0510 14:48:30.109612  5307 net.cpp:542] conv4_1/dw -> conv4_1/dw
I0510 14:48:30.109755  5307 net.cpp:260] Setting up conv4_1/dw
I0510 14:48:30.109761  5307 net.cpp:267] TRAIN Top shape for layer 39 'conv4_1/dw' 16 128 32 64 (4194304)
I0510 14:48:30.109767  5307 layer_factory.hpp:172] Creating layer 'conv4_1/dw/bn' of type 'BatchNorm'
I0510 14:48:30.109771  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.109777  5307 net.cpp:200] Created Layer conv4_1/dw/bn (40)
I0510 14:48:30.109781  5307 net.cpp:572] conv4_1/dw/bn <- conv4_1/dw
I0510 14:48:30.109786  5307 net.cpp:527] conv4_1/dw/bn -> conv4_1/dw (in-place)
I0510 14:48:30.110059  5307 net.cpp:260] Setting up conv4_1/dw/bn
I0510 14:48:30.110075  5307 net.cpp:267] TRAIN Top shape for layer 40 'conv4_1/dw/bn' 16 128 32 64 (4194304)
I0510 14:48:30.110090  5307 layer_factory.hpp:172] Creating layer 'conv4_1/dw/scale' of type 'Scale'
I0510 14:48:30.110102  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.110112  5307 net.cpp:200] Created Layer conv4_1/dw/scale (41)
I0510 14:48:30.110121  5307 net.cpp:572] conv4_1/dw/scale <- conv4_1/dw
I0510 14:48:30.110129  5307 net.cpp:527] conv4_1/dw/scale -> conv4_1/dw (in-place)
I0510 14:48:30.110170  5307 layer_factory.hpp:172] Creating layer 'conv4_1/dw/scale' of type 'Bias'
I0510 14:48:30.110905  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.111003  5307 net.cpp:260] Setting up conv4_1/dw/scale
I0510 14:48:30.111017  5307 net.cpp:267] TRAIN Top shape for layer 41 'conv4_1/dw/scale' 16 128 32 64 (4194304)
I0510 14:48:30.111029  5307 layer_factory.hpp:172] Creating layer 'relu4_1/dw' of type 'ReLU'
I0510 14:48:30.111037  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.111047  5307 net.cpp:200] Created Layer relu4_1/dw (42)
I0510 14:48:30.111055  5307 net.cpp:572] relu4_1/dw <- conv4_1/dw
I0510 14:48:30.111064  5307 net.cpp:527] relu4_1/dw -> conv4_1/dw (in-place)
I0510 14:48:30.111074  5307 net.cpp:260] Setting up relu4_1/dw
I0510 14:48:30.111084  5307 net.cpp:267] TRAIN Top shape for layer 42 'relu4_1/dw' 16 128 32 64 (4194304)
I0510 14:48:30.111093  5307 layer_factory.hpp:172] Creating layer 'conv4_1/sep' of type 'Convolution'
I0510 14:48:30.111100  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.111114  5307 net.cpp:200] Created Layer conv4_1/sep (43)
I0510 14:48:30.111122  5307 net.cpp:572] conv4_1/sep <- conv4_1/dw
I0510 14:48:30.111131  5307 net.cpp:542] conv4_1/sep -> conv4_1/sep
I0510 14:48:30.111766  5307 net.cpp:260] Setting up conv4_1/sep
I0510 14:48:30.111775  5307 net.cpp:267] TRAIN Top shape for layer 43 'conv4_1/sep' 16 128 32 64 (4194304)
I0510 14:48:30.111783  5307 layer_factory.hpp:172] Creating layer 'conv4_1/sep/bn' of type 'BatchNorm'
I0510 14:48:30.111786  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.111793  5307 net.cpp:200] Created Layer conv4_1/sep/bn (44)
I0510 14:48:30.111798  5307 net.cpp:572] conv4_1/sep/bn <- conv4_1/sep
I0510 14:48:30.111802  5307 net.cpp:527] conv4_1/sep/bn -> conv4_1/sep (in-place)
I0510 14:48:30.112027  5307 net.cpp:260] Setting up conv4_1/sep/bn
I0510 14:48:30.112035  5307 net.cpp:267] TRAIN Top shape for layer 44 'conv4_1/sep/bn' 16 128 32 64 (4194304)
I0510 14:48:30.112045  5307 layer_factory.hpp:172] Creating layer 'conv4_1/sep/scale' of type 'Scale'
I0510 14:48:30.112049  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.112056  5307 net.cpp:200] Created Layer conv4_1/sep/scale (45)
I0510 14:48:30.112059  5307 net.cpp:572] conv4_1/sep/scale <- conv4_1/sep
I0510 14:48:30.112063  5307 net.cpp:527] conv4_1/sep/scale -> conv4_1/sep (in-place)
I0510 14:48:30.112092  5307 layer_factory.hpp:172] Creating layer 'conv4_1/sep/scale' of type 'Bias'
I0510 14:48:30.112097  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.112161  5307 net.cpp:260] Setting up conv4_1/sep/scale
I0510 14:48:30.112167  5307 net.cpp:267] TRAIN Top shape for layer 45 'conv4_1/sep/scale' 16 128 32 64 (4194304)
I0510 14:48:30.112174  5307 layer_factory.hpp:172] Creating layer 'relu4_1/sep' of type 'ReLU'
I0510 14:48:30.112179  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.112184  5307 net.cpp:200] Created Layer relu4_1/sep (46)
I0510 14:48:30.112187  5307 net.cpp:572] relu4_1/sep <- conv4_1/sep
I0510 14:48:30.112191  5307 net.cpp:527] relu4_1/sep -> conv4_1/sep (in-place)
I0510 14:48:30.112197  5307 net.cpp:260] Setting up relu4_1/sep
I0510 14:48:30.112202  5307 net.cpp:267] TRAIN Top shape for layer 46 'relu4_1/sep' 16 128 32 64 (4194304)
I0510 14:48:30.112215  5307 layer_factory.hpp:172] Creating layer 'conv4_2/dw' of type 'Convolution'
I0510 14:48:30.112220  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.112228  5307 net.cpp:200] Created Layer conv4_2/dw (47)
I0510 14:48:30.112232  5307 net.cpp:572] conv4_2/dw <- conv4_1/sep
I0510 14:48:30.112237  5307 net.cpp:542] conv4_2/dw -> conv4_2/dw
I0510 14:48:30.112385  5307 net.cpp:260] Setting up conv4_2/dw
I0510 14:48:30.112392  5307 net.cpp:267] TRAIN Top shape for layer 47 'conv4_2/dw' 16 128 16 32 (1048576)
I0510 14:48:30.112399  5307 layer_factory.hpp:172] Creating layer 'conv4_2/dw/bn' of type 'BatchNorm'
I0510 14:48:30.112403  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.112409  5307 net.cpp:200] Created Layer conv4_2/dw/bn (48)
I0510 14:48:30.112413  5307 net.cpp:572] conv4_2/dw/bn <- conv4_2/dw
I0510 14:48:30.112418  5307 net.cpp:527] conv4_2/dw/bn -> conv4_2/dw (in-place)
I0510 14:48:30.112669  5307 net.cpp:260] Setting up conv4_2/dw/bn
I0510 14:48:30.112685  5307 net.cpp:267] TRAIN Top shape for layer 48 'conv4_2/dw/bn' 16 128 16 32 (1048576)
I0510 14:48:30.112696  5307 layer_factory.hpp:172] Creating layer 'conv4_2/dw/scale' of type 'Scale'
I0510 14:48:30.112705  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.112715  5307 net.cpp:200] Created Layer conv4_2/dw/scale (49)
I0510 14:48:30.112722  5307 net.cpp:572] conv4_2/dw/scale <- conv4_2/dw
I0510 14:48:30.112730  5307 net.cpp:527] conv4_2/dw/scale -> conv4_2/dw (in-place)
I0510 14:48:30.112766  5307 layer_factory.hpp:172] Creating layer 'conv4_2/dw/scale' of type 'Bias'
I0510 14:48:30.112776  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.112857  5307 net.cpp:260] Setting up conv4_2/dw/scale
I0510 14:48:30.112869  5307 net.cpp:267] TRAIN Top shape for layer 49 'conv4_2/dw/scale' 16 128 16 32 (1048576)
I0510 14:48:30.112879  5307 layer_factory.hpp:172] Creating layer 'relu4_2/dw' of type 'ReLU'
I0510 14:48:30.112887  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.112896  5307 net.cpp:200] Created Layer relu4_2/dw (50)
I0510 14:48:30.112905  5307 net.cpp:572] relu4_2/dw <- conv4_2/dw
I0510 14:48:30.112912  5307 net.cpp:527] relu4_2/dw -> conv4_2/dw (in-place)
I0510 14:48:30.112923  5307 net.cpp:260] Setting up relu4_2/dw
I0510 14:48:30.112928  5307 net.cpp:267] TRAIN Top shape for layer 50 'relu4_2/dw' 16 128 16 32 (1048576)
I0510 14:48:30.112934  5307 layer_factory.hpp:172] Creating layer 'conv4_2/sep' of type 'Convolution'
I0510 14:48:30.112938  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.112948  5307 net.cpp:200] Created Layer conv4_2/sep (51)
I0510 14:48:30.112952  5307 net.cpp:572] conv4_2/sep <- conv4_2/dw
I0510 14:48:30.112957  5307 net.cpp:542] conv4_2/sep -> conv4_2/sep
I0510 14:48:30.113800  5307 net.cpp:260] Setting up conv4_2/sep
I0510 14:48:30.113813  5307 net.cpp:267] TRAIN Top shape for layer 51 'conv4_2/sep' 16 256 16 32 (2097152)
I0510 14:48:30.113823  5307 layer_factory.hpp:172] Creating layer 'conv4_2/sep/bn' of type 'BatchNorm'
I0510 14:48:30.113831  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.113842  5307 net.cpp:200] Created Layer conv4_2/sep/bn (52)
I0510 14:48:30.113849  5307 net.cpp:572] conv4_2/sep/bn <- conv4_2/sep
I0510 14:48:30.113857  5307 net.cpp:527] conv4_2/sep/bn -> conv4_2/sep (in-place)
I0510 14:48:30.114123  5307 net.cpp:260] Setting up conv4_2/sep/bn
I0510 14:48:30.114135  5307 net.cpp:267] TRAIN Top shape for layer 52 'conv4_2/sep/bn' 16 256 16 32 (2097152)
I0510 14:48:30.114147  5307 layer_factory.hpp:172] Creating layer 'conv4_2/sep/scale' of type 'Scale'
I0510 14:48:30.114156  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.114173  5307 net.cpp:200] Created Layer conv4_2/sep/scale (53)
I0510 14:48:30.114181  5307 net.cpp:572] conv4_2/sep/scale <- conv4_2/sep
I0510 14:48:30.114189  5307 net.cpp:527] conv4_2/sep/scale -> conv4_2/sep (in-place)
I0510 14:48:30.114230  5307 layer_factory.hpp:172] Creating layer 'conv4_2/sep/scale' of type 'Bias'
I0510 14:48:30.114235  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.114305  5307 net.cpp:260] Setting up conv4_2/sep/scale
I0510 14:48:30.114310  5307 net.cpp:267] TRAIN Top shape for layer 53 'conv4_2/sep/scale' 16 256 16 32 (2097152)
I0510 14:48:30.114317  5307 layer_factory.hpp:172] Creating layer 'relu4_2/sep' of type 'ReLU'
I0510 14:48:30.114321  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.114326  5307 net.cpp:200] Created Layer relu4_2/sep (54)
I0510 14:48:30.114331  5307 net.cpp:572] relu4_2/sep <- conv4_2/sep
I0510 14:48:30.114336  5307 net.cpp:527] relu4_2/sep -> conv4_2/sep (in-place)
I0510 14:48:30.114341  5307 net.cpp:260] Setting up relu4_2/sep
I0510 14:48:30.114346  5307 net.cpp:267] TRAIN Top shape for layer 54 'relu4_2/sep' 16 256 16 32 (2097152)
I0510 14:48:30.114349  5307 layer_factory.hpp:172] Creating layer 'conv5_1/dw' of type 'Convolution'
I0510 14:48:30.114354  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.114362  5307 net.cpp:200] Created Layer conv5_1/dw (55)
I0510 14:48:30.114365  5307 net.cpp:572] conv5_1/dw <- conv4_2/sep
I0510 14:48:30.114370  5307 net.cpp:542] conv5_1/dw -> conv5_1/dw
I0510 14:48:30.114540  5307 net.cpp:260] Setting up conv5_1/dw
I0510 14:48:30.114547  5307 net.cpp:267] TRAIN Top shape for layer 55 'conv5_1/dw' 16 256 16 32 (2097152)
I0510 14:48:30.114553  5307 layer_factory.hpp:172] Creating layer 'conv5_1/dw/bn' of type 'BatchNorm'
I0510 14:48:30.114557  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.114563  5307 net.cpp:200] Created Layer conv5_1/dw/bn (56)
I0510 14:48:30.114567  5307 net.cpp:572] conv5_1/dw/bn <- conv5_1/dw
I0510 14:48:30.114573  5307 net.cpp:527] conv5_1/dw/bn -> conv5_1/dw (in-place)
I0510 14:48:30.114795  5307 net.cpp:260] Setting up conv5_1/dw/bn
I0510 14:48:30.114802  5307 net.cpp:267] TRAIN Top shape for layer 56 'conv5_1/dw/bn' 16 256 16 32 (2097152)
I0510 14:48:30.114810  5307 layer_factory.hpp:172] Creating layer 'conv5_1/dw/scale' of type 'Scale'
I0510 14:48:30.114820  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.114830  5307 net.cpp:200] Created Layer conv5_1/dw/scale (57)
I0510 14:48:30.114838  5307 net.cpp:572] conv5_1/dw/scale <- conv5_1/dw
I0510 14:48:30.114845  5307 net.cpp:527] conv5_1/dw/scale -> conv5_1/dw (in-place)
I0510 14:48:30.114882  5307 layer_factory.hpp:172] Creating layer 'conv5_1/dw/scale' of type 'Bias'
I0510 14:48:30.114892  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.114976  5307 net.cpp:260] Setting up conv5_1/dw/scale
I0510 14:48:30.114989  5307 net.cpp:267] TRAIN Top shape for layer 57 'conv5_1/dw/scale' 16 256 16 32 (2097152)
I0510 14:48:30.114998  5307 layer_factory.hpp:172] Creating layer 'relu5_1/dw' of type 'ReLU'
I0510 14:48:30.115006  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.115015  5307 net.cpp:200] Created Layer relu5_1/dw (58)
I0510 14:48:30.115022  5307 net.cpp:572] relu5_1/dw <- conv5_1/dw
I0510 14:48:30.115031  5307 net.cpp:527] relu5_1/dw -> conv5_1/dw (in-place)
I0510 14:48:30.115041  5307 net.cpp:260] Setting up relu5_1/dw
I0510 14:48:30.115049  5307 net.cpp:267] TRAIN Top shape for layer 58 'relu5_1/dw' 16 256 16 32 (2097152)
I0510 14:48:30.115057  5307 layer_factory.hpp:172] Creating layer 'conv5_1/sep' of type 'Convolution'
I0510 14:48:30.115067  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.115084  5307 net.cpp:200] Created Layer conv5_1/sep (59)
I0510 14:48:30.115093  5307 net.cpp:572] conv5_1/sep <- conv5_1/dw
I0510 14:48:30.115101  5307 net.cpp:542] conv5_1/sep -> conv5_1/sep
I0510 14:48:30.117199  5307 net.cpp:260] Setting up conv5_1/sep
I0510 14:48:30.117218  5307 net.cpp:267] TRAIN Top shape for layer 59 'conv5_1/sep' 16 256 16 32 (2097152)
I0510 14:48:30.117230  5307 layer_factory.hpp:172] Creating layer 'conv5_1/sep/bn' of type 'BatchNorm'
I0510 14:48:30.117240  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.117251  5307 net.cpp:200] Created Layer conv5_1/sep/bn (60)
I0510 14:48:30.117260  5307 net.cpp:572] conv5_1/sep/bn <- conv5_1/sep
I0510 14:48:30.117270  5307 net.cpp:527] conv5_1/sep/bn -> conv5_1/sep (in-place)
I0510 14:48:30.117601  5307 net.cpp:260] Setting up conv5_1/sep/bn
I0510 14:48:30.117615  5307 net.cpp:267] TRAIN Top shape for layer 60 'conv5_1/sep/bn' 16 256 16 32 (2097152)
I0510 14:48:30.117628  5307 layer_factory.hpp:172] Creating layer 'conv5_1/sep/scale' of type 'Scale'
I0510 14:48:30.117640  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.117650  5307 net.cpp:200] Created Layer conv5_1/sep/scale (61)
I0510 14:48:30.117660  5307 net.cpp:572] conv5_1/sep/scale <- conv5_1/sep
I0510 14:48:30.117669  5307 net.cpp:527] conv5_1/sep/scale -> conv5_1/sep (in-place)
I0510 14:48:30.117710  5307 layer_factory.hpp:172] Creating layer 'conv5_1/sep/scale' of type 'Bias'
I0510 14:48:30.117722  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.117818  5307 net.cpp:260] Setting up conv5_1/sep/scale
I0510 14:48:30.117835  5307 net.cpp:267] TRAIN Top shape for layer 61 'conv5_1/sep/scale' 16 256 16 32 (2097152)
I0510 14:48:30.117847  5307 layer_factory.hpp:172] Creating layer 'relu5_1/sep' of type 'ReLU'
I0510 14:48:30.117853  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.117861  5307 net.cpp:200] Created Layer relu5_1/sep (62)
I0510 14:48:30.117866  5307 net.cpp:572] relu5_1/sep <- conv5_1/sep
I0510 14:48:30.117871  5307 net.cpp:527] relu5_1/sep -> conv5_1/sep (in-place)
I0510 14:48:30.117877  5307 net.cpp:260] Setting up relu5_1/sep
I0510 14:48:30.117883  5307 net.cpp:267] TRAIN Top shape for layer 62 'relu5_1/sep' 16 256 16 32 (2097152)
I0510 14:48:30.117887  5307 layer_factory.hpp:172] Creating layer 'conv5_2/dw' of type 'Convolution'
I0510 14:48:30.117892  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.117900  5307 net.cpp:200] Created Layer conv5_2/dw (63)
I0510 14:48:30.117903  5307 net.cpp:572] conv5_2/dw <- conv5_1/sep
I0510 14:48:30.117908  5307 net.cpp:542] conv5_2/dw -> conv5_2/dw
I0510 14:48:30.118083  5307 net.cpp:260] Setting up conv5_2/dw
I0510 14:48:30.118090  5307 net.cpp:267] TRAIN Top shape for layer 63 'conv5_2/dw' 16 256 16 32 (2097152)
I0510 14:48:30.118096  5307 layer_factory.hpp:172] Creating layer 'conv5_2/dw/bn' of type 'BatchNorm'
I0510 14:48:30.118100  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.118109  5307 net.cpp:200] Created Layer conv5_2/dw/bn (64)
I0510 14:48:30.118113  5307 net.cpp:572] conv5_2/dw/bn <- conv5_2/dw
I0510 14:48:30.118119  5307 net.cpp:527] conv5_2/dw/bn -> conv5_2/dw (in-place)
I0510 14:48:30.118343  5307 net.cpp:260] Setting up conv5_2/dw/bn
I0510 14:48:30.118350  5307 net.cpp:267] TRAIN Top shape for layer 64 'conv5_2/dw/bn' 16 256 16 32 (2097152)
I0510 14:48:30.118357  5307 layer_factory.hpp:172] Creating layer 'conv5_2/dw/scale' of type 'Scale'
I0510 14:48:30.118361  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.118367  5307 net.cpp:200] Created Layer conv5_2/dw/scale (65)
I0510 14:48:30.118371  5307 net.cpp:572] conv5_2/dw/scale <- conv5_2/dw
I0510 14:48:30.118376  5307 net.cpp:527] conv5_2/dw/scale -> conv5_2/dw (in-place)
I0510 14:48:30.118410  5307 layer_factory.hpp:172] Creating layer 'conv5_2/dw/scale' of type 'Bias'
I0510 14:48:30.118415  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.118484  5307 net.cpp:260] Setting up conv5_2/dw/scale
I0510 14:48:30.118489  5307 net.cpp:267] TRAIN Top shape for layer 65 'conv5_2/dw/scale' 16 256 16 32 (2097152)
I0510 14:48:30.118496  5307 layer_factory.hpp:172] Creating layer 'relu5_2/dw' of type 'ReLU'
I0510 14:48:30.118500  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.118505  5307 net.cpp:200] Created Layer relu5_2/dw (66)
I0510 14:48:30.118510  5307 net.cpp:572] relu5_2/dw <- conv5_2/dw
I0510 14:48:30.118515  5307 net.cpp:527] relu5_2/dw -> conv5_2/dw (in-place)
I0510 14:48:30.118520  5307 net.cpp:260] Setting up relu5_2/dw
I0510 14:48:30.118525  5307 net.cpp:267] TRAIN Top shape for layer 66 'relu5_2/dw' 16 256 16 32 (2097152)
I0510 14:48:30.118528  5307 layer_factory.hpp:172] Creating layer 'conv5_2/sep' of type 'Convolution'
I0510 14:48:30.118533  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.118542  5307 net.cpp:200] Created Layer conv5_2/sep (67)
I0510 14:48:30.118546  5307 net.cpp:572] conv5_2/sep <- conv5_2/dw
I0510 14:48:30.118551  5307 net.cpp:542] conv5_2/sep -> conv5_2/sep
I0510 14:48:30.120138  5307 net.cpp:260] Setting up conv5_2/sep
I0510 14:48:30.120154  5307 net.cpp:267] TRAIN Top shape for layer 67 'conv5_2/sep' 16 256 16 32 (2097152)
I0510 14:48:30.120165  5307 layer_factory.hpp:172] Creating layer 'conv5_2/sep/bn' of type 'BatchNorm'
I0510 14:48:30.120174  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.120184  5307 net.cpp:200] Created Layer conv5_2/sep/bn (68)
I0510 14:48:30.120193  5307 net.cpp:572] conv5_2/sep/bn <- conv5_2/sep
I0510 14:48:30.120203  5307 net.cpp:527] conv5_2/sep/bn -> conv5_2/sep (in-place)
I0510 14:48:30.120518  5307 net.cpp:260] Setting up conv5_2/sep/bn
I0510 14:48:30.120535  5307 net.cpp:267] TRAIN Top shape for layer 68 'conv5_2/sep/bn' 16 256 16 32 (2097152)
I0510 14:48:30.120548  5307 layer_factory.hpp:172] Creating layer 'conv5_2/sep/scale' of type 'Scale'
I0510 14:48:30.120555  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.120565  5307 net.cpp:200] Created Layer conv5_2/sep/scale (69)
I0510 14:48:30.120573  5307 net.cpp:572] conv5_2/sep/scale <- conv5_2/sep
I0510 14:48:30.120581  5307 net.cpp:527] conv5_2/sep/scale -> conv5_2/sep (in-place)
I0510 14:48:30.120617  5307 layer_factory.hpp:172] Creating layer 'conv5_2/sep/scale' of type 'Bias'
I0510 14:48:30.120626  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.120719  5307 net.cpp:260] Setting up conv5_2/sep/scale
I0510 14:48:30.120730  5307 net.cpp:267] TRAIN Top shape for layer 69 'conv5_2/sep/scale' 16 256 16 32 (2097152)
I0510 14:48:30.120740  5307 layer_factory.hpp:172] Creating layer 'relu5_2/sep' of type 'ReLU'
I0510 14:48:30.120748  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.120757  5307 net.cpp:200] Created Layer relu5_2/sep (70)
I0510 14:48:30.120764  5307 net.cpp:572] relu5_2/sep <- conv5_2/sep
I0510 14:48:30.120772  5307 net.cpp:527] relu5_2/sep -> conv5_2/sep (in-place)
I0510 14:48:30.120782  5307 net.cpp:260] Setting up relu5_2/sep
I0510 14:48:30.120791  5307 net.cpp:267] TRAIN Top shape for layer 70 'relu5_2/sep' 16 256 16 32 (2097152)
I0510 14:48:30.120800  5307 layer_factory.hpp:172] Creating layer 'conv5_3/dw' of type 'Convolution'
I0510 14:48:30.120807  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.120818  5307 net.cpp:200] Created Layer conv5_3/dw (71)
I0510 14:48:30.120829  5307 net.cpp:572] conv5_3/dw <- conv5_2/sep
I0510 14:48:30.120838  5307 net.cpp:542] conv5_3/dw -> conv5_3/dw
I0510 14:48:30.121068  5307 net.cpp:260] Setting up conv5_3/dw
I0510 14:48:30.121081  5307 net.cpp:267] TRAIN Top shape for layer 71 'conv5_3/dw' 16 256 16 32 (2097152)
I0510 14:48:30.121091  5307 layer_factory.hpp:172] Creating layer 'conv5_3/dw/bn' of type 'BatchNorm'
I0510 14:48:30.121099  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.121109  5307 net.cpp:200] Created Layer conv5_3/dw/bn (72)
I0510 14:48:30.121116  5307 net.cpp:572] conv5_3/dw/bn <- conv5_3/dw
I0510 14:48:30.121125  5307 net.cpp:527] conv5_3/dw/bn -> conv5_3/dw (in-place)
I0510 14:48:30.121392  5307 net.cpp:260] Setting up conv5_3/dw/bn
I0510 14:48:30.121398  5307 net.cpp:267] TRAIN Top shape for layer 72 'conv5_3/dw/bn' 16 256 16 32 (2097152)
I0510 14:48:30.121407  5307 layer_factory.hpp:172] Creating layer 'conv5_3/dw/scale' of type 'Scale'
I0510 14:48:30.121410  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.121417  5307 net.cpp:200] Created Layer conv5_3/dw/scale (73)
I0510 14:48:30.121420  5307 net.cpp:572] conv5_3/dw/scale <- conv5_3/dw
I0510 14:48:30.121425  5307 net.cpp:527] conv5_3/dw/scale -> conv5_3/dw (in-place)
I0510 14:48:30.121454  5307 layer_factory.hpp:172] Creating layer 'conv5_3/dw/scale' of type 'Bias'
I0510 14:48:30.121459  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.121527  5307 net.cpp:260] Setting up conv5_3/dw/scale
I0510 14:48:30.121533  5307 net.cpp:267] TRAIN Top shape for layer 73 'conv5_3/dw/scale' 16 256 16 32 (2097152)
I0510 14:48:30.121541  5307 layer_factory.hpp:172] Creating layer 'relu5_3/dw' of type 'ReLU'
I0510 14:48:30.121544  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.121549  5307 net.cpp:200] Created Layer relu5_3/dw (74)
I0510 14:48:30.121553  5307 net.cpp:572] relu5_3/dw <- conv5_3/dw
I0510 14:48:30.121558  5307 net.cpp:527] relu5_3/dw -> conv5_3/dw (in-place)
I0510 14:48:30.121565  5307 net.cpp:260] Setting up relu5_3/dw
I0510 14:48:30.121570  5307 net.cpp:267] TRAIN Top shape for layer 74 'relu5_3/dw' 16 256 16 32 (2097152)
I0510 14:48:30.121574  5307 layer_factory.hpp:172] Creating layer 'conv5_3/sep' of type 'Convolution'
I0510 14:48:30.121578  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.121587  5307 net.cpp:200] Created Layer conv5_3/sep (75)
I0510 14:48:30.121589  5307 net.cpp:572] conv5_3/sep <- conv5_3/dw
I0510 14:48:30.121594  5307 net.cpp:542] conv5_3/sep -> conv5_3/sep
I0510 14:48:30.123428  5307 net.cpp:260] Setting up conv5_3/sep
I0510 14:48:30.123436  5307 net.cpp:267] TRAIN Top shape for layer 75 'conv5_3/sep' 16 256 16 32 (2097152)
I0510 14:48:30.123442  5307 layer_factory.hpp:172] Creating layer 'conv5_3/sep/bn' of type 'BatchNorm'
I0510 14:48:30.123446  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.123452  5307 net.cpp:200] Created Layer conv5_3/sep/bn (76)
I0510 14:48:30.123456  5307 net.cpp:572] conv5_3/sep/bn <- conv5_3/sep
I0510 14:48:30.123461  5307 net.cpp:527] conv5_3/sep/bn -> conv5_3/sep (in-place)
I0510 14:48:30.123687  5307 net.cpp:260] Setting up conv5_3/sep/bn
I0510 14:48:30.123692  5307 net.cpp:267] TRAIN Top shape for layer 76 'conv5_3/sep/bn' 16 256 16 32 (2097152)
I0510 14:48:30.123700  5307 layer_factory.hpp:172] Creating layer 'conv5_3/sep/scale' of type 'Scale'
I0510 14:48:30.123703  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.123711  5307 net.cpp:200] Created Layer conv5_3/sep/scale (77)
I0510 14:48:30.123715  5307 net.cpp:572] conv5_3/sep/scale <- conv5_3/sep
I0510 14:48:30.123720  5307 net.cpp:527] conv5_3/sep/scale -> conv5_3/sep (in-place)
I0510 14:48:30.123749  5307 layer_factory.hpp:172] Creating layer 'conv5_3/sep/scale' of type 'Bias'
I0510 14:48:30.123754  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.123829  5307 net.cpp:260] Setting up conv5_3/sep/scale
I0510 14:48:30.123836  5307 net.cpp:267] TRAIN Top shape for layer 77 'conv5_3/sep/scale' 16 256 16 32 (2097152)
I0510 14:48:30.123842  5307 layer_factory.hpp:172] Creating layer 'relu5_3/sep' of type 'ReLU'
I0510 14:48:30.123847  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.123852  5307 net.cpp:200] Created Layer relu5_3/sep (78)
I0510 14:48:30.123855  5307 net.cpp:572] relu5_3/sep <- conv5_3/sep
I0510 14:48:30.123859  5307 net.cpp:527] relu5_3/sep -> conv5_3/sep (in-place)
I0510 14:48:30.123865  5307 net.cpp:260] Setting up relu5_3/sep
I0510 14:48:30.123870  5307 net.cpp:267] TRAIN Top shape for layer 78 'relu5_3/sep' 16 256 16 32 (2097152)
I0510 14:48:30.123874  5307 layer_factory.hpp:172] Creating layer 'conv5_4/dw' of type 'Convolution'
I0510 14:48:30.123878  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.123886  5307 net.cpp:200] Created Layer conv5_4/dw (79)
I0510 14:48:30.123890  5307 net.cpp:572] conv5_4/dw <- conv5_3/sep
I0510 14:48:30.123894  5307 net.cpp:542] conv5_4/dw -> conv5_4/dw
I0510 14:48:30.124126  5307 net.cpp:260] Setting up conv5_4/dw
I0510 14:48:30.124142  5307 net.cpp:267] TRAIN Top shape for layer 79 'conv5_4/dw' 16 256 16 32 (2097152)
I0510 14:48:30.124152  5307 layer_factory.hpp:172] Creating layer 'conv5_4/dw/bn' of type 'BatchNorm'
I0510 14:48:30.124161  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.124172  5307 net.cpp:200] Created Layer conv5_4/dw/bn (80)
I0510 14:48:30.124181  5307 net.cpp:572] conv5_4/dw/bn <- conv5_4/dw
I0510 14:48:30.124189  5307 net.cpp:527] conv5_4/dw/bn -> conv5_4/dw (in-place)
I0510 14:48:30.124495  5307 net.cpp:260] Setting up conv5_4/dw/bn
I0510 14:48:30.124506  5307 net.cpp:267] TRAIN Top shape for layer 80 'conv5_4/dw/bn' 16 256 16 32 (2097152)
I0510 14:48:30.124517  5307 layer_factory.hpp:172] Creating layer 'conv5_4/dw/scale' of type 'Scale'
I0510 14:48:30.124533  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.124545  5307 net.cpp:200] Created Layer conv5_4/dw/scale (81)
I0510 14:48:30.124554  5307 net.cpp:572] conv5_4/dw/scale <- conv5_4/dw
I0510 14:48:30.124563  5307 net.cpp:527] conv5_4/dw/scale -> conv5_4/dw (in-place)
I0510 14:48:30.124601  5307 layer_factory.hpp:172] Creating layer 'conv5_4/dw/scale' of type 'Bias'
I0510 14:48:30.124611  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.124696  5307 net.cpp:260] Setting up conv5_4/dw/scale
I0510 14:48:30.124706  5307 net.cpp:267] TRAIN Top shape for layer 81 'conv5_4/dw/scale' 16 256 16 32 (2097152)
I0510 14:48:30.124716  5307 layer_factory.hpp:172] Creating layer 'relu5_4/dw' of type 'ReLU'
I0510 14:48:30.124724  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.124732  5307 net.cpp:200] Created Layer relu5_4/dw (82)
I0510 14:48:30.124740  5307 net.cpp:572] relu5_4/dw <- conv5_4/dw
I0510 14:48:30.124748  5307 net.cpp:527] relu5_4/dw -> conv5_4/dw (in-place)
I0510 14:48:30.124758  5307 net.cpp:260] Setting up relu5_4/dw
I0510 14:48:30.124766  5307 net.cpp:267] TRAIN Top shape for layer 82 'relu5_4/dw' 16 256 16 32 (2097152)
I0510 14:48:30.124774  5307 layer_factory.hpp:172] Creating layer 'conv5_4/sep' of type 'Convolution'
I0510 14:48:30.124783  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.124794  5307 net.cpp:200] Created Layer conv5_4/sep (83)
I0510 14:48:30.124802  5307 net.cpp:572] conv5_4/sep <- conv5_4/dw
I0510 14:48:30.124810  5307 net.cpp:542] conv5_4/sep -> conv5_4/sep
I0510 14:48:30.128613  5307 net.cpp:260] Setting up conv5_4/sep
I0510 14:48:30.128695  5307 net.cpp:267] TRAIN Top shape for layer 83 'conv5_4/sep' 16 256 16 32 (2097152)
I0510 14:48:30.128736  5307 layer_factory.hpp:172] Creating layer 'conv5_4/sep/bn' of type 'BatchNorm'
I0510 14:48:30.128757  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.128780  5307 net.cpp:200] Created Layer conv5_4/sep/bn (84)
I0510 14:48:30.128794  5307 net.cpp:572] conv5_4/sep/bn <- conv5_4/sep
I0510 14:48:30.128809  5307 net.cpp:527] conv5_4/sep/bn -> conv5_4/sep (in-place)
I0510 14:48:30.129273  5307 net.cpp:260] Setting up conv5_4/sep/bn
I0510 14:48:30.129310  5307 net.cpp:267] TRAIN Top shape for layer 84 'conv5_4/sep/bn' 16 256 16 32 (2097152)
I0510 14:48:30.129335  5307 layer_factory.hpp:172] Creating layer 'conv5_4/sep/scale' of type 'Scale'
I0510 14:48:30.129354  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.129376  5307 net.cpp:200] Created Layer conv5_4/sep/scale (85)
I0510 14:48:30.129393  5307 net.cpp:572] conv5_4/sep/scale <- conv5_4/sep
I0510 14:48:30.129410  5307 net.cpp:527] conv5_4/sep/scale -> conv5_4/sep (in-place)
I0510 14:48:30.129469  5307 layer_factory.hpp:172] Creating layer 'conv5_4/sep/scale' of type 'Bias'
I0510 14:48:30.129492  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.129631  5307 net.cpp:260] Setting up conv5_4/sep/scale
I0510 14:48:30.129653  5307 net.cpp:267] TRAIN Top shape for layer 85 'conv5_4/sep/scale' 16 256 16 32 (2097152)
I0510 14:48:30.129673  5307 layer_factory.hpp:172] Creating layer 'relu5_4/sep' of type 'ReLU'
I0510 14:48:30.129693  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.129714  5307 net.cpp:200] Created Layer relu5_4/sep (86)
I0510 14:48:30.129737  5307 net.cpp:572] relu5_4/sep <- conv5_4/sep
I0510 14:48:30.129758  5307 net.cpp:527] relu5_4/sep -> conv5_4/sep (in-place)
I0510 14:48:30.129781  5307 net.cpp:260] Setting up relu5_4/sep
I0510 14:48:30.129801  5307 net.cpp:267] TRAIN Top shape for layer 86 'relu5_4/sep' 16 256 16 32 (2097152)
I0510 14:48:30.129820  5307 layer_factory.hpp:172] Creating layer 'conv5_5/dw' of type 'Convolution'
I0510 14:48:30.129839  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.129868  5307 net.cpp:200] Created Layer conv5_5/dw (87)
I0510 14:48:30.129887  5307 net.cpp:572] conv5_5/dw <- conv5_4/sep
I0510 14:48:30.129905  5307 net.cpp:542] conv5_5/dw -> conv5_5/dw
I0510 14:48:30.130306  5307 net.cpp:260] Setting up conv5_5/dw
I0510 14:48:30.130342  5307 net.cpp:267] TRAIN Top shape for layer 87 'conv5_5/dw' 16 256 16 32 (2097152)
I0510 14:48:30.130373  5307 layer_factory.hpp:172] Creating layer 'conv5_5/dw/bn' of type 'BatchNorm'
I0510 14:48:30.130393  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.130414  5307 net.cpp:200] Created Layer conv5_5/dw/bn (88)
I0510 14:48:30.130434  5307 net.cpp:572] conv5_5/dw/bn <- conv5_5/dw
I0510 14:48:30.130450  5307 net.cpp:527] conv5_5/dw/bn -> conv5_5/dw (in-place)
I0510 14:48:30.130820  5307 net.cpp:260] Setting up conv5_5/dw/bn
I0510 14:48:30.130844  5307 net.cpp:267] TRAIN Top shape for layer 88 'conv5_5/dw/bn' 16 256 16 32 (2097152)
I0510 14:48:30.130873  5307 layer_factory.hpp:172] Creating layer 'conv5_5/dw/scale' of type 'Scale'
I0510 14:48:30.130889  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.130909  5307 net.cpp:200] Created Layer conv5_5/dw/scale (89)
I0510 14:48:30.130926  5307 net.cpp:572] conv5_5/dw/scale <- conv5_5/dw
I0510 14:48:30.130942  5307 net.cpp:527] conv5_5/dw/scale -> conv5_5/dw (in-place)
I0510 14:48:30.130995  5307 layer_factory.hpp:172] Creating layer 'conv5_5/dw/scale' of type 'Bias'
I0510 14:48:30.131014  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.131129  5307 net.cpp:260] Setting up conv5_5/dw/scale
I0510 14:48:30.131156  5307 net.cpp:267] TRAIN Top shape for layer 89 'conv5_5/dw/scale' 16 256 16 32 (2097152)
I0510 14:48:30.131183  5307 layer_factory.hpp:172] Creating layer 'relu5_5/dw' of type 'ReLU'
I0510 14:48:30.131199  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.131216  5307 net.cpp:200] Created Layer relu5_5/dw (90)
I0510 14:48:30.131229  5307 net.cpp:572] relu5_5/dw <- conv5_5/dw
I0510 14:48:30.131244  5307 net.cpp:527] relu5_5/dw -> conv5_5/dw (in-place)
I0510 14:48:30.131261  5307 net.cpp:260] Setting up relu5_5/dw
I0510 14:48:30.131278  5307 net.cpp:267] TRAIN Top shape for layer 90 'relu5_5/dw' 16 256 16 32 (2097152)
I0510 14:48:30.131291  5307 layer_factory.hpp:172] Creating layer 'conv5_5/sep' of type 'Convolution'
I0510 14:48:30.131305  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.131325  5307 net.cpp:200] Created Layer conv5_5/sep (91)
I0510 14:48:30.131340  5307 net.cpp:572] conv5_5/sep <- conv5_5/dw
I0510 14:48:30.131356  5307 net.cpp:542] conv5_5/sep -> conv5_5/sep
I0510 14:48:30.133545  5307 net.cpp:260] Setting up conv5_5/sep
I0510 14:48:30.133577  5307 net.cpp:267] TRAIN Top shape for layer 91 'conv5_5/sep' 16 256 16 32 (2097152)
I0510 14:48:30.133596  5307 layer_factory.hpp:172] Creating layer 'conv5_5/sep/bn' of type 'BatchNorm'
I0510 14:48:30.133611  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.133628  5307 net.cpp:200] Created Layer conv5_5/sep/bn (92)
I0510 14:48:30.133644  5307 net.cpp:572] conv5_5/sep/bn <- conv5_5/sep
I0510 14:48:30.133661  5307 net.cpp:527] conv5_5/sep/bn -> conv5_5/sep (in-place)
I0510 14:48:30.134043  5307 net.cpp:260] Setting up conv5_5/sep/bn
I0510 14:48:30.134069  5307 net.cpp:267] TRAIN Top shape for layer 92 'conv5_5/sep/bn' 16 256 16 32 (2097152)
I0510 14:48:30.134088  5307 layer_factory.hpp:172] Creating layer 'conv5_5/sep/scale' of type 'Scale'
I0510 14:48:30.134104  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.134121  5307 net.cpp:200] Created Layer conv5_5/sep/scale (93)
I0510 14:48:30.134137  5307 net.cpp:572] conv5_5/sep/scale <- conv5_5/sep
I0510 14:48:30.134155  5307 net.cpp:527] conv5_5/sep/scale -> conv5_5/sep (in-place)
I0510 14:48:30.134205  5307 layer_factory.hpp:172] Creating layer 'conv5_5/sep/scale' of type 'Bias'
I0510 14:48:30.134222  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.134336  5307 net.cpp:260] Setting up conv5_5/sep/scale
I0510 14:48:30.134356  5307 net.cpp:267] TRAIN Top shape for layer 93 'conv5_5/sep/scale' 16 256 16 32 (2097152)
I0510 14:48:30.134379  5307 layer_factory.hpp:172] Creating layer 'relu5_5/sep' of type 'ReLU'
I0510 14:48:30.134397  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.134414  5307 net.cpp:200] Created Layer relu5_5/sep (94)
I0510 14:48:30.134429  5307 net.cpp:572] relu5_5/sep <- conv5_5/sep
I0510 14:48:30.134443  5307 net.cpp:527] relu5_5/sep -> conv5_5/sep (in-place)
I0510 14:48:30.134460  5307 net.cpp:260] Setting up relu5_5/sep
I0510 14:48:30.134475  5307 net.cpp:267] TRAIN Top shape for layer 94 'relu5_5/sep' 16 256 16 32 (2097152)
I0510 14:48:30.134490  5307 layer_factory.hpp:172] Creating layer 'conv5_5/sep_relu5_5/sep_0_split' of type 'Split'
I0510 14:48:30.134505  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.134519  5307 net.cpp:200] Created Layer conv5_5/sep_relu5_5/sep_0_split (95)
I0510 14:48:30.134533  5307 net.cpp:572] conv5_5/sep_relu5_5/sep_0_split <- conv5_5/sep
I0510 14:48:30.134548  5307 net.cpp:542] conv5_5/sep_relu5_5/sep_0_split -> conv5_5/sep_relu5_5/sep_0_split_0
I0510 14:48:30.134565  5307 net.cpp:542] conv5_5/sep_relu5_5/sep_0_split -> conv5_5/sep_relu5_5/sep_0_split_1
I0510 14:48:30.134613  5307 net.cpp:260] Setting up conv5_5/sep_relu5_5/sep_0_split
I0510 14:48:30.134639  5307 net.cpp:267] TRAIN Top shape for layer 95 'conv5_5/sep_relu5_5/sep_0_split' 16 256 16 32 (2097152)
I0510 14:48:30.134663  5307 net.cpp:267] TRAIN Top shape for layer 95 'conv5_5/sep_relu5_5/sep_0_split' 16 256 16 32 (2097152)
I0510 14:48:30.134680  5307 layer_factory.hpp:172] Creating layer 'conv5_6/dw' of type 'Convolution'
I0510 14:48:30.134696  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.134718  5307 net.cpp:200] Created Layer conv5_6/dw (96)
I0510 14:48:30.134734  5307 net.cpp:572] conv5_6/dw <- conv5_5/sep_relu5_5/sep_0_split_0
I0510 14:48:30.134749  5307 net.cpp:542] conv5_6/dw -> conv5_6/dw
I0510 14:48:30.135025  5307 net.cpp:260] Setting up conv5_6/dw
I0510 14:48:30.135047  5307 net.cpp:267] TRAIN Top shape for layer 96 'conv5_6/dw' 16 256 8 16 (524288)
I0510 14:48:30.135064  5307 layer_factory.hpp:172] Creating layer 'conv5_6/dw/bn' of type 'BatchNorm'
I0510 14:48:30.135078  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.135095  5307 net.cpp:200] Created Layer conv5_6/dw/bn (97)
I0510 14:48:30.135114  5307 net.cpp:572] conv5_6/dw/bn <- conv5_6/dw
I0510 14:48:30.135130  5307 net.cpp:527] conv5_6/dw/bn -> conv5_6/dw (in-place)
I0510 14:48:30.135478  5307 net.cpp:260] Setting up conv5_6/dw/bn
I0510 14:48:30.135500  5307 net.cpp:267] TRAIN Top shape for layer 97 'conv5_6/dw/bn' 16 256 8 16 (524288)
I0510 14:48:30.135519  5307 layer_factory.hpp:172] Creating layer 'conv5_6/dw/scale' of type 'Scale'
I0510 14:48:30.135534  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.135550  5307 net.cpp:200] Created Layer conv5_6/dw/scale (98)
I0510 14:48:30.135568  5307 net.cpp:572] conv5_6/dw/scale <- conv5_6/dw
I0510 14:48:30.135586  5307 net.cpp:527] conv5_6/dw/scale -> conv5_6/dw (in-place)
I0510 14:48:30.135637  5307 layer_factory.hpp:172] Creating layer 'conv5_6/dw/scale' of type 'Bias'
I0510 14:48:30.135654  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.135759  5307 net.cpp:260] Setting up conv5_6/dw/scale
I0510 14:48:30.135778  5307 net.cpp:267] TRAIN Top shape for layer 98 'conv5_6/dw/scale' 16 256 8 16 (524288)
I0510 14:48:30.135797  5307 layer_factory.hpp:172] Creating layer 'relu5_6/dw' of type 'ReLU'
I0510 14:48:30.135814  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.135830  5307 net.cpp:200] Created Layer relu5_6/dw (99)
I0510 14:48:30.135845  5307 net.cpp:572] relu5_6/dw <- conv5_6/dw
I0510 14:48:30.135860  5307 net.cpp:527] relu5_6/dw -> conv5_6/dw (in-place)
I0510 14:48:30.135876  5307 net.cpp:260] Setting up relu5_6/dw
I0510 14:48:30.135891  5307 net.cpp:267] TRAIN Top shape for layer 99 'relu5_6/dw' 16 256 8 16 (524288)
I0510 14:48:30.135906  5307 layer_factory.hpp:172] Creating layer 'conv5_6/sep' of type 'Convolution'
I0510 14:48:30.135921  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.135939  5307 net.cpp:200] Created Layer conv5_6/sep (100)
I0510 14:48:30.135953  5307 net.cpp:572] conv5_6/sep <- conv5_6/dw
I0510 14:48:30.135967  5307 net.cpp:542] conv5_6/sep -> conv5_6/sep
I0510 14:48:30.140096  5307 net.cpp:260] Setting up conv5_6/sep
I0510 14:48:30.140142  5307 net.cpp:267] TRAIN Top shape for layer 100 'conv5_6/sep' 16 512 8 16 (1048576)
I0510 14:48:30.140163  5307 layer_factory.hpp:172] Creating layer 'conv5_6/sep/bn' of type 'BatchNorm'
I0510 14:48:30.140183  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.140204  5307 net.cpp:200] Created Layer conv5_6/sep/bn (101)
I0510 14:48:30.140221  5307 net.cpp:572] conv5_6/sep/bn <- conv5_6/sep
I0510 14:48:30.140239  5307 net.cpp:527] conv5_6/sep/bn -> conv5_6/sep (in-place)
I0510 14:48:30.140622  5307 net.cpp:260] Setting up conv5_6/sep/bn
I0510 14:48:30.140650  5307 net.cpp:267] TRAIN Top shape for layer 101 'conv5_6/sep/bn' 16 512 8 16 (1048576)
I0510 14:48:30.140676  5307 layer_factory.hpp:172] Creating layer 'conv5_6/sep/scale' of type 'Scale'
I0510 14:48:30.140700  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.140722  5307 net.cpp:200] Created Layer conv5_6/sep/scale (102)
I0510 14:48:30.140741  5307 net.cpp:572] conv5_6/sep/scale <- conv5_6/sep
I0510 14:48:30.140758  5307 net.cpp:527] conv5_6/sep/scale -> conv5_6/sep (in-place)
I0510 14:48:30.140813  5307 layer_factory.hpp:172] Creating layer 'conv5_6/sep/scale' of type 'Bias'
I0510 14:48:30.140830  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.140949  5307 net.cpp:260] Setting up conv5_6/sep/scale
I0510 14:48:30.140969  5307 net.cpp:267] TRAIN Top shape for layer 102 'conv5_6/sep/scale' 16 512 8 16 (1048576)
I0510 14:48:30.140987  5307 layer_factory.hpp:172] Creating layer 'relu5_6/sep' of type 'ReLU'
I0510 14:48:30.141003  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.141021  5307 net.cpp:200] Created Layer relu5_6/sep (103)
I0510 14:48:30.141036  5307 net.cpp:572] relu5_6/sep <- conv5_6/sep
I0510 14:48:30.141052  5307 net.cpp:527] relu5_6/sep -> conv5_6/sep (in-place)
I0510 14:48:30.141070  5307 net.cpp:260] Setting up relu5_6/sep
I0510 14:48:30.141088  5307 net.cpp:267] TRAIN Top shape for layer 103 'relu5_6/sep' 16 512 8 16 (1048576)
I0510 14:48:30.141103  5307 layer_factory.hpp:172] Creating layer 'conv6/dw' of type 'Convolution'
I0510 14:48:30.141118  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.141139  5307 net.cpp:200] Created Layer conv6/dw (104)
I0510 14:48:30.141163  5307 net.cpp:572] conv6/dw <- conv5_6/sep
I0510 14:48:30.141181  5307 net.cpp:542] conv6/dw -> conv6/dw
I0510 14:48:30.141530  5307 net.cpp:260] Setting up conv6/dw
I0510 14:48:30.141553  5307 net.cpp:267] TRAIN Top shape for layer 104 'conv6/dw' 16 512 8 16 (1048576)
I0510 14:48:30.141571  5307 layer_factory.hpp:172] Creating layer 'conv6/dw/bn' of type 'BatchNorm'
I0510 14:48:30.141587  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.141602  5307 net.cpp:200] Created Layer conv6/dw/bn (105)
I0510 14:48:30.141618  5307 net.cpp:572] conv6/dw/bn <- conv6/dw
I0510 14:48:30.141631  5307 net.cpp:527] conv6/dw/bn -> conv6/dw (in-place)
I0510 14:48:30.141988  5307 net.cpp:260] Setting up conv6/dw/bn
I0510 14:48:30.142010  5307 net.cpp:267] TRAIN Top shape for layer 105 'conv6/dw/bn' 16 512 8 16 (1048576)
I0510 14:48:30.142029  5307 layer_factory.hpp:172] Creating layer 'conv6/dw/scale' of type 'Scale'
I0510 14:48:30.142045  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.142060  5307 net.cpp:200] Created Layer conv6/dw/scale (106)
I0510 14:48:30.142076  5307 net.cpp:572] conv6/dw/scale <- conv6/dw
I0510 14:48:30.142089  5307 net.cpp:527] conv6/dw/scale -> conv6/dw (in-place)
I0510 14:48:30.142138  5307 layer_factory.hpp:172] Creating layer 'conv6/dw/scale' of type 'Bias'
I0510 14:48:30.142154  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.142272  5307 net.cpp:260] Setting up conv6/dw/scale
I0510 14:48:30.142292  5307 net.cpp:267] TRAIN Top shape for layer 106 'conv6/dw/scale' 16 512 8 16 (1048576)
I0510 14:48:30.142313  5307 layer_factory.hpp:172] Creating layer 'relu6/dw' of type 'ReLU'
I0510 14:48:30.142328  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.142344  5307 net.cpp:200] Created Layer relu6/dw (107)
I0510 14:48:30.142359  5307 net.cpp:572] relu6/dw <- conv6/dw
I0510 14:48:30.142375  5307 net.cpp:527] relu6/dw -> conv6/dw (in-place)
I0510 14:48:30.142392  5307 net.cpp:260] Setting up relu6/dw
I0510 14:48:30.142410  5307 net.cpp:267] TRAIN Top shape for layer 107 'relu6/dw' 16 512 8 16 (1048576)
I0510 14:48:30.142429  5307 layer_factory.hpp:172] Creating layer 'conv6/sep' of type 'Convolution'
I0510 14:48:30.142452  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.142474  5307 net.cpp:200] Created Layer conv6/sep (108)
I0510 14:48:30.142490  5307 net.cpp:572] conv6/sep <- conv6/dw
I0510 14:48:30.142504  5307 net.cpp:542] conv6/sep -> conv6/sep
I0510 14:48:30.148224  5307 net.cpp:260] Setting up conv6/sep
I0510 14:48:30.148257  5307 net.cpp:267] TRAIN Top shape for layer 108 'conv6/sep' 16 512 8 16 (1048576)
I0510 14:48:30.148267  5307 layer_factory.hpp:172] Creating layer 'conv6/sep/bn' of type 'BatchNorm'
I0510 14:48:30.148273  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.148284  5307 net.cpp:200] Created Layer conv6/sep/bn (109)
I0510 14:48:30.148300  5307 net.cpp:572] conv6/sep/bn <- conv6/sep
I0510 14:48:30.148313  5307 net.cpp:527] conv6/sep/bn -> conv6/sep (in-place)
I0510 14:48:30.148607  5307 net.cpp:260] Setting up conv6/sep/bn
I0510 14:48:30.148614  5307 net.cpp:267] TRAIN Top shape for layer 109 'conv6/sep/bn' 16 512 8 16 (1048576)
I0510 14:48:30.148622  5307 layer_factory.hpp:172] Creating layer 'conv6/sep/scale' of type 'Scale'
I0510 14:48:30.148633  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.148646  5307 net.cpp:200] Created Layer conv6/sep/scale (110)
I0510 14:48:30.148651  5307 net.cpp:572] conv6/sep/scale <- conv6/sep
I0510 14:48:30.148655  5307 net.cpp:527] conv6/sep/scale -> conv6/sep (in-place)
I0510 14:48:30.148696  5307 layer_factory.hpp:172] Creating layer 'conv6/sep/scale' of type 'Bias'
I0510 14:48:30.148701  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.148789  5307 net.cpp:260] Setting up conv6/sep/scale
I0510 14:48:30.148797  5307 net.cpp:267] TRAIN Top shape for layer 110 'conv6/sep/scale' 16 512 8 16 (1048576)
I0510 14:48:30.148802  5307 layer_factory.hpp:172] Creating layer 'relu6/sep' of type 'ReLU'
I0510 14:48:30.148813  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.148820  5307 net.cpp:200] Created Layer relu6/sep (111)
I0510 14:48:30.148829  5307 net.cpp:572] relu6/sep <- conv6/sep
I0510 14:48:30.148834  5307 net.cpp:527] relu6/sep -> conv6/sep (in-place)
I0510 14:48:30.148846  5307 net.cpp:260] Setting up relu6/sep
I0510 14:48:30.148852  5307 net.cpp:267] TRAIN Top shape for layer 111 'relu6/sep' 16 512 8 16 (1048576)
I0510 14:48:30.148861  5307 layer_factory.hpp:172] Creating layer 'conv6/sep_relu6/sep_0_split' of type 'Split'
I0510 14:48:30.148867  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.148877  5307 net.cpp:200] Created Layer conv6/sep_relu6/sep_0_split (112)
I0510 14:48:30.148890  5307 net.cpp:572] conv6/sep_relu6/sep_0_split <- conv6/sep
I0510 14:48:30.148902  5307 net.cpp:542] conv6/sep_relu6/sep_0_split -> conv6/sep_relu6/sep_0_split_0
I0510 14:48:30.148916  5307 net.cpp:542] conv6/sep_relu6/sep_0_split -> conv6/sep_relu6/sep_0_split_1
I0510 14:48:30.148953  5307 net.cpp:260] Setting up conv6/sep_relu6/sep_0_split
I0510 14:48:30.148969  5307 net.cpp:267] TRAIN Top shape for layer 112 'conv6/sep_relu6/sep_0_split' 16 512 8 16 (1048576)
I0510 14:48:30.148983  5307 net.cpp:267] TRAIN Top shape for layer 112 'conv6/sep_relu6/sep_0_split' 16 512 8 16 (1048576)
I0510 14:48:30.148994  5307 layer_factory.hpp:172] Creating layer 'pool6' of type 'Pooling'
I0510 14:48:30.149006  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.149024  5307 net.cpp:200] Created Layer pool6 (113)
I0510 14:48:30.149036  5307 net.cpp:572] pool6 <- conv6/sep_relu6/sep_0_split_0
I0510 14:48:30.149049  5307 net.cpp:542] pool6 -> pool6
I0510 14:48:30.149118  5307 net.cpp:260] Setting up pool6
I0510 14:48:30.149134  5307 net.cpp:267] TRAIN Top shape for layer 113 'pool6' 16 512 5 9 (368640)
I0510 14:48:30.149150  5307 layer_factory.hpp:172] Creating layer 'pool6_pool6_0_split' of type 'Split'
I0510 14:48:30.149171  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.149184  5307 net.cpp:200] Created Layer pool6_pool6_0_split (114)
I0510 14:48:30.149196  5307 net.cpp:572] pool6_pool6_0_split <- pool6
I0510 14:48:30.149209  5307 net.cpp:542] pool6_pool6_0_split -> pool6_pool6_0_split_0
I0510 14:48:30.149220  5307 net.cpp:542] pool6_pool6_0_split -> pool6_pool6_0_split_1
I0510 14:48:30.149258  5307 net.cpp:260] Setting up pool6_pool6_0_split
I0510 14:48:30.149273  5307 net.cpp:267] TRAIN Top shape for layer 114 'pool6_pool6_0_split' 16 512 5 9 (368640)
I0510 14:48:30.149286  5307 net.cpp:267] TRAIN Top shape for layer 114 'pool6_pool6_0_split' 16 512 5 9 (368640)
I0510 14:48:30.149297  5307 layer_factory.hpp:172] Creating layer 'pool7' of type 'Pooling'
I0510 14:48:30.149302  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.149309  5307 net.cpp:200] Created Layer pool7 (115)
I0510 14:48:30.149318  5307 net.cpp:572] pool7 <- pool6_pool6_0_split_0
I0510 14:48:30.149324  5307 net.cpp:542] pool7 -> pool7
I0510 14:48:30.149363  5307 net.cpp:260] Setting up pool7
I0510 14:48:30.149369  5307 net.cpp:267] TRAIN Top shape for layer 115 'pool7' 16 512 3 5 (122880)
I0510 14:48:30.149379  5307 layer_factory.hpp:172] Creating layer 'pool7_pool7_0_split' of type 'Split'
I0510 14:48:30.149384  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.149394  5307 net.cpp:200] Created Layer pool7_pool7_0_split (116)
I0510 14:48:30.149399  5307 net.cpp:572] pool7_pool7_0_split <- pool7
I0510 14:48:30.149408  5307 net.cpp:542] pool7_pool7_0_split -> pool7_pool7_0_split_0
I0510 14:48:30.149418  5307 net.cpp:542] pool7_pool7_0_split -> pool7_pool7_0_split_1
I0510 14:48:30.149449  5307 net.cpp:260] Setting up pool7_pool7_0_split
I0510 14:48:30.149456  5307 net.cpp:267] TRAIN Top shape for layer 116 'pool7_pool7_0_split' 16 512 3 5 (122880)
I0510 14:48:30.149466  5307 net.cpp:267] TRAIN Top shape for layer 116 'pool7_pool7_0_split' 16 512 3 5 (122880)
I0510 14:48:30.149471  5307 layer_factory.hpp:172] Creating layer 'pool8' of type 'Pooling'
I0510 14:48:30.149479  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.149487  5307 net.cpp:200] Created Layer pool8 (117)
I0510 14:48:30.149495  5307 net.cpp:572] pool8 <- pool7_pool7_0_split_0
I0510 14:48:30.149500  5307 net.cpp:542] pool8 -> pool8
I0510 14:48:30.149540  5307 net.cpp:260] Setting up pool8
I0510 14:48:30.149546  5307 net.cpp:267] TRAIN Top shape for layer 117 'pool8' 16 512 3 5 (122880)
I0510 14:48:30.149556  5307 layer_factory.hpp:172] Creating layer 'ctx_output1/1x1' of type 'Convolution'
I0510 14:48:30.149562  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.149576  5307 net.cpp:200] Created Layer ctx_output1/1x1 (118)
I0510 14:48:30.149581  5307 net.cpp:572] ctx_output1/1x1 <- conv5_5/sep_relu5_5/sep_0_split_1
I0510 14:48:30.149591  5307 net.cpp:542] ctx_output1/1x1 -> ctx_output1/1x1
I0510 14:48:30.153045  5307 net.cpp:260] Setting up ctx_output1/1x1
I0510 14:48:30.153059  5307 net.cpp:267] TRAIN Top shape for layer 118 'ctx_output1/1x1' 16 512 16 32 (4194304)
I0510 14:48:30.153066  5307 layer_factory.hpp:172] Creating layer 'ctx_output1/1x1/bn' of type 'BatchNorm'
I0510 14:48:30.153079  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.153091  5307 net.cpp:200] Created Layer ctx_output1/1x1/bn (119)
I0510 14:48:30.153097  5307 net.cpp:572] ctx_output1/1x1/bn <- ctx_output1/1x1
I0510 14:48:30.153102  5307 net.cpp:527] ctx_output1/1x1/bn -> ctx_output1/1x1 (in-place)
I0510 14:48:30.153360  5307 net.cpp:260] Setting up ctx_output1/1x1/bn
I0510 14:48:30.153368  5307 net.cpp:267] TRAIN Top shape for layer 119 'ctx_output1/1x1/bn' 16 512 16 32 (4194304)
I0510 14:48:30.153378  5307 layer_factory.hpp:172] Creating layer 'ctx_output1/1x1/relu' of type 'ReLU'
I0510 14:48:30.153395  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.153403  5307 net.cpp:200] Created Layer ctx_output1/1x1/relu (120)
I0510 14:48:30.153412  5307 net.cpp:572] ctx_output1/1x1/relu <- ctx_output1/1x1
I0510 14:48:30.153419  5307 net.cpp:527] ctx_output1/1x1/relu -> ctx_output1/1x1 (in-place)
I0510 14:48:30.153429  5307 net.cpp:260] Setting up ctx_output1/1x1/relu
I0510 14:48:30.153435  5307 net.cpp:267] TRAIN Top shape for layer 120 'ctx_output1/1x1/relu' 16 512 16 32 (4194304)
I0510 14:48:30.153445  5307 layer_factory.hpp:172] Creating layer 'ctx_output1' of type 'Convolution'
I0510 14:48:30.153450  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.153465  5307 net.cpp:200] Created Layer ctx_output1 (121)
I0510 14:48:30.153470  5307 net.cpp:572] ctx_output1 <- ctx_output1/1x1
I0510 14:48:30.153475  5307 net.cpp:542] ctx_output1 -> ctx_output1
I0510 14:48:30.153739  5307 net.cpp:260] Setting up ctx_output1
I0510 14:48:30.153748  5307 net.cpp:267] TRAIN Top shape for layer 121 'ctx_output1' 16 512 16 32 (4194304)
I0510 14:48:30.153754  5307 layer_factory.hpp:172] Creating layer 'ctx_output1/bn' of type 'BatchNorm'
I0510 14:48:30.153764  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.153772  5307 net.cpp:200] Created Layer ctx_output1/bn (122)
I0510 14:48:30.153781  5307 net.cpp:572] ctx_output1/bn <- ctx_output1
I0510 14:48:30.153787  5307 net.cpp:527] ctx_output1/bn -> ctx_output1 (in-place)
I0510 14:48:30.154044  5307 net.cpp:260] Setting up ctx_output1/bn
I0510 14:48:30.154052  5307 net.cpp:267] TRAIN Top shape for layer 122 'ctx_output1/bn' 16 512 16 32 (4194304)
I0510 14:48:30.154067  5307 layer_factory.hpp:172] Creating layer 'ctx_output1/relu' of type 'ReLU'
I0510 14:48:30.154073  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.154079  5307 net.cpp:200] Created Layer ctx_output1/relu (123)
I0510 14:48:30.154088  5307 net.cpp:572] ctx_output1/relu <- ctx_output1
I0510 14:48:30.154095  5307 net.cpp:527] ctx_output1/relu -> ctx_output1 (in-place)
I0510 14:48:30.154106  5307 net.cpp:260] Setting up ctx_output1/relu
I0510 14:48:30.154111  5307 net.cpp:267] TRAIN Top shape for layer 123 'ctx_output1/relu' 16 512 16 32 (4194304)
I0510 14:48:30.154120  5307 layer_factory.hpp:172] Creating layer 'ctx_output1_ctx_output1/relu_0_split' of type 'Split'
I0510 14:48:30.154126  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.154136  5307 net.cpp:200] Created Layer ctx_output1_ctx_output1/relu_0_split (124)
I0510 14:48:30.154141  5307 net.cpp:572] ctx_output1_ctx_output1/relu_0_split <- ctx_output1
I0510 14:48:30.154150  5307 net.cpp:542] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_0
I0510 14:48:30.154157  5307 net.cpp:542] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_1
I0510 14:48:30.154167  5307 net.cpp:542] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_2
I0510 14:48:30.154211  5307 net.cpp:260] Setting up ctx_output1_ctx_output1/relu_0_split
I0510 14:48:30.154217  5307 net.cpp:267] TRAIN Top shape for layer 124 'ctx_output1_ctx_output1/relu_0_split' 16 512 16 32 (4194304)
I0510 14:48:30.154227  5307 net.cpp:267] TRAIN Top shape for layer 124 'ctx_output1_ctx_output1/relu_0_split' 16 512 16 32 (4194304)
I0510 14:48:30.154233  5307 net.cpp:267] TRAIN Top shape for layer 124 'ctx_output1_ctx_output1/relu_0_split' 16 512 16 32 (4194304)
I0510 14:48:30.154242  5307 layer_factory.hpp:172] Creating layer 'ctx_output2/1x1' of type 'Convolution'
I0510 14:48:30.154247  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.154265  5307 net.cpp:200] Created Layer ctx_output2/1x1 (125)
I0510 14:48:30.154275  5307 net.cpp:572] ctx_output2/1x1 <- conv6/sep_relu6/sep_0_split_1
I0510 14:48:30.154285  5307 net.cpp:542] ctx_output2/1x1 -> ctx_output2/1x1
I0510 14:48:30.162034  5307 net.cpp:260] Setting up ctx_output2/1x1
I0510 14:48:30.162204  5307 net.cpp:267] TRAIN Top shape for layer 125 'ctx_output2/1x1' 16 512 8 16 (1048576)
I0510 14:48:30.162295  5307 layer_factory.hpp:172] Creating layer 'ctx_output2/1x1/bn' of type 'BatchNorm'
I0510 14:48:30.162374  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.162456  5307 net.cpp:200] Created Layer ctx_output2/1x1/bn (126)
I0510 14:48:30.162525  5307 net.cpp:572] ctx_output2/1x1/bn <- ctx_output2/1x1
I0510 14:48:30.162591  5307 net.cpp:527] ctx_output2/1x1/bn -> ctx_output2/1x1 (in-place)
I0510 14:48:30.163060  5307 net.cpp:260] Setting up ctx_output2/1x1/bn
I0510 14:48:30.163136  5307 net.cpp:267] TRAIN Top shape for layer 126 'ctx_output2/1x1/bn' 16 512 8 16 (1048576)
I0510 14:48:30.163213  5307 layer_factory.hpp:172] Creating layer 'ctx_output2/1x1/relu' of type 'ReLU'
I0510 14:48:30.163283  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.163358  5307 net.cpp:200] Created Layer ctx_output2/1x1/relu (127)
I0510 14:48:30.163419  5307 net.cpp:572] ctx_output2/1x1/relu <- ctx_output2/1x1
I0510 14:48:30.163480  5307 net.cpp:527] ctx_output2/1x1/relu -> ctx_output2/1x1 (in-place)
I0510 14:48:30.163552  5307 net.cpp:260] Setting up ctx_output2/1x1/relu
I0510 14:48:30.163614  5307 net.cpp:267] TRAIN Top shape for layer 127 'ctx_output2/1x1/relu' 16 512 8 16 (1048576)
I0510 14:48:30.163682  5307 layer_factory.hpp:172] Creating layer 'ctx_output2' of type 'Convolution'
I0510 14:48:30.163758  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.163839  5307 net.cpp:200] Created Layer ctx_output2 (128)
I0510 14:48:30.163899  5307 net.cpp:572] ctx_output2 <- ctx_output2/1x1
I0510 14:48:30.163960  5307 net.cpp:542] ctx_output2 -> ctx_output2
I0510 14:48:30.164412  5307 net.cpp:260] Setting up ctx_output2
I0510 14:48:30.164489  5307 net.cpp:267] TRAIN Top shape for layer 128 'ctx_output2' 16 512 8 16 (1048576)
I0510 14:48:30.164567  5307 layer_factory.hpp:172] Creating layer 'ctx_output2/bn' of type 'BatchNorm'
I0510 14:48:30.164635  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.164711  5307 net.cpp:200] Created Layer ctx_output2/bn (129)
I0510 14:48:30.164772  5307 net.cpp:572] ctx_output2/bn <- ctx_output2
I0510 14:48:30.164831  5307 net.cpp:527] ctx_output2/bn -> ctx_output2 (in-place)
I0510 14:48:30.165230  5307 net.cpp:260] Setting up ctx_output2/bn
I0510 14:48:30.165298  5307 net.cpp:267] TRAIN Top shape for layer 129 'ctx_output2/bn' 16 512 8 16 (1048576)
I0510 14:48:30.165375  5307 layer_factory.hpp:172] Creating layer 'ctx_output2/relu' of type 'ReLU'
I0510 14:48:30.165443  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.165515  5307 net.cpp:200] Created Layer ctx_output2/relu (130)
I0510 14:48:30.165576  5307 net.cpp:572] ctx_output2/relu <- ctx_output2
I0510 14:48:30.165642  5307 net.cpp:527] ctx_output2/relu -> ctx_output2 (in-place)
I0510 14:48:30.165704  5307 net.cpp:260] Setting up ctx_output2/relu
I0510 14:48:30.165763  5307 net.cpp:267] TRAIN Top shape for layer 130 'ctx_output2/relu' 16 512 8 16 (1048576)
I0510 14:48:30.165832  5307 layer_factory.hpp:172] Creating layer 'ctx_output2_ctx_output2/relu_0_split' of type 'Split'
I0510 14:48:30.165905  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.165974  5307 net.cpp:200] Created Layer ctx_output2_ctx_output2/relu_0_split (131)
I0510 14:48:30.166040  5307 net.cpp:572] ctx_output2_ctx_output2/relu_0_split <- ctx_output2
I0510 14:48:30.166112  5307 net.cpp:542] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_0
I0510 14:48:30.166188  5307 net.cpp:542] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_1
I0510 14:48:30.166267  5307 net.cpp:542] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_2
I0510 14:48:30.166391  5307 net.cpp:260] Setting up ctx_output2_ctx_output2/relu_0_split
I0510 14:48:30.166460  5307 net.cpp:267] TRAIN Top shape for layer 131 'ctx_output2_ctx_output2/relu_0_split' 16 512 8 16 (1048576)
I0510 14:48:30.166540  5307 net.cpp:267] TRAIN Top shape for layer 131 'ctx_output2_ctx_output2/relu_0_split' 16 512 8 16 (1048576)
I0510 14:48:30.166615  5307 net.cpp:267] TRAIN Top shape for layer 131 'ctx_output2_ctx_output2/relu_0_split' 16 512 8 16 (1048576)
I0510 14:48:30.166692  5307 layer_factory.hpp:172] Creating layer 'ctx_output3/1x1' of type 'Convolution'
I0510 14:48:30.166769  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.166844  5307 net.cpp:200] Created Layer ctx_output3/1x1 (132)
I0510 14:48:30.166905  5307 net.cpp:572] ctx_output3/1x1 <- pool6_pool6_0_split_1
I0510 14:48:30.166970  5307 net.cpp:542] ctx_output3/1x1 -> ctx_output3/1x1
I0510 14:48:30.175863  5307 net.cpp:260] Setting up ctx_output3/1x1
I0510 14:48:30.175884  5307 net.cpp:267] TRAIN Top shape for layer 132 'ctx_output3/1x1' 16 512 5 9 (368640)
I0510 14:48:30.175894  5307 layer_factory.hpp:172] Creating layer 'ctx_output3/1x1/bn' of type 'BatchNorm'
I0510 14:48:30.175899  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.175916  5307 net.cpp:200] Created Layer ctx_output3/1x1/bn (133)
I0510 14:48:30.176038  5307 net.cpp:572] ctx_output3/1x1/bn <- ctx_output3/1x1
I0510 14:48:30.176079  5307 net.cpp:527] ctx_output3/1x1/bn -> ctx_output3/1x1 (in-place)
I0510 14:48:30.176417  5307 net.cpp:260] Setting up ctx_output3/1x1/bn
I0510 14:48:30.176426  5307 net.cpp:267] TRAIN Top shape for layer 133 'ctx_output3/1x1/bn' 16 512 5 9 (368640)
I0510 14:48:30.176435  5307 layer_factory.hpp:172] Creating layer 'ctx_output3/1x1/relu' of type 'ReLU'
I0510 14:48:30.176491  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.176533  5307 net.cpp:200] Created Layer ctx_output3/1x1/relu (134)
I0510 14:48:30.176587  5307 net.cpp:572] ctx_output3/1x1/relu <- ctx_output3/1x1
I0510 14:48:30.176594  5307 net.cpp:527] ctx_output3/1x1/relu -> ctx_output3/1x1 (in-place)
I0510 14:48:30.176601  5307 net.cpp:260] Setting up ctx_output3/1x1/relu
I0510 14:48:30.176676  5307 net.cpp:267] TRAIN Top shape for layer 134 'ctx_output3/1x1/relu' 16 512 5 9 (368640)
I0510 14:48:30.176682  5307 layer_factory.hpp:172] Creating layer 'ctx_output3' of type 'Convolution'
I0510 14:48:30.176738  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.176784  5307 net.cpp:200] Created Layer ctx_output3 (135)
I0510 14:48:30.176790  5307 net.cpp:572] ctx_output3 <- ctx_output3/1x1
I0510 14:48:30.176795  5307 net.cpp:542] ctx_output3 -> ctx_output3
I0510 14:48:30.177225  5307 net.cpp:260] Setting up ctx_output3
I0510 14:48:30.177243  5307 net.cpp:267] TRAIN Top shape for layer 135 'ctx_output3' 16 512 5 9 (368640)
I0510 14:48:30.177256  5307 layer_factory.hpp:172] Creating layer 'ctx_output3/bn' of type 'BatchNorm'
I0510 14:48:30.177265  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.177276  5307 net.cpp:200] Created Layer ctx_output3/bn (136)
I0510 14:48:30.177286  5307 net.cpp:572] ctx_output3/bn <- ctx_output3
I0510 14:48:30.177296  5307 net.cpp:527] ctx_output3/bn -> ctx_output3 (in-place)
I0510 14:48:30.177644  5307 net.cpp:260] Setting up ctx_output3/bn
I0510 14:48:30.177659  5307 net.cpp:267] TRAIN Top shape for layer 136 'ctx_output3/bn' 16 512 5 9 (368640)
I0510 14:48:30.177676  5307 layer_factory.hpp:172] Creating layer 'ctx_output3/relu' of type 'ReLU'
I0510 14:48:30.177685  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.177903  5307 net.cpp:200] Created Layer ctx_output3/relu (137)
I0510 14:48:30.177911  5307 net.cpp:572] ctx_output3/relu <- ctx_output3
I0510 14:48:30.177914  5307 net.cpp:527] ctx_output3/relu -> ctx_output3 (in-place)
I0510 14:48:30.177976  5307 net.cpp:260] Setting up ctx_output3/relu
I0510 14:48:30.177984  5307 net.cpp:267] TRAIN Top shape for layer 137 'ctx_output3/relu' 16 512 5 9 (368640)
I0510 14:48:30.178035  5307 layer_factory.hpp:172] Creating layer 'ctx_output3_ctx_output3/relu_0_split' of type 'Split'
I0510 14:48:30.178041  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.178047  5307 net.cpp:200] Created Layer ctx_output3_ctx_output3/relu_0_split (138)
I0510 14:48:30.178133  5307 net.cpp:572] ctx_output3_ctx_output3/relu_0_split <- ctx_output3
I0510 14:48:30.178143  5307 net.cpp:542] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_0
I0510 14:48:30.178200  5307 net.cpp:542] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_1
I0510 14:48:30.178207  5307 net.cpp:542] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_2
I0510 14:48:30.178302  5307 net.cpp:260] Setting up ctx_output3_ctx_output3/relu_0_split
I0510 14:48:30.178309  5307 net.cpp:267] TRAIN Top shape for layer 138 'ctx_output3_ctx_output3/relu_0_split' 16 512 5 9 (368640)
I0510 14:48:30.178367  5307 net.cpp:267] TRAIN Top shape for layer 138 'ctx_output3_ctx_output3/relu_0_split' 16 512 5 9 (368640)
I0510 14:48:30.178375  5307 net.cpp:267] TRAIN Top shape for layer 138 'ctx_output3_ctx_output3/relu_0_split' 16 512 5 9 (368640)
I0510 14:48:30.178445  5307 layer_factory.hpp:172] Creating layer 'ctx_output4/1x1' of type 'Convolution'
I0510 14:48:30.178452  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.178521  5307 net.cpp:200] Created Layer ctx_output4/1x1 (139)
I0510 14:48:30.178527  5307 net.cpp:572] ctx_output4/1x1 <- pool7_pool7_0_split_1
I0510 14:48:30.178581  5307 net.cpp:542] ctx_output4/1x1 -> ctx_output4/1x1
I0510 14:48:30.183876  5307 net.cpp:260] Setting up ctx_output4/1x1
I0510 14:48:30.183899  5307 net.cpp:267] TRAIN Top shape for layer 139 'ctx_output4/1x1' 16 512 3 5 (122880)
I0510 14:48:30.183907  5307 layer_factory.hpp:172] Creating layer 'ctx_output4/1x1/bn' of type 'BatchNorm'
I0510 14:48:30.183912  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.184043  5307 net.cpp:200] Created Layer ctx_output4/1x1/bn (140)
I0510 14:48:30.184052  5307 net.cpp:572] ctx_output4/1x1/bn <- ctx_output4/1x1
I0510 14:48:30.184064  5307 net.cpp:527] ctx_output4/1x1/bn -> ctx_output4/1x1 (in-place)
I0510 14:48:30.184386  5307 net.cpp:260] Setting up ctx_output4/1x1/bn
I0510 14:48:30.184393  5307 net.cpp:267] TRAIN Top shape for layer 140 'ctx_output4/1x1/bn' 16 512 3 5 (122880)
I0510 14:48:30.184403  5307 layer_factory.hpp:172] Creating layer 'ctx_output4/1x1/relu' of type 'ReLU'
I0510 14:48:30.184415  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.184427  5307 net.cpp:200] Created Layer ctx_output4/1x1/relu (141)
I0510 14:48:30.184437  5307 net.cpp:572] ctx_output4/1x1/relu <- ctx_output4/1x1
I0510 14:48:30.184448  5307 net.cpp:527] ctx_output4/1x1/relu -> ctx_output4/1x1 (in-place)
I0510 14:48:30.184461  5307 net.cpp:260] Setting up ctx_output4/1x1/relu
I0510 14:48:30.184473  5307 net.cpp:267] TRAIN Top shape for layer 141 'ctx_output4/1x1/relu' 16 512 3 5 (122880)
I0510 14:48:30.184482  5307 layer_factory.hpp:172] Creating layer 'ctx_output4' of type 'Convolution'
I0510 14:48:30.184491  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.184509  5307 net.cpp:200] Created Layer ctx_output4 (142)
I0510 14:48:30.184520  5307 net.cpp:572] ctx_output4 <- ctx_output4/1x1
I0510 14:48:30.184541  5307 net.cpp:542] ctx_output4 -> ctx_output4
I0510 14:48:30.184945  5307 net.cpp:260] Setting up ctx_output4
I0510 14:48:30.184970  5307 net.cpp:267] TRAIN Top shape for layer 142 'ctx_output4' 16 512 3 5 (122880)
I0510 14:48:30.184983  5307 layer_factory.hpp:172] Creating layer 'ctx_output4/bn' of type 'BatchNorm'
I0510 14:48:30.184994  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.185008  5307 net.cpp:200] Created Layer ctx_output4/bn (143)
I0510 14:48:30.185017  5307 net.cpp:572] ctx_output4/bn <- ctx_output4
I0510 14:48:30.185027  5307 net.cpp:527] ctx_output4/bn -> ctx_output4 (in-place)
I0510 14:48:30.185374  5307 net.cpp:260] Setting up ctx_output4/bn
I0510 14:48:30.185382  5307 net.cpp:267] TRAIN Top shape for layer 143 'ctx_output4/bn' 16 512 3 5 (122880)
I0510 14:48:30.185391  5307 layer_factory.hpp:172] Creating layer 'ctx_output4/relu' of type 'ReLU'
I0510 14:48:30.185402  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.185415  5307 net.cpp:200] Created Layer ctx_output4/relu (144)
I0510 14:48:30.185425  5307 net.cpp:572] ctx_output4/relu <- ctx_output4
I0510 14:48:30.185436  5307 net.cpp:527] ctx_output4/relu -> ctx_output4 (in-place)
I0510 14:48:30.185448  5307 net.cpp:260] Setting up ctx_output4/relu
I0510 14:48:30.185459  5307 net.cpp:267] TRAIN Top shape for layer 144 'ctx_output4/relu' 16 512 3 5 (122880)
I0510 14:48:30.185469  5307 layer_factory.hpp:172] Creating layer 'ctx_output4_ctx_output4/relu_0_split' of type 'Split'
I0510 14:48:30.185479  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.185492  5307 net.cpp:200] Created Layer ctx_output4_ctx_output4/relu_0_split (145)
I0510 14:48:30.185501  5307 net.cpp:572] ctx_output4_ctx_output4/relu_0_split <- ctx_output4
I0510 14:48:30.185513  5307 net.cpp:542] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_0
I0510 14:48:30.185525  5307 net.cpp:542] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_1
I0510 14:48:30.185537  5307 net.cpp:542] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_2
I0510 14:48:30.185593  5307 net.cpp:260] Setting up ctx_output4_ctx_output4/relu_0_split
I0510 14:48:30.185607  5307 net.cpp:267] TRAIN Top shape for layer 145 'ctx_output4_ctx_output4/relu_0_split' 16 512 3 5 (122880)
I0510 14:48:30.185619  5307 net.cpp:267] TRAIN Top shape for layer 145 'ctx_output4_ctx_output4/relu_0_split' 16 512 3 5 (122880)
I0510 14:48:30.185631  5307 net.cpp:267] TRAIN Top shape for layer 145 'ctx_output4_ctx_output4/relu_0_split' 16 512 3 5 (122880)
I0510 14:48:30.185640  5307 layer_factory.hpp:172] Creating layer 'ctx_output5/1x1' of type 'Convolution'
I0510 14:48:30.185650  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.185667  5307 net.cpp:200] Created Layer ctx_output5/1x1 (146)
I0510 14:48:30.185678  5307 net.cpp:572] ctx_output5/1x1 <- pool8
I0510 14:48:30.185688  5307 net.cpp:542] ctx_output5/1x1 -> ctx_output5/1x1
I0510 14:48:30.194860  5307 net.cpp:260] Setting up ctx_output5/1x1
I0510 14:48:30.194931  5307 net.cpp:267] TRAIN Top shape for layer 146 'ctx_output5/1x1' 16 512 3 5 (122880)
I0510 14:48:30.194957  5307 layer_factory.hpp:172] Creating layer 'ctx_output5/1x1/bn' of type 'BatchNorm'
I0510 14:48:30.194974  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.194999  5307 net.cpp:200] Created Layer ctx_output5/1x1/bn (147)
I0510 14:48:30.195019  5307 net.cpp:572] ctx_output5/1x1/bn <- ctx_output5/1x1
I0510 14:48:30.195035  5307 net.cpp:527] ctx_output5/1x1/bn -> ctx_output5/1x1 (in-place)
I0510 14:48:30.195438  5307 net.cpp:260] Setting up ctx_output5/1x1/bn
I0510 14:48:30.195466  5307 net.cpp:267] TRAIN Top shape for layer 147 'ctx_output5/1x1/bn' 16 512 3 5 (122880)
I0510 14:48:30.195488  5307 layer_factory.hpp:172] Creating layer 'ctx_output5/1x1/relu' of type 'ReLU'
I0510 14:48:30.195513  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.195540  5307 net.cpp:200] Created Layer ctx_output5/1x1/relu (148)
I0510 14:48:30.195557  5307 net.cpp:572] ctx_output5/1x1/relu <- ctx_output5/1x1
I0510 14:48:30.195574  5307 net.cpp:527] ctx_output5/1x1/relu -> ctx_output5/1x1 (in-place)
I0510 14:48:30.195593  5307 net.cpp:260] Setting up ctx_output5/1x1/relu
I0510 14:48:30.195610  5307 net.cpp:267] TRAIN Top shape for layer 148 'ctx_output5/1x1/relu' 16 512 3 5 (122880)
I0510 14:48:30.195626  5307 layer_factory.hpp:172] Creating layer 'ctx_output5' of type 'Convolution'
I0510 14:48:30.195641  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.195664  5307 net.cpp:200] Created Layer ctx_output5 (149)
I0510 14:48:30.195683  5307 net.cpp:572] ctx_output5 <- ctx_output5/1x1
I0510 14:48:30.195698  5307 net.cpp:542] ctx_output5 -> ctx_output5
I0510 14:48:30.196110  5307 net.cpp:260] Setting up ctx_output5
I0510 14:48:30.196135  5307 net.cpp:267] TRAIN Top shape for layer 149 'ctx_output5' 16 512 3 5 (122880)
I0510 14:48:30.196156  5307 layer_factory.hpp:172] Creating layer 'ctx_output5/bn' of type 'BatchNorm'
I0510 14:48:30.196174  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.196193  5307 net.cpp:200] Created Layer ctx_output5/bn (150)
I0510 14:48:30.196210  5307 net.cpp:572] ctx_output5/bn <- ctx_output5
I0510 14:48:30.196226  5307 net.cpp:527] ctx_output5/bn -> ctx_output5 (in-place)
I0510 14:48:30.196609  5307 net.cpp:260] Setting up ctx_output5/bn
I0510 14:48:30.196635  5307 net.cpp:267] TRAIN Top shape for layer 150 'ctx_output5/bn' 16 512 3 5 (122880)
I0510 14:48:30.196662  5307 layer_factory.hpp:172] Creating layer 'ctx_output5/relu' of type 'ReLU'
I0510 14:48:30.196681  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.196698  5307 net.cpp:200] Created Layer ctx_output5/relu (151)
I0510 14:48:30.196717  5307 net.cpp:572] ctx_output5/relu <- ctx_output5
I0510 14:48:30.196732  5307 net.cpp:527] ctx_output5/relu -> ctx_output5 (in-place)
I0510 14:48:30.196750  5307 net.cpp:260] Setting up ctx_output5/relu
I0510 14:48:30.196768  5307 net.cpp:267] TRAIN Top shape for layer 151 'ctx_output5/relu' 16 512 3 5 (122880)
I0510 14:48:30.196784  5307 layer_factory.hpp:172] Creating layer 'ctx_output5_ctx_output5/relu_0_split' of type 'Split'
I0510 14:48:30.196800  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.196818  5307 net.cpp:200] Created Layer ctx_output5_ctx_output5/relu_0_split (152)
I0510 14:48:30.196833  5307 net.cpp:572] ctx_output5_ctx_output5/relu_0_split <- ctx_output5
I0510 14:48:30.196849  5307 net.cpp:542] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_0
I0510 14:48:30.196867  5307 net.cpp:542] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_1
I0510 14:48:30.196887  5307 net.cpp:542] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_2
I0510 14:48:30.196943  5307 net.cpp:260] Setting up ctx_output5_ctx_output5/relu_0_split
I0510 14:48:30.196961  5307 net.cpp:267] TRAIN Top shape for layer 152 'ctx_output5_ctx_output5/relu_0_split' 16 512 3 5 (122880)
I0510 14:48:30.196979  5307 net.cpp:267] TRAIN Top shape for layer 152 'ctx_output5_ctx_output5/relu_0_split' 16 512 3 5 (122880)
I0510 14:48:30.196995  5307 net.cpp:267] TRAIN Top shape for layer 152 'ctx_output5_ctx_output5/relu_0_split' 16 512 3 5 (122880)
I0510 14:48:30.197012  5307 layer_factory.hpp:172] Creating layer 'ctx_output1/relu_mbox_loc' of type 'Convolution'
I0510 14:48:30.197028  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.197051  5307 net.cpp:200] Created Layer ctx_output1/relu_mbox_loc (153)
I0510 14:48:30.197068  5307 net.cpp:572] ctx_output1/relu_mbox_loc <- ctx_output1_ctx_output1/relu_0_split_0
I0510 14:48:30.197089  5307 net.cpp:542] ctx_output1/relu_mbox_loc -> ctx_output1/relu_mbox_loc
I0510 14:48:30.197599  5307 net.cpp:260] Setting up ctx_output1/relu_mbox_loc
I0510 14:48:30.197623  5307 net.cpp:267] TRAIN Top shape for layer 153 'ctx_output1/relu_mbox_loc' 16 16 16 32 (131072)
I0510 14:48:30.197641  5307 layer_factory.hpp:172] Creating layer 'ctx_output1/relu_mbox_loc_perm' of type 'Permute'
I0510 14:48:30.197657  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.197681  5307 net.cpp:200] Created Layer ctx_output1/relu_mbox_loc_perm (154)
I0510 14:48:30.197700  5307 net.cpp:572] ctx_output1/relu_mbox_loc_perm <- ctx_output1/relu_mbox_loc
I0510 14:48:30.197717  5307 net.cpp:542] ctx_output1/relu_mbox_loc_perm -> ctx_output1/relu_mbox_loc_perm
I0510 14:48:30.197830  5307 net.cpp:260] Setting up ctx_output1/relu_mbox_loc_perm
I0510 14:48:30.197850  5307 net.cpp:267] TRAIN Top shape for layer 154 'ctx_output1/relu_mbox_loc_perm' 16 16 32 16 (131072)
I0510 14:48:30.197866  5307 layer_factory.hpp:172] Creating layer 'ctx_output1/relu_mbox_loc_flat' of type 'Flatten'
I0510 14:48:30.197883  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.197902  5307 net.cpp:200] Created Layer ctx_output1/relu_mbox_loc_flat (155)
I0510 14:48:30.197918  5307 net.cpp:572] ctx_output1/relu_mbox_loc_flat <- ctx_output1/relu_mbox_loc_perm
I0510 14:48:30.197934  5307 net.cpp:542] ctx_output1/relu_mbox_loc_flat -> ctx_output1/relu_mbox_loc_flat
I0510 14:48:30.198081  5307 net.cpp:260] Setting up ctx_output1/relu_mbox_loc_flat
I0510 14:48:30.198103  5307 net.cpp:267] TRAIN Top shape for layer 155 'ctx_output1/relu_mbox_loc_flat' 16 8192 (131072)
I0510 14:48:30.198122  5307 layer_factory.hpp:172] Creating layer 'ctx_output1/relu_mbox_conf' of type 'Convolution'
I0510 14:48:30.198138  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.198158  5307 net.cpp:200] Created Layer ctx_output1/relu_mbox_conf (156)
I0510 14:48:30.198174  5307 net.cpp:572] ctx_output1/relu_mbox_conf <- ctx_output1_ctx_output1/relu_0_split_1
I0510 14:48:30.198191  5307 net.cpp:542] ctx_output1/relu_mbox_conf -> ctx_output1/relu_mbox_conf
I0510 14:48:30.199424  5307 net.cpp:260] Setting up ctx_output1/relu_mbox_conf
I0510 14:48:30.199432  5307 net.cpp:267] TRAIN Top shape for layer 156 'ctx_output1/relu_mbox_conf' 16 84 16 32 (688128)
I0510 14:48:30.199439  5307 layer_factory.hpp:172] Creating layer 'ctx_output1/relu_mbox_conf_perm' of type 'Permute'
I0510 14:48:30.199455  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.199476  5307 net.cpp:200] Created Layer ctx_output1/relu_mbox_conf_perm (157)
I0510 14:48:30.199491  5307 net.cpp:572] ctx_output1/relu_mbox_conf_perm <- ctx_output1/relu_mbox_conf
I0510 14:48:30.199507  5307 net.cpp:542] ctx_output1/relu_mbox_conf_perm -> ctx_output1/relu_mbox_conf_perm
I0510 14:48:30.199615  5307 net.cpp:260] Setting up ctx_output1/relu_mbox_conf_perm
I0510 14:48:30.199636  5307 net.cpp:267] TRAIN Top shape for layer 157 'ctx_output1/relu_mbox_conf_perm' 16 16 32 84 (688128)
I0510 14:48:30.199651  5307 layer_factory.hpp:172] Creating layer 'ctx_output1/relu_mbox_conf_flat' of type 'Flatten'
I0510 14:48:30.199667  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.199683  5307 net.cpp:200] Created Layer ctx_output1/relu_mbox_conf_flat (158)
I0510 14:48:30.199700  5307 net.cpp:572] ctx_output1/relu_mbox_conf_flat <- ctx_output1/relu_mbox_conf_perm
I0510 14:48:30.199718  5307 net.cpp:542] ctx_output1/relu_mbox_conf_flat -> ctx_output1/relu_mbox_conf_flat
I0510 14:48:30.202023  5307 net.cpp:260] Setting up ctx_output1/relu_mbox_conf_flat
I0510 14:48:30.202046  5307 net.cpp:267] TRAIN Top shape for layer 158 'ctx_output1/relu_mbox_conf_flat' 16 43008 (688128)
I0510 14:48:30.202054  5307 layer_factory.hpp:172] Creating layer 'ctx_output1/relu_mbox_priorbox' of type 'PriorBox'
I0510 14:48:30.202088  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.202116  5307 net.cpp:200] Created Layer ctx_output1/relu_mbox_priorbox (159)
I0510 14:48:30.202134  5307 net.cpp:572] ctx_output1/relu_mbox_priorbox <- ctx_output1_ctx_output1/relu_0_split_2
I0510 14:48:30.202153  5307 net.cpp:572] ctx_output1/relu_mbox_priorbox <- data_data_0_split_1
I0510 14:48:30.202172  5307 net.cpp:542] ctx_output1/relu_mbox_priorbox -> ctx_output1/relu_mbox_priorbox
I0510 14:48:30.202232  5307 net.cpp:260] Setting up ctx_output1/relu_mbox_priorbox
I0510 14:48:30.202253  5307 net.cpp:267] TRAIN Top shape for layer 159 'ctx_output1/relu_mbox_priorbox' 1 2 8192 (16384)
I0510 14:48:30.202270  5307 layer_factory.hpp:172] Creating layer 'ctx_output2/relu_mbox_loc' of type 'Convolution'
I0510 14:48:30.202286  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.202309  5307 net.cpp:200] Created Layer ctx_output2/relu_mbox_loc (160)
I0510 14:48:30.202325  5307 net.cpp:572] ctx_output2/relu_mbox_loc <- ctx_output2_ctx_output2/relu_0_split_0
I0510 14:48:30.202342  5307 net.cpp:542] ctx_output2/relu_mbox_loc -> ctx_output2/relu_mbox_loc
I0510 14:48:30.202988  5307 net.cpp:260] Setting up ctx_output2/relu_mbox_loc
I0510 14:48:30.203012  5307 net.cpp:267] TRAIN Top shape for layer 160 'ctx_output2/relu_mbox_loc' 16 24 8 16 (49152)
I0510 14:48:30.203033  5307 layer_factory.hpp:172] Creating layer 'ctx_output2/relu_mbox_loc_perm' of type 'Permute'
I0510 14:48:30.203050  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.203073  5307 net.cpp:200] Created Layer ctx_output2/relu_mbox_loc_perm (161)
I0510 14:48:30.203092  5307 net.cpp:572] ctx_output2/relu_mbox_loc_perm <- ctx_output2/relu_mbox_loc
I0510 14:48:30.203110  5307 net.cpp:542] ctx_output2/relu_mbox_loc_perm -> ctx_output2/relu_mbox_loc_perm
I0510 14:48:30.203215  5307 net.cpp:260] Setting up ctx_output2/relu_mbox_loc_perm
I0510 14:48:30.203235  5307 net.cpp:267] TRAIN Top shape for layer 161 'ctx_output2/relu_mbox_loc_perm' 16 8 16 24 (49152)
I0510 14:48:30.203253  5307 layer_factory.hpp:172] Creating layer 'ctx_output2/relu_mbox_loc_flat' of type 'Flatten'
I0510 14:48:30.203269  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.203286  5307 net.cpp:200] Created Layer ctx_output2/relu_mbox_loc_flat (162)
I0510 14:48:30.203301  5307 net.cpp:572] ctx_output2/relu_mbox_loc_flat <- ctx_output2/relu_mbox_loc_perm
I0510 14:48:30.203318  5307 net.cpp:542] ctx_output2/relu_mbox_loc_flat -> ctx_output2/relu_mbox_loc_flat
I0510 14:48:30.203414  5307 net.cpp:260] Setting up ctx_output2/relu_mbox_loc_flat
I0510 14:48:30.203434  5307 net.cpp:267] TRAIN Top shape for layer 162 'ctx_output2/relu_mbox_loc_flat' 16 3072 (49152)
I0510 14:48:30.203452  5307 layer_factory.hpp:172] Creating layer 'ctx_output2/relu_mbox_conf' of type 'Convolution'
I0510 14:48:30.203469  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.203488  5307 net.cpp:200] Created Layer ctx_output2/relu_mbox_conf (163)
I0510 14:48:30.203505  5307 net.cpp:572] ctx_output2/relu_mbox_conf <- ctx_output2_ctx_output2/relu_0_split_1
I0510 14:48:30.203522  5307 net.cpp:542] ctx_output2/relu_mbox_conf -> ctx_output2/relu_mbox_conf
I0510 14:48:30.205476  5307 net.cpp:260] Setting up ctx_output2/relu_mbox_conf
I0510 14:48:30.205487  5307 net.cpp:267] TRAIN Top shape for layer 163 'ctx_output2/relu_mbox_conf' 16 126 8 16 (258048)
I0510 14:48:30.205520  5307 layer_factory.hpp:172] Creating layer 'ctx_output2/relu_mbox_conf_perm' of type 'Permute'
I0510 14:48:30.205536  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.205556  5307 net.cpp:200] Created Layer ctx_output2/relu_mbox_conf_perm (164)
I0510 14:48:30.205574  5307 net.cpp:572] ctx_output2/relu_mbox_conf_perm <- ctx_output2/relu_mbox_conf
I0510 14:48:30.205595  5307 net.cpp:542] ctx_output2/relu_mbox_conf_perm -> ctx_output2/relu_mbox_conf_perm
I0510 14:48:30.205690  5307 net.cpp:260] Setting up ctx_output2/relu_mbox_conf_perm
I0510 14:48:30.205698  5307 net.cpp:267] TRAIN Top shape for layer 164 'ctx_output2/relu_mbox_conf_perm' 16 8 16 126 (258048)
I0510 14:48:30.205719  5307 layer_factory.hpp:172] Creating layer 'ctx_output2/relu_mbox_conf_flat' of type 'Flatten'
I0510 14:48:30.205734  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.205750  5307 net.cpp:200] Created Layer ctx_output2/relu_mbox_conf_flat (165)
I0510 14:48:30.205765  5307 net.cpp:572] ctx_output2/relu_mbox_conf_flat <- ctx_output2/relu_mbox_conf_perm
I0510 14:48:30.205780  5307 net.cpp:542] ctx_output2/relu_mbox_conf_flat -> ctx_output2/relu_mbox_conf_flat
I0510 14:48:30.206703  5307 net.cpp:260] Setting up ctx_output2/relu_mbox_conf_flat
I0510 14:48:30.206729  5307 net.cpp:267] TRAIN Top shape for layer 165 'ctx_output2/relu_mbox_conf_flat' 16 16128 (258048)
I0510 14:48:30.206745  5307 layer_factory.hpp:172] Creating layer 'ctx_output2/relu_mbox_priorbox' of type 'PriorBox'
I0510 14:48:30.206761  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.206779  5307 net.cpp:200] Created Layer ctx_output2/relu_mbox_priorbox (166)
I0510 14:48:30.206794  5307 net.cpp:572] ctx_output2/relu_mbox_priorbox <- ctx_output2_ctx_output2/relu_0_split_2
I0510 14:48:30.206810  5307 net.cpp:572] ctx_output2/relu_mbox_priorbox <- data_data_0_split_2
I0510 14:48:30.206826  5307 net.cpp:542] ctx_output2/relu_mbox_priorbox -> ctx_output2/relu_mbox_priorbox
I0510 14:48:30.206867  5307 net.cpp:260] Setting up ctx_output2/relu_mbox_priorbox
I0510 14:48:30.206888  5307 net.cpp:267] TRAIN Top shape for layer 166 'ctx_output2/relu_mbox_priorbox' 1 2 3072 (6144)
I0510 14:48:30.206904  5307 layer_factory.hpp:172] Creating layer 'ctx_output3/relu_mbox_loc' of type 'Convolution'
I0510 14:48:30.206919  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.206944  5307 net.cpp:200] Created Layer ctx_output3/relu_mbox_loc (167)
I0510 14:48:30.206959  5307 net.cpp:572] ctx_output3/relu_mbox_loc <- ctx_output3_ctx_output3/relu_0_split_0
I0510 14:48:30.206975  5307 net.cpp:542] ctx_output3/relu_mbox_loc -> ctx_output3/relu_mbox_loc
I0510 14:48:30.207593  5307 net.cpp:260] Setting up ctx_output3/relu_mbox_loc
I0510 14:48:30.207613  5307 net.cpp:267] TRAIN Top shape for layer 167 'ctx_output3/relu_mbox_loc' 16 24 5 9 (17280)
I0510 14:48:30.207634  5307 layer_factory.hpp:172] Creating layer 'ctx_output3/relu_mbox_loc_perm' of type 'Permute'
I0510 14:48:30.207653  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.207671  5307 net.cpp:200] Created Layer ctx_output3/relu_mbox_loc_perm (168)
I0510 14:48:30.207690  5307 net.cpp:572] ctx_output3/relu_mbox_loc_perm <- ctx_output3/relu_mbox_loc
I0510 14:48:30.207707  5307 net.cpp:542] ctx_output3/relu_mbox_loc_perm -> ctx_output3/relu_mbox_loc_perm
I0510 14:48:30.207818  5307 net.cpp:260] Setting up ctx_output3/relu_mbox_loc_perm
I0510 14:48:30.207839  5307 net.cpp:267] TRAIN Top shape for layer 168 'ctx_output3/relu_mbox_loc_perm' 16 5 9 24 (17280)
I0510 14:48:30.207854  5307 layer_factory.hpp:172] Creating layer 'ctx_output3/relu_mbox_loc_flat' of type 'Flatten'
I0510 14:48:30.207870  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.207886  5307 net.cpp:200] Created Layer ctx_output3/relu_mbox_loc_flat (169)
I0510 14:48:30.207901  5307 net.cpp:572] ctx_output3/relu_mbox_loc_flat <- ctx_output3/relu_mbox_loc_perm
I0510 14:48:30.207916  5307 net.cpp:542] ctx_output3/relu_mbox_loc_flat -> ctx_output3/relu_mbox_loc_flat
I0510 14:48:30.207991  5307 net.cpp:260] Setting up ctx_output3/relu_mbox_loc_flat
I0510 14:48:30.208011  5307 net.cpp:267] TRAIN Top shape for layer 169 'ctx_output3/relu_mbox_loc_flat' 16 1080 (17280)
I0510 14:48:30.208036  5307 layer_factory.hpp:172] Creating layer 'ctx_output3/relu_mbox_conf' of type 'Convolution'
I0510 14:48:30.208052  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.208072  5307 net.cpp:200] Created Layer ctx_output3/relu_mbox_conf (170)
I0510 14:48:30.208088  5307 net.cpp:572] ctx_output3/relu_mbox_conf <- ctx_output3_ctx_output3/relu_0_split_1
I0510 14:48:30.208104  5307 net.cpp:542] ctx_output3/relu_mbox_conf -> ctx_output3/relu_mbox_conf
I0510 14:48:30.209836  5307 net.cpp:260] Setting up ctx_output3/relu_mbox_conf
I0510 14:48:30.209846  5307 net.cpp:267] TRAIN Top shape for layer 170 'ctx_output3/relu_mbox_conf' 16 126 5 9 (90720)
I0510 14:48:30.209878  5307 layer_factory.hpp:172] Creating layer 'ctx_output3/relu_mbox_conf_perm' of type 'Permute'
I0510 14:48:30.209895  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.209915  5307 net.cpp:200] Created Layer ctx_output3/relu_mbox_conf_perm (171)
I0510 14:48:30.209931  5307 net.cpp:572] ctx_output3/relu_mbox_conf_perm <- ctx_output3/relu_mbox_conf
I0510 14:48:30.209949  5307 net.cpp:542] ctx_output3/relu_mbox_conf_perm -> ctx_output3/relu_mbox_conf_perm
I0510 14:48:30.210062  5307 net.cpp:260] Setting up ctx_output3/relu_mbox_conf_perm
I0510 14:48:30.210083  5307 net.cpp:267] TRAIN Top shape for layer 171 'ctx_output3/relu_mbox_conf_perm' 16 5 9 126 (90720)
I0510 14:48:30.210099  5307 layer_factory.hpp:172] Creating layer 'ctx_output3/relu_mbox_conf_flat' of type 'Flatten'
I0510 14:48:30.210116  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.210136  5307 net.cpp:200] Created Layer ctx_output3/relu_mbox_conf_flat (172)
I0510 14:48:30.210152  5307 net.cpp:572] ctx_output3/relu_mbox_conf_flat <- ctx_output3/relu_mbox_conf_perm
I0510 14:48:30.210170  5307 net.cpp:542] ctx_output3/relu_mbox_conf_flat -> ctx_output3/relu_mbox_conf_flat
I0510 14:48:30.210278  5307 net.cpp:260] Setting up ctx_output3/relu_mbox_conf_flat
I0510 14:48:30.210299  5307 net.cpp:267] TRAIN Top shape for layer 172 'ctx_output3/relu_mbox_conf_flat' 16 5670 (90720)
I0510 14:48:30.210316  5307 layer_factory.hpp:172] Creating layer 'ctx_output3/relu_mbox_priorbox' of type 'PriorBox'
I0510 14:48:30.210331  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.210348  5307 net.cpp:200] Created Layer ctx_output3/relu_mbox_priorbox (173)
I0510 14:48:30.210366  5307 net.cpp:572] ctx_output3/relu_mbox_priorbox <- ctx_output3_ctx_output3/relu_0_split_2
I0510 14:48:30.210383  5307 net.cpp:572] ctx_output3/relu_mbox_priorbox <- data_data_0_split_3
I0510 14:48:30.210399  5307 net.cpp:542] ctx_output3/relu_mbox_priorbox -> ctx_output3/relu_mbox_priorbox
I0510 14:48:30.210436  5307 net.cpp:260] Setting up ctx_output3/relu_mbox_priorbox
I0510 14:48:30.210455  5307 net.cpp:267] TRAIN Top shape for layer 173 'ctx_output3/relu_mbox_priorbox' 1 2 1080 (2160)
I0510 14:48:30.210472  5307 layer_factory.hpp:172] Creating layer 'ctx_output4/relu_mbox_loc' of type 'Convolution'
I0510 14:48:30.210489  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.210510  5307 net.cpp:200] Created Layer ctx_output4/relu_mbox_loc (174)
I0510 14:48:30.210525  5307 net.cpp:572] ctx_output4/relu_mbox_loc <- ctx_output4_ctx_output4/relu_0_split_0
I0510 14:48:30.210542  5307 net.cpp:542] ctx_output4/relu_mbox_loc -> ctx_output4/relu_mbox_loc
I0510 14:48:30.210978  5307 net.cpp:260] Setting up ctx_output4/relu_mbox_loc
I0510 14:48:30.210986  5307 net.cpp:267] TRAIN Top shape for layer 174 'ctx_output4/relu_mbox_loc' 16 16 3 5 (3840)
I0510 14:48:30.211015  5307 layer_factory.hpp:172] Creating layer 'ctx_output4/relu_mbox_loc_perm' of type 'Permute'
I0510 14:48:30.211032  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.211056  5307 net.cpp:200] Created Layer ctx_output4/relu_mbox_loc_perm (175)
I0510 14:48:30.211083  5307 net.cpp:572] ctx_output4/relu_mbox_loc_perm <- ctx_output4/relu_mbox_loc
I0510 14:48:30.211099  5307 net.cpp:542] ctx_output4/relu_mbox_loc_perm -> ctx_output4/relu_mbox_loc_perm
I0510 14:48:30.211210  5307 net.cpp:260] Setting up ctx_output4/relu_mbox_loc_perm
I0510 14:48:30.211230  5307 net.cpp:267] TRAIN Top shape for layer 175 'ctx_output4/relu_mbox_loc_perm' 16 3 5 16 (3840)
I0510 14:48:30.211247  5307 layer_factory.hpp:172] Creating layer 'ctx_output4/relu_mbox_loc_flat' of type 'Flatten'
I0510 14:48:30.211263  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.211282  5307 net.cpp:200] Created Layer ctx_output4/relu_mbox_loc_flat (176)
I0510 14:48:30.211297  5307 net.cpp:572] ctx_output4/relu_mbox_loc_flat <- ctx_output4/relu_mbox_loc_perm
I0510 14:48:30.211313  5307 net.cpp:542] ctx_output4/relu_mbox_loc_flat -> ctx_output4/relu_mbox_loc_flat
I0510 14:48:30.211381  5307 net.cpp:260] Setting up ctx_output4/relu_mbox_loc_flat
I0510 14:48:30.211403  5307 net.cpp:267] TRAIN Top shape for layer 176 'ctx_output4/relu_mbox_loc_flat' 16 240 (3840)
I0510 14:48:30.211419  5307 layer_factory.hpp:172] Creating layer 'ctx_output4/relu_mbox_conf' of type 'Convolution'
I0510 14:48:30.211434  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.211457  5307 net.cpp:200] Created Layer ctx_output4/relu_mbox_conf (177)
I0510 14:48:30.211473  5307 net.cpp:572] ctx_output4/relu_mbox_conf <- ctx_output4_ctx_output4/relu_0_split_1
I0510 14:48:30.211493  5307 net.cpp:542] ctx_output4/relu_mbox_conf -> ctx_output4/relu_mbox_conf
I0510 14:48:30.212776  5307 net.cpp:260] Setting up ctx_output4/relu_mbox_conf
I0510 14:48:30.212785  5307 net.cpp:267] TRAIN Top shape for layer 177 'ctx_output4/relu_mbox_conf' 16 84 3 5 (20160)
I0510 14:48:30.212822  5307 layer_factory.hpp:172] Creating layer 'ctx_output4/relu_mbox_conf_perm' of type 'Permute'
I0510 14:48:30.212841  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.212859  5307 net.cpp:200] Created Layer ctx_output4/relu_mbox_conf_perm (178)
I0510 14:48:30.212877  5307 net.cpp:572] ctx_output4/relu_mbox_conf_perm <- ctx_output4/relu_mbox_conf
I0510 14:48:30.212894  5307 net.cpp:542] ctx_output4/relu_mbox_conf_perm -> ctx_output4/relu_mbox_conf_perm
I0510 14:48:30.213009  5307 net.cpp:260] Setting up ctx_output4/relu_mbox_conf_perm
I0510 14:48:30.213030  5307 net.cpp:267] TRAIN Top shape for layer 178 'ctx_output4/relu_mbox_conf_perm' 16 3 5 84 (20160)
I0510 14:48:30.213047  5307 layer_factory.hpp:172] Creating layer 'ctx_output4/relu_mbox_conf_flat' of type 'Flatten'
I0510 14:48:30.213063  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.213080  5307 net.cpp:200] Created Layer ctx_output4/relu_mbox_conf_flat (179)
I0510 14:48:30.213096  5307 net.cpp:572] ctx_output4/relu_mbox_conf_flat <- ctx_output4/relu_mbox_conf_perm
I0510 14:48:30.213112  5307 net.cpp:542] ctx_output4/relu_mbox_conf_flat -> ctx_output4/relu_mbox_conf_flat
I0510 14:48:30.213191  5307 net.cpp:260] Setting up ctx_output4/relu_mbox_conf_flat
I0510 14:48:30.213210  5307 net.cpp:267] TRAIN Top shape for layer 179 'ctx_output4/relu_mbox_conf_flat' 16 1260 (20160)
I0510 14:48:30.213227  5307 layer_factory.hpp:172] Creating layer 'ctx_output4/relu_mbox_priorbox' of type 'PriorBox'
I0510 14:48:30.213241  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.213259  5307 net.cpp:200] Created Layer ctx_output4/relu_mbox_priorbox (180)
I0510 14:48:30.213276  5307 net.cpp:572] ctx_output4/relu_mbox_priorbox <- ctx_output4_ctx_output4/relu_0_split_2
I0510 14:48:30.213292  5307 net.cpp:572] ctx_output4/relu_mbox_priorbox <- data_data_0_split_4
I0510 14:48:30.213310  5307 net.cpp:542] ctx_output4/relu_mbox_priorbox -> ctx_output4/relu_mbox_priorbox
I0510 14:48:30.213349  5307 net.cpp:260] Setting up ctx_output4/relu_mbox_priorbox
I0510 14:48:30.213374  5307 net.cpp:267] TRAIN Top shape for layer 180 'ctx_output4/relu_mbox_priorbox' 1 2 240 (480)
I0510 14:48:30.213392  5307 layer_factory.hpp:172] Creating layer 'ctx_output5/relu_mbox_loc' of type 'Convolution'
I0510 14:48:30.213407  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.213428  5307 net.cpp:200] Created Layer ctx_output5/relu_mbox_loc (181)
I0510 14:48:30.213444  5307 net.cpp:572] ctx_output5/relu_mbox_loc <- ctx_output5_ctx_output5/relu_0_split_0
I0510 14:48:30.213460  5307 net.cpp:542] ctx_output5/relu_mbox_loc -> ctx_output5/relu_mbox_loc
I0510 14:48:30.213901  5307 net.cpp:260] Setting up ctx_output5/relu_mbox_loc
I0510 14:48:30.213910  5307 net.cpp:267] TRAIN Top shape for layer 181 'ctx_output5/relu_mbox_loc' 16 16 3 5 (3840)
I0510 14:48:30.213917  5307 layer_factory.hpp:172] Creating layer 'ctx_output5/relu_mbox_loc_perm' of type 'Permute'
I0510 14:48:30.213928  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.213940  5307 net.cpp:200] Created Layer ctx_output5/relu_mbox_loc_perm (182)
I0510 14:48:30.213950  5307 net.cpp:572] ctx_output5/relu_mbox_loc_perm <- ctx_output5/relu_mbox_loc
I0510 14:48:30.213961  5307 net.cpp:542] ctx_output5/relu_mbox_loc_perm -> ctx_output5/relu_mbox_loc_perm
I0510 14:48:30.214069  5307 net.cpp:260] Setting up ctx_output5/relu_mbox_loc_perm
I0510 14:48:30.214084  5307 net.cpp:267] TRAIN Top shape for layer 182 'ctx_output5/relu_mbox_loc_perm' 16 3 5 16 (3840)
I0510 14:48:30.214095  5307 layer_factory.hpp:172] Creating layer 'ctx_output5/relu_mbox_loc_flat' of type 'Flatten'
I0510 14:48:30.214105  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.214118  5307 net.cpp:200] Created Layer ctx_output5/relu_mbox_loc_flat (183)
I0510 14:48:30.214126  5307 net.cpp:572] ctx_output5/relu_mbox_loc_flat <- ctx_output5/relu_mbox_loc_perm
I0510 14:48:30.214136  5307 net.cpp:542] ctx_output5/relu_mbox_loc_flat -> ctx_output5/relu_mbox_loc_flat
I0510 14:48:30.214196  5307 net.cpp:260] Setting up ctx_output5/relu_mbox_loc_flat
I0510 14:48:30.214210  5307 net.cpp:267] TRAIN Top shape for layer 183 'ctx_output5/relu_mbox_loc_flat' 16 240 (3840)
I0510 14:48:30.214221  5307 layer_factory.hpp:172] Creating layer 'ctx_output5/relu_mbox_conf' of type 'Convolution'
I0510 14:48:30.214232  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.214246  5307 net.cpp:200] Created Layer ctx_output5/relu_mbox_conf (184)
I0510 14:48:30.214256  5307 net.cpp:572] ctx_output5/relu_mbox_conf <- ctx_output5_ctx_output5/relu_0_split_1
I0510 14:48:30.214267  5307 net.cpp:542] ctx_output5/relu_mbox_conf -> ctx_output5/relu_mbox_conf
I0510 14:48:30.215553  5307 net.cpp:260] Setting up ctx_output5/relu_mbox_conf
I0510 14:48:30.215562  5307 net.cpp:267] TRAIN Top shape for layer 184 'ctx_output5/relu_mbox_conf' 16 84 3 5 (20160)
I0510 14:48:30.215569  5307 layer_factory.hpp:172] Creating layer 'ctx_output5/relu_mbox_conf_perm' of type 'Permute'
I0510 14:48:30.215580  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.215595  5307 net.cpp:200] Created Layer ctx_output5/relu_mbox_conf_perm (185)
I0510 14:48:30.215605  5307 net.cpp:572] ctx_output5/relu_mbox_conf_perm <- ctx_output5/relu_mbox_conf
I0510 14:48:30.215615  5307 net.cpp:542] ctx_output5/relu_mbox_conf_perm -> ctx_output5/relu_mbox_conf_perm
I0510 14:48:30.215721  5307 net.cpp:260] Setting up ctx_output5/relu_mbox_conf_perm
I0510 14:48:30.215736  5307 net.cpp:267] TRAIN Top shape for layer 185 'ctx_output5/relu_mbox_conf_perm' 16 3 5 84 (20160)
I0510 14:48:30.215747  5307 layer_factory.hpp:172] Creating layer 'ctx_output5/relu_mbox_conf_flat' of type 'Flatten'
I0510 14:48:30.215757  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.215773  5307 net.cpp:200] Created Layer ctx_output5/relu_mbox_conf_flat (186)
I0510 14:48:30.215790  5307 net.cpp:572] ctx_output5/relu_mbox_conf_flat <- ctx_output5/relu_mbox_conf_perm
I0510 14:48:30.215801  5307 net.cpp:542] ctx_output5/relu_mbox_conf_flat -> ctx_output5/relu_mbox_conf_flat
I0510 14:48:30.215883  5307 net.cpp:260] Setting up ctx_output5/relu_mbox_conf_flat
I0510 14:48:30.215898  5307 net.cpp:267] TRAIN Top shape for layer 186 'ctx_output5/relu_mbox_conf_flat' 16 1260 (20160)
I0510 14:48:30.215907  5307 layer_factory.hpp:172] Creating layer 'ctx_output5/relu_mbox_priorbox' of type 'PriorBox'
I0510 14:48:30.215919  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.215931  5307 net.cpp:200] Created Layer ctx_output5/relu_mbox_priorbox (187)
I0510 14:48:30.215942  5307 net.cpp:572] ctx_output5/relu_mbox_priorbox <- ctx_output5_ctx_output5/relu_0_split_2
I0510 14:48:30.215953  5307 net.cpp:572] ctx_output5/relu_mbox_priorbox <- data_data_0_split_5
I0510 14:48:30.215963  5307 net.cpp:542] ctx_output5/relu_mbox_priorbox -> ctx_output5/relu_mbox_priorbox
I0510 14:48:30.215996  5307 net.cpp:260] Setting up ctx_output5/relu_mbox_priorbox
I0510 14:48:30.216009  5307 net.cpp:267] TRAIN Top shape for layer 187 'ctx_output5/relu_mbox_priorbox' 1 2 240 (480)
I0510 14:48:30.216018  5307 layer_factory.hpp:172] Creating layer 'mbox_loc' of type 'Concat'
I0510 14:48:30.216028  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.216044  5307 net.cpp:200] Created Layer mbox_loc (188)
I0510 14:48:30.216055  5307 net.cpp:572] mbox_loc <- ctx_output1/relu_mbox_loc_flat
I0510 14:48:30.216065  5307 net.cpp:572] mbox_loc <- ctx_output2/relu_mbox_loc_flat
I0510 14:48:30.216076  5307 net.cpp:572] mbox_loc <- ctx_output3/relu_mbox_loc_flat
I0510 14:48:30.216087  5307 net.cpp:572] mbox_loc <- ctx_output4/relu_mbox_loc_flat
I0510 14:48:30.216099  5307 net.cpp:572] mbox_loc <- ctx_output5/relu_mbox_loc_flat
I0510 14:48:30.216110  5307 net.cpp:542] mbox_loc -> mbox_loc
I0510 14:48:30.216143  5307 net.cpp:260] Setting up mbox_loc
I0510 14:48:30.216156  5307 net.cpp:267] TRAIN Top shape for layer 188 'mbox_loc' 16 12824 (205184)
I0510 14:48:30.216167  5307 layer_factory.hpp:172] Creating layer 'mbox_conf' of type 'Concat'
I0510 14:48:30.216177  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.216187  5307 net.cpp:200] Created Layer mbox_conf (189)
I0510 14:48:30.216197  5307 net.cpp:572] mbox_conf <- ctx_output1/relu_mbox_conf_flat
I0510 14:48:30.216207  5307 net.cpp:572] mbox_conf <- ctx_output2/relu_mbox_conf_flat
I0510 14:48:30.216219  5307 net.cpp:572] mbox_conf <- ctx_output3/relu_mbox_conf_flat
I0510 14:48:30.216231  5307 net.cpp:572] mbox_conf <- ctx_output4/relu_mbox_conf_flat
I0510 14:48:30.216241  5307 net.cpp:572] mbox_conf <- ctx_output5/relu_mbox_conf_flat
I0510 14:48:30.216253  5307 net.cpp:542] mbox_conf -> mbox_conf
I0510 14:48:30.216284  5307 net.cpp:260] Setting up mbox_conf
I0510 14:48:30.216296  5307 net.cpp:267] TRAIN Top shape for layer 189 'mbox_conf' 16 67326 (1077216)
I0510 14:48:30.216306  5307 layer_factory.hpp:172] Creating layer 'mbox_priorbox' of type 'Concat'
I0510 14:48:30.216317  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.216329  5307 net.cpp:200] Created Layer mbox_priorbox (190)
I0510 14:48:30.216339  5307 net.cpp:572] mbox_priorbox <- ctx_output1/relu_mbox_priorbox
I0510 14:48:30.216351  5307 net.cpp:572] mbox_priorbox <- ctx_output2/relu_mbox_priorbox
I0510 14:48:30.216361  5307 net.cpp:572] mbox_priorbox <- ctx_output3/relu_mbox_priorbox
I0510 14:48:30.216372  5307 net.cpp:572] mbox_priorbox <- ctx_output4/relu_mbox_priorbox
I0510 14:48:30.216383  5307 net.cpp:572] mbox_priorbox <- ctx_output5/relu_mbox_priorbox
I0510 14:48:30.216393  5307 net.cpp:542] mbox_priorbox -> mbox_priorbox
I0510 14:48:30.216425  5307 net.cpp:260] Setting up mbox_priorbox
I0510 14:48:30.216442  5307 net.cpp:267] TRAIN Top shape for layer 190 'mbox_priorbox' 1 2 12824 (25648)
I0510 14:48:30.216459  5307 layer_factory.hpp:172] Creating layer 'mbox_loss' of type 'MultiBoxLoss'
I0510 14:48:30.216470  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.216485  5307 net.cpp:200] Created Layer mbox_loss (191)
I0510 14:48:30.216495  5307 net.cpp:572] mbox_loss <- mbox_loc
I0510 14:48:30.216506  5307 net.cpp:572] mbox_loss <- mbox_conf
I0510 14:48:30.216517  5307 net.cpp:572] mbox_loss <- mbox_priorbox
I0510 14:48:30.216532  5307 net.cpp:572] mbox_loss <- label
I0510 14:48:30.216547  5307 net.cpp:542] mbox_loss -> mbox_loss
I0510 14:48:30.216626  5307 layer_factory.hpp:172] Creating layer 'mbox_loss_smooth_L1_loc' of type 'SmoothL1Loss'
I0510 14:48:30.216639  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.216751  5307 layer_factory.hpp:172] Creating layer 'mbox_loss_softmax_conf' of type 'SoftmaxWithLoss'
I0510 14:48:30.216764  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.216893  5307 net.cpp:260] Setting up mbox_loss
I0510 14:48:30.216907  5307 net.cpp:267] TRAIN Top shape for layer 191 'mbox_loss' (1)
I0510 14:48:30.216917  5307 net.cpp:271]     with loss weight 1
I0510 14:48:30.216939  5307 net.cpp:336] mbox_loss needs backward computation.
I0510 14:48:30.216951  5307 net.cpp:338] mbox_priorbox does not need backward computation.
I0510 14:48:30.216964  5307 net.cpp:336] mbox_conf needs backward computation.
I0510 14:48:30.216974  5307 net.cpp:336] mbox_loc needs backward computation.
I0510 14:48:30.216984  5307 net.cpp:338] ctx_output5/relu_mbox_priorbox does not need backward computation.
I0510 14:48:30.216995  5307 net.cpp:336] ctx_output5/relu_mbox_conf_flat needs backward computation.
I0510 14:48:30.217005  5307 net.cpp:336] ctx_output5/relu_mbox_conf_perm needs backward computation.
I0510 14:48:30.217015  5307 net.cpp:336] ctx_output5/relu_mbox_conf needs backward computation.
I0510 14:48:30.217025  5307 net.cpp:336] ctx_output5/relu_mbox_loc_flat needs backward computation.
I0510 14:48:30.217036  5307 net.cpp:336] ctx_output5/relu_mbox_loc_perm needs backward computation.
I0510 14:48:30.217046  5307 net.cpp:336] ctx_output5/relu_mbox_loc needs backward computation.
I0510 14:48:30.217056  5307 net.cpp:338] ctx_output4/relu_mbox_priorbox does not need backward computation.
I0510 14:48:30.217067  5307 net.cpp:336] ctx_output4/relu_mbox_conf_flat needs backward computation.
I0510 14:48:30.217077  5307 net.cpp:336] ctx_output4/relu_mbox_conf_perm needs backward computation.
I0510 14:48:30.217087  5307 net.cpp:336] ctx_output4/relu_mbox_conf needs backward computation.
I0510 14:48:30.217098  5307 net.cpp:336] ctx_output4/relu_mbox_loc_flat needs backward computation.
I0510 14:48:30.217108  5307 net.cpp:336] ctx_output4/relu_mbox_loc_perm needs backward computation.
I0510 14:48:30.217118  5307 net.cpp:336] ctx_output4/relu_mbox_loc needs backward computation.
I0510 14:48:30.217128  5307 net.cpp:338] ctx_output3/relu_mbox_priorbox does not need backward computation.
I0510 14:48:30.217139  5307 net.cpp:336] ctx_output3/relu_mbox_conf_flat needs backward computation.
I0510 14:48:30.217149  5307 net.cpp:336] ctx_output3/relu_mbox_conf_perm needs backward computation.
I0510 14:48:30.217159  5307 net.cpp:336] ctx_output3/relu_mbox_conf needs backward computation.
I0510 14:48:30.217169  5307 net.cpp:336] ctx_output3/relu_mbox_loc_flat needs backward computation.
I0510 14:48:30.217177  5307 net.cpp:336] ctx_output3/relu_mbox_loc_perm needs backward computation.
I0510 14:48:30.217185  5307 net.cpp:336] ctx_output3/relu_mbox_loc needs backward computation.
I0510 14:48:30.217195  5307 net.cpp:338] ctx_output2/relu_mbox_priorbox does not need backward computation.
I0510 14:48:30.217206  5307 net.cpp:336] ctx_output2/relu_mbox_conf_flat needs backward computation.
I0510 14:48:30.217214  5307 net.cpp:336] ctx_output2/relu_mbox_conf_perm needs backward computation.
I0510 14:48:30.217227  5307 net.cpp:336] ctx_output2/relu_mbox_conf needs backward computation.
I0510 14:48:30.217242  5307 net.cpp:336] ctx_output2/relu_mbox_loc_flat needs backward computation.
I0510 14:48:30.217250  5307 net.cpp:336] ctx_output2/relu_mbox_loc_perm needs backward computation.
I0510 14:48:30.217259  5307 net.cpp:336] ctx_output2/relu_mbox_loc needs backward computation.
I0510 14:48:30.217268  5307 net.cpp:338] ctx_output1/relu_mbox_priorbox does not need backward computation.
I0510 14:48:30.217278  5307 net.cpp:336] ctx_output1/relu_mbox_conf_flat needs backward computation.
I0510 14:48:30.217288  5307 net.cpp:336] ctx_output1/relu_mbox_conf_perm needs backward computation.
I0510 14:48:30.217296  5307 net.cpp:336] ctx_output1/relu_mbox_conf needs backward computation.
I0510 14:48:30.217305  5307 net.cpp:336] ctx_output1/relu_mbox_loc_flat needs backward computation.
I0510 14:48:30.217314  5307 net.cpp:336] ctx_output1/relu_mbox_loc_perm needs backward computation.
I0510 14:48:30.217322  5307 net.cpp:336] ctx_output1/relu_mbox_loc needs backward computation.
I0510 14:48:30.217331  5307 net.cpp:336] ctx_output5_ctx_output5/relu_0_split needs backward computation.
I0510 14:48:30.217340  5307 net.cpp:336] ctx_output5/relu needs backward computation.
I0510 14:48:30.217350  5307 net.cpp:336] ctx_output5/bn needs backward computation.
I0510 14:48:30.217358  5307 net.cpp:336] ctx_output5 needs backward computation.
I0510 14:48:30.217367  5307 net.cpp:336] ctx_output5/1x1/relu needs backward computation.
I0510 14:48:30.217376  5307 net.cpp:336] ctx_output5/1x1/bn needs backward computation.
I0510 14:48:30.217386  5307 net.cpp:336] ctx_output5/1x1 needs backward computation.
I0510 14:48:30.217394  5307 net.cpp:336] ctx_output4_ctx_output4/relu_0_split needs backward computation.
I0510 14:48:30.217403  5307 net.cpp:336] ctx_output4/relu needs backward computation.
I0510 14:48:30.217412  5307 net.cpp:336] ctx_output4/bn needs backward computation.
I0510 14:48:30.217422  5307 net.cpp:336] ctx_output4 needs backward computation.
I0510 14:48:30.217429  5307 net.cpp:336] ctx_output4/1x1/relu needs backward computation.
I0510 14:48:30.217438  5307 net.cpp:336] ctx_output4/1x1/bn needs backward computation.
I0510 14:48:30.217447  5307 net.cpp:336] ctx_output4/1x1 needs backward computation.
I0510 14:48:30.217455  5307 net.cpp:336] ctx_output3_ctx_output3/relu_0_split needs backward computation.
I0510 14:48:30.217463  5307 net.cpp:336] ctx_output3/relu needs backward computation.
I0510 14:48:30.217473  5307 net.cpp:336] ctx_output3/bn needs backward computation.
I0510 14:48:30.217480  5307 net.cpp:336] ctx_output3 needs backward computation.
I0510 14:48:30.217489  5307 net.cpp:336] ctx_output3/1x1/relu needs backward computation.
I0510 14:48:30.217496  5307 net.cpp:336] ctx_output3/1x1/bn needs backward computation.
I0510 14:48:30.217505  5307 net.cpp:336] ctx_output3/1x1 needs backward computation.
I0510 14:48:30.217514  5307 net.cpp:336] ctx_output2_ctx_output2/relu_0_split needs backward computation.
I0510 14:48:30.217522  5307 net.cpp:336] ctx_output2/relu needs backward computation.
I0510 14:48:30.217530  5307 net.cpp:336] ctx_output2/bn needs backward computation.
I0510 14:48:30.217538  5307 net.cpp:336] ctx_output2 needs backward computation.
I0510 14:48:30.217546  5307 net.cpp:336] ctx_output2/1x1/relu needs backward computation.
I0510 14:48:30.217555  5307 net.cpp:336] ctx_output2/1x1/bn needs backward computation.
I0510 14:48:30.217563  5307 net.cpp:336] ctx_output2/1x1 needs backward computation.
I0510 14:48:30.217571  5307 net.cpp:336] ctx_output1_ctx_output1/relu_0_split needs backward computation.
I0510 14:48:30.217581  5307 net.cpp:336] ctx_output1/relu needs backward computation.
I0510 14:48:30.217588  5307 net.cpp:336] ctx_output1/bn needs backward computation.
I0510 14:48:30.217597  5307 net.cpp:336] ctx_output1 needs backward computation.
I0510 14:48:30.217605  5307 net.cpp:336] ctx_output1/1x1/relu needs backward computation.
I0510 14:48:30.217617  5307 net.cpp:336] ctx_output1/1x1/bn needs backward computation.
I0510 14:48:30.217628  5307 net.cpp:336] ctx_output1/1x1 needs backward computation.
I0510 14:48:30.217638  5307 net.cpp:336] pool8 needs backward computation.
I0510 14:48:30.217646  5307 net.cpp:336] pool7_pool7_0_split needs backward computation.
I0510 14:48:30.217654  5307 net.cpp:336] pool7 needs backward computation.
I0510 14:48:30.217664  5307 net.cpp:336] pool6_pool6_0_split needs backward computation.
I0510 14:48:30.217671  5307 net.cpp:336] pool6 needs backward computation.
I0510 14:48:30.217679  5307 net.cpp:336] conv6/sep_relu6/sep_0_split needs backward computation.
I0510 14:48:30.217689  5307 net.cpp:336] relu6/sep needs backward computation.
I0510 14:48:30.217697  5307 net.cpp:336] conv6/sep/scale needs backward computation.
I0510 14:48:30.217705  5307 net.cpp:336] conv6/sep/bn needs backward computation.
I0510 14:48:30.217713  5307 net.cpp:336] conv6/sep needs backward computation.
I0510 14:48:30.217721  5307 net.cpp:336] relu6/dw needs backward computation.
I0510 14:48:30.217730  5307 net.cpp:336] conv6/dw/scale needs backward computation.
I0510 14:48:30.217738  5307 net.cpp:336] conv6/dw/bn needs backward computation.
I0510 14:48:30.217747  5307 net.cpp:336] conv6/dw needs backward computation.
I0510 14:48:30.217756  5307 net.cpp:336] relu5_6/sep needs backward computation.
I0510 14:48:30.217766  5307 net.cpp:336] conv5_6/sep/scale needs backward computation.
I0510 14:48:30.217774  5307 net.cpp:336] conv5_6/sep/bn needs backward computation.
I0510 14:48:30.217782  5307 net.cpp:336] conv5_6/sep needs backward computation.
I0510 14:48:30.217792  5307 net.cpp:336] relu5_6/dw needs backward computation.
I0510 14:48:30.217800  5307 net.cpp:336] conv5_6/dw/scale needs backward computation.
I0510 14:48:30.217808  5307 net.cpp:336] conv5_6/dw/bn needs backward computation.
I0510 14:48:30.217816  5307 net.cpp:336] conv5_6/dw needs backward computation.
I0510 14:48:30.217825  5307 net.cpp:336] conv5_5/sep_relu5_5/sep_0_split needs backward computation.
I0510 14:48:30.217834  5307 net.cpp:336] relu5_5/sep needs backward computation.
I0510 14:48:30.217842  5307 net.cpp:336] conv5_5/sep/scale needs backward computation.
I0510 14:48:30.217850  5307 net.cpp:336] conv5_5/sep/bn needs backward computation.
I0510 14:48:30.217859  5307 net.cpp:336] conv5_5/sep needs backward computation.
I0510 14:48:30.217866  5307 net.cpp:336] relu5_5/dw needs backward computation.
I0510 14:48:30.217875  5307 net.cpp:336] conv5_5/dw/scale needs backward computation.
I0510 14:48:30.217883  5307 net.cpp:336] conv5_5/dw/bn needs backward computation.
I0510 14:48:30.217891  5307 net.cpp:336] conv5_5/dw needs backward computation.
I0510 14:48:30.217900  5307 net.cpp:336] relu5_4/sep needs backward computation.
I0510 14:48:30.217908  5307 net.cpp:336] conv5_4/sep/scale needs backward computation.
I0510 14:48:30.217916  5307 net.cpp:336] conv5_4/sep/bn needs backward computation.
I0510 14:48:30.217924  5307 net.cpp:336] conv5_4/sep needs backward computation.
I0510 14:48:30.217932  5307 net.cpp:336] relu5_4/dw needs backward computation.
I0510 14:48:30.217941  5307 net.cpp:336] conv5_4/dw/scale needs backward computation.
I0510 14:48:30.217949  5307 net.cpp:336] conv5_4/dw/bn needs backward computation.
I0510 14:48:30.217959  5307 net.cpp:336] conv5_4/dw needs backward computation.
I0510 14:48:30.217969  5307 net.cpp:336] relu5_3/sep needs backward computation.
I0510 14:48:30.217978  5307 net.cpp:336] conv5_3/sep/scale needs backward computation.
I0510 14:48:30.217988  5307 net.cpp:336] conv5_3/sep/bn needs backward computation.
I0510 14:48:30.217998  5307 net.cpp:336] conv5_3/sep needs backward computation.
I0510 14:48:30.218006  5307 net.cpp:336] relu5_3/dw needs backward computation.
I0510 14:48:30.218016  5307 net.cpp:336] conv5_3/dw/scale needs backward computation.
I0510 14:48:30.218026  5307 net.cpp:336] conv5_3/dw/bn needs backward computation.
I0510 14:48:30.218035  5307 net.cpp:336] conv5_3/dw needs backward computation.
I0510 14:48:30.218045  5307 net.cpp:336] relu5_2/sep needs backward computation.
I0510 14:48:30.218058  5307 net.cpp:336] conv5_2/sep/scale needs backward computation.
I0510 14:48:30.218072  5307 net.cpp:336] conv5_2/sep/bn needs backward computation.
I0510 14:48:30.218082  5307 net.cpp:336] conv5_2/sep needs backward computation.
I0510 14:48:30.218091  5307 net.cpp:336] relu5_2/dw needs backward computation.
I0510 14:48:30.218101  5307 net.cpp:336] conv5_2/dw/scale needs backward computation.
I0510 14:48:30.218111  5307 net.cpp:336] conv5_2/dw/bn needs backward computation.
I0510 14:48:30.218120  5307 net.cpp:336] conv5_2/dw needs backward computation.
I0510 14:48:30.218130  5307 net.cpp:336] relu5_1/sep needs backward computation.
I0510 14:48:30.218140  5307 net.cpp:336] conv5_1/sep/scale needs backward computation.
I0510 14:48:30.218150  5307 net.cpp:336] conv5_1/sep/bn needs backward computation.
I0510 14:48:30.218160  5307 net.cpp:336] conv5_1/sep needs backward computation.
I0510 14:48:30.218169  5307 net.cpp:336] relu5_1/dw needs backward computation.
I0510 14:48:30.218179  5307 net.cpp:336] conv5_1/dw/scale needs backward computation.
I0510 14:48:30.218189  5307 net.cpp:336] conv5_1/dw/bn needs backward computation.
I0510 14:48:30.218199  5307 net.cpp:336] conv5_1/dw needs backward computation.
I0510 14:48:30.218209  5307 net.cpp:336] relu4_2/sep needs backward computation.
I0510 14:48:30.218219  5307 net.cpp:336] conv4_2/sep/scale needs backward computation.
I0510 14:48:30.218227  5307 net.cpp:336] conv4_2/sep/bn needs backward computation.
I0510 14:48:30.218237  5307 net.cpp:336] conv4_2/sep needs backward computation.
I0510 14:48:30.218247  5307 net.cpp:336] relu4_2/dw needs backward computation.
I0510 14:48:30.218256  5307 net.cpp:336] conv4_2/dw/scale needs backward computation.
I0510 14:48:30.218266  5307 net.cpp:336] conv4_2/dw/bn needs backward computation.
I0510 14:48:30.218276  5307 net.cpp:336] conv4_2/dw needs backward computation.
I0510 14:48:30.218286  5307 net.cpp:336] relu4_1/sep needs backward computation.
I0510 14:48:30.218295  5307 net.cpp:336] conv4_1/sep/scale needs backward computation.
I0510 14:48:30.218305  5307 net.cpp:336] conv4_1/sep/bn needs backward computation.
I0510 14:48:30.218314  5307 net.cpp:336] conv4_1/sep needs backward computation.
I0510 14:48:30.218324  5307 net.cpp:336] relu4_1/dw needs backward computation.
I0510 14:48:30.218334  5307 net.cpp:336] conv4_1/dw/scale needs backward computation.
I0510 14:48:30.218343  5307 net.cpp:336] conv4_1/dw/bn needs backward computation.
I0510 14:48:30.218353  5307 net.cpp:336] conv4_1/dw needs backward computation.
I0510 14:48:30.218364  5307 net.cpp:336] relu3_2/sep needs backward computation.
I0510 14:48:30.218372  5307 net.cpp:336] conv3_2/sep/scale needs backward computation.
I0510 14:48:30.218382  5307 net.cpp:336] conv3_2/sep/bn needs backward computation.
I0510 14:48:30.218392  5307 net.cpp:336] conv3_2/sep needs backward computation.
I0510 14:48:30.218402  5307 net.cpp:336] relu3_2/dw needs backward computation.
I0510 14:48:30.218411  5307 net.cpp:336] conv3_2/dw/scale needs backward computation.
I0510 14:48:30.218421  5307 net.cpp:336] conv3_2/dw/bn needs backward computation.
I0510 14:48:30.218430  5307 net.cpp:336] conv3_2/dw needs backward computation.
I0510 14:48:30.218441  5307 net.cpp:336] relu3_1/sep needs backward computation.
I0510 14:48:30.218451  5307 net.cpp:336] conv3_1/sep/scale needs backward computation.
I0510 14:48:30.218459  5307 net.cpp:336] conv3_1/sep/bn needs backward computation.
I0510 14:48:30.218469  5307 net.cpp:336] conv3_1/sep needs backward computation.
I0510 14:48:30.218479  5307 net.cpp:336] relu3_1/dw needs backward computation.
I0510 14:48:30.218488  5307 net.cpp:336] conv3_1/dw/scale needs backward computation.
I0510 14:48:30.218497  5307 net.cpp:336] conv3_1/dw/bn needs backward computation.
I0510 14:48:30.218508  5307 net.cpp:336] conv3_1/dw needs backward computation.
I0510 14:48:30.218518  5307 net.cpp:336] relu2_2/sep needs backward computation.
I0510 14:48:30.218528  5307 net.cpp:336] conv2_2/sep/scale needs backward computation.
I0510 14:48:30.218539  5307 net.cpp:336] conv2_2/sep/bn needs backward computation.
I0510 14:48:30.218554  5307 net.cpp:336] conv2_2/sep needs backward computation.
I0510 14:48:30.218562  5307 net.cpp:336] relu2_2/dw needs backward computation.
I0510 14:48:30.218571  5307 net.cpp:336] conv2_2/dw/scale needs backward computation.
I0510 14:48:30.218580  5307 net.cpp:336] conv2_2/dw/bn needs backward computation.
I0510 14:48:30.218586  5307 net.cpp:336] conv2_2/dw needs backward computation.
I0510 14:48:30.218595  5307 net.cpp:336] relu2_1/sep needs backward computation.
I0510 14:48:30.218602  5307 net.cpp:336] conv2_1/sep/scale needs backward computation.
I0510 14:48:30.218611  5307 net.cpp:336] conv2_1/sep/bn needs backward computation.
I0510 14:48:30.218618  5307 net.cpp:336] conv2_1/sep needs backward computation.
I0510 14:48:30.218626  5307 net.cpp:336] relu2_1/dw needs backward computation.
I0510 14:48:30.218634  5307 net.cpp:336] conv2_1/dw/scale needs backward computation.
I0510 14:48:30.218642  5307 net.cpp:336] conv2_1/dw/bn needs backward computation.
I0510 14:48:30.218650  5307 net.cpp:336] conv2_1/dw needs backward computation.
I0510 14:48:30.218658  5307 net.cpp:336] relu1 needs backward computation.
I0510 14:48:30.218667  5307 net.cpp:336] conv1/scale needs backward computation.
I0510 14:48:30.218673  5307 net.cpp:336] conv1/bn needs backward computation.
I0510 14:48:30.218681  5307 net.cpp:336] conv1 needs backward computation.
I0510 14:48:30.218691  5307 net.cpp:338] data/bias does not need backward computation.
I0510 14:48:30.218700  5307 net.cpp:338] data_data_0_split does not need backward computation.
I0510 14:48:30.218709  5307 net.cpp:338] data does not need backward computation.
I0510 14:48:30.218717  5307 net.cpp:380] This network produces output mbox_loss
I0510 14:48:30.218881  5307 net.cpp:403] Top memory (TRAIN) required for data: 2150578120 diff: 2150578120
I0510 14:48:30.218894  5307 net.cpp:406] Bottom memory (TRAIN) required for data: 2150578112 diff: 2150578112
I0510 14:48:30.218901  5307 net.cpp:409] Shared (in-place) memory (TRAIN) by data: 1358299136 diff: 1358299136
I0510 14:48:30.218910  5307 net.cpp:412] Parameters memory (TRAIN) required for data: 9462808 diff: 9462808
I0510 14:48:30.218919  5307 net.cpp:415] Parameters shared memory (TRAIN) by data: 0 diff: 0
I0510 14:48:30.218926  5307 net.cpp:421] Network initialization done.
I0510 14:48:30.221627  5307 solver.cpp:175] Creating test net (#0) specified by test_net file: training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/test.prototxt
I0510 14:48:30.222658  5307 net.cpp:80] Initializing net from parameters: 
name: "mobiledetnet-0.5_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_value: 0
    mean_value: 0
    mean_value: 0
    force_color: false
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 256
      width: 512
      interp_mode: LINEAR
    }
    crop_h: 256
    crop_w: 512
  }
  data_param {
    source: "../../caffe-jacinto/examples/VOC0712/VOC0712_test_lmdb"
    batch_size: 8
    backend: LMDB
    threads: 4
    parser_threads: 4
  }
  annotated_data_param {
    batch_sampler {
    }
    label_map_file: "../../caffe-jacinto/data/VOC0712/labelmap_voc.prototxt"
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1/dw"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1/dw"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 16
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
}
layer {
  name: "conv2_1/dw/scale"
  type: "Scale"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1/dw"
  type: "ReLU"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
}
layer {
  name: "conv2_1/sep"
  type: "Convolution"
  bottom: "conv2_1/dw"
  top: "conv2_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
}
layer {
  name: "conv2_1/sep/scale"
  type: "Scale"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1/sep"
  type: "ReLU"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
}
layer {
  name: "conv2_2/dw"
  type: "Convolution"
  bottom: "conv2_1/sep"
  top: "conv2_2/dw"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
}
layer {
  name: "conv2_2/dw/scale"
  type: "Scale"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2/dw"
  type: "ReLU"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
}
layer {
  name: "conv2_2/sep"
  type: "Convolution"
  bottom: "conv2_2/dw"
  top: "conv2_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
}
layer {
  name: "conv2_2/sep/scale"
  type: "Scale"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2/sep"
  type: "ReLU"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
}
layer {
  name: "conv3_1/dw"
  type: "Convolution"
  bottom: "conv2_2/sep"
  top: "conv3_1/dw"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
}
layer {
  name: "conv3_1/dw/scale"
  type: "Scale"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1/dw"
  type: "ReLU"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
}
layer {
  name: "conv3_1/sep"
  type: "Convolution"
  bottom: "conv3_1/dw"
  top: "conv3_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
}
layer {
  name: "conv3_1/sep/scale"
  type: "Scale"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1/sep"
  type: "ReLU"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
}
layer {
  name: "conv3_2/dw"
  type: "Convolution"
  bottom: "conv3_1/sep"
  top: "conv3_2/dw"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
}
layer {
  name: "conv3_2/dw/scale"
  type: "Scale"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2/dw"
  type: "ReLU"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
}
layer {
  name: "conv3_2/sep"
  type: "Convolution"
  bottom: "conv3_2/dw"
  top: "conv3_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
}
layer {
  name: "conv3_2/sep/scale"
  type: "Scale"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2/sep"
  type: "ReLU"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
}
layer {
  name: "conv4_1/dw"
  type: "Convolution"
  bottom: "conv3_2/sep"
  top: "conv4_1/dw"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
}
layer {
  name: "conv4_1/dw/scale"
  type: "Scale"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1/dw"
  type: "ReLU"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
}
layer {
  name: "conv4_1/sep"
  type: "Convolution"
  bottom: "conv4_1/dw"
  top: "conv4_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
}
layer {
  name: "conv4_1/sep/scale"
  type: "Scale"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1/sep"
  type: "ReLU"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
}
layer {
  name: "conv4_2/dw"
  type: "Convolution"
  bottom: "conv4_1/sep"
  top: "conv4_2/dw"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
}
layer {
  name: "conv4_2/dw/scale"
  type: "Scale"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2/dw"
  type: "ReLU"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
}
layer {
  name: "conv4_2/sep"
  type: "Convolution"
  bottom: "conv4_2/dw"
  top: "conv4_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
}
layer {
  name: "conv4_2/sep/scale"
  type: "Scale"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2/sep"
  type: "ReLU"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
}
layer {
  name: "conv5_1/dw"
  type: "Convolution"
  bottom: "conv4_2/sep"
  top: "conv5_1/dw"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
}
layer {
  name: "conv5_1/dw/scale"
  type: "Scale"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1/dw"
  type: "ReLU"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
}
layer {
  name: "conv5_1/sep"
  type: "Convolution"
  bottom: "conv5_1/dw"
  top: "conv5_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
}
layer {
  name: "conv5_1/sep/scale"
  type: "Scale"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1/sep"
  type: "ReLU"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
}
layer {
  name: "conv5_2/dw"
  type: "Convolution"
  bottom: "conv5_1/sep"
  top: "conv5_2/dw"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
}
layer {
  name: "conv5_2/dw/scale"
  type: "Scale"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2/dw"
  type: "ReLU"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
}
layer {
  name: "conv5_2/sep"
  type: "Convolution"
  bottom: "conv5_2/dw"
  top: "conv5_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
}
layer {
  name: "conv5_2/sep/scale"
  type: "Scale"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2/sep"
  type: "ReLU"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
}
layer {
  name: "conv5_3/dw"
  type: "Convolution"
  bottom: "conv5_2/sep"
  top: "conv5_3/dw"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
}
layer {
  name: "conv5_3/dw/scale"
  type: "Scale"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3/dw"
  type: "ReLU"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
}
layer {
  name: "conv5_3/sep"
  type: "Convolution"
  bottom: "conv5_3/dw"
  top: "conv5_3/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
}
layer {
  name: "conv5_3/sep/scale"
  type: "Scale"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3/sep"
  type: "ReLU"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
}
layer {
  name: "conv5_4/dw"
  type: "Convolution"
  bottom: "conv5_3/sep"
  top: "conv5_4/dw"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
}
layer {
  name: "conv5_4/dw/scale"
  type: "Scale"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_4/dw"
  type: "ReLU"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
}
layer {
  name: "conv5_4/sep"
  type: "Convolution"
  bottom: "conv5_4/dw"
  top: "conv5_4/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
}
layer {
  name: "conv5_4/sep/scale"
  type: "Scale"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_4/sep"
  type: "ReLU"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
}
layer {
  name: "conv5_5/dw"
  type: "Convolution"
  bottom: "conv5_4/sep"
  top: "conv5_5/dw"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
}
layer {
  name: "conv5_5/dw/scale"
  type: "Scale"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_5/dw"
  type: "ReLU"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
}
layer {
  name: "conv5_5/sep"
  type: "Convolution"
  bottom: "conv5_5/dw"
  top: "conv5_5/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
}
layer {
  name: "conv5_5/sep/scale"
  type: "Scale"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_5/sep"
  type: "ReLU"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
}
layer {
  name: "conv5_6/dw"
  type: "Convolution"
  bottom: "conv5_5/sep"
  top: "conv5_6/dw"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_6/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
}
layer {
  name: "conv5_6/dw/scale"
  type: "Scale"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_6/dw"
  type: "ReLU"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
}
layer {
  name: "conv5_6/sep"
  type: "Convolution"
  bottom: "conv5_6/dw"
  top: "conv5_6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_6/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
}
layer {
  name: "conv5_6/sep/scale"
  type: "Scale"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_6/sep"
  type: "ReLU"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
}
layer {
  name: "conv6/dw"
  type: "Convolution"
  bottom: "conv5_6/sep"
  top: "conv6/dw"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6/dw"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/sep"
  type: "Convolution"
  bottom: "conv6/dw"
  top: "conv6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/sep/bn"
  type: "BatchNorm"
  bottom: "conv6/sep"
  top: "conv6/sep"
}
layer {
  name: "conv6/sep/scale"
  type: "Scale"
  bottom: "conv6/sep"
  top: "conv6/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6/sep"
  type: "ReLU"
  bottom: "conv6/sep"
  top: "conv6/sep"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv6/sep"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "pool6"
  top: "pool7"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "pool8"
  type: "Pooling"
  bottom: "pool7"
  top: "pool8"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "ctx_output1/1x1"
  type: "Convolution"
  bottom: "conv5_5/sep"
  top: "ctx_output1/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/1x1/bn"
  type: "BatchNorm"
  bottom: "ctx_output1/1x1"
  top: "ctx_output1/1x1"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_output1/1x1/relu"
  type: "ReLU"
  bottom: "ctx_output1/1x1"
  top: "ctx_output1/1x1"
}
layer {
  name: "ctx_output1"
  type: "Convolution"
  bottom: "ctx_output1/1x1"
  top: "ctx_output1"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/bn"
  type: "BatchNorm"
  bottom: "ctx_output1"
  top: "ctx_output1"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_output1/relu"
  type: "ReLU"
  bottom: "ctx_output1"
  top: "ctx_output1"
}
layer {
  name: "ctx_output2/1x1"
  type: "Convolution"
  bottom: "conv6/sep"
  top: "ctx_output2/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/1x1/bn"
  type: "BatchNorm"
  bottom: "ctx_output2/1x1"
  top: "ctx_output2/1x1"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_output2/1x1/relu"
  type: "ReLU"
  bottom: "ctx_output2/1x1"
  top: "ctx_output2/1x1"
}
layer {
  name: "ctx_output2"
  type: "Convolution"
  bottom: "ctx_output2/1x1"
  top: "ctx_output2"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/bn"
  type: "BatchNorm"
  bottom: "ctx_output2"
  top: "ctx_output2"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_output2/relu"
  type: "ReLU"
  bottom: "ctx_output2"
  top: "ctx_output2"
}
layer {
  name: "ctx_output3/1x1"
  type: "Convolution"
  bottom: "pool6"
  top: "ctx_output3/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/1x1/bn"
  type: "BatchNorm"
  bottom: "ctx_output3/1x1"
  top: "ctx_output3/1x1"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_output3/1x1/relu"
  type: "ReLU"
  bottom: "ctx_output3/1x1"
  top: "ctx_output3/1x1"
}
layer {
  name: "ctx_output3"
  type: "Convolution"
  bottom: "ctx_output3/1x1"
  top: "ctx_output3"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output3/bn"
  type: "BatchNorm"
  bottom: "ctx_output3"
  top: "ctx_output3"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_output3/relu"
  type: "ReLU"
  bottom: "ctx_output3"
  top: "ctx_output3"
}
layer {
  name: "ctx_output4/1x1"
  type: "Convolution"
  bottom: "pool7"
  top: "ctx_output4/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/1x1/bn"
  type: "BatchNorm"
  bottom: "ctx_output4/1x1"
  top: "ctx_output4/1x1"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_output4/1x1/relu"
  type: "ReLU"
  bottom: "ctx_output4/1x1"
  top: "ctx_output4/1x1"
}
layer {
  name: "ctx_output4"
  type: "Convolution"
  bottom: "ctx_output4/1x1"
  top: "ctx_output4"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output4/bn"
  type: "BatchNorm"
  bottom: "ctx_output4"
  top: "ctx_output4"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_output4/relu"
  type: "ReLU"
  bottom: "ctx_output4"
  top: "ctx_output4"
}
layer {
  name: "ctx_output5/1x1"
  type: "Convolution"
  bottom: "pool8"
  top: "ctx_output5/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/1x1/bn"
  type: "BatchNorm"
  bottom: "ctx_output5/1x1"
  top: "ctx_output5/1x1"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_output5/1x1/relu"
  type: "ReLU"
  bottom: "ctx_output5/1x1"
  top: "ctx_output5/1x1"
}
layer {
  name: "ctx_output5"
  type: "Convolution"
  bottom: "ctx_output5/1x1"
  top: "ctx_output5"
  param {
    lr_mult: 1
    decay_mult: 0.01
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output5/bn"
  type: "BatchNorm"
  bottom: "ctx_output5"
  top: "ctx_output5"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_output5/relu"
  type: "ReLU"
  bottom: "ctx_output5"
  top: "ctx_output5"
}
layer {
  name: "ctx_output1/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_loc"
  top: "ctx_output1/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_loc_perm"
  top: "ctx_output1/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output1"
  top: "ctx_output1/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 84
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output1/relu_mbox_conf"
  top: "ctx_output1/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output1/relu_mbox_conf_perm"
  top: "ctx_output1/relu_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output1/relu_mbox_priorbox"
  type: "PriorBox"
  bottom: "ctx_output1"
  bottom: "data"
  top: "ctx_output1/relu_mbox_priorbox"
  prior_box_param {
    min_size: 19
    max_size: 88
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_loc"
  top: "ctx_output2/relu_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_loc_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_loc_perm"
  top: "ctx_output2/relu_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf"
  type: "Convolution"
  bottom: "ctx_output2"
  top: "ctx_output2/relu_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 126
    bias_term: true
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_perm"
  type: "Permute"
  bottom: "ctx_output2/relu_mbox_conf"
  top: "ctx_output2/relu_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ctx_output2/relu_mbox_conf_flat"
  type: "Flatten"
  bottom: "ctx_output2/relu_mbox_conf_perm"
  top: "ctx_output2/rel
I0510 14:48:30.223242  5307 net.cpp:110] Using FLOAT as default forward math type
I0510 14:48:30.223258  5307 net.cpp:116] Using FLOAT as default backward math type
I0510 14:48:30.223271  5307 layer_factory.hpp:172] Creating layer 'data' of type 'AnnotatedData'
I0510 14:48:30.223291  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.223315  5307 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0510 14:48:30.224280  5307 net.cpp:200] Created Layer data (0)
I0510 14:48:30.224289  5307 net.cpp:542] data -> data
I0510 14:48:30.224298  5307 net.cpp:542] data -> label
I0510 14:48:30.224310  5307 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 8
I0510 14:48:30.224318  5307 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0510 14:48:30.225162  5353 db_lmdb.cpp:36] Opened lmdb ../../caffe-jacinto/examples/VOC0712/VOC0712_test_lmdb
I0510 14:48:30.226320  5307 annotated_data_layer.cpp:105] output data size: 8,3,256,512
I0510 14:48:30.226392  5307 annotated_data_layer.cpp:150] (0) Output data size: 8, 3, 256, 512
I0510 14:48:30.226428  5307 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0510 14:48:30.226449  5307 net.cpp:260] Setting up data
I0510 14:48:30.226456  5307 net.cpp:267] TEST Top shape for layer 0 'data' 8 3 256 512 (3145728)
I0510 14:48:30.227767  5354 data_layer.cpp:105] (0) Parser threads: 1
I0510 14:48:30.227777  5354 data_layer.cpp:107] (0) Transformer threads: 1
I0510 14:48:30.227795  5307 net.cpp:267] TEST Top shape for layer 0 'data' 1 1 2 8 (16)
I0510 14:48:30.227813  5307 layer_factory.hpp:172] Creating layer 'data_data_0_split' of type 'Split'
I0510 14:48:30.227828  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.227845  5307 net.cpp:200] Created Layer data_data_0_split (1)
I0510 14:48:30.227859  5307 net.cpp:572] data_data_0_split <- data
I0510 14:48:30.227874  5307 net.cpp:542] data_data_0_split -> data_data_0_split_0
I0510 14:48:30.227890  5307 net.cpp:542] data_data_0_split -> data_data_0_split_1
I0510 14:48:30.227902  5307 net.cpp:542] data_data_0_split -> data_data_0_split_2
I0510 14:48:30.227917  5307 net.cpp:542] data_data_0_split -> data_data_0_split_3
I0510 14:48:30.227931  5307 net.cpp:542] data_data_0_split -> data_data_0_split_4
I0510 14:48:30.227943  5307 net.cpp:542] data_data_0_split -> data_data_0_split_5
I0510 14:48:30.228044  5307 net.cpp:260] Setting up data_data_0_split
I0510 14:48:30.228060  5307 net.cpp:267] TEST Top shape for layer 1 'data_data_0_split' 8 3 256 512 (3145728)
I0510 14:48:30.228075  5307 net.cpp:267] TEST Top shape for layer 1 'data_data_0_split' 8 3 256 512 (3145728)
I0510 14:48:30.228087  5307 net.cpp:267] TEST Top shape for layer 1 'data_data_0_split' 8 3 256 512 (3145728)
I0510 14:48:30.228101  5307 net.cpp:267] TEST Top shape for layer 1 'data_data_0_split' 8 3 256 512 (3145728)
I0510 14:48:30.228114  5307 net.cpp:267] TEST Top shape for layer 1 'data_data_0_split' 8 3 256 512 (3145728)
I0510 14:48:30.228127  5307 net.cpp:267] TEST Top shape for layer 1 'data_data_0_split' 8 3 256 512 (3145728)
I0510 14:48:30.228140  5307 layer_factory.hpp:172] Creating layer 'data/bias' of type 'Bias'
I0510 14:48:30.228154  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.228170  5307 net.cpp:200] Created Layer data/bias (2)
I0510 14:48:30.228183  5307 net.cpp:572] data/bias <- data_data_0_split_0
I0510 14:48:30.228196  5307 net.cpp:542] data/bias -> data/bias
I0510 14:48:30.228427  5307 net.cpp:260] Setting up data/bias
I0510 14:48:30.228446  5307 net.cpp:267] TEST Top shape for layer 2 'data/bias' 8 3 256 512 (3145728)
I0510 14:48:30.228464  5307 layer_factory.hpp:172] Creating layer 'conv1' of type 'Convolution'
I0510 14:48:30.228478  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.228498  5307 net.cpp:200] Created Layer conv1 (3)
I0510 14:48:30.228513  5307 net.cpp:572] conv1 <- data/bias
I0510 14:48:30.228540  5307 net.cpp:542] conv1 -> conv1
I0510 14:48:30.228772  5307 net.cpp:260] Setting up conv1
I0510 14:48:30.228781  5307 net.cpp:267] TEST Top shape for layer 3 'conv1' 8 16 128 256 (4194304)
I0510 14:48:30.228788  5307 layer_factory.hpp:172] Creating layer 'conv1/bn' of type 'BatchNorm'
I0510 14:48:30.228801  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.228811  5307 net.cpp:200] Created Layer conv1/bn (4)
I0510 14:48:30.228814  5307 net.cpp:572] conv1/bn <- conv1
I0510 14:48:30.228818  5307 net.cpp:527] conv1/bn -> conv1 (in-place)
I0510 14:48:30.242122  5307 net.cpp:260] Setting up conv1/bn
I0510 14:48:30.242146  5307 net.cpp:267] TEST Top shape for layer 4 'conv1/bn' 8 16 128 256 (4194304)
I0510 14:48:30.242161  5307 layer_factory.hpp:172] Creating layer 'conv1/scale' of type 'Scale'
I0510 14:48:30.242178  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.242193  5307 net.cpp:200] Created Layer conv1/scale (5)
I0510 14:48:30.242205  5307 net.cpp:572] conv1/scale <- conv1
I0510 14:48:30.242216  5307 net.cpp:527] conv1/scale -> conv1 (in-place)
I0510 14:48:30.242266  5307 layer_factory.hpp:172] Creating layer 'conv1/scale' of type 'Bias'
I0510 14:48:30.242278  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.242435  5307 net.cpp:260] Setting up conv1/scale
I0510 14:48:30.242456  5307 net.cpp:267] TEST Top shape for layer 5 'conv1/scale' 8 16 128 256 (4194304)
I0510 14:48:30.242472  5307 layer_factory.hpp:172] Creating layer 'relu1' of type 'ReLU'
I0510 14:48:30.242486  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.242501  5307 net.cpp:200] Created Layer relu1 (6)
I0510 14:48:30.242513  5307 net.cpp:572] relu1 <- conv1
I0510 14:48:30.242527  5307 net.cpp:527] relu1 -> conv1 (in-place)
I0510 14:48:30.242547  5307 net.cpp:260] Setting up relu1
I0510 14:48:30.242563  5307 net.cpp:267] TEST Top shape for layer 6 'relu1' 8 16 128 256 (4194304)
I0510 14:48:30.242575  5307 layer_factory.hpp:172] Creating layer 'conv2_1/dw' of type 'Convolution'
I0510 14:48:30.242588  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.242612  5307 net.cpp:200] Created Layer conv2_1/dw (7)
I0510 14:48:30.242625  5307 net.cpp:572] conv2_1/dw <- conv1
I0510 14:48:30.242638  5307 net.cpp:542] conv2_1/dw -> conv2_1/dw
I0510 14:48:30.242871  5307 net.cpp:260] Setting up conv2_1/dw
I0510 14:48:30.242893  5307 net.cpp:267] TEST Top shape for layer 7 'conv2_1/dw' 8 16 128 256 (4194304)
I0510 14:48:30.242910  5307 layer_factory.hpp:172] Creating layer 'conv2_1/dw/bn' of type 'BatchNorm'
I0510 14:48:30.242925  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.242943  5307 net.cpp:200] Created Layer conv2_1/dw/bn (8)
I0510 14:48:30.242957  5307 net.cpp:572] conv2_1/dw/bn <- conv2_1/dw
I0510 14:48:30.242971  5307 net.cpp:527] conv2_1/dw/bn -> conv2_1/dw (in-place)
I0510 14:48:30.243391  5307 net.cpp:260] Setting up conv2_1/dw/bn
I0510 14:48:30.243412  5307 net.cpp:267] TEST Top shape for layer 8 'conv2_1/dw/bn' 8 16 128 256 (4194304)
I0510 14:48:30.243432  5307 layer_factory.hpp:172] Creating layer 'conv2_1/dw/scale' of type 'Scale'
I0510 14:48:30.243445  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.243461  5307 net.cpp:200] Created Layer conv2_1/dw/scale (9)
I0510 14:48:30.243475  5307 net.cpp:572] conv2_1/dw/scale <- conv2_1/dw
I0510 14:48:30.243489  5307 net.cpp:527] conv2_1/dw/scale -> conv2_1/dw (in-place)
I0510 14:48:30.243537  5307 layer_factory.hpp:172] Creating layer 'conv2_1/dw/scale' of type 'Bias'
I0510 14:48:30.243553  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.243713  5307 net.cpp:260] Setting up conv2_1/dw/scale
I0510 14:48:30.243731  5307 net.cpp:267] TEST Top shape for layer 9 'conv2_1/dw/scale' 8 16 128 256 (4194304)
I0510 14:48:30.243748  5307 layer_factory.hpp:172] Creating layer 'relu2_1/dw' of type 'ReLU'
I0510 14:48:30.243767  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.243791  5307 net.cpp:200] Created Layer relu2_1/dw (10)
I0510 14:48:30.243805  5307 net.cpp:572] relu2_1/dw <- conv2_1/dw
I0510 14:48:30.243819  5307 net.cpp:527] relu2_1/dw -> conv2_1/dw (in-place)
I0510 14:48:30.243835  5307 net.cpp:260] Setting up relu2_1/dw
I0510 14:48:30.243849  5307 net.cpp:267] TEST Top shape for layer 10 'relu2_1/dw' 8 16 128 256 (4194304)
I0510 14:48:30.243863  5307 layer_factory.hpp:172] Creating layer 'conv2_1/sep' of type 'Convolution'
I0510 14:48:30.243876  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.243896  5307 net.cpp:200] Created Layer conv2_1/sep (11)
I0510 14:48:30.243911  5307 net.cpp:572] conv2_1/sep <- conv2_1/dw
I0510 14:48:30.243927  5307 net.cpp:542] conv2_1/sep -> conv2_1/sep
I0510 14:48:30.244163  5307 net.cpp:260] Setting up conv2_1/sep
I0510 14:48:30.244171  5307 net.cpp:267] TEST Top shape for layer 11 'conv2_1/sep' 8 32 128 256 (8388608)
I0510 14:48:30.244179  5307 layer_factory.hpp:172] Creating layer 'conv2_1/sep/bn' of type 'BatchNorm'
I0510 14:48:30.244184  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.244190  5307 net.cpp:200] Created Layer conv2_1/sep/bn (12)
I0510 14:48:30.244194  5307 net.cpp:572] conv2_1/sep/bn <- conv2_1/sep
I0510 14:48:30.244199  5307 net.cpp:527] conv2_1/sep/bn -> conv2_1/sep (in-place)
I0510 14:48:30.244614  5307 net.cpp:260] Setting up conv2_1/sep/bn
I0510 14:48:30.244623  5307 net.cpp:267] TEST Top shape for layer 12 'conv2_1/sep/bn' 8 32 128 256 (8388608)
I0510 14:48:30.244632  5307 layer_factory.hpp:172] Creating layer 'conv2_1/sep/scale' of type 'Scale'
I0510 14:48:30.244637  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.244642  5307 net.cpp:200] Created Layer conv2_1/sep/scale (13)
I0510 14:48:30.244647  5307 net.cpp:572] conv2_1/sep/scale <- conv2_1/sep
I0510 14:48:30.244650  5307 net.cpp:527] conv2_1/sep/scale -> conv2_1/sep (in-place)
I0510 14:48:30.244686  5307 layer_factory.hpp:172] Creating layer 'conv2_1/sep/scale' of type 'Bias'
I0510 14:48:30.244701  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.244850  5307 net.cpp:260] Setting up conv2_1/sep/scale
I0510 14:48:30.244863  5307 net.cpp:267] TEST Top shape for layer 13 'conv2_1/sep/scale' 8 32 128 256 (8388608)
I0510 14:48:30.244875  5307 layer_factory.hpp:172] Creating layer 'relu2_1/sep' of type 'ReLU'
I0510 14:48:30.244884  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.244894  5307 net.cpp:200] Created Layer relu2_1/sep (14)
I0510 14:48:30.244902  5307 net.cpp:572] relu2_1/sep <- conv2_1/sep
I0510 14:48:30.244911  5307 net.cpp:527] relu2_1/sep -> conv2_1/sep (in-place)
I0510 14:48:30.244922  5307 net.cpp:260] Setting up relu2_1/sep
I0510 14:48:30.244932  5307 net.cpp:267] TEST Top shape for layer 14 'relu2_1/sep' 8 32 128 256 (8388608)
I0510 14:48:30.244941  5307 layer_factory.hpp:172] Creating layer 'conv2_2/dw' of type 'Convolution'
I0510 14:48:30.244951  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.244962  5307 net.cpp:200] Created Layer conv2_2/dw (15)
I0510 14:48:30.244971  5307 net.cpp:572] conv2_2/dw <- conv2_1/sep
I0510 14:48:30.244979  5307 net.cpp:542] conv2_2/dw -> conv2_2/dw
I0510 14:48:30.245188  5307 net.cpp:260] Setting up conv2_2/dw
I0510 14:48:30.245209  5307 net.cpp:267] TEST Top shape for layer 15 'conv2_2/dw' 8 32 64 128 (2097152)
I0510 14:48:30.245224  5307 layer_factory.hpp:172] Creating layer 'conv2_2/dw/bn' of type 'BatchNorm'
I0510 14:48:30.245237  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.245254  5307 net.cpp:200] Created Layer conv2_2/dw/bn (16)
I0510 14:48:30.245270  5307 net.cpp:572] conv2_2/dw/bn <- conv2_2/dw
I0510 14:48:30.245283  5307 net.cpp:527] conv2_2/dw/bn -> conv2_2/dw (in-place)
I0510 14:48:30.245674  5307 net.cpp:260] Setting up conv2_2/dw/bn
I0510 14:48:30.245693  5307 net.cpp:267] TEST Top shape for layer 16 'conv2_2/dw/bn' 8 32 64 128 (2097152)
I0510 14:48:30.245710  5307 layer_factory.hpp:172] Creating layer 'conv2_2/dw/scale' of type 'Scale'
I0510 14:48:30.245724  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.245738  5307 net.cpp:200] Created Layer conv2_2/dw/scale (17)
I0510 14:48:30.245751  5307 net.cpp:572] conv2_2/dw/scale <- conv2_2/dw
I0510 14:48:30.245764  5307 net.cpp:527] conv2_2/dw/scale -> conv2_2/dw (in-place)
I0510 14:48:30.245811  5307 layer_factory.hpp:172] Creating layer 'conv2_2/dw/scale' of type 'Bias'
I0510 14:48:30.245826  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.245949  5307 net.cpp:260] Setting up conv2_2/dw/scale
I0510 14:48:30.245966  5307 net.cpp:267] TEST Top shape for layer 17 'conv2_2/dw/scale' 8 32 64 128 (2097152)
I0510 14:48:30.245982  5307 layer_factory.hpp:172] Creating layer 'relu2_2/dw' of type 'ReLU'
I0510 14:48:30.245995  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.246008  5307 net.cpp:200] Created Layer relu2_2/dw (18)
I0510 14:48:30.246021  5307 net.cpp:572] relu2_2/dw <- conv2_2/dw
I0510 14:48:30.246035  5307 net.cpp:527] relu2_2/dw -> conv2_2/dw (in-place)
I0510 14:48:30.246049  5307 net.cpp:260] Setting up relu2_2/dw
I0510 14:48:30.246063  5307 net.cpp:267] TEST Top shape for layer 18 'relu2_2/dw' 8 32 64 128 (2097152)
I0510 14:48:30.246076  5307 layer_factory.hpp:172] Creating layer 'conv2_2/sep' of type 'Convolution'
I0510 14:48:30.246093  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.246112  5307 net.cpp:200] Created Layer conv2_2/sep (19)
I0510 14:48:30.246125  5307 net.cpp:572] conv2_2/sep <- conv2_2/dw
I0510 14:48:30.246139  5307 net.cpp:542] conv2_2/sep -> conv2_2/sep
I0510 14:48:30.246407  5307 net.cpp:260] Setting up conv2_2/sep
I0510 14:48:30.246417  5307 net.cpp:267] TEST Top shape for layer 19 'conv2_2/sep' 8 64 64 128 (4194304)
I0510 14:48:30.246421  5307 layer_factory.hpp:172] Creating layer 'conv2_2/sep/bn' of type 'BatchNorm'
I0510 14:48:30.246425  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.246431  5307 net.cpp:200] Created Layer conv2_2/sep/bn (20)
I0510 14:48:30.246435  5307 net.cpp:572] conv2_2/sep/bn <- conv2_2/sep
I0510 14:48:30.246439  5307 net.cpp:527] conv2_2/sep/bn -> conv2_2/sep (in-place)
I0510 14:48:30.246834  5307 net.cpp:260] Setting up conv2_2/sep/bn
I0510 14:48:30.246841  5307 net.cpp:267] TEST Top shape for layer 20 'conv2_2/sep/bn' 8 64 64 128 (4194304)
I0510 14:48:30.246850  5307 layer_factory.hpp:172] Creating layer 'conv2_2/sep/scale' of type 'Scale'
I0510 14:48:30.246853  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.246860  5307 net.cpp:200] Created Layer conv2_2/sep/scale (21)
I0510 14:48:30.246862  5307 net.cpp:572] conv2_2/sep/scale <- conv2_2/sep
I0510 14:48:30.246866  5307 net.cpp:527] conv2_2/sep/scale -> conv2_2/sep (in-place)
I0510 14:48:30.246904  5307 layer_factory.hpp:172] Creating layer 'conv2_2/sep/scale' of type 'Bias'
I0510 14:48:30.246909  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.247018  5307 net.cpp:260] Setting up conv2_2/sep/scale
I0510 14:48:30.247025  5307 net.cpp:267] TEST Top shape for layer 21 'conv2_2/sep/scale' 8 64 64 128 (4194304)
I0510 14:48:30.247032  5307 layer_factory.hpp:172] Creating layer 'relu2_2/sep' of type 'ReLU'
I0510 14:48:30.247036  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.247041  5307 net.cpp:200] Created Layer relu2_2/sep (22)
I0510 14:48:30.247045  5307 net.cpp:572] relu2_2/sep <- conv2_2/sep
I0510 14:48:30.247058  5307 net.cpp:527] relu2_2/sep -> conv2_2/sep (in-place)
I0510 14:48:30.247064  5307 net.cpp:260] Setting up relu2_2/sep
I0510 14:48:30.247068  5307 net.cpp:267] TEST Top shape for layer 22 'relu2_2/sep' 8 64 64 128 (4194304)
I0510 14:48:30.247072  5307 layer_factory.hpp:172] Creating layer 'conv3_1/dw' of type 'Convolution'
I0510 14:48:30.247076  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.247084  5307 net.cpp:200] Created Layer conv3_1/dw (23)
I0510 14:48:30.247088  5307 net.cpp:572] conv3_1/dw <- conv2_2/sep
I0510 14:48:30.247092  5307 net.cpp:542] conv3_1/dw -> conv3_1/dw
I0510 14:48:30.247303  5307 net.cpp:260] Setting up conv3_1/dw
I0510 14:48:30.247310  5307 net.cpp:267] TEST Top shape for layer 23 'conv3_1/dw' 8 64 64 128 (4194304)
I0510 14:48:30.247316  5307 layer_factory.hpp:172] Creating layer 'conv3_1/dw/bn' of type 'BatchNorm'
I0510 14:48:30.247321  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.247328  5307 net.cpp:200] Created Layer conv3_1/dw/bn (24)
I0510 14:48:30.247333  5307 net.cpp:572] conv3_1/dw/bn <- conv3_1/dw
I0510 14:48:30.247337  5307 net.cpp:527] conv3_1/dw/bn -> conv3_1/dw (in-place)
I0510 14:48:30.247715  5307 net.cpp:260] Setting up conv3_1/dw/bn
I0510 14:48:30.247725  5307 net.cpp:267] TEST Top shape for layer 24 'conv3_1/dw/bn' 8 64 64 128 (4194304)
I0510 14:48:30.247738  5307 layer_factory.hpp:172] Creating layer 'conv3_1/dw/scale' of type 'Scale'
I0510 14:48:30.247743  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.247751  5307 net.cpp:200] Created Layer conv3_1/dw/scale (25)
I0510 14:48:30.247756  5307 net.cpp:572] conv3_1/dw/scale <- conv3_1/dw
I0510 14:48:30.247761  5307 net.cpp:527] conv3_1/dw/scale -> conv3_1/dw (in-place)
I0510 14:48:30.247802  5307 layer_factory.hpp:172] Creating layer 'conv3_1/dw/scale' of type 'Bias'
I0510 14:48:30.247807  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.247918  5307 net.cpp:260] Setting up conv3_1/dw/scale
I0510 14:48:30.247925  5307 net.cpp:267] TEST Top shape for layer 25 'conv3_1/dw/scale' 8 64 64 128 (4194304)
I0510 14:48:30.247941  5307 layer_factory.hpp:172] Creating layer 'relu3_1/dw' of type 'ReLU'
I0510 14:48:30.247951  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.247962  5307 net.cpp:200] Created Layer relu3_1/dw (26)
I0510 14:48:30.247972  5307 net.cpp:572] relu3_1/dw <- conv3_1/dw
I0510 14:48:30.247982  5307 net.cpp:527] relu3_1/dw -> conv3_1/dw (in-place)
I0510 14:48:30.247993  5307 net.cpp:260] Setting up relu3_1/dw
I0510 14:48:30.248004  5307 net.cpp:267] TEST Top shape for layer 26 'relu3_1/dw' 8 64 64 128 (4194304)
I0510 14:48:30.248014  5307 layer_factory.hpp:172] Creating layer 'conv3_1/sep' of type 'Convolution'
I0510 14:48:30.248024  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.248037  5307 net.cpp:200] Created Layer conv3_1/sep (27)
I0510 14:48:30.248047  5307 net.cpp:572] conv3_1/sep <- conv3_1/dw
I0510 14:48:30.248057  5307 net.cpp:542] conv3_1/sep -> conv3_1/sep
I0510 14:48:30.248392  5307 net.cpp:260] Setting up conv3_1/sep
I0510 14:48:30.248400  5307 net.cpp:267] TEST Top shape for layer 27 'conv3_1/sep' 8 64 64 128 (4194304)
I0510 14:48:30.248407  5307 layer_factory.hpp:172] Creating layer 'conv3_1/sep/bn' of type 'BatchNorm'
I0510 14:48:30.248411  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.248417  5307 net.cpp:200] Created Layer conv3_1/sep/bn (28)
I0510 14:48:30.248421  5307 net.cpp:572] conv3_1/sep/bn <- conv3_1/sep
I0510 14:48:30.248426  5307 net.cpp:527] conv3_1/sep/bn -> conv3_1/sep (in-place)
I0510 14:48:30.248793  5307 net.cpp:260] Setting up conv3_1/sep/bn
I0510 14:48:30.248801  5307 net.cpp:267] TEST Top shape for layer 28 'conv3_1/sep/bn' 8 64 64 128 (4194304)
I0510 14:48:30.248826  5307 layer_factory.hpp:172] Creating layer 'conv3_1/sep/scale' of type 'Scale'
I0510 14:48:30.248831  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.248837  5307 net.cpp:200] Created Layer conv3_1/sep/scale (29)
I0510 14:48:30.248842  5307 net.cpp:572] conv3_1/sep/scale <- conv3_1/sep
I0510 14:48:30.248845  5307 net.cpp:527] conv3_1/sep/scale -> conv3_1/sep (in-place)
I0510 14:48:30.248880  5307 layer_factory.hpp:172] Creating layer 'conv3_1/sep/scale' of type 'Bias'
I0510 14:48:30.248893  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.249006  5307 net.cpp:260] Setting up conv3_1/sep/scale
I0510 14:48:30.249013  5307 net.cpp:267] TEST Top shape for layer 29 'conv3_1/sep/scale' 8 64 64 128 (4194304)
I0510 14:48:30.249020  5307 layer_factory.hpp:172] Creating layer 'relu3_1/sep' of type 'ReLU'
I0510 14:48:30.249025  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.249030  5307 net.cpp:200] Created Layer relu3_1/sep (30)
I0510 14:48:30.249034  5307 net.cpp:572] relu3_1/sep <- conv3_1/sep
I0510 14:48:30.249039  5307 net.cpp:527] relu3_1/sep -> conv3_1/sep (in-place)
I0510 14:48:30.249044  5307 net.cpp:260] Setting up relu3_1/sep
I0510 14:48:30.249049  5307 net.cpp:267] TEST Top shape for layer 30 'relu3_1/sep' 8 64 64 128 (4194304)
I0510 14:48:30.249053  5307 layer_factory.hpp:172] Creating layer 'conv3_2/dw' of type 'Convolution'
I0510 14:48:30.249058  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.249065  5307 net.cpp:200] Created Layer conv3_2/dw (31)
I0510 14:48:30.249069  5307 net.cpp:572] conv3_2/dw <- conv3_1/sep
I0510 14:48:30.249074  5307 net.cpp:542] conv3_2/dw -> conv3_2/dw
I0510 14:48:30.249277  5307 net.cpp:260] Setting up conv3_2/dw
I0510 14:48:30.249285  5307 net.cpp:267] TEST Top shape for layer 31 'conv3_2/dw' 8 64 32 64 (1048576)
I0510 14:48:30.249291  5307 layer_factory.hpp:172] Creating layer 'conv3_2/dw/bn' of type 'BatchNorm'
I0510 14:48:30.249296  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.249305  5307 net.cpp:200] Created Layer conv3_2/dw/bn (32)
I0510 14:48:30.249310  5307 net.cpp:572] conv3_2/dw/bn <- conv3_2/dw
I0510 14:48:30.249315  5307 net.cpp:527] conv3_2/dw/bn -> conv3_2/dw (in-place)
I0510 14:48:30.249661  5307 net.cpp:260] Setting up conv3_2/dw/bn
I0510 14:48:30.249670  5307 net.cpp:267] TEST Top shape for layer 32 'conv3_2/dw/bn' 8 64 32 64 (1048576)
I0510 14:48:30.249685  5307 layer_factory.hpp:172] Creating layer 'conv3_2/dw/scale' of type 'Scale'
I0510 14:48:30.249694  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.249706  5307 net.cpp:200] Created Layer conv3_2/dw/scale (33)
I0510 14:48:30.249714  5307 net.cpp:572] conv3_2/dw/scale <- conv3_2/dw
I0510 14:48:30.249723  5307 net.cpp:527] conv3_2/dw/scale -> conv3_2/dw (in-place)
I0510 14:48:30.249765  5307 layer_factory.hpp:172] Creating layer 'conv3_2/dw/scale' of type 'Bias'
I0510 14:48:30.249776  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.249883  5307 net.cpp:260] Setting up conv3_2/dw/scale
I0510 14:48:30.249891  5307 net.cpp:267] TEST Top shape for layer 33 'conv3_2/dw/scale' 8 64 32 64 (1048576)
I0510 14:48:30.249898  5307 layer_factory.hpp:172] Creating layer 'relu3_2/dw' of type 'ReLU'
I0510 14:48:30.249903  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.249908  5307 net.cpp:200] Created Layer relu3_2/dw (34)
I0510 14:48:30.249913  5307 net.cpp:572] relu3_2/dw <- conv3_2/dw
I0510 14:48:30.249917  5307 net.cpp:527] relu3_2/dw -> conv3_2/dw (in-place)
I0510 14:48:30.249923  5307 net.cpp:260] Setting up relu3_2/dw
I0510 14:48:30.249938  5307 net.cpp:267] TEST Top shape for layer 34 'relu3_2/dw' 8 64 32 64 (1048576)
I0510 14:48:30.249953  5307 layer_factory.hpp:172] Creating layer 'conv3_2/sep' of type 'Convolution'
I0510 14:48:30.249963  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.249975  5307 net.cpp:200] Created Layer conv3_2/sep (35)
I0510 14:48:30.249984  5307 net.cpp:572] conv3_2/sep <- conv3_2/dw
I0510 14:48:30.249992  5307 net.cpp:542] conv3_2/sep -> conv3_2/sep
I0510 14:48:30.250567  5307 net.cpp:260] Setting up conv3_2/sep
I0510 14:48:30.250586  5307 net.cpp:267] TEST Top shape for layer 35 'conv3_2/sep' 8 128 32 64 (2097152)
I0510 14:48:30.250597  5307 layer_factory.hpp:172] Creating layer 'conv3_2/sep/bn' of type 'BatchNorm'
I0510 14:48:30.250604  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.250614  5307 net.cpp:200] Created Layer conv3_2/sep/bn (36)
I0510 14:48:30.250622  5307 net.cpp:572] conv3_2/sep/bn <- conv3_2/sep
I0510 14:48:30.250630  5307 net.cpp:527] conv3_2/sep/bn -> conv3_2/sep (in-place)
I0510 14:48:30.251098  5307 net.cpp:260] Setting up conv3_2/sep/bn
I0510 14:48:30.251116  5307 net.cpp:267] TEST Top shape for layer 36 'conv3_2/sep/bn' 8 128 32 64 (2097152)
I0510 14:48:30.251128  5307 layer_factory.hpp:172] Creating layer 'conv3_2/sep/scale' of type 'Scale'
I0510 14:48:30.251137  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.251147  5307 net.cpp:200] Created Layer conv3_2/sep/scale (37)
I0510 14:48:30.251157  5307 net.cpp:572] conv3_2/sep/scale <- conv3_2/sep
I0510 14:48:30.251164  5307 net.cpp:527] conv3_2/sep/scale -> conv3_2/sep (in-place)
I0510 14:48:30.251205  5307 layer_factory.hpp:172] Creating layer 'conv3_2/sep/scale' of type 'Bias'
I0510 14:48:30.251215  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.251317  5307 net.cpp:260] Setting up conv3_2/sep/scale
I0510 14:48:30.251330  5307 net.cpp:267] TEST Top shape for layer 37 'conv3_2/sep/scale' 8 128 32 64 (2097152)
I0510 14:48:30.251341  5307 layer_factory.hpp:172] Creating layer 'relu3_2/sep' of type 'ReLU'
I0510 14:48:30.251350  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.251360  5307 net.cpp:200] Created Layer relu3_2/sep (38)
I0510 14:48:30.251369  5307 net.cpp:572] relu3_2/sep <- conv3_2/sep
I0510 14:48:30.251379  5307 net.cpp:527] relu3_2/sep -> conv3_2/sep (in-place)
I0510 14:48:30.251389  5307 net.cpp:260] Setting up relu3_2/sep
I0510 14:48:30.251399  5307 net.cpp:267] TEST Top shape for layer 38 'relu3_2/sep' 8 128 32 64 (2097152)
I0510 14:48:30.251407  5307 layer_factory.hpp:172] Creating layer 'conv4_1/dw' of type 'Convolution'
I0510 14:48:30.251416  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.251430  5307 net.cpp:200] Created Layer conv4_1/dw (39)
I0510 14:48:30.251438  5307 net.cpp:572] conv4_1/dw <- conv3_2/sep
I0510 14:48:30.251447  5307 net.cpp:542] conv4_1/dw -> conv4_1/dw
I0510 14:48:30.251679  5307 net.cpp:260] Setting up conv4_1/dw
I0510 14:48:30.251698  5307 net.cpp:267] TEST Top shape for layer 39 'conv4_1/dw' 8 128 32 64 (2097152)
I0510 14:48:30.251710  5307 layer_factory.hpp:172] Creating layer 'conv4_1/dw/bn' of type 'BatchNorm'
I0510 14:48:30.251720  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.251732  5307 net.cpp:200] Created Layer conv4_1/dw/bn (40)
I0510 14:48:30.251742  5307 net.cpp:572] conv4_1/dw/bn <- conv4_1/dw
I0510 14:48:30.251752  5307 net.cpp:527] conv4_1/dw/bn -> conv4_1/dw (in-place)
I0510 14:48:30.252107  5307 net.cpp:260] Setting up conv4_1/dw/bn
I0510 14:48:30.252125  5307 net.cpp:267] TEST Top shape for layer 40 'conv4_1/dw/bn' 8 128 32 64 (2097152)
I0510 14:48:30.252138  5307 layer_factory.hpp:172] Creating layer 'conv4_1/dw/scale' of type 'Scale'
I0510 14:48:30.252153  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.252174  5307 net.cpp:200] Created Layer conv4_1/dw/scale (41)
I0510 14:48:30.252184  5307 net.cpp:572] conv4_1/dw/scale <- conv4_1/dw
I0510 14:48:30.252193  5307 net.cpp:527] conv4_1/dw/scale -> conv4_1/dw (in-place)
I0510 14:48:30.252236  5307 layer_factory.hpp:172] Creating layer 'conv4_1/dw/scale' of type 'Bias'
I0510 14:48:30.252249  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.252357  5307 net.cpp:260] Setting up conv4_1/dw/scale
I0510 14:48:30.252372  5307 net.cpp:267] TEST Top shape for layer 41 'conv4_1/dw/scale' 8 128 32 64 (2097152)
I0510 14:48:30.252387  5307 layer_factory.hpp:172] Creating layer 'relu4_1/dw' of type 'ReLU'
I0510 14:48:30.252398  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.252408  5307 net.cpp:200] Created Layer relu4_1/dw (42)
I0510 14:48:30.252418  5307 net.cpp:572] relu4_1/dw <- conv4_1/dw
I0510 14:48:30.252429  5307 net.cpp:527] relu4_1/dw -> conv4_1/dw (in-place)
I0510 14:48:30.252442  5307 net.cpp:260] Setting up relu4_1/dw
I0510 14:48:30.252454  5307 net.cpp:267] TEST Top shape for layer 42 'relu4_1/dw' 8 128 32 64 (2097152)
I0510 14:48:30.252465  5307 layer_factory.hpp:172] Creating layer 'conv4_1/sep' of type 'Convolution'
I0510 14:48:30.252475  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.252490  5307 net.cpp:200] Created Layer conv4_1/sep (43)
I0510 14:48:30.252501  5307 net.cpp:572] conv4_1/sep <- conv4_1/dw
I0510 14:48:30.252511  5307 net.cpp:542] conv4_1/sep -> conv4_1/sep
I0510 14:48:30.253233  5307 net.cpp:260] Setting up conv4_1/sep
I0510 14:48:30.253252  5307 net.cpp:267] TEST Top shape for layer 43 'conv4_1/sep' 8 128 32 64 (2097152)
I0510 14:48:30.253264  5307 layer_factory.hpp:172] Creating layer 'conv4_1/sep/bn' of type 'BatchNorm'
I0510 14:48:30.253273  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.253284  5307 net.cpp:200] Created Layer conv4_1/sep/bn (44)
I0510 14:48:30.253293  5307 net.cpp:572] conv4_1/sep/bn <- conv4_1/sep
I0510 14:48:30.253302  5307 net.cpp:527] conv4_1/sep/bn -> conv4_1/sep (in-place)
I0510 14:48:30.253645  5307 net.cpp:260] Setting up conv4_1/sep/bn
I0510 14:48:30.253659  5307 net.cpp:267] TEST Top shape for layer 44 'conv4_1/sep/bn' 8 128 32 64 (2097152)
I0510 14:48:30.253674  5307 layer_factory.hpp:172] Creating layer 'conv4_1/sep/scale' of type 'Scale'
I0510 14:48:30.253684  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.253695  5307 net.cpp:200] Created Layer conv4_1/sep/scale (45)
I0510 14:48:30.253705  5307 net.cpp:572] conv4_1/sep/scale <- conv4_1/sep
I0510 14:48:30.253713  5307 net.cpp:527] conv4_1/sep/scale -> conv4_1/sep (in-place)
I0510 14:48:30.253756  5307 layer_factory.hpp:172] Creating layer 'conv4_1/sep/scale' of type 'Bias'
I0510 14:48:30.253767  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.253870  5307 net.cpp:260] Setting up conv4_1/sep/scale
I0510 14:48:30.253882  5307 net.cpp:267] TEST Top shape for layer 45 'conv4_1/sep/scale' 8 128 32 64 (2097152)
I0510 14:48:30.253895  5307 layer_factory.hpp:172] Creating layer 'relu4_1/sep' of type 'ReLU'
I0510 14:48:30.253902  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.253912  5307 net.cpp:200] Created Layer relu4_1/sep (46)
I0510 14:48:30.253921  5307 net.cpp:572] relu4_1/sep <- conv4_1/sep
I0510 14:48:30.253929  5307 net.cpp:527] relu4_1/sep -> conv4_1/sep (in-place)
I0510 14:48:30.253939  5307 net.cpp:260] Setting up relu4_1/sep
I0510 14:48:30.253949  5307 net.cpp:267] TEST Top shape for layer 46 'relu4_1/sep' 8 128 32 64 (2097152)
I0510 14:48:30.253957  5307 layer_factory.hpp:172] Creating layer 'conv4_2/dw' of type 'Convolution'
I0510 14:48:30.253969  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.253988  5307 net.cpp:200] Created Layer conv4_2/dw (47)
I0510 14:48:30.253998  5307 net.cpp:572] conv4_2/dw <- conv4_1/sep
I0510 14:48:30.254006  5307 net.cpp:542] conv4_2/dw -> conv4_2/dw
I0510 14:48:30.254235  5307 net.cpp:260] Setting up conv4_2/dw
I0510 14:48:30.254248  5307 net.cpp:267] TEST Top shape for layer 47 'conv4_2/dw' 8 128 16 32 (524288)
I0510 14:48:30.254259  5307 layer_factory.hpp:172] Creating layer 'conv4_2/dw/bn' of type 'BatchNorm'
I0510 14:48:30.254268  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.254278  5307 net.cpp:200] Created Layer conv4_2/dw/bn (48)
I0510 14:48:30.254287  5307 net.cpp:572] conv4_2/dw/bn <- conv4_2/dw
I0510 14:48:30.254297  5307 net.cpp:527] conv4_2/dw/bn -> conv4_2/dw (in-place)
I0510 14:48:30.254638  5307 net.cpp:260] Setting up conv4_2/dw/bn
I0510 14:48:30.254652  5307 net.cpp:267] TEST Top shape for layer 48 'conv4_2/dw/bn' 8 128 16 32 (524288)
I0510 14:48:30.254663  5307 layer_factory.hpp:172] Creating layer 'conv4_2/dw/scale' of type 'Scale'
I0510 14:48:30.254673  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.254683  5307 net.cpp:200] Created Layer conv4_2/dw/scale (49)
I0510 14:48:30.254691  5307 net.cpp:572] conv4_2/dw/scale <- conv4_2/dw
I0510 14:48:30.254699  5307 net.cpp:527] conv4_2/dw/scale -> conv4_2/dw (in-place)
I0510 14:48:30.254740  5307 layer_factory.hpp:172] Creating layer 'conv4_2/dw/scale' of type 'Bias'
I0510 14:48:30.254750  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.254853  5307 net.cpp:260] Setting up conv4_2/dw/scale
I0510 14:48:30.254865  5307 net.cpp:267] TEST Top shape for layer 49 'conv4_2/dw/scale' 8 128 16 32 (524288)
I0510 14:48:30.254876  5307 layer_factory.hpp:172] Creating layer 'relu4_2/dw' of type 'ReLU'
I0510 14:48:30.254885  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.254895  5307 net.cpp:200] Created Layer relu4_2/dw (50)
I0510 14:48:30.254906  5307 net.cpp:572] relu4_2/dw <- conv4_2/dw
I0510 14:48:30.254916  5307 net.cpp:527] relu4_2/dw -> conv4_2/dw (in-place)
I0510 14:48:30.254928  5307 net.cpp:260] Setting up relu4_2/dw
I0510 14:48:30.254940  5307 net.cpp:267] TEST Top shape for layer 50 'relu4_2/dw' 8 128 16 32 (524288)
I0510 14:48:30.254951  5307 layer_factory.hpp:172] Creating layer 'conv4_2/sep' of type 'Convolution'
I0510 14:48:30.254961  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.254974  5307 net.cpp:200] Created Layer conv4_2/sep (51)
I0510 14:48:30.254982  5307 net.cpp:572] conv4_2/sep <- conv4_2/dw
I0510 14:48:30.254992  5307 net.cpp:542] conv4_2/sep -> conv4_2/sep
I0510 14:48:30.256186  5307 net.cpp:260] Setting up conv4_2/sep
I0510 14:48:30.256203  5307 net.cpp:267] TEST Top shape for layer 51 'conv4_2/sep' 8 256 16 32 (1048576)
I0510 14:48:30.256216  5307 layer_factory.hpp:172] Creating layer 'conv4_2/sep/bn' of type 'BatchNorm'
I0510 14:48:30.256224  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.256237  5307 net.cpp:200] Created Layer conv4_2/sep/bn (52)
I0510 14:48:30.256247  5307 net.cpp:572] conv4_2/sep/bn <- conv4_2/sep
I0510 14:48:30.256256  5307 net.cpp:527] conv4_2/sep/bn -> conv4_2/sep (in-place)
I0510 14:48:30.256623  5307 net.cpp:260] Setting up conv4_2/sep/bn
I0510 14:48:30.256640  5307 net.cpp:267] TEST Top shape for layer 52 'conv4_2/sep/bn' 8 256 16 32 (1048576)
I0510 14:48:30.256654  5307 layer_factory.hpp:172] Creating layer 'conv4_2/sep/scale' of type 'Scale'
I0510 14:48:30.256664  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.256675  5307 net.cpp:200] Created Layer conv4_2/sep/scale (53)
I0510 14:48:30.256683  5307 net.cpp:572] conv4_2/sep/scale <- conv4_2/sep
I0510 14:48:30.256696  5307 net.cpp:527] conv4_2/sep/scale -> conv4_2/sep (in-place)
I0510 14:48:30.256747  5307 layer_factory.hpp:172] Creating layer 'conv4_2/sep/scale' of type 'Bias'
I0510 14:48:30.256757  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.256861  5307 net.cpp:260] Setting up conv4_2/sep/scale
I0510 14:48:30.256873  5307 net.cpp:267] TEST Top shape for layer 53 'conv4_2/sep/scale' 8 256 16 32 (1048576)
I0510 14:48:30.256886  5307 layer_factory.hpp:172] Creating layer 'relu4_2/sep' of type 'ReLU'
I0510 14:48:30.256893  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.256903  5307 net.cpp:200] Created Layer relu4_2/sep (54)
I0510 14:48:30.256912  5307 net.cpp:572] relu4_2/sep <- conv4_2/sep
I0510 14:48:30.256920  5307 net.cpp:527] relu4_2/sep -> conv4_2/sep (in-place)
I0510 14:48:30.256932  5307 net.cpp:260] Setting up relu4_2/sep
I0510 14:48:30.256940  5307 net.cpp:267] TEST Top shape for layer 54 'relu4_2/sep' 8 256 16 32 (1048576)
I0510 14:48:30.256949  5307 layer_factory.hpp:172] Creating layer 'conv5_1/dw' of type 'Convolution'
I0510 14:48:30.256958  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.256971  5307 net.cpp:200] Created Layer conv5_1/dw (55)
I0510 14:48:30.256980  5307 net.cpp:572] conv5_1/dw <- conv4_2/sep
I0510 14:48:30.256989  5307 net.cpp:542] conv5_1/dw -> conv5_1/dw
I0510 14:48:30.257251  5307 net.cpp:260] Setting up conv5_1/dw
I0510 14:48:30.257264  5307 net.cpp:267] TEST Top shape for layer 55 'conv5_1/dw' 8 256 16 32 (1048576)
I0510 14:48:30.257275  5307 layer_factory.hpp:172] Creating layer 'conv5_1/dw/bn' of type 'BatchNorm'
I0510 14:48:30.257284  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.257295  5307 net.cpp:200] Created Layer conv5_1/dw/bn (56)
I0510 14:48:30.257304  5307 net.cpp:572] conv5_1/dw/bn <- conv5_1/dw
I0510 14:48:30.257313  5307 net.cpp:527] conv5_1/dw/bn -> conv5_1/dw (in-place)
I0510 14:48:30.257652  5307 net.cpp:260] Setting up conv5_1/dw/bn
I0510 14:48:30.257665  5307 net.cpp:267] TEST Top shape for layer 56 'conv5_1/dw/bn' 8 256 16 32 (1048576)
I0510 14:48:30.257678  5307 layer_factory.hpp:172] Creating layer 'conv5_1/dw/scale' of type 'Scale'
I0510 14:48:30.257686  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.257697  5307 net.cpp:200] Created Layer conv5_1/dw/scale (57)
I0510 14:48:30.257706  5307 net.cpp:572] conv5_1/dw/scale <- conv5_1/dw
I0510 14:48:30.257714  5307 net.cpp:527] conv5_1/dw/scale -> conv5_1/dw (in-place)
I0510 14:48:30.257757  5307 layer_factory.hpp:172] Creating layer 'conv5_1/dw/scale' of type 'Bias'
I0510 14:48:30.257767  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.257871  5307 net.cpp:260] Setting up conv5_1/dw/scale
I0510 14:48:30.257884  5307 net.cpp:267] TEST Top shape for layer 57 'conv5_1/dw/scale' 8 256 16 32 (1048576)
I0510 14:48:30.257895  5307 layer_factory.hpp:172] Creating layer 'relu5_1/dw' of type 'ReLU'
I0510 14:48:30.257903  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.257912  5307 net.cpp:200] Created Layer relu5_1/dw (58)
I0510 14:48:30.257921  5307 net.cpp:572] relu5_1/dw <- conv5_1/dw
I0510 14:48:30.257930  5307 net.cpp:527] relu5_1/dw -> conv5_1/dw (in-place)
I0510 14:48:30.257941  5307 net.cpp:260] Setting up relu5_1/dw
I0510 14:48:30.257951  5307 net.cpp:267] TEST Top shape for layer 58 'relu5_1/dw' 8 256 16 32 (1048576)
I0510 14:48:30.257958  5307 layer_factory.hpp:172] Creating layer 'conv5_1/sep' of type 'Convolution'
I0510 14:48:30.257967  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.257982  5307 net.cpp:200] Created Layer conv5_1/sep (59)
I0510 14:48:30.257990  5307 net.cpp:572] conv5_1/sep <- conv5_1/dw
I0510 14:48:30.258002  5307 net.cpp:542] conv5_1/sep -> conv5_1/sep
I0510 14:48:30.260092  5307 net.cpp:260] Setting up conv5_1/sep
I0510 14:48:30.260109  5307 net.cpp:267] TEST Top shape for layer 59 'conv5_1/sep' 8 256 16 32 (1048576)
I0510 14:48:30.260119  5307 layer_factory.hpp:172] Creating layer 'conv5_1/sep/bn' of type 'BatchNorm'
I0510 14:48:30.260128  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.260138  5307 net.cpp:200] Created Layer conv5_1/sep/bn (60)
I0510 14:48:30.260145  5307 net.cpp:572] conv5_1/sep/bn <- conv5_1/sep
I0510 14:48:30.260154  5307 net.cpp:527] conv5_1/sep/bn -> conv5_1/sep (in-place)
I0510 14:48:30.260478  5307 net.cpp:260] Setting up conv5_1/sep/bn
I0510 14:48:30.260491  5307 net.cpp:267] TEST Top shape for layer 60 'conv5_1/sep/bn' 8 256 16 32 (1048576)
I0510 14:48:30.260504  5307 layer_factory.hpp:172] Creating layer 'conv5_1/sep/scale' of type 'Scale'
I0510 14:48:30.260514  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.260529  5307 net.cpp:200] Created Layer conv5_1/sep/scale (61)
I0510 14:48:30.260540  5307 net.cpp:572] conv5_1/sep/scale <- conv5_1/sep
I0510 14:48:30.260550  5307 net.cpp:527] conv5_1/sep/scale -> conv5_1/sep (in-place)
I0510 14:48:30.260593  5307 layer_factory.hpp:172] Creating layer 'conv5_1/sep/scale' of type 'Bias'
I0510 14:48:30.260604  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.260711  5307 net.cpp:260] Setting up conv5_1/sep/scale
I0510 14:48:30.260723  5307 net.cpp:267] TEST Top shape for layer 61 'conv5_1/sep/scale' 8 256 16 32 (1048576)
I0510 14:48:30.260735  5307 layer_factory.hpp:172] Creating layer 'relu5_1/sep' of type 'ReLU'
I0510 14:48:30.260743  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.260752  5307 net.cpp:200] Created Layer relu5_1/sep (62)
I0510 14:48:30.260761  5307 net.cpp:572] relu5_1/sep <- conv5_1/sep
I0510 14:48:30.260771  5307 net.cpp:527] relu5_1/sep -> conv5_1/sep (in-place)
I0510 14:48:30.260782  5307 net.cpp:260] Setting up relu5_1/sep
I0510 14:48:30.260792  5307 net.cpp:267] TEST Top shape for layer 62 'relu5_1/sep' 8 256 16 32 (1048576)
I0510 14:48:30.260800  5307 layer_factory.hpp:172] Creating layer 'conv5_2/dw' of type 'Convolution'
I0510 14:48:30.260809  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.260821  5307 net.cpp:200] Created Layer conv5_2/dw (63)
I0510 14:48:30.260830  5307 net.cpp:572] conv5_2/dw <- conv5_1/sep
I0510 14:48:30.260838  5307 net.cpp:542] conv5_2/dw -> conv5_2/dw
I0510 14:48:30.261092  5307 net.cpp:260] Setting up conv5_2/dw
I0510 14:48:30.261106  5307 net.cpp:267] TEST Top shape for layer 63 'conv5_2/dw' 8 256 16 32 (1048576)
I0510 14:48:30.261116  5307 layer_factory.hpp:172] Creating layer 'conv5_2/dw/bn' of type 'BatchNorm'
I0510 14:48:30.261124  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.261135  5307 net.cpp:200] Created Layer conv5_2/dw/bn (64)
I0510 14:48:30.261144  5307 net.cpp:572] conv5_2/dw/bn <- conv5_2/dw
I0510 14:48:30.261152  5307 net.cpp:527] conv5_2/dw/bn -> conv5_2/dw (in-place)
I0510 14:48:30.261476  5307 net.cpp:260] Setting up conv5_2/dw/bn
I0510 14:48:30.261487  5307 net.cpp:267] TEST Top shape for layer 64 'conv5_2/dw/bn' 8 256 16 32 (1048576)
I0510 14:48:30.261499  5307 layer_factory.hpp:172] Creating layer 'conv5_2/dw/scale' of type 'Scale'
I0510 14:48:30.261507  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.261519  5307 net.cpp:200] Created Layer conv5_2/dw/scale (65)
I0510 14:48:30.261528  5307 net.cpp:572] conv5_2/dw/scale <- conv5_2/dw
I0510 14:48:30.261535  5307 net.cpp:527] conv5_2/dw/scale -> conv5_2/dw (in-place)
I0510 14:48:30.261574  5307 layer_factory.hpp:172] Creating layer 'conv5_2/dw/scale' of type 'Bias'
I0510 14:48:30.261586  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.261684  5307 net.cpp:260] Setting up conv5_2/dw/scale
I0510 14:48:30.261696  5307 net.cpp:267] TEST Top shape for layer 65 'conv5_2/dw/scale' 8 256 16 32 (1048576)
I0510 14:48:30.261708  5307 layer_factory.hpp:172] Creating layer 'relu5_2/dw' of type 'ReLU'
I0510 14:48:30.261715  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.261723  5307 net.cpp:200] Created Layer relu5_2/dw (66)
I0510 14:48:30.261732  5307 net.cpp:572] relu5_2/dw <- conv5_2/dw
I0510 14:48:30.261740  5307 net.cpp:527] relu5_2/dw -> conv5_2/dw (in-place)
I0510 14:48:30.261749  5307 net.cpp:260] Setting up relu5_2/dw
I0510 14:48:30.261759  5307 net.cpp:267] TEST Top shape for layer 66 'relu5_2/dw' 8 256 16 32 (1048576)
I0510 14:48:30.261766  5307 layer_factory.hpp:172] Creating layer 'conv5_2/sep' of type 'Convolution'
I0510 14:48:30.261775  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.261786  5307 net.cpp:200] Created Layer conv5_2/sep (67)
I0510 14:48:30.261795  5307 net.cpp:572] conv5_2/sep <- conv5_2/dw
I0510 14:48:30.261802  5307 net.cpp:542] conv5_2/sep -> conv5_2/sep
I0510 14:48:30.263923  5307 net.cpp:260] Setting up conv5_2/sep
I0510 14:48:30.263937  5307 net.cpp:267] TEST Top shape for layer 67 'conv5_2/sep' 8 256 16 32 (1048576)
I0510 14:48:30.263947  5307 layer_factory.hpp:172] Creating layer 'conv5_2/sep/bn' of type 'BatchNorm'
I0510 14:48:30.263955  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.263967  5307 net.cpp:200] Created Layer conv5_2/sep/bn (68)
I0510 14:48:30.263975  5307 net.cpp:572] conv5_2/sep/bn <- conv5_2/sep
I0510 14:48:30.263983  5307 net.cpp:527] conv5_2/sep/bn -> conv5_2/sep (in-place)
I0510 14:48:30.264274  5307 net.cpp:260] Setting up conv5_2/sep/bn
I0510 14:48:30.264288  5307 net.cpp:267] TEST Top shape for layer 68 'conv5_2/sep/bn' 8 256 16 32 (1048576)
I0510 14:48:30.264300  5307 layer_factory.hpp:172] Creating layer 'conv5_2/sep/scale' of type 'Scale'
I0510 14:48:30.264310  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.264320  5307 net.cpp:200] Created Layer conv5_2/sep/scale (69)
I0510 14:48:30.264329  5307 net.cpp:572] conv5_2/sep/scale <- conv5_2/sep
I0510 14:48:30.264338  5307 net.cpp:527] conv5_2/sep/scale -> conv5_2/sep (in-place)
I0510 14:48:30.264381  5307 layer_factory.hpp:172] Creating layer 'conv5_2/sep/scale' of type 'Bias'
I0510 14:48:30.264392  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.264497  5307 net.cpp:260] Setting up conv5_2/sep/scale
I0510 14:48:30.264510  5307 net.cpp:267] TEST Top shape for layer 69 'conv5_2/sep/scale' 8 256 16 32 (1048576)
I0510 14:48:30.264521  5307 layer_factory.hpp:172] Creating layer 'relu5_2/sep' of type 'ReLU'
I0510 14:48:30.264536  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.264545  5307 net.cpp:200] Created Layer relu5_2/sep (70)
I0510 14:48:30.264554  5307 net.cpp:572] relu5_2/sep <- conv5_2/sep
I0510 14:48:30.264564  5307 net.cpp:527] relu5_2/sep -> conv5_2/sep (in-place)
I0510 14:48:30.264575  5307 net.cpp:260] Setting up relu5_2/sep
I0510 14:48:30.264585  5307 net.cpp:267] TEST Top shape for layer 70 'relu5_2/sep' 8 256 16 32 (1048576)
I0510 14:48:30.264592  5307 layer_factory.hpp:172] Creating layer 'conv5_3/dw' of type 'Convolution'
I0510 14:48:30.264601  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.264616  5307 net.cpp:200] Created Layer conv5_3/dw (71)
I0510 14:48:30.264626  5307 net.cpp:572] conv5_3/dw <- conv5_2/sep
I0510 14:48:30.264633  5307 net.cpp:542] conv5_3/dw -> conv5_3/dw
I0510 14:48:30.264899  5307 net.cpp:260] Setting up conv5_3/dw
I0510 14:48:30.264914  5307 net.cpp:267] TEST Top shape for layer 71 'conv5_3/dw' 8 256 16 32 (1048576)
I0510 14:48:30.264930  5307 layer_factory.hpp:172] Creating layer 'conv5_3/dw/bn' of type 'BatchNorm'
I0510 14:48:30.264946  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.264956  5307 net.cpp:200] Created Layer conv5_3/dw/bn (72)
I0510 14:48:30.264966  5307 net.cpp:572] conv5_3/dw/bn <- conv5_3/dw
I0510 14:48:30.264974  5307 net.cpp:527] conv5_3/dw/bn -> conv5_3/dw (in-place)
I0510 14:48:30.265358  5307 net.cpp:260] Setting up conv5_3/dw/bn
I0510 14:48:30.265375  5307 net.cpp:267] TEST Top shape for layer 72 'conv5_3/dw/bn' 8 256 16 32 (1048576)
I0510 14:48:30.265388  5307 layer_factory.hpp:172] Creating layer 'conv5_3/dw/scale' of type 'Scale'
I0510 14:48:30.265398  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.265409  5307 net.cpp:200] Created Layer conv5_3/dw/scale (73)
I0510 14:48:30.265419  5307 net.cpp:572] conv5_3/dw/scale <- conv5_3/dw
I0510 14:48:30.265429  5307 net.cpp:527] conv5_3/dw/scale -> conv5_3/dw (in-place)
I0510 14:48:30.265482  5307 layer_factory.hpp:172] Creating layer 'conv5_3/dw/scale' of type 'Bias'
I0510 14:48:30.265493  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.265604  5307 net.cpp:260] Setting up conv5_3/dw/scale
I0510 14:48:30.265615  5307 net.cpp:267] TEST Top shape for layer 73 'conv5_3/dw/scale' 8 256 16 32 (1048576)
I0510 14:48:30.265626  5307 layer_factory.hpp:172] Creating layer 'relu5_3/dw' of type 'ReLU'
I0510 14:48:30.265635  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.265643  5307 net.cpp:200] Created Layer relu5_3/dw (74)
I0510 14:48:30.265651  5307 net.cpp:572] relu5_3/dw <- conv5_3/dw
I0510 14:48:30.265658  5307 net.cpp:527] relu5_3/dw -> conv5_3/dw (in-place)
I0510 14:48:30.265668  5307 net.cpp:260] Setting up relu5_3/dw
I0510 14:48:30.265676  5307 net.cpp:267] TEST Top shape for layer 74 'relu5_3/dw' 8 256 16 32 (1048576)
I0510 14:48:30.265684  5307 layer_factory.hpp:172] Creating layer 'conv5_3/sep' of type 'Convolution'
I0510 14:48:30.265692  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.265704  5307 net.cpp:200] Created Layer conv5_3/sep (75)
I0510 14:48:30.265712  5307 net.cpp:572] conv5_3/sep <- conv5_3/dw
I0510 14:48:30.265720  5307 net.cpp:542] conv5_3/sep -> conv5_3/sep
I0510 14:48:30.277580  5307 net.cpp:260] Setting up conv5_3/sep
I0510 14:48:30.277678  5307 net.cpp:267] TEST Top shape for layer 75 'conv5_3/sep' 8 256 16 32 (1048576)
I0510 14:48:30.277724  5307 layer_factory.hpp:172] Creating layer 'conv5_3/sep/bn' of type 'BatchNorm'
I0510 14:48:30.277750  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.277782  5307 net.cpp:200] Created Layer conv5_3/sep/bn (76)
I0510 14:48:30.277806  5307 net.cpp:572] conv5_3/sep/bn <- conv5_3/sep
I0510 14:48:30.277829  5307 net.cpp:527] conv5_3/sep/bn -> conv5_3/sep (in-place)
I0510 14:48:30.278512  5307 net.cpp:260] Setting up conv5_3/sep/bn
I0510 14:48:30.278524  5307 net.cpp:267] TEST Top shape for layer 76 'conv5_3/sep/bn' 8 256 16 32 (1048576)
I0510 14:48:30.278535  5307 layer_factory.hpp:172] Creating layer 'conv5_3/sep/scale' of type 'Scale'
I0510 14:48:30.278543  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.278571  5307 net.cpp:200] Created Layer conv5_3/sep/scale (77)
I0510 14:48:30.278589  5307 net.cpp:572] conv5_3/sep/scale <- conv5_3/sep
I0510 14:48:30.278605  5307 net.cpp:527] conv5_3/sep/scale -> conv5_3/sep (in-place)
I0510 14:48:30.278686  5307 layer_factory.hpp:172] Creating layer 'conv5_3/sep/scale' of type 'Bias'
I0510 14:48:30.278695  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.279238  5307 net.cpp:260] Setting up conv5_3/sep/scale
I0510 14:48:30.279259  5307 net.cpp:267] TEST Top shape for layer 77 'conv5_3/sep/scale' 8 256 16 32 (1048576)
I0510 14:48:30.279630  5307 layer_factory.hpp:172] Creating layer 'relu5_3/sep' of type 'ReLU'
I0510 14:48:30.279650  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.279662  5307 net.cpp:200] Created Layer relu5_3/sep (78)
I0510 14:48:30.279671  5307 net.cpp:572] relu5_3/sep <- conv5_3/sep
I0510 14:48:30.279681  5307 net.cpp:527] relu5_3/sep -> conv5_3/sep (in-place)
I0510 14:48:30.279696  5307 net.cpp:260] Setting up relu5_3/sep
I0510 14:48:30.279707  5307 net.cpp:267] TEST Top shape for layer 78 'relu5_3/sep' 8 256 16 32 (1048576)
I0510 14:48:30.279716  5307 layer_factory.hpp:172] Creating layer 'conv5_4/dw' of type 'Convolution'
I0510 14:48:30.279726  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.279747  5307 net.cpp:200] Created Layer conv5_4/dw (79)
I0510 14:48:30.279757  5307 net.cpp:572] conv5_4/dw <- conv5_3/sep
I0510 14:48:30.279765  5307 net.cpp:542] conv5_4/dw -> conv5_4/dw
I0510 14:48:30.280048  5307 net.cpp:260] Setting up conv5_4/dw
I0510 14:48:30.280062  5307 net.cpp:267] TEST Top shape for layer 79 'conv5_4/dw' 8 256 16 32 (1048576)
I0510 14:48:30.280073  5307 layer_factory.hpp:172] Creating layer 'conv5_4/dw/bn' of type 'BatchNorm'
I0510 14:48:30.280082  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.280093  5307 net.cpp:200] Created Layer conv5_4/dw/bn (80)
I0510 14:48:30.280102  5307 net.cpp:572] conv5_4/dw/bn <- conv5_4/dw
I0510 14:48:30.280112  5307 net.cpp:527] conv5_4/dw/bn -> conv5_4/dw (in-place)
I0510 14:48:30.281548  5307 net.cpp:260] Setting up conv5_4/dw/bn
I0510 14:48:30.281565  5307 net.cpp:267] TEST Top shape for layer 80 'conv5_4/dw/bn' 8 256 16 32 (1048576)
I0510 14:48:30.281579  5307 layer_factory.hpp:172] Creating layer 'conv5_4/dw/scale' of type 'Scale'
I0510 14:48:30.281587  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.281599  5307 net.cpp:200] Created Layer conv5_4/dw/scale (81)
I0510 14:48:30.281606  5307 net.cpp:572] conv5_4/dw/scale <- conv5_4/dw
I0510 14:48:30.281615  5307 net.cpp:527] conv5_4/dw/scale -> conv5_4/dw (in-place)
I0510 14:48:30.281661  5307 layer_factory.hpp:172] Creating layer 'conv5_4/dw/scale' of type 'Bias'
I0510 14:48:30.281672  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.281785  5307 net.cpp:260] Setting up conv5_4/dw/scale
I0510 14:48:30.281801  5307 net.cpp:267] TEST Top shape for layer 81 'conv5_4/dw/scale' 8 256 16 32 (1048576)
I0510 14:48:30.281816  5307 layer_factory.hpp:172] Creating layer 'relu5_4/dw' of type 'ReLU'
I0510 14:48:30.281826  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.281837  5307 net.cpp:200] Created Layer relu5_4/dw (82)
I0510 14:48:30.281848  5307 net.cpp:572] relu5_4/dw <- conv5_4/dw
I0510 14:48:30.281859  5307 net.cpp:527] relu5_4/dw -> conv5_4/dw (in-place)
I0510 14:48:30.281872  5307 net.cpp:260] Setting up relu5_4/dw
I0510 14:48:30.282164  5307 net.cpp:267] TEST Top shape for layer 82 'relu5_4/dw' 8 256 16 32 (1048576)
I0510 14:48:30.282176  5307 layer_factory.hpp:172] Creating layer 'conv5_4/sep' of type 'Convolution'
I0510 14:48:30.282184  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.282199  5307 net.cpp:200] Created Layer conv5_4/sep (83)
I0510 14:48:30.282209  5307 net.cpp:572] conv5_4/sep <- conv5_4/dw
I0510 14:48:30.282219  5307 net.cpp:542] conv5_4/sep -> conv5_4/sep
I0510 14:48:30.288540  5307 net.cpp:260] Setting up conv5_4/sep
I0510 14:48:30.288624  5307 net.cpp:267] TEST Top shape for layer 83 'conv5_4/sep' 8 256 16 32 (1048576)
I0510 14:48:30.288655  5307 layer_factory.hpp:172] Creating layer 'conv5_4/sep/bn' of type 'BatchNorm'
I0510 14:48:30.288674  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.288705  5307 net.cpp:200] Created Layer conv5_4/sep/bn (84)
I0510 14:48:30.288733  5307 net.cpp:572] conv5_4/sep/bn <- conv5_4/sep
I0510 14:48:30.288749  5307 net.cpp:527] conv5_4/sep/bn -> conv5_4/sep (in-place)
I0510 14:48:30.289172  5307 net.cpp:260] Setting up conv5_4/sep/bn
I0510 14:48:30.289194  5307 net.cpp:267] TEST Top shape for layer 84 'conv5_4/sep/bn' 8 256 16 32 (1048576)
I0510 14:48:30.289214  5307 layer_factory.hpp:172] Creating layer 'conv5_4/sep/scale' of type 'Scale'
I0510 14:48:30.289229  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.289247  5307 net.cpp:200] Created Layer conv5_4/sep/scale (85)
I0510 14:48:30.289263  5307 net.cpp:572] conv5_4/sep/scale <- conv5_4/sep
I0510 14:48:30.289278  5307 net.cpp:527] conv5_4/sep/scale -> conv5_4/sep (in-place)
I0510 14:48:30.289335  5307 layer_factory.hpp:172] Creating layer 'conv5_4/sep/scale' of type 'Bias'
I0510 14:48:30.289351  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.289476  5307 net.cpp:260] Setting up conv5_4/sep/scale
I0510 14:48:30.289496  5307 net.cpp:267] TEST Top shape for layer 85 'conv5_4/sep/scale' 8 256 16 32 (1048576)
I0510 14:48:30.289515  5307 layer_factory.hpp:172] Creating layer 'relu5_4/sep' of type 'ReLU'
I0510 14:48:30.289530  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.289546  5307 net.cpp:200] Created Layer relu5_4/sep (86)
I0510 14:48:30.289561  5307 net.cpp:572] relu5_4/sep <- conv5_4/sep
I0510 14:48:30.289575  5307 net.cpp:527] relu5_4/sep -> conv5_4/sep (in-place)
I0510 14:48:30.289592  5307 net.cpp:260] Setting up relu5_4/sep
I0510 14:48:30.289608  5307 net.cpp:267] TEST Top shape for layer 86 'relu5_4/sep' 8 256 16 32 (1048576)
I0510 14:48:30.289626  5307 layer_factory.hpp:172] Creating layer 'conv5_5/dw' of type 'Convolution'
I0510 14:48:30.289643  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.289662  5307 net.cpp:200] Created Layer conv5_5/dw (87)
I0510 14:48:30.289677  5307 net.cpp:572] conv5_5/dw <- conv5_4/sep
I0510 14:48:30.289691  5307 net.cpp:542] conv5_5/dw -> conv5_5/dw
I0510 14:48:30.289973  5307 net.cpp:260] Setting up conv5_5/dw
I0510 14:48:30.289995  5307 net.cpp:267] TEST Top shape for layer 87 'conv5_5/dw' 8 256 16 32 (1048576)
I0510 14:48:30.290016  5307 layer_factory.hpp:172] Creating layer 'conv5_5/dw/bn' of type 'BatchNorm'
I0510 14:48:30.290036  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.290056  5307 net.cpp:200] Created Layer conv5_5/dw/bn (88)
I0510 14:48:30.290076  5307 net.cpp:572] conv5_5/dw/bn <- conv5_5/dw
I0510 14:48:30.290094  5307 net.cpp:527] conv5_5/dw/bn -> conv5_5/dw (in-place)
I0510 14:48:30.290571  5307 net.cpp:260] Setting up conv5_5/dw/bn
I0510 14:48:30.290596  5307 net.cpp:267] TEST Top shape for layer 88 'conv5_5/dw/bn' 8 256 16 32 (1048576)
I0510 14:48:30.290626  5307 layer_factory.hpp:172] Creating layer 'conv5_5/dw/scale' of type 'Scale'
I0510 14:48:30.290642  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.290661  5307 net.cpp:200] Created Layer conv5_5/dw/scale (89)
I0510 14:48:30.290678  5307 net.cpp:572] conv5_5/dw/scale <- conv5_5/dw
I0510 14:48:30.290693  5307 net.cpp:527] conv5_5/dw/scale -> conv5_5/dw (in-place)
I0510 14:48:30.290745  5307 layer_factory.hpp:172] Creating layer 'conv5_5/dw/scale' of type 'Bias'
I0510 14:48:30.290763  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.290879  5307 net.cpp:260] Setting up conv5_5/dw/scale
I0510 14:48:30.290900  5307 net.cpp:267] TEST Top shape for layer 89 'conv5_5/dw/scale' 8 256 16 32 (1048576)
I0510 14:48:30.290920  5307 layer_factory.hpp:172] Creating layer 'relu5_5/dw' of type 'ReLU'
I0510 14:48:30.290935  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.290956  5307 net.cpp:200] Created Layer relu5_5/dw (90)
I0510 14:48:30.290980  5307 net.cpp:572] relu5_5/dw <- conv5_5/dw
I0510 14:48:30.290997  5307 net.cpp:527] relu5_5/dw -> conv5_5/dw (in-place)
I0510 14:48:30.291014  5307 net.cpp:260] Setting up relu5_5/dw
I0510 14:48:30.291031  5307 net.cpp:267] TEST Top shape for layer 90 'relu5_5/dw' 8 256 16 32 (1048576)
I0510 14:48:30.291046  5307 layer_factory.hpp:172] Creating layer 'conv5_5/sep' of type 'Convolution'
I0510 14:48:30.291062  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.291085  5307 net.cpp:200] Created Layer conv5_5/sep (91)
I0510 14:48:30.291100  5307 net.cpp:572] conv5_5/sep <- conv5_5/dw
I0510 14:48:30.291116  5307 net.cpp:542] conv5_5/sep -> conv5_5/sep
I0510 14:48:30.295755  5307 net.cpp:260] Setting up conv5_5/sep
I0510 14:48:30.295776  5307 net.cpp:267] TEST Top shape for layer 91 'conv5_5/sep' 8 256 16 32 (1048576)
I0510 14:48:30.295784  5307 layer_factory.hpp:172] Creating layer 'conv5_5/sep/bn' of type 'BatchNorm'
I0510 14:48:30.295789  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.295799  5307 net.cpp:200] Created Layer conv5_5/sep/bn (92)
I0510 14:48:30.295804  5307 net.cpp:572] conv5_5/sep/bn <- conv5_5/sep
I0510 14:48:30.295809  5307 net.cpp:527] conv5_5/sep/bn -> conv5_5/sep (in-place)
I0510 14:48:30.296200  5307 net.cpp:260] Setting up conv5_5/sep/bn
I0510 14:48:30.296209  5307 net.cpp:267] TEST Top shape for layer 92 'conv5_5/sep/bn' 8 256 16 32 (1048576)
I0510 14:48:30.296223  5307 layer_factory.hpp:172] Creating layer 'conv5_5/sep/scale' of type 'Scale'
I0510 14:48:30.296231  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.296252  5307 net.cpp:200] Created Layer conv5_5/sep/scale (93)
I0510 14:48:30.296265  5307 net.cpp:572] conv5_5/sep/scale <- conv5_5/sep
I0510 14:48:30.296277  5307 net.cpp:527] conv5_5/sep/scale -> conv5_5/sep (in-place)
I0510 14:48:30.296329  5307 layer_factory.hpp:172] Creating layer 'conv5_5/sep/scale' of type 'Bias'
I0510 14:48:30.296336  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.296476  5307 net.cpp:260] Setting up conv5_5/sep/scale
I0510 14:48:30.296484  5307 net.cpp:267] TEST Top shape for layer 93 'conv5_5/sep/scale' 8 256 16 32 (1048576)
I0510 14:48:30.296499  5307 layer_factory.hpp:172] Creating layer 'relu5_5/sep' of type 'ReLU'
I0510 14:48:30.296509  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.296520  5307 net.cpp:200] Created Layer relu5_5/sep (94)
I0510 14:48:30.296541  5307 net.cpp:572] relu5_5/sep <- conv5_5/sep
I0510 14:48:30.296551  5307 net.cpp:527] relu5_5/sep -> conv5_5/sep (in-place)
I0510 14:48:30.296564  5307 net.cpp:260] Setting up relu5_5/sep
I0510 14:48:30.296576  5307 net.cpp:267] TEST Top shape for layer 94 'relu5_5/sep' 8 256 16 32 (1048576)
I0510 14:48:30.296584  5307 layer_factory.hpp:172] Creating layer 'conv5_5/sep_relu5_5/sep_0_split' of type 'Split'
I0510 14:48:30.296594  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.296604  5307 net.cpp:200] Created Layer conv5_5/sep_relu5_5/sep_0_split (95)
I0510 14:48:30.296614  5307 net.cpp:572] conv5_5/sep_relu5_5/sep_0_split <- conv5_5/sep
I0510 14:48:30.296623  5307 net.cpp:542] conv5_5/sep_relu5_5/sep_0_split -> conv5_5/sep_relu5_5/sep_0_split_0
I0510 14:48:30.296635  5307 net.cpp:542] conv5_5/sep_relu5_5/sep_0_split -> conv5_5/sep_relu5_5/sep_0_split_1
I0510 14:48:30.296679  5307 net.cpp:260] Setting up conv5_5/sep_relu5_5/sep_0_split
I0510 14:48:30.296685  5307 net.cpp:267] TEST Top shape for layer 95 'conv5_5/sep_relu5_5/sep_0_split' 8 256 16 32 (1048576)
I0510 14:48:30.296691  5307 net.cpp:267] TEST Top shape for layer 95 'conv5_5/sep_relu5_5/sep_0_split' 8 256 16 32 (1048576)
I0510 14:48:30.296696  5307 layer_factory.hpp:172] Creating layer 'conv5_6/dw' of type 'Convolution'
I0510 14:48:30.296710  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.296722  5307 net.cpp:200] Created Layer conv5_6/dw (96)
I0510 14:48:30.296726  5307 net.cpp:572] conv5_6/dw <- conv5_5/sep_relu5_5/sep_0_split_0
I0510 14:48:30.296731  5307 net.cpp:542] conv5_6/dw -> conv5_6/dw
I0510 14:48:30.297003  5307 net.cpp:260] Setting up conv5_6/dw
I0510 14:48:30.297011  5307 net.cpp:267] TEST Top shape for layer 96 'conv5_6/dw' 8 256 8 16 (262144)
I0510 14:48:30.297017  5307 layer_factory.hpp:172] Creating layer 'conv5_6/dw/bn' of type 'BatchNorm'
I0510 14:48:30.297030  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.297049  5307 net.cpp:200] Created Layer conv5_6/dw/bn (97)
I0510 14:48:30.297062  5307 net.cpp:572] conv5_6/dw/bn <- conv5_6/dw
I0510 14:48:30.297076  5307 net.cpp:527] conv5_6/dw/bn -> conv5_6/dw (in-place)
I0510 14:48:30.297441  5307 net.cpp:260] Setting up conv5_6/dw/bn
I0510 14:48:30.297461  5307 net.cpp:267] TEST Top shape for layer 97 'conv5_6/dw/bn' 8 256 8 16 (262144)
I0510 14:48:30.297479  5307 layer_factory.hpp:172] Creating layer 'conv5_6/dw/scale' of type 'Scale'
I0510 14:48:30.297493  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.297510  5307 net.cpp:200] Created Layer conv5_6/dw/scale (98)
I0510 14:48:30.297524  5307 net.cpp:572] conv5_6/dw/scale <- conv5_6/dw
I0510 14:48:30.297538  5307 net.cpp:527] conv5_6/dw/scale -> conv5_6/dw (in-place)
I0510 14:48:30.297588  5307 layer_factory.hpp:172] Creating layer 'conv5_6/dw/scale' of type 'Bias'
I0510 14:48:30.297605  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.297725  5307 net.cpp:260] Setting up conv5_6/dw/scale
I0510 14:48:30.297744  5307 net.cpp:267] TEST Top shape for layer 98 'conv5_6/dw/scale' 8 256 8 16 (262144)
I0510 14:48:30.297760  5307 layer_factory.hpp:172] Creating layer 'relu5_6/dw' of type 'ReLU'
I0510 14:48:30.297775  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.297789  5307 net.cpp:200] Created Layer relu5_6/dw (99)
I0510 14:48:30.297802  5307 net.cpp:572] relu5_6/dw <- conv5_6/dw
I0510 14:48:30.297816  5307 net.cpp:527] relu5_6/dw -> conv5_6/dw (in-place)
I0510 14:48:30.297832  5307 net.cpp:260] Setting up relu5_6/dw
I0510 14:48:30.297839  5307 net.cpp:267] TEST Top shape for layer 99 'relu5_6/dw' 8 256 8 16 (262144)
I0510 14:48:30.297843  5307 layer_factory.hpp:172] Creating layer 'conv5_6/sep' of type 'Convolution'
I0510 14:48:30.297848  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.297857  5307 net.cpp:200] Created Layer conv5_6/sep (100)
I0510 14:48:30.297860  5307 net.cpp:572] conv5_6/sep <- conv5_6/dw
I0510 14:48:30.297864  5307 net.cpp:542] conv5_6/sep -> conv5_6/sep
I0510 14:48:30.301995  5307 net.cpp:260] Setting up conv5_6/sep
I0510 14:48:30.302006  5307 net.cpp:267] TEST Top shape for layer 100 'conv5_6/sep' 8 512 8 16 (524288)
I0510 14:48:30.302012  5307 layer_factory.hpp:172] Creating layer 'conv5_6/sep/bn' of type 'BatchNorm'
I0510 14:48:30.302016  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.302022  5307 net.cpp:200] Created Layer conv5_6/sep/bn (101)
I0510 14:48:30.302027  5307 net.cpp:572] conv5_6/sep/bn <- conv5_6/sep
I0510 14:48:30.302031  5307 net.cpp:527] conv5_6/sep/bn -> conv5_6/sep (in-place)
I0510 14:48:30.302390  5307 net.cpp:260] Setting up conv5_6/sep/bn
I0510 14:48:30.302413  5307 net.cpp:267] TEST Top shape for layer 101 'conv5_6/sep/bn' 8 512 8 16 (524288)
I0510 14:48:30.302433  5307 layer_factory.hpp:172] Creating layer 'conv5_6/sep/scale' of type 'Scale'
I0510 14:48:30.302446  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.302469  5307 net.cpp:200] Created Layer conv5_6/sep/scale (102)
I0510 14:48:30.302484  5307 net.cpp:572] conv5_6/sep/scale <- conv5_6/sep
I0510 14:48:30.302505  5307 net.cpp:527] conv5_6/sep/scale -> conv5_6/sep (in-place)
I0510 14:48:30.302554  5307 layer_factory.hpp:172] Creating layer 'conv5_6/sep/scale' of type 'Bias'
I0510 14:48:30.302570  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.302696  5307 net.cpp:260] Setting up conv5_6/sep/scale
I0510 14:48:30.302714  5307 net.cpp:267] TEST Top shape for layer 102 'conv5_6/sep/scale' 8 512 8 16 (524288)
I0510 14:48:30.302731  5307 layer_factory.hpp:172] Creating layer 'relu5_6/sep' of type 'ReLU'
I0510 14:48:30.302743  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.302758  5307 net.cpp:200] Created Layer relu5_6/sep (103)
I0510 14:48:30.302772  5307 net.cpp:572] relu5_6/sep <- conv5_6/sep
I0510 14:48:30.302784  5307 net.cpp:527] relu5_6/sep -> conv5_6/sep (in-place)
I0510 14:48:30.302799  5307 net.cpp:260] Setting up relu5_6/sep
I0510 14:48:30.302814  5307 net.cpp:267] TEST Top shape for layer 103 'relu5_6/sep' 8 512 8 16 (524288)
I0510 14:48:30.302826  5307 layer_factory.hpp:172] Creating layer 'conv6/dw' of type 'Convolution'
I0510 14:48:30.302839  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.302856  5307 net.cpp:200] Created Layer conv6/dw (104)
I0510 14:48:30.302870  5307 net.cpp:572] conv6/dw <- conv5_6/sep
I0510 14:48:30.302882  5307 net.cpp:542] conv6/dw -> conv6/dw
I0510 14:48:30.303230  5307 net.cpp:260] Setting up conv6/dw
I0510 14:48:30.303238  5307 net.cpp:267] TEST Top shape for layer 104 'conv6/dw' 8 512 8 16 (524288)
I0510 14:48:30.303262  5307 layer_factory.hpp:172] Creating layer 'conv6/dw/bn' of type 'BatchNorm'
I0510 14:48:30.303278  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.303295  5307 net.cpp:200] Created Layer conv6/dw/bn (105)
I0510 14:48:30.303308  5307 net.cpp:572] conv6/dw/bn <- conv6/dw
I0510 14:48:30.303320  5307 net.cpp:527] conv6/dw/bn -> conv6/dw (in-place)
I0510 14:48:30.303689  5307 net.cpp:260] Setting up conv6/dw/bn
I0510 14:48:30.303696  5307 net.cpp:267] TEST Top shape for layer 105 'conv6/dw/bn' 8 512 8 16 (524288)
I0510 14:48:30.303721  5307 layer_factory.hpp:172] Creating layer 'conv6/dw/scale' of type 'Scale'
I0510 14:48:30.303735  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.303750  5307 net.cpp:200] Created Layer conv6/dw/scale (106)
I0510 14:48:30.303763  5307 net.cpp:572] conv6/dw/scale <- conv6/dw
I0510 14:48:30.303776  5307 net.cpp:527] conv6/dw/scale -> conv6/dw (in-place)
I0510 14:48:30.303827  5307 layer_factory.hpp:172] Creating layer 'conv6/dw/scale' of type 'Bias'
I0510 14:48:30.303833  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.303958  5307 net.cpp:260] Setting up conv6/dw/scale
I0510 14:48:30.303972  5307 net.cpp:267] TEST Top shape for layer 106 'conv6/dw/scale' 8 512 8 16 (524288)
I0510 14:48:30.303988  5307 layer_factory.hpp:172] Creating layer 'relu6/dw' of type 'ReLU'
I0510 14:48:30.304003  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.304016  5307 net.cpp:200] Created Layer relu6/dw (107)
I0510 14:48:30.304029  5307 net.cpp:572] relu6/dw <- conv6/dw
I0510 14:48:30.304041  5307 net.cpp:527] relu6/dw -> conv6/dw (in-place)
I0510 14:48:30.304055  5307 net.cpp:260] Setting up relu6/dw
I0510 14:48:30.304069  5307 net.cpp:267] TEST Top shape for layer 107 'relu6/dw' 8 512 8 16 (524288)
I0510 14:48:30.304082  5307 layer_factory.hpp:172] Creating layer 'conv6/sep' of type 'Convolution'
I0510 14:48:30.304095  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.304113  5307 net.cpp:200] Created Layer conv6/sep (108)
I0510 14:48:30.304129  5307 net.cpp:572] conv6/sep <- conv6/dw
I0510 14:48:30.304143  5307 net.cpp:542] conv6/sep -> conv6/sep
I0510 14:48:30.314024  5307 net.cpp:260] Setting up conv6/sep
I0510 14:48:30.314102  5307 net.cpp:267] TEST Top shape for layer 108 'conv6/sep' 8 512 8 16 (524288)
I0510 14:48:30.314126  5307 layer_factory.hpp:172] Creating layer 'conv6/sep/bn' of type 'BatchNorm'
I0510 14:48:30.314141  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.314159  5307 net.cpp:200] Created Layer conv6/sep/bn (109)
I0510 14:48:30.314174  5307 net.cpp:572] conv6/sep/bn <- conv6/sep
I0510 14:48:30.314188  5307 net.cpp:527] conv6/sep/bn -> conv6/sep (in-place)
I0510 14:48:30.314595  5307 net.cpp:260] Setting up conv6/sep/bn
I0510 14:48:30.314612  5307 net.cpp:267] TEST Top shape for layer 109 'conv6/sep/bn' 8 512 8 16 (524288)
I0510 14:48:30.314628  5307 layer_factory.hpp:172] Creating layer 'conv6/sep/scale' of type 'Scale'
I0510 14:48:30.314641  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.314657  5307 net.cpp:200] Created Layer conv6/sep/scale (110)
I0510 14:48:30.314668  5307 net.cpp:572] conv6/sep/scale <- conv6/sep
I0510 14:48:30.314680  5307 net.cpp:527] conv6/sep/scale -> conv6/sep (in-place)
I0510 14:48:30.314728  5307 layer_factory.hpp:172] Creating layer 'conv6/sep/scale' of type 'Bias'
I0510 14:48:30.314743  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.314865  5307 net.cpp:260] Setting up conv6/sep/scale
I0510 14:48:30.314882  5307 net.cpp:267] TEST Top shape for layer 110 'conv6/sep/scale' 8 512 8 16 (524288)
I0510 14:48:30.314896  5307 layer_factory.hpp:172] Creating layer 'relu6/sep' of type 'ReLU'
I0510 14:48:30.314914  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.314929  5307 net.cpp:200] Created Layer relu6/sep (111)
I0510 14:48:30.314939  5307 net.cpp:572] relu6/sep <- conv6/sep
I0510 14:48:30.314950  5307 net.cpp:527] relu6/sep -> conv6/sep (in-place)
I0510 14:48:30.314965  5307 net.cpp:260] Setting up relu6/sep
I0510 14:48:30.314977  5307 net.cpp:267] TEST Top shape for layer 111 'relu6/sep' 8 512 8 16 (524288)
I0510 14:48:30.314988  5307 layer_factory.hpp:172] Creating layer 'conv6/sep_relu6/sep_0_split' of type 'Split'
I0510 14:48:30.315001  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.315013  5307 net.cpp:200] Created Layer conv6/sep_relu6/sep_0_split (112)
I0510 14:48:30.315024  5307 net.cpp:572] conv6/sep_relu6/sep_0_split <- conv6/sep
I0510 14:48:30.315035  5307 net.cpp:542] conv6/sep_relu6/sep_0_split -> conv6/sep_relu6/sep_0_split_0
I0510 14:48:30.315048  5307 net.cpp:542] conv6/sep_relu6/sep_0_split -> conv6/sep_relu6/sep_0_split_1
I0510 14:48:30.315089  5307 net.cpp:260] Setting up conv6/sep_relu6/sep_0_split
I0510 14:48:30.315105  5307 net.cpp:267] TEST Top shape for layer 112 'conv6/sep_relu6/sep_0_split' 8 512 8 16 (524288)
I0510 14:48:30.315117  5307 net.cpp:267] TEST Top shape for layer 112 'conv6/sep_relu6/sep_0_split' 8 512 8 16 (524288)
I0510 14:48:30.315129  5307 layer_factory.hpp:172] Creating layer 'pool6' of type 'Pooling'
I0510 14:48:30.315140  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.315155  5307 net.cpp:200] Created Layer pool6 (113)
I0510 14:48:30.315165  5307 net.cpp:572] pool6 <- conv6/sep_relu6/sep_0_split_0
I0510 14:48:30.315177  5307 net.cpp:542] pool6 -> pool6
I0510 14:48:30.315233  5307 net.cpp:260] Setting up pool6
I0510 14:48:30.315248  5307 net.cpp:267] TEST Top shape for layer 113 'pool6' 8 512 5 9 (184320)
I0510 14:48:30.315259  5307 layer_factory.hpp:172] Creating layer 'pool6_pool6_0_split' of type 'Split'
I0510 14:48:30.315271  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.315284  5307 net.cpp:200] Created Layer pool6_pool6_0_split (114)
I0510 14:48:30.315300  5307 net.cpp:572] pool6_pool6_0_split <- pool6
I0510 14:48:30.315312  5307 net.cpp:542] pool6_pool6_0_split -> pool6_pool6_0_split_0
I0510 14:48:30.315332  5307 net.cpp:542] pool6_pool6_0_split -> pool6_pool6_0_split_1
I0510 14:48:30.315374  5307 net.cpp:260] Setting up pool6_pool6_0_split
I0510 14:48:30.315388  5307 net.cpp:267] TEST Top shape for layer 114 'pool6_pool6_0_split' 8 512 5 9 (184320)
I0510 14:48:30.315400  5307 net.cpp:267] TEST Top shape for layer 114 'pool6_pool6_0_split' 8 512 5 9 (184320)
I0510 14:48:30.315412  5307 layer_factory.hpp:172] Creating layer 'pool7' of type 'Pooling'
I0510 14:48:30.315423  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.315435  5307 net.cpp:200] Created Layer pool7 (115)
I0510 14:48:30.315448  5307 net.cpp:572] pool7 <- pool6_pool6_0_split_0
I0510 14:48:30.315459  5307 net.cpp:542] pool7 -> pool7
I0510 14:48:30.315513  5307 net.cpp:260] Setting up pool7
I0510 14:48:30.315528  5307 net.cpp:267] TEST Top shape for layer 115 'pool7' 8 512 3 5 (61440)
I0510 14:48:30.315539  5307 layer_factory.hpp:172] Creating layer 'pool7_pool7_0_split' of type 'Split'
I0510 14:48:30.315551  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.315563  5307 net.cpp:200] Created Layer pool7_pool7_0_split (116)
I0510 14:48:30.315574  5307 net.cpp:572] pool7_pool7_0_split <- pool7
I0510 14:48:30.315585  5307 net.cpp:542] pool7_pool7_0_split -> pool7_pool7_0_split_0
I0510 14:48:30.315598  5307 net.cpp:542] pool7_pool7_0_split -> pool7_pool7_0_split_1
I0510 14:48:30.315639  5307 net.cpp:260] Setting up pool7_pool7_0_split
I0510 14:48:30.315654  5307 net.cpp:267] TEST Top shape for layer 116 'pool7_pool7_0_split' 8 512 3 5 (61440)
I0510 14:48:30.315670  5307 net.cpp:267] TEST Top shape for layer 116 'pool7_pool7_0_split' 8 512 3 5 (61440)
I0510 14:48:30.315681  5307 layer_factory.hpp:172] Creating layer 'pool8' of type 'Pooling'
I0510 14:48:30.315692  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.315706  5307 net.cpp:200] Created Layer pool8 (117)
I0510 14:48:30.315717  5307 net.cpp:572] pool8 <- pool7_pool7_0_split_0
I0510 14:48:30.315729  5307 net.cpp:542] pool8 -> pool8
I0510 14:48:30.315781  5307 net.cpp:260] Setting up pool8
I0510 14:48:30.315796  5307 net.cpp:267] TEST Top shape for layer 117 'pool8' 8 512 3 5 (61440)
I0510 14:48:30.315809  5307 layer_factory.hpp:172] Creating layer 'ctx_output1/1x1' of type 'Convolution'
I0510 14:48:30.315819  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.315837  5307 net.cpp:200] Created Layer ctx_output1/1x1 (118)
I0510 14:48:30.315850  5307 net.cpp:572] ctx_output1/1x1 <- conv5_5/sep_relu5_5/sep_0_split_1
I0510 14:48:30.315862  5307 net.cpp:542] ctx_output1/1x1 -> ctx_output1/1x1
I0510 14:48:30.319830  5307 net.cpp:260] Setting up ctx_output1/1x1
I0510 14:48:30.319865  5307 net.cpp:267] TEST Top shape for layer 118 'ctx_output1/1x1' 8 512 16 32 (2097152)
I0510 14:48:30.319883  5307 layer_factory.hpp:172] Creating layer 'ctx_output1/1x1/bn' of type 'BatchNorm'
I0510 14:48:30.319895  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.319916  5307 net.cpp:200] Created Layer ctx_output1/1x1/bn (119)
I0510 14:48:30.319929  5307 net.cpp:572] ctx_output1/1x1/bn <- ctx_output1/1x1
I0510 14:48:30.319944  5307 net.cpp:527] ctx_output1/1x1/bn -> ctx_output1/1x1 (in-place)
I0510 14:48:30.320313  5307 net.cpp:260] Setting up ctx_output1/1x1/bn
I0510 14:48:30.320389  5307 net.cpp:267] TEST Top shape for layer 119 'ctx_output1/1x1/bn' 8 512 16 32 (2097152)
I0510 14:48:30.320462  5307 layer_factory.hpp:172] Creating layer 'ctx_output1/1x1/relu' of type 'ReLU'
I0510 14:48:30.320534  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.320606  5307 net.cpp:200] Created Layer ctx_output1/1x1/relu (120)
I0510 14:48:30.320670  5307 net.cpp:572] ctx_output1/1x1/relu <- ctx_output1/1x1
I0510 14:48:30.320737  5307 net.cpp:527] ctx_output1/1x1/relu -> ctx_output1/1x1 (in-place)
I0510 14:48:30.320801  5307 net.cpp:260] Setting up ctx_output1/1x1/relu
I0510 14:48:30.320860  5307 net.cpp:267] TEST Top shape for layer 120 'ctx_output1/1x1/relu' 8 512 16 32 (2097152)
I0510 14:48:30.320928  5307 layer_factory.hpp:172] Creating layer 'ctx_output1' of type 'Convolution'
I0510 14:48:30.320991  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.321064  5307 net.cpp:200] Created Layer ctx_output1 (121)
I0510 14:48:30.321121  5307 net.cpp:572] ctx_output1 <- ctx_output1/1x1
I0510 14:48:30.321177  5307 net.cpp:542] ctx_output1 -> ctx_output1
I0510 14:48:30.321615  5307 net.cpp:260] Setting up ctx_output1
I0510 14:48:30.321679  5307 net.cpp:267] TEST Top shape for layer 121 'ctx_output1' 8 512 16 32 (2097152)
I0510 14:48:30.321748  5307 layer_factory.hpp:172] Creating layer 'ctx_output1/bn' of type 'BatchNorm'
I0510 14:48:30.321811  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.321873  5307 net.cpp:200] Created Layer ctx_output1/bn (122)
I0510 14:48:30.321925  5307 net.cpp:572] ctx_output1/bn <- ctx_output1
I0510 14:48:30.321975  5307 net.cpp:527] ctx_output1/bn -> ctx_output1 (in-place)
I0510 14:48:30.322360  5307 net.cpp:260] Setting up ctx_output1/bn
I0510 14:48:30.322424  5307 net.cpp:267] TEST Top shape for layer 122 'ctx_output1/bn' 8 512 16 32 (2097152)
I0510 14:48:30.322499  5307 layer_factory.hpp:172] Creating layer 'ctx_output1/relu' of type 'ReLU'
I0510 14:48:30.322566  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.322643  5307 net.cpp:200] Created Layer ctx_output1/relu (123)
I0510 14:48:30.322703  5307 net.cpp:572] ctx_output1/relu <- ctx_output1
I0510 14:48:30.322757  5307 net.cpp:527] ctx_output1/relu -> ctx_output1 (in-place)
I0510 14:48:30.322819  5307 net.cpp:260] Setting up ctx_output1/relu
I0510 14:48:30.322877  5307 net.cpp:267] TEST Top shape for layer 123 'ctx_output1/relu' 8 512 16 32 (2097152)
I0510 14:48:30.322943  5307 layer_factory.hpp:172] Creating layer 'ctx_output1_ctx_output1/relu_0_split' of type 'Split'
I0510 14:48:30.323010  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.323079  5307 net.cpp:200] Created Layer ctx_output1_ctx_output1/relu_0_split (124)
I0510 14:48:30.323150  5307 net.cpp:572] ctx_output1_ctx_output1/relu_0_split <- ctx_output1
I0510 14:48:30.323212  5307 net.cpp:542] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_0
I0510 14:48:30.323287  5307 net.cpp:542] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_1
I0510 14:48:30.323357  5307 net.cpp:542] ctx_output1_ctx_output1/relu_0_split -> ctx_output1_ctx_output1/relu_0_split_2
I0510 14:48:30.323474  5307 net.cpp:260] Setting up ctx_output1_ctx_output1/relu_0_split
I0510 14:48:30.323539  5307 net.cpp:267] TEST Top shape for layer 124 'ctx_output1_ctx_output1/relu_0_split' 8 512 16 32 (2097152)
I0510 14:48:30.323612  5307 net.cpp:267] TEST Top shape for layer 124 'ctx_output1_ctx_output1/relu_0_split' 8 512 16 32 (2097152)
I0510 14:48:30.323689  5307 net.cpp:267] TEST Top shape for layer 124 'ctx_output1_ctx_output1/relu_0_split' 8 512 16 32 (2097152)
I0510 14:48:30.323763  5307 layer_factory.hpp:172] Creating layer 'ctx_output2/1x1' of type 'Convolution'
I0510 14:48:30.323829  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.323902  5307 net.cpp:200] Created Layer ctx_output2/1x1 (125)
I0510 14:48:30.323961  5307 net.cpp:572] ctx_output2/1x1 <- conv6/sep_relu6/sep_0_split_1
I0510 14:48:30.324023  5307 net.cpp:542] ctx_output2/1x1 -> ctx_output2/1x1
I0510 14:48:30.333039  5307 net.cpp:260] Setting up ctx_output2/1x1
I0510 14:48:30.333173  5307 net.cpp:267] TEST Top shape for layer 125 'ctx_output2/1x1' 8 512 8 16 (524288)
I0510 14:48:30.333248  5307 layer_factory.hpp:172] Creating layer 'ctx_output2/1x1/bn' of type 'BatchNorm'
I0510 14:48:30.333317  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.333382  5307 net.cpp:200] Created Layer ctx_output2/1x1/bn (126)
I0510 14:48:30.333403  5307 net.cpp:572] ctx_output2/1x1/bn <- ctx_output2/1x1
I0510 14:48:30.333421  5307 net.cpp:527] ctx_output2/1x1/bn -> ctx_output2/1x1 (in-place)
I0510 14:48:30.333811  5307 net.cpp:260] Setting up ctx_output2/1x1/bn
I0510 14:48:30.333820  5307 net.cpp:267] TEST Top shape for layer 126 'ctx_output2/1x1/bn' 8 512 8 16 (524288)
I0510 14:48:30.333829  5307 layer_factory.hpp:172] Creating layer 'ctx_output2/1x1/relu' of type 'ReLU'
I0510 14:48:30.333834  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.333840  5307 net.cpp:200] Created Layer ctx_output2/1x1/relu (127)
I0510 14:48:30.333844  5307 net.cpp:572] ctx_output2/1x1/relu <- ctx_output2/1x1
I0510 14:48:30.333875  5307 net.cpp:527] ctx_output2/1x1/relu -> ctx_output2/1x1 (in-place)
I0510 14:48:30.333899  5307 net.cpp:260] Setting up ctx_output2/1x1/relu
I0510 14:48:30.333911  5307 net.cpp:267] TEST Top shape for layer 127 'ctx_output2/1x1/relu' 8 512 8 16 (524288)
I0510 14:48:30.333925  5307 layer_factory.hpp:172] Creating layer 'ctx_output2' of type 'Convolution'
I0510 14:48:30.333938  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.333961  5307 net.cpp:200] Created Layer ctx_output2 (128)
I0510 14:48:30.333966  5307 net.cpp:572] ctx_output2 <- ctx_output2/1x1
I0510 14:48:30.333986  5307 net.cpp:542] ctx_output2 -> ctx_output2
I0510 14:48:30.334405  5307 net.cpp:260] Setting up ctx_output2
I0510 14:48:30.334429  5307 net.cpp:267] TEST Top shape for layer 128 'ctx_output2' 8 512 8 16 (524288)
I0510 14:48:30.334444  5307 layer_factory.hpp:172] Creating layer 'ctx_output2/bn' of type 'BatchNorm'
I0510 14:48:30.334450  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.334468  5307 net.cpp:200] Created Layer ctx_output2/bn (129)
I0510 14:48:30.334473  5307 net.cpp:572] ctx_output2/bn <- ctx_output2
I0510 14:48:30.334491  5307 net.cpp:527] ctx_output2/bn -> ctx_output2 (in-place)
I0510 14:48:30.334856  5307 net.cpp:260] Setting up ctx_output2/bn
I0510 14:48:30.334874  5307 net.cpp:267] TEST Top shape for layer 129 'ctx_output2/bn' 8 512 8 16 (524288)
I0510 14:48:30.334892  5307 layer_factory.hpp:172] Creating layer 'ctx_output2/relu' of type 'ReLU'
I0510 14:48:30.334905  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.334919  5307 net.cpp:200] Created Layer ctx_output2/relu (130)
I0510 14:48:30.334933  5307 net.cpp:572] ctx_output2/relu <- ctx_output2
I0510 14:48:30.334944  5307 net.cpp:527] ctx_output2/relu -> ctx_output2 (in-place)
I0510 14:48:30.334959  5307 net.cpp:260] Setting up ctx_output2/relu
I0510 14:48:30.334972  5307 net.cpp:267] TEST Top shape for layer 130 'ctx_output2/relu' 8 512 8 16 (524288)
I0510 14:48:30.334985  5307 layer_factory.hpp:172] Creating layer 'ctx_output2_ctx_output2/relu_0_split' of type 'Split'
I0510 14:48:30.334997  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.335011  5307 net.cpp:200] Created Layer ctx_output2_ctx_output2/relu_0_split (131)
I0510 14:48:30.335023  5307 net.cpp:572] ctx_output2_ctx_output2/relu_0_split <- ctx_output2
I0510 14:48:30.335036  5307 net.cpp:542] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_0
I0510 14:48:30.335050  5307 net.cpp:542] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_1
I0510 14:48:30.335064  5307 net.cpp:542] ctx_output2_ctx_output2/relu_0_split -> ctx_output2_ctx_output2/relu_0_split_2
I0510 14:48:30.335119  5307 net.cpp:260] Setting up ctx_output2_ctx_output2/relu_0_split
I0510 14:48:30.335137  5307 net.cpp:267] TEST Top shape for layer 131 'ctx_output2_ctx_output2/relu_0_split' 8 512 8 16 (524288)
I0510 14:48:30.335158  5307 net.cpp:267] TEST Top shape for layer 131 'ctx_output2_ctx_output2/relu_0_split' 8 512 8 16 (524288)
I0510 14:48:30.335171  5307 net.cpp:267] TEST Top shape for layer 131 'ctx_output2_ctx_output2/relu_0_split' 8 512 8 16 (524288)
I0510 14:48:30.335183  5307 layer_factory.hpp:172] Creating layer 'ctx_output3/1x1' of type 'Convolution'
I0510 14:48:30.335196  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.335212  5307 net.cpp:200] Created Layer ctx_output3/1x1 (132)
I0510 14:48:30.335225  5307 net.cpp:572] ctx_output3/1x1 <- pool6_pool6_0_split_1
I0510 14:48:30.335238  5307 net.cpp:542] ctx_output3/1x1 -> ctx_output3/1x1
I0510 14:48:30.343972  5307 net.cpp:260] Setting up ctx_output3/1x1
I0510 14:48:30.344038  5307 net.cpp:267] TEST Top shape for layer 132 'ctx_output3/1x1' 8 512 5 9 (184320)
I0510 14:48:30.344063  5307 layer_factory.hpp:172] Creating layer 'ctx_output3/1x1/bn' of type 'BatchNorm'
I0510 14:48:30.344081  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.344110  5307 net.cpp:200] Created Layer ctx_output3/1x1/bn (133)
I0510 14:48:30.344127  5307 net.cpp:572] ctx_output3/1x1/bn <- ctx_output3/1x1
I0510 14:48:30.344146  5307 net.cpp:527] ctx_output3/1x1/bn -> ctx_output3/1x1 (in-place)
I0510 14:48:30.344579  5307 net.cpp:260] Setting up ctx_output3/1x1/bn
I0510 14:48:30.344604  5307 net.cpp:267] TEST Top shape for layer 133 'ctx_output3/1x1/bn' 8 512 5 9 (184320)
I0510 14:48:30.344625  5307 layer_factory.hpp:172] Creating layer 'ctx_output3/1x1/relu' of type 'ReLU'
I0510 14:48:30.344641  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.344671  5307 net.cpp:200] Created Layer ctx_output3/1x1/relu (134)
I0510 14:48:30.344687  5307 net.cpp:572] ctx_output3/1x1/relu <- ctx_output3/1x1
I0510 14:48:30.344702  5307 net.cpp:527] ctx_output3/1x1/relu -> ctx_output3/1x1 (in-place)
I0510 14:48:30.344722  5307 net.cpp:260] Setting up ctx_output3/1x1/relu
I0510 14:48:30.344739  5307 net.cpp:267] TEST Top shape for layer 134 'ctx_output3/1x1/relu' 8 512 5 9 (184320)
I0510 14:48:30.344755  5307 layer_factory.hpp:172] Creating layer 'ctx_output3' of type 'Convolution'
I0510 14:48:30.344771  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.344795  5307 net.cpp:200] Created Layer ctx_output3 (135)
I0510 14:48:30.344811  5307 net.cpp:572] ctx_output3 <- ctx_output3/1x1
I0510 14:48:30.344826  5307 net.cpp:542] ctx_output3 -> ctx_output3
I0510 14:48:30.345271  5307 net.cpp:260] Setting up ctx_output3
I0510 14:48:30.345295  5307 net.cpp:267] TEST Top shape for layer 135 'ctx_output3' 8 512 5 9 (184320)
I0510 14:48:30.345315  5307 layer_factory.hpp:172] Creating layer 'ctx_output3/bn' of type 'BatchNorm'
I0510 14:48:30.345333  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.345353  5307 net.cpp:200] Created Layer ctx_output3/bn (136)
I0510 14:48:30.345371  5307 net.cpp:572] ctx_output3/bn <- ctx_output3
I0510 14:48:30.345386  5307 net.cpp:527] ctx_output3/bn -> ctx_output3 (in-place)
I0510 14:48:30.345791  5307 net.cpp:260] Setting up ctx_output3/bn
I0510 14:48:30.345813  5307 net.cpp:267] TEST Top shape for layer 136 'ctx_output3/bn' 8 512 5 9 (184320)
I0510 14:48:30.345834  5307 layer_factory.hpp:172] Creating layer 'ctx_output3/relu' of type 'ReLU'
I0510 14:48:30.345852  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.345870  5307 net.cpp:200] Created Layer ctx_output3/relu (137)
I0510 14:48:30.345885  5307 net.cpp:572] ctx_output3/relu <- ctx_output3
I0510 14:48:30.345902  5307 net.cpp:527] ctx_output3/relu -> ctx_output3 (in-place)
I0510 14:48:30.345921  5307 net.cpp:260] Setting up ctx_output3/relu
I0510 14:48:30.345937  5307 net.cpp:267] TEST Top shape for layer 137 'ctx_output3/relu' 8 512 5 9 (184320)
I0510 14:48:30.345960  5307 layer_factory.hpp:172] Creating layer 'ctx_output3_ctx_output3/relu_0_split' of type 'Split'
I0510 14:48:30.345985  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.346002  5307 net.cpp:200] Created Layer ctx_output3_ctx_output3/relu_0_split (138)
I0510 14:48:30.346017  5307 net.cpp:572] ctx_output3_ctx_output3/relu_0_split <- ctx_output3
I0510 14:48:30.346036  5307 net.cpp:542] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_0
I0510 14:48:30.346053  5307 net.cpp:542] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_1
I0510 14:48:30.346071  5307 net.cpp:542] ctx_output3_ctx_output3/relu_0_split -> ctx_output3_ctx_output3/relu_0_split_2
I0510 14:48:30.346129  5307 net.cpp:260] Setting up ctx_output3_ctx_output3/relu_0_split
I0510 14:48:30.346148  5307 net.cpp:267] TEST Top shape for layer 138 'ctx_output3_ctx_output3/relu_0_split' 8 512 5 9 (184320)
I0510 14:48:30.346166  5307 net.cpp:267] TEST Top shape for layer 138 'ctx_output3_ctx_output3/relu_0_split' 8 512 5 9 (184320)
I0510 14:48:30.346181  5307 net.cpp:267] TEST Top shape for layer 138 'ctx_output3_ctx_output3/relu_0_split' 8 512 5 9 (184320)
I0510 14:48:30.346196  5307 layer_factory.hpp:172] Creating layer 'ctx_output4/1x1' of type 'Convolution'
I0510 14:48:30.346211  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.346231  5307 net.cpp:200] Created Layer ctx_output4/1x1 (139)
I0510 14:48:30.346248  5307 net.cpp:572] ctx_output4/1x1 <- pool7_pool7_0_split_1
I0510 14:48:30.346264  5307 net.cpp:542] ctx_output4/1x1 -> ctx_output4/1x1
I0510 14:48:30.355239  5307 net.cpp:260] Setting up ctx_output4/1x1
I0510 14:48:30.355317  5307 net.cpp:267] TEST Top shape for layer 139 'ctx_output4/1x1' 8 512 3 5 (61440)
I0510 14:48:30.355342  5307 layer_factory.hpp:172] Creating layer 'ctx_output4/1x1/bn' of type 'BatchNorm'
I0510 14:48:30.355360  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.355389  5307 net.cpp:200] Created Layer ctx_output4/1x1/bn (140)
I0510 14:48:30.355408  5307 net.cpp:572] ctx_output4/1x1/bn <- ctx_output4/1x1
I0510 14:48:30.355425  5307 net.cpp:527] ctx_output4/1x1/bn -> ctx_output4/1x1 (in-place)
I0510 14:48:30.355901  5307 net.cpp:260] Setting up ctx_output4/1x1/bn
I0510 14:48:30.355921  5307 net.cpp:267] TEST Top shape for layer 140 'ctx_output4/1x1/bn' 8 512 3 5 (61440)
I0510 14:48:30.355939  5307 layer_factory.hpp:172] Creating layer 'ctx_output4/1x1/relu' of type 'ReLU'
I0510 14:48:30.355952  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.355965  5307 net.cpp:200] Created Layer ctx_output4/1x1/relu (141)
I0510 14:48:30.355976  5307 net.cpp:572] ctx_output4/1x1/relu <- ctx_output4/1x1
I0510 14:48:30.355988  5307 net.cpp:527] ctx_output4/1x1/relu -> ctx_output4/1x1 (in-place)
I0510 14:48:30.356003  5307 net.cpp:260] Setting up ctx_output4/1x1/relu
I0510 14:48:30.356014  5307 net.cpp:267] TEST Top shape for layer 141 'ctx_output4/1x1/relu' 8 512 3 5 (61440)
I0510 14:48:30.356026  5307 layer_factory.hpp:172] Creating layer 'ctx_output4' of type 'Convolution'
I0510 14:48:30.356039  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.356055  5307 net.cpp:200] Created Layer ctx_output4 (142)
I0510 14:48:30.356066  5307 net.cpp:572] ctx_output4 <- ctx_output4/1x1
I0510 14:48:30.356077  5307 net.cpp:542] ctx_output4 -> ctx_output4
I0510 14:48:30.356488  5307 net.cpp:260] Setting up ctx_output4
I0510 14:48:30.356510  5307 net.cpp:267] TEST Top shape for layer 142 'ctx_output4' 8 512 3 5 (61440)
I0510 14:48:30.356542  5307 layer_factory.hpp:172] Creating layer 'ctx_output4/bn' of type 'BatchNorm'
I0510 14:48:30.356559  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.356581  5307 net.cpp:200] Created Layer ctx_output4/bn (143)
I0510 14:48:30.356603  5307 net.cpp:572] ctx_output4/bn <- ctx_output4
I0510 14:48:30.356616  5307 net.cpp:527] ctx_output4/bn -> ctx_output4 (in-place)
I0510 14:48:30.356990  5307 net.cpp:260] Setting up ctx_output4/bn
I0510 14:48:30.357010  5307 net.cpp:267] TEST Top shape for layer 143 'ctx_output4/bn' 8 512 3 5 (61440)
I0510 14:48:30.357029  5307 layer_factory.hpp:172] Creating layer 'ctx_output4/relu' of type 'ReLU'
I0510 14:48:30.357046  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.357069  5307 net.cpp:200] Created Layer ctx_output4/relu (144)
I0510 14:48:30.357084  5307 net.cpp:572] ctx_output4/relu <- ctx_output4
I0510 14:48:30.357100  5307 net.cpp:527] ctx_output4/relu -> ctx_output4 (in-place)
I0510 14:48:30.357116  5307 net.cpp:260] Setting up ctx_output4/relu
I0510 14:48:30.357132  5307 net.cpp:267] TEST Top shape for layer 144 'ctx_output4/relu' 8 512 3 5 (61440)
I0510 14:48:30.357147  5307 layer_factory.hpp:172] Creating layer 'ctx_output4_ctx_output4/relu_0_split' of type 'Split'
I0510 14:48:30.357162  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.357178  5307 net.cpp:200] Created Layer ctx_output4_ctx_output4/relu_0_split (145)
I0510 14:48:30.357193  5307 net.cpp:572] ctx_output4_ctx_output4/relu_0_split <- ctx_output4
I0510 14:48:30.357208  5307 net.cpp:542] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_0
I0510 14:48:30.357230  5307 net.cpp:542] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_1
I0510 14:48:30.357247  5307 net.cpp:542] ctx_output4_ctx_output4/relu_0_split -> ctx_output4_ctx_output4/relu_0_split_2
I0510 14:48:30.357311  5307 net.cpp:260] Setting up ctx_output4_ctx_output4/relu_0_split
I0510 14:48:30.357331  5307 net.cpp:267] TEST Top shape for layer 145 'ctx_output4_ctx_output4/relu_0_split' 8 512 3 5 (61440)
I0510 14:48:30.357347  5307 net.cpp:267] TEST Top shape for layer 145 'ctx_output4_ctx_output4/relu_0_split' 8 512 3 5 (61440)
I0510 14:48:30.357362  5307 net.cpp:267] TEST Top shape for layer 145 'ctx_output4_ctx_output4/relu_0_split' 8 512 3 5 (61440)
I0510 14:48:30.357376  5307 layer_factory.hpp:172] Creating layer 'ctx_output5/1x1' of type 'Convolution'
I0510 14:48:30.357389  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.357409  5307 net.cpp:200] Created Layer ctx_output5/1x1 (146)
I0510 14:48:30.357424  5307 net.cpp:572] ctx_output5/1x1 <- pool8
I0510 14:48:30.357439  5307 net.cpp:542] ctx_output5/1x1 -> ctx_output5/1x1
I0510 14:48:30.365607  5307 net.cpp:260] Setting up ctx_output5/1x1
I0510 14:48:30.365667  5307 net.cpp:267] TEST Top shape for layer 146 'ctx_output5/1x1' 8 512 3 5 (61440)
I0510 14:48:30.365686  5307 layer_factory.hpp:172] Creating layer 'ctx_output5/1x1/bn' of type 'BatchNorm'
I0510 14:48:30.365700  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.365716  5307 net.cpp:200] Created Layer ctx_output5/1x1/bn (147)
I0510 14:48:30.365731  5307 net.cpp:572] ctx_output5/1x1/bn <- ctx_output5/1x1
I0510 14:48:30.365743  5307 net.cpp:527] ctx_output5/1x1/bn -> ctx_output5/1x1 (in-place)
I0510 14:48:30.366083  5307 net.cpp:260] Setting up ctx_output5/1x1/bn
I0510 14:48:30.366092  5307 net.cpp:267] TEST Top shape for layer 147 'ctx_output5/1x1/bn' 8 512 3 5 (61440)
I0510 14:48:30.366101  5307 layer_factory.hpp:172] Creating layer 'ctx_output5/1x1/relu' of type 'ReLU'
I0510 14:48:30.366104  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.366109  5307 net.cpp:200] Created Layer ctx_output5/1x1/relu (148)
I0510 14:48:30.366113  5307 net.cpp:572] ctx_output5/1x1/relu <- ctx_output5/1x1
I0510 14:48:30.366117  5307 net.cpp:527] ctx_output5/1x1/relu -> ctx_output5/1x1 (in-place)
I0510 14:48:30.366137  5307 net.cpp:260] Setting up ctx_output5/1x1/relu
I0510 14:48:30.366158  5307 net.cpp:267] TEST Top shape for layer 148 'ctx_output5/1x1/relu' 8 512 3 5 (61440)
I0510 14:48:30.366180  5307 layer_factory.hpp:172] Creating layer 'ctx_output5' of type 'Convolution'
I0510 14:48:30.366194  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.366211  5307 net.cpp:200] Created Layer ctx_output5 (149)
I0510 14:48:30.366223  5307 net.cpp:572] ctx_output5 <- ctx_output5/1x1
I0510 14:48:30.366236  5307 net.cpp:542] ctx_output5 -> ctx_output5
I0510 14:48:30.366629  5307 net.cpp:260] Setting up ctx_output5
I0510 14:48:30.366637  5307 net.cpp:267] TEST Top shape for layer 149 'ctx_output5' 8 512 3 5 (61440)
I0510 14:48:30.366662  5307 layer_factory.hpp:172] Creating layer 'ctx_output5/bn' of type 'BatchNorm'
I0510 14:48:30.366677  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.366693  5307 net.cpp:200] Created Layer ctx_output5/bn (150)
I0510 14:48:30.366706  5307 net.cpp:572] ctx_output5/bn <- ctx_output5
I0510 14:48:30.366720  5307 net.cpp:527] ctx_output5/bn -> ctx_output5 (in-place)
I0510 14:48:30.367090  5307 net.cpp:260] Setting up ctx_output5/bn
I0510 14:48:30.367097  5307 net.cpp:267] TEST Top shape for layer 150 'ctx_output5/bn' 8 512 3 5 (61440)
I0510 14:48:30.367121  5307 layer_factory.hpp:172] Creating layer 'ctx_output5/relu' of type 'ReLU'
I0510 14:48:30.367133  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.367146  5307 net.cpp:200] Created Layer ctx_output5/relu (151)
I0510 14:48:30.367158  5307 net.cpp:572] ctx_output5/relu <- ctx_output5
I0510 14:48:30.367171  5307 net.cpp:527] ctx_output5/relu -> ctx_output5 (in-place)
I0510 14:48:30.367187  5307 net.cpp:260] Setting up ctx_output5/relu
I0510 14:48:30.367200  5307 net.cpp:267] TEST Top shape for layer 151 'ctx_output5/relu' 8 512 3 5 (61440)
I0510 14:48:30.367213  5307 layer_factory.hpp:172] Creating layer 'ctx_output5_ctx_output5/relu_0_split' of type 'Split'
I0510 14:48:30.367224  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.367238  5307 net.cpp:200] Created Layer ctx_output5_ctx_output5/relu_0_split (152)
I0510 14:48:30.367249  5307 net.cpp:572] ctx_output5_ctx_output5/relu_0_split <- ctx_output5
I0510 14:48:30.367261  5307 net.cpp:542] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_0
I0510 14:48:30.367274  5307 net.cpp:542] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_1
I0510 14:48:30.367288  5307 net.cpp:542] ctx_output5_ctx_output5/relu_0_split -> ctx_output5_ctx_output5/relu_0_split_2
I0510 14:48:30.367344  5307 net.cpp:260] Setting up ctx_output5_ctx_output5/relu_0_split
I0510 14:48:30.367359  5307 net.cpp:267] TEST Top shape for layer 152 'ctx_output5_ctx_output5/relu_0_split' 8 512 3 5 (61440)
I0510 14:48:30.367372  5307 net.cpp:267] TEST Top shape for layer 152 'ctx_output5_ctx_output5/relu_0_split' 8 512 3 5 (61440)
I0510 14:48:30.367385  5307 net.cpp:267] TEST Top shape for layer 152 'ctx_output5_ctx_output5/relu_0_split' 8 512 3 5 (61440)
I0510 14:48:30.367398  5307 layer_factory.hpp:172] Creating layer 'ctx_output1/relu_mbox_loc' of type 'Convolution'
I0510 14:48:30.367411  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.367432  5307 net.cpp:200] Created Layer ctx_output1/relu_mbox_loc (153)
I0510 14:48:30.367446  5307 net.cpp:572] ctx_output1/relu_mbox_loc <- ctx_output1_ctx_output1/relu_0_split_0
I0510 14:48:30.367461  5307 net.cpp:542] ctx_output1/relu_mbox_loc -> ctx_output1/relu_mbox_loc
I0510 14:48:30.367933  5307 net.cpp:260] Setting up ctx_output1/relu_mbox_loc
I0510 14:48:30.367951  5307 net.cpp:267] TEST Top shape for layer 153 'ctx_output1/relu_mbox_loc' 8 16 16 32 (65536)
I0510 14:48:30.367966  5307 layer_factory.hpp:172] Creating layer 'ctx_output1/relu_mbox_loc_perm' of type 'Permute'
I0510 14:48:30.367979  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.368005  5307 net.cpp:200] Created Layer ctx_output1/relu_mbox_loc_perm (154)
I0510 14:48:30.368018  5307 net.cpp:572] ctx_output1/relu_mbox_loc_perm <- ctx_output1/relu_mbox_loc
I0510 14:48:30.368031  5307 net.cpp:542] ctx_output1/relu_mbox_loc_perm -> ctx_output1/relu_mbox_loc_perm
I0510 14:48:30.368134  5307 net.cpp:260] Setting up ctx_output1/relu_mbox_loc_perm
I0510 14:48:30.368149  5307 net.cpp:267] TEST Top shape for layer 154 'ctx_output1/relu_mbox_loc_perm' 8 16 32 16 (65536)
I0510 14:48:30.368162  5307 layer_factory.hpp:172] Creating layer 'ctx_output1/relu_mbox_loc_flat' of type 'Flatten'
I0510 14:48:30.368175  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.368188  5307 net.cpp:200] Created Layer ctx_output1/relu_mbox_loc_flat (155)
I0510 14:48:30.368201  5307 net.cpp:572] ctx_output1/relu_mbox_loc_flat <- ctx_output1/relu_mbox_loc_perm
I0510 14:48:30.368214  5307 net.cpp:542] ctx_output1/relu_mbox_loc_flat -> ctx_output1/relu_mbox_loc_flat
I0510 14:48:30.368324  5307 net.cpp:260] Setting up ctx_output1/relu_mbox_loc_flat
I0510 14:48:30.368340  5307 net.cpp:267] TEST Top shape for layer 155 'ctx_output1/relu_mbox_loc_flat' 8 8192 (65536)
I0510 14:48:30.368352  5307 layer_factory.hpp:172] Creating layer 'ctx_output1/relu_mbox_conf' of type 'Convolution'
I0510 14:48:30.368366  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.368384  5307 net.cpp:200] Created Layer ctx_output1/relu_mbox_conf (156)
I0510 14:48:30.368396  5307 net.cpp:572] ctx_output1/relu_mbox_conf <- ctx_output1_ctx_output1/relu_0_split_1
I0510 14:48:30.368410  5307 net.cpp:542] ctx_output1/relu_mbox_conf -> ctx_output1/relu_mbox_conf
I0510 14:48:30.369997  5307 net.cpp:260] Setting up ctx_output1/relu_mbox_conf
I0510 14:48:30.370007  5307 net.cpp:267] TEST Top shape for layer 156 'ctx_output1/relu_mbox_conf' 8 84 16 32 (344064)
I0510 14:48:30.370031  5307 layer_factory.hpp:172] Creating layer 'ctx_output1/relu_mbox_conf_perm' of type 'Permute'
I0510 14:48:30.370044  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.370059  5307 net.cpp:200] Created Layer ctx_output1/relu_mbox_conf_perm (157)
I0510 14:48:30.370071  5307 net.cpp:572] ctx_output1/relu_mbox_conf_perm <- ctx_output1/relu_mbox_conf
I0510 14:48:30.370085  5307 net.cpp:542] ctx_output1/relu_mbox_conf_perm -> ctx_output1/relu_mbox_conf_perm
I0510 14:48:30.370190  5307 net.cpp:260] Setting up ctx_output1/relu_mbox_conf_perm
I0510 14:48:30.370206  5307 net.cpp:267] TEST Top shape for layer 157 'ctx_output1/relu_mbox_conf_perm' 8 16 32 84 (344064)
I0510 14:48:30.370219  5307 layer_factory.hpp:172] Creating layer 'ctx_output1/relu_mbox_conf_flat' of type 'Flatten'
I0510 14:48:30.370232  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.370245  5307 net.cpp:200] Created Layer ctx_output1/relu_mbox_conf_flat (158)
I0510 14:48:30.370257  5307 net.cpp:572] ctx_output1/relu_mbox_conf_flat <- ctx_output1/relu_mbox_conf_perm
I0510 14:48:30.370270  5307 net.cpp:542] ctx_output1/relu_mbox_conf_flat -> ctx_output1/relu_mbox_conf_flat
I0510 14:48:30.379266  5307 net.cpp:260] Setting up ctx_output1/relu_mbox_conf_flat
I0510 14:48:30.379313  5307 net.cpp:267] TEST Top shape for layer 158 'ctx_output1/relu_mbox_conf_flat' 8 43008 (344064)
I0510 14:48:30.379328  5307 layer_factory.hpp:172] Creating layer 'ctx_output1/relu_mbox_priorbox' of type 'PriorBox'
I0510 14:48:30.379344  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.379364  5307 net.cpp:200] Created Layer ctx_output1/relu_mbox_priorbox (159)
I0510 14:48:30.379375  5307 net.cpp:572] ctx_output1/relu_mbox_priorbox <- ctx_output1_ctx_output1/relu_0_split_2
I0510 14:48:30.379390  5307 net.cpp:572] ctx_output1/relu_mbox_priorbox <- data_data_0_split_1
I0510 14:48:30.379401  5307 net.cpp:542] ctx_output1/relu_mbox_priorbox -> ctx_output1/relu_mbox_priorbox
I0510 14:48:30.379524  5307 net.cpp:260] Setting up ctx_output1/relu_mbox_priorbox
I0510 14:48:30.379534  5307 net.cpp:267] TEST Top shape for layer 159 'ctx_output1/relu_mbox_priorbox' 1 2 8192 (16384)
I0510 14:48:30.379539  5307 layer_factory.hpp:172] Creating layer 'ctx_output2/relu_mbox_loc' of type 'Convolution'
I0510 14:48:30.379546  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.379560  5307 net.cpp:200] Created Layer ctx_output2/relu_mbox_loc (160)
I0510 14:48:30.379565  5307 net.cpp:572] ctx_output2/relu_mbox_loc <- ctx_output2_ctx_output2/relu_0_split_0
I0510 14:48:30.379570  5307 net.cpp:542] ctx_output2/relu_mbox_loc -> ctx_output2/relu_mbox_loc
I0510 14:48:30.380260  5307 net.cpp:260] Setting up ctx_output2/relu_mbox_loc
I0510 14:48:30.380270  5307 net.cpp:267] TEST Top shape for layer 160 'ctx_output2/relu_mbox_loc' 8 24 8 16 (24576)
I0510 14:48:30.380276  5307 layer_factory.hpp:172] Creating layer 'ctx_output2/relu_mbox_loc_perm' of type 'Permute'
I0510 14:48:30.380281  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.380288  5307 net.cpp:200] Created Layer ctx_output2/relu_mbox_loc_perm (161)
I0510 14:48:30.380293  5307 net.cpp:572] ctx_output2/relu_mbox_loc_perm <- ctx_output2/relu_mbox_loc
I0510 14:48:30.380297  5307 net.cpp:542] ctx_output2/relu_mbox_loc_perm -> ctx_output2/relu_mbox_loc_perm
I0510 14:48:30.380390  5307 net.cpp:260] Setting up ctx_output2/relu_mbox_loc_perm
I0510 14:48:30.380398  5307 net.cpp:267] TEST Top shape for layer 161 'ctx_output2/relu_mbox_loc_perm' 8 8 16 24 (24576)
I0510 14:48:30.380403  5307 layer_factory.hpp:172] Creating layer 'ctx_output2/relu_mbox_loc_flat' of type 'Flatten'
I0510 14:48:30.380406  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.380411  5307 net.cpp:200] Created Layer ctx_output2/relu_mbox_loc_flat (162)
I0510 14:48:30.380415  5307 net.cpp:572] ctx_output2/relu_mbox_loc_flat <- ctx_output2/relu_mbox_loc_perm
I0510 14:48:30.380420  5307 net.cpp:542] ctx_output2/relu_mbox_loc_flat -> ctx_output2/relu_mbox_loc_flat
I0510 14:48:30.380486  5307 net.cpp:260] Setting up ctx_output2/relu_mbox_loc_flat
I0510 14:48:30.380492  5307 net.cpp:267] TEST Top shape for layer 162 'ctx_output2/relu_mbox_loc_flat' 8 3072 (24576)
I0510 14:48:30.380497  5307 layer_factory.hpp:172] Creating layer 'ctx_output2/relu_mbox_conf' of type 'Convolution'
I0510 14:48:30.380501  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.380509  5307 net.cpp:200] Created Layer ctx_output2/relu_mbox_conf (163)
I0510 14:48:30.380513  5307 net.cpp:572] ctx_output2/relu_mbox_conf <- ctx_output2_ctx_output2/relu_0_split_1
I0510 14:48:30.380518  5307 net.cpp:542] ctx_output2/relu_mbox_conf -> ctx_output2/relu_mbox_conf
I0510 14:48:30.382915  5307 net.cpp:260] Setting up ctx_output2/relu_mbox_conf
I0510 14:48:30.382927  5307 net.cpp:267] TEST Top shape for layer 163 'ctx_output2/relu_mbox_conf' 8 126 8 16 (129024)
I0510 14:48:30.382935  5307 layer_factory.hpp:172] Creating layer 'ctx_output2/relu_mbox_conf_perm' of type 'Permute'
I0510 14:48:30.382939  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.382946  5307 net.cpp:200] Created Layer ctx_output2/relu_mbox_conf_perm (164)
I0510 14:48:30.382951  5307 net.cpp:572] ctx_output2/relu_mbox_conf_perm <- ctx_output2/relu_mbox_conf
I0510 14:48:30.382954  5307 net.cpp:542] ctx_output2/relu_mbox_conf_perm -> ctx_output2/relu_mbox_conf_perm
I0510 14:48:30.383042  5307 net.cpp:260] Setting up ctx_output2/relu_mbox_conf_perm
I0510 14:48:30.383049  5307 net.cpp:267] TEST Top shape for layer 164 'ctx_output2/relu_mbox_conf_perm' 8 8 16 126 (129024)
I0510 14:48:30.383052  5307 layer_factory.hpp:172] Creating layer 'ctx_output2/relu_mbox_conf_flat' of type 'Flatten'
I0510 14:48:30.383057  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.383070  5307 net.cpp:200] Created Layer ctx_output2/relu_mbox_conf_flat (165)
I0510 14:48:30.383074  5307 net.cpp:572] ctx_output2/relu_mbox_conf_flat <- ctx_output2/relu_mbox_conf_perm
I0510 14:48:30.383080  5307 net.cpp:542] ctx_output2/relu_mbox_conf_flat -> ctx_output2/relu_mbox_conf_flat
I0510 14:48:30.383201  5307 net.cpp:260] Setting up ctx_output2/relu_mbox_conf_flat
I0510 14:48:30.383208  5307 net.cpp:267] TEST Top shape for layer 165 'ctx_output2/relu_mbox_conf_flat' 8 16128 (129024)
I0510 14:48:30.383213  5307 layer_factory.hpp:172] Creating layer 'ctx_output2/relu_mbox_priorbox' of type 'PriorBox'
I0510 14:48:30.383216  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.383221  5307 net.cpp:200] Created Layer ctx_output2/relu_mbox_priorbox (166)
I0510 14:48:30.383224  5307 net.cpp:572] ctx_output2/relu_mbox_priorbox <- ctx_output2_ctx_output2/relu_0_split_2
I0510 14:48:30.383229  5307 net.cpp:572] ctx_output2/relu_mbox_priorbox <- data_data_0_split_2
I0510 14:48:30.383234  5307 net.cpp:542] ctx_output2/relu_mbox_priorbox -> ctx_output2/relu_mbox_priorbox
I0510 14:48:30.383253  5307 net.cpp:260] Setting up ctx_output2/relu_mbox_priorbox
I0510 14:48:30.383260  5307 net.cpp:267] TEST Top shape for layer 166 'ctx_output2/relu_mbox_priorbox' 1 2 3072 (6144)
I0510 14:48:30.383263  5307 layer_factory.hpp:172] Creating layer 'ctx_output3/relu_mbox_loc' of type 'Convolution'
I0510 14:48:30.383266  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.383277  5307 net.cpp:200] Created Layer ctx_output3/relu_mbox_loc (167)
I0510 14:48:30.383281  5307 net.cpp:572] ctx_output3/relu_mbox_loc <- ctx_output3_ctx_output3/relu_0_split_0
I0510 14:48:30.383285  5307 net.cpp:542] ctx_output3/relu_mbox_loc -> ctx_output3/relu_mbox_loc
I0510 14:48:30.383890  5307 net.cpp:260] Setting up ctx_output3/relu_mbox_loc
I0510 14:48:30.383898  5307 net.cpp:267] TEST Top shape for layer 167 'ctx_output3/relu_mbox_loc' 8 24 5 9 (8640)
I0510 14:48:30.383905  5307 layer_factory.hpp:172] Creating layer 'ctx_output3/relu_mbox_loc_perm' of type 'Permute'
I0510 14:48:30.383908  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.383913  5307 net.cpp:200] Created Layer ctx_output3/relu_mbox_loc_perm (168)
I0510 14:48:30.383918  5307 net.cpp:572] ctx_output3/relu_mbox_loc_perm <- ctx_output3/relu_mbox_loc
I0510 14:48:30.383921  5307 net.cpp:542] ctx_output3/relu_mbox_loc_perm -> ctx_output3/relu_mbox_loc_perm
I0510 14:48:30.384006  5307 net.cpp:260] Setting up ctx_output3/relu_mbox_loc_perm
I0510 14:48:30.384011  5307 net.cpp:267] TEST Top shape for layer 168 'ctx_output3/relu_mbox_loc_perm' 8 5 9 24 (8640)
I0510 14:48:30.384016  5307 layer_factory.hpp:172] Creating layer 'ctx_output3/relu_mbox_loc_flat' of type 'Flatten'
I0510 14:48:30.384018  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.384022  5307 net.cpp:200] Created Layer ctx_output3/relu_mbox_loc_flat (169)
I0510 14:48:30.384027  5307 net.cpp:572] ctx_output3/relu_mbox_loc_flat <- ctx_output3/relu_mbox_loc_perm
I0510 14:48:30.384032  5307 net.cpp:542] ctx_output3/relu_mbox_loc_flat -> ctx_output3/relu_mbox_loc_flat
I0510 14:48:30.384083  5307 net.cpp:260] Setting up ctx_output3/relu_mbox_loc_flat
I0510 14:48:30.384089  5307 net.cpp:267] TEST Top shape for layer 169 'ctx_output3/relu_mbox_loc_flat' 8 1080 (8640)
I0510 14:48:30.384093  5307 layer_factory.hpp:172] Creating layer 'ctx_output3/relu_mbox_conf' of type 'Convolution'
I0510 14:48:30.384096  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.384102  5307 net.cpp:200] Created Layer ctx_output3/relu_mbox_conf (170)
I0510 14:48:30.384106  5307 net.cpp:572] ctx_output3/relu_mbox_conf <- ctx_output3_ctx_output3/relu_0_split_1
I0510 14:48:30.384110  5307 net.cpp:542] ctx_output3/relu_mbox_conf -> ctx_output3/relu_mbox_conf
I0510 14:48:30.386309  5307 net.cpp:260] Setting up ctx_output3/relu_mbox_conf
I0510 14:48:30.386322  5307 net.cpp:267] TEST Top shape for layer 170 'ctx_output3/relu_mbox_conf' 8 126 5 9 (45360)
I0510 14:48:30.386328  5307 layer_factory.hpp:172] Creating layer 'ctx_output3/relu_mbox_conf_perm' of type 'Permute'
I0510 14:48:30.386333  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.386339  5307 net.cpp:200] Created Layer ctx_output3/relu_mbox_conf_perm (171)
I0510 14:48:30.386343  5307 net.cpp:572] ctx_output3/relu_mbox_conf_perm <- ctx_output3/relu_mbox_conf
I0510 14:48:30.386348  5307 net.cpp:542] ctx_output3/relu_mbox_conf_perm -> ctx_output3/relu_mbox_conf_perm
I0510 14:48:30.386449  5307 net.cpp:260] Setting up ctx_output3/relu_mbox_conf_perm
I0510 14:48:30.386456  5307 net.cpp:267] TEST Top shape for layer 171 'ctx_output3/relu_mbox_conf_perm' 8 5 9 126 (45360)
I0510 14:48:30.386461  5307 layer_factory.hpp:172] Creating layer 'ctx_output3/relu_mbox_conf_flat' of type 'Flatten'
I0510 14:48:30.386464  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.386468  5307 net.cpp:200] Created Layer ctx_output3/relu_mbox_conf_flat (172)
I0510 14:48:30.386472  5307 net.cpp:572] ctx_output3/relu_mbox_conf_flat <- ctx_output3/relu_mbox_conf_perm
I0510 14:48:30.386476  5307 net.cpp:542] ctx_output3/relu_mbox_conf_flat -> ctx_output3/relu_mbox_conf_flat
I0510 14:48:30.387451  5307 net.cpp:260] Setting up ctx_output3/relu_mbox_conf_flat
I0510 14:48:30.387465  5307 net.cpp:267] TEST Top shape for layer 172 'ctx_output3/relu_mbox_conf_flat' 8 5670 (45360)
I0510 14:48:30.387470  5307 layer_factory.hpp:172] Creating layer 'ctx_output3/relu_mbox_priorbox' of type 'PriorBox'
I0510 14:48:30.387476  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.387483  5307 net.cpp:200] Created Layer ctx_output3/relu_mbox_priorbox (173)
I0510 14:48:30.387488  5307 net.cpp:572] ctx_output3/relu_mbox_priorbox <- ctx_output3_ctx_output3/relu_0_split_2
I0510 14:48:30.387495  5307 net.cpp:572] ctx_output3/relu_mbox_priorbox <- data_data_0_split_3
I0510 14:48:30.387501  5307 net.cpp:542] ctx_output3/relu_mbox_priorbox -> ctx_output3/relu_mbox_priorbox
I0510 14:48:30.387526  5307 net.cpp:260] Setting up ctx_output3/relu_mbox_priorbox
I0510 14:48:30.387534  5307 net.cpp:267] TEST Top shape for layer 173 'ctx_output3/relu_mbox_priorbox' 1 2 1080 (2160)
I0510 14:48:30.387538  5307 layer_factory.hpp:172] Creating layer 'ctx_output4/relu_mbox_loc' of type 'Convolution'
I0510 14:48:30.387543  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.387553  5307 net.cpp:200] Created Layer ctx_output4/relu_mbox_loc (174)
I0510 14:48:30.387557  5307 net.cpp:572] ctx_output4/relu_mbox_loc <- ctx_output4_ctx_output4/relu_0_split_0
I0510 14:48:30.387562  5307 net.cpp:542] ctx_output4/relu_mbox_loc -> ctx_output4/relu_mbox_loc
I0510 14:48:30.388070  5307 net.cpp:260] Setting up ctx_output4/relu_mbox_loc
I0510 14:48:30.388082  5307 net.cpp:267] TEST Top shape for layer 174 'ctx_output4/relu_mbox_loc' 8 16 3 5 (1920)
I0510 14:48:30.388089  5307 layer_factory.hpp:172] Creating layer 'ctx_output4/relu_mbox_loc_perm' of type 'Permute'
I0510 14:48:30.388094  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.388101  5307 net.cpp:200] Created Layer ctx_output4/relu_mbox_loc_perm (175)
I0510 14:48:30.388108  5307 net.cpp:572] ctx_output4/relu_mbox_loc_perm <- ctx_output4/relu_mbox_loc
I0510 14:48:30.388113  5307 net.cpp:542] ctx_output4/relu_mbox_loc_perm -> ctx_output4/relu_mbox_loc_perm
I0510 14:48:30.388193  5307 net.cpp:260] Setting up ctx_output4/relu_mbox_loc_perm
I0510 14:48:30.388201  5307 net.cpp:267] TEST Top shape for layer 175 'ctx_output4/relu_mbox_loc_perm' 8 3 5 16 (1920)
I0510 14:48:30.388206  5307 layer_factory.hpp:172] Creating layer 'ctx_output4/relu_mbox_loc_flat' of type 'Flatten'
I0510 14:48:30.388226  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.388233  5307 net.cpp:200] Created Layer ctx_output4/relu_mbox_loc_flat (176)
I0510 14:48:30.388237  5307 net.cpp:572] ctx_output4/relu_mbox_loc_flat <- ctx_output4/relu_mbox_loc_perm
I0510 14:48:30.388242  5307 net.cpp:542] ctx_output4/relu_mbox_loc_flat -> ctx_output4/relu_mbox_loc_flat
I0510 14:48:30.388301  5307 net.cpp:260] Setting up ctx_output4/relu_mbox_loc_flat
I0510 14:48:30.388309  5307 net.cpp:267] TEST Top shape for layer 176 'ctx_output4/relu_mbox_loc_flat' 8 240 (1920)
I0510 14:48:30.388314  5307 layer_factory.hpp:172] Creating layer 'ctx_output4/relu_mbox_conf' of type 'Convolution'
I0510 14:48:30.388319  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.388327  5307 net.cpp:200] Created Layer ctx_output4/relu_mbox_conf (177)
I0510 14:48:30.388331  5307 net.cpp:572] ctx_output4/relu_mbox_conf <- ctx_output4_ctx_output4/relu_0_split_1
I0510 14:48:30.388336  5307 net.cpp:542] ctx_output4/relu_mbox_conf -> ctx_output4/relu_mbox_conf
I0510 14:48:30.389809  5307 net.cpp:260] Setting up ctx_output4/relu_mbox_conf
I0510 14:48:30.389820  5307 net.cpp:267] TEST Top shape for layer 177 'ctx_output4/relu_mbox_conf' 8 84 3 5 (10080)
I0510 14:48:30.389827  5307 layer_factory.hpp:172] Creating layer 'ctx_output4/relu_mbox_conf_perm' of type 'Permute'
I0510 14:48:30.389832  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.389837  5307 net.cpp:200] Created Layer ctx_output4/relu_mbox_conf_perm (178)
I0510 14:48:30.389842  5307 net.cpp:572] ctx_output4/relu_mbox_conf_perm <- ctx_output4/relu_mbox_conf
I0510 14:48:30.389847  5307 net.cpp:542] ctx_output4/relu_mbox_conf_perm -> ctx_output4/relu_mbox_conf_perm
I0510 14:48:30.389919  5307 net.cpp:260] Setting up ctx_output4/relu_mbox_conf_perm
I0510 14:48:30.389926  5307 net.cpp:267] TEST Top shape for layer 178 'ctx_output4/relu_mbox_conf_perm' 8 3 5 84 (10080)
I0510 14:48:30.389930  5307 layer_factory.hpp:172] Creating layer 'ctx_output4/relu_mbox_conf_flat' of type 'Flatten'
I0510 14:48:30.389935  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.389940  5307 net.cpp:200] Created Layer ctx_output4/relu_mbox_conf_flat (179)
I0510 14:48:30.389943  5307 net.cpp:572] ctx_output4/relu_mbox_conf_flat <- ctx_output4/relu_mbox_conf_perm
I0510 14:48:30.389959  5307 net.cpp:542] ctx_output4/relu_mbox_conf_flat -> ctx_output4/relu_mbox_conf_flat
I0510 14:48:30.391364  5307 net.cpp:260] Setting up ctx_output4/relu_mbox_conf_flat
I0510 14:48:30.391393  5307 net.cpp:267] TEST Top shape for layer 179 'ctx_output4/relu_mbox_conf_flat' 8 1260 (10080)
I0510 14:48:30.391407  5307 layer_factory.hpp:172] Creating layer 'ctx_output4/relu_mbox_priorbox' of type 'PriorBox'
I0510 14:48:30.391420  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.391439  5307 net.cpp:200] Created Layer ctx_output4/relu_mbox_priorbox (180)
I0510 14:48:30.391455  5307 net.cpp:572] ctx_output4/relu_mbox_priorbox <- ctx_output4_ctx_output4/relu_0_split_2
I0510 14:48:30.391474  5307 net.cpp:572] ctx_output4/relu_mbox_priorbox <- data_data_0_split_4
I0510 14:48:30.391490  5307 net.cpp:542] ctx_output4/relu_mbox_priorbox -> ctx_output4/relu_mbox_priorbox
I0510 14:48:30.391535  5307 net.cpp:260] Setting up ctx_output4/relu_mbox_priorbox
I0510 14:48:30.391548  5307 net.cpp:267] TEST Top shape for layer 180 'ctx_output4/relu_mbox_priorbox' 1 2 240 (480)
I0510 14:48:30.391559  5307 layer_factory.hpp:172] Creating layer 'ctx_output5/relu_mbox_loc' of type 'Convolution'
I0510 14:48:30.391571  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.391589  5307 net.cpp:200] Created Layer ctx_output5/relu_mbox_loc (181)
I0510 14:48:30.391605  5307 net.cpp:572] ctx_output5/relu_mbox_loc <- ctx_output5_ctx_output5/relu_0_split_0
I0510 14:48:30.391626  5307 net.cpp:542] ctx_output5/relu_mbox_loc -> ctx_output5/relu_mbox_loc
I0510 14:48:30.393018  5307 net.cpp:260] Setting up ctx_output5/relu_mbox_loc
I0510 14:48:30.393043  5307 net.cpp:267] TEST Top shape for layer 181 'ctx_output5/relu_mbox_loc' 8 16 3 5 (1920)
I0510 14:48:30.393057  5307 layer_factory.hpp:172] Creating layer 'ctx_output5/relu_mbox_loc_perm' of type 'Permute'
I0510 14:48:30.393067  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.393081  5307 net.cpp:200] Created Layer ctx_output5/relu_mbox_loc_perm (182)
I0510 14:48:30.393092  5307 net.cpp:572] ctx_output5/relu_mbox_loc_perm <- ctx_output5/relu_mbox_loc
I0510 14:48:30.393103  5307 net.cpp:542] ctx_output5/relu_mbox_loc_perm -> ctx_output5/relu_mbox_loc_perm
I0510 14:48:30.393191  5307 net.cpp:260] Setting up ctx_output5/relu_mbox_loc_perm
I0510 14:48:30.393204  5307 net.cpp:267] TEST Top shape for layer 182 'ctx_output5/relu_mbox_loc_perm' 8 3 5 16 (1920)
I0510 14:48:30.393214  5307 layer_factory.hpp:172] Creating layer 'ctx_output5/relu_mbox_loc_flat' of type 'Flatten'
I0510 14:48:30.393224  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.393236  5307 net.cpp:200] Created Layer ctx_output5/relu_mbox_loc_flat (183)
I0510 14:48:30.393246  5307 net.cpp:572] ctx_output5/relu_mbox_loc_flat <- ctx_output5/relu_mbox_loc_perm
I0510 14:48:30.393257  5307 net.cpp:542] ctx_output5/relu_mbox_loc_flat -> ctx_output5/relu_mbox_loc_flat
I0510 14:48:30.393319  5307 net.cpp:260] Setting up ctx_output5/relu_mbox_loc_flat
I0510 14:48:30.393332  5307 net.cpp:267] TEST Top shape for layer 183 'ctx_output5/relu_mbox_loc_flat' 8 240 (1920)
I0510 14:48:30.393343  5307 layer_factory.hpp:172] Creating layer 'ctx_output5/relu_mbox_conf' of type 'Convolution'
I0510 14:48:30.393352  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.393366  5307 net.cpp:200] Created Layer ctx_output5/relu_mbox_conf (184)
I0510 14:48:30.393378  5307 net.cpp:572] ctx_output5/relu_mbox_conf <- ctx_output5_ctx_output5/relu_0_split_1
I0510 14:48:30.393398  5307 net.cpp:542] ctx_output5/relu_mbox_conf -> ctx_output5/relu_mbox_conf
I0510 14:48:30.395787  5307 net.cpp:260] Setting up ctx_output5/relu_mbox_conf
I0510 14:48:30.395815  5307 net.cpp:267] TEST Top shape for layer 184 'ctx_output5/relu_mbox_conf' 8 84 3 5 (10080)
I0510 14:48:30.395833  5307 layer_factory.hpp:172] Creating layer 'ctx_output5/relu_mbox_conf_perm' of type 'Permute'
I0510 14:48:30.395848  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.395864  5307 net.cpp:200] Created Layer ctx_output5/relu_mbox_conf_perm (185)
I0510 14:48:30.395879  5307 net.cpp:572] ctx_output5/relu_mbox_conf_perm <- ctx_output5/relu_mbox_conf
I0510 14:48:30.395893  5307 net.cpp:542] ctx_output5/relu_mbox_conf_perm -> ctx_output5/relu_mbox_conf_perm
I0510 14:48:30.395985  5307 net.cpp:260] Setting up ctx_output5/relu_mbox_conf_perm
I0510 14:48:30.396003  5307 net.cpp:267] TEST Top shape for layer 185 'ctx_output5/relu_mbox_conf_perm' 8 3 5 84 (10080)
I0510 14:48:30.396016  5307 layer_factory.hpp:172] Creating layer 'ctx_output5/relu_mbox_conf_flat' of type 'Flatten'
I0510 14:48:30.396030  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.396046  5307 net.cpp:200] Created Layer ctx_output5/relu_mbox_conf_flat (186)
I0510 14:48:30.396060  5307 net.cpp:572] ctx_output5/relu_mbox_conf_flat <- ctx_output5/relu_mbox_conf_perm
I0510 14:48:30.396075  5307 net.cpp:542] ctx_output5/relu_mbox_conf_flat -> ctx_output5/relu_mbox_conf_flat
I0510 14:48:30.396143  5307 net.cpp:260] Setting up ctx_output5/relu_mbox_conf_flat
I0510 14:48:30.396162  5307 net.cpp:267] TEST Top shape for layer 186 'ctx_output5/relu_mbox_conf_flat' 8 1260 (10080)
I0510 14:48:30.396179  5307 layer_factory.hpp:172] Creating layer 'ctx_output5/relu_mbox_priorbox' of type 'PriorBox'
I0510 14:48:30.396200  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.396216  5307 net.cpp:200] Created Layer ctx_output5/relu_mbox_priorbox (187)
I0510 14:48:30.396230  5307 net.cpp:572] ctx_output5/relu_mbox_priorbox <- ctx_output5_ctx_output5/relu_0_split_2
I0510 14:48:30.396245  5307 net.cpp:572] ctx_output5/relu_mbox_priorbox <- data_data_0_split_5
I0510 14:48:30.396260  5307 net.cpp:542] ctx_output5/relu_mbox_priorbox -> ctx_output5/relu_mbox_priorbox
I0510 14:48:30.396292  5307 net.cpp:260] Setting up ctx_output5/relu_mbox_priorbox
I0510 14:48:30.396317  5307 net.cpp:267] TEST Top shape for layer 187 'ctx_output5/relu_mbox_priorbox' 1 2 240 (480)
I0510 14:48:30.396332  5307 layer_factory.hpp:172] Creating layer 'mbox_loc' of type 'Concat'
I0510 14:48:30.396344  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.396360  5307 net.cpp:200] Created Layer mbox_loc (188)
I0510 14:48:30.396374  5307 net.cpp:572] mbox_loc <- ctx_output1/relu_mbox_loc_flat
I0510 14:48:30.396389  5307 net.cpp:572] mbox_loc <- ctx_output2/relu_mbox_loc_flat
I0510 14:48:30.396404  5307 net.cpp:572] mbox_loc <- ctx_output3/relu_mbox_loc_flat
I0510 14:48:30.396417  5307 net.cpp:572] mbox_loc <- ctx_output4/relu_mbox_loc_flat
I0510 14:48:30.396438  5307 net.cpp:572] mbox_loc <- ctx_output5/relu_mbox_loc_flat
I0510 14:48:30.396452  5307 net.cpp:542] mbox_loc -> mbox_loc
I0510 14:48:30.396486  5307 net.cpp:260] Setting up mbox_loc
I0510 14:48:30.396502  5307 net.cpp:267] TEST Top shape for layer 188 'mbox_loc' 8 12824 (102592)
I0510 14:48:30.396515  5307 layer_factory.hpp:172] Creating layer 'mbox_conf' of type 'Concat'
I0510 14:48:30.396543  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.396560  5307 net.cpp:200] Created Layer mbox_conf (189)
I0510 14:48:30.396574  5307 net.cpp:572] mbox_conf <- ctx_output1/relu_mbox_conf_flat
I0510 14:48:30.396589  5307 net.cpp:572] mbox_conf <- ctx_output2/relu_mbox_conf_flat
I0510 14:48:30.396603  5307 net.cpp:572] mbox_conf <- ctx_output3/relu_mbox_conf_flat
I0510 14:48:30.396617  5307 net.cpp:572] mbox_conf <- ctx_output4/relu_mbox_conf_flat
I0510 14:48:30.396631  5307 net.cpp:572] mbox_conf <- ctx_output5/relu_mbox_conf_flat
I0510 14:48:30.396648  5307 net.cpp:542] mbox_conf -> mbox_conf
I0510 14:48:30.396682  5307 net.cpp:260] Setting up mbox_conf
I0510 14:48:30.396697  5307 net.cpp:267] TEST Top shape for layer 189 'mbox_conf' 8 67326 (538608)
I0510 14:48:30.396711  5307 layer_factory.hpp:172] Creating layer 'mbox_priorbox' of type 'Concat'
I0510 14:48:30.396724  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.396739  5307 net.cpp:200] Created Layer mbox_priorbox (190)
I0510 14:48:30.396751  5307 net.cpp:572] mbox_priorbox <- ctx_output1/relu_mbox_priorbox
I0510 14:48:30.396765  5307 net.cpp:572] mbox_priorbox <- ctx_output2/relu_mbox_priorbox
I0510 14:48:30.396780  5307 net.cpp:572] mbox_priorbox <- ctx_output3/relu_mbox_priorbox
I0510 14:48:30.396793  5307 net.cpp:572] mbox_priorbox <- ctx_output4/relu_mbox_priorbox
I0510 14:48:30.396806  5307 net.cpp:572] mbox_priorbox <- ctx_output5/relu_mbox_priorbox
I0510 14:48:30.396821  5307 net.cpp:542] mbox_priorbox -> mbox_priorbox
I0510 14:48:30.396848  5307 net.cpp:260] Setting up mbox_priorbox
I0510 14:48:30.396864  5307 net.cpp:267] TEST Top shape for layer 190 'mbox_priorbox' 1 2 12824 (25648)
I0510 14:48:30.396878  5307 layer_factory.hpp:172] Creating layer 'mbox_conf_reshape' of type 'Reshape'
I0510 14:48:30.396891  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.396908  5307 net.cpp:200] Created Layer mbox_conf_reshape (191)
I0510 14:48:30.396921  5307 net.cpp:572] mbox_conf_reshape <- mbox_conf
I0510 14:48:30.396935  5307 net.cpp:542] mbox_conf_reshape -> mbox_conf_reshape
I0510 14:48:30.396970  5307 net.cpp:260] Setting up mbox_conf_reshape
I0510 14:48:30.396992  5307 net.cpp:267] TEST Top shape for layer 191 'mbox_conf_reshape' 8 3206 21 (538608)
I0510 14:48:30.397006  5307 layer_factory.hpp:172] Creating layer 'mbox_conf_softmax' of type 'Softmax'
I0510 14:48:30.397020  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.397042  5307 net.cpp:200] Created Layer mbox_conf_softmax (192)
I0510 14:48:30.397056  5307 net.cpp:572] mbox_conf_softmax <- mbox_conf_reshape
I0510 14:48:30.397070  5307 net.cpp:542] mbox_conf_softmax -> mbox_conf_softmax
I0510 14:48:30.397140  5307 net.cpp:260] Setting up mbox_conf_softmax
I0510 14:48:30.397156  5307 net.cpp:267] TEST Top shape for layer 192 'mbox_conf_softmax' 8 3206 21 (538608)
I0510 14:48:30.397169  5307 layer_factory.hpp:172] Creating layer 'mbox_conf_flatten' of type 'Flatten'
I0510 14:48:30.397182  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.397215  5307 net.cpp:200] Created Layer mbox_conf_flatten (193)
I0510 14:48:30.397230  5307 net.cpp:572] mbox_conf_flatten <- mbox_conf_softmax
I0510 14:48:30.397243  5307 net.cpp:542] mbox_conf_flatten -> mbox_conf_flatten
I0510 14:48:30.399592  5307 net.cpp:260] Setting up mbox_conf_flatten
I0510 14:48:30.399636  5307 net.cpp:267] TEST Top shape for layer 193 'mbox_conf_flatten' 8 67326 (538608)
I0510 14:48:30.399652  5307 layer_factory.hpp:172] Creating layer 'detection_out' of type 'DetectionOutput'
I0510 14:48:30.399667  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.399698  5307 net.cpp:200] Created Layer detection_out (194)
I0510 14:48:30.399714  5307 net.cpp:572] detection_out <- mbox_loc
I0510 14:48:30.399745  5307 net.cpp:572] detection_out <- mbox_conf_flatten
I0510 14:48:30.399768  5307 net.cpp:572] detection_out <- mbox_priorbox
I0510 14:48:30.399790  5307 net.cpp:542] detection_out -> detection_out
I0510 14:48:30.401743  5307 net.cpp:260] Setting up detection_out
I0510 14:48:30.401783  5307 net.cpp:267] TEST Top shape for layer 194 'detection_out' 1 1 1 7 (7)
I0510 14:48:30.401799  5307 layer_factory.hpp:172] Creating layer 'detection_eval' of type 'DetectionEvaluate'
I0510 14:48:30.401813  5307 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0510 14:48:30.401832  5307 net.cpp:200] Created Layer detection_eval (195)
I0510 14:48:30.401847  5307 net.cpp:572] detection_eval <- detection_out
I0510 14:48:30.401861  5307 net.cpp:572] detection_eval <- label
I0510 14:48:30.401875  5307 net.cpp:542] detection_eval -> detection_eval
I0510 14:48:30.403245  5307 net.cpp:260] Setting up detection_eval
I0510 14:48:30.403267  5307 net.cpp:267] TEST Top shape for layer 195 'detection_eval' 1 1 21 5 (105)
I0510 14:48:30.403282  5307 net.cpp:338] detection_eval does not need backward computation.
I0510 14:48:30.403296  5307 net.cpp:338] detection_out does not need backward computation.
I0510 14:48:30.403309  5307 net.cpp:338] mbox_conf_flatten does not need backward computation.
I0510 14:48:30.403322  5307 net.cpp:338] mbox_conf_softmax does not need backward computation.
I0510 14:48:30.403334  5307 net.cpp:338] mbox_conf_reshape does not need backward computation.
I0510 14:48:30.403347  5307 net.cpp:338] mbox_priorbox does not need backward computation.
I0510 14:48:30.403362  5307 net.cpp:338] mbox_conf does not need backward computation.
I0510 14:48:30.403375  5307 net.cpp:338] mbox_loc does not need backward computation.
I0510 14:48:30.403389  5307 net.cpp:338] ctx_output5/relu_mbox_priorbox does not need backward computation.
I0510 14:48:30.403403  5307 net.cpp:338] ctx_output5/relu_mbox_conf_flat does not need backward computation.
I0510 14:48:30.403415  5307 net.cpp:338] ctx_output5/relu_mbox_conf_perm does not need backward computation.
I0510 14:48:30.403429  5307 net.cpp:338] ctx_output5/relu_mbox_conf does not need backward computation.
I0510 14:48:30.403450  5307 net.cpp:338] ctx_output5/relu_mbox_loc_flat does not need backward computation.
I0510 14:48:30.403471  5307 net.cpp:338] ctx_output5/relu_mbox_loc_perm does not need backward computation.
I0510 14:48:30.403484  5307 net.cpp:338] ctx_output5/relu_mbox_loc does not need backward computation.
I0510 14:48:30.403497  5307 net.cpp:338] ctx_output4/relu_mbox_priorbox does not need backward computation.
I0510 14:48:30.403511  5307 net.cpp:338] ctx_output4/relu_mbox_conf_flat does not need backward computation.
I0510 14:48:30.403522  5307 net.cpp:338] ctx_output4/relu_mbox_conf_perm does not need backward computation.
I0510 14:48:30.403537  5307 net.cpp:338] ctx_output4/relu_mbox_conf does not need backward computation.
I0510 14:48:30.403549  5307 net.cpp:338] ctx_output4/relu_mbox_loc_flat does not need backward computation.
I0510 14:48:30.403563  5307 net.cpp:338] ctx_output4/relu_mbox_loc_perm does not need backward computation.
I0510 14:48:30.403575  5307 net.cpp:338] ctx_output4/relu_mbox_loc does not need backward computation.
I0510 14:48:30.403589  5307 net.cpp:338] ctx_output3/relu_mbox_priorbox does not need backward computation.
I0510 14:48:30.403602  5307 net.cpp:338] ctx_output3/relu_mbox_conf_flat does not need backward computation.
I0510 14:48:30.403615  5307 net.cpp:338] ctx_output3/relu_mbox_conf_perm does not need backward computation.
I0510 14:48:30.403628  5307 net.cpp:338] ctx_output3/relu_mbox_conf does not need backward computation.
I0510 14:48:30.403641  5307 net.cpp:338] ctx_output3/relu_mbox_loc_flat does not need backward computation.
I0510 14:48:30.403654  5307 net.cpp:338] ctx_output3/relu_mbox_loc_perm does not need backward computation.
I0510 14:48:30.403666  5307 net.cpp:338] ctx_output3/relu_mbox_loc does not need backward computation.
I0510 14:48:30.403682  5307 net.cpp:338] ctx_output2/relu_mbox_priorbox does not need backward computation.
I0510 14:48:30.403695  5307 net.cpp:338] ctx_output2/relu_mbox_conf_flat does not need backward computation.
I0510 14:48:30.403708  5307 net.cpp:338] ctx_output2/relu_mbox_conf_perm does not need backward computation.
I0510 14:48:30.403722  5307 net.cpp:338] ctx_output2/relu_mbox_conf does not need backward computation.
I0510 14:48:30.403733  5307 net.cpp:338] ctx_output2/relu_mbox_loc_flat does not need backward computation.
I0510 14:48:30.403746  5307 net.cpp:338] ctx_output2/relu_mbox_loc_perm does not need backward computation.
I0510 14:48:30.403759  5307 net.cpp:338] ctx_output2/relu_mbox_loc does not need backward computation.
I0510 14:48:30.403770  5307 net.cpp:338] ctx_output1/relu_mbox_priorbox does not need backward computation.
I0510 14:48:30.403787  5307 net.cpp:338] ctx_output1/relu_mbox_conf_flat does not need backward computation.
I0510 14:48:30.403803  5307 net.cpp:338] ctx_output1/relu_mbox_conf_perm does not need backward computation.
I0510 14:48:30.403818  5307 net.cpp:338] ctx_output1/relu_mbox_conf does not need backward computation.
I0510 14:48:30.403834  5307 net.cpp:338] ctx_output1/relu_mbox_loc_flat does not need backward computation.
I0510 14:48:30.403849  5307 net.cpp:338] ctx_output1/relu_mbox_loc_perm does not need backward computation.
I0510 14:48:30.403864  5307 net.cpp:338] ctx_output1/relu_mbox_loc does not need backward computation.
I0510 14:48:30.403879  5307 net.cpp:338] ctx_output5_ctx_output5/relu_0_split does not need backward computation.
I0510 14:48:30.403895  5307 net.cpp:338] ctx_output5/relu does not need backward computation.
I0510 14:48:30.403910  5307 net.cpp:338] ctx_output5/bn does not need backward computation.
I0510 14:48:30.403926  5307 net.cpp:338] ctx_output5 does not need backward computation.
I0510 14:48:30.403944  5307 net.cpp:338] ctx_output5/1x1/relu does not need backward computation.
I0510 14:48:30.403959  5307 net.cpp:338] ctx_output5/1x1/bn does not need backward computation.
I0510 14:48:30.403973  5307 net.cpp:338] ctx_output5/1x1 does not need backward computation.
I0510 14:48:30.403988  5307 net.cpp:338] ctx_output4_ctx_output4/relu_0_split does not need backward computation.
I0510 14:48:30.404006  5307 net.cpp:338] ctx_output4/relu does not need backward computation.
I0510 14:48:30.404026  5307 net.cpp:338] ctx_output4/bn does not need backward computation.
I0510 14:48:30.404042  5307 net.cpp:338] ctx_output4 does not need backward computation.
I0510 14:48:30.404057  5307 net.cpp:338] ctx_output4/1x1/relu does not need backward computation.
I0510 14:48:30.404072  5307 net.cpp:338] ctx_output4/1x1/bn does not need backward computation.
I0510 14:48:30.404086  5307 net.cpp:338] ctx_output4/1x1 does not need backward computation.
I0510 14:48:30.404101  5307 net.cpp:338] ctx_output3_ctx_output3/relu_0_split does not need backward computation.
I0510 14:48:30.404116  5307 net.cpp:338] ctx_output3/relu does not need backward computation.
I0510 14:48:30.404131  5307 net.cpp:338] ctx_output3/bn does not need backward computation.
I0510 14:48:30.404146  5307 net.cpp:338] ctx_output3 does not need backward computation.
I0510 14:48:30.404161  5307 net.cpp:338] ctx_output3/1x1/relu does not need backward computation.
I0510 14:48:30.404176  5307 net.cpp:338] ctx_output3/1x1/bn does not need backward computation.
I0510 14:48:30.404191  5307 net.cpp:338] ctx_output3/1x1 does not need backward computation.
I0510 14:48:30.404206  5307 net.cpp:338] ctx_output2_ctx_output2/relu_0_split does not need backward computation.
I0510 14:48:30.404222  5307 net.cpp:338] ctx_output2/relu does not need backward computation.
I0510 14:48:30.404237  5307 net.cpp:338] ctx_output2/bn does not need backward computation.
I0510 14:48:30.404251  5307 net.cpp:338] ctx_output2 does not need backward computation.
I0510 14:48:30.404266  5307 net.cpp:338] ctx_output2/1x1/relu does not need backward computation.
I0510 14:48:30.404283  5307 net.cpp:338] ctx_output2/1x1/bn does not need backward computation.
I0510 14:48:30.404299  5307 net.cpp:338] ctx_output2/1x1 does not need backward computation.
I0510 14:48:30.404315  5307 net.cpp:338] ctx_output1_ctx_output1/relu_0_split does not need backward computation.
I0510 14:48:30.404330  5307 net.cpp:338] ctx_output1/relu does not need backward computation.
I0510 14:48:30.404345  5307 net.cpp:338] ctx_output1/bn does not need backward computation.
I0510 14:48:30.404359  5307 net.cpp:338] ctx_output1 does not need backward computation.
I0510 14:48:30.404374  5307 net.cpp:338] ctx_output1/1x1/relu does not need backward computation.
I0510 14:48:30.404389  5307 net.cpp:338] ctx_output1/1x1/bn does not need backward computation.
I0510 14:48:30.404404  5307 net.cpp:338] ctx_output1/1x1 does not need backward computation.
I0510 14:48:30.404419  5307 net.cpp:338] pool8 does not need backward computation.
I0510 14:48:30.404434  5307 net.cpp:338] pool7_pool7_0_split does not need backward computation.
I0510 14:48:30.404449  5307 net.cpp:338] pool7 does not need backward computation.
I0510 14:48:30.404464  5307 net.cpp:338] pool6_pool6_0_split does not need backward computation.
I0510 14:48:30.404479  5307 net.cpp:338] pool6 does not need backward computation.
I0510 14:48:30.404495  5307 net.cpp:338] conv6/sep_relu6/sep_0_split does not need backward computation.
I0510 14:48:30.404510  5307 net.cpp:338] relu6/sep does not need backward computation.
I0510 14:48:30.404530  5307 net.cpp:338] conv6/sep/scale does not need backward computation.
I0510 14:48:30.404546  5307 net.cpp:338] conv6/sep/bn does not need backward computation.
I0510 14:48:30.404561  5307 net.cpp:338] conv6/sep does not need backward computation.
I0510 14:48:30.404577  5307 net.cpp:338] relu6/dw does not need backward computation.
I0510 14:48:30.404592  5307 net.cpp:338] conv6/dw/scale does not need backward computation.
I0510 14:48:30.404606  5307 net.cpp:338] conv6/dw/bn does not need backward computation.
I0510 14:48:30.404621  5307 net.cpp:338] conv6/dw does not need backward computation.
I0510 14:48:30.404636  5307 net.cpp:338] relu5_6/sep does not need backward computation.
I0510 14:48:30.404650  5307 net.cpp:338] conv5_6/sep/scale does not need backward computation.
I0510 14:48:30.404665  5307 net.cpp:338] conv5_6/sep/bn does not need backward computation.
I0510 14:48:30.404683  5307 net.cpp:338] conv5_6/sep does not need backward computation.
I0510 14:48:30.404705  5307 net.cpp:338] relu5_6/dw does not need backward computation.
I0510 14:48:30.404719  5307 net.cpp:338] conv5_6/dw/scale does not need backward computation.
I0510 14:48:30.404733  5307 net.cpp:338] conv5_6/dw/bn does not need backward computation.
I0510 14:48:30.404748  5307 net.cpp:338] conv5_6/dw does not need backward computation.
I0510 14:48:30.404763  5307 net.cpp:338] conv5_5/sep_relu5_5/sep_0_split does not need backward computation.
I0510 14:48:30.404779  5307 net.cpp:338] relu5_5/sep does not need backward computation.
I0510 14:48:30.404793  5307 net.cpp:338] conv5_5/sep/scale does not need backward computation.
I0510 14:48:30.404808  5307 net.cpp:338] conv5_5/sep/bn does not need backward computation.
I0510 14:48:30.404824  5307 net.cpp:338] conv5_5/sep does not need backward computation.
I0510 14:48:30.404842  5307 net.cpp:338] relu5_5/dw does not need backward computation.
I0510 14:48:30.404860  5307 net.cpp:338] conv5_5/dw/scale does not need backward computation.
I0510 14:48:30.404875  5307 net.cpp:338] conv5_5/dw/bn does not need backward computation.
I0510 14:48:30.404891  5307 net.cpp:338] conv5_5/dw does not need backward computation.
I0510 14:48:30.404906  5307 net.cpp:338] relu5_4/sep does not need backward computation.
I0510 14:48:30.404920  5307 net.cpp:338] conv5_4/sep/scale does not need backward computation.
I0510 14:48:30.404935  5307 net.cpp:338] conv5_4/sep/bn does not need backward computation.
I0510 14:48:30.404949  5307 net.cpp:338] conv5_4/sep does not need backward computation.
I0510 14:48:30.404964  5307 net.cpp:338] relu5_4/dw does not need backward computation.
I0510 14:48:30.404978  5307 net.cpp:338] conv5_4/dw/scale does not need backward computation.
I0510 14:48:30.404996  5307 net.cpp:338] conv5_4/dw/bn does not need backward computation.
I0510 14:48:30.405012  5307 net.cpp:338] conv5_4/dw does not need backward computation.
I0510 14:48:30.405027  5307 net.cpp:338] relu5_3/sep does not need backward computation.
I0510 14:48:30.405042  5307 net.cpp:338] conv5_3/sep/scale does not need backward computation.
I0510 14:48:30.405057  5307 net.cpp:338] conv5_3/sep/bn does not need backward computation.
I0510 14:48:30.405076  5307 net.cpp:338] conv5_3/sep does not need backward computation.
I0510 14:48:30.405092  5307 net.cpp:338] relu5_3/dw does not need backward computation.
I0510 14:48:30.405107  5307 net.cpp:338] conv5_3/dw/scale does not need backward computation.
I0510 14:48:30.405122  5307 net.cpp:338] conv5_3/dw/bn does not need backward computation.
I0510 14:48:30.405136  5307 net.cpp:338] conv5_3/dw does not need backward computation.
I0510 14:48:30.405153  5307 net.cpp:338] relu5_2/sep does not need backward computation.
I0510 14:48:30.405167  5307 net.cpp:338] conv5_2/sep/scale does not need backward computation.
I0510 14:48:30.405182  5307 net.cpp:338] conv5_2/sep/bn does not need backward computation.
I0510 14:48:30.405198  5307 net.cpp:338] conv5_2/sep does not need backward computation.
I0510 14:48:30.405213  5307 net.cpp:338] relu5_2/dw does not need backward computation.
I0510 14:48:30.405228  5307 net.cpp:338] conv5_2/dw/scale does not need backward computation.
I0510 14:48:30.405243  5307 net.cpp:338] conv5_2/dw/bn does not need backward computation.
I0510 14:48:30.405258  5307 net.cpp:338] conv5_2/dw does not need backward computation.
I0510 14:48:30.405273  5307 net.cpp:338] relu5_1/sep does not need backward computation.
I0510 14:48:30.405287  5307 net.cpp:338] conv5_1/sep/scale does not need backward computation.
I0510 14:48:30.405303  5307 net.cpp:338] conv5_1/sep/bn does not need backward computation.
I0510 14:48:30.405318  5307 net.cpp:338] conv5_1/sep does not need backward computation.
I0510 14:48:30.405333  5307 net.cpp:338] relu5_1/dw does not need backward computation.
I0510 14:48:30.405346  5307 net.cpp:338] conv5_1/dw/scale does not need backward computation.
I0510 14:48:30.405361  5307 net.cpp:338] conv5_1/dw/bn does not need backward computation.
I0510 14:48:30.405386  5307 net.cpp:338] conv5_1/dw does not need backward computation.
I0510 14:48:30.405408  5307 net.cpp:338] relu4_2/sep does not need backward computation.
I0510 14:48:30.405423  5307 net.cpp:338] conv4_2/sep/scale does not need backward computation.
I0510 14:48:30.405438  5307 net.cpp:338] conv4_2/sep/bn does not need backward computation.
I0510 14:48:30.405453  5307 net.cpp:338] conv4_2/sep does not need backward computation.
I0510 14:48:30.405468  5307 net.cpp:338] relu4_2/dw does not need backward computation.
I0510 14:48:30.405483  5307 net.cpp:338] conv4_2/dw/scale does not need backward computation.
I0510 14:48:30.405498  5307 net.cpp:338] conv4_2/dw/bn does not need backward computation.
I0510 14:48:30.405513  5307 net.cpp:338] conv4_2/dw does not need backward computation.
I0510 14:48:30.405527  5307 net.cpp:338] relu4_1/sep does not need backward computation.
I0510 14:48:30.405542  5307 net.cpp:338] conv4_1/sep/scale does not need backward computation.
I0510 14:48:30.405557  5307 net.cpp:338] conv4_1/sep/bn does not need backward computation.
I0510 14:48:30.405571  5307 net.cpp:338] conv4_1/sep does not need backward computation.
I0510 14:48:30.405586  5307 net.cpp:338] relu4_1/dw does not need backward computation.
I0510 14:48:30.405601  5307 net.cpp:338] conv4_1/dw/scale does not need backward computation.
I0510 14:48:30.405614  5307 net.cpp:338] conv4_1/dw/bn does not need backward computation.
I0510 14:48:30.405630  5307 net.cpp:338] conv4_1/dw does not need backward computation.
I0510 14:48:30.405644  5307 net.cpp:338] relu3_2/sep does not need backward computation.
I0510 14:48:30.405659  5307 net.cpp:338] conv3_2/sep/scale does not need backward computation.
I0510 14:48:30.405673  5307 net.cpp:338] conv3_2/sep/bn does not need backward computation.
I0510 14:48:30.405691  5307 net.cpp:338] conv3_2/sep does not need backward computation.
I0510 14:48:30.405706  5307 net.cpp:338] relu3_2/dw does not need backward computation.
I0510 14:48:30.405722  5307 net.cpp:338] conv3_2/dw/scale does not need backward computation.
I0510 14:48:30.405736  5307 net.cpp:338] conv3_2/dw/bn does not need backward computation.
I0510 14:48:30.405751  5307 net.cpp:338] conv3_2/dw does not need backward computation.
I0510 14:48:30.405766  5307 net.cpp:338] relu3_1/sep does not need backward computation.
I0510 14:48:30.405781  5307 net.cpp:338] conv3_1/sep/scale does not need backward computation.
I0510 14:48:30.405797  5307 net.cpp:338] conv3_1/sep/bn does not need backward computation.
I0510 14:48:30.405812  5307 net.cpp:338] conv3_1/sep does not need backward computation.
I0510 14:48:30.405827  5307 net.cpp:338] relu3_1/dw does not need backward computation.
I0510 14:48:30.405841  5307 net.cpp:338] conv3_1/dw/scale does not need backward computation.
I0510 14:48:30.405856  5307 net.cpp:338] conv3_1/dw/bn does not need backward computation.
I0510 14:48:30.405870  5307 net.cpp:338] conv3_1/dw does not need backward computation.
I0510 14:48:30.405886  5307 net.cpp:338] relu2_2/sep does not need backward computation.
I0510 14:48:30.405901  5307 net.cpp:338] conv2_2/sep/scale does not need backward computation.
I0510 14:48:30.405916  5307 net.cpp:338] conv2_2/sep/bn does not need backward computation.
I0510 14:48:30.405930  5307 net.cpp:338] conv2_2/sep does not need backward computation.
I0510 14:48:30.405944  5307 net.cpp:338] relu2_2/dw does not need backward computation.
I0510 14:48:30.405959  5307 net.cpp:338] conv2_2/dw/scale does not need backward computation.
I0510 14:48:30.405974  5307 net.cpp:338] conv2_2/dw/bn does not need backward computation.
I0510 14:48:30.405989  5307 net.cpp:338] conv2_2/dw does not need backward computation.
I0510 14:48:30.406004  5307 net.cpp:338] relu2_1/sep does not need backward computation.
I0510 14:48:30.406018  5307 net.cpp:338] conv2_1/sep/scale does not need backward computation.
I0510 14:48:30.406033  5307 net.cpp:338] conv2_1/sep/bn does not need backward computation.
I0510 14:48:30.406046  5307 net.cpp:338] conv2_1/sep does not need backward computation.
I0510 14:48:30.406064  5307 net.cpp:338] relu2_1/dw does not need backward computation.
I0510 14:48:30.406086  5307 net.cpp:338] conv2_1/dw/scale does not need backward computation.
I0510 14:48:30.406100  5307 net.cpp:338] conv2_1/dw/bn does not need backward computation.
I0510 14:48:30.406116  5307 net.cpp:338] conv2_1/dw does not need backward computation.
I0510 14:48:30.406131  5307 net.cpp:338] relu1 does not need backward computation.
I0510 14:48:30.406146  5307 net.cpp:338] conv1/scale does not need backward computation.
I0510 14:48:30.406160  5307 net.cpp:338] conv1/bn does not need backward computation.
I0510 14:48:30.406175  5307 net.cpp:338] conv1 does not need backward computation.
I0510 14:48:30.406190  5307 net.cpp:338] data/bias does not need backward computation.
I0510 14:48:30.406205  5307 net.cpp:338] data_data_0_split does not need backward computation.
I0510 14:48:30.406220  5307 net.cpp:338] data does not need backward computation.
I0510 14:48:30.406234  5307 net.cpp:380] This network produces output detection_eval
I0510 14:48:30.406448  5307 net.cpp:403] Top memory (TEST) required for data: 1081855432 diff: 1081855432
I0510 14:48:30.406466  5307 net.cpp:406] Bottom memory (TEST) required for data: 1081855008 diff: 1081855008
I0510 14:48:30.406481  5307 net.cpp:409] Shared (in-place) memory (TEST) by data: 679149568 diff: 679149568
I0510 14:48:30.406496  5307 net.cpp:412] Parameters memory (TEST) required for data: 9462808 diff: 9462808
I0510 14:48:30.406510  5307 net.cpp:415] Parameters shared memory (TEST) by data: 0 diff: 0
I0510 14:48:30.406525  5307 net.cpp:421] Network initialization done.
I0510 14:48:30.406883  5307 solver.cpp:55] Solver scaffolding done.
I0510 14:48:30.413641  5307 caffe.cpp:158] Finetuning from ../trained/image_classification/imagenet_mobilenet-0.5/initial/imagenet_mobilenet-0.5_iter_320000.caffemodel
I0510 14:48:30.415630  5307 net.cpp:1144] Copying source layer data Type:Data #blobs=0
I0510 14:48:30.415675  5307 net.cpp:1144] Copying source layer data/bias Type:Bias #blobs=1
I0510 14:48:30.415719  5307 net.cpp:1144] Copying source layer conv1 Type:Convolution #blobs=1
I0510 14:48:30.415745  5307 net.cpp:1144] Copying source layer conv1/bn Type:BatchNorm #blobs=3
I0510 14:48:30.415774  5307 net.cpp:1144] Copying source layer conv1/scale Type:Scale #blobs=2
I0510 14:48:30.415802  5307 net.cpp:1144] Copying source layer relu1 Type:ReLU #blobs=0
I0510 14:48:30.415817  5307 net.cpp:1144] Copying source layer conv2_1/dw Type:Convolution #blobs=1
I0510 14:48:30.415838  5307 net.cpp:1144] Copying source layer conv2_1/dw/bn Type:BatchNorm #blobs=3
I0510 14:48:30.415866  5307 net.cpp:1144] Copying source layer conv2_1/dw/scale Type:Scale #blobs=2
I0510 14:48:30.415891  5307 net.cpp:1144] Copying source layer relu2_1/dw Type:ReLU #blobs=0
I0510 14:48:30.415906  5307 net.cpp:1144] Copying source layer conv2_1/sep Type:Convolution #blobs=1
I0510 14:48:30.415927  5307 net.cpp:1144] Copying source layer conv2_1/sep/bn Type:BatchNorm #blobs=3
I0510 14:48:30.415959  5307 net.cpp:1144] Copying source layer conv2_1/sep/scale Type:Scale #blobs=2
I0510 14:48:30.415987  5307 net.cpp:1144] Copying source layer relu2_1/sep Type:ReLU #blobs=0
I0510 14:48:30.416002  5307 net.cpp:1144] Copying source layer conv2_2/dw Type:Convolution #blobs=1
I0510 14:48:30.416023  5307 net.cpp:1144] Copying source layer conv2_2/dw/bn Type:BatchNorm #blobs=3
I0510 14:48:30.416052  5307 net.cpp:1144] Copying source layer conv2_2/dw/scale Type:Scale #blobs=2
I0510 14:48:30.416079  5307 net.cpp:1144] Copying source layer relu2_2/dw Type:ReLU #blobs=0
I0510 14:48:30.416095  5307 net.cpp:1144] Copying source layer conv2_2/sep Type:Convolution #blobs=1
I0510 14:48:30.416118  5307 net.cpp:1144] Copying source layer conv2_2/sep/bn Type:BatchNorm #blobs=3
I0510 14:48:30.416151  5307 net.cpp:1144] Copying source layer conv2_2/sep/scale Type:Scale #blobs=2
I0510 14:48:30.416177  5307 net.cpp:1144] Copying source layer relu2_2/sep Type:ReLU #blobs=0
I0510 14:48:30.416193  5307 net.cpp:1144] Copying source layer conv3_1/dw Type:Convolution #blobs=1
I0510 14:48:30.416219  5307 net.cpp:1144] Copying source layer conv3_1/dw/bn Type:BatchNorm #blobs=3
I0510 14:48:30.416255  5307 net.cpp:1144] Copying source layer conv3_1/dw/scale Type:Scale #blobs=2
I0510 14:48:30.416281  5307 net.cpp:1144] Copying source layer relu3_1/dw Type:ReLU #blobs=0
I0510 14:48:30.416297  5307 net.cpp:1144] Copying source layer conv3_1/sep Type:Convolution #blobs=1
I0510 14:48:30.416319  5307 net.cpp:1144] Copying source layer conv3_1/sep/bn Type:BatchNorm #blobs=3
I0510 14:48:30.416348  5307 net.cpp:1144] Copying source layer conv3_1/sep/scale Type:Scale #blobs=2
I0510 14:48:30.416374  5307 net.cpp:1144] Copying source layer relu3_1/sep Type:ReLU #blobs=0
I0510 14:48:30.416389  5307 net.cpp:1144] Copying source layer conv3_2/dw Type:Convolution #blobs=1
I0510 14:48:30.416410  5307 net.cpp:1144] Copying source layer conv3_2/dw/bn Type:BatchNorm #blobs=3
I0510 14:48:30.416440  5307 net.cpp:1144] Copying source layer conv3_2/dw/scale Type:Scale #blobs=2
I0510 14:48:30.416465  5307 net.cpp:1144] Copying source layer relu3_2/dw Type:ReLU #blobs=0
I0510 14:48:30.416479  5307 net.cpp:1144] Copying source layer conv3_2/sep Type:Convolution #blobs=1
I0510 14:48:30.416503  5307 net.cpp:1144] Copying source layer conv3_2/sep/bn Type:BatchNorm #blobs=3
I0510 14:48:30.416546  5307 net.cpp:1144] Copying source layer conv3_2/sep/scale Type:Scale #blobs=2
I0510 14:48:30.416574  5307 net.cpp:1144] Copying source layer relu3_2/sep Type:ReLU #blobs=0
I0510 14:48:30.416589  5307 net.cpp:1144] Copying source layer conv4_1/dw Type:Convolution #blobs=1
I0510 14:48:30.416610  5307 net.cpp:1144] Copying source layer conv4_1/dw/bn Type:BatchNorm #blobs=3
I0510 14:48:30.416638  5307 net.cpp:1144] Copying source layer conv4_1/dw/scale Type:Scale #blobs=2
I0510 14:48:30.416666  5307 net.cpp:1144] Copying source layer relu4_1/dw Type:ReLU #blobs=0
I0510 14:48:30.416682  5307 net.cpp:1144] Copying source layer conv4_1/sep Type:Convolution #blobs=1
I0510 14:48:30.416709  5307 net.cpp:1144] Copying source layer conv4_1/sep/bn Type:BatchNorm #blobs=3
I0510 14:48:30.416739  5307 net.cpp:1144] Copying source layer conv4_1/sep/scale Type:Scale #blobs=2
I0510 14:48:30.416764  5307 net.cpp:1144] Copying source layer relu4_1/sep Type:ReLU #blobs=0
I0510 14:48:30.416779  5307 net.cpp:1144] Copying source layer conv4_2/dw Type:Convolution #blobs=1
I0510 14:48:30.416802  5307 net.cpp:1144] Copying source layer conv4_2/dw/bn Type:BatchNorm #blobs=3
I0510 14:48:30.416828  5307 net.cpp:1144] Copying source layer conv4_2/dw/scale Type:Scale #blobs=2
I0510 14:48:30.416851  5307 net.cpp:1144] Copying source layer relu4_2/dw Type:ReLU #blobs=0
I0510 14:48:30.416863  5307 net.cpp:1144] Copying source layer conv4_2/sep Type:Convolution #blobs=1
I0510 14:48:30.416894  5307 net.cpp:1144] Copying source layer conv4_2/sep/bn Type:BatchNorm #blobs=3
I0510 14:48:30.416921  5307 net.cpp:1144] Copying source layer conv4_2/sep/scale Type:Scale #blobs=2
I0510 14:48:30.416944  5307 net.cpp:1144] Copying source layer relu4_2/sep Type:ReLU #blobs=0
I0510 14:48:30.416956  5307 net.cpp:1144] Copying source layer conv5_1/dw Type:Convolution #blobs=1
I0510 14:48:30.416975  5307 net.cpp:1144] Copying source layer conv5_1/dw/bn Type:BatchNorm #blobs=3
I0510 14:48:30.417001  5307 net.cpp:1144] Copying source layer conv5_1/dw/scale Type:Scale #blobs=2
I0510 14:48:30.417021  5307 net.cpp:1144] Copying source layer relu5_1/dw Type:ReLU #blobs=0
I0510 14:48:30.417034  5307 net.cpp:1144] Copying source layer conv5_1/sep Type:Convolution #blobs=1
I0510 14:48:30.417079  5307 net.cpp:1144] Copying source layer conv5_1/sep/bn Type:BatchNorm #blobs=3
I0510 14:48:30.417106  5307 net.cpp:1144] Copying source layer conv5_1/sep/scale Type:Scale #blobs=2
I0510 14:48:30.417129  5307 net.cpp:1144] Copying source layer relu5_1/sep Type:ReLU #blobs=0
I0510 14:48:30.417141  5307 net.cpp:1144] Copying source layer conv5_2/dw Type:Convolution #blobs=1
I0510 14:48:30.417158  5307 net.cpp:1144] Copying source layer conv5_2/dw/bn Type:BatchNorm #blobs=3
I0510 14:48:30.417186  5307 net.cpp:1144] Copying source layer conv5_2/dw/scale Type:Scale #blobs=2
I0510 14:48:30.417217  5307 net.cpp:1144] Copying source layer relu5_2/dw Type:ReLU #blobs=0
I0510 14:48:30.417229  5307 net.cpp:1144] Copying source layer conv5_2/sep Type:Convolution #blobs=1
I0510 14:48:30.417277  5307 net.cpp:1144] Copying source layer conv5_2/sep/bn Type:BatchNorm #blobs=3
I0510 14:48:30.417304  5307 net.cpp:1144] Copying source layer conv5_2/sep/scale Type:Scale #blobs=2
I0510 14:48:30.417327  5307 net.cpp:1144] Copying source layer relu5_2/sep Type:ReLU #blobs=0
I0510 14:48:30.417340  5307 net.cpp:1144] Copying source layer conv5_3/dw Type:Convolution #blobs=1
I0510 14:48:30.417358  5307 net.cpp:1144] Copying source layer conv5_3/dw/bn Type:BatchNorm #blobs=3
I0510 14:48:30.417383  5307 net.cpp:1144] Copying source layer conv5_3/dw/scale Type:Scale #blobs=2
I0510 14:48:30.417405  5307 net.cpp:1144] Copying source layer relu5_3/dw Type:ReLU #blobs=0
I0510 14:48:30.417418  5307 net.cpp:1144] Copying source layer conv5_3/sep Type:Convolution #blobs=1
I0510 14:48:30.417486  5307 net.cpp:1144] Copying source layer conv5_3/sep/bn Type:BatchNorm #blobs=3
I0510 14:48:30.417515  5307 net.cpp:1144] Copying source layer conv5_3/sep/scale Type:Scale #blobs=2
I0510 14:48:30.417536  5307 net.cpp:1144] Copying source layer relu5_3/sep Type:ReLU #blobs=0
I0510 14:48:30.417549  5307 net.cpp:1144] Copying source layer conv5_4/dw Type:Convolution #blobs=1
I0510 14:48:30.417567  5307 net.cpp:1144] Copying source layer conv5_4/dw/bn Type:BatchNorm #blobs=3
I0510 14:48:30.417593  5307 net.cpp:1144] Copying source layer conv5_4/dw/scale Type:Scale #blobs=2
I0510 14:48:30.417614  5307 net.cpp:1144] Copying source layer relu5_4/dw Type:ReLU #blobs=0
I0510 14:48:30.417626  5307 net.cpp:1144] Copying source layer conv5_4/sep Type:Convolution #blobs=1
I0510 14:48:30.417673  5307 net.cpp:1144] Copying source layer conv5_4/sep/bn Type:BatchNorm #blobs=3
I0510 14:48:30.417699  5307 net.cpp:1144] Copying source layer conv5_4/sep/scale Type:Scale #blobs=2
I0510 14:48:30.417721  5307 net.cpp:1144] Copying source layer relu5_4/sep Type:ReLU #blobs=0
I0510 14:48:30.417733  5307 net.cpp:1144] Copying source layer conv5_5/dw Type:Convolution #blobs=1
I0510 14:48:30.417752  5307 net.cpp:1144] Copying source layer conv5_5/dw/bn Type:BatchNorm #blobs=3
I0510 14:48:30.417776  5307 net.cpp:1144] Copying source layer conv5_5/dw/scale Type:Scale #blobs=2
I0510 14:48:30.417798  5307 net.cpp:1144] Copying source layer relu5_5/dw Type:ReLU #blobs=0
I0510 14:48:30.417810  5307 net.cpp:1144] Copying source layer conv5_5/sep Type:Convolution #blobs=1
I0510 14:48:30.417853  5307 net.cpp:1144] Copying source layer conv5_5/sep/bn Type:BatchNorm #blobs=3
I0510 14:48:30.417879  5307 net.cpp:1144] Copying source layer conv5_5/sep/scale Type:Scale #blobs=2
I0510 14:48:30.417902  5307 net.cpp:1144] Copying source layer relu5_5/sep Type:ReLU #blobs=0
I0510 14:48:30.417915  5307 net.cpp:1144] Copying source layer conv5_6/dw Type:Convolution #blobs=1
I0510 14:48:30.417933  5307 net.cpp:1144] Copying source layer conv5_6/dw/bn Type:BatchNorm #blobs=3
I0510 14:48:30.417958  5307 net.cpp:1144] Copying source layer conv5_6/dw/scale Type:Scale #blobs=2
I0510 14:48:30.417980  5307 net.cpp:1144] Copying source layer relu5_6/dw Type:ReLU #blobs=0
I0510 14:48:30.417992  5307 net.cpp:1144] Copying source layer conv5_6/sep Type:Convolution #blobs=1
I0510 14:48:30.418058  5307 net.cpp:1144] Copying source layer conv5_6/sep/bn Type:BatchNorm #blobs=3
I0510 14:48:30.418087  5307 net.cpp:1144] Copying source layer conv5_6/sep/scale Type:Scale #blobs=2
I0510 14:48:30.418109  5307 net.cpp:1144] Copying source layer relu5_6/sep Type:ReLU #blobs=0
I0510 14:48:30.418121  5307 net.cpp:1144] Copying source layer conv6/dw Type:Convolution #blobs=1
I0510 14:48:30.418140  5307 net.cpp:1144] Copying source layer conv6/dw/bn Type:BatchNorm #blobs=3
I0510 14:48:30.418165  5307 net.cpp:1144] Copying source layer conv6/dw/scale Type:Scale #blobs=2
I0510 14:48:30.418189  5307 net.cpp:1144] Copying source layer relu6/dw Type:ReLU #blobs=0
I0510 14:48:30.418203  5307 net.cpp:1144] Copying source layer conv6/sep Type:Convolution #blobs=1
I0510 14:48:30.418311  5307 net.cpp:1144] Copying source layer conv6/sep/bn Type:BatchNorm #blobs=3
I0510 14:48:30.418339  5307 net.cpp:1144] Copying source layer conv6/sep/scale Type:Scale #blobs=2
I0510 14:48:30.418361  5307 net.cpp:1144] Copying source layer relu6/sep Type:ReLU #blobs=0
I0510 14:48:30.418375  5307 net.cpp:1144] Copying source layer pool6 Type:Pooling #blobs=0
I0510 14:48:30.418385  5307 net.cpp:1136] Ignoring source layer fc7
I0510 14:48:30.418396  5307 net.cpp:1136] Ignoring source layer loss
I0510 14:48:30.420141  5307 net.cpp:1144] Copying source layer data Type:Data #blobs=0
I0510 14:48:30.420172  5307 net.cpp:1144] Copying source layer data/bias Type:Bias #blobs=1
I0510 14:48:30.420200  5307 net.cpp:1144] Copying source layer conv1 Type:Convolution #blobs=1
I0510 14:48:30.420218  5307 net.cpp:1144] Copying source layer conv1/bn Type:BatchNorm #blobs=3
I0510 14:48:30.420244  5307 net.cpp:1144] Copying source layer conv1/scale Type:Scale #blobs=2
I0510 14:48:30.420265  5307 net.cpp:1144] Copying source layer relu1 Type:ReLU #blobs=0
I0510 14:48:30.420277  5307 net.cpp:1144] Copying source layer conv2_1/dw Type:Convolution #blobs=1
I0510 14:48:30.420295  5307 net.cpp:1144] Copying source layer conv2_1/dw/bn Type:BatchNorm #blobs=3
I0510 14:48:30.420320  5307 net.cpp:1144] Copying source layer conv2_1/dw/scale Type:Scale #blobs=2
I0510 14:48:30.420341  5307 net.cpp:1144] Copying source layer relu2_1/dw Type:ReLU #blobs=0
I0510 14:48:30.420352  5307 net.cpp:1144] Copying source layer conv2_1/sep Type:Convolution #blobs=1
I0510 14:48:30.420369  5307 net.cpp:1144] Copying source layer conv2_1/sep/bn Type:BatchNorm #blobs=3
I0510 14:48:30.420398  5307 net.cpp:1144] Copying source layer conv2_1/sep/scale Type:Scale #blobs=2
I0510 14:48:30.420421  5307 net.cpp:1144] Copying source layer relu2_1/sep Type:ReLU #blobs=0
I0510 14:48:30.420433  5307 net.cpp:1144] Copying source layer conv2_2/dw Type:Convolution #blobs=1
I0510 14:48:30.420450  5307 net.cpp:1144] Copying source layer conv2_2/dw/bn Type:BatchNorm #blobs=3
I0510 14:48:30.420476  5307 net.cpp:1144] Copying source layer conv2_2/dw/scale Type:Scale #blobs=2
I0510 14:48:30.420500  5307 net.cpp:1144] Copying source layer relu2_2/dw Type:ReLU #blobs=0
I0510 14:48:30.420512  5307 net.cpp:1144] Copying source layer conv2_2/sep Type:Convolution #blobs=1
I0510 14:48:30.420537  5307 net.cpp:1144] Copying source layer conv2_2/sep/bn Type:BatchNorm #blobs=3
I0510 14:48:30.420565  5307 net.cpp:1144] Copying source layer conv2_2/sep/scale Type:Scale #blobs=2
I0510 14:48:30.420586  5307 net.cpp:1144] Copying source layer relu2_2/sep Type:ReLU #blobs=0
I0510 14:48:30.420598  5307 net.cpp:1144] Copying source layer conv3_1/dw Type:Convolution #blobs=1
I0510 14:48:30.420616  5307 net.cpp:1144] Copying source layer conv3_1/dw/bn Type:BatchNorm #blobs=3
I0510 14:48:30.420640  5307 net.cpp:1144] Copying source layer conv3_1/dw/scale Type:Scale #blobs=2
I0510 14:48:30.420662  5307 net.cpp:1144] Copying source layer relu3_1/dw Type:ReLU #blobs=0
I0510 14:48:30.420675  5307 net.cpp:1144] Copying source layer conv3_1/sep Type:Convolution #blobs=1
I0510 14:48:30.420693  5307 net.cpp:1144] Copying source layer conv3_1/sep/bn Type:BatchNorm #blobs=3
I0510 14:48:30.420718  5307 net.cpp:1144] Copying source layer conv3_1/sep/scale Type:Scale #blobs=2
I0510 14:48:30.420740  5307 net.cpp:1144] Copying source layer relu3_1/sep Type:ReLU #blobs=0
I0510 14:48:30.420753  5307 net.cpp:1144] Copying source layer conv3_2/dw Type:Convolution #blobs=1
I0510 14:48:30.420769  5307 net.cpp:1144] Copying source layer conv3_2/dw/bn Type:BatchNorm #blobs=3
I0510 14:48:30.420794  5307 net.cpp:1144] Copying source layer conv3_2/dw/scale Type:Scale #blobs=2
I0510 14:48:30.420815  5307 net.cpp:1144] Copying source layer relu3_2/dw Type:ReLU #blobs=0
I0510 14:48:30.420827  5307 net.cpp:1144] Copying source layer conv3_2/sep Type:Convolution #blobs=1
I0510 14:48:30.420851  5307 net.cpp:1144] Copying source layer conv3_2/sep/bn Type:BatchNorm #blobs=3
I0510 14:48:30.420883  5307 net.cpp:1144] Copying source layer conv3_2/sep/scale Type:Scale #blobs=2
I0510 14:48:30.420905  5307 net.cpp:1144] Copying source layer relu3_2/sep Type:ReLU #blobs=0
I0510 14:48:30.420918  5307 net.cpp:1144] Copying source layer conv4_1/dw Type:Convolution #blobs=1
I0510 14:48:30.420936  5307 net.cpp:1144] Copying source layer conv4_1/dw/bn Type:BatchNorm #blobs=3
I0510 14:48:30.420960  5307 net.cpp:1144] Copying source layer conv4_1/dw/scale Type:Scale #blobs=2
I0510 14:48:30.420982  5307 net.cpp:1144] Copying source layer relu4_1/dw Type:ReLU #blobs=0
I0510 14:48:30.420994  5307 net.cpp:1144] Copying source layer conv4_1/sep Type:Convolution #blobs=1
I0510 14:48:30.421017  5307 net.cpp:1144] Copying source layer conv4_1/sep/bn Type:BatchNorm #blobs=3
I0510 14:48:30.421042  5307 net.cpp:1144] Copying source layer conv4_1/sep/scale Type:Scale #blobs=2
I0510 14:48:30.421064  5307 net.cpp:1144] Copying source layer relu4_1/sep Type:ReLU #blobs=0
I0510 14:48:30.421077  5307 net.cpp:1144] Copying source layer conv4_2/dw Type:Convolution #blobs=1
I0510 14:48:30.421095  5307 net.cpp:1144] Copying source layer conv4_2/dw/bn Type:BatchNorm #blobs=3
I0510 14:48:30.421119  5307 net.cpp:1144] Copying source layer conv4_2/dw/scale Type:Scale #blobs=2
I0510 14:48:30.421141  5307 net.cpp:1144] Copying source layer relu4_2/dw Type:ReLU #blobs=0
I0510 14:48:30.421154  5307 net.cpp:1144] Copying source layer conv4_2/sep Type:Convolution #blobs=1
I0510 14:48:30.421190  5307 net.cpp:1144] Copying source layer conv4_2/sep/bn Type:BatchNorm #blobs=3
I0510 14:48:30.421217  5307 net.cpp:1144] Copying source layer conv4_2/sep/scale Type:Scale #blobs=2
I0510 14:48:30.421241  5307 net.cpp:1144] Copying source layer relu4_2/sep Type:ReLU #blobs=0
I0510 14:48:30.421254  5307 net.cpp:1144] Copying source layer conv5_1/dw Type:Convolution #blobs=1
I0510 14:48:30.421272  5307 net.cpp:1144] Copying source layer conv5_1/dw/bn Type:BatchNorm #blobs=3
I0510 14:48:30.421298  5307 net.cpp:1144] Copying source layer conv5_1/dw/scale Type:Scale #blobs=2
I0510 14:48:30.421319  5307 net.cpp:1144] Copying source layer relu5_1/dw Type:ReLU #blobs=0
I0510 14:48:30.421331  5307 net.cpp:1144] Copying source layer conv5_1/sep Type:Convolution #blobs=1
I0510 14:48:30.421375  5307 net.cpp:1144] Copying source layer conv5_1/sep/bn Type:BatchNorm #blobs=3
I0510 14:48:30.421401  5307 net.cpp:1144] Copying source layer conv5_1/sep/scale Type:Scale #blobs=2
I0510 14:48:30.421423  5307 net.cpp:1144] Copying source layer relu5_1/sep Type:ReLU #blobs=0
I0510 14:48:30.421435  5307 net.cpp:1144] Copying source layer conv5_2/dw Type:Convolution #blobs=1
I0510 14:48:30.421452  5307 net.cpp:1144] Copying source layer conv5_2/dw/bn Type:BatchNorm #blobs=3
I0510 14:48:30.421476  5307 net.cpp:1144] Copying source layer conv5_2/dw/scale Type:Scale #blobs=2
I0510 14:48:30.421499  5307 net.cpp:1144] Copying source layer relu5_2/dw Type:ReLU #blobs=0
I0510 14:48:30.421510  5307 net.cpp:1144] Copying source layer conv5_2/sep Type:Convolution #blobs=1
I0510 14:48:30.421555  5307 net.cpp:1144] Copying source layer conv5_2/sep/bn Type:BatchNorm #blobs=3
I0510 14:48:30.421581  5307 net.cpp:1144] Copying source layer conv5_2/sep/scale Type:Scale #blobs=2
I0510 14:48:30.421603  5307 net.cpp:1144] Copying source layer relu5_2/sep Type:ReLU #blobs=0
I0510 14:48:30.421615  5307 net.cpp:1144] Copying source layer conv5_3/dw Type:Convolution #blobs=1
I0510 14:48:30.421633  5307 net.cpp:1144] Copying source layer conv5_3/dw/bn Type:BatchNorm #blobs=3
I0510 14:48:30.421658  5307 net.cpp:1144] Copying source layer conv5_3/dw/scale Type:Scale #blobs=2
I0510 14:48:30.421681  5307 net.cpp:1144] Copying source layer relu5_3/dw Type:ReLU #blobs=0
I0510 14:48:30.421694  5307 net.cpp:1144] Copying source layer conv5_3/sep Type:Convolution #blobs=1
I0510 14:48:30.421737  5307 net.cpp:1144] Copying source layer conv5_3/sep/bn Type:BatchNorm #blobs=3
I0510 14:48:30.421762  5307 net.cpp:1144] Copying source layer conv5_3/sep/scale Type:Scale #blobs=2
I0510 14:48:30.421788  5307 net.cpp:1144] Copying source layer relu5_3/sep Type:ReLU #blobs=0
I0510 14:48:30.421805  5307 net.cpp:1144] Copying source layer conv5_4/dw Type:Convolution #blobs=1
I0510 14:48:30.421824  5307 net.cpp:1144] Copying source layer conv5_4/dw/bn Type:BatchNorm #blobs=3
I0510 14:48:30.421849  5307 net.cpp:1144] Copying source layer conv5_4/dw/scale Type:Scale #blobs=2
I0510 14:48:30.421871  5307 net.cpp:1144] Copying source layer relu5_4/dw Type:ReLU #blobs=0
I0510 14:48:30.421883  5307 net.cpp:1144] Copying source layer conv5_4/sep Type:Convolution #blobs=1
I0510 14:48:30.421927  5307 net.cpp:1144] Copying source layer conv5_4/sep/bn Type:BatchNorm #blobs=3
I0510 14:48:30.421955  5307 net.cpp:1144] Copying source layer conv5_4/sep/scale Type:Scale #blobs=2
I0510 14:48:30.421979  5307 net.cpp:1144] Copying source layer relu5_4/sep Type:ReLU #blobs=0
I0510 14:48:30.421993  5307 net.cpp:1144] Copying source layer conv5_5/dw Type:Convolution #blobs=1
I0510 14:48:30.422011  5307 net.cpp:1144] Copying source layer conv5_5/dw/bn Type:BatchNorm #blobs=3
I0510 14:48:30.422036  5307 net.cpp:1144] Copying source layer conv5_5/dw/scale Type:Scale #blobs=2
I0510 14:48:30.422060  5307 net.cpp:1144] Copying source layer relu5_5/dw Type:ReLU #blobs=0
I0510 14:48:30.422073  5307 net.cpp:1144] Copying source layer conv5_5/sep Type:Convolution #blobs=1
I0510 14:48:30.422117  5307 net.cpp:1144] Copying source layer conv5_5/sep/bn Type:BatchNorm #blobs=3
I0510 14:48:30.422147  5307 net.cpp:1144] Copying source layer conv5_5/sep/scale Type:Scale #blobs=2
I0510 14:48:30.422169  5307 net.cpp:1144] Copying source layer relu5_5/sep Type:ReLU #blobs=0
I0510 14:48:30.422183  5307 net.cpp:1144] Copying source layer conv5_6/dw Type:Convolution #blobs=1
I0510 14:48:30.422205  5307 net.cpp:1144] Copying source layer conv5_6/dw/bn Type:BatchNorm #blobs=3
I0510 14:48:30.422232  5307 net.cpp:1144] Copying source layer conv5_6/dw/scale Type:Scale #blobs=2
I0510 14:48:30.422255  5307 net.cpp:1144] Copying source layer relu5_6/dw Type:ReLU #blobs=0
I0510 14:48:30.422268  5307 net.cpp:1144] Copying source layer conv5_6/sep Type:Convolution #blobs=1
I0510 14:48:30.422336  5307 net.cpp:1144] Copying source layer conv5_6/sep/bn Type:BatchNorm #blobs=3
I0510 14:48:30.422365  5307 net.cpp:1144] Copying source layer conv5_6/sep/scale Type:Scale #blobs=2
I0510 14:48:30.422389  5307 net.cpp:1144] Copying source layer relu5_6/sep Type:ReLU #blobs=0
I0510 14:48:30.422402  5307 net.cpp:1144] Copying source layer conv6/dw Type:Convolution #blobs=1
I0510 14:48:30.422422  5307 net.cpp:1144] Copying source layer conv6/dw/bn Type:BatchNorm #blobs=3
I0510 14:48:30.422449  5307 net.cpp:1144] Copying source layer conv6/dw/scale Type:Scale #blobs=2
I0510 14:48:30.422472  5307 net.cpp:1144] Copying source layer relu6/dw Type:ReLU #blobs=0
I0510 14:48:30.422485  5307 net.cpp:1144] Copying source layer conv6/sep Type:Convolution #blobs=1
I0510 14:48:30.422605  5307 net.cpp:1144] Copying source layer conv6/sep/bn Type:BatchNorm #blobs=3
I0510 14:48:30.422636  5307 net.cpp:1144] Copying source layer conv6/sep/scale Type:Scale #blobs=2
I0510 14:48:30.422662  5307 net.cpp:1144] Copying source layer relu6/sep Type:ReLU #blobs=0
I0510 14:48:30.422675  5307 net.cpp:1144] Copying source layer pool6 Type:Pooling #blobs=0
I0510 14:48:30.422689  5307 net.cpp:1136] Ignoring source layer fc7
I0510 14:48:30.422701  5307 net.cpp:1136] Ignoring source layer loss
I0510 14:48:30.422816  5307 caffe.cpp:260] Starting Optimization
I0510 14:48:30.422832  5307 solver.cpp:453] Solving mobiledetnet-0.5
I0510 14:48:30.422842  5307 solver.cpp:454] Learning Rate Policy: multistep
I0510 14:48:30.422900  5307 net.cpp:1443] [0] Reserving 9381120 bytes of shared learnable space for type FLOAT
I0510 14:48:30.428328  5307 solver.cpp:269] Initial Test started...
I0510 14:48:30.428369  5307 solver.cpp:635] Iteration 0, Testing net (#0)
I0510 14:48:30.429464  5355 common.cpp:528] NVML initialized, thread 5355
I0510 14:48:30.433272  5307 net.cpp:1071] Ignoring source layer mbox_loss
I0510 14:48:30.508715  5355 common.cpp:550] NVML succeeded to set CPU affinity on device 0, thread 5355
I0510 14:49:00.809654  5353 data_reader.cpp:320] Restarting data pre-fetching
I0510 14:49:00.990506  5307 solver.cpp:747] class AP 1: 4.20608e-06
I0510 14:49:00.998561  5307 solver.cpp:747] class AP 2: 2.36312e-05
I0510 14:49:01.033555  5307 solver.cpp:747] class AP 3: 3.95601e-05
I0510 14:49:01.033614  5307 solver.cpp:747] class AP 4: 0
W0510 14:49:01.033622  5307 solver.cpp:731] Missing true_pos for label: 5
W0510 14:49:01.033705  5307 solver.cpp:731] Missing true_pos for label: 6
W0510 14:49:01.033710  5307 solver.cpp:731] Missing true_pos for label: 7
W0510 14:49:01.033713  5307 solver.cpp:731] Missing true_pos for label: 8
W0510 14:49:01.033716  5307 solver.cpp:731] Missing true_pos for label: 9
W0510 14:49:01.033718  5307 solver.cpp:731] Missing true_pos for label: 10
W0510 14:49:01.033721  5307 solver.cpp:731] Missing true_pos for label: 11
W0510 14:49:01.033723  5307 solver.cpp:731] Missing true_pos for label: 12
W0510 14:49:01.033726  5307 solver.cpp:731] Missing true_pos for label: 13
W0510 14:49:01.033728  5307 solver.cpp:731] Missing true_pos for label: 14
W0510 14:49:01.033731  5307 solver.cpp:731] Missing true_pos for label: 15
W0510 14:49:01.033735  5307 solver.cpp:731] Missing true_pos for label: 16
W0510 14:49:01.033736  5307 solver.cpp:731] Missing true_pos for label: 17
W0510 14:49:01.033740  5307 solver.cpp:731] Missing true_pos for label: 18
W0510 14:49:01.033741  5307 solver.cpp:731] Missing true_pos for label: 19
W0510 14:49:01.033744  5307 solver.cpp:731] Missing true_pos for label: 20
I0510 14:49:01.033747  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 3.36987e-06
I0510 14:49:01.033784  5307 solver.cpp:274] Initial Test completed in 30.6046s
I0510 14:49:01.729894  5307 solver.cpp:358] Iteration 0 (0.696069 s), loss = 30.2997
I0510 14:49:01.729921  5307 solver.cpp:376]     Train net output #0: mbox_loss = 28.8664 (* 1 = 28.8664 loss)
I0510 14:49:01.729928  5307 sgd_solver.cpp:172] Iteration 0, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 14:49:01.750205  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'conv1' with space 3.29M 3/1 1 1 3 	(avail 1.28G, req 3.29M)	t: 0 0 0.92
I0510 14:49:01.872751  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'conv2_1/dw' with space 3.29M 16/16. 0 1 3 	(avail 1.28G, req 3.29M)	t: 0 2.47 8.62
I0510 14:49:01.937407  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'conv2_1/sep' with space 3.29M 16/1 1 1 3 	(avail 1.28G, req 3.29M)	t: 0 0.33 1.49
I0510 14:49:02.031493  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'conv2_2/dw' with space 3.29M 32/32. 0 0 3 	(avail 1.28G, req 3.29M)	t: 0 3.58 4.43
I0510 14:49:02.084003  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'conv2_2/sep' with space 3.29M 32/1 1 1 3 	(avail 1.28G, req 3.29M)	t: 0 0.31 0.83
I0510 14:49:02.237854  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'conv3_1/dw' with space 3.29M 64/64. 0 1 3 	(avail 1.28G, req 3.29M)	t: 0 2.74 8.84
I0510 14:49:02.313946  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'conv3_1/sep' with space 3.29M 64/1 1 1 3 	(avail 1.28G, req 3.29M)	t: 0 0.29 0.87
I0510 14:49:02.403553  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'conv3_2/dw' with space 3.29M 64/64. 0 0 0 	(avail 1.28G, req 3.29M)	t: 0 1.87 2.19
I0510 14:49:02.433367  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'conv3_2/sep' with space 3.29M 64/1 1 1 3 	(avail 1.28G, req 3.29M)	t: 0 0.13 0.22
I0510 14:49:02.500931  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'conv4_1/dw' with space 3.29M 128/128. 0 1 0 	(avail 1.28G, req 3.29M)	t: 0 1.43 4.07
I0510 14:49:02.541015  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'conv4_1/sep' with space 3.29M 128/1 1 1 3 	(avail 1.28G, req 3.29M)	t: 0 0.17 0.24
I0510 14:49:02.578392  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'conv4_2/dw' with space 3.29M 128/128. 0 1 3 	(avail 1.28G, req 3.29M)	t: 0 1.86 1.51
I0510 14:49:02.594458  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'conv4_2/sep' with space 3.29M 128/1 1 1 3 	(avail 1.28G, req 3.29M)	t: 0 0.1 0.13
I0510 14:49:02.656378  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'conv5_1/dw' with space 3.29M 256/256. 0 1 0 	(avail 1.28G, req 3.29M)	t: 0 1.8 2.88
I0510 14:49:02.687712  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'conv5_1/sep' with space 3.29M 256/1 1 1 1 	(avail 1.28G, req 3.29M)	t: 0 0.15 0.22
I0510 14:49:02.751070  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'conv5_2/dw' with space 3.29M 256/256. 0 1 0 	(avail 1.28G, req 3.29M)	t: 0 1.9 2.91
I0510 14:49:02.783671  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'conv5_2/sep' with space 3.29M 256/1 1 1 3 	(avail 1.28G, req 3.29M)	t: 0 0.22 0.29
I0510 14:49:02.885000  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'conv5_3/dw' with space 3.29M 256/256. 0 1 0 	(avail 1.28G, req 3.29M)	t: 0 1.84 2.91
I0510 14:49:02.918089  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'conv5_3/sep' with space 3.29M 256/1 1 1 1 	(avail 1.28G, req 3.29M)	t: 0 0.21 0.21
I0510 14:49:03.025629  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'conv5_4/dw' with space 3.29M 256/256. 0 1 0 	(avail 1.28G, req 3.29M)	t: 0 1.82 2.9
I0510 14:49:03.055307  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'conv5_4/sep' with space 3.29M 256/1 1 1 1 	(avail 1.28G, req 3.29M)	t: 0 0.18 0.24
I0510 14:49:03.127607  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'conv5_5/dw' with space 3.29M 256/256. 0 1 3 	(avail 1.28G, req 3.29M)	t: 0 2.09 3.49
I0510 14:49:03.155717  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'conv5_5/sep' with space 3.29M 256/1 1 1 1 	(avail 1.28G, req 3.29M)	t: 0 0.15 0.21
I0510 14:49:03.205742  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'conv5_6/dw' with space 3.29M 256/256. 0 0 3 	(avail 1.28G, req 3.29M)	t: 0 4.67 2.27
I0510 14:49:03.221109  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'conv5_6/sep' with space 3.29M 256/1 1 1 1 	(avail 1.28G, req 3.29M)	t: 0 0.11 0.11
I0510 14:49:03.308890  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'conv6/dw' with space 3.29M 512/512. 0 1 0 	(avail 1.28G, req 3.29M)	t: 0 3.54 4.82
I0510 14:49:03.339993  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'conv6/sep' with space 3.29M 512/1 1 1 1 	(avail 1.28G, req 3.29M)	t: 0 0.17 0.18
I0510 14:49:03.385284  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'ctx_output1/1x1' with space 3.29M 256/1 1 1 1 	(avail 1.28G, req 3.29M)	t: 0 0.29 0.31
I0510 14:49:03.546432  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'ctx_output1' with space 3.29M 512/512. 0 1 0 	(avail 1.28G, req 3.29M)	t: 0 3.56 5.95
I0510 14:49:03.576686  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'ctx_output2/1x1' with space 3.29M 512/1 1 1 1 	(avail 1.28G, req 3.29M)	t: 0 0.17 0.17
I0510 14:49:03.656278  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'ctx_output2' with space 3.29M 512/512. 0 1 3 	(avail 1.28G, req 3.29M)	t: 0 3.55 4.45
I0510 14:49:03.679927  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'ctx_output3/1x1' with space 3.29M 512/1 1 1 1 	(avail 1.28G, req 3.29M)	t: 0 0.09 0.11
I0510 14:49:03.779830  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'ctx_output3' with space 3.29M 512/512. 0 1 3 	(avail 1.28G, req 3.29M)	t: 0 3.66 4.51
I0510 14:49:03.805711  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'ctx_output4/1x1' with space 3.29M 512/1 1 0 1 	(avail 1.28G, req 3.29M)	t: 0 0.07 0.06
I0510 14:49:03.892918  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'ctx_output4' with space 3.29M 512/512. 0 1 0 	(avail 1.28G, req 3.29M)	t: 0 3.58 4.73
I0510 14:49:03.916041  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'ctx_output5/1x1' with space 3.29M 512/1 1 0 1 	(avail 1.28G, req 3.29M)	t: 0 0.07 0.06
I0510 14:49:04.017879  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'ctx_output5' with space 3.29M 512/512. 0 1 0 	(avail 1.28G, req 3.29M)	t: 0 3.56 4.66
I0510 14:49:04.029551  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_loc' with space 3.29M 512/1 1 1 3 	(avail 1.28G, req 3.29M)	t: 0 0.08 0.14
I0510 14:49:04.056619  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'ctx_output1/relu_mbox_conf' with space 3.29M 512/1 1 1 0 	(avail 1.28G, req 3.29M)	t: 0 0.14 0.25
I0510 14:49:04.066035  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_loc' with space 3.29M 512/1 1 1 0 	(avail 1.28G, req 3.29M)	t: 0 0.04 0.05
I0510 14:49:04.076759  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'ctx_output2/relu_mbox_conf' with space 3.29M 512/1 1 1 3 	(avail 1.28G, req 3.29M)	t: 0 0.07 0.08
I0510 14:49:04.083274  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_loc' with space 3.29M 512/1 1 1 0 	(avail 1.28G, req 3.29M)	t: 0 0.03 0.03
I0510 14:49:04.094904  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'ctx_output3/relu_mbox_conf' with space 3.29M 512/1 1 1 3 	(avail 1.28G, req 3.29M)	t: 0 0.04 0.05
I0510 14:49:04.101155  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_loc' with space 3.29M 512/1 1 0 0 	(avail 1.28G, req 3.29M)	t: 0 0.03 0.02
I0510 14:49:04.115995  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'ctx_output4/relu_mbox_conf' with space 3.29M 512/1 1 0 3 	(avail 1.28G, req 3.29M)	t: 0 0.04 0.04
I0510 14:49:04.123507  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_loc' with space 3.29M 512/1 0 0 0 	(avail 1.28G, req 3.29M)	t: 0 0.04 0.03
I0510 14:49:04.138696  5307 cudnn_conv_layer.cpp:848] [0] Conv Algos (F,BD,BF): 'ctx_output5/relu_mbox_conf' with space 3.29M 512/1 1 1 3 	(avail 1.28G, req 3.29M)	t: 0 0.05 0.06
I0510 14:49:04.617333  5307 solver.cpp:358] Iteration 1 (2.88736 s), loss = 27.6163
I0510 14:49:04.617358  5307 solver.cpp:376]     Train net output #0: mbox_loss = 25.7089 (* 1 = 25.7089 loss)
I0510 14:49:05.138526  5307 solver.cpp:358] Iteration 2 (0.521175 s), loss = 26.3567
I0510 14:49:05.138555  5307 solver.cpp:376]     Train net output #0: mbox_loss = 24.5248 (* 1 = 24.5248 loss)
I0510 14:49:53.104404  5307 solver.cpp:352] Iteration 100 (2.04317 iter/s, 47.9647s/98 iter), loss = 7.17953
I0510 14:49:53.104457  5307 solver.cpp:376]     Train net output #0: mbox_loss = 7.1951 (* 1 = 7.1951 loss)
I0510 14:49:53.104465  5307 sgd_solver.cpp:172] Iteration 100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 14:50:44.360132  5307 solver.cpp:352] Iteration 200 (1.95105 iter/s, 51.2546s/100 iter), loss = 6.72388
I0510 14:50:44.360198  5307 solver.cpp:376]     Train net output #0: mbox_loss = 6.90003 (* 1 = 6.90003 loss)
I0510 14:50:44.360209  5307 sgd_solver.cpp:172] Iteration 200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 14:51:45.371630  5307 solver.cpp:352] Iteration 300 (1.63907 iter/s, 61.0102s/100 iter), loss = 6.42418
I0510 14:51:45.371706  5307 solver.cpp:376]     Train net output #0: mbox_loss = 6.27518 (* 1 = 6.27518 loss)
I0510 14:51:45.371714  5307 sgd_solver.cpp:172] Iteration 300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 14:52:45.343096  5307 solver.cpp:352] Iteration 400 (1.66749 iter/s, 59.9703s/100 iter), loss = 6.34919
I0510 14:52:45.343987  5307 solver.cpp:376]     Train net output #0: mbox_loss = 7.68054 (* 1 = 7.68054 loss)
I0510 14:52:45.344005  5307 sgd_solver.cpp:172] Iteration 400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 14:53:45.887753  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 14:53:46.284636  5307 solver.cpp:352] Iteration 500 (1.64095 iter/s, 60.9404s/100 iter), 1/231.9ep, loss = 6.23284
I0510 14:53:46.284762  5307 solver.cpp:376]     Train net output #0: mbox_loss = 6.66315 (* 1 = 6.66315 loss)
I0510 14:53:46.284775  5307 sgd_solver.cpp:172] Iteration 500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 14:54:46.641153  5307 solver.cpp:352] Iteration 600 (1.65685 iter/s, 60.3554s/100 iter), 1.2/232ep, loss = 6.05849
I0510 14:54:46.641240  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.92231 (* 1 = 5.92231 loss)
I0510 14:54:46.641304  5307 sgd_solver.cpp:172] Iteration 600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 14:55:47.433953  5307 solver.cpp:352] Iteration 700 (1.64496 iter/s, 60.7917s/100 iter), 1.4/232ep, loss = 6.17512
I0510 14:55:47.434027  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.76096 (* 1 = 5.76096 loss)
I0510 14:55:47.434036  5307 sgd_solver.cpp:172] Iteration 700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 14:56:47.787348  5307 solver.cpp:352] Iteration 800 (1.65694 iter/s, 60.3523s/100 iter), 1.5/232ep, loss = 5.85499
I0510 14:56:47.787832  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.32266 (* 1 = 5.32266 loss)
I0510 14:56:47.787853  5307 sgd_solver.cpp:172] Iteration 800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 14:57:48.278928  5307 solver.cpp:352] Iteration 900 (1.65315 iter/s, 60.4905s/100 iter), 1.7/232ep, loss = 5.92378
I0510 14:57:48.278992  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.94175 (* 1 = 4.94175 loss)
I0510 14:57:48.279001  5307 sgd_solver.cpp:172] Iteration 900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 14:58:48.328603  5307 solver.cpp:352] Iteration 1000 (1.66532 iter/s, 60.0486s/100 iter), 1.9/232ep, loss = 5.526
I0510 14:58:48.328774  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.45025 (* 1 = 5.45025 loss)
I0510 14:58:48.328784  5307 sgd_solver.cpp:172] Iteration 1000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 14:58:58.570034  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 14:59:48.448968  5307 solver.cpp:352] Iteration 1100 (1.66336 iter/s, 60.1193s/100 iter), 2.1/232ep, loss = 5.69474
I0510 14:59:48.449040  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.50119 (* 1 = 5.50119 loss)
I0510 14:59:48.449049  5307 sgd_solver.cpp:172] Iteration 1100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:00:48.629653  5307 solver.cpp:352] Iteration 1200 (1.66169 iter/s, 60.1796s/100 iter), 2.3/232ep, loss = 5.57004
I0510 15:00:48.629717  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.65429 (* 1 = 5.65429 loss)
I0510 15:00:48.629725  5307 sgd_solver.cpp:172] Iteration 1200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:01:49.735715  5307 solver.cpp:352] Iteration 1300 (1.63653 iter/s, 61.1049s/100 iter), 2.5/232ep, loss = 5.30555
I0510 15:01:49.735811  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.14266 (* 1 = 5.14266 loss)
I0510 15:01:49.735837  5307 sgd_solver.cpp:172] Iteration 1300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:02:49.690517  5307 solver.cpp:352] Iteration 1400 (1.66795 iter/s, 59.9537s/100 iter), 2.7/232ep, loss = 5.25238
I0510 15:02:49.690871  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.66859 (* 1 = 4.66859 loss)
I0510 15:02:49.690878  5307 sgd_solver.cpp:172] Iteration 1400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:03:50.002152  5307 solver.cpp:352] Iteration 1500 (1.65809 iter/s, 60.3105s/100 iter), 2.9/232ep, loss = 5.29437
I0510 15:03:50.002264  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.88893 (* 1 = 4.88893 loss)
I0510 15:03:50.002279  5307 sgd_solver.cpp:172] Iteration 1500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:04:09.962220  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 15:04:51.827756  5307 solver.cpp:352] Iteration 1600 (1.61748 iter/s, 61.8245s/100 iter), 3.1/232ep, loss = 5.31895
I0510 15:04:51.827807  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.96819 (* 1 = 4.96819 loss)
I0510 15:04:51.827816  5307 sgd_solver.cpp:172] Iteration 1600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:05:53.059509  5307 solver.cpp:352] Iteration 1700 (1.63317 iter/s, 61.2306s/100 iter), 3.3/232ep, loss = 5.27998
I0510 15:05:53.059577  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.47371 (* 1 = 4.47371 loss)
I0510 15:05:53.059587  5307 sgd_solver.cpp:172] Iteration 1700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:06:53.011014  5307 solver.cpp:352] Iteration 1800 (1.66805 iter/s, 59.9504s/100 iter), 3.5/232ep, loss = 5.39397
I0510 15:06:53.011147  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.32477 (* 1 = 5.32477 loss)
I0510 15:06:53.011168  5307 sgd_solver.cpp:172] Iteration 1800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:07:52.740694  5307 solver.cpp:352] Iteration 1900 (1.67424 iter/s, 59.7286s/100 iter), 3.7/232ep, loss = 5.28387
I0510 15:07:52.741019  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.91122 (* 1 = 4.91122 loss)
I0510 15:07:52.741029  5307 sgd_solver.cpp:172] Iteration 1900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:08:52.557755  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_2000.caffemodel
I0510 15:08:52.587344  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_2000.solverstate
I0510 15:08:52.593171  5307 solver.cpp:635] Iteration 2000, Testing net (#0)
I0510 15:09:36.971422  5353 data_reader.cpp:320] Restarting data pre-fetching
I0510 15:09:37.205752  5307 solver.cpp:747] class AP 1: 0.241176
I0510 15:09:37.205962  5307 solver.cpp:747] class AP 2: 0.276057
I0510 15:09:37.207545  5307 solver.cpp:747] class AP 3: 0.14808
I0510 15:09:37.208468  5307 solver.cpp:747] class AP 4: 0.104791
I0510 15:09:37.210508  5307 solver.cpp:747] class AP 5: 0.00422833
I0510 15:09:37.210934  5307 solver.cpp:747] class AP 6: 0.308869
I0510 15:09:37.216711  5307 solver.cpp:747] class AP 7: 0.388322
I0510 15:09:37.217422  5307 solver.cpp:747] class AP 8: 0.392466
I0510 15:09:37.275566  5307 solver.cpp:747] class AP 9: 0.135234
I0510 15:09:37.276011  5307 solver.cpp:747] class AP 10: 0.146175
I0510 15:09:37.276978  5307 solver.cpp:747] class AP 11: 0.059112
I0510 15:09:37.277819  5307 solver.cpp:747] class AP 12: 0.288268
I0510 15:09:37.278260  5307 solver.cpp:747] class AP 13: 0.337969
I0510 15:09:37.278450  5307 solver.cpp:747] class AP 14: 0.24926
I0510 15:09:37.347717  5307 solver.cpp:747] class AP 15: 0.433317
I0510 15:09:37.347993  5307 solver.cpp:747] class AP 16: 0.0127273
I0510 15:09:37.348687  5307 solver.cpp:747] class AP 17: 0.19425
I0510 15:09:37.349203  5307 solver.cpp:747] class AP 18: 0.166066
I0510 15:09:37.349592  5307 solver.cpp:747] class AP 19: 0.265589
I0510 15:09:37.351342  5307 solver.cpp:747] class AP 20: 0.112928
I0510 15:09:37.351349  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.213244
I0510 15:09:37.351563  5307 solver.cpp:283] Tests completed in 104.609s
I0510 15:09:37.907531  5307 solver.cpp:352] Iteration 2000 (0.955941 iter/s, 104.609s/100 iter), 3.9/232ep, loss = 5.1678
I0510 15:09:37.907558  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.39318 (* 1 = 5.39318 loss)
I0510 15:09:37.907567  5307 sgd_solver.cpp:172] Iteration 2000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:10:08.820240  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 15:10:37.929075  5307 solver.cpp:352] Iteration 2100 (1.6661 iter/s, 60.0204s/100 iter), 4.1/232ep, loss = 5.23718
I0510 15:10:37.929100  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.6325 (* 1 = 4.6325 loss)
I0510 15:10:37.929107  5307 sgd_solver.cpp:172] Iteration 2100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:11:38.703663  5307 solver.cpp:352] Iteration 2200 (1.64545 iter/s, 60.7735s/100 iter), 4.3/232ep, loss = 5.204
I0510 15:11:38.703722  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.60013 (* 1 = 5.60013 loss)
I0510 15:11:38.703730  5307 sgd_solver.cpp:172] Iteration 2200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:12:38.392817  5307 solver.cpp:352] Iteration 2300 (1.67538 iter/s, 59.6881s/100 iter), 4.4/232ep, loss = 5.23689
I0510 15:12:38.392879  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.4605 (* 1 = 5.4605 loss)
I0510 15:12:38.392889  5307 sgd_solver.cpp:172] Iteration 2300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:13:39.239018  5307 solver.cpp:352] Iteration 2400 (1.64352 iter/s, 60.8451s/100 iter), 4.6/232ep, loss = 4.8862
I0510 15:13:39.239135  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.68924 (* 1 = 4.68924 loss)
I0510 15:13:39.239411  5307 sgd_solver.cpp:172] Iteration 2400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:14:40.495874  5307 solver.cpp:352] Iteration 2500 (1.6325 iter/s, 61.2558s/100 iter), 4.8/232ep, loss = 4.9742
I0510 15:14:40.495930  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.79053 (* 1 = 5.79053 loss)
I0510 15:14:40.495941  5307 sgd_solver.cpp:172] Iteration 2500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:15:22.295766  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 15:15:41.688493  5307 solver.cpp:352] Iteration 2600 (1.63421 iter/s, 61.1915s/100 iter), 5/232ep, loss = 5.10483
I0510 15:15:41.688520  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.85971 (* 1 = 4.85971 loss)
I0510 15:15:41.688539  5307 sgd_solver.cpp:172] Iteration 2600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:16:42.982174  5307 solver.cpp:352] Iteration 2700 (1.63152 iter/s, 61.2926s/100 iter), 5.2/232ep, loss = 5.12771
I0510 15:16:42.982233  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.38579 (* 1 = 4.38579 loss)
I0510 15:16:42.982241  5307 sgd_solver.cpp:172] Iteration 2700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:17:43.821645  5307 solver.cpp:352] Iteration 2800 (1.6437 iter/s, 60.8384s/100 iter), 5.4/232ep, loss = 4.86479
I0510 15:17:43.821764  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.85436 (* 1 = 4.85436 loss)
I0510 15:17:43.821818  5307 sgd_solver.cpp:172] Iteration 2800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:18:44.342092  5307 solver.cpp:352] Iteration 2900 (1.65236 iter/s, 60.5194s/100 iter), 5.6/232ep, loss = 4.99139
I0510 15:18:44.342231  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.15122 (* 1 = 5.15122 loss)
I0510 15:18:44.342245  5307 sgd_solver.cpp:172] Iteration 2900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:19:46.351919  5307 solver.cpp:352] Iteration 3000 (1.61268 iter/s, 62.0087s/100 iter), 5.8/232ep, loss = 4.95241
I0510 15:19:46.352030  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.45109 (* 1 = 4.45109 loss)
I0510 15:19:46.352042  5307 sgd_solver.cpp:172] Iteration 3000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:20:38.992974  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 15:20:48.269686  5307 solver.cpp:352] Iteration 3100 (1.61507 iter/s, 61.9167s/100 iter), 6/232ep, loss = 5.13158
I0510 15:20:48.269755  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.02616 (* 1 = 5.02616 loss)
I0510 15:20:48.269775  5307 sgd_solver.cpp:172] Iteration 3100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:21:50.193011  5307 solver.cpp:352] Iteration 3200 (1.61493 iter/s, 61.9222s/100 iter), 6.2/232ep, loss = 4.95878
I0510 15:21:50.193161  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.99084 (* 1 = 4.99084 loss)
I0510 15:21:50.193187  5307 sgd_solver.cpp:172] Iteration 3200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:22:52.971943  5307 solver.cpp:352] Iteration 3300 (1.59292 iter/s, 62.7777s/100 iter), 6.4/232ep, loss = 4.71981
I0510 15:22:52.972044  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.98499 (* 1 = 4.98499 loss)
I0510 15:22:52.972054  5307 sgd_solver.cpp:172] Iteration 3300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:23:54.334111  5307 solver.cpp:352] Iteration 3400 (1.6297 iter/s, 61.3611s/100 iter), 6.6/232ep, loss = 4.78574
I0510 15:23:54.334228  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.49641 (* 1 = 4.49641 loss)
I0510 15:23:54.334244  5307 sgd_solver.cpp:172] Iteration 3400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:24:55.895929  5307 solver.cpp:352] Iteration 3500 (1.62441 iter/s, 61.5607s/100 iter), 6.8/232ep, loss = 4.77709
I0510 15:24:55.897032  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.93638 (* 1 = 4.93638 loss)
I0510 15:24:55.897043  5307 sgd_solver.cpp:172] Iteration 3500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:25:56.356941  5307 solver.cpp:352] Iteration 3600 (1.65399 iter/s, 60.4599s/100 iter), 7/232ep, loss = 4.90801
I0510 15:25:56.358294  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.33671 (* 1 = 4.33671 loss)
I0510 15:25:56.358317  5307 sgd_solver.cpp:172] Iteration 3600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:25:58.086321  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 15:26:57.752619  5307 solver.cpp:352] Iteration 3700 (1.62881 iter/s, 61.3946s/100 iter), 7.2/232ep, loss = 4.89432
I0510 15:26:57.752725  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.51655 (* 1 = 4.51655 loss)
I0510 15:26:57.752748  5307 sgd_solver.cpp:172] Iteration 3700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:27:59.361323  5307 solver.cpp:352] Iteration 3800 (1.62318 iter/s, 61.6076s/100 iter), 7.3/232ep, loss = 4.72437
I0510 15:27:59.364637  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.02982 (* 1 = 4.02982 loss)
I0510 15:27:59.364663  5307 sgd_solver.cpp:172] Iteration 3800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:29:00.746966  5307 solver.cpp:352] Iteration 3900 (1.62908 iter/s, 61.3845s/100 iter), 7.5/232ep, loss = 4.54618
I0510 15:29:00.752626  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.57019 (* 1 = 4.57019 loss)
I0510 15:29:00.752717  5307 sgd_solver.cpp:172] Iteration 3900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:30:01.201730  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_4000.caffemodel
I0510 15:30:01.218586  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_4000.solverstate
I0510 15:30:01.223902  5307 solver.cpp:635] Iteration 4000, Testing net (#0)
I0510 15:30:45.120575  5353 data_reader.cpp:320] Restarting data pre-fetching
I0510 15:30:45.351639  5307 solver.cpp:747] class AP 1: 0.206601
I0510 15:30:45.352443  5307 solver.cpp:747] class AP 2: 0.367045
I0510 15:30:45.355480  5307 solver.cpp:747] class AP 3: 0.230397
I0510 15:30:45.356767  5307 solver.cpp:747] class AP 4: 0.135427
I0510 15:30:45.374042  5307 solver.cpp:747] class AP 5: 0.0700225
I0510 15:30:45.374305  5307 solver.cpp:747] class AP 6: 0.389016
I0510 15:30:45.376086  5307 solver.cpp:747] class AP 7: 0.423877
I0510 15:30:45.376555  5307 solver.cpp:747] class AP 8: 0.466201
I0510 15:30:45.418108  5307 solver.cpp:747] class AP 9: 0.152882
I0510 15:30:45.418695  5307 solver.cpp:747] class AP 10: 0.224414
I0510 15:30:45.420948  5307 solver.cpp:747] class AP 11: 0.260761
I0510 15:30:45.421463  5307 solver.cpp:747] class AP 12: 0.367263
I0510 15:30:45.421973  5307 solver.cpp:747] class AP 13: 0.403105
I0510 15:30:45.422230  5307 solver.cpp:747] class AP 14: 0.355312
I0510 15:30:45.484895  5307 solver.cpp:747] class AP 15: 0.501333
I0510 15:30:45.488716  5307 solver.cpp:747] class AP 16: 0.0390343
I0510 15:30:45.490855  5307 solver.cpp:747] class AP 17: 0.256806
I0510 15:30:45.492317  5307 solver.cpp:747] class AP 18: 0.220857
I0510 15:30:45.492729  5307 solver.cpp:747] class AP 19: 0.323311
I0510 15:30:45.493448  5307 solver.cpp:747] class AP 20: 0.171304
I0510 15:30:45.493455  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.278248
I0510 15:30:45.493628  5307 solver.cpp:283] Tests completed in 104.745s
I0510 15:30:46.064640  5307 solver.cpp:352] Iteration 4000 (0.954702 iter/s, 104.745s/100 iter), 7.7/232ep, loss = 4.75776
I0510 15:30:46.064726  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.69811 (* 1 = 4.69811 loss)
I0510 15:30:46.064749  5307 sgd_solver.cpp:172] Iteration 4000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:31:46.889731  5307 solver.cpp:352] Iteration 4100 (1.64409 iter/s, 60.824s/100 iter), 7.9/232ep, loss = 4.62315
I0510 15:31:46.889819  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.65004 (* 1 = 3.65004 loss)
I0510 15:31:46.889827  5307 sgd_solver.cpp:172] Iteration 4100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:31:58.322438  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 15:32:47.780087  5307 solver.cpp:352] Iteration 4200 (1.64233 iter/s, 60.8892s/100 iter), 8.1/232ep, loss = 4.93722
I0510 15:32:47.780309  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.30114 (* 1 = 4.30114 loss)
I0510 15:32:47.780371  5307 sgd_solver.cpp:172] Iteration 4200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:33:48.548478  5307 solver.cpp:352] Iteration 4300 (1.64562 iter/s, 60.7673s/100 iter), 8.3/232ep, loss = 4.73264
I0510 15:33:48.548557  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.864 (* 1 = 4.864 loss)
I0510 15:33:48.548565  5307 sgd_solver.cpp:172] Iteration 4300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:34:49.456447  5307 solver.cpp:352] Iteration 4400 (1.64185 iter/s, 60.9069s/100 iter), 8.5/232ep, loss = 4.58244
I0510 15:34:49.456498  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.41459 (* 1 = 4.41459 loss)
I0510 15:34:49.456506  5307 sgd_solver.cpp:172] Iteration 4400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:35:49.381788  5307 solver.cpp:352] Iteration 4500 (1.66877 iter/s, 59.9243s/100 iter), 8.7/232ep, loss = 4.66685
I0510 15:35:49.381906  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.01909 (* 1 = 4.01909 loss)
I0510 15:35:49.381916  5307 sgd_solver.cpp:172] Iteration 4500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:36:50.129918  5307 solver.cpp:352] Iteration 4600 (1.64617 iter/s, 60.747s/100 iter), 8.9/232ep, loss = 4.64371
I0510 15:36:50.131379  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.87533 (* 1 = 4.87533 loss)
I0510 15:36:50.131404  5307 sgd_solver.cpp:172] Iteration 4600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:37:12.411576  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 15:37:49.867966  5307 solver.cpp:352] Iteration 4700 (1.674 iter/s, 59.737s/100 iter), 9.1/232ep, loss = 4.62321
I0510 15:37:49.868119  5307 solver.cpp:376]     Train net output #0: mbox_loss = 6.32694 (* 1 = 6.32694 loss)
I0510 15:37:49.868136  5307 sgd_solver.cpp:172] Iteration 4700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:38:50.386214  5307 solver.cpp:352] Iteration 4800 (1.65242 iter/s, 60.5172s/100 iter), 9.3/232ep, loss = 4.515
I0510 15:38:50.386273  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.09599 (* 1 = 4.09599 loss)
I0510 15:38:50.386282  5307 sgd_solver.cpp:172] Iteration 4800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:39:51.384122  5307 solver.cpp:352] Iteration 4900 (1.63943 iter/s, 60.9968s/100 iter), 9.5/232ep, loss = 4.58634
I0510 15:39:51.384201  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.49087 (* 1 = 4.49087 loss)
I0510 15:39:51.384210  5307 sgd_solver.cpp:172] Iteration 4900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:40:51.456099  5307 solver.cpp:352] Iteration 5000 (1.6647 iter/s, 60.0709s/100 iter), 9.7/232ep, loss = 4.79531
I0510 15:40:51.461995  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.5938 (* 1 = 4.5938 loss)
I0510 15:40:51.462021  5307 sgd_solver.cpp:172] Iteration 5000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:41:52.329574  5307 solver.cpp:352] Iteration 5100 (1.64278 iter/s, 60.8724s/100 iter), 9.9/232ep, loss = 4.69331
I0510 15:41:52.329661  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.59687 (* 1 = 4.59687 loss)
I0510 15:41:52.329679  5307 sgd_solver.cpp:172] Iteration 5100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:42:25.642316  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 15:42:52.869071  5307 solver.cpp:352] Iteration 5200 (1.65184 iter/s, 60.5384s/100 iter), 10.1/232ep, loss = 4.61058
I0510 15:42:52.869096  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.73034 (* 1 = 3.73034 loss)
I0510 15:42:52.869102  5307 sgd_solver.cpp:172] Iteration 5200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:43:53.011672  5307 solver.cpp:352] Iteration 5300 (1.66274 iter/s, 60.1415s/100 iter), 10.2/232ep, loss = 4.53749
I0510 15:43:53.016227  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.06435 (* 1 = 4.06435 loss)
I0510 15:43:53.016248  5307 sgd_solver.cpp:172] Iteration 5300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:44:52.968842  5307 solver.cpp:352] Iteration 5400 (1.66789 iter/s, 59.9561s/100 iter), 10.4/232ep, loss = 4.64367
I0510 15:44:52.969082  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.59465 (* 1 = 4.59465 loss)
I0510 15:44:52.969095  5307 sgd_solver.cpp:172] Iteration 5400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:45:53.614475  5307 solver.cpp:352] Iteration 5500 (1.64895 iter/s, 60.6446s/100 iter), 10.6/232ep, loss = 4.76142
I0510 15:45:53.614565  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.71894 (* 1 = 4.71894 loss)
I0510 15:45:53.614584  5307 sgd_solver.cpp:172] Iteration 5500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:46:54.232838  5307 solver.cpp:352] Iteration 5600 (1.6497 iter/s, 60.6173s/100 iter), 10.8/232ep, loss = 4.59661
I0510 15:46:54.232895  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.42444 (* 1 = 3.42444 loss)
I0510 15:46:54.232906  5307 sgd_solver.cpp:172] Iteration 5600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:47:37.166826  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 15:47:54.647212  5307 solver.cpp:352] Iteration 5700 (1.65527 iter/s, 60.4133s/100 iter), 11/232ep, loss = 4.50432
I0510 15:47:54.647388  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.91722 (* 1 = 3.91722 loss)
I0510 15:47:54.647413  5307 sgd_solver.cpp:172] Iteration 5700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:48:54.521733  5307 solver.cpp:352] Iteration 5800 (1.67019 iter/s, 59.8734s/100 iter), 11.2/232ep, loss = 4.55135
I0510 15:48:54.521875  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.27885 (* 1 = 5.27885 loss)
I0510 15:48:54.521898  5307 sgd_solver.cpp:172] Iteration 5800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:49:54.036702  5307 solver.cpp:352] Iteration 5900 (1.68028 iter/s, 59.5139s/100 iter), 11.4/232ep, loss = 4.54151
I0510 15:49:54.036756  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.00221 (* 1 = 4.00221 loss)
I0510 15:49:54.036764  5307 sgd_solver.cpp:172] Iteration 5900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:50:53.529439  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_6000.caffemodel
I0510 15:50:53.545519  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_6000.solverstate
I0510 15:50:53.550115  5307 solver.cpp:635] Iteration 6000, Testing net (#0)
I0510 15:51:35.765430  5353 data_reader.cpp:320] Restarting data pre-fetching
I0510 15:51:36.005661  5307 solver.cpp:747] class AP 1: 0.343603
I0510 15:51:36.005951  5307 solver.cpp:747] class AP 2: 0.339176
I0510 15:51:36.008163  5307 solver.cpp:747] class AP 3: 0.200234
I0510 15:51:36.009189  5307 solver.cpp:747] class AP 4: 0.132322
I0510 15:51:36.045416  5307 solver.cpp:747] class AP 5: 0.143882
I0510 15:51:36.045706  5307 solver.cpp:747] class AP 6: 0.421355
I0510 15:51:36.047044  5307 solver.cpp:747] class AP 7: 0.482913
I0510 15:51:36.047725  5307 solver.cpp:747] class AP 8: 0.503616
I0510 15:51:36.076642  5307 solver.cpp:747] class AP 9: 0.170713
I0510 15:51:36.076894  5307 solver.cpp:747] class AP 10: 0.266493
I0510 15:51:36.078565  5307 solver.cpp:747] class AP 11: 0.231238
I0510 15:51:36.080288  5307 solver.cpp:747] class AP 12: 0.375903
I0510 15:51:36.080466  5307 solver.cpp:747] class AP 13: 0.504411
I0510 15:51:36.080862  5307 solver.cpp:747] class AP 14: 0.371008
I0510 15:51:36.137048  5307 solver.cpp:747] class AP 15: 0.498699
I0510 15:51:36.140677  5307 solver.cpp:747] class AP 16: 0.0532492
I0510 15:51:36.142189  5307 solver.cpp:747] class AP 17: 0.250349
I0510 15:51:36.143249  5307 solver.cpp:747] class AP 18: 0.233757
I0510 15:51:36.143421  5307 solver.cpp:747] class AP 19: 0.337436
I0510 15:51:36.144233  5307 solver.cpp:747] class AP 20: 0.298036
I0510 15:51:36.144239  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.30792
I0510 15:51:36.144384  5307 solver.cpp:283] Tests completed in 102.106s
I0510 15:51:36.718585  5307 solver.cpp:352] Iteration 6000 (0.979376 iter/s, 102.106s/100 iter), 11.6/232ep, loss = 4.49617
I0510 15:51:36.718739  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.89786 (* 1 = 3.89786 loss)
I0510 15:51:36.718768  5307 sgd_solver.cpp:172] Iteration 6000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:52:36.928555  5307 solver.cpp:352] Iteration 6100 (1.66089 iter/s, 60.2088s/100 iter), 11.8/232ep, loss = 4.57125
I0510 15:52:36.928704  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.78149 (* 1 = 3.78149 loss)
I0510 15:52:36.928714  5307 sgd_solver.cpp:172] Iteration 6100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:53:30.810858  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 15:53:37.308396  5307 solver.cpp:352] Iteration 6200 (1.65621 iter/s, 60.3787s/100 iter), 12/232ep, loss = 4.49143
I0510 15:53:37.308425  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.49279 (* 1 = 4.49279 loss)
I0510 15:53:37.308434  5307 sgd_solver.cpp:172] Iteration 6200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:54:37.473292  5307 solver.cpp:352] Iteration 6300 (1.66213 iter/s, 60.1638s/100 iter), 12.2/232ep, loss = 4.48289
I0510 15:54:37.473388  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.74283 (* 1 = 4.74283 loss)
I0510 15:54:37.473410  5307 sgd_solver.cpp:172] Iteration 6300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:55:37.702651  5307 solver.cpp:352] Iteration 6400 (1.66035 iter/s, 60.2283s/100 iter), 12.4/232ep, loss = 4.56006
I0510 15:55:37.702899  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.82329 (* 1 = 4.82329 loss)
I0510 15:55:37.702926  5307 sgd_solver.cpp:172] Iteration 6400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:56:37.662981  5307 solver.cpp:352] Iteration 6500 (1.6678 iter/s, 59.9593s/100 iter), 12.6/232ep, loss = 4.48101
I0510 15:56:37.663030  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.19505 (* 1 = 4.19505 loss)
I0510 15:56:37.663039  5307 sgd_solver.cpp:172] Iteration 6500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:57:36.854810  5307 solver.cpp:352] Iteration 6600 (1.68945 iter/s, 59.1908s/100 iter), 12.8/232ep, loss = 4.38066
I0510 15:57:36.855403  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.18159 (* 1 = 4.18159 loss)
I0510 15:57:36.855425  5307 sgd_solver.cpp:172] Iteration 6600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:58:44.572839  5307 solver.cpp:352] Iteration 6700 (1.47674 iter/s, 67.7168s/100 iter), 13/232ep, loss = 4.418
I0510 15:58:44.572919  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.71588 (* 1 = 4.71588 loss)
I0510 15:58:44.572929  5307 sgd_solver.cpp:172] Iteration 6700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 15:58:48.144181  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 15:59:47.231030  5307 solver.cpp:352] Iteration 6800 (1.59599 iter/s, 62.6571s/100 iter), 13.1/232ep, loss = 4.3694
I0510 15:59:47.231144  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.31186 (* 1 = 4.31186 loss)
I0510 15:59:47.231168  5307 sgd_solver.cpp:172] Iteration 6800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:00:47.528723  5307 solver.cpp:352] Iteration 6900 (1.65847 iter/s, 60.2966s/100 iter), 13.3/232ep, loss = 4.40375
I0510 16:00:47.529601  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.53692 (* 1 = 5.53692 loss)
I0510 16:00:47.529611  5307 sgd_solver.cpp:172] Iteration 6900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:01:47.887481  5307 solver.cpp:352] Iteration 7000 (1.65679 iter/s, 60.3577s/100 iter), 13.5/232ep, loss = 4.29458
I0510 16:01:47.887647  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.5077 (* 1 = 4.5077 loss)
I0510 16:01:47.887661  5307 sgd_solver.cpp:172] Iteration 7000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:02:48.194983  5307 solver.cpp:352] Iteration 7100 (1.6582 iter/s, 60.3065s/100 iter), 13.7/232ep, loss = 4.34698
I0510 16:02:48.195036  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.99513 (* 1 = 3.99513 loss)
I0510 16:02:48.195044  5307 sgd_solver.cpp:172] Iteration 7100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:03:47.820672  5307 solver.cpp:352] Iteration 7200 (1.67716 iter/s, 59.6247s/100 iter), 13.9/232ep, loss = 4.21892
I0510 16:03:47.820744  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.91532 (* 1 = 3.91532 loss)
I0510 16:03:47.820753  5307 sgd_solver.cpp:172] Iteration 7200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:04:01.660982  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 16:04:48.659145  5307 solver.cpp:352] Iteration 7300 (1.64373 iter/s, 60.8374s/100 iter), 14.1/232ep, loss = 4.43065
I0510 16:04:48.659251  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.29698 (* 1 = 4.29698 loss)
I0510 16:04:48.659278  5307 sgd_solver.cpp:172] Iteration 7300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:05:48.998246  5307 solver.cpp:352] Iteration 7400 (1.65733 iter/s, 60.338s/100 iter), 14.3/232ep, loss = 4.41088
I0510 16:05:48.998353  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.48164 (* 1 = 3.48164 loss)
I0510 16:05:48.998364  5307 sgd_solver.cpp:172] Iteration 7400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:06:49.963078  5307 solver.cpp:352] Iteration 7500 (1.64032 iter/s, 60.9638s/100 iter), 14.5/232ep, loss = 4.42881
I0510 16:06:49.963234  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.26356 (* 1 = 4.26356 loss)
I0510 16:06:49.963246  5307 sgd_solver.cpp:172] Iteration 7500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:07:51.170918  5307 solver.cpp:352] Iteration 7600 (1.63381 iter/s, 61.2068s/100 iter), 14.7/232ep, loss = 4.38766
I0510 16:07:51.171381  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.86193 (* 1 = 4.86193 loss)
I0510 16:07:51.171404  5307 sgd_solver.cpp:172] Iteration 7600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:08:52.659510  5307 solver.cpp:352] Iteration 7700 (1.62635 iter/s, 61.4875s/100 iter), 14.9/232ep, loss = 4.28137
I0510 16:08:52.659694  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.95457 (* 1 = 3.95457 loss)
I0510 16:08:52.659721  5307 sgd_solver.cpp:172] Iteration 7700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:09:17.163449  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 16:09:53.273126  5307 solver.cpp:352] Iteration 7800 (1.64982 iter/s, 60.6125s/100 iter), 15.1/232ep, loss = 4.28748
I0510 16:09:53.273193  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.74378 (* 1 = 4.74378 loss)
I0510 16:09:53.273202  5307 sgd_solver.cpp:172] Iteration 7800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:10:53.718170  5307 solver.cpp:352] Iteration 7900 (1.65443 iter/s, 60.444s/100 iter), 15.3/232ep, loss = 4.48724
I0510 16:10:53.718232  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.72057 (* 1 = 4.72057 loss)
I0510 16:10:53.718240  5307 sgd_solver.cpp:172] Iteration 7900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:11:53.707036  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_8000.caffemodel
I0510 16:11:53.729109  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_8000.solverstate
I0510 16:11:53.735050  5307 solver.cpp:635] Iteration 8000, Testing net (#0)
I0510 16:12:35.622887  5353 data_reader.cpp:320] Restarting data pre-fetching
I0510 16:12:35.819828  5307 solver.cpp:747] class AP 1: 0.187161
I0510 16:12:35.819895  5307 solver.cpp:747] class AP 2: 0.132867
I0510 16:12:35.820551  5307 solver.cpp:747] class AP 3: 0.093213
I0510 16:12:35.822451  5307 solver.cpp:747] class AP 4: 0.134172
I0510 16:12:35.833393  5307 solver.cpp:747] class AP 5: 0.116078
I0510 16:12:35.833920  5307 solver.cpp:747] class AP 6: 0.18732
I0510 16:12:35.843909  5307 solver.cpp:747] class AP 7: 0.326991
I0510 16:12:35.844079  5307 solver.cpp:747] class AP 8: 0.380603
I0510 16:12:35.871490  5307 solver.cpp:747] class AP 9: 0.0880095
I0510 16:12:35.871589  5307 solver.cpp:747] class AP 10: 0.23624
I0510 16:12:35.871991  5307 solver.cpp:747] class AP 11: 0.147733
I0510 16:12:35.872153  5307 solver.cpp:747] class AP 12: 0.253221
I0510 16:12:35.872205  5307 solver.cpp:747] class AP 13: 0.174242
I0510 16:12:35.872351  5307 solver.cpp:747] class AP 14: 0.146544
I0510 16:12:36.012958  5307 solver.cpp:747] class AP 15: 0.278914
I0510 16:12:36.013765  5307 solver.cpp:747] class AP 16: 0.0510046
I0510 16:12:36.014111  5307 solver.cpp:747] class AP 17: 0.115495
I0510 16:12:36.015322  5307 solver.cpp:747] class AP 18: 0.170786
I0510 16:12:36.015656  5307 solver.cpp:747] class AP 19: 0.274256
I0510 16:12:36.022532  5307 solver.cpp:747] class AP 20: 0.157187
I0510 16:12:36.022603  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.182602
I0510 16:12:36.023149  5307 solver.cpp:283] Tests completed in 102.303s
I0510 16:12:36.587702  5307 solver.cpp:352] Iteration 8000 (0.977487 iter/s, 102.303s/100 iter), 15.5/232ep, loss = 4.39346
I0510 16:12:36.587725  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.59318 (* 1 = 5.59318 loss)
I0510 16:12:36.587734  5307 sgd_solver.cpp:172] Iteration 8000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:13:36.125911  5307 solver.cpp:352] Iteration 8100 (1.67963 iter/s, 59.5371s/100 iter), 15.7/232ep, loss = 4.40548
I0510 16:13:36.126049  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.30731 (* 1 = 4.30731 loss)
I0510 16:13:36.126067  5307 sgd_solver.cpp:172] Iteration 8100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:14:37.028736  5307 solver.cpp:352] Iteration 8200 (1.64199 iter/s, 60.9017s/100 iter), 15.9/232ep, loss = 4.36387
I0510 16:14:37.028792  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.04558 (* 1 = 4.04558 loss)
I0510 16:14:37.028800  5307 sgd_solver.cpp:172] Iteration 8200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:15:11.105940  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 16:15:37.020285  5307 solver.cpp:352] Iteration 8300 (1.66693 iter/s, 59.9904s/100 iter), 16/232ep, loss = 4.31154
I0510 16:15:37.020372  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.1889 (* 1 = 5.1889 loss)
I0510 16:15:37.020390  5307 sgd_solver.cpp:172] Iteration 8300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:16:37.154593  5307 solver.cpp:352] Iteration 8400 (1.66297 iter/s, 60.1332s/100 iter), 16.2/232ep, loss = 4.4104
I0510 16:16:37.154779  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.68552 (* 1 = 4.68552 loss)
I0510 16:16:37.154812  5307 sgd_solver.cpp:172] Iteration 8400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:17:38.530937  5307 solver.cpp:352] Iteration 8500 (1.62932 iter/s, 61.3753s/100 iter), 16.4/232ep, loss = 4.27246
I0510 16:17:38.531033  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.4225 (* 1 = 3.4225 loss)
I0510 16:17:38.531054  5307 sgd_solver.cpp:172] Iteration 8500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:18:39.009922  5307 solver.cpp:352] Iteration 8600 (1.6535 iter/s, 60.4779s/100 iter), 16.6/232ep, loss = 4.39125
I0510 16:18:39.010030  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.33212 (* 1 = 4.33212 loss)
I0510 16:18:39.010053  5307 sgd_solver.cpp:172] Iteration 8600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:19:40.334738  5307 solver.cpp:352] Iteration 8700 (1.63069 iter/s, 61.3237s/100 iter), 16.8/232ep, loss = 4.33689
I0510 16:19:40.335502  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.9013 (* 1 = 4.9013 loss)
I0510 16:19:40.335515  5307 sgd_solver.cpp:172] Iteration 8700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:20:26.046443  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 16:20:41.286645  5307 solver.cpp:352] Iteration 8800 (1.64067 iter/s, 60.9509s/100 iter), 17/232ep, loss = 4.26008
I0510 16:20:41.286676  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.38479 (* 1 = 5.38479 loss)
I0510 16:20:41.286685  5307 sgd_solver.cpp:172] Iteration 8800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:21:41.783578  5307 solver.cpp:352] Iteration 8900 (1.65301 iter/s, 60.4959s/100 iter), 17.2/232ep, loss = 4.10042
I0510 16:21:41.783674  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.54616 (* 1 = 3.54616 loss)
I0510 16:21:41.783684  5307 sgd_solver.cpp:172] Iteration 8900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:22:43.384639  5307 solver.cpp:352] Iteration 9000 (1.62338 iter/s, 61.6s/100 iter), 17.4/232ep, loss = 4.29836
I0510 16:22:43.384814  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.46384 (* 1 = 4.46384 loss)
I0510 16:22:43.384824  5307 sgd_solver.cpp:172] Iteration 9000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:23:44.433280  5307 solver.cpp:352] Iteration 9100 (1.63807 iter/s, 61.0476s/100 iter), 17.6/232ep, loss = 4.13168
I0510 16:23:44.433372  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.40502 (* 1 = 4.40502 loss)
I0510 16:23:44.433382  5307 sgd_solver.cpp:172] Iteration 9100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:24:46.060052  5307 solver.cpp:352] Iteration 9200 (1.6227 iter/s, 61.6257s/100 iter), 17.8/232ep, loss = 4.21399
I0510 16:24:46.060153  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.21245 (* 1 = 4.21245 loss)
I0510 16:24:46.060163  5307 sgd_solver.cpp:172] Iteration 9200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:25:42.008615  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 16:25:47.175756  5307 solver.cpp:352] Iteration 9300 (1.63627 iter/s, 61.1146s/100 iter), 18/232ep, loss = 4.42703
I0510 16:25:47.175787  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.93399 (* 1 = 3.93399 loss)
I0510 16:25:47.175796  5307 sgd_solver.cpp:172] Iteration 9300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:26:48.714920  5307 solver.cpp:352] Iteration 9400 (1.62501 iter/s, 61.5381s/100 iter), 18.2/232ep, loss = 4.3202
I0510 16:26:48.715634  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.67566 (* 1 = 4.67566 loss)
I0510 16:26:48.715649  5307 sgd_solver.cpp:172] Iteration 9400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:27:49.669996  5307 solver.cpp:352] Iteration 9500 (1.64058 iter/s, 60.954s/100 iter), 18.4/232ep, loss = 4.3158
I0510 16:27:49.670137  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.50218 (* 1 = 4.50218 loss)
I0510 16:27:49.670156  5307 sgd_solver.cpp:172] Iteration 9500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:28:50.534543  5307 solver.cpp:352] Iteration 9600 (1.64302 iter/s, 60.8635s/100 iter), 18.6/232ep, loss = 4.31481
I0510 16:28:50.534724  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.78233 (* 1 = 4.78233 loss)
I0510 16:28:50.534744  5307 sgd_solver.cpp:172] Iteration 9600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:29:52.043104  5307 solver.cpp:352] Iteration 9700 (1.62582 iter/s, 61.5075s/100 iter), 18.8/232ep, loss = 4.26232
I0510 16:29:52.044564  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.77904 (* 1 = 3.77904 loss)
I0510 16:29:52.044596  5307 sgd_solver.cpp:172] Iteration 9700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:30:52.859931  5307 solver.cpp:352] Iteration 9800 (1.64431 iter/s, 60.8158s/100 iter), 18.9/232ep, loss = 4.17125
I0510 16:30:52.860009  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.84245 (* 1 = 3.84245 loss)
I0510 16:30:52.860018  5307 sgd_solver.cpp:172] Iteration 9800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:30:58.494596  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 16:31:53.523766  5307 solver.cpp:352] Iteration 9900 (1.64846 iter/s, 60.6627s/100 iter), 19.1/232ep, loss = 4.19495
I0510 16:31:53.523844  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.45795 (* 1 = 4.45795 loss)
I0510 16:31:53.523854  5307 sgd_solver.cpp:172] Iteration 9900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:32:53.689491  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_10000.caffemodel
I0510 16:32:53.705381  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_10000.solverstate
I0510 16:32:53.710855  5307 solver.cpp:635] Iteration 10000, Testing net (#0)
I0510 16:33:35.652021  5353 data_reader.cpp:320] Restarting data pre-fetching
I0510 16:33:35.887356  5307 solver.cpp:747] class AP 1: 0.378373
I0510 16:33:35.887681  5307 solver.cpp:747] class AP 2: 0.446617
I0510 16:33:35.890889  5307 solver.cpp:747] class AP 3: 0.323297
I0510 16:33:35.893777  5307 solver.cpp:747] class AP 4: 0.22195
I0510 16:33:35.909973  5307 solver.cpp:747] class AP 5: 0.127367
I0510 16:33:35.910291  5307 solver.cpp:747] class AP 6: 0.42865
I0510 16:33:35.913208  5307 solver.cpp:747] class AP 7: 0.439762
I0510 16:33:35.913678  5307 solver.cpp:747] class AP 8: 0.564868
I0510 16:33:35.935222  5307 solver.cpp:747] class AP 9: 0.217799
I0510 16:33:35.935350  5307 solver.cpp:747] class AP 10: 0.278676
I0510 16:33:35.936563  5307 solver.cpp:747] class AP 11: 0.347657
I0510 16:33:35.937006  5307 solver.cpp:747] class AP 12: 0.462001
I0510 16:33:35.937166  5307 solver.cpp:747] class AP 13: 0.457945
I0510 16:33:35.937306  5307 solver.cpp:747] class AP 14: 0.48744
I0510 16:33:36.011561  5307 solver.cpp:747] class AP 15: 0.539054
I0510 16:33:36.020725  5307 solver.cpp:747] class AP 16: 0.150607
I0510 16:33:36.021001  5307 solver.cpp:747] class AP 17: 0.341589
I0510 16:33:36.021291  5307 solver.cpp:747] class AP 18: 0.307463
I0510 16:33:36.021807  5307 solver.cpp:747] class AP 19: 0.426576
I0510 16:33:36.023761  5307 solver.cpp:747] class AP 20: 0.277367
I0510 16:33:36.023767  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.361253
I0510 16:33:36.023957  5307 solver.cpp:283] Tests completed in 102.498s
I0510 16:33:36.602188  5307 solver.cpp:352] Iteration 10000 (0.975625 iter/s, 102.498s/100 iter), 19.3/232ep, loss = 4.38477
I0510 16:33:36.602257  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.72253 (* 1 = 4.72253 loss)
I0510 16:33:36.602274  5307 sgd_solver.cpp:172] Iteration 10000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:34:38.145097  5307 solver.cpp:352] Iteration 10100 (1.62491 iter/s, 61.5418s/100 iter), 19.5/232ep, loss = 4.14872
I0510 16:34:38.145155  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.9657 (* 1 = 3.9657 loss)
I0510 16:34:38.145354  5307 sgd_solver.cpp:172] Iteration 10100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:35:39.481259  5307 solver.cpp:352] Iteration 10200 (1.63039 iter/s, 61.335s/100 iter), 19.7/232ep, loss = 4.3917
I0510 16:35:39.481500  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.11003 (* 1 = 4.11003 loss)
I0510 16:35:39.481559  5307 sgd_solver.cpp:172] Iteration 10200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:36:40.322700  5307 solver.cpp:352] Iteration 10300 (1.64365 iter/s, 60.8404s/100 iter), 19.9/232ep, loss = 4.11278
I0510 16:36:40.322809  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.95169 (* 1 = 3.95169 loss)
I0510 16:36:40.322818  5307 sgd_solver.cpp:172] Iteration 10300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:36:56.879952  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 16:37:41.590212  5307 solver.cpp:352] Iteration 10400 (1.63222 iter/s, 61.2664s/100 iter), 20.1/232ep, loss = 4.2348
I0510 16:37:41.590725  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.0292 (* 1 = 4.0292 loss)
I0510 16:37:41.590734  5307 sgd_solver.cpp:172] Iteration 10400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:38:42.635974  5307 solver.cpp:352] Iteration 10500 (1.63814 iter/s, 61.0447s/100 iter), 20.3/232ep, loss = 4.43859
I0510 16:38:42.636080  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.53269 (* 1 = 4.53269 loss)
I0510 16:38:42.636142  5307 sgd_solver.cpp:172] Iteration 10500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:39:43.396457  5307 solver.cpp:352] Iteration 10600 (1.64584 iter/s, 60.7594s/100 iter), 20.5/232ep, loss = 4.08796
I0510 16:39:43.396561  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.48421 (* 1 = 4.48421 loss)
I0510 16:39:43.396579  5307 sgd_solver.cpp:172] Iteration 10600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:40:44.580492  5307 solver.cpp:352] Iteration 10700 (1.63444 iter/s, 61.183s/100 iter), 20.7/232ep, loss = 4.25233
I0510 16:40:44.582834  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.41945 (* 1 = 3.41945 loss)
I0510 16:40:44.582845  5307 sgd_solver.cpp:172] Iteration 10700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:41:46.095185  5307 solver.cpp:352] Iteration 10800 (1.62566 iter/s, 61.5136s/100 iter), 20.9/232ep, loss = 4.1095
I0510 16:41:46.095281  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.14543 (* 1 = 5.14543 loss)
I0510 16:41:46.095299  5307 sgd_solver.cpp:172] Iteration 10800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:42:12.404253  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 16:42:47.050778  5307 solver.cpp:352] Iteration 10900 (1.64057 iter/s, 60.9545s/100 iter), 21.1/232ep, loss = 4.19932
I0510 16:42:47.050837  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.53899 (* 1 = 4.53899 loss)
I0510 16:42:47.050843  5307 sgd_solver.cpp:172] Iteration 10900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:43:48.170625  5307 solver.cpp:352] Iteration 11000 (1.63616 iter/s, 61.1188s/100 iter), 21.3/232ep, loss = 4.08915
I0510 16:43:48.170718  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.08948 (* 1 = 4.08948 loss)
I0510 16:43:48.170742  5307 sgd_solver.cpp:172] Iteration 11000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:44:48.368515  5307 solver.cpp:352] Iteration 11100 (1.66122 iter/s, 60.1968s/100 iter), 21.5/232ep, loss = 3.97626
I0510 16:44:48.368626  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.17662 (* 1 = 4.17662 loss)
I0510 16:44:48.368635  5307 sgd_solver.cpp:172] Iteration 11100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:45:48.322374  5307 solver.cpp:352] Iteration 11200 (1.66798 iter/s, 59.9528s/100 iter), 21.7/232ep, loss = 4.23018
I0510 16:45:48.322760  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.64182 (* 1 = 3.64182 loss)
I0510 16:45:48.322772  5307 sgd_solver.cpp:172] Iteration 11200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:46:48.441637  5307 solver.cpp:352] Iteration 11300 (1.66339 iter/s, 60.1182s/100 iter), 21.8/232ep, loss = 4.2839
I0510 16:46:48.441692  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.20155 (* 1 = 3.20155 loss)
I0510 16:46:48.441699  5307 sgd_solver.cpp:172] Iteration 11300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:47:25.483207  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 16:47:49.252192  5307 solver.cpp:352] Iteration 11400 (1.64448 iter/s, 60.8095s/100 iter), 22/232ep, loss = 4.16623
I0510 16:47:49.252215  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.13885 (* 1 = 3.13885 loss)
I0510 16:47:49.252223  5307 sgd_solver.cpp:172] Iteration 11400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:48:50.116747  5307 solver.cpp:352] Iteration 11500 (1.64302 iter/s, 60.8635s/100 iter), 22.2/232ep, loss = 4.14411
I0510 16:48:50.116850  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.16257 (* 1 = 4.16257 loss)
I0510 16:48:50.116873  5307 sgd_solver.cpp:172] Iteration 11500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:49:51.222333  5307 solver.cpp:352] Iteration 11600 (1.63654 iter/s, 61.1045s/100 iter), 22.4/232ep, loss = 4.14758
I0510 16:49:51.222458  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.1045 (* 1 = 4.1045 loss)
I0510 16:49:51.222470  5307 sgd_solver.cpp:172] Iteration 11600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:50:52.188690  5307 solver.cpp:352] Iteration 11700 (1.64028 iter/s, 60.9653s/100 iter), 22.6/232ep, loss = 4.45619
I0510 16:50:52.188776  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.1889 (* 1 = 5.1889 loss)
I0510 16:50:52.188787  5307 sgd_solver.cpp:172] Iteration 11700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:51:53.544272  5307 solver.cpp:352] Iteration 11800 (1.62987 iter/s, 61.3545s/100 iter), 22.8/232ep, loss = 4.10034
I0510 16:51:53.544347  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.12696 (* 1 = 4.12696 loss)
I0510 16:51:53.544355  5307 sgd_solver.cpp:172] Iteration 11800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:52:40.321614  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 16:52:54.253976  5307 solver.cpp:352] Iteration 11900 (1.64721 iter/s, 60.7086s/100 iter), 23/232ep, loss = 4.27672
I0510 16:52:54.254007  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.39659 (* 1 = 4.39659 loss)
I0510 16:52:54.254089  5307 sgd_solver.cpp:172] Iteration 11900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:53:53.266656  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_12000.caffemodel
I0510 16:53:53.284037  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_12000.solverstate
I0510 16:53:53.289765  5307 solver.cpp:635] Iteration 12000, Testing net (#0)
I0510 16:54:34.372668  5353 data_reader.cpp:320] Restarting data pre-fetching
I0510 16:54:34.597332  5307 solver.cpp:747] class AP 1: 0.377338
I0510 16:54:34.598632  5307 solver.cpp:747] class AP 2: 0.473243
I0510 16:54:34.606649  5307 solver.cpp:747] class AP 3: 0.28361
I0510 16:54:34.609349  5307 solver.cpp:747] class AP 4: 0.236268
I0510 16:54:34.614091  5307 solver.cpp:747] class AP 5: 0.154874
I0510 16:54:34.614581  5307 solver.cpp:747] class AP 6: 0.430217
I0510 16:54:34.625377  5307 solver.cpp:747] class AP 7: 0.498381
I0510 16:54:34.625912  5307 solver.cpp:747] class AP 8: 0.514091
I0510 16:54:34.643224  5307 solver.cpp:747] class AP 9: 0.185966
I0510 16:54:34.643985  5307 solver.cpp:747] class AP 10: 0.279618
I0510 16:54:34.644327  5307 solver.cpp:747] class AP 11: 0.260463
I0510 16:54:34.645735  5307 solver.cpp:747] class AP 12: 0.434783
I0510 16:54:34.646425  5307 solver.cpp:747] class AP 13: 0.544954
I0510 16:54:34.646972  5307 solver.cpp:747] class AP 14: 0.511976
I0510 16:54:34.737347  5307 solver.cpp:747] class AP 15: 0.500064
I0510 16:54:34.738363  5307 solver.cpp:747] class AP 16: 0.167407
I0510 16:54:34.741420  5307 solver.cpp:747] class AP 17: 0.288721
I0510 16:54:34.741683  5307 solver.cpp:747] class AP 18: 0.227028
I0510 16:54:34.742285  5307 solver.cpp:747] class AP 19: 0.392775
I0510 16:54:34.742945  5307 solver.cpp:747] class AP 20: 0.278508
I0510 16:54:34.742951  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.352014
I0510 16:54:34.743127  5307 solver.cpp:283] Tests completed in 100.487s
I0510 16:54:35.285920  5307 solver.cpp:352] Iteration 12000 (0.99515 iter/s, 100.487s/100 iter), 23.2/232ep, loss = 4.13124
I0510 16:54:35.285944  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.88816 (* 1 = 3.88816 loss)
I0510 16:54:35.285953  5307 sgd_solver.cpp:172] Iteration 12000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:55:34.848623  5307 solver.cpp:352] Iteration 12100 (1.67893 iter/s, 59.5616s/100 iter), 23.4/232ep, loss = 3.97695
I0510 16:55:34.848683  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.20505 (* 1 = 3.20505 loss)
I0510 16:55:34.848691  5307 sgd_solver.cpp:172] Iteration 12100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:56:35.011502  5307 solver.cpp:352] Iteration 12200 (1.66219 iter/s, 60.1617s/100 iter), 23.6/232ep, loss = 4.0189
I0510 16:56:35.012388  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.4049 (* 1 = 3.4049 loss)
I0510 16:56:35.012408  5307 sgd_solver.cpp:172] Iteration 12200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:57:35.002763  5307 solver.cpp:352] Iteration 12300 (1.66694 iter/s, 59.9902s/100 iter), 23.8/232ep, loss = 4.05656
I0510 16:57:35.003190  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.29515 (* 1 = 4.29515 loss)
I0510 16:57:35.003201  5307 sgd_solver.cpp:172] Iteration 12300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:58:32.893283  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 16:58:35.812647  5307 solver.cpp:352] Iteration 12400 (1.6445 iter/s, 60.8088s/100 iter), 24/232ep, loss = 4.24311
I0510 16:58:35.812897  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.02051 (* 1 = 4.02051 loss)
I0510 16:58:35.812952  5307 sgd_solver.cpp:172] Iteration 12400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 16:59:37.592346  5307 solver.cpp:352] Iteration 12500 (1.61868 iter/s, 61.7786s/100 iter), 24.2/232ep, loss = 4.08884
I0510 16:59:37.596276  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.82929 (* 1 = 3.82929 loss)
I0510 16:59:37.596339  5307 sgd_solver.cpp:172] Iteration 12500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:00:38.686198  5307 solver.cpp:352] Iteration 12600 (1.63686 iter/s, 61.0928s/100 iter), 24.4/232ep, loss = 4.14987
I0510 17:00:38.686290  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.31445 (* 1 = 4.31445 loss)
I0510 17:00:38.686305  5307 sgd_solver.cpp:172] Iteration 12600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:01:38.478579  5307 solver.cpp:352] Iteration 12700 (1.67248 iter/s, 59.7913s/100 iter), 24.6/232ep, loss = 3.97729
I0510 17:01:38.479331  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.01469 (* 1 = 4.01469 loss)
I0510 17:01:38.479349  5307 sgd_solver.cpp:172] Iteration 12700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:02:39.137495  5307 solver.cpp:352] Iteration 12800 (1.64859 iter/s, 60.6578s/100 iter), 24.7/232ep, loss = 4.10032
I0510 17:02:39.137583  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.73172 (* 1 = 4.73172 loss)
I0510 17:02:39.137591  5307 sgd_solver.cpp:172] Iteration 12800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:03:39.246263  5307 solver.cpp:352] Iteration 12900 (1.66368 iter/s, 60.1077s/100 iter), 24.9/232ep, loss = 4.03988
I0510 17:03:39.246330  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.31536 (* 1 = 4.31536 loss)
I0510 17:03:39.246340  5307 sgd_solver.cpp:172] Iteration 12900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:03:47.180572  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 17:04:40.025022  5307 solver.cpp:352] Iteration 13000 (1.64534 iter/s, 60.7777s/100 iter), 25.1/232ep, loss = 4.02856
I0510 17:04:40.025166  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.68971 (* 1 = 3.68971 loss)
I0510 17:04:40.025225  5307 sgd_solver.cpp:172] Iteration 13000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:05:40.191223  5307 solver.cpp:352] Iteration 13100 (1.66209 iter/s, 60.1651s/100 iter), 25.3/232ep, loss = 4.16508
I0510 17:05:40.191306  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.49254 (* 1 = 4.49254 loss)
I0510 17:05:40.191313  5307 sgd_solver.cpp:172] Iteration 13100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:06:48.350085  5307 solver.cpp:352] Iteration 13200 (1.46719 iter/s, 68.1577s/100 iter), 25.5/232ep, loss = 4.01508
I0510 17:06:48.354142  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.76144 (* 1 = 4.76144 loss)
I0510 17:06:48.354167  5307 sgd_solver.cpp:172] Iteration 13200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:07:53.096518  5307 solver.cpp:352] Iteration 13300 (1.54451 iter/s, 64.7453s/100 iter), 25.7/232ep, loss = 4.15617
I0510 17:07:53.096621  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.55177 (* 1 = 4.55177 loss)
I0510 17:07:53.096631  5307 sgd_solver.cpp:172] Iteration 13300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:08:52.704501  5307 solver.cpp:352] Iteration 13400 (1.67766 iter/s, 59.6069s/100 iter), 25.9/232ep, loss = 4.03562
I0510 17:08:52.704582  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.56205 (* 1 = 3.56205 loss)
I0510 17:08:52.704591  5307 sgd_solver.cpp:172] Iteration 13400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:09:10.333612  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 17:09:53.295830  5307 solver.cpp:352] Iteration 13500 (1.65043 iter/s, 60.5903s/100 iter), 26.1/232ep, loss = 4.18251
I0510 17:09:53.295914  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.89812 (* 1 = 3.89812 loss)
I0510 17:09:53.295923  5307 sgd_solver.cpp:172] Iteration 13500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:10:53.762625  5307 solver.cpp:352] Iteration 13600 (1.65383 iter/s, 60.4657s/100 iter), 26.3/232ep, loss = 4.3044
I0510 17:10:53.762749  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.40704 (* 1 = 4.40704 loss)
I0510 17:10:53.762779  5307 sgd_solver.cpp:172] Iteration 13600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:11:53.526618  5307 solver.cpp:352] Iteration 13700 (1.67328 iter/s, 59.763s/100 iter), 26.5/232ep, loss = 4.05516
I0510 17:11:53.526890  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.48273 (* 1 = 4.48273 loss)
I0510 17:11:53.526914  5307 sgd_solver.cpp:172] Iteration 13700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:12:54.021212  5307 solver.cpp:352] Iteration 13800 (1.65307 iter/s, 60.4935s/100 iter), 26.7/232ep, loss = 4.13883
I0510 17:12:54.023648  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.82784 (* 1 = 3.82784 loss)
I0510 17:12:54.023679  5307 sgd_solver.cpp:172] Iteration 13800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:13:53.147681  5307 solver.cpp:352] Iteration 13900 (1.69132 iter/s, 59.1254s/100 iter), 26.9/232ep, loss = 3.92843
I0510 17:13:53.147752  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.15256 (* 1 = 5.15256 loss)
I0510 17:13:53.147760  5307 sgd_solver.cpp:172] Iteration 13900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:14:21.294966  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 17:14:53.081138  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_14000.caffemodel
I0510 17:14:53.106668  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_14000.solverstate
I0510 17:14:53.115489  5307 solver.cpp:635] Iteration 14000, Testing net (#0)
I0510 17:15:36.413102  5353 data_reader.cpp:320] Restarting data pre-fetching
I0510 17:15:36.644253  5307 solver.cpp:747] class AP 1: 0.26767
I0510 17:15:36.644846  5307 solver.cpp:747] class AP 2: 0.521108
I0510 17:15:36.645982  5307 solver.cpp:747] class AP 3: 0.190442
I0510 17:15:36.649343  5307 solver.cpp:747] class AP 4: 0.209313
I0510 17:15:36.675809  5307 solver.cpp:747] class AP 5: 0.196156
I0510 17:15:36.676244  5307 solver.cpp:747] class AP 6: 0.524823
I0510 17:15:36.684424  5307 solver.cpp:747] class AP 7: 0.544608
I0510 17:15:36.684862  5307 solver.cpp:747] class AP 8: 0.460104
I0510 17:15:36.702005  5307 solver.cpp:747] class AP 9: 0.141894
I0510 17:15:36.702060  5307 solver.cpp:747] class AP 10: 0.171285
I0510 17:15:36.704457  5307 solver.cpp:747] class AP 11: 0.324904
I0510 17:15:36.704716  5307 solver.cpp:747] class AP 12: 0.356893
I0510 17:15:36.704767  5307 solver.cpp:747] class AP 13: 0.244357
I0510 17:15:36.705610  5307 solver.cpp:747] class AP 14: 0.572795
I0510 17:15:36.763828  5307 solver.cpp:747] class AP 15: 0.551995
I0510 17:15:36.782464  5307 solver.cpp:747] class AP 16: 0.160565
I0510 17:15:36.782575  5307 solver.cpp:747] class AP 17: 0.262686
I0510 17:15:36.783303  5307 solver.cpp:747] class AP 18: 0.248361
I0510 17:15:36.783385  5307 solver.cpp:747] class AP 19: 0.502314
I0510 17:15:36.785104  5307 solver.cpp:747] class AP 20: 0.379687
I0510 17:15:36.785117  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.341598
I0510 17:15:36.785410  5307 solver.cpp:283] Tests completed in 103.636s
I0510 17:15:37.416332  5307 solver.cpp:352] Iteration 14000 (0.964917 iter/s, 103.636s/100 iter), 27.1/232ep, loss = 4.10391
I0510 17:15:37.416354  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.94686 (* 1 = 3.94686 loss)
I0510 17:15:37.416363  5307 sgd_solver.cpp:172] Iteration 14000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:16:38.509384  5307 solver.cpp:352] Iteration 14100 (1.63688 iter/s, 61.0919s/100 iter), 27.3/232ep, loss = 4.0748
I0510 17:16:38.509459  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.024 (* 1 = 4.024 loss)
I0510 17:16:38.509469  5307 sgd_solver.cpp:172] Iteration 14100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:17:39.031899  5307 solver.cpp:352] Iteration 14200 (1.65231 iter/s, 60.5214s/100 iter), 27.5/232ep, loss = 4.04891
I0510 17:17:39.031961  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.72282 (* 1 = 4.72282 loss)
I0510 17:17:39.031971  5307 sgd_solver.cpp:172] Iteration 14200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:18:39.693130  5307 solver.cpp:352] Iteration 14300 (1.64853 iter/s, 60.6601s/100 iter), 27.6/232ep, loss = 4.06177
I0510 17:18:39.693199  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.31345 (* 1 = 4.31345 loss)
I0510 17:18:39.693244  5307 sgd_solver.cpp:172] Iteration 14300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:19:40.746486  5307 solver.cpp:352] Iteration 14400 (1.63794 iter/s, 61.0523s/100 iter), 27.8/232ep, loss = 4.2231
I0510 17:19:40.746574  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.62917 (* 1 = 4.62917 loss)
I0510 17:19:40.746584  5307 sgd_solver.cpp:172] Iteration 14400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:20:20.180049  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 17:20:41.706598  5307 solver.cpp:352] Iteration 14500 (1.64045 iter/s, 60.959s/100 iter), 28/232ep, loss = 3.993
I0510 17:20:41.706683  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.50615 (* 1 = 4.50615 loss)
I0510 17:20:41.706708  5307 sgd_solver.cpp:172] Iteration 14500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:21:42.623369  5307 solver.cpp:352] Iteration 14600 (1.64161 iter/s, 60.9157s/100 iter), 28.2/232ep, loss = 4.06883
I0510 17:21:42.623472  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.08766 (* 1 = 3.08766 loss)
I0510 17:21:42.623486  5307 sgd_solver.cpp:172] Iteration 14600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:22:43.666040  5307 solver.cpp:352] Iteration 14700 (1.63823 iter/s, 61.0416s/100 iter), 28.4/232ep, loss = 3.97623
I0510 17:22:43.666119  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.33782 (* 1 = 3.33782 loss)
I0510 17:22:43.666136  5307 sgd_solver.cpp:172] Iteration 14700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:23:44.337112  5307 solver.cpp:352] Iteration 14800 (1.64826 iter/s, 60.67s/100 iter), 28.6/232ep, loss = 4.22662
I0510 17:23:44.337558  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.92494 (* 1 = 3.92494 loss)
I0510 17:23:44.337577  5307 sgd_solver.cpp:172] Iteration 14800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:24:44.634955  5307 solver.cpp:352] Iteration 14900 (1.65846 iter/s, 60.2968s/100 iter), 28.8/232ep, loss = 4.08335
I0510 17:24:44.635013  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.69729 (* 1 = 4.69729 loss)
I0510 17:24:44.635020  5307 sgd_solver.cpp:172] Iteration 14900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:25:33.500568  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 17:25:44.786931  5307 solver.cpp:352] Iteration 15000 (1.66249 iter/s, 60.1509s/100 iter), 29/232ep, loss = 4.09779
I0510 17:25:44.786994  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.80358 (* 1 = 3.80358 loss)
I0510 17:25:44.787019  5307 sgd_solver.cpp:172] Iteration 15000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:26:45.754842  5307 solver.cpp:352] Iteration 15100 (1.64024 iter/s, 60.9668s/100 iter), 29.2/232ep, loss = 3.83954
I0510 17:26:45.759059  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.36041 (* 1 = 4.36041 loss)
I0510 17:26:45.759080  5307 sgd_solver.cpp:172] Iteration 15100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:27:46.087405  5307 solver.cpp:352] Iteration 15200 (1.65751 iter/s, 60.3315s/100 iter), 29.4/232ep, loss = 3.79234
I0510 17:27:46.087489  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.89815 (* 1 = 3.89815 loss)
I0510 17:27:46.087505  5307 sgd_solver.cpp:172] Iteration 15200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:28:47.248160  5307 solver.cpp:352] Iteration 15300 (1.63506 iter/s, 61.1597s/100 iter), 29.6/232ep, loss = 4.25529
I0510 17:28:47.248291  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.52093 (* 1 = 4.52093 loss)
I0510 17:28:47.248311  5307 sgd_solver.cpp:172] Iteration 15300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:29:47.624392  5307 solver.cpp:352] Iteration 15400 (1.65631 iter/s, 60.3752s/100 iter), 29.8/232ep, loss = 3.90185
I0510 17:29:47.624768  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.14909 (* 1 = 4.14909 loss)
I0510 17:29:47.624789  5307 sgd_solver.cpp:172] Iteration 15400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:30:47.525804  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 17:30:48.213439  5307 solver.cpp:352] Iteration 15500 (1.65049 iter/s, 60.588s/100 iter), 30/232ep, loss = 4.31352
I0510 17:30:48.213562  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.92865 (* 1 = 4.92865 loss)
I0510 17:30:48.213585  5307 sgd_solver.cpp:172] Iteration 15500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:31:49.500659  5307 solver.cpp:352] Iteration 15600 (1.63169 iter/s, 61.2862s/100 iter), 30.2/232ep, loss = 4.06144
I0510 17:31:49.500794  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.67102 (* 1 = 4.67102 loss)
I0510 17:31:49.500823  5307 sgd_solver.cpp:172] Iteration 15600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:32:49.536686  5307 solver.cpp:352] Iteration 15700 (1.6657 iter/s, 60.035s/100 iter), 30.4/232ep, loss = 4.13441
I0510 17:32:49.537791  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.47626 (* 1 = 3.47626 loss)
I0510 17:32:49.537806  5307 sgd_solver.cpp:172] Iteration 15700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:33:50.337203  5307 solver.cpp:352] Iteration 15800 (1.64475 iter/s, 60.7995s/100 iter), 30.5/232ep, loss = 3.98306
I0510 17:33:50.337349  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.89969 (* 1 = 3.89969 loss)
I0510 17:33:50.337357  5307 sgd_solver.cpp:172] Iteration 15800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:34:50.994805  5307 solver.cpp:352] Iteration 15900 (1.64863 iter/s, 60.6565s/100 iter), 30.7/232ep, loss = 3.94058
I0510 17:34:50.995951  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.15672 (* 1 = 4.15672 loss)
I0510 17:34:50.995962  5307 sgd_solver.cpp:172] Iteration 15900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:35:51.081809  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_16000.caffemodel
I0510 17:35:51.098748  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_16000.solverstate
I0510 17:35:51.104290  5307 solver.cpp:635] Iteration 16000, Testing net (#0)
I0510 17:36:33.383131  5353 data_reader.cpp:320] Restarting data pre-fetching
I0510 17:36:33.610116  5307 solver.cpp:747] class AP 1: 0.486965
I0510 17:36:33.610594  5307 solver.cpp:747] class AP 2: 0.526476
I0510 17:36:33.614055  5307 solver.cpp:747] class AP 3: 0.364743
I0510 17:36:33.615774  5307 solver.cpp:747] class AP 4: 0.298434
I0510 17:36:33.624733  5307 solver.cpp:747] class AP 5: 0.151348
I0510 17:36:33.625550  5307 solver.cpp:747] class AP 6: 0.594422
I0510 17:36:33.635076  5307 solver.cpp:747] class AP 7: 0.564054
I0510 17:36:33.635455  5307 solver.cpp:747] class AP 8: 0.653435
I0510 17:36:33.657244  5307 solver.cpp:747] class AP 9: 0.246602
I0510 17:36:33.657665  5307 solver.cpp:747] class AP 10: 0.407204
I0510 17:36:33.658128  5307 solver.cpp:747] class AP 11: 0.326416
I0510 17:36:33.659003  5307 solver.cpp:747] class AP 12: 0.557808
I0510 17:36:33.659384  5307 solver.cpp:747] class AP 13: 0.654049
I0510 17:36:33.659610  5307 solver.cpp:747] class AP 14: 0.561787
I0510 17:36:33.743221  5307 solver.cpp:747] class AP 15: 0.609836
I0510 17:36:33.745687  5307 solver.cpp:747] class AP 16: 0.204773
I0510 17:36:33.746655  5307 solver.cpp:747] class AP 17: 0.436756
I0510 17:36:33.747130  5307 solver.cpp:747] class AP 18: 0.468889
I0510 17:36:33.747989  5307 solver.cpp:747] class AP 19: 0.595545
I0510 17:36:33.749708  5307 solver.cpp:747] class AP 20: 0.467597
I0510 17:36:33.749716  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.458857
I0510 17:36:33.749986  5307 solver.cpp:283] Tests completed in 102.753s
I0510 17:36:34.340684  5307 solver.cpp:352] Iteration 16000 (0.973204 iter/s, 102.753s/100 iter), 30.9/232ep, loss = 3.82997
I0510 17:36:34.340775  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.73402 (* 1 = 2.73402 loss)
I0510 17:36:34.340798  5307 sgd_solver.cpp:172] Iteration 16000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:36:43.517487  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 17:37:35.048465  5307 solver.cpp:352] Iteration 16100 (1.64727 iter/s, 60.7067s/100 iter), 31.1/232ep, loss = 4.22994
I0510 17:37:35.048614  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.20404 (* 1 = 5.20404 loss)
I0510 17:37:35.048635  5307 sgd_solver.cpp:172] Iteration 16100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:38:35.793680  5307 solver.cpp:352] Iteration 16200 (1.64625 iter/s, 60.7441s/100 iter), 31.3/232ep, loss = 3.97765
I0510 17:38:35.793766  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.58101 (* 1 = 4.58101 loss)
I0510 17:38:35.793776  5307 sgd_solver.cpp:172] Iteration 16200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:39:35.721940  5307 solver.cpp:352] Iteration 16300 (1.66869 iter/s, 59.9272s/100 iter), 31.5/232ep, loss = 3.78574
I0510 17:39:35.722015  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.64567 (* 1 = 4.64567 loss)
I0510 17:39:35.722024  5307 sgd_solver.cpp:172] Iteration 16300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:40:35.965342  5307 solver.cpp:352] Iteration 16400 (1.65996 iter/s, 60.2423s/100 iter), 31.7/232ep, loss = 3.97578
I0510 17:40:35.965407  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.22316 (* 1 = 3.22316 loss)
I0510 17:40:35.965415  5307 sgd_solver.cpp:172] Iteration 16400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:41:37.109102  5307 solver.cpp:352] Iteration 16500 (1.63552 iter/s, 61.1426s/100 iter), 31.9/232ep, loss = 3.84236
I0510 17:41:37.112644  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.35575 (* 1 = 4.35575 loss)
I0510 17:41:37.112681  5307 sgd_solver.cpp:172] Iteration 16500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:41:57.559957  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 17:42:38.290222  5307 solver.cpp:352] Iteration 16600 (1.63452 iter/s, 61.18s/100 iter), 32.1/232ep, loss = 3.9832
I0510 17:42:38.290297  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.06678 (* 1 = 4.06678 loss)
I0510 17:42:38.290305  5307 sgd_solver.cpp:172] Iteration 16600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:43:39.620643  5307 solver.cpp:352] Iteration 16700 (1.63054 iter/s, 61.3293s/100 iter), 32.3/232ep, loss = 3.93954
I0510 17:43:39.620726  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.65763 (* 1 = 3.65763 loss)
I0510 17:43:39.620740  5307 sgd_solver.cpp:172] Iteration 16700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:44:40.493341  5307 solver.cpp:352] Iteration 16800 (1.6428 iter/s, 60.8716s/100 iter), 32.5/232ep, loss = 4.09846
I0510 17:44:40.493398  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.68261 (* 1 = 3.68261 loss)
I0510 17:44:40.493405  5307 sgd_solver.cpp:172] Iteration 16800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:45:41.239418  5307 solver.cpp:352] Iteration 16900 (1.64623 iter/s, 60.745s/100 iter), 32.7/232ep, loss = 3.76668
I0510 17:45:41.239538  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.29666 (* 1 = 3.29666 loss)
I0510 17:45:41.239555  5307 sgd_solver.cpp:172] Iteration 16900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:46:42.703081  5307 solver.cpp:352] Iteration 17000 (1.62701 iter/s, 61.4626s/100 iter), 32.9/232ep, loss = 3.9525
I0510 17:46:42.703943  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.58665 (* 1 = 3.58665 loss)
I0510 17:46:42.703951  5307 sgd_solver.cpp:172] Iteration 17000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:47:13.536533  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 17:47:43.672152  5307 solver.cpp:352] Iteration 17100 (1.64021 iter/s, 60.968s/100 iter), 33.1/232ep, loss = 4.24186
I0510 17:47:43.672236  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.35574 (* 1 = 4.35574 loss)
I0510 17:47:43.672252  5307 sgd_solver.cpp:172] Iteration 17100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:48:44.434834  5307 solver.cpp:352] Iteration 17200 (1.64578 iter/s, 60.7616s/100 iter), 33.3/232ep, loss = 4.11966
I0510 17:48:44.434926  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.3499 (* 1 = 3.3499 loss)
I0510 17:48:44.434934  5307 sgd_solver.cpp:172] Iteration 17200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:49:45.975968  5307 solver.cpp:352] Iteration 17300 (1.62496 iter/s, 61.54s/100 iter), 33.4/232ep, loss = 3.93047
I0510 17:49:45.976122  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.90535 (* 1 = 3.90535 loss)
I0510 17:49:45.976135  5307 sgd_solver.cpp:172] Iteration 17300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:50:46.313288  5307 solver.cpp:352] Iteration 17400 (1.65738 iter/s, 60.3363s/100 iter), 33.6/232ep, loss = 3.95524
I0510 17:50:46.315484  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.67539 (* 1 = 3.67539 loss)
I0510 17:50:46.315497  5307 sgd_solver.cpp:172] Iteration 17400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:51:47.110417  5307 solver.cpp:352] Iteration 17500 (1.64484 iter/s, 60.7961s/100 iter), 33.8/232ep, loss = 4.11225
I0510 17:51:47.110472  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.59651 (* 1 = 4.59651 loss)
I0510 17:51:47.110479  5307 sgd_solver.cpp:172] Iteration 17500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:52:27.470515  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 17:52:47.254881  5307 solver.cpp:352] Iteration 17600 (1.66269 iter/s, 60.1434s/100 iter), 34/232ep, loss = 4.07409
I0510 17:52:47.254906  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.87837 (* 1 = 3.87837 loss)
I0510 17:52:47.254914  5307 sgd_solver.cpp:172] Iteration 17600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:53:47.585824  5307 solver.cpp:352] Iteration 17700 (1.65755 iter/s, 60.3299s/100 iter), 34.2/232ep, loss = 4.09266
I0510 17:53:47.585917  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.20773 (* 1 = 4.20773 loss)
I0510 17:53:47.585937  5307 sgd_solver.cpp:172] Iteration 17700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:54:49.169430  5307 solver.cpp:352] Iteration 17800 (1.62384 iter/s, 61.5825s/100 iter), 34.4/232ep, loss = 4.06271
I0510 17:54:49.169489  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.08636 (* 1 = 4.08636 loss)
I0510 17:54:49.169497  5307 sgd_solver.cpp:172] Iteration 17800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:55:51.290794  5307 solver.cpp:352] Iteration 17900 (1.60978 iter/s, 62.1203s/100 iter), 34.6/232ep, loss = 3.95755
I0510 17:55:51.290895  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.02087 (* 1 = 4.02087 loss)
I0510 17:55:51.290905  5307 sgd_solver.cpp:172] Iteration 17900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:56:51.971354  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_18000.caffemodel
I0510 17:56:51.990205  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_18000.solverstate
I0510 17:56:51.995992  5307 solver.cpp:635] Iteration 18000, Testing net (#0)
I0510 17:57:33.766407  5353 data_reader.cpp:320] Restarting data pre-fetching
I0510 17:57:33.960752  5307 solver.cpp:747] class AP 1: 0.406091
I0510 17:57:33.961108  5307 solver.cpp:747] class AP 2: 0.464497
I0510 17:57:33.964440  5307 solver.cpp:747] class AP 3: 0.2912
I0510 17:57:33.965749  5307 solver.cpp:747] class AP 4: 0.207739
I0510 17:57:33.996084  5307 solver.cpp:747] class AP 5: 0.167533
I0510 17:57:33.996301  5307 solver.cpp:747] class AP 6: 0.579484
I0510 17:57:34.003047  5307 solver.cpp:747] class AP 7: 0.549524
I0510 17:57:34.003806  5307 solver.cpp:747] class AP 8: 0.616621
I0510 17:57:34.028941  5307 solver.cpp:747] class AP 9: 0.269421
I0510 17:57:34.029110  5307 solver.cpp:747] class AP 10: 0.293091
I0510 17:57:34.030127  5307 solver.cpp:747] class AP 11: 0.404158
I0510 17:57:34.030670  5307 solver.cpp:747] class AP 12: 0.489255
I0510 17:57:34.030750  5307 solver.cpp:747] class AP 13: 0.475573
I0510 17:57:34.031006  5307 solver.cpp:747] class AP 14: 0.444097
I0510 17:57:34.081130  5307 solver.cpp:747] class AP 15: 0.539198
I0510 17:57:34.096513  5307 solver.cpp:747] class AP 16: 0.149469
I0510 17:57:34.096949  5307 solver.cpp:747] class AP 17: 0.370188
I0510 17:57:34.097833  5307 solver.cpp:747] class AP 18: 0.353684
I0510 17:57:34.098188  5307 solver.cpp:747] class AP 19: 0.501156
I0510 17:57:34.101331  5307 solver.cpp:747] class AP 20: 0.364472
I0510 17:57:34.101347  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.396823
I0510 17:57:34.101477  5307 solver.cpp:283] Tests completed in 102.809s
I0510 17:57:34.706904  5307 solver.cpp:352] Iteration 18000 (0.972679 iter/s, 102.809s/100 iter), 34.8/232ep, loss = 4.1169
I0510 17:57:34.706931  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.28014 (* 1 = 4.28014 loss)
I0510 17:57:34.706939  5307 sgd_solver.cpp:172] Iteration 18000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:58:26.168864  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 17:58:34.832660  5307 solver.cpp:352] Iteration 18100 (1.66321 iter/s, 60.1246s/100 iter), 35/232ep, loss = 4.08924
I0510 17:58:34.832814  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.48788 (* 1 = 4.48788 loss)
I0510 17:58:34.832832  5307 sgd_solver.cpp:172] Iteration 18100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 17:59:35.985110  5307 solver.cpp:352] Iteration 18200 (1.63529 iter/s, 61.1514s/100 iter), 35.2/232ep, loss = 3.75936
I0510 17:59:35.985201  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.16756 (* 1 = 3.16756 loss)
I0510 17:59:35.985221  5307 sgd_solver.cpp:172] Iteration 18200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:00:36.783682  5307 solver.cpp:352] Iteration 18300 (1.64481 iter/s, 60.7975s/100 iter), 35.4/232ep, loss = 3.86903
I0510 18:00:36.783763  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.3618 (* 1 = 4.3618 loss)
I0510 18:00:36.783771  5307 sgd_solver.cpp:172] Iteration 18300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:01:38.399515  5307 solver.cpp:352] Iteration 18400 (1.62299 iter/s, 61.6147s/100 iter), 35.6/232ep, loss = 4.0389
I0510 18:01:38.399615  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.60873 (* 1 = 3.60873 loss)
I0510 18:01:38.399624  5307 sgd_solver.cpp:172] Iteration 18400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:02:40.127353  5307 solver.cpp:352] Iteration 18500 (1.62004 iter/s, 61.7267s/100 iter), 35.8/232ep, loss = 3.90535
I0510 18:02:40.127506  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.57586 (* 1 = 3.57586 loss)
I0510 18:02:40.127534  5307 sgd_solver.cpp:172] Iteration 18500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:03:39.942431  5307 solver.cpp:352] Iteration 18600 (1.67185 iter/s, 59.814s/100 iter), 36/232ep, loss = 3.91408
I0510 18:03:39.942529  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.13427 (* 1 = 5.13427 loss)
I0510 18:03:39.942539  5307 sgd_solver.cpp:172] Iteration 18600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:03:40.720665  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 18:04:39.985424  5307 solver.cpp:352] Iteration 18700 (1.6655 iter/s, 60.0419s/100 iter), 36.2/232ep, loss = 3.97106
I0510 18:04:39.985500  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.63197 (* 1 = 3.63197 loss)
I0510 18:04:39.985510  5307 sgd_solver.cpp:172] Iteration 18700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:05:40.361156  5307 solver.cpp:352] Iteration 18800 (1.65632 iter/s, 60.3746s/100 iter), 36.3/232ep, loss = 3.98146
I0510 18:05:40.364639  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.842 (* 1 = 4.842 loss)
I0510 18:05:40.364675  5307 sgd_solver.cpp:172] Iteration 18800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:06:40.600116  5307 solver.cpp:352] Iteration 18900 (1.66008 iter/s, 60.2379s/100 iter), 36.5/232ep, loss = 3.86298
I0510 18:06:40.600175  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.85125 (* 1 = 3.85125 loss)
I0510 18:06:40.600183  5307 sgd_solver.cpp:172] Iteration 18900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:07:41.151947  5307 solver.cpp:352] Iteration 19000 (1.65151 iter/s, 60.5508s/100 iter), 36.7/232ep, loss = 4.04988
I0510 18:07:41.152015  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.93703 (* 1 = 3.93703 loss)
I0510 18:07:41.152024  5307 sgd_solver.cpp:172] Iteration 19000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:08:41.814600  5307 solver.cpp:352] Iteration 19100 (1.64849 iter/s, 60.6616s/100 iter), 36.9/232ep, loss = 3.8313
I0510 18:08:41.815102  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.45588 (* 1 = 4.45588 loss)
I0510 18:08:41.815121  5307 sgd_solver.cpp:172] Iteration 19100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:08:53.398103  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 18:09:41.547041  5307 solver.cpp:352] Iteration 19200 (1.67416 iter/s, 59.7314s/100 iter), 37.1/232ep, loss = 3.9092
I0510 18:09:41.547230  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.30575 (* 1 = 3.30575 loss)
I0510 18:09:41.547346  5307 sgd_solver.cpp:172] Iteration 19200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:10:41.878931  5307 solver.cpp:352] Iteration 19300 (1.65753 iter/s, 60.3308s/100 iter), 37.3/232ep, loss = 4.02067
I0510 18:10:41.879042  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.05662 (* 1 = 4.05662 loss)
I0510 18:10:41.879062  5307 sgd_solver.cpp:172] Iteration 19300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:11:41.982174  5307 solver.cpp:352] Iteration 19400 (1.66383 iter/s, 60.1022s/100 iter), 37.5/232ep, loss = 3.94155
I0510 18:11:41.982257  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.74712 (* 1 = 4.74712 loss)
I0510 18:11:41.982267  5307 sgd_solver.cpp:172] Iteration 19400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:12:42.256016  5307 solver.cpp:352] Iteration 19500 (1.65912 iter/s, 60.2727s/100 iter), 37.7/232ep, loss = 3.96735
I0510 18:12:42.256213  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.91876 (* 1 = 3.91876 loss)
I0510 18:12:42.256234  5307 sgd_solver.cpp:172] Iteration 19500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:13:42.999758  5307 solver.cpp:352] Iteration 19600 (1.64629 iter/s, 60.7427s/100 iter), 37.9/232ep, loss = 4.12041
I0510 18:13:42.999848  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.56942 (* 1 = 3.56942 loss)
I0510 18:13:42.999858  5307 sgd_solver.cpp:172] Iteration 19600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:14:06.984825  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 18:14:50.224472  5307 solver.cpp:352] Iteration 19700 (1.48757 iter/s, 67.2235s/100 iter), 38.1/232ep, loss = 4.04457
I0510 18:14:50.224571  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.32989 (* 1 = 4.32989 loss)
I0510 18:14:50.224588  5307 sgd_solver.cpp:172] Iteration 19700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:15:55.267130  5307 solver.cpp:352] Iteration 19800 (1.53748 iter/s, 65.0415s/100 iter), 38.3/232ep, loss = 3.97563
I0510 18:15:55.267290  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.43165 (* 1 = 3.43165 loss)
I0510 18:15:55.267304  5307 sgd_solver.cpp:172] Iteration 19800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:16:56.501657  5307 solver.cpp:352] Iteration 19900 (1.63309 iter/s, 61.2334s/100 iter), 38.5/232ep, loss = 3.9215
I0510 18:16:56.501725  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.38991 (* 1 = 3.38991 loss)
I0510 18:16:56.501735  5307 sgd_solver.cpp:172] Iteration 19900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:17:55.653561  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_20000.caffemodel
I0510 18:17:55.693248  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_20000.solverstate
I0510 18:17:55.697934  5307 solver.cpp:635] Iteration 20000, Testing net (#0)
I0510 18:18:37.112228  5353 data_reader.cpp:320] Restarting data pre-fetching
I0510 18:18:37.306205  5307 solver.cpp:747] class AP 1: 0.34128
I0510 18:18:37.306692  5307 solver.cpp:747] class AP 2: 0.466179
I0510 18:18:37.316076  5307 solver.cpp:747] class AP 3: 0.338858
I0510 18:18:37.320827  5307 solver.cpp:747] class AP 4: 0.227758
I0510 18:18:37.331344  5307 solver.cpp:747] class AP 5: 0.208365
I0510 18:18:37.332031  5307 solver.cpp:747] class AP 6: 0.544774
I0510 18:18:37.339907  5307 solver.cpp:747] class AP 7: 0.530615
I0510 18:18:37.341220  5307 solver.cpp:747] class AP 8: 0.540702
I0510 18:18:37.378499  5307 solver.cpp:747] class AP 9: 0.206761
I0510 18:18:37.379087  5307 solver.cpp:747] class AP 10: 0.379273
I0510 18:18:37.379915  5307 solver.cpp:747] class AP 11: 0.333792
I0510 18:18:37.380676  5307 solver.cpp:747] class AP 12: 0.447937
I0510 18:18:37.381017  5307 solver.cpp:747] class AP 13: 0.587963
I0510 18:18:37.381248  5307 solver.cpp:747] class AP 14: 0.473695
I0510 18:18:37.442178  5307 solver.cpp:747] class AP 15: 0.517321
I0510 18:18:37.448504  5307 solver.cpp:747] class AP 16: 0.189493
I0510 18:18:37.452178  5307 solver.cpp:747] class AP 17: 0.361723
I0510 18:18:37.452957  5307 solver.cpp:747] class AP 18: 0.335269
I0510 18:18:37.454664  5307 solver.cpp:747] class AP 19: 0.548444
I0510 18:18:37.459687  5307 solver.cpp:747] class AP 20: 0.405736
I0510 18:18:37.459728  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.399297
I0510 18:18:37.460028  5307 solver.cpp:283] Tests completed in 100.957s
I0510 18:18:38.128073  5307 solver.cpp:352] Iteration 20000 (0.990525 iter/s, 100.957s/100 iter), 38.7/232ep, loss = 3.92276
I0510 18:18:38.128098  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.68845 (* 1 = 3.68845 loss)
I0510 18:18:38.128104  5307 sgd_solver.cpp:172] Iteration 20000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:19:38.890480  5307 solver.cpp:352] Iteration 20100 (1.64578 iter/s, 60.7613s/100 iter), 38.9/232ep, loss = 3.81434
I0510 18:19:38.890576  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.05766 (* 1 = 4.05766 loss)
I0510 18:19:38.890584  5307 sgd_solver.cpp:172] Iteration 20100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:20:10.870867  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 18:20:39.101873  5307 solver.cpp:352] Iteration 20200 (1.66085 iter/s, 60.2103s/100 iter), 39.1/232ep, loss = 3.93665
I0510 18:20:39.101954  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.36537 (* 1 = 4.36537 loss)
I0510 18:20:39.101975  5307 sgd_solver.cpp:172] Iteration 20200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:21:39.325006  5307 solver.cpp:352] Iteration 20300 (1.66052 iter/s, 60.2221s/100 iter), 39.2/232ep, loss = 3.84677
I0510 18:21:39.325109  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.61705 (* 1 = 3.61705 loss)
I0510 18:21:39.325120  5307 sgd_solver.cpp:172] Iteration 20300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:22:39.772847  5307 solver.cpp:352] Iteration 20400 (1.65435 iter/s, 60.4467s/100 iter), 39.4/232ep, loss = 3.83104
I0510 18:22:39.773057  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.03349 (* 1 = 4.03349 loss)
I0510 18:22:39.773083  5307 sgd_solver.cpp:172] Iteration 20400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:23:39.822788  5307 solver.cpp:352] Iteration 20500 (1.66531 iter/s, 60.0489s/100 iter), 39.6/232ep, loss = 3.87636
I0510 18:23:39.822922  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.35261 (* 1 = 4.35261 loss)
I0510 18:23:39.822937  5307 sgd_solver.cpp:172] Iteration 20500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:24:39.488035  5307 solver.cpp:352] Iteration 20600 (1.67605 iter/s, 59.6642s/100 iter), 39.8/232ep, loss = 3.97765
I0510 18:24:39.488114  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.28101 (* 1 = 4.28101 loss)
I0510 18:24:39.488124  5307 sgd_solver.cpp:172] Iteration 20600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:25:22.277652  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 18:25:39.628329  5307 solver.cpp:352] Iteration 20700 (1.66281 iter/s, 60.1392s/100 iter), 40/232ep, loss = 3.92331
I0510 18:25:39.628352  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.61269 (* 1 = 3.61269 loss)
I0510 18:25:39.628358  5307 sgd_solver.cpp:172] Iteration 20700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:26:39.289927  5307 solver.cpp:352] Iteration 20800 (1.67615 iter/s, 59.6605s/100 iter), 40.2/232ep, loss = 3.75517
I0510 18:26:39.289999  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.53533 (* 1 = 3.53533 loss)
I0510 18:26:39.290007  5307 sgd_solver.cpp:172] Iteration 20800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:27:40.264546  5307 solver.cpp:352] Iteration 20900 (1.64006 iter/s, 60.9735s/100 iter), 40.4/232ep, loss = 4.09701
I0510 18:27:40.265084  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.93349 (* 1 = 3.93349 loss)
I0510 18:27:40.265094  5307 sgd_solver.cpp:172] Iteration 20900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:28:41.227520  5307 solver.cpp:352] Iteration 21000 (1.64037 iter/s, 60.9619s/100 iter), 40.6/232ep, loss = 3.9031
I0510 18:28:41.229018  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.82276 (* 1 = 3.82276 loss)
I0510 18:28:41.229033  5307 sgd_solver.cpp:172] Iteration 21000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:29:41.710839  5307 solver.cpp:352] Iteration 21100 (1.65338 iter/s, 60.4822s/100 iter), 40.8/232ep, loss = 4.0459
I0510 18:29:41.710918  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.45003 (* 1 = 5.45003 loss)
I0510 18:29:41.710929  5307 sgd_solver.cpp:172] Iteration 21100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:30:34.003978  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 18:30:41.507900  5307 solver.cpp:352] Iteration 21200 (1.67235 iter/s, 59.796s/100 iter), 41/232ep, loss = 4.03447
I0510 18:30:41.507969  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.2517 (* 1 = 4.2517 loss)
I0510 18:30:41.507989  5307 sgd_solver.cpp:172] Iteration 21200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:31:41.589257  5307 solver.cpp:352] Iteration 21300 (1.66444 iter/s, 60.0803s/100 iter), 41.2/232ep, loss = 4.00796
I0510 18:31:41.589359  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.64948 (* 1 = 4.64948 loss)
I0510 18:31:41.589378  5307 sgd_solver.cpp:172] Iteration 21300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:32:41.931206  5307 solver.cpp:352] Iteration 21400 (1.65725 iter/s, 60.3409s/100 iter), 41.4/232ep, loss = 3.80331
I0510 18:32:41.931308  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.65604 (* 1 = 3.65604 loss)
I0510 18:32:41.931512  5307 sgd_solver.cpp:172] Iteration 21400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:33:42.036473  5307 solver.cpp:352] Iteration 21500 (1.66378 iter/s, 60.1042s/100 iter), 41.6/232ep, loss = 4.00471
I0510 18:33:42.036576  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.9934 (* 1 = 5.9934 loss)
I0510 18:33:42.036587  5307 sgd_solver.cpp:172] Iteration 21500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:34:41.460405  5307 solver.cpp:352] Iteration 21600 (1.68285 iter/s, 59.4229s/100 iter), 41.8/232ep, loss = 3.79898
I0510 18:34:41.460487  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.68195 (* 1 = 4.68195 loss)
I0510 18:34:41.460497  5307 sgd_solver.cpp:172] Iteration 21600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:35:41.398211  5307 solver.cpp:352] Iteration 21700 (1.66843 iter/s, 59.9368s/100 iter), 42/232ep, loss = 3.8566
I0510 18:35:41.398293  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.24144 (* 1 = 4.24144 loss)
I0510 18:35:41.398301  5307 sgd_solver.cpp:172] Iteration 21700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:35:44.294472  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 18:36:41.684083  5307 solver.cpp:352] Iteration 21800 (1.65879 iter/s, 60.2848s/100 iter), 42.1/232ep, loss = 3.88238
I0510 18:36:41.684232  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.80177 (* 1 = 3.80177 loss)
I0510 18:36:41.684255  5307 sgd_solver.cpp:172] Iteration 21800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:37:42.083560  5307 solver.cpp:352] Iteration 21900 (1.65567 iter/s, 60.3984s/100 iter), 42.3/232ep, loss = 3.93615
I0510 18:37:42.083660  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.17012 (* 1 = 3.17012 loss)
I0510 18:37:42.083669  5307 sgd_solver.cpp:172] Iteration 21900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:38:42.316890  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_22000.caffemodel
I0510 18:38:42.336257  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_22000.solverstate
I0510 18:38:42.343206  5307 solver.cpp:635] Iteration 22000, Testing net (#0)
I0510 18:39:23.263263  5353 data_reader.cpp:320] Restarting data pre-fetching
I0510 18:39:23.482539  5307 solver.cpp:747] class AP 1: 0.530255
I0510 18:39:23.483283  5307 solver.cpp:747] class AP 2: 0.599847
I0510 18:39:23.490195  5307 solver.cpp:747] class AP 3: 0.416361
I0510 18:39:23.492012  5307 solver.cpp:747] class AP 4: 0.327485
I0510 18:39:23.506052  5307 solver.cpp:747] class AP 5: 0.238198
I0510 18:39:23.506343  5307 solver.cpp:747] class AP 6: 0.611445
I0510 18:39:23.512264  5307 solver.cpp:747] class AP 7: 0.597716
I0510 18:39:23.513100  5307 solver.cpp:747] class AP 8: 0.673315
I0510 18:39:23.529266  5307 solver.cpp:747] class AP 9: 0.239872
I0510 18:39:23.530041  5307 solver.cpp:747] class AP 10: 0.456606
I0510 18:39:23.530591  5307 solver.cpp:747] class AP 11: 0.429406
I0510 18:39:23.532676  5307 solver.cpp:747] class AP 12: 0.59359
I0510 18:39:23.533262  5307 solver.cpp:747] class AP 13: 0.692092
I0510 18:39:23.533761  5307 solver.cpp:747] class AP 14: 0.583687
I0510 18:39:23.602900  5307 solver.cpp:747] class AP 15: 0.641689
I0510 18:39:23.609939  5307 solver.cpp:747] class AP 16: 0.227152
I0510 18:39:23.611941  5307 solver.cpp:747] class AP 17: 0.475418
I0510 18:39:23.613131  5307 solver.cpp:747] class AP 18: 0.426319
I0510 18:39:23.614387  5307 solver.cpp:747] class AP 19: 0.632528
I0510 18:39:23.615263  5307 solver.cpp:747] class AP 20: 0.441181
I0510 18:39:23.615268  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.491708
I0510 18:39:23.615408  5307 solver.cpp:283] Tests completed in 101.53s
I0510 18:39:24.182399  5307 solver.cpp:352] Iteration 22000 (0.98493 iter/s, 101.53s/100 iter), 42.5/232ep, loss = 3.75261
I0510 18:39:24.182422  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.98661 (* 1 = 3.98661 loss)
I0510 18:39:24.182430  5307 sgd_solver.cpp:172] Iteration 22000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:40:24.254237  5307 solver.cpp:352] Iteration 22100 (1.6647 iter/s, 60.0707s/100 iter), 42.7/232ep, loss = 3.94477
I0510 18:40:24.255007  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.10083 (* 1 = 4.10083 loss)
I0510 18:40:24.255017  5307 sgd_solver.cpp:172] Iteration 22100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:41:25.275432  5307 solver.cpp:352] Iteration 22200 (1.63881 iter/s, 61.0201s/100 iter), 42.9/232ep, loss = 3.93176
I0510 18:41:25.275652  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.34443 (* 1 = 4.34443 loss)
I0510 18:41:25.275666  5307 sgd_solver.cpp:172] Iteration 22200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:41:39.151403  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 18:42:25.048168  5307 solver.cpp:352] Iteration 22300 (1.67303 iter/s, 59.7717s/100 iter), 43.1/232ep, loss = 3.80451
I0510 18:42:25.048316  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.18245 (* 1 = 3.18245 loss)
I0510 18:42:25.048336  5307 sgd_solver.cpp:172] Iteration 22300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:43:24.551668  5307 solver.cpp:352] Iteration 22400 (1.6806 iter/s, 59.5024s/100 iter), 43.3/232ep, loss = 3.88076
I0510 18:43:24.551745  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.97335 (* 1 = 2.97335 loss)
I0510 18:43:24.551754  5307 sgd_solver.cpp:172] Iteration 22400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:44:24.905186  5307 solver.cpp:352] Iteration 22500 (1.65693 iter/s, 60.3524s/100 iter), 43.5/232ep, loss = 3.91015
I0510 18:44:24.905256  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.46989 (* 1 = 3.46989 loss)
I0510 18:44:24.905262  5307 sgd_solver.cpp:172] Iteration 22500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:45:25.671592  5307 solver.cpp:352] Iteration 22600 (1.64568 iter/s, 60.7653s/100 iter), 43.7/232ep, loss = 3.83031
I0510 18:45:25.671681  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.12052 (* 1 = 3.12052 loss)
I0510 18:45:25.671700  5307 sgd_solver.cpp:172] Iteration 22600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:46:25.727347  5307 solver.cpp:352] Iteration 22700 (1.66515 iter/s, 60.0547s/100 iter), 43.9/232ep, loss = 3.77082
I0510 18:46:25.727466  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.15335 (* 1 = 4.15335 loss)
I0510 18:46:25.727480  5307 sgd_solver.cpp:172] Iteration 22700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:46:49.056587  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 18:47:25.671694  5307 solver.cpp:352] Iteration 22800 (1.66824 iter/s, 59.9433s/100 iter), 44.1/232ep, loss = 3.75317
I0510 18:47:25.675361  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.52456 (* 1 = 3.52456 loss)
I0510 18:47:25.675397  5307 sgd_solver.cpp:172] Iteration 22800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:48:26.058811  5307 solver.cpp:352] Iteration 22900 (1.65601 iter/s, 60.386s/100 iter), 44.3/232ep, loss = 3.91824
I0510 18:48:26.058909  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.12324 (* 1 = 3.12324 loss)
I0510 18:48:26.058931  5307 sgd_solver.cpp:172] Iteration 22900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:49:25.958818  5307 solver.cpp:352] Iteration 23000 (1.66948 iter/s, 59.8989s/100 iter), 44.5/232ep, loss = 3.88529
I0510 18:49:25.958876  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.82834 (* 1 = 3.82834 loss)
I0510 18:49:25.958884  5307 sgd_solver.cpp:172] Iteration 23000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:50:26.141391  5307 solver.cpp:352] Iteration 23100 (1.66164 iter/s, 60.1815s/100 iter), 44.7/232ep, loss = 3.84205
I0510 18:50:26.141486  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.80804 (* 1 = 3.80804 loss)
I0510 18:50:26.141495  5307 sgd_solver.cpp:172] Iteration 23100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:51:26.120424  5307 solver.cpp:352] Iteration 23200 (1.66728 iter/s, 59.978s/100 iter), 44.9/232ep, loss = 3.85392
I0510 18:51:26.120483  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.56861 (* 1 = 3.56861 loss)
I0510 18:51:26.120492  5307 sgd_solver.cpp:172] Iteration 23200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:52:00.375195  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 18:52:25.731971  5307 solver.cpp:352] Iteration 23300 (1.67756 iter/s, 59.6105s/100 iter), 45/232ep, loss = 3.81557
I0510 18:52:25.732010  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.45628 (* 1 = 3.45628 loss)
I0510 18:52:25.732020  5307 sgd_solver.cpp:172] Iteration 23300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:53:26.464812  5307 solver.cpp:352] Iteration 23400 (1.64658 iter/s, 60.7318s/100 iter), 45.2/232ep, loss = 3.80069
I0510 18:53:26.464896  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.2912 (* 1 = 3.2912 loss)
I0510 18:53:26.464906  5307 sgd_solver.cpp:172] Iteration 23400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:54:27.701195  5307 solver.cpp:352] Iteration 23500 (1.63304 iter/s, 61.2353s/100 iter), 45.4/232ep, loss = 3.89957
I0510 18:54:27.701269  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.27479 (* 1 = 3.27479 loss)
I0510 18:54:27.701277  5307 sgd_solver.cpp:172] Iteration 23500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:55:29.363590  5307 solver.cpp:352] Iteration 23600 (1.62176 iter/s, 61.6613s/100 iter), 45.6/232ep, loss = 4.05547
I0510 18:55:29.363911  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.68351 (* 1 = 4.68351 loss)
I0510 18:55:29.363940  5307 sgd_solver.cpp:172] Iteration 23600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:56:31.339885  5307 solver.cpp:352] Iteration 23700 (1.61355 iter/s, 61.9752s/100 iter), 45.8/232ep, loss = 3.94768
I0510 18:56:31.339956  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.78877 (* 1 = 3.78877 loss)
I0510 18:56:31.339964  5307 sgd_solver.cpp:172] Iteration 23700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:57:16.840919  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 18:57:32.433218  5307 solver.cpp:352] Iteration 23800 (1.63687 iter/s, 61.0923s/100 iter), 46/232ep, loss = 3.87
I0510 18:57:32.433284  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.22068 (* 1 = 4.22068 loss)
I0510 18:57:32.433292  5307 sgd_solver.cpp:172] Iteration 23800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:58:33.108304  5307 solver.cpp:352] Iteration 23900 (1.64815 iter/s, 60.674s/100 iter), 46.2/232ep, loss = 3.5852
I0510 18:58:33.108393  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.06789 (* 1 = 4.06789 loss)
I0510 18:58:33.108404  5307 sgd_solver.cpp:172] Iteration 23900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 18:59:33.702417  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_24000.caffemodel
I0510 18:59:33.715880  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_24000.solverstate
I0510 18:59:33.719976  5307 solver.cpp:635] Iteration 24000, Testing net (#0)
I0510 19:00:15.762233  5353 data_reader.cpp:320] Restarting data pre-fetching
I0510 19:00:15.999637  5307 solver.cpp:747] class AP 1: 0.484444
I0510 19:00:15.999975  5307 solver.cpp:747] class AP 2: 0.482623
I0510 19:00:16.003038  5307 solver.cpp:747] class AP 3: 0.351549
I0510 19:00:16.006753  5307 solver.cpp:747] class AP 4: 0.350077
I0510 19:00:16.033462  5307 solver.cpp:747] class AP 5: 0.213984
I0510 19:00:16.034142  5307 solver.cpp:747] class AP 6: 0.605831
I0510 19:00:16.040594  5307 solver.cpp:747] class AP 7: 0.574534
I0510 19:00:16.041268  5307 solver.cpp:747] class AP 8: 0.637335
I0510 19:00:16.059988  5307 solver.cpp:747] class AP 9: 0.269435
I0510 19:00:16.060272  5307 solver.cpp:747] class AP 10: 0.375766
I0510 19:00:16.061775  5307 solver.cpp:747] class AP 11: 0.40548
I0510 19:00:16.062548  5307 solver.cpp:747] class AP 12: 0.519061
I0510 19:00:16.062849  5307 solver.cpp:747] class AP 13: 0.527503
I0510 19:00:16.063004  5307 solver.cpp:747] class AP 14: 0.472097
I0510 19:00:16.124413  5307 solver.cpp:747] class AP 15: 0.617836
I0510 19:00:16.132398  5307 solver.cpp:747] class AP 16: 0.211552
I0510 19:00:16.133635  5307 solver.cpp:747] class AP 17: 0.336798
I0510 19:00:16.134557  5307 solver.cpp:747] class AP 18: 0.421108
I0510 19:00:16.135125  5307 solver.cpp:747] class AP 19: 0.594174
I0510 19:00:16.136035  5307 solver.cpp:747] class AP 20: 0.435553
I0510 19:00:16.136041  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.444337
I0510 19:00:16.136257  5307 solver.cpp:283] Tests completed in 103.026s
I0510 19:00:16.756871  5307 solver.cpp:352] Iteration 24000 (0.970627 iter/s, 103.026s/100 iter), 46.4/232ep, loss = 3.9067
I0510 19:00:16.756903  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.44319 (* 1 = 3.44319 loss)
I0510 19:00:16.756912  5307 sgd_solver.cpp:172] Iteration 24000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:01:17.363162  5307 solver.cpp:352] Iteration 24100 (1.65002 iter/s, 60.6052s/100 iter), 46.6/232ep, loss = 3.77663
I0510 19:01:17.363291  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.04249 (* 1 = 4.04249 loss)
I0510 19:01:17.363312  5307 sgd_solver.cpp:172] Iteration 24100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:02:18.204226  5307 solver.cpp:352] Iteration 24200 (1.64366 iter/s, 60.84s/100 iter), 46.8/232ep, loss = 3.9649
I0510 19:02:18.204455  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.57627 (* 1 = 3.57627 loss)
I0510 19:02:18.204466  5307 sgd_solver.cpp:172] Iteration 24200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:03:14.237166  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 19:03:19.448635  5307 solver.cpp:352] Iteration 24300 (1.63283 iter/s, 61.2433s/100 iter), 47/232ep, loss = 3.96085
I0510 19:03:19.448683  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.11814 (* 1 = 3.11814 loss)
I0510 19:03:19.448693  5307 sgd_solver.cpp:172] Iteration 24300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:04:19.763339  5307 solver.cpp:352] Iteration 24400 (1.658 iter/s, 60.3136s/100 iter), 47.2/232ep, loss = 3.78938
I0510 19:04:19.763430  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.58582 (* 1 = 3.58582 loss)
I0510 19:04:19.763447  5307 sgd_solver.cpp:172] Iteration 24400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:05:20.826309  5307 solver.cpp:352] Iteration 24500 (1.63768 iter/s, 61.0619s/100 iter), 47.4/232ep, loss = 3.86039
I0510 19:05:20.826555  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.19428 (* 1 = 3.19428 loss)
I0510 19:05:20.826565  5307 sgd_solver.cpp:172] Iteration 24500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:06:21.950335  5307 solver.cpp:352] Iteration 24600 (1.63605 iter/s, 61.1229s/100 iter), 47.6/232ep, loss = 3.78745
I0510 19:06:21.950456  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.91877 (* 1 = 4.91877 loss)
I0510 19:06:21.950484  5307 sgd_solver.cpp:172] Iteration 24600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:07:24.160080  5307 solver.cpp:352] Iteration 24700 (1.60749 iter/s, 62.2086s/100 iter), 47.8/232ep, loss = 3.66962
I0510 19:07:24.160152  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.87449 (* 1 = 3.87449 loss)
I0510 19:07:24.160161  5307 sgd_solver.cpp:172] Iteration 24700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:08:25.133620  5307 solver.cpp:352] Iteration 24800 (1.64009 iter/s, 60.9724s/100 iter), 47.9/232ep, loss = 3.65032
I0510 19:08:25.133761  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.49542 (* 1 = 3.49542 loss)
I0510 19:08:25.133775  5307 sgd_solver.cpp:172] Iteration 24800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:08:30.483697  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 19:09:26.062394  5307 solver.cpp:352] Iteration 24900 (1.64129 iter/s, 60.9277s/100 iter), 48.1/232ep, loss = 3.83275
I0510 19:09:26.062619  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.22737 (* 1 = 5.22737 loss)
I0510 19:09:26.062644  5307 sgd_solver.cpp:172] Iteration 24900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:10:27.073468  5307 solver.cpp:352] Iteration 25000 (1.63908 iter/s, 61.01s/100 iter), 48.3/232ep, loss = 4.03657
I0510 19:10:27.073570  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.51471 (* 1 = 3.51471 loss)
I0510 19:10:27.073578  5307 sgd_solver.cpp:172] Iteration 25000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:11:28.260156  5307 solver.cpp:352] Iteration 25100 (1.63437 iter/s, 61.1856s/100 iter), 48.5/232ep, loss = 3.5904
I0510 19:11:28.260237  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.638 (* 1 = 3.638 loss)
I0510 19:11:28.260244  5307 sgd_solver.cpp:172] Iteration 25100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:12:29.748556  5307 solver.cpp:352] Iteration 25200 (1.62635 iter/s, 61.4873s/100 iter), 48.7/232ep, loss = 3.85716
I0510 19:12:29.748668  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.36624 (* 1 = 3.36624 loss)
I0510 19:12:29.748684  5307 sgd_solver.cpp:172] Iteration 25200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:13:30.301437  5307 solver.cpp:352] Iteration 25300 (1.65148 iter/s, 60.5518s/100 iter), 48.9/232ep, loss = 3.68767
I0510 19:13:30.301498  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.43387 (* 1 = 3.43387 loss)
I0510 19:13:30.301506  5307 sgd_solver.cpp:172] Iteration 25300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:13:45.276093  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 19:14:29.971930  5307 solver.cpp:352] Iteration 25400 (1.6759 iter/s, 59.6694s/100 iter), 49.1/232ep, loss = 3.84171
I0510 19:14:29.972039  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.54642 (* 1 = 4.54642 loss)
I0510 19:14:29.972059  5307 sgd_solver.cpp:172] Iteration 25400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:15:30.884881  5307 solver.cpp:352] Iteration 25500 (1.64172 iter/s, 60.9119s/100 iter), 49.3/232ep, loss = 4.00768
I0510 19:15:30.884943  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.93366 (* 1 = 3.93366 loss)
I0510 19:15:30.884948  5307 sgd_solver.cpp:172] Iteration 25500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:16:30.960016  5307 solver.cpp:352] Iteration 25600 (1.66461 iter/s, 60.0741s/100 iter), 49.5/232ep, loss = 3.89147
I0510 19:16:30.960086  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.27457 (* 1 = 3.27457 loss)
I0510 19:16:30.960094  5307 sgd_solver.cpp:172] Iteration 25600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:17:31.220655  5307 solver.cpp:352] Iteration 25700 (1.65949 iter/s, 60.2596s/100 iter), 49.7/232ep, loss = 3.77153
I0510 19:17:31.222297  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.89295 (* 1 = 3.89295 loss)
I0510 19:17:31.222306  5307 sgd_solver.cpp:172] Iteration 25700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:18:31.005316  5307 solver.cpp:352] Iteration 25800 (1.6727 iter/s, 59.7836s/100 iter), 49.9/232ep, loss = 3.86166
I0510 19:18:31.005399  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.19522 (* 1 = 4.19522 loss)
I0510 19:18:31.005409  5307 sgd_solver.cpp:172] Iteration 25800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:18:57.666621  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 19:19:31.365808  5307 solver.cpp:352] Iteration 25900 (1.65674 iter/s, 60.3594s/100 iter), 50.1/232ep, loss = 3.97279
I0510 19:19:31.365890  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.03542 (* 1 = 4.03542 loss)
I0510 19:19:31.365897  5307 sgd_solver.cpp:172] Iteration 25900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:20:31.104477  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_26000.caffemodel
I0510 19:20:31.123970  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_26000.solverstate
I0510 19:20:31.131429  5307 solver.cpp:635] Iteration 26000, Testing net (#0)
I0510 19:21:12.665139  5353 data_reader.cpp:320] Restarting data pre-fetching
I0510 19:21:12.910117  5307 solver.cpp:747] class AP 1: 0.527658
I0510 19:21:12.910953  5307 solver.cpp:747] class AP 2: 0.58519
I0510 19:21:12.918699  5307 solver.cpp:747] class AP 3: 0.408892
I0510 19:21:12.925354  5307 solver.cpp:747] class AP 4: 0.323238
I0510 19:21:12.933722  5307 solver.cpp:747] class AP 5: 0.196721
I0510 19:21:12.934037  5307 solver.cpp:747] class AP 6: 0.601376
I0510 19:21:12.953480  5307 solver.cpp:747] class AP 7: 0.617601
I0510 19:21:12.954058  5307 solver.cpp:747] class AP 8: 0.655444
I0510 19:21:12.971992  5307 solver.cpp:747] class AP 9: 0.291683
I0510 19:21:12.972307  5307 solver.cpp:747] class AP 10: 0.440488
I0510 19:21:12.972625  5307 solver.cpp:747] class AP 11: 0.432128
I0510 19:21:12.973682  5307 solver.cpp:747] class AP 12: 0.558183
I0510 19:21:12.973996  5307 solver.cpp:747] class AP 13: 0.66504
I0510 19:21:12.974239  5307 solver.cpp:747] class AP 14: 0.63709
I0510 19:21:13.041898  5307 solver.cpp:747] class AP 15: 0.59983
I0510 19:21:13.044495  5307 solver.cpp:747] class AP 16: 0.20258
I0510 19:21:13.047165  5307 solver.cpp:747] class AP 17: 0.391476
I0510 19:21:13.048035  5307 solver.cpp:747] class AP 18: 0.391003
I0510 19:21:13.048532  5307 solver.cpp:747] class AP 19: 0.637381
I0510 19:21:13.049194  5307 solver.cpp:747] class AP 20: 0.471418
I0510 19:21:13.049202  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.481721
I0510 19:21:13.049327  5307 solver.cpp:283] Tests completed in 101.682s
I0510 19:21:13.606369  5307 solver.cpp:352] Iteration 26000 (0.983461 iter/s, 101.682s/100 iter), 50.3/232ep, loss = 3.93858
I0510 19:21:13.606431  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.02108 (* 1 = 4.02108 loss)
I0510 19:21:13.606443  5307 sgd_solver.cpp:172] Iteration 26000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:22:16.320257  5307 solver.cpp:352] Iteration 26100 (1.59457 iter/s, 62.7127s/100 iter), 50.5/232ep, loss = 3.82841
I0510 19:22:16.320799  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.68787 (* 1 = 3.68787 loss)
I0510 19:22:16.320818  5307 sgd_solver.cpp:172] Iteration 26100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:23:24.497467  5307 solver.cpp:352] Iteration 26200 (1.46679 iter/s, 68.176s/100 iter), 50.7/232ep, loss = 3.76185
I0510 19:23:24.497622  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.67768 (* 1 = 3.67768 loss)
I0510 19:23:24.497642  5307 sgd_solver.cpp:172] Iteration 26200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:24:25.847491  5307 solver.cpp:352] Iteration 26300 (1.63002 iter/s, 61.3489s/100 iter), 50.8/232ep, loss = 3.94741
I0510 19:24:25.847573  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.27126 (* 1 = 4.27126 loss)
I0510 19:24:25.847581  5307 sgd_solver.cpp:172] Iteration 26300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:25:02.195729  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 19:25:25.784054  5307 solver.cpp:352] Iteration 26400 (1.66846 iter/s, 59.9355s/100 iter), 51/232ep, loss = 3.76409
I0510 19:25:25.784085  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.58813 (* 1 = 4.58813 loss)
I0510 19:25:25.784093  5307 sgd_solver.cpp:172] Iteration 26400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:26:26.028339  5307 solver.cpp:352] Iteration 26500 (1.65994 iter/s, 60.2432s/100 iter), 51.2/232ep, loss = 3.84718
I0510 19:26:26.028415  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.04022 (* 1 = 4.04022 loss)
I0510 19:26:26.028424  5307 sgd_solver.cpp:172] Iteration 26500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:27:27.105324  5307 solver.cpp:352] Iteration 26600 (1.63731 iter/s, 61.0759s/100 iter), 51.4/232ep, loss = 3.73108
I0510 19:27:27.105420  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.22452 (* 1 = 3.22452 loss)
I0510 19:27:27.105428  5307 sgd_solver.cpp:172] Iteration 26600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:28:27.265174  5307 solver.cpp:352] Iteration 26700 (1.66227 iter/s, 60.1588s/100 iter), 51.6/232ep, loss = 3.73865
I0510 19:28:27.265241  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.65277 (* 1 = 3.65277 loss)
I0510 19:28:27.265247  5307 sgd_solver.cpp:172] Iteration 26700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:29:27.365866  5307 solver.cpp:352] Iteration 26800 (1.6639 iter/s, 60.0996s/100 iter), 51.8/232ep, loss = 3.82671
I0510 19:29:27.365945  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.49587 (* 1 = 4.49587 loss)
I0510 19:29:27.365955  5307 sgd_solver.cpp:172] Iteration 26800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:30:13.481175  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 19:30:27.466990  5307 solver.cpp:352] Iteration 26900 (1.66389 iter/s, 60.1s/100 iter), 52/232ep, loss = 3.72676
I0510 19:30:27.467074  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.70798 (* 1 = 3.70798 loss)
I0510 19:30:27.467095  5307 sgd_solver.cpp:172] Iteration 26900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:31:27.867920  5307 solver.cpp:352] Iteration 27000 (1.65563 iter/s, 60.3998s/100 iter), 52.2/232ep, loss = 3.60723
I0510 19:31:27.868335  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.30788 (* 1 = 3.30788 loss)
I0510 19:31:27.868350  5307 sgd_solver.cpp:172] Iteration 27000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:32:27.997393  5307 solver.cpp:352] Iteration 27100 (1.66311 iter/s, 60.1284s/100 iter), 52.4/232ep, loss = 3.60799
I0510 19:32:27.998000  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.05221 (* 1 = 3.05221 loss)
I0510 19:32:27.998009  5307 sgd_solver.cpp:172] Iteration 27100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:33:28.887500  5307 solver.cpp:352] Iteration 27200 (1.64233 iter/s, 60.889s/100 iter), 52.6/232ep, loss = 3.85192
I0510 19:33:28.887666  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.21449 (* 1 = 4.21449 loss)
I0510 19:33:28.887676  5307 sgd_solver.cpp:172] Iteration 27200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:34:29.287021  5307 solver.cpp:352] Iteration 27300 (1.65567 iter/s, 60.3984s/100 iter), 52.8/232ep, loss = 3.80451
I0510 19:34:29.290815  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.61041 (* 1 = 3.61041 loss)
I0510 19:34:29.290830  5307 sgd_solver.cpp:172] Iteration 27300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:35:27.106932  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 19:35:30.255291  5307 solver.cpp:352] Iteration 27400 (1.64023 iter/s, 60.9672s/100 iter), 53/232ep, loss = 3.9971
I0510 19:35:30.255317  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.47735 (* 1 = 3.47735 loss)
I0510 19:35:30.255324  5307 sgd_solver.cpp:172] Iteration 27400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:36:30.755306  5307 solver.cpp:352] Iteration 27500 (1.65292 iter/s, 60.4989s/100 iter), 53.2/232ep, loss = 3.76978
I0510 19:36:30.755390  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.83909 (* 1 = 3.83909 loss)
I0510 19:36:30.755400  5307 sgd_solver.cpp:172] Iteration 27500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:37:31.814741  5307 solver.cpp:352] Iteration 27600 (1.63778 iter/s, 61.0584s/100 iter), 53.4/232ep, loss = 3.97396
I0510 19:37:31.814800  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.91227 (* 1 = 3.91227 loss)
I0510 19:37:31.814810  5307 sgd_solver.cpp:172] Iteration 27600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:38:32.215876  5307 solver.cpp:352] Iteration 27700 (1.65563 iter/s, 60.4001s/100 iter), 53.6/232ep, loss = 3.80746
I0510 19:38:32.215960  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.0961 (* 1 = 4.0961 loss)
I0510 19:38:32.215975  5307 sgd_solver.cpp:172] Iteration 27700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:39:32.541234  5307 solver.cpp:352] Iteration 27800 (1.65771 iter/s, 60.3243s/100 iter), 53.7/232ep, loss = 3.68896
I0510 19:39:32.541684  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.45826 (* 1 = 3.45826 loss)
I0510 19:39:32.541694  5307 sgd_solver.cpp:172] Iteration 27800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:40:32.999799  5307 solver.cpp:352] Iteration 27900 (1.65406 iter/s, 60.4575s/100 iter), 53.9/232ep, loss = 3.7588
I0510 19:40:33.000018  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.83248 (* 1 = 4.83248 loss)
I0510 19:40:33.000042  5307 sgd_solver.cpp:172] Iteration 27900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:40:39.858031  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 19:41:32.854823  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_28000.caffemodel
I0510 19:41:32.869741  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_28000.solverstate
I0510 19:41:32.875227  5307 solver.cpp:635] Iteration 28000, Testing net (#0)
I0510 19:42:13.878679  5353 data_reader.cpp:320] Restarting data pre-fetching
I0510 19:42:14.101833  5307 solver.cpp:747] class AP 1: 0.447821
I0510 19:42:14.102130  5307 solver.cpp:747] class AP 2: 0.514945
I0510 19:42:14.110472  5307 solver.cpp:747] class AP 3: 0.332307
I0510 19:42:14.113862  5307 solver.cpp:747] class AP 4: 0.276696
I0510 19:42:14.147543  5307 solver.cpp:747] class AP 5: 0.218325
I0510 19:42:14.147663  5307 solver.cpp:747] class AP 6: 0.566076
I0510 19:42:14.150702  5307 solver.cpp:747] class AP 7: 0.520006
I0510 19:42:14.151751  5307 solver.cpp:747] class AP 8: 0.57054
I0510 19:42:14.180486  5307 solver.cpp:747] class AP 9: 0.224394
I0510 19:42:14.181216  5307 solver.cpp:747] class AP 10: 0.335236
I0510 19:42:14.183318  5307 solver.cpp:747] class AP 11: 0.356538
I0510 19:42:14.184463  5307 solver.cpp:747] class AP 12: 0.474195
I0510 19:42:14.184739  5307 solver.cpp:747] class AP 13: 0.507128
I0510 19:42:14.184957  5307 solver.cpp:747] class AP 14: 0.516949
I0510 19:42:14.219790  5307 solver.cpp:747] class AP 15: 0.595535
I0510 19:42:14.231107  5307 solver.cpp:747] class AP 16: 0.219246
I0510 19:42:14.232429  5307 solver.cpp:747] class AP 17: 0.385486
I0510 19:42:14.233534  5307 solver.cpp:747] class AP 18: 0.332484
I0510 19:42:14.233866  5307 solver.cpp:747] class AP 19: 0.542427
I0510 19:42:14.234956  5307 solver.cpp:747] class AP 20: 0.421216
I0510 19:42:14.234963  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.417878
I0510 19:42:14.235227  5307 solver.cpp:283] Tests completed in 101.234s
I0510 19:42:14.854811  5307 solver.cpp:352] Iteration 28000 (0.987813 iter/s, 101.234s/100 iter), 54.1/232ep, loss = 3.52533
I0510 19:42:14.854843  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.06378 (* 1 = 4.06378 loss)
I0510 19:42:14.854853  5307 sgd_solver.cpp:172] Iteration 28000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:43:15.252923  5307 solver.cpp:352] Iteration 28100 (1.65571 iter/s, 60.397s/100 iter), 54.3/232ep, loss = 3.81855
I0510 19:43:15.253015  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.67796 (* 1 = 3.67796 loss)
I0510 19:43:15.253027  5307 sgd_solver.cpp:172] Iteration 28100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:44:15.360148  5307 solver.cpp:352] Iteration 28200 (1.66372 iter/s, 60.1062s/100 iter), 54.5/232ep, loss = 3.75696
I0510 19:44:15.360235  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.11185 (* 1 = 4.11185 loss)
I0510 19:44:15.360249  5307 sgd_solver.cpp:172] Iteration 28200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:45:16.344228  5307 solver.cpp:352] Iteration 28300 (1.6398 iter/s, 60.983s/100 iter), 54.7/232ep, loss = 3.74448
I0510 19:45:16.344310  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.81193 (* 1 = 3.81193 loss)
I0510 19:45:16.344317  5307 sgd_solver.cpp:172] Iteration 28300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:46:16.309695  5307 solver.cpp:352] Iteration 28400 (1.66766 iter/s, 59.9644s/100 iter), 54.9/232ep, loss = 3.7683
I0510 19:46:16.309792  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.79755 (* 1 = 3.79755 loss)
I0510 19:46:16.309808  5307 sgd_solver.cpp:172] Iteration 28400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:46:33.785228  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 19:47:16.645256  5307 solver.cpp:352] Iteration 28500 (1.65743 iter/s, 60.3345s/100 iter), 55.1/232ep, loss = 3.87838
I0510 19:47:16.645334  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.06779 (* 1 = 3.06779 loss)
I0510 19:47:16.645344  5307 sgd_solver.cpp:172] Iteration 28500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:48:16.931111  5307 solver.cpp:352] Iteration 28600 (1.65879 iter/s, 60.2848s/100 iter), 55.3/232ep, loss = 3.7845
I0510 19:48:16.931172  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.90429 (* 1 = 3.90429 loss)
I0510 19:48:16.931180  5307 sgd_solver.cpp:172] Iteration 28600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:49:17.907735  5307 solver.cpp:352] Iteration 28700 (1.64 iter/s, 60.9755s/100 iter), 55.5/232ep, loss = 3.6071
I0510 19:49:17.907867  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.59682 (* 1 = 3.59682 loss)
I0510 19:49:17.907881  5307 sgd_solver.cpp:172] Iteration 28700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:50:18.755187  5307 solver.cpp:352] Iteration 28800 (1.64348 iter/s, 60.8463s/100 iter), 55.7/232ep, loss = 3.75675
I0510 19:50:18.755365  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.5903 (* 1 = 3.5903 loss)
I0510 19:50:18.755391  5307 sgd_solver.cpp:172] Iteration 28800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:51:19.042055  5307 solver.cpp:352] Iteration 28900 (1.65877 iter/s, 60.2858s/100 iter), 55.9/232ep, loss = 3.71257
I0510 19:51:19.042114  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.48781 (* 1 = 4.48781 loss)
I0510 19:51:19.042121  5307 sgd_solver.cpp:172] Iteration 28900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:51:47.191911  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 19:52:19.624878  5307 solver.cpp:352] Iteration 29000 (1.65066 iter/s, 60.5817s/100 iter), 56.1/232ep, loss = 3.67674
I0510 19:52:19.625249  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.87256 (* 1 = 3.87256 loss)
I0510 19:52:19.625259  5307 sgd_solver.cpp:172] Iteration 29000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:53:20.396816  5307 solver.cpp:352] Iteration 29100 (1.64553 iter/s, 60.7708s/100 iter), 56.3/232ep, loss = 3.99434
I0510 19:53:20.396867  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.8691 (* 1 = 3.8691 loss)
I0510 19:53:20.396876  5307 sgd_solver.cpp:172] Iteration 29100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:54:20.580611  5307 solver.cpp:352] Iteration 29200 (1.66161 iter/s, 60.1827s/100 iter), 56.5/232ep, loss = 3.78493
I0510 19:54:20.580708  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.06183 (* 1 = 4.06183 loss)
I0510 19:54:20.580732  5307 sgd_solver.cpp:172] Iteration 29200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:55:20.472167  5307 solver.cpp:352] Iteration 29300 (1.66971 iter/s, 59.8905s/100 iter), 56.6/232ep, loss = 3.62764
I0510 19:55:20.472227  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.31053 (* 1 = 3.31053 loss)
I0510 19:55:20.472235  5307 sgd_solver.cpp:172] Iteration 29300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:56:21.429445  5307 solver.cpp:352] Iteration 29400 (1.64052 iter/s, 60.9562s/100 iter), 56.8/232ep, loss = 3.77345
I0510 19:56:21.429524  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.61489 (* 1 = 3.61489 loss)
I0510 19:56:21.429533  5307 sgd_solver.cpp:172] Iteration 29400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:56:59.462847  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 19:57:22.076934  5307 solver.cpp:352] Iteration 29500 (1.6489 iter/s, 60.6464s/100 iter), 57/232ep, loss = 3.6652
I0510 19:57:22.076967  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.40196 (* 1 = 3.40196 loss)
I0510 19:57:22.076977  5307 sgd_solver.cpp:172] Iteration 29500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:58:22.610980  5307 solver.cpp:352] Iteration 29600 (1.65199 iter/s, 60.533s/100 iter), 57.2/232ep, loss = 3.70211
I0510 19:58:22.611089  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.43717 (* 1 = 3.43717 loss)
I0510 19:58:22.611099  5307 sgd_solver.cpp:172] Iteration 29600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 19:59:22.832132  5307 solver.cpp:352] Iteration 29700 (1.66058 iter/s, 60.2201s/100 iter), 57.4/232ep, loss = 3.74542
I0510 19:59:22.835464  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.23196 (* 1 = 4.23196 loss)
I0510 19:59:22.835556  5307 sgd_solver.cpp:172] Iteration 29700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:00:23.247373  5307 solver.cpp:352] Iteration 29800 (1.65524 iter/s, 60.4142s/100 iter), 57.6/232ep, loss = 3.74278
I0510 20:00:23.247465  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.83845 (* 1 = 3.83845 loss)
I0510 20:00:23.247474  5307 sgd_solver.cpp:172] Iteration 29800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:01:24.044986  5307 solver.cpp:352] Iteration 29900 (1.64483 iter/s, 60.7965s/100 iter), 57.8/232ep, loss = 3.6145
I0510 20:01:24.045045  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.74996 (* 1 = 2.74996 loss)
I0510 20:01:24.045053  5307 sgd_solver.cpp:172] Iteration 29900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:02:12.929261  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 20:02:23.974081  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_30000.caffemodel
I0510 20:02:23.993046  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_30000.solverstate
I0510 20:02:23.999919  5307 solver.cpp:635] Iteration 30000, Testing net (#0)
I0510 20:03:05.099125  5353 data_reader.cpp:320] Restarting data pre-fetching
I0510 20:03:05.335094  5307 solver.cpp:747] class AP 1: 0.49288
I0510 20:03:05.335618  5307 solver.cpp:747] class AP 2: 0.572298
I0510 20:03:05.351456  5307 solver.cpp:747] class AP 3: 0.411125
I0510 20:03:05.354663  5307 solver.cpp:747] class AP 4: 0.283815
I0510 20:03:05.369340  5307 solver.cpp:747] class AP 5: 0.159748
I0510 20:03:05.369539  5307 solver.cpp:747] class AP 6: 0.57257
I0510 20:03:05.377823  5307 solver.cpp:747] class AP 7: 0.55566
I0510 20:03:05.378362  5307 solver.cpp:747] class AP 8: 0.604174
I0510 20:03:05.393599  5307 solver.cpp:747] class AP 9: 0.217753
I0510 20:03:05.394135  5307 solver.cpp:747] class AP 10: 0.400134
I0510 20:03:05.394649  5307 solver.cpp:747] class AP 11: 0.429815
I0510 20:03:05.396200  5307 solver.cpp:747] class AP 12: 0.544543
I0510 20:03:05.396452  5307 solver.cpp:747] class AP 13: 0.672034
I0510 20:03:05.396749  5307 solver.cpp:747] class AP 14: 0.587423
I0510 20:03:05.454797  5307 solver.cpp:747] class AP 15: 0.603451
I0510 20:03:05.464190  5307 solver.cpp:747] class AP 16: 0.160115
I0510 20:03:05.465623  5307 solver.cpp:747] class AP 17: 0.407475
I0510 20:03:05.465979  5307 solver.cpp:747] class AP 18: 0.364085
I0510 20:03:05.466434  5307 solver.cpp:747] class AP 19: 0.563487
I0510 20:03:05.467962  5307 solver.cpp:747] class AP 20: 0.370664
I0510 20:03:05.467970  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.448662
I0510 20:03:05.468106  5307 solver.cpp:283] Tests completed in 101.421s
I0510 20:03:06.032670  5307 solver.cpp:352] Iteration 30000 (0.985986 iter/s, 101.421s/100 iter), 58/232ep, loss = 3.82731
I0510 20:03:06.032719  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.5366 (* 1 = 3.5366 loss)
I0510 20:03:06.032733  5307 sgd_solver.cpp:172] Iteration 30000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:04:06.726922  5307 solver.cpp:352] Iteration 30100 (1.64763 iter/s, 60.6932s/100 iter), 58.2/232ep, loss = 3.74437
I0510 20:04:06.726979  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.78703 (* 1 = 3.78703 loss)
I0510 20:04:06.726985  5307 sgd_solver.cpp:172] Iteration 30100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:05:07.274248  5307 solver.cpp:352] Iteration 30200 (1.65163 iter/s, 60.5462s/100 iter), 58.4/232ep, loss = 3.47742
I0510 20:05:07.274332  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.05092 (* 1 = 4.05092 loss)
I0510 20:05:07.274341  5307 sgd_solver.cpp:172] Iteration 30200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:06:08.827862  5307 solver.cpp:352] Iteration 30300 (1.62463 iter/s, 61.5525s/100 iter), 58.6/232ep, loss = 3.77468
I0510 20:06:08.827973  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.50115 (* 1 = 3.50115 loss)
I0510 20:06:08.827985  5307 sgd_solver.cpp:172] Iteration 30300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:07:10.170852  5307 solver.cpp:352] Iteration 30400 (1.63021 iter/s, 61.3419s/100 iter), 58.8/232ep, loss = 3.64959
I0510 20:07:10.170904  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.96388 (* 1 = 2.96388 loss)
I0510 20:07:10.170913  5307 sgd_solver.cpp:172] Iteration 30400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:08:10.422246  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 20:08:12.163167  5307 solver.cpp:352] Iteration 30500 (1.61313 iter/s, 61.9912s/100 iter), 59/232ep, loss = 3.95137
I0510 20:08:12.163193  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.71779 (* 1 = 4.71779 loss)
I0510 20:08:12.163203  5307 sgd_solver.cpp:172] Iteration 30500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:09:13.321945  5307 solver.cpp:352] Iteration 30600 (1.63512 iter/s, 61.1576s/100 iter), 59.2/232ep, loss = 3.72914
I0510 20:09:13.322137  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.10117 (* 1 = 4.10117 loss)
I0510 20:09:13.322167  5307 sgd_solver.cpp:172] Iteration 30600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:10:14.789160  5307 solver.cpp:352] Iteration 30700 (1.62691 iter/s, 61.4662s/100 iter), 59.4/232ep, loss = 3.80969
I0510 20:10:14.789242  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.44581 (* 1 = 4.44581 loss)
I0510 20:10:14.789257  5307 sgd_solver.cpp:172] Iteration 30700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:11:16.550231  5307 solver.cpp:352] Iteration 30800 (1.61917 iter/s, 61.76s/100 iter), 59.5/232ep, loss = 3.63191
I0510 20:11:16.551460  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.36055 (* 1 = 4.36055 loss)
I0510 20:11:16.551486  5307 sgd_solver.cpp:172] Iteration 30800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:12:16.602501  5307 solver.cpp:352] Iteration 30900 (1.66524 iter/s, 60.0513s/100 iter), 59.7/232ep, loss = 3.7639
I0510 20:12:16.602596  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.01655 (* 1 = 3.01655 loss)
I0510 20:12:16.602603  5307 sgd_solver.cpp:172] Iteration 30900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:13:16.543359  5307 solver.cpp:352] Iteration 31000 (1.66834 iter/s, 59.9398s/100 iter), 59.9/232ep, loss = 3.63295
I0510 20:13:16.543452  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.37379 (* 1 = 3.37379 loss)
I0510 20:13:16.543471  5307 sgd_solver.cpp:172] Iteration 31000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:13:25.537050  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 20:14:16.204613  5307 solver.cpp:352] Iteration 31100 (1.67616 iter/s, 59.6602s/100 iter), 60.1/232ep, loss = 3.72176
I0510 20:14:16.204711  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.31073 (* 1 = 3.31073 loss)
I0510 20:14:16.204720  5307 sgd_solver.cpp:172] Iteration 31100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:15:16.277683  5307 solver.cpp:352] Iteration 31200 (1.66467 iter/s, 60.072s/100 iter), 60.3/232ep, loss = 3.58337
I0510 20:15:16.278057  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.95243 (* 1 = 3.95243 loss)
I0510 20:15:16.278071  5307 sgd_solver.cpp:172] Iteration 31200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:16:17.477808  5307 solver.cpp:352] Iteration 31300 (1.63401 iter/s, 61.1991s/100 iter), 60.5/232ep, loss = 3.7103
I0510 20:16:17.477916  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.55529 (* 1 = 2.55529 loss)
I0510 20:16:17.477927  5307 sgd_solver.cpp:172] Iteration 31300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:17:18.232285  5307 solver.cpp:352] Iteration 31400 (1.646 iter/s, 60.7534s/100 iter), 60.7/232ep, loss = 3.75925
I0510 20:17:18.232393  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.36327 (* 1 = 4.36327 loss)
I0510 20:17:18.232416  5307 sgd_solver.cpp:172] Iteration 31400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:18:19.069918  5307 solver.cpp:352] Iteration 31500 (1.64375 iter/s, 60.8366s/100 iter), 60.9/232ep, loss = 3.53607
I0510 20:18:19.069981  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.8967 (* 1 = 2.8967 loss)
I0510 20:18:19.069990  5307 sgd_solver.cpp:172] Iteration 31500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:18:39.256943  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 20:19:19.638444  5307 solver.cpp:352] Iteration 31600 (1.65105 iter/s, 60.5675s/100 iter), 61.1/232ep, loss = 3.67042
I0510 20:19:19.638500  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.80708 (* 1 = 2.80708 loss)
I0510 20:19:19.638509  5307 sgd_solver.cpp:172] Iteration 31600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:20:21.356631  5307 solver.cpp:352] Iteration 31700 (1.6203 iter/s, 61.7171s/100 iter), 61.3/232ep, loss = 3.81229
I0510 20:20:21.357816  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.15715 (* 1 = 4.15715 loss)
I0510 20:20:21.357830  5307 sgd_solver.cpp:172] Iteration 31700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:21:22.677747  5307 solver.cpp:352] Iteration 31800 (1.63079 iter/s, 61.3201s/100 iter), 61.5/232ep, loss = 3.76929
I0510 20:21:22.677806  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.08326 (* 1 = 3.08326 loss)
I0510 20:21:22.677814  5307 sgd_solver.cpp:172] Iteration 31800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:22:24.012138  5307 solver.cpp:352] Iteration 31900 (1.63043 iter/s, 61.3333s/100 iter), 61.7/232ep, loss = 3.64278
I0510 20:22:24.012224  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.62073 (* 1 = 3.62073 loss)
I0510 20:22:24.012233  5307 sgd_solver.cpp:172] Iteration 31900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:23:25.565407  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_32000.caffemodel
I0510 20:23:25.587774  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_32000.solverstate
I0510 20:23:25.595491  5307 solver.cpp:635] Iteration 32000, Testing net (#0)
I0510 20:23:31.821794  5352 blocking_queue.cpp:40] Data layer prefetch queue empty
I0510 20:24:06.804874  5353 data_reader.cpp:320] Restarting data pre-fetching
I0510 20:24:07.037050  5307 solver.cpp:747] class AP 1: 0.526383
I0510 20:24:07.037438  5307 solver.cpp:747] class AP 2: 0.635977
I0510 20:24:07.048976  5307 solver.cpp:747] class AP 3: 0.399524
I0510 20:24:07.051331  5307 solver.cpp:747] class AP 4: 0.347869
I0510 20:24:07.067064  5307 solver.cpp:747] class AP 5: 0.256745
I0510 20:24:07.067379  5307 solver.cpp:747] class AP 6: 0.649957
I0510 20:24:07.072592  5307 solver.cpp:747] class AP 7: 0.617347
I0510 20:24:07.073444  5307 solver.cpp:747] class AP 8: 0.690625
I0510 20:24:07.097751  5307 solver.cpp:747] class AP 9: 0.335321
I0510 20:24:07.098278  5307 solver.cpp:747] class AP 10: 0.517511
I0510 20:24:07.099396  5307 solver.cpp:747] class AP 11: 0.472751
I0510 20:24:07.100687  5307 solver.cpp:747] class AP 12: 0.596647
I0510 20:24:07.100947  5307 solver.cpp:747] class AP 13: 0.676235
I0510 20:24:07.101212  5307 solver.cpp:747] class AP 14: 0.649562
I0510 20:24:07.157392  5307 solver.cpp:747] class AP 15: 0.64047
I0510 20:24:07.162349  5307 solver.cpp:747] class AP 16: 0.223401
I0510 20:24:07.165511  5307 solver.cpp:747] class AP 17: 0.496675
I0510 20:24:07.166776  5307 solver.cpp:747] class AP 18: 0.510274
I0510 20:24:07.167563  5307 solver.cpp:747] class AP 19: 0.621777
I0510 20:24:07.168772  5307 solver.cpp:747] class AP 20: 0.474429
I0510 20:24:07.168787  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.516974
I0510 20:24:07.169006  5307 solver.cpp:283] Tests completed in 103.155s
I0510 20:24:07.804672  5307 solver.cpp:352] Iteration 32000 (0.969414 iter/s, 103.155s/100 iter), 61.9/232ep, loss = 3.62977
I0510 20:24:07.804797  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.35768 (* 1 = 3.35768 loss)
I0510 20:24:07.804810  5307 sgd_solver.cpp:172] Iteration 32000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:24:38.469461  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 20:25:10.240434  5307 solver.cpp:352] Iteration 32100 (1.60168 iter/s, 62.4346s/100 iter), 62.1/232ep, loss = 3.66677
I0510 20:25:10.240602  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.87714 (* 1 = 3.87714 loss)
I0510 20:25:10.240623  5307 sgd_solver.cpp:172] Iteration 32100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:26:11.415913  5307 solver.cpp:352] Iteration 32200 (1.63467 iter/s, 61.1744s/100 iter), 62.3/232ep, loss = 3.86129
I0510 20:26:11.416028  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.7976 (* 1 = 3.7976 loss)
I0510 20:26:11.416046  5307 sgd_solver.cpp:172] Iteration 32200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:27:13.032047  5307 solver.cpp:352] Iteration 32300 (1.62298 iter/s, 61.6151s/100 iter), 62.4/232ep, loss = 3.80358
I0510 20:27:13.032133  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.5296 (* 1 = 3.5296 loss)
I0510 20:27:13.032150  5307 sgd_solver.cpp:172] Iteration 32300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:28:13.966925  5307 solver.cpp:352] Iteration 32400 (1.64113 iter/s, 60.9338s/100 iter), 62.6/232ep, loss = 3.76398
I0510 20:28:13.967087  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.43466 (* 1 = 4.43466 loss)
I0510 20:28:13.967106  5307 sgd_solver.cpp:172] Iteration 32400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:29:14.266544  5307 solver.cpp:352] Iteration 32500 (1.65841 iter/s, 60.2986s/100 iter), 62.8/232ep, loss = 3.84687
I0510 20:29:14.267472  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.96284 (* 1 = 3.96284 loss)
I0510 20:29:14.267482  5307 sgd_solver.cpp:172] Iteration 32500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:29:55.900570  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 20:30:19.120484  5307 solver.cpp:352] Iteration 32600 (1.54195 iter/s, 64.8528s/100 iter), 63/232ep, loss = 3.61782
I0510 20:30:19.120555  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.3348 (* 1 = 3.3348 loss)
I0510 20:30:19.120576  5307 sgd_solver.cpp:172] Iteration 32600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:31:27.233445  5307 solver.cpp:352] Iteration 32700 (1.46818 iter/s, 68.1118s/100 iter), 63.2/232ep, loss = 3.76131
I0510 20:31:27.233536  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.97666 (* 1 = 3.97666 loss)
I0510 20:31:27.233542  5307 sgd_solver.cpp:172] Iteration 32700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:32:27.301883  5307 solver.cpp:352] Iteration 32800 (1.6648 iter/s, 60.0674s/100 iter), 63.4/232ep, loss = 3.6275
I0510 20:32:27.302006  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.93594 (* 1 = 2.93594 loss)
I0510 20:32:27.302021  5307 sgd_solver.cpp:172] Iteration 32800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:33:28.381314  5307 solver.cpp:352] Iteration 32900 (1.63724 iter/s, 61.0784s/100 iter), 63.6/232ep, loss = 3.75429
I0510 20:33:28.382957  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.38282 (* 1 = 4.38282 loss)
I0510 20:33:28.382968  5307 sgd_solver.cpp:172] Iteration 32900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:34:28.517973  5307 solver.cpp:352] Iteration 33000 (1.66291 iter/s, 60.1356s/100 iter), 63.8/232ep, loss = 3.79048
I0510 20:34:28.518059  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.23225 (* 1 = 4.23225 loss)
I0510 20:34:28.518067  5307 sgd_solver.cpp:172] Iteration 33000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:35:18.557407  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 20:35:28.267971  5307 solver.cpp:352] Iteration 33100 (1.67367 iter/s, 59.749s/100 iter), 64/232ep, loss = 3.6645
I0510 20:35:28.267993  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.03611 (* 1 = 3.03611 loss)
I0510 20:35:28.267999  5307 sgd_solver.cpp:172] Iteration 33100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:36:29.240681  5307 solver.cpp:352] Iteration 33200 (1.64011 iter/s, 60.9717s/100 iter), 64.2/232ep, loss = 3.70925
I0510 20:36:29.240780  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.69101 (* 1 = 3.69101 loss)
I0510 20:36:29.240792  5307 sgd_solver.cpp:172] Iteration 33200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:37:29.509500  5307 solver.cpp:352] Iteration 33300 (1.65926 iter/s, 60.2678s/100 iter), 64.4/232ep, loss = 3.64561
I0510 20:37:29.512552  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.32793 (* 1 = 3.32793 loss)
I0510 20:37:29.512594  5307 sgd_solver.cpp:172] Iteration 33300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:38:30.920509  5307 solver.cpp:352] Iteration 33400 (1.6284 iter/s, 61.41s/100 iter), 64.6/232ep, loss = 3.73497
I0510 20:38:30.920578  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.27622 (* 1 = 4.27622 loss)
I0510 20:38:30.920588  5307 sgd_solver.cpp:172] Iteration 33400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:39:32.842433  5307 solver.cpp:352] Iteration 33500 (1.61496 iter/s, 61.9209s/100 iter), 64.8/232ep, loss = 3.82568
I0510 20:39:32.842490  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.13622 (* 1 = 4.13622 loss)
I0510 20:39:32.842499  5307 sgd_solver.cpp:172] Iteration 33500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:40:33.841985  5307 solver.cpp:352] Iteration 33600 (1.63938 iter/s, 60.9985s/100 iter), 65/232ep, loss = 3.69743
I0510 20:40:33.842221  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.75096 (* 1 = 3.75096 loss)
I0510 20:40:33.842247  5307 sgd_solver.cpp:172] Iteration 33600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:40:34.609417  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 20:41:35.916772  5307 solver.cpp:352] Iteration 33700 (1.61099 iter/s, 62.0737s/100 iter), 65.2/232ep, loss = 3.8023
I0510 20:41:35.916874  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.88991 (* 1 = 3.88991 loss)
I0510 20:41:35.916884  5307 sgd_solver.cpp:172] Iteration 33700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:42:36.419731  5307 solver.cpp:352] Iteration 33800 (1.65284 iter/s, 60.5019s/100 iter), 65.3/232ep, loss = 3.567
I0510 20:42:36.419812  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.4897 (* 1 = 3.4897 loss)
I0510 20:42:36.419819  5307 sgd_solver.cpp:172] Iteration 33800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:43:36.926913  5307 solver.cpp:352] Iteration 33900 (1.65272 iter/s, 60.5061s/100 iter), 65.5/232ep, loss = 3.61852
I0510 20:43:36.929528  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.40645 (* 1 = 3.40645 loss)
I0510 20:43:36.929539  5307 sgd_solver.cpp:172] Iteration 33900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:44:37.329893  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_34000.caffemodel
I0510 20:44:37.345214  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_34000.solverstate
I0510 20:44:37.350540  5307 solver.cpp:635] Iteration 34000, Testing net (#0)
I0510 20:45:18.248383  5353 data_reader.cpp:320] Restarting data pre-fetching
I0510 20:45:18.483002  5307 solver.cpp:747] class AP 1: 0.468396
I0510 20:45:18.484258  5307 solver.cpp:747] class AP 2: 0.505179
I0510 20:45:18.489697  5307 solver.cpp:747] class AP 3: 0.354221
I0510 20:45:18.493027  5307 solver.cpp:747] class AP 4: 0.355639
I0510 20:45:18.514153  5307 solver.cpp:747] class AP 5: 0.19221
I0510 20:45:18.514439  5307 solver.cpp:747] class AP 6: 0.58785
I0510 20:45:18.519455  5307 solver.cpp:747] class AP 7: 0.56004
I0510 20:45:18.519934  5307 solver.cpp:747] class AP 8: 0.604614
I0510 20:45:18.549664  5307 solver.cpp:747] class AP 9: 0.315277
I0510 20:45:18.549860  5307 solver.cpp:747] class AP 10: 0.427041
I0510 20:45:18.550740  5307 solver.cpp:747] class AP 11: 0.436946
I0510 20:45:18.551120  5307 solver.cpp:747] class AP 12: 0.507325
I0510 20:45:18.551321  5307 solver.cpp:747] class AP 13: 0.552242
I0510 20:45:18.551616  5307 solver.cpp:747] class AP 14: 0.531344
I0510 20:45:18.596168  5307 solver.cpp:747] class AP 15: 0.593803
I0510 20:45:18.613611  5307 solver.cpp:747] class AP 16: 0.182031
I0510 20:45:18.614923  5307 solver.cpp:747] class AP 17: 0.416545
I0510 20:45:18.615754  5307 solver.cpp:747] class AP 18: 0.478007
I0510 20:45:18.616039  5307 solver.cpp:747] class AP 19: 0.576452
I0510 20:45:18.617624  5307 solver.cpp:747] class AP 20: 0.367012
I0510 20:45:18.617635  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.450609
I0510 20:45:18.617774  5307 solver.cpp:283] Tests completed in 101.689s
I0510 20:45:19.214574  5307 solver.cpp:352] Iteration 34000 (0.983389 iter/s, 101.689s/100 iter), 65.7/232ep, loss = 3.70767
I0510 20:45:19.214648  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.55412 (* 1 = 4.55412 loss)
I0510 20:45:19.214668  5307 sgd_solver.cpp:172] Iteration 34000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:46:19.771157  5307 solver.cpp:352] Iteration 34100 (1.65138 iter/s, 60.5555s/100 iter), 65.9/232ep, loss = 3.48196
I0510 20:46:19.771966  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.2801 (* 1 = 3.2801 loss)
I0510 20:46:19.771975  5307 sgd_solver.cpp:172] Iteration 34100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:46:31.240007  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 20:47:20.672050  5307 solver.cpp:352] Iteration 34200 (1.64204 iter/s, 60.8998s/100 iter), 66.1/232ep, loss = 3.76233
I0510 20:47:20.672143  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.77907 (* 1 = 3.77907 loss)
I0510 20:47:20.672163  5307 sgd_solver.cpp:172] Iteration 34200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:48:21.350836  5307 solver.cpp:352] Iteration 34300 (1.64805 iter/s, 60.6777s/100 iter), 66.3/232ep, loss = 3.5743
I0510 20:48:21.350909  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.14103 (* 1 = 3.14103 loss)
I0510 20:48:21.350927  5307 sgd_solver.cpp:172] Iteration 34300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:49:22.619603  5307 solver.cpp:352] Iteration 34400 (1.63218 iter/s, 61.2677s/100 iter), 66.5/232ep, loss = 3.59712
I0510 20:49:22.620645  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.3178 (* 1 = 3.3178 loss)
I0510 20:49:22.620659  5307 sgd_solver.cpp:172] Iteration 34400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:50:24.179818  5307 solver.cpp:352] Iteration 34500 (1.62445 iter/s, 61.5592s/100 iter), 66.7/232ep, loss = 3.80377
I0510 20:50:24.180825  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.96294 (* 1 = 3.96294 loss)
I0510 20:50:24.180835  5307 sgd_solver.cpp:172] Iteration 34500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:51:24.903394  5307 solver.cpp:352] Iteration 34600 (1.64683 iter/s, 60.7225s/100 iter), 66.9/232ep, loss = 3.86259
I0510 20:51:24.903481  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.41186 (* 1 = 4.41186 loss)
I0510 20:51:24.903538  5307 sgd_solver.cpp:172] Iteration 34600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:51:46.390770  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 20:52:25.481698  5307 solver.cpp:352] Iteration 34700 (1.65078 iter/s, 60.5773s/100 iter), 67.1/232ep, loss = 3.66415
I0510 20:52:25.481909  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.71425 (* 1 = 3.71425 loss)
I0510 20:52:25.481936  5307 sgd_solver.cpp:172] Iteration 34700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:53:25.305434  5307 solver.cpp:352] Iteration 34800 (1.67161 iter/s, 59.8227s/100 iter), 67.3/232ep, loss = 3.60402
I0510 20:53:25.305531  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.56683 (* 1 = 3.56683 loss)
I0510 20:53:25.305541  5307 sgd_solver.cpp:172] Iteration 34800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:54:25.806474  5307 solver.cpp:352] Iteration 34900 (1.65289 iter/s, 60.5s/100 iter), 67.5/232ep, loss = 3.95134
I0510 20:54:25.806650  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.80422 (* 1 = 3.80422 loss)
I0510 20:54:25.806704  5307 sgd_solver.cpp:172] Iteration 34900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:55:26.613881  5307 solver.cpp:352] Iteration 35000 (1.64456 iter/s, 60.8064s/100 iter), 67.7/232ep, loss = 3.76141
I0510 20:55:26.613971  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.25462 (* 1 = 3.25462 loss)
I0510 20:55:26.613988  5307 sgd_solver.cpp:172] Iteration 35000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:56:27.344899  5307 solver.cpp:352] Iteration 35100 (1.64663 iter/s, 60.73s/100 iter), 67.9/232ep, loss = 3.5772
I0510 20:56:27.344980  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.69115 (* 1 = 3.69115 loss)
I0510 20:56:27.344990  5307 sgd_solver.cpp:172] Iteration 35100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:56:59.136808  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 20:57:27.278641  5307 solver.cpp:352] Iteration 35200 (1.66854 iter/s, 59.9327s/100 iter), 68.1/232ep, loss = 3.73241
I0510 20:57:27.278709  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.85551 (* 1 = 3.85551 loss)
I0510 20:57:27.278722  5307 sgd_solver.cpp:172] Iteration 35200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:58:27.649441  5307 solver.cpp:352] Iteration 35300 (1.65646 iter/s, 60.3698s/100 iter), 68.2/232ep, loss = 3.69123
I0510 20:58:27.649540  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.00623 (* 1 = 4.00623 loss)
I0510 20:58:27.649559  5307 sgd_solver.cpp:172] Iteration 35300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 20:59:28.589807  5307 solver.cpp:352] Iteration 35400 (1.64098 iter/s, 60.9393s/100 iter), 68.4/232ep, loss = 3.6245
I0510 20:59:28.589917  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.83925 (* 1 = 3.83925 loss)
I0510 20:59:28.589929  5307 sgd_solver.cpp:172] Iteration 35400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:00:28.993971  5307 solver.cpp:352] Iteration 35500 (1.65554 iter/s, 60.4032s/100 iter), 68.6/232ep, loss = 3.68356
I0510 21:00:28.994617  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.54682 (* 1 = 3.54682 loss)
I0510 21:00:28.994635  5307 sgd_solver.cpp:172] Iteration 35500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:01:29.870028  5307 solver.cpp:352] Iteration 35600 (1.64271 iter/s, 60.875s/100 iter), 68.8/232ep, loss = 3.76594
I0510 21:01:29.870085  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.28141 (* 1 = 3.28141 loss)
I0510 21:01:29.870092  5307 sgd_solver.cpp:172] Iteration 35600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:02:11.876209  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 21:02:29.675426  5307 solver.cpp:352] Iteration 35700 (1.67212 iter/s, 59.8044s/100 iter), 69/232ep, loss = 3.60164
I0510 21:02:29.675454  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.09273 (* 1 = 4.09273 loss)
I0510 21:02:29.675460  5307 sgd_solver.cpp:172] Iteration 35700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:03:30.000664  5307 solver.cpp:352] Iteration 35800 (1.65771 iter/s, 60.3242s/100 iter), 69.2/232ep, loss = 3.59873
I0510 21:03:30.000756  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.98077 (* 1 = 3.98077 loss)
I0510 21:03:30.000772  5307 sgd_solver.cpp:172] Iteration 35800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:04:30.281559  5307 solver.cpp:352] Iteration 35900 (1.65893 iter/s, 60.2799s/100 iter), 69.4/232ep, loss = 3.67615
I0510 21:04:30.281621  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.51516 (* 1 = 3.51516 loss)
I0510 21:04:30.281631  5307 sgd_solver.cpp:172] Iteration 35900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:05:30.561995  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_36000.caffemodel
I0510 21:05:30.577775  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_36000.solverstate
I0510 21:05:30.582509  5307 solver.cpp:635] Iteration 36000, Testing net (#0)
I0510 21:06:11.008594  5353 data_reader.cpp:320] Restarting data pre-fetching
I0510 21:06:11.250401  5307 solver.cpp:747] class AP 1: 0.568783
I0510 21:06:11.251291  5307 solver.cpp:747] class AP 2: 0.65916
I0510 21:06:11.261994  5307 solver.cpp:747] class AP 3: 0.446317
I0510 21:06:11.267140  5307 solver.cpp:747] class AP 4: 0.395777
I0510 21:06:11.279081  5307 solver.cpp:747] class AP 5: 0.260131
I0510 21:06:11.279667  5307 solver.cpp:747] class AP 6: 0.619327
I0510 21:06:11.286386  5307 solver.cpp:747] class AP 7: 0.635646
I0510 21:06:11.287024  5307 solver.cpp:747] class AP 8: 0.685365
I0510 21:06:11.310312  5307 solver.cpp:747] class AP 9: 0.308565
I0510 21:06:11.311499  5307 solver.cpp:747] class AP 10: 0.4708
I0510 21:06:11.312520  5307 solver.cpp:747] class AP 11: 0.476802
I0510 21:06:11.314118  5307 solver.cpp:747] class AP 12: 0.617592
I0510 21:06:11.314607  5307 solver.cpp:747] class AP 13: 0.680942
I0510 21:06:11.315171  5307 solver.cpp:747] class AP 14: 0.635709
I0510 21:06:11.376093  5307 solver.cpp:747] class AP 15: 0.637665
I0510 21:06:11.382761  5307 solver.cpp:747] class AP 16: 0.224308
I0510 21:06:11.392376  5307 solver.cpp:747] class AP 17: 0.440435
I0510 21:06:11.393535  5307 solver.cpp:747] class AP 18: 0.524649
I0510 21:06:11.394313  5307 solver.cpp:747] class AP 19: 0.632256
I0510 21:06:11.395380  5307 solver.cpp:747] class AP 20: 0.475234
I0510 21:06:11.395386  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.519773
I0510 21:06:11.395527  5307 solver.cpp:283] Tests completed in 101.112s
I0510 21:06:11.943778  5307 solver.cpp:352] Iteration 36000 (0.989 iter/s, 101.112s/100 iter), 69.6/232ep, loss = 3.35457
I0510 21:06:11.943830  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.43099 (* 1 = 3.43099 loss)
I0510 21:06:11.943842  5307 sgd_solver.cpp:172] Iteration 36000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:07:12.810127  5307 solver.cpp:352] Iteration 36100 (1.64297 iter/s, 60.8653s/100 iter), 69.8/232ep, loss = 3.67175
I0510 21:07:12.810981  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.53452 (* 1 = 3.53452 loss)
I0510 21:07:12.811048  5307 sgd_solver.cpp:172] Iteration 36100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:08:05.406282  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 21:08:13.164630  5307 solver.cpp:352] Iteration 36200 (1.65691 iter/s, 60.3534s/100 iter), 70/232ep, loss = 3.62086
I0510 21:08:13.164672  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.69297 (* 1 = 2.69297 loss)
I0510 21:08:13.164682  5307 sgd_solver.cpp:172] Iteration 36200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:09:13.744716  5307 solver.cpp:352] Iteration 36300 (1.65074 iter/s, 60.579s/100 iter), 70.2/232ep, loss = 3.5315
I0510 21:09:13.744881  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.55787 (* 1 = 3.55787 loss)
I0510 21:09:13.744909  5307 sgd_solver.cpp:172] Iteration 36300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:10:14.500439  5307 solver.cpp:352] Iteration 36400 (1.64596 iter/s, 60.7547s/100 iter), 70.4/232ep, loss = 3.63935
I0510 21:10:14.500519  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.89221 (* 1 = 3.89221 loss)
I0510 21:10:14.500545  5307 sgd_solver.cpp:172] Iteration 36400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:11:14.099763  5307 solver.cpp:352] Iteration 36500 (1.6779 iter/s, 59.5983s/100 iter), 70.6/232ep, loss = 3.9966
I0510 21:11:14.099948  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.81575 (* 1 = 3.81575 loss)
I0510 21:11:14.099975  5307 sgd_solver.cpp:172] Iteration 36500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:12:14.474020  5307 solver.cpp:352] Iteration 36600 (1.65636 iter/s, 60.3732s/100 iter), 70.8/232ep, loss = 3.64754
I0510 21:12:14.485167  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.13334 (* 1 = 3.13334 loss)
I0510 21:12:14.485191  5307 sgd_solver.cpp:172] Iteration 36600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:13:14.260732  5307 solver.cpp:352] Iteration 36700 (1.67264 iter/s, 59.7857s/100 iter), 71/232ep, loss = 3.69982
I0510 21:13:14.260835  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.12445 (* 1 = 4.12445 loss)
I0510 21:13:14.260859  5307 sgd_solver.cpp:172] Iteration 36700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:13:17.213470  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 21:14:13.801023  5307 solver.cpp:352] Iteration 36800 (1.67956 iter/s, 59.5393s/100 iter), 71.1/232ep, loss = 3.5667
I0510 21:14:13.801134  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.63345 (* 1 = 3.63345 loss)
I0510 21:14:13.801147  5307 sgd_solver.cpp:172] Iteration 36800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:15:14.316159  5307 solver.cpp:352] Iteration 36900 (1.65251 iter/s, 60.5141s/100 iter), 71.3/232ep, loss = 3.71623
I0510 21:15:14.316234  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.73786 (* 1 = 2.73786 loss)
I0510 21:15:14.316244  5307 sgd_solver.cpp:172] Iteration 36900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:16:14.722913  5307 solver.cpp:352] Iteration 37000 (1.65547 iter/s, 60.4057s/100 iter), 71.5/232ep, loss = 3.5448
I0510 21:16:14.722980  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.92331 (* 1 = 2.92331 loss)
I0510 21:16:14.722988  5307 sgd_solver.cpp:172] Iteration 37000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:17:14.764508  5307 solver.cpp:352] Iteration 37100 (1.66554 iter/s, 60.0406s/100 iter), 71.7/232ep, loss = 3.59719
I0510 21:17:14.764567  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.05983 (* 1 = 4.05983 loss)
I0510 21:17:14.764573  5307 sgd_solver.cpp:172] Iteration 37100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:18:14.917587  5307 solver.cpp:352] Iteration 37200 (1.66245 iter/s, 60.1521s/100 iter), 71.9/232ep, loss = 3.60382
I0510 21:18:14.917676  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.51662 (* 1 = 3.51662 loss)
I0510 21:18:14.917697  5307 sgd_solver.cpp:172] Iteration 37200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:18:27.635392  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 21:19:15.886972  5307 solver.cpp:352] Iteration 37300 (1.6402 iter/s, 60.9683s/100 iter), 72.1/232ep, loss = 3.70657
I0510 21:19:15.887038  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.28576 (* 1 = 3.28576 loss)
I0510 21:19:15.887046  5307 sgd_solver.cpp:172] Iteration 37300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:20:15.671473  5307 solver.cpp:352] Iteration 37400 (1.6727 iter/s, 59.7835s/100 iter), 72.3/232ep, loss = 3.46799
I0510 21:20:15.671617  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.14536 (* 1 = 4.14536 loss)
I0510 21:20:15.671633  5307 sgd_solver.cpp:172] Iteration 37400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:21:17.264648  5307 solver.cpp:352] Iteration 37500 (1.62358 iter/s, 61.5922s/100 iter), 72.5/232ep, loss = 3.59698
I0510 21:21:17.264725  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.37801 (* 1 = 3.37801 loss)
I0510 21:21:17.264735  5307 sgd_solver.cpp:172] Iteration 37500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:22:18.230902  5307 solver.cpp:352] Iteration 37600 (1.64028 iter/s, 60.9652s/100 iter), 72.7/232ep, loss = 3.59863
I0510 21:22:18.231084  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.41289 (* 1 = 3.41289 loss)
I0510 21:22:18.231132  5307 sgd_solver.cpp:172] Iteration 37600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:23:19.303782  5307 solver.cpp:352] Iteration 37700 (1.63742 iter/s, 61.0719s/100 iter), 72.9/232ep, loss = 3.61308
I0510 21:23:19.303894  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.26588 (* 1 = 3.26588 loss)
I0510 21:23:19.303903  5307 sgd_solver.cpp:172] Iteration 37700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:23:43.063323  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 21:24:19.149380  5307 solver.cpp:352] Iteration 37800 (1.67099 iter/s, 59.8446s/100 iter), 73.1/232ep, loss = 3.59578
I0510 21:24:19.149605  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.75051 (* 1 = 3.75051 loss)
I0510 21:24:19.149615  5307 sgd_solver.cpp:172] Iteration 37800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:25:19.356627  5307 solver.cpp:352] Iteration 37900 (1.66096 iter/s, 60.2062s/100 iter), 73.3/232ep, loss = 3.73517
I0510 21:25:19.356943  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.43998 (* 1 = 4.43998 loss)
I0510 21:25:19.356952  5307 sgd_solver.cpp:172] Iteration 37900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:26:19.011675  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_38000.caffemodel
I0510 21:26:19.031734  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_38000.solverstate
I0510 21:26:19.038130  5307 solver.cpp:635] Iteration 38000, Testing net (#0)
I0510 21:26:59.776566  5353 data_reader.cpp:320] Restarting data pre-fetching
I0510 21:27:00.004941  5307 solver.cpp:747] class AP 1: 0.5052
I0510 21:27:00.005132  5307 solver.cpp:747] class AP 2: 0.539033
I0510 21:27:00.010339  5307 solver.cpp:747] class AP 3: 0.357168
I0510 21:27:00.012910  5307 solver.cpp:747] class AP 4: 0.333069
I0510 21:27:00.030097  5307 solver.cpp:747] class AP 5: 0.204389
I0510 21:27:00.030365  5307 solver.cpp:747] class AP 6: 0.609031
I0510 21:27:00.039222  5307 solver.cpp:747] class AP 7: 0.591758
I0510 21:27:00.040027  5307 solver.cpp:747] class AP 8: 0.656491
I0510 21:27:00.071101  5307 solver.cpp:747] class AP 9: 0.298
I0510 21:27:00.071439  5307 solver.cpp:747] class AP 10: 0.475356
I0510 21:27:00.071856  5307 solver.cpp:747] class AP 11: 0.50872
I0510 21:27:00.072576  5307 solver.cpp:747] class AP 12: 0.538248
I0510 21:27:00.072798  5307 solver.cpp:747] class AP 13: 0.651622
I0510 21:27:00.073029  5307 solver.cpp:747] class AP 14: 0.562866
I0510 21:27:00.128082  5307 solver.cpp:747] class AP 15: 0.606885
I0510 21:27:00.130252  5307 solver.cpp:747] class AP 16: 0.222947
I0510 21:27:00.132756  5307 solver.cpp:747] class AP 17: 0.437542
I0510 21:27:00.134523  5307 solver.cpp:747] class AP 18: 0.413573
I0510 21:27:00.134902  5307 solver.cpp:747] class AP 19: 0.619407
I0510 21:27:00.136670  5307 solver.cpp:747] class AP 20: 0.461706
I0510 21:27:00.136685  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.47965
I0510 21:27:00.136886  5307 solver.cpp:283] Tests completed in 100.779s
I0510 21:27:00.678278  5307 solver.cpp:352] Iteration 38000 (0.992274 iter/s, 100.779s/100 iter), 73.5/232ep, loss = 3.82641
I0510 21:27:00.678313  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.13177 (* 1 = 3.13177 loss)
I0510 21:27:00.678320  5307 sgd_solver.cpp:172] Iteration 38000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:28:00.853718  5307 solver.cpp:352] Iteration 38100 (1.66184 iter/s, 60.1744s/100 iter), 73.7/232ep, loss = 3.62437
I0510 21:28:00.853843  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.30541 (* 1 = 3.30541 loss)
I0510 21:28:00.853859  5307 sgd_solver.cpp:172] Iteration 38100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:29:01.346016  5307 solver.cpp:352] Iteration 38200 (1.65313 iter/s, 60.4912s/100 iter), 73.9/232ep, loss = 3.60155
I0510 21:29:01.350435  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.7041 (* 1 = 3.7041 loss)
I0510 21:29:01.350448  5307 sgd_solver.cpp:172] Iteration 38200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:29:35.598528  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 21:30:01.741117  5307 solver.cpp:352] Iteration 38300 (1.65579 iter/s, 60.3941s/100 iter), 74/232ep, loss = 3.58561
I0510 21:30:01.741160  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.48464 (* 1 = 3.48464 loss)
I0510 21:30:01.741169  5307 sgd_solver.cpp:172] Iteration 38300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:31:02.368338  5307 solver.cpp:352] Iteration 38400 (1.64945 iter/s, 60.6262s/100 iter), 74.2/232ep, loss = 3.65317
I0510 21:31:02.368399  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.03553 (* 1 = 4.03553 loss)
I0510 21:31:02.368409  5307 sgd_solver.cpp:172] Iteration 38400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:32:03.428159  5307 solver.cpp:352] Iteration 38500 (1.63777 iter/s, 61.0588s/100 iter), 74.4/232ep, loss = 3.61148
I0510 21:32:03.428247  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.8391 (* 1 = 3.8391 loss)
I0510 21:32:03.428261  5307 sgd_solver.cpp:172] Iteration 38500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:33:03.708784  5307 solver.cpp:352] Iteration 38600 (1.65894 iter/s, 60.2796s/100 iter), 74.6/232ep, loss = 3.81464
I0510 21:33:03.709264  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.7558 (* 1 = 3.7558 loss)
I0510 21:33:03.709309  5307 sgd_solver.cpp:172] Iteration 38600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:34:04.382413  5307 solver.cpp:352] Iteration 38700 (1.64819 iter/s, 60.6726s/100 iter), 74.8/232ep, loss = 3.83513
I0510 21:34:04.382488  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.41642 (* 1 = 3.41642 loss)
I0510 21:34:04.382498  5307 sgd_solver.cpp:172] Iteration 38700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:34:48.086021  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 21:35:04.040887  5307 solver.cpp:352] Iteration 38800 (1.67624 iter/s, 59.6575s/100 iter), 75/232ep, loss = 3.62916
I0510 21:35:04.040923  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.41938 (* 1 = 4.41938 loss)
I0510 21:35:04.040931  5307 sgd_solver.cpp:172] Iteration 38800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:36:04.107892  5307 solver.cpp:352] Iteration 38900 (1.66484 iter/s, 60.066s/100 iter), 75.2/232ep, loss = 3.58486
I0510 21:36:04.107978  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.21385 (* 1 = 3.21385 loss)
I0510 21:36:04.107995  5307 sgd_solver.cpp:172] Iteration 38900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:37:04.114724  5307 solver.cpp:352] Iteration 39000 (1.6665 iter/s, 60.0058s/100 iter), 75.4/232ep, loss = 3.52668
I0510 21:37:04.115047  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.35119 (* 1 = 4.35119 loss)
I0510 21:37:04.115056  5307 sgd_solver.cpp:172] Iteration 39000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:38:06.187549  5307 solver.cpp:352] Iteration 39100 (1.61104 iter/s, 62.0718s/100 iter), 75.6/232ep, loss = 3.52495
I0510 21:38:06.187664  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.16989 (* 1 = 4.16989 loss)
I0510 21:38:06.187674  5307 sgd_solver.cpp:172] Iteration 39100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:39:15.436691  5307 solver.cpp:352] Iteration 39200 (1.44409 iter/s, 69.248s/100 iter), 75.8/232ep, loss = 3.67819
I0510 21:39:15.437286  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.09562 (* 1 = 3.09562 loss)
I0510 21:39:15.437294  5307 sgd_solver.cpp:172] Iteration 39200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:40:11.855397  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 21:40:17.215807  5307 solver.cpp:352] Iteration 39300 (1.6187 iter/s, 61.7781s/100 iter), 76/232ep, loss = 3.78971
I0510 21:40:17.215832  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.55306 (* 1 = 3.55306 loss)
I0510 21:40:17.215840  5307 sgd_solver.cpp:172] Iteration 39300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:41:17.962391  5307 solver.cpp:352] Iteration 39400 (1.64621 iter/s, 60.7455s/100 iter), 76.2/232ep, loss = 3.89644
I0510 21:41:17.962517  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.11371 (* 1 = 4.11371 loss)
I0510 21:41:17.962525  5307 sgd_solver.cpp:172] Iteration 39400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:42:18.468636  5307 solver.cpp:352] Iteration 39500 (1.65275 iter/s, 60.5052s/100 iter), 76.4/232ep, loss = 3.64194
I0510 21:42:18.468721  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.74449 (* 1 = 3.74449 loss)
I0510 21:42:18.468731  5307 sgd_solver.cpp:172] Iteration 39500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:43:19.419124  5307 solver.cpp:352] Iteration 39600 (1.6407 iter/s, 60.9495s/100 iter), 76.6/232ep, loss = 3.63924
I0510 21:43:19.419281  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.61965 (* 1 = 3.61965 loss)
I0510 21:43:19.419332  5307 sgd_solver.cpp:172] Iteration 39600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:44:20.567492  5307 solver.cpp:352] Iteration 39700 (1.63539 iter/s, 61.1473s/100 iter), 76.8/232ep, loss = 3.65378
I0510 21:44:20.568058  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.64097 (* 1 = 3.64097 loss)
I0510 21:44:20.568075  5307 sgd_solver.cpp:172] Iteration 39700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:45:20.776649  5307 solver.cpp:352] Iteration 39800 (1.66091 iter/s, 60.2081s/100 iter), 77/232ep, loss = 3.61238
I0510 21:45:20.776767  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.49909 (* 1 = 3.49909 loss)
I0510 21:45:20.776785  5307 sgd_solver.cpp:172] Iteration 39800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:45:24.994469  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 21:46:20.611048  5307 solver.cpp:352] Iteration 39900 (1.67131 iter/s, 59.8334s/100 iter), 77.1/232ep, loss = 3.56136
I0510 21:46:20.611136  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.26811 (* 1 = 3.26811 loss)
I0510 21:46:20.611156  5307 sgd_solver.cpp:172] Iteration 39900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:47:20.372117  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_40000.caffemodel
I0510 21:47:20.389097  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_40000.solverstate
I0510 21:47:20.394568  5307 solver.cpp:635] Iteration 40000, Testing net (#0)
I0510 21:48:00.663660  5353 data_reader.cpp:320] Restarting data pre-fetching
I0510 21:48:00.872752  5307 solver.cpp:747] class AP 1: 0.520476
I0510 21:48:00.873112  5307 solver.cpp:747] class AP 2: 0.577247
I0510 21:48:00.878597  5307 solver.cpp:747] class AP 3: 0.314433
I0510 21:48:00.879312  5307 solver.cpp:747] class AP 4: 0.335391
I0510 21:48:00.899533  5307 solver.cpp:747] class AP 5: 0.227511
I0510 21:48:00.899749  5307 solver.cpp:747] class AP 6: 0.573794
I0510 21:48:00.905573  5307 solver.cpp:747] class AP 7: 0.569326
I0510 21:48:00.907130  5307 solver.cpp:747] class AP 8: 0.655245
I0510 21:48:00.917480  5307 solver.cpp:747] class AP 9: 0.261153
I0510 21:48:00.918313  5307 solver.cpp:747] class AP 10: 0.416685
I0510 21:48:00.918567  5307 solver.cpp:747] class AP 11: 0.489146
I0510 21:48:00.921221  5307 solver.cpp:747] class AP 12: 0.578182
I0510 21:48:00.921957  5307 solver.cpp:747] class AP 13: 0.706205
I0510 21:48:00.922250  5307 solver.cpp:747] class AP 14: 0.591031
I0510 21:48:01.001513  5307 solver.cpp:747] class AP 15: 0.615364
I0510 21:48:01.005388  5307 solver.cpp:747] class AP 16: 0.207144
I0510 21:48:01.006865  5307 solver.cpp:747] class AP 17: 0.43087
I0510 21:48:01.007848  5307 solver.cpp:747] class AP 18: 0.419016
I0510 21:48:01.008469  5307 solver.cpp:747] class AP 19: 0.614923
I0510 21:48:01.009793  5307 solver.cpp:747] class AP 20: 0.450545
I0510 21:48:01.009802  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.477684
I0510 21:48:01.010001  5307 solver.cpp:283] Tests completed in 100.397s
I0510 21:48:01.576629  5307 solver.cpp:352] Iteration 40000 (0.996043 iter/s, 100.397s/100 iter), 77.3/232ep, loss = 3.86338
I0510 21:48:01.576654  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.65106 (* 1 = 4.65106 loss)
I0510 21:48:01.576660  5307 sgd_solver.cpp:172] Iteration 40000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:49:01.632191  5307 solver.cpp:352] Iteration 40100 (1.66515 iter/s, 60.0545s/100 iter), 77.5/232ep, loss = 3.58973
I0510 21:49:01.632961  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.6637 (* 1 = 3.6637 loss)
I0510 21:49:01.632982  5307 sgd_solver.cpp:172] Iteration 40100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:50:02.186213  5307 solver.cpp:352] Iteration 40200 (1.65145 iter/s, 60.553s/100 iter), 77.7/232ep, loss = 3.734
I0510 21:50:02.187319  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.30205 (* 1 = 3.30205 loss)
I0510 21:50:02.187347  5307 sgd_solver.cpp:172] Iteration 40200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:51:02.389930  5307 solver.cpp:352] Iteration 40300 (1.66106 iter/s, 60.2027s/100 iter), 77.9/232ep, loss = 3.55042
I0510 21:51:02.389989  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.4546 (* 1 = 3.4546 loss)
I0510 21:51:02.389998  5307 sgd_solver.cpp:172] Iteration 40300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:51:17.505239  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 21:52:02.887758  5307 solver.cpp:352] Iteration 40400 (1.65298 iter/s, 60.4968s/100 iter), 78.1/232ep, loss = 3.61956
I0510 21:52:02.887820  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.15467 (* 1 = 4.15467 loss)
I0510 21:52:02.887827  5307 sgd_solver.cpp:172] Iteration 40400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:53:03.079121  5307 solver.cpp:352] Iteration 40500 (1.6614 iter/s, 60.1904s/100 iter), 78.3/232ep, loss = 3.71012
I0510 21:53:03.079205  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.61716 (* 1 = 3.61716 loss)
I0510 21:53:03.079222  5307 sgd_solver.cpp:172] Iteration 40500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:54:03.590065  5307 solver.cpp:352] Iteration 40600 (1.65262 iter/s, 60.5099s/100 iter), 78.5/232ep, loss = 3.5501
I0510 21:54:03.590135  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.84851 (* 1 = 2.84851 loss)
I0510 21:54:03.590147  5307 sgd_solver.cpp:172] Iteration 40600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:55:04.550119  5307 solver.cpp:352] Iteration 40700 (1.64045 iter/s, 60.959s/100 iter), 78.7/232ep, loss = 3.6139
I0510 21:55:04.550245  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.00362 (* 1 = 4.00362 loss)
I0510 21:55:04.550262  5307 sgd_solver.cpp:172] Iteration 40700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:56:04.426820  5307 solver.cpp:352] Iteration 40800 (1.67013 iter/s, 59.8757s/100 iter), 78.9/232ep, loss = 3.45172
I0510 21:56:04.426923  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.41889 (* 1 = 3.41889 loss)
I0510 21:56:04.426934  5307 sgd_solver.cpp:172] Iteration 40800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:56:30.006772  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 21:57:04.665575  5307 solver.cpp:352] Iteration 40900 (1.66009 iter/s, 60.2377s/100 iter), 79.1/232ep, loss = 3.62553
I0510 21:57:04.665683  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.69357 (* 1 = 3.69357 loss)
I0510 21:57:04.665704  5307 sgd_solver.cpp:172] Iteration 40900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:58:04.750860  5307 solver.cpp:352] Iteration 41000 (1.66433 iter/s, 60.0843s/100 iter), 79.3/232ep, loss = 3.74795
I0510 21:58:04.750957  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.99367 (* 1 = 2.99367 loss)
I0510 21:58:04.750977  5307 sgd_solver.cpp:172] Iteration 41000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 21:59:05.323962  5307 solver.cpp:352] Iteration 41100 (1.65093 iter/s, 60.5721s/100 iter), 79.5/232ep, loss = 3.56803
I0510 21:59:05.324067  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.03478 (* 1 = 4.03478 loss)
I0510 21:59:05.324082  5307 sgd_solver.cpp:172] Iteration 41100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:00:05.307688  5307 solver.cpp:352] Iteration 41200 (1.66715 iter/s, 59.9827s/100 iter), 79.7/232ep, loss = 3.52172
I0510 22:00:05.312608  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.72247 (* 1 = 3.72247 loss)
I0510 22:00:05.312623  5307 sgd_solver.cpp:172] Iteration 41200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:01:04.931408  5307 solver.cpp:352] Iteration 41300 (1.67721 iter/s, 59.6227s/100 iter), 79.9/232ep, loss = 3.77013
I0510 22:01:04.931486  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.49615 (* 1 = 3.49615 loss)
I0510 22:01:04.931495  5307 sgd_solver.cpp:172] Iteration 41300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:01:40.768656  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 22:02:05.374547  5307 solver.cpp:352] Iteration 41400 (1.65448 iter/s, 60.4421s/100 iter), 80/232ep, loss = 3.62685
I0510 22:02:05.374572  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.10421 (* 1 = 3.10421 loss)
I0510 22:02:05.374579  5307 sgd_solver.cpp:172] Iteration 41400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:03:06.852798  5307 solver.cpp:352] Iteration 41500 (1.62662 iter/s, 61.4772s/100 iter), 80.2/232ep, loss = 3.50893
I0510 22:03:06.853668  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.39475 (* 1 = 3.39475 loss)
I0510 22:03:06.853682  5307 sgd_solver.cpp:172] Iteration 41500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:04:07.508661  5307 solver.cpp:352] Iteration 41600 (1.64867 iter/s, 60.6548s/100 iter), 80.4/232ep, loss = 3.59382
I0510 22:04:07.509981  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.30832 (* 1 = 4.30832 loss)
I0510 22:04:07.509997  5307 sgd_solver.cpp:172] Iteration 41600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:05:07.744612  5307 solver.cpp:352] Iteration 41700 (1.66017 iter/s, 60.235s/100 iter), 80.6/232ep, loss = 3.74398
I0510 22:05:07.744665  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.21229 (* 1 = 3.21229 loss)
I0510 22:05:07.744671  5307 sgd_solver.cpp:172] Iteration 41700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:06:08.835930  5307 solver.cpp:352] Iteration 41800 (1.63692 iter/s, 61.0903s/100 iter), 80.8/232ep, loss = 3.61463
I0510 22:06:08.836014  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.87827 (* 1 = 3.87827 loss)
I0510 22:06:08.836027  5307 sgd_solver.cpp:172] Iteration 41800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:06:55.344455  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 22:07:09.105779  5307 solver.cpp:352] Iteration 41900 (1.65923 iter/s, 60.2688s/100 iter), 81/232ep, loss = 3.66765
I0510 22:07:09.105804  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.99514 (* 1 = 3.99514 loss)
I0510 22:07:09.105813  5307 sgd_solver.cpp:172] Iteration 41900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:08:08.894412  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_42000.caffemodel
I0510 22:08:08.913151  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_42000.solverstate
I0510 22:08:08.920022  5307 solver.cpp:635] Iteration 42000, Testing net (#0)
I0510 22:08:49.789216  5353 data_reader.cpp:320] Restarting data pre-fetching
I0510 22:08:50.003633  5307 solver.cpp:747] class AP 1: 0.534171
I0510 22:08:50.004140  5307 solver.cpp:747] class AP 2: 0.628472
I0510 22:08:50.010937  5307 solver.cpp:747] class AP 3: 0.418746
I0510 22:08:50.014612  5307 solver.cpp:747] class AP 4: 0.364946
I0510 22:08:50.031375  5307 solver.cpp:747] class AP 5: 0.213854
I0510 22:08:50.031503  5307 solver.cpp:747] class AP 6: 0.627559
I0510 22:08:50.041143  5307 solver.cpp:747] class AP 7: 0.620652
I0510 22:08:50.042007  5307 solver.cpp:747] class AP 8: 0.710804
I0510 22:08:50.061527  5307 solver.cpp:747] class AP 9: 0.330063
I0510 22:08:50.061870  5307 solver.cpp:747] class AP 10: 0.504193
I0510 22:08:50.062520  5307 solver.cpp:747] class AP 11: 0.534669
I0510 22:08:50.063248  5307 solver.cpp:747] class AP 12: 0.633615
I0510 22:08:50.063508  5307 solver.cpp:747] class AP 13: 0.705069
I0510 22:08:50.063880  5307 solver.cpp:747] class AP 14: 0.632479
I0510 22:08:50.124693  5307 solver.cpp:747] class AP 15: 0.632617
I0510 22:08:50.129084  5307 solver.cpp:747] class AP 16: 0.246861
I0510 22:08:50.130812  5307 solver.cpp:747] class AP 17: 0.470018
I0510 22:08:50.131456  5307 solver.cpp:747] class AP 18: 0.51479
I0510 22:08:50.131898  5307 solver.cpp:747] class AP 19: 0.688099
I0510 22:08:50.132757  5307 solver.cpp:747] class AP 20: 0.523382
I0510 22:08:50.132762  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.526753
I0510 22:08:50.133000  5307 solver.cpp:283] Tests completed in 101.026s
I0510 22:08:50.669611  5307 solver.cpp:352] Iteration 42000 (0.989849 iter/s, 101.026s/100 iter), 81.2/232ep, loss = 3.56295
I0510 22:08:50.669718  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.17089 (* 1 = 3.17089 loss)
I0510 22:08:50.669739  5307 sgd_solver.cpp:172] Iteration 42000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:09:50.111747  5307 solver.cpp:352] Iteration 42100 (1.68234 iter/s, 59.4411s/100 iter), 81.4/232ep, loss = 3.46262
I0510 22:09:50.111821  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.23969 (* 1 = 4.23969 loss)
I0510 22:09:50.111830  5307 sgd_solver.cpp:172] Iteration 42100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:10:50.060981  5307 solver.cpp:352] Iteration 42200 (1.66811 iter/s, 59.9482s/100 iter), 81.6/232ep, loss = 3.44918
I0510 22:10:50.061062  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.74013 (* 1 = 2.74013 loss)
I0510 22:10:50.061074  5307 sgd_solver.cpp:172] Iteration 42200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:11:50.372360  5307 solver.cpp:352] Iteration 42300 (1.65809 iter/s, 60.3104s/100 iter), 81.8/232ep, loss = 3.7762
I0510 22:11:50.372473  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.85189 (* 1 = 3.85189 loss)
I0510 22:11:50.372489  5307 sgd_solver.cpp:172] Iteration 42300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:12:46.130507  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 22:12:50.435878  5307 solver.cpp:352] Iteration 42400 (1.66493 iter/s, 60.0625s/100 iter), 82/232ep, loss = 3.733
I0510 22:12:50.435904  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.80832 (* 1 = 4.80832 loss)
I0510 22:12:50.435912  5307 sgd_solver.cpp:172] Iteration 42400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:13:51.216261  5307 solver.cpp:352] Iteration 42500 (1.6453 iter/s, 60.7794s/100 iter), 82.2/232ep, loss = 3.67476
I0510 22:13:51.216312  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.61387 (* 1 = 3.61387 loss)
I0510 22:13:51.216320  5307 sgd_solver.cpp:172] Iteration 42500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:14:51.837419  5307 solver.cpp:352] Iteration 42600 (1.64962 iter/s, 60.6201s/100 iter), 82.4/232ep, loss = 3.84191
I0510 22:14:51.837563  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.19984 (* 1 = 3.19984 loss)
I0510 22:14:51.837589  5307 sgd_solver.cpp:172] Iteration 42600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:15:52.448808  5307 solver.cpp:352] Iteration 42700 (1.64988 iter/s, 60.6104s/100 iter), 82.6/232ep, loss = 3.55317
I0510 22:15:52.448926  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.00699 (* 1 = 4.00699 loss)
I0510 22:15:52.448948  5307 sgd_solver.cpp:172] Iteration 42700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:16:53.346068  5307 solver.cpp:352] Iteration 42800 (1.64214 iter/s, 60.8962s/100 iter), 82.8/232ep, loss = 3.53187
I0510 22:16:53.346138  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.07234 (* 1 = 4.07234 loss)
I0510 22:16:53.346146  5307 sgd_solver.cpp:172] Iteration 42800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:17:53.733168  5307 solver.cpp:352] Iteration 42900 (1.65601 iter/s, 60.3861s/100 iter), 82.9/232ep, loss = 3.60057
I0510 22:17:53.733270  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.17121 (* 1 = 4.17121 loss)
I0510 22:17:53.733295  5307 sgd_solver.cpp:172] Iteration 42900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:18:00.223826  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 22:18:54.359382  5307 solver.cpp:352] Iteration 43000 (1.64948 iter/s, 60.6252s/100 iter), 83.1/232ep, loss = 3.46198
I0510 22:18:54.359463  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.06771 (* 1 = 4.06771 loss)
I0510 22:18:54.359474  5307 sgd_solver.cpp:172] Iteration 43000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:19:55.495054  5307 solver.cpp:352] Iteration 43100 (1.63573 iter/s, 61.1346s/100 iter), 83.3/232ep, loss = 3.58179
I0510 22:19:55.495151  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.99761 (* 1 = 2.99761 loss)
I0510 22:19:55.495167  5307 sgd_solver.cpp:172] Iteration 43100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:20:57.084606  5307 solver.cpp:352] Iteration 43200 (1.62368 iter/s, 61.5885s/100 iter), 83.5/232ep, loss = 3.36912
I0510 22:20:57.084743  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.31 (* 1 = 3.31 loss)
I0510 22:20:57.084753  5307 sgd_solver.cpp:172] Iteration 43200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:21:57.941856  5307 solver.cpp:352] Iteration 43300 (1.64322 iter/s, 60.8563s/100 iter), 83.7/232ep, loss = 3.66869
I0510 22:21:57.941979  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.89205 (* 1 = 3.89205 loss)
I0510 22:21:57.942003  5307 sgd_solver.cpp:172] Iteration 43300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:22:59.763221  5307 solver.cpp:352] Iteration 43400 (1.61759 iter/s, 61.8203s/100 iter), 83.9/232ep, loss = 3.53433
I0510 22:22:59.763306  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.77005 (* 1 = 2.77005 loss)
I0510 22:22:59.763316  5307 sgd_solver.cpp:172] Iteration 43400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:23:17.433843  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 22:24:00.845634  5307 solver.cpp:352] Iteration 43500 (1.63716 iter/s, 61.0814s/100 iter), 84.1/232ep, loss = 3.45022
I0510 22:24:00.845722  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.95186 (* 1 = 3.95186 loss)
I0510 22:24:00.845732  5307 sgd_solver.cpp:172] Iteration 43500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:25:00.274463  5307 solver.cpp:352] Iteration 43600 (1.68271 iter/s, 59.4278s/100 iter), 84.3/232ep, loss = 3.60126
I0510 22:25:00.274605  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.79965 (* 1 = 2.79965 loss)
I0510 22:25:00.274617  5307 sgd_solver.cpp:172] Iteration 43600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:26:00.962894  5307 solver.cpp:352] Iteration 43700 (1.64779 iter/s, 60.6874s/100 iter), 84.5/232ep, loss = 3.59502
I0510 22:26:00.964380  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.55997 (* 1 = 2.55997 loss)
I0510 22:26:00.964414  5307 sgd_solver.cpp:172] Iteration 43700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:27:01.428666  5307 solver.cpp:352] Iteration 43800 (1.65386 iter/s, 60.4647s/100 iter), 84.7/232ep, loss = 3.55229
I0510 22:27:01.428730  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.97239 (* 1 = 3.97239 loss)
I0510 22:27:01.428738  5307 sgd_solver.cpp:172] Iteration 43800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:28:02.477066  5307 solver.cpp:352] Iteration 43900 (1.63807 iter/s, 61.0474s/100 iter), 84.9/232ep, loss = 3.45262
I0510 22:28:02.477171  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.79397 (* 1 = 3.79397 loss)
I0510 22:28:02.477183  5307 sgd_solver.cpp:172] Iteration 43900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:28:30.984215  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 22:29:03.972008  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_44000.caffemodel
I0510 22:29:03.986655  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_44000.solverstate
I0510 22:29:03.990772  5307 solver.cpp:635] Iteration 44000, Testing net (#0)
I0510 22:29:44.763483  5353 data_reader.cpp:320] Restarting data pre-fetching
I0510 22:29:45.015172  5307 solver.cpp:747] class AP 1: 0.537234
I0510 22:29:45.015624  5307 solver.cpp:747] class AP 2: 0.566408
I0510 22:29:45.019718  5307 solver.cpp:747] class AP 3: 0.411401
I0510 22:29:45.022940  5307 solver.cpp:747] class AP 4: 0.364857
I0510 22:29:45.038170  5307 solver.cpp:747] class AP 5: 0.233334
I0510 22:29:45.038571  5307 solver.cpp:747] class AP 6: 0.629944
I0510 22:29:45.042909  5307 solver.cpp:747] class AP 7: 0.613214
I0510 22:29:45.043376  5307 solver.cpp:747] class AP 8: 0.656918
I0510 22:29:45.063295  5307 solver.cpp:747] class AP 9: 0.338147
I0510 22:29:45.063719  5307 solver.cpp:747] class AP 10: 0.461028
I0510 22:29:45.064224  5307 solver.cpp:747] class AP 11: 0.43602
I0510 22:29:45.064898  5307 solver.cpp:747] class AP 12: 0.606772
I0510 22:29:45.065259  5307 solver.cpp:747] class AP 13: 0.686549
I0510 22:29:45.065376  5307 solver.cpp:747] class AP 14: 0.586515
I0510 22:29:45.134161  5307 solver.cpp:747] class AP 15: 0.635893
I0510 22:29:45.143028  5307 solver.cpp:747] class AP 16: 0.177475
I0510 22:29:45.144666  5307 solver.cpp:747] class AP 17: 0.391172
I0510 22:29:45.145244  5307 solver.cpp:747] class AP 18: 0.434161
I0510 22:29:45.145675  5307 solver.cpp:747] class AP 19: 0.618719
I0510 22:29:45.146224  5307 solver.cpp:747] class AP 20: 0.446521
I0510 22:29:45.146230  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.491614
I0510 22:29:45.146399  5307 solver.cpp:283] Tests completed in 102.668s
I0510 22:29:45.713840  5307 solver.cpp:352] Iteration 44000 (0.974017 iter/s, 102.668s/100 iter), 85.1/232ep, loss = 3.40872
I0510 22:29:45.713865  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.29076 (* 1 = 3.29076 loss)
I0510 22:29:45.713871  5307 sgd_solver.cpp:172] Iteration 44000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:30:45.584980  5307 solver.cpp:352] Iteration 44100 (1.67028 iter/s, 59.8701s/100 iter), 85.3/232ep, loss = 3.56606
I0510 22:30:45.586292  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.71579 (* 1 = 3.71579 loss)
I0510 22:30:45.586303  5307 sgd_solver.cpp:172] Iteration 44100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:31:45.395543  5307 solver.cpp:352] Iteration 44200 (1.67197 iter/s, 59.8095s/100 iter), 85.5/232ep, loss = 3.64415
I0510 22:31:45.395606  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.41891 (* 1 = 4.41891 loss)
I0510 22:31:45.395613  5307 sgd_solver.cpp:172] Iteration 44200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:32:46.211119  5307 solver.cpp:352] Iteration 44300 (1.64434 iter/s, 60.8145s/100 iter), 85.7/232ep, loss = 3.5561
I0510 22:32:46.211210  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.11668 (* 1 = 4.11668 loss)
I0510 22:32:46.211227  5307 sgd_solver.cpp:172] Iteration 44300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:33:47.296813  5307 solver.cpp:352] Iteration 44400 (1.63707 iter/s, 61.0847s/100 iter), 85.8/232ep, loss = 3.65152
I0510 22:33:47.296867  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.57339 (* 1 = 4.57339 loss)
I0510 22:33:47.296875  5307 sgd_solver.cpp:172] Iteration 44400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:34:26.328572  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 22:34:48.634385  5307 solver.cpp:352] Iteration 44500 (1.63035 iter/s, 61.3365s/100 iter), 86/232ep, loss = 3.51682
I0510 22:34:48.634536  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.79272 (* 1 = 3.79272 loss)
I0510 22:34:48.634568  5307 sgd_solver.cpp:172] Iteration 44500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:35:49.449618  5307 solver.cpp:352] Iteration 44600 (1.64435 iter/s, 60.8142s/100 iter), 86.2/232ep, loss = 3.63962
I0510 22:35:49.451788  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.95575 (* 1 = 3.95575 loss)
I0510 22:35:49.451802  5307 sgd_solver.cpp:172] Iteration 44600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:36:50.505905  5307 solver.cpp:352] Iteration 44700 (1.63786 iter/s, 61.0553s/100 iter), 86.4/232ep, loss = 3.55994
I0510 22:36:50.506018  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.28054 (* 1 = 3.28054 loss)
I0510 22:36:50.506028  5307 sgd_solver.cpp:172] Iteration 44700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:37:51.268187  5307 solver.cpp:352] Iteration 44800 (1.64579 iter/s, 60.7613s/100 iter), 86.6/232ep, loss = 3.58286
I0510 22:37:51.268245  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.91869 (* 1 = 3.91869 loss)
I0510 22:37:51.268254  5307 sgd_solver.cpp:172] Iteration 44800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:38:52.239480  5307 solver.cpp:352] Iteration 44900 (1.64014 iter/s, 60.9703s/100 iter), 86.8/232ep, loss = 3.62117
I0510 22:38:52.241292  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.73229 (* 1 = 2.73229 loss)
I0510 22:38:52.241310  5307 sgd_solver.cpp:172] Iteration 44900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:39:40.497205  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 22:39:53.324957  5307 solver.cpp:352] Iteration 45000 (1.63708 iter/s, 61.0844s/100 iter), 87/232ep, loss = 3.54813
I0510 22:39:53.325136  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.86743 (* 1 = 2.86743 loss)
I0510 22:39:53.325163  5307 sgd_solver.cpp:172] Iteration 45000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:40:53.649266  5307 solver.cpp:352] Iteration 45100 (1.65773 iter/s, 60.3233s/100 iter), 87.2/232ep, loss = 3.34768
I0510 22:40:53.649327  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.63302 (* 1 = 3.63302 loss)
I0510 22:40:53.649335  5307 sgd_solver.cpp:172] Iteration 45100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:41:53.778311  5307 solver.cpp:352] Iteration 45200 (1.66312 iter/s, 60.128s/100 iter), 87.4/232ep, loss = 3.61005
I0510 22:41:53.778378  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.56444 (* 1 = 3.56444 loss)
I0510 22:41:53.778388  5307 sgd_solver.cpp:172] Iteration 45200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:42:54.838815  5307 solver.cpp:352] Iteration 45300 (1.63775 iter/s, 61.0595s/100 iter), 87.6/232ep, loss = 3.43124
I0510 22:42:54.838886  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.88264 (* 1 = 3.88264 loss)
I0510 22:42:54.838896  5307 sgd_solver.cpp:172] Iteration 45300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:43:55.382688  5307 solver.cpp:352] Iteration 45400 (1.65172 iter/s, 60.5428s/100 iter), 87.8/232ep, loss = 3.39923
I0510 22:43:55.382769  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.00722 (* 1 = 3.00722 loss)
I0510 22:43:55.382781  5307 sgd_solver.cpp:172] Iteration 45400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:44:53.739300  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 22:44:55.335280  5307 solver.cpp:352] Iteration 45500 (1.66801 iter/s, 59.9516s/100 iter), 88/232ep, loss = 3.77631
I0510 22:44:55.335304  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.65193 (* 1 = 3.65193 loss)
I0510 22:44:55.335312  5307 sgd_solver.cpp:172] Iteration 45500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:45:57.312166  5307 solver.cpp:352] Iteration 45600 (1.61353 iter/s, 61.9758s/100 iter), 88.2/232ep, loss = 3.60661
I0510 22:45:57.312297  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.44258 (* 1 = 3.44258 loss)
I0510 22:45:57.312321  5307 sgd_solver.cpp:172] Iteration 45600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:47:06.872303  5307 solver.cpp:352] Iteration 45700 (1.43763 iter/s, 69.559s/100 iter), 88.4/232ep, loss = 3.70569
I0510 22:47:06.872428  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.80139 (* 1 = 3.80139 loss)
I0510 22:47:06.872499  5307 sgd_solver.cpp:172] Iteration 45700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:48:08.359077  5307 solver.cpp:352] Iteration 45800 (1.62639 iter/s, 61.4857s/100 iter), 88.6/232ep, loss = 3.43112
I0510 22:48:08.359217  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.58173 (* 1 = 3.58173 loss)
I0510 22:48:08.359228  5307 sgd_solver.cpp:172] Iteration 45800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:49:09.033349  5307 solver.cpp:352] Iteration 45900 (1.64817 iter/s, 60.6732s/100 iter), 88.7/232ep, loss = 3.56771
I0510 22:49:09.033437  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.74137 (* 1 = 3.74137 loss)
I0510 22:49:09.033447  5307 sgd_solver.cpp:172] Iteration 45900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:50:08.859191  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_46000.caffemodel
I0510 22:50:08.871475  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_46000.solverstate
I0510 22:50:08.877465  5307 solver.cpp:635] Iteration 46000, Testing net (#0)
I0510 22:50:49.766000  5353 data_reader.cpp:320] Restarting data pre-fetching
I0510 22:50:50.001467  5307 solver.cpp:747] class AP 1: 0.505791
I0510 22:50:50.002292  5307 solver.cpp:747] class AP 2: 0.564018
I0510 22:50:50.012104  5307 solver.cpp:747] class AP 3: 0.350009
I0510 22:50:50.013630  5307 solver.cpp:747] class AP 4: 0.233533
I0510 22:50:50.032207  5307 solver.cpp:747] class AP 5: 0.18993
I0510 22:50:50.032379  5307 solver.cpp:747] class AP 6: 0.539161
I0510 22:50:50.035763  5307 solver.cpp:747] class AP 7: 0.567182
I0510 22:50:50.036207  5307 solver.cpp:747] class AP 8: 0.649454
I0510 22:50:50.061702  5307 solver.cpp:747] class AP 9: 0.276798
I0510 22:50:50.061992  5307 solver.cpp:747] class AP 10: 0.46867
I0510 22:50:50.062243  5307 solver.cpp:747] class AP 11: 0.443067
I0510 22:50:50.062950  5307 solver.cpp:747] class AP 12: 0.539027
I0510 22:50:50.063304  5307 solver.cpp:747] class AP 13: 0.625951
I0510 22:50:50.063649  5307 solver.cpp:747] class AP 14: 0.53717
I0510 22:50:50.126659  5307 solver.cpp:747] class AP 15: 0.567079
I0510 22:50:50.130455  5307 solver.cpp:747] class AP 16: 0.213157
I0510 22:50:50.132161  5307 solver.cpp:747] class AP 17: 0.450719
I0510 22:50:50.133276  5307 solver.cpp:747] class AP 18: 0.382244
I0510 22:50:50.133790  5307 solver.cpp:747] class AP 19: 0.491094
I0510 22:50:50.134387  5307 solver.cpp:747] class AP 20: 0.415519
I0510 22:50:50.134392  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.450479
I0510 22:50:50.134629  5307 solver.cpp:283] Tests completed in 101.1s
I0510 22:50:50.690054  5307 solver.cpp:352] Iteration 46000 (0.989124 iter/s, 101.1s/100 iter), 88.9/232ep, loss = 3.5812
I0510 22:50:50.690084  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.04849 (* 1 = 3.04849 loss)
I0510 22:50:50.690093  5307 sgd_solver.cpp:172] Iteration 46000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:50:59.990258  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 22:51:52.370064  5307 solver.cpp:352] Iteration 46100 (1.6213 iter/s, 61.6789s/100 iter), 89.1/232ep, loss = 3.6177
I0510 22:51:52.375166  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.14417 (* 1 = 3.14417 loss)
I0510 22:51:52.375182  5307 sgd_solver.cpp:172] Iteration 46100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:52:52.779439  5307 solver.cpp:352] Iteration 46200 (1.6554 iter/s, 60.4083s/100 iter), 89.3/232ep, loss = 3.5219
I0510 22:52:52.780040  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.57021 (* 1 = 3.57021 loss)
I0510 22:52:52.780048  5307 sgd_solver.cpp:172] Iteration 46200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:53:52.598860  5307 solver.cpp:352] Iteration 46300 (1.67173 iter/s, 59.8184s/100 iter), 89.5/232ep, loss = 3.51801
I0510 22:53:52.598942  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.62599 (* 1 = 4.62599 loss)
I0510 22:53:52.598951  5307 sgd_solver.cpp:172] Iteration 46300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:54:54.260977  5307 solver.cpp:352] Iteration 46400 (1.62177 iter/s, 61.6611s/100 iter), 89.7/232ep, loss = 3.51888
I0510 22:54:54.261050  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.83006 (* 1 = 3.83006 loss)
I0510 22:54:54.261060  5307 sgd_solver.cpp:172] Iteration 46400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:55:55.168646  5307 solver.cpp:352] Iteration 46500 (1.64186 iter/s, 60.9066s/100 iter), 89.9/232ep, loss = 3.59075
I0510 22:55:55.168771  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.46868 (* 1 = 3.46868 loss)
I0510 22:55:55.168786  5307 sgd_solver.cpp:172] Iteration 46500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:56:14.018493  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 22:56:55.430907  5307 solver.cpp:352] Iteration 46600 (1.65944 iter/s, 60.2613s/100 iter), 90.1/232ep, loss = 3.5544
I0510 22:56:55.430966  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.53938 (* 1 = 3.53938 loss)
I0510 22:56:55.430976  5307 sgd_solver.cpp:172] Iteration 46600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:57:55.534490  5307 solver.cpp:352] Iteration 46700 (1.66382 iter/s, 60.1026s/100 iter), 90.3/232ep, loss = 3.58514
I0510 22:57:55.534706  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.84802 (* 1 = 3.84802 loss)
I0510 22:57:55.534716  5307 sgd_solver.cpp:172] Iteration 46700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:58:56.183460  5307 solver.cpp:352] Iteration 46800 (1.64886 iter/s, 60.648s/100 iter), 90.5/232ep, loss = 3.73727
I0510 22:58:56.183609  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.74044 (* 1 = 3.74044 loss)
I0510 22:58:56.183665  5307 sgd_solver.cpp:172] Iteration 46800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 22:59:55.746423  5307 solver.cpp:352] Iteration 46900 (1.67892 iter/s, 59.562s/100 iter), 90.7/232ep, loss = 3.45096
I0510 22:59:55.747187  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.21738 (* 1 = 3.21738 loss)
I0510 22:59:55.747200  5307 sgd_solver.cpp:172] Iteration 46900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:00:56.605301  5307 solver.cpp:352] Iteration 47000 (1.64317 iter/s, 60.8579s/100 iter), 90.9/232ep, loss = 3.43792
I0510 23:00:56.605358  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.27902 (* 1 = 3.27902 loss)
I0510 23:00:56.605366  5307 sgd_solver.cpp:172] Iteration 47000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:01:25.881090  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 23:01:56.549991  5307 solver.cpp:352] Iteration 47100 (1.66823 iter/s, 59.9437s/100 iter), 91.1/232ep, loss = 3.42707
I0510 23:01:56.550885  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.03025 (* 1 = 4.03025 loss)
I0510 23:01:56.550915  5307 sgd_solver.cpp:172] Iteration 47100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:02:57.036665  5307 solver.cpp:352] Iteration 47200 (1.65328 iter/s, 60.4857s/100 iter), 91.3/232ep, loss = 3.7613
I0510 23:02:57.036772  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.40235 (* 1 = 3.40235 loss)
I0510 23:02:57.036782  5307 sgd_solver.cpp:172] Iteration 47200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:03:56.531098  5307 solver.cpp:352] Iteration 47300 (1.68086 iter/s, 59.4934s/100 iter), 91.5/232ep, loss = 3.48968
I0510 23:03:56.531193  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.02474 (* 1 = 3.02474 loss)
I0510 23:03:56.531200  5307 sgd_solver.cpp:172] Iteration 47300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:04:57.948027  5307 solver.cpp:352] Iteration 47400 (1.62824 iter/s, 61.4159s/100 iter), 91.6/232ep, loss = 3.50518
I0510 23:04:57.948096  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.26962 (* 1 = 3.26962 loss)
I0510 23:04:57.948105  5307 sgd_solver.cpp:172] Iteration 47400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:05:58.396701  5307 solver.cpp:352] Iteration 47500 (1.65432 iter/s, 60.4476s/100 iter), 91.8/232ep, loss = 3.48586
I0510 23:05:58.397729  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.72773 (* 1 = 3.72773 loss)
I0510 23:05:58.397742  5307 sgd_solver.cpp:172] Iteration 47500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:06:38.718721  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 23:06:59.352711  5307 solver.cpp:352] Iteration 47600 (1.64055 iter/s, 60.955s/100 iter), 92/232ep, loss = 3.41207
I0510 23:06:59.352737  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.55819 (* 1 = 3.55819 loss)
I0510 23:06:59.352746  5307 sgd_solver.cpp:172] Iteration 47600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:08:00.463523  5307 solver.cpp:352] Iteration 47700 (1.6364 iter/s, 61.1098s/100 iter), 92.2/232ep, loss = 3.60284
I0510 23:08:00.463587  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.78579 (* 1 = 3.78579 loss)
I0510 23:08:00.463596  5307 sgd_solver.cpp:172] Iteration 47700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:09:01.200682  5307 solver.cpp:352] Iteration 47800 (1.64647 iter/s, 60.7361s/100 iter), 92.4/232ep, loss = 3.47811
I0510 23:09:01.200820  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.30471 (* 1 = 3.30471 loss)
I0510 23:09:01.200846  5307 sgd_solver.cpp:172] Iteration 47800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:10:01.542644  5307 solver.cpp:352] Iteration 47900 (1.65725 iter/s, 60.341s/100 iter), 92.6/232ep, loss = 3.50561
I0510 23:10:01.542717  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.78229 (* 1 = 3.78229 loss)
I0510 23:10:01.542724  5307 sgd_solver.cpp:172] Iteration 47900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:11:01.568513  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_48000.caffemodel
I0510 23:11:01.588152  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_48000.solverstate
I0510 23:11:01.593969  5307 solver.cpp:635] Iteration 48000, Testing net (#0)
I0510 23:11:42.426506  5353 data_reader.cpp:320] Restarting data pre-fetching
I0510 23:11:42.629566  5307 solver.cpp:747] class AP 1: 0.561305
I0510 23:11:42.630336  5307 solver.cpp:747] class AP 2: 0.631307
I0510 23:11:42.641363  5307 solver.cpp:747] class AP 3: 0.430626
I0510 23:11:42.645922  5307 solver.cpp:747] class AP 4: 0.414595
I0510 23:11:42.659302  5307 solver.cpp:747] class AP 5: 0.252742
I0510 23:11:42.659512  5307 solver.cpp:747] class AP 6: 0.633689
I0510 23:11:42.666606  5307 solver.cpp:747] class AP 7: 0.623457
I0510 23:11:42.667166  5307 solver.cpp:747] class AP 8: 0.719229
I0510 23:11:42.683421  5307 solver.cpp:747] class AP 9: 0.326172
I0510 23:11:42.683758  5307 solver.cpp:747] class AP 10: 0.497288
I0510 23:11:42.684813  5307 solver.cpp:747] class AP 11: 0.421488
I0510 23:11:42.685557  5307 solver.cpp:747] class AP 12: 0.630654
I0510 23:11:42.685842  5307 solver.cpp:747] class AP 13: 0.69289
I0510 23:11:42.686149  5307 solver.cpp:747] class AP 14: 0.646715
I0510 23:11:42.750618  5307 solver.cpp:747] class AP 15: 0.665926
I0510 23:11:42.756969  5307 solver.cpp:747] class AP 16: 0.265218
I0510 23:11:42.757716  5307 solver.cpp:747] class AP 17: 0.466147
I0510 23:11:42.758103  5307 solver.cpp:747] class AP 18: 0.448701
I0510 23:11:42.758491  5307 solver.cpp:747] class AP 19: 0.658598
I0510 23:11:42.759832  5307 solver.cpp:747] class AP 20: 0.479947
I0510 23:11:42.759840  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.523335
I0510 23:11:42.760054  5307 solver.cpp:283] Tests completed in 101.216s
I0510 23:11:43.307546  5307 solver.cpp:352] Iteration 48000 (0.987989 iter/s, 101.216s/100 iter), 92.8/232ep, loss = 3.52073
I0510 23:11:43.307855  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.35066 (* 1 = 3.35066 loss)
I0510 23:11:43.307865  5307 sgd_solver.cpp:172] Iteration 48000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:12:33.688110  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 23:12:43.568645  5307 solver.cpp:352] Iteration 48100 (1.65947 iter/s, 60.26s/100 iter), 93/232ep, loss = 3.5282
I0510 23:12:43.568722  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.78314 (* 1 = 3.78314 loss)
I0510 23:12:43.568742  5307 sgd_solver.cpp:172] Iteration 48100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:13:43.754045  5307 solver.cpp:352] Iteration 48200 (1.66156 iter/s, 60.1844s/100 iter), 93.2/232ep, loss = 3.47301
I0510 23:13:43.754109  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.12876 (* 1 = 4.12876 loss)
I0510 23:13:43.754146  5307 sgd_solver.cpp:172] Iteration 48200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:14:43.993510  5307 solver.cpp:352] Iteration 48300 (1.66007 iter/s, 60.2384s/100 iter), 93.4/232ep, loss = 3.32308
I0510 23:14:43.993574  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.74263 (* 1 = 2.74263 loss)
I0510 23:14:43.993583  5307 sgd_solver.cpp:172] Iteration 48300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:15:44.278393  5307 solver.cpp:352] Iteration 48400 (1.65882 iter/s, 60.2839s/100 iter), 93.6/232ep, loss = 3.54178
I0510 23:15:44.278501  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.06438 (* 1 = 3.06438 loss)
I0510 23:15:44.278522  5307 sgd_solver.cpp:172] Iteration 48400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:16:45.246727  5307 solver.cpp:352] Iteration 48500 (1.64022 iter/s, 60.9673s/100 iter), 93.8/232ep, loss = 3.41037
I0510 23:16:45.247236  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.66525 (* 1 = 2.66525 loss)
I0510 23:16:45.247246  5307 sgd_solver.cpp:172] Iteration 48500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:17:46.222647  5307 solver.cpp:352] Iteration 48600 (1.64002 iter/s, 60.9749s/100 iter), 94/232ep, loss = 3.44866
I0510 23:17:46.222743  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.40669 (* 1 = 4.40669 loss)
I0510 23:17:46.222754  5307 sgd_solver.cpp:172] Iteration 48600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:17:46.884136  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 23:18:46.703645  5307 solver.cpp:352] Iteration 48700 (1.65344 iter/s, 60.48s/100 iter), 94.2/232ep, loss = 3.52651
I0510 23:18:46.703832  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.07363 (* 1 = 3.07363 loss)
I0510 23:18:46.703843  5307 sgd_solver.cpp:172] Iteration 48700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:19:46.584103  5307 solver.cpp:352] Iteration 48800 (1.67002 iter/s, 59.8794s/100 iter), 94.4/232ep, loss = 3.60143
I0510 23:19:46.584192  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.7301 (* 1 = 5.7301 loss)
I0510 23:19:46.584203  5307 sgd_solver.cpp:172] Iteration 48800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:20:47.415668  5307 solver.cpp:352] Iteration 48900 (1.64391 iter/s, 60.8305s/100 iter), 94.5/232ep, loss = 3.5456
I0510 23:20:47.415730  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.52771 (* 1 = 4.52771 loss)
I0510 23:20:47.415740  5307 sgd_solver.cpp:172] Iteration 48900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:21:48.702627  5307 solver.cpp:352] Iteration 49000 (1.6317 iter/s, 61.2859s/100 iter), 94.7/232ep, loss = 3.63742
I0510 23:21:48.702687  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.15913 (* 1 = 3.15913 loss)
I0510 23:21:48.702695  5307 sgd_solver.cpp:172] Iteration 49000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:22:49.551187  5307 solver.cpp:352] Iteration 49100 (1.64345 iter/s, 60.8475s/100 iter), 94.9/232ep, loss = 3.31566
I0510 23:22:49.551270  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.04667 (* 1 = 3.04667 loss)
I0510 23:22:49.551278  5307 sgd_solver.cpp:172] Iteration 49100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:22:59.950218  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 23:23:49.574358  5307 solver.cpp:352] Iteration 49200 (1.66605 iter/s, 60.0222s/100 iter), 95.1/232ep, loss = 3.35315
I0510 23:23:49.575289  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.41286 (* 1 = 3.41286 loss)
I0510 23:23:49.575297  5307 sgd_solver.cpp:172] Iteration 49200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:24:50.395352  5307 solver.cpp:352] Iteration 49300 (1.6442 iter/s, 60.82s/100 iter), 95.3/232ep, loss = 3.40763
I0510 23:24:50.395437  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.00214 (* 1 = 3.00214 loss)
I0510 23:24:50.395447  5307 sgd_solver.cpp:172] Iteration 49300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:25:50.372149  5307 solver.cpp:352] Iteration 49400 (1.66734 iter/s, 59.9758s/100 iter), 95.5/232ep, loss = 3.49907
I0510 23:25:50.372229  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.41385 (* 1 = 4.41385 loss)
I0510 23:25:50.372244  5307 sgd_solver.cpp:172] Iteration 49400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:26:50.997179  5307 solver.cpp:352] Iteration 49500 (1.64951 iter/s, 60.624s/100 iter), 95.7/232ep, loss = 3.59319
I0510 23:26:50.997364  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.9471 (* 1 = 2.9471 loss)
I0510 23:26:50.997385  5307 sgd_solver.cpp:172] Iteration 49500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:27:51.858150  5307 solver.cpp:352] Iteration 49600 (1.64312 iter/s, 60.8599s/100 iter), 95.9/232ep, loss = 3.64598
I0510 23:27:51.858709  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.03478 (* 1 = 3.03478 loss)
I0510 23:27:51.858719  5307 sgd_solver.cpp:172] Iteration 49600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:28:13.082340  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 23:28:52.739567  5307 solver.cpp:352] Iteration 49700 (1.64257 iter/s, 60.8804s/100 iter), 96.1/232ep, loss = 3.42936
I0510 23:28:52.740306  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.38264 (* 1 = 3.38264 loss)
I0510 23:28:52.740326  5307 sgd_solver.cpp:172] Iteration 49700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:29:52.705199  5307 solver.cpp:352] Iteration 49800 (1.66765 iter/s, 59.9646s/100 iter), 96.3/232ep, loss = 3.6499
I0510 23:29:52.705310  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.27572 (* 1 = 4.27572 loss)
I0510 23:29:52.705402  5307 sgd_solver.cpp:172] Iteration 49800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:30:53.042645  5307 solver.cpp:352] Iteration 49900 (1.65737 iter/s, 60.3364s/100 iter), 96.5/232ep, loss = 3.74318
I0510 23:30:53.042707  5307 solver.cpp:376]     Train net output #0: mbox_loss = 5.01434 (* 1 = 5.01434 loss)
I0510 23:30:53.042718  5307 sgd_solver.cpp:172] Iteration 49900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:31:53.273087  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_50000.caffemodel
I0510 23:31:53.290220  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_50000.solverstate
I0510 23:31:53.295753  5307 solver.cpp:635] Iteration 50000, Testing net (#0)
I0510 23:32:33.427985  5353 data_reader.cpp:320] Restarting data pre-fetching
I0510 23:32:33.640146  5307 solver.cpp:747] class AP 1: 0.498915
I0510 23:32:33.640626  5307 solver.cpp:747] class AP 2: 0.585154
I0510 23:32:33.648393  5307 solver.cpp:747] class AP 3: 0.417897
I0510 23:32:33.664778  5307 solver.cpp:747] class AP 4: 0.337787
I0510 23:32:33.674645  5307 solver.cpp:747] class AP 5: 0.251842
I0510 23:32:33.676306  5307 solver.cpp:747] class AP 6: 0.628646
I0510 23:32:33.684816  5307 solver.cpp:747] class AP 7: 0.572198
I0510 23:32:33.685539  5307 solver.cpp:747] class AP 8: 0.663112
I0510 23:32:33.709209  5307 solver.cpp:747] class AP 9: 0.282948
I0510 23:32:33.710723  5307 solver.cpp:747] class AP 10: 0.427062
I0510 23:32:33.711442  5307 solver.cpp:747] class AP 11: 0.48655
I0510 23:32:33.712664  5307 solver.cpp:747] class AP 12: 0.581236
I0510 23:32:33.713263  5307 solver.cpp:747] class AP 13: 0.654671
I0510 23:32:33.713531  5307 solver.cpp:747] class AP 14: 0.589124
I0510 23:32:33.759228  5307 solver.cpp:747] class AP 15: 0.633411
I0510 23:32:33.766373  5307 solver.cpp:747] class AP 16: 0.243572
I0510 23:32:33.774631  5307 solver.cpp:747] class AP 17: 0.457656
I0510 23:32:33.775758  5307 solver.cpp:747] class AP 18: 0.471969
I0510 23:32:33.776513  5307 solver.cpp:747] class AP 19: 0.627506
I0510 23:32:33.778980  5307 solver.cpp:747] class AP 20: 0.464373
I0510 23:32:33.778993  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.493781
I0510 23:32:33.779156  5307 solver.cpp:283] Tests completed in 100.735s
I0510 23:32:34.377696  5307 solver.cpp:352] Iteration 50000 (0.992705 iter/s, 100.735s/100 iter), 96.7/232ep, loss = 3.42507
I0510 23:32:34.377723  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.44672 (* 1 = 4.44672 loss)
I0510 23:32:34.377730  5307 sgd_solver.cpp:172] Iteration 50000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:33:35.872683  5307 solver.cpp:352] Iteration 50100 (1.62618 iter/s, 61.4939s/100 iter), 96.9/232ep, loss = 3.44612
I0510 23:33:35.873013  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.74043 (* 1 = 3.74043 loss)
I0510 23:33:35.873035  5307 sgd_solver.cpp:172] Iteration 50100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:34:07.855278  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 23:34:36.364137  5307 solver.cpp:352] Iteration 50200 (1.65315 iter/s, 60.4904s/100 iter), 97.1/232ep, loss = 3.55674
I0510 23:34:36.364169  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.44396 (* 1 = 4.44396 loss)
I0510 23:34:36.364176  5307 sgd_solver.cpp:172] Iteration 50200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:35:35.969579  5307 solver.cpp:352] Iteration 50300 (1.67773 iter/s, 59.6044s/100 iter), 97.3/232ep, loss = 3.51906
I0510 23:35:35.969683  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.32653 (* 1 = 4.32653 loss)
I0510 23:35:35.969761  5307 sgd_solver.cpp:172] Iteration 50300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:36:36.370111  5307 solver.cpp:352] Iteration 50400 (1.65564 iter/s, 60.3995s/100 iter), 97.4/232ep, loss = 3.47102
I0510 23:36:36.370185  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.71015 (* 1 = 3.71015 loss)
I0510 23:36:36.370198  5307 sgd_solver.cpp:172] Iteration 50400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:37:37.328444  5307 solver.cpp:352] Iteration 50500 (1.64049 iter/s, 60.9573s/100 iter), 97.6/232ep, loss = 3.49171
I0510 23:37:37.328510  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.7692 (* 1 = 2.7692 loss)
I0510 23:37:37.328521  5307 sgd_solver.cpp:172] Iteration 50500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:38:37.899471  5307 solver.cpp:352] Iteration 50600 (1.65098 iter/s, 60.57s/100 iter), 97.8/232ep, loss = 3.53187
I0510 23:38:37.899546  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.51964 (* 1 = 3.51964 loss)
I0510 23:38:37.899555  5307 sgd_solver.cpp:172] Iteration 50600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:39:19.902827  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 23:39:38.853461  5307 solver.cpp:352] Iteration 50700 (1.64061 iter/s, 60.953s/100 iter), 98/232ep, loss = 3.48521
I0510 23:39:38.853549  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.83649 (* 1 = 3.83649 loss)
I0510 23:39:38.853569  5307 sgd_solver.cpp:172] Iteration 50700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:40:39.750469  5307 solver.cpp:352] Iteration 50800 (1.64214 iter/s, 60.896s/100 iter), 98.2/232ep, loss = 3.33293
I0510 23:40:39.750550  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.94241 (* 1 = 3.94241 loss)
I0510 23:40:39.750560  5307 sgd_solver.cpp:172] Iteration 50800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:41:40.515030  5307 solver.cpp:352] Iteration 50900 (1.64572 iter/s, 60.7635s/100 iter), 98.4/232ep, loss = 3.48554
I0510 23:41:40.515100  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.14265 (* 1 = 3.14265 loss)
I0510 23:41:40.515107  5307 sgd_solver.cpp:172] Iteration 50900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:42:41.899195  5307 solver.cpp:352] Iteration 51000 (1.62911 iter/s, 61.3831s/100 iter), 98.6/232ep, loss = 3.37388
I0510 23:42:41.899366  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.59194 (* 1 = 3.59194 loss)
I0510 23:42:41.899385  5307 sgd_solver.cpp:172] Iteration 51000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:43:43.308969  5307 solver.cpp:352] Iteration 51100 (1.62843 iter/s, 61.4087s/100 iter), 98.8/232ep, loss = 3.53026
I0510 23:43:43.309039  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.1463 (* 1 = 3.1463 loss)
I0510 23:43:43.309047  5307 sgd_solver.cpp:172] Iteration 51100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:44:37.293272  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 23:44:45.357547  5307 solver.cpp:352] Iteration 51200 (1.61167 iter/s, 62.0475s/100 iter), 99/232ep, loss = 3.4011
I0510 23:44:45.357604  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.56569 (* 1 = 3.56569 loss)
I0510 23:44:45.357622  5307 sgd_solver.cpp:172] Iteration 51200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:45:47.347355  5307 solver.cpp:352] Iteration 51300 (1.6132 iter/s, 61.9888s/100 iter), 99.2/232ep, loss = 3.5833
I0510 23:45:47.347461  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.82223 (* 1 = 3.82223 loss)
I0510 23:45:47.347473  5307 sgd_solver.cpp:172] Iteration 51300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:46:49.121846  5307 solver.cpp:352] Iteration 51400 (1.61882 iter/s, 61.7735s/100 iter), 99.4/232ep, loss = 3.3464
I0510 23:46:49.122498  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.88903 (* 1 = 2.88903 loss)
I0510 23:46:49.122505  5307 sgd_solver.cpp:172] Iteration 51400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:47:50.326306  5307 solver.cpp:352] Iteration 51500 (1.6339 iter/s, 61.2034s/100 iter), 99.6/232ep, loss = 3.49587
I0510 23:47:50.326407  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.25812 (* 1 = 3.25812 loss)
I0510 23:47:50.326422  5307 sgd_solver.cpp:172] Iteration 51500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:48:50.905516  5307 solver.cpp:352] Iteration 51600 (1.65076 iter/s, 60.5782s/100 iter), 99.8/232ep, loss = 3.49921
I0510 23:48:50.905804  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.91085 (* 1 = 2.91085 loss)
I0510 23:48:50.905815  5307 sgd_solver.cpp:172] Iteration 51600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:49:52.094168  5307 solver.cpp:352] Iteration 51700 (1.63432 iter/s, 61.1876s/100 iter), 100/232ep, loss = 3.39004
I0510 23:49:52.094250  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.73419 (* 1 = 2.73419 loss)
I0510 23:49:52.094262  5307 sgd_solver.cpp:172] Iteration 51700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:49:53.973093  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 23:50:52.856155  5307 solver.cpp:352] Iteration 51800 (1.64579 iter/s, 60.761s/100 iter), 100.2/232ep, loss = 3.36415
I0510 23:50:52.856760  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.68732 (* 1 = 3.68732 loss)
I0510 23:50:52.856777  5307 sgd_solver.cpp:172] Iteration 51800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:51:54.498759  5307 solver.cpp:352] Iteration 51900 (1.62228 iter/s, 61.6416s/100 iter), 100.3/232ep, loss = 3.44527
I0510 23:51:54.498867  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.07261 (* 1 = 3.07261 loss)
I0510 23:51:54.498878  5307 sgd_solver.cpp:172] Iteration 51900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:52:55.465734  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_52000.caffemodel
I0510 23:52:55.483183  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_52000.solverstate
I0510 23:52:55.490092  5307 solver.cpp:635] Iteration 52000, Testing net (#0)
I0510 23:53:35.352563  5353 data_reader.cpp:320] Restarting data pre-fetching
I0510 23:53:35.534699  5307 solver.cpp:747] class AP 1: 0.518978
I0510 23:53:35.535761  5307 solver.cpp:747] class AP 2: 0.636386
I0510 23:53:35.548604  5307 solver.cpp:747] class AP 3: 0.366596
I0510 23:53:35.551271  5307 solver.cpp:747] class AP 4: 0.37599
I0510 23:53:35.572114  5307 solver.cpp:747] class AP 5: 0.227827
I0510 23:53:35.572397  5307 solver.cpp:747] class AP 6: 0.615003
I0510 23:53:35.578673  5307 solver.cpp:747] class AP 7: 0.608683
I0510 23:53:35.579653  5307 solver.cpp:747] class AP 8: 0.675214
I0510 23:53:35.606160  5307 solver.cpp:747] class AP 9: 0.318541
I0510 23:53:35.606945  5307 solver.cpp:747] class AP 10: 0.467367
I0510 23:53:35.607692  5307 solver.cpp:747] class AP 11: 0.484164
I0510 23:53:35.608516  5307 solver.cpp:747] class AP 12: 0.578948
I0510 23:53:35.608963  5307 solver.cpp:747] class AP 13: 0.713434
I0510 23:53:35.609189  5307 solver.cpp:747] class AP 14: 0.620618
I0510 23:53:35.680815  5307 solver.cpp:747] class AP 15: 0.642361
I0510 23:53:35.699427  5307 solver.cpp:747] class AP 16: 0.23837
I0510 23:53:35.703963  5307 solver.cpp:747] class AP 17: 0.460253
I0510 23:53:35.705580  5307 solver.cpp:747] class AP 18: 0.542439
I0510 23:53:35.706110  5307 solver.cpp:747] class AP 19: 0.657206
I0510 23:53:35.707695  5307 solver.cpp:747] class AP 20: 0.473692
I0510 23:53:35.707732  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.511103
I0510 23:53:35.707897  5307 solver.cpp:283] Tests completed in 101.207s
I0510 23:53:36.340836  5307 solver.cpp:352] Iteration 52000 (0.98807 iter/s, 101.207s/100 iter), 100.5/232ep, loss = 3.33154
I0510 23:53:36.340910  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.54616 (* 1 = 3.54616 loss)
I0510 23:53:36.340932  5307 sgd_solver.cpp:172] Iteration 52000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:54:44.919634  5307 solver.cpp:352] Iteration 52100 (1.4582 iter/s, 68.5776s/100 iter), 100.7/232ep, loss = 3.29883
I0510 23:54:44.922762  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.15171 (* 1 = 4.15171 loss)
I0510 23:54:44.922811  5307 sgd_solver.cpp:172] Iteration 52100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:55:47.649695  5307 solver.cpp:352] Iteration 52200 (1.59416 iter/s, 62.729s/100 iter), 100.9/232ep, loss = 3.4715
I0510 23:55:47.649773  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.65583 (* 1 = 3.65583 loss)
I0510 23:55:47.649786  5307 sgd_solver.cpp:172] Iteration 52200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:56:00.402654  5323 data_reader.cpp:320] Restarting data pre-fetching
I0510 23:56:47.282253  5307 solver.cpp:352] Iteration 52300 (1.67696 iter/s, 59.6315s/100 iter), 101.1/232ep, loss = 3.6139
I0510 23:56:47.282346  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.04672 (* 1 = 3.04672 loss)
I0510 23:56:47.282354  5307 sgd_solver.cpp:172] Iteration 52300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:57:48.046723  5307 solver.cpp:352] Iteration 52400 (1.64573 iter/s, 60.7634s/100 iter), 101.3/232ep, loss = 3.62294
I0510 23:57:48.046809  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.25532 (* 1 = 3.25532 loss)
I0510 23:57:48.046818  5307 sgd_solver.cpp:172] Iteration 52400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:58:48.641021  5307 solver.cpp:352] Iteration 52500 (1.65035 iter/s, 60.5933s/100 iter), 101.5/232ep, loss = 3.43837
I0510 23:58:48.641079  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.36506 (* 1 = 3.36506 loss)
I0510 23:58:48.641089  5307 sgd_solver.cpp:172] Iteration 52500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0510 23:59:49.140475  5307 solver.cpp:352] Iteration 52600 (1.65294 iter/s, 60.4984s/100 iter), 101.7/232ep, loss = 3.55552
I0510 23:59:49.140640  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.77614 (* 1 = 3.77614 loss)
I0510 23:59:49.140661  5307 sgd_solver.cpp:172] Iteration 52600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:00:49.939690  5307 solver.cpp:352] Iteration 52700 (1.64479 iter/s, 60.7982s/100 iter), 101.9/232ep, loss = 3.40258
I0511 00:00:49.939792  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.58967 (* 1 = 2.58967 loss)
I0511 00:00:49.939841  5307 sgd_solver.cpp:172] Iteration 52700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:01:13.674773  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 00:01:51.234668  5307 solver.cpp:352] Iteration 52800 (1.63148 iter/s, 61.2939s/100 iter), 102.1/232ep, loss = 3.52778
I0511 00:01:51.235667  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.6839 (* 1 = 3.6839 loss)
I0511 00:01:51.235677  5307 sgd_solver.cpp:172] Iteration 52800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:02:52.080087  5307 solver.cpp:352] Iteration 52900 (1.64354 iter/s, 60.8444s/100 iter), 102.3/232ep, loss = 3.51606
I0511 00:02:52.080184  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.61498 (* 1 = 2.61498 loss)
I0511 00:02:52.080193  5307 sgd_solver.cpp:172] Iteration 52900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:03:51.713644  5307 solver.cpp:352] Iteration 53000 (1.67694 iter/s, 59.6325s/100 iter), 102.5/232ep, loss = 3.56518
I0511 00:03:51.713754  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.98872 (* 1 = 2.98872 loss)
I0511 00:03:51.713768  5307 sgd_solver.cpp:172] Iteration 53000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:04:51.912704  5307 solver.cpp:352] Iteration 53100 (1.66118 iter/s, 60.198s/100 iter), 102.7/232ep, loss = 3.60422
I0511 00:04:51.912780  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.43261 (* 1 = 4.43261 loss)
I0511 00:04:51.912791  5307 sgd_solver.cpp:172] Iteration 53100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:05:52.756698  5307 solver.cpp:352] Iteration 53200 (1.64358 iter/s, 60.843s/100 iter), 102.9/232ep, loss = 3.65099
I0511 00:05:52.756784  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.59315 (* 1 = 3.59315 loss)
I0511 00:05:52.756800  5307 sgd_solver.cpp:172] Iteration 53200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:06:26.347018  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 00:06:53.908424  5307 solver.cpp:352] Iteration 53300 (1.6353 iter/s, 61.1507s/100 iter), 103.1/232ep, loss = 3.49781
I0511 00:06:53.908447  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.37101 (* 1 = 3.37101 loss)
I0511 00:06:53.908455  5307 sgd_solver.cpp:172] Iteration 53300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:07:55.388799  5307 solver.cpp:352] Iteration 53400 (1.62656 iter/s, 61.4793s/100 iter), 103.2/232ep, loss = 3.4449
I0511 00:07:55.388917  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.35449 (* 1 = 3.35449 loss)
I0511 00:07:55.388942  5307 sgd_solver.cpp:172] Iteration 53400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:08:55.777259  5307 solver.cpp:352] Iteration 53500 (1.65597 iter/s, 60.3874s/100 iter), 103.4/232ep, loss = 3.47036
I0511 00:08:55.777381  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.902 (* 1 = 3.902 loss)
I0511 00:08:55.777406  5307 sgd_solver.cpp:172] Iteration 53500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:09:55.897388  5307 solver.cpp:352] Iteration 53600 (1.66336 iter/s, 60.1191s/100 iter), 103.6/232ep, loss = 3.55858
I0511 00:09:55.897610  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.62222 (* 1 = 2.62222 loss)
I0511 00:09:55.897622  5307 sgd_solver.cpp:172] Iteration 53600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:10:55.804698  5307 solver.cpp:352] Iteration 53700 (1.66927 iter/s, 59.9063s/100 iter), 103.8/232ep, loss = 3.53354
I0511 00:10:55.804759  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.07751 (* 1 = 3.07751 loss)
I0511 00:10:55.804765  5307 sgd_solver.cpp:172] Iteration 53700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:11:39.663512  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 00:11:56.229519  5307 solver.cpp:352] Iteration 53800 (1.65498 iter/s, 60.4238s/100 iter), 104/232ep, loss = 3.35147
I0511 00:11:56.229543  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.7491 (* 1 = 2.7491 loss)
I0511 00:11:56.229549  5307 sgd_solver.cpp:172] Iteration 53800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:12:56.770020  5307 solver.cpp:352] Iteration 53900 (1.65181 iter/s, 60.5395s/100 iter), 104.2/232ep, loss = 3.51365
I0511 00:12:56.770087  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.95267 (* 1 = 2.95267 loss)
I0511 00:12:56.770093  5307 sgd_solver.cpp:172] Iteration 53900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:13:56.372295  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_54000.caffemodel
I0511 00:13:56.389125  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_54000.solverstate
I0511 00:13:56.394472  5307 solver.cpp:635] Iteration 54000, Testing net (#0)
I0511 00:14:37.672940  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 00:14:37.919394  5307 solver.cpp:747] class AP 1: 0.525506
I0511 00:14:37.919723  5307 solver.cpp:747] class AP 2: 0.623355
I0511 00:14:37.921825  5307 solver.cpp:747] class AP 3: 0.432165
I0511 00:14:37.923365  5307 solver.cpp:747] class AP 4: 0.382349
I0511 00:14:37.949615  5307 solver.cpp:747] class AP 5: 0.247984
I0511 00:14:37.949892  5307 solver.cpp:747] class AP 6: 0.653941
I0511 00:14:37.955955  5307 solver.cpp:747] class AP 7: 0.630902
I0511 00:14:37.956923  5307 solver.cpp:747] class AP 8: 0.71827
I0511 00:14:37.979024  5307 solver.cpp:747] class AP 9: 0.326747
I0511 00:14:37.979353  5307 solver.cpp:747] class AP 10: 0.480525
I0511 00:14:37.980017  5307 solver.cpp:747] class AP 11: 0.530881
I0511 00:14:37.980465  5307 solver.cpp:747] class AP 12: 0.623067
I0511 00:14:37.980967  5307 solver.cpp:747] class AP 13: 0.69642
I0511 00:14:37.981154  5307 solver.cpp:747] class AP 14: 0.665992
I0511 00:14:38.042522  5307 solver.cpp:747] class AP 15: 0.670577
I0511 00:14:38.047544  5307 solver.cpp:747] class AP 16: 0.282663
I0511 00:14:38.048463  5307 solver.cpp:747] class AP 17: 0.492775
I0511 00:14:38.049235  5307 solver.cpp:747] class AP 18: 0.524552
I0511 00:14:38.050112  5307 solver.cpp:747] class AP 19: 0.65139
I0511 00:14:38.052436  5307 solver.cpp:747] class AP 20: 0.517409
I0511 00:14:38.052445  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.533873
I0511 00:14:38.052774  5307 solver.cpp:283] Tests completed in 101.281s
I0511 00:14:38.590441  5307 solver.cpp:352] Iteration 54000 (0.987352 iter/s, 101.281s/100 iter), 104.4/232ep, loss = 3.6458
I0511 00:14:38.590467  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.11997 (* 1 = 4.11997 loss)
I0511 00:14:38.590474  5307 sgd_solver.cpp:172] Iteration 54000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:15:37.921257  5307 solver.cpp:352] Iteration 54100 (1.68549 iter/s, 59.3298s/100 iter), 104.6/232ep, loss = 3.58635
I0511 00:15:37.921360  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.27227 (* 1 = 3.27227 loss)
I0511 00:15:37.921370  5307 sgd_solver.cpp:172] Iteration 54100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:16:37.701010  5307 solver.cpp:352] Iteration 54200 (1.67284 iter/s, 59.7787s/100 iter), 104.8/232ep, loss = 3.72543
I0511 00:16:37.702693  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.84609 (* 1 = 3.84609 loss)
I0511 00:16:37.702716  5307 sgd_solver.cpp:172] Iteration 54200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:17:31.908587  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 00:17:38.575501  5307 solver.cpp:352] Iteration 54300 (1.64275 iter/s, 60.8734s/100 iter), 105/232ep, loss = 3.60018
I0511 00:17:38.575531  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.38112 (* 1 = 3.38112 loss)
I0511 00:17:38.575538  5307 sgd_solver.cpp:172] Iteration 54300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:18:38.992295  5307 solver.cpp:352] Iteration 54400 (1.6552 iter/s, 60.4158s/100 iter), 105.2/232ep, loss = 3.65693
I0511 00:18:38.992363  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.51708 (* 1 = 2.51708 loss)
I0511 00:18:38.992372  5307 sgd_solver.cpp:172] Iteration 54400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:19:39.192565  5307 solver.cpp:352] Iteration 54500 (1.66115 iter/s, 60.1992s/100 iter), 105.4/232ep, loss = 3.34804
I0511 00:19:39.192680  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.07612 (* 1 = 4.07612 loss)
I0511 00:19:39.192697  5307 sgd_solver.cpp:172] Iteration 54500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:20:39.840927  5307 solver.cpp:352] Iteration 54600 (1.64888 iter/s, 60.6473s/100 iter), 105.6/232ep, loss = 3.49878
I0511 00:20:39.841084  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.6027 (* 1 = 4.6027 loss)
I0511 00:20:39.841110  5307 sgd_solver.cpp:172] Iteration 54600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:21:40.356724  5307 solver.cpp:352] Iteration 54700 (1.65249 iter/s, 60.5148s/100 iter), 105.8/232ep, loss = 3.41457
I0511 00:21:40.356827  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.73008 (* 1 = 2.73008 loss)
I0511 00:21:40.356837  5307 sgd_solver.cpp:172] Iteration 54700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:22:40.322903  5307 solver.cpp:352] Iteration 54800 (1.66763 iter/s, 59.9652s/100 iter), 106/232ep, loss = 3.46247
I0511 00:22:40.324194  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.50552 (* 1 = 2.50552 loss)
I0511 00:22:40.324211  5307 sgd_solver.cpp:172] Iteration 54800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:22:44.903548  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 00:23:40.294348  5307 solver.cpp:352] Iteration 54900 (1.66749 iter/s, 59.9704s/100 iter), 106.1/232ep, loss = 3.46535
I0511 00:23:40.294414  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.37254 (* 1 = 3.37254 loss)
I0511 00:23:40.294423  5307 sgd_solver.cpp:172] Iteration 54900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:24:40.674048  5307 solver.cpp:352] Iteration 55000 (1.65621 iter/s, 60.3787s/100 iter), 106.3/232ep, loss = 3.60302
I0511 00:24:40.674123  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.72011 (* 1 = 3.72011 loss)
I0511 00:24:40.674132  5307 sgd_solver.cpp:172] Iteration 55000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:25:42.052397  5307 solver.cpp:352] Iteration 55100 (1.62927 iter/s, 61.3773s/100 iter), 106.5/232ep, loss = 3.48589
I0511 00:25:42.052486  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.69904 (* 1 = 2.69904 loss)
I0511 00:25:42.052500  5307 sgd_solver.cpp:172] Iteration 55100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:26:41.886087  5307 solver.cpp:352] Iteration 55200 (1.67133 iter/s, 59.8327s/100 iter), 106.7/232ep, loss = 3.52104
I0511 00:26:41.886149  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.02414 (* 1 = 4.02414 loss)
I0511 00:26:41.886157  5307 sgd_solver.cpp:172] Iteration 55200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:27:42.614260  5307 solver.cpp:352] Iteration 55300 (1.64671 iter/s, 60.7271s/100 iter), 106.9/232ep, loss = 3.50302
I0511 00:27:42.614336  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.99667 (* 1 = 2.99667 loss)
I0511 00:27:42.614346  5307 sgd_solver.cpp:172] Iteration 55300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:27:57.643421  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 00:28:42.579155  5307 solver.cpp:352] Iteration 55400 (1.66767 iter/s, 59.9639s/100 iter), 107.1/232ep, loss = 3.60342
I0511 00:28:42.579264  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.53387 (* 1 = 3.53387 loss)
I0511 00:28:42.579288  5307 sgd_solver.cpp:172] Iteration 55400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:29:43.274452  5307 solver.cpp:352] Iteration 55500 (1.6476 iter/s, 60.6943s/100 iter), 107.3/232ep, loss = 3.50229
I0511 00:29:43.274533  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.57112 (* 1 = 3.57112 loss)
I0511 00:29:43.274541  5307 sgd_solver.cpp:172] Iteration 55500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:30:43.800295  5307 solver.cpp:352] Iteration 55600 (1.65222 iter/s, 60.5248s/100 iter), 107.5/232ep, loss = 3.44192
I0511 00:30:43.804119  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.46049 (* 1 = 3.46049 loss)
I0511 00:30:43.804157  5307 sgd_solver.cpp:172] Iteration 55600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:31:44.431244  5307 solver.cpp:352] Iteration 55700 (1.64935 iter/s, 60.6299s/100 iter), 107.7/232ep, loss = 3.45246
I0511 00:31:44.431331  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.46113 (* 1 = 2.46113 loss)
I0511 00:31:44.431356  5307 sgd_solver.cpp:172] Iteration 55700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:32:45.694702  5307 solver.cpp:352] Iteration 55800 (1.63232 iter/s, 61.2624s/100 iter), 107.9/232ep, loss = 3.40326
I0511 00:32:45.694761  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.0129 (* 1 = 3.0129 loss)
I0511 00:32:45.694770  5307 sgd_solver.cpp:172] Iteration 55800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:33:10.587299  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 00:33:46.352715  5307 solver.cpp:352] Iteration 55900 (1.64862 iter/s, 60.6569s/100 iter), 108.1/232ep, loss = 3.54755
I0511 00:33:46.352850  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.69712 (* 1 = 3.69712 loss)
I0511 00:33:46.352869  5307 sgd_solver.cpp:172] Iteration 55900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:34:46.579649  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_56000.caffemodel
I0511 00:34:46.599112  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_56000.solverstate
I0511 00:34:46.605146  5307 solver.cpp:635] Iteration 56000, Testing net (#0)
I0511 00:35:27.777395  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 00:35:28.025400  5307 solver.cpp:747] class AP 1: 0.535526
I0511 00:35:28.026069  5307 solver.cpp:747] class AP 2: 0.638728
I0511 00:35:28.036048  5307 solver.cpp:747] class AP 3: 0.429233
I0511 00:35:28.038990  5307 solver.cpp:747] class AP 4: 0.333136
I0511 00:35:28.053520  5307 solver.cpp:747] class AP 5: 0.211951
I0511 00:35:28.053802  5307 solver.cpp:747] class AP 6: 0.661569
I0511 00:35:28.064337  5307 solver.cpp:747] class AP 7: 0.616551
I0511 00:35:28.064812  5307 solver.cpp:747] class AP 8: 0.672303
I0511 00:35:28.090167  5307 solver.cpp:747] class AP 9: 0.349538
I0511 00:35:28.090848  5307 solver.cpp:747] class AP 10: 0.511583
I0511 00:35:28.091517  5307 solver.cpp:747] class AP 11: 0.503518
I0511 00:35:28.092128  5307 solver.cpp:747] class AP 12: 0.58544
I0511 00:35:28.092429  5307 solver.cpp:747] class AP 13: 0.694684
I0511 00:35:28.092682  5307 solver.cpp:747] class AP 14: 0.630494
I0511 00:35:28.145862  5307 solver.cpp:747] class AP 15: 0.655244
I0511 00:35:28.150086  5307 solver.cpp:747] class AP 16: 0.245485
I0511 00:35:28.153009  5307 solver.cpp:747] class AP 17: 0.516143
I0511 00:35:28.153900  5307 solver.cpp:747] class AP 18: 0.465221
I0511 00:35:28.154693  5307 solver.cpp:747] class AP 19: 0.633202
I0511 00:35:28.155895  5307 solver.cpp:747] class AP 20: 0.515829
I0511 00:35:28.155906  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.520269
I0511 00:35:28.156122  5307 solver.cpp:283] Tests completed in 101.802s
I0511 00:35:28.712455  5307 solver.cpp:352] Iteration 56000 (0.982302 iter/s, 101.802s/100 iter), 108.3/232ep, loss = 3.7071
I0511 00:35:28.712481  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.10523 (* 1 = 3.10523 loss)
I0511 00:35:28.712489  5307 sgd_solver.cpp:172] Iteration 56000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:36:28.768484  5307 solver.cpp:352] Iteration 56100 (1.66514 iter/s, 60.055s/100 iter), 108.5/232ep, loss = 3.5618
I0511 00:36:28.768560  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.67482 (* 1 = 3.67482 loss)
I0511 00:36:28.768570  5307 sgd_solver.cpp:172] Iteration 56100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:37:29.082165  5307 solver.cpp:352] Iteration 56200 (1.65803 iter/s, 60.3126s/100 iter), 108.7/232ep, loss = 3.36023
I0511 00:37:29.083581  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.33626 (* 1 = 3.33626 loss)
I0511 00:37:29.083616  5307 sgd_solver.cpp:172] Iteration 56200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:38:30.046433  5307 solver.cpp:352] Iteration 56300 (1.64033 iter/s, 60.9632s/100 iter), 108.9/232ep, loss = 3.67072
I0511 00:38:30.046625  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.69164 (* 1 = 3.69164 loss)
I0511 00:38:30.046633  5307 sgd_solver.cpp:172] Iteration 56300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:39:05.675428  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 00:39:29.936378  5307 solver.cpp:352] Iteration 56400 (1.66976 iter/s, 59.8889s/100 iter), 109/232ep, loss = 3.347
I0511 00:39:29.936400  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.32941 (* 1 = 3.32941 loss)
I0511 00:39:29.936405  5307 sgd_solver.cpp:172] Iteration 56400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:40:30.386986  5307 solver.cpp:352] Iteration 56500 (1.65427 iter/s, 60.4496s/100 iter), 109.2/232ep, loss = 3.47285
I0511 00:40:30.387064  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.59983 (* 1 = 3.59983 loss)
I0511 00:40:30.387073  5307 sgd_solver.cpp:172] Iteration 56500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:41:30.451970  5307 solver.cpp:352] Iteration 56600 (1.66489 iter/s, 60.064s/100 iter), 109.4/232ep, loss = 3.34361
I0511 00:41:30.452033  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.31377 (* 1 = 3.31377 loss)
I0511 00:41:30.452042  5307 sgd_solver.cpp:172] Iteration 56600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:42:31.110832  5307 solver.cpp:352] Iteration 56700 (1.64859 iter/s, 60.6578s/100 iter), 109.6/232ep, loss = 3.63717
I0511 00:42:31.110963  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.51525 (* 1 = 3.51525 loss)
I0511 00:42:31.110978  5307 sgd_solver.cpp:172] Iteration 56700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:43:31.553923  5307 solver.cpp:352] Iteration 56800 (1.65448 iter/s, 60.4421s/100 iter), 109.8/232ep, loss = 3.71151
I0511 00:43:31.553988  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.05874 (* 1 = 4.05874 loss)
I0511 00:43:31.553997  5307 sgd_solver.cpp:172] Iteration 56800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:44:18.155795  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 00:44:32.454998  5307 solver.cpp:352] Iteration 56900 (1.64204 iter/s, 60.9s/100 iter), 110/232ep, loss = 3.56385
I0511 00:44:32.455027  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.38724 (* 1 = 3.38724 loss)
I0511 00:44:32.455034  5307 sgd_solver.cpp:172] Iteration 56900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:45:32.628466  5307 solver.cpp:352] Iteration 57000 (1.66189 iter/s, 60.1725s/100 iter), 110.2/232ep, loss = 3.36299
I0511 00:45:32.628590  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.87368 (* 1 = 3.87368 loss)
I0511 00:45:32.628612  5307 sgd_solver.cpp:172] Iteration 57000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:46:33.259104  5307 solver.cpp:352] Iteration 57100 (1.64936 iter/s, 60.6296s/100 iter), 110.4/232ep, loss = 3.57393
I0511 00:46:33.259186  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.70297 (* 1 = 3.70297 loss)
I0511 00:46:33.259202  5307 sgd_solver.cpp:172] Iteration 57100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:47:34.351581  5307 solver.cpp:352] Iteration 57200 (1.63689 iter/s, 61.0914s/100 iter), 110.6/232ep, loss = 3.46394
I0511 00:47:34.351634  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.81547 (* 1 = 2.81547 loss)
I0511 00:47:34.351642  5307 sgd_solver.cpp:172] Iteration 57200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:48:34.817998  5307 solver.cpp:352] Iteration 57300 (1.65384 iter/s, 60.4654s/100 iter), 110.8/232ep, loss = 3.3979
I0511 00:48:34.818073  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.7929 (* 1 = 2.7929 loss)
I0511 00:48:34.818079  5307 sgd_solver.cpp:172] Iteration 57300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:49:32.352228  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 00:49:36.503605  5307 solver.cpp:352] Iteration 57400 (1.62115 iter/s, 61.6846s/100 iter), 111/232ep, loss = 3.83276
I0511 00:49:36.503638  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.1509 (* 1 = 3.1509 loss)
I0511 00:49:36.503646  5307 sgd_solver.cpp:172] Iteration 57400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:50:38.050436  5307 solver.cpp:352] Iteration 57500 (1.62481 iter/s, 61.5458s/100 iter), 111.2/232ep, loss = 3.42789
I0511 00:50:38.050493  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.65941 (* 1 = 3.65941 loss)
I0511 00:50:38.050503  5307 sgd_solver.cpp:172] Iteration 57500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:51:40.025753  5307 solver.cpp:352] Iteration 57600 (1.61357 iter/s, 61.9743s/100 iter), 111.4/232ep, loss = 3.73921
I0511 00:51:40.026000  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.20821 (* 1 = 4.20821 loss)
I0511 00:51:40.026042  5307 sgd_solver.cpp:172] Iteration 57600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:52:41.653494  5307 solver.cpp:352] Iteration 57700 (1.62267 iter/s, 61.6267s/100 iter), 111.6/232ep, loss = 3.42248
I0511 00:52:41.653587  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.36359 (* 1 = 3.36359 loss)
I0511 00:52:41.653602  5307 sgd_solver.cpp:172] Iteration 57700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:53:42.557371  5307 solver.cpp:352] Iteration 57800 (1.64196 iter/s, 60.9028s/100 iter), 111.8/232ep, loss = 3.44499
I0511 00:53:42.557584  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.86643 (* 1 = 3.86643 loss)
I0511 00:53:42.557593  5307 sgd_solver.cpp:172] Iteration 57800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:54:43.308697  5307 solver.cpp:352] Iteration 57900 (1.64608 iter/s, 60.7503s/100 iter), 111.9/232ep, loss = 3.27644
I0511 00:54:43.308866  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.78733 (* 1 = 2.78733 loss)
I0511 00:54:43.308876  5307 sgd_solver.cpp:172] Iteration 57900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:54:50.058835  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 00:55:43.244065  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_58000.caffemodel
I0511 00:55:43.258394  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_58000.solverstate
I0511 00:55:43.266721  5307 solver.cpp:635] Iteration 58000, Testing net (#0)
I0511 00:56:24.250465  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 00:56:24.440966  5307 solver.cpp:747] class AP 1: 0.536921
I0511 00:56:24.441691  5307 solver.cpp:747] class AP 2: 0.636741
I0511 00:56:24.448153  5307 solver.cpp:747] class AP 3: 0.475505
I0511 00:56:24.453078  5307 solver.cpp:747] class AP 4: 0.408649
I0511 00:56:24.466481  5307 solver.cpp:747] class AP 5: 0.271112
I0511 00:56:24.466751  5307 solver.cpp:747] class AP 6: 0.634191
I0511 00:56:24.474997  5307 solver.cpp:747] class AP 7: 0.636721
I0511 00:56:24.475579  5307 solver.cpp:747] class AP 8: 0.72689
I0511 00:56:24.498325  5307 solver.cpp:747] class AP 9: 0.362138
I0511 00:56:24.499078  5307 solver.cpp:747] class AP 10: 0.496736
I0511 00:56:24.500514  5307 solver.cpp:747] class AP 11: 0.492416
I0511 00:56:24.501749  5307 solver.cpp:747] class AP 12: 0.646025
I0511 00:56:24.502315  5307 solver.cpp:747] class AP 13: 0.765683
I0511 00:56:24.502632  5307 solver.cpp:747] class AP 14: 0.669449
I0511 00:56:24.566150  5307 solver.cpp:747] class AP 15: 0.672423
I0511 00:56:24.569351  5307 solver.cpp:747] class AP 16: 0.284018
I0511 00:56:24.570860  5307 solver.cpp:747] class AP 17: 0.476287
I0511 00:56:24.571535  5307 solver.cpp:747] class AP 18: 0.55905
I0511 00:56:24.572093  5307 solver.cpp:747] class AP 19: 0.676947
I0511 00:56:24.572917  5307 solver.cpp:747] class AP 20: 0.550362
I0511 00:56:24.572924  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.548913
I0511 00:56:24.573099  5307 solver.cpp:283] Tests completed in 101.263s
I0511 00:56:25.165314  5307 solver.cpp:352] Iteration 58000 (0.98753 iter/s, 101.263s/100 iter), 112.1/232ep, loss = 3.30281
I0511 00:56:25.165344  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.47412 (* 1 = 3.47412 loss)
I0511 00:56:25.165351  5307 sgd_solver.cpp:172] Iteration 58000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:57:25.432214  5307 solver.cpp:352] Iteration 58100 (1.65931 iter/s, 60.2658s/100 iter), 112.3/232ep, loss = 3.57495
I0511 00:57:25.432303  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.09301 (* 1 = 3.09301 loss)
I0511 00:57:25.432313  5307 sgd_solver.cpp:172] Iteration 58100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:58:25.854038  5307 solver.cpp:352] Iteration 58200 (1.65506 iter/s, 60.4207s/100 iter), 112.5/232ep, loss = 3.37738
I0511 00:58:25.854207  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.47003 (* 1 = 3.47003 loss)
I0511 00:58:25.854228  5307 sgd_solver.cpp:172] Iteration 58200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 00:59:25.874824  5307 solver.cpp:352] Iteration 58300 (1.66612 iter/s, 60.0198s/100 iter), 112.7/232ep, loss = 3.43581
I0511 00:59:25.874918  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.27225 (* 1 = 3.27225 loss)
I0511 00:59:25.874928  5307 sgd_solver.cpp:172] Iteration 58300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 01:00:27.051739  5307 solver.cpp:352] Iteration 58400 (1.63463 iter/s, 61.1759s/100 iter), 112.9/232ep, loss = 3.4495
I0511 01:00:27.051857  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.92781 (* 1 = 2.92781 loss)
I0511 01:00:27.051867  5307 sgd_solver.cpp:172] Iteration 58400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 01:00:43.793057  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 01:01:30.215191  5307 solver.cpp:352] Iteration 58500 (1.58322 iter/s, 63.1624s/100 iter), 113.1/232ep, loss = 3.54849
I0511 01:01:30.217983  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.15411 (* 1 = 3.15411 loss)
I0511 01:01:30.218010  5307 sgd_solver.cpp:172] Iteration 58500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 01:02:39.419816  5307 solver.cpp:352] Iteration 58600 (1.44501 iter/s, 69.2034s/100 iter), 113.3/232ep, loss = 3.44474
I0511 01:02:39.419972  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.19437 (* 1 = 3.19437 loss)
I0511 01:02:39.419981  5307 sgd_solver.cpp:172] Iteration 58600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 01:03:41.282872  5307 solver.cpp:352] Iteration 58700 (1.6165 iter/s, 61.862s/100 iter), 113.5/232ep, loss = 3.48314
I0511 01:03:41.282948  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.47422 (* 1 = 3.47422 loss)
I0511 01:03:41.282958  5307 sgd_solver.cpp:172] Iteration 58700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 01:04:42.387756  5307 solver.cpp:352] Iteration 58800 (1.63656 iter/s, 61.1038s/100 iter), 113.7/232ep, loss = 3.30446
I0511 01:04:42.387814  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.03247 (* 1 = 4.03247 loss)
I0511 01:04:42.387821  5307 sgd_solver.cpp:172] Iteration 58800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 01:05:42.568261  5307 solver.cpp:352] Iteration 58900 (1.6617 iter/s, 60.1795s/100 iter), 113.9/232ep, loss = 3.26982
I0511 01:05:42.568331  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.71852 (* 1 = 2.71852 loss)
I0511 01:05:42.568341  5307 sgd_solver.cpp:172] Iteration 58900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 01:06:09.855984  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 01:06:43.287122  5307 solver.cpp:352] Iteration 59000 (1.64696 iter/s, 60.7178s/100 iter), 114.1/232ep, loss = 3.40579
I0511 01:06:43.287201  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.13 (* 1 = 3.13 loss)
I0511 01:06:43.287211  5307 sgd_solver.cpp:172] Iteration 59000, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 01:07:43.903594  5307 solver.cpp:352] Iteration 59100 (1.64974 iter/s, 60.6154s/100 iter), 114.3/232ep, loss = 3.52119
I0511 01:07:43.903730  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.2336 (* 1 = 3.2336 loss)
I0511 01:07:43.903741  5307 sgd_solver.cpp:172] Iteration 59100, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 01:08:44.515570  5307 solver.cpp:352] Iteration 59200 (1.64987 iter/s, 60.611s/100 iter), 114.5/232ep, loss = 3.51671
I0511 01:08:44.515648  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.63872 (* 1 = 3.63872 loss)
I0511 01:08:44.515664  5307 sgd_solver.cpp:172] Iteration 59200, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 01:09:44.930148  5307 solver.cpp:352] Iteration 59300 (1.65526 iter/s, 60.4136s/100 iter), 114.7/232ep, loss = 3.38098
I0511 01:09:44.930215  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.86821 (* 1 = 3.86821 loss)
I0511 01:09:44.930222  5307 sgd_solver.cpp:172] Iteration 59300, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 01:10:44.699968  5307 solver.cpp:352] Iteration 59400 (1.67311 iter/s, 59.7688s/100 iter), 114.8/232ep, loss = 3.61522
I0511 01:10:44.700042  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.49936 (* 1 = 3.49936 loss)
I0511 01:10:44.700050  5307 sgd_solver.cpp:172] Iteration 59400, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 01:11:22.176784  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 01:11:44.708138  5307 solver.cpp:352] Iteration 59500 (1.66647 iter/s, 60.0071s/100 iter), 115/232ep, loss = 3.24844
I0511 01:11:44.708240  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.93217 (* 1 = 2.93217 loss)
I0511 01:11:44.708266  5307 sgd_solver.cpp:172] Iteration 59500, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 01:12:45.026967  5307 solver.cpp:352] Iteration 59600 (1.65788 iter/s, 60.3178s/100 iter), 115.2/232ep, loss = 3.47464
I0511 01:12:45.027045  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.0506 (* 1 = 4.0506 loss)
I0511 01:12:45.027056  5307 sgd_solver.cpp:172] Iteration 59600, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 01:13:45.293133  5307 solver.cpp:352] Iteration 59700 (1.65933 iter/s, 60.2651s/100 iter), 115.4/232ep, loss = 3.29606
I0511 01:13:45.293268  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.21834 (* 1 = 2.21834 loss)
I0511 01:13:45.293280  5307 sgd_solver.cpp:172] Iteration 59700, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 01:14:45.865222  5307 solver.cpp:352] Iteration 59800 (1.65095 iter/s, 60.5711s/100 iter), 115.6/232ep, loss = 3.48137
I0511 01:14:45.865280  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.19146 (* 1 = 3.19146 loss)
I0511 01:14:45.865288  5307 sgd_solver.cpp:172] Iteration 59800, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 01:15:45.711884  5307 solver.cpp:352] Iteration 59900 (1.67097 iter/s, 59.8456s/100 iter), 115.8/232ep, loss = 3.47236
I0511 01:15:45.711971  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.97808 (* 1 = 2.97808 loss)
I0511 01:15:45.711985  5307 sgd_solver.cpp:172] Iteration 59900, lr = 0.01, m = 0.9, wd = 0.0001, gs = 1
I0511 01:16:34.266850  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 01:16:46.247411  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_60000.caffemodel
I0511 01:16:46.265805  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_60000.solverstate
I0511 01:16:46.271970  5307 solver.cpp:635] Iteration 60000, Testing net (#0)
I0511 01:17:26.765581  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 01:17:26.971472  5307 solver.cpp:747] class AP 1: 0.574086
I0511 01:17:26.971858  5307 solver.cpp:747] class AP 2: 0.613003
I0511 01:17:26.980267  5307 solver.cpp:747] class AP 3: 0.452021
I0511 01:17:26.987545  5307 solver.cpp:747] class AP 4: 0.332015
I0511 01:17:27.011425  5307 solver.cpp:747] class AP 5: 0.259983
I0511 01:17:27.011533  5307 solver.cpp:747] class AP 6: 0.614489
I0511 01:17:27.020190  5307 solver.cpp:747] class AP 7: 0.613133
I0511 01:17:27.021162  5307 solver.cpp:747] class AP 8: 0.677218
I0511 01:17:27.039156  5307 solver.cpp:747] class AP 9: 0.334882
I0511 01:17:27.039464  5307 solver.cpp:747] class AP 10: 0.527755
I0511 01:17:27.040042  5307 solver.cpp:747] class AP 11: 0.480282
I0511 01:17:27.040508  5307 solver.cpp:747] class AP 12: 0.591494
I0511 01:17:27.040783  5307 solver.cpp:747] class AP 13: 0.700473
I0511 01:17:27.041205  5307 solver.cpp:747] class AP 14: 0.655316
I0511 01:17:27.083600  5307 solver.cpp:747] class AP 15: 0.615903
I0511 01:17:27.092900  5307 solver.cpp:747] class AP 16: 0.274368
I0511 01:17:27.094329  5307 solver.cpp:747] class AP 17: 0.427949
I0511 01:17:27.094879  5307 solver.cpp:747] class AP 18: 0.54173
I0511 01:17:27.095206  5307 solver.cpp:747] class AP 19: 0.654811
I0511 01:17:27.096396  5307 solver.cpp:747] class AP 20: 0.495851
I0511 01:17:27.096405  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.521838
I0511 01:17:27.096727  5307 solver.cpp:283] Tests completed in 101.383s
I0511 01:17:27.445214  5355 sgd_solver.cpp:50] MultiStep Status: Iteration 60000, step = 1
I0511 01:17:27.682260  5307 solver.cpp:352] Iteration 60000 (0.986357 iter/s, 101.383s/100 iter), 116/232ep, loss = 3.57575
I0511 01:17:27.682317  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.59007 (* 1 = 3.59007 loss)
I0511 01:17:27.682333  5307 sgd_solver.cpp:172] Iteration 60000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:18:29.066782  5307 solver.cpp:352] Iteration 60100 (1.6291 iter/s, 61.3834s/100 iter), 116.2/232ep, loss = 3.33893
I0511 01:18:29.066859  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.36745 (* 1 = 3.36745 loss)
I0511 01:18:29.066942  5307 sgd_solver.cpp:172] Iteration 60100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:19:30.656616  5307 solver.cpp:352] Iteration 60200 (1.62367 iter/s, 61.5887s/100 iter), 116.4/232ep, loss = 3.30766
I0511 01:19:30.657325  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.66321 (* 1 = 3.66321 loss)
I0511 01:19:30.657394  5307 sgd_solver.cpp:172] Iteration 60200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:20:32.139109  5307 solver.cpp:352] Iteration 60300 (1.62651 iter/s, 61.4814s/100 iter), 116.6/232ep, loss = 3.53453
I0511 01:20:32.139199  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.27908 (* 1 = 4.27908 loss)
I0511 01:20:32.139214  5307 sgd_solver.cpp:172] Iteration 60300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:21:33.893513  5307 solver.cpp:352] Iteration 60400 (1.61935 iter/s, 61.7534s/100 iter), 116.8/232ep, loss = 3.07137
I0511 01:21:33.893599  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.51694 (* 1 = 2.51694 loss)
I0511 01:21:33.893795  5307 sgd_solver.cpp:172] Iteration 60400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:22:34.057631  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 01:22:35.990677  5307 solver.cpp:352] Iteration 60500 (1.61041 iter/s, 62.0961s/100 iter), 117/232ep, loss = 3.3171
I0511 01:22:35.990705  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.99441 (* 1 = 2.99441 loss)
I0511 01:22:35.990715  5307 sgd_solver.cpp:172] Iteration 60500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:23:37.404093  5307 solver.cpp:352] Iteration 60600 (1.62834 iter/s, 61.4123s/100 iter), 117.2/232ep, loss = 3.38382
I0511 01:23:37.404161  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.96618 (* 1 = 2.96618 loss)
I0511 01:23:37.404171  5307 sgd_solver.cpp:172] Iteration 60600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:24:39.115162  5307 solver.cpp:352] Iteration 60700 (1.62048 iter/s, 61.71s/100 iter), 117.4/232ep, loss = 3.29782
I0511 01:24:39.115264  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.73199 (* 1 = 2.73199 loss)
I0511 01:24:39.115273  5307 sgd_solver.cpp:172] Iteration 60700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:25:40.255695  5307 solver.cpp:352] Iteration 60800 (1.6356 iter/s, 61.1395s/100 iter), 117.6/232ep, loss = 3.31946
I0511 01:25:40.255801  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.72749 (* 1 = 3.72749 loss)
I0511 01:25:40.255810  5307 sgd_solver.cpp:172] Iteration 60800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:26:40.877454  5307 solver.cpp:352] Iteration 60900 (1.6496 iter/s, 60.6207s/100 iter), 117.7/232ep, loss = 3.24465
I0511 01:26:40.877571  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.59557 (* 1 = 3.59557 loss)
I0511 01:26:40.877586  5307 sgd_solver.cpp:172] Iteration 60900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:27:42.193470  5307 solver.cpp:352] Iteration 61000 (1.63092 iter/s, 61.315s/100 iter), 117.9/232ep, loss = 2.96329
I0511 01:27:42.195245  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.5253 (* 1 = 2.5253 loss)
I0511 01:27:42.195256  5307 sgd_solver.cpp:172] Iteration 61000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:27:50.109959  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 01:28:42.751310  5307 solver.cpp:352] Iteration 61100 (1.65134 iter/s, 60.5568s/100 iter), 118.1/232ep, loss = 3.174
I0511 01:28:42.754483  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.70197 (* 1 = 2.70197 loss)
I0511 01:28:42.754503  5307 sgd_solver.cpp:172] Iteration 61100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:29:44.676252  5307 solver.cpp:352] Iteration 61200 (1.61489 iter/s, 61.9239s/100 iter), 118.3/232ep, loss = 3.40893
I0511 01:29:44.676367  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.61415 (* 1 = 3.61415 loss)
I0511 01:29:44.676388  5307 sgd_solver.cpp:172] Iteration 61200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:30:44.929544  5307 solver.cpp:352] Iteration 61300 (1.65969 iter/s, 60.2523s/100 iter), 118.5/232ep, loss = 3.03333
I0511 01:30:44.930357  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.07757 (* 1 = 3.07757 loss)
I0511 01:30:44.930377  5307 sgd_solver.cpp:172] Iteration 61300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:31:45.904727  5307 solver.cpp:352] Iteration 61400 (1.64004 iter/s, 60.9742s/100 iter), 118.7/232ep, loss = 3.19597
I0511 01:31:45.905048  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.73004 (* 1 = 2.73004 loss)
I0511 01:31:45.905057  5307 sgd_solver.cpp:172] Iteration 61400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:32:46.642874  5307 solver.cpp:352] Iteration 61500 (1.64644 iter/s, 60.7371s/100 iter), 118.9/232ep, loss = 3.19309
I0511 01:32:46.642956  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.14063 (* 1 = 3.14063 loss)
I0511 01:32:46.642966  5307 sgd_solver.cpp:172] Iteration 61500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:33:05.857440  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 01:33:47.518443  5307 solver.cpp:352] Iteration 61600 (1.64272 iter/s, 60.8745s/100 iter), 119.1/232ep, loss = 3.33877
I0511 01:33:47.518563  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.71762 (* 1 = 3.71762 loss)
I0511 01:33:47.518584  5307 sgd_solver.cpp:172] Iteration 61600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:34:47.873309  5307 solver.cpp:352] Iteration 61700 (1.6569 iter/s, 60.3538s/100 iter), 119.3/232ep, loss = 3.27758
I0511 01:34:47.873818  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.90094 (* 1 = 2.90094 loss)
I0511 01:34:47.873839  5307 sgd_solver.cpp:172] Iteration 61700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:35:48.313613  5307 solver.cpp:352] Iteration 61800 (1.65455 iter/s, 60.4393s/100 iter), 119.5/232ep, loss = 3.40443
I0511 01:35:48.313936  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.3341 (* 1 = 3.3341 loss)
I0511 01:35:48.313948  5307 sgd_solver.cpp:172] Iteration 61800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:36:49.063982  5307 solver.cpp:352] Iteration 61900 (1.64611 iter/s, 60.7493s/100 iter), 119.7/232ep, loss = 3.16417
I0511 01:36:49.064105  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.94675 (* 1 = 3.94675 loss)
I0511 01:36:49.064129  5307 sgd_solver.cpp:172] Iteration 61900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:37:49.609964  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_62000.caffemodel
I0511 01:37:49.629725  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_62000.solverstate
I0511 01:37:49.637205  5307 solver.cpp:635] Iteration 62000, Testing net (#0)
I0511 01:38:30.271909  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 01:38:30.498445  5307 solver.cpp:747] class AP 1: 0.638976
I0511 01:38:30.498889  5307 solver.cpp:747] class AP 2: 0.696391
I0511 01:38:30.506206  5307 solver.cpp:747] class AP 3: 0.530722
I0511 01:38:30.509886  5307 solver.cpp:747] class AP 4: 0.474306
I0511 01:38:30.532281  5307 solver.cpp:747] class AP 5: 0.325235
I0511 01:38:30.532739  5307 solver.cpp:747] class AP 6: 0.705911
I0511 01:38:30.541038  5307 solver.cpp:747] class AP 7: 0.682504
I0511 01:38:30.541545  5307 solver.cpp:747] class AP 8: 0.784299
I0511 01:38:30.562366  5307 solver.cpp:747] class AP 9: 0.406171
I0511 01:38:30.563141  5307 solver.cpp:747] class AP 10: 0.579289
I0511 01:38:30.563907  5307 solver.cpp:747] class AP 11: 0.579477
I0511 01:38:30.564935  5307 solver.cpp:747] class AP 12: 0.707274
I0511 01:38:30.565356  5307 solver.cpp:747] class AP 13: 0.781847
I0511 01:38:30.565732  5307 solver.cpp:747] class AP 14: 0.725835
I0511 01:38:30.624557  5307 solver.cpp:747] class AP 15: 0.717883
I0511 01:38:30.633199  5307 solver.cpp:747] class AP 16: 0.318442
I0511 01:38:30.637576  5307 solver.cpp:747] class AP 17: 0.577362
I0511 01:38:30.638466  5307 solver.cpp:747] class AP 18: 0.617153
I0511 01:38:30.639308  5307 solver.cpp:747] class AP 19: 0.734592
I0511 01:38:30.641549  5307 solver.cpp:747] class AP 20: 0.582975
I0511 01:38:30.641572  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.608332
I0511 01:38:30.641708  5307 solver.cpp:283] Tests completed in 101.576s
I0511 01:38:31.202342  5307 solver.cpp:352] Iteration 62000 (0.984484 iter/s, 101.576s/100 iter), 119.9/232ep, loss = 3.18528
I0511 01:38:31.202376  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.26906 (* 1 = 3.26906 loss)
I0511 01:38:31.202385  5307 sgd_solver.cpp:172] Iteration 62000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:39:00.942828  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 01:39:32.470726  5307 solver.cpp:352] Iteration 62100 (1.63219 iter/s, 61.2673s/100 iter), 120.1/232ep, loss = 3.32069
I0511 01:39:32.470837  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.25149 (* 1 = 3.25149 loss)
I0511 01:39:32.470847  5307 sgd_solver.cpp:172] Iteration 62100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:40:32.866340  5307 solver.cpp:352] Iteration 62200 (1.65578 iter/s, 60.3946s/100 iter), 120.3/232ep, loss = 3.24012
I0511 01:40:32.871697  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.33285 (* 1 = 3.33285 loss)
I0511 01:40:32.871791  5307 sgd_solver.cpp:172] Iteration 62200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:41:33.514859  5307 solver.cpp:352] Iteration 62300 (1.64887 iter/s, 60.6474s/100 iter), 120.5/232ep, loss = 3.14737
I0511 01:41:33.517706  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.01378 (* 1 = 2.01378 loss)
I0511 01:41:33.517721  5307 sgd_solver.cpp:172] Iteration 62300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:42:34.198036  5307 solver.cpp:352] Iteration 62400 (1.64793 iter/s, 60.6822s/100 iter), 120.6/232ep, loss = 3.04684
I0511 01:42:34.198324  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.95164 (* 1 = 2.95164 loss)
I0511 01:42:34.198341  5307 sgd_solver.cpp:172] Iteration 62400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:43:35.042399  5307 solver.cpp:352] Iteration 62500 (1.64357 iter/s, 60.8433s/100 iter), 120.8/232ep, loss = 3.38942
I0511 01:43:35.042520  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.01356 (* 1 = 3.01356 loss)
I0511 01:43:35.042529  5307 sgd_solver.cpp:172] Iteration 62500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:44:15.422554  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 01:44:36.124577  5307 solver.cpp:352] Iteration 62600 (1.63717 iter/s, 61.0811s/100 iter), 121/232ep, loss = 3.2401
I0511 01:44:36.124794  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.23748 (* 1 = 3.23748 loss)
I0511 01:44:36.124814  5307 sgd_solver.cpp:172] Iteration 62600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:45:36.969264  5307 solver.cpp:352] Iteration 62700 (1.64356 iter/s, 60.8437s/100 iter), 121.2/232ep, loss = 3.49287
I0511 01:45:36.969357  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.75813 (* 1 = 3.75813 loss)
I0511 01:45:36.969365  5307 sgd_solver.cpp:172] Iteration 62700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:46:37.442836  5307 solver.cpp:352] Iteration 62800 (1.65364 iter/s, 60.4725s/100 iter), 121.4/232ep, loss = 3.21464
I0511 01:46:37.442962  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.30845 (* 1 = 3.30845 loss)
I0511 01:46:37.442970  5307 sgd_solver.cpp:172] Iteration 62800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:47:38.004196  5307 solver.cpp:352] Iteration 62900 (1.65125 iter/s, 60.5603s/100 iter), 121.6/232ep, loss = 3.15143
I0511 01:47:38.004312  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.25155 (* 1 = 3.25155 loss)
I0511 01:47:38.004331  5307 sgd_solver.cpp:172] Iteration 62900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:48:38.915096  5307 solver.cpp:352] Iteration 63000 (1.64177 iter/s, 60.9099s/100 iter), 121.8/232ep, loss = 3.1154
I0511 01:48:38.915282  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.55979 (* 1 = 3.55979 loss)
I0511 01:48:38.915294  5307 sgd_solver.cpp:172] Iteration 63000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:49:29.128574  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 01:49:39.204468  5307 solver.cpp:352] Iteration 63100 (1.65869 iter/s, 60.2884s/100 iter), 122/232ep, loss = 3.10442
I0511 01:49:39.204491  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.14016 (* 1 = 3.14016 loss)
I0511 01:49:39.204499  5307 sgd_solver.cpp:172] Iteration 63100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:50:38.492687  5307 solver.cpp:352] Iteration 63200 (1.68671 iter/s, 59.2872s/100 iter), 122.2/232ep, loss = 3.15629
I0511 01:50:38.492832  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.25644 (* 1 = 4.25644 loss)
I0511 01:50:38.492857  5307 sgd_solver.cpp:172] Iteration 63200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:51:39.091516  5307 solver.cpp:352] Iteration 63300 (1.65022 iter/s, 60.5978s/100 iter), 122.4/232ep, loss = 3.01801
I0511 01:51:39.091578  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.67144 (* 1 = 3.67144 loss)
I0511 01:51:39.091585  5307 sgd_solver.cpp:172] Iteration 63300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:52:39.720751  5307 solver.cpp:352] Iteration 63400 (1.6494 iter/s, 60.6282s/100 iter), 122.6/232ep, loss = 3.26002
I0511 01:52:39.721735  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.84441 (* 1 = 3.84441 loss)
I0511 01:52:39.721746  5307 sgd_solver.cpp:172] Iteration 63400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:53:39.748903  5307 solver.cpp:352] Iteration 63500 (1.66591 iter/s, 60.0271s/100 iter), 122.8/232ep, loss = 3.11425
I0511 01:53:39.749964  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.13076 (* 1 = 3.13076 loss)
I0511 01:53:39.749975  5307 sgd_solver.cpp:172] Iteration 63500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:54:39.551507  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 01:54:40.126468  5307 solver.cpp:352] Iteration 63600 (1.65627 iter/s, 60.3766s/100 iter), 123/232ep, loss = 3.36435
I0511 01:54:40.126544  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.82291 (* 1 = 3.82291 loss)
I0511 01:54:40.126564  5307 sgd_solver.cpp:172] Iteration 63600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:55:41.248622  5307 solver.cpp:352] Iteration 63700 (1.6361 iter/s, 61.1211s/100 iter), 123.2/232ep, loss = 3.28457
I0511 01:55:41.250053  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.92716 (* 1 = 3.92716 loss)
I0511 01:55:41.250136  5307 sgd_solver.cpp:172] Iteration 63700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:56:41.808493  5307 solver.cpp:352] Iteration 63800 (1.65129 iter/s, 60.5588s/100 iter), 123.4/232ep, loss = 3.16873
I0511 01:56:41.808573  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.16457 (* 1 = 3.16457 loss)
I0511 01:56:41.808583  5307 sgd_solver.cpp:172] Iteration 63800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:57:41.697094  5307 solver.cpp:352] Iteration 63900 (1.6698 iter/s, 59.8876s/100 iter), 123.5/232ep, loss = 3.09208
I0511 01:57:41.697197  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.56341 (* 1 = 2.56341 loss)
I0511 01:57:41.697211  5307 sgd_solver.cpp:172] Iteration 63900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 01:58:41.914530  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_64000.caffemodel
I0511 01:58:41.936115  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_64000.solverstate
I0511 01:58:41.942518  5307 solver.cpp:635] Iteration 64000, Testing net (#0)
I0511 01:58:54.503506  5352 blocking_queue.cpp:40] Data layer prefetch queue empty
I0511 01:59:22.812211  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 01:59:23.034703  5307 solver.cpp:747] class AP 1: 0.633344
I0511 01:59:23.035193  5307 solver.cpp:747] class AP 2: 0.71913
I0511 01:59:23.041399  5307 solver.cpp:747] class AP 3: 0.523038
I0511 01:59:23.044920  5307 solver.cpp:747] class AP 4: 0.487088
I0511 01:59:23.065953  5307 solver.cpp:747] class AP 5: 0.323399
I0511 01:59:23.066340  5307 solver.cpp:747] class AP 6: 0.712963
I0511 01:59:23.073334  5307 solver.cpp:747] class AP 7: 0.678412
I0511 01:59:23.073962  5307 solver.cpp:747] class AP 8: 0.791006
I0511 01:59:23.093544  5307 solver.cpp:747] class AP 9: 0.418986
I0511 01:59:23.094259  5307 solver.cpp:747] class AP 10: 0.613647
I0511 01:59:23.094915  5307 solver.cpp:747] class AP 11: 0.564244
I0511 01:59:23.095716  5307 solver.cpp:747] class AP 12: 0.6965
I0511 01:59:23.096119  5307 solver.cpp:747] class AP 13: 0.777461
I0511 01:59:23.096477  5307 solver.cpp:747] class AP 14: 0.733747
I0511 01:59:23.148425  5307 solver.cpp:747] class AP 15: 0.713203
I0511 01:59:23.154863  5307 solver.cpp:747] class AP 16: 0.343052
I0511 01:59:23.157761  5307 solver.cpp:747] class AP 17: 0.584989
I0511 01:59:23.158402  5307 solver.cpp:747] class AP 18: 0.589125
I0511 01:59:23.158951  5307 solver.cpp:747] class AP 19: 0.73742
I0511 01:59:23.160584  5307 solver.cpp:747] class AP 20: 0.592467
I0511 01:59:23.160596  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.611661
I0511 01:59:23.160784  5307 solver.cpp:283] Tests completed in 101.462s
I0511 01:59:23.710171  5307 solver.cpp:352] Iteration 64000 (0.985591 iter/s, 101.462s/100 iter), 123.7/232ep, loss = 3.07692
I0511 01:59:23.710196  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.87853 (* 1 = 2.87853 loss)
I0511 01:59:23.710201  5307 sgd_solver.cpp:172] Iteration 64000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:00:23.587422  5307 solver.cpp:352] Iteration 64100 (1.67011 iter/s, 59.8762s/100 iter), 123.9/232ep, loss = 3.19645
I0511 02:00:23.587507  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.44664 (* 1 = 3.44664 loss)
I0511 02:00:23.587524  5307 sgd_solver.cpp:172] Iteration 64100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:00:34.106542  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 02:01:23.968485  5307 solver.cpp:352] Iteration 64200 (1.65618 iter/s, 60.38s/100 iter), 124.1/232ep, loss = 3.05154
I0511 02:01:23.968683  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.59048 (* 1 = 3.59048 loss)
I0511 02:01:23.968695  5307 sgd_solver.cpp:172] Iteration 64200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:02:24.219705  5307 solver.cpp:352] Iteration 64300 (1.65975 iter/s, 60.2502s/100 iter), 124.3/232ep, loss = 3.12734
I0511 02:02:24.219782  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.08787 (* 1 = 3.08787 loss)
I0511 02:02:24.219791  5307 sgd_solver.cpp:172] Iteration 64300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:03:24.846391  5307 solver.cpp:352] Iteration 64400 (1.64947 iter/s, 60.6257s/100 iter), 124.5/232ep, loss = 3.0666
I0511 02:03:24.846494  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.15372 (* 1 = 3.15372 loss)
I0511 02:03:24.846513  5307 sgd_solver.cpp:172] Iteration 64400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:04:25.418087  5307 solver.cpp:352] Iteration 64500 (1.65096 iter/s, 60.5707s/100 iter), 124.7/232ep, loss = 3.25712
I0511 02:04:25.418170  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.20735 (* 1 = 3.20735 loss)
I0511 02:04:25.418179  5307 sgd_solver.cpp:172] Iteration 64500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:05:25.953708  5307 solver.cpp:352] Iteration 64600 (1.65195 iter/s, 60.5346s/100 iter), 124.9/232ep, loss = 3.072
I0511 02:05:25.953817  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.88575 (* 1 = 2.88575 loss)
I0511 02:05:25.953832  5307 sgd_solver.cpp:172] Iteration 64600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:05:46.779067  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 02:06:26.804708  5307 solver.cpp:352] Iteration 64700 (1.64339 iter/s, 60.85s/100 iter), 125.1/232ep, loss = 3.16899
I0511 02:06:26.805696  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.78591 (* 1 = 2.78591 loss)
I0511 02:06:26.805712  5307 sgd_solver.cpp:172] Iteration 64700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:07:27.332586  5307 solver.cpp:352] Iteration 64800 (1.65216 iter/s, 60.5269s/100 iter), 125.3/232ep, loss = 3.11116
I0511 02:07:27.332701  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.53597 (* 1 = 3.53597 loss)
I0511 02:07:27.332718  5307 sgd_solver.cpp:172] Iteration 64800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:08:27.384068  5307 solver.cpp:352] Iteration 64900 (1.66527 iter/s, 60.0505s/100 iter), 125.5/232ep, loss = 3.25568
I0511 02:08:27.384121  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.64235 (* 1 = 3.64235 loss)
I0511 02:08:27.384130  5307 sgd_solver.cpp:172] Iteration 64900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:09:32.242856  5307 solver.cpp:352] Iteration 65000 (1.54184 iter/s, 64.8577s/100 iter), 125.7/232ep, loss = 3.19532
I0511 02:09:32.245679  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.05203 (* 1 = 3.05203 loss)
I0511 02:09:32.245710  5307 sgd_solver.cpp:172] Iteration 65000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:10:40.086432  5307 solver.cpp:352] Iteration 65100 (1.474 iter/s, 67.8424s/100 iter), 125.9/232ep, loss = 3.23919
I0511 02:10:40.086539  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.31138 (* 1 = 3.31138 loss)
I0511 02:10:40.086555  5307 sgd_solver.cpp:172] Iteration 65100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:11:11.076592  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 02:11:40.491904  5307 solver.cpp:352] Iteration 65200 (1.65551 iter/s, 60.4044s/100 iter), 126.1/232ep, loss = 3.29238
I0511 02:11:40.491936  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.03786 (* 1 = 3.03786 loss)
I0511 02:11:40.491945  5307 sgd_solver.cpp:172] Iteration 65200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:12:41.340348  5307 solver.cpp:352] Iteration 65300 (1.64346 iter/s, 60.8474s/100 iter), 126.3/232ep, loss = 3.20961
I0511 02:12:41.340802  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.39202 (* 1 = 4.39202 loss)
I0511 02:12:41.340811  5307 sgd_solver.cpp:172] Iteration 65300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:13:40.918337  5307 solver.cpp:352] Iteration 65400 (1.6785 iter/s, 59.577s/100 iter), 126.4/232ep, loss = 3.12944
I0511 02:13:40.918462  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.88578 (* 1 = 2.88578 loss)
I0511 02:13:40.918475  5307 sgd_solver.cpp:172] Iteration 65400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:14:41.663523  5307 solver.cpp:352] Iteration 65500 (1.64625 iter/s, 60.7442s/100 iter), 126.6/232ep, loss = 3.17585
I0511 02:14:41.663591  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.27108 (* 1 = 3.27108 loss)
I0511 02:14:41.663600  5307 sgd_solver.cpp:172] Iteration 65500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:15:41.835770  5307 solver.cpp:352] Iteration 65600 (1.66192 iter/s, 60.1712s/100 iter), 126.8/232ep, loss = 3.22622
I0511 02:15:41.835837  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.64396 (* 1 = 3.64396 loss)
I0511 02:15:41.835847  5307 sgd_solver.cpp:172] Iteration 65600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:16:23.883992  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 02:16:42.569505  5307 solver.cpp:352] Iteration 65700 (1.64656 iter/s, 60.7327s/100 iter), 127/232ep, loss = 3.21759
I0511 02:16:42.569663  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.02444 (* 1 = 3.02444 loss)
I0511 02:16:42.569728  5307 sgd_solver.cpp:172] Iteration 65700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:17:44.531523  5307 solver.cpp:352] Iteration 65800 (1.61392 iter/s, 61.961s/100 iter), 127.2/232ep, loss = 3.1564
I0511 02:17:44.531584  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.46917 (* 1 = 3.46917 loss)
I0511 02:17:44.531592  5307 sgd_solver.cpp:172] Iteration 65800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:18:45.268631  5307 solver.cpp:352] Iteration 65900 (1.64647 iter/s, 60.7361s/100 iter), 127.4/232ep, loss = 3.09757
I0511 02:18:45.268702  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.98101 (* 1 = 2.98101 loss)
I0511 02:18:45.268712  5307 sgd_solver.cpp:172] Iteration 65900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:19:45.910188  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_66000.caffemodel
I0511 02:19:45.926357  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_66000.solverstate
I0511 02:19:45.931254  5307 solver.cpp:635] Iteration 66000, Testing net (#0)
I0511 02:20:26.794226  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 02:20:27.040277  5307 solver.cpp:747] class AP 1: 0.64229
I0511 02:20:27.040701  5307 solver.cpp:747] class AP 2: 0.706363
I0511 02:20:27.047019  5307 solver.cpp:747] class AP 3: 0.531507
I0511 02:20:27.050629  5307 solver.cpp:747] class AP 4: 0.49355
I0511 02:20:27.070884  5307 solver.cpp:747] class AP 5: 0.323647
I0511 02:20:27.071313  5307 solver.cpp:747] class AP 6: 0.704733
I0511 02:20:27.079596  5307 solver.cpp:747] class AP 7: 0.697777
I0511 02:20:27.080271  5307 solver.cpp:747] class AP 8: 0.798769
I0511 02:20:27.099870  5307 solver.cpp:747] class AP 9: 0.412927
I0511 02:20:27.100630  5307 solver.cpp:747] class AP 10: 0.632788
I0511 02:20:27.101251  5307 solver.cpp:747] class AP 11: 0.571624
I0511 02:20:27.102129  5307 solver.cpp:747] class AP 12: 0.718176
I0511 02:20:27.102501  5307 solver.cpp:747] class AP 13: 0.786534
I0511 02:20:27.102790  5307 solver.cpp:747] class AP 14: 0.73184
I0511 02:20:27.153549  5307 solver.cpp:747] class AP 15: 0.714214
I0511 02:20:27.160442  5307 solver.cpp:747] class AP 16: 0.342798
I0511 02:20:27.163242  5307 solver.cpp:747] class AP 17: 0.582979
I0511 02:20:27.163986  5307 solver.cpp:747] class AP 18: 0.620496
I0511 02:20:27.164631  5307 solver.cpp:747] class AP 19: 0.743935
I0511 02:20:27.166348  5307 solver.cpp:747] class AP 20: 0.586294
I0511 02:20:27.166357  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.617162
I0511 02:20:27.166574  5307 solver.cpp:283] Tests completed in 101.896s
I0511 02:20:27.747750  5307 solver.cpp:352] Iteration 66000 (0.981391 iter/s, 101.896s/100 iter), 127.6/232ep, loss = 3.06323
I0511 02:20:27.747782  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.37556 (* 1 = 3.37556 loss)
I0511 02:20:27.747792  5307 sgd_solver.cpp:172] Iteration 66000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:21:28.306773  5307 solver.cpp:352] Iteration 66100 (1.65131 iter/s, 60.558s/100 iter), 127.8/232ep, loss = 3.12489
I0511 02:21:28.306880  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.96524 (* 1 = 2.96524 loss)
I0511 02:21:28.306896  5307 sgd_solver.cpp:172] Iteration 66100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:22:19.897558  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 02:22:28.833058  5307 solver.cpp:352] Iteration 66200 (1.6522 iter/s, 60.5252s/100 iter), 128/232ep, loss = 3.16999
I0511 02:22:28.833091  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.08489 (* 1 = 3.08489 loss)
I0511 02:22:28.833099  5307 sgd_solver.cpp:172] Iteration 66200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:23:28.684754  5307 solver.cpp:352] Iteration 66300 (1.67083 iter/s, 59.8507s/100 iter), 128.2/232ep, loss = 3.05533
I0511 02:23:28.684828  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.32332 (* 1 = 3.32332 loss)
I0511 02:23:28.684836  5307 sgd_solver.cpp:172] Iteration 66300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:24:29.196430  5307 solver.cpp:352] Iteration 66400 (1.6526 iter/s, 60.5106s/100 iter), 128.4/232ep, loss = 3.15909
I0511 02:24:29.196501  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.45537 (* 1 = 2.45537 loss)
I0511 02:24:29.196511  5307 sgd_solver.cpp:172] Iteration 66400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:25:29.284615  5307 solver.cpp:352] Iteration 66500 (1.66425 iter/s, 60.0871s/100 iter), 128.6/232ep, loss = 3.17891
I0511 02:25:29.284759  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.80693 (* 1 = 2.80693 loss)
I0511 02:25:29.284773  5307 sgd_solver.cpp:172] Iteration 66500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:26:29.177669  5307 solver.cpp:352] Iteration 66600 (1.66967 iter/s, 59.8921s/100 iter), 128.8/232ep, loss = 3.04129
I0511 02:26:29.177758  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.84487 (* 1 = 3.84487 loss)
I0511 02:26:29.177778  5307 sgd_solver.cpp:172] Iteration 66600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:27:29.551985  5307 solver.cpp:352] Iteration 66700 (1.65636 iter/s, 60.3733s/100 iter), 129/232ep, loss = 3.10101
I0511 02:27:29.552503  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.98461 (* 1 = 2.98461 loss)
I0511 02:27:29.552539  5307 sgd_solver.cpp:172] Iteration 66700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:27:31.497298  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 02:28:29.639467  5307 solver.cpp:352] Iteration 66800 (1.66427 iter/s, 60.0865s/100 iter), 129.2/232ep, loss = 3.27425
I0511 02:28:29.639585  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.99742 (* 1 = 2.99742 loss)
I0511 02:28:29.639600  5307 sgd_solver.cpp:172] Iteration 66800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:29:30.188894  5307 solver.cpp:352] Iteration 66900 (1.65157 iter/s, 60.5484s/100 iter), 129.3/232ep, loss = 3.07127
I0511 02:29:30.189085  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.49614 (* 1 = 2.49614 loss)
I0511 02:29:30.189118  5307 sgd_solver.cpp:172] Iteration 66900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:30:30.186563  5307 solver.cpp:352] Iteration 67000 (1.66676 iter/s, 59.9967s/100 iter), 129.5/232ep, loss = 3.04688
I0511 02:30:30.186645  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.31019 (* 1 = 3.31019 loss)
I0511 02:30:30.186655  5307 sgd_solver.cpp:172] Iteration 67000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:31:30.200628  5307 solver.cpp:352] Iteration 67100 (1.6663 iter/s, 60.013s/100 iter), 129.7/232ep, loss = 3.24378
I0511 02:31:30.200717  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.95658 (* 1 = 2.95658 loss)
I0511 02:31:30.200726  5307 sgd_solver.cpp:172] Iteration 67100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:32:30.827069  5307 solver.cpp:352] Iteration 67200 (1.64947 iter/s, 60.6254s/100 iter), 129.9/232ep, loss = 3.10399
I0511 02:32:30.827136  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.56074 (* 1 = 3.56074 loss)
I0511 02:32:30.827142  5307 sgd_solver.cpp:172] Iteration 67200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:32:43.731626  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 02:33:30.801796  5307 solver.cpp:352] Iteration 67300 (1.6674 iter/s, 59.9737s/100 iter), 130.1/232ep, loss = 3.18025
I0511 02:33:30.801970  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.09506 (* 1 = 3.09506 loss)
I0511 02:33:30.801990  5307 sgd_solver.cpp:172] Iteration 67300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:34:31.469436  5307 solver.cpp:352] Iteration 67400 (1.64835 iter/s, 60.6666s/100 iter), 130.3/232ep, loss = 3.25361
I0511 02:34:31.469583  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.88847 (* 1 = 2.88847 loss)
I0511 02:34:31.469594  5307 sgd_solver.cpp:172] Iteration 67400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:35:31.926903  5307 solver.cpp:352] Iteration 67500 (1.65408 iter/s, 60.4565s/100 iter), 130.5/232ep, loss = 3.20026
I0511 02:35:31.927027  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.99033 (* 1 = 3.99033 loss)
I0511 02:35:31.927047  5307 sgd_solver.cpp:172] Iteration 67500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:36:32.995633  5307 solver.cpp:352] Iteration 67600 (1.63753 iter/s, 61.0677s/100 iter), 130.7/232ep, loss = 3.14645
I0511 02:36:33.001457  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.64913 (* 1 = 2.64913 loss)
I0511 02:36:33.001477  5307 sgd_solver.cpp:172] Iteration 67600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:37:34.313900  5307 solver.cpp:352] Iteration 67700 (1.63086 iter/s, 61.3172s/100 iter), 130.9/232ep, loss = 3.0593
I0511 02:37:34.314021  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.51218 (* 1 = 2.51218 loss)
I0511 02:37:34.314043  5307 sgd_solver.cpp:172] Iteration 67700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:37:56.572094  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 02:38:34.731317  5307 solver.cpp:352] Iteration 67800 (1.65518 iter/s, 60.4164s/100 iter), 131.1/232ep, loss = 3.07228
I0511 02:38:34.731390  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.85683 (* 1 = 3.85683 loss)
I0511 02:38:34.731400  5307 sgd_solver.cpp:172] Iteration 67800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:39:35.165295  5307 solver.cpp:352] Iteration 67900 (1.65473 iter/s, 60.4329s/100 iter), 131.3/232ep, loss = 3.21763
I0511 02:39:35.168763  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.18548 (* 1 = 4.18548 loss)
I0511 02:39:35.168782  5307 sgd_solver.cpp:172] Iteration 67900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:40:35.312610  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_68000.caffemodel
I0511 02:40:35.335475  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_68000.solverstate
I0511 02:40:35.341565  5307 solver.cpp:635] Iteration 68000, Testing net (#0)
I0511 02:41:15.746647  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 02:41:15.956759  5307 solver.cpp:747] class AP 1: 0.659079
I0511 02:41:15.957516  5307 solver.cpp:747] class AP 2: 0.732531
I0511 02:41:15.964699  5307 solver.cpp:747] class AP 3: 0.534657
I0511 02:41:15.968891  5307 solver.cpp:747] class AP 4: 0.510083
I0511 02:41:15.988533  5307 solver.cpp:747] class AP 5: 0.312808
I0511 02:41:15.988878  5307 solver.cpp:747] class AP 6: 0.711184
I0511 02:41:15.996846  5307 solver.cpp:747] class AP 7: 0.695885
I0511 02:41:15.997467  5307 solver.cpp:747] class AP 8: 0.791351
I0511 02:41:16.014248  5307 solver.cpp:747] class AP 9: 0.415975
I0511 02:41:16.014916  5307 solver.cpp:747] class AP 10: 0.608569
I0511 02:41:16.015545  5307 solver.cpp:747] class AP 11: 0.562536
I0511 02:41:16.016479  5307 solver.cpp:747] class AP 12: 0.72295
I0511 02:41:16.016935  5307 solver.cpp:747] class AP 13: 0.788439
I0511 02:41:16.017293  5307 solver.cpp:747] class AP 14: 0.726442
I0511 02:41:16.068330  5307 solver.cpp:747] class AP 15: 0.720163
I0511 02:41:16.074450  5307 solver.cpp:747] class AP 16: 0.357333
I0511 02:41:16.076555  5307 solver.cpp:747] class AP 17: 0.573487
I0511 02:41:16.077015  5307 solver.cpp:747] class AP 18: 0.621755
I0511 02:41:16.077679  5307 solver.cpp:747] class AP 19: 0.750308
I0511 02:41:16.078996  5307 solver.cpp:747] class AP 20: 0.58943
I0511 02:41:16.079004  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.619248
I0511 02:41:16.079181  5307 solver.cpp:283] Tests completed in 100.912s
I0511 02:41:16.621726  5307 solver.cpp:352] Iteration 68000 (0.990961 iter/s, 100.912s/100 iter), 131.5/232ep, loss = 3.21332
I0511 02:41:16.621757  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.426 (* 1 = 2.426 loss)
I0511 02:41:16.621765  5307 sgd_solver.cpp:172] Iteration 68000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:42:17.548768  5307 solver.cpp:352] Iteration 68100 (1.64134 iter/s, 60.926s/100 iter), 131.7/232ep, loss = 3.23785
I0511 02:42:17.548938  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.05499 (* 1 = 3.05499 loss)
I0511 02:42:17.548955  5307 sgd_solver.cpp:172] Iteration 68100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:43:18.543166  5307 solver.cpp:352] Iteration 68200 (1.63952 iter/s, 60.9933s/100 iter), 131.9/232ep, loss = 3.18542
I0511 02:43:18.543371  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.21433 (* 1 = 3.21433 loss)
I0511 02:43:18.543467  5307 sgd_solver.cpp:172] Iteration 68200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:43:52.088322  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 02:44:19.328593  5307 solver.cpp:352] Iteration 68300 (1.64516 iter/s, 60.7844s/100 iter), 132.1/232ep, loss = 3.15519
I0511 02:44:19.328624  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.33395 (* 1 = 3.33395 loss)
I0511 02:44:19.328634  5307 sgd_solver.cpp:172] Iteration 68300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:45:19.909802  5307 solver.cpp:352] Iteration 68400 (1.6507 iter/s, 60.5802s/100 iter), 132.2/232ep, loss = 3.1727
I0511 02:45:19.909880  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.32494 (* 1 = 3.32494 loss)
I0511 02:45:19.909890  5307 sgd_solver.cpp:172] Iteration 68400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:46:21.203446  5307 solver.cpp:352] Iteration 68500 (1.63152 iter/s, 61.2926s/100 iter), 132.4/232ep, loss = 3.02053
I0511 02:46:21.203536  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.99906 (* 1 = 2.99906 loss)
I0511 02:46:21.203547  5307 sgd_solver.cpp:172] Iteration 68500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:47:22.625470  5307 solver.cpp:352] Iteration 68600 (1.62811 iter/s, 61.421s/100 iter), 132.6/232ep, loss = 3.19481
I0511 02:47:22.625568  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.63442 (* 1 = 2.63442 loss)
I0511 02:47:22.625591  5307 sgd_solver.cpp:172] Iteration 68600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:48:22.788887  5307 solver.cpp:352] Iteration 68700 (1.66217 iter/s, 60.1624s/100 iter), 132.8/232ep, loss = 3.31883
I0511 02:48:22.788957  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.53685 (* 1 = 3.53685 loss)
I0511 02:48:22.788977  5307 sgd_solver.cpp:172] Iteration 68700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:49:07.016917  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 02:49:23.496430  5307 solver.cpp:352] Iteration 68800 (1.64727 iter/s, 60.7065s/100 iter), 133/232ep, loss = 3.31059
I0511 02:49:23.496461  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.60516 (* 1 = 4.60516 loss)
I0511 02:49:23.496469  5307 sgd_solver.cpp:172] Iteration 68800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:50:23.810361  5307 solver.cpp:352] Iteration 68900 (1.65802 iter/s, 60.3129s/100 iter), 133.2/232ep, loss = 3.13913
I0511 02:50:23.810559  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.73763 (* 1 = 3.73763 loss)
I0511 02:50:23.810570  5307 sgd_solver.cpp:172] Iteration 68900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:51:24.725180  5307 solver.cpp:352] Iteration 69000 (1.64167 iter/s, 60.9138s/100 iter), 133.4/232ep, loss = 3.34018
I0511 02:51:24.725426  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.06818 (* 1 = 4.06818 loss)
I0511 02:51:24.725502  5307 sgd_solver.cpp:172] Iteration 69000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:52:25.565292  5307 solver.cpp:352] Iteration 69100 (1.64368 iter/s, 60.8391s/100 iter), 133.6/232ep, loss = 2.98946
I0511 02:52:25.565399  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.90528 (* 1 = 2.90528 loss)
I0511 02:52:25.565416  5307 sgd_solver.cpp:172] Iteration 69100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:53:26.489583  5307 solver.cpp:352] Iteration 69200 (1.64141 iter/s, 60.9233s/100 iter), 133.8/232ep, loss = 3.04981
I0511 02:53:26.489715  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.82091 (* 1 = 2.82091 loss)
I0511 02:53:26.489738  5307 sgd_solver.cpp:172] Iteration 69200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:54:20.484907  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 02:54:26.980163  5307 solver.cpp:352] Iteration 69300 (1.65318 iter/s, 60.4896s/100 iter), 134/232ep, loss = 3.16001
I0511 02:54:26.980187  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.88092 (* 1 = 2.88092 loss)
I0511 02:54:26.980195  5307 sgd_solver.cpp:172] Iteration 69300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:55:28.371501  5307 solver.cpp:352] Iteration 69400 (1.62892 iter/s, 61.3903s/100 iter), 134.2/232ep, loss = 3.13472
I0511 02:55:28.372318  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.85003 (* 1 = 2.85003 loss)
I0511 02:55:28.372362  5307 sgd_solver.cpp:172] Iteration 69400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:56:28.697196  5307 solver.cpp:352] Iteration 69500 (1.6577 iter/s, 60.3247s/100 iter), 134.4/232ep, loss = 3.218
I0511 02:56:28.697268  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.90315 (* 1 = 3.90315 loss)
I0511 02:56:28.697279  5307 sgd_solver.cpp:172] Iteration 69500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:57:29.238632  5307 solver.cpp:352] Iteration 69600 (1.65179 iter/s, 60.5404s/100 iter), 134.6/232ep, loss = 3.18379
I0511 02:57:29.238732  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.60102 (* 1 = 4.60102 loss)
I0511 02:57:29.238746  5307 sgd_solver.cpp:172] Iteration 69600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:58:29.184934  5307 solver.cpp:352] Iteration 69700 (1.66819 iter/s, 59.9453s/100 iter), 134.8/232ep, loss = 3.2003
I0511 02:58:29.185029  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.8632 (* 1 = 2.8632 loss)
I0511 02:58:29.185047  5307 sgd_solver.cpp:172] Iteration 69700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:59:30.345985  5307 solver.cpp:352] Iteration 69800 (1.63506 iter/s, 61.16s/100 iter), 135/232ep, loss = 3.04563
I0511 02:59:30.347682  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.74515 (* 1 = 2.74515 loss)
I0511 02:59:30.347692  5307 sgd_solver.cpp:172] Iteration 69800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 02:59:34.952587  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 03:00:31.122530  5307 solver.cpp:352] Iteration 69900 (1.6454 iter/s, 60.7755s/100 iter), 135.1/232ep, loss = 2.95089
I0511 03:00:31.124117  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.21105 (* 1 = 3.21105 loss)
I0511 03:00:31.124151  5307 sgd_solver.cpp:172] Iteration 69900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:01:31.175557  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_70000.caffemodel
I0511 03:01:31.191851  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_70000.solverstate
I0511 03:01:31.197576  5307 solver.cpp:635] Iteration 70000, Testing net (#0)
I0511 03:02:11.462358  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 03:02:11.687438  5307 solver.cpp:747] class AP 1: 0.633928
I0511 03:02:11.688009  5307 solver.cpp:747] class AP 2: 0.722257
I0511 03:02:11.696943  5307 solver.cpp:747] class AP 3: 0.52554
I0511 03:02:11.702378  5307 solver.cpp:747] class AP 4: 0.506187
I0511 03:02:11.728567  5307 solver.cpp:747] class AP 5: 0.317221
I0511 03:02:11.729123  5307 solver.cpp:747] class AP 6: 0.700389
I0511 03:02:11.741091  5307 solver.cpp:747] class AP 7: 0.690578
I0511 03:02:11.742168  5307 solver.cpp:747] class AP 8: 0.793709
I0511 03:02:11.760407  5307 solver.cpp:747] class AP 9: 0.412928
I0511 03:02:11.761131  5307 solver.cpp:747] class AP 10: 0.626752
I0511 03:02:11.761754  5307 solver.cpp:747] class AP 11: 0.569649
I0511 03:02:11.762750  5307 solver.cpp:747] class AP 12: 0.728977
I0511 03:02:11.763142  5307 solver.cpp:747] class AP 13: 0.79404
I0511 03:02:11.763547  5307 solver.cpp:747] class AP 14: 0.739371
I0511 03:02:11.816392  5307 solver.cpp:747] class AP 15: 0.716036
I0511 03:02:11.822613  5307 solver.cpp:747] class AP 16: 0.345662
I0511 03:02:11.825171  5307 solver.cpp:747] class AP 17: 0.588648
I0511 03:02:11.825748  5307 solver.cpp:747] class AP 18: 0.597739
I0511 03:02:11.826503  5307 solver.cpp:747] class AP 19: 0.748818
I0511 03:02:11.827986  5307 solver.cpp:747] class AP 20: 0.585734
I0511 03:02:11.827993  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.617208
I0511 03:02:11.828169  5307 solver.cpp:283] Tests completed in 100.704s
I0511 03:02:12.381124  5307 solver.cpp:352] Iteration 70000 (0.99301 iter/s, 100.704s/100 iter), 135.3/232ep, loss = 3.35481
I0511 03:02:12.381147  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.59581 (* 1 = 3.59581 loss)
I0511 03:02:12.381155  5307 sgd_solver.cpp:172] Iteration 70000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:03:12.412638  5307 solver.cpp:352] Iteration 70100 (1.66582 iter/s, 60.0305s/100 iter), 135.5/232ep, loss = 3.06649
I0511 03:03:12.412716  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.05734 (* 1 = 3.05734 loss)
I0511 03:03:12.412726  5307 sgd_solver.cpp:172] Iteration 70100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:04:13.535756  5307 solver.cpp:352] Iteration 70200 (1.63607 iter/s, 61.1221s/100 iter), 135.7/232ep, loss = 3.11306
I0511 03:04:13.535823  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.97389 (* 1 = 2.97389 loss)
I0511 03:04:13.535832  5307 sgd_solver.cpp:172] Iteration 70200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:05:13.983336  5307 solver.cpp:352] Iteration 70300 (1.65435 iter/s, 60.4465s/100 iter), 135.9/232ep, loss = 3.06026
I0511 03:05:13.983414  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.14835 (* 1 = 2.14835 loss)
I0511 03:05:13.983424  5307 sgd_solver.cpp:172] Iteration 70300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:05:27.617794  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 03:06:14.169797  5307 solver.cpp:352] Iteration 70400 (1.66153 iter/s, 60.1854s/100 iter), 136.1/232ep, loss = 3.23885
I0511 03:06:14.172082  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.23922 (* 1 = 3.23922 loss)
I0511 03:06:14.172091  5307 sgd_solver.cpp:172] Iteration 70400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:07:14.290994  5307 solver.cpp:352] Iteration 70500 (1.66334 iter/s, 60.1202s/100 iter), 136.3/232ep, loss = 3.11523
I0511 03:07:14.291625  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.43783 (* 1 = 2.43783 loss)
I0511 03:07:14.291651  5307 sgd_solver.cpp:172] Iteration 70500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:08:15.169945  5307 solver.cpp:352] Iteration 70600 (1.64263 iter/s, 60.8779s/100 iter), 136.5/232ep, loss = 3.23688
I0511 03:08:15.170079  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.11832 (* 1 = 3.11832 loss)
I0511 03:08:15.170087  5307 sgd_solver.cpp:172] Iteration 70600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:09:16.588992  5307 solver.cpp:352] Iteration 70700 (1.62819 iter/s, 61.418s/100 iter), 136.7/232ep, loss = 3.16966
I0511 03:09:16.589047  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.9083 (* 1 = 2.9083 loss)
I0511 03:09:16.589054  5307 sgd_solver.cpp:172] Iteration 70700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:10:17.104252  5307 solver.cpp:352] Iteration 70800 (1.6525 iter/s, 60.5142s/100 iter), 136.9/232ep, loss = 2.9313
I0511 03:10:17.104343  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.13385 (* 1 = 3.13385 loss)
I0511 03:10:17.104352  5307 sgd_solver.cpp:172] Iteration 70800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:10:42.343801  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 03:11:18.667933  5307 solver.cpp:352] Iteration 70900 (1.62436 iter/s, 61.5626s/100 iter), 137.1/232ep, loss = 3.02674
I0511 03:11:18.668010  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.99819 (* 1 = 3.99819 loss)
I0511 03:11:18.668016  5307 sgd_solver.cpp:172] Iteration 70900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:12:20.048511  5307 solver.cpp:352] Iteration 71000 (1.62921 iter/s, 61.3795s/100 iter), 137.3/232ep, loss = 3.13359
I0511 03:12:20.051676  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.6327 (* 1 = 3.6327 loss)
I0511 03:12:20.051697  5307 sgd_solver.cpp:172] Iteration 71000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:13:21.222898  5307 solver.cpp:352] Iteration 71100 (1.6347 iter/s, 61.1733s/100 iter), 137.5/232ep, loss = 3.08443
I0511 03:13:21.225001  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.2047 (* 1 = 3.2047 loss)
I0511 03:13:21.225018  5307 sgd_solver.cpp:172] Iteration 71100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:14:21.752249  5307 solver.cpp:352] Iteration 71200 (1.65212 iter/s, 60.5283s/100 iter), 137.7/232ep, loss = 2.94043
I0511 03:14:21.752353  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.73582 (* 1 = 2.73582 loss)
I0511 03:14:21.752368  5307 sgd_solver.cpp:172] Iteration 71200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:15:23.472234  5307 solver.cpp:352] Iteration 71300 (1.62025 iter/s, 61.7189s/100 iter), 137.9/232ep, loss = 3.25058
I0511 03:15:23.476651  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.54697 (* 1 = 3.54697 loss)
I0511 03:15:23.476688  5307 sgd_solver.cpp:172] Iteration 71300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:15:59.221091  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 03:16:24.756625  5307 solver.cpp:352] Iteration 71400 (1.63176 iter/s, 61.2834s/100 iter), 138/232ep, loss = 3.00779
I0511 03:16:24.756692  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.75285 (* 1 = 2.75285 loss)
I0511 03:16:24.756788  5307 sgd_solver.cpp:172] Iteration 71400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:17:33.508616  5307 solver.cpp:352] Iteration 71500 (1.45453 iter/s, 68.7508s/100 iter), 138.2/232ep, loss = 3.13443
I0511 03:17:33.508985  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.40484 (* 1 = 3.40484 loss)
I0511 03:17:33.508996  5307 sgd_solver.cpp:172] Iteration 71500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:18:36.579047  5307 solver.cpp:352] Iteration 71600 (1.58556 iter/s, 63.0693s/100 iter), 138.4/232ep, loss = 3.07886
I0511 03:18:36.579121  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.34027 (* 1 = 3.34027 loss)
I0511 03:18:36.579138  5307 sgd_solver.cpp:172] Iteration 71600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:19:37.170053  5307 solver.cpp:352] Iteration 71700 (1.65044 iter/s, 60.59s/100 iter), 138.6/232ep, loss = 3.27583
I0511 03:19:37.170119  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.00287 (* 1 = 3.00287 loss)
I0511 03:19:37.170125  5307 sgd_solver.cpp:172] Iteration 71700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:20:37.967916  5307 solver.cpp:352] Iteration 71800 (1.64482 iter/s, 60.7968s/100 iter), 138.8/232ep, loss = 3.22436
I0511 03:20:37.967975  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.96683 (* 1 = 3.96683 loss)
I0511 03:20:37.967983  5307 sgd_solver.cpp:172] Iteration 71800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:21:24.001253  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 03:21:39.559343  5307 solver.cpp:352] Iteration 71900 (1.62363 iter/s, 61.5904s/100 iter), 139/232ep, loss = 3.02662
I0511 03:21:39.559372  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.47239 (* 1 = 2.47239 loss)
I0511 03:21:39.559381  5307 sgd_solver.cpp:172] Iteration 71900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:22:39.245753  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_72000.caffemodel
I0511 03:22:39.260543  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_72000.solverstate
I0511 03:22:39.265848  5307 solver.cpp:635] Iteration 72000, Testing net (#0)
I0511 03:23:19.926988  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 03:23:20.152026  5307 solver.cpp:747] class AP 1: 0.643178
I0511 03:23:20.152619  5307 solver.cpp:747] class AP 2: 0.730592
I0511 03:23:20.158911  5307 solver.cpp:747] class AP 3: 0.525441
I0511 03:23:20.163348  5307 solver.cpp:747] class AP 4: 0.490848
I0511 03:23:20.185232  5307 solver.cpp:747] class AP 5: 0.323959
I0511 03:23:20.185839  5307 solver.cpp:747] class AP 6: 0.7124
I0511 03:23:20.197413  5307 solver.cpp:747] class AP 7: 0.699418
I0511 03:23:20.197970  5307 solver.cpp:747] class AP 8: 0.796918
I0511 03:23:20.217874  5307 solver.cpp:747] class AP 9: 0.412358
I0511 03:23:20.218621  5307 solver.cpp:747] class AP 10: 0.612703
I0511 03:23:20.219408  5307 solver.cpp:747] class AP 11: 0.583159
I0511 03:23:20.220283  5307 solver.cpp:747] class AP 12: 0.718245
I0511 03:23:20.220710  5307 solver.cpp:747] class AP 13: 0.788613
I0511 03:23:20.221154  5307 solver.cpp:747] class AP 14: 0.743379
I0511 03:23:20.272939  5307 solver.cpp:747] class AP 15: 0.721877
I0511 03:23:20.278545  5307 solver.cpp:747] class AP 16: 0.348866
I0511 03:23:20.281221  5307 solver.cpp:747] class AP 17: 0.583127
I0511 03:23:20.281805  5307 solver.cpp:747] class AP 18: 0.60061
I0511 03:23:20.282523  5307 solver.cpp:747] class AP 19: 0.748297
I0511 03:23:20.283898  5307 solver.cpp:747] class AP 20: 0.59774
I0511 03:23:20.283905  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.619087
I0511 03:23:20.284065  5307 solver.cpp:283] Tests completed in 100.723s
I0511 03:23:20.840155  5307 solver.cpp:352] Iteration 72000 (0.992822 iter/s, 100.723s/100 iter), 139.2/232ep, loss = 3.05155
I0511 03:23:20.840183  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.95617 (* 1 = 2.95617 loss)
I0511 03:23:20.840191  5307 sgd_solver.cpp:172] Iteration 72000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:24:21.332583  5307 solver.cpp:352] Iteration 72100 (1.65313 iter/s, 60.4914s/100 iter), 139.4/232ep, loss = 3.07664
I0511 03:24:21.332656  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.57719 (* 1 = 3.57719 loss)
I0511 03:24:21.332665  5307 sgd_solver.cpp:172] Iteration 72100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:25:21.916609  5307 solver.cpp:352] Iteration 72200 (1.65063 iter/s, 60.583s/100 iter), 139.6/232ep, loss = 3.06678
I0511 03:25:21.920967  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.38199 (* 1 = 3.38199 loss)
I0511 03:25:21.921028  5307 sgd_solver.cpp:172] Iteration 72200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:26:22.121351  5307 solver.cpp:352] Iteration 72300 (1.66103 iter/s, 60.2037s/100 iter), 139.8/232ep, loss = 3.00508
I0511 03:26:22.121433  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.74731 (* 1 = 2.74731 loss)
I0511 03:26:22.121441  5307 sgd_solver.cpp:172] Iteration 72300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:27:18.519220  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 03:27:22.728324  5307 solver.cpp:352] Iteration 72400 (1.65 iter/s, 60.6059s/100 iter), 140/232ep, loss = 3.1278
I0511 03:27:22.728421  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.64797 (* 1 = 2.64797 loss)
I0511 03:27:22.728431  5307 sgd_solver.cpp:172] Iteration 72400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:28:23.054373  5307 solver.cpp:352] Iteration 72500 (1.65769 iter/s, 60.325s/100 iter), 140.2/232ep, loss = 3.01141
I0511 03:28:23.054436  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.71092 (* 1 = 2.71092 loss)
I0511 03:28:23.054445  5307 sgd_solver.cpp:172] Iteration 72500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:29:23.481869  5307 solver.cpp:352] Iteration 72600 (1.6549 iter/s, 60.4265s/100 iter), 140.4/232ep, loss = 3.26152
I0511 03:29:23.481925  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.14742 (* 1 = 3.14742 loss)
I0511 03:29:23.481932  5307 sgd_solver.cpp:172] Iteration 72600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:30:23.728221  5307 solver.cpp:352] Iteration 72700 (1.65988 iter/s, 60.2453s/100 iter), 140.6/232ep, loss = 3.17499
I0511 03:30:23.728341  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.33493 (* 1 = 4.33493 loss)
I0511 03:30:23.728349  5307 sgd_solver.cpp:172] Iteration 72700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:31:23.844614  5307 solver.cpp:352] Iteration 72800 (1.66347 iter/s, 60.1154s/100 iter), 140.8/232ep, loss = 3.15664
I0511 03:31:23.844673  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.66648 (* 1 = 3.66648 loss)
I0511 03:31:23.844682  5307 sgd_solver.cpp:172] Iteration 72800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:32:24.520457  5307 solver.cpp:352] Iteration 72900 (1.64813 iter/s, 60.6748s/100 iter), 140.9/232ep, loss = 2.99479
I0511 03:32:24.520572  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.53888 (* 1 = 2.53888 loss)
I0511 03:32:24.520582  5307 sgd_solver.cpp:172] Iteration 72900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:32:30.003759  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 03:33:25.126344  5307 solver.cpp:352] Iteration 73000 (1.65003 iter/s, 60.6049s/100 iter), 141.1/232ep, loss = 2.92323
I0511 03:33:25.126405  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.59324 (* 1 = 2.59324 loss)
I0511 03:33:25.126415  5307 sgd_solver.cpp:172] Iteration 73000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:34:25.279366  5307 solver.cpp:352] Iteration 73100 (1.66246 iter/s, 60.152s/100 iter), 141.3/232ep, loss = 3.19742
I0511 03:34:25.279520  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.23241 (* 1 = 3.23241 loss)
I0511 03:34:25.279536  5307 sgd_solver.cpp:172] Iteration 73100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:35:25.761797  5307 solver.cpp:352] Iteration 73200 (1.6534 iter/s, 60.4814s/100 iter), 141.5/232ep, loss = 3.00938
I0511 03:35:25.761957  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.9753 (* 1 = 2.9753 loss)
I0511 03:35:25.761970  5307 sgd_solver.cpp:172] Iteration 73200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:36:26.001161  5307 solver.cpp:352] Iteration 73300 (1.66007 iter/s, 60.2383s/100 iter), 141.7/232ep, loss = 3.24271
I0511 03:36:26.001288  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.25406 (* 1 = 3.25406 loss)
I0511 03:36:26.001312  5307 sgd_solver.cpp:172] Iteration 73300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:37:26.115409  5307 solver.cpp:352] Iteration 73400 (1.66353 iter/s, 60.1132s/100 iter), 141.9/232ep, loss = 2.95538
I0511 03:37:26.115499  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.21927 (* 1 = 4.21927 loss)
I0511 03:37:26.115511  5307 sgd_solver.cpp:172] Iteration 73400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:37:42.700953  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 03:38:27.965601  5307 solver.cpp:352] Iteration 73500 (1.61684 iter/s, 61.8491s/100 iter), 142.1/232ep, loss = 2.98142
I0511 03:38:27.965658  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.88538 (* 1 = 2.88538 loss)
I0511 03:38:27.965667  5307 sgd_solver.cpp:172] Iteration 73500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:39:28.462384  5307 solver.cpp:352] Iteration 73600 (1.65301 iter/s, 60.4957s/100 iter), 142.3/232ep, loss = 3.18136
I0511 03:39:28.462545  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.7183 (* 1 = 2.7183 loss)
I0511 03:39:28.462556  5307 sgd_solver.cpp:172] Iteration 73600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:40:29.701385  5307 solver.cpp:352] Iteration 73700 (1.63297 iter/s, 61.2379s/100 iter), 142.5/232ep, loss = 3.24209
I0511 03:40:29.701820  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.14435 (* 1 = 3.14435 loss)
I0511 03:40:29.701833  5307 sgd_solver.cpp:172] Iteration 73700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:41:30.354627  5307 solver.cpp:352] Iteration 73800 (1.64874 iter/s, 60.6522s/100 iter), 142.7/232ep, loss = 3.10667
I0511 03:41:30.360618  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.50329 (* 1 = 3.50329 loss)
I0511 03:41:30.360646  5307 sgd_solver.cpp:172] Iteration 73800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:42:30.918884  5307 solver.cpp:352] Iteration 73900 (1.65117 iter/s, 60.5632s/100 iter), 142.9/232ep, loss = 2.98285
I0511 03:42:30.918987  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.23428 (* 1 = 2.23428 loss)
I0511 03:42:30.918998  5307 sgd_solver.cpp:172] Iteration 73900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:42:57.789077  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 03:43:30.908464  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_74000.caffemodel
I0511 03:43:30.925472  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_74000.solverstate
I0511 03:43:30.930797  5307 solver.cpp:635] Iteration 74000, Testing net (#0)
I0511 03:44:11.253901  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 03:44:11.489528  5307 solver.cpp:747] class AP 1: 0.641228
I0511 03:44:11.490033  5307 solver.cpp:747] class AP 2: 0.726448
I0511 03:44:11.495765  5307 solver.cpp:747] class AP 3: 0.532019
I0511 03:44:11.499542  5307 solver.cpp:747] class AP 4: 0.513854
I0511 03:44:11.519951  5307 solver.cpp:747] class AP 5: 0.325712
I0511 03:44:11.520368  5307 solver.cpp:747] class AP 6: 0.730229
I0511 03:44:11.529734  5307 solver.cpp:747] class AP 7: 0.697817
I0511 03:44:11.530369  5307 solver.cpp:747] class AP 8: 0.799968
I0511 03:44:11.547799  5307 solver.cpp:747] class AP 9: 0.416313
I0511 03:44:11.548456  5307 solver.cpp:747] class AP 10: 0.634536
I0511 03:44:11.549134  5307 solver.cpp:747] class AP 11: 0.569721
I0511 03:44:11.549952  5307 solver.cpp:747] class AP 12: 0.724131
I0511 03:44:11.550333  5307 solver.cpp:747] class AP 13: 0.784362
I0511 03:44:11.550717  5307 solver.cpp:747] class AP 14: 0.745329
I0511 03:44:11.598302  5307 solver.cpp:747] class AP 15: 0.721109
I0511 03:44:11.605280  5307 solver.cpp:747] class AP 16: 0.365057
I0511 03:44:11.607946  5307 solver.cpp:747] class AP 17: 0.59138
I0511 03:44:11.608561  5307 solver.cpp:747] class AP 18: 0.597681
I0511 03:44:11.609176  5307 solver.cpp:747] class AP 19: 0.748637
I0511 03:44:11.610620  5307 solver.cpp:747] class AP 20: 0.598941
I0511 03:44:11.610625  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.623223
I0511 03:44:11.610837  5307 solver.cpp:283] Tests completed in 100.69s
I0511 03:44:12.156131  5307 solver.cpp:352] Iteration 74000 (0.993144 iter/s, 100.69s/100 iter), 143.1/232ep, loss = 3.17362
I0511 03:44:12.156162  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.56647 (* 1 = 2.56647 loss)
I0511 03:44:12.156170  5307 sgd_solver.cpp:172] Iteration 74000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:45:12.416200  5307 solver.cpp:352] Iteration 74100 (1.6595 iter/s, 60.259s/100 iter), 143.3/232ep, loss = 3.02609
I0511 03:45:12.416337  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.72373 (* 1 = 2.72373 loss)
I0511 03:45:12.416348  5307 sgd_solver.cpp:172] Iteration 74100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:46:12.726747  5307 solver.cpp:352] Iteration 74200 (1.65811 iter/s, 60.3095s/100 iter), 143.5/232ep, loss = 3.04684
I0511 03:46:12.726939  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.64403 (* 1 = 2.64403 loss)
I0511 03:46:12.726958  5307 sgd_solver.cpp:172] Iteration 74200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:47:13.618039  5307 solver.cpp:352] Iteration 74300 (1.6423 iter/s, 60.8902s/100 iter), 143.7/232ep, loss = 3.13517
I0511 03:47:13.618142  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.88684 (* 1 = 2.88684 loss)
I0511 03:47:13.618157  5307 sgd_solver.cpp:172] Iteration 74300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:48:14.861030  5307 solver.cpp:352] Iteration 74400 (1.63287 iter/s, 61.242s/100 iter), 143.8/232ep, loss = 3.45337
I0511 03:48:14.861167  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.3419 (* 1 = 3.3419 loss)
I0511 03:48:14.861178  5307 sgd_solver.cpp:172] Iteration 74400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:48:51.966392  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 03:49:15.283468  5307 solver.cpp:352] Iteration 74500 (1.65504 iter/s, 60.4214s/100 iter), 144/232ep, loss = 2.85047
I0511 03:49:15.283495  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.93082 (* 1 = 2.93082 loss)
I0511 03:49:15.283504  5307 sgd_solver.cpp:172] Iteration 74500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:50:15.385535  5307 solver.cpp:352] Iteration 74600 (1.66386 iter/s, 60.1011s/100 iter), 144.2/232ep, loss = 3.20432
I0511 03:50:15.385777  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.67358 (* 1 = 2.67358 loss)
I0511 03:50:15.385788  5307 sgd_solver.cpp:172] Iteration 74600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:51:15.879094  5307 solver.cpp:352] Iteration 74700 (1.6531 iter/s, 60.4925s/100 iter), 144.4/232ep, loss = 3.25151
I0511 03:51:15.879184  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.59463 (* 1 = 3.59463 loss)
I0511 03:51:15.879199  5307 sgd_solver.cpp:172] Iteration 74700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:52:16.319046  5307 solver.cpp:352] Iteration 74800 (1.65456 iter/s, 60.4389s/100 iter), 144.6/232ep, loss = 3.18278
I0511 03:52:16.319164  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.4493 (* 1 = 3.4493 loss)
I0511 03:52:16.319173  5307 sgd_solver.cpp:172] Iteration 74800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:53:17.035173  5307 solver.cpp:352] Iteration 74900 (1.64704 iter/s, 60.7151s/100 iter), 144.8/232ep, loss = 2.96317
I0511 03:53:17.035262  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.10215 (* 1 = 3.10215 loss)
I0511 03:53:17.035274  5307 sgd_solver.cpp:172] Iteration 74900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:54:04.660311  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 03:54:17.287374  5307 solver.cpp:352] Iteration 75000 (1.65972 iter/s, 60.2512s/100 iter), 145/232ep, loss = 3.04642
I0511 03:54:17.287405  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.91731 (* 1 = 2.91731 loss)
I0511 03:54:17.287411  5307 sgd_solver.cpp:172] Iteration 75000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:55:16.952937  5307 solver.cpp:352] Iteration 75100 (1.67604 iter/s, 59.6646s/100 iter), 145.2/232ep, loss = 3.07866
I0511 03:55:16.953037  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.96777 (* 1 = 2.96777 loss)
I0511 03:55:16.953059  5307 sgd_solver.cpp:172] Iteration 75100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:56:17.980620  5307 solver.cpp:352] Iteration 75200 (1.63863 iter/s, 61.0266s/100 iter), 145.4/232ep, loss = 3.0594
I0511 03:56:17.980721  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.35611 (* 1 = 3.35611 loss)
I0511 03:56:17.980746  5307 sgd_solver.cpp:172] Iteration 75200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:57:19.051538  5307 solver.cpp:352] Iteration 75300 (1.63747 iter/s, 61.0699s/100 iter), 145.6/232ep, loss = 3.14592
I0511 03:57:19.051651  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.43066 (* 1 = 2.43066 loss)
I0511 03:57:19.051674  5307 sgd_solver.cpp:172] Iteration 75300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:58:20.779593  5307 solver.cpp:352] Iteration 75400 (1.62004 iter/s, 61.727s/100 iter), 145.8/232ep, loss = 2.98371
I0511 03:58:20.780081  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.68028 (* 1 = 3.68028 loss)
I0511 03:58:20.780143  5307 sgd_solver.cpp:172] Iteration 75400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 03:59:19.123008  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 03:59:22.062898  5307 solver.cpp:352] Iteration 75500 (1.63179 iter/s, 61.2823s/100 iter), 146/232ep, loss = 3.34483
I0511 03:59:22.062996  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.76846 (* 1 = 3.76846 loss)
I0511 03:59:22.063019  5307 sgd_solver.cpp:172] Iteration 75500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:00:23.406405  5307 solver.cpp:352] Iteration 75600 (1.63019 iter/s, 61.3425s/100 iter), 146.2/232ep, loss = 2.99761
I0511 04:00:23.406504  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.74646 (* 1 = 2.74646 loss)
I0511 04:00:23.406527  5307 sgd_solver.cpp:172] Iteration 75600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:01:25.636024  5307 solver.cpp:352] Iteration 75700 (1.60698 iter/s, 62.2285s/100 iter), 146.4/232ep, loss = 3.04397
I0511 04:01:25.636116  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.0651 (* 1 = 4.0651 loss)
I0511 04:01:25.636124  5307 sgd_solver.cpp:172] Iteration 75700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:02:27.433805  5307 solver.cpp:352] Iteration 75800 (1.61821 iter/s, 61.7967s/100 iter), 146.6/232ep, loss = 3.0474
I0511 04:02:27.433866  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.96175 (* 1 = 2.96175 loss)
I0511 04:02:27.433876  5307 sgd_solver.cpp:172] Iteration 75800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:03:28.920656  5307 solver.cpp:352] Iteration 75900 (1.62639 iter/s, 61.4858s/100 iter), 146.7/232ep, loss = 3.04129
I0511 04:03:28.921588  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.01541 (* 1 = 2.01541 loss)
I0511 04:03:28.921612  5307 sgd_solver.cpp:172] Iteration 75900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:04:29.593194  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_76000.caffemodel
I0511 04:04:29.607446  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_76000.solverstate
I0511 04:04:29.613701  5307 solver.cpp:635] Iteration 76000, Testing net (#0)
I0511 04:05:10.383334  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 04:05:10.593204  5307 solver.cpp:747] class AP 1: 0.637343
I0511 04:05:10.593714  5307 solver.cpp:747] class AP 2: 0.725514
I0511 04:05:10.600751  5307 solver.cpp:747] class AP 3: 0.543728
I0511 04:05:10.604346  5307 solver.cpp:747] class AP 4: 0.513556
I0511 04:05:10.624176  5307 solver.cpp:747] class AP 5: 0.327433
I0511 04:05:10.624552  5307 solver.cpp:747] class AP 6: 0.710337
I0511 04:05:10.632586  5307 solver.cpp:747] class AP 7: 0.696507
I0511 04:05:10.633287  5307 solver.cpp:747] class AP 8: 0.80158
I0511 04:05:10.653848  5307 solver.cpp:747] class AP 9: 0.424203
I0511 04:05:10.654513  5307 solver.cpp:747] class AP 10: 0.638241
I0511 04:05:10.655176  5307 solver.cpp:747] class AP 11: 0.585361
I0511 04:05:10.656023  5307 solver.cpp:747] class AP 12: 0.714094
I0511 04:05:10.656427  5307 solver.cpp:747] class AP 13: 0.791293
I0511 04:05:10.656805  5307 solver.cpp:747] class AP 14: 0.739938
I0511 04:05:10.705305  5307 solver.cpp:747] class AP 15: 0.721612
I0511 04:05:10.712443  5307 solver.cpp:747] class AP 16: 0.353075
I0511 04:05:10.715252  5307 solver.cpp:747] class AP 17: 0.607122
I0511 04:05:10.715829  5307 solver.cpp:747] class AP 18: 0.608899
I0511 04:05:10.716554  5307 solver.cpp:747] class AP 19: 0.746024
I0511 04:05:10.718053  5307 solver.cpp:747] class AP 20: 0.601709
I0511 04:05:10.718061  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.624378
I0511 04:05:10.718263  5307 solver.cpp:283] Tests completed in 101.796s
I0511 04:05:11.252502  5307 solver.cpp:352] Iteration 76000 (0.982358 iter/s, 101.796s/100 iter), 146.9/232ep, loss = 2.94222
I0511 04:05:11.252539  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.04738 (* 1 = 4.04738 loss)
I0511 04:05:11.252548  5307 sgd_solver.cpp:172] Iteration 76000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:05:19.245709  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 04:06:11.964781  5307 solver.cpp:352] Iteration 76100 (1.64714 iter/s, 60.7112s/100 iter), 147.1/232ep, loss = 2.95309
I0511 04:06:11.964931  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.86256 (* 1 = 2.86256 loss)
I0511 04:06:11.964942  5307 sgd_solver.cpp:172] Iteration 76100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:07:12.802561  5307 solver.cpp:352] Iteration 76200 (1.64374 iter/s, 60.8367s/100 iter), 147.3/232ep, loss = 3.25318
I0511 04:07:12.802662  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.17985 (* 1 = 4.17985 loss)
I0511 04:07:12.802690  5307 sgd_solver.cpp:172] Iteration 76200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:08:14.762794  5307 solver.cpp:352] Iteration 76300 (1.61397 iter/s, 61.9592s/100 iter), 147.5/232ep, loss = 2.94757
I0511 04:08:14.762857  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.23976 (* 1 = 2.23976 loss)
I0511 04:08:14.762864  5307 sgd_solver.cpp:172] Iteration 76300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:09:16.026989  5307 solver.cpp:352] Iteration 76400 (1.6323 iter/s, 61.2631s/100 iter), 147.7/232ep, loss = 3.11323
I0511 04:09:16.027123  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.97677 (* 1 = 3.97677 loss)
I0511 04:09:16.027142  5307 sgd_solver.cpp:172] Iteration 76400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:10:17.014519  5307 solver.cpp:352] Iteration 76500 (1.63971 iter/s, 60.9865s/100 iter), 147.9/232ep, loss = 3.02502
I0511 04:10:17.014600  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.14904 (* 1 = 3.14904 loss)
I0511 04:10:17.014618  5307 sgd_solver.cpp:172] Iteration 76500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:10:36.196403  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 04:11:19.378612  5307 solver.cpp:352] Iteration 76600 (1.60351 iter/s, 62.363s/100 iter), 148.1/232ep, loss = 3.1812
I0511 04:11:19.380671  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.34103 (* 1 = 3.34103 loss)
I0511 04:11:19.380684  5307 sgd_solver.cpp:172] Iteration 76600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:12:21.259330  5307 solver.cpp:352] Iteration 76700 (1.61604 iter/s, 61.8797s/100 iter), 148.3/232ep, loss = 3.13056
I0511 04:12:21.259500  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.73742 (* 1 = 2.73742 loss)
I0511 04:12:21.259526  5307 sgd_solver.cpp:172] Iteration 76700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:13:23.125416  5307 solver.cpp:352] Iteration 76800 (1.61642 iter/s, 61.865s/100 iter), 148.5/232ep, loss = 3.21444
I0511 04:13:23.125500  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.94929 (* 1 = 2.94929 loss)
I0511 04:13:23.125511  5307 sgd_solver.cpp:172] Iteration 76800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:14:24.983587  5307 solver.cpp:352] Iteration 76900 (1.61663 iter/s, 61.8571s/100 iter), 148.7/232ep, loss = 2.99404
I0511 04:14:24.983664  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.85883 (* 1 = 2.85883 loss)
I0511 04:14:24.983672  5307 sgd_solver.cpp:172] Iteration 76900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:15:26.783061  5307 solver.cpp:352] Iteration 77000 (1.61816 iter/s, 61.7984s/100 iter), 148.9/232ep, loss = 2.95391
I0511 04:15:26.783149  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.34189 (* 1 = 2.34189 loss)
I0511 04:15:26.783167  5307 sgd_solver.cpp:172] Iteration 77000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:15:55.960445  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 04:16:28.692605  5307 solver.cpp:352] Iteration 77100 (1.61529 iter/s, 61.9085s/100 iter), 149.1/232ep, loss = 3.08061
I0511 04:16:28.693063  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.6037 (* 1 = 2.6037 loss)
I0511 04:16:28.693089  5307 sgd_solver.cpp:172] Iteration 77100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:17:30.074394  5307 solver.cpp:352] Iteration 77200 (1.62918 iter/s, 61.3808s/100 iter), 149.3/232ep, loss = 3.09659
I0511 04:17:30.074466  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.57682 (* 1 = 2.57682 loss)
I0511 04:17:30.074475  5307 sgd_solver.cpp:172] Iteration 77200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:18:31.458698  5307 solver.cpp:352] Iteration 77300 (1.62911 iter/s, 61.3832s/100 iter), 149.5/232ep, loss = 3.17427
I0511 04:18:31.458783  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.77503 (* 1 = 3.77503 loss)
I0511 04:18:31.458793  5307 sgd_solver.cpp:172] Iteration 77300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:19:33.653574  5307 solver.cpp:352] Iteration 77400 (1.60788 iter/s, 62.1938s/100 iter), 149.6/232ep, loss = 3.12145
I0511 04:19:33.653671  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.94468 (* 1 = 2.94468 loss)
I0511 04:19:33.653678  5307 sgd_solver.cpp:172] Iteration 77400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:20:35.175375  5307 solver.cpp:352] Iteration 77500 (1.62547 iter/s, 61.5207s/100 iter), 149.8/232ep, loss = 3.29141
I0511 04:20:35.175492  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.42403 (* 1 = 2.42403 loss)
I0511 04:20:35.175504  5307 sgd_solver.cpp:172] Iteration 77500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:21:14.659782  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 04:21:35.705682  5307 solver.cpp:352] Iteration 77600 (1.65209 iter/s, 60.5293s/100 iter), 150/232ep, loss = 3.04855
I0511 04:21:35.705739  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.83429 (* 1 = 2.83429 loss)
I0511 04:21:35.705750  5307 sgd_solver.cpp:172] Iteration 77600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:22:36.228951  5307 solver.cpp:352] Iteration 77700 (1.65228 iter/s, 60.5223s/100 iter), 150.2/232ep, loss = 3.05063
I0511 04:22:36.229099  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.06361 (* 1 = 3.06361 loss)
I0511 04:22:36.229125  5307 sgd_solver.cpp:172] Iteration 77700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:23:37.886205  5307 solver.cpp:352] Iteration 77800 (1.6219 iter/s, 61.6562s/100 iter), 150.4/232ep, loss = 3.20392
I0511 04:23:37.886261  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.26003 (* 1 = 4.26003 loss)
I0511 04:23:37.886270  5307 sgd_solver.cpp:172] Iteration 77800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:24:45.856096  5307 solver.cpp:352] Iteration 77900 (1.47126 iter/s, 67.9687s/100 iter), 150.6/232ep, loss = 3.197
I0511 04:24:45.856202  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.5935 (* 1 = 3.5935 loss)
I0511 04:24:45.856223  5307 sgd_solver.cpp:172] Iteration 77900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:25:50.988086  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_78000.caffemodel
I0511 04:25:51.005568  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_78000.solverstate
I0511 04:25:51.010843  5307 solver.cpp:635] Iteration 78000, Testing net (#0)
I0511 04:26:31.213625  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 04:26:31.416895  5307 solver.cpp:747] class AP 1: 0.632267
I0511 04:26:31.417551  5307 solver.cpp:747] class AP 2: 0.7226
I0511 04:26:31.424793  5307 solver.cpp:747] class AP 3: 0.54852
I0511 04:26:31.428757  5307 solver.cpp:747] class AP 4: 0.509979
I0511 04:26:31.444545  5307 solver.cpp:747] class AP 5: 0.316974
I0511 04:26:31.444928  5307 solver.cpp:747] class AP 6: 0.724555
I0511 04:26:31.455165  5307 solver.cpp:747] class AP 7: 0.705174
I0511 04:26:31.455703  5307 solver.cpp:747] class AP 8: 0.798495
I0511 04:26:31.472879  5307 solver.cpp:747] class AP 9: 0.411551
I0511 04:26:31.473654  5307 solver.cpp:747] class AP 10: 0.616103
I0511 04:26:31.474263  5307 solver.cpp:747] class AP 11: 0.570838
I0511 04:26:31.475164  5307 solver.cpp:747] class AP 12: 0.724401
I0511 04:26:31.475595  5307 solver.cpp:747] class AP 13: 0.79868
I0511 04:26:31.476016  5307 solver.cpp:747] class AP 14: 0.739518
I0511 04:26:31.527408  5307 solver.cpp:747] class AP 15: 0.72125
I0511 04:26:31.532173  5307 solver.cpp:747] class AP 16: 0.356912
I0511 04:26:31.535329  5307 solver.cpp:747] class AP 17: 0.57359
I0511 04:26:31.535961  5307 solver.cpp:747] class AP 18: 0.596406
I0511 04:26:31.536696  5307 solver.cpp:747] class AP 19: 0.74554
I0511 04:26:31.538126  5307 solver.cpp:747] class AP 20: 0.598131
I0511 04:26:31.538133  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.620574
I0511 04:26:31.538298  5307 solver.cpp:283] Tests completed in 105.68s
I0511 04:26:32.080586  5307 solver.cpp:352] Iteration 78000 (0.946249 iter/s, 105.68s/100 iter), 150.8/232ep, loss = 2.87031
I0511 04:26:32.080616  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.55553 (* 1 = 2.55553 loss)
I0511 04:26:32.080626  5307 sgd_solver.cpp:172] Iteration 78000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:27:21.375700  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 04:27:32.847172  5307 solver.cpp:352] Iteration 78100 (1.64567 iter/s, 60.7655s/100 iter), 151/232ep, loss = 3.09697
I0511 04:27:32.847259  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.07398 (* 1 = 4.07398 loss)
I0511 04:27:32.847275  5307 sgd_solver.cpp:172] Iteration 78100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:28:33.441352  5307 solver.cpp:352] Iteration 78200 (1.65035 iter/s, 60.5931s/100 iter), 151.2/232ep, loss = 2.97198
I0511 04:28:33.441449  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.01782 (* 1 = 3.01782 loss)
I0511 04:28:33.441468  5307 sgd_solver.cpp:172] Iteration 78200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:29:34.452617  5307 solver.cpp:352] Iteration 78300 (1.63907 iter/s, 61.0102s/100 iter), 151.4/232ep, loss = 2.90562
I0511 04:29:34.452863  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.22756 (* 1 = 2.22756 loss)
I0511 04:29:34.452874  5307 sgd_solver.cpp:172] Iteration 78300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:30:34.917018  5307 solver.cpp:352] Iteration 78400 (1.65389 iter/s, 60.4634s/100 iter), 151.6/232ep, loss = 3.18169
I0511 04:30:34.917094  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.8036 (* 1 = 2.8036 loss)
I0511 04:30:34.917109  5307 sgd_solver.cpp:172] Iteration 78400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:31:36.095175  5307 solver.cpp:352] Iteration 78500 (1.6346 iter/s, 61.1771s/100 iter), 151.8/232ep, loss = 3.01962
I0511 04:31:36.095235  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.8123 (* 1 = 2.8123 loss)
I0511 04:31:36.095243  5307 sgd_solver.cpp:172] Iteration 78500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:32:35.911156  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 04:32:36.532106  5307 solver.cpp:352] Iteration 78600 (1.65465 iter/s, 60.4359s/100 iter), 152/232ep, loss = 3.21632
I0511 04:32:36.532129  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.63883 (* 1 = 3.63883 loss)
I0511 04:32:36.532133  5307 sgd_solver.cpp:172] Iteration 78600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:33:38.368151  5307 solver.cpp:352] Iteration 78700 (1.61721 iter/s, 61.835s/100 iter), 152.2/232ep, loss = 3.0718
I0511 04:33:38.368247  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.00937 (* 1 = 3.00937 loss)
I0511 04:33:38.368254  5307 sgd_solver.cpp:172] Iteration 78700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:34:39.152809  5307 solver.cpp:352] Iteration 78800 (1.64518 iter/s, 60.7836s/100 iter), 152.4/232ep, loss = 3.26289
I0511 04:34:39.152863  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.34513 (* 1 = 2.34513 loss)
I0511 04:34:39.152868  5307 sgd_solver.cpp:172] Iteration 78800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:35:39.979418  5307 solver.cpp:352] Iteration 78900 (1.64405 iter/s, 60.8256s/100 iter), 152.5/232ep, loss = 2.99703
I0511 04:35:39.979521  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.28211 (* 1 = 3.28211 loss)
I0511 04:35:39.979542  5307 sgd_solver.cpp:172] Iteration 78900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:36:41.730059  5307 solver.cpp:352] Iteration 79000 (1.61944 iter/s, 61.7496s/100 iter), 152.7/232ep, loss = 3.15469
I0511 04:36:41.730115  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.83027 (* 1 = 2.83027 loss)
I0511 04:36:41.730124  5307 sgd_solver.cpp:172] Iteration 79000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:37:43.383158  5307 solver.cpp:352] Iteration 79100 (1.62201 iter/s, 61.652s/100 iter), 152.9/232ep, loss = 3.03458
I0511 04:37:43.383288  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.40238 (* 1 = 3.40238 loss)
I0511 04:37:43.383308  5307 sgd_solver.cpp:172] Iteration 79100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:37:54.007740  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 04:38:44.456564  5307 solver.cpp:352] Iteration 79200 (1.6374 iter/s, 61.0724s/100 iter), 153.1/232ep, loss = 3.09404
I0511 04:38:44.456629  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.76522 (* 1 = 2.76522 loss)
I0511 04:38:44.456636  5307 sgd_solver.cpp:172] Iteration 79200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:39:46.192864  5307 solver.cpp:352] Iteration 79300 (1.61982 iter/s, 61.7352s/100 iter), 153.3/232ep, loss = 3.07999
I0511 04:39:46.192991  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.25264 (* 1 = 3.25264 loss)
I0511 04:39:46.193011  5307 sgd_solver.cpp:172] Iteration 79300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:40:47.734508  5307 solver.cpp:352] Iteration 79400 (1.62494 iter/s, 61.5406s/100 iter), 153.5/232ep, loss = 3.03022
I0511 04:40:47.734652  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.10661 (* 1 = 3.10661 loss)
I0511 04:40:47.734671  5307 sgd_solver.cpp:172] Iteration 79400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:41:48.032901  5307 solver.cpp:352] Iteration 79500 (1.65845 iter/s, 60.2974s/100 iter), 153.7/232ep, loss = 3.18149
I0511 04:41:48.032958  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.84987 (* 1 = 4.84987 loss)
I0511 04:41:48.032968  5307 sgd_solver.cpp:172] Iteration 79500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:42:48.269826  5307 solver.cpp:352] Iteration 79600 (1.66014 iter/s, 60.2359s/100 iter), 153.9/232ep, loss = 3.0324
I0511 04:42:48.269889  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.51017 (* 1 = 3.51017 loss)
I0511 04:42:48.269898  5307 sgd_solver.cpp:172] Iteration 79600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:43:08.215611  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 04:43:48.437150  5307 solver.cpp:352] Iteration 79700 (1.66206 iter/s, 60.1663s/100 iter), 154.1/232ep, loss = 3.10614
I0511 04:43:48.437216  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.18151 (* 1 = 3.18151 loss)
I0511 04:43:48.437223  5307 sgd_solver.cpp:172] Iteration 79700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:44:49.525799  5307 solver.cpp:352] Iteration 79800 (1.63699 iter/s, 61.0876s/100 iter), 154.3/232ep, loss = 2.98906
I0511 04:44:49.525918  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.24818 (* 1 = 2.24818 loss)
I0511 04:44:49.525928  5307 sgd_solver.cpp:172] Iteration 79800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:45:50.659781  5307 solver.cpp:352] Iteration 79900 (1.63578 iter/s, 61.133s/100 iter), 154.5/232ep, loss = 3.13227
I0511 04:45:50.659904  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.23574 (* 1 = 3.23574 loss)
I0511 04:45:50.659934  5307 sgd_solver.cpp:172] Iteration 79900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:46:51.066712  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_80000.caffemodel
I0511 04:46:51.080826  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_80000.solverstate
I0511 04:46:51.084496  5307 solver.cpp:635] Iteration 80000, Testing net (#0)
I0511 04:47:31.970968  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 04:47:32.214776  5307 solver.cpp:747] class AP 1: 0.656922
I0511 04:47:32.215538  5307 solver.cpp:747] class AP 2: 0.736532
I0511 04:47:32.223600  5307 solver.cpp:747] class AP 3: 0.537648
I0511 04:47:32.228229  5307 solver.cpp:747] class AP 4: 0.508865
I0511 04:47:32.246457  5307 solver.cpp:747] class AP 5: 0.331343
I0511 04:47:32.246815  5307 solver.cpp:747] class AP 6: 0.724548
I0511 04:47:32.254050  5307 solver.cpp:747] class AP 7: 0.694589
I0511 04:47:32.254701  5307 solver.cpp:747] class AP 8: 0.803459
I0511 04:47:32.274544  5307 solver.cpp:747] class AP 9: 0.431811
I0511 04:47:32.275423  5307 solver.cpp:747] class AP 10: 0.626501
I0511 04:47:32.276293  5307 solver.cpp:747] class AP 11: 0.587636
I0511 04:47:32.277295  5307 solver.cpp:747] class AP 12: 0.712719
I0511 04:47:32.277781  5307 solver.cpp:747] class AP 13: 0.787989
I0511 04:47:32.278138  5307 solver.cpp:747] class AP 14: 0.731135
I0511 04:47:32.329286  5307 solver.cpp:747] class AP 15: 0.721379
I0511 04:47:32.335880  5307 solver.cpp:747] class AP 16: 0.358117
I0511 04:47:32.338951  5307 solver.cpp:747] class AP 17: 0.586319
I0511 04:47:32.339478  5307 solver.cpp:747] class AP 18: 0.602769
I0511 04:47:32.340133  5307 solver.cpp:747] class AP 19: 0.74245
I0511 04:47:32.341581  5307 solver.cpp:747] class AP 20: 0.596077
I0511 04:47:32.341706  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.62394
I0511 04:47:32.341799  5307 solver.cpp:283] Tests completed in 101.68s
I0511 04:47:32.905565  5307 solver.cpp:352] Iteration 80000 (0.983475 iter/s, 101.68s/100 iter), 154.7/232ep, loss = 2.99031
I0511 04:47:32.905604  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.96569 (* 1 = 2.96569 loss)
I0511 04:47:32.905612  5307 sgd_solver.cpp:172] Iteration 80000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:48:34.126289  5307 solver.cpp:352] Iteration 80100 (1.63346 iter/s, 61.2196s/100 iter), 154.9/232ep, loss = 2.95308
I0511 04:48:34.126351  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.89951 (* 1 = 2.89951 loss)
I0511 04:48:34.126360  5307 sgd_solver.cpp:172] Iteration 80100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:49:05.360407  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 04:49:35.240214  5307 solver.cpp:352] Iteration 80200 (1.63632 iter/s, 61.1129s/100 iter), 155.1/232ep, loss = 3.06651
I0511 04:49:35.240325  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.07834 (* 1 = 3.07834 loss)
I0511 04:49:35.240341  5307 sgd_solver.cpp:172] Iteration 80200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:50:35.741667  5307 solver.cpp:352] Iteration 80300 (1.65288 iter/s, 60.5004s/100 iter), 155.3/232ep, loss = 3.06086
I0511 04:50:35.741739  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.36068 (* 1 = 3.36068 loss)
I0511 04:50:35.741750  5307 sgd_solver.cpp:172] Iteration 80300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:51:37.026394  5307 solver.cpp:352] Iteration 80400 (1.63176 iter/s, 61.2837s/100 iter), 155.4/232ep, loss = 3.0957
I0511 04:51:37.026475  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.44752 (* 1 = 3.44752 loss)
I0511 04:51:37.026511  5307 sgd_solver.cpp:172] Iteration 80400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:52:38.957073  5307 solver.cpp:352] Iteration 80500 (1.61474 iter/s, 61.9296s/100 iter), 155.6/232ep, loss = 3.05734
I0511 04:52:38.957156  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.89145 (* 1 = 2.89145 loss)
I0511 04:52:38.957165  5307 sgd_solver.cpp:172] Iteration 80500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:53:40.124766  5307 solver.cpp:352] Iteration 80600 (1.63488 iter/s, 61.1666s/100 iter), 155.8/232ep, loss = 3.12808
I0511 04:53:40.124861  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.12121 (* 1 = 4.12121 loss)
I0511 04:53:40.124873  5307 sgd_solver.cpp:172] Iteration 80600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:54:22.535035  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 04:54:41.483376  5307 solver.cpp:352] Iteration 80700 (1.62979 iter/s, 61.3576s/100 iter), 156/232ep, loss = 3.07514
I0511 04:54:41.483403  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.65612 (* 1 = 2.65612 loss)
I0511 04:54:41.483409  5307 sgd_solver.cpp:172] Iteration 80700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:55:43.258492  5307 solver.cpp:352] Iteration 80800 (1.6188 iter/s, 61.7741s/100 iter), 156.2/232ep, loss = 3.16967
I0511 04:55:43.261402  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.26641 (* 1 = 3.26641 loss)
I0511 04:55:43.261415  5307 sgd_solver.cpp:172] Iteration 80800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:56:44.410297  5307 solver.cpp:352] Iteration 80900 (1.6353 iter/s, 61.1508s/100 iter), 156.4/232ep, loss = 2.97334
I0511 04:56:44.410429  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.81958 (* 1 = 2.81958 loss)
I0511 04:56:44.410444  5307 sgd_solver.cpp:172] Iteration 80900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:57:45.559784  5307 solver.cpp:352] Iteration 81000 (1.63536 iter/s, 61.1484s/100 iter), 156.6/232ep, loss = 3.06272
I0511 04:57:45.559870  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.07643 (* 1 = 4.07643 loss)
I0511 04:57:45.559885  5307 sgd_solver.cpp:172] Iteration 81000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:58:47.035486  5307 solver.cpp:352] Iteration 81100 (1.62669 iter/s, 61.4747s/100 iter), 156.8/232ep, loss = 3.18442
I0511 04:58:47.035533  5307 solver.cpp:376]     Train net output #0: mbox_loss = 1.86006 (* 1 = 1.86006 loss)
I0511 04:58:47.035540  5307 sgd_solver.cpp:172] Iteration 81100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 04:59:39.381413  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 04:59:48.628669  5307 solver.cpp:352] Iteration 81200 (1.62358 iter/s, 61.5921s/100 iter), 157/232ep, loss = 2.97539
I0511 04:59:48.628701  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.39648 (* 1 = 2.39648 loss)
I0511 04:59:48.628711  5307 sgd_solver.cpp:172] Iteration 81200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:00:50.158447  5307 solver.cpp:352] Iteration 81300 (1.62526 iter/s, 61.5287s/100 iter), 157.2/232ep, loss = 3.16712
I0511 05:00:50.158540  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.19337 (* 1 = 3.19337 loss)
I0511 05:00:50.158632  5307 sgd_solver.cpp:172] Iteration 81300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:01:50.419970  5307 solver.cpp:352] Iteration 81400 (1.65946 iter/s, 60.2605s/100 iter), 157.4/232ep, loss = 2.95731
I0511 05:01:50.420078  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.30601 (* 1 = 3.30601 loss)
I0511 05:01:50.420086  5307 sgd_solver.cpp:172] Iteration 81400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:02:51.010126  5307 solver.cpp:352] Iteration 81500 (1.65046 iter/s, 60.5891s/100 iter), 157.6/232ep, loss = 3.17708
I0511 05:02:51.012492  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.81883 (* 1 = 2.81883 loss)
I0511 05:02:51.012545  5307 sgd_solver.cpp:172] Iteration 81500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:03:51.385087  5307 solver.cpp:352] Iteration 81600 (1.65634 iter/s, 60.3739s/100 iter), 157.8/232ep, loss = 3.05348
I0511 05:03:51.385354  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.47478 (* 1 = 3.47478 loss)
I0511 05:03:51.385385  5307 sgd_solver.cpp:172] Iteration 81600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:04:52.400323  5307 solver.cpp:352] Iteration 81700 (1.63896 iter/s, 61.0142s/100 iter), 158/232ep, loss = 3.07452
I0511 05:04:52.401495  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.68926 (* 1 = 3.68926 loss)
I0511 05:04:52.401525  5307 sgd_solver.cpp:172] Iteration 81700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:04:54.259804  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 05:05:52.793665  5307 solver.cpp:352] Iteration 81800 (1.65584 iter/s, 60.3923s/100 iter), 158.2/232ep, loss = 3.01624
I0511 05:05:52.793802  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.86283 (* 1 = 2.86283 loss)
I0511 05:05:52.793817  5307 sgd_solver.cpp:172] Iteration 81800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:06:54.638144  5307 solver.cpp:352] Iteration 81900 (1.61699 iter/s, 61.8434s/100 iter), 158.3/232ep, loss = 3.15624
I0511 05:06:54.638219  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.09845 (* 1 = 4.09845 loss)
I0511 05:06:54.638228  5307 sgd_solver.cpp:172] Iteration 81900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:07:55.882076  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_82000.caffemodel
I0511 05:07:55.897613  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_82000.solverstate
I0511 05:07:55.919564  5307 solver.cpp:635] Iteration 82000, Testing net (#0)
I0511 05:08:36.424590  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 05:08:36.650754  5307 solver.cpp:747] class AP 1: 0.655134
I0511 05:08:36.651391  5307 solver.cpp:747] class AP 2: 0.733262
I0511 05:08:36.658165  5307 solver.cpp:747] class AP 3: 0.534205
I0511 05:08:36.661967  5307 solver.cpp:747] class AP 4: 0.499522
I0511 05:08:36.679430  5307 solver.cpp:747] class AP 5: 0.335833
I0511 05:08:36.679822  5307 solver.cpp:747] class AP 6: 0.722328
I0511 05:08:36.688561  5307 solver.cpp:747] class AP 7: 0.701715
I0511 05:08:36.689237  5307 solver.cpp:747] class AP 8: 0.803519
I0511 05:08:36.707600  5307 solver.cpp:747] class AP 9: 0.419425
I0511 05:08:36.708217  5307 solver.cpp:747] class AP 10: 0.598135
I0511 05:08:36.708843  5307 solver.cpp:747] class AP 11: 0.574544
I0511 05:08:36.709736  5307 solver.cpp:747] class AP 12: 0.72618
I0511 05:08:36.710386  5307 solver.cpp:747] class AP 13: 0.787962
I0511 05:08:36.710856  5307 solver.cpp:747] class AP 14: 0.746405
I0511 05:08:36.762650  5307 solver.cpp:747] class AP 15: 0.723499
I0511 05:08:36.768735  5307 solver.cpp:747] class AP 16: 0.363718
I0511 05:08:36.771150  5307 solver.cpp:747] class AP 17: 0.580612
I0511 05:08:36.771631  5307 solver.cpp:747] class AP 18: 0.586409
I0511 05:08:36.772302  5307 solver.cpp:747] class AP 19: 0.74642
I0511 05:08:36.773516  5307 solver.cpp:747] class AP 20: 0.599333
I0511 05:08:36.773522  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.621908
I0511 05:08:36.773705  5307 solver.cpp:283] Tests completed in 102.134s
I0511 05:08:37.404319  5307 solver.cpp:352] Iteration 82000 (0.979107 iter/s, 102.134s/100 iter), 158.5/232ep, loss = 3.12407
I0511 05:08:37.404367  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.05297 (* 1 = 3.05297 loss)
I0511 05:08:37.404381  5307 sgd_solver.cpp:172] Iteration 82000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:09:38.488523  5307 solver.cpp:352] Iteration 82100 (1.63711 iter/s, 61.0832s/100 iter), 158.7/232ep, loss = 3.17095
I0511 05:09:38.489747  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.8145 (* 1 = 2.8145 loss)
I0511 05:09:38.489768  5307 sgd_solver.cpp:172] Iteration 82100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:10:40.255704  5307 solver.cpp:352] Iteration 82200 (1.61901 iter/s, 61.7661s/100 iter), 158.9/232ep, loss = 3.03422
I0511 05:10:40.255859  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.23898 (* 1 = 2.23898 loss)
I0511 05:10:40.256000  5307 sgd_solver.cpp:172] Iteration 82200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:10:51.850184  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 05:11:40.704710  5307 solver.cpp:352] Iteration 82300 (1.65432 iter/s, 60.448s/100 iter), 159.1/232ep, loss = 3.07507
I0511 05:11:40.704779  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.08429 (* 1 = 3.08429 loss)
I0511 05:11:40.704788  5307 sgd_solver.cpp:172] Iteration 82300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:12:41.458498  5307 solver.cpp:352] Iteration 82400 (1.64602 iter/s, 60.7528s/100 iter), 159.3/232ep, loss = 3.13112
I0511 05:12:41.458572  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.09384 (* 1 = 3.09384 loss)
I0511 05:12:41.458581  5307 sgd_solver.cpp:172] Iteration 82400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:13:42.341801  5307 solver.cpp:352] Iteration 82500 (1.64251 iter/s, 60.8823s/100 iter), 159.5/232ep, loss = 2.99072
I0511 05:13:42.341908  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.91019 (* 1 = 2.91019 loss)
I0511 05:13:42.341918  5307 sgd_solver.cpp:172] Iteration 82500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:14:42.496304  5307 solver.cpp:352] Iteration 82600 (1.66241 iter/s, 60.1535s/100 iter), 159.7/232ep, loss = 3.11013
I0511 05:14:42.496400  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.54618 (* 1 = 2.54618 loss)
I0511 05:14:42.496408  5307 sgd_solver.cpp:172] Iteration 82600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:15:43.573561  5307 solver.cpp:352] Iteration 82700 (1.6373 iter/s, 61.0762s/100 iter), 159.9/232ep, loss = 3.14549
I0511 05:15:43.573624  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.76109 (* 1 = 3.76109 loss)
I0511 05:15:43.573633  5307 sgd_solver.cpp:172] Iteration 82700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:16:06.394397  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 05:16:43.689371  5307 solver.cpp:352] Iteration 82800 (1.66348 iter/s, 60.1148s/100 iter), 160.1/232ep, loss = 3.16714
I0511 05:16:43.689472  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.97011 (* 1 = 4.97011 loss)
I0511 05:16:43.689481  5307 sgd_solver.cpp:172] Iteration 82800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:17:43.947782  5307 solver.cpp:352] Iteration 82900 (1.65955 iter/s, 60.2574s/100 iter), 160.3/232ep, loss = 3.14576
I0511 05:17:43.947850  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.03271 (* 1 = 3.03271 loss)
I0511 05:17:43.947860  5307 sgd_solver.cpp:172] Iteration 82900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:18:44.860479  5307 solver.cpp:352] Iteration 83000 (1.64172 iter/s, 60.9117s/100 iter), 160.5/232ep, loss = 3.07304
I0511 05:18:44.860572  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.58383 (* 1 = 2.58383 loss)
I0511 05:18:44.860581  5307 sgd_solver.cpp:172] Iteration 83000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:19:45.264725  5307 solver.cpp:352] Iteration 83100 (1.65554 iter/s, 60.4032s/100 iter), 160.7/232ep, loss = 3.1804
I0511 05:19:45.264848  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.89042 (* 1 = 2.89042 loss)
I0511 05:19:45.264878  5307 sgd_solver.cpp:172] Iteration 83100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:20:46.261476  5307 solver.cpp:352] Iteration 83200 (1.63946 iter/s, 60.9957s/100 iter), 160.9/232ep, loss = 3.1519
I0511 05:20:46.261567  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.90517 (* 1 = 2.90517 loss)
I0511 05:20:46.261579  5307 sgd_solver.cpp:172] Iteration 83200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:21:19.365172  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 05:21:47.061985  5307 solver.cpp:352] Iteration 83300 (1.64475 iter/s, 60.7995s/100 iter), 161.1/232ep, loss = 3.04006
I0511 05:21:47.062106  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.31735 (* 1 = 2.31735 loss)
I0511 05:21:47.062114  5307 sgd_solver.cpp:172] Iteration 83300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:22:48.098809  5307 solver.cpp:352] Iteration 83400 (1.63838 iter/s, 61.0358s/100 iter), 161.2/232ep, loss = 2.98619
I0511 05:22:48.098963  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.46974 (* 1 = 2.46974 loss)
I0511 05:22:48.098987  5307 sgd_solver.cpp:172] Iteration 83400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:23:48.358436  5307 solver.cpp:352] Iteration 83500 (1.65951 iter/s, 60.2586s/100 iter), 161.4/232ep, loss = 3.22008
I0511 05:23:48.359045  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.2878 (* 1 = 4.2878 loss)
I0511 05:23:48.359057  5307 sgd_solver.cpp:172] Iteration 83500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:24:48.559589  5307 solver.cpp:352] Iteration 83600 (1.66113 iter/s, 60.2001s/100 iter), 161.6/232ep, loss = 3.22677
I0511 05:24:48.559682  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.00922 (* 1 = 4.00922 loss)
I0511 05:24:48.559692  5307 sgd_solver.cpp:172] Iteration 83600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:25:49.113479  5307 solver.cpp:352] Iteration 83700 (1.65145 iter/s, 60.5528s/100 iter), 161.8/232ep, loss = 3.1475
I0511 05:25:49.113591  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.92199 (* 1 = 2.92199 loss)
I0511 05:25:49.113601  5307 sgd_solver.cpp:172] Iteration 83700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:26:32.403017  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 05:26:49.811486  5307 solver.cpp:352] Iteration 83800 (1.64753 iter/s, 60.697s/100 iter), 162/232ep, loss = 2.86257
I0511 05:26:49.811573  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.61325 (* 1 = 2.61325 loss)
I0511 05:26:49.811594  5307 sgd_solver.cpp:172] Iteration 83800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:27:51.098587  5307 solver.cpp:352] Iteration 83900 (1.63169 iter/s, 61.2861s/100 iter), 162.2/232ep, loss = 3.01158
I0511 05:27:51.098793  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.96056 (* 1 = 2.96056 loss)
I0511 05:27:51.098819  5307 sgd_solver.cpp:172] Iteration 83900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:28:51.532718  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_84000.caffemodel
I0511 05:28:51.545850  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_84000.solverstate
I0511 05:28:51.549816  5307 solver.cpp:635] Iteration 84000, Testing net (#0)
I0511 05:29:32.318837  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 05:29:32.539342  5307 solver.cpp:747] class AP 1: 0.657814
I0511 05:29:32.539938  5307 solver.cpp:747] class AP 2: 0.710111
I0511 05:29:32.546946  5307 solver.cpp:747] class AP 3: 0.538842
I0511 05:29:32.551157  5307 solver.cpp:747] class AP 4: 0.516887
I0511 05:29:32.570926  5307 solver.cpp:747] class AP 5: 0.332202
I0511 05:29:32.571310  5307 solver.cpp:747] class AP 6: 0.720453
I0511 05:29:32.581048  5307 solver.cpp:747] class AP 7: 0.69799
I0511 05:29:32.581704  5307 solver.cpp:747] class AP 8: 0.808262
I0511 05:29:32.599418  5307 solver.cpp:747] class AP 9: 0.417677
I0511 05:29:32.600200  5307 solver.cpp:747] class AP 10: 0.610413
I0511 05:29:32.600850  5307 solver.cpp:747] class AP 11: 0.601455
I0511 05:29:32.601739  5307 solver.cpp:747] class AP 12: 0.726204
I0511 05:29:32.602188  5307 solver.cpp:747] class AP 13: 0.7924
I0511 05:29:32.602545  5307 solver.cpp:747] class AP 14: 0.737359
I0511 05:29:32.656461  5307 solver.cpp:747] class AP 15: 0.727442
I0511 05:29:32.663388  5307 solver.cpp:747] class AP 16: 0.360737
I0511 05:29:32.666069  5307 solver.cpp:747] class AP 17: 0.601944
I0511 05:29:32.666663  5307 solver.cpp:747] class AP 18: 0.595583
I0511 05:29:32.667361  5307 solver.cpp:747] class AP 19: 0.750944
I0511 05:29:32.668655  5307 solver.cpp:747] class AP 20: 0.604164
I0511 05:29:32.668670  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.625444
I0511 05:29:32.668895  5307 solver.cpp:283] Tests completed in 101.569s
I0511 05:29:33.352635  5307 solver.cpp:352] Iteration 84000 (0.984556 iter/s, 101.569s/100 iter), 162.4/232ep, loss = 3.15069
I0511 05:29:33.352704  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.23146 (* 1 = 2.23146 loss)
I0511 05:29:33.352723  5307 sgd_solver.cpp:172] Iteration 84000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:30:34.203102  5307 solver.cpp:352] Iteration 84100 (1.6434 iter/s, 60.8494s/100 iter), 162.6/232ep, loss = 3.1621
I0511 05:30:34.203176  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.85364 (* 1 = 3.85364 loss)
I0511 05:30:34.203222  5307 sgd_solver.cpp:172] Iteration 84100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:31:38.800949  5307 solver.cpp:352] Iteration 84200 (1.54807 iter/s, 64.5967s/100 iter), 162.8/232ep, loss = 2.92466
I0511 05:31:38.804613  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.49924 (* 1 = 2.49924 loss)
I0511 05:31:38.804641  5307 sgd_solver.cpp:172] Iteration 84200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:32:40.326196  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 05:32:47.100292  5307 solver.cpp:352] Iteration 84300 (1.46417 iter/s, 68.2982s/100 iter), 163/232ep, loss = 3.00704
I0511 05:32:47.100380  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.16228 (* 1 = 3.16228 loss)
I0511 05:32:47.100400  5307 sgd_solver.cpp:172] Iteration 84300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:33:48.171579  5307 solver.cpp:352] Iteration 84400 (1.63746 iter/s, 61.0702s/100 iter), 163.2/232ep, loss = 3.09693
I0511 05:33:48.171639  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.22999 (* 1 = 3.22999 loss)
I0511 05:33:48.171648  5307 sgd_solver.cpp:172] Iteration 84400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:34:49.438040  5307 solver.cpp:352] Iteration 84500 (1.63224 iter/s, 61.2654s/100 iter), 163.4/232ep, loss = 3.14147
I0511 05:34:49.438123  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.30156 (* 1 = 3.30156 loss)
I0511 05:34:49.438133  5307 sgd_solver.cpp:172] Iteration 84500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:35:50.558140  5307 solver.cpp:352] Iteration 84600 (1.63615 iter/s, 61.119s/100 iter), 163.6/232ep, loss = 3.1531
I0511 05:35:50.558445  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.08956 (* 1 = 3.08956 loss)
I0511 05:35:50.558482  5307 sgd_solver.cpp:172] Iteration 84600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:36:51.441037  5307 solver.cpp:352] Iteration 84700 (1.64252 iter/s, 60.8819s/100 iter), 163.8/232ep, loss = 3.01361
I0511 05:36:51.442643  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.2958 (* 1 = 3.2958 loss)
I0511 05:36:51.442658  5307 sgd_solver.cpp:172] Iteration 84700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:37:51.773715  5307 solver.cpp:352] Iteration 84800 (1.6575 iter/s, 60.3316s/100 iter), 164/232ep, loss = 3.08956
I0511 05:37:51.773800  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.61149 (* 1 = 3.61149 loss)
I0511 05:37:51.773808  5307 sgd_solver.cpp:172] Iteration 84800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:37:54.923580  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 05:38:52.148077  5307 solver.cpp:352] Iteration 84900 (1.65636 iter/s, 60.3733s/100 iter), 164.1/232ep, loss = 2.88072
I0511 05:38:52.148218  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.33891 (* 1 = 3.33891 loss)
I0511 05:38:52.148241  5307 sgd_solver.cpp:172] Iteration 84900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:39:52.873411  5307 solver.cpp:352] Iteration 85000 (1.64679 iter/s, 60.7243s/100 iter), 164.3/232ep, loss = 3.03843
I0511 05:39:52.873515  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.0034 (* 1 = 3.0034 loss)
I0511 05:39:52.873525  5307 sgd_solver.cpp:172] Iteration 85000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:40:53.578524  5307 solver.cpp:352] Iteration 85100 (1.64734 iter/s, 60.7041s/100 iter), 164.5/232ep, loss = 2.99282
I0511 05:40:53.579010  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.06392 (* 1 = 3.06392 loss)
I0511 05:40:53.579025  5307 sgd_solver.cpp:172] Iteration 85100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:41:54.347714  5307 solver.cpp:352] Iteration 85200 (1.6456 iter/s, 60.7682s/100 iter), 164.7/232ep, loss = 3.18014
I0511 05:41:54.347831  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.2297 (* 1 = 3.2297 loss)
I0511 05:41:54.347851  5307 sgd_solver.cpp:172] Iteration 85200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:42:56.362783  5307 solver.cpp:352] Iteration 85300 (1.61254 iter/s, 62.014s/100 iter), 164.9/232ep, loss = 2.98081
I0511 05:42:56.362850  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.67103 (* 1 = 2.67103 loss)
I0511 05:42:56.362859  5307 sgd_solver.cpp:172] Iteration 85300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:43:10.316454  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 05:43:56.733450  5307 solver.cpp:352] Iteration 85400 (1.65646 iter/s, 60.3696s/100 iter), 165.1/232ep, loss = 3.11945
I0511 05:43:56.733593  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.08746 (* 1 = 3.08746 loss)
I0511 05:43:56.733611  5307 sgd_solver.cpp:172] Iteration 85400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:44:58.045892  5307 solver.cpp:352] Iteration 85500 (1.63102 iter/s, 61.3114s/100 iter), 165.3/232ep, loss = 3.0195
I0511 05:44:58.045987  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.69612 (* 1 = 2.69612 loss)
I0511 05:44:58.046008  5307 sgd_solver.cpp:172] Iteration 85500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:45:58.778966  5307 solver.cpp:352] Iteration 85600 (1.64658 iter/s, 60.732s/100 iter), 165.5/232ep, loss = 2.96903
I0511 05:45:58.781806  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.53359 (* 1 = 3.53359 loss)
I0511 05:45:58.781831  5307 sgd_solver.cpp:172] Iteration 85600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:46:59.483292  5307 solver.cpp:352] Iteration 85700 (1.64736 iter/s, 60.7033s/100 iter), 165.7/232ep, loss = 3.0415
I0511 05:46:59.483381  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.60919 (* 1 = 2.60919 loss)
I0511 05:46:59.483388  5307 sgd_solver.cpp:172] Iteration 85700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:47:59.298246  5307 solver.cpp:352] Iteration 85800 (1.67185 iter/s, 59.8139s/100 iter), 165.9/232ep, loss = 2.86475
I0511 05:47:59.298338  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.01744 (* 1 = 3.01744 loss)
I0511 05:47:59.298348  5307 sgd_solver.cpp:172] Iteration 85800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:48:24.107800  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 05:48:59.673207  5307 solver.cpp:352] Iteration 85900 (1.65634 iter/s, 60.3739s/100 iter), 166.1/232ep, loss = 2.76809
I0511 05:48:59.673928  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.84943 (* 1 = 2.84943 loss)
I0511 05:48:59.674026  5307 sgd_solver.cpp:172] Iteration 85900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:50:00.043298  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_86000.caffemodel
I0511 05:50:00.075486  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_86000.solverstate
I0511 05:50:00.080802  5307 solver.cpp:635] Iteration 86000, Testing net (#0)
I0511 05:50:40.533110  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 05:50:40.757798  5307 solver.cpp:747] class AP 1: 0.644248
I0511 05:50:40.758245  5307 solver.cpp:747] class AP 2: 0.7234
I0511 05:50:40.767001  5307 solver.cpp:747] class AP 3: 0.546652
I0511 05:50:40.770838  5307 solver.cpp:747] class AP 4: 0.505063
I0511 05:50:40.789113  5307 solver.cpp:747] class AP 5: 0.336162
I0511 05:50:40.789417  5307 solver.cpp:747] class AP 6: 0.731788
I0511 05:50:40.798163  5307 solver.cpp:747] class AP 7: 0.704465
I0511 05:50:40.798924  5307 solver.cpp:747] class AP 8: 0.799013
I0511 05:50:40.818701  5307 solver.cpp:747] class AP 9: 0.418467
I0511 05:50:40.819725  5307 solver.cpp:747] class AP 10: 0.618901
I0511 05:50:40.820538  5307 solver.cpp:747] class AP 11: 0.581964
I0511 05:50:40.821631  5307 solver.cpp:747] class AP 12: 0.724035
I0511 05:50:40.822109  5307 solver.cpp:747] class AP 13: 0.787672
I0511 05:50:40.822438  5307 solver.cpp:747] class AP 14: 0.737262
I0511 05:50:40.870316  5307 solver.cpp:747] class AP 15: 0.724478
I0511 05:50:40.876652  5307 solver.cpp:747] class AP 16: 0.359236
I0511 05:50:40.879967  5307 solver.cpp:747] class AP 17: 0.581703
I0511 05:50:40.880720  5307 solver.cpp:747] class AP 18: 0.595236
I0511 05:50:40.881427  5307 solver.cpp:747] class AP 19: 0.748551
I0511 05:50:40.882745  5307 solver.cpp:747] class AP 20: 0.608915
I0511 05:50:40.882756  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.62386
I0511 05:50:40.882899  5307 solver.cpp:283] Tests completed in 101.208s
I0511 05:50:41.464840  5307 solver.cpp:352] Iteration 86000 (0.988064 iter/s, 101.208s/100 iter), 166.3/232ep, loss = 2.9692
I0511 05:50:41.464874  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.43173 (* 1 = 3.43173 loss)
I0511 05:50:41.464881  5307 sgd_solver.cpp:172] Iteration 86000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:51:42.045100  5307 solver.cpp:352] Iteration 86100 (1.65073 iter/s, 60.5792s/100 iter), 166.5/232ep, loss = 3.0519
I0511 05:51:42.045164  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.30511 (* 1 = 3.30511 loss)
I0511 05:51:42.045173  5307 sgd_solver.cpp:172] Iteration 86100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:52:42.345363  5307 solver.cpp:352] Iteration 86200 (1.6584 iter/s, 60.2992s/100 iter), 166.7/232ep, loss = 3.13449
I0511 05:52:42.345502  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.16417 (* 1 = 3.16417 loss)
I0511 05:52:42.345513  5307 sgd_solver.cpp:172] Iteration 86200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:53:44.037740  5307 solver.cpp:352] Iteration 86300 (1.62097 iter/s, 61.6913s/100 iter), 166.9/232ep, loss = 3.16945
I0511 05:53:44.037837  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.6172 (* 1 = 2.6172 loss)
I0511 05:53:44.037858  5307 sgd_solver.cpp:172] Iteration 86300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:54:18.505733  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 05:54:44.654685  5307 solver.cpp:352] Iteration 86400 (1.64973 iter/s, 60.6159s/100 iter), 167/232ep, loss = 2.95208
I0511 05:54:44.654716  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.17169 (* 1 = 3.17169 loss)
I0511 05:54:44.654723  5307 sgd_solver.cpp:172] Iteration 86400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:55:45.467463  5307 solver.cpp:352] Iteration 86500 (1.64442 iter/s, 60.8117s/100 iter), 167.2/232ep, loss = 3.02727
I0511 05:55:45.467547  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.26439 (* 1 = 3.26439 loss)
I0511 05:55:45.467557  5307 sgd_solver.cpp:172] Iteration 86500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:56:45.926738  5307 solver.cpp:352] Iteration 86600 (1.65403 iter/s, 60.4583s/100 iter), 167.4/232ep, loss = 3.08285
I0511 05:56:45.926811  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.81787 (* 1 = 2.81787 loss)
I0511 05:56:45.926820  5307 sgd_solver.cpp:172] Iteration 86600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:57:46.451650  5307 solver.cpp:352] Iteration 86700 (1.65224 iter/s, 60.5239s/100 iter), 167.6/232ep, loss = 3.07502
I0511 05:57:46.451722  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.93777 (* 1 = 3.93777 loss)
I0511 05:57:46.451735  5307 sgd_solver.cpp:172] Iteration 86700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:58:47.215143  5307 solver.cpp:352] Iteration 86800 (1.64575 iter/s, 60.7625s/100 iter), 167.8/232ep, loss = 3.04614
I0511 05:58:47.215207  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.41199 (* 1 = 3.41199 loss)
I0511 05:58:47.215215  5307 sgd_solver.cpp:172] Iteration 86800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 05:59:32.973482  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 05:59:48.104275  5307 solver.cpp:352] Iteration 86900 (1.64236 iter/s, 60.8881s/100 iter), 168/232ep, loss = 3.05184
I0511 05:59:48.104303  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.73959 (* 1 = 2.73959 loss)
I0511 05:59:48.104311  5307 sgd_solver.cpp:172] Iteration 86900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:00:48.318265  5307 solver.cpp:352] Iteration 87000 (1.66077 iter/s, 60.213s/100 iter), 168.2/232ep, loss = 2.91989
I0511 06:00:48.318336  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.71483 (* 1 = 2.71483 loss)
I0511 06:00:48.318347  5307 sgd_solver.cpp:172] Iteration 87000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:01:48.634670  5307 solver.cpp:352] Iteration 87100 (1.65795 iter/s, 60.3154s/100 iter), 168.4/232ep, loss = 2.80193
I0511 06:01:48.635248  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.13481 (* 1 = 2.13481 loss)
I0511 06:01:48.635268  5307 sgd_solver.cpp:172] Iteration 87100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:02:48.851761  5307 solver.cpp:352] Iteration 87200 (1.66069 iter/s, 60.2161s/100 iter), 168.6/232ep, loss = 3.02473
I0511 06:02:48.851871  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.85324 (* 1 = 2.85324 loss)
I0511 06:02:48.851884  5307 sgd_solver.cpp:172] Iteration 87200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:03:50.542805  5307 solver.cpp:352] Iteration 87300 (1.62101 iter/s, 61.69s/100 iter), 168.8/232ep, loss = 3.01181
I0511 06:03:50.542874  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.18435 (* 1 = 3.18435 loss)
I0511 06:03:50.542882  5307 sgd_solver.cpp:172] Iteration 87300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:04:46.543390  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 06:04:52.260768  5307 solver.cpp:352] Iteration 87400 (1.6203 iter/s, 61.7169s/100 iter), 169/232ep, loss = 3.18492
I0511 06:04:52.261236  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.20891 (* 1 = 3.20891 loss)
I0511 06:04:52.261292  5307 sgd_solver.cpp:172] Iteration 87400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:05:54.376600  5307 solver.cpp:352] Iteration 87500 (1.60992 iter/s, 62.1148s/100 iter), 169.2/232ep, loss = 2.98092
I0511 06:05:54.376689  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.77034 (* 1 = 2.77034 loss)
I0511 06:05:54.376699  5307 sgd_solver.cpp:172] Iteration 87500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:06:56.324757  5307 solver.cpp:352] Iteration 87600 (1.61428 iter/s, 61.9471s/100 iter), 169.4/232ep, loss = 3.09123
I0511 06:06:56.324951  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.59935 (* 1 = 2.59935 loss)
I0511 06:06:56.324972  5307 sgd_solver.cpp:172] Iteration 87600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:07:58.232978  5307 solver.cpp:352] Iteration 87700 (1.61532 iter/s, 61.9072s/100 iter), 169.6/232ep, loss = 2.86781
I0511 06:07:58.233054  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.15377 (* 1 = 3.15377 loss)
I0511 06:07:58.233119  5307 sgd_solver.cpp:172] Iteration 87700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:09:00.459904  5307 solver.cpp:352] Iteration 87800 (1.60705 iter/s, 62.2258s/100 iter), 169.8/232ep, loss = 3.03055
I0511 06:09:00.460453  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.51731 (* 1 = 2.51731 loss)
I0511 06:09:00.460474  5307 sgd_solver.cpp:172] Iteration 87800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:10:01.098047  5307 solver.cpp:352] Iteration 87900 (1.64916 iter/s, 60.6371s/100 iter), 169.9/232ep, loss = 2.96504
I0511 06:10:01.098119  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.47514 (* 1 = 2.47514 loss)
I0511 06:10:01.098127  5307 sgd_solver.cpp:172] Iteration 87900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:10:06.589433  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 06:11:01.903599  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_88000.caffemodel
I0511 06:11:01.921385  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_88000.solverstate
I0511 06:11:01.929335  5307 solver.cpp:635] Iteration 88000, Testing net (#0)
I0511 06:11:42.505491  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 06:11:42.742010  5307 solver.cpp:747] class AP 1: 0.660187
I0511 06:11:42.742581  5307 solver.cpp:747] class AP 2: 0.72923
I0511 06:11:42.749033  5307 solver.cpp:747] class AP 3: 0.554101
I0511 06:11:42.752707  5307 solver.cpp:747] class AP 4: 0.490957
I0511 06:11:42.773998  5307 solver.cpp:747] class AP 5: 0.331025
I0511 06:11:42.774334  5307 solver.cpp:747] class AP 6: 0.724311
I0511 06:11:42.783169  5307 solver.cpp:747] class AP 7: 0.705649
I0511 06:11:42.783768  5307 solver.cpp:747] class AP 8: 0.79094
I0511 06:11:42.803867  5307 solver.cpp:747] class AP 9: 0.44045
I0511 06:11:42.804479  5307 solver.cpp:747] class AP 10: 0.621599
I0511 06:11:42.805268  5307 solver.cpp:747] class AP 11: 0.60273
I0511 06:11:42.806205  5307 solver.cpp:747] class AP 12: 0.717561
I0511 06:11:42.806623  5307 solver.cpp:747] class AP 13: 0.788349
I0511 06:11:42.806979  5307 solver.cpp:747] class AP 14: 0.743536
I0511 06:11:42.860196  5307 solver.cpp:747] class AP 15: 0.724921
I0511 06:11:42.868512  5307 solver.cpp:747] class AP 16: 0.353575
I0511 06:11:42.871130  5307 solver.cpp:747] class AP 17: 0.587968
I0511 06:11:42.871780  5307 solver.cpp:747] class AP 18: 0.601266
I0511 06:11:42.872375  5307 solver.cpp:747] class AP 19: 0.739207
I0511 06:11:42.873889  5307 solver.cpp:747] class AP 20: 0.605896
I0511 06:11:42.873899  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.625673
I0511 06:11:42.874081  5307 solver.cpp:283] Tests completed in 101.774s
I0511 06:11:43.418345  5307 solver.cpp:352] Iteration 88000 (0.982566 iter/s, 101.774s/100 iter), 170.1/232ep, loss = 3.05336
I0511 06:11:43.418370  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.2318 (* 1 = 3.2318 loss)
I0511 06:11:43.418378  5307 sgd_solver.cpp:172] Iteration 88000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:12:44.214612  5307 solver.cpp:352] Iteration 88100 (1.64487 iter/s, 60.7952s/100 iter), 170.3/232ep, loss = 3.18775
I0511 06:12:44.214668  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.04814 (* 1 = 3.04814 loss)
I0511 06:12:44.214675  5307 sgd_solver.cpp:172] Iteration 88100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:13:45.426923  5307 solver.cpp:352] Iteration 88200 (1.63369 iter/s, 61.2112s/100 iter), 170.5/232ep, loss = 2.93526
I0511 06:13:45.427034  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.69837 (* 1 = 3.69837 loss)
I0511 06:13:45.427053  5307 sgd_solver.cpp:172] Iteration 88200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:14:47.090023  5307 solver.cpp:352] Iteration 88300 (1.62174 iter/s, 61.662s/100 iter), 170.7/232ep, loss = 3.13437
I0511 06:14:47.090090  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.11089 (* 1 = 3.11089 loss)
I0511 06:14:47.090100  5307 sgd_solver.cpp:172] Iteration 88300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:15:48.794766  5307 solver.cpp:352] Iteration 88400 (1.62065 iter/s, 61.7037s/100 iter), 170.9/232ep, loss = 3.03478
I0511 06:15:48.795208  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.87982 (* 1 = 3.87982 loss)
I0511 06:15:48.795225  5307 sgd_solver.cpp:172] Iteration 88400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:16:05.361198  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 06:16:50.024565  5307 solver.cpp:352] Iteration 88500 (1.63322 iter/s, 61.2287s/100 iter), 171.1/232ep, loss = 2.96032
I0511 06:16:50.024686  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.97389 (* 1 = 2.97389 loss)
I0511 06:16:50.024703  5307 sgd_solver.cpp:172] Iteration 88500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:17:52.224668  5307 solver.cpp:352] Iteration 88600 (1.60774 iter/s, 62.1991s/100 iter), 171.3/232ep, loss = 3.26774
I0511 06:17:52.225001  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.02001 (* 1 = 4.02001 loss)
I0511 06:17:52.225014  5307 sgd_solver.cpp:172] Iteration 88600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:18:54.006628  5307 solver.cpp:352] Iteration 88700 (1.61862 iter/s, 61.7809s/100 iter), 171.5/232ep, loss = 2.90802
I0511 06:18:54.006784  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.11486 (* 1 = 3.11486 loss)
I0511 06:18:54.006793  5307 sgd_solver.cpp:172] Iteration 88700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:19:56.394021  5307 solver.cpp:352] Iteration 88800 (1.60292 iter/s, 62.3863s/100 iter), 171.7/232ep, loss = 3.09054
I0511 06:19:56.394305  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.78126 (* 1 = 2.78126 loss)
I0511 06:19:56.394325  5307 sgd_solver.cpp:172] Iteration 88800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:20:57.952348  5307 solver.cpp:352] Iteration 88900 (1.6245 iter/s, 61.5573s/100 iter), 171.9/232ep, loss = 2.90461
I0511 06:20:57.960649  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.8149 (* 1 = 2.8149 loss)
I0511 06:20:57.960680  5307 sgd_solver.cpp:172] Iteration 88900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:21:24.568037  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 06:21:59.451285  5307 solver.cpp:352] Iteration 89000 (1.62607 iter/s, 61.4979s/100 iter), 172.1/232ep, loss = 2.94432
I0511 06:21:59.451416  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.15219 (* 1 = 3.15219 loss)
I0511 06:21:59.451439  5307 sgd_solver.cpp:172] Iteration 89000, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:23:01.246716  5307 solver.cpp:352] Iteration 89100 (1.61827 iter/s, 61.7944s/100 iter), 172.3/232ep, loss = 3.05031
I0511 06:23:01.248620  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.08868 (* 1 = 3.08868 loss)
I0511 06:23:01.248646  5307 sgd_solver.cpp:172] Iteration 89100, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:24:03.109206  5307 solver.cpp:352] Iteration 89200 (1.61652 iter/s, 61.8614s/100 iter), 172.5/232ep, loss = 2.96362
I0511 06:24:03.109306  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.3566 (* 1 = 3.3566 loss)
I0511 06:24:03.109318  5307 sgd_solver.cpp:172] Iteration 89200, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:25:04.702862  5307 solver.cpp:352] Iteration 89300 (1.62357 iter/s, 61.5926s/100 iter), 172.7/232ep, loss = 3.08537
I0511 06:25:04.706243  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.38645 (* 1 = 3.38645 loss)
I0511 06:25:04.706276  5307 sgd_solver.cpp:172] Iteration 89300, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:26:04.479785  5307 solver.cpp:352] Iteration 89400 (1.67292 iter/s, 59.7759s/100 iter), 172.8/232ep, loss = 3.3297
I0511 06:26:04.480430  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.15903 (* 1 = 2.15903 loss)
I0511 06:26:04.482417  5307 sgd_solver.cpp:172] Iteration 89400, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:26:41.524902  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 06:27:05.238521  5307 solver.cpp:352] Iteration 89500 (1.64588 iter/s, 60.7577s/100 iter), 173/232ep, loss = 2.87615
I0511 06:27:05.238606  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.73996 (* 1 = 2.73996 loss)
I0511 06:27:05.238634  5307 sgd_solver.cpp:172] Iteration 89500, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:28:05.023437  5307 solver.cpp:352] Iteration 89600 (1.67269 iter/s, 59.7839s/100 iter), 173.2/232ep, loss = 3.24382
I0511 06:28:05.023519  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.9831 (* 1 = 2.9831 loss)
I0511 06:28:05.023528  5307 sgd_solver.cpp:172] Iteration 89600, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:29:06.104635  5307 solver.cpp:352] Iteration 89700 (1.63719 iter/s, 61.0802s/100 iter), 173.4/232ep, loss = 2.88581
I0511 06:29:06.104703  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.50106 (* 1 = 3.50106 loss)
I0511 06:29:06.104714  5307 sgd_solver.cpp:172] Iteration 89700, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:30:05.908205  5307 solver.cpp:352] Iteration 89800 (1.67217 iter/s, 59.8026s/100 iter), 173.6/232ep, loss = 3.19147
I0511 06:30:05.908301  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.82678 (* 1 = 3.82678 loss)
I0511 06:30:05.908309  5307 sgd_solver.cpp:172] Iteration 89800, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:31:06.240638  5307 solver.cpp:352] Iteration 89900 (1.65751 iter/s, 60.3314s/100 iter), 173.8/232ep, loss = 2.92829
I0511 06:31:06.244410  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.11302 (* 1 = 2.11302 loss)
I0511 06:31:06.244437  5307 sgd_solver.cpp:172] Iteration 89900, lr = 0.001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:31:54.437822  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 06:32:06.440652  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_90000.caffemodel
I0511 06:32:06.464042  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_90000.solverstate
I0511 06:32:06.470664  5307 solver.cpp:635] Iteration 90000, Testing net (#0)
I0511 06:32:46.600402  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 06:32:46.823004  5307 solver.cpp:747] class AP 1: 0.652784
I0511 06:32:46.823493  5307 solver.cpp:747] class AP 2: 0.729538
I0511 06:32:46.831249  5307 solver.cpp:747] class AP 3: 0.55649
I0511 06:32:46.834486  5307 solver.cpp:747] class AP 4: 0.508623
I0511 06:32:46.852995  5307 solver.cpp:747] class AP 5: 0.329417
I0511 06:32:46.853309  5307 solver.cpp:747] class AP 6: 0.730925
I0511 06:32:46.861941  5307 solver.cpp:747] class AP 7: 0.694457
I0511 06:32:46.862560  5307 solver.cpp:747] class AP 8: 0.807829
I0511 06:32:46.881888  5307 solver.cpp:747] class AP 9: 0.420227
I0511 06:32:46.882714  5307 solver.cpp:747] class AP 10: 0.632828
I0511 06:32:46.883391  5307 solver.cpp:747] class AP 11: 0.577087
I0511 06:32:46.884311  5307 solver.cpp:747] class AP 12: 0.722598
I0511 06:32:46.884766  5307 solver.cpp:747] class AP 13: 0.793949
I0511 06:32:46.885109  5307 solver.cpp:747] class AP 14: 0.735033
I0511 06:32:46.930568  5307 solver.cpp:747] class AP 15: 0.723676
I0511 06:32:46.937418  5307 solver.cpp:747] class AP 16: 0.361499
I0511 06:32:46.940719  5307 solver.cpp:747] class AP 17: 0.601625
I0511 06:32:46.941234  5307 solver.cpp:747] class AP 18: 0.612741
I0511 06:32:46.941953  5307 solver.cpp:747] class AP 19: 0.744411
I0511 06:32:46.943197  5307 solver.cpp:747] class AP 20: 0.607792
I0511 06:32:46.943202  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.627176
I0511 06:32:46.943362  5307 solver.cpp:283] Tests completed in 100.701s
I0511 06:32:47.283601  5355 sgd_solver.cpp:50] MultiStep Status: Iteration 90000, step = 2
I0511 06:32:47.528645  5307 solver.cpp:352] Iteration 90000 (0.993038 iter/s, 100.701s/100 iter), 174/232ep, loss = 3.06175
I0511 06:32:47.528715  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.88285 (* 1 = 3.88285 loss)
I0511 06:32:47.528735  5307 sgd_solver.cpp:172] Iteration 90000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:33:48.304985  5307 solver.cpp:352] Iteration 90100 (1.64541 iter/s, 60.7753s/100 iter), 174.2/232ep, loss = 2.96418
I0511 06:33:48.305083  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.5118 (* 1 = 2.5118 loss)
I0511 06:33:48.305094  5307 sgd_solver.cpp:172] Iteration 90100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:34:49.420004  5307 solver.cpp:352] Iteration 90200 (1.63629 iter/s, 61.114s/100 iter), 174.4/232ep, loss = 2.87708
I0511 06:34:49.420078  5307 solver.cpp:376]     Train net output #0: mbox_loss = 1.96865 (* 1 = 1.96865 loss)
I0511 06:34:49.420086  5307 sgd_solver.cpp:172] Iteration 90200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:35:50.142431  5307 solver.cpp:352] Iteration 90300 (1.64687 iter/s, 60.7214s/100 iter), 174.6/232ep, loss = 3.06197
I0511 06:35:50.142529  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.39679 (* 1 = 2.39679 loss)
I0511 06:35:50.142539  5307 sgd_solver.cpp:172] Iteration 90300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:36:50.662226  5307 solver.cpp:352] Iteration 90400 (1.65238 iter/s, 60.5188s/100 iter), 174.8/232ep, loss = 2.87284
I0511 06:36:50.662303  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.83573 (* 1 = 2.83573 loss)
I0511 06:36:50.662312  5307 sgd_solver.cpp:172] Iteration 90400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:37:48.705770  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 06:37:51.686559  5307 solver.cpp:352] Iteration 90500 (1.63872 iter/s, 61.0233s/100 iter), 175/232ep, loss = 3.05013
I0511 06:37:51.686622  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.23287 (* 1 = 2.23287 loss)
I0511 06:37:51.686633  5307 sgd_solver.cpp:172] Iteration 90500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:38:55.799005  5307 solver.cpp:352] Iteration 90600 (1.55979 iter/s, 64.1114s/100 iter), 175.2/232ep, loss = 3.02569
I0511 06:38:55.804631  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.77855 (* 1 = 2.77855 loss)
I0511 06:38:55.804669  5307 sgd_solver.cpp:172] Iteration 90600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:40:04.341732  5307 solver.cpp:352] Iteration 90700 (1.45897 iter/s, 68.5415s/100 iter), 175.4/232ep, loss = 3.20002
I0511 06:40:04.341799  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.9114 (* 1 = 2.9114 loss)
I0511 06:40:04.341811  5307 sgd_solver.cpp:172] Iteration 90700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:41:06.142693  5307 solver.cpp:352] Iteration 90800 (1.61813 iter/s, 61.7999s/100 iter), 175.6/232ep, loss = 2.92238
I0511 06:41:06.142745  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.49991 (* 1 = 2.49991 loss)
I0511 06:41:06.142753  5307 sgd_solver.cpp:172] Iteration 90800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:42:06.225172  5307 solver.cpp:352] Iteration 90900 (1.66441 iter/s, 60.0814s/100 iter), 175.7/232ep, loss = 3.06205
I0511 06:42:06.225240  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.38434 (* 1 = 3.38434 loss)
I0511 06:42:06.225250  5307 sgd_solver.cpp:172] Iteration 90900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:43:06.774168  5307 solver.cpp:352] Iteration 91000 (1.65158 iter/s, 60.548s/100 iter), 175.9/232ep, loss = 2.8425
I0511 06:43:06.774284  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.09239 (* 1 = 3.09239 loss)
I0511 06:43:06.774297  5307 sgd_solver.cpp:172] Iteration 91000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:43:14.753564  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 06:44:06.892729  5307 solver.cpp:352] Iteration 91100 (1.66341 iter/s, 60.1176s/100 iter), 176.1/232ep, loss = 2.96822
I0511 06:44:06.892796  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.7695 (* 1 = 2.7695 loss)
I0511 06:44:06.892803  5307 sgd_solver.cpp:172] Iteration 91100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:45:07.706563  5307 solver.cpp:352] Iteration 91200 (1.64439 iter/s, 60.8128s/100 iter), 176.3/232ep, loss = 3.08933
I0511 06:45:07.706674  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.11674 (* 1 = 3.11674 loss)
I0511 06:45:07.706684  5307 sgd_solver.cpp:172] Iteration 91200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:46:08.655390  5307 solver.cpp:352] Iteration 91300 (1.64075 iter/s, 60.9478s/100 iter), 176.5/232ep, loss = 2.94552
I0511 06:46:08.655488  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.26752 (* 1 = 3.26752 loss)
I0511 06:46:08.655509  5307 sgd_solver.cpp:172] Iteration 91300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:47:09.975742  5307 solver.cpp:352] Iteration 91400 (1.63081 iter/s, 61.3193s/100 iter), 176.7/232ep, loss = 2.98143
I0511 06:47:09.975798  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.4964 (* 1 = 3.4964 loss)
I0511 06:47:09.975806  5307 sgd_solver.cpp:172] Iteration 91400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:48:10.877688  5307 solver.cpp:352] Iteration 91500 (1.64201 iter/s, 60.9009s/100 iter), 176.9/232ep, loss = 2.77348
I0511 06:48:10.877744  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.87046 (* 1 = 2.87046 loss)
I0511 06:48:10.877751  5307 sgd_solver.cpp:172] Iteration 91500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:48:28.336748  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 06:49:11.077268  5307 solver.cpp:352] Iteration 91600 (1.66117 iter/s, 60.1986s/100 iter), 177.1/232ep, loss = 2.87366
I0511 06:49:11.077348  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.23284 (* 1 = 2.23284 loss)
I0511 06:49:11.077368  5307 sgd_solver.cpp:172] Iteration 91600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:50:12.198155  5307 solver.cpp:352] Iteration 91700 (1.63613 iter/s, 61.1199s/100 iter), 177.3/232ep, loss = 3.02639
I0511 06:50:12.198213  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.30429 (* 1 = 3.30429 loss)
I0511 06:50:12.198221  5307 sgd_solver.cpp:172] Iteration 91700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:51:12.915246  5307 solver.cpp:352] Iteration 91800 (1.64701 iter/s, 60.7161s/100 iter), 177.5/232ep, loss = 3.15878
I0511 06:51:12.916009  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.44774 (* 1 = 3.44774 loss)
I0511 06:51:12.916018  5307 sgd_solver.cpp:172] Iteration 91800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:52:13.195530  5307 solver.cpp:352] Iteration 91900 (1.65895 iter/s, 60.2793s/100 iter), 177.7/232ep, loss = 2.94377
I0511 06:52:13.195955  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.51839 (* 1 = 2.51839 loss)
I0511 06:52:13.195963  5307 sgd_solver.cpp:172] Iteration 91900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:53:13.970113  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_92000.caffemodel
I0511 06:53:13.984675  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_92000.solverstate
I0511 06:53:13.989930  5307 solver.cpp:635] Iteration 92000, Testing net (#0)
I0511 06:53:54.539722  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 06:53:54.751148  5307 solver.cpp:747] class AP 1: 0.6524
I0511 06:53:54.751955  5307 solver.cpp:747] class AP 2: 0.72956
I0511 06:53:54.760458  5307 solver.cpp:747] class AP 3: 0.558785
I0511 06:53:54.765637  5307 solver.cpp:747] class AP 4: 0.518879
I0511 06:53:54.789904  5307 solver.cpp:747] class AP 5: 0.337961
I0511 06:53:54.790262  5307 solver.cpp:747] class AP 6: 0.732748
I0511 06:53:54.799666  5307 solver.cpp:747] class AP 7: 0.701902
I0511 06:53:54.800206  5307 solver.cpp:747] class AP 8: 0.804724
I0511 06:53:54.820778  5307 solver.cpp:747] class AP 9: 0.430797
I0511 06:53:54.821504  5307 solver.cpp:747] class AP 10: 0.621646
I0511 06:53:54.822299  5307 solver.cpp:747] class AP 11: 0.589305
I0511 06:53:54.823139  5307 solver.cpp:747] class AP 12: 0.718752
I0511 06:53:54.823617  5307 solver.cpp:747] class AP 13: 0.795582
I0511 06:53:54.823979  5307 solver.cpp:747] class AP 14: 0.749374
I0511 06:53:54.879411  5307 solver.cpp:747] class AP 15: 0.726554
I0511 06:53:54.886247  5307 solver.cpp:747] class AP 16: 0.357537
I0511 06:53:54.888780  5307 solver.cpp:747] class AP 17: 0.593442
I0511 06:53:54.889374  5307 solver.cpp:747] class AP 18: 0.619407
I0511 06:53:54.890004  5307 solver.cpp:747] class AP 19: 0.7472
I0511 06:53:54.891474  5307 solver.cpp:747] class AP 20: 0.609963
I0511 06:53:54.891482  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.629826
I0511 06:53:54.891830  5307 solver.cpp:283] Tests completed in 101.695s
I0511 06:53:55.485334  5307 solver.cpp:352] Iteration 92000 (0.983336 iter/s, 101.695s/100 iter), 177.9/232ep, loss = 2.87393
I0511 06:53:55.485361  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.63063 (* 1 = 2.63063 loss)
I0511 06:53:55.485369  5307 sgd_solver.cpp:172] Iteration 92000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:54:23.681706  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 06:54:55.911607  5307 solver.cpp:352] Iteration 92100 (1.65494 iter/s, 60.4252s/100 iter), 178.1/232ep, loss = 2.93419
I0511 06:54:55.911684  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.47136 (* 1 = 3.47136 loss)
I0511 06:54:55.911695  5307 sgd_solver.cpp:172] Iteration 92100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:55:56.659097  5307 solver.cpp:352] Iteration 92200 (1.64619 iter/s, 60.7464s/100 iter), 178.3/232ep, loss = 3.30948
I0511 06:55:56.659168  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.13782 (* 1 = 4.13782 loss)
I0511 06:55:56.659178  5307 sgd_solver.cpp:172] Iteration 92200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:56:56.856077  5307 solver.cpp:352] Iteration 92300 (1.66124 iter/s, 60.1959s/100 iter), 178.5/232ep, loss = 2.98758
I0511 06:56:56.856153  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.08614 (* 1 = 3.08614 loss)
I0511 06:56:56.856160  5307 sgd_solver.cpp:172] Iteration 92300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:57:57.516736  5307 solver.cpp:352] Iteration 92400 (1.64854 iter/s, 60.6596s/100 iter), 178.6/232ep, loss = 3.00875
I0511 06:57:57.516957  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.93811 (* 1 = 2.93811 loss)
I0511 06:57:57.516968  5307 sgd_solver.cpp:172] Iteration 92400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:58:58.128021  5307 solver.cpp:352] Iteration 92500 (1.64989 iter/s, 60.6103s/100 iter), 178.8/232ep, loss = 3.06919
I0511 06:58:58.128134  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.60397 (* 1 = 3.60397 loss)
I0511 06:58:58.128156  5307 sgd_solver.cpp:172] Iteration 92500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 06:59:37.560575  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 06:59:58.865466  5307 solver.cpp:352] Iteration 92600 (1.64646 iter/s, 60.7364s/100 iter), 179/232ep, loss = 2.9328
I0511 06:59:58.865562  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.717 (* 1 = 2.717 loss)
I0511 06:59:58.865584  5307 sgd_solver.cpp:172] Iteration 92600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:00:59.504809  5307 solver.cpp:352] Iteration 92700 (1.64912 iter/s, 60.6383s/100 iter), 179.2/232ep, loss = 3.177
I0511 07:00:59.504895  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.27882 (* 1 = 3.27882 loss)
I0511 07:00:59.504904  5307 sgd_solver.cpp:172] Iteration 92700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:01:59.805862  5307 solver.cpp:352] Iteration 92800 (1.65837 iter/s, 60.3s/100 iter), 179.4/232ep, loss = 3.05714
I0511 07:01:59.805963  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.5165 (* 1 = 2.5165 loss)
I0511 07:01:59.806018  5307 sgd_solver.cpp:172] Iteration 92800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:03:00.626083  5307 solver.cpp:352] Iteration 92900 (1.64422 iter/s, 60.8192s/100 iter), 179.6/232ep, loss = 2.963
I0511 07:03:00.626170  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.00387 (* 1 = 3.00387 loss)
I0511 07:03:00.626179  5307 sgd_solver.cpp:172] Iteration 92900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:04:01.318279  5307 solver.cpp:352] Iteration 93000 (1.64769 iter/s, 60.6912s/100 iter), 179.8/232ep, loss = 2.90055
I0511 07:04:01.320188  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.65029 (* 1 = 2.65029 loss)
I0511 07:04:01.320212  5307 sgd_solver.cpp:172] Iteration 93000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:04:50.817641  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 07:05:02.257743  5307 solver.cpp:352] Iteration 93100 (1.641 iter/s, 60.9384s/100 iter), 180/232ep, loss = 3.23961
I0511 07:05:02.257766  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.14786 (* 1 = 3.14786 loss)
I0511 07:05:02.257772  5307 sgd_solver.cpp:172] Iteration 93100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:06:03.299690  5307 solver.cpp:352] Iteration 93200 (1.63825 iter/s, 61.0409s/100 iter), 180.2/232ep, loss = 2.91292
I0511 07:06:03.299780  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.25663 (* 1 = 3.25663 loss)
I0511 07:06:03.299795  5307 sgd_solver.cpp:172] Iteration 93200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:07:04.007691  5307 solver.cpp:352] Iteration 93300 (1.64726 iter/s, 60.7069s/100 iter), 180.4/232ep, loss = 2.8366
I0511 07:07:04.007822  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.76125 (* 1 = 2.76125 loss)
I0511 07:07:04.007833  5307 sgd_solver.cpp:172] Iteration 93300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:08:05.674250  5307 solver.cpp:352] Iteration 93400 (1.62165 iter/s, 61.6655s/100 iter), 180.6/232ep, loss = 2.9875
I0511 07:08:05.674376  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.00216 (* 1 = 3.00216 loss)
I0511 07:08:05.674407  5307 sgd_solver.cpp:172] Iteration 93400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:09:06.510345  5307 solver.cpp:352] Iteration 93500 (1.64379 iter/s, 60.835s/100 iter), 180.8/232ep, loss = 2.91242
I0511 07:09:06.510448  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.26614 (* 1 = 3.26614 loss)
I0511 07:09:06.510457  5307 sgd_solver.cpp:172] Iteration 93500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:10:07.199136  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 07:10:07.692203  5307 solver.cpp:352] Iteration 93600 (1.6345 iter/s, 61.1808s/100 iter), 181/232ep, loss = 2.92701
I0511 07:10:07.692236  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.92543 (* 1 = 2.92543 loss)
I0511 07:10:07.692245  5307 sgd_solver.cpp:172] Iteration 93600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:11:08.276374  5307 solver.cpp:352] Iteration 93700 (1.65063 iter/s, 60.5831s/100 iter), 181.2/232ep, loss = 2.97391
I0511 07:11:08.276445  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.84651 (* 1 = 2.84651 loss)
I0511 07:11:08.276464  5307 sgd_solver.cpp:172] Iteration 93700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:12:09.098157  5307 solver.cpp:352] Iteration 93800 (1.64418 iter/s, 60.8207s/100 iter), 181.4/232ep, loss = 3.05575
I0511 07:12:09.098242  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.10997 (* 1 = 3.10997 loss)
I0511 07:12:09.098258  5307 sgd_solver.cpp:172] Iteration 93800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:13:09.135836  5307 solver.cpp:352] Iteration 93900 (1.66565 iter/s, 60.0366s/100 iter), 181.5/232ep, loss = 2.79365
I0511 07:13:09.135907  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.80829 (* 1 = 2.80829 loss)
I0511 07:13:09.135917  5307 sgd_solver.cpp:172] Iteration 93900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:14:09.049873  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_94000.caffemodel
I0511 07:14:09.067451  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_94000.solverstate
I0511 07:14:09.073073  5307 solver.cpp:635] Iteration 94000, Testing net (#0)
I0511 07:14:49.386508  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 07:14:49.603636  5307 solver.cpp:747] class AP 1: 0.653359
I0511 07:14:49.604197  5307 solver.cpp:747] class AP 2: 0.73238
I0511 07:14:49.610410  5307 solver.cpp:747] class AP 3: 0.551173
I0511 07:14:49.614192  5307 solver.cpp:747] class AP 4: 0.511015
I0511 07:14:49.632762  5307 solver.cpp:747] class AP 5: 0.343197
I0511 07:14:49.633168  5307 solver.cpp:747] class AP 6: 0.732664
I0511 07:14:49.642177  5307 solver.cpp:747] class AP 7: 0.703703
I0511 07:14:49.642736  5307 solver.cpp:747] class AP 8: 0.806241
I0511 07:14:49.660897  5307 solver.cpp:747] class AP 9: 0.430877
I0511 07:14:49.661641  5307 solver.cpp:747] class AP 10: 0.626487
I0511 07:14:49.662276  5307 solver.cpp:747] class AP 11: 0.582946
I0511 07:14:49.663098  5307 solver.cpp:747] class AP 12: 0.72
I0511 07:14:49.663549  5307 solver.cpp:747] class AP 13: 0.795215
I0511 07:14:49.663914  5307 solver.cpp:747] class AP 14: 0.756727
I0511 07:14:49.716935  5307 solver.cpp:747] class AP 15: 0.725841
I0511 07:14:49.723117  5307 solver.cpp:747] class AP 16: 0.352762
I0511 07:14:49.725605  5307 solver.cpp:747] class AP 17: 0.594063
I0511 07:14:49.726192  5307 solver.cpp:747] class AP 18: 0.607985
I0511 07:14:49.726879  5307 solver.cpp:747] class AP 19: 0.752284
I0511 07:14:49.728354  5307 solver.cpp:747] class AP 20: 0.612051
I0511 07:14:49.728365  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.629548
I0511 07:14:49.728660  5307 solver.cpp:283] Tests completed in 100.591s
I0511 07:14:50.404428  5307 solver.cpp:352] Iteration 94000 (0.994125 iter/s, 100.591s/100 iter), 181.7/232ep, loss = 3.00078
I0511 07:14:50.404458  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.03151 (* 1 = 3.03151 loss)
I0511 07:14:50.404465  5307 sgd_solver.cpp:172] Iteration 94000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:15:51.333745  5307 solver.cpp:352] Iteration 94100 (1.64128 iter/s, 60.9282s/100 iter), 181.9/232ep, loss = 3.00365
I0511 07:15:51.333849  5307 solver.cpp:376]     Train net output #0: mbox_loss = 1.65699 (* 1 = 1.65699 loss)
I0511 07:15:51.333858  5307 sgd_solver.cpp:172] Iteration 94100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:16:00.422384  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 07:16:52.949550  5307 solver.cpp:352] Iteration 94200 (1.62299 iter/s, 61.6147s/100 iter), 182.1/232ep, loss = 2.99714
I0511 07:16:52.949631  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.91074 (* 1 = 2.91074 loss)
I0511 07:16:52.949641  5307 sgd_solver.cpp:172] Iteration 94200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:17:53.041024  5307 solver.cpp:352] Iteration 94300 (1.66416 iter/s, 60.0903s/100 iter), 182.3/232ep, loss = 2.97779
I0511 07:17:53.041158  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.01335 (* 1 = 3.01335 loss)
I0511 07:17:53.041172  5307 sgd_solver.cpp:172] Iteration 94300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:18:53.639108  5307 solver.cpp:352] Iteration 94400 (1.65025 iter/s, 60.597s/100 iter), 182.5/232ep, loss = 2.9533
I0511 07:18:53.639197  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.15735 (* 1 = 3.15735 loss)
I0511 07:18:53.639212  5307 sgd_solver.cpp:172] Iteration 94400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:19:54.755478  5307 solver.cpp:352] Iteration 94500 (1.63625 iter/s, 61.1153s/100 iter), 182.7/232ep, loss = 3.05215
I0511 07:19:54.755560  5307 solver.cpp:376]     Train net output #0: mbox_loss = 1.78547 (* 1 = 1.78547 loss)
I0511 07:19:54.755575  5307 sgd_solver.cpp:172] Iteration 94500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:20:55.250944  5307 solver.cpp:352] Iteration 94600 (1.65305 iter/s, 60.4943s/100 iter), 182.9/232ep, loss = 2.91921
I0511 07:20:55.251121  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.6026 (* 1 = 2.6026 loss)
I0511 07:20:55.251130  5307 sgd_solver.cpp:172] Iteration 94600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:21:15.316819  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 07:21:55.952729  5307 solver.cpp:352] Iteration 94700 (1.64743 iter/s, 60.7007s/100 iter), 183.1/232ep, loss = 2.97533
I0511 07:21:55.958325  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.53738 (* 1 = 2.53738 loss)
I0511 07:21:55.958407  5307 sgd_solver.cpp:172] Iteration 94700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:22:56.539149  5307 solver.cpp:352] Iteration 94800 (1.65056 iter/s, 60.5853s/100 iter), 183.3/232ep, loss = 2.88534
I0511 07:22:56.551717  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.51739 (* 1 = 2.51739 loss)
I0511 07:22:56.551738  5307 sgd_solver.cpp:172] Iteration 94800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:23:57.239343  5307 solver.cpp:352] Iteration 94900 (1.64747 iter/s, 60.6991s/100 iter), 183.5/232ep, loss = 3.07979
I0511 07:23:57.239454  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.56482 (* 1 = 2.56482 loss)
I0511 07:23:57.239470  5307 sgd_solver.cpp:172] Iteration 94900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:24:57.647054  5307 solver.cpp:352] Iteration 95000 (1.65545 iter/s, 60.4066s/100 iter), 183.7/232ep, loss = 2.9111
I0511 07:24:57.647584  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.51917 (* 1 = 2.51917 loss)
I0511 07:24:57.647593  5307 sgd_solver.cpp:172] Iteration 95000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:25:58.006286  5307 solver.cpp:352] Iteration 95100 (1.65678 iter/s, 60.3581s/100 iter), 183.9/232ep, loss = 2.91394
I0511 07:25:58.006376  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.16777 (* 1 = 2.16777 loss)
I0511 07:25:58.006386  5307 sgd_solver.cpp:172] Iteration 95100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:26:29.239646  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 07:26:58.534366  5307 solver.cpp:352] Iteration 95200 (1.65216 iter/s, 60.527s/100 iter), 184.1/232ep, loss = 2.99329
I0511 07:26:58.534436  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.20944 (* 1 = 4.20944 loss)
I0511 07:26:58.534467  5307 sgd_solver.cpp:172] Iteration 95200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:28:00.180697  5307 solver.cpp:352] Iteration 95300 (1.62219 iter/s, 61.6452s/100 iter), 184.3/232ep, loss = 3.05895
I0511 07:28:00.180809  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.2327 (* 1 = 2.2327 loss)
I0511 07:28:00.180820  5307 sgd_solver.cpp:172] Iteration 95300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:29:01.828652  5307 solver.cpp:352] Iteration 95400 (1.62214 iter/s, 61.6468s/100 iter), 184.4/232ep, loss = 3.03341
I0511 07:29:01.828793  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.27634 (* 1 = 2.27634 loss)
I0511 07:29:01.828820  5307 sgd_solver.cpp:172] Iteration 95400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:30:02.710813  5307 solver.cpp:352] Iteration 95500 (1.64255 iter/s, 60.881s/100 iter), 184.6/232ep, loss = 2.95368
I0511 07:30:02.710907  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.47872 (* 1 = 2.47872 loss)
I0511 07:30:02.710917  5307 sgd_solver.cpp:172] Iteration 95500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:31:03.373091  5307 solver.cpp:352] Iteration 95600 (1.6485 iter/s, 60.6612s/100 iter), 184.8/232ep, loss = 3.00084
I0511 07:31:03.373272  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.63916 (* 1 = 2.63916 loss)
I0511 07:31:03.373291  5307 sgd_solver.cpp:172] Iteration 95600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:31:44.715602  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 07:32:04.248646  5307 solver.cpp:352] Iteration 95700 (1.64273 iter/s, 60.8744s/100 iter), 185/232ep, loss = 3.05273
I0511 07:32:04.248762  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.04961 (* 1 = 3.04961 loss)
I0511 07:32:04.248780  5307 sgd_solver.cpp:172] Iteration 95700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:33:04.989846  5307 solver.cpp:352] Iteration 95800 (1.64636 iter/s, 60.7401s/100 iter), 185.2/232ep, loss = 3.06251
I0511 07:33:04.989917  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.85397 (* 1 = 2.85397 loss)
I0511 07:33:04.989924  5307 sgd_solver.cpp:172] Iteration 95800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:34:04.922678  5307 solver.cpp:352] Iteration 95900 (1.66857 iter/s, 59.9317s/100 iter), 185.4/232ep, loss = 3.11436
I0511 07:34:04.922744  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.51926 (* 1 = 2.51926 loss)
I0511 07:34:04.922751  5307 sgd_solver.cpp:172] Iteration 95900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:35:04.914889  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_96000.caffemodel
I0511 07:35:04.936225  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_96000.solverstate
I0511 07:35:04.941499  5307 solver.cpp:635] Iteration 96000, Testing net (#0)
I0511 07:35:23.672327  5352 blocking_queue.cpp:40] Data layer prefetch queue empty
I0511 07:35:45.077711  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 07:35:45.308502  5307 solver.cpp:747] class AP 1: 0.650321
I0511 07:35:45.309023  5307 solver.cpp:747] class AP 2: 0.734017
I0511 07:35:45.315362  5307 solver.cpp:747] class AP 3: 0.555505
I0511 07:35:45.319352  5307 solver.cpp:747] class AP 4: 0.501021
I0511 07:35:45.337565  5307 solver.cpp:747] class AP 5: 0.344569
I0511 07:35:45.337915  5307 solver.cpp:747] class AP 6: 0.733044
I0511 07:35:45.346527  5307 solver.cpp:747] class AP 7: 0.704343
I0511 07:35:45.347060  5307 solver.cpp:747] class AP 8: 0.813259
I0511 07:35:45.364531  5307 solver.cpp:747] class AP 9: 0.425829
I0511 07:35:45.365254  5307 solver.cpp:747] class AP 10: 0.624562
I0511 07:35:45.365865  5307 solver.cpp:747] class AP 11: 0.58426
I0511 07:35:45.366700  5307 solver.cpp:747] class AP 12: 0.722605
I0511 07:35:45.367126  5307 solver.cpp:747] class AP 13: 0.789451
I0511 07:35:45.367465  5307 solver.cpp:747] class AP 14: 0.745061
I0511 07:35:45.415539  5307 solver.cpp:747] class AP 15: 0.725725
I0511 07:35:45.421653  5307 solver.cpp:747] class AP 16: 0.354737
I0511 07:35:45.424113  5307 solver.cpp:747] class AP 17: 0.597748
I0511 07:35:45.424669  5307 solver.cpp:747] class AP 18: 0.618047
I0511 07:35:45.425331  5307 solver.cpp:747] class AP 19: 0.744493
I0511 07:35:45.426846  5307 solver.cpp:747] class AP 20: 0.608665
I0511 07:35:45.426854  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.628863
I0511 07:35:45.427047  5307 solver.cpp:283] Tests completed in 100.503s
I0511 07:35:45.994454  5307 solver.cpp:352] Iteration 96000 (0.995 iter/s, 100.503s/100 iter), 185.6/232ep, loss = 2.9123
I0511 07:35:45.994532  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.39141 (* 1 = 3.39141 loss)
I0511 07:35:45.994559  5307 sgd_solver.cpp:172] Iteration 96000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:36:46.702077  5307 solver.cpp:352] Iteration 96100 (1.64727 iter/s, 60.7065s/100 iter), 185.8/232ep, loss = 3.05719
I0511 07:36:46.702152  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.16969 (* 1 = 3.16969 loss)
I0511 07:36:46.702162  5307 sgd_solver.cpp:172] Iteration 96100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:37:38.127743  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 07:37:47.506345  5307 solver.cpp:352] Iteration 96200 (1.64465 iter/s, 60.8031s/100 iter), 186/232ep, loss = 2.96958
I0511 07:37:47.506371  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.18929 (* 1 = 3.18929 loss)
I0511 07:37:47.506381  5307 sgd_solver.cpp:172] Iteration 96200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:38:47.357182  5307 solver.cpp:352] Iteration 96300 (1.67085 iter/s, 59.8498s/100 iter), 186.2/232ep, loss = 3.00744
I0511 07:38:47.357235  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.54607 (* 1 = 2.54607 loss)
I0511 07:38:47.357244  5307 sgd_solver.cpp:172] Iteration 96300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:39:46.934804  5307 solver.cpp:352] Iteration 96400 (1.67851 iter/s, 59.5765s/100 iter), 186.4/232ep, loss = 2.90113
I0511 07:39:46.934885  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.7434 (* 1 = 2.7434 loss)
I0511 07:39:46.934895  5307 sgd_solver.cpp:172] Iteration 96400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:40:46.563388  5307 solver.cpp:352] Iteration 96500 (1.67708 iter/s, 59.6275s/100 iter), 186.6/232ep, loss = 3.30584
I0511 07:40:46.563503  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.42639 (* 1 = 3.42639 loss)
I0511 07:40:46.563514  5307 sgd_solver.cpp:172] Iteration 96500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:41:46.848609  5307 solver.cpp:352] Iteration 96600 (1.65881 iter/s, 60.2841s/100 iter), 186.8/232ep, loss = 2.93792
I0511 07:41:46.848676  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.63076 (* 1 = 2.63076 loss)
I0511 07:41:46.848685  5307 sgd_solver.cpp:172] Iteration 96600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:42:47.210800  5307 solver.cpp:352] Iteration 96700 (1.6567 iter/s, 60.3611s/100 iter), 187/232ep, loss = 3.05603
I0511 07:42:47.212236  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.73215 (* 1 = 3.73215 loss)
I0511 07:42:47.212250  5307 sgd_solver.cpp:172] Iteration 96700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:42:47.932543  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 07:43:47.787328  5307 solver.cpp:352] Iteration 96800 (1.65083 iter/s, 60.5754s/100 iter), 187.2/232ep, loss = 3.03419
I0511 07:43:47.787413  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.96915 (* 1 = 2.96915 loss)
I0511 07:43:47.787425  5307 sgd_solver.cpp:172] Iteration 96800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:44:49.099545  5307 solver.cpp:352] Iteration 96900 (1.63103 iter/s, 61.3111s/100 iter), 187.3/232ep, loss = 3.09535
I0511 07:44:49.099644  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.93823 (* 1 = 3.93823 loss)
I0511 07:44:49.099663  5307 sgd_solver.cpp:172] Iteration 96900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:45:52.576695  5307 solver.cpp:352] Iteration 97000 (1.5754 iter/s, 63.476s/100 iter), 187.5/232ep, loss = 2.80578
I0511 07:45:52.578472  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.33847 (* 1 = 2.33847 loss)
I0511 07:45:52.578514  5307 sgd_solver.cpp:172] Iteration 97000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:47:00.539968  5307 solver.cpp:352] Iteration 97100 (1.47141 iter/s, 67.962s/100 iter), 187.7/232ep, loss = 2.9538
I0511 07:47:00.540072  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.27623 (* 1 = 3.27623 loss)
I0511 07:47:00.540093  5307 sgd_solver.cpp:172] Iteration 97100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:48:01.684559  5307 solver.cpp:352] Iteration 97200 (1.6355 iter/s, 61.1434s/100 iter), 187.9/232ep, loss = 2.9581
I0511 07:48:01.684702  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.46043 (* 1 = 3.46043 loss)
I0511 07:48:01.684712  5307 sgd_solver.cpp:172] Iteration 97200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:48:13.198102  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 07:49:01.896059  5307 solver.cpp:352] Iteration 97300 (1.66084 iter/s, 60.2104s/100 iter), 188.1/232ep, loss = 3.00296
I0511 07:49:01.899176  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.27139 (* 1 = 2.27139 loss)
I0511 07:49:01.899194  5307 sgd_solver.cpp:172] Iteration 97300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:50:02.053539  5307 solver.cpp:352] Iteration 97400 (1.66234 iter/s, 60.1563s/100 iter), 188.3/232ep, loss = 2.91776
I0511 07:50:02.054003  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.90872 (* 1 = 2.90872 loss)
I0511 07:50:02.054015  5307 sgd_solver.cpp:172] Iteration 97400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:51:02.951967  5307 solver.cpp:352] Iteration 97500 (1.64211 iter/s, 60.8973s/100 iter), 188.5/232ep, loss = 2.875
I0511 07:51:02.952033  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.22074 (* 1 = 3.22074 loss)
I0511 07:51:02.952041  5307 sgd_solver.cpp:172] Iteration 97500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:52:04.163118  5307 solver.cpp:352] Iteration 97600 (1.63372 iter/s, 61.21s/100 iter), 188.7/232ep, loss = 2.90709
I0511 07:52:04.163497  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.6202 (* 1 = 3.6202 loss)
I0511 07:52:04.163509  5307 sgd_solver.cpp:172] Iteration 97600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:53:05.139300  5307 solver.cpp:352] Iteration 97700 (1.64001 iter/s, 60.9751s/100 iter), 188.9/232ep, loss = 3.0651
I0511 07:53:05.139398  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.82895 (* 1 = 3.82895 loss)
I0511 07:53:05.139415  5307 sgd_solver.cpp:172] Iteration 97700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:53:27.015391  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 07:54:05.430426  5307 solver.cpp:352] Iteration 97800 (1.65865 iter/s, 60.29s/100 iter), 189.1/232ep, loss = 2.91936
I0511 07:54:05.430500  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.72138 (* 1 = 3.72138 loss)
I0511 07:54:05.430510  5307 sgd_solver.cpp:172] Iteration 97800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:55:06.594501  5307 solver.cpp:352] Iteration 97900 (1.63498 iter/s, 61.163s/100 iter), 189.3/232ep, loss = 3.04614
I0511 07:55:06.594552  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.68441 (* 1 = 2.68441 loss)
I0511 07:55:06.594559  5307 sgd_solver.cpp:172] Iteration 97900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:56:06.258683  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_98000.caffemodel
I0511 07:56:06.280103  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_98000.solverstate
I0511 07:56:06.286790  5307 solver.cpp:635] Iteration 98000, Testing net (#0)
I0511 07:56:46.613548  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 07:56:46.815506  5307 solver.cpp:747] class AP 1: 0.654648
I0511 07:56:46.816174  5307 solver.cpp:747] class AP 2: 0.729718
I0511 07:56:46.824645  5307 solver.cpp:747] class AP 3: 0.556767
I0511 07:56:46.830163  5307 solver.cpp:747] class AP 4: 0.509277
I0511 07:56:46.853922  5307 solver.cpp:747] class AP 5: 0.343129
I0511 07:56:46.854557  5307 solver.cpp:747] class AP 6: 0.733831
I0511 07:56:46.863710  5307 solver.cpp:747] class AP 7: 0.699716
I0511 07:56:46.864267  5307 solver.cpp:747] class AP 8: 0.818443
I0511 07:56:46.883057  5307 solver.cpp:747] class AP 9: 0.426093
I0511 07:56:46.883762  5307 solver.cpp:747] class AP 10: 0.628663
I0511 07:56:46.884393  5307 solver.cpp:747] class AP 11: 0.58388
I0511 07:56:46.885224  5307 solver.cpp:747] class AP 12: 0.71764
I0511 07:56:46.885659  5307 solver.cpp:747] class AP 13: 0.794358
I0511 07:56:46.885994  5307 solver.cpp:747] class AP 14: 0.74868
I0511 07:56:46.938817  5307 solver.cpp:747] class AP 15: 0.724842
I0511 07:56:46.946049  5307 solver.cpp:747] class AP 16: 0.359878
I0511 07:56:46.948588  5307 solver.cpp:747] class AP 17: 0.593851
I0511 07:56:46.949234  5307 solver.cpp:747] class AP 18: 0.609637
I0511 07:56:46.950158  5307 solver.cpp:747] class AP 19: 0.747296
I0511 07:56:46.951679  5307 solver.cpp:747] class AP 20: 0.611734
I0511 07:56:46.951694  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.629604
I0511 07:56:46.951939  5307 solver.cpp:283] Tests completed in 100.356s
I0511 07:56:47.491531  5307 solver.cpp:352] Iteration 98000 (0.996456 iter/s, 100.356s/100 iter), 189.5/232ep, loss = 3.20631
I0511 07:56:47.491556  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.01891 (* 1 = 3.01891 loss)
I0511 07:56:47.491564  5307 sgd_solver.cpp:172] Iteration 98000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:57:47.971768  5307 solver.cpp:352] Iteration 98100 (1.65346 iter/s, 60.4791s/100 iter), 189.7/232ep, loss = 3.06749
I0511 07:57:47.972045  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.03684 (* 1 = 3.03684 loss)
I0511 07:57:47.972064  5307 sgd_solver.cpp:172] Iteration 98100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:58:50.075870  5307 solver.cpp:352] Iteration 98200 (1.61023 iter/s, 62.103s/100 iter), 189.9/232ep, loss = 2.9852
I0511 07:58:50.076016  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.37209 (* 1 = 3.37209 loss)
I0511 07:58:50.076025  5307 sgd_solver.cpp:172] Iteration 98200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 07:59:22.351446  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 07:59:50.813318  5307 solver.cpp:352] Iteration 98300 (1.64646 iter/s, 60.7363s/100 iter), 190.1/232ep, loss = 2.70888
I0511 07:59:50.813359  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.57383 (* 1 = 2.57383 loss)
I0511 07:59:50.813371  5307 sgd_solver.cpp:172] Iteration 98300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:00:51.706754  5307 solver.cpp:352] Iteration 98400 (1.64224 iter/s, 60.8923s/100 iter), 190.2/232ep, loss = 3.08315
I0511 08:00:51.706881  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.79268 (* 1 = 2.79268 loss)
I0511 08:00:51.706892  5307 sgd_solver.cpp:172] Iteration 98400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:01:52.966831  5307 solver.cpp:352] Iteration 98500 (1.63241 iter/s, 61.259s/100 iter), 190.4/232ep, loss = 3.01733
I0511 08:01:52.966913  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.21688 (* 1 = 3.21688 loss)
I0511 08:01:52.966922  5307 sgd_solver.cpp:172] Iteration 98500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:02:53.233733  5307 solver.cpp:352] Iteration 98600 (1.65932 iter/s, 60.2658s/100 iter), 190.6/232ep, loss = 3.05306
I0511 08:02:53.233789  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.07683 (* 1 = 3.07683 loss)
I0511 08:02:53.233798  5307 sgd_solver.cpp:172] Iteration 98600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:03:54.616510  5307 solver.cpp:352] Iteration 98700 (1.62915 iter/s, 61.3816s/100 iter), 190.8/232ep, loss = 3.10036
I0511 08:03:54.616595  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.22673 (* 1 = 3.22673 loss)
I0511 08:03:54.616603  5307 sgd_solver.cpp:172] Iteration 98700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:04:38.339814  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 08:04:55.744252  5307 solver.cpp:352] Iteration 98800 (1.63595 iter/s, 61.1266s/100 iter), 191/232ep, loss = 2.97291
I0511 08:04:55.744356  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.05587 (* 1 = 3.05587 loss)
I0511 08:04:55.744379  5307 sgd_solver.cpp:172] Iteration 98800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:05:56.503899  5307 solver.cpp:352] Iteration 98900 (1.64586 iter/s, 60.7585s/100 iter), 191.2/232ep, loss = 2.95962
I0511 08:05:56.503983  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.0435 (* 1 = 3.0435 loss)
I0511 08:05:56.503996  5307 sgd_solver.cpp:172] Iteration 98900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:06:58.032640  5307 solver.cpp:352] Iteration 99000 (1.62529 iter/s, 61.5276s/100 iter), 191.4/232ep, loss = 3.08671
I0511 08:06:58.032723  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.94509 (* 1 = 2.94509 loss)
I0511 08:06:58.032732  5307 sgd_solver.cpp:172] Iteration 99000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:07:59.002532  5307 solver.cpp:352] Iteration 99100 (1.64018 iter/s, 60.9688s/100 iter), 191.6/232ep, loss = 3.02594
I0511 08:07:59.002626  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.53134 (* 1 = 3.53134 loss)
I0511 08:07:59.002635  5307 sgd_solver.cpp:172] Iteration 99100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:09:00.493904  5307 solver.cpp:352] Iteration 99200 (1.62627 iter/s, 61.4902s/100 iter), 191.8/232ep, loss = 3.0374
I0511 08:09:00.494019  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.23447 (* 1 = 4.23447 loss)
I0511 08:09:00.494030  5307 sgd_solver.cpp:172] Iteration 99200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:09:53.119544  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 08:10:01.056978  5307 solver.cpp:352] Iteration 99300 (1.6512 iter/s, 60.5619s/100 iter), 192/232ep, loss = 3.03007
I0511 08:10:01.057054  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.11184 (* 1 = 3.11184 loss)
I0511 08:10:01.057076  5307 sgd_solver.cpp:172] Iteration 99300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:11:02.474581  5307 solver.cpp:352] Iteration 99400 (1.62823 iter/s, 61.4164s/100 iter), 192.2/232ep, loss = 3.02644
I0511 08:11:02.474658  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.58186 (* 1 = 3.58186 loss)
I0511 08:11:02.474666  5307 sgd_solver.cpp:172] Iteration 99400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:12:03.639566  5307 solver.cpp:352] Iteration 99500 (1.63495 iter/s, 61.1639s/100 iter), 192.4/232ep, loss = 3.0477
I0511 08:12:03.639678  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.54568 (* 1 = 3.54568 loss)
I0511 08:12:03.639699  5307 sgd_solver.cpp:172] Iteration 99500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:13:04.248728  5307 solver.cpp:352] Iteration 99600 (1.64995 iter/s, 60.608s/100 iter), 192.6/232ep, loss = 3.26572
I0511 08:13:04.248836  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.48364 (* 1 = 3.48364 loss)
I0511 08:13:04.248863  5307 sgd_solver.cpp:172] Iteration 99600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:14:04.842027  5307 solver.cpp:352] Iteration 99700 (1.65038 iter/s, 60.5922s/100 iter), 192.8/232ep, loss = 2.9188
I0511 08:14:04.842499  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.09875 (* 1 = 3.09875 loss)
I0511 08:14:04.842510  5307 sgd_solver.cpp:172] Iteration 99700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:15:05.169956  5307 solver.cpp:352] Iteration 99800 (1.65764 iter/s, 60.3268s/100 iter), 193/232ep, loss = 2.89835
I0511 08:15:05.170317  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.32569 (* 1 = 4.32569 loss)
I0511 08:15:05.170327  5307 sgd_solver.cpp:172] Iteration 99800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:15:08.292088  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 08:16:06.441372  5307 solver.cpp:352] Iteration 99900 (1.63211 iter/s, 61.2703s/100 iter), 193.1/232ep, loss = 3.01729
I0511 08:16:06.441478  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.73704 (* 1 = 3.73704 loss)
I0511 08:16:06.441498  5307 sgd_solver.cpp:172] Iteration 99900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:17:08.110452  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_100000.caffemodel
I0511 08:17:08.130551  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_100000.solverstate
I0511 08:17:08.136447  5307 solver.cpp:635] Iteration 100000, Testing net (#0)
I0511 08:17:48.875803  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 08:17:49.103816  5307 solver.cpp:747] class AP 1: 0.665005
I0511 08:17:49.104339  5307 solver.cpp:747] class AP 2: 0.730937
I0511 08:17:49.110823  5307 solver.cpp:747] class AP 3: 0.558327
I0511 08:17:49.114506  5307 solver.cpp:747] class AP 4: 0.507206
I0511 08:17:49.132952  5307 solver.cpp:747] class AP 5: 0.34404
I0511 08:17:49.133280  5307 solver.cpp:747] class AP 6: 0.735807
I0511 08:17:49.141923  5307 solver.cpp:747] class AP 7: 0.701335
I0511 08:17:49.142475  5307 solver.cpp:747] class AP 8: 0.815496
I0511 08:17:49.160322  5307 solver.cpp:747] class AP 9: 0.425556
I0511 08:17:49.161043  5307 solver.cpp:747] class AP 10: 0.626299
I0511 08:17:49.161677  5307 solver.cpp:747] class AP 11: 0.592111
I0511 08:17:49.162549  5307 solver.cpp:747] class AP 12: 0.718074
I0511 08:17:49.162979  5307 solver.cpp:747] class AP 13: 0.792086
I0511 08:17:49.163327  5307 solver.cpp:747] class AP 14: 0.756043
I0511 08:17:49.222995  5307 solver.cpp:747] class AP 15: 0.725033
I0511 08:17:49.231612  5307 solver.cpp:747] class AP 16: 0.357034
I0511 08:17:49.234997  5307 solver.cpp:747] class AP 17: 0.597503
I0511 08:17:49.235782  5307 solver.cpp:747] class AP 18: 0.606173
I0511 08:17:49.236677  5307 solver.cpp:747] class AP 19: 0.749204
I0511 08:17:49.238603  5307 solver.cpp:747] class AP 20: 0.617463
I0511 08:17:49.238801  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.631037
I0511 08:17:49.238991  5307 solver.cpp:283] Tests completed in 102.796s
I0511 08:17:49.832324  5307 solver.cpp:352] Iteration 100000 (0.972803 iter/s, 102.796s/100 iter), 193.3/232ep, loss = 3.0267
I0511 08:17:49.832352  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.33654 (* 1 = 2.33654 loss)
I0511 08:17:49.832360  5307 sgd_solver.cpp:172] Iteration 100000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:18:51.388283  5307 solver.cpp:352] Iteration 100100 (1.62457 iter/s, 61.5548s/100 iter), 193.5/232ep, loss = 2.84996
I0511 08:18:51.388463  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.45932 (* 1 = 2.45932 loss)
I0511 08:18:51.388489  5307 sgd_solver.cpp:172] Iteration 100100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:19:53.190773  5307 solver.cpp:352] Iteration 100200 (1.61809 iter/s, 61.8014s/100 iter), 193.7/232ep, loss = 3.15988
I0511 08:19:53.190889  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.08743 (* 1 = 3.08743 loss)
I0511 08:19:53.190897  5307 sgd_solver.cpp:172] Iteration 100200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:20:54.608816  5307 solver.cpp:352] Iteration 100300 (1.62822 iter/s, 61.4169s/100 iter), 193.9/232ep, loss = 2.97717
I0511 08:20:54.608924  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.59103 (* 1 = 3.59103 loss)
I0511 08:20:54.608954  5307 sgd_solver.cpp:172] Iteration 100300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:21:08.816452  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 08:21:55.471817  5307 solver.cpp:352] Iteration 100400 (1.64306 iter/s, 60.8619s/100 iter), 194.1/232ep, loss = 2.97832
I0511 08:21:55.471938  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.36064 (* 1 = 2.36064 loss)
I0511 08:21:55.471957  5307 sgd_solver.cpp:172] Iteration 100400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:22:56.358227  5307 solver.cpp:352] Iteration 100500 (1.64243 iter/s, 60.8853s/100 iter), 194.3/232ep, loss = 2.98626
I0511 08:22:56.358577  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.43856 (* 1 = 2.43856 loss)
I0511 08:22:56.358593  5307 sgd_solver.cpp:172] Iteration 100500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:23:57.579596  5307 solver.cpp:352] Iteration 100600 (1.63345 iter/s, 61.2203s/100 iter), 194.5/232ep, loss = 3.05359
I0511 08:23:57.582028  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.41592 (* 1 = 2.41592 loss)
I0511 08:23:57.582038  5307 sgd_solver.cpp:172] Iteration 100600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:24:58.344626  5307 solver.cpp:352] Iteration 100700 (1.64571 iter/s, 60.7639s/100 iter), 194.7/232ep, loss = 2.91428
I0511 08:24:58.344753  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.1572 (* 1 = 3.1572 loss)
I0511 08:24:58.344775  5307 sgd_solver.cpp:172] Iteration 100700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:25:59.356418  5307 solver.cpp:352] Iteration 100800 (1.63906 iter/s, 61.0107s/100 iter), 194.9/232ep, loss = 3.0662
I0511 08:25:59.356564  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.50593 (* 1 = 3.50593 loss)
I0511 08:25:59.356577  5307 sgd_solver.cpp:172] Iteration 100800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:26:23.589988  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 08:27:00.902576  5307 solver.cpp:352] Iteration 100900 (1.62483 iter/s, 61.5451s/100 iter), 195.1/232ep, loss = 2.96019
I0511 08:27:00.902674  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.54178 (* 1 = 2.54178 loss)
I0511 08:27:00.902681  5307 sgd_solver.cpp:172] Iteration 100900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:28:02.828667  5307 solver.cpp:352] Iteration 101000 (1.61486 iter/s, 61.9249s/100 iter), 195.3/232ep, loss = 2.93848
I0511 08:28:02.828826  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.41082 (* 1 = 2.41082 loss)
I0511 08:28:02.828871  5307 sgd_solver.cpp:172] Iteration 101000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:29:04.057327  5307 solver.cpp:352] Iteration 101100 (1.63325 iter/s, 61.2275s/100 iter), 195.5/232ep, loss = 3.148
I0511 08:29:04.057379  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.57206 (* 1 = 3.57206 loss)
I0511 08:29:04.057386  5307 sgd_solver.cpp:172] Iteration 101100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:30:05.313616  5307 solver.cpp:352] Iteration 101200 (1.63252 iter/s, 61.2551s/100 iter), 195.7/232ep, loss = 3.03246
I0511 08:30:05.313746  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.61708 (* 1 = 3.61708 loss)
I0511 08:30:05.313758  5307 sgd_solver.cpp:172] Iteration 101200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:31:07.408694  5307 solver.cpp:352] Iteration 101300 (1.61046 iter/s, 62.0939s/100 iter), 195.9/232ep, loss = 3.11302
I0511 08:31:07.408802  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.83745 (* 1 = 2.83745 loss)
I0511 08:31:07.408816  5307 sgd_solver.cpp:172] Iteration 101300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:31:42.815610  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 08:32:09.252004  5307 solver.cpp:352] Iteration 101400 (1.61702 iter/s, 61.8422s/100 iter), 196/232ep, loss = 2.79151
I0511 08:32:09.252032  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.39979 (* 1 = 2.39979 loss)
I0511 08:32:09.252040  5307 sgd_solver.cpp:172] Iteration 101400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:33:10.985529  5307 solver.cpp:352] Iteration 101500 (1.6199 iter/s, 61.7324s/100 iter), 196.2/232ep, loss = 2.91793
I0511 08:33:10.985631  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.04143 (* 1 = 3.04143 loss)
I0511 08:33:10.985642  5307 sgd_solver.cpp:172] Iteration 101500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:34:12.504964  5307 solver.cpp:352] Iteration 101600 (1.62553 iter/s, 61.5183s/100 iter), 196.4/232ep, loss = 2.99502
I0511 08:34:12.505041  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.19517 (* 1 = 2.19517 loss)
I0511 08:34:12.505050  5307 sgd_solver.cpp:172] Iteration 101600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:35:13.790604  5307 solver.cpp:352] Iteration 101700 (1.63173 iter/s, 61.2845s/100 iter), 196.6/232ep, loss = 3.06827
I0511 08:35:13.790659  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.38886 (* 1 = 3.38886 loss)
I0511 08:35:13.790666  5307 sgd_solver.cpp:172] Iteration 101700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:36:15.784857  5307 solver.cpp:352] Iteration 101800 (1.61308 iter/s, 61.9931s/100 iter), 196.8/232ep, loss = 3.18449
I0511 08:36:15.784955  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.28257 (* 1 = 3.28257 loss)
I0511 08:36:15.784977  5307 sgd_solver.cpp:172] Iteration 101800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:37:01.141197  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 08:37:16.739065  5307 solver.cpp:352] Iteration 101900 (1.64061 iter/s, 60.9531s/100 iter), 197/232ep, loss = 3.02052
I0511 08:37:16.739158  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.42314 (* 1 = 3.42314 loss)
I0511 08:37:16.739177  5307 sgd_solver.cpp:172] Iteration 101900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:38:16.737043  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_102000.caffemodel
I0511 08:38:16.749049  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_102000.solverstate
I0511 08:38:16.753746  5307 solver.cpp:635] Iteration 102000, Testing net (#0)
I0511 08:38:57.167840  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 08:38:57.375763  5307 solver.cpp:747] class AP 1: 0.662877
I0511 08:38:57.376477  5307 solver.cpp:747] class AP 2: 0.729423
I0511 08:38:57.385727  5307 solver.cpp:747] class AP 3: 0.558048
I0511 08:38:57.391151  5307 solver.cpp:747] class AP 4: 0.501808
I0511 08:38:57.416709  5307 solver.cpp:747] class AP 5: 0.339622
I0511 08:38:57.417057  5307 solver.cpp:747] class AP 6: 0.734243
I0511 08:38:57.425725  5307 solver.cpp:747] class AP 7: 0.703979
I0511 08:38:57.426270  5307 solver.cpp:747] class AP 8: 0.820063
I0511 08:38:57.444169  5307 solver.cpp:747] class AP 9: 0.430973
I0511 08:38:57.444890  5307 solver.cpp:747] class AP 10: 0.627212
I0511 08:38:57.445516  5307 solver.cpp:747] class AP 11: 0.598763
I0511 08:38:57.446367  5307 solver.cpp:747] class AP 12: 0.727264
I0511 08:38:57.446800  5307 solver.cpp:747] class AP 13: 0.795383
I0511 08:38:57.447157  5307 solver.cpp:747] class AP 14: 0.742447
I0511 08:38:57.496114  5307 solver.cpp:747] class AP 15: 0.724216
I0511 08:38:57.502737  5307 solver.cpp:747] class AP 16: 0.360335
I0511 08:38:57.505149  5307 solver.cpp:747] class AP 17: 0.59934
I0511 08:38:57.505834  5307 solver.cpp:747] class AP 18: 0.609809
I0511 08:38:57.506490  5307 solver.cpp:747] class AP 19: 0.750395
I0511 08:38:57.507906  5307 solver.cpp:747] class AP 20: 0.613732
I0511 08:38:57.507915  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.631497
I0511 08:38:57.508059  5307 solver.cpp:283] Tests completed in 100.767s
I0511 08:38:58.034000  5307 solver.cpp:352] Iteration 102000 (0.992386 iter/s, 100.767s/100 iter), 197.2/232ep, loss = 2.96189
I0511 08:38:58.034025  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.47859 (* 1 = 3.47859 loss)
I0511 08:38:58.034032  5307 sgd_solver.cpp:172] Iteration 102000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:39:59.308593  5307 solver.cpp:352] Iteration 102100 (1.63203 iter/s, 61.2734s/100 iter), 197.4/232ep, loss = 3.01728
I0511 08:39:59.308722  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.22398 (* 1 = 3.22398 loss)
I0511 08:39:59.308735  5307 sgd_solver.cpp:172] Iteration 102100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:40:59.338691  5307 solver.cpp:352] Iteration 102200 (1.66586 iter/s, 60.0291s/100 iter), 197.6/232ep, loss = 2.97617
I0511 08:40:59.338783  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.49093 (* 1 = 2.49093 loss)
I0511 08:40:59.338793  5307 sgd_solver.cpp:172] Iteration 102200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:42:01.744545  5307 solver.cpp:352] Iteration 102300 (1.60244 iter/s, 62.4047s/100 iter), 197.8/232ep, loss = 3.03357
I0511 08:42:01.744637  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.25867 (* 1 = 3.25867 loss)
I0511 08:42:01.744647  5307 sgd_solver.cpp:172] Iteration 102300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:42:57.391222  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 08:43:02.803563  5307 solver.cpp:352] Iteration 102400 (1.63779 iter/s, 61.058s/100 iter), 198/232ep, loss = 3.22251
I0511 08:43:02.803596  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.6136 (* 1 = 2.6136 loss)
I0511 08:43:02.803603  5307 sgd_solver.cpp:172] Iteration 102400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:44:04.976128  5307 solver.cpp:352] Iteration 102500 (1.60845 iter/s, 62.1715s/100 iter), 198.2/232ep, loss = 3.14362
I0511 08:44:04.976188  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.12992 (* 1 = 3.12992 loss)
I0511 08:44:04.976194  5307 sgd_solver.cpp:172] Iteration 102500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:45:06.639672  5307 solver.cpp:352] Iteration 102600 (1.62173 iter/s, 61.6625s/100 iter), 198.4/232ep, loss = 3.05518
I0511 08:45:06.640053  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.95388 (* 1 = 2.95388 loss)
I0511 08:45:06.640072  5307 sgd_solver.cpp:172] Iteration 102600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:46:07.664664  5307 solver.cpp:352] Iteration 102700 (1.6387 iter/s, 61.0239s/100 iter), 198.6/232ep, loss = 2.99007
I0511 08:46:07.667974  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.39835 (* 1 = 3.39835 loss)
I0511 08:46:07.668041  5307 sgd_solver.cpp:172] Iteration 102700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:47:09.222339  5307 solver.cpp:352] Iteration 102800 (1.62452 iter/s, 61.5566s/100 iter), 198.8/232ep, loss = 2.92772
I0511 08:47:09.222436  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.22916 (* 1 = 2.22916 loss)
I0511 08:47:09.222455  5307 sgd_solver.cpp:172] Iteration 102800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:48:10.972451  5307 solver.cpp:352] Iteration 102900 (1.61946 iter/s, 61.749s/100 iter), 198.9/232ep, loss = 2.97089
I0511 08:48:10.972628  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.5179 (* 1 = 3.5179 loss)
I0511 08:48:10.972647  5307 sgd_solver.cpp:172] Iteration 102900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:48:16.512580  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 08:49:12.852767  5307 solver.cpp:352] Iteration 103000 (1.61605 iter/s, 61.8792s/100 iter), 199.1/232ep, loss = 2.86671
I0511 08:49:12.853016  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.73384 (* 1 = 3.73384 loss)
I0511 08:49:12.853035  5307 sgd_solver.cpp:172] Iteration 103000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:50:14.537976  5307 solver.cpp:352] Iteration 103100 (1.62116 iter/s, 61.6841s/100 iter), 199.3/232ep, loss = 3.3114
I0511 08:50:14.538293  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.01035 (* 1 = 3.01035 loss)
I0511 08:50:14.538347  5307 sgd_solver.cpp:172] Iteration 103100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:51:16.029994  5307 solver.cpp:352] Iteration 103200 (1.62626 iter/s, 61.4909s/100 iter), 199.5/232ep, loss = 3.06903
I0511 08:51:16.036649  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.0684 (* 1 = 4.0684 loss)
I0511 08:51:16.036679  5307 sgd_solver.cpp:172] Iteration 103200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:52:17.581897  5307 solver.cpp:352] Iteration 103300 (1.62468 iter/s, 61.5508s/100 iter), 199.7/232ep, loss = 3.08515
I0511 08:52:17.582022  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.87733 (* 1 = 2.87733 loss)
I0511 08:52:17.582093  5307 sgd_solver.cpp:172] Iteration 103300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:53:25.213412  5307 solver.cpp:352] Iteration 103400 (1.47863 iter/s, 67.6302s/100 iter), 199.9/232ep, loss = 2.89853
I0511 08:53:25.213524  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.3616 (* 1 = 3.3616 loss)
I0511 08:53:25.213547  5307 sgd_solver.cpp:172] Iteration 103400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:53:42.453626  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 08:54:30.902637  5307 solver.cpp:352] Iteration 103500 (1.52235 iter/s, 65.688s/100 iter), 200.1/232ep, loss = 2.97316
I0511 08:54:30.902704  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.48358 (* 1 = 2.48358 loss)
I0511 08:54:30.902714  5307 sgd_solver.cpp:172] Iteration 103500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:55:32.001219  5307 solver.cpp:352] Iteration 103600 (1.63673 iter/s, 61.0974s/100 iter), 200.3/232ep, loss = 3.12863
I0511 08:55:32.001878  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.65934 (* 1 = 2.65934 loss)
I0511 08:55:32.001896  5307 sgd_solver.cpp:172] Iteration 103600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:56:32.925688  5307 solver.cpp:352] Iteration 103700 (1.64141 iter/s, 60.9234s/100 iter), 200.5/232ep, loss = 3.02484
I0511 08:56:32.930019  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.6127 (* 1 = 2.6127 loss)
I0511 08:56:32.930043  5307 sgd_solver.cpp:172] Iteration 103700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:57:34.563419  5307 solver.cpp:352] Iteration 103800 (1.62241 iter/s, 61.6366s/100 iter), 200.7/232ep, loss = 3.00477
I0511 08:57:34.564416  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.82427 (* 1 = 3.82427 loss)
I0511 08:57:34.564426  5307 sgd_solver.cpp:172] Iteration 103800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:58:35.047950  5307 solver.cpp:352] Iteration 103900 (1.65335 iter/s, 60.4834s/100 iter), 200.9/232ep, loss = 2.86798
I0511 08:58:35.048068  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.92458 (* 1 = 2.92458 loss)
I0511 08:58:35.048089  5307 sgd_solver.cpp:172] Iteration 103900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 08:59:01.674793  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 08:59:35.537987  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_104000.caffemodel
I0511 08:59:35.552865  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_104000.solverstate
I0511 08:59:35.557982  5307 solver.cpp:635] Iteration 104000, Testing net (#0)
I0511 09:00:15.941030  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 09:00:16.171171  5307 solver.cpp:747] class AP 1: 0.658912
I0511 09:00:16.171667  5307 solver.cpp:747] class AP 2: 0.733622
I0511 09:00:16.178172  5307 solver.cpp:747] class AP 3: 0.560076
I0511 09:00:16.181856  5307 solver.cpp:747] class AP 4: 0.507364
I0511 09:00:16.200403  5307 solver.cpp:747] class AP 5: 0.342464
I0511 09:00:16.200734  5307 solver.cpp:747] class AP 6: 0.737497
I0511 09:00:16.209339  5307 solver.cpp:747] class AP 7: 0.704001
I0511 09:00:16.209879  5307 solver.cpp:747] class AP 8: 0.816034
I0511 09:00:16.228055  5307 solver.cpp:747] class AP 9: 0.434627
I0511 09:00:16.228770  5307 solver.cpp:747] class AP 10: 0.626055
I0511 09:00:16.229395  5307 solver.cpp:747] class AP 11: 0.601497
I0511 09:00:16.230235  5307 solver.cpp:747] class AP 12: 0.720504
I0511 09:00:16.230667  5307 solver.cpp:747] class AP 13: 0.798838
I0511 09:00:16.231020  5307 solver.cpp:747] class AP 14: 0.741948
I0511 09:00:16.281016  5307 solver.cpp:747] class AP 15: 0.727061
I0511 09:00:16.287535  5307 solver.cpp:747] class AP 16: 0.36246
I0511 09:00:16.290091  5307 solver.cpp:747] class AP 17: 0.598146
I0511 09:00:16.290707  5307 solver.cpp:747] class AP 18: 0.609144
I0511 09:00:16.291417  5307 solver.cpp:747] class AP 19: 0.747257
I0511 09:00:16.292925  5307 solver.cpp:747] class AP 20: 0.609945
I0511 09:00:16.292943  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.631873
I0511 09:00:16.293195  5307 solver.cpp:283] Tests completed in 101.243s
I0511 09:00:16.893482  5307 solver.cpp:352] Iteration 104000 (0.987718 iter/s, 101.243s/100 iter), 201.1/232ep, loss = 2.84492
I0511 09:00:16.893506  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.13108 (* 1 = 2.13108 loss)
I0511 09:00:16.893512  5307 sgd_solver.cpp:172] Iteration 104000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:01:18.301661  5307 solver.cpp:352] Iteration 104100 (1.62848 iter/s, 61.4071s/100 iter), 201.3/232ep, loss = 3.17149
I0511 09:01:18.301719  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.66412 (* 1 = 2.66412 loss)
I0511 09:01:18.301728  5307 sgd_solver.cpp:172] Iteration 104100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:02:19.057096  5307 solver.cpp:352] Iteration 104200 (1.64597 iter/s, 60.7543s/100 iter), 201.5/232ep, loss = 2.97307
I0511 09:02:19.057158  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.79797 (* 1 = 2.79797 loss)
I0511 09:02:19.057164  5307 sgd_solver.cpp:172] Iteration 104200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:03:19.339989  5307 solver.cpp:352] Iteration 104300 (1.65888 iter/s, 60.2818s/100 iter), 201.7/232ep, loss = 2.97009
I0511 09:03:19.340106  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.71737 (* 1 = 2.71737 loss)
I0511 09:03:19.340113  5307 sgd_solver.cpp:172] Iteration 104300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:04:19.700664  5307 solver.cpp:352] Iteration 104400 (1.65674 iter/s, 60.3596s/100 iter), 201.8/232ep, loss = 3.18266
I0511 09:04:19.700740  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.75174 (* 1 = 2.75174 loss)
I0511 09:04:19.700747  5307 sgd_solver.cpp:172] Iteration 104400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:04:55.972400  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 09:05:19.960947  5307 solver.cpp:352] Iteration 104500 (1.6595 iter/s, 60.2592s/100 iter), 202/232ep, loss = 3.00151
I0511 09:05:19.960974  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.33216 (* 1 = 4.33216 loss)
I0511 09:05:19.960983  5307 sgd_solver.cpp:172] Iteration 104500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:06:21.572664  5307 solver.cpp:352] Iteration 104600 (1.6231 iter/s, 61.6106s/100 iter), 202.2/232ep, loss = 2.96726
I0511 09:06:21.574237  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.63491 (* 1 = 2.63491 loss)
I0511 09:06:21.574266  5307 sgd_solver.cpp:172] Iteration 104600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:07:22.228152  5307 solver.cpp:352] Iteration 104700 (1.64868 iter/s, 60.6544s/100 iter), 202.4/232ep, loss = 2.94288
I0511 09:07:22.228384  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.29353 (* 1 = 2.29353 loss)
I0511 09:07:22.228392  5307 sgd_solver.cpp:172] Iteration 104700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:08:22.898113  5307 solver.cpp:352] Iteration 104800 (1.64829 iter/s, 60.6688s/100 iter), 202.6/232ep, loss = 2.97853
I0511 09:08:22.899556  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.0337 (* 1 = 2.0337 loss)
I0511 09:08:22.899595  5307 sgd_solver.cpp:172] Iteration 104800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:09:23.892618  5307 solver.cpp:352] Iteration 104900 (1.63952 iter/s, 60.9934s/100 iter), 202.8/232ep, loss = 2.9735
I0511 09:09:23.892762  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.52497 (* 1 = 3.52497 loss)
I0511 09:09:23.892772  5307 sgd_solver.cpp:172] Iteration 104900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:10:10.349397  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 09:10:24.394165  5307 solver.cpp:352] Iteration 105000 (1.65288 iter/s, 60.5004s/100 iter), 203/232ep, loss = 3.00669
I0511 09:10:24.394269  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.04437 (* 1 = 3.04437 loss)
I0511 09:10:24.394306  5307 sgd_solver.cpp:172] Iteration 105000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:11:26.353379  5307 solver.cpp:352] Iteration 105100 (1.61399 iter/s, 61.9581s/100 iter), 203.2/232ep, loss = 2.88185
I0511 09:11:26.353467  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.6082 (* 1 = 2.6082 loss)
I0511 09:11:26.353478  5307 sgd_solver.cpp:172] Iteration 105100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:12:27.174247  5307 solver.cpp:352] Iteration 105200 (1.6442 iter/s, 60.8197s/100 iter), 203.4/232ep, loss = 2.87346
I0511 09:12:27.174407  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.02363 (* 1 = 4.02363 loss)
I0511 09:12:27.174417  5307 sgd_solver.cpp:172] Iteration 105200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:13:28.831068  5307 solver.cpp:352] Iteration 105300 (1.62191 iter/s, 61.6557s/100 iter), 203.6/232ep, loss = 3.00454
I0511 09:13:28.831135  5307 solver.cpp:376]     Train net output #0: mbox_loss = 4.38076 (* 1 = 4.38076 loss)
I0511 09:13:28.831141  5307 sgd_solver.cpp:172] Iteration 105300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:14:30.143863  5307 solver.cpp:352] Iteration 105400 (1.63101 iter/s, 61.3116s/100 iter), 203.8/232ep, loss = 2.85613
I0511 09:14:30.144198  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.83625 (* 1 = 2.83625 loss)
I0511 09:14:30.144227  5307 sgd_solver.cpp:172] Iteration 105400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:15:28.410624  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 09:15:31.289784  5307 solver.cpp:352] Iteration 105500 (1.63546 iter/s, 61.1448s/100 iter), 204/232ep, loss = 3.07666
I0511 09:15:31.289810  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.81599 (* 1 = 2.81599 loss)
I0511 09:15:31.289819  5307 sgd_solver.cpp:172] Iteration 105500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:16:31.947705  5307 solver.cpp:352] Iteration 105600 (1.64862 iter/s, 60.6568s/100 iter), 204.2/232ep, loss = 2.84988
I0511 09:16:31.947778  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.81488 (* 1 = 2.81488 loss)
I0511 09:16:31.947788  5307 sgd_solver.cpp:172] Iteration 105600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:17:32.886667  5307 solver.cpp:352] Iteration 105700 (1.64102 iter/s, 60.9379s/100 iter), 204.4/232ep, loss = 3.18043
I0511 09:17:32.886966  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.54316 (* 1 = 2.54316 loss)
I0511 09:17:32.886976  5307 sgd_solver.cpp:172] Iteration 105700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:18:34.355509  5307 solver.cpp:352] Iteration 105800 (1.62687 iter/s, 61.4677s/100 iter), 204.6/232ep, loss = 3.05276
I0511 09:18:34.355572  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.07529 (* 1 = 3.07529 loss)
I0511 09:18:34.355579  5307 sgd_solver.cpp:172] Iteration 105800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:19:35.041429  5307 solver.cpp:352] Iteration 105900 (1.64786 iter/s, 60.6848s/100 iter), 204.7/232ep, loss = 2.9841
I0511 09:19:35.041501  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.95786 (* 1 = 2.95786 loss)
I0511 09:19:35.041512  5307 sgd_solver.cpp:172] Iteration 105900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:20:35.229087  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_106000.caffemodel
I0511 09:20:35.249084  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_106000.solverstate
I0511 09:20:35.255237  5307 solver.cpp:635] Iteration 106000, Testing net (#0)
I0511 09:21:15.721871  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 09:21:15.931792  5307 solver.cpp:747] class AP 1: 0.660411
I0511 09:21:15.932317  5307 solver.cpp:747] class AP 2: 0.730086
I0511 09:21:15.938953  5307 solver.cpp:747] class AP 3: 0.557565
I0511 09:21:15.942739  5307 solver.cpp:747] class AP 4: 0.505904
I0511 09:21:15.962241  5307 solver.cpp:747] class AP 5: 0.345831
I0511 09:21:15.962599  5307 solver.cpp:747] class AP 6: 0.736774
I0511 09:21:15.971547  5307 solver.cpp:747] class AP 7: 0.705488
I0511 09:21:15.972134  5307 solver.cpp:747] class AP 8: 0.819378
I0511 09:21:15.990371  5307 solver.cpp:747] class AP 9: 0.429442
I0511 09:21:15.991097  5307 solver.cpp:747] class AP 10: 0.633304
I0511 09:21:15.991744  5307 solver.cpp:747] class AP 11: 0.595445
I0511 09:21:15.992588  5307 solver.cpp:747] class AP 12: 0.721519
I0511 09:21:15.993032  5307 solver.cpp:747] class AP 13: 0.796779
I0511 09:21:15.993393  5307 solver.cpp:747] class AP 14: 0.748903
I0511 09:21:16.041465  5307 solver.cpp:747] class AP 15: 0.725762
I0511 09:21:16.047837  5307 solver.cpp:747] class AP 16: 0.364806
I0511 09:21:16.050380  5307 solver.cpp:747] class AP 17: 0.598963
I0511 09:21:16.050945  5307 solver.cpp:747] class AP 18: 0.604041
I0511 09:21:16.051612  5307 solver.cpp:747] class AP 19: 0.749612
I0511 09:21:16.053093  5307 solver.cpp:747] class AP 20: 0.610039
I0511 09:21:16.053099  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.632003
I0511 09:21:16.053356  5307 solver.cpp:283] Tests completed in 101.01s
I0511 09:21:16.605718  5307 solver.cpp:352] Iteration 106000 (0.99 iter/s, 101.01s/100 iter), 204.9/232ep, loss = 2.97081
I0511 09:21:16.605746  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.91581 (* 1 = 2.91581 loss)
I0511 09:21:16.605754  5307 sgd_solver.cpp:172] Iteration 106000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:21:23.239075  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 09:22:16.511878  5307 solver.cpp:352] Iteration 106100 (1.66931 iter/s, 59.9051s/100 iter), 205.1/232ep, loss = 2.79096
I0511 09:22:16.511988  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.9052 (* 1 = 2.9052 loss)
I0511 09:22:16.512006  5307 sgd_solver.cpp:172] Iteration 106100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:23:17.654028  5307 solver.cpp:352] Iteration 106200 (1.63556 iter/s, 61.141s/100 iter), 205.3/232ep, loss = 2.99165
I0511 09:23:17.654165  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.20889 (* 1 = 3.20889 loss)
I0511 09:23:17.654181  5307 sgd_solver.cpp:172] Iteration 106200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:24:18.296691  5307 solver.cpp:352] Iteration 106300 (1.64903 iter/s, 60.6416s/100 iter), 205.5/232ep, loss = 3.0056
I0511 09:24:18.296780  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.80644 (* 1 = 3.80644 loss)
I0511 09:24:18.296798  5307 sgd_solver.cpp:172] Iteration 106300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:25:18.281538  5307 solver.cpp:352] Iteration 106400 (1.66712 iter/s, 59.9838s/100 iter), 205.7/232ep, loss = 2.94822
I0511 09:25:18.281648  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.13342 (* 1 = 2.13342 loss)
I0511 09:25:18.281662  5307 sgd_solver.cpp:172] Iteration 106400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:26:18.623312  5307 solver.cpp:352] Iteration 106500 (1.65726 iter/s, 60.3407s/100 iter), 205.9/232ep, loss = 2.91705
I0511 09:26:18.623702  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.31356 (* 1 = 3.31356 loss)
I0511 09:26:18.623710  5307 sgd_solver.cpp:172] Iteration 106500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:26:36.457285  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 09:27:19.887410  5307 solver.cpp:352] Iteration 106600 (1.63231 iter/s, 61.263s/100 iter), 206.1/232ep, loss = 3.00814
I0511 09:27:19.889544  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.25941 (* 1 = 3.25941 loss)
I0511 09:27:19.889564  5307 sgd_solver.cpp:172] Iteration 106600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:28:21.581161  5307 solver.cpp:352] Iteration 106700 (1.62094 iter/s, 61.6927s/100 iter), 206.3/232ep, loss = 3.08816
I0511 09:28:21.581254  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.27414 (* 1 = 3.27414 loss)
I0511 09:28:21.581272  5307 sgd_solver.cpp:172] Iteration 106700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:29:24.353520  5307 solver.cpp:352] Iteration 106800 (1.59309 iter/s, 62.7713s/100 iter), 206.5/232ep, loss = 2.97322
I0511 09:29:24.353602  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.45352 (* 1 = 3.45352 loss)
I0511 09:29:24.353622  5307 sgd_solver.cpp:172] Iteration 106800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:30:25.825932  5307 solver.cpp:352] Iteration 106900 (1.62678 iter/s, 61.4713s/100 iter), 206.7/232ep, loss = 2.96496
I0511 09:30:25.826134  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.6223 (* 1 = 2.6223 loss)
I0511 09:30:25.826148  5307 sgd_solver.cpp:172] Iteration 106900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:31:27.199806  5307 solver.cpp:352] Iteration 107000 (1.62939 iter/s, 61.3728s/100 iter), 206.9/232ep, loss = 2.87001
I0511 09:31:27.199870  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.64079 (* 1 = 3.64079 loss)
I0511 09:31:27.199879  5307 sgd_solver.cpp:172] Iteration 107000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:31:55.909417  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 09:32:28.962905  5307 solver.cpp:352] Iteration 107100 (1.61912 iter/s, 61.762s/100 iter), 207.1/232ep, loss = 3.00419
I0511 09:32:28.963433  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.91865 (* 1 = 2.91865 loss)
I0511 09:32:28.963446  5307 sgd_solver.cpp:172] Iteration 107100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:33:30.509364  5307 solver.cpp:352] Iteration 107200 (1.62482 iter/s, 61.5453s/100 iter), 207.3/232ep, loss = 3.30159
I0511 09:33:30.511792  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.6854 (* 1 = 2.6854 loss)
I0511 09:33:30.511801  5307 sgd_solver.cpp:172] Iteration 107200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:34:31.048547  5307 solver.cpp:352] Iteration 107300 (1.65185 iter/s, 60.5381s/100 iter), 207.5/232ep, loss = 3.02911
I0511 09:34:31.048740  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.60675 (* 1 = 3.60675 loss)
I0511 09:34:31.048806  5307 sgd_solver.cpp:172] Iteration 107300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:35:32.531407  5307 solver.cpp:352] Iteration 107400 (1.6265 iter/s, 61.4817s/100 iter), 207.6/232ep, loss = 2.8751
I0511 09:35:32.532121  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.31164 (* 1 = 3.31164 loss)
I0511 09:35:32.532130  5307 sgd_solver.cpp:172] Iteration 107400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:36:33.544476  5307 solver.cpp:352] Iteration 107500 (1.63902 iter/s, 61.0119s/100 iter), 207.8/232ep, loss = 3.05105
I0511 09:36:33.544617  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.65433 (* 1 = 2.65433 loss)
I0511 09:36:33.544636  5307 sgd_solver.cpp:172] Iteration 107500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:37:11.896042  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 09:37:34.432308  5307 solver.cpp:352] Iteration 107600 (1.64239 iter/s, 60.8867s/100 iter), 208/232ep, loss = 2.922
I0511 09:37:34.432337  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.57429 (* 1 = 2.57429 loss)
I0511 09:37:34.432345  5307 sgd_solver.cpp:172] Iteration 107600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:38:36.154429  5307 solver.cpp:352] Iteration 107700 (1.62019 iter/s, 61.721s/100 iter), 208.2/232ep, loss = 2.95121
I0511 09:38:36.156332  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.72509 (* 1 = 2.72509 loss)
I0511 09:38:36.156342  5307 sgd_solver.cpp:172] Iteration 107700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:39:37.661792  5307 solver.cpp:352] Iteration 107800 (1.62585 iter/s, 61.5062s/100 iter), 208.4/232ep, loss = 2.9885
I0511 09:39:37.662276  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.4115 (* 1 = 3.4115 loss)
I0511 09:39:37.662286  5307 sgd_solver.cpp:172] Iteration 107800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:40:38.793115  5307 solver.cpp:352] Iteration 107900 (1.63585 iter/s, 61.1302s/100 iter), 208.6/232ep, loss = 3.15024
I0511 09:40:38.794373  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.24121 (* 1 = 3.24121 loss)
I0511 09:40:38.794384  5307 sgd_solver.cpp:172] Iteration 107900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:41:39.421762  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_108000.caffemodel
I0511 09:41:39.435892  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_108000.solverstate
I0511 09:41:39.441318  5307 solver.cpp:635] Iteration 108000, Testing net (#0)
I0511 09:42:19.909317  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 09:42:20.142171  5307 solver.cpp:747] class AP 1: 0.656404
I0511 09:42:20.142681  5307 solver.cpp:747] class AP 2: 0.728707
I0511 09:42:20.149108  5307 solver.cpp:747] class AP 3: 0.554245
I0511 09:42:20.152906  5307 solver.cpp:747] class AP 4: 0.51111
I0511 09:42:20.172255  5307 solver.cpp:747] class AP 5: 0.346773
I0511 09:42:20.172605  5307 solver.cpp:747] class AP 6: 0.744805
I0511 09:42:20.181558  5307 solver.cpp:747] class AP 7: 0.703511
I0511 09:42:20.182119  5307 solver.cpp:747] class AP 8: 0.818978
I0511 09:42:20.200107  5307 solver.cpp:747] class AP 9: 0.432783
I0511 09:42:20.200898  5307 solver.cpp:747] class AP 10: 0.628323
I0511 09:42:20.201720  5307 solver.cpp:747] class AP 11: 0.588869
I0511 09:42:20.202574  5307 solver.cpp:747] class AP 12: 0.720254
I0511 09:42:20.203035  5307 solver.cpp:747] class AP 13: 0.798658
I0511 09:42:20.203418  5307 solver.cpp:747] class AP 14: 0.747712
I0511 09:42:20.259835  5307 solver.cpp:747] class AP 15: 0.726384
I0511 09:42:20.266482  5307 solver.cpp:747] class AP 16: 0.356199
I0511 09:42:20.269019  5307 solver.cpp:747] class AP 17: 0.598237
I0511 09:42:20.269618  5307 solver.cpp:747] class AP 18: 0.603476
I0511 09:42:20.270298  5307 solver.cpp:747] class AP 19: 0.759944
I0511 09:42:20.271759  5307 solver.cpp:747] class AP 20: 0.615325
I0511 09:42:20.271777  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.632035
I0511 09:42:20.272122  5307 solver.cpp:283] Tests completed in 101.477s
I0511 09:42:20.826761  5307 solver.cpp:352] Iteration 108000 (0.985443 iter/s, 101.477s/100 iter), 208.8/232ep, loss = 2.9927
I0511 09:42:20.827028  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.90072 (* 1 = 2.90072 loss)
I0511 09:42:20.827039  5307 sgd_solver.cpp:172] Iteration 108000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:43:10.224517  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 09:43:22.015218  5307 solver.cpp:352] Iteration 108100 (1.63432 iter/s, 61.1873s/100 iter), 209/232ep, loss = 3.04481
I0511 09:43:22.015246  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.63587 (* 1 = 2.63587 loss)
I0511 09:43:22.015254  5307 sgd_solver.cpp:172] Iteration 108100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:44:23.599179  5307 solver.cpp:352] Iteration 108200 (1.62383 iter/s, 61.5828s/100 iter), 209.2/232ep, loss = 2.92217
I0511 09:44:23.600044  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.41159 (* 1 = 2.41159 loss)
I0511 09:44:23.600061  5307 sgd_solver.cpp:172] Iteration 108200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:45:25.352929  5307 solver.cpp:352] Iteration 108300 (1.61936 iter/s, 61.7527s/100 iter), 209.4/232ep, loss = 2.88494
I0511 09:45:25.352996  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.46943 (* 1 = 3.46943 loss)
I0511 09:45:25.353006  5307 sgd_solver.cpp:172] Iteration 108300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:46:27.529007  5307 solver.cpp:352] Iteration 108400 (1.60836 iter/s, 62.1749s/100 iter), 209.6/232ep, loss = 3.15808
I0511 09:46:27.531289  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.35382 (* 1 = 2.35382 loss)
I0511 09:46:27.531325  5307 sgd_solver.cpp:172] Iteration 108400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:47:28.979347  5307 solver.cpp:352] Iteration 108500 (1.62736 iter/s, 61.4493s/100 iter), 209.8/232ep, loss = 3.06685
I0511 09:47:28.979426  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.57391 (* 1 = 2.57391 loss)
I0511 09:47:28.979434  5307 sgd_solver.cpp:172] Iteration 108500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:48:29.157548  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 09:48:30.958716  5307 solver.cpp:352] Iteration 108600 (1.61347 iter/s, 61.9783s/100 iter), 210/232ep, loss = 3.16514
I0511 09:48:30.958742  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.32524 (* 1 = 3.32524 loss)
I0511 09:48:30.958748  5307 sgd_solver.cpp:172] Iteration 108600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:49:31.946439  5307 solver.cpp:352] Iteration 108700 (1.6397 iter/s, 60.9866s/100 iter), 210.2/232ep, loss = 3.11442
I0511 09:49:31.946703  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.58374 (* 1 = 3.58374 loss)
I0511 09:49:31.946714  5307 sgd_solver.cpp:172] Iteration 108700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:50:33.278905  5307 solver.cpp:352] Iteration 108800 (1.63049 iter/s, 61.3314s/100 iter), 210.4/232ep, loss = 3.11977
I0511 09:50:33.279023  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.24816 (* 1 = 3.24816 loss)
I0511 09:50:33.279034  5307 sgd_solver.cpp:172] Iteration 108800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:51:35.136703  5307 solver.cpp:352] Iteration 108900 (1.61664 iter/s, 61.8567s/100 iter), 210.5/232ep, loss = 2.79067
I0511 09:51:35.138720  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.31322 (* 1 = 3.31322 loss)
I0511 09:51:35.138751  5307 sgd_solver.cpp:172] Iteration 108900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:52:36.540758  5307 solver.cpp:352] Iteration 109000 (1.62859 iter/s, 61.403s/100 iter), 210.7/232ep, loss = 3.03206
I0511 09:52:36.543386  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.53034 (* 1 = 2.53034 loss)
I0511 09:52:36.543408  5307 sgd_solver.cpp:172] Iteration 109000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:53:36.958336  5307 solver.cpp:352] Iteration 109100 (1.65518 iter/s, 60.4165s/100 iter), 210.9/232ep, loss = 2.81642
I0511 09:53:36.958397  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.55472 (* 1 = 3.55472 loss)
I0511 09:53:36.958406  5307 sgd_solver.cpp:172] Iteration 109100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:53:46.445642  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 09:54:39.186568  5307 solver.cpp:352] Iteration 109200 (1.60702 iter/s, 62.2271s/100 iter), 211.1/232ep, loss = 2.96823
I0511 09:54:39.186671  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.5983 (* 1 = 2.5983 loss)
I0511 09:54:39.186682  5307 sgd_solver.cpp:172] Iteration 109200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:55:41.894292  5307 solver.cpp:352] Iteration 109300 (1.59473 iter/s, 62.7066s/100 iter), 211.3/232ep, loss = 3.0341
I0511 09:55:41.894351  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.34157 (* 1 = 3.34157 loss)
I0511 09:55:41.894359  5307 sgd_solver.cpp:172] Iteration 109300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:56:43.293130  5307 solver.cpp:352] Iteration 109400 (1.62873 iter/s, 61.3977s/100 iter), 211.5/232ep, loss = 2.94719
I0511 09:56:43.293259  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.5932 (* 1 = 2.5932 loss)
I0511 09:56:43.293289  5307 sgd_solver.cpp:172] Iteration 109400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:57:44.943948  5307 solver.cpp:352] Iteration 109500 (1.62207 iter/s, 61.6497s/100 iter), 211.7/232ep, loss = 3.04132
I0511 09:57:44.944041  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.2802 (* 1 = 2.2802 loss)
I0511 09:57:44.944051  5307 sgd_solver.cpp:172] Iteration 109500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:58:46.472889  5307 solver.cpp:352] Iteration 109600 (1.62528 iter/s, 61.5278s/100 iter), 211.9/232ep, loss = 3.05654
I0511 09:58:46.476739  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.87819 (* 1 = 2.87819 loss)
I0511 09:58:46.476758  5307 sgd_solver.cpp:172] Iteration 109600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 09:59:07.274627  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 09:59:48.034642  5307 solver.cpp:352] Iteration 109700 (1.62442 iter/s, 61.5606s/100 iter), 212.1/232ep, loss = 3.04314
I0511 09:59:48.034703  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.15212 (* 1 = 3.15212 loss)
I0511 09:59:48.034711  5307 sgd_solver.cpp:172] Iteration 109700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:00:57.823367  5307 solver.cpp:352] Iteration 109800 (1.43292 iter/s, 69.7874s/100 iter), 212.3/232ep, loss = 3.09853
I0511 10:00:57.823479  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.29951 (* 1 = 3.29951 loss)
I0511 10:00:57.823501  5307 sgd_solver.cpp:172] Iteration 109800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:02:03.153767  5307 solver.cpp:352] Iteration 109900 (1.53071 iter/s, 65.3292s/100 iter), 212.5/232ep, loss = 3.13834
I0511 10:02:03.153846  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.69669 (* 1 = 3.69669 loss)
I0511 10:02:03.153853  5307 sgd_solver.cpp:172] Iteration 109900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:03:03.416615  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_110000.caffemodel
I0511 10:03:03.433248  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_110000.solverstate
I0511 10:03:03.438459  5307 solver.cpp:635] Iteration 110000, Testing net (#0)
I0511 10:03:25.448328  5354 blocking_queue.cpp:40] Waiting for data
I0511 10:03:43.845228  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 10:03:44.052278  5307 solver.cpp:747] class AP 1: 0.65293
I0511 10:03:44.052799  5307 solver.cpp:747] class AP 2: 0.733623
I0511 10:03:44.059448  5307 solver.cpp:747] class AP 3: 0.557503
I0511 10:03:44.063221  5307 solver.cpp:747] class AP 4: 0.512509
I0511 10:03:44.082121  5307 solver.cpp:747] class AP 5: 0.345366
I0511 10:03:44.082494  5307 solver.cpp:747] class AP 6: 0.739828
I0511 10:03:44.091215  5307 solver.cpp:747] class AP 7: 0.703411
I0511 10:03:44.091783  5307 solver.cpp:747] class AP 8: 0.816873
I0511 10:03:44.110553  5307 solver.cpp:747] class AP 9: 0.43649
I0511 10:03:44.111286  5307 solver.cpp:747] class AP 10: 0.631253
I0511 10:03:44.112057  5307 solver.cpp:747] class AP 11: 0.589722
I0511 10:03:44.113168  5307 solver.cpp:747] class AP 12: 0.720832
I0511 10:03:44.113615  5307 solver.cpp:747] class AP 13: 0.79909
I0511 10:03:44.113967  5307 solver.cpp:747] class AP 14: 0.74729
I0511 10:03:44.163322  5307 solver.cpp:747] class AP 15: 0.725755
I0511 10:03:44.169760  5307 solver.cpp:747] class AP 16: 0.358302
I0511 10:03:44.172224  5307 solver.cpp:747] class AP 17: 0.598111
I0511 10:03:44.172845  5307 solver.cpp:747] class AP 18: 0.601112
I0511 10:03:44.173518  5307 solver.cpp:747] class AP 19: 0.752073
I0511 10:03:44.175300  5307 solver.cpp:747] class AP 20: 0.609423
I0511 10:03:44.175433  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.631575
I0511 10:03:44.175595  5307 solver.cpp:283] Tests completed in 101.02s
I0511 10:03:44.715556  5307 solver.cpp:352] Iteration 110000 (0.989903 iter/s, 101.02s/100 iter), 212.7/232ep, loss = 2.89916
I0511 10:03:44.715628  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.63487 (* 1 = 2.63487 loss)
I0511 10:03:44.715646  5307 sgd_solver.cpp:172] Iteration 110000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:04:45.138458  5307 solver.cpp:352] Iteration 110100 (1.65503 iter/s, 60.4218s/100 iter), 212.9/232ep, loss = 3.00876
I0511 10:04:45.138525  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.1163 (* 1 = 3.1163 loss)
I0511 10:04:45.138535  5307 sgd_solver.cpp:172] Iteration 110100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:05:14.963007  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 10:05:46.285318  5307 solver.cpp:352] Iteration 110200 (1.63544 iter/s, 61.1457s/100 iter), 213.1/232ep, loss = 3.04647
I0511 10:05:46.285425  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.90314 (* 1 = 2.90314 loss)
I0511 10:05:46.285439  5307 sgd_solver.cpp:172] Iteration 110200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:06:46.456821  5307 solver.cpp:352] Iteration 110300 (1.66195 iter/s, 60.1704s/100 iter), 213.3/232ep, loss = 3.11642
I0511 10:06:46.456908  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.70813 (* 1 = 2.70813 loss)
I0511 10:06:46.456918  5307 sgd_solver.cpp:172] Iteration 110300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:07:47.811429  5307 solver.cpp:352] Iteration 110400 (1.6299 iter/s, 61.3535s/100 iter), 213.4/232ep, loss = 3.08903
I0511 10:07:47.811530  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.70512 (* 1 = 2.70512 loss)
I0511 10:07:47.811553  5307 sgd_solver.cpp:172] Iteration 110400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:08:48.071257  5307 solver.cpp:352] Iteration 110500 (1.65951 iter/s, 60.2587s/100 iter), 213.6/232ep, loss = 2.86229
I0511 10:08:48.071324  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.34643 (* 1 = 3.34643 loss)
I0511 10:08:48.071367  5307 sgd_solver.cpp:172] Iteration 110500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:09:49.470010  5307 solver.cpp:352] Iteration 110600 (1.62872 iter/s, 61.3977s/100 iter), 213.8/232ep, loss = 3.12379
I0511 10:09:49.470111  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.75619 (* 1 = 2.75619 loss)
I0511 10:09:49.470121  5307 sgd_solver.cpp:172] Iteration 110600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:10:30.507227  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 10:10:50.539381  5307 solver.cpp:352] Iteration 110700 (1.63751 iter/s, 61.0683s/100 iter), 214/232ep, loss = 2.99424
I0511 10:10:50.539412  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.89221 (* 1 = 2.89221 loss)
I0511 10:10:50.539420  5307 sgd_solver.cpp:172] Iteration 110700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:11:52.147364  5307 solver.cpp:352] Iteration 110800 (1.62319 iter/s, 61.6069s/100 iter), 214.2/232ep, loss = 3.14237
I0511 10:11:52.147531  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.78656 (* 1 = 2.78656 loss)
I0511 10:11:52.147547  5307 sgd_solver.cpp:172] Iteration 110800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:12:52.570505  5307 solver.cpp:352] Iteration 110900 (1.65502 iter/s, 60.4221s/100 iter), 214.4/232ep, loss = 3.02799
I0511 10:12:52.570567  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.16478 (* 1 = 2.16478 loss)
I0511 10:12:52.570576  5307 sgd_solver.cpp:172] Iteration 110900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:13:53.284628  5307 solver.cpp:352] Iteration 111000 (1.64709 iter/s, 60.7131s/100 iter), 214.6/232ep, loss = 2.94168
I0511 10:13:53.284693  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.99242 (* 1 = 2.99242 loss)
I0511 10:13:53.284700  5307 sgd_solver.cpp:172] Iteration 111000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:14:53.858494  5307 solver.cpp:352] Iteration 111100 (1.65091 iter/s, 60.5728s/100 iter), 214.8/232ep, loss = 2.93955
I0511 10:14:53.858589  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.69679 (* 1 = 2.69679 loss)
I0511 10:14:53.858608  5307 sgd_solver.cpp:172] Iteration 111100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:15:44.839627  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 10:15:55.098361  5307 solver.cpp:352] Iteration 111200 (1.63295 iter/s, 61.2388s/100 iter), 215/232ep, loss = 2.86403
I0511 10:15:55.098414  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.10467 (* 1 = 3.10467 loss)
I0511 10:15:55.098424  5307 sgd_solver.cpp:172] Iteration 111200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:16:55.731014  5307 solver.cpp:352] Iteration 111300 (1.6493 iter/s, 60.6316s/100 iter), 215.2/232ep, loss = 3.04527
I0511 10:16:55.731109  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.95204 (* 1 = 2.95204 loss)
I0511 10:16:55.731127  5307 sgd_solver.cpp:172] Iteration 111300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:17:56.691306  5307 solver.cpp:352] Iteration 111400 (1.64044 iter/s, 60.9592s/100 iter), 215.4/232ep, loss = 2.94958
I0511 10:17:56.691378  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.11284 (* 1 = 3.11284 loss)
I0511 10:17:56.691396  5307 sgd_solver.cpp:172] Iteration 111400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:18:57.145282  5307 solver.cpp:352] Iteration 111500 (1.65418 iter/s, 60.4529s/100 iter), 215.6/232ep, loss = 3.01524
I0511 10:18:57.145421  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.94067 (* 1 = 2.94067 loss)
I0511 10:18:57.145431  5307 sgd_solver.cpp:172] Iteration 111500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:19:58.131446  5307 solver.cpp:352] Iteration 111600 (1.63975 iter/s, 60.9851s/100 iter), 215.8/232ep, loss = 2.99065
I0511 10:19:58.131516  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.92307 (* 1 = 2.92307 loss)
I0511 10:19:58.131525  5307 sgd_solver.cpp:172] Iteration 111600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:20:59.895972  5307 solver.cpp:352] Iteration 111700 (1.61908 iter/s, 61.7634s/100 iter), 216/232ep, loss = 2.88708
I0511 10:20:59.896270  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.31386 (* 1 = 2.31386 loss)
I0511 10:20:59.896335  5307 sgd_solver.cpp:172] Iteration 111700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:21:00.557533  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 10:22:00.743355  5307 solver.cpp:352] Iteration 111800 (1.64349 iter/s, 60.8463s/100 iter), 216.2/232ep, loss = 3.08605
I0511 10:22:00.746047  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.7764 (* 1 = 2.7764 loss)
I0511 10:22:00.746073  5307 sgd_solver.cpp:172] Iteration 111800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:23:01.987576  5307 solver.cpp:352] Iteration 111900 (1.63284 iter/s, 61.2431s/100 iter), 216.3/232ep, loss = 3.08897
I0511 10:23:01.987634  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.6799 (* 1 = 2.6799 loss)
I0511 10:23:01.987643  5307 sgd_solver.cpp:172] Iteration 111900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:24:03.145884  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_112000.caffemodel
I0511 10:24:03.165766  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_112000.solverstate
I0511 10:24:03.171766  5307 solver.cpp:635] Iteration 112000, Testing net (#0)
I0511 10:24:43.817241  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 10:24:44.021019  5307 solver.cpp:747] class AP 1: 0.652025
I0511 10:24:44.021556  5307 solver.cpp:747] class AP 2: 0.735424
I0511 10:24:44.027999  5307 solver.cpp:747] class AP 3: 0.562478
I0511 10:24:44.031703  5307 solver.cpp:747] class AP 4: 0.510381
I0511 10:24:44.049821  5307 solver.cpp:747] class AP 5: 0.346569
I0511 10:24:44.050158  5307 solver.cpp:747] class AP 6: 0.736914
I0511 10:24:44.058876  5307 solver.cpp:747] class AP 7: 0.704268
I0511 10:24:44.059409  5307 solver.cpp:747] class AP 8: 0.818155
I0511 10:24:44.077251  5307 solver.cpp:747] class AP 9: 0.431948
I0511 10:24:44.078028  5307 solver.cpp:747] class AP 10: 0.627871
I0511 10:24:44.078682  5307 solver.cpp:747] class AP 11: 0.593541
I0511 10:24:44.079497  5307 solver.cpp:747] class AP 12: 0.724921
I0511 10:24:44.079932  5307 solver.cpp:747] class AP 13: 0.804708
I0511 10:24:44.080291  5307 solver.cpp:747] class AP 14: 0.748014
I0511 10:24:44.131726  5307 solver.cpp:747] class AP 15: 0.726007
I0511 10:24:44.138413  5307 solver.cpp:747] class AP 16: 0.365348
I0511 10:24:44.140985  5307 solver.cpp:747] class AP 17: 0.598858
I0511 10:24:44.141667  5307 solver.cpp:747] class AP 18: 0.608303
I0511 10:24:44.142585  5307 solver.cpp:747] class AP 19: 0.754497
I0511 10:24:44.144356  5307 solver.cpp:747] class AP 20: 0.611097
I0511 10:24:44.144549  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.633066
I0511 10:24:44.144703  5307 solver.cpp:283] Tests completed in 102.155s
I0511 10:24:44.779572  5307 solver.cpp:352] Iteration 112000 (0.978902 iter/s, 102.155s/100 iter), 216.5/232ep, loss = 2.84662
I0511 10:24:44.779598  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.99714 (* 1 = 2.99714 loss)
I0511 10:24:44.779605  5307 sgd_solver.cpp:172] Iteration 112000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:25:45.657253  5307 solver.cpp:352] Iteration 112100 (1.64267 iter/s, 60.8766s/100 iter), 216.7/232ep, loss = 2.94875
I0511 10:25:45.657313  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.73282 (* 1 = 3.73282 loss)
I0511 10:25:45.657322  5307 sgd_solver.cpp:172] Iteration 112100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:26:47.189956  5307 solver.cpp:352] Iteration 112200 (1.62518 iter/s, 61.5316s/100 iter), 216.9/232ep, loss = 2.94758
I0511 10:26:47.190044  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.77857 (* 1 = 2.77857 loss)
I0511 10:26:47.190053  5307 sgd_solver.cpp:172] Iteration 112200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:26:58.774957  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 10:27:48.748471  5307 solver.cpp:352] Iteration 112300 (1.6245 iter/s, 61.5574s/100 iter), 217.1/232ep, loss = 3.19982
I0511 10:27:48.748627  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.7726 (* 1 = 3.7726 loss)
I0511 10:27:48.748638  5307 sgd_solver.cpp:172] Iteration 112300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:28:51.163944  5307 solver.cpp:352] Iteration 112400 (1.60219 iter/s, 62.4144s/100 iter), 217.3/232ep, loss = 3.03614
I0511 10:28:51.166050  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.94561 (* 1 = 2.94561 loss)
I0511 10:28:51.166059  5307 sgd_solver.cpp:172] Iteration 112400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:29:52.775889  5307 solver.cpp:352] Iteration 112500 (1.62309 iter/s, 61.6109s/100 iter), 217.5/232ep, loss = 3.00284
I0511 10:29:52.775948  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.1787 (* 1 = 3.1787 loss)
I0511 10:29:52.775956  5307 sgd_solver.cpp:172] Iteration 112500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:30:53.999619  5307 solver.cpp:352] Iteration 112600 (1.63338 iter/s, 61.2226s/100 iter), 217.7/232ep, loss = 3.09079
I0511 10:30:53.999730  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.16119 (* 1 = 3.16119 loss)
I0511 10:30:53.999747  5307 sgd_solver.cpp:172] Iteration 112600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:31:55.897014  5307 solver.cpp:352] Iteration 112700 (1.61561 iter/s, 61.8963s/100 iter), 217.9/232ep, loss = 3.09488
I0511 10:31:55.899727  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.09322 (* 1 = 3.09322 loss)
I0511 10:31:55.899747  5307 sgd_solver.cpp:172] Iteration 112700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:32:17.061614  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 10:32:56.688714  5307 solver.cpp:352] Iteration 112800 (1.64499 iter/s, 60.7906s/100 iter), 218.1/232ep, loss = 2.89371
I0511 10:32:56.688843  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.51754 (* 1 = 2.51754 loss)
I0511 10:32:56.688855  5307 sgd_solver.cpp:172] Iteration 112800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:33:57.503278  5307 solver.cpp:352] Iteration 112900 (1.64437 iter/s, 60.8135s/100 iter), 218.3/232ep, loss = 3.04521
I0511 10:33:57.503353  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.81041 (* 1 = 2.81041 loss)
I0511 10:33:57.503362  5307 sgd_solver.cpp:172] Iteration 112900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:34:58.744582  5307 solver.cpp:352] Iteration 113000 (1.63291 iter/s, 61.2402s/100 iter), 218.5/232ep, loss = 3.17241
I0511 10:34:58.744669  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.21981 (* 1 = 3.21981 loss)
I0511 10:34:58.744678  5307 sgd_solver.cpp:172] Iteration 113000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:35:59.644662  5307 solver.cpp:352] Iteration 113100 (1.64206 iter/s, 60.899s/100 iter), 218.7/232ep, loss = 2.95082
I0511 10:35:59.644762  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.39512 (* 1 = 3.39512 loss)
I0511 10:35:59.644781  5307 sgd_solver.cpp:172] Iteration 113100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:37:00.493922  5307 solver.cpp:352] Iteration 113200 (1.64343 iter/s, 60.8482s/100 iter), 218.9/232ep, loss = 2.90385
I0511 10:37:00.494029  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.05948 (* 1 = 3.05948 loss)
I0511 10:37:00.494048  5307 sgd_solver.cpp:172] Iteration 113200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:37:33.207693  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 10:38:01.939122  5307 solver.cpp:352] Iteration 113300 (1.6275 iter/s, 61.4441s/100 iter), 219.1/232ep, loss = 2.96832
I0511 10:38:01.939155  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.38524 (* 1 = 3.38524 loss)
I0511 10:38:01.939164  5307 sgd_solver.cpp:172] Iteration 113300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:39:02.934594  5307 solver.cpp:352] Iteration 113400 (1.6395 iter/s, 60.9944s/100 iter), 219.2/232ep, loss = 2.95074
I0511 10:39:02.934692  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.87529 (* 1 = 2.87529 loss)
I0511 10:39:02.934710  5307 sgd_solver.cpp:172] Iteration 113400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:40:03.528507  5307 solver.cpp:352] Iteration 113500 (1.65036 iter/s, 60.5928s/100 iter), 219.4/232ep, loss = 3.19723
I0511 10:40:03.533421  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.77092 (* 1 = 2.77092 loss)
I0511 10:40:03.533440  5307 sgd_solver.cpp:172] Iteration 113500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:41:03.971828  5307 solver.cpp:352] Iteration 113600 (1.65447 iter/s, 60.4422s/100 iter), 219.6/232ep, loss = 2.86982
I0511 10:41:03.972090  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.33419 (* 1 = 3.33419 loss)
I0511 10:41:03.972113  5307 sgd_solver.cpp:172] Iteration 113600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:42:05.621686  5307 solver.cpp:352] Iteration 113700 (1.62209 iter/s, 61.6487s/100 iter), 219.8/232ep, loss = 3.13368
I0511 10:42:05.621779  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.27146 (* 1 = 2.27146 loss)
I0511 10:42:05.621790  5307 sgd_solver.cpp:172] Iteration 113700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:42:48.676345  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 10:43:06.615356  5307 solver.cpp:352] Iteration 113800 (1.63955 iter/s, 60.9925s/100 iter), 220/232ep, loss = 2.8886
I0511 10:43:06.615412  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.03967 (* 1 = 3.03967 loss)
I0511 10:43:06.615424  5307 sgd_solver.cpp:172] Iteration 113800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:44:08.389992  5307 solver.cpp:352] Iteration 113900 (1.61882 iter/s, 61.7735s/100 iter), 220.2/232ep, loss = 2.9446
I0511 10:44:08.390053  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.37132 (* 1 = 3.37132 loss)
I0511 10:44:08.390061  5307 sgd_solver.cpp:172] Iteration 113900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:45:08.962965  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_114000.caffemodel
I0511 10:45:08.976925  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_114000.solverstate
I0511 10:45:08.981122  5307 solver.cpp:635] Iteration 114000, Testing net (#0)
I0511 10:45:49.198523  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 10:45:49.415805  5307 solver.cpp:747] class AP 1: 0.662198
I0511 10:45:49.416313  5307 solver.cpp:747] class AP 2: 0.729406
I0511 10:45:49.422883  5307 solver.cpp:747] class AP 3: 0.557192
I0511 10:45:49.426580  5307 solver.cpp:747] class AP 4: 0.507719
I0511 10:45:49.445612  5307 solver.cpp:747] class AP 5: 0.345573
I0511 10:45:49.445950  5307 solver.cpp:747] class AP 6: 0.74042
I0511 10:45:49.454557  5307 solver.cpp:747] class AP 7: 0.705059
I0511 10:45:49.455088  5307 solver.cpp:747] class AP 8: 0.816973
I0511 10:45:49.473081  5307 solver.cpp:747] class AP 9: 0.431518
I0511 10:45:49.473772  5307 solver.cpp:747] class AP 10: 0.628521
I0511 10:45:49.474426  5307 solver.cpp:747] class AP 11: 0.587503
I0511 10:45:49.475253  5307 solver.cpp:747] class AP 12: 0.720823
I0511 10:45:49.475683  5307 solver.cpp:747] class AP 13: 0.790295
I0511 10:45:49.476042  5307 solver.cpp:747] class AP 14: 0.743502
I0511 10:45:49.524214  5307 solver.cpp:747] class AP 15: 0.723762
I0511 10:45:49.530274  5307 solver.cpp:747] class AP 16: 0.361899
I0511 10:45:49.532704  5307 solver.cpp:747] class AP 17: 0.596467
I0511 10:45:49.533264  5307 solver.cpp:747] class AP 18: 0.607036
I0511 10:45:49.533893  5307 solver.cpp:747] class AP 19: 0.745844
I0511 10:45:49.535290  5307 solver.cpp:747] class AP 20: 0.614507
I0511 10:45:49.535298  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.630811
I0511 10:45:49.535538  5307 solver.cpp:283] Tests completed in 101.144s
I0511 10:45:50.078846  5307 solver.cpp:352] Iteration 114000 (0.988692 iter/s, 101.144s/100 iter), 220.4/232ep, loss = 3.01824
I0511 10:45:50.078913  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.92418 (* 1 = 2.92418 loss)
I0511 10:45:50.079262  5307 sgd_solver.cpp:172] Iteration 114000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:46:51.070911  5307 solver.cpp:352] Iteration 114100 (1.63959 iter/s, 60.9909s/100 iter), 220.6/232ep, loss = 2.88598
I0511 10:46:51.071024  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.1741 (* 1 = 3.1741 loss)
I0511 10:46:51.071035  5307 sgd_solver.cpp:172] Iteration 114100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:47:52.394845  5307 solver.cpp:352] Iteration 114200 (1.63071 iter/s, 61.3228s/100 iter), 220.8/232ep, loss = 2.99809
I0511 10:47:52.394902  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.29741 (* 1 = 3.29741 loss)
I0511 10:47:52.394942  5307 sgd_solver.cpp:172] Iteration 114200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:48:46.215500  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 10:48:53.950975  5307 solver.cpp:352] Iteration 114300 (1.62456 iter/s, 61.555s/100 iter), 221/232ep, loss = 2.97063
I0511 10:48:53.951047  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.24911 (* 1 = 3.24911 loss)
I0511 10:48:53.951067  5307 sgd_solver.cpp:172] Iteration 114300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:49:54.352638  5307 solver.cpp:352] Iteration 114400 (1.65561 iter/s, 60.4006s/100 iter), 221.2/232ep, loss = 2.91539
I0511 10:49:54.353127  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.65132 (* 1 = 3.65132 loss)
I0511 10:49:54.353137  5307 sgd_solver.cpp:172] Iteration 114400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:50:55.012678  5307 solver.cpp:352] Iteration 114500 (1.64856 iter/s, 60.659s/100 iter), 221.4/232ep, loss = 2.86124
I0511 10:50:55.012753  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.58102 (* 1 = 2.58102 loss)
I0511 10:50:55.012768  5307 sgd_solver.cpp:172] Iteration 114500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:51:56.122793  5307 solver.cpp:352] Iteration 114600 (1.63642 iter/s, 61.109s/100 iter), 221.6/232ep, loss = 3.12296
I0511 10:51:56.122936  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.54923 (* 1 = 3.54923 loss)
I0511 10:51:56.122951  5307 sgd_solver.cpp:172] Iteration 114600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:52:58.023329  5307 solver.cpp:352] Iteration 114700 (1.61552 iter/s, 61.8994s/100 iter), 221.8/232ep, loss = 2.80427
I0511 10:52:58.023398  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.63464 (* 1 = 2.63464 loss)
I0511 10:52:58.023407  5307 sgd_solver.cpp:172] Iteration 114700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:53:59.532196  5307 solver.cpp:352] Iteration 114800 (1.62581 iter/s, 61.5078s/100 iter), 222/232ep, loss = 2.89953
I0511 10:53:59.532305  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.07735 (* 1 = 3.07735 loss)
I0511 10:53:59.532322  5307 sgd_solver.cpp:172] Iteration 114800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:54:02.501703  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 10:55:02.028355  5307 solver.cpp:352] Iteration 114900 (1.60013 iter/s, 62.4951s/100 iter), 222.1/232ep, loss = 2.98781
I0511 10:55:02.028434  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.15999 (* 1 = 3.15999 loss)
I0511 10:55:02.028443  5307 sgd_solver.cpp:172] Iteration 114900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:56:03.357002  5307 solver.cpp:352] Iteration 115000 (1.63059 iter/s, 61.3276s/100 iter), 222.3/232ep, loss = 3.05279
I0511 10:56:03.364600  5307 solver.cpp:376]     Train net output #0: mbox_loss = 1.97168 (* 1 = 1.97168 loss)
I0511 10:56:03.364627  5307 sgd_solver.cpp:172] Iteration 115000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:57:05.293462  5307 solver.cpp:352] Iteration 115100 (1.61459 iter/s, 61.9354s/100 iter), 222.5/232ep, loss = 2.94648
I0511 10:57:05.293543  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.89315 (* 1 = 2.89315 loss)
I0511 10:57:05.293552  5307 sgd_solver.cpp:172] Iteration 115100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:58:06.643431  5307 solver.cpp:352] Iteration 115200 (1.63002 iter/s, 61.3489s/100 iter), 222.7/232ep, loss = 2.99899
I0511 10:58:06.643540  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.02968 (* 1 = 3.02968 loss)
I0511 10:58:06.643551  5307 sgd_solver.cpp:172] Iteration 115200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:59:08.695617  5307 solver.cpp:352] Iteration 115300 (1.61158 iter/s, 62.0511s/100 iter), 222.9/232ep, loss = 3.02161
I0511 10:59:08.695713  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.39698 (* 1 = 3.39698 loss)
I0511 10:59:08.695724  5307 sgd_solver.cpp:172] Iteration 115300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 10:59:21.704402  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 11:00:09.808604  5307 solver.cpp:352] Iteration 115400 (1.63634 iter/s, 61.1119s/100 iter), 223.1/232ep, loss = 2.98201
I0511 11:00:09.808735  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.65728 (* 1 = 2.65728 loss)
I0511 11:00:09.808758  5307 sgd_solver.cpp:172] Iteration 115400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:01:10.817817  5307 solver.cpp:352] Iteration 115500 (1.63913 iter/s, 61.0081s/100 iter), 223.3/232ep, loss = 2.86876
I0511 11:01:10.817908  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.74372 (* 1 = 3.74372 loss)
I0511 11:01:10.817925  5307 sgd_solver.cpp:172] Iteration 115500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:02:12.303939  5307 solver.cpp:352] Iteration 115600 (1.62641 iter/s, 61.485s/100 iter), 223.5/232ep, loss = 2.99374
I0511 11:02:12.307034  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.66607 (* 1 = 2.66607 loss)
I0511 11:02:12.307056  5307 sgd_solver.cpp:172] Iteration 115600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:03:12.455924  5307 solver.cpp:352] Iteration 115700 (1.66249 iter/s, 60.1509s/100 iter), 223.7/232ep, loss = 3.09511
I0511 11:03:12.455989  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.1523 (* 1 = 3.1523 loss)
I0511 11:03:12.455998  5307 sgd_solver.cpp:172] Iteration 115700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:04:13.109742  5307 solver.cpp:352] Iteration 115800 (1.64873 iter/s, 60.6527s/100 iter), 223.9/232ep, loss = 2.8967
I0511 11:04:13.109834  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.7674 (* 1 = 2.7674 loss)
I0511 11:04:13.109855  5307 sgd_solver.cpp:172] Iteration 115800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:04:37.028450  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 11:05:14.281826  5307 solver.cpp:352] Iteration 115900 (1.63476 iter/s, 61.171s/100 iter), 224.1/232ep, loss = 2.95257
I0511 11:05:14.281886  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.62779 (* 1 = 2.62779 loss)
I0511 11:05:14.281895  5307 sgd_solver.cpp:172] Iteration 115900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:06:14.788892  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_116000.caffemodel
I0511 11:06:14.807366  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_116000.solverstate
I0511 11:06:14.813482  5307 solver.cpp:635] Iteration 116000, Testing net (#0)
I0511 11:06:55.290019  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 11:06:55.517653  5307 solver.cpp:747] class AP 1: 0.650297
I0511 11:06:55.518486  5307 solver.cpp:747] class AP 2: 0.731171
I0511 11:06:55.527159  5307 solver.cpp:747] class AP 3: 0.55694
I0511 11:06:55.532552  5307 solver.cpp:747] class AP 4: 0.516235
I0511 11:06:55.556718  5307 solver.cpp:747] class AP 5: 0.347945
I0511 11:06:55.557184  5307 solver.cpp:747] class AP 6: 0.737584
I0511 11:06:55.568270  5307 solver.cpp:747] class AP 7: 0.704858
I0511 11:06:55.569039  5307 solver.cpp:747] class AP 8: 0.81655
I0511 11:06:55.593116  5307 solver.cpp:747] class AP 9: 0.433403
I0511 11:06:55.593871  5307 solver.cpp:747] class AP 10: 0.627933
I0511 11:06:55.594524  5307 solver.cpp:747] class AP 11: 0.592362
I0511 11:06:55.595378  5307 solver.cpp:747] class AP 12: 0.722884
I0511 11:06:55.595813  5307 solver.cpp:747] class AP 13: 0.802147
I0511 11:06:55.596138  5307 solver.cpp:747] class AP 14: 0.744025
I0511 11:06:55.643785  5307 solver.cpp:747] class AP 15: 0.726057
I0511 11:06:55.650180  5307 solver.cpp:747] class AP 16: 0.359646
I0511 11:06:55.652637  5307 solver.cpp:747] class AP 17: 0.594529
I0511 11:06:55.653204  5307 solver.cpp:747] class AP 18: 0.609831
I0511 11:06:55.653875  5307 solver.cpp:747] class AP 19: 0.743373
I0511 11:06:55.655283  5307 solver.cpp:747] class AP 20: 0.619952
I0511 11:06:55.655295  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.631886
I0511 11:06:55.655506  5307 solver.cpp:283] Tests completed in 101.372s
I0511 11:06:56.292500  5307 solver.cpp:352] Iteration 116000 (0.986467 iter/s, 101.372s/100 iter), 224.3/232ep, loss = 3.11957
I0511 11:06:56.292546  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.71054 (* 1 = 2.71054 loss)
I0511 11:06:56.292552  5307 sgd_solver.cpp:172] Iteration 116000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:08:02.647570  5307 solver.cpp:352] Iteration 116100 (1.50707 iter/s, 66.3538s/100 iter), 224.5/232ep, loss = 3.17559
I0511 11:08:02.647683  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.4876 (* 1 = 3.4876 loss)
I0511 11:08:02.647696  5307 sgd_solver.cpp:172] Iteration 116100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:09:08.393443  5307 solver.cpp:352] Iteration 116200 (1.52104 iter/s, 65.7447s/100 iter), 224.7/232ep, loss = 2.99814
I0511 11:09:08.396077  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.22462 (* 1 = 3.22462 loss)
I0511 11:09:08.396090  5307 sgd_solver.cpp:172] Iteration 116200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:10:09.231055  5307 solver.cpp:352] Iteration 116300 (1.64375 iter/s, 60.8365s/100 iter), 224.9/232ep, loss = 3.04884
I0511 11:10:09.231128  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.9264 (* 1 = 3.9264 loss)
I0511 11:10:09.231138  5307 sgd_solver.cpp:172] Iteration 116300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:10:43.547654  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 11:11:09.930076  5307 solver.cpp:352] Iteration 116400 (1.6475 iter/s, 60.6979s/100 iter), 225/232ep, loss = 3.0008
I0511 11:11:09.930106  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.90725 (* 1 = 2.90725 loss)
I0511 11:11:09.930115  5307 sgd_solver.cpp:172] Iteration 116400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:12:09.585803  5307 solver.cpp:352] Iteration 116500 (1.67631 iter/s, 59.6547s/100 iter), 225.2/232ep, loss = 3.17016
I0511 11:12:09.585994  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.0389 (* 1 = 3.0389 loss)
I0511 11:12:09.586025  5307 sgd_solver.cpp:172] Iteration 116500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:13:10.186215  5307 solver.cpp:352] Iteration 116600 (1.65018 iter/s, 60.5993s/100 iter), 225.4/232ep, loss = 2.88852
I0511 11:13:10.186285  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.17429 (* 1 = 3.17429 loss)
I0511 11:13:10.186295  5307 sgd_solver.cpp:172] Iteration 116600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:14:09.787925  5307 solver.cpp:352] Iteration 116700 (1.67783 iter/s, 59.6007s/100 iter), 225.6/232ep, loss = 3.10487
I0511 11:14:09.788018  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.28151 (* 1 = 3.28151 loss)
I0511 11:14:09.788035  5307 sgd_solver.cpp:172] Iteration 116700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:15:11.139684  5307 solver.cpp:352] Iteration 116800 (1.62997 iter/s, 61.3507s/100 iter), 225.8/232ep, loss = 3.23564
I0511 11:15:11.139751  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.45886 (* 1 = 3.45886 loss)
I0511 11:15:11.139758  5307 sgd_solver.cpp:172] Iteration 116800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:15:55.356794  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 11:16:11.635367  5307 solver.cpp:352] Iteration 116900 (1.65304 iter/s, 60.4946s/100 iter), 226/232ep, loss = 3.05684
I0511 11:16:11.635630  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.91783 (* 1 = 2.91783 loss)
I0511 11:16:11.635658  5307 sgd_solver.cpp:172] Iteration 116900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:17:12.995401  5307 solver.cpp:352] Iteration 117000 (1.62975 iter/s, 61.359s/100 iter), 226.2/232ep, loss = 2.99461
I0511 11:17:12.995496  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.50326 (* 1 = 3.50326 loss)
I0511 11:17:12.995514  5307 sgd_solver.cpp:172] Iteration 117000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:18:13.218389  5307 solver.cpp:352] Iteration 117100 (1.66052 iter/s, 60.2219s/100 iter), 226.4/232ep, loss = 3.03247
I0511 11:18:13.218454  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.68845 (* 1 = 3.68845 loss)
I0511 11:18:13.218463  5307 sgd_solver.cpp:172] Iteration 117100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:19:13.291749  5307 solver.cpp:352] Iteration 117200 (1.66466 iter/s, 60.0723s/100 iter), 226.6/232ep, loss = 2.87023
I0511 11:19:13.291846  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.85732 (* 1 = 2.85732 loss)
I0511 11:19:13.291857  5307 sgd_solver.cpp:172] Iteration 117200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:20:13.224674  5307 solver.cpp:352] Iteration 117300 (1.66856 iter/s, 59.9319s/100 iter), 226.8/232ep, loss = 2.96887
I0511 11:20:13.225811  5307 solver.cpp:376]     Train net output #0: mbox_loss = 1.86509 (* 1 = 1.86509 loss)
I0511 11:20:13.225838  5307 sgd_solver.cpp:172] Iteration 117300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:21:08.103113  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 11:21:13.299240  5307 solver.cpp:352] Iteration 117400 (1.66463 iter/s, 60.0735s/100 iter), 227/232ep, loss = 3.09113
I0511 11:21:13.299270  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.52411 (* 1 = 2.52411 loss)
I0511 11:21:13.299278  5307 sgd_solver.cpp:172] Iteration 117400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:22:13.700301  5307 solver.cpp:352] Iteration 117500 (1.65563 iter/s, 60.4s/100 iter), 227.2/232ep, loss = 3.03423
I0511 11:22:13.700546  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.85504 (* 1 = 3.85504 loss)
I0511 11:22:13.700562  5307 sgd_solver.cpp:172] Iteration 117500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:23:14.520663  5307 solver.cpp:352] Iteration 117600 (1.64422 iter/s, 60.8193s/100 iter), 227.4/232ep, loss = 2.91665
I0511 11:23:14.520825  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.40878 (* 1 = 2.40878 loss)
I0511 11:23:14.520834  5307 sgd_solver.cpp:172] Iteration 117600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:24:15.486469  5307 solver.cpp:352] Iteration 117700 (1.64029 iter/s, 60.9647s/100 iter), 227.6/232ep, loss = 3.19194
I0511 11:24:15.486999  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.24722 (* 1 = 3.24722 loss)
I0511 11:24:15.487007  5307 sgd_solver.cpp:172] Iteration 117700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:25:16.517316  5307 solver.cpp:352] Iteration 117800 (1.63855 iter/s, 61.0297s/100 iter), 227.8/232ep, loss = 2.87382
I0511 11:25:16.517437  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.81489 (* 1 = 2.81489 loss)
I0511 11:25:16.517447  5307 sgd_solver.cpp:172] Iteration 117800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:26:16.765038  5307 solver.cpp:352] Iteration 117900 (1.65984 iter/s, 60.2466s/100 iter), 227.9/232ep, loss = 2.99439
I0511 11:26:16.765139  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.282 (* 1 = 2.282 loss)
I0511 11:26:16.765159  5307 sgd_solver.cpp:172] Iteration 117900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:26:21.159152  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 11:27:17.238680  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_118000.caffemodel
I0511 11:27:17.257541  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_118000.solverstate
I0511 11:27:17.263979  5307 solver.cpp:635] Iteration 118000, Testing net (#0)
I0511 11:27:57.641331  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 11:27:57.861429  5307 solver.cpp:747] class AP 1: 0.654472
I0511 11:27:57.861944  5307 solver.cpp:747] class AP 2: 0.731609
I0511 11:27:57.868554  5307 solver.cpp:747] class AP 3: 0.557668
I0511 11:27:57.872315  5307 solver.cpp:747] class AP 4: 0.517042
I0511 11:27:57.891069  5307 solver.cpp:747] class AP 5: 0.345227
I0511 11:27:57.891412  5307 solver.cpp:747] class AP 6: 0.738804
I0511 11:27:57.900190  5307 solver.cpp:747] class AP 7: 0.703705
I0511 11:27:57.900959  5307 solver.cpp:747] class AP 8: 0.817978
I0511 11:27:57.920097  5307 solver.cpp:747] class AP 9: 0.430764
I0511 11:27:57.920806  5307 solver.cpp:747] class AP 10: 0.635427
I0511 11:27:57.921437  5307 solver.cpp:747] class AP 11: 0.594552
I0511 11:27:57.922281  5307 solver.cpp:747] class AP 12: 0.719994
I0511 11:27:57.922788  5307 solver.cpp:747] class AP 13: 0.788424
I0511 11:27:57.923264  5307 solver.cpp:747] class AP 14: 0.745163
I0511 11:27:57.972834  5307 solver.cpp:747] class AP 15: 0.725318
I0511 11:27:57.979189  5307 solver.cpp:747] class AP 16: 0.368298
I0511 11:27:57.981844  5307 solver.cpp:747] class AP 17: 0.596233
I0511 11:27:57.982441  5307 solver.cpp:747] class AP 18: 0.610433
I0511 11:27:57.983145  5307 solver.cpp:747] class AP 19: 0.751794
I0511 11:27:57.984674  5307 solver.cpp:747] class AP 20: 0.617365
I0511 11:27:57.984683  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.632513
I0511 11:27:57.984807  5307 solver.cpp:283] Tests completed in 101.218s
I0511 11:27:58.641021  5307 solver.cpp:352] Iteration 118000 (0.987967 iter/s, 101.218s/100 iter), 228.1/232ep, loss = 2.9497
I0511 11:27:58.641055  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.12983 (* 1 = 3.12983 loss)
I0511 11:27:58.641063  5307 sgd_solver.cpp:172] Iteration 118000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:28:58.839681  5307 solver.cpp:352] Iteration 118100 (1.6612 iter/s, 60.1975s/100 iter), 228.3/232ep, loss = 3.24715
I0511 11:28:58.839756  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.65285 (* 1 = 3.65285 loss)
I0511 11:28:58.839774  5307 sgd_solver.cpp:172] Iteration 118100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:30:00.189913  5307 solver.cpp:352] Iteration 118200 (1.63002 iter/s, 61.3491s/100 iter), 228.5/232ep, loss = 2.8064
I0511 11:30:00.191293  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.91214 (* 1 = 2.91214 loss)
I0511 11:30:00.191314  5307 sgd_solver.cpp:172] Iteration 118200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:31:00.269927  5307 solver.cpp:352] Iteration 118300 (1.66448 iter/s, 60.0789s/100 iter), 228.7/232ep, loss = 3.06632
I0511 11:31:00.270061  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.44544 (* 1 = 3.44544 loss)
I0511 11:31:00.270086  5307 sgd_solver.cpp:172] Iteration 118300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:32:01.229151  5307 solver.cpp:352] Iteration 118400 (1.64047 iter/s, 60.9581s/100 iter), 228.9/232ep, loss = 2.92896
I0511 11:32:01.229290  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.68048 (* 1 = 3.68048 loss)
I0511 11:32:01.229305  5307 sgd_solver.cpp:172] Iteration 118400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:32:16.214731  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 11:33:01.567019  5307 solver.cpp:352] Iteration 118500 (1.65736 iter/s, 60.3368s/100 iter), 229.1/232ep, loss = 3.13304
I0511 11:33:01.567117  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.15197 (* 1 = 3.15197 loss)
I0511 11:33:01.567138  5307 sgd_solver.cpp:172] Iteration 118500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:34:01.775032  5307 solver.cpp:352] Iteration 118600 (1.66094 iter/s, 60.207s/100 iter), 229.3/232ep, loss = 3.0296
I0511 11:34:01.775141  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.71965 (* 1 = 2.71965 loss)
I0511 11:34:01.775158  5307 sgd_solver.cpp:172] Iteration 118600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:35:02.408643  5307 solver.cpp:352] Iteration 118700 (1.64928 iter/s, 60.6325s/100 iter), 229.5/232ep, loss = 2.91601
I0511 11:35:02.408749  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.7621 (* 1 = 2.7621 loss)
I0511 11:35:02.408767  5307 sgd_solver.cpp:172] Iteration 118700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:36:03.211777  5307 solver.cpp:352] Iteration 118800 (1.64468 iter/s, 60.8021s/100 iter), 229.7/232ep, loss = 3.03007
I0511 11:36:03.211851  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.71402 (* 1 = 3.71402 loss)
I0511 11:36:03.211863  5307 sgd_solver.cpp:172] Iteration 118800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:37:03.776070  5307 solver.cpp:352] Iteration 118900 (1.65117 iter/s, 60.5632s/100 iter), 229.9/232ep, loss = 2.9015
I0511 11:37:03.776235  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.77313 (* 1 = 2.77313 loss)
I0511 11:37:03.776248  5307 sgd_solver.cpp:172] Iteration 118900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:37:29.550253  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 11:38:03.689391  5307 solver.cpp:352] Iteration 119000 (1.66911 iter/s, 59.9123s/100 iter), 230.1/232ep, loss = 2.88679
I0511 11:38:03.689962  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.22293 (* 1 = 3.22293 loss)
I0511 11:38:03.690055  5307 sgd_solver.cpp:172] Iteration 119000, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:39:03.612455  5307 solver.cpp:352] Iteration 119100 (1.66884 iter/s, 59.922s/100 iter), 230.3/232ep, loss = 3.19493
I0511 11:39:03.612581  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.60366 (* 1 = 2.60366 loss)
I0511 11:39:03.612608  5307 sgd_solver.cpp:172] Iteration 119100, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:40:04.584720  5307 solver.cpp:352] Iteration 119200 (1.64012 iter/s, 60.9712s/100 iter), 230.5/232ep, loss = 3.04357
I0511 11:40:04.584801  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.52593 (* 1 = 3.52593 loss)
I0511 11:40:04.584810  5307 sgd_solver.cpp:172] Iteration 119200, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:41:06.064980  5307 solver.cpp:352] Iteration 119300 (1.62657 iter/s, 61.4792s/100 iter), 230.7/232ep, loss = 2.91227
I0511 11:41:06.065052  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.61844 (* 1 = 2.61844 loss)
I0511 11:41:06.065062  5307 sgd_solver.cpp:172] Iteration 119300, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:42:06.932260  5307 solver.cpp:352] Iteration 119400 (1.64295 iter/s, 60.8662s/100 iter), 230.9/232ep, loss = 3.17262
I0511 11:42:06.932314  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.95531 (* 1 = 2.95531 loss)
I0511 11:42:06.932320  5307 sgd_solver.cpp:172] Iteration 119400, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:42:42.828730  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 11:43:07.304044  5307 solver.cpp:352] Iteration 119500 (1.65643 iter/s, 60.3707s/100 iter), 231/232ep, loss = 2.80561
I0511 11:43:07.304111  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.30471 (* 1 = 3.30471 loss)
I0511 11:43:07.304133  5307 sgd_solver.cpp:172] Iteration 119500, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:44:08.021536  5307 solver.cpp:352] Iteration 119600 (1.647 iter/s, 60.7164s/100 iter), 231.2/232ep, loss = 2.93156
I0511 11:44:08.021646  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.35993 (* 1 = 2.35993 loss)
I0511 11:44:08.021667  5307 sgd_solver.cpp:172] Iteration 119600, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:45:08.781613  5307 solver.cpp:352] Iteration 119700 (1.64585 iter/s, 60.759s/100 iter), 231.4/232ep, loss = 3.03697
I0511 11:45:08.781715  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.44033 (* 1 = 3.44033 loss)
I0511 11:45:08.781733  5307 sgd_solver.cpp:172] Iteration 119700, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:46:10.104699  5307 solver.cpp:352] Iteration 119800 (1.63074 iter/s, 61.322s/100 iter), 231.6/232ep, loss = 3.10778
I0511 11:46:10.104800  5307 solver.cpp:376]     Train net output #0: mbox_loss = 2.60798 (* 1 = 2.60798 loss)
I0511 11:46:10.104815  5307 sgd_solver.cpp:172] Iteration 119800, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:47:10.143796  5307 solver.cpp:352] Iteration 119900 (1.66561 iter/s, 60.038s/100 iter), 231.8/232ep, loss = 2.83629
I0511 11:47:10.143863  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.14731 (* 1 = 3.14731 loss)
I0511 11:47:10.143874  5307 sgd_solver.cpp:172] Iteration 119900, lr = 0.0001, m = 0.9, wd = 0.0001, gs = 1
I0511 11:47:56.251756  5323 data_reader.cpp:320] Restarting data pre-fetching
I0511 11:48:09.220212  5307 solver.cpp:352] Iteration 119999 (1.67583 iter/s, 59.0753s/99 iter), 232/232ep, loss = 3.15551
I0511 11:48:09.220237  5307 solver.cpp:376]     Train net output #0: mbox_loss = 3.67871 (* 1 = 3.67871 loss)
I0511 11:48:09.220245  5307 solver.cpp:905] Snapshotting to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_120000.caffemodel
I0511 11:48:09.232520  5307 sgd_solver.cpp:398] Snapshotting solver state to binary proto file training/voc0712/mobiledetnet-0.5/20180510_14-48_ds_PSP_dsFac_32_hdDS8_1/initial/voc0712_mobiledetnet-0.5_iter_120000.solverstate
I0511 11:48:09.280829  5307 solver.cpp:501] Iteration 120000, loss = 3.15029
I0511 11:48:09.280858  5307 solver.cpp:635] Iteration 120000, Testing net (#0)
I0511 11:48:49.480348  5353 data_reader.cpp:320] Restarting data pre-fetching
I0511 11:48:49.715391  5307 solver.cpp:747] class AP 1: 0.651863
I0511 11:48:49.715903  5307 solver.cpp:747] class AP 2: 0.731042
I0511 11:48:49.722532  5307 solver.cpp:747] class AP 3: 0.56037
I0511 11:48:49.726208  5307 solver.cpp:747] class AP 4: 0.508346
I0511 11:48:49.744891  5307 solver.cpp:747] class AP 5: 0.337747
I0511 11:48:49.745234  5307 solver.cpp:747] class AP 6: 0.737946
I0511 11:48:49.753764  5307 solver.cpp:747] class AP 7: 0.703266
I0511 11:48:49.754317  5307 solver.cpp:747] class AP 8: 0.816119
I0511 11:48:49.772083  5307 solver.cpp:747] class AP 9: 0.429319
I0511 11:48:49.772775  5307 solver.cpp:747] class AP 10: 0.63832
I0511 11:48:49.773403  5307 solver.cpp:747] class AP 11: 0.596956
I0511 11:48:49.774240  5307 solver.cpp:747] class AP 12: 0.725066
I0511 11:48:49.774662  5307 solver.cpp:747] class AP 13: 0.799125
I0511 11:48:49.775009  5307 solver.cpp:747] class AP 14: 0.745774
I0511 11:48:49.823776  5307 solver.cpp:747] class AP 15: 0.727146
I0511 11:48:49.830077  5307 solver.cpp:747] class AP 16: 0.366462
I0511 11:48:49.832449  5307 solver.cpp:747] class AP 17: 0.600338
I0511 11:48:49.833067  5307 solver.cpp:747] class AP 18: 0.609607
I0511 11:48:49.833757  5307 solver.cpp:747] class AP 19: 0.750236
I0511 11:48:49.835151  5307 solver.cpp:747] class AP 20: 0.617223
I0511 11:48:49.835160  5307 solver.cpp:753] Test net output mAP #0: detection_eval = 0.632614
I0511 11:48:49.835372  5307 caffe.cpp:268] Solver performance on device 0: 1.589 * 16 = 50.85 img/sec (120000 itr in 7.551e+04 sec)
I0511 11:48:49.835388  5307 caffe.cpp:271] Optimization Done in 21h 0m 20s
