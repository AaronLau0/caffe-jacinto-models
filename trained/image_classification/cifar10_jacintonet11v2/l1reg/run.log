I0801 13:29:13.756988  3122 caffe.cpp:608] This is NVCaffe 0.16.3 started at Tue Aug  1 13:29:13 2017
I0801 13:29:13.757109  3122 caffe.cpp:611] CuDNN version: 6021
I0801 13:29:13.757114  3122 caffe.cpp:612] CuBLAS version: 8000
I0801 13:29:13.757117  3122 caffe.cpp:613] CUDA version: 8000
I0801 13:29:13.757120  3122 caffe.cpp:614] CUDA driver version: 8000
I0801 13:29:14.010447  3122 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0801 13:29:14.011023  3122 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8278441984, dev_info[0]: total=8506769408 free=8278441984
I0801 13:29:14.011545  3122 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8278441984, dev_info[1]: total=8508145664 free=8379236352
I0801 13:29:14.012064  3122 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8278441984, dev_info[2]: total=8508145664 free=8379236352
I0801 13:29:14.012074  3122 caffe.cpp:208] Using GPUs 0, 1, 2
I0801 13:29:14.012399  3122 caffe.cpp:213] GPU 0: GeForce GTX 1080
I0801 13:29:14.012737  3122 caffe.cpp:213] GPU 1: GeForce GTX 1080
I0801 13:29:14.013077  3122 caffe.cpp:213] GPU 2: GeForce GTX 1080
I0801 13:29:14.013119  3122 solver.cpp:42] Solver data type: FLOAT
I0801 13:29:14.013149  3122 solver.cpp:45] Initializing solver from parameters: 
train_net: "training/cifar10_jacintonet11v2_2017-08-01_13-11-28/l1reg/train.prototxt"
test_net: "training/cifar10_jacintonet11v2_2017-08-01_13-11-28/l1reg/test.prototxt"
test_iter: 200
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 64000
lr_policy: "poly"
gamma: 0.1
power: 1
momentum: 0.9
weight_decay: 1e-05
snapshot: 10000
snapshot_prefix: "training/cifar10_jacintonet11v2_2017-08-01_13-11-28/l1reg/cifar10_jacintonet11v2"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
snapshot_after_train: true
regularization_type: "L1"
test_initialization: true
iter_size: 1
type: "SGD"
I0801 13:29:14.019997  3122 solver.cpp:77] Creating training net from train_net file: training/cifar10_jacintonet11v2_2017-08-01_13-11-28/l1reg/train.prototxt
I0801 13:29:14.020421  3122 net.cpp:443] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top1
I0801 13:29:14.020426  3122 net.cpp:443] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top5
W0801 13:29:14.020450  3122 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 64 to 66
I0801 13:29:14.020635  3122 net.cpp:72] Initializing net from parameters: 
name: "jacintonet11v2_train"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: true
    crop_size: 32
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/cifar10_train_lmdb"
    batch_size: 22
    backend: LMDB
    threads: 1
    parser_threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc10"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc10"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
I0801 13:29:14.020740  3122 net.cpp:104] Using FLOAT as default forward math type
I0801 13:29:14.020743  3122 net.cpp:110] Using FLOAT as default backward math type
I0801 13:29:14.020748  3122 layer_factory.hpp:136] Creating layer 'data' of type 'Data'
I0801 13:29:14.020751  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.020797  3122 net.cpp:184] Created Layer data (0)
I0801 13:29:14.020802  3122 net.cpp:530] data -> data
I0801 13:29:14.020812  3122 net.cpp:530] data -> label
I0801 13:29:14.020841  3122 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 22
I0801 13:29:14.020861  3122 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0801 13:29:14.022356  3155 db_lmdb.cpp:35] Opened lmdb ./data/cifar10_train_lmdb
I0801 13:29:14.023387  3122 data_layer.cpp:184] [0] ReshapePrefetch 22, 3, 32, 32
I0801 13:29:14.023450  3122 data_layer.cpp:208] [0] Output data size: 22, 3, 32, 32
I0801 13:29:14.023455  3122 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0801 13:29:14.023473  3122 net.cpp:245] Setting up data
I0801 13:29:14.023479  3122 net.cpp:252] TRAIN Top shape for layer 0 'data' 22 3 32 32 (67584)
I0801 13:29:14.023484  3122 net.cpp:252] TRAIN Top shape for layer 0 'data' 22 (22)
I0801 13:29:14.023489  3122 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0801 13:29:14.023494  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.023505  3122 net.cpp:184] Created Layer data/bias (1)
I0801 13:29:14.023510  3122 net.cpp:561] data/bias <- data
I0801 13:29:14.023516  3122 net.cpp:530] data/bias -> data/bias
I0801 13:29:14.025501  3122 net.cpp:245] Setting up data/bias
I0801 13:29:14.025511  3122 net.cpp:252] TRAIN Top shape for layer 1 'data/bias' 22 3 32 32 (67584)
I0801 13:29:14.025521  3122 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0801 13:29:14.025527  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.025540  3122 net.cpp:184] Created Layer conv1a (2)
I0801 13:29:14.025544  3122 net.cpp:561] conv1a <- data/bias
I0801 13:29:14.025549  3122 net.cpp:530] conv1a -> conv1a
I0801 13:29:14.343989  3122 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.01G/1 1 0 3  (limit 8.15G, req 0G)
I0801 13:29:14.344012  3122 net.cpp:245] Setting up conv1a
I0801 13:29:14.344019  3122 net.cpp:252] TRAIN Top shape for layer 2 'conv1a' 22 32 32 32 (720896)
I0801 13:29:14.344033  3122 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0801 13:29:14.344038  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.344051  3122 net.cpp:184] Created Layer conv1a/bn (3)
I0801 13:29:14.344055  3122 net.cpp:561] conv1a/bn <- conv1a
I0801 13:29:14.344061  3122 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0801 13:29:14.344754  3122 net.cpp:245] Setting up conv1a/bn
I0801 13:29:14.344763  3122 net.cpp:252] TRAIN Top shape for layer 3 'conv1a/bn' 22 32 32 32 (720896)
I0801 13:29:14.344779  3122 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0801 13:29:14.344782  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.344790  3122 net.cpp:184] Created Layer conv1a/relu (4)
I0801 13:29:14.344794  3122 net.cpp:561] conv1a/relu <- conv1a
I0801 13:29:14.344799  3122 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0801 13:29:14.344813  3122 net.cpp:245] Setting up conv1a/relu
I0801 13:29:14.344830  3122 net.cpp:252] TRAIN Top shape for layer 4 'conv1a/relu' 22 32 32 32 (720896)
I0801 13:29:14.344832  3122 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0801 13:29:14.344835  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.344842  3122 net.cpp:184] Created Layer conv1b (5)
I0801 13:29:14.344844  3122 net.cpp:561] conv1b <- conv1a
I0801 13:29:14.344846  3122 net.cpp:530] conv1b -> conv1b
I0801 13:29:14.352490  3122 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 8.13G, req 0G)
I0801 13:29:14.352502  3122 net.cpp:245] Setting up conv1b
I0801 13:29:14.352506  3122 net.cpp:252] TRAIN Top shape for layer 5 'conv1b' 22 32 32 32 (720896)
I0801 13:29:14.352511  3122 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0801 13:29:14.352514  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.352519  3122 net.cpp:184] Created Layer conv1b/bn (6)
I0801 13:29:14.352522  3122 net.cpp:561] conv1b/bn <- conv1b
I0801 13:29:14.352535  3122 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0801 13:29:14.353173  3122 net.cpp:245] Setting up conv1b/bn
I0801 13:29:14.353181  3122 net.cpp:252] TRAIN Top shape for layer 6 'conv1b/bn' 22 32 32 32 (720896)
I0801 13:29:14.353188  3122 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0801 13:29:14.353189  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.353193  3122 net.cpp:184] Created Layer conv1b/relu (7)
I0801 13:29:14.353195  3122 net.cpp:561] conv1b/relu <- conv1b
I0801 13:29:14.353199  3122 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0801 13:29:14.353201  3122 net.cpp:245] Setting up conv1b/relu
I0801 13:29:14.353204  3122 net.cpp:252] TRAIN Top shape for layer 7 'conv1b/relu' 22 32 32 32 (720896)
I0801 13:29:14.353205  3122 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0801 13:29:14.353207  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.353212  3122 net.cpp:184] Created Layer pool1 (8)
I0801 13:29:14.353214  3122 net.cpp:561] pool1 <- conv1b
I0801 13:29:14.353216  3122 net.cpp:530] pool1 -> pool1
I0801 13:29:14.353298  3122 net.cpp:245] Setting up pool1
I0801 13:29:14.353305  3122 net.cpp:252] TRAIN Top shape for layer 8 'pool1' 22 32 32 32 (720896)
I0801 13:29:14.353310  3122 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0801 13:29:14.353312  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.353322  3122 net.cpp:184] Created Layer res2a_branch2a (9)
I0801 13:29:14.353325  3122 net.cpp:561] res2a_branch2a <- pool1
I0801 13:29:14.353327  3122 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0801 13:29:14.364796  3122 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 1  (limit 8.11G, req 0G)
I0801 13:29:14.364809  3122 net.cpp:245] Setting up res2a_branch2a
I0801 13:29:14.364820  3122 net.cpp:252] TRAIN Top shape for layer 9 'res2a_branch2a' 22 64 32 32 (1441792)
I0801 13:29:14.364830  3122 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0801 13:29:14.364833  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.364837  3122 net.cpp:184] Created Layer res2a_branch2a/bn (10)
I0801 13:29:14.364840  3122 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0801 13:29:14.364842  3122 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0801 13:29:14.365476  3122 net.cpp:245] Setting up res2a_branch2a/bn
I0801 13:29:14.365484  3122 net.cpp:252] TRAIN Top shape for layer 10 'res2a_branch2a/bn' 22 64 32 32 (1441792)
I0801 13:29:14.365490  3122 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0801 13:29:14.365492  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.365496  3122 net.cpp:184] Created Layer res2a_branch2a/relu (11)
I0801 13:29:14.365499  3122 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0801 13:29:14.365501  3122 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0801 13:29:14.365504  3122 net.cpp:245] Setting up res2a_branch2a/relu
I0801 13:29:14.365506  3122 net.cpp:252] TRAIN Top shape for layer 11 'res2a_branch2a/relu' 22 64 32 32 (1441792)
I0801 13:29:14.365509  3122 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0801 13:29:14.365511  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.365517  3122 net.cpp:184] Created Layer res2a_branch2b (12)
I0801 13:29:14.365520  3122 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0801 13:29:14.365523  3122 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0801 13:29:14.373082  3122 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 8.1G, req 0G)
I0801 13:29:14.373102  3122 net.cpp:245] Setting up res2a_branch2b
I0801 13:29:14.373126  3122 net.cpp:252] TRAIN Top shape for layer 12 'res2a_branch2b' 22 64 32 32 (1441792)
I0801 13:29:14.373136  3122 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0801 13:29:14.373143  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.373157  3122 net.cpp:184] Created Layer res2a_branch2b/bn (13)
I0801 13:29:14.373162  3122 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0801 13:29:14.373165  3122 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0801 13:29:14.373837  3122 net.cpp:245] Setting up res2a_branch2b/bn
I0801 13:29:14.373845  3122 net.cpp:252] TRAIN Top shape for layer 13 'res2a_branch2b/bn' 22 64 32 32 (1441792)
I0801 13:29:14.373855  3122 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0801 13:29:14.373862  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.373867  3122 net.cpp:184] Created Layer res2a_branch2b/relu (14)
I0801 13:29:14.373872  3122 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0801 13:29:14.373878  3122 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0801 13:29:14.373884  3122 net.cpp:245] Setting up res2a_branch2b/relu
I0801 13:29:14.373889  3122 net.cpp:252] TRAIN Top shape for layer 14 'res2a_branch2b/relu' 22 64 32 32 (1441792)
I0801 13:29:14.373894  3122 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0801 13:29:14.373898  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.373908  3122 net.cpp:184] Created Layer pool2 (15)
I0801 13:29:14.373913  3122 net.cpp:561] pool2 <- res2a_branch2b
I0801 13:29:14.373916  3122 net.cpp:530] pool2 -> pool2
I0801 13:29:14.373983  3122 net.cpp:245] Setting up pool2
I0801 13:29:14.373989  3122 net.cpp:252] TRAIN Top shape for layer 15 'pool2' 22 64 16 16 (360448)
I0801 13:29:14.373993  3122 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0801 13:29:14.373998  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.374011  3122 net.cpp:184] Created Layer res3a_branch2a (16)
I0801 13:29:14.374014  3122 net.cpp:561] res3a_branch2a <- pool2
I0801 13:29:14.374017  3122 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0801 13:29:14.385411  3122 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 3  (limit 8.09G, req 0G)
I0801 13:29:14.385426  3122 net.cpp:245] Setting up res3a_branch2a
I0801 13:29:14.385432  3122 net.cpp:252] TRAIN Top shape for layer 16 'res3a_branch2a' 22 128 16 16 (720896)
I0801 13:29:14.385442  3122 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0801 13:29:14.385447  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.385457  3122 net.cpp:184] Created Layer res3a_branch2a/bn (17)
I0801 13:29:14.385462  3122 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0801 13:29:14.385464  3122 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0801 13:29:14.386086  3122 net.cpp:245] Setting up res3a_branch2a/bn
I0801 13:29:14.386095  3122 net.cpp:252] TRAIN Top shape for layer 17 'res3a_branch2a/bn' 22 128 16 16 (720896)
I0801 13:29:14.386106  3122 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0801 13:29:14.386111  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.386117  3122 net.cpp:184] Created Layer res3a_branch2a/relu (18)
I0801 13:29:14.386121  3122 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0801 13:29:14.386127  3122 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0801 13:29:14.386133  3122 net.cpp:245] Setting up res3a_branch2a/relu
I0801 13:29:14.386139  3122 net.cpp:252] TRAIN Top shape for layer 18 'res3a_branch2a/relu' 22 128 16 16 (720896)
I0801 13:29:14.386143  3122 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0801 13:29:14.386157  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.386168  3122 net.cpp:184] Created Layer res3a_branch2b (19)
I0801 13:29:14.386173  3122 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0801 13:29:14.386175  3122 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0801 13:29:14.390890  3122 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 8.08G, req 0G)
I0801 13:29:14.390902  3122 net.cpp:245] Setting up res3a_branch2b
I0801 13:29:14.390908  3122 net.cpp:252] TRAIN Top shape for layer 19 'res3a_branch2b' 22 128 16 16 (720896)
I0801 13:29:14.390915  3122 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0801 13:29:14.390921  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.390928  3122 net.cpp:184] Created Layer res3a_branch2b/bn (20)
I0801 13:29:14.390933  3122 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0801 13:29:14.390938  3122 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0801 13:29:14.391541  3122 net.cpp:245] Setting up res3a_branch2b/bn
I0801 13:29:14.391548  3122 net.cpp:252] TRAIN Top shape for layer 20 'res3a_branch2b/bn' 22 128 16 16 (720896)
I0801 13:29:14.391557  3122 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0801 13:29:14.391562  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.391567  3122 net.cpp:184] Created Layer res3a_branch2b/relu (21)
I0801 13:29:14.391571  3122 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0801 13:29:14.391577  3122 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0801 13:29:14.391583  3122 net.cpp:245] Setting up res3a_branch2b/relu
I0801 13:29:14.391588  3122 net.cpp:252] TRAIN Top shape for layer 21 'res3a_branch2b/relu' 22 128 16 16 (720896)
I0801 13:29:14.391593  3122 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0801 13:29:14.391597  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.391604  3122 net.cpp:184] Created Layer pool3 (22)
I0801 13:29:14.391609  3122 net.cpp:561] pool3 <- res3a_branch2b
I0801 13:29:14.391614  3122 net.cpp:530] pool3 -> pool3
I0801 13:29:14.391680  3122 net.cpp:245] Setting up pool3
I0801 13:29:14.391685  3122 net.cpp:252] TRAIN Top shape for layer 22 'pool3' 22 128 16 16 (720896)
I0801 13:29:14.391690  3122 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0801 13:29:14.391695  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.391703  3122 net.cpp:184] Created Layer res4a_branch2a (23)
I0801 13:29:14.391707  3122 net.cpp:561] res4a_branch2a <- pool3
I0801 13:29:14.391711  3122 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0801 13:29:14.410507  3122 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 8.05G, req 0G)
I0801 13:29:14.410531  3122 net.cpp:245] Setting up res4a_branch2a
I0801 13:29:14.410538  3122 net.cpp:252] TRAIN Top shape for layer 23 'res4a_branch2a' 22 256 16 16 (1441792)
I0801 13:29:14.410547  3122 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0801 13:29:14.410552  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.410568  3122 net.cpp:184] Created Layer res4a_branch2a/bn (24)
I0801 13:29:14.410573  3122 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0801 13:29:14.410581  3122 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0801 13:29:14.411303  3122 net.cpp:245] Setting up res4a_branch2a/bn
I0801 13:29:14.411311  3122 net.cpp:252] TRAIN Top shape for layer 24 'res4a_branch2a/bn' 22 256 16 16 (1441792)
I0801 13:29:14.411317  3122 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0801 13:29:14.411331  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.411335  3122 net.cpp:184] Created Layer res4a_branch2a/relu (25)
I0801 13:29:14.411339  3122 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0801 13:29:14.411341  3122 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0801 13:29:14.411346  3122 net.cpp:245] Setting up res4a_branch2a/relu
I0801 13:29:14.411352  3122 net.cpp:252] TRAIN Top shape for layer 25 'res4a_branch2a/relu' 22 256 16 16 (1441792)
I0801 13:29:14.411357  3122 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0801 13:29:14.411360  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.411370  3122 net.cpp:184] Created Layer res4a_branch2b (26)
I0801 13:29:14.411373  3122 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0801 13:29:14.411375  3122 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0801 13:29:14.420203  3122 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 8.04G, req 0G)
I0801 13:29:14.420214  3122 net.cpp:245] Setting up res4a_branch2b
I0801 13:29:14.420219  3122 net.cpp:252] TRAIN Top shape for layer 26 'res4a_branch2b' 22 256 16 16 (1441792)
I0801 13:29:14.420223  3122 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0801 13:29:14.420227  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.420230  3122 net.cpp:184] Created Layer res4a_branch2b/bn (27)
I0801 13:29:14.420233  3122 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0801 13:29:14.420235  3122 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0801 13:29:14.420864  3122 net.cpp:245] Setting up res4a_branch2b/bn
I0801 13:29:14.420872  3122 net.cpp:252] TRAIN Top shape for layer 27 'res4a_branch2b/bn' 22 256 16 16 (1441792)
I0801 13:29:14.420878  3122 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0801 13:29:14.420881  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.420884  3122 net.cpp:184] Created Layer res4a_branch2b/relu (28)
I0801 13:29:14.420886  3122 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0801 13:29:14.420888  3122 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0801 13:29:14.420892  3122 net.cpp:245] Setting up res4a_branch2b/relu
I0801 13:29:14.420894  3122 net.cpp:252] TRAIN Top shape for layer 28 'res4a_branch2b/relu' 22 256 16 16 (1441792)
I0801 13:29:14.420897  3122 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0801 13:29:14.420898  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.420905  3122 net.cpp:184] Created Layer pool4 (29)
I0801 13:29:14.420909  3122 net.cpp:561] pool4 <- res4a_branch2b
I0801 13:29:14.420913  3122 net.cpp:530] pool4 -> pool4
I0801 13:29:14.420981  3122 net.cpp:245] Setting up pool4
I0801 13:29:14.420986  3122 net.cpp:252] TRAIN Top shape for layer 29 'pool4' 22 256 8 8 (360448)
I0801 13:29:14.420989  3122 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0801 13:29:14.420991  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.420997  3122 net.cpp:184] Created Layer res5a_branch2a (30)
I0801 13:29:14.421000  3122 net.cpp:561] res5a_branch2a <- pool4
I0801 13:29:14.421002  3122 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0801 13:29:14.464953  3122 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 1  (limit 8.02G, req 0.01G)
I0801 13:29:14.464972  3122 net.cpp:245] Setting up res5a_branch2a
I0801 13:29:14.464977  3122 net.cpp:252] TRAIN Top shape for layer 30 'res5a_branch2a' 22 512 8 8 (720896)
I0801 13:29:14.464983  3122 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0801 13:29:14.464987  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.465013  3122 net.cpp:184] Created Layer res5a_branch2a/bn (31)
I0801 13:29:14.465018  3122 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0801 13:29:14.465023  3122 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0801 13:29:14.465677  3122 net.cpp:245] Setting up res5a_branch2a/bn
I0801 13:29:14.465684  3122 net.cpp:252] TRAIN Top shape for layer 31 'res5a_branch2a/bn' 22 512 8 8 (720896)
I0801 13:29:14.465689  3122 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0801 13:29:14.465692  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.465697  3122 net.cpp:184] Created Layer res5a_branch2a/relu (32)
I0801 13:29:14.465698  3122 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0801 13:29:14.465701  3122 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0801 13:29:14.465704  3122 net.cpp:245] Setting up res5a_branch2a/relu
I0801 13:29:14.465708  3122 net.cpp:252] TRAIN Top shape for layer 32 'res5a_branch2a/relu' 22 512 8 8 (720896)
I0801 13:29:14.465709  3122 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0801 13:29:14.465711  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.465721  3122 net.cpp:184] Created Layer res5a_branch2b (33)
I0801 13:29:14.465726  3122 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0801 13:29:14.465730  3122 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0801 13:29:14.485797  3122 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 7 4 3  (limit 8G, req 0.01G)
I0801 13:29:14.485812  3122 net.cpp:245] Setting up res5a_branch2b
I0801 13:29:14.485821  3122 net.cpp:252] TRAIN Top shape for layer 33 'res5a_branch2b' 22 512 8 8 (720896)
I0801 13:29:14.485831  3122 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0801 13:29:14.485837  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.485846  3122 net.cpp:184] Created Layer res5a_branch2b/bn (34)
I0801 13:29:14.485848  3122 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0801 13:29:14.485851  3122 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0801 13:29:14.486500  3122 net.cpp:245] Setting up res5a_branch2b/bn
I0801 13:29:14.486508  3122 net.cpp:252] TRAIN Top shape for layer 34 'res5a_branch2b/bn' 22 512 8 8 (720896)
I0801 13:29:14.486517  3122 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0801 13:29:14.486523  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.486529  3122 net.cpp:184] Created Layer res5a_branch2b/relu (35)
I0801 13:29:14.486534  3122 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0801 13:29:14.486539  3122 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0801 13:29:14.486546  3122 net.cpp:245] Setting up res5a_branch2b/relu
I0801 13:29:14.486551  3122 net.cpp:252] TRAIN Top shape for layer 35 'res5a_branch2b/relu' 22 512 8 8 (720896)
I0801 13:29:14.486555  3122 layer_factory.hpp:136] Creating layer 'pool5' of type 'Pooling'
I0801 13:29:14.486560  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.486567  3122 net.cpp:184] Created Layer pool5 (36)
I0801 13:29:14.486572  3122 net.cpp:561] pool5 <- res5a_branch2b
I0801 13:29:14.486577  3122 net.cpp:530] pool5 -> pool5
I0801 13:29:14.486608  3122 net.cpp:245] Setting up pool5
I0801 13:29:14.486613  3122 net.cpp:252] TRAIN Top shape for layer 36 'pool5' 22 512 1 1 (11264)
I0801 13:29:14.486616  3122 layer_factory.hpp:136] Creating layer 'fc10' of type 'InnerProduct'
I0801 13:29:14.486621  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.486629  3122 net.cpp:184] Created Layer fc10 (37)
I0801 13:29:14.486634  3122 net.cpp:561] fc10 <- pool5
I0801 13:29:14.486645  3122 net.cpp:530] fc10 -> fc10
I0801 13:29:14.486909  3122 net.cpp:245] Setting up fc10
I0801 13:29:14.486917  3122 net.cpp:252] TRAIN Top shape for layer 37 'fc10' 22 10 (220)
I0801 13:29:14.486923  3122 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0801 13:29:14.486928  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.486944  3122 net.cpp:184] Created Layer loss (38)
I0801 13:29:14.486948  3122 net.cpp:561] loss <- fc10
I0801 13:29:14.486951  3122 net.cpp:561] loss <- label
I0801 13:29:14.486958  3122 net.cpp:530] loss -> loss
I0801 13:29:14.487110  3122 net.cpp:245] Setting up loss
I0801 13:29:14.487118  3122 net.cpp:252] TRAIN Top shape for layer 38 'loss' (1)
I0801 13:29:14.487121  3122 net.cpp:256]     with loss weight 1
I0801 13:29:14.487128  3122 net.cpp:323] loss needs backward computation.
I0801 13:29:14.487133  3122 net.cpp:323] fc10 needs backward computation.
I0801 13:29:14.487136  3122 net.cpp:323] pool5 needs backward computation.
I0801 13:29:14.487140  3122 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0801 13:29:14.487144  3122 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0801 13:29:14.487149  3122 net.cpp:323] res5a_branch2b needs backward computation.
I0801 13:29:14.487154  3122 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0801 13:29:14.487157  3122 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0801 13:29:14.487161  3122 net.cpp:323] res5a_branch2a needs backward computation.
I0801 13:29:14.487165  3122 net.cpp:323] pool4 needs backward computation.
I0801 13:29:14.487170  3122 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0801 13:29:14.487174  3122 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0801 13:29:14.487179  3122 net.cpp:323] res4a_branch2b needs backward computation.
I0801 13:29:14.487182  3122 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0801 13:29:14.487186  3122 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0801 13:29:14.487190  3122 net.cpp:323] res4a_branch2a needs backward computation.
I0801 13:29:14.487195  3122 net.cpp:323] pool3 needs backward computation.
I0801 13:29:14.487200  3122 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0801 13:29:14.487203  3122 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0801 13:29:14.487207  3122 net.cpp:323] res3a_branch2b needs backward computation.
I0801 13:29:14.487211  3122 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0801 13:29:14.487215  3122 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0801 13:29:14.487220  3122 net.cpp:323] res3a_branch2a needs backward computation.
I0801 13:29:14.487223  3122 net.cpp:323] pool2 needs backward computation.
I0801 13:29:14.487228  3122 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0801 13:29:14.487232  3122 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0801 13:29:14.487236  3122 net.cpp:323] res2a_branch2b needs backward computation.
I0801 13:29:14.487241  3122 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0801 13:29:14.487246  3122 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0801 13:29:14.487249  3122 net.cpp:323] res2a_branch2a needs backward computation.
I0801 13:29:14.487253  3122 net.cpp:323] pool1 needs backward computation.
I0801 13:29:14.487258  3122 net.cpp:323] conv1b/relu needs backward computation.
I0801 13:29:14.487262  3122 net.cpp:323] conv1b/bn needs backward computation.
I0801 13:29:14.487267  3122 net.cpp:323] conv1b needs backward computation.
I0801 13:29:14.487270  3122 net.cpp:323] conv1a/relu needs backward computation.
I0801 13:29:14.487274  3122 net.cpp:323] conv1a/bn needs backward computation.
I0801 13:29:14.487279  3122 net.cpp:323] conv1a needs backward computation.
I0801 13:29:14.487283  3122 net.cpp:325] data/bias does not need backward computation.
I0801 13:29:14.487288  3122 net.cpp:325] data does not need backward computation.
I0801 13:29:14.487293  3122 net.cpp:367] This network produces output loss
I0801 13:29:14.487326  3122 net.cpp:389] Top memory (TRAIN) required for data: 121110528 diff: 121110536
I0801 13:29:14.487330  3122 net.cpp:392] Bottom memory (TRAIN) required for data: 121110528 diff: 121110528
I0801 13:29:14.487334  3122 net.cpp:395] Shared (in-place) memory (TRAIN) by data: 80740352 diff: 80740352
I0801 13:29:14.487337  3122 net.cpp:398] Parameters memory (TRAIN) required for data: 9450960 diff: 9450960
I0801 13:29:14.487341  3122 net.cpp:401] Parameters shared memory (TRAIN) by data: 0 diff: 0
I0801 13:29:14.487345  3122 net.cpp:407] Network initialization done.
I0801 13:29:14.487692  3122 solver.cpp:176] Creating test net (#0) specified by test_net file: training/cifar10_jacintonet11v2_2017-08-01_13-11-28/l1reg/test.prototxt
W0801 13:29:14.487741  3122 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 50 to 51
I0801 13:29:14.487864  3122 net.cpp:72] Initializing net from parameters: 
name: "jacintonet11v2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: false
    crop_size: 32
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/cifar10_test_lmdb"
    batch_size: 17
    backend: LMDB
    threads: 1
    parser_threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc10"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc10"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "fc10"
  bottom: "label"
  top: "accuracy/top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "fc10"
  bottom: "label"
  top: "accuracy/top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0801 13:29:14.487973  3122 net.cpp:104] Using FLOAT as default forward math type
I0801 13:29:14.487979  3122 net.cpp:110] Using FLOAT as default backward math type
I0801 13:29:14.487982  3122 layer_factory.hpp:136] Creating layer 'data' of type 'Data'
I0801 13:29:14.487987  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.487998  3122 net.cpp:184] Created Layer data (0)
I0801 13:29:14.488003  3122 net.cpp:530] data -> data
I0801 13:29:14.488008  3122 net.cpp:530] data -> label
I0801 13:29:14.488016  3122 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 17
I0801 13:29:14.488024  3122 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0801 13:29:14.488734  3160 db_lmdb.cpp:35] Opened lmdb ./data/cifar10_test_lmdb
I0801 13:29:14.488790  3122 data_layer.cpp:184] (0) ReshapePrefetch 17, 3, 32, 32
I0801 13:29:14.488869  3122 data_layer.cpp:208] (0) Output data size: 17, 3, 32, 32
I0801 13:29:14.488874  3122 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0801 13:29:14.488890  3122 net.cpp:245] Setting up data
I0801 13:29:14.488895  3122 net.cpp:252] TEST Top shape for layer 0 'data' 17 3 32 32 (52224)
I0801 13:29:14.488901  3122 net.cpp:252] TEST Top shape for layer 0 'data' 17 (17)
I0801 13:29:14.488906  3122 layer_factory.hpp:136] Creating layer 'label_data_1_split' of type 'Split'
I0801 13:29:14.488910  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.488917  3122 net.cpp:184] Created Layer label_data_1_split (1)
I0801 13:29:14.488922  3122 net.cpp:561] label_data_1_split <- label
I0801 13:29:14.488926  3122 net.cpp:530] label_data_1_split -> label_data_1_split_0
I0801 13:29:14.488939  3122 net.cpp:530] label_data_1_split -> label_data_1_split_1
I0801 13:29:14.488945  3122 net.cpp:530] label_data_1_split -> label_data_1_split_2
I0801 13:29:14.489011  3122 net.cpp:245] Setting up label_data_1_split
I0801 13:29:14.489017  3122 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 17 (17)
I0801 13:29:14.489022  3122 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 17 (17)
I0801 13:29:14.489027  3122 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 17 (17)
I0801 13:29:14.489032  3122 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0801 13:29:14.489035  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.489042  3122 net.cpp:184] Created Layer data/bias (2)
I0801 13:29:14.489048  3122 net.cpp:561] data/bias <- data
I0801 13:29:14.489051  3122 net.cpp:530] data/bias -> data/bias
I0801 13:29:14.489181  3122 net.cpp:245] Setting up data/bias
I0801 13:29:14.489187  3122 net.cpp:252] TEST Top shape for layer 2 'data/bias' 17 3 32 32 (52224)
I0801 13:29:14.489194  3122 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0801 13:29:14.489199  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.489209  3122 net.cpp:184] Created Layer conv1a (3)
I0801 13:29:14.489213  3122 net.cpp:561] conv1a <- data/bias
I0801 13:29:14.489217  3122 net.cpp:530] conv1a -> conv1a
I0801 13:29:14.489534  3161 data_layer.cpp:97] (0) Parser threads: 1
I0801 13:29:14.489540  3161 data_layer.cpp:99] (0) Transformer threads: 1
I0801 13:29:14.492254  3122 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 8G, req 0.01G)
I0801 13:29:14.492262  3122 net.cpp:245] Setting up conv1a
I0801 13:29:14.492269  3122 net.cpp:252] TEST Top shape for layer 3 'conv1a' 17 32 32 32 (557056)
I0801 13:29:14.492276  3122 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0801 13:29:14.492278  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.492283  3122 net.cpp:184] Created Layer conv1a/bn (4)
I0801 13:29:14.492286  3122 net.cpp:561] conv1a/bn <- conv1a
I0801 13:29:14.492288  3122 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0801 13:29:14.492924  3122 net.cpp:245] Setting up conv1a/bn
I0801 13:29:14.492933  3122 net.cpp:252] TEST Top shape for layer 4 'conv1a/bn' 17 32 32 32 (557056)
I0801 13:29:14.492941  3122 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0801 13:29:14.492947  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.492954  3122 net.cpp:184] Created Layer conv1a/relu (5)
I0801 13:29:14.492966  3122 net.cpp:561] conv1a/relu <- conv1a
I0801 13:29:14.492971  3122 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0801 13:29:14.492979  3122 net.cpp:245] Setting up conv1a/relu
I0801 13:29:14.492985  3122 net.cpp:252] TEST Top shape for layer 5 'conv1a/relu' 17 32 32 32 (557056)
I0801 13:29:14.492988  3122 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0801 13:29:14.492993  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.493008  3122 net.cpp:184] Created Layer conv1b (6)
I0801 13:29:14.493012  3122 net.cpp:561] conv1b <- conv1a
I0801 13:29:14.493016  3122 net.cpp:530] conv1b -> conv1b
I0801 13:29:14.496242  3122 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'conv1b' with space 0.02G/2 1  (limit 8G, req 0.01G)
I0801 13:29:14.496253  3122 net.cpp:245] Setting up conv1b
I0801 13:29:14.496258  3122 net.cpp:252] TEST Top shape for layer 6 'conv1b' 17 32 32 32 (557056)
I0801 13:29:14.496268  3122 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0801 13:29:14.496273  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.496281  3122 net.cpp:184] Created Layer conv1b/bn (7)
I0801 13:29:14.496294  3122 net.cpp:561] conv1b/bn <- conv1b
I0801 13:29:14.496297  3122 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0801 13:29:14.496953  3122 net.cpp:245] Setting up conv1b/bn
I0801 13:29:14.496961  3122 net.cpp:252] TEST Top shape for layer 7 'conv1b/bn' 17 32 32 32 (557056)
I0801 13:29:14.496968  3122 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0801 13:29:14.496969  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.496973  3122 net.cpp:184] Created Layer conv1b/relu (8)
I0801 13:29:14.496975  3122 net.cpp:561] conv1b/relu <- conv1b
I0801 13:29:14.496978  3122 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0801 13:29:14.496981  3122 net.cpp:245] Setting up conv1b/relu
I0801 13:29:14.496984  3122 net.cpp:252] TEST Top shape for layer 8 'conv1b/relu' 17 32 32 32 (557056)
I0801 13:29:14.496985  3122 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0801 13:29:14.496987  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.496991  3122 net.cpp:184] Created Layer pool1 (9)
I0801 13:29:14.496994  3122 net.cpp:561] pool1 <- conv1b
I0801 13:29:14.496997  3122 net.cpp:530] pool1 -> pool1
I0801 13:29:14.497063  3122 net.cpp:245] Setting up pool1
I0801 13:29:14.497068  3122 net.cpp:252] TEST Top shape for layer 9 'pool1' 17 32 32 32 (557056)
I0801 13:29:14.497071  3122 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0801 13:29:14.497073  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.497081  3122 net.cpp:184] Created Layer res2a_branch2a (10)
I0801 13:29:14.497084  3122 net.cpp:561] res2a_branch2a <- pool1
I0801 13:29:14.497087  3122 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0801 13:29:14.501042  3122 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.99G, req 0.01G)
I0801 13:29:14.501054  3122 net.cpp:245] Setting up res2a_branch2a
I0801 13:29:14.501058  3122 net.cpp:252] TEST Top shape for layer 10 'res2a_branch2a' 17 64 32 32 (1114112)
I0801 13:29:14.501067  3122 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0801 13:29:14.501075  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.501081  3122 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0801 13:29:14.501086  3122 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0801 13:29:14.501106  3122 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0801 13:29:14.501754  3122 net.cpp:245] Setting up res2a_branch2a/bn
I0801 13:29:14.501761  3122 net.cpp:252] TEST Top shape for layer 11 'res2a_branch2a/bn' 17 64 32 32 (1114112)
I0801 13:29:14.501770  3122 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0801 13:29:14.501775  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.501781  3122 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0801 13:29:14.501785  3122 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0801 13:29:14.501791  3122 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0801 13:29:14.501799  3122 net.cpp:245] Setting up res2a_branch2a/relu
I0801 13:29:14.501806  3122 net.cpp:252] TEST Top shape for layer 12 'res2a_branch2a/relu' 17 64 32 32 (1114112)
I0801 13:29:14.501809  3122 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0801 13:29:14.501814  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.501826  3122 net.cpp:184] Created Layer res2a_branch2b (13)
I0801 13:29:14.501829  3122 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0801 13:29:14.501832  3122 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0801 13:29:14.504802  3122 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.98G, req 0.01G)
I0801 13:29:14.504813  3122 net.cpp:245] Setting up res2a_branch2b
I0801 13:29:14.504835  3122 net.cpp:252] TEST Top shape for layer 13 'res2a_branch2b' 17 64 32 32 (1114112)
I0801 13:29:14.504843  3122 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0801 13:29:14.504848  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.504855  3122 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0801 13:29:14.504860  3122 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0801 13:29:14.504865  3122 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0801 13:29:14.505497  3122 net.cpp:245] Setting up res2a_branch2b/bn
I0801 13:29:14.505506  3122 net.cpp:252] TEST Top shape for layer 14 'res2a_branch2b/bn' 17 64 32 32 (1114112)
I0801 13:29:14.505514  3122 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0801 13:29:14.505519  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.505525  3122 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0801 13:29:14.505530  3122 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0801 13:29:14.505535  3122 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0801 13:29:14.505542  3122 net.cpp:245] Setting up res2a_branch2b/relu
I0801 13:29:14.505547  3122 net.cpp:252] TEST Top shape for layer 15 'res2a_branch2b/relu' 17 64 32 32 (1114112)
I0801 13:29:14.505551  3122 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0801 13:29:14.505555  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.505563  3122 net.cpp:184] Created Layer pool2 (16)
I0801 13:29:14.505568  3122 net.cpp:561] pool2 <- res2a_branch2b
I0801 13:29:14.505571  3122 net.cpp:530] pool2 -> pool2
I0801 13:29:14.505635  3122 net.cpp:245] Setting up pool2
I0801 13:29:14.505640  3122 net.cpp:252] TEST Top shape for layer 16 'pool2' 17 64 16 16 (278528)
I0801 13:29:14.505645  3122 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0801 13:29:14.505648  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.505657  3122 net.cpp:184] Created Layer res3a_branch2a (17)
I0801 13:29:14.505661  3122 net.cpp:561] res3a_branch2a <- pool2
I0801 13:29:14.505666  3122 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0801 13:29:14.511615  3122 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.97G, req 0.01G)
I0801 13:29:14.511626  3122 net.cpp:245] Setting up res3a_branch2a
I0801 13:29:14.511629  3122 net.cpp:252] TEST Top shape for layer 17 'res3a_branch2a' 17 128 16 16 (557056)
I0801 13:29:14.511634  3122 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0801 13:29:14.511637  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.511641  3122 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0801 13:29:14.511643  3122 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0801 13:29:14.511646  3122 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0801 13:29:14.512364  3122 net.cpp:245] Setting up res3a_branch2a/bn
I0801 13:29:14.512372  3122 net.cpp:252] TEST Top shape for layer 18 'res3a_branch2a/bn' 17 128 16 16 (557056)
I0801 13:29:14.512380  3122 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0801 13:29:14.512383  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.512387  3122 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0801 13:29:14.512388  3122 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0801 13:29:14.512392  3122 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0801 13:29:14.512394  3122 net.cpp:245] Setting up res3a_branch2a/relu
I0801 13:29:14.512398  3122 net.cpp:252] TEST Top shape for layer 19 'res3a_branch2a/relu' 17 128 16 16 (557056)
I0801 13:29:14.512401  3122 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0801 13:29:14.512419  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.512431  3122 net.cpp:184] Created Layer res3a_branch2b (20)
I0801 13:29:14.512435  3122 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0801 13:29:14.512439  3122 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0801 13:29:14.515883  3122 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.97G, req 0.01G)
I0801 13:29:14.515892  3122 net.cpp:245] Setting up res3a_branch2b
I0801 13:29:14.515897  3122 net.cpp:252] TEST Top shape for layer 20 'res3a_branch2b' 17 128 16 16 (557056)
I0801 13:29:14.515904  3122 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0801 13:29:14.515910  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.515923  3122 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0801 13:29:14.515926  3122 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0801 13:29:14.515931  3122 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0801 13:29:14.516579  3122 net.cpp:245] Setting up res3a_branch2b/bn
I0801 13:29:14.516587  3122 net.cpp:252] TEST Top shape for layer 21 'res3a_branch2b/bn' 17 128 16 16 (557056)
I0801 13:29:14.516597  3122 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0801 13:29:14.516602  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.516607  3122 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0801 13:29:14.516611  3122 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0801 13:29:14.516616  3122 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0801 13:29:14.516623  3122 net.cpp:245] Setting up res3a_branch2b/relu
I0801 13:29:14.516628  3122 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b/relu' 17 128 16 16 (557056)
I0801 13:29:14.516633  3122 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0801 13:29:14.516638  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.516644  3122 net.cpp:184] Created Layer pool3 (23)
I0801 13:29:14.516649  3122 net.cpp:561] pool3 <- res3a_branch2b
I0801 13:29:14.516654  3122 net.cpp:530] pool3 -> pool3
I0801 13:29:14.516718  3122 net.cpp:245] Setting up pool3
I0801 13:29:14.516724  3122 net.cpp:252] TEST Top shape for layer 23 'pool3' 17 128 16 16 (557056)
I0801 13:29:14.516728  3122 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0801 13:29:14.516733  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.516754  3122 net.cpp:184] Created Layer res4a_branch2a (24)
I0801 13:29:14.516758  3122 net.cpp:561] res4a_branch2a <- pool3
I0801 13:29:14.516762  3122 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0801 13:29:14.527681  3122 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.96G, req 0.01G)
I0801 13:29:14.527698  3122 net.cpp:245] Setting up res4a_branch2a
I0801 13:29:14.527704  3122 net.cpp:252] TEST Top shape for layer 24 'res4a_branch2a' 17 256 16 16 (1114112)
I0801 13:29:14.527711  3122 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0801 13:29:14.527714  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.527724  3122 net.cpp:184] Created Layer res4a_branch2a/bn (25)
I0801 13:29:14.527726  3122 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0801 13:29:14.527729  3122 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0801 13:29:14.528458  3122 net.cpp:245] Setting up res4a_branch2a/bn
I0801 13:29:14.528466  3122 net.cpp:252] TEST Top shape for layer 25 'res4a_branch2a/bn' 17 256 16 16 (1114112)
I0801 13:29:14.528472  3122 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0801 13:29:14.528475  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.528491  3122 net.cpp:184] Created Layer res4a_branch2a/relu (26)
I0801 13:29:14.528494  3122 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0801 13:29:14.528496  3122 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0801 13:29:14.528501  3122 net.cpp:245] Setting up res4a_branch2a/relu
I0801 13:29:14.528504  3122 net.cpp:252] TEST Top shape for layer 26 'res4a_branch2a/relu' 17 256 16 16 (1114112)
I0801 13:29:14.528507  3122 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0801 13:29:14.528511  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.528517  3122 net.cpp:184] Created Layer res4a_branch2b (27)
I0801 13:29:14.528522  3122 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0801 13:29:14.528523  3122 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0801 13:29:14.534788  3122 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.95G, req 0.01G)
I0801 13:29:14.534802  3122 net.cpp:245] Setting up res4a_branch2b
I0801 13:29:14.534807  3122 net.cpp:252] TEST Top shape for layer 27 'res4a_branch2b' 17 256 16 16 (1114112)
I0801 13:29:14.534812  3122 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0801 13:29:14.534816  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.534821  3122 net.cpp:184] Created Layer res4a_branch2b/bn (28)
I0801 13:29:14.534824  3122 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0801 13:29:14.534827  3122 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0801 13:29:14.535502  3122 net.cpp:245] Setting up res4a_branch2b/bn
I0801 13:29:14.535511  3122 net.cpp:252] TEST Top shape for layer 28 'res4a_branch2b/bn' 17 256 16 16 (1114112)
I0801 13:29:14.535516  3122 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0801 13:29:14.535521  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.535523  3122 net.cpp:184] Created Layer res4a_branch2b/relu (29)
I0801 13:29:14.535526  3122 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0801 13:29:14.535528  3122 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0801 13:29:14.535532  3122 net.cpp:245] Setting up res4a_branch2b/relu
I0801 13:29:14.535536  3122 net.cpp:252] TEST Top shape for layer 29 'res4a_branch2b/relu' 17 256 16 16 (1114112)
I0801 13:29:14.535538  3122 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0801 13:29:14.535540  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.535545  3122 net.cpp:184] Created Layer pool4 (30)
I0801 13:29:14.535547  3122 net.cpp:561] pool4 <- res4a_branch2b
I0801 13:29:14.535550  3122 net.cpp:530] pool4 -> pool4
I0801 13:29:14.535616  3122 net.cpp:245] Setting up pool4
I0801 13:29:14.535621  3122 net.cpp:252] TEST Top shape for layer 30 'pool4' 17 256 8 8 (278528)
I0801 13:29:14.535624  3122 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0801 13:29:14.535627  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.535634  3122 net.cpp:184] Created Layer res5a_branch2a (31)
I0801 13:29:14.535637  3122 net.cpp:561] res5a_branch2a <- pool4
I0801 13:29:14.535640  3122 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0801 13:29:14.567392  3122 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.94G, req 0.01G)
I0801 13:29:14.567409  3122 net.cpp:245] Setting up res5a_branch2a
I0801 13:29:14.567415  3122 net.cpp:252] TEST Top shape for layer 31 'res5a_branch2a' 17 512 8 8 (557056)
I0801 13:29:14.567421  3122 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0801 13:29:14.567425  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.567447  3122 net.cpp:184] Created Layer res5a_branch2a/bn (32)
I0801 13:29:14.567451  3122 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0801 13:29:14.567456  3122 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0801 13:29:14.568148  3122 net.cpp:245] Setting up res5a_branch2a/bn
I0801 13:29:14.568156  3122 net.cpp:252] TEST Top shape for layer 32 'res5a_branch2a/bn' 17 512 8 8 (557056)
I0801 13:29:14.568162  3122 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0801 13:29:14.568166  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.568168  3122 net.cpp:184] Created Layer res5a_branch2a/relu (33)
I0801 13:29:14.568171  3122 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0801 13:29:14.568173  3122 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0801 13:29:14.568177  3122 net.cpp:245] Setting up res5a_branch2a/relu
I0801 13:29:14.568179  3122 net.cpp:252] TEST Top shape for layer 33 'res5a_branch2a/relu' 17 512 8 8 (557056)
I0801 13:29:14.568181  3122 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0801 13:29:14.568183  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.568190  3122 net.cpp:184] Created Layer res5a_branch2b (34)
I0801 13:29:14.568193  3122 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0801 13:29:14.568195  3122 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0801 13:29:14.585315  3122 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.93G, req 0.01G)
I0801 13:29:14.585327  3122 net.cpp:245] Setting up res5a_branch2b
I0801 13:29:14.585331  3122 net.cpp:252] TEST Top shape for layer 34 'res5a_branch2b' 17 512 8 8 (557056)
I0801 13:29:14.585340  3122 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0801 13:29:14.585342  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.585348  3122 net.cpp:184] Created Layer res5a_branch2b/bn (35)
I0801 13:29:14.585351  3122 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0801 13:29:14.585353  3122 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0801 13:29:14.586086  3122 net.cpp:245] Setting up res5a_branch2b/bn
I0801 13:29:14.586094  3122 net.cpp:252] TEST Top shape for layer 35 'res5a_branch2b/bn' 17 512 8 8 (557056)
I0801 13:29:14.586100  3122 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0801 13:29:14.586104  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.586114  3122 net.cpp:184] Created Layer res5a_branch2b/relu (36)
I0801 13:29:14.586117  3122 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0801 13:29:14.586119  3122 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0801 13:29:14.586124  3122 net.cpp:245] Setting up res5a_branch2b/relu
I0801 13:29:14.586127  3122 net.cpp:252] TEST Top shape for layer 36 'res5a_branch2b/relu' 17 512 8 8 (557056)
I0801 13:29:14.586128  3122 layer_factory.hpp:136] Creating layer 'pool5' of type 'Pooling'
I0801 13:29:14.586132  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.586143  3122 net.cpp:184] Created Layer pool5 (37)
I0801 13:29:14.586145  3122 net.cpp:561] pool5 <- res5a_branch2b
I0801 13:29:14.586148  3122 net.cpp:530] pool5 -> pool5
I0801 13:29:14.586179  3122 net.cpp:245] Setting up pool5
I0801 13:29:14.586182  3122 net.cpp:252] TEST Top shape for layer 37 'pool5' 17 512 1 1 (8704)
I0801 13:29:14.586185  3122 layer_factory.hpp:136] Creating layer 'fc10' of type 'InnerProduct'
I0801 13:29:14.586187  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.586192  3122 net.cpp:184] Created Layer fc10 (38)
I0801 13:29:14.586194  3122 net.cpp:561] fc10 <- pool5
I0801 13:29:14.586197  3122 net.cpp:530] fc10 -> fc10
I0801 13:29:14.586484  3122 net.cpp:245] Setting up fc10
I0801 13:29:14.586501  3122 net.cpp:252] TEST Top shape for layer 38 'fc10' 17 10 (170)
I0801 13:29:14.586506  3122 layer_factory.hpp:136] Creating layer 'fc10_fc10_0_split' of type 'Split'
I0801 13:29:14.586509  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.586514  3122 net.cpp:184] Created Layer fc10_fc10_0_split (39)
I0801 13:29:14.586518  3122 net.cpp:561] fc10_fc10_0_split <- fc10
I0801 13:29:14.586520  3122 net.cpp:530] fc10_fc10_0_split -> fc10_fc10_0_split_0
I0801 13:29:14.586524  3122 net.cpp:530] fc10_fc10_0_split -> fc10_fc10_0_split_1
I0801 13:29:14.586526  3122 net.cpp:530] fc10_fc10_0_split -> fc10_fc10_0_split_2
I0801 13:29:14.586596  3122 net.cpp:245] Setting up fc10_fc10_0_split
I0801 13:29:14.586599  3122 net.cpp:252] TEST Top shape for layer 39 'fc10_fc10_0_split' 17 10 (170)
I0801 13:29:14.586602  3122 net.cpp:252] TEST Top shape for layer 39 'fc10_fc10_0_split' 17 10 (170)
I0801 13:29:14.586604  3122 net.cpp:252] TEST Top shape for layer 39 'fc10_fc10_0_split' 17 10 (170)
I0801 13:29:14.586607  3122 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0801 13:29:14.586609  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.586617  3122 net.cpp:184] Created Layer loss (40)
I0801 13:29:14.586621  3122 net.cpp:561] loss <- fc10_fc10_0_split_0
I0801 13:29:14.586623  3122 net.cpp:561] loss <- label_data_1_split_0
I0801 13:29:14.586627  3122 net.cpp:530] loss -> loss
I0801 13:29:14.586772  3122 net.cpp:245] Setting up loss
I0801 13:29:14.586778  3122 net.cpp:252] TEST Top shape for layer 40 'loss' (1)
I0801 13:29:14.586781  3122 net.cpp:256]     with loss weight 1
I0801 13:29:14.586786  3122 layer_factory.hpp:136] Creating layer 'accuracy/top1' of type 'Accuracy'
I0801 13:29:14.586788  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.586796  3122 net.cpp:184] Created Layer accuracy/top1 (41)
I0801 13:29:14.586798  3122 net.cpp:561] accuracy/top1 <- fc10_fc10_0_split_1
I0801 13:29:14.586800  3122 net.cpp:561] accuracy/top1 <- label_data_1_split_1
I0801 13:29:14.586803  3122 net.cpp:530] accuracy/top1 -> accuracy/top1
I0801 13:29:14.586808  3122 net.cpp:245] Setting up accuracy/top1
I0801 13:29:14.586812  3122 net.cpp:252] TEST Top shape for layer 41 'accuracy/top1' (1)
I0801 13:29:14.586813  3122 layer_factory.hpp:136] Creating layer 'accuracy/top5' of type 'Accuracy'
I0801 13:29:14.586815  3122 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:29:14.586819  3122 net.cpp:184] Created Layer accuracy/top5 (42)
I0801 13:29:14.586822  3122 net.cpp:561] accuracy/top5 <- fc10_fc10_0_split_2
I0801 13:29:14.586824  3122 net.cpp:561] accuracy/top5 <- label_data_1_split_2
I0801 13:29:14.586827  3122 net.cpp:530] accuracy/top5 -> accuracy/top5
I0801 13:29:14.586830  3122 net.cpp:245] Setting up accuracy/top5
I0801 13:29:14.586833  3122 net.cpp:252] TEST Top shape for layer 42 'accuracy/top5' (1)
I0801 13:29:14.586836  3122 net.cpp:325] accuracy/top5 does not need backward computation.
I0801 13:29:14.586838  3122 net.cpp:325] accuracy/top1 does not need backward computation.
I0801 13:29:14.586840  3122 net.cpp:323] loss needs backward computation.
I0801 13:29:14.586843  3122 net.cpp:323] fc10_fc10_0_split needs backward computation.
I0801 13:29:14.586845  3122 net.cpp:323] fc10 needs backward computation.
I0801 13:29:14.586848  3122 net.cpp:323] pool5 needs backward computation.
I0801 13:29:14.586850  3122 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0801 13:29:14.586851  3122 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0801 13:29:14.586854  3122 net.cpp:323] res5a_branch2b needs backward computation.
I0801 13:29:14.586856  3122 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0801 13:29:14.586858  3122 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0801 13:29:14.586861  3122 net.cpp:323] res5a_branch2a needs backward computation.
I0801 13:29:14.586869  3122 net.cpp:323] pool4 needs backward computation.
I0801 13:29:14.586871  3122 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0801 13:29:14.586874  3122 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0801 13:29:14.586875  3122 net.cpp:323] res4a_branch2b needs backward computation.
I0801 13:29:14.586879  3122 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0801 13:29:14.586880  3122 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0801 13:29:14.586882  3122 net.cpp:323] res4a_branch2a needs backward computation.
I0801 13:29:14.586884  3122 net.cpp:323] pool3 needs backward computation.
I0801 13:29:14.586887  3122 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0801 13:29:14.586889  3122 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0801 13:29:14.586891  3122 net.cpp:323] res3a_branch2b needs backward computation.
I0801 13:29:14.586894  3122 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0801 13:29:14.586895  3122 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0801 13:29:14.586897  3122 net.cpp:323] res3a_branch2a needs backward computation.
I0801 13:29:14.586899  3122 net.cpp:323] pool2 needs backward computation.
I0801 13:29:14.586902  3122 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0801 13:29:14.586905  3122 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0801 13:29:14.586905  3122 net.cpp:323] res2a_branch2b needs backward computation.
I0801 13:29:14.586907  3122 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0801 13:29:14.586910  3122 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0801 13:29:14.586912  3122 net.cpp:323] res2a_branch2a needs backward computation.
I0801 13:29:14.586915  3122 net.cpp:323] pool1 needs backward computation.
I0801 13:29:14.586916  3122 net.cpp:323] conv1b/relu needs backward computation.
I0801 13:29:14.586918  3122 net.cpp:323] conv1b/bn needs backward computation.
I0801 13:29:14.586920  3122 net.cpp:323] conv1b needs backward computation.
I0801 13:29:14.586922  3122 net.cpp:323] conv1a/relu needs backward computation.
I0801 13:29:14.586925  3122 net.cpp:323] conv1a/bn needs backward computation.
I0801 13:29:14.586927  3122 net.cpp:323] conv1a needs backward computation.
I0801 13:29:14.586930  3122 net.cpp:325] data/bias does not need backward computation.
I0801 13:29:14.586932  3122 net.cpp:325] label_data_1_split does not need backward computation.
I0801 13:29:14.586935  3122 net.cpp:325] data does not need backward computation.
I0801 13:29:14.586938  3122 net.cpp:367] This network produces output accuracy/top1
I0801 13:29:14.586941  3122 net.cpp:367] This network produces output accuracy/top5
I0801 13:29:14.586942  3122 net.cpp:367] This network produces output loss
I0801 13:29:14.586969  3122 net.cpp:389] Top memory (TEST) required for data: 93585408 diff: 8
I0801 13:29:14.586972  3122 net.cpp:392] Bottom memory (TEST) required for data: 93585408 diff: 93585408
I0801 13:29:14.586974  3122 net.cpp:395] Shared (in-place) memory (TEST) by data: 62390272 diff: 62390272
I0801 13:29:14.586977  3122 net.cpp:398] Parameters memory (TEST) required for data: 9450960 diff: 9450960
I0801 13:29:14.586979  3122 net.cpp:401] Parameters shared memory (TEST) by data: 0 diff: 0
I0801 13:29:14.586982  3122 net.cpp:407] Network initialization done.
I0801 13:29:14.587034  3122 solver.cpp:56] Solver scaffolding done.
I0801 13:29:14.591033  3122 caffe.cpp:137] Finetuning from training/cifar10_jacintonet11v2_2017-08-01_13-11-28/initial/cifar10_jacintonet11v2_iter_64000.caffemodel
I0801 13:29:14.595549  3122 net.cpp:1089] Copying source layer data Type:Data #blobs=0
I0801 13:29:14.595571  3122 net.cpp:1089] Copying source layer data/bias Type:Bias #blobs=1
I0801 13:29:14.595602  3122 net.cpp:1089] Copying source layer conv1a Type:Convolution #blobs=2
I0801 13:29:14.595613  3122 net.cpp:1089] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0801 13:29:14.595877  3122 net.cpp:1089] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0801 13:29:14.595892  3122 net.cpp:1089] Copying source layer conv1b Type:Convolution #blobs=2
I0801 13:29:14.595902  3122 net.cpp:1089] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0801 13:29:14.596053  3122 net.cpp:1089] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0801 13:29:14.596057  3122 net.cpp:1089] Copying source layer pool1 Type:Pooling #blobs=0
I0801 13:29:14.596060  3122 net.cpp:1089] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0801 13:29:14.596077  3122 net.cpp:1089] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0801 13:29:14.596233  3122 net.cpp:1089] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0801 13:29:14.596237  3122 net.cpp:1089] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0801 13:29:14.596251  3122 net.cpp:1089] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0801 13:29:14.596392  3122 net.cpp:1089] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0801 13:29:14.596396  3122 net.cpp:1089] Copying source layer pool2 Type:Pooling #blobs=0
I0801 13:29:14.596398  3122 net.cpp:1089] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0801 13:29:14.596438  3122 net.cpp:1089] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0801 13:29:14.596565  3122 net.cpp:1089] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0801 13:29:14.596570  3122 net.cpp:1089] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0801 13:29:14.596591  3122 net.cpp:1089] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0801 13:29:14.596712  3122 net.cpp:1089] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0801 13:29:14.596716  3122 net.cpp:1089] Copying source layer pool3 Type:Pooling #blobs=0
I0801 13:29:14.596719  3122 net.cpp:1089] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0801 13:29:14.596839  3122 net.cpp:1089] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0801 13:29:14.596967  3122 net.cpp:1089] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0801 13:29:14.596971  3122 net.cpp:1089] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0801 13:29:14.597030  3122 net.cpp:1089] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0801 13:29:14.597147  3122 net.cpp:1089] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0801 13:29:14.597151  3122 net.cpp:1089] Copying source layer pool4 Type:Pooling #blobs=0
I0801 13:29:14.597154  3122 net.cpp:1089] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0801 13:29:14.597513  3122 net.cpp:1089] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0801 13:29:14.597645  3122 net.cpp:1089] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0801 13:29:14.597651  3122 net.cpp:1089] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0801 13:29:14.597810  3122 net.cpp:1089] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0801 13:29:14.597935  3122 net.cpp:1089] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0801 13:29:14.597940  3122 net.cpp:1089] Copying source layer pool5 Type:Pooling #blobs=0
I0801 13:29:14.597942  3122 net.cpp:1089] Copying source layer fc10 Type:InnerProduct #blobs=2
I0801 13:29:14.597952  3122 net.cpp:1089] Copying source layer loss Type:SoftmaxWithLoss #blobs=0
I0801 13:29:14.600687  3122 net.cpp:1089] Copying source layer data Type:Data #blobs=0
I0801 13:29:14.600704  3122 net.cpp:1089] Copying source layer data/bias Type:Bias #blobs=1
I0801 13:29:14.600725  3122 net.cpp:1089] Copying source layer conv1a Type:Convolution #blobs=2
I0801 13:29:14.600736  3122 net.cpp:1089] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0801 13:29:14.600980  3122 net.cpp:1089] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0801 13:29:14.600986  3122 net.cpp:1089] Copying source layer conv1b Type:Convolution #blobs=2
I0801 13:29:14.600996  3122 net.cpp:1089] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0801 13:29:14.601150  3122 net.cpp:1089] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0801 13:29:14.601155  3122 net.cpp:1089] Copying source layer pool1 Type:Pooling #blobs=0
I0801 13:29:14.601157  3122 net.cpp:1089] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0801 13:29:14.601172  3122 net.cpp:1089] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0801 13:29:14.601327  3122 net.cpp:1089] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0801 13:29:14.601331  3122 net.cpp:1089] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0801 13:29:14.601343  3122 net.cpp:1089] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0801 13:29:14.601488  3122 net.cpp:1089] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0801 13:29:14.601492  3122 net.cpp:1089] Copying source layer pool2 Type:Pooling #blobs=0
I0801 13:29:14.601495  3122 net.cpp:1089] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0801 13:29:14.601532  3122 net.cpp:1089] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0801 13:29:14.601662  3122 net.cpp:1089] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0801 13:29:14.601666  3122 net.cpp:1089] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0801 13:29:14.601687  3122 net.cpp:1089] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0801 13:29:14.601799  3122 net.cpp:1089] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0801 13:29:14.601804  3122 net.cpp:1089] Copying source layer pool3 Type:Pooling #blobs=0
I0801 13:29:14.601805  3122 net.cpp:1089] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0801 13:29:14.601917  3122 net.cpp:1089] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0801 13:29:14.602041  3122 net.cpp:1089] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0801 13:29:14.602044  3122 net.cpp:1089] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0801 13:29:14.602115  3122 net.cpp:1089] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0801 13:29:14.602237  3122 net.cpp:1089] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0801 13:29:14.602242  3122 net.cpp:1089] Copying source layer pool4 Type:Pooling #blobs=0
I0801 13:29:14.602244  3122 net.cpp:1089] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0801 13:29:14.602617  3122 net.cpp:1089] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0801 13:29:14.602751  3122 net.cpp:1089] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0801 13:29:14.602756  3122 net.cpp:1089] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0801 13:29:14.602917  3122 net.cpp:1089] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0801 13:29:14.603041  3122 net.cpp:1089] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0801 13:29:14.603046  3122 net.cpp:1089] Copying source layer pool5 Type:Pooling #blobs=0
I0801 13:29:14.603049  3122 net.cpp:1089] Copying source layer fc10 Type:InnerProduct #blobs=2
I0801 13:29:14.603057  3122 net.cpp:1089] Copying source layer loss Type:SoftmaxWithLoss #blobs=0
I0801 13:29:14.603119  3122 parallel.cpp:108] [0 - 0] P2pSync adding callback
I0801 13:29:14.603127  3122 parallel.cpp:108] [1 - 1] P2pSync adding callback
I0801 13:29:14.603129  3122 parallel.cpp:108] [2 - 2] P2pSync adding callback
I0801 13:29:14.603132  3122 parallel.cpp:61] Starting Optimization
I0801 13:29:14.603133  3122 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0801 13:29:14.603158  3122 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0801 13:29:14.603173  3122 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0801 13:29:14.603864  3162 device_alternate.hpp:116] NVML initialized on thread 139819137378048
I0801 13:29:14.616526  3162 common.cpp:583] NVML succeeded to set CPU affinity on device 0
I0801 13:29:14.616583  3164 device_alternate.hpp:116] NVML initialized on thread 139819120592640
I0801 13:29:14.617558  3164 common.cpp:583] NVML succeeded to set CPU affinity on device 2
I0801 13:29:14.617575  3163 device_alternate.hpp:116] NVML initialized on thread 139819128985344
I0801 13:29:14.618023  3163 common.cpp:583] NVML succeeded to set CPU affinity on device 1
I0801 13:29:14.621947  3164 solver.cpp:42] Solver data type: FLOAT
W0801 13:29:14.622326  3164 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 64 to 66
I0801 13:29:14.622409  3164 net.cpp:104] Using FLOAT as default forward math type
I0801 13:29:14.622414  3164 net.cpp:110] Using FLOAT as default backward math type
I0801 13:29:14.622439  3164 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 22
I0801 13:29:14.622450  3164 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0801 13:29:14.626257  3163 solver.cpp:42] Solver data type: FLOAT
W0801 13:29:14.626652  3163 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 64 to 66
I0801 13:29:14.626725  3163 net.cpp:104] Using FLOAT as default forward math type
I0801 13:29:14.626731  3163 net.cpp:110] Using FLOAT as default backward math type
I0801 13:29:14.626770  3163 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 22
I0801 13:29:14.626780  3163 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0801 13:29:14.626943  3165 db_lmdb.cpp:35] Opened lmdb ./data/cifar10_train_lmdb
I0801 13:29:14.627977  3164 data_layer.cpp:184] [2] ReshapePrefetch 22, 3, 32, 32
I0801 13:29:14.628002  3166 db_lmdb.cpp:35] Opened lmdb ./data/cifar10_train_lmdb
I0801 13:29:14.628077  3164 data_layer.cpp:208] [2] Output data size: 22, 3, 32, 32
I0801 13:29:14.628083  3164 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0801 13:29:14.629179  3163 data_layer.cpp:184] [1] ReshapePrefetch 22, 3, 32, 32
I0801 13:29:14.629335  3163 data_layer.cpp:208] [1] Output data size: 22, 3, 32, 32
I0801 13:29:14.629343  3163 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0801 13:29:15.062960  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1a' with space 0.01G/1 1 0 3  (limit 8.25G, req 0G)
I0801 13:29:15.087224  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.01G/1 1 0 3  (limit 8.25G, req 0G)
I0801 13:29:15.089684  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 8.23G, req 0G)
I0801 13:29:15.096436  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 8.23G, req 0G)
I0801 13:29:15.102864  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 8.21G, req 0G)
I0801 13:29:15.109472  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 8.21G, req 0G)
I0801 13:29:15.111850  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 8.19G, req 0G)
I0801 13:29:15.118031  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 8.19G, req 0G)
I0801 13:29:15.125424  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 8.18G, req 0.01G)
I0801 13:29:15.131359  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 8.18G, req 0.01G)
I0801 13:29:15.131760  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 8.17G, req 0.01G)
I0801 13:29:15.137384  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 8.17G, req 0.01G)
I0801 13:29:15.153551  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 8.15G, req 0.01G)
I0801 13:29:15.159842  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 8.15G, req 0.01G)
I0801 13:29:15.163216  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 8.14G, req 0.01G)
I0801 13:29:15.170840  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 8.14G, req 0.01G)
I0801 13:29:15.208693  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 1  (limit 8.11G, req 0.01G)
I0801 13:29:15.216064  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 1  (limit 8.11G, req 0.01G)
I0801 13:29:15.229213  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 5  (limit 8.1G, req 0.01G)
I0801 13:29:15.231143  3164 solver.cpp:176] Creating test net (#0) specified by test_net file: training/cifar10_jacintonet11v2_2017-08-01_13-11-28/l1reg/test.prototxt
W0801 13:29:15.231196  3164 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 50 to 51
I0801 13:29:15.231300  3164 net.cpp:104] Using FLOAT as default forward math type
I0801 13:29:15.231307  3164 net.cpp:110] Using FLOAT as default backward math type
I0801 13:29:15.231323  3164 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 17
I0801 13:29:15.231333  3164 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0801 13:29:15.232579  3199 db_lmdb.cpp:35] Opened lmdb ./data/cifar10_test_lmdb
I0801 13:29:15.232650  3164 data_layer.cpp:184] (2) ReshapePrefetch 17, 3, 32, 32
I0801 13:29:15.232729  3164 data_layer.cpp:208] (2) Output data size: 17, 3, 32, 32
I0801 13:29:15.232733  3164 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0801 13:29:15.233520  3200 data_layer.cpp:97] (2) Parser threads: 1
I0801 13:29:15.233527  3200 data_layer.cpp:99] (2) Transformer threads: 1
I0801 13:29:15.236889  3164 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 8.1G, req 0.01G)
I0801 13:29:15.237282  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 5  (limit 8.1G, req 0.01G)
I0801 13:29:15.239449  3163 solver.cpp:176] Creating test net (#0) specified by test_net file: training/cifar10_jacintonet11v2_2017-08-01_13-11-28/l1reg/test.prototxt
W0801 13:29:15.239502  3163 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 50 to 51
I0801 13:29:15.239593  3163 net.cpp:104] Using FLOAT as default forward math type
I0801 13:29:15.239598  3163 net.cpp:110] Using FLOAT as default backward math type
I0801 13:29:15.239617  3163 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 17
I0801 13:29:15.239626  3163 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0801 13:29:15.240434  3201 db_lmdb.cpp:35] Opened lmdb ./data/cifar10_test_lmdb
I0801 13:29:15.240499  3163 data_layer.cpp:184] (1) ReshapePrefetch 17, 3, 32, 32
I0801 13:29:15.240581  3163 data_layer.cpp:208] (1) Output data size: 17, 3, 32, 32
I0801 13:29:15.240586  3163 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0801 13:29:15.241341  3202 data_layer.cpp:97] (1) Parser threads: 1
I0801 13:29:15.241349  3202 data_layer.cpp:99] (1) Transformer threads: 1
I0801 13:29:15.241582  3164 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'conv1b' with space 0.02G/2 1  (limit 8.09G, req 0.01G)
I0801 13:29:15.244722  3163 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 8.1G, req 0.01G)
I0801 13:29:15.248422  3164 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 8.08G, req 0.01G)
I0801 13:29:15.250787  3163 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'conv1b' with space 0.02G/2 1  (limit 8.09G, req 0.01G)
I0801 13:29:15.253612  3164 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 8.08G, req 0.01G)
I0801 13:29:15.256777  3163 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 8.08G, req 0.01G)
I0801 13:29:15.261252  3163 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 8.08G, req 0.01G)
I0801 13:29:15.262959  3164 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 8.07G, req 0.01G)
I0801 13:29:15.268293  3164 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 8.06G, req 0.01G)
I0801 13:29:15.269264  3163 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 8.07G, req 0.01G)
I0801 13:29:15.273605  3163 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 8.06G, req 0.01G)
I0801 13:29:15.280712  3164 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 8.05G, req 0.01G)
I0801 13:29:15.286226  3163 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 8.05G, req 0.01G)
I0801 13:29:15.288936  3164 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 8.05G, req 0.01G)
I0801 13:29:15.294080  3163 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 8.05G, req 0.01G)
I0801 13:29:15.322609  3164 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 8.03G, req 0.01G)
I0801 13:29:15.327172  3163 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 8.03G, req 0.01G)
I0801 13:29:15.341019  3164 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 8.02G, req 0.01G)
I0801 13:29:15.343916  3164 solver.cpp:56] Solver scaffolding done.
I0801 13:29:15.345284  3163 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 8.02G, req 0.01G)
I0801 13:29:15.347918  3163 solver.cpp:56] Solver scaffolding done.
I0801 13:29:15.392069  3163 parallel.cpp:164] [1 - 1] P2pSync adding callback
I0801 13:29:15.392069  3164 parallel.cpp:164] [2 - 2] P2pSync adding callback
I0801 13:29:15.392069  3162 parallel.cpp:164] [0 - 0] P2pSync adding callback
I0801 13:29:15.598502  3162 solver.cpp:479] Solving jacintonet11v2_train
I0801 13:29:15.598521  3162 solver.cpp:480] Learning Rate Policy: poly
I0801 13:29:15.598629  3163 solver.cpp:479] Solving jacintonet11v2_train
I0801 13:29:15.598639  3163 solver.cpp:480] Learning Rate Policy: poly
I0801 13:29:15.598654  3164 solver.cpp:479] Solving jacintonet11v2_train
I0801 13:29:15.598662  3164 solver.cpp:480] Learning Rate Policy: poly
I0801 13:29:15.605558  3163 solver.cpp:268] Starting Optimization on GPU 1
I0801 13:29:15.605561  3162 solver.cpp:268] Starting Optimization on GPU 0
I0801 13:29:15.605559  3164 solver.cpp:268] Starting Optimization on GPU 2
I0801 13:29:15.605805  3162 solver.cpp:550] Iteration 0, Testing net (#0)
I0801 13:29:15.605845  3204 device_alternate.hpp:116] NVML initialized on thread 139818360960768
I0801 13:29:15.605867  3204 common.cpp:583] NVML succeeded to set CPU affinity on device 1
I0801 13:29:15.605883  3203 device_alternate.hpp:116] NVML initialized on thread 139818344175360
I0801 13:29:15.605900  3203 common.cpp:583] NVML succeeded to set CPU affinity on device 2
I0801 13:29:15.605907  3205 device_alternate.hpp:116] NVML initialized on thread 139818352568064
I0801 13:29:15.605913  3205 common.cpp:583] NVML succeeded to set CPU affinity on device 0
I0801 13:29:15.613801  3164 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 7.99G, req 0.01G)
I0801 13:29:15.614630  3163 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 7.99G, req 0.01G)
I0801 13:29:15.619359  3164 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'conv1b' with space 0.02G/2 1  (limit 7.98G, req 0.01G)
I0801 13:29:15.619904  3163 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'conv1b' with space 0.02G/2 0  (limit 7.98G, req 0.01G)
I0801 13:29:15.626740  3162 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'conv1a' with space 0.01G/1 1  (limit 7.92G, req 0G)
I0801 13:29:15.627140  3164 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.97G, req 0.01G)
I0801 13:29:15.628572  3163 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.97G, req 0.01G)
I0801 13:29:15.633829  3164 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.96G, req 0.01G)
I0801 13:29:15.634358  3162 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'conv1b' with space 0.02G/2 1  (limit 7.9G, req 0G)
I0801 13:29:15.635562  3163 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.96G, req 0.01G)
I0801 13:29:15.640805  3164 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.94G, req 0.01G)
I0801 13:29:15.642652  3163 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.94G, req 0.01G)
I0801 13:29:15.644711  3162 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.89G, req 0G)
I0801 13:29:15.647100  3164 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.94G, req 0.01G)
I0801 13:29:15.648241  3163 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.94G, req 0.01G)
I0801 13:29:15.651068  3162 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.88G, req 0G)
I0801 13:29:15.655203  3164 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.92G, req 0.01G)
I0801 13:29:15.656754  3163 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.92G, req 0.01G)
I0801 13:29:15.657341  3162 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.86G, req 0G)
I0801 13:29:15.661970  3164 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.91G, req 0.01G)
I0801 13:29:15.662678  3163 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.91G, req 0.01G)
I0801 13:29:15.663537  3162 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.85G, req 0G)
I0801 13:29:15.673192  3162 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.84G, req 0G)
I0801 13:29:15.675915  3163 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.9G, req 0.01G)
I0801 13:29:15.680377  3164 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 6  (limit 7.9G, req 0.01G)
I0801 13:29:15.697088  3162 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.83G, req 0G)
I0801 13:29:15.702097  3163 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.89G, req 0.01G)
I0801 13:29:15.704711  3164 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 7  (limit 7.89G, req 0.01G)
I0801 13:29:15.716457  3162 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.81G, req 0G)
I0801 13:29:15.723232  3162 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.8G, req 0G)
I0801 13:29:15.727095  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 1
I0801 13:29:15.727116  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 1
I0801 13:29:15.727128  3162 solver.cpp:635]     Test net output #2: loss = 0.0237409 (* 1 = 0.0237409 loss)
I0801 13:29:15.727138  3162 solver.cpp:295] [MultiGPU] Initial Test completed
I0801 13:29:15.727192  3163 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 13:29:15.739651  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 3  (limit 7.88G, req 0.01G)
I0801 13:29:15.740289  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 3  (limit 7.88G, req 0.01G)
I0801 13:29:15.741392  3162 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 3  (limit 7.8G, req 0G)
I0801 13:29:15.750335  3162 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 7.79G, req 0G)
I0801 13:29:15.752027  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 7.87G, req 0.01G)
I0801 13:29:15.752079  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 7.87G, req 0.01G)
I0801 13:29:15.763388  3162 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 7.77G, req 0G)
I0801 13:29:15.765116  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 7.86G, req 0.01G)
I0801 13:29:15.765527  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 7.86G, req 0.01G)
I0801 13:29:15.771883  3162 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 7.76G, req 0G)
I0801 13:29:15.774112  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 7.85G, req 0.01G)
I0801 13:29:15.774379  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 7.85G, req 0.01G)
I0801 13:29:15.783619  3162 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 7.75G, req 0.01G)
I0801 13:29:15.785270  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 7.83G, req 0.01G)
I0801 13:29:15.786154  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 7.83G, req 0.01G)
I0801 13:29:15.791059  3162 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 7.74G, req 0.01G)
I0801 13:29:15.792491  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 7.82G, req 0.01G)
I0801 13:29:15.793196  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 7.82G, req 0.01G)
I0801 13:29:15.809177  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 7.81G, req 0.01G)
I0801 13:29:15.811017  3162 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 7.72G, req 0.01G)
I0801 13:29:15.811231  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 7.81G, req 0.01G)
I0801 13:29:15.817015  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 7.8G, req 0.01G)
I0801 13:29:15.818725  3162 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 7.71G, req 0.01G)
I0801 13:29:15.819743  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 7.8G, req 0.01G)
I0801 13:29:15.838498  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 1  (limit 7.78G, req 0.01G)
I0801 13:29:15.841948  3162 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 1  (limit 7.69G, req 0.01G)
I0801 13:29:15.842185  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 1  (limit 7.78G, req 0.01G)
I0801 13:29:15.847117  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 5  (limit 7.77G, req 0.01G)
I0801 13:29:15.850098  3162 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 5  (limit 7.68G, req 0.01G)
I0801 13:29:15.850919  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 5  (limit 7.77G, req 0.01G)
I0801 13:29:15.881527  3168 data_layer.cpp:97] [1] Parser threads: 1
I0801 13:29:15.881543  3168 data_layer.cpp:99] [1] Transformer threads: 1
I0801 13:29:15.886729  3156 data_layer.cpp:97] [0] Parser threads: 1
I0801 13:29:15.886739  3156 data_layer.cpp:99] [0] Transformer threads: 1
I0801 13:29:15.889241  3167 data_layer.cpp:97] [2] Parser threads: 1
I0801 13:29:15.889251  3167 data_layer.cpp:99] [2] Transformer threads: 1
I0801 13:29:15.891764  3162 solver.cpp:358] Iteration 0 (0.163392 s), loss = 0.000644316
I0801 13:29:15.891783  3162 solver.cpp:375]     Train net output #0: loss = 0.000644316 (* 1 = 0.000644316 loss)
I0801 13:29:15.891788  3162 sgd_solver.cpp:136] Iteration 0, lr = 0.01, m = 0.9
I0801 13:29:15.919473  3162 solver.cpp:358] Iteration 1 (0.0277002 s), loss = 0.0023243
I0801 13:29:15.919497  3162 solver.cpp:375]     Train net output #0: loss = 0.0023243 (* 1 = 0.0023243 loss)
I0801 13:29:15.930356  3162 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.64G/1 1 0 3  (limit 6.98G, req 0.01G)
I0801 13:29:15.930719  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1a' with space 0.64G/1 1 0 3  (limit 7.07G, req 0.01G)
I0801 13:29:15.931094  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.64G/1 1 0 3  (limit 7.07G, req 0.01G)
I0801 13:29:15.938777  3162 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1b' with space 1.29G/2 1 1 3  (limit 6.34G, req 0.01G)
I0801 13:29:15.940126  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1b' with space 1.29G/2 1 1 3  (limit 6.43G, req 0.01G)
I0801 13:29:15.941627  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1b' with space 1.29G/2 1 1 3  (limit 6.43G, req 0.01G)
I0801 13:29:15.952899  3162 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 1.29G/1 6 4 3  (limit 6.34G, req 0.01G)
I0801 13:29:15.955171  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 1.29G/1 6 4 3  (limit 6.43G, req 0.01G)
I0801 13:29:15.955700  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 1.29G/1 6 4 3  (limit 6.43G, req 0.01G)
I0801 13:29:15.960572  3162 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 1.29G/2 6 4 3  (limit 6.34G, req 0.01G)
I0801 13:29:15.962363  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 1.29G/2 6 4 3  (limit 6.43G, req 0.01G)
I0801 13:29:15.962921  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 1.29G/2 6 4 3  (limit 6.43G, req 0.01G)
I0801 13:29:15.970629  3162 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 1.29G/1 6 4 5  (limit 6.34G, req 0.01G)
I0801 13:29:15.972206  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 1.29G/1 6 4 5  (limit 6.43G, req 0.01G)
I0801 13:29:15.972919  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 1.29G/1 6 4 5  (limit 6.43G, req 0.01G)
I0801 13:29:15.975869  3162 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 1.29G/2 6 4 0  (limit 6.34G, req 0.01G)
I0801 13:29:15.977636  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 1.29G/2 6 4 3  (limit 6.43G, req 0.01G)
I0801 13:29:15.978096  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 1.29G/2 6 4 0  (limit 6.43G, req 0.01G)
I0801 13:29:16.001245  3162 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 1.29G/1 6 4 5  (limit 6.34G, req 0.02G)
I0801 13:29:16.003756  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 1.29G/1 6 4 5  (limit 6.43G, req 0.02G)
I0801 13:29:16.004195  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 1.29G/1 6 4 5  (limit 6.43G, req 0.02G)
I0801 13:29:16.009896  3162 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 1.29G/2 6 4 3  (limit 6.34G, req 0.02G)
I0801 13:29:16.011837  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 1.29G/2 6 4 3  (limit 6.43G, req 0.02G)
I0801 13:29:16.012176  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 1.29G/2 6 4 3  (limit 6.43G, req 0.02G)
I0801 13:29:16.046934  3162 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 1.29G/1 7 5 5  (limit 6.34G, req 0.03G)
I0801 13:29:16.050330  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 1.29G/1 7 5 5  (limit 6.43G, req 0.03G)
I0801 13:29:16.050546  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 1.29G/1 7 5 5  (limit 6.43G, req 0.03G)
I0801 13:29:16.055833  3162 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 1.29G/2 6 4 5  (limit 6.34G, req 0.03G)
I0801 13:29:16.059402  3164 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 1.29G/2 6 4 5  (limit 6.43G, req 0.03G)
I0801 13:29:16.059744  3163 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 1.29G/2 6 4 5  (limit 6.43G, req 0.03G)
I0801 13:29:16.077657  3162 solver.cpp:358] Iteration 2 (0.158173 s), loss = 0.000399625
I0801 13:29:16.077674  3162 solver.cpp:375]     Train net output #0: loss = 0.000399625 (* 1 = 0.000399625 loss)
I0801 13:29:16.077690  3163 cudnn_conv_layer.cpp:292] [1] Layer 'conv1a' reallocating workspace: 1.29G -> 0.07G
I0801 13:29:16.077702  3162 cudnn_conv_layer.cpp:292] [0] Layer 'conv1a' reallocating workspace: 1.29G -> 0.07G
I0801 13:29:16.077852  3164 cudnn_conv_layer.cpp:292] [2] Layer 'conv1a' reallocating workspace: 1.29G -> 0.07G
I0801 13:29:17.624125  3162 solver.cpp:353] Iteration 100 (63.3722 iter/s, 1.54642s/98 iter), loss = 0.000982303
I0801 13:29:17.624174  3162 solver.cpp:375]     Train net output #0: loss = 0.000982303 (* 1 = 0.000982303 loss)
I0801 13:29:17.624188  3162 sgd_solver.cpp:136] Iteration 100, lr = 0.00998437, m = 0.9
I0801 13:29:19.204876  3162 solver.cpp:353] Iteration 200 (63.2631 iter/s, 1.5807s/100 iter), loss = 0.00218474
I0801 13:29:19.204944  3162 solver.cpp:375]     Train net output #0: loss = 0.00218474 (* 1 = 0.00218474 loss)
I0801 13:29:19.204962  3162 sgd_solver.cpp:136] Iteration 200, lr = 0.00996875, m = 0.9
I0801 13:29:20.789155  3162 solver.cpp:353] Iteration 300 (63.1223 iter/s, 1.58423s/100 iter), loss = 0.000952938
I0801 13:29:20.789180  3162 solver.cpp:375]     Train net output #0: loss = 0.000952939 (* 1 = 0.000952939 loss)
I0801 13:29:20.789186  3162 sgd_solver.cpp:136] Iteration 300, lr = 0.00995312, m = 0.9
I0801 13:29:22.380322  3162 solver.cpp:353] Iteration 400 (62.8489 iter/s, 1.59112s/100 iter), loss = 0.000873645
I0801 13:29:22.380347  3162 solver.cpp:375]     Train net output #0: loss = 0.000873646 (* 1 = 0.000873646 loss)
I0801 13:29:22.380352  3162 sgd_solver.cpp:136] Iteration 400, lr = 0.0099375, m = 0.9
I0801 13:29:23.970485  3162 solver.cpp:353] Iteration 500 (62.8887 iter/s, 1.59011s/100 iter), loss = 0.00223915
I0801 13:29:23.970546  3162 solver.cpp:375]     Train net output #0: loss = 0.00223915 (* 1 = 0.00223915 loss)
I0801 13:29:23.970562  3162 sgd_solver.cpp:136] Iteration 500, lr = 0.00992187, m = 0.9
I0801 13:29:25.554164  3162 solver.cpp:353] Iteration 600 (63.1461 iter/s, 1.58363s/100 iter), loss = 0.00193867
I0801 13:29:25.554217  3162 solver.cpp:375]     Train net output #0: loss = 0.00193867 (* 1 = 0.00193867 loss)
I0801 13:29:25.554235  3162 sgd_solver.cpp:136] Iteration 600, lr = 0.00990625, m = 0.9
I0801 13:29:27.123188  3162 solver.cpp:353] Iteration 700 (63.736 iter/s, 1.56897s/100 iter), loss = 0.00019915
I0801 13:29:27.123217  3162 solver.cpp:375]     Train net output #0: loss = 0.000199149 (* 1 = 0.000199149 loss)
I0801 13:29:27.123224  3162 sgd_solver.cpp:136] Iteration 700, lr = 0.00989062, m = 0.9
I0801 13:29:27.981598  3155 data_reader.cpp:264] Starting prefetch of epoch 1
I0801 13:29:28.704540  3162 solver.cpp:353] Iteration 800 (63.2391 iter/s, 1.5813s/100 iter), loss = 0.00237601
I0801 13:29:28.704565  3162 solver.cpp:375]     Train net output #0: loss = 0.00237601 (* 1 = 0.00237601 loss)
I0801 13:29:28.704571  3162 sgd_solver.cpp:136] Iteration 800, lr = 0.009875, m = 0.9
I0801 13:29:30.273176  3162 solver.cpp:353] Iteration 900 (63.7515 iter/s, 1.56859s/100 iter), loss = 0.000469317
I0801 13:29:30.273201  3162 solver.cpp:375]     Train net output #0: loss = 0.000469317 (* 1 = 0.000469317 loss)
I0801 13:29:30.273207  3162 sgd_solver.cpp:136] Iteration 900, lr = 0.00985937, m = 0.9
I0801 13:29:31.825103  3162 solver.cpp:550] Iteration 1000, Testing net (#0)
I0801 13:29:32.669004  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.914707
I0801 13:29:32.669023  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.995588
I0801 13:29:32.669028  3162 solver.cpp:635]     Test net output #2: loss = 0.312955 (* 1 = 0.312955 loss)
I0801 13:29:32.669044  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.843918s
I0801 13:29:32.685055  3162 solver.cpp:353] Iteration 1000 (41.4627 iter/s, 2.41181s/100 iter), loss = 0.00061575
I0801 13:29:32.685073  3162 solver.cpp:375]     Train net output #0: loss = 0.00061575 (* 1 = 0.00061575 loss)
I0801 13:29:32.685079  3162 sgd_solver.cpp:136] Iteration 1000, lr = 0.00984375, m = 0.9
I0801 13:29:34.262768  3162 solver.cpp:353] Iteration 1100 (63.3849 iter/s, 1.57766s/100 iter), loss = 0.000395793
I0801 13:29:34.262815  3162 solver.cpp:375]     Train net output #0: loss = 0.000395793 (* 1 = 0.000395793 loss)
I0801 13:29:34.262830  3162 sgd_solver.cpp:136] Iteration 1100, lr = 0.00982813, m = 0.9
I0801 13:29:35.834139  3162 solver.cpp:353] Iteration 1200 (63.6406 iter/s, 1.57132s/100 iter), loss = 0.00133903
I0801 13:29:35.834162  3162 solver.cpp:375]     Train net output #0: loss = 0.00133903 (* 1 = 0.00133903 loss)
I0801 13:29:35.834167  3162 sgd_solver.cpp:136] Iteration 1200, lr = 0.0098125, m = 0.9
I0801 13:29:37.398190  3162 solver.cpp:353] Iteration 1300 (63.9386 iter/s, 1.564s/100 iter), loss = 0.000768105
I0801 13:29:37.398217  3162 solver.cpp:375]     Train net output #0: loss = 0.000768105 (* 1 = 0.000768105 loss)
I0801 13:29:37.398224  3162 sgd_solver.cpp:136] Iteration 1300, lr = 0.00979687, m = 0.9
I0801 13:29:38.973649  3162 solver.cpp:353] Iteration 1400 (63.4756 iter/s, 1.57541s/100 iter), loss = 0.00120894
I0801 13:29:38.973671  3162 solver.cpp:375]     Train net output #0: loss = 0.00120894 (* 1 = 0.00120894 loss)
I0801 13:29:38.973676  3162 sgd_solver.cpp:136] Iteration 1400, lr = 0.00978125, m = 0.9
I0801 13:29:40.540851  3162 solver.cpp:353] Iteration 1500 (63.8101 iter/s, 1.56715s/100 iter), loss = 0.000604387
I0801 13:29:40.540880  3162 solver.cpp:375]     Train net output #0: loss = 0.000604387 (* 1 = 0.000604387 loss)
I0801 13:29:40.540887  3162 sgd_solver.cpp:136] Iteration 1500, lr = 0.00976562, m = 0.9
I0801 13:29:42.120851  3162 solver.cpp:353] Iteration 1600 (63.2932 iter/s, 1.57995s/100 iter), loss = 0.000616028
I0801 13:29:42.120874  3162 solver.cpp:375]     Train net output #0: loss = 0.000616028 (* 1 = 0.000616028 loss)
I0801 13:29:42.120880  3162 sgd_solver.cpp:136] Iteration 1600, lr = 0.00975, m = 0.9
I0801 13:29:43.689839  3162 solver.cpp:353] Iteration 1700 (63.7373 iter/s, 1.56894s/100 iter), loss = 0.000947564
I0801 13:29:43.689863  3162 solver.cpp:375]     Train net output #0: loss = 0.000947564 (* 1 = 0.000947564 loss)
I0801 13:29:43.689869  3162 sgd_solver.cpp:136] Iteration 1700, lr = 0.00973437, m = 0.9
I0801 13:29:45.301298  3162 solver.cpp:353] Iteration 1800 (62.0575 iter/s, 1.61141s/100 iter), loss = 0.00104569
I0801 13:29:45.301399  3162 solver.cpp:375]     Train net output #0: loss = 0.00104569 (* 1 = 0.00104569 loss)
I0801 13:29:45.301406  3162 sgd_solver.cpp:136] Iteration 1800, lr = 0.00971875, m = 0.9
I0801 13:29:46.870904  3162 solver.cpp:353] Iteration 1900 (63.7122 iter/s, 1.56956s/100 iter), loss = 0.00066838
I0801 13:29:46.870931  3162 solver.cpp:375]     Train net output #0: loss = 0.000668379 (* 1 = 0.000668379 loss)
I0801 13:29:46.870936  3162 sgd_solver.cpp:136] Iteration 1900, lr = 0.00970312, m = 0.9
I0801 13:29:48.420970  3162 solver.cpp:550] Iteration 2000, Testing net (#0)
I0801 13:29:49.259698  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.913824
I0801 13:29:49.259716  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996177
I0801 13:29:49.259722  3162 solver.cpp:635]     Test net output #2: loss = 0.30619 (* 1 = 0.30619 loss)
I0801 13:29:49.259739  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.838746s
I0801 13:29:49.277870  3162 solver.cpp:353] Iteration 2000 (41.5473 iter/s, 2.40689s/100 iter), loss = 0.0005338
I0801 13:29:49.277899  3162 solver.cpp:375]     Train net output #0: loss = 0.0005338 (* 1 = 0.0005338 loss)
I0801 13:29:49.277904  3162 sgd_solver.cpp:136] Iteration 2000, lr = 0.0096875, m = 0.9
I0801 13:29:50.858700  3162 solver.cpp:353] Iteration 2100 (63.26 iter/s, 1.58078s/100 iter), loss = 0.000777376
I0801 13:29:50.858726  3162 solver.cpp:375]     Train net output #0: loss = 0.000777376 (* 1 = 0.000777376 loss)
I0801 13:29:50.858732  3162 sgd_solver.cpp:136] Iteration 2100, lr = 0.00967188, m = 0.9
I0801 13:29:52.425135  3162 solver.cpp:353] Iteration 2200 (63.8412 iter/s, 1.56639s/100 iter), loss = 0.00101096
I0801 13:29:52.425160  3162 solver.cpp:375]     Train net output #0: loss = 0.00101096 (* 1 = 0.00101096 loss)
I0801 13:29:52.425165  3162 sgd_solver.cpp:136] Iteration 2200, lr = 0.00965625, m = 0.9
I0801 13:29:53.997603  3162 solver.cpp:353] Iteration 2300 (63.5964 iter/s, 1.57242s/100 iter), loss = 0.000499038
I0801 13:29:53.997629  3162 solver.cpp:375]     Train net output #0: loss = 0.000499037 (* 1 = 0.000499037 loss)
I0801 13:29:53.997635  3162 sgd_solver.cpp:136] Iteration 2300, lr = 0.00964062, m = 0.9
I0801 13:29:55.571142  3162 solver.cpp:353] Iteration 2400 (63.5529 iter/s, 1.57349s/100 iter), loss = 0.000929002
I0801 13:29:55.571204  3162 solver.cpp:375]     Train net output #0: loss = 0.000929001 (* 1 = 0.000929001 loss)
I0801 13:29:55.571224  3162 sgd_solver.cpp:136] Iteration 2400, lr = 0.009625, m = 0.9
I0801 13:29:57.142524  3162 solver.cpp:353] Iteration 2500 (63.6403 iter/s, 1.57133s/100 iter), loss = 0.00106055
I0801 13:29:57.142551  3162 solver.cpp:375]     Train net output #0: loss = 0.00106055 (* 1 = 0.00106055 loss)
I0801 13:29:57.142556  3162 sgd_solver.cpp:136] Iteration 2500, lr = 0.00960938, m = 0.9
I0801 13:29:58.714123  3162 solver.cpp:353] Iteration 2600 (63.6315 iter/s, 1.57155s/100 iter), loss = 0.000959743
I0801 13:29:58.714146  3162 solver.cpp:375]     Train net output #0: loss = 0.000959743 (* 1 = 0.000959743 loss)
I0801 13:29:58.714150  3162 sgd_solver.cpp:136] Iteration 2600, lr = 0.00959375, m = 0.9
I0801 13:30:00.308389  3162 solver.cpp:353] Iteration 2700 (62.7266 iter/s, 1.59422s/100 iter), loss = 0.000694996
I0801 13:30:00.308413  3162 solver.cpp:375]     Train net output #0: loss = 0.000694996 (* 1 = 0.000694996 loss)
I0801 13:30:00.308420  3162 sgd_solver.cpp:136] Iteration 2700, lr = 0.00957812, m = 0.9
I0801 13:30:01.866765  3162 solver.cpp:353] Iteration 2800 (64.1714 iter/s, 1.55833s/100 iter), loss = 0.000510695
I0801 13:30:01.866791  3162 solver.cpp:375]     Train net output #0: loss = 0.000510694 (* 1 = 0.000510694 loss)
I0801 13:30:01.866796  3162 sgd_solver.cpp:136] Iteration 2800, lr = 0.0095625, m = 0.9
I0801 13:30:03.448011  3162 solver.cpp:353] Iteration 2900 (63.2433 iter/s, 1.58119s/100 iter), loss = 0.00111062
I0801 13:30:03.448037  3162 solver.cpp:375]     Train net output #0: loss = 0.00111062 (* 1 = 0.00111062 loss)
I0801 13:30:03.448042  3162 sgd_solver.cpp:136] Iteration 2900, lr = 0.00954687, m = 0.9
I0801 13:30:05.013067  3162 solver.cpp:550] Iteration 3000, Testing net (#0)
I0801 13:30:05.848307  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.920883
I0801 13:30:05.848325  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.995882
I0801 13:30:05.848332  3162 solver.cpp:635]     Test net output #2: loss = 0.289071 (* 1 = 0.289071 loss)
I0801 13:30:05.848352  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.83526s
I0801 13:30:05.864193  3162 solver.cpp:353] Iteration 3000 (41.3889 iter/s, 2.41611s/100 iter), loss = 0.00152305
I0801 13:30:05.864223  3162 solver.cpp:375]     Train net output #0: loss = 0.00152305 (* 1 = 0.00152305 loss)
I0801 13:30:05.864228  3162 sgd_solver.cpp:136] Iteration 3000, lr = 0.00953125, m = 0.9
I0801 13:30:07.439182  3162 solver.cpp:353] Iteration 3100 (63.4945 iter/s, 1.57494s/100 iter), loss = 0.000504059
I0801 13:30:07.439211  3162 solver.cpp:375]     Train net output #0: loss = 0.000504058 (* 1 = 0.000504058 loss)
I0801 13:30:07.439218  3162 sgd_solver.cpp:136] Iteration 3100, lr = 0.00951563, m = 0.9
I0801 13:30:09.006346  3162 solver.cpp:353] Iteration 3200 (63.8116 iter/s, 1.56711s/100 iter), loss = 0.000869849
I0801 13:30:09.006373  3162 solver.cpp:375]     Train net output #0: loss = 0.000869849 (* 1 = 0.000869849 loss)
I0801 13:30:09.006381  3162 sgd_solver.cpp:136] Iteration 3200, lr = 0.0095, m = 0.9
I0801 13:30:10.567947  3162 solver.cpp:353] Iteration 3300 (64.0389 iter/s, 1.56155s/100 iter), loss = 0.00133201
I0801 13:30:10.567973  3162 solver.cpp:375]     Train net output #0: loss = 0.00133201 (* 1 = 0.00133201 loss)
I0801 13:30:10.567980  3162 sgd_solver.cpp:136] Iteration 3300, lr = 0.00948437, m = 0.9
I0801 13:30:12.153888  3162 solver.cpp:353] Iteration 3400 (63.056 iter/s, 1.58589s/100 iter), loss = 0.000910939
I0801 13:30:12.153916  3162 solver.cpp:375]     Train net output #0: loss = 0.000910938 (* 1 = 0.000910938 loss)
I0801 13:30:12.153923  3162 sgd_solver.cpp:136] Iteration 3400, lr = 0.00946875, m = 0.9
I0801 13:30:13.738107  3162 solver.cpp:353] Iteration 3500 (63.1246 iter/s, 1.58417s/100 iter), loss = 0.00133019
I0801 13:30:13.738154  3162 solver.cpp:375]     Train net output #0: loss = 0.00133019 (* 1 = 0.00133019 loss)
I0801 13:30:13.738168  3162 sgd_solver.cpp:136] Iteration 3500, lr = 0.00945312, m = 0.9
I0801 13:30:15.335289  3162 solver.cpp:353] Iteration 3600 (62.6123 iter/s, 1.59713s/100 iter), loss = 0.000561474
I0801 13:30:15.335400  3162 solver.cpp:375]     Train net output #0: loss = 0.000561474 (* 1 = 0.000561474 loss)
I0801 13:30:15.335409  3162 sgd_solver.cpp:136] Iteration 3600, lr = 0.0094375, m = 0.9
I0801 13:30:16.904639  3162 solver.cpp:353] Iteration 3700 (63.7227 iter/s, 1.5693s/100 iter), loss = 0.00135393
I0801 13:30:16.904666  3162 solver.cpp:375]     Train net output #0: loss = 0.00135393 (* 1 = 0.00135393 loss)
I0801 13:30:16.904673  3162 sgd_solver.cpp:136] Iteration 3700, lr = 0.00942187, m = 0.9
I0801 13:30:18.476472  3162 solver.cpp:353] Iteration 3800 (63.6221 iter/s, 1.57178s/100 iter), loss = 0.00134666
I0801 13:30:18.476498  3162 solver.cpp:375]     Train net output #0: loss = 0.00134667 (* 1 = 0.00134667 loss)
I0801 13:30:18.476505  3162 sgd_solver.cpp:136] Iteration 3800, lr = 0.00940625, m = 0.9
I0801 13:30:20.048913  3162 solver.cpp:353] Iteration 3900 (63.5974 iter/s, 1.57239s/100 iter), loss = 0.00127371
I0801 13:30:20.048939  3162 solver.cpp:375]     Train net output #0: loss = 0.00127371 (* 1 = 0.00127371 loss)
I0801 13:30:20.048945  3162 sgd_solver.cpp:136] Iteration 3900, lr = 0.00939062, m = 0.9
I0801 13:30:21.598333  3162 solver.cpp:550] Iteration 4000, Testing net (#0)
I0801 13:30:22.435119  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.923824
I0801 13:30:22.435140  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996471
I0801 13:30:22.435147  3162 solver.cpp:635]     Test net output #2: loss = 0.265277 (* 1 = 0.265277 loss)
I0801 13:30:22.435166  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.836807s
I0801 13:30:22.455036  3162 solver.cpp:353] Iteration 4000 (41.5618 iter/s, 2.40605s/100 iter), loss = 0.00138526
I0801 13:30:22.455054  3162 solver.cpp:375]     Train net output #0: loss = 0.00138526 (* 1 = 0.00138526 loss)
I0801 13:30:22.455060  3162 sgd_solver.cpp:136] Iteration 4000, lr = 0.009375, m = 0.9
I0801 13:30:24.024078  3162 solver.cpp:353] Iteration 4100 (63.7354 iter/s, 1.56899s/100 iter), loss = 0.000911294
I0801 13:30:24.024147  3162 solver.cpp:375]     Train net output #0: loss = 0.000911294 (* 1 = 0.000911294 loss)
I0801 13:30:24.024168  3162 sgd_solver.cpp:136] Iteration 4100, lr = 0.00935937, m = 0.9
I0801 13:30:25.591672  3162 solver.cpp:353] Iteration 4200 (63.794 iter/s, 1.56755s/100 iter), loss = 0.00114406
I0801 13:30:25.591697  3162 solver.cpp:375]     Train net output #0: loss = 0.00114406 (* 1 = 0.00114406 loss)
I0801 13:30:25.591703  3162 sgd_solver.cpp:136] Iteration 4200, lr = 0.00934375, m = 0.9
I0801 13:30:27.170917  3162 solver.cpp:353] Iteration 4300 (63.3233 iter/s, 1.5792s/100 iter), loss = 0.00143925
I0801 13:30:27.170967  3162 solver.cpp:375]     Train net output #0: loss = 0.00143925 (* 1 = 0.00143925 loss)
I0801 13:30:27.170979  3162 sgd_solver.cpp:136] Iteration 4300, lr = 0.00932813, m = 0.9
I0801 13:30:28.759378  3162 solver.cpp:353] Iteration 4400 (62.956 iter/s, 1.58841s/100 iter), loss = 0.00203717
I0801 13:30:28.759402  3162 solver.cpp:375]     Train net output #0: loss = 0.00203717 (* 1 = 0.00203717 loss)
I0801 13:30:28.759407  3162 sgd_solver.cpp:136] Iteration 4400, lr = 0.0093125, m = 0.9
I0801 13:30:30.325217  3162 solver.cpp:353] Iteration 4500 (63.8655 iter/s, 1.56579s/100 iter), loss = 0.00106383
I0801 13:30:30.325242  3162 solver.cpp:375]     Train net output #0: loss = 0.00106382 (* 1 = 0.00106382 loss)
I0801 13:30:30.325248  3162 sgd_solver.cpp:136] Iteration 4500, lr = 0.00929687, m = 0.9
I0801 13:30:31.888751  3162 solver.cpp:353] Iteration 4600 (63.9597 iter/s, 1.56349s/100 iter), loss = 0.0003711
I0801 13:30:31.888775  3162 solver.cpp:375]     Train net output #0: loss = 0.0003711 (* 1 = 0.0003711 loss)
I0801 13:30:31.888782  3162 sgd_solver.cpp:136] Iteration 4600, lr = 0.00928125, m = 0.9
I0801 13:30:33.469310  3162 solver.cpp:353] Iteration 4700 (63.2709 iter/s, 1.58051s/100 iter), loss = 0.0027463
I0801 13:30:33.469377  3162 solver.cpp:375]     Train net output #0: loss = 0.0027463 (* 1 = 0.0027463 loss)
I0801 13:30:33.469396  3162 sgd_solver.cpp:136] Iteration 4700, lr = 0.00926562, m = 0.9
I0801 13:30:35.045347  3162 solver.cpp:353] Iteration 4800 (63.4522 iter/s, 1.57599s/100 iter), loss = 0.000925855
I0801 13:30:35.045372  3162 solver.cpp:375]     Train net output #0: loss = 0.000925854 (* 1 = 0.000925854 loss)
I0801 13:30:35.045377  3162 sgd_solver.cpp:136] Iteration 4800, lr = 0.00925, m = 0.9
I0801 13:30:36.620357  3162 solver.cpp:353] Iteration 4900 (63.4937 iter/s, 1.57496s/100 iter), loss = 0.00101231
I0801 13:30:36.620406  3162 solver.cpp:375]     Train net output #0: loss = 0.0010123 (* 1 = 0.0010123 loss)
I0801 13:30:36.620415  3162 sgd_solver.cpp:136] Iteration 4900, lr = 0.00923437, m = 0.9
I0801 13:30:38.198106  3162 solver.cpp:550] Iteration 5000, Testing net (#0)
I0801 13:30:38.886670  3160 data_reader.cpp:264] Starting prefetch of epoch 1
I0801 13:30:39.039919  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.926177
I0801 13:30:39.039939  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996765
I0801 13:30:39.039947  3162 solver.cpp:635]     Test net output #2: loss = 0.25179 (* 1 = 0.25179 loss)
I0801 13:30:39.039964  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.841835s
I0801 13:30:39.055541  3162 solver.cpp:353] Iteration 5000 (41.0659 iter/s, 2.43511s/100 iter), loss = 0.0011585
I0801 13:30:39.055572  3162 solver.cpp:375]     Train net output #0: loss = 0.0011585 (* 1 = 0.0011585 loss)
I0801 13:30:39.055584  3162 sgd_solver.cpp:136] Iteration 5000, lr = 0.00921875, m = 0.9
I0801 13:30:40.632364  3162 solver.cpp:353] Iteration 5100 (63.4208 iter/s, 1.57677s/100 iter), loss = 0.00159239
I0801 13:30:40.632417  3162 solver.cpp:375]     Train net output #0: loss = 0.00159239 (* 1 = 0.00159239 loss)
I0801 13:30:40.632431  3162 sgd_solver.cpp:136] Iteration 5100, lr = 0.00920312, m = 0.9
I0801 13:30:42.203094  3162 solver.cpp:353] Iteration 5200 (63.6667 iter/s, 1.57068s/100 iter), loss = 0.00243349
I0801 13:30:42.203146  3162 solver.cpp:375]     Train net output #0: loss = 0.00243349 (* 1 = 0.00243349 loss)
I0801 13:30:42.203161  3162 sgd_solver.cpp:136] Iteration 5200, lr = 0.0091875, m = 0.9
I0801 13:30:43.778520  3162 solver.cpp:353] Iteration 5300 (63.4768 iter/s, 1.57538s/100 iter), loss = 0.00206227
I0801 13:30:43.778548  3162 solver.cpp:375]     Train net output #0: loss = 0.00206227 (* 1 = 0.00206227 loss)
I0801 13:30:43.778553  3162 sgd_solver.cpp:136] Iteration 5300, lr = 0.00917188, m = 0.9
I0801 13:30:45.374445  3162 solver.cpp:353] Iteration 5400 (62.6615 iter/s, 1.59588s/100 iter), loss = 0.000611016
I0801 13:30:45.374569  3162 solver.cpp:375]     Train net output #0: loss = 0.000611015 (* 1 = 0.000611015 loss)
I0801 13:30:45.374588  3162 sgd_solver.cpp:136] Iteration 5400, lr = 0.00915625, m = 0.9
I0801 13:30:46.934321  3162 solver.cpp:353] Iteration 5500 (64.1097 iter/s, 1.55983s/100 iter), loss = 0.000581691
I0801 13:30:46.934367  3162 solver.cpp:375]     Train net output #0: loss = 0.000581689 (* 1 = 0.000581689 loss)
I0801 13:30:46.934375  3162 sgd_solver.cpp:136] Iteration 5500, lr = 0.00914062, m = 0.9
I0801 13:30:48.504204  3162 solver.cpp:353] Iteration 5600 (63.7011 iter/s, 1.56983s/100 iter), loss = 0.00248146
I0801 13:30:48.504253  3162 solver.cpp:375]     Train net output #0: loss = 0.00248145 (* 1 = 0.00248145 loss)
I0801 13:30:48.504266  3162 sgd_solver.cpp:136] Iteration 5600, lr = 0.009125, m = 0.9
I0801 13:30:50.088028  3162 solver.cpp:353] Iteration 5700 (63.1403 iter/s, 1.58378s/100 iter), loss = 0.000499506
I0801 13:30:50.088093  3162 solver.cpp:375]     Train net output #0: loss = 0.000499505 (* 1 = 0.000499505 loss)
I0801 13:30:50.088114  3162 sgd_solver.cpp:136] Iteration 5700, lr = 0.00910938, m = 0.9
I0801 13:30:51.657032  3162 solver.cpp:353] Iteration 5800 (63.7368 iter/s, 1.56895s/100 iter), loss = 0.000713967
I0801 13:30:51.657096  3162 solver.cpp:375]     Train net output #0: loss = 0.000713966 (* 1 = 0.000713966 loss)
I0801 13:30:51.657115  3162 sgd_solver.cpp:136] Iteration 5800, lr = 0.00909375, m = 0.9
I0801 13:30:53.242010  3162 solver.cpp:353] Iteration 5900 (63.0944 iter/s, 1.58493s/100 iter), loss = 0.00209601
I0801 13:30:53.242034  3162 solver.cpp:375]     Train net output #0: loss = 0.00209601 (* 1 = 0.00209601 loss)
I0801 13:30:53.242038  3162 sgd_solver.cpp:136] Iteration 5900, lr = 0.00907812, m = 0.9
I0801 13:30:54.810497  3162 solver.cpp:550] Iteration 6000, Testing net (#0)
I0801 13:30:55.645879  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.925001
I0801 13:30:55.645901  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996765
I0801 13:30:55.645907  3162 solver.cpp:635]     Test net output #2: loss = 0.254283 (* 1 = 0.254283 loss)
I0801 13:30:55.646004  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.835483s
I0801 13:30:55.661891  3162 solver.cpp:353] Iteration 6000 (41.3255 iter/s, 2.41981s/100 iter), loss = 0.000416732
I0801 13:30:55.661911  3162 solver.cpp:375]     Train net output #0: loss = 0.000416731 (* 1 = 0.000416731 loss)
I0801 13:30:55.661916  3162 sgd_solver.cpp:136] Iteration 6000, lr = 0.0090625, m = 0.9
I0801 13:30:57.245215  3162 solver.cpp:353] Iteration 6100 (63.1604 iter/s, 1.58327s/100 iter), loss = 0.00303363
I0801 13:30:57.245240  3162 solver.cpp:375]     Train net output #0: loss = 0.00303363 (* 1 = 0.00303363 loss)
I0801 13:30:57.245246  3162 sgd_solver.cpp:136] Iteration 6100, lr = 0.00904687, m = 0.9
I0801 13:30:58.834581  3162 solver.cpp:353] Iteration 6200 (62.9201 iter/s, 1.58932s/100 iter), loss = 0.00108963
I0801 13:30:58.834609  3162 solver.cpp:375]     Train net output #0: loss = 0.00108962 (* 1 = 0.00108962 loss)
I0801 13:30:58.834614  3162 sgd_solver.cpp:136] Iteration 6200, lr = 0.00903125, m = 0.9
I0801 13:31:00.420506  3162 solver.cpp:353] Iteration 6300 (63.0566 iter/s, 1.58588s/100 iter), loss = 0.000840407
I0801 13:31:00.420531  3162 solver.cpp:375]     Train net output #0: loss = 0.000840406 (* 1 = 0.000840406 loss)
I0801 13:31:00.420537  3162 sgd_solver.cpp:136] Iteration 6300, lr = 0.00901563, m = 0.9
I0801 13:31:01.976672  3162 solver.cpp:353] Iteration 6400 (64.2626 iter/s, 1.55612s/100 iter), loss = 0.00129467
I0801 13:31:01.976723  3162 solver.cpp:375]     Train net output #0: loss = 0.00129467 (* 1 = 0.00129467 loss)
I0801 13:31:01.976738  3162 sgd_solver.cpp:136] Iteration 6400, lr = 0.009, m = 0.9
I0801 13:31:03.538628  3162 solver.cpp:353] Iteration 6500 (64.0243 iter/s, 1.56191s/100 iter), loss = 0.00221487
I0801 13:31:03.538693  3162 solver.cpp:375]     Train net output #0: loss = 0.00221487 (* 1 = 0.00221487 loss)
I0801 13:31:03.538712  3162 sgd_solver.cpp:136] Iteration 6500, lr = 0.00898437, m = 0.9
I0801 13:31:05.105468  3162 solver.cpp:353] Iteration 6600 (63.8247 iter/s, 1.56679s/100 iter), loss = 0.00145209
I0801 13:31:05.105492  3162 solver.cpp:375]     Train net output #0: loss = 0.00145209 (* 1 = 0.00145209 loss)
I0801 13:31:05.105499  3162 sgd_solver.cpp:136] Iteration 6600, lr = 0.00896875, m = 0.9
I0801 13:31:06.667665  3162 solver.cpp:353] Iteration 6700 (64.0145 iter/s, 1.56215s/100 iter), loss = 0.000583105
I0801 13:31:06.667691  3162 solver.cpp:375]     Train net output #0: loss = 0.000583104 (* 1 = 0.000583104 loss)
I0801 13:31:06.667695  3162 sgd_solver.cpp:136] Iteration 6700, lr = 0.00895312, m = 0.9
I0801 13:31:08.237725  3162 solver.cpp:353] Iteration 6800 (63.6937 iter/s, 1.57001s/100 iter), loss = 0.000802125
I0801 13:31:08.237751  3162 solver.cpp:375]     Train net output #0: loss = 0.000802125 (* 1 = 0.000802125 loss)
I0801 13:31:08.237756  3162 sgd_solver.cpp:136] Iteration 6800, lr = 0.0089375, m = 0.9
I0801 13:31:09.803293  3162 solver.cpp:353] Iteration 6900 (63.8766 iter/s, 1.56552s/100 iter), loss = 0.000980888
I0801 13:31:09.803323  3162 solver.cpp:375]     Train net output #0: loss = 0.000980888 (* 1 = 0.000980888 loss)
I0801 13:31:09.803329  3162 sgd_solver.cpp:136] Iteration 6900, lr = 0.00892187, m = 0.9
I0801 13:31:11.366915  3162 solver.cpp:550] Iteration 7000, Testing net (#0)
I0801 13:31:12.204002  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.925001
I0801 13:31:12.204021  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996765
I0801 13:31:12.204027  3162 solver.cpp:635]     Test net output #2: loss = 0.265721 (* 1 = 0.265721 loss)
I0801 13:31:12.204041  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.837104s
I0801 13:31:12.219604  3162 solver.cpp:353] Iteration 7000 (41.3866 iter/s, 2.41624s/100 iter), loss = 0.00175226
I0801 13:31:12.219621  3162 solver.cpp:375]     Train net output #0: loss = 0.00175226 (* 1 = 0.00175226 loss)
I0801 13:31:12.219625  3162 sgd_solver.cpp:136] Iteration 7000, lr = 0.00890625, m = 0.9
I0801 13:31:13.781908  3162 solver.cpp:353] Iteration 7100 (64.0101 iter/s, 1.56225s/100 iter), loss = 0.00102344
I0801 13:31:13.781971  3162 solver.cpp:375]     Train net output #0: loss = 0.00102344 (* 1 = 0.00102344 loss)
I0801 13:31:13.781991  3162 sgd_solver.cpp:136] Iteration 7100, lr = 0.00889063, m = 0.9
I0801 13:31:15.354163  3162 solver.cpp:353] Iteration 7200 (63.6049 iter/s, 1.57221s/100 iter), loss = 0.00190367
I0801 13:31:15.354188  3162 solver.cpp:375]     Train net output #0: loss = 0.00190367 (* 1 = 0.00190367 loss)
I0801 13:31:15.354194  3162 sgd_solver.cpp:136] Iteration 7200, lr = 0.008875, m = 0.9
I0801 13:31:16.917906  3162 solver.cpp:353] Iteration 7300 (63.9512 iter/s, 1.56369s/100 iter), loss = 0.0014461
I0801 13:31:16.917965  3162 solver.cpp:375]     Train net output #0: loss = 0.0014461 (* 1 = 0.0014461 loss)
I0801 13:31:16.917973  3162 sgd_solver.cpp:136] Iteration 7300, lr = 0.00885937, m = 0.9
I0801 13:31:18.500180  3162 solver.cpp:353] Iteration 7400 (63.2021 iter/s, 1.58223s/100 iter), loss = 0.00140969
I0801 13:31:18.500228  3162 solver.cpp:375]     Train net output #0: loss = 0.00140969 (* 1 = 0.00140969 loss)
I0801 13:31:18.500244  3162 sgd_solver.cpp:136] Iteration 7400, lr = 0.00884375, m = 0.9
I0801 13:31:20.082496  3162 solver.cpp:353] Iteration 7500 (63.2005 iter/s, 1.58227s/100 iter), loss = 0.000922829
I0801 13:31:20.082522  3162 solver.cpp:375]     Train net output #0: loss = 0.000922827 (* 1 = 0.000922827 loss)
I0801 13:31:20.082530  3162 sgd_solver.cpp:136] Iteration 7500, lr = 0.00882812, m = 0.9
I0801 13:31:21.657436  3162 solver.cpp:353] Iteration 7600 (63.4965 iter/s, 1.57489s/100 iter), loss = 0.00206065
I0801 13:31:21.657461  3162 solver.cpp:375]     Train net output #0: loss = 0.00206065 (* 1 = 0.00206065 loss)
I0801 13:31:21.657467  3162 sgd_solver.cpp:136] Iteration 7600, lr = 0.0088125, m = 0.9
I0801 13:31:23.219352  3162 solver.cpp:353] Iteration 7700 (64.0259 iter/s, 1.56187s/100 iter), loss = 0.000426825
I0801 13:31:23.219415  3162 solver.cpp:375]     Train net output #0: loss = 0.000426824 (* 1 = 0.000426824 loss)
I0801 13:31:23.219436  3162 sgd_solver.cpp:136] Iteration 7700, lr = 0.00879687, m = 0.9
I0801 13:31:24.795656  3162 solver.cpp:353] Iteration 7800 (63.4415 iter/s, 1.57626s/100 iter), loss = 0.00234699
I0801 13:31:24.795704  3162 solver.cpp:375]     Train net output #0: loss = 0.00234699 (* 1 = 0.00234699 loss)
I0801 13:31:24.795712  3162 sgd_solver.cpp:136] Iteration 7800, lr = 0.00878125, m = 0.9
I0801 13:31:26.384944  3162 solver.cpp:353] Iteration 7900 (62.9233 iter/s, 1.58924s/100 iter), loss = 0.00164509
I0801 13:31:26.384973  3162 solver.cpp:375]     Train net output #0: loss = 0.00164509 (* 1 = 0.00164509 loss)
I0801 13:31:26.384979  3162 sgd_solver.cpp:136] Iteration 7900, lr = 0.00876562, m = 0.9
I0801 13:31:27.944139  3162 solver.cpp:550] Iteration 8000, Testing net (#0)
I0801 13:31:28.779789  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.918824
I0801 13:31:28.779808  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996471
I0801 13:31:28.779815  3162 solver.cpp:635]     Test net output #2: loss = 0.297845 (* 1 = 0.297845 loss)
I0801 13:31:28.779834  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.835672s
I0801 13:31:28.795506  3162 solver.cpp:353] Iteration 8000 (41.4853 iter/s, 2.41049s/100 iter), loss = 0.00351008
I0801 13:31:28.795526  3162 solver.cpp:375]     Train net output #0: loss = 0.00351007 (* 1 = 0.00351007 loss)
I0801 13:31:28.795531  3162 sgd_solver.cpp:136] Iteration 8000, lr = 0.00875, m = 0.9
I0801 13:31:30.358840  3162 solver.cpp:353] Iteration 8100 (63.968 iter/s, 1.56328s/100 iter), loss = 0.00187104
I0801 13:31:30.358866  3162 solver.cpp:375]     Train net output #0: loss = 0.00187104 (* 1 = 0.00187104 loss)
I0801 13:31:30.358872  3162 sgd_solver.cpp:136] Iteration 8100, lr = 0.00873438, m = 0.9
I0801 13:31:31.911736  3162 solver.cpp:353] Iteration 8200 (64.398 iter/s, 1.55284s/100 iter), loss = 0.000656529
I0801 13:31:31.911764  3162 solver.cpp:375]     Train net output #0: loss = 0.000656528 (* 1 = 0.000656528 loss)
I0801 13:31:31.911772  3162 sgd_solver.cpp:136] Iteration 8200, lr = 0.00871875, m = 0.9
I0801 13:31:33.498020  3162 solver.cpp:353] Iteration 8300 (63.0423 iter/s, 1.58624s/100 iter), loss = 0.00230785
I0801 13:31:33.498047  3162 solver.cpp:375]     Train net output #0: loss = 0.00230785 (* 1 = 0.00230785 loss)
I0801 13:31:33.498052  3162 sgd_solver.cpp:136] Iteration 8300, lr = 0.00870312, m = 0.9
I0801 13:31:35.075213  3162 solver.cpp:353] Iteration 8400 (63.4057 iter/s, 1.57714s/100 iter), loss = 0.00184507
I0801 13:31:35.075264  3162 solver.cpp:375]     Train net output #0: loss = 0.00184507 (* 1 = 0.00184507 loss)
I0801 13:31:35.075279  3162 sgd_solver.cpp:136] Iteration 8400, lr = 0.0086875, m = 0.9
I0801 13:31:36.637528  3162 solver.cpp:353] Iteration 8500 (64.0097 iter/s, 1.56226s/100 iter), loss = 0.00219064
I0801 13:31:36.637554  3162 solver.cpp:375]     Train net output #0: loss = 0.00219064 (* 1 = 0.00219064 loss)
I0801 13:31:36.637559  3162 sgd_solver.cpp:136] Iteration 8500, lr = 0.00867188, m = 0.9
I0801 13:31:38.204964  3162 solver.cpp:353] Iteration 8600 (63.8003 iter/s, 1.56739s/100 iter), loss = 0.000392103
I0801 13:31:38.204993  3162 solver.cpp:375]     Train net output #0: loss = 0.000392103 (* 1 = 0.000392103 loss)
I0801 13:31:38.204998  3162 sgd_solver.cpp:136] Iteration 8600, lr = 0.00865625, m = 0.9
I0801 13:31:39.785315  3162 solver.cpp:353] Iteration 8700 (63.2792 iter/s, 1.5803s/100 iter), loss = 0.00195381
I0801 13:31:39.785339  3162 solver.cpp:375]     Train net output #0: loss = 0.00195381 (* 1 = 0.00195381 loss)
I0801 13:31:39.785343  3162 sgd_solver.cpp:136] Iteration 8700, lr = 0.00864062, m = 0.9
I0801 13:31:41.371623  3162 solver.cpp:353] Iteration 8800 (63.0413 iter/s, 1.58626s/100 iter), loss = 0.00111174
I0801 13:31:41.371651  3162 solver.cpp:375]     Train net output #0: loss = 0.00111174 (* 1 = 0.00111174 loss)
I0801 13:31:41.371659  3162 sgd_solver.cpp:136] Iteration 8800, lr = 0.008625, m = 0.9
I0801 13:31:42.942541  3162 solver.cpp:353] Iteration 8900 (63.6592 iter/s, 1.57086s/100 iter), loss = 0.000753854
I0801 13:31:42.942569  3162 solver.cpp:375]     Train net output #0: loss = 0.000753854 (* 1 = 0.000753854 loss)
I0801 13:31:42.942576  3162 sgd_solver.cpp:136] Iteration 8900, lr = 0.00860937, m = 0.9
I0801 13:31:44.499622  3162 solver.cpp:550] Iteration 9000, Testing net (#0)
I0801 13:31:45.337705  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.915001
I0801 13:31:45.337724  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996176
I0801 13:31:45.337729  3162 solver.cpp:635]     Test net output #2: loss = 0.29666 (* 1 = 0.29666 loss)
I0801 13:31:45.337748  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.838103s
I0801 13:31:45.353518  3162 solver.cpp:353] Iteration 9000 (41.4782 iter/s, 2.41091s/100 iter), loss = 0.00147056
I0801 13:31:45.353538  3162 solver.cpp:375]     Train net output #0: loss = 0.00147056 (* 1 = 0.00147056 loss)
I0801 13:31:45.353543  3162 sgd_solver.cpp:136] Iteration 9000, lr = 0.00859375, m = 0.9
I0801 13:31:46.716778  3155 data_reader.cpp:264] Starting prefetch of epoch 2
I0801 13:31:46.921679  3162 solver.cpp:353] Iteration 9100 (63.7712 iter/s, 1.56811s/100 iter), loss = 0.00204251
I0801 13:31:46.921777  3162 solver.cpp:375]     Train net output #0: loss = 0.00204251 (* 1 = 0.00204251 loss)
I0801 13:31:46.921785  3162 sgd_solver.cpp:136] Iteration 9100, lr = 0.00857813, m = 0.9
I0801 13:31:48.493361  3162 solver.cpp:353] Iteration 9200 (63.628 iter/s, 1.57163s/100 iter), loss = 0.00299746
I0801 13:31:48.493409  3162 solver.cpp:375]     Train net output #0: loss = 0.00299746 (* 1 = 0.00299746 loss)
I0801 13:31:48.493422  3162 sgd_solver.cpp:136] Iteration 9200, lr = 0.0085625, m = 0.9
I0801 13:31:50.051386  3162 solver.cpp:353] Iteration 9300 (64.1859 iter/s, 1.55798s/100 iter), loss = 0.00117492
I0801 13:31:50.051414  3162 solver.cpp:375]     Train net output #0: loss = 0.00117492 (* 1 = 0.00117492 loss)
I0801 13:31:50.051420  3162 sgd_solver.cpp:136] Iteration 9300, lr = 0.00854687, m = 0.9
I0801 13:31:51.611081  3162 solver.cpp:353] Iteration 9400 (64.1171 iter/s, 1.55965s/100 iter), loss = 0.00224546
I0801 13:31:51.611107  3162 solver.cpp:375]     Train net output #0: loss = 0.00224546 (* 1 = 0.00224546 loss)
I0801 13:31:51.611114  3162 sgd_solver.cpp:136] Iteration 9400, lr = 0.00853125, m = 0.9
I0801 13:31:53.184434  3162 solver.cpp:353] Iteration 9500 (63.5606 iter/s, 1.5733s/100 iter), loss = 0.000844637
I0801 13:31:53.184459  3162 solver.cpp:375]     Train net output #0: loss = 0.000844638 (* 1 = 0.000844638 loss)
I0801 13:31:53.184465  3162 sgd_solver.cpp:136] Iteration 9500, lr = 0.00851563, m = 0.9
I0801 13:31:54.759958  3162 solver.cpp:353] Iteration 9600 (63.473 iter/s, 1.57547s/100 iter), loss = 0.00232089
I0801 13:31:54.759980  3162 solver.cpp:375]     Train net output #0: loss = 0.00232089 (* 1 = 0.00232089 loss)
I0801 13:31:54.759985  3162 sgd_solver.cpp:136] Iteration 9600, lr = 0.0085, m = 0.9
I0801 13:31:56.331617  3162 solver.cpp:353] Iteration 9700 (63.629 iter/s, 1.57161s/100 iter), loss = 0.00185868
I0801 13:31:56.331642  3162 solver.cpp:375]     Train net output #0: loss = 0.00185868 (* 1 = 0.00185868 loss)
I0801 13:31:56.331648  3162 sgd_solver.cpp:136] Iteration 9700, lr = 0.00848437, m = 0.9
I0801 13:31:57.898722  3162 solver.cpp:353] Iteration 9800 (63.8139 iter/s, 1.56706s/100 iter), loss = 0.00121665
I0801 13:31:57.898748  3162 solver.cpp:375]     Train net output #0: loss = 0.00121665 (* 1 = 0.00121665 loss)
I0801 13:31:57.898754  3162 sgd_solver.cpp:136] Iteration 9800, lr = 0.00846875, m = 0.9
I0801 13:31:59.478427  3162 solver.cpp:353] Iteration 9900 (63.3049 iter/s, 1.57966s/100 iter), loss = 0.000913426
I0801 13:31:59.478454  3162 solver.cpp:375]     Train net output #0: loss = 0.000913427 (* 1 = 0.000913427 loss)
I0801 13:31:59.478461  3162 sgd_solver.cpp:136] Iteration 9900, lr = 0.00845312, m = 0.9
I0801 13:32:01.048964  3162 solver.cpp:680] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/l1reg/cifar10_jacintonet11v2_iter_10000.caffemodel
I0801 13:32:01.064894  3162 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/l1reg/cifar10_jacintonet11v2_iter_10000.solverstate
I0801 13:32:01.068630  3162 solver.cpp:550] Iteration 10000, Testing net (#0)
I0801 13:32:01.883955  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.915295
I0801 13:32:01.883973  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996471
I0801 13:32:01.883980  3162 solver.cpp:635]     Test net output #2: loss = 0.31164 (* 1 = 0.31164 loss)
I0801 13:32:01.883996  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.815342s
I0801 13:32:01.899680  3162 solver.cpp:353] Iteration 10000 (41.3021 iter/s, 2.42118s/100 iter), loss = 0.00173234
I0801 13:32:01.899701  3162 solver.cpp:375]     Train net output #0: loss = 0.00173234 (* 1 = 0.00173234 loss)
I0801 13:32:01.899706  3162 sgd_solver.cpp:136] Iteration 10000, lr = 0.0084375, m = 0.9
I0801 13:32:03.482095  3162 solver.cpp:353] Iteration 10100 (63.1966 iter/s, 1.58236s/100 iter), loss = 0.00226461
I0801 13:32:03.482121  3162 solver.cpp:375]     Train net output #0: loss = 0.00226461 (* 1 = 0.00226461 loss)
I0801 13:32:03.482127  3162 sgd_solver.cpp:136] Iteration 10100, lr = 0.00842187, m = 0.9
I0801 13:32:05.081702  3162 solver.cpp:353] Iteration 10200 (62.5173 iter/s, 1.59956s/100 iter), loss = 0.00208562
I0801 13:32:05.081727  3162 solver.cpp:375]     Train net output #0: loss = 0.00208563 (* 1 = 0.00208563 loss)
I0801 13:32:05.081732  3162 sgd_solver.cpp:136] Iteration 10200, lr = 0.00840625, m = 0.9
I0801 13:32:06.648265  3162 solver.cpp:353] Iteration 10300 (63.8361 iter/s, 1.56651s/100 iter), loss = 0.0011056
I0801 13:32:06.648293  3162 solver.cpp:375]     Train net output #0: loss = 0.0011056 (* 1 = 0.0011056 loss)
I0801 13:32:06.648298  3162 sgd_solver.cpp:136] Iteration 10300, lr = 0.00839063, m = 0.9
I0801 13:32:08.229797  3162 solver.cpp:353] Iteration 10400 (63.2317 iter/s, 1.58148s/100 iter), loss = 0.00124456
I0801 13:32:08.229843  3162 solver.cpp:375]     Train net output #0: loss = 0.00124456 (* 1 = 0.00124456 loss)
I0801 13:32:08.229851  3162 sgd_solver.cpp:136] Iteration 10400, lr = 0.008375, m = 0.9
I0801 13:32:09.796406  3162 solver.cpp:353] Iteration 10500 (63.8342 iter/s, 1.56656s/100 iter), loss = 0.00142947
I0801 13:32:09.796430  3162 solver.cpp:375]     Train net output #0: loss = 0.00142947 (* 1 = 0.00142947 loss)
I0801 13:32:09.796437  3162 sgd_solver.cpp:136] Iteration 10500, lr = 0.00835937, m = 0.9
I0801 13:32:11.378278  3162 solver.cpp:353] Iteration 10600 (63.2182 iter/s, 1.58182s/100 iter), loss = 0.00137402
I0801 13:32:11.378322  3162 solver.cpp:375]     Train net output #0: loss = 0.00137403 (* 1 = 0.00137403 loss)
I0801 13:32:11.378334  3162 sgd_solver.cpp:136] Iteration 10600, lr = 0.00834375, m = 0.9
I0801 13:32:12.945981  3162 solver.cpp:353] Iteration 10700 (63.7896 iter/s, 1.56765s/100 iter), loss = 0.00254085
I0801 13:32:12.946007  3162 solver.cpp:375]     Train net output #0: loss = 0.00254085 (* 1 = 0.00254085 loss)
I0801 13:32:12.946012  3162 sgd_solver.cpp:136] Iteration 10700, lr = 0.00832812, m = 0.9
I0801 13:32:14.519613  3162 solver.cpp:353] Iteration 10800 (63.5493 iter/s, 1.57358s/100 iter), loss = 0.00321216
I0801 13:32:14.519639  3162 solver.cpp:375]     Train net output #0: loss = 0.00321217 (* 1 = 0.00321217 loss)
I0801 13:32:14.519644  3162 sgd_solver.cpp:136] Iteration 10800, lr = 0.0083125, m = 0.9
I0801 13:32:16.086491  3162 solver.cpp:353] Iteration 10900 (63.8231 iter/s, 1.56683s/100 iter), loss = 0.000936151
I0801 13:32:16.086518  3162 solver.cpp:375]     Train net output #0: loss = 0.000936151 (* 1 = 0.000936151 loss)
I0801 13:32:16.086522  3162 sgd_solver.cpp:136] Iteration 10900, lr = 0.00829687, m = 0.9
I0801 13:32:17.651856  3162 solver.cpp:550] Iteration 11000, Testing net (#0)
I0801 13:32:18.484928  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.915589
I0801 13:32:18.484947  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996177
I0801 13:32:18.484952  3162 solver.cpp:635]     Test net output #2: loss = 0.303572 (* 1 = 0.303572 loss)
I0801 13:32:18.484968  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.83309s
I0801 13:32:18.501391  3162 solver.cpp:353] Iteration 11000 (41.4108 iter/s, 2.41483s/100 iter), loss = 0.00143811
I0801 13:32:18.501408  3162 solver.cpp:375]     Train net output #0: loss = 0.00143811 (* 1 = 0.00143811 loss)
I0801 13:32:18.501412  3162 sgd_solver.cpp:136] Iteration 11000, lr = 0.00828125, m = 0.9
I0801 13:32:20.089097  3162 solver.cpp:353] Iteration 11100 (62.986 iter/s, 1.58765s/100 iter), loss = 0.00113562
I0801 13:32:20.089148  3162 solver.cpp:375]     Train net output #0: loss = 0.00113562 (* 1 = 0.00113562 loss)
I0801 13:32:20.089162  3162 sgd_solver.cpp:136] Iteration 11100, lr = 0.00826562, m = 0.9
I0801 13:32:21.663923  3162 solver.cpp:353] Iteration 11200 (63.5011 iter/s, 1.57478s/100 iter), loss = 0.00220204
I0801 13:32:21.663949  3162 solver.cpp:375]     Train net output #0: loss = 0.00220204 (* 1 = 0.00220204 loss)
I0801 13:32:21.663954  3162 sgd_solver.cpp:136] Iteration 11200, lr = 0.00825, m = 0.9
I0801 13:32:23.242085  3162 solver.cpp:353] Iteration 11300 (63.3668 iter/s, 1.57811s/100 iter), loss = 0.00159607
I0801 13:32:23.242110  3162 solver.cpp:375]     Train net output #0: loss = 0.00159607 (* 1 = 0.00159607 loss)
I0801 13:32:23.242115  3162 sgd_solver.cpp:136] Iteration 11300, lr = 0.00823438, m = 0.9
I0801 13:32:24.815724  3162 solver.cpp:353] Iteration 11400 (63.5491 iter/s, 1.57359s/100 iter), loss = 0.00215345
I0801 13:32:24.815775  3162 solver.cpp:375]     Train net output #0: loss = 0.00215345 (* 1 = 0.00215345 loss)
I0801 13:32:24.815789  3162 sgd_solver.cpp:136] Iteration 11400, lr = 0.00821875, m = 0.9
I0801 13:32:26.391762  3162 solver.cpp:353] Iteration 11500 (63.4522 iter/s, 1.57599s/100 iter), loss = 0.00318156
I0801 13:32:26.391788  3162 solver.cpp:375]     Train net output #0: loss = 0.00318156 (* 1 = 0.00318156 loss)
I0801 13:32:26.391793  3162 sgd_solver.cpp:136] Iteration 11500, lr = 0.00820312, m = 0.9
I0801 13:32:27.954838  3162 solver.cpp:353] Iteration 11600 (63.9786 iter/s, 1.56302s/100 iter), loss = 0.00238473
I0801 13:32:27.954869  3162 solver.cpp:375]     Train net output #0: loss = 0.00238473 (* 1 = 0.00238473 loss)
I0801 13:32:27.954877  3162 sgd_solver.cpp:136] Iteration 11600, lr = 0.0081875, m = 0.9
I0801 13:32:29.541326  3162 solver.cpp:353] Iteration 11700 (63.0342 iter/s, 1.58644s/100 iter), loss = 0.000946664
I0801 13:32:29.541352  3162 solver.cpp:375]     Train net output #0: loss = 0.000946662 (* 1 = 0.000946662 loss)
I0801 13:32:29.541358  3162 sgd_solver.cpp:136] Iteration 11700, lr = 0.00817188, m = 0.9
I0801 13:32:31.109436  3162 solver.cpp:353] Iteration 11800 (63.7731 iter/s, 1.56806s/100 iter), loss = 0.00117587
I0801 13:32:31.109462  3162 solver.cpp:375]     Train net output #0: loss = 0.00117587 (* 1 = 0.00117587 loss)
I0801 13:32:31.109467  3162 sgd_solver.cpp:136] Iteration 11800, lr = 0.00815625, m = 0.9
I0801 13:32:32.686770  3162 solver.cpp:353] Iteration 11900 (63.4001 iter/s, 1.57728s/100 iter), loss = 0.00222217
I0801 13:32:32.686795  3162 solver.cpp:375]     Train net output #0: loss = 0.00222217 (* 1 = 0.00222217 loss)
I0801 13:32:32.686800  3162 sgd_solver.cpp:136] Iteration 11900, lr = 0.00814062, m = 0.9
I0801 13:32:34.256557  3162 solver.cpp:550] Iteration 12000, Testing net (#0)
I0801 13:32:35.094554  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.909707
I0801 13:32:35.094574  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.994412
I0801 13:32:35.094581  3162 solver.cpp:635]     Test net output #2: loss = 0.316603 (* 1 = 0.316603 loss)
I0801 13:32:35.094601  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.83802s
I0801 13:32:35.110218  3162 solver.cpp:353] Iteration 12000 (41.2647 iter/s, 2.42338s/100 iter), loss = 0.000600822
I0801 13:32:35.110252  3162 solver.cpp:375]     Train net output #0: loss = 0.00060082 (* 1 = 0.00060082 loss)
I0801 13:32:35.110266  3162 sgd_solver.cpp:136] Iteration 12000, lr = 0.008125, m = 0.9
I0801 13:32:36.673475  3162 solver.cpp:353] Iteration 12100 (63.971 iter/s, 1.56321s/100 iter), loss = 0.000988703
I0801 13:32:36.673501  3162 solver.cpp:375]     Train net output #0: loss = 0.000988702 (* 1 = 0.000988702 loss)
I0801 13:32:36.673506  3162 sgd_solver.cpp:136] Iteration 12100, lr = 0.00810937, m = 0.9
I0801 13:32:38.237421  3162 solver.cpp:353] Iteration 12200 (63.9429 iter/s, 1.56389s/100 iter), loss = 0.00309733
I0801 13:32:38.237445  3162 solver.cpp:375]     Train net output #0: loss = 0.00309733 (* 1 = 0.00309733 loss)
I0801 13:32:38.237452  3162 sgd_solver.cpp:136] Iteration 12200, lr = 0.00809375, m = 0.9
I0801 13:32:39.807603  3162 solver.cpp:353] Iteration 12300 (63.6887 iter/s, 1.57014s/100 iter), loss = 0.00202324
I0801 13:32:39.807631  3162 solver.cpp:375]     Train net output #0: loss = 0.00202324 (* 1 = 0.00202324 loss)
I0801 13:32:39.807636  3162 sgd_solver.cpp:136] Iteration 12300, lr = 0.00807813, m = 0.9
I0801 13:32:41.384300  3162 solver.cpp:353] Iteration 12400 (63.4259 iter/s, 1.57664s/100 iter), loss = 0.00176809
I0801 13:32:41.384330  3162 solver.cpp:375]     Train net output #0: loss = 0.00176809 (* 1 = 0.00176809 loss)
I0801 13:32:41.384336  3162 sgd_solver.cpp:136] Iteration 12400, lr = 0.0080625, m = 0.9
I0801 13:32:42.944650  3162 solver.cpp:353] Iteration 12500 (64.0903 iter/s, 1.5603s/100 iter), loss = 0.00111036
I0801 13:32:42.944797  3162 solver.cpp:375]     Train net output #0: loss = 0.00111035 (* 1 = 0.00111035 loss)
I0801 13:32:42.944821  3162 sgd_solver.cpp:136] Iteration 12500, lr = 0.00804687, m = 0.9
I0801 13:32:44.518271  3162 solver.cpp:353] Iteration 12600 (63.5496 iter/s, 1.57357s/100 iter), loss = 0.0011039
I0801 13:32:44.518296  3162 solver.cpp:375]     Train net output #0: loss = 0.00110389 (* 1 = 0.00110389 loss)
I0801 13:32:44.518302  3162 sgd_solver.cpp:136] Iteration 12600, lr = 0.00803125, m = 0.9
I0801 13:32:46.097681  3162 solver.cpp:353] Iteration 12700 (63.3168 iter/s, 1.57936s/100 iter), loss = 0.0011304
I0801 13:32:46.097707  3162 solver.cpp:375]     Train net output #0: loss = 0.00113039 (* 1 = 0.00113039 loss)
I0801 13:32:46.097713  3162 sgd_solver.cpp:136] Iteration 12700, lr = 0.00801562, m = 0.9
I0801 13:32:47.666867  3162 solver.cpp:353] Iteration 12800 (63.7293 iter/s, 1.56914s/100 iter), loss = 0.00278072
I0801 13:32:47.666945  3162 solver.cpp:375]     Train net output #0: loss = 0.00278072 (* 1 = 0.00278072 loss)
I0801 13:32:47.666954  3162 sgd_solver.cpp:136] Iteration 12800, lr = 0.008, m = 0.9
I0801 13:32:49.229045  3162 solver.cpp:353] Iteration 12900 (64.0152 iter/s, 1.56213s/100 iter), loss = 0.00136278
I0801 13:32:49.229070  3162 solver.cpp:375]     Train net output #0: loss = 0.00136277 (* 1 = 0.00136277 loss)
I0801 13:32:49.229074  3162 sgd_solver.cpp:136] Iteration 12900, lr = 0.00798437, m = 0.9
I0801 13:32:50.783123  3162 solver.cpp:550] Iteration 13000, Testing net (#0)
I0801 13:32:51.616657  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.91206
I0801 13:32:51.616675  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.995882
I0801 13:32:51.616680  3162 solver.cpp:635]     Test net output #2: loss = 0.315384 (* 1 = 0.315384 loss)
I0801 13:32:51.616695  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.833548s
I0801 13:32:51.633438  3162 solver.cpp:353] Iteration 13000 (41.5918 iter/s, 2.40432s/100 iter), loss = 0.000915098
I0801 13:32:51.633458  3162 solver.cpp:375]     Train net output #0: loss = 0.000915094 (* 1 = 0.000915094 loss)
I0801 13:32:51.633462  3162 sgd_solver.cpp:136] Iteration 13000, lr = 0.00796875, m = 0.9
I0801 13:32:53.195667  3162 solver.cpp:353] Iteration 13100 (64.0132 iter/s, 1.56218s/100 iter), loss = 0.000996621
I0801 13:32:53.195691  3162 solver.cpp:375]     Train net output #0: loss = 0.000996617 (* 1 = 0.000996617 loss)
I0801 13:32:53.195698  3162 sgd_solver.cpp:136] Iteration 13100, lr = 0.00795313, m = 0.9
I0801 13:32:54.757623  3162 solver.cpp:353] Iteration 13200 (64.0242 iter/s, 1.56191s/100 iter), loss = 0.00246374
I0801 13:32:54.757650  3162 solver.cpp:375]     Train net output #0: loss = 0.00246374 (* 1 = 0.00246374 loss)
I0801 13:32:54.757658  3162 sgd_solver.cpp:136] Iteration 13200, lr = 0.0079375, m = 0.9
I0801 13:32:56.347180  3162 solver.cpp:353] Iteration 13300 (62.9126 iter/s, 1.58951s/100 iter), loss = 0.00218026
I0801 13:32:56.347204  3162 solver.cpp:375]     Train net output #0: loss = 0.00218025 (* 1 = 0.00218025 loss)
I0801 13:32:56.347209  3162 sgd_solver.cpp:136] Iteration 13300, lr = 0.00792187, m = 0.9
I0801 13:32:57.912459  3162 solver.cpp:353] Iteration 13400 (63.8884 iter/s, 1.56523s/100 iter), loss = 0.000563878
I0801 13:32:57.912484  3162 solver.cpp:375]     Train net output #0: loss = 0.000563874 (* 1 = 0.000563874 loss)
I0801 13:32:57.912490  3162 sgd_solver.cpp:136] Iteration 13400, lr = 0.00790625, m = 0.9
I0801 13:32:59.474351  3162 solver.cpp:353] Iteration 13500 (64.027 iter/s, 1.56184s/100 iter), loss = 0.00158472
I0801 13:32:59.474405  3162 solver.cpp:375]     Train net output #0: loss = 0.00158472 (* 1 = 0.00158472 loss)
I0801 13:32:59.474418  3162 sgd_solver.cpp:136] Iteration 13500, lr = 0.00789062, m = 0.9
I0801 13:33:01.066910  3162 solver.cpp:353] Iteration 13600 (62.794 iter/s, 1.59251s/100 iter), loss = 0.000385782
I0801 13:33:01.066934  3162 solver.cpp:375]     Train net output #0: loss = 0.000385777 (* 1 = 0.000385777 loss)
I0801 13:33:01.066939  3162 sgd_solver.cpp:136] Iteration 13600, lr = 0.007875, m = 0.9
I0801 13:33:01.581765  3155 data_reader.cpp:264] Starting prefetch of epoch 3
I0801 13:33:02.642241  3162 solver.cpp:353] Iteration 13700 (63.4807 iter/s, 1.57528s/100 iter), loss = 0.00186768
I0801 13:33:02.642268  3162 solver.cpp:375]     Train net output #0: loss = 0.00186768 (* 1 = 0.00186768 loss)
I0801 13:33:02.642274  3162 sgd_solver.cpp:136] Iteration 13700, lr = 0.00785937, m = 0.9
I0801 13:33:04.226573  3162 solver.cpp:353] Iteration 13800 (63.1202 iter/s, 1.58428s/100 iter), loss = 0.00135685
I0801 13:33:04.226627  3162 solver.cpp:375]     Train net output #0: loss = 0.00135685 (* 1 = 0.00135685 loss)
I0801 13:33:04.226642  3162 sgd_solver.cpp:136] Iteration 13800, lr = 0.00784375, m = 0.9
I0801 13:33:05.804574  3162 solver.cpp:353] Iteration 13900 (63.3733 iter/s, 1.57795s/100 iter), loss = 0.00110649
I0801 13:33:05.804713  3162 solver.cpp:375]     Train net output #0: loss = 0.00110649 (* 1 = 0.00110649 loss)
I0801 13:33:05.804744  3162 sgd_solver.cpp:136] Iteration 13900, lr = 0.00782812, m = 0.9
I0801 13:33:07.360246  3162 solver.cpp:550] Iteration 14000, Testing net (#0)
I0801 13:33:08.195405  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.91706
I0801 13:33:08.195427  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.995882
I0801 13:33:08.195433  3162 solver.cpp:635]     Test net output #2: loss = 0.304221 (* 1 = 0.304221 loss)
I0801 13:33:08.195454  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.835185s
I0801 13:33:08.211040  3162 solver.cpp:353] Iteration 14000 (41.5559 iter/s, 2.4064s/100 iter), loss = 0.00235621
I0801 13:33:08.211057  3162 solver.cpp:375]     Train net output #0: loss = 0.00235621 (* 1 = 0.00235621 loss)
I0801 13:33:08.211061  3162 sgd_solver.cpp:136] Iteration 14000, lr = 0.0078125, m = 0.9
I0801 13:33:09.784709  3162 solver.cpp:353] Iteration 14100 (63.5478 iter/s, 1.57362s/100 iter), loss = 0.00133989
I0801 13:33:09.784760  3162 solver.cpp:375]     Train net output #0: loss = 0.00133989 (* 1 = 0.00133989 loss)
I0801 13:33:09.784780  3162 sgd_solver.cpp:136] Iteration 14100, lr = 0.00779688, m = 0.9
I0801 13:33:11.368782  3162 solver.cpp:353] Iteration 14200 (63.1305 iter/s, 1.58402s/100 iter), loss = 0.000713062
I0801 13:33:11.368809  3162 solver.cpp:375]     Train net output #0: loss = 0.000713058 (* 1 = 0.000713058 loss)
I0801 13:33:11.368822  3162 sgd_solver.cpp:136] Iteration 14200, lr = 0.00778125, m = 0.9
I0801 13:33:12.928057  3162 solver.cpp:353] Iteration 14300 (64.1343 iter/s, 1.55923s/100 iter), loss = 0.00188834
I0801 13:33:12.928083  3162 solver.cpp:375]     Train net output #0: loss = 0.00188834 (* 1 = 0.00188834 loss)
I0801 13:33:12.928091  3162 sgd_solver.cpp:136] Iteration 14300, lr = 0.00776563, m = 0.9
I0801 13:33:14.492655  3162 solver.cpp:353] Iteration 14400 (63.9161 iter/s, 1.56455s/100 iter), loss = 0.00282532
I0801 13:33:14.492702  3162 solver.cpp:375]     Train net output #0: loss = 0.00282532 (* 1 = 0.00282532 loss)
I0801 13:33:14.492714  3162 sgd_solver.cpp:136] Iteration 14400, lr = 0.00775, m = 0.9
I0801 13:33:16.060449  3162 solver.cpp:353] Iteration 14500 (63.786 iter/s, 1.56774s/100 iter), loss = 0.00132761
I0801 13:33:16.060477  3162 solver.cpp:375]     Train net output #0: loss = 0.00132761 (* 1 = 0.00132761 loss)
I0801 13:33:16.060484  3162 sgd_solver.cpp:136] Iteration 14500, lr = 0.00773437, m = 0.9
I0801 13:33:17.622560  3162 solver.cpp:353] Iteration 14600 (64.0181 iter/s, 1.56206s/100 iter), loss = 0.00160064
I0801 13:33:17.622611  3162 solver.cpp:375]     Train net output #0: loss = 0.00160063 (* 1 = 0.00160063 loss)
I0801 13:33:17.622623  3162 sgd_solver.cpp:136] Iteration 14600, lr = 0.00771875, m = 0.9
I0801 13:33:19.186396  3162 solver.cpp:353] Iteration 14700 (63.9472 iter/s, 1.56379s/100 iter), loss = 0.00202809
I0801 13:33:19.186467  3162 solver.cpp:375]     Train net output #0: loss = 0.00202808 (* 1 = 0.00202808 loss)
I0801 13:33:19.186473  3162 sgd_solver.cpp:136] Iteration 14700, lr = 0.00770312, m = 0.9
I0801 13:33:20.746340  3162 solver.cpp:353] Iteration 14800 (64.1069 iter/s, 1.55989s/100 iter), loss = 0.00102306
I0801 13:33:20.746368  3162 solver.cpp:375]     Train net output #0: loss = 0.00102305 (* 1 = 0.00102305 loss)
I0801 13:33:20.746374  3162 sgd_solver.cpp:136] Iteration 14800, lr = 0.0076875, m = 0.9
I0801 13:33:22.325613  3162 solver.cpp:353] Iteration 14900 (63.3223 iter/s, 1.57922s/100 iter), loss = 0.0032764
I0801 13:33:22.325639  3162 solver.cpp:375]     Train net output #0: loss = 0.00327639 (* 1 = 0.00327639 loss)
I0801 13:33:22.325645  3162 sgd_solver.cpp:136] Iteration 14900, lr = 0.00767187, m = 0.9
I0801 13:33:23.872746  3162 solver.cpp:550] Iteration 15000, Testing net (#0)
I0801 13:33:24.713594  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.912648
I0801 13:33:24.713613  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996177
I0801 13:33:24.713618  3162 solver.cpp:635]     Test net output #2: loss = 0.303266 (* 1 = 0.303266 loss)
I0801 13:33:24.713634  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.840864s
I0801 13:33:24.729264  3162 solver.cpp:353] Iteration 15000 (41.6046 iter/s, 2.40358s/100 iter), loss = 0.00249473
I0801 13:33:24.729282  3162 solver.cpp:375]     Train net output #0: loss = 0.00249472 (* 1 = 0.00249472 loss)
I0801 13:33:24.729287  3162 sgd_solver.cpp:136] Iteration 15000, lr = 0.00765625, m = 0.9
I0801 13:33:26.334262  3162 solver.cpp:353] Iteration 15100 (62.3074 iter/s, 1.60495s/100 iter), loss = 0.00172766
I0801 13:33:26.334290  3162 solver.cpp:375]     Train net output #0: loss = 0.00172766 (* 1 = 0.00172766 loss)
I0801 13:33:26.334296  3162 sgd_solver.cpp:136] Iteration 15100, lr = 0.00764062, m = 0.9
I0801 13:33:27.908195  3162 solver.cpp:353] Iteration 15200 (63.5372 iter/s, 1.57388s/100 iter), loss = 0.000468749
I0801 13:33:27.908218  3162 solver.cpp:375]     Train net output #0: loss = 0.000468743 (* 1 = 0.000468743 loss)
I0801 13:33:27.908222  3162 sgd_solver.cpp:136] Iteration 15200, lr = 0.007625, m = 0.9
I0801 13:33:29.483650  3162 solver.cpp:353] Iteration 15300 (63.4756 iter/s, 1.57541s/100 iter), loss = 0.00093651
I0801 13:33:29.483675  3162 solver.cpp:375]     Train net output #0: loss = 0.000936505 (* 1 = 0.000936505 loss)
I0801 13:33:29.483681  3162 sgd_solver.cpp:136] Iteration 15300, lr = 0.00760937, m = 0.9
I0801 13:33:31.047931  3162 solver.cpp:353] Iteration 15400 (63.9291 iter/s, 1.56423s/100 iter), loss = 0.00665306
I0801 13:33:31.047958  3162 solver.cpp:375]     Train net output #0: loss = 0.00665305 (* 1 = 0.00665305 loss)
I0801 13:33:31.047965  3162 sgd_solver.cpp:136] Iteration 15400, lr = 0.00759375, m = 0.9
I0801 13:33:32.626648  3162 solver.cpp:353] Iteration 15500 (63.3447 iter/s, 1.57866s/100 iter), loss = 0.00197322
I0801 13:33:32.626698  3162 solver.cpp:375]     Train net output #0: loss = 0.00197321 (* 1 = 0.00197321 loss)
I0801 13:33:32.626710  3162 sgd_solver.cpp:136] Iteration 15500, lr = 0.00757812, m = 0.9
I0801 13:33:34.202169  3162 solver.cpp:353] Iteration 15600 (63.473 iter/s, 1.57547s/100 iter), loss = 0.000598932
I0801 13:33:34.202195  3162 solver.cpp:375]     Train net output #0: loss = 0.000598927 (* 1 = 0.000598927 loss)
I0801 13:33:34.202201  3162 sgd_solver.cpp:136] Iteration 15600, lr = 0.0075625, m = 0.9
I0801 13:33:35.786623  3162 solver.cpp:353] Iteration 15700 (63.1152 iter/s, 1.58441s/100 iter), loss = 0.0030882
I0801 13:33:35.786649  3162 solver.cpp:375]     Train net output #0: loss = 0.0030882 (* 1 = 0.0030882 loss)
I0801 13:33:35.786655  3162 sgd_solver.cpp:136] Iteration 15700, lr = 0.00754687, m = 0.9
I0801 13:33:37.364832  3162 solver.cpp:353] Iteration 15800 (63.365 iter/s, 1.57816s/100 iter), loss = 0.00111859
I0801 13:33:37.364980  3162 solver.cpp:375]     Train net output #0: loss = 0.00111858 (* 1 = 0.00111858 loss)
I0801 13:33:37.364998  3162 sgd_solver.cpp:136] Iteration 15800, lr = 0.00753125, m = 0.9
I0801 13:33:38.952788  3162 solver.cpp:353] Iteration 15900 (62.976 iter/s, 1.58791s/100 iter), loss = 0.00281346
I0801 13:33:38.952842  3162 solver.cpp:375]     Train net output #0: loss = 0.00281346 (* 1 = 0.00281346 loss)
I0801 13:33:38.952857  3162 sgd_solver.cpp:136] Iteration 15900, lr = 0.00751562, m = 0.9
I0801 13:33:40.507925  3162 solver.cpp:550] Iteration 16000, Testing net (#0)
I0801 13:33:41.342123  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.916766
I0801 13:33:41.342140  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.995882
I0801 13:33:41.342145  3162 solver.cpp:635]     Test net output #2: loss = 0.291256 (* 1 = 0.291256 loss)
I0801 13:33:41.342162  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.834216s
I0801 13:33:41.357769  3162 solver.cpp:353] Iteration 16000 (41.5816 iter/s, 2.40491s/100 iter), loss = 0.00201662
I0801 13:33:41.357786  3162 solver.cpp:375]     Train net output #0: loss = 0.00201661 (* 1 = 0.00201661 loss)
I0801 13:33:41.357790  3162 sgd_solver.cpp:136] Iteration 16000, lr = 0.0075, m = 0.9
I0801 13:33:42.927525  3162 solver.cpp:353] Iteration 16100 (63.7064 iter/s, 1.5697s/100 iter), loss = 0.000833457
I0801 13:33:42.927554  3162 solver.cpp:375]     Train net output #0: loss = 0.000833451 (* 1 = 0.000833451 loss)
I0801 13:33:42.927562  3162 sgd_solver.cpp:136] Iteration 16100, lr = 0.00748438, m = 0.9
I0801 13:33:44.505568  3162 solver.cpp:353] Iteration 16200 (63.3716 iter/s, 1.57799s/100 iter), loss = 0.00126809
I0801 13:33:44.505594  3162 solver.cpp:375]     Train net output #0: loss = 0.00126808 (* 1 = 0.00126808 loss)
I0801 13:33:44.505601  3162 sgd_solver.cpp:136] Iteration 16200, lr = 0.00746875, m = 0.9
I0801 13:33:46.078114  3162 solver.cpp:353] Iteration 16300 (63.5932 iter/s, 1.57249s/100 iter), loss = 0.00415631
I0801 13:33:46.078141  3162 solver.cpp:375]     Train net output #0: loss = 0.00415631 (* 1 = 0.00415631 loss)
I0801 13:33:46.078148  3162 sgd_solver.cpp:136] Iteration 16300, lr = 0.00745312, m = 0.9
I0801 13:33:47.640938  3162 solver.cpp:353] Iteration 16400 (63.9887 iter/s, 1.56278s/100 iter), loss = 0.00241172
I0801 13:33:47.640992  3162 solver.cpp:375]     Train net output #0: loss = 0.00241171 (* 1 = 0.00241171 loss)
I0801 13:33:47.641016  3162 sgd_solver.cpp:136] Iteration 16400, lr = 0.0074375, m = 0.9
I0801 13:33:49.220197  3162 solver.cpp:353] Iteration 16500 (63.3229 iter/s, 1.57921s/100 iter), loss = 0.00157382
I0801 13:33:49.220273  3162 solver.cpp:375]     Train net output #0: loss = 0.00157382 (* 1 = 0.00157382 loss)
I0801 13:33:49.220280  3162 sgd_solver.cpp:136] Iteration 16500, lr = 0.00742187, m = 0.9
I0801 13:33:50.785255  3162 solver.cpp:353] Iteration 16600 (63.8974 iter/s, 1.56501s/100 iter), loss = 0.00242527
I0801 13:33:50.785305  3162 solver.cpp:375]     Train net output #0: loss = 0.00242527 (* 1 = 0.00242527 loss)
I0801 13:33:50.785317  3162 sgd_solver.cpp:136] Iteration 16600, lr = 0.00740625, m = 0.9
I0801 13:33:52.352520  3162 solver.cpp:353] Iteration 16700 (63.8074 iter/s, 1.56722s/100 iter), loss = 0.00531678
I0801 13:33:52.352547  3162 solver.cpp:375]     Train net output #0: loss = 0.00531677 (* 1 = 0.00531677 loss)
I0801 13:33:52.352553  3162 sgd_solver.cpp:136] Iteration 16700, lr = 0.00739062, m = 0.9
I0801 13:33:53.922783  3162 solver.cpp:353] Iteration 16800 (63.6855 iter/s, 1.57022s/100 iter), loss = 0.00352906
I0801 13:33:53.922808  3162 solver.cpp:375]     Train net output #0: loss = 0.00352906 (* 1 = 0.00352906 loss)
I0801 13:33:53.922814  3162 sgd_solver.cpp:136] Iteration 16800, lr = 0.007375, m = 0.9
I0801 13:33:55.513481  3162 solver.cpp:353] Iteration 16900 (62.8675 iter/s, 1.59065s/100 iter), loss = 0.00219706
I0801 13:33:55.513535  3162 solver.cpp:375]     Train net output #0: loss = 0.00219705 (* 1 = 0.00219705 loss)
I0801 13:33:55.513550  3162 sgd_solver.cpp:136] Iteration 16900, lr = 0.00735937, m = 0.9
I0801 13:33:57.079848  3162 solver.cpp:550] Iteration 17000, Testing net (#0)
I0801 13:33:57.910871  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.920883
I0801 13:33:57.910889  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996765
I0801 13:33:57.910894  3162 solver.cpp:635]     Test net output #2: loss = 0.26985 (* 1 = 0.26985 loss)
I0801 13:33:57.910909  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.831038s
I0801 13:33:57.926388  3162 solver.cpp:353] Iteration 17000 (41.445 iter/s, 2.41284s/100 iter), loss = 0.0026438
I0801 13:33:57.926409  3162 solver.cpp:375]     Train net output #0: loss = 0.00264379 (* 1 = 0.00264379 loss)
I0801 13:33:57.926414  3162 sgd_solver.cpp:136] Iteration 17000, lr = 0.00734375, m = 0.9
I0801 13:33:59.496019  3162 solver.cpp:353] Iteration 17100 (63.7114 iter/s, 1.56958s/100 iter), loss = 0.00154093
I0801 13:33:59.496044  3162 solver.cpp:375]     Train net output #0: loss = 0.00154092 (* 1 = 0.00154092 loss)
I0801 13:33:59.496048  3162 sgd_solver.cpp:136] Iteration 17100, lr = 0.00732813, m = 0.9
I0801 13:34:01.065747  3162 solver.cpp:353] Iteration 17200 (63.7072 iter/s, 1.56968s/100 iter), loss = 0.00070843
I0801 13:34:01.065773  3162 solver.cpp:375]     Train net output #0: loss = 0.000708421 (* 1 = 0.000708421 loss)
I0801 13:34:01.065778  3162 sgd_solver.cpp:136] Iteration 17200, lr = 0.0073125, m = 0.9
I0801 13:34:02.649802  3162 solver.cpp:353] Iteration 17300 (63.1311 iter/s, 1.58401s/100 iter), loss = 0.00158507
I0801 13:34:02.649829  3162 solver.cpp:375]     Train net output #0: loss = 0.00158506 (* 1 = 0.00158506 loss)
I0801 13:34:02.649837  3162 sgd_solver.cpp:136] Iteration 17300, lr = 0.00729688, m = 0.9
I0801 13:34:04.239154  3162 solver.cpp:353] Iteration 17400 (62.9208 iter/s, 1.5893s/100 iter), loss = 0.00180337
I0801 13:34:04.239178  3162 solver.cpp:375]     Train net output #0: loss = 0.00180336 (* 1 = 0.00180336 loss)
I0801 13:34:04.239183  3162 sgd_solver.cpp:136] Iteration 17400, lr = 0.00728125, m = 0.9
I0801 13:34:05.825044  3162 solver.cpp:353] Iteration 17500 (63.058 iter/s, 1.58584s/100 iter), loss = 0.0020986
I0801 13:34:05.825093  3162 solver.cpp:375]     Train net output #0: loss = 0.0020986 (* 1 = 0.0020986 loss)
I0801 13:34:05.825106  3162 sgd_solver.cpp:136] Iteration 17500, lr = 0.00726563, m = 0.9
I0801 13:34:07.412231  3162 solver.cpp:353] Iteration 17600 (63.0064 iter/s, 1.58714s/100 iter), loss = 0.0019625
I0801 13:34:07.412258  3162 solver.cpp:375]     Train net output #0: loss = 0.00196249 (* 1 = 0.00196249 loss)
I0801 13:34:07.412264  3162 sgd_solver.cpp:136] Iteration 17600, lr = 0.00725, m = 0.9
I0801 13:34:08.976567  3162 solver.cpp:353] Iteration 17700 (63.9269 iter/s, 1.56429s/100 iter), loss = 0.0016693
I0801 13:34:08.976619  3162 solver.cpp:375]     Train net output #0: loss = 0.0016693 (* 1 = 0.0016693 loss)
I0801 13:34:08.976632  3162 sgd_solver.cpp:136] Iteration 17700, lr = 0.00723437, m = 0.9
I0801 13:34:10.548921  3162 solver.cpp:353] Iteration 17800 (63.6009 iter/s, 1.5723s/100 iter), loss = 0.00311991
I0801 13:34:10.548972  3162 solver.cpp:375]     Train net output #0: loss = 0.00311991 (* 1 = 0.00311991 loss)
I0801 13:34:10.548985  3162 sgd_solver.cpp:136] Iteration 17800, lr = 0.00721875, m = 0.9
I0801 13:34:12.117951  3162 solver.cpp:353] Iteration 17900 (63.7356 iter/s, 1.56898s/100 iter), loss = 0.00559395
I0801 13:34:12.117977  3162 solver.cpp:375]     Train net output #0: loss = 0.00559394 (* 1 = 0.00559394 loss)
I0801 13:34:12.117983  3162 sgd_solver.cpp:136] Iteration 17900, lr = 0.00720312, m = 0.9
I0801 13:34:13.688712  3162 solver.cpp:550] Iteration 18000, Testing net (#0)
I0801 13:34:14.165210  3160 data_reader.cpp:264] Starting prefetch of epoch 2
I0801 13:34:14.525331  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.922942
I0801 13:34:14.525352  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996177
I0801 13:34:14.525358  3162 solver.cpp:635]     Test net output #2: loss = 0.263901 (* 1 = 0.263901 loss)
I0801 13:34:14.525377  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.836641s
I0801 13:34:14.541443  3162 solver.cpp:353] Iteration 18000 (41.264 iter/s, 2.42342s/100 iter), loss = 0.000623171
I0801 13:34:14.541462  3162 solver.cpp:375]     Train net output #0: loss = 0.000623163 (* 1 = 0.000623163 loss)
I0801 13:34:14.541468  3162 sgd_solver.cpp:136] Iteration 18000, lr = 0.0071875, m = 0.9
I0801 13:34:16.126477  3162 solver.cpp:353] Iteration 18100 (63.0923 iter/s, 1.58498s/100 iter), loss = 0.000662073
I0801 13:34:16.126545  3162 solver.cpp:375]     Train net output #0: loss = 0.000662066 (* 1 = 0.000662066 loss)
I0801 13:34:16.126564  3162 sgd_solver.cpp:136] Iteration 18100, lr = 0.00717187, m = 0.9
I0801 13:34:17.765187  3162 solver.cpp:353] Iteration 18200 (61.0255 iter/s, 1.63866s/100 iter), loss = 0.00146008
I0801 13:34:17.765213  3162 solver.cpp:375]     Train net output #0: loss = 0.00146007 (* 1 = 0.00146007 loss)
I0801 13:34:17.765219  3162 sgd_solver.cpp:136] Iteration 18200, lr = 0.00715625, m = 0.9
I0801 13:34:19.355630  3162 solver.cpp:353] Iteration 18300 (62.8775 iter/s, 1.59039s/100 iter), loss = 0.00298968
I0801 13:34:19.355727  3162 solver.cpp:375]     Train net output #0: loss = 0.00298968 (* 1 = 0.00298968 loss)
I0801 13:34:19.355736  3162 sgd_solver.cpp:136] Iteration 18300, lr = 0.00714062, m = 0.9
I0801 13:34:20.945196  3162 solver.cpp:353] Iteration 18400 (62.9121 iter/s, 1.58952s/100 iter), loss = 0.00151914
I0801 13:34:20.945246  3162 solver.cpp:375]     Train net output #0: loss = 0.00151913 (* 1 = 0.00151913 loss)
I0801 13:34:20.945261  3162 sgd_solver.cpp:136] Iteration 18400, lr = 0.007125, m = 0.9
I0801 13:34:22.523524  3162 solver.cpp:353] Iteration 18500 (63.3602 iter/s, 1.57828s/100 iter), loss = 0.000660336
I0801 13:34:22.523674  3162 solver.cpp:375]     Train net output #0: loss = 0.000660327 (* 1 = 0.000660327 loss)
I0801 13:34:22.523692  3162 sgd_solver.cpp:136] Iteration 18500, lr = 0.00710937, m = 0.9
I0801 13:34:24.118630  3162 solver.cpp:353] Iteration 18600 (62.6937 iter/s, 1.59506s/100 iter), loss = 0.00188875
I0801 13:34:24.118655  3162 solver.cpp:375]     Train net output #0: loss = 0.00188874 (* 1 = 0.00188874 loss)
I0801 13:34:24.118661  3162 sgd_solver.cpp:136] Iteration 18600, lr = 0.00709375, m = 0.9
I0801 13:34:25.722347  3162 solver.cpp:353] Iteration 18700 (62.3571 iter/s, 1.60367s/100 iter), loss = 0.00235744
I0801 13:34:25.722373  3162 solver.cpp:375]     Train net output #0: loss = 0.00235743 (* 1 = 0.00235743 loss)
I0801 13:34:25.722379  3162 sgd_solver.cpp:136] Iteration 18700, lr = 0.00707812, m = 0.9
I0801 13:34:27.334364  3162 solver.cpp:353] Iteration 18800 (62.036 iter/s, 1.61197s/100 iter), loss = 0.000901946
I0801 13:34:27.334389  3162 solver.cpp:375]     Train net output #0: loss = 0.000901937 (* 1 = 0.000901937 loss)
I0801 13:34:27.334395  3162 sgd_solver.cpp:136] Iteration 18800, lr = 0.0070625, m = 0.9
I0801 13:34:28.908154  3162 solver.cpp:353] Iteration 18900 (63.543 iter/s, 1.57374s/100 iter), loss = 0.00125271
I0801 13:34:28.908181  3162 solver.cpp:375]     Train net output #0: loss = 0.0012527 (* 1 = 0.0012527 loss)
I0801 13:34:28.908187  3162 sgd_solver.cpp:136] Iteration 18900, lr = 0.00704687, m = 0.9
I0801 13:34:30.455989  3162 solver.cpp:550] Iteration 19000, Testing net (#0)
I0801 13:34:31.289330  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.919119
I0801 13:34:31.289350  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996177
I0801 13:34:31.289355  3162 solver.cpp:635]     Test net output #2: loss = 0.288479 (* 1 = 0.288479 loss)
I0801 13:34:31.289374  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.833362s
I0801 13:34:31.304822  3162 solver.cpp:353] Iteration 19000 (41.7258 iter/s, 2.3966s/100 iter), loss = 0.00221078
I0801 13:34:31.304841  3162 solver.cpp:375]     Train net output #0: loss = 0.00221077 (* 1 = 0.00221077 loss)
I0801 13:34:31.304846  3162 sgd_solver.cpp:136] Iteration 19000, lr = 0.00703125, m = 0.9
I0801 13:34:32.890051  3162 solver.cpp:353] Iteration 19100 (63.0844 iter/s, 1.58518s/100 iter), loss = 0.00450826
I0801 13:34:32.890077  3162 solver.cpp:375]     Train net output #0: loss = 0.00450825 (* 1 = 0.00450825 loss)
I0801 13:34:32.890082  3162 sgd_solver.cpp:136] Iteration 19100, lr = 0.00701563, m = 0.9
I0801 13:34:34.462971  3162 solver.cpp:353] Iteration 19200 (63.578 iter/s, 1.57287s/100 iter), loss = 0.000936962
I0801 13:34:34.462998  3162 solver.cpp:375]     Train net output #0: loss = 0.000936951 (* 1 = 0.000936951 loss)
I0801 13:34:34.463004  3162 sgd_solver.cpp:136] Iteration 19200, lr = 0.007, m = 0.9
I0801 13:34:36.028941  3162 solver.cpp:353] Iteration 19300 (63.8602 iter/s, 1.56592s/100 iter), loss = 0.00150343
I0801 13:34:36.028969  3162 solver.cpp:375]     Train net output #0: loss = 0.00150342 (* 1 = 0.00150342 loss)
I0801 13:34:36.028975  3162 sgd_solver.cpp:136] Iteration 19300, lr = 0.00698437, m = 0.9
I0801 13:34:37.622730  3162 solver.cpp:353] Iteration 19400 (62.7456 iter/s, 1.59374s/100 iter), loss = 0.00143186
I0801 13:34:37.622781  3162 solver.cpp:375]     Train net output #0: loss = 0.00143185 (* 1 = 0.00143185 loss)
I0801 13:34:37.622789  3162 sgd_solver.cpp:136] Iteration 19400, lr = 0.00696875, m = 0.9
I0801 13:34:39.198586  3162 solver.cpp:353] Iteration 19500 (63.4597 iter/s, 1.5758s/100 iter), loss = 0.00154799
I0801 13:34:39.198613  3162 solver.cpp:375]     Train net output #0: loss = 0.00154798 (* 1 = 0.00154798 loss)
I0801 13:34:39.198621  3162 sgd_solver.cpp:136] Iteration 19500, lr = 0.00695312, m = 0.9
I0801 13:34:40.762833  3162 solver.cpp:353] Iteration 19600 (63.9305 iter/s, 1.5642s/100 iter), loss = 0.0053359
I0801 13:34:40.762857  3162 solver.cpp:375]     Train net output #0: loss = 0.00533589 (* 1 = 0.00533589 loss)
I0801 13:34:40.762864  3162 sgd_solver.cpp:136] Iteration 19600, lr = 0.0069375, m = 0.9
I0801 13:34:42.343276  3162 solver.cpp:353] Iteration 19700 (63.2754 iter/s, 1.58039s/100 iter), loss = 0.00104835
I0801 13:34:42.343302  3162 solver.cpp:375]     Train net output #0: loss = 0.00104833 (* 1 = 0.00104833 loss)
I0801 13:34:42.343308  3162 sgd_solver.cpp:136] Iteration 19700, lr = 0.00692187, m = 0.9
I0801 13:34:43.920456  3162 solver.cpp:353] Iteration 19800 (63.4063 iter/s, 1.57713s/100 iter), loss = 0.00113683
I0801 13:34:43.920482  3162 solver.cpp:375]     Train net output #0: loss = 0.00113681 (* 1 = 0.00113681 loss)
I0801 13:34:43.920488  3162 sgd_solver.cpp:136] Iteration 19800, lr = 0.00690625, m = 0.9
I0801 13:34:45.487604  3162 solver.cpp:353] Iteration 19900 (63.8121 iter/s, 1.5671s/100 iter), loss = 0.00261222
I0801 13:34:45.487656  3162 solver.cpp:375]     Train net output #0: loss = 0.00261221 (* 1 = 0.00261221 loss)
I0801 13:34:45.487669  3162 sgd_solver.cpp:136] Iteration 19900, lr = 0.00689062, m = 0.9
I0801 13:34:47.054153  3162 solver.cpp:680] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/l1reg/cifar10_jacintonet11v2_iter_20000.caffemodel
I0801 13:34:47.062362  3162 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/l1reg/cifar10_jacintonet11v2_iter_20000.solverstate
I0801 13:34:47.066025  3162 solver.cpp:550] Iteration 20000, Testing net (#0)
I0801 13:34:47.894582  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.916178
I0801 13:34:47.894603  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.997353
I0801 13:34:47.894608  3162 solver.cpp:635]     Test net output #2: loss = 0.294117 (* 1 = 0.294117 loss)
I0801 13:34:47.894625  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.828575s
I0801 13:34:47.910117  3162 solver.cpp:353] Iteration 20000 (41.2807 iter/s, 2.42244s/100 iter), loss = 0.00179456
I0801 13:34:47.910137  3162 solver.cpp:375]     Train net output #0: loss = 0.00179455 (* 1 = 0.00179455 loss)
I0801 13:34:47.910143  3162 sgd_solver.cpp:136] Iteration 20000, lr = 0.006875, m = 0.9
I0801 13:34:49.479415  3162 solver.cpp:353] Iteration 20100 (63.7249 iter/s, 1.56925s/100 iter), loss = 0.0014933
I0801 13:34:49.479528  3162 solver.cpp:375]     Train net output #0: loss = 0.00149329 (* 1 = 0.00149329 loss)
I0801 13:34:49.479545  3162 sgd_solver.cpp:136] Iteration 20100, lr = 0.00685938, m = 0.9
I0801 13:34:51.056761  3162 solver.cpp:353] Iteration 20200 (63.3996 iter/s, 1.5773s/100 iter), loss = 0.00172633
I0801 13:34:51.056813  3162 solver.cpp:375]     Train net output #0: loss = 0.00172632 (* 1 = 0.00172632 loss)
I0801 13:34:51.056833  3162 sgd_solver.cpp:136] Iteration 20200, lr = 0.00684375, m = 0.9
I0801 13:34:52.628010  3162 solver.cpp:353] Iteration 20300 (63.6456 iter/s, 1.5712s/100 iter), loss = 0.000962344
I0801 13:34:52.628036  3162 solver.cpp:375]     Train net output #0: loss = 0.000962334 (* 1 = 0.000962334 loss)
I0801 13:34:52.628041  3162 sgd_solver.cpp:136] Iteration 20300, lr = 0.00682813, m = 0.9
I0801 13:34:54.236181  3162 solver.cpp:353] Iteration 20400 (62.1844 iter/s, 1.60812s/100 iter), loss = 0.00453277
I0801 13:34:54.236205  3162 solver.cpp:375]     Train net output #0: loss = 0.00453276 (* 1 = 0.00453276 loss)
I0801 13:34:54.236212  3162 sgd_solver.cpp:136] Iteration 20400, lr = 0.0068125, m = 0.9
I0801 13:34:55.811347  3162 solver.cpp:353] Iteration 20500 (63.4874 iter/s, 1.57512s/100 iter), loss = 0.0027373
I0801 13:34:55.811372  3162 solver.cpp:375]     Train net output #0: loss = 0.00273729 (* 1 = 0.00273729 loss)
I0801 13:34:55.811378  3162 sgd_solver.cpp:136] Iteration 20500, lr = 0.00679688, m = 0.9
I0801 13:34:57.394142  3162 solver.cpp:353] Iteration 20600 (63.1814 iter/s, 1.58275s/100 iter), loss = 0.00314268
I0801 13:34:57.394167  3162 solver.cpp:375]     Train net output #0: loss = 0.00314267 (* 1 = 0.00314267 loss)
I0801 13:34:57.394173  3162 sgd_solver.cpp:136] Iteration 20600, lr = 0.00678125, m = 0.9
I0801 13:34:58.966241  3162 solver.cpp:353] Iteration 20700 (63.6113 iter/s, 1.57205s/100 iter), loss = 0.00176934
I0801 13:34:58.966266  3162 solver.cpp:375]     Train net output #0: loss = 0.00176933 (* 1 = 0.00176933 loss)
I0801 13:34:58.966272  3162 sgd_solver.cpp:136] Iteration 20700, lr = 0.00676562, m = 0.9
I0801 13:35:00.529036  3162 solver.cpp:353] Iteration 20800 (63.9898 iter/s, 1.56275s/100 iter), loss = 0.00192885
I0801 13:35:00.529062  3162 solver.cpp:375]     Train net output #0: loss = 0.00192884 (* 1 = 0.00192884 loss)
I0801 13:35:00.529067  3162 sgd_solver.cpp:136] Iteration 20800, lr = 0.00675, m = 0.9
I0801 13:35:02.120262  3162 solver.cpp:353] Iteration 20900 (62.8467 iter/s, 1.59117s/100 iter), loss = 0.000963729
I0801 13:35:02.120291  3162 solver.cpp:375]     Train net output #0: loss = 0.000963719 (* 1 = 0.000963719 loss)
I0801 13:35:02.120298  3162 sgd_solver.cpp:136] Iteration 20900, lr = 0.00673437, m = 0.9
I0801 13:35:03.676352  3162 solver.cpp:550] Iteration 21000, Testing net (#0)
I0801 13:35:04.510782  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.913825
I0801 13:35:04.510802  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996765
I0801 13:35:04.510807  3162 solver.cpp:635]     Test net output #2: loss = 0.307761 (* 1 = 0.307761 loss)
I0801 13:35:04.510824  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.834448s
I0801 13:35:04.526720  3162 solver.cpp:353] Iteration 21000 (41.556 iter/s, 2.40639s/100 iter), loss = 0.00189566
I0801 13:35:04.526741  3162 solver.cpp:375]     Train net output #0: loss = 0.00189565 (* 1 = 0.00189565 loss)
I0801 13:35:04.526744  3162 sgd_solver.cpp:136] Iteration 21000, lr = 0.00671875, m = 0.9
I0801 13:35:06.108706  3162 solver.cpp:353] Iteration 21100 (63.2137 iter/s, 1.58194s/100 iter), loss = 0.000865045
I0801 13:35:06.108734  3162 solver.cpp:375]     Train net output #0: loss = 0.000865034 (* 1 = 0.000865034 loss)
I0801 13:35:06.108738  3162 sgd_solver.cpp:136] Iteration 21100, lr = 0.00670313, m = 0.9
I0801 13:35:07.691102  3162 solver.cpp:353] Iteration 21200 (63.1972 iter/s, 1.58235s/100 iter), loss = 0.00182832
I0801 13:35:07.691126  3162 solver.cpp:375]     Train net output #0: loss = 0.00182831 (* 1 = 0.00182831 loss)
I0801 13:35:07.691133  3162 sgd_solver.cpp:136] Iteration 21200, lr = 0.0066875, m = 0.9
I0801 13:35:09.258183  3162 solver.cpp:353] Iteration 21300 (63.815 iter/s, 1.56703s/100 iter), loss = 0.00110769
I0801 13:35:09.258235  3162 solver.cpp:375]     Train net output #0: loss = 0.00110768 (* 1 = 0.00110768 loss)
I0801 13:35:09.258246  3162 sgd_solver.cpp:136] Iteration 21300, lr = 0.00667187, m = 0.9
I0801 13:35:10.827497  3162 solver.cpp:353] Iteration 21400 (63.7241 iter/s, 1.56927s/100 iter), loss = 0.00063296
I0801 13:35:10.827522  3162 solver.cpp:375]     Train net output #0: loss = 0.000632949 (* 1 = 0.000632949 loss)
I0801 13:35:10.827527  3162 sgd_solver.cpp:136] Iteration 21400, lr = 0.00665625, m = 0.9
I0801 13:35:12.425302  3162 solver.cpp:353] Iteration 21500 (62.5879 iter/s, 1.59775s/100 iter), loss = 0.00137809
I0801 13:35:12.425326  3162 solver.cpp:375]     Train net output #0: loss = 0.00137808 (* 1 = 0.00137808 loss)
I0801 13:35:12.425333  3162 sgd_solver.cpp:136] Iteration 21500, lr = 0.00664062, m = 0.9
I0801 13:35:13.989990  3162 solver.cpp:353] Iteration 21600 (63.9123 iter/s, 1.56464s/100 iter), loss = 0.00249254
I0801 13:35:13.990015  3162 solver.cpp:375]     Train net output #0: loss = 0.00249252 (* 1 = 0.00249252 loss)
I0801 13:35:13.990022  3162 sgd_solver.cpp:136] Iteration 21600, lr = 0.006625, m = 0.9
I0801 13:35:15.558779  3162 solver.cpp:353] Iteration 21700 (63.7455 iter/s, 1.56874s/100 iter), loss = 0.00496568
I0801 13:35:15.558847  3162 solver.cpp:375]     Train net output #0: loss = 0.00496567 (* 1 = 0.00496567 loss)
I0801 13:35:15.558867  3162 sgd_solver.cpp:136] Iteration 21700, lr = 0.00660937, m = 0.9
I0801 13:35:17.133287  3162 solver.cpp:353] Iteration 21800 (63.5139 iter/s, 1.57446s/100 iter), loss = 0.00127497
I0801 13:35:17.133312  3162 solver.cpp:375]     Train net output #0: loss = 0.00127496 (* 1 = 0.00127496 loss)
I0801 13:35:17.133317  3162 sgd_solver.cpp:136] Iteration 21800, lr = 0.00659375, m = 0.9
I0801 13:35:18.716269  3162 solver.cpp:353] Iteration 21900 (63.1739 iter/s, 1.58293s/100 iter), loss = 0.000735967
I0801 13:35:18.716295  3162 solver.cpp:375]     Train net output #0: loss = 0.000735954 (* 1 = 0.000735954 loss)
I0801 13:35:18.716301  3162 sgd_solver.cpp:136] Iteration 21900, lr = 0.00657812, m = 0.9
I0801 13:35:20.278791  3162 solver.cpp:550] Iteration 22000, Testing net (#0)
I0801 13:35:20.693555  3160 data_reader.cpp:264] Starting prefetch of epoch 3
I0801 13:35:21.112946  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.909119
I0801 13:35:21.112967  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996177
I0801 13:35:21.112972  3162 solver.cpp:635]     Test net output #2: loss = 0.328989 (* 1 = 0.328989 loss)
I0801 13:35:21.112988  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.834175s
I0801 13:35:21.133836  3162 solver.cpp:353] Iteration 22000 (41.3651 iter/s, 2.4175s/100 iter), loss = 0.00116915
I0801 13:35:21.133886  3162 solver.cpp:375]     Train net output #0: loss = 0.00116914 (* 1 = 0.00116914 loss)
I0801 13:35:21.133898  3162 sgd_solver.cpp:136] Iteration 22000, lr = 0.0065625, m = 0.9
I0801 13:35:22.738128  3162 solver.cpp:353] Iteration 22100 (62.3346 iter/s, 1.60424s/100 iter), loss = 0.00215396
I0801 13:35:22.738175  3162 solver.cpp:375]     Train net output #0: loss = 0.00215395 (* 1 = 0.00215395 loss)
I0801 13:35:22.738188  3162 sgd_solver.cpp:136] Iteration 22100, lr = 0.00654687, m = 0.9
I0801 13:35:24.329382  3162 solver.cpp:353] Iteration 22200 (62.8455 iter/s, 1.5912s/100 iter), loss = 0.00181298
I0801 13:35:24.329408  3162 solver.cpp:375]     Train net output #0: loss = 0.00181296 (* 1 = 0.00181296 loss)
I0801 13:35:24.329414  3162 sgd_solver.cpp:136] Iteration 22200, lr = 0.00653125, m = 0.9
I0801 13:35:25.896111  3162 solver.cpp:353] Iteration 22300 (63.8292 iter/s, 1.56668s/100 iter), loss = 0.000230271
I0801 13:35:25.896136  3162 solver.cpp:375]     Train net output #0: loss = 0.000230256 (* 1 = 0.000230256 loss)
I0801 13:35:25.896142  3162 sgd_solver.cpp:136] Iteration 22300, lr = 0.00651562, m = 0.9
I0801 13:35:27.482998  3162 solver.cpp:353] Iteration 22400 (63.0185 iter/s, 1.58684s/100 iter), loss = 0.00165331
I0801 13:35:27.483050  3162 solver.cpp:375]     Train net output #0: loss = 0.0016533 (* 1 = 0.0016533 loss)
I0801 13:35:27.483064  3162 sgd_solver.cpp:136] Iteration 22400, lr = 0.0065, m = 0.9
I0801 13:35:29.052687  3162 solver.cpp:353] Iteration 22500 (63.7089 iter/s, 1.56964s/100 iter), loss = 0.00123862
I0801 13:35:29.052713  3162 solver.cpp:375]     Train net output #0: loss = 0.00123861 (* 1 = 0.00123861 loss)
I0801 13:35:29.052718  3162 sgd_solver.cpp:136] Iteration 22500, lr = 0.00648437, m = 0.9
I0801 13:35:30.622566  3162 solver.cpp:353] Iteration 22600 (63.7012 iter/s, 1.56983s/100 iter), loss = 0.000938061
I0801 13:35:30.622591  3162 solver.cpp:375]     Train net output #0: loss = 0.000938045 (* 1 = 0.000938045 loss)
I0801 13:35:30.622596  3162 sgd_solver.cpp:136] Iteration 22600, lr = 0.00646875, m = 0.9
I0801 13:35:32.191764  3162 solver.cpp:353] Iteration 22700 (63.7287 iter/s, 1.56915s/100 iter), loss = 0.00381101
I0801 13:35:32.191788  3162 solver.cpp:375]     Train net output #0: loss = 0.00381099 (* 1 = 0.00381099 loss)
I0801 13:35:32.191794  3162 sgd_solver.cpp:136] Iteration 22700, lr = 0.00645312, m = 0.9
I0801 13:35:33.782351  3162 solver.cpp:353] Iteration 22800 (62.8719 iter/s, 1.59054s/100 iter), loss = 0.0038699
I0801 13:35:33.782398  3162 solver.cpp:375]     Train net output #0: loss = 0.00386988 (* 1 = 0.00386988 loss)
I0801 13:35:33.782405  3162 sgd_solver.cpp:136] Iteration 22800, lr = 0.0064375, m = 0.9
I0801 13:35:35.351768  3162 solver.cpp:353] Iteration 22900 (63.72 iter/s, 1.56937s/100 iter), loss = 0.000424948
I0801 13:35:35.351794  3162 solver.cpp:375]     Train net output #0: loss = 0.00042493 (* 1 = 0.00042493 loss)
I0801 13:35:35.351799  3162 sgd_solver.cpp:136] Iteration 22900, lr = 0.00642187, m = 0.9
I0801 13:35:36.891412  3162 solver.cpp:550] Iteration 23000, Testing net (#0)
I0801 13:35:37.741916  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.910001
I0801 13:35:37.741936  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.997059
I0801 13:35:37.741941  3162 solver.cpp:635]     Test net output #2: loss = 0.313046 (* 1 = 0.313046 loss)
I0801 13:35:37.741960  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.850526s
I0801 13:35:37.757463  3162 solver.cpp:353] Iteration 23000 (41.5692 iter/s, 2.40563s/100 iter), loss = 0.00142508
I0801 13:35:37.757509  3162 solver.cpp:375]     Train net output #0: loss = 0.00142506 (* 1 = 0.00142506 loss)
I0801 13:35:37.757526  3162 sgd_solver.cpp:136] Iteration 23000, lr = 0.00640625, m = 0.9
I0801 13:35:39.319633  3162 solver.cpp:353] Iteration 23100 (64.0156 iter/s, 1.56212s/100 iter), loss = 0.00276654
I0801 13:35:39.319658  3162 solver.cpp:375]     Train net output #0: loss = 0.00276653 (* 1 = 0.00276653 loss)
I0801 13:35:39.319664  3162 sgd_solver.cpp:136] Iteration 23100, lr = 0.00639063, m = 0.9
I0801 13:35:40.885732  3162 solver.cpp:353] Iteration 23200 (63.8549 iter/s, 1.56605s/100 iter), loss = 0.0022474
I0801 13:35:40.885758  3162 solver.cpp:375]     Train net output #0: loss = 0.00224738 (* 1 = 0.00224738 loss)
I0801 13:35:40.885762  3162 sgd_solver.cpp:136] Iteration 23200, lr = 0.006375, m = 0.9
I0801 13:35:42.463582  3162 solver.cpp:353] Iteration 23300 (63.3794 iter/s, 1.5778s/100 iter), loss = 0.00169306
I0801 13:35:42.463629  3162 solver.cpp:375]     Train net output #0: loss = 0.00169304 (* 1 = 0.00169304 loss)
I0801 13:35:42.463640  3162 sgd_solver.cpp:136] Iteration 23300, lr = 0.00635938, m = 0.9
I0801 13:35:44.041713  3162 solver.cpp:353] Iteration 23400 (63.368 iter/s, 1.57808s/100 iter), loss = 0.00179238
I0801 13:35:44.041764  3162 solver.cpp:375]     Train net output #0: loss = 0.00179236 (* 1 = 0.00179236 loss)
I0801 13:35:44.041777  3162 sgd_solver.cpp:136] Iteration 23400, lr = 0.00634375, m = 0.9
I0801 13:35:45.615854  3162 solver.cpp:353] Iteration 23500 (63.5287 iter/s, 1.57409s/100 iter), loss = 0.000936574
I0801 13:35:45.615880  3162 solver.cpp:375]     Train net output #0: loss = 0.000936556 (* 1 = 0.000936556 loss)
I0801 13:35:45.615886  3162 sgd_solver.cpp:136] Iteration 23500, lr = 0.00632813, m = 0.9
I0801 13:35:47.184586  3162 solver.cpp:353] Iteration 23600 (63.7478 iter/s, 1.56868s/100 iter), loss = 0.0013329
I0801 13:35:47.184610  3162 solver.cpp:375]     Train net output #0: loss = 0.00133288 (* 1 = 0.00133288 loss)
I0801 13:35:47.184617  3162 sgd_solver.cpp:136] Iteration 23600, lr = 0.0063125, m = 0.9
I0801 13:35:48.746670  3162 solver.cpp:353] Iteration 23700 (64.019 iter/s, 1.56204s/100 iter), loss = 0.00252372
I0801 13:35:48.746696  3162 solver.cpp:375]     Train net output #0: loss = 0.00252371 (* 1 = 0.00252371 loss)
I0801 13:35:48.746703  3162 sgd_solver.cpp:136] Iteration 23700, lr = 0.00629687, m = 0.9
I0801 13:35:50.326304  3162 solver.cpp:353] Iteration 23800 (63.3078 iter/s, 1.57958s/100 iter), loss = 0.000803195
I0801 13:35:50.326400  3162 solver.cpp:375]     Train net output #0: loss = 0.000803179 (* 1 = 0.000803179 loss)
I0801 13:35:50.326407  3162 sgd_solver.cpp:136] Iteration 23800, lr = 0.00628125, m = 0.9
I0801 13:35:51.884249  3162 solver.cpp:353] Iteration 23900 (64.1892 iter/s, 1.55789s/100 iter), loss = 0.000968432
I0801 13:35:51.884275  3162 solver.cpp:375]     Train net output #0: loss = 0.000968417 (* 1 = 0.000968417 loss)
I0801 13:35:51.884281  3162 sgd_solver.cpp:136] Iteration 23900, lr = 0.00626562, m = 0.9
I0801 13:35:53.443436  3162 solver.cpp:550] Iteration 24000, Testing net (#0)
I0801 13:35:54.276695  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.907354
I0801 13:35:54.276713  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996765
I0801 13:35:54.276718  3162 solver.cpp:635]     Test net output #2: loss = 0.323635 (* 1 = 0.323635 loss)
I0801 13:35:54.276736  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.833276s
I0801 13:35:54.301069  3162 solver.cpp:353] Iteration 24000 (41.3779 iter/s, 2.41675s/100 iter), loss = 0.00329714
I0801 13:35:54.301092  3162 solver.cpp:375]     Train net output #0: loss = 0.00329712 (* 1 = 0.00329712 loss)
I0801 13:35:54.301096  3162 sgd_solver.cpp:136] Iteration 24000, lr = 0.00625, m = 0.9
I0801 13:35:55.866780  3162 solver.cpp:353] Iteration 24100 (63.8706 iter/s, 1.56566s/100 iter), loss = 0.00163425
I0801 13:35:55.866833  3162 solver.cpp:375]     Train net output #0: loss = 0.00163423 (* 1 = 0.00163423 loss)
I0801 13:35:55.866848  3162 sgd_solver.cpp:136] Iteration 24100, lr = 0.00623438, m = 0.9
I0801 13:35:57.454303  3162 solver.cpp:353] Iteration 24200 (62.9932 iter/s, 1.58747s/100 iter), loss = 0.00154251
I0801 13:35:57.454327  3162 solver.cpp:375]     Train net output #0: loss = 0.0015425 (* 1 = 0.0015425 loss)
I0801 13:35:57.454334  3162 sgd_solver.cpp:136] Iteration 24200, lr = 0.00621875, m = 0.9
I0801 13:35:59.027142  3162 solver.cpp:353] Iteration 24300 (63.5812 iter/s, 1.57279s/100 iter), loss = 0.00136563
I0801 13:35:59.027166  3162 solver.cpp:375]     Train net output #0: loss = 0.00136562 (* 1 = 0.00136562 loss)
I0801 13:35:59.027170  3162 sgd_solver.cpp:136] Iteration 24300, lr = 0.00620312, m = 0.9
I0801 13:36:00.606956  3162 solver.cpp:353] Iteration 24400 (63.3007 iter/s, 1.57976s/100 iter), loss = 0.0027343
I0801 13:36:00.606982  3162 solver.cpp:375]     Train net output #0: loss = 0.00273429 (* 1 = 0.00273429 loss)
I0801 13:36:00.606989  3162 sgd_solver.cpp:136] Iteration 24400, lr = 0.0061875, m = 0.9
I0801 13:36:02.173779  3162 solver.cpp:353] Iteration 24500 (63.8253 iter/s, 1.56678s/100 iter), loss = 0.000771487
I0801 13:36:02.173807  3162 solver.cpp:375]     Train net output #0: loss = 0.000771475 (* 1 = 0.000771475 loss)
I0801 13:36:02.173811  3162 sgd_solver.cpp:136] Iteration 24500, lr = 0.00617187, m = 0.9
I0801 13:36:03.742211  3162 solver.cpp:353] Iteration 24600 (63.7599 iter/s, 1.56838s/100 iter), loss = 0.00227917
I0801 13:36:03.742238  3162 solver.cpp:375]     Train net output #0: loss = 0.00227915 (* 1 = 0.00227915 loss)
I0801 13:36:03.742244  3162 sgd_solver.cpp:136] Iteration 24600, lr = 0.00615625, m = 0.9
I0801 13:36:05.327760  3162 solver.cpp:353] Iteration 24700 (63.0715 iter/s, 1.5855s/100 iter), loss = 0.00190813
I0801 13:36:05.327786  3162 solver.cpp:375]     Train net output #0: loss = 0.00190812 (* 1 = 0.00190812 loss)
I0801 13:36:05.327791  3162 sgd_solver.cpp:136] Iteration 24700, lr = 0.00614062, m = 0.9
I0801 13:36:06.889142  3162 solver.cpp:353] Iteration 24800 (64.0478 iter/s, 1.56133s/100 iter), loss = 0.00148341
I0801 13:36:06.889169  3162 solver.cpp:375]     Train net output #0: loss = 0.0014834 (* 1 = 0.0014834 loss)
I0801 13:36:06.889176  3162 sgd_solver.cpp:136] Iteration 24800, lr = 0.006125, m = 0.9
I0801 13:36:08.465796  3162 solver.cpp:353] Iteration 24900 (63.4274 iter/s, 1.5766s/100 iter), loss = 0.00087245
I0801 13:36:08.465819  3162 solver.cpp:375]     Train net output #0: loss = 0.000872442 (* 1 = 0.000872442 loss)
I0801 13:36:08.465823  3162 sgd_solver.cpp:136] Iteration 24900, lr = 0.00610937, m = 0.9
I0801 13:36:10.016957  3162 solver.cpp:550] Iteration 25000, Testing net (#0)
I0801 13:36:10.849700  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.905001
I0801 13:36:10.849720  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.995294
I0801 13:36:10.849725  3162 solver.cpp:635]     Test net output #2: loss = 0.348231 (* 1 = 0.348231 loss)
I0801 13:36:10.849740  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.83276s
I0801 13:36:10.866247  3162 solver.cpp:353] Iteration 25000 (41.6601 iter/s, 2.40038s/100 iter), loss = 0.00223768
I0801 13:36:10.866266  3162 solver.cpp:375]     Train net output #0: loss = 0.00223768 (* 1 = 0.00223768 loss)
I0801 13:36:10.866269  3162 sgd_solver.cpp:136] Iteration 25000, lr = 0.00609375, m = 0.9
I0801 13:36:12.443892  3162 solver.cpp:353] Iteration 25100 (63.3877 iter/s, 1.57759s/100 iter), loss = 0.00128196
I0801 13:36:12.443915  3162 solver.cpp:375]     Train net output #0: loss = 0.00128195 (* 1 = 0.00128195 loss)
I0801 13:36:12.443919  3162 sgd_solver.cpp:136] Iteration 25100, lr = 0.00607812, m = 0.9
I0801 13:36:14.006191  3162 solver.cpp:353] Iteration 25200 (64.0102 iter/s, 1.56225s/100 iter), loss = 0.00386459
I0801 13:36:14.006218  3162 solver.cpp:375]     Train net output #0: loss = 0.00386458 (* 1 = 0.00386458 loss)
I0801 13:36:14.006224  3162 sgd_solver.cpp:136] Iteration 25200, lr = 0.0060625, m = 0.9
I0801 13:36:15.585216  3162 solver.cpp:353] Iteration 25300 (63.3322 iter/s, 1.57898s/100 iter), loss = 0.000680805
I0801 13:36:15.585268  3162 solver.cpp:375]     Train net output #0: loss = 0.000680796 (* 1 = 0.000680796 loss)
I0801 13:36:15.585299  3162 sgd_solver.cpp:136] Iteration 25300, lr = 0.00604687, m = 0.9
I0801 13:36:17.174904  3162 solver.cpp:353] Iteration 25400 (62.9075 iter/s, 1.58964s/100 iter), loss = 0.00114861
I0801 13:36:17.174934  3162 solver.cpp:375]     Train net output #0: loss = 0.0011486 (* 1 = 0.0011486 loss)
I0801 13:36:17.174940  3162 sgd_solver.cpp:136] Iteration 25400, lr = 0.00603125, m = 0.9
I0801 13:36:18.749426  3162 solver.cpp:353] Iteration 25500 (63.5134 iter/s, 1.57447s/100 iter), loss = 0.00367265
I0801 13:36:18.749451  3162 solver.cpp:375]     Train net output #0: loss = 0.00367264 (* 1 = 0.00367264 loss)
I0801 13:36:18.749456  3162 sgd_solver.cpp:136] Iteration 25500, lr = 0.00601562, m = 0.9
I0801 13:36:20.324941  3162 solver.cpp:353] Iteration 25600 (63.4732 iter/s, 1.57547s/100 iter), loss = 0.00181789
I0801 13:36:20.324990  3162 solver.cpp:375]     Train net output #0: loss = 0.00181788 (* 1 = 0.00181788 loss)
I0801 13:36:20.325003  3162 sgd_solver.cpp:136] Iteration 25600, lr = 0.006, m = 0.9
I0801 13:36:21.877605  3162 solver.cpp:353] Iteration 25700 (64.4075 iter/s, 1.55261s/100 iter), loss = 0.000208859
I0801 13:36:21.877691  3162 solver.cpp:375]     Train net output #0: loss = 0.000208847 (* 1 = 0.000208847 loss)
I0801 13:36:21.877698  3162 sgd_solver.cpp:136] Iteration 25700, lr = 0.00598437, m = 0.9
I0801 13:36:23.441684  3162 solver.cpp:353] Iteration 25800 (63.9374 iter/s, 1.56403s/100 iter), loss = 0.00167767
I0801 13:36:23.441709  3162 solver.cpp:375]     Train net output #0: loss = 0.00167766 (* 1 = 0.00167766 loss)
I0801 13:36:23.441715  3162 sgd_solver.cpp:136] Iteration 25800, lr = 0.00596875, m = 0.9
I0801 13:36:25.009162  3162 solver.cpp:353] Iteration 25900 (63.7987 iter/s, 1.56743s/100 iter), loss = 0.000373563
I0801 13:36:25.009189  3162 solver.cpp:375]     Train net output #0: loss = 0.00037355 (* 1 = 0.00037355 loss)
I0801 13:36:25.009196  3162 sgd_solver.cpp:136] Iteration 25900, lr = 0.00595312, m = 0.9
I0801 13:36:26.560359  3162 solver.cpp:550] Iteration 26000, Testing net (#0)
I0801 13:36:27.401494  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.902648
I0801 13:36:27.401510  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996471
I0801 13:36:27.401515  3162 solver.cpp:635]     Test net output #2: loss = 0.344368 (* 1 = 0.344368 loss)
I0801 13:36:27.401533  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.841151s
I0801 13:36:27.417439  3162 solver.cpp:353] Iteration 26000 (41.5247 iter/s, 2.40821s/100 iter), loss = 0.00135849
I0801 13:36:27.417459  3162 solver.cpp:375]     Train net output #0: loss = 0.00135847 (* 1 = 0.00135847 loss)
I0801 13:36:27.417465  3162 sgd_solver.cpp:136] Iteration 26000, lr = 0.0059375, m = 0.9
I0801 13:36:28.979737  3162 solver.cpp:353] Iteration 26100 (64.0103 iter/s, 1.56225s/100 iter), loss = 0.00030438
I0801 13:36:28.979761  3162 solver.cpp:375]     Train net output #0: loss = 0.000304366 (* 1 = 0.000304366 loss)
I0801 13:36:28.979768  3162 sgd_solver.cpp:136] Iteration 26100, lr = 0.00592188, m = 0.9
I0801 13:36:30.552006  3162 solver.cpp:353] Iteration 26200 (63.6043 iter/s, 1.57222s/100 iter), loss = 0.00125945
I0801 13:36:30.552032  3162 solver.cpp:375]     Train net output #0: loss = 0.00125944 (* 1 = 0.00125944 loss)
I0801 13:36:30.552038  3162 sgd_solver.cpp:136] Iteration 26200, lr = 0.00590625, m = 0.9
I0801 13:36:32.138422  3162 solver.cpp:353] Iteration 26300 (63.0373 iter/s, 1.58636s/100 iter), loss = 0.000798849
I0801 13:36:32.138475  3162 solver.cpp:375]     Train net output #0: loss = 0.000798837 (* 1 = 0.000798837 loss)
I0801 13:36:32.138489  3162 sgd_solver.cpp:136] Iteration 26300, lr = 0.00589063, m = 0.9
I0801 13:36:33.731420  3162 solver.cpp:353] Iteration 26400 (62.7766 iter/s, 1.59295s/100 iter), loss = 0.00145864
I0801 13:36:33.731444  3162 solver.cpp:375]     Train net output #0: loss = 0.00145863 (* 1 = 0.00145863 loss)
I0801 13:36:33.731451  3162 sgd_solver.cpp:136] Iteration 26400, lr = 0.005875, m = 0.9
I0801 13:36:35.318101  3162 solver.cpp:353] Iteration 26500 (63.0266 iter/s, 1.58663s/100 iter), loss = 0.00122978
I0801 13:36:35.318130  3162 solver.cpp:375]     Train net output #0: loss = 0.00122977 (* 1 = 0.00122977 loss)
I0801 13:36:35.318135  3162 sgd_solver.cpp:136] Iteration 26500, lr = 0.00585938, m = 0.9
I0801 13:36:35.504281  3155 data_reader.cpp:264] Starting prefetch of epoch 4
I0801 13:36:36.901480  3162 solver.cpp:353] Iteration 26600 (63.1581 iter/s, 1.58333s/100 iter), loss = 0.0060073
I0801 13:36:36.901507  3162 solver.cpp:375]     Train net output #0: loss = 0.00600729 (* 1 = 0.00600729 loss)
I0801 13:36:36.901513  3162 sgd_solver.cpp:136] Iteration 26600, lr = 0.00584375, m = 0.9
I0801 13:36:38.482816  3162 solver.cpp:353] Iteration 26700 (63.2395 iter/s, 1.58129s/100 iter), loss = 0.000729036
I0801 13:36:38.482842  3162 solver.cpp:375]     Train net output #0: loss = 0.000729024 (* 1 = 0.000729024 loss)
I0801 13:36:38.482849  3162 sgd_solver.cpp:136] Iteration 26700, lr = 0.00582812, m = 0.9
I0801 13:36:40.071686  3162 solver.cpp:353] Iteration 26800 (62.9398 iter/s, 1.58882s/100 iter), loss = 0.00188542
I0801 13:36:40.071713  3162 solver.cpp:375]     Train net output #0: loss = 0.0018854 (* 1 = 0.0018854 loss)
I0801 13:36:40.071743  3162 sgd_solver.cpp:136] Iteration 26800, lr = 0.0058125, m = 0.9
I0801 13:36:41.649560  3162 solver.cpp:353] Iteration 26900 (63.3786 iter/s, 1.57782s/100 iter), loss = 0.000398044
I0801 13:36:41.649592  3162 solver.cpp:375]     Train net output #0: loss = 0.000398032 (* 1 = 0.000398032 loss)
I0801 13:36:41.649598  3162 sgd_solver.cpp:136] Iteration 26900, lr = 0.00579687, m = 0.9
I0801 13:36:43.198582  3162 solver.cpp:550] Iteration 27000, Testing net (#0)
I0801 13:36:44.036263  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.908236
I0801 13:36:44.036285  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.995882
I0801 13:36:44.036290  3162 solver.cpp:635]     Test net output #2: loss = 0.349026 (* 1 = 0.349026 loss)
I0801 13:36:44.036353  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.837748s
I0801 13:36:44.052059  3162 solver.cpp:353] Iteration 27000 (41.6245 iter/s, 2.40243s/100 iter), loss = 0.000798737
I0801 13:36:44.052078  3162 solver.cpp:375]     Train net output #0: loss = 0.000798724 (* 1 = 0.000798724 loss)
I0801 13:36:44.052084  3162 sgd_solver.cpp:136] Iteration 27000, lr = 0.00578125, m = 0.9
I0801 13:36:45.639225  3162 solver.cpp:353] Iteration 27100 (63.0074 iter/s, 1.58712s/100 iter), loss = 0.00192432
I0801 13:36:45.639253  3162 solver.cpp:375]     Train net output #0: loss = 0.00192431 (* 1 = 0.00192431 loss)
I0801 13:36:45.639261  3162 sgd_solver.cpp:136] Iteration 27100, lr = 0.00576563, m = 0.9
I0801 13:36:47.220161  3162 solver.cpp:353] Iteration 27200 (63.2557 iter/s, 1.58089s/100 iter), loss = 0.00094211
I0801 13:36:47.220212  3162 solver.cpp:375]     Train net output #0: loss = 0.000942096 (* 1 = 0.000942096 loss)
I0801 13:36:47.220232  3162 sgd_solver.cpp:136] Iteration 27200, lr = 0.00575, m = 0.9
I0801 13:36:48.796099  3162 solver.cpp:353] Iteration 27300 (63.4563 iter/s, 1.57589s/100 iter), loss = 0.00098815
I0801 13:36:48.796128  3162 solver.cpp:375]     Train net output #0: loss = 0.000988137 (* 1 = 0.000988137 loss)
I0801 13:36:48.796133  3162 sgd_solver.cpp:136] Iteration 27300, lr = 0.00573438, m = 0.9
I0801 13:36:50.369688  3162 solver.cpp:353] Iteration 27400 (63.551 iter/s, 1.57354s/100 iter), loss = 0.000479659
I0801 13:36:50.369760  3162 solver.cpp:375]     Train net output #0: loss = 0.000479645 (* 1 = 0.000479645 loss)
I0801 13:36:50.369781  3162 sgd_solver.cpp:136] Iteration 27400, lr = 0.00571875, m = 0.9
I0801 13:36:51.936031  3162 solver.cpp:353] Iteration 27500 (63.8449 iter/s, 1.5663s/100 iter), loss = 0.00140472
I0801 13:36:51.936133  3162 solver.cpp:375]     Train net output #0: loss = 0.0014047 (* 1 = 0.0014047 loss)
I0801 13:36:51.936152  3162 sgd_solver.cpp:136] Iteration 27500, lr = 0.00570312, m = 0.9
I0801 13:36:53.499089  3162 solver.cpp:353] Iteration 27600 (63.9792 iter/s, 1.56301s/100 iter), loss = 0.00295227
I0801 13:36:53.499114  3162 solver.cpp:375]     Train net output #0: loss = 0.00295226 (* 1 = 0.00295226 loss)
I0801 13:36:53.499120  3162 sgd_solver.cpp:136] Iteration 27600, lr = 0.0056875, m = 0.9
I0801 13:36:55.064117  3162 solver.cpp:353] Iteration 27700 (63.8987 iter/s, 1.56498s/100 iter), loss = 0.000319496
I0801 13:36:55.064170  3162 solver.cpp:375]     Train net output #0: loss = 0.000319483 (* 1 = 0.000319483 loss)
I0801 13:36:55.064184  3162 sgd_solver.cpp:136] Iteration 27700, lr = 0.00567187, m = 0.9
I0801 13:36:56.640965  3162 solver.cpp:353] Iteration 27800 (63.4196 iter/s, 1.5768s/100 iter), loss = 0.000888276
I0801 13:36:56.640990  3162 solver.cpp:375]     Train net output #0: loss = 0.000888262 (* 1 = 0.000888262 loss)
I0801 13:36:56.640995  3162 sgd_solver.cpp:136] Iteration 27800, lr = 0.00565625, m = 0.9
I0801 13:36:58.230782  3162 solver.cpp:353] Iteration 27900 (62.9024 iter/s, 1.58977s/100 iter), loss = 0.000906093
I0801 13:36:58.230811  3162 solver.cpp:375]     Train net output #0: loss = 0.000906078 (* 1 = 0.000906078 loss)
I0801 13:36:58.230816  3162 sgd_solver.cpp:136] Iteration 27900, lr = 0.00564062, m = 0.9
I0801 13:36:59.783843  3162 solver.cpp:550] Iteration 28000, Testing net (#0)
I0801 13:37:00.617080  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.901766
I0801 13:37:00.617100  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.995294
I0801 13:37:00.617105  3162 solver.cpp:635]     Test net output #2: loss = 0.344178 (* 1 = 0.344178 loss)
I0801 13:37:00.617118  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.833252s
I0801 13:37:00.632686  3162 solver.cpp:353] Iteration 28000 (41.6348 iter/s, 2.40184s/100 iter), loss = 0.00166902
I0801 13:37:00.632705  3162 solver.cpp:375]     Train net output #0: loss = 0.00166901 (* 1 = 0.00166901 loss)
I0801 13:37:00.632709  3162 sgd_solver.cpp:136] Iteration 28000, lr = 0.005625, m = 0.9
I0801 13:37:02.198653  3162 solver.cpp:353] Iteration 28100 (63.8604 iter/s, 1.56592s/100 iter), loss = 0.00327241
I0801 13:37:02.198678  3162 solver.cpp:375]     Train net output #0: loss = 0.00327239 (* 1 = 0.00327239 loss)
I0801 13:37:02.198681  3162 sgd_solver.cpp:136] Iteration 28100, lr = 0.00560937, m = 0.9
I0801 13:37:03.773459  3162 solver.cpp:353] Iteration 28200 (63.502 iter/s, 1.57475s/100 iter), loss = 0.000307535
I0801 13:37:03.773641  3162 solver.cpp:375]     Train net output #0: loss = 0.000307519 (* 1 = 0.000307519 loss)
I0801 13:37:03.773660  3162 sgd_solver.cpp:136] Iteration 28200, lr = 0.00559375, m = 0.9
I0801 13:37:05.346474  3162 solver.cpp:353] Iteration 28300 (63.5741 iter/s, 1.57297s/100 iter), loss = 0.000818517
I0801 13:37:05.346498  3162 solver.cpp:375]     Train net output #0: loss = 0.000818501 (* 1 = 0.000818501 loss)
I0801 13:37:05.346503  3162 sgd_solver.cpp:136] Iteration 28300, lr = 0.00557812, m = 0.9
I0801 13:37:06.909046  3162 solver.cpp:353] Iteration 28400 (63.999 iter/s, 1.56252s/100 iter), loss = 0.000916163
I0801 13:37:06.909108  3162 solver.cpp:375]     Train net output #0: loss = 0.000916147 (* 1 = 0.000916147 loss)
I0801 13:37:06.909127  3162 sgd_solver.cpp:136] Iteration 28400, lr = 0.0055625, m = 0.9
I0801 13:37:08.477705  3162 solver.cpp:353] Iteration 28500 (63.7507 iter/s, 1.56861s/100 iter), loss = 0.00202818
I0801 13:37:08.477731  3162 solver.cpp:375]     Train net output #0: loss = 0.00202816 (* 1 = 0.00202816 loss)
I0801 13:37:08.477736  3162 sgd_solver.cpp:136] Iteration 28500, lr = 0.00554687, m = 0.9
I0801 13:37:10.036187  3162 solver.cpp:353] Iteration 28600 (64.167 iter/s, 1.55843s/100 iter), loss = 0.0010555
I0801 13:37:10.036236  3162 solver.cpp:375]     Train net output #0: loss = 0.00105548 (* 1 = 0.00105548 loss)
I0801 13:37:10.036249  3162 sgd_solver.cpp:136] Iteration 28600, lr = 0.00553125, m = 0.9
I0801 13:37:11.610000  3162 solver.cpp:353] Iteration 28700 (63.542 iter/s, 1.57376s/100 iter), loss = 0.00153006
I0801 13:37:11.610028  3162 solver.cpp:375]     Train net output #0: loss = 0.00153005 (* 1 = 0.00153005 loss)
I0801 13:37:11.610033  3162 sgd_solver.cpp:136] Iteration 28700, lr = 0.00551562, m = 0.9
I0801 13:37:13.187621  3162 solver.cpp:353] Iteration 28800 (63.3885 iter/s, 1.57757s/100 iter), loss = 0.00183215
I0801 13:37:13.187650  3162 solver.cpp:375]     Train net output #0: loss = 0.00183214 (* 1 = 0.00183214 loss)
I0801 13:37:13.187657  3162 sgd_solver.cpp:136] Iteration 28800, lr = 0.0055, m = 0.9
I0801 13:37:14.766568  3162 solver.cpp:353] Iteration 28900 (63.3354 iter/s, 1.5789s/100 iter), loss = 0.0027007
I0801 13:37:14.766594  3162 solver.cpp:375]     Train net output #0: loss = 0.00270069 (* 1 = 0.00270069 loss)
I0801 13:37:14.766599  3162 sgd_solver.cpp:136] Iteration 28900, lr = 0.00548437, m = 0.9
I0801 13:37:16.336758  3162 solver.cpp:550] Iteration 29000, Testing net (#0)
I0801 13:37:17.168149  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.914119
I0801 13:37:17.168169  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996177
I0801 13:37:17.168176  3162 solver.cpp:635]     Test net output #2: loss = 0.297321 (* 1 = 0.297321 loss)
I0801 13:37:17.168196  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.831414s
I0801 13:37:17.184496  3162 solver.cpp:353] Iteration 29000 (41.3589 iter/s, 2.41786s/100 iter), loss = 0.00456476
I0801 13:37:17.184518  3162 solver.cpp:375]     Train net output #0: loss = 0.00456475 (* 1 = 0.00456475 loss)
I0801 13:37:17.184525  3162 sgd_solver.cpp:136] Iteration 29000, lr = 0.00546875, m = 0.9
I0801 13:37:18.765697  3162 solver.cpp:353] Iteration 29100 (63.2451 iter/s, 1.58115s/100 iter), loss = 0.0168719
I0801 13:37:18.765722  3162 solver.cpp:375]     Train net output #0: loss = 0.0168719 (* 1 = 0.0168719 loss)
I0801 13:37:18.765727  3162 sgd_solver.cpp:136] Iteration 29100, lr = 0.00545313, m = 0.9
I0801 13:37:20.360671  3162 solver.cpp:353] Iteration 29200 (62.699 iter/s, 1.59492s/100 iter), loss = 0.00132883
I0801 13:37:20.360697  3162 solver.cpp:375]     Train net output #0: loss = 0.00132882 (* 1 = 0.00132882 loss)
I0801 13:37:20.360704  3162 sgd_solver.cpp:136] Iteration 29200, lr = 0.0054375, m = 0.9
I0801 13:37:21.937532  3162 solver.cpp:353] Iteration 29300 (63.419 iter/s, 1.57681s/100 iter), loss = 0.00261831
I0801 13:37:21.937608  3162 solver.cpp:375]     Train net output #0: loss = 0.0026183 (* 1 = 0.0026183 loss)
I0801 13:37:21.937613  3162 sgd_solver.cpp:136] Iteration 29300, lr = 0.00542188, m = 0.9
I0801 13:37:23.512759  3162 solver.cpp:353] Iteration 29400 (63.4849 iter/s, 1.57518s/100 iter), loss = 0.00407552
I0801 13:37:23.512784  3162 solver.cpp:375]     Train net output #0: loss = 0.00407551 (* 1 = 0.00407551 loss)
I0801 13:37:23.512790  3162 sgd_solver.cpp:136] Iteration 29400, lr = 0.00540625, m = 0.9
I0801 13:37:25.080785  3162 solver.cpp:353] Iteration 29500 (63.7764 iter/s, 1.56798s/100 iter), loss = 0.00230512
I0801 13:37:25.080852  3162 solver.cpp:375]     Train net output #0: loss = 0.00230511 (* 1 = 0.00230511 loss)
I0801 13:37:25.080869  3162 sgd_solver.cpp:136] Iteration 29500, lr = 0.00539062, m = 0.9
I0801 13:37:26.645603  3162 solver.cpp:353] Iteration 29600 (63.9072 iter/s, 1.56477s/100 iter), loss = 0.000542094
I0801 13:37:26.645628  3162 solver.cpp:375]     Train net output #0: loss = 0.000542087 (* 1 = 0.000542087 loss)
I0801 13:37:26.645634  3162 sgd_solver.cpp:136] Iteration 29600, lr = 0.005375, m = 0.9
I0801 13:37:28.220088  3162 solver.cpp:353] Iteration 29700 (63.5148 iter/s, 1.57444s/100 iter), loss = 0.00657517
I0801 13:37:28.220113  3162 solver.cpp:375]     Train net output #0: loss = 0.00657516 (* 1 = 0.00657516 loss)
I0801 13:37:28.220119  3162 sgd_solver.cpp:136] Iteration 29700, lr = 0.00535937, m = 0.9
I0801 13:37:29.798686  3162 solver.cpp:353] Iteration 29800 (63.3495 iter/s, 1.57855s/100 iter), loss = 0.00243559
I0801 13:37:29.798712  3162 solver.cpp:375]     Train net output #0: loss = 0.00243559 (* 1 = 0.00243559 loss)
I0801 13:37:29.798717  3162 sgd_solver.cpp:136] Iteration 29800, lr = 0.00534375, m = 0.9
I0801 13:37:31.377461  3162 solver.cpp:353] Iteration 29900 (63.3422 iter/s, 1.57873s/100 iter), loss = 0.00124994
I0801 13:37:31.377528  3162 solver.cpp:375]     Train net output #0: loss = 0.00124993 (* 1 = 0.00124993 loss)
I0801 13:37:31.377562  3162 sgd_solver.cpp:136] Iteration 29900, lr = 0.00532812, m = 0.9
I0801 13:37:32.924229  3162 solver.cpp:680] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/l1reg/cifar10_jacintonet11v2_iter_30000.caffemodel
I0801 13:37:32.932258  3162 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/l1reg/cifar10_jacintonet11v2_iter_30000.solverstate
I0801 13:37:32.935839  3162 solver.cpp:550] Iteration 30000, Testing net (#0)
I0801 13:37:33.757733  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.913825
I0801 13:37:33.757753  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.997059
I0801 13:37:33.757761  3162 solver.cpp:635]     Test net output #2: loss = 0.29831 (* 1 = 0.29831 loss)
I0801 13:37:33.757776  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.821914s
I0801 13:37:33.773289  3162 solver.cpp:353] Iteration 30000 (41.7404 iter/s, 2.39576s/100 iter), loss = 0.00158852
I0801 13:37:33.773308  3162 solver.cpp:375]     Train net output #0: loss = 0.00158851 (* 1 = 0.00158851 loss)
I0801 13:37:33.773313  3162 sgd_solver.cpp:136] Iteration 30000, lr = 0.0053125, m = 0.9
I0801 13:37:35.341737  3162 solver.cpp:353] Iteration 30100 (63.7594 iter/s, 1.5684s/100 iter), loss = 0.00317809
I0801 13:37:35.341784  3162 solver.cpp:375]     Train net output #0: loss = 0.00317809 (* 1 = 0.00317809 loss)
I0801 13:37:35.341796  3162 sgd_solver.cpp:136] Iteration 30100, lr = 0.00529688, m = 0.9
I0801 13:37:36.889783  3162 solver.cpp:353] Iteration 30200 (64.5996 iter/s, 1.548s/100 iter), loss = 0.00267509
I0801 13:37:36.889808  3162 solver.cpp:375]     Train net output #0: loss = 0.00267509 (* 1 = 0.00267509 loss)
I0801 13:37:36.889812  3162 sgd_solver.cpp:136] Iteration 30200, lr = 0.00528125, m = 0.9
I0801 13:37:38.450132  3162 solver.cpp:353] Iteration 30300 (64.0902 iter/s, 1.5603s/100 iter), loss = 0.0025633
I0801 13:37:38.450158  3162 solver.cpp:375]     Train net output #0: loss = 0.0025633 (* 1 = 0.0025633 loss)
I0801 13:37:38.450163  3162 sgd_solver.cpp:136] Iteration 30300, lr = 0.00526563, m = 0.9
I0801 13:37:40.015164  3162 solver.cpp:353] Iteration 30400 (63.8984 iter/s, 1.56498s/100 iter), loss = 0.00371974
I0801 13:37:40.015187  3162 solver.cpp:375]     Train net output #0: loss = 0.00371974 (* 1 = 0.00371974 loss)
I0801 13:37:40.015192  3162 sgd_solver.cpp:136] Iteration 30400, lr = 0.00525, m = 0.9
I0801 13:37:41.592931  3162 solver.cpp:353] Iteration 30500 (63.3827 iter/s, 1.57772s/100 iter), loss = 0.00086553
I0801 13:37:41.593004  3162 solver.cpp:375]     Train net output #0: loss = 0.000865525 (* 1 = 0.000865525 loss)
I0801 13:37:41.593026  3162 sgd_solver.cpp:136] Iteration 30500, lr = 0.00523437, m = 0.9
I0801 13:37:43.163537  3162 solver.cpp:353] Iteration 30600 (63.6717 iter/s, 1.57056s/100 iter), loss = 0.000598142
I0801 13:37:43.163563  3162 solver.cpp:375]     Train net output #0: loss = 0.000598139 (* 1 = 0.000598139 loss)
I0801 13:37:43.163568  3162 sgd_solver.cpp:136] Iteration 30600, lr = 0.00521875, m = 0.9
I0801 13:37:44.725179  3162 solver.cpp:353] Iteration 30700 (64.0371 iter/s, 1.56159s/100 iter), loss = 0.000652803
I0801 13:37:44.725203  3162 solver.cpp:375]     Train net output #0: loss = 0.000652801 (* 1 = 0.000652801 loss)
I0801 13:37:44.725208  3162 sgd_solver.cpp:136] Iteration 30700, lr = 0.00520312, m = 0.9
I0801 13:37:46.301169  3162 solver.cpp:353] Iteration 30800 (63.4541 iter/s, 1.57594s/100 iter), loss = 0.00104314
I0801 13:37:46.301198  3162 solver.cpp:375]     Train net output #0: loss = 0.00104313 (* 1 = 0.00104313 loss)
I0801 13:37:46.301204  3162 sgd_solver.cpp:136] Iteration 30800, lr = 0.0051875, m = 0.9
I0801 13:37:47.873076  3162 solver.cpp:353] Iteration 30900 (63.619 iter/s, 1.57186s/100 iter), loss = 0.00514514
I0801 13:37:47.873102  3162 solver.cpp:375]     Train net output #0: loss = 0.00514514 (* 1 = 0.00514514 loss)
I0801 13:37:47.873107  3162 sgd_solver.cpp:136] Iteration 30900, lr = 0.00517187, m = 0.9
I0801 13:37:49.441807  3162 solver.cpp:550] Iteration 31000, Testing net (#0)
I0801 13:37:49.725514  3160 data_reader.cpp:264] Starting prefetch of epoch 4
I0801 13:37:50.274772  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.919707
I0801 13:37:50.274801  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.997353
I0801 13:37:50.274811  3162 solver.cpp:635]     Test net output #2: loss = 0.281995 (* 1 = 0.281995 loss)
I0801 13:37:50.274837  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.833005s
I0801 13:37:50.293512  3162 solver.cpp:353] Iteration 31000 (41.3161 iter/s, 2.42036s/100 iter), loss = 0.000757176
I0801 13:37:50.293540  3162 solver.cpp:375]     Train net output #0: loss = 0.000757171 (* 1 = 0.000757171 loss)
I0801 13:37:50.293545  3162 sgd_solver.cpp:136] Iteration 31000, lr = 0.00515625, m = 0.9
I0801 13:37:51.857398  3162 solver.cpp:353] Iteration 31100 (63.9453 iter/s, 1.56384s/100 iter), loss = 0.00374733
I0801 13:37:51.857425  3162 solver.cpp:375]     Train net output #0: loss = 0.00374732 (* 1 = 0.00374732 loss)
I0801 13:37:51.857431  3162 sgd_solver.cpp:136] Iteration 31100, lr = 0.00514062, m = 0.9
I0801 13:37:53.437690  3162 solver.cpp:353] Iteration 31200 (63.2813 iter/s, 1.58025s/100 iter), loss = 0.00181581
I0801 13:37:53.439328  3162 solver.cpp:375]     Train net output #0: loss = 0.00181581 (* 1 = 0.00181581 loss)
I0801 13:37:53.439335  3162 sgd_solver.cpp:136] Iteration 31200, lr = 0.005125, m = 0.9
I0801 13:37:54.997088  3162 solver.cpp:353] Iteration 31300 (64.1294 iter/s, 1.55935s/100 iter), loss = 0.000940504
I0801 13:37:54.997113  3162 solver.cpp:375]     Train net output #0: loss = 0.000940501 (* 1 = 0.000940501 loss)
I0801 13:37:54.997118  3162 sgd_solver.cpp:136] Iteration 31300, lr = 0.00510937, m = 0.9
I0801 13:37:56.565480  3162 solver.cpp:353] Iteration 31400 (63.7615 iter/s, 1.56834s/100 iter), loss = 0.00162418
I0801 13:37:56.565506  3162 solver.cpp:375]     Train net output #0: loss = 0.00162418 (* 1 = 0.00162418 loss)
I0801 13:37:56.565512  3162 sgd_solver.cpp:136] Iteration 31400, lr = 0.00509375, m = 0.9
I0801 13:37:58.132678  3162 solver.cpp:353] Iteration 31500 (63.8101 iter/s, 1.56715s/100 iter), loss = 0.00418708
I0801 13:37:58.132702  3162 solver.cpp:375]     Train net output #0: loss = 0.00418708 (* 1 = 0.00418708 loss)
I0801 13:37:58.132706  3162 sgd_solver.cpp:136] Iteration 31500, lr = 0.00507812, m = 0.9
I0801 13:37:59.818749  3162 solver.cpp:353] Iteration 31600 (59.3115 iter/s, 1.68602s/100 iter), loss = 0.0021307
I0801 13:37:59.818842  3162 solver.cpp:375]     Train net output #0: loss = 0.0021307 (* 1 = 0.0021307 loss)
I0801 13:37:59.818873  3162 sgd_solver.cpp:136] Iteration 31600, lr = 0.0050625, m = 0.9
I0801 13:38:01.444239  3162 solver.cpp:353] Iteration 31700 (61.5218 iter/s, 1.62544s/100 iter), loss = 0.000879557
I0801 13:38:01.444264  3162 solver.cpp:375]     Train net output #0: loss = 0.000879556 (* 1 = 0.000879556 loss)
I0801 13:38:01.444268  3162 sgd_solver.cpp:136] Iteration 31700, lr = 0.00504687, m = 0.9
I0801 13:38:03.141391  3162 solver.cpp:353] Iteration 31800 (58.9242 iter/s, 1.69709s/100 iter), loss = 0.000958173
I0801 13:38:03.141430  3162 solver.cpp:375]     Train net output #0: loss = 0.000958172 (* 1 = 0.000958172 loss)
I0801 13:38:03.141439  3162 sgd_solver.cpp:136] Iteration 31800, lr = 0.00503125, m = 0.9
I0801 13:38:04.903939  3162 solver.cpp:353] Iteration 31900 (56.7376 iter/s, 1.7625s/100 iter), loss = 0.00144018
I0801 13:38:04.903987  3162 solver.cpp:375]     Train net output #0: loss = 0.00144018 (* 1 = 0.00144018 loss)
I0801 13:38:04.904001  3162 sgd_solver.cpp:136] Iteration 31900, lr = 0.00501562, m = 0.9
I0801 13:38:06.519161  3162 solver.cpp:550] Iteration 32000, Testing net (#0)
I0801 13:38:07.364393  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.911177
I0801 13:38:07.364420  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996765
I0801 13:38:07.364434  3162 solver.cpp:635]     Test net output #2: loss = 0.33074 (* 1 = 0.33074 loss)
I0801 13:38:07.364477  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.845284s
I0801 13:38:07.385143  3162 solver.cpp:353] Iteration 32000 (40.3045 iter/s, 2.48111s/100 iter), loss = 0.00119466
I0801 13:38:07.385205  3162 solver.cpp:375]     Train net output #0: loss = 0.00119466 (* 1 = 0.00119466 loss)
I0801 13:38:07.385221  3162 sgd_solver.cpp:136] Iteration 32000, lr = 0.005, m = 0.9
I0801 13:38:09.033972  3162 solver.cpp:353] Iteration 32100 (60.6506 iter/s, 1.64879s/100 iter), loss = 0.00118984
I0801 13:38:09.033999  3162 solver.cpp:375]     Train net output #0: loss = 0.00118984 (* 1 = 0.00118984 loss)
I0801 13:38:09.034006  3162 sgd_solver.cpp:136] Iteration 32100, lr = 0.00498438, m = 0.9
I0801 13:38:10.734344  3162 solver.cpp:353] Iteration 32200 (58.8125 iter/s, 1.70032s/100 iter), loss = 0.00241458
I0801 13:38:10.734371  3162 solver.cpp:375]     Train net output #0: loss = 0.00241458 (* 1 = 0.00241458 loss)
I0801 13:38:10.734378  3162 sgd_solver.cpp:136] Iteration 32200, lr = 0.00496875, m = 0.9
I0801 13:38:12.400414  3162 solver.cpp:353] Iteration 32300 (60.0235 iter/s, 1.66601s/100 iter), loss = 0.00212096
I0801 13:38:12.400449  3162 solver.cpp:375]     Train net output #0: loss = 0.00212096 (* 1 = 0.00212096 loss)
I0801 13:38:12.400454  3162 sgd_solver.cpp:136] Iteration 32300, lr = 0.00495313, m = 0.9
I0801 13:38:14.191614  3162 solver.cpp:353] Iteration 32400 (55.8301 iter/s, 1.79115s/100 iter), loss = 0.00080271
I0801 13:38:14.191638  3162 solver.cpp:375]     Train net output #0: loss = 0.000802709 (* 1 = 0.000802709 loss)
I0801 13:38:14.191643  3162 sgd_solver.cpp:136] Iteration 32400, lr = 0.0049375, m = 0.9
I0801 13:38:15.857960  3162 solver.cpp:353] Iteration 32500 (60.0135 iter/s, 1.66629s/100 iter), loss = 0.0012079
I0801 13:38:15.857986  3162 solver.cpp:375]     Train net output #0: loss = 0.0012079 (* 1 = 0.0012079 loss)
I0801 13:38:15.857991  3162 sgd_solver.cpp:136] Iteration 32500, lr = 0.00492187, m = 0.9
I0801 13:38:17.566371  3162 solver.cpp:353] Iteration 32600 (58.5359 iter/s, 1.70835s/100 iter), loss = 0.00196988
I0801 13:38:17.566493  3162 solver.cpp:375]     Train net output #0: loss = 0.00196988 (* 1 = 0.00196988 loss)
I0801 13:38:17.566511  3162 sgd_solver.cpp:136] Iteration 32600, lr = 0.00490625, m = 0.9
I0801 13:38:19.345716  3162 solver.cpp:353] Iteration 32700 (56.2024 iter/s, 1.77928s/100 iter), loss = 0.000622774
I0801 13:38:19.346271  3162 solver.cpp:375]     Train net output #0: loss = 0.000622775 (* 1 = 0.000622775 loss)
I0801 13:38:19.346303  3162 sgd_solver.cpp:136] Iteration 32700, lr = 0.00489062, m = 0.9
I0801 13:38:21.141953  3162 solver.cpp:353] Iteration 32800 (55.6734 iter/s, 1.79619s/100 iter), loss = 0.00353842
I0801 13:38:21.141976  3162 solver.cpp:375]     Train net output #0: loss = 0.00353842 (* 1 = 0.00353842 loss)
I0801 13:38:21.141983  3162 sgd_solver.cpp:136] Iteration 32800, lr = 0.004875, m = 0.9
I0801 13:38:22.745998  3162 solver.cpp:353] Iteration 32900 (62.3444 iter/s, 1.60399s/100 iter), loss = 0.00171669
I0801 13:38:22.746023  3162 solver.cpp:375]     Train net output #0: loss = 0.0017167 (* 1 = 0.0017167 loss)
I0801 13:38:22.746029  3162 sgd_solver.cpp:136] Iteration 32900, lr = 0.00485937, m = 0.9
I0801 13:38:24.321533  3162 solver.cpp:550] Iteration 33000, Testing net (#0)
I0801 13:38:25.239856  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.909707
I0801 13:38:25.239876  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.997059
I0801 13:38:25.239881  3162 solver.cpp:635]     Test net output #2: loss = 0.335162 (* 1 = 0.335162 loss)
I0801 13:38:25.239898  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.918342s
I0801 13:38:25.255494  3162 solver.cpp:353] Iteration 33000 (39.8498 iter/s, 2.50942s/100 iter), loss = 0.00329251
I0801 13:38:25.255511  3162 solver.cpp:375]     Train net output #0: loss = 0.00329251 (* 1 = 0.00329251 loss)
I0801 13:38:25.255515  3162 sgd_solver.cpp:136] Iteration 33000, lr = 0.00484375, m = 0.9
I0801 13:38:27.018158  3162 solver.cpp:353] Iteration 33100 (56.7344 iter/s, 1.7626s/100 iter), loss = 0.00697683
I0801 13:38:27.018203  3162 solver.cpp:375]     Train net output #0: loss = 0.00697683 (* 1 = 0.00697683 loss)
I0801 13:38:27.018208  3162 sgd_solver.cpp:136] Iteration 33100, lr = 0.00482813, m = 0.9
I0801 13:38:28.784464  3162 solver.cpp:353] Iteration 33200 (56.6168 iter/s, 1.76626s/100 iter), loss = 0.00028278
I0801 13:38:28.784489  3162 solver.cpp:375]     Train net output #0: loss = 0.000282784 (* 1 = 0.000282784 loss)
I0801 13:38:28.784495  3162 sgd_solver.cpp:136] Iteration 33200, lr = 0.0048125, m = 0.9
I0801 13:38:30.504385  3162 solver.cpp:353] Iteration 33300 (58.144 iter/s, 1.71987s/100 iter), loss = 0.00162913
I0801 13:38:30.504412  3162 solver.cpp:375]     Train net output #0: loss = 0.00162914 (* 1 = 0.00162914 loss)
I0801 13:38:30.504420  3162 sgd_solver.cpp:136] Iteration 33300, lr = 0.00479688, m = 0.9
I0801 13:38:32.194854  3162 solver.cpp:353] Iteration 33400 (59.1576 iter/s, 1.6904s/100 iter), loss = 0.00335986
I0801 13:38:32.194934  3162 solver.cpp:375]     Train net output #0: loss = 0.00335987 (* 1 = 0.00335987 loss)
I0801 13:38:32.194959  3162 sgd_solver.cpp:136] Iteration 33400, lr = 0.00478125, m = 0.9
I0801 13:38:33.853703  3162 solver.cpp:353] Iteration 33500 (60.2846 iter/s, 1.6588s/100 iter), loss = 0.00169337
I0801 13:38:33.853746  3162 solver.cpp:375]     Train net output #0: loss = 0.00169338 (* 1 = 0.00169338 loss)
I0801 13:38:33.853757  3162 sgd_solver.cpp:136] Iteration 33500, lr = 0.00476563, m = 0.9
I0801 13:38:35.552662  3162 solver.cpp:353] Iteration 33600 (58.8612 iter/s, 1.69891s/100 iter), loss = 0.00060496
I0801 13:38:35.552692  3162 solver.cpp:375]     Train net output #0: loss = 0.000604963 (* 1 = 0.000604963 loss)
I0801 13:38:35.552700  3162 sgd_solver.cpp:136] Iteration 33600, lr = 0.00475, m = 0.9
I0801 13:38:37.186064  3162 solver.cpp:353] Iteration 33700 (61.2239 iter/s, 1.63335s/100 iter), loss = 0.00171959
I0801 13:38:37.186089  3162 solver.cpp:375]     Train net output #0: loss = 0.00171959 (* 1 = 0.00171959 loss)
I0801 13:38:37.186095  3162 sgd_solver.cpp:136] Iteration 33700, lr = 0.00473437, m = 0.9
I0801 13:38:38.921067  3162 solver.cpp:353] Iteration 33800 (57.6384 iter/s, 1.73495s/100 iter), loss = 0.00118606
I0801 13:38:38.921092  3162 solver.cpp:375]     Train net output #0: loss = 0.00118607 (* 1 = 0.00118607 loss)
I0801 13:38:38.921097  3162 sgd_solver.cpp:136] Iteration 33800, lr = 0.00471875, m = 0.9
I0801 13:38:40.677613  3162 solver.cpp:353] Iteration 33900 (56.9321 iter/s, 1.75648s/100 iter), loss = 0.00296368
I0801 13:38:40.677655  3162 solver.cpp:375]     Train net output #0: loss = 0.00296368 (* 1 = 0.00296368 loss)
I0801 13:38:40.677664  3162 sgd_solver.cpp:136] Iteration 33900, lr = 0.00470312, m = 0.9
I0801 13:38:42.374754  3162 solver.cpp:550] Iteration 34000, Testing net (#0)
I0801 13:38:43.356022  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.90853
I0801 13:38:43.356041  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996765
I0801 13:38:43.356048  3162 solver.cpp:635]     Test net output #2: loss = 0.352253 (* 1 = 0.352253 loss)
I0801 13:38:43.356065  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.981288s
I0801 13:38:43.371742  3162 solver.cpp:353] Iteration 34000 (37.1187 iter/s, 2.69406s/100 iter), loss = 0.00195717
I0801 13:38:43.371775  3162 solver.cpp:375]     Train net output #0: loss = 0.00195717 (* 1 = 0.00195717 loss)
I0801 13:38:43.371781  3162 sgd_solver.cpp:136] Iteration 34000, lr = 0.0046875, m = 0.9
I0801 13:38:44.988729  3162 solver.cpp:353] Iteration 34100 (61.8456 iter/s, 1.61693s/100 iter), loss = 0.0014722
I0801 13:38:44.988788  3162 solver.cpp:375]     Train net output #0: loss = 0.0014722 (* 1 = 0.0014722 loss)
I0801 13:38:44.988803  3162 sgd_solver.cpp:136] Iteration 34100, lr = 0.00467187, m = 0.9
I0801 13:38:46.630722  3162 solver.cpp:353] Iteration 34200 (60.9034 iter/s, 1.64195s/100 iter), loss = 0.0028856
I0801 13:38:46.630779  3162 solver.cpp:375]     Train net output #0: loss = 0.0028856 (* 1 = 0.0028856 loss)
I0801 13:38:46.630791  3162 sgd_solver.cpp:136] Iteration 34200, lr = 0.00465625, m = 0.9
I0801 13:38:48.239861  3162 solver.cpp:353] Iteration 34300 (62.1469 iter/s, 1.60909s/100 iter), loss = 0.000534971
I0801 13:38:48.239887  3162 solver.cpp:375]     Train net output #0: loss = 0.000534972 (* 1 = 0.000534972 loss)
I0801 13:38:48.239893  3162 sgd_solver.cpp:136] Iteration 34300, lr = 0.00464062, m = 0.9
I0801 13:38:49.983104  3162 solver.cpp:353] Iteration 34400 (57.3661 iter/s, 1.74319s/100 iter), loss = 0.00246556
I0801 13:38:49.983129  3162 solver.cpp:375]     Train net output #0: loss = 0.00246556 (* 1 = 0.00246556 loss)
I0801 13:38:49.983134  3162 sgd_solver.cpp:136] Iteration 34400, lr = 0.004625, m = 0.9
I0801 13:38:51.673835  3162 solver.cpp:353] Iteration 34500 (59.1484 iter/s, 1.69066s/100 iter), loss = 0.0005024
I0801 13:38:51.673933  3162 solver.cpp:375]     Train net output #0: loss = 0.000502401 (* 1 = 0.000502401 loss)
I0801 13:38:51.673964  3162 sgd_solver.cpp:136] Iteration 34500, lr = 0.00460937, m = 0.9
I0801 13:38:53.336881  3162 solver.cpp:353] Iteration 34600 (60.1322 iter/s, 1.663s/100 iter), loss = 0.00292516
I0801 13:38:53.336910  3162 solver.cpp:375]     Train net output #0: loss = 0.00292516 (* 1 = 0.00292516 loss)
I0801 13:38:53.336916  3162 sgd_solver.cpp:136] Iteration 34600, lr = 0.00459375, m = 0.9
I0801 13:38:54.968257  3162 solver.cpp:353] Iteration 34700 (61.2998 iter/s, 1.63133s/100 iter), loss = 0.00204724
I0801 13:38:54.968333  3162 solver.cpp:375]     Train net output #0: loss = 0.00204725 (* 1 = 0.00204725 loss)
I0801 13:38:54.968340  3162 sgd_solver.cpp:136] Iteration 34700, lr = 0.00457812, m = 0.9
I0801 13:38:56.549706  3162 solver.cpp:353] Iteration 34800 (63.2352 iter/s, 1.5814s/100 iter), loss = 0.00777014
I0801 13:38:56.549731  3162 solver.cpp:375]     Train net output #0: loss = 0.00777014 (* 1 = 0.00777014 loss)
I0801 13:38:56.549738  3162 sgd_solver.cpp:136] Iteration 34800, lr = 0.0045625, m = 0.9
I0801 13:38:58.116303  3162 solver.cpp:353] Iteration 34900 (63.8346 iter/s, 1.56655s/100 iter), loss = 0.00119366
I0801 13:38:58.116331  3162 solver.cpp:375]     Train net output #0: loss = 0.00119366 (* 1 = 0.00119366 loss)
I0801 13:38:58.116338  3162 sgd_solver.cpp:136] Iteration 34900, lr = 0.00454687, m = 0.9
I0801 13:38:59.665186  3162 solver.cpp:550] Iteration 35000, Testing net (#0)
I0801 13:38:59.887994  3160 data_reader.cpp:264] Starting prefetch of epoch 5
I0801 13:39:00.517067  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.891766
I0801 13:39:00.517103  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996765
I0801 13:39:00.517115  3162 solver.cpp:635]     Test net output #2: loss = 0.42495 (* 1 = 0.42495 loss)
I0801 13:39:00.517148  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.851933s
I0801 13:39:00.534488  3162 solver.cpp:353] Iteration 35000 (41.3546 iter/s, 2.41811s/100 iter), loss = 0.00495565
I0801 13:39:00.534519  3162 solver.cpp:375]     Train net output #0: loss = 0.00495565 (* 1 = 0.00495565 loss)
I0801 13:39:00.534526  3162 sgd_solver.cpp:136] Iteration 35000, lr = 0.00453125, m = 0.9
I0801 13:39:02.169075  3162 solver.cpp:353] Iteration 35100 (61.1794 iter/s, 1.63454s/100 iter), loss = 0.00404985
I0801 13:39:02.169122  3162 solver.cpp:375]     Train net output #0: loss = 0.00404985 (* 1 = 0.00404985 loss)
I0801 13:39:02.169134  3162 sgd_solver.cpp:136] Iteration 35100, lr = 0.00451563, m = 0.9
I0801 13:39:03.921278  3162 solver.cpp:353] Iteration 35200 (57.0728 iter/s, 1.75215s/100 iter), loss = 0.00162285
I0801 13:39:03.921304  3162 solver.cpp:375]     Train net output #0: loss = 0.00162284 (* 1 = 0.00162284 loss)
I0801 13:39:03.921308  3162 sgd_solver.cpp:136] Iteration 35200, lr = 0.0045, m = 0.9
I0801 13:39:05.500864  3162 solver.cpp:353] Iteration 35300 (63.3098 iter/s, 1.57954s/100 iter), loss = 0.0006806
I0801 13:39:05.500916  3162 solver.cpp:375]     Train net output #0: loss = 0.000680599 (* 1 = 0.000680599 loss)
I0801 13:39:05.500933  3162 sgd_solver.cpp:136] Iteration 35300, lr = 0.00448438, m = 0.9
I0801 13:39:07.074770  3162 solver.cpp:353] Iteration 35400 (63.5382 iter/s, 1.57386s/100 iter), loss = 0.000681427
I0801 13:39:07.074825  3162 solver.cpp:375]     Train net output #0: loss = 0.000681427 (* 1 = 0.000681427 loss)
I0801 13:39:07.074839  3162 sgd_solver.cpp:136] Iteration 35400, lr = 0.00446875, m = 0.9
I0801 13:39:08.652256  3162 solver.cpp:353] Iteration 35500 (63.3941 iter/s, 1.57743s/100 iter), loss = 0.00218876
I0801 13:39:08.652307  3162 solver.cpp:375]     Train net output #0: loss = 0.00218876 (* 1 = 0.00218876 loss)
I0801 13:39:08.652323  3162 sgd_solver.cpp:136] Iteration 35500, lr = 0.00445312, m = 0.9
I0801 13:39:10.255499  3162 solver.cpp:353] Iteration 35600 (62.3754 iter/s, 1.6032s/100 iter), loss = 0.00210413
I0801 13:39:10.255524  3162 solver.cpp:375]     Train net output #0: loss = 0.00210414 (* 1 = 0.00210414 loss)
I0801 13:39:10.255529  3162 sgd_solver.cpp:136] Iteration 35600, lr = 0.0044375, m = 0.9
I0801 13:39:12.117563  3162 solver.cpp:353] Iteration 35700 (53.7056 iter/s, 1.862s/100 iter), loss = 0.155426
I0801 13:39:12.117585  3162 solver.cpp:375]     Train net output #0: loss = 0.155426 (* 1 = 0.155426 loss)
I0801 13:39:12.117589  3162 sgd_solver.cpp:136] Iteration 35700, lr = 0.00442187, m = 0.9
I0801 13:39:13.741785  3162 solver.cpp:353] Iteration 35800 (61.5699 iter/s, 1.62417s/100 iter), loss = 0.0520642
I0801 13:39:13.741811  3162 solver.cpp:375]     Train net output #0: loss = 0.0520643 (* 1 = 0.0520643 loss)
I0801 13:39:13.741840  3162 sgd_solver.cpp:136] Iteration 35800, lr = 0.00440625, m = 0.9
I0801 13:39:15.428097  3162 solver.cpp:353] Iteration 35900 (59.3028 iter/s, 1.68626s/100 iter), loss = 0.0238419
I0801 13:39:15.428153  3162 solver.cpp:375]     Train net output #0: loss = 0.0238421 (* 1 = 0.0238421 loss)
I0801 13:39:15.428167  3162 sgd_solver.cpp:136] Iteration 35900, lr = 0.00439062, m = 0.9
I0801 13:39:17.137547  3162 solver.cpp:550] Iteration 36000, Testing net (#0)
I0801 13:39:17.970355  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.805001
I0801 13:39:17.970373  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.99
I0801 13:39:17.970381  3162 solver.cpp:635]     Test net output #2: loss = 0.750817 (* 1 = 0.750817 loss)
I0801 13:39:17.970398  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.832828s
I0801 13:39:17.986057  3162 solver.cpp:353] Iteration 36000 (39.0948 iter/s, 2.55789s/100 iter), loss = 0.0666959
I0801 13:39:17.986075  3162 solver.cpp:375]     Train net output #0: loss = 0.0666962 (* 1 = 0.0666962 loss)
I0801 13:39:17.986081  3162 sgd_solver.cpp:136] Iteration 36000, lr = 0.004375, m = 0.9
I0801 13:39:19.671316  3162 solver.cpp:353] Iteration 36100 (59.3399 iter/s, 1.68521s/100 iter), loss = 0.192064
I0801 13:39:19.671346  3162 solver.cpp:375]     Train net output #0: loss = 0.192064 (* 1 = 0.192064 loss)
I0801 13:39:19.671352  3162 sgd_solver.cpp:136] Iteration 36100, lr = 0.00435938, m = 0.9
I0801 13:39:21.346091  3162 solver.cpp:353] Iteration 36200 (59.7115 iter/s, 1.67472s/100 iter), loss = 0.0527203
I0801 13:39:21.346117  3162 solver.cpp:375]     Train net output #0: loss = 0.0527204 (* 1 = 0.0527204 loss)
I0801 13:39:21.346122  3162 sgd_solver.cpp:136] Iteration 36200, lr = 0.00434375, m = 0.9
I0801 13:39:22.985620  3162 solver.cpp:353] Iteration 36300 (60.9951 iter/s, 1.63948s/100 iter), loss = 0.0219281
I0801 13:39:22.985642  3162 solver.cpp:375]     Train net output #0: loss = 0.0219282 (* 1 = 0.0219282 loss)
I0801 13:39:22.985648  3162 sgd_solver.cpp:136] Iteration 36300, lr = 0.00432813, m = 0.9
I0801 13:39:24.644286  3162 solver.cpp:353] Iteration 36400 (60.2912 iter/s, 1.65862s/100 iter), loss = 0.120613
I0801 13:39:24.644314  3162 solver.cpp:375]     Train net output #0: loss = 0.120613 (* 1 = 0.120613 loss)
I0801 13:39:24.644320  3162 sgd_solver.cpp:136] Iteration 36400, lr = 0.0043125, m = 0.9
I0801 13:39:26.287356  3162 solver.cpp:353] Iteration 36500 (60.8637 iter/s, 1.64302s/100 iter), loss = 0.0653825
I0801 13:39:26.287519  3162 solver.cpp:375]     Train net output #0: loss = 0.0653826 (* 1 = 0.0653826 loss)
I0801 13:39:26.287546  3162 sgd_solver.cpp:136] Iteration 36500, lr = 0.00429688, m = 0.9
I0801 13:39:27.966568  3162 solver.cpp:353] Iteration 36600 (59.5537 iter/s, 1.67916s/100 iter), loss = 0.127271
I0801 13:39:27.966621  3162 solver.cpp:375]     Train net output #0: loss = 0.127271 (* 1 = 0.127271 loss)
I0801 13:39:27.966632  3162 sgd_solver.cpp:136] Iteration 36600, lr = 0.00428125, m = 0.9
I0801 13:39:29.666169  3162 solver.cpp:353] Iteration 36700 (58.8391 iter/s, 1.69955s/100 iter), loss = 0.0563792
I0801 13:39:29.666246  3162 solver.cpp:375]     Train net output #0: loss = 0.0563792 (* 1 = 0.0563792 loss)
I0801 13:39:29.666268  3162 sgd_solver.cpp:136] Iteration 36700, lr = 0.00426562, m = 0.9
I0801 13:39:31.291872  3162 solver.cpp:353] Iteration 36800 (61.5138 iter/s, 1.62565s/100 iter), loss = 0.0200769
I0801 13:39:31.291898  3162 solver.cpp:375]     Train net output #0: loss = 0.0200769 (* 1 = 0.0200769 loss)
I0801 13:39:31.291903  3162 sgd_solver.cpp:136] Iteration 36800, lr = 0.00425, m = 0.9
I0801 13:39:33.036584  3162 solver.cpp:353] Iteration 36900 (57.3179 iter/s, 1.74466s/100 iter), loss = 0.0518104
I0801 13:39:33.036682  3162 solver.cpp:375]     Train net output #0: loss = 0.0518104 (* 1 = 0.0518104 loss)
I0801 13:39:33.036691  3162 sgd_solver.cpp:136] Iteration 36900, lr = 0.00423437, m = 0.9
I0801 13:39:34.864212  3162 solver.cpp:550] Iteration 37000, Testing net (#0)
I0801 13:39:35.732789  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.850589
I0801 13:39:35.732805  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.993824
I0801 13:39:35.732813  3162 solver.cpp:635]     Test net output #2: loss = 0.544351 (* 1 = 0.544351 loss)
I0801 13:39:35.732847  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.868611s
I0801 13:39:35.757055  3162 solver.cpp:353] Iteration 37000 (36.7594 iter/s, 2.72039s/100 iter), loss = 0.0954478
I0801 13:39:35.757081  3162 solver.cpp:375]     Train net output #0: loss = 0.0954479 (* 1 = 0.0954479 loss)
I0801 13:39:35.757086  3162 sgd_solver.cpp:136] Iteration 37000, lr = 0.00421875, m = 0.9
I0801 13:39:37.386126  3162 solver.cpp:353] Iteration 37100 (61.3867 iter/s, 1.62902s/100 iter), loss = 0.0535867
I0801 13:39:37.386160  3162 solver.cpp:375]     Train net output #0: loss = 0.0535867 (* 1 = 0.0535867 loss)
I0801 13:39:37.386165  3162 sgd_solver.cpp:136] Iteration 37100, lr = 0.00420313, m = 0.9
I0801 13:39:39.183184  3162 solver.cpp:353] Iteration 37200 (55.6482 iter/s, 1.797s/100 iter), loss = 0.0263588
I0801 13:39:39.183212  3162 solver.cpp:375]     Train net output #0: loss = 0.0263588 (* 1 = 0.0263588 loss)
I0801 13:39:39.183218  3162 sgd_solver.cpp:136] Iteration 37200, lr = 0.0041875, m = 0.9
I0801 13:39:40.967257  3162 solver.cpp:353] Iteration 37300 (56.0533 iter/s, 1.78402s/100 iter), loss = 0.0551731
I0801 13:39:40.967283  3162 solver.cpp:375]     Train net output #0: loss = 0.0551731 (* 1 = 0.0551731 loss)
I0801 13:39:40.967288  3162 sgd_solver.cpp:136] Iteration 37300, lr = 0.00417187, m = 0.9
I0801 13:39:42.678665  3162 solver.cpp:353] Iteration 37400 (58.4335 iter/s, 1.71135s/100 iter), loss = 0.0327556
I0801 13:39:42.678712  3162 solver.cpp:375]     Train net output #0: loss = 0.0327556 (* 1 = 0.0327556 loss)
I0801 13:39:42.678725  3162 sgd_solver.cpp:136] Iteration 37400, lr = 0.00415625, m = 0.9
I0801 13:39:44.325409  3162 solver.cpp:353] Iteration 37500 (60.7276 iter/s, 1.6467s/100 iter), loss = 0.0441725
I0801 13:39:44.325439  3162 solver.cpp:375]     Train net output #0: loss = 0.0441726 (* 1 = 0.0441726 loss)
I0801 13:39:44.325445  3162 sgd_solver.cpp:136] Iteration 37500, lr = 0.00414062, m = 0.9
I0801 13:39:46.025084  3162 solver.cpp:353] Iteration 37600 (58.8367 iter/s, 1.69962s/100 iter), loss = 0.0324173
I0801 13:39:46.025110  3162 solver.cpp:375]     Train net output #0: loss = 0.0324173 (* 1 = 0.0324173 loss)
I0801 13:39:46.025113  3162 sgd_solver.cpp:136] Iteration 37600, lr = 0.004125, m = 0.9
I0801 13:39:47.749119  3162 solver.cpp:353] Iteration 37700 (58.0054 iter/s, 1.72398s/100 iter), loss = 0.00871978
I0801 13:39:47.749198  3162 solver.cpp:375]     Train net output #0: loss = 0.00871981 (* 1 = 0.00871981 loss)
I0801 13:39:47.749224  3162 sgd_solver.cpp:136] Iteration 37700, lr = 0.00410937, m = 0.9
I0801 13:39:49.355520  3162 solver.cpp:353] Iteration 37800 (62.2528 iter/s, 1.60635s/100 iter), loss = 0.0311927
I0801 13:39:49.355550  3162 solver.cpp:375]     Train net output #0: loss = 0.0311927 (* 1 = 0.0311927 loss)
I0801 13:39:49.355556  3162 sgd_solver.cpp:136] Iteration 37800, lr = 0.00409375, m = 0.9
I0801 13:39:51.077220  3162 solver.cpp:353] Iteration 37900 (58.0842 iter/s, 1.72164s/100 iter), loss = 0.0205516
I0801 13:39:51.077308  3162 solver.cpp:375]     Train net output #0: loss = 0.0205516 (* 1 = 0.0205516 loss)
I0801 13:39:51.077334  3162 sgd_solver.cpp:136] Iteration 37900, lr = 0.00407812, m = 0.9
I0801 13:39:52.865202  3162 solver.cpp:550] Iteration 38000, Testing net (#0)
I0801 13:39:53.744098  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.874707
I0801 13:39:53.744141  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.992941
I0801 13:39:53.744153  3162 solver.cpp:635]     Test net output #2: loss = 0.506074 (* 1 = 0.506074 loss)
I0801 13:39:53.744189  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.878962s
I0801 13:39:53.765185  3162 solver.cpp:353] Iteration 38000 (37.204 iter/s, 2.68788s/100 iter), loss = 0.00288516
I0801 13:39:53.765239  3162 solver.cpp:375]     Train net output #0: loss = 0.00288526 (* 1 = 0.00288526 loss)
I0801 13:39:53.765260  3162 sgd_solver.cpp:136] Iteration 38000, lr = 0.0040625, m = 0.9
I0801 13:39:55.367113  3162 solver.cpp:353] Iteration 38100 (62.4267 iter/s, 1.60188s/100 iter), loss = 0.00676392
I0801 13:39:55.367136  3162 solver.cpp:375]     Train net output #0: loss = 0.00676404 (* 1 = 0.00676404 loss)
I0801 13:39:55.367142  3162 sgd_solver.cpp:136] Iteration 38100, lr = 0.00404688, m = 0.9
I0801 13:39:57.024411  3162 solver.cpp:353] Iteration 38200 (60.3411 iter/s, 1.65725s/100 iter), loss = 0.0156398
I0801 13:39:57.024556  3162 solver.cpp:375]     Train net output #0: loss = 0.0156399 (* 1 = 0.0156399 loss)
I0801 13:39:57.024581  3162 sgd_solver.cpp:136] Iteration 38200, lr = 0.00403125, m = 0.9
I0801 13:39:58.822015  3162 solver.cpp:353] Iteration 38300 (55.6315 iter/s, 1.79754s/100 iter), loss = 0.0275954
I0801 13:39:58.822060  3162 solver.cpp:375]     Train net output #0: loss = 0.0275955 (* 1 = 0.0275955 loss)
I0801 13:39:58.822082  3162 sgd_solver.cpp:136] Iteration 38300, lr = 0.00401562, m = 0.9
I0801 13:40:00.478654  3162 solver.cpp:353] Iteration 38400 (60.3651 iter/s, 1.65659s/100 iter), loss = 0.00720645
I0801 13:40:00.478768  3162 solver.cpp:375]     Train net output #0: loss = 0.00720658 (* 1 = 0.00720658 loss)
I0801 13:40:00.478782  3162 sgd_solver.cpp:136] Iteration 38400, lr = 0.004, m = 0.9
I0801 13:40:02.128168  3162 solver.cpp:353] Iteration 38500 (60.6256 iter/s, 1.64947s/100 iter), loss = 0.0737231
I0801 13:40:02.128195  3162 solver.cpp:375]     Train net output #0: loss = 0.0737232 (* 1 = 0.0737232 loss)
I0801 13:40:02.128199  3162 sgd_solver.cpp:136] Iteration 38500, lr = 0.00398437, m = 0.9
I0801 13:40:03.808524  3162 solver.cpp:353] Iteration 38600 (59.5132 iter/s, 1.6803s/100 iter), loss = 0.0198419
I0801 13:40:03.808583  3162 solver.cpp:375]     Train net output #0: loss = 0.019842 (* 1 = 0.019842 loss)
I0801 13:40:03.808598  3162 sgd_solver.cpp:136] Iteration 38600, lr = 0.00396875, m = 0.9
I0801 13:40:05.442548  3162 solver.cpp:353] Iteration 38700 (61.2005 iter/s, 1.63397s/100 iter), loss = 0.0172191
I0801 13:40:05.442576  3162 solver.cpp:375]     Train net output #0: loss = 0.0172192 (* 1 = 0.0172192 loss)
I0801 13:40:05.442584  3162 sgd_solver.cpp:136] Iteration 38700, lr = 0.00395312, m = 0.9
I0801 13:40:07.018795  3162 solver.cpp:353] Iteration 38800 (63.4439 iter/s, 1.5762s/100 iter), loss = 0.00217083
I0801 13:40:07.018818  3162 solver.cpp:375]     Train net output #0: loss = 0.00217088 (* 1 = 0.00217088 loss)
I0801 13:40:07.018823  3162 sgd_solver.cpp:136] Iteration 38800, lr = 0.0039375, m = 0.9
I0801 13:40:08.587514  3162 solver.cpp:353] Iteration 38900 (63.7482 iter/s, 1.56867s/100 iter), loss = 0.0169003
I0801 13:40:08.587570  3162 solver.cpp:375]     Train net output #0: loss = 0.0169004 (* 1 = 0.0169004 loss)
I0801 13:40:08.587584  3162 sgd_solver.cpp:136] Iteration 38900, lr = 0.00392187, m = 0.9
I0801 13:40:10.156637  3162 solver.cpp:550] Iteration 39000, Testing net (#0)
I0801 13:40:10.992246  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.885589
I0801 13:40:10.992264  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.993235
I0801 13:40:10.992269  3162 solver.cpp:635]     Test net output #2: loss = 0.436306 (* 1 = 0.436306 loss)
I0801 13:40:10.992285  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.835625s
I0801 13:40:11.008044  3162 solver.cpp:353] Iteration 39000 (41.3145 iter/s, 2.42046s/100 iter), loss = 0.059026
I0801 13:40:11.008061  3162 solver.cpp:375]     Train net output #0: loss = 0.059026 (* 1 = 0.059026 loss)
I0801 13:40:11.008065  3162 sgd_solver.cpp:136] Iteration 39000, lr = 0.00390625, m = 0.9
I0801 13:40:12.713440  3162 solver.cpp:353] Iteration 39100 (58.6393 iter/s, 1.70534s/100 iter), loss = 0.0205703
I0801 13:40:12.713526  3162 solver.cpp:375]     Train net output #0: loss = 0.0205704 (* 1 = 0.0205704 loss)
I0801 13:40:12.713546  3162 sgd_solver.cpp:136] Iteration 39100, lr = 0.00389063, m = 0.9
I0801 13:40:14.425623  3162 solver.cpp:353] Iteration 39200 (58.4068 iter/s, 1.71213s/100 iter), loss = 0.00251298
I0801 13:40:14.425675  3162 solver.cpp:375]     Train net output #0: loss = 0.00251305 (* 1 = 0.00251305 loss)
I0801 13:40:14.425690  3162 sgd_solver.cpp:136] Iteration 39200, lr = 0.003875, m = 0.9
I0801 13:40:15.994472  3162 solver.cpp:353] Iteration 39300 (63.7431 iter/s, 1.5688s/100 iter), loss = 0.012378
I0801 13:40:15.994498  3162 solver.cpp:375]     Train net output #0: loss = 0.0123781 (* 1 = 0.0123781 loss)
I0801 13:40:15.994503  3162 sgd_solver.cpp:136] Iteration 39300, lr = 0.00385938, m = 0.9
I0801 13:40:17.402776  3155 data_reader.cpp:264] Starting prefetch of epoch 5
I0801 13:40:17.562026  3162 solver.cpp:353] Iteration 39400 (63.7956 iter/s, 1.56751s/100 iter), loss = 0.00425621
I0801 13:40:17.562049  3162 solver.cpp:375]     Train net output #0: loss = 0.00425631 (* 1 = 0.00425631 loss)
I0801 13:40:17.562053  3162 sgd_solver.cpp:136] Iteration 39400, lr = 0.00384375, m = 0.9
I0801 13:40:19.131225  3162 solver.cpp:353] Iteration 39500 (63.7288 iter/s, 1.56915s/100 iter), loss = 0.0399989
I0801 13:40:19.131249  3162 solver.cpp:375]     Train net output #0: loss = 0.039999 (* 1 = 0.039999 loss)
I0801 13:40:19.131254  3162 sgd_solver.cpp:136] Iteration 39500, lr = 0.00382812, m = 0.9
I0801 13:40:20.691617  3162 solver.cpp:353] Iteration 39600 (64.0884 iter/s, 1.56035s/100 iter), loss = 0.0356467
I0801 13:40:20.691643  3162 solver.cpp:375]     Train net output #0: loss = 0.0356468 (* 1 = 0.0356468 loss)
I0801 13:40:20.691648  3162 sgd_solver.cpp:136] Iteration 39600, lr = 0.0038125, m = 0.9
I0801 13:40:22.279026  3162 solver.cpp:353] Iteration 39700 (62.9979 iter/s, 1.58736s/100 iter), loss = 0.00320679
I0801 13:40:22.279078  3162 solver.cpp:375]     Train net output #0: loss = 0.00320689 (* 1 = 0.00320689 loss)
I0801 13:40:22.279093  3162 sgd_solver.cpp:136] Iteration 39700, lr = 0.00379687, m = 0.9
I0801 13:40:23.911515  3162 solver.cpp:353] Iteration 39800 (61.2583 iter/s, 1.63243s/100 iter), loss = 0.00271452
I0801 13:40:23.911561  3162 solver.cpp:375]     Train net output #0: loss = 0.00271463 (* 1 = 0.00271463 loss)
I0801 13:40:23.911583  3162 sgd_solver.cpp:136] Iteration 39800, lr = 0.00378125, m = 0.9
I0801 13:40:25.554805  3162 solver.cpp:353] Iteration 39900 (60.856 iter/s, 1.64322s/100 iter), loss = 0.0087018
I0801 13:40:25.554867  3162 solver.cpp:375]     Train net output #0: loss = 0.00870191 (* 1 = 0.00870191 loss)
I0801 13:40:25.554888  3162 sgd_solver.cpp:136] Iteration 39900, lr = 0.00376562, m = 0.9
I0801 13:40:27.153556  3162 solver.cpp:680] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/l1reg/cifar10_jacintonet11v2_iter_40000.caffemodel
I0801 13:40:27.163272  3162 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/l1reg/cifar10_jacintonet11v2_iter_40000.solverstate
I0801 13:40:27.168110  3162 solver.cpp:550] Iteration 40000, Testing net (#0)
I0801 13:40:28.092874  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.874707
I0801 13:40:28.092895  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.992059
I0801 13:40:28.092900  3162 solver.cpp:635]     Test net output #2: loss = 0.510542 (* 1 = 0.510542 loss)
I0801 13:40:28.092916  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.92478s
I0801 13:40:28.108687  3162 solver.cpp:353] Iteration 40000 (39.1571 iter/s, 2.55381s/100 iter), loss = 0.00683019
I0801 13:40:28.108742  3162 solver.cpp:375]     Train net output #0: loss = 0.00683031 (* 1 = 0.00683031 loss)
I0801 13:40:28.108758  3162 sgd_solver.cpp:136] Iteration 40000, lr = 0.00375, m = 0.9
I0801 13:40:29.769644  3162 solver.cpp:353] Iteration 40100 (60.2082 iter/s, 1.6609s/100 iter), loss = 0.00309148
I0801 13:40:29.769675  3162 solver.cpp:375]     Train net output #0: loss = 0.0030916 (* 1 = 0.0030916 loss)
I0801 13:40:29.769682  3162 sgd_solver.cpp:136] Iteration 40100, lr = 0.00373438, m = 0.9
I0801 13:40:31.363916  3162 solver.cpp:353] Iteration 40200 (62.7264 iter/s, 1.59423s/100 iter), loss = 0.00163039
I0801 13:40:31.363943  3162 solver.cpp:375]     Train net output #0: loss = 0.00163051 (* 1 = 0.00163051 loss)
I0801 13:40:31.363950  3162 sgd_solver.cpp:136] Iteration 40200, lr = 0.00371875, m = 0.9
I0801 13:40:33.046895  3162 solver.cpp:353] Iteration 40300 (59.4204 iter/s, 1.68292s/100 iter), loss = 0.00245952
I0801 13:40:33.046919  3162 solver.cpp:375]     Train net output #0: loss = 0.00245964 (* 1 = 0.00245964 loss)
I0801 13:40:33.046923  3162 sgd_solver.cpp:136] Iteration 40300, lr = 0.00370313, m = 0.9
I0801 13:40:34.673785  3162 solver.cpp:353] Iteration 40400 (61.4688 iter/s, 1.62684s/100 iter), loss = 0.0452328
I0801 13:40:34.673810  3162 solver.cpp:375]     Train net output #0: loss = 0.0452329 (* 1 = 0.0452329 loss)
I0801 13:40:34.673815  3162 sgd_solver.cpp:136] Iteration 40400, lr = 0.0036875, m = 0.9
I0801 13:40:36.364244  3162 solver.cpp:353] Iteration 40500 (59.1575 iter/s, 1.6904s/100 iter), loss = 0.00162398
I0801 13:40:36.364295  3162 solver.cpp:375]     Train net output #0: loss = 0.0016241 (* 1 = 0.0016241 loss)
I0801 13:40:36.364307  3162 sgd_solver.cpp:136] Iteration 40500, lr = 0.00367187, m = 0.9
I0801 13:40:38.141518  3162 solver.cpp:353] Iteration 40600 (56.2677 iter/s, 1.77722s/100 iter), loss = 0.000638246
I0801 13:40:38.141573  3162 solver.cpp:375]     Train net output #0: loss = 0.000638369 (* 1 = 0.000638369 loss)
I0801 13:40:38.141588  3162 sgd_solver.cpp:136] Iteration 40600, lr = 0.00365625, m = 0.9
I0801 13:40:39.778069  3162 solver.cpp:353] Iteration 40700 (61.1062 iter/s, 1.63649s/100 iter), loss = 0.00405577
I0801 13:40:39.778237  3162 solver.cpp:375]     Train net output #0: loss = 0.00405589 (* 1 = 0.00405589 loss)
I0801 13:40:39.778259  3162 sgd_solver.cpp:136] Iteration 40700, lr = 0.00364062, m = 0.9
I0801 13:40:41.454694  3162 solver.cpp:353] Iteration 40800 (59.6455 iter/s, 1.67657s/100 iter), loss = 0.00169312
I0801 13:40:41.454766  3162 solver.cpp:375]     Train net output #0: loss = 0.00169324 (* 1 = 0.00169324 loss)
I0801 13:40:41.454783  3162 sgd_solver.cpp:136] Iteration 40800, lr = 0.003625, m = 0.9
I0801 13:40:43.153105  3162 solver.cpp:353] Iteration 40900 (58.8803 iter/s, 1.69836s/100 iter), loss = 0.00575983
I0801 13:40:43.153131  3162 solver.cpp:375]     Train net output #0: loss = 0.00575995 (* 1 = 0.00575995 loss)
I0801 13:40:43.153137  3162 sgd_solver.cpp:136] Iteration 40900, lr = 0.00360937, m = 0.9
I0801 13:40:44.766434  3162 solver.cpp:550] Iteration 41000, Testing net (#0)
I0801 13:40:45.658963  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.906178
I0801 13:40:45.659029  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.995294
I0801 13:40:45.659276  3162 solver.cpp:635]     Test net output #2: loss = 0.362849 (* 1 = 0.362849 loss)
I0801 13:40:45.659581  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.893102s
I0801 13:40:45.676623  3162 solver.cpp:353] Iteration 41000 (39.6285 iter/s, 2.52344s/100 iter), loss = 0.00131682
I0801 13:40:45.676666  3162 solver.cpp:375]     Train net output #0: loss = 0.00131693 (* 1 = 0.00131693 loss)
I0801 13:40:45.676681  3162 sgd_solver.cpp:136] Iteration 41000, lr = 0.00359375, m = 0.9
I0801 13:40:47.397800  3162 solver.cpp:353] Iteration 41100 (58.1015 iter/s, 1.72113s/100 iter), loss = 0.000673118
I0801 13:40:47.397827  3162 solver.cpp:375]     Train net output #0: loss = 0.000673232 (* 1 = 0.000673232 loss)
I0801 13:40:47.397832  3162 sgd_solver.cpp:136] Iteration 41100, lr = 0.00357813, m = 0.9
I0801 13:40:49.117645  3162 solver.cpp:353] Iteration 41200 (58.1466 iter/s, 1.71979s/100 iter), loss = 0.00128522
I0801 13:40:49.117671  3162 solver.cpp:375]     Train net output #0: loss = 0.00128533 (* 1 = 0.00128533 loss)
I0801 13:40:49.117676  3162 sgd_solver.cpp:136] Iteration 41200, lr = 0.0035625, m = 0.9
I0801 13:40:50.819411  3162 solver.cpp:353] Iteration 41300 (58.7643 iter/s, 1.70171s/100 iter), loss = 0.000984248
I0801 13:40:50.819434  3162 solver.cpp:375]     Train net output #0: loss = 0.000984364 (* 1 = 0.000984364 loss)
I0801 13:40:50.819439  3162 sgd_solver.cpp:136] Iteration 41300, lr = 0.00354687, m = 0.9
I0801 13:40:52.446076  3162 solver.cpp:353] Iteration 41400 (61.4775 iter/s, 1.62661s/100 iter), loss = 0.00213586
I0801 13:40:52.446108  3162 solver.cpp:375]     Train net output #0: loss = 0.00213597 (* 1 = 0.00213597 loss)
I0801 13:40:52.446112  3162 sgd_solver.cpp:136] Iteration 41400, lr = 0.00353125, m = 0.9
I0801 13:40:54.134475  3162 solver.cpp:353] Iteration 41500 (59.2294 iter/s, 1.68835s/100 iter), loss = 0.0057573
I0801 13:40:54.134502  3162 solver.cpp:375]     Train net output #0: loss = 0.00575741 (* 1 = 0.00575741 loss)
I0801 13:40:54.134508  3162 sgd_solver.cpp:136] Iteration 41500, lr = 0.00351562, m = 0.9
I0801 13:40:55.785329  3162 solver.cpp:353] Iteration 41600 (60.5766 iter/s, 1.6508s/100 iter), loss = 0.0025656
I0801 13:40:55.785393  3162 solver.cpp:375]     Train net output #0: loss = 0.00256571 (* 1 = 0.00256571 loss)
I0801 13:40:55.785411  3162 sgd_solver.cpp:136] Iteration 41600, lr = 0.0035, m = 0.9
I0801 13:40:57.420375  3162 solver.cpp:353] Iteration 41700 (61.1623 iter/s, 1.63499s/100 iter), loss = 0.0487198
I0801 13:40:57.420459  3162 solver.cpp:375]     Train net output #0: loss = 0.0487199 (* 1 = 0.0487199 loss)
I0801 13:40:57.420473  3162 sgd_solver.cpp:136] Iteration 41700, lr = 0.00348437, m = 0.9
I0801 13:40:59.084676  3162 solver.cpp:353] Iteration 41800 (60.0871 iter/s, 1.66425s/100 iter), loss = 0.00133475
I0801 13:40:59.084702  3162 solver.cpp:375]     Train net output #0: loss = 0.00133486 (* 1 = 0.00133486 loss)
I0801 13:40:59.084708  3162 sgd_solver.cpp:136] Iteration 41800, lr = 0.00346875, m = 0.9
I0801 13:41:00.858556  3162 solver.cpp:353] Iteration 41900 (56.3758 iter/s, 1.77381s/100 iter), loss = 0.00175435
I0801 13:41:00.858605  3162 solver.cpp:375]     Train net output #0: loss = 0.00175447 (* 1 = 0.00175447 loss)
I0801 13:41:00.858717  3162 sgd_solver.cpp:136] Iteration 41900, lr = 0.00345312, m = 0.9
I0801 13:41:02.437942  3162 solver.cpp:550] Iteration 42000, Testing net (#0)
I0801 13:41:03.429474  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.906766
I0801 13:41:03.429497  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.995882
I0801 13:41:03.429502  3162 solver.cpp:635]     Test net output #2: loss = 0.361323 (* 1 = 0.361323 loss)
I0801 13:41:03.429517  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.991549s
I0801 13:41:03.445490  3162 solver.cpp:353] Iteration 42000 (38.6568 iter/s, 2.58687s/100 iter), loss = 0.00300552
I0801 13:41:03.445508  3162 solver.cpp:375]     Train net output #0: loss = 0.00300564 (* 1 = 0.00300564 loss)
I0801 13:41:03.445514  3162 sgd_solver.cpp:136] Iteration 42000, lr = 0.0034375, m = 0.9
I0801 13:41:05.109112  3162 solver.cpp:353] Iteration 42100 (60.112 iter/s, 1.66356s/100 iter), loss = 0.00192978
I0801 13:41:05.109205  3162 solver.cpp:375]     Train net output #0: loss = 0.00192989 (* 1 = 0.00192989 loss)
I0801 13:41:05.109236  3162 sgd_solver.cpp:136] Iteration 42100, lr = 0.00342188, m = 0.9
I0801 13:41:06.747817  3162 solver.cpp:353] Iteration 42200 (61.0257 iter/s, 1.63865s/100 iter), loss = 0.000785716
I0801 13:41:06.747848  3162 solver.cpp:375]     Train net output #0: loss = 0.000785838 (* 1 = 0.000785838 loss)
I0801 13:41:06.747853  3162 sgd_solver.cpp:136] Iteration 42200, lr = 0.00340625, m = 0.9
I0801 13:41:08.543383  3162 solver.cpp:353] Iteration 42300 (55.6947 iter/s, 1.7955s/100 iter), loss = 0.000862253
I0801 13:41:08.543517  3162 solver.cpp:375]     Train net output #0: loss = 0.000862375 (* 1 = 0.000862375 loss)
I0801 13:41:08.543536  3162 sgd_solver.cpp:136] Iteration 42300, lr = 0.00339063, m = 0.9
I0801 13:41:10.200898  3162 solver.cpp:353] Iteration 42400 (60.3328 iter/s, 1.65747s/100 iter), loss = 0.00214077
I0801 13:41:10.200923  3162 solver.cpp:375]     Train net output #0: loss = 0.0021409 (* 1 = 0.0021409 loss)
I0801 13:41:10.200929  3162 sgd_solver.cpp:136] Iteration 42400, lr = 0.003375, m = 0.9
I0801 13:41:11.911299  3162 solver.cpp:353] Iteration 42500 (58.4677 iter/s, 1.71035s/100 iter), loss = 0.0075202
I0801 13:41:11.911350  3162 solver.cpp:375]     Train net output #0: loss = 0.00752032 (* 1 = 0.00752032 loss)
I0801 13:41:11.911370  3162 sgd_solver.cpp:136] Iteration 42500, lr = 0.00335937, m = 0.9
I0801 13:41:13.634366  3162 solver.cpp:353] Iteration 42600 (58.0385 iter/s, 1.72299s/100 iter), loss = 0.00570642
I0801 13:41:13.634430  3162 solver.cpp:375]     Train net output #0: loss = 0.00570655 (* 1 = 0.00570655 loss)
I0801 13:41:13.634449  3162 sgd_solver.cpp:136] Iteration 42600, lr = 0.00334375, m = 0.9
I0801 13:41:15.357712  3162 solver.cpp:353] Iteration 42700 (58.0281 iter/s, 1.7233s/100 iter), loss = 0.00473276
I0801 13:41:15.357739  3162 solver.cpp:375]     Train net output #0: loss = 0.00473288 (* 1 = 0.00473288 loss)
I0801 13:41:15.357745  3162 sgd_solver.cpp:136] Iteration 42700, lr = 0.00332812, m = 0.9
I0801 13:41:16.954197  3162 solver.cpp:353] Iteration 42800 (62.6395 iter/s, 1.59644s/100 iter), loss = 0.000943755
I0801 13:41:16.954222  3162 solver.cpp:375]     Train net output #0: loss = 0.00094388 (* 1 = 0.00094388 loss)
I0801 13:41:16.954228  3162 sgd_solver.cpp:136] Iteration 42800, lr = 0.0033125, m = 0.9
I0801 13:41:18.527747  3162 solver.cpp:353] Iteration 42900 (63.5526 iter/s, 1.5735s/100 iter), loss = 0.00628885
I0801 13:41:18.527772  3162 solver.cpp:375]     Train net output #0: loss = 0.00628897 (* 1 = 0.00628897 loss)
I0801 13:41:18.527778  3162 sgd_solver.cpp:136] Iteration 42900, lr = 0.00329687, m = 0.9
I0801 13:41:20.073931  3162 solver.cpp:550] Iteration 43000, Testing net (#0)
I0801 13:41:20.907050  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.913531
I0801 13:41:20.907069  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.997059
I0801 13:41:20.907076  3162 solver.cpp:635]     Test net output #2: loss = 0.3247 (* 1 = 0.3247 loss)
I0801 13:41:20.907094  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.833139s
I0801 13:41:20.922844  3162 solver.cpp:353] Iteration 43000 (41.7532 iter/s, 2.39503s/100 iter), loss = 0.000706747
I0801 13:41:20.922864  3162 solver.cpp:375]     Train net output #0: loss = 0.000706873 (* 1 = 0.000706873 loss)
I0801 13:41:20.922869  3162 sgd_solver.cpp:136] Iteration 43000, lr = 0.00328125, m = 0.9
I0801 13:41:22.492360  3162 solver.cpp:353] Iteration 43100 (63.7161 iter/s, 1.56946s/100 iter), loss = 0.000193988
I0801 13:41:22.492388  3162 solver.cpp:375]     Train net output #0: loss = 0.000194113 (* 1 = 0.000194113 loss)
I0801 13:41:22.492394  3162 sgd_solver.cpp:136] Iteration 43100, lr = 0.00326563, m = 0.9
I0801 13:41:24.204766  3162 solver.cpp:353] Iteration 43200 (58.3994 iter/s, 1.71235s/100 iter), loss = 0.00508896
I0801 13:41:24.204813  3162 solver.cpp:375]     Train net output #0: loss = 0.00508909 (* 1 = 0.00508909 loss)
I0801 13:41:24.204831  3162 sgd_solver.cpp:136] Iteration 43200, lr = 0.00325, m = 0.9
I0801 13:41:25.805055  3162 solver.cpp:353] Iteration 43300 (62.4904 iter/s, 1.60025s/100 iter), loss = 0.0428959
I0801 13:41:25.805084  3162 solver.cpp:375]     Train net output #0: loss = 0.0428961 (* 1 = 0.0428961 loss)
I0801 13:41:25.805091  3162 sgd_solver.cpp:136] Iteration 43300, lr = 0.00323438, m = 0.9
I0801 13:41:27.368271  3162 solver.cpp:353] Iteration 43400 (63.9727 iter/s, 1.56317s/100 iter), loss = 0.00152221
I0801 13:41:27.368297  3162 solver.cpp:375]     Train net output #0: loss = 0.00152234 (* 1 = 0.00152234 loss)
I0801 13:41:27.368304  3162 sgd_solver.cpp:136] Iteration 43400, lr = 0.00321875, m = 0.9
I0801 13:41:28.944165  3162 solver.cpp:353] Iteration 43500 (63.4581 iter/s, 1.57584s/100 iter), loss = 0.000266026
I0801 13:41:28.944272  3162 solver.cpp:375]     Train net output #0: loss = 0.000266156 (* 1 = 0.000266156 loss)
I0801 13:41:28.944285  3162 sgd_solver.cpp:136] Iteration 43500, lr = 0.00320312, m = 0.9
I0801 13:41:30.537282  3162 solver.cpp:353] Iteration 43600 (62.7725 iter/s, 1.59306s/100 iter), loss = 0.00107396
I0801 13:41:30.537369  3162 solver.cpp:375]     Train net output #0: loss = 0.00107409 (* 1 = 0.00107409 loss)
I0801 13:41:30.537395  3162 sgd_solver.cpp:136] Iteration 43600, lr = 0.0031875, m = 0.9
I0801 13:41:32.210388  3162 solver.cpp:353] Iteration 43700 (59.7707 iter/s, 1.67306s/100 iter), loss = 0.000559897
I0801 13:41:32.210443  3162 solver.cpp:375]     Train net output #0: loss = 0.000560027 (* 1 = 0.000560027 loss)
I0801 13:41:32.210456  3162 sgd_solver.cpp:136] Iteration 43700, lr = 0.00317187, m = 0.9
I0801 13:41:33.997359  3162 solver.cpp:353] Iteration 43800 (55.9624 iter/s, 1.78691s/100 iter), loss = 0.000115311
I0801 13:41:33.997385  3162 solver.cpp:375]     Train net output #0: loss = 0.000115447 (* 1 = 0.000115447 loss)
I0801 13:41:33.997388  3162 sgd_solver.cpp:136] Iteration 43800, lr = 0.00315625, m = 0.9
I0801 13:41:35.620261  3162 solver.cpp:353] Iteration 43900 (61.6204 iter/s, 1.62284s/100 iter), loss = 0.000924004
I0801 13:41:35.620353  3162 solver.cpp:375]     Train net output #0: loss = 0.000924133 (* 1 = 0.000924133 loss)
I0801 13:41:35.620379  3162 sgd_solver.cpp:136] Iteration 43900, lr = 0.00314062, m = 0.9
I0801 13:41:36.211024  3155 data_reader.cpp:264] Starting prefetch of epoch 6
I0801 13:41:37.299839  3162 solver.cpp:550] Iteration 44000, Testing net (#0)
I0801 13:41:38.162240  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.920589
I0801 13:41:38.162281  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.997353
I0801 13:41:38.162293  3162 solver.cpp:635]     Test net output #2: loss = 0.299588 (* 1 = 0.299588 loss)
I0801 13:41:38.162325  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.862459s
I0801 13:41:38.186105  3162 solver.cpp:353] Iteration 44000 (38.9746 iter/s, 2.56577s/100 iter), loss = 0.00177889
I0801 13:41:38.186134  3162 solver.cpp:375]     Train net output #0: loss = 0.00177902 (* 1 = 0.00177902 loss)
I0801 13:41:38.186139  3162 sgd_solver.cpp:136] Iteration 44000, lr = 0.003125, m = 0.9
I0801 13:41:39.883288  3162 solver.cpp:353] Iteration 44100 (58.923 iter/s, 1.69713s/100 iter), loss = 0.0014717
I0801 13:41:39.883316  3162 solver.cpp:375]     Train net output #0: loss = 0.00147183 (* 1 = 0.00147183 loss)
I0801 13:41:39.883322  3162 sgd_solver.cpp:136] Iteration 44100, lr = 0.00310938, m = 0.9
I0801 13:41:41.607561  3162 solver.cpp:353] Iteration 44200 (57.9973 iter/s, 1.72422s/100 iter), loss = 0.000366713
I0801 13:41:41.607587  3162 solver.cpp:375]     Train net output #0: loss = 0.000366843 (* 1 = 0.000366843 loss)
I0801 13:41:41.607594  3162 sgd_solver.cpp:136] Iteration 44200, lr = 0.00309375, m = 0.9
I0801 13:41:43.256124  3162 solver.cpp:353] Iteration 44300 (60.6608 iter/s, 1.64851s/100 iter), loss = 0.00116798
I0801 13:41:43.256197  3162 solver.cpp:375]     Train net output #0: loss = 0.00116811 (* 1 = 0.00116811 loss)
I0801 13:41:43.256230  3162 sgd_solver.cpp:136] Iteration 44300, lr = 0.00307812, m = 0.9
I0801 13:41:44.997181  3162 solver.cpp:353] Iteration 44400 (57.4384 iter/s, 1.74099s/100 iter), loss = 0.00349851
I0801 13:41:44.997227  3162 solver.cpp:375]     Train net output #0: loss = 0.00349864 (* 1 = 0.00349864 loss)
I0801 13:41:44.997236  3162 sgd_solver.cpp:136] Iteration 44400, lr = 0.0030625, m = 0.9
I0801 13:41:46.604364  3162 solver.cpp:353] Iteration 44500 (62.2229 iter/s, 1.60713s/100 iter), loss = 0.000682049
I0801 13:41:46.604586  3162 solver.cpp:375]     Train net output #0: loss = 0.000682179 (* 1 = 0.000682179 loss)
I0801 13:41:46.604677  3162 sgd_solver.cpp:136] Iteration 44500, lr = 0.00304687, m = 0.9
I0801 13:41:48.321514  3162 solver.cpp:353] Iteration 44600 (58.2375 iter/s, 1.71711s/100 iter), loss = 0.00198234
I0801 13:41:48.321538  3162 solver.cpp:375]     Train net output #0: loss = 0.00198247 (* 1 = 0.00198247 loss)
I0801 13:41:48.321563  3162 sgd_solver.cpp:136] Iteration 44600, lr = 0.00303125, m = 0.9
I0801 13:41:50.024631  3162 solver.cpp:353] Iteration 44700 (58.7179 iter/s, 1.70306s/100 iter), loss = 0.000152428
I0801 13:41:50.024659  3162 solver.cpp:375]     Train net output #0: loss = 0.000152557 (* 1 = 0.000152557 loss)
I0801 13:41:50.024667  3162 sgd_solver.cpp:136] Iteration 44700, lr = 0.00301562, m = 0.9
I0801 13:41:51.802703  3162 solver.cpp:353] Iteration 44800 (56.2423 iter/s, 1.77802s/100 iter), loss = 0.00346247
I0801 13:41:51.802734  3162 solver.cpp:375]     Train net output #0: loss = 0.0034626 (* 1 = 0.0034626 loss)
I0801 13:41:51.802742  3162 sgd_solver.cpp:136] Iteration 44800, lr = 0.003, m = 0.9
I0801 13:41:53.395320  3162 solver.cpp:353] Iteration 44900 (62.7918 iter/s, 1.59256s/100 iter), loss = 0.00280417
I0801 13:41:53.395412  3162 solver.cpp:375]     Train net output #0: loss = 0.0028043 (* 1 = 0.0028043 loss)
I0801 13:41:53.395421  3162 sgd_solver.cpp:136] Iteration 44900, lr = 0.00298437, m = 0.9
I0801 13:41:55.035684  3162 solver.cpp:550] Iteration 45000, Testing net (#0)
I0801 13:41:55.954360  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.919119
I0801 13:41:55.954378  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.997647
I0801 13:41:55.954383  3162 solver.cpp:635]     Test net output #2: loss = 0.317746 (* 1 = 0.317746 loss)
I0801 13:41:55.954399  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.91869s
I0801 13:41:55.970777  3162 solver.cpp:353] Iteration 45000 (38.8293 iter/s, 2.57538s/100 iter), loss = 0.00110971
I0801 13:41:55.970798  3162 solver.cpp:375]     Train net output #0: loss = 0.00110984 (* 1 = 0.00110984 loss)
I0801 13:41:55.970803  3162 sgd_solver.cpp:136] Iteration 45000, lr = 0.00296875, m = 0.9
I0801 13:41:57.613937  3162 solver.cpp:353] Iteration 45100 (60.8602 iter/s, 1.64311s/100 iter), loss = 0.00105821
I0801 13:41:57.613976  3162 solver.cpp:375]     Train net output #0: loss = 0.00105834 (* 1 = 0.00105834 loss)
I0801 13:41:57.613982  3162 sgd_solver.cpp:136] Iteration 45100, lr = 0.00295313, m = 0.9
I0801 13:41:59.300936  3162 solver.cpp:353] Iteration 45200 (59.2787 iter/s, 1.68695s/100 iter), loss = 0.00127226
I0801 13:41:59.301185  3162 solver.cpp:375]     Train net output #0: loss = 0.00127239 (* 1 = 0.00127239 loss)
I0801 13:41:59.301195  3162 sgd_solver.cpp:136] Iteration 45200, lr = 0.0029375, m = 0.9
I0801 13:42:01.107919  3162 solver.cpp:353] Iteration 45300 (55.3426 iter/s, 1.80693s/100 iter), loss = 0.000400358
I0801 13:42:01.107947  3162 solver.cpp:375]     Train net output #0: loss = 0.000400489 (* 1 = 0.000400489 loss)
I0801 13:42:01.107954  3162 sgd_solver.cpp:136] Iteration 45300, lr = 0.00292188, m = 0.9
I0801 13:42:02.739167  3162 solver.cpp:353] Iteration 45400 (61.3047 iter/s, 1.6312s/100 iter), loss = 0.00091782
I0801 13:42:02.739197  3162 solver.cpp:375]     Train net output #0: loss = 0.000917949 (* 1 = 0.000917949 loss)
I0801 13:42:02.739204  3162 sgd_solver.cpp:136] Iteration 45400, lr = 0.00290625, m = 0.9
I0801 13:42:04.369397  3162 solver.cpp:353] Iteration 45500 (61.3429 iter/s, 1.63018s/100 iter), loss = 0.000671595
I0801 13:42:04.369424  3162 solver.cpp:375]     Train net output #0: loss = 0.000671726 (* 1 = 0.000671726 loss)
I0801 13:42:04.369431  3162 sgd_solver.cpp:136] Iteration 45500, lr = 0.00289063, m = 0.9
I0801 13:42:05.981248  3162 solver.cpp:353] Iteration 45600 (62.0428 iter/s, 1.61179s/100 iter), loss = 0.00123627
I0801 13:42:05.981294  3162 solver.cpp:375]     Train net output #0: loss = 0.0012364 (* 1 = 0.0012364 loss)
I0801 13:42:05.981317  3162 sgd_solver.cpp:136] Iteration 45600, lr = 0.002875, m = 0.9
I0801 13:42:07.759845  3162 solver.cpp:353] Iteration 45700 (56.2261 iter/s, 1.77853s/100 iter), loss = 0.00128022
I0801 13:42:07.760129  3162 solver.cpp:375]     Train net output #0: loss = 0.00128035 (* 1 = 0.00128035 loss)
I0801 13:42:07.760257  3162 sgd_solver.cpp:136] Iteration 45700, lr = 0.00285937, m = 0.9
I0801 13:42:09.404652  3162 solver.cpp:353] Iteration 45800 (60.799 iter/s, 1.64476s/100 iter), loss = 0.000407946
I0801 13:42:09.404741  3162 solver.cpp:375]     Train net output #0: loss = 0.000408077 (* 1 = 0.000408077 loss)
I0801 13:42:09.404748  3162 sgd_solver.cpp:136] Iteration 45800, lr = 0.00284375, m = 0.9
I0801 13:42:11.109827  3162 solver.cpp:353] Iteration 45900 (58.6469 iter/s, 1.70512s/100 iter), loss = 0.00242511
I0801 13:42:11.109850  3162 solver.cpp:375]     Train net output #0: loss = 0.00242524 (* 1 = 0.00242524 loss)
I0801 13:42:11.109854  3162 sgd_solver.cpp:136] Iteration 45900, lr = 0.00282812, m = 0.9
I0801 13:42:12.747606  3162 solver.cpp:550] Iteration 46000, Testing net (#0)
I0801 13:42:13.617817  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.910001
I0801 13:42:13.617843  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996471
I0801 13:42:13.617851  3162 solver.cpp:635]     Test net output #2: loss = 0.331918 (* 1 = 0.331918 loss)
I0801 13:42:13.617874  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.87025s
I0801 13:42:13.638016  3162 solver.cpp:353] Iteration 46000 (39.5553 iter/s, 2.52811s/100 iter), loss = 0.00168187
I0801 13:42:13.638053  3162 solver.cpp:375]     Train net output #0: loss = 0.001682 (* 1 = 0.001682 loss)
I0801 13:42:13.638069  3162 sgd_solver.cpp:136] Iteration 46000, lr = 0.0028125, m = 0.9
I0801 13:42:15.262856  3162 solver.cpp:353] Iteration 46100 (61.5463 iter/s, 1.62479s/100 iter), loss = 0.00138357
I0801 13:42:15.262881  3162 solver.cpp:375]     Train net output #0: loss = 0.0013837 (* 1 = 0.0013837 loss)
I0801 13:42:15.262887  3162 sgd_solver.cpp:136] Iteration 46100, lr = 0.00279688, m = 0.9
I0801 13:42:16.923267  3162 solver.cpp:353] Iteration 46200 (60.228 iter/s, 1.66036s/100 iter), loss = 0.000780777
I0801 13:42:16.923319  3162 solver.cpp:375]     Train net output #0: loss = 0.000780909 (* 1 = 0.000780909 loss)
I0801 13:42:16.923333  3162 sgd_solver.cpp:136] Iteration 46200, lr = 0.00278125, m = 0.9
I0801 13:42:18.669873  3162 solver.cpp:353] Iteration 46300 (57.2558 iter/s, 1.74655s/100 iter), loss = 0.000649345
I0801 13:42:18.669937  3162 solver.cpp:375]     Train net output #0: loss = 0.000649477 (* 1 = 0.000649477 loss)
I0801 13:42:18.669957  3162 sgd_solver.cpp:136] Iteration 46300, lr = 0.00276563, m = 0.9
I0801 13:42:20.454071  3162 solver.cpp:353] Iteration 46400 (56.0492 iter/s, 1.78415s/100 iter), loss = 0.000218571
I0801 13:42:20.454097  3162 solver.cpp:375]     Train net output #0: loss = 0.000218704 (* 1 = 0.000218704 loss)
I0801 13:42:20.454103  3162 sgd_solver.cpp:136] Iteration 46400, lr = 0.00275, m = 0.9
I0801 13:42:22.157699  3162 solver.cpp:353] Iteration 46500 (58.7001 iter/s, 1.70358s/100 iter), loss = 0.001244
I0801 13:42:22.157724  3162 solver.cpp:375]     Train net output #0: loss = 0.00124413 (* 1 = 0.00124413 loss)
I0801 13:42:22.157730  3162 sgd_solver.cpp:136] Iteration 46500, lr = 0.00273437, m = 0.9
I0801 13:42:23.838973  3162 solver.cpp:353] Iteration 46600 (59.4806 iter/s, 1.68122s/100 iter), loss = 0.000676376
I0801 13:42:23.839046  3162 solver.cpp:375]     Train net output #0: loss = 0.00067651 (* 1 = 0.00067651 loss)
I0801 13:42:23.839066  3162 sgd_solver.cpp:136] Iteration 46600, lr = 0.00271875, m = 0.9
I0801 13:42:25.524070  3162 solver.cpp:353] Iteration 46700 (59.3457 iter/s, 1.68504s/100 iter), loss = 0.00146967
I0801 13:42:25.524143  3162 solver.cpp:375]     Train net output #0: loss = 0.00146981 (* 1 = 0.00146981 loss)
I0801 13:42:25.524158  3162 sgd_solver.cpp:136] Iteration 46700, lr = 0.00270312, m = 0.9
I0801 13:42:27.093744  3162 solver.cpp:353] Iteration 46800 (63.7095 iter/s, 1.56963s/100 iter), loss = 0.000499066
I0801 13:42:27.093773  3162 solver.cpp:375]     Train net output #0: loss = 0.0004992 (* 1 = 0.0004992 loss)
I0801 13:42:27.093780  3162 sgd_solver.cpp:136] Iteration 46800, lr = 0.0026875, m = 0.9
I0801 13:42:28.689327  3162 solver.cpp:353] Iteration 46900 (62.6749 iter/s, 1.59554s/100 iter), loss = 0.000178366
I0801 13:42:28.689353  3162 solver.cpp:375]     Train net output #0: loss = 0.000178502 (* 1 = 0.000178502 loss)
I0801 13:42:28.689359  3162 sgd_solver.cpp:136] Iteration 46900, lr = 0.00267187, m = 0.9
I0801 13:42:30.246856  3162 solver.cpp:550] Iteration 47000, Testing net (#0)
I0801 13:42:31.079294  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.907942
I0801 13:42:31.079313  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.997059
I0801 13:42:31.079319  3162 solver.cpp:635]     Test net output #2: loss = 0.346737 (* 1 = 0.346737 loss)
I0801 13:42:31.079334  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.832455s
I0801 13:42:31.095064  3162 solver.cpp:353] Iteration 47000 (41.5686 iter/s, 2.40566s/100 iter), loss = 0.00126874
I0801 13:42:31.095084  3162 solver.cpp:375]     Train net output #0: loss = 0.00126888 (* 1 = 0.00126888 loss)
I0801 13:42:31.095090  3162 sgd_solver.cpp:136] Iteration 47000, lr = 0.00265625, m = 0.9
I0801 13:42:32.754015  3162 solver.cpp:353] Iteration 47100 (60.2815 iter/s, 1.65888s/100 iter), loss = 0.00160353
I0801 13:42:32.754098  3162 solver.cpp:375]     Train net output #0: loss = 0.00160367 (* 1 = 0.00160367 loss)
I0801 13:42:32.754125  3162 sgd_solver.cpp:136] Iteration 47100, lr = 0.00264063, m = 0.9
I0801 13:42:34.348410  3162 solver.cpp:353] Iteration 47200 (62.7214 iter/s, 1.59435s/100 iter), loss = 0.00103847
I0801 13:42:34.348434  3162 solver.cpp:375]     Train net output #0: loss = 0.0010386 (* 1 = 0.0010386 loss)
I0801 13:42:34.348440  3162 sgd_solver.cpp:136] Iteration 47200, lr = 0.002625, m = 0.9
I0801 13:42:36.033289  3162 solver.cpp:353] Iteration 47300 (59.3533 iter/s, 1.68483s/100 iter), loss = 0.000257937
I0801 13:42:36.033316  3162 solver.cpp:375]     Train net output #0: loss = 0.000258072 (* 1 = 0.000258072 loss)
I0801 13:42:36.033323  3162 sgd_solver.cpp:136] Iteration 47300, lr = 0.00260938, m = 0.9
I0801 13:42:37.603328  3162 solver.cpp:353] Iteration 47400 (63.6946 iter/s, 1.56999s/100 iter), loss = 0.0012193
I0801 13:42:37.603351  3162 solver.cpp:375]     Train net output #0: loss = 0.00121943 (* 1 = 0.00121943 loss)
I0801 13:42:37.603356  3162 sgd_solver.cpp:136] Iteration 47400, lr = 0.00259375, m = 0.9
I0801 13:42:39.174629  3162 solver.cpp:353] Iteration 47500 (63.6435 iter/s, 1.57125s/100 iter), loss = 0.00108784
I0801 13:42:39.174655  3162 solver.cpp:375]     Train net output #0: loss = 0.00108798 (* 1 = 0.00108798 loss)
I0801 13:42:39.174661  3162 sgd_solver.cpp:136] Iteration 47500, lr = 0.00257812, m = 0.9
I0801 13:42:40.791870  3162 solver.cpp:353] Iteration 47600 (61.8358 iter/s, 1.61719s/100 iter), loss = 0.000155928
I0801 13:42:40.792098  3162 solver.cpp:375]     Train net output #0: loss = 0.000156062 (* 1 = 0.000156062 loss)
I0801 13:42:40.792224  3162 sgd_solver.cpp:136] Iteration 47600, lr = 0.0025625, m = 0.9
I0801 13:42:42.439376  3162 solver.cpp:353] Iteration 47700 (60.6996 iter/s, 1.64746s/100 iter), loss = 0.0021478
I0801 13:42:42.439429  3162 solver.cpp:375]     Train net output #0: loss = 0.00214793 (* 1 = 0.00214793 loss)
I0801 13:42:42.439437  3162 sgd_solver.cpp:136] Iteration 47700, lr = 0.00254687, m = 0.9
I0801 13:42:44.146163  3162 solver.cpp:353] Iteration 47800 (58.5915 iter/s, 1.70673s/100 iter), loss = 0.00156237
I0801 13:42:44.146189  3162 solver.cpp:375]     Train net output #0: loss = 0.00156251 (* 1 = 0.00156251 loss)
I0801 13:42:44.146195  3162 sgd_solver.cpp:136] Iteration 47800, lr = 0.00253125, m = 0.9
I0801 13:42:45.877737  3162 solver.cpp:353] Iteration 47900 (57.7526 iter/s, 1.73152s/100 iter), loss = 0.000995956
I0801 13:42:45.877761  3162 solver.cpp:375]     Train net output #0: loss = 0.000996089 (* 1 = 0.000996089 loss)
I0801 13:42:45.877768  3162 sgd_solver.cpp:136] Iteration 47900, lr = 0.00251562, m = 0.9
I0801 13:42:47.457856  3162 solver.cpp:550] Iteration 48000, Testing net (#0)
I0801 13:42:47.488243  3160 data_reader.cpp:264] Starting prefetch of epoch 6
I0801 13:42:48.466490  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.910295
I0801 13:42:48.466513  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.997059
I0801 13:42:48.466519  3162 solver.cpp:635]     Test net output #2: loss = 0.340712 (* 1 = 0.340712 loss)
I0801 13:42:48.466766  3162 solver.cpp:305] [MultiGPU] Tests completed in 1.00866s
I0801 13:42:48.482089  3162 solver.cpp:353] Iteration 48000 (38.3984 iter/s, 2.60428s/100 iter), loss = 0.00158598
I0801 13:42:48.482120  3162 solver.cpp:375]     Train net output #0: loss = 0.00158611 (* 1 = 0.00158611 loss)
I0801 13:42:48.482125  3162 sgd_solver.cpp:136] Iteration 48000, lr = 0.0025, m = 0.9
I0801 13:42:50.080060  3162 solver.cpp:353] Iteration 48100 (62.5818 iter/s, 1.59791s/100 iter), loss = 0.00135707
I0801 13:42:50.080103  3162 solver.cpp:375]     Train net output #0: loss = 0.0013572 (* 1 = 0.0013572 loss)
I0801 13:42:50.080221  3162 sgd_solver.cpp:136] Iteration 48100, lr = 0.00248438, m = 0.9
I0801 13:42:51.834782  3162 solver.cpp:353] Iteration 48200 (56.9909 iter/s, 1.75467s/100 iter), loss = 0.00153219
I0801 13:42:51.835047  3162 solver.cpp:375]     Train net output #0: loss = 0.00153232 (* 1 = 0.00153232 loss)
I0801 13:42:51.835172  3162 sgd_solver.cpp:136] Iteration 48200, lr = 0.00246875, m = 0.9
I0801 13:42:53.538575  3162 solver.cpp:353] Iteration 48300 (58.6942 iter/s, 1.70375s/100 iter), loss = 0.000675027
I0801 13:42:53.538600  3162 solver.cpp:375]     Train net output #0: loss = 0.000675161 (* 1 = 0.000675161 loss)
I0801 13:42:53.538606  3162 sgd_solver.cpp:136] Iteration 48300, lr = 0.00245313, m = 0.9
I0801 13:42:55.236089  3162 solver.cpp:353] Iteration 48400 (58.9117 iter/s, 1.69746s/100 iter), loss = 0.000178911
I0801 13:42:55.236161  3162 solver.cpp:375]     Train net output #0: loss = 0.000179045 (* 1 = 0.000179045 loss)
I0801 13:42:55.236181  3162 sgd_solver.cpp:136] Iteration 48400, lr = 0.0024375, m = 0.9
I0801 13:42:56.902595  3162 solver.cpp:353] Iteration 48500 (60.0077 iter/s, 1.66645s/100 iter), loss = 0.000420602
I0801 13:42:56.902670  3162 solver.cpp:375]     Train net output #0: loss = 0.000420735 (* 1 = 0.000420735 loss)
I0801 13:42:56.902695  3162 sgd_solver.cpp:136] Iteration 48500, lr = 0.00242188, m = 0.9
I0801 13:42:58.521833  3162 solver.cpp:353] Iteration 48600 (61.7592 iter/s, 1.61919s/100 iter), loss = 0.00126469
I0801 13:42:58.521895  3162 solver.cpp:375]     Train net output #0: loss = 0.00126482 (* 1 = 0.00126482 loss)
I0801 13:42:58.521914  3162 sgd_solver.cpp:136] Iteration 48600, lr = 0.00240625, m = 0.9
I0801 13:43:00.237936  3162 solver.cpp:353] Iteration 48700 (58.2736 iter/s, 1.71604s/100 iter), loss = 0.000549521
I0801 13:43:00.237987  3162 solver.cpp:375]     Train net output #0: loss = 0.000549655 (* 1 = 0.000549655 loss)
I0801 13:43:00.238198  3162 sgd_solver.cpp:136] Iteration 48700, lr = 0.00239062, m = 0.9
I0801 13:43:01.888628  3162 solver.cpp:353] Iteration 48800 (60.5827 iter/s, 1.65064s/100 iter), loss = 0.00071877
I0801 13:43:01.888784  3162 solver.cpp:375]     Train net output #0: loss = 0.000718904 (* 1 = 0.000718904 loss)
I0801 13:43:01.888811  3162 sgd_solver.cpp:136] Iteration 48800, lr = 0.002375, m = 0.9
I0801 13:43:03.500634  3162 solver.cpp:353] Iteration 48900 (62.0362 iter/s, 1.61196s/100 iter), loss = 0.00104895
I0801 13:43:03.500660  3162 solver.cpp:375]     Train net output #0: loss = 0.00104909 (* 1 = 0.00104909 loss)
I0801 13:43:03.500666  3162 sgd_solver.cpp:136] Iteration 48900, lr = 0.00235937, m = 0.9
I0801 13:43:05.203639  3162 solver.cpp:550] Iteration 49000, Testing net (#0)
I0801 13:43:06.151350  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.910001
I0801 13:43:06.151370  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.995588
I0801 13:43:06.151374  3162 solver.cpp:635]     Test net output #2: loss = 0.341068 (* 1 = 0.341068 loss)
I0801 13:43:06.151391  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.947724s
I0801 13:43:06.167027  3162 solver.cpp:353] Iteration 49000 (37.505 iter/s, 2.66631s/100 iter), loss = 0.00331568
I0801 13:43:06.167043  3162 solver.cpp:375]     Train net output #0: loss = 0.00331581 (* 1 = 0.00331581 loss)
I0801 13:43:06.167047  3162 sgd_solver.cpp:136] Iteration 49000, lr = 0.00234375, m = 0.9
I0801 13:43:07.853847  3162 solver.cpp:353] Iteration 49100 (59.2855 iter/s, 1.68675s/100 iter), loss = 0.00102733
I0801 13:43:07.853898  3162 solver.cpp:375]     Train net output #0: loss = 0.00102747 (* 1 = 0.00102747 loss)
I0801 13:43:07.853906  3162 sgd_solver.cpp:136] Iteration 49100, lr = 0.00232813, m = 0.9
I0801 13:43:09.455504  3162 solver.cpp:353] Iteration 49200 (62.4369 iter/s, 1.60162s/100 iter), loss = 0.00150719
I0801 13:43:09.455556  3162 solver.cpp:375]     Train net output #0: loss = 0.00150732 (* 1 = 0.00150732 loss)
I0801 13:43:09.455571  3162 sgd_solver.cpp:136] Iteration 49200, lr = 0.0023125, m = 0.9
I0801 13:43:11.106542  3162 solver.cpp:353] Iteration 49300 (60.57 iter/s, 1.65098s/100 iter), loss = 0.000505843
I0801 13:43:11.106570  3162 solver.cpp:375]     Train net output #0: loss = 0.000505978 (* 1 = 0.000505978 loss)
I0801 13:43:11.106576  3162 sgd_solver.cpp:136] Iteration 49300, lr = 0.00229687, m = 0.9
I0801 13:43:12.784241  3162 solver.cpp:353] Iteration 49400 (59.6074 iter/s, 1.67764s/100 iter), loss = 0.000741314
I0801 13:43:12.784342  3162 solver.cpp:375]     Train net output #0: loss = 0.00074145 (* 1 = 0.00074145 loss)
I0801 13:43:12.784369  3162 sgd_solver.cpp:136] Iteration 49400, lr = 0.00228125, m = 0.9
I0801 13:43:14.535714  3162 solver.cpp:353] Iteration 49500 (57.0964 iter/s, 1.75142s/100 iter), loss = 0.000677509
I0801 13:43:14.535742  3162 solver.cpp:375]     Train net output #0: loss = 0.000677643 (* 1 = 0.000677643 loss)
I0801 13:43:14.535748  3162 sgd_solver.cpp:136] Iteration 49500, lr = 0.00226562, m = 0.9
I0801 13:43:16.221545  3162 solver.cpp:353] Iteration 49600 (59.3198 iter/s, 1.68578s/100 iter), loss = 0.000919108
I0801 13:43:16.221596  3162 solver.cpp:375]     Train net output #0: loss = 0.000919243 (* 1 = 0.000919243 loss)
I0801 13:43:16.221607  3162 sgd_solver.cpp:136] Iteration 49600, lr = 0.00225, m = 0.9
I0801 13:43:17.885617  3162 solver.cpp:353] Iteration 49700 (60.0954 iter/s, 1.66402s/100 iter), loss = 0.000867596
I0801 13:43:17.885643  3162 solver.cpp:375]     Train net output #0: loss = 0.000867731 (* 1 = 0.000867731 loss)
I0801 13:43:17.885650  3162 sgd_solver.cpp:136] Iteration 49700, lr = 0.00223437, m = 0.9
I0801 13:43:19.583712  3162 solver.cpp:353] Iteration 49800 (58.8914 iter/s, 1.69804s/100 iter), loss = 0.000457131
I0801 13:43:19.583740  3162 solver.cpp:375]     Train net output #0: loss = 0.000457266 (* 1 = 0.000457266 loss)
I0801 13:43:19.583747  3162 sgd_solver.cpp:136] Iteration 49800, lr = 0.00221875, m = 0.9
I0801 13:43:21.267417  3162 solver.cpp:353] Iteration 49900 (59.3947 iter/s, 1.68365s/100 iter), loss = 0.00024708
I0801 13:43:21.267441  3162 solver.cpp:375]     Train net output #0: loss = 0.000247215 (* 1 = 0.000247215 loss)
I0801 13:43:21.267446  3162 sgd_solver.cpp:136] Iteration 49900, lr = 0.00220312, m = 0.9
I0801 13:43:22.869583  3162 solver.cpp:680] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/l1reg/cifar10_jacintonet11v2_iter_50000.caffemodel
I0801 13:43:22.879567  3162 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/l1reg/cifar10_jacintonet11v2_iter_50000.solverstate
I0801 13:43:22.883487  3162 solver.cpp:550] Iteration 50000, Testing net (#0)
I0801 13:43:23.728260  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.905589
I0801 13:43:23.728277  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.995294
I0801 13:43:23.728283  3162 solver.cpp:635]     Test net output #2: loss = 0.362569 (* 1 = 0.362569 loss)
I0801 13:43:23.728302  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.844791s
I0801 13:43:23.746763  3162 solver.cpp:353] Iteration 50000 (40.3345 iter/s, 2.47927s/100 iter), loss = 0.000739925
I0801 13:43:23.746786  3162 solver.cpp:375]     Train net output #0: loss = 0.000740061 (* 1 = 0.000740061 loss)
I0801 13:43:23.746790  3162 sgd_solver.cpp:136] Iteration 50000, lr = 0.0021875, m = 0.9
I0801 13:43:25.412663  3162 solver.cpp:353] Iteration 50100 (60.0295 iter/s, 1.66585s/100 iter), loss = 0.000256935
I0801 13:43:25.412691  3162 solver.cpp:375]     Train net output #0: loss = 0.000257071 (* 1 = 0.000257071 loss)
I0801 13:43:25.412698  3162 sgd_solver.cpp:136] Iteration 50100, lr = 0.00217188, m = 0.9
I0801 13:43:27.057118  3162 solver.cpp:353] Iteration 50200 (60.8122 iter/s, 1.64441s/100 iter), loss = 0.0036674
I0801 13:43:27.057145  3162 solver.cpp:375]     Train net output #0: loss = 0.00366753 (* 1 = 0.00366753 loss)
I0801 13:43:27.057152  3162 sgd_solver.cpp:136] Iteration 50200, lr = 0.00215625, m = 0.9
I0801 13:43:28.733896  3162 solver.cpp:353] Iteration 50300 (59.6405 iter/s, 1.67671s/100 iter), loss = 0.000221225
I0801 13:43:28.733953  3162 solver.cpp:375]     Train net output #0: loss = 0.000221363 (* 1 = 0.000221363 loss)
I0801 13:43:28.733965  3162 sgd_solver.cpp:136] Iteration 50300, lr = 0.00214063, m = 0.9
I0801 13:43:30.422533  3162 solver.cpp:353] Iteration 50400 (59.221 iter/s, 1.68859s/100 iter), loss = 0.00101477
I0801 13:43:30.422559  3162 solver.cpp:375]     Train net output #0: loss = 0.0010149 (* 1 = 0.0010149 loss)
I0801 13:43:30.422564  3162 sgd_solver.cpp:136] Iteration 50400, lr = 0.002125, m = 0.9
I0801 13:43:32.042439  3162 solver.cpp:353] Iteration 50500 (61.7339 iter/s, 1.61986s/100 iter), loss = 0.0024834
I0801 13:43:32.042520  3162 solver.cpp:375]     Train net output #0: loss = 0.00248353 (* 1 = 0.00248353 loss)
I0801 13:43:32.042527  3162 sgd_solver.cpp:136] Iteration 50500, lr = 0.00210937, m = 0.9
I0801 13:43:33.724272  3162 solver.cpp:353] Iteration 50600 (59.4609 iter/s, 1.68178s/100 iter), loss = 0.00128911
I0801 13:43:33.724300  3162 solver.cpp:375]     Train net output #0: loss = 0.00128925 (* 1 = 0.00128925 loss)
I0801 13:43:33.724308  3162 sgd_solver.cpp:136] Iteration 50600, lr = 0.00209375, m = 0.9
I0801 13:43:35.381302  3162 solver.cpp:353] Iteration 50700 (60.351 iter/s, 1.65697s/100 iter), loss = 0.000791598
I0801 13:43:35.381350  3162 solver.cpp:375]     Train net output #0: loss = 0.000791736 (* 1 = 0.000791736 loss)
I0801 13:43:35.381362  3162 sgd_solver.cpp:136] Iteration 50700, lr = 0.00207812, m = 0.9
I0801 13:43:36.974944  3162 solver.cpp:353] Iteration 50800 (62.7512 iter/s, 1.5936s/100 iter), loss = 0.000438652
I0801 13:43:36.975010  3162 solver.cpp:375]     Train net output #0: loss = 0.00043879 (* 1 = 0.00043879 loss)
I0801 13:43:36.975030  3162 sgd_solver.cpp:136] Iteration 50800, lr = 0.0020625, m = 0.9
I0801 13:43:38.534957  3162 solver.cpp:353] Iteration 50900 (64.1041 iter/s, 1.55996s/100 iter), loss = 0.000174204
I0801 13:43:38.534981  3162 solver.cpp:375]     Train net output #0: loss = 0.000174341 (* 1 = 0.000174341 loss)
I0801 13:43:38.534986  3162 sgd_solver.cpp:136] Iteration 50900, lr = 0.00204687, m = 0.9
I0801 13:43:40.085543  3162 solver.cpp:550] Iteration 51000, Testing net (#0)
I0801 13:43:40.918507  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.910589
I0801 13:43:40.918527  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.995588
I0801 13:43:40.918532  3162 solver.cpp:635]     Test net output #2: loss = 0.349791 (* 1 = 0.349791 loss)
I0801 13:43:40.918550  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.832983s
I0801 13:43:40.934376  3162 solver.cpp:353] Iteration 51000 (41.678 iter/s, 2.39935s/100 iter), loss = 0.00075372
I0801 13:43:40.934399  3162 solver.cpp:375]     Train net output #0: loss = 0.000753856 (* 1 = 0.000753856 loss)
I0801 13:43:40.934403  3162 sgd_solver.cpp:136] Iteration 51000, lr = 0.00203125, m = 0.9
I0801 13:43:42.644898  3162 solver.cpp:353] Iteration 51100 (58.4638 iter/s, 1.71046s/100 iter), loss = 0.000837216
I0801 13:43:42.644937  3162 solver.cpp:375]     Train net output #0: loss = 0.000837352 (* 1 = 0.000837352 loss)
I0801 13:43:42.644945  3162 sgd_solver.cpp:136] Iteration 51100, lr = 0.00201563, m = 0.9
I0801 13:43:44.287966  3162 solver.cpp:353] Iteration 51200 (60.8639 iter/s, 1.64301s/100 iter), loss = 0.00045923
I0801 13:43:44.288055  3162 solver.cpp:375]     Train net output #0: loss = 0.000459366 (* 1 = 0.000459366 loss)
I0801 13:43:44.288084  3162 sgd_solver.cpp:136] Iteration 51200, lr = 0.002, m = 0.9
I0801 13:43:46.039134  3162 solver.cpp:353] Iteration 51300 (57.1064 iter/s, 1.75112s/100 iter), loss = 0.00157965
I0801 13:43:46.039160  3162 solver.cpp:375]     Train net output #0: loss = 0.00157978 (* 1 = 0.00157978 loss)
I0801 13:43:46.039166  3162 sgd_solver.cpp:136] Iteration 51300, lr = 0.00198438, m = 0.9
I0801 13:43:47.625402  3162 solver.cpp:353] Iteration 51400 (63.043 iter/s, 1.58622s/100 iter), loss = 0.000651837
I0801 13:43:47.625465  3162 solver.cpp:375]     Train net output #0: loss = 0.000651974 (* 1 = 0.000651974 loss)
I0801 13:43:47.625484  3162 sgd_solver.cpp:136] Iteration 51400, lr = 0.00196875, m = 0.9
I0801 13:43:49.186872  3162 solver.cpp:353] Iteration 51500 (64.0442 iter/s, 1.56142s/100 iter), loss = 0.000356192
I0801 13:43:49.186936  3162 solver.cpp:375]     Train net output #0: loss = 0.000356328 (* 1 = 0.000356328 loss)
I0801 13:43:49.186954  3162 sgd_solver.cpp:136] Iteration 51500, lr = 0.00195312, m = 0.9
I0801 13:43:50.773639  3162 solver.cpp:353] Iteration 51600 (63.0233 iter/s, 1.58672s/100 iter), loss = 0.000493204
I0801 13:43:50.773663  3162 solver.cpp:375]     Train net output #0: loss = 0.000493341 (* 1 = 0.000493341 loss)
I0801 13:43:50.773669  3162 sgd_solver.cpp:136] Iteration 51600, lr = 0.0019375, m = 0.9
I0801 13:43:52.337167  3162 solver.cpp:353] Iteration 51700 (63.96 iter/s, 1.56348s/100 iter), loss = 0.00111509
I0801 13:43:52.337191  3162 solver.cpp:375]     Train net output #0: loss = 0.00111522 (* 1 = 0.00111522 loss)
I0801 13:43:52.337198  3162 sgd_solver.cpp:136] Iteration 51700, lr = 0.00192187, m = 0.9
I0801 13:43:53.999502  3162 solver.cpp:353] Iteration 51800 (60.1581 iter/s, 1.66229s/100 iter), loss = 0.00095207
I0801 13:43:53.999763  3162 solver.cpp:375]     Train net output #0: loss = 0.000952208 (* 1 = 0.000952208 loss)
I0801 13:43:53.999771  3162 sgd_solver.cpp:136] Iteration 51800, lr = 0.00190625, m = 0.9
I0801 13:43:55.620753  3162 solver.cpp:353] Iteration 51900 (61.6828 iter/s, 1.6212s/100 iter), loss = 0.000142626
I0801 13:43:55.620833  3162 solver.cpp:375]     Train net output #0: loss = 0.000142763 (* 1 = 0.000142763 loss)
I0801 13:43:55.620857  3162 sgd_solver.cpp:136] Iteration 51900, lr = 0.00189062, m = 0.9
I0801 13:43:57.297513  3162 solver.cpp:550] Iteration 52000, Testing net (#0)
I0801 13:43:58.067265  3160 data_reader.cpp:264] Starting prefetch of epoch 7
I0801 13:43:58.180057  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.907354
I0801 13:43:58.180074  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996177
I0801 13:43:58.180079  3162 solver.cpp:635]     Test net output #2: loss = 0.340996 (* 1 = 0.340996 loss)
I0801 13:43:58.180099  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.882567s
I0801 13:43:58.195694  3162 solver.cpp:353] Iteration 52000 (38.8369 iter/s, 2.57487s/100 iter), loss = 0.000604304
I0801 13:43:58.195713  3162 solver.cpp:375]     Train net output #0: loss = 0.000604441 (* 1 = 0.000604441 loss)
I0801 13:43:58.195716  3162 sgd_solver.cpp:136] Iteration 52000, lr = 0.001875, m = 0.9
I0801 13:43:59.848172  3162 solver.cpp:353] Iteration 52100 (60.5171 iter/s, 1.65242s/100 iter), loss = 0.00056832
I0801 13:43:59.848201  3162 solver.cpp:375]     Train net output #0: loss = 0.000568455 (* 1 = 0.000568455 loss)
I0801 13:43:59.848207  3162 sgd_solver.cpp:136] Iteration 52100, lr = 0.00185938, m = 0.9
I0801 13:44:01.485837  3162 solver.cpp:353] Iteration 52200 (61.0645 iter/s, 1.63761s/100 iter), loss = 0.000400705
I0801 13:44:01.485863  3162 solver.cpp:375]     Train net output #0: loss = 0.000400841 (* 1 = 0.000400841 loss)
I0801 13:44:01.485868  3162 sgd_solver.cpp:136] Iteration 52200, lr = 0.00184375, m = 0.9
I0801 13:44:03.213965  3162 solver.cpp:353] Iteration 52300 (57.8678 iter/s, 1.72808s/100 iter), loss = 0.000682341
I0801 13:44:03.214069  3162 solver.cpp:375]     Train net output #0: loss = 0.000682476 (* 1 = 0.000682476 loss)
I0801 13:44:03.214085  3162 sgd_solver.cpp:136] Iteration 52300, lr = 0.00182813, m = 0.9
I0801 13:44:04.874238  3162 solver.cpp:353] Iteration 52400 (60.233 iter/s, 1.66022s/100 iter), loss = 0.000902179
I0801 13:44:04.874266  3162 solver.cpp:375]     Train net output #0: loss = 0.000902314 (* 1 = 0.000902314 loss)
I0801 13:44:04.874274  3162 sgd_solver.cpp:136] Iteration 52400, lr = 0.0018125, m = 0.9
I0801 13:44:06.473001  3162 solver.cpp:353] Iteration 52500 (62.5504 iter/s, 1.59871s/100 iter), loss = 0.000473948
I0801 13:44:06.473177  3162 solver.cpp:375]     Train net output #0: loss = 0.000474083 (* 1 = 0.000474083 loss)
I0801 13:44:06.473255  3162 sgd_solver.cpp:136] Iteration 52500, lr = 0.00179687, m = 0.9
I0801 13:44:08.066215  3162 solver.cpp:353] Iteration 52600 (62.7683 iter/s, 1.59316s/100 iter), loss = 0.00430296
I0801 13:44:08.066258  3162 solver.cpp:375]     Train net output #0: loss = 0.0043031 (* 1 = 0.0043031 loss)
I0801 13:44:08.066279  3162 sgd_solver.cpp:136] Iteration 52600, lr = 0.00178125, m = 0.9
I0801 13:44:09.782471  3162 solver.cpp:353] Iteration 52700 (58.2683 iter/s, 1.7162s/100 iter), loss = 0.000131277
I0801 13:44:09.782521  3162 solver.cpp:375]     Train net output #0: loss = 0.000131412 (* 1 = 0.000131412 loss)
I0801 13:44:09.782534  3162 sgd_solver.cpp:136] Iteration 52700, lr = 0.00176562, m = 0.9
I0801 13:44:11.558751  3162 solver.cpp:353] Iteration 52800 (56.2991 iter/s, 1.77623s/100 iter), loss = 0.000648517
I0801 13:44:11.558776  3162 solver.cpp:375]     Train net output #0: loss = 0.000648653 (* 1 = 0.000648653 loss)
I0801 13:44:11.558784  3162 sgd_solver.cpp:136] Iteration 52800, lr = 0.00175, m = 0.9
I0801 13:44:13.213408  3162 solver.cpp:353] Iteration 52900 (60.4374 iter/s, 1.6546s/100 iter), loss = 0.0005505
I0801 13:44:13.213439  3162 solver.cpp:375]     Train net output #0: loss = 0.000550636 (* 1 = 0.000550636 loss)
I0801 13:44:13.213448  3162 sgd_solver.cpp:136] Iteration 52900, lr = 0.00173437, m = 0.9
I0801 13:44:14.901338  3162 solver.cpp:550] Iteration 53000, Testing net (#0)
I0801 13:44:15.773753  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.915295
I0801 13:44:15.773773  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.995294
I0801 13:44:15.773778  3162 solver.cpp:635]     Test net output #2: loss = 0.323728 (* 1 = 0.323728 loss)
I0801 13:44:15.773795  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.872434s
I0801 13:44:15.789299  3162 solver.cpp:353] Iteration 53000 (38.8227 iter/s, 2.57581s/100 iter), loss = 0.00217085
I0801 13:44:15.789316  3162 solver.cpp:375]     Train net output #0: loss = 0.00217099 (* 1 = 0.00217099 loss)
I0801 13:44:15.789322  3162 sgd_solver.cpp:136] Iteration 53000, lr = 0.00171875, m = 0.9
I0801 13:44:17.404556  3162 solver.cpp:353] Iteration 53100 (61.9117 iter/s, 1.6152s/100 iter), loss = 0.00082083
I0801 13:44:17.404582  3162 solver.cpp:375]     Train net output #0: loss = 0.000820966 (* 1 = 0.000820966 loss)
I0801 13:44:17.404588  3162 sgd_solver.cpp:136] Iteration 53100, lr = 0.00170313, m = 0.9
I0801 13:44:19.072906  3162 solver.cpp:353] Iteration 53200 (59.9413 iter/s, 1.6683s/100 iter), loss = 0.000684126
I0801 13:44:19.072931  3162 solver.cpp:375]     Train net output #0: loss = 0.000684261 (* 1 = 0.000684261 loss)
I0801 13:44:19.072937  3162 sgd_solver.cpp:136] Iteration 53200, lr = 0.0016875, m = 0.9
I0801 13:44:20.735505  3162 solver.cpp:353] Iteration 53300 (60.1489 iter/s, 1.66254s/100 iter), loss = 0.00126845
I0801 13:44:20.735553  3162 solver.cpp:375]     Train net output #0: loss = 0.00126858 (* 1 = 0.00126858 loss)
I0801 13:44:20.735572  3162 sgd_solver.cpp:136] Iteration 53300, lr = 0.00167188, m = 0.9
I0801 13:44:22.364574  3162 solver.cpp:353] Iteration 53400 (61.3865 iter/s, 1.62902s/100 iter), loss = 0.000630443
I0801 13:44:22.364599  3162 solver.cpp:375]     Train net output #0: loss = 0.000630577 (* 1 = 0.000630577 loss)
I0801 13:44:22.364605  3162 sgd_solver.cpp:136] Iteration 53400, lr = 0.00165625, m = 0.9
I0801 13:44:24.079638  3162 solver.cpp:353] Iteration 53500 (58.3085 iter/s, 1.71501s/100 iter), loss = 0.00164472
I0801 13:44:24.079664  3162 solver.cpp:375]     Train net output #0: loss = 0.00164485 (* 1 = 0.00164485 loss)
I0801 13:44:24.079670  3162 sgd_solver.cpp:136] Iteration 53500, lr = 0.00164062, m = 0.9
I0801 13:44:25.716122  3162 solver.cpp:353] Iteration 53600 (61.1086 iter/s, 1.63643s/100 iter), loss = 0.000188614
I0801 13:44:25.716150  3162 solver.cpp:375]     Train net output #0: loss = 0.000188748 (* 1 = 0.000188748 loss)
I0801 13:44:25.716156  3162 sgd_solver.cpp:136] Iteration 53600, lr = 0.001625, m = 0.9
I0801 13:44:27.302887  3162 solver.cpp:353] Iteration 53700 (63.0233 iter/s, 1.58671s/100 iter), loss = 0.00104392
I0801 13:44:27.302928  3162 solver.cpp:375]     Train net output #0: loss = 0.00104406 (* 1 = 0.00104406 loss)
I0801 13:44:27.302935  3162 sgd_solver.cpp:136] Iteration 53700, lr = 0.00160937, m = 0.9
I0801 13:44:28.939327  3162 solver.cpp:353] Iteration 53800 (61.1102 iter/s, 1.63639s/100 iter), loss = 0.00145785
I0801 13:44:28.939354  3162 solver.cpp:375]     Train net output #0: loss = 0.00145799 (* 1 = 0.00145799 loss)
I0801 13:44:28.939360  3162 sgd_solver.cpp:136] Iteration 53800, lr = 0.00159375, m = 0.9
I0801 13:44:30.524838  3162 solver.cpp:353] Iteration 53900 (63.0731 iter/s, 1.58546s/100 iter), loss = 0.000961353
I0801 13:44:30.524878  3162 solver.cpp:375]     Train net output #0: loss = 0.000961489 (* 1 = 0.000961489 loss)
I0801 13:44:30.524890  3162 sgd_solver.cpp:136] Iteration 53900, lr = 0.00157812, m = 0.9
I0801 13:44:32.130167  3162 solver.cpp:550] Iteration 54000, Testing net (#0)
I0801 13:44:32.994294  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.918236
I0801 13:44:32.994323  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996471
I0801 13:44:32.994330  3162 solver.cpp:635]     Test net output #2: loss = 0.294463 (* 1 = 0.294463 loss)
I0801 13:44:32.994350  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.864159s
I0801 13:44:33.010334  3162 solver.cpp:353] Iteration 54000 (40.2347 iter/s, 2.48541s/100 iter), loss = 0.0011502
I0801 13:44:33.010386  3162 solver.cpp:375]     Train net output #0: loss = 0.00115034 (* 1 = 0.00115034 loss)
I0801 13:44:33.010403  3162 sgd_solver.cpp:136] Iteration 54000, lr = 0.0015625, m = 0.9
I0801 13:44:34.582283  3162 solver.cpp:353] Iteration 54100 (63.6172 iter/s, 1.5719s/100 iter), loss = 0.000455005
I0801 13:44:34.582360  3162 solver.cpp:375]     Train net output #0: loss = 0.000455141 (* 1 = 0.000455141 loss)
I0801 13:44:34.582365  3162 sgd_solver.cpp:136] Iteration 54100, lr = 0.00154688, m = 0.9
I0801 13:44:36.281616  3162 solver.cpp:353] Iteration 54200 (58.8485 iter/s, 1.69928s/100 iter), loss = 0.000608006
I0801 13:44:36.281662  3162 solver.cpp:375]     Train net output #0: loss = 0.000608143 (* 1 = 0.000608143 loss)
I0801 13:44:36.281683  3162 sgd_solver.cpp:136] Iteration 54200, lr = 0.00153125, m = 0.9
I0801 13:44:37.868492  3162 solver.cpp:353] Iteration 54300 (63.019 iter/s, 1.58682s/100 iter), loss = 0.000591646
I0801 13:44:37.868568  3162 solver.cpp:375]     Train net output #0: loss = 0.000591784 (* 1 = 0.000591784 loss)
I0801 13:44:37.868588  3162 sgd_solver.cpp:136] Iteration 54300, lr = 0.00151563, m = 0.9
I0801 13:44:39.550293  3162 solver.cpp:353] Iteration 54400 (59.4618 iter/s, 1.68175s/100 iter), loss = 0.00224078
I0801 13:44:39.550318  3162 solver.cpp:375]     Train net output #0: loss = 0.00224091 (* 1 = 0.00224091 loss)
I0801 13:44:39.550323  3162 sgd_solver.cpp:136] Iteration 54400, lr = 0.0015, m = 0.9
I0801 13:44:41.268268  3162 solver.cpp:353] Iteration 54500 (58.2098 iter/s, 1.71792s/100 iter), loss = 0.00114785
I0801 13:44:41.268331  3162 solver.cpp:375]     Train net output #0: loss = 0.00114799 (* 1 = 0.00114799 loss)
I0801 13:44:41.268349  3162 sgd_solver.cpp:136] Iteration 54500, lr = 0.00148437, m = 0.9
I0801 13:44:42.940306  3162 solver.cpp:353] Iteration 54600 (59.8095 iter/s, 1.67198s/100 iter), loss = 0.000524731
I0801 13:44:42.940536  3162 solver.cpp:375]     Train net output #0: loss = 0.000524868 (* 1 = 0.000524868 loss)
I0801 13:44:42.940670  3162 sgd_solver.cpp:136] Iteration 54600, lr = 0.00146875, m = 0.9
I0801 13:44:44.581524  3162 solver.cpp:353] Iteration 54700 (60.9322 iter/s, 1.64117s/100 iter), loss = 0.00238353
I0801 13:44:44.581547  3162 solver.cpp:375]     Train net output #0: loss = 0.00238367 (* 1 = 0.00238367 loss)
I0801 13:44:44.581552  3162 sgd_solver.cpp:136] Iteration 54700, lr = 0.00145312, m = 0.9
I0801 13:44:46.294838  3162 solver.cpp:353] Iteration 54800 (58.3682 iter/s, 1.71326s/100 iter), loss = 0.00382023
I0801 13:44:46.294864  3162 solver.cpp:375]     Train net output #0: loss = 0.00382036 (* 1 = 0.00382036 loss)
I0801 13:44:46.294870  3162 sgd_solver.cpp:136] Iteration 54800, lr = 0.0014375, m = 0.9
I0801 13:44:47.865986  3162 solver.cpp:353] Iteration 54900 (63.6496 iter/s, 1.5711s/100 iter), loss = 0.000898492
I0801 13:44:47.866013  3162 solver.cpp:375]     Train net output #0: loss = 0.00089863 (* 1 = 0.00089863 loss)
I0801 13:44:47.866019  3162 sgd_solver.cpp:136] Iteration 54900, lr = 0.00142187, m = 0.9
I0801 13:44:49.414680  3162 solver.cpp:550] Iteration 55000, Testing net (#0)
I0801 13:44:50.252034  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.91853
I0801 13:44:50.252053  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.995882
I0801 13:44:50.252058  3162 solver.cpp:635]     Test net output #2: loss = 0.286537 (* 1 = 0.286537 loss)
I0801 13:44:50.252074  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.837369s
I0801 13:44:50.267709  3162 solver.cpp:353] Iteration 55000 (41.638 iter/s, 2.40165s/100 iter), loss = 0.000916867
I0801 13:44:50.267724  3162 solver.cpp:375]     Train net output #0: loss = 0.000917004 (* 1 = 0.000917004 loss)
I0801 13:44:50.267729  3162 sgd_solver.cpp:136] Iteration 55000, lr = 0.00140625, m = 0.9
I0801 13:44:51.848708  3162 solver.cpp:353] Iteration 55100 (63.2533 iter/s, 1.58094s/100 iter), loss = 0.000842907
I0801 13:44:51.848739  3162 solver.cpp:375]     Train net output #0: loss = 0.000843044 (* 1 = 0.000843044 loss)
I0801 13:44:51.848747  3162 sgd_solver.cpp:136] Iteration 55100, lr = 0.00139063, m = 0.9
I0801 13:44:53.491247  3162 solver.cpp:353] Iteration 55200 (60.8832 iter/s, 1.64249s/100 iter), loss = 0.00148851
I0801 13:44:53.491317  3162 solver.cpp:375]     Train net output #0: loss = 0.00148865 (* 1 = 0.00148865 loss)
I0801 13:44:53.491338  3162 sgd_solver.cpp:136] Iteration 55200, lr = 0.001375, m = 0.9
I0801 13:44:55.176470  3162 solver.cpp:353] Iteration 55300 (59.3411 iter/s, 1.68517s/100 iter), loss = 0.000737463
I0801 13:44:55.176491  3162 solver.cpp:375]     Train net output #0: loss = 0.000737601 (* 1 = 0.000737601 loss)
I0801 13:44:55.176496  3162 sgd_solver.cpp:136] Iteration 55300, lr = 0.00135938, m = 0.9
I0801 13:44:56.768203  3162 solver.cpp:353] Iteration 55400 (62.8266 iter/s, 1.59168s/100 iter), loss = 0.000680306
I0801 13:44:56.768232  3162 solver.cpp:375]     Train net output #0: loss = 0.000680443 (* 1 = 0.000680443 loss)
I0801 13:44:56.768239  3162 sgd_solver.cpp:136] Iteration 55400, lr = 0.00134375, m = 0.9
I0801 13:44:58.328851  3162 solver.cpp:353] Iteration 55500 (64.078 iter/s, 1.5606s/100 iter), loss = 0.000894445
I0801 13:44:58.328876  3162 solver.cpp:375]     Train net output #0: loss = 0.000894582 (* 1 = 0.000894582 loss)
I0801 13:44:58.328881  3162 sgd_solver.cpp:136] Iteration 55500, lr = 0.00132813, m = 0.9
I0801 13:44:59.905804  3162 solver.cpp:353] Iteration 55600 (63.4154 iter/s, 1.5769s/100 iter), loss = 0.000544839
I0801 13:44:59.905831  3162 solver.cpp:375]     Train net output #0: loss = 0.000544976 (* 1 = 0.000544976 loss)
I0801 13:44:59.905836  3162 sgd_solver.cpp:136] Iteration 55600, lr = 0.0013125, m = 0.9
I0801 13:45:01.519470  3162 solver.cpp:353] Iteration 55700 (61.9726 iter/s, 1.61362s/100 iter), loss = 0.000429219
I0801 13:45:01.519533  3162 solver.cpp:375]     Train net output #0: loss = 0.000429356 (* 1 = 0.000429356 loss)
I0801 13:45:01.519551  3162 sgd_solver.cpp:136] Iteration 55700, lr = 0.00129687, m = 0.9
I0801 13:45:03.191597  3162 solver.cpp:353] Iteration 55800 (59.8059 iter/s, 1.67208s/100 iter), loss = 0.000715096
I0801 13:45:03.191622  3162 solver.cpp:375]     Train net output #0: loss = 0.000715233 (* 1 = 0.000715233 loss)
I0801 13:45:03.191627  3162 sgd_solver.cpp:136] Iteration 55800, lr = 0.00128125, m = 0.9
I0801 13:45:04.794059  3162 solver.cpp:353] Iteration 55900 (62.4065 iter/s, 1.6024s/100 iter), loss = 0.00147684
I0801 13:45:04.794431  3162 solver.cpp:375]     Train net output #0: loss = 0.00147698 (* 1 = 0.00147698 loss)
I0801 13:45:04.794453  3162 sgd_solver.cpp:136] Iteration 55900, lr = 0.00126562, m = 0.9
I0801 13:45:06.423166  3162 solver.cpp:550] Iteration 56000, Testing net (#0)
I0801 13:45:07.295747  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.919413
I0801 13:45:07.295766  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996765
I0801 13:45:07.295771  3162 solver.cpp:635]     Test net output #2: loss = 0.293835 (* 1 = 0.293835 loss)
I0801 13:45:07.295789  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.872598s
I0801 13:45:07.311409  3162 solver.cpp:353] Iteration 56000 (39.7254 iter/s, 2.51728s/100 iter), loss = 0.000102655
I0801 13:45:07.311427  3162 solver.cpp:375]     Train net output #0: loss = 0.000102793 (* 1 = 0.000102793 loss)
I0801 13:45:07.311431  3162 sgd_solver.cpp:136] Iteration 56000, lr = 0.00125, m = 0.9
I0801 13:45:08.213677  3155 data_reader.cpp:264] Starting prefetch of epoch 7
I0801 13:45:08.965605  3162 solver.cpp:353] Iteration 56100 (60.4543 iter/s, 1.65414s/100 iter), loss = 0.00221284
I0801 13:45:08.965628  3162 solver.cpp:375]     Train net output #0: loss = 0.00221297 (* 1 = 0.00221297 loss)
I0801 13:45:08.965632  3162 sgd_solver.cpp:136] Iteration 56100, lr = 0.00123438, m = 0.9
I0801 13:45:10.586272  3162 solver.cpp:353] Iteration 56200 (61.705 iter/s, 1.62061s/100 iter), loss = 0.000375064
I0801 13:45:10.586302  3162 solver.cpp:375]     Train net output #0: loss = 0.0003752 (* 1 = 0.0003752 loss)
I0801 13:45:10.586308  3162 sgd_solver.cpp:136] Iteration 56200, lr = 0.00121875, m = 0.9
I0801 13:45:12.174783  3162 solver.cpp:353] Iteration 56300 (62.9544 iter/s, 1.58845s/100 iter), loss = 0.000410269
I0801 13:45:12.174856  3162 solver.cpp:375]     Train net output #0: loss = 0.000410405 (* 1 = 0.000410405 loss)
I0801 13:45:12.174873  3162 sgd_solver.cpp:136] Iteration 56300, lr = 0.00120313, m = 0.9
I0801 13:45:13.841225  3162 solver.cpp:353] Iteration 56400 (60.0101 iter/s, 1.66639s/100 iter), loss = 0.00145035
I0801 13:45:13.841406  3162 solver.cpp:375]     Train net output #0: loss = 0.00145048 (* 1 = 0.00145048 loss)
I0801 13:45:13.841521  3162 sgd_solver.cpp:136] Iteration 56400, lr = 0.0011875, m = 0.9
I0801 13:45:15.520261  3162 solver.cpp:353] Iteration 56500 (59.5596 iter/s, 1.67899s/100 iter), loss = 0.00101778
I0801 13:45:15.520308  3162 solver.cpp:375]     Train net output #0: loss = 0.00101791 (* 1 = 0.00101791 loss)
I0801 13:45:15.520321  3162 sgd_solver.cpp:136] Iteration 56500, lr = 0.00117187, m = 0.9
I0801 13:45:17.164057  3162 solver.cpp:353] Iteration 56600 (60.8367 iter/s, 1.64375s/100 iter), loss = 0.000601969
I0801 13:45:17.164088  3162 solver.cpp:375]     Train net output #0: loss = 0.000602105 (* 1 = 0.000602105 loss)
I0801 13:45:17.164093  3162 sgd_solver.cpp:136] Iteration 56600, lr = 0.00115625, m = 0.9
I0801 13:45:18.760139  3162 solver.cpp:353] Iteration 56700 (62.6558 iter/s, 1.59602s/100 iter), loss = 0.00110084
I0801 13:45:18.760226  3162 solver.cpp:375]     Train net output #0: loss = 0.00110097 (* 1 = 0.00110097 loss)
I0801 13:45:18.760251  3162 sgd_solver.cpp:136] Iteration 56700, lr = 0.00114062, m = 0.9
I0801 13:45:20.463424  3162 solver.cpp:353] Iteration 56800 (58.7117 iter/s, 1.70324s/100 iter), loss = 0.000655694
I0801 13:45:20.463452  3162 solver.cpp:375]     Train net output #0: loss = 0.00065583 (* 1 = 0.00065583 loss)
I0801 13:45:20.463457  3162 sgd_solver.cpp:136] Iteration 56800, lr = 0.001125, m = 0.9
I0801 13:45:22.149739  3162 solver.cpp:353] Iteration 56900 (59.3033 iter/s, 1.68625s/100 iter), loss = 0.000568809
I0801 13:45:22.149818  3162 solver.cpp:375]     Train net output #0: loss = 0.000568945 (* 1 = 0.000568945 loss)
I0801 13:45:22.149840  3162 sgd_solver.cpp:136] Iteration 56900, lr = 0.00110937, m = 0.9
I0801 13:45:23.759310  3162 solver.cpp:550] Iteration 57000, Testing net (#0)
I0801 13:45:24.736634  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.91853
I0801 13:45:24.736655  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.997353
I0801 13:45:24.736680  3162 solver.cpp:635]     Test net output #2: loss = 0.304993 (* 1 = 0.304993 loss)
I0801 13:45:24.736696  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.97737s
I0801 13:45:24.752930  3162 solver.cpp:353] Iteration 57000 (38.4154 iter/s, 2.60313s/100 iter), loss = 0.00304667
I0801 13:45:24.752949  3162 solver.cpp:375]     Train net output #0: loss = 0.00304681 (* 1 = 0.00304681 loss)
I0801 13:45:24.752954  3162 sgd_solver.cpp:136] Iteration 57000, lr = 0.00109375, m = 0.9
I0801 13:45:26.336927  3162 solver.cpp:353] Iteration 57100 (63.1335 iter/s, 1.58395s/100 iter), loss = 0.00244975
I0801 13:45:26.336952  3162 solver.cpp:375]     Train net output #0: loss = 0.00244989 (* 1 = 0.00244989 loss)
I0801 13:45:26.336957  3162 sgd_solver.cpp:136] Iteration 57100, lr = 0.00107813, m = 0.9
I0801 13:45:28.054162  3162 solver.cpp:353] Iteration 57200 (58.2349 iter/s, 1.71718s/100 iter), loss = 0.00152488
I0801 13:45:28.054186  3162 solver.cpp:375]     Train net output #0: loss = 0.00152501 (* 1 = 0.00152501 loss)
I0801 13:45:28.054193  3162 sgd_solver.cpp:136] Iteration 57200, lr = 0.0010625, m = 0.9
I0801 13:45:29.770164  3162 solver.cpp:353] Iteration 57300 (58.2768 iter/s, 1.71595s/100 iter), loss = 0.00158709
I0801 13:45:29.770193  3162 solver.cpp:375]     Train net output #0: loss = 0.00158723 (* 1 = 0.00158723 loss)
I0801 13:45:29.770200  3162 sgd_solver.cpp:136] Iteration 57300, lr = 0.00104688, m = 0.9
I0801 13:45:31.414824  3162 solver.cpp:353] Iteration 57400 (60.8047 iter/s, 1.64461s/100 iter), loss = 0.00106836
I0801 13:45:31.414849  3162 solver.cpp:375]     Train net output #0: loss = 0.0010685 (* 1 = 0.0010685 loss)
I0801 13:45:31.414855  3162 sgd_solver.cpp:136] Iteration 57400, lr = 0.00103125, m = 0.9
I0801 13:45:33.045073  3162 solver.cpp:353] Iteration 57500 (61.3423 iter/s, 1.6302s/100 iter), loss = 0.000887686
I0801 13:45:33.045099  3162 solver.cpp:375]     Train net output #0: loss = 0.000887821 (* 1 = 0.000887821 loss)
I0801 13:45:33.045104  3162 sgd_solver.cpp:136] Iteration 57500, lr = 0.00101562, m = 0.9
I0801 13:45:34.608155  3162 solver.cpp:353] Iteration 57600 (63.9783 iter/s, 1.56303s/100 iter), loss = 0.00187435
I0801 13:45:34.608183  3162 solver.cpp:375]     Train net output #0: loss = 0.00187448 (* 1 = 0.00187448 loss)
I0801 13:45:34.608191  3162 sgd_solver.cpp:136] Iteration 57600, lr = 0.001, m = 0.9
I0801 13:45:36.311223  3162 solver.cpp:353] Iteration 57700 (58.7194 iter/s, 1.70302s/100 iter), loss = 0.000185922
I0801 13:45:36.311269  3162 solver.cpp:375]     Train net output #0: loss = 0.000186058 (* 1 = 0.000186058 loss)
I0801 13:45:36.311275  3162 sgd_solver.cpp:136] Iteration 57700, lr = 0.000984375, m = 0.9
I0801 13:45:37.978587  3162 solver.cpp:353] Iteration 57800 (59.9767 iter/s, 1.66731s/100 iter), loss = 0.000851888
I0801 13:45:37.978652  3162 solver.cpp:375]     Train net output #0: loss = 0.000852025 (* 1 = 0.000852025 loss)
I0801 13:45:37.978678  3162 sgd_solver.cpp:136] Iteration 57800, lr = 0.00096875, m = 0.9
I0801 13:45:39.602505  3162 solver.cpp:353] Iteration 57900 (61.5813 iter/s, 1.62387s/100 iter), loss = 0.00104307
I0801 13:45:39.602558  3162 solver.cpp:375]     Train net output #0: loss = 0.00104321 (* 1 = 0.00104321 loss)
I0801 13:45:39.602573  3162 sgd_solver.cpp:136] Iteration 57900, lr = 0.000953125, m = 0.9
I0801 13:45:41.174137  3162 solver.cpp:550] Iteration 58000, Testing net (#0)
I0801 13:45:42.032374  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.908236
I0801 13:45:42.032393  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.997059
I0801 13:45:42.032398  3162 solver.cpp:635]     Test net output #2: loss = 0.339138 (* 1 = 0.339138 loss)
I0801 13:45:42.032415  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.858263s
I0801 13:45:42.048105  3162 solver.cpp:353] Iteration 58000 (40.891 iter/s, 2.44553s/100 iter), loss = 0.00116856
I0801 13:45:42.048123  3162 solver.cpp:375]     Train net output #0: loss = 0.0011687 (* 1 = 0.0011687 loss)
I0801 13:45:42.048130  3162 sgd_solver.cpp:136] Iteration 58000, lr = 0.0009375, m = 0.9
I0801 13:45:43.688973  3162 solver.cpp:353] Iteration 58100 (60.9452 iter/s, 1.64082s/100 iter), loss = 0.00549615
I0801 13:45:43.688998  3162 solver.cpp:375]     Train net output #0: loss = 0.00549628 (* 1 = 0.00549628 loss)
I0801 13:45:43.689004  3162 sgd_solver.cpp:136] Iteration 58100, lr = 0.000921875, m = 0.9
I0801 13:45:45.364521  3162 solver.cpp:353] Iteration 58200 (59.6841 iter/s, 1.67549s/100 iter), loss = 0.00182245
I0801 13:45:45.364614  3162 solver.cpp:375]     Train net output #0: loss = 0.00182259 (* 1 = 0.00182259 loss)
I0801 13:45:45.364644  3162 sgd_solver.cpp:136] Iteration 58200, lr = 0.00090625, m = 0.9
I0801 13:45:47.048308  3162 solver.cpp:353] Iteration 58300 (59.3918 iter/s, 1.68373s/100 iter), loss = 0.000983475
I0801 13:45:47.048549  3162 solver.cpp:375]     Train net output #0: loss = 0.000983613 (* 1 = 0.000983613 loss)
I0801 13:45:47.048907  3162 sgd_solver.cpp:136] Iteration 58300, lr = 0.000890625, m = 0.9
I0801 13:45:48.637640  3162 solver.cpp:353] Iteration 58400 (62.9214 iter/s, 1.58928s/100 iter), loss = 0.000537124
I0801 13:45:48.637670  3162 solver.cpp:375]     Train net output #0: loss = 0.000537262 (* 1 = 0.000537262 loss)
I0801 13:45:48.637676  3162 sgd_solver.cpp:136] Iteration 58400, lr = 0.000875, m = 0.9
I0801 13:45:50.286171  3162 solver.cpp:353] Iteration 58500 (60.662 iter/s, 1.64848s/100 iter), loss = 0.00204948
I0801 13:45:50.286200  3162 solver.cpp:375]     Train net output #0: loss = 0.00204962 (* 1 = 0.00204962 loss)
I0801 13:45:50.286206  3162 sgd_solver.cpp:136] Iteration 58500, lr = 0.000859375, m = 0.9
I0801 13:45:51.982018  3162 solver.cpp:353] Iteration 58600 (58.9698 iter/s, 1.69578s/100 iter), loss = 0.000231225
I0801 13:45:51.982087  3162 solver.cpp:375]     Train net output #0: loss = 0.000231362 (* 1 = 0.000231362 loss)
I0801 13:45:51.982106  3162 sgd_solver.cpp:136] Iteration 58600, lr = 0.00084375, m = 0.9
I0801 13:45:53.676705  3162 solver.cpp:353] Iteration 58700 (59.0096 iter/s, 1.69464s/100 iter), loss = 0.000909585
I0801 13:45:53.676754  3162 solver.cpp:375]     Train net output #0: loss = 0.000909722 (* 1 = 0.000909722 loss)
I0801 13:45:53.676767  3162 sgd_solver.cpp:136] Iteration 58700, lr = 0.000828125, m = 0.9
I0801 13:45:55.394945  3162 solver.cpp:353] Iteration 58800 (58.201 iter/s, 1.71818s/100 iter), loss = 0.00287022
I0801 13:45:55.395040  3162 solver.cpp:375]     Train net output #0: loss = 0.00287036 (* 1 = 0.00287036 loss)
I0801 13:45:55.395063  3162 sgd_solver.cpp:136] Iteration 58800, lr = 0.0008125, m = 0.9
I0801 13:45:57.009697  3162 solver.cpp:353] Iteration 58900 (61.9309 iter/s, 1.6147s/100 iter), loss = 0.00160161
I0801 13:45:57.009724  3162 solver.cpp:375]     Train net output #0: loss = 0.00160175 (* 1 = 0.00160175 loss)
I0801 13:45:57.009730  3162 sgd_solver.cpp:136] Iteration 58900, lr = 0.000796875, m = 0.9
I0801 13:45:58.552067  3162 solver.cpp:550] Iteration 59000, Testing net (#0)
I0801 13:45:59.386802  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.907354
I0801 13:45:59.386822  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.997353
I0801 13:45:59.386828  3162 solver.cpp:635]     Test net output #2: loss = 0.338581 (* 1 = 0.338581 loss)
I0801 13:45:59.386847  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.834758s
I0801 13:45:59.402396  3162 solver.cpp:353] Iteration 59000 (41.795 iter/s, 2.39263s/100 iter), loss = 0.000933278
I0801 13:45:59.402415  3162 solver.cpp:375]     Train net output #0: loss = 0.000933416 (* 1 = 0.000933416 loss)
I0801 13:45:59.402420  3162 sgd_solver.cpp:136] Iteration 59000, lr = 0.00078125, m = 0.9
I0801 13:46:00.976445  3162 solver.cpp:353] Iteration 59100 (63.5325 iter/s, 1.574s/100 iter), loss = 0.000874505
I0801 13:46:00.976471  3162 solver.cpp:375]     Train net output #0: loss = 0.000874642 (* 1 = 0.000874642 loss)
I0801 13:46:00.976477  3162 sgd_solver.cpp:136] Iteration 59100, lr = 0.000765625, m = 0.9
I0801 13:46:02.593515  3162 solver.cpp:353] Iteration 59200 (61.8421 iter/s, 1.61702s/100 iter), loss = 0.00275622
I0801 13:46:02.593542  3162 solver.cpp:375]     Train net output #0: loss = 0.00275635 (* 1 = 0.00275635 loss)
I0801 13:46:02.593549  3162 sgd_solver.cpp:136] Iteration 59200, lr = 0.00075, m = 0.9
I0801 13:46:04.330885  3162 solver.cpp:353] Iteration 59300 (57.5601 iter/s, 1.73732s/100 iter), loss = 0.000464212
I0801 13:46:04.330965  3162 solver.cpp:375]     Train net output #0: loss = 0.000464348 (* 1 = 0.000464348 loss)
I0801 13:46:04.330988  3162 sgd_solver.cpp:136] Iteration 59300, lr = 0.000734375, m = 0.9
I0801 13:46:05.995328  3162 solver.cpp:353] Iteration 59400 (60.082 iter/s, 1.66439s/100 iter), loss = 0.00178427
I0801 13:46:05.995358  3162 solver.cpp:375]     Train net output #0: loss = 0.0017844 (* 1 = 0.0017844 loss)
I0801 13:46:05.995363  3162 sgd_solver.cpp:136] Iteration 59400, lr = 0.00071875, m = 0.9
I0801 13:46:07.582315  3162 solver.cpp:353] Iteration 59500 (63.0144 iter/s, 1.58694s/100 iter), loss = 0.000767793
I0801 13:46:07.582412  3162 solver.cpp:375]     Train net output #0: loss = 0.000767929 (* 1 = 0.000767929 loss)
I0801 13:46:07.582424  3162 sgd_solver.cpp:136] Iteration 59500, lr = 0.000703125, m = 0.9
I0801 13:46:09.154914  3162 solver.cpp:353] Iteration 59600 (63.5911 iter/s, 1.57255s/100 iter), loss = 0.0024679
I0801 13:46:09.154976  3162 solver.cpp:375]     Train net output #0: loss = 0.00246804 (* 1 = 0.00246804 loss)
I0801 13:46:09.154994  3162 sgd_solver.cpp:136] Iteration 59600, lr = 0.0006875, m = 0.9
I0801 13:46:10.723644  3162 solver.cpp:353] Iteration 59700 (63.7478 iter/s, 1.56868s/100 iter), loss = 0.00257634
I0801 13:46:10.723671  3162 solver.cpp:375]     Train net output #0: loss = 0.00257647 (* 1 = 0.00257647 loss)
I0801 13:46:10.723677  3162 sgd_solver.cpp:136] Iteration 59700, lr = 0.000671875, m = 0.9
I0801 13:46:12.304626  3162 solver.cpp:353] Iteration 59800 (63.2538 iter/s, 1.58093s/100 iter), loss = 0.0010244
I0801 13:46:12.304679  3162 solver.cpp:375]     Train net output #0: loss = 0.00102454 (* 1 = 0.00102454 loss)
I0801 13:46:12.304694  3162 sgd_solver.cpp:136] Iteration 59800, lr = 0.00065625, m = 0.9
I0801 13:46:13.868911  3162 solver.cpp:353] Iteration 59900 (63.929 iter/s, 1.56424s/100 iter), loss = 0.000952152
I0801 13:46:13.868937  3162 solver.cpp:375]     Train net output #0: loss = 0.000952286 (* 1 = 0.000952286 loss)
I0801 13:46:13.868942  3162 sgd_solver.cpp:136] Iteration 59900, lr = 0.000640625, m = 0.9
I0801 13:46:15.506772  3162 solver.cpp:680] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/l1reg/cifar10_jacintonet11v2_iter_60000.caffemodel
I0801 13:46:15.514756  3162 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/l1reg/cifar10_jacintonet11v2_iter_60000.solverstate
I0801 13:46:15.518360  3162 solver.cpp:550] Iteration 60000, Testing net (#0)
I0801 13:46:16.342375  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.905589
I0801 13:46:16.342396  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996471
I0801 13:46:16.342401  3162 solver.cpp:635]     Test net output #2: loss = 0.354346 (* 1 = 0.354346 loss)
I0801 13:46:16.342417  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.824032s
I0801 13:46:16.358114  3162 solver.cpp:353] Iteration 60000 (40.1747 iter/s, 2.48913s/100 iter), loss = 0.00204092
I0801 13:46:16.358130  3162 solver.cpp:375]     Train net output #0: loss = 0.00204105 (* 1 = 0.00204105 loss)
I0801 13:46:16.358134  3162 sgd_solver.cpp:136] Iteration 60000, lr = 0.000625, m = 0.9
I0801 13:46:18.068044  3162 solver.cpp:353] Iteration 60100 (58.4837 iter/s, 1.70988s/100 iter), loss = 0.000826949
I0801 13:46:18.068069  3162 solver.cpp:375]     Train net output #0: loss = 0.000827083 (* 1 = 0.000827083 loss)
I0801 13:46:18.068073  3162 sgd_solver.cpp:136] Iteration 60100, lr = 0.000609375, m = 0.9
I0801 13:46:19.704610  3162 solver.cpp:353] Iteration 60200 (61.1055 iter/s, 1.63651s/100 iter), loss = 0.00106044
I0801 13:46:19.704638  3162 solver.cpp:375]     Train net output #0: loss = 0.00106058 (* 1 = 0.00106058 loss)
I0801 13:46:19.704645  3162 sgd_solver.cpp:136] Iteration 60200, lr = 0.00059375, m = 0.9
I0801 13:46:21.354585  3162 solver.cpp:353] Iteration 60300 (60.6089 iter/s, 1.64992s/100 iter), loss = 0.000670495
I0801 13:46:21.354609  3162 solver.cpp:375]     Train net output #0: loss = 0.000670628 (* 1 = 0.000670628 loss)
I0801 13:46:21.354614  3162 sgd_solver.cpp:136] Iteration 60300, lr = 0.000578125, m = 0.9
I0801 13:46:22.947965  3162 solver.cpp:353] Iteration 60400 (62.7617 iter/s, 1.59333s/100 iter), loss = 0.000904247
I0801 13:46:22.947995  3162 solver.cpp:375]     Train net output #0: loss = 0.00090438 (* 1 = 0.00090438 loss)
I0801 13:46:22.948001  3162 sgd_solver.cpp:136] Iteration 60400, lr = 0.0005625, m = 0.9
I0801 13:46:24.582021  3162 solver.cpp:353] Iteration 60500 (61.1992 iter/s, 1.63401s/100 iter), loss = 0.00173767
I0801 13:46:24.582070  3162 solver.cpp:375]     Train net output #0: loss = 0.0017378 (* 1 = 0.0017378 loss)
I0801 13:46:24.582098  3162 sgd_solver.cpp:136] Iteration 60500, lr = 0.000546875, m = 0.9
I0801 13:46:26.278993  3162 solver.cpp:353] Iteration 60600 (58.9307 iter/s, 1.69691s/100 iter), loss = 0.00203452
I0801 13:46:26.279062  3162 solver.cpp:375]     Train net output #0: loss = 0.00203466 (* 1 = 0.00203466 loss)
I0801 13:46:26.279083  3162 sgd_solver.cpp:136] Iteration 60600, lr = 0.00053125, m = 0.9
I0801 13:46:26.326967  3155 data_reader.cpp:264] Starting prefetch of epoch 8
I0801 13:46:27.859788  3162 solver.cpp:353] Iteration 60700 (63.2613 iter/s, 1.58075s/100 iter), loss = 0.00102988
I0801 13:46:27.859840  3162 solver.cpp:375]     Train net output #0: loss = 0.00103001 (* 1 = 0.00103001 loss)
I0801 13:46:27.859851  3162 sgd_solver.cpp:136] Iteration 60700, lr = 0.000515625, m = 0.9
I0801 13:46:29.481102  3162 solver.cpp:353] Iteration 60800 (61.6802 iter/s, 1.62127s/100 iter), loss = 0.00137992
I0801 13:46:29.481127  3162 solver.cpp:375]     Train net output #0: loss = 0.00138005 (* 1 = 0.00138005 loss)
I0801 13:46:29.481132  3162 sgd_solver.cpp:136] Iteration 60800, lr = 0.0005, m = 0.9
I0801 13:46:31.118185  3162 solver.cpp:353] Iteration 60900 (61.0861 iter/s, 1.63703s/100 iter), loss = 0.000350291
I0801 13:46:31.118238  3162 solver.cpp:375]     Train net output #0: loss = 0.000350424 (* 1 = 0.000350424 loss)
I0801 13:46:31.118253  3162 sgd_solver.cpp:136] Iteration 60900, lr = 0.000484375, m = 0.9
I0801 13:46:32.707386  3162 solver.cpp:550] Iteration 61000, Testing net (#0)
I0801 13:46:33.586587  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.90353
I0801 13:46:33.586607  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.995882
I0801 13:46:33.586612  3162 solver.cpp:635]     Test net output #2: loss = 0.35269 (* 1 = 0.35269 loss)
I0801 13:46:33.586627  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.879216s
I0801 13:46:33.602342  3162 solver.cpp:353] Iteration 61000 (40.2563 iter/s, 2.48408s/100 iter), loss = 0.0020512
I0801 13:46:33.602360  3162 solver.cpp:375]     Train net output #0: loss = 0.00205133 (* 1 = 0.00205133 loss)
I0801 13:46:33.602365  3162 sgd_solver.cpp:136] Iteration 61000, lr = 0.00046875, m = 0.9
I0801 13:46:35.217396  3162 solver.cpp:353] Iteration 61100 (61.9196 iter/s, 1.615s/100 iter), loss = 0.000705706
I0801 13:46:35.217483  3162 solver.cpp:375]     Train net output #0: loss = 0.00070584 (* 1 = 0.00070584 loss)
I0801 13:46:35.217506  3162 sgd_solver.cpp:136] Iteration 61100, lr = 0.000453125, m = 0.9
I0801 13:46:36.889499  3162 solver.cpp:353] Iteration 61200 (59.8067 iter/s, 1.67205s/100 iter), loss = 0.00171059
I0801 13:46:36.889524  3162 solver.cpp:375]     Train net output #0: loss = 0.00171073 (* 1 = 0.00171073 loss)
I0801 13:46:36.889528  3162 sgd_solver.cpp:136] Iteration 61200, lr = 0.0004375, m = 0.9
I0801 13:46:38.569823  3162 solver.cpp:353] Iteration 61300 (59.5143 iter/s, 1.68027s/100 iter), loss = 0.00106814
I0801 13:46:38.569948  3162 solver.cpp:375]     Train net output #0: loss = 0.00106828 (* 1 = 0.00106828 loss)
I0801 13:46:38.569959  3162 sgd_solver.cpp:136] Iteration 61300, lr = 0.000421875, m = 0.9
I0801 13:46:40.226923  3162 solver.cpp:353] Iteration 61400 (60.3484 iter/s, 1.65705s/100 iter), loss = 0.00115873
I0801 13:46:40.226968  3162 solver.cpp:375]     Train net output #0: loss = 0.00115887 (* 1 = 0.00115887 loss)
I0801 13:46:40.226987  3162 sgd_solver.cpp:136] Iteration 61400, lr = 0.00040625, m = 0.9
I0801 13:46:41.934173  3162 solver.cpp:353] Iteration 61500 (58.5756 iter/s, 1.7072s/100 iter), loss = 0.00132242
I0801 13:46:41.934207  3162 solver.cpp:375]     Train net output #0: loss = 0.00132255 (* 1 = 0.00132255 loss)
I0801 13:46:41.934214  3162 sgd_solver.cpp:136] Iteration 61500, lr = 0.000390625, m = 0.9
I0801 13:46:43.534689  3162 solver.cpp:353] Iteration 61600 (62.4817 iter/s, 1.60047s/100 iter), loss = 0.00144664
I0801 13:46:43.534739  3162 solver.cpp:375]     Train net output #0: loss = 0.00144677 (* 1 = 0.00144677 loss)
I0801 13:46:43.534754  3162 sgd_solver.cpp:136] Iteration 61600, lr = 0.000375, m = 0.9
I0801 13:46:45.188684  3162 solver.cpp:353] Iteration 61700 (60.4616 iter/s, 1.65394s/100 iter), loss = 0.000623951
I0801 13:46:45.188742  3162 solver.cpp:375]     Train net output #0: loss = 0.000624085 (* 1 = 0.000624085 loss)
I0801 13:46:45.188758  3162 sgd_solver.cpp:136] Iteration 61700, lr = 0.000359375, m = 0.9
I0801 13:46:46.812023  3162 solver.cpp:353] Iteration 61800 (61.6038 iter/s, 1.62328s/100 iter), loss = 0.00077011
I0801 13:46:46.812119  3162 solver.cpp:375]     Train net output #0: loss = 0.000770244 (* 1 = 0.000770244 loss)
I0801 13:46:46.812146  3162 sgd_solver.cpp:136] Iteration 61800, lr = 0.00034375, m = 0.9
I0801 13:46:48.430866  3162 solver.cpp:353] Iteration 61900 (61.7741 iter/s, 1.6188s/100 iter), loss = 0.00180879
I0801 13:46:48.430891  3162 solver.cpp:375]     Train net output #0: loss = 0.00180893 (* 1 = 0.00180893 loss)
I0801 13:46:48.430894  3162 sgd_solver.cpp:136] Iteration 61900, lr = 0.000328125, m = 0.9
I0801 13:46:50.117517  3162 solver.cpp:550] Iteration 62000, Testing net (#0)
I0801 13:46:50.985618  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.903236
I0801 13:46:50.985641  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.995882
I0801 13:46:50.985646  3162 solver.cpp:635]     Test net output #2: loss = 0.366849 (* 1 = 0.366849 loss)
I0801 13:46:50.985662  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.868124s
I0801 13:46:51.001480  3162 solver.cpp:353] Iteration 62000 (38.9024 iter/s, 2.57054s/100 iter), loss = 0.000507733
I0801 13:46:51.001507  3162 solver.cpp:375]     Train net output #0: loss = 0.000507867 (* 1 = 0.000507867 loss)
I0801 13:46:51.001513  3162 sgd_solver.cpp:136] Iteration 62000, lr = 0.0003125, m = 0.9
I0801 13:46:52.584156  3162 solver.cpp:353] Iteration 62100 (63.1861 iter/s, 1.58263s/100 iter), loss = 0.000505252
I0801 13:46:52.584183  3162 solver.cpp:375]     Train net output #0: loss = 0.000505384 (* 1 = 0.000505384 loss)
I0801 13:46:52.584189  3162 sgd_solver.cpp:136] Iteration 62100, lr = 0.000296875, m = 0.9
I0801 13:46:54.307184  3162 solver.cpp:353] Iteration 62200 (58.0395 iter/s, 1.72297s/100 iter), loss = 0.00120934
I0801 13:46:54.307274  3162 solver.cpp:375]     Train net output #0: loss = 0.00120947 (* 1 = 0.00120947 loss)
I0801 13:46:54.307304  3162 sgd_solver.cpp:136] Iteration 62200, lr = 0.00028125, m = 0.9
I0801 13:46:56.010308  3162 solver.cpp:353] Iteration 62300 (58.7176 iter/s, 1.70307s/100 iter), loss = 0.00107623
I0801 13:46:56.010417  3162 solver.cpp:375]     Train net output #0: loss = 0.00107636 (* 1 = 0.00107636 loss)
I0801 13:46:56.010447  3162 sgd_solver.cpp:136] Iteration 62300, lr = 0.000265625, m = 0.9
I0801 13:46:57.636804  3162 solver.cpp:353] Iteration 62400 (61.4837 iter/s, 1.62645s/100 iter), loss = 0.000746316
I0801 13:46:57.636835  3162 solver.cpp:375]     Train net output #0: loss = 0.000746447 (* 1 = 0.000746447 loss)
I0801 13:46:57.636842  3162 sgd_solver.cpp:136] Iteration 62400, lr = 0.00025, m = 0.9
I0801 13:46:59.278522  3162 solver.cpp:353] Iteration 62500 (60.9137 iter/s, 1.64167s/100 iter), loss = 0.000474796
I0801 13:46:59.278547  3162 solver.cpp:375]     Train net output #0: loss = 0.000474927 (* 1 = 0.000474927 loss)
I0801 13:46:59.278550  3162 sgd_solver.cpp:136] Iteration 62500, lr = 0.000234375, m = 0.9
I0801 13:47:01.085181  3162 solver.cpp:353] Iteration 62600 (55.3525 iter/s, 1.8066s/100 iter), loss = 0.000650956
I0801 13:47:01.085207  3162 solver.cpp:375]     Train net output #0: loss = 0.000651087 (* 1 = 0.000651087 loss)
I0801 13:47:01.085213  3162 sgd_solver.cpp:136] Iteration 62600, lr = 0.00021875, m = 0.9
I0801 13:47:02.744630  3162 solver.cpp:353] Iteration 62700 (60.2627 iter/s, 1.6594s/100 iter), loss = 0.00149603
I0801 13:47:02.744657  3162 solver.cpp:375]     Train net output #0: loss = 0.00149616 (* 1 = 0.00149616 loss)
I0801 13:47:02.744664  3162 sgd_solver.cpp:136] Iteration 62700, lr = 0.000203125, m = 0.9
I0801 13:47:04.422838  3162 solver.cpp:353] Iteration 62800 (59.5893 iter/s, 1.67815s/100 iter), loss = 0.00229836
I0801 13:47:04.422889  3162 solver.cpp:375]     Train net output #0: loss = 0.00229849 (* 1 = 0.00229849 loss)
I0801 13:47:04.422904  3162 sgd_solver.cpp:136] Iteration 62800, lr = 0.0001875, m = 0.9
I0801 13:47:06.099673  3162 solver.cpp:353] Iteration 62900 (59.6381 iter/s, 1.67678s/100 iter), loss = 0.00161587
I0801 13:47:06.099699  3162 solver.cpp:375]     Train net output #0: loss = 0.001616 (* 1 = 0.001616 loss)
I0801 13:47:06.099704  3162 sgd_solver.cpp:136] Iteration 62900, lr = 0.000171875, m = 0.9
I0801 13:47:07.668948  3162 solver.cpp:550] Iteration 63000, Testing net (#0)
I0801 13:47:08.502861  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.90706
I0801 13:47:08.502881  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.995882
I0801 13:47:08.502887  3162 solver.cpp:635]     Test net output #2: loss = 0.358423 (* 1 = 0.358423 loss)
I0801 13:47:08.502904  3162 solver.cpp:305] [MultiGPU] Tests completed in 0.833932s
I0801 13:47:08.521960  3162 solver.cpp:353] Iteration 63000 (41.2845 iter/s, 2.42222s/100 iter), loss = 0.000912424
I0801 13:47:08.521978  3162 solver.cpp:375]     Train net output #0: loss = 0.000912556 (* 1 = 0.000912556 loss)
I0801 13:47:08.521983  3162 sgd_solver.cpp:136] Iteration 63000, lr = 0.00015625, m = 0.9
I0801 13:47:10.106366  3162 solver.cpp:353] Iteration 63100 (63.1171 iter/s, 1.58436s/100 iter), loss = 0.00114126
I0801 13:47:10.106429  3162 solver.cpp:375]     Train net output #0: loss = 0.00114139 (* 1 = 0.00114139 loss)
I0801 13:47:10.106439  3162 sgd_solver.cpp:136] Iteration 63100, lr = 0.000140625, m = 0.9
I0801 13:47:11.701206  3162 solver.cpp:353] Iteration 63200 (62.7042 iter/s, 1.59479s/100 iter), loss = 0.00169459
I0801 13:47:11.701231  3162 solver.cpp:375]     Train net output #0: loss = 0.00169472 (* 1 = 0.00169472 loss)
I0801 13:47:11.701237  3162 sgd_solver.cpp:136] Iteration 63200, lr = 0.000125, m = 0.9
I0801 13:47:13.289443  3162 solver.cpp:353] Iteration 63300 (62.9649 iter/s, 1.58819s/100 iter), loss = 0.00183363
I0801 13:47:13.289469  3162 solver.cpp:375]     Train net output #0: loss = 0.00183376 (* 1 = 0.00183376 loss)
I0801 13:47:13.289472  3162 sgd_solver.cpp:136] Iteration 63300, lr = 0.000109375, m = 0.9
I0801 13:47:14.932013  3162 solver.cpp:353] Iteration 63400 (60.882 iter/s, 1.64252s/100 iter), loss = 0.000551688
I0801 13:47:14.932065  3162 solver.cpp:375]     Train net output #0: loss = 0.000551818 (* 1 = 0.000551818 loss)
I0801 13:47:14.932080  3162 sgd_solver.cpp:136] Iteration 63400, lr = 9.37498e-05, m = 0.9
I0801 13:47:16.617338  3162 solver.cpp:353] Iteration 63500 (59.3376 iter/s, 1.68527s/100 iter), loss = 0.00110375
I0801 13:47:16.617388  3162 solver.cpp:375]     Train net output #0: loss = 0.00110388 (* 1 = 0.00110388 loss)
I0801 13:47:16.617403  3162 sgd_solver.cpp:136] Iteration 63500, lr = 7.8125e-05, m = 0.9
I0801 13:47:18.196970  3162 solver.cpp:353] Iteration 63600 (63.3078 iter/s, 1.57958s/100 iter), loss = 0.000320617
I0801 13:47:18.196995  3162 solver.cpp:375]     Train net output #0: loss = 0.000320749 (* 1 = 0.000320749 loss)
I0801 13:47:18.197001  3162 sgd_solver.cpp:136] Iteration 63600, lr = 6.25002e-05, m = 0.9
I0801 13:47:19.762063  3162 solver.cpp:353] Iteration 63700 (63.896 iter/s, 1.56504s/100 iter), loss = 0.00137995
I0801 13:47:19.762130  3162 solver.cpp:375]     Train net output #0: loss = 0.00138008 (* 1 = 0.00138008 loss)
I0801 13:47:19.762151  3162 sgd_solver.cpp:136] Iteration 63700, lr = 4.68749e-05, m = 0.9
I0801 13:47:21.324304  3162 solver.cpp:353] Iteration 63800 (64.0127 iter/s, 1.56219s/100 iter), loss = 0.00173982
I0801 13:47:21.324332  3162 solver.cpp:375]     Train net output #0: loss = 0.00173995 (* 1 = 0.00173995 loss)
I0801 13:47:21.324338  3162 sgd_solver.cpp:136] Iteration 63800, lr = 3.12501e-05, m = 0.9
I0801 13:47:22.892196  3162 solver.cpp:353] Iteration 63900 (63.7818 iter/s, 1.56784s/100 iter), loss = 0.000415953
I0801 13:47:22.892220  3162 solver.cpp:375]     Train net output #0: loss = 0.000416084 (* 1 = 0.000416084 loss)
I0801 13:47:22.892225  3162 sgd_solver.cpp:136] Iteration 63900, lr = 1.56248e-05, m = 0.9
I0801 13:47:24.514693  3162 solver.cpp:353] Iteration 63999 (61.0191 iter/s, 1.62244s/99 iter), loss = 0.000428463
I0801 13:47:24.514716  3162 solver.cpp:375]     Train net output #0: loss = 0.000428594 (* 1 = 0.000428594 loss)
I0801 13:47:24.514843  3162 solver.cpp:680] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/l1reg/cifar10_jacintonet11v2_iter_64000.caffemodel
I0801 13:47:24.522917  3162 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/l1reg/cifar10_jacintonet11v2_iter_64000.solverstate
I0801 13:47:24.531424  3162 solver.cpp:527] Iteration 64000, loss = 0.000431558
I0801 13:47:24.531445  3162 solver.cpp:550] Iteration 64000, Testing net (#0)
I0801 13:47:25.355577  3162 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.90853
I0801 13:47:25.355597  3162 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.995294
I0801 13:47:25.355602  3162 solver.cpp:635]     Test net output #2: loss = 0.347261 (* 1 = 0.347261 loss)
I0801 13:47:25.358602  3122 parallel.cpp:73] Root Solver performance on device 0: 58.8 * 22 = 1294 img/sec (64000 itr in 1088 sec)
I0801 13:47:25.358614  3122 parallel.cpp:78]      Solver performance on device 1: 58.8 * 22 = 1294 img/sec (64000 itr in 1088 sec)
I0801 13:47:25.358618  3122 parallel.cpp:78]      Solver performance on device 2: 58.8 * 22 = 1294 img/sec (64000 itr in 1088 sec)
I0801 13:47:25.358640  3122 parallel.cpp:81] Overall multi-GPU performance: 3880.74 img/sec
I0801 13:47:25.441818  3122 caffe.cpp:247] Optimization Done in 18m 12s
