I0801 13:11:30.970116 12832 caffe.cpp:608] This is NVCaffe 0.16.3 started at Tue Aug  1 13:11:30 2017
I0801 13:11:30.970247 12832 caffe.cpp:611] CuDNN version: 6021
I0801 13:11:30.970252 12832 caffe.cpp:612] CuBLAS version: 8000
I0801 13:11:30.970252 12832 caffe.cpp:613] CUDA version: 8000
I0801 13:11:30.970254 12832 caffe.cpp:614] CUDA driver version: 8000
I0801 13:11:31.235533 12832 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0801 13:11:31.236104 12832 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8278441984, dev_info[0]: total=8506769408 free=8278441984
I0801 13:11:31.236624 12832 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8278441984, dev_info[1]: total=8508145664 free=8379236352
I0801 13:11:31.237141 12832 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8278441984, dev_info[2]: total=8508145664 free=8379236352
I0801 13:11:31.237150 12832 caffe.cpp:208] Using GPUs 0, 1, 2
I0801 13:11:31.237471 12832 caffe.cpp:213] GPU 0: GeForce GTX 1080
I0801 13:11:31.237793 12832 caffe.cpp:213] GPU 1: GeForce GTX 1080
I0801 13:11:31.238114 12832 caffe.cpp:213] GPU 2: GeForce GTX 1080
I0801 13:11:31.238155 12832 solver.cpp:42] Solver data type: FLOAT
I0801 13:11:31.238185 12832 solver.cpp:45] Initializing solver from parameters: 
train_net: "training/cifar10_jacintonet11v2_2017-08-01_13-11-28/initial/train.prototxt"
test_net: "training/cifar10_jacintonet11v2_2017-08-01_13-11-28/initial/test.prototxt"
test_iter: 200
test_interval: 1000
base_lr: 0.1
display: 100
max_iter: 64000
lr_policy: "poly"
gamma: 0.1
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 10000
snapshot_prefix: "training/cifar10_jacintonet11v2_2017-08-01_13-11-28/initial/cifar10_jacintonet11v2"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
snapshot_after_train: true
test_initialization: true
iter_size: 1
type: "SGD"
I0801 13:11:31.245029 12832 solver.cpp:77] Creating training net from train_net file: training/cifar10_jacintonet11v2_2017-08-01_13-11-28/initial/train.prototxt
I0801 13:11:31.245455 12832 net.cpp:443] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top1
I0801 13:11:31.245462 12832 net.cpp:443] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top5
W0801 13:11:31.245486 12832 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 64 to 66
I0801 13:11:31.245671 12832 net.cpp:72] Initializing net from parameters: 
name: "jacintonet11v2_train"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: true
    crop_size: 32
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/cifar10_train_lmdb"
    batch_size: 22
    backend: LMDB
    threads: 1
    parser_threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc10"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc10"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
I0801 13:11:31.245775 12832 net.cpp:104] Using FLOAT as default forward math type
I0801 13:11:31.245782 12832 net.cpp:110] Using FLOAT as default backward math type
I0801 13:11:31.245786 12832 layer_factory.hpp:136] Creating layer 'data' of type 'Data'
I0801 13:11:31.245791 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.245833 12832 net.cpp:184] Created Layer data (0)
I0801 13:11:31.245839 12832 net.cpp:530] data -> data
I0801 13:11:31.245851 12832 net.cpp:530] data -> label
I0801 13:11:31.245874 12832 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 22
I0801 13:11:31.245890 12832 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0801 13:11:31.247082 12870 db_lmdb.cpp:35] Opened lmdb ./data/cifar10_train_lmdb
I0801 13:11:31.248091 12832 data_layer.cpp:184] [0] ReshapePrefetch 22, 3, 32, 32
I0801 13:11:31.248160 12832 data_layer.cpp:208] [0] Output data size: 22, 3, 32, 32
I0801 13:11:31.248167 12832 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0801 13:11:31.248188 12832 net.cpp:245] Setting up data
I0801 13:11:31.248198 12832 net.cpp:252] TRAIN Top shape for layer 0 'data' 22 3 32 32 (67584)
I0801 13:11:31.248208 12832 net.cpp:252] TRAIN Top shape for layer 0 'data' 22 (22)
I0801 13:11:31.248215 12832 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0801 13:11:31.248220 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.248232 12832 net.cpp:184] Created Layer data/bias (1)
I0801 13:11:31.248237 12832 net.cpp:561] data/bias <- data
I0801 13:11:31.248246 12832 net.cpp:530] data/bias -> data/bias
I0801 13:11:31.250210 12832 net.cpp:245] Setting up data/bias
I0801 13:11:31.250221 12832 net.cpp:252] TRAIN Top shape for layer 1 'data/bias' 22 3 32 32 (67584)
I0801 13:11:31.250231 12832 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0801 13:11:31.250236 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.250249 12832 net.cpp:184] Created Layer conv1a (2)
I0801 13:11:31.250254 12832 net.cpp:561] conv1a <- data/bias
I0801 13:11:31.250259 12832 net.cpp:530] conv1a -> conv1a
I0801 13:11:31.548847 12832 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.01G/1 1 0 0  (limit 8.15G, req 0G)
I0801 13:11:31.548869 12832 net.cpp:245] Setting up conv1a
I0801 13:11:31.548877 12832 net.cpp:252] TRAIN Top shape for layer 2 'conv1a' 22 32 32 32 (720896)
I0801 13:11:31.548888 12832 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0801 13:11:31.548894 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.548907 12832 net.cpp:184] Created Layer conv1a/bn (3)
I0801 13:11:31.548912 12832 net.cpp:561] conv1a/bn <- conv1a
I0801 13:11:31.548918 12832 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0801 13:11:31.549579 12832 net.cpp:245] Setting up conv1a/bn
I0801 13:11:31.549587 12832 net.cpp:252] TRAIN Top shape for layer 3 'conv1a/bn' 22 32 32 32 (720896)
I0801 13:11:31.549598 12832 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0801 13:11:31.549602 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.549610 12832 net.cpp:184] Created Layer conv1a/relu (4)
I0801 13:11:31.549614 12832 net.cpp:561] conv1a/relu <- conv1a
I0801 13:11:31.549618 12832 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0801 13:11:31.549633 12832 net.cpp:245] Setting up conv1a/relu
I0801 13:11:31.549638 12832 net.cpp:252] TRAIN Top shape for layer 4 'conv1a/relu' 22 32 32 32 (720896)
I0801 13:11:31.549643 12832 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0801 13:11:31.549646 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.549656 12832 net.cpp:184] Created Layer conv1b (5)
I0801 13:11:31.549660 12832 net.cpp:561] conv1b <- conv1a
I0801 13:11:31.549665 12832 net.cpp:530] conv1b -> conv1b
I0801 13:11:31.556358 12832 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 8.13G, req 0G)
I0801 13:11:31.556370 12832 net.cpp:245] Setting up conv1b
I0801 13:11:31.556378 12832 net.cpp:252] TRAIN Top shape for layer 5 'conv1b' 22 32 32 32 (720896)
I0801 13:11:31.556386 12832 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0801 13:11:31.556391 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.556399 12832 net.cpp:184] Created Layer conv1b/bn (6)
I0801 13:11:31.556403 12832 net.cpp:561] conv1b/bn <- conv1b
I0801 13:11:31.556416 12832 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0801 13:11:31.557029 12832 net.cpp:245] Setting up conv1b/bn
I0801 13:11:31.557037 12832 net.cpp:252] TRAIN Top shape for layer 6 'conv1b/bn' 22 32 32 32 (720896)
I0801 13:11:31.557046 12832 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0801 13:11:31.557050 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.557056 12832 net.cpp:184] Created Layer conv1b/relu (7)
I0801 13:11:31.557060 12832 net.cpp:561] conv1b/relu <- conv1b
I0801 13:11:31.557065 12832 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0801 13:11:31.557071 12832 net.cpp:245] Setting up conv1b/relu
I0801 13:11:31.557075 12832 net.cpp:252] TRAIN Top shape for layer 7 'conv1b/relu' 22 32 32 32 (720896)
I0801 13:11:31.557080 12832 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0801 13:11:31.557083 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.557091 12832 net.cpp:184] Created Layer pool1 (8)
I0801 13:11:31.557096 12832 net.cpp:561] pool1 <- conv1b
I0801 13:11:31.557099 12832 net.cpp:530] pool1 -> pool1
I0801 13:11:31.557173 12832 net.cpp:245] Setting up pool1
I0801 13:11:31.557178 12832 net.cpp:252] TRAIN Top shape for layer 8 'pool1' 22 32 32 32 (720896)
I0801 13:11:31.557183 12832 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0801 13:11:31.557188 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.557199 12832 net.cpp:184] Created Layer res2a_branch2a (9)
I0801 13:11:31.557204 12832 net.cpp:561] res2a_branch2a <- pool1
I0801 13:11:31.557209 12832 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0801 13:11:31.568933 12832 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 8.11G, req 0G)
I0801 13:11:31.568948 12832 net.cpp:245] Setting up res2a_branch2a
I0801 13:11:31.568954 12832 net.cpp:252] TRAIN Top shape for layer 9 'res2a_branch2a' 22 64 32 32 (1441792)
I0801 13:11:31.568964 12832 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0801 13:11:31.568969 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.568976 12832 net.cpp:184] Created Layer res2a_branch2a/bn (10)
I0801 13:11:31.568979 12832 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0801 13:11:31.568984 12832 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0801 13:11:31.569608 12832 net.cpp:245] Setting up res2a_branch2a/bn
I0801 13:11:31.569617 12832 net.cpp:252] TRAIN Top shape for layer 10 'res2a_branch2a/bn' 22 64 32 32 (1441792)
I0801 13:11:31.569627 12832 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0801 13:11:31.569630 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.569638 12832 net.cpp:184] Created Layer res2a_branch2a/relu (11)
I0801 13:11:31.569641 12832 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0801 13:11:31.569646 12832 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0801 13:11:31.569653 12832 net.cpp:245] Setting up res2a_branch2a/relu
I0801 13:11:31.569656 12832 net.cpp:252] TRAIN Top shape for layer 11 'res2a_branch2a/relu' 22 64 32 32 (1441792)
I0801 13:11:31.569661 12832 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0801 13:11:31.569666 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.569675 12832 net.cpp:184] Created Layer res2a_branch2b (12)
I0801 13:11:31.569679 12832 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0801 13:11:31.569684 12832 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0801 13:11:31.576776 12832 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 8.1G, req 0G)
I0801 13:11:31.576794 12832 net.cpp:245] Setting up res2a_branch2b
I0801 13:11:31.576829 12832 net.cpp:252] TRAIN Top shape for layer 12 'res2a_branch2b' 22 64 32 32 (1441792)
I0801 13:11:31.576840 12832 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0801 13:11:31.576854 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.576869 12832 net.cpp:184] Created Layer res2a_branch2b/bn (13)
I0801 13:11:31.576874 12832 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0801 13:11:31.576881 12832 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0801 13:11:31.577540 12832 net.cpp:245] Setting up res2a_branch2b/bn
I0801 13:11:31.577548 12832 net.cpp:252] TRAIN Top shape for layer 13 'res2a_branch2b/bn' 22 64 32 32 (1441792)
I0801 13:11:31.577558 12832 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0801 13:11:31.577561 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.577566 12832 net.cpp:184] Created Layer res2a_branch2b/relu (14)
I0801 13:11:31.577570 12832 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0801 13:11:31.577574 12832 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0801 13:11:31.577580 12832 net.cpp:245] Setting up res2a_branch2b/relu
I0801 13:11:31.577586 12832 net.cpp:252] TRAIN Top shape for layer 14 'res2a_branch2b/relu' 22 64 32 32 (1441792)
I0801 13:11:31.577590 12832 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0801 13:11:31.577594 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.577666 12832 net.cpp:184] Created Layer pool2 (15)
I0801 13:11:31.577672 12832 net.cpp:561] pool2 <- res2a_branch2b
I0801 13:11:31.577675 12832 net.cpp:530] pool2 -> pool2
I0801 13:11:31.577744 12832 net.cpp:245] Setting up pool2
I0801 13:11:31.577750 12832 net.cpp:252] TRAIN Top shape for layer 15 'pool2' 22 64 16 16 (360448)
I0801 13:11:31.577754 12832 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0801 13:11:31.577759 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.577769 12832 net.cpp:184] Created Layer res3a_branch2a (16)
I0801 13:11:31.577774 12832 net.cpp:561] res3a_branch2a <- pool2
I0801 13:11:31.577778 12832 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0801 13:11:31.590695 12832 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 8.09G, req 0.01G)
I0801 13:11:31.590711 12832 net.cpp:245] Setting up res3a_branch2a
I0801 13:11:31.590718 12832 net.cpp:252] TRAIN Top shape for layer 16 'res3a_branch2a' 22 128 16 16 (720896)
I0801 13:11:31.590728 12832 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0801 13:11:31.590732 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.590741 12832 net.cpp:184] Created Layer res3a_branch2a/bn (17)
I0801 13:11:31.590745 12832 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0801 13:11:31.590750 12832 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0801 13:11:31.591387 12832 net.cpp:245] Setting up res3a_branch2a/bn
I0801 13:11:31.591394 12832 net.cpp:252] TRAIN Top shape for layer 17 'res3a_branch2a/bn' 22 128 16 16 (720896)
I0801 13:11:31.591404 12832 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0801 13:11:31.591409 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.591414 12832 net.cpp:184] Created Layer res3a_branch2a/relu (18)
I0801 13:11:31.591419 12832 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0801 13:11:31.591423 12832 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0801 13:11:31.591429 12832 net.cpp:245] Setting up res3a_branch2a/relu
I0801 13:11:31.591434 12832 net.cpp:252] TRAIN Top shape for layer 18 'res3a_branch2a/relu' 22 128 16 16 (720896)
I0801 13:11:31.591439 12832 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0801 13:11:31.591451 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.591461 12832 net.cpp:184] Created Layer res3a_branch2b (19)
I0801 13:11:31.591465 12832 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0801 13:11:31.591470 12832 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0801 13:11:31.596166 12832 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 8.08G, req 0.01G)
I0801 13:11:31.596177 12832 net.cpp:245] Setting up res3a_branch2b
I0801 13:11:31.596184 12832 net.cpp:252] TRAIN Top shape for layer 19 'res3a_branch2b' 22 128 16 16 (720896)
I0801 13:11:31.596192 12832 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0801 13:11:31.596196 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.596204 12832 net.cpp:184] Created Layer res3a_branch2b/bn (20)
I0801 13:11:31.596209 12832 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0801 13:11:31.596212 12832 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0801 13:11:31.596845 12832 net.cpp:245] Setting up res3a_branch2b/bn
I0801 13:11:31.596854 12832 net.cpp:252] TRAIN Top shape for layer 20 'res3a_branch2b/bn' 22 128 16 16 (720896)
I0801 13:11:31.596863 12832 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0801 13:11:31.596866 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.596871 12832 net.cpp:184] Created Layer res3a_branch2b/relu (21)
I0801 13:11:31.596875 12832 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0801 13:11:31.596879 12832 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0801 13:11:31.596886 12832 net.cpp:245] Setting up res3a_branch2b/relu
I0801 13:11:31.596891 12832 net.cpp:252] TRAIN Top shape for layer 21 'res3a_branch2b/relu' 22 128 16 16 (720896)
I0801 13:11:31.596895 12832 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0801 13:11:31.596900 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.596906 12832 net.cpp:184] Created Layer pool3 (22)
I0801 13:11:31.596910 12832 net.cpp:561] pool3 <- res3a_branch2b
I0801 13:11:31.596915 12832 net.cpp:530] pool3 -> pool3
I0801 13:11:31.596981 12832 net.cpp:245] Setting up pool3
I0801 13:11:31.596987 12832 net.cpp:252] TRAIN Top shape for layer 22 'pool3' 22 128 16 16 (720896)
I0801 13:11:31.596990 12832 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0801 13:11:31.596995 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.597003 12832 net.cpp:184] Created Layer res4a_branch2a (23)
I0801 13:11:31.597007 12832 net.cpp:561] res4a_branch2a <- pool3
I0801 13:11:31.597012 12832 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0801 13:11:31.617228 12832 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 8.05G, req 0.01G)
I0801 13:11:31.617249 12832 net.cpp:245] Setting up res4a_branch2a
I0801 13:11:31.617256 12832 net.cpp:252] TRAIN Top shape for layer 23 'res4a_branch2a' 22 256 16 16 (1441792)
I0801 13:11:31.617266 12832 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0801 13:11:31.617271 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.617288 12832 net.cpp:184] Created Layer res4a_branch2a/bn (24)
I0801 13:11:31.617293 12832 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0801 13:11:31.617300 12832 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0801 13:11:31.618002 12832 net.cpp:245] Setting up res4a_branch2a/bn
I0801 13:11:31.618011 12832 net.cpp:252] TRAIN Top shape for layer 24 'res4a_branch2a/bn' 22 256 16 16 (1441792)
I0801 13:11:31.618021 12832 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0801 13:11:31.618032 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.618039 12832 net.cpp:184] Created Layer res4a_branch2a/relu (25)
I0801 13:11:31.618043 12832 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0801 13:11:31.618047 12832 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0801 13:11:31.618054 12832 net.cpp:245] Setting up res4a_branch2a/relu
I0801 13:11:31.618060 12832 net.cpp:252] TRAIN Top shape for layer 25 'res4a_branch2a/relu' 22 256 16 16 (1441792)
I0801 13:11:31.618064 12832 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0801 13:11:31.618069 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.618079 12832 net.cpp:184] Created Layer res4a_branch2b (26)
I0801 13:11:31.618083 12832 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0801 13:11:31.618088 12832 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0801 13:11:31.626850 12832 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 8.04G, req 0.01G)
I0801 13:11:31.626864 12832 net.cpp:245] Setting up res4a_branch2b
I0801 13:11:31.626871 12832 net.cpp:252] TRAIN Top shape for layer 26 'res4a_branch2b' 22 256 16 16 (1441792)
I0801 13:11:31.626879 12832 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0801 13:11:31.626883 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.626890 12832 net.cpp:184] Created Layer res4a_branch2b/bn (27)
I0801 13:11:31.626895 12832 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0801 13:11:31.626900 12832 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0801 13:11:31.627543 12832 net.cpp:245] Setting up res4a_branch2b/bn
I0801 13:11:31.627552 12832 net.cpp:252] TRAIN Top shape for layer 27 'res4a_branch2b/bn' 22 256 16 16 (1441792)
I0801 13:11:31.627559 12832 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0801 13:11:31.627563 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.627569 12832 net.cpp:184] Created Layer res4a_branch2b/relu (28)
I0801 13:11:31.627574 12832 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0801 13:11:31.627578 12832 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0801 13:11:31.627585 12832 net.cpp:245] Setting up res4a_branch2b/relu
I0801 13:11:31.627590 12832 net.cpp:252] TRAIN Top shape for layer 28 'res4a_branch2b/relu' 22 256 16 16 (1441792)
I0801 13:11:31.627594 12832 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0801 13:11:31.627599 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.627605 12832 net.cpp:184] Created Layer pool4 (29)
I0801 13:11:31.627609 12832 net.cpp:561] pool4 <- res4a_branch2b
I0801 13:11:31.627614 12832 net.cpp:530] pool4 -> pool4
I0801 13:11:31.627682 12832 net.cpp:245] Setting up pool4
I0801 13:11:31.627688 12832 net.cpp:252] TRAIN Top shape for layer 29 'pool4' 22 256 8 8 (360448)
I0801 13:11:31.627693 12832 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0801 13:11:31.627697 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.627710 12832 net.cpp:184] Created Layer res5a_branch2a (30)
I0801 13:11:31.627714 12832 net.cpp:561] res5a_branch2a <- pool4
I0801 13:11:31.627718 12832 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0801 13:11:31.670059 12832 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 1  (limit 8.02G, req 0.01G)
I0801 13:11:31.670094 12832 net.cpp:245] Setting up res5a_branch2a
I0801 13:11:31.670101 12832 net.cpp:252] TRAIN Top shape for layer 30 'res5a_branch2a' 22 512 8 8 (720896)
I0801 13:11:31.670114 12832 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0801 13:11:31.670120 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.670147 12832 net.cpp:184] Created Layer res5a_branch2a/bn (31)
I0801 13:11:31.670152 12832 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0801 13:11:31.670157 12832 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0801 13:11:31.670994 12832 net.cpp:245] Setting up res5a_branch2a/bn
I0801 13:11:31.671007 12832 net.cpp:252] TRAIN Top shape for layer 31 'res5a_branch2a/bn' 22 512 8 8 (720896)
I0801 13:11:31.671015 12832 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0801 13:11:31.671018 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.671025 12832 net.cpp:184] Created Layer res5a_branch2a/relu (32)
I0801 13:11:31.671030 12832 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0801 13:11:31.671032 12832 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0801 13:11:31.671036 12832 net.cpp:245] Setting up res5a_branch2a/relu
I0801 13:11:31.671041 12832 net.cpp:252] TRAIN Top shape for layer 32 'res5a_branch2a/relu' 22 512 8 8 (720896)
I0801 13:11:31.671042 12832 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0801 13:11:31.671046 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.671058 12832 net.cpp:184] Created Layer res5a_branch2b (33)
I0801 13:11:31.671061 12832 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0801 13:11:31.671064 12832 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0801 13:11:31.691817 12832 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 5  (limit 8G, req 0.01G)
I0801 13:11:31.691834 12832 net.cpp:245] Setting up res5a_branch2b
I0801 13:11:31.691840 12832 net.cpp:252] TRAIN Top shape for layer 33 'res5a_branch2b' 22 512 8 8 (720896)
I0801 13:11:31.691851 12832 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0801 13:11:31.691855 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.691869 12832 net.cpp:184] Created Layer res5a_branch2b/bn (34)
I0801 13:11:31.691872 12832 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0801 13:11:31.691875 12832 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0801 13:11:31.692595 12832 net.cpp:245] Setting up res5a_branch2b/bn
I0801 13:11:31.692605 12832 net.cpp:252] TRAIN Top shape for layer 34 'res5a_branch2b/bn' 22 512 8 8 (720896)
I0801 13:11:31.692610 12832 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0801 13:11:31.692615 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.692620 12832 net.cpp:184] Created Layer res5a_branch2b/relu (35)
I0801 13:11:31.692622 12832 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0801 13:11:31.692625 12832 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0801 13:11:31.692631 12832 net.cpp:245] Setting up res5a_branch2b/relu
I0801 13:11:31.692633 12832 net.cpp:252] TRAIN Top shape for layer 35 'res5a_branch2b/relu' 22 512 8 8 (720896)
I0801 13:11:31.692636 12832 layer_factory.hpp:136] Creating layer 'pool5' of type 'Pooling'
I0801 13:11:31.692639 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.692646 12832 net.cpp:184] Created Layer pool5 (36)
I0801 13:11:31.692651 12832 net.cpp:561] pool5 <- res5a_branch2b
I0801 13:11:31.692654 12832 net.cpp:530] pool5 -> pool5
I0801 13:11:31.692684 12832 net.cpp:245] Setting up pool5
I0801 13:11:31.692690 12832 net.cpp:252] TRAIN Top shape for layer 36 'pool5' 22 512 1 1 (11264)
I0801 13:11:31.692694 12832 layer_factory.hpp:136] Creating layer 'fc10' of type 'InnerProduct'
I0801 13:11:31.692699 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.692708 12832 net.cpp:184] Created Layer fc10 (37)
I0801 13:11:31.692711 12832 net.cpp:561] fc10 <- pool5
I0801 13:11:31.692715 12832 net.cpp:530] fc10 -> fc10
I0801 13:11:31.693017 12832 net.cpp:245] Setting up fc10
I0801 13:11:31.693027 12832 net.cpp:252] TRAIN Top shape for layer 37 'fc10' 22 10 (220)
I0801 13:11:31.693033 12832 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0801 13:11:31.693037 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.693049 12832 net.cpp:184] Created Layer loss (38)
I0801 13:11:31.693053 12832 net.cpp:561] loss <- fc10
I0801 13:11:31.693058 12832 net.cpp:561] loss <- label
I0801 13:11:31.693064 12832 net.cpp:530] loss -> loss
I0801 13:11:31.693236 12832 net.cpp:245] Setting up loss
I0801 13:11:31.693244 12832 net.cpp:252] TRAIN Top shape for layer 38 'loss' (1)
I0801 13:11:31.693248 12832 net.cpp:256]     with loss weight 1
I0801 13:11:31.693255 12832 net.cpp:323] loss needs backward computation.
I0801 13:11:31.693260 12832 net.cpp:323] fc10 needs backward computation.
I0801 13:11:31.693264 12832 net.cpp:323] pool5 needs backward computation.
I0801 13:11:31.693267 12832 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0801 13:11:31.693271 12832 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0801 13:11:31.693275 12832 net.cpp:323] res5a_branch2b needs backward computation.
I0801 13:11:31.693280 12832 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0801 13:11:31.693284 12832 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0801 13:11:31.693287 12832 net.cpp:323] res5a_branch2a needs backward computation.
I0801 13:11:31.693292 12832 net.cpp:323] pool4 needs backward computation.
I0801 13:11:31.693296 12832 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0801 13:11:31.693300 12832 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0801 13:11:31.693305 12832 net.cpp:323] res4a_branch2b needs backward computation.
I0801 13:11:31.693310 12832 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0801 13:11:31.693313 12832 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0801 13:11:31.693317 12832 net.cpp:323] res4a_branch2a needs backward computation.
I0801 13:11:31.693320 12832 net.cpp:323] pool3 needs backward computation.
I0801 13:11:31.693325 12832 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0801 13:11:31.693328 12832 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0801 13:11:31.693331 12832 net.cpp:323] res3a_branch2b needs backward computation.
I0801 13:11:31.693336 12832 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0801 13:11:31.693338 12832 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0801 13:11:31.693342 12832 net.cpp:323] res3a_branch2a needs backward computation.
I0801 13:11:31.693346 12832 net.cpp:323] pool2 needs backward computation.
I0801 13:11:31.693352 12832 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0801 13:11:31.693356 12832 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0801 13:11:31.693361 12832 net.cpp:323] res2a_branch2b needs backward computation.
I0801 13:11:31.693364 12832 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0801 13:11:31.693368 12832 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0801 13:11:31.693372 12832 net.cpp:323] res2a_branch2a needs backward computation.
I0801 13:11:31.693377 12832 net.cpp:323] pool1 needs backward computation.
I0801 13:11:31.693382 12832 net.cpp:323] conv1b/relu needs backward computation.
I0801 13:11:31.693385 12832 net.cpp:323] conv1b/bn needs backward computation.
I0801 13:11:31.693389 12832 net.cpp:323] conv1b needs backward computation.
I0801 13:11:31.693393 12832 net.cpp:323] conv1a/relu needs backward computation.
I0801 13:11:31.693397 12832 net.cpp:323] conv1a/bn needs backward computation.
I0801 13:11:31.693401 12832 net.cpp:323] conv1a needs backward computation.
I0801 13:11:31.693405 12832 net.cpp:325] data/bias does not need backward computation.
I0801 13:11:31.693410 12832 net.cpp:325] data does not need backward computation.
I0801 13:11:31.693414 12832 net.cpp:367] This network produces output loss
I0801 13:11:31.693452 12832 net.cpp:389] Top memory (TRAIN) required for data: 121110528 diff: 121110536
I0801 13:11:31.693456 12832 net.cpp:392] Bottom memory (TRAIN) required for data: 121110528 diff: 121110528
I0801 13:11:31.693460 12832 net.cpp:395] Shared (in-place) memory (TRAIN) by data: 80740352 diff: 80740352
I0801 13:11:31.693464 12832 net.cpp:398] Parameters memory (TRAIN) required for data: 9450960 diff: 9450960
I0801 13:11:31.693469 12832 net.cpp:401] Parameters shared memory (TRAIN) by data: 0 diff: 0
I0801 13:11:31.693472 12832 net.cpp:407] Network initialization done.
I0801 13:11:31.693838 12832 solver.cpp:176] Creating test net (#0) specified by test_net file: training/cifar10_jacintonet11v2_2017-08-01_13-11-28/initial/test.prototxt
W0801 13:11:31.693897 12832 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 50 to 51
I0801 13:11:31.694025 12832 net.cpp:72] Initializing net from parameters: 
name: "jacintonet11v2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: false
    crop_size: 32
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/cifar10_test_lmdb"
    batch_size: 17
    backend: LMDB
    threads: 1
    parser_threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc10"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc10"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "fc10"
  bottom: "label"
  top: "accuracy/top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "fc10"
  bottom: "label"
  top: "accuracy/top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0801 13:11:31.694119 12832 net.cpp:104] Using FLOAT as default forward math type
I0801 13:11:31.694124 12832 net.cpp:110] Using FLOAT as default backward math type
I0801 13:11:31.694128 12832 layer_factory.hpp:136] Creating layer 'data' of type 'Data'
I0801 13:11:31.694133 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.694145 12832 net.cpp:184] Created Layer data (0)
I0801 13:11:31.694149 12832 net.cpp:530] data -> data
I0801 13:11:31.694154 12832 net.cpp:530] data -> label
I0801 13:11:31.694164 12832 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 17
I0801 13:11:31.694170 12832 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0801 13:11:31.697546 12893 db_lmdb.cpp:35] Opened lmdb ./data/cifar10_test_lmdb
I0801 13:11:31.697643 12832 data_layer.cpp:184] (0) ReshapePrefetch 17, 3, 32, 32
I0801 13:11:31.697721 12832 data_layer.cpp:208] (0) Output data size: 17, 3, 32, 32
I0801 13:11:31.697726 12832 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0801 13:11:31.697741 12832 net.cpp:245] Setting up data
I0801 13:11:31.697746 12832 net.cpp:252] TEST Top shape for layer 0 'data' 17 3 32 32 (52224)
I0801 13:11:31.697749 12832 net.cpp:252] TEST Top shape for layer 0 'data' 17 (17)
I0801 13:11:31.697752 12832 layer_factory.hpp:136] Creating layer 'label_data_1_split' of type 'Split'
I0801 13:11:31.697755 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.697760 12832 net.cpp:184] Created Layer label_data_1_split (1)
I0801 13:11:31.697762 12832 net.cpp:561] label_data_1_split <- label
I0801 13:11:31.697765 12832 net.cpp:530] label_data_1_split -> label_data_1_split_0
I0801 13:11:31.697775 12832 net.cpp:530] label_data_1_split -> label_data_1_split_1
I0801 13:11:31.697778 12832 net.cpp:530] label_data_1_split -> label_data_1_split_2
I0801 13:11:31.697846 12832 net.cpp:245] Setting up label_data_1_split
I0801 13:11:31.697851 12832 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 17 (17)
I0801 13:11:31.697854 12832 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 17 (17)
I0801 13:11:31.697857 12832 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 17 (17)
I0801 13:11:31.697860 12832 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0801 13:11:31.697863 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.697868 12832 net.cpp:184] Created Layer data/bias (2)
I0801 13:11:31.697871 12832 net.cpp:561] data/bias <- data
I0801 13:11:31.697875 12832 net.cpp:530] data/bias -> data/bias
I0801 13:11:31.698026 12832 net.cpp:245] Setting up data/bias
I0801 13:11:31.698034 12832 net.cpp:252] TEST Top shape for layer 2 'data/bias' 17 3 32 32 (52224)
I0801 13:11:31.698040 12832 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0801 13:11:31.698042 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.698051 12832 net.cpp:184] Created Layer conv1a (3)
I0801 13:11:31.698055 12832 net.cpp:561] conv1a <- data/bias
I0801 13:11:31.698057 12832 net.cpp:530] conv1a -> conv1a
I0801 13:11:31.698526 12894 data_layer.cpp:97] (0) Parser threads: 1
I0801 13:11:31.698535 12894 data_layer.cpp:99] (0) Transformer threads: 1
I0801 13:11:31.701913 12832 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 8G, req 0.01G)
I0801 13:11:31.701933 12832 net.cpp:245] Setting up conv1a
I0801 13:11:31.701941 12832 net.cpp:252] TEST Top shape for layer 3 'conv1a' 17 32 32 32 (557056)
I0801 13:11:31.701951 12832 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0801 13:11:31.701957 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.701968 12832 net.cpp:184] Created Layer conv1a/bn (4)
I0801 13:11:31.701973 12832 net.cpp:561] conv1a/bn <- conv1a
I0801 13:11:31.701977 12832 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0801 13:11:31.702977 12832 net.cpp:245] Setting up conv1a/bn
I0801 13:11:31.702991 12832 net.cpp:252] TEST Top shape for layer 4 'conv1a/bn' 17 32 32 32 (557056)
I0801 13:11:31.703004 12832 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0801 13:11:31.703011 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.703017 12832 net.cpp:184] Created Layer conv1a/relu (5)
I0801 13:11:31.703023 12832 net.cpp:561] conv1a/relu <- conv1a
I0801 13:11:31.703028 12832 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0801 13:11:31.703035 12832 net.cpp:245] Setting up conv1a/relu
I0801 13:11:31.703042 12832 net.cpp:252] TEST Top shape for layer 5 'conv1a/relu' 17 32 32 32 (557056)
I0801 13:11:31.703045 12832 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0801 13:11:31.703049 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.703066 12832 net.cpp:184] Created Layer conv1b (6)
I0801 13:11:31.703073 12832 net.cpp:561] conv1b <- conv1a
I0801 13:11:31.703076 12832 net.cpp:530] conv1b -> conv1b
I0801 13:11:31.706704 12832 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'conv1b' with space 0.02G/2 1  (limit 8G, req 0.01G)
I0801 13:11:31.706717 12832 net.cpp:245] Setting up conv1b
I0801 13:11:31.706722 12832 net.cpp:252] TEST Top shape for layer 6 'conv1b' 17 32 32 32 (557056)
I0801 13:11:31.706729 12832 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0801 13:11:31.706733 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.706740 12832 net.cpp:184] Created Layer conv1b/bn (7)
I0801 13:11:31.706753 12832 net.cpp:561] conv1b/bn <- conv1b
I0801 13:11:31.706759 12832 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0801 13:11:31.707458 12832 net.cpp:245] Setting up conv1b/bn
I0801 13:11:31.707465 12832 net.cpp:252] TEST Top shape for layer 7 'conv1b/bn' 17 32 32 32 (557056)
I0801 13:11:31.707471 12832 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0801 13:11:31.707475 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.707480 12832 net.cpp:184] Created Layer conv1b/relu (8)
I0801 13:11:31.707484 12832 net.cpp:561] conv1b/relu <- conv1b
I0801 13:11:31.707486 12832 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0801 13:11:31.707490 12832 net.cpp:245] Setting up conv1b/relu
I0801 13:11:31.707494 12832 net.cpp:252] TEST Top shape for layer 8 'conv1b/relu' 17 32 32 32 (557056)
I0801 13:11:31.707496 12832 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0801 13:11:31.707501 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.707509 12832 net.cpp:184] Created Layer pool1 (9)
I0801 13:11:31.707512 12832 net.cpp:561] pool1 <- conv1b
I0801 13:11:31.707515 12832 net.cpp:530] pool1 -> pool1
I0801 13:11:31.707586 12832 net.cpp:245] Setting up pool1
I0801 13:11:31.707590 12832 net.cpp:252] TEST Top shape for layer 9 'pool1' 17 32 32 32 (557056)
I0801 13:11:31.707593 12832 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0801 13:11:31.707598 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.707612 12832 net.cpp:184] Created Layer res2a_branch2a (10)
I0801 13:11:31.707615 12832 net.cpp:561] res2a_branch2a <- pool1
I0801 13:11:31.707618 12832 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0801 13:11:31.711448 12832 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.99G, req 0.01G)
I0801 13:11:31.711458 12832 net.cpp:245] Setting up res2a_branch2a
I0801 13:11:31.711462 12832 net.cpp:252] TEST Top shape for layer 10 'res2a_branch2a' 17 64 32 32 (1114112)
I0801 13:11:31.711468 12832 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0801 13:11:31.711472 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.711477 12832 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0801 13:11:31.711479 12832 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0801 13:11:31.711482 12832 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0801 13:11:31.712173 12832 net.cpp:245] Setting up res2a_branch2a/bn
I0801 13:11:31.712182 12832 net.cpp:252] TEST Top shape for layer 11 'res2a_branch2a/bn' 17 64 32 32 (1114112)
I0801 13:11:31.712186 12832 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0801 13:11:31.712190 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.712194 12832 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0801 13:11:31.712198 12832 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0801 13:11:31.712199 12832 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0801 13:11:31.712205 12832 net.cpp:245] Setting up res2a_branch2a/relu
I0801 13:11:31.712209 12832 net.cpp:252] TEST Top shape for layer 12 'res2a_branch2a/relu' 17 64 32 32 (1114112)
I0801 13:11:31.712213 12832 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0801 13:11:31.712215 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.712225 12832 net.cpp:184] Created Layer res2a_branch2b (13)
I0801 13:11:31.712229 12832 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0801 13:11:31.712232 12832 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0801 13:11:31.715647 12832 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.98G, req 0.01G)
I0801 13:11:31.715661 12832 net.cpp:245] Setting up res2a_branch2b
I0801 13:11:31.715675 12832 net.cpp:252] TEST Top shape for layer 13 'res2a_branch2b' 17 64 32 32 (1114112)
I0801 13:11:31.715682 12832 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0801 13:11:31.715684 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.715690 12832 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0801 13:11:31.715693 12832 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0801 13:11:31.715698 12832 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0801 13:11:31.716403 12832 net.cpp:245] Setting up res2a_branch2b/bn
I0801 13:11:31.716411 12832 net.cpp:252] TEST Top shape for layer 14 'res2a_branch2b/bn' 17 64 32 32 (1114112)
I0801 13:11:31.716418 12832 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0801 13:11:31.716419 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.716423 12832 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0801 13:11:31.716425 12832 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0801 13:11:31.716428 12832 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0801 13:11:31.716433 12832 net.cpp:245] Setting up res2a_branch2b/relu
I0801 13:11:31.716434 12832 net.cpp:252] TEST Top shape for layer 15 'res2a_branch2b/relu' 17 64 32 32 (1114112)
I0801 13:11:31.716437 12832 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0801 13:11:31.716439 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.716444 12832 net.cpp:184] Created Layer pool2 (16)
I0801 13:11:31.716446 12832 net.cpp:561] pool2 <- res2a_branch2b
I0801 13:11:31.716449 12832 net.cpp:530] pool2 -> pool2
I0801 13:11:31.716511 12832 net.cpp:245] Setting up pool2
I0801 13:11:31.716516 12832 net.cpp:252] TEST Top shape for layer 16 'pool2' 17 64 16 16 (278528)
I0801 13:11:31.716518 12832 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0801 13:11:31.716521 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.716528 12832 net.cpp:184] Created Layer res3a_branch2a (17)
I0801 13:11:31.716531 12832 net.cpp:561] res3a_branch2a <- pool2
I0801 13:11:31.716533 12832 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0801 13:11:31.722843 12832 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.97G, req 0.01G)
I0801 13:11:31.722862 12832 net.cpp:245] Setting up res3a_branch2a
I0801 13:11:31.722867 12832 net.cpp:252] TEST Top shape for layer 17 'res3a_branch2a' 17 128 16 16 (557056)
I0801 13:11:31.722874 12832 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0801 13:11:31.722878 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.722885 12832 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0801 13:11:31.722888 12832 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0801 13:11:31.722892 12832 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0801 13:11:31.723605 12832 net.cpp:245] Setting up res3a_branch2a/bn
I0801 13:11:31.723613 12832 net.cpp:252] TEST Top shape for layer 18 'res3a_branch2a/bn' 17 128 16 16 (557056)
I0801 13:11:31.723620 12832 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0801 13:11:31.723623 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.723628 12832 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0801 13:11:31.723630 12832 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0801 13:11:31.723633 12832 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0801 13:11:31.723636 12832 net.cpp:245] Setting up res3a_branch2a/relu
I0801 13:11:31.723639 12832 net.cpp:252] TEST Top shape for layer 19 'res3a_branch2a/relu' 17 128 16 16 (557056)
I0801 13:11:31.723640 12832 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0801 13:11:31.723652 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.723661 12832 net.cpp:184] Created Layer res3a_branch2b (20)
I0801 13:11:31.723664 12832 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0801 13:11:31.723666 12832 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0801 13:11:31.727133 12832 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.97G, req 0.01G)
I0801 13:11:31.727144 12832 net.cpp:245] Setting up res3a_branch2b
I0801 13:11:31.727149 12832 net.cpp:252] TEST Top shape for layer 20 'res3a_branch2b' 17 128 16 16 (557056)
I0801 13:11:31.727154 12832 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0801 13:11:31.727157 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.727166 12832 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0801 13:11:31.727169 12832 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0801 13:11:31.727172 12832 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0801 13:11:31.727954 12832 net.cpp:245] Setting up res3a_branch2b/bn
I0801 13:11:31.727963 12832 net.cpp:252] TEST Top shape for layer 21 'res3a_branch2b/bn' 17 128 16 16 (557056)
I0801 13:11:31.727969 12832 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0801 13:11:31.727972 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.727975 12832 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0801 13:11:31.727978 12832 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0801 13:11:31.727980 12832 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0801 13:11:31.727983 12832 net.cpp:245] Setting up res3a_branch2b/relu
I0801 13:11:31.727987 12832 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b/relu' 17 128 16 16 (557056)
I0801 13:11:31.727989 12832 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0801 13:11:31.727991 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.727995 12832 net.cpp:184] Created Layer pool3 (23)
I0801 13:11:31.727998 12832 net.cpp:561] pool3 <- res3a_branch2b
I0801 13:11:31.728000 12832 net.cpp:530] pool3 -> pool3
I0801 13:11:31.728065 12832 net.cpp:245] Setting up pool3
I0801 13:11:31.728070 12832 net.cpp:252] TEST Top shape for layer 23 'pool3' 17 128 16 16 (557056)
I0801 13:11:31.728072 12832 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0801 13:11:31.728075 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.728091 12832 net.cpp:184] Created Layer res4a_branch2a (24)
I0801 13:11:31.728096 12832 net.cpp:561] res4a_branch2a <- pool3
I0801 13:11:31.728097 12832 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0801 13:11:31.739334 12832 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.96G, req 0.01G)
I0801 13:11:31.739351 12832 net.cpp:245] Setting up res4a_branch2a
I0801 13:11:31.739357 12832 net.cpp:252] TEST Top shape for layer 24 'res4a_branch2a' 17 256 16 16 (1114112)
I0801 13:11:31.739365 12832 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0801 13:11:31.739368 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.739377 12832 net.cpp:184] Created Layer res4a_branch2a/bn (25)
I0801 13:11:31.739380 12832 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0801 13:11:31.739384 12832 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0801 13:11:31.740125 12832 net.cpp:245] Setting up res4a_branch2a/bn
I0801 13:11:31.740134 12832 net.cpp:252] TEST Top shape for layer 25 'res4a_branch2a/bn' 17 256 16 16 (1114112)
I0801 13:11:31.740139 12832 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0801 13:11:31.740142 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.740154 12832 net.cpp:184] Created Layer res4a_branch2a/relu (26)
I0801 13:11:31.740157 12832 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0801 13:11:31.740160 12832 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0801 13:11:31.740164 12832 net.cpp:245] Setting up res4a_branch2a/relu
I0801 13:11:31.740167 12832 net.cpp:252] TEST Top shape for layer 26 'res4a_branch2a/relu' 17 256 16 16 (1114112)
I0801 13:11:31.740170 12832 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0801 13:11:31.740173 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.740180 12832 net.cpp:184] Created Layer res4a_branch2b (27)
I0801 13:11:31.740183 12832 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0801 13:11:31.740186 12832 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0801 13:11:31.745883 12832 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.95G, req 0.01G)
I0801 13:11:31.745898 12832 net.cpp:245] Setting up res4a_branch2b
I0801 13:11:31.745903 12832 net.cpp:252] TEST Top shape for layer 27 'res4a_branch2b' 17 256 16 16 (1114112)
I0801 13:11:31.745908 12832 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0801 13:11:31.745913 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.745919 12832 net.cpp:184] Created Layer res4a_branch2b/bn (28)
I0801 13:11:31.745923 12832 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0801 13:11:31.745925 12832 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0801 13:11:31.746639 12832 net.cpp:245] Setting up res4a_branch2b/bn
I0801 13:11:31.746646 12832 net.cpp:252] TEST Top shape for layer 28 'res4a_branch2b/bn' 17 256 16 16 (1114112)
I0801 13:11:31.746652 12832 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0801 13:11:31.746655 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.746659 12832 net.cpp:184] Created Layer res4a_branch2b/relu (29)
I0801 13:11:31.746661 12832 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0801 13:11:31.746664 12832 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0801 13:11:31.746667 12832 net.cpp:245] Setting up res4a_branch2b/relu
I0801 13:11:31.746670 12832 net.cpp:252] TEST Top shape for layer 29 'res4a_branch2b/relu' 17 256 16 16 (1114112)
I0801 13:11:31.746671 12832 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0801 13:11:31.746675 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.746677 12832 net.cpp:184] Created Layer pool4 (30)
I0801 13:11:31.746681 12832 net.cpp:561] pool4 <- res4a_branch2b
I0801 13:11:31.746685 12832 net.cpp:530] pool4 -> pool4
I0801 13:11:31.746752 12832 net.cpp:245] Setting up pool4
I0801 13:11:31.746757 12832 net.cpp:252] TEST Top shape for layer 30 'pool4' 17 256 8 8 (278528)
I0801 13:11:31.746759 12832 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0801 13:11:31.746762 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.746768 12832 net.cpp:184] Created Layer res5a_branch2a (31)
I0801 13:11:31.746772 12832 net.cpp:561] res5a_branch2a <- pool4
I0801 13:11:31.746773 12832 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0801 13:11:31.778327 12832 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.94G, req 0.01G)
I0801 13:11:31.778345 12832 net.cpp:245] Setting up res5a_branch2a
I0801 13:11:31.778352 12832 net.cpp:252] TEST Top shape for layer 31 'res5a_branch2a' 17 512 8 8 (557056)
I0801 13:11:31.778358 12832 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0801 13:11:31.778362 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.778385 12832 net.cpp:184] Created Layer res5a_branch2a/bn (32)
I0801 13:11:31.778388 12832 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0801 13:11:31.778393 12832 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0801 13:11:31.779140 12832 net.cpp:245] Setting up res5a_branch2a/bn
I0801 13:11:31.779148 12832 net.cpp:252] TEST Top shape for layer 32 'res5a_branch2a/bn' 17 512 8 8 (557056)
I0801 13:11:31.779155 12832 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0801 13:11:31.779158 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.779162 12832 net.cpp:184] Created Layer res5a_branch2a/relu (33)
I0801 13:11:31.779165 12832 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0801 13:11:31.779166 12832 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0801 13:11:31.779170 12832 net.cpp:245] Setting up res5a_branch2a/relu
I0801 13:11:31.779173 12832 net.cpp:252] TEST Top shape for layer 33 'res5a_branch2a/relu' 17 512 8 8 (557056)
I0801 13:11:31.779175 12832 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0801 13:11:31.779177 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.779184 12832 net.cpp:184] Created Layer res5a_branch2b (34)
I0801 13:11:31.779187 12832 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0801 13:11:31.779189 12832 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0801 13:11:31.796063 12832 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.93G, req 0.01G)
I0801 13:11:31.796080 12832 net.cpp:245] Setting up res5a_branch2b
I0801 13:11:31.796087 12832 net.cpp:252] TEST Top shape for layer 34 'res5a_branch2b' 17 512 8 8 (557056)
I0801 13:11:31.796097 12832 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0801 13:11:31.796100 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.796108 12832 net.cpp:184] Created Layer res5a_branch2b/bn (35)
I0801 13:11:31.796111 12832 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0801 13:11:31.796114 12832 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0801 13:11:31.796846 12832 net.cpp:245] Setting up res5a_branch2b/bn
I0801 13:11:31.796854 12832 net.cpp:252] TEST Top shape for layer 35 'res5a_branch2b/bn' 17 512 8 8 (557056)
I0801 13:11:31.796860 12832 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0801 13:11:31.796864 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.796932 12832 net.cpp:184] Created Layer res5a_branch2b/relu (36)
I0801 13:11:31.796937 12832 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0801 13:11:31.796941 12832 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0801 13:11:31.796944 12832 net.cpp:245] Setting up res5a_branch2b/relu
I0801 13:11:31.796947 12832 net.cpp:252] TEST Top shape for layer 36 'res5a_branch2b/relu' 17 512 8 8 (557056)
I0801 13:11:31.796950 12832 layer_factory.hpp:136] Creating layer 'pool5' of type 'Pooling'
I0801 13:11:31.796953 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.796962 12832 net.cpp:184] Created Layer pool5 (37)
I0801 13:11:31.796965 12832 net.cpp:561] pool5 <- res5a_branch2b
I0801 13:11:31.796968 12832 net.cpp:530] pool5 -> pool5
I0801 13:11:31.796999 12832 net.cpp:245] Setting up pool5
I0801 13:11:31.797004 12832 net.cpp:252] TEST Top shape for layer 37 'pool5' 17 512 1 1 (8704)
I0801 13:11:31.797008 12832 layer_factory.hpp:136] Creating layer 'fc10' of type 'InnerProduct'
I0801 13:11:31.797010 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.797014 12832 net.cpp:184] Created Layer fc10 (38)
I0801 13:11:31.797018 12832 net.cpp:561] fc10 <- pool5
I0801 13:11:31.797020 12832 net.cpp:530] fc10 -> fc10
I0801 13:11:31.797319 12832 net.cpp:245] Setting up fc10
I0801 13:11:31.797338 12832 net.cpp:252] TEST Top shape for layer 38 'fc10' 17 10 (170)
I0801 13:11:31.797343 12832 layer_factory.hpp:136] Creating layer 'fc10_fc10_0_split' of type 'Split'
I0801 13:11:31.797346 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.797350 12832 net.cpp:184] Created Layer fc10_fc10_0_split (39)
I0801 13:11:31.797353 12832 net.cpp:561] fc10_fc10_0_split <- fc10
I0801 13:11:31.797356 12832 net.cpp:530] fc10_fc10_0_split -> fc10_fc10_0_split_0
I0801 13:11:31.797359 12832 net.cpp:530] fc10_fc10_0_split -> fc10_fc10_0_split_1
I0801 13:11:31.797363 12832 net.cpp:530] fc10_fc10_0_split -> fc10_fc10_0_split_2
I0801 13:11:31.797441 12832 net.cpp:245] Setting up fc10_fc10_0_split
I0801 13:11:31.797446 12832 net.cpp:252] TEST Top shape for layer 39 'fc10_fc10_0_split' 17 10 (170)
I0801 13:11:31.797449 12832 net.cpp:252] TEST Top shape for layer 39 'fc10_fc10_0_split' 17 10 (170)
I0801 13:11:31.797452 12832 net.cpp:252] TEST Top shape for layer 39 'fc10_fc10_0_split' 17 10 (170)
I0801 13:11:31.797454 12832 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0801 13:11:31.797457 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.797466 12832 net.cpp:184] Created Layer loss (40)
I0801 13:11:31.797469 12832 net.cpp:561] loss <- fc10_fc10_0_split_0
I0801 13:11:31.797472 12832 net.cpp:561] loss <- label_data_1_split_0
I0801 13:11:31.797475 12832 net.cpp:530] loss -> loss
I0801 13:11:31.797632 12832 net.cpp:245] Setting up loss
I0801 13:11:31.797639 12832 net.cpp:252] TEST Top shape for layer 40 'loss' (1)
I0801 13:11:31.797641 12832 net.cpp:256]     with loss weight 1
I0801 13:11:31.797646 12832 layer_factory.hpp:136] Creating layer 'accuracy/top1' of type 'Accuracy'
I0801 13:11:31.797649 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.797657 12832 net.cpp:184] Created Layer accuracy/top1 (41)
I0801 13:11:31.797660 12832 net.cpp:561] accuracy/top1 <- fc10_fc10_0_split_1
I0801 13:11:31.797663 12832 net.cpp:561] accuracy/top1 <- label_data_1_split_1
I0801 13:11:31.797667 12832 net.cpp:530] accuracy/top1 -> accuracy/top1
I0801 13:11:31.797672 12832 net.cpp:245] Setting up accuracy/top1
I0801 13:11:31.797675 12832 net.cpp:252] TEST Top shape for layer 41 'accuracy/top1' (1)
I0801 13:11:31.797678 12832 layer_factory.hpp:136] Creating layer 'accuracy/top5' of type 'Accuracy'
I0801 13:11:31.797680 12832 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 13:11:31.797684 12832 net.cpp:184] Created Layer accuracy/top5 (42)
I0801 13:11:31.797686 12832 net.cpp:561] accuracy/top5 <- fc10_fc10_0_split_2
I0801 13:11:31.797689 12832 net.cpp:561] accuracy/top5 <- label_data_1_split_2
I0801 13:11:31.797693 12832 net.cpp:530] accuracy/top5 -> accuracy/top5
I0801 13:11:31.797695 12832 net.cpp:245] Setting up accuracy/top5
I0801 13:11:31.797699 12832 net.cpp:252] TEST Top shape for layer 42 'accuracy/top5' (1)
I0801 13:11:31.797703 12832 net.cpp:325] accuracy/top5 does not need backward computation.
I0801 13:11:31.797704 12832 net.cpp:325] accuracy/top1 does not need backward computation.
I0801 13:11:31.797708 12832 net.cpp:323] loss needs backward computation.
I0801 13:11:31.797709 12832 net.cpp:323] fc10_fc10_0_split needs backward computation.
I0801 13:11:31.797713 12832 net.cpp:323] fc10 needs backward computation.
I0801 13:11:31.797714 12832 net.cpp:323] pool5 needs backward computation.
I0801 13:11:31.797716 12832 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0801 13:11:31.797719 12832 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0801 13:11:31.797720 12832 net.cpp:323] res5a_branch2b needs backward computation.
I0801 13:11:31.797722 12832 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0801 13:11:31.797725 12832 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0801 13:11:31.797727 12832 net.cpp:323] res5a_branch2a needs backward computation.
I0801 13:11:31.797736 12832 net.cpp:323] pool4 needs backward computation.
I0801 13:11:31.797739 12832 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0801 13:11:31.797741 12832 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0801 13:11:31.797744 12832 net.cpp:323] res4a_branch2b needs backward computation.
I0801 13:11:31.797746 12832 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0801 13:11:31.797749 12832 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0801 13:11:31.797751 12832 net.cpp:323] res4a_branch2a needs backward computation.
I0801 13:11:31.797755 12832 net.cpp:323] pool3 needs backward computation.
I0801 13:11:31.797756 12832 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0801 13:11:31.797758 12832 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0801 13:11:31.797761 12832 net.cpp:323] res3a_branch2b needs backward computation.
I0801 13:11:31.797763 12832 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0801 13:11:31.797765 12832 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0801 13:11:31.797767 12832 net.cpp:323] res3a_branch2a needs backward computation.
I0801 13:11:31.797770 12832 net.cpp:323] pool2 needs backward computation.
I0801 13:11:31.797772 12832 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0801 13:11:31.797775 12832 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0801 13:11:31.797777 12832 net.cpp:323] res2a_branch2b needs backward computation.
I0801 13:11:31.797780 12832 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0801 13:11:31.797782 12832 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0801 13:11:31.797785 12832 net.cpp:323] res2a_branch2a needs backward computation.
I0801 13:11:31.797786 12832 net.cpp:323] pool1 needs backward computation.
I0801 13:11:31.797790 12832 net.cpp:323] conv1b/relu needs backward computation.
I0801 13:11:31.797791 12832 net.cpp:323] conv1b/bn needs backward computation.
I0801 13:11:31.797794 12832 net.cpp:323] conv1b needs backward computation.
I0801 13:11:31.797796 12832 net.cpp:323] conv1a/relu needs backward computation.
I0801 13:11:31.797799 12832 net.cpp:323] conv1a/bn needs backward computation.
I0801 13:11:31.797801 12832 net.cpp:323] conv1a needs backward computation.
I0801 13:11:31.797803 12832 net.cpp:325] data/bias does not need backward computation.
I0801 13:11:31.797807 12832 net.cpp:325] label_data_1_split does not need backward computation.
I0801 13:11:31.797809 12832 net.cpp:325] data does not need backward computation.
I0801 13:11:31.797812 12832 net.cpp:367] This network produces output accuracy/top1
I0801 13:11:31.797814 12832 net.cpp:367] This network produces output accuracy/top5
I0801 13:11:31.797816 12832 net.cpp:367] This network produces output loss
I0801 13:11:31.797850 12832 net.cpp:389] Top memory (TEST) required for data: 93585408 diff: 8
I0801 13:11:31.797853 12832 net.cpp:392] Bottom memory (TEST) required for data: 93585408 diff: 93585408
I0801 13:11:31.797855 12832 net.cpp:395] Shared (in-place) memory (TEST) by data: 62390272 diff: 62390272
I0801 13:11:31.797857 12832 net.cpp:398] Parameters memory (TEST) required for data: 9450960 diff: 9450960
I0801 13:11:31.797860 12832 net.cpp:401] Parameters shared memory (TEST) by data: 0 diff: 0
I0801 13:11:31.797863 12832 net.cpp:407] Network initialization done.
I0801 13:11:31.797917 12832 solver.cpp:56] Solver scaffolding done.
I0801 13:11:31.802109 12832 parallel.cpp:108] [0 - 0] P2pSync adding callback
I0801 13:11:31.802119 12832 parallel.cpp:108] [1 - 1] P2pSync adding callback
I0801 13:11:31.802121 12832 parallel.cpp:108] [2 - 2] P2pSync adding callback
I0801 13:11:31.802124 12832 parallel.cpp:61] Starting Optimization
I0801 13:11:31.802125 12832 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0801 13:11:31.802146 12832 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0801 13:11:31.802261 12832 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0801 13:11:31.802956 12903 device_alternate.hpp:116] NVML initialized on thread 140416049637120
I0801 13:11:31.815770 12903 common.cpp:583] NVML succeeded to set CPU affinity on device 0
I0801 13:11:31.815811 12904 device_alternate.hpp:116] NVML initialized on thread 140416041244416
I0801 13:11:31.816948 12904 common.cpp:583] NVML succeeded to set CPU affinity on device 1
I0801 13:11:31.816990 12905 device_alternate.hpp:116] NVML initialized on thread 140416032851712
I0801 13:11:31.817873 12905 common.cpp:583] NVML succeeded to set CPU affinity on device 2
I0801 13:11:31.822919 12904 solver.cpp:42] Solver data type: FLOAT
W0801 13:11:31.823340 12904 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 64 to 66
I0801 13:11:31.823459 12904 net.cpp:104] Using FLOAT as default forward math type
I0801 13:11:31.823467 12904 net.cpp:110] Using FLOAT as default backward math type
I0801 13:11:31.823494 12904 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 22
I0801 13:11:31.823501 12904 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0801 13:11:31.829360 12905 solver.cpp:42] Solver data type: FLOAT
W0801 13:11:31.830039 12905 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 64 to 66
I0801 13:11:31.830066 12906 db_lmdb.cpp:35] Opened lmdb ./data/cifar10_train_lmdb
I0801 13:11:31.830154 12905 net.cpp:104] Using FLOAT as default forward math type
I0801 13:11:31.830162 12905 net.cpp:110] Using FLOAT as default backward math type
I0801 13:11:31.830202 12905 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 22
I0801 13:11:31.830216 12905 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0801 13:11:31.831046 12907 db_lmdb.cpp:35] Opened lmdb ./data/cifar10_train_lmdb
I0801 13:11:31.831145 12904 data_layer.cpp:184] [1] ReshapePrefetch 22, 3, 32, 32
I0801 13:11:31.832110 12905 data_layer.cpp:184] [2] ReshapePrefetch 22, 3, 32, 32
I0801 13:11:31.832128 12904 data_layer.cpp:208] [1] Output data size: 22, 3, 32, 32
I0801 13:11:31.832135 12904 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0801 13:11:31.832247 12905 data_layer.cpp:208] [2] Output data size: 22, 3, 32, 32
I0801 13:11:31.832257 12905 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0801 13:11:32.255859 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.01G/1 1 0 3  (limit 8.25G, req 0G)
I0801 13:11:32.292644 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1a' with space 0.01G/1 1 0 3  (limit 8.25G, req 0G)
I0801 13:11:32.295126 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 8.23G, req 0G)
I0801 13:11:32.301831 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 8.23G, req 0G)
I0801 13:11:32.308153 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 8.21G, req 0G)
I0801 13:11:32.313410 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 8.21G, req 0G)
I0801 13:11:32.317062 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 8.19G, req 0G)
I0801 13:11:32.323158 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 8.19G, req 0G)
I0801 13:11:32.331441 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 8.18G, req 0.01G)
I0801 13:11:32.336865 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 8.18G, req 0.01G)
I0801 13:11:32.338165 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 8.17G, req 0.01G)
I0801 13:11:32.342612 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 8.17G, req 0.01G)
I0801 13:11:32.361412 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 8.15G, req 0.01G)
I0801 13:11:32.364269 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 3  (limit 8.15G, req 0.01G)
I0801 13:11:32.371371 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 8.14G, req 0.01G)
I0801 13:11:32.374678 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 8.14G, req 0.01G)
I0801 13:11:32.417062 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 1  (limit 8.11G, req 0.01G)
I0801 13:11:32.418705 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 1  (limit 8.11G, req 0.01G)
I0801 13:11:32.437849 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 5  (limit 8.1G, req 0.01G)
I0801 13:11:32.439458 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 5  (limit 8.1G, req 0.01G)
I0801 13:11:32.439640 12904 solver.cpp:176] Creating test net (#0) specified by test_net file: training/cifar10_jacintonet11v2_2017-08-01_13-11-28/initial/test.prototxt
W0801 13:11:32.439741 12904 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 50 to 51
I0801 13:11:32.439837 12904 net.cpp:104] Using FLOAT as default forward math type
I0801 13:11:32.439842 12904 net.cpp:110] Using FLOAT as default backward math type
I0801 13:11:32.439860 12904 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 17
I0801 13:11:32.439869 12904 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0801 13:11:32.441218 12905 solver.cpp:176] Creating test net (#0) specified by test_net file: training/cifar10_jacintonet11v2_2017-08-01_13-11-28/initial/test.prototxt
W0801 13:11:32.441288 12905 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 50 to 51
I0801 13:11:32.441395 12905 net.cpp:104] Using FLOAT as default forward math type
I0801 13:11:32.441401 12905 net.cpp:110] Using FLOAT as default backward math type
I0801 13:11:32.441416 12905 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 17
I0801 13:11:32.441423 12905 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0801 13:11:32.441540 12910 db_lmdb.cpp:35] Opened lmdb ./data/cifar10_test_lmdb
I0801 13:11:32.441623 12904 data_layer.cpp:184] (1) ReshapePrefetch 17, 3, 32, 32
I0801 13:11:32.441725 12904 data_layer.cpp:208] (1) Output data size: 17, 3, 32, 32
I0801 13:11:32.441730 12904 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0801 13:11:32.442180 12911 db_lmdb.cpp:35] Opened lmdb ./data/cifar10_test_lmdb
I0801 13:11:32.442291 12905 data_layer.cpp:184] (2) ReshapePrefetch 17, 3, 32, 32
I0801 13:11:32.442405 12905 data_layer.cpp:208] (2) Output data size: 17, 3, 32, 32
I0801 13:11:32.442410 12905 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0801 13:11:32.442888 12912 data_layer.cpp:97] (1) Parser threads: 1
I0801 13:11:32.442896 12912 data_layer.cpp:99] (1) Transformer threads: 1
I0801 13:11:32.443898 12913 data_layer.cpp:97] (2) Parser threads: 1
I0801 13:11:32.443907 12913 data_layer.cpp:99] (2) Transformer threads: 1
I0801 13:11:32.446748 12904 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 8.1G, req 0.01G)
I0801 13:11:32.447299 12905 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 8.1G, req 0.01G)
I0801 13:11:32.451643 12904 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'conv1b' with space 0.02G/2 1  (limit 8.09G, req 0.01G)
I0801 13:11:32.452172 12905 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'conv1b' with space 0.02G/2 1  (limit 8.09G, req 0.01G)
I0801 13:11:32.457224 12904 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 8.08G, req 0.01G)
I0801 13:11:32.458299 12905 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 8.08G, req 0.01G)
I0801 13:11:32.461889 12904 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 8.08G, req 0.01G)
I0801 13:11:32.463157 12905 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 8.08G, req 0.01G)
I0801 13:11:32.470088 12904 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 8.07G, req 0.01G)
I0801 13:11:32.471611 12905 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 8.07G, req 0.01G)
I0801 13:11:32.474647 12904 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 8.06G, req 0.01G)
I0801 13:11:32.476845 12905 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 8.06G, req 0.01G)
I0801 13:11:32.487634 12904 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 8.05G, req 0.01G)
I0801 13:11:32.489132 12905 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 8.05G, req 0.01G)
I0801 13:11:32.494931 12904 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 8.05G, req 0.01G)
I0801 13:11:32.495694 12905 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 8.05G, req 0.01G)
I0801 13:11:32.529136 12904 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 8.03G, req 0.01G)
I0801 13:11:32.530444 12905 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 8.03G, req 0.01G)
I0801 13:11:32.547308 12904 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 8.02G, req 0.01G)
I0801 13:11:32.548954 12904 solver.cpp:56] Solver scaffolding done.
I0801 13:11:32.548979 12905 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 8.02G, req 0.01G)
I0801 13:11:32.551641 12905 solver.cpp:56] Solver scaffolding done.
I0801 13:11:32.596570 12905 parallel.cpp:164] [2 - 2] P2pSync adding callback
I0801 13:11:32.596570 12904 parallel.cpp:164] [1 - 1] P2pSync adding callback
I0801 13:11:32.596570 12903 parallel.cpp:164] [0 - 0] P2pSync adding callback
I0801 13:11:32.812036 12903 solver.cpp:479] Solving jacintonet11v2_train
I0801 13:11:32.812055 12903 solver.cpp:480] Learning Rate Policy: poly
I0801 13:11:32.812062 12905 solver.cpp:479] Solving jacintonet11v2_train
I0801 13:11:32.812070 12905 solver.cpp:480] Learning Rate Policy: poly
I0801 13:11:32.812093 12904 solver.cpp:479] Solving jacintonet11v2_train
I0801 13:11:32.812103 12904 solver.cpp:480] Learning Rate Policy: poly
I0801 13:11:32.818377 12904 solver.cpp:268] Starting Optimization on GPU 1
I0801 13:11:32.818380 12905 solver.cpp:268] Starting Optimization on GPU 2
I0801 13:11:32.818384 12903 solver.cpp:268] Starting Optimization on GPU 0
I0801 13:11:32.818671 12903 solver.cpp:550] Iteration 0, Testing net (#0)
I0801 13:11:32.818687 12931 device_alternate.hpp:116] NVML initialized on thread 140415277430528
I0801 13:11:32.818707 12931 common.cpp:583] NVML succeeded to set CPU affinity on device 1
I0801 13:11:32.818719 12930 device_alternate.hpp:116] NVML initialized on thread 140415269037824
I0801 13:11:32.818735 12930 common.cpp:583] NVML succeeded to set CPU affinity on device 2
I0801 13:11:32.818750 12932 device_alternate.hpp:116] NVML initialized on thread 140415260645120
I0801 13:11:32.818761 12932 common.cpp:583] NVML succeeded to set CPU affinity on device 0
I0801 13:11:32.830557 12904 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'conv1a' with space 0.02G/1 0  (limit 7.99G, req 0.01G)
I0801 13:11:32.830838 12905 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 7.99G, req 0.01G)
I0801 13:11:32.832025 12903 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'conv1a' with space 0.01G/1 1  (limit 7.92G, req 0G)
I0801 13:11:32.836846 12904 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'conv1b' with space 0.02G/2 1  (limit 7.98G, req 0.01G)
I0801 13:11:32.837093 12905 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'conv1b' with space 0.02G/2 1  (limit 7.98G, req 0.01G)
I0801 13:11:32.839046 12903 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'conv1b' with space 0.02G/2 1  (limit 7.9G, req 0G)
I0801 13:11:32.845527 12904 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.97G, req 0.01G)
I0801 13:11:32.846027 12905 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.97G, req 0.01G)
I0801 13:11:32.847280 12903 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.89G, req 0G)
I0801 13:11:32.852174 12904 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.96G, req 0.01G)
I0801 13:11:32.853627 12905 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.96G, req 0.01G)
I0801 13:11:32.854104 12903 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.88G, req 0G)
I0801 13:11:32.859119 12904 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.94G, req 0.01G)
I0801 13:11:32.860810 12905 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.94G, req 0.01G)
I0801 13:11:32.861845 12903 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.86G, req 0G)
I0801 13:11:32.864555 12904 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.94G, req 0.01G)
I0801 13:11:32.867116 12905 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.94G, req 0.01G)
I0801 13:11:32.868065 12903 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.85G, req 0G)
I0801 13:11:32.873355 12904 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.92G, req 0.01G)
I0801 13:11:32.876505 12905 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.92G, req 0.01G)
I0801 13:11:32.877053 12903 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.84G, req 0G)
I0801 13:11:32.878301 12904 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.91G, req 0.01G)
I0801 13:11:32.883409 12905 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.91G, req 0.01G)
I0801 13:11:32.883749 12903 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.83G, req 0G)
I0801 13:11:32.887611 12904 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.9G, req 0.01G)
I0801 13:11:32.892279 12904 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.89G, req 0.01G)
I0801 13:11:32.893220 12905 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.9G, req 0.01G)
I0801 13:11:32.893733 12903 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.81G, req 0G)
I0801 13:11:32.898883 12903 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.8G, req 0G)
I0801 13:11:32.899408 12905 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.89G, req 0.01G)
I0801 13:11:32.902508 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.176471
I0801 13:11:32.902521 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.470588
I0801 13:11:32.902529 12903 solver.cpp:635]     Test net output #2: loss = 71.9242 (* 1 = 71.9242 loss)
I0801 13:11:32.902536 12903 solver.cpp:295] [MultiGPU] Initial Test completed
I0801 13:11:32.902551 12905 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 13:11:32.911949 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 3  (limit 7.88G, req 0.01G)
I0801 13:11:32.912586 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 3  (limit 7.88G, req 0.01G)
I0801 13:11:32.913465 12903 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 3  (limit 7.8G, req 0G)
I0801 13:11:32.921797 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 7.87G, req 0.01G)
I0801 13:11:32.922413 12903 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 6 1 3  (limit 7.79G, req 0G)
I0801 13:11:32.922798 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 7.87G, req 0.01G)
I0801 13:11:32.932942 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 7.86G, req 0.01G)
I0801 13:11:32.934037 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 7.86G, req 0.01G)
I0801 13:11:32.934751 12903 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 7.77G, req 0G)
I0801 13:11:32.941846 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 7.85G, req 0.01G)
I0801 13:11:32.943269 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 7.85G, req 0.01G)
I0801 13:11:32.943527 12903 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 7.76G, req 0G)
I0801 13:11:32.953407 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 7.83G, req 0.01G)
I0801 13:11:32.954684 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 7.83G, req 0.01G)
I0801 13:11:32.955873 12903 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 7.75G, req 0.01G)
I0801 13:11:32.960441 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 7.82G, req 0.01G)
I0801 13:11:32.961796 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 7.82G, req 0.01G)
I0801 13:11:32.962955 12903 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 7.74G, req 0.01G)
I0801 13:11:32.977159 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 7.81G, req 0.01G)
I0801 13:11:32.977588 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 3  (limit 7.81G, req 0.01G)
I0801 13:11:32.979619 12903 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 3  (limit 7.72G, req 0.01G)
I0801 13:11:32.986232 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 7.8G, req 0.01G)
I0801 13:11:32.986631 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 7.8G, req 0.01G)
I0801 13:11:32.987221 12903 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 7.71G, req 0.01G)
I0801 13:11:33.006700 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 3  (limit 7.78G, req 0.01G)
I0801 13:11:33.007408 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 1  (limit 7.78G, req 0.01G)
I0801 13:11:33.008667 12903 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 1  (limit 7.69G, req 0.01G)
I0801 13:11:33.015650 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 5  (limit 7.77G, req 0.01G)
I0801 13:11:33.017277 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 5  (limit 7.77G, req 0.01G)
I0801 13:11:33.017868 12903 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 5  (limit 7.68G, req 0.01G)
I0801 13:11:33.051841 12908 data_layer.cpp:97] [1] Parser threads: 1
I0801 13:11:33.051856 12908 data_layer.cpp:99] [1] Transformer threads: 1
I0801 13:11:33.051954 12871 data_layer.cpp:97] [0] Parser threads: 1
I0801 13:11:33.051966 12871 data_layer.cpp:99] [0] Transformer threads: 1
I0801 13:11:33.053287 12909 data_layer.cpp:97] [2] Parser threads: 1
I0801 13:11:33.053298 12909 data_layer.cpp:99] [2] Transformer threads: 1
I0801 13:11:33.054494 12903 solver.cpp:358] Iteration 0 (0.151878 s), loss = 2.32328
I0801 13:11:33.054513 12903 solver.cpp:375]     Train net output #0: loss = 2.32328 (* 1 = 2.32328 loss)
I0801 13:11:33.054519 12903 sgd_solver.cpp:136] Iteration 0, lr = 0.1, m = 0.9
I0801 13:11:33.081914 12903 solver.cpp:358] Iteration 1 (0.0274135 s), loss = 2.19252
I0801 13:11:33.081960 12903 solver.cpp:375]     Train net output #0: loss = 2.19252 (* 1 = 2.19252 loss)
I0801 13:11:33.093075 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.64G/1 1 0 3  (limit 7.07G, req 0.01G)
I0801 13:11:33.093354 12903 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.64G/1 1 0 3  (limit 6.98G, req 0.01G)
I0801 13:11:33.093552 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1a' with space 0.64G/1 1 0 3  (limit 7.07G, req 0.01G)
I0801 13:11:33.105315 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1b' with space 1.29G/2 1 1 3  (limit 6.43G, req 0.01G)
I0801 13:11:33.108330 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1b' with space 1.29G/2 1 1 3  (limit 6.43G, req 0.01G)
I0801 13:11:33.108530 12903 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1b' with space 1.29G/2 1 1 3  (limit 6.34G, req 0.01G)
I0801 13:11:33.121667 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 1.29G/1 6 4 3  (limit 6.43G, req 0.01G)
I0801 13:11:33.124449 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 1.29G/1 6 4 3  (limit 6.43G, req 0.01G)
I0801 13:11:33.124646 12903 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 1.29G/1 6 4 3  (limit 6.34G, req 0.01G)
I0801 13:11:33.128487 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 1.29G/2 6 4 3  (limit 6.43G, req 0.01G)
I0801 13:11:33.132149 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 1.29G/2 6 4 3  (limit 6.43G, req 0.01G)
I0801 13:11:33.132315 12903 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 1.29G/2 6 4 3  (limit 6.34G, req 0.01G)
I0801 13:11:33.138290 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 1.29G/1 6 4 5  (limit 6.43G, req 0.01G)
I0801 13:11:33.142653 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 1.29G/1 6 4 5  (limit 6.43G, req 0.01G)
I0801 13:11:33.143148 12903 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 1.29G/1 6 4 5  (limit 6.34G, req 0.01G)
I0801 13:11:33.143623 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 1.29G/2 6 4 3  (limit 6.43G, req 0.01G)
I0801 13:11:33.148010 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 1.29G/2 6 4 0  (limit 6.43G, req 0.01G)
I0801 13:11:33.148514 12903 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 1.29G/2 6 4 0  (limit 6.34G, req 0.01G)
I0801 13:11:33.168022 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 1.29G/1 6 4 5  (limit 6.43G, req 0.02G)
I0801 13:11:33.173910 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 1.29G/1 6 4 5  (limit 6.43G, req 0.02G)
I0801 13:11:33.174095 12903 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 1.29G/1 6 4 5  (limit 6.34G, req 0.02G)
I0801 13:11:33.176501 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 1.29G/2 6 4 3  (limit 6.43G, req 0.02G)
I0801 13:11:33.182030 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 1.29G/2 6 4 3  (limit 6.43G, req 0.02G)
I0801 13:11:33.182242 12903 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 1.29G/2 6 4 3  (limit 6.34G, req 0.02G)
I0801 13:11:33.212615 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 1.29G/1 7 5 5  (limit 6.43G, req 0.03G)
I0801 13:11:33.219210 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 1.29G/1 7 5 5  (limit 6.43G, req 0.03G)
I0801 13:11:33.219375 12903 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 1.29G/1 7 5 5  (limit 6.34G, req 0.03G)
I0801 13:11:33.222070 12904 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 1.29G/2 6 4 5  (limit 6.43G, req 0.03G)
I0801 13:11:33.228199 12905 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 1.29G/2 6 4 5  (limit 6.43G, req 0.03G)
I0801 13:11:33.228502 12903 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 1.29G/2 6 4 5  (limit 6.34G, req 0.03G)
I0801 13:11:33.238867 12903 solver.cpp:358] Iteration 2 (0.156942 s), loss = 2.16932
I0801 13:11:33.238889 12903 solver.cpp:375]     Train net output #0: loss = 2.16932 (* 1 = 2.16932 loss)
I0801 13:11:33.238900 12905 cudnn_conv_layer.cpp:292] [2] Layer 'conv1a' reallocating workspace: 1.29G -> 0.07G
I0801 13:11:33.238903 12904 cudnn_conv_layer.cpp:292] [1] Layer 'conv1a' reallocating workspace: 1.29G -> 0.07G
I0801 13:11:33.238922 12903 cudnn_conv_layer.cpp:292] [0] Layer 'conv1a' reallocating workspace: 1.29G -> 0.07G
I0801 13:11:34.723676 12903 solver.cpp:353] Iteration 100 (66.004 iter/s, 1.48476s/98 iter), loss = 2.16189
I0801 13:11:34.723701 12903 solver.cpp:375]     Train net output #0: loss = 2.16189 (* 1 = 2.16189 loss)
I0801 13:11:34.723706 12903 sgd_solver.cpp:136] Iteration 100, lr = 0.0998438, m = 0.9
I0801 13:11:36.243721 12903 solver.cpp:353] Iteration 200 (65.7897 iter/s, 1.51999s/100 iter), loss = 1.422
I0801 13:11:36.243769 12903 solver.cpp:375]     Train net output #0: loss = 1.422 (* 1 = 1.422 loss)
I0801 13:11:36.243782 12903 sgd_solver.cpp:136] Iteration 200, lr = 0.0996875, m = 0.9
I0801 13:11:37.761785 12903 solver.cpp:353] Iteration 300 (65.8755 iter/s, 1.51801s/100 iter), loss = 1.27943
I0801 13:11:37.761847 12903 solver.cpp:375]     Train net output #0: loss = 1.27943 (* 1 = 1.27943 loss)
I0801 13:11:37.761865 12903 sgd_solver.cpp:136] Iteration 300, lr = 0.0995313, m = 0.9
I0801 13:11:39.284245 12903 solver.cpp:353] Iteration 400 (65.6853 iter/s, 1.52241s/100 iter), loss = 1.08396
I0801 13:11:39.284272 12903 solver.cpp:375]     Train net output #0: loss = 1.08396 (* 1 = 1.08396 loss)
I0801 13:11:39.284278 12903 sgd_solver.cpp:136] Iteration 400, lr = 0.099375, m = 0.9
I0801 13:11:40.824879 12903 solver.cpp:353] Iteration 500 (64.9104 iter/s, 1.54058s/100 iter), loss = 1.62044
I0801 13:11:40.824906 12903 solver.cpp:375]     Train net output #0: loss = 1.62044 (* 1 = 1.62044 loss)
I0801 13:11:40.824913 12903 sgd_solver.cpp:136] Iteration 500, lr = 0.0992187, m = 0.9
I0801 13:11:42.348969 12903 solver.cpp:353] Iteration 600 (65.6151 iter/s, 1.52404s/100 iter), loss = 1.05527
I0801 13:11:42.349118 12903 solver.cpp:375]     Train net output #0: loss = 1.05527 (* 1 = 1.05527 loss)
I0801 13:11:42.349138 12903 sgd_solver.cpp:136] Iteration 600, lr = 0.0990625, m = 0.9
I0801 13:11:43.881842 12903 solver.cpp:353] Iteration 700 (65.239 iter/s, 1.53282s/100 iter), loss = 0.796999
I0801 13:11:43.881867 12903 solver.cpp:375]     Train net output #0: loss = 0.796999 (* 1 = 0.796999 loss)
I0801 13:11:43.881892 12903 sgd_solver.cpp:136] Iteration 700, lr = 0.0989062, m = 0.9
I0801 13:11:44.708917 12870 data_reader.cpp:264] Starting prefetch of epoch 1
I0801 13:11:45.410946 12903 solver.cpp:353] Iteration 800 (65.3999 iter/s, 1.52905s/100 iter), loss = 0.583395
I0801 13:11:45.410974 12903 solver.cpp:375]     Train net output #0: loss = 0.583395 (* 1 = 0.583395 loss)
I0801 13:11:45.410980 12903 sgd_solver.cpp:136] Iteration 800, lr = 0.09875, m = 0.9
I0801 13:11:46.985213 12903 solver.cpp:353] Iteration 900 (63.5237 iter/s, 1.57422s/100 iter), loss = 0.516644
I0801 13:11:46.985236 12903 solver.cpp:375]     Train net output #0: loss = 0.516644 (* 1 = 0.516644 loss)
I0801 13:11:46.985241 12903 sgd_solver.cpp:136] Iteration 900, lr = 0.0985937, m = 0.9
I0801 13:11:48.487159 12903 solver.cpp:550] Iteration 1000, Testing net (#0)
I0801 13:11:49.271790 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.559412
I0801 13:11:49.271808 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.925883
I0801 13:11:49.271813 12903 solver.cpp:635]     Test net output #2: loss = 1.30952 (* 1 = 1.30952 loss)
I0801 13:11:49.271829 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.784647s
I0801 13:11:49.286805 12903 solver.cpp:353] Iteration 1000 (43.4495 iter/s, 2.30152s/100 iter), loss = 1.1014
I0801 13:11:49.286820 12903 solver.cpp:375]     Train net output #0: loss = 1.1014 (* 1 = 1.1014 loss)
I0801 13:11:49.286825 12903 sgd_solver.cpp:136] Iteration 1000, lr = 0.0984375, m = 0.9
I0801 13:11:50.789301 12903 solver.cpp:353] Iteration 1100 (66.5582 iter/s, 1.50244s/100 iter), loss = 0.806615
I0801 13:11:50.789350 12903 solver.cpp:375]     Train net output #0: loss = 0.806615 (* 1 = 0.806615 loss)
I0801 13:11:50.789362 12903 sgd_solver.cpp:136] Iteration 1100, lr = 0.0982813, m = 0.9
I0801 13:11:52.305724 12903 solver.cpp:353] Iteration 1200 (65.9468 iter/s, 1.51637s/100 iter), loss = 0.708315
I0801 13:11:52.305750 12903 solver.cpp:375]     Train net output #0: loss = 0.708315 (* 1 = 0.708315 loss)
I0801 13:11:52.305757 12903 sgd_solver.cpp:136] Iteration 1200, lr = 0.098125, m = 0.9
I0801 13:11:53.854111 12903 solver.cpp:353] Iteration 1300 (64.5854 iter/s, 1.54834s/100 iter), loss = 0.76829
I0801 13:11:53.854136 12903 solver.cpp:375]     Train net output #0: loss = 0.768291 (* 1 = 0.768291 loss)
I0801 13:11:53.854142 12903 sgd_solver.cpp:136] Iteration 1300, lr = 0.0979687, m = 0.9
I0801 13:11:55.372375 12903 solver.cpp:353] Iteration 1400 (65.8669 iter/s, 1.51821s/100 iter), loss = 0.699026
I0801 13:11:55.372444 12903 solver.cpp:375]     Train net output #0: loss = 0.699026 (* 1 = 0.699026 loss)
I0801 13:11:55.372464 12903 sgd_solver.cpp:136] Iteration 1400, lr = 0.0978125, m = 0.9
I0801 13:11:56.886628 12903 solver.cpp:353] Iteration 1500 (66.0413 iter/s, 1.5142s/100 iter), loss = 0.421276
I0801 13:11:56.886653 12903 solver.cpp:375]     Train net output #0: loss = 0.421277 (* 1 = 0.421277 loss)
I0801 13:11:56.886659 12903 sgd_solver.cpp:136] Iteration 1500, lr = 0.0976562, m = 0.9
I0801 13:11:58.446661 12903 solver.cpp:353] Iteration 1600 (64.1033 iter/s, 1.55998s/100 iter), loss = 0.719585
I0801 13:11:58.446684 12903 solver.cpp:375]     Train net output #0: loss = 0.719585 (* 1 = 0.719585 loss)
I0801 13:11:58.446689 12903 sgd_solver.cpp:136] Iteration 1600, lr = 0.0975, m = 0.9
I0801 13:11:59.973229 12903 solver.cpp:353] Iteration 1700 (65.5086 iter/s, 1.52652s/100 iter), loss = 0.59711
I0801 13:11:59.973253 12903 solver.cpp:375]     Train net output #0: loss = 0.597111 (* 1 = 0.597111 loss)
I0801 13:11:59.973258 12903 sgd_solver.cpp:136] Iteration 1700, lr = 0.0973438, m = 0.9
I0801 13:12:01.494354 12903 solver.cpp:353] Iteration 1800 (65.7429 iter/s, 1.52108s/100 iter), loss = 0.369106
I0801 13:12:01.494470 12903 solver.cpp:375]     Train net output #0: loss = 0.369106 (* 1 = 0.369106 loss)
I0801 13:12:01.494478 12903 sgd_solver.cpp:136] Iteration 1800, lr = 0.0971875, m = 0.9
I0801 13:12:03.027909 12903 solver.cpp:353] Iteration 1900 (65.2101 iter/s, 1.53351s/100 iter), loss = 0.806105
I0801 13:12:03.027962 12903 solver.cpp:375]     Train net output #0: loss = 0.806105 (* 1 = 0.806105 loss)
I0801 13:12:03.027977 12903 sgd_solver.cpp:136] Iteration 1900, lr = 0.0970313, m = 0.9
I0801 13:12:04.552696 12903 solver.cpp:550] Iteration 2000, Testing net (#0)
I0801 13:12:05.358249 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.643823
I0801 13:12:05.358268 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.961471
I0801 13:12:05.358275 12903 solver.cpp:635]     Test net output #2: loss = 1.07889 (* 1 = 1.07889 loss)
I0801 13:12:05.358294 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.805575s
I0801 13:12:05.373716 12903 solver.cpp:353] Iteration 2000 (42.6305 iter/s, 2.34574s/100 iter), loss = 0.831556
I0801 13:12:05.373745 12903 solver.cpp:375]     Train net output #0: loss = 0.831557 (* 1 = 0.831557 loss)
I0801 13:12:05.373757 12903 sgd_solver.cpp:136] Iteration 2000, lr = 0.096875, m = 0.9
I0801 13:12:06.911116 12903 solver.cpp:353] Iteration 2100 (65.0471 iter/s, 1.53735s/100 iter), loss = 0.675357
I0801 13:12:06.911140 12903 solver.cpp:375]     Train net output #0: loss = 0.675357 (* 1 = 0.675357 loss)
I0801 13:12:06.911146 12903 sgd_solver.cpp:136] Iteration 2100, lr = 0.0967188, m = 0.9
I0801 13:12:08.451097 12903 solver.cpp:353] Iteration 2200 (64.9379 iter/s, 1.53993s/100 iter), loss = 0.580449
I0801 13:12:08.451122 12903 solver.cpp:375]     Train net output #0: loss = 0.58045 (* 1 = 0.58045 loss)
I0801 13:12:08.451128 12903 sgd_solver.cpp:136] Iteration 2200, lr = 0.0965625, m = 0.9
I0801 13:12:09.973106 12903 solver.cpp:353] Iteration 2300 (65.7048 iter/s, 1.52196s/100 iter), loss = 0.312723
I0801 13:12:09.973129 12903 solver.cpp:375]     Train net output #0: loss = 0.312723 (* 1 = 0.312723 loss)
I0801 13:12:09.973134 12903 sgd_solver.cpp:136] Iteration 2300, lr = 0.0964063, m = 0.9
I0801 13:12:11.509886 12903 solver.cpp:353] Iteration 2400 (65.0733 iter/s, 1.53673s/100 iter), loss = 0.566582
I0801 13:12:11.509923 12903 solver.cpp:375]     Train net output #0: loss = 0.566583 (* 1 = 0.566583 loss)
I0801 13:12:11.509930 12903 sgd_solver.cpp:136] Iteration 2400, lr = 0.09625, m = 0.9
I0801 13:12:13.044085 12903 solver.cpp:353] Iteration 2500 (65.1826 iter/s, 1.53415s/100 iter), loss = 0.245808
I0801 13:12:13.044111 12903 solver.cpp:375]     Train net output #0: loss = 0.245808 (* 1 = 0.245808 loss)
I0801 13:12:13.044117 12903 sgd_solver.cpp:136] Iteration 2500, lr = 0.0960938, m = 0.9
I0801 13:12:14.576988 12903 solver.cpp:353] Iteration 2600 (65.2378 iter/s, 1.53285s/100 iter), loss = 0.364048
I0801 13:12:14.577013 12903 solver.cpp:375]     Train net output #0: loss = 0.364049 (* 1 = 0.364049 loss)
I0801 13:12:14.577018 12903 sgd_solver.cpp:136] Iteration 2600, lr = 0.0959375, m = 0.9
I0801 13:12:16.104897 12903 solver.cpp:353] Iteration 2700 (65.4511 iter/s, 1.52786s/100 iter), loss = 0.285343
I0801 13:12:16.104921 12903 solver.cpp:375]     Train net output #0: loss = 0.285343 (* 1 = 0.285343 loss)
I0801 13:12:16.104928 12903 sgd_solver.cpp:136] Iteration 2700, lr = 0.0957813, m = 0.9
I0801 13:12:17.650336 12903 solver.cpp:353] Iteration 2800 (64.7087 iter/s, 1.54539s/100 iter), loss = 0.456162
I0801 13:12:17.650362 12903 solver.cpp:375]     Train net output #0: loss = 0.456162 (* 1 = 0.456162 loss)
I0801 13:12:17.650367 12903 sgd_solver.cpp:136] Iteration 2800, lr = 0.095625, m = 0.9
I0801 13:12:19.178120 12903 solver.cpp:353] Iteration 2900 (65.4563 iter/s, 1.52774s/100 iter), loss = 0.212026
I0801 13:12:19.178148 12903 solver.cpp:375]     Train net output #0: loss = 0.212026 (* 1 = 0.212026 loss)
I0801 13:12:19.178155 12903 sgd_solver.cpp:136] Iteration 2900, lr = 0.0954688, m = 0.9
I0801 13:12:20.700646 12903 solver.cpp:550] Iteration 3000, Testing net (#0)
I0801 13:12:21.508605 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.672353
I0801 13:12:21.508637 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.976177
I0801 13:12:21.508646 12903 solver.cpp:635]     Test net output #2: loss = 0.973545 (* 1 = 0.973545 loss)
I0801 13:12:21.508666 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.807995s
I0801 13:12:21.523877 12903 solver.cpp:353] Iteration 3000 (42.6314 iter/s, 2.34569s/100 iter), loss = 0.529866
I0801 13:12:21.523892 12903 solver.cpp:375]     Train net output #0: loss = 0.529866 (* 1 = 0.529866 loss)
I0801 13:12:21.523898 12903 sgd_solver.cpp:136] Iteration 3000, lr = 0.0953125, m = 0.9
I0801 13:12:23.055491 12903 solver.cpp:353] Iteration 3100 (65.2929 iter/s, 1.53156s/100 iter), loss = 0.196981
I0801 13:12:23.055519 12903 solver.cpp:375]     Train net output #0: loss = 0.196981 (* 1 = 0.196981 loss)
I0801 13:12:23.055526 12903 sgd_solver.cpp:136] Iteration 3100, lr = 0.0951563, m = 0.9
I0801 13:12:24.608433 12903 solver.cpp:353] Iteration 3200 (64.3961 iter/s, 1.55289s/100 iter), loss = 0.650997
I0801 13:12:24.608485 12903 solver.cpp:375]     Train net output #0: loss = 0.650997 (* 1 = 0.650997 loss)
I0801 13:12:24.608501 12903 sgd_solver.cpp:136] Iteration 3200, lr = 0.095, m = 0.9
I0801 13:12:26.163813 12903 solver.cpp:353] Iteration 3300 (64.295 iter/s, 1.55533s/100 iter), loss = 0.101506
I0801 13:12:26.163859 12903 solver.cpp:375]     Train net output #0: loss = 0.101506 (* 1 = 0.101506 loss)
I0801 13:12:26.163867 12903 sgd_solver.cpp:136] Iteration 3300, lr = 0.0948438, m = 0.9
I0801 13:12:27.731096 12903 solver.cpp:353] Iteration 3400 (63.8069 iter/s, 1.56723s/100 iter), loss = 0.525725
I0801 13:12:27.731154 12903 solver.cpp:375]     Train net output #0: loss = 0.525725 (* 1 = 0.525725 loss)
I0801 13:12:27.731169 12903 sgd_solver.cpp:136] Iteration 3400, lr = 0.0946875, m = 0.9
I0801 13:12:29.293987 12903 solver.cpp:353] Iteration 3500 (63.9862 iter/s, 1.56284s/100 iter), loss = 0.531755
I0801 13:12:29.294013 12903 solver.cpp:375]     Train net output #0: loss = 0.531756 (* 1 = 0.531756 loss)
I0801 13:12:29.294018 12903 sgd_solver.cpp:136] Iteration 3500, lr = 0.0945313, m = 0.9
I0801 13:12:30.882663 12903 solver.cpp:353] Iteration 3600 (62.9475 iter/s, 1.58863s/100 iter), loss = 0.241733
I0801 13:12:30.882711 12903 solver.cpp:375]     Train net output #0: loss = 0.241733 (* 1 = 0.241733 loss)
I0801 13:12:30.882725 12903 sgd_solver.cpp:136] Iteration 3600, lr = 0.094375, m = 0.9
I0801 13:12:32.468650 12903 solver.cpp:353] Iteration 3700 (63.0543 iter/s, 1.58594s/100 iter), loss = 0.214614
I0801 13:12:32.468736 12903 solver.cpp:375]     Train net output #0: loss = 0.214614 (* 1 = 0.214614 loss)
I0801 13:12:32.468744 12903 sgd_solver.cpp:136] Iteration 3700, lr = 0.0942188, m = 0.9
I0801 13:12:34.065635 12903 solver.cpp:353] Iteration 3800 (62.6199 iter/s, 1.59694s/100 iter), loss = 0.831711
I0801 13:12:34.065659 12903 solver.cpp:375]     Train net output #0: loss = 0.831711 (* 1 = 0.831711 loss)
I0801 13:12:34.065665 12903 sgd_solver.cpp:136] Iteration 3800, lr = 0.0940625, m = 0.9
I0801 13:12:35.622169 12903 solver.cpp:353] Iteration 3900 (64.2474 iter/s, 1.55648s/100 iter), loss = 0.799882
I0801 13:12:35.622193 12903 solver.cpp:375]     Train net output #0: loss = 0.799882 (* 1 = 0.799882 loss)
I0801 13:12:35.622200 12903 sgd_solver.cpp:136] Iteration 3900, lr = 0.0939062, m = 0.9
I0801 13:12:37.187930 12903 solver.cpp:550] Iteration 4000, Testing net (#0)
I0801 13:12:38.021989 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.716471
I0801 13:12:38.022012 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.984412
I0801 13:12:38.022017 12903 solver.cpp:635]     Test net output #2: loss = 0.848979 (* 1 = 0.848979 loss)
I0801 13:12:38.022044 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.834091s
I0801 13:12:38.037724 12903 solver.cpp:353] Iteration 4000 (41.3996 iter/s, 2.41548s/100 iter), loss = 0.279819
I0801 13:12:38.037740 12903 solver.cpp:375]     Train net output #0: loss = 0.279819 (* 1 = 0.279819 loss)
I0801 13:12:38.037744 12903 sgd_solver.cpp:136] Iteration 4000, lr = 0.09375, m = 0.9
I0801 13:12:39.602623 12903 solver.cpp:353] Iteration 4100 (63.9041 iter/s, 1.56485s/100 iter), loss = 0.198207
I0801 13:12:39.602648 12903 solver.cpp:375]     Train net output #0: loss = 0.198207 (* 1 = 0.198207 loss)
I0801 13:12:39.602654 12903 sgd_solver.cpp:136] Iteration 4100, lr = 0.0935938, m = 0.9
I0801 13:12:41.196776 12903 solver.cpp:353] Iteration 4200 (62.7312 iter/s, 1.5941s/100 iter), loss = 0.582615
I0801 13:12:41.196799 12903 solver.cpp:375]     Train net output #0: loss = 0.582615 (* 1 = 0.582615 loss)
I0801 13:12:41.196804 12903 sgd_solver.cpp:136] Iteration 4200, lr = 0.0934375, m = 0.9
I0801 13:12:42.781155 12903 solver.cpp:353] Iteration 4300 (63.1183 iter/s, 1.58433s/100 iter), loss = 0.316222
I0801 13:12:42.781183 12903 solver.cpp:375]     Train net output #0: loss = 0.316222 (* 1 = 0.316222 loss)
I0801 13:12:42.781188 12903 sgd_solver.cpp:136] Iteration 4300, lr = 0.0932813, m = 0.9
I0801 13:12:44.379304 12903 solver.cpp:353] Iteration 4400 (62.5744 iter/s, 1.5981s/100 iter), loss = 0.478641
I0801 13:12:44.379351 12903 solver.cpp:375]     Train net output #0: loss = 0.478641 (* 1 = 0.478641 loss)
I0801 13:12:44.379359 12903 sgd_solver.cpp:136] Iteration 4400, lr = 0.093125, m = 0.9
I0801 13:12:45.973162 12903 solver.cpp:353] Iteration 4500 (62.7429 iter/s, 1.59381s/100 iter), loss = 0.267014
I0801 13:12:45.973214 12903 solver.cpp:375]     Train net output #0: loss = 0.267014 (* 1 = 0.267014 loss)
I0801 13:12:45.973229 12903 sgd_solver.cpp:136] Iteration 4500, lr = 0.0929688, m = 0.9
I0801 13:12:47.551133 12903 solver.cpp:353] Iteration 4600 (63.3746 iter/s, 1.57792s/100 iter), loss = 0.155118
I0801 13:12:47.551184 12903 solver.cpp:375]     Train net output #0: loss = 0.155118 (* 1 = 0.155118 loss)
I0801 13:12:47.551198 12903 sgd_solver.cpp:136] Iteration 4600, lr = 0.0928125, m = 0.9
I0801 13:12:49.117053 12903 solver.cpp:353] Iteration 4700 (63.8623 iter/s, 1.56587s/100 iter), loss = 0.653835
I0801 13:12:49.117105 12903 solver.cpp:375]     Train net output #0: loss = 0.653835 (* 1 = 0.653835 loss)
I0801 13:12:49.117120 12903 sgd_solver.cpp:136] Iteration 4700, lr = 0.0926562, m = 0.9
I0801 13:12:50.679749 12903 solver.cpp:353] Iteration 4800 (63.994 iter/s, 1.56265s/100 iter), loss = 0.494451
I0801 13:12:50.679775 12903 solver.cpp:375]     Train net output #0: loss = 0.494451 (* 1 = 0.494451 loss)
I0801 13:12:50.679781 12903 sgd_solver.cpp:136] Iteration 4800, lr = 0.0925, m = 0.9
I0801 13:12:52.249183 12903 solver.cpp:353] Iteration 4900 (63.7193 iter/s, 1.56938s/100 iter), loss = 0.157635
I0801 13:12:52.249224 12903 solver.cpp:375]     Train net output #0: loss = 0.157635 (* 1 = 0.157635 loss)
I0801 13:12:52.249230 12903 sgd_solver.cpp:136] Iteration 4900, lr = 0.0923437, m = 0.9
I0801 13:12:53.821192 12903 solver.cpp:550] Iteration 5000, Testing net (#0)
I0801 13:12:54.488847 12893 data_reader.cpp:264] Starting prefetch of epoch 1
I0801 13:12:54.634626 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.826766
I0801 13:12:54.634645 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.991471
I0801 13:12:54.634650 12903 solver.cpp:635]     Test net output #2: loss = 0.533382 (* 1 = 0.533382 loss)
I0801 13:12:54.634670 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.813453s
I0801 13:12:54.650584 12903 solver.cpp:353] Iteration 5000 (41.6436 iter/s, 2.40133s/100 iter), loss = 0.576708
I0801 13:12:54.650605 12903 solver.cpp:375]     Train net output #0: loss = 0.576708 (* 1 = 0.576708 loss)
I0801 13:12:54.650611 12903 sgd_solver.cpp:136] Iteration 5000, lr = 0.0921875, m = 0.9
I0801 13:12:56.219452 12903 solver.cpp:353] Iteration 5100 (63.7424 iter/s, 1.56881s/100 iter), loss = 0.188347
I0801 13:12:56.219478 12903 solver.cpp:375]     Train net output #0: loss = 0.188347 (* 1 = 0.188347 loss)
I0801 13:12:56.219485 12903 sgd_solver.cpp:136] Iteration 5100, lr = 0.0920313, m = 0.9
I0801 13:12:57.802814 12903 solver.cpp:353] Iteration 5200 (63.1587 iter/s, 1.58331s/100 iter), loss = 0.285026
I0801 13:12:57.802839 12903 solver.cpp:375]     Train net output #0: loss = 0.285026 (* 1 = 0.285026 loss)
I0801 13:12:57.802845 12903 sgd_solver.cpp:136] Iteration 5200, lr = 0.091875, m = 0.9
I0801 13:12:59.355649 12903 solver.cpp:353] Iteration 5300 (64.4004 iter/s, 1.55279s/100 iter), loss = 0.522394
I0801 13:12:59.355712 12903 solver.cpp:375]     Train net output #0: loss = 0.522394 (* 1 = 0.522394 loss)
I0801 13:12:59.355729 12903 sgd_solver.cpp:136] Iteration 5300, lr = 0.0917188, m = 0.9
I0801 13:13:00.932822 12903 solver.cpp:353] Iteration 5400 (63.4068 iter/s, 1.57712s/100 iter), loss = 0.489632
I0801 13:13:00.932848 12903 solver.cpp:375]     Train net output #0: loss = 0.489632 (* 1 = 0.489632 loss)
I0801 13:13:00.932854 12903 sgd_solver.cpp:136] Iteration 5400, lr = 0.0915625, m = 0.9
I0801 13:13:02.495333 12903 solver.cpp:353] Iteration 5500 (64.0016 iter/s, 1.56246s/100 iter), loss = 0.400948
I0801 13:13:02.495405 12903 solver.cpp:375]     Train net output #0: loss = 0.400948 (* 1 = 0.400948 loss)
I0801 13:13:02.495411 12903 sgd_solver.cpp:136] Iteration 5500, lr = 0.0914062, m = 0.9
I0801 13:13:04.066716 12903 solver.cpp:353] Iteration 5600 (63.6404 iter/s, 1.57133s/100 iter), loss = 0.176532
I0801 13:13:04.066741 12903 solver.cpp:375]     Train net output #0: loss = 0.176532 (* 1 = 0.176532 loss)
I0801 13:13:04.066747 12903 sgd_solver.cpp:136] Iteration 5600, lr = 0.09125, m = 0.9
I0801 13:13:05.640213 12903 solver.cpp:353] Iteration 5700 (63.5547 iter/s, 1.57345s/100 iter), loss = 0.092255
I0801 13:13:05.640266 12903 solver.cpp:375]     Train net output #0: loss = 0.0922551 (* 1 = 0.0922551 loss)
I0801 13:13:05.640280 12903 sgd_solver.cpp:136] Iteration 5700, lr = 0.0910937, m = 0.9
I0801 13:13:07.230319 12903 solver.cpp:353] Iteration 5800 (62.8908 iter/s, 1.59006s/100 iter), loss = 0.487442
I0801 13:13:07.230388 12903 solver.cpp:375]     Train net output #0: loss = 0.487442 (* 1 = 0.487442 loss)
I0801 13:13:07.230408 12903 sgd_solver.cpp:136] Iteration 5800, lr = 0.0909375, m = 0.9
I0801 13:13:08.817369 12903 solver.cpp:353] Iteration 5900 (63.012 iter/s, 1.587s/100 iter), loss = 0.38352
I0801 13:13:08.817394 12903 solver.cpp:375]     Train net output #0: loss = 0.38352 (* 1 = 0.38352 loss)
I0801 13:13:08.817399 12903 sgd_solver.cpp:136] Iteration 5900, lr = 0.0907812, m = 0.9
I0801 13:13:10.380487 12903 solver.cpp:550] Iteration 6000, Testing net (#0)
I0801 13:13:11.218156 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.733236
I0801 13:13:11.218176 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.977059
I0801 13:13:11.218181 12903 solver.cpp:635]     Test net output #2: loss = 0.923823 (* 1 = 0.923823 loss)
I0801 13:13:11.218197 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.837686s
I0801 13:13:11.234141 12903 solver.cpp:353] Iteration 6000 (41.3787 iter/s, 2.4167s/100 iter), loss = 0.21119
I0801 13:13:11.234158 12903 solver.cpp:375]     Train net output #0: loss = 0.21119 (* 1 = 0.21119 loss)
I0801 13:13:11.234163 12903 sgd_solver.cpp:136] Iteration 6000, lr = 0.090625, m = 0.9
I0801 13:13:12.813745 12903 solver.cpp:353] Iteration 6100 (63.3091 iter/s, 1.57955s/100 iter), loss = 0.308741
I0801 13:13:12.813771 12903 solver.cpp:375]     Train net output #0: loss = 0.308741 (* 1 = 0.308741 loss)
I0801 13:13:12.813777 12903 sgd_solver.cpp:136] Iteration 6100, lr = 0.0904688, m = 0.9
I0801 13:13:14.393987 12903 solver.cpp:353] Iteration 6200 (63.2835 iter/s, 1.58019s/100 iter), loss = 0.460715
I0801 13:13:14.394011 12903 solver.cpp:375]     Train net output #0: loss = 0.460715 (* 1 = 0.460715 loss)
I0801 13:13:14.394014 12903 sgd_solver.cpp:136] Iteration 6200, lr = 0.0903125, m = 0.9
I0801 13:13:15.959728 12903 solver.cpp:353] Iteration 6300 (63.8696 iter/s, 1.56569s/100 iter), loss = 0.478396
I0801 13:13:15.959754 12903 solver.cpp:375]     Train net output #0: loss = 0.478396 (* 1 = 0.478396 loss)
I0801 13:13:15.959760 12903 sgd_solver.cpp:136] Iteration 6300, lr = 0.0901562, m = 0.9
I0801 13:13:17.544641 12903 solver.cpp:353] Iteration 6400 (63.097 iter/s, 1.58486s/100 iter), loss = 0.414294
I0801 13:13:17.544669 12903 solver.cpp:375]     Train net output #0: loss = 0.414294 (* 1 = 0.414294 loss)
I0801 13:13:17.544677 12903 sgd_solver.cpp:136] Iteration 6400, lr = 0.09, m = 0.9
I0801 13:13:19.143203 12903 solver.cpp:353] Iteration 6500 (62.5582 iter/s, 1.59851s/100 iter), loss = 0.260976
I0801 13:13:19.143229 12903 solver.cpp:375]     Train net output #0: loss = 0.260976 (* 1 = 0.260976 loss)
I0801 13:13:19.143235 12903 sgd_solver.cpp:136] Iteration 6500, lr = 0.0898438, m = 0.9
I0801 13:13:20.712553 12903 solver.cpp:353] Iteration 6600 (63.7227 iter/s, 1.5693s/100 iter), loss = 0.255901
I0801 13:13:20.712577 12903 solver.cpp:375]     Train net output #0: loss = 0.255901 (* 1 = 0.255901 loss)
I0801 13:13:20.712581 12903 sgd_solver.cpp:136] Iteration 6600, lr = 0.0896875, m = 0.9
I0801 13:13:22.282143 12903 solver.cpp:353] Iteration 6700 (63.7129 iter/s, 1.56954s/100 iter), loss = 0.0730741
I0801 13:13:22.282194 12903 solver.cpp:375]     Train net output #0: loss = 0.0730744 (* 1 = 0.0730744 loss)
I0801 13:13:22.282202 12903 sgd_solver.cpp:136] Iteration 6700, lr = 0.0895313, m = 0.9
I0801 13:13:23.873383 12903 solver.cpp:353] Iteration 6800 (62.8462 iter/s, 1.59119s/100 iter), loss = 0.253255
I0801 13:13:23.873411 12903 solver.cpp:375]     Train net output #0: loss = 0.253256 (* 1 = 0.253256 loss)
I0801 13:13:23.873420 12903 sgd_solver.cpp:136] Iteration 6800, lr = 0.089375, m = 0.9
I0801 13:13:25.441468 12903 solver.cpp:353] Iteration 6900 (63.7741 iter/s, 1.56804s/100 iter), loss = 0.429764
I0801 13:13:25.441520 12903 solver.cpp:375]     Train net output #0: loss = 0.429765 (* 1 = 0.429765 loss)
I0801 13:13:25.441535 12903 sgd_solver.cpp:136] Iteration 6900, lr = 0.0892188, m = 0.9
I0801 13:13:27.006330 12903 solver.cpp:550] Iteration 7000, Testing net (#0)
I0801 13:13:27.828063 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.76853
I0801 13:13:27.828081 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.984412
I0801 13:13:27.828086 12903 solver.cpp:635]     Test net output #2: loss = 0.829131 (* 1 = 0.829131 loss)
I0801 13:13:27.828110 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.821756s
I0801 13:13:27.844494 12903 solver.cpp:353] Iteration 7000 (41.6155 iter/s, 2.40295s/100 iter), loss = 0.266784
I0801 13:13:27.844521 12903 solver.cpp:375]     Train net output #0: loss = 0.266785 (* 1 = 0.266785 loss)
I0801 13:13:27.844527 12903 sgd_solver.cpp:136] Iteration 7000, lr = 0.0890625, m = 0.9
I0801 13:13:29.412071 12903 solver.cpp:353] Iteration 7100 (63.7947 iter/s, 1.56753s/100 iter), loss = 0.0672804
I0801 13:13:29.412099 12903 solver.cpp:375]     Train net output #0: loss = 0.0672807 (* 1 = 0.0672807 loss)
I0801 13:13:29.412106 12903 sgd_solver.cpp:136] Iteration 7100, lr = 0.0889063, m = 0.9
I0801 13:13:31.010226 12903 solver.cpp:353] Iteration 7200 (62.5742 iter/s, 1.5981s/100 iter), loss = 0.732841
I0801 13:13:31.010251 12903 solver.cpp:375]     Train net output #0: loss = 0.732841 (* 1 = 0.732841 loss)
I0801 13:13:31.010255 12903 sgd_solver.cpp:136] Iteration 7200, lr = 0.08875, m = 0.9
I0801 13:13:32.597729 12903 solver.cpp:353] Iteration 7300 (62.994 iter/s, 1.58745s/100 iter), loss = 0.267667
I0801 13:13:32.597839 12903 solver.cpp:375]     Train net output #0: loss = 0.267668 (* 1 = 0.267668 loss)
I0801 13:13:32.597852 12903 sgd_solver.cpp:136] Iteration 7300, lr = 0.0885938, m = 0.9
I0801 13:13:34.188274 12903 solver.cpp:353] Iteration 7400 (62.8735 iter/s, 1.5905s/100 iter), loss = 0.299707
I0801 13:13:34.188298 12903 solver.cpp:375]     Train net output #0: loss = 0.299708 (* 1 = 0.299708 loss)
I0801 13:13:34.188302 12903 sgd_solver.cpp:136] Iteration 7400, lr = 0.0884375, m = 0.9
I0801 13:13:35.749122 12903 solver.cpp:353] Iteration 7500 (64.0699 iter/s, 1.5608s/100 iter), loss = 0.179877
I0801 13:13:35.749147 12903 solver.cpp:375]     Train net output #0: loss = 0.179878 (* 1 = 0.179878 loss)
I0801 13:13:35.749152 12903 sgd_solver.cpp:136] Iteration 7500, lr = 0.0882813, m = 0.9
I0801 13:13:37.327405 12903 solver.cpp:353] Iteration 7600 (63.3619 iter/s, 1.57823s/100 iter), loss = 0.41949
I0801 13:13:37.327433 12903 solver.cpp:375]     Train net output #0: loss = 0.41949 (* 1 = 0.41949 loss)
I0801 13:13:37.327440 12903 sgd_solver.cpp:136] Iteration 7600, lr = 0.088125, m = 0.9
I0801 13:13:38.903018 12903 solver.cpp:353] Iteration 7700 (63.4694 iter/s, 1.57556s/100 iter), loss = 0.0513038
I0801 13:13:38.903108 12903 solver.cpp:375]     Train net output #0: loss = 0.051304 (* 1 = 0.051304 loss)
I0801 13:13:38.903131 12903 sgd_solver.cpp:136] Iteration 7700, lr = 0.0879688, m = 0.9
I0801 13:13:40.471758 12903 solver.cpp:353] Iteration 7800 (63.7474 iter/s, 1.56869s/100 iter), loss = 0.584675
I0801 13:13:40.471807 12903 solver.cpp:375]     Train net output #0: loss = 0.584675 (* 1 = 0.584675 loss)
I0801 13:13:40.471820 12903 sgd_solver.cpp:136] Iteration 7800, lr = 0.0878125, m = 0.9
I0801 13:13:42.037654 12903 solver.cpp:353] Iteration 7900 (63.8633 iter/s, 1.56584s/100 iter), loss = 0.188815
I0801 13:13:42.037740 12903 solver.cpp:375]     Train net output #0: loss = 0.188815 (* 1 = 0.188815 loss)
I0801 13:13:42.037760 12903 sgd_solver.cpp:136] Iteration 7900, lr = 0.0876563, m = 0.9
I0801 13:13:43.609072 12903 solver.cpp:550] Iteration 8000, Testing net (#0)
I0801 13:13:44.425168 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.773825
I0801 13:13:44.425189 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.979706
I0801 13:13:44.425194 12903 solver.cpp:635]     Test net output #2: loss = 0.785101 (* 1 = 0.785101 loss)
I0801 13:13:44.425209 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.816113s
I0801 13:13:44.440757 12903 solver.cpp:353] Iteration 8000 (41.6141 iter/s, 2.40303s/100 iter), loss = 0.201074
I0801 13:13:44.440774 12903 solver.cpp:375]     Train net output #0: loss = 0.201074 (* 1 = 0.201074 loss)
I0801 13:13:44.440778 12903 sgd_solver.cpp:136] Iteration 8000, lr = 0.0875, m = 0.9
I0801 13:13:46.016144 12903 solver.cpp:353] Iteration 8100 (63.4786 iter/s, 1.57533s/100 iter), loss = 0.211855
I0801 13:13:46.016170 12903 solver.cpp:375]     Train net output #0: loss = 0.211855 (* 1 = 0.211855 loss)
I0801 13:13:46.016175 12903 sgd_solver.cpp:136] Iteration 8100, lr = 0.0873438, m = 0.9
I0801 13:13:47.592468 12903 solver.cpp:353] Iteration 8200 (63.4409 iter/s, 1.57627s/100 iter), loss = 0.175261
I0801 13:13:47.592497 12903 solver.cpp:375]     Train net output #0: loss = 0.175261 (* 1 = 0.175261 loss)
I0801 13:13:47.592504 12903 sgd_solver.cpp:136] Iteration 8200, lr = 0.0871875, m = 0.9
I0801 13:13:49.151078 12903 solver.cpp:353] Iteration 8300 (64.1617 iter/s, 1.55856s/100 iter), loss = 0.386741
I0801 13:13:49.151104 12903 solver.cpp:375]     Train net output #0: loss = 0.386742 (* 1 = 0.386742 loss)
I0801 13:13:49.151110 12903 sgd_solver.cpp:136] Iteration 8300, lr = 0.0870313, m = 0.9
I0801 13:13:50.721679 12903 solver.cpp:353] Iteration 8400 (63.672 iter/s, 1.57055s/100 iter), loss = 0.081487
I0801 13:13:50.721729 12903 solver.cpp:375]     Train net output #0: loss = 0.081487 (* 1 = 0.081487 loss)
I0801 13:13:50.721741 12903 sgd_solver.cpp:136] Iteration 8400, lr = 0.086875, m = 0.9
I0801 13:13:52.280230 12903 solver.cpp:353] Iteration 8500 (64.1642 iter/s, 1.5585s/100 iter), loss = 0.476171
I0801 13:13:52.280302 12903 solver.cpp:375]     Train net output #0: loss = 0.476171 (* 1 = 0.476171 loss)
I0801 13:13:52.280315 12903 sgd_solver.cpp:136] Iteration 8500, lr = 0.0867188, m = 0.9
I0801 13:13:53.859277 12903 solver.cpp:353] Iteration 8600 (63.3313 iter/s, 1.579s/100 iter), loss = 0.0597984
I0801 13:13:53.859302 12903 solver.cpp:375]     Train net output #0: loss = 0.0597985 (* 1 = 0.0597985 loss)
I0801 13:13:53.859308 12903 sgd_solver.cpp:136] Iteration 8600, lr = 0.0865625, m = 0.9
I0801 13:13:55.414697 12903 solver.cpp:353] Iteration 8700 (64.2934 iter/s, 1.55537s/100 iter), loss = 0.166269
I0801 13:13:55.414750 12903 solver.cpp:375]     Train net output #0: loss = 0.166269 (* 1 = 0.166269 loss)
I0801 13:13:55.414763 12903 sgd_solver.cpp:136] Iteration 8700, lr = 0.0864063, m = 0.9
I0801 13:13:56.980902 12903 solver.cpp:353] Iteration 8800 (63.8508 iter/s, 1.56615s/100 iter), loss = 0.281878
I0801 13:13:56.980931 12903 solver.cpp:375]     Train net output #0: loss = 0.281879 (* 1 = 0.281879 loss)
I0801 13:13:56.980938 12903 sgd_solver.cpp:136] Iteration 8800, lr = 0.08625, m = 0.9
I0801 13:13:58.572885 12903 solver.cpp:353] Iteration 8900 (62.8168 iter/s, 1.59193s/100 iter), loss = 0.216198
I0801 13:13:58.572912 12903 solver.cpp:375]     Train net output #0: loss = 0.216198 (* 1 = 0.216198 loss)
I0801 13:13:58.572918 12903 sgd_solver.cpp:136] Iteration 8900, lr = 0.0860937, m = 0.9
I0801 13:14:00.119240 12903 solver.cpp:550] Iteration 9000, Testing net (#0)
I0801 13:14:00.967067 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.757354
I0801 13:14:00.967087 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.981471
I0801 13:14:00.967092 12903 solver.cpp:635]     Test net output #2: loss = 0.84657 (* 1 = 0.84657 loss)
I0801 13:14:00.967108 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.847844s
I0801 13:14:00.985702 12903 solver.cpp:353] Iteration 9000 (41.4466 iter/s, 2.41275s/100 iter), loss = 0.129191
I0801 13:14:00.985720 12903 solver.cpp:375]     Train net output #0: loss = 0.129191 (* 1 = 0.129191 loss)
I0801 13:14:00.985724 12903 sgd_solver.cpp:136] Iteration 9000, lr = 0.0859375, m = 0.9
I0801 13:14:02.348058 12870 data_reader.cpp:264] Starting prefetch of epoch 2
I0801 13:14:02.549327 12903 solver.cpp:353] Iteration 9100 (63.9561 iter/s, 1.56357s/100 iter), loss = 0.324097
I0801 13:14:02.549355 12903 solver.cpp:375]     Train net output #0: loss = 0.324097 (* 1 = 0.324097 loss)
I0801 13:14:02.549360 12903 sgd_solver.cpp:136] Iteration 9100, lr = 0.0857813, m = 0.9
I0801 13:14:04.111938 12903 solver.cpp:353] Iteration 9200 (63.9975 iter/s, 1.56256s/100 iter), loss = 0.387215
I0801 13:14:04.112035 12903 solver.cpp:375]     Train net output #0: loss = 0.387215 (* 1 = 0.387215 loss)
I0801 13:14:04.112043 12903 sgd_solver.cpp:136] Iteration 9200, lr = 0.085625, m = 0.9
I0801 13:14:05.696894 12903 solver.cpp:353] Iteration 9300 (63.0953 iter/s, 1.5849s/100 iter), loss = 0.318413
I0801 13:14:05.696918 12903 solver.cpp:375]     Train net output #0: loss = 0.318413 (* 1 = 0.318413 loss)
I0801 13:14:05.696921 12903 sgd_solver.cpp:136] Iteration 9300, lr = 0.0854688, m = 0.9
I0801 13:14:07.270874 12903 solver.cpp:353] Iteration 9400 (63.5351 iter/s, 1.57393s/100 iter), loss = 0.33538
I0801 13:14:07.270900 12903 solver.cpp:375]     Train net output #0: loss = 0.335381 (* 1 = 0.335381 loss)
I0801 13:14:07.270905 12903 sgd_solver.cpp:136] Iteration 9400, lr = 0.0853125, m = 0.9
I0801 13:14:08.844954 12903 solver.cpp:353] Iteration 9500 (63.5314 iter/s, 1.57403s/100 iter), loss = 0.0883561
I0801 13:14:08.844980 12903 solver.cpp:375]     Train net output #0: loss = 0.0883565 (* 1 = 0.0883565 loss)
I0801 13:14:08.844987 12903 sgd_solver.cpp:136] Iteration 9500, lr = 0.0851563, m = 0.9
I0801 13:14:10.411011 12903 solver.cpp:353] Iteration 9600 (63.8567 iter/s, 1.56601s/100 iter), loss = 0.333449
I0801 13:14:10.411039 12903 solver.cpp:375]     Train net output #0: loss = 0.33345 (* 1 = 0.33345 loss)
I0801 13:14:10.411046 12903 sgd_solver.cpp:136] Iteration 9600, lr = 0.085, m = 0.9
I0801 13:14:11.975211 12903 solver.cpp:353] Iteration 9700 (63.9326 iter/s, 1.56415s/100 iter), loss = 0.155642
I0801 13:14:11.975235 12903 solver.cpp:375]     Train net output #0: loss = 0.155643 (* 1 = 0.155643 loss)
I0801 13:14:11.975240 12903 sgd_solver.cpp:136] Iteration 9700, lr = 0.0848437, m = 0.9
I0801 13:14:13.547852 12903 solver.cpp:353] Iteration 9800 (63.5893 iter/s, 1.57259s/100 iter), loss = 0.114806
I0801 13:14:13.547878 12903 solver.cpp:375]     Train net output #0: loss = 0.114806 (* 1 = 0.114806 loss)
I0801 13:14:13.547883 12903 sgd_solver.cpp:136] Iteration 9800, lr = 0.0846875, m = 0.9
I0801 13:14:15.117142 12903 solver.cpp:353] Iteration 9900 (63.7252 iter/s, 1.56924s/100 iter), loss = 0.215342
I0801 13:14:15.117172 12903 solver.cpp:375]     Train net output #0: loss = 0.215342 (* 1 = 0.215342 loss)
I0801 13:14:15.117177 12903 sgd_solver.cpp:136] Iteration 9900, lr = 0.0845312, m = 0.9
I0801 13:14:16.665267 12903 solver.cpp:680] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/initial/cifar10_jacintonet11v2_iter_10000.caffemodel
I0801 13:14:16.682497 12903 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/initial/cifar10_jacintonet11v2_iter_10000.solverstate
I0801 13:14:16.686014 12903 solver.cpp:550] Iteration 10000, Testing net (#0)
I0801 13:14:17.490361 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.795001
I0801 13:14:17.490381 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.989706
I0801 13:14:17.490388 12903 solver.cpp:635]     Test net output #2: loss = 0.652113 (* 1 = 0.652113 loss)
I0801 13:14:17.490407 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.804367s
I0801 13:14:17.505964 12903 solver.cpp:353] Iteration 10000 (41.8629 iter/s, 2.38875s/100 iter), loss = 0.0968604
I0801 13:14:17.505982 12903 solver.cpp:375]     Train net output #0: loss = 0.0968611 (* 1 = 0.0968611 loss)
I0801 13:14:17.505987 12903 sgd_solver.cpp:136] Iteration 10000, lr = 0.084375, m = 0.9
I0801 13:14:19.076315 12903 solver.cpp:353] Iteration 10100 (63.6821 iter/s, 1.5703s/100 iter), loss = 0.247012
I0801 13:14:19.076341 12903 solver.cpp:375]     Train net output #0: loss = 0.247013 (* 1 = 0.247013 loss)
I0801 13:14:19.076347 12903 sgd_solver.cpp:136] Iteration 10100, lr = 0.0842188, m = 0.9
I0801 13:14:20.655696 12903 solver.cpp:353] Iteration 10200 (63.3179 iter/s, 1.57933s/100 iter), loss = 0.183296
I0801 13:14:20.655748 12903 solver.cpp:375]     Train net output #0: loss = 0.183297 (* 1 = 0.183297 loss)
I0801 13:14:20.655762 12903 sgd_solver.cpp:136] Iteration 10200, lr = 0.0840625, m = 0.9
I0801 13:14:22.256867 12903 solver.cpp:353] Iteration 10300 (62.4563 iter/s, 1.60112s/100 iter), loss = 0.22598
I0801 13:14:22.256894 12903 solver.cpp:375]     Train net output #0: loss = 0.225981 (* 1 = 0.225981 loss)
I0801 13:14:22.256901 12903 sgd_solver.cpp:136] Iteration 10300, lr = 0.0839063, m = 0.9
I0801 13:14:23.842947 12903 solver.cpp:353] Iteration 10400 (63.0506 iter/s, 1.58603s/100 iter), loss = 0.140279
I0801 13:14:23.842973 12903 solver.cpp:375]     Train net output #0: loss = 0.14028 (* 1 = 0.14028 loss)
I0801 13:14:23.842979 12903 sgd_solver.cpp:136] Iteration 10400, lr = 0.08375, m = 0.9
I0801 13:14:25.404311 12903 solver.cpp:353] Iteration 10500 (64.0486 iter/s, 1.56131s/100 iter), loss = 0.313812
I0801 13:14:25.404337 12903 solver.cpp:375]     Train net output #0: loss = 0.313812 (* 1 = 0.313812 loss)
I0801 13:14:25.404343 12903 sgd_solver.cpp:136] Iteration 10500, lr = 0.0835937, m = 0.9
I0801 13:14:26.987125 12903 solver.cpp:353] Iteration 10600 (63.1807 iter/s, 1.58276s/100 iter), loss = 0.27377
I0801 13:14:26.987150 12903 solver.cpp:375]     Train net output #0: loss = 0.273771 (* 1 = 0.273771 loss)
I0801 13:14:26.987154 12903 sgd_solver.cpp:136] Iteration 10600, lr = 0.0834375, m = 0.9
I0801 13:14:28.557603 12903 solver.cpp:353] Iteration 10700 (63.677 iter/s, 1.57043s/100 iter), loss = 0.184891
I0801 13:14:28.557631 12903 solver.cpp:375]     Train net output #0: loss = 0.184892 (* 1 = 0.184892 loss)
I0801 13:14:28.557636 12903 sgd_solver.cpp:136] Iteration 10700, lr = 0.0832812, m = 0.9
I0801 13:14:30.137354 12903 solver.cpp:353] Iteration 10800 (63.303 iter/s, 1.5797s/100 iter), loss = 0.201943
I0801 13:14:30.137504 12903 solver.cpp:375]     Train net output #0: loss = 0.201944 (* 1 = 0.201944 loss)
I0801 13:14:30.137522 12903 sgd_solver.cpp:136] Iteration 10800, lr = 0.083125, m = 0.9
I0801 13:14:31.701612 12903 solver.cpp:353] Iteration 10900 (63.9302 iter/s, 1.56421s/100 iter), loss = 0.157755
I0801 13:14:31.701664 12903 solver.cpp:375]     Train net output #0: loss = 0.157756 (* 1 = 0.157756 loss)
I0801 13:14:31.701678 12903 sgd_solver.cpp:136] Iteration 10900, lr = 0.0829687, m = 0.9
I0801 13:14:33.261041 12903 solver.cpp:550] Iteration 11000, Testing net (#0)
I0801 13:14:34.084204 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.666176
I0801 13:14:34.084224 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.953236
I0801 13:14:34.084228 12903 solver.cpp:635]     Test net output #2: loss = 1.38065 (* 1 = 1.38065 loss)
I0801 13:14:34.084245 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.82318s
I0801 13:14:34.099776 12903 solver.cpp:353] Iteration 11000 (41.6998 iter/s, 2.39809s/100 iter), loss = 0.0286317
I0801 13:14:34.099794 12903 solver.cpp:375]     Train net output #0: loss = 0.0286323 (* 1 = 0.0286323 loss)
I0801 13:14:34.099800 12903 sgd_solver.cpp:136] Iteration 11000, lr = 0.0828125, m = 0.9
I0801 13:14:35.670325 12903 solver.cpp:353] Iteration 11100 (63.6741 iter/s, 1.5705s/100 iter), loss = 0.114052
I0801 13:14:35.670405 12903 solver.cpp:375]     Train net output #0: loss = 0.114053 (* 1 = 0.114053 loss)
I0801 13:14:35.670413 12903 sgd_solver.cpp:136] Iteration 11100, lr = 0.0826563, m = 0.9
I0801 13:14:37.247364 12903 solver.cpp:353] Iteration 11200 (63.412 iter/s, 1.57699s/100 iter), loss = 0.0629293
I0801 13:14:37.247453 12903 solver.cpp:375]     Train net output #0: loss = 0.06293 (* 1 = 0.06293 loss)
I0801 13:14:37.247462 12903 sgd_solver.cpp:136] Iteration 11200, lr = 0.0825, m = 0.9
I0801 13:14:38.828712 12903 solver.cpp:353] Iteration 11300 (63.2392 iter/s, 1.5813s/100 iter), loss = 0.140887
I0801 13:14:38.828738 12903 solver.cpp:375]     Train net output #0: loss = 0.140887 (* 1 = 0.140887 loss)
I0801 13:14:38.828744 12903 sgd_solver.cpp:136] Iteration 11300, lr = 0.0823437, m = 0.9
I0801 13:14:40.411739 12903 solver.cpp:353] Iteration 11400 (63.1721 iter/s, 1.58298s/100 iter), loss = 0.18077
I0801 13:14:40.411768 12903 solver.cpp:375]     Train net output #0: loss = 0.180771 (* 1 = 0.180771 loss)
I0801 13:14:40.411775 12903 sgd_solver.cpp:136] Iteration 11400, lr = 0.0821875, m = 0.9
I0801 13:14:41.991463 12903 solver.cpp:353] Iteration 11500 (63.3042 iter/s, 1.57967s/100 iter), loss = 0.215835
I0801 13:14:41.991488 12903 solver.cpp:375]     Train net output #0: loss = 0.215835 (* 1 = 0.215835 loss)
I0801 13:14:41.991494 12903 sgd_solver.cpp:136] Iteration 11500, lr = 0.0820312, m = 0.9
I0801 13:14:43.566066 12903 solver.cpp:353] Iteration 11600 (63.5102 iter/s, 1.57455s/100 iter), loss = 0.39012
I0801 13:14:43.566093 12903 solver.cpp:375]     Train net output #0: loss = 0.39012 (* 1 = 0.39012 loss)
I0801 13:14:43.566099 12903 sgd_solver.cpp:136] Iteration 11600, lr = 0.081875, m = 0.9
I0801 13:14:45.122215 12903 solver.cpp:353] Iteration 11700 (64.2633 iter/s, 1.5561s/100 iter), loss = 0.0656421
I0801 13:14:45.122241 12903 solver.cpp:375]     Train net output #0: loss = 0.0656427 (* 1 = 0.0656427 loss)
I0801 13:14:45.122246 12903 sgd_solver.cpp:136] Iteration 11700, lr = 0.0817188, m = 0.9
I0801 13:14:46.689723 12903 solver.cpp:353] Iteration 11800 (63.7975 iter/s, 1.56746s/100 iter), loss = 0.0495864
I0801 13:14:46.689761 12903 solver.cpp:375]     Train net output #0: loss = 0.049587 (* 1 = 0.049587 loss)
I0801 13:14:46.689772 12903 sgd_solver.cpp:136] Iteration 11800, lr = 0.0815625, m = 0.9
I0801 13:14:48.275430 12903 solver.cpp:353] Iteration 11900 (63.0653 iter/s, 1.58566s/100 iter), loss = 0.307851
I0801 13:14:48.275456 12903 solver.cpp:375]     Train net output #0: loss = 0.307851 (* 1 = 0.307851 loss)
I0801 13:14:48.275463 12903 sgd_solver.cpp:136] Iteration 11900, lr = 0.0814063, m = 0.9
I0801 13:14:49.819017 12903 solver.cpp:550] Iteration 12000, Testing net (#0)
I0801 13:14:50.635424 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.786471
I0801 13:14:50.635444 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.987647
I0801 13:14:50.635452 12903 solver.cpp:635]     Test net output #2: loss = 0.7812 (* 1 = 0.7812 loss)
I0801 13:14:50.635469 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.816429s
I0801 13:14:50.651510 12903 solver.cpp:353] Iteration 12000 (42.0874 iter/s, 2.37601s/100 iter), loss = 0.031052
I0801 13:14:50.651528 12903 solver.cpp:375]     Train net output #0: loss = 0.0310526 (* 1 = 0.0310526 loss)
I0801 13:14:50.651535 12903 sgd_solver.cpp:136] Iteration 12000, lr = 0.08125, m = 0.9
I0801 13:14:52.239353 12903 solver.cpp:353] Iteration 12100 (62.9806 iter/s, 1.58779s/100 iter), loss = 0.0276272
I0801 13:14:52.239408 12903 solver.cpp:375]     Train net output #0: loss = 0.0276278 (* 1 = 0.0276278 loss)
I0801 13:14:52.239420 12903 sgd_solver.cpp:136] Iteration 12100, lr = 0.0810938, m = 0.9
I0801 13:14:53.814644 12903 solver.cpp:353] Iteration 12200 (63.4824 iter/s, 1.57524s/100 iter), loss = 0.0802128
I0801 13:14:53.814669 12903 solver.cpp:375]     Train net output #0: loss = 0.0802134 (* 1 = 0.0802134 loss)
I0801 13:14:53.814674 12903 sgd_solver.cpp:136] Iteration 12200, lr = 0.0809375, m = 0.9
I0801 13:14:55.385556 12903 solver.cpp:353] Iteration 12300 (63.6593 iter/s, 1.57086s/100 iter), loss = 0.0586162
I0801 13:14:55.385596 12903 solver.cpp:375]     Train net output #0: loss = 0.0586169 (* 1 = 0.0586169 loss)
I0801 13:14:55.385602 12903 sgd_solver.cpp:136] Iteration 12300, lr = 0.0807813, m = 0.9
I0801 13:14:56.991448 12903 solver.cpp:353] Iteration 12400 (62.2727 iter/s, 1.60584s/100 iter), loss = 0.109059
I0801 13:14:56.991472 12903 solver.cpp:375]     Train net output #0: loss = 0.10906 (* 1 = 0.10906 loss)
I0801 13:14:56.991478 12903 sgd_solver.cpp:136] Iteration 12400, lr = 0.080625, m = 0.9
I0801 13:14:58.561775 12903 solver.cpp:353] Iteration 12500 (63.6831 iter/s, 1.57028s/100 iter), loss = 0.210456
I0801 13:14:58.561826 12903 solver.cpp:375]     Train net output #0: loss = 0.210456 (* 1 = 0.210456 loss)
I0801 13:14:58.561841 12903 sgd_solver.cpp:136] Iteration 12500, lr = 0.0804688, m = 0.9
I0801 13:15:00.150984 12903 solver.cpp:353] Iteration 12600 (62.9266 iter/s, 1.58915s/100 iter), loss = 0.502962
I0801 13:15:00.151013 12903 solver.cpp:375]     Train net output #0: loss = 0.502963 (* 1 = 0.502963 loss)
I0801 13:15:00.151021 12903 sgd_solver.cpp:136] Iteration 12600, lr = 0.0803125, m = 0.9
I0801 13:15:01.724153 12903 solver.cpp:353] Iteration 12700 (63.5679 iter/s, 1.57312s/100 iter), loss = 0.212604
I0801 13:15:01.724242 12903 solver.cpp:375]     Train net output #0: loss = 0.212605 (* 1 = 0.212605 loss)
I0801 13:15:01.724264 12903 sgd_solver.cpp:136] Iteration 12700, lr = 0.0801563, m = 0.9
I0801 13:15:03.324414 12903 solver.cpp:353] Iteration 12800 (62.4918 iter/s, 1.60021s/100 iter), loss = 0.308461
I0801 13:15:03.324465 12903 solver.cpp:375]     Train net output #0: loss = 0.308462 (* 1 = 0.308462 loss)
I0801 13:15:03.324479 12903 sgd_solver.cpp:136] Iteration 12800, lr = 0.08, m = 0.9
I0801 13:15:04.910869 12903 solver.cpp:353] Iteration 12900 (63.0356 iter/s, 1.58641s/100 iter), loss = 0.0632347
I0801 13:15:04.910895 12903 solver.cpp:375]     Train net output #0: loss = 0.0632353 (* 1 = 0.0632353 loss)
I0801 13:15:04.910902 12903 sgd_solver.cpp:136] Iteration 12900, lr = 0.0798438, m = 0.9
I0801 13:15:06.463152 12903 solver.cpp:550] Iteration 13000, Testing net (#0)
I0801 13:15:07.283565 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.828825
I0801 13:15:07.283586 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.987353
I0801 13:15:07.283591 12903 solver.cpp:635]     Test net output #2: loss = 0.543 (* 1 = 0.543 loss)
I0801 13:15:07.283610 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.820436s
I0801 13:15:07.301355 12903 solver.cpp:353] Iteration 13000 (41.8338 iter/s, 2.39041s/100 iter), loss = 0.0616847
I0801 13:15:07.301373 12903 solver.cpp:375]     Train net output #0: loss = 0.0616853 (* 1 = 0.0616853 loss)
I0801 13:15:07.301378 12903 sgd_solver.cpp:136] Iteration 13000, lr = 0.0796875, m = 0.9
I0801 13:15:08.872885 12903 solver.cpp:353] Iteration 13100 (63.6345 iter/s, 1.57147s/100 iter), loss = 0.191889
I0801 13:15:08.872939 12903 solver.cpp:375]     Train net output #0: loss = 0.19189 (* 1 = 0.19189 loss)
I0801 13:15:08.872953 12903 sgd_solver.cpp:136] Iteration 13100, lr = 0.0795313, m = 0.9
I0801 13:15:10.476745 12903 solver.cpp:353] Iteration 13200 (62.3515 iter/s, 1.60381s/100 iter), loss = 0.26734
I0801 13:15:10.476775 12903 solver.cpp:375]     Train net output #0: loss = 0.26734 (* 1 = 0.26734 loss)
I0801 13:15:10.476783 12903 sgd_solver.cpp:136] Iteration 13200, lr = 0.079375, m = 0.9
I0801 13:15:12.040865 12903 solver.cpp:353] Iteration 13300 (63.9357 iter/s, 1.56407s/100 iter), loss = 0.050729
I0801 13:15:12.040891 12903 solver.cpp:375]     Train net output #0: loss = 0.0507296 (* 1 = 0.0507296 loss)
I0801 13:15:12.040897 12903 sgd_solver.cpp:136] Iteration 13300, lr = 0.0792188, m = 0.9
I0801 13:15:13.612516 12903 solver.cpp:353] Iteration 13400 (63.6294 iter/s, 1.5716s/100 iter), loss = 0.0947752
I0801 13:15:13.612542 12903 solver.cpp:375]     Train net output #0: loss = 0.0947758 (* 1 = 0.0947758 loss)
I0801 13:15:13.612548 12903 sgd_solver.cpp:136] Iteration 13400, lr = 0.0790625, m = 0.9
I0801 13:15:15.199750 12903 solver.cpp:353] Iteration 13500 (63.0047 iter/s, 1.58718s/100 iter), loss = 0.318299
I0801 13:15:15.199774 12903 solver.cpp:375]     Train net output #0: loss = 0.3183 (* 1 = 0.3183 loss)
I0801 13:15:15.199780 12903 sgd_solver.cpp:136] Iteration 13500, lr = 0.0789063, m = 0.9
I0801 13:15:16.778798 12903 solver.cpp:353] Iteration 13600 (63.3314 iter/s, 1.57899s/100 iter), loss = 0.0254486
I0801 13:15:16.778869 12903 solver.cpp:375]     Train net output #0: loss = 0.0254492 (* 1 = 0.0254492 loss)
I0801 13:15:16.778890 12903 sgd_solver.cpp:136] Iteration 13600, lr = 0.07875, m = 0.9
I0801 13:15:17.302585 12870 data_reader.cpp:264] Starting prefetch of epoch 3
I0801 13:15:18.363423 12903 solver.cpp:353] Iteration 13700 (63.1083 iter/s, 1.58458s/100 iter), loss = 0.0738615
I0801 13:15:18.363447 12903 solver.cpp:375]     Train net output #0: loss = 0.0738621 (* 1 = 0.0738621 loss)
I0801 13:15:18.363454 12903 sgd_solver.cpp:136] Iteration 13700, lr = 0.0785938, m = 0.9
I0801 13:15:19.934172 12903 solver.cpp:353] Iteration 13800 (63.666 iter/s, 1.5707s/100 iter), loss = 0.176015
I0801 13:15:19.934197 12903 solver.cpp:375]     Train net output #0: loss = 0.176016 (* 1 = 0.176016 loss)
I0801 13:15:19.934203 12903 sgd_solver.cpp:136] Iteration 13800, lr = 0.0784375, m = 0.9
I0801 13:15:21.513840 12903 solver.cpp:353] Iteration 13900 (63.3064 iter/s, 1.57962s/100 iter), loss = 0.0669967
I0801 13:15:21.513865 12903 solver.cpp:375]     Train net output #0: loss = 0.0669973 (* 1 = 0.0669973 loss)
I0801 13:15:21.513870 12903 sgd_solver.cpp:136] Iteration 13900, lr = 0.0782812, m = 0.9
I0801 13:15:23.086127 12903 solver.cpp:550] Iteration 14000, Testing net (#0)
I0801 13:15:23.936877 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.803825
I0801 13:15:23.936894 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.976765
I0801 13:15:23.936899 12903 solver.cpp:635]     Test net output #2: loss = 0.778601 (* 1 = 0.778601 loss)
I0801 13:15:23.936918 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.850765s
I0801 13:15:23.952594 12903 solver.cpp:353] Iteration 14000 (41.0058 iter/s, 2.43868s/100 iter), loss = 0.0218137
I0801 13:15:23.952623 12903 solver.cpp:375]     Train net output #0: loss = 0.0218143 (* 1 = 0.0218143 loss)
I0801 13:15:23.952627 12903 sgd_solver.cpp:136] Iteration 14000, lr = 0.078125, m = 0.9
I0801 13:15:25.531596 12903 solver.cpp:353] Iteration 14100 (63.3334 iter/s, 1.57895s/100 iter), loss = 0.179836
I0801 13:15:25.531625 12903 solver.cpp:375]     Train net output #0: loss = 0.179837 (* 1 = 0.179837 loss)
I0801 13:15:25.531632 12903 sgd_solver.cpp:136] Iteration 14100, lr = 0.0779688, m = 0.9
I0801 13:15:27.156195 12903 solver.cpp:353] Iteration 14200 (61.5555 iter/s, 1.62455s/100 iter), loss = 0.118573
I0801 13:15:27.156268 12903 solver.cpp:375]     Train net output #0: loss = 0.118574 (* 1 = 0.118574 loss)
I0801 13:15:27.156289 12903 sgd_solver.cpp:136] Iteration 14200, lr = 0.0778125, m = 0.9
I0801 13:15:28.731712 12903 solver.cpp:353] Iteration 14300 (63.4733 iter/s, 1.57547s/100 iter), loss = 0.10363
I0801 13:15:28.731739 12903 solver.cpp:375]     Train net output #0: loss = 0.103631 (* 1 = 0.103631 loss)
I0801 13:15:28.731745 12903 sgd_solver.cpp:136] Iteration 14300, lr = 0.0776563, m = 0.9
I0801 13:15:30.320605 12903 solver.cpp:353] Iteration 14400 (62.9389 iter/s, 1.58884s/100 iter), loss = 0.0805124
I0801 13:15:30.320633 12903 solver.cpp:375]     Train net output #0: loss = 0.080513 (* 1 = 0.080513 loss)
I0801 13:15:30.320639 12903 sgd_solver.cpp:136] Iteration 14400, lr = 0.0775, m = 0.9
I0801 13:15:31.881691 12903 solver.cpp:353] Iteration 14500 (64.06 iter/s, 1.56104s/100 iter), loss = 0.0920467
I0801 13:15:31.881716 12903 solver.cpp:375]     Train net output #0: loss = 0.0920474 (* 1 = 0.0920474 loss)
I0801 13:15:31.881721 12903 sgd_solver.cpp:136] Iteration 14500, lr = 0.0773438, m = 0.9
I0801 13:15:33.450800 12903 solver.cpp:353] Iteration 14600 (63.7324 iter/s, 1.56906s/100 iter), loss = 0.153982
I0801 13:15:33.450826 12903 solver.cpp:375]     Train net output #0: loss = 0.153983 (* 1 = 0.153983 loss)
I0801 13:15:33.450832 12903 sgd_solver.cpp:136] Iteration 14600, lr = 0.0771875, m = 0.9
I0801 13:15:35.018544 12903 solver.cpp:353] Iteration 14700 (63.788 iter/s, 1.56769s/100 iter), loss = 0.0648973
I0801 13:15:35.018647 12903 solver.cpp:375]     Train net output #0: loss = 0.0648978 (* 1 = 0.0648978 loss)
I0801 13:15:35.018663 12903 sgd_solver.cpp:136] Iteration 14700, lr = 0.0770312, m = 0.9
I0801 13:15:36.605067 12903 solver.cpp:353] Iteration 14800 (63.0329 iter/s, 1.58647s/100 iter), loss = 0.230067
I0801 13:15:36.605139 12903 solver.cpp:375]     Train net output #0: loss = 0.230068 (* 1 = 0.230068 loss)
I0801 13:15:36.605147 12903 sgd_solver.cpp:136] Iteration 14800, lr = 0.076875, m = 0.9
I0801 13:15:38.162236 12903 solver.cpp:353] Iteration 14900 (64.2212 iter/s, 1.55712s/100 iter), loss = 0.2231
I0801 13:15:38.162261 12903 solver.cpp:375]     Train net output #0: loss = 0.2231 (* 1 = 0.2231 loss)
I0801 13:15:38.162266 12903 sgd_solver.cpp:136] Iteration 14900, lr = 0.0767187, m = 0.9
I0801 13:15:39.729168 12903 solver.cpp:550] Iteration 15000, Testing net (#0)
I0801 13:15:40.544236 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.79353
I0801 13:15:40.544256 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.982941
I0801 13:15:40.544263 12903 solver.cpp:635]     Test net output #2: loss = 0.730555 (* 1 = 0.730555 loss)
I0801 13:15:40.544281 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.815089s
I0801 13:15:40.560045 12903 solver.cpp:353] Iteration 15000 (41.706 iter/s, 2.39774s/100 iter), loss = 0.147933
I0801 13:15:40.560065 12903 solver.cpp:375]     Train net output #0: loss = 0.147933 (* 1 = 0.147933 loss)
I0801 13:15:40.560071 12903 sgd_solver.cpp:136] Iteration 15000, lr = 0.0765625, m = 0.9
I0801 13:15:42.127401 12903 solver.cpp:353] Iteration 15100 (63.8038 iter/s, 1.5673s/100 iter), loss = 0.11041
I0801 13:15:42.127452 12903 solver.cpp:375]     Train net output #0: loss = 0.11041 (* 1 = 0.11041 loss)
I0801 13:15:42.127465 12903 sgd_solver.cpp:136] Iteration 15100, lr = 0.0764063, m = 0.9
I0801 13:15:43.701954 12903 solver.cpp:353] Iteration 15200 (63.5122 iter/s, 1.5745s/100 iter), loss = 0.0395188
I0801 13:15:43.702003 12903 solver.cpp:375]     Train net output #0: loss = 0.0395194 (* 1 = 0.0395194 loss)
I0801 13:15:43.702016 12903 sgd_solver.cpp:136] Iteration 15200, lr = 0.07625, m = 0.9
I0801 13:15:45.278079 12903 solver.cpp:353] Iteration 15300 (63.4487 iter/s, 1.57608s/100 iter), loss = 0.107459
I0801 13:15:45.278126 12903 solver.cpp:375]     Train net output #0: loss = 0.10746 (* 1 = 0.10746 loss)
I0801 13:15:45.278138 12903 sgd_solver.cpp:136] Iteration 15300, lr = 0.0760938, m = 0.9
I0801 13:15:46.834820 12903 solver.cpp:353] Iteration 15400 (64.239 iter/s, 1.55669s/100 iter), loss = 0.132986
I0801 13:15:46.834846 12903 solver.cpp:375]     Train net output #0: loss = 0.132987 (* 1 = 0.132987 loss)
I0801 13:15:46.834853 12903 sgd_solver.cpp:136] Iteration 15400, lr = 0.0759375, m = 0.9
I0801 13:15:48.405814 12903 solver.cpp:353] Iteration 15500 (63.6559 iter/s, 1.57095s/100 iter), loss = 0.0621492
I0801 13:15:48.405838 12903 solver.cpp:375]     Train net output #0: loss = 0.0621499 (* 1 = 0.0621499 loss)
I0801 13:15:48.405844 12903 sgd_solver.cpp:136] Iteration 15500, lr = 0.0757812, m = 0.9
I0801 13:15:49.988392 12903 solver.cpp:353] Iteration 15600 (63.19 iter/s, 1.58253s/100 iter), loss = 0.0472353
I0801 13:15:49.988417 12903 solver.cpp:375]     Train net output #0: loss = 0.047236 (* 1 = 0.047236 loss)
I0801 13:15:49.988421 12903 sgd_solver.cpp:136] Iteration 15600, lr = 0.075625, m = 0.9
I0801 13:15:51.547634 12903 solver.cpp:353] Iteration 15700 (64.1358 iter/s, 1.55919s/100 iter), loss = 0.153151
I0801 13:15:51.547660 12903 solver.cpp:375]     Train net output #0: loss = 0.153152 (* 1 = 0.153152 loss)
I0801 13:15:51.547667 12903 sgd_solver.cpp:136] Iteration 15700, lr = 0.0754687, m = 0.9
I0801 13:15:53.126308 12903 solver.cpp:353] Iteration 15800 (63.3463 iter/s, 1.57862s/100 iter), loss = 0.156411
I0801 13:15:53.126333 12903 solver.cpp:375]     Train net output #0: loss = 0.156412 (* 1 = 0.156412 loss)
I0801 13:15:53.126339 12903 sgd_solver.cpp:136] Iteration 15800, lr = 0.0753125, m = 0.9
I0801 13:15:54.695632 12903 solver.cpp:353] Iteration 15900 (63.7237 iter/s, 1.56927s/100 iter), loss = 0.295374
I0801 13:15:54.695659 12903 solver.cpp:375]     Train net output #0: loss = 0.295374 (* 1 = 0.295374 loss)
I0801 13:15:54.695667 12903 sgd_solver.cpp:136] Iteration 15900, lr = 0.0751562, m = 0.9
I0801 13:15:56.270628 12903 solver.cpp:550] Iteration 16000, Testing net (#0)
I0801 13:15:56.946890 12913 blocking_queue.cpp:40] Waiting for datum
I0801 13:15:57.088625 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.815001
I0801 13:15:57.088647 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.97853
I0801 13:15:57.088655 12903 solver.cpp:635]     Test net output #2: loss = 0.798367 (* 1 = 0.798367 loss)
I0801 13:15:57.088673 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.818021s
I0801 13:15:57.104346 12903 solver.cpp:353] Iteration 16000 (41.5172 iter/s, 2.40864s/100 iter), loss = 0.158883
I0801 13:15:57.104362 12903 solver.cpp:375]     Train net output #0: loss = 0.158883 (* 1 = 0.158883 loss)
I0801 13:15:57.104368 12903 sgd_solver.cpp:136] Iteration 16000, lr = 0.075, m = 0.9
I0801 13:15:58.674341 12903 solver.cpp:353] Iteration 16100 (63.6966 iter/s, 1.56994s/100 iter), loss = 0.0435842
I0801 13:15:58.674370 12903 solver.cpp:375]     Train net output #0: loss = 0.043585 (* 1 = 0.043585 loss)
I0801 13:15:58.674376 12903 sgd_solver.cpp:136] Iteration 16100, lr = 0.0748438, m = 0.9
I0801 13:16:00.233573 12903 solver.cpp:353] Iteration 16200 (64.1363 iter/s, 1.55918s/100 iter), loss = 0.203749
I0801 13:16:00.233599 12903 solver.cpp:375]     Train net output #0: loss = 0.203749 (* 1 = 0.203749 loss)
I0801 13:16:00.233605 12903 sgd_solver.cpp:136] Iteration 16200, lr = 0.0746875, m = 0.9
I0801 13:16:01.787672 12903 solver.cpp:353] Iteration 16300 (64.348 iter/s, 1.55405s/100 iter), loss = 0.0404613
I0801 13:16:01.787698 12903 solver.cpp:375]     Train net output #0: loss = 0.040462 (* 1 = 0.040462 loss)
I0801 13:16:01.787703 12903 sgd_solver.cpp:136] Iteration 16300, lr = 0.0745312, m = 0.9
I0801 13:16:03.363639 12903 solver.cpp:353] Iteration 16400 (63.4551 iter/s, 1.57592s/100 iter), loss = 0.068397
I0801 13:16:03.363668 12903 solver.cpp:375]     Train net output #0: loss = 0.0683977 (* 1 = 0.0683977 loss)
I0801 13:16:03.363677 12903 sgd_solver.cpp:136] Iteration 16400, lr = 0.074375, m = 0.9
I0801 13:16:04.927234 12903 solver.cpp:353] Iteration 16500 (63.9572 iter/s, 1.56355s/100 iter), loss = 0.0644417
I0801 13:16:04.927258 12903 solver.cpp:375]     Train net output #0: loss = 0.0644423 (* 1 = 0.0644423 loss)
I0801 13:16:04.927264 12903 sgd_solver.cpp:136] Iteration 16500, lr = 0.0742188, m = 0.9
I0801 13:16:06.483500 12903 solver.cpp:353] Iteration 16600 (64.2584 iter/s, 1.55622s/100 iter), loss = 0.0465417
I0801 13:16:06.483528 12903 solver.cpp:375]     Train net output #0: loss = 0.0465424 (* 1 = 0.0465424 loss)
I0801 13:16:06.483534 12903 sgd_solver.cpp:136] Iteration 16600, lr = 0.0740625, m = 0.9
I0801 13:16:08.043642 12903 solver.cpp:353] Iteration 16700 (64.0988 iter/s, 1.56009s/100 iter), loss = 0.0663972
I0801 13:16:08.043726 12903 solver.cpp:375]     Train net output #0: loss = 0.0663977 (* 1 = 0.0663977 loss)
I0801 13:16:08.043733 12903 sgd_solver.cpp:136] Iteration 16700, lr = 0.0739063, m = 0.9
I0801 13:16:09.614581 12903 solver.cpp:353] Iteration 16800 (63.6581 iter/s, 1.57089s/100 iter), loss = 0.00790468
I0801 13:16:09.614608 12903 solver.cpp:375]     Train net output #0: loss = 0.00790514 (* 1 = 0.00790514 loss)
I0801 13:16:09.614614 12903 sgd_solver.cpp:136] Iteration 16800, lr = 0.07375, m = 0.9
I0801 13:16:11.184695 12903 solver.cpp:353] Iteration 16900 (63.6917 iter/s, 1.57006s/100 iter), loss = 0.00988932
I0801 13:16:11.184743 12903 solver.cpp:375]     Train net output #0: loss = 0.00988976 (* 1 = 0.00988976 loss)
I0801 13:16:11.184756 12903 sgd_solver.cpp:136] Iteration 16900, lr = 0.0735938, m = 0.9
I0801 13:16:12.740751 12903 solver.cpp:550] Iteration 17000, Testing net (#0)
I0801 13:16:13.559648 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.776178
I0801 13:16:13.559669 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.976765
I0801 13:16:13.559675 12903 solver.cpp:635]     Test net output #2: loss = 0.986495 (* 1 = 0.986495 loss)
I0801 13:16:13.559695 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.81892s
I0801 13:16:13.575240 12903 solver.cpp:353] Iteration 17000 (41.8327 iter/s, 2.39048s/100 iter), loss = 0.429367
I0801 13:16:13.575256 12903 solver.cpp:375]     Train net output #0: loss = 0.429367 (* 1 = 0.429367 loss)
I0801 13:16:13.575263 12903 sgd_solver.cpp:136] Iteration 17000, lr = 0.0734375, m = 0.9
I0801 13:16:15.141163 12903 solver.cpp:353] Iteration 17100 (63.8623 iter/s, 1.56587s/100 iter), loss = 0.0869716
I0801 13:16:15.141216 12903 solver.cpp:375]     Train net output #0: loss = 0.086972 (* 1 = 0.086972 loss)
I0801 13:16:15.141232 12903 sgd_solver.cpp:136] Iteration 17100, lr = 0.0732813, m = 0.9
I0801 13:16:16.699821 12903 solver.cpp:353] Iteration 17200 (64.1599 iter/s, 1.55861s/100 iter), loss = 0.038889
I0801 13:16:16.699846 12903 solver.cpp:375]     Train net output #0: loss = 0.0388895 (* 1 = 0.0388895 loss)
I0801 13:16:16.699852 12903 sgd_solver.cpp:136] Iteration 17200, lr = 0.073125, m = 0.9
I0801 13:16:18.273562 12903 solver.cpp:353] Iteration 17300 (63.5448 iter/s, 1.57369s/100 iter), loss = 0.0269961
I0801 13:16:18.273588 12903 solver.cpp:375]     Train net output #0: loss = 0.0269965 (* 1 = 0.0269965 loss)
I0801 13:16:18.273594 12903 sgd_solver.cpp:136] Iteration 17300, lr = 0.0729688, m = 0.9
I0801 13:16:19.849478 12903 solver.cpp:353] Iteration 17400 (63.4572 iter/s, 1.57587s/100 iter), loss = 0.123826
I0801 13:16:19.849501 12903 solver.cpp:375]     Train net output #0: loss = 0.123826 (* 1 = 0.123826 loss)
I0801 13:16:19.849506 12903 sgd_solver.cpp:136] Iteration 17400, lr = 0.0728125, m = 0.9
I0801 13:16:21.411478 12903 solver.cpp:353] Iteration 17500 (64.0225 iter/s, 1.56195s/100 iter), loss = 0.190857
I0801 13:16:21.411500 12903 solver.cpp:375]     Train net output #0: loss = 0.190858 (* 1 = 0.190858 loss)
I0801 13:16:21.411505 12903 sgd_solver.cpp:136] Iteration 17500, lr = 0.0726563, m = 0.9
I0801 13:16:22.977277 12903 solver.cpp:353] Iteration 17600 (63.8673 iter/s, 1.56575s/100 iter), loss = 0.0515884
I0801 13:16:22.977336 12903 solver.cpp:375]     Train net output #0: loss = 0.0515889 (* 1 = 0.0515889 loss)
I0801 13:16:22.977352 12903 sgd_solver.cpp:136] Iteration 17600, lr = 0.0725, m = 0.9
I0801 13:16:24.538825 12903 solver.cpp:353] Iteration 17700 (64.041 iter/s, 1.5615s/100 iter), loss = 0.173723
I0801 13:16:24.538856 12903 solver.cpp:375]     Train net output #0: loss = 0.173724 (* 1 = 0.173724 loss)
I0801 13:16:24.538862 12903 sgd_solver.cpp:136] Iteration 17700, lr = 0.0723438, m = 0.9
I0801 13:16:26.109226 12903 solver.cpp:353] Iteration 17800 (63.6799 iter/s, 1.57035s/100 iter), loss = 0.0634107
I0801 13:16:26.109277 12903 solver.cpp:375]     Train net output #0: loss = 0.0634112 (* 1 = 0.0634112 loss)
I0801 13:16:26.109284 12903 sgd_solver.cpp:136] Iteration 17800, lr = 0.0721875, m = 0.9
I0801 13:16:27.663343 12903 solver.cpp:353] Iteration 17900 (64.3474 iter/s, 1.55406s/100 iter), loss = 0.342297
I0801 13:16:27.663393 12903 solver.cpp:375]     Train net output #0: loss = 0.342297 (* 1 = 0.342297 loss)
I0801 13:16:27.663400 12903 sgd_solver.cpp:136] Iteration 17900, lr = 0.0720313, m = 0.9
I0801 13:16:29.239886 12903 solver.cpp:550] Iteration 18000, Testing net (#0)
I0801 13:16:29.716502 12893 data_reader.cpp:264] Starting prefetch of epoch 2
I0801 13:16:30.064829 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.736177
I0801 13:16:30.064849 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.985294
I0801 13:16:30.064854 12903 solver.cpp:635]     Test net output #2: loss = 1.34523 (* 1 = 1.34523 loss)
I0801 13:16:30.064872 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.824963s
I0801 13:16:30.080520 12903 solver.cpp:353] Iteration 18000 (41.3718 iter/s, 2.41711s/100 iter), loss = 0.0494345
I0801 13:16:30.080551 12903 solver.cpp:375]     Train net output #0: loss = 0.049435 (* 1 = 0.049435 loss)
I0801 13:16:30.080564 12903 sgd_solver.cpp:136] Iteration 18000, lr = 0.071875, m = 0.9
I0801 13:16:31.652369 12903 solver.cpp:353] Iteration 18100 (63.6214 iter/s, 1.5718s/100 iter), loss = 0.00731387
I0801 13:16:31.652416 12903 solver.cpp:375]     Train net output #0: loss = 0.0073145 (* 1 = 0.0073145 loss)
I0801 13:16:31.652429 12903 sgd_solver.cpp:136] Iteration 18100, lr = 0.0717188, m = 0.9
I0801 13:16:33.210959 12903 solver.cpp:353] Iteration 18200 (64.1626 iter/s, 1.55854s/100 iter), loss = 0.0181449
I0801 13:16:33.210984 12903 solver.cpp:375]     Train net output #0: loss = 0.0181455 (* 1 = 0.0181455 loss)
I0801 13:16:33.210990 12903 sgd_solver.cpp:136] Iteration 18200, lr = 0.0715625, m = 0.9
I0801 13:16:34.775666 12903 solver.cpp:353] Iteration 18300 (63.9117 iter/s, 1.56466s/100 iter), loss = 0.0653655
I0801 13:16:34.775715 12903 solver.cpp:375]     Train net output #0: loss = 0.0653662 (* 1 = 0.0653662 loss)
I0801 13:16:34.775729 12903 sgd_solver.cpp:136] Iteration 18300, lr = 0.0714063, m = 0.9
I0801 13:16:36.358712 12903 solver.cpp:353] Iteration 18400 (63.1714 iter/s, 1.583s/100 iter), loss = 0.0643747
I0801 13:16:36.358741 12903 solver.cpp:375]     Train net output #0: loss = 0.0643754 (* 1 = 0.0643754 loss)
I0801 13:16:36.358745 12903 sgd_solver.cpp:136] Iteration 18400, lr = 0.07125, m = 0.9
I0801 13:16:37.941381 12903 solver.cpp:353] Iteration 18500 (63.1864 iter/s, 1.58262s/100 iter), loss = 0.084998
I0801 13:16:37.941417 12903 solver.cpp:375]     Train net output #0: loss = 0.0849987 (* 1 = 0.0849987 loss)
I0801 13:16:37.941427 12903 sgd_solver.cpp:136] Iteration 18500, lr = 0.0710938, m = 0.9
I0801 13:16:39.517455 12903 solver.cpp:353] Iteration 18600 (63.4509 iter/s, 1.57602s/100 iter), loss = 0.246818
I0801 13:16:39.517518 12903 solver.cpp:375]     Train net output #0: loss = 0.246818 (* 1 = 0.246818 loss)
I0801 13:16:39.517524 12903 sgd_solver.cpp:136] Iteration 18600, lr = 0.0709375, m = 0.9
I0801 13:16:41.098078 12903 solver.cpp:353] Iteration 18700 (63.2682 iter/s, 1.58057s/100 iter), loss = 0.179071
I0801 13:16:41.098103 12903 solver.cpp:375]     Train net output #0: loss = 0.179072 (* 1 = 0.179072 loss)
I0801 13:16:41.098106 12903 sgd_solver.cpp:136] Iteration 18700, lr = 0.0707813, m = 0.9
I0801 13:16:42.654813 12903 solver.cpp:353] Iteration 18800 (64.2392 iter/s, 1.55668s/100 iter), loss = 0.0873211
I0801 13:16:42.654839 12903 solver.cpp:375]     Train net output #0: loss = 0.0873217 (* 1 = 0.0873217 loss)
I0801 13:16:42.654844 12903 sgd_solver.cpp:136] Iteration 18800, lr = 0.070625, m = 0.9
I0801 13:16:44.235460 12903 solver.cpp:353] Iteration 18900 (63.2673 iter/s, 1.5806s/100 iter), loss = 0.0394266
I0801 13:16:44.235550 12903 solver.cpp:375]     Train net output #0: loss = 0.0394273 (* 1 = 0.0394273 loss)
I0801 13:16:44.235572 12903 sgd_solver.cpp:136] Iteration 18900, lr = 0.0704687, m = 0.9
I0801 13:16:45.793783 12903 solver.cpp:550] Iteration 19000, Testing net (#0)
I0801 13:16:46.610960 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.844119
I0801 13:16:46.610977 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.991765
I0801 13:16:46.610985 12903 solver.cpp:635]     Test net output #2: loss = 0.5505 (* 1 = 0.5505 loss)
I0801 13:16:46.611002 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.817196s
I0801 13:16:46.626462 12903 solver.cpp:353] Iteration 19000 (41.8246 iter/s, 2.39094s/100 iter), loss = 0.206606
I0801 13:16:46.626478 12903 solver.cpp:375]     Train net output #0: loss = 0.206607 (* 1 = 0.206607 loss)
I0801 13:16:46.626484 12903 sgd_solver.cpp:136] Iteration 19000, lr = 0.0703125, m = 0.9
I0801 13:16:48.202502 12903 solver.cpp:353] Iteration 19100 (63.4522 iter/s, 1.57599s/100 iter), loss = 0.133242
I0801 13:16:48.202527 12903 solver.cpp:375]     Train net output #0: loss = 0.133243 (* 1 = 0.133243 loss)
I0801 13:16:48.202533 12903 sgd_solver.cpp:136] Iteration 19100, lr = 0.0701563, m = 0.9
I0801 13:16:49.774096 12903 solver.cpp:353] Iteration 19200 (63.6317 iter/s, 1.57154s/100 iter), loss = 0.139233
I0801 13:16:49.774123 12903 solver.cpp:375]     Train net output #0: loss = 0.139234 (* 1 = 0.139234 loss)
I0801 13:16:49.774129 12903 sgd_solver.cpp:136] Iteration 19200, lr = 0.07, m = 0.9
I0801 13:16:51.329727 12903 solver.cpp:353] Iteration 19300 (64.2847 iter/s, 1.55558s/100 iter), loss = 0.0800915
I0801 13:16:51.329754 12903 solver.cpp:375]     Train net output #0: loss = 0.0800922 (* 1 = 0.0800922 loss)
I0801 13:16:51.329761 12903 sgd_solver.cpp:136] Iteration 19300, lr = 0.0698438, m = 0.9
I0801 13:16:52.899533 12903 solver.cpp:353] Iteration 19400 (63.7042 iter/s, 1.56976s/100 iter), loss = 0.0929699
I0801 13:16:52.899559 12903 solver.cpp:375]     Train net output #0: loss = 0.0929706 (* 1 = 0.0929706 loss)
I0801 13:16:52.899564 12903 sgd_solver.cpp:136] Iteration 19400, lr = 0.0696875, m = 0.9
I0801 13:16:54.468325 12903 solver.cpp:353] Iteration 19500 (63.7454 iter/s, 1.56874s/100 iter), loss = 0.145609
I0801 13:16:54.468349 12903 solver.cpp:375]     Train net output #0: loss = 0.14561 (* 1 = 0.14561 loss)
I0801 13:16:54.468355 12903 sgd_solver.cpp:136] Iteration 19500, lr = 0.0695313, m = 0.9
I0801 13:16:56.035140 12903 solver.cpp:353] Iteration 19600 (63.8257 iter/s, 1.56677s/100 iter), loss = 0.0838101
I0801 13:16:56.035171 12903 solver.cpp:375]     Train net output #0: loss = 0.0838108 (* 1 = 0.0838108 loss)
I0801 13:16:56.035177 12903 sgd_solver.cpp:136] Iteration 19600, lr = 0.069375, m = 0.9
I0801 13:16:57.604518 12903 solver.cpp:353] Iteration 19700 (63.7215 iter/s, 1.56933s/100 iter), loss = 0.0582358
I0801 13:16:57.604564 12903 solver.cpp:375]     Train net output #0: loss = 0.0582365 (* 1 = 0.0582365 loss)
I0801 13:16:57.604578 12903 sgd_solver.cpp:136] Iteration 19700, lr = 0.0692187, m = 0.9
I0801 13:16:59.183856 12903 solver.cpp:353] Iteration 19800 (63.3197 iter/s, 1.57929s/100 iter), loss = 0.206744
I0801 13:16:59.183895 12903 solver.cpp:375]     Train net output #0: loss = 0.206745 (* 1 = 0.206745 loss)
I0801 13:16:59.183902 12903 sgd_solver.cpp:136] Iteration 19800, lr = 0.0690625, m = 0.9
I0801 13:17:00.748004 12903 solver.cpp:353] Iteration 19900 (63.9346 iter/s, 1.5641s/100 iter), loss = 0.308058
I0801 13:17:00.748091 12903 solver.cpp:375]     Train net output #0: loss = 0.308059 (* 1 = 0.308059 loss)
I0801 13:17:00.748111 12903 sgd_solver.cpp:136] Iteration 19900, lr = 0.0689062, m = 0.9
I0801 13:17:02.299149 12903 solver.cpp:680] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/initial/cifar10_jacintonet11v2_iter_20000.caffemodel
I0801 13:17:02.307430 12903 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/initial/cifar10_jacintonet11v2_iter_20000.solverstate
I0801 13:17:02.311074 12903 solver.cpp:550] Iteration 20000, Testing net (#0)
I0801 13:17:03.123563 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.801766
I0801 13:17:03.123584 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.989706
I0801 13:17:03.123589 12903 solver.cpp:635]     Test net output #2: loss = 0.735514 (* 1 = 0.735514 loss)
I0801 13:17:03.123610 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.812512s
I0801 13:17:03.141013 12903 solver.cpp:353] Iteration 20000 (41.7896 iter/s, 2.39294s/100 iter), loss = 0.0798239
I0801 13:17:03.141031 12903 solver.cpp:375]     Train net output #0: loss = 0.0798245 (* 1 = 0.0798245 loss)
I0801 13:17:03.141037 12903 sgd_solver.cpp:136] Iteration 20000, lr = 0.06875, m = 0.9
I0801 13:17:04.735405 12903 solver.cpp:353] Iteration 20100 (62.7218 iter/s, 1.59434s/100 iter), loss = 0.0351999
I0801 13:17:04.735430 12903 solver.cpp:375]     Train net output #0: loss = 0.0352005 (* 1 = 0.0352005 loss)
I0801 13:17:04.735436 12903 sgd_solver.cpp:136] Iteration 20100, lr = 0.0685938, m = 0.9
I0801 13:17:06.315487 12903 solver.cpp:353] Iteration 20200 (63.2898 iter/s, 1.58003s/100 iter), loss = 0.282975
I0801 13:17:06.315534 12903 solver.cpp:375]     Train net output #0: loss = 0.282975 (* 1 = 0.282975 loss)
I0801 13:17:06.315549 12903 sgd_solver.cpp:136] Iteration 20200, lr = 0.0684375, m = 0.9
I0801 13:17:07.881752 12903 solver.cpp:353] Iteration 20300 (63.8483 iter/s, 1.56621s/100 iter), loss = 0.0405654
I0801 13:17:07.881778 12903 solver.cpp:375]     Train net output #0: loss = 0.040566 (* 1 = 0.040566 loss)
I0801 13:17:07.881784 12903 sgd_solver.cpp:136] Iteration 20300, lr = 0.0682813, m = 0.9
I0801 13:17:09.455365 12903 solver.cpp:353] Iteration 20400 (63.5501 iter/s, 1.57356s/100 iter), loss = 0.249243
I0801 13:17:09.455433 12903 solver.cpp:375]     Train net output #0: loss = 0.249243 (* 1 = 0.249243 loss)
I0801 13:17:09.455451 12903 sgd_solver.cpp:136] Iteration 20400, lr = 0.068125, m = 0.9
I0801 13:17:11.031255 12903 solver.cpp:353] Iteration 20500 (63.4583 iter/s, 1.57584s/100 iter), loss = 0.0385901
I0801 13:17:11.031358 12903 solver.cpp:375]     Train net output #0: loss = 0.0385907 (* 1 = 0.0385907 loss)
I0801 13:17:11.031375 12903 sgd_solver.cpp:136] Iteration 20500, lr = 0.0679687, m = 0.9
I0801 13:17:12.589074 12903 solver.cpp:353] Iteration 20600 (64.1944 iter/s, 1.55777s/100 iter), loss = 0.0532564
I0801 13:17:12.589100 12903 solver.cpp:375]     Train net output #0: loss = 0.0532571 (* 1 = 0.0532571 loss)
I0801 13:17:12.589107 12903 sgd_solver.cpp:136] Iteration 20600, lr = 0.0678125, m = 0.9
I0801 13:17:14.163791 12903 solver.cpp:353] Iteration 20700 (63.5055 iter/s, 1.57467s/100 iter), loss = 0.105265
I0801 13:17:14.163842 12903 solver.cpp:375]     Train net output #0: loss = 0.105266 (* 1 = 0.105266 loss)
I0801 13:17:14.163856 12903 sgd_solver.cpp:136] Iteration 20700, lr = 0.0676562, m = 0.9
I0801 13:17:15.754593 12903 solver.cpp:353] Iteration 20800 (62.8634 iter/s, 1.59075s/100 iter), loss = 0.0502444
I0801 13:17:15.754617 12903 solver.cpp:375]     Train net output #0: loss = 0.050245 (* 1 = 0.050245 loss)
I0801 13:17:15.754621 12903 sgd_solver.cpp:136] Iteration 20800, lr = 0.0675, m = 0.9
I0801 13:17:17.349426 12903 solver.cpp:353] Iteration 20900 (62.7045 iter/s, 1.59478s/100 iter), loss = 0.115353
I0801 13:17:17.349457 12903 solver.cpp:375]     Train net output #0: loss = 0.115354 (* 1 = 0.115354 loss)
I0801 13:17:17.349463 12903 sgd_solver.cpp:136] Iteration 20900, lr = 0.0673437, m = 0.9
I0801 13:17:18.934700 12903 solver.cpp:550] Iteration 21000, Testing net (#0)
I0801 13:17:19.756031 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.798236
I0801 13:17:19.756052 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.988824
I0801 13:17:19.756057 12903 solver.cpp:635]     Test net output #2: loss = 0.733127 (* 1 = 0.733127 loss)
I0801 13:17:19.756075 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.821353s
I0801 13:17:19.771512 12903 solver.cpp:353] Iteration 21000 (41.288 iter/s, 2.42201s/100 iter), loss = 0.190796
I0801 13:17:19.771530 12903 solver.cpp:375]     Train net output #0: loss = 0.190797 (* 1 = 0.190797 loss)
I0801 13:17:19.771536 12903 sgd_solver.cpp:136] Iteration 21000, lr = 0.0671875, m = 0.9
I0801 13:17:21.344230 12903 solver.cpp:353] Iteration 21100 (63.5862 iter/s, 1.57267s/100 iter), loss = 0.185934
I0801 13:17:21.344254 12903 solver.cpp:375]     Train net output #0: loss = 0.185935 (* 1 = 0.185935 loss)
I0801 13:17:21.344260 12903 sgd_solver.cpp:136] Iteration 21100, lr = 0.0670313, m = 0.9
I0801 13:17:22.943061 12903 solver.cpp:353] Iteration 21200 (62.5476 iter/s, 1.59878s/100 iter), loss = 0.12885
I0801 13:17:22.943089 12903 solver.cpp:375]     Train net output #0: loss = 0.128851 (* 1 = 0.128851 loss)
I0801 13:17:22.943094 12903 sgd_solver.cpp:136] Iteration 21200, lr = 0.066875, m = 0.9
I0801 13:17:24.556046 12903 solver.cpp:353] Iteration 21300 (61.9989 iter/s, 1.61293s/100 iter), loss = 0.107908
I0801 13:17:24.556073 12903 solver.cpp:375]     Train net output #0: loss = 0.107908 (* 1 = 0.107908 loss)
I0801 13:17:24.556079 12903 sgd_solver.cpp:136] Iteration 21300, lr = 0.0667187, m = 0.9
I0801 13:17:26.162856 12903 solver.cpp:353] Iteration 21400 (62.237 iter/s, 1.60676s/100 iter), loss = 0.0233504
I0801 13:17:26.162883 12903 solver.cpp:375]     Train net output #0: loss = 0.0233512 (* 1 = 0.0233512 loss)
I0801 13:17:26.162889 12903 sgd_solver.cpp:136] Iteration 21400, lr = 0.0665625, m = 0.9
I0801 13:17:27.721737 12903 solver.cpp:353] Iteration 21500 (64.1505 iter/s, 1.55883s/100 iter), loss = 0.0514108
I0801 13:17:27.721786 12903 solver.cpp:375]     Train net output #0: loss = 0.0514114 (* 1 = 0.0514114 loss)
I0801 13:17:27.721801 12903 sgd_solver.cpp:136] Iteration 21500, lr = 0.0664062, m = 0.9
I0801 13:17:29.315318 12903 solver.cpp:353] Iteration 21600 (62.7537 iter/s, 1.59353s/100 iter), loss = 0.0338371
I0801 13:17:29.315369 12903 solver.cpp:375]     Train net output #0: loss = 0.0338378 (* 1 = 0.0338378 loss)
I0801 13:17:29.315377 12903 sgd_solver.cpp:136] Iteration 21600, lr = 0.06625, m = 0.9
I0801 13:17:30.901733 12903 solver.cpp:353] Iteration 21700 (63.0372 iter/s, 1.58637s/100 iter), loss = 0.20073
I0801 13:17:30.901774 12903 solver.cpp:375]     Train net output #0: loss = 0.200731 (* 1 = 0.200731 loss)
I0801 13:17:30.901782 12903 sgd_solver.cpp:136] Iteration 21700, lr = 0.0660938, m = 0.9
I0801 13:17:32.491482 12903 solver.cpp:353] Iteration 21800 (62.9051 iter/s, 1.5897s/100 iter), loss = 0.047012
I0801 13:17:32.491544 12903 solver.cpp:375]     Train net output #0: loss = 0.0470126 (* 1 = 0.0470126 loss)
I0801 13:17:32.491564 12903 sgd_solver.cpp:136] Iteration 21800, lr = 0.0659375, m = 0.9
I0801 13:17:34.062002 12903 solver.cpp:353] Iteration 21900 (63.6752 iter/s, 1.57047s/100 iter), loss = 0.157895
I0801 13:17:34.062029 12903 solver.cpp:375]     Train net output #0: loss = 0.157896 (* 1 = 0.157896 loss)
I0801 13:17:34.062036 12903 sgd_solver.cpp:136] Iteration 21900, lr = 0.0657813, m = 0.9
I0801 13:17:35.625849 12903 solver.cpp:550] Iteration 22000, Testing net (#0)
I0801 13:17:36.060626 12893 data_reader.cpp:264] Starting prefetch of epoch 3
I0801 13:17:36.454396 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.789707
I0801 13:17:36.454416 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.987647
I0801 13:17:36.454421 12903 solver.cpp:635]     Test net output #2: loss = 0.752263 (* 1 = 0.752263 loss)
I0801 13:17:36.454435 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.828565s
I0801 13:17:36.470975 12903 solver.cpp:353] Iteration 22000 (41.5127 iter/s, 2.4089s/100 iter), loss = 0.0319324
I0801 13:17:36.470993 12903 solver.cpp:375]     Train net output #0: loss = 0.031933 (* 1 = 0.031933 loss)
I0801 13:17:36.470999 12903 sgd_solver.cpp:136] Iteration 22000, lr = 0.065625, m = 0.9
I0801 13:17:38.058241 12903 solver.cpp:353] Iteration 22100 (63.0036 iter/s, 1.58721s/100 iter), loss = 0.0547343
I0801 13:17:38.058267 12903 solver.cpp:375]     Train net output #0: loss = 0.0547349 (* 1 = 0.0547349 loss)
I0801 13:17:38.058274 12903 sgd_solver.cpp:136] Iteration 22100, lr = 0.0654688, m = 0.9
I0801 13:17:39.618600 12903 solver.cpp:353] Iteration 22200 (64.0898 iter/s, 1.56031s/100 iter), loss = 0.0524233
I0801 13:17:39.618651 12903 solver.cpp:375]     Train net output #0: loss = 0.0524239 (* 1 = 0.0524239 loss)
I0801 13:17:39.618666 12903 sgd_solver.cpp:136] Iteration 22200, lr = 0.0653125, m = 0.9
I0801 13:17:41.230015 12903 solver.cpp:353] Iteration 22300 (62.0592 iter/s, 1.61136s/100 iter), loss = 0.0111228
I0801 13:17:41.230135 12903 solver.cpp:375]     Train net output #0: loss = 0.0111234 (* 1 = 0.0111234 loss)
I0801 13:17:41.230145 12903 sgd_solver.cpp:136] Iteration 22300, lr = 0.0651563, m = 0.9
I0801 13:17:42.795311 12903 solver.cpp:353] Iteration 22400 (63.8875 iter/s, 1.56525s/100 iter), loss = 0.0443752
I0801 13:17:42.795339 12903 solver.cpp:375]     Train net output #0: loss = 0.0443758 (* 1 = 0.0443758 loss)
I0801 13:17:42.795346 12903 sgd_solver.cpp:136] Iteration 22400, lr = 0.065, m = 0.9
I0801 13:17:44.398124 12903 solver.cpp:353] Iteration 22500 (62.3923 iter/s, 1.60276s/100 iter), loss = 0.131248
I0801 13:17:44.398177 12903 solver.cpp:375]     Train net output #0: loss = 0.131249 (* 1 = 0.131249 loss)
I0801 13:17:44.398190 12903 sgd_solver.cpp:136] Iteration 22500, lr = 0.0648438, m = 0.9
I0801 13:17:46.019071 12903 solver.cpp:353] Iteration 22600 (61.6943 iter/s, 1.62089s/100 iter), loss = 0.0305089
I0801 13:17:46.019098 12903 solver.cpp:375]     Train net output #0: loss = 0.0305095 (* 1 = 0.0305095 loss)
I0801 13:17:46.019101 12903 sgd_solver.cpp:136] Iteration 22600, lr = 0.0646875, m = 0.9
I0801 13:17:47.614580 12903 solver.cpp:353] Iteration 22700 (62.6779 iter/s, 1.59546s/100 iter), loss = 0.0776237
I0801 13:17:47.614634 12903 solver.cpp:375]     Train net output #0: loss = 0.0776243 (* 1 = 0.0776243 loss)
I0801 13:17:47.614650 12903 sgd_solver.cpp:136] Iteration 22700, lr = 0.0645313, m = 0.9
I0801 13:17:49.179945 12903 solver.cpp:353] Iteration 22800 (63.8848 iter/s, 1.56532s/100 iter), loss = 0.142916
I0801 13:17:49.179973 12903 solver.cpp:375]     Train net output #0: loss = 0.142916 (* 1 = 0.142916 loss)
I0801 13:17:49.179980 12903 sgd_solver.cpp:136] Iteration 22800, lr = 0.064375, m = 0.9
I0801 13:17:50.752549 12903 solver.cpp:353] Iteration 22900 (63.5908 iter/s, 1.57255s/100 iter), loss = 0.0195689
I0801 13:17:50.752611 12903 solver.cpp:375]     Train net output #0: loss = 0.0195696 (* 1 = 0.0195696 loss)
I0801 13:17:50.752619 12903 sgd_solver.cpp:136] Iteration 22900, lr = 0.0642188, m = 0.9
I0801 13:17:52.310751 12903 solver.cpp:550] Iteration 23000, Testing net (#0)
I0801 13:17:53.129485 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.83853
I0801 13:17:53.129503 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.990294
I0801 13:17:53.129508 12903 solver.cpp:635]     Test net output #2: loss = 0.55757 (* 1 = 0.55757 loss)
I0801 13:17:53.129525 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.818751s
I0801 13:17:53.145289 12903 solver.cpp:353] Iteration 23000 (41.7943 iter/s, 2.39267s/100 iter), loss = 0.15341
I0801 13:17:53.145308 12903 solver.cpp:375]     Train net output #0: loss = 0.15341 (* 1 = 0.15341 loss)
I0801 13:17:53.145313 12903 sgd_solver.cpp:136] Iteration 23000, lr = 0.0640625, m = 0.9
I0801 13:17:54.706693 12903 solver.cpp:353] Iteration 23100 (64.0469 iter/s, 1.56136s/100 iter), loss = 0.0606729
I0801 13:17:54.706722 12903 solver.cpp:375]     Train net output #0: loss = 0.0606735 (* 1 = 0.0606735 loss)
I0801 13:17:54.706727 12903 sgd_solver.cpp:136] Iteration 23100, lr = 0.0639063, m = 0.9
I0801 13:17:56.283850 12903 solver.cpp:353] Iteration 23200 (63.4074 iter/s, 1.5771s/100 iter), loss = 0.0618001
I0801 13:17:56.283875 12903 solver.cpp:375]     Train net output #0: loss = 0.0618008 (* 1 = 0.0618008 loss)
I0801 13:17:56.283879 12903 sgd_solver.cpp:136] Iteration 23200, lr = 0.06375, m = 0.9
I0801 13:17:57.845881 12903 solver.cpp:353] Iteration 23300 (64.0211 iter/s, 1.56198s/100 iter), loss = 0.0129523
I0801 13:17:57.845911 12903 solver.cpp:375]     Train net output #0: loss = 0.012953 (* 1 = 0.012953 loss)
I0801 13:17:57.845916 12903 sgd_solver.cpp:136] Iteration 23300, lr = 0.0635938, m = 0.9
I0801 13:17:59.420377 12903 solver.cpp:353] Iteration 23400 (63.5144 iter/s, 1.57445s/100 iter), loss = 0.0354972
I0801 13:17:59.420426 12903 solver.cpp:375]     Train net output #0: loss = 0.035498 (* 1 = 0.035498 loss)
I0801 13:17:59.420440 12903 sgd_solver.cpp:136] Iteration 23400, lr = 0.0634375, m = 0.9
I0801 13:18:00.981323 12903 solver.cpp:353] Iteration 23500 (64.0658 iter/s, 1.56089s/100 iter), loss = 0.0336877
I0801 13:18:00.981387 12903 solver.cpp:375]     Train net output #0: loss = 0.0336885 (* 1 = 0.0336885 loss)
I0801 13:18:00.981400 12903 sgd_solver.cpp:136] Iteration 23500, lr = 0.0632813, m = 0.9
I0801 13:18:02.558248 12903 solver.cpp:353] Iteration 23600 (63.4165 iter/s, 1.57688s/100 iter), loss = 0.0725311
I0801 13:18:02.558296 12903 solver.cpp:375]     Train net output #0: loss = 0.0725319 (* 1 = 0.0725319 loss)
I0801 13:18:02.558310 12903 sgd_solver.cpp:136] Iteration 23600, lr = 0.063125, m = 0.9
I0801 13:18:04.136199 12903 solver.cpp:353] Iteration 23700 (63.3754 iter/s, 1.5779s/100 iter), loss = 0.0202771
I0801 13:18:04.136225 12903 solver.cpp:375]     Train net output #0: loss = 0.0202779 (* 1 = 0.0202779 loss)
I0801 13:18:04.136231 12903 sgd_solver.cpp:136] Iteration 23700, lr = 0.0629688, m = 0.9
I0801 13:18:05.715359 12903 solver.cpp:353] Iteration 23800 (63.3269 iter/s, 1.57911s/100 iter), loss = 0.0552958
I0801 13:18:05.715410 12903 solver.cpp:375]     Train net output #0: loss = 0.0552966 (* 1 = 0.0552966 loss)
I0801 13:18:05.715425 12903 sgd_solver.cpp:136] Iteration 23800, lr = 0.0628125, m = 0.9
I0801 13:18:07.298463 12903 solver.cpp:353] Iteration 23900 (63.169 iter/s, 1.58305s/100 iter), loss = 0.0468401
I0801 13:18:07.298493 12903 solver.cpp:375]     Train net output #0: loss = 0.0468409 (* 1 = 0.0468409 loss)
I0801 13:18:07.298501 12903 sgd_solver.cpp:136] Iteration 23900, lr = 0.0626562, m = 0.9
I0801 13:18:08.866011 12903 solver.cpp:550] Iteration 24000, Testing net (#0)
I0801 13:18:09.689333 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.764707
I0801 13:18:09.689353 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.986765
I0801 13:18:09.689358 12903 solver.cpp:635]     Test net output #2: loss = 0.981463 (* 1 = 0.981463 loss)
I0801 13:18:09.689374 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.823342s
I0801 13:18:09.704948 12903 solver.cpp:353] Iteration 24000 (41.5556 iter/s, 2.40642s/100 iter), loss = 0.282579
I0801 13:18:09.704969 12903 solver.cpp:375]     Train net output #0: loss = 0.282579 (* 1 = 0.282579 loss)
I0801 13:18:09.704974 12903 sgd_solver.cpp:136] Iteration 24000, lr = 0.0625, m = 0.9
I0801 13:18:11.261765 12903 solver.cpp:353] Iteration 24100 (64.2357 iter/s, 1.55677s/100 iter), loss = 0.234483
I0801 13:18:11.261828 12903 solver.cpp:375]     Train net output #0: loss = 0.234484 (* 1 = 0.234484 loss)
I0801 13:18:11.261837 12903 sgd_solver.cpp:136] Iteration 24100, lr = 0.0623438, m = 0.9
I0801 13:18:12.835752 12903 solver.cpp:353] Iteration 24200 (63.535 iter/s, 1.57394s/100 iter), loss = 0.0764246
I0801 13:18:12.835817 12903 solver.cpp:375]     Train net output #0: loss = 0.0764253 (* 1 = 0.0764253 loss)
I0801 13:18:12.835837 12903 sgd_solver.cpp:136] Iteration 24200, lr = 0.0621875, m = 0.9
I0801 13:18:14.423643 12903 solver.cpp:353] Iteration 24300 (62.9785 iter/s, 1.58784s/100 iter), loss = 0.0421338
I0801 13:18:14.423667 12903 solver.cpp:375]     Train net output #0: loss = 0.0421344 (* 1 = 0.0421344 loss)
I0801 13:18:14.423671 12903 sgd_solver.cpp:136] Iteration 24300, lr = 0.0620313, m = 0.9
I0801 13:18:16.012585 12903 solver.cpp:353] Iteration 24400 (62.937 iter/s, 1.58889s/100 iter), loss = 0.0200215
I0801 13:18:16.012610 12903 solver.cpp:375]     Train net output #0: loss = 0.0200222 (* 1 = 0.0200222 loss)
I0801 13:18:16.012616 12903 sgd_solver.cpp:136] Iteration 24400, lr = 0.061875, m = 0.9
I0801 13:18:17.579010 12903 solver.cpp:353] Iteration 24500 (63.8417 iter/s, 1.56637s/100 iter), loss = 0.0234707
I0801 13:18:17.579061 12903 solver.cpp:375]     Train net output #0: loss = 0.0234714 (* 1 = 0.0234714 loss)
I0801 13:18:17.579068 12903 sgd_solver.cpp:136] Iteration 24500, lr = 0.0617188, m = 0.9
I0801 13:18:19.146867 12903 solver.cpp:353] Iteration 24600 (63.7834 iter/s, 1.56781s/100 iter), loss = 0.349178
I0801 13:18:19.146891 12903 solver.cpp:375]     Train net output #0: loss = 0.349179 (* 1 = 0.349179 loss)
I0801 13:18:19.146896 12903 sgd_solver.cpp:136] Iteration 24600, lr = 0.0615625, m = 0.9
I0801 13:18:20.727782 12903 solver.cpp:353] Iteration 24700 (63.2564 iter/s, 1.58087s/100 iter), loss = 0.0277971
I0801 13:18:20.727833 12903 solver.cpp:375]     Train net output #0: loss = 0.0277978 (* 1 = 0.0277978 loss)
I0801 13:18:20.727846 12903 sgd_solver.cpp:136] Iteration 24700, lr = 0.0614063, m = 0.9
I0801 13:18:22.298023 12903 solver.cpp:353] Iteration 24800 (63.6865 iter/s, 1.57019s/100 iter), loss = 0.0229158
I0801 13:18:22.298049 12903 solver.cpp:375]     Train net output #0: loss = 0.0229165 (* 1 = 0.0229165 loss)
I0801 13:18:22.298055 12903 sgd_solver.cpp:136] Iteration 24800, lr = 0.06125, m = 0.9
I0801 13:18:23.871305 12903 solver.cpp:353] Iteration 24900 (63.5635 iter/s, 1.57323s/100 iter), loss = 0.209355
I0801 13:18:23.871332 12903 solver.cpp:375]     Train net output #0: loss = 0.209356 (* 1 = 0.209356 loss)
I0801 13:18:23.871338 12903 sgd_solver.cpp:136] Iteration 24900, lr = 0.0610937, m = 0.9
I0801 13:18:25.446949 12903 solver.cpp:550] Iteration 25000, Testing net (#0)
I0801 13:18:26.284291 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.802354
I0801 13:18:26.284310 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.987353
I0801 13:18:26.284315 12903 solver.cpp:635]     Test net output #2: loss = 0.76946 (* 1 = 0.76946 loss)
I0801 13:18:26.284330 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.837359s
I0801 13:18:26.299943 12903 solver.cpp:353] Iteration 25000 (41.1765 iter/s, 2.42857s/100 iter), loss = 0.0128152
I0801 13:18:26.299960 12903 solver.cpp:375]     Train net output #0: loss = 0.0128161 (* 1 = 0.0128161 loss)
I0801 13:18:26.299963 12903 sgd_solver.cpp:136] Iteration 25000, lr = 0.0609375, m = 0.9
I0801 13:18:27.879655 12903 solver.cpp:353] Iteration 25100 (63.3049 iter/s, 1.57966s/100 iter), loss = 0.0378628
I0801 13:18:27.879684 12903 solver.cpp:375]     Train net output #0: loss = 0.0378637 (* 1 = 0.0378637 loss)
I0801 13:18:27.879691 12903 sgd_solver.cpp:136] Iteration 25100, lr = 0.0607813, m = 0.9
I0801 13:18:29.481611 12903 solver.cpp:353] Iteration 25200 (62.4257 iter/s, 1.6019s/100 iter), loss = 0.145939
I0801 13:18:29.481637 12903 solver.cpp:375]     Train net output #0: loss = 0.14594 (* 1 = 0.14594 loss)
I0801 13:18:29.481642 12903 sgd_solver.cpp:136] Iteration 25200, lr = 0.060625, m = 0.9
I0801 13:18:31.055794 12903 solver.cpp:353] Iteration 25300 (63.5269 iter/s, 1.57414s/100 iter), loss = 0.0300126
I0801 13:18:31.055863 12903 solver.cpp:375]     Train net output #0: loss = 0.0300135 (* 1 = 0.0300135 loss)
I0801 13:18:31.055876 12903 sgd_solver.cpp:136] Iteration 25300, lr = 0.0604688, m = 0.9
I0801 13:18:32.636147 12903 solver.cpp:353] Iteration 25400 (63.279 iter/s, 1.5803s/100 iter), loss = 0.0341789
I0801 13:18:32.636174 12903 solver.cpp:375]     Train net output #0: loss = 0.0341798 (* 1 = 0.0341798 loss)
I0801 13:18:32.636180 12903 sgd_solver.cpp:136] Iteration 25400, lr = 0.0603125, m = 0.9
I0801 13:18:34.195500 12903 solver.cpp:353] Iteration 25500 (64.1312 iter/s, 1.5593s/100 iter), loss = 0.0432964
I0801 13:18:34.195525 12903 solver.cpp:375]     Train net output #0: loss = 0.0432974 (* 1 = 0.0432974 loss)
I0801 13:18:34.195531 12903 sgd_solver.cpp:136] Iteration 25500, lr = 0.0601563, m = 0.9
I0801 13:18:35.766695 12903 solver.cpp:353] Iteration 25600 (63.6478 iter/s, 1.57115s/100 iter), loss = 0.196588
I0801 13:18:35.766719 12903 solver.cpp:375]     Train net output #0: loss = 0.196589 (* 1 = 0.196589 loss)
I0801 13:18:35.766723 12903 sgd_solver.cpp:136] Iteration 25600, lr = 0.06, m = 0.9
I0801 13:18:37.341743 12903 solver.cpp:353] Iteration 25700 (63.4921 iter/s, 1.575s/100 iter), loss = 0.010989
I0801 13:18:37.341770 12903 solver.cpp:375]     Train net output #0: loss = 0.0109898 (* 1 = 0.0109898 loss)
I0801 13:18:37.341776 12903 sgd_solver.cpp:136] Iteration 25700, lr = 0.0598437, m = 0.9
I0801 13:18:38.929780 12903 solver.cpp:353] Iteration 25800 (62.9729 iter/s, 1.58798s/100 iter), loss = 0.147114
I0801 13:18:38.929802 12903 solver.cpp:375]     Train net output #0: loss = 0.147115 (* 1 = 0.147115 loss)
I0801 13:18:38.929807 12903 sgd_solver.cpp:136] Iteration 25800, lr = 0.0596875, m = 0.9
I0801 13:18:40.496073 12903 solver.cpp:353] Iteration 25900 (63.8469 iter/s, 1.56625s/100 iter), loss = 0.0229598
I0801 13:18:40.496122 12903 solver.cpp:375]     Train net output #0: loss = 0.0229606 (* 1 = 0.0229606 loss)
I0801 13:18:40.496134 12903 sgd_solver.cpp:136] Iteration 25900, lr = 0.0595312, m = 0.9
I0801 13:18:42.041857 12903 solver.cpp:550] Iteration 26000, Testing net (#0)
I0801 13:18:42.863293 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.841472
I0801 13:18:42.863313 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.990588
I0801 13:18:42.863318 12903 solver.cpp:635]     Test net output #2: loss = 0.65314 (* 1 = 0.65314 loss)
I0801 13:18:42.863335 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.821455s
I0801 13:18:42.879252 12903 solver.cpp:353] Iteration 26000 (41.962 iter/s, 2.38311s/100 iter), loss = 0.182856
I0801 13:18:42.879271 12903 solver.cpp:375]     Train net output #0: loss = 0.182857 (* 1 = 0.182857 loss)
I0801 13:18:42.879277 12903 sgd_solver.cpp:136] Iteration 26000, lr = 0.059375, m = 0.9
I0801 13:18:44.462620 12903 solver.cpp:353] Iteration 26100 (63.1585 iter/s, 1.58332s/100 iter), loss = 0.0362426
I0801 13:18:44.462646 12903 solver.cpp:375]     Train net output #0: loss = 0.0362434 (* 1 = 0.0362434 loss)
I0801 13:18:44.462651 12903 sgd_solver.cpp:136] Iteration 26100, lr = 0.0592188, m = 0.9
I0801 13:18:46.031821 12903 solver.cpp:353] Iteration 26200 (63.7289 iter/s, 1.56915s/100 iter), loss = 0.0030601
I0801 13:18:46.031847 12903 solver.cpp:375]     Train net output #0: loss = 0.00306086 (* 1 = 0.00306086 loss)
I0801 13:18:46.031852 12903 sgd_solver.cpp:136] Iteration 26200, lr = 0.0590625, m = 0.9
I0801 13:18:47.604722 12903 solver.cpp:353] Iteration 26300 (63.5787 iter/s, 1.57285s/100 iter), loss = 0.0444908
I0801 13:18:47.604746 12903 solver.cpp:375]     Train net output #0: loss = 0.0444916 (* 1 = 0.0444916 loss)
I0801 13:18:47.604753 12903 sgd_solver.cpp:136] Iteration 26300, lr = 0.0589063, m = 0.9
I0801 13:18:49.168068 12903 solver.cpp:353] Iteration 26400 (63.9673 iter/s, 1.5633s/100 iter), loss = 0.0316287
I0801 13:18:49.168093 12903 solver.cpp:375]     Train net output #0: loss = 0.0316294 (* 1 = 0.0316294 loss)
I0801 13:18:49.168099 12903 sgd_solver.cpp:136] Iteration 26400, lr = 0.05875, m = 0.9
I0801 13:18:50.738174 12903 solver.cpp:353] Iteration 26500 (63.692 iter/s, 1.57006s/100 iter), loss = 0.0137714
I0801 13:18:50.738200 12903 solver.cpp:375]     Train net output #0: loss = 0.0137721 (* 1 = 0.0137721 loss)
I0801 13:18:50.738205 12903 sgd_solver.cpp:136] Iteration 26500, lr = 0.0585938, m = 0.9
I0801 13:18:50.926573 12870 data_reader.cpp:264] Starting prefetch of epoch 4
I0801 13:18:52.308274 12903 solver.cpp:353] Iteration 26600 (63.6922 iter/s, 1.57005s/100 iter), loss = 0.138731
I0801 13:18:52.308298 12903 solver.cpp:375]     Train net output #0: loss = 0.138732 (* 1 = 0.138732 loss)
I0801 13:18:52.308305 12903 sgd_solver.cpp:136] Iteration 26600, lr = 0.0584375, m = 0.9
I0801 13:18:53.866943 12903 solver.cpp:353] Iteration 26700 (64.1594 iter/s, 1.55862s/100 iter), loss = 0.124244
I0801 13:18:53.866968 12903 solver.cpp:375]     Train net output #0: loss = 0.124245 (* 1 = 0.124245 loss)
I0801 13:18:53.866976 12903 sgd_solver.cpp:136] Iteration 26700, lr = 0.0582813, m = 0.9
I0801 13:18:55.444183 12903 solver.cpp:353] Iteration 26800 (63.4038 iter/s, 1.57719s/100 iter), loss = 0.0136097
I0801 13:18:55.444211 12903 solver.cpp:375]     Train net output #0: loss = 0.0136105 (* 1 = 0.0136105 loss)
I0801 13:18:55.444216 12903 sgd_solver.cpp:136] Iteration 26800, lr = 0.058125, m = 0.9
I0801 13:18:57.002624 12903 solver.cpp:353] Iteration 26900 (64.1688 iter/s, 1.55839s/100 iter), loss = 0.134228
I0801 13:18:57.002648 12903 solver.cpp:375]     Train net output #0: loss = 0.134229 (* 1 = 0.134229 loss)
I0801 13:18:57.002655 12903 sgd_solver.cpp:136] Iteration 26900, lr = 0.0579687, m = 0.9
I0801 13:18:58.559458 12903 solver.cpp:550] Iteration 27000, Testing net (#0)
I0801 13:18:59.374589 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.761177
I0801 13:18:59.374613 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.98
I0801 13:18:59.374619 12903 solver.cpp:635]     Test net output #2: loss = 1.04647 (* 1 = 1.04647 loss)
I0801 13:18:59.374639 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.815155s
I0801 13:18:59.390285 12903 solver.cpp:353] Iteration 27000 (41.8832 iter/s, 2.38759s/100 iter), loss = 0.155631
I0801 13:18:59.390326 12903 solver.cpp:375]     Train net output #0: loss = 0.155632 (* 1 = 0.155632 loss)
I0801 13:18:59.390333 12903 sgd_solver.cpp:136] Iteration 27000, lr = 0.0578125, m = 0.9
I0801 13:19:00.951516 12903 solver.cpp:353] Iteration 27100 (64.0541 iter/s, 1.56118s/100 iter), loss = 0.0136827
I0801 13:19:00.951539 12903 solver.cpp:375]     Train net output #0: loss = 0.0136835 (* 1 = 0.0136835 loss)
I0801 13:19:00.951544 12903 sgd_solver.cpp:136] Iteration 27100, lr = 0.0576563, m = 0.9
I0801 13:19:02.522156 12903 solver.cpp:353] Iteration 27200 (63.6703 iter/s, 1.57059s/100 iter), loss = 0.0298563
I0801 13:19:02.522209 12903 solver.cpp:375]     Train net output #0: loss = 0.0298572 (* 1 = 0.0298572 loss)
I0801 13:19:02.522218 12903 sgd_solver.cpp:136] Iteration 27200, lr = 0.0575, m = 0.9
I0801 13:19:04.096778 12903 solver.cpp:353] Iteration 27300 (63.5093 iter/s, 1.57457s/100 iter), loss = 0.0440706
I0801 13:19:04.096803 12903 solver.cpp:375]     Train net output #0: loss = 0.0440715 (* 1 = 0.0440715 loss)
I0801 13:19:04.096807 12903 sgd_solver.cpp:136] Iteration 27300, lr = 0.0573438, m = 0.9
I0801 13:19:05.652714 12903 solver.cpp:353] Iteration 27400 (64.272 iter/s, 1.55589s/100 iter), loss = 0.0122278
I0801 13:19:05.652737 12903 solver.cpp:375]     Train net output #0: loss = 0.0122286 (* 1 = 0.0122286 loss)
I0801 13:19:05.652741 12903 sgd_solver.cpp:136] Iteration 27400, lr = 0.0571875, m = 0.9
I0801 13:19:07.231357 12903 solver.cpp:353] Iteration 27500 (63.3475 iter/s, 1.57859s/100 iter), loss = 0.00341758
I0801 13:19:07.231384 12903 solver.cpp:375]     Train net output #0: loss = 0.00341844 (* 1 = 0.00341844 loss)
I0801 13:19:07.231389 12903 sgd_solver.cpp:136] Iteration 27500, lr = 0.0570313, m = 0.9
I0801 13:19:08.784945 12903 solver.cpp:353] Iteration 27600 (64.3692 iter/s, 1.55354s/100 iter), loss = 0.0835366
I0801 13:19:08.784970 12903 solver.cpp:375]     Train net output #0: loss = 0.0835375 (* 1 = 0.0835375 loss)
I0801 13:19:08.784976 12903 sgd_solver.cpp:136] Iteration 27600, lr = 0.056875, m = 0.9
I0801 13:19:10.342945 12903 solver.cpp:353] Iteration 27700 (64.1867 iter/s, 1.55796s/100 iter), loss = 0.0201948
I0801 13:19:10.342970 12903 solver.cpp:375]     Train net output #0: loss = 0.0201957 (* 1 = 0.0201957 loss)
I0801 13:19:10.342975 12903 sgd_solver.cpp:136] Iteration 27700, lr = 0.0567187, m = 0.9
I0801 13:19:11.909867 12903 solver.cpp:353] Iteration 27800 (63.8215 iter/s, 1.56687s/100 iter), loss = 0.110205
I0801 13:19:11.909917 12903 solver.cpp:375]     Train net output #0: loss = 0.110206 (* 1 = 0.110206 loss)
I0801 13:19:11.909931 12903 sgd_solver.cpp:136] Iteration 27800, lr = 0.0565625, m = 0.9
I0801 13:19:13.484905 12903 solver.cpp:353] Iteration 27900 (63.4925 iter/s, 1.57499s/100 iter), loss = 0.0792626
I0801 13:19:13.484977 12903 solver.cpp:375]     Train net output #0: loss = 0.0792634 (* 1 = 0.0792634 loss)
I0801 13:19:13.484984 12903 sgd_solver.cpp:136] Iteration 27900, lr = 0.0564062, m = 0.9
I0801 13:19:15.039685 12903 solver.cpp:550] Iteration 28000, Testing net (#0)
I0801 13:19:15.865063 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.818237
I0801 13:19:15.865083 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.985882
I0801 13:19:15.865088 12903 solver.cpp:635]     Test net output #2: loss = 0.720152 (* 1 = 0.720152 loss)
I0801 13:19:15.865103 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.825396s
I0801 13:19:15.880712 12903 solver.cpp:353] Iteration 28000 (41.7408 iter/s, 2.39574s/100 iter), loss = 0.0103387
I0801 13:19:15.880730 12903 solver.cpp:375]     Train net output #0: loss = 0.0103395 (* 1 = 0.0103395 loss)
I0801 13:19:15.880735 12903 sgd_solver.cpp:136] Iteration 28000, lr = 0.05625, m = 0.9
I0801 13:19:17.458732 12903 solver.cpp:353] Iteration 28100 (63.3727 iter/s, 1.57797s/100 iter), loss = 0.00308307
I0801 13:19:17.458758 12903 solver.cpp:375]     Train net output #0: loss = 0.00308388 (* 1 = 0.00308388 loss)
I0801 13:19:17.458765 12903 sgd_solver.cpp:136] Iteration 28100, lr = 0.0560938, m = 0.9
I0801 13:19:19.025322 12903 solver.cpp:353] Iteration 28200 (63.8348 iter/s, 1.56654s/100 iter), loss = 0.0154131
I0801 13:19:19.025374 12903 solver.cpp:375]     Train net output #0: loss = 0.0154139 (* 1 = 0.0154139 loss)
I0801 13:19:19.025389 12903 sgd_solver.cpp:136] Iteration 28200, lr = 0.0559375, m = 0.9
I0801 13:19:20.597263 12903 solver.cpp:353] Iteration 28300 (63.6176 iter/s, 1.57189s/100 iter), loss = 0.00487105
I0801 13:19:20.597332 12903 solver.cpp:375]     Train net output #0: loss = 0.00487193 (* 1 = 0.00487193 loss)
I0801 13:19:20.597352 12903 sgd_solver.cpp:136] Iteration 28300, lr = 0.0557813, m = 0.9
I0801 13:19:22.177201 12903 solver.cpp:353] Iteration 28400 (63.2958 iter/s, 1.57988s/100 iter), loss = 0.00554207
I0801 13:19:22.177222 12903 solver.cpp:375]     Train net output #0: loss = 0.00554294 (* 1 = 0.00554294 loss)
I0801 13:19:22.177227 12903 sgd_solver.cpp:136] Iteration 28400, lr = 0.055625, m = 0.9
I0801 13:19:23.737725 12903 solver.cpp:353] Iteration 28500 (64.0829 iter/s, 1.56048s/100 iter), loss = 0.0227279
I0801 13:19:23.737751 12903 solver.cpp:375]     Train net output #0: loss = 0.0227288 (* 1 = 0.0227288 loss)
I0801 13:19:23.737757 12903 sgd_solver.cpp:136] Iteration 28500, lr = 0.0554687, m = 0.9
I0801 13:19:25.313868 12903 solver.cpp:353] Iteration 28600 (63.448 iter/s, 1.57609s/100 iter), loss = 0.0582862
I0801 13:19:25.313930 12903 solver.cpp:375]     Train net output #0: loss = 0.0582871 (* 1 = 0.0582871 loss)
I0801 13:19:25.313946 12903 sgd_solver.cpp:136] Iteration 28600, lr = 0.0553125, m = 0.9
I0801 13:19:26.871470 12903 solver.cpp:353] Iteration 28700 (64.2033 iter/s, 1.55755s/100 iter), loss = 0.00931215
I0801 13:19:26.871495 12903 solver.cpp:375]     Train net output #0: loss = 0.00931306 (* 1 = 0.00931306 loss)
I0801 13:19:26.871501 12903 sgd_solver.cpp:136] Iteration 28700, lr = 0.0551562, m = 0.9
I0801 13:19:28.437305 12903 solver.cpp:353] Iteration 28800 (63.8657 iter/s, 1.56579s/100 iter), loss = 0.204172
I0801 13:19:28.437330 12903 solver.cpp:375]     Train net output #0: loss = 0.204173 (* 1 = 0.204173 loss)
I0801 13:19:28.437335 12903 sgd_solver.cpp:136] Iteration 28800, lr = 0.055, m = 0.9
I0801 13:19:30.002331 12903 solver.cpp:353] Iteration 28900 (63.8986 iter/s, 1.56498s/100 iter), loss = 0.384051
I0801 13:19:30.002377 12903 solver.cpp:375]     Train net output #0: loss = 0.384052 (* 1 = 0.384052 loss)
I0801 13:19:30.002390 12903 sgd_solver.cpp:136] Iteration 28900, lr = 0.0548437, m = 0.9
I0801 13:19:31.560981 12903 solver.cpp:550] Iteration 29000, Testing net (#0)
I0801 13:19:32.377212 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.808237
I0801 13:19:32.377233 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.989706
I0801 13:19:32.377239 12903 solver.cpp:635]     Test net output #2: loss = 0.727913 (* 1 = 0.727913 loss)
I0801 13:19:32.377271 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.816268s
I0801 13:19:32.392943 12903 solver.cpp:353] Iteration 29000 (41.8315 iter/s, 2.39054s/100 iter), loss = 0.0255828
I0801 13:19:32.392961 12903 solver.cpp:375]     Train net output #0: loss = 0.0255838 (* 1 = 0.0255838 loss)
I0801 13:19:32.392966 12903 sgd_solver.cpp:136] Iteration 29000, lr = 0.0546875, m = 0.9
I0801 13:19:33.978689 12903 solver.cpp:353] Iteration 29100 (63.0639 iter/s, 1.58569s/100 iter), loss = 0.166557
I0801 13:19:33.978715 12903 solver.cpp:375]     Train net output #0: loss = 0.166558 (* 1 = 0.166558 loss)
I0801 13:19:33.978720 12903 sgd_solver.cpp:136] Iteration 29100, lr = 0.0545313, m = 0.9
I0801 13:19:35.544332 12903 solver.cpp:353] Iteration 29200 (63.8734 iter/s, 1.5656s/100 iter), loss = 0.0122728
I0801 13:19:35.544358 12903 solver.cpp:375]     Train net output #0: loss = 0.0122737 (* 1 = 0.0122737 loss)
I0801 13:19:35.544361 12903 sgd_solver.cpp:136] Iteration 29200, lr = 0.054375, m = 0.9
I0801 13:19:37.114794 12903 solver.cpp:353] Iteration 29300 (63.6776 iter/s, 1.57041s/100 iter), loss = 0.0565891
I0801 13:19:37.114819 12903 solver.cpp:375]     Train net output #0: loss = 0.05659 (* 1 = 0.05659 loss)
I0801 13:19:37.114825 12903 sgd_solver.cpp:136] Iteration 29300, lr = 0.0542188, m = 0.9
I0801 13:19:38.693460 12903 solver.cpp:353] Iteration 29400 (63.3466 iter/s, 1.57862s/100 iter), loss = 0.0995631
I0801 13:19:38.693488 12903 solver.cpp:375]     Train net output #0: loss = 0.099564 (* 1 = 0.099564 loss)
I0801 13:19:38.693495 12903 sgd_solver.cpp:136] Iteration 29400, lr = 0.0540625, m = 0.9
I0801 13:19:40.271533 12903 solver.cpp:353] Iteration 29500 (63.3705 iter/s, 1.57802s/100 iter), loss = 0.108334
I0801 13:19:40.271558 12903 solver.cpp:375]     Train net output #0: loss = 0.108335 (* 1 = 0.108335 loss)
I0801 13:19:40.271562 12903 sgd_solver.cpp:136] Iteration 29500, lr = 0.0539063, m = 0.9
I0801 13:19:41.827592 12903 solver.cpp:353] Iteration 29600 (64.2669 iter/s, 1.55601s/100 iter), loss = 0.0224814
I0801 13:19:41.827620 12903 solver.cpp:375]     Train net output #0: loss = 0.0224822 (* 1 = 0.0224822 loss)
I0801 13:19:41.827626 12903 sgd_solver.cpp:136] Iteration 29600, lr = 0.05375, m = 0.9
I0801 13:19:43.404446 12903 solver.cpp:353] Iteration 29700 (63.4194 iter/s, 1.57681s/100 iter), loss = 0.0276138
I0801 13:19:43.404470 12903 solver.cpp:375]     Train net output #0: loss = 0.0276147 (* 1 = 0.0276147 loss)
I0801 13:19:43.404475 12903 sgd_solver.cpp:136] Iteration 29700, lr = 0.0535938, m = 0.9
I0801 13:19:44.973008 12903 solver.cpp:353] Iteration 29800 (63.7547 iter/s, 1.56851s/100 iter), loss = 0.2419
I0801 13:19:44.973090 12903 solver.cpp:375]     Train net output #0: loss = 0.241901 (* 1 = 0.241901 loss)
I0801 13:19:44.973098 12903 sgd_solver.cpp:136] Iteration 29800, lr = 0.0534375, m = 0.9
I0801 13:19:46.556089 12903 solver.cpp:353] Iteration 29900 (63.17 iter/s, 1.58303s/100 iter), loss = 0.0645409
I0801 13:19:46.556155 12903 solver.cpp:375]     Train net output #0: loss = 0.0645418 (* 1 = 0.0645418 loss)
I0801 13:19:46.556174 12903 sgd_solver.cpp:136] Iteration 29900, lr = 0.0532812, m = 0.9
I0801 13:19:48.107110 12903 solver.cpp:680] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/initial/cifar10_jacintonet11v2_iter_30000.caffemodel
I0801 13:19:48.115345 12903 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/initial/cifar10_jacintonet11v2_iter_30000.solverstate
I0801 13:19:48.119196 12903 solver.cpp:550] Iteration 30000, Testing net (#0)
I0801 13:19:48.924273 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.816766
I0801 13:19:48.924293 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.977647
I0801 13:19:48.924299 12903 solver.cpp:635]     Test net output #2: loss = 0.774208 (* 1 = 0.774208 loss)
I0801 13:19:48.924316 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.805095s
I0801 13:19:48.939811 12903 solver.cpp:353] Iteration 30000 (41.9524 iter/s, 2.38365s/100 iter), loss = 0.00282293
I0801 13:19:48.939831 12903 solver.cpp:375]     Train net output #0: loss = 0.00282387 (* 1 = 0.00282387 loss)
I0801 13:19:48.939836 12903 sgd_solver.cpp:136] Iteration 30000, lr = 0.053125, m = 0.9
I0801 13:19:50.522711 12903 solver.cpp:353] Iteration 30100 (63.1772 iter/s, 1.58285s/100 iter), loss = 0.0173817
I0801 13:19:50.522737 12903 solver.cpp:375]     Train net output #0: loss = 0.0173826 (* 1 = 0.0173826 loss)
I0801 13:19:50.522742 12903 sgd_solver.cpp:136] Iteration 30100, lr = 0.0529688, m = 0.9
I0801 13:19:52.087143 12903 solver.cpp:353] Iteration 30200 (63.923 iter/s, 1.56438s/100 iter), loss = 0.0142286
I0801 13:19:52.087172 12903 solver.cpp:375]     Train net output #0: loss = 0.0142297 (* 1 = 0.0142297 loss)
I0801 13:19:52.087177 12903 sgd_solver.cpp:136] Iteration 30200, lr = 0.0528125, m = 0.9
I0801 13:19:53.657212 12903 solver.cpp:353] Iteration 30300 (63.6935 iter/s, 1.57002s/100 iter), loss = 0.0293468
I0801 13:19:53.657268 12903 solver.cpp:375]     Train net output #0: loss = 0.0293478 (* 1 = 0.0293478 loss)
I0801 13:19:53.657281 12903 sgd_solver.cpp:136] Iteration 30300, lr = 0.0526563, m = 0.9
I0801 13:19:55.222640 12903 solver.cpp:353] Iteration 30400 (63.8822 iter/s, 1.56538s/100 iter), loss = 0.124695
I0801 13:19:55.222664 12903 solver.cpp:375]     Train net output #0: loss = 0.124696 (* 1 = 0.124696 loss)
I0801 13:19:55.222671 12903 sgd_solver.cpp:136] Iteration 30400, lr = 0.0525, m = 0.9
I0801 13:19:56.792764 12903 solver.cpp:353] Iteration 30500 (63.6913 iter/s, 1.57007s/100 iter), loss = 0.0972575
I0801 13:19:56.792790 12903 solver.cpp:375]     Train net output #0: loss = 0.0972584 (* 1 = 0.0972584 loss)
I0801 13:19:56.792795 12903 sgd_solver.cpp:136] Iteration 30500, lr = 0.0523438, m = 0.9
I0801 13:19:58.362519 12903 solver.cpp:353] Iteration 30600 (63.7061 iter/s, 1.56971s/100 iter), loss = 0.0933293
I0801 13:19:58.362543 12903 solver.cpp:375]     Train net output #0: loss = 0.0933302 (* 1 = 0.0933302 loss)
I0801 13:19:58.362550 12903 sgd_solver.cpp:136] Iteration 30600, lr = 0.0521875, m = 0.9
I0801 13:19:59.947283 12903 solver.cpp:353] Iteration 30700 (63.1029 iter/s, 1.58471s/100 iter), loss = 0.0172982
I0801 13:19:59.947332 12903 solver.cpp:375]     Train net output #0: loss = 0.0172991 (* 1 = 0.0172991 loss)
I0801 13:19:59.947345 12903 sgd_solver.cpp:136] Iteration 30700, lr = 0.0520312, m = 0.9
I0801 13:20:01.516372 12903 solver.cpp:353] Iteration 30800 (63.7333 iter/s, 1.56904s/100 iter), loss = 0.0307401
I0801 13:20:01.516422 12903 solver.cpp:375]     Train net output #0: loss = 0.030741 (* 1 = 0.030741 loss)
I0801 13:20:01.516436 12903 sgd_solver.cpp:136] Iteration 30800, lr = 0.051875, m = 0.9
I0801 13:20:03.079638 12903 solver.cpp:353] Iteration 30900 (63.9706 iter/s, 1.56322s/100 iter), loss = 0.00696703
I0801 13:20:03.079664 12903 solver.cpp:375]     Train net output #0: loss = 0.00696792 (* 1 = 0.00696792 loss)
I0801 13:20:03.079668 12903 sgd_solver.cpp:136] Iteration 30900, lr = 0.0517187, m = 0.9
I0801 13:20:04.635092 12903 solver.cpp:550] Iteration 31000, Testing net (#0)
I0801 13:20:04.919972 12893 data_reader.cpp:264] Starting prefetch of epoch 4
I0801 13:20:05.459306 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.808825
I0801 13:20:05.459326 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.990882
I0801 13:20:05.459331 12903 solver.cpp:635]     Test net output #2: loss = 0.72431 (* 1 = 0.72431 loss)
I0801 13:20:05.459347 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.824233s
I0801 13:20:05.474874 12903 solver.cpp:353] Iteration 31000 (41.7508 iter/s, 2.39517s/100 iter), loss = 0.123113
I0801 13:20:05.474894 12903 solver.cpp:375]     Train net output #0: loss = 0.123114 (* 1 = 0.123114 loss)
I0801 13:20:05.474900 12903 sgd_solver.cpp:136] Iteration 31000, lr = 0.0515625, m = 0.9
I0801 13:20:07.033507 12903 solver.cpp:353] Iteration 31100 (64.1609 iter/s, 1.55858s/100 iter), loss = 0.0327819
I0801 13:20:07.033534 12903 solver.cpp:375]     Train net output #0: loss = 0.0327828 (* 1 = 0.0327828 loss)
I0801 13:20:07.033540 12903 sgd_solver.cpp:136] Iteration 31100, lr = 0.0514063, m = 0.9
I0801 13:20:08.597133 12903 solver.cpp:353] Iteration 31200 (63.9559 iter/s, 1.56358s/100 iter), loss = 0.0352371
I0801 13:20:08.597158 12903 solver.cpp:375]     Train net output #0: loss = 0.0352379 (* 1 = 0.0352379 loss)
I0801 13:20:08.597162 12903 sgd_solver.cpp:136] Iteration 31200, lr = 0.05125, m = 0.9
I0801 13:20:10.186554 12903 solver.cpp:353] Iteration 31300 (62.918 iter/s, 1.58937s/100 iter), loss = 0.0120523
I0801 13:20:10.186581 12903 solver.cpp:375]     Train net output #0: loss = 0.0120531 (* 1 = 0.0120531 loss)
I0801 13:20:10.186588 12903 sgd_solver.cpp:136] Iteration 31300, lr = 0.0510938, m = 0.9
I0801 13:20:11.760176 12903 solver.cpp:353] Iteration 31400 (63.5495 iter/s, 1.57358s/100 iter), loss = 0.122995
I0801 13:20:11.760202 12903 solver.cpp:375]     Train net output #0: loss = 0.122996 (* 1 = 0.122996 loss)
I0801 13:20:11.760208 12903 sgd_solver.cpp:136] Iteration 31400, lr = 0.0509375, m = 0.9
I0801 13:20:13.330746 12903 solver.cpp:353] Iteration 31500 (63.6731 iter/s, 1.57052s/100 iter), loss = 0.0744548
I0801 13:20:13.330772 12903 solver.cpp:375]     Train net output #0: loss = 0.0744555 (* 1 = 0.0744555 loss)
I0801 13:20:13.330778 12903 sgd_solver.cpp:136] Iteration 31500, lr = 0.0507812, m = 0.9
I0801 13:20:14.903846 12903 solver.cpp:353] Iteration 31600 (63.5708 iter/s, 1.57305s/100 iter), loss = 0.144658
I0801 13:20:14.903872 12903 solver.cpp:375]     Train net output #0: loss = 0.144658 (* 1 = 0.144658 loss)
I0801 13:20:14.903878 12903 sgd_solver.cpp:136] Iteration 31600, lr = 0.050625, m = 0.9
I0801 13:20:16.484014 12903 solver.cpp:353] Iteration 31700 (63.2864 iter/s, 1.58012s/100 iter), loss = 0.0161382
I0801 13:20:16.484099 12903 solver.cpp:375]     Train net output #0: loss = 0.0161389 (* 1 = 0.0161389 loss)
I0801 13:20:16.484107 12903 sgd_solver.cpp:136] Iteration 31700, lr = 0.0504688, m = 0.9
I0801 13:20:18.054582 12903 solver.cpp:353] Iteration 31800 (63.673 iter/s, 1.57052s/100 iter), loss = 0.0319641
I0801 13:20:18.054630 12903 solver.cpp:375]     Train net output #0: loss = 0.0319648 (* 1 = 0.0319648 loss)
I0801 13:20:18.054643 12903 sgd_solver.cpp:136] Iteration 31800, lr = 0.0503125, m = 0.9
I0801 13:20:19.630633 12903 solver.cpp:353] Iteration 31900 (63.4518 iter/s, 1.576s/100 iter), loss = 0.160699
I0801 13:20:19.630659 12903 solver.cpp:375]     Train net output #0: loss = 0.160699 (* 1 = 0.160699 loss)
I0801 13:20:19.630666 12903 sgd_solver.cpp:136] Iteration 31900, lr = 0.0501562, m = 0.9
I0801 13:20:21.188724 12903 solver.cpp:550] Iteration 32000, Testing net (#0)
I0801 13:20:22.004017 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.842648
I0801 13:20:22.004041 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.987941
I0801 13:20:22.004047 12903 solver.cpp:635]     Test net output #2: loss = 0.627861 (* 1 = 0.627861 loss)
I0801 13:20:22.004062 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.815318s
I0801 13:20:22.021642 12903 solver.cpp:353] Iteration 32000 (41.8246 iter/s, 2.39094s/100 iter), loss = 0.141767
I0801 13:20:22.021663 12903 solver.cpp:375]     Train net output #0: loss = 0.141767 (* 1 = 0.141767 loss)
I0801 13:20:22.021667 12903 sgd_solver.cpp:136] Iteration 32000, lr = 0.05, m = 0.9
I0801 13:20:23.589875 12903 solver.cpp:353] Iteration 32100 (63.7681 iter/s, 1.56818s/100 iter), loss = 0.0670104
I0801 13:20:23.589901 12903 solver.cpp:375]     Train net output #0: loss = 0.0670111 (* 1 = 0.0670111 loss)
I0801 13:20:23.589907 12903 sgd_solver.cpp:136] Iteration 32100, lr = 0.0498438, m = 0.9
I0801 13:20:25.155197 12903 solver.cpp:353] Iteration 32200 (63.8866 iter/s, 1.56527s/100 iter), loss = 0.103009
I0801 13:20:25.155264 12903 solver.cpp:375]     Train net output #0: loss = 0.10301 (* 1 = 0.10301 loss)
I0801 13:20:25.155282 12903 sgd_solver.cpp:136] Iteration 32200, lr = 0.0496875, m = 0.9
I0801 13:20:26.748344 12903 solver.cpp:353] Iteration 32300 (62.7708 iter/s, 1.5931s/100 iter), loss = 0.0432137
I0801 13:20:26.748370 12903 solver.cpp:375]     Train net output #0: loss = 0.0432144 (* 1 = 0.0432144 loss)
I0801 13:20:26.748376 12903 sgd_solver.cpp:136] Iteration 32300, lr = 0.0495313, m = 0.9
I0801 13:20:28.314968 12903 solver.cpp:353] Iteration 32400 (63.8335 iter/s, 1.56658s/100 iter), loss = 0.0215235
I0801 13:20:28.315028 12903 solver.cpp:375]     Train net output #0: loss = 0.0215242 (* 1 = 0.0215242 loss)
I0801 13:20:28.315035 12903 sgd_solver.cpp:136] Iteration 32400, lr = 0.049375, m = 0.9
I0801 13:20:29.881680 12903 solver.cpp:353] Iteration 32500 (63.8299 iter/s, 1.56666s/100 iter), loss = 0.0548085
I0801 13:20:29.881705 12903 solver.cpp:375]     Train net output #0: loss = 0.0548092 (* 1 = 0.0548092 loss)
I0801 13:20:29.881709 12903 sgd_solver.cpp:136] Iteration 32500, lr = 0.0492188, m = 0.9
I0801 13:20:31.458968 12903 solver.cpp:353] Iteration 32600 (63.402 iter/s, 1.57724s/100 iter), loss = 0.141973
I0801 13:20:31.458993 12903 solver.cpp:375]     Train net output #0: loss = 0.141974 (* 1 = 0.141974 loss)
I0801 13:20:31.458999 12903 sgd_solver.cpp:136] Iteration 32600, lr = 0.0490625, m = 0.9
I0801 13:20:33.024302 12903 solver.cpp:353] Iteration 32700 (63.8862 iter/s, 1.56528s/100 iter), loss = 0.00710496
I0801 13:20:33.024332 12903 solver.cpp:375]     Train net output #0: loss = 0.00710569 (* 1 = 0.00710569 loss)
I0801 13:20:33.024338 12903 sgd_solver.cpp:136] Iteration 32700, lr = 0.0489062, m = 0.9
I0801 13:20:34.599494 12903 solver.cpp:353] Iteration 32800 (63.4863 iter/s, 1.57514s/100 iter), loss = 0.2191
I0801 13:20:34.599522 12903 solver.cpp:375]     Train net output #0: loss = 0.219101 (* 1 = 0.219101 loss)
I0801 13:20:34.599529 12903 sgd_solver.cpp:136] Iteration 32800, lr = 0.04875, m = 0.9
I0801 13:20:36.169252 12903 solver.cpp:353] Iteration 32900 (63.706 iter/s, 1.56971s/100 iter), loss = 0.131595
I0801 13:20:36.169296 12903 solver.cpp:375]     Train net output #0: loss = 0.131596 (* 1 = 0.131596 loss)
I0801 13:20:36.169303 12903 sgd_solver.cpp:136] Iteration 32900, lr = 0.0485937, m = 0.9
I0801 13:20:37.733317 12903 solver.cpp:550] Iteration 33000, Testing net (#0)
I0801 13:20:38.563258 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.845589
I0801 13:20:38.563279 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.991177
I0801 13:20:38.563284 12903 solver.cpp:635]     Test net output #2: loss = 0.648838 (* 1 = 0.648838 loss)
I0801 13:20:38.563300 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.82996s
I0801 13:20:38.578841 12903 solver.cpp:353] Iteration 33000 (41.502 iter/s, 2.40952s/100 iter), loss = 0.0207509
I0801 13:20:38.578876 12903 solver.cpp:375]     Train net output #0: loss = 0.0207516 (* 1 = 0.0207516 loss)
I0801 13:20:38.578891 12903 sgd_solver.cpp:136] Iteration 33000, lr = 0.0484375, m = 0.9
I0801 13:20:40.173532 12903 solver.cpp:353] Iteration 33100 (62.7101 iter/s, 1.59464s/100 iter), loss = 0.0663823
I0801 13:20:40.173583 12903 solver.cpp:375]     Train net output #0: loss = 0.066383 (* 1 = 0.066383 loss)
I0801 13:20:40.173595 12903 sgd_solver.cpp:136] Iteration 33100, lr = 0.0482813, m = 0.9
I0801 13:20:41.750718 12903 solver.cpp:353] Iteration 33200 (63.4061 iter/s, 1.57714s/100 iter), loss = 0.00263963
I0801 13:20:41.750746 12903 solver.cpp:375]     Train net output #0: loss = 0.00264033 (* 1 = 0.00264033 loss)
I0801 13:20:41.750752 12903 sgd_solver.cpp:136] Iteration 33200, lr = 0.048125, m = 0.9
I0801 13:20:43.322434 12903 solver.cpp:353] Iteration 33300 (63.6266 iter/s, 1.57167s/100 iter), loss = 0.0533619
I0801 13:20:43.322484 12903 solver.cpp:375]     Train net output #0: loss = 0.0533626 (* 1 = 0.0533626 loss)
I0801 13:20:43.322497 12903 sgd_solver.cpp:136] Iteration 33300, lr = 0.0479688, m = 0.9
I0801 13:20:44.906105 12903 solver.cpp:353] Iteration 33400 (63.1464 iter/s, 1.58362s/100 iter), loss = 0.0122192
I0801 13:20:44.906157 12903 solver.cpp:375]     Train net output #0: loss = 0.0122198 (* 1 = 0.0122198 loss)
I0801 13:20:44.906170 12903 sgd_solver.cpp:136] Iteration 33400, lr = 0.0478125, m = 0.9
I0801 13:20:46.475555 12903 solver.cpp:353] Iteration 33500 (63.7187 iter/s, 1.5694s/100 iter), loss = 0.0520932
I0801 13:20:46.475580 12903 solver.cpp:375]     Train net output #0: loss = 0.0520939 (* 1 = 0.0520939 loss)
I0801 13:20:46.475587 12903 sgd_solver.cpp:136] Iteration 33500, lr = 0.0476562, m = 0.9
I0801 13:20:48.040910 12903 solver.cpp:353] Iteration 33600 (63.8852 iter/s, 1.56531s/100 iter), loss = 0.114354
I0801 13:20:48.040997 12903 solver.cpp:375]     Train net output #0: loss = 0.114355 (* 1 = 0.114355 loss)
I0801 13:20:48.041005 12903 sgd_solver.cpp:136] Iteration 33600, lr = 0.0475, m = 0.9
I0801 13:20:49.619446 12903 solver.cpp:353] Iteration 33700 (63.3518 iter/s, 1.57849s/100 iter), loss = 0.0320136
I0801 13:20:49.619472 12903 solver.cpp:375]     Train net output #0: loss = 0.0320143 (* 1 = 0.0320143 loss)
I0801 13:20:49.619477 12903 sgd_solver.cpp:136] Iteration 33700, lr = 0.0473437, m = 0.9
I0801 13:20:51.187954 12903 solver.cpp:353] Iteration 33800 (63.7568 iter/s, 1.56846s/100 iter), loss = 0.00604984
I0801 13:20:51.187978 12903 solver.cpp:375]     Train net output #0: loss = 0.00605062 (* 1 = 0.00605062 loss)
I0801 13:20:51.187983 12903 sgd_solver.cpp:136] Iteration 33800, lr = 0.0471875, m = 0.9
I0801 13:20:52.757736 12903 solver.cpp:353] Iteration 33900 (63.7052 iter/s, 1.56973s/100 iter), loss = 0.0420881
I0801 13:20:52.757761 12903 solver.cpp:375]     Train net output #0: loss = 0.0420888 (* 1 = 0.0420888 loss)
I0801 13:20:52.757767 12903 sgd_solver.cpp:136] Iteration 33900, lr = 0.0470312, m = 0.9
I0801 13:20:54.307013 12903 solver.cpp:550] Iteration 34000, Testing net (#0)
I0801 13:20:55.124490 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.864413
I0801 13:20:55.124511 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.993529
I0801 13:20:55.124516 12903 solver.cpp:635]     Test net output #2: loss = 0.50605 (* 1 = 0.50605 loss)
I0801 13:20:55.124531 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.817495s
I0801 13:20:55.140169 12903 solver.cpp:353] Iteration 34000 (41.9751 iter/s, 2.38236s/100 iter), loss = 0.0788738
I0801 13:20:55.140188 12903 solver.cpp:375]     Train net output #0: loss = 0.0788746 (* 1 = 0.0788746 loss)
I0801 13:20:55.140194 12903 sgd_solver.cpp:136] Iteration 34000, lr = 0.046875, m = 0.9
I0801 13:20:56.720142 12903 solver.cpp:353] Iteration 34100 (63.2943 iter/s, 1.57992s/100 iter), loss = 0.0111962
I0801 13:20:56.720167 12903 solver.cpp:375]     Train net output #0: loss = 0.011197 (* 1 = 0.011197 loss)
I0801 13:20:56.720172 12903 sgd_solver.cpp:136] Iteration 34100, lr = 0.0467188, m = 0.9
I0801 13:20:58.288722 12903 solver.cpp:353] Iteration 34200 (63.7539 iter/s, 1.56853s/100 iter), loss = 0.0603026
I0801 13:20:58.288748 12903 solver.cpp:375]     Train net output #0: loss = 0.0603034 (* 1 = 0.0603034 loss)
I0801 13:20:58.288754 12903 sgd_solver.cpp:136] Iteration 34200, lr = 0.0465625, m = 0.9
I0801 13:20:59.862128 12903 solver.cpp:353] Iteration 34300 (63.5584 iter/s, 1.57336s/100 iter), loss = 0.00766906
I0801 13:20:59.862155 12903 solver.cpp:375]     Train net output #0: loss = 0.00766982 (* 1 = 0.00766982 loss)
I0801 13:20:59.862161 12903 sgd_solver.cpp:136] Iteration 34300, lr = 0.0464063, m = 0.9
I0801 13:21:01.422943 12903 solver.cpp:353] Iteration 34400 (64.0712 iter/s, 1.56076s/100 iter), loss = 0.0704771
I0801 13:21:01.422971 12903 solver.cpp:375]     Train net output #0: loss = 0.0704779 (* 1 = 0.0704779 loss)
I0801 13:21:01.422977 12903 sgd_solver.cpp:136] Iteration 34400, lr = 0.04625, m = 0.9
I0801 13:21:02.978734 12903 solver.cpp:353] Iteration 34500 (64.278 iter/s, 1.55574s/100 iter), loss = 0.000861189
I0801 13:21:02.978759 12903 solver.cpp:375]     Train net output #0: loss = 0.000861965 (* 1 = 0.000861965 loss)
I0801 13:21:02.978765 12903 sgd_solver.cpp:136] Iteration 34500, lr = 0.0460938, m = 0.9
I0801 13:21:04.536851 12903 solver.cpp:353] Iteration 34600 (64.182 iter/s, 1.55807s/100 iter), loss = 0.0459457
I0801 13:21:04.536876 12903 solver.cpp:375]     Train net output #0: loss = 0.0459465 (* 1 = 0.0459465 loss)
I0801 13:21:04.536882 12903 sgd_solver.cpp:136] Iteration 34600, lr = 0.0459375, m = 0.9
I0801 13:21:06.111032 12903 solver.cpp:353] Iteration 34700 (63.5271 iter/s, 1.57413s/100 iter), loss = 0.0359318
I0801 13:21:06.111086 12903 solver.cpp:375]     Train net output #0: loss = 0.0359325 (* 1 = 0.0359325 loss)
I0801 13:21:06.111100 12903 sgd_solver.cpp:136] Iteration 34700, lr = 0.0457813, m = 0.9
I0801 13:21:07.684150 12903 solver.cpp:353] Iteration 34800 (63.5701 iter/s, 1.57307s/100 iter), loss = 0.00243393
I0801 13:21:07.684216 12903 solver.cpp:375]     Train net output #0: loss = 0.00243463 (* 1 = 0.00243463 loss)
I0801 13:21:07.684229 12903 sgd_solver.cpp:136] Iteration 34800, lr = 0.045625, m = 0.9
I0801 13:21:09.245198 12903 solver.cpp:353] Iteration 34900 (64.0616 iter/s, 1.561s/100 iter), loss = 0.100616
I0801 13:21:09.245223 12903 solver.cpp:375]     Train net output #0: loss = 0.100617 (* 1 = 0.100617 loss)
I0801 13:21:09.245229 12903 sgd_solver.cpp:136] Iteration 34900, lr = 0.0454687, m = 0.9
I0801 13:21:10.787868 12903 solver.cpp:550] Iteration 35000, Testing net (#0)
I0801 13:21:11.010586 12893 data_reader.cpp:264] Starting prefetch of epoch 5
I0801 13:21:11.604420 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.824413
I0801 13:21:11.604444 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.986471
I0801 13:21:11.604454 12903 solver.cpp:635]     Test net output #2: loss = 0.700598 (* 1 = 0.700598 loss)
I0801 13:21:11.604478 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.816586s
I0801 13:21:11.624210 12903 solver.cpp:353] Iteration 35000 (42.0355 iter/s, 2.37894s/100 iter), loss = 0.084809
I0801 13:21:11.624236 12903 solver.cpp:375]     Train net output #0: loss = 0.0848097 (* 1 = 0.0848097 loss)
I0801 13:21:11.624243 12903 sgd_solver.cpp:136] Iteration 35000, lr = 0.0453125, m = 0.9
I0801 13:21:13.184963 12903 solver.cpp:353] Iteration 35100 (64.0739 iter/s, 1.5607s/100 iter), loss = 0.0110816
I0801 13:21:13.185019 12903 solver.cpp:375]     Train net output #0: loss = 0.0110823 (* 1 = 0.0110823 loss)
I0801 13:21:13.185034 12903 sgd_solver.cpp:136] Iteration 35100, lr = 0.0451563, m = 0.9
I0801 13:21:14.768916 12903 solver.cpp:353] Iteration 35200 (63.1352 iter/s, 1.5839s/100 iter), loss = 0.145628
I0801 13:21:14.768968 12903 solver.cpp:375]     Train net output #0: loss = 0.145629 (* 1 = 0.145629 loss)
I0801 13:21:14.768982 12903 sgd_solver.cpp:136] Iteration 35200, lr = 0.045, m = 0.9
I0801 13:21:16.345621 12903 solver.cpp:353] Iteration 35300 (63.4253 iter/s, 1.57666s/100 iter), loss = 0.0221993
I0801 13:21:16.345671 12903 solver.cpp:375]     Train net output #0: loss = 0.0222 (* 1 = 0.0222 loss)
I0801 13:21:16.345679 12903 sgd_solver.cpp:136] Iteration 35300, lr = 0.0448438, m = 0.9
I0801 13:21:17.919375 12903 solver.cpp:353] Iteration 35400 (63.5444 iter/s, 1.5737s/100 iter), loss = 0.0069335
I0801 13:21:17.919401 12903 solver.cpp:375]     Train net output #0: loss = 0.0069342 (* 1 = 0.0069342 loss)
I0801 13:21:17.919406 12903 sgd_solver.cpp:136] Iteration 35400, lr = 0.0446875, m = 0.9
I0801 13:21:19.490217 12903 solver.cpp:353] Iteration 35500 (63.6621 iter/s, 1.57079s/100 iter), loss = 0.0534759
I0801 13:21:19.490308 12903 solver.cpp:375]     Train net output #0: loss = 0.0534765 (* 1 = 0.0534765 loss)
I0801 13:21:19.490315 12903 sgd_solver.cpp:136] Iteration 35500, lr = 0.0445313, m = 0.9
I0801 13:21:21.066292 12903 solver.cpp:353] Iteration 35600 (63.4508 iter/s, 1.57602s/100 iter), loss = 0.167116
I0801 13:21:21.066318 12903 solver.cpp:375]     Train net output #0: loss = 0.167117 (* 1 = 0.167117 loss)
I0801 13:21:21.066323 12903 sgd_solver.cpp:136] Iteration 35600, lr = 0.044375, m = 0.9
I0801 13:21:22.637814 12903 solver.cpp:353] Iteration 35700 (63.6346 iter/s, 1.57147s/100 iter), loss = 0.0044398
I0801 13:21:22.637841 12903 solver.cpp:375]     Train net output #0: loss = 0.00444054 (* 1 = 0.00444054 loss)
I0801 13:21:22.637847 12903 sgd_solver.cpp:136] Iteration 35700, lr = 0.0442187, m = 0.9
I0801 13:21:24.193387 12903 solver.cpp:353] Iteration 35800 (64.287 iter/s, 1.55552s/100 iter), loss = 0.183123
I0801 13:21:24.193413 12903 solver.cpp:375]     Train net output #0: loss = 0.183124 (* 1 = 0.183124 loss)
I0801 13:21:24.193418 12903 sgd_solver.cpp:136] Iteration 35800, lr = 0.0440625, m = 0.9
I0801 13:21:25.755043 12903 solver.cpp:353] Iteration 35900 (64.0367 iter/s, 1.56161s/100 iter), loss = 0.00455636
I0801 13:21:25.755069 12903 solver.cpp:375]     Train net output #0: loss = 0.00455704 (* 1 = 0.00455704 loss)
I0801 13:21:25.755075 12903 sgd_solver.cpp:136] Iteration 35900, lr = 0.0439062, m = 0.9
I0801 13:21:27.327338 12903 solver.cpp:550] Iteration 36000, Testing net (#0)
I0801 13:21:28.143462 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.850001
I0801 13:21:28.143481 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.990588
I0801 13:21:28.143486 12903 solver.cpp:635]     Test net output #2: loss = 0.556262 (* 1 = 0.556262 loss)
I0801 13:21:28.143501 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.81614s
I0801 13:21:28.159039 12903 solver.cpp:353] Iteration 36000 (41.5987 iter/s, 2.40392s/100 iter), loss = 0.00880365
I0801 13:21:28.159073 12903 solver.cpp:375]     Train net output #0: loss = 0.00880438 (* 1 = 0.00880438 loss)
I0801 13:21:28.159086 12903 sgd_solver.cpp:136] Iteration 36000, lr = 0.04375, m = 0.9
I0801 13:21:29.736711 12903 solver.cpp:353] Iteration 36100 (63.3866 iter/s, 1.57762s/100 iter), loss = 0.0686506
I0801 13:21:29.736763 12903 solver.cpp:375]     Train net output #0: loss = 0.0686513 (* 1 = 0.0686513 loss)
I0801 13:21:29.736775 12903 sgd_solver.cpp:136] Iteration 36100, lr = 0.0435938, m = 0.9
I0801 13:21:31.309363 12903 solver.cpp:353] Iteration 36200 (63.589 iter/s, 1.5726s/100 iter), loss = 0.010064
I0801 13:21:31.309392 12903 solver.cpp:375]     Train net output #0: loss = 0.0100648 (* 1 = 0.0100648 loss)
I0801 13:21:31.309399 12903 sgd_solver.cpp:136] Iteration 36200, lr = 0.0434375, m = 0.9
I0801 13:21:32.883000 12903 solver.cpp:353] Iteration 36300 (63.549 iter/s, 1.57359s/100 iter), loss = 0.0260525
I0801 13:21:32.883026 12903 solver.cpp:375]     Train net output #0: loss = 0.0260533 (* 1 = 0.0260533 loss)
I0801 13:21:32.883030 12903 sgd_solver.cpp:136] Iteration 36300, lr = 0.0432813, m = 0.9
I0801 13:21:34.456220 12903 solver.cpp:353] Iteration 36400 (63.5659 iter/s, 1.57317s/100 iter), loss = 0.00627342
I0801 13:21:34.456244 12903 solver.cpp:375]     Train net output #0: loss = 0.00627415 (* 1 = 0.00627415 loss)
I0801 13:21:34.456248 12903 sgd_solver.cpp:136] Iteration 36400, lr = 0.043125, m = 0.9
I0801 13:21:36.021198 12903 solver.cpp:353] Iteration 36500 (63.9007 iter/s, 1.56493s/100 iter), loss = 0.0158319
I0801 13:21:36.021224 12903 solver.cpp:375]     Train net output #0: loss = 0.0158326 (* 1 = 0.0158326 loss)
I0801 13:21:36.021229 12903 sgd_solver.cpp:136] Iteration 36500, lr = 0.0429688, m = 0.9
I0801 13:21:37.585971 12903 solver.cpp:353] Iteration 36600 (63.909 iter/s, 1.56472s/100 iter), loss = 0.0196456
I0801 13:21:37.585997 12903 solver.cpp:375]     Train net output #0: loss = 0.0196463 (* 1 = 0.0196463 loss)
I0801 13:21:37.586004 12903 sgd_solver.cpp:136] Iteration 36600, lr = 0.0428125, m = 0.9
I0801 13:21:39.153141 12903 solver.cpp:353] Iteration 36700 (63.8114 iter/s, 1.56712s/100 iter), loss = 0.0356679
I0801 13:21:39.153185 12903 solver.cpp:375]     Train net output #0: loss = 0.0356686 (* 1 = 0.0356686 loss)
I0801 13:21:39.153192 12903 sgd_solver.cpp:136] Iteration 36700, lr = 0.0426563, m = 0.9
I0801 13:21:40.729609 12903 solver.cpp:353] Iteration 36800 (63.4349 iter/s, 1.57642s/100 iter), loss = 0.0022766
I0801 13:21:40.729670 12903 solver.cpp:375]     Train net output #0: loss = 0.00227732 (* 1 = 0.00227732 loss)
I0801 13:21:40.729688 12903 sgd_solver.cpp:136] Iteration 36800, lr = 0.0425, m = 0.9
I0801 13:21:42.294559 12903 solver.cpp:353] Iteration 36900 (63.9019 iter/s, 1.5649s/100 iter), loss = 0.0258758
I0801 13:21:42.294589 12903 solver.cpp:375]     Train net output #0: loss = 0.0258765 (* 1 = 0.0258765 loss)
I0801 13:21:42.294595 12903 sgd_solver.cpp:136] Iteration 36900, lr = 0.0423437, m = 0.9
I0801 13:21:43.840965 12903 solver.cpp:550] Iteration 37000, Testing net (#0)
I0801 13:21:44.658710 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.810001
I0801 13:21:44.658727 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.991471
I0801 13:21:44.658732 12903 solver.cpp:635]     Test net output #2: loss = 0.832782 (* 1 = 0.832782 loss)
I0801 13:21:44.658748 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.817761s
I0801 13:21:44.674500 12903 solver.cpp:353] Iteration 37000 (42.0191 iter/s, 2.37987s/100 iter), loss = 0.00558834
I0801 13:21:44.674520 12903 solver.cpp:375]     Train net output #0: loss = 0.00558905 (* 1 = 0.00558905 loss)
I0801 13:21:44.674525 12903 sgd_solver.cpp:136] Iteration 37000, lr = 0.0421875, m = 0.9
I0801 13:21:46.266409 12903 solver.cpp:353] Iteration 37100 (62.8198 iter/s, 1.59186s/100 iter), loss = 0.00339739
I0801 13:21:46.266463 12903 solver.cpp:375]     Train net output #0: loss = 0.00339808 (* 1 = 0.00339808 loss)
I0801 13:21:46.266471 12903 sgd_solver.cpp:136] Iteration 37100, lr = 0.0420313, m = 0.9
I0801 13:21:47.839165 12903 solver.cpp:353] Iteration 37200 (63.5845 iter/s, 1.57271s/100 iter), loss = 0.012429
I0801 13:21:47.839190 12903 solver.cpp:375]     Train net output #0: loss = 0.0124297 (* 1 = 0.0124297 loss)
I0801 13:21:47.839196 12903 sgd_solver.cpp:136] Iteration 37200, lr = 0.041875, m = 0.9
I0801 13:21:49.413099 12903 solver.cpp:353] Iteration 37300 (63.5372 iter/s, 1.57388s/100 iter), loss = 0.0185539
I0801 13:21:49.413122 12903 solver.cpp:375]     Train net output #0: loss = 0.0185545 (* 1 = 0.0185545 loss)
I0801 13:21:49.413126 12903 sgd_solver.cpp:136] Iteration 37300, lr = 0.0417188, m = 0.9
I0801 13:21:50.979746 12903 solver.cpp:353] Iteration 37400 (63.8325 iter/s, 1.5666s/100 iter), loss = 0.0139212
I0801 13:21:50.979845 12903 solver.cpp:375]     Train net output #0: loss = 0.0139218 (* 1 = 0.0139218 loss)
I0801 13:21:50.979857 12903 sgd_solver.cpp:136] Iteration 37400, lr = 0.0415625, m = 0.9
I0801 13:21:52.541896 12903 solver.cpp:353] Iteration 37500 (64.0164 iter/s, 1.5621s/100 iter), loss = 0.0437395
I0801 13:21:52.541923 12903 solver.cpp:375]     Train net output #0: loss = 0.0437402 (* 1 = 0.0437402 loss)
I0801 13:21:52.541929 12903 sgd_solver.cpp:136] Iteration 37500, lr = 0.0414063, m = 0.9
I0801 13:21:54.121470 12903 solver.cpp:353] Iteration 37600 (63.3103 iter/s, 1.57952s/100 iter), loss = 0.0486163
I0801 13:21:54.121496 12903 solver.cpp:375]     Train net output #0: loss = 0.048617 (* 1 = 0.048617 loss)
I0801 13:21:54.121502 12903 sgd_solver.cpp:136] Iteration 37600, lr = 0.04125, m = 0.9
I0801 13:21:55.690500 12903 solver.cpp:353] Iteration 37700 (63.7356 iter/s, 1.56898s/100 iter), loss = 0.0429001
I0801 13:21:55.690546 12903 solver.cpp:375]     Train net output #0: loss = 0.0429007 (* 1 = 0.0429007 loss)
I0801 13:21:55.690559 12903 sgd_solver.cpp:136] Iteration 37700, lr = 0.0410937, m = 0.9
I0801 13:21:57.274880 12903 solver.cpp:353] Iteration 37800 (63.1182 iter/s, 1.58433s/100 iter), loss = 0.0267743
I0801 13:21:57.274943 12903 solver.cpp:375]     Train net output #0: loss = 0.0267749 (* 1 = 0.0267749 loss)
I0801 13:21:57.274961 12903 sgd_solver.cpp:136] Iteration 37800, lr = 0.0409375, m = 0.9
I0801 13:21:58.852851 12903 solver.cpp:353] Iteration 37900 (63.3745 iter/s, 1.57792s/100 iter), loss = 0.00860051
I0801 13:21:58.852896 12903 solver.cpp:375]     Train net output #0: loss = 0.00860116 (* 1 = 0.00860116 loss)
I0801 13:21:58.852910 12903 sgd_solver.cpp:136] Iteration 37900, lr = 0.0407812, m = 0.9
I0801 13:22:00.400579 12903 solver.cpp:550] Iteration 38000, Testing net (#0)
I0801 13:22:01.229962 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.853237
I0801 13:22:01.229984 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.994706
I0801 13:22:01.229990 12903 solver.cpp:635]     Test net output #2: loss = 0.560239 (* 1 = 0.560239 loss)
I0801 13:22:01.230007 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.829403s
I0801 13:22:01.245518 12903 solver.cpp:353] Iteration 38000 (41.7956 iter/s, 2.3926s/100 iter), loss = 0.02575
I0801 13:22:01.245551 12903 solver.cpp:375]     Train net output #0: loss = 0.0257506 (* 1 = 0.0257506 loss)
I0801 13:22:01.245565 12903 sgd_solver.cpp:136] Iteration 38000, lr = 0.040625, m = 0.9
I0801 13:22:02.805614 12903 solver.cpp:353] Iteration 38100 (64.1007 iter/s, 1.56005s/100 iter), loss = 0.00618284
I0801 13:22:02.805640 12903 solver.cpp:375]     Train net output #0: loss = 0.00618346 (* 1 = 0.00618346 loss)
I0801 13:22:02.805646 12903 sgd_solver.cpp:136] Iteration 38100, lr = 0.0404688, m = 0.9
I0801 13:22:04.388962 12903 solver.cpp:353] Iteration 38200 (63.1594 iter/s, 1.58329s/100 iter), loss = 0.00480429
I0801 13:22:04.389015 12903 solver.cpp:375]     Train net output #0: loss = 0.00480495 (* 1 = 0.00480495 loss)
I0801 13:22:04.389024 12903 sgd_solver.cpp:136] Iteration 38200, lr = 0.0403125, m = 0.9
I0801 13:22:05.972122 12903 solver.cpp:353] Iteration 38300 (63.1668 iter/s, 1.58311s/100 iter), loss = 0.00375757
I0801 13:22:05.972149 12903 solver.cpp:375]     Train net output #0: loss = 0.00375821 (* 1 = 0.00375821 loss)
I0801 13:22:05.972156 12903 sgd_solver.cpp:136] Iteration 38300, lr = 0.0401563, m = 0.9
I0801 13:22:07.556260 12903 solver.cpp:353] Iteration 38400 (63.1279 iter/s, 1.58409s/100 iter), loss = 0.0140965
I0801 13:22:07.556289 12903 solver.cpp:375]     Train net output #0: loss = 0.0140971 (* 1 = 0.0140971 loss)
I0801 13:22:07.556298 12903 sgd_solver.cpp:136] Iteration 38400, lr = 0.04, m = 0.9
I0801 13:22:09.123580 12903 solver.cpp:353] Iteration 38500 (63.8051 iter/s, 1.56727s/100 iter), loss = 0.044271
I0801 13:22:09.123607 12903 solver.cpp:375]     Train net output #0: loss = 0.0442716 (* 1 = 0.0442716 loss)
I0801 13:22:09.123613 12903 sgd_solver.cpp:136] Iteration 38500, lr = 0.0398437, m = 0.9
I0801 13:22:10.715175 12903 solver.cpp:353] Iteration 38600 (62.832 iter/s, 1.59154s/100 iter), loss = 0.00170557
I0801 13:22:10.715224 12903 solver.cpp:375]     Train net output #0: loss = 0.00170623 (* 1 = 0.00170623 loss)
I0801 13:22:10.715230 12903 sgd_solver.cpp:136] Iteration 38600, lr = 0.0396875, m = 0.9
I0801 13:22:12.289366 12903 solver.cpp:353] Iteration 38700 (63.5267 iter/s, 1.57414s/100 iter), loss = 0.0383477
I0801 13:22:12.289392 12903 solver.cpp:375]     Train net output #0: loss = 0.0383483 (* 1 = 0.0383483 loss)
I0801 13:22:12.289398 12903 sgd_solver.cpp:136] Iteration 38700, lr = 0.0395312, m = 0.9
I0801 13:22:13.851032 12903 solver.cpp:353] Iteration 38800 (64.0363 iter/s, 1.56162s/100 iter), loss = 0.0363005
I0801 13:22:13.851058 12903 solver.cpp:375]     Train net output #0: loss = 0.0363011 (* 1 = 0.0363011 loss)
I0801 13:22:13.851063 12903 sgd_solver.cpp:136] Iteration 38800, lr = 0.039375, m = 0.9
I0801 13:22:15.424202 12903 solver.cpp:353] Iteration 38900 (63.5679 iter/s, 1.57312s/100 iter), loss = 0.0199156
I0801 13:22:15.424227 12903 solver.cpp:375]     Train net output #0: loss = 0.0199162 (* 1 = 0.0199162 loss)
I0801 13:22:15.424233 12903 sgd_solver.cpp:136] Iteration 38900, lr = 0.0392187, m = 0.9
I0801 13:22:16.977782 12903 solver.cpp:550] Iteration 39000, Testing net (#0)
I0801 13:22:17.794718 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.866472
I0801 13:22:17.794737 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.991471
I0801 13:22:17.794742 12903 solver.cpp:635]     Test net output #2: loss = 0.540518 (* 1 = 0.540518 loss)
I0801 13:22:17.794756 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.816951s
I0801 13:22:17.810317 12903 solver.cpp:353] Iteration 39000 (41.9104 iter/s, 2.38605s/100 iter), loss = 0.00339754
I0801 13:22:17.810333 12903 solver.cpp:375]     Train net output #0: loss = 0.0033982 (* 1 = 0.0033982 loss)
I0801 13:22:17.810338 12903 sgd_solver.cpp:136] Iteration 39000, lr = 0.0390625, m = 0.9
I0801 13:22:19.380826 12903 solver.cpp:353] Iteration 39100 (63.6758 iter/s, 1.57046s/100 iter), loss = 0.00743481
I0801 13:22:19.380854 12903 solver.cpp:375]     Train net output #0: loss = 0.00743545 (* 1 = 0.00743545 loss)
I0801 13:22:19.380862 12903 sgd_solver.cpp:136] Iteration 39100, lr = 0.0389063, m = 0.9
I0801 13:22:20.957968 12903 solver.cpp:353] Iteration 39200 (63.4078 iter/s, 1.57709s/100 iter), loss = 0.00468189
I0801 13:22:20.957993 12903 solver.cpp:375]     Train net output #0: loss = 0.00468255 (* 1 = 0.00468255 loss)
I0801 13:22:20.957998 12903 sgd_solver.cpp:136] Iteration 39200, lr = 0.03875, m = 0.9
I0801 13:22:22.529660 12903 solver.cpp:353] Iteration 39300 (63.6277 iter/s, 1.57164s/100 iter), loss = 0.0260674
I0801 13:22:22.529747 12903 solver.cpp:375]     Train net output #0: loss = 0.026068 (* 1 = 0.026068 loss)
I0801 13:22:22.529755 12903 sgd_solver.cpp:136] Iteration 39300, lr = 0.0385938, m = 0.9
I0801 13:22:23.943529 12870 data_reader.cpp:264] Starting prefetch of epoch 5
I0801 13:22:24.097896 12903 solver.cpp:353] Iteration 39400 (63.7679 iter/s, 1.56819s/100 iter), loss = 0.0311039
I0801 13:22:24.097921 12903 solver.cpp:375]     Train net output #0: loss = 0.0311046 (* 1 = 0.0311046 loss)
I0801 13:22:24.097928 12903 sgd_solver.cpp:136] Iteration 39400, lr = 0.0384375, m = 0.9
I0801 13:22:25.673393 12903 solver.cpp:353] Iteration 39500 (63.474 iter/s, 1.57545s/100 iter), loss = 0.00666544
I0801 13:22:25.673420 12903 solver.cpp:375]     Train net output #0: loss = 0.00666608 (* 1 = 0.00666608 loss)
I0801 13:22:25.673426 12903 sgd_solver.cpp:136] Iteration 39500, lr = 0.0382813, m = 0.9
I0801 13:22:27.244699 12903 solver.cpp:353] Iteration 39600 (63.6435 iter/s, 1.57125s/100 iter), loss = 0.0184722
I0801 13:22:27.244724 12903 solver.cpp:375]     Train net output #0: loss = 0.0184729 (* 1 = 0.0184729 loss)
I0801 13:22:27.244730 12903 sgd_solver.cpp:136] Iteration 39600, lr = 0.038125, m = 0.9
I0801 13:22:28.826341 12903 solver.cpp:353] Iteration 39700 (63.2273 iter/s, 1.58159s/100 iter), loss = 0.0589073
I0801 13:22:28.826370 12903 solver.cpp:375]     Train net output #0: loss = 0.0589079 (* 1 = 0.0589079 loss)
I0801 13:22:28.826377 12903 sgd_solver.cpp:136] Iteration 39700, lr = 0.0379688, m = 0.9
I0801 13:22:30.408896 12903 solver.cpp:353] Iteration 39800 (63.191 iter/s, 1.5825s/100 iter), loss = 0.0327832
I0801 13:22:30.408939 12903 solver.cpp:375]     Train net output #0: loss = 0.0327838 (* 1 = 0.0327838 loss)
I0801 13:22:30.408946 12903 sgd_solver.cpp:136] Iteration 39800, lr = 0.0378125, m = 0.9
I0801 13:22:31.965821 12903 solver.cpp:353] Iteration 39900 (64.2312 iter/s, 1.55688s/100 iter), loss = 0.00806561
I0801 13:22:31.965847 12903 solver.cpp:375]     Train net output #0: loss = 0.00806624 (* 1 = 0.00806624 loss)
I0801 13:22:31.965852 12903 sgd_solver.cpp:136] Iteration 39900, lr = 0.0376562, m = 0.9
I0801 13:22:33.530298 12903 solver.cpp:680] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/initial/cifar10_jacintonet11v2_iter_40000.caffemodel
I0801 13:22:33.540218 12903 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/initial/cifar10_jacintonet11v2_iter_40000.solverstate
I0801 13:22:33.545266 12903 solver.cpp:550] Iteration 40000, Testing net (#0)
I0801 13:22:34.372448 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.851472
I0801 13:22:34.372469 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.992353
I0801 13:22:34.372475 12903 solver.cpp:635]     Test net output #2: loss = 0.613981 (* 1 = 0.613981 loss)
I0801 13:22:34.372501 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.82721s
I0801 13:22:34.388134 12903 solver.cpp:353] Iteration 40000 (41.284 iter/s, 2.42224s/100 iter), loss = 0.000913055
I0801 13:22:34.388150 12903 solver.cpp:375]     Train net output #0: loss = 0.000913658 (* 1 = 0.000913658 loss)
I0801 13:22:34.388157 12903 sgd_solver.cpp:136] Iteration 40000, lr = 0.0375, m = 0.9
I0801 13:22:35.952852 12903 solver.cpp:353] Iteration 40100 (63.9114 iter/s, 1.56467s/100 iter), loss = 0.0289101
I0801 13:22:35.952881 12903 solver.cpp:375]     Train net output #0: loss = 0.0289107 (* 1 = 0.0289107 loss)
I0801 13:22:35.952889 12903 sgd_solver.cpp:136] Iteration 40100, lr = 0.0373438, m = 0.9
I0801 13:22:37.518323 12903 solver.cpp:353] Iteration 40200 (63.8806 iter/s, 1.56542s/100 iter), loss = 0.00203802
I0801 13:22:37.518354 12903 solver.cpp:375]     Train net output #0: loss = 0.00203862 (* 1 = 0.00203862 loss)
I0801 13:22:37.518362 12903 sgd_solver.cpp:136] Iteration 40200, lr = 0.0371875, m = 0.9
I0801 13:22:39.099884 12903 solver.cpp:353] Iteration 40300 (63.2306 iter/s, 1.58151s/100 iter), loss = 0.07079
I0801 13:22:39.099911 12903 solver.cpp:375]     Train net output #0: loss = 0.0707906 (* 1 = 0.0707906 loss)
I0801 13:22:39.099947 12903 sgd_solver.cpp:136] Iteration 40300, lr = 0.0370313, m = 0.9
I0801 13:22:40.678938 12903 solver.cpp:353] Iteration 40400 (63.3311 iter/s, 1.579s/100 iter), loss = 0.0392231
I0801 13:22:40.678966 12903 solver.cpp:375]     Train net output #0: loss = 0.0392237 (* 1 = 0.0392237 loss)
I0801 13:22:40.678972 12903 sgd_solver.cpp:136] Iteration 40400, lr = 0.036875, m = 0.9
I0801 13:22:42.247707 12903 solver.cpp:353] Iteration 40500 (63.7462 iter/s, 1.56872s/100 iter), loss = 0.0323806
I0801 13:22:42.247737 12903 solver.cpp:375]     Train net output #0: loss = 0.0323812 (* 1 = 0.0323812 loss)
I0801 13:22:42.247745 12903 sgd_solver.cpp:136] Iteration 40500, lr = 0.0367188, m = 0.9
I0801 13:22:43.820482 12903 solver.cpp:353] Iteration 40600 (63.5839 iter/s, 1.57272s/100 iter), loss = 0.0357822
I0801 13:22:43.820508 12903 solver.cpp:375]     Train net output #0: loss = 0.0357828 (* 1 = 0.0357828 loss)
I0801 13:22:43.820513 12903 sgd_solver.cpp:136] Iteration 40600, lr = 0.0365625, m = 0.9
I0801 13:22:45.390982 12903 solver.cpp:353] Iteration 40700 (63.6759 iter/s, 1.57045s/100 iter), loss = 0.00581616
I0801 13:22:45.391008 12903 solver.cpp:375]     Train net output #0: loss = 0.00581676 (* 1 = 0.00581676 loss)
I0801 13:22:45.391016 12903 sgd_solver.cpp:136] Iteration 40700, lr = 0.0364062, m = 0.9
I0801 13:22:46.952445 12903 solver.cpp:353] Iteration 40800 (64.0447 iter/s, 1.56141s/100 iter), loss = 0.0219299
I0801 13:22:46.952498 12903 solver.cpp:375]     Train net output #0: loss = 0.0219305 (* 1 = 0.0219305 loss)
I0801 13:22:46.952512 12903 sgd_solver.cpp:136] Iteration 40800, lr = 0.03625, m = 0.9
I0801 13:22:48.525328 12903 solver.cpp:353] Iteration 40900 (63.5794 iter/s, 1.57284s/100 iter), loss = 0.0670992
I0801 13:22:48.525355 12903 solver.cpp:375]     Train net output #0: loss = 0.0670998 (* 1 = 0.0670998 loss)
I0801 13:22:48.525362 12903 sgd_solver.cpp:136] Iteration 40900, lr = 0.0360937, m = 0.9
I0801 13:22:50.075798 12903 solver.cpp:550] Iteration 41000, Testing net (#0)
I0801 13:22:50.900959 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.864707
I0801 13:22:50.900979 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.993235
I0801 13:22:50.900984 12903 solver.cpp:635]     Test net output #2: loss = 0.555799 (* 1 = 0.555799 loss)
I0801 13:22:50.901000 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.825179s
I0801 13:22:50.916640 12903 solver.cpp:353] Iteration 41000 (41.8193 iter/s, 2.39124s/100 iter), loss = 0.0284629
I0801 13:22:50.916658 12903 solver.cpp:375]     Train net output #0: loss = 0.0284635 (* 1 = 0.0284635 loss)
I0801 13:22:50.916664 12903 sgd_solver.cpp:136] Iteration 41000, lr = 0.0359375, m = 0.9
I0801 13:22:52.487674 12903 solver.cpp:353] Iteration 41100 (63.6545 iter/s, 1.57098s/100 iter), loss = 0.0324772
I0801 13:22:52.487726 12903 solver.cpp:375]     Train net output #0: loss = 0.0324778 (* 1 = 0.0324778 loss)
I0801 13:22:52.487741 12903 sgd_solver.cpp:136] Iteration 41100, lr = 0.0357813, m = 0.9
I0801 13:22:54.059928 12903 solver.cpp:353] Iteration 41200 (63.6048 iter/s, 1.57221s/100 iter), loss = 0.0432132
I0801 13:22:54.060039 12903 solver.cpp:375]     Train net output #0: loss = 0.0432138 (* 1 = 0.0432138 loss)
I0801 13:22:54.060055 12903 sgd_solver.cpp:136] Iteration 41200, lr = 0.035625, m = 0.9
I0801 13:22:55.631335 12903 solver.cpp:353] Iteration 41300 (63.6393 iter/s, 1.57136s/100 iter), loss = 0.0174801
I0801 13:22:55.631361 12903 solver.cpp:375]     Train net output #0: loss = 0.0174807 (* 1 = 0.0174807 loss)
I0801 13:22:55.631367 12903 sgd_solver.cpp:136] Iteration 41300, lr = 0.0354688, m = 0.9
I0801 13:22:57.213966 12903 solver.cpp:353] Iteration 41400 (63.1879 iter/s, 1.58258s/100 iter), loss = 0.0106245
I0801 13:22:57.213994 12903 solver.cpp:375]     Train net output #0: loss = 0.0106251 (* 1 = 0.0106251 loss)
I0801 13:22:57.213999 12903 sgd_solver.cpp:136] Iteration 41400, lr = 0.0353125, m = 0.9
I0801 13:22:58.781814 12903 solver.cpp:353] Iteration 41500 (63.7838 iter/s, 1.5678s/100 iter), loss = 0.0101751
I0801 13:22:58.781841 12903 solver.cpp:375]     Train net output #0: loss = 0.0101757 (* 1 = 0.0101757 loss)
I0801 13:22:58.781847 12903 sgd_solver.cpp:136] Iteration 41500, lr = 0.0351562, m = 0.9
I0801 13:23:00.344100 12903 solver.cpp:353] Iteration 41600 (64.0108 iter/s, 1.56224s/100 iter), loss = 0.0621812
I0801 13:23:00.344130 12903 solver.cpp:375]     Train net output #0: loss = 0.0621818 (* 1 = 0.0621818 loss)
I0801 13:23:00.344137 12903 sgd_solver.cpp:136] Iteration 41600, lr = 0.035, m = 0.9
I0801 13:23:01.918496 12903 solver.cpp:353] Iteration 41700 (63.5185 iter/s, 1.57435s/100 iter), loss = 0.00498844
I0801 13:23:01.918521 12903 solver.cpp:375]     Train net output #0: loss = 0.00498905 (* 1 = 0.00498905 loss)
I0801 13:23:01.918527 12903 sgd_solver.cpp:136] Iteration 41700, lr = 0.0348438, m = 0.9
I0801 13:23:03.496642 12903 solver.cpp:353] Iteration 41800 (63.3674 iter/s, 1.5781s/100 iter), loss = 0.013951
I0801 13:23:03.496666 12903 solver.cpp:375]     Train net output #0: loss = 0.0139516 (* 1 = 0.0139516 loss)
I0801 13:23:03.496673 12903 sgd_solver.cpp:136] Iteration 41800, lr = 0.0346875, m = 0.9
I0801 13:23:05.061095 12903 solver.cpp:353] Iteration 41900 (63.9221 iter/s, 1.5644s/100 iter), loss = 0.00662456
I0801 13:23:05.061121 12903 solver.cpp:375]     Train net output #0: loss = 0.00662518 (* 1 = 0.00662518 loss)
I0801 13:23:05.061127 12903 sgd_solver.cpp:136] Iteration 41900, lr = 0.0345312, m = 0.9
I0801 13:23:06.615298 12903 solver.cpp:550] Iteration 42000, Testing net (#0)
I0801 13:23:07.431303 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.875001
I0801 13:23:07.431321 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996177
I0801 13:23:07.431327 12903 solver.cpp:635]     Test net output #2: loss = 0.459553 (* 1 = 0.459553 loss)
I0801 13:23:07.431349 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.816028s
I0801 13:23:07.446903 12903 solver.cpp:353] Iteration 42000 (41.9158 iter/s, 2.38574s/100 iter), loss = 0.00358973
I0801 13:23:07.446920 12903 solver.cpp:375]     Train net output #0: loss = 0.00359034 (* 1 = 0.00359034 loss)
I0801 13:23:07.446926 12903 sgd_solver.cpp:136] Iteration 42000, lr = 0.034375, m = 0.9
I0801 13:23:09.014989 12903 solver.cpp:353] Iteration 42100 (63.7741 iter/s, 1.56803s/100 iter), loss = 0.00491471
I0801 13:23:09.015038 12903 solver.cpp:375]     Train net output #0: loss = 0.00491534 (* 1 = 0.00491534 loss)
I0801 13:23:09.015049 12903 sgd_solver.cpp:136] Iteration 42100, lr = 0.0342188, m = 0.9
I0801 13:23:10.599735 12903 solver.cpp:353] Iteration 42200 (63.1035 iter/s, 1.5847s/100 iter), loss = 0.00190843
I0801 13:23:10.599761 12903 solver.cpp:375]     Train net output #0: loss = 0.00190906 (* 1 = 0.00190906 loss)
I0801 13:23:10.599766 12903 sgd_solver.cpp:136] Iteration 42200, lr = 0.0340625, m = 0.9
I0801 13:23:12.179766 12903 solver.cpp:353] Iteration 42300 (63.292 iter/s, 1.57998s/100 iter), loss = 0.0228381
I0801 13:23:12.179795 12903 solver.cpp:375]     Train net output #0: loss = 0.0228387 (* 1 = 0.0228387 loss)
I0801 13:23:12.179802 12903 sgd_solver.cpp:136] Iteration 42300, lr = 0.0339063, m = 0.9
I0801 13:23:13.747807 12903 solver.cpp:353] Iteration 42400 (63.7759 iter/s, 1.56799s/100 iter), loss = 0.0104314
I0801 13:23:13.747848 12903 solver.cpp:375]     Train net output #0: loss = 0.0104321 (* 1 = 0.0104321 loss)
I0801 13:23:13.747853 12903 sgd_solver.cpp:136] Iteration 42400, lr = 0.03375, m = 0.9
I0801 13:23:15.320464 12903 solver.cpp:353] Iteration 42500 (63.5886 iter/s, 1.57261s/100 iter), loss = 0.0415968
I0801 13:23:15.320492 12903 solver.cpp:375]     Train net output #0: loss = 0.0415975 (* 1 = 0.0415975 loss)
I0801 13:23:15.320498 12903 sgd_solver.cpp:136] Iteration 42500, lr = 0.0335938, m = 0.9
I0801 13:23:16.892467 12903 solver.cpp:353] Iteration 42600 (63.6151 iter/s, 1.57195s/100 iter), loss = 0.00319946
I0801 13:23:16.892537 12903 solver.cpp:375]     Train net output #0: loss = 0.0032001 (* 1 = 0.0032001 loss)
I0801 13:23:16.892555 12903 sgd_solver.cpp:136] Iteration 42600, lr = 0.0334375, m = 0.9
I0801 13:23:18.472226 12903 solver.cpp:353] Iteration 42700 (63.3029 iter/s, 1.57971s/100 iter), loss = 0.00331861
I0801 13:23:18.472254 12903 solver.cpp:375]     Train net output #0: loss = 0.00331926 (* 1 = 0.00331926 loss)
I0801 13:23:18.472261 12903 sgd_solver.cpp:136] Iteration 42700, lr = 0.0332812, m = 0.9
I0801 13:23:20.042201 12903 solver.cpp:353] Iteration 42800 (63.6973 iter/s, 1.56993s/100 iter), loss = 0.000590882
I0801 13:23:20.042254 12903 solver.cpp:375]     Train net output #0: loss = 0.000591527 (* 1 = 0.000591527 loss)
I0801 13:23:20.042268 12903 sgd_solver.cpp:136] Iteration 42800, lr = 0.033125, m = 0.9
I0801 13:23:21.603500 12903 solver.cpp:353] Iteration 42900 (64.0512 iter/s, 1.56125s/100 iter), loss = 0.018764
I0801 13:23:21.603524 12903 solver.cpp:375]     Train net output #0: loss = 0.0187646 (* 1 = 0.0187646 loss)
I0801 13:23:21.603529 12903 sgd_solver.cpp:136] Iteration 42900, lr = 0.0329687, m = 0.9
I0801 13:23:23.164796 12903 solver.cpp:550] Iteration 43000, Testing net (#0)
I0801 13:23:23.990846 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.870295
I0801 13:23:23.990865 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.994412
I0801 13:23:23.990870 12903 solver.cpp:635]     Test net output #2: loss = 0.49932 (* 1 = 0.49932 loss)
I0801 13:23:23.990885 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.826067s
I0801 13:23:24.008705 12903 solver.cpp:353] Iteration 43000 (41.5778 iter/s, 2.40513s/100 iter), loss = 0.00163354
I0801 13:23:24.008724 12903 solver.cpp:375]     Train net output #0: loss = 0.00163418 (* 1 = 0.00163418 loss)
I0801 13:23:24.008730 12903 sgd_solver.cpp:136] Iteration 43000, lr = 0.0328125, m = 0.9
I0801 13:23:25.595888 12903 solver.cpp:353] Iteration 43100 (63.0067 iter/s, 1.58713s/100 iter), loss = 0.00049281
I0801 13:23:25.595991 12903 solver.cpp:375]     Train net output #0: loss = 0.000493442 (* 1 = 0.000493442 loss)
I0801 13:23:25.595999 12903 sgd_solver.cpp:136] Iteration 43100, lr = 0.0326563, m = 0.9
I0801 13:23:27.160331 12903 solver.cpp:353] Iteration 43200 (63.9227 iter/s, 1.56439s/100 iter), loss = 0.00382919
I0801 13:23:27.160382 12903 solver.cpp:375]     Train net output #0: loss = 0.00382983 (* 1 = 0.00382983 loss)
I0801 13:23:27.160398 12903 sgd_solver.cpp:136] Iteration 43200, lr = 0.0325, m = 0.9
I0801 13:23:28.720990 12903 solver.cpp:353] Iteration 43300 (64.0775 iter/s, 1.56061s/100 iter), loss = 0.00966514
I0801 13:23:28.721016 12903 solver.cpp:375]     Train net output #0: loss = 0.00966578 (* 1 = 0.00966578 loss)
I0801 13:23:28.721022 12903 sgd_solver.cpp:136] Iteration 43300, lr = 0.0323438, m = 0.9
I0801 13:23:30.284855 12903 solver.cpp:353] Iteration 43400 (63.946 iter/s, 1.56382s/100 iter), loss = 0.00849421
I0801 13:23:30.284883 12903 solver.cpp:375]     Train net output #0: loss = 0.00849485 (* 1 = 0.00849485 loss)
I0801 13:23:30.284889 12903 sgd_solver.cpp:136] Iteration 43400, lr = 0.0321875, m = 0.9
I0801 13:23:31.859689 12903 solver.cpp:353] Iteration 43500 (63.5009 iter/s, 1.57478s/100 iter), loss = 0.00529374
I0801 13:23:31.859714 12903 solver.cpp:375]     Train net output #0: loss = 0.00529439 (* 1 = 0.00529439 loss)
I0801 13:23:31.859719 12903 sgd_solver.cpp:136] Iteration 43500, lr = 0.0320312, m = 0.9
I0801 13:23:33.444329 12903 solver.cpp:353] Iteration 43600 (63.1078 iter/s, 1.58459s/100 iter), loss = 0.00571609
I0801 13:23:33.444403 12903 solver.cpp:375]     Train net output #0: loss = 0.00571675 (* 1 = 0.00571675 loss)
I0801 13:23:33.444425 12903 sgd_solver.cpp:136] Iteration 43600, lr = 0.031875, m = 0.9
I0801 13:23:35.008502 12903 solver.cpp:353] Iteration 43700 (63.9335 iter/s, 1.56413s/100 iter), loss = 0.0170403
I0801 13:23:35.008530 12903 solver.cpp:375]     Train net output #0: loss = 0.017041 (* 1 = 0.017041 loss)
I0801 13:23:35.008536 12903 sgd_solver.cpp:136] Iteration 43700, lr = 0.0317187, m = 0.9
I0801 13:23:36.602890 12903 solver.cpp:353] Iteration 43800 (62.722 iter/s, 1.59434s/100 iter), loss = 0.000179543
I0801 13:23:36.602947 12903 solver.cpp:375]     Train net output #0: loss = 0.000180218 (* 1 = 0.000180218 loss)
I0801 13:23:36.602963 12903 sgd_solver.cpp:136] Iteration 43800, lr = 0.0315625, m = 0.9
I0801 13:23:38.171965 12903 solver.cpp:353] Iteration 43900 (63.7339 iter/s, 1.56902s/100 iter), loss = 0.00262171
I0801 13:23:38.171989 12903 solver.cpp:375]     Train net output #0: loss = 0.00262239 (* 1 = 0.00262239 loss)
I0801 13:23:38.171994 12903 sgd_solver.cpp:136] Iteration 43900, lr = 0.0314062, m = 0.9
I0801 13:23:38.738921 12870 data_reader.cpp:264] Starting prefetch of epoch 6
I0801 13:23:39.725353 12903 solver.cpp:550] Iteration 44000, Testing net (#0)
I0801 13:23:40.546962 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.889707
I0801 13:23:40.546983 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.994706
I0801 13:23:40.546988 12903 solver.cpp:635]     Test net output #2: loss = 0.466261 (* 1 = 0.466261 loss)
I0801 13:23:40.547001 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.821626s
I0801 13:23:40.570926 12903 solver.cpp:353] Iteration 44000 (41.6859 iter/s, 2.39889s/100 iter), loss = 0.024151
I0801 13:23:40.570962 12903 solver.cpp:375]     Train net output #0: loss = 0.0241516 (* 1 = 0.0241516 loss)
I0801 13:23:40.570973 12903 sgd_solver.cpp:136] Iteration 44000, lr = 0.03125, m = 0.9
I0801 13:23:42.140739 12903 solver.cpp:353] Iteration 44100 (63.7039 iter/s, 1.56976s/100 iter), loss = 0.007219
I0801 13:23:42.140768 12903 solver.cpp:375]     Train net output #0: loss = 0.00721968 (* 1 = 0.00721968 loss)
I0801 13:23:42.140774 12903 sgd_solver.cpp:136] Iteration 44100, lr = 0.0310938, m = 0.9
I0801 13:23:43.725574 12903 solver.cpp:353] Iteration 44200 (63.1001 iter/s, 1.58478s/100 iter), loss = 0.0373023
I0801 13:23:43.725603 12903 solver.cpp:375]     Train net output #0: loss = 0.0373029 (* 1 = 0.0373029 loss)
I0801 13:23:43.725611 12903 sgd_solver.cpp:136] Iteration 44200, lr = 0.0309375, m = 0.9
I0801 13:23:45.320130 12903 solver.cpp:353] Iteration 44300 (62.7154 iter/s, 1.5945s/100 iter), loss = 0.0334322
I0801 13:23:45.320157 12903 solver.cpp:375]     Train net output #0: loss = 0.0334328 (* 1 = 0.0334328 loss)
I0801 13:23:45.320163 12903 sgd_solver.cpp:136] Iteration 44300, lr = 0.0307813, m = 0.9
I0801 13:23:46.888900 12903 solver.cpp:353] Iteration 44400 (63.7463 iter/s, 1.56872s/100 iter), loss = 0.00275525
I0801 13:23:46.888948 12903 solver.cpp:375]     Train net output #0: loss = 0.00275593 (* 1 = 0.00275593 loss)
I0801 13:23:46.888962 12903 sgd_solver.cpp:136] Iteration 44400, lr = 0.030625, m = 0.9
I0801 13:23:48.465529 12903 solver.cpp:353] Iteration 44500 (63.4284 iter/s, 1.57658s/100 iter), loss = 0.00144589
I0801 13:23:48.465713 12903 solver.cpp:375]     Train net output #0: loss = 0.00144657 (* 1 = 0.00144657 loss)
I0801 13:23:48.465801 12903 sgd_solver.cpp:136] Iteration 44500, lr = 0.0304688, m = 0.9
I0801 13:23:50.035730 12903 solver.cpp:353] Iteration 44600 (63.6881 iter/s, 1.57015s/100 iter), loss = 0.000496966
I0801 13:23:50.035758 12903 solver.cpp:375]     Train net output #0: loss = 0.000497654 (* 1 = 0.000497654 loss)
I0801 13:23:50.035763 12903 sgd_solver.cpp:136] Iteration 44600, lr = 0.0303125, m = 0.9
I0801 13:23:51.630412 12903 solver.cpp:353] Iteration 44700 (62.7105 iter/s, 1.59463s/100 iter), loss = 0.00047225
I0801 13:23:51.630475 12903 solver.cpp:375]     Train net output #0: loss = 0.000472938 (* 1 = 0.000472938 loss)
I0801 13:23:51.630491 12903 sgd_solver.cpp:136] Iteration 44700, lr = 0.0301562, m = 0.9
I0801 13:23:53.204741 12903 solver.cpp:353] Iteration 44800 (63.5211 iter/s, 1.57428s/100 iter), loss = 0.000775094
I0801 13:23:53.204766 12903 solver.cpp:375]     Train net output #0: loss = 0.000775782 (* 1 = 0.000775782 loss)
I0801 13:23:53.204772 12903 sgd_solver.cpp:136] Iteration 44800, lr = 0.03, m = 0.9
I0801 13:23:54.762850 12903 solver.cpp:353] Iteration 44900 (64.1824 iter/s, 1.55806s/100 iter), loss = 0.0126118
I0801 13:23:54.762876 12903 solver.cpp:375]     Train net output #0: loss = 0.0126125 (* 1 = 0.0126125 loss)
I0801 13:23:54.762882 12903 sgd_solver.cpp:136] Iteration 44900, lr = 0.0298437, m = 0.9
I0801 13:23:56.331804 12903 solver.cpp:550] Iteration 45000, Testing net (#0)
I0801 13:23:57.158357 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.902354
I0801 13:23:57.158380 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.994412
I0801 13:23:57.158385 12903 solver.cpp:635]     Test net output #2: loss = 0.38598 (* 1 = 0.38598 loss)
I0801 13:23:57.158443 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.826616s
I0801 13:23:57.173914 12903 solver.cpp:353] Iteration 45000 (41.4767 iter/s, 2.41099s/100 iter), loss = 0.00244864
I0801 13:23:57.173933 12903 solver.cpp:375]     Train net output #0: loss = 0.00244932 (* 1 = 0.00244932 loss)
I0801 13:23:57.173938 12903 sgd_solver.cpp:136] Iteration 45000, lr = 0.0296875, m = 0.9
I0801 13:23:58.740428 12903 solver.cpp:353] Iteration 45100 (63.8381 iter/s, 1.56646s/100 iter), loss = 0.000717065
I0801 13:23:58.740455 12903 solver.cpp:375]     Train net output #0: loss = 0.000717748 (* 1 = 0.000717748 loss)
I0801 13:23:58.740461 12903 sgd_solver.cpp:136] Iteration 45100, lr = 0.0295313, m = 0.9
I0801 13:24:00.339850 12903 solver.cpp:353] Iteration 45200 (62.5245 iter/s, 1.59937s/100 iter), loss = 0.00151424
I0801 13:24:00.339879 12903 solver.cpp:375]     Train net output #0: loss = 0.00151492 (* 1 = 0.00151492 loss)
I0801 13:24:00.339885 12903 sgd_solver.cpp:136] Iteration 45200, lr = 0.029375, m = 0.9
I0801 13:24:01.924839 12903 solver.cpp:353] Iteration 45300 (63.094 iter/s, 1.58494s/100 iter), loss = 0.000231652
I0801 13:24:01.924863 12903 solver.cpp:375]     Train net output #0: loss = 0.000232331 (* 1 = 0.000232331 loss)
I0801 13:24:01.924868 12903 sgd_solver.cpp:136] Iteration 45300, lr = 0.0292188, m = 0.9
I0801 13:24:03.499505 12903 solver.cpp:353] Iteration 45400 (63.5074 iter/s, 1.57462s/100 iter), loss = 0.00135304
I0801 13:24:03.499534 12903 solver.cpp:375]     Train net output #0: loss = 0.00135372 (* 1 = 0.00135372 loss)
I0801 13:24:03.499541 12903 sgd_solver.cpp:136] Iteration 45400, lr = 0.0290625, m = 0.9
I0801 13:24:05.059900 12903 solver.cpp:353] Iteration 45500 (64.0884 iter/s, 1.56035s/100 iter), loss = 0.0066793
I0801 13:24:05.059924 12903 solver.cpp:375]     Train net output #0: loss = 0.00667997 (* 1 = 0.00667997 loss)
I0801 13:24:05.059929 12903 sgd_solver.cpp:136] Iteration 45500, lr = 0.0289063, m = 0.9
I0801 13:24:06.633359 12903 solver.cpp:353] Iteration 45600 (63.5562 iter/s, 1.57341s/100 iter), loss = 0.00493855
I0801 13:24:06.633383 12903 solver.cpp:375]     Train net output #0: loss = 0.00493923 (* 1 = 0.00493923 loss)
I0801 13:24:06.633389 12903 sgd_solver.cpp:136] Iteration 45600, lr = 0.02875, m = 0.9
I0801 13:24:08.220883 12903 solver.cpp:353] Iteration 45700 (62.9931 iter/s, 1.58747s/100 iter), loss = 0.0044013
I0801 13:24:08.220947 12903 solver.cpp:375]     Train net output #0: loss = 0.00440198 (* 1 = 0.00440198 loss)
I0801 13:24:08.220966 12903 sgd_solver.cpp:136] Iteration 45700, lr = 0.0285937, m = 0.9
I0801 13:24:09.790107 12903 solver.cpp:353] Iteration 45800 (63.7279 iter/s, 1.56917s/100 iter), loss = 0.00065469
I0801 13:24:09.790156 12903 solver.cpp:375]     Train net output #0: loss = 0.000655367 (* 1 = 0.000655367 loss)
I0801 13:24:09.790169 12903 sgd_solver.cpp:136] Iteration 45800, lr = 0.0284375, m = 0.9
I0801 13:24:11.368975 12903 solver.cpp:353] Iteration 45900 (63.3386 iter/s, 1.57882s/100 iter), loss = 0.00223704
I0801 13:24:11.369000 12903 solver.cpp:375]     Train net output #0: loss = 0.00223772 (* 1 = 0.00223772 loss)
I0801 13:24:11.369006 12903 sgd_solver.cpp:136] Iteration 45900, lr = 0.0282812, m = 0.9
I0801 13:24:12.920959 12903 solver.cpp:550] Iteration 46000, Testing net (#0)
I0801 13:24:13.736898 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.907648
I0801 13:24:13.736918 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996765
I0801 13:24:13.736923 12903 solver.cpp:635]     Test net output #2: loss = 0.34087 (* 1 = 0.34087 loss)
I0801 13:24:13.736937 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.815956s
I0801 13:24:13.752568 12903 solver.cpp:353] Iteration 46000 (41.9547 iter/s, 2.38352s/100 iter), loss = 0.00445603
I0801 13:24:13.752588 12903 solver.cpp:375]     Train net output #0: loss = 0.00445671 (* 1 = 0.00445671 loss)
I0801 13:24:13.752614 12903 sgd_solver.cpp:136] Iteration 46000, lr = 0.028125, m = 0.9
I0801 13:24:15.307039 12903 solver.cpp:353] Iteration 46100 (64.3327 iter/s, 1.55442s/100 iter), loss = 0.00200996
I0801 13:24:15.307065 12903 solver.cpp:375]     Train net output #0: loss = 0.00201065 (* 1 = 0.00201065 loss)
I0801 13:24:15.307070 12903 sgd_solver.cpp:136] Iteration 46100, lr = 0.0279688, m = 0.9
I0801 13:24:16.885483 12903 solver.cpp:353] Iteration 46200 (63.3556 iter/s, 1.57839s/100 iter), loss = 0.000643884
I0801 13:24:16.885509 12903 solver.cpp:375]     Train net output #0: loss = 0.000644577 (* 1 = 0.000644577 loss)
I0801 13:24:16.885514 12903 sgd_solver.cpp:136] Iteration 46200, lr = 0.0278125, m = 0.9
I0801 13:24:18.489982 12903 solver.cpp:353] Iteration 46300 (62.3266 iter/s, 1.60445s/100 iter), loss = 0.000431973
I0801 13:24:18.490006 12903 solver.cpp:375]     Train net output #0: loss = 0.000432667 (* 1 = 0.000432667 loss)
I0801 13:24:18.490010 12903 sgd_solver.cpp:136] Iteration 46300, lr = 0.0276563, m = 0.9
I0801 13:24:20.052724 12903 solver.cpp:353] Iteration 46400 (63.9922 iter/s, 1.56269s/100 iter), loss = 0.000461719
I0801 13:24:20.052774 12903 solver.cpp:375]     Train net output #0: loss = 0.000462417 (* 1 = 0.000462417 loss)
I0801 13:24:20.052788 12903 sgd_solver.cpp:136] Iteration 46400, lr = 0.0275, m = 0.9
I0801 13:24:21.617964 12903 solver.cpp:353] Iteration 46500 (63.89 iter/s, 1.56519s/100 iter), loss = 0.00184761
I0801 13:24:21.618015 12903 solver.cpp:375]     Train net output #0: loss = 0.00184832 (* 1 = 0.00184832 loss)
I0801 13:24:21.618027 12903 sgd_solver.cpp:136] Iteration 46500, lr = 0.0273438, m = 0.9
I0801 13:24:23.187100 12903 solver.cpp:353] Iteration 46600 (63.7313 iter/s, 1.56909s/100 iter), loss = 0.00628541
I0801 13:24:23.187126 12903 solver.cpp:375]     Train net output #0: loss = 0.00628611 (* 1 = 0.00628611 loss)
I0801 13:24:23.187132 12903 sgd_solver.cpp:136] Iteration 46600, lr = 0.0271875, m = 0.9
I0801 13:24:24.764751 12903 solver.cpp:353] Iteration 46700 (63.3875 iter/s, 1.5776s/100 iter), loss = 0.00393961
I0801 13:24:24.764780 12903 solver.cpp:375]     Train net output #0: loss = 0.00394032 (* 1 = 0.00394032 loss)
I0801 13:24:24.764784 12903 sgd_solver.cpp:136] Iteration 46700, lr = 0.0270312, m = 0.9
I0801 13:24:26.337888 12903 solver.cpp:353] Iteration 46800 (63.5693 iter/s, 1.57309s/100 iter), loss = 0.00156902
I0801 13:24:26.337977 12903 solver.cpp:375]     Train net output #0: loss = 0.00156972 (* 1 = 0.00156972 loss)
I0801 13:24:26.337985 12903 sgd_solver.cpp:136] Iteration 46800, lr = 0.026875, m = 0.9
I0801 13:24:27.906286 12903 solver.cpp:353] Iteration 46900 (63.7613 iter/s, 1.56835s/100 iter), loss = 0.000759462
I0801 13:24:27.906313 12903 solver.cpp:375]     Train net output #0: loss = 0.000760166 (* 1 = 0.000760166 loss)
I0801 13:24:27.906319 12903 sgd_solver.cpp:136] Iteration 46900, lr = 0.0267187, m = 0.9
I0801 13:24:29.453059 12903 solver.cpp:550] Iteration 47000, Testing net (#0)
I0801 13:24:30.270009 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.905295
I0801 13:24:30.270028 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996765
I0801 13:24:30.270033 12903 solver.cpp:635]     Test net output #2: loss = 0.361522 (* 1 = 0.361522 loss)
I0801 13:24:30.270047 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.816965s
I0801 13:24:30.285619 12903 solver.cpp:353] Iteration 47000 (42.0298 iter/s, 2.37926s/100 iter), loss = 0.00262795
I0801 13:24:30.285639 12903 solver.cpp:375]     Train net output #0: loss = 0.00262866 (* 1 = 0.00262866 loss)
I0801 13:24:30.285642 12903 sgd_solver.cpp:136] Iteration 47000, lr = 0.0265625, m = 0.9
I0801 13:24:31.855190 12903 solver.cpp:353] Iteration 47100 (63.7137 iter/s, 1.56952s/100 iter), loss = 0.0232653
I0801 13:24:31.855218 12903 solver.cpp:375]     Train net output #0: loss = 0.023266 (* 1 = 0.023266 loss)
I0801 13:24:31.855224 12903 sgd_solver.cpp:136] Iteration 47100, lr = 0.0264063, m = 0.9
I0801 13:24:33.419955 12903 solver.cpp:353] Iteration 47200 (63.9095 iter/s, 1.56471s/100 iter), loss = 0.00329942
I0801 13:24:33.419981 12903 solver.cpp:375]     Train net output #0: loss = 0.00330012 (* 1 = 0.00330012 loss)
I0801 13:24:33.419987 12903 sgd_solver.cpp:136] Iteration 47200, lr = 0.02625, m = 0.9
I0801 13:24:34.994333 12903 solver.cpp:353] Iteration 47300 (63.5191 iter/s, 1.57433s/100 iter), loss = 0.000508554
I0801 13:24:34.994380 12903 solver.cpp:375]     Train net output #0: loss = 0.000509257 (* 1 = 0.000509257 loss)
I0801 13:24:34.994393 12903 sgd_solver.cpp:136] Iteration 47300, lr = 0.0260938, m = 0.9
I0801 13:24:36.579315 12903 solver.cpp:353] Iteration 47400 (63.0943 iter/s, 1.58493s/100 iter), loss = 0.00672366
I0801 13:24:36.579371 12903 solver.cpp:375]     Train net output #0: loss = 0.00672437 (* 1 = 0.00672437 loss)
I0801 13:24:36.579383 12903 sgd_solver.cpp:136] Iteration 47400, lr = 0.0259375, m = 0.9
I0801 13:24:38.144776 12903 solver.cpp:353] Iteration 47500 (63.881 iter/s, 1.56541s/100 iter), loss = 0.00104128
I0801 13:24:38.144804 12903 solver.cpp:375]     Train net output #0: loss = 0.00104198 (* 1 = 0.00104198 loss)
I0801 13:24:38.144809 12903 sgd_solver.cpp:136] Iteration 47500, lr = 0.0257812, m = 0.9
I0801 13:24:39.704267 12903 solver.cpp:353] Iteration 47600 (64.1256 iter/s, 1.55944s/100 iter), loss = 0.000792594
I0801 13:24:39.704293 12903 solver.cpp:375]     Train net output #0: loss = 0.000793299 (* 1 = 0.000793299 loss)
I0801 13:24:39.704300 12903 sgd_solver.cpp:136] Iteration 47600, lr = 0.025625, m = 0.9
I0801 13:24:41.276806 12903 solver.cpp:353] Iteration 47700 (63.5934 iter/s, 1.57249s/100 iter), loss = 0.00168473
I0801 13:24:41.276836 12903 solver.cpp:375]     Train net output #0: loss = 0.00168544 (* 1 = 0.00168544 loss)
I0801 13:24:41.276842 12903 sgd_solver.cpp:136] Iteration 47700, lr = 0.0254687, m = 0.9
I0801 13:24:42.859408 12903 solver.cpp:353] Iteration 47800 (63.1891 iter/s, 1.58255s/100 iter), loss = 0.0012303
I0801 13:24:42.859433 12903 solver.cpp:375]     Train net output #0: loss = 0.001231 (* 1 = 0.001231 loss)
I0801 13:24:42.859437 12903 sgd_solver.cpp:136] Iteration 47800, lr = 0.0253125, m = 0.9
I0801 13:24:44.432739 12903 solver.cpp:353] Iteration 47900 (63.5615 iter/s, 1.57328s/100 iter), loss = 7.00162e-05
I0801 13:24:44.432763 12903 solver.cpp:375]     Train net output #0: loss = 7.07198e-05 (* 1 = 7.07198e-05 loss)
I0801 13:24:44.432767 12903 sgd_solver.cpp:136] Iteration 47900, lr = 0.0251562, m = 0.9
I0801 13:24:45.976703 12903 solver.cpp:550] Iteration 48000, Testing net (#0)
I0801 13:24:46.007869 12893 data_reader.cpp:264] Starting prefetch of epoch 6
I0801 13:24:46.801564 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.910295
I0801 13:24:46.801584 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.997353
I0801 13:24:46.801589 12903 solver.cpp:635]     Test net output #2: loss = 0.3393 (* 1 = 0.3393 loss)
I0801 13:24:46.801604 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.824879s
I0801 13:24:46.817209 12903 solver.cpp:353] Iteration 48000 (41.9392 iter/s, 2.3844s/100 iter), loss = 0.00096214
I0801 13:24:46.817239 12903 solver.cpp:375]     Train net output #0: loss = 0.000962844 (* 1 = 0.000962844 loss)
I0801 13:24:46.817250 12903 sgd_solver.cpp:136] Iteration 48000, lr = 0.025, m = 0.9
I0801 13:24:48.391712 12903 solver.cpp:353] Iteration 48100 (63.5142 iter/s, 1.57445s/100 iter), loss = 0.00148356
I0801 13:24:48.391774 12903 solver.cpp:375]     Train net output #0: loss = 0.00148426 (* 1 = 0.00148426 loss)
I0801 13:24:48.391791 12903 sgd_solver.cpp:136] Iteration 48100, lr = 0.0248438, m = 0.9
I0801 13:24:49.980670 12903 solver.cpp:353] Iteration 48200 (62.9363 iter/s, 1.58891s/100 iter), loss = 0.00194852
I0801 13:24:49.980695 12903 solver.cpp:375]     Train net output #0: loss = 0.00194922 (* 1 = 0.00194922 loss)
I0801 13:24:49.980701 12903 sgd_solver.cpp:136] Iteration 48200, lr = 0.0246875, m = 0.9
I0801 13:24:51.558743 12903 solver.cpp:353] Iteration 48300 (63.3705 iter/s, 1.57802s/100 iter), loss = 0.000907289
I0801 13:24:51.558770 12903 solver.cpp:375]     Train net output #0: loss = 0.000907992 (* 1 = 0.000907992 loss)
I0801 13:24:51.558776 12903 sgd_solver.cpp:136] Iteration 48300, lr = 0.0245313, m = 0.9
I0801 13:24:53.142416 12903 solver.cpp:353] Iteration 48400 (63.1463 iter/s, 1.58362s/100 iter), loss = 0.000900091
I0801 13:24:53.142441 12903 solver.cpp:375]     Train net output #0: loss = 0.000900794 (* 1 = 0.000900794 loss)
I0801 13:24:53.142446 12903 sgd_solver.cpp:136] Iteration 48400, lr = 0.024375, m = 0.9
I0801 13:24:54.708547 12903 solver.cpp:353] Iteration 48500 (63.8535 iter/s, 1.56608s/100 iter), loss = 0.000506197
I0801 13:24:54.708575 12903 solver.cpp:375]     Train net output #0: loss = 0.000506901 (* 1 = 0.000506901 loss)
I0801 13:24:54.708580 12903 sgd_solver.cpp:136] Iteration 48500, lr = 0.0242188, m = 0.9
I0801 13:24:56.290611 12903 solver.cpp:353] Iteration 48600 (63.2106 iter/s, 1.58201s/100 iter), loss = 0.00143697
I0801 13:24:56.290637 12903 solver.cpp:375]     Train net output #0: loss = 0.00143767 (* 1 = 0.00143767 loss)
I0801 13:24:56.290642 12903 sgd_solver.cpp:136] Iteration 48600, lr = 0.0240625, m = 0.9
I0801 13:24:57.869447 12903 solver.cpp:353] Iteration 48700 (63.3397 iter/s, 1.57879s/100 iter), loss = 0.000564478
I0801 13:24:57.869539 12903 solver.cpp:375]     Train net output #0: loss = 0.000565183 (* 1 = 0.000565183 loss)
I0801 13:24:57.869546 12903 sgd_solver.cpp:136] Iteration 48700, lr = 0.0239062, m = 0.9
I0801 13:24:59.455576 12903 solver.cpp:353] Iteration 48800 (63.0486 iter/s, 1.58608s/100 iter), loss = 0.000833325
I0801 13:24:59.455605 12903 solver.cpp:375]     Train net output #0: loss = 0.000834032 (* 1 = 0.000834032 loss)
I0801 13:24:59.455612 12903 sgd_solver.cpp:136] Iteration 48800, lr = 0.02375, m = 0.9
I0801 13:25:01.014787 12903 solver.cpp:353] Iteration 48900 (64.137 iter/s, 1.55916s/100 iter), loss = 0.000657971
I0801 13:25:01.014813 12903 solver.cpp:375]     Train net output #0: loss = 0.000658678 (* 1 = 0.000658678 loss)
I0801 13:25:01.014819 12903 sgd_solver.cpp:136] Iteration 48900, lr = 0.0235937, m = 0.9
I0801 13:25:02.568639 12903 solver.cpp:550] Iteration 49000, Testing net (#0)
I0801 13:25:03.382109 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.919119
I0801 13:25:03.382129 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996471
I0801 13:25:03.382134 12903 solver.cpp:635]     Test net output #2: loss = 0.313162 (* 1 = 0.313162 loss)
I0801 13:25:03.382148 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.813486s
I0801 13:25:03.397828 12903 solver.cpp:353] Iteration 49000 (41.9644 iter/s, 2.38297s/100 iter), loss = 0.0013943
I0801 13:25:03.397847 12903 solver.cpp:375]     Train net output #0: loss = 0.00139501 (* 1 = 0.00139501 loss)
I0801 13:25:03.397853 12903 sgd_solver.cpp:136] Iteration 49000, lr = 0.0234375, m = 0.9
I0801 13:25:04.990711 12903 solver.cpp:353] Iteration 49100 (62.7813 iter/s, 1.59283s/100 iter), loss = 0.000739293
I0801 13:25:04.990761 12903 solver.cpp:375]     Train net output #0: loss = 0.000739998 (* 1 = 0.000739998 loss)
I0801 13:25:04.990775 12903 sgd_solver.cpp:136] Iteration 49100, lr = 0.0232813, m = 0.9
I0801 13:25:06.582110 12903 solver.cpp:353] Iteration 49200 (62.8398 iter/s, 1.59135s/100 iter), loss = 0.000679991
I0801 13:25:06.582134 12903 solver.cpp:375]     Train net output #0: loss = 0.000680696 (* 1 = 0.000680696 loss)
I0801 13:25:06.582139 12903 sgd_solver.cpp:136] Iteration 49200, lr = 0.023125, m = 0.9
I0801 13:25:08.149071 12903 solver.cpp:353] Iteration 49300 (63.8198 iter/s, 1.56691s/100 iter), loss = 0.00296403
I0801 13:25:08.149096 12903 solver.cpp:375]     Train net output #0: loss = 0.00296474 (* 1 = 0.00296474 loss)
I0801 13:25:08.149102 12903 sgd_solver.cpp:136] Iteration 49300, lr = 0.0229688, m = 0.9
I0801 13:25:09.735374 12903 solver.cpp:353] Iteration 49400 (63.0417 iter/s, 1.58625s/100 iter), loss = 0.00084682
I0801 13:25:09.735400 12903 solver.cpp:375]     Train net output #0: loss = 0.000847525 (* 1 = 0.000847525 loss)
I0801 13:25:09.735405 12903 sgd_solver.cpp:136] Iteration 49400, lr = 0.0228125, m = 0.9
I0801 13:25:11.319339 12903 solver.cpp:353] Iteration 49500 (63.1347 iter/s, 1.58391s/100 iter), loss = 0.000480535
I0801 13:25:11.319366 12903 solver.cpp:375]     Train net output #0: loss = 0.00048124 (* 1 = 0.00048124 loss)
I0801 13:25:11.319371 12903 sgd_solver.cpp:136] Iteration 49500, lr = 0.0226563, m = 0.9
I0801 13:25:12.882639 12903 solver.cpp:353] Iteration 49600 (63.9692 iter/s, 1.56325s/100 iter), loss = 0.00132814
I0801 13:25:12.882668 12903 solver.cpp:375]     Train net output #0: loss = 0.00132885 (* 1 = 0.00132885 loss)
I0801 13:25:12.882673 12903 sgd_solver.cpp:136] Iteration 49600, lr = 0.0225, m = 0.9
I0801 13:25:14.451462 12903 solver.cpp:353] Iteration 49700 (63.7441 iter/s, 1.56877s/100 iter), loss = 0.000381254
I0801 13:25:14.451520 12903 solver.cpp:375]     Train net output #0: loss = 0.000381959 (* 1 = 0.000381959 loss)
I0801 13:25:14.451539 12903 sgd_solver.cpp:136] Iteration 49700, lr = 0.0223437, m = 0.9
I0801 13:25:16.011600 12903 solver.cpp:353] Iteration 49800 (64.099 iter/s, 1.56009s/100 iter), loss = 0.000385292
I0801 13:25:16.011652 12903 solver.cpp:375]     Train net output #0: loss = 0.000385997 (* 1 = 0.000385997 loss)
I0801 13:25:16.011667 12903 sgd_solver.cpp:136] Iteration 49800, lr = 0.0221875, m = 0.9
I0801 13:25:17.605468 12903 solver.cpp:353] Iteration 49900 (62.7424 iter/s, 1.59382s/100 iter), loss = 0.000165863
I0801 13:25:17.605520 12903 solver.cpp:375]     Train net output #0: loss = 0.000166567 (* 1 = 0.000166567 loss)
I0801 13:25:17.605533 12903 sgd_solver.cpp:136] Iteration 49900, lr = 0.0220312, m = 0.9
I0801 13:25:19.151702 12903 solver.cpp:680] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/initial/cifar10_jacintonet11v2_iter_50000.caffemodel
I0801 13:25:19.159831 12903 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/initial/cifar10_jacintonet11v2_iter_50000.solverstate
I0801 13:25:19.163585 12903 solver.cpp:550] Iteration 50000, Testing net (#0)
I0801 13:25:19.969437 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.915001
I0801 13:25:19.969458 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.995588
I0801 13:25:19.969465 12903 solver.cpp:635]     Test net output #2: loss = 0.328909 (* 1 = 0.328909 loss)
I0801 13:25:19.969481 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.805871s
I0801 13:25:19.985030 12903 solver.cpp:353] Iteration 50000 (42.0258 iter/s, 2.37949s/100 iter), loss = 0.000590556
I0801 13:25:19.985047 12903 solver.cpp:375]     Train net output #0: loss = 0.000591259 (* 1 = 0.000591259 loss)
I0801 13:25:19.985054 12903 sgd_solver.cpp:136] Iteration 50000, lr = 0.021875, m = 0.9
I0801 13:25:21.565487 12903 solver.cpp:353] Iteration 50100 (63.2749 iter/s, 1.5804s/100 iter), loss = 0.000640826
I0801 13:25:21.565512 12903 solver.cpp:375]     Train net output #0: loss = 0.00064153 (* 1 = 0.00064153 loss)
I0801 13:25:21.565518 12903 sgd_solver.cpp:136] Iteration 50100, lr = 0.0217188, m = 0.9
I0801 13:25:23.149327 12903 solver.cpp:353] Iteration 50200 (63.1398 iter/s, 1.58379s/100 iter), loss = 0.00143141
I0801 13:25:23.149353 12903 solver.cpp:375]     Train net output #0: loss = 0.00143211 (* 1 = 0.00143211 loss)
I0801 13:25:23.149356 12903 sgd_solver.cpp:136] Iteration 50200, lr = 0.0215625, m = 0.9
I0801 13:25:24.711545 12903 solver.cpp:353] Iteration 50300 (64.0136 iter/s, 1.56217s/100 iter), loss = 0.00119181
I0801 13:25:24.711575 12903 solver.cpp:375]     Train net output #0: loss = 0.00119251 (* 1 = 0.00119251 loss)
I0801 13:25:24.711582 12903 sgd_solver.cpp:136] Iteration 50300, lr = 0.0214063, m = 0.9
I0801 13:25:26.276260 12903 solver.cpp:353] Iteration 50400 (63.9114 iter/s, 1.56467s/100 iter), loss = 0.000815547
I0801 13:25:26.276288 12903 solver.cpp:375]     Train net output #0: loss = 0.000816249 (* 1 = 0.000816249 loss)
I0801 13:25:26.276293 12903 sgd_solver.cpp:136] Iteration 50400, lr = 0.02125, m = 0.9
I0801 13:25:27.840178 12903 solver.cpp:353] Iteration 50500 (63.944 iter/s, 1.56387s/100 iter), loss = 0.00130608
I0801 13:25:27.840204 12903 solver.cpp:375]     Train net output #0: loss = 0.00130678 (* 1 = 0.00130678 loss)
I0801 13:25:27.840209 12903 sgd_solver.cpp:136] Iteration 50500, lr = 0.0210938, m = 0.9
I0801 13:25:29.413121 12903 solver.cpp:353] Iteration 50600 (63.5771 iter/s, 1.57289s/100 iter), loss = 0.00107607
I0801 13:25:29.413215 12903 solver.cpp:375]     Train net output #0: loss = 0.00107678 (* 1 = 0.00107678 loss)
I0801 13:25:29.413223 12903 sgd_solver.cpp:136] Iteration 50600, lr = 0.0209375, m = 0.9
I0801 13:25:30.983394 12903 solver.cpp:353] Iteration 50700 (63.6852 iter/s, 1.57022s/100 iter), loss = 0.00135973
I0801 13:25:30.983443 12903 solver.cpp:375]     Train net output #0: loss = 0.00136043 (* 1 = 0.00136043 loss)
I0801 13:25:30.983454 12903 sgd_solver.cpp:136] Iteration 50700, lr = 0.0207812, m = 0.9
I0801 13:25:32.568013 12903 solver.cpp:353] Iteration 50800 (63.1087 iter/s, 1.58457s/100 iter), loss = 0.000312682
I0801 13:25:32.568039 12903 solver.cpp:375]     Train net output #0: loss = 0.000313386 (* 1 = 0.000313386 loss)
I0801 13:25:32.568045 12903 sgd_solver.cpp:136] Iteration 50800, lr = 0.020625, m = 0.9
I0801 13:25:34.143808 12903 solver.cpp:353] Iteration 50900 (63.462 iter/s, 1.57575s/100 iter), loss = 0.000513935
I0801 13:25:34.143838 12903 solver.cpp:375]     Train net output #0: loss = 0.000514639 (* 1 = 0.000514639 loss)
I0801 13:25:34.143846 12903 sgd_solver.cpp:136] Iteration 50900, lr = 0.0204687, m = 0.9
I0801 13:25:35.703783 12903 solver.cpp:550] Iteration 51000, Testing net (#0)
I0801 13:25:36.521924 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.914119
I0801 13:25:36.521944 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.995882
I0801 13:25:36.521950 12903 solver.cpp:635]     Test net output #2: loss = 0.325929 (* 1 = 0.325929 loss)
I0801 13:25:36.521965 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.818159s
I0801 13:25:36.538552 12903 solver.cpp:353] Iteration 51000 (41.7594 iter/s, 2.39467s/100 iter), loss = 0.00179885
I0801 13:25:36.538586 12903 solver.cpp:375]     Train net output #0: loss = 0.00179956 (* 1 = 0.00179956 loss)
I0801 13:25:36.538594 12903 sgd_solver.cpp:136] Iteration 51000, lr = 0.0203125, m = 0.9
I0801 13:25:38.116425 12903 solver.cpp:353] Iteration 51100 (63.3784 iter/s, 1.57782s/100 iter), loss = 0.000391277
I0801 13:25:38.116452 12903 solver.cpp:375]     Train net output #0: loss = 0.000391981 (* 1 = 0.000391981 loss)
I0801 13:25:38.116458 12903 sgd_solver.cpp:136] Iteration 51100, lr = 0.0201563, m = 0.9
I0801 13:25:39.682034 12903 solver.cpp:353] Iteration 51200 (63.875 iter/s, 1.56556s/100 iter), loss = 0.000696904
I0801 13:25:39.682061 12903 solver.cpp:375]     Train net output #0: loss = 0.000697608 (* 1 = 0.000697608 loss)
I0801 13:25:39.682066 12903 sgd_solver.cpp:136] Iteration 51200, lr = 0.02, m = 0.9
I0801 13:25:41.262037 12903 solver.cpp:353] Iteration 51300 (63.293 iter/s, 1.57995s/100 iter), loss = 0.000892735
I0801 13:25:41.262257 12903 solver.cpp:375]     Train net output #0: loss = 0.000893439 (* 1 = 0.000893439 loss)
I0801 13:25:41.262267 12903 sgd_solver.cpp:136] Iteration 51300, lr = 0.0198438, m = 0.9
I0801 13:25:42.835777 12903 solver.cpp:353] Iteration 51400 (63.5449 iter/s, 1.57369s/100 iter), loss = 0.00351579
I0801 13:25:42.835808 12903 solver.cpp:375]     Train net output #0: loss = 0.0035165 (* 1 = 0.0035165 loss)
I0801 13:25:42.835814 12903 sgd_solver.cpp:136] Iteration 51400, lr = 0.0196875, m = 0.9
I0801 13:25:44.400761 12903 solver.cpp:353] Iteration 51500 (63.9005 iter/s, 1.56493s/100 iter), loss = 0.000573569
I0801 13:25:44.400791 12903 solver.cpp:375]     Train net output #0: loss = 0.000574273 (* 1 = 0.000574273 loss)
I0801 13:25:44.400799 12903 sgd_solver.cpp:136] Iteration 51500, lr = 0.0195312, m = 0.9
I0801 13:25:45.980165 12903 solver.cpp:353] Iteration 51600 (63.3171 iter/s, 1.57935s/100 iter), loss = 0.000836615
I0801 13:25:45.980216 12903 solver.cpp:375]     Train net output #0: loss = 0.000837321 (* 1 = 0.000837321 loss)
I0801 13:25:45.980229 12903 sgd_solver.cpp:136] Iteration 51600, lr = 0.019375, m = 0.9
I0801 13:25:47.591292 12903 solver.cpp:353] Iteration 51700 (62.0703 iter/s, 1.61108s/100 iter), loss = 0.000292465
I0801 13:25:47.591320 12903 solver.cpp:375]     Train net output #0: loss = 0.00029317 (* 1 = 0.00029317 loss)
I0801 13:25:47.591327 12903 sgd_solver.cpp:136] Iteration 51700, lr = 0.0192187, m = 0.9
I0801 13:25:49.159061 12903 solver.cpp:353] Iteration 51800 (63.7869 iter/s, 1.56772s/100 iter), loss = 0.00181618
I0801 13:25:49.159086 12903 solver.cpp:375]     Train net output #0: loss = 0.00181688 (* 1 = 0.00181688 loss)
I0801 13:25:49.159090 12903 sgd_solver.cpp:136] Iteration 51800, lr = 0.0190625, m = 0.9
I0801 13:25:50.739166 12903 solver.cpp:353] Iteration 51900 (63.289 iter/s, 1.58005s/100 iter), loss = 0.000260359
I0801 13:25:50.739192 12903 solver.cpp:375]     Train net output #0: loss = 0.000261065 (* 1 = 0.000261065 loss)
I0801 13:25:50.739198 12903 sgd_solver.cpp:136] Iteration 51900, lr = 0.0189062, m = 0.9
I0801 13:25:52.285542 12903 solver.cpp:550] Iteration 52000, Testing net (#0)
I0801 13:25:53.017277 12893 data_reader.cpp:264] Starting prefetch of epoch 7
I0801 13:25:53.109104 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.915883
I0801 13:25:53.109122 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.995882
I0801 13:25:53.109127 12903 solver.cpp:635]     Test net output #2: loss = 0.316027 (* 1 = 0.316027 loss)
I0801 13:25:53.109144 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.823582s
I0801 13:25:53.124887 12903 solver.cpp:353] Iteration 52000 (41.9173 iter/s, 2.38565s/100 iter), loss = 0.000716578
I0801 13:25:53.124904 12903 solver.cpp:375]     Train net output #0: loss = 0.000717283 (* 1 = 0.000717283 loss)
I0801 13:25:53.124909 12903 sgd_solver.cpp:136] Iteration 52000, lr = 0.01875, m = 0.9
I0801 13:25:54.681800 12903 solver.cpp:353] Iteration 52100 (64.2317 iter/s, 1.55686s/100 iter), loss = 0.000778962
I0801 13:25:54.681849 12903 solver.cpp:375]     Train net output #0: loss = 0.000779667 (* 1 = 0.000779667 loss)
I0801 13:25:54.681857 12903 sgd_solver.cpp:136] Iteration 52100, lr = 0.0185938, m = 0.9
I0801 13:25:56.248119 12903 solver.cpp:353] Iteration 52200 (63.8459 iter/s, 1.56627s/100 iter), loss = 0.000693935
I0801 13:25:56.248147 12903 solver.cpp:375]     Train net output #0: loss = 0.000694641 (* 1 = 0.000694641 loss)
I0801 13:25:56.248153 12903 sgd_solver.cpp:136] Iteration 52200, lr = 0.0184375, m = 0.9
I0801 13:25:57.836972 12903 solver.cpp:353] Iteration 52300 (62.9404 iter/s, 1.5888s/100 iter), loss = 0.000633808
I0801 13:25:57.837023 12903 solver.cpp:375]     Train net output #0: loss = 0.000634514 (* 1 = 0.000634514 loss)
I0801 13:25:57.837036 12903 sgd_solver.cpp:136] Iteration 52300, lr = 0.0182813, m = 0.9
I0801 13:25:59.421001 12903 solver.cpp:353] Iteration 52400 (63.1322 iter/s, 1.58398s/100 iter), loss = 0.00088626
I0801 13:25:59.421056 12903 solver.cpp:375]     Train net output #0: loss = 0.000886966 (* 1 = 0.000886966 loss)
I0801 13:25:59.421063 12903 sgd_solver.cpp:136] Iteration 52400, lr = 0.018125, m = 0.9
I0801 13:26:01.000838 12903 solver.cpp:353] Iteration 52500 (63.2997 iter/s, 1.57979s/100 iter), loss = 0.000941273
I0801 13:26:01.000903 12903 solver.cpp:375]     Train net output #0: loss = 0.000941979 (* 1 = 0.000941979 loss)
I0801 13:26:01.000924 12903 sgd_solver.cpp:136] Iteration 52500, lr = 0.0179687, m = 0.9
I0801 13:26:02.577596 12903 solver.cpp:353] Iteration 52600 (63.4234 iter/s, 1.57671s/100 iter), loss = 0.00150245
I0801 13:26:02.577622 12903 solver.cpp:375]     Train net output #0: loss = 0.00150315 (* 1 = 0.00150315 loss)
I0801 13:26:02.577628 12903 sgd_solver.cpp:136] Iteration 52600, lr = 0.0178125, m = 0.9
I0801 13:26:04.146711 12903 solver.cpp:353] Iteration 52700 (63.7321 iter/s, 1.56907s/100 iter), loss = 0.000527074
I0801 13:26:04.146736 12903 solver.cpp:375]     Train net output #0: loss = 0.00052778 (* 1 = 0.00052778 loss)
I0801 13:26:04.146742 12903 sgd_solver.cpp:136] Iteration 52700, lr = 0.0176562, m = 0.9
I0801 13:26:05.728227 12903 solver.cpp:353] Iteration 52800 (63.2325 iter/s, 1.58146s/100 iter), loss = 0.000359977
I0801 13:26:05.728291 12903 solver.cpp:375]     Train net output #0: loss = 0.000360684 (* 1 = 0.000360684 loss)
I0801 13:26:05.728301 12903 sgd_solver.cpp:136] Iteration 52800, lr = 0.0175, m = 0.9
I0801 13:26:07.300171 12903 solver.cpp:353] Iteration 52900 (63.6175 iter/s, 1.57189s/100 iter), loss = 0.000546978
I0801 13:26:07.300192 12903 solver.cpp:375]     Train net output #0: loss = 0.000547685 (* 1 = 0.000547685 loss)
I0801 13:26:07.300199 12903 sgd_solver.cpp:136] Iteration 52900, lr = 0.0173437, m = 0.9
I0801 13:26:08.853878 12903 solver.cpp:550] Iteration 53000, Testing net (#0)
I0801 13:26:09.672026 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.92206
I0801 13:26:09.672049 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.995882
I0801 13:26:09.672053 12903 solver.cpp:635]     Test net output #2: loss = 0.299387 (* 1 = 0.299387 loss)
I0801 13:26:09.672068 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.818168s
I0801 13:26:09.688053 12903 solver.cpp:353] Iteration 53000 (41.8793 iter/s, 2.38781s/100 iter), loss = 0.00106192
I0801 13:26:09.688071 12903 solver.cpp:375]     Train net output #0: loss = 0.00106262 (* 1 = 0.00106262 loss)
I0801 13:26:09.688074 12903 sgd_solver.cpp:136] Iteration 53000, lr = 0.0171875, m = 0.9
I0801 13:26:11.253165 12903 solver.cpp:353] Iteration 53100 (63.8953 iter/s, 1.56506s/100 iter), loss = 0.000354649
I0801 13:26:11.253196 12903 solver.cpp:375]     Train net output #0: loss = 0.000355355 (* 1 = 0.000355355 loss)
I0801 13:26:11.253202 12903 sgd_solver.cpp:136] Iteration 53100, lr = 0.0170313, m = 0.9
I0801 13:26:12.826190 12903 solver.cpp:353] Iteration 53200 (63.5738 iter/s, 1.57297s/100 iter), loss = 0.000400784
I0801 13:26:12.826239 12903 solver.cpp:375]     Train net output #0: loss = 0.00040149 (* 1 = 0.00040149 loss)
I0801 13:26:12.826251 12903 sgd_solver.cpp:136] Iteration 53200, lr = 0.016875, m = 0.9
I0801 13:26:14.381875 12903 solver.cpp:353] Iteration 53300 (64.2824 iter/s, 1.55564s/100 iter), loss = 0.000891638
I0801 13:26:14.381899 12903 solver.cpp:375]     Train net output #0: loss = 0.000892345 (* 1 = 0.000892345 loss)
I0801 13:26:14.381904 12903 sgd_solver.cpp:136] Iteration 53300, lr = 0.0167188, m = 0.9
I0801 13:26:15.961071 12903 solver.cpp:353] Iteration 53400 (63.3254 iter/s, 1.57915s/100 iter), loss = 0.000831972
I0801 13:26:15.961097 12903 solver.cpp:375]     Train net output #0: loss = 0.000832679 (* 1 = 0.000832679 loss)
I0801 13:26:15.961102 12903 sgd_solver.cpp:136] Iteration 53400, lr = 0.0165625, m = 0.9
I0801 13:26:17.532518 12903 solver.cpp:353] Iteration 53500 (63.6376 iter/s, 1.5714s/100 iter), loss = 0.00101401
I0801 13:26:17.532542 12903 solver.cpp:375]     Train net output #0: loss = 0.00101471 (* 1 = 0.00101471 loss)
I0801 13:26:17.532548 12903 sgd_solver.cpp:136] Iteration 53500, lr = 0.0164063, m = 0.9
I0801 13:26:19.096906 12903 solver.cpp:353] Iteration 53600 (63.9248 iter/s, 1.56434s/100 iter), loss = 0.000911714
I0801 13:26:19.096932 12903 solver.cpp:375]     Train net output #0: loss = 0.000912421 (* 1 = 0.000912421 loss)
I0801 13:26:19.096938 12903 sgd_solver.cpp:136] Iteration 53600, lr = 0.01625, m = 0.9
I0801 13:26:20.662706 12903 solver.cpp:353] Iteration 53700 (63.8672 iter/s, 1.56575s/100 iter), loss = 0.000385599
I0801 13:26:20.662755 12903 solver.cpp:375]     Train net output #0: loss = 0.000386305 (* 1 = 0.000386305 loss)
I0801 13:26:20.662766 12903 sgd_solver.cpp:136] Iteration 53700, lr = 0.0160937, m = 0.9
I0801 13:26:22.235769 12903 solver.cpp:353] Iteration 53800 (63.5723 iter/s, 1.57301s/100 iter), loss = 0.000702459
I0801 13:26:22.235795 12903 solver.cpp:375]     Train net output #0: loss = 0.000703165 (* 1 = 0.000703165 loss)
I0801 13:26:22.235800 12903 sgd_solver.cpp:136] Iteration 53800, lr = 0.0159375, m = 0.9
I0801 13:26:23.813295 12903 solver.cpp:353] Iteration 53900 (63.3923 iter/s, 1.57748s/100 iter), loss = 0.00320757
I0801 13:26:23.813344 12903 solver.cpp:375]     Train net output #0: loss = 0.00320828 (* 1 = 0.00320828 loss)
I0801 13:26:23.813355 12903 sgd_solver.cpp:136] Iteration 53900, lr = 0.0157812, m = 0.9
I0801 13:26:25.365409 12903 solver.cpp:550] Iteration 54000, Testing net (#0)
I0801 13:26:26.186767 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.92853
I0801 13:26:26.186790 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996177
I0801 13:26:26.186796 12903 solver.cpp:635]     Test net output #2: loss = 0.270657 (* 1 = 0.270657 loss)
I0801 13:26:26.186838 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.821407s
I0801 13:26:26.202659 12903 solver.cpp:353] Iteration 54000 (41.8534 iter/s, 2.38929s/100 iter), loss = 0.00339948
I0801 13:26:26.202677 12903 solver.cpp:375]     Train net output #0: loss = 0.00340019 (* 1 = 0.00340019 loss)
I0801 13:26:26.202680 12903 sgd_solver.cpp:136] Iteration 54000, lr = 0.015625, m = 0.9
I0801 13:26:27.801885 12903 solver.cpp:353] Iteration 54100 (62.5323 iter/s, 1.59917s/100 iter), loss = 0.000838586
I0801 13:26:27.801911 12903 solver.cpp:375]     Train net output #0: loss = 0.000839292 (* 1 = 0.000839292 loss)
I0801 13:26:27.801918 12903 sgd_solver.cpp:136] Iteration 54100, lr = 0.0154688, m = 0.9
I0801 13:26:29.375375 12903 solver.cpp:353] Iteration 54200 (63.555 iter/s, 1.57344s/100 iter), loss = 0.00139794
I0801 13:26:29.375403 12903 solver.cpp:375]     Train net output #0: loss = 0.00139865 (* 1 = 0.00139865 loss)
I0801 13:26:29.375411 12903 sgd_solver.cpp:136] Iteration 54200, lr = 0.0153125, m = 0.9
I0801 13:26:30.957545 12903 solver.cpp:353] Iteration 54300 (63.2063 iter/s, 1.58212s/100 iter), loss = 0.00110081
I0801 13:26:30.957630 12903 solver.cpp:375]     Train net output #0: loss = 0.00110152 (* 1 = 0.00110152 loss)
I0801 13:26:30.957638 12903 sgd_solver.cpp:136] Iteration 54300, lr = 0.0151563, m = 0.9
I0801 13:26:32.529386 12903 solver.cpp:353] Iteration 54400 (63.6217 iter/s, 1.57179s/100 iter), loss = 0.00134927
I0801 13:26:32.529417 12903 solver.cpp:375]     Train net output #0: loss = 0.00134997 (* 1 = 0.00134997 loss)
I0801 13:26:32.529423 12903 sgd_solver.cpp:136] Iteration 54400, lr = 0.015, m = 0.9
I0801 13:26:34.115867 12903 solver.cpp:353] Iteration 54500 (63.0344 iter/s, 1.58643s/100 iter), loss = 0.00102437
I0801 13:26:34.115895 12903 solver.cpp:375]     Train net output #0: loss = 0.00102507 (* 1 = 0.00102507 loss)
I0801 13:26:34.115901 12903 sgd_solver.cpp:136] Iteration 54500, lr = 0.0148437, m = 0.9
I0801 13:26:35.687711 12903 solver.cpp:353] Iteration 54600 (63.6216 iter/s, 1.57179s/100 iter), loss = 0.000828277
I0801 13:26:35.687757 12903 solver.cpp:375]     Train net output #0: loss = 0.000828984 (* 1 = 0.000828984 loss)
I0801 13:26:35.687768 12903 sgd_solver.cpp:136] Iteration 54600, lr = 0.0146875, m = 0.9
I0801 13:26:37.270185 12903 solver.cpp:353] Iteration 54700 (63.1941 iter/s, 1.58243s/100 iter), loss = 0.00237774
I0801 13:26:37.270210 12903 solver.cpp:375]     Train net output #0: loss = 0.00237845 (* 1 = 0.00237845 loss)
I0801 13:26:37.270215 12903 sgd_solver.cpp:136] Iteration 54700, lr = 0.0145312, m = 0.9
I0801 13:26:38.843350 12903 solver.cpp:353] Iteration 54800 (63.5682 iter/s, 1.57311s/100 iter), loss = 0.00100538
I0801 13:26:38.843377 12903 solver.cpp:375]     Train net output #0: loss = 0.00100609 (* 1 = 0.00100609 loss)
I0801 13:26:38.843384 12903 sgd_solver.cpp:136] Iteration 54800, lr = 0.014375, m = 0.9
I0801 13:26:40.430138 12903 solver.cpp:353] Iteration 54900 (63.0224 iter/s, 1.58674s/100 iter), loss = 0.000933578
I0801 13:26:40.430164 12903 solver.cpp:375]     Train net output #0: loss = 0.000934284 (* 1 = 0.000934284 loss)
I0801 13:26:40.430171 12903 sgd_solver.cpp:136] Iteration 54900, lr = 0.0142187, m = 0.9
I0801 13:26:41.978225 12903 solver.cpp:550] Iteration 55000, Testing net (#0)
I0801 13:26:42.799010 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.927942
I0801 13:26:42.799029 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996177
I0801 13:26:42.799034 12903 solver.cpp:635]     Test net output #2: loss = 0.254924 (* 1 = 0.254924 loss)
I0801 13:26:42.799048 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.820801s
I0801 13:26:42.814617 12903 solver.cpp:353] Iteration 55000 (41.9391 iter/s, 2.38441s/100 iter), loss = 0.000735547
I0801 13:26:42.814635 12903 solver.cpp:375]     Train net output #0: loss = 0.000736253 (* 1 = 0.000736253 loss)
I0801 13:26:42.814640 12903 sgd_solver.cpp:136] Iteration 55000, lr = 0.0140625, m = 0.9
I0801 13:26:44.381736 12903 solver.cpp:353] Iteration 55100 (63.8134 iter/s, 1.56707s/100 iter), loss = 0.00125402
I0801 13:26:44.381788 12903 solver.cpp:375]     Train net output #0: loss = 0.00125473 (* 1 = 0.00125473 loss)
I0801 13:26:44.381796 12903 sgd_solver.cpp:136] Iteration 55100, lr = 0.0139063, m = 0.9
I0801 13:26:45.950969 12903 solver.cpp:353] Iteration 55200 (63.7274 iter/s, 1.56918s/100 iter), loss = 0.00140519
I0801 13:26:45.950996 12903 solver.cpp:375]     Train net output #0: loss = 0.00140589 (* 1 = 0.00140589 loss)
I0801 13:26:45.951004 12903 sgd_solver.cpp:136] Iteration 55200, lr = 0.01375, m = 0.9
I0801 13:26:47.527004 12903 solver.cpp:353] Iteration 55300 (63.4523 iter/s, 1.57599s/100 iter), loss = 0.00249049
I0801 13:26:47.527031 12903 solver.cpp:375]     Train net output #0: loss = 0.0024912 (* 1 = 0.0024912 loss)
I0801 13:26:47.527037 12903 sgd_solver.cpp:136] Iteration 55300, lr = 0.0135938, m = 0.9
I0801 13:26:49.114117 12903 solver.cpp:353] Iteration 55400 (63.0095 iter/s, 1.58706s/100 iter), loss = 0.00128893
I0801 13:26:49.114142 12903 solver.cpp:375]     Train net output #0: loss = 0.00128964 (* 1 = 0.00128964 loss)
I0801 13:26:49.114147 12903 sgd_solver.cpp:136] Iteration 55400, lr = 0.0134375, m = 0.9
I0801 13:26:50.679811 12903 solver.cpp:353] Iteration 55500 (63.8714 iter/s, 1.56565s/100 iter), loss = 0.000798003
I0801 13:26:50.679836 12903 solver.cpp:375]     Train net output #0: loss = 0.000798709 (* 1 = 0.000798709 loss)
I0801 13:26:50.679842 12903 sgd_solver.cpp:136] Iteration 55500, lr = 0.0132813, m = 0.9
I0801 13:26:52.248179 12903 solver.cpp:353] Iteration 55600 (63.7627 iter/s, 1.56832s/100 iter), loss = 0.000996815
I0801 13:26:52.248208 12903 solver.cpp:375]     Train net output #0: loss = 0.000997521 (* 1 = 0.000997521 loss)
I0801 13:26:52.248215 12903 sgd_solver.cpp:136] Iteration 55600, lr = 0.013125, m = 0.9
I0801 13:26:53.832119 12903 solver.cpp:353] Iteration 55700 (63.1356 iter/s, 1.58389s/100 iter), loss = 0.000572216
I0801 13:26:53.832146 12903 solver.cpp:375]     Train net output #0: loss = 0.000572923 (* 1 = 0.000572923 loss)
I0801 13:26:53.832152 12903 sgd_solver.cpp:136] Iteration 55700, lr = 0.0129687, m = 0.9
I0801 13:26:55.413475 12903 solver.cpp:353] Iteration 55800 (63.2388 iter/s, 1.58131s/100 iter), loss = 0.000747486
I0801 13:26:55.413501 12903 solver.cpp:375]     Train net output #0: loss = 0.000748193 (* 1 = 0.000748193 loss)
I0801 13:26:55.413506 12903 sgd_solver.cpp:136] Iteration 55800, lr = 0.0128125, m = 0.9
I0801 13:26:56.991545 12903 solver.cpp:353] Iteration 55900 (63.3705 iter/s, 1.57802s/100 iter), loss = 0.0019735
I0801 13:26:56.991606 12903 solver.cpp:375]     Train net output #0: loss = 0.0019742 (* 1 = 0.0019742 loss)
I0801 13:26:56.991626 12903 sgd_solver.cpp:136] Iteration 55900, lr = 0.0126562, m = 0.9
I0801 13:26:58.550799 12903 solver.cpp:550] Iteration 56000, Testing net (#0)
I0801 13:26:59.364428 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.927354
I0801 13:26:59.364447 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996471
I0801 13:26:59.364454 12903 solver.cpp:635]     Test net output #2: loss = 0.258522 (* 1 = 0.258522 loss)
I0801 13:26:59.364471 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.813649s
I0801 13:26:59.379948 12903 solver.cpp:353] Iteration 56000 (41.8702 iter/s, 2.38833s/100 iter), loss = 0.000184903
I0801 13:26:59.379966 12903 solver.cpp:375]     Train net output #0: loss = 0.000185611 (* 1 = 0.000185611 loss)
I0801 13:26:59.379971 12903 sgd_solver.cpp:136] Iteration 56000, lr = 0.0125, m = 0.9
I0801 13:27:00.291280 12870 data_reader.cpp:264] Starting prefetch of epoch 7
I0801 13:27:00.964884 12903 solver.cpp:353] Iteration 56100 (63.0962 iter/s, 1.58488s/100 iter), loss = 0.00215221
I0801 13:27:00.964980 12903 solver.cpp:375]     Train net output #0: loss = 0.00215292 (* 1 = 0.00215292 loss)
I0801 13:27:00.964988 12903 sgd_solver.cpp:136] Iteration 56100, lr = 0.0123438, m = 0.9
I0801 13:27:02.539563 12903 solver.cpp:353] Iteration 56200 (63.5069 iter/s, 1.57463s/100 iter), loss = 0.00107203
I0801 13:27:02.539590 12903 solver.cpp:375]     Train net output #0: loss = 0.00107274 (* 1 = 0.00107274 loss)
I0801 13:27:02.539597 12903 sgd_solver.cpp:136] Iteration 56200, lr = 0.0121875, m = 0.9
I0801 13:27:04.119421 12903 solver.cpp:353] Iteration 56300 (63.2988 iter/s, 1.57981s/100 iter), loss = 0.000766076
I0801 13:27:04.119469 12903 solver.cpp:375]     Train net output #0: loss = 0.000766782 (* 1 = 0.000766782 loss)
I0801 13:27:04.119483 12903 sgd_solver.cpp:136] Iteration 56300, lr = 0.0120313, m = 0.9
I0801 13:27:05.693104 12903 solver.cpp:353] Iteration 56400 (63.5472 iter/s, 1.57363s/100 iter), loss = 0.00143096
I0801 13:27:05.693131 12903 solver.cpp:375]     Train net output #0: loss = 0.00143167 (* 1 = 0.00143167 loss)
I0801 13:27:05.693136 12903 sgd_solver.cpp:136] Iteration 56400, lr = 0.011875, m = 0.9
I0801 13:27:07.270184 12903 solver.cpp:353] Iteration 56500 (63.4104 iter/s, 1.57703s/100 iter), loss = 0.00115065
I0801 13:27:07.270212 12903 solver.cpp:375]     Train net output #0: loss = 0.00115136 (* 1 = 0.00115136 loss)
I0801 13:27:07.270218 12903 sgd_solver.cpp:136] Iteration 56500, lr = 0.0117188, m = 0.9
I0801 13:27:08.853374 12903 solver.cpp:353] Iteration 56600 (63.1657 iter/s, 1.58314s/100 iter), loss = 0.00097385
I0801 13:27:08.853427 12903 solver.cpp:375]     Train net output #0: loss = 0.000974556 (* 1 = 0.000974556 loss)
I0801 13:27:08.853443 12903 sgd_solver.cpp:136] Iteration 56600, lr = 0.0115625, m = 0.9
I0801 13:27:10.453546 12903 solver.cpp:353] Iteration 56700 (62.4951 iter/s, 1.60012s/100 iter), loss = 0.000849945
I0801 13:27:10.453572 12903 solver.cpp:375]     Train net output #0: loss = 0.000850651 (* 1 = 0.000850651 loss)
I0801 13:27:10.453578 12903 sgd_solver.cpp:136] Iteration 56700, lr = 0.0114062, m = 0.9
I0801 13:27:12.032438 12903 solver.cpp:353] Iteration 56800 (63.3375 iter/s, 1.57884s/100 iter), loss = 0.000787578
I0801 13:27:12.032464 12903 solver.cpp:375]     Train net output #0: loss = 0.000788284 (* 1 = 0.000788284 loss)
I0801 13:27:12.032470 12903 sgd_solver.cpp:136] Iteration 56800, lr = 0.01125, m = 0.9
I0801 13:27:13.604084 12903 solver.cpp:353] Iteration 56900 (63.6297 iter/s, 1.57159s/100 iter), loss = 0.000532971
I0801 13:27:13.604112 12903 solver.cpp:375]     Train net output #0: loss = 0.000533676 (* 1 = 0.000533676 loss)
I0801 13:27:13.604118 12903 sgd_solver.cpp:136] Iteration 56900, lr = 0.0110937, m = 0.9
I0801 13:27:15.184379 12903 solver.cpp:550] Iteration 57000, Testing net (#0)
I0801 13:27:15.999169 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.924707
I0801 13:27:15.999189 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.997059
I0801 13:27:15.999197 12903 solver.cpp:635]     Test net output #2: loss = 0.267246 (* 1 = 0.267246 loss)
I0801 13:27:15.999213 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.814812s
I0801 13:27:16.014741 12903 solver.cpp:353] Iteration 57000 (41.4837 iter/s, 2.41059s/100 iter), loss = 0.00408351
I0801 13:27:16.014758 12903 solver.cpp:375]     Train net output #0: loss = 0.00408422 (* 1 = 0.00408422 loss)
I0801 13:27:16.014765 12903 sgd_solver.cpp:136] Iteration 57000, lr = 0.0109375, m = 0.9
I0801 13:27:17.605005 12903 solver.cpp:353] Iteration 57100 (62.8847 iter/s, 1.59021s/100 iter), loss = 0.00104905
I0801 13:27:17.605034 12903 solver.cpp:375]     Train net output #0: loss = 0.00104976 (* 1 = 0.00104976 loss)
I0801 13:27:17.605041 12903 sgd_solver.cpp:136] Iteration 57100, lr = 0.0107813, m = 0.9
I0801 13:27:19.204416 12903 solver.cpp:353] Iteration 57200 (62.5251 iter/s, 1.59936s/100 iter), loss = 0.00138985
I0801 13:27:19.204468 12903 solver.cpp:375]     Train net output #0: loss = 0.00139056 (* 1 = 0.00139056 loss)
I0801 13:27:19.204494 12903 sgd_solver.cpp:136] Iteration 57200, lr = 0.010625, m = 0.9
I0801 13:27:20.780978 12903 solver.cpp:353] Iteration 57300 (63.4311 iter/s, 1.57651s/100 iter), loss = 0.00123318
I0801 13:27:20.781006 12903 solver.cpp:375]     Train net output #0: loss = 0.00123388 (* 1 = 0.00123388 loss)
I0801 13:27:20.781011 12903 sgd_solver.cpp:136] Iteration 57300, lr = 0.0104688, m = 0.9
I0801 13:27:22.380795 12903 solver.cpp:353] Iteration 57400 (62.5091 iter/s, 1.59977s/100 iter), loss = 0.00179599
I0801 13:27:22.380827 12903 solver.cpp:375]     Train net output #0: loss = 0.00179669 (* 1 = 0.00179669 loss)
I0801 13:27:22.380834 12903 sgd_solver.cpp:136] Iteration 57400, lr = 0.0103125, m = 0.9
I0801 13:27:23.950064 12903 solver.cpp:353] Iteration 57500 (63.726 iter/s, 1.56922s/100 iter), loss = 0.00157718
I0801 13:27:23.950114 12903 solver.cpp:375]     Train net output #0: loss = 0.00157789 (* 1 = 0.00157789 loss)
I0801 13:27:23.950126 12903 sgd_solver.cpp:136] Iteration 57500, lr = 0.0101563, m = 0.9
I0801 13:27:25.526654 12903 solver.cpp:353] Iteration 57600 (63.4299 iter/s, 1.57654s/100 iter), loss = 0.00236302
I0801 13:27:25.526684 12903 solver.cpp:375]     Train net output #0: loss = 0.00236373 (* 1 = 0.00236373 loss)
I0801 13:27:25.526690 12903 sgd_solver.cpp:136] Iteration 57600, lr = 0.01, m = 0.9
I0801 13:27:27.094729 12903 solver.cpp:353] Iteration 57700 (63.7746 iter/s, 1.56802s/100 iter), loss = 0.000587495
I0801 13:27:27.094753 12903 solver.cpp:375]     Train net output #0: loss = 0.000588201 (* 1 = 0.000588201 loss)
I0801 13:27:27.094758 12903 sgd_solver.cpp:136] Iteration 57700, lr = 0.00984375, m = 0.9
I0801 13:27:28.662787 12903 solver.cpp:353] Iteration 57800 (63.7752 iter/s, 1.56801s/100 iter), loss = 0.0011759
I0801 13:27:28.662817 12903 solver.cpp:375]     Train net output #0: loss = 0.00117661 (* 1 = 0.00117661 loss)
I0801 13:27:28.662824 12903 sgd_solver.cpp:136] Iteration 57800, lr = 0.0096875, m = 0.9
I0801 13:27:30.227545 12903 solver.cpp:353] Iteration 57900 (63.9097 iter/s, 1.56471s/100 iter), loss = 0.00141676
I0801 13:27:30.227568 12903 solver.cpp:375]     Train net output #0: loss = 0.00141747 (* 1 = 0.00141747 loss)
I0801 13:27:30.227572 12903 sgd_solver.cpp:136] Iteration 57900, lr = 0.00953125, m = 0.9
I0801 13:27:31.784024 12903 solver.cpp:550] Iteration 58000, Testing net (#0)
I0801 13:27:32.603066 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.919118
I0801 13:27:32.603086 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.997059
I0801 13:27:32.603091 12903 solver.cpp:635]     Test net output #2: loss = 0.296162 (* 1 = 0.296162 loss)
I0801 13:27:32.603107 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.819062s
I0801 13:27:32.618710 12903 solver.cpp:353] Iteration 58000 (41.8218 iter/s, 2.3911s/100 iter), loss = 0.00214606
I0801 13:27:32.618728 12903 solver.cpp:375]     Train net output #0: loss = 0.00214677 (* 1 = 0.00214677 loss)
I0801 13:27:32.618734 12903 sgd_solver.cpp:136] Iteration 58000, lr = 0.009375, m = 0.9
I0801 13:27:34.202669 12903 solver.cpp:353] Iteration 58100 (63.135 iter/s, 1.58391s/100 iter), loss = 0.00272546
I0801 13:27:34.202697 12903 solver.cpp:375]     Train net output #0: loss = 0.00272616 (* 1 = 0.00272616 loss)
I0801 13:27:34.202702 12903 sgd_solver.cpp:136] Iteration 58100, lr = 0.00921875, m = 0.9
I0801 13:27:35.775634 12903 solver.cpp:353] Iteration 58200 (63.5762 iter/s, 1.57292s/100 iter), loss = 0.000810932
I0801 13:27:35.775660 12903 solver.cpp:375]     Train net output #0: loss = 0.000811638 (* 1 = 0.000811638 loss)
I0801 13:27:35.775665 12903 sgd_solver.cpp:136] Iteration 58200, lr = 0.0090625, m = 0.9
I0801 13:27:37.348601 12903 solver.cpp:353] Iteration 58300 (63.576 iter/s, 1.57292s/100 iter), loss = 0.00163075
I0801 13:27:37.348628 12903 solver.cpp:375]     Train net output #0: loss = 0.00163146 (* 1 = 0.00163146 loss)
I0801 13:27:37.348634 12903 sgd_solver.cpp:136] Iteration 58300, lr = 0.00890625, m = 0.9
I0801 13:27:38.920658 12903 solver.cpp:353] Iteration 58400 (63.613 iter/s, 1.57201s/100 iter), loss = 0.000631986
I0801 13:27:38.920682 12903 solver.cpp:375]     Train net output #0: loss = 0.000632692 (* 1 = 0.000632692 loss)
I0801 13:27:38.920686 12903 sgd_solver.cpp:136] Iteration 58400, lr = 0.00875, m = 0.9
I0801 13:27:40.490636 12903 solver.cpp:353] Iteration 58500 (63.6972 iter/s, 1.56993s/100 iter), loss = 0.00064692
I0801 13:27:40.490692 12903 solver.cpp:375]     Train net output #0: loss = 0.000647626 (* 1 = 0.000647626 loss)
I0801 13:27:40.490707 12903 sgd_solver.cpp:136] Iteration 58500, lr = 0.00859375, m = 0.9
I0801 13:27:42.051048 12903 solver.cpp:353] Iteration 58600 (64.0876 iter/s, 1.56036s/100 iter), loss = 0.00025714
I0801 13:27:42.051076 12903 solver.cpp:375]     Train net output #0: loss = 0.000257846 (* 1 = 0.000257846 loss)
I0801 13:27:42.051082 12903 sgd_solver.cpp:136] Iteration 58600, lr = 0.0084375, m = 0.9
I0801 13:27:43.628379 12903 solver.cpp:353] Iteration 58700 (63.4002 iter/s, 1.57728s/100 iter), loss = 0.00112536
I0801 13:27:43.628406 12903 solver.cpp:375]     Train net output #0: loss = 0.00112607 (* 1 = 0.00112607 loss)
I0801 13:27:43.628412 12903 sgd_solver.cpp:136] Iteration 58700, lr = 0.00828125, m = 0.9
I0801 13:27:45.188421 12903 solver.cpp:353] Iteration 58800 (64.1029 iter/s, 1.55999s/100 iter), loss = 0.000975752
I0801 13:27:45.188448 12903 solver.cpp:375]     Train net output #0: loss = 0.000976458 (* 1 = 0.000976458 loss)
I0801 13:27:45.188454 12903 sgd_solver.cpp:136] Iteration 58800, lr = 0.008125, m = 0.9
I0801 13:27:46.753273 12903 solver.cpp:353] Iteration 58900 (63.9059 iter/s, 1.5648s/100 iter), loss = 0.00208931
I0801 13:27:46.753298 12903 solver.cpp:375]     Train net output #0: loss = 0.00209001 (* 1 = 0.00209001 loss)
I0801 13:27:46.753304 12903 sgd_solver.cpp:136] Iteration 58900, lr = 0.00796875, m = 0.9
I0801 13:27:48.324371 12903 solver.cpp:550] Iteration 59000, Testing net (#0)
I0801 13:27:49.138923 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.91706
I0801 13:27:49.138942 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996765
I0801 13:27:49.138950 12903 solver.cpp:635]     Test net output #2: loss = 0.292 (* 1 = 0.292 loss)
I0801 13:27:49.138974 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.814578s
I0801 13:27:49.154676 12903 solver.cpp:353] Iteration 59000 (41.6436 iter/s, 2.40133s/100 iter), loss = 0.0013726
I0801 13:27:49.154700 12903 solver.cpp:375]     Train net output #0: loss = 0.00137331 (* 1 = 0.00137331 loss)
I0801 13:27:49.154724 12903 sgd_solver.cpp:136] Iteration 59000, lr = 0.0078125, m = 0.9
I0801 13:27:50.717939 12903 solver.cpp:353] Iteration 59100 (63.9708 iter/s, 1.56321s/100 iter), loss = 0.00104596
I0801 13:27:50.717962 12903 solver.cpp:375]     Train net output #0: loss = 0.00104667 (* 1 = 0.00104667 loss)
I0801 13:27:50.717967 12903 sgd_solver.cpp:136] Iteration 59100, lr = 0.00765625, m = 0.9
I0801 13:27:52.296286 12903 solver.cpp:353] Iteration 59200 (63.3595 iter/s, 1.5783s/100 iter), loss = 0.00116725
I0801 13:27:52.296335 12903 solver.cpp:375]     Train net output #0: loss = 0.00116796 (* 1 = 0.00116796 loss)
I0801 13:27:52.296349 12903 sgd_solver.cpp:136] Iteration 59200, lr = 0.0075, m = 0.9
I0801 13:27:53.867784 12903 solver.cpp:353] Iteration 59300 (63.6357 iter/s, 1.57145s/100 iter), loss = 0.00149698
I0801 13:27:53.867810 12903 solver.cpp:375]     Train net output #0: loss = 0.00149768 (* 1 = 0.00149768 loss)
I0801 13:27:53.867815 12903 sgd_solver.cpp:136] Iteration 59300, lr = 0.00734375, m = 0.9
I0801 13:27:55.424927 12903 solver.cpp:353] Iteration 59400 (64.2221 iter/s, 1.5571s/100 iter), loss = 0.0021473
I0801 13:27:55.424949 12903 solver.cpp:375]     Train net output #0: loss = 0.00214801 (* 1 = 0.00214801 loss)
I0801 13:27:55.424953 12903 sgd_solver.cpp:136] Iteration 59400, lr = 0.0071875, m = 0.9
I0801 13:27:57.005421 12903 solver.cpp:353] Iteration 59500 (63.2734 iter/s, 1.58044s/100 iter), loss = 0.000855981
I0801 13:27:57.005475 12903 solver.cpp:375]     Train net output #0: loss = 0.000856685 (* 1 = 0.000856685 loss)
I0801 13:27:57.005491 12903 sgd_solver.cpp:136] Iteration 59500, lr = 0.00703125, m = 0.9
I0801 13:27:58.578826 12903 solver.cpp:353] Iteration 59600 (63.5586 iter/s, 1.57335s/100 iter), loss = 0.00139616
I0801 13:27:58.578878 12903 solver.cpp:375]     Train net output #0: loss = 0.00139686 (* 1 = 0.00139686 loss)
I0801 13:27:58.578892 12903 sgd_solver.cpp:136] Iteration 59600, lr = 0.006875, m = 0.9
I0801 13:28:00.164309 12903 solver.cpp:353] Iteration 59700 (63.0742 iter/s, 1.58543s/100 iter), loss = 0.00177853
I0801 13:28:00.164338 12903 solver.cpp:375]     Train net output #0: loss = 0.00177924 (* 1 = 0.00177924 loss)
I0801 13:28:00.164345 12903 sgd_solver.cpp:136] Iteration 59700, lr = 0.00671875, m = 0.9
I0801 13:28:01.735613 12903 solver.cpp:353] Iteration 59800 (63.6434 iter/s, 1.57126s/100 iter), loss = 0.00134299
I0801 13:28:01.735636 12903 solver.cpp:375]     Train net output #0: loss = 0.00134369 (* 1 = 0.00134369 loss)
I0801 13:28:01.735641 12903 sgd_solver.cpp:136] Iteration 59800, lr = 0.0065625, m = 0.9
I0801 13:28:03.315631 12903 solver.cpp:353] Iteration 59900 (63.2923 iter/s, 1.57997s/100 iter), loss = 0.00115282
I0801 13:28:03.315722 12903 solver.cpp:375]     Train net output #0: loss = 0.00115353 (* 1 = 0.00115353 loss)
I0801 13:28:03.315729 12903 sgd_solver.cpp:136] Iteration 59900, lr = 0.00640625, m = 0.9
I0801 13:28:04.871706 12903 solver.cpp:680] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/initial/cifar10_jacintonet11v2_iter_60000.caffemodel
I0801 13:28:04.879818 12903 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/initial/cifar10_jacintonet11v2_iter_60000.solverstate
I0801 13:28:04.883352 12903 solver.cpp:550] Iteration 60000, Testing net (#0)
I0801 13:28:05.688143 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.917942
I0801 13:28:05.688168 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996471
I0801 13:28:05.688174 12903 solver.cpp:635]     Test net output #2: loss = 0.308536 (* 1 = 0.308536 loss)
I0801 13:28:05.688199 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.80482s
I0801 13:28:05.705426 12903 solver.cpp:353] Iteration 60000 (41.8459 iter/s, 2.38972s/100 iter), loss = 0.00178693
I0801 13:28:05.705451 12903 solver.cpp:375]     Train net output #0: loss = 0.00178763 (* 1 = 0.00178763 loss)
I0801 13:28:05.705456 12903 sgd_solver.cpp:136] Iteration 60000, lr = 0.00625, m = 0.9
I0801 13:28:07.269307 12903 solver.cpp:353] Iteration 60100 (63.9454 iter/s, 1.56383s/100 iter), loss = 0.00143045
I0801 13:28:07.269335 12903 solver.cpp:375]     Train net output #0: loss = 0.00143115 (* 1 = 0.00143115 loss)
I0801 13:28:07.269340 12903 sgd_solver.cpp:136] Iteration 60100, lr = 0.00609375, m = 0.9
I0801 13:28:08.840478 12903 solver.cpp:353] Iteration 60200 (63.6487 iter/s, 1.57112s/100 iter), loss = 0.00160128
I0801 13:28:08.840503 12903 solver.cpp:375]     Train net output #0: loss = 0.00160198 (* 1 = 0.00160198 loss)
I0801 13:28:08.840509 12903 sgd_solver.cpp:136] Iteration 60200, lr = 0.0059375, m = 0.9
I0801 13:28:10.395427 12903 solver.cpp:353] Iteration 60300 (64.3128 iter/s, 1.5549s/100 iter), loss = 0.00156852
I0801 13:28:10.395452 12903 solver.cpp:375]     Train net output #0: loss = 0.00156922 (* 1 = 0.00156922 loss)
I0801 13:28:10.395458 12903 sgd_solver.cpp:136] Iteration 60300, lr = 0.00578125, m = 0.9
I0801 13:28:11.962107 12903 solver.cpp:353] Iteration 60400 (63.8313 iter/s, 1.56663s/100 iter), loss = 0.000430844
I0801 13:28:11.962137 12903 solver.cpp:375]     Train net output #0: loss = 0.000431549 (* 1 = 0.000431549 loss)
I0801 13:28:11.962146 12903 sgd_solver.cpp:136] Iteration 60400, lr = 0.005625, m = 0.9
I0801 13:28:13.542696 12903 solver.cpp:353] Iteration 60500 (63.2695 iter/s, 1.58054s/100 iter), loss = 0.0015867
I0801 13:28:13.542747 12903 solver.cpp:375]     Train net output #0: loss = 0.0015874 (* 1 = 0.0015874 loss)
I0801 13:28:13.542762 12903 sgd_solver.cpp:136] Iteration 60500, lr = 0.00546875, m = 0.9
I0801 13:28:15.116317 12903 solver.cpp:353] Iteration 60600 (63.5498 iter/s, 1.57357s/100 iter), loss = 0.00137623
I0801 13:28:15.116345 12903 solver.cpp:375]     Train net output #0: loss = 0.00137693 (* 1 = 0.00137693 loss)
I0801 13:28:15.116351 12903 sgd_solver.cpp:136] Iteration 60600, lr = 0.0053125, m = 0.9
I0801 13:28:15.166486 12870 data_reader.cpp:264] Starting prefetch of epoch 8
I0801 13:28:16.690309 12903 solver.cpp:353] Iteration 60700 (63.5349 iter/s, 1.57394s/100 iter), loss = 0.00136159
I0801 13:28:16.690337 12903 solver.cpp:375]     Train net output #0: loss = 0.00136229 (* 1 = 0.00136229 loss)
I0801 13:28:16.690343 12903 sgd_solver.cpp:136] Iteration 60700, lr = 0.00515625, m = 0.9
I0801 13:28:18.266511 12903 solver.cpp:353] Iteration 60800 (63.4456 iter/s, 1.57615s/100 iter), loss = 0.00147759
I0801 13:28:18.266540 12903 solver.cpp:375]     Train net output #0: loss = 0.00147829 (* 1 = 0.00147829 loss)
I0801 13:28:18.266546 12903 sgd_solver.cpp:136] Iteration 60800, lr = 0.005, m = 0.9
I0801 13:28:19.850352 12903 solver.cpp:353] Iteration 60900 (63.1396 iter/s, 1.58379s/100 iter), loss = 0.000706712
I0801 13:28:19.850378 12903 solver.cpp:375]     Train net output #0: loss = 0.000707416 (* 1 = 0.000707416 loss)
I0801 13:28:19.850412 12903 sgd_solver.cpp:136] Iteration 60900, lr = 0.00484375, m = 0.9
I0801 13:28:21.396302 12903 solver.cpp:550] Iteration 61000, Testing net (#0)
I0801 13:28:22.213696 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.915883
I0801 13:28:22.213717 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.996471
I0801 13:28:22.213722 12903 solver.cpp:635]     Test net output #2: loss = 0.298915 (* 1 = 0.298915 loss)
I0801 13:28:22.213737 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.817413s
I0801 13:28:22.229301 12903 solver.cpp:353] Iteration 61000 (42.0366 iter/s, 2.37888s/100 iter), loss = 0.0011437
I0801 13:28:22.229318 12903 solver.cpp:375]     Train net output #0: loss = 0.0011444 (* 1 = 0.0011444 loss)
I0801 13:28:22.229322 12903 sgd_solver.cpp:136] Iteration 61000, lr = 0.0046875, m = 0.9
I0801 13:28:23.802240 12903 solver.cpp:353] Iteration 61100 (63.5773 iter/s, 1.57289s/100 iter), loss = 0.000591563
I0801 13:28:23.802266 12903 solver.cpp:375]     Train net output #0: loss = 0.000592267 (* 1 = 0.000592267 loss)
I0801 13:28:23.802273 12903 sgd_solver.cpp:136] Iteration 61100, lr = 0.00453125, m = 0.9
I0801 13:28:25.358064 12903 solver.cpp:353] Iteration 61200 (64.2766 iter/s, 1.55578s/100 iter), loss = 0.000864033
I0801 13:28:25.358089 12903 solver.cpp:375]     Train net output #0: loss = 0.000864738 (* 1 = 0.000864738 loss)
I0801 13:28:25.358095 12903 sgd_solver.cpp:136] Iteration 61200, lr = 0.004375, m = 0.9
I0801 13:28:26.943308 12903 solver.cpp:353] Iteration 61300 (63.0836 iter/s, 1.5852s/100 iter), loss = 0.00127265
I0801 13:28:26.943334 12903 solver.cpp:375]     Train net output #0: loss = 0.00127336 (* 1 = 0.00127336 loss)
I0801 13:28:26.943341 12903 sgd_solver.cpp:136] Iteration 61300, lr = 0.00421875, m = 0.9
I0801 13:28:28.515003 12903 solver.cpp:353] Iteration 61400 (63.6277 iter/s, 1.57164s/100 iter), loss = 0.00112791
I0801 13:28:28.515030 12903 solver.cpp:375]     Train net output #0: loss = 0.00112861 (* 1 = 0.00112861 loss)
I0801 13:28:28.515036 12903 sgd_solver.cpp:136] Iteration 61400, lr = 0.0040625, m = 0.9
I0801 13:28:30.115522 12903 solver.cpp:353] Iteration 61500 (62.4816 iter/s, 1.60047s/100 iter), loss = 0.00241912
I0801 13:28:30.115571 12903 solver.cpp:375]     Train net output #0: loss = 0.00241982 (* 1 = 0.00241982 loss)
I0801 13:28:30.115586 12903 sgd_solver.cpp:136] Iteration 61500, lr = 0.00390625, m = 0.9
I0801 13:28:31.675556 12903 solver.cpp:353] Iteration 61600 (64.1033 iter/s, 1.55998s/100 iter), loss = 0.00259818
I0801 13:28:31.675586 12903 solver.cpp:375]     Train net output #0: loss = 0.00259889 (* 1 = 0.00259889 loss)
I0801 13:28:31.675593 12903 sgd_solver.cpp:136] Iteration 61600, lr = 0.00375, m = 0.9
I0801 13:28:33.312621 12903 solver.cpp:353] Iteration 61700 (61.0868 iter/s, 1.63702s/100 iter), loss = 0.000434242
I0801 13:28:33.312649 12903 solver.cpp:375]     Train net output #0: loss = 0.000434947 (* 1 = 0.000434947 loss)
I0801 13:28:33.312656 12903 sgd_solver.cpp:136] Iteration 61700, lr = 0.00359375, m = 0.9
I0801 13:28:34.973466 12903 solver.cpp:353] Iteration 61800 (60.2122 iter/s, 1.66079s/100 iter), loss = 0.000707011
I0801 13:28:34.973562 12903 solver.cpp:375]     Train net output #0: loss = 0.000707716 (* 1 = 0.000707716 loss)
I0801 13:28:34.973569 12903 sgd_solver.cpp:136] Iteration 61800, lr = 0.0034375, m = 0.9
I0801 13:28:36.579821 12903 solver.cpp:353] Iteration 61900 (62.2547 iter/s, 1.6063s/100 iter), loss = 0.00105429
I0801 13:28:36.579849 12903 solver.cpp:375]     Train net output #0: loss = 0.00105499 (* 1 = 0.00105499 loss)
I0801 13:28:36.579855 12903 sgd_solver.cpp:136] Iteration 61900, lr = 0.00328125, m = 0.9
I0801 13:28:38.166905 12903 solver.cpp:550] Iteration 62000, Testing net (#0)
I0801 13:28:39.005867 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.915001
I0801 13:28:39.005887 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.995588
I0801 13:28:39.005892 12903 solver.cpp:635]     Test net output #2: loss = 0.315541 (* 1 = 0.315541 loss)
I0801 13:28:39.005906 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.838978s
I0801 13:28:39.021929 12903 solver.cpp:353] Iteration 62000 (40.9495 iter/s, 2.44203s/100 iter), loss = 0.000610828
I0801 13:28:39.021950 12903 solver.cpp:375]     Train net output #0: loss = 0.000611534 (* 1 = 0.000611534 loss)
I0801 13:28:39.021955 12903 sgd_solver.cpp:136] Iteration 62000, lr = 0.003125, m = 0.9
I0801 13:28:40.608515 12903 solver.cpp:353] Iteration 62100 (63.0305 iter/s, 1.58653s/100 iter), loss = 0.000730326
I0801 13:28:40.608541 12903 solver.cpp:375]     Train net output #0: loss = 0.000731031 (* 1 = 0.000731031 loss)
I0801 13:28:40.608547 12903 sgd_solver.cpp:136] Iteration 62100, lr = 0.00296875, m = 0.9
I0801 13:28:42.208557 12903 solver.cpp:353] Iteration 62200 (62.5004 iter/s, 1.59999s/100 iter), loss = 0.00114449
I0801 13:28:42.208611 12903 solver.cpp:375]     Train net output #0: loss = 0.0011452 (* 1 = 0.0011452 loss)
I0801 13:28:42.208626 12903 sgd_solver.cpp:136] Iteration 62200, lr = 0.0028125, m = 0.9
I0801 13:28:43.791429 12903 solver.cpp:353] Iteration 62300 (63.1784 iter/s, 1.58282s/100 iter), loss = 0.00143707
I0801 13:28:43.791462 12903 solver.cpp:375]     Train net output #0: loss = 0.00143778 (* 1 = 0.00143778 loss)
I0801 13:28:43.791468 12903 sgd_solver.cpp:136] Iteration 62300, lr = 0.00265625, m = 0.9
I0801 13:28:45.453290 12903 solver.cpp:353] Iteration 62400 (60.1753 iter/s, 1.66181s/100 iter), loss = 0.00109732
I0801 13:28:45.453316 12903 solver.cpp:375]     Train net output #0: loss = 0.00109803 (* 1 = 0.00109803 loss)
I0801 13:28:45.453322 12903 sgd_solver.cpp:136] Iteration 62400, lr = 0.0025, m = 0.9
I0801 13:28:47.033403 12903 solver.cpp:353] Iteration 62500 (63.2887 iter/s, 1.58006s/100 iter), loss = 0.000554101
I0801 13:28:47.033433 12903 solver.cpp:375]     Train net output #0: loss = 0.000554806 (* 1 = 0.000554806 loss)
I0801 13:28:47.033439 12903 sgd_solver.cpp:136] Iteration 62500, lr = 0.00234375, m = 0.9
I0801 13:28:48.603997 12903 solver.cpp:353] Iteration 62600 (63.6721 iter/s, 1.57055s/100 iter), loss = 0.00202539
I0801 13:28:48.604048 12903 solver.cpp:375]     Train net output #0: loss = 0.00202609 (* 1 = 0.00202609 loss)
I0801 13:28:48.604061 12903 sgd_solver.cpp:136] Iteration 62600, lr = 0.0021875, m = 0.9
I0801 13:28:50.233196 12903 solver.cpp:353] Iteration 62700 (61.3819 iter/s, 1.62914s/100 iter), loss = 0.00161189
I0801 13:28:50.233248 12903 solver.cpp:375]     Train net output #0: loss = 0.0016126 (* 1 = 0.0016126 loss)
I0801 13:28:50.233264 12903 sgd_solver.cpp:136] Iteration 62700, lr = 0.00203125, m = 0.9
I0801 13:28:51.841365 12903 solver.cpp:353] Iteration 62800 (62.1844 iter/s, 1.60812s/100 iter), loss = 0.00134809
I0801 13:28:51.841392 12903 solver.cpp:375]     Train net output #0: loss = 0.00134879 (* 1 = 0.00134879 loss)
I0801 13:28:51.841399 12903 sgd_solver.cpp:136] Iteration 62800, lr = 0.001875, m = 0.9
I0801 13:28:53.471943 12903 solver.cpp:353] Iteration 62900 (61.33 iter/s, 1.63052s/100 iter), loss = 0.00068901
I0801 13:28:53.471971 12903 solver.cpp:375]     Train net output #0: loss = 0.000689715 (* 1 = 0.000689715 loss)
I0801 13:28:53.471976 12903 sgd_solver.cpp:136] Iteration 62900, lr = 0.00171875, m = 0.9
I0801 13:28:55.066890 12903 solver.cpp:550] Iteration 63000, Testing net (#0)
I0801 13:28:55.899088 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.914413
I0801 13:28:55.899114 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.995588
I0801 13:28:55.899121 12903 solver.cpp:635]     Test net output #2: loss = 0.317738 (* 1 = 0.317738 loss)
I0801 13:28:55.899147 12903 solver.cpp:305] [MultiGPU] Tests completed in 0.83223s
I0801 13:28:55.918171 12903 solver.cpp:353] Iteration 63000 (40.8805 iter/s, 2.44615s/100 iter), loss = 0.000878555
I0801 13:28:55.918483 12903 solver.cpp:375]     Train net output #0: loss = 0.000879261 (* 1 = 0.000879261 loss)
I0801 13:28:55.918505 12903 sgd_solver.cpp:136] Iteration 63000, lr = 0.0015625, m = 0.9
I0801 13:28:57.508882 12903 solver.cpp:353] Iteration 63100 (62.8668 iter/s, 1.59066s/100 iter), loss = 0.00103529
I0801 13:28:57.508937 12903 solver.cpp:375]     Train net output #0: loss = 0.001036 (* 1 = 0.001036 loss)
I0801 13:28:57.508952 12903 sgd_solver.cpp:136] Iteration 63100, lr = 0.00140625, m = 0.9
I0801 13:28:59.107507 12903 solver.cpp:353] Iteration 63200 (62.5557 iter/s, 1.59857s/100 iter), loss = 0.00124583
I0801 13:28:59.107532 12903 solver.cpp:375]     Train net output #0: loss = 0.00124654 (* 1 = 0.00124654 loss)
I0801 13:28:59.107538 12903 sgd_solver.cpp:136] Iteration 63200, lr = 0.00125, m = 0.9
I0801 13:29:00.724050 12903 solver.cpp:353] Iteration 63300 (61.8624 iter/s, 1.61649s/100 iter), loss = 0.0018219
I0801 13:29:00.724076 12903 solver.cpp:375]     Train net output #0: loss = 0.00182261 (* 1 = 0.00182261 loss)
I0801 13:29:00.724082 12903 sgd_solver.cpp:136] Iteration 63300, lr = 0.00109375, m = 0.9
I0801 13:29:02.369475 12903 solver.cpp:353] Iteration 63400 (60.7765 iter/s, 1.64537s/100 iter), loss = 0.000529927
I0801 13:29:02.369500 12903 solver.cpp:375]     Train net output #0: loss = 0.000530634 (* 1 = 0.000530634 loss)
I0801 13:29:02.369504 12903 sgd_solver.cpp:136] Iteration 63400, lr = 0.000937498, m = 0.9
I0801 13:29:03.969825 12903 solver.cpp:353] Iteration 63500 (62.4882 iter/s, 1.6003s/100 iter), loss = 0.00106112
I0801 13:29:03.969851 12903 solver.cpp:375]     Train net output #0: loss = 0.00106182 (* 1 = 0.00106182 loss)
I0801 13:29:03.969856 12903 sgd_solver.cpp:136] Iteration 63500, lr = 0.00078125, m = 0.9
I0801 13:29:05.552489 12903 solver.cpp:353] Iteration 63600 (63.1867 iter/s, 1.58261s/100 iter), loss = 0.000353943
I0801 13:29:05.552564 12903 solver.cpp:375]     Train net output #0: loss = 0.000354649 (* 1 = 0.000354649 loss)
I0801 13:29:05.552572 12903 sgd_solver.cpp:136] Iteration 63600, lr = 0.000625002, m = 0.9
I0801 13:29:07.173454 12903 solver.cpp:353] Iteration 63700 (61.6936 iter/s, 1.62091s/100 iter), loss = 0.000846336
I0801 13:29:07.173481 12903 solver.cpp:375]     Train net output #0: loss = 0.000847042 (* 1 = 0.000847042 loss)
I0801 13:29:07.173487 12903 sgd_solver.cpp:136] Iteration 63700, lr = 0.000468749, m = 0.9
I0801 13:29:08.748536 12903 solver.cpp:353] Iteration 63800 (63.4907 iter/s, 1.57503s/100 iter), loss = 0.00156873
I0801 13:29:08.748569 12903 solver.cpp:375]     Train net output #0: loss = 0.00156943 (* 1 = 0.00156943 loss)
I0801 13:29:08.748576 12903 sgd_solver.cpp:136] Iteration 63800, lr = 0.000312501, m = 0.9
I0801 13:29:10.339066 12903 solver.cpp:353] Iteration 63900 (62.8741 iter/s, 1.59048s/100 iter), loss = 0.00114089
I0801 13:29:10.339118 12903 solver.cpp:375]     Train net output #0: loss = 0.00114159 (* 1 = 0.00114159 loss)
I0801 13:29:10.339133 12903 sgd_solver.cpp:136] Iteration 63900, lr = 0.000156248, m = 0.9
I0801 13:29:11.957785 12903 solver.cpp:353] Iteration 63999 (61.1615 iter/s, 1.61867s/99 iter), loss = 0.000412225
I0801 13:29:11.957821 12903 solver.cpp:375]     Train net output #0: loss = 0.00041293 (* 1 = 0.00041293 loss)
I0801 13:29:11.957875 12903 solver.cpp:680] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/initial/cifar10_jacintonet11v2_iter_64000.caffemodel
I0801 13:29:11.969826 12903 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-01_13-11-28/initial/cifar10_jacintonet11v2_iter_64000.solverstate
I0801 13:29:11.980089 12903 solver.cpp:527] Iteration 64000, loss = 0.000956977
I0801 13:29:11.980119 12903 solver.cpp:550] Iteration 64000, Testing net (#0)
I0801 13:29:12.787591 12903 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.916177
I0801 13:29:12.787618 12903 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.995294
I0801 13:29:12.787624 12903 solver.cpp:635]     Test net output #2: loss = 0.307259 (* 1 = 0.307259 loss)
I0801 13:29:12.790948 12832 parallel.cpp:73] Root Solver performance on device 0: 60.45 * 22 = 1330 img/sec (64000 itr in 1059 sec)
I0801 13:29:12.790963 12832 parallel.cpp:78]      Solver performance on device 1: 60.45 * 22 = 1330 img/sec (64000 itr in 1059 sec)
I0801 13:29:12.790967 12832 parallel.cpp:78]      Solver performance on device 2: 60.45 * 22 = 1330 img/sec (64000 itr in 1059 sec)
I0801 13:29:12.790969 12832 parallel.cpp:81] Overall multi-GPU performance: 3989.68 img/sec
I0801 13:29:12.890754 12832 caffe.cpp:247] Optimization Done in 17m 42s
