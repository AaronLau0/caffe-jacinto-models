I0628 18:56:54.560250  7562 caffe.cpp:608] This is NVCaffe 0.16.2 started at Wed Jun 28 18:56:53 2017
I0628 18:56:54.560612  7562 caffe.cpp:611] CuDNN version: 6.0.21
I0628 18:56:54.560632  7562 caffe.cpp:612] CuBLAS version: 8000
I0628 18:56:54.560642  7562 caffe.cpp:613] CUDA version: 8000
I0628 18:56:54.560652  7562 caffe.cpp:614] CUDA driver version: 8000
I0628 18:56:54.807449  7562 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0628 18:56:54.807942  7562 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8277393408, dev_info[0]: total=8506769408 free=8277393408
I0628 18:56:54.808387  7562 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8277393408, dev_info[1]: total=8508145664 free=8379236352
I0628 18:56:54.808394  7562 caffe.cpp:208] Using GPUs 0, 1
I0628 18:56:54.808652  7562 caffe.cpp:213] GPU 0: GeForce GTX 1080
I0628 18:56:54.808908  7562 caffe.cpp:213] GPU 1: GeForce GTX 1080
I0628 18:56:54.823622  7562 solver.cpp:42] Solver data type: FLOAT
I0628 18:56:54.823729  7562 solver.cpp:45] Initializing solver from parameters: 
train_net: "training/cifar10_jacintonet11v2_2017-06-28_18-56-45/initial/train.prototxt"
test_net: "training/cifar10_jacintonet11v2_2017-06-28_18-56-45/initial/test.prototxt"
test_iter: 200
test_interval: 1000
base_lr: 0.1
display: 100
max_iter: 64000
lr_policy: "poly"
gamma: 0.1
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 10000
snapshot_prefix: "training/cifar10_jacintonet11v2_2017-06-28_18-56-45/initial/cifar10_jacintonet11v2"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
snapshot_after_train: true
test_initialization: true
iter_size: 1
type: "SGD"
I0628 18:56:54.849927  7562 solver.cpp:77] Creating training net from train_net file: training/cifar10_jacintonet11v2_2017-06-28_18-56-45/initial/train.prototxt
I0628 18:56:54.852391  7562 net.cpp:442] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top1
I0628 18:56:54.852425  7562 net.cpp:442] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top5
I0628 18:56:54.853091  7562 net.cpp:77] Initializing net from parameters: 
name: "jacintonet11v2_train"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: true
    crop_size: 32
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/cifar10_train_lmdb"
    batch_size: 32
    backend: LMDB
    threads: 1
    parser_threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc10"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc10"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
I0628 18:56:54.853525  7562 net.cpp:108] Using FLOAT as default forward math type
I0628 18:56:54.853585  7562 net.cpp:114] Using FLOAT as default backward math type
I0628 18:56:54.853600  7562 layer_factory.hpp:136] Creating layer 'data' of type 'Data'
I0628 18:56:54.853613  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:54.858359  7562 net.cpp:183] Created Layer data (0)
I0628 18:56:54.858391  7562 net.cpp:529] data -> data
I0628 18:56:54.858417  7562 net.cpp:529] data -> label
I0628 18:56:54.858469  7562 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 32
I0628 18:56:54.858508  7562 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0628 18:56:54.893507  7613 db_lmdb.cpp:35] Opened lmdb ./data/cifar10_train_lmdb
I0628 18:56:54.911458  7562 data_layer.cpp:188] ReshapePrefetch 32, 3, 32, 32
I0628 18:56:54.911697  7562 data_layer.cpp:206] Output data size: 32, 3, 32, 32
I0628 18:56:54.911722  7562 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0628 18:56:54.911837  7562 net.cpp:244] Setting up data
I0628 18:56:54.911880  7562 net.cpp:251] TRAIN Top shape for layer 0 'data' 32 3 32 32 (98304)
I0628 18:56:54.911906  7562 net.cpp:251] TRAIN Top shape for layer 0 'data' 32 (32)
I0628 18:56:54.911929  7562 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0628 18:56:54.911947  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:54.912303  7562 net.cpp:183] Created Layer data/bias (1)
I0628 18:56:54.912329  7562 net.cpp:560] data/bias <- data
I0628 18:56:54.912354  7562 net.cpp:529] data/bias -> data/bias
I0628 18:56:54.919833  7562 net.cpp:244] Setting up data/bias
I0628 18:56:54.919883  7562 net.cpp:251] TRAIN Top shape for layer 1 'data/bias' 32 3 32 32 (98304)
I0628 18:56:54.919914  7562 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0628 18:56:54.919929  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:54.919977  7562 net.cpp:183] Created Layer conv1a (2)
I0628 18:56:54.919994  7562 net.cpp:560] conv1a <- data/bias
I0628 18:56:54.920008  7562 net.cpp:529] conv1a -> conv1a
I0628 18:56:55.692991  7562 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.01G/1 1 0 0  (limit 8.15G, req 0G)
I0628 18:56:55.693027  7562 net.cpp:244] Setting up conv1a
I0628 18:56:55.693035  7562 net.cpp:251] TRAIN Top shape for layer 2 'conv1a' 32 32 32 32 (1048576)
I0628 18:56:55.693044  7562 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0628 18:56:55.693049  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.693059  7562 net.cpp:183] Created Layer conv1a/bn (3)
I0628 18:56:55.693063  7562 net.cpp:560] conv1a/bn <- conv1a
I0628 18:56:55.693068  7562 net.cpp:512] conv1a/bn -> conv1a (in-place)
I0628 18:56:55.694069  7562 net.cpp:244] Setting up conv1a/bn
I0628 18:56:55.694077  7562 net.cpp:251] TRAIN Top shape for layer 3 'conv1a/bn' 32 32 32 32 (1048576)
I0628 18:56:55.694085  7562 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0628 18:56:55.694088  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.694093  7562 net.cpp:183] Created Layer conv1a/relu (4)
I0628 18:56:55.694095  7562 net.cpp:560] conv1a/relu <- conv1a
I0628 18:56:55.694098  7562 net.cpp:512] conv1a/relu -> conv1a (in-place)
I0628 18:56:55.694650  7562 net.cpp:244] Setting up conv1a/relu
I0628 18:56:55.694655  7562 net.cpp:251] TRAIN Top shape for layer 4 'conv1a/relu' 32 32 32 32 (1048576)
I0628 18:56:55.694658  7562 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0628 18:56:55.694660  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.694672  7562 net.cpp:183] Created Layer conv1b (5)
I0628 18:56:55.694674  7562 net.cpp:560] conv1b <- conv1a
I0628 18:56:55.694677  7562 net.cpp:529] conv1b -> conv1b
I0628 18:56:55.702595  7562 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 8.13G, req 0G)
I0628 18:56:55.702610  7562 net.cpp:244] Setting up conv1b
I0628 18:56:55.702615  7562 net.cpp:251] TRAIN Top shape for layer 5 'conv1b' 32 32 32 32 (1048576)
I0628 18:56:55.702621  7562 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0628 18:56:55.702623  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.702628  7562 net.cpp:183] Created Layer conv1b/bn (6)
I0628 18:56:55.702630  7562 net.cpp:560] conv1b/bn <- conv1b
I0628 18:56:55.702632  7562 net.cpp:512] conv1b/bn -> conv1b (in-place)
I0628 18:56:55.703147  7562 net.cpp:244] Setting up conv1b/bn
I0628 18:56:55.703155  7562 net.cpp:251] TRAIN Top shape for layer 6 'conv1b/bn' 32 32 32 32 (1048576)
I0628 18:56:55.703161  7562 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0628 18:56:55.703171  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.703174  7562 net.cpp:183] Created Layer conv1b/relu (7)
I0628 18:56:55.703176  7562 net.cpp:560] conv1b/relu <- conv1b
I0628 18:56:55.703181  7562 net.cpp:512] conv1b/relu -> conv1b (in-place)
I0628 18:56:55.703183  7562 net.cpp:244] Setting up conv1b/relu
I0628 18:56:55.703186  7562 net.cpp:251] TRAIN Top shape for layer 7 'conv1b/relu' 32 32 32 32 (1048576)
I0628 18:56:55.703188  7562 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0628 18:56:55.703191  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.703204  7562 net.cpp:183] Created Layer pool1 (8)
I0628 18:56:55.703208  7562 net.cpp:560] pool1 <- conv1b
I0628 18:56:55.703212  7562 net.cpp:529] pool1 -> pool1
I0628 18:56:55.703276  7562 net.cpp:244] Setting up pool1
I0628 18:56:55.703284  7562 net.cpp:251] TRAIN Top shape for layer 8 'pool1' 32 32 32 32 (1048576)
I0628 18:56:55.703287  7562 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0628 18:56:55.703291  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.703301  7562 net.cpp:183] Created Layer res2a_branch2a (9)
I0628 18:56:55.703305  7562 net.cpp:560] res2a_branch2a <- pool1
I0628 18:56:55.703308  7562 net.cpp:529] res2a_branch2a -> res2a_branch2a
I0628 18:56:55.716311  7562 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 1  (limit 8.11G, req 0G)
I0628 18:56:55.716329  7562 net.cpp:244] Setting up res2a_branch2a
I0628 18:56:55.716336  7562 net.cpp:251] TRAIN Top shape for layer 9 'res2a_branch2a' 32 64 32 32 (2097152)
I0628 18:56:55.716346  7562 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0628 18:56:55.716351  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.716359  7562 net.cpp:183] Created Layer res2a_branch2a/bn (10)
I0628 18:56:55.716362  7562 net.cpp:560] res2a_branch2a/bn <- res2a_branch2a
I0628 18:56:55.716367  7562 net.cpp:512] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0628 18:56:55.716892  7562 net.cpp:244] Setting up res2a_branch2a/bn
I0628 18:56:55.716900  7562 net.cpp:251] TRAIN Top shape for layer 10 'res2a_branch2a/bn' 32 64 32 32 (2097152)
I0628 18:56:55.716909  7562 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0628 18:56:55.716912  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.716917  7562 net.cpp:183] Created Layer res2a_branch2a/relu (11)
I0628 18:56:55.716922  7562 net.cpp:560] res2a_branch2a/relu <- res2a_branch2a
I0628 18:56:55.716925  7562 net.cpp:512] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0628 18:56:55.716930  7562 net.cpp:244] Setting up res2a_branch2a/relu
I0628 18:56:55.716935  7562 net.cpp:251] TRAIN Top shape for layer 11 'res2a_branch2a/relu' 32 64 32 32 (2097152)
I0628 18:56:55.716939  7562 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0628 18:56:55.716943  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.716951  7562 net.cpp:183] Created Layer res2a_branch2b (12)
I0628 18:56:55.716955  7562 net.cpp:560] res2a_branch2b <- res2a_branch2a
I0628 18:56:55.716958  7562 net.cpp:529] res2a_branch2b -> res2a_branch2b
I0628 18:56:55.722749  7562 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 8.09G, req 0G)
I0628 18:56:55.722776  7562 net.cpp:244] Setting up res2a_branch2b
I0628 18:56:55.722784  7562 net.cpp:251] TRAIN Top shape for layer 12 'res2a_branch2b' 32 64 32 32 (2097152)
I0628 18:56:55.722793  7562 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0628 18:56:55.722798  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.722818  7562 net.cpp:183] Created Layer res2a_branch2b/bn (13)
I0628 18:56:55.722825  7562 net.cpp:560] res2a_branch2b/bn <- res2a_branch2b
I0628 18:56:55.722831  7562 net.cpp:512] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0628 18:56:55.723387  7562 net.cpp:244] Setting up res2a_branch2b/bn
I0628 18:56:55.723394  7562 net.cpp:251] TRAIN Top shape for layer 13 'res2a_branch2b/bn' 32 64 32 32 (2097152)
I0628 18:56:55.723403  7562 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0628 18:56:55.723407  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.723413  7562 net.cpp:183] Created Layer res2a_branch2b/relu (14)
I0628 18:56:55.723417  7562 net.cpp:560] res2a_branch2b/relu <- res2a_branch2b
I0628 18:56:55.723420  7562 net.cpp:512] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0628 18:56:55.723428  7562 net.cpp:244] Setting up res2a_branch2b/relu
I0628 18:56:55.723433  7562 net.cpp:251] TRAIN Top shape for layer 14 'res2a_branch2b/relu' 32 64 32 32 (2097152)
I0628 18:56:55.723436  7562 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0628 18:56:55.723440  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.723446  7562 net.cpp:183] Created Layer pool2 (15)
I0628 18:56:55.723450  7562 net.cpp:560] pool2 <- res2a_branch2b
I0628 18:56:55.723454  7562 net.cpp:529] pool2 -> pool2
I0628 18:56:55.723505  7562 net.cpp:244] Setting up pool2
I0628 18:56:55.723510  7562 net.cpp:251] TRAIN Top shape for layer 15 'pool2' 32 64 16 16 (524288)
I0628 18:56:55.723515  7562 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0628 18:56:55.723520  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.723529  7562 net.cpp:183] Created Layer res3a_branch2a (16)
I0628 18:56:55.723532  7562 net.cpp:560] res3a_branch2a <- pool2
I0628 18:56:55.723536  7562 net.cpp:529] res3a_branch2a -> res3a_branch2a
I0628 18:56:55.735329  7562 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 8.08G, req 0.02G)
I0628 18:56:55.735349  7562 net.cpp:244] Setting up res3a_branch2a
I0628 18:56:55.735357  7562 net.cpp:251] TRAIN Top shape for layer 16 'res3a_branch2a' 32 128 16 16 (1048576)
I0628 18:56:55.735365  7562 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0628 18:56:55.735370  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.735379  7562 net.cpp:183] Created Layer res3a_branch2a/bn (17)
I0628 18:56:55.735383  7562 net.cpp:560] res3a_branch2a/bn <- res3a_branch2a
I0628 18:56:55.735388  7562 net.cpp:512] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0628 18:56:55.735903  7562 net.cpp:244] Setting up res3a_branch2a/bn
I0628 18:56:55.735910  7562 net.cpp:251] TRAIN Top shape for layer 17 'res3a_branch2a/bn' 32 128 16 16 (1048576)
I0628 18:56:55.735924  7562 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0628 18:56:55.735927  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.735932  7562 net.cpp:183] Created Layer res3a_branch2a/relu (18)
I0628 18:56:55.735936  7562 net.cpp:560] res3a_branch2a/relu <- res3a_branch2a
I0628 18:56:55.735940  7562 net.cpp:512] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0628 18:56:55.735946  7562 net.cpp:244] Setting up res3a_branch2a/relu
I0628 18:56:55.735951  7562 net.cpp:251] TRAIN Top shape for layer 18 'res3a_branch2a/relu' 32 128 16 16 (1048576)
I0628 18:56:55.735955  7562 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0628 18:56:55.735960  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.735970  7562 net.cpp:183] Created Layer res3a_branch2b (19)
I0628 18:56:55.735972  7562 net.cpp:560] res3a_branch2b <- res3a_branch2a
I0628 18:56:55.735976  7562 net.cpp:529] res3a_branch2b -> res3a_branch2b
I0628 18:56:55.740900  7562 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 8.07G, req 0.02G)
I0628 18:56:55.740916  7562 net.cpp:244] Setting up res3a_branch2b
I0628 18:56:55.740924  7562 net.cpp:251] TRAIN Top shape for layer 19 'res3a_branch2b' 32 128 16 16 (1048576)
I0628 18:56:55.740931  7562 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0628 18:56:55.740936  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.740943  7562 net.cpp:183] Created Layer res3a_branch2b/bn (20)
I0628 18:56:55.740947  7562 net.cpp:560] res3a_branch2b/bn <- res3a_branch2b
I0628 18:56:55.740950  7562 net.cpp:512] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0628 18:56:55.741466  7562 net.cpp:244] Setting up res3a_branch2b/bn
I0628 18:56:55.741473  7562 net.cpp:251] TRAIN Top shape for layer 20 'res3a_branch2b/bn' 32 128 16 16 (1048576)
I0628 18:56:55.741482  7562 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0628 18:56:55.741485  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.741490  7562 net.cpp:183] Created Layer res3a_branch2b/relu (21)
I0628 18:56:55.741494  7562 net.cpp:560] res3a_branch2b/relu <- res3a_branch2b
I0628 18:56:55.741497  7562 net.cpp:512] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0628 18:56:55.741503  7562 net.cpp:244] Setting up res3a_branch2b/relu
I0628 18:56:55.741508  7562 net.cpp:251] TRAIN Top shape for layer 21 'res3a_branch2b/relu' 32 128 16 16 (1048576)
I0628 18:56:55.741513  7562 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0628 18:56:55.741518  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.741523  7562 net.cpp:183] Created Layer pool3 (22)
I0628 18:56:55.741526  7562 net.cpp:560] pool3 <- res3a_branch2b
I0628 18:56:55.741530  7562 net.cpp:529] pool3 -> pool3
I0628 18:56:55.741586  7562 net.cpp:244] Setting up pool3
I0628 18:56:55.741592  7562 net.cpp:251] TRAIN Top shape for layer 22 'pool3' 32 128 16 16 (1048576)
I0628 18:56:55.741597  7562 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0628 18:56:55.741601  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.741610  7562 net.cpp:183] Created Layer res4a_branch2a (23)
I0628 18:56:55.741613  7562 net.cpp:560] res4a_branch2a <- pool3
I0628 18:56:55.741616  7562 net.cpp:529] res4a_branch2a -> res4a_branch2a
I0628 18:56:55.764475  7562 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 8.04G, req 0.02G)
I0628 18:56:55.764503  7562 net.cpp:244] Setting up res4a_branch2a
I0628 18:56:55.764513  7562 net.cpp:251] TRAIN Top shape for layer 23 'res4a_branch2a' 32 256 16 16 (2097152)
I0628 18:56:55.764524  7562 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0628 18:56:55.764529  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.764541  7562 net.cpp:183] Created Layer res4a_branch2a/bn (24)
I0628 18:56:55.764545  7562 net.cpp:560] res4a_branch2a/bn <- res4a_branch2a
I0628 18:56:55.764550  7562 net.cpp:512] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0628 18:56:55.765112  7562 net.cpp:244] Setting up res4a_branch2a/bn
I0628 18:56:55.765120  7562 net.cpp:251] TRAIN Top shape for layer 24 'res4a_branch2a/bn' 32 256 16 16 (2097152)
I0628 18:56:55.765130  7562 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0628 18:56:55.765133  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.765138  7562 net.cpp:183] Created Layer res4a_branch2a/relu (25)
I0628 18:56:55.765142  7562 net.cpp:560] res4a_branch2a/relu <- res4a_branch2a
I0628 18:56:55.765146  7562 net.cpp:512] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0628 18:56:55.765161  7562 net.cpp:244] Setting up res4a_branch2a/relu
I0628 18:56:55.765166  7562 net.cpp:251] TRAIN Top shape for layer 25 'res4a_branch2a/relu' 32 256 16 16 (2097152)
I0628 18:56:55.765171  7562 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0628 18:56:55.765174  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.765184  7562 net.cpp:183] Created Layer res4a_branch2b (26)
I0628 18:56:55.765187  7562 net.cpp:560] res4a_branch2b <- res4a_branch2a
I0628 18:56:55.765192  7562 net.cpp:529] res4a_branch2b -> res4a_branch2b
I0628 18:56:55.775107  7562 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 8.02G, req 0.02G)
I0628 18:56:55.775125  7562 net.cpp:244] Setting up res4a_branch2b
I0628 18:56:55.775132  7562 net.cpp:251] TRAIN Top shape for layer 26 'res4a_branch2b' 32 256 16 16 (2097152)
I0628 18:56:55.775140  7562 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0628 18:56:55.775143  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.775151  7562 net.cpp:183] Created Layer res4a_branch2b/bn (27)
I0628 18:56:55.775154  7562 net.cpp:560] res4a_branch2b/bn <- res4a_branch2b
I0628 18:56:55.775158  7562 net.cpp:512] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0628 18:56:55.775673  7562 net.cpp:244] Setting up res4a_branch2b/bn
I0628 18:56:55.775681  7562 net.cpp:251] TRAIN Top shape for layer 27 'res4a_branch2b/bn' 32 256 16 16 (2097152)
I0628 18:56:55.775689  7562 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0628 18:56:55.775693  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.775698  7562 net.cpp:183] Created Layer res4a_branch2b/relu (28)
I0628 18:56:55.775702  7562 net.cpp:560] res4a_branch2b/relu <- res4a_branch2b
I0628 18:56:55.775707  7562 net.cpp:512] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0628 18:56:55.775712  7562 net.cpp:244] Setting up res4a_branch2b/relu
I0628 18:56:55.775717  7562 net.cpp:251] TRAIN Top shape for layer 28 'res4a_branch2b/relu' 32 256 16 16 (2097152)
I0628 18:56:55.775720  7562 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0628 18:56:55.775724  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.775730  7562 net.cpp:183] Created Layer pool4 (29)
I0628 18:56:55.775733  7562 net.cpp:560] pool4 <- res4a_branch2b
I0628 18:56:55.775738  7562 net.cpp:529] pool4 -> pool4
I0628 18:56:55.775784  7562 net.cpp:244] Setting up pool4
I0628 18:56:55.775790  7562 net.cpp:251] TRAIN Top shape for layer 29 'pool4' 32 256 8 8 (524288)
I0628 18:56:55.775794  7562 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0628 18:56:55.775799  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.775807  7562 net.cpp:183] Created Layer res5a_branch2a (30)
I0628 18:56:55.775810  7562 net.cpp:560] res5a_branch2a <- pool4
I0628 18:56:55.775815  7562 net.cpp:529] res5a_branch2a -> res5a_branch2a
I0628 18:56:55.821928  7562 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 1  (limit 8G, req 0.02G)
I0628 18:56:55.821954  7562 net.cpp:244] Setting up res5a_branch2a
I0628 18:56:55.821964  7562 net.cpp:251] TRAIN Top shape for layer 30 'res5a_branch2a' 32 512 8 8 (1048576)
I0628 18:56:55.821974  7562 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0628 18:56:55.821979  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.821988  7562 net.cpp:183] Created Layer res5a_branch2a/bn (31)
I0628 18:56:55.821992  7562 net.cpp:560] res5a_branch2a/bn <- res5a_branch2a
I0628 18:56:55.821997  7562 net.cpp:512] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0628 18:56:55.822541  7562 net.cpp:244] Setting up res5a_branch2a/bn
I0628 18:56:55.822556  7562 net.cpp:251] TRAIN Top shape for layer 31 'res5a_branch2a/bn' 32 512 8 8 (1048576)
I0628 18:56:55.822566  7562 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0628 18:56:55.822571  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.822576  7562 net.cpp:183] Created Layer res5a_branch2a/relu (32)
I0628 18:56:55.822580  7562 net.cpp:560] res5a_branch2a/relu <- res5a_branch2a
I0628 18:56:55.822584  7562 net.cpp:512] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0628 18:56:55.822590  7562 net.cpp:244] Setting up res5a_branch2a/relu
I0628 18:56:55.822595  7562 net.cpp:251] TRAIN Top shape for layer 32 'res5a_branch2a/relu' 32 512 8 8 (1048576)
I0628 18:56:55.822599  7562 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0628 18:56:55.822603  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.822613  7562 net.cpp:183] Created Layer res5a_branch2b (33)
I0628 18:56:55.822615  7562 net.cpp:560] res5a_branch2b <- res5a_branch2a
I0628 18:56:55.822619  7562 net.cpp:529] res5a_branch2b -> res5a_branch2b
I0628 18:56:55.842761  7562 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 5 5  (limit 7.98G, req 0.02G)
I0628 18:56:55.842782  7562 net.cpp:244] Setting up res5a_branch2b
I0628 18:56:55.842789  7562 net.cpp:251] TRAIN Top shape for layer 33 'res5a_branch2b' 32 512 8 8 (1048576)
I0628 18:56:55.842802  7562 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0628 18:56:55.842805  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.842815  7562 net.cpp:183] Created Layer res5a_branch2b/bn (34)
I0628 18:56:55.842819  7562 net.cpp:560] res5a_branch2b/bn <- res5a_branch2b
I0628 18:56:55.842824  7562 net.cpp:512] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0628 18:56:55.843360  7562 net.cpp:244] Setting up res5a_branch2b/bn
I0628 18:56:55.843369  7562 net.cpp:251] TRAIN Top shape for layer 34 'res5a_branch2b/bn' 32 512 8 8 (1048576)
I0628 18:56:55.843376  7562 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0628 18:56:55.843380  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.843385  7562 net.cpp:183] Created Layer res5a_branch2b/relu (35)
I0628 18:56:55.843389  7562 net.cpp:560] res5a_branch2b/relu <- res5a_branch2b
I0628 18:56:55.843394  7562 net.cpp:512] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0628 18:56:55.843400  7562 net.cpp:244] Setting up res5a_branch2b/relu
I0628 18:56:55.843403  7562 net.cpp:251] TRAIN Top shape for layer 35 'res5a_branch2b/relu' 32 512 8 8 (1048576)
I0628 18:56:55.843407  7562 layer_factory.hpp:136] Creating layer 'pool5' of type 'Pooling'
I0628 18:56:55.843412  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.843418  7562 net.cpp:183] Created Layer pool5 (36)
I0628 18:56:55.843421  7562 net.cpp:560] pool5 <- res5a_branch2b
I0628 18:56:55.843425  7562 net.cpp:529] pool5 -> pool5
I0628 18:56:55.843451  7562 net.cpp:244] Setting up pool5
I0628 18:56:55.843456  7562 net.cpp:251] TRAIN Top shape for layer 36 'pool5' 32 512 1 1 (16384)
I0628 18:56:55.843461  7562 layer_factory.hpp:136] Creating layer 'fc10' of type 'InnerProduct'
I0628 18:56:55.843464  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.843472  7562 net.cpp:183] Created Layer fc10 (37)
I0628 18:56:55.843477  7562 net.cpp:560] fc10 <- pool5
I0628 18:56:55.843479  7562 net.cpp:529] fc10 -> fc10
I0628 18:56:55.843708  7562 net.cpp:244] Setting up fc10
I0628 18:56:55.843715  7562 net.cpp:251] TRAIN Top shape for layer 37 'fc10' 32 10 (320)
I0628 18:56:55.843722  7562 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0628 18:56:55.843727  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.843992  7562 net.cpp:183] Created Layer loss (38)
I0628 18:56:55.843998  7562 net.cpp:560] loss <- fc10
I0628 18:56:55.844002  7562 net.cpp:560] loss <- label
I0628 18:56:55.844008  7562 net.cpp:529] loss -> loss
I0628 18:56:55.844141  7562 net.cpp:244] Setting up loss
I0628 18:56:55.844147  7562 net.cpp:251] TRAIN Top shape for layer 38 'loss' (1)
I0628 18:56:55.844151  7562 net.cpp:255]     with loss weight 1
I0628 18:56:55.844156  7562 net.cpp:322] loss needs backward computation.
I0628 18:56:55.844161  7562 net.cpp:322] fc10 needs backward computation.
I0628 18:56:55.844164  7562 net.cpp:322] pool5 needs backward computation.
I0628 18:56:55.844167  7562 net.cpp:322] res5a_branch2b/relu needs backward computation.
I0628 18:56:55.844171  7562 net.cpp:322] res5a_branch2b/bn needs backward computation.
I0628 18:56:55.844174  7562 net.cpp:322] res5a_branch2b needs backward computation.
I0628 18:56:55.844178  7562 net.cpp:322] res5a_branch2a/relu needs backward computation.
I0628 18:56:55.844182  7562 net.cpp:322] res5a_branch2a/bn needs backward computation.
I0628 18:56:55.844187  7562 net.cpp:322] res5a_branch2a needs backward computation.
I0628 18:56:55.844190  7562 net.cpp:322] pool4 needs backward computation.
I0628 18:56:55.844194  7562 net.cpp:322] res4a_branch2b/relu needs backward computation.
I0628 18:56:55.844198  7562 net.cpp:322] res4a_branch2b/bn needs backward computation.
I0628 18:56:55.844202  7562 net.cpp:322] res4a_branch2b needs backward computation.
I0628 18:56:55.844207  7562 net.cpp:322] res4a_branch2a/relu needs backward computation.
I0628 18:56:55.844210  7562 net.cpp:322] res4a_branch2a/bn needs backward computation.
I0628 18:56:55.844214  7562 net.cpp:322] res4a_branch2a needs backward computation.
I0628 18:56:55.844218  7562 net.cpp:322] pool3 needs backward computation.
I0628 18:56:55.844221  7562 net.cpp:322] res3a_branch2b/relu needs backward computation.
I0628 18:56:55.844225  7562 net.cpp:322] res3a_branch2b/bn needs backward computation.
I0628 18:56:55.844229  7562 net.cpp:322] res3a_branch2b needs backward computation.
I0628 18:56:55.844233  7562 net.cpp:322] res3a_branch2a/relu needs backward computation.
I0628 18:56:55.844235  7562 net.cpp:322] res3a_branch2a/bn needs backward computation.
I0628 18:56:55.844239  7562 net.cpp:322] res3a_branch2a needs backward computation.
I0628 18:56:55.844244  7562 net.cpp:322] pool2 needs backward computation.
I0628 18:56:55.844247  7562 net.cpp:322] res2a_branch2b/relu needs backward computation.
I0628 18:56:55.844251  7562 net.cpp:322] res2a_branch2b/bn needs backward computation.
I0628 18:56:55.844254  7562 net.cpp:322] res2a_branch2b needs backward computation.
I0628 18:56:55.844259  7562 net.cpp:322] res2a_branch2a/relu needs backward computation.
I0628 18:56:55.844262  7562 net.cpp:322] res2a_branch2a/bn needs backward computation.
I0628 18:56:55.844265  7562 net.cpp:322] res2a_branch2a needs backward computation.
I0628 18:56:55.844269  7562 net.cpp:322] pool1 needs backward computation.
I0628 18:56:55.844272  7562 net.cpp:322] conv1b/relu needs backward computation.
I0628 18:56:55.844276  7562 net.cpp:322] conv1b/bn needs backward computation.
I0628 18:56:55.844280  7562 net.cpp:322] conv1b needs backward computation.
I0628 18:56:55.844285  7562 net.cpp:322] conv1a/relu needs backward computation.
I0628 18:56:55.844288  7562 net.cpp:322] conv1a/bn needs backward computation.
I0628 18:56:55.844291  7562 net.cpp:322] conv1a needs backward computation.
I0628 18:56:55.844296  7562 net.cpp:324] data/bias does not need backward computation.
I0628 18:56:55.844300  7562 net.cpp:324] data does not need backward computation.
I0628 18:56:55.844305  7562 net.cpp:366] This network produces output loss
I0628 18:56:55.844333  7562 net.cpp:388] Top memory (TRAIN) required for data: 176160768 diff: 176160776
I0628 18:56:55.844336  7562 net.cpp:391] Bottom memory (TRAIN) required for data: 176160768 diff: 176160768
I0628 18:56:55.844339  7562 net.cpp:394] Shared (in-place) memory (TRAIN) by data: 117440512 diff: 117440512
I0628 18:56:55.844347  7562 net.cpp:397] Parameters memory (TRAIN) required for data: 9450960 diff: 9450960
I0628 18:56:55.844352  7562 net.cpp:400] Parameters shared memory (TRAIN) by data: 0 diff: 0
I0628 18:56:55.844354  7562 net.cpp:406] Network initialization done.
I0628 18:56:55.844703  7562 solver.cpp:176] Creating test net (#0) specified by test_net file: training/cifar10_jacintonet11v2_2017-06-28_18-56-45/initial/test.prototxt
I0628 18:56:55.844857  7562 net.cpp:77] Initializing net from parameters: 
name: "jacintonet11v2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: false
    crop_size: 32
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/cifar10_test_lmdb"
    batch_size: 25
    backend: LMDB
    threads: 1
    parser_threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc10"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc10"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "fc10"
  bottom: "label"
  top: "accuracy/top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "fc10"
  bottom: "label"
  top: "accuracy/top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0628 18:56:55.844946  7562 net.cpp:108] Using FLOAT as default forward math type
I0628 18:56:55.844951  7562 net.cpp:114] Using FLOAT as default backward math type
I0628 18:56:55.844954  7562 layer_factory.hpp:136] Creating layer 'data' of type 'Data'
I0628 18:56:55.844959  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.844970  7562 net.cpp:183] Created Layer data (0)
I0628 18:56:55.844974  7562 net.cpp:529] data -> data
I0628 18:56:55.844980  7562 net.cpp:529] data -> label
I0628 18:56:55.844987  7562 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 25
I0628 18:56:55.844996  7562 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0628 18:56:55.864421  7626 db_lmdb.cpp:35] Opened lmdb ./data/cifar10_test_lmdb
I0628 18:56:55.867936  7562 data_layer.cpp:188] ReshapePrefetch 25, 3, 32, 32
I0628 18:56:55.868002  7562 data_layer.cpp:206] Output data size: 25, 3, 32, 32
I0628 18:56:55.868007  7562 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0628 18:56:55.868029  7562 net.cpp:244] Setting up data
I0628 18:56:55.868036  7562 net.cpp:251] TEST Top shape for layer 0 'data' 25 3 32 32 (76800)
I0628 18:56:55.868041  7562 net.cpp:251] TEST Top shape for layer 0 'data' 25 (25)
I0628 18:56:55.868046  7562 layer_factory.hpp:136] Creating layer 'label_data_1_split' of type 'Split'
I0628 18:56:55.868049  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.868057  7562 net.cpp:183] Created Layer label_data_1_split (1)
I0628 18:56:55.868062  7562 net.cpp:560] label_data_1_split <- label
I0628 18:56:55.868064  7562 net.cpp:529] label_data_1_split -> label_data_1_split_0
I0628 18:56:55.868068  7562 net.cpp:529] label_data_1_split -> label_data_1_split_1
I0628 18:56:55.868070  7562 net.cpp:529] label_data_1_split -> label_data_1_split_2
I0628 18:56:55.868118  7562 net.cpp:244] Setting up label_data_1_split
I0628 18:56:55.868121  7562 net.cpp:251] TEST Top shape for layer 1 'label_data_1_split' 25 (25)
I0628 18:56:55.868124  7562 net.cpp:251] TEST Top shape for layer 1 'label_data_1_split' 25 (25)
I0628 18:56:55.868126  7562 net.cpp:251] TEST Top shape for layer 1 'label_data_1_split' 25 (25)
I0628 18:56:55.868139  7562 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0628 18:56:55.868141  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.868147  7562 net.cpp:183] Created Layer data/bias (2)
I0628 18:56:55.868149  7562 net.cpp:560] data/bias <- data
I0628 18:56:55.868152  7562 net.cpp:529] data/bias -> data/bias
I0628 18:56:55.868289  7562 net.cpp:244] Setting up data/bias
I0628 18:56:55.868295  7562 net.cpp:251] TEST Top shape for layer 2 'data/bias' 25 3 32 32 (76800)
I0628 18:56:55.868301  7562 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0628 18:56:55.868304  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.868311  7562 net.cpp:183] Created Layer conv1a (3)
I0628 18:56:55.868314  7562 net.cpp:560] conv1a <- data/bias
I0628 18:56:55.868316  7562 net.cpp:529] conv1a -> conv1a
I0628 18:56:55.869148  7627 data_layer.cpp:188] ReshapePrefetch 25, 3, 32, 32
I0628 18:56:55.869156  7627 data_layer.cpp:206] Output data size: 25, 3, 32, 32
I0628 18:56:55.870039  7627 data_layer.cpp:110] [0] Parser threads: 1
I0628 18:56:55.870048  7627 data_layer.cpp:112] [0] Transformer threads: 1
I0628 18:56:55.871743  7562 net.cpp:244] Setting up conv1a
I0628 18:56:55.871754  7562 net.cpp:251] TEST Top shape for layer 3 'conv1a' 25 32 32 32 (819200)
I0628 18:56:55.871762  7562 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0628 18:56:55.871764  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.871770  7562 net.cpp:183] Created Layer conv1a/bn (4)
I0628 18:56:55.871773  7562 net.cpp:560] conv1a/bn <- conv1a
I0628 18:56:55.871776  7562 net.cpp:512] conv1a/bn -> conv1a (in-place)
I0628 18:56:55.872804  7562 net.cpp:244] Setting up conv1a/bn
I0628 18:56:55.872814  7562 net.cpp:251] TEST Top shape for layer 4 'conv1a/bn' 25 32 32 32 (819200)
I0628 18:56:55.872822  7562 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0628 18:56:55.872824  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.872833  7562 net.cpp:183] Created Layer conv1a/relu (5)
I0628 18:56:55.872835  7562 net.cpp:560] conv1a/relu <- conv1a
I0628 18:56:55.872838  7562 net.cpp:512] conv1a/relu -> conv1a (in-place)
I0628 18:56:55.872843  7562 net.cpp:244] Setting up conv1a/relu
I0628 18:56:55.872845  7562 net.cpp:251] TEST Top shape for layer 5 'conv1a/relu' 25 32 32 32 (819200)
I0628 18:56:55.872849  7562 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0628 18:56:55.872853  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.872860  7562 net.cpp:183] Created Layer conv1b (6)
I0628 18:56:55.872864  7562 net.cpp:560] conv1b <- conv1a
I0628 18:56:55.872865  7562 net.cpp:529] conv1b -> conv1b
I0628 18:56:55.875077  7562 net.cpp:244] Setting up conv1b
I0628 18:56:55.875088  7562 net.cpp:251] TEST Top shape for layer 6 'conv1b' 25 32 32 32 (819200)
I0628 18:56:55.875095  7562 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0628 18:56:55.875098  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.875103  7562 net.cpp:183] Created Layer conv1b/bn (7)
I0628 18:56:55.875107  7562 net.cpp:560] conv1b/bn <- conv1b
I0628 18:56:55.875109  7562 net.cpp:512] conv1b/bn -> conv1b (in-place)
I0628 18:56:55.876184  7562 net.cpp:244] Setting up conv1b/bn
I0628 18:56:55.876194  7562 net.cpp:251] TEST Top shape for layer 7 'conv1b/bn' 25 32 32 32 (819200)
I0628 18:56:55.876201  7562 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0628 18:56:55.876205  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.876209  7562 net.cpp:183] Created Layer conv1b/relu (8)
I0628 18:56:55.876220  7562 net.cpp:560] conv1b/relu <- conv1b
I0628 18:56:55.876224  7562 net.cpp:512] conv1b/relu -> conv1b (in-place)
I0628 18:56:55.876229  7562 net.cpp:244] Setting up conv1b/relu
I0628 18:56:55.876231  7562 net.cpp:251] TEST Top shape for layer 8 'conv1b/relu' 25 32 32 32 (819200)
I0628 18:56:55.876235  7562 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0628 18:56:55.876237  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.876243  7562 net.cpp:183] Created Layer pool1 (9)
I0628 18:56:55.876247  7562 net.cpp:560] pool1 <- conv1b
I0628 18:56:55.876250  7562 net.cpp:529] pool1 -> pool1
I0628 18:56:55.876307  7562 net.cpp:244] Setting up pool1
I0628 18:56:55.876312  7562 net.cpp:251] TEST Top shape for layer 9 'pool1' 25 32 32 32 (819200)
I0628 18:56:55.876314  7562 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0628 18:56:55.876317  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.876329  7562 net.cpp:183] Created Layer res2a_branch2a (10)
I0628 18:56:55.876332  7562 net.cpp:560] res2a_branch2a <- pool1
I0628 18:56:55.876335  7562 net.cpp:529] res2a_branch2a -> res2a_branch2a
I0628 18:56:55.879525  7562 net.cpp:244] Setting up res2a_branch2a
I0628 18:56:55.879537  7562 net.cpp:251] TEST Top shape for layer 10 'res2a_branch2a' 25 64 32 32 (1638400)
I0628 18:56:55.879545  7562 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0628 18:56:55.879549  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.879554  7562 net.cpp:183] Created Layer res2a_branch2a/bn (11)
I0628 18:56:55.879557  7562 net.cpp:560] res2a_branch2a/bn <- res2a_branch2a
I0628 18:56:55.879560  7562 net.cpp:512] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0628 18:56:55.880750  7562 net.cpp:244] Setting up res2a_branch2a/bn
I0628 18:56:55.880761  7562 net.cpp:251] TEST Top shape for layer 11 'res2a_branch2a/bn' 25 64 32 32 (1638400)
I0628 18:56:55.880769  7562 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0628 18:56:55.880772  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.880776  7562 net.cpp:183] Created Layer res2a_branch2a/relu (12)
I0628 18:56:55.880779  7562 net.cpp:560] res2a_branch2a/relu <- res2a_branch2a
I0628 18:56:55.880781  7562 net.cpp:512] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0628 18:56:55.880786  7562 net.cpp:244] Setting up res2a_branch2a/relu
I0628 18:56:55.880790  7562 net.cpp:251] TEST Top shape for layer 12 'res2a_branch2a/relu' 25 64 32 32 (1638400)
I0628 18:56:55.880794  7562 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0628 18:56:55.880795  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.880808  7562 net.cpp:183] Created Layer res2a_branch2b (13)
I0628 18:56:55.880812  7562 net.cpp:560] res2a_branch2b <- res2a_branch2a
I0628 18:56:55.880815  7562 net.cpp:529] res2a_branch2b -> res2a_branch2b
I0628 18:56:55.883154  7562 net.cpp:244] Setting up res2a_branch2b
I0628 18:56:55.883168  7562 net.cpp:251] TEST Top shape for layer 13 'res2a_branch2b' 25 64 32 32 (1638400)
I0628 18:56:55.883175  7562 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0628 18:56:55.883179  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.883191  7562 net.cpp:183] Created Layer res2a_branch2b/bn (14)
I0628 18:56:55.883194  7562 net.cpp:560] res2a_branch2b/bn <- res2a_branch2b
I0628 18:56:55.883198  7562 net.cpp:512] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0628 18:56:55.884416  7562 net.cpp:244] Setting up res2a_branch2b/bn
I0628 18:56:55.884428  7562 net.cpp:251] TEST Top shape for layer 14 'res2a_branch2b/bn' 25 64 32 32 (1638400)
I0628 18:56:55.884435  7562 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0628 18:56:55.884450  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.884455  7562 net.cpp:183] Created Layer res2a_branch2b/relu (15)
I0628 18:56:55.884459  7562 net.cpp:560] res2a_branch2b/relu <- res2a_branch2b
I0628 18:56:55.884461  7562 net.cpp:512] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0628 18:56:55.884466  7562 net.cpp:244] Setting up res2a_branch2b/relu
I0628 18:56:55.884470  7562 net.cpp:251] TEST Top shape for layer 15 'res2a_branch2b/relu' 25 64 32 32 (1638400)
I0628 18:56:55.884474  7562 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0628 18:56:55.884476  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.884481  7562 net.cpp:183] Created Layer pool2 (16)
I0628 18:56:55.884485  7562 net.cpp:560] pool2 <- res2a_branch2b
I0628 18:56:55.884487  7562 net.cpp:529] pool2 -> pool2
I0628 18:56:55.884563  7562 net.cpp:244] Setting up pool2
I0628 18:56:55.884569  7562 net.cpp:251] TEST Top shape for layer 16 'pool2' 25 64 16 16 (409600)
I0628 18:56:55.884572  7562 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0628 18:56:55.884575  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.884582  7562 net.cpp:183] Created Layer res3a_branch2a (17)
I0628 18:56:55.884585  7562 net.cpp:560] res3a_branch2a <- pool2
I0628 18:56:55.884588  7562 net.cpp:529] res3a_branch2a -> res3a_branch2a
I0628 18:56:55.889614  7562 net.cpp:244] Setting up res3a_branch2a
I0628 18:56:55.889626  7562 net.cpp:251] TEST Top shape for layer 17 'res3a_branch2a' 25 128 16 16 (819200)
I0628 18:56:55.889631  7562 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0628 18:56:55.889633  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.889638  7562 net.cpp:183] Created Layer res3a_branch2a/bn (18)
I0628 18:56:55.889641  7562 net.cpp:560] res3a_branch2a/bn <- res3a_branch2a
I0628 18:56:55.889643  7562 net.cpp:512] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0628 18:56:55.891186  7562 net.cpp:244] Setting up res3a_branch2a/bn
I0628 18:56:55.891196  7562 net.cpp:251] TEST Top shape for layer 18 'res3a_branch2a/bn' 25 128 16 16 (819200)
I0628 18:56:55.891204  7562 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0628 18:56:55.891207  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.891211  7562 net.cpp:183] Created Layer res3a_branch2a/relu (19)
I0628 18:56:55.891213  7562 net.cpp:560] res3a_branch2a/relu <- res3a_branch2a
I0628 18:56:55.891216  7562 net.cpp:512] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0628 18:56:55.891219  7562 net.cpp:244] Setting up res3a_branch2a/relu
I0628 18:56:55.891222  7562 net.cpp:251] TEST Top shape for layer 19 'res3a_branch2a/relu' 25 128 16 16 (819200)
I0628 18:56:55.891225  7562 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0628 18:56:55.891228  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.891238  7562 net.cpp:183] Created Layer res3a_branch2b (20)
I0628 18:56:55.891243  7562 net.cpp:560] res3a_branch2b <- res3a_branch2a
I0628 18:56:55.891247  7562 net.cpp:529] res3a_branch2b -> res3a_branch2b
I0628 18:56:55.893456  7562 net.cpp:244] Setting up res3a_branch2b
I0628 18:56:55.893466  7562 net.cpp:251] TEST Top shape for layer 20 'res3a_branch2b' 25 128 16 16 (819200)
I0628 18:56:55.893471  7562 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0628 18:56:55.893473  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.893478  7562 net.cpp:183] Created Layer res3a_branch2b/bn (21)
I0628 18:56:55.893481  7562 net.cpp:560] res3a_branch2b/bn <- res3a_branch2b
I0628 18:56:55.893483  7562 net.cpp:512] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0628 18:56:55.894455  7562 net.cpp:244] Setting up res3a_branch2b/bn
I0628 18:56:55.894465  7562 net.cpp:251] TEST Top shape for layer 21 'res3a_branch2b/bn' 25 128 16 16 (819200)
I0628 18:56:55.894471  7562 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0628 18:56:55.894474  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.894476  7562 net.cpp:183] Created Layer res3a_branch2b/relu (22)
I0628 18:56:55.894479  7562 net.cpp:560] res3a_branch2b/relu <- res3a_branch2b
I0628 18:56:55.894481  7562 net.cpp:512] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0628 18:56:55.894485  7562 net.cpp:244] Setting up res3a_branch2b/relu
I0628 18:56:55.894487  7562 net.cpp:251] TEST Top shape for layer 22 'res3a_branch2b/relu' 25 128 16 16 (819200)
I0628 18:56:55.894490  7562 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0628 18:56:55.894492  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.894496  7562 net.cpp:183] Created Layer pool3 (23)
I0628 18:56:55.894500  7562 net.cpp:560] pool3 <- res3a_branch2b
I0628 18:56:55.894505  7562 net.cpp:529] pool3 -> pool3
I0628 18:56:55.894560  7562 net.cpp:244] Setting up pool3
I0628 18:56:55.894567  7562 net.cpp:251] TEST Top shape for layer 23 'pool3' 25 128 16 16 (819200)
I0628 18:56:55.894568  7562 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0628 18:56:55.894572  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.894577  7562 net.cpp:183] Created Layer res4a_branch2a (24)
I0628 18:56:55.894578  7562 net.cpp:560] res4a_branch2a <- pool3
I0628 18:56:55.894582  7562 net.cpp:529] res4a_branch2a -> res4a_branch2a
I0628 18:56:55.905725  7562 net.cpp:244] Setting up res4a_branch2a
I0628 18:56:55.905735  7562 net.cpp:251] TEST Top shape for layer 24 'res4a_branch2a' 25 256 16 16 (1638400)
I0628 18:56:55.905740  7562 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0628 18:56:55.905743  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.905747  7562 net.cpp:183] Created Layer res4a_branch2a/bn (25)
I0628 18:56:55.905750  7562 net.cpp:560] res4a_branch2a/bn <- res4a_branch2a
I0628 18:56:55.905752  7562 net.cpp:512] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0628 18:56:55.906728  7562 net.cpp:244] Setting up res4a_branch2a/bn
I0628 18:56:55.906735  7562 net.cpp:251] TEST Top shape for layer 25 'res4a_branch2a/bn' 25 256 16 16 (1638400)
I0628 18:56:55.906743  7562 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0628 18:56:55.906744  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.906749  7562 net.cpp:183] Created Layer res4a_branch2a/relu (26)
I0628 18:56:55.906750  7562 net.cpp:560] res4a_branch2a/relu <- res4a_branch2a
I0628 18:56:55.906752  7562 net.cpp:512] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0628 18:56:55.906756  7562 net.cpp:244] Setting up res4a_branch2a/relu
I0628 18:56:55.906759  7562 net.cpp:251] TEST Top shape for layer 26 'res4a_branch2a/relu' 25 256 16 16 (1638400)
I0628 18:56:55.906761  7562 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0628 18:56:55.906764  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.906771  7562 net.cpp:183] Created Layer res4a_branch2b (27)
I0628 18:56:55.906775  7562 net.cpp:560] res4a_branch2b <- res4a_branch2a
I0628 18:56:55.906780  7562 net.cpp:529] res4a_branch2b -> res4a_branch2b
I0628 18:56:55.911975  7562 net.cpp:244] Setting up res4a_branch2b
I0628 18:56:55.911988  7562 net.cpp:251] TEST Top shape for layer 27 'res4a_branch2b' 25 256 16 16 (1638400)
I0628 18:56:55.911995  7562 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0628 18:56:55.911999  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.912014  7562 net.cpp:183] Created Layer res4a_branch2b/bn (28)
I0628 18:56:55.912019  7562 net.cpp:560] res4a_branch2b/bn <- res4a_branch2b
I0628 18:56:55.912024  7562 net.cpp:512] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0628 18:56:55.913183  7562 net.cpp:244] Setting up res4a_branch2b/bn
I0628 18:56:55.913193  7562 net.cpp:251] TEST Top shape for layer 28 'res4a_branch2b/bn' 25 256 16 16 (1638400)
I0628 18:56:55.913199  7562 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0628 18:56:55.913203  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.913206  7562 net.cpp:183] Created Layer res4a_branch2b/relu (29)
I0628 18:56:55.913208  7562 net.cpp:560] res4a_branch2b/relu <- res4a_branch2b
I0628 18:56:55.913211  7562 net.cpp:512] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0628 18:56:55.913215  7562 net.cpp:244] Setting up res4a_branch2b/relu
I0628 18:56:55.913218  7562 net.cpp:251] TEST Top shape for layer 29 'res4a_branch2b/relu' 25 256 16 16 (1638400)
I0628 18:56:55.913221  7562 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0628 18:56:55.913223  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.913228  7562 net.cpp:183] Created Layer pool4 (30)
I0628 18:56:55.913230  7562 net.cpp:560] pool4 <- res4a_branch2b
I0628 18:56:55.913233  7562 net.cpp:529] pool4 -> pool4
I0628 18:56:55.913285  7562 net.cpp:244] Setting up pool4
I0628 18:56:55.913290  7562 net.cpp:251] TEST Top shape for layer 30 'pool4' 25 256 8 8 (409600)
I0628 18:56:55.913292  7562 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0628 18:56:55.913295  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.913307  7562 net.cpp:183] Created Layer res5a_branch2a (31)
I0628 18:56:55.913310  7562 net.cpp:560] res5a_branch2a <- pool4
I0628 18:56:55.913312  7562 net.cpp:529] res5a_branch2a -> res5a_branch2a
I0628 18:56:55.944370  7562 net.cpp:244] Setting up res5a_branch2a
I0628 18:56:55.944391  7562 net.cpp:251] TEST Top shape for layer 31 'res5a_branch2a' 25 512 8 8 (819200)
I0628 18:56:55.944398  7562 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0628 18:56:55.944402  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.944412  7562 net.cpp:183] Created Layer res5a_branch2a/bn (32)
I0628 18:56:55.944416  7562 net.cpp:560] res5a_branch2a/bn <- res5a_branch2a
I0628 18:56:55.944418  7562 net.cpp:512] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0628 18:56:55.945488  7562 net.cpp:244] Setting up res5a_branch2a/bn
I0628 18:56:55.945497  7562 net.cpp:251] TEST Top shape for layer 32 'res5a_branch2a/bn' 25 512 8 8 (819200)
I0628 18:56:55.945503  7562 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0628 18:56:55.945507  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.945509  7562 net.cpp:183] Created Layer res5a_branch2a/relu (33)
I0628 18:56:55.945513  7562 net.cpp:560] res5a_branch2a/relu <- res5a_branch2a
I0628 18:56:55.945514  7562 net.cpp:512] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0628 18:56:55.945519  7562 net.cpp:244] Setting up res5a_branch2a/relu
I0628 18:56:55.945521  7562 net.cpp:251] TEST Top shape for layer 33 'res5a_branch2a/relu' 25 512 8 8 (819200)
I0628 18:56:55.945524  7562 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0628 18:56:55.945526  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.945533  7562 net.cpp:183] Created Layer res5a_branch2b (34)
I0628 18:56:55.945536  7562 net.cpp:560] res5a_branch2b <- res5a_branch2a
I0628 18:56:55.945538  7562 net.cpp:529] res5a_branch2b -> res5a_branch2b
I0628 18:56:55.961493  7562 net.cpp:244] Setting up res5a_branch2b
I0628 18:56:55.961519  7562 net.cpp:251] TEST Top shape for layer 34 'res5a_branch2b' 25 512 8 8 (819200)
I0628 18:56:55.961532  7562 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0628 18:56:55.961535  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.961542  7562 net.cpp:183] Created Layer res5a_branch2b/bn (35)
I0628 18:56:55.961545  7562 net.cpp:560] res5a_branch2b/bn <- res5a_branch2b
I0628 18:56:55.961557  7562 net.cpp:512] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0628 18:56:55.962556  7562 net.cpp:244] Setting up res5a_branch2b/bn
I0628 18:56:55.962564  7562 net.cpp:251] TEST Top shape for layer 35 'res5a_branch2b/bn' 25 512 8 8 (819200)
I0628 18:56:55.962571  7562 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0628 18:56:55.962574  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.962577  7562 net.cpp:183] Created Layer res5a_branch2b/relu (36)
I0628 18:56:55.962579  7562 net.cpp:560] res5a_branch2b/relu <- res5a_branch2b
I0628 18:56:55.962581  7562 net.cpp:512] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0628 18:56:55.962586  7562 net.cpp:244] Setting up res5a_branch2b/relu
I0628 18:56:55.962589  7562 net.cpp:251] TEST Top shape for layer 36 'res5a_branch2b/relu' 25 512 8 8 (819200)
I0628 18:56:55.962591  7562 layer_factory.hpp:136] Creating layer 'pool5' of type 'Pooling'
I0628 18:56:55.962594  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.962604  7562 net.cpp:183] Created Layer pool5 (37)
I0628 18:56:55.962606  7562 net.cpp:560] pool5 <- res5a_branch2b
I0628 18:56:55.962610  7562 net.cpp:529] pool5 -> pool5
I0628 18:56:55.962635  7562 net.cpp:244] Setting up pool5
I0628 18:56:55.962637  7562 net.cpp:251] TEST Top shape for layer 37 'pool5' 25 512 1 1 (12800)
I0628 18:56:55.962640  7562 layer_factory.hpp:136] Creating layer 'fc10' of type 'InnerProduct'
I0628 18:56:55.962642  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.962646  7562 net.cpp:183] Created Layer fc10 (38)
I0628 18:56:55.962648  7562 net.cpp:560] fc10 <- pool5
I0628 18:56:55.962651  7562 net.cpp:529] fc10 -> fc10
I0628 18:56:55.962893  7562 net.cpp:244] Setting up fc10
I0628 18:56:55.962899  7562 net.cpp:251] TEST Top shape for layer 38 'fc10' 25 10 (250)
I0628 18:56:55.962903  7562 layer_factory.hpp:136] Creating layer 'fc10_fc10_0_split' of type 'Split'
I0628 18:56:55.962906  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.962909  7562 net.cpp:183] Created Layer fc10_fc10_0_split (39)
I0628 18:56:55.962911  7562 net.cpp:560] fc10_fc10_0_split <- fc10
I0628 18:56:55.962913  7562 net.cpp:529] fc10_fc10_0_split -> fc10_fc10_0_split_0
I0628 18:56:55.962916  7562 net.cpp:529] fc10_fc10_0_split -> fc10_fc10_0_split_1
I0628 18:56:55.962919  7562 net.cpp:529] fc10_fc10_0_split -> fc10_fc10_0_split_2
I0628 18:56:55.962968  7562 net.cpp:244] Setting up fc10_fc10_0_split
I0628 18:56:55.962972  7562 net.cpp:251] TEST Top shape for layer 39 'fc10_fc10_0_split' 25 10 (250)
I0628 18:56:55.962975  7562 net.cpp:251] TEST Top shape for layer 39 'fc10_fc10_0_split' 25 10 (250)
I0628 18:56:55.962977  7562 net.cpp:251] TEST Top shape for layer 39 'fc10_fc10_0_split' 25 10 (250)
I0628 18:56:55.962980  7562 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0628 18:56:55.962981  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.962985  7562 net.cpp:183] Created Layer loss (40)
I0628 18:56:55.962987  7562 net.cpp:560] loss <- fc10_fc10_0_split_0
I0628 18:56:55.962990  7562 net.cpp:560] loss <- label_data_1_split_0
I0628 18:56:55.962992  7562 net.cpp:529] loss -> loss
I0628 18:56:55.963107  7562 net.cpp:244] Setting up loss
I0628 18:56:55.963114  7562 net.cpp:251] TEST Top shape for layer 40 'loss' (1)
I0628 18:56:55.963121  7562 net.cpp:255]     with loss weight 1
I0628 18:56:55.963126  7562 layer_factory.hpp:136] Creating layer 'accuracy/top1' of type 'Accuracy'
I0628 18:56:55.963129  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.963137  7562 net.cpp:183] Created Layer accuracy/top1 (41)
I0628 18:56:55.963140  7562 net.cpp:560] accuracy/top1 <- fc10_fc10_0_split_1
I0628 18:56:55.963142  7562 net.cpp:560] accuracy/top1 <- label_data_1_split_1
I0628 18:56:55.963145  7562 net.cpp:529] accuracy/top1 -> accuracy/top1
I0628 18:56:55.963150  7562 net.cpp:244] Setting up accuracy/top1
I0628 18:56:55.963152  7562 net.cpp:251] TEST Top shape for layer 41 'accuracy/top1' (1)
I0628 18:56:55.963155  7562 layer_factory.hpp:136] Creating layer 'accuracy/top5' of type 'Accuracy'
I0628 18:56:55.963157  7562 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 18:56:55.963160  7562 net.cpp:183] Created Layer accuracy/top5 (42)
I0628 18:56:55.963163  7562 net.cpp:560] accuracy/top5 <- fc10_fc10_0_split_2
I0628 18:56:55.963165  7562 net.cpp:560] accuracy/top5 <- label_data_1_split_2
I0628 18:56:55.963167  7562 net.cpp:529] accuracy/top5 -> accuracy/top5
I0628 18:56:55.963171  7562 net.cpp:244] Setting up accuracy/top5
I0628 18:56:55.963174  7562 net.cpp:251] TEST Top shape for layer 42 'accuracy/top5' (1)
I0628 18:56:55.963176  7562 net.cpp:324] accuracy/top5 does not need backward computation.
I0628 18:56:55.963178  7562 net.cpp:324] accuracy/top1 does not need backward computation.
I0628 18:56:55.963181  7562 net.cpp:322] loss needs backward computation.
I0628 18:56:55.963182  7562 net.cpp:322] fc10_fc10_0_split needs backward computation.
I0628 18:56:55.963184  7562 net.cpp:322] fc10 needs backward computation.
I0628 18:56:55.963186  7562 net.cpp:322] pool5 needs backward computation.
I0628 18:56:55.963189  7562 net.cpp:322] res5a_branch2b/relu needs backward computation.
I0628 18:56:55.963191  7562 net.cpp:322] res5a_branch2b/bn needs backward computation.
I0628 18:56:55.963192  7562 net.cpp:322] res5a_branch2b needs backward computation.
I0628 18:56:55.963194  7562 net.cpp:322] res5a_branch2a/relu needs backward computation.
I0628 18:56:55.963197  7562 net.cpp:322] res5a_branch2a/bn needs backward computation.
I0628 18:56:55.963199  7562 net.cpp:322] res5a_branch2a needs backward computation.
I0628 18:56:55.963201  7562 net.cpp:322] pool4 needs backward computation.
I0628 18:56:55.963203  7562 net.cpp:322] res4a_branch2b/relu needs backward computation.
I0628 18:56:55.963205  7562 net.cpp:322] res4a_branch2b/bn needs backward computation.
I0628 18:56:55.963207  7562 net.cpp:322] res4a_branch2b needs backward computation.
I0628 18:56:55.963209  7562 net.cpp:322] res4a_branch2a/relu needs backward computation.
I0628 18:56:55.963212  7562 net.cpp:322] res4a_branch2a/bn needs backward computation.
I0628 18:56:55.963213  7562 net.cpp:322] res4a_branch2a needs backward computation.
I0628 18:56:55.963217  7562 net.cpp:322] pool3 needs backward computation.
I0628 18:56:55.963218  7562 net.cpp:322] res3a_branch2b/relu needs backward computation.
I0628 18:56:55.963220  7562 net.cpp:322] res3a_branch2b/bn needs backward computation.
I0628 18:56:55.963222  7562 net.cpp:322] res3a_branch2b needs backward computation.
I0628 18:56:55.963224  7562 net.cpp:322] res3a_branch2a/relu needs backward computation.
I0628 18:56:55.963227  7562 net.cpp:322] res3a_branch2a/bn needs backward computation.
I0628 18:56:55.963229  7562 net.cpp:322] res3a_branch2a needs backward computation.
I0628 18:56:55.963232  7562 net.cpp:322] pool2 needs backward computation.
I0628 18:56:55.963233  7562 net.cpp:322] res2a_branch2b/relu needs backward computation.
I0628 18:56:55.963237  7562 net.cpp:322] res2a_branch2b/bn needs backward computation.
I0628 18:56:55.963238  7562 net.cpp:322] res2a_branch2b needs backward computation.
I0628 18:56:55.963240  7562 net.cpp:322] res2a_branch2a/relu needs backward computation.
I0628 18:56:55.963243  7562 net.cpp:322] res2a_branch2a/bn needs backward computation.
I0628 18:56:55.963248  7562 net.cpp:322] res2a_branch2a needs backward computation.
I0628 18:56:55.963250  7562 net.cpp:322] pool1 needs backward computation.
I0628 18:56:55.963253  7562 net.cpp:322] conv1b/relu needs backward computation.
I0628 18:56:55.963255  7562 net.cpp:322] conv1b/bn needs backward computation.
I0628 18:56:55.963258  7562 net.cpp:322] conv1b needs backward computation.
I0628 18:56:55.963260  7562 net.cpp:322] conv1a/relu needs backward computation.
I0628 18:56:55.963263  7562 net.cpp:322] conv1a/bn needs backward computation.
I0628 18:56:55.963265  7562 net.cpp:322] conv1a needs backward computation.
I0628 18:56:55.963268  7562 net.cpp:324] data/bias does not need backward computation.
I0628 18:56:55.963270  7562 net.cpp:324] label_data_1_split does not need backward computation.
I0628 18:56:55.963275  7562 net.cpp:324] data does not need backward computation.
I0628 18:56:55.963277  7562 net.cpp:366] This network produces output accuracy/top1
I0628 18:56:55.963279  7562 net.cpp:366] This network produces output accuracy/top5
I0628 18:56:55.963282  7562 net.cpp:366] This network produces output loss
I0628 18:56:55.963309  7562 net.cpp:388] Top memory (TEST) required for data: 137625600 diff: 91750408
I0628 18:56:55.963311  7562 net.cpp:391] Bottom memory (TEST) required for data: 137625600 diff: 137625600
I0628 18:56:55.963313  7562 net.cpp:394] Shared (in-place) memory (TEST) by data: 91750400 diff: 91750400
I0628 18:56:55.963316  7562 net.cpp:397] Parameters memory (TEST) required for data: 9450960 diff: 9450960
I0628 18:56:55.963318  7562 net.cpp:400] Parameters shared memory (TEST) by data: 0 diff: 0
I0628 18:56:55.963320  7562 net.cpp:406] Network initialization done.
I0628 18:56:55.963368  7562 solver.cpp:56] Solver scaffolding done.
I0628 18:56:55.966418  7562 parallel.cpp:106] [0 - 0] P2pSync adding callback
I0628 18:56:55.966425  7562 parallel.cpp:106] [1 - 1] P2pSync adding callback
I0628 18:56:55.966428  7562 parallel.cpp:59] Starting Optimization
I0628 18:56:55.966430  7562 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0628 18:56:55.966450  7562 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0628 18:56:55.967025  7628 device_alternate.hpp:116] NVML initialized on thread 140325007435520
I0628 18:56:55.983276  7628 common.cpp:563] NVML succeeded to set CPU affinity on device 0
I0628 18:56:55.983342  7629 device_alternate.hpp:116] NVML initialized on thread 140324999042816
I0628 18:56:55.984500  7629 common.cpp:563] NVML succeeded to set CPU affinity on device 1
I0628 18:56:55.989423  7629 solver.cpp:42] Solver data type: FLOAT
I0628 18:56:55.989903  7629 net.cpp:108] Using FLOAT as default forward math type
I0628 18:56:55.989910  7629 net.cpp:114] Using FLOAT as default backward math type
I0628 18:56:55.989933  7629 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 32
I0628 18:56:55.989941  7629 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0628 18:56:55.990581  7630 db_lmdb.cpp:35] Opened lmdb ./data/cifar10_train_lmdb
I0628 18:56:55.991341  7629 data_layer.cpp:188] ReshapePrefetch 32, 3, 32, 32
I0628 18:56:55.991407  7629 data_layer.cpp:206] Output data size: 32, 3, 32, 32
I0628 18:56:55.991412  7629 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0628 18:56:56.275199  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.01G/1 1 0 3  (limit 8.25G, req 0G)
I0628 18:56:56.282495  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 8.23G, req 0G)
I0628 18:56:56.294962  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 8.2G, req 0G)
I0628 18:56:56.301175  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 8.19G, req 0G)
I0628 18:56:56.315212  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 8.17G, req 0.02G)
I0628 18:56:56.321156  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 8.17G, req 0.02G)
I0628 18:56:56.345001  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 8.14G, req 0.02G)
I0628 18:56:56.355793  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 8.12G, req 0.02G)
I0628 18:56:56.402783  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 3  (limit 8.09G, req 0.02G)
I0628 18:56:56.423377  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 7 5 5  (limit 8.08G, req 0.02G)
I0628 18:56:56.424752  7629 solver.cpp:176] Creating test net (#0) specified by test_net file: training/cifar10_jacintonet11v2_2017-06-28_18-56-45/initial/test.prototxt
I0628 18:56:56.424896  7629 net.cpp:108] Using FLOAT as default forward math type
I0628 18:56:56.424901  7629 net.cpp:114] Using FLOAT as default backward math type
I0628 18:56:56.424923  7629 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 25
I0628 18:56:56.424932  7629 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0628 18:56:56.425591  7642 db_lmdb.cpp:35] Opened lmdb ./data/cifar10_test_lmdb
I0628 18:56:56.425664  7629 data_layer.cpp:188] ReshapePrefetch 25, 3, 32, 32
I0628 18:56:56.425725  7629 data_layer.cpp:206] Output data size: 25, 3, 32, 32
I0628 18:56:56.425731  7629 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0628 18:56:56.426736  7643 data_layer.cpp:188] ReshapePrefetch 25, 3, 32, 32
I0628 18:56:56.426745  7643 data_layer.cpp:206] Output data size: 25, 3, 32, 32
I0628 18:56:56.427556  7643 data_layer.cpp:110] [1] Parser threads: 1
I0628 18:56:56.427563  7643 data_layer.cpp:112] [1] Transformer threads: 1
I0628 18:56:56.526877  7629 solver.cpp:56] Solver scaffolding done.
I0628 18:56:56.543489  7628 parallel.cpp:161] [0 - 0] P2pSync adding callback
I0628 18:56:56.543489  7629 parallel.cpp:161] [1 - 1] P2pSync adding callback
I0628 18:56:56.644317  7628 solver.cpp:474] Solving jacintonet11v2_train
I0628 18:56:56.644317  7629 solver.cpp:474] Solving jacintonet11v2_train
I0628 18:56:56.644340  7628 solver.cpp:475] Learning Rate Policy: poly
I0628 18:56:56.644340  7629 solver.cpp:475] Learning Rate Policy: poly
I0628 18:56:56.647692  7628 solver.cpp:268] Starting Optimization on GPU 0
I0628 18:56:56.647692  7629 solver.cpp:268] Starting Optimization on GPU 1
I0628 18:56:56.647727  7628 solver.cpp:545] Iteration 0, Testing net (#0)
I0628 18:56:56.647778  7661 device_alternate.hpp:116] NVML initialized on thread 140324615075584
I0628 18:56:56.647797  7661 common.cpp:563] NVML succeeded to set CPU affinity on device 1
I0628 18:56:56.648401  7662 device_alternate.hpp:116] NVML initialized on thread 140324606682880
I0628 18:56:56.648411  7662 common.cpp:563] NVML succeeded to set CPU affinity on device 0
I0628 18:56:56.697265  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.16
I0628 18:56:56.697281  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.36
I0628 18:56:56.697286  7628 solver.cpp:630]     Test net output #2: loss = 73.3627 (* 1 = 73.3627 loss)
I0628 18:56:56.697291  7628 solver.cpp:295] [MultiGPU] Initial Test completed
I0628 18:56:56.697301  7628 blocking_queue.cpp:40] Data layer prefetch queue empty
I0628 18:56:56.703909  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 3  (limit 7.78G, req 0.02G)
I0628 18:56:56.704222  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 3  (limit 7.69G, req 0.01G)
I0628 18:56:56.710994  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 7.68G, req 0.01G)
I0628 18:56:56.711364  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 7.77G, req 0.02G)
I0628 18:56:56.731009  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 1  (limit 7.76G, req 0.02G)
I0628 18:56:56.732504  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 1  (limit 7.67G, req 0.01G)
I0628 18:56:56.736830  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 7.74G, req 0.02G)
I0628 18:56:56.738157  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 7.65G, req 0.01G)
I0628 18:56:56.746064  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 7.72G, req 0.02G)
I0628 18:56:56.748677  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 7.64G, req 0.02G)
I0628 18:56:56.751243  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 7.71G, req 0.02G)
I0628 18:56:56.753705  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 7.63G, req 0.02G)
I0628 18:56:56.767408  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 7.7G, req 0.02G)
I0628 18:56:56.770647  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 7.61G, req 0.02G)
I0628 18:56:56.773895  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 7.68G, req 0.02G)
I0628 18:56:56.777537  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 7.6G, req 0.02G)
I0628 18:56:56.793442  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 1  (limit 7.66G, req 0.02G)
I0628 18:56:56.799634  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 1  (limit 7.57G, req 0.02G)
I0628 18:56:56.799988  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 7 5 5  (limit 7.66G, req 0.02G)
I0628 18:56:56.807359  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 7 5 5  (limit 7.56G, req 0.02G)
I0628 18:56:56.822409  7631 data_layer.cpp:188] ReshapePrefetch 32, 3, 32, 32
I0628 18:56:56.822422  7631 data_layer.cpp:206] Output data size: 32, 3, 32, 32
I0628 18:56:56.822933  7631 data_layer.cpp:110] [1] Parser threads: 1
I0628 18:56:56.822943  7631 data_layer.cpp:112] [1] Transformer threads: 1
I0628 18:56:56.828666  7614 data_layer.cpp:188] ReshapePrefetch 32, 3, 32, 32
I0628 18:56:56.828681  7614 data_layer.cpp:206] Output data size: 32, 3, 32, 32
I0628 18:56:56.828797  7614 data_layer.cpp:110] [0] Parser threads: 1
I0628 18:56:56.828804  7614 data_layer.cpp:112] [0] Transformer threads: 1
I0628 18:56:56.829016  7628 solver.cpp:354] Iteration 0 (0.131709 s), loss = 2.41522
I0628 18:56:56.829031  7628 solver.cpp:371]     Train net output #0: loss = 2.41522 (* 1 = 2.41522 loss)
I0628 18:56:56.829035  7628 sgd_solver.cpp:137] Iteration 0, lr = 0.1, m = 0.9
I0628 18:56:56.837764  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 3  (limit 7.57G, req 0.02G)
I0628 18:56:56.838003  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 3  (limit 7.48G, req 0.02G)
I0628 18:56:56.842315  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 7.57G, req 0.02G)
I0628 18:56:56.842878  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 7.48G, req 0.02G)
I0628 18:56:56.849628  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 7.57G, req 0.02G)
I0628 18:56:56.850136  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 1  (limit 7.48G, req 0.02G)
I0628 18:56:56.853710  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 7.57G, req 0.02G)
I0628 18:56:56.854269  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 7.48G, req 0.02G)
I0628 18:56:56.860527  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 7.57G, req 0.02G)
I0628 18:56:56.861380  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 7.48G, req 0.02G)
I0628 18:56:56.864367  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 7.57G, req 0.02G)
I0628 18:56:56.865006  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 7.48G, req 0.02G)
I0628 18:56:56.877744  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 7.57G, req 0.02G)
I0628 18:56:56.879294  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 7.48G, req 0.02G)
I0628 18:56:56.883482  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 7.57G, req 0.02G)
I0628 18:56:56.884305  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 7.48G, req 0.02G)
I0628 18:56:56.904563  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 1  (limit 7.57G, req 0.02G)
I0628 18:56:56.905021  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 3  (limit 7.48G, req 0.02G)
I0628 18:56:56.910465  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 7 5 5  (limit 7.57G, req 0.02G)
I0628 18:56:56.910751  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 7 5 5  (limit 7.48G, req 0.02G)
I0628 18:56:56.923387  7628 solver.cpp:354] Iteration 1 (0.0943329 s), loss = 2.20263
I0628 18:56:56.923408  7628 solver.cpp:371]     Train net output #0: loss = 2.20263 (* 1 = 2.20263 loss)
I0628 18:56:56.932822  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.68G/1 1 0 3  (limit 6.91G, req 0.02G)
I0628 18:56:56.932979  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.68G/1 1 0 0  (limit 6.82G, req 0.02G)
I0628 18:56:56.939556  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'conv1b' with space 1.35G/2 1 1 3  (limit 6.23G, req 0.02G)
I0628 18:56:56.941026  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'conv1b' with space 1.35G/2 1 1 3  (limit 6.14G, req 0.02G)
I0628 18:56:56.955101  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 1.35G/1 6 4 3  (limit 6.23G, req 0.02G)
I0628 18:56:56.957144  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 1.35G/1 6 4 1  (limit 6.14G, req 0.02G)
I0628 18:56:56.963120  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 1.35G/2 6 4 3  (limit 6.23G, req 0.02G)
I0628 18:56:56.965086  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 1.35G/2 6 4 3  (limit 6.14G, req 0.02G)
I0628 18:56:56.976718  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 1.35G/1 6 4 5  (limit 6.23G, req 0.02G)
I0628 18:56:56.976999  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 1.35G/1 6 4 5  (limit 6.14G, req 0.02G)
I0628 18:56:56.981122  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 1.35G/2 6 4 0  (limit 6.23G, req 0.02G)
I0628 18:56:56.982252  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 1.35G/2 6 4 0  (limit 6.14G, req 0.02G)
I0628 18:56:57.011062  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 1.35G/1 6 4 5  (limit 6.14G, req 0.03G)
I0628 18:56:57.013208  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 1.35G/1 6 4 5  (limit 6.23G, req 0.03G)
I0628 18:56:57.019074  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 1.35G/2 6 4 3  (limit 6.14G, req 0.03G)
I0628 18:56:57.020934  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 1.35G/2 6 4 3  (limit 6.23G, req 0.03G)
I0628 18:56:57.061944  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 1.35G/1 7 5 5  (limit 6.14G, req 0.03G)
I0628 18:56:57.064550  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 1.35G/1 7 5 5  (limit 6.23G, req 0.03G)
I0628 18:56:57.075949  7629 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 1.35G/2 7 5 5  (limit 6.23G, req 0.03G)
I0628 18:56:57.079802  7628 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 1.35G/2 7 4 5  (limit 6.14G, req 0.03G)
I0628 18:56:57.092095  7628 solver.cpp:349] Iteration 2 (5.92891 iter/s, 0.168665s/100 iter), loss = 2.47595
I0628 18:56:57.092124  7628 solver.cpp:371]     Train net output #0: loss = 2.47595 (* 1 = 2.47595 loss)
I0628 18:56:57.126940  7628 cudnn_conv_layer.cpp:283] [0] Layer 'conv1a' reallocating workspace: 1.35G -> 0.07G
I0628 18:56:57.126940  7629 cudnn_conv_layer.cpp:283] [1] Layer 'conv1a' reallocating workspace: 1.35G -> 0.07G
I0628 18:56:58.368986  7614 blocking_queue.cpp:40] Waiting for datum
I0628 18:56:58.760920  7628 solver.cpp:349] Iteration 100 (58.7274 iter/s, 1.66873s/100 iter), loss = 1.65823
I0628 18:56:58.760939  7628 solver.cpp:371]     Train net output #0: loss = 1.65823 (* 1 = 1.65823 loss)
I0628 18:56:58.760944  7628 sgd_solver.cpp:137] Iteration 100, lr = 0.0998438, m = 0.9
I0628 18:57:00.776150  7628 solver.cpp:349] Iteration 200 (49.6245 iter/s, 2.01513s/100 iter), loss = 1.63203
I0628 18:57:00.776175  7628 solver.cpp:371]     Train net output #0: loss = 1.63203 (* 1 = 1.63203 loss)
I0628 18:57:00.776183  7628 sgd_solver.cpp:137] Iteration 200, lr = 0.0996875, m = 0.9
I0628 18:57:02.557868  7628 solver.cpp:349] Iteration 300 (56.1287 iter/s, 1.78162s/100 iter), loss = 1.58065
I0628 18:57:02.557891  7628 solver.cpp:371]     Train net output #0: loss = 1.58065 (* 1 = 1.58065 loss)
I0628 18:57:02.557898  7628 sgd_solver.cpp:137] Iteration 300, lr = 0.0995313, m = 0.9
I0628 18:57:04.259845  7628 solver.cpp:349] Iteration 400 (58.7585 iter/s, 1.70188s/100 iter), loss = 1.43131
I0628 18:57:04.259866  7628 solver.cpp:371]     Train net output #0: loss = 1.43131 (* 1 = 1.43131 loss)
I0628 18:57:04.259871  7628 sgd_solver.cpp:137] Iteration 400, lr = 0.099375, m = 0.9
I0628 18:57:05.963021  7628 solver.cpp:349] Iteration 500 (58.7169 iter/s, 1.70309s/100 iter), loss = 1.1501
I0628 18:57:05.963043  7628 solver.cpp:371]     Train net output #0: loss = 1.1501 (* 1 = 1.1501 loss)
I0628 18:57:05.963047  7628 sgd_solver.cpp:137] Iteration 500, lr = 0.0992187, m = 0.9
I0628 18:57:07.668576  7628 solver.cpp:349] Iteration 600 (58.635 iter/s, 1.70546s/100 iter), loss = 0.984433
I0628 18:57:07.668597  7628 solver.cpp:371]     Train net output #0: loss = 0.984433 (* 1 = 0.984433 loss)
I0628 18:57:07.668602  7628 sgd_solver.cpp:137] Iteration 600, lr = 0.0990625, m = 0.9
I0628 18:57:09.372469  7628 solver.cpp:349] Iteration 700 (58.6922 iter/s, 1.7038s/100 iter), loss = 1.16149
I0628 18:57:09.372491  7628 solver.cpp:371]     Train net output #0: loss = 1.16149 (* 1 = 1.16149 loss)
I0628 18:57:09.372496  7628 sgd_solver.cpp:137] Iteration 700, lr = 0.0989062, m = 0.9
I0628 18:57:10.710011  7613 data_reader.cpp:262] Starting prefetch of epoch 1
I0628 18:57:11.084947  7628 solver.cpp:349] Iteration 800 (58.3981 iter/s, 1.71239s/100 iter), loss = 0.884332
I0628 18:57:11.084972  7628 solver.cpp:371]     Train net output #0: loss = 0.884332 (* 1 = 0.884332 loss)
I0628 18:57:11.084976  7628 sgd_solver.cpp:137] Iteration 800, lr = 0.09875, m = 0.9
I0628 18:57:12.787426  7628 solver.cpp:349] Iteration 900 (58.7411 iter/s, 1.70239s/100 iter), loss = 0.932051
I0628 18:57:12.787466  7628 solver.cpp:371]     Train net output #0: loss = 0.932051 (* 1 = 0.932051 loss)
I0628 18:57:12.787470  7628 sgd_solver.cpp:137] Iteration 900, lr = 0.0985937, m = 0.9
I0628 18:57:14.476846  7628 solver.cpp:545] Iteration 1000, Testing net (#0)
I0628 18:57:15.483477  7626 data_reader.cpp:262] Starting prefetch of epoch 1
I0628 18:57:15.503803  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.534
I0628 18:57:15.503815  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.966201
I0628 18:57:15.503819  7628 solver.cpp:630]     Test net output #2: loss = 1.30125 (* 1 = 1.30125 loss)
I0628 18:57:15.503834  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02696s
I0628 18:57:15.521096  7628 solver.cpp:349] Iteration 1000 (36.5827 iter/s, 2.73353s/100 iter), loss = 0.97534
I0628 18:57:15.521118  7628 solver.cpp:371]     Train net output #0: loss = 0.97534 (* 1 = 0.97534 loss)
I0628 18:57:15.521124  7628 sgd_solver.cpp:137] Iteration 1000, lr = 0.0984375, m = 0.9
I0628 18:57:17.228981  7628 solver.cpp:349] Iteration 1100 (58.5552 iter/s, 1.70779s/100 iter), loss = 1.43777
I0628 18:57:17.229002  7628 solver.cpp:371]     Train net output #0: loss = 1.43777 (* 1 = 1.43777 loss)
I0628 18:57:17.229007  7628 sgd_solver.cpp:137] Iteration 1100, lr = 0.0982813, m = 0.9
I0628 18:57:18.932545  7628 solver.cpp:349] Iteration 1200 (58.7036 iter/s, 1.70347s/100 iter), loss = 1.07396
I0628 18:57:18.932565  7628 solver.cpp:371]     Train net output #0: loss = 1.07396 (* 1 = 1.07396 loss)
I0628 18:57:18.932569  7628 sgd_solver.cpp:137] Iteration 1200, lr = 0.098125, m = 0.9
I0628 18:57:20.636276  7628 solver.cpp:349] Iteration 1300 (58.6978 iter/s, 1.70364s/100 iter), loss = 0.599833
I0628 18:57:20.636301  7628 solver.cpp:371]     Train net output #0: loss = 0.599833 (* 1 = 0.599833 loss)
I0628 18:57:20.636306  7628 sgd_solver.cpp:137] Iteration 1300, lr = 0.0979687, m = 0.9
I0628 18:57:22.339951  7628 solver.cpp:349] Iteration 1400 (58.6999 iter/s, 1.70358s/100 iter), loss = 0.676795
I0628 18:57:22.339975  7628 solver.cpp:371]     Train net output #0: loss = 0.676795 (* 1 = 0.676795 loss)
I0628 18:57:22.339982  7628 sgd_solver.cpp:137] Iteration 1400, lr = 0.0978125, m = 0.9
I0628 18:57:24.038277  7628 solver.cpp:349] Iteration 1500 (58.8848 iter/s, 1.69823s/100 iter), loss = 0.575772
I0628 18:57:24.038300  7628 solver.cpp:371]     Train net output #0: loss = 0.575772 (* 1 = 0.575772 loss)
I0628 18:57:24.038305  7628 sgd_solver.cpp:137] Iteration 1500, lr = 0.0976562, m = 0.9
I0628 18:57:25.043442  7613 data_reader.cpp:262] Starting prefetch of epoch 2
I0628 18:57:25.740754  7628 solver.cpp:349] Iteration 1600 (58.7412 iter/s, 1.70238s/100 iter), loss = 0.791276
I0628 18:57:25.740778  7628 solver.cpp:371]     Train net output #0: loss = 0.791276 (* 1 = 0.791276 loss)
I0628 18:57:25.740783  7628 sgd_solver.cpp:137] Iteration 1600, lr = 0.0975, m = 0.9
I0628 18:57:27.445808  7628 solver.cpp:349] Iteration 1700 (58.6524 iter/s, 1.70496s/100 iter), loss = 0.509466
I0628 18:57:27.445832  7628 solver.cpp:371]     Train net output #0: loss = 0.509466 (* 1 = 0.509466 loss)
I0628 18:57:27.445837  7628 sgd_solver.cpp:137] Iteration 1700, lr = 0.0973438, m = 0.9
I0628 18:57:29.151619  7628 solver.cpp:349] Iteration 1800 (58.6263 iter/s, 1.70572s/100 iter), loss = 0.849034
I0628 18:57:29.151640  7628 solver.cpp:371]     Train net output #0: loss = 0.849034 (* 1 = 0.849034 loss)
I0628 18:57:29.151644  7628 sgd_solver.cpp:137] Iteration 1800, lr = 0.0971875, m = 0.9
I0628 18:57:30.855134  7628 solver.cpp:349] Iteration 1900 (58.7053 iter/s, 1.70342s/100 iter), loss = 0.438497
I0628 18:57:30.855156  7628 solver.cpp:371]     Train net output #0: loss = 0.438497 (* 1 = 0.438497 loss)
I0628 18:57:30.855161  7628 sgd_solver.cpp:137] Iteration 1900, lr = 0.0970313, m = 0.9
I0628 18:57:32.544883  7628 solver.cpp:545] Iteration 2000, Testing net (#0)
I0628 18:57:33.548089  7626 data_reader.cpp:262] Starting prefetch of epoch 2
I0628 18:57:33.568892  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.6804
I0628 18:57:33.568907  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.974801
I0628 18:57:33.568912  7628 solver.cpp:630]     Test net output #2: loss = 0.918189 (* 1 = 0.918189 loss)
I0628 18:57:33.568925  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02401s
I0628 18:57:33.586102  7628 solver.cpp:349] Iteration 2000 (36.6187 iter/s, 2.73085s/100 iter), loss = 0.637231
I0628 18:57:33.586125  7628 solver.cpp:371]     Train net output #0: loss = 0.637231 (* 1 = 0.637231 loss)
I0628 18:57:33.586129  7628 sgd_solver.cpp:137] Iteration 2000, lr = 0.096875, m = 0.9
I0628 18:57:35.293756  7628 solver.cpp:349] Iteration 2100 (58.5631 iter/s, 1.70756s/100 iter), loss = 0.558987
I0628 18:57:35.293777  7628 solver.cpp:371]     Train net output #0: loss = 0.558987 (* 1 = 0.558987 loss)
I0628 18:57:35.293781  7628 sgd_solver.cpp:137] Iteration 2100, lr = 0.0967188, m = 0.9
I0628 18:57:36.998931  7628 solver.cpp:349] Iteration 2200 (58.6481 iter/s, 1.70508s/100 iter), loss = 0.855461
I0628 18:57:36.998952  7628 solver.cpp:371]     Train net output #0: loss = 0.855461 (* 1 = 0.855461 loss)
I0628 18:57:36.998956  7628 sgd_solver.cpp:137] Iteration 2200, lr = 0.0965625, m = 0.9
I0628 18:57:38.704803  7628 solver.cpp:349] Iteration 2300 (58.6242 iter/s, 1.70578s/100 iter), loss = 0.448389
I0628 18:57:38.704825  7628 solver.cpp:371]     Train net output #0: loss = 0.448389 (* 1 = 0.448389 loss)
I0628 18:57:38.704829  7628 sgd_solver.cpp:137] Iteration 2300, lr = 0.0964063, m = 0.9
I0628 18:57:39.391474  7613 data_reader.cpp:262] Starting prefetch of epoch 3
I0628 18:57:40.414566  7628 solver.cpp:349] Iteration 2400 (58.4909 iter/s, 1.70967s/100 iter), loss = 0.533496
I0628 18:57:40.414588  7628 solver.cpp:371]     Train net output #0: loss = 0.533496 (* 1 = 0.533496 loss)
I0628 18:57:40.414592  7628 sgd_solver.cpp:137] Iteration 2400, lr = 0.09625, m = 0.9
I0628 18:57:42.118415  7628 solver.cpp:349] Iteration 2500 (58.6939 iter/s, 1.70375s/100 iter), loss = 0.776698
I0628 18:57:42.118440  7628 solver.cpp:371]     Train net output #0: loss = 0.776698 (* 1 = 0.776698 loss)
I0628 18:57:42.118448  7628 sgd_solver.cpp:137] Iteration 2500, lr = 0.0960938, m = 0.9
I0628 18:57:43.828238  7628 solver.cpp:349] Iteration 2600 (58.4891 iter/s, 1.70972s/100 iter), loss = 0.788647
I0628 18:57:43.828258  7628 solver.cpp:371]     Train net output #0: loss = 0.788647 (* 1 = 0.788647 loss)
I0628 18:57:43.828263  7628 sgd_solver.cpp:137] Iteration 2600, lr = 0.0959375, m = 0.9
I0628 18:57:45.536448  7628 solver.cpp:349] Iteration 2700 (58.5439 iter/s, 1.70812s/100 iter), loss = 0.466793
I0628 18:57:45.536469  7628 solver.cpp:371]     Train net output #0: loss = 0.466793 (* 1 = 0.466793 loss)
I0628 18:57:45.536483  7628 sgd_solver.cpp:137] Iteration 2700, lr = 0.0957813, m = 0.9
I0628 18:57:47.241859  7628 solver.cpp:349] Iteration 2800 (58.6404 iter/s, 1.70531s/100 iter), loss = 0.518772
I0628 18:57:47.241879  7628 solver.cpp:371]     Train net output #0: loss = 0.518772 (* 1 = 0.518772 loss)
I0628 18:57:47.241883  7628 sgd_solver.cpp:137] Iteration 2800, lr = 0.095625, m = 0.9
I0628 18:57:48.951158  7628 solver.cpp:349] Iteration 2900 (58.5067 iter/s, 1.70921s/100 iter), loss = 0.435994
I0628 18:57:48.951179  7628 solver.cpp:371]     Train net output #0: loss = 0.435994 (* 1 = 0.435994 loss)
I0628 18:57:48.951184  7628 sgd_solver.cpp:137] Iteration 2900, lr = 0.0954688, m = 0.9
I0628 18:57:50.643957  7628 solver.cpp:545] Iteration 3000, Testing net (#0)
I0628 18:57:51.646183  7626 data_reader.cpp:262] Starting prefetch of epoch 3
I0628 18:57:51.667026  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.7472
I0628 18:57:51.667040  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.978
I0628 18:57:51.667045  7628 solver.cpp:630]     Test net output #2: loss = 0.757618 (* 1 = 0.757618 loss)
I0628 18:57:51.667059  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02307s
I0628 18:57:51.684321  7628 solver.cpp:349] Iteration 3000 (36.5893 iter/s, 2.73304s/100 iter), loss = 0.468012
I0628 18:57:51.684343  7628 solver.cpp:371]     Train net output #0: loss = 0.468012 (* 1 = 0.468012 loss)
I0628 18:57:51.684347  7628 sgd_solver.cpp:137] Iteration 3000, lr = 0.0953125, m = 0.9
I0628 18:57:53.394284  7628 solver.cpp:349] Iteration 3100 (58.4839 iter/s, 1.70987s/100 iter), loss = 0.716954
I0628 18:57:53.394305  7628 solver.cpp:371]     Train net output #0: loss = 0.716954 (* 1 = 0.716954 loss)
I0628 18:57:53.394310  7628 sgd_solver.cpp:137] Iteration 3100, lr = 0.0951563, m = 0.9
I0628 18:57:53.752128  7613 data_reader.cpp:262] Starting prefetch of epoch 4
I0628 18:57:55.100917  7628 solver.cpp:349] Iteration 3200 (58.598 iter/s, 1.70654s/100 iter), loss = 0.527757
I0628 18:57:55.100996  7628 solver.cpp:371]     Train net output #0: loss = 0.527757 (* 1 = 0.527757 loss)
I0628 18:57:55.101004  7628 sgd_solver.cpp:137] Iteration 3200, lr = 0.095, m = 0.9
I0628 18:57:56.813741  7628 solver.cpp:349] Iteration 3300 (58.3885 iter/s, 1.71267s/100 iter), loss = 0.512567
I0628 18:57:56.813765  7628 solver.cpp:371]     Train net output #0: loss = 0.512567 (* 1 = 0.512567 loss)
I0628 18:57:56.813769  7628 sgd_solver.cpp:137] Iteration 3300, lr = 0.0948438, m = 0.9
I0628 18:57:58.523288  7628 solver.cpp:349] Iteration 3400 (58.4982 iter/s, 1.70945s/100 iter), loss = 0.442209
I0628 18:57:58.523311  7628 solver.cpp:371]     Train net output #0: loss = 0.442209 (* 1 = 0.442209 loss)
I0628 18:57:58.523315  7628 sgd_solver.cpp:137] Iteration 3400, lr = 0.0946875, m = 0.9
I0628 18:58:00.232589  7628 solver.cpp:349] Iteration 3500 (58.5067 iter/s, 1.70921s/100 iter), loss = 0.280772
I0628 18:58:00.232610  7628 solver.cpp:371]     Train net output #0: loss = 0.280772 (* 1 = 0.280772 loss)
I0628 18:58:00.232614  7628 sgd_solver.cpp:137] Iteration 3500, lr = 0.0945313, m = 0.9
I0628 18:58:01.941632  7628 solver.cpp:349] Iteration 3600 (58.5154 iter/s, 1.70895s/100 iter), loss = 0.540488
I0628 18:58:01.941653  7628 solver.cpp:371]     Train net output #0: loss = 0.540488 (* 1 = 0.540488 loss)
I0628 18:58:01.941658  7628 sgd_solver.cpp:137] Iteration 3600, lr = 0.094375, m = 0.9
I0628 18:58:03.650167  7628 solver.cpp:349] Iteration 3700 (58.5328 iter/s, 1.70844s/100 iter), loss = 0.637194
I0628 18:58:03.650188  7628 solver.cpp:371]     Train net output #0: loss = 0.637194 (* 1 = 0.637194 loss)
I0628 18:58:03.650192  7628 sgd_solver.cpp:137] Iteration 3700, lr = 0.0942188, m = 0.9
I0628 18:58:05.360621  7628 solver.cpp:349] Iteration 3800 (58.4671 iter/s, 1.71036s/100 iter), loss = 0.445415
I0628 18:58:05.360644  7628 solver.cpp:371]     Train net output #0: loss = 0.445415 (* 1 = 0.445415 loss)
I0628 18:58:05.360648  7628 sgd_solver.cpp:137] Iteration 3800, lr = 0.0940625, m = 0.9
I0628 18:58:07.068754  7628 solver.cpp:349] Iteration 3900 (58.5467 iter/s, 1.70804s/100 iter), loss = 0.294246
I0628 18:58:07.068775  7628 solver.cpp:371]     Train net output #0: loss = 0.294246 (* 1 = 0.294246 loss)
I0628 18:58:07.068779  7628 sgd_solver.cpp:137] Iteration 3900, lr = 0.0939062, m = 0.9
I0628 18:58:07.120252  7613 data_reader.cpp:262] Starting prefetch of epoch 5
I0628 18:58:08.760432  7628 solver.cpp:545] Iteration 4000, Testing net (#0)
I0628 18:58:09.767961  7626 data_reader.cpp:262] Starting prefetch of epoch 4
I0628 18:58:09.788322  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.7006
I0628 18:58:09.788336  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.979401
I0628 18:58:09.788343  7628 solver.cpp:630]     Test net output #2: loss = 0.879205 (* 1 = 0.879205 loss)
I0628 18:58:09.788360  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.0279s
I0628 18:58:09.805625  7628 solver.cpp:349] Iteration 4000 (36.5397 iter/s, 2.73675s/100 iter), loss = 0.60244
I0628 18:58:09.805650  7628 solver.cpp:371]     Train net output #0: loss = 0.60244 (* 1 = 0.60244 loss)
I0628 18:58:09.805655  7628 sgd_solver.cpp:137] Iteration 4000, lr = 0.09375, m = 0.9
I0628 18:58:11.516031  7628 solver.cpp:349] Iteration 4100 (58.4691 iter/s, 1.71031s/100 iter), loss = 0.421332
I0628 18:58:11.516054  7628 solver.cpp:371]     Train net output #0: loss = 0.421332 (* 1 = 0.421332 loss)
I0628 18:58:11.516060  7628 sgd_solver.cpp:137] Iteration 4100, lr = 0.0935938, m = 0.9
I0628 18:58:13.229832  7628 solver.cpp:349] Iteration 4200 (58.3532 iter/s, 1.7137s/100 iter), loss = 0.131802
I0628 18:58:13.229856  7628 solver.cpp:371]     Train net output #0: loss = 0.131802 (* 1 = 0.131802 loss)
I0628 18:58:13.229862  7628 sgd_solver.cpp:137] Iteration 4200, lr = 0.0934375, m = 0.9
I0628 18:58:14.938930  7628 solver.cpp:349] Iteration 4300 (58.5137 iter/s, 1.709s/100 iter), loss = 0.831636
I0628 18:58:14.938954  7628 solver.cpp:371]     Train net output #0: loss = 0.831636 (* 1 = 0.831636 loss)
I0628 18:58:14.938959  7628 sgd_solver.cpp:137] Iteration 4300, lr = 0.0932813, m = 0.9
I0628 18:58:16.651981  7628 solver.cpp:349] Iteration 4400 (58.3792 iter/s, 1.71294s/100 iter), loss = 0.251769
I0628 18:58:16.652005  7628 solver.cpp:371]     Train net output #0: loss = 0.251768 (* 1 = 0.251768 loss)
I0628 18:58:16.652009  7628 sgd_solver.cpp:137] Iteration 4400, lr = 0.093125, m = 0.9
I0628 18:58:18.363818  7628 solver.cpp:349] Iteration 4500 (58.42 iter/s, 1.71174s/100 iter), loss = 0.311408
I0628 18:58:18.363840  7628 solver.cpp:371]     Train net output #0: loss = 0.311407 (* 1 = 0.311407 loss)
I0628 18:58:18.363845  7628 sgd_solver.cpp:137] Iteration 4500, lr = 0.0929688, m = 0.9
I0628 18:58:20.075278  7628 solver.cpp:349] Iteration 4600 (58.4328 iter/s, 1.71137s/100 iter), loss = 0.313337
I0628 18:58:20.075299  7628 solver.cpp:371]     Train net output #0: loss = 0.313337 (* 1 = 0.313337 loss)
I0628 18:58:20.075304  7628 sgd_solver.cpp:137] Iteration 4600, lr = 0.0928125, m = 0.9
I0628 18:58:21.513731  7613 data_reader.cpp:262] Starting prefetch of epoch 6
I0628 18:58:21.788449  7628 solver.cpp:349] Iteration 4700 (58.3745 iter/s, 1.71308s/100 iter), loss = 0.450369
I0628 18:58:21.788471  7628 solver.cpp:371]     Train net output #0: loss = 0.450369 (* 1 = 0.450369 loss)
I0628 18:58:21.788475  7628 sgd_solver.cpp:137] Iteration 4700, lr = 0.0926562, m = 0.9
I0628 18:58:23.496522  7628 solver.cpp:349] Iteration 4800 (58.5486 iter/s, 1.70798s/100 iter), loss = 0.558355
I0628 18:58:23.496543  7628 solver.cpp:371]     Train net output #0: loss = 0.558355 (* 1 = 0.558355 loss)
I0628 18:58:23.496547  7628 sgd_solver.cpp:137] Iteration 4800, lr = 0.0925, m = 0.9
I0628 18:58:25.205067  7628 solver.cpp:349] Iteration 4900 (58.5325 iter/s, 1.70845s/100 iter), loss = 0.239262
I0628 18:58:25.205127  7628 solver.cpp:371]     Train net output #0: loss = 0.239262 (* 1 = 0.239262 loss)
I0628 18:58:25.205133  7628 sgd_solver.cpp:137] Iteration 4900, lr = 0.0923437, m = 0.9
I0628 18:58:26.899996  7628 solver.cpp:545] Iteration 5000, Testing net (#0)
I0628 18:58:27.905269  7626 data_reader.cpp:262] Starting prefetch of epoch 5
I0628 18:58:27.925591  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.7434
I0628 18:58:27.925606  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.976201
I0628 18:58:27.925611  7628 solver.cpp:630]     Test net output #2: loss = 0.799174 (* 1 = 0.799174 loss)
I0628 18:58:27.925624  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.0256s
I0628 18:58:27.943014  7628 solver.cpp:349] Iteration 5000 (36.5259 iter/s, 2.73778s/100 iter), loss = 0.350767
I0628 18:58:27.943037  7628 solver.cpp:371]     Train net output #0: loss = 0.350767 (* 1 = 0.350767 loss)
I0628 18:58:27.943040  7628 sgd_solver.cpp:137] Iteration 5000, lr = 0.0921875, m = 0.9
I0628 18:58:29.651821  7628 solver.cpp:349] Iteration 5100 (58.5235 iter/s, 1.70872s/100 iter), loss = 0.251671
I0628 18:58:29.651841  7628 solver.cpp:371]     Train net output #0: loss = 0.251671 (* 1 = 0.251671 loss)
I0628 18:58:29.651846  7628 sgd_solver.cpp:137] Iteration 5100, lr = 0.0920313, m = 0.9
I0628 18:58:31.367152  7628 solver.cpp:349] Iteration 5200 (58.3008 iter/s, 1.71524s/100 iter), loss = 0.696482
I0628 18:58:31.367175  7628 solver.cpp:371]     Train net output #0: loss = 0.696482 (* 1 = 0.696482 loss)
I0628 18:58:31.367179  7628 sgd_solver.cpp:137] Iteration 5200, lr = 0.091875, m = 0.9
I0628 18:58:33.077075  7628 solver.cpp:349] Iteration 5300 (58.4853 iter/s, 1.70983s/100 iter), loss = 0.366943
I0628 18:58:33.077096  7628 solver.cpp:371]     Train net output #0: loss = 0.366943 (* 1 = 0.366943 loss)
I0628 18:58:33.077100  7628 sgd_solver.cpp:137] Iteration 5300, lr = 0.0917188, m = 0.9
I0628 18:58:34.786497  7628 solver.cpp:349] Iteration 5400 (58.5024 iter/s, 1.70933s/100 iter), loss = 0.254856
I0628 18:58:34.786520  7628 solver.cpp:371]     Train net output #0: loss = 0.254856 (* 1 = 0.254856 loss)
I0628 18:58:34.786525  7628 sgd_solver.cpp:137] Iteration 5400, lr = 0.0915625, m = 0.9
I0628 18:58:35.897660  7613 data_reader.cpp:262] Starting prefetch of epoch 7
I0628 18:58:36.495265  7628 solver.cpp:349] Iteration 5500 (58.525 iter/s, 1.70867s/100 iter), loss = 0.331896
I0628 18:58:36.495286  7628 solver.cpp:371]     Train net output #0: loss = 0.331896 (* 1 = 0.331896 loss)
I0628 18:58:36.495291  7628 sgd_solver.cpp:137] Iteration 5500, lr = 0.0914062, m = 0.9
I0628 18:58:38.204319  7628 solver.cpp:349] Iteration 5600 (58.5151 iter/s, 1.70896s/100 iter), loss = 0.195107
I0628 18:58:38.204339  7628 solver.cpp:371]     Train net output #0: loss = 0.195107 (* 1 = 0.195107 loss)
I0628 18:58:38.204344  7628 sgd_solver.cpp:137] Iteration 5600, lr = 0.09125, m = 0.9
I0628 18:58:39.915815  7628 solver.cpp:349] Iteration 5700 (58.4315 iter/s, 1.71141s/100 iter), loss = 0.2654
I0628 18:58:39.915837  7628 solver.cpp:371]     Train net output #0: loss = 0.2654 (* 1 = 0.2654 loss)
I0628 18:58:39.915840  7628 sgd_solver.cpp:137] Iteration 5700, lr = 0.0910937, m = 0.9
I0628 18:58:41.629324  7628 solver.cpp:349] Iteration 5800 (58.3629 iter/s, 1.71342s/100 iter), loss = 0.405319
I0628 18:58:41.629348  7628 solver.cpp:371]     Train net output #0: loss = 0.405319 (* 1 = 0.405319 loss)
I0628 18:58:41.629354  7628 sgd_solver.cpp:137] Iteration 5800, lr = 0.0909375, m = 0.9
I0628 18:58:43.337491  7628 solver.cpp:349] Iteration 5900 (58.5456 iter/s, 1.70807s/100 iter), loss = 0.4415
I0628 18:58:43.337512  7628 solver.cpp:371]     Train net output #0: loss = 0.4415 (* 1 = 0.4415 loss)
I0628 18:58:43.337517  7628 sgd_solver.cpp:137] Iteration 5900, lr = 0.0907812, m = 0.9
I0628 18:58:45.026653  7628 solver.cpp:545] Iteration 6000, Testing net (#0)
I0628 18:58:46.033563  7626 data_reader.cpp:262] Starting prefetch of epoch 6
I0628 18:58:46.055513  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.739
I0628 18:58:46.055538  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9826
I0628 18:58:46.055544  7628 solver.cpp:630]     Test net output #2: loss = 0.816913 (* 1 = 0.816913 loss)
I0628 18:58:46.055558  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02887s
I0628 18:58:46.072798  7628 solver.cpp:349] Iteration 6000 (36.5606 iter/s, 2.73518s/100 iter), loss = 0.498414
I0628 18:58:46.072821  7628 solver.cpp:371]     Train net output #0: loss = 0.498414 (* 1 = 0.498414 loss)
I0628 18:58:46.072825  7628 sgd_solver.cpp:137] Iteration 6000, lr = 0.090625, m = 0.9
I0628 18:58:47.784095  7628 solver.cpp:349] Iteration 6100 (58.4384 iter/s, 1.7112s/100 iter), loss = 0.299796
I0628 18:58:47.784116  7628 solver.cpp:371]     Train net output #0: loss = 0.299796 (* 1 = 0.299796 loss)
I0628 18:58:47.784119  7628 sgd_solver.cpp:137] Iteration 6100, lr = 0.0904688, m = 0.9
I0628 18:58:49.495116  7628 solver.cpp:349] Iteration 6200 (58.4478 iter/s, 1.71093s/100 iter), loss = 0.148227
I0628 18:58:49.495139  7628 solver.cpp:371]     Train net output #0: loss = 0.148227 (* 1 = 0.148227 loss)
I0628 18:58:49.495143  7628 sgd_solver.cpp:137] Iteration 6200, lr = 0.0903125, m = 0.9
I0628 18:58:50.280009  7613 data_reader.cpp:262] Starting prefetch of epoch 8
I0628 18:58:51.203538  7628 solver.cpp:349] Iteration 6300 (58.5368 iter/s, 1.70833s/100 iter), loss = 0.507794
I0628 18:58:51.203558  7628 solver.cpp:371]     Train net output #0: loss = 0.507794 (* 1 = 0.507794 loss)
I0628 18:58:51.203562  7628 sgd_solver.cpp:137] Iteration 6300, lr = 0.0901562, m = 0.9
I0628 18:58:52.917884  7628 solver.cpp:349] Iteration 6400 (58.3344 iter/s, 1.71425s/100 iter), loss = 0.208579
I0628 18:58:52.917906  7628 solver.cpp:371]     Train net output #0: loss = 0.208579 (* 1 = 0.208579 loss)
I0628 18:58:52.917910  7628 sgd_solver.cpp:137] Iteration 6400, lr = 0.09, m = 0.9
I0628 18:58:54.627974  7628 solver.cpp:349] Iteration 6500 (58.4796 iter/s, 1.71s/100 iter), loss = 0.650913
I0628 18:58:54.627997  7628 solver.cpp:371]     Train net output #0: loss = 0.650913 (* 1 = 0.650913 loss)
I0628 18:58:54.628002  7628 sgd_solver.cpp:137] Iteration 6500, lr = 0.0898438, m = 0.9
I0628 18:58:56.339025  7628 solver.cpp:349] Iteration 6600 (58.4468 iter/s, 1.71096s/100 iter), loss = 0.325468
I0628 18:58:56.339128  7628 solver.cpp:371]     Train net output #0: loss = 0.325468 (* 1 = 0.325468 loss)
I0628 18:58:56.339134  7628 sgd_solver.cpp:137] Iteration 6600, lr = 0.0896875, m = 0.9
I0628 18:58:58.059311  7628 solver.cpp:349] Iteration 6700 (58.136 iter/s, 1.72011s/100 iter), loss = 0.232637
I0628 18:58:58.059334  7628 solver.cpp:371]     Train net output #0: loss = 0.232637 (* 1 = 0.232637 loss)
I0628 18:58:58.059339  7628 sgd_solver.cpp:137] Iteration 6700, lr = 0.0895313, m = 0.9
I0628 18:58:59.771634  7628 solver.cpp:349] Iteration 6800 (58.4034 iter/s, 1.71223s/100 iter), loss = 0.352915
I0628 18:58:59.771657  7628 solver.cpp:371]     Train net output #0: loss = 0.352915 (* 1 = 0.352915 loss)
I0628 18:58:59.771663  7628 sgd_solver.cpp:137] Iteration 6800, lr = 0.089375, m = 0.9
I0628 18:59:01.486265  7628 solver.cpp:349] Iteration 6900 (58.325 iter/s, 1.71453s/100 iter), loss = 0.293398
I0628 18:59:01.486287  7628 solver.cpp:371]     Train net output #0: loss = 0.293398 (* 1 = 0.293398 loss)
I0628 18:59:01.486292  7628 sgd_solver.cpp:137] Iteration 6900, lr = 0.0892188, m = 0.9
I0628 18:59:03.179867  7628 solver.cpp:545] Iteration 7000, Testing net (#0)
I0628 18:59:04.187443  7626 data_reader.cpp:262] Starting prefetch of epoch 7
I0628 18:59:04.208379  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.6106
I0628 18:59:04.208395  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9572
I0628 18:59:04.208400  7628 solver.cpp:630]     Test net output #2: loss = 1.54411 (* 1 = 1.54411 loss)
I0628 18:59:04.208418  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02852s
I0628 18:59:04.229830  7628 solver.cpp:349] Iteration 7000 (36.4506 iter/s, 2.74344s/100 iter), loss = 0.504363
I0628 18:59:04.229852  7628 solver.cpp:371]     Train net output #0: loss = 0.504363 (* 1 = 0.504363 loss)
I0628 18:59:04.229857  7628 sgd_solver.cpp:137] Iteration 7000, lr = 0.0890625, m = 0.9
I0628 18:59:04.708396  7613 data_reader.cpp:262] Starting prefetch of epoch 9
I0628 18:59:05.942025  7628 solver.cpp:349] Iteration 7100 (58.4078 iter/s, 1.7121s/100 iter), loss = 0.124974
I0628 18:59:05.942046  7628 solver.cpp:371]     Train net output #0: loss = 0.124974 (* 1 = 0.124974 loss)
I0628 18:59:05.942050  7628 sgd_solver.cpp:137] Iteration 7100, lr = 0.0889063, m = 0.9
I0628 18:59:07.654798  7628 solver.cpp:349] Iteration 7200 (58.388 iter/s, 1.71268s/100 iter), loss = 0.255013
I0628 18:59:07.654820  7628 solver.cpp:371]     Train net output #0: loss = 0.255013 (* 1 = 0.255013 loss)
I0628 18:59:07.654826  7628 sgd_solver.cpp:137] Iteration 7200, lr = 0.08875, m = 0.9
I0628 18:59:09.372557  7628 solver.cpp:349] Iteration 7300 (58.2187 iter/s, 1.71766s/100 iter), loss = 0.422509
I0628 18:59:09.372579  7628 solver.cpp:371]     Train net output #0: loss = 0.422509 (* 1 = 0.422509 loss)
I0628 18:59:09.372584  7628 sgd_solver.cpp:137] Iteration 7300, lr = 0.0885938, m = 0.9
I0628 18:59:11.081279  7628 solver.cpp:349] Iteration 7400 (58.5266 iter/s, 1.70863s/100 iter), loss = 0.20628
I0628 18:59:11.081301  7628 solver.cpp:371]     Train net output #0: loss = 0.20628 (* 1 = 0.20628 loss)
I0628 18:59:11.081306  7628 sgd_solver.cpp:137] Iteration 7400, lr = 0.0884375, m = 0.9
I0628 18:59:12.794934  7628 solver.cpp:349] Iteration 7500 (58.3581 iter/s, 1.71356s/100 iter), loss = 0.184212
I0628 18:59:12.794955  7628 solver.cpp:371]     Train net output #0: loss = 0.184212 (* 1 = 0.184212 loss)
I0628 18:59:12.794960  7628 sgd_solver.cpp:137] Iteration 7500, lr = 0.0882813, m = 0.9
I0628 18:59:14.505671  7628 solver.cpp:349] Iteration 7600 (58.4576 iter/s, 1.71064s/100 iter), loss = 0.448168
I0628 18:59:14.505692  7628 solver.cpp:371]     Train net output #0: loss = 0.448168 (* 1 = 0.448168 loss)
I0628 18:59:14.505697  7628 sgd_solver.cpp:137] Iteration 7600, lr = 0.088125, m = 0.9
I0628 18:59:16.216424  7628 solver.cpp:349] Iteration 7700 (58.457 iter/s, 1.71066s/100 iter), loss = 0.345105
I0628 18:59:16.216444  7628 solver.cpp:371]     Train net output #0: loss = 0.345105 (* 1 = 0.345105 loss)
I0628 18:59:16.216449  7628 sgd_solver.cpp:137] Iteration 7700, lr = 0.0879688, m = 0.9
I0628 18:59:17.934273  7628 solver.cpp:349] Iteration 7800 (58.2161 iter/s, 1.71774s/100 iter), loss = 0.294949
I0628 18:59:17.934293  7628 solver.cpp:371]     Train net output #0: loss = 0.294949 (* 1 = 0.294949 loss)
I0628 18:59:17.934298  7628 sgd_solver.cpp:137] Iteration 7800, lr = 0.0878125, m = 0.9
I0628 18:59:18.088512  7613 data_reader.cpp:262] Starting prefetch of epoch 10
I0628 18:59:19.648531  7628 solver.cpp:349] Iteration 7900 (58.3374 iter/s, 1.71416s/100 iter), loss = 0.183327
I0628 18:59:19.648555  7628 solver.cpp:371]     Train net output #0: loss = 0.183327 (* 1 = 0.183327 loss)
I0628 18:59:19.648558  7628 sgd_solver.cpp:137] Iteration 7900, lr = 0.0876563, m = 0.9
I0628 18:59:21.345592  7628 solver.cpp:545] Iteration 8000, Testing net (#0)
I0628 18:59:22.353842  7626 data_reader.cpp:262] Starting prefetch of epoch 8
I0628 18:59:22.374259  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.7918
I0628 18:59:22.374274  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9844
I0628 18:59:22.374279  7628 solver.cpp:630]     Test net output #2: loss = 0.668494 (* 1 = 0.668494 loss)
I0628 18:59:22.374292  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02867s
I0628 18:59:22.391546  7628 solver.cpp:349] Iteration 8000 (36.458 iter/s, 2.74289s/100 iter), loss = 0.0587083
I0628 18:59:22.391568  7628 solver.cpp:371]     Train net output #0: loss = 0.0587083 (* 1 = 0.0587083 loss)
I0628 18:59:22.391572  7628 sgd_solver.cpp:137] Iteration 8000, lr = 0.0875, m = 0.9
I0628 18:59:24.111915  7628 solver.cpp:349] Iteration 8100 (58.1302 iter/s, 1.72027s/100 iter), loss = 0.172685
I0628 18:59:24.111937  7628 solver.cpp:371]     Train net output #0: loss = 0.172685 (* 1 = 0.172685 loss)
I0628 18:59:24.111940  7628 sgd_solver.cpp:137] Iteration 8100, lr = 0.0873438, m = 0.9
I0628 18:59:25.824093  7628 solver.cpp:349] Iteration 8200 (58.4083 iter/s, 1.71209s/100 iter), loss = 0.356011
I0628 18:59:25.824116  7628 solver.cpp:371]     Train net output #0: loss = 0.356011 (* 1 = 0.356011 loss)
I0628 18:59:25.824120  7628 sgd_solver.cpp:137] Iteration 8200, lr = 0.0871875, m = 0.9
I0628 18:59:27.535820  7628 solver.cpp:349] Iteration 8300 (58.4238 iter/s, 1.71163s/100 iter), loss = 0.258547
I0628 18:59:27.535892  7628 solver.cpp:371]     Train net output #0: loss = 0.258547 (* 1 = 0.258547 loss)
I0628 18:59:27.535897  7628 sgd_solver.cpp:137] Iteration 8300, lr = 0.0870313, m = 0.9
I0628 18:59:29.250907  7628 solver.cpp:349] Iteration 8400 (58.311 iter/s, 1.71494s/100 iter), loss = 0.353219
I0628 18:59:29.250926  7628 solver.cpp:371]     Train net output #0: loss = 0.353219 (* 1 = 0.353219 loss)
I0628 18:59:29.250931  7628 sgd_solver.cpp:137] Iteration 8400, lr = 0.086875, m = 0.9
I0628 18:59:30.961786  7628 solver.cpp:349] Iteration 8500 (58.4526 iter/s, 1.71079s/100 iter), loss = 0.197068
I0628 18:59:30.961807  7628 solver.cpp:371]     Train net output #0: loss = 0.197069 (* 1 = 0.197069 loss)
I0628 18:59:30.961812  7628 sgd_solver.cpp:137] Iteration 8500, lr = 0.0867188, m = 0.9
I0628 18:59:32.503006  7613 data_reader.cpp:262] Starting prefetch of epoch 11
I0628 18:59:32.673987  7628 solver.cpp:349] Iteration 8600 (58.4075 iter/s, 1.71211s/100 iter), loss = 0.0931155
I0628 18:59:32.674010  7628 solver.cpp:371]     Train net output #0: loss = 0.0931156 (* 1 = 0.0931156 loss)
I0628 18:59:32.674013  7628 sgd_solver.cpp:137] Iteration 8600, lr = 0.0865625, m = 0.9
I0628 18:59:34.387147  7628 solver.cpp:349] Iteration 8700 (58.3748 iter/s, 1.71307s/100 iter), loss = 0.122131
I0628 18:59:34.387169  7628 solver.cpp:371]     Train net output #0: loss = 0.122131 (* 1 = 0.122131 loss)
I0628 18:59:34.387173  7628 sgd_solver.cpp:137] Iteration 8700, lr = 0.0864063, m = 0.9
I0628 18:59:36.094295  7628 solver.cpp:349] Iteration 8800 (58.5805 iter/s, 1.70705s/100 iter), loss = 0.385177
I0628 18:59:36.094314  7628 solver.cpp:371]     Train net output #0: loss = 0.385177 (* 1 = 0.385177 loss)
I0628 18:59:36.094319  7628 sgd_solver.cpp:137] Iteration 8800, lr = 0.08625, m = 0.9
I0628 18:59:37.809098  7628 solver.cpp:349] Iteration 8900 (58.319 iter/s, 1.71471s/100 iter), loss = 0.160747
I0628 18:59:37.809120  7628 solver.cpp:371]     Train net output #0: loss = 0.160747 (* 1 = 0.160747 loss)
I0628 18:59:37.809124  7628 sgd_solver.cpp:137] Iteration 8900, lr = 0.0860937, m = 0.9
I0628 18:59:39.504081  7628 solver.cpp:545] Iteration 9000, Testing net (#0)
I0628 18:59:40.510597  7626 data_reader.cpp:262] Starting prefetch of epoch 9
I0628 18:59:40.531467  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.7536
I0628 18:59:40.531481  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.977601
I0628 18:59:40.531488  7628 solver.cpp:630]     Test net output #2: loss = 0.837314 (* 1 = 0.837314 loss)
I0628 18:59:40.531504  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02739s
I0628 18:59:40.548750  7628 solver.cpp:349] Iteration 9000 (36.5027 iter/s, 2.73953s/100 iter), loss = 0.147756
I0628 18:59:40.548774  7628 solver.cpp:371]     Train net output #0: loss = 0.147757 (* 1 = 0.147757 loss)
I0628 18:59:40.548779  7628 sgd_solver.cpp:137] Iteration 9000, lr = 0.0859375, m = 0.9
I0628 18:59:42.258196  7628 solver.cpp:349] Iteration 9100 (58.5018 iter/s, 1.70935s/100 iter), loss = 0.115033
I0628 18:59:42.258218  7628 solver.cpp:371]     Train net output #0: loss = 0.115033 (* 1 = 0.115033 loss)
I0628 18:59:42.258222  7628 sgd_solver.cpp:137] Iteration 9100, lr = 0.0857813, m = 0.9
I0628 18:59:43.968487  7628 solver.cpp:349] Iteration 9200 (58.4728 iter/s, 1.7102s/100 iter), loss = 0.188793
I0628 18:59:43.968509  7628 solver.cpp:371]     Train net output #0: loss = 0.188793 (* 1 = 0.188793 loss)
I0628 18:59:43.968514  7628 sgd_solver.cpp:137] Iteration 9200, lr = 0.085625, m = 0.9
I0628 18:59:45.677125  7628 solver.cpp:349] Iteration 9300 (58.5295 iter/s, 1.70854s/100 iter), loss = 0.232534
I0628 18:59:45.677150  7628 solver.cpp:371]     Train net output #0: loss = 0.232534 (* 1 = 0.232534 loss)
I0628 18:59:45.677155  7628 sgd_solver.cpp:137] Iteration 9300, lr = 0.0854688, m = 0.9
I0628 18:59:46.896631  7613 data_reader.cpp:262] Starting prefetch of epoch 12
I0628 18:59:47.392678  7628 solver.cpp:349] Iteration 9400 (58.2936 iter/s, 1.71545s/100 iter), loss = 0.240122
I0628 18:59:47.392701  7628 solver.cpp:371]     Train net output #0: loss = 0.240122 (* 1 = 0.240122 loss)
I0628 18:59:47.392722  7628 sgd_solver.cpp:137] Iteration 9400, lr = 0.0853125, m = 0.9
I0628 18:59:49.103521  7628 solver.cpp:349] Iteration 9500 (58.4547 iter/s, 1.71073s/100 iter), loss = 0.276256
I0628 18:59:49.103543  7628 solver.cpp:371]     Train net output #0: loss = 0.276256 (* 1 = 0.276256 loss)
I0628 18:59:49.103548  7628 sgd_solver.cpp:137] Iteration 9500, lr = 0.0851563, m = 0.9
I0628 18:59:50.815011  7628 solver.cpp:349] Iteration 9600 (58.4318 iter/s, 1.7114s/100 iter), loss = 0.215347
I0628 18:59:50.815032  7628 solver.cpp:371]     Train net output #0: loss = 0.215348 (* 1 = 0.215348 loss)
I0628 18:59:50.815037  7628 sgd_solver.cpp:137] Iteration 9600, lr = 0.085, m = 0.9
I0628 18:59:52.528447  7628 solver.cpp:349] Iteration 9700 (58.3654 iter/s, 1.71334s/100 iter), loss = 0.113045
I0628 18:59:52.528470  7628 solver.cpp:371]     Train net output #0: loss = 0.113046 (* 1 = 0.113046 loss)
I0628 18:59:52.528473  7628 sgd_solver.cpp:137] Iteration 9700, lr = 0.0848437, m = 0.9
I0628 18:59:54.238328  7628 solver.cpp:349] Iteration 9800 (58.4868 iter/s, 1.70979s/100 iter), loss = 0.215752
I0628 18:59:54.238351  7628 solver.cpp:371]     Train net output #0: loss = 0.215752 (* 1 = 0.215752 loss)
I0628 18:59:54.238355  7628 sgd_solver.cpp:137] Iteration 9800, lr = 0.0846875, m = 0.9
I0628 18:59:55.954592  7628 solver.cpp:349] Iteration 9900 (58.2693 iter/s, 1.71617s/100 iter), loss = 0.237879
I0628 18:59:55.954614  7628 solver.cpp:371]     Train net output #0: loss = 0.23788 (* 1 = 0.23788 loss)
I0628 18:59:55.954618  7628 sgd_solver.cpp:137] Iteration 9900, lr = 0.0845312, m = 0.9
I0628 18:59:57.649991  7628 solver.cpp:675] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-06-28_18-56-45/initial/cifar10_jacintonet11v2_iter_10000.caffemodel
I0628 18:59:57.664676  7628 sgd_solver.cpp:288] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-06-28_18-56-45/initial/cifar10_jacintonet11v2_iter_10000.solverstate
I0628 18:59:57.668166  7628 solver.cpp:545] Iteration 10000, Testing net (#0)
I0628 18:59:58.677172  7626 data_reader.cpp:262] Starting prefetch of epoch 10
I0628 18:59:58.697583  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.7392
I0628 18:59:58.697597  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9838
I0628 18:59:58.697602  7628 solver.cpp:630]     Test net output #2: loss = 0.99326 (* 1 = 0.99326 loss)
I0628 18:59:58.697614  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02941s
I0628 18:59:58.714846  7628 solver.cpp:349] Iteration 10000 (36.2302 iter/s, 2.76013s/100 iter), loss = 0.114256
I0628 18:59:58.714869  7628 solver.cpp:371]     Train net output #0: loss = 0.114256 (* 1 = 0.114256 loss)
I0628 18:59:58.714874  7628 sgd_solver.cpp:137] Iteration 10000, lr = 0.084375, m = 0.9
I0628 19:00:00.433503  7628 solver.cpp:349] Iteration 10100 (58.1882 iter/s, 1.71856s/100 iter), loss = 0.186613
I0628 19:00:00.433528  7628 solver.cpp:371]     Train net output #0: loss = 0.186614 (* 1 = 0.186614 loss)
I0628 19:00:00.433532  7628 sgd_solver.cpp:137] Iteration 10100, lr = 0.0842188, m = 0.9
I0628 19:00:01.339294  7613 data_reader.cpp:262] Starting prefetch of epoch 13
I0628 19:00:02.142325  7628 solver.cpp:349] Iteration 10200 (58.5232 iter/s, 1.70873s/100 iter), loss = 0.126598
I0628 19:00:02.142348  7628 solver.cpp:371]     Train net output #0: loss = 0.126598 (* 1 = 0.126598 loss)
I0628 19:00:02.142351  7628 sgd_solver.cpp:137] Iteration 10200, lr = 0.0840625, m = 0.9
I0628 19:00:03.856747  7628 solver.cpp:349] Iteration 10300 (58.3319 iter/s, 1.71433s/100 iter), loss = 0.136496
I0628 19:00:03.856768  7628 solver.cpp:371]     Train net output #0: loss = 0.136496 (* 1 = 0.136496 loss)
I0628 19:00:03.856772  7628 sgd_solver.cpp:137] Iteration 10300, lr = 0.0839063, m = 0.9
I0628 19:00:05.575719  7628 solver.cpp:349] Iteration 10400 (58.1775 iter/s, 1.71888s/100 iter), loss = 0.321512
I0628 19:00:05.575742  7628 solver.cpp:371]     Train net output #0: loss = 0.321513 (* 1 = 0.321513 loss)
I0628 19:00:05.575747  7628 sgd_solver.cpp:137] Iteration 10400, lr = 0.08375, m = 0.9
I0628 19:00:07.286770  7628 solver.cpp:349] Iteration 10500 (58.4468 iter/s, 1.71096s/100 iter), loss = 0.249485
I0628 19:00:07.286789  7628 solver.cpp:371]     Train net output #0: loss = 0.249485 (* 1 = 0.249485 loss)
I0628 19:00:07.286793  7628 sgd_solver.cpp:137] Iteration 10500, lr = 0.0835937, m = 0.9
I0628 19:00:08.998852  7628 solver.cpp:349] Iteration 10600 (58.4115 iter/s, 1.71199s/100 iter), loss = 0.270804
I0628 19:00:08.998874  7628 solver.cpp:371]     Train net output #0: loss = 0.270805 (* 1 = 0.270805 loss)
I0628 19:00:08.998878  7628 sgd_solver.cpp:137] Iteration 10600, lr = 0.0834375, m = 0.9
I0628 19:00:10.711431  7628 solver.cpp:349] Iteration 10700 (58.3947 iter/s, 1.71248s/100 iter), loss = 0.0600235
I0628 19:00:10.711452  7628 solver.cpp:371]     Train net output #0: loss = 0.0600239 (* 1 = 0.0600239 loss)
I0628 19:00:10.711457  7628 sgd_solver.cpp:137] Iteration 10700, lr = 0.0832812, m = 0.9
I0628 19:00:12.427345  7628 solver.cpp:349] Iteration 10800 (58.2811 iter/s, 1.71582s/100 iter), loss = 0.0713831
I0628 19:00:12.427367  7628 solver.cpp:371]     Train net output #0: loss = 0.0713836 (* 1 = 0.0713836 loss)
I0628 19:00:12.427372  7628 sgd_solver.cpp:137] Iteration 10800, lr = 0.083125, m = 0.9
I0628 19:00:14.138257  7628 solver.cpp:349] Iteration 10900 (58.4516 iter/s, 1.71082s/100 iter), loss = 0.143183
I0628 19:00:14.138280  7628 solver.cpp:371]     Train net output #0: loss = 0.143184 (* 1 = 0.143184 loss)
I0628 19:00:14.138284  7628 sgd_solver.cpp:137] Iteration 10900, lr = 0.0829687, m = 0.9
I0628 19:00:14.724583  7613 data_reader.cpp:262] Starting prefetch of epoch 14
I0628 19:00:15.836019  7628 solver.cpp:545] Iteration 11000, Testing net (#0)
I0628 19:00:16.846747  7626 data_reader.cpp:262] Starting prefetch of epoch 11
I0628 19:00:16.867131  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.819
I0628 19:00:16.867142  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9898
I0628 19:00:16.867147  7628 solver.cpp:630]     Test net output #2: loss = 0.626114 (* 1 = 0.626114 loss)
I0628 19:00:16.867161  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.03111s
I0628 19:00:16.884371  7628 solver.cpp:349] Iteration 11000 (36.4168 iter/s, 2.74599s/100 iter), loss = 0.408234
I0628 19:00:16.884393  7628 solver.cpp:371]     Train net output #0: loss = 0.408234 (* 1 = 0.408234 loss)
I0628 19:00:16.884397  7628 sgd_solver.cpp:137] Iteration 11000, lr = 0.0828125, m = 0.9
I0628 19:00:18.599318  7628 solver.cpp:349] Iteration 11100 (58.3141 iter/s, 1.71485s/100 iter), loss = 0.106473
I0628 19:00:18.599341  7628 solver.cpp:371]     Train net output #0: loss = 0.106473 (* 1 = 0.106473 loss)
I0628 19:00:18.599346  7628 sgd_solver.cpp:137] Iteration 11100, lr = 0.0826563, m = 0.9
I0628 19:00:20.316668  7628 solver.cpp:349] Iteration 11200 (58.2325 iter/s, 1.71725s/100 iter), loss = 0.192165
I0628 19:00:20.316689  7628 solver.cpp:371]     Train net output #0: loss = 0.192165 (* 1 = 0.192165 loss)
I0628 19:00:20.316694  7628 sgd_solver.cpp:137] Iteration 11200, lr = 0.0825, m = 0.9
I0628 19:00:22.034867  7628 solver.cpp:349] Iteration 11300 (58.2037 iter/s, 1.7181s/100 iter), loss = 0.190229
I0628 19:00:22.034886  7628 solver.cpp:371]     Train net output #0: loss = 0.190229 (* 1 = 0.190229 loss)
I0628 19:00:22.034891  7628 sgd_solver.cpp:137] Iteration 11300, lr = 0.0823437, m = 0.9
I0628 19:00:23.747957  7628 solver.cpp:349] Iteration 11400 (58.3772 iter/s, 1.713s/100 iter), loss = 0.207648
I0628 19:00:23.747980  7628 solver.cpp:371]     Train net output #0: loss = 0.207648 (* 1 = 0.207648 loss)
I0628 19:00:23.747984  7628 sgd_solver.cpp:137] Iteration 11400, lr = 0.0821875, m = 0.9
I0628 19:00:25.460595  7628 solver.cpp:349] Iteration 11500 (58.3927 iter/s, 1.71254s/100 iter), loss = 0.258353
I0628 19:00:25.460616  7628 solver.cpp:371]     Train net output #0: loss = 0.258354 (* 1 = 0.258354 loss)
I0628 19:00:25.460621  7628 sgd_solver.cpp:137] Iteration 11500, lr = 0.0820312, m = 0.9
I0628 19:00:27.173782  7628 solver.cpp:349] Iteration 11600 (58.374 iter/s, 1.71309s/100 iter), loss = 0.312742
I0628 19:00:27.173805  7628 solver.cpp:371]     Train net output #0: loss = 0.312743 (* 1 = 0.312743 loss)
I0628 19:00:27.173810  7628 sgd_solver.cpp:137] Iteration 11600, lr = 0.081875, m = 0.9
I0628 19:00:28.887151  7628 solver.cpp:349] Iteration 11700 (58.3678 iter/s, 1.71327s/100 iter), loss = 0.0974607
I0628 19:00:28.887200  7628 solver.cpp:371]     Train net output #0: loss = 0.0974611 (* 1 = 0.0974611 loss)
I0628 19:00:28.887207  7628 sgd_solver.cpp:137] Iteration 11700, lr = 0.0817188, m = 0.9
I0628 19:00:29.144381  7613 data_reader.cpp:262] Starting prefetch of epoch 15
I0628 19:00:30.602329  7628 solver.cpp:349] Iteration 11800 (58.3073 iter/s, 1.71505s/100 iter), loss = 0.236051
I0628 19:00:30.602351  7628 solver.cpp:371]     Train net output #0: loss = 0.236051 (* 1 = 0.236051 loss)
I0628 19:00:30.602357  7628 sgd_solver.cpp:137] Iteration 11800, lr = 0.0815625, m = 0.9
I0628 19:00:32.316040  7628 solver.cpp:349] Iteration 11900 (58.3562 iter/s, 1.71361s/100 iter), loss = 0.0998526
I0628 19:00:32.316059  7628 solver.cpp:371]     Train net output #0: loss = 0.0998531 (* 1 = 0.0998531 loss)
I0628 19:00:32.316064  7628 sgd_solver.cpp:137] Iteration 11900, lr = 0.0814063, m = 0.9
I0628 19:00:34.009630  7628 solver.cpp:545] Iteration 12000, Testing net (#0)
I0628 19:00:35.016335  7626 data_reader.cpp:262] Starting prefetch of epoch 12
I0628 19:00:35.036870  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.7586
I0628 19:00:35.036885  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9766
I0628 19:00:35.036890  7628 solver.cpp:630]     Test net output #2: loss = 0.901653 (* 1 = 0.901653 loss)
I0628 19:00:35.036905  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02724s
I0628 19:00:35.054491  7628 solver.cpp:349] Iteration 12000 (36.5187 iter/s, 2.73833s/100 iter), loss = 0.204839
I0628 19:00:35.054514  7628 solver.cpp:371]     Train net output #0: loss = 0.204839 (* 1 = 0.204839 loss)
I0628 19:00:35.054518  7628 sgd_solver.cpp:137] Iteration 12000, lr = 0.08125, m = 0.9
I0628 19:00:36.768368  7628 solver.cpp:349] Iteration 12100 (58.3505 iter/s, 1.71378s/100 iter), loss = 0.225372
I0628 19:00:36.768391  7628 solver.cpp:371]     Train net output #0: loss = 0.225372 (* 1 = 0.225372 loss)
I0628 19:00:36.768395  7628 sgd_solver.cpp:137] Iteration 12100, lr = 0.0810938, m = 0.9
I0628 19:00:38.482367  7628 solver.cpp:349] Iteration 12200 (58.3463 iter/s, 1.7139s/100 iter), loss = 0.185573
I0628 19:00:38.482390  7628 solver.cpp:371]     Train net output #0: loss = 0.185573 (* 1 = 0.185573 loss)
I0628 19:00:38.482394  7628 sgd_solver.cpp:137] Iteration 12200, lr = 0.0809375, m = 0.9
I0628 19:00:40.195760  7628 solver.cpp:349] Iteration 12300 (58.367 iter/s, 1.7133s/100 iter), loss = 0.0656828
I0628 19:00:40.195782  7628 solver.cpp:371]     Train net output #0: loss = 0.0656833 (* 1 = 0.0656833 loss)
I0628 19:00:40.195786  7628 sgd_solver.cpp:137] Iteration 12300, lr = 0.0807813, m = 0.9
I0628 19:00:41.905248  7628 solver.cpp:349] Iteration 12400 (58.5002 iter/s, 1.70939s/100 iter), loss = 0.0676406
I0628 19:00:41.905272  7628 solver.cpp:371]     Train net output #0: loss = 0.0676411 (* 1 = 0.0676411 loss)
I0628 19:00:41.905275  7628 sgd_solver.cpp:137] Iteration 12400, lr = 0.080625, m = 0.9
I0628 19:00:43.549695  7613 data_reader.cpp:262] Starting prefetch of epoch 16
I0628 19:00:43.618424  7628 solver.cpp:349] Iteration 12500 (58.3743 iter/s, 1.71308s/100 iter), loss = 0.0564481
I0628 19:00:43.618448  7628 solver.cpp:371]     Train net output #0: loss = 0.0564486 (* 1 = 0.0564486 loss)
I0628 19:00:43.618451  7628 sgd_solver.cpp:137] Iteration 12500, lr = 0.0804688, m = 0.9
I0628 19:00:45.331581  7628 solver.cpp:349] Iteration 12600 (58.375 iter/s, 1.71306s/100 iter), loss = 0.174829
I0628 19:00:45.331603  7628 solver.cpp:371]     Train net output #0: loss = 0.17483 (* 1 = 0.17483 loss)
I0628 19:00:45.331606  7628 sgd_solver.cpp:137] Iteration 12600, lr = 0.0803125, m = 0.9
I0628 19:00:47.042168  7628 solver.cpp:349] Iteration 12700 (58.4627 iter/s, 1.71049s/100 iter), loss = 0.115948
I0628 19:00:47.042189  7628 solver.cpp:371]     Train net output #0: loss = 0.115949 (* 1 = 0.115949 loss)
I0628 19:00:47.042194  7628 sgd_solver.cpp:137] Iteration 12700, lr = 0.0801563, m = 0.9
I0628 19:00:48.756283  7628 solver.cpp:349] Iteration 12800 (58.3423 iter/s, 1.71402s/100 iter), loss = 0.332341
I0628 19:00:48.756305  7628 solver.cpp:371]     Train net output #0: loss = 0.332342 (* 1 = 0.332342 loss)
I0628 19:00:48.756325  7628 sgd_solver.cpp:137] Iteration 12800, lr = 0.08, m = 0.9
I0628 19:00:50.468256  7628 solver.cpp:349] Iteration 12900 (58.416 iter/s, 1.71186s/100 iter), loss = 0.105072
I0628 19:00:50.468281  7628 solver.cpp:371]     Train net output #0: loss = 0.105073 (* 1 = 0.105073 loss)
I0628 19:00:50.468286  7628 sgd_solver.cpp:137] Iteration 12900, lr = 0.0798438, m = 0.9
I0628 19:00:52.163018  7628 solver.cpp:545] Iteration 13000, Testing net (#0)
I0628 19:00:53.172190  7626 data_reader.cpp:262] Starting prefetch of epoch 13
I0628 19:00:53.192456  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.8054
I0628 19:00:53.192468  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.979
I0628 19:00:53.192473  7628 solver.cpp:630]     Test net output #2: loss = 0.759524 (* 1 = 0.759524 loss)
I0628 19:00:53.192487  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02944s
I0628 19:00:53.209723  7628 solver.cpp:349] Iteration 13000 (36.4786 iter/s, 2.74134s/100 iter), loss = 0.243238
I0628 19:00:53.209746  7628 solver.cpp:371]     Train net output #0: loss = 0.243238 (* 1 = 0.243238 loss)
I0628 19:00:53.209750  7628 sgd_solver.cpp:137] Iteration 13000, lr = 0.0796875, m = 0.9
I0628 19:00:54.919363  7628 solver.cpp:349] Iteration 13100 (58.4951 iter/s, 1.70954s/100 iter), loss = 0.047774
I0628 19:00:54.919384  7628 solver.cpp:371]     Train net output #0: loss = 0.0477745 (* 1 = 0.0477745 loss)
I0628 19:00:54.919389  7628 sgd_solver.cpp:137] Iteration 13100, lr = 0.0795313, m = 0.9
I0628 19:00:56.635632  7628 solver.cpp:349] Iteration 13200 (58.2691 iter/s, 1.71618s/100 iter), loss = 0.0969247
I0628 19:00:56.635654  7628 solver.cpp:371]     Train net output #0: loss = 0.0969252 (* 1 = 0.0969252 loss)
I0628 19:00:56.635658  7628 sgd_solver.cpp:137] Iteration 13200, lr = 0.079375, m = 0.9
I0628 19:00:57.970258  7613 data_reader.cpp:262] Starting prefetch of epoch 17
I0628 19:00:58.347604  7628 solver.cpp:349] Iteration 13300 (58.4154 iter/s, 1.71188s/100 iter), loss = 0.162249
I0628 19:00:58.347625  7628 solver.cpp:371]     Train net output #0: loss = 0.16225 (* 1 = 0.16225 loss)
I0628 19:00:58.347628  7628 sgd_solver.cpp:137] Iteration 13300, lr = 0.0792188, m = 0.9
I0628 19:01:00.057996  7628 solver.cpp:349] Iteration 13400 (58.4693 iter/s, 1.7103s/100 iter), loss = 0.0838849
I0628 19:01:00.058080  7628 solver.cpp:371]     Train net output #0: loss = 0.0838855 (* 1 = 0.0838855 loss)
I0628 19:01:00.058087  7628 sgd_solver.cpp:137] Iteration 13400, lr = 0.0790625, m = 0.9
I0628 19:01:01.773780  7628 solver.cpp:349] Iteration 13500 (58.2879 iter/s, 1.71562s/100 iter), loss = 0.253003
I0628 19:01:01.773803  7628 solver.cpp:371]     Train net output #0: loss = 0.253003 (* 1 = 0.253003 loss)
I0628 19:01:01.773808  7628 sgd_solver.cpp:137] Iteration 13500, lr = 0.0789063, m = 0.9
I0628 19:01:03.484941  7628 solver.cpp:349] Iteration 13600 (58.4432 iter/s, 1.71106s/100 iter), loss = 0.231076
I0628 19:01:03.484964  7628 solver.cpp:371]     Train net output #0: loss = 0.231077 (* 1 = 0.231077 loss)
I0628 19:01:03.484971  7628 sgd_solver.cpp:137] Iteration 13600, lr = 0.07875, m = 0.9
I0628 19:01:05.197497  7628 solver.cpp:349] Iteration 13700 (58.3956 iter/s, 1.71246s/100 iter), loss = 0.201843
I0628 19:01:05.197518  7628 solver.cpp:371]     Train net output #0: loss = 0.201844 (* 1 = 0.201844 loss)
I0628 19:01:05.197525  7628 sgd_solver.cpp:137] Iteration 13700, lr = 0.0785938, m = 0.9
I0628 19:01:06.908433  7628 solver.cpp:349] Iteration 13800 (58.4509 iter/s, 1.71084s/100 iter), loss = 0.255508
I0628 19:01:06.908455  7628 solver.cpp:371]     Train net output #0: loss = 0.255509 (* 1 = 0.255509 loss)
I0628 19:01:06.908459  7628 sgd_solver.cpp:137] Iteration 13800, lr = 0.0784375, m = 0.9
I0628 19:01:08.629220  7628 solver.cpp:349] Iteration 13900 (58.1162 iter/s, 1.72069s/100 iter), loss = 0.216105
I0628 19:01:08.629242  7628 solver.cpp:371]     Train net output #0: loss = 0.216106 (* 1 = 0.216106 loss)
I0628 19:01:08.629246  7628 sgd_solver.cpp:137] Iteration 13900, lr = 0.0782812, m = 0.9
I0628 19:01:10.327332  7628 solver.cpp:545] Iteration 14000, Testing net (#0)
I0628 19:01:11.334349  7626 data_reader.cpp:262] Starting prefetch of epoch 14
I0628 19:01:11.357941  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.7944
I0628 19:01:11.357961  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.983801
I0628 19:01:11.357966  7628 solver.cpp:630]     Test net output #2: loss = 0.834006 (* 1 = 0.834006 loss)
I0628 19:01:11.357983  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.03062s
I0628 19:01:11.375288  7628 solver.cpp:349] Iteration 14000 (36.4174 iter/s, 2.74594s/100 iter), loss = 0.209353
I0628 19:01:11.375304  7628 solver.cpp:371]     Train net output #0: loss = 0.209353 (* 1 = 0.209353 loss)
I0628 19:01:11.375308  7628 sgd_solver.cpp:137] Iteration 14000, lr = 0.078125, m = 0.9
I0628 19:01:12.385795  7613 data_reader.cpp:262] Starting prefetch of epoch 18
I0628 19:01:13.085840  7628 solver.cpp:349] Iteration 14100 (58.4637 iter/s, 1.71046s/100 iter), loss = 0.299395
I0628 19:01:13.085862  7628 solver.cpp:371]     Train net output #0: loss = 0.299395 (* 1 = 0.299395 loss)
I0628 19:01:13.085866  7628 sgd_solver.cpp:137] Iteration 14100, lr = 0.0779688, m = 0.9
I0628 19:01:14.797941  7628 solver.cpp:349] Iteration 14200 (58.411 iter/s, 1.71201s/100 iter), loss = 0.110924
I0628 19:01:14.797963  7628 solver.cpp:371]     Train net output #0: loss = 0.110924 (* 1 = 0.110924 loss)
I0628 19:01:14.797968  7628 sgd_solver.cpp:137] Iteration 14200, lr = 0.0778125, m = 0.9
I0628 19:01:16.513340  7628 solver.cpp:349] Iteration 14300 (58.2987 iter/s, 1.71531s/100 iter), loss = 0.141536
I0628 19:01:16.513363  7628 solver.cpp:371]     Train net output #0: loss = 0.141536 (* 1 = 0.141536 loss)
I0628 19:01:16.513367  7628 sgd_solver.cpp:137] Iteration 14300, lr = 0.0776563, m = 0.9
I0628 19:01:18.222049  7628 solver.cpp:349] Iteration 14400 (58.527 iter/s, 1.70861s/100 iter), loss = 0.0302711
I0628 19:01:18.222074  7628 solver.cpp:371]     Train net output #0: loss = 0.0302717 (* 1 = 0.0302717 loss)
I0628 19:01:18.222077  7628 sgd_solver.cpp:137] Iteration 14400, lr = 0.0775, m = 0.9
I0628 19:01:19.934074  7628 solver.cpp:349] Iteration 14500 (58.4137 iter/s, 1.71193s/100 iter), loss = 0.0424164
I0628 19:01:19.934096  7628 solver.cpp:371]     Train net output #0: loss = 0.042417 (* 1 = 0.042417 loss)
I0628 19:01:19.934115  7628 sgd_solver.cpp:137] Iteration 14500, lr = 0.0773438, m = 0.9
I0628 19:01:21.644227  7628 solver.cpp:349] Iteration 14600 (58.4781 iter/s, 1.71004s/100 iter), loss = 0.201706
I0628 19:01:21.644249  7628 solver.cpp:371]     Train net output #0: loss = 0.201707 (* 1 = 0.201707 loss)
I0628 19:01:21.644253  7628 sgd_solver.cpp:137] Iteration 14600, lr = 0.0771875, m = 0.9
I0628 19:01:23.364027  7628 solver.cpp:349] Iteration 14700 (58.1496 iter/s, 1.7197s/100 iter), loss = 0.107836
I0628 19:01:23.364049  7628 solver.cpp:371]     Train net output #0: loss = 0.107836 (* 1 = 0.107836 loss)
I0628 19:01:23.364055  7628 sgd_solver.cpp:137] Iteration 14700, lr = 0.0770312, m = 0.9
I0628 19:01:25.075682  7628 solver.cpp:349] Iteration 14800 (58.4263 iter/s, 1.71156s/100 iter), loss = 0.145064
I0628 19:01:25.075703  7628 solver.cpp:371]     Train net output #0: loss = 0.145064 (* 1 = 0.145064 loss)
I0628 19:01:25.075707  7628 sgd_solver.cpp:137] Iteration 14800, lr = 0.076875, m = 0.9
I0628 19:01:25.761139  7613 data_reader.cpp:262] Starting prefetch of epoch 19
I0628 19:01:26.787044  7628 solver.cpp:349] Iteration 14900 (58.4362 iter/s, 1.71127s/100 iter), loss = 0.0956827
I0628 19:01:26.787065  7628 solver.cpp:371]     Train net output #0: loss = 0.0956833 (* 1 = 0.0956833 loss)
I0628 19:01:26.787070  7628 sgd_solver.cpp:137] Iteration 14900, lr = 0.0767187, m = 0.9
I0628 19:01:28.487818  7628 solver.cpp:545] Iteration 15000, Testing net (#0)
I0628 19:01:29.495463  7626 data_reader.cpp:262] Starting prefetch of epoch 15
I0628 19:01:29.516189  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.7782
I0628 19:01:29.516202  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9876
I0628 19:01:29.516208  7628 solver.cpp:630]     Test net output #2: loss = 0.760733 (* 1 = 0.760733 loss)
I0628 19:01:29.516225  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02837s
I0628 19:01:29.533433  7628 solver.cpp:349] Iteration 15000 (36.4131 iter/s, 2.74626s/100 iter), loss = 0.150676
I0628 19:01:29.533457  7628 solver.cpp:371]     Train net output #0: loss = 0.150677 (* 1 = 0.150677 loss)
I0628 19:01:29.533463  7628 sgd_solver.cpp:137] Iteration 15000, lr = 0.0765625, m = 0.9
I0628 19:01:31.248615  7628 solver.cpp:349] Iteration 15100 (58.3061 iter/s, 1.71509s/100 iter), loss = 0.247647
I0628 19:01:31.248690  7628 solver.cpp:371]     Train net output #0: loss = 0.247647 (* 1 = 0.247647 loss)
I0628 19:01:31.248698  7628 sgd_solver.cpp:137] Iteration 15100, lr = 0.0764063, m = 0.9
I0628 19:01:32.961988  7628 solver.cpp:349] Iteration 15200 (58.3697 iter/s, 1.71322s/100 iter), loss = 0.220546
I0628 19:01:32.962011  7628 solver.cpp:371]     Train net output #0: loss = 0.220547 (* 1 = 0.220547 loss)
I0628 19:01:32.962018  7628 sgd_solver.cpp:137] Iteration 15200, lr = 0.07625, m = 0.9
I0628 19:01:34.673091  7628 solver.cpp:349] Iteration 15300 (58.4452 iter/s, 1.711s/100 iter), loss = 0.199043
I0628 19:01:34.673115  7628 solver.cpp:371]     Train net output #0: loss = 0.199044 (* 1 = 0.199044 loss)
I0628 19:01:34.673118  7628 sgd_solver.cpp:137] Iteration 15300, lr = 0.0760938, m = 0.9
I0628 19:01:36.387403  7628 solver.cpp:349] Iteration 15400 (58.3358 iter/s, 1.71421s/100 iter), loss = 0.10147
I0628 19:01:36.387423  7628 solver.cpp:371]     Train net output #0: loss = 0.101471 (* 1 = 0.101471 loss)
I0628 19:01:36.387426  7628 sgd_solver.cpp:137] Iteration 15400, lr = 0.0759375, m = 0.9
I0628 19:01:38.098556  7628 solver.cpp:349] Iteration 15500 (58.4433 iter/s, 1.71106s/100 iter), loss = 0.201609
I0628 19:01:38.098577  7628 solver.cpp:371]     Train net output #0: loss = 0.201609 (* 1 = 0.201609 loss)
I0628 19:01:38.098582  7628 sgd_solver.cpp:137] Iteration 15500, lr = 0.0757812, m = 0.9
I0628 19:01:39.810825  7628 solver.cpp:349] Iteration 15600 (58.4052 iter/s, 1.71218s/100 iter), loss = 0.0450677
I0628 19:01:39.810848  7628 solver.cpp:371]     Train net output #0: loss = 0.0450682 (* 1 = 0.0450682 loss)
I0628 19:01:39.810853  7628 sgd_solver.cpp:137] Iteration 15600, lr = 0.075625, m = 0.9
I0628 19:01:40.170361  7613 data_reader.cpp:262] Starting prefetch of epoch 20
I0628 19:01:41.521721  7628 solver.cpp:349] Iteration 15700 (58.4522 iter/s, 1.7108s/100 iter), loss = 0.15556
I0628 19:01:41.521742  7628 solver.cpp:371]     Train net output #0: loss = 0.15556 (* 1 = 0.15556 loss)
I0628 19:01:41.521747  7628 sgd_solver.cpp:137] Iteration 15700, lr = 0.0754687, m = 0.9
I0628 19:01:43.232728  7628 solver.cpp:349] Iteration 15800 (58.4484 iter/s, 1.71091s/100 iter), loss = 0.0627177
I0628 19:01:43.232750  7628 solver.cpp:371]     Train net output #0: loss = 0.0627182 (* 1 = 0.0627182 loss)
I0628 19:01:43.232754  7628 sgd_solver.cpp:137] Iteration 15800, lr = 0.0753125, m = 0.9
I0628 19:01:44.946244  7628 solver.cpp:349] Iteration 15900 (58.3628 iter/s, 1.71342s/100 iter), loss = 0.0412791
I0628 19:01:44.946266  7628 solver.cpp:371]     Train net output #0: loss = 0.0412796 (* 1 = 0.0412796 loss)
I0628 19:01:44.946271  7628 sgd_solver.cpp:137] Iteration 15900, lr = 0.0751562, m = 0.9
I0628 19:01:46.648152  7628 solver.cpp:545] Iteration 16000, Testing net (#0)
I0628 19:01:47.658442  7626 data_reader.cpp:262] Starting prefetch of epoch 16
I0628 19:01:47.678848  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.817
I0628 19:01:47.678859  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.982401
I0628 19:01:47.678865  7628 solver.cpp:630]     Test net output #2: loss = 0.70037 (* 1 = 0.70037 loss)
I0628 19:01:47.678880  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.0307s
I0628 19:01:47.696147  7628 solver.cpp:349] Iteration 16000 (36.3666 iter/s, 2.74978s/100 iter), loss = 0.0383414
I0628 19:01:47.696171  7628 solver.cpp:371]     Train net output #0: loss = 0.0383419 (* 1 = 0.0383419 loss)
I0628 19:01:47.696175  7628 sgd_solver.cpp:137] Iteration 16000, lr = 0.075, m = 0.9
I0628 19:01:49.405478  7628 solver.cpp:349] Iteration 16100 (58.5057 iter/s, 1.70923s/100 iter), loss = 0.242713
I0628 19:01:49.405498  7628 solver.cpp:371]     Train net output #0: loss = 0.242713 (* 1 = 0.242713 loss)
I0628 19:01:49.405501  7628 sgd_solver.cpp:137] Iteration 16100, lr = 0.0748438, m = 0.9
I0628 19:01:51.117408  7628 solver.cpp:349] Iteration 16200 (58.4168 iter/s, 1.71184s/100 iter), loss = 0.313398
I0628 19:01:51.117429  7628 solver.cpp:371]     Train net output #0: loss = 0.313398 (* 1 = 0.313398 loss)
I0628 19:01:51.117446  7628 sgd_solver.cpp:137] Iteration 16200, lr = 0.0746875, m = 0.9
I0628 19:01:52.832142  7628 solver.cpp:349] Iteration 16300 (58.3217 iter/s, 1.71463s/100 iter), loss = 0.0471741
I0628 19:01:52.832166  7628 solver.cpp:371]     Train net output #0: loss = 0.0471746 (* 1 = 0.0471746 loss)
I0628 19:01:52.832171  7628 sgd_solver.cpp:137] Iteration 16300, lr = 0.0745312, m = 0.9
I0628 19:01:54.555857  7628 solver.cpp:349] Iteration 16400 (58.0176 iter/s, 1.72362s/100 iter), loss = 0.0955996
I0628 19:01:54.555878  7628 solver.cpp:371]     Train net output #0: loss = 0.0956001 (* 1 = 0.0956001 loss)
I0628 19:01:54.555883  7628 sgd_solver.cpp:137] Iteration 16400, lr = 0.074375, m = 0.9
I0628 19:01:54.608268  7613 data_reader.cpp:262] Starting prefetch of epoch 21
I0628 19:01:56.267971  7628 solver.cpp:349] Iteration 16500 (58.4106 iter/s, 1.71202s/100 iter), loss = 0.233595
I0628 19:01:56.267992  7628 solver.cpp:371]     Train net output #0: loss = 0.233596 (* 1 = 0.233596 loss)
I0628 19:01:56.267997  7628 sgd_solver.cpp:137] Iteration 16500, lr = 0.0742188, m = 0.9
I0628 19:01:57.982388  7628 solver.cpp:349] Iteration 16600 (58.3321 iter/s, 1.71432s/100 iter), loss = 0.112702
I0628 19:01:57.982410  7628 solver.cpp:371]     Train net output #0: loss = 0.112702 (* 1 = 0.112702 loss)
I0628 19:01:57.982414  7628 sgd_solver.cpp:137] Iteration 16600, lr = 0.0740625, m = 0.9
I0628 19:01:59.698839  7628 solver.cpp:349] Iteration 16700 (58.2629 iter/s, 1.71636s/100 iter), loss = 0.264605
I0628 19:01:59.698860  7628 solver.cpp:371]     Train net output #0: loss = 0.264606 (* 1 = 0.264606 loss)
I0628 19:01:59.698865  7628 sgd_solver.cpp:137] Iteration 16700, lr = 0.0739063, m = 0.9
I0628 19:02:01.414146  7628 solver.cpp:349] Iteration 16800 (58.3018 iter/s, 1.71521s/100 iter), loss = 0.178389
I0628 19:02:01.414199  7628 solver.cpp:371]     Train net output #0: loss = 0.178389 (* 1 = 0.178389 loss)
I0628 19:02:01.414206  7628 sgd_solver.cpp:137] Iteration 16800, lr = 0.07375, m = 0.9
I0628 19:02:03.131058  7628 solver.cpp:349] Iteration 16900 (58.2485 iter/s, 1.71678s/100 iter), loss = 0.0772925
I0628 19:02:03.131081  7628 solver.cpp:371]     Train net output #0: loss = 0.0772931 (* 1 = 0.0772931 loss)
I0628 19:02:03.131088  7628 sgd_solver.cpp:137] Iteration 16900, lr = 0.0735938, m = 0.9
I0628 19:02:04.827167  7628 solver.cpp:545] Iteration 17000, Testing net (#0)
I0628 19:02:05.834820  7626 data_reader.cpp:262] Starting prefetch of epoch 17
I0628 19:02:05.856271  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.8258
I0628 19:02:05.856283  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.99
I0628 19:02:05.856288  7628 solver.cpp:630]     Test net output #2: loss = 0.659182 (* 1 = 0.659182 loss)
I0628 19:02:05.856302  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.0291s
I0628 19:02:05.873535  7628 solver.cpp:349] Iteration 17000 (36.4651 iter/s, 2.74235s/100 iter), loss = 0.064513
I0628 19:02:05.873551  7628 solver.cpp:371]     Train net output #0: loss = 0.0645136 (* 1 = 0.0645136 loss)
I0628 19:02:05.873556  7628 sgd_solver.cpp:137] Iteration 17000, lr = 0.0734375, m = 0.9
I0628 19:02:07.590374  7628 solver.cpp:349] Iteration 17100 (58.2496 iter/s, 1.71675s/100 iter), loss = 0.0429606
I0628 19:02:07.590396  7628 solver.cpp:371]     Train net output #0: loss = 0.0429611 (* 1 = 0.0429611 loss)
I0628 19:02:07.590399  7628 sgd_solver.cpp:137] Iteration 17100, lr = 0.0732813, m = 0.9
I0628 19:02:09.028726  7613 data_reader.cpp:262] Starting prefetch of epoch 22
I0628 19:02:09.301760  7628 solver.cpp:349] Iteration 17200 (58.4353 iter/s, 1.71129s/100 iter), loss = 0.115812
I0628 19:02:09.301782  7628 solver.cpp:371]     Train net output #0: loss = 0.115812 (* 1 = 0.115812 loss)
I0628 19:02:09.301786  7628 sgd_solver.cpp:137] Iteration 17200, lr = 0.073125, m = 0.9
I0628 19:02:11.018302  7628 solver.cpp:349] Iteration 17300 (58.2598 iter/s, 1.71645s/100 iter), loss = 0.187114
I0628 19:02:11.018324  7628 solver.cpp:371]     Train net output #0: loss = 0.187115 (* 1 = 0.187115 loss)
I0628 19:02:11.018328  7628 sgd_solver.cpp:137] Iteration 17300, lr = 0.0729688, m = 0.9
I0628 19:02:12.731353  7628 solver.cpp:349] Iteration 17400 (58.3786 iter/s, 1.71296s/100 iter), loss = 0.343612
I0628 19:02:12.731375  7628 solver.cpp:371]     Train net output #0: loss = 0.343613 (* 1 = 0.343613 loss)
I0628 19:02:12.731380  7628 sgd_solver.cpp:137] Iteration 17400, lr = 0.0728125, m = 0.9
I0628 19:02:14.449165  7628 solver.cpp:349] Iteration 17500 (58.2169 iter/s, 1.71771s/100 iter), loss = 0.191918
I0628 19:02:14.449187  7628 solver.cpp:371]     Train net output #0: loss = 0.191918 (* 1 = 0.191918 loss)
I0628 19:02:14.449190  7628 sgd_solver.cpp:137] Iteration 17500, lr = 0.0726563, m = 0.9
I0628 19:02:16.168869  7628 solver.cpp:349] Iteration 17600 (58.1528 iter/s, 1.71961s/100 iter), loss = 0.0775687
I0628 19:02:16.168893  7628 solver.cpp:371]     Train net output #0: loss = 0.0775692 (* 1 = 0.0775692 loss)
I0628 19:02:16.168897  7628 sgd_solver.cpp:137] Iteration 17600, lr = 0.0725, m = 0.9
I0628 19:02:17.879652  7628 solver.cpp:349] Iteration 17700 (58.4561 iter/s, 1.71069s/100 iter), loss = 0.19436
I0628 19:02:17.879675  7628 solver.cpp:371]     Train net output #0: loss = 0.194361 (* 1 = 0.194361 loss)
I0628 19:02:17.879679  7628 sgd_solver.cpp:137] Iteration 17700, lr = 0.0723438, m = 0.9
I0628 19:02:19.593752  7628 solver.cpp:349] Iteration 17800 (58.3429 iter/s, 1.714s/100 iter), loss = 0.167825
I0628 19:02:19.593775  7628 solver.cpp:371]     Train net output #0: loss = 0.167825 (* 1 = 0.167825 loss)
I0628 19:02:19.593780  7628 sgd_solver.cpp:137] Iteration 17800, lr = 0.0721875, m = 0.9
I0628 19:02:21.304932  7628 solver.cpp:349] Iteration 17900 (58.4425 iter/s, 1.71108s/100 iter), loss = 0.108304
I0628 19:02:21.304955  7628 solver.cpp:371]     Train net output #0: loss = 0.108305 (* 1 = 0.108305 loss)
I0628 19:02:21.304980  7628 sgd_solver.cpp:137] Iteration 17900, lr = 0.0720313, m = 0.9
I0628 19:02:22.420881  7613 data_reader.cpp:262] Starting prefetch of epoch 23
I0628 19:02:23.004319  7628 solver.cpp:545] Iteration 18000, Testing net (#0)
I0628 19:02:24.011137  7626 data_reader.cpp:262] Starting prefetch of epoch 18
I0628 19:02:24.031456  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.7576
I0628 19:02:24.031471  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9844
I0628 19:02:24.031476  7628 solver.cpp:630]     Test net output #2: loss = 1.01993 (* 1 = 1.01993 loss)
I0628 19:02:24.031489  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02714s
I0628 19:02:24.048673  7628 solver.cpp:349] Iteration 18000 (36.4486 iter/s, 2.74359s/100 iter), loss = 0.156118
I0628 19:02:24.048696  7628 solver.cpp:371]     Train net output #0: loss = 0.156119 (* 1 = 0.156119 loss)
I0628 19:02:24.048701  7628 sgd_solver.cpp:137] Iteration 18000, lr = 0.071875, m = 0.9
I0628 19:02:25.765646  7628 solver.cpp:349] Iteration 18100 (58.2454 iter/s, 1.71688s/100 iter), loss = 0.0753203
I0628 19:02:25.765676  7628 solver.cpp:371]     Train net output #0: loss = 0.0753209 (* 1 = 0.0753209 loss)
I0628 19:02:25.765682  7628 sgd_solver.cpp:137] Iteration 18100, lr = 0.0717188, m = 0.9
I0628 19:02:27.487658  7628 solver.cpp:349] Iteration 18200 (58.0753 iter/s, 1.7219s/100 iter), loss = 0.0712755
I0628 19:02:27.487679  7628 solver.cpp:371]     Train net output #0: loss = 0.071276 (* 1 = 0.071276 loss)
I0628 19:02:27.487684  7628 sgd_solver.cpp:137] Iteration 18200, lr = 0.0715625, m = 0.9
I0628 19:02:29.202008  7628 solver.cpp:349] Iteration 18300 (58.3344 iter/s, 1.71426s/100 iter), loss = 0.161428
I0628 19:02:29.202031  7628 solver.cpp:371]     Train net output #0: loss = 0.161428 (* 1 = 0.161428 loss)
I0628 19:02:29.202035  7628 sgd_solver.cpp:137] Iteration 18300, lr = 0.0714063, m = 0.9
I0628 19:02:30.920578  7628 solver.cpp:349] Iteration 18400 (58.1911 iter/s, 1.71848s/100 iter), loss = 0.0964538
I0628 19:02:30.920600  7628 solver.cpp:371]     Train net output #0: loss = 0.0964542 (* 1 = 0.0964542 loss)
I0628 19:02:30.920604  7628 sgd_solver.cpp:137] Iteration 18400, lr = 0.07125, m = 0.9
I0628 19:02:32.633864  7628 solver.cpp:349] Iteration 18500 (58.3706 iter/s, 1.71319s/100 iter), loss = 0.360065
I0628 19:02:32.633931  7628 solver.cpp:371]     Train net output #0: loss = 0.360066 (* 1 = 0.360066 loss)
I0628 19:02:32.633936  7628 sgd_solver.cpp:137] Iteration 18500, lr = 0.0710938, m = 0.9
I0628 19:02:34.344336  7628 solver.cpp:349] Iteration 18600 (58.4683 iter/s, 1.71033s/100 iter), loss = 0.1421
I0628 19:02:34.344357  7628 solver.cpp:371]     Train net output #0: loss = 0.1421 (* 1 = 0.1421 loss)
I0628 19:02:34.344360  7628 sgd_solver.cpp:137] Iteration 18600, lr = 0.0709375, m = 0.9
I0628 19:02:36.054982  7628 solver.cpp:349] Iteration 18700 (58.4606 iter/s, 1.71055s/100 iter), loss = 0.0430234
I0628 19:02:36.055003  7628 solver.cpp:371]     Train net output #0: loss = 0.0430238 (* 1 = 0.0430238 loss)
I0628 19:02:36.055007  7628 sgd_solver.cpp:137] Iteration 18700, lr = 0.0707813, m = 0.9
I0628 19:02:36.841756  7613 data_reader.cpp:262] Starting prefetch of epoch 24
I0628 19:02:37.768894  7628 solver.cpp:349] Iteration 18800 (58.3492 iter/s, 1.71382s/100 iter), loss = 0.079406
I0628 19:02:37.768918  7628 solver.cpp:371]     Train net output #0: loss = 0.0794064 (* 1 = 0.0794064 loss)
I0628 19:02:37.768921  7628 sgd_solver.cpp:137] Iteration 18800, lr = 0.070625, m = 0.9
I0628 19:02:39.487743  7628 solver.cpp:349] Iteration 18900 (58.1817 iter/s, 1.71875s/100 iter), loss = 0.246608
I0628 19:02:39.487766  7628 solver.cpp:371]     Train net output #0: loss = 0.246608 (* 1 = 0.246608 loss)
I0628 19:02:39.487771  7628 sgd_solver.cpp:137] Iteration 18900, lr = 0.0704687, m = 0.9
I0628 19:02:41.183037  7628 solver.cpp:545] Iteration 19000, Testing net (#0)
I0628 19:02:42.191124  7626 data_reader.cpp:262] Starting prefetch of epoch 19
I0628 19:02:42.212862  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.7804
I0628 19:02:42.212875  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.984801
I0628 19:02:42.212880  7628 solver.cpp:630]     Test net output #2: loss = 0.845874 (* 1 = 0.845874 loss)
I0628 19:02:42.212894  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02982s
I0628 19:02:42.230347  7628 solver.cpp:349] Iteration 19000 (36.4634 iter/s, 2.74247s/100 iter), loss = 0.228494
I0628 19:02:42.230370  7628 solver.cpp:371]     Train net output #0: loss = 0.228495 (* 1 = 0.228495 loss)
I0628 19:02:42.230374  7628 sgd_solver.cpp:137] Iteration 19000, lr = 0.0703125, m = 0.9
I0628 19:02:43.947237  7628 solver.cpp:349] Iteration 19100 (58.2481 iter/s, 1.71679s/100 iter), loss = 0.137511
I0628 19:02:43.947259  7628 solver.cpp:371]     Train net output #0: loss = 0.137511 (* 1 = 0.137511 loss)
I0628 19:02:43.947264  7628 sgd_solver.cpp:137] Iteration 19100, lr = 0.0701563, m = 0.9
I0628 19:02:45.661747  7628 solver.cpp:349] Iteration 19200 (58.3289 iter/s, 1.71442s/100 iter), loss = 0.188803
I0628 19:02:45.661769  7628 solver.cpp:371]     Train net output #0: loss = 0.188804 (* 1 = 0.188804 loss)
I0628 19:02:45.661774  7628 sgd_solver.cpp:137] Iteration 19200, lr = 0.07, m = 0.9
I0628 19:02:47.378449  7628 solver.cpp:349] Iteration 19300 (58.2545 iter/s, 1.71661s/100 iter), loss = 0.0854008
I0628 19:02:47.378473  7628 solver.cpp:371]     Train net output #0: loss = 0.0854013 (* 1 = 0.0854013 loss)
I0628 19:02:47.378476  7628 sgd_solver.cpp:137] Iteration 19300, lr = 0.0698438, m = 0.9
I0628 19:02:49.094321  7628 solver.cpp:349] Iteration 19400 (58.2827 iter/s, 1.71578s/100 iter), loss = 0.155817
I0628 19:02:49.094343  7628 solver.cpp:371]     Train net output #0: loss = 0.155818 (* 1 = 0.155818 loss)
I0628 19:02:49.094347  7628 sgd_solver.cpp:137] Iteration 19400, lr = 0.0696875, m = 0.9
I0628 19:02:50.818792  7628 solver.cpp:349] Iteration 19500 (57.992 iter/s, 1.72438s/100 iter), loss = 0.0426153
I0628 19:02:50.818816  7628 solver.cpp:371]     Train net output #0: loss = 0.0426157 (* 1 = 0.0426157 loss)
I0628 19:02:50.818820  7628 sgd_solver.cpp:137] Iteration 19500, lr = 0.0695313, m = 0.9
I0628 19:02:51.298395  7613 data_reader.cpp:262] Starting prefetch of epoch 25
I0628 19:02:52.537441  7628 solver.cpp:349] Iteration 19600 (58.1885 iter/s, 1.71855s/100 iter), loss = 0.0243979
I0628 19:02:52.537463  7628 solver.cpp:371]     Train net output #0: loss = 0.0243983 (* 1 = 0.0243983 loss)
I0628 19:02:52.537482  7628 sgd_solver.cpp:137] Iteration 19600, lr = 0.069375, m = 0.9
I0628 19:02:54.253075  7628 solver.cpp:349] Iteration 19700 (58.2913 iter/s, 1.71552s/100 iter), loss = 0.123077
I0628 19:02:54.253098  7628 solver.cpp:371]     Train net output #0: loss = 0.123078 (* 1 = 0.123078 loss)
I0628 19:02:54.253101  7628 sgd_solver.cpp:137] Iteration 19700, lr = 0.0692187, m = 0.9
I0628 19:02:55.973013  7628 solver.cpp:349] Iteration 19800 (58.1448 iter/s, 1.71984s/100 iter), loss = 0.12663
I0628 19:02:55.973037  7628 solver.cpp:371]     Train net output #0: loss = 0.126631 (* 1 = 0.126631 loss)
I0628 19:02:55.973040  7628 sgd_solver.cpp:137] Iteration 19800, lr = 0.0690625, m = 0.9
I0628 19:02:57.690799  7628 solver.cpp:349] Iteration 19900 (58.2177 iter/s, 1.71769s/100 iter), loss = 0.139685
I0628 19:02:57.690821  7628 solver.cpp:371]     Train net output #0: loss = 0.139686 (* 1 = 0.139686 loss)
I0628 19:02:57.690825  7628 sgd_solver.cpp:137] Iteration 19900, lr = 0.0689062, m = 0.9
I0628 19:02:59.388952  7628 solver.cpp:675] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-06-28_18-56-45/initial/cifar10_jacintonet11v2_iter_20000.caffemodel
I0628 19:02:59.396878  7628 sgd_solver.cpp:288] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-06-28_18-56-45/initial/cifar10_jacintonet11v2_iter_20000.solverstate
I0628 19:02:59.400355  7628 solver.cpp:545] Iteration 20000, Testing net (#0)
I0628 19:03:00.407846  7626 data_reader.cpp:262] Starting prefetch of epoch 20
I0628 19:03:00.428213  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.7706
I0628 19:03:00.428228  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9888
I0628 19:03:00.428236  7628 solver.cpp:630]     Test net output #2: loss = 0.876744 (* 1 = 0.876744 loss)
I0628 19:03:00.428253  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02786s
I0628 19:03:00.445734  7628 solver.cpp:349] Iteration 20000 (36.3002 iter/s, 2.7548s/100 iter), loss = 0.0415254
I0628 19:03:00.445760  7628 solver.cpp:371]     Train net output #0: loss = 0.041526 (* 1 = 0.041526 loss)
I0628 19:03:00.445766  7628 sgd_solver.cpp:137] Iteration 20000, lr = 0.06875, m = 0.9
I0628 19:03:02.161533  7628 solver.cpp:349] Iteration 20100 (58.2854 iter/s, 1.7157s/100 iter), loss = 0.163195
I0628 19:03:02.161559  7628 solver.cpp:371]     Train net output #0: loss = 0.163196 (* 1 = 0.163196 loss)
I0628 19:03:02.161566  7628 sgd_solver.cpp:137] Iteration 20100, lr = 0.0685938, m = 0.9
I0628 19:03:03.879040  7628 solver.cpp:349] Iteration 20200 (58.2274 iter/s, 1.7174s/100 iter), loss = 0.113287
I0628 19:03:03.880627  7628 solver.cpp:371]     Train net output #0: loss = 0.113288 (* 1 = 0.113288 loss)
I0628 19:03:03.880635  7628 sgd_solver.cpp:137] Iteration 20200, lr = 0.0684375, m = 0.9
I0628 19:03:05.596398  7628 solver.cpp:349] Iteration 20300 (58.2856 iter/s, 1.71569s/100 iter), loss = 0.0162844
I0628 19:03:05.596421  7628 solver.cpp:371]     Train net output #0: loss = 0.016285 (* 1 = 0.016285 loss)
I0628 19:03:05.596426  7628 sgd_solver.cpp:137] Iteration 20300, lr = 0.0682813, m = 0.9
I0628 19:03:05.751698  7613 data_reader.cpp:262] Starting prefetch of epoch 26
I0628 19:03:07.314674  7628 solver.cpp:349] Iteration 20400 (58.2011 iter/s, 1.71818s/100 iter), loss = 0.0662627
I0628 19:03:07.314695  7628 solver.cpp:371]     Train net output #0: loss = 0.0662633 (* 1 = 0.0662633 loss)
I0628 19:03:07.314700  7628 sgd_solver.cpp:137] Iteration 20400, lr = 0.068125, m = 0.9
I0628 19:03:09.033452  7628 solver.cpp:349] Iteration 20500 (58.1841 iter/s, 1.71868s/100 iter), loss = 0.0271667
I0628 19:03:09.033480  7628 solver.cpp:371]     Train net output #0: loss = 0.0271672 (* 1 = 0.0271672 loss)
I0628 19:03:09.033488  7628 sgd_solver.cpp:137] Iteration 20500, lr = 0.0679687, m = 0.9
I0628 19:03:10.752234  7628 solver.cpp:349] Iteration 20600 (58.1844 iter/s, 1.71867s/100 iter), loss = 0.257284
I0628 19:03:10.752257  7628 solver.cpp:371]     Train net output #0: loss = 0.257284 (* 1 = 0.257284 loss)
I0628 19:03:10.752261  7628 sgd_solver.cpp:137] Iteration 20600, lr = 0.0678125, m = 0.9
I0628 19:03:12.471570  7628 solver.cpp:349] Iteration 20700 (58.1652 iter/s, 1.71924s/100 iter), loss = 0.084298
I0628 19:03:12.471595  7628 solver.cpp:371]     Train net output #0: loss = 0.0842984 (* 1 = 0.0842984 loss)
I0628 19:03:12.471601  7628 sgd_solver.cpp:137] Iteration 20700, lr = 0.0676562, m = 0.9
I0628 19:03:14.185050  7628 solver.cpp:349] Iteration 20800 (58.3642 iter/s, 1.71338s/100 iter), loss = 0.106801
I0628 19:03:14.185071  7628 solver.cpp:371]     Train net output #0: loss = 0.106801 (* 1 = 0.106801 loss)
I0628 19:03:14.185075  7628 sgd_solver.cpp:137] Iteration 20800, lr = 0.0675, m = 0.9
I0628 19:03:15.901823  7628 solver.cpp:349] Iteration 20900 (58.252 iter/s, 1.71668s/100 iter), loss = 0.0654122
I0628 19:03:15.901849  7628 solver.cpp:371]     Train net output #0: loss = 0.0654127 (* 1 = 0.0654127 loss)
I0628 19:03:15.901852  7628 sgd_solver.cpp:137] Iteration 20900, lr = 0.0673437, m = 0.9
I0628 19:03:17.609927  7628 solver.cpp:545] Iteration 21000, Testing net (#0)
I0628 19:03:18.617839  7626 data_reader.cpp:262] Starting prefetch of epoch 21
I0628 19:03:18.640863  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.7992
I0628 19:03:18.640877  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.984601
I0628 19:03:18.640882  7628 solver.cpp:630]     Test net output #2: loss = 0.889261 (* 1 = 0.889261 loss)
I0628 19:03:18.640897  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.03094s
I0628 19:03:18.658236  7628 solver.cpp:349] Iteration 21000 (36.2808 iter/s, 2.75628s/100 iter), loss = 0.135288
I0628 19:03:18.658259  7628 solver.cpp:371]     Train net output #0: loss = 0.135288 (* 1 = 0.135288 loss)
I0628 19:03:18.658264  7628 sgd_solver.cpp:137] Iteration 21000, lr = 0.0671875, m = 0.9
I0628 19:03:20.202744  7613 data_reader.cpp:262] Starting prefetch of epoch 27
I0628 19:03:20.374210  7628 solver.cpp:349] Iteration 21100 (58.2792 iter/s, 1.71588s/100 iter), loss = 0.0663834
I0628 19:03:20.374233  7628 solver.cpp:371]     Train net output #0: loss = 0.0663839 (* 1 = 0.0663839 loss)
I0628 19:03:20.374236  7628 sgd_solver.cpp:137] Iteration 21100, lr = 0.0670313, m = 0.9
I0628 19:03:22.101454  7628 solver.cpp:349] Iteration 21200 (57.8989 iter/s, 1.72715s/100 iter), loss = 0.159229
I0628 19:03:22.101476  7628 solver.cpp:371]     Train net output #0: loss = 0.15923 (* 1 = 0.15923 loss)
I0628 19:03:22.101480  7628 sgd_solver.cpp:137] Iteration 21200, lr = 0.066875, m = 0.9
I0628 19:03:23.818737  7628 solver.cpp:349] Iteration 21300 (58.2348 iter/s, 1.71719s/100 iter), loss = 0.224368
I0628 19:03:23.818758  7628 solver.cpp:371]     Train net output #0: loss = 0.224369 (* 1 = 0.224369 loss)
I0628 19:03:23.818778  7628 sgd_solver.cpp:137] Iteration 21300, lr = 0.0667187, m = 0.9
I0628 19:03:25.541247  7628 solver.cpp:349] Iteration 21400 (58.0586 iter/s, 1.7224s/100 iter), loss = 0.0988281
I0628 19:03:25.541270  7628 solver.cpp:371]     Train net output #0: loss = 0.0988286 (* 1 = 0.0988286 loss)
I0628 19:03:25.541275  7628 sgd_solver.cpp:137] Iteration 21400, lr = 0.0665625, m = 0.9
I0628 19:03:27.258735  7628 solver.cpp:349] Iteration 21500 (58.2278 iter/s, 1.71739s/100 iter), loss = 0.058926
I0628 19:03:27.258759  7628 solver.cpp:371]     Train net output #0: loss = 0.0589265 (* 1 = 0.0589265 loss)
I0628 19:03:27.258764  7628 sgd_solver.cpp:137] Iteration 21500, lr = 0.0664062, m = 0.9
I0628 19:03:28.976531  7628 solver.cpp:349] Iteration 21600 (58.2174 iter/s, 1.7177s/100 iter), loss = 0.12357
I0628 19:03:28.976553  7628 solver.cpp:371]     Train net output #0: loss = 0.12357 (* 1 = 0.12357 loss)
I0628 19:03:28.976559  7628 sgd_solver.cpp:137] Iteration 21600, lr = 0.06625, m = 0.9
I0628 19:03:30.693145  7628 solver.cpp:349] Iteration 21700 (58.2576 iter/s, 1.71652s/100 iter), loss = 0.105311
I0628 19:03:30.693167  7628 solver.cpp:371]     Train net output #0: loss = 0.105311 (* 1 = 0.105311 loss)
I0628 19:03:30.693172  7628 sgd_solver.cpp:137] Iteration 21700, lr = 0.0660938, m = 0.9
I0628 19:03:32.413148  7628 solver.cpp:349] Iteration 21800 (58.1427 iter/s, 1.71991s/100 iter), loss = 0.0887567
I0628 19:03:32.413172  7628 solver.cpp:371]     Train net output #0: loss = 0.0887572 (* 1 = 0.0887572 loss)
I0628 19:03:32.413177  7628 sgd_solver.cpp:137] Iteration 21800, lr = 0.0659375, m = 0.9
I0628 19:03:33.634526  7613 data_reader.cpp:262] Starting prefetch of epoch 28
I0628 19:03:34.131238  7628 solver.cpp:349] Iteration 21900 (58.2075 iter/s, 1.71799s/100 iter), loss = 0.0658916
I0628 19:03:34.131321  7628 solver.cpp:371]     Train net output #0: loss = 0.0658921 (* 1 = 0.0658921 loss)
I0628 19:03:34.131330  7628 sgd_solver.cpp:137] Iteration 21900, lr = 0.0657813, m = 0.9
I0628 19:03:35.835413  7628 solver.cpp:545] Iteration 22000, Testing net (#0)
I0628 19:03:36.845732  7626 data_reader.cpp:262] Starting prefetch of epoch 22
I0628 19:03:36.866143  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.842
I0628 19:03:36.866155  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9918
I0628 19:03:36.866160  7628 solver.cpp:630]     Test net output #2: loss = 0.557517 (* 1 = 0.557517 loss)
I0628 19:03:36.866173  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.03073s
I0628 19:03:36.883497  7628 solver.cpp:349] Iteration 22000 (36.3364 iter/s, 2.75206s/100 iter), loss = 0.161584
I0628 19:03:36.883519  7628 solver.cpp:371]     Train net output #0: loss = 0.161585 (* 1 = 0.161585 loss)
I0628 19:03:36.883523  7628 sgd_solver.cpp:137] Iteration 22000, lr = 0.065625, m = 0.9
I0628 19:03:38.596156  7628 solver.cpp:349] Iteration 22100 (58.3919 iter/s, 1.71257s/100 iter), loss = 0.0650359
I0628 19:03:38.596179  7628 solver.cpp:371]     Train net output #0: loss = 0.0650365 (* 1 = 0.0650365 loss)
I0628 19:03:38.596182  7628 sgd_solver.cpp:137] Iteration 22100, lr = 0.0654688, m = 0.9
I0628 19:03:40.312649  7628 solver.cpp:349] Iteration 22200 (58.2615 iter/s, 1.7164s/100 iter), loss = 0.00898014
I0628 19:03:40.312671  7628 solver.cpp:371]     Train net output #0: loss = 0.0089807 (* 1 = 0.0089807 loss)
I0628 19:03:40.312675  7628 sgd_solver.cpp:137] Iteration 22200, lr = 0.0653125, m = 0.9
I0628 19:03:42.029618  7628 solver.cpp:349] Iteration 22300 (58.2454 iter/s, 1.71687s/100 iter), loss = 0.0655617
I0628 19:03:42.029639  7628 solver.cpp:371]     Train net output #0: loss = 0.0655624 (* 1 = 0.0655624 loss)
I0628 19:03:42.029644  7628 sgd_solver.cpp:137] Iteration 22300, lr = 0.0651563, m = 0.9
I0628 19:03:43.750936  7628 solver.cpp:349] Iteration 22400 (58.0982 iter/s, 1.72122s/100 iter), loss = 0.0694209
I0628 19:03:43.750958  7628 solver.cpp:371]     Train net output #0: loss = 0.0694215 (* 1 = 0.0694215 loss)
I0628 19:03:43.750962  7628 sgd_solver.cpp:137] Iteration 22400, lr = 0.065, m = 0.9
I0628 19:03:45.465617  7628 solver.cpp:349] Iteration 22500 (58.3231 iter/s, 1.71459s/100 iter), loss = 0.034521
I0628 19:03:45.465639  7628 solver.cpp:371]     Train net output #0: loss = 0.0345216 (* 1 = 0.0345216 loss)
I0628 19:03:45.465643  7628 sgd_solver.cpp:137] Iteration 22500, lr = 0.0648438, m = 0.9
I0628 19:03:47.183300  7628 solver.cpp:349] Iteration 22600 (58.2212 iter/s, 1.71759s/100 iter), loss = 0.174943
I0628 19:03:47.183322  7628 solver.cpp:371]     Train net output #0: loss = 0.174943 (* 1 = 0.174943 loss)
I0628 19:03:47.183326  7628 sgd_solver.cpp:137] Iteration 22600, lr = 0.0646875, m = 0.9
I0628 19:03:48.094523  7613 data_reader.cpp:262] Starting prefetch of epoch 29
I0628 19:03:48.900153  7628 solver.cpp:349] Iteration 22700 (58.2493 iter/s, 1.71676s/100 iter), loss = 0.0680287
I0628 19:03:48.900174  7628 solver.cpp:371]     Train net output #0: loss = 0.0680293 (* 1 = 0.0680293 loss)
I0628 19:03:48.900178  7628 sgd_solver.cpp:137] Iteration 22700, lr = 0.0645313, m = 0.9
I0628 19:03:50.617058  7628 solver.cpp:349] Iteration 22800 (58.2476 iter/s, 1.71681s/100 iter), loss = 0.0437461
I0628 19:03:50.617079  7628 solver.cpp:371]     Train net output #0: loss = 0.0437467 (* 1 = 0.0437467 loss)
I0628 19:03:50.617082  7628 sgd_solver.cpp:137] Iteration 22800, lr = 0.064375, m = 0.9
I0628 19:03:52.335393  7628 solver.cpp:349] Iteration 22900 (58.199 iter/s, 1.71824s/100 iter), loss = 0.0141577
I0628 19:03:52.335415  7628 solver.cpp:371]     Train net output #0: loss = 0.0141583 (* 1 = 0.0141583 loss)
I0628 19:03:52.335419  7628 sgd_solver.cpp:137] Iteration 22900, lr = 0.0642188, m = 0.9
I0628 19:03:54.036454  7628 solver.cpp:545] Iteration 23000, Testing net (#0)
I0628 19:03:55.043154  7626 data_reader.cpp:262] Starting prefetch of epoch 23
I0628 19:03:55.065836  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.798399
I0628 19:03:55.065865  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9886
I0628 19:03:55.065871  7628 solver.cpp:630]     Test net output #2: loss = 0.731195 (* 1 = 0.731195 loss)
I0628 19:03:55.065886  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.0294s
I0628 19:03:55.083269  7628 solver.cpp:349] Iteration 23000 (36.3934 iter/s, 2.74775s/100 iter), loss = 0.20092
I0628 19:03:55.083295  7628 solver.cpp:371]     Train net output #0: loss = 0.20092 (* 1 = 0.20092 loss)
I0628 19:03:55.083300  7628 sgd_solver.cpp:137] Iteration 23000, lr = 0.0640625, m = 0.9
I0628 19:03:56.802773  7628 solver.cpp:349] Iteration 23100 (58.1596 iter/s, 1.71941s/100 iter), loss = 0.179231
I0628 19:03:56.802798  7628 solver.cpp:371]     Train net output #0: loss = 0.179231 (* 1 = 0.179231 loss)
I0628 19:03:56.802801  7628 sgd_solver.cpp:137] Iteration 23100, lr = 0.0639063, m = 0.9
I0628 19:03:58.519323  7628 solver.cpp:349] Iteration 23200 (58.2597 iter/s, 1.71645s/100 iter), loss = 0.105
I0628 19:03:58.519345  7628 solver.cpp:371]     Train net output #0: loss = 0.105001 (* 1 = 0.105001 loss)
I0628 19:03:58.519348  7628 sgd_solver.cpp:137] Iteration 23200, lr = 0.06375, m = 0.9
I0628 19:04:00.240334  7628 solver.cpp:349] Iteration 23300 (58.1086 iter/s, 1.72092s/100 iter), loss = 0.114955
I0628 19:04:00.240356  7628 solver.cpp:371]     Train net output #0: loss = 0.114955 (* 1 = 0.114955 loss)
I0628 19:04:00.240360  7628 sgd_solver.cpp:137] Iteration 23300, lr = 0.0635938, m = 0.9
I0628 19:04:01.956389  7628 solver.cpp:349] Iteration 23400 (58.2764 iter/s, 1.71596s/100 iter), loss = 0.0340129
I0628 19:04:01.956411  7628 solver.cpp:371]     Train net output #0: loss = 0.0340133 (* 1 = 0.0340133 loss)
I0628 19:04:01.956415  7628 sgd_solver.cpp:137] Iteration 23400, lr = 0.0634375, m = 0.9
I0628 19:04:02.541893  7613 data_reader.cpp:262] Starting prefetch of epoch 30
I0628 19:04:03.691287  7628 solver.cpp:349] Iteration 23500 (57.6435 iter/s, 1.7348s/100 iter), loss = 0.124718
I0628 19:04:03.691310  7628 solver.cpp:371]     Train net output #0: loss = 0.124718 (* 1 = 0.124718 loss)
I0628 19:04:03.691314  7628 sgd_solver.cpp:137] Iteration 23500, lr = 0.0632813, m = 0.9
I0628 19:04:05.407145  7628 solver.cpp:349] Iteration 23600 (58.2831 iter/s, 1.71576s/100 iter), loss = 0.117434
I0628 19:04:05.407208  7628 solver.cpp:371]     Train net output #0: loss = 0.117434 (* 1 = 0.117434 loss)
I0628 19:04:05.407213  7628 sgd_solver.cpp:137] Iteration 23600, lr = 0.063125, m = 0.9
I0628 19:04:07.128844  7628 solver.cpp:349] Iteration 23700 (58.0868 iter/s, 1.72156s/100 iter), loss = 0.055336
I0628 19:04:07.128866  7628 solver.cpp:371]     Train net output #0: loss = 0.0553364 (* 1 = 0.0553364 loss)
I0628 19:04:07.128870  7628 sgd_solver.cpp:137] Iteration 23700, lr = 0.0629688, m = 0.9
I0628 19:04:08.843495  7628 solver.cpp:349] Iteration 23800 (58.3242 iter/s, 1.71455s/100 iter), loss = 0.065086
I0628 19:04:08.843518  7628 solver.cpp:371]     Train net output #0: loss = 0.0650865 (* 1 = 0.0650865 loss)
I0628 19:04:08.843521  7628 sgd_solver.cpp:137] Iteration 23800, lr = 0.0628125, m = 0.9
I0628 19:04:10.557212  7628 solver.cpp:349] Iteration 23900 (58.3559 iter/s, 1.71362s/100 iter), loss = 0.109873
I0628 19:04:10.557232  7628 solver.cpp:371]     Train net output #0: loss = 0.109874 (* 1 = 0.109874 loss)
I0628 19:04:10.557236  7628 sgd_solver.cpp:137] Iteration 23900, lr = 0.0626562, m = 0.9
I0628 19:04:12.254539  7628 solver.cpp:545] Iteration 24000, Testing net (#0)
I0628 19:04:13.260766  7626 data_reader.cpp:262] Starting prefetch of epoch 24
I0628 19:04:13.284538  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.8488
I0628 19:04:13.284551  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9908
I0628 19:04:13.284556  7628 solver.cpp:630]     Test net output #2: loss = 0.566731 (* 1 = 0.566731 loss)
I0628 19:04:13.284569  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.03s
I0628 19:04:13.301950  7628 solver.cpp:349] Iteration 24000 (36.435 iter/s, 2.74461s/100 iter), loss = 0.0357238
I0628 19:04:13.301973  7628 solver.cpp:371]     Train net output #0: loss = 0.0357243 (* 1 = 0.0357243 loss)
I0628 19:04:13.301976  7628 sgd_solver.cpp:137] Iteration 24000, lr = 0.0625, m = 0.9
I0628 19:04:15.019606  7628 solver.cpp:349] Iteration 24100 (58.2221 iter/s, 1.71756s/100 iter), loss = 0.12955
I0628 19:04:15.019629  7628 solver.cpp:371]     Train net output #0: loss = 0.129551 (* 1 = 0.129551 loss)
I0628 19:04:15.019635  7628 sgd_solver.cpp:137] Iteration 24100, lr = 0.0623438, m = 0.9
I0628 19:04:16.745823  7628 solver.cpp:349] Iteration 24200 (57.9334 iter/s, 1.72612s/100 iter), loss = 0.129574
I0628 19:04:16.745848  7628 solver.cpp:371]     Train net output #0: loss = 0.129575 (* 1 = 0.129575 loss)
I0628 19:04:16.745852  7628 sgd_solver.cpp:137] Iteration 24200, lr = 0.0621875, m = 0.9
I0628 19:04:17.004359  7613 data_reader.cpp:262] Starting prefetch of epoch 31
I0628 19:04:18.466428  7628 solver.cpp:349] Iteration 24300 (58.1225 iter/s, 1.72051s/100 iter), loss = 0.0603604
I0628 19:04:18.466451  7628 solver.cpp:371]     Train net output #0: loss = 0.0603609 (* 1 = 0.0603609 loss)
I0628 19:04:18.466457  7628 sgd_solver.cpp:137] Iteration 24300, lr = 0.0620313, m = 0.9
I0628 19:04:20.184626  7628 solver.cpp:349] Iteration 24400 (58.2038 iter/s, 1.7181s/100 iter), loss = 0.0671634
I0628 19:04:20.184648  7628 solver.cpp:371]     Train net output #0: loss = 0.0671639 (* 1 = 0.0671639 loss)
I0628 19:04:20.184653  7628 sgd_solver.cpp:137] Iteration 24400, lr = 0.061875, m = 0.9
I0628 19:04:21.901255  7628 solver.cpp:349] Iteration 24500 (58.2569 iter/s, 1.71654s/100 iter), loss = 0.108937
I0628 19:04:21.901279  7628 solver.cpp:371]     Train net output #0: loss = 0.108937 (* 1 = 0.108937 loss)
I0628 19:04:21.901284  7628 sgd_solver.cpp:137] Iteration 24500, lr = 0.0617188, m = 0.9
I0628 19:04:23.626744  7628 solver.cpp:349] Iteration 24600 (57.958 iter/s, 1.72539s/100 iter), loss = 0.149503
I0628 19:04:23.626767  7628 solver.cpp:371]     Train net output #0: loss = 0.149504 (* 1 = 0.149504 loss)
I0628 19:04:23.626772  7628 sgd_solver.cpp:137] Iteration 24600, lr = 0.0615625, m = 0.9
I0628 19:04:25.343310  7628 solver.cpp:349] Iteration 24700 (58.2592 iter/s, 1.71647s/100 iter), loss = 0.0177554
I0628 19:04:25.343333  7628 solver.cpp:371]     Train net output #0: loss = 0.0177559 (* 1 = 0.0177559 loss)
I0628 19:04:25.343355  7628 sgd_solver.cpp:137] Iteration 24700, lr = 0.0614063, m = 0.9
I0628 19:04:27.064278  7628 solver.cpp:349] Iteration 24800 (58.1111 iter/s, 1.72084s/100 iter), loss = 0.0426147
I0628 19:04:27.064301  7628 solver.cpp:371]     Train net output #0: loss = 0.0426152 (* 1 = 0.0426152 loss)
I0628 19:04:27.064307  7628 sgd_solver.cpp:137] Iteration 24800, lr = 0.06125, m = 0.9
I0628 19:04:28.783128  7628 solver.cpp:349] Iteration 24900 (58.1818 iter/s, 1.71875s/100 iter), loss = 0.023172
I0628 19:04:28.783152  7628 solver.cpp:371]     Train net output #0: loss = 0.0231725 (* 1 = 0.0231725 loss)
I0628 19:04:28.783157  7628 sgd_solver.cpp:137] Iteration 24900, lr = 0.0610937, m = 0.9
I0628 19:04:30.432338  7613 data_reader.cpp:262] Starting prefetch of epoch 32
I0628 19:04:30.483827  7628 solver.cpp:545] Iteration 25000, Testing net (#0)
I0628 19:04:31.490572  7626 data_reader.cpp:262] Starting prefetch of epoch 25
I0628 19:04:31.512877  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.8398
I0628 19:04:31.512890  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9906
I0628 19:04:31.512895  7628 solver.cpp:630]     Test net output #2: loss = 0.611064 (* 1 = 0.611064 loss)
I0628 19:04:31.512909  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02905s
I0628 19:04:31.530408  7628 solver.cpp:349] Iteration 25000 (36.4014 iter/s, 2.74715s/100 iter), loss = 0.023916
I0628 19:04:31.530434  7628 solver.cpp:371]     Train net output #0: loss = 0.0239164 (* 1 = 0.0239164 loss)
I0628 19:04:31.530438  7628 sgd_solver.cpp:137] Iteration 25000, lr = 0.0609375, m = 0.9
I0628 19:04:33.248417  7628 solver.cpp:349] Iteration 25100 (58.2103 iter/s, 1.71791s/100 iter), loss = 0.021974
I0628 19:04:33.248440  7628 solver.cpp:371]     Train net output #0: loss = 0.0219744 (* 1 = 0.0219744 loss)
I0628 19:04:33.248445  7628 sgd_solver.cpp:137] Iteration 25100, lr = 0.0607813, m = 0.9
I0628 19:04:34.962828  7628 solver.cpp:349] Iteration 25200 (58.3323 iter/s, 1.71432s/100 iter), loss = 0.094193
I0628 19:04:34.962851  7628 solver.cpp:371]     Train net output #0: loss = 0.0941935 (* 1 = 0.0941935 loss)
I0628 19:04:34.962854  7628 sgd_solver.cpp:137] Iteration 25200, lr = 0.060625, m = 0.9
I0628 19:04:36.679065  7628 solver.cpp:349] Iteration 25300 (58.2702 iter/s, 1.71614s/100 iter), loss = 0.128046
I0628 19:04:36.679147  7628 solver.cpp:371]     Train net output #0: loss = 0.128046 (* 1 = 0.128046 loss)
I0628 19:04:36.679153  7628 sgd_solver.cpp:137] Iteration 25300, lr = 0.0604688, m = 0.9
I0628 19:04:38.394839  7628 solver.cpp:349] Iteration 25400 (58.2881 iter/s, 1.71561s/100 iter), loss = 0.0498717
I0628 19:04:38.394861  7628 solver.cpp:371]     Train net output #0: loss = 0.0498721 (* 1 = 0.0498721 loss)
I0628 19:04:38.394866  7628 sgd_solver.cpp:137] Iteration 25400, lr = 0.0603125, m = 0.9
I0628 19:04:40.113113  7628 solver.cpp:349] Iteration 25500 (58.2012 iter/s, 1.71818s/100 iter), loss = 0.0575084
I0628 19:04:40.113137  7628 solver.cpp:371]     Train net output #0: loss = 0.0575088 (* 1 = 0.0575088 loss)
I0628 19:04:40.113140  7628 sgd_solver.cpp:137] Iteration 25500, lr = 0.0601563, m = 0.9
I0628 19:04:41.831223  7628 solver.cpp:349] Iteration 25600 (58.2067 iter/s, 1.71801s/100 iter), loss = 0.00772723
I0628 19:04:41.831244  7628 solver.cpp:371]     Train net output #0: loss = 0.00772761 (* 1 = 0.00772761 loss)
I0628 19:04:41.831249  7628 sgd_solver.cpp:137] Iteration 25600, lr = 0.06, m = 0.9
I0628 19:04:43.546838  7628 solver.cpp:349] Iteration 25700 (58.2914 iter/s, 1.71552s/100 iter), loss = 0.0618837
I0628 19:04:43.546860  7628 solver.cpp:371]     Train net output #0: loss = 0.0618841 (* 1 = 0.0618841 loss)
I0628 19:04:43.546865  7628 sgd_solver.cpp:137] Iteration 25700, lr = 0.0598437, m = 0.9
I0628 19:04:44.890121  7613 data_reader.cpp:262] Starting prefetch of epoch 33
I0628 19:04:45.267797  7628 solver.cpp:349] Iteration 25800 (58.1104 iter/s, 1.72086s/100 iter), loss = 0.00967285
I0628 19:04:45.267822  7628 solver.cpp:371]     Train net output #0: loss = 0.0096733 (* 1 = 0.0096733 loss)
I0628 19:04:45.267825  7628 sgd_solver.cpp:137] Iteration 25800, lr = 0.0596875, m = 0.9
I0628 19:04:46.986641  7628 solver.cpp:349] Iteration 25900 (58.1819 iter/s, 1.71875s/100 iter), loss = 0.0729209
I0628 19:04:46.986665  7628 solver.cpp:371]     Train net output #0: loss = 0.0729214 (* 1 = 0.0729214 loss)
I0628 19:04:46.986670  7628 sgd_solver.cpp:137] Iteration 25900, lr = 0.0595312, m = 0.9
I0628 19:04:48.684849  7628 solver.cpp:545] Iteration 26000, Testing net (#0)
I0628 19:04:49.693657  7626 data_reader.cpp:262] Starting prefetch of epoch 26
I0628 19:04:49.714624  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.7904
I0628 19:04:49.714635  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9882
I0628 19:04:49.714640  7628 solver.cpp:630]     Test net output #2: loss = 0.735148 (* 1 = 0.735148 loss)
I0628 19:04:49.714654  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02977s
I0628 19:04:49.731997  7628 solver.cpp:349] Iteration 26000 (36.4269 iter/s, 2.74523s/100 iter), loss = 0.0748499
I0628 19:04:49.732018  7628 solver.cpp:371]     Train net output #0: loss = 0.0748503 (* 1 = 0.0748503 loss)
I0628 19:04:49.732023  7628 sgd_solver.cpp:137] Iteration 26000, lr = 0.059375, m = 0.9
I0628 19:04:51.454314  7628 solver.cpp:349] Iteration 26100 (58.0645 iter/s, 1.72222s/100 iter), loss = 0.181765
I0628 19:04:51.454336  7628 solver.cpp:371]     Train net output #0: loss = 0.181766 (* 1 = 0.181766 loss)
I0628 19:04:51.454340  7628 sgd_solver.cpp:137] Iteration 26100, lr = 0.0592188, m = 0.9
I0628 19:04:53.168582  7628 solver.cpp:349] Iteration 26200 (58.3372 iter/s, 1.71417s/100 iter), loss = 0.15598
I0628 19:04:53.168604  7628 solver.cpp:371]     Train net output #0: loss = 0.155981 (* 1 = 0.155981 loss)
I0628 19:04:53.168608  7628 sgd_solver.cpp:137] Iteration 26200, lr = 0.0590625, m = 0.9
I0628 19:04:54.886709  7628 solver.cpp:349] Iteration 26300 (58.2061 iter/s, 1.71803s/100 iter), loss = 0.0386525
I0628 19:04:54.886731  7628 solver.cpp:371]     Train net output #0: loss = 0.0386529 (* 1 = 0.0386529 loss)
I0628 19:04:54.886735  7628 sgd_solver.cpp:137] Iteration 26300, lr = 0.0589063, m = 0.9
I0628 19:04:56.602882  7628 solver.cpp:349] Iteration 26400 (58.2724 iter/s, 1.71608s/100 iter), loss = 0.0649482
I0628 19:04:56.602902  7628 solver.cpp:371]     Train net output #0: loss = 0.0649486 (* 1 = 0.0649486 loss)
I0628 19:04:56.602921  7628 sgd_solver.cpp:137] Iteration 26400, lr = 0.05875, m = 0.9
I0628 19:04:58.324997  7628 solver.cpp:349] Iteration 26500 (58.0718 iter/s, 1.72201s/100 iter), loss = 0.136356
I0628 19:04:58.325021  7628 solver.cpp:371]     Train net output #0: loss = 0.136356 (* 1 = 0.136356 loss)
I0628 19:04:58.325026  7628 sgd_solver.cpp:137] Iteration 26500, lr = 0.0585938, m = 0.9
I0628 19:04:59.336755  7613 data_reader.cpp:262] Starting prefetch of epoch 34
I0628 19:05:00.041446  7628 solver.cpp:349] Iteration 26600 (58.2632 iter/s, 1.71635s/100 iter), loss = 0.0637655
I0628 19:05:00.041467  7628 solver.cpp:371]     Train net output #0: loss = 0.063766 (* 1 = 0.063766 loss)
I0628 19:05:00.041471  7628 sgd_solver.cpp:137] Iteration 26600, lr = 0.0584375, m = 0.9
I0628 19:05:01.756268  7628 solver.cpp:349] Iteration 26700 (58.3183 iter/s, 1.71473s/100 iter), loss = 0.264775
I0628 19:05:01.756289  7628 solver.cpp:371]     Train net output #0: loss = 0.264776 (* 1 = 0.264776 loss)
I0628 19:05:01.756294  7628 sgd_solver.cpp:137] Iteration 26700, lr = 0.0582813, m = 0.9
I0628 19:05:03.476562  7628 solver.cpp:349] Iteration 26800 (58.1328 iter/s, 1.7202s/100 iter), loss = 0.0658696
I0628 19:05:03.476584  7628 solver.cpp:371]     Train net output #0: loss = 0.0658701 (* 1 = 0.0658701 loss)
I0628 19:05:03.476588  7628 sgd_solver.cpp:137] Iteration 26800, lr = 0.058125, m = 0.9
I0628 19:05:05.196439  7628 solver.cpp:349] Iteration 26900 (58.1469 iter/s, 1.71978s/100 iter), loss = 0.09746
I0628 19:05:05.196461  7628 solver.cpp:371]     Train net output #0: loss = 0.0974605 (* 1 = 0.0974605 loss)
I0628 19:05:05.196465  7628 sgd_solver.cpp:137] Iteration 26900, lr = 0.0579687, m = 0.9
I0628 19:05:06.900190  7628 solver.cpp:545] Iteration 27000, Testing net (#0)
I0628 19:05:07.908499  7626 data_reader.cpp:262] Starting prefetch of epoch 27
I0628 19:05:07.928814  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.8248
I0628 19:05:07.928829  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9942
I0628 19:05:07.928834  7628 solver.cpp:630]     Test net output #2: loss = 0.718437 (* 1 = 0.718437 loss)
I0628 19:05:07.928848  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02863s
I0628 19:05:07.946106  7628 solver.cpp:349] Iteration 27000 (36.3697 iter/s, 2.74954s/100 iter), loss = 0.034943
I0628 19:05:07.946130  7628 solver.cpp:371]     Train net output #0: loss = 0.0349435 (* 1 = 0.0349435 loss)
I0628 19:05:07.946133  7628 sgd_solver.cpp:137] Iteration 27000, lr = 0.0578125, m = 0.9
I0628 19:05:09.668051  7628 solver.cpp:349] Iteration 27100 (58.0771 iter/s, 1.72185s/100 iter), loss = 0.105791
I0628 19:05:09.668072  7628 solver.cpp:371]     Train net output #0: loss = 0.105791 (* 1 = 0.105791 loss)
I0628 19:05:09.668076  7628 sgd_solver.cpp:137] Iteration 27100, lr = 0.0576563, m = 0.9
I0628 19:05:11.387207  7628 solver.cpp:349] Iteration 27200 (58.1713 iter/s, 1.71906s/100 iter), loss = 0.0212828
I0628 19:05:11.387229  7628 solver.cpp:371]     Train net output #0: loss = 0.0212833 (* 1 = 0.0212833 loss)
I0628 19:05:11.387233  7628 sgd_solver.cpp:137] Iteration 27200, lr = 0.0575, m = 0.9
I0628 19:05:13.101455  7628 solver.cpp:349] Iteration 27300 (58.3378 iter/s, 1.71415s/100 iter), loss = 0.30651
I0628 19:05:13.101477  7628 solver.cpp:371]     Train net output #0: loss = 0.30651 (* 1 = 0.30651 loss)
I0628 19:05:13.101481  7628 sgd_solver.cpp:137] Iteration 27300, lr = 0.0573438, m = 0.9
I0628 19:05:13.786952  7613 data_reader.cpp:262] Starting prefetch of epoch 35
I0628 19:05:14.817136  7628 solver.cpp:349] Iteration 27400 (58.2892 iter/s, 1.71559s/100 iter), loss = 0.125281
I0628 19:05:14.817157  7628 solver.cpp:371]     Train net output #0: loss = 0.125282 (* 1 = 0.125282 loss)
I0628 19:05:14.817162  7628 sgd_solver.cpp:137] Iteration 27400, lr = 0.0571875, m = 0.9
I0628 19:05:16.541220  7628 solver.cpp:349] Iteration 27500 (58.0049 iter/s, 1.72399s/100 iter), loss = 0.0593361
I0628 19:05:16.541247  7628 solver.cpp:371]     Train net output #0: loss = 0.0593366 (* 1 = 0.0593366 loss)
I0628 19:05:16.541254  7628 sgd_solver.cpp:137] Iteration 27500, lr = 0.0570313, m = 0.9
I0628 19:05:18.261922  7628 solver.cpp:349] Iteration 27600 (58.1193 iter/s, 1.7206s/100 iter), loss = 0.0993841
I0628 19:05:18.261946  7628 solver.cpp:371]     Train net output #0: loss = 0.0993847 (* 1 = 0.0993847 loss)
I0628 19:05:18.261950  7628 sgd_solver.cpp:137] Iteration 27600, lr = 0.056875, m = 0.9
I0628 19:05:19.980873  7628 solver.cpp:349] Iteration 27700 (58.1783 iter/s, 1.71885s/100 iter), loss = 0.0192212
I0628 19:05:19.980893  7628 solver.cpp:371]     Train net output #0: loss = 0.0192218 (* 1 = 0.0192218 loss)
I0628 19:05:19.980897  7628 sgd_solver.cpp:137] Iteration 27700, lr = 0.0567187, m = 0.9
I0628 19:05:21.695430  7628 solver.cpp:349] Iteration 27800 (58.3273 iter/s, 1.71446s/100 iter), loss = 0.0273402
I0628 19:05:21.695451  7628 solver.cpp:371]     Train net output #0: loss = 0.0273407 (* 1 = 0.0273407 loss)
I0628 19:05:21.695454  7628 sgd_solver.cpp:137] Iteration 27800, lr = 0.0565625, m = 0.9
I0628 19:05:23.412189  7628 solver.cpp:349] Iteration 27900 (58.2525 iter/s, 1.71666s/100 iter), loss = 0.113072
I0628 19:05:23.412211  7628 solver.cpp:371]     Train net output #0: loss = 0.113073 (* 1 = 0.113073 loss)
I0628 19:05:23.412215  7628 sgd_solver.cpp:137] Iteration 27900, lr = 0.0564062, m = 0.9
I0628 19:05:25.107760  7628 solver.cpp:545] Iteration 28000, Testing net (#0)
I0628 19:05:26.114333  7626 data_reader.cpp:262] Starting prefetch of epoch 28
I0628 19:05:26.137614  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.8264
I0628 19:05:26.137627  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.989401
I0628 19:05:26.137632  7628 solver.cpp:630]     Test net output #2: loss = 0.736059 (* 1 = 0.736059 loss)
I0628 19:05:26.137647  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02985s
I0628 19:05:26.154966  7628 solver.cpp:349] Iteration 28000 (36.4611 iter/s, 2.74265s/100 iter), loss = 0.0286982
I0628 19:05:26.154989  7628 solver.cpp:371]     Train net output #0: loss = 0.0286987 (* 1 = 0.0286987 loss)
I0628 19:05:26.154994  7628 sgd_solver.cpp:137] Iteration 28000, lr = 0.05625, m = 0.9
I0628 19:05:27.873250  7628 solver.cpp:349] Iteration 28100 (58.2008 iter/s, 1.71819s/100 iter), loss = 0.082039
I0628 19:05:27.873270  7628 solver.cpp:371]     Train net output #0: loss = 0.0820395 (* 1 = 0.0820395 loss)
I0628 19:05:27.873273  7628 sgd_solver.cpp:137] Iteration 28100, lr = 0.0560938, m = 0.9
I0628 19:05:28.233837  7613 data_reader.cpp:262] Starting prefetch of epoch 36
I0628 19:05:29.587970  7628 solver.cpp:349] Iteration 28200 (58.3217 iter/s, 1.71463s/100 iter), loss = 0.0510117
I0628 19:05:29.587991  7628 solver.cpp:371]     Train net output #0: loss = 0.0510122 (* 1 = 0.0510122 loss)
I0628 19:05:29.587996  7628 sgd_solver.cpp:137] Iteration 28200, lr = 0.0559375, m = 0.9
I0628 19:05:31.307284  7628 solver.cpp:349] Iteration 28300 (58.1659 iter/s, 1.71922s/100 iter), loss = 0.00825809
I0628 19:05:31.307307  7628 solver.cpp:371]     Train net output #0: loss = 0.00825857 (* 1 = 0.00825857 loss)
I0628 19:05:31.307310  7628 sgd_solver.cpp:137] Iteration 28300, lr = 0.0557813, m = 0.9
I0628 19:05:33.031756  7628 solver.cpp:349] Iteration 28400 (57.992 iter/s, 1.72438s/100 iter), loss = 0.138117
I0628 19:05:33.031776  7628 solver.cpp:371]     Train net output #0: loss = 0.138118 (* 1 = 0.138118 loss)
I0628 19:05:33.031780  7628 sgd_solver.cpp:137] Iteration 28400, lr = 0.055625, m = 0.9
I0628 19:05:34.752979  7628 solver.cpp:349] Iteration 28500 (58.1014 iter/s, 1.72113s/100 iter), loss = 0.038144
I0628 19:05:34.753000  7628 solver.cpp:371]     Train net output #0: loss = 0.0381445 (* 1 = 0.0381445 loss)
I0628 19:05:34.753005  7628 sgd_solver.cpp:137] Iteration 28500, lr = 0.0554687, m = 0.9
I0628 19:05:36.469840  7628 solver.cpp:349] Iteration 28600 (58.249 iter/s, 1.71677s/100 iter), loss = 0.123572
I0628 19:05:36.469862  7628 solver.cpp:371]     Train net output #0: loss = 0.123573 (* 1 = 0.123573 loss)
I0628 19:05:36.469866  7628 sgd_solver.cpp:137] Iteration 28600, lr = 0.0553125, m = 0.9
I0628 19:05:38.186184  7628 solver.cpp:349] Iteration 28700 (58.2666 iter/s, 1.71625s/100 iter), loss = 0.123993
I0628 19:05:38.186254  7628 solver.cpp:371]     Train net output #0: loss = 0.123994 (* 1 = 0.123994 loss)
I0628 19:05:38.186261  7628 sgd_solver.cpp:137] Iteration 28700, lr = 0.0551562, m = 0.9
I0628 19:05:39.900254  7628 solver.cpp:349] Iteration 28800 (58.3458 iter/s, 1.71392s/100 iter), loss = 0.0142047
I0628 19:05:39.900276  7628 solver.cpp:371]     Train net output #0: loss = 0.0142052 (* 1 = 0.0142052 loss)
I0628 19:05:39.900280  7628 sgd_solver.cpp:137] Iteration 28800, lr = 0.055, m = 0.9
I0628 19:05:41.614596  7628 solver.cpp:349] Iteration 28900 (58.3346 iter/s, 1.71425s/100 iter), loss = 0.0465973
I0628 19:05:41.614619  7628 solver.cpp:371]     Train net output #0: loss = 0.0465978 (* 1 = 0.0465978 loss)
I0628 19:05:41.614622  7628 sgd_solver.cpp:137] Iteration 28900, lr = 0.0548437, m = 0.9
I0628 19:05:41.669292  7613 data_reader.cpp:262] Starting prefetch of epoch 37
I0628 19:05:43.323330  7628 solver.cpp:545] Iteration 29000, Testing net (#0)
I0628 19:05:44.329296  7626 data_reader.cpp:262] Starting prefetch of epoch 29
I0628 19:05:44.351356  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.8282
I0628 19:05:44.351369  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9864
I0628 19:05:44.351375  7628 solver.cpp:630]     Test net output #2: loss = 0.80059 (* 1 = 0.80059 loss)
I0628 19:05:44.351390  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02803s
I0628 19:05:44.368608  7628 solver.cpp:349] Iteration 29000 (36.3123 iter/s, 2.75389s/100 iter), loss = 0.171577
I0628 19:05:44.368630  7628 solver.cpp:371]     Train net output #0: loss = 0.171577 (* 1 = 0.171577 loss)
I0628 19:05:44.368634  7628 sgd_solver.cpp:137] Iteration 29000, lr = 0.0546875, m = 0.9
I0628 19:05:46.086408  7628 solver.cpp:349] Iteration 29100 (58.2172 iter/s, 1.7177s/100 iter), loss = 0.226602
I0628 19:05:46.086431  7628 solver.cpp:371]     Train net output #0: loss = 0.226603 (* 1 = 0.226603 loss)
I0628 19:05:46.086434  7628 sgd_solver.cpp:137] Iteration 29100, lr = 0.0545313, m = 0.9
I0628 19:05:47.803170  7628 solver.cpp:349] Iteration 29200 (58.2524 iter/s, 1.71667s/100 iter), loss = 0.0983857
I0628 19:05:47.803192  7628 solver.cpp:371]     Train net output #0: loss = 0.0983862 (* 1 = 0.0983862 loss)
I0628 19:05:47.803196  7628 sgd_solver.cpp:137] Iteration 29200, lr = 0.054375, m = 0.9
I0628 19:05:49.515540  7628 solver.cpp:349] Iteration 29300 (58.4018 iter/s, 1.71228s/100 iter), loss = 0.0454113
I0628 19:05:49.515563  7628 solver.cpp:371]     Train net output #0: loss = 0.0454118 (* 1 = 0.0454118 loss)
I0628 19:05:49.515568  7628 sgd_solver.cpp:137] Iteration 29300, lr = 0.0542188, m = 0.9
I0628 19:05:51.230937  7628 solver.cpp:349] Iteration 29400 (58.2989 iter/s, 1.7153s/100 iter), loss = 0.0166961
I0628 19:05:51.230958  7628 solver.cpp:371]     Train net output #0: loss = 0.0166966 (* 1 = 0.0166966 loss)
I0628 19:05:51.230962  7628 sgd_solver.cpp:137] Iteration 29400, lr = 0.0540625, m = 0.9
I0628 19:05:52.944142  7628 solver.cpp:349] Iteration 29500 (58.3733 iter/s, 1.71311s/100 iter), loss = 0.0827445
I0628 19:05:52.944164  7628 solver.cpp:371]     Train net output #0: loss = 0.082745 (* 1 = 0.082745 loss)
I0628 19:05:52.944167  7628 sgd_solver.cpp:137] Iteration 29500, lr = 0.0539063, m = 0.9
I0628 19:05:54.659499  7628 solver.cpp:349] Iteration 29600 (58.3 iter/s, 1.71526s/100 iter), loss = 0.0149628
I0628 19:05:54.659518  7628 solver.cpp:371]     Train net output #0: loss = 0.0149633 (* 1 = 0.0149633 loss)
I0628 19:05:54.659523  7628 sgd_solver.cpp:137] Iteration 29600, lr = 0.05375, m = 0.9
I0628 19:05:56.099551  7613 data_reader.cpp:262] Starting prefetch of epoch 38
I0628 19:05:56.374198  7628 solver.cpp:349] Iteration 29700 (58.3224 iter/s, 1.71461s/100 iter), loss = 0.0162122
I0628 19:05:56.374220  7628 solver.cpp:371]     Train net output #0: loss = 0.0162126 (* 1 = 0.0162126 loss)
I0628 19:05:56.374225  7628 sgd_solver.cpp:137] Iteration 29700, lr = 0.0535938, m = 0.9
I0628 19:05:58.091725  7628 solver.cpp:349] Iteration 29800 (58.2265 iter/s, 1.71743s/100 iter), loss = 0.15719
I0628 19:05:58.091747  7628 solver.cpp:371]     Train net output #0: loss = 0.157191 (* 1 = 0.157191 loss)
I0628 19:05:58.091766  7628 sgd_solver.cpp:137] Iteration 29800, lr = 0.0534375, m = 0.9
I0628 19:05:59.805541  7628 solver.cpp:349] Iteration 29900 (58.3532 iter/s, 1.7137s/100 iter), loss = 0.120593
I0628 19:05:59.805567  7628 solver.cpp:371]     Train net output #0: loss = 0.120593 (* 1 = 0.120593 loss)
I0628 19:05:59.805572  7628 sgd_solver.cpp:137] Iteration 29900, lr = 0.0532812, m = 0.9
I0628 19:06:01.502374  7628 solver.cpp:675] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-06-28_18-56-45/initial/cifar10_jacintonet11v2_iter_30000.caffemodel
I0628 19:06:01.510514  7628 sgd_solver.cpp:288] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-06-28_18-56-45/initial/cifar10_jacintonet11v2_iter_30000.solverstate
I0628 19:06:01.514026  7628 solver.cpp:545] Iteration 30000, Testing net (#0)
I0628 19:06:02.520715  7626 data_reader.cpp:262] Starting prefetch of epoch 30
I0628 19:06:02.540995  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.849
I0628 19:06:02.541007  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.989
I0628 19:06:02.541010  7628 solver.cpp:630]     Test net output #2: loss = 0.603788 (* 1 = 0.603788 loss)
I0628 19:06:02.541024  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02696s
I0628 19:06:02.558336  7628 solver.cpp:349] Iteration 30000 (36.3285 iter/s, 2.75266s/100 iter), loss = 0.0241424
I0628 19:06:02.558359  7628 solver.cpp:371]     Train net output #0: loss = 0.0241429 (* 1 = 0.0241429 loss)
I0628 19:06:02.558363  7628 sgd_solver.cpp:137] Iteration 30000, lr = 0.053125, m = 0.9
I0628 19:06:04.275207  7628 solver.cpp:349] Iteration 30100 (58.2488 iter/s, 1.71677s/100 iter), loss = 0.20854
I0628 19:06:04.275228  7628 solver.cpp:371]     Train net output #0: loss = 0.208541 (* 1 = 0.208541 loss)
I0628 19:06:04.275233  7628 sgd_solver.cpp:137] Iteration 30100, lr = 0.0529688, m = 0.9
I0628 19:06:05.990310  7628 solver.cpp:349] Iteration 30200 (58.3088 iter/s, 1.71501s/100 iter), loss = 0.18254
I0628 19:06:05.990331  7628 solver.cpp:371]     Train net output #0: loss = 0.18254 (* 1 = 0.18254 loss)
I0628 19:06:05.990335  7628 sgd_solver.cpp:137] Iteration 30200, lr = 0.0528125, m = 0.9
I0628 19:06:07.707015  7628 solver.cpp:349] Iteration 30300 (58.2544 iter/s, 1.71661s/100 iter), loss = 0.134757
I0628 19:06:07.707039  7628 solver.cpp:371]     Train net output #0: loss = 0.134757 (* 1 = 0.134757 loss)
I0628 19:06:07.707046  7628 sgd_solver.cpp:137] Iteration 30300, lr = 0.0526563, m = 0.9
I0628 19:06:09.426231  7628 solver.cpp:349] Iteration 30400 (58.1695 iter/s, 1.71911s/100 iter), loss = 0.113125
I0628 19:06:09.426301  7628 solver.cpp:371]     Train net output #0: loss = 0.113126 (* 1 = 0.113126 loss)
I0628 19:06:09.426306  7628 sgd_solver.cpp:137] Iteration 30400, lr = 0.0525, m = 0.9
I0628 19:06:10.544381  7613 data_reader.cpp:262] Starting prefetch of epoch 39
I0628 19:06:11.144446  7628 solver.cpp:349] Iteration 30500 (58.2049 iter/s, 1.71807s/100 iter), loss = 0.0324748
I0628 19:06:11.144470  7628 solver.cpp:371]     Train net output #0: loss = 0.0324752 (* 1 = 0.0324752 loss)
I0628 19:06:11.144474  7628 sgd_solver.cpp:137] Iteration 30500, lr = 0.0523438, m = 0.9
I0628 19:06:12.860878  7628 solver.cpp:349] Iteration 30600 (58.2637 iter/s, 1.71634s/100 iter), loss = 0.0132616
I0628 19:06:12.860899  7628 solver.cpp:371]     Train net output #0: loss = 0.013262 (* 1 = 0.013262 loss)
I0628 19:06:12.860903  7628 sgd_solver.cpp:137] Iteration 30600, lr = 0.0521875, m = 0.9
I0628 19:06:14.574206  7628 solver.cpp:349] Iteration 30700 (58.3691 iter/s, 1.71324s/100 iter), loss = 0.0107287
I0628 19:06:14.574229  7628 solver.cpp:371]     Train net output #0: loss = 0.010729 (* 1 = 0.010729 loss)
I0628 19:06:14.574234  7628 sgd_solver.cpp:137] Iteration 30700, lr = 0.0520312, m = 0.9
I0628 19:06:16.287752  7628 solver.cpp:349] Iteration 30800 (58.3618 iter/s, 1.71345s/100 iter), loss = 0.230793
I0628 19:06:16.287775  7628 solver.cpp:371]     Train net output #0: loss = 0.230793 (* 1 = 0.230793 loss)
I0628 19:06:16.287778  7628 sgd_solver.cpp:137] Iteration 30800, lr = 0.051875, m = 0.9
I0628 19:06:18.004813  7628 solver.cpp:349] Iteration 30900 (58.2423 iter/s, 1.71696s/100 iter), loss = 0.0709451
I0628 19:06:18.004835  7628 solver.cpp:371]     Train net output #0: loss = 0.0709454 (* 1 = 0.0709454 loss)
I0628 19:06:18.004839  7628 sgd_solver.cpp:137] Iteration 30900, lr = 0.0517187, m = 0.9
I0628 19:06:19.703270  7628 solver.cpp:545] Iteration 31000, Testing net (#0)
I0628 19:06:20.711752  7626 data_reader.cpp:262] Starting prefetch of epoch 31
I0628 19:06:20.736156  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.7916
I0628 19:06:20.736176  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9894
I0628 19:06:20.736181  7628 solver.cpp:630]     Test net output #2: loss = 0.856665 (* 1 = 0.856665 loss)
I0628 19:06:20.736196  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.03289s
I0628 19:06:20.753470  7628 solver.cpp:349] Iteration 31000 (36.3831 iter/s, 2.74853s/100 iter), loss = 0.304491
I0628 19:06:20.753494  7628 solver.cpp:371]     Train net output #0: loss = 0.304491 (* 1 = 0.304491 loss)
I0628 19:06:20.753497  7628 sgd_solver.cpp:137] Iteration 31000, lr = 0.0515625, m = 0.9
I0628 19:06:22.470469  7628 solver.cpp:349] Iteration 31100 (58.2444 iter/s, 1.7169s/100 iter), loss = 0.121171
I0628 19:06:22.470489  7628 solver.cpp:371]     Train net output #0: loss = 0.121171 (* 1 = 0.121171 loss)
I0628 19:06:22.470494  7628 sgd_solver.cpp:137] Iteration 31100, lr = 0.0514063, m = 0.9
I0628 19:06:24.194416  7628 solver.cpp:349] Iteration 31200 (58.0095 iter/s, 1.72386s/100 iter), loss = 0.062766
I0628 19:06:24.194440  7628 solver.cpp:371]     Train net output #0: loss = 0.0627663 (* 1 = 0.0627663 loss)
I0628 19:06:24.194444  7628 sgd_solver.cpp:137] Iteration 31200, lr = 0.05125, m = 0.9
I0628 19:06:24.984730  7613 data_reader.cpp:262] Starting prefetch of epoch 40
I0628 19:06:25.917922  7628 solver.cpp:349] Iteration 31300 (58.0245 iter/s, 1.72341s/100 iter), loss = 0.110448
I0628 19:06:25.917943  7628 solver.cpp:371]     Train net output #0: loss = 0.110448 (* 1 = 0.110448 loss)
I0628 19:06:25.917948  7628 sgd_solver.cpp:137] Iteration 31300, lr = 0.0510938, m = 0.9
I0628 19:06:27.637514  7628 solver.cpp:349] Iteration 31400 (58.1565 iter/s, 1.7195s/100 iter), loss = 0.0764309
I0628 19:06:27.637537  7628 solver.cpp:371]     Train net output #0: loss = 0.0764313 (* 1 = 0.0764313 loss)
I0628 19:06:27.637540  7628 sgd_solver.cpp:137] Iteration 31400, lr = 0.0509375, m = 0.9
I0628 19:06:29.357252  7628 solver.cpp:349] Iteration 31500 (58.1516 iter/s, 1.71964s/100 iter), loss = 0.0140733
I0628 19:06:29.357275  7628 solver.cpp:371]     Train net output #0: loss = 0.0140736 (* 1 = 0.0140736 loss)
I0628 19:06:29.357292  7628 sgd_solver.cpp:137] Iteration 31500, lr = 0.0507812, m = 0.9
I0628 19:06:31.073936  7628 solver.cpp:349] Iteration 31600 (58.2556 iter/s, 1.71657s/100 iter), loss = 0.0125675
I0628 19:06:31.073959  7628 solver.cpp:371]     Train net output #0: loss = 0.0125678 (* 1 = 0.0125678 loss)
I0628 19:06:31.073964  7628 sgd_solver.cpp:137] Iteration 31600, lr = 0.050625, m = 0.9
I0628 19:06:32.788538  7628 solver.cpp:349] Iteration 31700 (58.3259 iter/s, 1.7145s/100 iter), loss = 0.0115482
I0628 19:06:32.788560  7628 solver.cpp:371]     Train net output #0: loss = 0.0115486 (* 1 = 0.0115486 loss)
I0628 19:06:32.788566  7628 sgd_solver.cpp:137] Iteration 31700, lr = 0.0504688, m = 0.9
I0628 19:06:34.507336  7628 solver.cpp:349] Iteration 31800 (58.1835 iter/s, 1.7187s/100 iter), loss = 0.0473853
I0628 19:06:34.507361  7628 solver.cpp:371]     Train net output #0: loss = 0.0473857 (* 1 = 0.0473857 loss)
I0628 19:06:34.507366  7628 sgd_solver.cpp:137] Iteration 31800, lr = 0.0503125, m = 0.9
I0628 19:06:36.223901  7628 solver.cpp:349] Iteration 31900 (58.2593 iter/s, 1.71646s/100 iter), loss = 0.0374394
I0628 19:06:36.223924  7628 solver.cpp:371]     Train net output #0: loss = 0.0374398 (* 1 = 0.0374398 loss)
I0628 19:06:36.223929  7628 sgd_solver.cpp:137] Iteration 31900, lr = 0.0501562, m = 0.9
I0628 19:06:37.928499  7628 solver.cpp:545] Iteration 32000, Testing net (#0)
I0628 19:06:38.933234  7626 data_reader.cpp:262] Starting prefetch of epoch 32
I0628 19:06:38.957514  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.8364
I0628 19:06:38.957526  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9906
I0628 19:06:38.957532  7628 solver.cpp:630]     Test net output #2: loss = 0.636487 (* 1 = 0.636487 loss)
I0628 19:06:38.957554  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02902s
I0628 19:06:38.974835  7628 solver.cpp:349] Iteration 32000 (36.353 iter/s, 2.7508s/100 iter), loss = 0.0228742
I0628 19:06:38.974858  7628 solver.cpp:371]     Train net output #0: loss = 0.0228745 (* 1 = 0.0228745 loss)
I0628 19:06:38.974861  7628 sgd_solver.cpp:137] Iteration 32000, lr = 0.05, m = 0.9
I0628 19:06:39.454885  7613 data_reader.cpp:262] Starting prefetch of epoch 41
I0628 19:06:40.693675  7628 solver.cpp:349] Iteration 32100 (58.1821 iter/s, 1.71874s/100 iter), loss = 0.00624635
I0628 19:06:40.693698  7628 solver.cpp:371]     Train net output #0: loss = 0.00624673 (* 1 = 0.00624673 loss)
I0628 19:06:40.693704  7628 sgd_solver.cpp:137] Iteration 32100, lr = 0.0498438, m = 0.9
I0628 19:06:42.409294  7628 solver.cpp:349] Iteration 32200 (58.2914 iter/s, 1.71552s/100 iter), loss = 0.00632464
I0628 19:06:42.409317  7628 solver.cpp:371]     Train net output #0: loss = 0.00632502 (* 1 = 0.00632502 loss)
I0628 19:06:42.409323  7628 sgd_solver.cpp:137] Iteration 32200, lr = 0.0496875, m = 0.9
I0628 19:06:44.127518  7628 solver.cpp:349] Iteration 32300 (58.203 iter/s, 1.71812s/100 iter), loss = 0.205381
I0628 19:06:44.127542  7628 solver.cpp:371]     Train net output #0: loss = 0.205381 (* 1 = 0.205381 loss)
I0628 19:06:44.127547  7628 sgd_solver.cpp:137] Iteration 32300, lr = 0.0495313, m = 0.9
I0628 19:06:45.841627  7628 solver.cpp:349] Iteration 32400 (58.3427 iter/s, 1.71401s/100 iter), loss = 0.0250125
I0628 19:06:45.841650  7628 solver.cpp:371]     Train net output #0: loss = 0.0250129 (* 1 = 0.0250129 loss)
I0628 19:06:45.841653  7628 sgd_solver.cpp:137] Iteration 32400, lr = 0.049375, m = 0.9
I0628 19:06:47.560745  7628 solver.cpp:349] Iteration 32500 (58.1725 iter/s, 1.71902s/100 iter), loss = 0.00547277
I0628 19:06:47.560768  7628 solver.cpp:371]     Train net output #0: loss = 0.00547318 (* 1 = 0.00547318 loss)
I0628 19:06:47.560772  7628 sgd_solver.cpp:137] Iteration 32500, lr = 0.0492188, m = 0.9
I0628 19:06:49.281523  7628 solver.cpp:349] Iteration 32600 (58.1165 iter/s, 1.72068s/100 iter), loss = 0.230489
I0628 19:06:49.281545  7628 solver.cpp:371]     Train net output #0: loss = 0.230489 (* 1 = 0.230489 loss)
I0628 19:06:49.281553  7628 sgd_solver.cpp:137] Iteration 32600, lr = 0.0490625, m = 0.9
I0628 19:06:50.998386  7628 solver.cpp:349] Iteration 32700 (58.2491 iter/s, 1.71676s/100 iter), loss = 0.0659411
I0628 19:06:50.998409  7628 solver.cpp:371]     Train net output #0: loss = 0.0659415 (* 1 = 0.0659415 loss)
I0628 19:06:50.998412  7628 sgd_solver.cpp:137] Iteration 32700, lr = 0.0489062, m = 0.9
I0628 19:06:52.713414  7628 solver.cpp:349] Iteration 32800 (58.3113 iter/s, 1.71493s/100 iter), loss = 0.0237529
I0628 19:06:52.713434  7628 solver.cpp:371]     Train net output #0: loss = 0.0237533 (* 1 = 0.0237533 loss)
I0628 19:06:52.713438  7628 sgd_solver.cpp:137] Iteration 32800, lr = 0.04875, m = 0.9
I0628 19:06:52.868574  7613 data_reader.cpp:262] Starting prefetch of epoch 42
I0628 19:06:54.427783  7628 solver.cpp:349] Iteration 32900 (58.3337 iter/s, 1.71427s/100 iter), loss = 0.0654004
I0628 19:06:54.427803  7628 solver.cpp:371]     Train net output #0: loss = 0.0654008 (* 1 = 0.0654008 loss)
I0628 19:06:54.427809  7628 sgd_solver.cpp:137] Iteration 32900, lr = 0.0485937, m = 0.9
I0628 19:06:56.136521  7628 solver.cpp:545] Iteration 33000, Testing net (#0)
I0628 19:06:57.143769  7626 data_reader.cpp:262] Starting prefetch of epoch 33
I0628 19:06:57.166792  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.8522
I0628 19:06:57.166805  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9924
I0628 19:06:57.166811  7628 solver.cpp:630]     Test net output #2: loss = 0.561435 (* 1 = 0.561435 loss)
I0628 19:06:57.166826  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.03027s
I0628 19:06:57.184093  7628 solver.cpp:349] Iteration 33000 (36.2821 iter/s, 2.75618s/100 iter), loss = 0.00449223
I0628 19:06:57.184118  7628 solver.cpp:371]     Train net output #0: loss = 0.0044926 (* 1 = 0.0044926 loss)
I0628 19:06:57.184123  7628 sgd_solver.cpp:137] Iteration 33000, lr = 0.0484375, m = 0.9
I0628 19:06:58.897359  7628 solver.cpp:349] Iteration 33100 (58.3714 iter/s, 1.71317s/100 iter), loss = 0.0134461
I0628 19:06:58.897382  7628 solver.cpp:371]     Train net output #0: loss = 0.0134464 (* 1 = 0.0134464 loss)
I0628 19:06:58.897385  7628 sgd_solver.cpp:137] Iteration 33100, lr = 0.0482813, m = 0.9
I0628 19:07:00.618787  7628 solver.cpp:349] Iteration 33200 (58.0946 iter/s, 1.72133s/100 iter), loss = 0.0356514
I0628 19:07:00.618824  7628 solver.cpp:371]     Train net output #0: loss = 0.0356518 (* 1 = 0.0356518 loss)
I0628 19:07:00.618830  7628 sgd_solver.cpp:137] Iteration 33200, lr = 0.048125, m = 0.9
I0628 19:07:02.337651  7628 solver.cpp:349] Iteration 33300 (58.1819 iter/s, 1.71875s/100 iter), loss = 0.0281387
I0628 19:07:02.337673  7628 solver.cpp:371]     Train net output #0: loss = 0.0281391 (* 1 = 0.0281391 loss)
I0628 19:07:02.337677  7628 sgd_solver.cpp:137] Iteration 33300, lr = 0.0479688, m = 0.9
I0628 19:07:04.053452  7628 solver.cpp:349] Iteration 33400 (58.2851 iter/s, 1.71571s/100 iter), loss = 0.0164205
I0628 19:07:04.053473  7628 solver.cpp:371]     Train net output #0: loss = 0.0164208 (* 1 = 0.0164208 loss)
I0628 19:07:04.053479  7628 sgd_solver.cpp:137] Iteration 33400, lr = 0.0478125, m = 0.9
I0628 19:07:05.771042  7628 solver.cpp:349] Iteration 33500 (58.2244 iter/s, 1.71749s/100 iter), loss = 0.0269668
I0628 19:07:05.771064  7628 solver.cpp:371]     Train net output #0: loss = 0.026967 (* 1 = 0.026967 loss)
I0628 19:07:05.771067  7628 sgd_solver.cpp:137] Iteration 33500, lr = 0.0476562, m = 0.9
I0628 19:07:07.313874  7613 data_reader.cpp:262] Starting prefetch of epoch 43
I0628 19:07:07.485524  7628 solver.cpp:349] Iteration 33600 (58.3299 iter/s, 1.71439s/100 iter), loss = 0.0663488
I0628 19:07:07.485553  7628 solver.cpp:371]     Train net output #0: loss = 0.0663491 (* 1 = 0.0663491 loss)
I0628 19:07:07.485559  7628 sgd_solver.cpp:137] Iteration 33600, lr = 0.0475, m = 0.9
I0628 19:07:09.202986  7628 solver.cpp:349] Iteration 33700 (58.2291 iter/s, 1.71736s/100 iter), loss = 0.0171326
I0628 19:07:09.203008  7628 solver.cpp:371]     Train net output #0: loss = 0.0171329 (* 1 = 0.0171329 loss)
I0628 19:07:09.203012  7628 sgd_solver.cpp:137] Iteration 33700, lr = 0.0473437, m = 0.9
I0628 19:07:10.918723  7628 solver.cpp:349] Iteration 33800 (58.2872 iter/s, 1.71564s/100 iter), loss = 0.100063
I0628 19:07:10.918793  7628 solver.cpp:371]     Train net output #0: loss = 0.100063 (* 1 = 0.100063 loss)
I0628 19:07:10.918799  7628 sgd_solver.cpp:137] Iteration 33800, lr = 0.0471875, m = 0.9
I0628 19:07:12.639168  7628 solver.cpp:349] Iteration 33900 (58.1294 iter/s, 1.7203s/100 iter), loss = 0.0367861
I0628 19:07:12.639191  7628 solver.cpp:371]     Train net output #0: loss = 0.0367865 (* 1 = 0.0367865 loss)
I0628 19:07:12.639195  7628 sgd_solver.cpp:137] Iteration 33900, lr = 0.0470312, m = 0.9
I0628 19:07:14.337692  7628 solver.cpp:545] Iteration 34000, Testing net (#0)
I0628 19:07:15.345922  7626 data_reader.cpp:262] Starting prefetch of epoch 34
I0628 19:07:15.366288  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.848
I0628 19:07:15.366302  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9926
I0628 19:07:15.366307  7628 solver.cpp:630]     Test net output #2: loss = 0.559289 (* 1 = 0.559289 loss)
I0628 19:07:15.366319  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.0286s
I0628 19:07:15.383575  7628 solver.cpp:349] Iteration 34000 (36.4395 iter/s, 2.74428s/100 iter), loss = 0.0220245
I0628 19:07:15.383599  7628 solver.cpp:371]     Train net output #0: loss = 0.0220248 (* 1 = 0.0220248 loss)
I0628 19:07:15.383602  7628 sgd_solver.cpp:137] Iteration 34000, lr = 0.046875, m = 0.9
I0628 19:07:17.102461  7628 solver.cpp:349] Iteration 34100 (58.1804 iter/s, 1.71879s/100 iter), loss = 0.0262743
I0628 19:07:17.102483  7628 solver.cpp:371]     Train net output #0: loss = 0.0262746 (* 1 = 0.0262746 loss)
I0628 19:07:17.102486  7628 sgd_solver.cpp:137] Iteration 34100, lr = 0.0467188, m = 0.9
I0628 19:07:18.824784  7628 solver.cpp:349] Iteration 34200 (58.0644 iter/s, 1.72223s/100 iter), loss = 0.120657
I0628 19:07:18.824805  7628 solver.cpp:371]     Train net output #0: loss = 0.120657 (* 1 = 0.120657 loss)
I0628 19:07:18.824808  7628 sgd_solver.cpp:137] Iteration 34200, lr = 0.0465625, m = 0.9
I0628 19:07:20.542635  7628 solver.cpp:349] Iteration 34300 (58.2154 iter/s, 1.71776s/100 iter), loss = 0.0190968
I0628 19:07:20.542659  7628 solver.cpp:371]     Train net output #0: loss = 0.0190971 (* 1 = 0.0190971 loss)
I0628 19:07:20.542662  7628 sgd_solver.cpp:137] Iteration 34300, lr = 0.0464063, m = 0.9
I0628 19:07:21.759445  7613 data_reader.cpp:262] Starting prefetch of epoch 44
I0628 19:07:22.256207  7628 solver.cpp:349] Iteration 34400 (58.3609 iter/s, 1.71348s/100 iter), loss = 0.196539
I0628 19:07:22.256229  7628 solver.cpp:371]     Train net output #0: loss = 0.19654 (* 1 = 0.19654 loss)
I0628 19:07:22.256233  7628 sgd_solver.cpp:137] Iteration 34400, lr = 0.04625, m = 0.9
I0628 19:07:23.974836  7628 solver.cpp:349] Iteration 34500 (58.1892 iter/s, 1.71853s/100 iter), loss = 0.0528431
I0628 19:07:23.974859  7628 solver.cpp:371]     Train net output #0: loss = 0.0528435 (* 1 = 0.0528435 loss)
I0628 19:07:23.974864  7628 sgd_solver.cpp:137] Iteration 34500, lr = 0.0460938, m = 0.9
I0628 19:07:25.696321  7628 solver.cpp:349] Iteration 34600 (58.0927 iter/s, 1.72139s/100 iter), loss = 0.0482805
I0628 19:07:25.696343  7628 solver.cpp:371]     Train net output #0: loss = 0.0482809 (* 1 = 0.0482809 loss)
I0628 19:07:25.696348  7628 sgd_solver.cpp:137] Iteration 34600, lr = 0.0459375, m = 0.9
I0628 19:07:27.412932  7628 solver.cpp:349] Iteration 34700 (58.2576 iter/s, 1.71651s/100 iter), loss = 0.127694
I0628 19:07:27.412955  7628 solver.cpp:371]     Train net output #0: loss = 0.127694 (* 1 = 0.127694 loss)
I0628 19:07:27.412958  7628 sgd_solver.cpp:137] Iteration 34700, lr = 0.0457813, m = 0.9
I0628 19:07:29.144345  7628 solver.cpp:349] Iteration 34800 (57.7595 iter/s, 1.73132s/100 iter), loss = 0.0281769
I0628 19:07:29.144366  7628 solver.cpp:371]     Train net output #0: loss = 0.0281772 (* 1 = 0.0281772 loss)
I0628 19:07:29.144369  7628 sgd_solver.cpp:137] Iteration 34800, lr = 0.045625, m = 0.9
I0628 19:07:30.859596  7628 solver.cpp:349] Iteration 34900 (58.3037 iter/s, 1.71516s/100 iter), loss = 0.0892715
I0628 19:07:30.859619  7628 solver.cpp:371]     Train net output #0: loss = 0.0892718 (* 1 = 0.0892718 loss)
I0628 19:07:30.859638  7628 sgd_solver.cpp:137] Iteration 34900, lr = 0.0454687, m = 0.9
I0628 19:07:32.560883  7628 solver.cpp:545] Iteration 35000, Testing net (#0)
I0628 19:07:33.567853  7626 data_reader.cpp:262] Starting prefetch of epoch 35
I0628 19:07:33.589843  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.8538
I0628 19:07:33.589855  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9936
I0628 19:07:33.589860  7628 solver.cpp:630]     Test net output #2: loss = 0.536602 (* 1 = 0.536602 loss)
I0628 19:07:33.589874  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02896s
I0628 19:07:33.607177  7628 solver.cpp:349] Iteration 35000 (36.3978 iter/s, 2.74742s/100 iter), loss = 0.0187084
I0628 19:07:33.607200  7628 solver.cpp:371]     Train net output #0: loss = 0.0187087 (* 1 = 0.0187087 loss)
I0628 19:07:33.607203  7628 sgd_solver.cpp:137] Iteration 35000, lr = 0.0453125, m = 0.9
I0628 19:07:35.322659  7628 solver.cpp:349] Iteration 35100 (58.2959 iter/s, 1.71539s/100 iter), loss = 0.110716
I0628 19:07:35.322682  7628 solver.cpp:371]     Train net output #0: loss = 0.110716 (* 1 = 0.110716 loss)
I0628 19:07:35.322688  7628 sgd_solver.cpp:137] Iteration 35100, lr = 0.0451563, m = 0.9
I0628 19:07:36.231232  7613 data_reader.cpp:262] Starting prefetch of epoch 45
I0628 19:07:37.036922  7628 solver.cpp:349] Iteration 35200 (58.3375 iter/s, 1.71416s/100 iter), loss = 0.0618912
I0628 19:07:37.036944  7628 solver.cpp:371]     Train net output #0: loss = 0.0618915 (* 1 = 0.0618915 loss)
I0628 19:07:37.036950  7628 sgd_solver.cpp:137] Iteration 35200, lr = 0.045, m = 0.9
I0628 19:07:38.753038  7628 solver.cpp:349] Iteration 35300 (58.2745 iter/s, 1.71602s/100 iter), loss = 0.0607481
I0628 19:07:38.753067  7628 solver.cpp:371]     Train net output #0: loss = 0.0607484 (* 1 = 0.0607484 loss)
I0628 19:07:38.753072  7628 sgd_solver.cpp:137] Iteration 35300, lr = 0.0448438, m = 0.9
I0628 19:07:40.471261  7628 solver.cpp:349] Iteration 35400 (58.2032 iter/s, 1.71812s/100 iter), loss = 0.00911259
I0628 19:07:40.471284  7628 solver.cpp:371]     Train net output #0: loss = 0.00911287 (* 1 = 0.00911287 loss)
I0628 19:07:40.471290  7628 sgd_solver.cpp:137] Iteration 35400, lr = 0.0446875, m = 0.9
I0628 19:07:42.190755  7628 solver.cpp:349] Iteration 35500 (58.1599 iter/s, 1.7194s/100 iter), loss = 0.0329522
I0628 19:07:42.190811  7628 solver.cpp:371]     Train net output #0: loss = 0.0329525 (* 1 = 0.0329525 loss)
I0628 19:07:42.190817  7628 sgd_solver.cpp:137] Iteration 35500, lr = 0.0445313, m = 0.9
I0628 19:07:43.909140  7628 solver.cpp:349] Iteration 35600 (58.1986 iter/s, 1.71825s/100 iter), loss = 0.0115108
I0628 19:07:43.909164  7628 solver.cpp:371]     Train net output #0: loss = 0.0115111 (* 1 = 0.0115111 loss)
I0628 19:07:43.909168  7628 sgd_solver.cpp:137] Iteration 35600, lr = 0.044375, m = 0.9
I0628 19:07:45.626662  7628 solver.cpp:349] Iteration 35700 (58.2267 iter/s, 1.71742s/100 iter), loss = 0.00237727
I0628 19:07:45.626684  7628 solver.cpp:371]     Train net output #0: loss = 0.00237758 (* 1 = 0.00237758 loss)
I0628 19:07:45.626688  7628 sgd_solver.cpp:137] Iteration 35700, lr = 0.0442187, m = 0.9
I0628 19:07:47.340960  7628 solver.cpp:349] Iteration 35800 (58.3361 iter/s, 1.7142s/100 iter), loss = 0.0121522
I0628 19:07:47.340981  7628 solver.cpp:371]     Train net output #0: loss = 0.0121525 (* 1 = 0.0121525 loss)
I0628 19:07:47.340986  7628 sgd_solver.cpp:137] Iteration 35800, lr = 0.0440625, m = 0.9
I0628 19:07:49.055169  7628 solver.cpp:349] Iteration 35900 (58.3392 iter/s, 1.71411s/100 iter), loss = 0.00802933
I0628 19:07:49.055194  7628 solver.cpp:371]     Train net output #0: loss = 0.00802965 (* 1 = 0.00802965 loss)
I0628 19:07:49.055200  7628 sgd_solver.cpp:137] Iteration 35900, lr = 0.0439062, m = 0.9
I0628 19:07:49.638314  7613 data_reader.cpp:262] Starting prefetch of epoch 46
I0628 19:07:50.753692  7628 solver.cpp:545] Iteration 36000, Testing net (#0)
I0628 19:07:51.761230  7626 data_reader.cpp:262] Starting prefetch of epoch 36
I0628 19:07:51.781632  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.8596
I0628 19:07:51.781647  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9906
I0628 19:07:51.781654  7628 solver.cpp:630]     Test net output #2: loss = 0.537938 (* 1 = 0.537938 loss)
I0628 19:07:51.781671  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02794s
I0628 19:07:51.798995  7628 solver.cpp:349] Iteration 36000 (36.4472 iter/s, 2.74369s/100 iter), loss = 0.0272031
I0628 19:07:51.799018  7628 solver.cpp:371]     Train net output #0: loss = 0.0272035 (* 1 = 0.0272035 loss)
I0628 19:07:51.799023  7628 sgd_solver.cpp:137] Iteration 36000, lr = 0.04375, m = 0.9
I0628 19:07:53.514238  7628 solver.cpp:349] Iteration 36100 (58.3041 iter/s, 1.71515s/100 iter), loss = 0.0089812
I0628 19:07:53.514261  7628 solver.cpp:371]     Train net output #0: loss = 0.00898156 (* 1 = 0.00898156 loss)
I0628 19:07:53.514266  7628 sgd_solver.cpp:137] Iteration 36100, lr = 0.0435938, m = 0.9
I0628 19:07:55.232810  7628 solver.cpp:349] Iteration 36200 (58.1912 iter/s, 1.71847s/100 iter), loss = 0.0155364
I0628 19:07:55.232832  7628 solver.cpp:371]     Train net output #0: loss = 0.0155368 (* 1 = 0.0155368 loss)
I0628 19:07:55.232836  7628 sgd_solver.cpp:137] Iteration 36200, lr = 0.0434375, m = 0.9
I0628 19:07:56.952695  7628 solver.cpp:349] Iteration 36300 (58.1467 iter/s, 1.71979s/100 iter), loss = 0.0181644
I0628 19:07:56.952718  7628 solver.cpp:371]     Train net output #0: loss = 0.0181647 (* 1 = 0.0181647 loss)
I0628 19:07:56.952724  7628 sgd_solver.cpp:137] Iteration 36300, lr = 0.0432813, m = 0.9
I0628 19:07:58.667616  7628 solver.cpp:349] Iteration 36400 (58.3152 iter/s, 1.71482s/100 iter), loss = 0.0159306
I0628 19:07:58.667639  7628 solver.cpp:371]     Train net output #0: loss = 0.015931 (* 1 = 0.015931 loss)
I0628 19:07:58.667644  7628 sgd_solver.cpp:137] Iteration 36400, lr = 0.043125, m = 0.9
I0628 19:08:00.381820  7628 solver.cpp:349] Iteration 36500 (58.3394 iter/s, 1.71411s/100 iter), loss = 0.0107752
I0628 19:08:00.381842  7628 solver.cpp:371]     Train net output #0: loss = 0.0107755 (* 1 = 0.0107755 loss)
I0628 19:08:00.381846  7628 sgd_solver.cpp:137] Iteration 36500, lr = 0.0429688, m = 0.9
I0628 19:08:02.102459  7628 solver.cpp:349] Iteration 36600 (58.1211 iter/s, 1.72054s/100 iter), loss = 0.024237
I0628 19:08:02.102483  7628 solver.cpp:371]     Train net output #0: loss = 0.0242374 (* 1 = 0.0242374 loss)
I0628 19:08:02.102501  7628 sgd_solver.cpp:137] Iteration 36600, lr = 0.0428125, m = 0.9
I0628 19:08:03.816993  7628 solver.cpp:349] Iteration 36700 (58.3287 iter/s, 1.71442s/100 iter), loss = 0.0201448
I0628 19:08:03.817014  7628 solver.cpp:371]     Train net output #0: loss = 0.0201452 (* 1 = 0.0201452 loss)
I0628 19:08:03.817018  7628 sgd_solver.cpp:137] Iteration 36700, lr = 0.0426563, m = 0.9
I0628 19:08:04.073990  7613 data_reader.cpp:262] Starting prefetch of epoch 47
I0628 19:08:05.531886  7628 solver.cpp:349] Iteration 36800 (58.3159 iter/s, 1.7148s/100 iter), loss = 0.00588903
I0628 19:08:05.531909  7628 solver.cpp:371]     Train net output #0: loss = 0.00588941 (* 1 = 0.00588941 loss)
I0628 19:08:05.531914  7628 sgd_solver.cpp:137] Iteration 36800, lr = 0.0425, m = 0.9
I0628 19:08:07.246667  7628 solver.cpp:349] Iteration 36900 (58.3198 iter/s, 1.71468s/100 iter), loss = 0.101347
I0628 19:08:07.246690  7628 solver.cpp:371]     Train net output #0: loss = 0.101348 (* 1 = 0.101348 loss)
I0628 19:08:07.246695  7628 sgd_solver.cpp:137] Iteration 36900, lr = 0.0423437, m = 0.9
I0628 19:08:08.946420  7628 solver.cpp:545] Iteration 37000, Testing net (#0)
I0628 19:08:09.952678  7626 data_reader.cpp:262] Starting prefetch of epoch 37
I0628 19:08:09.975914  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.8732
I0628 19:08:09.975927  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.995
I0628 19:08:09.975935  7628 solver.cpp:630]     Test net output #2: loss = 0.46482 (* 1 = 0.46482 loss)
I0628 19:08:09.975951  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.0295s
I0628 19:08:09.993208  7628 solver.cpp:349] Iteration 37000 (36.4111 iter/s, 2.74641s/100 iter), loss = 0.00667003
I0628 19:08:09.993232  7628 solver.cpp:371]     Train net output #0: loss = 0.00667039 (* 1 = 0.00667039 loss)
I0628 19:08:09.993235  7628 sgd_solver.cpp:137] Iteration 37000, lr = 0.0421875, m = 0.9
I0628 19:08:11.708642  7628 solver.cpp:349] Iteration 37100 (58.2976 iter/s, 1.71534s/100 iter), loss = 0.00462772
I0628 19:08:11.708664  7628 solver.cpp:371]     Train net output #0: loss = 0.00462809 (* 1 = 0.00462809 loss)
I0628 19:08:11.708669  7628 sgd_solver.cpp:137] Iteration 37100, lr = 0.0420313, m = 0.9
I0628 19:08:13.427738  7628 solver.cpp:349] Iteration 37200 (58.1734 iter/s, 1.719s/100 iter), loss = 0.0112082
I0628 19:08:13.427810  7628 solver.cpp:371]     Train net output #0: loss = 0.0112086 (* 1 = 0.0112086 loss)
I0628 19:08:13.427819  7628 sgd_solver.cpp:137] Iteration 37200, lr = 0.041875, m = 0.9
I0628 19:08:15.148217  7628 solver.cpp:349] Iteration 37300 (58.1288 iter/s, 1.72032s/100 iter), loss = 0.0235273
I0628 19:08:15.148241  7628 solver.cpp:371]     Train net output #0: loss = 0.0235276 (* 1 = 0.0235276 loss)
I0628 19:08:15.148247  7628 sgd_solver.cpp:137] Iteration 37300, lr = 0.0417188, m = 0.9
I0628 19:08:16.867226  7628 solver.cpp:349] Iteration 37400 (58.1764 iter/s, 1.71891s/100 iter), loss = 0.0162059
I0628 19:08:16.867249  7628 solver.cpp:371]     Train net output #0: loss = 0.0162063 (* 1 = 0.0162063 loss)
I0628 19:08:16.867254  7628 sgd_solver.cpp:137] Iteration 37400, lr = 0.0415625, m = 0.9
I0628 19:08:18.514746  7613 data_reader.cpp:262] Starting prefetch of epoch 48
I0628 19:08:18.583156  7628 solver.cpp:349] Iteration 37500 (58.2807 iter/s, 1.71583s/100 iter), loss = 0.0309206
I0628 19:08:18.583181  7628 solver.cpp:371]     Train net output #0: loss = 0.030921 (* 1 = 0.030921 loss)
I0628 19:08:18.583186  7628 sgd_solver.cpp:137] Iteration 37500, lr = 0.0414063, m = 0.9
I0628 19:08:20.304745  7628 solver.cpp:349] Iteration 37600 (58.0892 iter/s, 1.72149s/100 iter), loss = 0.0701489
I0628 19:08:20.304769  7628 solver.cpp:371]     Train net output #0: loss = 0.0701492 (* 1 = 0.0701492 loss)
I0628 19:08:20.304774  7628 sgd_solver.cpp:137] Iteration 37600, lr = 0.04125, m = 0.9
I0628 19:08:22.018965  7628 solver.cpp:349] Iteration 37700 (58.3389 iter/s, 1.71412s/100 iter), loss = 0.0114137
I0628 19:08:22.018987  7628 solver.cpp:371]     Train net output #0: loss = 0.0114141 (* 1 = 0.0114141 loss)
I0628 19:08:22.018993  7628 sgd_solver.cpp:137] Iteration 37700, lr = 0.0410937, m = 0.9
I0628 19:08:23.733577  7628 solver.cpp:349] Iteration 37800 (58.3256 iter/s, 1.71451s/100 iter), loss = 0.012169
I0628 19:08:23.733600  7628 solver.cpp:371]     Train net output #0: loss = 0.0121694 (* 1 = 0.0121694 loss)
I0628 19:08:23.733605  7628 sgd_solver.cpp:137] Iteration 37800, lr = 0.0409375, m = 0.9
I0628 19:08:25.450923  7628 solver.cpp:349] Iteration 37900 (58.2327 iter/s, 1.71725s/100 iter), loss = 0.0327604
I0628 19:08:25.450947  7628 solver.cpp:371]     Train net output #0: loss = 0.0327607 (* 1 = 0.0327607 loss)
I0628 19:08:25.450953  7628 sgd_solver.cpp:137] Iteration 37900, lr = 0.0407812, m = 0.9
I0628 19:08:27.155746  7628 solver.cpp:545] Iteration 38000, Testing net (#0)
I0628 19:08:28.163497  7626 data_reader.cpp:262] Starting prefetch of epoch 38
I0628 19:08:28.183831  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.849599
I0628 19:08:28.183845  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.991
I0628 19:08:28.183851  7628 solver.cpp:630]     Test net output #2: loss = 0.612599 (* 1 = 0.612599 loss)
I0628 19:08:28.183867  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02809s
I0628 19:08:28.201110  7628 solver.cpp:349] Iteration 38000 (36.3629 iter/s, 2.75005s/100 iter), loss = 0.0171528
I0628 19:08:28.201133  7628 solver.cpp:371]     Train net output #0: loss = 0.0171532 (* 1 = 0.0171532 loss)
I0628 19:08:28.201138  7628 sgd_solver.cpp:137] Iteration 38000, lr = 0.040625, m = 0.9
I0628 19:08:29.918480  7628 solver.cpp:349] Iteration 38100 (58.2319 iter/s, 1.71727s/100 iter), loss = 0.00206838
I0628 19:08:29.918501  7628 solver.cpp:371]     Train net output #0: loss = 0.00206876 (* 1 = 0.00206876 loss)
I0628 19:08:29.918505  7628 sgd_solver.cpp:137] Iteration 38100, lr = 0.0404688, m = 0.9
I0628 19:08:31.632891  7628 solver.cpp:349] Iteration 38200 (58.3323 iter/s, 1.71432s/100 iter), loss = 0.00361431
I0628 19:08:31.632913  7628 solver.cpp:371]     Train net output #0: loss = 0.00361472 (* 1 = 0.00361472 loss)
I0628 19:08:31.632918  7628 sgd_solver.cpp:137] Iteration 38200, lr = 0.0403125, m = 0.9
I0628 19:08:32.975740  7613 data_reader.cpp:262] Starting prefetch of epoch 49
I0628 19:08:33.352918  7628 solver.cpp:349] Iteration 38300 (58.1419 iter/s, 1.71993s/100 iter), loss = 0.00566228
I0628 19:08:33.352957  7628 solver.cpp:371]     Train net output #0: loss = 0.00566269 (* 1 = 0.00566269 loss)
I0628 19:08:33.352962  7628 sgd_solver.cpp:137] Iteration 38300, lr = 0.0401563, m = 0.9
I0628 19:08:35.084727  7628 solver.cpp:349] Iteration 38400 (57.7469 iter/s, 1.73169s/100 iter), loss = 0.00626966
I0628 19:08:35.084748  7628 solver.cpp:371]     Train net output #0: loss = 0.00627008 (* 1 = 0.00627008 loss)
I0628 19:08:35.084753  7628 sgd_solver.cpp:137] Iteration 38400, lr = 0.04, m = 0.9
I0628 19:08:36.797818  7628 solver.cpp:349] Iteration 38500 (58.3772 iter/s, 1.713s/100 iter), loss = 0.0153058
I0628 19:08:36.797842  7628 solver.cpp:371]     Train net output #0: loss = 0.0153063 (* 1 = 0.0153063 loss)
I0628 19:08:36.797845  7628 sgd_solver.cpp:137] Iteration 38500, lr = 0.0398437, m = 0.9
I0628 19:08:38.519796  7628 solver.cpp:349] Iteration 38600 (58.0759 iter/s, 1.72188s/100 iter), loss = 0.0286314
I0628 19:08:38.519820  7628 solver.cpp:371]     Train net output #0: loss = 0.0286318 (* 1 = 0.0286318 loss)
I0628 19:08:38.519826  7628 sgd_solver.cpp:137] Iteration 38600, lr = 0.0396875, m = 0.9
I0628 19:08:40.238936  7628 solver.cpp:349] Iteration 38700 (58.172 iter/s, 1.71904s/100 iter), loss = 0.0444973
I0628 19:08:40.238958  7628 solver.cpp:371]     Train net output #0: loss = 0.0444977 (* 1 = 0.0444977 loss)
I0628 19:08:40.238962  7628 sgd_solver.cpp:137] Iteration 38700, lr = 0.0395312, m = 0.9
I0628 19:08:41.958065  7628 solver.cpp:349] Iteration 38800 (58.1722 iter/s, 1.71903s/100 iter), loss = 0.00743446
I0628 19:08:41.958086  7628 solver.cpp:371]     Train net output #0: loss = 0.00743485 (* 1 = 0.00743485 loss)
I0628 19:08:41.958089  7628 sgd_solver.cpp:137] Iteration 38800, lr = 0.039375, m = 0.9
I0628 19:08:43.679538  7628 solver.cpp:349] Iteration 38900 (58.0929 iter/s, 1.72138s/100 iter), loss = 0.0333561
I0628 19:08:43.679596  7628 solver.cpp:371]     Train net output #0: loss = 0.0333565 (* 1 = 0.0333565 loss)
I0628 19:08:43.679602  7628 sgd_solver.cpp:137] Iteration 38900, lr = 0.0392187, m = 0.9
I0628 19:08:45.380416  7628 solver.cpp:545] Iteration 39000, Testing net (#0)
I0628 19:08:46.386996  7626 data_reader.cpp:262] Starting prefetch of epoch 39
I0628 19:08:46.412103  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.8528
I0628 19:08:46.412117  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9922
I0628 19:08:46.412122  7628 solver.cpp:630]     Test net output #2: loss = 0.576209 (* 1 = 0.576209 loss)
I0628 19:08:46.412137  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.03169s
I0628 19:08:46.429533  7628 solver.cpp:349] Iteration 39000 (36.3659 iter/s, 2.74983s/100 iter), loss = 0.00407377
I0628 19:08:46.429560  7628 solver.cpp:371]     Train net output #0: loss = 0.00407415 (* 1 = 0.00407415 loss)
I0628 19:08:46.429564  7628 sgd_solver.cpp:137] Iteration 39000, lr = 0.0390625, m = 0.9
I0628 19:08:47.440009  7613 data_reader.cpp:262] Starting prefetch of epoch 50
I0628 19:08:48.144347  7628 solver.cpp:349] Iteration 39100 (58.3188 iter/s, 1.71471s/100 iter), loss = 0.0473808
I0628 19:08:48.144369  7628 solver.cpp:371]     Train net output #0: loss = 0.0473812 (* 1 = 0.0473812 loss)
I0628 19:08:48.144374  7628 sgd_solver.cpp:137] Iteration 39100, lr = 0.0389063, m = 0.9
I0628 19:08:49.861182  7628 solver.cpp:349] Iteration 39200 (58.2499 iter/s, 1.71674s/100 iter), loss = 0.00407912
I0628 19:08:49.861203  7628 solver.cpp:371]     Train net output #0: loss = 0.00407951 (* 1 = 0.00407951 loss)
I0628 19:08:49.861207  7628 sgd_solver.cpp:137] Iteration 39200, lr = 0.03875, m = 0.9
I0628 19:08:51.579151  7628 solver.cpp:349] Iteration 39300 (58.2115 iter/s, 1.71787s/100 iter), loss = 0.00519119
I0628 19:08:51.579174  7628 solver.cpp:371]     Train net output #0: loss = 0.00519157 (* 1 = 0.00519157 loss)
I0628 19:08:51.579179  7628 sgd_solver.cpp:137] Iteration 39300, lr = 0.0385938, m = 0.9
I0628 19:08:53.299473  7628 solver.cpp:349] Iteration 39400 (58.1319 iter/s, 1.72022s/100 iter), loss = 0.0811738
I0628 19:08:53.299494  7628 solver.cpp:371]     Train net output #0: loss = 0.0811741 (* 1 = 0.0811741 loss)
I0628 19:08:53.299499  7628 sgd_solver.cpp:137] Iteration 39400, lr = 0.0384375, m = 0.9
I0628 19:08:55.016705  7628 solver.cpp:349] Iteration 39500 (58.2365 iter/s, 1.71714s/100 iter), loss = 0.0086869
I0628 19:08:55.016726  7628 solver.cpp:371]     Train net output #0: loss = 0.00868726 (* 1 = 0.00868726 loss)
I0628 19:08:55.016731  7628 sgd_solver.cpp:137] Iteration 39500, lr = 0.0382813, m = 0.9
I0628 19:08:56.735754  7628 solver.cpp:349] Iteration 39600 (58.1749 iter/s, 1.71895s/100 iter), loss = 0.00970481
I0628 19:08:56.735780  7628 solver.cpp:371]     Train net output #0: loss = 0.0097052 (* 1 = 0.0097052 loss)
I0628 19:08:56.735785  7628 sgd_solver.cpp:137] Iteration 39600, lr = 0.038125, m = 0.9
I0628 19:08:58.452507  7628 solver.cpp:349] Iteration 39700 (58.253 iter/s, 1.71665s/100 iter), loss = 0.00522529
I0628 19:08:58.452530  7628 solver.cpp:371]     Train net output #0: loss = 0.00522569 (* 1 = 0.00522569 loss)
I0628 19:08:58.452534  7628 sgd_solver.cpp:137] Iteration 39700, lr = 0.0379688, m = 0.9
I0628 19:09:00.170562  7628 solver.cpp:349] Iteration 39800 (58.2087 iter/s, 1.71796s/100 iter), loss = 0.01124
I0628 19:09:00.170588  7628 solver.cpp:371]     Train net output #0: loss = 0.0112404 (* 1 = 0.0112404 loss)
I0628 19:09:00.170593  7628 sgd_solver.cpp:137] Iteration 39800, lr = 0.0378125, m = 0.9
I0628 19:09:00.859266  7613 data_reader.cpp:262] Starting prefetch of epoch 51
I0628 19:09:01.888404  7628 solver.cpp:349] Iteration 39900 (58.2159 iter/s, 1.71774s/100 iter), loss = 0.0106123
I0628 19:09:01.888427  7628 solver.cpp:371]     Train net output #0: loss = 0.0106127 (* 1 = 0.0106127 loss)
I0628 19:09:01.888430  7628 sgd_solver.cpp:137] Iteration 39900, lr = 0.0376562, m = 0.9
I0628 19:09:03.590788  7628 solver.cpp:675] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-06-28_18-56-45/initial/cifar10_jacintonet11v2_iter_40000.caffemodel
I0628 19:09:03.598634  7628 sgd_solver.cpp:288] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-06-28_18-56-45/initial/cifar10_jacintonet11v2_iter_40000.solverstate
I0628 19:09:03.602140  7628 solver.cpp:545] Iteration 40000, Testing net (#0)
I0628 19:09:04.607772  7626 data_reader.cpp:262] Starting prefetch of epoch 40
I0628 19:09:04.628270  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.8754
I0628 19:09:04.628288  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9966
I0628 19:09:04.628293  7628 solver.cpp:630]     Test net output #2: loss = 0.496466 (* 1 = 0.496466 loss)
I0628 19:09:04.628307  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02613s
I0628 19:09:04.645763  7628 solver.cpp:349] Iteration 40000 (36.2683 iter/s, 2.75723s/100 iter), loss = 0.0346598
I0628 19:09:04.645784  7628 solver.cpp:371]     Train net output #0: loss = 0.0346602 (* 1 = 0.0346602 loss)
I0628 19:09:04.645788  7628 sgd_solver.cpp:137] Iteration 40000, lr = 0.0375, m = 0.9
I0628 19:09:06.363258  7628 solver.cpp:349] Iteration 40100 (58.2275 iter/s, 1.7174s/100 iter), loss = 0.0196048
I0628 19:09:06.363281  7628 solver.cpp:371]     Train net output #0: loss = 0.0196052 (* 1 = 0.0196052 loss)
I0628 19:09:06.363286  7628 sgd_solver.cpp:137] Iteration 40100, lr = 0.0373438, m = 0.9
I0628 19:09:08.083108  7628 solver.cpp:349] Iteration 40200 (58.148 iter/s, 1.71975s/100 iter), loss = 0.113466
I0628 19:09:08.083132  7628 solver.cpp:371]     Train net output #0: loss = 0.113467 (* 1 = 0.113467 loss)
I0628 19:09:08.083138  7628 sgd_solver.cpp:137] Iteration 40200, lr = 0.0371875, m = 0.9
I0628 19:09:09.805130  7628 solver.cpp:349] Iteration 40300 (58.0747 iter/s, 1.72192s/100 iter), loss = 0.0101451
I0628 19:09:09.805153  7628 solver.cpp:371]     Train net output #0: loss = 0.0101455 (* 1 = 0.0101455 loss)
I0628 19:09:09.805158  7628 sgd_solver.cpp:137] Iteration 40300, lr = 0.0370313, m = 0.9
I0628 19:09:11.524960  7628 solver.cpp:349] Iteration 40400 (58.1485 iter/s, 1.71973s/100 iter), loss = 0.0108949
I0628 19:09:11.524984  7628 solver.cpp:371]     Train net output #0: loss = 0.0108954 (* 1 = 0.0108954 loss)
I0628 19:09:11.524988  7628 sgd_solver.cpp:137] Iteration 40400, lr = 0.036875, m = 0.9
I0628 19:09:13.242022  7628 solver.cpp:349] Iteration 40500 (58.2424 iter/s, 1.71696s/100 iter), loss = 0.0207278
I0628 19:09:13.242044  7628 solver.cpp:371]     Train net output #0: loss = 0.0207282 (* 1 = 0.0207282 loss)
I0628 19:09:13.242048  7628 sgd_solver.cpp:137] Iteration 40500, lr = 0.0367188, m = 0.9
I0628 19:09:14.959985  7628 solver.cpp:349] Iteration 40600 (58.2117 iter/s, 1.71787s/100 iter), loss = 0.0356346
I0628 19:09:14.960050  7628 solver.cpp:371]     Train net output #0: loss = 0.035635 (* 1 = 0.035635 loss)
I0628 19:09:14.960055  7628 sgd_solver.cpp:137] Iteration 40600, lr = 0.0365625, m = 0.9
I0628 19:09:15.320765  7613 data_reader.cpp:262] Starting prefetch of epoch 52
I0628 19:09:16.676318  7628 solver.cpp:349] Iteration 40700 (58.2685 iter/s, 1.71619s/100 iter), loss = 0.00262606
I0628 19:09:16.676343  7628 solver.cpp:371]     Train net output #0: loss = 0.00262653 (* 1 = 0.00262653 loss)
I0628 19:09:16.676347  7628 sgd_solver.cpp:137] Iteration 40700, lr = 0.0364062, m = 0.9
I0628 19:09:18.395689  7628 solver.cpp:349] Iteration 40800 (58.1641 iter/s, 1.71927s/100 iter), loss = 0.0360126
I0628 19:09:18.395714  7628 solver.cpp:371]     Train net output #0: loss = 0.0360131 (* 1 = 0.0360131 loss)
I0628 19:09:18.395717  7628 sgd_solver.cpp:137] Iteration 40800, lr = 0.03625, m = 0.9
I0628 19:09:20.112407  7628 solver.cpp:349] Iteration 40900 (58.254 iter/s, 1.71662s/100 iter), loss = 0.100507
I0628 19:09:20.112431  7628 solver.cpp:371]     Train net output #0: loss = 0.100508 (* 1 = 0.100508 loss)
I0628 19:09:20.112435  7628 sgd_solver.cpp:137] Iteration 40900, lr = 0.0360937, m = 0.9
I0628 19:09:21.810118  7628 solver.cpp:545] Iteration 41000, Testing net (#0)
I0628 19:09:22.815233  7626 data_reader.cpp:262] Starting prefetch of epoch 41
I0628 19:09:22.838134  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.8754
I0628 19:09:22.838146  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9928
I0628 19:09:22.838151  7628 solver.cpp:630]     Test net output #2: loss = 0.52067 (* 1 = 0.52067 loss)
I0628 19:09:22.838165  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02801s
I0628 19:09:22.855538  7628 solver.cpp:349] Iteration 41000 (36.4564 iter/s, 2.743s/100 iter), loss = 0.0448198
I0628 19:09:22.855566  7628 solver.cpp:371]     Train net output #0: loss = 0.0448203 (* 1 = 0.0448203 loss)
I0628 19:09:22.855571  7628 sgd_solver.cpp:137] Iteration 41000, lr = 0.0359375, m = 0.9
I0628 19:09:24.573632  7628 solver.cpp:349] Iteration 41100 (58.2075 iter/s, 1.71799s/100 iter), loss = 0.0312866
I0628 19:09:24.573654  7628 solver.cpp:371]     Train net output #0: loss = 0.031287 (* 1 = 0.031287 loss)
I0628 19:09:24.573659  7628 sgd_solver.cpp:137] Iteration 41100, lr = 0.0357813, m = 0.9
I0628 19:09:26.292304  7628 solver.cpp:349] Iteration 41200 (58.1877 iter/s, 1.71857s/100 iter), loss = 0.0465467
I0628 19:09:26.292323  7628 solver.cpp:371]     Train net output #0: loss = 0.0465472 (* 1 = 0.0465472 loss)
I0628 19:09:26.292327  7628 sgd_solver.cpp:137] Iteration 41200, lr = 0.035625, m = 0.9
I0628 19:09:28.007899  7628 solver.cpp:349] Iteration 41300 (58.2919 iter/s, 1.7155s/100 iter), loss = 0.00172372
I0628 19:09:28.007922  7628 solver.cpp:371]     Train net output #0: loss = 0.0017242 (* 1 = 0.0017242 loss)
I0628 19:09:28.007926  7628 sgd_solver.cpp:137] Iteration 41300, lr = 0.0354688, m = 0.9
I0628 19:09:29.724270  7628 solver.cpp:349] Iteration 41400 (58.2657 iter/s, 1.71628s/100 iter), loss = 0.00651548
I0628 19:09:29.724293  7628 solver.cpp:371]     Train net output #0: loss = 0.00651595 (* 1 = 0.00651595 loss)
I0628 19:09:29.724298  7628 sgd_solver.cpp:137] Iteration 41400, lr = 0.0353125, m = 0.9
I0628 19:09:29.775957  7613 data_reader.cpp:262] Starting prefetch of epoch 53
I0628 19:09:31.441108  7628 solver.cpp:349] Iteration 41500 (58.2554 iter/s, 1.71658s/100 iter), loss = 0.0578199
I0628 19:09:31.441131  7628 solver.cpp:371]     Train net output #0: loss = 0.0578204 (* 1 = 0.0578204 loss)
I0628 19:09:31.441136  7628 sgd_solver.cpp:137] Iteration 41500, lr = 0.0351562, m = 0.9
I0628 19:09:33.162967  7628 solver.cpp:349] Iteration 41600 (58.087 iter/s, 1.72156s/100 iter), loss = 0.0221522
I0628 19:09:33.162992  7628 solver.cpp:371]     Train net output #0: loss = 0.0221526 (* 1 = 0.0221526 loss)
I0628 19:09:33.162997  7628 sgd_solver.cpp:137] Iteration 41600, lr = 0.035, m = 0.9
I0628 19:09:34.880414  7628 solver.cpp:349] Iteration 41700 (58.2364 iter/s, 1.71714s/100 iter), loss = 0.0124277
I0628 19:09:34.880447  7628 solver.cpp:371]     Train net output #0: loss = 0.0124281 (* 1 = 0.0124281 loss)
I0628 19:09:34.880452  7628 sgd_solver.cpp:137] Iteration 41700, lr = 0.0348438, m = 0.9
I0628 19:09:36.598331  7628 solver.cpp:349] Iteration 41800 (58.2208 iter/s, 1.7176s/100 iter), loss = 0.00652132
I0628 19:09:36.598354  7628 solver.cpp:371]     Train net output #0: loss = 0.00652179 (* 1 = 0.00652179 loss)
I0628 19:09:36.598358  7628 sgd_solver.cpp:137] Iteration 41800, lr = 0.0346875, m = 0.9
I0628 19:09:38.321244  7628 solver.cpp:349] Iteration 41900 (58.0515 iter/s, 1.72261s/100 iter), loss = 0.0147461
I0628 19:09:38.321266  7628 solver.cpp:371]     Train net output #0: loss = 0.0147465 (* 1 = 0.0147465 loss)
I0628 19:09:38.321270  7628 sgd_solver.cpp:137] Iteration 41900, lr = 0.0345312, m = 0.9
I0628 19:09:40.021109  7628 solver.cpp:545] Iteration 42000, Testing net (#0)
I0628 19:09:41.027163  7626 data_reader.cpp:262] Starting prefetch of epoch 42
I0628 19:09:41.049722  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.8882
I0628 19:09:41.049736  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9954
I0628 19:09:41.049741  7628 solver.cpp:630]     Test net output #2: loss = 0.461238 (* 1 = 0.461238 loss)
I0628 19:09:41.049754  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02849s
I0628 19:09:41.066990  7628 solver.cpp:349] Iteration 42000 (36.4261 iter/s, 2.74529s/100 iter), loss = 0.00966658
I0628 19:09:41.067013  7628 solver.cpp:371]     Train net output #0: loss = 0.00966707 (* 1 = 0.00966707 loss)
I0628 19:09:41.067016  7628 sgd_solver.cpp:137] Iteration 42000, lr = 0.034375, m = 0.9
I0628 19:09:42.780144  7628 solver.cpp:349] Iteration 42100 (58.3822 iter/s, 1.71285s/100 iter), loss = 0.00243018
I0628 19:09:42.780166  7628 solver.cpp:371]     Train net output #0: loss = 0.00243066 (* 1 = 0.00243066 loss)
I0628 19:09:42.780170  7628 sgd_solver.cpp:137] Iteration 42100, lr = 0.0342188, m = 0.9
I0628 19:09:44.223675  7613 data_reader.cpp:262] Starting prefetch of epoch 54
I0628 19:09:44.497489  7628 solver.cpp:349] Iteration 42200 (58.2397 iter/s, 1.71704s/100 iter), loss = 0.00100872
I0628 19:09:44.497510  7628 solver.cpp:371]     Train net output #0: loss = 0.00100921 (* 1 = 0.00100921 loss)
I0628 19:09:44.497514  7628 sgd_solver.cpp:137] Iteration 42200, lr = 0.0340625, m = 0.9
I0628 19:09:46.220155  7628 solver.cpp:349] Iteration 42300 (58.0598 iter/s, 1.72236s/100 iter), loss = 0.00575902
I0628 19:09:46.221843  7628 solver.cpp:371]     Train net output #0: loss = 0.00575952 (* 1 = 0.00575952 loss)
I0628 19:09:46.221851  7628 sgd_solver.cpp:137] Iteration 42300, lr = 0.0339063, m = 0.9
I0628 19:09:47.936377  7628 solver.cpp:349] Iteration 42400 (58.3347 iter/s, 1.71425s/100 iter), loss = 0.00137994
I0628 19:09:47.936395  7628 solver.cpp:371]     Train net output #0: loss = 0.00138043 (* 1 = 0.00138043 loss)
I0628 19:09:47.936399  7628 sgd_solver.cpp:137] Iteration 42400, lr = 0.03375, m = 0.9
I0628 19:09:49.651553  7628 solver.cpp:349] Iteration 42500 (58.3132 iter/s, 1.71488s/100 iter), loss = 0.00101983
I0628 19:09:49.651576  7628 solver.cpp:371]     Train net output #0: loss = 0.00102033 (* 1 = 0.00102033 loss)
I0628 19:09:49.651579  7628 sgd_solver.cpp:137] Iteration 42500, lr = 0.0335938, m = 0.9
I0628 19:09:51.364567  7628 solver.cpp:349] Iteration 42600 (58.3869 iter/s, 1.71271s/100 iter), loss = 0.0333354
I0628 19:09:51.364589  7628 solver.cpp:371]     Train net output #0: loss = 0.0333359 (* 1 = 0.0333359 loss)
I0628 19:09:51.364593  7628 sgd_solver.cpp:137] Iteration 42600, lr = 0.0334375, m = 0.9
I0628 19:09:53.085614  7628 solver.cpp:349] Iteration 42700 (58.1144 iter/s, 1.72074s/100 iter), loss = 0.0114139
I0628 19:09:53.085636  7628 solver.cpp:371]     Train net output #0: loss = 0.0114144 (* 1 = 0.0114144 loss)
I0628 19:09:53.085640  7628 sgd_solver.cpp:137] Iteration 42700, lr = 0.0332812, m = 0.9
I0628 19:09:54.801475  7628 solver.cpp:349] Iteration 42800 (58.2902 iter/s, 1.71556s/100 iter), loss = 0.00239018
I0628 19:09:54.801496  7628 solver.cpp:371]     Train net output #0: loss = 0.00239066 (* 1 = 0.00239066 loss)
I0628 19:09:54.801501  7628 sgd_solver.cpp:137] Iteration 42800, lr = 0.033125, m = 0.9
I0628 19:09:56.521100  7628 solver.cpp:349] Iteration 42900 (58.1624 iter/s, 1.71932s/100 iter), loss = 0.0131129
I0628 19:09:56.521121  7628 solver.cpp:371]     Train net output #0: loss = 0.0131134 (* 1 = 0.0131134 loss)
I0628 19:09:56.521126  7628 sgd_solver.cpp:137] Iteration 42900, lr = 0.0329687, m = 0.9
I0628 19:09:57.637574  7613 data_reader.cpp:262] Starting prefetch of epoch 55
I0628 19:09:58.221505  7628 solver.cpp:545] Iteration 43000, Testing net (#0)
I0628 19:09:59.226701  7626 data_reader.cpp:262] Starting prefetch of epoch 43
I0628 19:09:59.249558  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.8992
I0628 19:09:59.249572  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9942
I0628 19:09:59.249577  7628 solver.cpp:630]     Test net output #2: loss = 0.413229 (* 1 = 0.413229 loss)
I0628 19:09:59.249590  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02793s
I0628 19:09:59.266927  7628 solver.cpp:349] Iteration 43000 (36.425 iter/s, 2.74537s/100 iter), loss = 0.0030306
I0628 19:09:59.266949  7628 solver.cpp:371]     Train net output #0: loss = 0.00303108 (* 1 = 0.00303108 loss)
I0628 19:09:59.266953  7628 sgd_solver.cpp:137] Iteration 43000, lr = 0.0328125, m = 0.9
I0628 19:10:00.981752  7628 solver.cpp:349] Iteration 43100 (58.3252 iter/s, 1.71452s/100 iter), loss = 0.00149266
I0628 19:10:00.981775  7628 solver.cpp:371]     Train net output #0: loss = 0.00149314 (* 1 = 0.00149314 loss)
I0628 19:10:00.981777  7628 sgd_solver.cpp:137] Iteration 43100, lr = 0.0326563, m = 0.9
I0628 19:10:02.695204  7628 solver.cpp:349] Iteration 43200 (58.372 iter/s, 1.71315s/100 iter), loss = 0.00574449
I0628 19:10:02.695226  7628 solver.cpp:371]     Train net output #0: loss = 0.00574497 (* 1 = 0.00574497 loss)
I0628 19:10:02.695230  7628 sgd_solver.cpp:137] Iteration 43200, lr = 0.0325, m = 0.9
I0628 19:10:04.410310  7628 solver.cpp:349] Iteration 43300 (58.3157 iter/s, 1.7148s/100 iter), loss = 0.0112118
I0628 19:10:04.410332  7628 solver.cpp:371]     Train net output #0: loss = 0.0112122 (* 1 = 0.0112122 loss)
I0628 19:10:04.410336  7628 sgd_solver.cpp:137] Iteration 43300, lr = 0.0323438, m = 0.9
I0628 19:10:06.128149  7628 solver.cpp:349] Iteration 43400 (58.2229 iter/s, 1.71754s/100 iter), loss = 0.00467569
I0628 19:10:06.128170  7628 solver.cpp:371]     Train net output #0: loss = 0.00467617 (* 1 = 0.00467617 loss)
I0628 19:10:06.128190  7628 sgd_solver.cpp:137] Iteration 43400, lr = 0.0321875, m = 0.9
I0628 19:10:07.845494  7628 solver.cpp:349] Iteration 43500 (58.2402 iter/s, 1.71703s/100 iter), loss = 0.00383569
I0628 19:10:07.845516  7628 solver.cpp:371]     Train net output #0: loss = 0.00383617 (* 1 = 0.00383617 loss)
I0628 19:10:07.845520  7628 sgd_solver.cpp:137] Iteration 43500, lr = 0.0320312, m = 0.9
I0628 19:10:09.561127  7628 solver.cpp:349] Iteration 43600 (58.2979 iter/s, 1.71533s/100 iter), loss = 0.00209082
I0628 19:10:09.561151  7628 solver.cpp:371]     Train net output #0: loss = 0.00209129 (* 1 = 0.00209129 loss)
I0628 19:10:09.561154  7628 sgd_solver.cpp:137] Iteration 43600, lr = 0.031875, m = 0.9
I0628 19:10:11.279901  7628 solver.cpp:349] Iteration 43700 (58.1914 iter/s, 1.71847s/100 iter), loss = 0.00163946
I0628 19:10:11.279922  7628 solver.cpp:371]     Train net output #0: loss = 0.00163994 (* 1 = 0.00163994 loss)
I0628 19:10:11.279927  7628 sgd_solver.cpp:137] Iteration 43700, lr = 0.0317187, m = 0.9
I0628 19:10:12.067689  7613 data_reader.cpp:262] Starting prefetch of epoch 56
I0628 19:10:12.995774  7628 solver.cpp:349] Iteration 43800 (58.2897 iter/s, 1.71557s/100 iter), loss = 0.00229173
I0628 19:10:12.995795  7628 solver.cpp:371]     Train net output #0: loss = 0.00229221 (* 1 = 0.00229221 loss)
I0628 19:10:12.995798  7628 sgd_solver.cpp:137] Iteration 43800, lr = 0.0315625, m = 0.9
I0628 19:10:14.707870  7628 solver.cpp:349] Iteration 43900 (58.4182 iter/s, 1.7118s/100 iter), loss = 0.00158572
I0628 19:10:14.707892  7628 solver.cpp:371]     Train net output #0: loss = 0.0015862 (* 1 = 0.0015862 loss)
I0628 19:10:14.707896  7628 sgd_solver.cpp:137] Iteration 43900, lr = 0.0314062, m = 0.9
I0628 19:10:16.407232  7628 solver.cpp:545] Iteration 44000, Testing net (#0)
I0628 19:10:17.417415  7626 data_reader.cpp:262] Starting prefetch of epoch 44
I0628 19:10:17.437829  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.8966
I0628 19:10:17.437842  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9966
I0628 19:10:17.437847  7628 solver.cpp:630]     Test net output #2: loss = 0.41162 (* 1 = 0.41162 loss)
I0628 19:10:17.437860  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.03047s
I0628 19:10:17.455255  7628 solver.cpp:349] Iteration 44000 (36.4043 iter/s, 2.74693s/100 iter), loss = 0.00776767
I0628 19:10:17.455277  7628 solver.cpp:371]     Train net output #0: loss = 0.00776816 (* 1 = 0.00776816 loss)
I0628 19:10:17.455281  7628 sgd_solver.cpp:137] Iteration 44000, lr = 0.03125, m = 0.9
I0628 19:10:19.170554  7628 solver.cpp:349] Iteration 44100 (58.3092 iter/s, 1.71499s/100 iter), loss = 0.00415644
I0628 19:10:19.170574  7628 solver.cpp:371]     Train net output #0: loss = 0.00415693 (* 1 = 0.00415693 loss)
I0628 19:10:19.170578  7628 sgd_solver.cpp:137] Iteration 44100, lr = 0.0310938, m = 0.9
I0628 19:10:20.886026  7628 solver.cpp:349] Iteration 44200 (58.3032 iter/s, 1.71517s/100 iter), loss = 0.000475857
I0628 19:10:20.886050  7628 solver.cpp:371]     Train net output #0: loss = 0.000476353 (* 1 = 0.000476353 loss)
I0628 19:10:20.886055  7628 sgd_solver.cpp:137] Iteration 44200, lr = 0.0309375, m = 0.9
I0628 19:10:22.604846  7628 solver.cpp:349] Iteration 44300 (58.1899 iter/s, 1.71851s/100 iter), loss = 0.000835079
I0628 19:10:22.604869  7628 solver.cpp:371]     Train net output #0: loss = 0.000835574 (* 1 = 0.000835574 loss)
I0628 19:10:22.604874  7628 sgd_solver.cpp:137] Iteration 44300, lr = 0.0307813, m = 0.9
I0628 19:10:24.322022  7628 solver.cpp:349] Iteration 44400 (58.2456 iter/s, 1.71687s/100 iter), loss = 0.000569043
I0628 19:10:24.322044  7628 solver.cpp:371]     Train net output #0: loss = 0.000569534 (* 1 = 0.000569534 loss)
I0628 19:10:24.322048  7628 sgd_solver.cpp:137] Iteration 44400, lr = 0.030625, m = 0.9
I0628 19:10:26.036743  7628 solver.cpp:349] Iteration 44500 (58.3288 iter/s, 1.71442s/100 iter), loss = 0.00224332
I0628 19:10:26.036763  7628 solver.cpp:371]     Train net output #0: loss = 0.00224381 (* 1 = 0.00224381 loss)
I0628 19:10:26.036767  7628 sgd_solver.cpp:137] Iteration 44500, lr = 0.0304688, m = 0.9
I0628 19:10:26.516526  7613 data_reader.cpp:262] Starting prefetch of epoch 57
I0628 19:10:27.751324  7628 solver.cpp:349] Iteration 44600 (58.3335 iter/s, 1.71428s/100 iter), loss = 0.00182194
I0628 19:10:27.751346  7628 solver.cpp:371]     Train net output #0: loss = 0.00182244 (* 1 = 0.00182244 loss)
I0628 19:10:27.751350  7628 sgd_solver.cpp:137] Iteration 44600, lr = 0.0303125, m = 0.9
I0628 19:10:29.467573  7628 solver.cpp:349] Iteration 44700 (58.2768 iter/s, 1.71595s/100 iter), loss = 0.00302607
I0628 19:10:29.467597  7628 solver.cpp:371]     Train net output #0: loss = 0.00302656 (* 1 = 0.00302656 loss)
I0628 19:10:29.467602  7628 sgd_solver.cpp:137] Iteration 44700, lr = 0.0301562, m = 0.9
I0628 19:10:31.182684  7628 solver.cpp:349] Iteration 44800 (58.3156 iter/s, 1.71481s/100 iter), loss = 0.00257459
I0628 19:10:31.182706  7628 solver.cpp:371]     Train net output #0: loss = 0.00257508 (* 1 = 0.00257508 loss)
I0628 19:10:31.182710  7628 sgd_solver.cpp:137] Iteration 44800, lr = 0.03, m = 0.9
I0628 19:10:32.904532  7628 solver.cpp:349] Iteration 44900 (58.0874 iter/s, 1.72154s/100 iter), loss = 0.0129254
I0628 19:10:32.904554  7628 solver.cpp:371]     Train net output #0: loss = 0.0129259 (* 1 = 0.0129259 loss)
I0628 19:10:32.904558  7628 sgd_solver.cpp:137] Iteration 44900, lr = 0.0298437, m = 0.9
I0628 19:10:34.604908  7628 solver.cpp:545] Iteration 45000, Testing net (#0)
I0628 19:10:35.609802  7626 data_reader.cpp:262] Starting prefetch of epoch 45
I0628 19:10:35.633929  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.906
I0628 19:10:35.633944  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9962
I0628 19:10:35.633950  7628 solver.cpp:630]     Test net output #2: loss = 0.363261 (* 1 = 0.363261 loss)
I0628 19:10:35.633977  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02891s
I0628 19:10:35.651216  7628 solver.cpp:349] Iteration 45000 (36.4137 iter/s, 2.74622s/100 iter), loss = 0.00116706
I0628 19:10:35.651237  7628 solver.cpp:371]     Train net output #0: loss = 0.00116756 (* 1 = 0.00116756 loss)
I0628 19:10:35.651243  7628 sgd_solver.cpp:137] Iteration 45000, lr = 0.0296875, m = 0.9
I0628 19:10:37.368077  7628 solver.cpp:349] Iteration 45100 (58.2562 iter/s, 1.71656s/100 iter), loss = 0.00119502
I0628 19:10:37.368101  7628 solver.cpp:371]     Train net output #0: loss = 0.00119552 (* 1 = 0.00119552 loss)
I0628 19:10:37.368106  7628 sgd_solver.cpp:137] Iteration 45100, lr = 0.0295313, m = 0.9
I0628 19:10:39.084430  7628 solver.cpp:349] Iteration 45200 (58.2735 iter/s, 1.71605s/100 iter), loss = 0.00137846
I0628 19:10:39.084452  7628 solver.cpp:371]     Train net output #0: loss = 0.00137896 (* 1 = 0.00137896 loss)
I0628 19:10:39.084456  7628 sgd_solver.cpp:137] Iteration 45200, lr = 0.029375, m = 0.9
I0628 19:10:40.800128  7628 solver.cpp:349] Iteration 45300 (58.2956 iter/s, 1.7154s/100 iter), loss = 0.00118251
I0628 19:10:40.800149  7628 solver.cpp:371]     Train net output #0: loss = 0.00118301 (* 1 = 0.00118301 loss)
I0628 19:10:40.800153  7628 sgd_solver.cpp:137] Iteration 45300, lr = 0.0292188, m = 0.9
I0628 19:10:40.955957  7613 data_reader.cpp:262] Starting prefetch of epoch 58
I0628 19:10:42.517959  7628 solver.cpp:349] Iteration 45400 (58.2232 iter/s, 1.71753s/100 iter), loss = 0.00054028
I0628 19:10:42.517982  7628 solver.cpp:371]     Train net output #0: loss = 0.000540779 (* 1 = 0.000540779 loss)
I0628 19:10:42.517985  7628 sgd_solver.cpp:137] Iteration 45400, lr = 0.0290625, m = 0.9
I0628 19:10:44.237550  7628 solver.cpp:349] Iteration 45500 (58.1638 iter/s, 1.71928s/100 iter), loss = 0.000857456
I0628 19:10:44.237572  7628 solver.cpp:371]     Train net output #0: loss = 0.000857955 (* 1 = 0.000857955 loss)
I0628 19:10:44.237576  7628 sgd_solver.cpp:137] Iteration 45500, lr = 0.0289063, m = 0.9
I0628 19:10:45.954308  7628 solver.cpp:349] Iteration 45600 (58.2597 iter/s, 1.71645s/100 iter), loss = 0.000725433
I0628 19:10:45.954327  7628 solver.cpp:371]     Train net output #0: loss = 0.000725933 (* 1 = 0.000725933 loss)
I0628 19:10:45.954331  7628 sgd_solver.cpp:137] Iteration 45600, lr = 0.02875, m = 0.9
I0628 19:10:47.673192  7628 solver.cpp:349] Iteration 45700 (58.1875 iter/s, 1.71858s/100 iter), loss = 0.00171231
I0628 19:10:47.673260  7628 solver.cpp:371]     Train net output #0: loss = 0.00171281 (* 1 = 0.00171281 loss)
I0628 19:10:47.673267  7628 sgd_solver.cpp:137] Iteration 45700, lr = 0.0285937, m = 0.9
I0628 19:10:49.395074  7628 solver.cpp:349] Iteration 45800 (58.088 iter/s, 1.72153s/100 iter), loss = 0.000452113
I0628 19:10:49.395097  7628 solver.cpp:371]     Train net output #0: loss = 0.000452608 (* 1 = 0.000452608 loss)
I0628 19:10:49.395102  7628 sgd_solver.cpp:137] Iteration 45800, lr = 0.0284375, m = 0.9
I0628 19:10:51.115139  7628 solver.cpp:349] Iteration 45900 (58.1478 iter/s, 1.71976s/100 iter), loss = 0.000580397
I0628 19:10:51.115161  7628 solver.cpp:371]     Train net output #0: loss = 0.000580893 (* 1 = 0.000580893 loss)
I0628 19:10:51.115166  7628 sgd_solver.cpp:137] Iteration 45900, lr = 0.0282812, m = 0.9
I0628 19:10:52.812131  7628 solver.cpp:545] Iteration 46000, Testing net (#0)
I0628 19:10:53.820148  7626 data_reader.cpp:262] Starting prefetch of epoch 46
I0628 19:10:53.844609  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.9074
I0628 19:10:53.844620  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.996
I0628 19:10:53.844625  7628 solver.cpp:630]     Test net output #2: loss = 0.374992 (* 1 = 0.374992 loss)
I0628 19:10:53.844640  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.03235s
I0628 19:10:53.862095  7628 solver.cpp:349] Iteration 46000 (36.41 iter/s, 2.74649s/100 iter), loss = 0.000904135
I0628 19:10:53.862118  7628 solver.cpp:371]     Train net output #0: loss = 0.000904629 (* 1 = 0.000904629 loss)
I0628 19:10:53.862121  7628 sgd_solver.cpp:137] Iteration 46000, lr = 0.028125, m = 0.9
I0628 19:10:55.409126  7613 data_reader.cpp:262] Starting prefetch of epoch 59
I0628 19:10:55.580260  7628 solver.cpp:349] Iteration 46100 (58.212 iter/s, 1.71786s/100 iter), loss = 0.00528782
I0628 19:10:55.580281  7628 solver.cpp:371]     Train net output #0: loss = 0.00528832 (* 1 = 0.00528832 loss)
I0628 19:10:55.580286  7628 sgd_solver.cpp:137] Iteration 46100, lr = 0.0279688, m = 0.9
I0628 19:10:57.294173  7628 solver.cpp:349] Iteration 46200 (58.3563 iter/s, 1.71361s/100 iter), loss = 0.00419687
I0628 19:10:57.294194  7628 solver.cpp:371]     Train net output #0: loss = 0.00419737 (* 1 = 0.00419737 loss)
I0628 19:10:57.294198  7628 sgd_solver.cpp:137] Iteration 46200, lr = 0.0278125, m = 0.9
I0628 19:10:59.014798  7628 solver.cpp:349] Iteration 46300 (58.1286 iter/s, 1.72032s/100 iter), loss = 0.000930343
I0628 19:10:59.014820  7628 solver.cpp:371]     Train net output #0: loss = 0.000930837 (* 1 = 0.000930837 loss)
I0628 19:10:59.014824  7628 sgd_solver.cpp:137] Iteration 46300, lr = 0.0276563, m = 0.9
I0628 19:11:00.733325  7628 solver.cpp:349] Iteration 46400 (58.1996 iter/s, 1.71823s/100 iter), loss = 0.00102227
I0628 19:11:00.733347  7628 solver.cpp:371]     Train net output #0: loss = 0.00102276 (* 1 = 0.00102276 loss)
I0628 19:11:00.733351  7628 sgd_solver.cpp:137] Iteration 46400, lr = 0.0275, m = 0.9
I0628 19:11:02.448709  7628 solver.cpp:349] Iteration 46500 (58.3063 iter/s, 1.71508s/100 iter), loss = 0.00174281
I0628 19:11:02.448731  7628 solver.cpp:371]     Train net output #0: loss = 0.0017433 (* 1 = 0.0017433 loss)
I0628 19:11:02.448735  7628 sgd_solver.cpp:137] Iteration 46500, lr = 0.0273438, m = 0.9
I0628 19:11:04.165575  7628 solver.cpp:349] Iteration 46600 (58.256 iter/s, 1.71656s/100 iter), loss = 0.00100025
I0628 19:11:04.165596  7628 solver.cpp:371]     Train net output #0: loss = 0.00100075 (* 1 = 0.00100075 loss)
I0628 19:11:04.165601  7628 sgd_solver.cpp:137] Iteration 46600, lr = 0.0271875, m = 0.9
I0628 19:11:05.880583  7628 solver.cpp:349] Iteration 46700 (58.3191 iter/s, 1.71471s/100 iter), loss = 0.00040306
I0628 19:11:05.880604  7628 solver.cpp:371]     Train net output #0: loss = 0.000403554 (* 1 = 0.000403554 loss)
I0628 19:11:05.880609  7628 sgd_solver.cpp:137] Iteration 46700, lr = 0.0270312, m = 0.9
I0628 19:11:07.604487  7628 solver.cpp:349] Iteration 46800 (58.018 iter/s, 1.7236s/100 iter), loss = 0.00099551
I0628 19:11:07.604511  7628 solver.cpp:371]     Train net output #0: loss = 0.000996004 (* 1 = 0.000996004 loss)
I0628 19:11:07.604531  7628 sgd_solver.cpp:137] Iteration 46800, lr = 0.026875, m = 0.9
I0628 19:11:08.826562  7613 data_reader.cpp:262] Starting prefetch of epoch 60
I0628 19:11:09.324095  7628 solver.cpp:349] Iteration 46900 (58.1638 iter/s, 1.71928s/100 iter), loss = 0.00249307
I0628 19:11:09.324117  7628 solver.cpp:371]     Train net output #0: loss = 0.00249356 (* 1 = 0.00249356 loss)
I0628 19:11:09.324122  7628 sgd_solver.cpp:137] Iteration 46900, lr = 0.0267187, m = 0.9
I0628 19:11:11.024080  7628 solver.cpp:545] Iteration 47000, Testing net (#0)
I0628 19:11:12.029095  7626 data_reader.cpp:262] Starting prefetch of epoch 47
I0628 19:11:12.052038  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.9168
I0628 19:11:12.052052  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9962
I0628 19:11:12.052059  7628 solver.cpp:630]     Test net output #2: loss = 0.33035 (* 1 = 0.33035 loss)
I0628 19:11:12.052076  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02784s
I0628 19:11:12.069401  7628 solver.cpp:349] Iteration 47000 (36.432 iter/s, 2.74484s/100 iter), loss = 0.00146492
I0628 19:11:12.069423  7628 solver.cpp:371]     Train net output #0: loss = 0.00146541 (* 1 = 0.00146541 loss)
I0628 19:11:12.069427  7628 sgd_solver.cpp:137] Iteration 47000, lr = 0.0265625, m = 0.9
I0628 19:11:13.782934  7628 solver.cpp:349] Iteration 47100 (58.3692 iter/s, 1.71323s/100 iter), loss = 0.00141971
I0628 19:11:13.782958  7628 solver.cpp:371]     Train net output #0: loss = 0.00142021 (* 1 = 0.00142021 loss)
I0628 19:11:13.782961  7628 sgd_solver.cpp:137] Iteration 47100, lr = 0.0264063, m = 0.9
I0628 19:11:15.500231  7628 solver.cpp:349] Iteration 47200 (58.2414 iter/s, 1.71699s/100 iter), loss = 0.000828162
I0628 19:11:15.500253  7628 solver.cpp:371]     Train net output #0: loss = 0.000828657 (* 1 = 0.000828657 loss)
I0628 19:11:15.500257  7628 sgd_solver.cpp:137] Iteration 47200, lr = 0.02625, m = 0.9
I0628 19:11:17.214612  7628 solver.cpp:349] Iteration 47300 (58.3404 iter/s, 1.71408s/100 iter), loss = 0.000408608
I0628 19:11:17.214634  7628 solver.cpp:371]     Train net output #0: loss = 0.000409102 (* 1 = 0.000409102 loss)
I0628 19:11:17.214639  7628 sgd_solver.cpp:137] Iteration 47300, lr = 0.0260938, m = 0.9
I0628 19:11:18.930631  7628 solver.cpp:349] Iteration 47400 (58.2847 iter/s, 1.71571s/100 iter), loss = 0.0012414
I0628 19:11:18.930706  7628 solver.cpp:371]     Train net output #0: loss = 0.0012419 (* 1 = 0.0012419 loss)
I0628 19:11:18.930713  7628 sgd_solver.cpp:137] Iteration 47400, lr = 0.0259375, m = 0.9
I0628 19:11:20.645803  7628 solver.cpp:349] Iteration 47500 (58.3154 iter/s, 1.71481s/100 iter), loss = 0.000378691
I0628 19:11:20.645825  7628 solver.cpp:371]     Train net output #0: loss = 0.000379185 (* 1 = 0.000379185 loss)
I0628 19:11:20.645829  7628 sgd_solver.cpp:137] Iteration 47500, lr = 0.0257812, m = 0.9
I0628 19:11:22.366601  7628 solver.cpp:349] Iteration 47600 (58.1228 iter/s, 1.72049s/100 iter), loss = 0.000732727
I0628 19:11:22.366623  7628 solver.cpp:371]     Train net output #0: loss = 0.000733222 (* 1 = 0.000733222 loss)
I0628 19:11:22.366627  7628 sgd_solver.cpp:137] Iteration 47600, lr = 0.025625, m = 0.9
I0628 19:11:23.278105  7613 data_reader.cpp:262] Starting prefetch of epoch 61
I0628 19:11:24.083503  7628 solver.cpp:349] Iteration 47700 (58.2547 iter/s, 1.7166s/100 iter), loss = 0.000534719
I0628 19:11:24.083524  7628 solver.cpp:371]     Train net output #0: loss = 0.000535214 (* 1 = 0.000535214 loss)
I0628 19:11:24.083530  7628 sgd_solver.cpp:137] Iteration 47700, lr = 0.0254687, m = 0.9
I0628 19:11:25.797927  7628 solver.cpp:349] Iteration 47800 (58.339 iter/s, 1.71412s/100 iter), loss = 0.000481959
I0628 19:11:25.797951  7628 solver.cpp:371]     Train net output #0: loss = 0.000482454 (* 1 = 0.000482454 loss)
I0628 19:11:25.797956  7628 sgd_solver.cpp:137] Iteration 47800, lr = 0.0253125, m = 0.9
I0628 19:11:27.512107  7628 solver.cpp:349] Iteration 47900 (58.3474 iter/s, 1.71387s/100 iter), loss = 0.000864414
I0628 19:11:27.512128  7628 solver.cpp:371]     Train net output #0: loss = 0.000864909 (* 1 = 0.000864909 loss)
I0628 19:11:27.512133  7628 sgd_solver.cpp:137] Iteration 47900, lr = 0.0251562, m = 0.9
I0628 19:11:29.207978  7628 solver.cpp:545] Iteration 48000, Testing net (#0)
I0628 19:11:30.215631  7626 data_reader.cpp:262] Starting prefetch of epoch 48
I0628 19:11:30.239089  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.916
I0628 19:11:30.239101  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9964
I0628 19:11:30.239106  7628 solver.cpp:630]     Test net output #2: loss = 0.321366 (* 1 = 0.321366 loss)
I0628 19:11:30.239120  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.03098s
I0628 19:11:30.256501  7628 solver.cpp:349] Iteration 48000 (36.4441 iter/s, 2.74393s/100 iter), loss = 0.00435377
I0628 19:11:30.256523  7628 solver.cpp:371]     Train net output #0: loss = 0.00435426 (* 1 = 0.00435426 loss)
I0628 19:11:30.256527  7628 sgd_solver.cpp:137] Iteration 48000, lr = 0.025, m = 0.9
I0628 19:11:31.973134  7628 solver.cpp:349] Iteration 48100 (58.2638 iter/s, 1.71633s/100 iter), loss = 0.000986121
I0628 19:11:31.973157  7628 solver.cpp:371]     Train net output #0: loss = 0.000986616 (* 1 = 0.000986616 loss)
I0628 19:11:31.973161  7628 sgd_solver.cpp:137] Iteration 48100, lr = 0.0248438, m = 0.9
I0628 19:11:33.689941  7628 solver.cpp:349] Iteration 48200 (58.258 iter/s, 1.7165s/100 iter), loss = 0.000934479
I0628 19:11:33.689963  7628 solver.cpp:371]     Train net output #0: loss = 0.000934975 (* 1 = 0.000934975 loss)
I0628 19:11:33.689967  7628 sgd_solver.cpp:137] Iteration 48200, lr = 0.0246875, m = 0.9
I0628 19:11:35.406158  7628 solver.cpp:349] Iteration 48300 (58.2779 iter/s, 1.71592s/100 iter), loss = 0.000775601
I0628 19:11:35.406182  7628 solver.cpp:371]     Train net output #0: loss = 0.000776096 (* 1 = 0.000776096 loss)
I0628 19:11:35.406185  7628 sgd_solver.cpp:137] Iteration 48300, lr = 0.0245313, m = 0.9
I0628 19:11:37.124022  7628 solver.cpp:349] Iteration 48400 (58.2221 iter/s, 1.71756s/100 iter), loss = 0.000967483
I0628 19:11:37.124043  7628 solver.cpp:371]     Train net output #0: loss = 0.000967979 (* 1 = 0.000967979 loss)
I0628 19:11:37.124047  7628 sgd_solver.cpp:137] Iteration 48400, lr = 0.024375, m = 0.9
I0628 19:11:37.709177  7613 data_reader.cpp:262] Starting prefetch of epoch 62
I0628 19:11:38.838964  7628 solver.cpp:349] Iteration 48500 (58.3212 iter/s, 1.71464s/100 iter), loss = 0.00231042
I0628 19:11:38.839002  7628 solver.cpp:371]     Train net output #0: loss = 0.00231092 (* 1 = 0.00231092 loss)
I0628 19:11:38.839006  7628 sgd_solver.cpp:137] Iteration 48500, lr = 0.0242188, m = 0.9
I0628 19:11:40.558801  7628 solver.cpp:349] Iteration 48600 (58.1559 iter/s, 1.71952s/100 iter), loss = 0.000637642
I0628 19:11:40.558825  7628 solver.cpp:371]     Train net output #0: loss = 0.000638137 (* 1 = 0.000638137 loss)
I0628 19:11:40.558828  7628 sgd_solver.cpp:137] Iteration 48600, lr = 0.0240625, m = 0.9
I0628 19:11:42.275573  7628 solver.cpp:349] Iteration 48700 (58.2592 iter/s, 1.71647s/100 iter), loss = 0.00146904
I0628 19:11:42.275595  7628 solver.cpp:371]     Train net output #0: loss = 0.00146953 (* 1 = 0.00146953 loss)
I0628 19:11:42.275599  7628 sgd_solver.cpp:137] Iteration 48700, lr = 0.0239062, m = 0.9
I0628 19:11:43.991360  7628 solver.cpp:349] Iteration 48800 (58.2926 iter/s, 1.71548s/100 iter), loss = 0.000547666
I0628 19:11:43.991381  7628 solver.cpp:371]     Train net output #0: loss = 0.000548162 (* 1 = 0.000548162 loss)
I0628 19:11:43.991385  7628 sgd_solver.cpp:137] Iteration 48800, lr = 0.02375, m = 0.9
I0628 19:11:45.707096  7628 solver.cpp:349] Iteration 48900 (58.2943 iter/s, 1.71543s/100 iter), loss = 0.000985773
I0628 19:11:45.707120  7628 solver.cpp:371]     Train net output #0: loss = 0.000986268 (* 1 = 0.000986268 loss)
I0628 19:11:45.707125  7628 sgd_solver.cpp:137] Iteration 48900, lr = 0.0235937, m = 0.9
I0628 19:11:47.406577  7628 solver.cpp:545] Iteration 49000, Testing net (#0)
I0628 19:11:48.415715  7626 data_reader.cpp:262] Starting prefetch of epoch 49
I0628 19:11:48.436552  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.9156
I0628 19:11:48.436564  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9968
I0628 19:11:48.436569  7628 solver.cpp:630]     Test net output #2: loss = 0.314365 (* 1 = 0.314365 loss)
I0628 19:11:48.436583  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02985s
I0628 19:11:48.453876  7628 solver.cpp:349] Iteration 49000 (36.4125 iter/s, 2.74631s/100 iter), loss = 0.000900694
I0628 19:11:48.453899  7628 solver.cpp:371]     Train net output #0: loss = 0.000901189 (* 1 = 0.000901189 loss)
I0628 19:11:48.453903  7628 sgd_solver.cpp:137] Iteration 49000, lr = 0.0234375, m = 0.9
I0628 19:11:50.171735  7628 solver.cpp:349] Iteration 49100 (58.2224 iter/s, 1.71755s/100 iter), loss = 0.000571003
I0628 19:11:50.171833  7628 solver.cpp:371]     Train net output #0: loss = 0.000571498 (* 1 = 0.000571498 loss)
I0628 19:11:50.171838  7628 sgd_solver.cpp:137] Iteration 49100, lr = 0.0232813, m = 0.9
I0628 19:11:51.886750  7628 solver.cpp:349] Iteration 49200 (58.3214 iter/s, 1.71464s/100 iter), loss = 0.000793613
I0628 19:11:51.886773  7628 solver.cpp:371]     Train net output #0: loss = 0.000794108 (* 1 = 0.000794108 loss)
I0628 19:11:51.886777  7628 sgd_solver.cpp:137] Iteration 49200, lr = 0.023125, m = 0.9
I0628 19:11:52.146584  7613 data_reader.cpp:262] Starting prefetch of epoch 63
I0628 19:11:53.609701  7628 solver.cpp:349] Iteration 49300 (58.0502 iter/s, 1.72265s/100 iter), loss = 0.000874412
I0628 19:11:53.609724  7628 solver.cpp:371]     Train net output #0: loss = 0.000874907 (* 1 = 0.000874907 loss)
I0628 19:11:53.609728  7628 sgd_solver.cpp:137] Iteration 49300, lr = 0.0229688, m = 0.9
I0628 19:11:55.327529  7628 solver.cpp:349] Iteration 49400 (58.2233 iter/s, 1.71753s/100 iter), loss = 0.00109905
I0628 19:11:55.327551  7628 solver.cpp:371]     Train net output #0: loss = 0.00109954 (* 1 = 0.00109954 loss)
I0628 19:11:55.327555  7628 sgd_solver.cpp:137] Iteration 49400, lr = 0.0228125, m = 0.9
I0628 19:11:57.047526  7628 solver.cpp:349] Iteration 49500 (58.1499 iter/s, 1.71969s/100 iter), loss = 0.00146004
I0628 19:11:57.047551  7628 solver.cpp:371]     Train net output #0: loss = 0.00146053 (* 1 = 0.00146053 loss)
I0628 19:11:57.047555  7628 sgd_solver.cpp:137] Iteration 49500, lr = 0.0226563, m = 0.9
I0628 19:11:58.762517  7628 solver.cpp:349] Iteration 49600 (58.3197 iter/s, 1.71469s/100 iter), loss = 0.00134828
I0628 19:11:58.762540  7628 solver.cpp:371]     Train net output #0: loss = 0.00134877 (* 1 = 0.00134877 loss)
I0628 19:11:58.762544  7628 sgd_solver.cpp:137] Iteration 49600, lr = 0.0225, m = 0.9
I0628 19:12:00.480763  7628 solver.cpp:349] Iteration 49700 (58.2092 iter/s, 1.71794s/100 iter), loss = 0.000630087
I0628 19:12:00.480785  7628 solver.cpp:371]     Train net output #0: loss = 0.000630582 (* 1 = 0.000630582 loss)
I0628 19:12:00.480789  7628 sgd_solver.cpp:137] Iteration 49700, lr = 0.0223437, m = 0.9
I0628 19:12:02.197926  7628 solver.cpp:349] Iteration 49800 (58.2459 iter/s, 1.71686s/100 iter), loss = 0.00144857
I0628 19:12:02.197947  7628 solver.cpp:371]     Train net output #0: loss = 0.00144907 (* 1 = 0.00144907 loss)
I0628 19:12:02.197950  7628 sgd_solver.cpp:137] Iteration 49800, lr = 0.0221875, m = 0.9
I0628 19:12:03.914445  7628 solver.cpp:349] Iteration 49900 (58.2677 iter/s, 1.71622s/100 iter), loss = 0.00029653
I0628 19:12:03.914468  7628 solver.cpp:371]     Train net output #0: loss = 0.000297025 (* 1 = 0.000297025 loss)
I0628 19:12:03.914471  7628 sgd_solver.cpp:137] Iteration 49900, lr = 0.0220312, m = 0.9
I0628 19:12:05.563856  7613 data_reader.cpp:262] Starting prefetch of epoch 64
I0628 19:12:05.615854  7628 solver.cpp:675] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-06-28_18-56-45/initial/cifar10_jacintonet11v2_iter_50000.caffemodel
I0628 19:12:05.624622  7628 sgd_solver.cpp:288] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-06-28_18-56-45/initial/cifar10_jacintonet11v2_iter_50000.solverstate
I0628 19:12:05.628192  7628 solver.cpp:545] Iteration 50000, Testing net (#0)
I0628 19:12:06.636804  7626 data_reader.cpp:262] Starting prefetch of epoch 50
I0628 19:12:06.657254  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.9176
I0628 19:12:06.657274  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9966
I0628 19:12:06.657279  7628 solver.cpp:630]     Test net output #2: loss = 0.31463 (* 1 = 0.31463 loss)
I0628 19:12:06.657294  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02894s
I0628 19:12:06.674578  7628 solver.cpp:349] Iteration 50000 (36.2362 iter/s, 2.75967s/100 iter), loss = 0.00104589
I0628 19:12:06.674600  7628 solver.cpp:371]     Train net output #0: loss = 0.00104638 (* 1 = 0.00104638 loss)
I0628 19:12:06.674604  7628 sgd_solver.cpp:137] Iteration 50000, lr = 0.021875, m = 0.9
I0628 19:12:08.390637  7628 solver.cpp:349] Iteration 50100 (58.2839 iter/s, 1.71574s/100 iter), loss = 0.00130691
I0628 19:12:08.390661  7628 solver.cpp:371]     Train net output #0: loss = 0.00130741 (* 1 = 0.00130741 loss)
I0628 19:12:08.390664  7628 sgd_solver.cpp:137] Iteration 50100, lr = 0.0217188, m = 0.9
I0628 19:12:10.110435  7628 solver.cpp:349] Iteration 50200 (58.1566 iter/s, 1.71949s/100 iter), loss = 0.00180283
I0628 19:12:10.110456  7628 solver.cpp:371]     Train net output #0: loss = 0.00180332 (* 1 = 0.00180332 loss)
I0628 19:12:10.110461  7628 sgd_solver.cpp:137] Iteration 50200, lr = 0.0215625, m = 0.9
I0628 19:12:11.821542  7628 solver.cpp:349] Iteration 50300 (58.452 iter/s, 1.7108s/100 iter), loss = 0.000863771
I0628 19:12:11.821568  7628 solver.cpp:371]     Train net output #0: loss = 0.000864266 (* 1 = 0.000864266 loss)
I0628 19:12:11.821573  7628 sgd_solver.cpp:137] Iteration 50300, lr = 0.0214063, m = 0.9
I0628 19:12:13.540753  7628 solver.cpp:349] Iteration 50400 (58.1766 iter/s, 1.7189s/100 iter), loss = 0.00155872
I0628 19:12:13.540776  7628 solver.cpp:371]     Train net output #0: loss = 0.00155922 (* 1 = 0.00155922 loss)
I0628 19:12:13.540779  7628 sgd_solver.cpp:137] Iteration 50400, lr = 0.02125, m = 0.9
I0628 19:12:15.256536  7628 solver.cpp:349] Iteration 50500 (58.2927 iter/s, 1.71548s/100 iter), loss = 0.000717441
I0628 19:12:15.256558  7628 solver.cpp:371]     Train net output #0: loss = 0.000717936 (* 1 = 0.000717936 loss)
I0628 19:12:15.256562  7628 sgd_solver.cpp:137] Iteration 50500, lr = 0.0210938, m = 0.9
I0628 19:12:16.979229  7628 solver.cpp:349] Iteration 50600 (58.0588 iter/s, 1.72239s/100 iter), loss = 0.000640474
I0628 19:12:16.979254  7628 solver.cpp:371]     Train net output #0: loss = 0.000640969 (* 1 = 0.000640969 loss)
I0628 19:12:16.979257  7628 sgd_solver.cpp:137] Iteration 50600, lr = 0.0209375, m = 0.9
I0628 19:12:18.695534  7628 solver.cpp:349] Iteration 50700 (58.275 iter/s, 1.716s/100 iter), loss = 0.00142492
I0628 19:12:18.695559  7628 solver.cpp:371]     Train net output #0: loss = 0.00142542 (* 1 = 0.00142542 loss)
I0628 19:12:18.695562  7628 sgd_solver.cpp:137] Iteration 50700, lr = 0.0207812, m = 0.9
I0628 19:12:20.035614  7613 data_reader.cpp:262] Starting prefetch of epoch 65
I0628 19:12:20.415071  7628 solver.cpp:349] Iteration 50800 (58.1656 iter/s, 1.71923s/100 iter), loss = 0.000468509
I0628 19:12:20.415139  7628 solver.cpp:371]     Train net output #0: loss = 0.000469004 (* 1 = 0.000469004 loss)
I0628 19:12:20.415145  7628 sgd_solver.cpp:137] Iteration 50800, lr = 0.020625, m = 0.9
I0628 19:12:22.136160  7628 solver.cpp:349] Iteration 50900 (58.1146 iter/s, 1.72074s/100 iter), loss = 0.000852344
I0628 19:12:22.136183  7628 solver.cpp:371]     Train net output #0: loss = 0.00085284 (* 1 = 0.00085284 loss)
I0628 19:12:22.136186  7628 sgd_solver.cpp:137] Iteration 50900, lr = 0.0204687, m = 0.9
I0628 19:12:23.835794  7628 solver.cpp:545] Iteration 51000, Testing net (#0)
I0628 19:12:24.842306  7626 data_reader.cpp:262] Starting prefetch of epoch 51
I0628 19:12:24.863960  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.917
I0628 19:12:24.863978  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9968
I0628 19:12:24.863983  7628 solver.cpp:630]     Test net output #2: loss = 0.312147 (* 1 = 0.312147 loss)
I0628 19:12:24.863998  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02805s
I0628 19:12:24.881219  7628 solver.cpp:349] Iteration 51000 (36.4352 iter/s, 2.7446s/100 iter), loss = 0.00205634
I0628 19:12:24.881242  7628 solver.cpp:371]     Train net output #0: loss = 0.00205683 (* 1 = 0.00205683 loss)
I0628 19:12:24.881247  7628 sgd_solver.cpp:137] Iteration 51000, lr = 0.0203125, m = 0.9
I0628 19:12:26.596889  7628 solver.cpp:349] Iteration 51100 (58.2966 iter/s, 1.71537s/100 iter), loss = 0.00198327
I0628 19:12:26.596912  7628 solver.cpp:371]     Train net output #0: loss = 0.00198376 (* 1 = 0.00198376 loss)
I0628 19:12:26.596916  7628 sgd_solver.cpp:137] Iteration 51100, lr = 0.0201563, m = 0.9
I0628 19:12:28.313642  7628 solver.cpp:349] Iteration 51200 (58.2598 iter/s, 1.71645s/100 iter), loss = 0.00128275
I0628 19:12:28.313663  7628 solver.cpp:371]     Train net output #0: loss = 0.00128324 (* 1 = 0.00128324 loss)
I0628 19:12:28.313668  7628 sgd_solver.cpp:137] Iteration 51200, lr = 0.02, m = 0.9
I0628 19:12:30.031705  7628 solver.cpp:349] Iteration 51300 (58.2154 iter/s, 1.71776s/100 iter), loss = 0.00125445
I0628 19:12:30.031726  7628 solver.cpp:371]     Train net output #0: loss = 0.00125495 (* 1 = 0.00125495 loss)
I0628 19:12:30.031730  7628 sgd_solver.cpp:137] Iteration 51300, lr = 0.0198438, m = 0.9
I0628 19:12:31.749881  7628 solver.cpp:349] Iteration 51400 (58.2115 iter/s, 1.71787s/100 iter), loss = 0.000987464
I0628 19:12:31.749904  7628 solver.cpp:371]     Train net output #0: loss = 0.00098796 (* 1 = 0.00098796 loss)
I0628 19:12:31.749908  7628 sgd_solver.cpp:137] Iteration 51400, lr = 0.0196875, m = 0.9
I0628 19:12:33.465088  7628 solver.cpp:349] Iteration 51500 (58.3123 iter/s, 1.7149s/100 iter), loss = 0.000573213
I0628 19:12:33.465111  7628 solver.cpp:371]     Train net output #0: loss = 0.000573709 (* 1 = 0.000573709 loss)
I0628 19:12:33.465116  7628 sgd_solver.cpp:137] Iteration 51500, lr = 0.0195312, m = 0.9
I0628 19:12:34.479270  7613 data_reader.cpp:262] Starting prefetch of epoch 66
I0628 19:12:35.182248  7628 solver.cpp:349] Iteration 51600 (58.246 iter/s, 1.71686s/100 iter), loss = 0.0012108
I0628 19:12:35.182271  7628 solver.cpp:371]     Train net output #0: loss = 0.0012113 (* 1 = 0.0012113 loss)
I0628 19:12:35.182274  7628 sgd_solver.cpp:137] Iteration 51600, lr = 0.019375, m = 0.9
I0628 19:12:36.895792  7628 solver.cpp:349] Iteration 51700 (58.3689 iter/s, 1.71324s/100 iter), loss = 0.000878255
I0628 19:12:36.895814  7628 solver.cpp:371]     Train net output #0: loss = 0.000878751 (* 1 = 0.000878751 loss)
I0628 19:12:36.895818  7628 sgd_solver.cpp:137] Iteration 51700, lr = 0.0192187, m = 0.9
I0628 19:12:38.615947  7628 solver.cpp:349] Iteration 51800 (58.1445 iter/s, 1.71985s/100 iter), loss = 0.00111304
I0628 19:12:38.615970  7628 solver.cpp:371]     Train net output #0: loss = 0.00111354 (* 1 = 0.00111354 loss)
I0628 19:12:38.615974  7628 sgd_solver.cpp:137] Iteration 51800, lr = 0.0190625, m = 0.9
I0628 19:12:40.337216  7628 solver.cpp:349] Iteration 51900 (58.1069 iter/s, 1.72096s/100 iter), loss = 0.000501029
I0628 19:12:40.337239  7628 solver.cpp:371]     Train net output #0: loss = 0.000501525 (* 1 = 0.000501525 loss)
I0628 19:12:40.337260  7628 sgd_solver.cpp:137] Iteration 51900, lr = 0.0189062, m = 0.9
I0628 19:12:42.033964  7628 solver.cpp:545] Iteration 52000, Testing net (#0)
I0628 19:12:43.039011  7626 data_reader.cpp:262] Starting prefetch of epoch 52
I0628 19:12:43.062808  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.9178
I0628 19:12:43.062827  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9964
I0628 19:12:43.062834  7628 solver.cpp:630]     Test net output #2: loss = 0.308237 (* 1 = 0.308237 loss)
I0628 19:12:43.062855  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02873s
I0628 19:12:43.082193  7628 solver.cpp:349] Iteration 52000 (36.4366 iter/s, 2.74449s/100 iter), loss = 0.00161176
I0628 19:12:43.082212  7628 solver.cpp:371]     Train net output #0: loss = 0.00161226 (* 1 = 0.00161226 loss)
I0628 19:12:43.082216  7628 sgd_solver.cpp:137] Iteration 52000, lr = 0.01875, m = 0.9
I0628 19:12:44.803483  7628 solver.cpp:349] Iteration 52100 (58.1061 iter/s, 1.72099s/100 iter), loss = 0.000605589
I0628 19:12:44.803506  7628 solver.cpp:371]     Train net output #0: loss = 0.000606085 (* 1 = 0.000606085 loss)
I0628 19:12:44.803510  7628 sgd_solver.cpp:137] Iteration 52100, lr = 0.0185938, m = 0.9
I0628 19:12:46.520481  7628 solver.cpp:349] Iteration 52200 (58.2515 iter/s, 1.71669s/100 iter), loss = 0.000699406
I0628 19:12:46.520503  7628 solver.cpp:371]     Train net output #0: loss = 0.000699902 (* 1 = 0.000699902 loss)
I0628 19:12:46.520508  7628 sgd_solver.cpp:137] Iteration 52200, lr = 0.0184375, m = 0.9
I0628 19:12:48.240588  7628 solver.cpp:349] Iteration 52300 (58.1462 iter/s, 1.7198s/100 iter), loss = 0.00253099
I0628 19:12:48.240612  7628 solver.cpp:371]     Train net output #0: loss = 0.00253149 (* 1 = 0.00253149 loss)
I0628 19:12:48.240617  7628 sgd_solver.cpp:137] Iteration 52300, lr = 0.0182813, m = 0.9
I0628 19:12:48.926971  7613 data_reader.cpp:262] Starting prefetch of epoch 67
I0628 19:12:49.954496  7628 solver.cpp:349] Iteration 52400 (58.3567 iter/s, 1.7136s/100 iter), loss = 0.000589798
I0628 19:12:49.954520  7628 solver.cpp:371]     Train net output #0: loss = 0.000590295 (* 1 = 0.000590295 loss)
I0628 19:12:49.954525  7628 sgd_solver.cpp:137] Iteration 52400, lr = 0.018125, m = 0.9
I0628 19:12:51.674468  7628 solver.cpp:349] Iteration 52500 (58.1509 iter/s, 1.71966s/100 iter), loss = 0.00186909
I0628 19:12:51.674530  7628 solver.cpp:371]     Train net output #0: loss = 0.00186959 (* 1 = 0.00186959 loss)
I0628 19:12:51.674536  7628 sgd_solver.cpp:137] Iteration 52500, lr = 0.0179687, m = 0.9
I0628 19:12:53.389947  7628 solver.cpp:349] Iteration 52600 (58.3046 iter/s, 1.71513s/100 iter), loss = 0.00192031
I0628 19:12:53.389969  7628 solver.cpp:371]     Train net output #0: loss = 0.0019208 (* 1 = 0.0019208 loss)
I0628 19:12:53.389973  7628 sgd_solver.cpp:137] Iteration 52600, lr = 0.0178125, m = 0.9
I0628 19:12:55.107594  7628 solver.cpp:349] Iteration 52700 (58.2295 iter/s, 1.71734s/100 iter), loss = 0.000886136
I0628 19:12:55.107614  7628 solver.cpp:371]     Train net output #0: loss = 0.000886632 (* 1 = 0.000886632 loss)
I0628 19:12:55.107619  7628 sgd_solver.cpp:137] Iteration 52700, lr = 0.0176562, m = 0.9
I0628 19:12:56.826196  7628 solver.cpp:349] Iteration 52800 (58.1971 iter/s, 1.7183s/100 iter), loss = 0.000856207
I0628 19:12:56.826218  7628 solver.cpp:371]     Train net output #0: loss = 0.000856703 (* 1 = 0.000856703 loss)
I0628 19:12:56.826222  7628 sgd_solver.cpp:137] Iteration 52800, lr = 0.0175, m = 0.9
I0628 19:12:58.547482  7628 solver.cpp:349] Iteration 52900 (58.1064 iter/s, 1.72098s/100 iter), loss = 0.000759574
I0628 19:12:58.547502  7628 solver.cpp:371]     Train net output #0: loss = 0.00076007 (* 1 = 0.00076007 loss)
I0628 19:12:58.547507  7628 sgd_solver.cpp:137] Iteration 52900, lr = 0.0173437, m = 0.9
I0628 19:13:00.246402  7628 solver.cpp:545] Iteration 53000, Testing net (#0)
I0628 19:13:01.252332  7626 data_reader.cpp:262] Starting prefetch of epoch 53
I0628 19:13:01.276298  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.9176
I0628 19:13:01.276310  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9964
I0628 19:13:01.276315  7628 solver.cpp:630]     Test net output #2: loss = 0.305927 (* 1 = 0.305927 loss)
I0628 19:13:01.276329  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02977s
I0628 19:13:01.293685  7628 solver.cpp:349] Iteration 53000 (36.42 iter/s, 2.74574s/100 iter), loss = 0.000957383
I0628 19:13:01.293709  7628 solver.cpp:371]     Train net output #0: loss = 0.00095788 (* 1 = 0.00095788 loss)
I0628 19:13:01.293714  7628 sgd_solver.cpp:137] Iteration 53000, lr = 0.0171875, m = 0.9
I0628 19:13:03.007062  7628 solver.cpp:349] Iteration 53100 (58.3746 iter/s, 1.71307s/100 iter), loss = 0.00104925
I0628 19:13:03.007086  7628 solver.cpp:371]     Train net output #0: loss = 0.00104974 (* 1 = 0.00104974 loss)
I0628 19:13:03.007089  7628 sgd_solver.cpp:137] Iteration 53100, lr = 0.0170313, m = 0.9
I0628 19:13:03.370810  7613 data_reader.cpp:262] Starting prefetch of epoch 68
I0628 19:13:04.723975  7628 solver.cpp:349] Iteration 53200 (58.2543 iter/s, 1.71661s/100 iter), loss = 0.00124105
I0628 19:13:04.723997  7628 solver.cpp:371]     Train net output #0: loss = 0.00124155 (* 1 = 0.00124155 loss)
I0628 19:13:04.724001  7628 sgd_solver.cpp:137] Iteration 53200, lr = 0.016875, m = 0.9
I0628 19:13:06.438504  7628 solver.cpp:349] Iteration 53300 (58.3354 iter/s, 1.71423s/100 iter), loss = 0.00101389
I0628 19:13:06.438525  7628 solver.cpp:371]     Train net output #0: loss = 0.00101439 (* 1 = 0.00101439 loss)
I0628 19:13:06.438529  7628 sgd_solver.cpp:137] Iteration 53300, lr = 0.0167188, m = 0.9
I0628 19:13:08.154439  7628 solver.cpp:349] Iteration 53400 (58.2875 iter/s, 1.71563s/100 iter), loss = 0.000756935
I0628 19:13:08.154460  7628 solver.cpp:371]     Train net output #0: loss = 0.000757431 (* 1 = 0.000757431 loss)
I0628 19:13:08.154464  7628 sgd_solver.cpp:137] Iteration 53400, lr = 0.0165625, m = 0.9
I0628 19:13:09.868989  7628 solver.cpp:349] Iteration 53500 (58.3346 iter/s, 1.71425s/100 iter), loss = 0.000881029
I0628 19:13:09.869012  7628 solver.cpp:371]     Train net output #0: loss = 0.000881526 (* 1 = 0.000881526 loss)
I0628 19:13:09.869015  7628 sgd_solver.cpp:137] Iteration 53500, lr = 0.0164063, m = 0.9
I0628 19:13:11.582813  7628 solver.cpp:349] Iteration 53600 (58.3595 iter/s, 1.71352s/100 iter), loss = 0.00213722
I0628 19:13:11.582835  7628 solver.cpp:371]     Train net output #0: loss = 0.00213771 (* 1 = 0.00213771 loss)
I0628 19:13:11.582865  7628 sgd_solver.cpp:137] Iteration 53600, lr = 0.01625, m = 0.9
I0628 19:13:13.299230  7628 solver.cpp:349] Iteration 53700 (58.2722 iter/s, 1.71608s/100 iter), loss = 0.00088306
I0628 19:13:13.299254  7628 solver.cpp:371]     Train net output #0: loss = 0.000883556 (* 1 = 0.000883556 loss)
I0628 19:13:13.299259  7628 sgd_solver.cpp:137] Iteration 53700, lr = 0.0160937, m = 0.9
I0628 19:13:15.014704  7628 solver.cpp:349] Iteration 53800 (58.3034 iter/s, 1.71517s/100 iter), loss = 0.00128973
I0628 19:13:15.014727  7628 solver.cpp:371]     Train net output #0: loss = 0.00129022 (* 1 = 0.00129022 loss)
I0628 19:13:15.014731  7628 sgd_solver.cpp:137] Iteration 53800, lr = 0.0159375, m = 0.9
I0628 19:13:16.732082  7628 solver.cpp:349] Iteration 53900 (58.2385 iter/s, 1.71708s/100 iter), loss = 0.00193199
I0628 19:13:16.732106  7628 solver.cpp:371]     Train net output #0: loss = 0.00193248 (* 1 = 0.00193248 loss)
I0628 19:13:16.732110  7628 sgd_solver.cpp:137] Iteration 53900, lr = 0.0157812, m = 0.9
I0628 19:13:16.784112  7613 data_reader.cpp:262] Starting prefetch of epoch 69
I0628 19:13:18.432446  7628 solver.cpp:545] Iteration 54000, Testing net (#0)
I0628 19:13:19.437641  7626 data_reader.cpp:262] Starting prefetch of epoch 54
I0628 19:13:19.459843  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.9178
I0628 19:13:19.459857  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9962
I0628 19:13:19.459864  7628 solver.cpp:630]     Test net output #2: loss = 0.305362 (* 1 = 0.305362 loss)
I0628 19:13:19.459882  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02728s
I0628 19:13:19.477337  7628 solver.cpp:349] Iteration 54000 (36.4326 iter/s, 2.74479s/100 iter), loss = 0.0012479
I0628 19:13:19.477363  7628 solver.cpp:371]     Train net output #0: loss = 0.0012484 (* 1 = 0.0012484 loss)
I0628 19:13:19.477368  7628 sgd_solver.cpp:137] Iteration 54000, lr = 0.015625, m = 0.9
I0628 19:13:21.200141  7628 solver.cpp:349] Iteration 54100 (58.0554 iter/s, 1.72249s/100 iter), loss = 0.00111788
I0628 19:13:21.200163  7628 solver.cpp:371]     Train net output #0: loss = 0.00111838 (* 1 = 0.00111838 loss)
I0628 19:13:21.200167  7628 sgd_solver.cpp:137] Iteration 54100, lr = 0.0154688, m = 0.9
I0628 19:13:22.916797  7628 solver.cpp:349] Iteration 54200 (58.263 iter/s, 1.71635s/100 iter), loss = 0.000801612
I0628 19:13:22.916874  7628 solver.cpp:371]     Train net output #0: loss = 0.000802108 (* 1 = 0.000802108 loss)
I0628 19:13:22.916882  7628 sgd_solver.cpp:137] Iteration 54200, lr = 0.0153125, m = 0.9
I0628 19:13:24.631489  7628 solver.cpp:349] Iteration 54300 (58.3318 iter/s, 1.71433s/100 iter), loss = 0.00134284
I0628 19:13:24.631511  7628 solver.cpp:371]     Train net output #0: loss = 0.00134334 (* 1 = 0.00134334 loss)
I0628 19:13:24.631516  7628 sgd_solver.cpp:137] Iteration 54300, lr = 0.0151563, m = 0.9
I0628 19:13:26.345990  7628 solver.cpp:349] Iteration 54400 (58.3363 iter/s, 1.7142s/100 iter), loss = 0.00063919
I0628 19:13:26.346014  7628 solver.cpp:371]     Train net output #0: loss = 0.000639687 (* 1 = 0.000639687 loss)
I0628 19:13:26.346017  7628 sgd_solver.cpp:137] Iteration 54400, lr = 0.015, m = 0.9
I0628 19:13:28.067685  7628 solver.cpp:349] Iteration 54500 (58.0926 iter/s, 1.72139s/100 iter), loss = 0.00256845
I0628 19:13:28.067706  7628 solver.cpp:371]     Train net output #0: loss = 0.00256894 (* 1 = 0.00256894 loss)
I0628 19:13:28.067711  7628 sgd_solver.cpp:137] Iteration 54500, lr = 0.0148437, m = 0.9
I0628 19:13:29.786275  7628 solver.cpp:349] Iteration 54600 (58.1975 iter/s, 1.71829s/100 iter), loss = 0.00202671
I0628 19:13:29.786298  7628 solver.cpp:371]     Train net output #0: loss = 0.00202721 (* 1 = 0.00202721 loss)
I0628 19:13:29.786301  7628 sgd_solver.cpp:137] Iteration 54600, lr = 0.0146875, m = 0.9
I0628 19:13:31.229182  7613 data_reader.cpp:262] Starting prefetch of epoch 70
I0628 19:13:31.502985  7628 solver.cpp:349] Iteration 54700 (58.2612 iter/s, 1.71641s/100 iter), loss = 0.000649771
I0628 19:13:31.503008  7628 solver.cpp:371]     Train net output #0: loss = 0.000650267 (* 1 = 0.000650267 loss)
I0628 19:13:31.503012  7628 sgd_solver.cpp:137] Iteration 54700, lr = 0.0145312, m = 0.9
I0628 19:13:33.221186  7628 solver.cpp:349] Iteration 54800 (58.2107 iter/s, 1.7179s/100 iter), loss = 0.00210659
I0628 19:13:33.221209  7628 solver.cpp:371]     Train net output #0: loss = 0.00210709 (* 1 = 0.00210709 loss)
I0628 19:13:33.221212  7628 sgd_solver.cpp:137] Iteration 54800, lr = 0.014375, m = 0.9
I0628 19:13:34.935330  7628 solver.cpp:349] Iteration 54900 (58.3485 iter/s, 1.71384s/100 iter), loss = 0.0007056
I0628 19:13:34.935353  7628 solver.cpp:371]     Train net output #0: loss = 0.000706096 (* 1 = 0.000706096 loss)
I0628 19:13:34.935359  7628 sgd_solver.cpp:137] Iteration 54900, lr = 0.0142187, m = 0.9
I0628 19:13:36.635212  7628 solver.cpp:545] Iteration 55000, Testing net (#0)
I0628 19:13:37.642582  7626 data_reader.cpp:262] Starting prefetch of epoch 55
I0628 19:13:37.665961  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.9174
I0628 19:13:37.665973  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9964
I0628 19:13:37.665978  7628 solver.cpp:630]     Test net output #2: loss = 0.305114 (* 1 = 0.305114 loss)
I0628 19:13:37.665992  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.03062s
I0628 19:13:37.683476  7628 solver.cpp:349] Iteration 55000 (36.3943 iter/s, 2.74768s/100 iter), loss = 0.00127458
I0628 19:13:37.683501  7628 solver.cpp:371]     Train net output #0: loss = 0.00127508 (* 1 = 0.00127508 loss)
I0628 19:13:37.683506  7628 sgd_solver.cpp:137] Iteration 55000, lr = 0.0140625, m = 0.9
I0628 19:13:39.400568  7628 solver.cpp:349] Iteration 55100 (58.2484 iter/s, 1.71678s/100 iter), loss = 0.001173
I0628 19:13:39.400590  7628 solver.cpp:371]     Train net output #0: loss = 0.0011735 (* 1 = 0.0011735 loss)
I0628 19:13:39.400594  7628 sgd_solver.cpp:137] Iteration 55100, lr = 0.0139063, m = 0.9
I0628 19:13:41.117389  7628 solver.cpp:349] Iteration 55200 (58.2575 iter/s, 1.71652s/100 iter), loss = 0.00150837
I0628 19:13:41.117411  7628 solver.cpp:371]     Train net output #0: loss = 0.00150886 (* 1 = 0.00150886 loss)
I0628 19:13:41.117415  7628 sgd_solver.cpp:137] Iteration 55200, lr = 0.01375, m = 0.9
I0628 19:13:42.834484  7628 solver.cpp:349] Iteration 55300 (58.2481 iter/s, 1.71679s/100 iter), loss = 0.00158128
I0628 19:13:42.834504  7628 solver.cpp:371]     Train net output #0: loss = 0.00158177 (* 1 = 0.00158177 loss)
I0628 19:13:42.834525  7628 sgd_solver.cpp:137] Iteration 55300, lr = 0.0135938, m = 0.9
I0628 19:13:44.551364  7628 solver.cpp:349] Iteration 55400 (58.2561 iter/s, 1.71656s/100 iter), loss = 0.00105118
I0628 19:13:44.551386  7628 solver.cpp:371]     Train net output #0: loss = 0.00105168 (* 1 = 0.00105168 loss)
I0628 19:13:44.551391  7628 sgd_solver.cpp:137] Iteration 55400, lr = 0.0134375, m = 0.9
I0628 19:13:45.666088  7613 data_reader.cpp:262] Starting prefetch of epoch 71
I0628 19:13:46.270015  7628 solver.cpp:349] Iteration 55500 (58.1955 iter/s, 1.71834s/100 iter), loss = 0.000792137
I0628 19:13:46.270036  7628 solver.cpp:371]     Train net output #0: loss = 0.000792633 (* 1 = 0.000792633 loss)
I0628 19:13:46.270040  7628 sgd_solver.cpp:137] Iteration 55500, lr = 0.0132813, m = 0.9
I0628 19:13:47.993338  7628 solver.cpp:349] Iteration 55600 (58.0376 iter/s, 1.72302s/100 iter), loss = 0.0018869
I0628 19:13:47.993360  7628 solver.cpp:371]     Train net output #0: loss = 0.0018874 (* 1 = 0.0018874 loss)
I0628 19:13:47.993362  7628 sgd_solver.cpp:137] Iteration 55600, lr = 0.013125, m = 0.9
I0628 19:13:49.707345  7628 solver.cpp:349] Iteration 55700 (58.3531 iter/s, 1.71371s/100 iter), loss = 0.0013089
I0628 19:13:49.707366  7628 solver.cpp:371]     Train net output #0: loss = 0.0013094 (* 1 = 0.0013094 loss)
I0628 19:13:49.707370  7628 sgd_solver.cpp:137] Iteration 55700, lr = 0.0129687, m = 0.9
I0628 19:13:51.431846  7628 solver.cpp:349] Iteration 55800 (57.998 iter/s, 1.7242s/100 iter), loss = 0.00149494
I0628 19:13:51.431869  7628 solver.cpp:371]     Train net output #0: loss = 0.00149543 (* 1 = 0.00149543 loss)
I0628 19:13:51.431872  7628 sgd_solver.cpp:137] Iteration 55800, lr = 0.0128125, m = 0.9
I0628 19:13:53.147600  7628 solver.cpp:349] Iteration 55900 (58.2938 iter/s, 1.71545s/100 iter), loss = 0.000781932
I0628 19:13:53.147670  7628 solver.cpp:371]     Train net output #0: loss = 0.000782429 (* 1 = 0.000782429 loss)
I0628 19:13:53.147675  7628 sgd_solver.cpp:137] Iteration 55900, lr = 0.0126562, m = 0.9
I0628 19:13:54.845824  7628 solver.cpp:545] Iteration 56000, Testing net (#0)
I0628 19:13:55.850599  7626 data_reader.cpp:262] Starting prefetch of epoch 56
I0628 19:13:55.873781  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.9172
I0628 19:13:55.873795  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9966
I0628 19:13:55.873800  7628 solver.cpp:630]     Test net output #2: loss = 0.3025 (* 1 = 0.3025 loss)
I0628 19:13:55.873813  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02783s
I0628 19:13:55.891119  7628 solver.cpp:349] Iteration 56000 (36.4563 iter/s, 2.74301s/100 iter), loss = 0.00162678
I0628 19:13:55.891141  7628 solver.cpp:371]     Train net output #0: loss = 0.00162727 (* 1 = 0.00162727 loss)
I0628 19:13:55.891145  7628 sgd_solver.cpp:137] Iteration 56000, lr = 0.0125, m = 0.9
I0628 19:13:57.613221  7628 solver.cpp:349] Iteration 56100 (58.0788 iter/s, 1.7218s/100 iter), loss = 0.000808359
I0628 19:13:57.613245  7628 solver.cpp:371]     Train net output #0: loss = 0.000808856 (* 1 = 0.000808856 loss)
I0628 19:13:57.613248  7628 sgd_solver.cpp:137] Iteration 56100, lr = 0.0123438, m = 0.9
I0628 19:13:59.334744  7628 solver.cpp:349] Iteration 56200 (58.0983 iter/s, 1.72122s/100 iter), loss = 0.000844953
I0628 19:13:59.334766  7628 solver.cpp:371]     Train net output #0: loss = 0.000845449 (* 1 = 0.000845449 loss)
I0628 19:13:59.334770  7628 sgd_solver.cpp:137] Iteration 56200, lr = 0.0121875, m = 0.9
I0628 19:14:00.124487  7613 data_reader.cpp:262] Starting prefetch of epoch 72
I0628 19:14:01.051942  7628 solver.cpp:349] Iteration 56300 (58.2447 iter/s, 1.71689s/100 iter), loss = 0.000623107
I0628 19:14:01.051964  7628 solver.cpp:371]     Train net output #0: loss = 0.000623603 (* 1 = 0.000623603 loss)
I0628 19:14:01.051967  7628 sgd_solver.cpp:137] Iteration 56300, lr = 0.0120313, m = 0.9
I0628 19:14:02.767623  7628 solver.cpp:349] Iteration 56400 (58.2962 iter/s, 1.71538s/100 iter), loss = 0.000770935
I0628 19:14:02.767647  7628 solver.cpp:371]     Train net output #0: loss = 0.000771431 (* 1 = 0.000771431 loss)
I0628 19:14:02.767650  7628 sgd_solver.cpp:137] Iteration 56400, lr = 0.011875, m = 0.9
I0628 19:14:04.481848  7628 solver.cpp:349] Iteration 56500 (58.3458 iter/s, 1.71392s/100 iter), loss = 0.000951465
I0628 19:14:04.481869  7628 solver.cpp:371]     Train net output #0: loss = 0.000951961 (* 1 = 0.000951961 loss)
I0628 19:14:04.481873  7628 sgd_solver.cpp:137] Iteration 56500, lr = 0.0117188, m = 0.9
I0628 19:14:06.201721  7628 solver.cpp:349] Iteration 56600 (58.154 iter/s, 1.71957s/100 iter), loss = 0.00127786
I0628 19:14:06.201741  7628 solver.cpp:371]     Train net output #0: loss = 0.00127836 (* 1 = 0.00127836 loss)
I0628 19:14:06.201745  7628 sgd_solver.cpp:137] Iteration 56600, lr = 0.0115625, m = 0.9
I0628 19:14:07.916896  7628 solver.cpp:349] Iteration 56700 (58.3133 iter/s, 1.71487s/100 iter), loss = 0.000729334
I0628 19:14:07.916918  7628 solver.cpp:371]     Train net output #0: loss = 0.000729829 (* 1 = 0.000729829 loss)
I0628 19:14:07.916923  7628 sgd_solver.cpp:137] Iteration 56700, lr = 0.0114062, m = 0.9
I0628 19:14:09.635399  7628 solver.cpp:349] Iteration 56800 (58.2004 iter/s, 1.7182s/100 iter), loss = 0.000479912
I0628 19:14:09.635421  7628 solver.cpp:371]     Train net output #0: loss = 0.000480408 (* 1 = 0.000480408 loss)
I0628 19:14:09.635426  7628 sgd_solver.cpp:137] Iteration 56800, lr = 0.01125, m = 0.9
I0628 19:14:11.351325  7628 solver.cpp:349] Iteration 56900 (58.288 iter/s, 1.71562s/100 iter), loss = 0.000857208
I0628 19:14:11.351346  7628 solver.cpp:371]     Train net output #0: loss = 0.000857703 (* 1 = 0.000857703 loss)
I0628 19:14:11.351351  7628 sgd_solver.cpp:137] Iteration 56900, lr = 0.0110937, m = 0.9
I0628 19:14:13.047166  7628 solver.cpp:545] Iteration 57000, Testing net (#0)
I0628 19:14:14.057441  7626 data_reader.cpp:262] Starting prefetch of epoch 57
I0628 19:14:14.077788  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.9164
I0628 19:14:14.077800  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9968
I0628 19:14:14.077805  7628 solver.cpp:630]     Test net output #2: loss = 0.303103 (* 1 = 0.303103 loss)
I0628 19:14:14.077817  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.03049s
I0628 19:14:14.095127  7628 solver.cpp:349] Iteration 57000 (36.4519 iter/s, 2.74334s/100 iter), loss = 0.0011335
I0628 19:14:14.095150  7628 solver.cpp:371]     Train net output #0: loss = 0.001134 (* 1 = 0.001134 loss)
I0628 19:14:14.095154  7628 sgd_solver.cpp:137] Iteration 57000, lr = 0.0109375, m = 0.9
I0628 19:14:14.576170  7613 data_reader.cpp:262] Starting prefetch of epoch 73
I0628 19:14:15.810928  7628 solver.cpp:349] Iteration 57100 (58.2921 iter/s, 1.7155s/100 iter), loss = 0.000464545
I0628 19:14:15.810952  7628 solver.cpp:371]     Train net output #0: loss = 0.000465041 (* 1 = 0.000465041 loss)
I0628 19:14:15.810956  7628 sgd_solver.cpp:137] Iteration 57100, lr = 0.0107813, m = 0.9
I0628 19:14:17.527192  7628 solver.cpp:349] Iteration 57200 (58.2764 iter/s, 1.71596s/100 iter), loss = 0.000797259
I0628 19:14:17.527217  7628 solver.cpp:371]     Train net output #0: loss = 0.000797755 (* 1 = 0.000797755 loss)
I0628 19:14:17.527222  7628 sgd_solver.cpp:137] Iteration 57200, lr = 0.010625, m = 0.9
I0628 19:14:19.247623  7628 solver.cpp:349] Iteration 57300 (58.1354 iter/s, 1.72012s/100 iter), loss = 0.00145732
I0628 19:14:19.247644  7628 solver.cpp:371]     Train net output #0: loss = 0.00145782 (* 1 = 0.00145782 loss)
I0628 19:14:19.247648  7628 sgd_solver.cpp:137] Iteration 57300, lr = 0.0104688, m = 0.9
I0628 19:14:20.968912  7628 solver.cpp:349] Iteration 57400 (58.1063 iter/s, 1.72098s/100 iter), loss = 0.00124758
I0628 19:14:20.968935  7628 solver.cpp:371]     Train net output #0: loss = 0.00124807 (* 1 = 0.00124807 loss)
I0628 19:14:20.968940  7628 sgd_solver.cpp:137] Iteration 57400, lr = 0.0103125, m = 0.9
I0628 19:14:22.684162  7628 solver.cpp:349] Iteration 57500 (58.3108 iter/s, 1.71495s/100 iter), loss = 0.00128449
I0628 19:14:22.684185  7628 solver.cpp:371]     Train net output #0: loss = 0.00128499 (* 1 = 0.00128499 loss)
I0628 19:14:22.684190  7628 sgd_solver.cpp:137] Iteration 57500, lr = 0.0101563, m = 0.9
I0628 19:14:24.407841  7628 solver.cpp:349] Iteration 57600 (58.0257 iter/s, 1.72338s/100 iter), loss = 0.00138138
I0628 19:14:24.407922  7628 solver.cpp:371]     Train net output #0: loss = 0.00138188 (* 1 = 0.00138188 loss)
I0628 19:14:24.407927  7628 sgd_solver.cpp:137] Iteration 57600, lr = 0.01, m = 0.9
I0628 19:14:26.121163  7628 solver.cpp:349] Iteration 57700 (58.3786 iter/s, 1.71296s/100 iter), loss = 0.00163093
I0628 19:14:26.121186  7628 solver.cpp:371]     Train net output #0: loss = 0.00163143 (* 1 = 0.00163143 loss)
I0628 19:14:26.121189  7628 sgd_solver.cpp:137] Iteration 57700, lr = 0.00984375, m = 0.9
I0628 19:14:27.836798  7628 solver.cpp:349] Iteration 57800 (58.2977 iter/s, 1.71533s/100 iter), loss = 0.0013781
I0628 19:14:27.836822  7628 solver.cpp:371]     Train net output #0: loss = 0.00137859 (* 1 = 0.00137859 loss)
I0628 19:14:27.836825  7628 sgd_solver.cpp:137] Iteration 57800, lr = 0.0096875, m = 0.9
I0628 19:14:27.991729  7613 data_reader.cpp:262] Starting prefetch of epoch 74
I0628 19:14:29.553380  7628 solver.cpp:349] Iteration 57900 (58.2655 iter/s, 1.71628s/100 iter), loss = 0.00126192
I0628 19:14:29.553402  7628 solver.cpp:371]     Train net output #0: loss = 0.00126242 (* 1 = 0.00126242 loss)
I0628 19:14:29.553406  7628 sgd_solver.cpp:137] Iteration 57900, lr = 0.00953125, m = 0.9
I0628 19:14:31.250757  7628 solver.cpp:545] Iteration 58000, Testing net (#0)
I0628 19:14:32.256024  7626 data_reader.cpp:262] Starting prefetch of epoch 58
I0628 19:14:32.280632  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.9178
I0628 19:14:32.280644  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9964
I0628 19:14:32.280649  7628 solver.cpp:630]     Test net output #2: loss = 0.30209 (* 1 = 0.30209 loss)
I0628 19:14:32.280664  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02975s
I0628 19:14:32.297901  7628 solver.cpp:349] Iteration 58000 (36.4424 iter/s, 2.74406s/100 iter), loss = 0.000792703
I0628 19:14:32.297924  7628 solver.cpp:371]     Train net output #0: loss = 0.000793198 (* 1 = 0.000793198 loss)
I0628 19:14:32.297927  7628 sgd_solver.cpp:137] Iteration 58000, lr = 0.009375, m = 0.9
I0628 19:14:34.015252  7628 solver.cpp:349] Iteration 58100 (58.2395 iter/s, 1.71705s/100 iter), loss = 0.000582912
I0628 19:14:34.015275  7628 solver.cpp:371]     Train net output #0: loss = 0.000583407 (* 1 = 0.000583407 loss)
I0628 19:14:34.015280  7628 sgd_solver.cpp:137] Iteration 58100, lr = 0.00921875, m = 0.9
I0628 19:14:35.731423  7628 solver.cpp:349] Iteration 58200 (58.2797 iter/s, 1.71586s/100 iter), loss = 0.00137347
I0628 19:14:35.731446  7628 solver.cpp:371]     Train net output #0: loss = 0.00137396 (* 1 = 0.00137396 loss)
I0628 19:14:35.731451  7628 sgd_solver.cpp:137] Iteration 58200, lr = 0.0090625, m = 0.9
I0628 19:14:37.450810  7628 solver.cpp:349] Iteration 58300 (58.1706 iter/s, 1.71908s/100 iter), loss = 0.00108824
I0628 19:14:37.450834  7628 solver.cpp:371]     Train net output #0: loss = 0.00108873 (* 1 = 0.00108873 loss)
I0628 19:14:37.450837  7628 sgd_solver.cpp:137] Iteration 58300, lr = 0.00890625, m = 0.9
I0628 19:14:39.164475  7628 solver.cpp:349] Iteration 58400 (58.3648 iter/s, 1.71336s/100 iter), loss = 0.000856623
I0628 19:14:39.164499  7628 solver.cpp:371]     Train net output #0: loss = 0.000857118 (* 1 = 0.000857118 loss)
I0628 19:14:39.164502  7628 sgd_solver.cpp:137] Iteration 58400, lr = 0.00875, m = 0.9
I0628 19:14:40.878182  7628 solver.cpp:349] Iteration 58500 (58.3634 iter/s, 1.7134s/100 iter), loss = 0.00123742
I0628 19:14:40.878204  7628 solver.cpp:371]     Train net output #0: loss = 0.00123792 (* 1 = 0.00123792 loss)
I0628 19:14:40.878208  7628 sgd_solver.cpp:137] Iteration 58500, lr = 0.00859375, m = 0.9
I0628 19:14:42.425743  7613 data_reader.cpp:262] Starting prefetch of epoch 75
I0628 19:14:42.596977  7628 solver.cpp:349] Iteration 58600 (58.1905 iter/s, 1.71849s/100 iter), loss = 0.000853292
I0628 19:14:42.597002  7628 solver.cpp:371]     Train net output #0: loss = 0.000853787 (* 1 = 0.000853787 loss)
I0628 19:14:42.597005  7628 sgd_solver.cpp:137] Iteration 58600, lr = 0.0084375, m = 0.9
I0628 19:14:44.314164  7628 solver.cpp:349] Iteration 58700 (58.2451 iter/s, 1.71688s/100 iter), loss = 0.00157045
I0628 19:14:44.314209  7628 solver.cpp:371]     Train net output #0: loss = 0.00157095 (* 1 = 0.00157095 loss)
I0628 19:14:44.314214  7628 sgd_solver.cpp:137] Iteration 58700, lr = 0.00828125, m = 0.9
I0628 19:14:46.032122  7628 solver.cpp:349] Iteration 58800 (58.2197 iter/s, 1.71763s/100 iter), loss = 0.00121077
I0628 19:14:46.032143  7628 solver.cpp:371]     Train net output #0: loss = 0.00121126 (* 1 = 0.00121126 loss)
I0628 19:14:46.032147  7628 sgd_solver.cpp:137] Iteration 58800, lr = 0.008125, m = 0.9
I0628 19:14:47.750437  7628 solver.cpp:349] Iteration 58900 (58.2068 iter/s, 1.71801s/100 iter), loss = 0.000546711
I0628 19:14:47.750458  7628 solver.cpp:371]     Train net output #0: loss = 0.000547207 (* 1 = 0.000547207 loss)
I0628 19:14:47.750461  7628 sgd_solver.cpp:137] Iteration 58900, lr = 0.00796875, m = 0.9
I0628 19:14:49.451138  7628 solver.cpp:545] Iteration 59000, Testing net (#0)
I0628 19:14:50.459617  7626 data_reader.cpp:262] Starting prefetch of epoch 59
I0628 19:14:50.479953  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.9176
I0628 19:14:50.479964  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9962
I0628 19:14:50.479969  7628 solver.cpp:630]     Test net output #2: loss = 0.302434 (* 1 = 0.302434 loss)
I0628 19:14:50.479981  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02869s
I0628 19:14:50.497279  7628 solver.cpp:349] Iteration 59000 (36.4115 iter/s, 2.74638s/100 iter), loss = 0.0015475
I0628 19:14:50.497303  7628 solver.cpp:371]     Train net output #0: loss = 0.00154799 (* 1 = 0.00154799 loss)
I0628 19:14:50.497306  7628 sgd_solver.cpp:137] Iteration 59000, lr = 0.0078125, m = 0.9
I0628 19:14:52.219291  7628 solver.cpp:349] Iteration 59100 (58.0819 iter/s, 1.72171s/100 iter), loss = 0.000893756
I0628 19:14:52.219311  7628 solver.cpp:371]     Train net output #0: loss = 0.000894251 (* 1 = 0.000894251 loss)
I0628 19:14:52.219316  7628 sgd_solver.cpp:137] Iteration 59100, lr = 0.00765625, m = 0.9
I0628 19:14:53.935809  7628 solver.cpp:349] Iteration 59200 (58.2677 iter/s, 1.71622s/100 iter), loss = 0.000492424
I0628 19:14:53.935832  7628 solver.cpp:371]     Train net output #0: loss = 0.000492919 (* 1 = 0.000492919 loss)
I0628 19:14:53.935837  7628 sgd_solver.cpp:137] Iteration 59200, lr = 0.0075, m = 0.9
I0628 19:14:55.650110  7628 solver.cpp:349] Iteration 59300 (58.3432 iter/s, 1.71399s/100 iter), loss = 0.00119854
I0628 19:14:55.650161  7628 solver.cpp:371]     Train net output #0: loss = 0.00119904 (* 1 = 0.00119904 loss)
I0628 19:14:55.650168  7628 sgd_solver.cpp:137] Iteration 59300, lr = 0.00734375, m = 0.9
I0628 19:14:56.871307  7613 data_reader.cpp:262] Starting prefetch of epoch 76
I0628 19:14:57.369377  7628 solver.cpp:349] Iteration 59400 (58.1758 iter/s, 1.71893s/100 iter), loss = 0.00127121
I0628 19:14:57.369400  7628 solver.cpp:371]     Train net output #0: loss = 0.00127171 (* 1 = 0.00127171 loss)
I0628 19:14:57.369405  7628 sgd_solver.cpp:137] Iteration 59400, lr = 0.0071875, m = 0.9
I0628 19:14:59.089146  7628 solver.cpp:349] Iteration 59500 (58.1577 iter/s, 1.71946s/100 iter), loss = 0.00142835
I0628 19:14:59.089169  7628 solver.cpp:371]     Train net output #0: loss = 0.00142885 (* 1 = 0.00142885 loss)
I0628 19:14:59.089175  7628 sgd_solver.cpp:137] Iteration 59500, lr = 0.00703125, m = 0.9
I0628 19:15:00.807771  7628 solver.cpp:349] Iteration 59600 (58.1964 iter/s, 1.71832s/100 iter), loss = 0.0014177
I0628 19:15:00.807795  7628 solver.cpp:371]     Train net output #0: loss = 0.00141819 (* 1 = 0.00141819 loss)
I0628 19:15:00.807798  7628 sgd_solver.cpp:137] Iteration 59600, lr = 0.006875, m = 0.9
I0628 19:15:02.522892  7628 solver.cpp:349] Iteration 59700 (58.3152 iter/s, 1.71482s/100 iter), loss = 0.0012766
I0628 19:15:02.522915  7628 solver.cpp:371]     Train net output #0: loss = 0.0012771 (* 1 = 0.0012771 loss)
I0628 19:15:02.522919  7628 sgd_solver.cpp:137] Iteration 59700, lr = 0.00671875, m = 0.9
I0628 19:15:04.239603  7628 solver.cpp:349] Iteration 59800 (58.2613 iter/s, 1.71641s/100 iter), loss = 0.000773642
I0628 19:15:04.239622  7628 solver.cpp:371]     Train net output #0: loss = 0.000774138 (* 1 = 0.000774138 loss)
I0628 19:15:04.239626  7628 sgd_solver.cpp:137] Iteration 59800, lr = 0.0065625, m = 0.9
I0628 19:15:05.959028  7628 solver.cpp:349] Iteration 59900 (58.1691 iter/s, 1.71913s/100 iter), loss = 0.0019883
I0628 19:15:05.959049  7628 solver.cpp:371]     Train net output #0: loss = 0.0019888 (* 1 = 0.0019888 loss)
I0628 19:15:05.959053  7628 sgd_solver.cpp:137] Iteration 59900, lr = 0.00640625, m = 0.9
I0628 19:15:07.659164  7628 solver.cpp:675] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-06-28_18-56-45/initial/cifar10_jacintonet11v2_iter_60000.caffemodel
I0628 19:15:07.667017  7628 sgd_solver.cpp:288] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-06-28_18-56-45/initial/cifar10_jacintonet11v2_iter_60000.solverstate
I0628 19:15:07.670486  7628 solver.cpp:545] Iteration 60000, Testing net (#0)
I0628 19:15:08.675168  7626 data_reader.cpp:262] Starting prefetch of epoch 60
I0628 19:15:08.695619  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.9182
I0628 19:15:08.695636  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9962
I0628 19:15:08.695642  7628 solver.cpp:630]     Test net output #2: loss = 0.300749 (* 1 = 0.300749 loss)
I0628 19:15:08.695655  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02501s
I0628 19:15:08.714131  7628 solver.cpp:349] Iteration 60000 (36.3024 iter/s, 2.75464s/100 iter), loss = 0.000588658
I0628 19:15:08.714161  7628 solver.cpp:371]     Train net output #0: loss = 0.000589153 (* 1 = 0.000589153 loss)
I0628 19:15:08.714165  7628 sgd_solver.cpp:137] Iteration 60000, lr = 0.00625, m = 0.9
I0628 19:15:10.429891  7628 solver.cpp:349] Iteration 60100 (58.2938 iter/s, 1.71545s/100 iter), loss = 0.000986898
I0628 19:15:10.429913  7628 solver.cpp:371]     Train net output #0: loss = 0.000987393 (* 1 = 0.000987393 loss)
I0628 19:15:10.429916  7628 sgd_solver.cpp:137] Iteration 60100, lr = 0.00609375, m = 0.9
I0628 19:15:11.345257  7613 data_reader.cpp:262] Starting prefetch of epoch 77
I0628 19:15:12.149569  7628 solver.cpp:349] Iteration 60200 (58.1607 iter/s, 1.71937s/100 iter), loss = 0.000731806
I0628 19:15:12.149591  7628 solver.cpp:371]     Train net output #0: loss = 0.000732302 (* 1 = 0.000732302 loss)
I0628 19:15:12.149595  7628 sgd_solver.cpp:137] Iteration 60200, lr = 0.0059375, m = 0.9
I0628 19:15:13.867714  7628 solver.cpp:349] Iteration 60300 (58.213 iter/s, 1.71783s/100 iter), loss = 0.001069
I0628 19:15:13.867738  7628 solver.cpp:371]     Train net output #0: loss = 0.0010695 (* 1 = 0.0010695 loss)
I0628 19:15:13.867741  7628 sgd_solver.cpp:137] Iteration 60300, lr = 0.00578125, m = 0.9
I0628 19:15:15.583225  7628 solver.cpp:349] Iteration 60400 (58.302 iter/s, 1.71521s/100 iter), loss = 0.00150259
I0628 19:15:15.583246  7628 solver.cpp:371]     Train net output #0: loss = 0.00150308 (* 1 = 0.00150308 loss)
I0628 19:15:15.583251  7628 sgd_solver.cpp:137] Iteration 60400, lr = 0.005625, m = 0.9
I0628 19:15:17.298167  7628 solver.cpp:349] Iteration 60500 (58.3213 iter/s, 1.71464s/100 iter), loss = 0.00127904
I0628 19:15:17.298190  7628 solver.cpp:371]     Train net output #0: loss = 0.00127953 (* 1 = 0.00127953 loss)
I0628 19:15:17.298194  7628 sgd_solver.cpp:137] Iteration 60500, lr = 0.00546875, m = 0.9
I0628 19:15:19.010416  7628 solver.cpp:349] Iteration 60600 (58.4131 iter/s, 1.71195s/100 iter), loss = 0.00191661
I0628 19:15:19.010438  7628 solver.cpp:371]     Train net output #0: loss = 0.00191711 (* 1 = 0.00191711 loss)
I0628 19:15:19.010442  7628 sgd_solver.cpp:137] Iteration 60600, lr = 0.0053125, m = 0.9
I0628 19:15:20.724943  7628 solver.cpp:349] Iteration 60700 (58.3354 iter/s, 1.71422s/100 iter), loss = 0.000639156
I0628 19:15:20.724966  7628 solver.cpp:371]     Train net output #0: loss = 0.000639651 (* 1 = 0.000639651 loss)
I0628 19:15:20.724969  7628 sgd_solver.cpp:137] Iteration 60700, lr = 0.00515625, m = 0.9
I0628 19:15:22.444485  7628 solver.cpp:349] Iteration 60800 (58.1652 iter/s, 1.71924s/100 iter), loss = 0.00112943
I0628 19:15:22.444506  7628 solver.cpp:371]     Train net output #0: loss = 0.00112993 (* 1 = 0.00112993 loss)
I0628 19:15:22.444511  7628 sgd_solver.cpp:137] Iteration 60800, lr = 0.005, m = 0.9
I0628 19:15:24.161047  7628 solver.cpp:349] Iteration 60900 (58.2663 iter/s, 1.71626s/100 iter), loss = 0.00110679
I0628 19:15:24.161070  7628 solver.cpp:371]     Train net output #0: loss = 0.00110729 (* 1 = 0.00110729 loss)
I0628 19:15:24.161074  7628 sgd_solver.cpp:137] Iteration 60900, lr = 0.00484375, m = 0.9
I0628 19:15:24.743489  7613 data_reader.cpp:262] Starting prefetch of epoch 78
I0628 19:15:25.861317  7628 solver.cpp:545] Iteration 61000, Testing net (#0)
I0628 19:15:26.867300  7626 data_reader.cpp:262] Starting prefetch of epoch 61
I0628 19:15:26.888324  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.9164
I0628 19:15:26.888337  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.996
I0628 19:15:26.888344  7628 solver.cpp:630]     Test net output #2: loss = 0.301281 (* 1 = 0.301281 loss)
I0628 19:15:26.888360  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02688s
I0628 19:15:26.905768  7628 solver.cpp:349] Iteration 61000 (36.4397 iter/s, 2.74426s/100 iter), loss = 0.00231112
I0628 19:15:26.905791  7628 solver.cpp:371]     Train net output #0: loss = 0.00231162 (* 1 = 0.00231162 loss)
I0628 19:15:26.905794  7628 sgd_solver.cpp:137] Iteration 61000, lr = 0.0046875, m = 0.9
I0628 19:15:28.627837  7628 solver.cpp:349] Iteration 61100 (58.0799 iter/s, 1.72177s/100 iter), loss = 0.0010903
I0628 19:15:28.627862  7628 solver.cpp:371]     Train net output #0: loss = 0.0010908 (* 1 = 0.0010908 loss)
I0628 19:15:28.627867  7628 sgd_solver.cpp:137] Iteration 61100, lr = 0.00453125, m = 0.9
I0628 19:15:30.346869  7628 solver.cpp:349] Iteration 61200 (58.1827 iter/s, 1.71872s/100 iter), loss = 0.00116113
I0628 19:15:30.346891  7628 solver.cpp:371]     Train net output #0: loss = 0.00116163 (* 1 = 0.00116163 loss)
I0628 19:15:30.346895  7628 sgd_solver.cpp:137] Iteration 61200, lr = 0.004375, m = 0.9
I0628 19:15:32.063922  7628 solver.cpp:349] Iteration 61300 (58.2496 iter/s, 1.71675s/100 iter), loss = 0.000634547
I0628 19:15:32.063944  7628 solver.cpp:371]     Train net output #0: loss = 0.000635042 (* 1 = 0.000635042 loss)
I0628 19:15:32.063948  7628 sgd_solver.cpp:137] Iteration 61300, lr = 0.00421875, m = 0.9
I0628 19:15:33.778012  7628 solver.cpp:349] Iteration 61400 (58.3503 iter/s, 1.71379s/100 iter), loss = 0.00123137
I0628 19:15:33.778034  7628 solver.cpp:371]     Train net output #0: loss = 0.00123187 (* 1 = 0.00123187 loss)
I0628 19:15:33.778038  7628 sgd_solver.cpp:137] Iteration 61400, lr = 0.0040625, m = 0.9
I0628 19:15:35.494246  7628 solver.cpp:349] Iteration 61500 (58.2775 iter/s, 1.71593s/100 iter), loss = 0.00100535
I0628 19:15:35.494268  7628 solver.cpp:371]     Train net output #0: loss = 0.00100585 (* 1 = 0.00100585 loss)
I0628 19:15:35.494272  7628 sgd_solver.cpp:137] Iteration 61500, lr = 0.00390625, m = 0.9
I0628 19:15:37.215955  7628 solver.cpp:349] Iteration 61600 (58.0922 iter/s, 1.7214s/100 iter), loss = 0.00180023
I0628 19:15:37.215975  7628 solver.cpp:371]     Train net output #0: loss = 0.00180073 (* 1 = 0.00180073 loss)
I0628 19:15:37.215981  7628 sgd_solver.cpp:137] Iteration 61600, lr = 0.00375, m = 0.9
I0628 19:15:38.929664  7628 solver.cpp:349] Iteration 61700 (58.3632 iter/s, 1.71341s/100 iter), loss = 0.00148542
I0628 19:15:38.929687  7628 solver.cpp:371]     Train net output #0: loss = 0.00148591 (* 1 = 0.00148591 loss)
I0628 19:15:38.929690  7628 sgd_solver.cpp:137] Iteration 61700, lr = 0.00359375, m = 0.9
I0628 19:15:39.187254  7613 data_reader.cpp:262] Starting prefetch of epoch 79
I0628 19:15:40.647749  7628 solver.cpp:349] Iteration 61800 (58.2147 iter/s, 1.71778s/100 iter), loss = 0.00118566
I0628 19:15:40.647773  7628 solver.cpp:371]     Train net output #0: loss = 0.00118616 (* 1 = 0.00118616 loss)
I0628 19:15:40.647778  7628 sgd_solver.cpp:137] Iteration 61800, lr = 0.0034375, m = 0.9
I0628 19:15:42.371969  7628 solver.cpp:349] Iteration 61900 (58.0077 iter/s, 1.72391s/100 iter), loss = 0.000947787
I0628 19:15:42.371994  7628 solver.cpp:371]     Train net output #0: loss = 0.000948282 (* 1 = 0.000948282 loss)
I0628 19:15:42.372001  7628 sgd_solver.cpp:137] Iteration 61900, lr = 0.00328125, m = 0.9
I0628 19:15:44.076521  7628 solver.cpp:545] Iteration 62000, Testing net (#0)
I0628 19:15:45.082273  7626 data_reader.cpp:262] Starting prefetch of epoch 62
I0628 19:15:45.108429  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.9174
I0628 19:15:45.108449  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.996
I0628 19:15:45.108455  7628 solver.cpp:630]     Test net output #2: loss = 0.301195 (* 1 = 0.301195 loss)
I0628 19:15:45.108486  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.03181s
I0628 19:15:45.125819  7628 solver.cpp:349] Iteration 62000 (36.319 iter/s, 2.75338s/100 iter), loss = 0.001339
I0628 19:15:45.125835  7628 solver.cpp:371]     Train net output #0: loss = 0.00133949 (* 1 = 0.00133949 loss)
I0628 19:15:45.125839  7628 sgd_solver.cpp:137] Iteration 62000, lr = 0.003125, m = 0.9
I0628 19:15:46.840582  7628 solver.cpp:349] Iteration 62100 (58.3272 iter/s, 1.71447s/100 iter), loss = 0.00165798
I0628 19:15:46.840606  7628 solver.cpp:371]     Train net output #0: loss = 0.00165847 (* 1 = 0.00165847 loss)
I0628 19:15:46.840610  7628 sgd_solver.cpp:137] Iteration 62100, lr = 0.00296875, m = 0.9
I0628 19:15:48.557597  7628 solver.cpp:349] Iteration 62200 (58.251 iter/s, 1.71671s/100 iter), loss = 0.00075679
I0628 19:15:48.557620  7628 solver.cpp:371]     Train net output #0: loss = 0.000757284 (* 1 = 0.000757284 loss)
I0628 19:15:48.557623  7628 sgd_solver.cpp:137] Iteration 62200, lr = 0.0028125, m = 0.9
I0628 19:15:50.272292  7628 solver.cpp:349] Iteration 62300 (58.3297 iter/s, 1.71439s/100 iter), loss = 0.00135423
I0628 19:15:50.272312  7628 solver.cpp:371]     Train net output #0: loss = 0.00135473 (* 1 = 0.00135473 loss)
I0628 19:15:50.272316  7628 sgd_solver.cpp:137] Iteration 62300, lr = 0.00265625, m = 0.9
I0628 19:15:51.998705  7628 solver.cpp:349] Iteration 62400 (57.9337 iter/s, 1.72611s/100 iter), loss = 0.00063447
I0628 19:15:51.998733  7628 solver.cpp:371]     Train net output #0: loss = 0.000634965 (* 1 = 0.000634965 loss)
I0628 19:15:51.998739  7628 sgd_solver.cpp:137] Iteration 62400, lr = 0.0025, m = 0.9
I0628 19:15:53.652981  7613 data_reader.cpp:262] Starting prefetch of epoch 80
I0628 19:15:53.721344  7628 solver.cpp:349] Iteration 62500 (58.0611 iter/s, 1.72232s/100 iter), loss = 0.0012559
I0628 19:15:53.721369  7628 solver.cpp:371]     Train net output #0: loss = 0.0012564 (* 1 = 0.0012564 loss)
I0628 19:15:53.721372  7628 sgd_solver.cpp:137] Iteration 62500, lr = 0.00234375, m = 0.9
I0628 19:15:55.435757  7628 solver.cpp:349] Iteration 62600 (58.3394 iter/s, 1.71411s/100 iter), loss = 0.000651107
I0628 19:15:55.435778  7628 solver.cpp:371]     Train net output #0: loss = 0.000651601 (* 1 = 0.000651601 loss)
I0628 19:15:55.435782  7628 sgd_solver.cpp:137] Iteration 62600, lr = 0.0021875, m = 0.9
I0628 19:15:57.152112  7628 solver.cpp:349] Iteration 62700 (58.2733 iter/s, 1.71605s/100 iter), loss = 0.00214806
I0628 19:15:57.152189  7628 solver.cpp:371]     Train net output #0: loss = 0.00214855 (* 1 = 0.00214855 loss)
I0628 19:15:57.152194  7628 sgd_solver.cpp:137] Iteration 62700, lr = 0.00203125, m = 0.9
I0628 19:15:58.866389  7628 solver.cpp:349] Iteration 62800 (58.3458 iter/s, 1.71392s/100 iter), loss = 0.00167872
I0628 19:15:58.866410  7628 solver.cpp:371]     Train net output #0: loss = 0.00167921 (* 1 = 0.00167921 loss)
I0628 19:15:58.866415  7628 sgd_solver.cpp:137] Iteration 62800, lr = 0.001875, m = 0.9
I0628 19:16:00.580729  7628 solver.cpp:349] Iteration 62900 (58.3418 iter/s, 1.71404s/100 iter), loss = 0.00144808
I0628 19:16:00.580752  7628 solver.cpp:371]     Train net output #0: loss = 0.00144857 (* 1 = 0.00144857 loss)
I0628 19:16:00.580755  7628 sgd_solver.cpp:137] Iteration 62900, lr = 0.00171875, m = 0.9
I0628 19:16:02.279505  7628 solver.cpp:545] Iteration 63000, Testing net (#0)
I0628 19:16:03.284483  7626 data_reader.cpp:262] Starting prefetch of epoch 63
I0628 19:16:03.308208  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.9184
I0628 19:16:03.308228  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.9962
I0628 19:16:03.308233  7628 solver.cpp:630]     Test net output #2: loss = 0.302289 (* 1 = 0.302289 loss)
I0628 19:16:03.308246  7628 solver.cpp:305] [MultiGPU] Tests completed in 1.02858s
I0628 19:16:03.325546  7628 solver.cpp:349] Iteration 63000 (36.4384 iter/s, 2.74436s/100 iter), loss = 0.000795351
I0628 19:16:03.325577  7628 solver.cpp:371]     Train net output #0: loss = 0.000795846 (* 1 = 0.000795846 loss)
I0628 19:16:03.325583  7628 sgd_solver.cpp:137] Iteration 63000, lr = 0.0015625, m = 0.9
I0628 19:16:05.039954  7628 solver.cpp:349] Iteration 63100 (58.34 iter/s, 1.71409s/100 iter), loss = 0.0010553
I0628 19:16:05.039975  7628 solver.cpp:371]     Train net output #0: loss = 0.0010558 (* 1 = 0.0010558 loss)
I0628 19:16:05.039979  7628 sgd_solver.cpp:137] Iteration 63100, lr = 0.00140625, m = 0.9
I0628 19:16:06.756326  7628 solver.cpp:349] Iteration 63200 (58.2726 iter/s, 1.71607s/100 iter), loss = 0.00124562
I0628 19:16:06.756350  7628 solver.cpp:371]     Train net output #0: loss = 0.00124611 (* 1 = 0.00124611 loss)
I0628 19:16:06.756353  7628 sgd_solver.cpp:137] Iteration 63200, lr = 0.00125, m = 0.9
I0628 19:16:08.095125  7613 data_reader.cpp:262] Starting prefetch of epoch 81
I0628 19:16:08.482486  7628 solver.cpp:349] Iteration 63300 (57.9423 iter/s, 1.72585s/100 iter), loss = 0.000814115
I0628 19:16:08.482509  7628 solver.cpp:371]     Train net output #0: loss = 0.00081461 (* 1 = 0.00081461 loss)
I0628 19:16:08.482516  7628 sgd_solver.cpp:137] Iteration 63300, lr = 0.00109375, m = 0.9
I0628 19:16:10.196393  7628 solver.cpp:349] Iteration 63400 (58.3567 iter/s, 1.7136s/100 iter), loss = 0.00121793
I0628 19:16:10.196416  7628 solver.cpp:371]     Train net output #0: loss = 0.00121843 (* 1 = 0.00121843 loss)
I0628 19:16:10.196422  7628 sgd_solver.cpp:137] Iteration 63400, lr = 0.000937498, m = 0.9
I0628 19:16:11.916324  7628 solver.cpp:349] Iteration 63500 (58.1523 iter/s, 1.71962s/100 iter), loss = 0.0019167
I0628 19:16:11.916347  7628 solver.cpp:371]     Train net output #0: loss = 0.00191719 (* 1 = 0.00191719 loss)
I0628 19:16:11.916352  7628 sgd_solver.cpp:137] Iteration 63500, lr = 0.00078125, m = 0.9
I0628 19:16:13.631709  7628 solver.cpp:349] Iteration 63600 (58.3062 iter/s, 1.71508s/100 iter), loss = 0.00234713
I0628 19:16:13.631732  7628 solver.cpp:371]     Train net output #0: loss = 0.00234762 (* 1 = 0.00234762 loss)
I0628 19:16:13.631736  7628 sgd_solver.cpp:137] Iteration 63600, lr = 0.000625002, m = 0.9
I0628 19:16:15.347185  7628 solver.cpp:349] Iteration 63700 (58.3032 iter/s, 1.71517s/100 iter), loss = 0.00175486
I0628 19:16:15.347208  7628 solver.cpp:371]     Train net output #0: loss = 0.00175536 (* 1 = 0.00175536 loss)
I0628 19:16:15.347211  7628 sgd_solver.cpp:137] Iteration 63700, lr = 0.000468749, m = 0.9
I0628 19:16:17.064702  7628 solver.cpp:349] Iteration 63800 (58.2339 iter/s, 1.71721s/100 iter), loss = 0.00118228
I0628 19:16:17.064726  7628 solver.cpp:371]     Train net output #0: loss = 0.00118277 (* 1 = 0.00118277 loss)
I0628 19:16:17.064749  7628 sgd_solver.cpp:137] Iteration 63800, lr = 0.000312501, m = 0.9
I0628 19:16:18.783427  7628 solver.cpp:349] Iteration 63900 (58.1937 iter/s, 1.7184s/100 iter), loss = 0.00138932
I0628 19:16:18.783448  7628 solver.cpp:371]     Train net output #0: loss = 0.00138981 (* 1 = 0.00138981 loss)
I0628 19:16:18.783452  7628 sgd_solver.cpp:137] Iteration 63900, lr = 0.000156248, m = 0.9
I0628 19:16:20.487411  7628 solver.cpp:349] Iteration 63999 (58.1094 iter/s, 1.70368s/100 iter), loss = 0.000932424
I0628 19:16:20.487433  7628 solver.cpp:371]     Train net output #0: loss = 0.000932919 (* 1 = 0.000932919 loss)
I0628 19:16:20.487496  7628 solver.cpp:675] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-06-28_18-56-45/initial/cifar10_jacintonet11v2_iter_64000.caffemodel
I0628 19:16:20.495379  7628 sgd_solver.cpp:288] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-06-28_18-56-45/initial/cifar10_jacintonet11v2_iter_64000.solverstate
I0628 19:16:20.505228  7628 solver.cpp:522] Iteration 64000, loss = 0.000714081
I0628 19:16:20.505247  7628 solver.cpp:545] Iteration 64000, Testing net (#0)
I0628 19:16:21.511070  7626 data_reader.cpp:262] Starting prefetch of epoch 64
I0628 19:16:21.531349  7628 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.9166
I0628 19:16:21.531363  7628 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.996
I0628 19:16:21.531368  7628 solver.cpp:630]     Test net output #2: loss = 0.300819 (* 1 = 0.300819 loss)
I0628 19:16:21.532887  7562 parallel.cpp:71] Root Solver performance on device 0: 55.01 * 32 = 1760 img/sec
I0628 19:16:21.532897  7562 parallel.cpp:76]      Solver performance on device 1: 55.01 * 32 = 1760 img/sec
I0628 19:16:21.532899  7562 parallel.cpp:79] Overall multi-GPU performance: 3520.43 img/sec
I0628 19:16:21.568742  7562 caffe.cpp:247] Optimization Done in 19m 28s
