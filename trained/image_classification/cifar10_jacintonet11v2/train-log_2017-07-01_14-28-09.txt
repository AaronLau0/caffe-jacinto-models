Logging output to training/cifar10_jacintonet11v2_2017-07-01_14-28-09/train-log_2017-07-01_14-28-09.txt
I0701 14:28:10.269484 30423 caffe.cpp:209] Using GPUs 0, 1, 2
I0701 14:28:10.269950 30423 caffe.cpp:214] GPU 0: GeForce GTX 1080
I0701 14:28:10.270277 30423 caffe.cpp:214] GPU 1: GeForce GTX 1080
I0701 14:28:10.270606 30423 caffe.cpp:214] GPU 2: GeForce GTX 1080
I0701 14:28:10.653224 30423 solver.cpp:48] Initializing solver from parameters: 
train_net: "training/cifar10_jacintonet11v2_2017-07-01_14-28-09/initial/train.prototxt"
test_net: "training/cifar10_jacintonet11v2_2017-07-01_14-28-09/initial/test.prototxt"
test_iter: 200
test_interval: 1000
base_lr: 0.1
display: 100
max_iter: 64000
lr_policy: "poly"
gamma: 0.1
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 10000
snapshot_prefix: "training/cifar10_jacintonet11v2_2017-07-01_14-28-09/initial/cifar10_jacintonet11v2"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
snapshot_after_train: true
test_initialization: true
iter_size: 1
type: "SGD"
I0701 14:28:10.653317 30423 solver.cpp:82] Creating training net from train_net file: training/cifar10_jacintonet11v2_2017-07-01_14-28-09/initial/train.prototxt
I0701 14:28:10.653775 30423 net.cpp:327] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top1
I0701 14:28:10.653781 30423 net.cpp:327] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top5
I0701 14:28:10.653939 30423 net.cpp:56] Initializing net from parameters: 
name: "jacintonet11v2_train"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: true
    crop_size: 32
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/cifar10_train_lmdb"
    batch_size: 21
    backend: LMDB
    threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a/bn"
  top: "conv1a/bn"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a/bn"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b/bn"
  top: "conv1b/bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b/bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2a/bn"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b/bn"
  top: "res2a_branch2b/bn"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b/bn"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2a/bn"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b/bn"
  top: "res3a_branch2b/bn"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b/bn"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2a/bn"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b/bn"
  top: "res4a_branch2b/bn"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b/bn"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2a/bn"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b/bn"
  top: "res5a_branch2b/bn"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b/bn"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc10"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc10"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
I0701 14:28:10.654023 30423 layer_factory.hpp:77] Creating layer data
I0701 14:28:10.654101 30423 net.cpp:98] Creating Layer data
I0701 14:28:10.654108 30423 net.cpp:413] data -> data
I0701 14:28:10.654124 30423 net.cpp:413] data -> label
I0701 14:28:10.718039 30452 db_lmdb.cpp:35] Opened lmdb ./data/cifar10_train_lmdb
I0701 14:28:10.743927 30423 data_layer.cpp:78] ReshapePrefetch 21, 3, 32, 32
I0701 14:28:10.744019 30423 data_layer.cpp:83] output data size: 21,3,32,32
I0701 14:28:10.746642 30423 net.cpp:148] Setting up data
I0701 14:28:10.746670 30423 net.cpp:155] Top shape: 21 3 32 32 (64512)
I0701 14:28:10.746676 30423 net.cpp:155] Top shape: 21 (21)
I0701 14:28:10.746680 30423 net.cpp:163] Memory required for data: 258132
I0701 14:28:10.746691 30423 layer_factory.hpp:77] Creating layer data/bias
I0701 14:28:10.746711 30423 net.cpp:98] Creating Layer data/bias
I0701 14:28:10.746718 30423 net.cpp:439] data/bias <- data
I0701 14:28:10.746731 30423 net.cpp:413] data/bias -> data/bias
I0701 14:28:10.748436 30423 net.cpp:148] Setting up data/bias
I0701 14:28:10.748456 30423 net.cpp:155] Top shape: 21 3 32 32 (64512)
I0701 14:28:10.748461 30423 net.cpp:163] Memory required for data: 516180
I0701 14:28:10.748476 30423 layer_factory.hpp:77] Creating layer conv1a
I0701 14:28:10.748492 30423 net.cpp:98] Creating Layer conv1a
I0701 14:28:10.748500 30423 net.cpp:439] conv1a <- data/bias
I0701 14:28:10.748510 30423 net.cpp:413] conv1a -> conv1a
I0701 14:28:10.749061 30454 blocking_queue.cpp:50] Waiting for data
I0701 14:28:10.750982 30423 net.cpp:148] Setting up conv1a
I0701 14:28:10.751003 30423 net.cpp:155] Top shape: 21 32 32 32 (688128)
I0701 14:28:10.751008 30423 net.cpp:163] Memory required for data: 3268692
I0701 14:28:10.751018 30423 layer_factory.hpp:77] Creating layer conv1a/bn
I0701 14:28:10.751030 30423 net.cpp:98] Creating Layer conv1a/bn
I0701 14:28:10.751037 30423 net.cpp:439] conv1a/bn <- conv1a
I0701 14:28:10.751044 30423 net.cpp:413] conv1a/bn -> conv1a/bn
I0701 14:28:10.752418 30423 net.cpp:148] Setting up conv1a/bn
I0701 14:28:10.752432 30423 net.cpp:155] Top shape: 21 32 32 32 (688128)
I0701 14:28:10.752437 30423 net.cpp:163] Memory required for data: 6021204
I0701 14:28:10.752450 30423 layer_factory.hpp:77] Creating layer conv1a/relu
I0701 14:28:10.752460 30423 net.cpp:98] Creating Layer conv1a/relu
I0701 14:28:10.752465 30423 net.cpp:439] conv1a/relu <- conv1a/bn
I0701 14:28:10.752470 30423 net.cpp:400] conv1a/relu -> conv1a/bn (in-place)
I0701 14:28:10.752491 30423 net.cpp:148] Setting up conv1a/relu
I0701 14:28:10.752498 30423 net.cpp:155] Top shape: 21 32 32 32 (688128)
I0701 14:28:10.752503 30423 net.cpp:163] Memory required for data: 8773716
I0701 14:28:10.752507 30423 layer_factory.hpp:77] Creating layer conv1b
I0701 14:28:10.752533 30423 net.cpp:98] Creating Layer conv1b
I0701 14:28:10.752539 30423 net.cpp:439] conv1b <- conv1a/bn
I0701 14:28:10.752545 30423 net.cpp:413] conv1b -> conv1b
I0701 14:28:10.753285 30423 net.cpp:148] Setting up conv1b
I0701 14:28:10.753298 30423 net.cpp:155] Top shape: 21 32 32 32 (688128)
I0701 14:28:10.753304 30423 net.cpp:163] Memory required for data: 11526228
I0701 14:28:10.753312 30423 layer_factory.hpp:77] Creating layer conv1b/bn
I0701 14:28:10.753320 30423 net.cpp:98] Creating Layer conv1b/bn
I0701 14:28:10.753325 30423 net.cpp:439] conv1b/bn <- conv1b
I0701 14:28:10.753331 30423 net.cpp:413] conv1b/bn -> conv1b/bn
I0701 14:28:10.754858 30423 net.cpp:148] Setting up conv1b/bn
I0701 14:28:10.754871 30423 net.cpp:155] Top shape: 21 32 32 32 (688128)
I0701 14:28:10.754876 30423 net.cpp:163] Memory required for data: 14278740
I0701 14:28:10.754889 30423 layer_factory.hpp:77] Creating layer conv1b/relu
I0701 14:28:10.754894 30423 net.cpp:98] Creating Layer conv1b/relu
I0701 14:28:10.754900 30423 net.cpp:439] conv1b/relu <- conv1b/bn
I0701 14:28:10.754905 30423 net.cpp:400] conv1b/relu -> conv1b/bn (in-place)
I0701 14:28:10.754914 30423 net.cpp:148] Setting up conv1b/relu
I0701 14:28:10.754922 30423 net.cpp:155] Top shape: 21 32 32 32 (688128)
I0701 14:28:10.754928 30423 net.cpp:163] Memory required for data: 17031252
I0701 14:28:10.754933 30423 layer_factory.hpp:77] Creating layer pool1
I0701 14:28:10.754943 30423 net.cpp:98] Creating Layer pool1
I0701 14:28:10.754948 30423 net.cpp:439] pool1 <- conv1b/bn
I0701 14:28:10.754954 30423 net.cpp:413] pool1 -> pool1
I0701 14:28:10.755040 30423 net.cpp:148] Setting up pool1
I0701 14:28:10.755050 30423 net.cpp:155] Top shape: 21 32 32 32 (688128)
I0701 14:28:10.755054 30423 net.cpp:163] Memory required for data: 19783764
I0701 14:28:10.755059 30423 layer_factory.hpp:77] Creating layer res2a_branch2a
I0701 14:28:10.755069 30423 net.cpp:98] Creating Layer res2a_branch2a
I0701 14:28:10.755076 30423 net.cpp:439] res2a_branch2a <- pool1
I0701 14:28:10.755082 30423 net.cpp:413] res2a_branch2a -> res2a_branch2a
I0701 14:28:10.756551 30423 net.cpp:148] Setting up res2a_branch2a
I0701 14:28:10.756564 30423 net.cpp:155] Top shape: 21 64 32 32 (1376256)
I0701 14:28:10.756568 30423 net.cpp:163] Memory required for data: 25288788
I0701 14:28:10.756578 30423 layer_factory.hpp:77] Creating layer res2a_branch2a/bn
I0701 14:28:10.756585 30423 net.cpp:98] Creating Layer res2a_branch2a/bn
I0701 14:28:10.756592 30423 net.cpp:439] res2a_branch2a/bn <- res2a_branch2a
I0701 14:28:10.756597 30423 net.cpp:413] res2a_branch2a/bn -> res2a_branch2a/bn
I0701 14:28:10.758311 30423 net.cpp:148] Setting up res2a_branch2a/bn
I0701 14:28:10.758327 30423 net.cpp:155] Top shape: 21 64 32 32 (1376256)
I0701 14:28:10.758332 30423 net.cpp:163] Memory required for data: 30793812
I0701 14:28:10.758347 30423 layer_factory.hpp:77] Creating layer res2a_branch2a/relu
I0701 14:28:10.758354 30423 net.cpp:98] Creating Layer res2a_branch2a/relu
I0701 14:28:10.758361 30423 net.cpp:439] res2a_branch2a/relu <- res2a_branch2a/bn
I0701 14:28:10.758368 30423 net.cpp:400] res2a_branch2a/relu -> res2a_branch2a/bn (in-place)
I0701 14:28:10.758376 30423 net.cpp:148] Setting up res2a_branch2a/relu
I0701 14:28:10.758391 30423 net.cpp:155] Top shape: 21 64 32 32 (1376256)
I0701 14:28:10.758397 30423 net.cpp:163] Memory required for data: 36298836
I0701 14:28:10.758402 30423 layer_factory.hpp:77] Creating layer res2a_branch2b
I0701 14:28:10.758412 30423 net.cpp:98] Creating Layer res2a_branch2b
I0701 14:28:10.758420 30423 net.cpp:439] res2a_branch2b <- res2a_branch2a/bn
I0701 14:28:10.758429 30423 net.cpp:413] res2a_branch2b -> res2a_branch2b
I0701 14:28:10.761548 30423 net.cpp:148] Setting up res2a_branch2b
I0701 14:28:10.761569 30423 net.cpp:155] Top shape: 21 64 32 32 (1376256)
I0701 14:28:10.761576 30423 net.cpp:163] Memory required for data: 41803860
I0701 14:28:10.761586 30423 layer_factory.hpp:77] Creating layer res2a_branch2b/bn
I0701 14:28:10.761596 30423 net.cpp:98] Creating Layer res2a_branch2b/bn
I0701 14:28:10.761603 30423 net.cpp:439] res2a_branch2b/bn <- res2a_branch2b
I0701 14:28:10.761626 30423 net.cpp:413] res2a_branch2b/bn -> res2a_branch2b/bn
I0701 14:28:10.763429 30423 net.cpp:148] Setting up res2a_branch2b/bn
I0701 14:28:10.763447 30423 net.cpp:155] Top shape: 21 64 32 32 (1376256)
I0701 14:28:10.763453 30423 net.cpp:163] Memory required for data: 47308884
I0701 14:28:10.763468 30423 layer_factory.hpp:77] Creating layer res2a_branch2b/relu
I0701 14:28:10.763475 30423 net.cpp:98] Creating Layer res2a_branch2b/relu
I0701 14:28:10.763481 30423 net.cpp:439] res2a_branch2b/relu <- res2a_branch2b/bn
I0701 14:28:10.763489 30423 net.cpp:400] res2a_branch2b/relu -> res2a_branch2b/bn (in-place)
I0701 14:28:10.763502 30423 net.cpp:148] Setting up res2a_branch2b/relu
I0701 14:28:10.763511 30423 net.cpp:155] Top shape: 21 64 32 32 (1376256)
I0701 14:28:10.763516 30423 net.cpp:163] Memory required for data: 52813908
I0701 14:28:10.763521 30423 layer_factory.hpp:77] Creating layer pool2
I0701 14:28:10.763530 30423 net.cpp:98] Creating Layer pool2
I0701 14:28:10.763536 30423 net.cpp:439] pool2 <- res2a_branch2b/bn
I0701 14:28:10.763542 30423 net.cpp:413] pool2 -> pool2
I0701 14:28:10.763641 30423 net.cpp:148] Setting up pool2
I0701 14:28:10.763653 30423 net.cpp:155] Top shape: 21 64 16 16 (344064)
I0701 14:28:10.763659 30423 net.cpp:163] Memory required for data: 54190164
I0701 14:28:10.763664 30423 layer_factory.hpp:77] Creating layer res3a_branch2a
I0701 14:28:10.763684 30423 net.cpp:98] Creating Layer res3a_branch2a
I0701 14:28:10.763694 30423 net.cpp:439] res3a_branch2a <- pool2
I0701 14:28:10.763701 30423 net.cpp:413] res3a_branch2a -> res3a_branch2a
I0701 14:28:10.770318 30423 net.cpp:148] Setting up res3a_branch2a
I0701 14:28:10.770340 30423 net.cpp:155] Top shape: 21 128 16 16 (688128)
I0701 14:28:10.770346 30423 net.cpp:163] Memory required for data: 56942676
I0701 14:28:10.770356 30423 layer_factory.hpp:77] Creating layer res3a_branch2a/bn
I0701 14:28:10.770367 30423 net.cpp:98] Creating Layer res3a_branch2a/bn
I0701 14:28:10.770375 30423 net.cpp:439] res3a_branch2a/bn <- res3a_branch2a
I0701 14:28:10.770382 30423 net.cpp:413] res3a_branch2a/bn -> res3a_branch2a/bn
I0701 14:28:10.772038 30423 net.cpp:148] Setting up res3a_branch2a/bn
I0701 14:28:10.772058 30423 net.cpp:155] Top shape: 21 128 16 16 (688128)
I0701 14:28:10.772063 30423 net.cpp:163] Memory required for data: 59695188
I0701 14:28:10.772094 30423 layer_factory.hpp:77] Creating layer res3a_branch2a/relu
I0701 14:28:10.772101 30423 net.cpp:98] Creating Layer res3a_branch2a/relu
I0701 14:28:10.772110 30423 net.cpp:439] res3a_branch2a/relu <- res3a_branch2a/bn
I0701 14:28:10.772116 30423 net.cpp:400] res3a_branch2a/relu -> res3a_branch2a/bn (in-place)
I0701 14:28:10.772128 30423 net.cpp:148] Setting up res3a_branch2a/relu
I0701 14:28:10.772137 30423 net.cpp:155] Top shape: 21 128 16 16 (688128)
I0701 14:28:10.772142 30423 net.cpp:163] Memory required for data: 62447700
I0701 14:28:10.772147 30423 layer_factory.hpp:77] Creating layer res3a_branch2b
I0701 14:28:10.772159 30423 net.cpp:98] Creating Layer res3a_branch2b
I0701 14:28:10.772166 30423 net.cpp:439] res3a_branch2b <- res3a_branch2a/bn
I0701 14:28:10.772173 30423 net.cpp:413] res3a_branch2b -> res3a_branch2b
I0701 14:28:10.774978 30423 net.cpp:148] Setting up res3a_branch2b
I0701 14:28:10.774996 30423 net.cpp:155] Top shape: 21 128 16 16 (688128)
I0701 14:28:10.775001 30423 net.cpp:163] Memory required for data: 65200212
I0701 14:28:10.775009 30423 layer_factory.hpp:77] Creating layer res3a_branch2b/bn
I0701 14:28:10.775019 30423 net.cpp:98] Creating Layer res3a_branch2b/bn
I0701 14:28:10.775025 30423 net.cpp:439] res3a_branch2b/bn <- res3a_branch2b
I0701 14:28:10.775035 30423 net.cpp:413] res3a_branch2b/bn -> res3a_branch2b/bn
I0701 14:28:10.776650 30423 net.cpp:148] Setting up res3a_branch2b/bn
I0701 14:28:10.776669 30423 net.cpp:155] Top shape: 21 128 16 16 (688128)
I0701 14:28:10.776859 30423 net.cpp:163] Memory required for data: 67952724
I0701 14:28:10.776926 30423 layer_factory.hpp:77] Creating layer res3a_branch2b/relu
I0701 14:28:10.776979 30423 net.cpp:98] Creating Layer res3a_branch2b/relu
I0701 14:28:10.777016 30423 net.cpp:439] res3a_branch2b/relu <- res3a_branch2b/bn
I0701 14:28:10.777036 30423 net.cpp:400] res3a_branch2b/relu -> res3a_branch2b/bn (in-place)
I0701 14:28:10.777055 30423 net.cpp:148] Setting up res3a_branch2b/relu
I0701 14:28:10.777073 30423 net.cpp:155] Top shape: 21 128 16 16 (688128)
I0701 14:28:10.777082 30423 net.cpp:163] Memory required for data: 70705236
I0701 14:28:10.777093 30423 layer_factory.hpp:77] Creating layer pool3
I0701 14:28:10.777109 30423 net.cpp:98] Creating Layer pool3
I0701 14:28:10.777122 30423 net.cpp:439] pool3 <- res3a_branch2b/bn
I0701 14:28:10.777134 30423 net.cpp:413] pool3 -> pool3
I0701 14:28:10.777289 30423 net.cpp:148] Setting up pool3
I0701 14:28:10.777309 30423 net.cpp:155] Top shape: 21 128 16 16 (688128)
I0701 14:28:10.777320 30423 net.cpp:163] Memory required for data: 73457748
I0701 14:28:10.777330 30423 layer_factory.hpp:77] Creating layer res4a_branch2a
I0701 14:28:10.777349 30423 net.cpp:98] Creating Layer res4a_branch2a
I0701 14:28:10.777359 30423 net.cpp:439] res4a_branch2a <- pool3
I0701 14:28:10.777367 30423 net.cpp:413] res4a_branch2a -> res4a_branch2a
I0701 14:28:10.785326 30423 net.cpp:148] Setting up res4a_branch2a
I0701 14:28:10.785338 30423 net.cpp:155] Top shape: 21 256 16 16 (1376256)
I0701 14:28:10.785341 30423 net.cpp:163] Memory required for data: 78962772
I0701 14:28:10.785346 30423 layer_factory.hpp:77] Creating layer res4a_branch2a/bn
I0701 14:28:10.785351 30423 net.cpp:98] Creating Layer res4a_branch2a/bn
I0701 14:28:10.785353 30423 net.cpp:439] res4a_branch2a/bn <- res4a_branch2a
I0701 14:28:10.785357 30423 net.cpp:413] res4a_branch2a/bn -> res4a_branch2a/bn
I0701 14:28:10.785964 30423 net.cpp:148] Setting up res4a_branch2a/bn
I0701 14:28:10.785970 30423 net.cpp:155] Top shape: 21 256 16 16 (1376256)
I0701 14:28:10.785972 30423 net.cpp:163] Memory required for data: 84467796
I0701 14:28:10.785977 30423 layer_factory.hpp:77] Creating layer res4a_branch2a/relu
I0701 14:28:10.785980 30423 net.cpp:98] Creating Layer res4a_branch2a/relu
I0701 14:28:10.785984 30423 net.cpp:439] res4a_branch2a/relu <- res4a_branch2a/bn
I0701 14:28:10.785985 30423 net.cpp:400] res4a_branch2a/relu -> res4a_branch2a/bn (in-place)
I0701 14:28:10.785989 30423 net.cpp:148] Setting up res4a_branch2a/relu
I0701 14:28:10.785991 30423 net.cpp:155] Top shape: 21 256 16 16 (1376256)
I0701 14:28:10.785993 30423 net.cpp:163] Memory required for data: 89972820
I0701 14:28:10.785995 30423 layer_factory.hpp:77] Creating layer res4a_branch2b
I0701 14:28:10.786000 30423 net.cpp:98] Creating Layer res4a_branch2b
I0701 14:28:10.786002 30423 net.cpp:439] res4a_branch2b <- res4a_branch2a/bn
I0701 14:28:10.786005 30423 net.cpp:413] res4a_branch2b -> res4a_branch2b
I0701 14:28:10.789189 30423 net.cpp:148] Setting up res4a_branch2b
I0701 14:28:10.789194 30423 net.cpp:155] Top shape: 21 256 16 16 (1376256)
I0701 14:28:10.789196 30423 net.cpp:163] Memory required for data: 95477844
I0701 14:28:10.789199 30423 layer_factory.hpp:77] Creating layer res4a_branch2b/bn
I0701 14:28:10.789203 30423 net.cpp:98] Creating Layer res4a_branch2b/bn
I0701 14:28:10.789206 30423 net.cpp:439] res4a_branch2b/bn <- res4a_branch2b
I0701 14:28:10.789208 30423 net.cpp:413] res4a_branch2b/bn -> res4a_branch2b/bn
I0701 14:28:10.789793 30423 net.cpp:148] Setting up res4a_branch2b/bn
I0701 14:28:10.789798 30423 net.cpp:155] Top shape: 21 256 16 16 (1376256)
I0701 14:28:10.789800 30423 net.cpp:163] Memory required for data: 100982868
I0701 14:28:10.789804 30423 layer_factory.hpp:77] Creating layer res4a_branch2b/relu
I0701 14:28:10.789808 30423 net.cpp:98] Creating Layer res4a_branch2b/relu
I0701 14:28:10.789809 30423 net.cpp:439] res4a_branch2b/relu <- res4a_branch2b/bn
I0701 14:28:10.789811 30423 net.cpp:400] res4a_branch2b/relu -> res4a_branch2b/bn (in-place)
I0701 14:28:10.789815 30423 net.cpp:148] Setting up res4a_branch2b/relu
I0701 14:28:10.789818 30423 net.cpp:155] Top shape: 21 256 16 16 (1376256)
I0701 14:28:10.789829 30423 net.cpp:163] Memory required for data: 106487892
I0701 14:28:10.789831 30423 layer_factory.hpp:77] Creating layer pool4
I0701 14:28:10.789835 30423 net.cpp:98] Creating Layer pool4
I0701 14:28:10.789839 30423 net.cpp:439] pool4 <- res4a_branch2b/bn
I0701 14:28:10.789841 30423 net.cpp:413] pool4 -> pool4
I0701 14:28:10.789876 30423 net.cpp:148] Setting up pool4
I0701 14:28:10.789880 30423 net.cpp:155] Top shape: 21 256 8 8 (344064)
I0701 14:28:10.789882 30423 net.cpp:163] Memory required for data: 107864148
I0701 14:28:10.789885 30423 layer_factory.hpp:77] Creating layer res5a_branch2a
I0701 14:28:10.789888 30423 net.cpp:98] Creating Layer res5a_branch2a
I0701 14:28:10.789891 30423 net.cpp:439] res5a_branch2a <- pool4
I0701 14:28:10.789892 30423 net.cpp:413] res5a_branch2a -> res5a_branch2a
I0701 14:28:10.814815 30423 net.cpp:148] Setting up res5a_branch2a
I0701 14:28:10.814836 30423 net.cpp:155] Top shape: 21 512 8 8 (688128)
I0701 14:28:10.814838 30423 net.cpp:163] Memory required for data: 110616660
I0701 14:28:10.814844 30423 layer_factory.hpp:77] Creating layer res5a_branch2a/bn
I0701 14:28:10.814851 30423 net.cpp:98] Creating Layer res5a_branch2a/bn
I0701 14:28:10.814854 30423 net.cpp:439] res5a_branch2a/bn <- res5a_branch2a
I0701 14:28:10.814859 30423 net.cpp:413] res5a_branch2a/bn -> res5a_branch2a/bn
I0701 14:28:10.815500 30423 net.cpp:148] Setting up res5a_branch2a/bn
I0701 14:28:10.815506 30423 net.cpp:155] Top shape: 21 512 8 8 (688128)
I0701 14:28:10.815508 30423 net.cpp:163] Memory required for data: 113369172
I0701 14:28:10.815515 30423 layer_factory.hpp:77] Creating layer res5a_branch2a/relu
I0701 14:28:10.815520 30423 net.cpp:98] Creating Layer res5a_branch2a/relu
I0701 14:28:10.815521 30423 net.cpp:439] res5a_branch2a/relu <- res5a_branch2a/bn
I0701 14:28:10.815523 30423 net.cpp:400] res5a_branch2a/relu -> res5a_branch2a/bn (in-place)
I0701 14:28:10.815527 30423 net.cpp:148] Setting up res5a_branch2a/relu
I0701 14:28:10.815531 30423 net.cpp:155] Top shape: 21 512 8 8 (688128)
I0701 14:28:10.815531 30423 net.cpp:163] Memory required for data: 116121684
I0701 14:28:10.815533 30423 layer_factory.hpp:77] Creating layer res5a_branch2b
I0701 14:28:10.815542 30423 net.cpp:98] Creating Layer res5a_branch2b
I0701 14:28:10.815546 30423 net.cpp:439] res5a_branch2b <- res5a_branch2a/bn
I0701 14:28:10.815549 30423 net.cpp:413] res5a_branch2b -> res5a_branch2b
I0701 14:28:10.828374 30423 net.cpp:148] Setting up res5a_branch2b
I0701 14:28:10.828384 30423 net.cpp:155] Top shape: 21 512 8 8 (688128)
I0701 14:28:10.828387 30423 net.cpp:163] Memory required for data: 118874196
I0701 14:28:10.828393 30423 layer_factory.hpp:77] Creating layer res5a_branch2b/bn
I0701 14:28:10.828397 30423 net.cpp:98] Creating Layer res5a_branch2b/bn
I0701 14:28:10.828400 30423 net.cpp:439] res5a_branch2b/bn <- res5a_branch2b
I0701 14:28:10.828403 30423 net.cpp:413] res5a_branch2b/bn -> res5a_branch2b/bn
I0701 14:28:10.829026 30423 net.cpp:148] Setting up res5a_branch2b/bn
I0701 14:28:10.829031 30423 net.cpp:155] Top shape: 21 512 8 8 (688128)
I0701 14:28:10.829035 30423 net.cpp:163] Memory required for data: 121626708
I0701 14:28:10.829040 30423 layer_factory.hpp:77] Creating layer res5a_branch2b/relu
I0701 14:28:10.829042 30423 net.cpp:98] Creating Layer res5a_branch2b/relu
I0701 14:28:10.829044 30423 net.cpp:439] res5a_branch2b/relu <- res5a_branch2b/bn
I0701 14:28:10.829046 30423 net.cpp:400] res5a_branch2b/relu -> res5a_branch2b/bn (in-place)
I0701 14:28:10.829049 30423 net.cpp:148] Setting up res5a_branch2b/relu
I0701 14:28:10.829052 30423 net.cpp:155] Top shape: 21 512 8 8 (688128)
I0701 14:28:10.829054 30423 net.cpp:163] Memory required for data: 124379220
I0701 14:28:10.829056 30423 layer_factory.hpp:77] Creating layer pool5
I0701 14:28:10.829061 30423 net.cpp:98] Creating Layer pool5
I0701 14:28:10.829063 30423 net.cpp:439] pool5 <- res5a_branch2b/bn
I0701 14:28:10.829066 30423 net.cpp:413] pool5 -> pool5
I0701 14:28:10.829092 30423 net.cpp:148] Setting up pool5
I0701 14:28:10.829097 30423 net.cpp:155] Top shape: 21 512 1 1 (10752)
I0701 14:28:10.829107 30423 net.cpp:163] Memory required for data: 124422228
I0701 14:28:10.829109 30423 layer_factory.hpp:77] Creating layer fc10
I0701 14:28:10.829113 30423 net.cpp:98] Creating Layer fc10
I0701 14:28:10.829115 30423 net.cpp:439] fc10 <- pool5
I0701 14:28:10.829118 30423 net.cpp:413] fc10 -> fc10
I0701 14:28:10.829340 30423 net.cpp:148] Setting up fc10
I0701 14:28:10.829345 30423 net.cpp:155] Top shape: 21 10 (210)
I0701 14:28:10.829347 30423 net.cpp:163] Memory required for data: 124423068
I0701 14:28:10.829350 30423 layer_factory.hpp:77] Creating layer loss
I0701 14:28:10.829354 30423 net.cpp:98] Creating Layer loss
I0701 14:28:10.829355 30423 net.cpp:439] loss <- fc10
I0701 14:28:10.829357 30423 net.cpp:439] loss <- label
I0701 14:28:10.829360 30423 net.cpp:413] loss -> loss
I0701 14:28:10.829367 30423 layer_factory.hpp:77] Creating layer loss
I0701 14:28:10.829479 30423 net.cpp:148] Setting up loss
I0701 14:28:10.829484 30423 net.cpp:155] Top shape: (1)
I0701 14:28:10.829486 30423 net.cpp:158]     with loss weight 1
I0701 14:28:10.829496 30423 net.cpp:163] Memory required for data: 124423072
I0701 14:28:10.829499 30423 net.cpp:224] loss needs backward computation.
I0701 14:28:10.829501 30423 net.cpp:224] fc10 needs backward computation.
I0701 14:28:10.829504 30423 net.cpp:224] pool5 needs backward computation.
I0701 14:28:10.829504 30423 net.cpp:224] res5a_branch2b/relu needs backward computation.
I0701 14:28:10.829506 30423 net.cpp:224] res5a_branch2b/bn needs backward computation.
I0701 14:28:10.829509 30423 net.cpp:224] res5a_branch2b needs backward computation.
I0701 14:28:10.829510 30423 net.cpp:224] res5a_branch2a/relu needs backward computation.
I0701 14:28:10.829512 30423 net.cpp:224] res5a_branch2a/bn needs backward computation.
I0701 14:28:10.829514 30423 net.cpp:224] res5a_branch2a needs backward computation.
I0701 14:28:10.829516 30423 net.cpp:224] pool4 needs backward computation.
I0701 14:28:10.829519 30423 net.cpp:224] res4a_branch2b/relu needs backward computation.
I0701 14:28:10.829519 30423 net.cpp:224] res4a_branch2b/bn needs backward computation.
I0701 14:28:10.829521 30423 net.cpp:224] res4a_branch2b needs backward computation.
I0701 14:28:10.829524 30423 net.cpp:224] res4a_branch2a/relu needs backward computation.
I0701 14:28:10.829527 30423 net.cpp:224] res4a_branch2a/bn needs backward computation.
I0701 14:28:10.829530 30423 net.cpp:224] res4a_branch2a needs backward computation.
I0701 14:28:10.829532 30423 net.cpp:224] pool3 needs backward computation.
I0701 14:28:10.829535 30423 net.cpp:224] res3a_branch2b/relu needs backward computation.
I0701 14:28:10.829536 30423 net.cpp:224] res3a_branch2b/bn needs backward computation.
I0701 14:28:10.829538 30423 net.cpp:224] res3a_branch2b needs backward computation.
I0701 14:28:10.829541 30423 net.cpp:224] res3a_branch2a/relu needs backward computation.
I0701 14:28:10.829543 30423 net.cpp:224] res3a_branch2a/bn needs backward computation.
I0701 14:28:10.829546 30423 net.cpp:224] res3a_branch2a needs backward computation.
I0701 14:28:10.829548 30423 net.cpp:224] pool2 needs backward computation.
I0701 14:28:10.829551 30423 net.cpp:224] res2a_branch2b/relu needs backward computation.
I0701 14:28:10.829553 30423 net.cpp:224] res2a_branch2b/bn needs backward computation.
I0701 14:28:10.829556 30423 net.cpp:224] res2a_branch2b needs backward computation.
I0701 14:28:10.829560 30423 net.cpp:224] res2a_branch2a/relu needs backward computation.
I0701 14:28:10.829561 30423 net.cpp:224] res2a_branch2a/bn needs backward computation.
I0701 14:28:10.829563 30423 net.cpp:224] res2a_branch2a needs backward computation.
I0701 14:28:10.829566 30423 net.cpp:224] pool1 needs backward computation.
I0701 14:28:10.829568 30423 net.cpp:224] conv1b/relu needs backward computation.
I0701 14:28:10.829571 30423 net.cpp:224] conv1b/bn needs backward computation.
I0701 14:28:10.829573 30423 net.cpp:224] conv1b needs backward computation.
I0701 14:28:10.829576 30423 net.cpp:224] conv1a/relu needs backward computation.
I0701 14:28:10.829577 30423 net.cpp:224] conv1a/bn needs backward computation.
I0701 14:28:10.829584 30423 net.cpp:224] conv1a needs backward computation.
I0701 14:28:10.829587 30423 net.cpp:226] data/bias does not need backward computation.
I0701 14:28:10.829591 30423 net.cpp:226] data does not need backward computation.
I0701 14:28:10.829592 30423 net.cpp:268] This network produces output loss
I0701 14:28:10.829610 30423 net.cpp:288] Network initialization done.
I0701 14:28:10.830044 30423 solver.cpp:182] Creating test net (#0) specified by test_net file: training/cifar10_jacintonet11v2_2017-07-01_14-28-09/initial/test.prototxt
I0701 14:28:10.830230 30423 net.cpp:56] Initializing net from parameters: 
name: "jacintonet11v2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: false
    crop_size: 32
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/cifar10_test_lmdb"
    batch_size: 50
    backend: LMDB
    threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a/bn"
  top: "conv1a/bn"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a/bn"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b/bn"
  top: "conv1b/bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b/bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2a/bn"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b/bn"
  top: "res2a_branch2b/bn"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b/bn"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2a/bn"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b/bn"
  top: "res3a_branch2b/bn"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b/bn"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2a/bn"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b/bn"
  top: "res4a_branch2b/bn"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b/bn"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2a/bn"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b/bn"
  top: "res5a_branch2b/bn"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b/bn"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc10"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc10"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "fc10"
  bottom: "label"
  top: "accuracy/top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "fc10"
  bottom: "label"
  top: "accuracy/top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0701 14:28:10.830312 30423 layer_factory.hpp:77] Creating layer data
I0701 14:28:10.830366 30423 net.cpp:98] Creating Layer data
I0701 14:28:10.830371 30423 net.cpp:413] data -> data
I0701 14:28:10.830376 30423 net.cpp:413] data -> label
I0701 14:28:10.836664 30455 db_lmdb.cpp:35] Opened lmdb ./data/cifar10_test_lmdb
I0701 14:28:10.840301 30423 data_layer.cpp:78] ReshapePrefetch 50, 3, 32, 32
I0701 14:28:10.840373 30423 data_layer.cpp:83] output data size: 50,3,32,32
I0701 14:28:10.842820 30423 net.cpp:148] Setting up data
I0701 14:28:10.842833 30423 net.cpp:155] Top shape: 50 3 32 32 (153600)
I0701 14:28:10.842839 30423 net.cpp:155] Top shape: 50 (50)
I0701 14:28:10.842842 30423 net.cpp:163] Memory required for data: 614600
I0701 14:28:10.842849 30423 layer_factory.hpp:77] Creating layer label_data_1_split
I0701 14:28:10.842859 30423 net.cpp:98] Creating Layer label_data_1_split
I0701 14:28:10.842864 30423 net.cpp:439] label_data_1_split <- label
I0701 14:28:10.842869 30423 net.cpp:413] label_data_1_split -> label_data_1_split_0
I0701 14:28:10.842877 30423 net.cpp:413] label_data_1_split -> label_data_1_split_1
I0701 14:28:10.842882 30423 net.cpp:413] label_data_1_split -> label_data_1_split_2
I0701 14:28:10.842998 30423 net.cpp:148] Setting up label_data_1_split
I0701 14:28:10.843008 30423 net.cpp:155] Top shape: 50 (50)
I0701 14:28:10.843014 30423 net.cpp:155] Top shape: 50 (50)
I0701 14:28:10.843017 30423 net.cpp:155] Top shape: 50 (50)
I0701 14:28:10.843021 30423 net.cpp:163] Memory required for data: 615200
I0701 14:28:10.843026 30423 layer_factory.hpp:77] Creating layer data/bias
I0701 14:28:10.843034 30423 net.cpp:98] Creating Layer data/bias
I0701 14:28:10.843039 30423 net.cpp:439] data/bias <- data
I0701 14:28:10.843044 30423 net.cpp:413] data/bias -> data/bias
I0701 14:28:10.843149 30423 net.cpp:148] Setting up data/bias
I0701 14:28:10.843155 30423 net.cpp:155] Top shape: 50 3 32 32 (153600)
I0701 14:28:10.843159 30423 net.cpp:163] Memory required for data: 1229600
I0701 14:28:10.843166 30423 layer_factory.hpp:77] Creating layer conv1a
I0701 14:28:10.843174 30423 net.cpp:98] Creating Layer conv1a
I0701 14:28:10.843178 30423 net.cpp:439] conv1a <- data/bias
I0701 14:28:10.843183 30423 net.cpp:413] conv1a -> conv1a
I0701 14:28:10.843539 30423 net.cpp:148] Setting up conv1a
I0701 14:28:10.843547 30423 net.cpp:155] Top shape: 50 32 32 32 (1638400)
I0701 14:28:10.843551 30423 net.cpp:163] Memory required for data: 7783200
I0701 14:28:10.843559 30423 layer_factory.hpp:77] Creating layer conv1a/bn
I0701 14:28:10.843565 30423 net.cpp:98] Creating Layer conv1a/bn
I0701 14:28:10.843569 30423 net.cpp:439] conv1a/bn <- conv1a
I0701 14:28:10.843575 30423 net.cpp:413] conv1a/bn -> conv1a/bn
I0701 14:28:10.844449 30423 net.cpp:148] Setting up conv1a/bn
I0701 14:28:10.844455 30423 net.cpp:155] Top shape: 50 32 32 32 (1638400)
I0701 14:28:10.844458 30423 net.cpp:163] Memory required for data: 14336800
I0701 14:28:10.844467 30423 layer_factory.hpp:77] Creating layer conv1a/relu
I0701 14:28:10.844473 30423 net.cpp:98] Creating Layer conv1a/relu
I0701 14:28:10.844477 30423 net.cpp:439] conv1a/relu <- conv1a/bn
I0701 14:28:10.844491 30423 net.cpp:400] conv1a/relu -> conv1a/bn (in-place)
I0701 14:28:10.844497 30423 net.cpp:148] Setting up conv1a/relu
I0701 14:28:10.844502 30423 net.cpp:155] Top shape: 50 32 32 32 (1638400)
I0701 14:28:10.844506 30423 net.cpp:163] Memory required for data: 20890400
I0701 14:28:10.844509 30423 layer_factory.hpp:77] Creating layer conv1b
I0701 14:28:10.844521 30423 net.cpp:98] Creating Layer conv1b
I0701 14:28:10.844527 30423 net.cpp:439] conv1b <- conv1a/bn
I0701 14:28:10.844534 30423 net.cpp:413] conv1b -> conv1b
I0701 14:28:10.844871 30423 net.cpp:148] Setting up conv1b
I0701 14:28:10.844877 30423 net.cpp:155] Top shape: 50 32 32 32 (1638400)
I0701 14:28:10.844882 30423 net.cpp:163] Memory required for data: 27444000
I0701 14:28:10.844888 30423 layer_factory.hpp:77] Creating layer conv1b/bn
I0701 14:28:10.844895 30423 net.cpp:98] Creating Layer conv1b/bn
I0701 14:28:10.844898 30423 net.cpp:439] conv1b/bn <- conv1b
I0701 14:28:10.844904 30423 net.cpp:413] conv1b/bn -> conv1b/bn
I0701 14:28:10.845692 30423 net.cpp:148] Setting up conv1b/bn
I0701 14:28:10.845700 30423 net.cpp:155] Top shape: 50 32 32 32 (1638400)
I0701 14:28:10.845703 30423 net.cpp:163] Memory required for data: 33997600
I0701 14:28:10.845711 30423 layer_factory.hpp:77] Creating layer conv1b/relu
I0701 14:28:10.845716 30423 net.cpp:98] Creating Layer conv1b/relu
I0701 14:28:10.845721 30423 net.cpp:439] conv1b/relu <- conv1b/bn
I0701 14:28:10.845726 30423 net.cpp:400] conv1b/relu -> conv1b/bn (in-place)
I0701 14:28:10.845731 30423 net.cpp:148] Setting up conv1b/relu
I0701 14:28:10.845736 30423 net.cpp:155] Top shape: 50 32 32 32 (1638400)
I0701 14:28:10.845739 30423 net.cpp:163] Memory required for data: 40551200
I0701 14:28:10.845742 30423 layer_factory.hpp:77] Creating layer pool1
I0701 14:28:10.845748 30423 net.cpp:98] Creating Layer pool1
I0701 14:28:10.845752 30423 net.cpp:439] pool1 <- conv1b/bn
I0701 14:28:10.845755 30423 net.cpp:413] pool1 -> pool1
I0701 14:28:10.845794 30423 net.cpp:148] Setting up pool1
I0701 14:28:10.845799 30423 net.cpp:155] Top shape: 50 32 32 32 (1638400)
I0701 14:28:10.845803 30423 net.cpp:163] Memory required for data: 47104800
I0701 14:28:10.845806 30423 layer_factory.hpp:77] Creating layer res2a_branch2a
I0701 14:28:10.845814 30423 net.cpp:98] Creating Layer res2a_branch2a
I0701 14:28:10.845818 30423 net.cpp:439] res2a_branch2a <- pool1
I0701 14:28:10.845824 30423 net.cpp:413] res2a_branch2a -> res2a_branch2a
I0701 14:28:10.846491 30423 net.cpp:148] Setting up res2a_branch2a
I0701 14:28:10.846498 30423 net.cpp:155] Top shape: 50 64 32 32 (3276800)
I0701 14:28:10.846503 30423 net.cpp:163] Memory required for data: 60212000
I0701 14:28:10.846509 30423 layer_factory.hpp:77] Creating layer res2a_branch2a/bn
I0701 14:28:10.846514 30423 net.cpp:98] Creating Layer res2a_branch2a/bn
I0701 14:28:10.846518 30423 net.cpp:439] res2a_branch2a/bn <- res2a_branch2a
I0701 14:28:10.846524 30423 net.cpp:413] res2a_branch2a/bn -> res2a_branch2a/bn
I0701 14:28:10.847208 30423 net.cpp:148] Setting up res2a_branch2a/bn
I0701 14:28:10.847214 30423 net.cpp:155] Top shape: 50 64 32 32 (3276800)
I0701 14:28:10.847218 30423 net.cpp:163] Memory required for data: 73319200
I0701 14:28:10.847226 30423 layer_factory.hpp:77] Creating layer res2a_branch2a/relu
I0701 14:28:10.847230 30423 net.cpp:98] Creating Layer res2a_branch2a/relu
I0701 14:28:10.847235 30423 net.cpp:439] res2a_branch2a/relu <- res2a_branch2a/bn
I0701 14:28:10.847239 30423 net.cpp:400] res2a_branch2a/relu -> res2a_branch2a/bn (in-place)
I0701 14:28:10.847245 30423 net.cpp:148] Setting up res2a_branch2a/relu
I0701 14:28:10.847249 30423 net.cpp:155] Top shape: 50 64 32 32 (3276800)
I0701 14:28:10.847254 30423 net.cpp:163] Memory required for data: 86426400
I0701 14:28:10.847256 30423 layer_factory.hpp:77] Creating layer res2a_branch2b
I0701 14:28:10.847262 30423 net.cpp:98] Creating Layer res2a_branch2b
I0701 14:28:10.847266 30423 net.cpp:439] res2a_branch2b <- res2a_branch2a/bn
I0701 14:28:10.847271 30423 net.cpp:413] res2a_branch2b -> res2a_branch2b
I0701 14:28:10.847743 30423 net.cpp:148] Setting up res2a_branch2b
I0701 14:28:10.847749 30423 net.cpp:155] Top shape: 50 64 32 32 (3276800)
I0701 14:28:10.847754 30423 net.cpp:163] Memory required for data: 99533600
I0701 14:28:10.847759 30423 layer_factory.hpp:77] Creating layer res2a_branch2b/bn
I0701 14:28:10.847764 30423 net.cpp:98] Creating Layer res2a_branch2b/bn
I0701 14:28:10.847769 30423 net.cpp:439] res2a_branch2b/bn <- res2a_branch2b
I0701 14:28:10.847774 30423 net.cpp:413] res2a_branch2b/bn -> res2a_branch2b/bn
I0701 14:28:10.848454 30423 net.cpp:148] Setting up res2a_branch2b/bn
I0701 14:28:10.848460 30423 net.cpp:155] Top shape: 50 64 32 32 (3276800)
I0701 14:28:10.848464 30423 net.cpp:163] Memory required for data: 112640800
I0701 14:28:10.848472 30423 layer_factory.hpp:77] Creating layer res2a_branch2b/relu
I0701 14:28:10.848476 30423 net.cpp:98] Creating Layer res2a_branch2b/relu
I0701 14:28:10.848480 30423 net.cpp:439] res2a_branch2b/relu <- res2a_branch2b/bn
I0701 14:28:10.848485 30423 net.cpp:400] res2a_branch2b/relu -> res2a_branch2b/bn (in-place)
I0701 14:28:10.848490 30423 net.cpp:148] Setting up res2a_branch2b/relu
I0701 14:28:10.848495 30423 net.cpp:155] Top shape: 50 64 32 32 (3276800)
I0701 14:28:10.848500 30423 net.cpp:163] Memory required for data: 125748000
I0701 14:28:10.848502 30423 layer_factory.hpp:77] Creating layer pool2
I0701 14:28:10.848508 30423 net.cpp:98] Creating Layer pool2
I0701 14:28:10.848511 30423 net.cpp:439] pool2 <- res2a_branch2b/bn
I0701 14:28:10.848516 30423 net.cpp:413] pool2 -> pool2
I0701 14:28:10.848556 30423 net.cpp:148] Setting up pool2
I0701 14:28:10.848562 30423 net.cpp:155] Top shape: 50 64 16 16 (819200)
I0701 14:28:10.848565 30423 net.cpp:163] Memory required for data: 129024800
I0701 14:28:10.848569 30423 layer_factory.hpp:77] Creating layer res3a_branch2a
I0701 14:28:10.848575 30423 net.cpp:98] Creating Layer res3a_branch2a
I0701 14:28:10.848579 30423 net.cpp:439] res3a_branch2a <- pool2
I0701 14:28:10.848584 30423 net.cpp:413] res3a_branch2a -> res3a_branch2a
I0701 14:28:10.851197 30423 net.cpp:148] Setting up res3a_branch2a
I0701 14:28:10.851207 30423 net.cpp:155] Top shape: 50 128 16 16 (1638400)
I0701 14:28:10.851210 30423 net.cpp:163] Memory required for data: 135578400
I0701 14:28:10.851217 30423 layer_factory.hpp:77] Creating layer res3a_branch2a/bn
I0701 14:28:10.851222 30423 net.cpp:98] Creating Layer res3a_branch2a/bn
I0701 14:28:10.851227 30423 net.cpp:439] res3a_branch2a/bn <- res3a_branch2a
I0701 14:28:10.851233 30423 net.cpp:413] res3a_branch2a/bn -> res3a_branch2a/bn
I0701 14:28:10.851836 30423 net.cpp:148] Setting up res3a_branch2a/bn
I0701 14:28:10.851843 30423 net.cpp:155] Top shape: 50 128 16 16 (1638400)
I0701 14:28:10.851847 30423 net.cpp:163] Memory required for data: 142132000
I0701 14:28:10.851856 30423 layer_factory.hpp:77] Creating layer res3a_branch2a/relu
I0701 14:28:10.851862 30423 net.cpp:98] Creating Layer res3a_branch2a/relu
I0701 14:28:10.851866 30423 net.cpp:439] res3a_branch2a/relu <- res3a_branch2a/bn
I0701 14:28:10.851871 30423 net.cpp:400] res3a_branch2a/relu -> res3a_branch2a/bn (in-place)
I0701 14:28:10.851877 30423 net.cpp:148] Setting up res3a_branch2a/relu
I0701 14:28:10.851881 30423 net.cpp:155] Top shape: 50 128 16 16 (1638400)
I0701 14:28:10.851886 30423 net.cpp:163] Memory required for data: 148685600
I0701 14:28:10.851888 30423 layer_factory.hpp:77] Creating layer res3a_branch2b
I0701 14:28:10.851894 30423 net.cpp:98] Creating Layer res3a_branch2b
I0701 14:28:10.851898 30423 net.cpp:439] res3a_branch2b <- res3a_branch2a/bn
I0701 14:28:10.851903 30423 net.cpp:413] res3a_branch2b -> res3a_branch2b
I0701 14:28:10.852916 30423 net.cpp:148] Setting up res3a_branch2b
I0701 14:28:10.852921 30423 net.cpp:155] Top shape: 50 128 16 16 (1638400)
I0701 14:28:10.852926 30423 net.cpp:163] Memory required for data: 155239200
I0701 14:28:10.852931 30423 layer_factory.hpp:77] Creating layer res3a_branch2b/bn
I0701 14:28:10.852936 30423 net.cpp:98] Creating Layer res3a_branch2b/bn
I0701 14:28:10.852941 30423 net.cpp:439] res3a_branch2b/bn <- res3a_branch2b
I0701 14:28:10.852952 30423 net.cpp:413] res3a_branch2b/bn -> res3a_branch2b/bn
I0701 14:28:10.853560 30423 net.cpp:148] Setting up res3a_branch2b/bn
I0701 14:28:10.853566 30423 net.cpp:155] Top shape: 50 128 16 16 (1638400)
I0701 14:28:10.853570 30423 net.cpp:163] Memory required for data: 161792800
I0701 14:28:10.853579 30423 layer_factory.hpp:77] Creating layer res3a_branch2b/relu
I0701 14:28:10.853582 30423 net.cpp:98] Creating Layer res3a_branch2b/relu
I0701 14:28:10.853587 30423 net.cpp:439] res3a_branch2b/relu <- res3a_branch2b/bn
I0701 14:28:10.853591 30423 net.cpp:400] res3a_branch2b/relu -> res3a_branch2b/bn (in-place)
I0701 14:28:10.853597 30423 net.cpp:148] Setting up res3a_branch2b/relu
I0701 14:28:10.853601 30423 net.cpp:155] Top shape: 50 128 16 16 (1638400)
I0701 14:28:10.853605 30423 net.cpp:163] Memory required for data: 168346400
I0701 14:28:10.853608 30423 layer_factory.hpp:77] Creating layer pool3
I0701 14:28:10.853613 30423 net.cpp:98] Creating Layer pool3
I0701 14:28:10.853617 30423 net.cpp:439] pool3 <- res3a_branch2b/bn
I0701 14:28:10.853621 30423 net.cpp:413] pool3 -> pool3
I0701 14:28:10.853662 30423 net.cpp:148] Setting up pool3
I0701 14:28:10.853667 30423 net.cpp:155] Top shape: 50 128 16 16 (1638400)
I0701 14:28:10.853669 30423 net.cpp:163] Memory required for data: 174900000
I0701 14:28:10.853673 30423 layer_factory.hpp:77] Creating layer res4a_branch2a
I0701 14:28:10.853682 30423 net.cpp:98] Creating Layer res4a_branch2a
I0701 14:28:10.853684 30423 net.cpp:439] res4a_branch2a <- pool3
I0701 14:28:10.853689 30423 net.cpp:413] res4a_branch2a -> res4a_branch2a
I0701 14:28:10.859738 30423 net.cpp:148] Setting up res4a_branch2a
I0701 14:28:10.859745 30423 net.cpp:155] Top shape: 50 256 16 16 (3276800)
I0701 14:28:10.859748 30423 net.cpp:163] Memory required for data: 188007200
I0701 14:28:10.859755 30423 layer_factory.hpp:77] Creating layer res4a_branch2a/bn
I0701 14:28:10.859760 30423 net.cpp:98] Creating Layer res4a_branch2a/bn
I0701 14:28:10.859764 30423 net.cpp:439] res4a_branch2a/bn <- res4a_branch2a
I0701 14:28:10.859769 30423 net.cpp:413] res4a_branch2a/bn -> res4a_branch2a/bn
I0701 14:28:10.860378 30423 net.cpp:148] Setting up res4a_branch2a/bn
I0701 14:28:10.860383 30423 net.cpp:155] Top shape: 50 256 16 16 (3276800)
I0701 14:28:10.860388 30423 net.cpp:163] Memory required for data: 201114400
I0701 14:28:10.860396 30423 layer_factory.hpp:77] Creating layer res4a_branch2a/relu
I0701 14:28:10.860400 30423 net.cpp:98] Creating Layer res4a_branch2a/relu
I0701 14:28:10.860404 30423 net.cpp:439] res4a_branch2a/relu <- res4a_branch2a/bn
I0701 14:28:10.860409 30423 net.cpp:400] res4a_branch2a/relu -> res4a_branch2a/bn (in-place)
I0701 14:28:10.860414 30423 net.cpp:148] Setting up res4a_branch2a/relu
I0701 14:28:10.860419 30423 net.cpp:155] Top shape: 50 256 16 16 (3276800)
I0701 14:28:10.860422 30423 net.cpp:163] Memory required for data: 214221600
I0701 14:28:10.860426 30423 layer_factory.hpp:77] Creating layer res4a_branch2b
I0701 14:28:10.860432 30423 net.cpp:98] Creating Layer res4a_branch2b
I0701 14:28:10.860436 30423 net.cpp:439] res4a_branch2b <- res4a_branch2a/bn
I0701 14:28:10.860441 30423 net.cpp:413] res4a_branch2b -> res4a_branch2b
I0701 14:28:10.863603 30423 net.cpp:148] Setting up res4a_branch2b
I0701 14:28:10.863610 30423 net.cpp:155] Top shape: 50 256 16 16 (3276800)
I0701 14:28:10.863615 30423 net.cpp:163] Memory required for data: 227328800
I0701 14:28:10.863620 30423 layer_factory.hpp:77] Creating layer res4a_branch2b/bn
I0701 14:28:10.863626 30423 net.cpp:98] Creating Layer res4a_branch2b/bn
I0701 14:28:10.863629 30423 net.cpp:439] res4a_branch2b/bn <- res4a_branch2b
I0701 14:28:10.863636 30423 net.cpp:413] res4a_branch2b/bn -> res4a_branch2b/bn
I0701 14:28:10.864248 30423 net.cpp:148] Setting up res4a_branch2b/bn
I0701 14:28:10.864254 30423 net.cpp:155] Top shape: 50 256 16 16 (3276800)
I0701 14:28:10.864258 30423 net.cpp:163] Memory required for data: 240436000
I0701 14:28:10.864265 30423 layer_factory.hpp:77] Creating layer res4a_branch2b/relu
I0701 14:28:10.864275 30423 net.cpp:98] Creating Layer res4a_branch2b/relu
I0701 14:28:10.864279 30423 net.cpp:439] res4a_branch2b/relu <- res4a_branch2b/bn
I0701 14:28:10.864284 30423 net.cpp:400] res4a_branch2b/relu -> res4a_branch2b/bn (in-place)
I0701 14:28:10.864290 30423 net.cpp:148] Setting up res4a_branch2b/relu
I0701 14:28:10.864295 30423 net.cpp:155] Top shape: 50 256 16 16 (3276800)
I0701 14:28:10.864298 30423 net.cpp:163] Memory required for data: 253543200
I0701 14:28:10.864302 30423 layer_factory.hpp:77] Creating layer pool4
I0701 14:28:10.864307 30423 net.cpp:98] Creating Layer pool4
I0701 14:28:10.864310 30423 net.cpp:439] pool4 <- res4a_branch2b/bn
I0701 14:28:10.864315 30423 net.cpp:413] pool4 -> pool4
I0701 14:28:10.864354 30423 net.cpp:148] Setting up pool4
I0701 14:28:10.864359 30423 net.cpp:155] Top shape: 50 256 8 8 (819200)
I0701 14:28:10.864363 30423 net.cpp:163] Memory required for data: 256820000
I0701 14:28:10.864367 30423 layer_factory.hpp:77] Creating layer res5a_branch2a
I0701 14:28:10.864373 30423 net.cpp:98] Creating Layer res5a_branch2a
I0701 14:28:10.864377 30423 net.cpp:439] res5a_branch2a <- pool4
I0701 14:28:10.864382 30423 net.cpp:413] res5a_branch2a -> res5a_branch2a
I0701 14:28:10.889181 30423 net.cpp:148] Setting up res5a_branch2a
I0701 14:28:10.889204 30423 net.cpp:155] Top shape: 50 512 8 8 (1638400)
I0701 14:28:10.889207 30423 net.cpp:163] Memory required for data: 263373600
I0701 14:28:10.889215 30423 layer_factory.hpp:77] Creating layer res5a_branch2a/bn
I0701 14:28:10.889226 30423 net.cpp:98] Creating Layer res5a_branch2a/bn
I0701 14:28:10.889230 30423 net.cpp:439] res5a_branch2a/bn <- res5a_branch2a
I0701 14:28:10.889237 30423 net.cpp:413] res5a_branch2a/bn -> res5a_branch2a/bn
I0701 14:28:10.889909 30423 net.cpp:148] Setting up res5a_branch2a/bn
I0701 14:28:10.889917 30423 net.cpp:155] Top shape: 50 512 8 8 (1638400)
I0701 14:28:10.889922 30423 net.cpp:163] Memory required for data: 269927200
I0701 14:28:10.889931 30423 layer_factory.hpp:77] Creating layer res5a_branch2a/relu
I0701 14:28:10.889936 30423 net.cpp:98] Creating Layer res5a_branch2a/relu
I0701 14:28:10.889940 30423 net.cpp:439] res5a_branch2a/relu <- res5a_branch2a/bn
I0701 14:28:10.889945 30423 net.cpp:400] res5a_branch2a/relu -> res5a_branch2a/bn (in-place)
I0701 14:28:10.889951 30423 net.cpp:148] Setting up res5a_branch2a/relu
I0701 14:28:10.889956 30423 net.cpp:155] Top shape: 50 512 8 8 (1638400)
I0701 14:28:10.889960 30423 net.cpp:163] Memory required for data: 276480800
I0701 14:28:10.889963 30423 layer_factory.hpp:77] Creating layer res5a_branch2b
I0701 14:28:10.889971 30423 net.cpp:98] Creating Layer res5a_branch2b
I0701 14:28:10.889974 30423 net.cpp:439] res5a_branch2b <- res5a_branch2a/bn
I0701 14:28:10.889979 30423 net.cpp:413] res5a_branch2b -> res5a_branch2b
I0701 14:28:10.902959 30423 net.cpp:148] Setting up res5a_branch2b
I0701 14:28:10.902990 30423 net.cpp:155] Top shape: 50 512 8 8 (1638400)
I0701 14:28:10.902994 30423 net.cpp:163] Memory required for data: 283034400
I0701 14:28:10.903010 30423 layer_factory.hpp:77] Creating layer res5a_branch2b/bn
I0701 14:28:10.903025 30423 net.cpp:98] Creating Layer res5a_branch2b/bn
I0701 14:28:10.903031 30423 net.cpp:439] res5a_branch2b/bn <- res5a_branch2b
I0701 14:28:10.903038 30423 net.cpp:413] res5a_branch2b/bn -> res5a_branch2b/bn
I0701 14:28:10.903734 30423 net.cpp:148] Setting up res5a_branch2b/bn
I0701 14:28:10.903743 30423 net.cpp:155] Top shape: 50 512 8 8 (1638400)
I0701 14:28:10.903745 30423 net.cpp:163] Memory required for data: 289588000
I0701 14:28:10.903754 30423 layer_factory.hpp:77] Creating layer res5a_branch2b/relu
I0701 14:28:10.903759 30423 net.cpp:98] Creating Layer res5a_branch2b/relu
I0701 14:28:10.903762 30423 net.cpp:439] res5a_branch2b/relu <- res5a_branch2b/bn
I0701 14:28:10.903766 30423 net.cpp:400] res5a_branch2b/relu -> res5a_branch2b/bn (in-place)
I0701 14:28:10.903771 30423 net.cpp:148] Setting up res5a_branch2b/relu
I0701 14:28:10.903774 30423 net.cpp:155] Top shape: 50 512 8 8 (1638400)
I0701 14:28:10.903775 30423 net.cpp:163] Memory required for data: 296141600
I0701 14:28:10.903789 30423 layer_factory.hpp:77] Creating layer pool5
I0701 14:28:10.903795 30423 net.cpp:98] Creating Layer pool5
I0701 14:28:10.903796 30423 net.cpp:439] pool5 <- res5a_branch2b/bn
I0701 14:28:10.903800 30423 net.cpp:413] pool5 -> pool5
I0701 14:28:10.903825 30423 net.cpp:148] Setting up pool5
I0701 14:28:10.903828 30423 net.cpp:155] Top shape: 50 512 1 1 (25600)
I0701 14:28:10.903829 30423 net.cpp:163] Memory required for data: 296244000
I0701 14:28:10.903831 30423 layer_factory.hpp:77] Creating layer fc10
I0701 14:28:10.903838 30423 net.cpp:98] Creating Layer fc10
I0701 14:28:10.903841 30423 net.cpp:439] fc10 <- pool5
I0701 14:28:10.903843 30423 net.cpp:413] fc10 -> fc10
I0701 14:28:10.904079 30423 net.cpp:148] Setting up fc10
I0701 14:28:10.904084 30423 net.cpp:155] Top shape: 50 10 (500)
I0701 14:28:10.904088 30423 net.cpp:163] Memory required for data: 296246000
I0701 14:28:10.904090 30423 layer_factory.hpp:77] Creating layer fc10_fc10_0_split
I0701 14:28:10.904094 30423 net.cpp:98] Creating Layer fc10_fc10_0_split
I0701 14:28:10.904096 30423 net.cpp:439] fc10_fc10_0_split <- fc10
I0701 14:28:10.904099 30423 net.cpp:413] fc10_fc10_0_split -> fc10_fc10_0_split_0
I0701 14:28:10.904103 30423 net.cpp:413] fc10_fc10_0_split -> fc10_fc10_0_split_1
I0701 14:28:10.904106 30423 net.cpp:413] fc10_fc10_0_split -> fc10_fc10_0_split_2
I0701 14:28:10.904160 30423 net.cpp:148] Setting up fc10_fc10_0_split
I0701 14:28:10.904165 30423 net.cpp:155] Top shape: 50 10 (500)
I0701 14:28:10.904166 30423 net.cpp:155] Top shape: 50 10 (500)
I0701 14:28:10.904170 30423 net.cpp:155] Top shape: 50 10 (500)
I0701 14:28:10.904170 30423 net.cpp:163] Memory required for data: 296252000
I0701 14:28:10.904172 30423 layer_factory.hpp:77] Creating layer loss
I0701 14:28:10.904175 30423 net.cpp:98] Creating Layer loss
I0701 14:28:10.904178 30423 net.cpp:439] loss <- fc10_fc10_0_split_0
I0701 14:28:10.904181 30423 net.cpp:439] loss <- label_data_1_split_0
I0701 14:28:10.904183 30423 net.cpp:413] loss -> loss
I0701 14:28:10.904187 30423 layer_factory.hpp:77] Creating layer loss
I0701 14:28:10.904286 30423 net.cpp:148] Setting up loss
I0701 14:28:10.904290 30423 net.cpp:155] Top shape: (1)
I0701 14:28:10.904294 30423 net.cpp:158]     with loss weight 1
I0701 14:28:10.904300 30423 net.cpp:163] Memory required for data: 296252004
I0701 14:28:10.904302 30423 layer_factory.hpp:77] Creating layer accuracy/top1
I0701 14:28:10.904306 30423 net.cpp:98] Creating Layer accuracy/top1
I0701 14:28:10.904309 30423 net.cpp:439] accuracy/top1 <- fc10_fc10_0_split_1
I0701 14:28:10.904311 30423 net.cpp:439] accuracy/top1 <- label_data_1_split_1
I0701 14:28:10.904314 30423 net.cpp:413] accuracy/top1 -> accuracy/top1
I0701 14:28:10.904325 30423 net.cpp:148] Setting up accuracy/top1
I0701 14:28:10.904327 30423 net.cpp:155] Top shape: (1)
I0701 14:28:10.904330 30423 net.cpp:163] Memory required for data: 296252008
I0701 14:28:10.904331 30423 layer_factory.hpp:77] Creating layer accuracy/top5
I0701 14:28:10.904335 30423 net.cpp:98] Creating Layer accuracy/top5
I0701 14:28:10.904338 30423 net.cpp:439] accuracy/top5 <- fc10_fc10_0_split_2
I0701 14:28:10.904340 30423 net.cpp:439] accuracy/top5 <- label_data_1_split_2
I0701 14:28:10.904343 30423 net.cpp:413] accuracy/top5 -> accuracy/top5
I0701 14:28:10.904347 30423 net.cpp:148] Setting up accuracy/top5
I0701 14:28:10.904350 30423 net.cpp:155] Top shape: (1)
I0701 14:28:10.904352 30423 net.cpp:163] Memory required for data: 296252012
I0701 14:28:10.904355 30423 net.cpp:226] accuracy/top5 does not need backward computation.
I0701 14:28:10.904357 30423 net.cpp:226] accuracy/top1 does not need backward computation.
I0701 14:28:10.904359 30423 net.cpp:224] loss needs backward computation.
I0701 14:28:10.904362 30423 net.cpp:224] fc10_fc10_0_split needs backward computation.
I0701 14:28:10.904366 30423 net.cpp:224] fc10 needs backward computation.
I0701 14:28:10.904367 30423 net.cpp:224] pool5 needs backward computation.
I0701 14:28:10.904371 30423 net.cpp:224] res5a_branch2b/relu needs backward computation.
I0701 14:28:10.904378 30423 net.cpp:224] res5a_branch2b/bn needs backward computation.
I0701 14:28:10.904381 30423 net.cpp:224] res5a_branch2b needs backward computation.
I0701 14:28:10.904383 30423 net.cpp:224] res5a_branch2a/relu needs backward computation.
I0701 14:28:10.904386 30423 net.cpp:224] res5a_branch2a/bn needs backward computation.
I0701 14:28:10.904387 30423 net.cpp:224] res5a_branch2a needs backward computation.
I0701 14:28:10.904391 30423 net.cpp:224] pool4 needs backward computation.
I0701 14:28:10.904393 30423 net.cpp:224] res4a_branch2b/relu needs backward computation.
I0701 14:28:10.904395 30423 net.cpp:224] res4a_branch2b/bn needs backward computation.
I0701 14:28:10.904397 30423 net.cpp:224] res4a_branch2b needs backward computation.
I0701 14:28:10.904399 30423 net.cpp:224] res4a_branch2a/relu needs backward computation.
I0701 14:28:10.904402 30423 net.cpp:224] res4a_branch2a/bn needs backward computation.
I0701 14:28:10.904405 30423 net.cpp:224] res4a_branch2a needs backward computation.
I0701 14:28:10.904407 30423 net.cpp:224] pool3 needs backward computation.
I0701 14:28:10.904410 30423 net.cpp:224] res3a_branch2b/relu needs backward computation.
I0701 14:28:10.904412 30423 net.cpp:224] res3a_branch2b/bn needs backward computation.
I0701 14:28:10.904414 30423 net.cpp:224] res3a_branch2b needs backward computation.
I0701 14:28:10.904417 30423 net.cpp:224] res3a_branch2a/relu needs backward computation.
I0701 14:28:10.904419 30423 net.cpp:224] res3a_branch2a/bn needs backward computation.
I0701 14:28:10.904422 30423 net.cpp:224] res3a_branch2a needs backward computation.
I0701 14:28:10.904424 30423 net.cpp:224] pool2 needs backward computation.
I0701 14:28:10.904428 30423 net.cpp:224] res2a_branch2b/relu needs backward computation.
I0701 14:28:10.904429 30423 net.cpp:224] res2a_branch2b/bn needs backward computation.
I0701 14:28:10.904433 30423 net.cpp:224] res2a_branch2b needs backward computation.
I0701 14:28:10.904434 30423 net.cpp:224] res2a_branch2a/relu needs backward computation.
I0701 14:28:10.904436 30423 net.cpp:224] res2a_branch2a/bn needs backward computation.
I0701 14:28:10.904439 30423 net.cpp:224] res2a_branch2a needs backward computation.
I0701 14:28:10.904441 30423 net.cpp:224] pool1 needs backward computation.
I0701 14:28:10.904444 30423 net.cpp:224] conv1b/relu needs backward computation.
I0701 14:28:10.904446 30423 net.cpp:224] conv1b/bn needs backward computation.
I0701 14:28:10.904448 30423 net.cpp:224] conv1b needs backward computation.
I0701 14:28:10.904451 30423 net.cpp:224] conv1a/relu needs backward computation.
I0701 14:28:10.904454 30423 net.cpp:224] conv1a/bn needs backward computation.
I0701 14:28:10.904456 30423 net.cpp:224] conv1a needs backward computation.
I0701 14:28:10.904459 30423 net.cpp:226] data/bias does not need backward computation.
I0701 14:28:10.904462 30423 net.cpp:226] label_data_1_split does not need backward computation.
I0701 14:28:10.904465 30423 net.cpp:226] data does not need backward computation.
I0701 14:28:10.904467 30423 net.cpp:268] This network produces output accuracy/top1
I0701 14:28:10.904469 30423 net.cpp:268] This network produces output accuracy/top5
I0701 14:28:10.904472 30423 net.cpp:268] This network produces output loss
I0701 14:28:10.904492 30423 net.cpp:288] Network initialization done.
I0701 14:28:10.904554 30423 solver.cpp:60] Solver scaffolding done.
I0701 14:28:10.915462 30423 data_layer.cpp:78] ReshapePrefetch 21, 3, 32, 32
I0701 14:28:10.915518 30423 data_layer.cpp:83] output data size: 21,3,32,32
I0701 14:28:11.398552 30423 data_layer.cpp:78] ReshapePrefetch 21, 3, 32, 32
I0701 14:28:11.398623 30423 data_layer.cpp:83] output data size: 21,3,32,32
I0701 14:28:11.998267 30423 parallel.cpp:334] Starting Optimization
I0701 14:28:11.998319 30423 solver.cpp:415] Solving jacintonet11v2_train
I0701 14:28:11.998324 30423 solver.cpp:416] Learning Rate Policy: poly
I0701 14:28:12.003739 30423 solver.cpp:473] Iteration 0, Testing net (#0)
I0701 14:28:13.654204 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.1
I0701 14:28:13.654235 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.504
I0701 14:28:13.654242 30423 solver.cpp:546]     Test net output #2: loss = 78.2999 (* 1 = 78.2999 loss)
I0701 14:28:13.776979 30423 solver.cpp:290] Iteration 0 (0 iter/s, 1.77859s/100 iter), loss = 1.57143
I0701 14:28:13.777000 30423 solver.cpp:309]     Train net output #0: loss = 1.57143 (* 1 = 1.57143 loss)
I0701 14:28:13.777007 30423 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0701 14:28:15.712184 30423 solver.cpp:290] Iteration 100 (51.6762 iter/s, 1.93513s/100 iter), loss = 1.19048
I0701 14:28:15.712208 30423 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0701 14:28:15.712213 30423 sgd_solver.cpp:106] Iteration 100, lr = 0.0998438
I0701 14:28:17.619388 30423 solver.cpp:290] Iteration 200 (52.435 iter/s, 1.90712s/100 iter), loss = 1.04762
I0701 14:28:17.619410 30423 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0701 14:28:17.619416 30423 sgd_solver.cpp:106] Iteration 200, lr = 0.0996875
I0701 14:28:19.535058 30423 solver.cpp:290] Iteration 300 (52.2032 iter/s, 1.91559s/100 iter), loss = 0.761905
I0701 14:28:19.535082 30423 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0701 14:28:19.535090 30423 sgd_solver.cpp:106] Iteration 300, lr = 0.0995313
I0701 14:28:21.455950 30423 solver.cpp:290] Iteration 400 (52.0613 iter/s, 1.92081s/100 iter), loss = 0.809524
I0701 14:28:21.455971 30423 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0701 14:28:21.455977 30423 sgd_solver.cpp:106] Iteration 400, lr = 0.099375
I0701 14:28:23.371151 30423 solver.cpp:290] Iteration 500 (52.216 iter/s, 1.91512s/100 iter), loss = 1.04762
I0701 14:28:23.371172 30423 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0701 14:28:23.371181 30423 sgd_solver.cpp:106] Iteration 500, lr = 0.0992187
I0701 14:28:24.825141 30492 blocking_queue.cpp:50] Data layer prefetch queue empty
I0701 14:28:25.286257 30423 solver.cpp:290] Iteration 600 (52.2186 iter/s, 1.91503s/100 iter), loss = 0.666667
I0701 14:28:25.286278 30423 solver.cpp:309]     Train net output #0: loss = 0.666667 (* 1 = 0.666667 loss)
I0701 14:28:25.286284 30423 sgd_solver.cpp:106] Iteration 600, lr = 0.0990625
I0701 14:28:27.205281 30423 solver.cpp:290] Iteration 700 (52.1119 iter/s, 1.91895s/100 iter), loss = 0.809524
I0701 14:28:27.205304 30423 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0701 14:28:27.205312 30423 sgd_solver.cpp:106] Iteration 700, lr = 0.0989062
I0701 14:28:29.119262 30423 solver.cpp:290] Iteration 800 (52.2493 iter/s, 1.9139s/100 iter), loss = 0.238095
I0701 14:28:29.119284 30423 solver.cpp:309]     Train net output #0: loss = 0.238095 (* 1 = 0.238095 loss)
I0701 14:28:29.119290 30423 sgd_solver.cpp:106] Iteration 800, lr = 0.09875
I0701 14:28:31.041317 30423 solver.cpp:290] Iteration 900 (52.0298 iter/s, 1.92198s/100 iter), loss = 0.571428
I0701 14:28:31.041338 30423 solver.cpp:309]     Train net output #0: loss = 0.571429 (* 1 = 0.571429 loss)
I0701 14:28:31.041344 30423 sgd_solver.cpp:106] Iteration 900, lr = 0.0985937
I0701 14:28:32.938386 30423 solver.cpp:473] Iteration 1000, Testing net (#0)
I0701 14:28:34.564493 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.4962
I0701 14:28:34.564512 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.947001
I0701 14:28:34.564517 30423 solver.cpp:546]     Test net output #2: loss = 1.2498 (* 1 = 1.2498 loss)
I0701 14:28:34.582892 30423 solver.cpp:290] Iteration 1000 (28.237 iter/s, 3.54146s/100 iter), loss = 0.238095
I0701 14:28:34.582909 30423 solver.cpp:309]     Train net output #0: loss = 0.238095 (* 1 = 0.238095 loss)
I0701 14:28:34.582921 30423 sgd_solver.cpp:106] Iteration 1000, lr = 0.0984375
I0701 14:28:36.503283 30423 solver.cpp:290] Iteration 1100 (52.0748 iter/s, 1.92032s/100 iter), loss = 0.0952379
I0701 14:28:36.503304 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:28:36.503325 30423 sgd_solver.cpp:106] Iteration 1100, lr = 0.0982813
I0701 14:28:38.422114 30423 solver.cpp:290] Iteration 1200 (52.1172 iter/s, 1.91875s/100 iter), loss = 0.428571
I0701 14:28:38.422135 30423 solver.cpp:309]     Train net output #0: loss = 0.428571 (* 1 = 0.428571 loss)
I0701 14:28:38.422142 30423 sgd_solver.cpp:106] Iteration 1200, lr = 0.098125
I0701 14:28:40.347932 30423 solver.cpp:290] Iteration 1300 (51.9282 iter/s, 1.92574s/100 iter), loss = 0.666666
I0701 14:28:40.348018 30423 solver.cpp:309]     Train net output #0: loss = 0.666667 (* 1 = 0.666667 loss)
I0701 14:28:40.348026 30423 sgd_solver.cpp:106] Iteration 1300, lr = 0.0979687
I0701 14:28:42.274507 30423 solver.cpp:290] Iteration 1400 (51.9094 iter/s, 1.92643s/100 iter), loss = 0.619047
I0701 14:28:42.274528 30423 solver.cpp:309]     Train net output #0: loss = 0.619048 (* 1 = 0.619048 loss)
I0701 14:28:42.274534 30423 sgd_solver.cpp:106] Iteration 1400, lr = 0.0978125
I0701 14:28:44.199949 30423 solver.cpp:290] Iteration 1500 (51.9382 iter/s, 1.92536s/100 iter), loss = 0.428571
I0701 14:28:44.199972 30423 solver.cpp:309]     Train net output #0: loss = 0.428571 (* 1 = 0.428571 loss)
I0701 14:28:44.199978 30423 sgd_solver.cpp:106] Iteration 1500, lr = 0.0976562
I0701 14:28:46.124085 30423 solver.cpp:290] Iteration 1600 (51.9735 iter/s, 1.92406s/100 iter), loss = 0.190475
I0701 14:28:46.124109 30423 solver.cpp:309]     Train net output #0: loss = 0.190476 (* 1 = 0.190476 loss)
I0701 14:28:46.124114 30423 sgd_solver.cpp:106] Iteration 1600, lr = 0.0975
I0701 14:28:48.055701 30423 solver.cpp:290] Iteration 1700 (51.7724 iter/s, 1.93153s/100 iter), loss = 0.523809
I0701 14:28:48.055726 30423 solver.cpp:309]     Train net output #0: loss = 0.52381 (* 1 = 0.52381 loss)
I0701 14:28:48.055734 30423 sgd_solver.cpp:106] Iteration 1700, lr = 0.0973438
I0701 14:28:49.981014 30423 solver.cpp:290] Iteration 1800 (51.9418 iter/s, 1.92523s/100 iter), loss = 0.666666
I0701 14:28:49.981036 30423 solver.cpp:309]     Train net output #0: loss = 0.666667 (* 1 = 0.666667 loss)
I0701 14:28:49.981042 30423 sgd_solver.cpp:106] Iteration 1800, lr = 0.0971875
I0701 14:28:51.904011 30423 solver.cpp:290] Iteration 1900 (52.0044 iter/s, 1.92291s/100 iter), loss = 0.380952
I0701 14:28:51.904038 30423 solver.cpp:309]     Train net output #0: loss = 0.380952 (* 1 = 0.380952 loss)
I0701 14:28:51.904047 30423 sgd_solver.cpp:106] Iteration 1900, lr = 0.0970313
I0701 14:28:53.811870 30423 solver.cpp:473] Iteration 2000, Testing net (#0)
I0701 14:28:55.444764 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.6411
I0701 14:28:55.444783 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.965501
I0701 14:28:55.444789 30423 solver.cpp:546]     Test net output #2: loss = 0.6985 (* 1 = 0.6985 loss)
I0701 14:28:55.463246 30423 solver.cpp:290] Iteration 2000 (28.0969 iter/s, 3.55911s/100 iter), loss = 0.190476
I0701 14:28:55.463264 30423 solver.cpp:309]     Train net output #0: loss = 0.190476 (* 1 = 0.190476 loss)
I0701 14:28:55.463276 30423 sgd_solver.cpp:106] Iteration 2000, lr = 0.096875
I0701 14:28:57.424199 30423 solver.cpp:290] Iteration 2100 (50.9976 iter/s, 1.96088s/100 iter), loss = 0.47619
I0701 14:28:57.424221 30423 solver.cpp:309]     Train net output #0: loss = 0.47619 (* 1 = 0.47619 loss)
I0701 14:28:57.424227 30423 sgd_solver.cpp:106] Iteration 2100, lr = 0.0967188
I0701 14:28:59.355484 30423 solver.cpp:290] Iteration 2200 (51.7813 iter/s, 1.9312s/100 iter), loss = 0.380951
I0701 14:28:59.355515 30423 solver.cpp:309]     Train net output #0: loss = 0.380952 (* 1 = 0.380952 loss)
I0701 14:28:59.355525 30423 sgd_solver.cpp:106] Iteration 2200, lr = 0.0965625
I0701 14:29:01.290449 30423 solver.cpp:290] Iteration 2300 (51.6829 iter/s, 1.93488s/100 iter), loss = 0.190475
I0701 14:29:01.290472 30423 solver.cpp:309]     Train net output #0: loss = 0.190476 (* 1 = 0.190476 loss)
I0701 14:29:01.290479 30423 sgd_solver.cpp:106] Iteration 2300, lr = 0.0964063
I0701 14:29:03.218468 30423 solver.cpp:290] Iteration 2400 (51.8689 iter/s, 1.92794s/100 iter), loss = 0.380951
I0701 14:29:03.218490 30423 solver.cpp:309]     Train net output #0: loss = 0.380952 (* 1 = 0.380952 loss)
I0701 14:29:03.218497 30423 sgd_solver.cpp:106] Iteration 2400, lr = 0.09625
I0701 14:29:05.158907 30423 solver.cpp:290] Iteration 2500 (51.5369 iter/s, 1.94036s/100 iter), loss = 0.714285
I0701 14:29:05.158928 30423 solver.cpp:309]     Train net output #0: loss = 0.714286 (* 1 = 0.714286 loss)
I0701 14:29:05.158936 30423 sgd_solver.cpp:106] Iteration 2500, lr = 0.0960938
I0701 14:29:07.088258 30423 solver.cpp:290] Iteration 2600 (51.833 iter/s, 1.92927s/100 iter), loss = 0.190475
I0701 14:29:07.088279 30423 solver.cpp:309]     Train net output #0: loss = 0.190476 (* 1 = 0.190476 loss)
I0701 14:29:07.088286 30423 sgd_solver.cpp:106] Iteration 2600, lr = 0.0959375
I0701 14:29:09.015609 30423 solver.cpp:290] Iteration 2700 (51.8869 iter/s, 1.92727s/100 iter), loss = 0.761904
I0701 14:29:09.015635 30423 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0701 14:29:09.015642 30423 sgd_solver.cpp:106] Iteration 2700, lr = 0.0957813
I0701 14:29:10.949627 30423 solver.cpp:290] Iteration 2800 (51.708 iter/s, 1.93394s/100 iter), loss = 0.333332
I0701 14:29:10.949681 30423 solver.cpp:309]     Train net output #0: loss = 0.333333 (* 1 = 0.333333 loss)
I0701 14:29:10.949688 30423 sgd_solver.cpp:106] Iteration 2800, lr = 0.095625
I0701 14:29:12.885761 30423 solver.cpp:290] Iteration 2900 (51.6523 iter/s, 1.93602s/100 iter), loss = 0.333332
I0701 14:29:12.885783 30423 solver.cpp:309]     Train net output #0: loss = 0.333333 (* 1 = 0.333333 loss)
I0701 14:29:12.885789 30423 sgd_solver.cpp:106] Iteration 2900, lr = 0.0954688
I0701 14:29:14.796950 30423 solver.cpp:473] Iteration 3000, Testing net (#0)
I0701 14:29:16.428858 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.7264
I0701 14:29:16.428876 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9854
I0701 14:29:16.428884 30423 solver.cpp:546]     Test net output #2: loss = 0.5192 (* 1 = 0.5192 loss)
I0701 14:29:16.447428 30423 solver.cpp:290] Iteration 3000 (28.0777 iter/s, 3.56155s/100 iter), loss = 0.285713
I0701 14:29:16.447445 30423 solver.cpp:309]     Train net output #0: loss = 0.285714 (* 1 = 0.285714 loss)
I0701 14:29:16.447458 30423 sgd_solver.cpp:106] Iteration 3000, lr = 0.0953125
I0701 14:29:18.378787 30423 solver.cpp:290] Iteration 3100 (51.7792 iter/s, 1.93128s/100 iter), loss = 0.42857
I0701 14:29:18.378824 30423 solver.cpp:309]     Train net output #0: loss = 0.428571 (* 1 = 0.428571 loss)
I0701 14:29:18.378835 30423 sgd_solver.cpp:106] Iteration 3100, lr = 0.0951563
I0701 14:29:20.308243 30423 solver.cpp:290] Iteration 3200 (51.8306 iter/s, 1.92936s/100 iter), loss = 0.571428
I0701 14:29:20.308264 30423 solver.cpp:309]     Train net output #0: loss = 0.571429 (* 1 = 0.571429 loss)
I0701 14:29:20.308271 30423 sgd_solver.cpp:106] Iteration 3200, lr = 0.095
I0701 14:29:22.239812 30423 solver.cpp:290] Iteration 3300 (51.7735 iter/s, 1.93149s/100 iter), loss = 0.095237
I0701 14:29:22.239835 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:29:22.239840 30423 sgd_solver.cpp:106] Iteration 3300, lr = 0.0948438
I0701 14:29:24.169245 30423 solver.cpp:290] Iteration 3400 (51.8309 iter/s, 1.92935s/100 iter), loss = 0.238094
I0701 14:29:24.169266 30423 solver.cpp:309]     Train net output #0: loss = 0.238095 (* 1 = 0.238095 loss)
I0701 14:29:24.169272 30423 sgd_solver.cpp:106] Iteration 3400, lr = 0.0946875
I0701 14:29:26.100443 30423 solver.cpp:290] Iteration 3500 (51.7835 iter/s, 1.93112s/100 iter), loss = 0.0476179
I0701 14:29:26.100468 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:29:26.100476 30423 sgd_solver.cpp:106] Iteration 3500, lr = 0.0945313
I0701 14:29:28.038626 30423 solver.cpp:290] Iteration 3600 (51.5969 iter/s, 1.9381s/100 iter), loss = 0.285713
I0701 14:29:28.038648 30423 solver.cpp:309]     Train net output #0: loss = 0.285714 (* 1 = 0.285714 loss)
I0701 14:29:28.038655 30423 sgd_solver.cpp:106] Iteration 3600, lr = 0.094375
I0701 14:29:29.979208 30423 solver.cpp:290] Iteration 3700 (51.5331 iter/s, 1.9405s/100 iter), loss = -1.19209e-06
I0701 14:29:29.979229 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:29:29.979238 30423 sgd_solver.cpp:106] Iteration 3700, lr = 0.0942188
I0701 14:29:31.920043 30423 solver.cpp:290] Iteration 3800 (51.5264 iter/s, 1.94075s/100 iter), loss = 0.380951
I0701 14:29:31.920065 30423 solver.cpp:309]     Train net output #0: loss = 0.380952 (* 1 = 0.380952 loss)
I0701 14:29:31.920073 30423 sgd_solver.cpp:106] Iteration 3800, lr = 0.0940625
I0701 14:29:33.857532 30423 solver.cpp:290] Iteration 3900 (51.6154 iter/s, 1.9374s/100 iter), loss = 0.285713
I0701 14:29:33.857553 30423 solver.cpp:309]     Train net output #0: loss = 0.285714 (* 1 = 0.285714 loss)
I0701 14:29:33.857561 30423 sgd_solver.cpp:106] Iteration 3900, lr = 0.0939062
I0701 14:29:35.776975 30423 solver.cpp:473] Iteration 4000, Testing net (#0)
I0701 14:29:37.414464 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.7707
I0701 14:29:37.414482 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9865
I0701 14:29:37.414489 30423 solver.cpp:546]     Test net output #2: loss = 0.4097 (* 1 = 0.4097 loss)
I0701 14:29:37.433003 30423 solver.cpp:290] Iteration 4000 (27.9693 iter/s, 3.57535s/100 iter), loss = 0.190475
I0701 14:29:37.433022 30423 solver.cpp:309]     Train net output #0: loss = 0.190476 (* 1 = 0.190476 loss)
I0701 14:29:37.433037 30423 sgd_solver.cpp:106] Iteration 4000, lr = 0.09375
I0701 14:29:39.378729 30423 solver.cpp:290] Iteration 4100 (51.3968 iter/s, 1.94565s/100 iter), loss = 0.0476176
I0701 14:29:39.378752 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:29:39.378759 30423 sgd_solver.cpp:106] Iteration 4100, lr = 0.0935938
I0701 14:29:41.316798 30423 solver.cpp:290] Iteration 4200 (51.5999 iter/s, 1.93799s/100 iter), loss = 0.190475
I0701 14:29:41.316840 30423 solver.cpp:309]     Train net output #0: loss = 0.190476 (* 1 = 0.190476 loss)
I0701 14:29:41.316848 30423 sgd_solver.cpp:106] Iteration 4200, lr = 0.0934375
I0701 14:29:43.254623 30423 solver.cpp:290] Iteration 4300 (51.607 iter/s, 1.93772s/100 iter), loss = -1.40071e-06
I0701 14:29:43.254643 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:29:43.254650 30423 sgd_solver.cpp:106] Iteration 4300, lr = 0.0932813
I0701 14:29:45.193902 30423 solver.cpp:290] Iteration 4400 (51.5677 iter/s, 1.9392s/100 iter), loss = 0.142856
I0701 14:29:45.193923 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:29:45.193931 30423 sgd_solver.cpp:106] Iteration 4400, lr = 0.093125
I0701 14:29:47.131479 30423 solver.cpp:290] Iteration 4500 (51.613 iter/s, 1.93749s/100 iter), loss = 0.238094
I0701 14:29:47.131500 30423 solver.cpp:309]     Train net output #0: loss = 0.238095 (* 1 = 0.238095 loss)
I0701 14:29:47.131506 30423 sgd_solver.cpp:106] Iteration 4500, lr = 0.0929688
I0701 14:29:49.068776 30423 solver.cpp:290] Iteration 4600 (51.6205 iter/s, 1.93722s/100 iter), loss = 0.42857
I0701 14:29:49.068799 30423 solver.cpp:309]     Train net output #0: loss = 0.428571 (* 1 = 0.428571 loss)
I0701 14:29:49.068805 30423 sgd_solver.cpp:106] Iteration 4600, lr = 0.0928125
I0701 14:29:51.006060 30423 solver.cpp:290] Iteration 4700 (51.6209 iter/s, 1.9372s/100 iter), loss = 0.285713
I0701 14:29:51.006080 30423 solver.cpp:309]     Train net output #0: loss = 0.285714 (* 1 = 0.285714 loss)
I0701 14:29:51.006088 30423 sgd_solver.cpp:106] Iteration 4700, lr = 0.0926562
I0701 14:29:52.944854 30423 solver.cpp:290] Iteration 4800 (51.5806 iter/s, 1.93871s/100 iter), loss = 0.0952365
I0701 14:29:52.944877 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:29:52.944883 30423 sgd_solver.cpp:106] Iteration 4800, lr = 0.0925
I0701 14:29:54.898098 30423 solver.cpp:290] Iteration 4900 (51.1991 iter/s, 1.95316s/100 iter), loss = 0.333332
I0701 14:29:54.898123 30423 solver.cpp:309]     Train net output #0: loss = 0.333333 (* 1 = 0.333333 loss)
I0701 14:29:54.898130 30423 sgd_solver.cpp:106] Iteration 4900, lr = 0.0923437
I0701 14:29:56.854609 30423 solver.cpp:473] Iteration 5000, Testing net (#0)
I0701 14:29:58.495550 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.7852
I0701 14:29:58.495569 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9853
I0701 14:29:58.495575 30423 solver.cpp:546]     Test net output #2: loss = 0.4558 (* 1 = 0.4558 loss)
I0701 14:29:58.514626 30423 solver.cpp:290] Iteration 5000 (27.6518 iter/s, 3.6164s/100 iter), loss = 0.238094
I0701 14:29:58.514642 30423 solver.cpp:309]     Train net output #0: loss = 0.238095 (* 1 = 0.238095 loss)
I0701 14:29:58.514654 30423 sgd_solver.cpp:106] Iteration 5000, lr = 0.0921875
I0701 14:30:00.471710 30423 solver.cpp:290] Iteration 5100 (51.0984 iter/s, 1.95701s/100 iter), loss = 0.0952365
I0701 14:30:00.471731 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:30:00.471738 30423 sgd_solver.cpp:106] Iteration 5100, lr = 0.0920313
I0701 14:30:02.434017 30423 solver.cpp:290] Iteration 5200 (50.9626 iter/s, 1.96222s/100 iter), loss = 0.285713
I0701 14:30:02.434047 30423 solver.cpp:309]     Train net output #0: loss = 0.285714 (* 1 = 0.285714 loss)
I0701 14:30:02.434056 30423 sgd_solver.cpp:106] Iteration 5200, lr = 0.091875
I0701 14:30:04.409914 30423 solver.cpp:290] Iteration 5300 (50.6122 iter/s, 1.97581s/100 iter), loss = 0.0476174
I0701 14:30:04.409936 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:30:04.409942 30423 sgd_solver.cpp:106] Iteration 5300, lr = 0.0917188
I0701 14:30:06.407558 30423 solver.cpp:290] Iteration 5400 (50.0611 iter/s, 1.99756s/100 iter), loss = 0.285713
I0701 14:30:06.407580 30423 solver.cpp:309]     Train net output #0: loss = 0.285714 (* 1 = 0.285714 loss)
I0701 14:30:06.407588 30423 sgd_solver.cpp:106] Iteration 5400, lr = 0.0915625
I0701 14:30:08.415895 30423 solver.cpp:290] Iteration 5500 (49.7945 iter/s, 2.00825s/100 iter), loss = 0.238093
I0701 14:30:08.415920 30423 solver.cpp:309]     Train net output #0: loss = 0.238095 (* 1 = 0.238095 loss)
I0701 14:30:08.415928 30423 sgd_solver.cpp:106] Iteration 5500, lr = 0.0914062
I0701 14:30:10.418520 30423 solver.cpp:290] Iteration 5600 (49.9366 iter/s, 2.00254s/100 iter), loss = 0.190474
I0701 14:30:10.418542 30423 solver.cpp:309]     Train net output #0: loss = 0.190476 (* 1 = 0.190476 loss)
I0701 14:30:10.418548 30423 sgd_solver.cpp:106] Iteration 5600, lr = 0.09125
I0701 14:30:12.414727 30423 solver.cpp:290] Iteration 5700 (50.0971 iter/s, 1.99612s/100 iter), loss = 0.285712
I0701 14:30:12.414814 30423 solver.cpp:309]     Train net output #0: loss = 0.285714 (* 1 = 0.285714 loss)
I0701 14:30:12.414822 30423 sgd_solver.cpp:106] Iteration 5700, lr = 0.0910937
I0701 14:30:14.394702 30423 solver.cpp:290] Iteration 5800 (50.5094 iter/s, 1.97983s/100 iter), loss = 0.285712
I0701 14:30:14.394726 30423 solver.cpp:309]     Train net output #0: loss = 0.285714 (* 1 = 0.285714 loss)
I0701 14:30:14.394731 30423 sgd_solver.cpp:106] Iteration 5800, lr = 0.0909375
I0701 14:30:16.390974 30423 solver.cpp:290] Iteration 5900 (50.0954 iter/s, 1.99619s/100 iter), loss = 0.523808
I0701 14:30:16.390997 30423 solver.cpp:309]     Train net output #0: loss = 0.52381 (* 1 = 0.52381 loss)
I0701 14:30:16.391005 30423 sgd_solver.cpp:106] Iteration 5900, lr = 0.0907812
I0701 14:30:18.389777 30423 solver.cpp:473] Iteration 6000, Testing net (#0)
I0701 14:30:20.028057 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.7851
I0701 14:30:20.028076 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9876
I0701 14:30:20.028082 30423 solver.cpp:546]     Test net output #2: loss = 0.457 (* 1 = 0.457 loss)
I0701 14:30:20.047078 30423 solver.cpp:290] Iteration 6000 (27.3525 iter/s, 3.65598s/100 iter), loss = 0.0952361
I0701 14:30:20.047096 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:30:20.047107 30423 sgd_solver.cpp:106] Iteration 6000, lr = 0.090625
I0701 14:30:22.029150 30423 solver.cpp:290] Iteration 6100 (50.4543 iter/s, 1.98199s/100 iter), loss = 0.095236
I0701 14:30:22.029172 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:30:22.029180 30423 sgd_solver.cpp:106] Iteration 6100, lr = 0.0904688
I0701 14:30:24.030304 30423 solver.cpp:290] Iteration 6200 (49.9732 iter/s, 2.00107s/100 iter), loss = 0.142855
I0701 14:30:24.030326 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:30:24.030335 30423 sgd_solver.cpp:106] Iteration 6200, lr = 0.0903125
I0701 14:30:26.046030 30423 solver.cpp:290] Iteration 6300 (49.612 iter/s, 2.01564s/100 iter), loss = 0.428569
I0701 14:30:26.046053 30423 solver.cpp:309]     Train net output #0: loss = 0.428571 (* 1 = 0.428571 loss)
I0701 14:30:26.046061 30423 sgd_solver.cpp:106] Iteration 6300, lr = 0.0901562
I0701 14:30:28.059458 30423 solver.cpp:290] Iteration 6400 (49.6687 iter/s, 2.01334s/100 iter), loss = 0.0952359
I0701 14:30:28.059478 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:30:28.059485 30423 sgd_solver.cpp:106] Iteration 6400, lr = 0.09
I0701 14:30:30.092353 30423 solver.cpp:290] Iteration 6500 (49.193 iter/s, 2.03281s/100 iter), loss = 0.0476168
I0701 14:30:30.092378 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:30:30.092386 30423 sgd_solver.cpp:106] Iteration 6500, lr = 0.0898438
I0701 14:30:32.124315 30423 solver.cpp:290] Iteration 6600 (49.2156 iter/s, 2.03188s/100 iter), loss = 0.0952359
I0701 14:30:32.124337 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:30:32.124346 30423 sgd_solver.cpp:106] Iteration 6600, lr = 0.0896875
I0701 14:30:34.156363 30423 solver.cpp:290] Iteration 6700 (49.2135 iter/s, 2.03196s/100 iter), loss = 0.428569
I0701 14:30:34.156384 30423 solver.cpp:309]     Train net output #0: loss = 0.428571 (* 1 = 0.428571 loss)
I0701 14:30:34.156390 30423 sgd_solver.cpp:106] Iteration 6700, lr = 0.0895313
I0701 14:30:36.187005 30423 solver.cpp:290] Iteration 6800 (49.2475 iter/s, 2.03056s/100 iter), loss = 0.285712
I0701 14:30:36.187026 30423 solver.cpp:309]     Train net output #0: loss = 0.285714 (* 1 = 0.285714 loss)
I0701 14:30:36.187034 30423 sgd_solver.cpp:106] Iteration 6800, lr = 0.089375
I0701 14:30:38.228368 30423 solver.cpp:290] Iteration 6900 (48.9889 iter/s, 2.04128s/100 iter), loss = -2.26498e-06
I0701 14:30:38.228390 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:30:38.228396 30423 sgd_solver.cpp:106] Iteration 6900, lr = 0.0892188
I0701 14:30:40.249402 30423 solver.cpp:473] Iteration 7000, Testing net (#0)
I0701 14:30:41.886848 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.798
I0701 14:30:41.886868 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9846
I0701 14:30:41.886873 30423 solver.cpp:546]     Test net output #2: loss = 0.449 (* 1 = 0.449 loss)
I0701 14:30:41.907505 30423 solver.cpp:290] Iteration 7000 (27.1812 iter/s, 3.67901s/100 iter), loss = 0.0952358
I0701 14:30:41.907521 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:30:41.907533 30423 sgd_solver.cpp:106] Iteration 7000, lr = 0.0890625
I0701 14:30:43.905443 30423 solver.cpp:290] Iteration 7100 (50.0535 iter/s, 1.99786s/100 iter), loss = 0.0476168
I0701 14:30:43.905495 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:30:43.905503 30423 sgd_solver.cpp:106] Iteration 7100, lr = 0.0889063
I0701 14:30:45.941591 30423 solver.cpp:290] Iteration 7200 (49.115 iter/s, 2.03604s/100 iter), loss = 0.0952358
I0701 14:30:45.941613 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:30:45.941620 30423 sgd_solver.cpp:106] Iteration 7200, lr = 0.08875
I0701 14:30:47.979192 30423 solver.cpp:290] Iteration 7300 (49.0794 iter/s, 2.03752s/100 iter), loss = 0.142855
I0701 14:30:47.979213 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:30:47.979219 30423 sgd_solver.cpp:106] Iteration 7300, lr = 0.0885938
I0701 14:30:50.030038 30423 solver.cpp:290] Iteration 7400 (48.7623 iter/s, 2.05076s/100 iter), loss = 0.142855
I0701 14:30:50.030062 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:30:50.030071 30423 sgd_solver.cpp:106] Iteration 7400, lr = 0.0884375
I0701 14:30:52.079136 30423 solver.cpp:290] Iteration 7500 (48.804 iter/s, 2.04901s/100 iter), loss = -2.41399e-06
I0701 14:30:52.079159 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:30:52.079166 30423 sgd_solver.cpp:106] Iteration 7500, lr = 0.0882813
I0701 14:30:54.128788 30423 solver.cpp:290] Iteration 7600 (48.7908 iter/s, 2.04957s/100 iter), loss = 0.190474
I0701 14:30:54.128811 30423 solver.cpp:309]     Train net output #0: loss = 0.190476 (* 1 = 0.190476 loss)
I0701 14:30:54.128819 30423 sgd_solver.cpp:106] Iteration 7600, lr = 0.088125
I0701 14:30:56.190877 30423 solver.cpp:290] Iteration 7700 (48.4965 iter/s, 2.062s/100 iter), loss = 0.142855
I0701 14:30:56.190901 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:30:56.190907 30423 sgd_solver.cpp:106] Iteration 7700, lr = 0.0879688
I0701 14:30:58.275223 30423 solver.cpp:290] Iteration 7800 (47.9787 iter/s, 2.08426s/100 iter), loss = 0.0952357
I0701 14:30:58.275249 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:30:58.275259 30423 sgd_solver.cpp:106] Iteration 7800, lr = 0.0878125
I0701 14:31:00.324661 30423 solver.cpp:290] Iteration 7900 (48.796 iter/s, 2.04935s/100 iter), loss = 0.0476167
I0701 14:31:00.324682 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:31:00.324689 30423 sgd_solver.cpp:106] Iteration 7900, lr = 0.0876563
I0701 14:31:02.359242 30423 solver.cpp:473] Iteration 8000, Testing net (#0)
I0701 14:31:03.995338 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.7681
I0701 14:31:03.995358 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9778
I0701 14:31:03.995363 30423 solver.cpp:546]     Test net output #2: loss = 0.5832 (* 1 = 0.5832 loss)
I0701 14:31:04.015677 30423 solver.cpp:290] Iteration 8000 (27.0938 iter/s, 3.69089s/100 iter), loss = 0.0476167
I0701 14:31:04.015697 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:31:04.015709 30423 sgd_solver.cpp:106] Iteration 8000, lr = 0.0875
I0701 14:31:06.042546 30423 solver.cpp:290] Iteration 8100 (49.3392 iter/s, 2.02679s/100 iter), loss = 0.238093
I0701 14:31:06.042568 30423 solver.cpp:309]     Train net output #0: loss = 0.238095 (* 1 = 0.238095 loss)
I0701 14:31:06.042575 30423 sgd_solver.cpp:106] Iteration 8100, lr = 0.0873438
I0701 14:31:08.094996 30423 solver.cpp:290] Iteration 8200 (48.7243 iter/s, 2.05236s/100 iter), loss = -2.38419e-06
I0701 14:31:08.095023 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:31:08.095032 30423 sgd_solver.cpp:106] Iteration 8200, lr = 0.0871875
I0701 14:31:10.149725 30423 solver.cpp:290] Iteration 8300 (48.6703 iter/s, 2.05464s/100 iter), loss = 0.142855
I0701 14:31:10.149747 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:31:10.149755 30423 sgd_solver.cpp:106] Iteration 8300, lr = 0.0870313
I0701 14:31:12.198626 30423 solver.cpp:290] Iteration 8400 (48.8087 iter/s, 2.04882s/100 iter), loss = 0.0952357
I0701 14:31:12.198647 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:31:12.198654 30423 sgd_solver.cpp:106] Iteration 8400, lr = 0.086875
I0701 14:31:14.249996 30423 solver.cpp:290] Iteration 8500 (48.7499 iter/s, 2.05129s/100 iter), loss = 0.142855
I0701 14:31:14.250068 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:31:14.250077 30423 sgd_solver.cpp:106] Iteration 8500, lr = 0.0867188
I0701 14:31:16.308722 30423 solver.cpp:290] Iteration 8600 (48.5768 iter/s, 2.05859s/100 iter), loss = 0.285712
I0701 14:31:16.308743 30423 solver.cpp:309]     Train net output #0: loss = 0.285714 (* 1 = 0.285714 loss)
I0701 14:31:16.308750 30423 sgd_solver.cpp:106] Iteration 8600, lr = 0.0865625
I0701 14:31:18.366108 30423 solver.cpp:290] Iteration 8700 (48.6073 iter/s, 2.0573s/100 iter), loss = 0.142855
I0701 14:31:18.366129 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:31:18.366137 30423 sgd_solver.cpp:106] Iteration 8700, lr = 0.0864063
I0701 14:31:20.423398 30423 solver.cpp:290] Iteration 8800 (48.6096 iter/s, 2.05721s/100 iter), loss = 0.0952355
I0701 14:31:20.423421 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:31:20.423429 30423 sgd_solver.cpp:106] Iteration 8800, lr = 0.08625
I0701 14:31:22.479177 30423 solver.cpp:290] Iteration 8900 (48.6454 iter/s, 2.05569s/100 iter), loss = 0.190474
I0701 14:31:22.479199 30423 solver.cpp:309]     Train net output #0: loss = 0.190476 (* 1 = 0.190476 loss)
I0701 14:31:22.479207 30423 sgd_solver.cpp:106] Iteration 8900, lr = 0.0860937
I0701 14:31:24.515419 30423 solver.cpp:473] Iteration 9000, Testing net (#0)
I0701 14:31:26.152055 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.5532
I0701 14:31:26.152072 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.952601
I0701 14:31:26.152078 30423 solver.cpp:546]     Test net output #2: loss = 1.7537 (* 1 = 1.7537 loss)
I0701 14:31:26.171803 30423 solver.cpp:290] Iteration 9000 (27.0819 iter/s, 3.6925s/100 iter), loss = 0.142855
I0701 14:31:26.171820 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:31:26.171833 30423 sgd_solver.cpp:106] Iteration 9000, lr = 0.0859375
I0701 14:31:28.206522 30423 solver.cpp:290] Iteration 9100 (49.1487 iter/s, 2.03464s/100 iter), loss = 0.0952355
I0701 14:31:28.206545 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:31:28.206552 30423 sgd_solver.cpp:106] Iteration 9100, lr = 0.0857813
I0701 14:31:30.260510 30423 solver.cpp:290] Iteration 9200 (48.6878 iter/s, 2.0539s/100 iter), loss = 0.0476165
I0701 14:31:30.260532 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:31:30.260540 30423 sgd_solver.cpp:106] Iteration 9200, lr = 0.085625
I0701 14:31:32.319074 30423 solver.cpp:290] Iteration 9300 (48.5796 iter/s, 2.05848s/100 iter), loss = -2.65986e-06
I0701 14:31:32.319102 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:31:32.319110 30423 sgd_solver.cpp:106] Iteration 9300, lr = 0.0854688
I0701 14:31:34.381808 30423 solver.cpp:290] Iteration 9400 (48.4814 iter/s, 2.06265s/100 iter), loss = -2.71201e-06
I0701 14:31:34.381830 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:31:34.381837 30423 sgd_solver.cpp:106] Iteration 9400, lr = 0.0853125
I0701 14:31:36.438671 30423 solver.cpp:290] Iteration 9500 (48.6197 iter/s, 2.05678s/100 iter), loss = 0.0952353
I0701 14:31:36.438694 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:31:36.438701 30423 sgd_solver.cpp:106] Iteration 9500, lr = 0.0851563
I0701 14:31:38.500018 30423 solver.cpp:290] Iteration 9600 (48.514 iter/s, 2.06126s/100 iter), loss = 0.0476163
I0701 14:31:38.500039 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:31:38.500047 30423 sgd_solver.cpp:106] Iteration 9600, lr = 0.085
I0701 14:31:40.559892 30423 solver.cpp:290] Iteration 9700 (48.5487 iter/s, 2.05979s/100 iter), loss = 0.0476163
I0701 14:31:40.559913 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:31:40.559921 30423 sgd_solver.cpp:106] Iteration 9700, lr = 0.0848437
I0701 14:31:42.618100 30423 solver.cpp:290] Iteration 9800 (48.588 iter/s, 2.05812s/100 iter), loss = -2.74181e-06
I0701 14:31:42.618129 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:31:42.618139 30423 sgd_solver.cpp:106] Iteration 9800, lr = 0.0846875
I0701 14:31:44.670462 30423 solver.cpp:290] Iteration 9900 (48.7265 iter/s, 2.05227s/100 iter), loss = 0.0476163
I0701 14:31:44.670549 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:31:44.670564 30423 sgd_solver.cpp:106] Iteration 9900, lr = 0.0845312
I0701 14:31:46.705291 30423 solver.cpp:600] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/initial/cifar10_jacintonet11v2_iter_10000.caffemodel
I0701 14:31:46.728801 30423 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/initial/cifar10_jacintonet11v2_iter_10000.solverstate
I0701 14:31:46.736028 30423 solver.cpp:473] Iteration 10000, Testing net (#0)
I0701 14:31:48.372937 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8068
I0701 14:31:48.372957 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9923
I0701 14:31:48.372963 30423 solver.cpp:546]     Test net output #2: loss = 0.4304 (* 1 = 0.4304 loss)
I0701 14:31:48.392376 30423 solver.cpp:290] Iteration 10000 (26.8692 iter/s, 3.72173s/100 iter), loss = -2.77162e-06
I0701 14:31:48.392395 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:31:48.392406 30423 sgd_solver.cpp:106] Iteration 10000, lr = 0.084375
I0701 14:31:50.446552 30423 solver.cpp:290] Iteration 10100 (48.6832 iter/s, 2.05409s/100 iter), loss = 0.142854
I0701 14:31:50.446574 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:31:50.446581 30423 sgd_solver.cpp:106] Iteration 10100, lr = 0.0842188
I0701 14:31:52.505610 30423 solver.cpp:290] Iteration 10200 (48.5679 iter/s, 2.05897s/100 iter), loss = 0.0476162
I0701 14:31:52.505633 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:31:52.505640 30423 sgd_solver.cpp:106] Iteration 10200, lr = 0.0840625
I0701 14:31:54.562212 30423 solver.cpp:290] Iteration 10300 (48.6259 iter/s, 2.05652s/100 iter), loss = 0.0476162
I0701 14:31:54.562235 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:31:54.562242 30423 sgd_solver.cpp:106] Iteration 10300, lr = 0.0839063
I0701 14:31:56.619346 30423 solver.cpp:290] Iteration 10400 (48.6133 iter/s, 2.05705s/100 iter), loss = 0.428569
I0701 14:31:56.619369 30423 solver.cpp:309]     Train net output #0: loss = 0.428571 (* 1 = 0.428571 loss)
I0701 14:31:56.619377 30423 sgd_solver.cpp:106] Iteration 10400, lr = 0.08375
I0701 14:31:58.780134 30423 solver.cpp:290] Iteration 10500 (46.2813 iter/s, 2.1607s/100 iter), loss = 0.142854
I0701 14:31:58.780156 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:31:58.780163 30423 sgd_solver.cpp:106] Iteration 10500, lr = 0.0835937
I0701 14:32:00.832455 30423 solver.cpp:290] Iteration 10600 (48.7273 iter/s, 2.05224s/100 iter), loss = 0.0476161
I0701 14:32:00.832479 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:32:00.832486 30423 sgd_solver.cpp:106] Iteration 10600, lr = 0.0834375
I0701 14:32:02.894970 30423 solver.cpp:290] Iteration 10700 (48.4865 iter/s, 2.06243s/100 iter), loss = 0.142854
I0701 14:32:02.894994 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:32:02.895000 30423 sgd_solver.cpp:106] Iteration 10700, lr = 0.0832812
I0701 14:32:04.951210 30423 solver.cpp:290] Iteration 10800 (48.6345 iter/s, 2.05615s/100 iter), loss = -3.01749e-06
I0701 14:32:04.951234 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:32:04.951243 30423 sgd_solver.cpp:106] Iteration 10800, lr = 0.083125
I0701 14:32:07.006326 30423 solver.cpp:290] Iteration 10900 (48.661 iter/s, 2.05503s/100 iter), loss = -3.02494e-06
I0701 14:32:07.006350 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:32:07.006358 30423 sgd_solver.cpp:106] Iteration 10900, lr = 0.0829687
I0701 14:32:09.044925 30423 solver.cpp:473] Iteration 11000, Testing net (#0)
I0701 14:32:10.683280 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.7851
I0701 14:32:10.683300 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9859
I0701 14:32:10.683320 30423 solver.cpp:546]     Test net output #2: loss = 0.5706 (* 1 = 0.5706 loss)
I0701 14:32:10.703135 30423 solver.cpp:290] Iteration 11000 (27.0513 iter/s, 3.69668s/100 iter), loss = 0.047616
I0701 14:32:10.703151 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:32:10.703164 30423 sgd_solver.cpp:106] Iteration 11000, lr = 0.0828125
I0701 14:32:12.756726 30423 solver.cpp:290] Iteration 11100 (48.6971 iter/s, 2.05351s/100 iter), loss = 0.238092
I0701 14:32:12.756747 30423 solver.cpp:309]     Train net output #0: loss = 0.238095 (* 1 = 0.238095 loss)
I0701 14:32:12.756754 30423 sgd_solver.cpp:106] Iteration 11100, lr = 0.0826563
I0701 14:32:14.812705 30423 solver.cpp:290] Iteration 11200 (48.6406 iter/s, 2.05589s/100 iter), loss = 0.33333
I0701 14:32:14.812760 30423 solver.cpp:309]     Train net output #0: loss = 0.333333 (* 1 = 0.333333 loss)
I0701 14:32:14.812768 30423 sgd_solver.cpp:106] Iteration 11200, lr = 0.0825
I0701 14:32:16.868693 30423 solver.cpp:290] Iteration 11300 (48.6412 iter/s, 2.05587s/100 iter), loss = 0.047616
I0701 14:32:16.868715 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:32:16.868723 30423 sgd_solver.cpp:106] Iteration 11300, lr = 0.0823437
I0701 14:32:18.926568 30423 solver.cpp:290] Iteration 11400 (48.5959 iter/s, 2.05779s/100 iter), loss = 0.095235
I0701 14:32:18.926594 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:32:18.926604 30423 sgd_solver.cpp:106] Iteration 11400, lr = 0.0821875
I0701 14:32:20.982906 30423 solver.cpp:290] Iteration 11500 (48.6322 iter/s, 2.05625s/100 iter), loss = 0.095235
I0701 14:32:20.982936 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:32:20.982947 30423 sgd_solver.cpp:106] Iteration 11500, lr = 0.0820312
I0701 14:32:23.044297 30423 solver.cpp:290] Iteration 11600 (48.513 iter/s, 2.0613s/100 iter), loss = 0.0476159
I0701 14:32:23.044320 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:32:23.044327 30423 sgd_solver.cpp:106] Iteration 11600, lr = 0.081875
I0701 14:32:25.096940 30423 solver.cpp:290] Iteration 11700 (48.7197 iter/s, 2.05256s/100 iter), loss = 0.0476159
I0701 14:32:25.096962 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:32:25.096971 30423 sgd_solver.cpp:106] Iteration 11700, lr = 0.0817188
I0701 14:32:27.152410 30423 solver.cpp:290] Iteration 11800 (48.6527 iter/s, 2.05539s/100 iter), loss = 0.0476159
I0701 14:32:27.152432 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:32:27.152438 30423 sgd_solver.cpp:106] Iteration 11800, lr = 0.0815625
I0701 14:32:29.206212 30423 solver.cpp:290] Iteration 11900 (48.6922 iter/s, 2.05372s/100 iter), loss = 0.142854
I0701 14:32:29.206234 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:32:29.206243 30423 sgd_solver.cpp:106] Iteration 11900, lr = 0.0814063
I0701 14:32:31.241933 30423 solver.cpp:473] Iteration 12000, Testing net (#0)
I0701 14:32:32.881146 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.7398
I0701 14:32:32.881165 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9619
I0701 14:32:32.881171 30423 solver.cpp:546]     Test net output #2: loss = 0.7685 (* 1 = 0.7685 loss)
I0701 14:32:32.901038 30423 solver.cpp:290] Iteration 12000 (27.0658 iter/s, 3.6947s/100 iter), loss = 0.142854
I0701 14:32:32.901056 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:32:32.901069 30423 sgd_solver.cpp:106] Iteration 12000, lr = 0.08125
I0701 14:32:34.957408 30423 solver.cpp:290] Iteration 12100 (48.6313 iter/s, 2.05629s/100 iter), loss = 0.238092
I0701 14:32:34.957430 30423 solver.cpp:309]     Train net output #0: loss = 0.238095 (* 1 = 0.238095 loss)
I0701 14:32:34.957437 30423 sgd_solver.cpp:106] Iteration 12100, lr = 0.0810938
I0701 14:32:37.013586 30423 solver.cpp:290] Iteration 12200 (48.6359 iter/s, 2.05609s/100 iter), loss = -3.18885e-06
I0701 14:32:37.013607 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:32:37.013614 30423 sgd_solver.cpp:106] Iteration 12200, lr = 0.0809375
I0701 14:32:39.066406 30423 solver.cpp:290] Iteration 12300 (48.7155 iter/s, 2.05273s/100 iter), loss = -3.15905e-06
I0701 14:32:39.066428 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:32:39.066434 30423 sgd_solver.cpp:106] Iteration 12300, lr = 0.0807813
I0701 14:32:41.122357 30423 solver.cpp:290] Iteration 12400 (48.6412 iter/s, 2.05587s/100 iter), loss = 0.476187
I0701 14:32:41.122380 30423 solver.cpp:309]     Train net output #0: loss = 0.47619 (* 1 = 0.47619 loss)
I0701 14:32:41.122390 30423 sgd_solver.cpp:106] Iteration 12400, lr = 0.080625
I0701 14:32:43.176430 30423 solver.cpp:290] Iteration 12500 (48.6858 iter/s, 2.05399s/100 iter), loss = 0.0476159
I0701 14:32:43.176455 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:32:43.176463 30423 sgd_solver.cpp:106] Iteration 12500, lr = 0.0804688
I0701 14:32:45.233649 30423 solver.cpp:290] Iteration 12600 (48.6113 iter/s, 2.05713s/100 iter), loss = 0.190473
I0701 14:32:45.233701 30423 solver.cpp:309]     Train net output #0: loss = 0.190476 (* 1 = 0.190476 loss)
I0701 14:32:45.233716 30423 sgd_solver.cpp:106] Iteration 12600, lr = 0.0803125
I0701 14:32:47.290693 30423 solver.cpp:290] Iteration 12700 (48.6161 iter/s, 2.05693s/100 iter), loss = 0.142854
I0701 14:32:47.290715 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:32:47.290721 30423 sgd_solver.cpp:106] Iteration 12700, lr = 0.0801563
I0701 14:32:49.344558 30423 solver.cpp:290] Iteration 12800 (48.6907 iter/s, 2.05378s/100 iter), loss = -3.18885e-06
I0701 14:32:49.344581 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:32:49.344588 30423 sgd_solver.cpp:106] Iteration 12800, lr = 0.08
I0701 14:32:51.403223 30423 solver.cpp:290] Iteration 12900 (48.5772 iter/s, 2.05858s/100 iter), loss = 0.285711
I0701 14:32:51.403244 30423 solver.cpp:309]     Train net output #0: loss = 0.285714 (* 1 = 0.285714 loss)
I0701 14:32:51.403250 30423 sgd_solver.cpp:106] Iteration 12900, lr = 0.0798438
I0701 14:32:53.437975 30423 solver.cpp:473] Iteration 13000, Testing net (#0)
I0701 14:32:55.074370 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.7142
I0701 14:32:55.074393 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9782
I0701 14:32:55.074398 30423 solver.cpp:546]     Test net output #2: loss = 0.9118 (* 1 = 0.9118 loss)
I0701 14:32:55.094656 30423 solver.cpp:290] Iteration 13000 (27.0907 iter/s, 3.69131s/100 iter), loss = 0.0952349
I0701 14:32:55.094674 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:32:55.094687 30423 sgd_solver.cpp:106] Iteration 13000, lr = 0.0796875
I0701 14:32:57.182817 30423 solver.cpp:290] Iteration 13100 (47.8909 iter/s, 2.08808s/100 iter), loss = 0.0952349
I0701 14:32:57.182839 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:32:57.182847 30423 sgd_solver.cpp:106] Iteration 13100, lr = 0.0795313
I0701 14:32:59.236064 30423 solver.cpp:290] Iteration 13200 (48.7054 iter/s, 2.05316s/100 iter), loss = 0.0476158
I0701 14:32:59.236086 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:32:59.236093 30423 sgd_solver.cpp:106] Iteration 13200, lr = 0.079375
I0701 14:33:01.291621 30423 solver.cpp:290] Iteration 13300 (48.6506 iter/s, 2.05547s/100 iter), loss = 0.0952349
I0701 14:33:01.291646 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:33:01.291654 30423 sgd_solver.cpp:106] Iteration 13300, lr = 0.0792188
I0701 14:33:03.344384 30423 solver.cpp:290] Iteration 13400 (48.7169 iter/s, 2.05268s/100 iter), loss = 0.190473
I0701 14:33:03.344406 30423 solver.cpp:309]     Train net output #0: loss = 0.190476 (* 1 = 0.190476 loss)
I0701 14:33:03.344413 30423 sgd_solver.cpp:106] Iteration 13400, lr = 0.0790625
I0701 14:33:05.401701 30423 solver.cpp:290] Iteration 13500 (48.609 iter/s, 2.05723s/100 iter), loss = -3.21865e-06
I0701 14:33:05.401724 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:33:05.401731 30423 sgd_solver.cpp:106] Iteration 13500, lr = 0.0789063
I0701 14:33:07.457849 30423 solver.cpp:290] Iteration 13600 (48.6367 iter/s, 2.05606s/100 iter), loss = -3.23355e-06
I0701 14:33:07.457872 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:33:07.457878 30423 sgd_solver.cpp:106] Iteration 13600, lr = 0.07875
I0701 14:33:09.510941 30423 solver.cpp:290] Iteration 13700 (48.7091 iter/s, 2.05301s/100 iter), loss = -3.22238e-06
I0701 14:33:09.510963 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:33:09.510972 30423 sgd_solver.cpp:106] Iteration 13700, lr = 0.0785938
I0701 14:33:11.566463 30423 solver.cpp:290] Iteration 13800 (48.6514 iter/s, 2.05544s/100 iter), loss = 0.0952349
I0701 14:33:11.566488 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:33:11.566493 30423 sgd_solver.cpp:106] Iteration 13800, lr = 0.0784375
I0701 14:33:13.621489 30423 solver.cpp:290] Iteration 13900 (48.6634 iter/s, 2.05493s/100 iter), loss = -3.17395e-06
I0701 14:33:13.621529 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:33:13.621537 30423 sgd_solver.cpp:106] Iteration 13900, lr = 0.0782812
I0701 14:33:15.658495 30423 solver.cpp:473] Iteration 14000, Testing net (#0)
I0701 14:33:17.295035 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.7197
I0701 14:33:17.295053 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9706
I0701 14:33:17.295059 30423 solver.cpp:546]     Test net output #2: loss = 0.996 (* 1 = 0.996 loss)
I0701 14:33:17.315524 30423 solver.cpp:290] Iteration 14000 (27.0717 iter/s, 3.69389s/100 iter), loss = -3.18885e-06
I0701 14:33:17.315542 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:33:17.315556 30423 sgd_solver.cpp:106] Iteration 14000, lr = 0.078125
I0701 14:33:19.369937 30423 solver.cpp:290] Iteration 14100 (48.6776 iter/s, 2.05433s/100 iter), loss = 0.476187
I0701 14:33:19.369959 30423 solver.cpp:309]     Train net output #0: loss = 0.47619 (* 1 = 0.47619 loss)
I0701 14:33:19.369966 30423 sgd_solver.cpp:106] Iteration 14100, lr = 0.0779688
I0701 14:33:21.421509 30423 solver.cpp:290] Iteration 14200 (48.7451 iter/s, 2.05149s/100 iter), loss = 0.0476159
I0701 14:33:21.421533 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:33:21.421542 30423 sgd_solver.cpp:106] Iteration 14200, lr = 0.0778125
I0701 14:33:23.482614 30423 solver.cpp:290] Iteration 14300 (48.5197 iter/s, 2.06102s/100 iter), loss = 0.0952349
I0701 14:33:23.482640 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:33:23.482647 30423 sgd_solver.cpp:106] Iteration 14300, lr = 0.0776563
I0701 14:33:25.540495 30423 solver.cpp:290] Iteration 14400 (48.5957 iter/s, 2.0578s/100 iter), loss = -3.26335e-06
I0701 14:33:25.540518 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:33:25.540524 30423 sgd_solver.cpp:106] Iteration 14400, lr = 0.0775
I0701 14:33:27.602314 30423 solver.cpp:290] Iteration 14500 (48.5029 iter/s, 2.06173s/100 iter), loss = 0.380949
I0701 14:33:27.602340 30423 solver.cpp:309]     Train net output #0: loss = 0.380952 (* 1 = 0.380952 loss)
I0701 14:33:27.602349 30423 sgd_solver.cpp:106] Iteration 14500, lr = 0.0773438
I0701 14:33:29.658162 30423 solver.cpp:290] Iteration 14600 (48.6438 iter/s, 2.05576s/100 iter), loss = -3.24845e-06
I0701 14:33:29.658185 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:33:29.658191 30423 sgd_solver.cpp:106] Iteration 14600, lr = 0.0771875
I0701 14:33:31.711897 30423 solver.cpp:290] Iteration 14700 (48.6938 iter/s, 2.05365s/100 iter), loss = 0.142854
I0701 14:33:31.711920 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:33:31.711926 30423 sgd_solver.cpp:106] Iteration 14700, lr = 0.0770312
I0701 14:33:33.764570 30423 solver.cpp:290] Iteration 14800 (48.7189 iter/s, 2.05259s/100 iter), loss = -3.24845e-06
I0701 14:33:33.764595 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:33:33.764603 30423 sgd_solver.cpp:106] Iteration 14800, lr = 0.076875
I0701 14:33:35.818753 30423 solver.cpp:290] Iteration 14900 (48.6832 iter/s, 2.0541s/100 iter), loss = -3.24845e-06
I0701 14:33:35.818774 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:33:35.818783 30423 sgd_solver.cpp:106] Iteration 14900, lr = 0.0767187
I0701 14:33:37.852172 30423 solver.cpp:473] Iteration 15000, Testing net (#0)
I0701 14:33:39.490265 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.6644
I0701 14:33:39.490286 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.967
I0701 14:33:39.490293 30423 solver.cpp:546]     Test net output #2: loss = 1.2482 (* 1 = 1.2482 loss)
I0701 14:33:39.509904 30423 solver.cpp:290] Iteration 15000 (27.0927 iter/s, 3.69103s/100 iter), loss = -3.23355e-06
I0701 14:33:39.509924 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:33:39.509935 30423 sgd_solver.cpp:106] Iteration 15000, lr = 0.0765625
I0701 14:33:41.566304 30423 solver.cpp:290] Iteration 15100 (48.6306 iter/s, 2.05632s/100 iter), loss = 0.142854
I0701 14:33:41.566328 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:33:41.566351 30423 sgd_solver.cpp:106] Iteration 15100, lr = 0.0764063
I0701 14:33:43.622663 30423 solver.cpp:290] Iteration 15200 (48.6317 iter/s, 2.05627s/100 iter), loss = 0.142854
I0701 14:33:43.622684 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:33:43.622691 30423 sgd_solver.cpp:106] Iteration 15200, lr = 0.07625
I0701 14:33:45.683280 30423 solver.cpp:290] Iteration 15300 (48.5312 iter/s, 2.06053s/100 iter), loss = 0.142854
I0701 14:33:45.683354 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:33:45.683367 30423 sgd_solver.cpp:106] Iteration 15300, lr = 0.0760938
I0701 14:33:47.737301 30423 solver.cpp:290] Iteration 15400 (48.6881 iter/s, 2.05389s/100 iter), loss = -3.30806e-06
I0701 14:33:47.737323 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:33:47.737330 30423 sgd_solver.cpp:106] Iteration 15400, lr = 0.0759375
I0701 14:33:49.793222 30423 solver.cpp:290] Iteration 15500 (48.642 iter/s, 2.05584s/100 iter), loss = 0.0476157
I0701 14:33:49.793246 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:33:49.793252 30423 sgd_solver.cpp:106] Iteration 15500, lr = 0.0757812
I0701 14:33:51.867745 30423 solver.cpp:290] Iteration 15600 (48.2058 iter/s, 2.07444s/100 iter), loss = 0.0476158
I0701 14:33:51.867769 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:33:51.867775 30423 sgd_solver.cpp:106] Iteration 15600, lr = 0.075625
I0701 14:33:53.923768 30423 solver.cpp:290] Iteration 15700 (48.6396 iter/s, 2.05594s/100 iter), loss = -3.31551e-06
I0701 14:33:53.923790 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:33:53.923797 30423 sgd_solver.cpp:106] Iteration 15700, lr = 0.0754687
I0701 14:33:55.977833 30423 solver.cpp:290] Iteration 15800 (48.6859 iter/s, 2.05398s/100 iter), loss = 0.142854
I0701 14:33:55.977854 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:33:55.977862 30423 sgd_solver.cpp:106] Iteration 15800, lr = 0.0753125
I0701 14:33:58.066234 30423 solver.cpp:290] Iteration 15900 (47.8855 iter/s, 2.08832s/100 iter), loss = 0.238092
I0701 14:33:58.066257 30423 solver.cpp:309]     Train net output #0: loss = 0.238095 (* 1 = 0.238095 loss)
I0701 14:33:58.066264 30423 sgd_solver.cpp:106] Iteration 15900, lr = 0.0751562
I0701 14:34:00.099870 30423 solver.cpp:473] Iteration 16000, Testing net (#0)
I0701 14:34:01.738422 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8027
I0701 14:34:01.738441 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9901
I0701 14:34:01.738448 30423 solver.cpp:546]     Test net output #2: loss = 0.5056 (* 1 = 0.5056 loss)
I0701 14:34:01.759074 30423 solver.cpp:290] Iteration 16000 (27.0803 iter/s, 3.69272s/100 iter), loss = -3.36766e-06
I0701 14:34:01.759093 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:34:01.759104 30423 sgd_solver.cpp:106] Iteration 16000, lr = 0.075
I0701 14:34:03.811569 30423 solver.cpp:290] Iteration 16100 (48.7231 iter/s, 2.05242s/100 iter), loss = -3.38256e-06
I0701 14:34:03.811592 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:34:03.811600 30423 sgd_solver.cpp:106] Iteration 16100, lr = 0.0748438
I0701 14:34:05.863338 30423 solver.cpp:290] Iteration 16200 (48.7404 iter/s, 2.05168s/100 iter), loss = 0.33333
I0701 14:34:05.863361 30423 solver.cpp:309]     Train net output #0: loss = 0.333333 (* 1 = 0.333333 loss)
I0701 14:34:05.863368 30423 sgd_solver.cpp:106] Iteration 16200, lr = 0.0746875
I0701 14:34:07.916287 30423 solver.cpp:290] Iteration 16300 (48.7124 iter/s, 2.05287s/100 iter), loss = 0.190473
I0701 14:34:07.916309 30423 solver.cpp:309]     Train net output #0: loss = 0.190476 (* 1 = 0.190476 loss)
I0701 14:34:07.916316 30423 sgd_solver.cpp:106] Iteration 16300, lr = 0.0745312
I0701 14:34:09.971415 30423 solver.cpp:290] Iteration 16400 (48.6607 iter/s, 2.05505s/100 iter), loss = 0.0476157
I0701 14:34:09.971439 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:34:09.971448 30423 sgd_solver.cpp:106] Iteration 16400, lr = 0.074375
I0701 14:34:12.032232 30423 solver.cpp:290] Iteration 16500 (48.5266 iter/s, 2.06073s/100 iter), loss = 0.0476157
I0701 14:34:12.032261 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:34:12.032270 30423 sgd_solver.cpp:106] Iteration 16500, lr = 0.0742188
I0701 14:34:14.092555 30423 solver.cpp:290] Iteration 16600 (48.5382 iter/s, 2.06023s/100 iter), loss = 0.0952347
I0701 14:34:14.092581 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:34:14.092586 30423 sgd_solver.cpp:106] Iteration 16600, lr = 0.0740625
I0701 14:34:16.144800 30423 solver.cpp:290] Iteration 16700 (48.7292 iter/s, 2.05216s/100 iter), loss = 0.142854
I0701 14:34:16.144846 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:34:16.144855 30423 sgd_solver.cpp:106] Iteration 16700, lr = 0.0739063
I0701 14:34:18.200038 30423 solver.cpp:290] Iteration 16800 (48.6587 iter/s, 2.05513s/100 iter), loss = -3.44589e-06
I0701 14:34:18.200059 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:34:18.200067 30423 sgd_solver.cpp:106] Iteration 16800, lr = 0.07375
I0701 14:34:20.255240 30423 solver.cpp:290] Iteration 16900 (48.659 iter/s, 2.05512s/100 iter), loss = 0.285711
I0701 14:34:20.255264 30423 solver.cpp:309]     Train net output #0: loss = 0.285714 (* 1 = 0.285714 loss)
I0701 14:34:20.255272 30423 sgd_solver.cpp:106] Iteration 16900, lr = 0.0735938
I0701 14:34:22.293376 30423 solver.cpp:473] Iteration 17000, Testing net (#0)
I0701 14:34:23.930956 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.7954
I0701 14:34:23.930974 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9886
I0701 14:34:23.930980 30423 solver.cpp:546]     Test net output #2: loss = 0.5607 (* 1 = 0.5607 loss)
I0701 14:34:23.950902 30423 solver.cpp:290] Iteration 17000 (27.0597 iter/s, 3.69554s/100 iter), loss = -3.50177e-06
I0701 14:34:23.950918 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:34:23.950937 30423 sgd_solver.cpp:106] Iteration 17000, lr = 0.0734375
I0701 14:34:26.005878 30423 solver.cpp:290] Iteration 17100 (48.6642 iter/s, 2.0549s/100 iter), loss = -3.48687e-06
I0701 14:34:26.005900 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:34:26.005908 30423 sgd_solver.cpp:106] Iteration 17100, lr = 0.0732813
I0701 14:34:28.059255 30423 solver.cpp:290] Iteration 17200 (48.7023 iter/s, 2.05329s/100 iter), loss = 0.380949
I0701 14:34:28.059276 30423 solver.cpp:309]     Train net output #0: loss = 0.380952 (* 1 = 0.380952 loss)
I0701 14:34:28.059285 30423 sgd_solver.cpp:106] Iteration 17200, lr = 0.073125
I0701 14:34:30.114948 30423 solver.cpp:290] Iteration 17300 (48.6474 iter/s, 2.05561s/100 iter), loss = -3.51667e-06
I0701 14:34:30.114970 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:34:30.114977 30423 sgd_solver.cpp:106] Iteration 17300, lr = 0.0729688
I0701 14:34:32.167876 30423 solver.cpp:290] Iteration 17400 (48.7129 iter/s, 2.05284s/100 iter), loss = -3.5204e-06
I0701 14:34:32.167897 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:34:32.167904 30423 sgd_solver.cpp:106] Iteration 17400, lr = 0.0728125
I0701 14:34:34.227015 30423 solver.cpp:290] Iteration 17500 (48.5659 iter/s, 2.05906s/100 iter), loss = -3.51667e-06
I0701 14:34:34.227037 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:34:34.227043 30423 sgd_solver.cpp:106] Iteration 17500, lr = 0.0726563
I0701 14:34:36.288242 30423 solver.cpp:290] Iteration 17600 (48.5167 iter/s, 2.06114s/100 iter), loss = -3.56138e-06
I0701 14:34:36.288264 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:34:36.288271 30423 sgd_solver.cpp:106] Iteration 17600, lr = 0.0725
I0701 14:34:38.342345 30423 solver.cpp:290] Iteration 17700 (48.685 iter/s, 2.05402s/100 iter), loss = 0.0476155
I0701 14:34:38.342368 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:34:38.342377 30423 sgd_solver.cpp:106] Iteration 17700, lr = 0.0723438
I0701 14:34:40.396157 30423 solver.cpp:290] Iteration 17800 (48.692 iter/s, 2.05373s/100 iter), loss = 0.0952346
I0701 14:34:40.396181 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:34:40.396188 30423 sgd_solver.cpp:106] Iteration 17800, lr = 0.0721875
I0701 14:34:42.453011 30423 solver.cpp:290] Iteration 17900 (48.62 iter/s, 2.05677s/100 iter), loss = -3.56138e-06
I0701 14:34:42.453032 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:34:42.453038 30423 sgd_solver.cpp:106] Iteration 17900, lr = 0.0720313
I0701 14:34:44.491569 30423 solver.cpp:473] Iteration 18000, Testing net (#0)
I0701 14:34:46.127905 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.7827
I0701 14:34:46.127924 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9892
I0701 14:34:46.127930 30423 solver.cpp:546]     Test net output #2: loss = 0.7233 (* 1 = 0.7233 loss)
I0701 14:34:46.147784 30423 solver.cpp:290] Iteration 18000 (27.0662 iter/s, 3.69465s/100 iter), loss = 0.285711
I0701 14:34:46.147881 30423 solver.cpp:309]     Train net output #0: loss = 0.285714 (* 1 = 0.285714 loss)
I0701 14:34:46.147891 30423 sgd_solver.cpp:106] Iteration 18000, lr = 0.071875
I0701 14:34:48.202055 30423 solver.cpp:290] Iteration 18100 (48.6827 iter/s, 2.05412s/100 iter), loss = -3.53158e-06
I0701 14:34:48.202078 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:34:48.202085 30423 sgd_solver.cpp:106] Iteration 18100, lr = 0.0717188
I0701 14:34:50.256012 30423 solver.cpp:290] Iteration 18200 (48.6885 iter/s, 2.05387s/100 iter), loss = 0.0476155
I0701 14:34:50.256034 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:34:50.256042 30423 sgd_solver.cpp:106] Iteration 18200, lr = 0.0715625
I0701 14:34:52.311933 30423 solver.cpp:290] Iteration 18300 (48.642 iter/s, 2.05584s/100 iter), loss = 0.0952345
I0701 14:34:52.311955 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:34:52.311961 30423 sgd_solver.cpp:106] Iteration 18300, lr = 0.0714063
I0701 14:34:54.369238 30423 solver.cpp:290] Iteration 18400 (48.6092 iter/s, 2.05722s/100 iter), loss = 0.0476155
I0701 14:34:54.369261 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:34:54.369267 30423 sgd_solver.cpp:106] Iteration 18400, lr = 0.07125
I0701 14:34:56.423810 30423 solver.cpp:290] Iteration 18500 (48.674 iter/s, 2.05449s/100 iter), loss = -3.59863e-06
I0701 14:34:56.423831 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:34:56.423840 30423 sgd_solver.cpp:106] Iteration 18500, lr = 0.0710938
I0701 14:34:58.508047 30423 solver.cpp:290] Iteration 18600 (47.9811 iter/s, 2.08415s/100 iter), loss = 0.0952345
I0701 14:34:58.508072 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:34:58.508081 30423 sgd_solver.cpp:106] Iteration 18600, lr = 0.0709375
I0701 14:35:00.562062 30423 solver.cpp:290] Iteration 18700 (48.6872 iter/s, 2.05393s/100 iter), loss = -3.60608e-06
I0701 14:35:00.562084 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:35:00.562093 30423 sgd_solver.cpp:106] Iteration 18700, lr = 0.0707813
I0701 14:35:02.617220 30423 solver.cpp:290] Iteration 18800 (48.6601 iter/s, 2.05507s/100 iter), loss = 0.0476154
I0701 14:35:02.617241 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:35:02.617249 30423 sgd_solver.cpp:106] Iteration 18800, lr = 0.070625
I0701 14:35:04.672415 30423 solver.cpp:290] Iteration 18900 (48.6591 iter/s, 2.05511s/100 iter), loss = -3.60608e-06
I0701 14:35:04.672437 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:35:04.672446 30423 sgd_solver.cpp:106] Iteration 18900, lr = 0.0704687
I0701 14:35:06.706682 30423 solver.cpp:473] Iteration 19000, Testing net (#0)
I0701 14:35:08.344454 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8114
I0701 14:35:08.344473 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9895
I0701 14:35:08.344481 30423 solver.cpp:546]     Test net output #2: loss = 0.5442 (* 1 = 0.5442 loss)
I0701 14:35:08.364789 30423 solver.cpp:290] Iteration 19000 (27.0838 iter/s, 3.69225s/100 iter), loss = -3.62098e-06
I0701 14:35:08.364809 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:35:08.364820 30423 sgd_solver.cpp:106] Iteration 19000, lr = 0.0703125
I0701 14:35:10.419517 30423 solver.cpp:290] Iteration 19100 (48.6702 iter/s, 2.05465s/100 iter), loss = 0.0476154
I0701 14:35:10.419540 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:35:10.419548 30423 sgd_solver.cpp:106] Iteration 19100, lr = 0.0701563
I0701 14:35:12.476953 30423 solver.cpp:290] Iteration 19200 (48.6062 iter/s, 2.05735s/100 iter), loss = 0.0476154
I0701 14:35:12.476976 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:35:12.476984 30423 sgd_solver.cpp:106] Iteration 19200, lr = 0.07
I0701 14:35:14.530594 30423 solver.cpp:290] Iteration 19300 (48.696 iter/s, 2.05356s/100 iter), loss = -3.60608e-06
I0701 14:35:14.530618 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:35:14.530624 30423 sgd_solver.cpp:106] Iteration 19300, lr = 0.0698438
I0701 14:35:16.589926 30423 solver.cpp:290] Iteration 19400 (48.5615 iter/s, 2.05925s/100 iter), loss = 0.0476154
I0701 14:35:16.589987 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:35:16.589996 30423 sgd_solver.cpp:106] Iteration 19400, lr = 0.0696875
I0701 14:35:18.645892 30423 solver.cpp:290] Iteration 19500 (48.6418 iter/s, 2.05585s/100 iter), loss = 0.190473
I0701 14:35:18.645913 30423 solver.cpp:309]     Train net output #0: loss = 0.190476 (* 1 = 0.190476 loss)
I0701 14:35:18.645920 30423 sgd_solver.cpp:106] Iteration 19500, lr = 0.0695313
I0701 14:35:20.699131 30423 solver.cpp:290] Iteration 19600 (48.7055 iter/s, 2.05316s/100 iter), loss = -3.68059e-06
I0701 14:35:20.699154 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:35:20.699162 30423 sgd_solver.cpp:106] Iteration 19600, lr = 0.069375
I0701 14:35:22.756664 30423 solver.cpp:290] Iteration 19700 (48.6039 iter/s, 2.05745s/100 iter), loss = 0.0476154
I0701 14:35:22.756688 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:35:22.756695 30423 sgd_solver.cpp:106] Iteration 19700, lr = 0.0692187
I0701 14:35:24.813423 30423 solver.cpp:290] Iteration 19800 (48.6222 iter/s, 2.05667s/100 iter), loss = -3.66569e-06
I0701 14:35:24.813444 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:35:24.813453 30423 sgd_solver.cpp:106] Iteration 19800, lr = 0.0690625
I0701 14:35:26.872591 30423 solver.cpp:290] Iteration 19900 (48.5653 iter/s, 2.05908s/100 iter), loss = -3.71039e-06
I0701 14:35:26.872613 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:35:26.872620 30423 sgd_solver.cpp:106] Iteration 19900, lr = 0.0689062
I0701 14:35:28.907559 30423 solver.cpp:600] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/initial/cifar10_jacintonet11v2_iter_20000.caffemodel
I0701 14:35:28.924340 30423 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/initial/cifar10_jacintonet11v2_iter_20000.solverstate
I0701 14:35:28.931721 30423 solver.cpp:473] Iteration 20000, Testing net (#0)
I0701 14:35:30.567507 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8185
I0701 14:35:30.567526 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9914
I0701 14:35:30.567531 30423 solver.cpp:546]     Test net output #2: loss = 0.4478 (* 1 = 0.4478 loss)
I0701 14:35:30.587186 30423 solver.cpp:290] Iteration 20000 (26.9217 iter/s, 3.71447s/100 iter), loss = 0.0952344
I0701 14:35:30.587203 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:35:30.587215 30423 sgd_solver.cpp:106] Iteration 20000, lr = 0.06875
I0701 14:35:32.642802 30423 solver.cpp:290] Iteration 20100 (48.6491 iter/s, 2.05554s/100 iter), loss = 0.0476153
I0701 14:35:32.642823 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:35:32.642830 30423 sgd_solver.cpp:106] Iteration 20100, lr = 0.0685938
I0701 14:35:34.696338 30423 solver.cpp:290] Iteration 20200 (48.6984 iter/s, 2.05345s/100 iter), loss = 0.142853
I0701 14:35:34.696359 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:35:34.696367 30423 sgd_solver.cpp:106] Iteration 20200, lr = 0.0684375
I0701 14:35:36.751559 30423 solver.cpp:290] Iteration 20300 (48.6585 iter/s, 2.05514s/100 iter), loss = 0.190472
I0701 14:35:36.751580 30423 solver.cpp:309]     Train net output #0: loss = 0.190476 (* 1 = 0.190476 loss)
I0701 14:35:36.751587 30423 sgd_solver.cpp:106] Iteration 20300, lr = 0.0682813
I0701 14:35:38.804764 30423 solver.cpp:290] Iteration 20400 (48.7063 iter/s, 2.05312s/100 iter), loss = -3.7998e-06
I0701 14:35:38.804786 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:35:38.804793 30423 sgd_solver.cpp:106] Iteration 20400, lr = 0.068125
I0701 14:35:40.861156 30423 solver.cpp:290] Iteration 20500 (48.6309 iter/s, 2.05631s/100 iter), loss = -3.7998e-06
I0701 14:35:40.861178 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:35:40.861202 30423 sgd_solver.cpp:106] Iteration 20500, lr = 0.0679687
I0701 14:35:42.916553 30423 solver.cpp:290] Iteration 20600 (48.6544 iter/s, 2.05531s/100 iter), loss = -3.78489e-06
I0701 14:35:42.916575 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:35:42.916582 30423 sgd_solver.cpp:106] Iteration 20600, lr = 0.0678125
I0701 14:35:44.977324 30423 solver.cpp:290] Iteration 20700 (48.5275 iter/s, 2.06069s/100 iter), loss = -3.78489e-06
I0701 14:35:44.977345 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:35:44.977352 30423 sgd_solver.cpp:106] Iteration 20700, lr = 0.0676562
I0701 14:35:47.030750 30423 solver.cpp:290] Iteration 20800 (48.7011 iter/s, 2.05334s/100 iter), loss = 0.0476153
I0701 14:35:47.030817 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:35:47.030825 30423 sgd_solver.cpp:106] Iteration 20800, lr = 0.0675
I0701 14:35:49.088531 30423 solver.cpp:290] Iteration 20900 (48.599 iter/s, 2.05766s/100 iter), loss = 0.142853
I0701 14:35:49.088552 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:35:49.088560 30423 sgd_solver.cpp:106] Iteration 20900, lr = 0.0673437
I0701 14:35:51.122205 30423 solver.cpp:473] Iteration 21000, Testing net (#0)
I0701 14:35:52.759627 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.783
I0701 14:35:52.759645 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9862
I0701 14:35:52.759651 30423 solver.cpp:546]     Test net output #2: loss = 0.6548 (* 1 = 0.6548 loss)
I0701 14:35:52.779304 30423 solver.cpp:290] Iteration 21000 (27.0955 iter/s, 3.69065s/100 iter), loss = -3.78489e-06
I0701 14:35:52.779325 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:35:52.779333 30423 sgd_solver.cpp:106] Iteration 21000, lr = 0.0671875
I0701 14:35:54.833004 30423 solver.cpp:290] Iteration 21100 (48.6946 iter/s, 2.05362s/100 iter), loss = 0.190472
I0701 14:35:54.833026 30423 solver.cpp:309]     Train net output #0: loss = 0.190476 (* 1 = 0.190476 loss)
I0701 14:35:54.833034 30423 sgd_solver.cpp:106] Iteration 21100, lr = 0.0670313
I0701 14:35:56.927000 30423 solver.cpp:290] Iteration 21200 (47.7575 iter/s, 2.09391s/100 iter), loss = 0.142853
I0701 14:35:56.927021 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:35:56.927027 30423 sgd_solver.cpp:106] Iteration 21200, lr = 0.066875
I0701 14:35:58.989661 30423 solver.cpp:290] Iteration 21300 (48.483 iter/s, 2.06258s/100 iter), loss = 0.238091
I0701 14:35:58.989686 30423 solver.cpp:309]     Train net output #0: loss = 0.238095 (* 1 = 0.238095 loss)
I0701 14:35:58.989692 30423 sgd_solver.cpp:106] Iteration 21300, lr = 0.0667187
I0701 14:36:01.041981 30423 solver.cpp:290] Iteration 21400 (48.7274 iter/s, 2.05224s/100 iter), loss = -3.78489e-06
I0701 14:36:01.042003 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:36:01.042011 30423 sgd_solver.cpp:106] Iteration 21400, lr = 0.0665625
I0701 14:36:03.095954 30423 solver.cpp:290] Iteration 21500 (48.6881 iter/s, 2.05389s/100 iter), loss = 0.190472
I0701 14:36:03.095983 30423 solver.cpp:309]     Train net output #0: loss = 0.190476 (* 1 = 0.190476 loss)
I0701 14:36:03.095991 30423 sgd_solver.cpp:106] Iteration 21500, lr = 0.0664062
I0701 14:36:05.152608 30423 solver.cpp:290] Iteration 21600 (48.6248 iter/s, 2.05656s/100 iter), loss = 0.0476153
I0701 14:36:05.152634 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:36:05.152643 30423 sgd_solver.cpp:106] Iteration 21600, lr = 0.06625
I0701 14:36:07.206372 30423 solver.cpp:290] Iteration 21700 (48.6931 iter/s, 2.05368s/100 iter), loss = -3.80725e-06
I0701 14:36:07.206396 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:36:07.206405 30423 sgd_solver.cpp:106] Iteration 21700, lr = 0.0660938
I0701 14:36:09.260105 30423 solver.cpp:290] Iteration 21800 (48.6938 iter/s, 2.05365s/100 iter), loss = 0.190472
I0701 14:36:09.260128 30423 solver.cpp:309]     Train net output #0: loss = 0.190476 (* 1 = 0.190476 loss)
I0701 14:36:09.260135 30423 sgd_solver.cpp:106] Iteration 21800, lr = 0.0659375
I0701 14:36:11.317350 30423 solver.cpp:290] Iteration 21900 (48.6107 iter/s, 2.05716s/100 iter), loss = 0.190472
I0701 14:36:11.317373 30423 solver.cpp:309]     Train net output #0: loss = 0.190476 (* 1 = 0.190476 loss)
I0701 14:36:11.317380 30423 sgd_solver.cpp:106] Iteration 21900, lr = 0.0657813
I0701 14:36:13.353447 30423 solver.cpp:473] Iteration 22000, Testing net (#0)
I0701 14:36:14.993654 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.7118
I0701 14:36:14.993671 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.942201
I0701 14:36:14.993677 30423 solver.cpp:546]     Test net output #2: loss = 1.4105 (* 1 = 1.4105 loss)
I0701 14:36:15.013836 30423 solver.cpp:290] Iteration 22000 (27.0537 iter/s, 3.69636s/100 iter), loss = 0.190472
I0701 14:36:15.013859 30423 solver.cpp:309]     Train net output #0: loss = 0.190476 (* 1 = 0.190476 loss)
I0701 14:36:15.013864 30423 sgd_solver.cpp:106] Iteration 22000, lr = 0.065625
I0701 14:36:17.075172 30423 solver.cpp:290] Iteration 22100 (48.5142 iter/s, 2.06125s/100 iter), loss = -3.78489e-06
I0701 14:36:17.075239 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:36:17.075248 30423 sgd_solver.cpp:106] Iteration 22100, lr = 0.0654688
I0701 14:36:19.130779 30423 solver.cpp:290] Iteration 22200 (48.6504 iter/s, 2.05548s/100 iter), loss = 0.428568
I0701 14:36:19.130800 30423 solver.cpp:309]     Train net output #0: loss = 0.428571 (* 1 = 0.428571 loss)
I0701 14:36:19.130808 30423 sgd_solver.cpp:106] Iteration 22200, lr = 0.0653125
I0701 14:36:21.184859 30423 solver.cpp:290] Iteration 22300 (48.6855 iter/s, 2.054s/100 iter), loss = 0.0952343
I0701 14:36:21.184881 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:36:21.184888 30423 sgd_solver.cpp:106] Iteration 22300, lr = 0.0651563
I0701 14:36:23.239513 30423 solver.cpp:290] Iteration 22400 (48.672 iter/s, 2.05457s/100 iter), loss = 0.0476152
I0701 14:36:23.239534 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:36:23.239543 30423 sgd_solver.cpp:106] Iteration 22400, lr = 0.065
I0701 14:36:25.296823 30423 solver.cpp:290] Iteration 22500 (48.6091 iter/s, 2.05723s/100 iter), loss = -3.7998e-06
I0701 14:36:25.296845 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:36:25.296854 30423 sgd_solver.cpp:106] Iteration 22500, lr = 0.0648438
I0701 14:36:27.353582 30423 solver.cpp:290] Iteration 22600 (48.6221 iter/s, 2.05668s/100 iter), loss = -3.78862e-06
I0701 14:36:27.353605 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:36:27.353611 30423 sgd_solver.cpp:106] Iteration 22600, lr = 0.0646875
I0701 14:36:29.410290 30423 solver.cpp:290] Iteration 22700 (48.6234 iter/s, 2.05662s/100 iter), loss = 0.142853
I0701 14:36:29.410310 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:36:29.410320 30423 sgd_solver.cpp:106] Iteration 22700, lr = 0.0645313
I0701 14:36:31.468050 30423 solver.cpp:290] Iteration 22800 (48.5985 iter/s, 2.05768s/100 iter), loss = 0.0476153
I0701 14:36:31.468071 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:36:31.468078 30423 sgd_solver.cpp:106] Iteration 22800, lr = 0.064375
I0701 14:36:33.529208 30423 solver.cpp:290] Iteration 22900 (48.5184 iter/s, 2.06108s/100 iter), loss = -3.80725e-06
I0701 14:36:33.529232 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:36:33.529242 30423 sgd_solver.cpp:106] Iteration 22900, lr = 0.0642188
I0701 14:36:35.566012 30423 solver.cpp:473] Iteration 23000, Testing net (#0)
I0701 14:36:37.206493 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8253
I0701 14:36:37.206511 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9917
I0701 14:36:37.206517 30423 solver.cpp:546]     Test net output #2: loss = 0.489 (* 1 = 0.489 loss)
I0701 14:36:37.226469 30423 solver.cpp:290] Iteration 23000 (27.048 iter/s, 3.69713s/100 iter), loss = -3.8445e-06
I0701 14:36:37.226493 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:36:37.226500 30423 sgd_solver.cpp:106] Iteration 23000, lr = 0.0640625
I0701 14:36:39.284320 30423 solver.cpp:290] Iteration 23100 (48.5964 iter/s, 2.05776s/100 iter), loss = 0.0476152
I0701 14:36:39.284346 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:36:39.284353 30423 sgd_solver.cpp:106] Iteration 23100, lr = 0.0639063
I0701 14:36:41.336263 30423 solver.cpp:290] Iteration 23200 (48.7364 iter/s, 2.05185s/100 iter), loss = -3.8594e-06
I0701 14:36:41.336289 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:36:41.336297 30423 sgd_solver.cpp:106] Iteration 23200, lr = 0.06375
I0701 14:36:43.390074 30423 solver.cpp:290] Iteration 23300 (48.692 iter/s, 2.05372s/100 iter), loss = -3.8594e-06
I0701 14:36:43.390097 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:36:43.390103 30423 sgd_solver.cpp:106] Iteration 23300, lr = 0.0635938
I0701 14:36:45.444902 30423 solver.cpp:290] Iteration 23400 (48.6679 iter/s, 2.05474s/100 iter), loss = -3.8445e-06
I0701 14:36:45.444943 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:36:45.444950 30423 sgd_solver.cpp:106] Iteration 23400, lr = 0.0634375
I0701 14:36:47.500128 30423 solver.cpp:290] Iteration 23500 (48.6588 iter/s, 2.05512s/100 iter), loss = -3.8445e-06
I0701 14:36:47.500190 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:36:47.500197 30423 sgd_solver.cpp:106] Iteration 23500, lr = 0.0632813
I0701 14:36:49.555815 30423 solver.cpp:290] Iteration 23600 (48.6484 iter/s, 2.05557s/100 iter), loss = 0.0476152
I0701 14:36:49.555838 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:36:49.555845 30423 sgd_solver.cpp:106] Iteration 23600, lr = 0.063125
I0701 14:36:51.609321 30423 solver.cpp:290] Iteration 23700 (48.6992 iter/s, 2.05342s/100 iter), loss = -3.8445e-06
I0701 14:36:51.609344 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:36:51.609351 30423 sgd_solver.cpp:106] Iteration 23700, lr = 0.0629688
I0701 14:36:53.665113 30423 solver.cpp:290] Iteration 23800 (48.6451 iter/s, 2.05571s/100 iter), loss = -3.86685e-06
I0701 14:36:53.665136 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:36:53.665143 30423 sgd_solver.cpp:106] Iteration 23800, lr = 0.0628125
I0701 14:36:55.719565 30423 solver.cpp:290] Iteration 23900 (48.6768 iter/s, 2.05437s/100 iter), loss = -3.8743e-06
I0701 14:36:55.719589 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:36:55.719599 30423 sgd_solver.cpp:106] Iteration 23900, lr = 0.0626562
I0701 14:36:57.790662 30423 solver.cpp:473] Iteration 24000, Testing net (#0)
I0701 14:36:59.430135 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.7536
I0701 14:36:59.430155 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9741
I0701 14:36:59.430161 30423 solver.cpp:546]     Test net output #2: loss = 0.9309 (* 1 = 0.9309 loss)
I0701 14:36:59.450628 30423 solver.cpp:290] Iteration 24000 (26.8029 iter/s, 3.73094s/100 iter), loss = 0.142853
I0701 14:36:59.450645 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:36:59.450659 30423 sgd_solver.cpp:106] Iteration 24000, lr = 0.0625
I0701 14:37:01.515327 30423 solver.cpp:290] Iteration 24100 (48.435 iter/s, 2.06462s/100 iter), loss = -3.92273e-06
I0701 14:37:01.515349 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:37:01.515357 30423 sgd_solver.cpp:106] Iteration 24100, lr = 0.0623438
I0701 14:37:03.571848 30423 solver.cpp:290] Iteration 24200 (48.6278 iter/s, 2.05644s/100 iter), loss = -3.9041e-06
I0701 14:37:03.571871 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:37:03.571879 30423 sgd_solver.cpp:106] Iteration 24200, lr = 0.0621875
I0701 14:37:05.636575 30423 solver.cpp:290] Iteration 24300 (48.4345 iter/s, 2.06464s/100 iter), loss = -3.9041e-06
I0701 14:37:05.636598 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:37:05.636605 30423 sgd_solver.cpp:106] Iteration 24300, lr = 0.0620313
I0701 14:37:07.694946 30423 solver.cpp:290] Iteration 24400 (48.5841 iter/s, 2.05829s/100 iter), loss = -3.9041e-06
I0701 14:37:07.694968 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:37:07.694977 30423 sgd_solver.cpp:106] Iteration 24400, lr = 0.061875
I0701 14:37:09.752938 30423 solver.cpp:290] Iteration 24500 (48.5931 iter/s, 2.05791s/100 iter), loss = -3.91901e-06
I0701 14:37:09.752959 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:37:09.752966 30423 sgd_solver.cpp:106] Iteration 24500, lr = 0.0617188
I0701 14:37:11.808773 30423 solver.cpp:290] Iteration 24600 (48.644 iter/s, 2.05575s/100 iter), loss = 0.0952342
I0701 14:37:11.808796 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:37:11.808805 30423 sgd_solver.cpp:106] Iteration 24600, lr = 0.0615625
I0701 14:37:13.864631 30423 solver.cpp:290] Iteration 24700 (48.6435 iter/s, 2.05577s/100 iter), loss = -3.96371e-06
I0701 14:37:13.864655 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:37:13.864665 30423 sgd_solver.cpp:106] Iteration 24700, lr = 0.0614063
I0701 14:37:15.923148 30423 solver.cpp:290] Iteration 24800 (48.5806 iter/s, 2.05843s/100 iter), loss = -3.96371e-06
I0701 14:37:15.923182 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:37:15.923192 30423 sgd_solver.cpp:106] Iteration 24800, lr = 0.06125
I0701 14:37:17.982218 30423 solver.cpp:290] Iteration 24900 (48.5678 iter/s, 2.05898s/100 iter), loss = 0.0476151
I0701 14:37:17.982287 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:37:17.982295 30423 sgd_solver.cpp:106] Iteration 24900, lr = 0.0610937
I0701 14:37:20.014924 30423 solver.cpp:473] Iteration 25000, Testing net (#0)
I0701 14:37:21.652508 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8403
I0701 14:37:21.652528 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9939
I0701 14:37:21.652535 30423 solver.cpp:546]     Test net output #2: loss = 0.385 (* 1 = 0.385 loss)
I0701 14:37:21.672225 30423 solver.cpp:290] Iteration 25000 (27.1015 iter/s, 3.68984s/100 iter), loss = -3.96743e-06
I0701 14:37:21.672245 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:37:21.672256 30423 sgd_solver.cpp:106] Iteration 25000, lr = 0.0609375
I0701 14:37:23.732628 30423 solver.cpp:290] Iteration 25100 (48.5361 iter/s, 2.06032s/100 iter), loss = -3.96371e-06
I0701 14:37:23.732650 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:37:23.732658 30423 sgd_solver.cpp:106] Iteration 25100, lr = 0.0607813
I0701 14:37:25.788234 30423 solver.cpp:290] Iteration 25200 (48.6494 iter/s, 2.05552s/100 iter), loss = -3.96371e-06
I0701 14:37:25.788257 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:37:25.788264 30423 sgd_solver.cpp:106] Iteration 25200, lr = 0.060625
I0701 14:37:27.841297 30423 solver.cpp:290] Iteration 25300 (48.7097 iter/s, 2.05298s/100 iter), loss = 0.0476151
I0701 14:37:27.841320 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:37:27.841326 30423 sgd_solver.cpp:106] Iteration 25300, lr = 0.0604688
I0701 14:37:29.897529 30423 solver.cpp:290] Iteration 25400 (48.6347 iter/s, 2.05615s/100 iter), loss = 0.0952341
I0701 14:37:29.897600 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:37:29.897631 30423 sgd_solver.cpp:106] Iteration 25400, lr = 0.0603125
I0701 14:37:31.958940 30423 solver.cpp:290] Iteration 25500 (48.5136 iter/s, 2.06128s/100 iter), loss = -3.97116e-06
I0701 14:37:31.958966 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:37:31.958974 30423 sgd_solver.cpp:106] Iteration 25500, lr = 0.0601563
I0701 14:37:34.014606 30423 solver.cpp:290] Iteration 25600 (48.6481 iter/s, 2.05558s/100 iter), loss = 0.0476151
I0701 14:37:34.014628 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:37:34.014636 30423 sgd_solver.cpp:106] Iteration 25600, lr = 0.06
I0701 14:37:36.073962 30423 solver.cpp:290] Iteration 25700 (48.5608 iter/s, 2.05927s/100 iter), loss = 0.0476151
I0701 14:37:36.073984 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:37:36.073992 30423 sgd_solver.cpp:106] Iteration 25700, lr = 0.0598437
I0701 14:37:38.130018 30423 solver.cpp:290] Iteration 25800 (48.6388 iter/s, 2.05597s/100 iter), loss = -3.96371e-06
I0701 14:37:38.130040 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:37:38.130048 30423 sgd_solver.cpp:106] Iteration 25800, lr = 0.0596875
I0701 14:37:40.183310 30423 solver.cpp:290] Iteration 25900 (48.7043 iter/s, 2.05321s/100 iter), loss = -3.98234e-06
I0701 14:37:40.183331 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:37:40.183339 30423 sgd_solver.cpp:106] Iteration 25900, lr = 0.0595312
I0701 14:37:42.218864 30423 solver.cpp:473] Iteration 26000, Testing net (#0)
I0701 14:37:43.860165 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8558
I0701 14:37:43.860184 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9932
I0701 14:37:43.860190 30423 solver.cpp:546]     Test net output #2: loss = 0.4122 (* 1 = 0.4122 loss)
I0701 14:37:43.879804 30423 solver.cpp:290] Iteration 26000 (27.0536 iter/s, 3.69637s/100 iter), loss = -3.97861e-06
I0701 14:37:43.879823 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:37:43.879832 30423 sgd_solver.cpp:106] Iteration 26000, lr = 0.059375
I0701 14:37:45.932833 30423 solver.cpp:290] Iteration 26100 (48.7105 iter/s, 2.05295s/100 iter), loss = 0.142853
I0701 14:37:45.932860 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:37:45.932869 30423 sgd_solver.cpp:106] Iteration 26100, lr = 0.0592188
I0701 14:37:47.987282 30423 solver.cpp:290] Iteration 26200 (48.6769 iter/s, 2.05436s/100 iter), loss = 0.0476151
I0701 14:37:47.987344 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:37:47.987352 30423 sgd_solver.cpp:106] Iteration 26200, lr = 0.0590625
I0701 14:37:50.043617 30423 solver.cpp:290] Iteration 26300 (48.6331 iter/s, 2.05621s/100 iter), loss = -3.97861e-06
I0701 14:37:50.043638 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:37:50.043645 30423 sgd_solver.cpp:106] Iteration 26300, lr = 0.0589063
I0701 14:37:52.102757 30423 solver.cpp:290] Iteration 26400 (48.5659 iter/s, 2.05906s/100 iter), loss = -3.97861e-06
I0701 14:37:52.102779 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:37:52.102787 30423 sgd_solver.cpp:106] Iteration 26400, lr = 0.05875
I0701 14:37:54.156761 30423 solver.cpp:290] Iteration 26500 (48.6873 iter/s, 2.05392s/100 iter), loss = 0.0952341
I0701 14:37:54.156785 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:37:54.156791 30423 sgd_solver.cpp:106] Iteration 26500, lr = 0.0585938
I0701 14:37:56.208247 30423 solver.cpp:290] Iteration 26600 (48.7472 iter/s, 2.0514s/100 iter), loss = -3.97861e-06
I0701 14:37:56.208282 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:37:56.208293 30423 sgd_solver.cpp:106] Iteration 26600, lr = 0.0584375
I0701 14:37:58.284402 30423 solver.cpp:290] Iteration 26700 (48.1681 iter/s, 2.07606s/100 iter), loss = 0.190472
I0701 14:37:58.284431 30423 solver.cpp:309]     Train net output #0: loss = 0.190476 (* 1 = 0.190476 loss)
I0701 14:37:58.284440 30423 sgd_solver.cpp:106] Iteration 26700, lr = 0.0582813
I0701 14:38:00.339109 30423 solver.cpp:290] Iteration 26800 (48.6708 iter/s, 2.05462s/100 iter), loss = -4.00841e-06
I0701 14:38:00.339131 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:38:00.339138 30423 sgd_solver.cpp:106] Iteration 26800, lr = 0.058125
I0701 14:38:02.393935 30423 solver.cpp:290] Iteration 26900 (48.6679 iter/s, 2.05474s/100 iter), loss = -4.02331e-06
I0701 14:38:02.393957 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:38:02.393965 30423 sgd_solver.cpp:106] Iteration 26900, lr = 0.0579687
I0701 14:38:04.426976 30423 solver.cpp:473] Iteration 27000, Testing net (#0)
I0701 14:38:06.067723 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8284
I0701 14:38:06.067741 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9905
I0701 14:38:06.067747 30423 solver.cpp:546]     Test net output #2: loss = 0.4912 (* 1 = 0.4912 loss)
I0701 14:38:06.087656 30423 solver.cpp:290] Iteration 27000 (27.0739 iter/s, 3.6936s/100 iter), loss = -4.04567e-06
I0701 14:38:06.087671 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:38:06.087685 30423 sgd_solver.cpp:106] Iteration 27000, lr = 0.0578125
I0701 14:38:08.142948 30423 solver.cpp:290] Iteration 27100 (48.6567 iter/s, 2.05522s/100 iter), loss = -4.05312e-06
I0701 14:38:08.142971 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:38:08.142977 30423 sgd_solver.cpp:106] Iteration 27100, lr = 0.0576563
I0701 14:38:10.199298 30423 solver.cpp:290] Iteration 27200 (48.6319 iter/s, 2.05627s/100 iter), loss = 0.142853
I0701 14:38:10.199321 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:38:10.199327 30423 sgd_solver.cpp:106] Iteration 27200, lr = 0.0575
I0701 14:38:12.259630 30423 solver.cpp:290] Iteration 27300 (48.5378 iter/s, 2.06025s/100 iter), loss = -4.06802e-06
I0701 14:38:12.259652 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:38:12.259661 30423 sgd_solver.cpp:106] Iteration 27300, lr = 0.0573438
I0701 14:38:14.317128 30423 solver.cpp:290] Iteration 27400 (48.6047 iter/s, 2.05741s/100 iter), loss = -4.09782e-06
I0701 14:38:14.317153 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:38:14.317162 30423 sgd_solver.cpp:106] Iteration 27400, lr = 0.0571875
I0701 14:38:16.371721 30423 solver.cpp:290] Iteration 27500 (48.6735 iter/s, 2.05451s/100 iter), loss = -4.11272e-06
I0701 14:38:16.371762 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:38:16.371770 30423 sgd_solver.cpp:106] Iteration 27500, lr = 0.0570313
I0701 14:38:18.425812 30423 solver.cpp:290] Iteration 27600 (48.6857 iter/s, 2.05399s/100 iter), loss = 0.142853
I0701 14:38:18.425880 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:38:18.425895 30423 sgd_solver.cpp:106] Iteration 27600, lr = 0.056875
I0701 14:38:20.481657 30423 solver.cpp:290] Iteration 27700 (48.6448 iter/s, 2.05572s/100 iter), loss = -4.09037e-06
I0701 14:38:20.481680 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:38:20.481688 30423 sgd_solver.cpp:106] Iteration 27700, lr = 0.0567187
I0701 14:38:22.538329 30423 solver.cpp:290] Iteration 27800 (48.6242 iter/s, 2.05659s/100 iter), loss = -4.09782e-06
I0701 14:38:22.538352 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:38:22.538358 30423 sgd_solver.cpp:106] Iteration 27800, lr = 0.0565625
I0701 14:38:24.598937 30423 solver.cpp:290] Iteration 27900 (48.5314 iter/s, 2.06052s/100 iter), loss = -4.10154e-06
I0701 14:38:24.598959 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:38:24.598965 30423 sgd_solver.cpp:106] Iteration 27900, lr = 0.0564062
I0701 14:38:26.633378 30423 solver.cpp:473] Iteration 28000, Testing net (#0)
I0701 14:38:28.272452 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8411
I0701 14:38:28.272472 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9919
I0701 14:38:28.272478 30423 solver.cpp:546]     Test net output #2: loss = 0.4894 (* 1 = 0.4894 loss)
I0701 14:38:28.292248 30423 solver.cpp:290] Iteration 28000 (27.0769 iter/s, 3.69319s/100 iter), loss = -4.08664e-06
I0701 14:38:28.292274 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:38:28.292284 30423 sgd_solver.cpp:106] Iteration 28000, lr = 0.05625
I0701 14:38:30.345723 30423 solver.cpp:290] Iteration 28100 (48.7 iter/s, 2.05339s/100 iter), loss = -4.08292e-06
I0701 14:38:30.345749 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:38:30.345757 30423 sgd_solver.cpp:106] Iteration 28100, lr = 0.0560938
I0701 14:38:32.397524 30423 solver.cpp:290] Iteration 28200 (48.7397 iter/s, 2.05172s/100 iter), loss = -4.12762e-06
I0701 14:38:32.397548 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:38:32.397557 30423 sgd_solver.cpp:106] Iteration 28200, lr = 0.0559375
I0701 14:38:34.453110 30423 solver.cpp:290] Iteration 28300 (48.6499 iter/s, 2.0555s/100 iter), loss = 0.0476149
I0701 14:38:34.453132 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:38:34.453140 30423 sgd_solver.cpp:106] Iteration 28300, lr = 0.0557813
I0701 14:38:36.508802 30423 solver.cpp:290] Iteration 28400 (48.6474 iter/s, 2.05561s/100 iter), loss = -4.14252e-06
I0701 14:38:36.508823 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:38:36.508831 30423 sgd_solver.cpp:106] Iteration 28400, lr = 0.055625
I0701 14:38:38.563588 30423 solver.cpp:290] Iteration 28500 (48.6688 iter/s, 2.0547s/100 iter), loss = -4.15742e-06
I0701 14:38:38.563611 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:38:38.563618 30423 sgd_solver.cpp:106] Iteration 28500, lr = 0.0554687
I0701 14:38:40.615624 30423 solver.cpp:290] Iteration 28600 (48.7341 iter/s, 2.05195s/100 iter), loss = -4.15742e-06
I0701 14:38:40.615648 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:38:40.615654 30423 sgd_solver.cpp:106] Iteration 28600, lr = 0.0553125
I0701 14:38:42.672027 30423 solver.cpp:290] Iteration 28700 (48.6306 iter/s, 2.05632s/100 iter), loss = 0.0952339
I0701 14:38:42.672049 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:38:42.672057 30423 sgd_solver.cpp:106] Iteration 28700, lr = 0.0551562
I0701 14:38:44.733781 30423 solver.cpp:290] Iteration 28800 (48.5044 iter/s, 2.06167s/100 iter), loss = -4.15742e-06
I0701 14:38:44.733804 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:38:44.733811 30423 sgd_solver.cpp:106] Iteration 28800, lr = 0.055
I0701 14:38:46.788924 30423 solver.cpp:290] Iteration 28900 (48.6604 iter/s, 2.05506s/100 iter), loss = -4.16115e-06
I0701 14:38:46.788964 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:38:46.788970 30423 sgd_solver.cpp:106] Iteration 28900, lr = 0.0548437
I0701 14:38:48.825829 30423 solver.cpp:473] Iteration 29000, Testing net (#0)
I0701 14:38:50.462788 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.78
I0701 14:38:50.462807 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9801
I0701 14:38:50.462812 30423 solver.cpp:546]     Test net output #2: loss = 0.7215 (* 1 = 0.7215 loss)
I0701 14:38:50.482638 30423 solver.cpp:290] Iteration 29000 (27.074 iter/s, 3.69357s/100 iter), loss = -4.14252e-06
I0701 14:38:50.482655 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:38:50.482668 30423 sgd_solver.cpp:106] Iteration 29000, lr = 0.0546875
I0701 14:38:52.542922 30423 solver.cpp:290] Iteration 29100 (48.5389 iter/s, 2.0602s/100 iter), loss = 0.0952339
I0701 14:38:52.542948 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:38:52.542958 30423 sgd_solver.cpp:106] Iteration 29100, lr = 0.0545313
I0701 14:38:54.600442 30423 solver.cpp:290] Iteration 29200 (48.6042 iter/s, 2.05743s/100 iter), loss = -4.14252e-06
I0701 14:38:54.600464 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:38:54.600471 30423 sgd_solver.cpp:106] Iteration 29200, lr = 0.054375
I0701 14:38:56.656226 30423 solver.cpp:290] Iteration 29300 (48.6452 iter/s, 2.0557s/100 iter), loss = 0.28571
I0701 14:38:56.656249 30423 solver.cpp:309]     Train net output #0: loss = 0.285714 (* 1 = 0.285714 loss)
I0701 14:38:56.656255 30423 sgd_solver.cpp:106] Iteration 29300, lr = 0.0542188
I0701 14:38:58.727555 30423 solver.cpp:290] Iteration 29400 (48.2801 iter/s, 2.07124s/100 iter), loss = -4.14252e-06
I0701 14:38:58.727579 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:38:58.727588 30423 sgd_solver.cpp:106] Iteration 29400, lr = 0.0540625
I0701 14:39:00.781544 30423 solver.cpp:290] Iteration 29500 (48.6877 iter/s, 2.05391s/100 iter), loss = -4.14252e-06
I0701 14:39:00.781568 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:39:00.781574 30423 sgd_solver.cpp:106] Iteration 29500, lr = 0.0539063
I0701 14:39:02.837620 30423 solver.cpp:290] Iteration 29600 (48.6383 iter/s, 2.05599s/100 iter), loss = 0.0476149
I0701 14:39:02.837641 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:39:02.837648 30423 sgd_solver.cpp:106] Iteration 29600, lr = 0.05375
I0701 14:39:04.889937 30423 solver.cpp:290] Iteration 29700 (48.7274 iter/s, 2.05224s/100 iter), loss = -4.14252e-06
I0701 14:39:04.889961 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:39:04.889969 30423 sgd_solver.cpp:106] Iteration 29700, lr = 0.0535938
I0701 14:39:06.942374 30423 solver.cpp:290] Iteration 29800 (48.7246 iter/s, 2.05235s/100 iter), loss = 0.0476149
I0701 14:39:06.942401 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:39:06.942409 30423 sgd_solver.cpp:106] Iteration 29800, lr = 0.0534375
I0701 14:39:08.995839 30423 solver.cpp:290] Iteration 29900 (48.7003 iter/s, 2.05338s/100 iter), loss = 0.142853
I0701 14:39:08.995868 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:39:08.995878 30423 sgd_solver.cpp:106] Iteration 29900, lr = 0.0532812
I0701 14:39:11.029181 30423 solver.cpp:600] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/initial/cifar10_jacintonet11v2_iter_30000.caffemodel
I0701 14:39:11.045668 30423 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/initial/cifar10_jacintonet11v2_iter_30000.solverstate
I0701 14:39:11.053117 30423 solver.cpp:473] Iteration 30000, Testing net (#0)
I0701 14:39:12.688967 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8059
I0701 14:39:12.688985 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9914
I0701 14:39:12.688992 30423 solver.cpp:546]     Test net output #2: loss = 0.6526 (* 1 = 0.6526 loss)
I0701 14:39:12.708865 30423 solver.cpp:290] Iteration 30000 (26.9331 iter/s, 3.7129s/100 iter), loss = -4.14997e-06
I0701 14:39:12.708884 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:39:12.708912 30423 sgd_solver.cpp:106] Iteration 30000, lr = 0.053125
I0701 14:39:14.763902 30423 solver.cpp:290] Iteration 30100 (48.6628 iter/s, 2.05496s/100 iter), loss = -4.15742e-06
I0701 14:39:14.763924 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:39:14.763932 30423 sgd_solver.cpp:106] Iteration 30100, lr = 0.0529688
I0701 14:39:16.817587 30423 solver.cpp:290] Iteration 30200 (48.6949 iter/s, 2.0536s/100 iter), loss = -4.14252e-06
I0701 14:39:16.817611 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:39:16.817620 30423 sgd_solver.cpp:106] Iteration 30200, lr = 0.0528125
I0701 14:39:18.875644 30423 solver.cpp:290] Iteration 30300 (48.5915 iter/s, 2.05797s/100 iter), loss = -4.13135e-06
I0701 14:39:18.875735 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:39:18.875743 30423 sgd_solver.cpp:106] Iteration 30300, lr = 0.0526563
I0701 14:39:20.928771 30423 solver.cpp:290] Iteration 30400 (48.7098 iter/s, 2.05298s/100 iter), loss = -4.13135e-06
I0701 14:39:20.928795 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:39:20.928803 30423 sgd_solver.cpp:106] Iteration 30400, lr = 0.0525
I0701 14:39:22.982591 30423 solver.cpp:290] Iteration 30500 (48.6917 iter/s, 2.05374s/100 iter), loss = -4.12762e-06
I0701 14:39:22.982615 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:39:22.982625 30423 sgd_solver.cpp:106] Iteration 30500, lr = 0.0523438
I0701 14:39:25.036456 30423 solver.cpp:290] Iteration 30600 (48.6907 iter/s, 2.05378s/100 iter), loss = -4.15742e-06
I0701 14:39:25.036484 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:39:25.036494 30423 sgd_solver.cpp:106] Iteration 30600, lr = 0.0521875
I0701 14:39:27.094665 30423 solver.cpp:290] Iteration 30700 (48.588 iter/s, 2.05812s/100 iter), loss = -4.15742e-06
I0701 14:39:27.094687 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:39:27.094696 30423 sgd_solver.cpp:106] Iteration 30700, lr = 0.0520312
I0701 14:39:29.148358 30423 solver.cpp:290] Iteration 30800 (48.6947 iter/s, 2.05361s/100 iter), loss = -4.15742e-06
I0701 14:39:29.148380 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:39:29.148386 30423 sgd_solver.cpp:106] Iteration 30800, lr = 0.051875
I0701 14:39:31.202136 30423 solver.cpp:290] Iteration 30900 (48.6927 iter/s, 2.0537s/100 iter), loss = -4.14997e-06
I0701 14:39:31.202159 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:39:31.202167 30423 sgd_solver.cpp:106] Iteration 30900, lr = 0.0517187
I0701 14:39:33.236307 30423 solver.cpp:473] Iteration 31000, Testing net (#0)
I0701 14:39:34.881963 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8404
I0701 14:39:34.881981 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9917
I0701 14:39:34.881988 30423 solver.cpp:546]     Test net output #2: loss = 0.4787 (* 1 = 0.4787 loss)
I0701 14:39:34.901657 30423 solver.cpp:290] Iteration 31000 (27.0314 iter/s, 3.6994s/100 iter), loss = -4.14252e-06
I0701 14:39:34.901674 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:39:34.901687 30423 sgd_solver.cpp:106] Iteration 31000, lr = 0.0515625
I0701 14:39:36.955569 30423 solver.cpp:290] Iteration 31100 (48.6894 iter/s, 2.05383s/100 iter), loss = 0.0476149
I0701 14:39:36.955590 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:39:36.955597 30423 sgd_solver.cpp:106] Iteration 31100, lr = 0.0514063
I0701 14:39:39.013439 30423 solver.cpp:290] Iteration 31200 (48.5959 iter/s, 2.05779s/100 iter), loss = 0.0476149
I0701 14:39:39.013463 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:39:39.013471 30423 sgd_solver.cpp:106] Iteration 31200, lr = 0.05125
I0701 14:39:41.067703 30423 solver.cpp:290] Iteration 31300 (48.6813 iter/s, 2.05418s/100 iter), loss = -4.12762e-06
I0701 14:39:41.067730 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:39:41.067739 30423 sgd_solver.cpp:106] Iteration 31300, lr = 0.0510938
I0701 14:39:43.121333 30423 solver.cpp:290] Iteration 31400 (48.6963 iter/s, 2.05354s/100 iter), loss = 0.095234
I0701 14:39:43.121357 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:39:43.121366 30423 sgd_solver.cpp:106] Iteration 31400, lr = 0.0509375
I0701 14:39:45.173090 30423 solver.cpp:290] Iteration 31500 (48.7407 iter/s, 2.05167s/100 iter), loss = -4.14997e-06
I0701 14:39:45.173112 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:39:45.173120 30423 sgd_solver.cpp:106] Iteration 31500, lr = 0.0507812
I0701 14:39:47.228190 30423 solver.cpp:290] Iteration 31600 (48.6614 iter/s, 2.05502s/100 iter), loss = 0.0476149
I0701 14:39:47.228229 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:39:47.228242 30423 sgd_solver.cpp:106] Iteration 31600, lr = 0.050625
I0701 14:39:49.284512 30423 solver.cpp:290] Iteration 31700 (48.6328 iter/s, 2.05623s/100 iter), loss = -4.18723e-06
I0701 14:39:49.284588 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:39:49.284603 30423 sgd_solver.cpp:106] Iteration 31700, lr = 0.0504688
I0701 14:39:51.340358 30423 solver.cpp:290] Iteration 31800 (48.6449 iter/s, 2.05571s/100 iter), loss = -4.20213e-06
I0701 14:39:51.340382 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:39:51.340390 30423 sgd_solver.cpp:106] Iteration 31800, lr = 0.0503125
I0701 14:39:53.397613 30423 solver.cpp:290] Iteration 31900 (48.6105 iter/s, 2.05717s/100 iter), loss = -4.20213e-06
I0701 14:39:53.397635 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:39:53.397644 30423 sgd_solver.cpp:106] Iteration 31900, lr = 0.0501562
I0701 14:39:55.432432 30423 solver.cpp:473] Iteration 32000, Testing net (#0)
I0701 14:39:57.074012 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8006
I0701 14:39:57.074029 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9895
I0701 14:39:57.074035 30423 solver.cpp:546]     Test net output #2: loss = 0.7039 (* 1 = 0.7039 loss)
I0701 14:39:57.093677 30423 solver.cpp:290] Iteration 32000 (27.0567 iter/s, 3.69594s/100 iter), loss = 0.0952339
I0701 14:39:57.093695 30423 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 14:39:57.093708 30423 sgd_solver.cpp:106] Iteration 32000, lr = 0.05
I0701 14:39:59.151322 30423 solver.cpp:290] Iteration 32100 (48.6011 iter/s, 2.05757s/100 iter), loss = -4.20585e-06
I0701 14:39:59.151345 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:39:59.151351 30423 sgd_solver.cpp:106] Iteration 32100, lr = 0.0498438
I0701 14:40:01.202232 30423 solver.cpp:290] Iteration 32200 (48.7608 iter/s, 2.05083s/100 iter), loss = -4.21703e-06
I0701 14:40:01.202256 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:40:01.202265 30423 sgd_solver.cpp:106] Iteration 32200, lr = 0.0496875
I0701 14:40:03.255412 30423 solver.cpp:290] Iteration 32300 (48.7069 iter/s, 2.0531s/100 iter), loss = -4.21703e-06
I0701 14:40:03.255436 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:40:03.255445 30423 sgd_solver.cpp:106] Iteration 32300, lr = 0.0495313
I0701 14:40:05.307528 30423 solver.cpp:290] Iteration 32400 (48.7322 iter/s, 2.05203s/100 iter), loss = -4.22075e-06
I0701 14:40:05.307551 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:40:05.307559 30423 sgd_solver.cpp:106] Iteration 32400, lr = 0.049375
I0701 14:40:07.370036 30423 solver.cpp:290] Iteration 32500 (48.4866 iter/s, 2.06243s/100 iter), loss = -4.20958e-06
I0701 14:40:07.370060 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:40:07.370066 30423 sgd_solver.cpp:106] Iteration 32500, lr = 0.0492188
I0701 14:40:09.425740 30423 solver.cpp:290] Iteration 32600 (48.6471 iter/s, 2.05562s/100 iter), loss = -4.24683e-06
I0701 14:40:09.425761 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:40:09.425770 30423 sgd_solver.cpp:106] Iteration 32600, lr = 0.0490625
I0701 14:40:11.479028 30423 solver.cpp:290] Iteration 32700 (48.7043 iter/s, 2.05321s/100 iter), loss = -4.25056e-06
I0701 14:40:11.479053 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:40:11.479061 30423 sgd_solver.cpp:106] Iteration 32700, lr = 0.0489062
I0701 14:40:13.533972 30423 solver.cpp:290] Iteration 32800 (48.6651 iter/s, 2.05486s/100 iter), loss = -4.24683e-06
I0701 14:40:13.533995 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:40:13.534003 30423 sgd_solver.cpp:106] Iteration 32800, lr = 0.04875
I0701 14:40:15.589426 30423 solver.cpp:290] Iteration 32900 (48.653 iter/s, 2.05537s/100 iter), loss = -4.24683e-06
I0701 14:40:15.589449 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:40:15.589455 30423 sgd_solver.cpp:106] Iteration 32900, lr = 0.0485937
I0701 14:40:17.625742 30423 solver.cpp:473] Iteration 33000, Testing net (#0)
I0701 14:40:19.270512 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8555
I0701 14:40:19.270545 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9925
I0701 14:40:19.270551 30423 solver.cpp:546]     Test net output #2: loss = 0.4413 (* 1 = 0.4413 loss)
I0701 14:40:19.290364 30423 solver.cpp:290] Iteration 33000 (27.0211 iter/s, 3.70081s/100 iter), loss = -4.26918e-06
I0701 14:40:19.290438 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:40:19.290448 30423 sgd_solver.cpp:106] Iteration 33000, lr = 0.0484375
I0701 14:40:21.343384 30423 solver.cpp:290] Iteration 33100 (48.7119 iter/s, 2.05289s/100 iter), loss = 0.0476148
I0701 14:40:21.343410 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:40:21.343420 30423 sgd_solver.cpp:106] Iteration 33100, lr = 0.0482813
I0701 14:40:23.395612 30423 solver.cpp:290] Iteration 33200 (48.7296 iter/s, 2.05214s/100 iter), loss = -4.28408e-06
I0701 14:40:23.395635 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:40:23.395642 30423 sgd_solver.cpp:106] Iteration 33200, lr = 0.048125
I0701 14:40:25.454591 30423 solver.cpp:290] Iteration 33300 (48.5698 iter/s, 2.05889s/100 iter), loss = -4.26173e-06
I0701 14:40:25.454613 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:40:25.454619 30423 sgd_solver.cpp:106] Iteration 33300, lr = 0.0479688
I0701 14:40:27.511711 30423 solver.cpp:290] Iteration 33400 (48.6136 iter/s, 2.05704s/100 iter), loss = -4.26173e-06
I0701 14:40:27.511734 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:40:27.511741 30423 sgd_solver.cpp:106] Iteration 33400, lr = 0.0478125
I0701 14:40:29.568218 30423 solver.cpp:290] Iteration 33500 (48.6281 iter/s, 2.05642s/100 iter), loss = 0.0476148
I0701 14:40:29.568241 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:40:29.568248 30423 sgd_solver.cpp:106] Iteration 33500, lr = 0.0476562
I0701 14:40:31.621700 30423 solver.cpp:290] Iteration 33600 (48.6998 iter/s, 2.0534s/100 iter), loss = -4.26173e-06
I0701 14:40:31.621721 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:40:31.621728 30423 sgd_solver.cpp:106] Iteration 33600, lr = 0.0475
I0701 14:40:33.679833 30423 solver.cpp:290] Iteration 33700 (48.5896 iter/s, 2.05805s/100 iter), loss = -4.26173e-06
I0701 14:40:33.679854 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:40:33.679862 30423 sgd_solver.cpp:106] Iteration 33700, lr = 0.0473437
I0701 14:40:35.732126 30423 solver.cpp:290] Iteration 33800 (48.7279 iter/s, 2.05221s/100 iter), loss = -4.26173e-06
I0701 14:40:35.732151 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:40:35.732159 30423 sgd_solver.cpp:106] Iteration 33800, lr = 0.0471875
I0701 14:40:37.789801 30423 solver.cpp:290] Iteration 33900 (48.6005 iter/s, 2.05759s/100 iter), loss = -4.26173e-06
I0701 14:40:37.789824 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:40:37.789830 30423 sgd_solver.cpp:106] Iteration 33900, lr = 0.0470312
I0701 14:40:39.822973 30423 solver.cpp:473] Iteration 34000, Testing net (#0)
I0701 14:40:41.462191 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8182
I0701 14:40:41.462210 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9797
I0701 14:40:41.462216 30423 solver.cpp:546]     Test net output #2: loss = 0.7002 (* 1 = 0.7002 loss)
I0701 14:40:41.481920 30423 solver.cpp:290] Iteration 34000 (27.0856 iter/s, 3.692s/100 iter), loss = -4.26173e-06
I0701 14:40:41.481936 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:40:41.481951 30423 sgd_solver.cpp:106] Iteration 34000, lr = 0.046875
I0701 14:40:43.538115 30423 solver.cpp:290] Iteration 34100 (48.6353 iter/s, 2.05612s/100 iter), loss = -4.26173e-06
I0701 14:40:43.538141 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:40:43.538149 30423 sgd_solver.cpp:106] Iteration 34100, lr = 0.0467188
I0701 14:40:45.593957 30423 solver.cpp:290] Iteration 34200 (48.6439 iter/s, 2.05576s/100 iter), loss = 0.0476148
I0701 14:40:45.593978 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:40:45.593986 30423 sgd_solver.cpp:106] Iteration 34200, lr = 0.0465625
I0701 14:40:47.650445 30423 solver.cpp:290] Iteration 34300 (48.6286 iter/s, 2.05641s/100 iter), loss = -4.27663e-06
I0701 14:40:47.650483 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:40:47.650490 30423 sgd_solver.cpp:106] Iteration 34300, lr = 0.0464063
I0701 14:40:49.704118 30423 solver.cpp:290] Iteration 34400 (48.6955 iter/s, 2.05358s/100 iter), loss = 0.0476148
I0701 14:40:49.704183 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:40:49.704190 30423 sgd_solver.cpp:106] Iteration 34400, lr = 0.04625
I0701 14:40:51.757912 30423 solver.cpp:290] Iteration 34500 (48.6933 iter/s, 2.05367s/100 iter), loss = 0.142853
I0701 14:40:51.757935 30423 solver.cpp:309]     Train net output #0: loss = 0.142857 (* 1 = 0.142857 loss)
I0701 14:40:51.757941 30423 sgd_solver.cpp:106] Iteration 34500, lr = 0.0460938
I0701 14:40:53.813148 30423 solver.cpp:290] Iteration 34600 (48.6582 iter/s, 2.05515s/100 iter), loss = -4.28408e-06
I0701 14:40:53.813170 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:40:53.813177 30423 sgd_solver.cpp:106] Iteration 34600, lr = 0.0459375
I0701 14:40:55.866777 30423 solver.cpp:290] Iteration 34700 (48.6962 iter/s, 2.05355s/100 iter), loss = -4.27663e-06
I0701 14:40:55.866801 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:40:55.866806 30423 sgd_solver.cpp:106] Iteration 34700, lr = 0.0457813
I0701 14:40:57.953066 30423 solver.cpp:290] Iteration 34800 (47.934 iter/s, 2.0862s/100 iter), loss = -4.26173e-06
I0701 14:40:57.953092 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:40:57.953101 30423 sgd_solver.cpp:106] Iteration 34800, lr = 0.045625
I0701 14:41:00.013468 30423 solver.cpp:290] Iteration 34900 (48.5363 iter/s, 2.06032s/100 iter), loss = 0.0476148
I0701 14:41:00.013489 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:41:00.013496 30423 sgd_solver.cpp:106] Iteration 34900, lr = 0.0454687
I0701 14:41:02.049537 30423 solver.cpp:473] Iteration 35000, Testing net (#0)
I0701 14:41:03.688592 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8464
I0701 14:41:03.688611 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9919
I0701 14:41:03.688617 30423 solver.cpp:546]     Test net output #2: loss = 0.5015 (* 1 = 0.5015 loss)
I0701 14:41:03.708847 30423 solver.cpp:290] Iteration 35000 (27.0617 iter/s, 3.69526s/100 iter), loss = -4.28408e-06
I0701 14:41:03.708866 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:41:03.708878 30423 sgd_solver.cpp:106] Iteration 35000, lr = 0.0453125
I0701 14:41:05.764365 30423 solver.cpp:290] Iteration 35100 (48.6514 iter/s, 2.05544s/100 iter), loss = -4.27663e-06
I0701 14:41:05.764387 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:41:05.764394 30423 sgd_solver.cpp:106] Iteration 35100, lr = 0.0451563
I0701 14:41:07.824172 30423 solver.cpp:290] Iteration 35200 (48.5502 iter/s, 2.05972s/100 iter), loss = -4.27663e-06
I0701 14:41:07.824198 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:41:07.824208 30423 sgd_solver.cpp:106] Iteration 35200, lr = 0.045
I0701 14:41:09.879163 30423 solver.cpp:290] Iteration 35300 (48.664 iter/s, 2.05491s/100 iter), loss = -4.26173e-06
I0701 14:41:09.879185 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:41:09.879192 30423 sgd_solver.cpp:106] Iteration 35300, lr = 0.0448438
I0701 14:41:11.934165 30423 solver.cpp:290] Iteration 35400 (48.6638 iter/s, 2.05491s/100 iter), loss = -4.26173e-06
I0701 14:41:11.934188 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:41:11.934195 30423 sgd_solver.cpp:106] Iteration 35400, lr = 0.0446875
I0701 14:41:13.989157 30423 solver.cpp:290] Iteration 35500 (48.664 iter/s, 2.05491s/100 iter), loss = -4.27663e-06
I0701 14:41:13.989178 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:41:13.989187 30423 sgd_solver.cpp:106] Iteration 35500, lr = 0.0445313
I0701 14:41:16.042359 30423 solver.cpp:290] Iteration 35600 (48.7063 iter/s, 2.05312s/100 iter), loss = 0.238091
I0701 14:41:16.042382 30423 solver.cpp:309]     Train net output #0: loss = 0.238095 (* 1 = 0.238095 loss)
I0701 14:41:16.042392 30423 sgd_solver.cpp:106] Iteration 35600, lr = 0.044375
I0701 14:41:18.096768 30423 solver.cpp:290] Iteration 35700 (48.6777 iter/s, 2.05433s/100 iter), loss = -4.27663e-06
I0701 14:41:18.096803 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:41:18.096810 30423 sgd_solver.cpp:106] Iteration 35700, lr = 0.0442187
I0701 14:41:20.155431 30423 solver.cpp:290] Iteration 35800 (48.5776 iter/s, 2.05856s/100 iter), loss = -4.28036e-06
I0701 14:41:20.157024 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:41:20.157038 30423 sgd_solver.cpp:106] Iteration 35800, lr = 0.0440625
I0701 14:41:22.216943 30423 solver.cpp:290] Iteration 35900 (48.5469 iter/s, 2.05986s/100 iter), loss = -4.27663e-06
I0701 14:41:22.216966 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:41:22.216974 30423 sgd_solver.cpp:106] Iteration 35900, lr = 0.0439062
I0701 14:41:24.257484 30423 solver.cpp:473] Iteration 36000, Testing net (#0)
I0701 14:41:25.899353 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8559
I0701 14:41:25.899371 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9946
I0701 14:41:25.899377 30423 solver.cpp:546]     Test net output #2: loss = 0.419 (* 1 = 0.419 loss)
I0701 14:41:25.919250 30423 solver.cpp:290] Iteration 36000 (27.0111 iter/s, 3.70218s/100 iter), loss = -4.27663e-06
I0701 14:41:25.919270 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:41:25.919282 30423 sgd_solver.cpp:106] Iteration 36000, lr = 0.04375
I0701 14:41:27.984640 30423 solver.cpp:290] Iteration 36100 (48.4189 iter/s, 2.06531s/100 iter), loss = -4.27663e-06
I0701 14:41:27.984668 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:41:27.984678 30423 sgd_solver.cpp:106] Iteration 36100, lr = 0.0435938
I0701 14:41:30.041481 30423 solver.cpp:290] Iteration 36200 (48.6203 iter/s, 2.05675s/100 iter), loss = -4.26173e-06
I0701 14:41:30.041503 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:41:30.041510 30423 sgd_solver.cpp:106] Iteration 36200, lr = 0.0434375
I0701 14:41:32.100677 30423 solver.cpp:290] Iteration 36300 (48.5646 iter/s, 2.05911s/100 iter), loss = 0.0476148
I0701 14:41:32.100699 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:41:32.100705 30423 sgd_solver.cpp:106] Iteration 36300, lr = 0.0432813
I0701 14:41:34.155067 30423 solver.cpp:290] Iteration 36400 (48.6782 iter/s, 2.05431s/100 iter), loss = -4.26546e-06
I0701 14:41:34.155098 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:41:34.155107 30423 sgd_solver.cpp:106] Iteration 36400, lr = 0.043125
I0701 14:41:36.208000 30423 solver.cpp:290] Iteration 36500 (48.713 iter/s, 2.05284s/100 iter), loss = -4.26918e-06
I0701 14:41:36.208030 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:41:36.208039 30423 sgd_solver.cpp:106] Iteration 36500, lr = 0.0429688
I0701 14:41:38.262848 30423 solver.cpp:290] Iteration 36600 (48.6675 iter/s, 2.05476s/100 iter), loss = -4.26173e-06
I0701 14:41:38.262876 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:41:38.262886 30423 sgd_solver.cpp:106] Iteration 36600, lr = 0.0428125
I0701 14:41:40.315502 30423 solver.cpp:290] Iteration 36700 (48.7195 iter/s, 2.05257s/100 iter), loss = -4.26918e-06
I0701 14:41:40.315526 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:41:40.315536 30423 sgd_solver.cpp:106] Iteration 36700, lr = 0.0426563
I0701 14:41:42.369073 30423 solver.cpp:290] Iteration 36800 (48.6977 iter/s, 2.05349s/100 iter), loss = -4.26173e-06
I0701 14:41:42.369099 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:41:42.369108 30423 sgd_solver.cpp:106] Iteration 36800, lr = 0.0425
I0701 14:41:44.424134 30423 solver.cpp:290] Iteration 36900 (48.6624 iter/s, 2.05498s/100 iter), loss = -4.26173e-06
I0701 14:41:44.424157 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:41:44.424165 30423 sgd_solver.cpp:106] Iteration 36900, lr = 0.0423437
I0701 14:41:46.459137 30423 solver.cpp:473] Iteration 37000, Testing net (#0)
I0701 14:41:48.100417 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8594
I0701 14:41:48.100435 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9929
I0701 14:41:48.100441 30423 solver.cpp:546]     Test net output #2: loss = 0.42 (* 1 = 0.42 loss)
I0701 14:41:48.120877 30423 solver.cpp:290] Iteration 37000 (27.0517 iter/s, 3.69662s/100 iter), loss = -4.26546e-06
I0701 14:41:48.120909 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:41:48.120916 30423 sgd_solver.cpp:106] Iteration 37000, lr = 0.0421875
I0701 14:41:50.175956 30423 solver.cpp:290] Iteration 37100 (48.6622 iter/s, 2.05498s/100 iter), loss = -4.26918e-06
I0701 14:41:50.176030 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:41:50.176039 30423 sgd_solver.cpp:106] Iteration 37100, lr = 0.0420313
I0701 14:41:52.229877 30423 solver.cpp:290] Iteration 37200 (48.6905 iter/s, 2.05379s/100 iter), loss = -4.27663e-06
I0701 14:41:52.229898 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:41:52.229905 30423 sgd_solver.cpp:106] Iteration 37200, lr = 0.041875
I0701 14:41:54.289525 30423 solver.cpp:290] Iteration 37300 (48.5539 iter/s, 2.05956s/100 iter), loss = -4.26173e-06
I0701 14:41:54.289546 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:41:54.289554 30423 sgd_solver.cpp:106] Iteration 37300, lr = 0.0417188
I0701 14:41:56.346752 30423 solver.cpp:290] Iteration 37400 (48.6111 iter/s, 2.05714s/100 iter), loss = 0.0476148
I0701 14:41:56.346774 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:41:56.346782 30423 sgd_solver.cpp:106] Iteration 37400, lr = 0.0415625
I0701 14:41:58.451979 30423 solver.cpp:290] Iteration 37500 (47.5027 iter/s, 2.10514s/100 iter), loss = -4.27663e-06
I0701 14:41:58.452002 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:41:58.452008 30423 sgd_solver.cpp:106] Iteration 37500, lr = 0.0414063
I0701 14:42:00.507174 30423 solver.cpp:290] Iteration 37600 (48.6592 iter/s, 2.05511s/100 iter), loss = -4.27663e-06
I0701 14:42:00.507196 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:42:00.507203 30423 sgd_solver.cpp:106] Iteration 37600, lr = 0.04125
I0701 14:42:02.562256 30423 solver.cpp:290] Iteration 37700 (48.6618 iter/s, 2.055s/100 iter), loss = -4.27663e-06
I0701 14:42:02.562279 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:42:02.562286 30423 sgd_solver.cpp:106] Iteration 37700, lr = 0.0410937
I0701 14:42:04.615322 30423 solver.cpp:290] Iteration 37800 (48.7096 iter/s, 2.05298s/100 iter), loss = -4.26173e-06
I0701 14:42:04.615345 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:42:04.615351 30423 sgd_solver.cpp:106] Iteration 37800, lr = 0.0409375
I0701 14:42:06.670050 30423 solver.cpp:290] Iteration 37900 (48.6702 iter/s, 2.05464s/100 iter), loss = -4.26173e-06
I0701 14:42:06.670071 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:42:06.670079 30423 sgd_solver.cpp:106] Iteration 37900, lr = 0.0407812
I0701 14:42:08.715809 30423 solver.cpp:473] Iteration 38000, Testing net (#0)
I0701 14:42:10.367940 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8534
I0701 14:42:10.367959 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9906
I0701 14:42:10.367964 30423 solver.cpp:546]     Test net output #2: loss = 0.4886 (* 1 = 0.4886 loss)
I0701 14:42:10.387620 30423 solver.cpp:290] Iteration 38000 (26.9002 iter/s, 3.71745s/100 iter), loss = -4.26173e-06
I0701 14:42:10.387636 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:42:10.387651 30423 sgd_solver.cpp:106] Iteration 38000, lr = 0.040625
I0701 14:42:12.441790 30423 solver.cpp:290] Iteration 38100 (48.6834 iter/s, 2.05409s/100 iter), loss = 0.0476148
I0701 14:42:12.441815 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:42:12.441821 30423 sgd_solver.cpp:106] Iteration 38100, lr = 0.0404688
I0701 14:42:14.496323 30423 solver.cpp:290] Iteration 38200 (48.6749 iter/s, 2.05445s/100 iter), loss = -4.26173e-06
I0701 14:42:14.496351 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:42:14.496359 30423 sgd_solver.cpp:106] Iteration 38200, lr = 0.0403125
I0701 14:42:16.553645 30423 solver.cpp:290] Iteration 38300 (48.6089 iter/s, 2.05724s/100 iter), loss = 0.0476148
I0701 14:42:16.553668 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:42:16.553674 30423 sgd_solver.cpp:106] Iteration 38300, lr = 0.0401563
I0701 14:42:18.609380 30423 solver.cpp:290] Iteration 38400 (48.6464 iter/s, 2.05565s/100 iter), loss = -4.26173e-06
I0701 14:42:18.609418 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:42:18.609426 30423 sgd_solver.cpp:106] Iteration 38400, lr = 0.04
I0701 14:42:20.662246 30423 solver.cpp:290] Iteration 38500 (48.7147 iter/s, 2.05277s/100 iter), loss = -4.26173e-06
I0701 14:42:20.662307 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:42:20.662314 30423 sgd_solver.cpp:106] Iteration 38500, lr = 0.0398437
I0701 14:42:22.718957 30423 solver.cpp:290] Iteration 38600 (48.6241 iter/s, 2.05659s/100 iter), loss = -4.26173e-06
I0701 14:42:22.718979 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:42:22.718987 30423 sgd_solver.cpp:106] Iteration 38600, lr = 0.0396875
I0701 14:42:24.778340 30423 solver.cpp:290] Iteration 38700 (48.5601 iter/s, 2.0593s/100 iter), loss = -4.26173e-06
I0701 14:42:24.778363 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:42:24.778370 30423 sgd_solver.cpp:106] Iteration 38700, lr = 0.0395312
I0701 14:42:26.833318 30423 solver.cpp:290] Iteration 38800 (48.6643 iter/s, 2.05489s/100 iter), loss = -4.26173e-06
I0701 14:42:26.833343 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:42:26.833351 30423 sgd_solver.cpp:106] Iteration 38800, lr = 0.039375
I0701 14:42:28.889169 30423 solver.cpp:290] Iteration 38900 (48.6436 iter/s, 2.05577s/100 iter), loss = -4.26173e-06
I0701 14:42:28.889191 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:42:28.889199 30423 sgd_solver.cpp:106] Iteration 38900, lr = 0.0392187
I0701 14:42:30.926120 30423 solver.cpp:473] Iteration 39000, Testing net (#0)
I0701 14:42:32.567250 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.855
I0701 14:42:32.567270 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9892
I0701 14:42:32.567276 30423 solver.cpp:546]     Test net output #2: loss = 0.441 (* 1 = 0.441 loss)
I0701 14:42:32.589989 30423 solver.cpp:290] Iteration 39000 (27.0219 iter/s, 3.7007s/100 iter), loss = -4.26546e-06
I0701 14:42:32.590008 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:42:32.590019 30423 sgd_solver.cpp:106] Iteration 39000, lr = 0.0390625
I0701 14:42:34.646451 30423 solver.cpp:290] Iteration 39100 (48.629 iter/s, 2.05638s/100 iter), loss = -4.26918e-06
I0701 14:42:34.646472 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:42:34.646481 30423 sgd_solver.cpp:106] Iteration 39100, lr = 0.0389063
I0701 14:42:36.699803 30423 solver.cpp:290] Iteration 39200 (48.7028 iter/s, 2.05327s/100 iter), loss = -4.27663e-06
I0701 14:42:36.699825 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:42:36.699831 30423 sgd_solver.cpp:106] Iteration 39200, lr = 0.03875
I0701 14:42:38.755082 30423 solver.cpp:290] Iteration 39300 (48.6571 iter/s, 2.0552s/100 iter), loss = -4.27663e-06
I0701 14:42:38.755105 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:42:38.755113 30423 sgd_solver.cpp:106] Iteration 39300, lr = 0.0385938
I0701 14:42:40.807348 30423 solver.cpp:290] Iteration 39400 (48.7286 iter/s, 2.05218s/100 iter), loss = -4.27663e-06
I0701 14:42:40.807369 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:42:40.807377 30423 sgd_solver.cpp:106] Iteration 39400, lr = 0.0384375
I0701 14:42:42.863030 30423 solver.cpp:290] Iteration 39500 (48.6476 iter/s, 2.0556s/100 iter), loss = -4.28036e-06
I0701 14:42:42.863052 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:42:42.863059 30423 sgd_solver.cpp:106] Iteration 39500, lr = 0.0382813
I0701 14:42:44.919821 30423 solver.cpp:290] Iteration 39600 (48.6214 iter/s, 2.05671s/100 iter), loss = 0.0476148
I0701 14:42:44.919847 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:42:44.919857 30423 sgd_solver.cpp:106] Iteration 39600, lr = 0.038125
I0701 14:42:46.976377 30423 solver.cpp:290] Iteration 39700 (48.627 iter/s, 2.05647s/100 iter), loss = -4.27663e-06
I0701 14:42:46.976400 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:42:46.976408 30423 sgd_solver.cpp:106] Iteration 39700, lr = 0.0379688
I0701 14:42:49.031855 30423 solver.cpp:290] Iteration 39800 (48.6525 iter/s, 2.05539s/100 iter), loss = -4.27663e-06
I0701 14:42:49.031891 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:42:49.031898 30423 sgd_solver.cpp:106] Iteration 39800, lr = 0.0378125
I0701 14:42:51.085171 30423 solver.cpp:290] Iteration 39900 (48.704 iter/s, 2.05322s/100 iter), loss = -4.27663e-06
I0701 14:42:51.085230 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:42:51.085238 30423 sgd_solver.cpp:106] Iteration 39900, lr = 0.0376562
I0701 14:42:53.121315 30423 solver.cpp:600] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/initial/cifar10_jacintonet11v2_iter_40000.caffemodel
I0701 14:42:53.137702 30423 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/initial/cifar10_jacintonet11v2_iter_40000.solverstate
I0701 14:42:53.145059 30423 solver.cpp:473] Iteration 40000, Testing net (#0)
I0701 14:42:54.783779 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8271
I0701 14:42:54.783797 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9881
I0701 14:42:54.783802 30423 solver.cpp:546]     Test net output #2: loss = 0.5876 (* 1 = 0.5876 loss)
I0701 14:42:54.804198 30423 solver.cpp:290] Iteration 40000 (26.8899 iter/s, 3.71887s/100 iter), loss = -4.27663e-06
I0701 14:42:54.804216 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:42:54.804227 30423 sgd_solver.cpp:106] Iteration 40000, lr = 0.0375
I0701 14:42:56.898567 30423 solver.cpp:290] Iteration 40100 (47.7489 iter/s, 2.09429s/100 iter), loss = -4.27663e-06
I0701 14:42:56.904772 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:42:56.904798 30423 sgd_solver.cpp:106] Iteration 40100, lr = 0.0373438
I0701 14:42:58.968219 30423 solver.cpp:290] Iteration 40200 (48.4639 iter/s, 2.06339s/100 iter), loss = -4.27663e-06
I0701 14:42:58.968245 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:42:58.968253 30423 sgd_solver.cpp:106] Iteration 40200, lr = 0.0371875
I0701 14:43:01.022209 30423 solver.cpp:290] Iteration 40300 (48.6877 iter/s, 2.05391s/100 iter), loss = -4.27663e-06
I0701 14:43:01.022231 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:43:01.022238 30423 sgd_solver.cpp:106] Iteration 40300, lr = 0.0370313
I0701 14:43:03.075718 30423 solver.cpp:290] Iteration 40400 (48.6991 iter/s, 2.05343s/100 iter), loss = 0.0476148
I0701 14:43:03.075740 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:43:03.075747 30423 sgd_solver.cpp:106] Iteration 40400, lr = 0.036875
I0701 14:43:05.129328 30423 solver.cpp:290] Iteration 40500 (48.6967 iter/s, 2.05353s/100 iter), loss = -4.27663e-06
I0701 14:43:05.129349 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:43:05.129356 30423 sgd_solver.cpp:106] Iteration 40500, lr = 0.0367188
I0701 14:43:07.182802 30423 solver.cpp:290] Iteration 40600 (48.6999 iter/s, 2.05339s/100 iter), loss = -4.27663e-06
I0701 14:43:07.182823 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:43:07.182832 30423 sgd_solver.cpp:106] Iteration 40600, lr = 0.0365625
I0701 14:43:09.236726 30423 solver.cpp:290] Iteration 40700 (48.6892 iter/s, 2.05384s/100 iter), loss = -4.26173e-06
I0701 14:43:09.236749 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:43:09.236757 30423 sgd_solver.cpp:106] Iteration 40700, lr = 0.0364062
I0701 14:43:11.292444 30423 solver.cpp:290] Iteration 40800 (48.6469 iter/s, 2.05563s/100 iter), loss = -4.26173e-06
I0701 14:43:11.292469 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:43:11.292476 30423 sgd_solver.cpp:106] Iteration 40800, lr = 0.03625
I0701 14:43:13.347424 30423 solver.cpp:290] Iteration 40900 (48.6643 iter/s, 2.05489s/100 iter), loss = -4.26546e-06
I0701 14:43:13.347445 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:43:13.347453 30423 sgd_solver.cpp:106] Iteration 40900, lr = 0.0360937
I0701 14:43:15.387027 30423 solver.cpp:473] Iteration 41000, Testing net (#0)
I0701 14:43:17.028708 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.867299
I0701 14:43:17.028728 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9932
I0701 14:43:17.028735 30423 solver.cpp:546]     Test net output #2: loss = 0.4182 (* 1 = 0.4182 loss)
I0701 14:43:17.048357 30423 solver.cpp:290] Iteration 41000 (27.0211 iter/s, 3.70081s/100 iter), loss = 0.0476148
I0701 14:43:17.048377 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:43:17.048385 30423 sgd_solver.cpp:106] Iteration 41000, lr = 0.0359375
I0701 14:43:19.102771 30423 solver.cpp:290] Iteration 41100 (48.6776 iter/s, 2.05433s/100 iter), loss = -4.26173e-06
I0701 14:43:19.102792 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:43:19.102799 30423 sgd_solver.cpp:106] Iteration 41100, lr = 0.0357813
I0701 14:43:21.155791 30423 solver.cpp:290] Iteration 41200 (48.7107 iter/s, 2.05294s/100 iter), loss = -4.26173e-06
I0701 14:43:21.155838 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:43:21.155845 30423 sgd_solver.cpp:106] Iteration 41200, lr = 0.035625
I0701 14:43:23.208422 30423 solver.cpp:290] Iteration 41300 (48.7205 iter/s, 2.05253s/100 iter), loss = -4.26173e-06
I0701 14:43:23.208446 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:43:23.208452 30423 sgd_solver.cpp:106] Iteration 41300, lr = 0.0354688
I0701 14:43:25.268882 30423 solver.cpp:290] Iteration 41400 (48.5349 iter/s, 2.06037s/100 iter), loss = -4.26173e-06
I0701 14:43:25.268911 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:43:25.268920 30423 sgd_solver.cpp:106] Iteration 41400, lr = 0.0353125
I0701 14:43:27.322945 30423 solver.cpp:290] Iteration 41500 (48.6861 iter/s, 2.05398s/100 iter), loss = -4.26173e-06
I0701 14:43:27.322968 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:43:27.322976 30423 sgd_solver.cpp:106] Iteration 41500, lr = 0.0351562
I0701 14:43:29.378161 30423 solver.cpp:290] Iteration 41600 (48.6587 iter/s, 2.05513s/100 iter), loss = -4.26173e-06
I0701 14:43:29.378187 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:43:29.378196 30423 sgd_solver.cpp:106] Iteration 41600, lr = 0.035
I0701 14:43:31.439659 30423 solver.cpp:290] Iteration 41700 (48.5104 iter/s, 2.06141s/100 iter), loss = -4.26173e-06
I0701 14:43:31.439682 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:43:31.439688 30423 sgd_solver.cpp:106] Iteration 41700, lr = 0.0348438
I0701 14:43:33.494642 30423 solver.cpp:290] Iteration 41800 (48.6642 iter/s, 2.0549s/100 iter), loss = -4.26173e-06
I0701 14:43:33.494669 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:43:33.494676 30423 sgd_solver.cpp:106] Iteration 41800, lr = 0.0346875
I0701 14:43:35.549238 30423 solver.cpp:290] Iteration 41900 (48.6735 iter/s, 2.05451s/100 iter), loss = -4.26173e-06
I0701 14:43:35.549263 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:43:35.549273 30423 sgd_solver.cpp:106] Iteration 41900, lr = 0.0345312
I0701 14:43:37.583055 30423 solver.cpp:473] Iteration 42000, Testing net (#0)
I0701 14:43:39.224354 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8309
I0701 14:43:39.224372 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9883
I0701 14:43:39.224377 30423 solver.cpp:546]     Test net output #2: loss = 0.5865 (* 1 = 0.5865 loss)
I0701 14:43:39.247984 30423 solver.cpp:290] Iteration 42000 (27.0371 iter/s, 3.69862s/100 iter), loss = -4.26173e-06
I0701 14:43:39.248004 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:43:39.248014 30423 sgd_solver.cpp:106] Iteration 42000, lr = 0.034375
I0701 14:43:41.306998 30423 solver.cpp:290] Iteration 42100 (48.5689 iter/s, 2.05893s/100 iter), loss = -4.26173e-06
I0701 14:43:41.307029 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:43:41.307039 30423 sgd_solver.cpp:106] Iteration 42100, lr = 0.0342188
I0701 14:43:43.360148 30423 solver.cpp:290] Iteration 42200 (48.7078 iter/s, 2.05306s/100 iter), loss = -4.26173e-06
I0701 14:43:43.360170 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:43:43.360177 30423 sgd_solver.cpp:106] Iteration 42200, lr = 0.0340625
I0701 14:43:45.413867 30423 solver.cpp:290] Iteration 42300 (48.6941 iter/s, 2.05364s/100 iter), loss = -4.26173e-06
I0701 14:43:45.413889 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:43:45.413897 30423 sgd_solver.cpp:106] Iteration 42300, lr = 0.0339063
I0701 14:43:47.467974 30423 solver.cpp:290] Iteration 42400 (48.685 iter/s, 2.05402s/100 iter), loss = -4.26173e-06
I0701 14:43:47.468000 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:43:47.468009 30423 sgd_solver.cpp:106] Iteration 42400, lr = 0.03375
I0701 14:43:49.521733 30423 solver.cpp:290] Iteration 42500 (48.6932 iter/s, 2.05367s/100 iter), loss = -4.26173e-06
I0701 14:43:49.521780 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:43:49.521790 30423 sgd_solver.cpp:106] Iteration 42500, lr = 0.0335938
I0701 14:43:51.577574 30423 solver.cpp:290] Iteration 42600 (48.6444 iter/s, 2.05574s/100 iter), loss = 0.0476148
I0701 14:43:51.577636 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:43:51.577646 30423 sgd_solver.cpp:106] Iteration 42600, lr = 0.0334375
I0701 14:43:53.632580 30423 solver.cpp:290] Iteration 42700 (48.6645 iter/s, 2.05488s/100 iter), loss = 0.0476148
I0701 14:43:53.632601 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:43:53.632611 30423 sgd_solver.cpp:106] Iteration 42700, lr = 0.0332812
I0701 14:43:55.691485 30423 solver.cpp:290] Iteration 42800 (48.5714 iter/s, 2.05882s/100 iter), loss = -4.26173e-06
I0701 14:43:55.691509 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:43:55.691515 30423 sgd_solver.cpp:106] Iteration 42800, lr = 0.033125
I0701 14:43:57.774216 30423 solver.cpp:290] Iteration 42900 (48.0158 iter/s, 2.08265s/100 iter), loss = -4.26173e-06
I0701 14:43:57.774237 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:43:57.774245 30423 sgd_solver.cpp:106] Iteration 42900, lr = 0.0329687
I0701 14:43:59.808773 30423 solver.cpp:473] Iteration 43000, Testing net (#0)
I0701 14:44:01.452252 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8961
I0701 14:44:01.452270 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9943
I0701 14:44:01.452275 30423 solver.cpp:546]     Test net output #2: loss = 0.3258 (* 1 = 0.3258 loss)
I0701 14:44:01.472195 30423 solver.cpp:290] Iteration 43000 (27.0427 iter/s, 3.69786s/100 iter), loss = -4.26173e-06
I0701 14:44:01.472213 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:44:01.472228 30423 sgd_solver.cpp:106] Iteration 43000, lr = 0.0328125
I0701 14:44:03.535434 30423 solver.cpp:290] Iteration 43100 (48.4693 iter/s, 2.06316s/100 iter), loss = -4.26173e-06
I0701 14:44:03.535457 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:44:03.535466 30423 sgd_solver.cpp:106] Iteration 43100, lr = 0.0326563
I0701 14:44:05.594789 30423 solver.cpp:290] Iteration 43200 (48.5609 iter/s, 2.05927s/100 iter), loss = -4.26173e-06
I0701 14:44:05.594815 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:44:05.594823 30423 sgd_solver.cpp:106] Iteration 43200, lr = 0.0325
I0701 14:44:07.654256 30423 solver.cpp:290] Iteration 43300 (48.5583 iter/s, 2.05938s/100 iter), loss = 0.0476148
I0701 14:44:07.654286 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:44:07.654295 30423 sgd_solver.cpp:106] Iteration 43300, lr = 0.0323438
I0701 14:44:09.714843 30423 solver.cpp:290] Iteration 43400 (48.532 iter/s, 2.0605s/100 iter), loss = 0.0476148
I0701 14:44:09.714871 30423 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 14:44:09.714880 30423 sgd_solver.cpp:106] Iteration 43400, lr = 0.0321875
I0701 14:44:11.770690 30423 solver.cpp:290] Iteration 43500 (48.6438 iter/s, 2.05576s/100 iter), loss = -4.26173e-06
I0701 14:44:11.770712 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:44:11.770720 30423 sgd_solver.cpp:106] Iteration 43500, lr = 0.0320312
I0701 14:44:13.828601 30423 solver.cpp:290] Iteration 43600 (48.5949 iter/s, 2.05783s/100 iter), loss = -4.26173e-06
I0701 14:44:13.828622 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:44:13.828630 30423 sgd_solver.cpp:106] Iteration 43600, lr = 0.031875
I0701 14:44:15.880455 30423 solver.cpp:290] Iteration 43700 (48.7384 iter/s, 2.05177s/100 iter), loss = -4.26173e-06
I0701 14:44:15.880477 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:44:15.880484 30423 sgd_solver.cpp:106] Iteration 43700, lr = 0.0317187
I0701 14:44:17.939230 30423 solver.cpp:290] Iteration 43800 (48.5745 iter/s, 2.05869s/100 iter), loss = -4.26173e-06
I0701 14:44:17.939254 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:44:17.939260 30423 sgd_solver.cpp:106] Iteration 43800, lr = 0.0315625
I0701 14:44:19.999176 30423 solver.cpp:290] Iteration 43900 (48.5469 iter/s, 2.05986s/100 iter), loss = -4.26173e-06
I0701 14:44:19.999215 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:44:19.999222 30423 sgd_solver.cpp:106] Iteration 43900, lr = 0.0314062
I0701 14:44:22.037730 30423 solver.cpp:473] Iteration 44000, Testing net (#0)
I0701 14:44:23.677098 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8771
I0701 14:44:23.677116 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9944
I0701 14:44:23.677122 30423 solver.cpp:546]     Test net output #2: loss = 0.4064 (* 1 = 0.4064 loss)
I0701 14:44:23.697206 30423 solver.cpp:290] Iteration 44000 (27.0424 iter/s, 3.69789s/100 iter), loss = -4.26173e-06
I0701 14:44:23.697222 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:44:23.697235 30423 sgd_solver.cpp:106] Iteration 44000, lr = 0.03125
I0701 14:44:25.751504 30423 solver.cpp:290] Iteration 44100 (48.6803 iter/s, 2.05422s/100 iter), loss = -4.26173e-06
I0701 14:44:25.751526 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:44:25.751533 30423 sgd_solver.cpp:106] Iteration 44100, lr = 0.0310938
I0701 14:44:27.808198 30423 solver.cpp:290] Iteration 44200 (48.6236 iter/s, 2.05661s/100 iter), loss = -4.26173e-06
I0701 14:44:27.808221 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:44:27.808230 30423 sgd_solver.cpp:106] Iteration 44200, lr = 0.0309375
I0701 14:44:29.864799 30423 solver.cpp:290] Iteration 44300 (48.6259 iter/s, 2.05652s/100 iter), loss = -4.26173e-06
I0701 14:44:29.864821 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:44:29.864828 30423 sgd_solver.cpp:106] Iteration 44300, lr = 0.0307813
I0701 14:44:31.921197 30423 solver.cpp:290] Iteration 44400 (48.6307 iter/s, 2.05632s/100 iter), loss = -4.26173e-06
I0701 14:44:31.921221 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:44:31.921231 30423 sgd_solver.cpp:106] Iteration 44400, lr = 0.030625
I0701 14:44:33.977931 30423 solver.cpp:290] Iteration 44500 (48.6228 iter/s, 2.05665s/100 iter), loss = -4.26173e-06
I0701 14:44:33.977953 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:44:33.977962 30423 sgd_solver.cpp:106] Iteration 44500, lr = 0.0304688
I0701 14:44:36.030954 30423 solver.cpp:290] Iteration 44600 (48.7106 iter/s, 2.05294s/100 iter), loss = -4.26173e-06
I0701 14:44:36.030977 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:44:36.030983 30423 sgd_solver.cpp:106] Iteration 44600, lr = 0.0303125
I0701 14:44:38.083209 30423 solver.cpp:290] Iteration 44700 (48.7289 iter/s, 2.05217s/100 iter), loss = -4.26173e-06
I0701 14:44:38.083230 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:44:38.083240 30423 sgd_solver.cpp:106] Iteration 44700, lr = 0.0301562
I0701 14:44:40.138162 30423 solver.cpp:290] Iteration 44800 (48.6649 iter/s, 2.05487s/100 iter), loss = -4.26173e-06
I0701 14:44:40.138185 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:44:40.138192 30423 sgd_solver.cpp:106] Iteration 44800, lr = 0.03
I0701 14:44:42.193058 30423 solver.cpp:290] Iteration 44900 (48.6662 iter/s, 2.05481s/100 iter), loss = -4.26173e-06
I0701 14:44:42.193079 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:44:42.193086 30423 sgd_solver.cpp:106] Iteration 44900, lr = 0.0298437
I0701 14:44:44.231375 30423 solver.cpp:473] Iteration 45000, Testing net (#0)
I0701 14:44:45.874778 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8964
I0701 14:44:45.874797 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9968
I0701 14:44:45.874802 30423 solver.cpp:546]     Test net output #2: loss = 0.3096 (* 1 = 0.3096 loss)
I0701 14:44:45.895874 30423 solver.cpp:290] Iteration 45000 (27.0074 iter/s, 3.70269s/100 iter), loss = -4.26173e-06
I0701 14:44:45.895890 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:44:45.895902 30423 sgd_solver.cpp:106] Iteration 45000, lr = 0.0296875
I0701 14:44:47.953851 30423 solver.cpp:290] Iteration 45100 (48.5932 iter/s, 2.0579s/100 iter), loss = -4.26173e-06
I0701 14:44:47.953873 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:44:47.953879 30423 sgd_solver.cpp:106] Iteration 45100, lr = 0.0295313
I0701 14:44:50.011612 30423 solver.cpp:290] Iteration 45200 (48.5985 iter/s, 2.05768s/100 iter), loss = -4.26173e-06
I0701 14:44:50.011634 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:44:50.011641 30423 sgd_solver.cpp:106] Iteration 45200, lr = 0.029375
I0701 14:44:52.064107 30423 solver.cpp:290] Iteration 45300 (48.7232 iter/s, 2.05241s/100 iter), loss = -4.26173e-06
I0701 14:44:52.064180 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:44:52.064188 30423 sgd_solver.cpp:106] Iteration 45300, lr = 0.0292188
I0701 14:44:54.118983 30423 solver.cpp:290] Iteration 45400 (48.6679 iter/s, 2.05474s/100 iter), loss = -4.26173e-06
I0701 14:44:54.119005 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:44:54.119014 30423 sgd_solver.cpp:106] Iteration 45400, lr = 0.0290625
I0701 14:44:56.173449 30423 solver.cpp:290] Iteration 45500 (48.6764 iter/s, 2.05438s/100 iter), loss = -4.26173e-06
I0701 14:44:56.173471 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:44:56.173478 30423 sgd_solver.cpp:106] Iteration 45500, lr = 0.0289063
I0701 14:44:58.245753 30423 solver.cpp:290] Iteration 45600 (48.2574 iter/s, 2.07222s/100 iter), loss = -4.26173e-06
I0701 14:44:58.245774 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:44:58.245782 30423 sgd_solver.cpp:106] Iteration 45600, lr = 0.02875
I0701 14:45:00.298192 30423 solver.cpp:290] Iteration 45700 (48.7245 iter/s, 2.05236s/100 iter), loss = -4.26173e-06
I0701 14:45:00.298215 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:45:00.298221 30423 sgd_solver.cpp:106] Iteration 45700, lr = 0.0285937
I0701 14:45:02.353307 30423 solver.cpp:290] Iteration 45800 (48.661 iter/s, 2.05503s/100 iter), loss = -4.26173e-06
I0701 14:45:02.353329 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:45:02.353337 30423 sgd_solver.cpp:106] Iteration 45800, lr = 0.0284375
I0701 14:45:04.405807 30423 solver.cpp:290] Iteration 45900 (48.7231 iter/s, 2.05241s/100 iter), loss = -4.26173e-06
I0701 14:45:04.405831 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:45:04.405838 30423 sgd_solver.cpp:106] Iteration 45900, lr = 0.0282812
I0701 14:45:06.443317 30423 solver.cpp:473] Iteration 46000, Testing net (#0)
I0701 14:45:08.084457 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9055
I0701 14:45:08.084476 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9976
I0701 14:45:08.084482 30423 solver.cpp:546]     Test net output #2: loss = 0.2594 (* 1 = 0.2594 loss)
I0701 14:45:08.104159 30423 solver.cpp:290] Iteration 46000 (27.04 iter/s, 3.69823s/100 iter), loss = -4.26173e-06
I0701 14:45:08.104179 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:45:08.104187 30423 sgd_solver.cpp:106] Iteration 46000, lr = 0.028125
I0701 14:45:10.161810 30423 solver.cpp:290] Iteration 46100 (48.601 iter/s, 2.05757s/100 iter), loss = -4.26173e-06
I0701 14:45:10.161833 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:45:10.161840 30423 sgd_solver.cpp:106] Iteration 46100, lr = 0.0279688
I0701 14:45:12.215495 30423 solver.cpp:290] Iteration 46200 (48.6949 iter/s, 2.0536s/100 iter), loss = -4.26173e-06
I0701 14:45:12.215517 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:45:12.215524 30423 sgd_solver.cpp:106] Iteration 46200, lr = 0.0278125
I0701 14:45:14.271102 30423 solver.cpp:290] Iteration 46300 (48.6494 iter/s, 2.05553s/100 iter), loss = -4.26173e-06
I0701 14:45:14.271124 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:45:14.271131 30423 sgd_solver.cpp:106] Iteration 46300, lr = 0.0276563
I0701 14:45:16.329638 30423 solver.cpp:290] Iteration 46400 (48.5801 iter/s, 2.05845s/100 iter), loss = -4.26173e-06
I0701 14:45:16.329660 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:45:16.329668 30423 sgd_solver.cpp:106] Iteration 46400, lr = 0.0275
I0701 14:45:18.383194 30423 solver.cpp:290] Iteration 46500 (48.698 iter/s, 2.05347s/100 iter), loss = -4.26173e-06
I0701 14:45:18.383216 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:45:18.383224 30423 sgd_solver.cpp:106] Iteration 46500, lr = 0.0273438
I0701 14:45:20.438479 30423 solver.cpp:290] Iteration 46600 (48.657 iter/s, 2.0552s/100 iter), loss = -4.26173e-06
I0701 14:45:20.438513 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:45:20.438520 30423 sgd_solver.cpp:106] Iteration 46600, lr = 0.0271875
I0701 14:45:22.498356 30423 solver.cpp:290] Iteration 46700 (48.5488 iter/s, 2.05978s/100 iter), loss = -4.26173e-06
I0701 14:45:22.498455 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:45:22.498462 30423 sgd_solver.cpp:106] Iteration 46700, lr = 0.0270312
I0701 14:45:24.553825 30423 solver.cpp:290] Iteration 46800 (48.6544 iter/s, 2.05531s/100 iter), loss = -4.26173e-06
I0701 14:45:24.553848 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:45:24.553854 30423 sgd_solver.cpp:106] Iteration 46800, lr = 0.026875
I0701 14:45:26.608314 30423 solver.cpp:290] Iteration 46900 (48.6759 iter/s, 2.0544s/100 iter), loss = -4.26173e-06
I0701 14:45:26.608340 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:45:26.608346 30423 sgd_solver.cpp:106] Iteration 46900, lr = 0.0267187
I0701 14:45:28.639048 30423 solver.cpp:473] Iteration 47000, Testing net (#0)
I0701 14:45:30.277849 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9061
I0701 14:45:30.277870 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9962
I0701 14:45:30.277875 30423 solver.cpp:546]     Test net output #2: loss = 0.2588 (* 1 = 0.2588 loss)
I0701 14:45:30.298075 30423 solver.cpp:290] Iteration 47000 (27.1029 iter/s, 3.68964s/100 iter), loss = -4.26173e-06
I0701 14:45:30.298094 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:45:30.298105 30423 sgd_solver.cpp:106] Iteration 47000, lr = 0.0265625
I0701 14:45:32.356037 30423 solver.cpp:290] Iteration 47100 (48.5936 iter/s, 2.05788s/100 iter), loss = -4.26173e-06
I0701 14:45:32.356060 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:45:32.356066 30423 sgd_solver.cpp:106] Iteration 47100, lr = 0.0264063
I0701 14:45:34.409714 30423 solver.cpp:290] Iteration 47200 (48.6952 iter/s, 2.05359s/100 iter), loss = -4.26173e-06
I0701 14:45:34.409739 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:45:34.409746 30423 sgd_solver.cpp:106] Iteration 47200, lr = 0.02625
I0701 14:45:36.465904 30423 solver.cpp:290] Iteration 47300 (48.6357 iter/s, 2.0561s/100 iter), loss = -4.26173e-06
I0701 14:45:36.465926 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:45:36.465934 30423 sgd_solver.cpp:106] Iteration 47300, lr = 0.0260938
I0701 14:45:38.519740 30423 solver.cpp:290] Iteration 47400 (48.6913 iter/s, 2.05375s/100 iter), loss = -4.26173e-06
I0701 14:45:38.519762 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:45:38.519769 30423 sgd_solver.cpp:106] Iteration 47400, lr = 0.0259375
I0701 14:45:40.573487 30423 solver.cpp:290] Iteration 47500 (48.6935 iter/s, 2.05366s/100 iter), loss = -4.26173e-06
I0701 14:45:40.573508 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:45:40.573514 30423 sgd_solver.cpp:106] Iteration 47500, lr = 0.0257812
I0701 14:45:42.629943 30423 solver.cpp:290] Iteration 47600 (48.6293 iter/s, 2.05638s/100 iter), loss = -4.26173e-06
I0701 14:45:42.629966 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:45:42.629973 30423 sgd_solver.cpp:106] Iteration 47600, lr = 0.025625
I0701 14:45:44.682164 30423 solver.cpp:290] Iteration 47700 (48.7296 iter/s, 2.05214s/100 iter), loss = -4.26173e-06
I0701 14:45:44.682186 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:45:44.682193 30423 sgd_solver.cpp:106] Iteration 47700, lr = 0.0254687
I0701 14:45:46.736017 30423 solver.cpp:290] Iteration 47800 (48.6909 iter/s, 2.05377s/100 iter), loss = -4.26173e-06
I0701 14:45:46.736038 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:45:46.736045 30423 sgd_solver.cpp:106] Iteration 47800, lr = 0.0253125
I0701 14:45:48.789376 30423 solver.cpp:290] Iteration 47900 (48.7026 iter/s, 2.05328s/100 iter), loss = -4.26173e-06
I0701 14:45:48.789399 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:45:48.789405 30423 sgd_solver.cpp:106] Iteration 47900, lr = 0.0251562
I0701 14:45:50.825191 30423 solver.cpp:473] Iteration 48000, Testing net (#0)
I0701 14:45:52.465700 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9084
I0701 14:45:52.465734 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9967
I0701 14:45:52.465739 30423 solver.cpp:546]     Test net output #2: loss = 0.2529 (* 1 = 0.2529 loss)
I0701 14:45:52.485479 30423 solver.cpp:290] Iteration 48000 (27.0565 iter/s, 3.69597s/100 iter), loss = -4.26173e-06
I0701 14:45:52.485507 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:45:52.485517 30423 sgd_solver.cpp:106] Iteration 48000, lr = 0.025
I0701 14:45:54.543265 30423 solver.cpp:290] Iteration 48100 (48.598 iter/s, 2.0577s/100 iter), loss = -4.26173e-06
I0701 14:45:54.543323 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:45:54.543331 30423 sgd_solver.cpp:106] Iteration 48100, lr = 0.0248438
I0701 14:45:56.597376 30423 solver.cpp:290] Iteration 48200 (48.6856 iter/s, 2.05399s/100 iter), loss = -4.26173e-06
I0701 14:45:56.597399 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:45:56.597409 30423 sgd_solver.cpp:106] Iteration 48200, lr = 0.0246875
I0701 14:45:58.678136 30423 solver.cpp:290] Iteration 48300 (48.0613 iter/s, 2.08068s/100 iter), loss = -4.26173e-06
I0701 14:45:58.678158 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:45:58.678165 30423 sgd_solver.cpp:106] Iteration 48300, lr = 0.0245313
I0701 14:46:00.732769 30423 solver.cpp:290] Iteration 48400 (48.6725 iter/s, 2.05455s/100 iter), loss = -4.26173e-06
I0701 14:46:00.732797 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:46:00.732807 30423 sgd_solver.cpp:106] Iteration 48400, lr = 0.024375
I0701 14:46:02.789285 30423 solver.cpp:290] Iteration 48500 (48.6281 iter/s, 2.05643s/100 iter), loss = -4.26173e-06
I0701 14:46:02.789314 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:46:02.789324 30423 sgd_solver.cpp:106] Iteration 48500, lr = 0.0242188
I0701 14:46:04.846447 30423 solver.cpp:290] Iteration 48600 (48.6127 iter/s, 2.05707s/100 iter), loss = -4.26173e-06
I0701 14:46:04.846470 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:46:04.846477 30423 sgd_solver.cpp:106] Iteration 48600, lr = 0.0240625
I0701 14:46:06.901278 30423 solver.cpp:290] Iteration 48700 (48.6678 iter/s, 2.05475s/100 iter), loss = -4.26173e-06
I0701 14:46:06.901299 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:46:06.901306 30423 sgd_solver.cpp:106] Iteration 48700, lr = 0.0239062
I0701 14:46:08.956233 30423 solver.cpp:290] Iteration 48800 (48.6648 iter/s, 2.05487s/100 iter), loss = -4.26173e-06
I0701 14:46:08.956254 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:46:08.956261 30423 sgd_solver.cpp:106] Iteration 48800, lr = 0.02375
I0701 14:46:11.017561 30423 solver.cpp:290] Iteration 48900 (48.5144 iter/s, 2.06124s/100 iter), loss = -4.26173e-06
I0701 14:46:11.017590 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:46:11.017598 30423 sgd_solver.cpp:106] Iteration 48900, lr = 0.0235937
I0701 14:46:13.050593 30423 solver.cpp:473] Iteration 49000, Testing net (#0)
I0701 14:46:14.690953 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9147
I0701 14:46:14.690971 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9975
I0701 14:46:14.690978 30423 solver.cpp:546]     Test net output #2: loss = 0.2368 (* 1 = 0.2368 loss)
I0701 14:46:14.712218 30423 solver.cpp:290] Iteration 49000 (27.067 iter/s, 3.69453s/100 iter), loss = -4.26173e-06
I0701 14:46:14.712234 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:46:14.712247 30423 sgd_solver.cpp:106] Iteration 49000, lr = 0.0234375
I0701 14:46:16.772047 30423 solver.cpp:290] Iteration 49100 (48.5495 iter/s, 2.05975s/100 iter), loss = -4.26173e-06
I0701 14:46:16.772073 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:46:16.772080 30423 sgd_solver.cpp:106] Iteration 49100, lr = 0.0232813
I0701 14:46:18.831336 30423 solver.cpp:290] Iteration 49200 (48.5624 iter/s, 2.05921s/100 iter), loss = -4.26173e-06
I0701 14:46:18.831359 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:46:18.831367 30423 sgd_solver.cpp:106] Iteration 49200, lr = 0.023125
I0701 14:46:20.885097 30423 solver.cpp:290] Iteration 49300 (48.6932 iter/s, 2.05368s/100 iter), loss = -4.26173e-06
I0701 14:46:20.885118 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:46:20.885125 30423 sgd_solver.cpp:106] Iteration 49300, lr = 0.0229688
I0701 14:46:22.939044 30423 solver.cpp:290] Iteration 49400 (48.6887 iter/s, 2.05387s/100 iter), loss = -4.26173e-06
I0701 14:46:22.939083 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:46:22.939092 30423 sgd_solver.cpp:106] Iteration 49400, lr = 0.0228125
I0701 14:46:24.993674 30423 solver.cpp:290] Iteration 49500 (48.6729 iter/s, 2.05453s/100 iter), loss = -4.26173e-06
I0701 14:46:24.993746 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:46:24.993753 30423 sgd_solver.cpp:106] Iteration 49500, lr = 0.0226563
I0701 14:46:27.048005 30423 solver.cpp:290] Iteration 49600 (48.6807 iter/s, 2.0542s/100 iter), loss = -4.26173e-06
I0701 14:46:27.048027 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:46:27.048034 30423 sgd_solver.cpp:106] Iteration 49600, lr = 0.0225
I0701 14:46:29.102828 30423 solver.cpp:290] Iteration 49700 (48.6679 iter/s, 2.05474s/100 iter), loss = -4.26173e-06
I0701 14:46:29.102850 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:46:29.102857 30423 sgd_solver.cpp:106] Iteration 49700, lr = 0.0223437
I0701 14:46:31.161952 30423 solver.cpp:290] Iteration 49800 (48.5663 iter/s, 2.05904s/100 iter), loss = -4.26173e-06
I0701 14:46:31.161974 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:46:31.161983 30423 sgd_solver.cpp:106] Iteration 49800, lr = 0.0221875
I0701 14:46:33.221174 30423 solver.cpp:290] Iteration 49900 (48.564 iter/s, 2.05914s/100 iter), loss = -4.26173e-06
I0701 14:46:33.221195 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:46:33.221204 30423 sgd_solver.cpp:106] Iteration 49900, lr = 0.0220312
I0701 14:46:35.255352 30423 solver.cpp:600] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/initial/cifar10_jacintonet11v2_iter_50000.caffemodel
I0701 14:46:35.271545 30423 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/initial/cifar10_jacintonet11v2_iter_50000.solverstate
I0701 14:46:35.278841 30423 solver.cpp:473] Iteration 50000, Testing net (#0)
I0701 14:46:36.917583 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9147
I0701 14:46:36.917603 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9973
I0701 14:46:36.917610 30423 solver.cpp:546]     Test net output #2: loss = 0.2317 (* 1 = 0.2317 loss)
I0701 14:46:36.937353 30423 solver.cpp:290] Iteration 50000 (26.9103 iter/s, 3.71605s/100 iter), loss = -4.26173e-06
I0701 14:46:36.937379 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:46:36.937388 30423 sgd_solver.cpp:106] Iteration 50000, lr = 0.021875
I0701 14:46:38.989979 30423 solver.cpp:290] Iteration 50100 (48.7201 iter/s, 2.05254s/100 iter), loss = -4.26173e-06
I0701 14:46:38.990000 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:46:38.990008 30423 sgd_solver.cpp:106] Iteration 50100, lr = 0.0217188
I0701 14:46:41.046922 30423 solver.cpp:290] Iteration 50200 (48.6177 iter/s, 2.05686s/100 iter), loss = -4.26173e-06
I0701 14:46:41.046946 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:46:41.046952 30423 sgd_solver.cpp:106] Iteration 50200, lr = 0.0215625
I0701 14:46:43.118438 30423 solver.cpp:290] Iteration 50300 (48.2758 iter/s, 2.07143s/100 iter), loss = -4.26173e-06
I0701 14:46:43.118460 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:46:43.118468 30423 sgd_solver.cpp:106] Iteration 50300, lr = 0.0214063
I0701 14:46:45.172659 30423 solver.cpp:290] Iteration 50400 (48.6822 iter/s, 2.05414s/100 iter), loss = -4.26173e-06
I0701 14:46:45.172682 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:46:45.172688 30423 sgd_solver.cpp:106] Iteration 50400, lr = 0.02125
I0701 14:46:47.230600 30423 solver.cpp:290] Iteration 50500 (48.5942 iter/s, 2.05786s/100 iter), loss = -4.26173e-06
I0701 14:46:47.230623 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:46:47.230630 30423 sgd_solver.cpp:106] Iteration 50500, lr = 0.0210938
I0701 14:46:49.284802 30423 solver.cpp:290] Iteration 50600 (48.6827 iter/s, 2.05412s/100 iter), loss = -4.26173e-06
I0701 14:46:49.284824 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:46:49.284832 30423 sgd_solver.cpp:106] Iteration 50600, lr = 0.0209375
I0701 14:46:51.342965 30423 solver.cpp:290] Iteration 50700 (48.589 iter/s, 2.05808s/100 iter), loss = -4.26173e-06
I0701 14:46:51.342989 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:46:51.342998 30423 sgd_solver.cpp:106] Iteration 50700, lr = 0.0207812
I0701 14:46:53.398942 30423 solver.cpp:290] Iteration 50800 (48.6407 iter/s, 2.05589s/100 iter), loss = -4.26173e-06
I0701 14:46:53.398968 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:46:53.398977 30423 sgd_solver.cpp:106] Iteration 50800, lr = 0.020625
I0701 14:46:55.457875 30423 solver.cpp:290] Iteration 50900 (48.5709 iter/s, 2.05885s/100 iter), loss = -4.26173e-06
I0701 14:46:55.457940 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:46:55.457948 30423 sgd_solver.cpp:106] Iteration 50900, lr = 0.0204687
I0701 14:46:57.544445 30423 solver.cpp:473] Iteration 51000, Testing net (#0)
I0701 14:46:59.189615 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9157
I0701 14:46:59.189635 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9975
I0701 14:46:59.189640 30423 solver.cpp:546]     Test net output #2: loss = 0.2279 (* 1 = 0.2279 loss)
I0701 14:46:59.209496 30423 solver.cpp:290] Iteration 51000 (26.6563 iter/s, 3.75146s/100 iter), loss = -4.26173e-06
I0701 14:46:59.209516 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:46:59.209528 30423 sgd_solver.cpp:106] Iteration 51000, lr = 0.0203125
I0701 14:47:01.263679 30423 solver.cpp:290] Iteration 51100 (48.683 iter/s, 2.05411s/100 iter), loss = -4.26173e-06
I0701 14:47:01.263702 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:47:01.263708 30423 sgd_solver.cpp:106] Iteration 51100, lr = 0.0201563
I0701 14:47:03.324226 30423 solver.cpp:290] Iteration 51200 (48.5328 iter/s, 2.06046s/100 iter), loss = -4.26173e-06
I0701 14:47:03.324252 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:47:03.324262 30423 sgd_solver.cpp:106] Iteration 51200, lr = 0.02
I0701 14:47:05.382551 30423 solver.cpp:290] Iteration 51300 (48.5852 iter/s, 2.05824s/100 iter), loss = -4.26173e-06
I0701 14:47:05.382575 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:47:05.382580 30423 sgd_solver.cpp:106] Iteration 51300, lr = 0.0198438
I0701 14:47:07.437623 30423 solver.cpp:290] Iteration 51400 (48.6621 iter/s, 2.05499s/100 iter), loss = -4.26173e-06
I0701 14:47:07.437645 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:47:07.437652 30423 sgd_solver.cpp:106] Iteration 51400, lr = 0.0196875
I0701 14:47:09.492485 30423 solver.cpp:290] Iteration 51500 (48.667 iter/s, 2.05478s/100 iter), loss = -4.26173e-06
I0701 14:47:09.492506 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:47:09.492514 30423 sgd_solver.cpp:106] Iteration 51500, lr = 0.0195312
I0701 14:47:11.547696 30423 solver.cpp:290] Iteration 51600 (48.6588 iter/s, 2.05513s/100 iter), loss = -4.26173e-06
I0701 14:47:11.547721 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:47:11.547730 30423 sgd_solver.cpp:106] Iteration 51600, lr = 0.019375
I0701 14:47:13.604037 30423 solver.cpp:290] Iteration 51700 (48.6321 iter/s, 2.05625s/100 iter), loss = -4.26173e-06
I0701 14:47:13.604059 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:47:13.604068 30423 sgd_solver.cpp:106] Iteration 51700, lr = 0.0192187
I0701 14:47:15.658852 30423 solver.cpp:290] Iteration 51800 (48.6681 iter/s, 2.05473s/100 iter), loss = -4.26173e-06
I0701 14:47:15.658874 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:47:15.658882 30423 sgd_solver.cpp:106] Iteration 51800, lr = 0.0190625
I0701 14:47:17.714143 30423 solver.cpp:290] Iteration 51900 (48.6569 iter/s, 2.05521s/100 iter), loss = -4.26173e-06
I0701 14:47:17.714164 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:47:17.714172 30423 sgd_solver.cpp:106] Iteration 51900, lr = 0.0189062
I0701 14:47:19.748718 30423 solver.cpp:473] Iteration 52000, Testing net (#0)
I0701 14:47:21.387818 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9154
I0701 14:47:21.387837 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9976
I0701 14:47:21.387842 30423 solver.cpp:546]     Test net output #2: loss = 0.2163 (* 1 = 0.2163 loss)
I0701 14:47:21.407378 30423 solver.cpp:290] Iteration 52000 (27.0774 iter/s, 3.69311s/100 iter), loss = -4.26173e-06
I0701 14:47:21.407394 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:47:21.407410 30423 sgd_solver.cpp:106] Iteration 52000, lr = 0.01875
I0701 14:47:23.468564 30423 solver.cpp:290] Iteration 52100 (48.5176 iter/s, 2.06111s/100 iter), loss = -4.26173e-06
I0701 14:47:23.468597 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:47:23.468605 30423 sgd_solver.cpp:106] Iteration 52100, lr = 0.0185938
I0701 14:47:25.524413 30423 solver.cpp:290] Iteration 52200 (48.6439 iter/s, 2.05576s/100 iter), loss = -4.26173e-06
I0701 14:47:25.524467 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:47:25.524477 30423 sgd_solver.cpp:106] Iteration 52200, lr = 0.0184375
I0701 14:47:27.579983 30423 solver.cpp:290] Iteration 52300 (48.651 iter/s, 2.05546s/100 iter), loss = -4.26173e-06
I0701 14:47:27.580006 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:47:27.580013 30423 sgd_solver.cpp:106] Iteration 52300, lr = 0.0182813
I0701 14:47:29.635046 30423 solver.cpp:290] Iteration 52400 (48.6623 iter/s, 2.05498s/100 iter), loss = -4.26173e-06
I0701 14:47:29.635071 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:47:29.635078 30423 sgd_solver.cpp:106] Iteration 52400, lr = 0.018125
I0701 14:47:31.691046 30423 solver.cpp:290] Iteration 52500 (48.6401 iter/s, 2.05592s/100 iter), loss = -4.26173e-06
I0701 14:47:31.691071 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:47:31.691079 30423 sgd_solver.cpp:106] Iteration 52500, lr = 0.0179687
I0701 14:47:33.744526 30423 solver.cpp:290] Iteration 52600 (48.6998 iter/s, 2.0534s/100 iter), loss = -4.26173e-06
I0701 14:47:33.744547 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:47:33.744556 30423 sgd_solver.cpp:106] Iteration 52600, lr = 0.0178125
I0701 14:47:35.800282 30423 solver.cpp:290] Iteration 52700 (48.6459 iter/s, 2.05567s/100 iter), loss = -4.26173e-06
I0701 14:47:35.800309 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:47:35.800318 30423 sgd_solver.cpp:106] Iteration 52700, lr = 0.0176562
I0701 14:47:37.854717 30423 solver.cpp:290] Iteration 52800 (48.6772 iter/s, 2.05435s/100 iter), loss = -4.26173e-06
I0701 14:47:37.854738 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:47:37.854745 30423 sgd_solver.cpp:106] Iteration 52800, lr = 0.0175
I0701 14:47:39.910353 30423 solver.cpp:290] Iteration 52900 (48.6487 iter/s, 2.05555s/100 iter), loss = -4.26173e-06
I0701 14:47:39.910378 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:47:39.910392 30423 sgd_solver.cpp:106] Iteration 52900, lr = 0.0173437
I0701 14:47:41.948707 30423 solver.cpp:473] Iteration 53000, Testing net (#0)
I0701 14:47:43.595417 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.918
I0701 14:47:43.595435 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9972
I0701 14:47:43.595441 30423 solver.cpp:546]     Test net output #2: loss = 0.2204 (* 1 = 0.2204 loss)
I0701 14:47:43.615281 30423 solver.cpp:290] Iteration 53000 (26.992 iter/s, 3.7048s/100 iter), loss = -4.26173e-06
I0701 14:47:43.615308 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:47:43.615314 30423 sgd_solver.cpp:106] Iteration 53000, lr = 0.0171875
I0701 14:47:45.669901 30423 solver.cpp:290] Iteration 53100 (48.6728 iter/s, 2.05453s/100 iter), loss = -4.26173e-06
I0701 14:47:45.669924 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:47:45.669930 30423 sgd_solver.cpp:106] Iteration 53100, lr = 0.0170313
I0701 14:47:47.725976 30423 solver.cpp:290] Iteration 53200 (48.6383 iter/s, 2.05599s/100 iter), loss = -4.26173e-06
I0701 14:47:47.725998 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:47:47.726006 30423 sgd_solver.cpp:106] Iteration 53200, lr = 0.016875
I0701 14:47:49.783406 30423 solver.cpp:290] Iteration 53300 (48.6063 iter/s, 2.05735s/100 iter), loss = -4.26173e-06
I0701 14:47:49.783429 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:47:49.783435 30423 sgd_solver.cpp:106] Iteration 53300, lr = 0.0167188
I0701 14:47:51.838654 30423 solver.cpp:290] Iteration 53400 (48.6579 iter/s, 2.05516s/100 iter), loss = -4.26173e-06
I0701 14:47:51.838676 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:47:51.838683 30423 sgd_solver.cpp:106] Iteration 53400, lr = 0.0165625
I0701 14:47:53.894968 30423 solver.cpp:290] Iteration 53500 (48.6327 iter/s, 2.05623s/100 iter), loss = -4.26173e-06
I0701 14:47:53.895000 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:47:53.895007 30423 sgd_solver.cpp:106] Iteration 53500, lr = 0.0164063
I0701 14:47:55.950599 30423 solver.cpp:290] Iteration 53600 (48.6491 iter/s, 2.05554s/100 iter), loss = -4.26173e-06
I0701 14:47:55.950714 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:47:55.950727 30423 sgd_solver.cpp:106] Iteration 53600, lr = 0.01625
I0701 14:47:58.035223 30423 solver.cpp:290] Iteration 53700 (47.9743 iter/s, 2.08445s/100 iter), loss = -4.26173e-06
I0701 14:47:58.035248 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:47:58.035255 30423 sgd_solver.cpp:106] Iteration 53700, lr = 0.0160937
I0701 14:48:00.090783 30423 solver.cpp:290] Iteration 53800 (48.6506 iter/s, 2.05547s/100 iter), loss = -4.26173e-06
I0701 14:48:00.090806 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:48:00.090812 30423 sgd_solver.cpp:106] Iteration 53800, lr = 0.0159375
I0701 14:48:02.144462 30423 solver.cpp:290] Iteration 53900 (48.6951 iter/s, 2.0536s/100 iter), loss = -4.26173e-06
I0701 14:48:02.144485 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:48:02.144492 30423 sgd_solver.cpp:106] Iteration 53900, lr = 0.0157812
I0701 14:48:04.181608 30423 solver.cpp:473] Iteration 54000, Testing net (#0)
I0701 14:48:05.822726 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9178
I0701 14:48:05.822746 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9973
I0701 14:48:05.822753 30423 solver.cpp:546]     Test net output #2: loss = 0.211 (* 1 = 0.211 loss)
I0701 14:48:05.842289 30423 solver.cpp:290] Iteration 54000 (27.0438 iter/s, 3.6977s/100 iter), loss = -4.26173e-06
I0701 14:48:05.842309 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:48:05.842322 30423 sgd_solver.cpp:106] Iteration 54000, lr = 0.015625
I0701 14:48:07.904873 30423 solver.cpp:290] Iteration 54100 (48.4848 iter/s, 2.0625s/100 iter), loss = -4.26173e-06
I0701 14:48:07.904896 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:48:07.904901 30423 sgd_solver.cpp:106] Iteration 54100, lr = 0.0154688
I0701 14:48:09.958731 30423 solver.cpp:290] Iteration 54200 (48.6908 iter/s, 2.05378s/100 iter), loss = -4.26173e-06
I0701 14:48:09.958753 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:48:09.958760 30423 sgd_solver.cpp:106] Iteration 54200, lr = 0.0153125
I0701 14:48:12.012756 30423 solver.cpp:290] Iteration 54300 (48.6869 iter/s, 2.05394s/100 iter), loss = -4.26173e-06
I0701 14:48:12.012778 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:48:12.012785 30423 sgd_solver.cpp:106] Iteration 54300, lr = 0.0151563
I0701 14:48:14.070789 30423 solver.cpp:290] Iteration 54400 (48.592 iter/s, 2.05795s/100 iter), loss = -4.26173e-06
I0701 14:48:14.070811 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:48:14.070818 30423 sgd_solver.cpp:106] Iteration 54400, lr = 0.015
I0701 14:48:16.124454 30423 solver.cpp:290] Iteration 54500 (48.6954 iter/s, 2.05358s/100 iter), loss = -4.26173e-06
I0701 14:48:16.124476 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:48:16.124483 30423 sgd_solver.cpp:106] Iteration 54500, lr = 0.0148437
I0701 14:48:18.178889 30423 solver.cpp:290] Iteration 54600 (48.6772 iter/s, 2.05435s/100 iter), loss = -4.26173e-06
I0701 14:48:18.178911 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:48:18.178918 30423 sgd_solver.cpp:106] Iteration 54600, lr = 0.0146875
I0701 14:48:20.233716 30423 solver.cpp:290] Iteration 54700 (48.6679 iter/s, 2.05474s/100 iter), loss = -4.26173e-06
I0701 14:48:20.233739 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:48:20.233748 30423 sgd_solver.cpp:106] Iteration 54700, lr = 0.0145312
I0701 14:48:22.289625 30423 solver.cpp:290] Iteration 54800 (48.6423 iter/s, 2.05582s/100 iter), loss = -4.26173e-06
I0701 14:48:22.289647 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:48:22.289655 30423 sgd_solver.cpp:106] Iteration 54800, lr = 0.014375
I0701 14:48:24.345885 30423 solver.cpp:290] Iteration 54900 (48.634 iter/s, 2.05618s/100 iter), loss = -4.26173e-06
I0701 14:48:24.345927 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:48:24.345934 30423 sgd_solver.cpp:106] Iteration 54900, lr = 0.0142187
I0701 14:48:26.382691 30423 solver.cpp:473] Iteration 55000, Testing net (#0)
I0701 14:48:28.026643 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9158
I0701 14:48:28.026662 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9973
I0701 14:48:28.026667 30423 solver.cpp:546]     Test net output #2: loss = 0.2116 (* 1 = 0.2116 loss)
I0701 14:48:28.046877 30423 solver.cpp:290] Iteration 55000 (27.0208 iter/s, 3.70085s/100 iter), loss = -4.26173e-06
I0701 14:48:28.046895 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:48:28.046907 30423 sgd_solver.cpp:106] Iteration 55000, lr = 0.0140625
I0701 14:48:30.103229 30423 solver.cpp:290] Iteration 55100 (48.6317 iter/s, 2.05627s/100 iter), loss = -4.26173e-06
I0701 14:48:30.103251 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:48:30.103258 30423 sgd_solver.cpp:106] Iteration 55100, lr = 0.0139063
I0701 14:48:32.157374 30423 solver.cpp:290] Iteration 55200 (48.6841 iter/s, 2.05406s/100 iter), loss = -4.26173e-06
I0701 14:48:32.157402 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:48:32.157411 30423 sgd_solver.cpp:106] Iteration 55200, lr = 0.01375
I0701 14:48:34.208113 30423 solver.cpp:290] Iteration 55300 (48.765 iter/s, 2.05065s/100 iter), loss = -4.26173e-06
I0701 14:48:34.208137 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:48:34.208147 30423 sgd_solver.cpp:106] Iteration 55300, lr = 0.0135938
I0701 14:48:36.265686 30423 solver.cpp:290] Iteration 55400 (48.603 iter/s, 2.05749s/100 iter), loss = -4.26173e-06
I0701 14:48:36.265709 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:48:36.265715 30423 sgd_solver.cpp:106] Iteration 55400, lr = 0.0134375
I0701 14:48:38.321481 30423 solver.cpp:290] Iteration 55500 (48.645 iter/s, 2.05571s/100 iter), loss = -4.26173e-06
I0701 14:48:38.321504 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:48:38.321511 30423 sgd_solver.cpp:106] Iteration 55500, lr = 0.0132813
I0701 14:48:40.373049 30423 solver.cpp:290] Iteration 55600 (48.7452 iter/s, 2.05148s/100 iter), loss = -4.26173e-06
I0701 14:48:40.373070 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:48:40.373077 30423 sgd_solver.cpp:106] Iteration 55600, lr = 0.013125
I0701 14:48:42.433462 30423 solver.cpp:290] Iteration 55700 (48.5359 iter/s, 2.06033s/100 iter), loss = -4.26173e-06
I0701 14:48:42.433485 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:48:42.433495 30423 sgd_solver.cpp:106] Iteration 55700, lr = 0.0129687
I0701 14:48:44.489919 30423 solver.cpp:290] Iteration 55800 (48.6294 iter/s, 2.05637s/100 iter), loss = -4.26173e-06
I0701 14:48:44.489945 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:48:44.489955 30423 sgd_solver.cpp:106] Iteration 55800, lr = 0.0128125
I0701 14:48:46.545967 30423 solver.cpp:290] Iteration 55900 (48.639 iter/s, 2.05596s/100 iter), loss = -4.26173e-06
I0701 14:48:46.545991 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:48:46.546000 30423 sgd_solver.cpp:106] Iteration 55900, lr = 0.0126562
I0701 14:48:48.595263 30423 solver.cpp:473] Iteration 56000, Testing net (#0)
I0701 14:48:50.234907 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9177
I0701 14:48:50.234926 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9973
I0701 14:48:50.234932 30423 solver.cpp:546]     Test net output #2: loss = 0.2081 (* 1 = 0.2081 loss)
I0701 14:48:50.254766 30423 solver.cpp:290] Iteration 56000 (26.9638 iter/s, 3.70867s/100 iter), loss = -4.26173e-06
I0701 14:48:50.254782 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:48:50.254798 30423 sgd_solver.cpp:106] Iteration 56000, lr = 0.0125
I0701 14:48:52.309376 30423 solver.cpp:290] Iteration 56100 (48.6729 iter/s, 2.05453s/100 iter), loss = -4.26173e-06
I0701 14:48:52.309399 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:48:52.309406 30423 sgd_solver.cpp:106] Iteration 56100, lr = 0.0123438
I0701 14:48:54.366264 30423 solver.cpp:290] Iteration 56200 (48.6191 iter/s, 2.0568s/100 iter), loss = -4.26173e-06
I0701 14:48:54.366287 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:48:54.366294 30423 sgd_solver.cpp:106] Iteration 56200, lr = 0.0121875
I0701 14:48:56.421066 30423 solver.cpp:290] Iteration 56300 (48.6685 iter/s, 2.05472s/100 iter), loss = -4.26173e-06
I0701 14:48:56.421139 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:48:56.421146 30423 sgd_solver.cpp:106] Iteration 56300, lr = 0.0120313
I0701 14:48:58.483636 30423 solver.cpp:290] Iteration 56400 (48.4863 iter/s, 2.06244s/100 iter), loss = -4.26173e-06
I0701 14:48:58.483661 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:48:58.483670 30423 sgd_solver.cpp:106] Iteration 56400, lr = 0.011875
I0701 14:49:00.539964 30423 solver.cpp:290] Iteration 56500 (48.6324 iter/s, 2.05624s/100 iter), loss = -4.26173e-06
I0701 14:49:00.539988 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:49:00.539994 30423 sgd_solver.cpp:106] Iteration 56500, lr = 0.0117188
I0701 14:49:02.595218 30423 solver.cpp:290] Iteration 56600 (48.6578 iter/s, 2.05517s/100 iter), loss = -4.26173e-06
I0701 14:49:02.595242 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:49:02.595248 30423 sgd_solver.cpp:106] Iteration 56600, lr = 0.0115625
I0701 14:49:04.650946 30423 solver.cpp:290] Iteration 56700 (48.6466 iter/s, 2.05564s/100 iter), loss = -4.26173e-06
I0701 14:49:04.650974 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:49:04.650984 30423 sgd_solver.cpp:106] Iteration 56700, lr = 0.0114062
I0701 14:49:06.705314 30423 solver.cpp:290] Iteration 56800 (48.6789 iter/s, 2.05428s/100 iter), loss = -4.26173e-06
I0701 14:49:06.705339 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:49:06.705348 30423 sgd_solver.cpp:106] Iteration 56800, lr = 0.01125
I0701 14:49:08.761497 30423 solver.cpp:290] Iteration 56900 (48.6358 iter/s, 2.0561s/100 iter), loss = -4.26173e-06
I0701 14:49:08.761520 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:49:08.761526 30423 sgd_solver.cpp:106] Iteration 56900, lr = 0.0110937
I0701 14:49:10.797863 30423 solver.cpp:473] Iteration 57000, Testing net (#0)
I0701 14:49:12.435979 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9174
I0701 14:49:12.435997 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9972
I0701 14:49:12.436004 30423 solver.cpp:546]     Test net output #2: loss = 0.2106 (* 1 = 0.2106 loss)
I0701 14:49:12.455651 30423 solver.cpp:290] Iteration 57000 (27.0707 iter/s, 3.69403s/100 iter), loss = -4.26173e-06
I0701 14:49:12.455667 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:49:12.455684 30423 sgd_solver.cpp:106] Iteration 57000, lr = 0.0109375
I0701 14:49:14.509384 30423 solver.cpp:290] Iteration 57100 (48.6937 iter/s, 2.05366s/100 iter), loss = -4.26173e-06
I0701 14:49:14.509407 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:49:14.509413 30423 sgd_solver.cpp:106] Iteration 57100, lr = 0.0107813
I0701 14:49:16.567178 30423 solver.cpp:290] Iteration 57200 (48.5977 iter/s, 2.05771s/100 iter), loss = -4.26173e-06
I0701 14:49:16.567199 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:49:16.567206 30423 sgd_solver.cpp:106] Iteration 57200, lr = 0.010625
I0701 14:49:18.622288 30423 solver.cpp:290] Iteration 57300 (48.6611 iter/s, 2.05503s/100 iter), loss = -4.26173e-06
I0701 14:49:18.622310 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:49:18.622318 30423 sgd_solver.cpp:106] Iteration 57300, lr = 0.0104688
I0701 14:49:20.680582 30423 solver.cpp:290] Iteration 57400 (48.5859 iter/s, 2.05821s/100 iter), loss = -4.26173e-06
I0701 14:49:20.680604 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:49:20.680611 30423 sgd_solver.cpp:106] Iteration 57400, lr = 0.0103125
I0701 14:49:22.735378 30423 solver.cpp:290] Iteration 57500 (48.6686 iter/s, 2.05471s/100 iter), loss = -4.26173e-06
I0701 14:49:22.735400 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:49:22.735406 30423 sgd_solver.cpp:106] Iteration 57500, lr = 0.0101563
I0701 14:49:24.789397 30423 solver.cpp:290] Iteration 57600 (48.687 iter/s, 2.05394s/100 iter), loss = -4.26173e-06
I0701 14:49:24.789435 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:49:24.789444 30423 sgd_solver.cpp:106] Iteration 57600, lr = 0.01
I0701 14:49:26.843792 30423 solver.cpp:290] Iteration 57700 (48.6784 iter/s, 2.0543s/100 iter), loss = -4.26173e-06
I0701 14:49:26.843854 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:49:26.843861 30423 sgd_solver.cpp:106] Iteration 57700, lr = 0.00984375
I0701 14:49:28.896481 30423 solver.cpp:290] Iteration 57800 (48.7195 iter/s, 2.05257s/100 iter), loss = -4.26173e-06
I0701 14:49:28.896503 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:49:28.896509 30423 sgd_solver.cpp:106] Iteration 57800, lr = 0.0096875
I0701 14:49:30.950522 30423 solver.cpp:290] Iteration 57900 (48.6865 iter/s, 2.05396s/100 iter), loss = -4.26173e-06
I0701 14:49:30.950548 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:49:30.950558 30423 sgd_solver.cpp:106] Iteration 57900, lr = 0.00953125
I0701 14:49:32.982569 30423 solver.cpp:473] Iteration 58000, Testing net (#0)
I0701 14:49:34.621414 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9183
I0701 14:49:34.621433 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9974
I0701 14:49:34.621438 30423 solver.cpp:546]     Test net output #2: loss = 0.2112 (* 1 = 0.2112 loss)
I0701 14:49:34.641852 30423 solver.cpp:290] Iteration 58000 (27.0915 iter/s, 3.6912s/100 iter), loss = -4.26173e-06
I0701 14:49:34.641868 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:49:34.641880 30423 sgd_solver.cpp:106] Iteration 58000, lr = 0.009375
I0701 14:49:36.699327 30423 solver.cpp:290] Iteration 58100 (48.6051 iter/s, 2.0574s/100 iter), loss = -4.26173e-06
I0701 14:49:36.699350 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:49:36.699357 30423 sgd_solver.cpp:106] Iteration 58100, lr = 0.00921875
I0701 14:49:38.755179 30423 solver.cpp:290] Iteration 58200 (48.6436 iter/s, 2.05577s/100 iter), loss = -4.26173e-06
I0701 14:49:38.755200 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:49:38.755208 30423 sgd_solver.cpp:106] Iteration 58200, lr = 0.0090625
I0701 14:49:40.807667 30423 solver.cpp:290] Iteration 58300 (48.7233 iter/s, 2.05241s/100 iter), loss = -4.26173e-06
I0701 14:49:40.807690 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:49:40.807696 30423 sgd_solver.cpp:106] Iteration 58300, lr = 0.00890625
I0701 14:49:42.863301 30423 solver.cpp:290] Iteration 58400 (48.6488 iter/s, 2.05555s/100 iter), loss = -4.26173e-06
I0701 14:49:42.863325 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:49:42.863334 30423 sgd_solver.cpp:106] Iteration 58400, lr = 0.00875
I0701 14:49:44.917594 30423 solver.cpp:290] Iteration 58500 (48.6805 iter/s, 2.05421s/100 iter), loss = -4.26173e-06
I0701 14:49:44.917616 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:49:44.917623 30423 sgd_solver.cpp:106] Iteration 58500, lr = 0.00859375
I0701 14:49:46.974330 30423 solver.cpp:290] Iteration 58600 (48.6228 iter/s, 2.05665s/100 iter), loss = -4.26173e-06
I0701 14:49:46.974354 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:49:46.974360 30423 sgd_solver.cpp:106] Iteration 58600, lr = 0.0084375
I0701 14:49:49.030752 30423 solver.cpp:290] Iteration 58700 (48.6302 iter/s, 2.05634s/100 iter), loss = -4.26173e-06
I0701 14:49:49.030781 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:49:49.030791 30423 sgd_solver.cpp:106] Iteration 58700, lr = 0.00828125
I0701 14:49:51.084745 30423 solver.cpp:290] Iteration 58800 (48.6878 iter/s, 2.0539s/100 iter), loss = -4.26173e-06
I0701 14:49:51.084781 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:49:51.084794 30423 sgd_solver.cpp:106] Iteration 58800, lr = 0.008125
I0701 14:49:53.138962 30423 solver.cpp:290] Iteration 58900 (48.6825 iter/s, 2.05412s/100 iter), loss = -4.26173e-06
I0701 14:49:53.138986 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:49:53.138995 30423 sgd_solver.cpp:106] Iteration 58900, lr = 0.00796875
I0701 14:49:55.173183 30423 solver.cpp:473] Iteration 59000, Testing net (#0)
I0701 14:49:56.812834 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.919
I0701 14:49:56.812887 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9973
I0701 14:49:56.812894 30423 solver.cpp:546]     Test net output #2: loss = 0.2075 (* 1 = 0.2075 loss)
I0701 14:49:56.832566 30423 solver.cpp:290] Iteration 59000 (27.0748 iter/s, 3.69347s/100 iter), loss = -4.26173e-06
I0701 14:49:56.832590 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:49:56.832597 30423 sgd_solver.cpp:106] Iteration 59000, lr = 0.0078125
I0701 14:49:58.894186 30423 solver.cpp:290] Iteration 59100 (48.5075 iter/s, 2.06154s/100 iter), loss = -4.26173e-06
I0701 14:49:58.894261 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:49:58.894273 30423 sgd_solver.cpp:106] Iteration 59100, lr = 0.00765625
I0701 14:50:00.947607 30423 solver.cpp:290] Iteration 59200 (48.7024 iter/s, 2.05329s/100 iter), loss = -4.26173e-06
I0701 14:50:00.947628 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:00.947636 30423 sgd_solver.cpp:106] Iteration 59200, lr = 0.0075
I0701 14:50:03.004483 30423 solver.cpp:290] Iteration 59300 (48.6194 iter/s, 2.05679s/100 iter), loss = -4.26173e-06
I0701 14:50:03.004508 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:03.004516 30423 sgd_solver.cpp:106] Iteration 59300, lr = 0.00734375
I0701 14:50:05.058184 30423 solver.cpp:290] Iteration 59400 (48.6946 iter/s, 2.05362s/100 iter), loss = -4.26173e-06
I0701 14:50:05.058207 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:05.058217 30423 sgd_solver.cpp:106] Iteration 59400, lr = 0.0071875
I0701 14:50:07.112264 30423 solver.cpp:290] Iteration 59500 (48.6856 iter/s, 2.054s/100 iter), loss = -4.26173e-06
I0701 14:50:07.112285 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:07.112293 30423 sgd_solver.cpp:106] Iteration 59500, lr = 0.00703125
I0701 14:50:09.169973 30423 solver.cpp:290] Iteration 59600 (48.5997 iter/s, 2.05763s/100 iter), loss = -4.26173e-06
I0701 14:50:09.169996 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:09.170002 30423 sgd_solver.cpp:106] Iteration 59600, lr = 0.006875
I0701 14:50:11.224829 30423 solver.cpp:290] Iteration 59700 (48.6672 iter/s, 2.05477s/100 iter), loss = -4.26173e-06
I0701 14:50:11.224851 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:11.224858 30423 sgd_solver.cpp:106] Iteration 59700, lr = 0.00671875
I0701 14:50:13.282259 30423 solver.cpp:290] Iteration 59800 (48.6063 iter/s, 2.05735s/100 iter), loss = -4.26173e-06
I0701 14:50:13.282281 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:13.282289 30423 sgd_solver.cpp:106] Iteration 59800, lr = 0.0065625
I0701 14:50:15.339205 30423 solver.cpp:290] Iteration 59900 (48.6178 iter/s, 2.05686s/100 iter), loss = -4.26173e-06
I0701 14:50:15.339227 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:15.339233 30423 sgd_solver.cpp:106] Iteration 59900, lr = 0.00640625
I0701 14:50:17.374524 30423 solver.cpp:600] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/initial/cifar10_jacintonet11v2_iter_60000.caffemodel
I0701 14:50:17.390700 30423 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/initial/cifar10_jacintonet11v2_iter_60000.solverstate
I0701 14:50:17.397929 30423 solver.cpp:473] Iteration 60000, Testing net (#0)
I0701 14:50:19.036723 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9179
I0701 14:50:19.036741 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9974
I0701 14:50:19.036747 30423 solver.cpp:546]     Test net output #2: loss = 0.2045 (* 1 = 0.2045 loss)
I0701 14:50:19.058130 30423 solver.cpp:290] Iteration 60000 (26.8904 iter/s, 3.7188s/100 iter), loss = -4.26173e-06
I0701 14:50:19.058146 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:19.058158 30423 sgd_solver.cpp:106] Iteration 60000, lr = 0.00625
I0701 14:50:21.112483 30423 solver.cpp:290] Iteration 60100 (48.679 iter/s, 2.05427s/100 iter), loss = -4.26173e-06
I0701 14:50:21.112506 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:21.112512 30423 sgd_solver.cpp:106] Iteration 60100, lr = 0.00609375
I0701 14:50:23.166234 30423 solver.cpp:290] Iteration 60200 (48.6935 iter/s, 2.05366s/100 iter), loss = -4.26173e-06
I0701 14:50:23.166260 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:23.166270 30423 sgd_solver.cpp:106] Iteration 60200, lr = 0.0059375
I0701 14:50:25.226441 30423 solver.cpp:290] Iteration 60300 (48.5409 iter/s, 2.06012s/100 iter), loss = -4.26173e-06
I0701 14:50:25.226505 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:25.226528 30423 sgd_solver.cpp:106] Iteration 60300, lr = 0.00578125
I0701 14:50:27.283226 30423 solver.cpp:290] Iteration 60400 (48.6225 iter/s, 2.05666s/100 iter), loss = -4.26173e-06
I0701 14:50:27.283248 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:27.283255 30423 sgd_solver.cpp:106] Iteration 60400, lr = 0.005625
I0701 14:50:29.339063 30423 solver.cpp:290] Iteration 60500 (48.644 iter/s, 2.05575s/100 iter), loss = -4.26173e-06
I0701 14:50:29.339130 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:29.339138 30423 sgd_solver.cpp:106] Iteration 60500, lr = 0.00546875
I0701 14:50:31.390529 30423 solver.cpp:290] Iteration 60600 (48.7486 iter/s, 2.05134s/100 iter), loss = -4.26173e-06
I0701 14:50:31.390552 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:31.390558 30423 sgd_solver.cpp:106] Iteration 60600, lr = 0.0053125
I0701 14:50:33.447552 30423 solver.cpp:290] Iteration 60700 (48.6159 iter/s, 2.05694s/100 iter), loss = -4.26173e-06
I0701 14:50:33.447576 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:33.447582 30423 sgd_solver.cpp:106] Iteration 60700, lr = 0.00515625
I0701 14:50:35.499903 30423 solver.cpp:290] Iteration 60800 (48.7266 iter/s, 2.05227s/100 iter), loss = -4.26173e-06
I0701 14:50:35.499925 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:35.499932 30423 sgd_solver.cpp:106] Iteration 60800, lr = 0.005
I0701 14:50:37.554067 30423 solver.cpp:290] Iteration 60900 (48.6836 iter/s, 2.05408s/100 iter), loss = -4.26173e-06
I0701 14:50:37.554090 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:37.554096 30423 sgd_solver.cpp:106] Iteration 60900, lr = 0.00484375
I0701 14:50:39.588832 30423 solver.cpp:473] Iteration 61000, Testing net (#0)
I0701 14:50:41.241992 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9179
I0701 14:50:41.242012 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9974
I0701 14:50:41.242018 30423 solver.cpp:546]     Test net output #2: loss = 0.2079 (* 1 = 0.2079 loss)
I0701 14:50:41.261863 30423 solver.cpp:290] Iteration 61000 (26.9711 iter/s, 3.70767s/100 iter), loss = -4.26173e-06
I0701 14:50:41.261883 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:41.261894 30423 sgd_solver.cpp:106] Iteration 61000, lr = 0.0046875
I0701 14:50:43.319118 30423 solver.cpp:290] Iteration 61100 (48.6103 iter/s, 2.05718s/100 iter), loss = -4.26173e-06
I0701 14:50:43.319140 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:43.319147 30423 sgd_solver.cpp:106] Iteration 61100, lr = 0.00453125
I0701 14:50:45.373585 30423 solver.cpp:290] Iteration 61200 (48.6764 iter/s, 2.05438s/100 iter), loss = -4.26173e-06
I0701 14:50:45.373608 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:45.373615 30423 sgd_solver.cpp:106] Iteration 61200, lr = 0.004375
I0701 14:50:47.435035 30423 solver.cpp:290] Iteration 61300 (48.5116 iter/s, 2.06136s/100 iter), loss = -4.26173e-06
I0701 14:50:47.435057 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:47.435063 30423 sgd_solver.cpp:106] Iteration 61300, lr = 0.00421875
I0701 14:50:49.490665 30423 solver.cpp:290] Iteration 61400 (48.6489 iter/s, 2.05555s/100 iter), loss = -4.26173e-06
I0701 14:50:49.490687 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:49.490694 30423 sgd_solver.cpp:106] Iteration 61400, lr = 0.0040625
I0701 14:50:51.547842 30423 solver.cpp:290] Iteration 61500 (48.6123 iter/s, 2.05709s/100 iter), loss = -4.26173e-06
I0701 14:50:51.547864 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:51.547873 30423 sgd_solver.cpp:106] Iteration 61500, lr = 0.00390625
I0701 14:50:53.602774 30423 solver.cpp:290] Iteration 61600 (48.6654 iter/s, 2.05485s/100 iter), loss = -4.26173e-06
I0701 14:50:53.602798 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:53.602805 30423 sgd_solver.cpp:106] Iteration 61600, lr = 0.00375
I0701 14:50:55.655081 30423 solver.cpp:290] Iteration 61700 (48.7277 iter/s, 2.05222s/100 iter), loss = -4.26173e-06
I0701 14:50:55.655102 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:55.655109 30423 sgd_solver.cpp:106] Iteration 61700, lr = 0.00359375
I0701 14:50:57.742857 30423 solver.cpp:290] Iteration 61800 (47.8998 iter/s, 2.08769s/100 iter), loss = -4.26173e-06
I0701 14:50:57.742895 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:57.742903 30423 sgd_solver.cpp:106] Iteration 61800, lr = 0.0034375
I0701 14:50:59.796252 30423 solver.cpp:290] Iteration 61900 (48.7022 iter/s, 2.0533s/100 iter), loss = -4.26173e-06
I0701 14:50:59.796319 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:50:59.796329 30423 sgd_solver.cpp:106] Iteration 61900, lr = 0.00328125
I0701 14:51:01.831493 30423 solver.cpp:473] Iteration 62000, Testing net (#0)
I0701 14:51:03.468343 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9181
I0701 14:51:03.468364 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9972
I0701 14:51:03.468369 30423 solver.cpp:546]     Test net output #2: loss = 0.2061 (* 1 = 0.2061 loss)
I0701 14:51:03.488306 30423 solver.cpp:290] Iteration 62000 (27.0864 iter/s, 3.69189s/100 iter), loss = -4.26173e-06
I0701 14:51:03.488327 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:51:03.488335 30423 sgd_solver.cpp:106] Iteration 62000, lr = 0.003125
I0701 14:51:05.551592 30423 solver.cpp:290] Iteration 62100 (48.4683 iter/s, 2.0632s/100 iter), loss = -4.26173e-06
I0701 14:51:05.551618 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:51:05.551627 30423 sgd_solver.cpp:106] Iteration 62100, lr = 0.00296875
I0701 14:51:07.609794 30423 solver.cpp:290] Iteration 62200 (48.5881 iter/s, 2.05812s/100 iter), loss = -4.26173e-06
I0701 14:51:07.609817 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:51:07.609823 30423 sgd_solver.cpp:106] Iteration 62200, lr = 0.0028125
I0701 14:51:09.671919 30423 solver.cpp:290] Iteration 62300 (48.4957 iter/s, 2.06204s/100 iter), loss = -4.26173e-06
I0701 14:51:09.671946 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:51:09.671953 30423 sgd_solver.cpp:106] Iteration 62300, lr = 0.00265625
I0701 14:51:11.735440 30423 solver.cpp:290] Iteration 62400 (48.463 iter/s, 2.06343s/100 iter), loss = -4.26173e-06
I0701 14:51:11.735466 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:51:11.735473 30423 sgd_solver.cpp:106] Iteration 62400, lr = 0.0025
I0701 14:51:13.794108 30423 solver.cpp:290] Iteration 62500 (48.5771 iter/s, 2.05858s/100 iter), loss = -4.26173e-06
I0701 14:51:13.794137 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:51:13.794144 30423 sgd_solver.cpp:106] Iteration 62500, lr = 0.00234375
I0701 14:51:15.854135 30423 solver.cpp:290] Iteration 62600 (48.5451 iter/s, 2.05994s/100 iter), loss = -4.26173e-06
I0701 14:51:15.854156 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:51:15.854164 30423 sgd_solver.cpp:106] Iteration 62600, lr = 0.0021875
I0701 14:51:17.909670 30423 solver.cpp:290] Iteration 62700 (48.6511 iter/s, 2.05545s/100 iter), loss = -4.26173e-06
I0701 14:51:17.909693 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:51:17.909698 30423 sgd_solver.cpp:106] Iteration 62700, lr = 0.00203125
I0701 14:51:19.963727 30423 solver.cpp:290] Iteration 62800 (48.6861 iter/s, 2.05397s/100 iter), loss = -4.26173e-06
I0701 14:51:19.963749 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:51:19.963755 30423 sgd_solver.cpp:106] Iteration 62800, lr = 0.001875
I0701 14:51:22.015059 30423 solver.cpp:290] Iteration 62900 (48.7508 iter/s, 2.05125s/100 iter), loss = -4.26173e-06
I0701 14:51:22.015081 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:51:22.015089 30423 sgd_solver.cpp:106] Iteration 62900, lr = 0.00171875
I0701 14:51:24.047857 30423 solver.cpp:473] Iteration 63000, Testing net (#0)
I0701 14:51:25.686120 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9179
I0701 14:51:25.686137 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9973
I0701 14:51:25.686143 30423 solver.cpp:546]     Test net output #2: loss = 0.2064 (* 1 = 0.2064 loss)
I0701 14:51:25.705673 30423 solver.cpp:290] Iteration 63000 (27.0967 iter/s, 3.69049s/100 iter), loss = -4.26173e-06
I0701 14:51:25.705690 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:51:25.705703 30423 sgd_solver.cpp:106] Iteration 63000, lr = 0.0015625
I0701 14:51:27.760849 30423 solver.cpp:290] Iteration 63100 (48.6595 iter/s, 2.0551s/100 iter), loss = -4.26173e-06
I0701 14:51:27.760886 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:51:27.760893 30423 sgd_solver.cpp:106] Iteration 63100, lr = 0.00140625
I0701 14:51:29.817390 30423 solver.cpp:290] Iteration 63200 (48.6277 iter/s, 2.05644s/100 iter), loss = -4.26173e-06
I0701 14:51:29.818393 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:51:29.818404 30423 sgd_solver.cpp:106] Iteration 63200, lr = 0.00125
I0701 14:51:31.878907 30423 solver.cpp:290] Iteration 63300 (48.5328 iter/s, 2.06046s/100 iter), loss = -4.26173e-06
I0701 14:51:31.878928 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:51:31.878937 30423 sgd_solver.cpp:106] Iteration 63300, lr = 0.00109375
I0701 14:51:33.932257 30423 solver.cpp:290] Iteration 63400 (48.7028 iter/s, 2.05327s/100 iter), loss = -4.26173e-06
I0701 14:51:33.932281 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:51:33.932287 30423 sgd_solver.cpp:106] Iteration 63400, lr = 0.000937498
I0701 14:51:35.983458 30423 solver.cpp:290] Iteration 63500 (48.7539 iter/s, 2.05112s/100 iter), loss = -4.26173e-06
I0701 14:51:35.983480 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:51:35.983487 30423 sgd_solver.cpp:106] Iteration 63500, lr = 0.00078125
I0701 14:51:38.038377 30423 solver.cpp:290] Iteration 63600 (48.6657 iter/s, 2.05484s/100 iter), loss = -4.26173e-06
I0701 14:51:38.038403 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:51:38.038409 30423 sgd_solver.cpp:106] Iteration 63600, lr = 0.000625002
I0701 14:51:40.097633 30423 solver.cpp:290] Iteration 63700 (48.5633 iter/s, 2.05917s/100 iter), loss = -4.26173e-06
I0701 14:51:40.097654 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:51:40.097662 30423 sgd_solver.cpp:106] Iteration 63700, lr = 0.000468749
I0701 14:51:42.150612 30423 solver.cpp:290] Iteration 63800 (48.7118 iter/s, 2.05289s/100 iter), loss = -4.26173e-06
I0701 14:51:42.150643 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:51:42.150652 30423 sgd_solver.cpp:106] Iteration 63800, lr = 0.000312501
I0701 14:51:44.206321 30423 solver.cpp:290] Iteration 63900 (48.6471 iter/s, 2.05562s/100 iter), loss = -4.26173e-06
I0701 14:51:44.206348 30423 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:51:44.206357 30423 sgd_solver.cpp:106] Iteration 63900, lr = 0.000156248
I0701 14:51:46.240893 30423 solver.cpp:600] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/initial/cifar10_jacintonet11v2_iter_64000.caffemodel
I0701 14:51:46.257076 30423 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/initial/cifar10_jacintonet11v2_iter_64000.solverstate
I0701 14:51:46.269533 30423 solver.cpp:453] Iteration 64000, loss = -4.26173e-06
I0701 14:51:46.269551 30423 solver.cpp:473] Iteration 64000, Testing net (#0)
I0701 14:51:47.909636 30423 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.917
I0701 14:51:47.909654 30423 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9974
I0701 14:51:47.909660 30423 solver.cpp:546]     Test net output #2: loss = 0.2069 (* 1 = 0.2069 loss)
I0701 14:51:47.909662 30423 solver.cpp:458] Optimization Done.
I0701 14:51:47.956264 30423 caffe.cpp:246] Optimization Done.
training/cifar10_jacintonet11v2_2017-07-01_14-28-09/sparse
I0701 14:51:50.347087  1052 caffe.cpp:209] Using GPUs 0, 1, 2
I0701 14:51:50.347551  1052 caffe.cpp:214] GPU 0: GeForce GTX 1080
I0701 14:51:50.347882  1052 caffe.cpp:214] GPU 1: GeForce GTX 1080
I0701 14:51:50.348208  1052 caffe.cpp:214] GPU 2: GeForce GTX 1080
I0701 14:51:50.731715  1052 solver.cpp:48] Initializing solver from parameters: 
train_net: "training/cifar10_jacintonet11v2_2017-07-01_14-28-09/sparse/train.prototxt"
test_net: "training/cifar10_jacintonet11v2_2017-07-01_14-28-09/sparse/test.prototxt"
test_iter: 200
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 64000
lr_policy: "poly"
gamma: 0.1
power: 1
momentum: 0.9
weight_decay: 1e-05
snapshot: 10000
snapshot_prefix: "training/cifar10_jacintonet11v2_2017-07-01_14-28-09/sparse/cifar10_jacintonet11v2"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
snapshot_after_train: true
regularization_type: "L1"
test_initialization: true
iter_size: 1
type: "SGD"
display_sparsity: 1000
sparse_mode: SPARSE_UPDATE
sparsity_target: 0.8
sparsity_step_factor: 0.02
sparsity_step_iter: 1000
sparsity_start_iter: 4000
sparsity_start_factor: 0
I0701 14:51:50.731806  1052 solver.cpp:82] Creating training net from train_net file: training/cifar10_jacintonet11v2_2017-07-01_14-28-09/sparse/train.prototxt
I0701 14:51:50.732460  1052 net.cpp:327] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top1
I0701 14:51:50.732466  1052 net.cpp:327] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top5
I0701 14:51:50.732677  1052 net.cpp:56] Initializing net from parameters: 
name: "jacintonet11v2_train"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: true
    crop_size: 32
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/cifar10_train_lmdb"
    batch_size: 21
    backend: LMDB
    threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a/bn"
  top: "conv1a/bn"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a/bn"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b/bn"
  top: "conv1b/bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b/bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2a/bn"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b/bn"
  top: "res2a_branch2b/bn"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b/bn"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2a/bn"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b/bn"
  top: "res3a_branch2b/bn"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b/bn"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2a/bn"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b/bn"
  top: "res4a_branch2b/bn"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b/bn"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2a/bn"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b/bn"
  top: "res5a_branch2b/bn"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b/bn"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc10"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc10"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
I0701 14:51:50.732796  1052 layer_factory.hpp:77] Creating layer data
I0701 14:51:50.732899  1052 net.cpp:98] Creating Layer data
I0701 14:51:50.732908  1052 net.cpp:413] data -> data
I0701 14:51:50.732928  1052 net.cpp:413] data -> label
I0701 14:51:50.733999  1083 db_lmdb.cpp:35] Opened lmdb ./data/cifar10_train_lmdb
I0701 14:51:50.747509  1052 data_layer.cpp:78] ReshapePrefetch 21, 3, 32, 32
I0701 14:51:50.747568  1052 data_layer.cpp:83] output data size: 21,3,32,32
I0701 14:51:50.749172  1052 net.cpp:148] Setting up data
I0701 14:51:50.749184  1052 net.cpp:155] Top shape: 21 3 32 32 (64512)
I0701 14:51:50.749187  1052 net.cpp:155] Top shape: 21 (21)
I0701 14:51:50.749189  1052 net.cpp:163] Memory required for data: 258132
I0701 14:51:50.749197  1052 layer_factory.hpp:77] Creating layer data/bias
I0701 14:51:50.749207  1052 net.cpp:98] Creating Layer data/bias
I0701 14:51:50.749210  1052 net.cpp:439] data/bias <- data
I0701 14:51:50.749217  1052 net.cpp:413] data/bias -> data/bias
I0701 14:51:50.750185  1052 net.cpp:148] Setting up data/bias
I0701 14:51:50.750195  1052 net.cpp:155] Top shape: 21 3 32 32 (64512)
I0701 14:51:50.750198  1052 net.cpp:163] Memory required for data: 516180
I0701 14:51:50.750206  1052 layer_factory.hpp:77] Creating layer conv1a
I0701 14:51:50.750214  1052 net.cpp:98] Creating Layer conv1a
I0701 14:51:50.750217  1052 net.cpp:439] conv1a <- data/bias
I0701 14:51:50.750221  1052 net.cpp:413] conv1a -> conv1a
I0701 14:51:50.750473  1085 blocking_queue.cpp:50] Waiting for data
I0701 14:51:50.751502  1052 net.cpp:148] Setting up conv1a
I0701 14:51:50.751512  1052 net.cpp:155] Top shape: 21 32 32 32 (688128)
I0701 14:51:50.751514  1052 net.cpp:163] Memory required for data: 3268692
I0701 14:51:50.751518  1052 layer_factory.hpp:77] Creating layer conv1a/bn
I0701 14:51:50.751525  1052 net.cpp:98] Creating Layer conv1a/bn
I0701 14:51:50.751528  1052 net.cpp:439] conv1a/bn <- conv1a
I0701 14:51:50.751530  1052 net.cpp:413] conv1a/bn -> conv1a/bn
I0701 14:51:50.752204  1052 net.cpp:148] Setting up conv1a/bn
I0701 14:51:50.752210  1052 net.cpp:155] Top shape: 21 32 32 32 (688128)
I0701 14:51:50.752213  1052 net.cpp:163] Memory required for data: 6021204
I0701 14:51:50.752218  1052 layer_factory.hpp:77] Creating layer conv1a/relu
I0701 14:51:50.752223  1052 net.cpp:98] Creating Layer conv1a/relu
I0701 14:51:50.752225  1052 net.cpp:439] conv1a/relu <- conv1a/bn
I0701 14:51:50.752228  1052 net.cpp:400] conv1a/relu -> conv1a/bn (in-place)
I0701 14:51:50.752236  1052 net.cpp:148] Setting up conv1a/relu
I0701 14:51:50.752239  1052 net.cpp:155] Top shape: 21 32 32 32 (688128)
I0701 14:51:50.752249  1052 net.cpp:163] Memory required for data: 8773716
I0701 14:51:50.752252  1052 layer_factory.hpp:77] Creating layer conv1b
I0701 14:51:50.752256  1052 net.cpp:98] Creating Layer conv1b
I0701 14:51:50.752259  1052 net.cpp:439] conv1b <- conv1a/bn
I0701 14:51:50.752261  1052 net.cpp:413] conv1b -> conv1b
I0701 14:51:50.752581  1052 net.cpp:148] Setting up conv1b
I0701 14:51:50.752586  1052 net.cpp:155] Top shape: 21 32 32 32 (688128)
I0701 14:51:50.752588  1052 net.cpp:163] Memory required for data: 11526228
I0701 14:51:50.752593  1052 layer_factory.hpp:77] Creating layer conv1b/bn
I0701 14:51:50.752596  1052 net.cpp:98] Creating Layer conv1b/bn
I0701 14:51:50.752599  1052 net.cpp:439] conv1b/bn <- conv1b
I0701 14:51:50.752600  1052 net.cpp:413] conv1b/bn -> conv1b/bn
I0701 14:51:50.753248  1052 net.cpp:148] Setting up conv1b/bn
I0701 14:51:50.753253  1052 net.cpp:155] Top shape: 21 32 32 32 (688128)
I0701 14:51:50.753255  1052 net.cpp:163] Memory required for data: 14278740
I0701 14:51:50.753260  1052 layer_factory.hpp:77] Creating layer conv1b/relu
I0701 14:51:50.753263  1052 net.cpp:98] Creating Layer conv1b/relu
I0701 14:51:50.753265  1052 net.cpp:439] conv1b/relu <- conv1b/bn
I0701 14:51:50.753268  1052 net.cpp:400] conv1b/relu -> conv1b/bn (in-place)
I0701 14:51:50.753271  1052 net.cpp:148] Setting up conv1b/relu
I0701 14:51:50.753274  1052 net.cpp:155] Top shape: 21 32 32 32 (688128)
I0701 14:51:50.753276  1052 net.cpp:163] Memory required for data: 17031252
I0701 14:51:50.753278  1052 layer_factory.hpp:77] Creating layer pool1
I0701 14:51:50.753283  1052 net.cpp:98] Creating Layer pool1
I0701 14:51:50.753285  1052 net.cpp:439] pool1 <- conv1b/bn
I0701 14:51:50.753288  1052 net.cpp:413] pool1 -> pool1
I0701 14:51:50.753329  1052 net.cpp:148] Setting up pool1
I0701 14:51:50.753334  1052 net.cpp:155] Top shape: 21 32 32 32 (688128)
I0701 14:51:50.753334  1052 net.cpp:163] Memory required for data: 19783764
I0701 14:51:50.753336  1052 layer_factory.hpp:77] Creating layer res2a_branch2a
I0701 14:51:50.753340  1052 net.cpp:98] Creating Layer res2a_branch2a
I0701 14:51:50.753342  1052 net.cpp:439] res2a_branch2a <- pool1
I0701 14:51:50.753345  1052 net.cpp:413] res2a_branch2a -> res2a_branch2a
I0701 14:51:50.753983  1052 net.cpp:148] Setting up res2a_branch2a
I0701 14:51:50.753988  1052 net.cpp:155] Top shape: 21 64 32 32 (1376256)
I0701 14:51:50.753990  1052 net.cpp:163] Memory required for data: 25288788
I0701 14:51:50.753995  1052 layer_factory.hpp:77] Creating layer res2a_branch2a/bn
I0701 14:51:50.753998  1052 net.cpp:98] Creating Layer res2a_branch2a/bn
I0701 14:51:50.754000  1052 net.cpp:439] res2a_branch2a/bn <- res2a_branch2a
I0701 14:51:50.754004  1052 net.cpp:413] res2a_branch2a/bn -> res2a_branch2a/bn
I0701 14:51:50.754672  1052 net.cpp:148] Setting up res2a_branch2a/bn
I0701 14:51:50.754679  1052 net.cpp:155] Top shape: 21 64 32 32 (1376256)
I0701 14:51:50.754681  1052 net.cpp:163] Memory required for data: 30793812
I0701 14:51:50.754686  1052 layer_factory.hpp:77] Creating layer res2a_branch2a/relu
I0701 14:51:50.754690  1052 net.cpp:98] Creating Layer res2a_branch2a/relu
I0701 14:51:50.754693  1052 net.cpp:439] res2a_branch2a/relu <- res2a_branch2a/bn
I0701 14:51:50.754695  1052 net.cpp:400] res2a_branch2a/relu -> res2a_branch2a/bn (in-place)
I0701 14:51:50.754700  1052 net.cpp:148] Setting up res2a_branch2a/relu
I0701 14:51:50.754703  1052 net.cpp:155] Top shape: 21 64 32 32 (1376256)
I0701 14:51:50.754705  1052 net.cpp:163] Memory required for data: 36298836
I0701 14:51:50.754707  1052 layer_factory.hpp:77] Creating layer res2a_branch2b
I0701 14:51:50.754712  1052 net.cpp:98] Creating Layer res2a_branch2b
I0701 14:51:50.754715  1052 net.cpp:439] res2a_branch2b <- res2a_branch2a/bn
I0701 14:51:50.754721  1052 net.cpp:413] res2a_branch2b -> res2a_branch2b
I0701 14:51:50.756182  1052 net.cpp:148] Setting up res2a_branch2b
I0701 14:51:50.756202  1052 net.cpp:155] Top shape: 21 64 32 32 (1376256)
I0701 14:51:50.756204  1052 net.cpp:163] Memory required for data: 41803860
I0701 14:51:50.756223  1052 layer_factory.hpp:77] Creating layer res2a_branch2b/bn
I0701 14:51:50.756232  1052 net.cpp:98] Creating Layer res2a_branch2b/bn
I0701 14:51:50.756235  1052 net.cpp:439] res2a_branch2b/bn <- res2a_branch2b
I0701 14:51:50.756240  1052 net.cpp:413] res2a_branch2b/bn -> res2a_branch2b/bn
I0701 14:51:50.756942  1052 net.cpp:148] Setting up res2a_branch2b/bn
I0701 14:51:50.756950  1052 net.cpp:155] Top shape: 21 64 32 32 (1376256)
I0701 14:51:50.756953  1052 net.cpp:163] Memory required for data: 47308884
I0701 14:51:50.756958  1052 layer_factory.hpp:77] Creating layer res2a_branch2b/relu
I0701 14:51:50.756961  1052 net.cpp:98] Creating Layer res2a_branch2b/relu
I0701 14:51:50.756963  1052 net.cpp:439] res2a_branch2b/relu <- res2a_branch2b/bn
I0701 14:51:50.756966  1052 net.cpp:400] res2a_branch2b/relu -> res2a_branch2b/bn (in-place)
I0701 14:51:50.756973  1052 net.cpp:148] Setting up res2a_branch2b/relu
I0701 14:51:50.756976  1052 net.cpp:155] Top shape: 21 64 32 32 (1376256)
I0701 14:51:50.756978  1052 net.cpp:163] Memory required for data: 52813908
I0701 14:51:50.756980  1052 layer_factory.hpp:77] Creating layer pool2
I0701 14:51:50.756984  1052 net.cpp:98] Creating Layer pool2
I0701 14:51:50.756986  1052 net.cpp:439] pool2 <- res2a_branch2b/bn
I0701 14:51:50.756989  1052 net.cpp:413] pool2 -> pool2
I0701 14:51:50.757030  1052 net.cpp:148] Setting up pool2
I0701 14:51:50.757035  1052 net.cpp:155] Top shape: 21 64 16 16 (344064)
I0701 14:51:50.757037  1052 net.cpp:163] Memory required for data: 54190164
I0701 14:51:50.757040  1052 layer_factory.hpp:77] Creating layer res3a_branch2a
I0701 14:51:50.757050  1052 net.cpp:98] Creating Layer res3a_branch2a
I0701 14:51:50.757052  1052 net.cpp:439] res3a_branch2a <- pool2
I0701 14:51:50.757055  1052 net.cpp:413] res3a_branch2a -> res3a_branch2a
I0701 14:51:50.759904  1052 net.cpp:148] Setting up res3a_branch2a
I0701 14:51:50.759914  1052 net.cpp:155] Top shape: 21 128 16 16 (688128)
I0701 14:51:50.759917  1052 net.cpp:163] Memory required for data: 56942676
I0701 14:51:50.759922  1052 layer_factory.hpp:77] Creating layer res3a_branch2a/bn
I0701 14:51:50.759927  1052 net.cpp:98] Creating Layer res3a_branch2a/bn
I0701 14:51:50.759929  1052 net.cpp:439] res3a_branch2a/bn <- res3a_branch2a
I0701 14:51:50.759933  1052 net.cpp:413] res3a_branch2a/bn -> res3a_branch2a/bn
I0701 14:51:50.760543  1052 net.cpp:148] Setting up res3a_branch2a/bn
I0701 14:51:50.760550  1052 net.cpp:155] Top shape: 21 128 16 16 (688128)
I0701 14:51:50.760551  1052 net.cpp:163] Memory required for data: 59695188
I0701 14:51:50.760561  1052 layer_factory.hpp:77] Creating layer res3a_branch2a/relu
I0701 14:51:50.760565  1052 net.cpp:98] Creating Layer res3a_branch2a/relu
I0701 14:51:50.760566  1052 net.cpp:439] res3a_branch2a/relu <- res3a_branch2a/bn
I0701 14:51:50.760568  1052 net.cpp:400] res3a_branch2a/relu -> res3a_branch2a/bn (in-place)
I0701 14:51:50.760572  1052 net.cpp:148] Setting up res3a_branch2a/relu
I0701 14:51:50.760574  1052 net.cpp:155] Top shape: 21 128 16 16 (688128)
I0701 14:51:50.760576  1052 net.cpp:163] Memory required for data: 62447700
I0701 14:51:50.760578  1052 layer_factory.hpp:77] Creating layer res3a_branch2b
I0701 14:51:50.760582  1052 net.cpp:98] Creating Layer res3a_branch2b
I0701 14:51:50.760584  1052 net.cpp:439] res3a_branch2b <- res3a_branch2a/bn
I0701 14:51:50.760587  1052 net.cpp:413] res3a_branch2b -> res3a_branch2b
I0701 14:51:50.761595  1052 net.cpp:148] Setting up res3a_branch2b
I0701 14:51:50.761600  1052 net.cpp:155] Top shape: 21 128 16 16 (688128)
I0701 14:51:50.761602  1052 net.cpp:163] Memory required for data: 65200212
I0701 14:51:50.761605  1052 layer_factory.hpp:77] Creating layer res3a_branch2b/bn
I0701 14:51:50.761610  1052 net.cpp:98] Creating Layer res3a_branch2b/bn
I0701 14:51:50.761612  1052 net.cpp:439] res3a_branch2b/bn <- res3a_branch2b
I0701 14:51:50.761615  1052 net.cpp:413] res3a_branch2b/bn -> res3a_branch2b/bn
I0701 14:51:50.762214  1052 net.cpp:148] Setting up res3a_branch2b/bn
I0701 14:51:50.762220  1052 net.cpp:155] Top shape: 21 128 16 16 (688128)
I0701 14:51:50.762229  1052 net.cpp:163] Memory required for data: 67952724
I0701 14:51:50.762234  1052 layer_factory.hpp:77] Creating layer res3a_branch2b/relu
I0701 14:51:50.762238  1052 net.cpp:98] Creating Layer res3a_branch2b/relu
I0701 14:51:50.762239  1052 net.cpp:439] res3a_branch2b/relu <- res3a_branch2b/bn
I0701 14:51:50.762241  1052 net.cpp:400] res3a_branch2b/relu -> res3a_branch2b/bn (in-place)
I0701 14:51:50.762245  1052 net.cpp:148] Setting up res3a_branch2b/relu
I0701 14:51:50.762248  1052 net.cpp:155] Top shape: 21 128 16 16 (688128)
I0701 14:51:50.762249  1052 net.cpp:163] Memory required for data: 70705236
I0701 14:51:50.762251  1052 layer_factory.hpp:77] Creating layer pool3
I0701 14:51:50.762254  1052 net.cpp:98] Creating Layer pool3
I0701 14:51:50.762257  1052 net.cpp:439] pool3 <- res3a_branch2b/bn
I0701 14:51:50.762260  1052 net.cpp:413] pool3 -> pool3
I0701 14:51:50.762298  1052 net.cpp:148] Setting up pool3
I0701 14:51:50.762303  1052 net.cpp:155] Top shape: 21 128 16 16 (688128)
I0701 14:51:50.762305  1052 net.cpp:163] Memory required for data: 73457748
I0701 14:51:50.762310  1052 layer_factory.hpp:77] Creating layer res4a_branch2a
I0701 14:51:50.762315  1052 net.cpp:98] Creating Layer res4a_branch2a
I0701 14:51:50.762320  1052 net.cpp:439] res4a_branch2a <- pool3
I0701 14:51:50.762323  1052 net.cpp:413] res4a_branch2a -> res4a_branch2a
I0701 14:51:50.768401  1052 net.cpp:148] Setting up res4a_branch2a
I0701 14:51:50.768409  1052 net.cpp:155] Top shape: 21 256 16 16 (1376256)
I0701 14:51:50.768410  1052 net.cpp:163] Memory required for data: 78962772
I0701 14:51:50.768414  1052 layer_factory.hpp:77] Creating layer res4a_branch2a/bn
I0701 14:51:50.768417  1052 net.cpp:98] Creating Layer res4a_branch2a/bn
I0701 14:51:50.768419  1052 net.cpp:439] res4a_branch2a/bn <- res4a_branch2a
I0701 14:51:50.768422  1052 net.cpp:413] res4a_branch2a/bn -> res4a_branch2a/bn
I0701 14:51:50.769026  1052 net.cpp:148] Setting up res4a_branch2a/bn
I0701 14:51:50.769032  1052 net.cpp:155] Top shape: 21 256 16 16 (1376256)
I0701 14:51:50.769033  1052 net.cpp:163] Memory required for data: 84467796
I0701 14:51:50.769037  1052 layer_factory.hpp:77] Creating layer res4a_branch2a/relu
I0701 14:51:50.769040  1052 net.cpp:98] Creating Layer res4a_branch2a/relu
I0701 14:51:50.769043  1052 net.cpp:439] res4a_branch2a/relu <- res4a_branch2a/bn
I0701 14:51:50.769045  1052 net.cpp:400] res4a_branch2a/relu -> res4a_branch2a/bn (in-place)
I0701 14:51:50.769048  1052 net.cpp:148] Setting up res4a_branch2a/relu
I0701 14:51:50.769050  1052 net.cpp:155] Top shape: 21 256 16 16 (1376256)
I0701 14:51:50.769052  1052 net.cpp:163] Memory required for data: 89972820
I0701 14:51:50.769054  1052 layer_factory.hpp:77] Creating layer res4a_branch2b
I0701 14:51:50.769057  1052 net.cpp:98] Creating Layer res4a_branch2b
I0701 14:51:50.769059  1052 net.cpp:439] res4a_branch2b <- res4a_branch2a/bn
I0701 14:51:50.769062  1052 net.cpp:413] res4a_branch2b -> res4a_branch2b
I0701 14:51:50.772238  1052 net.cpp:148] Setting up res4a_branch2b
I0701 14:51:50.772244  1052 net.cpp:155] Top shape: 21 256 16 16 (1376256)
I0701 14:51:50.772246  1052 net.cpp:163] Memory required for data: 95477844
I0701 14:51:50.772249  1052 layer_factory.hpp:77] Creating layer res4a_branch2b/bn
I0701 14:51:50.772253  1052 net.cpp:98] Creating Layer res4a_branch2b/bn
I0701 14:51:50.772256  1052 net.cpp:439] res4a_branch2b/bn <- res4a_branch2b
I0701 14:51:50.772260  1052 net.cpp:413] res4a_branch2b/bn -> res4a_branch2b/bn
I0701 14:51:50.772850  1052 net.cpp:148] Setting up res4a_branch2b/bn
I0701 14:51:50.772855  1052 net.cpp:155] Top shape: 21 256 16 16 (1376256)
I0701 14:51:50.772857  1052 net.cpp:163] Memory required for data: 100982868
I0701 14:51:50.772861  1052 layer_factory.hpp:77] Creating layer res4a_branch2b/relu
I0701 14:51:50.772864  1052 net.cpp:98] Creating Layer res4a_branch2b/relu
I0701 14:51:50.772866  1052 net.cpp:439] res4a_branch2b/relu <- res4a_branch2b/bn
I0701 14:51:50.772868  1052 net.cpp:400] res4a_branch2b/relu -> res4a_branch2b/bn (in-place)
I0701 14:51:50.772879  1052 net.cpp:148] Setting up res4a_branch2b/relu
I0701 14:51:50.772882  1052 net.cpp:155] Top shape: 21 256 16 16 (1376256)
I0701 14:51:50.772883  1052 net.cpp:163] Memory required for data: 106487892
I0701 14:51:50.772886  1052 layer_factory.hpp:77] Creating layer pool4
I0701 14:51:50.772888  1052 net.cpp:98] Creating Layer pool4
I0701 14:51:50.772891  1052 net.cpp:439] pool4 <- res4a_branch2b/bn
I0701 14:51:50.772894  1052 net.cpp:413] pool4 -> pool4
I0701 14:51:50.772928  1052 net.cpp:148] Setting up pool4
I0701 14:51:50.772933  1052 net.cpp:155] Top shape: 21 256 8 8 (344064)
I0701 14:51:50.772934  1052 net.cpp:163] Memory required for data: 107864148
I0701 14:51:50.772936  1052 layer_factory.hpp:77] Creating layer res5a_branch2a
I0701 14:51:50.772939  1052 net.cpp:98] Creating Layer res5a_branch2a
I0701 14:51:50.772943  1052 net.cpp:439] res5a_branch2a <- pool4
I0701 14:51:50.772944  1052 net.cpp:413] res5a_branch2a -> res5a_branch2a
I0701 14:51:50.801746  1052 net.cpp:148] Setting up res5a_branch2a
I0701 14:51:50.801767  1052 net.cpp:155] Top shape: 21 512 8 8 (688128)
I0701 14:51:50.801770  1052 net.cpp:163] Memory required for data: 110616660
I0701 14:51:50.801776  1052 layer_factory.hpp:77] Creating layer res5a_branch2a/bn
I0701 14:51:50.801784  1052 net.cpp:98] Creating Layer res5a_branch2a/bn
I0701 14:51:50.801786  1052 net.cpp:439] res5a_branch2a/bn <- res5a_branch2a
I0701 14:51:50.801790  1052 net.cpp:413] res5a_branch2a/bn -> res5a_branch2a/bn
I0701 14:51:50.802461  1052 net.cpp:148] Setting up res5a_branch2a/bn
I0701 14:51:50.802467  1052 net.cpp:155] Top shape: 21 512 8 8 (688128)
I0701 14:51:50.802469  1052 net.cpp:163] Memory required for data: 113369172
I0701 14:51:50.802474  1052 layer_factory.hpp:77] Creating layer res5a_branch2a/relu
I0701 14:51:50.802479  1052 net.cpp:98] Creating Layer res5a_branch2a/relu
I0701 14:51:50.802481  1052 net.cpp:439] res5a_branch2a/relu <- res5a_branch2a/bn
I0701 14:51:50.802484  1052 net.cpp:400] res5a_branch2a/relu -> res5a_branch2a/bn (in-place)
I0701 14:51:50.802489  1052 net.cpp:148] Setting up res5a_branch2a/relu
I0701 14:51:50.802490  1052 net.cpp:155] Top shape: 21 512 8 8 (688128)
I0701 14:51:50.802492  1052 net.cpp:163] Memory required for data: 116121684
I0701 14:51:50.802495  1052 layer_factory.hpp:77] Creating layer res5a_branch2b
I0701 14:51:50.802502  1052 net.cpp:98] Creating Layer res5a_branch2b
I0701 14:51:50.802505  1052 net.cpp:439] res5a_branch2b <- res5a_branch2a/bn
I0701 14:51:50.802508  1052 net.cpp:413] res5a_branch2b -> res5a_branch2b
I0701 14:51:50.815462  1052 net.cpp:148] Setting up res5a_branch2b
I0701 14:51:50.815482  1052 net.cpp:155] Top shape: 21 512 8 8 (688128)
I0701 14:51:50.815485  1052 net.cpp:163] Memory required for data: 118874196
I0701 14:51:50.815495  1052 layer_factory.hpp:77] Creating layer res5a_branch2b/bn
I0701 14:51:50.815501  1052 net.cpp:98] Creating Layer res5a_branch2b/bn
I0701 14:51:50.815505  1052 net.cpp:439] res5a_branch2b/bn <- res5a_branch2b
I0701 14:51:50.815508  1052 net.cpp:413] res5a_branch2b/bn -> res5a_branch2b/bn
I0701 14:51:50.816200  1052 net.cpp:148] Setting up res5a_branch2b/bn
I0701 14:51:50.816207  1052 net.cpp:155] Top shape: 21 512 8 8 (688128)
I0701 14:51:50.816210  1052 net.cpp:163] Memory required for data: 121626708
I0701 14:51:50.816215  1052 layer_factory.hpp:77] Creating layer res5a_branch2b/relu
I0701 14:51:50.816218  1052 net.cpp:98] Creating Layer res5a_branch2b/relu
I0701 14:51:50.816220  1052 net.cpp:439] res5a_branch2b/relu <- res5a_branch2b/bn
I0701 14:51:50.816222  1052 net.cpp:400] res5a_branch2b/relu -> res5a_branch2b/bn (in-place)
I0701 14:51:50.816227  1052 net.cpp:148] Setting up res5a_branch2b/relu
I0701 14:51:50.816229  1052 net.cpp:155] Top shape: 21 512 8 8 (688128)
I0701 14:51:50.816231  1052 net.cpp:163] Memory required for data: 124379220
I0701 14:51:50.816232  1052 layer_factory.hpp:77] Creating layer pool5
I0701 14:51:50.816238  1052 net.cpp:98] Creating Layer pool5
I0701 14:51:50.816239  1052 net.cpp:439] pool5 <- res5a_branch2b/bn
I0701 14:51:50.816252  1052 net.cpp:413] pool5 -> pool5
I0701 14:51:50.816283  1052 net.cpp:148] Setting up pool5
I0701 14:51:50.816287  1052 net.cpp:155] Top shape: 21 512 1 1 (10752)
I0701 14:51:50.816289  1052 net.cpp:163] Memory required for data: 124422228
I0701 14:51:50.816292  1052 layer_factory.hpp:77] Creating layer fc10
I0701 14:51:50.816295  1052 net.cpp:98] Creating Layer fc10
I0701 14:51:50.816298  1052 net.cpp:439] fc10 <- pool5
I0701 14:51:50.816300  1052 net.cpp:413] fc10 -> fc10
I0701 14:51:50.816535  1052 net.cpp:148] Setting up fc10
I0701 14:51:50.816540  1052 net.cpp:155] Top shape: 21 10 (210)
I0701 14:51:50.816542  1052 net.cpp:163] Memory required for data: 124423068
I0701 14:51:50.816545  1052 layer_factory.hpp:77] Creating layer loss
I0701 14:51:50.816550  1052 net.cpp:98] Creating Layer loss
I0701 14:51:50.816551  1052 net.cpp:439] loss <- fc10
I0701 14:51:50.816553  1052 net.cpp:439] loss <- label
I0701 14:51:50.816557  1052 net.cpp:413] loss -> loss
I0701 14:51:50.816565  1052 layer_factory.hpp:77] Creating layer loss
I0701 14:51:50.816684  1052 net.cpp:148] Setting up loss
I0701 14:51:50.816689  1052 net.cpp:155] Top shape: (1)
I0701 14:51:50.816694  1052 net.cpp:158]     with loss weight 1
I0701 14:51:50.816702  1052 net.cpp:163] Memory required for data: 124423072
I0701 14:51:50.816705  1052 net.cpp:224] loss needs backward computation.
I0701 14:51:50.816707  1052 net.cpp:224] fc10 needs backward computation.
I0701 14:51:50.816710  1052 net.cpp:224] pool5 needs backward computation.
I0701 14:51:50.816712  1052 net.cpp:224] res5a_branch2b/relu needs backward computation.
I0701 14:51:50.816715  1052 net.cpp:224] res5a_branch2b/bn needs backward computation.
I0701 14:51:50.816716  1052 net.cpp:224] res5a_branch2b needs backward computation.
I0701 14:51:50.816718  1052 net.cpp:224] res5a_branch2a/relu needs backward computation.
I0701 14:51:50.816722  1052 net.cpp:224] res5a_branch2a/bn needs backward computation.
I0701 14:51:50.816726  1052 net.cpp:224] res5a_branch2a needs backward computation.
I0701 14:51:50.816728  1052 net.cpp:224] pool4 needs backward computation.
I0701 14:51:50.816730  1052 net.cpp:224] res4a_branch2b/relu needs backward computation.
I0701 14:51:50.816732  1052 net.cpp:224] res4a_branch2b/bn needs backward computation.
I0701 14:51:50.816735  1052 net.cpp:224] res4a_branch2b needs backward computation.
I0701 14:51:50.816736  1052 net.cpp:224] res4a_branch2a/relu needs backward computation.
I0701 14:51:50.816740  1052 net.cpp:224] res4a_branch2a/bn needs backward computation.
I0701 14:51:50.816741  1052 net.cpp:224] res4a_branch2a needs backward computation.
I0701 14:51:50.816743  1052 net.cpp:224] pool3 needs backward computation.
I0701 14:51:50.816746  1052 net.cpp:224] res3a_branch2b/relu needs backward computation.
I0701 14:51:50.816747  1052 net.cpp:224] res3a_branch2b/bn needs backward computation.
I0701 14:51:50.816750  1052 net.cpp:224] res3a_branch2b needs backward computation.
I0701 14:51:50.816752  1052 net.cpp:224] res3a_branch2a/relu needs backward computation.
I0701 14:51:50.816754  1052 net.cpp:224] res3a_branch2a/bn needs backward computation.
I0701 14:51:50.816756  1052 net.cpp:224] res3a_branch2a needs backward computation.
I0701 14:51:50.816758  1052 net.cpp:224] pool2 needs backward computation.
I0701 14:51:50.816761  1052 net.cpp:224] res2a_branch2b/relu needs backward computation.
I0701 14:51:50.816762  1052 net.cpp:224] res2a_branch2b/bn needs backward computation.
I0701 14:51:50.816764  1052 net.cpp:224] res2a_branch2b needs backward computation.
I0701 14:51:50.816766  1052 net.cpp:224] res2a_branch2a/relu needs backward computation.
I0701 14:51:50.816768  1052 net.cpp:224] res2a_branch2a/bn needs backward computation.
I0701 14:51:50.816771  1052 net.cpp:224] res2a_branch2a needs backward computation.
I0701 14:51:50.816772  1052 net.cpp:224] pool1 needs backward computation.
I0701 14:51:50.816774  1052 net.cpp:224] conv1b/relu needs backward computation.
I0701 14:51:50.816776  1052 net.cpp:224] conv1b/bn needs backward computation.
I0701 14:51:50.816784  1052 net.cpp:224] conv1b needs backward computation.
I0701 14:51:50.816787  1052 net.cpp:224] conv1a/relu needs backward computation.
I0701 14:51:50.816788  1052 net.cpp:224] conv1a/bn needs backward computation.
I0701 14:51:50.816792  1052 net.cpp:224] conv1a needs backward computation.
I0701 14:51:50.816793  1052 net.cpp:226] data/bias does not need backward computation.
I0701 14:51:50.816795  1052 net.cpp:226] data does not need backward computation.
I0701 14:51:50.816798  1052 net.cpp:268] This network produces output loss
I0701 14:51:50.816815  1052 net.cpp:288] Network initialization done.
I0701 14:51:50.817245  1052 solver.cpp:182] Creating test net (#0) specified by test_net file: training/cifar10_jacintonet11v2_2017-07-01_14-28-09/sparse/test.prototxt
I0701 14:51:50.817436  1052 net.cpp:56] Initializing net from parameters: 
name: "jacintonet11v2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: false
    crop_size: 32
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/cifar10_test_lmdb"
    batch_size: 50
    backend: LMDB
    threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a/bn"
  top: "conv1a/bn"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a/bn"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b/bn"
  top: "conv1b/bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b/bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2a/bn"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b/bn"
  top: "res2a_branch2b/bn"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b/bn"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2a/bn"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b/bn"
  top: "res3a_branch2b/bn"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b/bn"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2a/bn"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b/bn"
  top: "res4a_branch2b/bn"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b/bn"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2a/bn"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b/bn"
  top: "res5a_branch2b/bn"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b/bn"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc10"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc10"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "fc10"
  bottom: "label"
  top: "accuracy/top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "fc10"
  bottom: "label"
  top: "accuracy/top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0701 14:51:50.817544  1052 layer_factory.hpp:77] Creating layer data
I0701 14:51:50.817617  1052 net.cpp:98] Creating Layer data
I0701 14:51:50.817625  1052 net.cpp:413] data -> data
I0701 14:51:50.817632  1052 net.cpp:413] data -> label
I0701 14:51:50.819277  1095 db_lmdb.cpp:35] Opened lmdb ./data/cifar10_test_lmdb
I0701 14:51:50.819423  1052 data_layer.cpp:78] ReshapePrefetch 50, 3, 32, 32
I0701 14:51:50.819483  1052 data_layer.cpp:83] output data size: 50,3,32,32
I0701 14:51:50.821696  1052 net.cpp:148] Setting up data
I0701 14:51:50.821709  1052 net.cpp:155] Top shape: 50 3 32 32 (153600)
I0701 14:51:50.821712  1052 net.cpp:155] Top shape: 50 (50)
I0701 14:51:50.821714  1052 net.cpp:163] Memory required for data: 614600
I0701 14:51:50.821718  1052 layer_factory.hpp:77] Creating layer label_data_1_split
I0701 14:51:50.821729  1052 net.cpp:98] Creating Layer label_data_1_split
I0701 14:51:50.821733  1052 net.cpp:439] label_data_1_split <- label
I0701 14:51:50.821738  1052 net.cpp:413] label_data_1_split -> label_data_1_split_0
I0701 14:51:50.821754  1052 net.cpp:413] label_data_1_split -> label_data_1_split_1
I0701 14:51:50.821760  1052 net.cpp:413] label_data_1_split -> label_data_1_split_2
I0701 14:51:50.821868  1052 net.cpp:148] Setting up label_data_1_split
I0701 14:51:50.821874  1052 net.cpp:155] Top shape: 50 (50)
I0701 14:51:50.821878  1052 net.cpp:155] Top shape: 50 (50)
I0701 14:51:50.821883  1052 net.cpp:155] Top shape: 50 (50)
I0701 14:51:50.821887  1052 net.cpp:163] Memory required for data: 615200
I0701 14:51:50.821890  1052 layer_factory.hpp:77] Creating layer data/bias
I0701 14:51:50.821897  1052 net.cpp:98] Creating Layer data/bias
I0701 14:51:50.821900  1052 net.cpp:439] data/bias <- data
I0701 14:51:50.821905  1052 net.cpp:413] data/bias -> data/bias
I0701 14:51:50.822015  1052 net.cpp:148] Setting up data/bias
I0701 14:51:50.822019  1052 net.cpp:155] Top shape: 50 3 32 32 (153600)
I0701 14:51:50.822023  1052 net.cpp:163] Memory required for data: 1229600
I0701 14:51:50.822031  1052 layer_factory.hpp:77] Creating layer conv1a
I0701 14:51:50.822037  1052 net.cpp:98] Creating Layer conv1a
I0701 14:51:50.822041  1052 net.cpp:439] conv1a <- data/bias
I0701 14:51:50.822046  1052 net.cpp:413] conv1a -> conv1a
I0701 14:51:50.822420  1052 net.cpp:148] Setting up conv1a
I0701 14:51:50.822428  1052 net.cpp:155] Top shape: 50 32 32 32 (1638400)
I0701 14:51:50.822432  1052 net.cpp:163] Memory required for data: 7783200
I0701 14:51:50.822439  1052 layer_factory.hpp:77] Creating layer conv1a/bn
I0701 14:51:50.822446  1052 net.cpp:98] Creating Layer conv1a/bn
I0701 14:51:50.822449  1052 net.cpp:439] conv1a/bn <- conv1a
I0701 14:51:50.822455  1052 net.cpp:413] conv1a/bn -> conv1a/bn
I0701 14:51:50.823333  1052 net.cpp:148] Setting up conv1a/bn
I0701 14:51:50.823344  1052 net.cpp:155] Top shape: 50 32 32 32 (1638400)
I0701 14:51:50.823348  1052 net.cpp:163] Memory required for data: 14336800
I0701 14:51:50.823370  1052 layer_factory.hpp:77] Creating layer conv1a/relu
I0701 14:51:50.823377  1052 net.cpp:98] Creating Layer conv1a/relu
I0701 14:51:50.823381  1052 net.cpp:439] conv1a/relu <- conv1a/bn
I0701 14:51:50.823386  1052 net.cpp:400] conv1a/relu -> conv1a/bn (in-place)
I0701 14:51:50.823393  1052 net.cpp:148] Setting up conv1a/relu
I0701 14:51:50.823397  1052 net.cpp:155] Top shape: 50 32 32 32 (1638400)
I0701 14:51:50.823401  1052 net.cpp:163] Memory required for data: 20890400
I0701 14:51:50.823405  1052 layer_factory.hpp:77] Creating layer conv1b
I0701 14:51:50.823413  1052 net.cpp:98] Creating Layer conv1b
I0701 14:51:50.823416  1052 net.cpp:439] conv1b <- conv1a/bn
I0701 14:51:50.823421  1052 net.cpp:413] conv1b -> conv1b
I0701 14:51:50.823798  1052 net.cpp:148] Setting up conv1b
I0701 14:51:50.823807  1052 net.cpp:155] Top shape: 50 32 32 32 (1638400)
I0701 14:51:50.823809  1052 net.cpp:163] Memory required for data: 27444000
I0701 14:51:50.823817  1052 layer_factory.hpp:77] Creating layer conv1b/bn
I0701 14:51:50.823824  1052 net.cpp:98] Creating Layer conv1b/bn
I0701 14:51:50.823827  1052 net.cpp:439] conv1b/bn <- conv1b
I0701 14:51:50.823833  1052 net.cpp:413] conv1b/bn -> conv1b/bn
I0701 14:51:50.824563  1052 net.cpp:148] Setting up conv1b/bn
I0701 14:51:50.824571  1052 net.cpp:155] Top shape: 50 32 32 32 (1638400)
I0701 14:51:50.824574  1052 net.cpp:163] Memory required for data: 33997600
I0701 14:51:50.824584  1052 layer_factory.hpp:77] Creating layer conv1b/relu
I0701 14:51:50.824589  1052 net.cpp:98] Creating Layer conv1b/relu
I0701 14:51:50.824594  1052 net.cpp:439] conv1b/relu <- conv1b/bn
I0701 14:51:50.824599  1052 net.cpp:400] conv1b/relu -> conv1b/bn (in-place)
I0701 14:51:50.824604  1052 net.cpp:148] Setting up conv1b/relu
I0701 14:51:50.824609  1052 net.cpp:155] Top shape: 50 32 32 32 (1638400)
I0701 14:51:50.824612  1052 net.cpp:163] Memory required for data: 40551200
I0701 14:51:50.824615  1052 layer_factory.hpp:77] Creating layer pool1
I0701 14:51:50.824622  1052 net.cpp:98] Creating Layer pool1
I0701 14:51:50.824625  1052 net.cpp:439] pool1 <- conv1b/bn
I0701 14:51:50.824630  1052 net.cpp:413] pool1 -> pool1
I0701 14:51:50.824669  1052 net.cpp:148] Setting up pool1
I0701 14:51:50.824674  1052 net.cpp:155] Top shape: 50 32 32 32 (1638400)
I0701 14:51:50.824677  1052 net.cpp:163] Memory required for data: 47104800
I0701 14:51:50.824681  1052 layer_factory.hpp:77] Creating layer res2a_branch2a
I0701 14:51:50.824689  1052 net.cpp:98] Creating Layer res2a_branch2a
I0701 14:51:50.824693  1052 net.cpp:439] res2a_branch2a <- pool1
I0701 14:51:50.824697  1052 net.cpp:413] res2a_branch2a -> res2a_branch2a
I0701 14:51:50.825384  1052 net.cpp:148] Setting up res2a_branch2a
I0701 14:51:50.825390  1052 net.cpp:155] Top shape: 50 64 32 32 (3276800)
I0701 14:51:50.825393  1052 net.cpp:163] Memory required for data: 60212000
I0701 14:51:50.825402  1052 layer_factory.hpp:77] Creating layer res2a_branch2a/bn
I0701 14:51:50.825407  1052 net.cpp:98] Creating Layer res2a_branch2a/bn
I0701 14:51:50.825410  1052 net.cpp:439] res2a_branch2a/bn <- res2a_branch2a
I0701 14:51:50.825415  1052 net.cpp:413] res2a_branch2a/bn -> res2a_branch2a/bn
I0701 14:51:50.826113  1052 net.cpp:148] Setting up res2a_branch2a/bn
I0701 14:51:50.826120  1052 net.cpp:155] Top shape: 50 64 32 32 (3276800)
I0701 14:51:50.826123  1052 net.cpp:163] Memory required for data: 73319200
I0701 14:51:50.826131  1052 layer_factory.hpp:77] Creating layer res2a_branch2a/relu
I0701 14:51:50.826135  1052 net.cpp:98] Creating Layer res2a_branch2a/relu
I0701 14:51:50.826139  1052 net.cpp:439] res2a_branch2a/relu <- res2a_branch2a/bn
I0701 14:51:50.826143  1052 net.cpp:400] res2a_branch2a/relu -> res2a_branch2a/bn (in-place)
I0701 14:51:50.826149  1052 net.cpp:148] Setting up res2a_branch2a/relu
I0701 14:51:50.826153  1052 net.cpp:155] Top shape: 50 64 32 32 (3276800)
I0701 14:51:50.826158  1052 net.cpp:163] Memory required for data: 86426400
I0701 14:51:50.826160  1052 layer_factory.hpp:77] Creating layer res2a_branch2b
I0701 14:51:50.826167  1052 net.cpp:98] Creating Layer res2a_branch2b
I0701 14:51:50.826181  1052 net.cpp:439] res2a_branch2b <- res2a_branch2a/bn
I0701 14:51:50.826186  1052 net.cpp:413] res2a_branch2b -> res2a_branch2b
I0701 14:51:50.826684  1052 net.cpp:148] Setting up res2a_branch2b
I0701 14:51:50.826691  1052 net.cpp:155] Top shape: 50 64 32 32 (3276800)
I0701 14:51:50.826695  1052 net.cpp:163] Memory required for data: 99533600
I0701 14:51:50.826701  1052 layer_factory.hpp:77] Creating layer res2a_branch2b/bn
I0701 14:51:50.826707  1052 net.cpp:98] Creating Layer res2a_branch2b/bn
I0701 14:51:50.826711  1052 net.cpp:439] res2a_branch2b/bn <- res2a_branch2b
I0701 14:51:50.826716  1052 net.cpp:413] res2a_branch2b/bn -> res2a_branch2b/bn
I0701 14:51:50.827405  1052 net.cpp:148] Setting up res2a_branch2b/bn
I0701 14:51:50.827411  1052 net.cpp:155] Top shape: 50 64 32 32 (3276800)
I0701 14:51:50.827415  1052 net.cpp:163] Memory required for data: 112640800
I0701 14:51:50.827425  1052 layer_factory.hpp:77] Creating layer res2a_branch2b/relu
I0701 14:51:50.827428  1052 net.cpp:98] Creating Layer res2a_branch2b/relu
I0701 14:51:50.827432  1052 net.cpp:439] res2a_branch2b/relu <- res2a_branch2b/bn
I0701 14:51:50.827436  1052 net.cpp:400] res2a_branch2b/relu -> res2a_branch2b/bn (in-place)
I0701 14:51:50.827442  1052 net.cpp:148] Setting up res2a_branch2b/relu
I0701 14:51:50.827447  1052 net.cpp:155] Top shape: 50 64 32 32 (3276800)
I0701 14:51:50.827450  1052 net.cpp:163] Memory required for data: 125748000
I0701 14:51:50.827455  1052 layer_factory.hpp:77] Creating layer pool2
I0701 14:51:50.827460  1052 net.cpp:98] Creating Layer pool2
I0701 14:51:50.827462  1052 net.cpp:439] pool2 <- res2a_branch2b/bn
I0701 14:51:50.827466  1052 net.cpp:413] pool2 -> pool2
I0701 14:51:50.827507  1052 net.cpp:148] Setting up pool2
I0701 14:51:50.827512  1052 net.cpp:155] Top shape: 50 64 16 16 (819200)
I0701 14:51:50.827517  1052 net.cpp:163] Memory required for data: 129024800
I0701 14:51:50.827520  1052 layer_factory.hpp:77] Creating layer res3a_branch2a
I0701 14:51:50.827527  1052 net.cpp:98] Creating Layer res3a_branch2a
I0701 14:51:50.827530  1052 net.cpp:439] res3a_branch2a <- pool2
I0701 14:51:50.827535  1052 net.cpp:413] res3a_branch2a -> res3a_branch2a
I0701 14:51:50.830276  1052 net.cpp:148] Setting up res3a_branch2a
I0701 14:51:50.830291  1052 net.cpp:155] Top shape: 50 128 16 16 (1638400)
I0701 14:51:50.830294  1052 net.cpp:163] Memory required for data: 135578400
I0701 14:51:50.830302  1052 layer_factory.hpp:77] Creating layer res3a_branch2a/bn
I0701 14:51:50.830310  1052 net.cpp:98] Creating Layer res3a_branch2a/bn
I0701 14:51:50.830314  1052 net.cpp:439] res3a_branch2a/bn <- res3a_branch2a
I0701 14:51:50.830322  1052 net.cpp:413] res3a_branch2a/bn -> res3a_branch2a/bn
I0701 14:51:50.831073  1052 net.cpp:148] Setting up res3a_branch2a/bn
I0701 14:51:50.831080  1052 net.cpp:155] Top shape: 50 128 16 16 (1638400)
I0701 14:51:50.831084  1052 net.cpp:163] Memory required for data: 142132000
I0701 14:51:50.831094  1052 layer_factory.hpp:77] Creating layer res3a_branch2a/relu
I0701 14:51:50.831104  1052 net.cpp:98] Creating Layer res3a_branch2a/relu
I0701 14:51:50.831107  1052 net.cpp:439] res3a_branch2a/relu <- res3a_branch2a/bn
I0701 14:51:50.831112  1052 net.cpp:400] res3a_branch2a/relu -> res3a_branch2a/bn (in-place)
I0701 14:51:50.831120  1052 net.cpp:148] Setting up res3a_branch2a/relu
I0701 14:51:50.831123  1052 net.cpp:155] Top shape: 50 128 16 16 (1638400)
I0701 14:51:50.831127  1052 net.cpp:163] Memory required for data: 148685600
I0701 14:51:50.831131  1052 layer_factory.hpp:77] Creating layer res3a_branch2b
I0701 14:51:50.831138  1052 net.cpp:98] Creating Layer res3a_branch2b
I0701 14:51:50.831142  1052 net.cpp:439] res3a_branch2b <- res3a_branch2a/bn
I0701 14:51:50.831146  1052 net.cpp:413] res3a_branch2b -> res3a_branch2b
I0701 14:51:50.832196  1052 net.cpp:148] Setting up res3a_branch2b
I0701 14:51:50.832203  1052 net.cpp:155] Top shape: 50 128 16 16 (1638400)
I0701 14:51:50.832206  1052 net.cpp:163] Memory required for data: 155239200
I0701 14:51:50.832219  1052 layer_factory.hpp:77] Creating layer res3a_branch2b/bn
I0701 14:51:50.832226  1052 net.cpp:98] Creating Layer res3a_branch2b/bn
I0701 14:51:50.832231  1052 net.cpp:439] res3a_branch2b/bn <- res3a_branch2b
I0701 14:51:50.832235  1052 net.cpp:413] res3a_branch2b/bn -> res3a_branch2b/bn
I0701 14:51:50.832881  1052 net.cpp:148] Setting up res3a_branch2b/bn
I0701 14:51:50.832888  1052 net.cpp:155] Top shape: 50 128 16 16 (1638400)
I0701 14:51:50.832892  1052 net.cpp:163] Memory required for data: 161792800
I0701 14:51:50.832901  1052 layer_factory.hpp:77] Creating layer res3a_branch2b/relu
I0701 14:51:50.832906  1052 net.cpp:98] Creating Layer res3a_branch2b/relu
I0701 14:51:50.832909  1052 net.cpp:439] res3a_branch2b/relu <- res3a_branch2b/bn
I0701 14:51:50.832913  1052 net.cpp:400] res3a_branch2b/relu -> res3a_branch2b/bn (in-place)
I0701 14:51:50.832919  1052 net.cpp:148] Setting up res3a_branch2b/relu
I0701 14:51:50.832924  1052 net.cpp:155] Top shape: 50 128 16 16 (1638400)
I0701 14:51:50.832927  1052 net.cpp:163] Memory required for data: 168346400
I0701 14:51:50.832931  1052 layer_factory.hpp:77] Creating layer pool3
I0701 14:51:50.832937  1052 net.cpp:98] Creating Layer pool3
I0701 14:51:50.832940  1052 net.cpp:439] pool3 <- res3a_branch2b/bn
I0701 14:51:50.832945  1052 net.cpp:413] pool3 -> pool3
I0701 14:51:50.832988  1052 net.cpp:148] Setting up pool3
I0701 14:51:50.832993  1052 net.cpp:155] Top shape: 50 128 16 16 (1638400)
I0701 14:51:50.832998  1052 net.cpp:163] Memory required for data: 174900000
I0701 14:51:50.833000  1052 layer_factory.hpp:77] Creating layer res4a_branch2a
I0701 14:51:50.833008  1052 net.cpp:98] Creating Layer res4a_branch2a
I0701 14:51:50.833010  1052 net.cpp:439] res4a_branch2a <- pool3
I0701 14:51:50.833015  1052 net.cpp:413] res4a_branch2a -> res4a_branch2a
I0701 14:51:50.839099  1052 net.cpp:148] Setting up res4a_branch2a
I0701 14:51:50.839107  1052 net.cpp:155] Top shape: 50 256 16 16 (3276800)
I0701 14:51:50.839109  1052 net.cpp:163] Memory required for data: 188007200
I0701 14:51:50.839117  1052 layer_factory.hpp:77] Creating layer res4a_branch2a/bn
I0701 14:51:50.839121  1052 net.cpp:98] Creating Layer res4a_branch2a/bn
I0701 14:51:50.839126  1052 net.cpp:439] res4a_branch2a/bn <- res4a_branch2a
I0701 14:51:50.839131  1052 net.cpp:413] res4a_branch2a/bn -> res4a_branch2a/bn
I0701 14:51:50.839771  1052 net.cpp:148] Setting up res4a_branch2a/bn
I0701 14:51:50.839777  1052 net.cpp:155] Top shape: 50 256 16 16 (3276800)
I0701 14:51:50.839782  1052 net.cpp:163] Memory required for data: 201114400
I0701 14:51:50.839790  1052 layer_factory.hpp:77] Creating layer res4a_branch2a/relu
I0701 14:51:50.839794  1052 net.cpp:98] Creating Layer res4a_branch2a/relu
I0701 14:51:50.839798  1052 net.cpp:439] res4a_branch2a/relu <- res4a_branch2a/bn
I0701 14:51:50.839803  1052 net.cpp:400] res4a_branch2a/relu -> res4a_branch2a/bn (in-place)
I0701 14:51:50.839809  1052 net.cpp:148] Setting up res4a_branch2a/relu
I0701 14:51:50.839813  1052 net.cpp:155] Top shape: 50 256 16 16 (3276800)
I0701 14:51:50.839818  1052 net.cpp:163] Memory required for data: 214221600
I0701 14:51:50.839820  1052 layer_factory.hpp:77] Creating layer res4a_branch2b
I0701 14:51:50.839826  1052 net.cpp:98] Creating Layer res4a_branch2b
I0701 14:51:50.839830  1052 net.cpp:439] res4a_branch2b <- res4a_branch2a/bn
I0701 14:51:50.839835  1052 net.cpp:413] res4a_branch2b -> res4a_branch2b
I0701 14:51:50.843037  1052 net.cpp:148] Setting up res4a_branch2b
I0701 14:51:50.843044  1052 net.cpp:155] Top shape: 50 256 16 16 (3276800)
I0701 14:51:50.843047  1052 net.cpp:163] Memory required for data: 227328800
I0701 14:51:50.843053  1052 layer_factory.hpp:77] Creating layer res4a_branch2b/bn
I0701 14:51:50.843058  1052 net.cpp:98] Creating Layer res4a_branch2b/bn
I0701 14:51:50.843062  1052 net.cpp:439] res4a_branch2b/bn <- res4a_branch2b
I0701 14:51:50.843072  1052 net.cpp:413] res4a_branch2b/bn -> res4a_branch2b/bn
I0701 14:51:50.843719  1052 net.cpp:148] Setting up res4a_branch2b/bn
I0701 14:51:50.843725  1052 net.cpp:155] Top shape: 50 256 16 16 (3276800)
I0701 14:51:50.843737  1052 net.cpp:163] Memory required for data: 240436000
I0701 14:51:50.843746  1052 layer_factory.hpp:77] Creating layer res4a_branch2b/relu
I0701 14:51:50.843751  1052 net.cpp:98] Creating Layer res4a_branch2b/relu
I0701 14:51:50.843755  1052 net.cpp:439] res4a_branch2b/relu <- res4a_branch2b/bn
I0701 14:51:50.843760  1052 net.cpp:400] res4a_branch2b/relu -> res4a_branch2b/bn (in-place)
I0701 14:51:50.843766  1052 net.cpp:148] Setting up res4a_branch2b/relu
I0701 14:51:50.843770  1052 net.cpp:155] Top shape: 50 256 16 16 (3276800)
I0701 14:51:50.843775  1052 net.cpp:163] Memory required for data: 253543200
I0701 14:51:50.843777  1052 layer_factory.hpp:77] Creating layer pool4
I0701 14:51:50.843783  1052 net.cpp:98] Creating Layer pool4
I0701 14:51:50.843787  1052 net.cpp:439] pool4 <- res4a_branch2b/bn
I0701 14:51:50.843792  1052 net.cpp:413] pool4 -> pool4
I0701 14:51:50.843839  1052 net.cpp:148] Setting up pool4
I0701 14:51:50.843844  1052 net.cpp:155] Top shape: 50 256 8 8 (819200)
I0701 14:51:50.843848  1052 net.cpp:163] Memory required for data: 256820000
I0701 14:51:50.843852  1052 layer_factory.hpp:77] Creating layer res5a_branch2a
I0701 14:51:50.843859  1052 net.cpp:98] Creating Layer res5a_branch2a
I0701 14:51:50.843863  1052 net.cpp:439] res5a_branch2a <- pool4
I0701 14:51:50.843868  1052 net.cpp:413] res5a_branch2a -> res5a_branch2a
I0701 14:51:50.868707  1052 net.cpp:148] Setting up res5a_branch2a
I0701 14:51:50.868726  1052 net.cpp:155] Top shape: 50 512 8 8 (1638400)
I0701 14:51:50.868729  1052 net.cpp:163] Memory required for data: 263373600
I0701 14:51:50.868736  1052 layer_factory.hpp:77] Creating layer res5a_branch2a/bn
I0701 14:51:50.868747  1052 net.cpp:98] Creating Layer res5a_branch2a/bn
I0701 14:51:50.868752  1052 net.cpp:439] res5a_branch2a/bn <- res5a_branch2a
I0701 14:51:50.868758  1052 net.cpp:413] res5a_branch2a/bn -> res5a_branch2a/bn
I0701 14:51:50.869464  1052 net.cpp:148] Setting up res5a_branch2a/bn
I0701 14:51:50.869477  1052 net.cpp:155] Top shape: 50 512 8 8 (1638400)
I0701 14:51:50.869482  1052 net.cpp:163] Memory required for data: 269927200
I0701 14:51:50.869489  1052 layer_factory.hpp:77] Creating layer res5a_branch2a/relu
I0701 14:51:50.869494  1052 net.cpp:98] Creating Layer res5a_branch2a/relu
I0701 14:51:50.869498  1052 net.cpp:439] res5a_branch2a/relu <- res5a_branch2a/bn
I0701 14:51:50.869503  1052 net.cpp:400] res5a_branch2a/relu -> res5a_branch2a/bn (in-place)
I0701 14:51:50.869509  1052 net.cpp:148] Setting up res5a_branch2a/relu
I0701 14:51:50.869514  1052 net.cpp:155] Top shape: 50 512 8 8 (1638400)
I0701 14:51:50.869518  1052 net.cpp:163] Memory required for data: 276480800
I0701 14:51:50.869523  1052 layer_factory.hpp:77] Creating layer res5a_branch2b
I0701 14:51:50.869529  1052 net.cpp:98] Creating Layer res5a_branch2b
I0701 14:51:50.869532  1052 net.cpp:439] res5a_branch2b <- res5a_branch2a/bn
I0701 14:51:50.869537  1052 net.cpp:413] res5a_branch2b -> res5a_branch2b
I0701 14:51:50.882344  1052 net.cpp:148] Setting up res5a_branch2b
I0701 14:51:50.882354  1052 net.cpp:155] Top shape: 50 512 8 8 (1638400)
I0701 14:51:50.882356  1052 net.cpp:163] Memory required for data: 283034400
I0701 14:51:50.882369  1052 layer_factory.hpp:77] Creating layer res5a_branch2b/bn
I0701 14:51:50.882376  1052 net.cpp:98] Creating Layer res5a_branch2b/bn
I0701 14:51:50.882380  1052 net.cpp:439] res5a_branch2b/bn <- res5a_branch2b
I0701 14:51:50.882388  1052 net.cpp:413] res5a_branch2b/bn -> res5a_branch2b/bn
I0701 14:51:50.883157  1052 net.cpp:148] Setting up res5a_branch2b/bn
I0701 14:51:50.883164  1052 net.cpp:155] Top shape: 50 512 8 8 (1638400)
I0701 14:51:50.883168  1052 net.cpp:163] Memory required for data: 289588000
I0701 14:51:50.883177  1052 layer_factory.hpp:77] Creating layer res5a_branch2b/relu
I0701 14:51:50.883182  1052 net.cpp:98] Creating Layer res5a_branch2b/relu
I0701 14:51:50.883185  1052 net.cpp:439] res5a_branch2b/relu <- res5a_branch2b/bn
I0701 14:51:50.883190  1052 net.cpp:400] res5a_branch2b/relu -> res5a_branch2b/bn (in-place)
I0701 14:51:50.883204  1052 net.cpp:148] Setting up res5a_branch2b/relu
I0701 14:51:50.883209  1052 net.cpp:155] Top shape: 50 512 8 8 (1638400)
I0701 14:51:50.883213  1052 net.cpp:163] Memory required for data: 296141600
I0701 14:51:50.883216  1052 layer_factory.hpp:77] Creating layer pool5
I0701 14:51:50.883222  1052 net.cpp:98] Creating Layer pool5
I0701 14:51:50.883225  1052 net.cpp:439] pool5 <- res5a_branch2b/bn
I0701 14:51:50.883230  1052 net.cpp:413] pool5 -> pool5
I0701 14:51:50.883258  1052 net.cpp:148] Setting up pool5
I0701 14:51:50.883263  1052 net.cpp:155] Top shape: 50 512 1 1 (25600)
I0701 14:51:50.883267  1052 net.cpp:163] Memory required for data: 296244000
I0701 14:51:50.883271  1052 layer_factory.hpp:77] Creating layer fc10
I0701 14:51:50.883283  1052 net.cpp:98] Creating Layer fc10
I0701 14:51:50.883287  1052 net.cpp:439] fc10 <- pool5
I0701 14:51:50.883293  1052 net.cpp:413] fc10 -> fc10
I0701 14:51:50.883548  1052 net.cpp:148] Setting up fc10
I0701 14:51:50.883554  1052 net.cpp:155] Top shape: 50 10 (500)
I0701 14:51:50.883558  1052 net.cpp:163] Memory required for data: 296246000
I0701 14:51:50.883564  1052 layer_factory.hpp:77] Creating layer fc10_fc10_0_split
I0701 14:51:50.883570  1052 net.cpp:98] Creating Layer fc10_fc10_0_split
I0701 14:51:50.883574  1052 net.cpp:439] fc10_fc10_0_split <- fc10
I0701 14:51:50.883579  1052 net.cpp:413] fc10_fc10_0_split -> fc10_fc10_0_split_0
I0701 14:51:50.883584  1052 net.cpp:413] fc10_fc10_0_split -> fc10_fc10_0_split_1
I0701 14:51:50.883589  1052 net.cpp:413] fc10_fc10_0_split -> fc10_fc10_0_split_2
I0701 14:51:50.883656  1052 net.cpp:148] Setting up fc10_fc10_0_split
I0701 14:51:50.883661  1052 net.cpp:155] Top shape: 50 10 (500)
I0701 14:51:50.883666  1052 net.cpp:155] Top shape: 50 10 (500)
I0701 14:51:50.883671  1052 net.cpp:155] Top shape: 50 10 (500)
I0701 14:51:50.883674  1052 net.cpp:163] Memory required for data: 296252000
I0701 14:51:50.883678  1052 layer_factory.hpp:77] Creating layer loss
I0701 14:51:50.883684  1052 net.cpp:98] Creating Layer loss
I0701 14:51:50.883688  1052 net.cpp:439] loss <- fc10_fc10_0_split_0
I0701 14:51:50.883692  1052 net.cpp:439] loss <- label_data_1_split_0
I0701 14:51:50.883697  1052 net.cpp:413] loss -> loss
I0701 14:51:50.883704  1052 layer_factory.hpp:77] Creating layer loss
I0701 14:51:50.883821  1052 net.cpp:148] Setting up loss
I0701 14:51:50.883826  1052 net.cpp:155] Top shape: (1)
I0701 14:51:50.883831  1052 net.cpp:158]     with loss weight 1
I0701 14:51:50.883841  1052 net.cpp:163] Memory required for data: 296252004
I0701 14:51:50.883843  1052 layer_factory.hpp:77] Creating layer accuracy/top1
I0701 14:51:50.883851  1052 net.cpp:98] Creating Layer accuracy/top1
I0701 14:51:50.883853  1052 net.cpp:439] accuracy/top1 <- fc10_fc10_0_split_1
I0701 14:51:50.883858  1052 net.cpp:439] accuracy/top1 <- label_data_1_split_1
I0701 14:51:50.883863  1052 net.cpp:413] accuracy/top1 -> accuracy/top1
I0701 14:51:50.883877  1052 net.cpp:148] Setting up accuracy/top1
I0701 14:51:50.883880  1052 net.cpp:155] Top shape: (1)
I0701 14:51:50.883884  1052 net.cpp:163] Memory required for data: 296252008
I0701 14:51:50.883888  1052 layer_factory.hpp:77] Creating layer accuracy/top5
I0701 14:51:50.883893  1052 net.cpp:98] Creating Layer accuracy/top5
I0701 14:51:50.883898  1052 net.cpp:439] accuracy/top5 <- fc10_fc10_0_split_2
I0701 14:51:50.883901  1052 net.cpp:439] accuracy/top5 <- label_data_1_split_2
I0701 14:51:50.883906  1052 net.cpp:413] accuracy/top5 -> accuracy/top5
I0701 14:51:50.883913  1052 net.cpp:148] Setting up accuracy/top5
I0701 14:51:50.883916  1052 net.cpp:155] Top shape: (1)
I0701 14:51:50.883919  1052 net.cpp:163] Memory required for data: 296252012
I0701 14:51:50.883924  1052 net.cpp:226] accuracy/top5 does not need backward computation.
I0701 14:51:50.883927  1052 net.cpp:226] accuracy/top1 does not need backward computation.
I0701 14:51:50.883931  1052 net.cpp:224] loss needs backward computation.
I0701 14:51:50.883935  1052 net.cpp:224] fc10_fc10_0_split needs backward computation.
I0701 14:51:50.883946  1052 net.cpp:224] fc10 needs backward computation.
I0701 14:51:50.883949  1052 net.cpp:224] pool5 needs backward computation.
I0701 14:51:50.883954  1052 net.cpp:224] res5a_branch2b/relu needs backward computation.
I0701 14:51:50.883956  1052 net.cpp:224] res5a_branch2b/bn needs backward computation.
I0701 14:51:50.883961  1052 net.cpp:224] res5a_branch2b needs backward computation.
I0701 14:51:50.883965  1052 net.cpp:224] res5a_branch2a/relu needs backward computation.
I0701 14:51:50.883968  1052 net.cpp:224] res5a_branch2a/bn needs backward computation.
I0701 14:51:50.883972  1052 net.cpp:224] res5a_branch2a needs backward computation.
I0701 14:51:50.883976  1052 net.cpp:224] pool4 needs backward computation.
I0701 14:51:50.883980  1052 net.cpp:224] res4a_branch2b/relu needs backward computation.
I0701 14:51:50.883985  1052 net.cpp:224] res4a_branch2b/bn needs backward computation.
I0701 14:51:50.883990  1052 net.cpp:224] res4a_branch2b needs backward computation.
I0701 14:51:50.883993  1052 net.cpp:224] res4a_branch2a/relu needs backward computation.
I0701 14:51:50.883996  1052 net.cpp:224] res4a_branch2a/bn needs backward computation.
I0701 14:51:50.884001  1052 net.cpp:224] res4a_branch2a needs backward computation.
I0701 14:51:50.884004  1052 net.cpp:224] pool3 needs backward computation.
I0701 14:51:50.884008  1052 net.cpp:224] res3a_branch2b/relu needs backward computation.
I0701 14:51:50.884012  1052 net.cpp:224] res3a_branch2b/bn needs backward computation.
I0701 14:51:50.884016  1052 net.cpp:224] res3a_branch2b needs backward computation.
I0701 14:51:50.884021  1052 net.cpp:224] res3a_branch2a/relu needs backward computation.
I0701 14:51:50.884024  1052 net.cpp:224] res3a_branch2a/bn needs backward computation.
I0701 14:51:50.884027  1052 net.cpp:224] res3a_branch2a needs backward computation.
I0701 14:51:50.884032  1052 net.cpp:224] pool2 needs backward computation.
I0701 14:51:50.884035  1052 net.cpp:224] res2a_branch2b/relu needs backward computation.
I0701 14:51:50.884039  1052 net.cpp:224] res2a_branch2b/bn needs backward computation.
I0701 14:51:50.884043  1052 net.cpp:224] res2a_branch2b needs backward computation.
I0701 14:51:50.884047  1052 net.cpp:224] res2a_branch2a/relu needs backward computation.
I0701 14:51:50.884050  1052 net.cpp:224] res2a_branch2a/bn needs backward computation.
I0701 14:51:50.884054  1052 net.cpp:224] res2a_branch2a needs backward computation.
I0701 14:51:50.884059  1052 net.cpp:224] pool1 needs backward computation.
I0701 14:51:50.884063  1052 net.cpp:224] conv1b/relu needs backward computation.
I0701 14:51:50.884066  1052 net.cpp:224] conv1b/bn needs backward computation.
I0701 14:51:50.884070  1052 net.cpp:224] conv1b needs backward computation.
I0701 14:51:50.884074  1052 net.cpp:224] conv1a/relu needs backward computation.
I0701 14:51:50.884078  1052 net.cpp:224] conv1a/bn needs backward computation.
I0701 14:51:50.884083  1052 net.cpp:224] conv1a needs backward computation.
I0701 14:51:50.884086  1052 net.cpp:226] data/bias does not need backward computation.
I0701 14:51:50.884091  1052 net.cpp:226] label_data_1_split does not need backward computation.
I0701 14:51:50.884095  1052 net.cpp:226] data does not need backward computation.
I0701 14:51:50.884099  1052 net.cpp:268] This network produces output accuracy/top1
I0701 14:51:50.884104  1052 net.cpp:268] This network produces output accuracy/top5
I0701 14:51:50.884107  1052 net.cpp:268] This network produces output loss
I0701 14:51:50.884132  1052 net.cpp:288] Network initialization done.
I0701 14:51:50.884202  1052 solver.cpp:60] Solver scaffolding done.
I0701 14:51:50.887645  1052 caffe.cpp:145] Finetuning from training/cifar10_jacintonet11v2_2017-07-01_14-28-09/initial/cifar10_jacintonet11v2_iter_64000.caffemodel
I0701 14:51:50.914508  1052 data_layer.cpp:78] ReshapePrefetch 21, 3, 32, 32
I0701 14:51:50.914577  1052 data_layer.cpp:83] output data size: 21,3,32,32
I0701 14:51:51.357589  1052 data_layer.cpp:78] ReshapePrefetch 21, 3, 32, 32
I0701 14:51:51.357663  1052 data_layer.cpp:83] output data size: 21,3,32,32
I0701 14:51:51.832545  1052 parallel.cpp:334] Starting Optimization
I0701 14:51:51.832597  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 14:51:51.841852  1052 solver.cpp:415] Solving jacintonet11v2_train
I0701 14:51:51.841871  1052 solver.cpp:416] Learning Rate Policy: poly
I0701 14:51:51.843724  1052 solver.cpp:473] Iteration 0, Testing net (#0)
I0701 14:51:53.520386  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9171
I0701 14:51:53.520406  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9974
I0701 14:51:53.520411  1052 solver.cpp:546]     Test net output #2: loss = 0.2066 (* 1 = 0.2066 loss)
I0701 14:51:53.622195  1052 solver.cpp:290] Iteration 0 (0 iter/s, 1.78026s/100 iter), loss = 0
I0701 14:51:53.622216  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:51:53.622223  1052 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0701 14:51:55.715358  1052 solver.cpp:290] Iteration 100 (47.7765 iter/s, 2.09308s/100 iter), loss = 0
I0701 14:51:55.715381  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:51:55.715387  1052 sgd_solver.cpp:106] Iteration 100, lr = 0.00998437
I0701 14:51:57.850760  1052 solver.cpp:290] Iteration 200 (46.8315 iter/s, 2.13531s/100 iter), loss = 0
I0701 14:51:57.850782  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:51:57.850788  1052 sgd_solver.cpp:106] Iteration 200, lr = 0.00996875
I0701 14:51:59.925151  1052 solver.cpp:290] Iteration 300 (48.2089 iter/s, 2.07431s/100 iter), loss = 0
I0701 14:51:59.925173  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:51:59.925180  1052 sgd_solver.cpp:106] Iteration 300, lr = 0.00995312
I0701 14:52:01.998052  1052 solver.cpp:290] Iteration 400 (48.2435 iter/s, 2.07282s/100 iter), loss = 0
I0701 14:52:01.998075  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:52:01.998085  1052 sgd_solver.cpp:106] Iteration 400, lr = 0.0099375
I0701 14:52:04.072420  1052 solver.cpp:290] Iteration 500 (48.2095 iter/s, 2.07428s/100 iter), loss = 0
I0701 14:52:04.072443  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:52:04.072451  1052 sgd_solver.cpp:106] Iteration 500, lr = 0.00992187
I0701 14:52:06.145853  1052 solver.cpp:290] Iteration 600 (48.2312 iter/s, 2.07335s/100 iter), loss = 0
I0701 14:52:06.145874  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:52:06.145881  1052 sgd_solver.cpp:106] Iteration 600, lr = 0.00990625
I0701 14:52:08.219409  1052 solver.cpp:290] Iteration 700 (48.2283 iter/s, 2.07347s/100 iter), loss = 0
I0701 14:52:08.219434  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:52:08.219442  1052 sgd_solver.cpp:106] Iteration 700, lr = 0.00989062
I0701 14:52:10.299667  1052 solver.cpp:290] Iteration 800 (48.0729 iter/s, 2.08017s/100 iter), loss = 0
I0701 14:52:10.299691  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:52:10.299700  1052 sgd_solver.cpp:106] Iteration 800, lr = 0.009875
I0701 14:52:12.377670  1052 solver.cpp:290] Iteration 900 (48.1251 iter/s, 2.07792s/100 iter), loss = 0
I0701 14:52:12.377694  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:52:12.377702  1052 sgd_solver.cpp:106] Iteration 900, lr = 0.00985937
I0701 14:52:14.435596  1052 solver.cpp:354] Sparsity after update:
I0701 14:52:14.436947  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 14:52:14.436954  1052 net.cpp:1851] conv1a_param_0(0) 
I0701 14:52:14.436965  1052 net.cpp:1851] conv1b_param_0(0) 
I0701 14:52:14.436967  1052 net.cpp:1851] fc10_param_0(0) 
I0701 14:52:14.436969  1052 net.cpp:1851] res2a_branch2a_param_0(0) 
I0701 14:52:14.436971  1052 net.cpp:1851] res2a_branch2b_param_0(0) 
I0701 14:52:14.436974  1052 net.cpp:1851] res3a_branch2a_param_0(0) 
I0701 14:52:14.436976  1052 net.cpp:1851] res3a_branch2b_param_0(0) 
I0701 14:52:14.436978  1052 net.cpp:1851] res4a_branch2a_param_0(0) 
I0701 14:52:14.436991  1052 net.cpp:1851] res4a_branch2b_param_0(0) 
I0701 14:52:14.436993  1052 net.cpp:1851] res5a_branch2a_param_0(0) 
I0701 14:52:14.436995  1052 net.cpp:1851] res5a_branch2b_param_0(0) 
I0701 14:52:14.436998  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (0/2.3599e+06) 0
I0701 14:52:14.437085  1052 solver.cpp:473] Iteration 1000, Testing net (#0)
I0701 14:52:16.077884  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9186
I0701 14:52:16.077903  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9972
I0701 14:52:16.077909  1052 solver.cpp:546]     Test net output #2: loss = 0.2066 (* 1 = 0.2066 loss)
I0701 14:52:16.097882  1052 solver.cpp:290] Iteration 1000 (26.8811 iter/s, 3.72009s/100 iter), loss = 0
I0701 14:52:16.097900  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:52:16.097910  1052 sgd_solver.cpp:106] Iteration 1000, lr = 0.00984375
I0701 14:52:18.181015  1052 solver.cpp:290] Iteration 1100 (48.0065 iter/s, 2.08305s/100 iter), loss = 0
I0701 14:52:18.181035  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:52:18.181042  1052 sgd_solver.cpp:106] Iteration 1100, lr = 0.00982813
I0701 14:52:20.256978  1052 solver.cpp:290] Iteration 1200 (48.1723 iter/s, 2.07588s/100 iter), loss = 0
I0701 14:52:20.257000  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:52:20.257006  1052 sgd_solver.cpp:106] Iteration 1200, lr = 0.0098125
I0701 14:52:22.331051  1052 solver.cpp:290] Iteration 1300 (48.2163 iter/s, 2.07399s/100 iter), loss = 0
I0701 14:52:22.331109  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:52:22.331115  1052 sgd_solver.cpp:106] Iteration 1300, lr = 0.00979687
I0701 14:52:24.404567  1052 solver.cpp:290] Iteration 1400 (48.23 iter/s, 2.0734s/100 iter), loss = 0
I0701 14:52:24.404588  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:52:24.404594  1052 sgd_solver.cpp:106] Iteration 1400, lr = 0.00978125
I0701 14:52:26.479073  1052 solver.cpp:290] Iteration 1500 (48.2062 iter/s, 2.07442s/100 iter), loss = 0
I0701 14:52:26.479094  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:52:26.479102  1052 sgd_solver.cpp:106] Iteration 1500, lr = 0.00976562
I0701 14:52:28.554941  1052 solver.cpp:290] Iteration 1600 (48.1746 iter/s, 2.07578s/100 iter), loss = 0
I0701 14:52:28.554962  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:52:28.554970  1052 sgd_solver.cpp:106] Iteration 1600, lr = 0.00975
I0701 14:52:30.634445  1052 solver.cpp:290] Iteration 1700 (48.0903 iter/s, 2.07942s/100 iter), loss = 0
I0701 14:52:30.634466  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:52:30.634474  1052 sgd_solver.cpp:106] Iteration 1700, lr = 0.00973437
I0701 14:52:32.709966  1052 solver.cpp:290] Iteration 1800 (48.1826 iter/s, 2.07544s/100 iter), loss = 0
I0701 14:52:32.709987  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:52:32.709995  1052 sgd_solver.cpp:106] Iteration 1800, lr = 0.00971875
I0701 14:52:34.781695  1052 solver.cpp:290] Iteration 1900 (48.2708 iter/s, 2.07165s/100 iter), loss = 0
I0701 14:52:34.781718  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:52:34.781724  1052 sgd_solver.cpp:106] Iteration 1900, lr = 0.00970312
I0701 14:52:36.836957  1052 solver.cpp:354] Sparsity after update:
I0701 14:52:36.838312  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 14:52:36.838320  1052 net.cpp:1851] conv1a_param_0(0) 
I0701 14:52:36.838326  1052 net.cpp:1851] conv1b_param_0(0) 
I0701 14:52:36.838328  1052 net.cpp:1851] fc10_param_0(0) 
I0701 14:52:36.838330  1052 net.cpp:1851] res2a_branch2a_param_0(0) 
I0701 14:52:36.838331  1052 net.cpp:1851] res2a_branch2b_param_0(0) 
I0701 14:52:36.838333  1052 net.cpp:1851] res3a_branch2a_param_0(0) 
I0701 14:52:36.838335  1052 net.cpp:1851] res3a_branch2b_param_0(0) 
I0701 14:52:36.838337  1052 net.cpp:1851] res4a_branch2a_param_0(0) 
I0701 14:52:36.838340  1052 net.cpp:1851] res4a_branch2b_param_0(0) 
I0701 14:52:36.838341  1052 net.cpp:1851] res5a_branch2a_param_0(0) 
I0701 14:52:36.838342  1052 net.cpp:1851] res5a_branch2b_param_0(0) 
I0701 14:52:36.838345  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (0/2.3599e+06) 0
I0701 14:52:36.838434  1052 solver.cpp:473] Iteration 2000, Testing net (#0)
I0701 14:52:38.478858  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9173
I0701 14:52:38.478878  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9975
I0701 14:52:38.478883  1052 solver.cpp:546]     Test net output #2: loss = 0.2061 (* 1 = 0.2061 loss)
I0701 14:52:38.499133  1052 solver.cpp:290] Iteration 2000 (26.9012 iter/s, 3.71731s/100 iter), loss = 0
I0701 14:52:38.499151  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:52:38.499163  1052 sgd_solver.cpp:106] Iteration 2000, lr = 0.0096875
I0701 14:52:40.579850  1052 solver.cpp:290] Iteration 2100 (48.0622 iter/s, 2.08064s/100 iter), loss = 0
I0701 14:52:40.579872  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:52:40.579879  1052 sgd_solver.cpp:106] Iteration 2100, lr = 0.00967188
I0701 14:52:42.660487  1052 solver.cpp:290] Iteration 2200 (48.0641 iter/s, 2.08055s/100 iter), loss = 0
I0701 14:52:42.660511  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:52:42.660518  1052 sgd_solver.cpp:106] Iteration 2200, lr = 0.00965625
I0701 14:52:44.737766  1052 solver.cpp:290] Iteration 2300 (48.1419 iter/s, 2.07719s/100 iter), loss = 0
I0701 14:52:44.737807  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:52:44.737814  1052 sgd_solver.cpp:106] Iteration 2300, lr = 0.00964062
I0701 14:52:46.812765  1052 solver.cpp:290] Iteration 2400 (48.1952 iter/s, 2.0749s/100 iter), loss = 0
I0701 14:52:46.812788  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:52:46.812794  1052 sgd_solver.cpp:106] Iteration 2400, lr = 0.009625
I0701 14:52:48.884222  1052 solver.cpp:290] Iteration 2500 (48.2773 iter/s, 2.07137s/100 iter), loss = 0
I0701 14:52:48.884248  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:52:48.884258  1052 sgd_solver.cpp:106] Iteration 2500, lr = 0.00960938
I0701 14:52:50.960265  1052 solver.cpp:290] Iteration 2600 (48.1705 iter/s, 2.07596s/100 iter), loss = 0
I0701 14:52:50.960286  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:52:50.960294  1052 sgd_solver.cpp:106] Iteration 2600, lr = 0.00959375
I0701 14:52:53.036571  1052 solver.cpp:290] Iteration 2700 (48.1644 iter/s, 2.07622s/100 iter), loss = 0
I0701 14:52:53.036623  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:52:53.036630  1052 sgd_solver.cpp:106] Iteration 2700, lr = 0.00957812
I0701 14:52:55.113955  1052 solver.cpp:290] Iteration 2800 (48.1401 iter/s, 2.07727s/100 iter), loss = 0
I0701 14:52:55.113977  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:52:55.113984  1052 sgd_solver.cpp:106] Iteration 2800, lr = 0.0095625
I0701 14:52:57.225872  1052 solver.cpp:290] Iteration 2900 (47.3523 iter/s, 2.11183s/100 iter), loss = 0
I0701 14:52:57.225898  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:52:57.225906  1052 sgd_solver.cpp:106] Iteration 2900, lr = 0.00954687
I0701 14:52:59.289978  1052 solver.cpp:354] Sparsity after update:
I0701 14:52:59.291328  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 14:52:59.291335  1052 net.cpp:1851] conv1a_param_0(0) 
I0701 14:52:59.291342  1052 net.cpp:1851] conv1b_param_0(0) 
I0701 14:52:59.291344  1052 net.cpp:1851] fc10_param_0(0) 
I0701 14:52:59.291347  1052 net.cpp:1851] res2a_branch2a_param_0(0) 
I0701 14:52:59.291348  1052 net.cpp:1851] res2a_branch2b_param_0(0) 
I0701 14:52:59.291349  1052 net.cpp:1851] res3a_branch2a_param_0(0) 
I0701 14:52:59.291352  1052 net.cpp:1851] res3a_branch2b_param_0(0) 
I0701 14:52:59.291353  1052 net.cpp:1851] res4a_branch2a_param_0(0) 
I0701 14:52:59.291355  1052 net.cpp:1851] res4a_branch2b_param_0(0) 
I0701 14:52:59.291357  1052 net.cpp:1851] res5a_branch2a_param_0(0) 
I0701 14:52:59.291358  1052 net.cpp:1851] res5a_branch2b_param_0(0) 
I0701 14:52:59.291360  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (0/2.3599e+06) 0
I0701 14:52:59.291445  1052 solver.cpp:473] Iteration 3000, Testing net (#0)
I0701 14:53:00.943097  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9178
I0701 14:53:00.943115  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9972
I0701 14:53:00.943120  1052 solver.cpp:546]     Test net output #2: loss = 0.208 (* 1 = 0.208 loss)
I0701 14:53:00.963281  1052 solver.cpp:290] Iteration 3000 (26.7574 iter/s, 3.73728s/100 iter), loss = 0
I0701 14:53:00.963299  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:53:00.963310  1052 sgd_solver.cpp:106] Iteration 3000, lr = 0.00953125
I0701 14:53:03.038866  1052 solver.cpp:290] Iteration 3100 (48.1811 iter/s, 2.0755s/100 iter), loss = 0
I0701 14:53:03.038888  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:53:03.038894  1052 sgd_solver.cpp:106] Iteration 3100, lr = 0.00951563
I0701 14:53:05.111137  1052 solver.cpp:290] Iteration 3200 (48.2582 iter/s, 2.07219s/100 iter), loss = 0
I0701 14:53:05.111160  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:53:05.111166  1052 sgd_solver.cpp:106] Iteration 3200, lr = 0.0095
I0701 14:53:07.184571  1052 solver.cpp:290] Iteration 3300 (48.2311 iter/s, 2.07335s/100 iter), loss = 0
I0701 14:53:07.184592  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:53:07.184599  1052 sgd_solver.cpp:106] Iteration 3300, lr = 0.00948437
I0701 14:53:09.264938  1052 solver.cpp:290] Iteration 3400 (48.0704 iter/s, 2.08028s/100 iter), loss = 0
I0701 14:53:09.264961  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:53:09.264967  1052 sgd_solver.cpp:106] Iteration 3400, lr = 0.00946875
I0701 14:53:11.340593  1052 solver.cpp:290] Iteration 3500 (48.1795 iter/s, 2.07557s/100 iter), loss = 0
I0701 14:53:11.340615  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:53:11.340621  1052 sgd_solver.cpp:106] Iteration 3500, lr = 0.00945312
I0701 14:53:13.414933  1052 solver.cpp:290] Iteration 3600 (48.2101 iter/s, 2.07426s/100 iter), loss = 0
I0701 14:53:13.414957  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:53:13.414963  1052 sgd_solver.cpp:106] Iteration 3600, lr = 0.0094375
I0701 14:53:15.488169  1052 solver.cpp:290] Iteration 3700 (48.2357 iter/s, 2.07315s/100 iter), loss = 0
I0701 14:53:15.488214  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:53:15.488220  1052 sgd_solver.cpp:106] Iteration 3700, lr = 0.00942187
I0701 14:53:17.561799  1052 solver.cpp:290] Iteration 3800 (48.2271 iter/s, 2.07352s/100 iter), loss = 0
I0701 14:53:17.561820  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:53:17.561827  1052 sgd_solver.cpp:106] Iteration 3800, lr = 0.00940625
I0701 14:53:19.633285  1052 solver.cpp:290] Iteration 3900 (48.2765 iter/s, 2.0714s/100 iter), loss = 0
I0701 14:53:19.633307  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:53:19.633314  1052 sgd_solver.cpp:106] Iteration 3900, lr = 0.00939062
I0701 14:53:21.690708  1052 solver.cpp:354] Sparsity after update:
I0701 14:53:21.692066  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 14:53:21.692073  1052 net.cpp:1851] conv1a_param_0(0) 
I0701 14:53:21.692082  1052 net.cpp:1851] conv1b_param_0(0) 
I0701 14:53:21.692087  1052 net.cpp:1851] fc10_param_0(0) 
I0701 14:53:21.692091  1052 net.cpp:1851] res2a_branch2a_param_0(0) 
I0701 14:53:21.692095  1052 net.cpp:1851] res2a_branch2b_param_0(0) 
I0701 14:53:21.692098  1052 net.cpp:1851] res3a_branch2a_param_0(0) 
I0701 14:53:21.692102  1052 net.cpp:1851] res3a_branch2b_param_0(0) 
I0701 14:53:21.692106  1052 net.cpp:1851] res4a_branch2a_param_0(0) 
I0701 14:53:21.692109  1052 net.cpp:1851] res4a_branch2b_param_0(0) 
I0701 14:53:21.692112  1052 net.cpp:1851] res5a_branch2a_param_0(0) 
I0701 14:53:21.692116  1052 net.cpp:1851] res5a_branch2b_param_0(0) 
I0701 14:53:21.692122  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (0/2.3599e+06) 0
I0701 14:53:21.692212  1052 solver.cpp:473] Iteration 4000, Testing net (#0)
I0701 14:53:23.339126  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9187
I0701 14:53:23.339223  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9972
I0701 14:53:23.339232  1052 solver.cpp:546]     Test net output #2: loss = 0.2076 (* 1 = 0.2076 loss)
I0701 14:53:23.359046  1052 solver.cpp:290] Iteration 4000 (26.841 iter/s, 3.72564s/100 iter), loss = 0
I0701 14:53:23.359066  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:53:23.359077  1052 sgd_solver.cpp:106] Iteration 4000, lr = 0.009375
I0701 14:53:23.359712  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.02
I0701 14:53:23.375741  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 14:53:25.451705  1052 solver.cpp:290] Iteration 4100 (47.7879 iter/s, 2.09258s/100 iter), loss = 0
I0701 14:53:25.451727  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:53:25.451735  1052 sgd_solver.cpp:106] Iteration 4100, lr = 0.00935937
I0701 14:53:27.525647  1052 solver.cpp:290] Iteration 4200 (48.2193 iter/s, 2.07386s/100 iter), loss = 0
I0701 14:53:27.525671  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:53:27.525676  1052 sgd_solver.cpp:106] Iteration 4200, lr = 0.00934375
I0701 14:53:29.598316  1052 solver.cpp:290] Iteration 4300 (48.249 iter/s, 2.07258s/100 iter), loss = 0
I0701 14:53:29.598338  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:53:29.598346  1052 sgd_solver.cpp:106] Iteration 4300, lr = 0.00932813
I0701 14:53:31.672260  1052 solver.cpp:290] Iteration 4400 (48.2193 iter/s, 2.07386s/100 iter), loss = 0
I0701 14:53:31.672281  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:53:31.672288  1052 sgd_solver.cpp:106] Iteration 4400, lr = 0.0093125
I0701 14:53:33.744017  1052 solver.cpp:290] Iteration 4500 (48.2701 iter/s, 2.07167s/100 iter), loss = 0
I0701 14:53:33.744038  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:53:33.744046  1052 sgd_solver.cpp:106] Iteration 4500, lr = 0.00929687
I0701 14:53:35.816669  1052 solver.cpp:290] Iteration 4600 (48.2493 iter/s, 2.07257s/100 iter), loss = 0
I0701 14:53:35.816691  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:53:35.816697  1052 sgd_solver.cpp:106] Iteration 4600, lr = 0.00928125
I0701 14:53:37.897264  1052 solver.cpp:290] Iteration 4700 (48.0652 iter/s, 2.08051s/100 iter), loss = 0
I0701 14:53:37.897289  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:53:37.897296  1052 sgd_solver.cpp:106] Iteration 4700, lr = 0.00926562
I0701 14:53:39.971644  1052 solver.cpp:290] Iteration 4800 (48.2092 iter/s, 2.07429s/100 iter), loss = 0
I0701 14:53:39.971664  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:53:39.971673  1052 sgd_solver.cpp:106] Iteration 4800, lr = 0.00925
I0701 14:53:42.045174  1052 solver.cpp:290] Iteration 4900 (48.2289 iter/s, 2.07345s/100 iter), loss = 0
I0701 14:53:42.045194  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:53:42.045202  1052 sgd_solver.cpp:106] Iteration 4900, lr = 0.00923437
I0701 14:53:44.102216  1052 solver.cpp:354] Sparsity after update:
I0701 14:53:44.103546  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 14:53:44.103554  1052 net.cpp:1851] conv1a_param_0(0) 
I0701 14:53:44.103564  1052 net.cpp:1851] conv1b_param_0(0.0195) 
I0701 14:53:44.103569  1052 net.cpp:1851] fc10_param_0(0) 
I0701 14:53:44.103574  1052 net.cpp:1851] res2a_branch2a_param_0(0.0195) 
I0701 14:53:44.103577  1052 net.cpp:1851] res2a_branch2b_param_0(0.0199) 
I0701 14:53:44.103581  1052 net.cpp:1851] res3a_branch2a_param_0(0.0196) 
I0701 14:53:44.103585  1052 net.cpp:1851] res3a_branch2b_param_0(0.0195) 
I0701 14:53:44.103590  1052 net.cpp:1851] res4a_branch2a_param_0(0.0196) 
I0701 14:53:44.103595  1052 net.cpp:1851] res4a_branch2b_param_0(0.0192) 
I0701 14:53:44.103600  1052 net.cpp:1851] res5a_branch2a_param_0(0.0171) 
I0701 14:53:44.103603  1052 net.cpp:1851] res5a_branch2b_param_0(0) 
I0701 14:53:44.103608  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (31510/2.3599e+06) 0.0134
I0701 14:53:44.103709  1052 solver.cpp:473] Iteration 5000, Testing net (#0)
I0701 14:53:45.744323  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.917
I0701 14:53:45.744343  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9968
I0701 14:53:45.744348  1052 solver.cpp:546]     Test net output #2: loss = 0.2084 (* 1 = 0.2084 loss)
I0701 14:53:45.764364  1052 solver.cpp:290] Iteration 5000 (26.8885 iter/s, 3.71907s/100 iter), loss = 0
I0701 14:53:45.764380  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:53:45.764395  1052 sgd_solver.cpp:106] Iteration 5000, lr = 0.00921875
I0701 14:53:45.765043  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.04
I0701 14:53:45.787500  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 14:53:47.864282  1052 solver.cpp:290] Iteration 5100 (47.6227 iter/s, 2.09984s/100 iter), loss = 0
I0701 14:53:47.864305  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:53:47.864311  1052 sgd_solver.cpp:106] Iteration 5100, lr = 0.00920312
I0701 14:53:49.937153  1052 solver.cpp:290] Iteration 5200 (48.2443 iter/s, 2.07278s/100 iter), loss = 0
I0701 14:53:49.937180  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:53:49.937188  1052 sgd_solver.cpp:106] Iteration 5200, lr = 0.0091875
I0701 14:53:52.017175  1052 solver.cpp:290] Iteration 5300 (48.0784 iter/s, 2.07994s/100 iter), loss = 0
I0701 14:53:52.017197  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:53:52.017204  1052 sgd_solver.cpp:106] Iteration 5300, lr = 0.00917188
I0701 14:53:54.089769  1052 solver.cpp:290] Iteration 5400 (48.2507 iter/s, 2.07251s/100 iter), loss = 0
I0701 14:53:54.089818  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:53:54.089828  1052 sgd_solver.cpp:106] Iteration 5400, lr = 0.00915625
I0701 14:53:56.161350  1052 solver.cpp:290] Iteration 5500 (48.2749 iter/s, 2.07147s/100 iter), loss = 0
I0701 14:53:56.161370  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:53:56.161378  1052 sgd_solver.cpp:106] Iteration 5500, lr = 0.00914062
I0701 14:53:58.256955  1052 solver.cpp:290] Iteration 5600 (47.7208 iter/s, 2.09552s/100 iter), loss = 0
I0701 14:53:58.256978  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:53:58.256984  1052 sgd_solver.cpp:106] Iteration 5600, lr = 0.009125
I0701 14:54:00.330370  1052 solver.cpp:290] Iteration 5700 (48.2316 iter/s, 2.07333s/100 iter), loss = 0
I0701 14:54:00.330396  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:54:00.330404  1052 sgd_solver.cpp:106] Iteration 5700, lr = 0.00910938
I0701 14:54:02.410126  1052 solver.cpp:290] Iteration 5800 (48.0846 iter/s, 2.07967s/100 iter), loss = 0
I0701 14:54:02.410148  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:54:02.410154  1052 sgd_solver.cpp:106] Iteration 5800, lr = 0.00909375
I0701 14:54:04.484351  1052 solver.cpp:290] Iteration 5900 (48.2127 iter/s, 2.07414s/100 iter), loss = 0
I0701 14:54:04.484375  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:54:04.484380  1052 sgd_solver.cpp:106] Iteration 5900, lr = 0.00907812
I0701 14:54:06.538925  1052 solver.cpp:354] Sparsity after update:
I0701 14:54:06.540278  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 14:54:06.540285  1052 net.cpp:1851] conv1a_param_0(0.0196) 
I0701 14:54:06.540292  1052 net.cpp:1851] conv1b_param_0(0.0378) 
I0701 14:54:06.540295  1052 net.cpp:1851] fc10_param_0(0) 
I0701 14:54:06.540298  1052 net.cpp:1851] res2a_branch2a_param_0(0.0394) 
I0701 14:54:06.540300  1052 net.cpp:1851] res2a_branch2b_param_0(0.0399) 
I0701 14:54:06.540302  1052 net.cpp:1851] res3a_branch2a_param_0(0.0397) 
I0701 14:54:06.540304  1052 net.cpp:1851] res3a_branch2b_param_0(0.0398) 
I0701 14:54:06.540307  1052 net.cpp:1851] res4a_branch2a_param_0(0.0394) 
I0701 14:54:06.540308  1052 net.cpp:1851] res4a_branch2b_param_0(0.0397) 
I0701 14:54:06.540310  1052 net.cpp:1851] res5a_branch2a_param_0(0.0397) 
I0701 14:54:06.540313  1052 net.cpp:1851] res5a_branch2b_param_0(0) 
I0701 14:54:06.540315  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (69939/2.3599e+06) 0.0296
I0701 14:54:06.540401  1052 solver.cpp:473] Iteration 6000, Testing net (#0)
I0701 14:54:08.183444  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9175
I0701 14:54:08.183462  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.997
I0701 14:54:08.183467  1052 solver.cpp:546]     Test net output #2: loss = 0.2068 (* 1 = 0.2068 loss)
I0701 14:54:08.203595  1052 solver.cpp:290] Iteration 6000 (26.8881 iter/s, 3.71912s/100 iter), loss = 0
I0701 14:54:08.203610  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:54:08.203624  1052 sgd_solver.cpp:106] Iteration 6000, lr = 0.0090625
I0701 14:54:08.204249  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.06
I0701 14:54:08.231411  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 14:54:10.306879  1052 solver.cpp:290] Iteration 6100 (47.5465 iter/s, 2.1032s/100 iter), loss = 0
I0701 14:54:10.306901  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:54:10.306908  1052 sgd_solver.cpp:106] Iteration 6100, lr = 0.00904687
I0701 14:54:12.380933  1052 solver.cpp:290] Iteration 6200 (48.2168 iter/s, 2.07397s/100 iter), loss = 0
I0701 14:54:12.380957  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:54:12.380965  1052 sgd_solver.cpp:106] Iteration 6200, lr = 0.00903125
I0701 14:54:14.459887  1052 solver.cpp:290] Iteration 6300 (48.1031 iter/s, 2.07887s/100 iter), loss = 0
I0701 14:54:14.459910  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:54:14.461437  1052 sgd_solver.cpp:106] Iteration 6300, lr = 0.00901563
I0701 14:54:16.534310  1052 solver.cpp:290] Iteration 6400 (48.2081 iter/s, 2.07434s/100 iter), loss = 0
I0701 14:54:16.534333  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:54:16.534340  1052 sgd_solver.cpp:106] Iteration 6400, lr = 0.009
I0701 14:54:18.611703  1052 solver.cpp:290] Iteration 6500 (48.1392 iter/s, 2.07731s/100 iter), loss = 0
I0701 14:54:18.611726  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:54:18.611732  1052 sgd_solver.cpp:106] Iteration 6500, lr = 0.00898437
I0701 14:54:20.683665  1052 solver.cpp:290] Iteration 6600 (48.2654 iter/s, 2.07188s/100 iter), loss = 0
I0701 14:54:20.683686  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:54:20.683692  1052 sgd_solver.cpp:106] Iteration 6600, lr = 0.00896875
I0701 14:54:22.757944  1052 solver.cpp:290] Iteration 6700 (48.2114 iter/s, 2.0742s/100 iter), loss = 0
I0701 14:54:22.757967  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:54:22.757973  1052 sgd_solver.cpp:106] Iteration 6700, lr = 0.00895312
I0701 14:54:24.833917  1052 solver.cpp:290] Iteration 6800 (48.1722 iter/s, 2.07589s/100 iter), loss = 0
I0701 14:54:24.833977  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:54:24.833988  1052 sgd_solver.cpp:106] Iteration 6800, lr = 0.0089375
I0701 14:54:26.917374  1052 solver.cpp:290] Iteration 6900 (47.9999 iter/s, 2.08334s/100 iter), loss = 0
I0701 14:54:26.917398  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:54:26.917407  1052 sgd_solver.cpp:106] Iteration 6900, lr = 0.00892187
I0701 14:54:28.970208  1052 solver.cpp:354] Sparsity after update:
I0701 14:54:28.971541  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 14:54:28.971549  1052 net.cpp:1851] conv1a_param_0(0.0288) 
I0701 14:54:28.971556  1052 net.cpp:1851] conv1b_param_0(0.0599) 
I0701 14:54:28.971560  1052 net.cpp:1851] fc10_param_0(0) 
I0701 14:54:28.971561  1052 net.cpp:1851] res2a_branch2a_param_0(0.059) 
I0701 14:54:28.971563  1052 net.cpp:1851] res2a_branch2b_param_0(0.0598) 
I0701 14:54:28.971566  1052 net.cpp:1851] res3a_branch2a_param_0(0.0594) 
I0701 14:54:28.971568  1052 net.cpp:1851] res3a_branch2b_param_0(0.0599) 
I0701 14:54:28.971570  1052 net.cpp:1851] res4a_branch2a_param_0(0.0583) 
I0701 14:54:28.971572  1052 net.cpp:1851] res4a_branch2b_param_0(0.0592) 
I0701 14:54:28.971575  1052 net.cpp:1851] res5a_branch2a_param_0(0.0524) 
I0701 14:54:28.971576  1052 net.cpp:1851] res5a_branch2b_param_0(0.0406) 
I0701 14:54:28.971578  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (120124/2.3599e+06) 0.0509
I0701 14:54:28.971711  1052 solver.cpp:473] Iteration 7000, Testing net (#0)
I0701 14:54:30.611065  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9186
I0701 14:54:30.611085  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9973
I0701 14:54:30.611090  1052 solver.cpp:546]     Test net output #2: loss = 0.2087 (* 1 = 0.2087 loss)
I0701 14:54:30.631289  1052 solver.cpp:290] Iteration 7000 (26.9267 iter/s, 3.71379s/100 iter), loss = 0
I0701 14:54:30.631306  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:54:30.631319  1052 sgd_solver.cpp:106] Iteration 7000, lr = 0.00890625
I0701 14:54:30.631958  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.08
I0701 14:54:30.669528  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 14:54:32.743878  1052 solver.cpp:290] Iteration 7100 (47.3371 iter/s, 2.11251s/100 iter), loss = 0
I0701 14:54:32.743901  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:54:32.743907  1052 sgd_solver.cpp:106] Iteration 7100, lr = 0.00889063
I0701 14:54:34.815923  1052 solver.cpp:290] Iteration 7200 (48.2635 iter/s, 2.07196s/100 iter), loss = 0
I0701 14:54:34.815945  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:54:34.815951  1052 sgd_solver.cpp:106] Iteration 7200, lr = 0.008875
I0701 14:54:36.890635  1052 solver.cpp:290] Iteration 7300 (48.2014 iter/s, 2.07463s/100 iter), loss = 0
I0701 14:54:36.890655  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:54:36.890662  1052 sgd_solver.cpp:106] Iteration 7300, lr = 0.00885937
I0701 14:54:38.969588  1052 solver.cpp:290] Iteration 7400 (48.103 iter/s, 2.07887s/100 iter), loss = 0
I0701 14:54:38.969610  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:54:38.969616  1052 sgd_solver.cpp:106] Iteration 7400, lr = 0.00884375
I0701 14:54:41.043184  1052 solver.cpp:290] Iteration 7500 (48.2274 iter/s, 2.07351s/100 iter), loss = 0
I0701 14:54:41.043206  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:54:41.043212  1052 sgd_solver.cpp:106] Iteration 7500, lr = 0.00882812
I0701 14:54:43.125360  1052 solver.cpp:290] Iteration 7600 (48.0286 iter/s, 2.08209s/100 iter), loss = 0
I0701 14:54:43.125382  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:54:43.125388  1052 sgd_solver.cpp:106] Iteration 7600, lr = 0.0088125
I0701 14:54:45.202054  1052 solver.cpp:290] Iteration 7700 (48.1554 iter/s, 2.07661s/100 iter), loss = 0
I0701 14:54:45.202093  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:54:45.202102  1052 sgd_solver.cpp:106] Iteration 7700, lr = 0.00879687
I0701 14:54:47.277709  1052 solver.cpp:290] Iteration 7800 (48.1799 iter/s, 2.07555s/100 iter), loss = 0
I0701 14:54:47.277731  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:54:47.277737  1052 sgd_solver.cpp:106] Iteration 7800, lr = 0.00878125
I0701 14:54:49.350203  1052 solver.cpp:290] Iteration 7900 (48.253 iter/s, 2.07241s/100 iter), loss = 0
I0701 14:54:49.350226  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:54:49.350234  1052 sgd_solver.cpp:106] Iteration 7900, lr = 0.00876562
I0701 14:54:51.405205  1052 solver.cpp:354] Sparsity after update:
I0701 14:54:51.406550  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 14:54:51.406558  1052 net.cpp:1851] conv1a_param_0(0.04) 
I0701 14:54:51.406565  1052 net.cpp:1851] conv1b_param_0(0.0799) 
I0701 14:54:51.406569  1052 net.cpp:1851] fc10_param_0(0) 
I0701 14:54:51.406570  1052 net.cpp:1851] res2a_branch2a_param_0(0.0799) 
I0701 14:54:51.406574  1052 net.cpp:1851] res2a_branch2b_param_0(0.08) 
I0701 14:54:51.406575  1052 net.cpp:1851] res3a_branch2a_param_0(0.0797) 
I0701 14:54:51.406577  1052 net.cpp:1851] res3a_branch2b_param_0(0.0799) 
I0701 14:54:51.406579  1052 net.cpp:1851] res4a_branch2a_param_0(0.0794) 
I0701 14:54:51.406581  1052 net.cpp:1851] res4a_branch2b_param_0(0.0797) 
I0701 14:54:51.406584  1052 net.cpp:1851] res5a_branch2a_param_0(0.0743) 
I0701 14:54:51.406586  1052 net.cpp:1851] res5a_branch2b_param_0(0.0513) 
I0701 14:54:51.406589  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (164447/2.3599e+06) 0.0697
I0701 14:54:51.406673  1052 solver.cpp:473] Iteration 8000, Testing net (#0)
I0701 14:54:53.047173  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9171
I0701 14:54:53.047189  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9971
I0701 14:54:53.047195  1052 solver.cpp:546]     Test net output #2: loss = 0.211 (* 1 = 0.211 loss)
I0701 14:54:53.067334  1052 solver.cpp:290] Iteration 8000 (26.9034 iter/s, 3.717s/100 iter), loss = 0
I0701 14:54:53.067351  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:54:53.067365  1052 sgd_solver.cpp:106] Iteration 8000, lr = 0.00875
I0701 14:54:53.068033  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.1
I0701 14:54:53.116209  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 14:54:55.193557  1052 solver.cpp:290] Iteration 8100 (47.0335 iter/s, 2.12614s/100 iter), loss = 0
I0701 14:54:55.193625  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:54:55.193634  1052 sgd_solver.cpp:106] Iteration 8100, lr = 0.00873438
I0701 14:54:57.293145  1052 solver.cpp:290] Iteration 8200 (47.6313 iter/s, 2.09946s/100 iter), loss = 0
I0701 14:54:57.293169  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:54:57.293174  1052 sgd_solver.cpp:106] Iteration 8200, lr = 0.00871875
I0701 14:54:59.368643  1052 solver.cpp:290] Iteration 8300 (48.1832 iter/s, 2.07541s/100 iter), loss = 0
I0701 14:54:59.368665  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:54:59.368671  1052 sgd_solver.cpp:106] Iteration 8300, lr = 0.00870312
I0701 14:55:01.444690  1052 solver.cpp:290] Iteration 8400 (48.1704 iter/s, 2.07596s/100 iter), loss = 0
I0701 14:55:01.444710  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:55:01.444718  1052 sgd_solver.cpp:106] Iteration 8400, lr = 0.0086875
I0701 14:55:03.514876  1052 solver.cpp:290] Iteration 8500 (48.3068 iter/s, 2.0701s/100 iter), loss = 0
I0701 14:55:03.514899  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:55:03.514905  1052 sgd_solver.cpp:106] Iteration 8500, lr = 0.00867188
I0701 14:55:05.587023  1052 solver.cpp:290] Iteration 8600 (48.2611 iter/s, 2.07206s/100 iter), loss = 0
I0701 14:55:05.587045  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:55:05.587052  1052 sgd_solver.cpp:106] Iteration 8600, lr = 0.00865625
I0701 14:55:07.660287  1052 solver.cpp:290] Iteration 8700 (48.2351 iter/s, 2.07318s/100 iter), loss = 0
I0701 14:55:07.660308  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:55:07.660315  1052 sgd_solver.cpp:106] Iteration 8700, lr = 0.00864062
I0701 14:55:09.739429  1052 solver.cpp:290] Iteration 8800 (48.0987 iter/s, 2.07906s/100 iter), loss = 0
I0701 14:55:09.739450  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:55:09.739456  1052 sgd_solver.cpp:106] Iteration 8800, lr = 0.008625
I0701 14:55:11.816689  1052 solver.cpp:290] Iteration 8900 (48.1423 iter/s, 2.07718s/100 iter), loss = 0
I0701 14:55:11.816710  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:55:11.816717  1052 sgd_solver.cpp:106] Iteration 8900, lr = 0.00860937
I0701 14:55:13.877259  1052 solver.cpp:354] Sparsity after update:
I0701 14:55:13.878608  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 14:55:13.878615  1052 net.cpp:1851] conv1a_param_0(0.0492) 
I0701 14:55:13.878623  1052 net.cpp:1851] conv1b_param_0(0.0998) 
I0701 14:55:13.878626  1052 net.cpp:1851] fc10_param_0(0) 
I0701 14:55:13.878628  1052 net.cpp:1851] res2a_branch2a_param_0(0.0998) 
I0701 14:55:13.878630  1052 net.cpp:1851] res2a_branch2b_param_0(0.0998) 
I0701 14:55:13.878633  1052 net.cpp:1851] res3a_branch2a_param_0(0.1) 
I0701 14:55:13.878634  1052 net.cpp:1851] res3a_branch2b_param_0(0.1) 
I0701 14:55:13.878636  1052 net.cpp:1851] res4a_branch2a_param_0(0.0989) 
I0701 14:55:13.878639  1052 net.cpp:1851] res4a_branch2b_param_0(0.1) 
I0701 14:55:13.878643  1052 net.cpp:1851] res5a_branch2a_param_0(0.0993) 
I0701 14:55:13.878644  1052 net.cpp:1851] res5a_branch2b_param_0(0.0982) 
I0701 14:55:13.878646  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (233121/2.3599e+06) 0.0988
I0701 14:55:13.878741  1052 solver.cpp:473] Iteration 9000, Testing net (#0)
I0701 14:55:15.519621  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9176
I0701 14:55:15.519639  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9969
I0701 14:55:15.519644  1052 solver.cpp:546]     Test net output #2: loss = 0.2036 (* 1 = 0.2036 loss)
I0701 14:55:15.539413  1052 solver.cpp:290] Iteration 9000 (26.863 iter/s, 3.7226s/100 iter), loss = 0
I0701 14:55:15.539438  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:55:15.539444  1052 sgd_solver.cpp:106] Iteration 9000, lr = 0.00859375
I0701 14:55:15.540091  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.12
I0701 14:55:15.590929  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 14:55:17.666021  1052 solver.cpp:290] Iteration 9100 (47.0252 iter/s, 2.12652s/100 iter), loss = 0
I0701 14:55:17.666045  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:55:17.666051  1052 sgd_solver.cpp:106] Iteration 9100, lr = 0.00857813
I0701 14:55:19.740772  1052 solver.cpp:290] Iteration 9200 (48.2006 iter/s, 2.07466s/100 iter), loss = 0
I0701 14:55:19.740797  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:55:19.740804  1052 sgd_solver.cpp:106] Iteration 9200, lr = 0.0085625
I0701 14:55:21.814779  1052 solver.cpp:290] Iteration 9300 (48.2179 iter/s, 2.07392s/100 iter), loss = 0
I0701 14:55:21.814801  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:55:21.814810  1052 sgd_solver.cpp:106] Iteration 9300, lr = 0.00854687
I0701 14:55:23.894500  1052 solver.cpp:290] Iteration 9400 (48.0853 iter/s, 2.07964s/100 iter), loss = 0
I0701 14:55:23.894521  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:55:23.894527  1052 sgd_solver.cpp:106] Iteration 9400, lr = 0.00853125
I0701 14:55:25.972079  1052 solver.cpp:290] Iteration 9500 (48.1349 iter/s, 2.07749s/100 iter), loss = 0
I0701 14:55:25.972133  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:55:25.972141  1052 sgd_solver.cpp:106] Iteration 9500, lr = 0.00851563
I0701 14:55:28.046365  1052 solver.cpp:290] Iteration 9600 (48.2121 iter/s, 2.07417s/100 iter), loss = 0
I0701 14:55:28.046406  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:55:28.046417  1052 sgd_solver.cpp:106] Iteration 9600, lr = 0.0085
I0701 14:55:30.120965  1052 solver.cpp:290] Iteration 9700 (48.2044 iter/s, 2.0745s/100 iter), loss = 0
I0701 14:55:30.120985  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:55:30.120993  1052 sgd_solver.cpp:106] Iteration 9700, lr = 0.00848437
I0701 14:55:32.197757  1052 solver.cpp:290] Iteration 9800 (48.1531 iter/s, 2.07671s/100 iter), loss = 0
I0701 14:55:32.197779  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:55:32.197787  1052 sgd_solver.cpp:106] Iteration 9800, lr = 0.00846875
I0701 14:55:34.272476  1052 solver.cpp:290] Iteration 9900 (48.2013 iter/s, 2.07463s/100 iter), loss = 0
I0701 14:55:34.272500  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:55:34.272507  1052 sgd_solver.cpp:106] Iteration 9900, lr = 0.00845312
I0701 14:55:36.324594  1052 solver.cpp:600] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/sparse/cifar10_jacintonet11v2_iter_10000.caffemodel
I0701 14:55:36.348734  1052 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/sparse/cifar10_jacintonet11v2_iter_10000.solverstate
I0701 14:55:36.356487  1052 solver.cpp:354] Sparsity after update:
I0701 14:55:36.357470  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 14:55:36.357481  1052 net.cpp:1851] conv1a_param_0(0.0596) 
I0701 14:55:36.357487  1052 net.cpp:1851] conv1b_param_0(0.12) 
I0701 14:55:36.357491  1052 net.cpp:1851] fc10_param_0(0) 
I0701 14:55:36.357492  1052 net.cpp:1851] res2a_branch2a_param_0(0.12) 
I0701 14:55:36.357494  1052 net.cpp:1851] res2a_branch2b_param_0(0.12) 
I0701 14:55:36.357496  1052 net.cpp:1851] res3a_branch2a_param_0(0.12) 
I0701 14:55:36.357498  1052 net.cpp:1851] res3a_branch2b_param_0(0.12) 
I0701 14:55:36.357499  1052 net.cpp:1851] res4a_branch2a_param_0(0.12) 
I0701 14:55:36.357501  1052 net.cpp:1851] res4a_branch2b_param_0(0.12) 
I0701 14:55:36.357503  1052 net.cpp:1851] res5a_branch2a_param_0(0.114) 
I0701 14:55:36.357506  1052 net.cpp:1851] res5a_branch2b_param_0(0.0679) 
I0701 14:55:36.357507  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (245001/2.3599e+06) 0.104
I0701 14:55:36.357617  1052 solver.cpp:473] Iteration 10000, Testing net (#0)
I0701 14:55:37.997452  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.918
I0701 14:55:37.997470  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.997
I0701 14:55:37.997475  1052 solver.cpp:546]     Test net output #2: loss = 0.2052 (* 1 = 0.2052 loss)
I0701 14:55:38.017151  1052 solver.cpp:290] Iteration 10000 (26.7055 iter/s, 3.74455s/100 iter), loss = 0
I0701 14:55:38.017168  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:55:38.017180  1052 sgd_solver.cpp:106] Iteration 10000, lr = 0.0084375
I0701 14:55:38.017810  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.14
I0701 14:55:38.068706  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 14:55:40.140461  1052 solver.cpp:290] Iteration 10100 (47.0981 iter/s, 2.12323s/100 iter), loss = 0
I0701 14:55:40.140482  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:55:40.140489  1052 sgd_solver.cpp:106] Iteration 10100, lr = 0.00842187
I0701 14:55:42.221897  1052 solver.cpp:290] Iteration 10200 (48.0457 iter/s, 2.08135s/100 iter), loss = 0
I0701 14:55:42.221920  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:55:42.221926  1052 sgd_solver.cpp:106] Iteration 10200, lr = 0.00840625
I0701 14:55:44.295156  1052 solver.cpp:290] Iteration 10300 (48.2352 iter/s, 2.07317s/100 iter), loss = 0
I0701 14:55:44.295202  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:55:44.295208  1052 sgd_solver.cpp:106] Iteration 10300, lr = 0.00839063
I0701 14:55:46.371007  1052 solver.cpp:290] Iteration 10400 (48.1754 iter/s, 2.07575s/100 iter), loss = 0
I0701 14:55:46.371031  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:55:46.371037  1052 sgd_solver.cpp:106] Iteration 10400, lr = 0.008375
I0701 14:55:48.444823  1052 solver.cpp:290] Iteration 10500 (48.2223 iter/s, 2.07373s/100 iter), loss = 0
I0701 14:55:48.444847  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:55:48.444856  1052 sgd_solver.cpp:106] Iteration 10500, lr = 0.00835937
I0701 14:55:50.518613  1052 solver.cpp:290] Iteration 10600 (48.2229 iter/s, 2.0737s/100 iter), loss = 0
I0701 14:55:50.518633  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:55:50.518640  1052 sgd_solver.cpp:106] Iteration 10600, lr = 0.00834375
I0701 14:55:52.591516  1052 solver.cpp:290] Iteration 10700 (48.2435 iter/s, 2.07282s/100 iter), loss = 0
I0701 14:55:52.591536  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:55:52.591543  1052 sgd_solver.cpp:106] Iteration 10700, lr = 0.00832812
I0701 14:55:54.666877  1052 solver.cpp:290] Iteration 10800 (48.1863 iter/s, 2.07528s/100 iter), loss = 0
I0701 14:55:54.666898  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:55:54.666906  1052 sgd_solver.cpp:106] Iteration 10800, lr = 0.0083125
I0701 14:55:56.741940  1052 solver.cpp:290] Iteration 10900 (48.1933 iter/s, 2.07498s/100 iter), loss = 0
I0701 14:55:56.742017  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:55:56.742024  1052 sgd_solver.cpp:106] Iteration 10900, lr = 0.00829687
I0701 14:55:58.800869  1052 solver.cpp:354] Sparsity after update:
I0701 14:55:58.802192  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 14:55:58.802199  1052 net.cpp:1851] conv1a_param_0(0.0696) 
I0701 14:55:58.802206  1052 net.cpp:1851] conv1b_param_0(0.14) 
I0701 14:55:58.802208  1052 net.cpp:1851] fc10_param_0(0) 
I0701 14:55:58.802211  1052 net.cpp:1851] res2a_branch2a_param_0(0.14) 
I0701 14:55:58.802212  1052 net.cpp:1851] res2a_branch2b_param_0(0.14) 
I0701 14:55:58.802214  1052 net.cpp:1851] res3a_branch2a_param_0(0.14) 
I0701 14:55:58.802217  1052 net.cpp:1851] res3a_branch2b_param_0(0.14) 
I0701 14:55:58.802218  1052 net.cpp:1851] res4a_branch2a_param_0(0.139) 
I0701 14:55:58.802220  1052 net.cpp:1851] res4a_branch2b_param_0(0.14) 
I0701 14:55:58.802222  1052 net.cpp:1851] res5a_branch2a_param_0(0.129) 
I0701 14:55:58.802224  1052 net.cpp:1851] res5a_branch2b_param_0(0.102) 
I0701 14:55:58.802225  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (293506/2.3599e+06) 0.124
I0701 14:55:58.802309  1052 solver.cpp:473] Iteration 11000, Testing net (#0)
I0701 14:56:00.443706  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9169
I0701 14:56:00.443725  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9972
I0701 14:56:00.443732  1052 solver.cpp:546]     Test net output #2: loss = 0.2104 (* 1 = 0.2104 loss)
I0701 14:56:00.463626  1052 solver.cpp:290] Iteration 11000 (26.8708 iter/s, 3.72151s/100 iter), loss = 0
I0701 14:56:00.463649  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:56:00.463655  1052 sgd_solver.cpp:106] Iteration 11000, lr = 0.00828125
I0701 14:56:00.464279  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.16
I0701 14:56:00.529772  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 14:56:02.611732  1052 solver.cpp:290] Iteration 11100 (46.5546 iter/s, 2.14802s/100 iter), loss = 0
I0701 14:56:02.611757  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:56:02.611764  1052 sgd_solver.cpp:106] Iteration 11100, lr = 0.00826562
I0701 14:56:04.684559  1052 solver.cpp:290] Iteration 11200 (48.2454 iter/s, 2.07274s/100 iter), loss = 0
I0701 14:56:04.684588  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:56:04.684597  1052 sgd_solver.cpp:106] Iteration 11200, lr = 0.00825
I0701 14:56:06.757217  1052 solver.cpp:290] Iteration 11300 (48.2494 iter/s, 2.07257s/100 iter), loss = 0
I0701 14:56:06.757243  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:56:06.757252  1052 sgd_solver.cpp:106] Iteration 11300, lr = 0.00823438
I0701 14:56:08.829772  1052 solver.cpp:290] Iteration 11400 (48.2517 iter/s, 2.07247s/100 iter), loss = 0
I0701 14:56:08.829792  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:56:08.829800  1052 sgd_solver.cpp:106] Iteration 11400, lr = 0.00821875
I0701 14:56:10.903398  1052 solver.cpp:290] Iteration 11500 (48.2266 iter/s, 2.07354s/100 iter), loss = 0
I0701 14:56:10.903420  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:56:10.903426  1052 sgd_solver.cpp:106] Iteration 11500, lr = 0.00820312
I0701 14:56:12.978557  1052 solver.cpp:290] Iteration 11600 (48.191 iter/s, 2.07507s/100 iter), loss = 0
I0701 14:56:12.978579  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:56:12.978585  1052 sgd_solver.cpp:106] Iteration 11600, lr = 0.0081875
I0701 14:56:15.048897  1052 solver.cpp:290] Iteration 11700 (48.3032 iter/s, 2.07026s/100 iter), loss = 0
I0701 14:56:15.048918  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:56:15.048925  1052 sgd_solver.cpp:106] Iteration 11700, lr = 0.00817188
I0701 14:56:17.120400  1052 solver.cpp:290] Iteration 11800 (48.2761 iter/s, 2.07142s/100 iter), loss = 0
I0701 14:56:17.120445  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:56:17.120455  1052 sgd_solver.cpp:106] Iteration 11800, lr = 0.00815625
I0701 14:56:19.196141  1052 solver.cpp:290] Iteration 11900 (48.178 iter/s, 2.07564s/100 iter), loss = 0
I0701 14:56:19.196164  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:56:19.196173  1052 sgd_solver.cpp:106] Iteration 11900, lr = 0.00814062
I0701 14:56:21.247362  1052 solver.cpp:354] Sparsity after update:
I0701 14:56:21.248698  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 14:56:21.248705  1052 net.cpp:1851] conv1a_param_0(0.0796) 
I0701 14:56:21.248713  1052 net.cpp:1851] conv1b_param_0(0.16) 
I0701 14:56:21.248718  1052 net.cpp:1851] fc10_param_0(0) 
I0701 14:56:21.248723  1052 net.cpp:1851] res2a_branch2a_param_0(0.16) 
I0701 14:56:21.248726  1052 net.cpp:1851] res2a_branch2b_param_0(0.16) 
I0701 14:56:21.248730  1052 net.cpp:1851] res3a_branch2a_param_0(0.16) 
I0701 14:56:21.248734  1052 net.cpp:1851] res3a_branch2b_param_0(0.16) 
I0701 14:56:21.248739  1052 net.cpp:1851] res4a_branch2a_param_0(0.159) 
I0701 14:56:21.248744  1052 net.cpp:1851] res4a_branch2b_param_0(0.16) 
I0701 14:56:21.248747  1052 net.cpp:1851] res5a_branch2a_param_0(0.158) 
I0701 14:56:21.248751  1052 net.cpp:1851] res5a_branch2b_param_0(0.136) 
I0701 14:56:21.248755  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (360076/2.3599e+06) 0.153
I0701 14:56:21.248890  1052 solver.cpp:473] Iteration 12000, Testing net (#0)
I0701 14:56:22.889287  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9175
I0701 14:56:22.889307  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9968
I0701 14:56:22.889312  1052 solver.cpp:546]     Test net output #2: loss = 0.2082 (* 1 = 0.2082 loss)
I0701 14:56:22.909430  1052 solver.cpp:290] Iteration 12000 (26.9312 iter/s, 3.71316s/100 iter), loss = 0
I0701 14:56:22.909446  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:56:22.909461  1052 sgd_solver.cpp:106] Iteration 12000, lr = 0.008125
I0701 14:56:22.910044  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.18
I0701 14:56:22.983129  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 14:56:25.055733  1052 solver.cpp:290] Iteration 12100 (46.5935 iter/s, 2.14622s/100 iter), loss = 0
I0701 14:56:25.055754  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:56:25.055761  1052 sgd_solver.cpp:106] Iteration 12100, lr = 0.00810937
I0701 14:56:27.127713  1052 solver.cpp:290] Iteration 12200 (48.265 iter/s, 2.07189s/100 iter), loss = 0
I0701 14:56:27.127843  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:56:27.127862  1052 sgd_solver.cpp:106] Iteration 12200, lr = 0.00809375
I0701 14:56:29.202370  1052 solver.cpp:290] Iteration 12300 (48.2051 iter/s, 2.07447s/100 iter), loss = 0
I0701 14:56:29.202395  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:56:29.202402  1052 sgd_solver.cpp:106] Iteration 12300, lr = 0.00807813
I0701 14:56:31.274754  1052 solver.cpp:290] Iteration 12400 (48.2557 iter/s, 2.0723s/100 iter), loss = 0
I0701 14:56:31.274775  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:56:31.274783  1052 sgd_solver.cpp:106] Iteration 12400, lr = 0.0080625
I0701 14:56:33.350996  1052 solver.cpp:290] Iteration 12500 (48.1658 iter/s, 2.07616s/100 iter), loss = 0
I0701 14:56:33.351019  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:56:33.351025  1052 sgd_solver.cpp:106] Iteration 12500, lr = 0.00804687
I0701 14:56:35.427017  1052 solver.cpp:290] Iteration 12600 (48.171 iter/s, 2.07594s/100 iter), loss = 0
I0701 14:56:35.427039  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:56:35.427047  1052 sgd_solver.cpp:106] Iteration 12600, lr = 0.00803125
I0701 14:56:37.502928  1052 solver.cpp:290] Iteration 12700 (48.1736 iter/s, 2.07583s/100 iter), loss = 0
I0701 14:56:37.502952  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:56:37.502959  1052 sgd_solver.cpp:106] Iteration 12700, lr = 0.00801562
I0701 14:56:39.575284  1052 solver.cpp:290] Iteration 12800 (48.2563 iter/s, 2.07227s/100 iter), loss = 0
I0701 14:56:39.575306  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:56:39.575314  1052 sgd_solver.cpp:106] Iteration 12800, lr = 0.008
I0701 14:56:41.646704  1052 solver.cpp:290] Iteration 12900 (48.278 iter/s, 2.07134s/100 iter), loss = 0
I0701 14:56:41.646728  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:56:41.646736  1052 sgd_solver.cpp:106] Iteration 12900, lr = 0.00798437
I0701 14:56:43.698079  1052 solver.cpp:354] Sparsity after update:
I0701 14:56:43.699419  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 14:56:43.699426  1052 net.cpp:1851] conv1a_param_0(0.0896) 
I0701 14:56:43.699434  1052 net.cpp:1851] conv1b_param_0(0.18) 
I0701 14:56:43.699435  1052 net.cpp:1851] fc10_param_0(0) 
I0701 14:56:43.699437  1052 net.cpp:1851] res2a_branch2a_param_0(0.18) 
I0701 14:56:43.699440  1052 net.cpp:1851] res2a_branch2b_param_0(0.18) 
I0701 14:56:43.699441  1052 net.cpp:1851] res3a_branch2a_param_0(0.18) 
I0701 14:56:43.699443  1052 net.cpp:1851] res3a_branch2b_param_0(0.18) 
I0701 14:56:43.699445  1052 net.cpp:1851] res4a_branch2a_param_0(0.18) 
I0701 14:56:43.699447  1052 net.cpp:1851] res4a_branch2b_param_0(0.18) 
I0701 14:56:43.699450  1052 net.cpp:1851] res5a_branch2a_param_0(0.179) 
I0701 14:56:43.699451  1052 net.cpp:1851] res5a_branch2b_param_0(0.179) 
I0701 14:56:43.699453  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (421543/2.3599e+06) 0.179
I0701 14:56:43.699548  1052 solver.cpp:473] Iteration 13000, Testing net (#0)
I0701 14:56:45.340271  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9169
I0701 14:56:45.340289  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9971
I0701 14:56:45.340294  1052 solver.cpp:546]     Test net output #2: loss = 0.21 (* 1 = 0.21 loss)
I0701 14:56:45.359966  1052 solver.cpp:290] Iteration 13000 (26.9314 iter/s, 3.71314s/100 iter), loss = 0
I0701 14:56:45.359984  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:56:45.359994  1052 sgd_solver.cpp:106] Iteration 13000, lr = 0.00796875
I0701 14:56:45.360642  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.2
I0701 14:56:45.454592  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 14:56:47.526427  1052 solver.cpp:290] Iteration 13100 (46.16 iter/s, 2.16638s/100 iter), loss = 0
I0701 14:56:47.526449  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:56:47.526470  1052 sgd_solver.cpp:106] Iteration 13100, lr = 0.00795313
I0701 14:56:49.597240  1052 solver.cpp:290] Iteration 13200 (48.2922 iter/s, 2.07073s/100 iter), loss = 0
I0701 14:56:49.597263  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:56:49.597272  1052 sgd_solver.cpp:106] Iteration 13200, lr = 0.0079375
I0701 14:56:51.674103  1052 solver.cpp:290] Iteration 13300 (48.1516 iter/s, 2.07678s/100 iter), loss = 0
I0701 14:56:51.674127  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:56:51.674134  1052 sgd_solver.cpp:106] Iteration 13300, lr = 0.00792187
I0701 14:56:53.750077  1052 solver.cpp:290] Iteration 13400 (48.1722 iter/s, 2.07589s/100 iter), loss = 0
I0701 14:56:53.750102  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:56:53.750108  1052 sgd_solver.cpp:106] Iteration 13400, lr = 0.00790625
I0701 14:56:55.822271  1052 solver.cpp:290] Iteration 13500 (48.26 iter/s, 2.07211s/100 iter), loss = 0
I0701 14:56:55.822294  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:56:55.822300  1052 sgd_solver.cpp:106] Iteration 13500, lr = 0.00789062
I0701 14:56:57.941469  1052 solver.cpp:290] Iteration 13600 (47.1896 iter/s, 2.11911s/100 iter), loss = 0
I0701 14:56:57.941531  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:56:57.941542  1052 sgd_solver.cpp:106] Iteration 13600, lr = 0.007875
I0701 14:57:00.014667  1052 solver.cpp:290] Iteration 13700 (48.2375 iter/s, 2.07308s/100 iter), loss = 0
I0701 14:57:00.014689  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:57:00.014696  1052 sgd_solver.cpp:106] Iteration 13700, lr = 0.00785937
I0701 14:57:02.089123  1052 solver.cpp:290] Iteration 13800 (48.2073 iter/s, 2.07437s/100 iter), loss = 0
I0701 14:57:02.089145  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:57:02.089153  1052 sgd_solver.cpp:106] Iteration 13800, lr = 0.00784375
I0701 14:57:04.161664  1052 solver.cpp:290] Iteration 13900 (48.2519 iter/s, 2.07246s/100 iter), loss = 0
I0701 14:57:04.161689  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:57:04.161695  1052 sgd_solver.cpp:106] Iteration 13900, lr = 0.00782812
I0701 14:57:06.213474  1052 solver.cpp:354] Sparsity after update:
I0701 14:57:06.214818  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 14:57:06.214825  1052 net.cpp:1851] conv1a_param_0(0.0996) 
I0701 14:57:06.214833  1052 net.cpp:1851] conv1b_param_0(0.2) 
I0701 14:57:06.214834  1052 net.cpp:1851] fc10_param_0(0) 
I0701 14:57:06.214836  1052 net.cpp:1851] res2a_branch2a_param_0(0.2) 
I0701 14:57:06.214838  1052 net.cpp:1851] res2a_branch2b_param_0(0.2) 
I0701 14:57:06.214840  1052 net.cpp:1851] res3a_branch2a_param_0(0.2) 
I0701 14:57:06.214843  1052 net.cpp:1851] res3a_branch2b_param_0(0.2) 
I0701 14:57:06.214844  1052 net.cpp:1851] res4a_branch2a_param_0(0.2) 
I0701 14:57:06.214845  1052 net.cpp:1851] res4a_branch2b_param_0(0.2) 
I0701 14:57:06.214848  1052 net.cpp:1851] res5a_branch2a_param_0(0.199) 
I0701 14:57:06.214849  1052 net.cpp:1851] res5a_branch2b_param_0(0.196) 
I0701 14:57:06.214851  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (466487/2.3599e+06) 0.198
I0701 14:57:06.214936  1052 solver.cpp:473] Iteration 14000, Testing net (#0)
I0701 14:57:07.857388  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9164
I0701 14:57:07.857408  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9969
I0701 14:57:07.857414  1052 solver.cpp:546]     Test net output #2: loss = 0.2086 (* 1 = 0.2086 loss)
I0701 14:57:07.877246  1052 solver.cpp:290] Iteration 14000 (26.9146 iter/s, 3.71546s/100 iter), loss = 0
I0701 14:57:07.877264  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:57:07.877275  1052 sgd_solver.cpp:106] Iteration 14000, lr = 0.0078125
I0701 14:57:07.877899  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.22
I0701 14:57:07.964072  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 14:57:10.036324  1052 solver.cpp:290] Iteration 14100 (46.3178 iter/s, 2.159s/100 iter), loss = 0
I0701 14:57:10.036347  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:57:10.036356  1052 sgd_solver.cpp:106] Iteration 14100, lr = 0.00779688
I0701 14:57:12.111448  1052 solver.cpp:290] Iteration 14200 (48.1919 iter/s, 2.07504s/100 iter), loss = 0
I0701 14:57:12.111471  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:57:12.111479  1052 sgd_solver.cpp:106] Iteration 14200, lr = 0.00778125
I0701 14:57:14.185742  1052 solver.cpp:290] Iteration 14300 (48.2112 iter/s, 2.07421s/100 iter), loss = 0
I0701 14:57:14.185770  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:57:14.185778  1052 sgd_solver.cpp:106] Iteration 14300, lr = 0.00776563
I0701 14:57:16.258656  1052 solver.cpp:290] Iteration 14400 (48.2433 iter/s, 2.07283s/100 iter), loss = 0
I0701 14:57:16.258677  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:57:16.258687  1052 sgd_solver.cpp:106] Iteration 14400, lr = 0.00775
I0701 14:57:18.329154  1052 solver.cpp:290] Iteration 14500 (48.2995 iter/s, 2.07041s/100 iter), loss = 0
I0701 14:57:18.329174  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:57:18.329202  1052 sgd_solver.cpp:106] Iteration 14500, lr = 0.00773437
I0701 14:57:20.403975  1052 solver.cpp:290] Iteration 14600 (48.1989 iter/s, 2.07474s/100 iter), loss = 0
I0701 14:57:20.403995  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:57:20.404002  1052 sgd_solver.cpp:106] Iteration 14600, lr = 0.00771875
I0701 14:57:22.479636  1052 solver.cpp:290] Iteration 14700 (48.1793 iter/s, 2.07558s/100 iter), loss = 0
I0701 14:57:22.479660  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:57:22.479665  1052 sgd_solver.cpp:106] Iteration 14700, lr = 0.00770312
I0701 14:57:24.552562  1052 solver.cpp:290] Iteration 14800 (48.243 iter/s, 2.07284s/100 iter), loss = 0
I0701 14:57:24.552584  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:57:24.552592  1052 sgd_solver.cpp:106] Iteration 14800, lr = 0.0076875
I0701 14:57:26.625819  1052 solver.cpp:290] Iteration 14900 (48.2352 iter/s, 2.07317s/100 iter), loss = 0
I0701 14:57:26.625841  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:57:26.625850  1052 sgd_solver.cpp:106] Iteration 14900, lr = 0.00767187
I0701 14:57:28.684590  1052 solver.cpp:354] Sparsity after update:
I0701 14:57:28.685950  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 14:57:28.685958  1052 net.cpp:1851] conv1a_param_0(0.11) 
I0701 14:57:28.685964  1052 net.cpp:1851] conv1b_param_0(0.22) 
I0701 14:57:28.685967  1052 net.cpp:1851] fc10_param_0(0) 
I0701 14:57:28.685969  1052 net.cpp:1851] res2a_branch2a_param_0(0.22) 
I0701 14:57:28.685971  1052 net.cpp:1851] res2a_branch2b_param_0(0.22) 
I0701 14:57:28.685973  1052 net.cpp:1851] res3a_branch2a_param_0(0.22) 
I0701 14:57:28.685976  1052 net.cpp:1851] res3a_branch2b_param_0(0.22) 
I0701 14:57:28.685977  1052 net.cpp:1851] res4a_branch2a_param_0(0.22) 
I0701 14:57:28.685978  1052 net.cpp:1851] res4a_branch2b_param_0(0.22) 
I0701 14:57:28.685981  1052 net.cpp:1851] res5a_branch2a_param_0(0.217) 
I0701 14:57:28.685982  1052 net.cpp:1851] res5a_branch2b_param_0(0.216) 
I0701 14:57:28.685984  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (511513/2.3599e+06) 0.217
I0701 14:57:28.686108  1052 solver.cpp:473] Iteration 15000, Testing net (#0)
I0701 14:57:30.326439  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9153
I0701 14:57:30.326458  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9969
I0701 14:57:30.326463  1052 solver.cpp:546]     Test net output #2: loss = 0.2154 (* 1 = 0.2154 loss)
I0701 14:57:30.346267  1052 solver.cpp:290] Iteration 15000 (26.8794 iter/s, 3.72032s/100 iter), loss = 0
I0701 14:57:30.346284  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:57:30.346295  1052 sgd_solver.cpp:106] Iteration 15000, lr = 0.00765625
I0701 14:57:30.346925  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.24
I0701 14:57:30.442493  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 14:57:32.523124  1052 solver.cpp:290] Iteration 15100 (45.9395 iter/s, 2.17678s/100 iter), loss = 0
I0701 14:57:32.523147  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:57:32.523154  1052 sgd_solver.cpp:106] Iteration 15100, lr = 0.00764062
I0701 14:57:34.598183  1052 solver.cpp:290] Iteration 15200 (48.1934 iter/s, 2.07497s/100 iter), loss = 0
I0701 14:57:34.598206  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:57:34.598212  1052 sgd_solver.cpp:106] Iteration 15200, lr = 0.007625
I0701 14:57:36.670677  1052 solver.cpp:290] Iteration 15300 (48.253 iter/s, 2.07241s/100 iter), loss = 0
I0701 14:57:36.670699  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:57:36.670706  1052 sgd_solver.cpp:106] Iteration 15300, lr = 0.00760937
I0701 14:57:38.743134  1052 solver.cpp:290] Iteration 15400 (48.2539 iter/s, 2.07237s/100 iter), loss = 0
I0701 14:57:38.743155  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:57:38.743162  1052 sgd_solver.cpp:106] Iteration 15400, lr = 0.00759375
I0701 14:57:40.814564  1052 solver.cpp:290] Iteration 15500 (48.2778 iter/s, 2.07134s/100 iter), loss = 0
I0701 14:57:40.814597  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:57:40.814609  1052 sgd_solver.cpp:106] Iteration 15500, lr = 0.00757812
I0701 14:57:42.886926  1052 solver.cpp:290] Iteration 15600 (48.2563 iter/s, 2.07227s/100 iter), loss = 0
I0701 14:57:42.886950  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:57:42.886956  1052 sgd_solver.cpp:106] Iteration 15600, lr = 0.0075625
I0701 14:57:44.958629  1052 solver.cpp:290] Iteration 15700 (48.2714 iter/s, 2.07162s/100 iter), loss = 0
I0701 14:57:44.958652  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:57:44.958657  1052 sgd_solver.cpp:106] Iteration 15700, lr = 0.00754687
I0701 14:57:47.032946  1052 solver.cpp:290] Iteration 15800 (48.2106 iter/s, 2.07423s/100 iter), loss = 0
I0701 14:57:47.032968  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:57:47.032975  1052 sgd_solver.cpp:106] Iteration 15800, lr = 0.00753125
I0701 14:57:49.102716  1052 solver.cpp:290] Iteration 15900 (48.3165 iter/s, 2.06969s/100 iter), loss = 0
I0701 14:57:49.102757  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:57:49.102767  1052 sgd_solver.cpp:106] Iteration 15900, lr = 0.00751562
I0701 14:57:51.158587  1052 solver.cpp:354] Sparsity after update:
I0701 14:57:51.159782  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 14:57:51.159790  1052 net.cpp:1851] conv1a_param_0(0.12) 
I0701 14:57:51.159797  1052 net.cpp:1851] conv1b_param_0(0.24) 
I0701 14:57:51.159799  1052 net.cpp:1851] fc10_param_0(0) 
I0701 14:57:51.159802  1052 net.cpp:1851] res2a_branch2a_param_0(0.24) 
I0701 14:57:51.159804  1052 net.cpp:1851] res2a_branch2b_param_0(0.24) 
I0701 14:57:51.159806  1052 net.cpp:1851] res3a_branch2a_param_0(0.24) 
I0701 14:57:51.159809  1052 net.cpp:1851] res3a_branch2b_param_0(0.24) 
I0701 14:57:51.159811  1052 net.cpp:1851] res4a_branch2a_param_0(0.24) 
I0701 14:57:51.159813  1052 net.cpp:1851] res4a_branch2b_param_0(0.24) 
I0701 14:57:51.159816  1052 net.cpp:1851] res5a_branch2a_param_0(0.237) 
I0701 14:57:51.159818  1052 net.cpp:1851] res5a_branch2b_param_0(0.234) 
I0701 14:57:51.159821  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (557643/2.3599e+06) 0.236
I0701 14:57:51.159904  1052 solver.cpp:473] Iteration 16000, Testing net (#0)
I0701 14:57:52.799790  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9166
I0701 14:57:52.799809  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9969
I0701 14:57:52.799813  1052 solver.cpp:546]     Test net output #2: loss = 0.2124 (* 1 = 0.2124 loss)
I0701 14:57:52.820827  1052 solver.cpp:290] Iteration 16000 (26.8964 iter/s, 3.71797s/100 iter), loss = 0
I0701 14:57:52.820844  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:57:52.820855  1052 sgd_solver.cpp:106] Iteration 16000, lr = 0.0075
I0701 14:57:52.821511  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.26
I0701 14:57:52.916638  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 14:57:54.997517  1052 solver.cpp:290] Iteration 16100 (45.943 iter/s, 2.17661s/100 iter), loss = 0
I0701 14:57:54.997540  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:57:54.997546  1052 sgd_solver.cpp:106] Iteration 16100, lr = 0.00748438
I0701 14:57:57.121526  1052 solver.cpp:290] Iteration 16200 (47.0827 iter/s, 2.12392s/100 iter), loss = 0
I0701 14:57:57.121547  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:57:57.121554  1052 sgd_solver.cpp:106] Iteration 16200, lr = 0.00746875
I0701 14:57:59.196969  1052 solver.cpp:290] Iteration 16300 (48.1844 iter/s, 2.07536s/100 iter), loss = 0
I0701 14:57:59.197046  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:57:59.197054  1052 sgd_solver.cpp:106] Iteration 16300, lr = 0.00745312
I0701 14:58:01.268970  1052 solver.cpp:290] Iteration 16400 (48.2657 iter/s, 2.07186s/100 iter), loss = 0
I0701 14:58:01.268991  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:58:01.268998  1052 sgd_solver.cpp:106] Iteration 16400, lr = 0.0074375
I0701 14:58:03.341953  1052 solver.cpp:290] Iteration 16500 (48.2416 iter/s, 2.0729s/100 iter), loss = 0
I0701 14:58:03.341975  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:58:03.341982  1052 sgd_solver.cpp:106] Iteration 16500, lr = 0.00742187
I0701 14:58:05.417023  1052 solver.cpp:290] Iteration 16600 (48.1931 iter/s, 2.07499s/100 iter), loss = 0
I0701 14:58:05.417047  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:58:05.417052  1052 sgd_solver.cpp:106] Iteration 16600, lr = 0.00740625
I0701 14:58:07.490671  1052 solver.cpp:290] Iteration 16700 (48.2262 iter/s, 2.07356s/100 iter), loss = 0
I0701 14:58:07.490694  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:58:07.490702  1052 sgd_solver.cpp:106] Iteration 16700, lr = 0.00739062
I0701 14:58:09.565937  1052 solver.cpp:290] Iteration 16800 (48.1886 iter/s, 2.07518s/100 iter), loss = 0
I0701 14:58:09.565958  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:58:09.565964  1052 sgd_solver.cpp:106] Iteration 16800, lr = 0.007375
I0701 14:58:11.639068  1052 solver.cpp:290] Iteration 16900 (48.2381 iter/s, 2.07305s/100 iter), loss = 0
I0701 14:58:11.639091  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:58:11.639097  1052 sgd_solver.cpp:106] Iteration 16900, lr = 0.00735937
I0701 14:58:13.696557  1052 solver.cpp:354] Sparsity after update:
I0701 14:58:13.697916  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 14:58:13.697922  1052 net.cpp:1851] conv1a_param_0(0.13) 
I0701 14:58:13.697931  1052 net.cpp:1851] conv1b_param_0(0.26) 
I0701 14:58:13.697932  1052 net.cpp:1851] fc10_param_0(0) 
I0701 14:58:13.697934  1052 net.cpp:1851] res2a_branch2a_param_0(0.26) 
I0701 14:58:13.697937  1052 net.cpp:1851] res2a_branch2b_param_0(0.26) 
I0701 14:58:13.697940  1052 net.cpp:1851] res3a_branch2a_param_0(0.26) 
I0701 14:58:13.697942  1052 net.cpp:1851] res3a_branch2b_param_0(0.26) 
I0701 14:58:13.697944  1052 net.cpp:1851] res4a_branch2a_param_0(0.26) 
I0701 14:58:13.697947  1052 net.cpp:1851] res4a_branch2b_param_0(0.26) 
I0701 14:58:13.697948  1052 net.cpp:1851] res5a_branch2a_param_0(0.259) 
I0701 14:58:13.697950  1052 net.cpp:1851] res5a_branch2b_param_0(0.247) 
I0701 14:58:13.697952  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (602813/2.3599e+06) 0.255
I0701 14:58:13.698036  1052 solver.cpp:473] Iteration 17000, Testing net (#0)
I0701 14:58:15.338090  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9174
I0701 14:58:15.338109  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.997
I0701 14:58:15.338114  1052 solver.cpp:546]     Test net output #2: loss = 0.2128 (* 1 = 0.2128 loss)
I0701 14:58:15.357781  1052 solver.cpp:290] Iteration 17000 (26.8919 iter/s, 3.71859s/100 iter), loss = 0
I0701 14:58:15.357798  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:58:15.357812  1052 sgd_solver.cpp:106] Iteration 17000, lr = 0.00734375
I0701 14:58:15.358429  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.28
I0701 14:58:15.465633  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 14:58:17.539340  1052 solver.cpp:290] Iteration 17100 (45.8405 iter/s, 2.18148s/100 iter), loss = 0
I0701 14:58:17.539364  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:58:17.539372  1052 sgd_solver.cpp:106] Iteration 17100, lr = 0.00732813
I0701 14:58:19.617242  1052 solver.cpp:290] Iteration 17200 (48.1274 iter/s, 2.07782s/100 iter), loss = 0
I0701 14:58:19.617280  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:58:19.617287  1052 sgd_solver.cpp:106] Iteration 17200, lr = 0.0073125
I0701 14:58:21.690240  1052 solver.cpp:290] Iteration 17300 (48.2416 iter/s, 2.0729s/100 iter), loss = 0
I0701 14:58:21.690263  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:58:21.690270  1052 sgd_solver.cpp:106] Iteration 17300, lr = 0.00729688
I0701 14:58:23.760582  1052 solver.cpp:290] Iteration 17400 (48.3032 iter/s, 2.07026s/100 iter), loss = 0
I0701 14:58:23.760604  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:58:23.760610  1052 sgd_solver.cpp:106] Iteration 17400, lr = 0.00728125
I0701 14:58:25.831326  1052 solver.cpp:290] Iteration 17500 (48.2938 iter/s, 2.07066s/100 iter), loss = 0
I0701 14:58:25.831348  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:58:25.831354  1052 sgd_solver.cpp:106] Iteration 17500, lr = 0.00726563
I0701 14:58:27.905176  1052 solver.cpp:290] Iteration 17600 (48.2215 iter/s, 2.07376s/100 iter), loss = 0
I0701 14:58:27.905199  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:58:27.905205  1052 sgd_solver.cpp:106] Iteration 17600, lr = 0.00725
I0701 14:58:29.979594  1052 solver.cpp:290] Iteration 17700 (48.2083 iter/s, 2.07433s/100 iter), loss = 0
I0701 14:58:29.979653  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:58:29.979661  1052 sgd_solver.cpp:106] Iteration 17700, lr = 0.00723437
I0701 14:58:32.053045  1052 solver.cpp:290] Iteration 17800 (48.2316 iter/s, 2.07333s/100 iter), loss = 0
I0701 14:58:32.053066  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:58:32.053073  1052 sgd_solver.cpp:106] Iteration 17800, lr = 0.00721875
I0701 14:58:34.126571  1052 solver.cpp:290] Iteration 17900 (48.229 iter/s, 2.07344s/100 iter), loss = 0
I0701 14:58:34.126605  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:58:34.126612  1052 sgd_solver.cpp:106] Iteration 17900, lr = 0.00720312
I0701 14:58:36.177155  1052 solver.cpp:354] Sparsity after update:
I0701 14:58:36.178555  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 14:58:36.178565  1052 net.cpp:1851] conv1a_param_0(0.14) 
I0701 14:58:36.178572  1052 net.cpp:1851] conv1b_param_0(0.28) 
I0701 14:58:36.178577  1052 net.cpp:1851] fc10_param_0(0) 
I0701 14:58:36.178582  1052 net.cpp:1851] res2a_branch2a_param_0(0.28) 
I0701 14:58:36.178586  1052 net.cpp:1851] res2a_branch2b_param_0(0.28) 
I0701 14:58:36.178591  1052 net.cpp:1851] res3a_branch2a_param_0(0.28) 
I0701 14:58:36.178596  1052 net.cpp:1851] res3a_branch2b_param_0(0.28) 
I0701 14:58:36.178601  1052 net.cpp:1851] res4a_branch2a_param_0(0.28) 
I0701 14:58:36.178606  1052 net.cpp:1851] res4a_branch2b_param_0(0.28) 
I0701 14:58:36.178609  1052 net.cpp:1851] res5a_branch2a_param_0(0.278) 
I0701 14:58:36.178613  1052 net.cpp:1851] res5a_branch2b_param_0(0.274) 
I0701 14:58:36.178618  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (652432/2.3599e+06) 0.276
I0701 14:58:36.178719  1052 solver.cpp:473] Iteration 18000, Testing net (#0)
I0701 14:58:37.827147  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9159
I0701 14:58:37.827167  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.997
I0701 14:58:37.827172  1052 solver.cpp:546]     Test net output #2: loss = 0.2133 (* 1 = 0.2133 loss)
I0701 14:58:37.846947  1052 solver.cpp:290] Iteration 18000 (26.88 iter/s, 3.72024s/100 iter), loss = 0
I0701 14:58:37.846963  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:58:37.846977  1052 sgd_solver.cpp:106] Iteration 18000, lr = 0.0071875
I0701 14:58:37.847612  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.3
I0701 14:58:37.966275  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 14:58:40.040916  1052 solver.cpp:290] Iteration 18100 (45.5812 iter/s, 2.19389s/100 iter), loss = 0
I0701 14:58:40.040938  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:58:40.040946  1052 sgd_solver.cpp:106] Iteration 18100, lr = 0.00717187
I0701 14:58:42.114106  1052 solver.cpp:290] Iteration 18200 (48.2368 iter/s, 2.07311s/100 iter), loss = 0
I0701 14:58:42.114127  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:58:42.114135  1052 sgd_solver.cpp:106] Iteration 18200, lr = 0.00715625
I0701 14:58:44.191133  1052 solver.cpp:290] Iteration 18300 (48.1477 iter/s, 2.07694s/100 iter), loss = 0
I0701 14:58:44.191155  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:58:44.191161  1052 sgd_solver.cpp:106] Iteration 18300, lr = 0.00714062
I0701 14:58:46.265734  1052 solver.cpp:290] Iteration 18400 (48.2041 iter/s, 2.07451s/100 iter), loss = 0
I0701 14:58:46.265763  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:58:46.265771  1052 sgd_solver.cpp:106] Iteration 18400, lr = 0.007125
I0701 14:58:48.339233  1052 solver.cpp:290] Iteration 18500 (48.2297 iter/s, 2.07341s/100 iter), loss = 0
I0701 14:58:48.339253  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:58:48.339262  1052 sgd_solver.cpp:106] Iteration 18500, lr = 0.00710937
I0701 14:58:50.413298  1052 solver.cpp:290] Iteration 18600 (48.2164 iter/s, 2.07398s/100 iter), loss = 0
I0701 14:58:50.413321  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:58:50.413347  1052 sgd_solver.cpp:106] Iteration 18600, lr = 0.00709375
I0701 14:58:52.491051  1052 solver.cpp:290] Iteration 18700 (48.1309 iter/s, 2.07767s/100 iter), loss = 0
I0701 14:58:52.491073  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:58:52.491080  1052 sgd_solver.cpp:106] Iteration 18700, lr = 0.00707812
I0701 14:58:54.567090  1052 solver.cpp:290] Iteration 18800 (48.1706 iter/s, 2.07596s/100 iter), loss = 0
I0701 14:58:54.567111  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:58:54.567118  1052 sgd_solver.cpp:106] Iteration 18800, lr = 0.0070625
I0701 14:58:56.638250  1052 solver.cpp:290] Iteration 18900 (48.2841 iter/s, 2.07108s/100 iter), loss = 0
I0701 14:58:56.638273  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:58:56.638278  1052 sgd_solver.cpp:106] Iteration 18900, lr = 0.00704687
I0701 14:58:58.712405  1052 solver.cpp:354] Sparsity after update:
I0701 14:58:58.713758  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 14:58:58.713766  1052 net.cpp:1851] conv1a_param_0(0.15) 
I0701 14:58:58.713773  1052 net.cpp:1851] conv1b_param_0(0.3) 
I0701 14:58:58.713775  1052 net.cpp:1851] fc10_param_0(0) 
I0701 14:58:58.713778  1052 net.cpp:1851] res2a_branch2a_param_0(0.3) 
I0701 14:58:58.713779  1052 net.cpp:1851] res2a_branch2b_param_0(0.3) 
I0701 14:58:58.713781  1052 net.cpp:1851] res3a_branch2a_param_0(0.3) 
I0701 14:58:58.713783  1052 net.cpp:1851] res3a_branch2b_param_0(0.3) 
I0701 14:58:58.713785  1052 net.cpp:1851] res4a_branch2a_param_0(0.3) 
I0701 14:58:58.713788  1052 net.cpp:1851] res4a_branch2b_param_0(0.3) 
I0701 14:58:58.713789  1052 net.cpp:1851] res5a_branch2a_param_0(0.298) 
I0701 14:58:58.713791  1052 net.cpp:1851] res5a_branch2b_param_0(0.3) 
I0701 14:58:58.713793  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (704160/2.3599e+06) 0.298
I0701 14:58:58.713886  1052 solver.cpp:473] Iteration 19000, Testing net (#0)
I0701 14:59:00.355278  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9145
I0701 14:59:00.355372  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9967
I0701 14:59:00.355379  1052 solver.cpp:546]     Test net output #2: loss = 0.2196 (* 1 = 0.2196 loss)
I0701 14:59:00.375772  1052 solver.cpp:290] Iteration 19000 (26.7566 iter/s, 3.7374s/100 iter), loss = 0
I0701 14:59:00.375789  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:59:00.375802  1052 sgd_solver.cpp:106] Iteration 19000, lr = 0.00703125
I0701 14:59:00.376437  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.32
I0701 14:59:00.497370  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 14:59:02.576351  1052 solver.cpp:290] Iteration 19100 (45.4443 iter/s, 2.2005s/100 iter), loss = 0
I0701 14:59:02.576373  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:59:02.576380  1052 sgd_solver.cpp:106] Iteration 19100, lr = 0.00701563
I0701 14:59:04.647954  1052 solver.cpp:290] Iteration 19200 (48.2738 iter/s, 2.07152s/100 iter), loss = 0
I0701 14:59:04.647976  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:59:04.647984  1052 sgd_solver.cpp:106] Iteration 19200, lr = 0.007
I0701 14:59:06.723918  1052 solver.cpp:290] Iteration 19300 (48.1723 iter/s, 2.07588s/100 iter), loss = 0
I0701 14:59:06.723942  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:59:06.723948  1052 sgd_solver.cpp:106] Iteration 19300, lr = 0.00698437
I0701 14:59:08.796815  1052 solver.cpp:290] Iteration 19400 (48.2436 iter/s, 2.07281s/100 iter), loss = 0
I0701 14:59:08.796838  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:59:08.796844  1052 sgd_solver.cpp:106] Iteration 19400, lr = 0.00696875
I0701 14:59:10.869602  1052 solver.cpp:290] Iteration 19500 (48.2462 iter/s, 2.0727s/100 iter), loss = 0
I0701 14:59:10.869626  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:59:10.869632  1052 sgd_solver.cpp:106] Iteration 19500, lr = 0.00695312
I0701 14:59:12.942423  1052 solver.cpp:290] Iteration 19600 (48.2454 iter/s, 2.07274s/100 iter), loss = 0
I0701 14:59:12.942445  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:59:12.942451  1052 sgd_solver.cpp:106] Iteration 19600, lr = 0.0069375
I0701 14:59:15.018015  1052 solver.cpp:290] Iteration 19700 (48.181 iter/s, 2.07551s/100 iter), loss = 0
I0701 14:59:15.018038  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:59:15.018044  1052 sgd_solver.cpp:106] Iteration 19700, lr = 0.00692187
I0701 14:59:17.094257  1052 solver.cpp:290] Iteration 19800 (48.1659 iter/s, 2.07616s/100 iter), loss = 0
I0701 14:59:17.094277  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:59:17.094286  1052 sgd_solver.cpp:106] Iteration 19800, lr = 0.00690625
I0701 14:59:19.167104  1052 solver.cpp:290] Iteration 19900 (48.2448 iter/s, 2.07276s/100 iter), loss = 0
I0701 14:59:19.167125  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:59:19.167131  1052 sgd_solver.cpp:106] Iteration 19900, lr = 0.00689062
I0701 14:59:21.221900  1052 solver.cpp:600] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/sparse/cifar10_jacintonet11v2_iter_20000.caffemodel
I0701 14:59:21.238241  1052 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/sparse/cifar10_jacintonet11v2_iter_20000.solverstate
I0701 14:59:21.245537  1052 solver.cpp:354] Sparsity after update:
I0701 14:59:21.246471  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 14:59:21.246479  1052 net.cpp:1851] conv1a_param_0(0.16) 
I0701 14:59:21.246486  1052 net.cpp:1851] conv1b_param_0(0.32) 
I0701 14:59:21.246490  1052 net.cpp:1851] fc10_param_0(0) 
I0701 14:59:21.246491  1052 net.cpp:1851] res2a_branch2a_param_0(0.32) 
I0701 14:59:21.246493  1052 net.cpp:1851] res2a_branch2b_param_0(0.32) 
I0701 14:59:21.246495  1052 net.cpp:1851] res3a_branch2a_param_0(0.32) 
I0701 14:59:21.246505  1052 net.cpp:1851] res3a_branch2b_param_0(0.32) 
I0701 14:59:21.246507  1052 net.cpp:1851] res4a_branch2a_param_0(0.32) 
I0701 14:59:21.246510  1052 net.cpp:1851] res4a_branch2b_param_0(0.32) 
I0701 14:59:21.246511  1052 net.cpp:1851] res5a_branch2a_param_0(0.319) 
I0701 14:59:21.246513  1052 net.cpp:1851] res5a_branch2b_param_0(0.314) 
I0701 14:59:21.246515  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (747795/2.3599e+06) 0.317
I0701 14:59:21.246610  1052 solver.cpp:473] Iteration 20000, Testing net (#0)
I0701 14:59:22.885303  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9137
I0701 14:59:22.885321  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9965
I0701 14:59:22.885326  1052 solver.cpp:546]     Test net output #2: loss = 0.2236 (* 1 = 0.2236 loss)
I0701 14:59:22.904932  1052 solver.cpp:290] Iteration 20000 (26.7544 iter/s, 3.7377s/100 iter), loss = 0
I0701 14:59:22.904952  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:59:22.904963  1052 sgd_solver.cpp:106] Iteration 20000, lr = 0.006875
I0701 14:59:22.905817  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.34
I0701 14:59:23.034603  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 14:59:25.113517  1052 solver.cpp:290] Iteration 20100 (45.2797 iter/s, 2.2085s/100 iter), loss = 0
I0701 14:59:25.113540  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:59:25.113548  1052 sgd_solver.cpp:106] Iteration 20100, lr = 0.00685938
I0701 14:59:27.186848  1052 solver.cpp:290] Iteration 20200 (48.2335 iter/s, 2.07325s/100 iter), loss = 0
I0701 14:59:27.186870  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:59:27.186877  1052 sgd_solver.cpp:106] Iteration 20200, lr = 0.00684375
I0701 14:59:29.263243  1052 solver.cpp:290] Iteration 20300 (48.1624 iter/s, 2.07631s/100 iter), loss = 0
I0701 14:59:29.263264  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:59:29.263272  1052 sgd_solver.cpp:106] Iteration 20300, lr = 0.00682813
I0701 14:59:31.337349  1052 solver.cpp:290] Iteration 20400 (48.2155 iter/s, 2.07402s/100 iter), loss = 0
I0701 14:59:31.337456  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:59:31.337467  1052 sgd_solver.cpp:106] Iteration 20400, lr = 0.0068125
I0701 14:59:33.408808  1052 solver.cpp:290] Iteration 20500 (48.279 iter/s, 2.07129s/100 iter), loss = 0
I0701 14:59:33.408829  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:59:33.408838  1052 sgd_solver.cpp:106] Iteration 20500, lr = 0.00679688
I0701 14:59:35.482383  1052 solver.cpp:290] Iteration 20600 (48.2279 iter/s, 2.07349s/100 iter), loss = 0
I0701 14:59:35.482409  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:59:35.482416  1052 sgd_solver.cpp:106] Iteration 20600, lr = 0.00678125
I0701 14:59:37.553769  1052 solver.cpp:290] Iteration 20700 (48.2789 iter/s, 2.0713s/100 iter), loss = 0
I0701 14:59:37.553791  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:59:37.553797  1052 sgd_solver.cpp:106] Iteration 20700, lr = 0.00676562
I0701 14:59:39.626327  1052 solver.cpp:290] Iteration 20800 (48.2515 iter/s, 2.07247s/100 iter), loss = 0
I0701 14:59:39.626349  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:59:39.626358  1052 sgd_solver.cpp:106] Iteration 20800, lr = 0.00675
I0701 14:59:41.699617  1052 solver.cpp:290] Iteration 20900 (48.2345 iter/s, 2.07321s/100 iter), loss = 0
I0701 14:59:41.699638  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:59:41.699645  1052 sgd_solver.cpp:106] Iteration 20900, lr = 0.00673437
I0701 14:59:43.755303  1052 solver.cpp:354] Sparsity after update:
I0701 14:59:43.756633  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 14:59:43.756639  1052 net.cpp:1851] conv1a_param_0(0.17) 
I0701 14:59:43.756646  1052 net.cpp:1851] conv1b_param_0(0.34) 
I0701 14:59:43.756649  1052 net.cpp:1851] fc10_param_0(0) 
I0701 14:59:43.756650  1052 net.cpp:1851] res2a_branch2a_param_0(0.34) 
I0701 14:59:43.756652  1052 net.cpp:1851] res2a_branch2b_param_0(0.34) 
I0701 14:59:43.756654  1052 net.cpp:1851] res3a_branch2a_param_0(0.34) 
I0701 14:59:43.756656  1052 net.cpp:1851] res3a_branch2b_param_0(0.34) 
I0701 14:59:43.756659  1052 net.cpp:1851] res4a_branch2a_param_0(0.34) 
I0701 14:59:43.756659  1052 net.cpp:1851] res4a_branch2b_param_0(0.34) 
I0701 14:59:43.756661  1052 net.cpp:1851] res5a_branch2a_param_0(0.339) 
I0701 14:59:43.756664  1052 net.cpp:1851] res5a_branch2b_param_0(0.339) 
I0701 14:59:43.756665  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (797937/2.3599e+06) 0.338
I0701 14:59:43.756757  1052 solver.cpp:473] Iteration 21000, Testing net (#0)
I0701 14:59:45.397343  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9157
I0701 14:59:45.397362  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9969
I0701 14:59:45.397368  1052 solver.cpp:546]     Test net output #2: loss = 0.2201 (* 1 = 0.2201 loss)
I0701 14:59:45.418704  1052 solver.cpp:290] Iteration 21000 (26.8892 iter/s, 3.71896s/100 iter), loss = 0
I0701 14:59:45.418725  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:59:45.418732  1052 sgd_solver.cpp:106] Iteration 21000, lr = 0.00671875
I0701 14:59:45.419602  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.36
I0701 14:59:45.562152  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 14:59:47.637367  1052 solver.cpp:290] Iteration 21100 (45.074 iter/s, 2.21858s/100 iter), loss = 0
I0701 14:59:47.637387  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:59:47.637393  1052 sgd_solver.cpp:106] Iteration 21100, lr = 0.00670313
I0701 14:59:49.707245  1052 solver.cpp:290] Iteration 21200 (48.3139 iter/s, 2.0698s/100 iter), loss = 0
I0701 14:59:49.707267  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:59:49.707273  1052 sgd_solver.cpp:106] Iteration 21200, lr = 0.0066875
I0701 14:59:51.781184  1052 solver.cpp:290] Iteration 21300 (48.2194 iter/s, 2.07385s/100 iter), loss = 0
I0701 14:59:51.781205  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:59:51.781230  1052 sgd_solver.cpp:106] Iteration 21300, lr = 0.00667187
I0701 14:59:53.852942  1052 solver.cpp:290] Iteration 21400 (48.2701 iter/s, 2.07167s/100 iter), loss = 0
I0701 14:59:53.852967  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:59:53.852975  1052 sgd_solver.cpp:106] Iteration 21400, lr = 0.00665625
I0701 14:59:55.925015  1052 solver.cpp:290] Iteration 21500 (48.2629 iter/s, 2.07199s/100 iter), loss = 0
I0701 14:59:55.925038  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:59:55.925047  1052 sgd_solver.cpp:106] Iteration 21500, lr = 0.00664062
I0701 14:59:58.001672  1052 solver.cpp:290] Iteration 21600 (48.1563 iter/s, 2.07657s/100 iter), loss = 0
I0701 14:59:58.001694  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 14:59:58.001700  1052 sgd_solver.cpp:106] Iteration 21600, lr = 0.006625
I0701 15:00:00.070660  1052 solver.cpp:290] Iteration 21700 (48.3348 iter/s, 2.0689s/100 iter), loss = 0
I0701 15:00:00.070683  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:00:00.070689  1052 sgd_solver.cpp:106] Iteration 21700, lr = 0.00660937
I0701 15:00:02.143307  1052 solver.cpp:290] Iteration 21800 (48.2494 iter/s, 2.07256s/100 iter), loss = 0
I0701 15:00:02.143383  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:00:02.143390  1052 sgd_solver.cpp:106] Iteration 21800, lr = 0.00659375
I0701 15:00:04.218446  1052 solver.cpp:290] Iteration 21900 (48.1927 iter/s, 2.075s/100 iter), loss = 0
I0701 15:00:04.218466  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:00:04.218472  1052 sgd_solver.cpp:106] Iteration 21900, lr = 0.00657812
I0701 15:00:06.274930  1052 solver.cpp:354] Sparsity after update:
I0701 15:00:06.276278  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:00:06.276285  1052 net.cpp:1851] conv1a_param_0(0.18) 
I0701 15:00:06.276293  1052 net.cpp:1851] conv1b_param_0(0.36) 
I0701 15:00:06.276295  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:00:06.276298  1052 net.cpp:1851] res2a_branch2a_param_0(0.36) 
I0701 15:00:06.276299  1052 net.cpp:1851] res2a_branch2b_param_0(0.36) 
I0701 15:00:06.276302  1052 net.cpp:1851] res3a_branch2a_param_0(0.36) 
I0701 15:00:06.276304  1052 net.cpp:1851] res3a_branch2b_param_0(0.36) 
I0701 15:00:06.276306  1052 net.cpp:1851] res4a_branch2a_param_0(0.36) 
I0701 15:00:06.276309  1052 net.cpp:1851] res4a_branch2b_param_0(0.36) 
I0701 15:00:06.276310  1052 net.cpp:1851] res5a_branch2a_param_0(0.358) 
I0701 15:00:06.276312  1052 net.cpp:1851] res5a_branch2b_param_0(0.356) 
I0701 15:00:06.276321  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (842397/2.3599e+06) 0.357
I0701 15:00:06.276407  1052 solver.cpp:473] Iteration 22000, Testing net (#0)
I0701 15:00:07.915347  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9132
I0701 15:00:07.915366  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9965
I0701 15:00:07.915371  1052 solver.cpp:546]     Test net output #2: loss = 0.2287 (* 1 = 0.2287 loss)
I0701 15:00:07.934985  1052 solver.cpp:290] Iteration 22000 (26.9076 iter/s, 3.71642s/100 iter), loss = 0
I0701 15:00:07.935001  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:00:07.935016  1052 sgd_solver.cpp:106] Iteration 22000, lr = 0.0065625
I0701 15:00:07.935637  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.38
I0701 15:00:08.096724  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 15:00:10.171809  1052 solver.cpp:290] Iteration 22100 (44.708 iter/s, 2.23674s/100 iter), loss = 0
I0701 15:00:10.171842  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:00:10.171854  1052 sgd_solver.cpp:106] Iteration 22100, lr = 0.00654687
I0701 15:00:12.242908  1052 solver.cpp:290] Iteration 22200 (48.2857 iter/s, 2.07101s/100 iter), loss = 0
I0701 15:00:12.242929  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:00:12.242935  1052 sgd_solver.cpp:106] Iteration 22200, lr = 0.00653125
I0701 15:00:14.314033  1052 solver.cpp:290] Iteration 22300 (48.2849 iter/s, 2.07104s/100 iter), loss = 0
I0701 15:00:14.314054  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:00:14.314062  1052 sgd_solver.cpp:106] Iteration 22300, lr = 0.00651562
I0701 15:00:16.388934  1052 solver.cpp:290] Iteration 22400 (48.1971 iter/s, 2.07481s/100 iter), loss = 0
I0701 15:00:16.388957  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:00:16.388964  1052 sgd_solver.cpp:106] Iteration 22400, lr = 0.0065
I0701 15:00:18.463380  1052 solver.cpp:290] Iteration 22500 (48.2076 iter/s, 2.07436s/100 iter), loss = 0
I0701 15:00:18.463400  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:00:18.463409  1052 sgd_solver.cpp:106] Iteration 22500, lr = 0.00648437
I0701 15:00:20.539101  1052 solver.cpp:290] Iteration 22600 (48.1779 iter/s, 2.07564s/100 iter), loss = 0
I0701 15:00:20.539122  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:00:20.539129  1052 sgd_solver.cpp:106] Iteration 22600, lr = 0.00646875
I0701 15:00:22.610502  1052 solver.cpp:290] Iteration 22700 (48.2785 iter/s, 2.07132s/100 iter), loss = 0
I0701 15:00:22.610525  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:00:22.610543  1052 sgd_solver.cpp:106] Iteration 22700, lr = 0.00645312
I0701 15:00:24.693601  1052 solver.cpp:290] Iteration 22800 (48.0074 iter/s, 2.08301s/100 iter), loss = 0
I0701 15:00:24.693624  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:00:24.693632  1052 sgd_solver.cpp:106] Iteration 22800, lr = 0.0064375
I0701 15:00:26.768054  1052 solver.cpp:290] Iteration 22900 (48.2075 iter/s, 2.07437s/100 iter), loss = 0
I0701 15:00:26.768075  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:00:26.768081  1052 sgd_solver.cpp:106] Iteration 22900, lr = 0.00642187
I0701 15:00:28.820425  1052 solver.cpp:354] Sparsity after update:
I0701 15:00:28.821770  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:00:28.821777  1052 net.cpp:1851] conv1a_param_0(0.19) 
I0701 15:00:28.821786  1052 net.cpp:1851] conv1b_param_0(0.38) 
I0701 15:00:28.821791  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:00:28.821795  1052 net.cpp:1851] res2a_branch2a_param_0(0.38) 
I0701 15:00:28.821799  1052 net.cpp:1851] res2a_branch2b_param_0(0.38) 
I0701 15:00:28.821804  1052 net.cpp:1851] res3a_branch2a_param_0(0.38) 
I0701 15:00:28.821807  1052 net.cpp:1851] res3a_branch2b_param_0(0.38) 
I0701 15:00:28.821811  1052 net.cpp:1851] res4a_branch2a_param_0(0.38) 
I0701 15:00:28.821815  1052 net.cpp:1851] res4a_branch2b_param_0(0.38) 
I0701 15:00:28.821820  1052 net.cpp:1851] res5a_branch2a_param_0(0.38) 
I0701 15:00:28.821823  1052 net.cpp:1851] res5a_branch2b_param_0(0.378) 
I0701 15:00:28.821826  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (893071/2.3599e+06) 0.378
I0701 15:00:28.821961  1052 solver.cpp:473] Iteration 23000, Testing net (#0)
I0701 15:00:30.461130  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9147
I0701 15:00:30.461148  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9966
I0701 15:00:30.461153  1052 solver.cpp:546]     Test net output #2: loss = 0.2244 (* 1 = 0.2244 loss)
I0701 15:00:30.480662  1052 solver.cpp:290] Iteration 23000 (26.9361 iter/s, 3.71248s/100 iter), loss = 0
I0701 15:00:30.480677  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:00:30.480692  1052 sgd_solver.cpp:106] Iteration 23000, lr = 0.00640625
I0701 15:00:30.481314  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.4
I0701 15:00:30.644665  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 15:00:32.719564  1052 solver.cpp:290] Iteration 23100 (44.6664 iter/s, 2.23882s/100 iter), loss = 0
I0701 15:00:32.719648  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:00:32.719660  1052 sgd_solver.cpp:106] Iteration 23100, lr = 0.00639063
I0701 15:00:34.798630  1052 solver.cpp:290] Iteration 23200 (48.1019 iter/s, 2.07892s/100 iter), loss = 0
I0701 15:00:34.798652  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:00:34.798660  1052 sgd_solver.cpp:106] Iteration 23200, lr = 0.006375
I0701 15:00:36.871207  1052 solver.cpp:290] Iteration 23300 (48.2511 iter/s, 2.07249s/100 iter), loss = 0
I0701 15:00:36.871229  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:00:36.871237  1052 sgd_solver.cpp:106] Iteration 23300, lr = 0.00635938
I0701 15:00:38.943619  1052 solver.cpp:290] Iteration 23400 (48.255 iter/s, 2.07233s/100 iter), loss = 0
I0701 15:00:38.943641  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:00:38.943648  1052 sgd_solver.cpp:106] Iteration 23400, lr = 0.00634375
I0701 15:00:41.014850  1052 solver.cpp:290] Iteration 23500 (48.2824 iter/s, 2.07115s/100 iter), loss = 0
I0701 15:00:41.014871  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:00:41.014878  1052 sgd_solver.cpp:106] Iteration 23500, lr = 0.00632813
I0701 15:00:43.088798  1052 solver.cpp:290] Iteration 23600 (48.2192 iter/s, 2.07386s/100 iter), loss = 0
I0701 15:00:43.088819  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:00:43.088827  1052 sgd_solver.cpp:106] Iteration 23600, lr = 0.0063125
I0701 15:00:45.167387  1052 solver.cpp:290] Iteration 23700 (48.1115 iter/s, 2.0785s/100 iter), loss = 0
I0701 15:00:45.167412  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:00:45.167419  1052 sgd_solver.cpp:106] Iteration 23700, lr = 0.00629687
I0701 15:00:47.242435  1052 solver.cpp:290] Iteration 23800 (48.1937 iter/s, 2.07496s/100 iter), loss = 0
I0701 15:00:47.242458  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:00:47.242465  1052 sgd_solver.cpp:106] Iteration 23800, lr = 0.00628125
I0701 15:00:49.315639  1052 solver.cpp:290] Iteration 23900 (48.2365 iter/s, 2.07312s/100 iter), loss = 0
I0701 15:00:49.315661  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:00:49.315668  1052 sgd_solver.cpp:106] Iteration 23900, lr = 0.00626562
I0701 15:00:51.369246  1052 solver.cpp:354] Sparsity after update:
I0701 15:00:51.370576  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:00:51.370584  1052 net.cpp:1851] conv1a_param_0(0.2) 
I0701 15:00:51.370589  1052 net.cpp:1851] conv1b_param_0(0.4) 
I0701 15:00:51.370592  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:00:51.370594  1052 net.cpp:1851] res2a_branch2a_param_0(0.4) 
I0701 15:00:51.370596  1052 net.cpp:1851] res2a_branch2b_param_0(0.4) 
I0701 15:00:51.370599  1052 net.cpp:1851] res3a_branch2a_param_0(0.4) 
I0701 15:00:51.370600  1052 net.cpp:1851] res3a_branch2b_param_0(0.4) 
I0701 15:00:51.370601  1052 net.cpp:1851] res4a_branch2a_param_0(0.4) 
I0701 15:00:51.370604  1052 net.cpp:1851] res4a_branch2b_param_0(0.4) 
I0701 15:00:51.370605  1052 net.cpp:1851] res5a_branch2a_param_0(0.399) 
I0701 15:00:51.370607  1052 net.cpp:1851] res5a_branch2b_param_0(0.4) 
I0701 15:00:51.370609  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (940680/2.3599e+06) 0.399
I0701 15:00:51.370692  1052 solver.cpp:473] Iteration 24000, Testing net (#0)
I0701 15:00:53.011499  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9132
I0701 15:00:53.011521  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9965
I0701 15:00:53.011526  1052 solver.cpp:546]     Test net output #2: loss = 0.2272 (* 1 = 0.2272 loss)
I0701 15:00:53.031148  1052 solver.cpp:290] Iteration 24000 (26.9151 iter/s, 3.71538s/100 iter), loss = 0
I0701 15:00:53.031167  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:00:53.031177  1052 sgd_solver.cpp:106] Iteration 24000, lr = 0.00625
I0701 15:00:53.031738  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.42
I0701 15:00:53.204202  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 15:00:55.279357  1052 solver.cpp:290] Iteration 24100 (44.4815 iter/s, 2.24812s/100 iter), loss = 0
I0701 15:00:55.279378  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:00:55.279386  1052 sgd_solver.cpp:106] Iteration 24100, lr = 0.00623438
I0701 15:00:57.363240  1052 solver.cpp:290] Iteration 24200 (47.9893 iter/s, 2.0838s/100 iter), loss = 0
I0701 15:00:57.363266  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:00:57.363276  1052 sgd_solver.cpp:106] Iteration 24200, lr = 0.00621875
I0701 15:00:59.437857  1052 solver.cpp:290] Iteration 24300 (48.2037 iter/s, 2.07453s/100 iter), loss = 0
I0701 15:00:59.437878  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:00:59.437885  1052 sgd_solver.cpp:106] Iteration 24300, lr = 0.00620312
I0701 15:01:01.510535  1052 solver.cpp:290] Iteration 24400 (48.2487 iter/s, 2.07259s/100 iter), loss = 0
I0701 15:01:01.510568  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:01:01.510579  1052 sgd_solver.cpp:106] Iteration 24400, lr = 0.0061875
I0701 15:01:03.583057  1052 solver.cpp:290] Iteration 24500 (48.2526 iter/s, 2.07243s/100 iter), loss = 0
I0701 15:01:03.583142  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:01:03.583151  1052 sgd_solver.cpp:106] Iteration 24500, lr = 0.00617187
I0701 15:01:05.655800  1052 solver.cpp:290] Iteration 24600 (48.2487 iter/s, 2.0726s/100 iter), loss = 0
I0701 15:01:05.655827  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:01:05.655835  1052 sgd_solver.cpp:106] Iteration 24600, lr = 0.00615625
I0701 15:01:07.726470  1052 solver.cpp:290] Iteration 24700 (48.2956 iter/s, 2.07058s/100 iter), loss = 0
I0701 15:01:07.726490  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:01:07.726500  1052 sgd_solver.cpp:106] Iteration 24700, lr = 0.00614062
I0701 15:01:09.797238  1052 solver.cpp:290] Iteration 24800 (48.2932 iter/s, 2.07069s/100 iter), loss = 0
I0701 15:01:09.797260  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:01:09.797266  1052 sgd_solver.cpp:106] Iteration 24800, lr = 0.006125
I0701 15:01:11.870394  1052 solver.cpp:290] Iteration 24900 (48.2376 iter/s, 2.07307s/100 iter), loss = 0
I0701 15:01:11.870416  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:01:11.870424  1052 sgd_solver.cpp:106] Iteration 24900, lr = 0.00610937
I0701 15:01:13.927269  1052 solver.cpp:354] Sparsity after update:
I0701 15:01:13.928617  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:01:13.928624  1052 net.cpp:1851] conv1a_param_0(0.21) 
I0701 15:01:13.928630  1052 net.cpp:1851] conv1b_param_0(0.42) 
I0701 15:01:13.928632  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:01:13.928634  1052 net.cpp:1851] res2a_branch2a_param_0(0.42) 
I0701 15:01:13.928637  1052 net.cpp:1851] res2a_branch2b_param_0(0.42) 
I0701 15:01:13.928638  1052 net.cpp:1851] res3a_branch2a_param_0(0.42) 
I0701 15:01:13.928640  1052 net.cpp:1851] res3a_branch2b_param_0(0.42) 
I0701 15:01:13.928642  1052 net.cpp:1851] res4a_branch2a_param_0(0.42) 
I0701 15:01:13.928644  1052 net.cpp:1851] res4a_branch2b_param_0(0.42) 
I0701 15:01:13.928647  1052 net.cpp:1851] res5a_branch2a_param_0(0.42) 
I0701 15:01:13.928647  1052 net.cpp:1851] res5a_branch2b_param_0(0.419) 
I0701 15:01:13.928649  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (987746/2.3599e+06) 0.419
I0701 15:01:13.928733  1052 solver.cpp:473] Iteration 25000, Testing net (#0)
I0701 15:01:15.568512  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9137
I0701 15:01:15.568531  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9961
I0701 15:01:15.568536  1052 solver.cpp:546]     Test net output #2: loss = 0.23 (* 1 = 0.23 loss)
I0701 15:01:15.588017  1052 solver.cpp:290] Iteration 25000 (26.8998 iter/s, 3.7175s/100 iter), loss = 0
I0701 15:01:15.588032  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:01:15.588047  1052 sgd_solver.cpp:106] Iteration 25000, lr = 0.00609375
I0701 15:01:15.588685  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.44
I0701 15:01:15.780843  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 15:01:17.856815  1052 solver.cpp:290] Iteration 25100 (44.0778 iter/s, 2.26872s/100 iter), loss = 0
I0701 15:01:17.856835  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:01:17.856842  1052 sgd_solver.cpp:106] Iteration 25100, lr = 0.00607812
I0701 15:01:19.932325  1052 solver.cpp:290] Iteration 25200 (48.1828 iter/s, 2.07543s/100 iter), loss = 0
I0701 15:01:19.932345  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:01:19.932353  1052 sgd_solver.cpp:106] Iteration 25200, lr = 0.0060625
I0701 15:01:22.004211  1052 solver.cpp:290] Iteration 25300 (48.2672 iter/s, 2.0718s/100 iter), loss = 0
I0701 15:01:22.004232  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:01:22.004241  1052 sgd_solver.cpp:106] Iteration 25300, lr = 0.00604687
I0701 15:01:24.083503  1052 solver.cpp:290] Iteration 25400 (48.0952 iter/s, 2.07921s/100 iter), loss = 0
I0701 15:01:24.083524  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:01:24.083545  1052 sgd_solver.cpp:106] Iteration 25400, lr = 0.00603125
I0701 15:01:26.155772  1052 solver.cpp:290] Iteration 25500 (48.2582 iter/s, 2.07219s/100 iter), loss = 0
I0701 15:01:26.155793  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:01:26.155802  1052 sgd_solver.cpp:106] Iteration 25500, lr = 0.00601562
I0701 15:01:28.229516  1052 solver.cpp:290] Iteration 25600 (48.2239 iter/s, 2.07366s/100 iter), loss = 0
I0701 15:01:28.229542  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:01:28.229549  1052 sgd_solver.cpp:106] Iteration 25600, lr = 0.006
I0701 15:01:30.305711  1052 solver.cpp:290] Iteration 25700 (48.167 iter/s, 2.07611s/100 iter), loss = 0
I0701 15:01:30.305732  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:01:30.305740  1052 sgd_solver.cpp:106] Iteration 25700, lr = 0.00598437
I0701 15:01:32.376921  1052 solver.cpp:290] Iteration 25800 (48.2829 iter/s, 2.07113s/100 iter), loss = 0
I0701 15:01:32.376943  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:01:32.376950  1052 sgd_solver.cpp:106] Iteration 25800, lr = 0.00596875
I0701 15:01:34.451064  1052 solver.cpp:290] Iteration 25900 (48.2147 iter/s, 2.07405s/100 iter), loss = 0
I0701 15:01:34.451136  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:01:34.451148  1052 sgd_solver.cpp:106] Iteration 25900, lr = 0.00595312
I0701 15:01:36.507050  1052 solver.cpp:354] Sparsity after update:
I0701 15:01:36.508404  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:01:36.508410  1052 net.cpp:1851] conv1a_param_0(0.22) 
I0701 15:01:36.508417  1052 net.cpp:1851] conv1b_param_0(0.44) 
I0701 15:01:36.508419  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:01:36.508421  1052 net.cpp:1851] res2a_branch2a_param_0(0.44) 
I0701 15:01:36.508424  1052 net.cpp:1851] res2a_branch2b_param_0(0.44) 
I0701 15:01:36.508425  1052 net.cpp:1851] res3a_branch2a_param_0(0.44) 
I0701 15:01:36.508427  1052 net.cpp:1851] res3a_branch2b_param_0(0.44) 
I0701 15:01:36.508429  1052 net.cpp:1851] res4a_branch2a_param_0(0.44) 
I0701 15:01:36.508430  1052 net.cpp:1851] res4a_branch2b_param_0(0.44) 
I0701 15:01:36.508432  1052 net.cpp:1851] res5a_branch2a_param_0(0.439) 
I0701 15:01:36.508435  1052 net.cpp:1851] res5a_branch2b_param_0(0.438) 
I0701 15:01:36.508436  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.03318e+06/2.3599e+06) 0.438
I0701 15:01:36.508520  1052 solver.cpp:473] Iteration 26000, Testing net (#0)
I0701 15:01:38.152555  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9123
I0701 15:01:38.152575  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9965
I0701 15:01:38.152580  1052 solver.cpp:546]     Test net output #2: loss = 0.2308 (* 1 = 0.2308 loss)
I0701 15:01:38.172178  1052 solver.cpp:290] Iteration 26000 (26.8749 iter/s, 3.72094s/100 iter), loss = 0
I0701 15:01:38.172195  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:01:38.172209  1052 sgd_solver.cpp:106] Iteration 26000, lr = 0.0059375
I0701 15:01:38.172833  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.46
I0701 15:01:38.358887  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 15:01:40.432869  1052 solver.cpp:290] Iteration 26100 (44.2359 iter/s, 2.26061s/100 iter), loss = 0
I0701 15:01:40.432893  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:01:40.432898  1052 sgd_solver.cpp:106] Iteration 26100, lr = 0.00592188
I0701 15:01:42.506875  1052 solver.cpp:290] Iteration 26200 (48.2178 iter/s, 2.07392s/100 iter), loss = 0
I0701 15:01:42.506896  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:01:42.506903  1052 sgd_solver.cpp:106] Iteration 26200, lr = 0.00590625
I0701 15:01:44.578145  1052 solver.cpp:290] Iteration 26300 (48.2815 iter/s, 2.07119s/100 iter), loss = 0
I0701 15:01:44.578166  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:01:44.578173  1052 sgd_solver.cpp:106] Iteration 26300, lr = 0.00589063
I0701 15:01:46.660135  1052 solver.cpp:290] Iteration 26400 (48.0329 iter/s, 2.08191s/100 iter), loss = 0
I0701 15:01:46.660156  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:01:46.660164  1052 sgd_solver.cpp:106] Iteration 26400, lr = 0.005875
I0701 15:01:48.732866  1052 solver.cpp:290] Iteration 26500 (48.2474 iter/s, 2.07265s/100 iter), loss = 0
I0701 15:01:48.732887  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:01:48.732893  1052 sgd_solver.cpp:106] Iteration 26500, lr = 0.00585938
I0701 15:01:50.806586  1052 solver.cpp:290] Iteration 26600 (48.2244 iter/s, 2.07364s/100 iter), loss = 0
I0701 15:01:50.806608  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:01:50.806615  1052 sgd_solver.cpp:106] Iteration 26600, lr = 0.00584375
I0701 15:01:52.878772  1052 solver.cpp:290] Iteration 26700 (48.2602 iter/s, 2.0721s/100 iter), loss = 0
I0701 15:01:52.878794  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:01:52.878800  1052 sgd_solver.cpp:106] Iteration 26700, lr = 0.00582812
I0701 15:01:54.950995  1052 solver.cpp:290] Iteration 26800 (48.2593 iter/s, 2.07214s/100 iter), loss = 0
I0701 15:01:54.951030  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:01:54.951036  1052 sgd_solver.cpp:106] Iteration 26800, lr = 0.0058125
I0701 15:01:57.053745  1052 solver.cpp:290] Iteration 26900 (47.559 iter/s, 2.10265s/100 iter), loss = 0
I0701 15:01:57.053771  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:01:57.053777  1052 sgd_solver.cpp:106] Iteration 26900, lr = 0.00579687
I0701 15:01:59.105934  1052 solver.cpp:354] Sparsity after update:
I0701 15:01:59.107302  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:01:59.107311  1052 net.cpp:1851] conv1a_param_0(0.23) 
I0701 15:01:59.107319  1052 net.cpp:1851] conv1b_param_0(0.46) 
I0701 15:01:59.107324  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:01:59.107329  1052 net.cpp:1851] res2a_branch2a_param_0(0.46) 
I0701 15:01:59.107333  1052 net.cpp:1851] res2a_branch2b_param_0(0.46) 
I0701 15:01:59.107337  1052 net.cpp:1851] res3a_branch2a_param_0(0.46) 
I0701 15:01:59.107342  1052 net.cpp:1851] res3a_branch2b_param_0(0.46) 
I0701 15:01:59.107345  1052 net.cpp:1851] res4a_branch2a_param_0(0.46) 
I0701 15:01:59.107349  1052 net.cpp:1851] res4a_branch2b_param_0(0.46) 
I0701 15:01:59.107354  1052 net.cpp:1851] res5a_branch2a_param_0(0.459) 
I0701 15:01:59.107358  1052 net.cpp:1851] res5a_branch2b_param_0(0.459) 
I0701 15:01:59.107362  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.08165e+06/2.3599e+06) 0.458
I0701 15:01:59.107455  1052 solver.cpp:473] Iteration 27000, Testing net (#0)
I0701 15:02:00.751395  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9116
I0701 15:02:00.751415  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9965
I0701 15:02:00.751421  1052 solver.cpp:546]     Test net output #2: loss = 0.2377 (* 1 = 0.2377 loss)
I0701 15:02:00.771739  1052 solver.cpp:290] Iteration 27000 (26.8971 iter/s, 3.71787s/100 iter), loss = 0
I0701 15:02:00.771759  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:02:00.771770  1052 sgd_solver.cpp:106] Iteration 27000, lr = 0.00578125
I0701 15:02:00.772419  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.48
I0701 15:02:00.983639  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 15:02:03.055547  1052 solver.cpp:290] Iteration 27100 (43.7882 iter/s, 2.28372s/100 iter), loss = 0
I0701 15:02:03.055570  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:02:03.055578  1052 sgd_solver.cpp:106] Iteration 27100, lr = 0.00576563
I0701 15:02:05.134080  1052 solver.cpp:290] Iteration 27200 (48.1128 iter/s, 2.07845s/100 iter), loss = 0
I0701 15:02:05.134155  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:02:05.134171  1052 sgd_solver.cpp:106] Iteration 27200, lr = 0.00575
I0701 15:02:07.206980  1052 solver.cpp:290] Iteration 27300 (48.2447 iter/s, 2.07277s/100 iter), loss = 0
I0701 15:02:07.207003  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:02:07.207010  1052 sgd_solver.cpp:106] Iteration 27300, lr = 0.00573438
I0701 15:02:09.277055  1052 solver.cpp:290] Iteration 27400 (48.3094 iter/s, 2.06999s/100 iter), loss = 0
I0701 15:02:09.277077  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:02:09.277086  1052 sgd_solver.cpp:106] Iteration 27400, lr = 0.00571875
I0701 15:02:11.349582  1052 solver.cpp:290] Iteration 27500 (48.2522 iter/s, 2.07244s/100 iter), loss = 0
I0701 15:02:11.349604  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:02:11.349611  1052 sgd_solver.cpp:106] Iteration 27500, lr = 0.00570312
I0701 15:02:13.421475  1052 solver.cpp:290] Iteration 27600 (48.267 iter/s, 2.07181s/100 iter), loss = 0
I0701 15:02:13.421499  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:02:13.421504  1052 sgd_solver.cpp:106] Iteration 27600, lr = 0.0056875
I0701 15:02:15.499193  1052 solver.cpp:290] Iteration 27700 (48.1318 iter/s, 2.07763s/100 iter), loss = 0
I0701 15:02:15.499224  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:02:15.499233  1052 sgd_solver.cpp:106] Iteration 27700, lr = 0.00567187
I0701 15:02:17.572474  1052 solver.cpp:290] Iteration 27800 (48.2348 iter/s, 2.07319s/100 iter), loss = 0
I0701 15:02:17.572495  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:02:17.572504  1052 sgd_solver.cpp:106] Iteration 27800, lr = 0.00565625
I0701 15:02:19.645678  1052 solver.cpp:290] Iteration 27900 (48.2365 iter/s, 2.07312s/100 iter), loss = 0
I0701 15:02:19.645700  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:02:19.645707  1052 sgd_solver.cpp:106] Iteration 27900, lr = 0.00564062
I0701 15:02:21.722249  1052 solver.cpp:354] Sparsity after update:
I0701 15:02:21.723440  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:02:21.723448  1052 net.cpp:1851] conv1a_param_0(0.24) 
I0701 15:02:21.723454  1052 net.cpp:1851] conv1b_param_0(0.48) 
I0701 15:02:21.723456  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:02:21.723459  1052 net.cpp:1851] res2a_branch2a_param_0(0.48) 
I0701 15:02:21.723461  1052 net.cpp:1851] res2a_branch2b_param_0(0.48) 
I0701 15:02:21.723462  1052 net.cpp:1851] res3a_branch2a_param_0(0.48) 
I0701 15:02:21.723464  1052 net.cpp:1851] res3a_branch2b_param_0(0.48) 
I0701 15:02:21.723466  1052 net.cpp:1851] res4a_branch2a_param_0(0.48) 
I0701 15:02:21.723469  1052 net.cpp:1851] res4a_branch2b_param_0(0.48) 
I0701 15:02:21.723470  1052 net.cpp:1851] res5a_branch2a_param_0(0.48) 
I0701 15:02:21.723472  1052 net.cpp:1851] res5a_branch2b_param_0(0.479) 
I0701 15:02:21.723474  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.12924e+06/2.3599e+06) 0.479
I0701 15:02:21.723561  1052 solver.cpp:473] Iteration 28000, Testing net (#0)
I0701 15:02:23.366746  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9128
I0701 15:02:23.366765  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9967
I0701 15:02:23.366771  1052 solver.cpp:546]     Test net output #2: loss = 0.2428 (* 1 = 0.2428 loss)
I0701 15:02:23.386467  1052 solver.cpp:290] Iteration 28000 (26.7332 iter/s, 3.74066s/100 iter), loss = 0
I0701 15:02:23.386485  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:02:23.386494  1052 sgd_solver.cpp:106] Iteration 28000, lr = 0.005625
I0701 15:02:23.387351  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.5
I0701 15:02:23.605900  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 15:02:25.687819  1052 solver.cpp:290] Iteration 28100 (43.4543 iter/s, 2.30127s/100 iter), loss = 0
I0701 15:02:25.687855  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:02:25.687860  1052 sgd_solver.cpp:106] Iteration 28100, lr = 0.00560937
I0701 15:02:27.762563  1052 solver.cpp:290] Iteration 28200 (48.201 iter/s, 2.07465s/100 iter), loss = 0
I0701 15:02:27.762585  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:02:27.762591  1052 sgd_solver.cpp:106] Iteration 28200, lr = 0.00559375
I0701 15:02:29.840180  1052 solver.cpp:290] Iteration 28300 (48.134 iter/s, 2.07753s/100 iter), loss = 0
I0701 15:02:29.840203  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:02:29.840209  1052 sgd_solver.cpp:106] Iteration 28300, lr = 0.00557812
I0701 15:02:31.912221  1052 solver.cpp:290] Iteration 28400 (48.2635 iter/s, 2.07196s/100 iter), loss = 0
I0701 15:02:31.912243  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:02:31.912251  1052 sgd_solver.cpp:106] Iteration 28400, lr = 0.0055625
I0701 15:02:33.988281  1052 solver.cpp:290] Iteration 28500 (48.1702 iter/s, 2.07597s/100 iter), loss = 0
I0701 15:02:33.988302  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:02:33.988309  1052 sgd_solver.cpp:106] Iteration 28500, lr = 0.00554687
I0701 15:02:36.058120  1052 solver.cpp:290] Iteration 28600 (48.3149 iter/s, 2.06976s/100 iter), loss = 0
I0701 15:02:36.058182  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:02:36.058190  1052 sgd_solver.cpp:106] Iteration 28600, lr = 0.00553125
I0701 15:02:38.129964  1052 solver.cpp:290] Iteration 28700 (48.269 iter/s, 2.07172s/100 iter), loss = 0
I0701 15:02:38.129986  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:02:38.129992  1052 sgd_solver.cpp:106] Iteration 28700, lr = 0.00551562
I0701 15:02:40.208613  1052 solver.cpp:290] Iteration 28800 (48.1101 iter/s, 2.07857s/100 iter), loss = 0
I0701 15:02:40.208636  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:02:40.208642  1052 sgd_solver.cpp:106] Iteration 28800, lr = 0.0055
I0701 15:02:42.282272  1052 solver.cpp:290] Iteration 28900 (48.2259 iter/s, 2.07357s/100 iter), loss = 0
I0701 15:02:42.282294  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:02:42.282300  1052 sgd_solver.cpp:106] Iteration 28900, lr = 0.00548437
I0701 15:02:44.334488  1052 solver.cpp:354] Sparsity after update:
I0701 15:02:44.335827  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:02:44.335834  1052 net.cpp:1851] conv1a_param_0(0.25) 
I0701 15:02:44.335841  1052 net.cpp:1851] conv1b_param_0(0.5) 
I0701 15:02:44.335844  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:02:44.335845  1052 net.cpp:1851] res2a_branch2a_param_0(0.5) 
I0701 15:02:44.335847  1052 net.cpp:1851] res2a_branch2b_param_0(0.5) 
I0701 15:02:44.335850  1052 net.cpp:1851] res3a_branch2a_param_0(0.5) 
I0701 15:02:44.335851  1052 net.cpp:1851] res3a_branch2b_param_0(0.5) 
I0701 15:02:44.335853  1052 net.cpp:1851] res4a_branch2a_param_0(0.5) 
I0701 15:02:44.335855  1052 net.cpp:1851] res4a_branch2b_param_0(0.5) 
I0701 15:02:44.335856  1052 net.cpp:1851] res5a_branch2a_param_0(0.5) 
I0701 15:02:44.335858  1052 net.cpp:1851] res5a_branch2b_param_0(0.499) 
I0701 15:02:44.335860  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.17607e+06/2.3599e+06) 0.498
I0701 15:02:44.335950  1052 solver.cpp:473] Iteration 29000, Testing net (#0)
I0701 15:02:45.976649  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9115
I0701 15:02:45.976668  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9959
I0701 15:02:45.976673  1052 solver.cpp:546]     Test net output #2: loss = 0.2426 (* 1 = 0.2426 loss)
I0701 15:02:45.998435  1052 solver.cpp:290] Iteration 29000 (26.9104 iter/s, 3.71603s/100 iter), loss = 0
I0701 15:02:45.998458  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:02:45.998466  1052 sgd_solver.cpp:106] Iteration 29000, lr = 0.00546875
I0701 15:02:45.999063  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.52
I0701 15:02:46.232348  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 15:02:48.314609  1052 solver.cpp:290] Iteration 29100 (43.1764 iter/s, 2.31608s/100 iter), loss = 0
I0701 15:02:48.314630  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:02:48.314636  1052 sgd_solver.cpp:106] Iteration 29100, lr = 0.00545313
I0701 15:02:50.389338  1052 solver.cpp:290] Iteration 29200 (48.201 iter/s, 2.07464s/100 iter), loss = 0
I0701 15:02:50.389358  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:02:50.389364  1052 sgd_solver.cpp:106] Iteration 29200, lr = 0.0054375
I0701 15:02:52.461716  1052 solver.cpp:290] Iteration 29300 (48.2557 iter/s, 2.0723s/100 iter), loss = 0
I0701 15:02:52.461748  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:02:52.461760  1052 sgd_solver.cpp:106] Iteration 29300, lr = 0.00542188
I0701 15:02:54.533905  1052 solver.cpp:290] Iteration 29400 (48.2603 iter/s, 2.07209s/100 iter), loss = 0
I0701 15:02:54.533941  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:02:54.533952  1052 sgd_solver.cpp:106] Iteration 29400, lr = 0.00540625
I0701 15:02:56.606051  1052 solver.cpp:290] Iteration 29500 (48.2614 iter/s, 2.07205s/100 iter), loss = 0
I0701 15:02:56.606072  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:02:56.606096  1052 sgd_solver.cpp:106] Iteration 29500, lr = 0.00539062
I0701 15:02:58.696468  1052 solver.cpp:290] Iteration 29600 (47.8393 iter/s, 2.09033s/100 iter), loss = 0
I0701 15:02:58.696488  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:02:58.696494  1052 sgd_solver.cpp:106] Iteration 29600, lr = 0.005375
I0701 15:03:00.771268  1052 solver.cpp:290] Iteration 29700 (48.1993 iter/s, 2.07472s/100 iter), loss = 0
I0701 15:03:00.771291  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:03:00.771301  1052 sgd_solver.cpp:106] Iteration 29700, lr = 0.00535937
I0701 15:03:02.845978  1052 solver.cpp:290] Iteration 29800 (48.2015 iter/s, 2.07462s/100 iter), loss = 0
I0701 15:03:02.845999  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:03:02.846006  1052 sgd_solver.cpp:106] Iteration 29800, lr = 0.00534375
I0701 15:03:04.917665  1052 solver.cpp:290] Iteration 29900 (48.2718 iter/s, 2.0716s/100 iter), loss = 0
I0701 15:03:04.917690  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:03:04.917697  1052 sgd_solver.cpp:106] Iteration 29900, lr = 0.00532812
I0701 15:03:06.971614  1052 solver.cpp:600] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/sparse/cifar10_jacintonet11v2_iter_30000.caffemodel
I0701 15:03:06.988145  1052 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/sparse/cifar10_jacintonet11v2_iter_30000.solverstate
I0701 15:03:06.995332  1052 solver.cpp:354] Sparsity after update:
I0701 15:03:06.996276  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:03:06.996285  1052 net.cpp:1851] conv1a_param_0(0.26) 
I0701 15:03:06.996292  1052 net.cpp:1851] conv1b_param_0(0.52) 
I0701 15:03:06.996294  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:03:06.996297  1052 net.cpp:1851] res2a_branch2a_param_0(0.52) 
I0701 15:03:06.996299  1052 net.cpp:1851] res2a_branch2b_param_0(0.52) 
I0701 15:03:06.996300  1052 net.cpp:1851] res3a_branch2a_param_0(0.52) 
I0701 15:03:06.996302  1052 net.cpp:1851] res3a_branch2b_param_0(0.52) 
I0701 15:03:06.996304  1052 net.cpp:1851] res4a_branch2a_param_0(0.52) 
I0701 15:03:06.996306  1052 net.cpp:1851] res4a_branch2b_param_0(0.52) 
I0701 15:03:06.996309  1052 net.cpp:1851] res5a_branch2a_param_0(0.52) 
I0701 15:03:06.996310  1052 net.cpp:1851] res5a_branch2b_param_0(0.52) 
I0701 15:03:06.996311  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.22344e+06/2.3599e+06) 0.518
I0701 15:03:06.996412  1052 solver.cpp:473] Iteration 30000, Testing net (#0)
I0701 15:03:08.635639  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9096
I0701 15:03:08.635658  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9961
I0701 15:03:08.635663  1052 solver.cpp:546]     Test net output #2: loss = 0.2469 (* 1 = 0.2469 loss)
I0701 15:03:08.655207  1052 solver.cpp:290] Iteration 30000 (26.7564 iter/s, 3.73742s/100 iter), loss = 0
I0701 15:03:08.655222  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:03:08.655236  1052 sgd_solver.cpp:106] Iteration 30000, lr = 0.0053125
I0701 15:03:08.655871  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.54
I0701 15:03:08.912091  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 15:03:10.988140  1052 solver.cpp:290] Iteration 30100 (42.866 iter/s, 2.33285s/100 iter), loss = 0
I0701 15:03:10.988162  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:03:10.988169  1052 sgd_solver.cpp:106] Iteration 30100, lr = 0.00529688
I0701 15:03:13.058857  1052 solver.cpp:290] Iteration 30200 (48.2944 iter/s, 2.07063s/100 iter), loss = 0
I0701 15:03:13.058878  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:03:13.058887  1052 sgd_solver.cpp:106] Iteration 30200, lr = 0.00528125
I0701 15:03:15.134234  1052 solver.cpp:290] Iteration 30300 (48.186 iter/s, 2.07529s/100 iter), loss = 0
I0701 15:03:15.134258  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:03:15.134266  1052 sgd_solver.cpp:106] Iteration 30300, lr = 0.00526563
I0701 15:03:17.206900  1052 solver.cpp:290] Iteration 30400 (48.249 iter/s, 2.07258s/100 iter), loss = 0
I0701 15:03:17.206923  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:03:17.206928  1052 sgd_solver.cpp:106] Iteration 30400, lr = 0.00525
I0701 15:03:19.279455  1052 solver.cpp:290] Iteration 30500 (48.2516 iter/s, 2.07247s/100 iter), loss = 0
I0701 15:03:19.279479  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:03:19.279484  1052 sgd_solver.cpp:106] Iteration 30500, lr = 0.00523437
I0701 15:03:21.353055  1052 solver.cpp:290] Iteration 30600 (48.2273 iter/s, 2.07351s/100 iter), loss = 0
I0701 15:03:21.353078  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:03:21.353085  1052 sgd_solver.cpp:106] Iteration 30600, lr = 0.00521875
I0701 15:03:23.426551  1052 solver.cpp:290] Iteration 30700 (48.2297 iter/s, 2.07341s/100 iter), loss = 0
I0701 15:03:23.426573  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:03:23.426580  1052 sgd_solver.cpp:106] Iteration 30700, lr = 0.00520312
I0701 15:03:25.501813  1052 solver.cpp:290] Iteration 30800 (48.1887 iter/s, 2.07518s/100 iter), loss = 0
I0701 15:03:25.501857  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:03:25.501863  1052 sgd_solver.cpp:106] Iteration 30800, lr = 0.0051875
I0701 15:03:27.573107  1052 solver.cpp:290] Iteration 30900 (48.2815 iter/s, 2.07119s/100 iter), loss = 0
I0701 15:03:27.573137  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:03:27.573144  1052 sgd_solver.cpp:106] Iteration 30900, lr = 0.00517187
I0701 15:03:29.637441  1052 solver.cpp:354] Sparsity after update:
I0701 15:03:29.638787  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:03:29.638794  1052 net.cpp:1851] conv1a_param_0(0.27) 
I0701 15:03:29.638801  1052 net.cpp:1851] conv1b_param_0(0.54) 
I0701 15:03:29.638803  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:03:29.638805  1052 net.cpp:1851] res2a_branch2a_param_0(0.54) 
I0701 15:03:29.638808  1052 net.cpp:1851] res2a_branch2b_param_0(0.54) 
I0701 15:03:29.638809  1052 net.cpp:1851] res3a_branch2a_param_0(0.54) 
I0701 15:03:29.638811  1052 net.cpp:1851] res3a_branch2b_param_0(0.54) 
I0701 15:03:29.638813  1052 net.cpp:1851] res4a_branch2a_param_0(0.54) 
I0701 15:03:29.638814  1052 net.cpp:1851] res4a_branch2b_param_0(0.54) 
I0701 15:03:29.638816  1052 net.cpp:1851] res5a_branch2a_param_0(0.54) 
I0701 15:03:29.638818  1052 net.cpp:1851] res5a_branch2b_param_0(0.54) 
I0701 15:03:29.638820  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.27063e+06/2.3599e+06) 0.538
I0701 15:03:29.638905  1052 solver.cpp:473] Iteration 31000, Testing net (#0)
I0701 15:03:31.279403  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9103
I0701 15:03:31.279422  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9955
I0701 15:03:31.279428  1052 solver.cpp:546]     Test net output #2: loss = 0.2504 (* 1 = 0.2504 loss)
I0701 15:03:31.299165  1052 solver.cpp:290] Iteration 31000 (26.8389 iter/s, 3.72593s/100 iter), loss = 0
I0701 15:03:31.299182  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:03:31.299196  1052 sgd_solver.cpp:106] Iteration 31000, lr = 0.00515625
I0701 15:03:31.299813  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.56
I0701 15:03:31.560353  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 15:03:33.638080  1052 solver.cpp:290] Iteration 31100 (42.7565 iter/s, 2.33883s/100 iter), loss = 0
I0701 15:03:33.638101  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:03:33.638109  1052 sgd_solver.cpp:106] Iteration 31100, lr = 0.00514062
I0701 15:03:35.709573  1052 solver.cpp:290] Iteration 31200 (48.2763 iter/s, 2.07141s/100 iter), loss = 0
I0701 15:03:35.709595  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:03:35.709602  1052 sgd_solver.cpp:106] Iteration 31200, lr = 0.005125
I0701 15:03:37.788341  1052 solver.cpp:290] Iteration 31300 (48.1074 iter/s, 2.07868s/100 iter), loss = 0
I0701 15:03:37.788414  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:03:37.788424  1052 sgd_solver.cpp:106] Iteration 31300, lr = 0.00510937
I0701 15:03:39.861642  1052 solver.cpp:290] Iteration 31400 (48.2354 iter/s, 2.07317s/100 iter), loss = 0
I0701 15:03:39.861663  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:03:39.861670  1052 sgd_solver.cpp:106] Iteration 31400, lr = 0.00509375
I0701 15:03:41.932555  1052 solver.cpp:290] Iteration 31500 (48.2898 iter/s, 2.07083s/100 iter), loss = 0
I0701 15:03:41.932576  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:03:41.932584  1052 sgd_solver.cpp:106] Iteration 31500, lr = 0.00507812
I0701 15:03:44.010284  1052 solver.cpp:290] Iteration 31600 (48.1315 iter/s, 2.07764s/100 iter), loss = 0
I0701 15:03:44.010309  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:03:44.010318  1052 sgd_solver.cpp:106] Iteration 31600, lr = 0.0050625
I0701 15:03:46.081310  1052 solver.cpp:290] Iteration 31700 (48.2873 iter/s, 2.07094s/100 iter), loss = 0
I0701 15:03:46.081332  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:03:46.081338  1052 sgd_solver.cpp:106] Iteration 31700, lr = 0.00504687
I0701 15:03:48.154903  1052 solver.cpp:290] Iteration 31800 (48.2275 iter/s, 2.07351s/100 iter), loss = 0
I0701 15:03:48.154924  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:03:48.154932  1052 sgd_solver.cpp:106] Iteration 31800, lr = 0.00503125
I0701 15:03:50.228189  1052 solver.cpp:290] Iteration 31900 (48.2346 iter/s, 2.0732s/100 iter), loss = 0
I0701 15:03:50.228212  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:03:50.228221  1052 sgd_solver.cpp:106] Iteration 31900, lr = 0.00501562
I0701 15:03:52.282536  1052 solver.cpp:354] Sparsity after update:
I0701 15:03:52.283890  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:03:52.283897  1052 net.cpp:1851] conv1a_param_0(0.28) 
I0701 15:03:52.283903  1052 net.cpp:1851] conv1b_param_0(0.56) 
I0701 15:03:52.283905  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:03:52.283908  1052 net.cpp:1851] res2a_branch2a_param_0(0.56) 
I0701 15:03:52.283910  1052 net.cpp:1851] res2a_branch2b_param_0(0.56) 
I0701 15:03:52.283911  1052 net.cpp:1851] res3a_branch2a_param_0(0.56) 
I0701 15:03:52.283913  1052 net.cpp:1851] res3a_branch2b_param_0(0.56) 
I0701 15:03:52.283915  1052 net.cpp:1851] res4a_branch2a_param_0(0.56) 
I0701 15:03:52.283917  1052 net.cpp:1851] res4a_branch2b_param_0(0.56) 
I0701 15:03:52.283920  1052 net.cpp:1851] res5a_branch2a_param_0(0.56) 
I0701 15:03:52.283921  1052 net.cpp:1851] res5a_branch2b_param_0(0.56) 
I0701 15:03:52.283923  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.31788e+06/2.3599e+06) 0.558
I0701 15:03:52.284008  1052 solver.cpp:473] Iteration 32000, Testing net (#0)
I0701 15:03:53.923701  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9084
I0701 15:03:53.923719  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9958
I0701 15:03:53.923725  1052 solver.cpp:546]     Test net output #2: loss = 0.2519 (* 1 = 0.2519 loss)
I0701 15:03:53.943660  1052 solver.cpp:290] Iteration 32000 (26.9154 iter/s, 3.71535s/100 iter), loss = 0
I0701 15:03:53.943675  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:03:53.943691  1052 sgd_solver.cpp:106] Iteration 32000, lr = 0.005
I0701 15:03:53.944325  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.58
I0701 15:03:54.243888  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 15:03:56.318377  1052 solver.cpp:290] Iteration 32100 (42.1118 iter/s, 2.37463s/100 iter), loss = 0
I0701 15:03:56.318403  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:03:56.318411  1052 sgd_solver.cpp:106] Iteration 32100, lr = 0.00498438
I0701 15:03:58.417080  1052 solver.cpp:290] Iteration 32200 (47.6505 iter/s, 2.09862s/100 iter), loss = 0
I0701 15:03:58.417119  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:03:58.417127  1052 sgd_solver.cpp:106] Iteration 32200, lr = 0.00496875
I0701 15:04:00.494045  1052 solver.cpp:290] Iteration 32300 (48.1495 iter/s, 2.07687s/100 iter), loss = 0
I0701 15:04:00.494066  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:04:00.494073  1052 sgd_solver.cpp:106] Iteration 32300, lr = 0.00495313
I0701 15:04:02.564651  1052 solver.cpp:290] Iteration 32400 (48.297 iter/s, 2.07052s/100 iter), loss = 0
I0701 15:04:02.564673  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:04:02.564680  1052 sgd_solver.cpp:106] Iteration 32400, lr = 0.0049375
I0701 15:04:04.635526  1052 solver.cpp:290] Iteration 32500 (48.2908 iter/s, 2.07079s/100 iter), loss = 0
I0701 15:04:04.635555  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:04:04.635562  1052 sgd_solver.cpp:106] Iteration 32500, lr = 0.00492187
I0701 15:04:06.712625  1052 solver.cpp:290] Iteration 32600 (48.1461 iter/s, 2.07701s/100 iter), loss = 0
I0701 15:04:06.712646  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:04:06.712653  1052 sgd_solver.cpp:106] Iteration 32600, lr = 0.00490625
I0701 15:04:08.789420  1052 solver.cpp:290] Iteration 32700 (48.153 iter/s, 2.07671s/100 iter), loss = 0
I0701 15:04:08.789486  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:04:08.789494  1052 sgd_solver.cpp:106] Iteration 32700, lr = 0.00489062
I0701 15:04:10.859503  1052 solver.cpp:290] Iteration 32800 (48.3102 iter/s, 2.06996s/100 iter), loss = 0
I0701 15:04:10.859525  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:04:10.859531  1052 sgd_solver.cpp:106] Iteration 32800, lr = 0.004875
I0701 15:04:12.935317  1052 solver.cpp:290] Iteration 32900 (48.1758 iter/s, 2.07573s/100 iter), loss = 0
I0701 15:04:12.935340  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:04:12.935346  1052 sgd_solver.cpp:106] Iteration 32900, lr = 0.00485937
I0701 15:04:14.987220  1052 solver.cpp:354] Sparsity after update:
I0701 15:04:14.988549  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:04:14.988555  1052 net.cpp:1851] conv1a_param_0(0.29) 
I0701 15:04:14.988562  1052 net.cpp:1851] conv1b_param_0(0.58) 
I0701 15:04:14.988564  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:04:14.988566  1052 net.cpp:1851] res2a_branch2a_param_0(0.58) 
I0701 15:04:14.988569  1052 net.cpp:1851] res2a_branch2b_param_0(0.58) 
I0701 15:04:14.988570  1052 net.cpp:1851] res3a_branch2a_param_0(0.58) 
I0701 15:04:14.988572  1052 net.cpp:1851] res3a_branch2b_param_0(0.58) 
I0701 15:04:14.988574  1052 net.cpp:1851] res4a_branch2a_param_0(0.58) 
I0701 15:04:14.988576  1052 net.cpp:1851] res4a_branch2b_param_0(0.58) 
I0701 15:04:14.988577  1052 net.cpp:1851] res5a_branch2a_param_0(0.58) 
I0701 15:04:14.988579  1052 net.cpp:1851] res5a_branch2b_param_0(0.58) 
I0701 15:04:14.988581  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.36502e+06/2.3599e+06) 0.578
I0701 15:04:14.988664  1052 solver.cpp:473] Iteration 33000, Testing net (#0)
I0701 15:04:16.627193  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9068
I0701 15:04:16.627213  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9954
I0701 15:04:16.627218  1052 solver.cpp:546]     Test net output #2: loss = 0.2626 (* 1 = 0.2626 loss)
I0701 15:04:16.647588  1052 solver.cpp:290] Iteration 33000 (26.9386 iter/s, 3.71214s/100 iter), loss = 0
I0701 15:04:16.647617  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:04:16.647624  1052 sgd_solver.cpp:106] Iteration 33000, lr = 0.00484375
I0701 15:04:16.648396  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.6
I0701 15:04:16.947458  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 15:04:19.033354  1052 solver.cpp:290] Iteration 33100 (41.917 iter/s, 2.38566s/100 iter), loss = 0
I0701 15:04:19.033378  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:04:19.033387  1052 sgd_solver.cpp:106] Iteration 33100, lr = 0.00482813
I0701 15:04:21.111152  1052 solver.cpp:290] Iteration 33200 (48.1299 iter/s, 2.07771s/100 iter), loss = 0
I0701 15:04:21.111174  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:04:21.111181  1052 sgd_solver.cpp:106] Iteration 33200, lr = 0.0048125
I0701 15:04:23.187947  1052 solver.cpp:290] Iteration 33300 (48.153 iter/s, 2.07671s/100 iter), loss = 0
I0701 15:04:23.187970  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:04:23.187978  1052 sgd_solver.cpp:106] Iteration 33300, lr = 0.00479688
I0701 15:04:25.264374  1052 solver.cpp:290] Iteration 33400 (48.1616 iter/s, 2.07634s/100 iter), loss = 0
I0701 15:04:25.264398  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:04:25.264406  1052 sgd_solver.cpp:106] Iteration 33400, lr = 0.00478125
I0701 15:04:27.337709  1052 solver.cpp:290] Iteration 33500 (48.2335 iter/s, 2.07325s/100 iter), loss = 0
I0701 15:04:27.337733  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:04:27.337741  1052 sgd_solver.cpp:106] Iteration 33500, lr = 0.00476563
I0701 15:04:29.407198  1052 solver.cpp:290] Iteration 33600 (48.3231 iter/s, 2.0694s/100 iter), loss = 0
I0701 15:04:29.407239  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:04:29.407246  1052 sgd_solver.cpp:106] Iteration 33600, lr = 0.00475
I0701 15:04:31.479643  1052 solver.cpp:290] Iteration 33700 (48.2545 iter/s, 2.07234s/100 iter), loss = 0
I0701 15:04:31.479665  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:04:31.479671  1052 sgd_solver.cpp:106] Iteration 33700, lr = 0.00473437
I0701 15:04:33.550963  1052 solver.cpp:290] Iteration 33800 (48.2803 iter/s, 2.07124s/100 iter), loss = 0
I0701 15:04:33.550987  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:04:33.550993  1052 sgd_solver.cpp:106] Iteration 33800, lr = 0.00471875
I0701 15:04:35.625618  1052 solver.cpp:290] Iteration 33900 (48.2028 iter/s, 2.07457s/100 iter), loss = 0
I0701 15:04:35.625640  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:04:35.625646  1052 sgd_solver.cpp:106] Iteration 33900, lr = 0.00470312
I0701 15:04:37.676743  1052 solver.cpp:354] Sparsity after update:
I0701 15:04:37.678114  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:04:37.678122  1052 net.cpp:1851] conv1a_param_0(0.3) 
I0701 15:04:37.678128  1052 net.cpp:1851] conv1b_param_0(0.6) 
I0701 15:04:37.678131  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:04:37.678133  1052 net.cpp:1851] res2a_branch2a_param_0(0.6) 
I0701 15:04:37.678135  1052 net.cpp:1851] res2a_branch2b_param_0(0.6) 
I0701 15:04:37.678138  1052 net.cpp:1851] res3a_branch2a_param_0(0.6) 
I0701 15:04:37.678139  1052 net.cpp:1851] res3a_branch2b_param_0(0.6) 
I0701 15:04:37.678140  1052 net.cpp:1851] res4a_branch2a_param_0(0.6) 
I0701 15:04:37.678143  1052 net.cpp:1851] res4a_branch2b_param_0(0.6) 
I0701 15:04:37.678144  1052 net.cpp:1851] res5a_branch2a_param_0(0.6) 
I0701 15:04:37.678146  1052 net.cpp:1851] res5a_branch2b_param_0(0.6) 
I0701 15:04:37.678148  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.41206e+06/2.3599e+06) 0.598
I0701 15:04:37.678236  1052 solver.cpp:473] Iteration 34000, Testing net (#0)
I0701 15:04:39.322887  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9098
I0701 15:04:39.322939  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.996
I0701 15:04:39.322947  1052 solver.cpp:546]     Test net output #2: loss = 0.2575 (* 1 = 0.2575 loss)
I0701 15:04:39.342883  1052 solver.cpp:290] Iteration 34000 (26.9024 iter/s, 3.71714s/100 iter), loss = 0
I0701 15:04:39.342898  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:04:39.342914  1052 sgd_solver.cpp:106] Iteration 34000, lr = 0.0046875
I0701 15:04:39.343538  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.62
I0701 15:04:39.661244  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 15:04:41.737977  1052 solver.cpp:290] Iteration 34100 (41.7535 iter/s, 2.39501s/100 iter), loss = 0
I0701 15:04:41.737998  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:04:41.738004  1052 sgd_solver.cpp:106] Iteration 34100, lr = 0.00467187
I0701 15:04:43.813228  1052 solver.cpp:290] Iteration 34200 (48.1889 iter/s, 2.07517s/100 iter), loss = 0
I0701 15:04:43.813251  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:04:43.813257  1052 sgd_solver.cpp:106] Iteration 34200, lr = 0.00465625
I0701 15:04:45.887528  1052 solver.cpp:290] Iteration 34300 (48.211 iter/s, 2.07422s/100 iter), loss = 0
I0701 15:04:45.887552  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:04:45.887559  1052 sgd_solver.cpp:106] Iteration 34300, lr = 0.00464062
I0701 15:04:47.961678  1052 solver.cpp:290] Iteration 34400 (48.2145 iter/s, 2.07406s/100 iter), loss = 0
I0701 15:04:47.961699  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:04:47.961706  1052 sgd_solver.cpp:106] Iteration 34400, lr = 0.004625
I0701 15:04:50.032259  1052 solver.cpp:290] Iteration 34500 (48.2976 iter/s, 2.0705s/100 iter), loss = 0
I0701 15:04:50.032279  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:04:50.032287  1052 sgd_solver.cpp:106] Iteration 34500, lr = 0.00460937
I0701 15:04:52.107586  1052 solver.cpp:290] Iteration 34600 (48.1871 iter/s, 2.07524s/100 iter), loss = 0
I0701 15:04:52.107607  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:04:52.107615  1052 sgd_solver.cpp:106] Iteration 34600, lr = 0.00459375
I0701 15:04:54.183130  1052 solver.cpp:290] Iteration 34700 (48.1821 iter/s, 2.07546s/100 iter), loss = 0
I0701 15:04:54.183151  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:04:54.183158  1052 sgd_solver.cpp:106] Iteration 34700, lr = 0.00457812
I0701 15:04:56.270223  1052 solver.cpp:290] Iteration 34800 (47.9155 iter/s, 2.08701s/100 iter), loss = 0
I0701 15:04:56.270246  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:04:56.270252  1052 sgd_solver.cpp:106] Iteration 34800, lr = 0.0045625
I0701 15:04:58.359833  1052 solver.cpp:290] Iteration 34900 (47.8578 iter/s, 2.08952s/100 iter), loss = 0
I0701 15:04:58.359858  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:04:58.359864  1052 sgd_solver.cpp:106] Iteration 34900, lr = 0.00454687
I0701 15:05:00.410311  1052 solver.cpp:354] Sparsity after update:
I0701 15:05:00.411698  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:05:00.411710  1052 net.cpp:1851] conv1a_param_0(0.31) 
I0701 15:05:00.411720  1052 net.cpp:1851] conv1b_param_0(0.62) 
I0701 15:05:00.411723  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:05:00.411728  1052 net.cpp:1851] res2a_branch2a_param_0(0.62) 
I0701 15:05:00.411732  1052 net.cpp:1851] res2a_branch2b_param_0(0.62) 
I0701 15:05:00.411736  1052 net.cpp:1851] res3a_branch2a_param_0(0.62) 
I0701 15:05:00.411741  1052 net.cpp:1851] res3a_branch2b_param_0(0.62) 
I0701 15:05:00.411744  1052 net.cpp:1851] res4a_branch2a_param_0(0.62) 
I0701 15:05:00.411749  1052 net.cpp:1851] res4a_branch2b_param_0(0.62) 
I0701 15:05:00.411752  1052 net.cpp:1851] res5a_branch2a_param_0(0.62) 
I0701 15:05:00.411756  1052 net.cpp:1851] res5a_branch2b_param_0(0.62) 
I0701 15:05:00.411772  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.45919e+06/2.3599e+06) 0.618
I0701 15:05:00.411869  1052 solver.cpp:473] Iteration 35000, Testing net (#0)
I0701 15:05:02.050586  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.909
I0701 15:05:02.050606  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9951
I0701 15:05:02.050612  1052 solver.cpp:546]     Test net output #2: loss = 0.2689 (* 1 = 0.2689 loss)
I0701 15:05:02.071806  1052 solver.cpp:290] Iteration 35000 (26.9408 iter/s, 3.71185s/100 iter), loss = 0
I0701 15:05:02.071825  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:05:02.071835  1052 sgd_solver.cpp:106] Iteration 35000, lr = 0.00453125
I0701 15:05:02.072482  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.64
I0701 15:05:02.415290  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 15:05:04.488059  1052 solver.cpp:290] Iteration 35100 (41.3879 iter/s, 2.41616s/100 iter), loss = 0
I0701 15:05:04.488080  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:05:04.488087  1052 sgd_solver.cpp:106] Iteration 35100, lr = 0.00451563
I0701 15:05:06.563498  1052 solver.cpp:290] Iteration 35200 (48.1845 iter/s, 2.07536s/100 iter), loss = 0
I0701 15:05:06.563521  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:05:06.563527  1052 sgd_solver.cpp:106] Iteration 35200, lr = 0.0045
I0701 15:05:08.636032  1052 solver.cpp:290] Iteration 35300 (48.2521 iter/s, 2.07245s/100 iter), loss = 0
I0701 15:05:08.636054  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:05:08.636061  1052 sgd_solver.cpp:106] Iteration 35300, lr = 0.00448438
I0701 15:05:10.714990  1052 solver.cpp:290] Iteration 35400 (48.103 iter/s, 2.07887s/100 iter), loss = 0
I0701 15:05:10.715060  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:05:10.715070  1052 sgd_solver.cpp:106] Iteration 35400, lr = 0.00446875
I0701 15:05:12.787228  1052 solver.cpp:290] Iteration 35500 (48.26 iter/s, 2.07211s/100 iter), loss = 0
I0701 15:05:12.787250  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:05:12.787257  1052 sgd_solver.cpp:106] Iteration 35500, lr = 0.00445312
I0701 15:05:14.860277  1052 solver.cpp:290] Iteration 35600 (48.2401 iter/s, 2.07297s/100 iter), loss = 0
I0701 15:05:14.860299  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:05:14.860306  1052 sgd_solver.cpp:106] Iteration 35600, lr = 0.0044375
I0701 15:05:16.933955  1052 solver.cpp:290] Iteration 35700 (48.2255 iter/s, 2.07359s/100 iter), loss = 0
I0701 15:05:16.933979  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:05:16.933986  1052 sgd_solver.cpp:106] Iteration 35700, lr = 0.00442187
I0701 15:05:19.006995  1052 solver.cpp:290] Iteration 35800 (48.2403 iter/s, 2.07295s/100 iter), loss = 0
I0701 15:05:19.007017  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:05:19.007024  1052 sgd_solver.cpp:106] Iteration 35800, lr = 0.00440625
I0701 15:05:21.080409  1052 solver.cpp:290] Iteration 35900 (48.2316 iter/s, 2.07333s/100 iter), loss = 0
I0701 15:05:21.080430  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:05:21.080436  1052 sgd_solver.cpp:106] Iteration 35900, lr = 0.00439062
I0701 15:05:23.133664  1052 solver.cpp:354] Sparsity after update:
I0701 15:05:23.135005  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:05:23.135012  1052 net.cpp:1851] conv1a_param_0(0.32) 
I0701 15:05:23.135020  1052 net.cpp:1851] conv1b_param_0(0.64) 
I0701 15:05:23.135022  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:05:23.135025  1052 net.cpp:1851] res2a_branch2a_param_0(0.64) 
I0701 15:05:23.135027  1052 net.cpp:1851] res2a_branch2b_param_0(0.64) 
I0701 15:05:23.135030  1052 net.cpp:1851] res3a_branch2a_param_0(0.64) 
I0701 15:05:23.135031  1052 net.cpp:1851] res3a_branch2b_param_0(0.64) 
I0701 15:05:23.135033  1052 net.cpp:1851] res4a_branch2a_param_0(0.64) 
I0701 15:05:23.135035  1052 net.cpp:1851] res4a_branch2b_param_0(0.64) 
I0701 15:05:23.135037  1052 net.cpp:1851] res5a_branch2a_param_0(0.64) 
I0701 15:05:23.135040  1052 net.cpp:1851] res5a_branch2b_param_0(0.64) 
I0701 15:05:23.135042  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.50624e+06/2.3599e+06) 0.638
I0701 15:05:23.135125  1052 solver.cpp:473] Iteration 36000, Testing net (#0)
I0701 15:05:24.776316  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8683
I0701 15:05:24.776335  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9928
I0701 15:05:24.776340  1052 solver.cpp:546]     Test net output #2: loss = 0.4828 (* 1 = 0.4828 loss)
I0701 15:05:24.795950  1052 solver.cpp:290] Iteration 36000 (26.9149 iter/s, 3.71542s/100 iter), loss = 0
I0701 15:05:24.795965  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:05:24.795981  1052 sgd_solver.cpp:106] Iteration 36000, lr = 0.004375
I0701 15:05:24.796558  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.66
I0701 15:05:25.164038  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 15:05:27.244323  1052 solver.cpp:290] Iteration 36100 (40.8449 iter/s, 2.44828s/100 iter), loss = 0
I0701 15:05:27.244345  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:05:27.244352  1052 sgd_solver.cpp:106] Iteration 36100, lr = 0.00435938
I0701 15:05:29.319905  1052 solver.cpp:290] Iteration 36200 (48.1812 iter/s, 2.0755s/100 iter), loss = 0
I0701 15:05:29.319927  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:05:29.319933  1052 sgd_solver.cpp:106] Iteration 36200, lr = 0.00434375
I0701 15:05:31.395179  1052 solver.cpp:290] Iteration 36300 (48.1884 iter/s, 2.07519s/100 iter), loss = 0
I0701 15:05:31.395221  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:05:31.395228  1052 sgd_solver.cpp:106] Iteration 36300, lr = 0.00432813
I0701 15:05:33.468698  1052 solver.cpp:290] Iteration 36400 (48.2296 iter/s, 2.07341s/100 iter), loss = 0
I0701 15:05:33.468721  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:05:33.468727  1052 sgd_solver.cpp:106] Iteration 36400, lr = 0.0043125
I0701 15:05:35.542382  1052 solver.cpp:290] Iteration 36500 (48.2254 iter/s, 2.0736s/100 iter), loss = 0
I0701 15:05:35.542407  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:05:35.542413  1052 sgd_solver.cpp:106] Iteration 36500, lr = 0.00429688
I0701 15:05:37.614773  1052 solver.cpp:290] Iteration 36600 (48.2555 iter/s, 2.0723s/100 iter), loss = 0
I0701 15:05:37.614796  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:05:37.614802  1052 sgd_solver.cpp:106] Iteration 36600, lr = 0.00428125
I0701 15:05:39.685159  1052 solver.cpp:290] Iteration 36700 (48.3022 iter/s, 2.0703s/100 iter), loss = 0
I0701 15:05:39.685180  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:05:39.685189  1052 sgd_solver.cpp:106] Iteration 36700, lr = 0.00426562
I0701 15:05:41.761080  1052 solver.cpp:290] Iteration 36800 (48.1734 iter/s, 2.07584s/100 iter), loss = 0
I0701 15:05:41.761163  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:05:41.761174  1052 sgd_solver.cpp:106] Iteration 36800, lr = 0.00425
I0701 15:05:43.833134  1052 solver.cpp:290] Iteration 36900 (48.2646 iter/s, 2.07191s/100 iter), loss = 0
I0701 15:05:43.833156  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:05:43.833164  1052 sgd_solver.cpp:106] Iteration 36900, lr = 0.00423437
I0701 15:05:45.884944  1052 solver.cpp:354] Sparsity after update:
I0701 15:05:45.886281  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:05:45.886287  1052 net.cpp:1851] conv1a_param_0(0.33) 
I0701 15:05:45.886294  1052 net.cpp:1851] conv1b_param_0(0.66) 
I0701 15:05:45.886296  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:05:45.886298  1052 net.cpp:1851] res2a_branch2a_param_0(0.66) 
I0701 15:05:45.886301  1052 net.cpp:1851] res2a_branch2b_param_0(0.66) 
I0701 15:05:45.886302  1052 net.cpp:1851] res3a_branch2a_param_0(0.66) 
I0701 15:05:45.886304  1052 net.cpp:1851] res3a_branch2b_param_0(0.66) 
I0701 15:05:45.886307  1052 net.cpp:1851] res4a_branch2a_param_0(0.66) 
I0701 15:05:45.886308  1052 net.cpp:1851] res4a_branch2b_param_0(0.66) 
I0701 15:05:45.886310  1052 net.cpp:1851] res5a_branch2a_param_0(0.66) 
I0701 15:05:45.886312  1052 net.cpp:1851] res5a_branch2b_param_0(0.66) 
I0701 15:05:45.886313  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.55334e+06/2.3599e+06) 0.658
I0701 15:05:45.886401  1052 solver.cpp:473] Iteration 37000, Testing net (#0)
I0701 15:05:47.526402  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8796
I0701 15:05:47.526422  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9944
I0701 15:05:47.526427  1052 solver.cpp:546]     Test net output #2: loss = 0.3571 (* 1 = 0.3571 loss)
I0701 15:05:47.550861  1052 solver.cpp:290] Iteration 37000 (26.8991 iter/s, 3.7176s/100 iter), loss = 0
I0701 15:05:47.550879  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:05:47.550891  1052 sgd_solver.cpp:106] Iteration 37000, lr = 0.00421875
I0701 15:05:47.551532  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.68
I0701 15:05:47.936548  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 15:05:50.011864  1052 solver.cpp:290] Iteration 37100 (40.6353 iter/s, 2.46091s/100 iter), loss = 0
I0701 15:05:50.011886  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:05:50.011894  1052 sgd_solver.cpp:106] Iteration 37100, lr = 0.00420313
I0701 15:05:52.084600  1052 solver.cpp:290] Iteration 37200 (48.2474 iter/s, 2.07265s/100 iter), loss = 0
I0701 15:05:52.084622  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:05:52.084630  1052 sgd_solver.cpp:106] Iteration 37200, lr = 0.0041875
I0701 15:05:54.159637  1052 solver.cpp:290] Iteration 37300 (48.1939 iter/s, 2.07495s/100 iter), loss = 0
I0701 15:05:54.159659  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:05:54.159667  1052 sgd_solver.cpp:106] Iteration 37300, lr = 0.00417187
I0701 15:05:56.233080  1052 solver.cpp:290] Iteration 37400 (48.2309 iter/s, 2.07336s/100 iter), loss = 0
I0701 15:05:56.233103  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:05:56.233108  1052 sgd_solver.cpp:106] Iteration 37400, lr = 0.00415625
I0701 15:05:58.318388  1052 solver.cpp:290] Iteration 37500 (47.9566 iter/s, 2.08522s/100 iter), loss = 0
I0701 15:05:58.318410  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:05:58.318416  1052 sgd_solver.cpp:106] Iteration 37500, lr = 0.00414062
I0701 15:06:00.391392  1052 solver.cpp:290] Iteration 37600 (48.2412 iter/s, 2.07292s/100 iter), loss = 0
I0701 15:06:00.391415  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:06:00.391422  1052 sgd_solver.cpp:106] Iteration 37600, lr = 0.004125
I0701 15:06:02.470079  1052 solver.cpp:290] Iteration 37700 (48.1093 iter/s, 2.0786s/100 iter), loss = 0
I0701 15:06:02.470113  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:06:02.470119  1052 sgd_solver.cpp:106] Iteration 37700, lr = 0.00410937
I0701 15:06:04.542878  1052 solver.cpp:290] Iteration 37800 (48.2462 iter/s, 2.0727s/100 iter), loss = 0
I0701 15:06:04.542901  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:06:04.542909  1052 sgd_solver.cpp:106] Iteration 37800, lr = 0.00409375
I0701 15:06:06.619071  1052 solver.cpp:290] Iteration 37900 (48.1671 iter/s, 2.0761s/100 iter), loss = 0
I0701 15:06:06.619099  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:06:06.619108  1052 sgd_solver.cpp:106] Iteration 37900, lr = 0.00407812
I0701 15:06:08.681866  1052 solver.cpp:354] Sparsity after update:
I0701 15:06:08.683220  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:06:08.683228  1052 net.cpp:1851] conv1a_param_0(0.34) 
I0701 15:06:08.683238  1052 net.cpp:1851] conv1b_param_0(0.68) 
I0701 15:06:08.683243  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:06:08.683246  1052 net.cpp:1851] res2a_branch2a_param_0(0.68) 
I0701 15:06:08.683250  1052 net.cpp:1851] res2a_branch2b_param_0(0.68) 
I0701 15:06:08.683255  1052 net.cpp:1851] res3a_branch2a_param_0(0.68) 
I0701 15:06:08.683259  1052 net.cpp:1851] res3a_branch2b_param_0(0.68) 
I0701 15:06:08.683262  1052 net.cpp:1851] res4a_branch2a_param_0(0.68) 
I0701 15:06:08.683266  1052 net.cpp:1851] res4a_branch2b_param_0(0.68) 
I0701 15:06:08.683270  1052 net.cpp:1851] res5a_branch2a_param_0(0.68) 
I0701 15:06:08.683274  1052 net.cpp:1851] res5a_branch2b_param_0(0.68) 
I0701 15:06:08.683277  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.60043e+06/2.3599e+06) 0.678
I0701 15:06:08.683368  1052 solver.cpp:473] Iteration 38000, Testing net (#0)
I0701 15:06:10.326652  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9017
I0701 15:06:10.326671  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9957
I0701 15:06:10.326676  1052 solver.cpp:546]     Test net output #2: loss = 0.2948 (* 1 = 0.2948 loss)
I0701 15:06:10.346379  1052 solver.cpp:290] Iteration 38000 (26.83 iter/s, 3.72717s/100 iter), loss = 0
I0701 15:06:10.346401  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:06:10.346408  1052 sgd_solver.cpp:106] Iteration 38000, lr = 0.0040625
I0701 15:06:10.346977  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.7
I0701 15:06:10.747671  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 15:06:12.828042  1052 solver.cpp:290] Iteration 38100 (40.2971 iter/s, 2.48157s/100 iter), loss = 0
I0701 15:06:12.828115  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:06:12.828124  1052 sgd_solver.cpp:106] Iteration 38100, lr = 0.00404688
I0701 15:06:14.902555  1052 solver.cpp:290] Iteration 38200 (48.2072 iter/s, 2.07438s/100 iter), loss = 0
I0701 15:06:14.902578  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:06:14.902585  1052 sgd_solver.cpp:106] Iteration 38200, lr = 0.00403125
I0701 15:06:16.980960  1052 solver.cpp:290] Iteration 38300 (48.1158 iter/s, 2.07832s/100 iter), loss = 0
I0701 15:06:16.980983  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:06:16.980993  1052 sgd_solver.cpp:106] Iteration 38300, lr = 0.00401562
I0701 15:06:19.065608  1052 solver.cpp:290] Iteration 38400 (47.9717 iter/s, 2.08456s/100 iter), loss = 0
I0701 15:06:19.065630  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:06:19.065636  1052 sgd_solver.cpp:106] Iteration 38400, lr = 0.004
I0701 15:06:21.140908  1052 solver.cpp:290] Iteration 38500 (48.1878 iter/s, 2.07521s/100 iter), loss = 0
I0701 15:06:21.140929  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:06:21.140936  1052 sgd_solver.cpp:106] Iteration 38500, lr = 0.00398437
I0701 15:06:23.216217  1052 solver.cpp:290] Iteration 38600 (48.1876 iter/s, 2.07522s/100 iter), loss = 0
I0701 15:06:23.216239  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:06:23.216246  1052 sgd_solver.cpp:106] Iteration 38600, lr = 0.00396875
I0701 15:06:25.290696  1052 solver.cpp:290] Iteration 38700 (48.2069 iter/s, 2.07439s/100 iter), loss = 0
I0701 15:06:25.290719  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:06:25.290725  1052 sgd_solver.cpp:106] Iteration 38700, lr = 0.00395312
I0701 15:06:27.363950  1052 solver.cpp:290] Iteration 38800 (48.2354 iter/s, 2.07317s/100 iter), loss = 0
I0701 15:06:27.363971  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:06:27.363978  1052 sgd_solver.cpp:106] Iteration 38800, lr = 0.0039375
I0701 15:06:29.435075  1052 solver.cpp:290] Iteration 38900 (48.2849 iter/s, 2.07104s/100 iter), loss = 0
I0701 15:06:29.435096  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:06:29.435103  1052 sgd_solver.cpp:106] Iteration 38900, lr = 0.00392187
I0701 15:06:31.490288  1052 solver.cpp:354] Sparsity after update:
I0701 15:06:31.491608  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:06:31.491616  1052 net.cpp:1851] conv1a_param_0(0.35) 
I0701 15:06:31.491622  1052 net.cpp:1851] conv1b_param_0(0.7) 
I0701 15:06:31.491626  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:06:31.491627  1052 net.cpp:1851] res2a_branch2a_param_0(0.7) 
I0701 15:06:31.491629  1052 net.cpp:1851] res2a_branch2b_param_0(0.7) 
I0701 15:06:31.491631  1052 net.cpp:1851] res3a_branch2a_param_0(0.7) 
I0701 15:06:31.491632  1052 net.cpp:1851] res3a_branch2b_param_0(0.7) 
I0701 15:06:31.491634  1052 net.cpp:1851] res4a_branch2a_param_0(0.7) 
I0701 15:06:31.491636  1052 net.cpp:1851] res4a_branch2b_param_0(0.7) 
I0701 15:06:31.491638  1052 net.cpp:1851] res5a_branch2a_param_0(0.7) 
I0701 15:06:31.491641  1052 net.cpp:1851] res5a_branch2b_param_0(0.7) 
I0701 15:06:31.491642  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.6475e+06/2.3599e+06) 0.698
I0701 15:06:31.491724  1052 solver.cpp:473] Iteration 39000, Testing net (#0)
I0701 15:06:33.132666  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9018
I0701 15:06:33.132684  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9953
I0701 15:06:33.132689  1052 solver.cpp:546]     Test net output #2: loss = 0.2793 (* 1 = 0.2793 loss)
I0701 15:06:33.154287  1052 solver.cpp:290] Iteration 39000 (26.8883 iter/s, 3.71909s/100 iter), loss = 0
I0701 15:06:33.154302  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:06:33.154319  1052 sgd_solver.cpp:106] Iteration 39000, lr = 0.00390625
I0701 15:06:33.154927  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.72
I0701 15:06:33.600458  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 15:06:35.678663  1052 solver.cpp:290] Iteration 39100 (39.6152 iter/s, 2.52428s/100 iter), loss = 0
I0701 15:06:35.678685  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:06:35.678692  1052 sgd_solver.cpp:106] Iteration 39100, lr = 0.00389063
I0701 15:06:37.754403  1052 solver.cpp:290] Iteration 39200 (48.1776 iter/s, 2.07566s/100 iter), loss = 0
I0701 15:06:37.754426  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:06:37.754431  1052 sgd_solver.cpp:106] Iteration 39200, lr = 0.003875
I0701 15:06:39.829251  1052 solver.cpp:290] Iteration 39300 (48.1983 iter/s, 2.07476s/100 iter), loss = 0
I0701 15:06:39.829273  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:06:39.829282  1052 sgd_solver.cpp:106] Iteration 39300, lr = 0.00385938
I0701 15:06:41.900652  1052 solver.cpp:290] Iteration 39400 (48.2785 iter/s, 2.07132s/100 iter), loss = 0
I0701 15:06:41.900676  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:06:41.900683  1052 sgd_solver.cpp:106] Iteration 39400, lr = 0.00384375
I0701 15:06:43.973551  1052 solver.cpp:290] Iteration 39500 (48.2436 iter/s, 2.07281s/100 iter), loss = 0.047619
I0701 15:06:43.973645  1052 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 15:06:43.973654  1052 sgd_solver.cpp:106] Iteration 39500, lr = 0.00382812
I0701 15:06:46.045058  1052 solver.cpp:290] Iteration 39600 (48.2777 iter/s, 2.07135s/100 iter), loss = 0
I0701 15:06:46.045080  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:06:46.045089  1052 sgd_solver.cpp:106] Iteration 39600, lr = 0.0038125
I0701 15:06:48.119784  1052 solver.cpp:290] Iteration 39700 (48.2011 iter/s, 2.07464s/100 iter), loss = 0
I0701 15:06:48.119806  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:06:48.119812  1052 sgd_solver.cpp:106] Iteration 39700, lr = 0.00379687
I0701 15:06:50.195766  1052 solver.cpp:290] Iteration 39800 (48.172 iter/s, 2.0759s/100 iter), loss = 0
I0701 15:06:50.195789  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:06:50.195797  1052 sgd_solver.cpp:106] Iteration 39800, lr = 0.00378125
I0701 15:06:52.267448  1052 solver.cpp:290] Iteration 39900 (48.2719 iter/s, 2.0716s/100 iter), loss = 0
I0701 15:06:52.267472  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:06:52.267480  1052 sgd_solver.cpp:106] Iteration 39900, lr = 0.00376562
I0701 15:06:54.319475  1052 solver.cpp:600] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/sparse/cifar10_jacintonet11v2_iter_40000.caffemodel
I0701 15:06:54.336736  1052 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/sparse/cifar10_jacintonet11v2_iter_40000.solverstate
I0701 15:06:54.357524  1052 solver.cpp:354] Sparsity after update:
I0701 15:06:54.358479  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:06:54.358487  1052 net.cpp:1851] conv1a_param_0(0.36) 
I0701 15:06:54.358495  1052 net.cpp:1851] conv1b_param_0(0.72) 
I0701 15:06:54.358499  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:06:54.358501  1052 net.cpp:1851] res2a_branch2a_param_0(0.72) 
I0701 15:06:54.358503  1052 net.cpp:1851] res2a_branch2b_param_0(0.72) 
I0701 15:06:54.358505  1052 net.cpp:1851] res3a_branch2a_param_0(0.72) 
I0701 15:06:54.358507  1052 net.cpp:1851] res3a_branch2b_param_0(0.72) 
I0701 15:06:54.358510  1052 net.cpp:1851] res4a_branch2a_param_0(0.72) 
I0701 15:06:54.358512  1052 net.cpp:1851] res4a_branch2b_param_0(0.72) 
I0701 15:06:54.358515  1052 net.cpp:1851] res5a_branch2a_param_0(0.72) 
I0701 15:06:54.358515  1052 net.cpp:1851] res5a_branch2b_param_0(0.72) 
I0701 15:06:54.358518  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.69457e+06/2.3599e+06) 0.718
I0701 15:06:54.358613  1052 solver.cpp:473] Iteration 40000, Testing net (#0)
I0701 15:06:55.998543  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8959
I0701 15:06:55.998561  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9944
I0701 15:06:55.998566  1052 solver.cpp:546]     Test net output #2: loss = 0.3177 (* 1 = 0.3177 loss)
I0701 15:06:56.018457  1052 solver.cpp:290] Iteration 40000 (26.6604 iter/s, 3.75088s/100 iter), loss = 0
I0701 15:06:56.018474  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:06:56.018486  1052 sgd_solver.cpp:106] Iteration 40000, lr = 0.00375
I0701 15:06:56.019122  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.74
I0701 15:06:56.519708  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 15:06:58.624063  1052 solver.cpp:290] Iteration 40100 (38.3802 iter/s, 2.60551s/100 iter), loss = 0
I0701 15:06:58.624084  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:06:58.624092  1052 sgd_solver.cpp:106] Iteration 40100, lr = 0.00373438
I0701 15:07:00.695520  1052 solver.cpp:290] Iteration 40200 (48.2772 iter/s, 2.07137s/100 iter), loss = 0
I0701 15:07:00.695543  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:07:00.695550  1052 sgd_solver.cpp:106] Iteration 40200, lr = 0.00371875
I0701 15:07:02.769898  1052 solver.cpp:290] Iteration 40300 (48.2092 iter/s, 2.07429s/100 iter), loss = 0
I0701 15:07:02.769920  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:07:02.769927  1052 sgd_solver.cpp:106] Iteration 40300, lr = 0.00370313
I0701 15:07:04.840912  1052 solver.cpp:290] Iteration 40400 (48.2875 iter/s, 2.07093s/100 iter), loss = 0
I0701 15:07:04.840934  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:07:04.840940  1052 sgd_solver.cpp:106] Iteration 40400, lr = 0.0036875
I0701 15:07:06.914180  1052 solver.cpp:290] Iteration 40500 (48.235 iter/s, 2.07318s/100 iter), loss = 0
I0701 15:07:06.914201  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:07:06.914207  1052 sgd_solver.cpp:106] Iteration 40500, lr = 0.00367187
I0701 15:07:08.986132  1052 solver.cpp:290] Iteration 40600 (48.2656 iter/s, 2.07187s/100 iter), loss = 0
I0701 15:07:08.986152  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:07:08.986160  1052 sgd_solver.cpp:106] Iteration 40600, lr = 0.00365625
I0701 15:07:11.057528  1052 solver.cpp:290] Iteration 40700 (48.2786 iter/s, 2.07131s/100 iter), loss = 0
I0701 15:07:11.057548  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:07:11.057555  1052 sgd_solver.cpp:106] Iteration 40700, lr = 0.00364062
I0701 15:07:13.129547  1052 solver.cpp:290] Iteration 40800 (48.264 iter/s, 2.07194s/100 iter), loss = 0
I0701 15:07:13.129570  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:07:13.129575  1052 sgd_solver.cpp:106] Iteration 40800, lr = 0.003625
I0701 15:07:15.202301  1052 solver.cpp:290] Iteration 40900 (48.247 iter/s, 2.07267s/100 iter), loss = 0
I0701 15:07:15.202373  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:07:15.202381  1052 sgd_solver.cpp:106] Iteration 40900, lr = 0.00360937
I0701 15:07:17.253896  1052 solver.cpp:354] Sparsity after update:
I0701 15:07:17.255237  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:07:17.255245  1052 net.cpp:1851] conv1a_param_0(0.37) 
I0701 15:07:17.255252  1052 net.cpp:1851] conv1b_param_0(0.74) 
I0701 15:07:17.255254  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:07:17.255256  1052 net.cpp:1851] res2a_branch2a_param_0(0.74) 
I0701 15:07:17.255259  1052 net.cpp:1851] res2a_branch2b_param_0(0.74) 
I0701 15:07:17.255260  1052 net.cpp:1851] res3a_branch2a_param_0(0.74) 
I0701 15:07:17.255262  1052 net.cpp:1851] res3a_branch2b_param_0(0.74) 
I0701 15:07:17.255264  1052 net.cpp:1851] res4a_branch2a_param_0(0.74) 
I0701 15:07:17.255266  1052 net.cpp:1851] res4a_branch2b_param_0(0.74) 
I0701 15:07:17.255269  1052 net.cpp:1851] res5a_branch2a_param_0(0.74) 
I0701 15:07:17.255270  1052 net.cpp:1851] res5a_branch2b_param_0(0.74) 
I0701 15:07:17.255272  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.74164e+06/2.3599e+06) 0.738
I0701 15:07:17.255365  1052 solver.cpp:473] Iteration 41000, Testing net (#0)
I0701 15:07:18.895387  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9003
I0701 15:07:18.895406  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9956
I0701 15:07:18.895411  1052 solver.cpp:546]     Test net output #2: loss = 0.2987 (* 1 = 0.2987 loss)
I0701 15:07:18.916050  1052 solver.cpp:290] Iteration 41000 (26.9282 iter/s, 3.71357s/100 iter), loss = 0
I0701 15:07:18.916066  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:07:18.916080  1052 sgd_solver.cpp:106] Iteration 41000, lr = 0.00359375
I0701 15:07:18.916700  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.76
I0701 15:07:19.454530  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 15:07:21.529126  1052 solver.cpp:290] Iteration 41100 (38.2705 iter/s, 2.61298s/100 iter), loss = 0
I0701 15:07:21.529147  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:07:21.529155  1052 sgd_solver.cpp:106] Iteration 41100, lr = 0.00357813
I0701 15:07:23.600281  1052 solver.cpp:290] Iteration 41200 (48.2842 iter/s, 2.07107s/100 iter), loss = 0
I0701 15:07:23.600303  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:07:23.600309  1052 sgd_solver.cpp:106] Iteration 41200, lr = 0.0035625
I0701 15:07:25.674244  1052 solver.cpp:290] Iteration 41300 (48.2189 iter/s, 2.07388s/100 iter), loss = 0
I0701 15:07:25.674265  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:07:25.674273  1052 sgd_solver.cpp:106] Iteration 41300, lr = 0.00354687
I0701 15:07:27.747905  1052 solver.cpp:290] Iteration 41400 (48.2259 iter/s, 2.07358s/100 iter), loss = 0
I0701 15:07:27.747926  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:07:27.747933  1052 sgd_solver.cpp:106] Iteration 41400, lr = 0.00353125
I0701 15:07:29.823629  1052 solver.cpp:290] Iteration 41500 (48.1779 iter/s, 2.07564s/100 iter), loss = 0
I0701 15:07:29.823652  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:07:29.823658  1052 sgd_solver.cpp:106] Iteration 41500, lr = 0.00351562
I0701 15:07:31.903961  1052 solver.cpp:290] Iteration 41600 (48.0713 iter/s, 2.08024s/100 iter), loss = 0
I0701 15:07:31.903985  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:07:31.903992  1052 sgd_solver.cpp:106] Iteration 41600, lr = 0.0035
I0701 15:07:33.977845  1052 solver.cpp:290] Iteration 41700 (48.2207 iter/s, 2.0738s/100 iter), loss = 0
I0701 15:07:33.977874  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:07:33.977881  1052 sgd_solver.cpp:106] Iteration 41700, lr = 0.00348437
I0701 15:07:36.048007  1052 solver.cpp:290] Iteration 41800 (48.3075 iter/s, 2.07007s/100 iter), loss = 0
I0701 15:07:36.048046  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:07:36.048053  1052 sgd_solver.cpp:106] Iteration 41800, lr = 0.00346875
I0701 15:07:38.126981  1052 solver.cpp:290] Iteration 41900 (48.103 iter/s, 2.07887s/100 iter), loss = 0
I0701 15:07:38.127002  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:07:38.127009  1052 sgd_solver.cpp:106] Iteration 41900, lr = 0.00345312
I0701 15:07:40.183691  1052 solver.cpp:354] Sparsity after update:
I0701 15:07:40.185030  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:07:40.185037  1052 net.cpp:1851] conv1a_param_0(0.38) 
I0701 15:07:40.185045  1052 net.cpp:1851] conv1b_param_0(0.76) 
I0701 15:07:40.185047  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:07:40.185050  1052 net.cpp:1851] res2a_branch2a_param_0(0.76) 
I0701 15:07:40.185056  1052 net.cpp:1851] res2a_branch2b_param_0(0.76) 
I0701 15:07:40.185058  1052 net.cpp:1851] res3a_branch2a_param_0(0.76) 
I0701 15:07:40.185060  1052 net.cpp:1851] res3a_branch2b_param_0(0.76) 
I0701 15:07:40.185062  1052 net.cpp:1851] res4a_branch2a_param_0(0.76) 
I0701 15:07:40.185065  1052 net.cpp:1851] res4a_branch2b_param_0(0.76) 
I0701 15:07:40.185066  1052 net.cpp:1851] res5a_branch2a_param_0(0.76) 
I0701 15:07:40.185067  1052 net.cpp:1851] res5a_branch2b_param_0(0.76) 
I0701 15:07:40.185070  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.78872e+06/2.3599e+06) 0.758
I0701 15:07:40.185153  1052 solver.cpp:473] Iteration 42000, Testing net (#0)
I0701 15:07:41.822499  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.900199
I0701 15:07:41.822520  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9952
I0701 15:07:41.822525  1052 solver.cpp:546]     Test net output #2: loss = 0.2838 (* 1 = 0.2838 loss)
I0701 15:07:41.842597  1052 solver.cpp:290] Iteration 42000 (26.9144 iter/s, 3.71549s/100 iter), loss = 0
I0701 15:07:41.842620  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:07:41.842630  1052 sgd_solver.cpp:106] Iteration 42000, lr = 0.0034375
I0701 15:07:41.843258  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.78
I0701 15:07:42.426532  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 15:07:44.503906  1052 solver.cpp:290] Iteration 42100 (37.5769 iter/s, 2.66121s/100 iter), loss = 0
I0701 15:07:44.503927  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:07:44.503934  1052 sgd_solver.cpp:106] Iteration 42100, lr = 0.00342188
I0701 15:07:46.577268  1052 solver.cpp:290] Iteration 42200 (48.2328 iter/s, 2.07328s/100 iter), loss = 0
I0701 15:07:46.577349  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:07:46.577360  1052 sgd_solver.cpp:106] Iteration 42200, lr = 0.00340625
I0701 15:07:48.652755  1052 solver.cpp:290] Iteration 42300 (48.1847 iter/s, 2.07535s/100 iter), loss = 0
I0701 15:07:48.652777  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:07:48.652784  1052 sgd_solver.cpp:106] Iteration 42300, lr = 0.00339063
I0701 15:07:50.723068  1052 solver.cpp:290] Iteration 42400 (48.3039 iter/s, 2.07023s/100 iter), loss = 0
I0701 15:07:50.723089  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:07:50.723098  1052 sgd_solver.cpp:106] Iteration 42400, lr = 0.003375
I0701 15:07:52.793658  1052 solver.cpp:290] Iteration 42500 (48.2974 iter/s, 2.07051s/100 iter), loss = 0
I0701 15:07:52.793681  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:07:52.793689  1052 sgd_solver.cpp:106] Iteration 42500, lr = 0.00335937
I0701 15:07:54.864538  1052 solver.cpp:290] Iteration 42600 (48.2907 iter/s, 2.07079s/100 iter), loss = 0
I0701 15:07:54.864567  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:07:54.864575  1052 sgd_solver.cpp:106] Iteration 42600, lr = 0.00334375
I0701 15:07:56.936810  1052 solver.cpp:290] Iteration 42700 (48.2583 iter/s, 2.07218s/100 iter), loss = 0
I0701 15:07:56.936832  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:07:56.936841  1052 sgd_solver.cpp:106] Iteration 42700, lr = 0.00332812
I0701 15:07:59.027246  1052 solver.cpp:290] Iteration 42800 (47.8389 iter/s, 2.09035s/100 iter), loss = 0
I0701 15:07:59.027267  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:07:59.027273  1052 sgd_solver.cpp:106] Iteration 42800, lr = 0.0033125
I0701 15:08:01.099779  1052 solver.cpp:290] Iteration 42900 (48.2522 iter/s, 2.07245s/100 iter), loss = 0
I0701 15:08:01.099804  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:08:01.099813  1052 sgd_solver.cpp:106] Iteration 42900, lr = 0.00329687
I0701 15:08:03.152734  1052 solver.cpp:354] Sparsity after update:
I0701 15:08:03.154064  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:08:03.154072  1052 net.cpp:1851] conv1a_param_0(0.39) 
I0701 15:08:03.154081  1052 net.cpp:1851] conv1b_param_0(0.78) 
I0701 15:08:03.154086  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:08:03.154090  1052 net.cpp:1851] res2a_branch2a_param_0(0.78) 
I0701 15:08:03.154094  1052 net.cpp:1851] res2a_branch2b_param_0(0.78) 
I0701 15:08:03.154098  1052 net.cpp:1851] res3a_branch2a_param_0(0.78) 
I0701 15:08:03.154103  1052 net.cpp:1851] res3a_branch2b_param_0(0.78) 
I0701 15:08:03.154105  1052 net.cpp:1851] res4a_branch2a_param_0(0.78) 
I0701 15:08:03.154109  1052 net.cpp:1851] res4a_branch2b_param_0(0.78) 
I0701 15:08:03.154114  1052 net.cpp:1851] res5a_branch2a_param_0(0.78) 
I0701 15:08:03.154117  1052 net.cpp:1851] res5a_branch2b_param_0(0.78) 
I0701 15:08:03.154121  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.83579e+06/2.3599e+06) 0.778
I0701 15:08:03.154209  1052 solver.cpp:473] Iteration 43000, Testing net (#0)
I0701 15:08:04.793078  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8983
I0701 15:08:04.793097  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9955
I0701 15:08:04.793102  1052 solver.cpp:546]     Test net output #2: loss = 0.2773 (* 1 = 0.2773 loss)
I0701 15:08:04.812613  1052 solver.cpp:290] Iteration 43000 (26.9345 iter/s, 3.7127s/100 iter), loss = 0
I0701 15:08:04.812628  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:08:04.812641  1052 sgd_solver.cpp:106] Iteration 43000, lr = 0.00328125
I0701 15:08:04.813263  1052 solver.cpp:377] Finding and applying thresholds. Target sparsity = 0.8
I0701 15:08:05.434777  1052 net.cpp:1824] All zero weights of convolution layers are frozen
I0701 15:08:07.509186  1052 solver.cpp:290] Iteration 43100 (37.0854 iter/s, 2.69648s/100 iter), loss = 0
I0701 15:08:07.509228  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:08:07.509235  1052 sgd_solver.cpp:106] Iteration 43100, lr = 0.00326563
I0701 15:08:09.585624  1052 solver.cpp:290] Iteration 43200 (48.1618 iter/s, 2.07633s/100 iter), loss = -7.45058e-09
I0701 15:08:09.585647  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:08:09.585654  1052 sgd_solver.cpp:106] Iteration 43200, lr = 0.00325
I0701 15:08:11.657964  1052 solver.cpp:290] Iteration 43300 (48.2567 iter/s, 2.07225s/100 iter), loss = 0.047619
I0701 15:08:11.657986  1052 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 15:08:11.657994  1052 sgd_solver.cpp:106] Iteration 43300, lr = 0.00323438
I0701 15:08:13.732048  1052 solver.cpp:290] Iteration 43400 (48.216 iter/s, 2.074s/100 iter), loss = 0
I0701 15:08:13.732069  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:08:13.732076  1052 sgd_solver.cpp:106] Iteration 43400, lr = 0.00321875
I0701 15:08:15.807276  1052 solver.cpp:290] Iteration 43500 (48.1894 iter/s, 2.07514s/100 iter), loss = 0
I0701 15:08:15.807298  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:08:15.807304  1052 sgd_solver.cpp:106] Iteration 43500, lr = 0.00320312
I0701 15:08:17.881533  1052 solver.cpp:290] Iteration 43600 (48.212 iter/s, 2.07417s/100 iter), loss = 0
I0701 15:08:17.881603  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:08:17.881618  1052 sgd_solver.cpp:106] Iteration 43600, lr = 0.0031875
I0701 15:08:19.957825  1052 solver.cpp:290] Iteration 43700 (48.1657 iter/s, 2.07616s/100 iter), loss = 0
I0701 15:08:19.957846  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:08:19.957854  1052 sgd_solver.cpp:106] Iteration 43700, lr = 0.00317187
I0701 15:08:22.029760  1052 solver.cpp:290] Iteration 43800 (48.266 iter/s, 2.07185s/100 iter), loss = 0
I0701 15:08:22.029780  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:08:22.029788  1052 sgd_solver.cpp:106] Iteration 43800, lr = 0.00315625
I0701 15:08:24.099591  1052 solver.cpp:290] Iteration 43900 (48.3151 iter/s, 2.06975s/100 iter), loss = 0
I0701 15:08:24.099612  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:08:24.099618  1052 sgd_solver.cpp:106] Iteration 43900, lr = 0.00314062
I0701 15:08:26.154439  1052 solver.cpp:354] Sparsity after update:
I0701 15:08:26.155815  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:08:26.155823  1052 net.cpp:1851] conv1a_param_0(0.4) 
I0701 15:08:26.155830  1052 net.cpp:1851] conv1b_param_0(0.8) 
I0701 15:08:26.155834  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:08:26.155838  1052 net.cpp:1851] res2a_branch2a_param_0(0.8) 
I0701 15:08:26.155843  1052 net.cpp:1851] res2a_branch2b_param_0(0.8) 
I0701 15:08:26.155848  1052 net.cpp:1851] res3a_branch2a_param_0(0.8) 
I0701 15:08:26.155851  1052 net.cpp:1851] res3a_branch2b_param_0(0.8) 
I0701 15:08:26.155855  1052 net.cpp:1851] res4a_branch2a_param_0(0.8) 
I0701 15:08:26.155859  1052 net.cpp:1851] res4a_branch2b_param_0(0.8) 
I0701 15:08:26.155864  1052 net.cpp:1851] res5a_branch2a_param_0(0.8) 
I0701 15:08:26.155869  1052 net.cpp:1851] res5a_branch2b_param_0(0.8) 
I0701 15:08:26.155872  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.88286e+06/2.3599e+06) 0.798
I0701 15:08:26.156006  1052 solver.cpp:473] Iteration 44000, Testing net (#0)
I0701 15:08:27.795007  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8943
I0701 15:08:27.795027  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9939
I0701 15:08:27.795032  1052 solver.cpp:546]     Test net output #2: loss = 0.3171 (* 1 = 0.3171 loss)
I0701 15:08:27.814724  1052 solver.cpp:290] Iteration 44000 (26.9178 iter/s, 3.71501s/100 iter), loss = 0
I0701 15:08:27.814740  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:08:27.814754  1052 sgd_solver.cpp:106] Iteration 44000, lr = 0.003125
I0701 15:08:29.889102  1052 solver.cpp:290] Iteration 44100 (48.209 iter/s, 2.0743s/100 iter), loss = 0
I0701 15:08:29.889124  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:08:29.889132  1052 sgd_solver.cpp:106] Iteration 44100, lr = 0.00310938
I0701 15:08:31.960598  1052 solver.cpp:290] Iteration 44200 (48.2763 iter/s, 2.07141s/100 iter), loss = 0
I0701 15:08:31.960619  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:08:31.960628  1052 sgd_solver.cpp:106] Iteration 44200, lr = 0.00309375
I0701 15:08:34.034138  1052 solver.cpp:290] Iteration 44300 (48.2287 iter/s, 2.07345s/100 iter), loss = 0
I0701 15:08:34.034159  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:08:34.034167  1052 sgd_solver.cpp:106] Iteration 44300, lr = 0.00307812
I0701 15:08:36.113406  1052 solver.cpp:290] Iteration 44400 (48.0958 iter/s, 2.07918s/100 iter), loss = 0
I0701 15:08:36.113428  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:08:36.113435  1052 sgd_solver.cpp:106] Iteration 44400, lr = 0.0030625
I0701 15:08:38.188180  1052 solver.cpp:290] Iteration 44500 (48.2 iter/s, 2.07469s/100 iter), loss = 0
I0701 15:08:38.188202  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:08:38.188208  1052 sgd_solver.cpp:106] Iteration 44500, lr = 0.00304687
I0701 15:08:40.263411  1052 solver.cpp:290] Iteration 44600 (48.1894 iter/s, 2.07514s/100 iter), loss = 0
I0701 15:08:40.263443  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:08:40.263450  1052 sgd_solver.cpp:106] Iteration 44600, lr = 0.00303125
I0701 15:08:42.332327  1052 solver.cpp:290] Iteration 44700 (48.3367 iter/s, 2.06882s/100 iter), loss = 0
I0701 15:08:42.332352  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:08:42.332358  1052 sgd_solver.cpp:106] Iteration 44700, lr = 0.00301562
I0701 15:08:44.403625  1052 solver.cpp:290] Iteration 44800 (48.281 iter/s, 2.07121s/100 iter), loss = 0.047619
I0701 15:08:44.403650  1052 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 15:08:44.403657  1052 sgd_solver.cpp:106] Iteration 44800, lr = 0.003
I0701 15:08:46.477176  1052 solver.cpp:290] Iteration 44900 (48.2285 iter/s, 2.07346s/100 iter), loss = 0
I0701 15:08:46.477198  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:08:46.477206  1052 sgd_solver.cpp:106] Iteration 44900, lr = 0.00298437
I0701 15:08:48.528331  1052 solver.cpp:354] Sparsity after update:
I0701 15:08:48.529670  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:08:48.529676  1052 net.cpp:1851] conv1a_param_0(0.4) 
I0701 15:08:48.529685  1052 net.cpp:1851] conv1b_param_0(0.8) 
I0701 15:08:48.529686  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:08:48.529688  1052 net.cpp:1851] res2a_branch2a_param_0(0.8) 
I0701 15:08:48.529690  1052 net.cpp:1851] res2a_branch2b_param_0(0.8) 
I0701 15:08:48.529693  1052 net.cpp:1851] res3a_branch2a_param_0(0.8) 
I0701 15:08:48.529695  1052 net.cpp:1851] res3a_branch2b_param_0(0.8) 
I0701 15:08:48.529697  1052 net.cpp:1851] res4a_branch2a_param_0(0.8) 
I0701 15:08:48.529700  1052 net.cpp:1851] res4a_branch2b_param_0(0.8) 
I0701 15:08:48.529701  1052 net.cpp:1851] res5a_branch2a_param_0(0.8) 
I0701 15:08:48.529705  1052 net.cpp:1851] res5a_branch2b_param_0(0.8) 
I0701 15:08:48.529706  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.88286e+06/2.3599e+06) 0.798
I0701 15:08:48.529795  1052 solver.cpp:473] Iteration 45000, Testing net (#0)
I0701 15:08:50.169348  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8957
I0701 15:08:50.169368  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9949
I0701 15:08:50.169373  1052 solver.cpp:546]     Test net output #2: loss = 0.2967 (* 1 = 0.2967 loss)
I0701 15:08:50.189182  1052 solver.cpp:290] Iteration 45000 (26.9405 iter/s, 3.71188s/100 iter), loss = 0
I0701 15:08:50.189198  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:08:50.189211  1052 sgd_solver.cpp:106] Iteration 45000, lr = 0.00296875
I0701 15:08:52.262703  1052 solver.cpp:290] Iteration 45100 (48.229 iter/s, 2.07344s/100 iter), loss = 0
I0701 15:08:52.262725  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:08:52.262732  1052 sgd_solver.cpp:106] Iteration 45100, lr = 0.00295313
I0701 15:08:54.338541  1052 solver.cpp:290] Iteration 45200 (48.1753 iter/s, 2.07575s/100 iter), loss = 0
I0701 15:08:54.338564  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:08:54.338572  1052 sgd_solver.cpp:106] Iteration 45200, lr = 0.0029375
I0701 15:08:56.411126  1052 solver.cpp:290] Iteration 45300 (48.2509 iter/s, 2.0725s/100 iter), loss = 0
I0701 15:08:56.411149  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:08:56.411155  1052 sgd_solver.cpp:106] Iteration 45300, lr = 0.00292188
I0701 15:08:58.514102  1052 solver.cpp:290] Iteration 45400 (47.5536 iter/s, 2.10289s/100 iter), loss = 0
I0701 15:08:58.514124  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:08:58.514132  1052 sgd_solver.cpp:106] Iteration 45400, lr = 0.00290625
I0701 15:09:00.591624  1052 solver.cpp:290] Iteration 45500 (48.1362 iter/s, 2.07744s/100 iter), loss = 0
I0701 15:09:00.591647  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:09:00.591653  1052 sgd_solver.cpp:106] Iteration 45500, lr = 0.00289063
I0701 15:09:02.662837  1052 solver.cpp:290] Iteration 45600 (48.2829 iter/s, 2.07113s/100 iter), loss = 0
I0701 15:09:02.662858  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:09:02.662865  1052 sgd_solver.cpp:106] Iteration 45600, lr = 0.002875
I0701 15:09:04.736812  1052 solver.cpp:290] Iteration 45700 (48.2185 iter/s, 2.07389s/100 iter), loss = 0
I0701 15:09:04.736834  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:09:04.736840  1052 sgd_solver.cpp:106] Iteration 45700, lr = 0.00285937
I0701 15:09:06.817104  1052 solver.cpp:290] Iteration 45800 (48.0721 iter/s, 2.08021s/100 iter), loss = 0
I0701 15:09:06.817127  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:09:06.817136  1052 sgd_solver.cpp:106] Iteration 45800, lr = 0.00284375
I0701 15:09:08.891165  1052 solver.cpp:290] Iteration 45900 (48.2166 iter/s, 2.07397s/100 iter), loss = 0
I0701 15:09:08.891186  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:09:08.891192  1052 sgd_solver.cpp:106] Iteration 45900, lr = 0.00282812
I0701 15:09:10.944818  1052 solver.cpp:354] Sparsity after update:
I0701 15:09:10.946089  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:09:10.946099  1052 net.cpp:1851] conv1a_param_0(0.4) 
I0701 15:09:10.946106  1052 net.cpp:1851] conv1b_param_0(0.8) 
I0701 15:09:10.946110  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:09:10.946120  1052 net.cpp:1851] res2a_branch2a_param_0(0.8) 
I0701 15:09:10.946125  1052 net.cpp:1851] res2a_branch2b_param_0(0.8) 
I0701 15:09:10.946128  1052 net.cpp:1851] res3a_branch2a_param_0(0.8) 
I0701 15:09:10.946132  1052 net.cpp:1851] res3a_branch2b_param_0(0.8) 
I0701 15:09:10.946137  1052 net.cpp:1851] res4a_branch2a_param_0(0.8) 
I0701 15:09:10.946141  1052 net.cpp:1851] res4a_branch2b_param_0(0.8) 
I0701 15:09:10.946146  1052 net.cpp:1851] res5a_branch2a_param_0(0.8) 
I0701 15:09:10.946149  1052 net.cpp:1851] res5a_branch2b_param_0(0.8) 
I0701 15:09:10.946153  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.88286e+06/2.3599e+06) 0.798
I0701 15:09:10.946295  1052 solver.cpp:473] Iteration 46000, Testing net (#0)
I0701 15:09:12.586824  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.8979
I0701 15:09:12.586843  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9961
I0701 15:09:12.586849  1052 solver.cpp:546]     Test net output #2: loss = 0.2837 (* 1 = 0.2837 loss)
I0701 15:09:12.606549  1052 solver.cpp:290] Iteration 46000 (26.9161 iter/s, 3.71526s/100 iter), loss = 0
I0701 15:09:12.606565  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:09:12.606578  1052 sgd_solver.cpp:106] Iteration 46000, lr = 0.0028125
I0701 15:09:14.682991  1052 solver.cpp:290] Iteration 46100 (48.1612 iter/s, 2.07636s/100 iter), loss = 0
I0701 15:09:14.683012  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:09:14.683018  1052 sgd_solver.cpp:106] Iteration 46100, lr = 0.00279688
I0701 15:09:16.756873  1052 solver.cpp:290] Iteration 46200 (48.2207 iter/s, 2.0738s/100 iter), loss = 0
I0701 15:09:16.756896  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:09:16.756902  1052 sgd_solver.cpp:106] Iteration 46200, lr = 0.00278125
I0701 15:09:18.828413  1052 solver.cpp:290] Iteration 46300 (48.2753 iter/s, 2.07145s/100 iter), loss = 0
I0701 15:09:18.828485  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:09:18.828491  1052 sgd_solver.cpp:106] Iteration 46300, lr = 0.00276563
I0701 15:09:20.899452  1052 solver.cpp:290] Iteration 46400 (48.288 iter/s, 2.07091s/100 iter), loss = 0
I0701 15:09:20.899474  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:09:20.899483  1052 sgd_solver.cpp:106] Iteration 46400, lr = 0.00275
I0701 15:09:22.969468  1052 solver.cpp:290] Iteration 46500 (48.3108 iter/s, 2.06993s/100 iter), loss = 0
I0701 15:09:22.969494  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:09:22.969503  1052 sgd_solver.cpp:106] Iteration 46500, lr = 0.00273437
I0701 15:09:25.043545  1052 solver.cpp:290] Iteration 46600 (48.2163 iter/s, 2.07399s/100 iter), loss = 0
I0701 15:09:25.043571  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:09:25.043581  1052 sgd_solver.cpp:106] Iteration 46600, lr = 0.00271875
I0701 15:09:27.116369  1052 solver.cpp:290] Iteration 46700 (48.2454 iter/s, 2.07274s/100 iter), loss = 0
I0701 15:09:27.116396  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:09:27.116405  1052 sgd_solver.cpp:106] Iteration 46700, lr = 0.00270312
I0701 15:09:29.197904  1052 solver.cpp:290] Iteration 46800 (48.0435 iter/s, 2.08145s/100 iter), loss = 0
I0701 15:09:29.197927  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:09:29.197934  1052 sgd_solver.cpp:106] Iteration 46800, lr = 0.0026875
I0701 15:09:31.270699  1052 solver.cpp:290] Iteration 46900 (48.2461 iter/s, 2.07271s/100 iter), loss = 0
I0701 15:09:31.270720  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:09:31.270727  1052 sgd_solver.cpp:106] Iteration 46900, lr = 0.00267187
I0701 15:09:33.320818  1052 solver.cpp:354] Sparsity after update:
I0701 15:09:33.322160  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:09:33.322166  1052 net.cpp:1851] conv1a_param_0(0.4) 
I0701 15:09:33.322173  1052 net.cpp:1851] conv1b_param_0(0.8) 
I0701 15:09:33.322175  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:09:33.322177  1052 net.cpp:1851] res2a_branch2a_param_0(0.8) 
I0701 15:09:33.322180  1052 net.cpp:1851] res2a_branch2b_param_0(0.8) 
I0701 15:09:33.322181  1052 net.cpp:1851] res3a_branch2a_param_0(0.8) 
I0701 15:09:33.322183  1052 net.cpp:1851] res3a_branch2b_param_0(0.8) 
I0701 15:09:33.322185  1052 net.cpp:1851] res4a_branch2a_param_0(0.8) 
I0701 15:09:33.322186  1052 net.cpp:1851] res4a_branch2b_param_0(0.8) 
I0701 15:09:33.322188  1052 net.cpp:1851] res5a_branch2a_param_0(0.8) 
I0701 15:09:33.322190  1052 net.cpp:1851] res5a_branch2b_param_0(0.8) 
I0701 15:09:33.322192  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.88286e+06/2.3599e+06) 0.798
I0701 15:09:33.322275  1052 solver.cpp:473] Iteration 47000, Testing net (#0)
I0701 15:09:34.962116  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9019
I0701 15:09:34.962141  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9959
I0701 15:09:34.962146  1052 solver.cpp:546]     Test net output #2: loss = 0.2848 (* 1 = 0.2848 loss)
I0701 15:09:34.983624  1052 solver.cpp:290] Iteration 47000 (26.9339 iter/s, 3.71279s/100 iter), loss = 0
I0701 15:09:34.983647  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:09:34.983654  1052 sgd_solver.cpp:106] Iteration 47000, lr = 0.00265625
I0701 15:09:37.055693  1052 solver.cpp:290] Iteration 47100 (48.263 iter/s, 2.07198s/100 iter), loss = 0
I0701 15:09:37.055716  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:09:37.055726  1052 sgd_solver.cpp:106] Iteration 47100, lr = 0.00264063
I0701 15:09:39.128352  1052 solver.cpp:290] Iteration 47200 (48.2492 iter/s, 2.07257s/100 iter), loss = 0
I0701 15:09:39.128373  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:09:39.128381  1052 sgd_solver.cpp:106] Iteration 47200, lr = 0.002625
I0701 15:09:41.200176  1052 solver.cpp:290] Iteration 47300 (48.2686 iter/s, 2.07174s/100 iter), loss = 0
I0701 15:09:41.200214  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:09:41.200222  1052 sgd_solver.cpp:106] Iteration 47300, lr = 0.00260938
I0701 15:09:43.270733  1052 solver.cpp:290] Iteration 47400 (48.2985 iter/s, 2.07046s/100 iter), loss = 0
I0701 15:09:43.270756  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:09:43.270764  1052 sgd_solver.cpp:106] Iteration 47400, lr = 0.00259375
I0701 15:09:45.348609  1052 solver.cpp:290] Iteration 47500 (48.1281 iter/s, 2.07779s/100 iter), loss = 0
I0701 15:09:45.348634  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:09:45.348642  1052 sgd_solver.cpp:106] Iteration 47500, lr = 0.00257812
I0701 15:09:47.423852  1052 solver.cpp:290] Iteration 47600 (48.1891 iter/s, 2.07516s/100 iter), loss = 0
I0701 15:09:47.423877  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:09:47.423885  1052 sgd_solver.cpp:106] Iteration 47600, lr = 0.0025625
I0701 15:09:49.494818  1052 solver.cpp:290] Iteration 47700 (48.2887 iter/s, 2.07088s/100 iter), loss = 0
I0701 15:09:49.494886  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:09:49.494894  1052 sgd_solver.cpp:106] Iteration 47700, lr = 0.00254687
I0701 15:09:51.567056  1052 solver.cpp:290] Iteration 47800 (48.26 iter/s, 2.07211s/100 iter), loss = 0
I0701 15:09:51.567080  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:09:51.567085  1052 sgd_solver.cpp:106] Iteration 47800, lr = 0.00253125
I0701 15:09:53.638643  1052 solver.cpp:290] Iteration 47900 (48.2742 iter/s, 2.0715s/100 iter), loss = 0
I0701 15:09:53.638664  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:09:53.638670  1052 sgd_solver.cpp:106] Iteration 47900, lr = 0.00251562
I0701 15:09:55.693048  1052 solver.cpp:354] Sparsity after update:
I0701 15:09:55.694406  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:09:55.694414  1052 net.cpp:1851] conv1a_param_0(0.4) 
I0701 15:09:55.694420  1052 net.cpp:1851] conv1b_param_0(0.8) 
I0701 15:09:55.694423  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:09:55.694425  1052 net.cpp:1851] res2a_branch2a_param_0(0.8) 
I0701 15:09:55.694427  1052 net.cpp:1851] res2a_branch2b_param_0(0.8) 
I0701 15:09:55.694429  1052 net.cpp:1851] res3a_branch2a_param_0(0.8) 
I0701 15:09:55.694432  1052 net.cpp:1851] res3a_branch2b_param_0(0.8) 
I0701 15:09:55.694432  1052 net.cpp:1851] res4a_branch2a_param_0(0.8) 
I0701 15:09:55.694434  1052 net.cpp:1851] res4a_branch2b_param_0(0.8) 
I0701 15:09:55.694437  1052 net.cpp:1851] res5a_branch2a_param_0(0.8) 
I0701 15:09:55.694438  1052 net.cpp:1851] res5a_branch2b_param_0(0.8) 
I0701 15:09:55.694440  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.88286e+06/2.3599e+06) 0.798
I0701 15:09:55.694524  1052 solver.cpp:473] Iteration 48000, Testing net (#0)
I0701 15:09:57.338568  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.904
I0701 15:09:57.338588  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9955
I0701 15:09:57.338593  1052 solver.cpp:546]     Test net output #2: loss = 0.2825 (* 1 = 0.2825 loss)
I0701 15:09:57.358561  1052 solver.cpp:290] Iteration 48000 (26.8832 iter/s, 3.71979s/100 iter), loss = 0
I0701 15:09:57.358579  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:09:57.358592  1052 sgd_solver.cpp:106] Iteration 48000, lr = 0.0025
I0701 15:09:59.431337  1052 solver.cpp:290] Iteration 48100 (48.2464 iter/s, 2.07269s/100 iter), loss = 0
I0701 15:09:59.431360  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:09:59.431366  1052 sgd_solver.cpp:106] Iteration 48100, lr = 0.00248438
I0701 15:10:01.503307  1052 solver.cpp:290] Iteration 48200 (48.2653 iter/s, 2.07188s/100 iter), loss = 0
I0701 15:10:01.503329  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:10:01.503334  1052 sgd_solver.cpp:106] Iteration 48200, lr = 0.00246875
I0701 15:10:03.579568  1052 solver.cpp:290] Iteration 48300 (48.1655 iter/s, 2.07617s/100 iter), loss = 0
I0701 15:10:03.579592  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:10:03.579602  1052 sgd_solver.cpp:106] Iteration 48300, lr = 0.00245313
I0701 15:10:05.661164  1052 solver.cpp:290] Iteration 48400 (48.0422 iter/s, 2.08151s/100 iter), loss = 0
I0701 15:10:05.661188  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:10:05.661195  1052 sgd_solver.cpp:106] Iteration 48400, lr = 0.0024375
I0701 15:10:07.737221  1052 solver.cpp:290] Iteration 48500 (48.1703 iter/s, 2.07597s/100 iter), loss = 0
I0701 15:10:07.737249  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:10:07.737257  1052 sgd_solver.cpp:106] Iteration 48500, lr = 0.00242188
I0701 15:10:09.807723  1052 solver.cpp:290] Iteration 48600 (48.2995 iter/s, 2.07041s/100 iter), loss = 0
I0701 15:10:09.807745  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:10:09.807752  1052 sgd_solver.cpp:106] Iteration 48600, lr = 0.00240625
I0701 15:10:11.878957  1052 solver.cpp:290] Iteration 48700 (48.2824 iter/s, 2.07115s/100 iter), loss = 0
I0701 15:10:11.878998  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:10:11.879005  1052 sgd_solver.cpp:106] Iteration 48700, lr = 0.00239062
I0701 15:10:13.950846  1052 solver.cpp:290] Iteration 48800 (48.2675 iter/s, 2.07179s/100 iter), loss = 0
I0701 15:10:13.950868  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:10:13.950875  1052 sgd_solver.cpp:106] Iteration 48800, lr = 0.002375
I0701 15:10:16.023214  1052 solver.cpp:290] Iteration 48900 (48.256 iter/s, 2.07228s/100 iter), loss = 0
I0701 15:10:16.023236  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:10:16.023242  1052 sgd_solver.cpp:106] Iteration 48900, lr = 0.00235937
I0701 15:10:18.076557  1052 solver.cpp:354] Sparsity after update:
I0701 15:10:18.077757  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:10:18.077765  1052 net.cpp:1851] conv1a_param_0(0.4) 
I0701 15:10:18.077772  1052 net.cpp:1851] conv1b_param_0(0.8) 
I0701 15:10:18.077775  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:10:18.077776  1052 net.cpp:1851] res2a_branch2a_param_0(0.8) 
I0701 15:10:18.077778  1052 net.cpp:1851] res2a_branch2b_param_0(0.8) 
I0701 15:10:18.077780  1052 net.cpp:1851] res3a_branch2a_param_0(0.8) 
I0701 15:10:18.077782  1052 net.cpp:1851] res3a_branch2b_param_0(0.8) 
I0701 15:10:18.077785  1052 net.cpp:1851] res4a_branch2a_param_0(0.8) 
I0701 15:10:18.077786  1052 net.cpp:1851] res4a_branch2b_param_0(0.8) 
I0701 15:10:18.077787  1052 net.cpp:1851] res5a_branch2a_param_0(0.8) 
I0701 15:10:18.077790  1052 net.cpp:1851] res5a_branch2b_param_0(0.8) 
I0701 15:10:18.077791  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.88286e+06/2.3599e+06) 0.798
I0701 15:10:18.077874  1052 solver.cpp:473] Iteration 49000, Testing net (#0)
I0701 15:10:19.717150  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9016
I0701 15:10:19.717247  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9961
I0701 15:10:19.717253  1052 solver.cpp:546]     Test net output #2: loss = 0.2825 (* 1 = 0.2825 loss)
I0701 15:10:19.736929  1052 solver.cpp:290] Iteration 49000 (26.9281 iter/s, 3.71359s/100 iter), loss = 0
I0701 15:10:19.736948  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:10:19.736958  1052 sgd_solver.cpp:106] Iteration 49000, lr = 0.00234375
I0701 15:10:21.813936  1052 solver.cpp:290] Iteration 49100 (48.1481 iter/s, 2.07693s/100 iter), loss = 0.047619
I0701 15:10:21.813958  1052 solver.cpp:309]     Train net output #0: loss = 0.047619 (* 1 = 0.047619 loss)
I0701 15:10:21.813964  1052 sgd_solver.cpp:106] Iteration 49100, lr = 0.00232813
I0701 15:10:23.886368  1052 solver.cpp:290] Iteration 49200 (48.2545 iter/s, 2.07235s/100 iter), loss = 0
I0701 15:10:23.886394  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:10:23.886404  1052 sgd_solver.cpp:106] Iteration 49200, lr = 0.0023125
I0701 15:10:25.959590  1052 solver.cpp:290] Iteration 49300 (48.2362 iter/s, 2.07313s/100 iter), loss = 0
I0701 15:10:25.959614  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:10:25.959619  1052 sgd_solver.cpp:106] Iteration 49300, lr = 0.00229687
I0701 15:10:28.032434  1052 solver.cpp:290] Iteration 49400 (48.245 iter/s, 2.07276s/100 iter), loss = 0
I0701 15:10:28.032457  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:10:28.032464  1052 sgd_solver.cpp:106] Iteration 49400, lr = 0.00228125
I0701 15:10:30.105556  1052 solver.cpp:290] Iteration 49500 (48.2384 iter/s, 2.07304s/100 iter), loss = 0
I0701 15:10:30.105576  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:10:30.105584  1052 sgd_solver.cpp:106] Iteration 49500, lr = 0.00226562
I0701 15:10:32.175570  1052 solver.cpp:290] Iteration 49600 (48.3108 iter/s, 2.06993s/100 iter), loss = 0
I0701 15:10:32.175591  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:10:32.175598  1052 sgd_solver.cpp:106] Iteration 49600, lr = 0.00225
I0701 15:10:34.253938  1052 solver.cpp:290] Iteration 49700 (48.1166 iter/s, 2.07828s/100 iter), loss = 0
I0701 15:10:34.253962  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:10:34.253968  1052 sgd_solver.cpp:106] Iteration 49700, lr = 0.00223437
I0701 15:10:36.327270  1052 solver.cpp:290] Iteration 49800 (48.2335 iter/s, 2.07325s/100 iter), loss = 0
I0701 15:10:36.327292  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:10:36.327301  1052 sgd_solver.cpp:106] Iteration 49800, lr = 0.00221875
I0701 15:10:38.405032  1052 solver.cpp:290] Iteration 49900 (48.1307 iter/s, 2.07768s/100 iter), loss = 0
I0701 15:10:38.405055  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:10:38.405061  1052 sgd_solver.cpp:106] Iteration 49900, lr = 0.00220312
I0701 15:10:40.457765  1052 solver.cpp:600] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/sparse/cifar10_jacintonet11v2_iter_50000.caffemodel
I0701 15:10:40.474093  1052 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/sparse/cifar10_jacintonet11v2_iter_50000.solverstate
I0701 15:10:40.481266  1052 solver.cpp:354] Sparsity after update:
I0701 15:10:40.482187  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:10:40.482195  1052 net.cpp:1851] conv1a_param_0(0.4) 
I0701 15:10:40.482206  1052 net.cpp:1851] conv1b_param_0(0.8) 
I0701 15:10:40.482210  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:10:40.482215  1052 net.cpp:1851] res2a_branch2a_param_0(0.8) 
I0701 15:10:40.482219  1052 net.cpp:1851] res2a_branch2b_param_0(0.8) 
I0701 15:10:40.482224  1052 net.cpp:1851] res3a_branch2a_param_0(0.8) 
I0701 15:10:40.482228  1052 net.cpp:1851] res3a_branch2b_param_0(0.8) 
I0701 15:10:40.482233  1052 net.cpp:1851] res4a_branch2a_param_0(0.8) 
I0701 15:10:40.482236  1052 net.cpp:1851] res4a_branch2b_param_0(0.8) 
I0701 15:10:40.482249  1052 net.cpp:1851] res5a_branch2a_param_0(0.8) 
I0701 15:10:40.482254  1052 net.cpp:1851] res5a_branch2b_param_0(0.8) 
I0701 15:10:40.482257  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.88286e+06/2.3599e+06) 0.798
I0701 15:10:40.482355  1052 solver.cpp:473] Iteration 50000, Testing net (#0)
I0701 15:10:42.122045  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9035
I0701 15:10:42.122066  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9963
I0701 15:10:42.122072  1052 solver.cpp:546]     Test net output #2: loss = 0.2867 (* 1 = 0.2867 loss)
I0701 15:10:42.141832  1052 solver.cpp:290] Iteration 50000 (26.7618 iter/s, 3.73667s/100 iter), loss = 0
I0701 15:10:42.141854  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:10:42.141861  1052 sgd_solver.cpp:106] Iteration 50000, lr = 0.0021875
I0701 15:10:44.219882  1052 solver.cpp:290] Iteration 50100 (48.124 iter/s, 2.07797s/100 iter), loss = 0
I0701 15:10:44.219903  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:10:44.219911  1052 sgd_solver.cpp:106] Iteration 50100, lr = 0.00217188
I0701 15:10:46.291302  1052 solver.cpp:290] Iteration 50200 (48.2781 iter/s, 2.07133s/100 iter), loss = 0
I0701 15:10:46.291326  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:10:46.291334  1052 sgd_solver.cpp:106] Iteration 50200, lr = 0.00215625
I0701 15:10:48.360561  1052 solver.cpp:290] Iteration 50300 (48.3285 iter/s, 2.06917s/100 iter), loss = 0
I0701 15:10:48.360586  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:10:48.360595  1052 sgd_solver.cpp:106] Iteration 50300, lr = 0.00214063
I0701 15:10:50.431143  1052 solver.cpp:290] Iteration 50400 (48.2977 iter/s, 2.07049s/100 iter), loss = 0
I0701 15:10:50.431252  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:10:50.431264  1052 sgd_solver.cpp:106] Iteration 50400, lr = 0.002125
I0701 15:10:52.503648  1052 solver.cpp:290] Iteration 50500 (48.2547 iter/s, 2.07234s/100 iter), loss = 0
I0701 15:10:52.503674  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:10:52.503682  1052 sgd_solver.cpp:106] Iteration 50500, lr = 0.00210937
I0701 15:10:54.575570  1052 solver.cpp:290] Iteration 50600 (48.2664 iter/s, 2.07184s/100 iter), loss = 0
I0701 15:10:54.575595  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:10:54.575603  1052 sgd_solver.cpp:106] Iteration 50600, lr = 0.00209375
I0701 15:10:56.648465  1052 solver.cpp:290] Iteration 50700 (48.2437 iter/s, 2.07281s/100 iter), loss = 0
I0701 15:10:56.648488  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:10:56.648494  1052 sgd_solver.cpp:106] Iteration 50700, lr = 0.00207812
I0701 15:10:58.729655  1052 solver.cpp:290] Iteration 50800 (48.0514 iter/s, 2.0811s/100 iter), loss = 0
I0701 15:10:58.729676  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:10:58.729683  1052 sgd_solver.cpp:106] Iteration 50800, lr = 0.0020625
I0701 15:11:00.802285  1052 solver.cpp:290] Iteration 50900 (48.2498 iter/s, 2.07255s/100 iter), loss = 0
I0701 15:11:00.802306  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:11:00.802314  1052 sgd_solver.cpp:106] Iteration 50900, lr = 0.00204687
I0701 15:11:02.855078  1052 solver.cpp:354] Sparsity after update:
I0701 15:11:02.856420  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:11:02.856426  1052 net.cpp:1851] conv1a_param_0(0.4) 
I0701 15:11:02.856434  1052 net.cpp:1851] conv1b_param_0(0.8) 
I0701 15:11:02.856436  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:11:02.856439  1052 net.cpp:1851] res2a_branch2a_param_0(0.8) 
I0701 15:11:02.856441  1052 net.cpp:1851] res2a_branch2b_param_0(0.8) 
I0701 15:11:02.856443  1052 net.cpp:1851] res3a_branch2a_param_0(0.8) 
I0701 15:11:02.856447  1052 net.cpp:1851] res3a_branch2b_param_0(0.8) 
I0701 15:11:02.856448  1052 net.cpp:1851] res4a_branch2a_param_0(0.8) 
I0701 15:11:02.856451  1052 net.cpp:1851] res4a_branch2b_param_0(0.8) 
I0701 15:11:02.856453  1052 net.cpp:1851] res5a_branch2a_param_0(0.8) 
I0701 15:11:02.856456  1052 net.cpp:1851] res5a_branch2b_param_0(0.8) 
I0701 15:11:02.856457  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.88286e+06/2.3599e+06) 0.798
I0701 15:11:02.856542  1052 solver.cpp:473] Iteration 51000, Testing net (#0)
I0701 15:11:04.495090  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9029
I0701 15:11:04.495110  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.996
I0701 15:11:04.495115  1052 solver.cpp:546]     Test net output #2: loss = 0.2855 (* 1 = 0.2855 loss)
I0701 15:11:04.515501  1052 solver.cpp:290] Iteration 51000 (26.9317 iter/s, 3.71309s/100 iter), loss = 0
I0701 15:11:04.515518  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:11:04.515530  1052 sgd_solver.cpp:106] Iteration 51000, lr = 0.00203125
I0701 15:11:06.586220  1052 solver.cpp:290] Iteration 51100 (48.2943 iter/s, 2.07064s/100 iter), loss = 0
I0701 15:11:06.586242  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:11:06.586248  1052 sgd_solver.cpp:106] Iteration 51100, lr = 0.00201563
I0701 15:11:08.660064  1052 solver.cpp:290] Iteration 51200 (48.2216 iter/s, 2.07376s/100 iter), loss = 0
I0701 15:11:08.660085  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:11:08.660094  1052 sgd_solver.cpp:106] Iteration 51200, lr = 0.002
I0701 15:11:10.731592  1052 solver.cpp:290] Iteration 51300 (48.2755 iter/s, 2.07144s/100 iter), loss = 0
I0701 15:11:10.731613  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:11:10.731621  1052 sgd_solver.cpp:106] Iteration 51300, lr = 0.00198438
I0701 15:11:12.806778  1052 solver.cpp:290] Iteration 51400 (48.1904 iter/s, 2.0751s/100 iter), loss = 0
I0701 15:11:12.806818  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:11:12.806828  1052 sgd_solver.cpp:106] Iteration 51400, lr = 0.00196875
I0701 15:11:14.880406  1052 solver.cpp:290] Iteration 51500 (48.227 iter/s, 2.07353s/100 iter), loss = 0
I0701 15:11:14.880430  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:11:14.880439  1052 sgd_solver.cpp:106] Iteration 51500, lr = 0.00195312
I0701 15:11:16.955579  1052 solver.cpp:290] Iteration 51600 (48.1907 iter/s, 2.07509s/100 iter), loss = 0
I0701 15:11:16.955602  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:11:16.955608  1052 sgd_solver.cpp:106] Iteration 51600, lr = 0.0019375
I0701 15:11:19.027704  1052 solver.cpp:290] Iteration 51700 (48.2617 iter/s, 2.07204s/100 iter), loss = 0.0952381
I0701 15:11:19.027726  1052 solver.cpp:309]     Train net output #0: loss = 0.0952381 (* 1 = 0.0952381 loss)
I0701 15:11:19.027734  1052 sgd_solver.cpp:106] Iteration 51700, lr = 0.00192187
I0701 15:11:21.103821  1052 solver.cpp:290] Iteration 51800 (48.1689 iter/s, 2.07603s/100 iter), loss = 0
I0701 15:11:21.103899  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:11:21.103910  1052 sgd_solver.cpp:106] Iteration 51800, lr = 0.00190625
I0701 15:11:23.175449  1052 solver.cpp:290] Iteration 51900 (48.2744 iter/s, 2.07149s/100 iter), loss = 0
I0701 15:11:23.175473  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:11:23.175482  1052 sgd_solver.cpp:106] Iteration 51900, lr = 0.00189062
I0701 15:11:25.231765  1052 solver.cpp:354] Sparsity after update:
I0701 15:11:25.233068  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:11:25.233074  1052 net.cpp:1851] conv1a_param_0(0.4) 
I0701 15:11:25.233083  1052 net.cpp:1851] conv1b_param_0(0.8) 
I0701 15:11:25.233084  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:11:25.233088  1052 net.cpp:1851] res2a_branch2a_param_0(0.8) 
I0701 15:11:25.233089  1052 net.cpp:1851] res2a_branch2b_param_0(0.8) 
I0701 15:11:25.233090  1052 net.cpp:1851] res3a_branch2a_param_0(0.8) 
I0701 15:11:25.233093  1052 net.cpp:1851] res3a_branch2b_param_0(0.8) 
I0701 15:11:25.233095  1052 net.cpp:1851] res4a_branch2a_param_0(0.8) 
I0701 15:11:25.233098  1052 net.cpp:1851] res4a_branch2b_param_0(0.8) 
I0701 15:11:25.233099  1052 net.cpp:1851] res5a_branch2a_param_0(0.8) 
I0701 15:11:25.233101  1052 net.cpp:1851] res5a_branch2b_param_0(0.8) 
I0701 15:11:25.233104  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.88286e+06/2.3599e+06) 0.798
I0701 15:11:25.233187  1052 solver.cpp:473] Iteration 52000, Testing net (#0)
I0701 15:11:26.870683  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9053
I0701 15:11:26.870702  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9957
I0701 15:11:26.870707  1052 solver.cpp:546]     Test net output #2: loss = 0.2838 (* 1 = 0.2838 loss)
I0701 15:11:26.890326  1052 solver.cpp:290] Iteration 52000 (26.9197 iter/s, 3.71475s/100 iter), loss = 0
I0701 15:11:26.890341  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:11:26.890357  1052 sgd_solver.cpp:106] Iteration 52000, lr = 0.001875
I0701 15:11:28.964016  1052 solver.cpp:290] Iteration 52100 (48.225 iter/s, 2.07361s/100 iter), loss = 0
I0701 15:11:28.964038  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:11:28.964045  1052 sgd_solver.cpp:106] Iteration 52100, lr = 0.00185938
I0701 15:11:31.037461  1052 solver.cpp:290] Iteration 52200 (48.231 iter/s, 2.07336s/100 iter), loss = 0
I0701 15:11:31.037485  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:11:31.037492  1052 sgd_solver.cpp:106] Iteration 52200, lr = 0.00184375
I0701 15:11:33.114460  1052 solver.cpp:290] Iteration 52300 (48.1485 iter/s, 2.07691s/100 iter), loss = 0
I0701 15:11:33.114483  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:11:33.114492  1052 sgd_solver.cpp:106] Iteration 52300, lr = 0.00182813
I0701 15:11:35.188736  1052 solver.cpp:290] Iteration 52400 (48.2116 iter/s, 2.07419s/100 iter), loss = 0
I0701 15:11:35.188763  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:11:35.188772  1052 sgd_solver.cpp:106] Iteration 52400, lr = 0.0018125
I0701 15:11:37.266635  1052 solver.cpp:290] Iteration 52500 (48.1276 iter/s, 2.07781s/100 iter), loss = 0
I0701 15:11:37.266656  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:11:37.266662  1052 sgd_solver.cpp:106] Iteration 52500, lr = 0.00179687
I0701 15:11:39.340826  1052 solver.cpp:290] Iteration 52600 (48.2135 iter/s, 2.07411s/100 iter), loss = 0
I0701 15:11:39.340848  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:11:39.340855  1052 sgd_solver.cpp:106] Iteration 52600, lr = 0.00178125
I0701 15:11:41.417341  1052 solver.cpp:290] Iteration 52700 (48.1596 iter/s, 2.07643s/100 iter), loss = 0
I0701 15:11:41.417363  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:11:41.417369  1052 sgd_solver.cpp:106] Iteration 52700, lr = 0.00176562
I0701 15:11:43.489948  1052 solver.cpp:290] Iteration 52800 (48.2504 iter/s, 2.07252s/100 iter), loss = 0
I0701 15:11:43.489990  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:11:43.489997  1052 sgd_solver.cpp:106] Iteration 52800, lr = 0.00175
I0701 15:11:45.564388  1052 solver.cpp:290] Iteration 52900 (48.2082 iter/s, 2.07434s/100 iter), loss = 0
I0701 15:11:45.564411  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:11:45.564419  1052 sgd_solver.cpp:106] Iteration 52900, lr = 0.00173437
I0701 15:11:47.622789  1052 solver.cpp:354] Sparsity after update:
I0701 15:11:47.623976  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:11:47.623983  1052 net.cpp:1851] conv1a_param_0(0.4) 
I0701 15:11:47.623991  1052 net.cpp:1851] conv1b_param_0(0.8) 
I0701 15:11:47.623993  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:11:47.623996  1052 net.cpp:1851] res2a_branch2a_param_0(0.8) 
I0701 15:11:47.623998  1052 net.cpp:1851] res2a_branch2b_param_0(0.8) 
I0701 15:11:47.624001  1052 net.cpp:1851] res3a_branch2a_param_0(0.8) 
I0701 15:11:47.624002  1052 net.cpp:1851] res3a_branch2b_param_0(0.8) 
I0701 15:11:47.624004  1052 net.cpp:1851] res4a_branch2a_param_0(0.8) 
I0701 15:11:47.624007  1052 net.cpp:1851] res4a_branch2b_param_0(0.8) 
I0701 15:11:47.624009  1052 net.cpp:1851] res5a_branch2a_param_0(0.8) 
I0701 15:11:47.624012  1052 net.cpp:1851] res5a_branch2b_param_0(0.8) 
I0701 15:11:47.624014  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.88286e+06/2.3599e+06) 0.798
I0701 15:11:47.624097  1052 solver.cpp:473] Iteration 53000, Testing net (#0)
I0701 15:11:49.262186  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9054
I0701 15:11:49.262204  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9965
I0701 15:11:49.262209  1052 solver.cpp:546]     Test net output #2: loss = 0.2805 (* 1 = 0.2805 loss)
I0701 15:11:49.281908  1052 solver.cpp:290] Iteration 53000 (26.9006 iter/s, 3.71739s/100 iter), loss = 0
I0701 15:11:49.281926  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:11:49.281939  1052 sgd_solver.cpp:106] Iteration 53000, lr = 0.00171875
I0701 15:11:51.358696  1052 solver.cpp:290] Iteration 53100 (48.1532 iter/s, 2.07671s/100 iter), loss = 0
I0701 15:11:51.358752  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:11:51.358759  1052 sgd_solver.cpp:106] Iteration 53100, lr = 0.00170313
I0701 15:11:53.430172  1052 solver.cpp:290] Iteration 53200 (48.2775 iter/s, 2.07136s/100 iter), loss = 0
I0701 15:11:53.430194  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:11:53.430200  1052 sgd_solver.cpp:106] Iteration 53200, lr = 0.0016875
I0701 15:11:55.502728  1052 solver.cpp:290] Iteration 53300 (48.2516 iter/s, 2.07247s/100 iter), loss = 0
I0701 15:11:55.502750  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:11:55.502758  1052 sgd_solver.cpp:106] Iteration 53300, lr = 0.00167188
I0701 15:11:57.596928  1052 solver.cpp:290] Iteration 53400 (47.7529 iter/s, 2.09411s/100 iter), loss = 0
I0701 15:11:57.596951  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:11:57.596957  1052 sgd_solver.cpp:106] Iteration 53400, lr = 0.00165625
I0701 15:11:59.668181  1052 solver.cpp:290] Iteration 53500 (48.282 iter/s, 2.07117s/100 iter), loss = 0
I0701 15:11:59.668206  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:11:59.668215  1052 sgd_solver.cpp:106] Iteration 53500, lr = 0.00164062
I0701 15:12:01.742238  1052 solver.cpp:290] Iteration 53600 (48.2167 iter/s, 2.07397s/100 iter), loss = 0
I0701 15:12:01.742260  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:12:01.742267  1052 sgd_solver.cpp:106] Iteration 53600, lr = 0.001625
I0701 15:12:03.819176  1052 solver.cpp:290] Iteration 53700 (48.1498 iter/s, 2.07685s/100 iter), loss = 0
I0701 15:12:03.819198  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:12:03.819205  1052 sgd_solver.cpp:106] Iteration 53700, lr = 0.00160937
I0701 15:12:05.891324  1052 solver.cpp:290] Iteration 53800 (48.2611 iter/s, 2.07206s/100 iter), loss = 0
I0701 15:12:05.891345  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:12:05.891352  1052 sgd_solver.cpp:106] Iteration 53800, lr = 0.00159375
I0701 15:12:07.968186  1052 solver.cpp:290] Iteration 53900 (48.1515 iter/s, 2.07678s/100 iter), loss = 0
I0701 15:12:07.968209  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:12:07.968215  1052 sgd_solver.cpp:106] Iteration 53900, lr = 0.00157812
I0701 15:12:10.022521  1052 solver.cpp:354] Sparsity after update:
I0701 15:12:10.023880  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:12:10.023887  1052 net.cpp:1851] conv1a_param_0(0.4) 
I0701 15:12:10.023895  1052 net.cpp:1851] conv1b_param_0(0.8) 
I0701 15:12:10.023897  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:12:10.023900  1052 net.cpp:1851] res2a_branch2a_param_0(0.8) 
I0701 15:12:10.023902  1052 net.cpp:1851] res2a_branch2b_param_0(0.8) 
I0701 15:12:10.023905  1052 net.cpp:1851] res3a_branch2a_param_0(0.8) 
I0701 15:12:10.023906  1052 net.cpp:1851] res3a_branch2b_param_0(0.8) 
I0701 15:12:10.023908  1052 net.cpp:1851] res4a_branch2a_param_0(0.8) 
I0701 15:12:10.023911  1052 net.cpp:1851] res4a_branch2b_param_0(0.8) 
I0701 15:12:10.023913  1052 net.cpp:1851] res5a_branch2a_param_0(0.8) 
I0701 15:12:10.023916  1052 net.cpp:1851] res5a_branch2b_param_0(0.8) 
I0701 15:12:10.023917  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.88286e+06/2.3599e+06) 0.798
I0701 15:12:10.024049  1052 solver.cpp:473] Iteration 54000, Testing net (#0)
I0701 15:12:11.663216  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9057
I0701 15:12:11.663234  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9959
I0701 15:12:11.663239  1052 solver.cpp:546]     Test net output #2: loss = 0.2807 (* 1 = 0.2807 loss)
I0701 15:12:11.683423  1052 solver.cpp:290] Iteration 54000 (26.9171 iter/s, 3.71511s/100 iter), loss = 0
I0701 15:12:11.683440  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:12:11.683454  1052 sgd_solver.cpp:106] Iteration 54000, lr = 0.0015625
I0701 15:12:13.756001  1052 solver.cpp:290] Iteration 54100 (48.251 iter/s, 2.0725s/100 iter), loss = 0
I0701 15:12:13.756033  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:12:13.756041  1052 sgd_solver.cpp:106] Iteration 54100, lr = 0.00154688
I0701 15:12:15.835737  1052 solver.cpp:290] Iteration 54200 (48.0852 iter/s, 2.07964s/100 iter), loss = 0
I0701 15:12:15.835768  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:12:15.835778  1052 sgd_solver.cpp:106] Iteration 54200, lr = 0.00153125
I0701 15:12:17.906008  1052 solver.cpp:290] Iteration 54300 (48.305 iter/s, 2.07018s/100 iter), loss = 0
I0701 15:12:17.906035  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:12:17.906044  1052 sgd_solver.cpp:106] Iteration 54300, lr = 0.00151563
I0701 15:12:19.976718  1052 solver.cpp:290] Iteration 54400 (48.2947 iter/s, 2.07062s/100 iter), loss = 0
I0701 15:12:19.976742  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:12:19.976750  1052 sgd_solver.cpp:106] Iteration 54400, lr = 0.0015
I0701 15:12:22.050171  1052 solver.cpp:290] Iteration 54500 (48.2307 iter/s, 2.07337s/100 iter), loss = 0
I0701 15:12:22.050272  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:12:22.050281  1052 sgd_solver.cpp:106] Iteration 54500, lr = 0.00148437
I0701 15:12:24.122274  1052 solver.cpp:290] Iteration 54600 (48.2639 iter/s, 2.07194s/100 iter), loss = 0
I0701 15:12:24.122294  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:12:24.122303  1052 sgd_solver.cpp:106] Iteration 54600, lr = 0.00146875
I0701 15:12:26.194259  1052 solver.cpp:290] Iteration 54700 (48.2649 iter/s, 2.0719s/100 iter), loss = 0
I0701 15:12:26.194280  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:12:26.194288  1052 sgd_solver.cpp:106] Iteration 54700, lr = 0.00145312
I0701 15:12:28.265162  1052 solver.cpp:290] Iteration 54800 (48.2901 iter/s, 2.07082s/100 iter), loss = 0
I0701 15:12:28.265183  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:12:28.265192  1052 sgd_solver.cpp:106] Iteration 54800, lr = 0.0014375
I0701 15:12:30.338882  1052 solver.cpp:290] Iteration 54900 (48.2245 iter/s, 2.07363s/100 iter), loss = 0
I0701 15:12:30.338904  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:12:30.338912  1052 sgd_solver.cpp:106] Iteration 54900, lr = 0.00142187
I0701 15:12:32.388968  1052 solver.cpp:354] Sparsity after update:
I0701 15:12:32.390302  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:12:32.390310  1052 net.cpp:1851] conv1a_param_0(0.4) 
I0701 15:12:32.390321  1052 net.cpp:1851] conv1b_param_0(0.8) 
I0701 15:12:32.390324  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:12:32.390329  1052 net.cpp:1851] res2a_branch2a_param_0(0.8) 
I0701 15:12:32.390332  1052 net.cpp:1851] res2a_branch2b_param_0(0.8) 
I0701 15:12:32.390336  1052 net.cpp:1851] res3a_branch2a_param_0(0.8) 
I0701 15:12:32.390341  1052 net.cpp:1851] res3a_branch2b_param_0(0.8) 
I0701 15:12:32.390344  1052 net.cpp:1851] res4a_branch2a_param_0(0.8) 
I0701 15:12:32.390348  1052 net.cpp:1851] res4a_branch2b_param_0(0.8) 
I0701 15:12:32.390353  1052 net.cpp:1851] res5a_branch2a_param_0(0.8) 
I0701 15:12:32.390357  1052 net.cpp:1851] res5a_branch2b_param_0(0.8) 
I0701 15:12:32.390360  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.88286e+06/2.3599e+06) 0.798
I0701 15:12:32.390455  1052 solver.cpp:473] Iteration 55000, Testing net (#0)
I0701 15:12:34.030294  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9046
I0701 15:12:34.030313  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9958
I0701 15:12:34.030319  1052 solver.cpp:546]     Test net output #2: loss = 0.2785 (* 1 = 0.2785 loss)
I0701 15:12:34.050891  1052 solver.cpp:290] Iteration 55000 (26.9405 iter/s, 3.71188s/100 iter), loss = 0
I0701 15:12:34.050909  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:12:34.050920  1052 sgd_solver.cpp:106] Iteration 55000, lr = 0.00140625
I0701 15:12:36.127663  1052 solver.cpp:290] Iteration 55100 (48.1535 iter/s, 2.07669s/100 iter), loss = 0
I0701 15:12:36.127686  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:12:36.127693  1052 sgd_solver.cpp:106] Iteration 55100, lr = 0.00139063
I0701 15:12:38.204151  1052 solver.cpp:290] Iteration 55200 (48.1602 iter/s, 2.0764s/100 iter), loss = 0
I0701 15:12:38.204170  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:12:38.204179  1052 sgd_solver.cpp:106] Iteration 55200, lr = 0.001375
I0701 15:12:40.282009  1052 solver.cpp:290] Iteration 55300 (48.1284 iter/s, 2.07778s/100 iter), loss = 0
I0701 15:12:40.282032  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:12:40.282039  1052 sgd_solver.cpp:106] Iteration 55300, lr = 0.00135938
I0701 15:12:42.359025  1052 solver.cpp:290] Iteration 55400 (48.148 iter/s, 2.07693s/100 iter), loss = 0
I0701 15:12:42.359047  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:12:42.359053  1052 sgd_solver.cpp:106] Iteration 55400, lr = 0.00134375
I0701 15:12:44.432562  1052 solver.cpp:290] Iteration 55500 (48.2288 iter/s, 2.07345s/100 iter), loss = 0
I0701 15:12:44.432602  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:12:44.432610  1052 sgd_solver.cpp:106] Iteration 55500, lr = 0.00132813
I0701 15:12:46.505254  1052 solver.cpp:290] Iteration 55600 (48.2488 iter/s, 2.07259s/100 iter), loss = 0
I0701 15:12:46.505275  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:12:46.505281  1052 sgd_solver.cpp:106] Iteration 55600, lr = 0.0013125
I0701 15:12:48.580217  1052 solver.cpp:290] Iteration 55700 (48.1956 iter/s, 2.07488s/100 iter), loss = 0
I0701 15:12:48.580237  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:12:48.580245  1052 sgd_solver.cpp:106] Iteration 55700, lr = 0.00129687
I0701 15:12:50.653173  1052 solver.cpp:290] Iteration 55800 (48.2422 iter/s, 2.07287s/100 iter), loss = 0
I0701 15:12:50.653195  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:12:50.653203  1052 sgd_solver.cpp:106] Iteration 55800, lr = 0.00128125
I0701 15:12:52.725404  1052 solver.cpp:290] Iteration 55900 (48.2592 iter/s, 2.07214s/100 iter), loss = 0
I0701 15:12:52.725464  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:12:52.725472  1052 sgd_solver.cpp:106] Iteration 55900, lr = 0.00126562
I0701 15:12:54.777276  1052 solver.cpp:354] Sparsity after update:
I0701 15:12:54.778620  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:12:54.778626  1052 net.cpp:1851] conv1a_param_0(0.4) 
I0701 15:12:54.778633  1052 net.cpp:1851] conv1b_param_0(0.8) 
I0701 15:12:54.778635  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:12:54.778638  1052 net.cpp:1851] res2a_branch2a_param_0(0.8) 
I0701 15:12:54.778640  1052 net.cpp:1851] res2a_branch2b_param_0(0.8) 
I0701 15:12:54.778641  1052 net.cpp:1851] res3a_branch2a_param_0(0.8) 
I0701 15:12:54.778643  1052 net.cpp:1851] res3a_branch2b_param_0(0.8) 
I0701 15:12:54.778645  1052 net.cpp:1851] res4a_branch2a_param_0(0.8) 
I0701 15:12:54.778647  1052 net.cpp:1851] res4a_branch2b_param_0(0.8) 
I0701 15:12:54.778650  1052 net.cpp:1851] res5a_branch2a_param_0(0.8) 
I0701 15:12:54.778651  1052 net.cpp:1851] res5a_branch2b_param_0(0.8) 
I0701 15:12:54.778653  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.88286e+06/2.3599e+06) 0.798
I0701 15:12:54.778741  1052 solver.cpp:473] Iteration 56000, Testing net (#0)
I0701 15:12:56.417760  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9047
I0701 15:12:56.417779  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9957
I0701 15:12:56.417784  1052 solver.cpp:546]     Test net output #2: loss = 0.2795 (* 1 = 0.2795 loss)
I0701 15:12:56.437500  1052 solver.cpp:290] Iteration 56000 (26.9401 iter/s, 3.71193s/100 iter), loss = 0
I0701 15:12:56.437517  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:12:56.437531  1052 sgd_solver.cpp:106] Iteration 56000, lr = 0.00125
I0701 15:12:58.536512  1052 solver.cpp:290] Iteration 56100 (47.6433 iter/s, 2.09893s/100 iter), loss = 0
I0701 15:12:58.536533  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:12:58.536541  1052 sgd_solver.cpp:106] Iteration 56100, lr = 0.00123438
I0701 15:13:00.608695  1052 solver.cpp:290] Iteration 56200 (48.2603 iter/s, 2.0721s/100 iter), loss = 0
I0701 15:13:00.608721  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:00.608727  1052 sgd_solver.cpp:106] Iteration 56200, lr = 0.00121875
I0701 15:13:02.685567  1052 solver.cpp:290] Iteration 56300 (48.1514 iter/s, 2.07678s/100 iter), loss = 0
I0701 15:13:02.685591  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:02.685598  1052 sgd_solver.cpp:106] Iteration 56300, lr = 0.00120313
I0701 15:13:04.759958  1052 solver.cpp:290] Iteration 56400 (48.209 iter/s, 2.0743s/100 iter), loss = 0
I0701 15:13:04.759982  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:04.759991  1052 sgd_solver.cpp:106] Iteration 56400, lr = 0.0011875
I0701 15:13:06.833923  1052 solver.cpp:290] Iteration 56500 (48.2188 iter/s, 2.07388s/100 iter), loss = 0
I0701 15:13:06.833947  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:06.833956  1052 sgd_solver.cpp:106] Iteration 56500, lr = 0.00117187
I0701 15:13:08.912364  1052 solver.cpp:290] Iteration 56600 (48.115 iter/s, 2.07835s/100 iter), loss = 0
I0701 15:13:08.912385  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:08.912394  1052 sgd_solver.cpp:106] Iteration 56600, lr = 0.00115625
I0701 15:13:10.988057  1052 solver.cpp:290] Iteration 56700 (48.1786 iter/s, 2.07561s/100 iter), loss = 0
I0701 15:13:10.988082  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:10.988090  1052 sgd_solver.cpp:106] Iteration 56700, lr = 0.00114062
I0701 15:13:13.073343  1052 solver.cpp:290] Iteration 56800 (47.957 iter/s, 2.0852s/100 iter), loss = 0
I0701 15:13:13.073364  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:13.073371  1052 sgd_solver.cpp:106] Iteration 56800, lr = 0.001125
I0701 15:13:15.149099  1052 solver.cpp:290] Iteration 56900 (48.1772 iter/s, 2.07567s/100 iter), loss = 0
I0701 15:13:15.149142  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:15.149152  1052 sgd_solver.cpp:106] Iteration 56900, lr = 0.00110937
I0701 15:13:17.201664  1052 solver.cpp:354] Sparsity after update:
I0701 15:13:17.203236  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:13:17.203246  1052 net.cpp:1851] conv1a_param_0(0.4) 
I0701 15:13:17.203253  1052 net.cpp:1851] conv1b_param_0(0.8) 
I0701 15:13:17.203256  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:13:17.203258  1052 net.cpp:1851] res2a_branch2a_param_0(0.8) 
I0701 15:13:17.203263  1052 net.cpp:1851] res2a_branch2b_param_0(0.8) 
I0701 15:13:17.203264  1052 net.cpp:1851] res3a_branch2a_param_0(0.8) 
I0701 15:13:17.203265  1052 net.cpp:1851] res3a_branch2b_param_0(0.8) 
I0701 15:13:17.203268  1052 net.cpp:1851] res4a_branch2a_param_0(0.8) 
I0701 15:13:17.203269  1052 net.cpp:1851] res4a_branch2b_param_0(0.8) 
I0701 15:13:17.203271  1052 net.cpp:1851] res5a_branch2a_param_0(0.8) 
I0701 15:13:17.203274  1052 net.cpp:1851] res5a_branch2b_param_0(0.8) 
I0701 15:13:17.203275  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.88286e+06/2.3599e+06) 0.798
I0701 15:13:17.203371  1052 solver.cpp:473] Iteration 57000, Testing net (#0)
I0701 15:13:18.842630  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9062
I0701 15:13:18.842648  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9959
I0701 15:13:18.842653  1052 solver.cpp:546]     Test net output #2: loss = 0.2791 (* 1 = 0.2791 loss)
I0701 15:13:18.862259  1052 solver.cpp:290] Iteration 57000 (26.9323 iter/s, 3.71302s/100 iter), loss = 0
I0701 15:13:18.862274  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:18.862289  1052 sgd_solver.cpp:106] Iteration 57000, lr = 0.00109375
I0701 15:13:20.931884  1052 solver.cpp:290] Iteration 57100 (48.3198 iter/s, 2.06955s/100 iter), loss = 0
I0701 15:13:20.931905  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:20.931912  1052 sgd_solver.cpp:106] Iteration 57100, lr = 0.00107813
I0701 15:13:23.004346  1052 solver.cpp:290] Iteration 57200 (48.2537 iter/s, 2.07238s/100 iter), loss = 0
I0701 15:13:23.004396  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:23.004403  1052 sgd_solver.cpp:106] Iteration 57200, lr = 0.0010625
I0701 15:13:25.076750  1052 solver.cpp:290] Iteration 57300 (48.2557 iter/s, 2.07229s/100 iter), loss = 0
I0701 15:13:25.076771  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:25.076777  1052 sgd_solver.cpp:106] Iteration 57300, lr = 0.00104688
I0701 15:13:27.150394  1052 solver.cpp:290] Iteration 57400 (48.2263 iter/s, 2.07356s/100 iter), loss = 0
I0701 15:13:27.150416  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:27.150423  1052 sgd_solver.cpp:106] Iteration 57400, lr = 0.00103125
I0701 15:13:29.223793  1052 solver.cpp:290] Iteration 57500 (48.232 iter/s, 2.07331s/100 iter), loss = 0
I0701 15:13:29.223816  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:29.223822  1052 sgd_solver.cpp:106] Iteration 57500, lr = 0.00101562
I0701 15:13:31.298455  1052 solver.cpp:290] Iteration 57600 (48.2026 iter/s, 2.07458s/100 iter), loss = 0
I0701 15:13:31.298477  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:31.298485  1052 sgd_solver.cpp:106] Iteration 57600, lr = 0.001
I0701 15:13:33.370314  1052 solver.cpp:290] Iteration 57700 (48.2678 iter/s, 2.07177s/100 iter), loss = 0
I0701 15:13:33.370337  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:33.370343  1052 sgd_solver.cpp:106] Iteration 57700, lr = 0.000984375
I0701 15:13:35.442553  1052 solver.cpp:290] Iteration 57800 (48.259 iter/s, 2.07215s/100 iter), loss = 0
I0701 15:13:35.442575  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:35.442581  1052 sgd_solver.cpp:106] Iteration 57800, lr = 0.00096875
I0701 15:13:37.513998  1052 solver.cpp:290] Iteration 57900 (48.2775 iter/s, 2.07136s/100 iter), loss = 0
I0701 15:13:37.514019  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:37.514026  1052 sgd_solver.cpp:106] Iteration 57900, lr = 0.000953125
I0701 15:13:39.566022  1052 solver.cpp:354] Sparsity after update:
I0701 15:13:39.567350  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:13:39.567356  1052 net.cpp:1851] conv1a_param_0(0.4) 
I0701 15:13:39.567368  1052 net.cpp:1851] conv1b_param_0(0.8) 
I0701 15:13:39.567373  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:13:39.567378  1052 net.cpp:1851] res2a_branch2a_param_0(0.8) 
I0701 15:13:39.567380  1052 net.cpp:1851] res2a_branch2b_param_0(0.8) 
I0701 15:13:39.567384  1052 net.cpp:1851] res3a_branch2a_param_0(0.8) 
I0701 15:13:39.567389  1052 net.cpp:1851] res3a_branch2b_param_0(0.8) 
I0701 15:13:39.567394  1052 net.cpp:1851] res4a_branch2a_param_0(0.8) 
I0701 15:13:39.567397  1052 net.cpp:1851] res4a_branch2b_param_0(0.8) 
I0701 15:13:39.567401  1052 net.cpp:1851] res5a_branch2a_param_0(0.8) 
I0701 15:13:39.567404  1052 net.cpp:1851] res5a_branch2b_param_0(0.8) 
I0701 15:13:39.567409  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.88286e+06/2.3599e+06) 0.798
I0701 15:13:39.567498  1052 solver.cpp:473] Iteration 58000, Testing net (#0)
I0701 15:13:41.209810  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9051
I0701 15:13:41.209839  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9959
I0701 15:13:41.209846  1052 solver.cpp:546]     Test net output #2: loss = 0.2799 (* 1 = 0.2799 loss)
I0701 15:13:41.229954  1052 solver.cpp:290] Iteration 58000 (26.9119 iter/s, 3.71583s/100 iter), loss = 0
I0701 15:13:41.229982  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:41.229992  1052 sgd_solver.cpp:106] Iteration 58000, lr = 0.0009375
I0701 15:13:43.302819  1052 solver.cpp:290] Iteration 58100 (48.2445 iter/s, 2.07277s/100 iter), loss = 0
I0701 15:13:43.302839  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:43.302846  1052 sgd_solver.cpp:106] Iteration 58100, lr = 0.000921875
I0701 15:13:45.378139  1052 solver.cpp:290] Iteration 58200 (48.1874 iter/s, 2.07523s/100 iter), loss = 0
I0701 15:13:45.378186  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:45.378196  1052 sgd_solver.cpp:106] Iteration 58200, lr = 0.00090625
I0701 15:13:47.448849  1052 solver.cpp:290] Iteration 58300 (48.2951 iter/s, 2.0706s/100 iter), loss = 0
I0701 15:13:47.448874  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:47.448880  1052 sgd_solver.cpp:106] Iteration 58300, lr = 0.000890625
I0701 15:13:49.521821  1052 solver.cpp:290] Iteration 58400 (48.2419 iter/s, 2.07289s/100 iter), loss = 0
I0701 15:13:49.521842  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:49.521850  1052 sgd_solver.cpp:106] Iteration 58400, lr = 0.000875
I0701 15:13:51.595252  1052 solver.cpp:290] Iteration 58500 (48.2312 iter/s, 2.07335s/100 iter), loss = 0
I0701 15:13:51.595273  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:51.595279  1052 sgd_solver.cpp:106] Iteration 58500, lr = 0.000859375
I0701 15:13:53.668828  1052 solver.cpp:290] Iteration 58600 (48.2279 iter/s, 2.07349s/100 iter), loss = 0
I0701 15:13:53.668905  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:53.668912  1052 sgd_solver.cpp:106] Iteration 58600, lr = 0.00084375
I0701 15:13:55.742139  1052 solver.cpp:290] Iteration 58700 (48.2352 iter/s, 2.07317s/100 iter), loss = 0
I0701 15:13:55.742161  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:55.742167  1052 sgd_solver.cpp:106] Iteration 58700, lr = 0.000828125
I0701 15:13:57.818140  1052 solver.cpp:290] Iteration 58800 (48.1715 iter/s, 2.07592s/100 iter), loss = 0
I0701 15:13:57.818161  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:57.818169  1052 sgd_solver.cpp:106] Iteration 58800, lr = 0.0008125
I0701 15:13:59.892568  1052 solver.cpp:290] Iteration 58900 (48.208 iter/s, 2.07434s/100 iter), loss = 0
I0701 15:13:59.892590  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:13:59.892596  1052 sgd_solver.cpp:106] Iteration 58900, lr = 0.000796875
I0701 15:14:01.947872  1052 solver.cpp:354] Sparsity after update:
I0701 15:14:01.949209  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:14:01.949216  1052 net.cpp:1851] conv1a_param_0(0.4) 
I0701 15:14:01.949223  1052 net.cpp:1851] conv1b_param_0(0.8) 
I0701 15:14:01.949225  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:14:01.949228  1052 net.cpp:1851] res2a_branch2a_param_0(0.8) 
I0701 15:14:01.949229  1052 net.cpp:1851] res2a_branch2b_param_0(0.8) 
I0701 15:14:01.949231  1052 net.cpp:1851] res3a_branch2a_param_0(0.8) 
I0701 15:14:01.949234  1052 net.cpp:1851] res3a_branch2b_param_0(0.8) 
I0701 15:14:01.949235  1052 net.cpp:1851] res4a_branch2a_param_0(0.8) 
I0701 15:14:01.949237  1052 net.cpp:1851] res4a_branch2b_param_0(0.8) 
I0701 15:14:01.949239  1052 net.cpp:1851] res5a_branch2a_param_0(0.8) 
I0701 15:14:01.949240  1052 net.cpp:1851] res5a_branch2b_param_0(0.8) 
I0701 15:14:01.949242  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.88286e+06/2.3599e+06) 0.798
I0701 15:14:01.949334  1052 solver.cpp:473] Iteration 59000, Testing net (#0)
I0701 15:14:03.588155  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9065
I0701 15:14:03.588174  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9961
I0701 15:14:03.588179  1052 solver.cpp:546]     Test net output #2: loss = 0.2745 (* 1 = 0.2745 loss)
I0701 15:14:03.607730  1052 solver.cpp:290] Iteration 59000 (26.9176 iter/s, 3.71504s/100 iter), loss = 0
I0701 15:14:03.607746  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:14:03.607760  1052 sgd_solver.cpp:106] Iteration 59000, lr = 0.00078125
I0701 15:14:05.681505  1052 solver.cpp:290] Iteration 59100 (48.2231 iter/s, 2.0737s/100 iter), loss = 0
I0701 15:14:05.681526  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:14:05.681533  1052 sgd_solver.cpp:106] Iteration 59100, lr = 0.000765625
I0701 15:14:07.752403  1052 solver.cpp:290] Iteration 59200 (48.2902 iter/s, 2.07081s/100 iter), loss = 0
I0701 15:14:07.752424  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:14:07.752430  1052 sgd_solver.cpp:106] Iteration 59200, lr = 0.00075
I0701 15:14:09.823225  1052 solver.cpp:290] Iteration 59300 (48.292 iter/s, 2.07074s/100 iter), loss = 0
I0701 15:14:09.823248  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:14:09.823254  1052 sgd_solver.cpp:106] Iteration 59300, lr = 0.000734375
I0701 15:14:11.896019  1052 solver.cpp:290] Iteration 59400 (48.246 iter/s, 2.07271s/100 iter), loss = 0
I0701 15:14:11.896041  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:14:11.896049  1052 sgd_solver.cpp:106] Iteration 59400, lr = 0.00071875
I0701 15:14:13.972677  1052 solver.cpp:290] Iteration 59500 (48.1563 iter/s, 2.07657s/100 iter), loss = 0
I0701 15:14:13.972702  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:14:13.972712  1052 sgd_solver.cpp:106] Iteration 59500, lr = 0.000703125
I0701 15:14:16.047492  1052 solver.cpp:290] Iteration 59600 (48.1991 iter/s, 2.07473s/100 iter), loss = 0
I0701 15:14:16.047538  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:14:16.047547  1052 sgd_solver.cpp:106] Iteration 59600, lr = 0.0006875
I0701 15:14:18.124919  1052 solver.cpp:290] Iteration 59700 (48.1389 iter/s, 2.07732s/100 iter), loss = 0
I0701 15:14:18.124940  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:14:18.124948  1052 sgd_solver.cpp:106] Iteration 59700, lr = 0.000671875
I0701 15:14:20.196146  1052 solver.cpp:290] Iteration 59800 (48.2825 iter/s, 2.07114s/100 iter), loss = 0
I0701 15:14:20.196168  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:14:20.196175  1052 sgd_solver.cpp:106] Iteration 59800, lr = 0.00065625
I0701 15:14:22.268791  1052 solver.cpp:290] Iteration 59900 (48.2496 iter/s, 2.07256s/100 iter), loss = 0
I0701 15:14:22.268816  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:14:22.268826  1052 sgd_solver.cpp:106] Iteration 59900, lr = 0.000640625
I0701 15:14:24.328308  1052 solver.cpp:600] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/sparse/cifar10_jacintonet11v2_iter_60000.caffemodel
I0701 15:14:24.365751  1052 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/sparse/cifar10_jacintonet11v2_iter_60000.solverstate
I0701 15:14:24.372896  1052 solver.cpp:354] Sparsity after update:
I0701 15:14:24.373841  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:14:24.373847  1052 net.cpp:1851] conv1a_param_0(0.4) 
I0701 15:14:24.373855  1052 net.cpp:1851] conv1b_param_0(0.8) 
I0701 15:14:24.373857  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:14:24.373859  1052 net.cpp:1851] res2a_branch2a_param_0(0.8) 
I0701 15:14:24.373862  1052 net.cpp:1851] res2a_branch2b_param_0(0.8) 
I0701 15:14:24.373863  1052 net.cpp:1851] res3a_branch2a_param_0(0.8) 
I0701 15:14:24.373865  1052 net.cpp:1851] res3a_branch2b_param_0(0.8) 
I0701 15:14:24.373867  1052 net.cpp:1851] res4a_branch2a_param_0(0.8) 
I0701 15:14:24.373868  1052 net.cpp:1851] res4a_branch2b_param_0(0.8) 
I0701 15:14:24.373870  1052 net.cpp:1851] res5a_branch2a_param_0(0.8) 
I0701 15:14:24.373872  1052 net.cpp:1851] res5a_branch2b_param_0(0.8) 
I0701 15:14:24.373874  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.88286e+06/2.3599e+06) 0.798
I0701 15:14:24.373972  1052 solver.cpp:473] Iteration 60000, Testing net (#0)
I0701 15:14:26.013275  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9069
I0701 15:14:26.013294  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9958
I0701 15:14:26.013299  1052 solver.cpp:546]     Test net output #2: loss = 0.2768 (* 1 = 0.2768 loss)
I0701 15:14:26.033428  1052 solver.cpp:290] Iteration 60000 (26.5639 iter/s, 3.76451s/100 iter), loss = 0
I0701 15:14:26.033447  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:14:26.033458  1052 sgd_solver.cpp:106] Iteration 60000, lr = 0.000625
I0701 15:14:28.104794  1052 solver.cpp:290] Iteration 60100 (48.2792 iter/s, 2.07128s/100 iter), loss = 0
I0701 15:14:28.104816  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:14:28.104825  1052 sgd_solver.cpp:106] Iteration 60100, lr = 0.000609375
I0701 15:14:30.180855  1052 solver.cpp:290] Iteration 60200 (48.1701 iter/s, 2.07598s/100 iter), loss = 0
I0701 15:14:30.180881  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:14:30.180891  1052 sgd_solver.cpp:106] Iteration 60200, lr = 0.00059375
I0701 15:14:32.252279  1052 solver.cpp:290] Iteration 60300 (48.2781 iter/s, 2.07133s/100 iter), loss = 0
I0701 15:14:32.252303  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:14:32.252310  1052 sgd_solver.cpp:106] Iteration 60300, lr = 0.000578125
I0701 15:14:34.329731  1052 solver.cpp:290] Iteration 60400 (48.1379 iter/s, 2.07737s/100 iter), loss = 0
I0701 15:14:34.329751  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:14:34.329759  1052 sgd_solver.cpp:106] Iteration 60400, lr = 0.0005625
I0701 15:14:36.403744  1052 solver.cpp:290] Iteration 60500 (48.2176 iter/s, 2.07393s/100 iter), loss = 0
I0701 15:14:36.403766  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:14:36.403774  1052 sgd_solver.cpp:106] Iteration 60500, lr = 0.000546875
I0701 15:14:38.476310  1052 solver.cpp:290] Iteration 60600 (48.2514 iter/s, 2.07248s/100 iter), loss = 0
I0701 15:14:38.476333  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:14:38.476341  1052 sgd_solver.cpp:106] Iteration 60600, lr = 0.00053125
I0701 15:14:40.547819  1052 solver.cpp:290] Iteration 60700 (48.276 iter/s, 2.07142s/100 iter), loss = 0
I0701 15:14:40.547842  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:14:40.547847  1052 sgd_solver.cpp:106] Iteration 60700, lr = 0.000515625
I0701 15:14:42.624524  1052 solver.cpp:290] Iteration 60800 (48.1552 iter/s, 2.07662s/100 iter), loss = 0
I0701 15:14:42.624546  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:14:42.624553  1052 sgd_solver.cpp:106] Iteration 60800, lr = 0.0005
I0701 15:14:44.697978  1052 solver.cpp:290] Iteration 60900 (48.2307 iter/s, 2.07337s/100 iter), loss = 0
I0701 15:14:44.698000  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:14:44.698006  1052 sgd_solver.cpp:106] Iteration 60900, lr = 0.000484375
I0701 15:14:46.750922  1052 solver.cpp:354] Sparsity after update:
I0701 15:14:46.752250  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:14:46.752257  1052 net.cpp:1851] conv1a_param_0(0.4) 
I0701 15:14:46.752267  1052 net.cpp:1851] conv1b_param_0(0.8) 
I0701 15:14:46.752271  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:14:46.752276  1052 net.cpp:1851] res2a_branch2a_param_0(0.8) 
I0701 15:14:46.752280  1052 net.cpp:1851] res2a_branch2b_param_0(0.8) 
I0701 15:14:46.752285  1052 net.cpp:1851] res3a_branch2a_param_0(0.8) 
I0701 15:14:46.752288  1052 net.cpp:1851] res3a_branch2b_param_0(0.8) 
I0701 15:14:46.752292  1052 net.cpp:1851] res4a_branch2a_param_0(0.8) 
I0701 15:14:46.752296  1052 net.cpp:1851] res4a_branch2b_param_0(0.8) 
I0701 15:14:46.752300  1052 net.cpp:1851] res5a_branch2a_param_0(0.8) 
I0701 15:14:46.752305  1052 net.cpp:1851] res5a_branch2b_param_0(0.8) 
I0701 15:14:46.752308  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.88286e+06/2.3599e+06) 0.798
I0701 15:14:46.752398  1052 solver.cpp:473] Iteration 61000, Testing net (#0)
I0701 15:14:48.392947  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9068
I0701 15:14:48.392966  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9961
I0701 15:14:48.392973  1052 solver.cpp:546]     Test net output #2: loss = 0.2748 (* 1 = 0.2748 loss)
I0701 15:14:48.412914  1052 solver.cpp:290] Iteration 61000 (26.9193 iter/s, 3.71481s/100 iter), loss = 0
I0701 15:14:48.412930  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:14:48.412943  1052 sgd_solver.cpp:106] Iteration 61000, lr = 0.00046875
I0701 15:14:50.487335  1052 solver.cpp:290] Iteration 61100 (48.2081 iter/s, 2.07434s/100 iter), loss = 0
I0701 15:14:50.487359  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:14:50.487366  1052 sgd_solver.cpp:106] Iteration 61100, lr = 0.000453125
I0701 15:14:52.558001  1052 solver.cpp:290] Iteration 61200 (48.2957 iter/s, 2.07058s/100 iter), loss = 0
I0701 15:14:52.558023  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:14:52.558030  1052 sgd_solver.cpp:106] Iteration 61200, lr = 0.0004375
I0701 15:14:54.631311  1052 solver.cpp:290] Iteration 61300 (48.234 iter/s, 2.07323s/100 iter), loss = 0
I0701 15:14:54.631408  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:14:54.631417  1052 sgd_solver.cpp:106] Iteration 61300, lr = 0.000421875
I0701 15:14:56.705013  1052 solver.cpp:290] Iteration 61400 (48.2266 iter/s, 2.07354s/100 iter), loss = 0
I0701 15:14:56.705034  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:14:56.705041  1052 sgd_solver.cpp:106] Iteration 61400, lr = 0.00040625
I0701 15:14:58.785362  1052 solver.cpp:290] Iteration 61500 (48.0708 iter/s, 2.08026s/100 iter), loss = 0
I0701 15:14:58.785384  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:14:58.785393  1052 sgd_solver.cpp:106] Iteration 61500, lr = 0.000390625
I0701 15:15:00.856842  1052 solver.cpp:290] Iteration 61600 (48.2766 iter/s, 2.0714s/100 iter), loss = 0
I0701 15:15:00.856863  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:15:00.856870  1052 sgd_solver.cpp:106] Iteration 61600, lr = 0.000375
I0701 15:15:02.928439  1052 solver.cpp:290] Iteration 61700 (48.2739 iter/s, 2.07151s/100 iter), loss = 0
I0701 15:15:02.928460  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:15:02.928468  1052 sgd_solver.cpp:106] Iteration 61700, lr = 0.000359375
I0701 15:15:05.001509  1052 solver.cpp:290] Iteration 61800 (48.2396 iter/s, 2.07298s/100 iter), loss = 0
I0701 15:15:05.001531  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:15:05.001538  1052 sgd_solver.cpp:106] Iteration 61800, lr = 0.00034375
I0701 15:15:07.075096  1052 solver.cpp:290] Iteration 61900 (48.2276 iter/s, 2.0735s/100 iter), loss = 0
I0701 15:15:07.075117  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:15:07.075125  1052 sgd_solver.cpp:106] Iteration 61900, lr = 0.000328125
I0701 15:15:09.130596  1052 solver.cpp:354] Sparsity after update:
I0701 15:15:09.131899  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:15:09.131906  1052 net.cpp:1851] conv1a_param_0(0.4) 
I0701 15:15:09.131913  1052 net.cpp:1851] conv1b_param_0(0.8) 
I0701 15:15:09.131916  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:15:09.131918  1052 net.cpp:1851] res2a_branch2a_param_0(0.8) 
I0701 15:15:09.131922  1052 net.cpp:1851] res2a_branch2b_param_0(0.8) 
I0701 15:15:09.131923  1052 net.cpp:1851] res3a_branch2a_param_0(0.8) 
I0701 15:15:09.131927  1052 net.cpp:1851] res3a_branch2b_param_0(0.8) 
I0701 15:15:09.131928  1052 net.cpp:1851] res4a_branch2a_param_0(0.8) 
I0701 15:15:09.131932  1052 net.cpp:1851] res4a_branch2b_param_0(0.8) 
I0701 15:15:09.131933  1052 net.cpp:1851] res5a_branch2a_param_0(0.8) 
I0701 15:15:09.131935  1052 net.cpp:1851] res5a_branch2b_param_0(0.8) 
I0701 15:15:09.131937  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.88286e+06/2.3599e+06) 0.798
I0701 15:15:09.132025  1052 solver.cpp:473] Iteration 62000, Testing net (#0)
I0701 15:15:10.770891  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9068
I0701 15:15:10.770910  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9959
I0701 15:15:10.770915  1052 solver.cpp:546]     Test net output #2: loss = 0.2767 (* 1 = 0.2767 loss)
I0701 15:15:10.790518  1052 solver.cpp:290] Iteration 62000 (26.9158 iter/s, 3.7153s/100 iter), loss = 0
I0701 15:15:10.790535  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:15:10.790549  1052 sgd_solver.cpp:106] Iteration 62000, lr = 0.0003125
I0701 15:15:12.861302  1052 solver.cpp:290] Iteration 62100 (48.2928 iter/s, 2.0707s/100 iter), loss = 0
I0701 15:15:12.861335  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:15:12.861344  1052 sgd_solver.cpp:106] Iteration 62100, lr = 0.000296875
I0701 15:15:14.933246  1052 solver.cpp:290] Iteration 62200 (48.266 iter/s, 2.07185s/100 iter), loss = 0
I0701 15:15:14.933274  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:15:14.933284  1052 sgd_solver.cpp:106] Iteration 62200, lr = 0.00028125
I0701 15:15:17.009932  1052 solver.cpp:290] Iteration 62300 (48.1557 iter/s, 2.0766s/100 iter), loss = 0
I0701 15:15:17.009968  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:15:17.009974  1052 sgd_solver.cpp:106] Iteration 62300, lr = 0.000265625
I0701 15:15:19.088891  1052 solver.cpp:290] Iteration 62400 (48.1033 iter/s, 2.07886s/100 iter), loss = 0
I0701 15:15:19.088912  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:15:19.088918  1052 sgd_solver.cpp:106] Iteration 62400, lr = 0.00025
I0701 15:15:21.165277  1052 solver.cpp:290] Iteration 62500 (48.1625 iter/s, 2.0763s/100 iter), loss = 0
I0701 15:15:21.165298  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:15:21.165304  1052 sgd_solver.cpp:106] Iteration 62500, lr = 0.000234375
I0701 15:15:23.238895  1052 solver.cpp:290] Iteration 62600 (48.2269 iter/s, 2.07353s/100 iter), loss = 0
I0701 15:15:23.238917  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:15:23.238924  1052 sgd_solver.cpp:106] Iteration 62600, lr = 0.00021875
I0701 15:15:25.312592  1052 solver.cpp:290] Iteration 62700 (48.2251 iter/s, 2.07361s/100 iter), loss = 0
I0701 15:15:25.312667  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:15:25.312680  1052 sgd_solver.cpp:106] Iteration 62700, lr = 0.000203125
I0701 15:15:27.383777  1052 solver.cpp:290] Iteration 62800 (48.2847 iter/s, 2.07105s/100 iter), loss = 0
I0701 15:15:27.383800  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:15:27.383808  1052 sgd_solver.cpp:106] Iteration 62800, lr = 0.0001875
I0701 15:15:29.465044  1052 solver.cpp:290] Iteration 62900 (48.0497 iter/s, 2.08118s/100 iter), loss = 0
I0701 15:15:29.465066  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:15:29.465075  1052 sgd_solver.cpp:106] Iteration 62900, lr = 0.000171875
I0701 15:15:31.517002  1052 solver.cpp:354] Sparsity after update:
I0701 15:15:31.518321  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:15:31.518328  1052 net.cpp:1851] conv1a_param_0(0.4) 
I0701 15:15:31.518335  1052 net.cpp:1851] conv1b_param_0(0.8) 
I0701 15:15:31.518337  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:15:31.518339  1052 net.cpp:1851] res2a_branch2a_param_0(0.8) 
I0701 15:15:31.518342  1052 net.cpp:1851] res2a_branch2b_param_0(0.8) 
I0701 15:15:31.518343  1052 net.cpp:1851] res3a_branch2a_param_0(0.8) 
I0701 15:15:31.518345  1052 net.cpp:1851] res3a_branch2b_param_0(0.8) 
I0701 15:15:31.518347  1052 net.cpp:1851] res4a_branch2a_param_0(0.8) 
I0701 15:15:31.518348  1052 net.cpp:1851] res4a_branch2b_param_0(0.8) 
I0701 15:15:31.518350  1052 net.cpp:1851] res5a_branch2a_param_0(0.8) 
I0701 15:15:31.518352  1052 net.cpp:1851] res5a_branch2b_param_0(0.8) 
I0701 15:15:31.518354  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.88286e+06/2.3599e+06) 0.798
I0701 15:15:31.518457  1052 solver.cpp:473] Iteration 63000, Testing net (#0)
I0701 15:15:33.159016  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9056
I0701 15:15:33.159035  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9962
I0701 15:15:33.159039  1052 solver.cpp:546]     Test net output #2: loss = 0.2779 (* 1 = 0.2779 loss)
I0701 15:15:33.178573  1052 solver.cpp:290] Iteration 63000 (26.9295 iter/s, 3.7134s/100 iter), loss = 0
I0701 15:15:33.178589  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:15:33.178602  1052 sgd_solver.cpp:106] Iteration 63000, lr = 0.00015625
I0701 15:15:35.257236  1052 solver.cpp:290] Iteration 63100 (48.1097 iter/s, 2.07858s/100 iter), loss = 0
I0701 15:15:35.257261  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:15:35.257269  1052 sgd_solver.cpp:106] Iteration 63100, lr = 0.000140625
I0701 15:15:37.328631  1052 solver.cpp:290] Iteration 63200 (48.2787 iter/s, 2.07131s/100 iter), loss = 0
I0701 15:15:37.328658  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:15:37.328667  1052 sgd_solver.cpp:106] Iteration 63200, lr = 0.000125
I0701 15:15:39.402906  1052 solver.cpp:290] Iteration 63300 (48.2116 iter/s, 2.07419s/100 iter), loss = 0
I0701 15:15:39.402927  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:15:39.402935  1052 sgd_solver.cpp:106] Iteration 63300, lr = 0.000109375
I0701 15:15:41.476460  1052 solver.cpp:290] Iteration 63400 (48.2284 iter/s, 2.07347s/100 iter), loss = 0
I0701 15:15:41.476481  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:15:41.476490  1052 sgd_solver.cpp:106] Iteration 63400, lr = 9.37498e-05
I0701 15:15:43.549033  1052 solver.cpp:290] Iteration 63500 (48.2512 iter/s, 2.07249s/100 iter), loss = 0
I0701 15:15:43.549055  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:15:43.549064  1052 sgd_solver.cpp:106] Iteration 63500, lr = 7.8125e-05
I0701 15:15:45.618161  1052 solver.cpp:290] Iteration 63600 (48.3315 iter/s, 2.06904s/100 iter), loss = 0
I0701 15:15:45.618183  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:15:45.618191  1052 sgd_solver.cpp:106] Iteration 63600, lr = 6.25002e-05
I0701 15:15:47.691979  1052 solver.cpp:290] Iteration 63700 (48.2222 iter/s, 2.07373s/100 iter), loss = 0
I0701 15:15:47.692016  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:15:47.692023  1052 sgd_solver.cpp:106] Iteration 63700, lr = 4.68749e-05
I0701 15:15:49.767176  1052 solver.cpp:290] Iteration 63800 (48.1905 iter/s, 2.0751s/100 iter), loss = 0
I0701 15:15:49.767199  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:15:49.767205  1052 sgd_solver.cpp:106] Iteration 63800, lr = 3.12501e-05
I0701 15:15:51.839397  1052 solver.cpp:290] Iteration 63900 (48.2594 iter/s, 2.07214s/100 iter), loss = 0
I0701 15:15:51.839421  1052 solver.cpp:309]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0701 15:15:51.839426  1052 sgd_solver.cpp:106] Iteration 63900, lr = 1.56248e-05
I0701 15:15:53.894714  1052 solver.cpp:354] Sparsity after update:
I0701 15:15:53.896200  1052 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0701 15:15:53.896208  1052 net.cpp:1851] conv1a_param_0(0.4) 
I0701 15:15:53.896214  1052 net.cpp:1851] conv1b_param_0(0.8) 
I0701 15:15:53.896216  1052 net.cpp:1851] fc10_param_0(0) 
I0701 15:15:53.896219  1052 net.cpp:1851] res2a_branch2a_param_0(0.8) 
I0701 15:15:53.896220  1052 net.cpp:1851] res2a_branch2b_param_0(0.8) 
I0701 15:15:53.896222  1052 net.cpp:1851] res3a_branch2a_param_0(0.8) 
I0701 15:15:53.896224  1052 net.cpp:1851] res3a_branch2b_param_0(0.8) 
I0701 15:15:53.896226  1052 net.cpp:1851] res4a_branch2a_param_0(0.8) 
I0701 15:15:53.896229  1052 net.cpp:1851] res4a_branch2b_param_0(0.8) 
I0701 15:15:53.896230  1052 net.cpp:1851] res5a_branch2a_param_0(0.8) 
I0701 15:15:53.896231  1052 net.cpp:1851] res5a_branch2b_param_0(0.8) 
I0701 15:15:53.896234  1052 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.88286e+06/2.3599e+06) 0.798
I0701 15:15:53.896241  1052 solver.cpp:600] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/sparse/cifar10_jacintonet11v2_iter_64000.caffemodel
I0701 15:15:53.912081  1052 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-07-01_14-28-09/sparse/cifar10_jacintonet11v2_iter_64000.solverstate
I0701 15:15:53.923957  1052 solver.cpp:453] Iteration 64000, loss = 0
I0701 15:15:53.923976  1052 solver.cpp:473] Iteration 64000, Testing net (#0)
I0701 15:15:55.562881  1052 solver.cpp:546]     Test net output #0: accuracy/top1 = 0.9074
I0701 15:15:55.562994  1052 solver.cpp:546]     Test net output #1: accuracy/top5 = 0.9961
I0701 15:15:55.563000  1052 solver.cpp:546]     Test net output #2: loss = 0.2748 (* 1 = 0.2748 loss)
I0701 15:15:55.563004  1052 solver.cpp:458] Optimization Done.
I0701 15:15:55.607966  1052 caffe.cpp:246] Optimization Done.
training/cifar10_jacintonet11v2_2017-07-01_14-28-09/test
I0701 15:15:56.368963  4639 caffe.cpp:264] Not using GPU #2 for single-GPU function
I0701 15:15:56.370664  4639 caffe.cpp:264] Not using GPU #1 for single-GPU function
I0701 15:15:56.573829  4639 caffe.cpp:273] Use GPU with device ID 0
I0701 15:15:56.574179  4639 caffe.cpp:277] GPU device name: GeForce GTX 1080
I0701 15:15:56.960472  4639 net.cpp:56] Initializing net from parameters: 
name: "jacintonet11v2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: false
    crop_size: 32
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/cifar10_test_lmdb"
    batch_size: 50
    backend: LMDB
    threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a/bn"
  top: "conv1a/bn"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a/bn"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b/bn"
  top: "conv1b/bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b/bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2a/bn"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b/bn"
  top: "res2a_branch2b/bn"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b/bn"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2a/bn"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b/bn"
  top: "res3a_branch2b/bn"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b/bn"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2a/bn"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b/bn"
  top: "res4a_branch2b/bn"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b/bn"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2a/bn"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b/bn"
  top: "res5a_branch2b/bn"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b/bn"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc10"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc10"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "fc10"
  bottom: "label"
  top: "accuracy/top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "fc10"
  bottom: "label"
  top: "accuracy/top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0701 15:15:56.960614  4639 layer_factory.hpp:77] Creating layer data
I0701 15:15:56.960996  4639 net.cpp:98] Creating Layer data
I0701 15:15:56.961005  4639 net.cpp:413] data -> data
I0701 15:15:56.961028  4639 net.cpp:413] data -> label
I0701 15:15:56.962054  4656 db_lmdb.cpp:35] Opened lmdb ./data/cifar10_test_lmdb
I0701 15:15:56.962885  4639 data_layer.cpp:78] ReshapePrefetch 50, 3, 32, 32
I0701 15:15:56.962929  4639 data_layer.cpp:83] output data size: 50,3,32,32
I0701 15:15:56.965003  4639 net.cpp:148] Setting up data
I0701 15:15:56.965024  4639 net.cpp:155] Top shape: 50 3 32 32 (153600)
I0701 15:15:56.965029  4639 net.cpp:155] Top shape: 50 (50)
I0701 15:15:56.965032  4639 net.cpp:163] Memory required for data: 614600
I0701 15:15:56.965042  4639 layer_factory.hpp:77] Creating layer label_data_1_split
I0701 15:15:56.965055  4639 net.cpp:98] Creating Layer label_data_1_split
I0701 15:15:56.965061  4639 net.cpp:439] label_data_1_split <- label
I0701 15:15:56.965070  4639 net.cpp:413] label_data_1_split -> label_data_1_split_0
I0701 15:15:56.965080  4639 net.cpp:413] label_data_1_split -> label_data_1_split_1
I0701 15:15:56.965083  4639 net.cpp:413] label_data_1_split -> label_data_1_split_2
I0701 15:15:56.965124  4639 net.cpp:148] Setting up label_data_1_split
I0701 15:15:56.965129  4639 net.cpp:155] Top shape: 50 (50)
I0701 15:15:56.965132  4639 net.cpp:155] Top shape: 50 (50)
I0701 15:15:56.965137  4639 net.cpp:155] Top shape: 50 (50)
I0701 15:15:56.965139  4639 net.cpp:163] Memory required for data: 615200
I0701 15:15:56.965142  4639 layer_factory.hpp:77] Creating layer data/bias
I0701 15:15:56.965152  4639 net.cpp:98] Creating Layer data/bias
I0701 15:15:56.965155  4639 net.cpp:439] data/bias <- data
I0701 15:15:56.965159  4639 net.cpp:413] data/bias -> data/bias
I0701 15:15:56.965898  4639 net.cpp:148] Setting up data/bias
I0701 15:15:56.965909  4639 net.cpp:155] Top shape: 50 3 32 32 (153600)
I0701 15:15:56.965912  4639 net.cpp:163] Memory required for data: 1229600
I0701 15:15:56.965924  4639 layer_factory.hpp:77] Creating layer conv1a
I0701 15:15:56.965936  4639 net.cpp:98] Creating Layer conv1a
I0701 15:15:56.965940  4639 net.cpp:439] conv1a <- data/bias
I0701 15:15:56.965945  4639 net.cpp:413] conv1a -> conv1a
I0701 15:15:56.967720  4639 net.cpp:148] Setting up conv1a
I0701 15:15:56.967770  4639 net.cpp:155] Top shape: 50 32 32 32 (1638400)
I0701 15:15:56.967787  4639 net.cpp:163] Memory required for data: 7783200
I0701 15:15:56.967804  4639 layer_factory.hpp:77] Creating layer conv1a/bn
I0701 15:15:56.967823  4639 net.cpp:98] Creating Layer conv1a/bn
I0701 15:15:56.967834  4639 net.cpp:439] conv1a/bn <- conv1a
I0701 15:15:56.967849  4639 net.cpp:413] conv1a/bn -> conv1a/bn
I0701 15:15:56.968281  4639 net.cpp:148] Setting up conv1a/bn
I0701 15:15:56.968303  4639 net.cpp:155] Top shape: 50 32 32 32 (1638400)
I0701 15:15:56.968318  4639 net.cpp:163] Memory required for data: 14336800
I0701 15:15:56.968338  4639 layer_factory.hpp:77] Creating layer conv1a/relu
I0701 15:15:56.968354  4639 net.cpp:98] Creating Layer conv1a/relu
I0701 15:15:56.968367  4639 net.cpp:439] conv1a/relu <- conv1a/bn
I0701 15:15:56.968380  4639 net.cpp:400] conv1a/relu -> conv1a/bn (in-place)
I0701 15:15:56.968401  4639 net.cpp:148] Setting up conv1a/relu
I0701 15:15:56.968416  4639 net.cpp:155] Top shape: 50 32 32 32 (1638400)
I0701 15:15:56.968427  4639 net.cpp:163] Memory required for data: 20890400
I0701 15:15:56.968442  4639 layer_factory.hpp:77] Creating layer conv1b
I0701 15:15:56.968459  4639 net.cpp:98] Creating Layer conv1b
I0701 15:15:56.968482  4639 net.cpp:439] conv1b <- conv1a/bn
I0701 15:15:56.968497  4639 net.cpp:413] conv1b -> conv1b
I0701 15:15:56.968752  4639 net.cpp:148] Setting up conv1b
I0701 15:15:56.968773  4639 net.cpp:155] Top shape: 50 32 32 32 (1638400)
I0701 15:15:56.968787  4639 net.cpp:163] Memory required for data: 27444000
I0701 15:15:56.968804  4639 layer_factory.hpp:77] Creating layer conv1b/bn
I0701 15:15:56.968821  4639 net.cpp:98] Creating Layer conv1b/bn
I0701 15:15:56.968832  4639 net.cpp:439] conv1b/bn <- conv1b
I0701 15:15:56.968847  4639 net.cpp:413] conv1b/bn -> conv1b/bn
I0701 15:15:56.969247  4639 net.cpp:148] Setting up conv1b/bn
I0701 15:15:56.969269  4639 net.cpp:155] Top shape: 50 32 32 32 (1638400)
I0701 15:15:56.969282  4639 net.cpp:163] Memory required for data: 33997600
I0701 15:15:56.969300  4639 layer_factory.hpp:77] Creating layer conv1b/relu
I0701 15:15:56.969316  4639 net.cpp:98] Creating Layer conv1b/relu
I0701 15:15:56.969328  4639 net.cpp:439] conv1b/relu <- conv1b/bn
I0701 15:15:56.969341  4639 net.cpp:400] conv1b/relu -> conv1b/bn (in-place)
I0701 15:15:56.969357  4639 net.cpp:148] Setting up conv1b/relu
I0701 15:15:56.969372  4639 net.cpp:155] Top shape: 50 32 32 32 (1638400)
I0701 15:15:56.969383  4639 net.cpp:163] Memory required for data: 40551200
I0701 15:15:56.969394  4639 layer_factory.hpp:77] Creating layer pool1
I0701 15:15:56.969410  4639 net.cpp:98] Creating Layer pool1
I0701 15:15:56.969422  4639 net.cpp:439] pool1 <- conv1b/bn
I0701 15:15:56.969434  4639 net.cpp:413] pool1 -> pool1
I0701 15:15:56.969480  4639 net.cpp:148] Setting up pool1
I0701 15:15:56.969498  4639 net.cpp:155] Top shape: 50 32 32 32 (1638400)
I0701 15:15:56.969509  4639 net.cpp:163] Memory required for data: 47104800
I0701 15:15:56.969521  4639 layer_factory.hpp:77] Creating layer res2a_branch2a
I0701 15:15:56.969537  4639 net.cpp:98] Creating Layer res2a_branch2a
I0701 15:15:56.969549  4639 net.cpp:439] res2a_branch2a <- pool1
I0701 15:15:56.969563  4639 net.cpp:413] res2a_branch2a -> res2a_branch2a
I0701 15:15:56.970973  4639 net.cpp:148] Setting up res2a_branch2a
I0701 15:15:56.971249  4639 net.cpp:155] Top shape: 50 64 32 32 (3276800)
I0701 15:15:56.971263  4639 net.cpp:163] Memory required for data: 60212000
I0701 15:15:56.971282  4639 layer_factory.hpp:77] Creating layer res2a_branch2a/bn
I0701 15:15:56.971299  4639 net.cpp:98] Creating Layer res2a_branch2a/bn
I0701 15:15:56.971313  4639 net.cpp:439] res2a_branch2a/bn <- res2a_branch2a
I0701 15:15:56.971326  4639 net.cpp:413] res2a_branch2a/bn -> res2a_branch2a/bn
I0701 15:15:56.971748  4639 net.cpp:148] Setting up res2a_branch2a/bn
I0701 15:15:56.971770  4639 net.cpp:155] Top shape: 50 64 32 32 (3276800)
I0701 15:15:56.971782  4639 net.cpp:163] Memory required for data: 73319200
I0701 15:15:56.971799  4639 layer_factory.hpp:77] Creating layer res2a_branch2a/relu
I0701 15:15:56.971820  4639 net.cpp:98] Creating Layer res2a_branch2a/relu
I0701 15:15:56.971833  4639 net.cpp:439] res2a_branch2a/relu <- res2a_branch2a/bn
I0701 15:15:56.971845  4639 net.cpp:400] res2a_branch2a/relu -> res2a_branch2a/bn (in-place)
I0701 15:15:56.971861  4639 net.cpp:148] Setting up res2a_branch2a/relu
I0701 15:15:56.971876  4639 net.cpp:155] Top shape: 50 64 32 32 (3276800)
I0701 15:15:56.971887  4639 net.cpp:163] Memory required for data: 86426400
I0701 15:15:56.971899  4639 layer_factory.hpp:77] Creating layer res2a_branch2b
I0701 15:15:56.971913  4639 net.cpp:98] Creating Layer res2a_branch2b
I0701 15:15:56.971925  4639 net.cpp:439] res2a_branch2b <- res2a_branch2a/bn
I0701 15:15:56.971937  4639 net.cpp:413] res2a_branch2b -> res2a_branch2b
I0701 15:15:56.973083  4639 net.cpp:148] Setting up res2a_branch2b
I0701 15:15:56.973109  4639 net.cpp:155] Top shape: 50 64 32 32 (3276800)
I0701 15:15:56.973122  4639 net.cpp:163] Memory required for data: 99533600
I0701 15:15:56.973137  4639 layer_factory.hpp:77] Creating layer res2a_branch2b/bn
I0701 15:15:56.973157  4639 net.cpp:98] Creating Layer res2a_branch2b/bn
I0701 15:15:56.973170  4639 net.cpp:439] res2a_branch2b/bn <- res2a_branch2b
I0701 15:15:56.973192  4639 net.cpp:413] res2a_branch2b/bn -> res2a_branch2b/bn
I0701 15:15:56.973615  4639 net.cpp:148] Setting up res2a_branch2b/bn
I0701 15:15:56.973636  4639 net.cpp:155] Top shape: 50 64 32 32 (3276800)
I0701 15:15:56.973650  4639 net.cpp:163] Memory required for data: 112640800
I0701 15:15:56.973666  4639 layer_factory.hpp:77] Creating layer res2a_branch2b/relu
I0701 15:15:56.973682  4639 net.cpp:98] Creating Layer res2a_branch2b/relu
I0701 15:15:56.973695  4639 net.cpp:439] res2a_branch2b/relu <- res2a_branch2b/bn
I0701 15:15:56.973707  4639 net.cpp:400] res2a_branch2b/relu -> res2a_branch2b/bn (in-place)
I0701 15:15:56.973721  4639 net.cpp:148] Setting up res2a_branch2b/relu
I0701 15:15:56.973737  4639 net.cpp:155] Top shape: 50 64 32 32 (3276800)
I0701 15:15:56.973748  4639 net.cpp:163] Memory required for data: 125748000
I0701 15:15:56.973759  4639 layer_factory.hpp:77] Creating layer pool2
I0701 15:15:56.973773  4639 net.cpp:98] Creating Layer pool2
I0701 15:15:56.973784  4639 net.cpp:439] pool2 <- res2a_branch2b/bn
I0701 15:15:56.973796  4639 net.cpp:413] pool2 -> pool2
I0701 15:15:56.973832  4639 net.cpp:148] Setting up pool2
I0701 15:15:56.973848  4639 net.cpp:155] Top shape: 50 64 16 16 (819200)
I0701 15:15:56.973860  4639 net.cpp:163] Memory required for data: 129024800
I0701 15:15:56.973870  4639 layer_factory.hpp:77] Creating layer res3a_branch2a
I0701 15:15:56.973889  4639 net.cpp:98] Creating Layer res3a_branch2a
I0701 15:15:56.973901  4639 net.cpp:439] res3a_branch2a <- pool2
I0701 15:15:56.973914  4639 net.cpp:413] res3a_branch2a -> res3a_branch2a
I0701 15:15:56.976910  4639 net.cpp:148] Setting up res3a_branch2a
I0701 15:15:56.976943  4639 net.cpp:155] Top shape: 50 128 16 16 (1638400)
I0701 15:15:56.976958  4639 net.cpp:163] Memory required for data: 135578400
I0701 15:15:56.976972  4639 layer_factory.hpp:77] Creating layer res3a_branch2a/bn
I0701 15:15:56.976995  4639 net.cpp:98] Creating Layer res3a_branch2a/bn
I0701 15:15:56.977010  4639 net.cpp:439] res3a_branch2a/bn <- res3a_branch2a
I0701 15:15:56.977023  4639 net.cpp:413] res3a_branch2a/bn -> res3a_branch2a/bn
I0701 15:15:56.977519  4639 net.cpp:148] Setting up res3a_branch2a/bn
I0701 15:15:56.977541  4639 net.cpp:155] Top shape: 50 128 16 16 (1638400)
I0701 15:15:56.977555  4639 net.cpp:163] Memory required for data: 142132000
I0701 15:15:56.977574  4639 layer_factory.hpp:77] Creating layer res3a_branch2a/relu
I0701 15:15:56.977591  4639 net.cpp:98] Creating Layer res3a_branch2a/relu
I0701 15:15:56.977603  4639 net.cpp:439] res3a_branch2a/relu <- res3a_branch2a/bn
I0701 15:15:56.977617  4639 net.cpp:400] res3a_branch2a/relu -> res3a_branch2a/bn (in-place)
I0701 15:15:56.977632  4639 net.cpp:148] Setting up res3a_branch2a/relu
I0701 15:15:56.977646  4639 net.cpp:155] Top shape: 50 128 16 16 (1638400)
I0701 15:15:56.977663  4639 net.cpp:163] Memory required for data: 148685600
I0701 15:15:56.977674  4639 layer_factory.hpp:77] Creating layer res3a_branch2b
I0701 15:15:56.977689  4639 net.cpp:98] Creating Layer res3a_branch2b
I0701 15:15:56.977700  4639 net.cpp:439] res3a_branch2b <- res3a_branch2a/bn
I0701 15:15:56.977713  4639 net.cpp:413] res3a_branch2b -> res3a_branch2b
I0701 15:15:56.978870  4639 net.cpp:148] Setting up res3a_branch2b
I0701 15:15:56.978880  4639 net.cpp:155] Top shape: 50 128 16 16 (1638400)
I0701 15:15:56.978883  4639 net.cpp:163] Memory required for data: 155239200
I0701 15:15:56.978889  4639 layer_factory.hpp:77] Creating layer res3a_branch2b/bn
I0701 15:15:56.978895  4639 net.cpp:98] Creating Layer res3a_branch2b/bn
I0701 15:15:56.978899  4639 net.cpp:439] res3a_branch2b/bn <- res3a_branch2b
I0701 15:15:56.978904  4639 net.cpp:413] res3a_branch2b/bn -> res3a_branch2b/bn
I0701 15:15:56.979192  4639 net.cpp:148] Setting up res3a_branch2b/bn
I0701 15:15:56.979198  4639 net.cpp:155] Top shape: 50 128 16 16 (1638400)
I0701 15:15:56.979200  4639 net.cpp:163] Memory required for data: 161792800
I0701 15:15:56.979205  4639 layer_factory.hpp:77] Creating layer res3a_branch2b/relu
I0701 15:15:56.979216  4639 net.cpp:98] Creating Layer res3a_branch2b/relu
I0701 15:15:56.979218  4639 net.cpp:439] res3a_branch2b/relu <- res3a_branch2b/bn
I0701 15:15:56.979221  4639 net.cpp:400] res3a_branch2b/relu -> res3a_branch2b/bn (in-place)
I0701 15:15:56.979226  4639 net.cpp:148] Setting up res3a_branch2b/relu
I0701 15:15:56.979229  4639 net.cpp:155] Top shape: 50 128 16 16 (1638400)
I0701 15:15:56.979231  4639 net.cpp:163] Memory required for data: 168346400
I0701 15:15:56.979233  4639 layer_factory.hpp:77] Creating layer pool3
I0701 15:15:56.979236  4639 net.cpp:98] Creating Layer pool3
I0701 15:15:56.979238  4639 net.cpp:439] pool3 <- res3a_branch2b/bn
I0701 15:15:56.979241  4639 net.cpp:413] pool3 -> pool3
I0701 15:15:56.979261  4639 net.cpp:148] Setting up pool3
I0701 15:15:56.979267  4639 net.cpp:155] Top shape: 50 128 16 16 (1638400)
I0701 15:15:56.979270  4639 net.cpp:163] Memory required for data: 174900000
I0701 15:15:56.979274  4639 layer_factory.hpp:77] Creating layer res4a_branch2a
I0701 15:15:56.979279  4639 net.cpp:98] Creating Layer res4a_branch2a
I0701 15:15:56.979281  4639 net.cpp:439] res4a_branch2a <- pool3
I0701 15:15:56.979285  4639 net.cpp:413] res4a_branch2a -> res4a_branch2a
I0701 15:15:56.987092  4639 net.cpp:148] Setting up res4a_branch2a
I0701 15:15:56.987114  4639 net.cpp:155] Top shape: 50 256 16 16 (3276800)
I0701 15:15:56.987118  4639 net.cpp:163] Memory required for data: 188007200
I0701 15:15:56.987126  4639 layer_factory.hpp:77] Creating layer res4a_branch2a/bn
I0701 15:15:56.987136  4639 net.cpp:98] Creating Layer res4a_branch2a/bn
I0701 15:15:56.987140  4639 net.cpp:439] res4a_branch2a/bn <- res4a_branch2a
I0701 15:15:56.987146  4639 net.cpp:413] res4a_branch2a/bn -> res4a_branch2a/bn
I0701 15:15:56.987510  4639 net.cpp:148] Setting up res4a_branch2a/bn
I0701 15:15:56.987519  4639 net.cpp:155] Top shape: 50 256 16 16 (3276800)
I0701 15:15:56.987521  4639 net.cpp:163] Memory required for data: 201114400
I0701 15:15:56.987529  4639 layer_factory.hpp:77] Creating layer res4a_branch2a/relu
I0701 15:15:56.987534  4639 net.cpp:98] Creating Layer res4a_branch2a/relu
I0701 15:15:56.987537  4639 net.cpp:439] res4a_branch2a/relu <- res4a_branch2a/bn
I0701 15:15:56.987540  4639 net.cpp:400] res4a_branch2a/relu -> res4a_branch2a/bn (in-place)
I0701 15:15:56.987546  4639 net.cpp:148] Setting up res4a_branch2a/relu
I0701 15:15:56.987550  4639 net.cpp:155] Top shape: 50 256 16 16 (3276800)
I0701 15:15:56.987553  4639 net.cpp:163] Memory required for data: 214221600
I0701 15:15:56.987557  4639 layer_factory.hpp:77] Creating layer res4a_branch2b
I0701 15:15:56.987565  4639 net.cpp:98] Creating Layer res4a_branch2b
I0701 15:15:56.987570  4639 net.cpp:439] res4a_branch2b <- res4a_branch2a/bn
I0701 15:15:56.987573  4639 net.cpp:413] res4a_branch2b -> res4a_branch2b
I0701 15:15:56.991560  4639 net.cpp:148] Setting up res4a_branch2b
I0701 15:15:56.991585  4639 net.cpp:155] Top shape: 50 256 16 16 (3276800)
I0701 15:15:56.991587  4639 net.cpp:163] Memory required for data: 227328800
I0701 15:15:56.991595  4639 layer_factory.hpp:77] Creating layer res4a_branch2b/bn
I0701 15:15:56.991602  4639 net.cpp:98] Creating Layer res4a_branch2b/bn
I0701 15:15:56.991606  4639 net.cpp:439] res4a_branch2b/bn <- res4a_branch2b
I0701 15:15:56.991614  4639 net.cpp:413] res4a_branch2b/bn -> res4a_branch2b/bn
I0701 15:15:56.991989  4639 net.cpp:148] Setting up res4a_branch2b/bn
I0701 15:15:56.991997  4639 net.cpp:155] Top shape: 50 256 16 16 (3276800)
I0701 15:15:56.991999  4639 net.cpp:163] Memory required for data: 240436000
I0701 15:15:56.992007  4639 layer_factory.hpp:77] Creating layer res4a_branch2b/relu
I0701 15:15:56.992012  4639 net.cpp:98] Creating Layer res4a_branch2b/relu
I0701 15:15:56.992014  4639 net.cpp:439] res4a_branch2b/relu <- res4a_branch2b/bn
I0701 15:15:56.992017  4639 net.cpp:400] res4a_branch2b/relu -> res4a_branch2b/bn (in-place)
I0701 15:15:56.992023  4639 net.cpp:148] Setting up res4a_branch2b/relu
I0701 15:15:56.992027  4639 net.cpp:155] Top shape: 50 256 16 16 (3276800)
I0701 15:15:56.992039  4639 net.cpp:163] Memory required for data: 253543200
I0701 15:15:56.992043  4639 layer_factory.hpp:77] Creating layer pool4
I0701 15:15:56.992048  4639 net.cpp:98] Creating Layer pool4
I0701 15:15:56.992053  4639 net.cpp:439] pool4 <- res4a_branch2b/bn
I0701 15:15:56.992056  4639 net.cpp:413] pool4 -> pool4
I0701 15:15:56.992082  4639 net.cpp:148] Setting up pool4
I0701 15:15:56.992087  4639 net.cpp:155] Top shape: 50 256 8 8 (819200)
I0701 15:15:56.992090  4639 net.cpp:163] Memory required for data: 256820000
I0701 15:15:56.992094  4639 layer_factory.hpp:77] Creating layer res5a_branch2a
I0701 15:15:56.992101  4639 net.cpp:98] Creating Layer res5a_branch2a
I0701 15:15:56.992105  4639 net.cpp:439] res5a_branch2a <- pool4
I0701 15:15:56.992110  4639 net.cpp:413] res5a_branch2a -> res5a_branch2a
I0701 15:15:57.024737  4639 net.cpp:148] Setting up res5a_branch2a
I0701 15:15:57.024761  4639 net.cpp:155] Top shape: 50 512 8 8 (1638400)
I0701 15:15:57.024765  4639 net.cpp:163] Memory required for data: 263373600
I0701 15:15:57.024773  4639 layer_factory.hpp:77] Creating layer res5a_branch2a/bn
I0701 15:15:57.024785  4639 net.cpp:98] Creating Layer res5a_branch2a/bn
I0701 15:15:57.024791  4639 net.cpp:439] res5a_branch2a/bn <- res5a_branch2a
I0701 15:15:57.024797  4639 net.cpp:413] res5a_branch2a/bn -> res5a_branch2a/bn
I0701 15:15:57.025182  4639 net.cpp:148] Setting up res5a_branch2a/bn
I0701 15:15:57.025189  4639 net.cpp:155] Top shape: 50 512 8 8 (1638400)
I0701 15:15:57.025192  4639 net.cpp:163] Memory required for data: 269927200
I0701 15:15:57.025202  4639 layer_factory.hpp:77] Creating layer res5a_branch2a/relu
I0701 15:15:57.025215  4639 net.cpp:98] Creating Layer res5a_branch2a/relu
I0701 15:15:57.025219  4639 net.cpp:439] res5a_branch2a/relu <- res5a_branch2a/bn
I0701 15:15:57.025224  4639 net.cpp:400] res5a_branch2a/relu -> res5a_branch2a/bn (in-place)
I0701 15:15:57.025235  4639 net.cpp:148] Setting up res5a_branch2a/relu
I0701 15:15:57.025240  4639 net.cpp:155] Top shape: 50 512 8 8 (1638400)
I0701 15:15:57.025243  4639 net.cpp:163] Memory required for data: 276480800
I0701 15:15:57.025251  4639 layer_factory.hpp:77] Creating layer res5a_branch2b
I0701 15:15:57.025259  4639 net.cpp:98] Creating Layer res5a_branch2b
I0701 15:15:57.025269  4639 net.cpp:439] res5a_branch2b <- res5a_branch2a/bn
I0701 15:15:57.025275  4639 net.cpp:413] res5a_branch2b -> res5a_branch2b
I0701 15:15:57.038326  4639 net.cpp:148] Setting up res5a_branch2b
I0701 15:15:57.038344  4639 net.cpp:155] Top shape: 50 512 8 8 (1638400)
I0701 15:15:57.038347  4639 net.cpp:163] Memory required for data: 283034400
I0701 15:15:57.038354  4639 layer_factory.hpp:77] Creating layer res5a_branch2b/bn
I0701 15:15:57.038362  4639 net.cpp:98] Creating Layer res5a_branch2b/bn
I0701 15:15:57.038364  4639 net.cpp:439] res5a_branch2b/bn <- res5a_branch2b
I0701 15:15:57.038367  4639 net.cpp:413] res5a_branch2b/bn -> res5a_branch2b/bn
I0701 15:15:57.038681  4639 net.cpp:148] Setting up res5a_branch2b/bn
I0701 15:15:57.038688  4639 net.cpp:155] Top shape: 50 512 8 8 (1638400)
I0701 15:15:57.038691  4639 net.cpp:163] Memory required for data: 289588000
I0701 15:15:57.038696  4639 layer_factory.hpp:77] Creating layer res5a_branch2b/relu
I0701 15:15:57.038699  4639 net.cpp:98] Creating Layer res5a_branch2b/relu
I0701 15:15:57.038702  4639 net.cpp:439] res5a_branch2b/relu <- res5a_branch2b/bn
I0701 15:15:57.038703  4639 net.cpp:400] res5a_branch2b/relu -> res5a_branch2b/bn (in-place)
I0701 15:15:57.038707  4639 net.cpp:148] Setting up res5a_branch2b/relu
I0701 15:15:57.038709  4639 net.cpp:155] Top shape: 50 512 8 8 (1638400)
I0701 15:15:57.038712  4639 net.cpp:163] Memory required for data: 296141600
I0701 15:15:57.038713  4639 layer_factory.hpp:77] Creating layer pool5
I0701 15:15:57.038718  4639 net.cpp:98] Creating Layer pool5
I0701 15:15:57.038722  4639 net.cpp:439] pool5 <- res5a_branch2b/bn
I0701 15:15:57.038727  4639 net.cpp:413] pool5 -> pool5
I0701 15:15:57.038749  4639 net.cpp:148] Setting up pool5
I0701 15:15:57.038754  4639 net.cpp:155] Top shape: 50 512 1 1 (25600)
I0701 15:15:57.038763  4639 net.cpp:163] Memory required for data: 296244000
I0701 15:15:57.038765  4639 layer_factory.hpp:77] Creating layer fc10
I0701 15:15:57.038772  4639 net.cpp:98] Creating Layer fc10
I0701 15:15:57.038775  4639 net.cpp:439] fc10 <- pool5
I0701 15:15:57.038777  4639 net.cpp:413] fc10 -> fc10
I0701 15:15:57.038942  4639 net.cpp:148] Setting up fc10
I0701 15:15:57.038947  4639 net.cpp:155] Top shape: 50 10 (500)
I0701 15:15:57.038951  4639 net.cpp:163] Memory required for data: 296246000
I0701 15:15:57.038957  4639 layer_factory.hpp:77] Creating layer fc10_fc10_0_split
I0701 15:15:57.038964  4639 net.cpp:98] Creating Layer fc10_fc10_0_split
I0701 15:15:57.038967  4639 net.cpp:439] fc10_fc10_0_split <- fc10
I0701 15:15:57.038974  4639 net.cpp:413] fc10_fc10_0_split -> fc10_fc10_0_split_0
I0701 15:15:57.038980  4639 net.cpp:413] fc10_fc10_0_split -> fc10_fc10_0_split_1
I0701 15:15:57.038985  4639 net.cpp:413] fc10_fc10_0_split -> fc10_fc10_0_split_2
I0701 15:15:57.039018  4639 net.cpp:148] Setting up fc10_fc10_0_split
I0701 15:15:57.039023  4639 net.cpp:155] Top shape: 50 10 (500)
I0701 15:15:57.039027  4639 net.cpp:155] Top shape: 50 10 (500)
I0701 15:15:57.039041  4639 net.cpp:155] Top shape: 50 10 (500)
I0701 15:15:57.039044  4639 net.cpp:163] Memory required for data: 296252000
I0701 15:15:57.039047  4639 layer_factory.hpp:77] Creating layer loss
I0701 15:15:57.039049  4639 net.cpp:98] Creating Layer loss
I0701 15:15:57.039052  4639 net.cpp:439] loss <- fc10_fc10_0_split_0
I0701 15:15:57.039054  4639 net.cpp:439] loss <- label_data_1_split_0
I0701 15:15:57.039057  4639 net.cpp:413] loss -> loss
I0701 15:15:57.039062  4639 layer_factory.hpp:77] Creating layer loss
I0701 15:15:57.039124  4639 net.cpp:148] Setting up loss
I0701 15:15:57.039129  4639 net.cpp:155] Top shape: (1)
I0701 15:15:57.039134  4639 net.cpp:158]     with loss weight 1
I0701 15:15:57.039146  4639 net.cpp:163] Memory required for data: 296252004
I0701 15:15:57.039149  4639 layer_factory.hpp:77] Creating layer accuracy/top1
I0701 15:15:57.039155  4639 net.cpp:98] Creating Layer accuracy/top1
I0701 15:15:57.039160  4639 net.cpp:439] accuracy/top1 <- fc10_fc10_0_split_1
I0701 15:15:57.039163  4639 net.cpp:439] accuracy/top1 <- label_data_1_split_1
I0701 15:15:57.039170  4639 net.cpp:413] accuracy/top1 -> accuracy/top1
I0701 15:15:57.039177  4639 net.cpp:148] Setting up accuracy/top1
I0701 15:15:57.039181  4639 net.cpp:155] Top shape: (1)
I0701 15:15:57.039186  4639 net.cpp:163] Memory required for data: 296252008
I0701 15:15:57.039189  4639 layer_factory.hpp:77] Creating layer accuracy/top5
I0701 15:15:57.039194  4639 net.cpp:98] Creating Layer accuracy/top5
I0701 15:15:57.039198  4639 net.cpp:439] accuracy/top5 <- fc10_fc10_0_split_2
I0701 15:15:57.039202  4639 net.cpp:439] accuracy/top5 <- label_data_1_split_2
I0701 15:15:57.039208  4639 net.cpp:413] accuracy/top5 -> accuracy/top5
I0701 15:15:57.039216  4639 net.cpp:148] Setting up accuracy/top5
I0701 15:15:57.039222  4639 net.cpp:155] Top shape: (1)
I0701 15:15:57.039224  4639 net.cpp:163] Memory required for data: 296252012
I0701 15:15:57.039228  4639 net.cpp:226] accuracy/top5 does not need backward computation.
I0701 15:15:57.039233  4639 net.cpp:226] accuracy/top1 does not need backward computation.
I0701 15:15:57.039237  4639 net.cpp:224] loss needs backward computation.
I0701 15:15:57.039242  4639 net.cpp:224] fc10_fc10_0_split needs backward computation.
I0701 15:15:57.039247  4639 net.cpp:224] fc10 needs backward computation.
I0701 15:15:57.039249  4639 net.cpp:224] pool5 needs backward computation.
I0701 15:15:57.039253  4639 net.cpp:224] res5a_branch2b/relu needs backward computation.
I0701 15:15:57.039258  4639 net.cpp:224] res5a_branch2b/bn needs backward computation.
I0701 15:15:57.039261  4639 net.cpp:224] res5a_branch2b needs backward computation.
I0701 15:15:57.039266  4639 net.cpp:224] res5a_branch2a/relu needs backward computation.
I0701 15:15:57.039270  4639 net.cpp:224] res5a_branch2a/bn needs backward computation.
I0701 15:15:57.039279  4639 net.cpp:224] res5a_branch2a needs backward computation.
I0701 15:15:57.039283  4639 net.cpp:224] pool4 needs backward computation.
I0701 15:15:57.039288  4639 net.cpp:224] res4a_branch2b/relu needs backward computation.
I0701 15:15:57.039291  4639 net.cpp:224] res4a_branch2b/bn needs backward computation.
I0701 15:15:57.039296  4639 net.cpp:224] res4a_branch2b needs backward computation.
I0701 15:15:57.039300  4639 net.cpp:224] res4a_branch2a/relu needs backward computation.
I0701 15:15:57.039304  4639 net.cpp:224] res4a_branch2a/bn needs backward computation.
I0701 15:15:57.039309  4639 net.cpp:224] res4a_branch2a needs backward computation.
I0701 15:15:57.039312  4639 net.cpp:224] pool3 needs backward computation.
I0701 15:15:57.039317  4639 net.cpp:224] res3a_branch2b/relu needs backward computation.
I0701 15:15:57.039321  4639 net.cpp:224] res3a_branch2b/bn needs backward computation.
I0701 15:15:57.039325  4639 net.cpp:224] res3a_branch2b needs backward computation.
I0701 15:15:57.039330  4639 net.cpp:224] res3a_branch2a/relu needs backward computation.
I0701 15:15:57.039333  4639 net.cpp:224] res3a_branch2a/bn needs backward computation.
I0701 15:15:57.039338  4639 net.cpp:224] res3a_branch2a needs backward computation.
I0701 15:15:57.039342  4639 net.cpp:224] pool2 needs backward computation.
I0701 15:15:57.039346  4639 net.cpp:224] res2a_branch2b/relu needs backward computation.
I0701 15:15:57.039350  4639 net.cpp:224] res2a_branch2b/bn needs backward computation.
I0701 15:15:57.039355  4639 net.cpp:224] res2a_branch2b needs backward computation.
I0701 15:15:57.039360  4639 net.cpp:224] res2a_branch2a/relu needs backward computation.
I0701 15:15:57.039363  4639 net.cpp:224] res2a_branch2a/bn needs backward computation.
I0701 15:15:57.039367  4639 net.cpp:224] res2a_branch2a needs backward computation.
I0701 15:15:57.039372  4639 net.cpp:224] pool1 needs backward computation.
I0701 15:15:57.039376  4639 net.cpp:224] conv1b/relu needs backward computation.
I0701 15:15:57.039381  4639 net.cpp:224] conv1b/bn needs backward computation.
I0701 15:15:57.039384  4639 net.cpp:224] conv1b needs backward computation.
I0701 15:15:57.039389  4639 net.cpp:224] conv1a/relu needs backward computation.
I0701 15:15:57.039393  4639 net.cpp:224] conv1a/bn needs backward computation.
I0701 15:15:57.039397  4639 net.cpp:224] conv1a needs backward computation.
I0701 15:15:57.039402  4639 net.cpp:226] data/bias does not need backward computation.
I0701 15:15:57.039407  4639 net.cpp:226] label_data_1_split does not need backward computation.
I0701 15:15:57.039412  4639 net.cpp:226] data does not need backward computation.
I0701 15:15:57.039415  4639 net.cpp:268] This network produces output accuracy/top1
I0701 15:15:57.039419  4639 net.cpp:268] This network produces output accuracy/top5
I0701 15:15:57.039423  4639 net.cpp:268] This network produces output loss
I0701 15:15:57.039446  4639 net.cpp:288] Network initialization done.
I0701 15:15:57.049998  4639 caffe.cpp:289] Running for 200 iterations.
I0701 15:15:57.072227  4639 caffe.cpp:312] Batch 0, accuracy/top1 = 0.88
I0701 15:15:57.072243  4639 caffe.cpp:312] Batch 0, accuracy/top5 = 1
I0701 15:15:57.072247  4639 caffe.cpp:312] Batch 0, loss = 0.1
I0701 15:15:57.080421  4639 caffe.cpp:312] Batch 1, accuracy/top1 = 0.92
I0701 15:15:57.080430  4639 caffe.cpp:312] Batch 1, accuracy/top5 = 1
I0701 15:15:57.080432  4639 caffe.cpp:312] Batch 1, loss = 0.18
I0701 15:15:57.088606  4639 caffe.cpp:312] Batch 2, accuracy/top1 = 0.96
I0701 15:15:57.088615  4639 caffe.cpp:312] Batch 2, accuracy/top5 = 0.98
I0701 15:15:57.088618  4639 caffe.cpp:312] Batch 2, loss = 0.38
I0701 15:15:57.096827  4639 caffe.cpp:312] Batch 3, accuracy/top1 = 0.9
I0701 15:15:57.096835  4639 caffe.cpp:312] Batch 3, accuracy/top5 = 1
I0701 15:15:57.096840  4639 caffe.cpp:312] Batch 3, loss = 0.2
I0701 15:15:57.105043  4639 caffe.cpp:312] Batch 4, accuracy/top1 = 0.88
I0701 15:15:57.105051  4639 caffe.cpp:312] Batch 4, accuracy/top5 = 1
I0701 15:15:57.105057  4639 caffe.cpp:312] Batch 4, loss = 0.3
I0701 15:15:57.113240  4639 caffe.cpp:312] Batch 5, accuracy/top1 = 0.96
I0701 15:15:57.113247  4639 caffe.cpp:312] Batch 5, accuracy/top5 = 1
I0701 15:15:57.113250  4639 caffe.cpp:312] Batch 5, loss = 0.06
I0701 15:15:57.121495  4639 caffe.cpp:312] Batch 6, accuracy/top1 = 0.96
I0701 15:15:57.121505  4639 caffe.cpp:312] Batch 6, accuracy/top5 = 1
I0701 15:15:57.121507  4639 caffe.cpp:312] Batch 6, loss = 0.2
I0701 15:15:57.129712  4639 caffe.cpp:312] Batch 7, accuracy/top1 = 0.92
I0701 15:15:57.129732  4639 caffe.cpp:312] Batch 7, accuracy/top5 = 0.94
I0701 15:15:57.129735  4639 caffe.cpp:312] Batch 7, loss = 0.54
I0701 15:15:57.140334  4639 caffe.cpp:312] Batch 8, accuracy/top1 = 0.9
I0701 15:15:57.140350  4639 caffe.cpp:312] Batch 8, accuracy/top5 = 1
I0701 15:15:57.140352  4639 caffe.cpp:312] Batch 8, loss = 0.14
I0701 15:15:57.148497  4639 caffe.cpp:312] Batch 9, accuracy/top1 = 0.9
I0701 15:15:57.148505  4639 caffe.cpp:312] Batch 9, accuracy/top5 = 1
I0701 15:15:57.148509  4639 caffe.cpp:312] Batch 9, loss = 0.14
I0701 15:15:57.156723  4639 caffe.cpp:312] Batch 10, accuracy/top1 = 0.94
I0701 15:15:57.156736  4639 caffe.cpp:312] Batch 10, accuracy/top5 = 1
I0701 15:15:57.156739  4639 caffe.cpp:312] Batch 10, loss = 0.06
I0701 15:15:57.164901  4639 caffe.cpp:312] Batch 11, accuracy/top1 = 0.98
I0701 15:15:57.164909  4639 caffe.cpp:312] Batch 11, accuracy/top5 = 1
I0701 15:15:57.164912  4639 caffe.cpp:312] Batch 11, loss = 0.1
I0701 15:15:57.173084  4639 caffe.cpp:312] Batch 12, accuracy/top1 = 0.92
I0701 15:15:57.173091  4639 caffe.cpp:312] Batch 12, accuracy/top5 = 1
I0701 15:15:57.173094  4639 caffe.cpp:312] Batch 12, loss = 0.14
I0701 15:15:57.181241  4639 caffe.cpp:312] Batch 13, accuracy/top1 = 0.86
I0701 15:15:57.181249  4639 caffe.cpp:312] Batch 13, accuracy/top5 = 0.98
I0701 15:15:57.181252  4639 caffe.cpp:312] Batch 13, loss = 0.58
I0701 15:15:57.189476  4639 caffe.cpp:312] Batch 14, accuracy/top1 = 0.84
I0701 15:15:57.189491  4639 caffe.cpp:312] Batch 14, accuracy/top5 = 1
I0701 15:15:57.189493  4639 caffe.cpp:312] Batch 14, loss = 0.52
I0701 15:15:57.197660  4639 caffe.cpp:312] Batch 15, accuracy/top1 = 0.84
I0701 15:15:57.197669  4639 caffe.cpp:312] Batch 15, accuracy/top5 = 1
I0701 15:15:57.197671  4639 caffe.cpp:312] Batch 15, loss = 0.54
I0701 15:15:57.205866  4639 caffe.cpp:312] Batch 16, accuracy/top1 = 0.94
I0701 15:15:57.205874  4639 caffe.cpp:312] Batch 16, accuracy/top5 = 1
I0701 15:15:57.205878  4639 caffe.cpp:312] Batch 16, loss = 0.24
I0701 15:15:57.214046  4639 caffe.cpp:312] Batch 17, accuracy/top1 = 0.88
I0701 15:15:57.214054  4639 caffe.cpp:312] Batch 17, accuracy/top5 = 0.98
I0701 15:15:57.214057  4639 caffe.cpp:312] Batch 17, loss = 0.62
I0701 15:15:57.222157  4639 caffe.cpp:312] Batch 18, accuracy/top1 = 0.96
I0701 15:15:57.222170  4639 caffe.cpp:312] Batch 18, accuracy/top5 = 1
I0701 15:15:57.222173  4639 caffe.cpp:312] Batch 18, loss = 0.12
I0701 15:15:57.230334  4639 caffe.cpp:312] Batch 19, accuracy/top1 = 0.9
I0701 15:15:57.230342  4639 caffe.cpp:312] Batch 19, accuracy/top5 = 1
I0701 15:15:57.230345  4639 caffe.cpp:312] Batch 19, loss = 0.3
I0701 15:15:57.238519  4639 caffe.cpp:312] Batch 20, accuracy/top1 = 0.92
I0701 15:15:57.238528  4639 caffe.cpp:312] Batch 20, accuracy/top5 = 1
I0701 15:15:57.238530  4639 caffe.cpp:312] Batch 20, loss = 0.16
I0701 15:15:57.246688  4639 caffe.cpp:312] Batch 21, accuracy/top1 = 0.9
I0701 15:15:57.246696  4639 caffe.cpp:312] Batch 21, accuracy/top5 = 1
I0701 15:15:57.246700  4639 caffe.cpp:312] Batch 21, loss = 0.28
I0701 15:15:57.254870  4639 caffe.cpp:312] Batch 22, accuracy/top1 = 0.9
I0701 15:15:57.254883  4639 caffe.cpp:312] Batch 22, accuracy/top5 = 1
I0701 15:15:57.254885  4639 caffe.cpp:312] Batch 22, loss = 0.34
I0701 15:15:57.262997  4639 caffe.cpp:312] Batch 23, accuracy/top1 = 0.9
I0701 15:15:57.263005  4639 caffe.cpp:312] Batch 23, accuracy/top5 = 0.98
I0701 15:15:57.263008  4639 caffe.cpp:312] Batch 23, loss = 0.46
I0701 15:15:57.271198  4639 caffe.cpp:312] Batch 24, accuracy/top1 = 0.9
I0701 15:15:57.271205  4639 caffe.cpp:312] Batch 24, accuracy/top5 = 0.98
I0701 15:15:57.271219  4639 caffe.cpp:312] Batch 24, loss = 0.36
I0701 15:15:57.279381  4639 caffe.cpp:312] Batch 25, accuracy/top1 = 0.94
I0701 15:15:57.279392  4639 caffe.cpp:312] Batch 25, accuracy/top5 = 1
I0701 15:15:57.279397  4639 caffe.cpp:312] Batch 25, loss = 0.1
I0701 15:15:57.287600  4639 caffe.cpp:312] Batch 26, accuracy/top1 = 0.92
I0701 15:15:57.287611  4639 caffe.cpp:312] Batch 26, accuracy/top5 = 1
I0701 15:15:57.287613  4639 caffe.cpp:312] Batch 26, loss = 0.32
I0701 15:15:57.295809  4639 caffe.cpp:312] Batch 27, accuracy/top1 = 0.88
I0701 15:15:57.295817  4639 caffe.cpp:312] Batch 27, accuracy/top5 = 1
I0701 15:15:57.295820  4639 caffe.cpp:312] Batch 27, loss = 0.22
I0701 15:15:57.303994  4639 caffe.cpp:312] Batch 28, accuracy/top1 = 0.9
I0701 15:15:57.304005  4639 caffe.cpp:312] Batch 28, accuracy/top5 = 1
I0701 15:15:57.304009  4639 caffe.cpp:312] Batch 28, loss = 0.24
I0701 15:15:57.312165  4639 caffe.cpp:312] Batch 29, accuracy/top1 = 0.92
I0701 15:15:57.312178  4639 caffe.cpp:312] Batch 29, accuracy/top5 = 1
I0701 15:15:57.312181  4639 caffe.cpp:312] Batch 29, loss = 0.38
I0701 15:15:57.320399  4639 caffe.cpp:312] Batch 30, accuracy/top1 = 0.88
I0701 15:15:57.320408  4639 caffe.cpp:312] Batch 30, accuracy/top5 = 1
I0701 15:15:57.320411  4639 caffe.cpp:312] Batch 30, loss = 0.38
I0701 15:15:57.328526  4639 caffe.cpp:312] Batch 31, accuracy/top1 = 0.9
I0701 15:15:57.328534  4639 caffe.cpp:312] Batch 31, accuracy/top5 = 1
I0701 15:15:57.328537  4639 caffe.cpp:312] Batch 31, loss = 0.36
I0701 15:15:57.336699  4639 caffe.cpp:312] Batch 32, accuracy/top1 = 0.92
I0701 15:15:57.336707  4639 caffe.cpp:312] Batch 32, accuracy/top5 = 1
I0701 15:15:57.336709  4639 caffe.cpp:312] Batch 32, loss = 0.26
I0701 15:15:57.345031  4639 caffe.cpp:312] Batch 33, accuracy/top1 = 0.96
I0701 15:15:57.345053  4639 caffe.cpp:312] Batch 33, accuracy/top5 = 0.98
I0701 15:15:57.345057  4639 caffe.cpp:312] Batch 33, loss = 0.2
I0701 15:15:57.353428  4639 caffe.cpp:312] Batch 34, accuracy/top1 = 0.88
I0701 15:15:57.353461  4639 caffe.cpp:312] Batch 34, accuracy/top5 = 1
I0701 15:15:57.353466  4639 caffe.cpp:312] Batch 34, loss = 0.32
I0701 15:15:57.361835  4639 caffe.cpp:312] Batch 35, accuracy/top1 = 0.9
I0701 15:15:57.361855  4639 caffe.cpp:312] Batch 35, accuracy/top5 = 1
I0701 15:15:57.361858  4639 caffe.cpp:312] Batch 35, loss = 0.2
I0701 15:15:57.370133  4639 caffe.cpp:312] Batch 36, accuracy/top1 = 0.92
I0701 15:15:57.370162  4639 caffe.cpp:312] Batch 36, accuracy/top5 = 1
I0701 15:15:57.370164  4639 caffe.cpp:312] Batch 36, loss = 0.26
I0701 15:15:57.378403  4639 caffe.cpp:312] Batch 37, accuracy/top1 = 0.88
I0701 15:15:57.378415  4639 caffe.cpp:312] Batch 37, accuracy/top5 = 1
I0701 15:15:57.378417  4639 caffe.cpp:312] Batch 37, loss = 0.42
I0701 15:15:57.386538  4639 caffe.cpp:312] Batch 38, accuracy/top1 = 0.86
I0701 15:15:57.386546  4639 caffe.cpp:312] Batch 38, accuracy/top5 = 0.96
I0701 15:15:57.386548  4639 caffe.cpp:312] Batch 38, loss = 0.72
I0701 15:15:57.394719  4639 caffe.cpp:312] Batch 39, accuracy/top1 = 0.94
I0701 15:15:57.394727  4639 caffe.cpp:312] Batch 39, accuracy/top5 = 0.98
I0701 15:15:57.394729  4639 caffe.cpp:312] Batch 39, loss = 0.32
I0701 15:15:57.402935  4639 caffe.cpp:312] Batch 40, accuracy/top1 = 0.86
I0701 15:15:57.402946  4639 caffe.cpp:312] Batch 40, accuracy/top5 = 1
I0701 15:15:57.402950  4639 caffe.cpp:312] Batch 40, loss = 0.24
I0701 15:15:57.411164  4639 caffe.cpp:312] Batch 41, accuracy/top1 = 0.94
I0701 15:15:57.411172  4639 caffe.cpp:312] Batch 41, accuracy/top5 = 1
I0701 15:15:57.411175  4639 caffe.cpp:312] Batch 41, loss = 0.18
I0701 15:15:57.419263  4639 caffe.cpp:312] Batch 42, accuracy/top1 = 0.92
I0701 15:15:57.419270  4639 caffe.cpp:312] Batch 42, accuracy/top5 = 1
I0701 15:15:57.419273  4639 caffe.cpp:312] Batch 42, loss = 0.26
I0701 15:15:57.427420  4639 caffe.cpp:312] Batch 43, accuracy/top1 = 0.88
I0701 15:15:57.427428  4639 caffe.cpp:312] Batch 43, accuracy/top5 = 1
I0701 15:15:57.427431  4639 caffe.cpp:312] Batch 43, loss = 0.1
I0701 15:15:57.435550  4639 caffe.cpp:312] Batch 44, accuracy/top1 = 0.9
I0701 15:15:57.435565  4639 caffe.cpp:312] Batch 44, accuracy/top5 = 0.98
I0701 15:15:57.435569  4639 caffe.cpp:312] Batch 44, loss = 0.34
I0701 15:15:57.443717  4639 caffe.cpp:312] Batch 45, accuracy/top1 = 0.84
I0701 15:15:57.443725  4639 caffe.cpp:312] Batch 45, accuracy/top5 = 1
I0701 15:15:57.443727  4639 caffe.cpp:312] Batch 45, loss = 0.5
I0701 15:15:57.451876  4639 caffe.cpp:312] Batch 46, accuracy/top1 = 0.98
I0701 15:15:57.451884  4639 caffe.cpp:312] Batch 46, accuracy/top5 = 1
I0701 15:15:57.451887  4639 caffe.cpp:312] Batch 46, loss = 0.06
I0701 15:15:57.460024  4639 caffe.cpp:312] Batch 47, accuracy/top1 = 0.82
I0701 15:15:57.460032  4639 caffe.cpp:312] Batch 47, accuracy/top5 = 0.98
I0701 15:15:57.460036  4639 caffe.cpp:312] Batch 47, loss = 0.54
I0701 15:15:57.468237  4639 caffe.cpp:312] Batch 48, accuracy/top1 = 0.96
I0701 15:15:57.468250  4639 caffe.cpp:312] Batch 48, accuracy/top5 = 0.98
I0701 15:15:57.468252  4639 caffe.cpp:312] Batch 48, loss = 0.54
I0701 15:15:57.476452  4639 caffe.cpp:312] Batch 49, accuracy/top1 = 0.92
I0701 15:15:57.476460  4639 caffe.cpp:312] Batch 49, accuracy/top5 = 1
I0701 15:15:57.476464  4639 caffe.cpp:312] Batch 49, loss = 0.32
I0701 15:15:57.484627  4639 caffe.cpp:312] Batch 50, accuracy/top1 = 0.82
I0701 15:15:57.484650  4639 caffe.cpp:312] Batch 50, accuracy/top5 = 1
I0701 15:15:57.484654  4639 caffe.cpp:312] Batch 50, loss = 0.52
I0701 15:15:57.492975  4639 caffe.cpp:312] Batch 51, accuracy/top1 = 0.9
I0701 15:15:57.493005  4639 caffe.cpp:312] Batch 51, accuracy/top5 = 0.98
I0701 15:15:57.493008  4639 caffe.cpp:312] Batch 51, loss = 0.4
I0701 15:15:57.501250  4639 caffe.cpp:312] Batch 52, accuracy/top1 = 0.94
I0701 15:15:57.501271  4639 caffe.cpp:312] Batch 52, accuracy/top5 = 1
I0701 15:15:57.501274  4639 caffe.cpp:312] Batch 52, loss = 0.14
I0701 15:15:57.509496  4639 caffe.cpp:312] Batch 53, accuracy/top1 = 0.96
I0701 15:15:57.509505  4639 caffe.cpp:312] Batch 53, accuracy/top5 = 1
I0701 15:15:57.509510  4639 caffe.cpp:312] Batch 53, loss = 0.04
I0701 15:15:57.517731  4639 caffe.cpp:312] Batch 54, accuracy/top1 = 0.94
I0701 15:15:57.517740  4639 caffe.cpp:312] Batch 54, accuracy/top5 = 1
I0701 15:15:57.517743  4639 caffe.cpp:312] Batch 54, loss = 0.24
I0701 15:15:57.525897  4639 caffe.cpp:312] Batch 55, accuracy/top1 = 0.94
I0701 15:15:57.525910  4639 caffe.cpp:312] Batch 55, accuracy/top5 = 1
I0701 15:15:57.525914  4639 caffe.cpp:312] Batch 55, loss = 0.4
I0701 15:15:57.534027  4639 caffe.cpp:312] Batch 56, accuracy/top1 = 0.86
I0701 15:15:57.534036  4639 caffe.cpp:312] Batch 56, accuracy/top5 = 0.98
I0701 15:15:57.534040  4639 caffe.cpp:312] Batch 56, loss = 0.72
I0701 15:15:57.542225  4639 caffe.cpp:312] Batch 57, accuracy/top1 = 0.94
I0701 15:15:57.542234  4639 caffe.cpp:312] Batch 57, accuracy/top5 = 1
I0701 15:15:57.542237  4639 caffe.cpp:312] Batch 57, loss = 0.1
I0701 15:15:57.550382  4639 caffe.cpp:312] Batch 58, accuracy/top1 = 0.94
I0701 15:15:57.550393  4639 caffe.cpp:312] Batch 58, accuracy/top5 = 1
I0701 15:15:57.550396  4639 caffe.cpp:312] Batch 58, loss = 0.32
I0701 15:15:57.558593  4639 caffe.cpp:312] Batch 59, accuracy/top1 = 0.94
I0701 15:15:57.558609  4639 caffe.cpp:312] Batch 59, accuracy/top5 = 1
I0701 15:15:57.558612  4639 caffe.cpp:312] Batch 59, loss = 0.1
I0701 15:15:57.566821  4639 caffe.cpp:312] Batch 60, accuracy/top1 = 0.9
I0701 15:15:57.566830  4639 caffe.cpp:312] Batch 60, accuracy/top5 = 1
I0701 15:15:57.566834  4639 caffe.cpp:312] Batch 60, loss = 0.36
I0701 15:15:57.575042  4639 caffe.cpp:312] Batch 61, accuracy/top1 = 0.94
I0701 15:15:57.575052  4639 caffe.cpp:312] Batch 61, accuracy/top5 = 0.98
I0701 15:15:57.575055  4639 caffe.cpp:312] Batch 61, loss = 0.3
I0701 15:15:57.583279  4639 caffe.cpp:312] Batch 62, accuracy/top1 = 0.98
I0701 15:15:57.583290  4639 caffe.cpp:312] Batch 62, accuracy/top5 = 1
I0701 15:15:57.583293  4639 caffe.cpp:312] Batch 62, loss = 0.06
I0701 15:15:57.591413  4639 caffe.cpp:312] Batch 63, accuracy/top1 = 0.84
I0701 15:15:57.591430  4639 caffe.cpp:312] Batch 63, accuracy/top5 = 0.98
I0701 15:15:57.591449  4639 caffe.cpp:312] Batch 63, loss = 0.48
I0701 15:15:57.599553  4639 caffe.cpp:312] Batch 64, accuracy/top1 = 0.86
I0701 15:15:57.599565  4639 caffe.cpp:312] Batch 64, accuracy/top5 = 1
I0701 15:15:57.599568  4639 caffe.cpp:312] Batch 64, loss = 0.26
I0701 15:15:57.607769  4639 caffe.cpp:312] Batch 65, accuracy/top1 = 0.96
I0701 15:15:57.607784  4639 caffe.cpp:312] Batch 65, accuracy/top5 = 1
I0701 15:15:57.607786  4639 caffe.cpp:312] Batch 65, loss = 0.1
I0701 15:15:57.615998  4639 caffe.cpp:312] Batch 66, accuracy/top1 = 0.92
I0701 15:15:57.616016  4639 caffe.cpp:312] Batch 66, accuracy/top5 = 1
I0701 15:15:57.616020  4639 caffe.cpp:312] Batch 66, loss = 0.24
I0701 15:15:57.624258  4639 caffe.cpp:312] Batch 67, accuracy/top1 = 0.94
I0701 15:15:57.624272  4639 caffe.cpp:312] Batch 67, accuracy/top5 = 1
I0701 15:15:57.624276  4639 caffe.cpp:312] Batch 67, loss = 0.1
I0701 15:15:57.632508  4639 caffe.cpp:312] Batch 68, accuracy/top1 = 0.92
I0701 15:15:57.632525  4639 caffe.cpp:312] Batch 68, accuracy/top5 = 1
I0701 15:15:57.632529  4639 caffe.cpp:312] Batch 68, loss = 0.38
I0701 15:15:57.640744  4639 caffe.cpp:312] Batch 69, accuracy/top1 = 0.9
I0701 15:15:57.640756  4639 caffe.cpp:312] Batch 69, accuracy/top5 = 1
I0701 15:15:57.640759  4639 caffe.cpp:312] Batch 69, loss = 0.28
I0701 15:15:57.648926  4639 caffe.cpp:312] Batch 70, accuracy/top1 = 0.96
I0701 15:15:57.648949  4639 caffe.cpp:312] Batch 70, accuracy/top5 = 0.98
I0701 15:15:57.648952  4639 caffe.cpp:312] Batch 70, loss = 0.28
I0701 15:15:57.657218  4639 caffe.cpp:312] Batch 71, accuracy/top1 = 0.86
I0701 15:15:57.657232  4639 caffe.cpp:312] Batch 71, accuracy/top5 = 1
I0701 15:15:57.657236  4639 caffe.cpp:312] Batch 71, loss = 0.46
I0701 15:15:57.665464  4639 caffe.cpp:312] Batch 72, accuracy/top1 = 0.84
I0701 15:15:57.665478  4639 caffe.cpp:312] Batch 72, accuracy/top5 = 0.98
I0701 15:15:57.665482  4639 caffe.cpp:312] Batch 72, loss = 0.5
I0701 15:15:57.673691  4639 caffe.cpp:312] Batch 73, accuracy/top1 = 0.92
I0701 15:15:57.673702  4639 caffe.cpp:312] Batch 73, accuracy/top5 = 1
I0701 15:15:57.673707  4639 caffe.cpp:312] Batch 73, loss = 0.3
I0701 15:15:57.681826  4639 caffe.cpp:312] Batch 74, accuracy/top1 = 0.88
I0701 15:15:57.681845  4639 caffe.cpp:312] Batch 74, accuracy/top5 = 1
I0701 15:15:57.681849  4639 caffe.cpp:312] Batch 74, loss = 0.28
I0701 15:15:57.690088  4639 caffe.cpp:312] Batch 75, accuracy/top1 = 0.82
I0701 15:15:57.690101  4639 caffe.cpp:312] Batch 75, accuracy/top5 = 1
I0701 15:15:57.690104  4639 caffe.cpp:312] Batch 75, loss = 0.62
I0701 15:15:57.698278  4639 caffe.cpp:312] Batch 76, accuracy/top1 = 0.94
I0701 15:15:57.698292  4639 caffe.cpp:312] Batch 76, accuracy/top5 = 1
I0701 15:15:57.698294  4639 caffe.cpp:312] Batch 76, loss = 0.18
I0701 15:15:57.706463  4639 caffe.cpp:312] Batch 77, accuracy/top1 = 0.92
I0701 15:15:57.706471  4639 caffe.cpp:312] Batch 77, accuracy/top5 = 1
I0701 15:15:57.706475  4639 caffe.cpp:312] Batch 77, loss = 0.26
I0701 15:15:57.714664  4639 caffe.cpp:312] Batch 78, accuracy/top1 = 0.96
I0701 15:15:57.714680  4639 caffe.cpp:312] Batch 78, accuracy/top5 = 1
I0701 15:15:57.714684  4639 caffe.cpp:312] Batch 78, loss = 0.02
I0701 15:15:57.722896  4639 caffe.cpp:312] Batch 79, accuracy/top1 = 0.94
I0701 15:15:57.722904  4639 caffe.cpp:312] Batch 79, accuracy/top5 = 1
I0701 15:15:57.722908  4639 caffe.cpp:312] Batch 79, loss = 0.3
I0701 15:15:57.731082  4639 caffe.cpp:312] Batch 80, accuracy/top1 = 0.96
I0701 15:15:57.731091  4639 caffe.cpp:312] Batch 80, accuracy/top5 = 1
I0701 15:15:57.731094  4639 caffe.cpp:312] Batch 80, loss = 0.1
I0701 15:15:57.739305  4639 caffe.cpp:312] Batch 81, accuracy/top1 = 0.9
I0701 15:15:57.739315  4639 caffe.cpp:312] Batch 81, accuracy/top5 = 1
I0701 15:15:57.739318  4639 caffe.cpp:312] Batch 81, loss = 0.12
I0701 15:15:57.747498  4639 caffe.cpp:312] Batch 82, accuracy/top1 = 0.84
I0701 15:15:57.747506  4639 caffe.cpp:312] Batch 82, accuracy/top5 = 0.98
I0701 15:15:57.747510  4639 caffe.cpp:312] Batch 82, loss = 0.68
I0701 15:15:57.755682  4639 caffe.cpp:312] Batch 83, accuracy/top1 = 0.94
I0701 15:15:57.755690  4639 caffe.cpp:312] Batch 83, accuracy/top5 = 1
I0701 15:15:57.755694  4639 caffe.cpp:312] Batch 83, loss = 0.18
I0701 15:15:57.763849  4639 caffe.cpp:312] Batch 84, accuracy/top1 = 0.94
I0701 15:15:57.763857  4639 caffe.cpp:312] Batch 84, accuracy/top5 = 1
I0701 15:15:57.763861  4639 caffe.cpp:312] Batch 84, loss = 0.12
I0701 15:15:57.772049  4639 caffe.cpp:312] Batch 85, accuracy/top1 = 0.94
I0701 15:15:57.772061  4639 caffe.cpp:312] Batch 85, accuracy/top5 = 1
I0701 15:15:57.772065  4639 caffe.cpp:312] Batch 85, loss = 0.12
I0701 15:15:57.780283  4639 caffe.cpp:312] Batch 86, accuracy/top1 = 0.9
I0701 15:15:57.780292  4639 caffe.cpp:312] Batch 86, accuracy/top5 = 1
I0701 15:15:57.780297  4639 caffe.cpp:312] Batch 86, loss = 0.32
I0701 15:15:57.788450  4639 caffe.cpp:312] Batch 87, accuracy/top1 = 0.96
I0701 15:15:57.788457  4639 caffe.cpp:312] Batch 87, accuracy/top5 = 1
I0701 15:15:57.788461  4639 caffe.cpp:312] Batch 87, loss = 0.12
I0701 15:15:57.796506  4639 caffe.cpp:312] Batch 88, accuracy/top1 = 0.9
I0701 15:15:57.796514  4639 caffe.cpp:312] Batch 88, accuracy/top5 = 1
I0701 15:15:57.796519  4639 caffe.cpp:312] Batch 88, loss = 0.24
I0701 15:15:57.804711  4639 caffe.cpp:312] Batch 89, accuracy/top1 = 0.88
I0701 15:15:57.804724  4639 caffe.cpp:312] Batch 89, accuracy/top5 = 1
I0701 15:15:57.804728  4639 caffe.cpp:312] Batch 89, loss = 0.24
I0701 15:15:57.812901  4639 caffe.cpp:312] Batch 90, accuracy/top1 = 0.88
I0701 15:15:57.812908  4639 caffe.cpp:312] Batch 90, accuracy/top5 = 1
I0701 15:15:57.812912  4639 caffe.cpp:312] Batch 90, loss = 0.4
I0701 15:15:57.821070  4639 caffe.cpp:312] Batch 91, accuracy/top1 = 0.86
I0701 15:15:57.821079  4639 caffe.cpp:312] Batch 91, accuracy/top5 = 1
I0701 15:15:57.821082  4639 caffe.cpp:312] Batch 91, loss = 0.26
I0701 15:15:57.829277  4639 caffe.cpp:312] Batch 92, accuracy/top1 = 0.94
I0701 15:15:57.829284  4639 caffe.cpp:312] Batch 92, accuracy/top5 = 1
I0701 15:15:57.829288  4639 caffe.cpp:312] Batch 92, loss = 0.14
I0701 15:15:57.837452  4639 caffe.cpp:312] Batch 93, accuracy/top1 = 0.92
I0701 15:15:57.837465  4639 caffe.cpp:312] Batch 93, accuracy/top5 = 1
I0701 15:15:57.837468  4639 caffe.cpp:312] Batch 93, loss = 0.28
I0701 15:15:57.845629  4639 caffe.cpp:312] Batch 94, accuracy/top1 = 0.88
I0701 15:15:57.845638  4639 caffe.cpp:312] Batch 94, accuracy/top5 = 1
I0701 15:15:57.845641  4639 caffe.cpp:312] Batch 94, loss = 0.34
I0701 15:15:57.853865  4639 caffe.cpp:312] Batch 95, accuracy/top1 = 0.92
I0701 15:15:57.853873  4639 caffe.cpp:312] Batch 95, accuracy/top5 = 0.98
I0701 15:15:57.853878  4639 caffe.cpp:312] Batch 95, loss = 0.4
I0701 15:15:57.862025  4639 caffe.cpp:312] Batch 96, accuracy/top1 = 0.98
I0701 15:15:57.862036  4639 caffe.cpp:312] Batch 96, accuracy/top5 = 1
I0701 15:15:57.862040  4639 caffe.cpp:312] Batch 96, loss = 0.04
I0701 15:15:57.870175  4639 caffe.cpp:312] Batch 97, accuracy/top1 = 0.94
I0701 15:15:57.870184  4639 caffe.cpp:312] Batch 97, accuracy/top5 = 1
I0701 15:15:57.870188  4639 caffe.cpp:312] Batch 97, loss = 0.06
I0701 15:15:57.878314  4639 caffe.cpp:312] Batch 98, accuracy/top1 = 0.92
I0701 15:15:57.878322  4639 caffe.cpp:312] Batch 98, accuracy/top5 = 1
I0701 15:15:57.878326  4639 caffe.cpp:312] Batch 98, loss = 0.14
I0701 15:15:57.886433  4639 caffe.cpp:312] Batch 99, accuracy/top1 = 0.92
I0701 15:15:57.886441  4639 caffe.cpp:312] Batch 99, accuracy/top5 = 0.98
I0701 15:15:57.886445  4639 caffe.cpp:312] Batch 99, loss = 0.32
I0701 15:15:57.894625  4639 caffe.cpp:312] Batch 100, accuracy/top1 = 0.94
I0701 15:15:57.894636  4639 caffe.cpp:312] Batch 100, accuracy/top5 = 1
I0701 15:15:57.894640  4639 caffe.cpp:312] Batch 100, loss = 0.14
I0701 15:15:57.902839  4639 caffe.cpp:312] Batch 101, accuracy/top1 = 0.94
I0701 15:15:57.902848  4639 caffe.cpp:312] Batch 101, accuracy/top5 = 1
I0701 15:15:57.902851  4639 caffe.cpp:312] Batch 101, loss = 0.16
I0701 15:15:57.911015  4639 caffe.cpp:312] Batch 102, accuracy/top1 = 0.94
I0701 15:15:57.911022  4639 caffe.cpp:312] Batch 102, accuracy/top5 = 1
I0701 15:15:57.911036  4639 caffe.cpp:312] Batch 102, loss = 0.08
I0701 15:15:57.919183  4639 caffe.cpp:312] Batch 103, accuracy/top1 = 0.8
I0701 15:15:57.919191  4639 caffe.cpp:312] Batch 103, accuracy/top5 = 1
I0701 15:15:57.919195  4639 caffe.cpp:312] Batch 103, loss = 0.34
I0701 15:15:57.927347  4639 caffe.cpp:312] Batch 104, accuracy/top1 = 0.88
I0701 15:15:57.927361  4639 caffe.cpp:312] Batch 104, accuracy/top5 = 1
I0701 15:15:57.927363  4639 caffe.cpp:312] Batch 104, loss = 0.4
I0701 15:15:57.935535  4639 caffe.cpp:312] Batch 105, accuracy/top1 = 0.96
I0701 15:15:57.935544  4639 caffe.cpp:312] Batch 105, accuracy/top5 = 1
I0701 15:15:57.935549  4639 caffe.cpp:312] Batch 105, loss = 0.04
I0701 15:15:57.943791  4639 caffe.cpp:312] Batch 106, accuracy/top1 = 0.96
I0701 15:15:57.943800  4639 caffe.cpp:312] Batch 106, accuracy/top5 = 1
I0701 15:15:57.943804  4639 caffe.cpp:312] Batch 106, loss = 0.1
I0701 15:15:57.952018  4639 caffe.cpp:312] Batch 107, accuracy/top1 = 0.92
I0701 15:15:57.952028  4639 caffe.cpp:312] Batch 107, accuracy/top5 = 1
I0701 15:15:57.952031  4639 caffe.cpp:312] Batch 107, loss = 0.34
I0701 15:15:57.960223  4639 caffe.cpp:312] Batch 108, accuracy/top1 = 0.9
I0701 15:15:57.960237  4639 caffe.cpp:312] Batch 108, accuracy/top5 = 1
I0701 15:15:57.960239  4639 caffe.cpp:312] Batch 108, loss = 0.36
I0701 15:15:57.968406  4639 caffe.cpp:312] Batch 109, accuracy/top1 = 0.94
I0701 15:15:57.968415  4639 caffe.cpp:312] Batch 109, accuracy/top5 = 1
I0701 15:15:57.968418  4639 caffe.cpp:312] Batch 109, loss = 0.1
I0701 15:15:57.976431  4639 caffe.cpp:312] Batch 110, accuracy/top1 = 0.9
I0701 15:15:57.976439  4639 caffe.cpp:312] Batch 110, accuracy/top5 = 1
I0701 15:15:57.976444  4639 caffe.cpp:312] Batch 110, loss = 0.54
I0701 15:15:57.984668  4639 caffe.cpp:312] Batch 111, accuracy/top1 = 0.98
I0701 15:15:57.984678  4639 caffe.cpp:312] Batch 111, accuracy/top5 = 1
I0701 15:15:57.984681  4639 caffe.cpp:312] Batch 111, loss = 0.02
I0701 15:15:57.992859  4639 caffe.cpp:312] Batch 112, accuracy/top1 = 0.86
I0701 15:15:57.992867  4639 caffe.cpp:312] Batch 112, accuracy/top5 = 1
I0701 15:15:57.992871  4639 caffe.cpp:312] Batch 112, loss = 0.38
I0701 15:15:58.000977  4639 caffe.cpp:312] Batch 113, accuracy/top1 = 0.86
I0701 15:15:58.000985  4639 caffe.cpp:312] Batch 113, accuracy/top5 = 1
I0701 15:15:58.000989  4639 caffe.cpp:312] Batch 113, loss = 0.22
I0701 15:15:58.009191  4639 caffe.cpp:312] Batch 114, accuracy/top1 = 0.9
I0701 15:15:58.009199  4639 caffe.cpp:312] Batch 114, accuracy/top5 = 1
I0701 15:15:58.009203  4639 caffe.cpp:312] Batch 114, loss = 0.26
I0701 15:15:58.017356  4639 caffe.cpp:312] Batch 115, accuracy/top1 = 0.92
I0701 15:15:58.017367  4639 caffe.cpp:312] Batch 115, accuracy/top5 = 1
I0701 15:15:58.017371  4639 caffe.cpp:312] Batch 115, loss = 0.16
I0701 15:15:58.025553  4639 caffe.cpp:312] Batch 116, accuracy/top1 = 0.88
I0701 15:15:58.025562  4639 caffe.cpp:312] Batch 116, accuracy/top5 = 1
I0701 15:15:58.025565  4639 caffe.cpp:312] Batch 116, loss = 0.12
I0701 15:15:58.033788  4639 caffe.cpp:312] Batch 117, accuracy/top1 = 0.88
I0701 15:15:58.033797  4639 caffe.cpp:312] Batch 117, accuracy/top5 = 1
I0701 15:15:58.033802  4639 caffe.cpp:312] Batch 117, loss = 0.36
I0701 15:15:58.041980  4639 caffe.cpp:312] Batch 118, accuracy/top1 = 0.9
I0701 15:15:58.041988  4639 caffe.cpp:312] Batch 118, accuracy/top5 = 1
I0701 15:15:58.041992  4639 caffe.cpp:312] Batch 118, loss = 0.22
I0701 15:15:58.050096  4639 caffe.cpp:312] Batch 119, accuracy/top1 = 0.88
I0701 15:15:58.050104  4639 caffe.cpp:312] Batch 119, accuracy/top5 = 1
I0701 15:15:58.050108  4639 caffe.cpp:312] Batch 119, loss = 0.28
I0701 15:15:58.058275  4639 caffe.cpp:312] Batch 120, accuracy/top1 = 0.84
I0701 15:15:58.058284  4639 caffe.cpp:312] Batch 120, accuracy/top5 = 0.98
I0701 15:15:58.058287  4639 caffe.cpp:312] Batch 120, loss = 0.26
I0701 15:15:58.066396  4639 caffe.cpp:312] Batch 121, accuracy/top1 = 0.92
I0701 15:15:58.066404  4639 caffe.cpp:312] Batch 121, accuracy/top5 = 1
I0701 15:15:58.066417  4639 caffe.cpp:312] Batch 121, loss = 0.44
I0701 15:15:58.074587  4639 caffe.cpp:312] Batch 122, accuracy/top1 = 0.9
I0701 15:15:58.074595  4639 caffe.cpp:312] Batch 122, accuracy/top5 = 1
I0701 15:15:58.074599  4639 caffe.cpp:312] Batch 122, loss = 0.08
I0701 15:15:58.082774  4639 caffe.cpp:312] Batch 123, accuracy/top1 = 0.84
I0701 15:15:58.082782  4639 caffe.cpp:312] Batch 123, accuracy/top5 = 1
I0701 15:15:58.082787  4639 caffe.cpp:312] Batch 123, loss = 0.44
I0701 15:15:58.090963  4639 caffe.cpp:312] Batch 124, accuracy/top1 = 0.9
I0701 15:15:58.090971  4639 caffe.cpp:312] Batch 124, accuracy/top5 = 1
I0701 15:15:58.090975  4639 caffe.cpp:312] Batch 124, loss = 0.26
I0701 15:15:58.099195  4639 caffe.cpp:312] Batch 125, accuracy/top1 = 0.96
I0701 15:15:58.099211  4639 caffe.cpp:312] Batch 125, accuracy/top5 = 1
I0701 15:15:58.099215  4639 caffe.cpp:312] Batch 125, loss = 0.06
I0701 15:15:58.107462  4639 caffe.cpp:312] Batch 126, accuracy/top1 = 0.98
I0701 15:15:58.107473  4639 caffe.cpp:312] Batch 126, accuracy/top5 = 1
I0701 15:15:58.107477  4639 caffe.cpp:312] Batch 126, loss = 0
I0701 15:15:58.115656  4639 caffe.cpp:312] Batch 127, accuracy/top1 = 1
I0701 15:15:58.115666  4639 caffe.cpp:312] Batch 127, accuracy/top5 = 1
I0701 15:15:58.115670  4639 caffe.cpp:312] Batch 127, loss = 0
I0701 15:15:58.123838  4639 caffe.cpp:312] Batch 128, accuracy/top1 = 0.84
I0701 15:15:58.123847  4639 caffe.cpp:312] Batch 128, accuracy/top5 = 1
I0701 15:15:58.123852  4639 caffe.cpp:312] Batch 128, loss = 0.48
I0701 15:15:58.131961  4639 caffe.cpp:312] Batch 129, accuracy/top1 = 0.92
I0701 15:15:58.131969  4639 caffe.cpp:312] Batch 129, accuracy/top5 = 1
I0701 15:15:58.131973  4639 caffe.cpp:312] Batch 129, loss = 0.1
I0701 15:15:58.140194  4639 caffe.cpp:312] Batch 130, accuracy/top1 = 0.86
I0701 15:15:58.140208  4639 caffe.cpp:312] Batch 130, accuracy/top5 = 1
I0701 15:15:58.140211  4639 caffe.cpp:312] Batch 130, loss = 0.22
I0701 15:15:58.148347  4639 caffe.cpp:312] Batch 131, accuracy/top1 = 0.9
I0701 15:15:58.148356  4639 caffe.cpp:312] Batch 131, accuracy/top5 = 1
I0701 15:15:58.148360  4639 caffe.cpp:312] Batch 131, loss = 0.2
I0701 15:15:58.156563  4639 caffe.cpp:312] Batch 132, accuracy/top1 = 0.92
I0701 15:15:58.156570  4639 caffe.cpp:312] Batch 132, accuracy/top5 = 1
I0701 15:15:58.156574  4639 caffe.cpp:312] Batch 132, loss = 0.18
I0701 15:15:58.164696  4639 caffe.cpp:312] Batch 133, accuracy/top1 = 0.92
I0701 15:15:58.164705  4639 caffe.cpp:312] Batch 133, accuracy/top5 = 1
I0701 15:15:58.164710  4639 caffe.cpp:312] Batch 133, loss = 0.3
I0701 15:15:58.172914  4639 caffe.cpp:312] Batch 134, accuracy/top1 = 0.92
I0701 15:15:58.172927  4639 caffe.cpp:312] Batch 134, accuracy/top5 = 1
I0701 15:15:58.172931  4639 caffe.cpp:312] Batch 134, loss = 0.22
I0701 15:15:58.181005  4639 caffe.cpp:312] Batch 135, accuracy/top1 = 0.86
I0701 15:15:58.181012  4639 caffe.cpp:312] Batch 135, accuracy/top5 = 0.98
I0701 15:15:58.181016  4639 caffe.cpp:312] Batch 135, loss = 0.44
I0701 15:15:58.189214  4639 caffe.cpp:312] Batch 136, accuracy/top1 = 0.98
I0701 15:15:58.189223  4639 caffe.cpp:312] Batch 136, accuracy/top5 = 1
I0701 15:15:58.189226  4639 caffe.cpp:312] Batch 136, loss = 0.06
I0701 15:15:58.197259  4639 caffe.cpp:312] Batch 137, accuracy/top1 = 0.86
I0701 15:15:58.197268  4639 caffe.cpp:312] Batch 137, accuracy/top5 = 1
I0701 15:15:58.197271  4639 caffe.cpp:312] Batch 137, loss = 0.42
I0701 15:15:58.205485  4639 caffe.cpp:312] Batch 138, accuracy/top1 = 0.94
I0701 15:15:58.205497  4639 caffe.cpp:312] Batch 138, accuracy/top5 = 1
I0701 15:15:58.205502  4639 caffe.cpp:312] Batch 138, loss = 0.14
I0701 15:15:58.213680  4639 caffe.cpp:312] Batch 139, accuracy/top1 = 0.74
I0701 15:15:58.213687  4639 caffe.cpp:312] Batch 139, accuracy/top5 = 0.98
I0701 15:15:58.213691  4639 caffe.cpp:312] Batch 139, loss = 0.56
I0701 15:15:58.221871  4639 caffe.cpp:312] Batch 140, accuracy/top1 = 0.88
I0701 15:15:58.221879  4639 caffe.cpp:312] Batch 140, accuracy/top5 = 1
I0701 15:15:58.221884  4639 caffe.cpp:312] Batch 140, loss = 0.34
I0701 15:15:58.230008  4639 caffe.cpp:312] Batch 141, accuracy/top1 = 0.92
I0701 15:15:58.230018  4639 caffe.cpp:312] Batch 141, accuracy/top5 = 1
I0701 15:15:58.230021  4639 caffe.cpp:312] Batch 141, loss = 0.42
I0701 15:15:58.238171  4639 caffe.cpp:312] Batch 142, accuracy/top1 = 0.9
I0701 15:15:58.238180  4639 caffe.cpp:312] Batch 142, accuracy/top5 = 1
I0701 15:15:58.238184  4639 caffe.cpp:312] Batch 142, loss = 0.2
I0701 15:15:58.246348  4639 caffe.cpp:312] Batch 143, accuracy/top1 = 0.92
I0701 15:15:58.246356  4639 caffe.cpp:312] Batch 143, accuracy/top5 = 1
I0701 15:15:58.246361  4639 caffe.cpp:312] Batch 143, loss = 0.18
I0701 15:15:58.254493  4639 caffe.cpp:312] Batch 144, accuracy/top1 = 0.92
I0701 15:15:58.254501  4639 caffe.cpp:312] Batch 144, accuracy/top5 = 1
I0701 15:15:58.254505  4639 caffe.cpp:312] Batch 144, loss = 0.22
I0701 15:15:58.262696  4639 caffe.cpp:312] Batch 145, accuracy/top1 = 0.94
I0701 15:15:58.262708  4639 caffe.cpp:312] Batch 145, accuracy/top5 = 1
I0701 15:15:58.262712  4639 caffe.cpp:312] Batch 145, loss = 0.06
I0701 15:15:58.270925  4639 caffe.cpp:312] Batch 146, accuracy/top1 = 0.9
I0701 15:15:58.270932  4639 caffe.cpp:312] Batch 146, accuracy/top5 = 1
I0701 15:15:58.270936  4639 caffe.cpp:312] Batch 146, loss = 0.24
I0701 15:15:58.279132  4639 caffe.cpp:312] Batch 147, accuracy/top1 = 0.88
I0701 15:15:58.279140  4639 caffe.cpp:312] Batch 147, accuracy/top5 = 0.98
I0701 15:15:58.279145  4639 caffe.cpp:312] Batch 147, loss = 0.4
I0701 15:15:58.287299  4639 caffe.cpp:312] Batch 148, accuracy/top1 = 0.88
I0701 15:15:58.287307  4639 caffe.cpp:312] Batch 148, accuracy/top5 = 1
I0701 15:15:58.287312  4639 caffe.cpp:312] Batch 148, loss = 0.26
I0701 15:15:58.295512  4639 caffe.cpp:312] Batch 149, accuracy/top1 = 0.88
I0701 15:15:58.295521  4639 caffe.cpp:312] Batch 149, accuracy/top5 = 1
I0701 15:15:58.295523  4639 caffe.cpp:312] Batch 149, loss = 0.2
I0701 15:15:58.303580  4639 caffe.cpp:312] Batch 150, accuracy/top1 = 0.94
I0701 15:15:58.303591  4639 caffe.cpp:312] Batch 150, accuracy/top5 = 0.98
I0701 15:15:58.303594  4639 caffe.cpp:312] Batch 150, loss = 0.16
I0701 15:15:58.311722  4639 caffe.cpp:312] Batch 151, accuracy/top1 = 0.92
I0701 15:15:58.311729  4639 caffe.cpp:312] Batch 151, accuracy/top5 = 0.98
I0701 15:15:58.311733  4639 caffe.cpp:312] Batch 151, loss = 0.4
I0701 15:15:58.319931  4639 caffe.cpp:312] Batch 152, accuracy/top1 = 0.92
I0701 15:15:58.319937  4639 caffe.cpp:312] Batch 152, accuracy/top5 = 0.98
I0701 15:15:58.319941  4639 caffe.cpp:312] Batch 152, loss = 0.22
I0701 15:15:58.328111  4639 caffe.cpp:312] Batch 153, accuracy/top1 = 0.92
I0701 15:15:58.328124  4639 caffe.cpp:312] Batch 153, accuracy/top5 = 0.98
I0701 15:15:58.328127  4639 caffe.cpp:312] Batch 153, loss = 0.36
I0701 15:15:58.336329  4639 caffe.cpp:312] Batch 154, accuracy/top1 = 0.96
I0701 15:15:58.336338  4639 caffe.cpp:312] Batch 154, accuracy/top5 = 1
I0701 15:15:58.336341  4639 caffe.cpp:312] Batch 154, loss = 0.14
I0701 15:15:58.344678  4639 caffe.cpp:312] Batch 155, accuracy/top1 = 0.88
I0701 15:15:58.344702  4639 caffe.cpp:312] Batch 155, accuracy/top5 = 1
I0701 15:15:58.344707  4639 caffe.cpp:312] Batch 155, loss = 0.42
I0701 15:15:58.353174  4639 caffe.cpp:312] Batch 156, accuracy/top1 = 0.88
I0701 15:15:58.353204  4639 caffe.cpp:312] Batch 156, accuracy/top5 = 1
I0701 15:15:58.353206  4639 caffe.cpp:312] Batch 156, loss = 0.4
I0701 15:15:58.361654  4639 caffe.cpp:312] Batch 157, accuracy/top1 = 0.92
I0701 15:15:58.361680  4639 caffe.cpp:312] Batch 157, accuracy/top5 = 0.98
I0701 15:15:58.361683  4639 caffe.cpp:312] Batch 157, loss = 0.24
I0701 15:15:58.369925  4639 caffe.cpp:312] Batch 158, accuracy/top1 = 0.88
I0701 15:15:58.369938  4639 caffe.cpp:312] Batch 158, accuracy/top5 = 1
I0701 15:15:58.369942  4639 caffe.cpp:312] Batch 158, loss = 0.32
I0701 15:15:58.378175  4639 caffe.cpp:312] Batch 159, accuracy/top1 = 0.86
I0701 15:15:58.378183  4639 caffe.cpp:312] Batch 159, accuracy/top5 = 1
I0701 15:15:58.378187  4639 caffe.cpp:312] Batch 159, loss = 0.28
I0701 15:15:58.386369  4639 caffe.cpp:312] Batch 160, accuracy/top1 = 0.98
I0701 15:15:58.386395  4639 caffe.cpp:312] Batch 160, accuracy/top5 = 1
I0701 15:15:58.386400  4639 caffe.cpp:312] Batch 160, loss = 0.1
I0701 15:15:58.394649  4639 caffe.cpp:312] Batch 161, accuracy/top1 = 0.92
I0701 15:15:58.394656  4639 caffe.cpp:312] Batch 161, accuracy/top5 = 1
I0701 15:15:58.394660  4639 caffe.cpp:312] Batch 161, loss = 0.18
I0701 15:15:58.402856  4639 caffe.cpp:312] Batch 162, accuracy/top1 = 0.94
I0701 15:15:58.402864  4639 caffe.cpp:312] Batch 162, accuracy/top5 = 1
I0701 15:15:58.402868  4639 caffe.cpp:312] Batch 162, loss = 0.12
I0701 15:15:58.411118  4639 caffe.cpp:312] Batch 163, accuracy/top1 = 0.88
I0701 15:15:58.411126  4639 caffe.cpp:312] Batch 163, accuracy/top5 = 1
I0701 15:15:58.411130  4639 caffe.cpp:312] Batch 163, loss = 0.28
I0701 15:15:58.419314  4639 caffe.cpp:312] Batch 164, accuracy/top1 = 0.9
I0701 15:15:58.419327  4639 caffe.cpp:312] Batch 164, accuracy/top5 = 1
I0701 15:15:58.419330  4639 caffe.cpp:312] Batch 164, loss = 0.18
I0701 15:15:58.427547  4639 caffe.cpp:312] Batch 165, accuracy/top1 = 0.9
I0701 15:15:58.427556  4639 caffe.cpp:312] Batch 165, accuracy/top5 = 1
I0701 15:15:58.427559  4639 caffe.cpp:312] Batch 165, loss = 0.22
I0701 15:15:58.435672  4639 caffe.cpp:312] Batch 166, accuracy/top1 = 0.94
I0701 15:15:58.435680  4639 caffe.cpp:312] Batch 166, accuracy/top5 = 1
I0701 15:15:58.435684  4639 caffe.cpp:312] Batch 166, loss = 0.1
I0701 15:15:58.443922  4639 caffe.cpp:312] Batch 167, accuracy/top1 = 0.96
I0701 15:15:58.443930  4639 caffe.cpp:312] Batch 167, accuracy/top5 = 1
I0701 15:15:58.443934  4639 caffe.cpp:312] Batch 167, loss = 0.12
I0701 15:15:58.452090  4639 caffe.cpp:312] Batch 168, accuracy/top1 = 0.92
I0701 15:15:58.452103  4639 caffe.cpp:312] Batch 168, accuracy/top5 = 1
I0701 15:15:58.452107  4639 caffe.cpp:312] Batch 168, loss = 0.3
I0701 15:15:58.460314  4639 caffe.cpp:312] Batch 169, accuracy/top1 = 0.8
I0701 15:15:58.460324  4639 caffe.cpp:312] Batch 169, accuracy/top5 = 1
I0701 15:15:58.460326  4639 caffe.cpp:312] Batch 169, loss = 0.44
I0701 15:15:58.468456  4639 caffe.cpp:312] Batch 170, accuracy/top1 = 0.88
I0701 15:15:58.468463  4639 caffe.cpp:312] Batch 170, accuracy/top5 = 0.98
I0701 15:15:58.468467  4639 caffe.cpp:312] Batch 170, loss = 0.28
I0701 15:15:58.476640  4639 caffe.cpp:312] Batch 171, accuracy/top1 = 0.88
I0701 15:15:58.476651  4639 caffe.cpp:312] Batch 171, accuracy/top5 = 1
I0701 15:15:58.476655  4639 caffe.cpp:312] Batch 171, loss = 0.54
I0701 15:15:58.484848  4639 caffe.cpp:312] Batch 172, accuracy/top1 = 0.9
I0701 15:15:58.484856  4639 caffe.cpp:312] Batch 172, accuracy/top5 = 1
I0701 15:15:58.484860  4639 caffe.cpp:312] Batch 172, loss = 0.28
I0701 15:15:58.493041  4639 caffe.cpp:312] Batch 173, accuracy/top1 = 0.96
I0701 15:15:58.493048  4639 caffe.cpp:312] Batch 173, accuracy/top5 = 1
I0701 15:15:58.493052  4639 caffe.cpp:312] Batch 173, loss = 0.06
I0701 15:15:58.501181  4639 caffe.cpp:312] Batch 174, accuracy/top1 = 0.88
I0701 15:15:58.501189  4639 caffe.cpp:312] Batch 174, accuracy/top5 = 1
I0701 15:15:58.501194  4639 caffe.cpp:312] Batch 174, loss = 0.68
I0701 15:15:58.509440  4639 caffe.cpp:312] Batch 175, accuracy/top1 = 0.92
I0701 15:15:58.509452  4639 caffe.cpp:312] Batch 175, accuracy/top5 = 1
I0701 15:15:58.509455  4639 caffe.cpp:312] Batch 175, loss = 0.2
I0701 15:15:58.517628  4639 caffe.cpp:312] Batch 176, accuracy/top1 = 0.84
I0701 15:15:58.517638  4639 caffe.cpp:312] Batch 176, accuracy/top5 = 0.96
I0701 15:15:58.517642  4639 caffe.cpp:312] Batch 176, loss = 0.5
I0701 15:15:58.525908  4639 caffe.cpp:312] Batch 177, accuracy/top1 = 0.96
I0701 15:15:58.525920  4639 caffe.cpp:312] Batch 177, accuracy/top5 = 1
I0701 15:15:58.525924  4639 caffe.cpp:312] Batch 177, loss = 0.06
I0701 15:15:58.534083  4639 caffe.cpp:312] Batch 178, accuracy/top1 = 0.88
I0701 15:15:58.534092  4639 caffe.cpp:312] Batch 178, accuracy/top5 = 1
I0701 15:15:58.534096  4639 caffe.cpp:312] Batch 178, loss = 0.56
I0701 15:15:58.542284  4639 caffe.cpp:312] Batch 179, accuracy/top1 = 0.88
I0701 15:15:58.542309  4639 caffe.cpp:312] Batch 179, accuracy/top5 = 1
I0701 15:15:58.542313  4639 caffe.cpp:312] Batch 179, loss = 0.58
I0701 15:15:58.550518  4639 caffe.cpp:312] Batch 180, accuracy/top1 = 0.92
I0701 15:15:58.550525  4639 caffe.cpp:312] Batch 180, accuracy/top5 = 1
I0701 15:15:58.550529  4639 caffe.cpp:312] Batch 180, loss = 0.24
I0701 15:15:58.558662  4639 caffe.cpp:312] Batch 181, accuracy/top1 = 0.94
I0701 15:15:58.558670  4639 caffe.cpp:312] Batch 181, accuracy/top5 = 1
I0701 15:15:58.558675  4639 caffe.cpp:312] Batch 181, loss = 0.08
I0701 15:15:58.566864  4639 caffe.cpp:312] Batch 182, accuracy/top1 = 0.92
I0701 15:15:58.566871  4639 caffe.cpp:312] Batch 182, accuracy/top5 = 1
I0701 15:15:58.566875  4639 caffe.cpp:312] Batch 182, loss = 0.16
I0701 15:15:58.575098  4639 caffe.cpp:312] Batch 183, accuracy/top1 = 0.96
I0701 15:15:58.575114  4639 caffe.cpp:312] Batch 183, accuracy/top5 = 1
I0701 15:15:58.575116  4639 caffe.cpp:312] Batch 183, loss = 0.1
I0701 15:15:58.583202  4639 caffe.cpp:312] Batch 184, accuracy/top1 = 0.9
I0701 15:15:58.583211  4639 caffe.cpp:312] Batch 184, accuracy/top5 = 1
I0701 15:15:58.583214  4639 caffe.cpp:312] Batch 184, loss = 0.52
I0701 15:15:58.591393  4639 caffe.cpp:312] Batch 185, accuracy/top1 = 0.88
I0701 15:15:58.591401  4639 caffe.cpp:312] Batch 185, accuracy/top5 = 1
I0701 15:15:58.591405  4639 caffe.cpp:312] Batch 185, loss = 0.44
I0701 15:15:58.599550  4639 caffe.cpp:312] Batch 186, accuracy/top1 = 0.92
I0701 15:15:58.599560  4639 caffe.cpp:312] Batch 186, accuracy/top5 = 1
I0701 15:15:58.599563  4639 caffe.cpp:312] Batch 186, loss = 0.2
I0701 15:15:58.607689  4639 caffe.cpp:312] Batch 187, accuracy/top1 = 0.84
I0701 15:15:58.607697  4639 caffe.cpp:312] Batch 187, accuracy/top5 = 0.98
I0701 15:15:58.607702  4639 caffe.cpp:312] Batch 187, loss = 0.48
I0701 15:15:58.615893  4639 caffe.cpp:312] Batch 188, accuracy/top1 = 0.96
I0701 15:15:58.615901  4639 caffe.cpp:312] Batch 188, accuracy/top5 = 1
I0701 15:15:58.615906  4639 caffe.cpp:312] Batch 188, loss = 0.02
I0701 15:15:58.624125  4639 caffe.cpp:312] Batch 189, accuracy/top1 = 0.9
I0701 15:15:58.624132  4639 caffe.cpp:312] Batch 189, accuracy/top5 = 1
I0701 15:15:58.624136  4639 caffe.cpp:312] Batch 189, loss = 0.16
I0701 15:15:58.632275  4639 caffe.cpp:312] Batch 190, accuracy/top1 = 0.92
I0701 15:15:58.632287  4639 caffe.cpp:312] Batch 190, accuracy/top5 = 1
I0701 15:15:58.632292  4639 caffe.cpp:312] Batch 190, loss = 0.34
I0701 15:15:58.640480  4639 caffe.cpp:312] Batch 191, accuracy/top1 = 0.88
I0701 15:15:58.640489  4639 caffe.cpp:312] Batch 191, accuracy/top5 = 1
I0701 15:15:58.640493  4639 caffe.cpp:312] Batch 191, loss = 0.28
I0701 15:15:58.648635  4639 caffe.cpp:312] Batch 192, accuracy/top1 = 0.9
I0701 15:15:58.648643  4639 caffe.cpp:312] Batch 192, accuracy/top5 = 1
I0701 15:15:58.648648  4639 caffe.cpp:312] Batch 192, loss = 0.18
I0701 15:15:58.656811  4639 caffe.cpp:312] Batch 193, accuracy/top1 = 0.94
I0701 15:15:58.656819  4639 caffe.cpp:312] Batch 193, accuracy/top5 = 1
I0701 15:15:58.656823  4639 caffe.cpp:312] Batch 193, loss = 0.08
I0701 15:15:58.664870  4639 caffe.cpp:312] Batch 194, accuracy/top1 = 0.88
I0701 15:15:58.664883  4639 caffe.cpp:312] Batch 194, accuracy/top5 = 0.98
I0701 15:15:58.664887  4639 caffe.cpp:312] Batch 194, loss = 0.62
I0701 15:15:58.673106  4639 caffe.cpp:312] Batch 195, accuracy/top1 = 0.84
I0701 15:15:58.673115  4639 caffe.cpp:312] Batch 195, accuracy/top5 = 1
I0701 15:15:58.673118  4639 caffe.cpp:312] Batch 195, loss = 0.34
I0701 15:15:58.681243  4639 caffe.cpp:312] Batch 196, accuracy/top1 = 0.8
I0701 15:15:58.681252  4639 caffe.cpp:312] Batch 196, accuracy/top5 = 1
I0701 15:15:58.681255  4639 caffe.cpp:312] Batch 196, loss = 0.96
I0701 15:15:58.689486  4639 caffe.cpp:312] Batch 197, accuracy/top1 = 0.86
I0701 15:15:58.689494  4639 caffe.cpp:312] Batch 197, accuracy/top5 = 0.98
I0701 15:15:58.689497  4639 caffe.cpp:312] Batch 197, loss = 0.38
I0701 15:15:58.697707  4639 caffe.cpp:312] Batch 198, accuracy/top1 = 0.94
I0701 15:15:58.697720  4639 caffe.cpp:312] Batch 198, accuracy/top5 = 1
I0701 15:15:58.697736  4639 caffe.cpp:312] Batch 198, loss = 0.16
I0701 15:15:58.705878  4639 caffe.cpp:312] Batch 199, accuracy/top1 = 0.9
I0701 15:15:58.705886  4639 caffe.cpp:312] Batch 199, accuracy/top5 = 1
I0701 15:15:58.705890  4639 caffe.cpp:312] Batch 199, loss = 0.36
I0701 15:15:58.705894  4639 caffe.cpp:317] Loss: 0.2751
I0701 15:15:58.705904  4639 caffe.cpp:329] accuracy/top1 = 0.9072
I0701 15:15:58.705909  4639 caffe.cpp:329] accuracy/top5 = 0.9961
I0701 15:15:58.705915  4639 caffe.cpp:329] loss = 0.2751 (* 1 = 0.2751 loss)
